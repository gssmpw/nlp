% NIDS Datasets Survey appendix file
% Author: Patrik Goldschmidt
% Author: Daniela Chuda
% Date - start:  2023-08-23
% Date - update: 2025-04-02

\section{Survey Methodology in Detail}
\label{asec:survey_methodology}

As outlined at the paper's beginning, the survey was conducted using the Systematic Literature Review (SLR) process to achieve comprehensive, unbiased, and replicable results.

The whole SLR process, most notably the specification of a review protocol, resource search, filtering, and results synthesis, was performed by two researchers. The first author (Ph.D. student) conducted the process under the supervision of the second author (Ph.D. supervisor), who helped in fine-tuning the review protocol and validated a random sample (10\%) of the studies. This appendix elaborates on the SLR details.

\subsection{Data Search and Filtering Process}
\label{assec:meth_search_criteria}

In order to ensure the replicability of our research, we outline the process used to identify and filter the datasets included in the survey (Figure~\ref{fig:slr_process}). The steps were as follows:

\begin{figure}[t]
    \centering
    \includegraphics[width=0.675\linewidth]{slr_process.pdf}
    \vspace*{-0.5em}
    \caption{The diagram illustrates the steps of searching, filtering, and selecting relevant studies during the systematic literature review process. Specifically, we identified the objects of interest from three sources: existing survey papers, our own search via paper titles and keywords, and an analysis of backward and forward references. To ensure the feasibility of the reference analysis, it was conducted after the initial filtering. Finally, all identified sources underwent a quality assurance process to include only relevant datasets.}
    \label{fig:slr_process}
\end{figure}

\begin{enumerate}[topsep=2pt]
    % Sum of the papers from Related Work table at the end of the paper
    \item \emph{Listing known datasets:} We extracted known datasets from existing network intrusion surveys listed in Table~\ref{tab:related_work_comparison}, resulting in 302 datasets (with duplicates).

    \item \emph{Own literature search:} We conducted a search with the following query: \textit{network (intrusion $\cup$ anomaly $\cup$ outlier $\cup$ attack $\cup$ threat) (dataset $\cup$ data\,set)}. The publication year was limited to 2023, so papers published since 2024 are not included. Matching on titles or author keywords, we used the following search engines and databases:
    
    \begin{itemize}[topsep=1pt, itemsep=1pt]
        \item SCOPUS: 656 results
        \item ACM Digital Library: 42 results
        \item IEEEXplore: 179 results
        \item Google Scholar: 600 results\footnote{Since Google Scholar returns thousands of results, we reviewed only the first 20 search pages (200 results) for all years, along with the first ten pages for 2020, 2021, 2022, and 2023 (400 results) to identify new datasets not covered in previous surveys. We acknowledge that this process is not entirely replicable. However, omitting it would leave over a dozen datasets undiscovered.}
    \end{itemize}
    
    \noindent In total, this step produced 1477 papers (with duplicates).

    \item \emph{Relevance filtering:} After collecting 302 + 1477 items from the previous steps, we excluded duplicates. Next, we selected only dataset-specific resources, as most articles from the previous step only used existing datasets. This filtering was performed based on title, abstract, and full-text analysis using the following criteria:

\noindent \textbf{Inclusion criteria:}
\begin{itemize}[topsep=1pt, itemsep=3pt, parsep=0pt]
    \item Published until 2023 (inclusive),
    \item Presents novel network data traces specifically for network intrusion or anomaly detection in the cyberthreat detection context.
\end{itemize}

\noindent \textbf{Exclusion criteria:}
\begin{itemize}[topsep=1pt, itemsep=3pt, parsep=0pt]
    \item Presents an IDS method using existing data,
    \item Focuses on host-based intrusions or an intrusion detection subdomain containing environment-specific data without network traces (packets, flows),
    \item Purposed for network traffic classification or non-cyberthreat anomaly detection.

\end{itemize}

    After the filtering, 113 objects were left.

    \item \emph{Backward and forward reference search:} Aiming to compile the most comprehensive contemporary dataset list, we also reviewed papers that cited (forward search) and were cited by (backward search) those obtained in the third step using Google Scholar. This process was limited to papers from the past five years (2018-2023). Applying the same filtering criteria as in the previous step yielded 25 additional papers, bringing the total to 138.

    \item \emph{Quality assurance:} Lastly, we aimed to ensure the quality of the selected papers. While datasets backed by scientific publications are preferable, a non-negligible portion of the data is only available via informal sources (e.g., websites), so including them is also desirable.
    
    Hence, we work with a mixture of scientific papers and other resources that do not follow a standard scientific paper format or provide experimental results, making common research quality assessments~\cite{yang2021_qa_slr} impractical. Since we do not aim to propose new NIDS data quality metrics, our quality check is based on a simple premise: \emph{Is the dataset useful for potential users?} We thus specify:

    \noindent \textbf{Quality-related exclusion criteria:}
    \begin{itemize}[topsep=1pt, itemsep=3pt, parsep=0pt]
        \item Was collected as auxiliary material to other research not primarily focused on data,
        \item Is heavily pre-processed, thus preventing meaningful analysis and sound conclusions,
        \item Is not publicly available.
    \end{itemize}
\end{enumerate}

\noindent Failing to reject all criteria results in the exclusion of a dataset. After their application, \emph{89 datasets remained for a final review}.

%%% Redundant in the final paper, however, might be interesting for extended versions
%In accordance with the specified filtering criteria, it is clear that we focus only on publicly available datasets specifically for network intrusion detection released before 2024. Additionally, our assurance criteria exclude datasets released as auxiliary (supplementary) material with other research not explicitly focused on the data. These datasets are usually very specific and hardly usable by other researchers due to insufficient documentation and low popularity. We further exclude heavily preprocessed datasets (e.g., normalized to contain only values between -1 and 1), as they give little data insights and cannot be used to analyze NIDS decision-making properly.

\subsection{Data Popularity Determination}
\label{assec:meth_popularity_determination}

In order to aid in the dataset selection, we also analyze dataset popularity in contemporary NIDS research. For this purpose, we focus on network intrusion/anomaly detection from Tier 1 and Tier 2 cybersecurity conferences, according to the MLSec group list\footnote{MLSec is a research group at Technical University (TU) Berlin focused on the intersection of cybersecurity and machine learning. They list top-tier cybersecurity conferences at \url{https://mlsec.org/topnotch/}. Similar rankings are also maintained by others, e.g., Guofei Gu: \url{https://people.engr.tamu.edu/guofei/sec_conf_stat.htm}.}. In particular, we surveyed the following 12 conferences: S\&P (Oakland), CCS, Security, NDSS, ACSAC, AsiaCCS, CSF, ESORICS, EuroS\&P, PETS, RAID, and DIMVA, in addition to the MLSec list.

Aiming to maximize the relevance of our findings, we analyzed only papers from the past four years (2020-2023). This was done by manually reviewing conference proceedings and conducting full-text analyses to identify used datasets.