%-------------------------------------------------------------------------------
\section{Experiment}
%-------------------------------------------------------------------------------

\subsection{Setup}
\label{sec:experiment_setup}
\noindent
\textbf{Latent Diffusion Models.} 
We employed three widely-used Stable Diffusion models as base models: Stable Diffusion v1-5 (SD v1-5), Stable Diffusion v2-1 (SD v2-1), and SD-XL 1.0-base (SDXL 1.0). 
For customized models, we downloaded 60 checkpoints from Hugging Face \cite{huggingface}, fine-tuned from three base models (SD v1-5, SD v2-1, and SDXL 1.0), with each base model comprising 20 different checkpoints. Detailed on these 60 checkpoints is provided in the Appendix.
Compared to previous work, our study covers the largest model set to date (60 models, \vs Tree-ring~\cite{wen2023tree} with 1, Gaussian Shading~\cite{yang2024gaussian} with 3, and DiffuseTrace~\cite{lei2024diffusetrace} with 2).

\noindent
\textbf{Image Generation Details.}  
To generate images, we use prompts from the Stable-Diffusion-Prompts dataset~\cite{Gustavosta}. The generated image resolution is 512×512 pixels, with latent noise dimensions set to 4×64×64 and a guidance scale of 7.5. We use DDIM sampling ~\cite{song2020denoising} with 50 timesteps. In practice, the original prompts of the generated images are often not shared. Hence, we use an empty prompt for diffusion inversion~\cite{dimm_inversion}. In this process, we set the guidance scale to 1 and perform 50 timesteps of DDIM inversion.

% \vspace{3pt}
\noindent
\textbf{Baselines.} 
We evaluate three representative latent-noise-based watermarking methods: Tree-ring~\cite{wen2023tree}, Gaussian Shading~\cite{yang2024gaussian}, and DiffuseTrace~\cite{lei2024diffusetrace}. 
For Gaussian Shading, we test both implementations, with and without the ChaCha20~\cite{bernstein2008chacha} secure stream cipher, which shuffles the watermark sequence. Detail of these methods are in the Appendix.

\noindent
\textbf{Evaluation Metrics.} To evaluate watermark presence attacks, we use the area under the ROC curve (AUC). Attack results on watermarking methods indicate stealthiness, calculated as (1 - \text{AUC of watermark presence attack}). We benchmark watermark effectiveness by reporting AUC and TPR at 1\% FPR (noted as TPR@1\%FPR) and bit accuracy for encoded information. For watermarked image quality, we use the CLIP score~\cite{radford2021learning} between generated images and prompts, measured using OpenCLIP-ViT/G~\cite{Cherti_2023_CVPR} and the Fréchet Inception Distance (FID)~\cite{NIPS2017_heuselgans}. FID, which evaluates feature similarity between generated and original images, is calculated from 5,000 images per base model generated using the MS-COCO-2017 dataset\cite{lin2014microsoft}.


\noindent
\textbf{Setup of Watermark Presence Attack.}  
The attacker generates 1,000 clean images using three base models (SD v1-5, SD v2-1, SDXL 1.0) and evaluates performance by averaging results across models. For the watermark feature extractor, we use a 12-layer CNN with convolutional and fully connected layers, ReLU activations, and layer normalization, outputting a 100-dimensional feature vector. Training uses SGD optimizer with a learning rate of 0.01, momentum of 0.9, and a scheduler with a 0.5 decay factor every 50 steps. Detailed architecture is in the Appendix.

\noindent
\textbf{Setup of \tool{}.} 
We integrate SWA-LDM with three baseline methods: \tool with Tree-Ring (\tool{}(T-R)), \tool with DiffuseTrace (\tool{}(D-T)), and \tool with Gaussian Shading (\tool{}(G-S)). Each method uses a key channel count of 1 to construct an 8-bit key with 64 redundant bits. The number of watermark channels is set to 1 for \tool{}(T-R) and 3 for both \tool{}(D-T) and \tool{}(G-S).

\input{Table/base_detection_performance}
\subsection{Comparison to Baseline Methods}
\label{sec:comparison_baselines}

\noindent
\textbf{Stealthiness Comparison.}
% \label{sec:stealthiness_comparison}
We conduct watermark presence attack experiments across \tool and baselines. The attack performance, summarized in the "Stealthiness" column of \cref{tab:base_performance}, shows the average stealthiness achieved by each method against an attacker using different base models. 

The results show that watermark presence attacks effectively detect watermarks in baseline methods. \tool improves stealthiness and provides defense against these attacks. Among baseline methods, Gaussian Shading is the most detectable, with the lowest stealthiness, while DiffuseTrace and Tree-Ring offer slight improvements but remain vulnerable. Gaussian Shading with ChaCha20 increases stealthiness but requires costly per-image nonce management. In contrast, \tool achieves ChaCha20-level stealthiness without nonce dependency, integrating smoothly with DiffuseTrace, Tree-Ring, and Gaussian Shading. Further analysis on the base model’s impact on detection is in \cref{sec:ablation_studies}.


\noindent
\textbf{Watermarking Effectiveness Comparison.}
For the evaluation of watermark effectiveness, As detailed in \cref{sec:experiment_setup}, each base model (SD v1-5, SD v2-1, SDXL 1.0) is fine-tuned to produce 20 checkpoints, each generating 1,000 images, resulting in 60,000 watermarked and 60,000 clean images per method. As shown in \cref{tab:base_performance}, \tool maintains AUC, TPR@1\%FPR, and bit accuracy comparable to original methods, with slight metric decreases due to key construction from latent noise for enhanced stealthiness. \tool also has minimal impact on FID and CLIP scores, preserving LDM-generated image quality.

\input{Table/robustness}
\noindent
\textbf{Benchmarking Watermark Robustness}
\label{sec:robustness_exp}
To evaluate the robustness of \tool, we assess its performance under seven common image perturbations as potential attacks: JPEG compression, random crop, random drop, resize and restore(Resize), Gaussian blur (GauBlur), median filter (MedFilter), brightness adjustments. The parameter ranges are shown in the Appendix.
For each parameter setting of every perturbation, we used 2,000 images generated by the SD v1-5 to evaluate performance. The average verification AUC for each perturbation is reported in \cref{table:robustness}, which compares the robustness of various watermarking methods, both with and without the integration of \tool.
Results indicate that \tool maintains robust watermark verification under moderate image perturbations, demonstrating its robustness. However, incorporating \tool impacts the original robustness of these watermarking methods, especially under high-intensity distortions. This occurs because \tool requires complete recovery of each bit in the key to retrieve the watermark, which can reduce robustness. Nevertheless, unless the image undergoes quality-compromising levels of perturbation, watermark remains practical. 

\subsection{Ablation Studies}
\label{sec:ablation_studies}

\input{Table/as_sdversion}

\noindent
\textbf{Impact of the clean SD model on watermark presence attack.} 
We evaluated whether the effectiveness of the watermark presence attack is influenced by the base model used by the attacker to generate clean images. Results shown in \cref{tab:ab_sd_version} indicate that the choice of base model has minimal impact on attack performance, demonstrating that the watermark detection attack remains effective without requiring knowledge related to the target model.

\input{Table/as_cleanimg}

\noindent
\textbf{Impact of image quantity on watermark presence attack.} 
Following the setup in \cref{sec:experiment_setup}, we varied the number of images generated by the watermark presence attacker to assess its effect on attack performance. Results shown in \cref{tab:ab_clean_img_num}, indicate that within our sampled range, the watermark presence attack's effectiveness remains stable regardless of image quantity. 

\begin{figure}[t]
    \centering
    \begin{minipage}{\linewidth}
        \centering
        \includegraphics[width=0.8\linewidth]{Figure/ablation_studies/legend_image.png} % 调整图例图片的宽度
        \vspace{-0.3cm} 
    \end{minipage}
    
    \resizebox{\columnwidth}{!}{%
    \subfloat[\tool{}(G-S).]{\label{fig:redundancy_G-S}\includegraphics[width=0.35\linewidth]{Figure/ablation_studies/key_redundancy_G-S.png}}\hspace{-0.015\linewidth}
     \subfloat[\tool{}(T-R).]{\label{fig:redundancy_T-R}\includegraphics[width=0.35\linewidth]{Figure/ablation_studies/key_redundancy_T-R.png}}\hspace{-0.015\linewidth}
     \subfloat[\tool{}(D-T).]{\label{fig:redundancy_D-T}\includegraphics[width=0.35\linewidth]{Figure/ablation_studies/key_redundancy_D-T.png}}
     }
     \vspace{-0.3cm}
    \caption{Performance of \tool with varying numbers of redundancies. The effectiveness is demonstrated through AUC and stealthiness metrics, where (a) compares \tool(G-S) with Gaussian Shading and (b) compares \tool(T-R) with Tree-Ring. (c) compares \tool(D-T) with DiffuseTrace.}
    \label{fig:redundancy}
    \vspace{-0.3cm}
\end{figure}

\noindent
\textbf{Impact of key redundancy on stealthiness and verification performance.} 
Following the setup in Section~\ref{sec:experiment_setup}, we evaluate how varying key redundancy levels affects watermark stealthiness and verification AUC. Results in \cref{fig:redundancy} show that with minimal redundancy (4 redundancies), \tool achieves a verification AUC around 0.8, compared to a near-perfect verification AUC of 1 for watermarking methods without \tool, indicating an 80\% key recovery success rate. As redundancy increases to 8, the recovery probability improves to 90\%, and with redundancy over 40, \tool achieves near-complete key recovery without compromising verification AUC.  Across all redundancy levels, \tool maintains consistently high stealthiness.
