\section{Introduction}
\label{sec:intro}

The Latent Diffusion Models (LDMs)  \cite{rombach2022high} represent a significant advancement in efficient, high-quality image generation.
By leveraging Variational Autoencoders (VAEs) \cite{Kingma2014}, LDMs transfer diffusion model operations from pixel space to latent space, allowing UNet \cite{ronneberger2015u} architectures to perform denoising in a lower-dimensional space. 
This shift dramatically enhances computational efficiency, enabling companies and individuals with limited resources to train models for commercial usage.
Consequently, popular models such as Stable Diffusion (SD) \cite{fernandez2023stable}, DALL-E 2 \cite{ramesh2022hierarchical}, and Midjourney \cite{midjourney} have emerged, facilitating the generation of high-quality, realistic images via user-accessible APIs.
 
The rapid advancements of LDMs have introduced critical challenges, particularly concerning copyright infringement and the potential misuse of generated content. Copyright violations arise when malicious actors steal and resell proprietary diffusion models, resulting in substantial financial losses for original creators. Additionally, the capability to generate hyper-realistic images has been exploited by individuals disseminating misinformation and fake news, thereby undermining public trust and social stability. Addressing these issues is paramount for safeguarding intellectual property rights and maintaining societal integrity.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figure/noise_based_detection.pdf}
    \vspace{-0.6cm}
    \caption{The general framework of the latent-based watermarking method for LDMs. They often add the same watermark signal to different generated images, which attackers can exploit to detect the presence of watermark. 
    }
    \vspace{-0.6cm}
    \label{fig:l-r-b_method_framework}
\end{figure}

To alleviate these issues, current LDMs employ watermarking techniques to embed pre-designed imperceptible watermarks within the generated images. Then, one can extract this watermark using corresponding methods to identify the image's origin. 
Existing watermark methods fall into two categories: post-processing watermarking ~\cite{Ruanaidh_Dowling_Boland_1996,Oâ€™Ruanaidh_Pun_2002,cox2007digital,zhang2019robust} and in-generation-process watermarking~\cite{fernandez2023stable, wen2023tree, yang2024gaussian, lei2024diffusetrace, feng2024aqualora}. Post-processing methods add watermarks after the images have been generated by LDMs, but they often compromise image quality \cite{fernandez2023stable}. Alternatively, in-generation-process methods embed watermarks during the image generation process, which can be further divided into model-based~\cite{fernandez2023stable, feng2024aqualora} and latent-based methods~\cite{wen2023tree, yang2024gaussian, lei2024diffusetrace}. The former embeds watermarks by modifying LDMs' parameters, such as VAE or UNet, resulting in training costs. In contrast, the latent-based methods, as shown in \cref{fig:l-r-b_method_framework}, embed a watermark to the latent noise before the denoising process. This approach eliminates the need for extensive retraining and incurs minimal computational overhead, making it highly efficient for practical applications.

However, a significant limitation of current latent-based watermarking techniques is their reliance on constant watermarks across all generated outputs, making them susceptible to detection by malicious users. This paper highlights this vulnerability for the first time, demonstrating that the stealthiness of existing methods can be easily compromised using only the generated images.
Unlike prior works that attempt to remove watermarks without first verifying their presence \cite{saberi2023robustness, yangcan}, we propose an attack to determine whether an image generated by an LDM contains a watermark, which can further inform adversarial actions. This attack also serves as an evaluation metric for the stealthiness of latent-based watermarking techniques.
Specifically, we design a feature extractor to identify constant watermark signals in images generated by the target LDM. Successful extraction of a constant signal indicates the presence of a watermark. Through this attack, we emphasize the urgent need to enhance the stealthiness of watermarking techniques to safeguard against unauthorized use.

To address this vulnerability, we introduce \tool, a plug-and-play component compatible with any latent-based watermarking method to create stealthy watermarks. Our approach randomizes the watermark by embedding image-dependent signals into generated images, effectively preventing the detection of a constant signal. The closest related work, Gaussian Shading, uses stream ciphers for randomization but incurs high management costs due to the need to remember a unique nonce for each image. In contrast, \tool leverages the inherent randomness of latent noise to generate image-dependent watermarks without additional management overhead. Specifically, we introduce a key channel sampled from the latent noise to create a random key that shuffles the watermark, ensuring uniqueness for each image. During watermark verification, \tool reconstructs the latent variable via diffusion inversion and extracts the key to retrieve the original watermark. However, inaccuracies may arise due to diffusion inversion errors and image transmission noises. To mitigate this, we propose an enhancement algorithm to store redundant keys in the key channel while preserving its distribution. The combination of randomized watermarks and key channel enhancement facilitates the generation of stealthy and robust watermarks.


Our contributions are summarized as follows:
\ding{172} We are the first to expose the stealthiness vulnerabilities inherent in current latent-based LDM watermarking methods, which generate constant watermarks that can be easily exploited by malicious users for detection. Our effective watermark presence attack demonstrates this vulnerability, underscoring the critical need for enhanced watermarking strategies.
% \vspace{-0.3cm}
\ding{173} We present \tool, a versatile plug-and-play component compatible with any latent-based watermarking method, designed to create stealthy watermarks. By leveraging the inherent randomness of latent noise, \tool generates image-dependent watermarks without incurring additional management costs. Additionally, we propose an enhancement algorithm that incorporates redundant keys within the key channel, preserving its distribution while significantly improving watermark robustness.
% \vspace{-0.3cm}
\ding{174} We conduct comprehensive experiments to evaluate the proposed watermark presence attack and \tool. Results show that \tool effectively improves the stealthiness of latent-based watermarks while achieving competitive visual quality, image-text similarity, and watermarking robustness.



