\section{Background and Related Works}

\textbf{Latent Diffusion Models.} Latent diffusion models are a computationally efficient version of diffusion models \cite{rombach2022high}. LDMs leverage a pretrained autoencoder to compress image $x\in \mathbb{R}^{3 \times H \times W}$ in RGB space into a lower dimensional latent representation $z \in \mathbb{R}^{c \times h \times w}$. Training and sampling LDMs in the latent space significantly reduces the computational complexity. More specifically, during training, the encoder $\mathcal{E}$ encodes the image $ x $ into a latent representation by $z = \mathcal{E}(x)$. Next, LDMs conduct diffusion and denoising process in the latent space, which converts $z$ to a latent noise $z_T$ and recovers the image latent $\tilde{z}$  from $z_T$ respectively over  $T$ timesteps. Then,  the decoder $\mathcal{D}$ reconstructs the image $\tilde{x}$  from the recovered latent by $\tilde{x} = \mathcal{D}(\tilde{z})$. During sampling, the LDMs sample a noise latent vector $z_T$ from Gaussian distribution \(\mathcal{N}(0, \mathbf{I})\). Subsequently, the trained LDM can utilize sampling methods like Denoising Diffusion Implicit Models (DDIM) \cite{song2020denoising, nichol2021improved} or DPM-Solver \cite{lu2022dpm} to obtain the latent representation of the sampled image $z_s$ from $z_T$ over $T$ timesteps. Then,  the decoder reconstructs the image from the latent by $x_s=\mathcal{D}\left(z_s\right)$. Besides, one can use methods like DDIM Inversion \cite{dimm_inversion} to invert the denoising process and recover the initial noise $z_T$ from the generated image $x_s$. 

\noindent \textbf{Watermarks for Latent Diffusion Models.} LDMs enable individuals to customize their own models for specific styles of image generation via training and fine-tuning, which they can publish and exchange in the online market space such as Civitai \cite{civitai} and Tensor.art \cite{tensorart}. However, these advancements have also raised concerns about the potential abuse of these models and the generated images. For instance, unauthorized commercial exploitation of LDM-generated images lacking inherent copyright protection is a significant risk. Besides, malicious users can generate realistic images to spread rumors and fake news on social media, potentially manipulating important social and economic events such as political elections and the stock market. Therefore, enhancing LDMs with copyright protection and traceability techniques is crucial. Watermarking has a long history to alleviate these issues via labeling image content \cite{Ruanaidh_Dowling_Boland_1996}, which involving incorporating watermark information into the generated images. Then, one can identify the origin of the images by verifying the watermark. 

Existing watermarking methods for LDMs can be categorized into post-processing and in-generation-process watermarks. Post-processing methods add watermarks to images after they have been generated by LDMs. For instance, the Stable Diffusion repository provides methods like DWT-DCT\cite{rahman2013dwt} and RivaGAN~\cite{zhang2019robust}. Despite their widespread usage, direct modification to the images can degrade image quality \cite{fernandez2023stable}. Alternatively,  recent research proposes in-generation-process watermarks, which integrate the watermark embedding with the image generation process. Stable Signature~\cite{fernandez2023stable}  and AquaLora \cite{feng2024aqualora} embed watermarks by fine-tuning the VAE decoder and UNet of the LDMs, respectively. These model-based methods improve the watermarked image quality but introduce substantial computational costs for training the model parameters.
Conversely, recent works propose latent-based watermarks, which embed the watermarks into the latent space of the diffusion models. Tree-Ring \cite{wen2023tree} encodes the watermark in the frequency domain of the latent noise, while Gaussian Shading \cite{yang2024gaussian} maps the watermark to the latent variable following Gaussian distribution. DiffuseTrace \cite{lei2024diffusetrace} uses an encoder model to modify the initial latent noise variable. Latent-based methods are free of model parameter modifications, making them much less computational and more user-friendly.  

While latent-based methods hold great promise for practical usage, our research reveals a critical issue: even though invisible, these techniques produce a constant signal across generated images. This uniformity undermines the stealthiness of the watermarks, increasing the risk of copyright infringement.
To address this, we propose a plug-and-play component that integrates with existing latent-based watermarking methods and enhances their stealthiness.
