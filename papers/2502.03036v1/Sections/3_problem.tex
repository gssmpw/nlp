\section{PROBLEM STATEMENT}

In the domain of sequential recommendation, the primary objective is to predict the next item a user is likely to interact with, based on their historical interaction sequence. Formally, consider a set of users $\mathcal{U} = \{u_1, u_2, \ldots, u_{|\mathcal{U}|}\}$ and a set of items $\mathcal{I} = \{i_1, i_2, \ldots, i_{|\mathcal{I}|}\}$. For each user $u \in \mathcal{U}$, we define an interaction sequence $\mathcal{S}_u = [i_1^{(u)}, i_2^{(u)}, \ldots, i_{n_u}^{(u)}]$, which is a chronologically ordered list of items.

The task of sequential recommendation is to predict the next item $i_{n_u+1}^{(u)}$ that user $u$ will interact with, given the sequence $\mathcal{S}_u$. 
This prediction can be formulated as estimating the probability distribution over the item set $\mathcal{I}$ for the next interaction, conditioned on the historical interactions: $P(i_{n_u+1}^{(u)} = i \mid \mathcal{S}_u)$ for all $i \in \mathcal{I}$.
During training, our objective is to predict the subsequent item $i^{(u)}_{j + 1}$ for every prefix $j$ of the sequence $\mathcal{S}_u$. The desired output sequence is $[i_2^{(u)}, i_3^{(u)}, \ldots, i_{n_u +1}^{(u)}]$ \cite{kang2018self}.