\begin{table*}[]
    \caption{The runtime performance of our sampling method against {\sc UniGen3}, {\sc CMSGen} and {\sc DiffSampler} in terms of unique solution throughput, where each sampler is tasked to generate a minimum of $1000$ solutions within a timeout (TO) of $2$ hours.}
    \vspace{-0.2cm}
    \centering
    \include{table2}
    \label{tab2}
    \vspace{-0.5cm}
\end{table*}

\vspace{-0.2cm}
\section{Experimental Results}
In this section, we demonstrate the effectiveness of our sampling technique. To accomplish this, we developed a prototype of our approach using PyTorch, an open-source machine learning library that integrates Torch's powerful GPU-optimized backend with a Python-friendly interface. For a thorough assessment, we evaluated $60$ problem instances of varying sizes from a public domain benchmark suite. The experiments were performed on a system featuring an Intel Xeon E5-2698 processor running at $2.2$ GHz and $8$ NVIDIA V$100$ GPUs, each with $32$ GB of memory. We present the runtime performance of our method in terms of throughput, defined as the number of unique and valid solutions generated per second, using a single NVIDIA V1$00$ GPU. GD was employed as the optimizer during the training phase, with the learning rate set to $10$ and the number of iterations to $5$. We varied the batch size between $100$ and $1,000,000$, based on the specific instances tested.

We compare the performance of our sampling method with leading SAT sampling methods, specifically {\sc UniGen3} \cite{Soos2020unigen3}, {\sc CMSGen} \cite{Golia2021cmsgen}, and {\sc DiffSampler} \cite{Ardakani2024diffsampler}. These samplers operate directly on the CNF of SAT instances, whereas our method handles the simplified multi-level, multi-output Boolean expressions derived from transforming their logical constraints. Both {\sc UniGen3} and {\sc CMSGen} are highly optimized implementations written in C++, while {\sc DiffSampler} is a Python-based, GPU-accelerated SAT sampler built using the high-performance JAX library. {\sc UniGen3} and {\sc CMSGen} were tested on a server-grade Intel Xeon Gold $6134$ CPU with $3.2$ GHz clock rate and 1TB of RAM. {\sc DiffSampler} was run on a system featuring an Intel Xeon E$5$-$2698$ processor at $2.2$ GHz and $8$ NVIDIA V$100$ GPUs, each equipped with $32$ GB of memory.

\begin{figure}[t]
    \centering
    \input{fig2}
    \caption{A log-log plot showing the runtime in milliseconds versus the number of unique satisfying solutions across all $60$ instances from the sampling benchmark. The dotted lines represent the performance trends for each sampler.}
    \label{fig2}
    \vspace{-0.5cm}
\end{figure}


\vspace{-0.2cm}
\subsection{Runtime Performance}
Table \ref{tab2} presents the sampling performance of our method in terms of throughput for a representative subset of $14$ instances from the sampling benchmark. Throughput is defined as the number of unique solutions generated per second. Each sampler is required to produce at least $1,000$ solutions within a maximum runtime of $2$ hours. The table shows the best throughput results obtained from each sampler. Our method consistently outperforms state-of-the-art samplers in unique solution throughput, achieving speedups ranging from $33.6\times$ to $523.6\times$, depending on the under-test SAT instances. This substantial performance improvement is due to two key factors. First, many logical constraints in the CNF representation are satisfied during the transformation, where sub-clauses are converted into simplified Boolean sub-expressions. This transforms the SAT sampling task into solving constrained paths in a simplified, multi-level, multi-output Boolean expression, significantly reducing the number of logical operations. Second, by framing the sampling problem as a learning task, where the computation of each sample is independent, GPU acceleration can be leveraged to further enhance runtime performance.

Fig. \ref{fig2} demonstrates how the runtime performance of each sampler varies as the number of unique solutions increases. A critical aspect of this comparison is the overall efficiency of our sampling method relative to {\sc UniGen3}, {\sc CMSGen}, and {\sc DiffSampler}. This is particularly evident when sampling larger quantities of solutions, where the runtime shows only a slight increase as the solution count grows.



\vspace{-0.2cm}
\subsection{Learning Dynamics}
We analyze the learning dynamics of our sampling method, focusing on hyper-parameters such as iterations and batch size. Fig. \ref{fig3} shows the progress in generating unique solutions over $10$ iterations, where the number of unique solutions increases with more iterations. Increasing the batch size improves runtime performance by leveraging GPU parallelism, but at the cost of higher memory usage. The GPU memory demand, as shown in Fig. \ref{fig3}, grows with both the complexity of the Boolean function derived from the CNF transformation and the batch size. In scenarios requiring a high number of unique samples with limited GPU memory, the practical solutions are to either run more iterations, reducing throughput, or use GPUs with larger memory.


% We present an in-depth analysis of the learning dynamics of our sampling method, focusing on hyper-parameters like the number of iterations and batch size. Fig. \ref{fig3} illustrates our sampler's progress in generating unique solutions over the course of $10$ training iterations. The learning curves indicate that as the number of iterations increases, our sampler uncovers more unique solutions. Although gradient descent lacks a theoretical guarantee of reaching the global minimum in non-convex landscapes, including our continuous SAT problem formulation, our experiments show its ability to find high-performing solutions in this context. While these solutions may not represent the global minimum in the continuous domain, they still meet the logical constraints of the discrete form.

\begin{figure}
    \centering
    \scalebox{0.9}{
    \input{fig3}}
    \caption{(Left) Learning curve showing the number of unique satisfying solutions over iterations. (Right) Log-log plot of GPU memory usage (MB), measured by ``nvidia-smi'', across different batch sizes for a subset of $4$ CNF instances.}
    \label{fig3}
    \vspace{-0.4cm}
\end{figure}


% \begin{figure}
%     \centering
%     \input{fig4}
%     \caption{Log-log plot of GPU memory usage of our sampler in megabytes, measured by ``nvidia-smi'' across different batch sizes for a representative subset of $4$ instances from the sampling benchmark.}
%     \label{fig4}
% \end{figure}

% One way to enhance the runtime performance of our sampler is by increasing the batch size, enabling more samples to be generated simultaneously through the parallel processing capabilities of GPUs. However, this improvement comes at the expense of GPU memory usage. The GPU memory demand rises based on the complexity of the simplified multi-output, multi-level Boolean function derived from the CNF transformation and the batch size. For instance, Fig. \ref{fig3} displays GPU memory usage, as recorded by ``nvidia-smi'', across varying batch sizes. The figure highlights the significant increase in memory consumption with larger batch sizes. In cases where the goal is to generate a high number of unique samples but GPU memory is limited, the practical solution is to either run more iterations, resulting in lower throughput, or use more powerful GPUs with greater memory capacity.
\vspace{-0.2cm}
\subsection{Ablation Study}
In this section, we analyze the extent of GPU acceleration by comparing the runtime performance of our sampler between the GPU and CPU, as presented in Fig. \ref{fig5}. The data shows that GPU execution results in an average speedup of $6.8\times$ over CPU execution. Additionally, we provide the rate of reduction in the number of bit-wise operations due to the transformation, measured as the number of operations in the CNF divided by the number of operations in the resulting multi-level, multi-output Boolean function in terms of 2-input gate equivalents in Fig. \ref{fig5}, demonstrating an average reduction of $4.2\times$. Finally, we present the transformation time required to convert CNF into a multi-level, multi-output Boolean function in Fig. \ref{fig5}. This conversion time is comparable to that of conversion time of SAT applications represented in higher-level logical formats into CNF. Given the superior runtime performance of our sampler, we suggest that SAT applications in high-level logical formats could be directly transformed into a multi-level, multi-output Boolean function.


