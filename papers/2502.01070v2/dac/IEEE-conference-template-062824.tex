\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\usepackage{listings}
\usepackage{color}

\usepackage{geometry}
\usepackage{multirow}
\usepackage{makecell}
\geometry{margin=1in}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{FP8 is not a Number Format: \\
An Investigation of FP8 Across Accelerators \\
% {\footnotesize \textsuperscript{*}Note: Sub-titles are not captured for https://ieeexplore.ieee.org  and
% should not be used}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle

\begin{abstract}
The introduction of 8-bit floating point (FP8) in recent AI accelerators has sparked great interest in using FP8 for training and inference. However, unlike 16-bit floating-point formats, a shared scaling factor is needed for FP8 in deep learning applications. Because of this, although the E5M2 and E4M3 binary formats are individual values, the methods for scaling and accumulation remain unspecified and vary depending on the hardware and software implementations. In other words, FP8 is closer in spirit to a quantization format than to a number format. In this work, for the first time, we explore how different devices, specifically the NVIDIA H100 and the Intel Gaudi v2, realize and accelerate FP8 computations in practice.
\end{abstract}

\begin{IEEEkeywords}
FP8, LLM, Quantization, GEMM, ULP, Llama
\end{IEEEkeywords}

\section{Introduction}
\input{01_introduction}

\section{Related Work}
\input{02_related_work}

\section{Methods}
\input{03_methods}

\section{Results}
\input{04_results}



\subsection{The Effect of the FP8 format}

\begin{table}[htbp]
\centering
\caption{MMLU Result for different FP8 Formats}
\label{tab:FP8_type_mmlu}

{\small
\begin{tabular}{llllll}
\Xhline{1.2pt}  

\multicolumn{1}{c|}{Model}                          & \multicolumn{1}{c|}{FP8 type} & \multicolumn{1}{c}{MMLU accuracy}  \\ \cline{1-3}
\multicolumn{1}{c|}{\multirow{2}{*}{Llama-3.2-1B}}  & \multicolumn{1}{c|}{E4M3}     & \multicolumn{1}{c}{34.65\%}        \\
\multicolumn{1}{c|}{}                               & \multicolumn{1}{c|}{E5M2}     & \multicolumn{1}{c}{33.80\%}        \\ \cline{1-3}
\multicolumn{1}{c|}{\multirow{2}{*}{Llama-3.2-3B}}  & \multicolumn{1}{c|}{E4M3}     & \multicolumn{1}{c}{53.75\%}        \\
\multicolumn{1}{c|}{}                               & \multicolumn{1}{c|}{E5M2}     & \multicolumn{1}{c}{52.81\%}        \\ \cline{1-3}
\multicolumn{1}{c|}{\multirow{2}{*}{Llama-3.1-8B}}  & \multicolumn{1}{c|}{E4M3}     & \multicolumn{1}{c}{62.90\%}        \\
\multicolumn{1}{c|}{}                               & \multicolumn{1}{c|}{E5M2}     & \multicolumn{1}{c}{61.88\%}        \\ \cline{1-3}
\multicolumn{1}{c|}{\multirow{2}{*}{Llama-3.1-70B}} & \multicolumn{1}{c|}{E4M3}     & \multicolumn{1}{c}{75.39\%}        \\
\multicolumn{1}{c|}{}                               & \multicolumn{1}{c|}{E5M2}     & \multicolumn{1}{c}{74.70\%}        \\
\Xhline{1.2pt}  
\end{tabular}
}
\end{table}

We conducted a comparative analysis of FP8 formats to determine the optimal choice for inference by measuring MMLU accuracy using the lm-evaluation-harness framework. Specifically, we compared the performance of the E4M3 and E5M2 formats.
The E4M3 format allocates relatively more bits to the mantissa, offering higher precision. In contrast, the E5M2 format dedicates more bits to the exponent, enabling a higher dynamic range.

Table \ref{tab:FP8_type_mmlu} presents the MMLU accuracy results for four models: Llama-3.2-1B, Llama-3.2-3B, Llama-3.1-8B, and Llama-3.1-70B, when evaluated with these two FP8 formats.
Experimental results consistently demonstrated that the E4M3 format outperformed E5M2 across all scenarios, making it the superior choice for inference. Notably, applying appropriate methods to mitigate outliers and effectively adjust the range is expected to further enhance the efficiency of the E4M3 format.




% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\centering
\caption{MMLU Result for stochastic rounding options}
\label{tab:sr_mmlu}
{\small
\begin{tabular}{c|cc|c}
\Xhline{1.2pt}  
\multirow{2}{*}{Model}                    & \multicolumn{2}{c|}{Stochastic Rounding} & \multirow{2}{*}{MMLU accuracy} \\
                                          & input                       & weight             &                                \\
                                          \hline
\multirow{4}{*}{Llama-3.2-1B}             & \checkmark                  & \checkmark         & 33.94\%                        \\
                                          & \checkmark                  &                    & 34.31\%                        \\
                                          &                             & \checkmark         & 35.20\%                        \\
                                          &                             &                    & 34.65\%                        \\
                                          \hline
\multirow{4}{*}{Llama-3.2-3B}             & \checkmark                  & \checkmark         & 54.09\%                        \\
                                          & \checkmark                  &                    & 53.95\%                        \\
                                          &                             & \checkmark         & 54.41\%                        \\
                                          &                             &                    & 53.75\%                        \\
                                          \hline
                                          
\multirow{4}{*}{Llama-3.1-8B}             & \checkmark                  & \checkmark         & 62.24\%                        \\
                                          & \checkmark                  &                    & 62.43\%                        \\
                                          &                             & \checkmark         & 62.55\%                        \\
                                          &                             &                    & 62.90\%                        \\
                                          \hline
                                          
\multirow{4}{*}{Llama-3.1-70B}            & \checkmark                  & \checkmark         & 75.05\%                        \\
                                          & \checkmark                  &                    & 75.18\%                        \\
                                          &                             & \checkmark         & 75.30\%                        \\
                                          &                             &                    & 75.39\%           
\\ \Xhline{1.2pt}  
                                          
\end{tabular}
}

\end{table}


\section{Discussion}
\input{05_discussion}


\section*{Acknowledgment}

The preferred spelling of the word ``acknowledgment'' in America is without 
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
acknowledgments in the unnumbered footnote on the first page.

\section*{References}

Please number citations consecutively within brackets \cite{b1}. The 
sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

Number footnotes separately in superscripts. Place the actual footnote at 
the bottom of the column in which it was cited. Do not put footnotes in the 
abstract or reference list. Use letters for table footnotes.

Unless there are six authors or more give all authors' names; do not use 
``et al.''. Papers that have not been published, even if they have been 
submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
Capitalize only the first word in a paper title, except for proper nouns and 
element symbols.

For papers published in translation journals, please give the English 
citation first, followed by the original foreign-language citation \cite{b6}.

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\bibitem{b8} D. P. Kingma and M. Welling, ``Auto-encoding variational Bayes,'' 2013, arXiv:1312.6114. [Online]. Available: https://arxiv.org/abs/1312.6114
\bibitem{b9} S. Liu, ``Wi-Fi Energy Detection Testbed (12MTC),'' 2023, gitHub repository. [Online]. Available: https://github.com/liustone99/Wi-Fi-Energy-Detection-Testbed-12MTC
\bibitem{b10} ``Treatment episode data set: discharges (TEDS-D): concatenated, 2006 to 2009.'' U.S. Department of Health and Human Services, Substance Abuse and Mental Health Services Administration, Office of Applied Studies, August, 2013, DOI:10.3886/ICPSR30122.v2
\bibitem{b11} K. Eves and J. Valasek, ``Adaptive control for singularly perturbed systems examples,'' Code Ocean, Aug. 2023. [Online]. Available: https://codeocean.com/capsule/4989235/tree
\end{thebibliography}

\vspace{12pt}
\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
