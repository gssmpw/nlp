\chapter{Numerical Results}
\textbf{In the previous section, two formulations of FWI within Deep Learning frameworks were presented. This chapter presents numerical results and additional outcomes of these implementations.}  

\section{Software Setup}\label{sec:results_results_software_setup}
Throughout the work shown in this chapter, Python 3.7 with the Anaconda distribution was used as the primary development language.


\section[FWI as a Data-Driven DNN]{FWI as a Data-Driven DNN}\label{sec:results_FWI_as_a_Learned_Direct_Approximation}
% \subsection{Experiment Setup}\label{sec:results_Experiment_setup}
% The hypothesis under investigation is as follows ``Given a seismic trace in time domain $\mathcal{T}$, invert for the $v_p$ velocity parameter via a DNN which transforms the input data into pseudo-spectral domain and learns to invert for a velocity estimate.''

\subsection{Train-Test Data Split}\label{sec:results_Train-Test_Data}
Learning the inversion from time to pseudo-spectral domain requires a training dataset which maps time to pseudo-spectral components and their respective velocity profile. A data generator was designed to create synthetic data on-the-fly for a 2000\si{ms} time window. The steps involved in the data generator are:
\begin{enumerate}[i)]
    \item Randomly create velocity profile $v_p$ for a 2000ms distance, with value ranging from 1450\si{ms^{-1}} and 4500\si{ms^{-1}}. The lower bound of 1400\si{ms^{-1}} was selected for the water column since the observed velocity in normal off-shore seismic exploration conditions ranges from 1440\si{ms^{-1}} to 1540\si{ms^{-1}} \citep{Cochrane1991}. The upper bound of 4000\si{ms^{-1}} was selected as this is the upper limit of velocity in porous and saturated sandstones \citep{Lee1996}. The assumption is made that limestones, carbonates and salt deposits are not present in the subsurface model being inverted since these would have velocity in excess of 4000\si{ms^{-1}} and go beyond the above defined parameters.
    \item Estimate the density $\rho$ using Gardner’s equation \citep{Gardner1974} $\rho=\alpha v_p^{\beta}$ where $\alpha=0.31$ and $\beta=0.25$ are empirically derived constants.
    \item At each interface, calculate the Reflection Coefficient $\mathcal{R}=\frac{\rho_2v_{p_{2}} - \rho_1v_{p_{1}}}{\rho_2v_{p_{2}} + \rho_1v_{p_{1}}}$ where $\rho_i$ is density of medium $i$ and $v_p$ is the p-wave velocity of medium $i$.
	\item For each medium, calculate the Acoustic Impedance $\mathcal{Z}=\rho v_p$.
    \item Define a wavelet $\mathcal{W}$. This was selected to be a Ricker wavelet at 10\si{Hz} \citep{Ryan1994}. The Ricker wavelet is a theoretical waveform that takes into account the effect of Newtonian viscosity and is representative of seismic waves propagating through visco-elastic homogeneous media \citep{wang2015frequencies}, thus making it ideal for this numerical simulation. The central frequency of 10\si{Hz} was chosen as a nominal value based on literature results to be representative of normal FWI conditions \citep{Morgan2013}. Beyond 10\si{Hz} would be considered to be super-high-resolution FWI \citep{mispel2019high}, which goes beyond the scope of this work.
	\item The reflection coefficient time series and wavelet are convolved to produce the seismic trace $\mathcal{T}$.
	\item Fourier coefficients for magnitude $\mathcal{M}(\zeta)$ and phase $\mathcal{M}(\phi)$ are derived based on the \ac{FFT}.
\end{enumerate} 

To exploit higher dimensionality and use 2D CNNs, a secondary generator was designed to perform a \ac{CWT}. This was identical to the previous generator, expect that in Step (vii), produce a CWT with sampling frequencies from 1-75\si{Hz} and wavelet identical to the wavelet given in Step (v). This is referred to as Step (viii). The different steps for these two generator flows are shown in Figure~\ref{fig:data_generators} for a sample velocity profile. These generators will be referred to as Generator 1 and Generator 2 respectively.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.9\textwidth]{26_Dissertation_02_generator_comparison_64-eps-converted-to.pdf}
	\caption[Workflow for creating a pseudo-spectral synthetic trace.]{Workflow for creating a pseudo-spectral synthetic trace.}
	\label{fig:data_generators}
\end{figure}
\clearpage
The parameters assigned with the generators are given in Table~\ref{tab:data_generator_params} and distribution of layers within a training run for 1,000,000 samples and 100,000 testing samples are given in Figure~\ref{fig:data_generators_params}. The \textbf{vel\_min\_separation}, \textbf{time\_min\_separation} are two key parameters as they control the velocity and temporal resolution of the model respectively.

\begin{table*}[ht!]
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}llc@{}}\toprule
        Parameter                  & Description                 & Value\\ \hline
        length (ms)                & Length of trace             & 2000  \\
        vel\_min (m/s)             & Minimum velocity            & 1450  \\
        vel\_max (m/s)             & Maximum velocity            & 5000  \\
        vel\_min\_separation (m/s) & Minimum velocity separation & 10    \\
        time\_min (ms)             & Minimum time sample         & 500   \\
        time\_max (ms)             & Maximum time sample         & 1500  \\
        time\_min\_separation (ms) & Minimum time separation     & 2     \\
        layers\_min                & Minimum number of layers    & 1     \\
        layers\_max                & Maximum number of layers    & 4     \\
        dominant\_frequency        &\si{Hz} of dominant frequency & 10     \\ \hline
    \end{tabular}
    \caption{Synthetic data generator parameters.}\label{tab:data_generator_params}
\end{table*}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.95\textwidth]{26_Dissertation_01_training_data_distributions-eps-converted-to.pdf}
    \caption[The overall statistics on the training and testing dataset.]{The overall statistics on the training and testing dataset.}
    \label{fig:data_generators_params}
\end{figure}

\subsection{DNN Framework}\label{sec:results_DNN_Framework}
Figure~\ref{fig:DNN_framework_1} illustrates the DNN framework used to first invert for the Fourier coefficients from the time domain and then invert for velocity profile. The complete workflow has five modules, with each module consisting of a NN with 5 fully connected hidden layers. The layer distributions consisted of an input layer of 2000 neurons, a set of 5 hidden layers of sizes 1000, 500, 250, 500, 1000 neurons, and an output layer of 2000 neurons. This hour-glass design can be considered representative of multi-scale FWI \citep{Bunks1995} since at each hidden layer, the NN learns an abstracted frequency component of the data at a different scale. This is Indeed synonymous with modern DNN approaches such as encoder-decoders and U-Net \citep{ronneberger2015u} and how they extract data representations \citep{Yu2019,Berthelot2018}. The final concatenate network learns the optimal way for combining the outputs. In total, the DNN had 25 hidden layers. In the case of the CWT pseudo-representation, we designed a similar framework to that shown in Figure~\ref{fig:DNN_framework_1}, except that the learned CWT network has an additional dimension to be able to create the CWT. This is shown in Figure~\ref{fig:DNN_framework_2}. The learned CWT network has layers of shape $(2000\times9), (1000\times18), (500\times37), (250\times37), (500\times37), (1000\times74), (2000\times74)$. The velocity inversion DNNs were built to be representatives of Conv1D, Conv2D, VGG, ResNet architectures respectively. A full architectural summary and training process for these network is provided in Appendix~\ref{sec:app_results_architectural_summary_dnn_workflow}.

\begin{figure}[!ht]
	\centering
	\subbottom[Fourier components.\label{fig:DNN_framework_1}]{\includegraphics[width=0.47\textwidth]{DNN_framework_1.png}}
	\subbottom[CWT.\label{fig:DNN_framework_2}]{\includegraphics[width=0.47\textwidth]{DNN_framework_2.png}}
	\caption[Pseudo-spectral FWI DNN workflow.]{Pseudo-spectral FWI DNN frameworks to invert for Fourier Transform and CWT. $X$ is the input time domain, $Y$ is the output $v_p$ velocity and $\mathcal{M}$ is the Fourier domain, with magnitude $\zeta$ and phase $\phi$. Each component (blue or grey box) is a network.}         
	\label{fig:DNN_frameworks}
\end{figure}

\clearpage
\subsection{Multi-layer Numerical Results}\label{sec:results_Multi-layer_1D_Numerical_Results}
The first experiment was to assert the validity of the framework in a 1D synthetic case. Using Generator 1 with 1,000,000 training and 100,000 testing samples, with DNN framework A for the Fourier components, loss function was set to be the Sum of Squared Error, stabilized via fixed $L_2-norm$ regularization, data batching, early stopping, and executed for 120 epochs (the number times that the algorithm passes through the entire training dataset). Gradient descent update was optimized via an ADAM optimizer. The DNN was implemented using Keras 2.2.4 and TensorFlow 1.13.1 backend. This was trained on an Intel i7-7800x X-series CPU workstation provided by the Department of Physics at the University of Malta.

Figure~\ref{fig:dnn_fwi_1d_predictions} illustrates the application of DNN architecture for a sample of unseen data and the respective inversion. Inspection of the first 750\si{ms} indicates that the DNN approach is able to reconstruct both the velocity and the waveform profile near perfectly, irrespective of the number of layers and the magnitude of the acoustic difference in this time range. Indeed, these indicate the validity of this approach. Beyond 750\si{ms}, reconstructions start suffering from slight degradation. As illustrated in the velocity reconstruction of the middle figure, the inaccuracy is minimal and ranges $\pm$100\si{ms^{-1}}. This leads to perturbations in the reconstruction and does not allow for perfect matching. Further inspection suggests that the main source of error is due to the magnitude component of the network (red). 

\begin{figure*}[ht!]
	\centering
	\includegraphics[width=0.9\textwidth]{2_multilayer_5_xjenza_Selected_12-eps-converted-to.pdf}
	\includegraphics[width=0.9\textwidth]{2_multilayer_5_xjenza_Selected_63-eps-converted-to.pdf}
	\includegraphics[width=0.9\textwidth]{2_multilayer_5_xjenza_Selected_6-eps-converted-to.pdf}
	\includegraphics[width=0.9\textwidth]{2_multilayer_5_xjenza_Selected_69-eps-converted-to.pdf}
	\caption[DNN predictions]{Four different predictions obtained from learned weights of the DNN on unseen data. The top panels are the velocity profile reconstructions from the two NN architecture branches ($\mathcal{M}(\zeta)$ and $\mathcal{M}(\phi)$) and the combined result. Bottom panels are the observed and inverted waveforms.}
	\label{fig:dnn_fwi_1d_predictions}
\end{figure*}

Figure~\ref{fig:dnn_fwi_1d_performance} shows the DNN mean squared error performance over the different epochs per DNN component. This graph indicates that the network is learning since mean squared error is overall decreasing at each epoch. The drastic decreases in the mean squared error at different epoch levels can be attributed to the step-wise reductions in learning rate shown in Figure~\ref{fig:dnn_perf_lr}. This varying learning rate allows the network to move to a deeper optimization level and approach a more global minima for the optimization problem. Interestingly, this performance plot indicates that the technique might suffer from a compounding error issue. The two best performing components are the first layer of learning for the inversion, namely Time-to-FFT-Magnitude and Time-to-FFT-Phase, as their mean squared error performance plateaus are at $10^{-1}$. In the second phase of the inversion from the respective FFT components to velocities (FFT-Magnitude-to-Velocity and FFT-Phase-to-Velocity) error plateaus are at $10^1$, which is two orders of magnitude greater. The final network component sits even higher on the scale at $10^2$.

\clearpage
\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth,  trim = {0.4cm 11.9cm 0.4cm 0.1cm}, clip]{2_multilayer_7_xjenza_DNN_perf_train_test_LEGEND-eps-converted-to.pdf}
    \hfill
    \subbottom[Training dataset MSE over the different epochs per DNN component. Overall performance is decreasing per epoch, indicating that the DNN is learning to invert.\label{fig:dnn_perf_metric_train}]
    {\includegraphics[width=0.43\textwidth,  trim = {0.3cm 0.2cm 20cm 0cm}, clip]{2_multilayer_7_xjenza_DNN_perf_train_test-eps-converted-to.pdf}}
    \hspace{10pt}
    \subbottom[Test dataset MSE over the different epochs per DNN component. Overall MSE is decreasing per epoch and there are not signs of over-fitting.\label{fig:dnn_perf_metric_test}]
    {\includegraphics[width=0.43\textwidth,  trim = {10.2cm 0.2cm 10.1cm 0cm}, clip]{2_multilayer_7_xjenza_DNN_perf_train_test-eps-converted-to.pdf}}
    
    \subbottom[Learning Rate performance over the different epochs per DNN component.\label{fig:dnn_perf_lr}]
    {\includegraphics[width=0.43\textwidth,  trim = {20cm 0.2cm 0.15cm 0cm}, clip]{2_multilayer_7_xjenza_DNN_perf_train_test-eps-converted-to.pdf}}
    \caption{DNN training performance metrics.}
    \label{fig:dnn_fwi_1d_performance}
\end{figure*}

\subsection{Pre-Processing}\label{sec:results_Normalisation}
In classical DNN approaches, it is best practice to normalise or standardize the dataset. An experiment was executed to assess what would happen with and without normalisation of the data for the Magnitude component architecture shown in the previous section. 10,000 training and 1,000 validation traces were generated using Generator 1, stored in memory so the only variance will be the scaling and trained for 200 epochs with early stopping and reducing learning rate monitor. The compute and memory resources necessary for this test were small enough such that this experiment was executed on a 2.6 GHz 6-Core Intel Core i7, 16GB RAM personal computer. The scaling approaches considered are the Standard Scaler and Min-Max Scaler. These are defined as:
\begin{equation}
    x_{MM} = \frac{x-x_{MIN}}{x_{MAX}-x_{MIN}}, 
\end{equation}
\begin{equation}
    x_{SS} = \frac{x-\mu}{\sigma},
\end{equation}
where $x_{MM}$, $x_{SS}$ are the scaled values for Min-Max and Standard Scaler respectively, $x_{MIN}$, $x_{MAX}$ are the minimum and maximum values of the data, $\mu$ is the mean and $\sigma$ is the standard deviation of the training samples.

The mean square error for the dataset with-out and with processing was evaluated and is shown in Table~\ref{tab:normalisation_mse}. The value of the mean squared error indicates that pre-processing in the form of normalisation or standardization should not be applied to the problem dataset. The impact of the pre-processing on the inverted velocity profiles is shown in Figure~\ref{fig:scaling_velocity}. In either case, Min-Max scaling was the worst performant, only able to reconstruct the first layer at 500\si{ms}.

\begin{table*}[ht!]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}cc@{}}\toprule
Pre-Processing & Mean Square Error \\ \hline
No Normalisation          & 4,041 \\
Min Max Normalisation     & 296,672 \\
Standard Scaling          & 17,653 \\\hline
\end{tabular}
\caption{Quantitative assessment on the impact of pre-precessing}\label{tab:normalisation_mse}
\end{table*} 

% Figure~\ref{fig:scaling_metrics} illustrates the loss value with and without scaling for both the training and validation dataset. Looking at just these metrics for network evaluation, it is evident that scaling should be implemented as it is improving the network performance by at least order of 4. When doing the prediction and inverse-scaling on the test data, the reconstruction of the data from the scaling is of poorer quality. Figure~\ref{fig:scaling_velocity} shows three velocity profiles inverted with and without scaling. In either case, Min-Max scaling was the worst performant, only able to reconstruct the first layer at 500\si{ms}. Standard Scaling was considered as a potential, however, considering the third velocity profile, we can see how without scaling, more of the second layer is being reconstructed. Furthermore, having to scale data would include an additional compute overhead. For these reasons, it was decided that normalization would not be applied to this problem dataset. 

% \clearpage
% \begin{figure}[!ht]
% 	\centering
%     \subbottom[Comparison of DNN performance metrics with and without scaling. \label{fig:scaling_metrics}]{\includegraphics[width=0.6\textwidth]{26_Dissertation_07_Normalization_01_metric_performance-eps-converted-to.pdf}}
% 	\subbottom[Comparison of velocity profiles with and without scaling. \label{fig:scaling_velocity}]{\includegraphics[width=0.6\textwidth]{26_Dissertation_07_Normalization_02_vel_profiles-eps-converted-to.pdf}}
% 	\caption[Comparison on the application of data scaling.]{Comparison on the application of data scaling.}        
% 	\label{fig:application_scaling}
% \end{figure}

\clearpage
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{26_Dissertation_07_Normalization_02_vel_profiles-eps-converted-to.pdf}
    \caption[Comparison of velocity profiles with and without scaling.]{Comparison of velocity profiles with and without scaling.}
    \label{fig:scaling_velocity}
\end{figure}

\subsection{Architecture Comparison}\label{sec:results_Architecture_Comparison}
In §~\ref{sec:results_Multi-layer_1D_Numerical_Results}, the validity of the approach was assessed and pitfalls identified for a simple example. This was extended to identify the ideal configuration in terms of architecture, loss, time-to-train and over-fitting. The following computation was made using Python 3.7 and Tensorflow 2.0.0 with a Keras backend. It was executed on an NVIDIA Titan V Graphical Processing Unit with 5120 cores and 12GB ram provided in collaboration with Dr. Carlo Giunchi at Istituto Nazionale di Geofisica e Vulcanologia at Pisa.

The conversion from time trace to pseudo-spectral representation was fixed for all 1D and 2D networks such that the comparison was done on only the different inversions architectures. This architecture given as ``Time to Pseudo-Spectral 1D'' or ``Time to Pseudo-Spectral 2D'' can be found in Appendix~\ref{sec:app_results_architectural_summary_dnn_workflow}. Figure~\ref{fig:dnn_fwi_1_comparison_dnn_arch} gives a comparison of different DNN architectures, loss optimizers, duration of training and validation curves. The networks were trained for the same number of epochs without early stopping. The training and validation data consisted of 1,000,000 and 100,000 generated traces using Generator 1 and Generator 2 respectively. The loss was fixed to be the MSE and lr represents the learning rate on a secondary axis in Red. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{26_disssertation_05_ArchComparison-eps-converted-to.pdf}
    \caption[Normalised comparison of DNN architectures]{Normalised comparison of DNN architectures, loss optimizer, duration of training and validation curves. The networks were trained for the same number of epochs without early stopping. The loss is the MSE and lr is the Learning Rate.}
    \label{fig:dnn_fwi_1_comparison_dnn_arch}
\end{figure}

Considering all loss curves, the best performing setup is that for Conv2D and RMSprop with 20,000 loss and worst performant are MLP-Adam and Conv2D-Adam. The deeper more complex Conv2D, VGG and ResNet architectures in general seem to be experiencing some under-fitting due to the parallel, non-convergent training-validation curves. This would be indicative that the complexity in the current problem is not high and less complex network type such as Conv1D would be more suitable. As evidenced by the gradual monotonic decrease in validation curves, none of the architecture-loss optimizer combinations experienced over-fitting. Conv1D-Adam and MLP, Conv1D and Conv2D for RMSprop seem to indicate increases between epochs 2 and 10 on the validation curves. This would be symptomatic to over-fitting; however, the learning rates move to lower orders of magnitude. This enables networks to continue training and move to lower orders of loss value. The lr for some of the combinations is remaining unvaried, namely Conv1D-Adagrad, Conv2D-Adagrad and Conv2D-Adadelta, all of VGG and ResNet-Adadelta and ResNet-Adam. This is indicative that these networks are not close to reaching a global minimum and would benefit from training for more epochs. Indeed, this would indicate that more complex architectures such as VGG and ResNet require longer training epochs. Indeed, the loss-validation curves further highlight this as, in general, they do not plateau. The more complex and deeper the architectures required longer training times. MLP averaged training time of 41.5 compute hours, whereas ResNet averaged 117 compute hours. These performance metrics should not be considered in isolation and visual inspection of inversion should be equally assessed.

Figure~\ref{fig:dnn_fwi_1_vel_results} show two sample traces inverted for all these architecture and loss optimizer combinations. Upon initial qualitative inspection, it is clearly evident how Conv1D is the superior architecture. This further confirms the previous assertion that for this given experiment, deeper and more complex architecture types such as Conv2D, VGG and ResNet are not necessary and can be detrimental to overall performance. Common to all architectures is a ringing effect on the time trace inversion. This is due to inadequate inversion for the velocity profile where the initial velocity increase is identified correctly, but beyond this, there is a step-wise incremental velocity profile. This is present in simple MLP and more complex DNNs. Conv1D is the only architecture type which is symptom free. 

\begin{figure}[!ht]
	\centering
    \subbottom[Trace A\label{fig:dnn_fwi_1_vel_results_A}]{\includegraphics[width=0.9\textwidth]{26_disssertation_06_TimeSeriesComparison2_5-eps-converted-to.pdf}}
	\subbottom[Trace B\label{fig:dnn_fwi_1_vel_results_B}]{\includegraphics[width=0.9\textwidth]{26_disssertation_06_TimeSeriesComparison2_1-eps-converted-to.pdf}}
    \caption[Velocity inversion for different DNN architectures and losses.]{Velocity inversion for different DNN architectures and losses.}
    \label{fig:dnn_fwi_1_vel_results}
\end{figure}

\clearpage
\subsection{Architecture-Loss Combination}\label{sec:results_arch_loss_combination}
All results are summarised in Table~\ref{tab:quantitative_assessment_arch_loss} to quantitatively assess the inversion process and the DNN performance metric. The evaluation criteria are:
\begin{itemize}
    \itemsep0em
    \item Duration ($d$): 	Duration of training
    \item Train ($t$): 		Lowest MSE within training
    \item Validation ($v$): Qualitative assess of under-fitting/over-fitting and learning rate performance
    \item Inversion ($i$):	RMSE of 100,000 validation velocities as compared to true velocity
\end{itemize}

These criteria are ranked from 1-20, with 20 being the best result. The score was calculated as
\begin{equation}
    \text{Score} = d+t+v+2i.
\end{equation} 
The formula is arbitrarily chosen and linear in nature, making ideal for interpretation and understanding. The additional weight of 2 for the inversion rank emphasizes the inversion is the most important criteria. The rank criteria ranks all scores, with the highest score being best. The best performing architecture-loss combination is identified as \textbf{Conv1D-Adadelta}. Table~\ref{tab:quantitative_assessment_summary_arch} and Table~\ref{tab:quantitative_assessment_summary_loss} summarize Table~\ref{tab:quantitative_assessment_arch_loss} per architecture and loss optimizer respectively. Table~\ref{tab:quantitative_assessment_summary_arch} further reinforces the choice for ideal setup being of type Conv1D since this architecture ranked in the top four, irrespective of Loss Optimizer. Table~\ref{tab:quantitative_assessment_summary_loss} is in agreement that Adadelta is the better loss optimizer for our setup, however the difference is relatively small and not substantial. Choosing a different loss optimizer would not result in deterioration of our result. Full results used to build these tables is given in Appendix~\ref{sec:app_results_summary_results_exp_1}.

\begin{table}[!htb]
    \centering
    \begin{minipage}[b]{.45\textwidth}
        \centering
            \begin{tabular}{cccc}\toprule
                \multirow{2}{*}{Architecture} & \multicolumn{3}{c}{Score} \\ \cline{2-4} 
                                            & Avg      & Min   & Max   \\ \hline
                Conv1D                        & 74.3 & 70 & 79 \\
                MLP                           & 63.8 & 61 & 66 \\
                Conv2D                        & 51.8 & 48 & 56 \\
                VGG                           & 48.5  & 34 & 55 \\
                ResNet                        & 33.5  & 28 & 42 \\\hline
            \end{tabular}
            \caption{Quantitative assessment for architectures.}
            \label{tab:quantitative_assessment_summary_arch}
    \end{minipage}
    \qquad
    \begin{minipage}[b]{.45\textwidth}
        \centering
            \begin{tabular}{cccc}\toprule
            \multirow{2}{*}{Architecture} & \multicolumn{3}{c}{Score} \\ \cline{2-4} 
                                        & Avg      & Min   & Max   \\ \hline
            Adadelta                      & 58.0   & 42 & 79 \\
            Adagrad                       & 54.6 & 31 & 70 \\
            RMSprop                       & 54.4 & 33 & 72 \\
            Adam                          & 50.4 & 28 & 76 \\\hline
            \end{tabular}
            \caption{Quantitative assessment for loss optimizers.}
            \label{tab:quantitative_assessment_summary_loss}
    \end{minipage}  
\end{table}

\clearpage
\begin{table*}[ht!]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}cccccccc@{}}\toprule
Architecture & Loss Optimizer & Duration & Train & Validation & Inversion & Score & Overall Rank \\ \hline
MLP          & Adagrad        & 18       & 4     & 20         & 11        & 64    & 6    \\
MLP          & Adadelta       & 16       & 13    & 19         & 8         & 64    & 6    \\
MLP          & RMSprop        & 20       & 7     & 9          & 15        & 66    & 5    \\
MLP          & Adam           & 19       & 19    & 9          & 7         & 61    & 8    \\
Conv1D       & Adagrad        & 17       & 2     & 15         & 18        & 70    & 4    \\
Conv1D       & Adadelta       & 14       & 8     & 19         & 19        & 79    & 1    \\
Conv1D       & RMSprop        & 14       & 9     & 9          & 20        & 72    & 3    \\
Conv1D       & Adam           & 15       & 10    & 17         & 17        & 76    & 2    \\
Conv2D       & Adagrad        & 12       & 5     & 15         & 12        & 56    & 9    \\
Conv2D       & Adadelta       & 12       & 15    & 15         & 4         & 50    & 14   \\
Conv2D       & RMSprop        & 10       & 1     & 9          & 14        & 48    & 15   \\
Conv2D       & Adam           & 10       & 20    & 3          & 10        & 53    & 11   \\
VGG          & Adagrad        & 8        & 3     & 15         & 13        & 52    & 13   \\
VGG          & Adadelta       & 8        & 14    & 15         & 9         & 55    & 10   \\
VGG          & RMSprop        & 1        & 11    & 9          & 16        & 53    & 11   \\
VGG          & Adam           & 8        & 12    & 4          & 5         & 34    & 17   \\
ResNet       & Adagrad        & 4        & 6     & 17         & 2         & 31    & 19   \\
ResNet       & Adadelta       & 4        & 17    & 15         & 3         & 42    & 16   \\
ResNet       & RMSprop        & 2        & 16    & 3          & 6         & 33    & 18   \\
ResNet       & Adam           & 5        & 18    & 3          & 1         & 28    & 20   \\\hline
\end{tabular}
\caption{Quantitative assessment for architecture and loss optimizers.}\label{tab:quantitative_assessment_arch_loss}
\end{table*}  

\subsection{Marmousi Model}\label{sec:results_Numerical_experiment}
\subsubsection{Dataset}\label{sec:results_marmousi_dataset}
The Marmousi-2 model \citep{Martin2002} was used to evaluate the technique on an industry standard dataset. Figure~\ref{fig:marm_modified} and Figure~\ref{fig:marm_modified_velocity} illustrate the Marmousi-2 model and velocity profile respectively. The model has a lateral extension of 17 km and a depth of 3.5 km and includes a total of 199 layers geophysical layers, as well as an extended water layer of 450 m depth to simulate a deep-water setting \citep{Martin2002}. The grid spacing was 10m vertically by 25m laterally, resulting in a 2801 by 13601 grid. The velocity in the model ranges from 1500\si{ms^{-1}} up to 4700\si{ms^{-1}} and after the application of a 150m vertical median filter to reduce the vertical resolution, the number of layers in each velocity profile was analytically calculated to range between 20 to 50 layers. The salt density as taken constant throughout. The generation for this model is provided in Appendix~\ref{sec:app_results_generation_marm}. This will be referred to as the Marmousi model for the rest of the thesis.

\clearpage
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_01_get_models_03_Marm2_01_vel_image-eps-converted-to.pdf}
    \caption[Marmousi-2 and modified Marmousi-2 velocity model.]{Marmousi-2 and modified Marmousi-2 velocity model.}
    \label{fig:marm_modified}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_01_get_models_03_Marm2_02_vel_profile-eps-converted-to.pdf}
    \caption[Velocity profiles through crosslines on Marmousi-2 and modified Marmousi-2.]{Velocity profiles through crosslines (Xlines) on Marmousi-2 and modified Marmousi-2 models.}
    \label{fig:marm_modified_velocity}
\end{figure}

\subsubsection{DNN FWI Generator}\label{sec:results_marm_generator}
Following from the work in Sections~\ref{sec:results_Train-Test_Data}-~\ref{sec:results_arch_loss_combination}, a generator was constructed to be able to invert for the Marmousi model. The generator parameters are given in Table~\ref{tab:marm_data_generator_params}. A sample of the velocity, trace and CWT generated by this generator are available in Figure~\ref{fig:marm_generator}.
\begin{table*}
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}llc@{}}\toprule
        Parameter                  & Description                   & Value \\ \hline
        length (ms)                & Length of trace               & 2801  \\
        vel\_min (m/s)             & Minimum velocity              & 1450  \\
        vel\_max (m/s)             & Maximum velocity              & 5000  \\
        vel\_min\_separation (m/s) & Minimum velocity separation   & 15    \\
        time\_min (ms)             & Minimum time sample           & 0     \\
        time\_max (ms)             & Maximum time sample           & 2801  \\
        time\_min\_separation (ms) & Minimum time separation       & 5     \\
        layers\_min                & Minimum number of layers      & 20    \\
        layers\_max                & Maximum number of layers      & 50    \\
        dominant\_frequency        & \si{Hz} of dominant frequency & 5     \\ \hline
    \end{tabular}
    \caption[Marmousi data generator parameters.]{Marmousi data generator parameters.}\label{tab:marm_data_generator_params}
\end{table*}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth]{27_real_data_07_Marmousi_Generator_Sample-eps-converted-to.pdf}
    \caption[Sample velocity profile, trace and CWT generated by Marmousi generator.]{Sample velocity profile, trace and CWT generated by Marmousi generator.}
    \label{fig:marm_generator}
\end{figure}

\subsubsection{DNN Training and Architecture Performance}\label{sec:results_marm_DNN_Training_and_Architecture_Performance}
The network was trained for 30 epochs, at 1,000,000 traces and 100,000 traces per training and testing dataset respectively. The network was a slightly modified version of the ideal network in §~\ref{sec:results_arch_loss_combination} due to the longer time length of trace. This network is given as two part network ``Marmousi - Time to Pseudo-Spectral'' and ``Marmousi - Pseudo-Spectral to Velocity'' in Appendix~\ref{tab:app_results_dnn_architectures}.

As expected from previous work, the DNN training performance shown in Figure~\ref{fig:marm_training_validation_curves} indicates how this workflow performs well with a monotonically decreasing loss per epoch, with no symptoms of over-fitting or under-fitting. From the Learning Rate plot, the DNN might benefit from a couple more additional training epochs since the automatic reducing learning rate callback within the network was never initiated. Figure~\ref{fig:marm_training_validation_metrics} reinforce this suggestion of good training and with additional metrics calculated per epoch of Explained Variance and R2 Score, both of which are gradually approaching one per epoch.
 
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_08_DNN_Performance_01_TrainValid-eps-converted-to.pdf}
    \caption[Training and Validation curves for DNN training and Learning Rate values.]{Training and Validation curves for DNN training and Learning Rate values.}
    \label{fig:marm_training_validation_curves}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_08_DNN_Performance_02_Metrics_3-eps-converted-to.pdf}
    \caption[Explained variance and R2 Score metrics calculated per epoch.]{Explained variance and R2 Score metrics calculated per epoch. Both these metrics are approaching one per epoch, suggesting a good overall DNN performance.}
    \label{fig:marm_training_validation_metrics}
\end{figure}

Figure~\ref{fig:marm_evolution_network_historgrams} show histograms for the evolution of network trainable parameters per epoch. The $y$-axis of these plots are the epochs and the darker saturation indicate the older the epoch value. The $z$-axis is the density of values represented at $x$-axis. The first 6 rows show histograms for the convolution and batch normalisation layers as groups per row. Each group is composed of Convolution – Convolution – Batch Normalisation layers which is getting repeated 6 times in the network. For each convolution, the trainable parameters are the bias and kernel, whilst for Batch Normalisation $\gamma$ and $\beta$ are the per epoch standard deviation and mean respectively, moving variance and moving mean. Convolution kernels are relatively flat, with narrow distribution from $\left[-0.15, 0.15\right]$ to $\left[-0.04, 0.04\right]$. This indicates that the input signal is getting collapsed into smaller probabilities for explanation. Comparing convolution kernels with each row, these are very similar. They both have wider distributions indicating that more abstractions are being included with each pass. The bias starts off with multiple peaks then centre about 0, moving from a left skewed to a more gaussian distribution. This shows that the initial layers are identifying multiple parts of the input signal as being important due to the multiple peaks, but as we go deeper into the network with more epochs, we start seeing that the network “understanding” starts to converge into a gaussian distribution and collapsing all the abstracted information from the upper layers into the desired output. The last row shows histograms for the two dense layers, with trainable parameters for bias and the kernel. The kernel distribution for both dense layers is centred around zero, with a very narrow standard deviation. This indicates how the last two layers a selectively choosing components from the different abstracted feature maps and adding small components to build up the final inversion. The shifting bias from left skewed to more Gaussian, with mean close to 0.004, indicates that the final reconstruction is happening within a Gaussian environment for the DNN. This is an ideal setup as this will facilitate regularizations to unseen data.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{27_real_data_10_Training_Histograms_3-eps-converted-to.pdf}
    \caption[Evolution of network histograms.]{Evolution of network histograms. The depth ($y$-dimension) of these plots are the epochs and the darker saturation indicate the older the epoch value. The $z$-dimension is the density of values represented at $x$-dimension.  MM is the moving average and MV is moving variance.}
    \label{fig:marm_evolution_network_historgrams}
\end{figure}

Figure~\ref{fig:marm_evolution_velocity_profile} and Figure~\ref{fig:marm_evolution_trace} show the velocity inversion and resultant trace for Xline 2000, 8000 and 12000 from that Marmousi model respectively for every training epoch for the DNN. From the initial epoch, the DNN was able to invert most of the information within the velocity profile. The inversion is not perfect, since there is a form of leakage/spikes coming in up to about epoch 10. This is the learning-process of the DNN, since this gets gradually removed from the velocity profile with additional epoch, and at about epoch 20 there is an almost perfect reconstruction. From epoch 20 to epoch 30, the differences are minimal as can be seen by the very small changes to the MSE shown in the plot and as well in the overall DNN loss values in Figure~\ref{fig:marm_training_validation_curves}. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{27_real_data_09_Evolution_Per_Epoch_01_Evolution_Velocity_VelProfile_2000-eps-converted-to.pdf}
    \includegraphics[width=0.98\textwidth]{27_real_data_09_Evolution_Per_Epoch_01_Evolution_Velocity_VelProfile_8000-eps-converted-to.pdf}
    \includegraphics[width=0.98\textwidth]{27_real_data_09_Evolution_Per_Epoch_01_Evolution_Velocity_VelProfile_12000-eps-converted-to.pdf}
    \caption[Evolution of velocity profile through different epochs.]{Evolution of velocity profile for Xline 2000, 8000 and 12000 through the different epochs respectively. Above each plot, there is the Epoch number in bold, and the MSE.}
    \label{fig:marm_evolution_velocity_profile}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{27_real_data_09_Evolution_Per_Epoch_02_Evolution_Trace_VelProfile_2000-eps-converted-to.pdf}
    \includegraphics[width=0.98\textwidth]{27_real_data_09_Evolution_Per_Epoch_02_Evolution_Trace_VelProfile_8000-eps-converted-to.pdf}
    \includegraphics[width=0.98\textwidth]{27_real_data_09_Evolution_Per_Epoch_02_Evolution_Trace_VelProfile_12000-eps-converted-to.pdf}
    \caption[Evolution of trace for Xline 2000, 8000 and 12000 through the different epochs.]{Evolution of trace for Xline 2000, 8000 and 12000 through the different epochs respectively.}
    \label{fig:marm_evolution_trace}
\end{figure}

\clearpage
\subsubsection{Deterministic FWI}\label{sec:results_classical_FWI}
Classical FWI with Sobolev space norm regularization was employed for comparative purposes – see Figure~\ref{fig:marm_classical_fwi} and Figure~\ref{fig:marm_classical_fwi_velocity}. This was a modified version of the FWI optimization framework provided by \cite{Kazei2019}. The maximum frequency of the inversion process was set to be 3.5\si{Hz}. This results in a minimum update resolution of 414m given by $\lambda=\frac{v_{min}}{f_{max}}$ where $v_{min}$ is 1450\si{ms^{-1}} and $f_{max}$ is 3.5\si{Hz}. The dataset was resampled and interpolated by a factor of 10 to enable a faster implementation and still retain the maximum update resolution. The iterative update process started from frequency 1\si{Hz} and iteratively updated by a factor of 1.2 until reaching a maximum frequency of 3.45\si{Hz}. The optimization algorithm was L-BFGS-B \citep{Zhu1997}, with 50 iterations per frequency band in each update. Forward shot modelling was done every 100m, starting from 100m offset, and receivers spaced every 100m. The detailed implementation and inversion parameters are provided in Appendix~\ref{sec:app_results_classical_FWI}. More advanced FWI code could have been implemented to improve lateral continuity and imaging, however results obtained by this implementation provided acceptable run-times and results, thus making feasible for our experimentation. Examples of state-of-the-art code which usually available for consortiums are FULLWAVE\footnote{\url{https://fullwave3d.github.io/}}
or CREWES\footnote{\url{https://www.crewes.org/ResearchLinks/Full_Waveform_Inversion/}}.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.78\textwidth]{27_real_data_03_FWI_results_01_vel_image-eps-converted-to.pdf}
    \caption[Classical FWI with Sobolev space norm regularization.]{Classical FWI with Sobolev space norm regularization result. Top: Initial modified Marmousi model. Middle: Initial velocity provided for FWI. Bottom: FWI result following from inverting for 3.6\si{Hz}.}
    \label{fig:marm_classical_fwi}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_03_FWI_results_02_vel_profile-eps-converted-to.pdf}
    \caption[Velocity profiles through Xlines on Marmousi, Initial and FWI results.]{Velocity profiles through Xlines on Marmousi, Initial and FWI results as shown in Figure~\ref{fig:marm_classical_fwi}.}
    \label{fig:marm_classical_fwi_velocity}
\end{figure}

\subsubsection{DNN and Classical FWI}\label{sec:results_comparison_dnn_fwi}
To evaluate the performance of our DNN approach, classical FWI and the DNN FWI approach are compared in Figure~\ref{fig:comparison_dnn_fwi_image}. Off the start, it is clearly evident how the DNN approach is producing a lot more uplift than the standard approach. There is improved imaging in the sediment layers, with distinct layers being reconstructed which would otherwise be missed with classical FWI – Zoom 1 in Figure~\ref{fig:comparison_dnn_fwi_image_zoom}. The middle section, with the heavily over-trusted layers shown in Zoom 2, the velocity layers are also being reconstructed to good levels and the small sedimentary pockets at the pinch of the over-thrust are being to be imaged as well. These are being missed completely in Classical FWI. Sub-salt in Zoom 3, DNN is once again producing much better imaging up to the salt and below the salt. Indeed, sub-salt, we are starting to image partially some of the layer coming up into the salt. The inversion process is not perfect as shown by the differences in velocities in Figure~\ref{fig:comparison_dnn_fwi_velocity} for either of the three zoomed sections. Comparison of the error maps, the problematic areas of DNN are also those for classical FWI. In Zoom 1, the amplitude of the large velocity layer coming in at 1400m depth is not being inverted properly. The onset of this layer is not as problematic, but leakage is evidently present. Similarly, for Zoom 3, the salt arrival at 2200m depth, is being imaged by DNN and not by FWI. In Zoom 2, the error hotspot for DNN are similar to those of FWI, however the magnitude of the error is of an order different. This would indicate that DNN is very good performant when it comes to inverting for large velocity packages. Figure~\ref{fig:comparison_dnn_fwi_spectra} gives the amplitude spectra for the full and zoomed velocity models respectively. This show that the frequency content is similar in either approach, yet both are lower than the true.

The velocity profiles (Figure~\ref{fig:comparison_dnn_fwi_velocity}) and trace reconstruction (Figure~\ref{fig:comparison_dnn_fwi_trace}) confirm that our DNN approach inverted more of the signal than classical FWI. Upon closer investigation, we are seeing small spikes on the velocity on the salt section of Xlines 2000, 4000 and 6000. Further training would potentially mitigate this, or a median filter could be applied post-inversion to resolve this. From the velocity profiles, we see how FWI is able to update the shallow sections up to 1400m really well, potentially better than DNN as it is able to identify a velocity inversion at depth 500m on Xline 8000 and a pronounced segment layer at depth 800m on Xline 12000. However, beyond 1400m depth, the geometry and forward-modelling physical constraints from ray-tracing come into play and FWI is unable to provide more uplift at deeper velocity packages.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_05_DNN_FWI_COMPARISON_01_vel_image-eps-converted-to.pdf}
    \caption[Comparison of DNN and Classical FWI reconstructed velocity models.]{Comparison of DNN and Classical FWI reconstructed velocity models. Top: Initial Marmousi model with highlighted Zoom 1-3 used in Figure 4.22. Middle: DNN FWI result. Bottom: Classical FWI result following from inverting for 3.6 Hz.}
    \label{fig:comparison_dnn_fwi_image}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{27_real_data_05_DNN_FWI_COMPARISON_01_vel_image_Zoomed_In-eps-converted-to.pdf}
    \caption[Zoomed comparison of DNN and Classical FWI velocity and errors.]{Zoomed comparison of DNN and Classical FWI reconstructed velocity models and corresponding errors.}
    \label{fig:comparison_dnn_fwi_image_zoom}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.96\textwidth]{27_real_data_05_DNN_FWI_COMPARISON_04_models_spectrum-eps-converted-to.pdf}
    \caption[DNN and Classical FWI amplitude spectra.]{DNN and Classical FWI amplitude spectra show that the frequency content is similar in either approach, yet both are lower than the true.}
    \label{fig:comparison_dnn_fwi_spectra}
\end{figure}


\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_05_DNN_FWI_COMPARISON_02_vel_profile-eps-converted-to.pdf}
    \caption[Velocity profiles through Xlines for Initial, DNN and FWI results.]{Velocity profiles through Xlines on Initial, DNN and FWI results as shown in Figure~\ref{fig:comparison_dnn_fwi_image}.}
    \label{fig:comparison_dnn_fwi_velocity}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{27_real_data_05_DNN_FWI_COMPARISON_03_time_profile-eps-converted-to.pdf}
    \caption[Time inversions of velocity for Initial, DNN and FWI results.]{Time inversions of velocity profiles through Xlines on Initial, DNN and FWI results as shown in Figure~\ref{fig:comparison_dnn_fwi_image}.}
    \label{fig:comparison_dnn_fwi_trace}
\end{figure}

\clearpage
\section[RNN as an Analogue of FWI]{Theory-Guided RNN as an Analogue of FWI}
Based on the formulation presented in the previous Chapter, results for theory-guided RNN as an analogue for FWI are presented in this Section. As indicated in the Literature Review, this idea is not novel. However, the use of pseudo-spectral spatial gradient calculation for the inversion process is novel. Two-dimensional experiment formulation are shown, and confirm the pseudo-spectral forward modelling implementation. This is then applied to synthetic data results.

\subsection{Experiment Setup}
The original code for the time inversion as RNN framework was provided by \cite{Richardson2018} and developed in TensorFlow v1.4. TensorFlow has been in active development since 2018, with a major release of v2.0 in September 2019. This provided much improvement in terms of efficiency and it allowed for easier implementation on GPUs. For this reason, the framework was re-written in v2.0 to enable the use of INGV’s NVIDIA Titan V GPU. This code is published as part of the additional resources to this dissertation in Appendix~\ref{sec:app_results_code_repo}.

\subsection{Forward Modelling using RNNs}\label{sec:results_forward_modelling_using_rnnd}
RNN should be able to model the different wave field components if it is to replace the forward modelling component. This was first tested by considering the 1D case for both Time and Frequency implementations and compared to a 1D Green function solution. This was achievable via a custom RNNcell unit developed in TensorFlow and can be inspected code repository provided in Appendix~\ref{sec:app_results_code_repo}. The 1D implementation provided promising results and is available as part of Appendix~\ref{sec:app_results_rnn_fwi_1d}.

The experiment was extended to 2D and tested for all wavefield components. A 25Hz Ricker wavelet was propagated through a 2D 1500\si{ms^{-1}} constant velocity model (Figure~\ref{fig:rnn_2d_multisource_vel}) with a multi-source multi-receiver geometry setup. The 25Hz source wavelet goes into the hyper-resolution realm for FWI and is beyond the resolution that will be investigated on the synthetic model, however this allows for gauging the limit of accuracy. This model setup was forward propagated for 5333 time-steps at 1ms, with a 10m grid spacing. Namely, this implies that 5333 LSTM cells where employed for the forward modelling. The resulting direct waves are illustrated in Figure~\ref{fig:rnn_2d_multisource_trace}, with True being the analytical solution calculated using a 2D Green’s function, RNN Time and RNN Freq are the RNN implementations for forward modelling using Time and Fourier spatial derivatives respectively. Qualitatively, there is no visible difference between either approach. 


Reflected and transmitted arrivals were tested using a simple step velocity model ranging from 1500\si{ms^{-1}} to 2000\si{ms^{-1}} as shown in Figure~\ref{fig:rnn_2d_reflection_vel}. Figure~\ref{fig:rnn_2d_reflection_wave} is the forward modelled wavefield for the two receiver locations (RCV-1 and RCV-2), top and bottom respectively. RCV-1 at ground level interacts with the direct wave at 125ms and reflected wave at 250ms. RCV-2 is below the acoustic impedance layer at 30m and shows the transmitted wave. Comparing these to the analytical solution, either are able to model the wave components perfectly.

The remaining wavefield components are scattering waves. A constant velocity model of 1500 \si{ms^{-1}} was created with a 1550\si{ms^{-1}} point scatterer (Figure~\ref{fig:rnn_2d_scattered_vel}). RNN implementations were modelled to be depended non-linearly on the scattering amplitude and then approximately linearised. The results are given in Figure~\ref{fig:rnn_2d_scattered_wavefield}. The direct wave was not included in the scattered wavefield reconstruction. Similarly to previous components, scattering are modelled successfully.

Table~\ref{tab:rnn_2d_direct_multi} lists quantitative metrics for the wavefield components. RNN Freq was found to be better for imaging the direct wave (Table~\ref{tab:rnn_2d_direct_multi}), with an improvement of 0.01 in error tolerance and 0.3\% \ac{RPE}. Metrics in Table~\ref{tab:rnn_2d_reflection} and Table~\ref{tab:rnn_2d_scattering} indicate that RNN Time matches the 2D Green’s function near perfectly, whilst RNN Freq introduce error of less than 0.04 and 0.1\% \ac{RPE}. RNN Time is able to model the wavefield within a maximum 0.06 error tolerance and 1.74\% RPE, whilst RNN Freq is overall more accurate with 0.05 and 1.449\% respectively. Given these metrics and the observed models, the discrepancies between the analytical solution and the RNN implementation are deemed acceptable and should be suitable for the modelling process.

\begin{table*}[ht!]
    \footnotesize
    \centering
    % \ra{1.3}
    \subbottom[Direct wave.\label{tab:rnn_2d_direct_multi}]{
        \begin{tabular}{@{}lcc@{}}\toprule
            Modelling  & Error Tolerance    & RPE (\%) \\ \hline
            RNN Time   & 0.060 & 1.740            \\
            RNN Freq   & 0.050 & 1.449            \\ \hline
        \end{tabular}}\qquad
    \subbottom[Reflected and transmitted wave.\label{tab:rnn_2d_reflection}]{
        \begin{tabular}{@{}lcc@{}}\toprule
            Modelling  & Error Tolerance    & RPE (\%) \\ \hline
            RNN Time   & 0.001 & 0.002                  \\
            RNN Freq   & 0.020 & 0.013                  \\ \hline
        \end{tabular}}
        
    \subbottom[Scattering wave.\label{tab:rnn_2d_scattering}]{
        \begin{tabular}{@{}lcc@{}}\toprule
            Modelling  & Error Tolerance    & RPE (\%) \\ \hline
            RNN Time – Non-linear	& 0.003	& 0.010     \\
            RNN Time – Linear   	& 0.010 & 0.025     \\
            RNN Freq – Non-linear	& 0.030	& 0.076     \\
            RNN Freq – Linear	    & 0.040 & 0.097     \\ \hline
    \end{tabular}}
    \caption[Empirical comparison of 2D wavefield components.]{Empirical comparison of 2D wavefield components.}
\end{table*}

\begin{figure}[!ht]
    \centering
    \subbottom[Constant velocity model.\label{fig:rnn_2d_multisource_vel}]{\includegraphics[width=0.35\textwidth]{15_Dissertation_01_initial_experiment_03_2d_direct_multi_src_rcv_model_only-eps-converted-to.pdf}}
    \subbottom[Direct wave RNN forward modelling.\label{fig:rnn_2d_multisource_trace}]{\includegraphics[width=0.5\textwidth]{15_Dissertation_01_initial_experiment_04_2d_direct_multi_src_rcv_trace_1-eps-converted-to.pdf}}
    \caption[Direct wave forward modelling for multi-source, multi-receiver geometry.]{Direct wave forward modelling for multi-source, multi-receiver geometry.}        
    \label{fig:rnn_2d_direct_multi}
\end{figure}

\begin{figure}[!ht]
	\centering
	\subbottom[Step velocity model.\label{fig:rnn_2d_reflection_vel}]{\includegraphics[width=0.35\textwidth]{15_Dissertation_01_initial_experiment_08_2d_reflection_velocity-eps-converted-to.pdf}}
    \subbottom[Top: RCV-1 located at ground level reacts to direct arrival at 125ms and reflected arrival at 250ms. \newline Bottom: RCV-2 shows transmitted arrival.\label{fig:rnn_2d_reflection_wave}]{\includegraphics[width=0.5\textwidth]{15_Dissertation_01_initial_experiment_09_2d_reflection_waves-eps-converted-to.pdf}}
	\caption[Reflected and transmitted wave RNN forward modelling.]{Reflected and transmitted wave RNN forward modelling.}        
	\label{fig:rnn_2d_reflection}
\end{figure}

\begin{figure}[!ht]
\centering
\subbottom[Point-scattering velocity model.\label{fig:rnn_2d_scattered_vel}]{\includegraphics[width=0.35\textwidth]{15_Dissertation_01_initial_experiment_05_2d_scattering_waves_model-eps-converted-to.pdf}}
\subbottom[Scattering wavefield modelling. Direct wavefield was excluded in the modelling.\label{fig:rnn_2d_scattered_wavefield}]{\includegraphics[width=0.5\textwidth]{15_Dissertation_01_initial_experiment_06_2d_scattering_waves_trace_full-eps-converted-to.pdf}}
\caption[Scattering wave RNN forward modelling.]{Scattering wave RNN forward modelling.}    
\label{fig:rnn_2d_scattering}
\end{figure}

\clearpage
\subsection{Gradient Comparison}
The gradient of the cost function defines the direction in which the model needs to be updated to reach a global minimum (§~\ref{sec:theory_model_update}). Classical FWI approaches generally use the adjoint state method to calculate gradients or the finite differences approach (although computationally expensive), whereas DNN frameworks use automatic differentiation. Theoretical equivalence has been shown in Appendix~\ref{sec:app_results_equivalence_AD_adjoint}, and we now confirm computational equivalence following the approach described by the work of \cite{Richardson2018}.

A random 1D model was generated, randomly perturbed and gradient of cost function evaluated along the trace. Figure~\ref{fig:rnn_gradient_comp} and Table~\ref{tab:rnn_gradient_comp} compare the gradients at each point for classical finite differences and adjoint techniques to automatic differentiation (AutoDiff.). The adjoint state and AutoDiff. Freq react similarly and slightly over-estimates the gradient, with the pseudo-spectral approach being worse. AutoDiff. Time under-estimates the gradient with an infinitesimal error. Gradients deviate at the edges in either case, with AutoDiff. Freq producing evident perturbation in the initial few time-steps. This is due to the choice of the batch-size within the inversion process and is further discussed in subsection §~\ref{sec:rnn_hp_tunin}. Although this might seem worrying, the scale of this deviation is very minimal and no concerning effects were observed within the previous experimentation leading to this investigation. The other discrepancies are attributed to numerical inaccuracies as per \cite{Richardson2018}.
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth]{15_Dissertation_03_gradient_comparison-eps-converted-to.pdf}
    \caption[Gradient comparison of RNN implementation with classical approaches.]{Gradient comparison of of RNN implementation with classical approaches. AutoDiff. is the automatic differentiation implementation in Tensorflow v2.0.}
    \label{fig:rnn_gradient_comp}
\end{figure}
\begin{table*}[!ht]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}lccc@{}}\toprule
        \textbf{Finite Difference gradient baseline} & Adjoint & AutoDiff. Time & AutoDiff. Freq \\ \hline 
        Error tolerance                     & $1.000\times10^{-5}$ & $-2.196\times10^{-9}$      & $3.000\times10^{-4}$       \\
        RPE (\%)                            & $0.593$   & $1.302\times10^{-5}$      & $1.779$        \\ \hline 
    \end{tabular}
    \caption{Empirical comparison of gradient calculations.}\label{tab:rnn_gradient_comp}
\end{table*}

\subsection{Hyper-Parameter Tuning}\label{sec:rnn_hp_tunin}
Similarly to the approach shown in \cite{Sun2019}, a benchmark 1D 4-layer synthetic profile, with velocities [2, 3, 4, 5]\si{kms^{-1}}, was used to identify the ideal parameters for the RNN architecture. This is illustrated as the Black line in Figure~\ref{fig:rnn_hp_tuning}. Classical 1D second-order FD modelling was used to generate the required true receiver data. Multiple learning rates for the different loss optimizers were investigated to try and identify the ideal combination. Figure~\ref{fig:rnn_hp_tuning} shows the best combination for all losses with an ideal batch size of three. The full investigation for this tuning is given in Appendix~\ref{sec:app_results_rnn_hp_tuning}. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.95\textwidth]{15_Dissertation_04_Hyperparameter_Selection_04_Best_LR_IDEAL_BATCH-eps-converted-to.pdf}
    \caption[Hyper-Parameter tuning.]{Tuning of hyper-parameters to identify ideal loss optimizer combination.}
    \label{fig:rnn_hp_tuning}
\end{figure}

Left side of Figure~\ref{fig:rnn_hp_tuning} shows the inverted velocity profiles, with Red being the initial velocity profile. For Stochastic Gradient Descent, the learning rates was found to be both between zero and one. This is as expected and follows conventional loss optimization. On the other hand, the other loss optimizers had to be scaled to beyond one due to the magnitude differences brought by accumulated squared-norms of the gradients as investigated by \citet{Sun2018}. This is allowed provided the scaling coefficient is between zero and one. For Adagrad, following from \cite{Duchi2011}, the $\beta$ hyper-parameter was fixed at 0.9 and learning rate found to be 20. Adadelta, RMSprop and Adam optimal learning rates were identified at 1000, 1 and 2 respectively. 

The right side of Figure~\ref{fig:rnn_hp_tuning} gives the loss progression. All optimizers iteratively reduce the error with additional shots and on similar scales. Stochastic Gradient Descent and Adagrad do this relatively sooner than the rest, yet the inverted velocity is not as good as the other optimizers. RMSprop follows a rather slow gradual decrease in loss, which then sudden increases. This is expected given that RMSprop updates are derived from a moving average of the square gradients and require an inertial start.

Based on this investigation, \textbf{Adam} with a learning rate of 2 was identified as the best optimizer. This provided the most stable inversion for either RNN Time or Freq, with the most update and reasonable error loss performance. Mis-match in the shallow part of the velocity is due to the choice of batch-size within the RNN update process. Figure~\ref{fig:rnn_hp_tuning_batch_size} shows the Adam optimizer fixed with learning rate 2 and inverted for batch sizes ranging from one to five. The smaller the batch size, the greater the error since the inversion is more localized and amplifies the gradient onset error shown in Figure~\ref{fig:rnn_gradient_comp}. The larger the batch size, the better the inversion as more data is being used. This poses a limitation since batch size is limited by the Graphical Processing Unit RAM. Given fore-sight that this approach will be used on a large dataset, this was taken as a caveat and batch size fixed at one for the rest of the implementation. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth]{15_Dissertation_04_Hyperparameter_Selection_05_Effect_BatchSize-eps-converted-to.pdf}
    \caption[Effect of batch-size on inversion process.]{A smaller batch-size introduces error at the initial part of the velocity profile due to more localized updates. This was derived for a time time implementation for RNN architecture with Adam loss optimizer and learning rate of 2.}
    \label{fig:rnn_hp_tuning_batch_size}
\end{figure}
\clearpage
\subsection{2D Synthetic}
\subsubsection{True and Initial Models}
A 2D scalar model of the Marmousi-2 was formulated similar to that in §~\ref{sec:results_marmousi_dataset}. This was re-sampled to a 50\si{m}$\times$50\si{m} grid and smoothed to create the initial model model. These velocity models are plotted in Figure~\ref{fig:rnn_marm_models}. True synthetic receivers were computed by forward modelling through the RNN framework. 56 shots at 300m intervals at depth 200m were generated with a Perfectly Matched Layer at the boundaries. Receivers were set at 50m intervals and modelled for 12\si{s} duration.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{13_Dissertation_Plots_01_model_inv_01_true_initial-eps-converted-to.pdf}
    \caption[Synthetic 2D Marmousi models for RNN training.]{50\si{m}$\times$50\si{m} grid 2D Marmousi models for RNN training.}
    \label{fig:rnn_marm_models}
\end{figure}

\subsubsection{Training of RNN}
As in standard RNN approaches, the receiver dataset was split into a training and development datasets with at 75\%-25\% split. Training was run for 100 epochs, with early stopping on an NVIDIA Titan V Graphical Processing Unit courtesy of Istituto Nazionale di Geofisica e Vulcanologia. Development loss was calculated every 5th training shot. Figure~\ref{fig:rnn_losses} gives the RNN performance for training and development datasets using Adam optimizer with learning rate of 2.0 and batch size 1. The horizontal labels shows the epoch number and respective number of shots evaluated for training and development. Computational run times are of 14 hours per approach. Both RNN Time and RNN Freq follow similar reductions in loss per epoch and indicate that either implementation converge to an optimal loss. L-BFGS-B loss for classical FWI is shown and is discussed is in the next section.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth]{13_Dissertation_Plots_01_model_inv_04_DNN_losses_LBFGSB-eps-converted-to.pdf}
    \caption[RNN loss performance.]{RNN loss performance for RNN training and development datasets using Adam optimizer with learning rate of 2 and batch size 1. The horizontal labels shows the epoch number and respective number of shots evaluated for training and development. L-BFGS-B is the cost function evaluation for classical FWI plotted on shot number equivalent. Either RNN approach converge quicker than L-BFGS-B, and RNN Freq provides a more stable convergence and better performance then RNN Time.}
    \label{fig:rnn_losses}
\end{figure}

\subsubsection{Comparison with classical FWI}\label{sec:results_rnn_comparison_to_FWI}
Figure~\ref{fig:rnn_losses} plots the cost function versus the number of shot evaluation equivalent for classical FWI and RNN. The RNN framework is more computationally efficient since either RNN approach converge significantly quicker than L-BFGS-B. RNN Freq provides a more stable convergence and is better performant then RNN Time. The classical FWI is plotted as a shot number equivalent and not the epoch number. The full cost function performance is provided in Appendix~\ref{sec:app_results_classical_FWI}. 

Figure~\ref{fig:rnn_models} compares the inverted velocities and residuals for FWI, together with RNN Time and RNN Freq implementations. Complementary plots showing the model update progressions for this sections are provided as part of Appendix~\ref{sec:app_results_rnn_update_progress}. The true model velocity in Figure~\ref{fig:rnn_models} identifies three zoomed areas which are shown in Figure~\ref{fig:rnn_model_zoomed_in} and Figure~\ref{fig:rnn_velocity_profiles} are velocity profiles taken at 2000 Xline intervals. Figure~\ref{fig:rnn_model_spectra} show the resolution spectra derived via FFT on the velocity models. Comparing FWI and the RNN model in either of these figures, it is clear that the resolution recovery is different. Figure~\ref{fig:rnn_model_spectra} confirms the frequency content in these approaches and shows how RNN models invert more of the lower frequencies in Zoom 2 and Zoom 3. In Zoom 1, FWI is slightly better at frequency recovery beyond 25Hz.

Residual plots (Figure~\ref{fig:rnn_models}-{~\ref{fig:rnn_model_zoomed_in}) and the velocity profiles (Figure~\ref{fig:rnn_velocity_profiles}) show how RNN approaches are able to recover more of the signal in the shallow right side (Zoom 1) and the over-thrust middle area (Zoom 2) of the model. Almost all the signal up to depth 1500m is inverted correctly in Zoom 1 whereas over-thrust faults are near perfectly recovered in Zoom 2 and ~\ref{fig:rnn_model_zoomed_in}F. Zoom 3 is of most interest. The prominent layer at depth circa 2000m is nearly completely missed by RNN models, whereas FWI is able to recover this partially. On the other hand, the deeper 3000m strata are hardly identified with FWI. Residual figures in the full sections show that the RNN model amplitude recover is not as good when compared to FWI (Labels~\ref{fig:rnn_model_zoomed_in}A-B). Indeed, some layers are missed at depth greater than 1500m for Xline number greater than 10,000 (Label~\ref{fig:rnn_model_zoomed_in}C-D). Considering either RNN approach in Figure~\ref{fig:rnn_models}, there is a low-frequency \textit{shadow} artefact introduced till depth 2300m from Xline 0 to 6000 and Xline 8000 to 13900. This is attributed to the practical implementation of batch-size discussed in §~\ref{sec:app_results_rnn_hp_tuning}.

Figure~\ref{fig:rnn_receivers} shows labelled receivers for either model at \ac{CDP} 60, 150 and 300. These CDPs split the model into three sections, representing the different extremities. Label A and B reiterate that the shallow left side is better imaged for FWI, whilst shallow right side is better for RNNs respectively. Label C is the missing high velocity at depth 2000m which has incorrect amplitude for the RNNs, but positioned correctly. Classical FWI has less prominent leakage in this area, yet very evident. Label D is the badly imaged layer at depth between 2000m and 2500m on the right side of the model. Labels E throughout the residuals highlight better low frequency resolution imaging by RNN approaches. Indeed, RNN Freq is able to recover slightly more of these low frequencies and identified by E$^{1}$ and E$^{2}$. Similar improvements are visible throughout the other plots. 

\vspace*{\fill} 
\begin{center}
    \emph{Intentionally left black space.}
\end{center}
\vspace*{\fill}


\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{13_Dissertation_Plots_01_model_inv_02_models_with_residual-eps-converted-to.pdf}
    \caption[Classical FWI and RNN implementation velocity model inversion.]{Classical FWI and RNN implementation velocity model inversion.}
    \label{fig:rnn_models}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.99\textwidth]{13_Dissertation_Plots_01_model_inv_02_models_with_residual_zoomed_in-eps-converted-to.pdf}
    \caption[Zoomed In RNN Models]{Zoomed In RNN Models}
    \label{fig:rnn_model_zoomed_in}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.8\textwidth]{13_Dissertation_Plots_01_model_inv_02_models_spectrum-eps-converted-to.pdf}
    \caption[RNN models velocity resolution spectra]{RNN model velocity resolution spectra.}
    \label{fig:rnn_model_spectra}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth]{13_Dissertation_Plots_01_model_inv_03_velocity_profiles_with_labels-eps-converted-to.pdf}
    \caption[Velocity profiles for RNN and classical FWI.]{Comparison of velocity profiles for RNN and classical FWI. Label \textbf{A-B}: RNN is able to identify strata near perfectly, however unable to inverte the amplitudes values correctly. Label \textbf{C-D}: Missed layers from RNN approaches. Label \textbf{E}: Low frequency artefact for RNN. Label \textbf{F}: Near perfect velocity inversion in the middle Xlines, over shallow depth.}
    \label{fig:rnn_velocity_profiles}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth]{13_Dissertation_Plots_01_model_inv_05_Receiver_with_labels-eps-converted-to.pdf}
    \caption[Labelled receivers for True, FWI and RNN models.]{Receivers for True, FWI and RNN models at CDP 60, 150 and 300. Label \textbf{A} and \textbf{B}: Shallow left side is better imaged for FWI. Label \textbf{C}: Missing high velocity with incorrect amplitude but positioned correctly. Label \textbf{D}: Badly imaged layer. Labels \textbf{E}: Better low frequency imaging for either RNN approaches. Labels \textbf{E$^{1}$} and \textbf{E$^{2}$}: RNN Freq is able to recover slightly more low frequencies. 
    }
    \label{fig:rnn_receivers}
\end{figure}

\clearpage
\section{Data-Driven and Theory-Guided NN Frameworks}
In this section, DNN refers to ``Data-Driven FWI'' and RNN to ``Theory-Guided RNN as an Analogue of FWI''.

\subsection{Data Volume}
The volume of data used to train for DNN was 20 orders of magnitude greater. Figure~\ref{fig:dnn_rnn_losses} shows the normalised loss for the two derived frameworks, with respective count for the number of training and validation shot or shot equivalent. Given that the DNN framework used randomly generated traces with each epoch of 1,000,000 and 100,000 trace for training and validation respectively, these were batched into groups of 340 traces to match the number of receivers in the RNN approach.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\textwidth]{02_all_freq_models_04_DNN_losses-eps-converted-to.pdf}
    \caption[Classical FWI and RNN implementation velocity model inversion.]{Classical FWI and RNN implementation velocity model inversion.}
    \label{fig:dnn_rnn_losses}
\end{figure}

\subsection{Data-Driven Uplift}
DNN produces more imaging uplift since it is not bound by the deterministic forward-modelling physical constraints from ray-tracing. Figure~\ref{fig:fwi_ray_tracing} shows a sample of shots through the Marmousi model. Ray-paths below the high velocity at depth 2-2.5km do not arrive at the receivers at the surface for the current model offsets. Acquisition geometry controlling the offset is a hard-limit within FWI. \citet{Morgan2009} considers large-offsets to be fundamental for successful FWI. Moreover, this hinders seismic imaging in and around salt bodies since, by definition, only one-way ray-paths are considered \citep{Jones2014}. In the case of the data-generators used for the DNN approach, these are free from offset-constraints and do not influence the inversion experiment employed by classical FWI.

%  - See Figures~\ref{fig:fwi_poor_illum}. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.95\linewidth]{27_real_data_06_ray_tracing_marm1_v2-eps-converted-to.pdf}
    \caption[Ray-tracing coverage within forward modelling]{Ray-tracing coverage within forward modelling derived from deterministic geophysics.}
    \label{fig:fwi_ray_tracing}
\end{figure}

% \begin{figure}[ht!]
%     \centering
%     \includegraphics[width=0.95\linewidth]{fwi_poor_illumination.png}
%     \caption[Typical ray-paths and Reflection point counts for classical FWI.]{Typical ray-paths and Reflection point counts for area at salt flank that has poor illumination due to deterministic inversion. Adapted from \cite{Jones2014}.}
%     \label{fig:fwi_poor_illum}
% \end{figure}

\subsection{Inversions}
Figure~\ref{fig:dnn_rnn_models} and~\ref{fig:dnn_rnn_model_zoomed_in} are the full and zoomed-in sections for the inverted models for classical FWI, DNN and RNN respectively. DNN has better layer amplitude continuity as seen by in Zoom 1 and Zoom 3. RNN is better at edge definition than both DNN and FWI as in Zoom 2. 

The velocity profiles in Figure~\ref{fig:dnn_rnn_velocity_profiles} illustrate with Label A how either approach is good in the middle and shallow sections. Indeed, if the RNN artefact labelled A$^{1}$ is excluded in smaller Xlines, this would be valid for either Xline. Label B show how large velocity contrasts within the velocities is well defined for DNN, followed by FWI. In particular, the RNN approach is able to identify the edges, but not able to reconstruct the amplitudes correct. Smaller velocity increases are not an issue as shown by B$^{1}$. A combination of FWI and RNN could potentially exploit the benefit of either. However, not in areas with large velocity contrasts such as salt areas and carbonates. With depth, DNN is a better framework as marked with Label C. Comparing RNN and FWI, RNN is more suited at the edges with Depth as shown with Label C$^{1}$. 

Receivers for pseudo-spectral NN frameworks and true models are shown in Figure~\ref{fig:dnn_rnn_receivers}. Either approach is able to recover different shallow arrivals successfully as marked with Label A. DNN has residual and RNN is able to invert more of the shallow, however FWI recovers direct arrival components nearly completely. Considering CDP 150 and 300, RNN is reinforced as being better performant at the edges from the residuals marked with Label A$^1$. Excluding the gradients artefact of RNN, theses receivers indicate that RNN is the most suited for shallow sections. Both DNN and RNN have leakage on CDP 60 and CDP 300 as shown with Label B. RNN's residual show evidence of signal, possible symptomatic to cycle-skipping. With depth, RNN in general has less residual as shown with Label C.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.8\textwidth]{02_all_freq_models_02_models_with_residual-eps-converted-to.pdf}
    \caption[Pseudo-spectral NN framework comparison of velocity inversion.]{Full model showing differences between DNN and RNN velocity inversion as compare to classical FWI, with residual differences.}
    \label{fig:dnn_rnn_models}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{02_all_freq_models_02_models_with_residual_zoomed_in-eps-converted-to.pdf}
    \caption[Zoomed In pseudo-spectral NN framework comparison]{Zoomed in sections showing differences between DNN and RNN velocity inversion as compare to classical FWI, with residual differences.}
    \label{fig:dnn_rnn_model_zoomed_in}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.98\textwidth]{02_all_freq_models_03_velocity_profiles_with_labels-eps-converted-to.pdf}
    \caption[Velocity profiles for pseudo-spectral NN framework comparison.]{Comparison of velocity profiles for DNN, RNN and classical FWI. Label \textbf{A}: Either approach is good in the middle and shallow sections, with the exception of the gradient artefact marked \textbf{A$^{1}$}. Label \textbf{B}: Problematic recover of large velocity contrasts for RNN, whilst smaller velocity contrasts are inverted corrected as marked by \textbf{B$^{1}$}. Label \textbf{C}: DNN is a better framework with depth for velocity, whilst RNN is more suited at the edges as shown with \textbf{C$^{1}$}}
    \label{fig:dnn_rnn_velocity_profiles}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.92\textwidth]{02_all_freq_models_05_Receiver_with_labels-eps-converted-to.pdf}
    \caption[Labelled receivers for pseudo-spectral NN framework comparison.]{Labelled receivers for True, FWI and RNN models at CDP 60, 150 and 300. Label \textbf{A}: NN frameworks recover shallow arrivals successfully, with RNN reinforced as being better performant at the edges from the residuals marked with \textbf{A$^1$}. Label \textbf{B}: Some signal leakage on NN frameworks. Label \textbf{C}: Less leakage from RNN with depth.}
    \label{fig:dnn_rnn_receivers}
\end{figure}

\clearpage
\section{Summary}
The key outcomes from this chapter can be summarised in the following lists. For ``FWI as a Data-Driven DNN'':
\begin{itemize}
    \item Elements within a classical FWI framework can be replaced with a DNN framework successfully. This was practically assessed for multi-strata model using geophysics-generated data.
    \item Normalization is not a necessary component within the framework.
    \item The ideal architecture is a 1D convolutional based (Conv1D), with Adadelta loss optimization.
    \item Kernel and bias distribution plots for the training process confirm that the framework is a learning process.
    \item Most of the update happens within the first few epochs. Additional epochs refine the inverted velocity.
    \item Inversion performance in shallow section was equally good for either classical FWI or DNN approach. DNN framework performs better for deeper and over-thrust areas since DNNs are not bound by forward-modelling physical constraints from ray-tracing.    
\end{itemize}
For ``RNN as an Analogue of FWI'':
\begin{itemize}
    \item Pseudo-spectral RNN frameworks are feasible approaches.
    \item Based on comparisons of a simple model with an analytical Green's function formulation, RNN Time is able to model the wavefield within a maximum 0.06 error tolerance and 1.74\% RPE. RNN Freq is overall more accurate with 0.05 error tolerance and 1.449\% RPE.
    \item Adjoint state and RNN Freq gradients overestimate the Finite Difference, whilst RNN Time under-estimates it with an infinitesimal error. RNN Freq produce a perturbation on the onset of the gradient which is attributed to modelling artefact.
    \item Based on the model size and compute available, the ideal loss was Adam with a learning rate of 2 and batch size of 1. Model batch size proved to be a limitation for practical implementations.
    \item RNN is computationally more efficient than the classical FWI presented in this work. RNN freq shows more stable convergence.
    \item Classical FWI and RNN approaches have merits. RNN frameworks are able to identify faults, but amplitudes are not fully inverted properly. This results in RNN inversions with some missing layers. However, the low frequency content in RNN approaches is better than classical FWI, particularly for RNN Freq.
\end{itemize}
Outcomes of the comparison between the NN approaches:
\begin{itemize}
    \item Well performing DNN was achievable through the use of a very large dataset.
    \item DNN recovers more of the velocity contrast and RNN is better at edge definition.
    \item RNN is the most suited for the shallow sections (exclude the gradient artefact) and at depth due to the cleaner residuals on the receivers. This is only valid in the middle section of the model with the most coverage from ray-tracing. Indeed, RNN approaches have some leakage on the edges which might be symptomatic to cycle-skipping.
    \item RNN Freq is able to recover more low frequencies. 
\end{itemize}