\chapter[Code and Additional Results]{Code Repository and Additional Results}

\section{Code Repository}\label{sec:app_results_code_repo}
A git repository with all code used in this dissertation is available at \url{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/}. In the following chapter, any reference made to code will refer to this repository.

\section{Marmousi-2 Model}\label{sec:app_results_generation_marm}
The original Marmousi-2 model has been made available by \cite{Martin2006} under a Creative Commons Attribution 4.0 International License. This was modified with a 150m median filter. Figure~\ref{fig:app_smooth_marm_vel_profile} shows the impact of the 150m median filter on the vertical resolution of the model. The code used for this modification is available at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/Marmousi_2_generator.ipynb}{\url{./code/appendix/Marmousi\_2\_generator.ipynb}}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.4\textwidth]{smooth_marm2.png}
    \caption[Sample velocity profile through original and modified Marmousi-2 model.]{Sample velocity through original and modified Marmousi-2 model. $s$ is the 150m median filtered modified Marmousi-2.}
    \label{fig:app_smooth_marm_vel_profile}
\end{figure}

\section{Classical FWI}\label{sec:app_results_classical_FWI}
\subsection{Inversion}
FWI with Sobolev space norm regularization was used as the deterministic version of FWI within this work. The maximum frequency of the inversion process was set to be 3.5\si{Hz}. The iterative update process started from frequency 1\si{Hz} and iteratively updated by a factor of 1.2 until reaching a maximum frequency of 3.45\si{Hz}. The optimization algorithm was L-BFGS-B, with 50 iterations per frequency. Figure~\ref{fig:app_classical_fwi_loss} is the loss update for L-BFGS-B and Stochastic Gradient Descent. Figure~\ref{fig:classical_fwi_progression} shows the progression of the frequency updates. Code for this implementation is available at \href{https://gitfront.io/r/zerafachris/fbeffbcbfa1a363bc271e3bcd3717a830d3bfe7f/academic/tree/PhD/code/classical_FWI/marmousi/*}{\url{./classical\_FWI/marmousi}}.

\begin{figure}[!ht]
        \centering
        \includegraphics[width=0.5\textwidth]{15_Dissertation_05_FWI_lbfgs_loss-eps-converted-to.pdf}
        \caption[Classical FWI loss update.]{Classical FWI loss update for L-BFGS-B and Stochastic Gradient Descent. L-BFGS-B was a better loss optimizer than Stochastic Gradient Descent due to the monotonically decreasing loss. Stochastic Gradient Descent training should have been stopped at an earlier epoch due to the increase at 30 when compared to earlier epoches.}
        \label{fig:app_classical_fwi_loss}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.44\textwidth]{classical_fwi/true-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/init-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/1-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/2-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/3-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/4-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/5-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/6-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/7-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/8-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/9-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/10-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/11-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/12-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/13-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/14-eps-converted-to.pdf}
    \includegraphics[width=0.44\textwidth]{classical_fwi/final-eps-converted-to.pdf}
    \caption[Classical FWI frequency updates.]{Classical FWI frequency updates. Starting from 1\si{Hz}, model update frequency was increased by a factor of 1.2 until a maximum frequency of 3.45\si{Hz}.The optimization algorithm was L-BFGS-B, with 50 iterations per step.}
    \label{fig:classical_fwi_progression}
\end{figure}

\subsection{Ray-Tracing}
Pre-cursor to FWI is ray-tracing modelling to assess areas of update from standard FWI formulation. Open source version of \textbf{fteikpy} Python library provided by \citet{Noble2014} was adapted and utilized on the Marmousi-2 in §~\ref{sec:app_results_generation_marm}. This implementation computes accurate first arrival travel-times in 2D heterogeneous isotropic velocity models. The algorithm solves a hybrid Eikonal formulation with a spherical approximation near-source and a plane wave approximation in the far field. This reproduces properly the spherical behaviour of wave fronts in the vicinity of the source \citep{Noble2014}. Figure~\ref{fig:fteikpy_ray_tracing_marmousi} shows a sample of ray-paths for a source at 0km and depth 0km and ray coverage for the Marmousi model. The adapted code is available within \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/ray_tracing/marmousi/marmousi_ray_tracing.ipynb}{\url{./ray_tracing/marmousi/marmousi_ray_tracing.ipynb}}.
\clearpage
\begin{figure}[ht]
        \centering
        \subbottom[Sample of ray-paths through Marmousi]{\includegraphics[width=0.65\textwidth]{fteikpy_ray_tracing_marmousi.png}}

        \subbottom[Area of coverage intensity from ray-tracing.]{\includegraphics[width=0.65\textwidth]{27_real_data_06_ray_tracing_marm1_ray_coverage-eps-converted-to.pdf}}
        \caption[Ray-tracing using \textbf{fteikpy}.]{Ray-tracing using \textbf{fteikpy}.}
        \label{fig:fteikpy_ray_tracing_marmousi}
\end{figure}

\section{Data-Driven FWI}\label{sec:app_results_summary_results_exp_1}
\subsection{DNN Architectures}\label{sec:app_results_architectural_summary_dnn_workflow}
Table~\ref{tab:app_results_dnn_architectures} lists DNN architectures used throughout Section~\ref{sec:results_FWI_as_a_Learned_Direct_Approximation}.
\begin{table*}[ht]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}ll@{}}\toprule
    Architecture                           & Code Repository    \\ \hline
    Time to Pseudo-Spectral 1D             & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_time_pseudo.txt}{\url{./appendix/DNN\_arch\_time\_pseudo_1D.txt}}\\
    Time to Pseudo-Spectral 2D             & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_time_pseudo.txt}{\url{./appendix/DNN\_arch\_time\_pseudo_2D.txt}}\\
    Conv1D                                 & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_conv1d.txt}{\url{./appendix/DNN\_arch\_conv1d.txt}}\\
    Conv2D                                 & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_conv2d.txt}{\url{./appendix/DNN\_arch\_conv2d.txt}}\\
    VGG                                    & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_vgg.txt}{\url{./appendix/DNN\_arch\_vgg.txt}}\\
    ResNet                                 & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_resnet.txt}{\url{./appendix/DNN\_arch\_resnet.txt}}\\
    Marmousi - Time to Pseudo-Spectral     & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_marm_time_pseudo.txt}{\url{./appendix/DNN\_arch\_marm\_time\_pseudo.txt}}\\
    Marmousi - Pseudo-Spectral to Velocity & \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_marm_pseudo_velocity.txt}{\url{./appendix/DNN\_arch\_marm\_pseudo\_velocity.txt}}\\
    \hline
    \end{tabular}
    \caption{Repositories defining different architectures used in Section~\ref{sec:results_FWI_as_a_Learned_Direct_Approximation}.}\label{tab:app_results_dnn_architectures}
\end{table*}
% \subsection{Time to Pseudo-Spectral representation network}\label{sec:app_results_time_pseudo}
% \verbatiminput{appB/DNN_arch_time_pseudo.txt}
% Available on GitHub at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_time_pseudo.txt}{\url{./appendix/DNN\_arch\_time\_pseudo.txt}}.

% \subsection{Conv1D}\label{sec:app_results_architectural_summary_Conv1D}
% % \verbatiminput{appB/DNN_arch_conv1d.txt}
% Available on GitHub at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_conv1d.txt}{\url{./appendix/DNN\_arch\_conv1d.txt}}.

% \subsection{Conv2D}\label{sec:app_results_architectural_summary_Conv2D}
% % \verbatiminput{appB/DNN_arch_conv2d.txt}
% Available on GitHub at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_conv2d.txt}{\url{./appendix/DNN\_arch\_conv2d.txt}}.

% \subsection{VGG}\label{sec:app_results_architectural_summary_VGG}
% % \verbatiminput{appB/DNN_arch_vgg.txt}
% Available on GitHub at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_vgg.txt}{\url{./appendix/DNN\_arch\_vgg.txt}}.

% \subsection{ResNet}\label{sec:app_results_architectural_summary_ResNet}
% % \verbatiminput{appB/DNN_arch_resnet.txt}
% Available on GitHub at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_resnet.txt}{\url{./appendix/DNN\_arch\_resnet.txt}}.

% \subsubsection{Marmousi - Time to Pseudo-Spectral}\label{sec:app_results_marm_dnn_time_pseudo}
% % \verbatiminput{appB/DNN_arch_marm_time_pseudo.txt}
% Available on GitHub at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_marm_time_pseudo.txt}{\url{./appendix/DNN\_arch\_marm\_time\_pseudo.txt}}.

% \subsubsection{Marmousi - Pseudo-Spectral to Velocity}\label{sec:app_results_marm_dnn_time_pseudo}
% % \verbatiminput{appB/DNN_arch_marm_pseudo_velocity.txt}
% Available on GitHub at \href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/DNN_arch_marm_pseudo_velocity.txt}{\url{./appendix/DNN\_arch\_marm\_pseudo\_velocity.txt}}.

\subsection{Architecture and Loss Tuning}
Tables~\ref{tab:app_res1_duration}-\ref{tab:app_res1_inversion} show results for different architecture and loss optimizer combinations.
\begin{table*}[!ht]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}llll@{}}\toprule
            Architecture & Loss Optimizer & Duration (Hours) & Rank         \\ \hline
            MLP          & Adagrad        & 45               & 18            \\
            MLP          & Adadelta       & 54               & 16            \\
            MLP          & RMSprop        & 31               & 20            \\
            MLP          & Adam           & 36               & 19            \\
            Conv1D       & Adagrad        & 49               & 17            \\
            Conv1D       & Adadelta       & 59               & 14            \\
            Conv1D       & RMSprop        & 59               & 14            \\
            Conv1D       & Adam           & 55               & 15            \\
            Conv2D       & Adagrad        & 66               & 12            \\
            Conv2D       & Adadelta       & 66               & 12            \\
            Conv2D       & RMSprop        & 67               & 10            \\
            Conv2D       & Adam           & 67               & 10            \\
            VGG          & Adagrad        & 75               & 8             \\
            VGG          & Adadelta       & 75               & 8             \\
            VGG          & RMSprop        & 177              & 1             \\
            VGG          & Adam           & 75               & 8             \\
            ResNet       & Adagrad        & 108              & 4             \\
            ResNet       & Adadelta       & 108              & 4             \\
            ResNet       & RMSprop        & 144              & 2             \\
            ResNet       & Adam           & 107              & 5             \\ \hline
    \end{tabular}
    \caption[Architecture and Loss comparison - Duration]{Architecture and Loss comparison - Duration. The shortest duration is better result.}
    \label{tab:app_res1_duration}
\end{table*}

\begin{table*}[!ht]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}llll@{}}\toprule
            Architecture & Loss Optimizer & Train MSE & Rank         \\ \hline
            MLP          & Adagrad        & 6352.22549   & 4    \\
            MLP          & Adadelta       & 86460.7877   & 13   \\
            MLP          & RMSprop        & 8098.47514   & 7    \\
            MLP          & Adam           & 1369163.37   & 19   \\
            Conv1D       & Adagrad        & 5180.91202   & 2    \\
            Conv1D       & Adadelta       & 9913.78826   & 8    \\
            Conv1D       & RMSprop        & 14578.6939   & 9    \\
            Conv1D       & Adam           & 20305.0825   & 10   \\
            Conv2D       & Adagrad        & 6808.32294   & 5    \\
            Conv2D       & Adadelta       & 111152.159   & 15   \\
            Conv2D       & RMSprop        & 1618.25641   & 1    \\
            Conv2D       & Adam           & 5145821.2    & 20   \\
            VGG          & Adagrad        & 6139.20768   & 3    \\
            VGG          & Adadelta       & 93423.5512   & 14   \\
            VGG          & RMSprop        & 59200.3044   & 11   \\
            VGG          & Adam           & 78038.1544   & 12   \\
            ResNet       & Adagrad        & 7280.4593    & 6    \\
            ResNet       & Adadelta       & 131353.653   & 17   \\
            ResNet       & RMSprop        & 123707.716   & 16   \\
            ResNet       & Adam           & 232489.037   & 18   \\ \hline
    \end{tabular}
    \caption[Architecture and Loss comparison - Training MSE.]{Architecture and Loss comparison - Training MSE. The lowest MSE is the better result.}\label{tab:app_res1_train_MSE}
\end{table*}

\begin{table*}[!ht]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}lll@{}}\toprule
            Architecture & Loss Optimizer & Rank         \\ \hline
            MLP          & Adagrad        & 20   \\
            MLP          & Adadelta       & 19   \\
            MLP          & RMSprop        & 9    \\
            MLP          & Adam           & 9    \\
            Conv1D       & Adagrad        & 15   \\
            Conv1D       & Adadelta       & 19   \\
            Conv1D       & RMSprop        & 9    \\
            Conv1D       & Adam           & 17   \\
            Conv2D       & Adagrad        & 15   \\
            Conv2D       & Adadelta       & 15   \\
            Conv2D       & RMSprop        & 9    \\
            Conv2D       & Adam           & 3    \\
            VGG          & Adagrad        & 15   \\
            VGG          & Adadelta       & 15   \\
            VGG          & RMSprop        & 9    \\
            VGG          & Adam           & 4    \\
            ResNet       & Adagrad        & 17   \\
            ResNet       & Adadelta       & 15   \\
            ResNet       & RMSprop        & 3    \\
            ResNet       & Adam           & 3   \\            \hline
    \end{tabular}
    \caption[Architecture and Loss comparison - Under-fitting/over-fitting]{Architecture and Loss comparison - Qualitative assessment of under-fitting/over-fitting and learning rate performance.}\label{tab:app_res1_validation_MSE}
\end{table*}

\begin{table*}[!ht]
    \footnotesize
    \centering
    % \ra{1.3}
    \begin{tabular}{@{}llll@{}}\toprule
            Architecture & Loss Optimizer & Inversion RMSE (Hours) & Rank         \\ \hline
                MLP          & Adagrad        & 102.008808 & 11   \\
                MLP          & Adadelta       & 144.749442 & 8    \\
                MLP          & RMSprop        & 41.112304  & 15   \\
                MLP          & Adam           & 161.546795 & 7    \\
                Conv1D       & Adagrad        & 19.0347424 & 18   \\
                Conv1D       & Adadelta       & 15.4491243 & 19   \\
                Conv1D       & RMSprop        & 15.4070707 & 20   \\
                Conv1D       & Adam           & 20.1883355 & 17   \\
                Conv2D       & Adagrad        & 84.3773592 & 12   \\
                Conv2D       & Adadelta       & 252.899762 & 4    \\
                Conv2D       & RMSprop        & 45.4919989 & 14   \\
                Conv2D       & Adam           & 117.230985 & 10   \\
                VGG          & Adagrad        & 61.7665919 & 13   \\
                VGG          & Adadelta       & 135.254508 & 9    \\
                VGG          & RMSprop        & 23.2408697 & 16   \\
                VGG          & Adam           & 220.758795 & 5    \\
                ResNet       & Adagrad        & 358.686894 & 2    \\
                ResNet       & Adadelta       & 264.61373  & 3    \\
                ResNet       & RMSprop        & 162.649915 & 6    \\
                ResNet       & Adam           & 406.824565 & 1   \\            
             \hline
    \end{tabular}
    \caption[Architecture and Loss comparison - Inversion RMSE]{Architecture and Loss comparison - Inversion RMSE. RMSE for 100,000 validation velocity profile are compared to the true velocity.}\label{tab:app_res1_inversion}
\end{table*}

\subsection{Network Training Process}
For each of the Architecture-Loss combinations available, these networks were trained on an Intel i7-7800x X-series CPU workstation provided by the Department of Physics at the University of Malta. The script for this is available at \\
\href{https://gitfront.io/r/zerafachris/52df30fb666ba880749c8e951a3d056ce628a6cd/PhD/blob/code/appendix/ArchitectureComparison.py}{\url{./code/appendix/ArchitectureComparison.py}}. The initial maximum epoch was set to 20, with 5 epoch early stopping and 2 epoch learning rate reduction of 0.2 when reaching a plateau. The number of traces in the training and testing epoch generators were 1,000,000 and 100,000 respectively. The batch size was set to 100 for MLP and Conv1D, whilst 20 for the other networks due to ram size of the workstation.

\clearpage
\section[Theory-Guided FWI]{Theory-Guided FWI}
\subsection{1D Results}\label{sec:app_results_rnn_fwi_1d}
Replacing the forward modelling component with RNN directly implies that the RNN should be able to retrieve all wavefield components. This was first tested by considering a 1D direct wave as shown in Figure~\ref{fig:app_rnn_1d_direct_results}. A 10Hz Ricker wavelet (Figure~\ref{fig:app_rnn_1d_source}) was injected into a 1D 1500 ms$^{-1}$ constant velocity model (Figure~\ref{fig:app_rnn_1d_velocity}) with a single source and single receiver. The wave was forward propagated for 5333 time-steps at 1ms, with a 10m grid spacing. The resulting direct wave is illustrated in Figure~\ref{fig:app_rnn_1d_direct_wave}, with True being the analytical solution calculated using a 1D Green’s function, RNN Time and RNN Freq are the RNN implementation for forward modelling using Time and Fourier spatial derivatives respectively. Qualitatively, there is no visible difference between either approach. Quantitative analysis shown in Table~\ref{tab:app_rnn_1d_direct} indicates that the pseudo-spectral approach is producing slightly better results with an improved error tolerance of 0.2 in amplitude, resulting in a 0.9\% improvement in the \ac{RPE}.

\begin{figure}[!ht]
        \centering
        \subbottom[Source for 1D experiments.\label{fig:app_rnn_1d_source}]{\includegraphics[width=0.48\textwidth, trim={0 0 19.5cm 0}, clip]{15_Dissertation_02_initial_experiment_1d_1d_direct_wave_velocity-eps-converted-to.pdf}}
        \subbottom[1D constant 1500 m/s velocity model.\label{fig:app_rnn_1d_velocity}]{\includegraphics[width=0.45\textwidth, trim={21cm 0 0 0}, clip]{15_Dissertation_02_initial_experiment_1d_1d_direct_wave_velocity-eps-converted-to.pdf}}

        \subbottom[1D direct wave trace forward modelling comparison to analytical 1D Green’s function wavefield, RNN Time and RNN Freq showing no discrepancies.\label{fig:app_rnn_1d_direct_wave}]{\includegraphics[width=0.9\textwidth, trim={0 0 0 0.7cm}, clip]{15_Dissertation_02_initial_experiment_1d_02_direct_wave_trace-eps-converted-to.pdf}}
        \caption[1D Direct wave forward modelling comparison.]{1D Direct wave forward modelling comparison.}        
        \label{fig:app_rnn_1d_direct_results}
\end{figure}

\begin{table*}[!ht]
        \footnotesize
        \centering
        % \ra{1.3}
        \begin{tabular}{@{}lcc@{}}\toprule
Modelling  & Error Tolerance    & RPE (\%) \\ \hline
RNN Time   & 0.980 & 4.786                           \\
RNN Freq   & 0.780 & 3.809                           \\ \hline
        \end{tabular}
        \caption{Empirical comparison of 1D Direct wave modelling to 1D Green's function.}\label{tab:app_rnn_1d_direct}
\end{table*}

An identical source was used to test for Reflected and Transmitted arrivals. Figure~\ref{fig:app_rnn_1d_direct_refl_transmitted_wavefield} is the 1D step velocity model ranging from 1500 \si{ms^{-1}} to 2500 \si{ms^{-1}} used to produce the forward propagated wavefields in Figure~\ref{fig:app_rnn_1d_direct_refl_transmitted_wavefield}. The top shows the full wavefield, with Direct and Reflected arrivals at about 20 ms and Transmitted wave with peak at 96 ms. Middle and bottom sections of Figure~\ref{fig:app_rnn_1d_direct_refl_transmitted_wavefield} show zoomed sections of the wavefield respectively. Either the Reflected and Transmitted component match near identically to the Green’s function formulation. Quantitatively, the RNN Time implementation was found to be slightly improved, with an improvement of 0.1 in error tolerance and 0.2\% RPE (Table~\ref{tab:app_rnn_1d_direct_refl_transmitted}).

\begin{figure}[!ht]
	\centering
	\subbottom[1D step velocity model ranging from 1500 \si{ms^{-1}} to 2500 \si{ms^{-1}}.\label{fig:app_rnn_1d_direct_refl_transmitted_vel}]{\includegraphics[width=0.8\textwidth]{15_Dissertation_02_initial_experiment_1d_03_reflection_vel_model_only-eps-converted-to.pdf}}
	\subbottom[Top: Full wavefield showing Direct and Reflected waves at about 20ms and Transmitted wave with peak at 96 ms. Middle and Bottom: Zoomed in sections from Full trace showing different components of the wavefield and near perfect reconstruction.\label{fig:app_rnn_1d_direct_refl_transmitted_wavefield}]{\includegraphics[width=0.9\textwidth]{15_Dissertation_02_initial_experiment_1d_04_reflection_traces-eps-converted-to.pdf}}
	\caption[1D direct, reflected and transmitted wave forward modelling comparison.]{1D direct, reflected and transmitted wave forward modelling comparison.}        
	\label{fig:app_rnn_1d_direct_refl_transmitted}
\end{figure}

\begin{table*}[!ht]
        \footnotesize
        \centering
        % \ra{1.3}
        \begin{tabular}{@{}lcc@{}}\toprule
Modelling  & Error Tolerance    & RPE (\%) \\ \hline
RNN Time   & 2.460 & 9.637                           \\
RNN Freq   & 2.520 & 9.872                           \\ \hline
        \end{tabular}
        \caption{Empirical comparison of 1D direct, reflected and transmitted wave modelling.}\label{tab:app_rnn_1d_direct_refl_transmitted}
\end{table*}

The remaining wavefield component to be modelled are Scattering waves. A constant velocity model with one-point scatterer was created with velocity ranging from 1500 \si{ms^{-1}} to 1550 \si{ms^{-1}} at the point scatterer (Figure ~\ref{fig:app_rnn_1d_scattered_vel}). The same source in the previous two wavefields was used. RNN implementations were modelled for the waveform at a point to be depended non-linearly on the scattering amplitude and then approximately linearised. The resulting wavefields are given in Figure~\ref{fig:app_rnn_1d_scattered_wavefield}. The Direct wave was not included in the Scattered wavefield reconstruction. From the error tolerance and RPE comparison (Table~\ref{tab:app_rnn_1d_scattering}), RNN Time produces marginally better results than RNN Freq.
This is due to the lack of ringing effect introduced due to discretisation beyond 1500ms which gets absorbed within the complex component of the pseudo-spectral approach. The RNN Frequency approach is thus a superior modelling approach in 1D. In the 2D case, RNN Time does not suffer from this effect.

\begin{figure}[!ht]
	\centering
	\subbottom[1D scattering velocity model ranging from 1500 \si{ms^{-1}} to 1550 \si{ms^{-1}}.\label{fig:app_rnn_1d_scattered_vel}]{\includegraphics[width=0.8\textwidth]{15_Dissertation_02_initial_experiment_1d_05_scatter_vel_model_only-eps-converted-to.pdf}}
	\subbottom[Scattering wavefield modelling. Direct wavefield was excluded in the modelling.\label{fig:app_rnn_1d_scattered_wavefield}]{\includegraphics[width=0.9\textwidth]{15_Dissertation_02_initial_experiment_1d_06_scatter_waves-eps-converted-to.pdf}}
	\caption[1D scattering wave forward modelling comparison.]{1D scattering wave forward modelling comparison.}    
	\label{fig:app_rnn_1d_scattering}
\end{figure}

\begin{table*}[!ht]
        \footnotesize
        \centering
        % \ra{1.3}
        \begin{tabular}{@{}lcc@{}}\toprule
Modelling  & Error Tolerance    & RPE (\%) \\ \hline
RNN Time – Non-linear	& 0.009	& 0.031     \\
RNN Time – Linear 	& 0.010	& 2.493         \\
RNN Freq – Non-linear	& 0.030	& 7.649         \\
RNN Freq – Linear	& 0.040 & 9.711          \\ \hline
        \end{tabular}
        \caption{Empirical comparison of 1D scattering wave modelling.}\label{tab:app_rnn_1d_scattering}
\end{table*}

% The experiment was extended to a simple 2D case before considering more complicated scenarios (§~\ref{sec:res_forward_modelling_using_rnnd}). A 25Hz Ricker wavelet (Figure~\ref{fig:rnn_2d_source}) was injected into a 2D 1500\si{ms^{-1}} constant velocity model (Figure~\ref{fig:rnn_2d_velocity}) with labelled \ac{SRC} and \ac{RCV}. The 25Hz source wavelet goes into the hyper-resolution realm for FWI and is beyond the resolution that will be investigated on the synthetic model, however this allows for gauging the limit of accuracy for this approach. This model setup was forward propagated for 5333 time-steps at 1ms, with a 10m grid spacing. The resulting direct wave is illustrated in Figure~\ref{fig:rnn_2d_direct_wave}, with True being the analytical solution calculated using a 2D Green’s function, RNN Time and RNN Freq are the RNN implementation for forward modelling using Time and Fourier spatial derivatives respectively. Qualitatively, there is no visible difference between either approach. From a quantitative analysis shown in Table~\ref{tab:rnn_2d_direct}, the time approach is producing slightly better results with an improved error tolerance of 0.2 in amplitude and 2.6\% in \ac{RPE}.

% \begin{figure}[!ht]
%     \centering
%     \subbottom[Source for 2D experiments.\label{fig:rnn_2d_source}]{\includegraphics[width=0.5\textwidth, trim={0 0 19.5cm 0}, clip]{15_Dissertation_02_initial_experiment_1d_1d_direct_wave_velocity-eps-converted-to.pdf}}
%     \subbottom[1D constant 1500\si{ms^{-1}} velocity model.\label{fig:rnn_2d_velocity}]{\includegraphics[width=0.35\textwidth]{15_Dissertation_01_initial_experiment_01_2d_direct_wave_velocity-eps-converted-to.pdf}}

%     \subbottom[2D direct wave trace forward modelling comparison to analytical 2D Green’s function wavefield, RNN Time and RNN Freq showing no discrepancies.\label{fig:rnn_2d_direct_wave}]{\includegraphics[width=0.8\textwidth]{15_Dissertation_02_initial_experiment_1d_02_direct_wave_trace-eps-converted-to.pdf}}
%     \caption[2D direct wave forward modelling comparison.]{2D direct wave forward modelling comparison.}        
%     \label{fig:rnn_2d_direct}
% \end{figure}
% \begin{table*}[!ht]
%     \footnotesize
%     \centering
%     % \ra{1.3}
%     \begin{tabular}{@{}lcc@{}}\toprule
% Modelling  & Error Tolerance    & RPE (\%) \\ \hline
% RNN Time   & 0.030	& 3.864                           \\
% RNN Freq   & 0.050	& 6.440                            \\ \hline
%     \end{tabular}
%     \caption{Empirical comparison of 2D direct wave modelling to 2D Green function.}\label{tab:rnn_2d_direct}
% \end{table*}

% The same source used for direct wave modelling was used to test for a multi-source, multi-receiver geometry. Figure~\ref{fig:rnn_2d_multisource_vel} shows a 2D velocity model ranging from 1500\si{ms^{-1}} to 2500\si{ms^{-1}}. Figure~\ref{fig:rnn_2d_multisource_trace} is the forward modelled wavefield and Figure~\ref{fig:rnn_2d_multisource_trace_zoom} are zoomed in sections respectively. The addition of geometric consideration to the problem did not qualitatively hinder the quality of the modelling. Based on the metrics in Table~\ref{tab:rnn_2d_direct_multi}, RNN Freq was found to be slightly better, with an improvement of 0.01 in error tolerance and 0.3\% \ac{RPE}.

% \begin{figure}[!ht]
%     \centering
%     \subbottom[2D constant velocity for multi-source and multi-receiver analysis.\label{fig:rnn_2d_multisource_vel}]{\includegraphics[width=0.75\textwidth]{15_Dissertation_01_initial_experiment_03_2d_direct_multi_src_rcv_model_only-eps-converted-to.pdf}}
%     \subbottom[2D direct wave trace forward modelled through multi-source and multi-receiver velocity model.\label{fig:rnn_2d_multisource_trace}]{\includegraphics[width=0.75\textwidth]{15_Dissertation_01_initial_experiment_04_2d_direct_multi_src_rcv_trace_1-eps-converted-to.pdf}}
%     \subbottom[Zoomed in areas over 2D direct wave trace forward modelled through multi-source and multi-receiver velocity model.\label{fig:rnn_2d_multisource_trace_zoom}]{\includegraphics[width=0.75\textwidth]{15_Dissertation_01_initial_experiment_04_2d_direct_multi_src_rcv_trace_2-eps-converted-to.pdf}}
    
%     \caption[2D direct wave forward modelling comparison for multi-source and multi-receiver.]{2D direct wave forward modelling comparison for multi-source and multi-receiver}        
%     \label{fig:rnn_2d_direct_multi}
% \end{figure}
    
% \begin{table*}[ht!]
%     \footnotesize
%     \centering
%     % \ra{1.3}
%     \begin{tabular}{@{}lcc@{}}\toprule
%     Modelling  & Error Tolerance    & RPE (\%) \\ \hline
%     RNN Time   & 0.060 & 1.740            \\
%     RNN Freq   & 0.050 & 1.449            \\ \hline
%     \end{tabular}
%     \caption{Empirical comparison of 2D multi-source, multi-receiver direct wave modelling.}\label{tab:rnn_2d_direct_multi}
% \end{table*}

% \clearpage
% Reflected and transmitted arrivals were tested using a simple step velocity model ranging from 1500\si{ms^{-1}} to 2000\si{ms^{-1}} (Figure~\ref{fig:rnn_2d_reflection_vel}). Figure~\ref{fig:rnn_2d_reflection_wave} is the forward modelled wavefield for two receiver locations RCV-1 and RCV-2, top and bottom respectively. RCV-1 at ground level interacts with the direct wave at 125ms and reflected wave is visible at 250ms. RCV-2 is below the acoustic impedance layer at 30m and shows the transmitted wave. Comparing these to the analytical solution, either are able to reconstruct the wave components perfectly. Metrics in Table~\ref{tab:rnn_2d_reflection} indicate that RNN Time matches the 2D Green’s function near perfectly, whilst RNN Freq introduces an error of 0.020 and 0.010\%. The latter is considered to be superficial and should not impact the modelling process.

% \begin{figure}[!ht]
% 	\centering
% 	\subbottom[2D step velocity model ranging from 1500\si{ms^{-1}} to 2000\si{ms^{-1}}.\label{fig:rnn_2d_reflection_vel}]{\includegraphics[width=0.9\textwidth]{15_Dissertation_01_initial_experiment_08_2d_reflection_velocity-eps-converted-to.pdf}}
% 	\subbottom[Top: Full wavefield showing Direct and Reflected waves at about 20ms and Transmitted wave with peak at 96 ms. Middle and Bottom: Zoomed in sections from Full trace showing different components of the wavefield and near perfect reconstruction.\label{fig:rnn_2d_reflection_wave}]{\includegraphics[width=0.9\textwidth]{15_Dissertation_01_initial_experiment_09_2d_reflection_waves-eps-converted-to.pdf}}
% 	\caption[1D direct, reflected and transmitted wave forward modelling comparison.]{1D direct, reflected and transmitted wave forward modelling comparison.}        
% 	\label{fig:rnn_2d_reflection}
% \end{figure}

% \begin{table*}[!ht]
%         \footnotesize
%         \centering
%         % \ra{1.3}
%         \begin{tabular}{@{}lcc@{}}\toprule
%             Modelling  & Error Tolerance    & RPE (\%) \\ \hline
%             RNN Time   & 0.001 & 0.002                  \\
%             RNN Freq   & 0.020 & 0.013                  \\ \hline
%         \end{tabular}
%         \caption{Empirical comparison of 2D reflected and transmitted wave modelling.}\label{tab:rnn_2d_reflection}
% \end{table*}

% The remaining wavefield components are scattering waves. A constant velocity model of 1500 \si{ms^{-1}} was created with a 1550\si{ms^{-1}} point scatterer (Figure~\ref{fig:rnn_2d_scattered_vel}). RNN implementations were modelled to be depended non-linearly on the scattering amplitude and then approximately linearised. The resultant are given in Figure~\ref{fig:rnn_2d_scattered_wavefield}. The direct wave was not included in the scattered wavefield reconstruction. From the error tolerance and RPE comparison (Table~\ref{tab:rnn_2d_scattering}), RNN Time produces marginally better results than RNN Freq.

% \begin{figure}[!ht]
% \centering
% \subbottom[2D scattering velocity model ranging from 1500\si{ms^{-1}} to 1550\si{ms^{-1}}.\label{fig:rnn_2d_scattered_vel}]{\includegraphics[width=0.75\textwidth]{15_Dissertation_01_initial_experiment_05_2d_scattering_waves_model-eps-converted-to.pdf}}
% \subbottom[Scattering wavefield modelling. Direct wavefield was excluded in the modelling.\label{fig:rnn_2d_scattered_wavefield}]{\includegraphics[width=0.75\textwidth]{15_Dissertation_01_initial_experiment_06_2d_scattering_waves_trace_full-eps-converted-to.pdf}}
% \subbottom[Zoomed scattering wavefield modelling. Direct wavefield was excluded in the modelling.\label{fig:rnn_2d_scattered_wavefield}]{\includegraphics[width=0.75\textwidth]{15_Dissertation_01_initial_experiment_07_2d_scattering_waves_trace_zoom-eps-converted-to.pdf}}
% \caption[2D scattering wave forward modelling comparison.]{2D scattering wave forward modelling comparison.}    
% \label{fig:rnn_2d_scattering}
% \end{figure}

% \begin{table*}[!ht]
%     \footnotesize
%     \centering
%     % \ra{1.3}
%     \begin{tabular}{@{}lcc@{}}\toprule
% Modelling  & Error Tolerance    & RPE (\%) \\ \hline
%     RNN Time – Non-linear	& 0.003	& 0.010  \\
%     RNN Time – Linear   	& 0.010 & 0.025         \\
%     RNN Freq – Non-linear	& 0.030	& 0.076         \\
%     RNN Freq – Linear	    & 0.040 & 0.097         \\ \hline
%     \end{tabular}
%     \caption{Empirical comparison of 2D scattering wave modelling.}\label{tab:rnn_2d_scattering}
% \end{table*}

% Summarising all these results for the modelled wave components, the proposed RNN implementation for FWI is a viable approach.

\subsection{RNN Hyper-Parameter Tuning}\label{sec:app_results_rnn_hp_tuning}
Similarly to the approach shown in \cite{Sun2019}, a benchmark 1D 4-layer synthetic profile, with velocities [2, 3, 4, 5] \si{kms^{-1}}, was used to identify the ideal parameters for the RNN architecture. Classical 1D second-order \ac{FD} modelling was used to generate the required true receiver data. Batch size is used as a discriminator throughout Figure~\ref{fig:app_results_rnn_hp_tuning_inversion}. The results indicate that the larger the batch size used, the better the inversion as more data is being used. However, given fore-sight that this hyper-parameter tuning will be used a large dataset that might not fit in Graphical Processing Unit RAM, this was fixed at batch size one. 

\begin{figure}[!ht]
        \centering
        \includegraphics[width=0.99\textwidth]{15_Dissertation_04_Hyperparameter_Selection_02_Losses-eps-converted-to.pdf}
        \caption[Losses for different loss optimizer learning rate hyper-parameter tuning.]{Losses for different loss optimizer learning rate hyper-parameter tuning.}
	\label{fig:app_results_rnn_hp_tuning_losses}
\end{figure}

\begin{figure}[!ht]
	\centering
	\subbottom[RNN Time]{\includegraphics[width=0.95\textwidth]{15_Dissertation_04_Hyperparameter_Selection_01_Model_Inversion_time-eps-converted-to.pdf}}
        \subbottom[RNN Freq]{\includegraphics[width=0.95\textwidth]{15_Dissertation_04_Hyperparameter_Selection_01_Model_Inversion_freq-eps-converted-to.pdf}}
	\caption[Different Loss optimizer learning rate hyper-parameter tuning results.]{Loss optimizer learning rate hyper-parameter tuning results.}
	\label{fig:app_results_rnn_hp_tuning_inversion}
\end{figure}

\clearpage
% \subsection{All inversions}
% Given that optimal loss optimizer can be derived from results in §~\ref{sec:app_results_rnn_hp_tuning}, the Marmousi model was inverted for the different loss optimizer. These results are given in Figure~\ref{fig:app_results_rnn_all_inversions}.

% \begin{figure}[!ht]
%         \centering
%         \includegraphics[width=0.95\textwidth]{15_Dissertation_04_Hyperparameter_Selection_02_Losses-eps-converted-to.pdf}
%         \caption[ALL INVERSIONS]{ALL INVERSIONS <------ NEED UPDATE}
% 	\label{fig:app_results_rnn_all_inversions}
% \end{figure}

\subsection{RNN Inversion Update Progress}\label{sec:app_results_rnn_update_progress}
Complementary to inverted Marmousi models in §~\ref{sec:results_rnn_comparison_to_FWI}, Figure~\ref{fig:app_results_rnn_update_progress_model} gives the update progress at epoch 10, 25, 40, 55, 70, 85 and 100 for RNN Time and RNN Freq, together with residual. Furthermore, classical FWI progress is included at different update frequency scales. In addition, receivers are provided in Figure~\ref{fig:app_results_rnn_update_progress_rcv}.

\begin{figure}[!ht]
        \centering
        \includegraphics[width=0.9\textwidth]{13_Dissertation_Plots_01_model_inv_06_update_progress_model-eps-converted-to.pdf}
        \caption[Velocity model inversion update progress.]{Velocity model inversion update progress for classical FWI, RNN Time and Freq, with residuals.}
	\label{fig:app_results_rnn_update_progress_model}
\end{figure}

\begin{figure}[!ht]
        \centering
        \includegraphics[width=0.95\textwidth]{13_Dissertation_Plots_01_model_inv_07_update_progress_receivers-eps-converted-to.pdf}
        \caption[Receiver progress through model updates.]{Receiver progress through model updates for classical FWI, RNN Time and Freq, with residuals.}
	\label{fig:app_results_rnn_update_progress_rcv}
\end{figure}
