\section{Constructing Domains for Web-Scale Data} \label{sec:taxonomies}

State-of-the-art language models rely overwhelmingly on \textit{web-crawled} training data \citep{baack2024critical, raffel2020exploring, brown2020language, rae2021scaling, penedo2023refinedweb, soldaini-etal-2024-dolma, penedo2024finewebdatasetsdecantingweb, li2024datacomplm}---with open-source research typically resorting to data provided by the CommonCrawl foundation\footnote{\href{https://commoncrawl.org}{\tt commoncrawl.org}}.
Unlike the large-scale ImageNet dataset \citep{imagenet_cvpr09}, which was collected according to an explicit conceptual hierarchy,
these web corpora simply contain all web pages adhering to certain filtering rules, resulting in trillions of tokens without an inherent structure.
While it is common practice to include selected URL domains, such as Wikipedia or StackOverflow \citep{touvron2023llama, together2023redpajama, soldaini-etal-2024-dolma}, these additions are comparatively small and do not demystify the vast amount of data within CommonCrawl.

Our practices of data curation are opaque and uninformed without a firm understanding of how these large-scale corpora are internally composed.
In this paper, our approach is to {\it design} domain taxonomies to address this short-coming.
We first lay out the desirable properties of such domains, then describe our method for creating taxonomies and annotating pre-training datasets,
and finally compare our taxonomy-driven domains to a baseline that partitions a corpus via $k$-means clusters.




\paragraph{Desiderata}
Since a corpus can be partitioned in exponentially many ways, we seek domains that produce human insights into pre-training corpora and our domains should align with meaningful human categories.
To facilitate human exploration, we also aim for a compact number of domains that capture high-level trends and allow for a concise representation of the corpus. 
Therefore, each domain should also have a reasonable amount of presence in the corpus.
For example, URL domains would be too granular, as there are 18.5k URL domain names with more than 1k documents in a 200B token subset of CommonCrawl and 14.7M URL domain names with fewer documents (see \autoref{fig:url_stats} in appendix). 
A smaller set of domains also decreases the chance of domain conflicts and ambiguities, 
and makes it easier to learn how to rebalance these domains.



\subsection{Human-in-the-loop design of domain taxonomies}

We design two domain taxonomies for WebOrganizer to capture the {\topics topic} and {\formats format} of web pages, respectively.
These are meant to capture complementary characteristics: The topic should describe the subject matter of the website content, whereas the format concerns its style, intent and venue.\footnote{
This distinction has also been made by \citet{vanderwees2015whats} in terms of topic and genre.}

We start by reviewing existing fine-grained web taxonomies, specifically the crowd-sourced {curlie.org} web directory, Google Adsense, the Wikipedia ontology, and the most frequent URL domains.
We identify common themes and propose coarse-grained topic and format definitions,
which we iteratively refine by prompting \mbox{Llama-3.1-405B-Instruct} \citep{dubey2024llama} to classify CommonCrawl samples and reviewing these annotations.

Following our desiderata, we consolidate less frequently occurring topics into topic clusters---for example, our {\atopic Industrial} topic spans manufacturing, mining, agriculture, and utilities, mathematics is subsumed in {\atopic Science \& Technology};
in terms of formats, cooking recipes become part of {\aformat Tutorials}.
We also adjust the categories to match the abilities of language models and what they can deduce from seeing only the URL and text contents of a web page.
For example, we observe that models are uncertain when choosing between comment sections and discussion forums, motivating us to merge these formats. 
In other instances, we add guidelines for resolving ambiguous cases.
We eventually settle on 24 categories per taxonomy (see definitions and prompts in  \autoref{app:domain_descriptions}).
 
Our approach of proposing taxonomies in natural language and refining them based on model annotations is flexible and can be used for other purposes---for instance, to annotate a corpus of scientific papers with detailed subject areas, or to taxonomize the data within each of our domains to build a nested hierarchy.
Unlike recent techniques for automatically constructing taxonomies with large-language models \citep{chen2021constructing, mishra2024flame, pham2024topicgpt}, our approach requires human effort, but also benefits from human oversight and domain expertise.


\vspace{-1em}
\subsection{Training domain classifiers for scaling annotations}

While useful during taxonomy development, it would be extremely expensive to annotate a web-scale corpus with a large language model.
Therefore, we enable WebOrganizer by fine-tuning small classifier model
to imitate the annotations of Llama-3.1-405B-Instruct using a soft knowledge distillation loss \citep{hinton2025distilling}.
We initialize the classifiers with \mbox{gte-base-en-v1.5} \citep{li2023gte}---a 140M parameter embedding model with a 8192 token context window---and train them in two stages to improve their coverage over diverse web content. 
In the first stage, we train with 1M annotations from the cheaper Llama-3.1-8B-Instruct model, followed by 80K high-quality annotations from Llama-3.1-405B-Instruct.
In \autoref{app:domain_classifiers}, we discuss the setup in more detail and show how the two-stage training is useful for improving the classifier accuracy. 
We use the topic and a format classifiers to annotate a 200B pre-training corpus, which is based on CommonCrawl and cleaned using heuristic rules \citep{penedo2023refinedweb} and deduplication \citep{soldaini-etal-2024-dolma}.


\subsection{Domain statistics} \label{sec:domain_statistics}
\ificml\else
\begin{minipage}[t]{0.5\linewidth}%
\fi
\autoref{fig:treemaps} gives an overview of the topic and format domains provided by WebOrganizer and visualizes their proportions in the pre-training corpus.
\autoref{fig:pmi_topic_type} shows the highest values of the normalized pointwise-mutual information between topic annotations $T$ and formats $F$,
$$\text{NPMI}(T; F) = {\log \frac{p(T, F)}{p(T)p(F)}}\;/\;{\log \frac{1}{p(T, F)}},$$ where a value of 0 suggests independence and 1 implies complete co-occurrence.
The majority of entries are close to zero with reasonable exceptions for pairs such as {\aformat Documentation} and {\atopic Software Development}.
The normalized mutual information measures the overall level of redundancy, $\text{NMI}(T;\;F) = \frac{2I(T;\; F)}{H(T)+H(F)} \approx 0.10,$
which is close to zero and suggests that an independence assumption approximates the domain product well.
\ificml
\input{figures/pmi_topic_type}
\else
\end{minipage}\hfill
\noindent\begin{minipage}[t]{0.45\linewidth}
\input{figures/pmi_topic_type}
\end{minipage}
\fi

\subsection{Comparison to \texorpdfstring{$k$}{k}-means clustering} \label{sec:kmeans}
Clustering is a natural baseline for partitioning a corpus and has previously been used for training expert models \citep{gururangan2023scaling}.
We use the {\it gte-base-en-v1.5} model \citep{li2023gte} to compute document embeddings for the 200B pre-training corpus and run $k$-means using a distributed implementation by \citet{vo2024automatic}.
We obtain 24 clusters that are more evenly balanced than our domains, but lack inherent natural language descriptions.
Interestingly, we find that the $k$-means cluster assignments $C$ tend to reflect the web site topic more strongly than its format (since $\text{NMI}(C; T) \approx 0.46$ vs. $\text{NMI}(C; F) \approx 0.13$, also see \autoref{fig:pmi_clusters} in the appendix).
Furthermore, the trend is similar even with more fine-grained $k$-means domains of 576 clusters (NMI statistics remain within $\pm$ 0.03).
The orthogonal nature of the format domains suggests that careful human-in-the-loop taxonomies can provide richer data annotations than clustering document embeddings alone.
