% !TEX root = mainfile.tex
 
 
 \section{Evaluation}  
 \label{sec:exp}


\subsection{Experimental Setup} 

\subsubsection{Datasets}
We use the following three datasets from different domains, including two discrete datasets (Cart Pole~\cite{barto1983neuronlike}, Lunar Lander~\cite{duan2016benchmarking}), and one continuous dataset (Inverted Pendulum~\cite{barto1983neuronlike}).
Details of these datasets are provided in Appendix~\ref{sec:datasets_app}.



\subsubsection{Compared Poisoning Attacks}


We compare our Normalized attack with one data poisoning attack (Random action attack~\cite{fan2021fault}) and three model poisoning attacks (Random noise~\cite{fan2021fault}, Trim~\cite{fang2020local}, and Shejwalkar~\cite{shejwalkar2021manipulating}). Details are in Appendix~\ref{sec:Compared_Poisoning_Attacks_app}.


\begin{figure*}[!t]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_mean_byzantine9}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_trim_byzantine9}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_median_byzantine9}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_FedPG-BR_byzantine9}}
	\caption{Results on Cart Pole dataset.}
	\label{Results_CartPole}
\end{figure*}


\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figs/FRLCert_attack_size.pdf}
    \caption{Impact of the fraction of malicious agents on our ensemble method, where the Cart Pole dataset is considered.}
    \label{fig:frac_of_mali}
\end{figure*}


\subsubsection{Foundational Aggregation Rules}
\label{base_agg}

We consider the following state-of-the-art foundational aggregation rules, including five aggregation rules designed for FL (FedAvg~\cite{mcmahan2017communication}, coordinate-wise trimmed mean (Trimmed-mean)~\cite{yin2018byzantine}, coordinate-wise median (Median)~\cite{yin2018byzantine}, geometric median~\cite{ChenPOMACS17} and FLAME~\cite{nguyen2022flame}) and one aggregation rule designed for FRL (FedPG-BR~\cite{fan2021fault}).
Details are in Appendix~\ref{sec:Aggregation_Rules_app}.




\subsubsection{Evaluation Metric}



We evaluate an FRL method’s robustness using \emph{test reward}. For the non-ensemble approach, the test reward is the average reward from 10 sampled trajectories using the trained global policy. In our ensemble method, we also average rewards from 10 trajectories, but actions are predicted using the ensemble framework. A lower test reward indicates a more effective attack and weaker defense.



\subsubsection{Parameter Settings}



By default, we assume that there are 30 agents in total.
Following~\cite{fan2021fault}, we assume that $30\%$ of agents are malicious. 
%
For our proposed ensemble method, we 
partition the agents into $K=5$ 
disjoint groups.
%
%
%
%
The batch sizes $B$ for Cart Pole, Lunar Lander, and Inverted Pendulum datasets are set to 16, 64, and 32, respectively. The learning rates for these three datasets are individually set to $1 \times 10^{-3}$, $3\times10^{-3}$, and $1\times10^{-3}$. Furthermore, for each of the three datasets, every agent samples a total of $5,000$, $10,000$, and $5,000$ trajectories during the training phase, respectively. Regarding the policy architectures, we train a Categorical MLP for the Cart Pole and Lunar Lander datasets and a Gaussian MLP for the Inverted Pendulum dataset. 
The policy architectures are shown in Table~\ref{tab:param_MLP} in Appendix.
%
We assume all agents use the same discount factor $\gamma$, trajectory horizon $H$, and $\Im$.
Our Normalized attack has parameters $ \Delta$, $\hat{\lambda}$ and $\hat{\zeta}$.
The default value of these six parameters are shown in Table~\ref{tab:param_addi} in Appendix.
%
%
%
FedPG-BR uses unique parameters, including mini-batch size \(b\), global sampling steps \(N\), variance bound \(\sigma\), and confidence parameter \(\delta\). Detailed settings are in Table~\ref{tab:param_FedPG-BR} in Appendix. We assume the attacker has full knowledge of the FRL system unless stated otherwise. Results are presented on the Cart Pole dataset by default.
%
%
We compare our ensemble method with the non-ensemble approach. In the non-ensemble method, the server trains a single global model with all agents using a foundational aggregation rule from Section~\ref{base_agg}. In our ensemble method, agents are divided into \(K\) groups, each training a global policy with the same aggregation rule by default.



\subsection{Experimental Results} 

\myparatight{Normalized attack is effective against non-ensemble methods}
Fig.~\ref{Results_CartPole} shows the results of different defenses under various attacks on Cart Pole dataset.
The results on Lunar Lander and Inverted Pendulum datasets are shown in Fig.~\ref{Results_LunarLander} and Fig.~\ref{Results_InvertedPendulum} in Appendix, respectively.
%
%
Based on Fig.~\ref{Results_CartPole} and Figs.~\ref{Results_LunarLander}-\ref{Results_InvertedPendulum}, it is evident that our proposed Normalized attack successfully targets the non-ensemble methods. 
%
For instance, in the Lunar Lander dataset, our Normalized attack reduces the test reward of the Median to -33.3 in the non-ensemble setting, compared to a reward of 219.3 when all agents are benign.
%
Notably, our Normalized attack stands out as the sole method capable of substantially manipulating the non-ensemble FedPG-BR aggregation rule across all three datasets. For example, in the Cart Pole dataset, the test reward of non-ensemble-based FedPG-BR drops from 500 in the absence of an attack to 101.4 under our Normalized attack.
%
However, existing attacks such as Trim attack and Shejwalkar attack achieve unsatisfactory attack performance.
%
The reason is that the Trim attack solely takes into account each dimension of the policy update, neglecting the entirety of the update itself. Furthermore, the Shejwalkar attack ignores the direction of the policy update.
%




\myparatight{Our ensemble method is effective}%
%
%
From Fig.~\ref{Results_CartPole} and Figs.~\ref{Results_LunarLander}-\ref{Results_InvertedPendulum} (in Appendix), we observe that when all agents are benign, our ensemble framework achieves test rewards comparable to FedAvg without attacks across all datasets and Byzantine-robust aggregation rules, fulfilling the goal of “superior learning performance.” 
%
For example, in the Inverted Pendulum dataset, the Trimmed-mean rule within the ensemble framework achieves a test reward of 1000, matching FedAvg's performance without attacks. However, non-ensemble Byzantine-robust aggregation rules remain vulnerable to poisoning attacks, including our Normalized attack.
%
As shown in the figures, embedding these robust rules within our ensemble framework ensures defense against all considered attacks, achieving the “resilience” goal. For instance, in the Cart Pole dataset under the Normalized attack, FedPG-BR achieves a test reward of 101.4 in the non-ensemble setting but 500 within our ensemble framework. Similarly, for the Inverted Pendulum dataset, Trimmed-mean yields test rewards of 152.7 without ensemble but 1000 with it under the Random action attack. 
%
However, FedAvg, even within our ensemble framework, remains vulnerable to attacks due to its inherent lack of robustness.









\begin{figure*}[!t]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/stage_CartPole_mean_byzantine9.pdf}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/stage_CartPole_trim_byzantine9.pdf}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/stage_CartPole_median_byzantine9.pdf}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/stage_CartPole_FedPG-BR_byzantine9.pdf}}
	\caption{Different variants of our Normalized attack, where the Cart Pole dataset is considered.}
	\label{our_attack_diff_stage}
\end{figure*}






\myparatight{Impact of the fraction of malicious agents}
Fig.~\ref{fig:frac_of_mali} shows the impact of the fraction of malicious agents on the robustness of our ensemble method on Cart Pole dataset. 
From Fig.~\ref{fig:frac_of_mali}, we observe that when a large fraction of agents are malicious, our ensemble framework can still tolerate all the poisoning attacks across all robust aggregation rules. 
For example, when 40\% of agents are malicious, our ensemble method achieves similar test rewards with that of FedAvg without attack. 
%
However, as shown in Fig. \ref{Results_CartPole}, even when the fraction of malicious agents is 30\%, existing robust aggregation rules under non-ensemble setting could be easily poisoned



\myparatight{Impact of total number of agents}
Fig.~\ref{fig:num_of_mali} in Appendix shows the influence of varying total agent numbers on our ensemble method under various attacks, with the proportion of malicious agents set at 30\% and the overall number of agents ranging from 30 to 90.
The numbers of groups are set to 5, 7, 7, and 9 when the total agents are 30, 50, 70, and 90, respectively.
%
We observe that our ensemble method remains robust when the total number of agents varies.



\myparatight{Impact of number of groups}%
%
%
Fig.~\ref{fig:num_of_group_size} in Appendix shows the results of our ensemble method with different group numbers, with 30 agents, 30\% of which are malicious. When there is only one group, the ensemble method becomes equivalent to the non-ensemble approach. For three Byzantine-robust methods under various attacks, the test rewards match those of FedAvg without attack when the group sizes are 3, 5, or 7.






\begin{table}[htbp]
  \centering
    \small
  \caption{Different variants of our Normalized attack.}
    \addtolength{\tabcolsep}{-1.2pt}
    \begin{tabular}{|c|c|c|c|}
    \hline
          & Stage I     & Stage  II    & Normalization \\
    \hline
    Variant I   &  \cmark      &  \xmark     &  \cmark \\
    \hline
    Variant II    & \xmark      &   \cmark     & \cmark   \\
    \hline
    Variant III    &  \cmark       &  \cmark    & \xmark   \\
    \hline
    Variant IV (default) &  \cmark  &  \cmark   &  \cmark \\
    \hline
    \end{tabular}%
    \label{tab:attack_variant}%
  % \vspace{-0.12in}
\end{table}%





\begin{figure}[htbp]
    \centering
    \subfloat[Geometric median] {\includegraphics[width=0.5\linewidth]{figs/bar_CartPole_geomedian_byzantine9.pdf}}
    \subfloat[FLAME] {\includegraphics[width=0.5\linewidth]{figs/bar_CartPole_flame_byzantine9.pdf}}
    \caption{Results of geometric median and FLAME aggregation rules, where the Cart Pole dataset is considered.}
    \label{CartPole_others}
      % \vspace{-0.12in}
\end{figure}






\myparatight{Impact of different perturbation vectors}%
%
%
Our Normalized attack uses a perturbation vector \(\Delta\). Table~\ref{tab:perturbation_vector} in Appendix lists three types: ``uv'', ``std'', and ``sgn''. \(\text{Avg} \{ \bm{g}_i: i \in [n]\}\) calculates the average of the \(n\) local policy updates, and \(\text{std}\{ \bm{g}_i: i \in [n]\}\) computes their standard deviation. ``sgn'' is our default perturbation vector.
%
Fig.~\ref{sgn&uv&std} in Appendix shows the results of FedAvg, Trimmed-mean, Median, and FedPG-BR under Normalized attacks with different vectors. ``Normalized-uv'' refers to the Normalized attack using the ``uv'' vector. We observe that FedPG-BR in the non-ensemble setting is particularly vulnerable to the ``sgn'' vector.





\myparatight{Different variants of Normalized attack}%
%
Our Normalized attack consists of two stages, with policy updates normalized during optimization. Table~\ref{tab:attack_variant} outlines its variants. For example, Variant I skips Stage II, which optimizes the magnitude of malicious updates. Variant IV is our default attack. 
%
Fig.~\ref{our_attack_diff_stage} illustrates the results of different variants of our Normalized attack.
We observe from Fig.~\ref{our_attack_diff_stage} that Variant IV achieves the most effective attack performance overall.





\myparatight{Results of partial knowledge attack}%
%
%
By default, we assume the attacker knows all agents' policy updates. Here, we explore a more realistic scenario where the attacker only knows updates from malicious agents. In this partial knowledge attack, we use \(\text{AR} \{\bm{g}_j: j \in \mathcal{B}\}\) to estimate the pre-attack aggregated update, where \(\bm{g}_j\) is the update from malicious agent \(j\), and \(\mathcal{B}\) is the set of malicious agents. 
%
Fig.~\ref{Results_CartPole_partial} in Appendix shows the results of the Trim, Shejwalkar, and our Normalized attacks. Even with partial knowledge, Byzantine-robust rules in non-ensemble settings remain vulnerable to poisoning. For example, FedPG-BR achieves a test reward of 242.6 under our Normalized attack.






\myparatight{Initiate the attack in the middle of the training phase}%
%
%
We assume by default that the attacker targets the FRL system from the start of training. Here, we explore a scenario where the attack begins midway through training. In the Cart Pole dataset, each agent samples 5,000 trajectories during training. 
%
Fig.~\ref{fig:start_attack} in Appendix shows the results of FedPG-BR, Trimmed-mean, and Median in the non-ensemble setting. Results for the ensemble framework are omitted since it remains robust against all attacks, even if initiated from the start, as seen in Fig.~\ref{Results_CartPole}. 
%
From Fig.~\ref{fig:start_attack}, we observe that current robust aggregation methods in non-ensemble settings are still vulnerable to poisoning, even when the attack starts mid-training.






\myparatight{Results of heterogeneous environment}%
%
%
In this part, we explore a heterogeneous environment setting where two agents execute the same action at the same state but receive different rewards. In our experiments, we introduce some noise generated from Gaussian distribution $N(0,0.1)$ to the rewards to simulate the heterogeneous environment.
%
Fig.~\ref{Results_CartPole_non_iid} in Appendix presents the results. We observe that non-ensemble aggregation rules remain vulnerable to poisoning attacks in heterogeneous environments. For example, FedPG-BR achieves a test reward of less than 100 under our Normalized attack. However, our ensemble framework effectively defends against all considered attacks using robust aggregation rules.





\myparatight{Results of other foundational aggregation rules}%
%
Fig.~\ref{CartPole_others} shows results using geometric median~\cite{ChenPOMACS17} and FLAME~\cite{nguyen2022flame} aggregation rules on the Cart Pole dataset. 
Note that within our ensemble framework, the server still uses the majority vote (action space in the Cart Pole dataset is discrete) to select the action during the testing phase.
%
We observe that, in a non-ensemble setting, the geometric median and FLAME aggregation rules are susceptible to either existing poisoning attacks or our proposed Normalized attack. In contrast, our ensemble framework remains robust.





\myparatight{Results of our ensemble method when using other aggregation rules to combine the $K$ continuous actions}
In our proposed ensemble framework, the server employs the geometric median aggregation rule to select the subsequent action during the testing phase when the action space is continuous. In this context, we investigate a scenario where the continuous actions are aggregated by the FedAvg or Trimmed-mean aggregation rules during the testing phase within our ensemble framework.
The results are shown in Figs.~\ref{Results_InvertedPendulum_mean}-\ref{Results_InvertedPendulum_trim} in Appendix, where the Inverted Pendulum dataset is considered (with a continuous action space).
%
From Figs.~\ref{Results_InvertedPendulum_mean}-\ref{Results_InvertedPendulum_trim}, we observe that existing robust foundational aggregation rules like Trimmed-mean and Median are susceptible to poisoning attacks when our ensemble framework employs FedAvg or Trimmed-mean to predict the subsequent action in the testing phase. This vulnerability arises because FedAvg is not robust, and Trimmed-mean is a coordinate-wise aggregation rule, it only has the capability to filter out individual outlier parameters and fails to eliminate an entire policy update, even when detected as malicious.
%
%















