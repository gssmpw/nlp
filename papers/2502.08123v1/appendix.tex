% !TEX root = mainfile.tex

\appendix

\section{Appendix}




\begin{algorithm}[t]
	\caption{Training phase of our ensemble framework.}
	\label{our_alg_training}
	\begin{algorithmic}[1]
		\renewcommand{\algorithmicrequire}{\textbf{Input:}}
		\renewcommand{\algorithmicensure}{\textbf{Output:}}
		\Require Number of agents $n$; number of groups $K$; learning rate $\eta$; foundational aggregation rule $\text{AR}\{\cdot\}$; global training rounds $T$.
		\Ensure Global policies $\bm{\theta}_k^T$, $k \in [K]$. 
		\State Divide $n$ agents into $K$ disjoint groups.
		\State Initialize $\bm{\theta}_k^1$, $k \in [K]$.
		\For {$t = 1, 2, \cdots, T$}
		\For {each group $k \in [K]$ in parallel}
		\label{each_group_train}
		\State  The server sends the global policy $\bm{\theta}_k^t$ to all agents in group $k$.
		\label{each_group_train_server}
		\For {each agent $i \in n_k$ in parallel}
		\label{each_group_update}
		\State Updates $\bm{\theta}_{i}^t$ and sends $\bm{g}_{i}^t$ to the server.
		\EndFor
		\label{each_group_update_end}
		\State The server updates the global policy of group $k$ as $\bm{\theta}_k^{t+1} \leftarrow \bm{\theta}_k^t + \eta \cdot \text{AR} \{ \bm{g}_{i}^t: i \in n_k \}.$
		\label{each_group_update_server}
		\EndFor
		\label{each_group_agg}
		\EndFor
	\end{algorithmic}
\end{algorithm}





\begin{algorithm}[t]
	\caption{Testing phase of our ensemble framework.}
	\label{our_alg_testing}
	\begin{algorithmic}[1]
		\renewcommand{\algorithmicrequire}{\textbf{Input:}}
		\renewcommand{\algorithmicensure}{\textbf{Output:}}
		\Require State $s$, $K$ actions $F(s, \bm{\theta}_k^T)$, $k \in [K]$; action space $\mathcal{A}$. 
		\Ensure Action $\Phi(s)$.
		\If {$\mathcal{A}$ is discrete}
		\State Computes action frequency  for each action $a \in \mathcal{A}$ according to Eq.~(\ref{action_freq}).
		\State Obtains $\Phi(s)$ according to Eq.~(\ref{fina_action_discrete}).
		\label{alg2_discrete}
		%
		\ElsIf {$\mathcal{A}$ is continuous}
		\State Calculates $\Phi(s)$ according to Eq.~(\ref{fina_action_continuous}).   
		\label{alg2_continuous}
		\EndIf
	\end{algorithmic}
\end{algorithm}



\begin{table}[htbp]
    \centering
    \caption{Architecture of MLPs for three datasets.}
    \resizebox{\linewidth}{!}{
    % \renewcommand\arraystretch{1.5}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \multirow{2}{*}{Parameter} & \multicolumn{3}{c|}{Dataset} \\
       \cline{2-4}          & Cart Pole     & Lunar Lander   &     Inverted Pendulum  \\
        \hline
        Hidden weights & $16,16$ & $64,64$ & $64,64$ \\
        \hline
        Activation & RELU & Tanh & Tanh\\
        \hline
        Output activation & \multicolumn{3}{c|}{Tanh}\\
        \hline
    \end{tabular}
    }
    \label{tab:param_MLP}
\end{table}

\subsection{Proof of Theorem~\ref{theorem_1}} 
\label{sec:theorem_1_proof}









Given a test state $s$, the action frequencies for actions $x$ and $y$  when up to $n^{\prime}$ agents are malicious are represented as $v^{\prime}(s,x)$ and $v^{\prime}(s,y)$, respectively.
%
%
Under the worst-case condition, for a specific group, if malicious agents are present, the global policy learnt by the group might predict action $y$  instead of  $x$  at state $s$. That is, $v^{\prime}(s,x)$ will decrease by 1 and $v^{\prime}(s,y)$ will increase by 1 after the attack.
%
Moreover, given that up to $n^{\prime}$ agents can be malicious, a maximum of $n^{\prime}$ groups may include malicious agents.
Then we have that:
\begin{align}
\label{v_x_inequ}
v^{\prime}(s,x) \ge v(s,x) - n^{\prime}, \\
v^{\prime}(s,y) \le v(s,y) + n^{\prime}.
\label{v_y_inequ}
\end{align}


In our proposed ensemble approach, when the test state $s$ is given, if the prediction of action $x$ still holds, then either Condition I or Condition II must be true:
%
%
\begin{align}
\label{condition_I_inequ}
\text{Condition I: }& v^{\prime}(s,x) > v^{\prime}(s,y), \\
\text{Condition II: }& v^{\prime}(s,x) = v^{\prime}(s,y)  \text{ and } x<y,
\label{condition_II_inequ}
\end{align}
where $\text{Condition II}$ is true due to the assumption in Theorem~\ref{theorem_1} that if two actions possess the same action frequencies, the action with the smaller index is chosen.

Combining Eqs.~(\ref{v_x_inequ})-(\ref{condition_II_inequ}), we have that:
\begin{align}
n^{\prime} \le \left\lfloor \frac{v(s,x)-v(s,y) - \mathbbm{1}_{\{ y<x \}}}{2} \right\rfloor,
\end{align}
which completes the proof.









\subsection{Proof of Theorem~\ref{theorem_2}} 
\label{sec:theorem_2_proof}

Let $F^{\prime}(s, \bm{\theta}_1^T), F^{\prime}(s, \bm{\theta}_2^T),..., F^{\prime}(s, \bm{\theta}_K^T)$ be the set of $K$ actions after attack.
%
Since $\Phi(s)$ and $\Phi^{\prime}(s)$ are respectively the before-attack and after-attack aggregated policy updates, then $\Phi^{\prime}(s) - \Phi(s)$ is the geometric median of $K$ vectors $\{F^{\prime}(s, \bm{\theta}_k^T) - \Phi(s): k \in [K]\}$.
Based on Lemma~\ref{sec:appendix_lemma}, let $w$ be defined as $w=\max \left\{ \| F(s, \bm{\theta}_k^T) - \Phi(s) \|  : k \in [K] \right\}$, and with the condition $0< n^{\prime} < K/2$, one has that:
\begin{align}
 \left\| \Phi(s)  - \Phi^{\prime}(s)  \right\|  \leq \frac{2  w(K-n^{\prime})}{K-2n^{\prime}},
\end{align}
which completes the proof.



\subsection{Useful Technical Lemma} \label{sec:appendix_lemma}


\begin{lem}
	\label{lemma_1}
	Let's consider $v_1, \ldots, v_K$ to be $K$ vectors in a Hilbert space, let $v_*$ represent a $(1+\epsilon)$-approximation of their geometric median.
    This means that for $\epsilon \geq 0$,  we have $\sum_{k \in [K]} \|v_k -v_*\| \leq (1+\epsilon) \min_z \sum\nolimits_{k \in [K]} \|v_k - z\|$.
    Given any $r$ with the condition that $0< r < K/2$ and a real number $w$, if the following condition satisfies:
    \begin{align}
    K -r \le \sum_{k \in [K]} \mathbbm{1}_{\|v_k\| \leq w}.
     \end{align}
     
    Then one has:
	\begin{align}
	\|v_*\| \leq w \alpha  + \epsilon \beta, 
	\end{align}
	where $\alpha = \frac{2(K-r)}{K-2r}$, $\beta = \frac{\min_z \sum_{k \in [K]} \|v_k - z \|}{K-2r}$. Ideally, the geometric median sets $ \epsilon=0$.
\end{lem}
\begin{proof}
This lemma is taken directly from~\cite{minsker2015geometric,cohen2016geometric}, so we omit its proof here.
\end{proof}



\subsection{Datasets}
\label{sec:datasets_app}

	
	\myparatight{Cart Pole~\cite{barto1983neuronlike}} The Cart Pole environment is a simulation of a cart with a pole attached to it by a hinge. The cart can move along a horizontal track, and the pole can swing freely in the air. The goal is to balance the pole on the cart by applying forces to the left or right of the cart. The action space is a discrete space $\{0, 1\}$ representing the direction of the fixed force applied to the cart, where $0$ for pushing the cart to the left, and $1$ for pushing it to the right. A reward of +1 is added for every time step that the pole remains upright. The episode ends if the pole falls over more than 12 degrees from vertical, the episode length is greater than 500, or the cart moves more than 2.4 units from the center. Given that the maximum episode length is 500, the highest possible reward in this scenario should also be 500.
	
	\myparatight{Lunar Lander~\cite{duan2016benchmarking}}
	The Lunar Lander environment is a simulation of a rocket landing on the moon. The rocketâ€™s engines are controlled by choosing one of four actions: do nothing, fire left engine, fire main engine, or fire right engine.
	The action space, therefore, is a discrete space and can be represented as $\{0,1,2,3\}$.
	%
	The goal is to land safely on the landing pad without crashing or going out of bounds. 
	A reward is obtained for every step that the rocket is kept upright, and a penalty for using the engines. The environment is stochastic, meaning that the initial state of the rocket is random within a certain range.
	
	\myparatight{Inverted Pendulum~\cite{barto1983neuronlike}}
	The Inverted Pendulum is similar to the Cart Pole problem, which is another classic control problem where you have to balance a pole on a cart by applying forces to the left or right. Yet, it is different from the Cart Pole in several key aspects. First, the Inverted Pendulum is powered by the Mujoco physics simulator\cite{todorov2012mujoco}, which allows for more realistic and complex experiments, such as varying the effects of gravity. Second, the action space of the Inverted Pendulum is continuous.
	Thirdly, considering that the maximum episode duration is set at 1000, the utmost attainable reward for the Inverted Pendulum dataset is 1000.





\subsection{Compared Poisoning Attacks}
\label{sec:Compared_Poisoning_Attacks_app}

	
	\myparatight{Random action attack~\cite{fan2021fault}}
	Random action attack is a category of data poisoning attacks in which malicious agents intend to corrupt their local trajectories. In particular, every malicious agent chooses a random action regardless of the state.

	
	\myparatight{Random noise attack~\cite{fan2021fault}}
	Random noise attack is a kind of model poisoning attack. 
	In each training round, a malicious agent draws each coordinate of its policy update from an isotropic Gaussian distribution with a mean of 0 and a variance of 1,000. 
	
	\myparatight{Trim attack~\cite{fang2020local}}
	This attack operates under the assumption that the server uses Trimmed-mean~\cite{yin2018byzantine} or Median~\cite{yin2018byzantine} as its aggregation rule, to combine the local policy updates sent from agents.
	%
	Trim attack considers each dimension of policy update independently.
	%
	Specifically, malicious agents intentionally manipulate their policy updates so that the aggregated policy update post-attack differs significantly from the one before the attack, for each dimension of policy updates.
	
	

	
	
	\myparatight{Shejwalkar attack~\cite{shejwalkar2021manipulating}}
	In the Shejwalkar attack, the attacker designs malicious local policy updates with the intent to enlarge the distance between the aggregated policy update before the attack and the one after the attack.
	

	
	



\subsection{Foundational Aggregation Rules}
\label{sec:Aggregation_Rules_app}


	\myparatight{FedAvg~\cite{mcmahan2017communication}}
	In FedAvg, once the server receives local policy updates from all agents, it calculates the global policy update by taking the average of these updates.
	
	
	
	\myparatight{Coordinate-wise trimmed mean (Trimmed-mean)~\cite{yin2018byzantine}}
	Upon receiving $n$ local policy updates, the server first discards the largest $c$ and smallest $c$ elements for each dimension, then computing the average of the remaining values, where $c$ is the trim parameter.

	
	\myparatight{Coordinate-wise median (Median)~\cite{yin2018byzantine}}
	In the Median aggregation rule, the server determines the aggregated global policy update by computing the coordinate-wise median from all received local policy updates.

	
	
	\myparatight{Geometric median~\cite{ChenPOMACS17}}
	For the geometric median aggregation rule, the server computes the aggregated policy update by taking the geometric median of received local policy updates from all agents.
	

	
	\myparatight{FLAME~\cite{nguyen2022flame}}
	The FLAME method starts by computing the cosine similarity among agents' local policy updates. It then employs clustering methods like HDBSCAN~\cite{campello2013density} to identify potentially malicious updates. To further reduce the impacts of poisoning attacks, it implements an adaptive clipping mechanism to adjust the local updates. Finally, the server adds noise to the aggregated policy update to obtain the final global update.
	


	\myparatight{FedPG-BR~\cite{fan2021fault}} 
	In the FedPG-BR aggregation rule, the server first calculates the vector median of all received local policy updates. A local policy update is deemed malicious if it fars from the calculated vector median. To additionally minimize the policy update variance, the server independently samples some trajectories to compute a server policy update. Subsequently, the server leverages the Stochastically Controlled Stochastic Gradient (SCSG)~\cite{lei2017less} framework to update the global policy.



\begin{table}[htbp]
    \centering
    \caption{Additional parameter settings for three datasets.}
    \resizebox{\linewidth}{!}{
    % \renewcommand\arraystretch{1.5}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \multirow{2}{*}{Parameter} & \multicolumn{3}{c|}{Dataset} \\
       \cline{2-4}          & Cart Pole     & Lunar Lander   &     Inverted Pendulum  \\
        \hline
        $\gamma$ & 0.999 & 0.99 & 0.995 \\
        \hline
        $H$ & 500 & 1000 & 1000 \\
        \hline
        $\Im$& \multicolumn{3}{c|}{0}\\
         \hline
        $ \Delta$ & \multicolumn{3}{c|}{$-\text{sign}(\text{Avg} \{ \bm{g}_i: i \in [n]\})$ }\\
        \hline
        $\hat{\lambda}$ & \makecell[c]{0.83 (decays at\\each iteration\\with factor $1/3$)} & \makecell[c]{1 (decays at\\each iteration\\with factor $1/3$)} & \makecell[c]{0.83 (decays at\\each iteration\\with factor $1/3$)} \\
        \hline
        $\hat{\zeta}$ & \makecell[c]{0.03 (decays at\\each iteration\\with factor $1/3$)} & \makecell[c]{0.02 (decays at\\each iteration\\with factor $1/3$)} & \makecell[c]{0.2 (decays at\\each iteration\\with factor $1/3$)} \\
        \hline
    \end{tabular}
    }
    \label{tab:param_addi}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{Parameter settings of FedPG-BR for three datasets.}
    \resizebox{\linewidth}{!}{
    % \renewcommand\arraystretch{1.5}
    \begin{tabular}{|c|c|c|c|}
        \hline
         \multirow{2}{*}{Parameter} & \multicolumn{3}{c|}{Dataset} \\
       \cline{2-4}          & Cart Pole     & Lunar Lander   &     Inverted Pendulum  \\
        \hline
        $b$ & 4 & 8 & 12 \\
        \hline
        $N$ & \multicolumn{3}{c|}{$N \sim Geom(\frac{B}{B+b})$}\\
        \hline
        $\sigma$ & 0.06 & 0.07 & 0.25\\
        \hline
        $\delta$ & 0.6 & 0.6 & 0.6 \\
        \hline
    \end{tabular}
    }
    \label{tab:param_FedPG-BR}
\end{table}



\begin{table}[htbp]
  \centering
  % \small
  % \addtolength{\tabcolsep}{-5.7pt}
\addtolength{\tabcolsep}{-3.7pt}
  \caption{Different perturbation vector $\Delta$.}
    \begin{tabular}{|c|c|c|c|}
    \hline
    & uv     & std          & sgn (default)     \\
    \hline
    $\Delta$       &  $ -  \frac{{\text{Avg}} \{ \bm{g}_i: i \in [n]\} }{\left\|{\text{Avg}} \{ \bm{g}_i: i \in [n]\} \right\|} $     &  $-\text{std}\{ \bm{g}_i: i \in [n]\}$  & $-\text{sign}(\text{Avg} \{ \bm{g}_i: i \in [n]\})$   \\
    \hline
    \end{tabular}%
      \label{tab:perturbation_vector}%
\end{table}%



\begin{figure*}[!t]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/bar_LunarLander_mean_byzantine9}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/bar_LunarLander_trim_byzantine9}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/bar_LunarLander_median_byzantine9}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/bar_LunarLander_FedPG-BR_byzantine9}}
	\caption{Results on Lunar Lander dataset.}
	\label{Results_LunarLander}
\end{figure*}



\begin{figure*}[!t]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_mean_byzantine9}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_trim_byzantine9}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_median_byzantine9}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_FedPG-BR_byzantine9}}
	\caption{Results on Inverted Pendulum dataset.}
	\label{Results_InvertedPendulum}
\end{figure*}





\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{figs/FRLCert_client_size.pdf}
	\caption{Impact of the total number of agents on our ensemble method, where the Cart Pole dataset is considered.}
	\label{fig:num_of_mali}
\end{figure*}



\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{figs/FRLCert_group_size.pdf}
	\caption{Impact of the number of groups on our ensemble method, where the Cart Pole dataset is considered.}
	\label{fig:num_of_group_size}
\end{figure*}



\begin{figure*}[!t]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/sgn_uv_std_CartPole_mean_byzantine9.pdf}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/sgn_uv_std_CartPole_trim_byzantine9.pdf}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/sgn_uv_std_CartPole_median_byzantine9.pdf}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/sgn_uv_std_CartPole_FedPG-BR_byzantine9.pdf}}
	\caption{Different perturbation vectors on our Normalized attack, where the Cart Pole dataset is considered.}
	\label{sgn&uv&std}
\end{figure*}






\begin{figure*}[!t]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/partial_bar_CartPole_mean_byzantine9.pdf}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/partial_bar_CartPole_trim_byzantine9.pdf}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/partial_bar_CartPole_median_byzantine9.pdf}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/partial_bar_CartPole_FedPG-BR_byzantine9.pdf}}
	\caption{Results of partial knowledge attack, where the Cart Pole dataset is considered.}
	\label{Results_CartPole_partial}
\end{figure*}




\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figs/FRLCert_attack_time.pdf}
    \caption{Impact of starting to attack after sampling a certain number of trajectories on different non-ensemble methods, where the Cart Pole dataset is considered.}
    \label{fig:start_attack}
\end{figure*}




\begin{figure*}[!t]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_mean_byzantine9_non_iid.pdf}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_trim_byzantine9_non_iid.pdf}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_median_byzantine9_non_iid.pdf}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/bar_CartPole_FedPG-BR_byzantine9_non_iid.pdf}}
	\caption{Results of heterogeneous environment, where the Cart Pole dataset is considered.}
	\label{Results_CartPole_non_iid}
\end{figure*}



\begin{figure*}[htbp]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_mean_byzantine9_mean.pdf}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_trim_byzantine9_mean.pdf}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_median_byzantine9_mean.pdf}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_FedPG-BR_byzantine9_mean.pdf}}
	\caption{Results of our ensemble method, where the continuous actions are aggregated by the FedAvg aggregation rule in the testing phase. The Inverted Pendulum dataset is considered.}
	\label{Results_InvertedPendulum_mean}
\end{figure*}



\begin{figure*}[htbp]
	\centering
	\subfloat[FedAvg]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_mean_byzantine9_trim.pdf}}
	\subfloat[Trimmed-mean]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_trim_byzantine9_trim.pdf}} 
	\subfloat[Median]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_median_byzantine9_trim.pdf}}
	\subfloat[FedPG-BR]{\includegraphics[width=0.25 \textwidth]{figs/bar_InvertedPendulum_FedPG-BR_byzantine9_trim.pdf}}
	\caption{Results of our ensemble method, where the continuous actions are aggregated by the Trimmed-mean aggregation rule in the testing phase. The Inverted Pendulum dataset is considered.}
	\label{Results_InvertedPendulum_trim}
\end{figure*}

