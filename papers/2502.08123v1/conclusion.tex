% !TEX root = mainfile.tex

% \section{Discussion and Limitations}

\section{Conclusion, Limitations, and Future Work}

% In this paper, we proposed the first model poisoning attacks to Byzantine-robust FRL. Extensively experimental results showed that our proposed Normalized attack could significantly reduce the test reward of non-ensemble based Byzantine-robust FRL method. We further proposed a novel ensemble method this is provably resistant against poisoning attacks under some mild assumptions. 


We introduced the first model poisoning attacks on Byzantine-robust FRL. Rather than increasing the distance between the aggregated policy updates before and after the attacks, our introduced Normalized attack strives to amplify the angular deviation between the two updates. Additionally, we proposed a unique ensemble method that is provably resistant to poisoning attacks under some mild assumptions. Comprehensive experimental findings demonstrated that our Normalized attack can significantly corrupt Byzantine-robust aggregation methods in non-ensemble configuration, and our ensemble approach effectively safeguards against poisoning attacks.


A limitation of our work is that our Normalized attack requires the attacker to be aware of the server's aggregation rule. An intriguing avenue for future research would be to develop new attacks that do not necessitate such information. 
Our Normalized attack is limited to untargeted poisoning attacks, another interesting future work is to study targeted poisoning attacks~\cite{bagdasaryan2020backdoor,wang2020attack,xie2019dba} to FRL.
Additionally, investigating security issues in multi-agent reinforcement learning~\cite{tan1993multi,bucsoniu2010multi,vinyals2019grandmaster,zhang2018fully,lin2020robustness,fang2024hardness} would be a fruitful area for further exploration.



\begin{acks}
We thank the anonymous reviewers for their comments. 
This work was supported in part by NSF grant No. 2131859, 2125977, 2112562, 1937787, and ARO grant No. W911NF2110182.
\end{acks}