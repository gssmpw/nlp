% !TEX root = mainfile.tex

\section{Problem Setting}


\myparatight{Threat model}%
%
%
We adopt the threat model from~\cite{fan2021fault}, where an attacker controls some malicious agents. These agents may poison their training trajectories or send random policy updates to the server. The attacker's goal is to disrupt the global policyâ€™s convergence or push it toward a bad optimum. 
%
In a full knowledge attack, the attacker knows all agents' policy updates and the server's aggregation rule. In a partial knowledge attack, the attacker only knows the malicious agents' updates and the aggregation rule.




\myparatight{Defense objectives}We aim to propose a method that achieves the following two goals. I) Superior learning performance: In non-adversarial settings, the method should perform as well as FedAvg, achieving comparable test rewards when all agents are benign. 
II) Resilience: It should defend against both data and model poisoning attacks. Even under attacks, the final global policy should maintain test rewards similar to those of FedAvg in attack-free scenarios.

