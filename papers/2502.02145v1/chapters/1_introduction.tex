%!TeX spellcheck = en_US
% !TeX root = ../main.tex

\section{Introduction}
\label{sec:introduction}
The autonomy of vehicles has advanced rapidly in recent years, reaching a level where human intervention is barely or not at all required in certain Operational Design Domains (ODDs). Leading the way are vehicle manufacturers such as Mercedes and BMW, which offer production vehicle at SAE Level 3, depending on the system's design. Additionally, companies like Waymo have introduced fully autonomous robotaxi services operating at SAE Level 4 in selected ODDs, showcasing the potential of driverless technology in urban environments. This progress is largely attributed to developing and validating highly reliable Automated Driving Systems (ADS). Traditionally, validation has been conducted in real-world test environments, such as on-road testing \cite{khan2023safety}. However, uncertainties remain regarding whether these ADS are sufficiently safe and robust in corner cases or safety-critical situations\cite{ding2023survey}.

Many researchers and companies are focusing on scenario-based approaches to testing ADS, not only because it is a cost-effective method for simulating realistic driving conditions \cite{riedmaier2020survey}, but also because distinct safety-critical scenarios can effectively simulate corner cases that are either rare or not captured in real-world data \cite{menzel2018scenarios}. However, determining whether these scenarios are sufficiently safety-critical is a crucial challenge. To address this, it is essential to consider safety-critical metrics \cite{vogel2003comparison}, such as Time-to-Collision (TTC), which are instrumental in identifying safety-critical situation based on quantitative risk assessment by using temporal proximity.

Current research has identified a range of proximity metrics, which can be classified into temporal and non-temporal indicators \cite{mahmud2017application}. 
%such as distance, deceleration, and others. 
Generally, these metrics are calculated by test engineers to assess whether a generated scenario is safety-critical. However, with the release of OpenAI's ChatGPT---a powerful AI chatbot---the outstanding capabilities of LLMs have emerged in tasks such as text generation, summarization, and reasoning.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.47\textwidth]{figures/Scenario.jpg} 
    \caption{Illustrative example of a safety-critical driving scenario and the use of LLMs for driving scenario analysis.}
    \label{fig:scenario} % Optional: for referencing the figure
\end{figure}

Given that LLMs are general-purpose pretrained transformer models \cite{vaswani2017attention} that have learned vast amounts of information, we conjecture that they can be effectively leveraged to analyze the safety-critical aspects of autonomous driving scenarios in Figure~\ref{fig:scenario}. To validate our proposed framework, we conduct an empirical evaluation to assess the performance of three prominent LLMsâ€”GPT-4o mini, GPT-4o\cite{achiam2023gpt}, Gemini-1.5 Pro\cite{team2023gemini}---in analyzing the safety criticality of driving scenarios. %Our validation is carried out on a randomly selected set of realistic recorded scenarios from CommonRoad, an open-source benchmark for evaluating and comparing motion planners for autonomous vehicles. In this way, we got 100 collision scenarios, which means by using a high-performance Frenetix planner as the motion planner, the ego car still collides with obstacles.

Our results show that,
by processing 100 safety-critical scenarios with collisions between an ego car and obstalces, the LLMs can assess the safety criticality of each scenario. By employing different prompt templates, the performance varies across different LLM models.
Using Cartesian coordinates to describe the scenarios in the prompt templates, all models have less than 25\% accuracy in identifying the index (ID) of the obstacle that collides with the ego car. With a Frenet coordinate template, the accuracy improves to around 75\%. Finally, using a prompt template based on safety-critical metrics, we got more than 90 \% accuracy, which is quite close to a human expert analysis.

In summary, this paper makes three key contributions:
\begin{itemize} 
    \item We propose a framework integrating large language models as evaluation modules to assess the safety criticality of autonomous driving scenarios. Our scenarios are generated with the CommonRoad open framework\cite{althoff2017commonroad}. 
    \item By specializing the prompt formulations to be fed to the LLMs, we enhance the LLMs' performance in correctly analyzing the safety-criticality of scenarios. 
    \item Leveraging the reasoning capabilities of LLMs, our framework outputs a feedback action to modify an existing non-critical scenario and make it safety-critical. Specifically, we use an adversarial method to change the current positions and trajectories of certain obstacles to make them safety-critical for the ego vehicle.
    In this way, our framework can generate new corner-case benchmarks to test motion planning algorithms in the CommonRoad environment. 
\end{itemize}

