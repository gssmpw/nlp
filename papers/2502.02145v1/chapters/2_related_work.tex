%!TeX spellcheck = en_US
% !TeX root = ../main.tex

\section{Related Work}
\label{sec:relatedwork}
Recently, many publications have emerged on scenario-based testing, focusing on generating various safety-critical scenarios for evaluation of ADS. By leveraging information from the real collected datasets, the data-driven method is proposed to generate a scenario that reflects reality and improves the diversity of the scenario to avoid the risk of over-fitting by using Bayesian Networks\cite{wheeler2016factor} and Deep Generative Modles\cite{ding2018new}. The adversarial generation method is used to generate scenarios more efficiently since it actively creates risky scenarios by attacking the ADS. Additionally, differentiable renders would be used to generate the static scenarios\cite{jain2019analyzing}, and dynamic scenario generation could be usually formatted in an Reinforcement Learning (RL) framework \cite{sun2021corner}. Meanwhile, to improve the controllability of specific scenarios, a knowledge-based approach is proposed based on pre-defined rules with domain expertise\cite{rana2021building} or knowledge-guided learning like combining the feasible constraints with adversarial policy development\cite{cao2023robust} based on RL framework.

With the increasing demand for LLMs' powerful functions like reasoning and understanding ability, researchers have begun applying them to systems and applications related to autonomous driving in the last two years, such as visual perception \cite{wu2023language}, motion planning\cite{wang2024dualad}, vehicle control\cite{xu2024drivegpt4} etc. In the context of LLMs-based driving scenario generation, it could be classified into microscopical and macroscopical categories depending on the simulator used, such as CARLA to evaluate specific driving behaviors of ego vehicle and SUMO to produce large-scale traffic scenarios. In Chatscene \cite{zhang2024chatscene} and TTSG\cite{ruan2024traffic}, the pipeline of text description by using LLMs with prompt techniques to generate safety-critical scenarios in CARLA was proposed, especially in Chatscene \cite{zhang2024chatscene} they use the newly generated scenario to train and improve the control algorithm of the ego vehicle. For the large-scale scenario generation, ChatSUMO \cite{li2024chatsumo} and OmniTester \cite{lu2024multimodal} are proposed to generate the accurate urban simulation by using the text description. Overall, the above publication analyzed the domain-specific language for each simulator, then used the template-based method and chain of thought in prompts to improve the performance of LLMs-based scenario generation. After that, they used specific metrics to evaluate whether the generated scenario fulfilled the demand like rarety, diversity, safety criticality and so on.
\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figures/framework.jpg} 
    \caption{Overview of the proposed framework based on LLMs to analysis the safety criticality of CommonRoad scenarios.}
    \label{fig:framework} % Optional: for referencing the figure
\end{figure*}

After driving scenarios are generated using the above classical and LLMs-based methodes, several publications have recently addressed this challenging topic safety-critical generated scenarios identification. In \cite{song2023critical}, safety-critical scenarios are defined as scenarios in which the autonomous vehicle causes or nearly causes a collision. Safety metrics like time to collision, time to brake, required deceleration, and new traffic
quality metrics were combined for the identification of safety-critical scenarios in  \cite{hallerbach2018simulation}. Until now, after calculation for the safety metrics, scenarios would be identified by human experts or test engineers. In considering LLMs-based scenario analysis, LLMs are first used to empirically identify the realistic driving scenarios in \cite{wu2024reality}. Also, in the OmniTester \cite{lu2024multimodal}, the researcher uses LLMs as an evaluator to evaluate the accuracy of the generated scenario compared to the text description. 

Overall, little attention has been paid to identifying safety-critical scenarios using LLMs, as well as generating such scenarios through LLM-based adversarial methods, which can efficiently provide more corner-case benchmarks.
