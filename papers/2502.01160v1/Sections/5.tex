\section{Experiments}
\label{sec:Experiments}

To evaluate the performance of PSE, we implemented a prototype in C++ that employs ExactMC as the model counter.
We extended the benchmarks from the experiments of Golia et al.~\cite{golia2022scalable} to conduct a more comprehensive evaluation of the performance of PSE. 
%We perform an extensive experimental evaluation over a comprehensive set of 441 benchmarks, including the QIF  benchmarks~\cite{fremont2017maximum}, combinatorial circuits (including ISCAS'85 and EPFL)~\cite{amaru2015epfl,brglez1989combinational}, plan recognition~\cite{soos2020tinted}, bit-blasted versions of SMTLIB benchmarks~\cite{sharma2019ganak}, and QBFEval competitions~\cite{golia2022scalable}. %~\cite{qbfeval2017, qbfeval2018}. 
We perform an extensive experimental evaluation over a comprehensive set of 441 benchmarks, which encompass diverse categories. These categories involve QIF benchmarks~\cite{fremont2017maximum}, plan recognition~\cite{soos2020tinted}, bit-blasted versions of SMTLIB benchmarks~\cite{sharma2019ganak}, and QBFEval competitions~\cite{golia2022scalable}. Among them, the combinatorial circuits category further includes well-known benchmarks like ISCAS'85 and EPFL~\cite{amaru2015epfl,brglez1989combinational}.
All experiments were run on a computer with Intel(R) Core(TM) i9-10920X CPU @ 3.50GHz and 32GB RAM.
Each instance was run on a single core with a timeout of 3000 seconds and 8GB memory.

Through our evaluations and analysis, we sought to answer the following research questions:
\begin{itemize}
	\item \textbf{RQ1:} How does the runtime performance of PSE compare to the state-of-the-art Shannon entropy tools with (probabilistic) accuracy guarantee?
	\item \textbf{RQ2:} How do the utilized methods impact the runtime performance of PSE? 
\end{itemize}

Golia et al.~\cite{golia2022scalable} have already demonstrated that their probably approximately correct tool EntropyEstimation is significantly more efficient than the state-of-the-art precise Shannon entropy tools. 
Due to space limit, we only compare with EntropyEstimation, and our detailed experimental comparison with the state-of-the-art precise tools is presented in the appendix.
We remark that PSE significantly outperforms the precise baseline (the baseline was able to solve only 18 benchmarks, whereas PSE solved 329 benchmarks). 
This marked improvement is attributed to the linear entropy computation capability of \ADDAND and the effectiveness of various strategies employed in PSE.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{figures/PSEvsEntropyEstimation_scatter.pdf}
	\caption{Scatter Plot of the running Time Comparison between PSE and EntropyEstimation.
	}
	\label{figure:scatter}
\end{figure} 

\subsection{Comparison with Shannon entropy estimation tool}


We compare PSE with EntropyEstimation, the current state-of-the-art Shannon entropy estimation tool on 441 instances. 
Table \ref{table:2} shows the performance of PSE and EntropyEstimation~\cite{golia2022scalable} in entropy computing.


\begin{comment}
	\begin{table}[!ht]
		\centering
		\renewcommand{\arraystretch}{1.2}
		% 调整列格式，让数值列右对齐
		\begin{tabularx}{\linewidth}{>{\centering\arraybackslash}c *{3}{@{\hspace{1pt}}>{\raggedleft\arraybackslash}X} >{\raggedleft\arraybackslash}X}
			\toprule
			\multirow{2}{*}{tool}  & \multicolumn{3}{c}{Instances Solved} & \multirow{2}{*}{PAR-2 score} \\
			% 子表头右对齐
			\cline{2-4}
			& Unique & Fastest & Total \\ 
			\midrule
			EntropyEstimation & 2 & 0 & 274 & 2421.46 \\
			PSE (ours) & \textbf{57} & \textbf{272} & \textbf{329} & \textbf{1531.56} \\
			\bottomrule
		\end{tabularx}
		\caption{Detailed performance comparison of PSE and EntropyEstimation. Unique represents the number of instances that can only be solved by a specific tool. Fastest represents the number of instances that a tool solves with the shortest time.}
		\label{table:2}
	\end{table}
	
\end{comment}

\begin{table}[!ht]
	\centering
	\renewcommand{\arraystretch}{1.2}
	% 减小字号
	\small
	% 使用固定宽度列
	\begin{tabular}{c *{3}{@{\hspace{9pt}}r} r}
		\toprule
		\multirow{2}{*}{tool}  
		% 缩写表头
		& \multicolumn{3}{c}{Solved Instances} 
		& \multirow{2}{*}{PAR-2 score} \\
		\cline{2-4}
		& Unique & Fastest & Total \\ 
		\midrule
		EntropyEstimation & 2 & 0 & 274 & 2421.46 \\
		PSE (ours) & \textbf{57} & \textbf{272} & \textbf{329} & \textbf{1531.56} \\
		\bottomrule
	\end{tabular}
	\caption{Detailed performance comparison of PSE and EntropyEstimation. Unique represents the number of instances that can only be solved by a specific tool. Fastest represents the number of instances that a tool solves with the shortest time.}
	\label{table:2}
\end{table}



\begin{comment}
	\begin{figure}[htbp]
		\centering
		\includegraphics[width=\linewidth]{figures/PSEvsEntropyEstimation.pdf}
		\caption{Cactus plot comparing the running time of PSE and EntropyEstimation.
		}
		\label{figure:2}
	\end{figure} 
\end{comment}





Table \ref{table:2} shows that, among the 441 instances tested and within the time limit of 3000 seconds, our tool PSE successfully solves 55 more instances than EntropyEstimation, indicating overall superior performance.
For the instances where both PSE and EntropyEstimation successfully solved within the given time limit, PSE demonstrates a shorter computation time and a substantially lower average PAR-2~\footnote{The average PAR-2 scoring scheme gives a penalized average runtime, assigning a runtime of two times the time limit for each benchmark that the tool fails to solve} score than EntropyEstimation.
More intuitively,  among all the benchmarks that both PSE and EntropyEstimation are capable of solving, in 98\% of those benchmarks, the efficiency of PSE surpasses that of EntropyEstimation by a margin of at least ten times.
For all the benchmarks where PSE and EntropyEstimation did not timeout and took more than 0.1 seconds, the mean speedup is 506.62, which indicates an improvement of more than two orders of magnitude. 
For the specific performance, please refer to the figure \ref{figure:scatter}.
%Figure \ref{figure:2} shows the cactus plot of runtime for PSE and EntropyEstimation, where the $x$-axis represents the number of benchmarks and the $y$-axis represents the runtime.
The results clearly indicate that PSE outperforms EntropyEstimation in the majority of instances. This validates a positive answer to \textbf{RQ1}.
We remark that EntropyEstimation is an estimation tool for Shannon entropy with probabilistic approximately correct results \cite{golia2022scalable}.
PSE consistently performs better than a state-of-the-art entropy estimator across most instances, highlighting that our methods significantly enhance the scalability of precise Shannon entropy computation.



%Meanwhile, we identified ten instances where PSE timed out while EntropyEstimation was able to solve within the time limit.
%Our experiments showed that, in cases where PSE was unable to solve the problem, the number of model counting queries escalated to an order of magnitude of ten million, and the entropy was still not computed.
%This suggests a potential bottleneck in the computation of precise Shannon entropy. 
%More sophisticated techniques are required to accurately compute the entropy for these challenging instances.
%We propose that improvements in pre-processing techniques and more effective variable heuristics for entropy computation could represent key breakthroughs.



\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{figures/PSE_Configuration.pdf}
	\caption{Cactus plot comparing different methods.}
	\label{figure:3}
\end{figure} 




\subsection{Impact of algorithmic configurations}
To better verify the effectiveness of the PSE methods and answer \textbf{RQ2}, we conducted a comparative study on all the utilized methods, including methods for the $Y$-stage: \textsf{Conjunctive Decomposition}, \textsf{YCache}, \textsf{Pre}, variable decision heuristics(\textsf{minfill}, \textsf{DLCP}, \textsf{SharpSAT-TD heuristic}, \textsf{VSADS}), and methods for the $X$-stage: \textsf{XCache} and \textsf{ConditionedCounting}.
In accordance with the principle of control variables, we conducted ablation experiments to evaluate the effectiveness of each method, ensuring that each experiment differed from the PSE tool by only one method.
The cactus plot for the different methods is shown in Figure \ref{figure:3}, where PSE represents our tool. 
PSE-wo-Decomposition indicates that the \textsf{ConjunctiveDecomposition} method is disabled in PSE, which means that its corresponding trace is ADD.
PSE-wo-Pre means that \textsf{Pre} is turned off in PSE.
PSE-ConditionedCounting indicates that PSE employed the \textsf{ConditionedCounting} method rather than \textsf{SharedCounting} in the $X$-stage.
PSE-wo-XCache indicates that the caching method is turned off in PSE in the $X$-stage. 
PSE-wo-YCache indicates that the caching method is turned off in PSE in the $Y$-stage.
PSE-dynamic-SharpSAT-TD means that PSE replaces the \textsf{minfill} static variable order with the dynamic variable order: the variable decision-making heuristic method of SharpSAT-TD (all other configurations are the same as in PSE, only the variable decision-making heuristic is different).
Similarly, PSE-dynamic-DLCP and PSE-dynamic-VSADS respectively indicate the selection of dynamic heuristic \textsf{DLCP} and \textsf{VSADS}.

%As can be seen from the experimental results, the power of implied literal is very strong. 
%The effect of caching is also significant, as has been demonstrated in previous studies of knowledge compilation.
%Although the effect of preprocessing is not very significant, it can still increase the number of instances solved.
The experimental results highlight the significant effects of conjunctive decomposition.
Caching also demonstrates significant benefits, consistent with findings from previous studies on knowledge compilation. 
It can also be clearly observed that \textsf{Pre} improves the efficiency of PSE.
Among the heuristic strategies, it is evident that \textsf{minfill} performs the best.
In the technique of the $X$-stage, the \textsf{ConditionedCounting} method performs better than \textsf{SharedCounting} without \textsf{XCache}, but not as well as the \textsf{SharedCounting} method.
This comparative experiment indicates that the shared component caching is quite effective.
The \textsf{ConditionedCounting} method's major advantage is its linear time complexity~\cite{lai2017new}. However, a notable drawback is the requirement to construct an \ADDAND based on a static variable order, which can introduce considerable time overhead for more complex problems. % ?
Although the \textsf{ConditionedCounting} method is not the most effective, we believe it is still a promising and scalable method. 
In cases where an \ADDAND can be efficiently constructed based on a static variable order, the \textsf{ConditionedCounting} method may be more effective than the \textsf{SharedCounting} method, especially when modeling counting in the $X$-stage is particularly challenging.
Finally, PSE utilizes the \textsf{SharedCounting} strategy in the $X$-stage, and incorporates  \textsf{ConjunctiveDecomposition}, \textsf{YCache}, \textsf{Pre}, and the \textsf{minfill} heuristic method in the $Y$-stage.
	



