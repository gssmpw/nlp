\section{Related Work}
\subsection{Classical Volume Reconstruction}

Classical Volume Reconstruction is a method used primarily in computerized tomography or medical imaging to construct a 3D image from a series of 2D cross-sectional images. This is often performed to visualize certain bodily structures. Within CT imaging, data is acquired by projecting X-rays through the body from multiple different angles. Detectors measure the absorption of the X-rays as they pass through different tissues. The data collected from these projections is then used to generate a series of 2D cross-sectional images that represent the internal structures of the measured body from multiple different depths. 

Classical Volume Reconstruction utilizes filtered back projection (FBP) to construct a 3D image using the newly generated series. FBP applies a series of filters to the raw data and then back-projects this into the form of a 3D image. Back-projection is the process of tracing the intensity values of the X-rays measured by the detectors along their path through the object ____. Each 3D pixel, known as a voxel, is then assigned an intensity value by summing the contributions of each projection that passes the voxel. Once the 3D volume is constructed, it may be visualized and manipulated using volume rendering techniques.  


\subsection{Neural Volume Reconstruction}

Neural Volume Reconstruction leverages the power of deep learning techniques for better image quality, faster reconstruction times, and the ability to handle more complicated reconstructive tasks. Similar to Classical Volume Reconstruction, neural volume reconstruction begins by acquiring 2D slices of a 3D object using image modalities such as CT, MRI, or other tomographic techniques. Following data acquisition, large datasets are constructed which contain subsets of 2D slices and their corresponding high-quality 3D volumes. Prior to training, datasets may undergo preprocessing steps such as normalization, cropping, or resampling to ensure consistency and compatibility with the neural network architecture. Data augmentation techniques such as rotation, translation, scaling, or adding noise may also be applied to increase the diversity of the training data and improve the generalization capability of the model.

A deep neural network architecture is then designed and trained to perform the task of reconstructing these volumes using the 2D slices. Convolutional Neural Networks (CNNs) are commonly used due to their ability to learn complex patterns and relationships within the data. During training, the neural network learns to map the input 2D projection images to their corresponding 3D volumes. The network also adjusts its internal parameters (such as weights/biases) through an optimization process, which minimizes the difference between the predicted 3D volumes and the ground truth volumes from the training dataset ____. A ground truth volume here is the ideal or reference 3D volume that most accurately and completely represents our given object. During the training and evaluation of a reconstruction algorithm, reconstructed volumes are compared to the ground truth volume to assess their accuracy and fidelity. Metrics such as structural similarity index (SSI), mean squared error (MSE), or visual inspection may be used to quantify the similarity between the reconstructed and ground truth volumes.

Once training has been completed, the neural network may be deployed for inference, where it takes new 2D projection images as input and reconstructs an original 3D volume. Along with the advantage of improved image quality and higher potential speeds, the training of the neural network enables the handling of more challenging reconstruction tasks such as noisy images or inputs with incomplete data ____.

\subsection{Accelerating NeRF}

Neural radiance fields (NeRFs) ____ represent a newer approach in computer graphics and computer vision for generating realistic 3D scenes. These models capture the volumetric properties of a scene and predict the color and intensity of light at any point in space. NeRFs are typically trained on pairs of 3D points and corresponding observed RGB colors from known viewpoints. 

During training, the neural network learns to approximate the underlying volumetric function that describes the scene. In the rendering process, NeRFs generate images by sampling rays from the camera's viewpoint and computing the radiance values along each ray. This enables the creation of photorealistic images with realistic lighting, shading, and surface details. However, NeRFs can be computationally demanding, requiring significant resources for training and rendering ____. Ongoing research aims to improve the scalability and efficiency of NeRFs to make them applicable to a wider range of scenes and applications ____.

One such method of improvement comes in the form of the PlenOctree ____. This method introduces an octree-based 3D representation enabling real-time rendering of NeRFs supporting view-dependent effects such as mirroring. This is achieved through the use of closed-form spherical basis functions, enabling it to render arbitrary geometrical scenes without quality loss. Overall, this approach can render 800Ã—800 images at over 150 FPS, which is more than 3000 times faster than conventional NeRFs.