\section{Introduction}

Despite the remarkable capabilities of large language models (LLMs)~\cite{DBLP:conf/emnlp/QinZ0CYY23,DBLP:journals/corr/abs-2307-09288}, they often inevitably exhibit hallucinations due to incorrect or outdated knowledge embedded in their parameters~\cite{DBLP:journals/corr/abs-2309-01219, DBLP:journals/corr/abs-2302-12813, DBLP:journals/csur/JiLFYSXIBMF23}.
Given the significant time and expense required to retrain LLMs, there has been growing interest in \emph{model editing} (a.k.a., \emph{knowledge editing})~\cite{DBLP:conf/iclr/SinitsinPPPB20, DBLP:journals/corr/abs-2012-00363, DBLP:conf/acl/DaiDHSCW22, DBLP:conf/icml/MitchellLBMF22, DBLP:conf/nips/MengBAB22, DBLP:conf/iclr/MengSABB23, DBLP:conf/emnlp/YaoWT0LDC023, DBLP:conf/emnlp/ZhongWMPC23, DBLP:conf/icml/MaL0G24, DBLP:journals/corr/abs-2401-04700}, 
which aims to update the knowledge of LLMs cost-effectively.
Some existing methods of model editing achieve this by modifying model parameters, which can be generally divided into two categories~\cite{DBLP:journals/corr/abs-2308-07269, DBLP:conf/emnlp/YaoWT0LDC023}.
Specifically, one type is based on \emph{Meta-Learning}~\cite{DBLP:conf/emnlp/CaoAT21, DBLP:conf/acl/DaiDHSCW22}, while the other is based on \emph{Locate-then-Edit}~\cite{DBLP:conf/acl/DaiDHSCW22, DBLP:conf/nips/MengBAB22, DBLP:conf/iclr/MengSABB23}. This paper primarily focuses on the latter.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.48\textwidth]{figures/demonstration.pdf}
  \vspace{-4mm}
  \caption{(a) Comparison of regular model editing and EAC. EAC compresses the editing information into the dimensions where the editing anchors are located. Here, we utilize the gradients generated during training and the magnitude of the updated knowledge vector to identify anchors. (b) Comparison of general downstream task performance before editing, after regular editing, and after constrained editing by EAC.}
  \vspace{-3mm}
  \label{demo}
\end{figure}

\emph{Sequential} model editing~\cite{DBLP:conf/emnlp/YaoWT0LDC023} can expedite the continual learning of LLMs where a series of consecutive edits are conducted.
This is very important in real-world scenarios because new knowledge continually appears, requiring the model to retain previous knowledge while conducting new edits. 
Some studies have experimentally revealed that in sequential editing, existing methods lead to a decrease in the general abilities of the model across downstream tasks~\cite{DBLP:journals/corr/abs-2401-04700, DBLP:conf/acl/GuptaRA24, DBLP:conf/acl/Yang0MLYC24, DBLP:conf/acl/HuC00024}. 
Besides, \citet{ma2024perturbation} have performed a theoretical analysis to elucidate the bottleneck of the general abilities during sequential editing.
However, previous work has not introduced an effective method that maintains editing performance while preserving general abilities in sequential editing.
This impacts model scalability and presents major challenges for continuous learning in LLMs.

In this paper, a statistical analysis is first conducted to help understand how the model is affected during sequential editing using two popular editing methods, including ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23}.
Matrix norms, particularly the L1 norm, have been shown to be effective indicators of matrix properties such as sparsity, stability, and conditioning, as evidenced by several theoretical works~\cite{kahan2013tutorial}. In our analysis of matrix norms, we observe significant deviations in the parameter matrix after sequential editing.
Besides, the semantic differences between the facts before and after editing are also visualized, and we find that the differences become larger as the deviation of the parameter matrix after editing increases.
Therefore, we assume that each edit during sequential editing not only updates the editing fact as expected but also unintentionally introduces non-trivial noise that can cause the edited model to deviate from its original semantics space.
Furthermore, the accumulation of non-trivial noise can amplify the negative impact on the general abilities of LLMs.

Inspired by these findings, a framework termed \textbf{E}diting \textbf{A}nchor \textbf{C}ompression (EAC) is proposed to constrain the deviation of the parameter matrix during sequential editing by reducing the norm of the update matrix at each step. 
As shown in Figure~\ref{demo}, EAC first selects a subset of dimension with a high product of gradient and magnitude values, namely editing anchors, that are considered crucial for encoding the new relation through a weighted gradient saliency map.
Retraining is then performed on the dimensions where these important editing anchors are located, effectively compressing the editing information.
By compressing information only in certain dimensions and leaving other dimensions unmodified, the deviation of the parameter matrix after editing is constrained. 
To further regulate changes in the L1 norm of the edited matrix to constrain the deviation, we incorporate a scored elastic net ~\cite{zou2005regularization} into the retraining process, optimizing the previously selected editing anchors.

To validate the effectiveness of the proposed EAC, experiments of applying EAC to \textbf{two popular editing methods} including ROME and MEMIT are conducted.
In addition, \textbf{three LLMs of varying sizes} including GPT2-XL~\cite{radford2019language}, LLaMA-3 (8B)~\cite{llama3} and LLaMA-2 (13B)~\cite{DBLP:journals/corr/abs-2307-09288} and \textbf{four representative tasks} including 
natural language inference~\cite{DBLP:conf/mlcw/DaganGM05}, 
summarization~\cite{gliwa-etal-2019-samsum},
open-domain question-answering~\cite{DBLP:journals/tacl/KwiatkowskiPRCP19},  
and sentiment analysis~\cite{DBLP:conf/emnlp/SocherPWCMNP13} are selected to extensively demonstrate the impact of model editing on the general abilities of LLMs. 
Experimental results demonstrate that in sequential editing, EAC can effectively preserve over 70\% of the general abilities of the model across downstream tasks and better retain the edited knowledge.

In summary, our contributions to this paper are three-fold:
(1) This paper statistically elucidates how deviations in the parameter matrix after editing are responsible for the decreased general abilities of the model across downstream tasks after sequential editing.
(2) A framework termed EAC is proposed, which ultimately aims to constrain the deviation of the parameter matrix after editing by compressing the editing information into editing anchors. 
(3) It is discovered that on models like GPT2-XL and LLaMA-3 (8B), EAC significantly preserves over 70\% of the general abilities across downstream tasks and retains the edited knowledge better.