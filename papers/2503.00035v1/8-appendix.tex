\section{Hard Threshold of EAC}\label{threshhold}
In constructing a weighted-gradient saliency map, the value of \(\gamma\) determines the number of the dimensions we select where important feature anchors are located. As the value of \(\gamma\) increases, the number of selected dimensions decreases, requiring the editing information to be compressed into a smaller space during the compression process. 
During compression, it is desired for the compression space to be as small as possible to preserve the general abilities of the model. However, reducing the compression space inevitably increases the loss of editing information, which reduces the editing performance of the model.
Therefore, to ensure editing performance in a single editing scenario, different values of \(\gamma\) are determined for various models, methods, and datasets. Fifty pieces of knowledge were randomly selected from the dataset, and reliability, generalization, and locality were measured after editing. The averages of these metrics were then taken as a measure of the editing performance of the model.
Table~\ref{value} presents the details of \(\gamma\), while Table~\ref{s} illustrates the corresponding editing performance before and after the introduction of EAC. $P_{x}$ denotes the value below which x\% of the values in the dataset.


\begin{table}[!htb]
\caption{The value of $\gamma$.}
\centering
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{lcccc}
\toprule
\textbf{Datasets} & \textbf{Model} & \textbf{ROME} & \textbf{MEMIT} \\
\midrule
\multirow{2}{*}{\textbf{ZSRE}} & GPT-2 XL & $P_{80}$ & $P_{80}$ \\
 & LLaMA-3 (8B) & $P_{90}$ & $P_{95}$ \\
\midrule
\multirow{2}{*}{\textbf{COUNTERFACT}} & GPT-2 XL & $P_{85}$ & $P_{85}$ \\
 & LLaMA-3 (8B) & $P_{95}$ & $P_{95}$ \\
\bottomrule
\end{tabular}}
\label{value}
\end{table}


\begin{table}[!htb]
\caption{The value of $\gamma$.}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccccccccccc}
\toprule
\multirow{1}{*}{Dataset} & \multirow{1}{*}{Method} & \multicolumn{3}{c}{\textbf{GPT-2 XL}} & \multicolumn{3}{c}{\textbf{LLaMA-3 (8B)}} \\
\cmidrule(lr){3-5} \cmidrule(lr){6-8}
& & \multicolumn{1}{c}{Reliability} & \multicolumn{1}{c}{Generalization} & \multicolumn{1}{c}{Locality} & \multicolumn{1}{c}{Reliability} & \multicolumn{1}{c}{Generalization} & \multicolumn{1}{c}{Locality} \\
\midrule
\multirow{1}{*}{ZsRE} & ROME & 1.0000 & 0.9112 & 0.9661 & 1.0000 & 0.9883 & 0.9600  \\
& ROME-EAC & 1.0000 & 0.8923 & 0.9560 & 0.9933 & 0.9733 & 0.9742  \\
\cmidrule(lr){2-8}
& MEMIT & 0.6928 & 0.5208 & 1.0000 & 0.9507 & 0.9333 & 0.9688  \\
& MEMIT-EAC & 0.6614 & 0.4968 & 0.9971 & 0.9503 & 0.9390 & 0.9767  \\
\midrule
\multirow{1}{*}{CounterFact} & ROME & 1.0000 & 0.4200 & 0.9600 & 1.0000 & 0.3600 & 0.7800  \\
& ROME-EAC & 0.9800 & 0.3800 & 0.9600 & 1.0000 & 0.3200 & 0.8800  \\
\cmidrule(lr){2-8}
& MEMIT & 0.9000 & 0.2200 & 1.0000 & 1.0000 & 0.3800 & 0.9500  \\
& MEMIT-EAC & 0.8000 & 0.1800 & 1.0000 & 1.0000 & 0.3200 & 0.9800  \\
\bottomrule
\end{tabular}%
}
\label{s}
\end{table}

\section{Optimization Details}\label{b}
ROME derives a closed-form solution to achieve the optimization:
\begin{equation}
\text{minimize} \ \| \widehat{W}K - V \| \ \text{such that} \ \widehat{W}\mathbf{k}_* = \mathbf{v}_* \ \text{by setting} \ \widehat{W} = W + \Lambda (C^{-1}\mathbf{k}_*)^T.
\end{equation}

Here \( W \) is the original matrix, \( C = KK^T \) is a constant that is pre-cached by estimating the uncentered covariance of \( \mathbf{k} \) from a sample of Wikipedia text, and \( \Lambda = (\mathbf{v}_* - W\mathbf{k}_*) / ( (C^{-1}\mathbf{k}_*)^T \mathbf{k}_*) \) is a vector proportional to the residual error of the new key-value pair on the original memory matrix.

In ROME, \(\mathbf{k}_*\) is derived from the following equation:
\begin{equation}
\mathbf{k}_* = \frac{1}{N} \sum_{j=1}^{N} \mathbf{k}(x_j + s), \quad \text{where} \quad \mathbf{k}(x) = \sigma \left( W_{f_c}^{(l^*)} \gamma \left( a_{[x],i}^{(l^*)} + h_{[x],i}^{(l^*-1)} \right) \right).
\end{equation}

ROME set $\mathbf{v}_* = \arg\min_z \mathcal{L}(z)$, where the objective $\mathcal{L}(z)$ is:
\begin{equation}
\frac{1}{N} \sum_{j=1}^{N} -\log \mathbb{P}_{G(m_{i}^{l^*}:=z))} \left[ o^* \mid x_j + p \right] + D_{KL} \left( \mathbb{P}_{G(m_{i}^{l^*}:=z)} \left[ x \mid p' \right] \parallel \mathbb{P}_{G} \left[ x \mid p' \right] \right).
\end{equation}

\section{Experimental Setup} \label{detail}

\subsection{Editing Methods}\label{EM}

In our experiments, Two popular editing methods including ROME and MEMIT were selected as baselines.

\textbf{ROME} \cite{DBLP:conf/nips/MengBAB22}: it first localized the factual knowledge at a specific layer in the transformer MLP modules, and then updated the knowledge by directly writing new key-value pairs in the MLP module.

\textbf{MEMIT} \cite{DBLP:conf/iclr/MengSABB23}: it extended ROME to edit a large set of facts and updated a set of MLP layers to update knowledge.

The ability of these methods was assessed based on EasyEdit~\cite{DBLP:journals/corr/abs-2308-07269}, an easy-to-use knowledge editing framework which integrates the released codes and hyperparameters from previous methods.

\subsection{Editing Datasets}\label{dat}
In our experiment, two popular model editing datasets \textsc{ZsRE}~\cite{DBLP:conf/conll/LevySCZ17} and \textsc{CounterFact}~\cite{DBLP:conf/nips/MengBAB22} were adopted.

\textbf{\textsc{ZsRE}} is a QA dataset using question rephrasings generated by back-translation as the equivalence neighborhood.
Each input is a question about an entity, and plausible alternative edit labels are sampled from the top-ranked predictions of a BART-base model trained on \textsc{ZsRE}.

\textbf{\textsc{CounterFact}} accounts for counterfacts that start with low scores in comparison to correct facts. It constructs out-of-scope data by substituting the subject entity for a proximate subject entity sharing a predicate. This alteration enables us to differentiate between superficial wording changes and more significant modifications that correspond to a meaningful shift in a fact. 

\subsection{Metrics for Evaluating Editing Performance}\label{Mediting performance}
\paragraph{Reliability} means that given an editing factual knowledge, the edited model should produce the expected predictions. The reliability is measured as the average accuracy on the edit case:
\begin{equation}
\mathbb{E}_{(x'_{ei}, y'_{ei}) \sim \{(x_{ei}, y_{ei})\}} \mathbf{1} \left\{ \arg\max_y f_{\theta_{i}} \left( y \mid x'_{ei} \right) = y'_{ei} \right\}.
\label{rel}
\end{equation}

\paragraph{Generalization} means that edited models should be able to recall the updated knowledge when prompted within the editing scope. The generalization is assessed by the average accuracy of the model on examples uniformly sampled from the equivalence neighborhood:
\begin{equation}
\mathbb{E}_{(x'_{ei}, y'_{ei}) \sim N(x_{ei}, y_{ei})} \mathbf{1} \left\{ \arg\max_y f_{\theta_{i}} \left( y \mid x'_{ei} \right) = y'_{ei} \right\}.
\label{gen}
\end{equation}

\paragraph{Locality} means that the edited model should remain unchanged in response to prompts that are irrelevant or the out-of-scope. The locality is evaluated by the rate at which the edited model's predictions remain unchanged compared to the pre-edit model.
\begin{equation}
\mathbb{E}_{(x'_{ei}, y'_{ei}) \sim O(x_{ei}, y_{ei})} \mathbf{1} \left\{ f_{\theta_{i}} \left( y \mid x'_{ei} \right) = f_{\theta_{i-1}} \left( y \mid x'_{ei} \right) \right\}.
\label{loc}
\end{equation}

\subsection{Downstream Tasks}\label{pro}

Four downstream tasks were selected to measure the general abilities of models before and after editing:
\textbf{Natural language inference (NLI)} on the RTE~\cite{DBLP:conf/mlcw/DaganGM05}, and the results were measured by accuracy of two-way classification.
\textbf{Open-domain QA} on the Natural Question~\cite{DBLP:journals/tacl/KwiatkowskiPRCP19}, and the results were measured by exact match (EM) with the reference answer after minor normalization as in \citet{DBLP:conf/acl/ChenFWB17} and \citet{DBLP:conf/acl/LeeCT19}.
\textbf{Summarization} on the SAMSum~\cite{gliwa-etal-2019-samsum}, and the results were measured by the average of ROUGE-1, ROUGE-2 and ROUGE-L as in \citet{lin-2004-rouge}.
\textbf{Sentiment analysis} on the SST2~\cite{DBLP:conf/emnlp/SocherPWCMNP13}, and the results were measured by accuracy of two-way classification.

The prompts for each task were illustrated in Table~\ref{tab-prompt}.

\begin{table*}[!htb]
% \small
\centering
\begin{tabular}{p{0.95\linewidth}}
\toprule

NLI:\\
\{\texttt{SENTENCE1}\} entails the \{\texttt{SENTENCE2}\}. True or False? answer:\\

\midrule

Open-domain QA:\\
Refer to the passage below and answer the following question. Passage: \{\texttt{DOCUMENT}\} Question: \{\texttt{QUESTION}\}\\

\midrule

Summarization:\\
\{\texttt{DIALOGUE}\} TL;DR:\\

\midrule


Sentiment analysis:\\
For each snippet of text, label the sentiment of the text as positive or negative. The answer should be exact 'positive' or 'negative'. text: \{\texttt{TEXT}\} answer:\\

\bottomrule
\end{tabular}
\caption{The prompts to LLMs for evaluating their zero-shot performance on these general tasks.}
\label{tab-prompt}
\end{table*}

\subsection{Hyper-parameters for Elastic Net}\label{hy}

In our experiment, we set \(\lambda = 5 \times 10^{-7} \), \(\mu = 5 \times 10^{-1} \) for GPT2-XL\cite{radford2019language} and \(\lambda = 5 \times 10^{-7} \), \(\mu = 1 \times 10^{-3} \) for LLaMA-3 (8B)\cite{llama3}.

\begin{figure*}[!hbt]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/legend_edit.pdf}
  \vspace{-4mm}
\end{figure*}

\begin{figure*}[!hbt]
  \centering
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-GPT2XL-CF-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA3-8B-CF-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-GPT2XL-CF-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA3-8B-CF-edit.pdf}}
  \caption{Edited on CounterFact, editing performance of edited models using the ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} on GPT2-XL~\cite{radford2019language} and LLaMA-3 (8B)~\cite{llama3}, as the number of edits increases before and after the introduction of EAC.}
  \vspace{-4mm}
  \label{edit-performance-cf}
\end{figure*}

\begin{figure*}[!hbt]
  \centering
  \includegraphics[width=0.75\textwidth]{figures/legend.pdf}
  \vspace{-4mm}
\end{figure*}

\begin{figure*}[!htb]
  \centering
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-GPT2XL-CounterFact.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA3-8B-CounterFact.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-GPT2XL-CounterFact.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA3-8B-CounterFact.pdf}}
  \caption{Edited on CounterFact, performance on general tasks using the ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} on GPT2-XL~\cite{radford2019language} and LLaMA-3 (8B)~\cite{llama3}, as the number of edits increases before and after the introduction of EAC.}
  \vspace{-4mm}
  \label{task-performance-cf}
\end{figure*}

\section{Experimental Results}\label{app}

\subsection{Results of Editing Performance}\label{cf-performance}
Applying CounterFact as the editing dataset, Figure~\ref{edit-performance-cf} presents the editing performance of the ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} methods on GPT2-XL~\cite{radford2019language} and LLaMA-3 (8B)~\cite{llama3}, respectively, as the number of edits increases before and after the introduction of EAC.
The dashed line represents the ROME or MEMIT, while the solid line represents the ROME or MEMIT applying the EAC.


\subsection{Results of General Abilities}\label{cf-ability}
Applying CounterFact as the editing dataset, Figure~\ref{task-performance-cf} presents the performance on general tasks of edited models using the ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} methods on GPT2-XL~\cite{radford2019language} and LLaMA-3 (8B)~\cite{llama3}, respectively, as the number of edits increases before and after the introduction of EAC. 
The dashed line represents the ROME or MEMIT, while the solid line represents the ROME or MEMIT applying the EAC.

\subsection{Results of Larger Model}\label{13 B}
To better demonstrate the scalability and efficiency of our approach, we conducted experiments using the LLaMA-2 (13B)~\cite{DBLP:journals/corr/abs-2307-09288}.
Figure~\ref{13B-edit} presents the editing performance of the ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} methods on LLaMA-2 (13B)
~\cite{DBLP:journals/corr/abs-2307-09288}, as the number of edits increases before and after the introduction of EAC.
Figure~\ref{13B} presents the performance on general tasks of edited models using the ROME and MEMIT methods on LLaMA-2 (13B), as the number of edits increases before and after the introduction of EAC.
The dashed line represents the ROME or MEMIT, while the solid line represents the ROME or MEMIT applying the EAC.

\begin{figure*}[!hbt]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/legend_edit.pdf}
  \vspace{-4mm}
\end{figure*}

\begin{figure*}[!hbt]
  \centering
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA2-13B-ZsRE-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA2-13B-ZsRE-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA2-13B-CF-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA2-13B-CF-edit.pdf}}
  \caption{Editing performance of edited models using the ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} on LLaMA-2 (13B)~\cite{DBLP:journals/corr/abs-2307-09288}, as the number of edits increases before and after the introduction of EAC.}
  \vspace{-4mm}
  \label{13B-edit}
\end{figure*}

\begin{figure*}[!hbt]
  \centering
  \includegraphics[width=0.75\textwidth]{figures/legend.pdf}
  \vspace{-4mm}
\end{figure*}

\begin{figure*}[!htb]
  \centering
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA2-13B-ZsRE.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA2-13B-ZsRE.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA2-13B-CounterFact.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA2-13B-CounterFact.pdf}}
  \caption{Performance on general tasks using the ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} on LLaMA-2 (13B)~\cite{DBLP:journals/corr/abs-2307-09288}, as the number of edits increases before and after the introduction of EAC.}
  \vspace{-4mm}
  \label{13B}
\end{figure*}

\section{Analysis of Elastic Net}
\label{FT}
It is worth noting that the elastic net introduced in EAC can be applied to methods beyond ROME and MEMIT, such as FT~\cite{DBLP:conf/emnlp/CaoAT21}, to preserve the general abilities of the model.
Unlike the previously mentioned fine-tuning, FT is a model editing approach. It utilized the gradient to gather information about the knowledge to be updated and applied this information directly to the model parameters for updates.
Similar to the approaches of ROME and MEMIT, which involve locating parameters and modifying them, the FT method utilizes gradient information to directly update the model parameters for editing. Therefore, we incorporate an elastic net during the training process to constrain the deviation of the edited matrix.
Figure~\ref{ft} shows the sequential editing performance of FT on GPT2-XL and LLaMA-3 (8B) before and after the introduction of elastic net.
The dashed line represents the FT, while the solid line represents the FT applying the elastic net.
The experimental results indicate that when using the FT method to edit the model, the direct use of gradient information to modify the parameters destroys the general ability of the model. By constraining the deviation of the edited matrix, the incorporation of the elastic net effectively preserves the general abilities of the model.

\begin{figure*}[t]
  \centering
  \subfigure{
  \includegraphics[width=0.43\textwidth]{figures/legend_FT.pdf}}
\end{figure*}

\begin{figure*}[t]%[!ht]
  \centering
  \subfigure{
  \includegraphics[width=0.22\textwidth]{figures/FT-GPT2XL-ZsRE.pdf}}
  \subfigure{
  \includegraphics[width=0.22\textwidth]{figures/FT-GPT2XL-CounterFact.pdf}}
  \vspace{-2mm}
  \caption{Edited on the ZsRE or CounterFact datasets, the sequential editing performance of FT~\cite{DBLP:conf/emnlp/CaoAT21} and FT with elastic net on GPT2-XL before and after the introduction of elastic net.}
  \vspace{-2mm}
  \label{ft}
\end{figure*}
