\section{Experiments}

\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.75\textwidth]{figures/legend.pdf}
  
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-GPT2XL-ZsRE.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA3-8B-ZsRE.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-GPT2XL-ZsRE.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA3-8B-ZsRE.pdf}}
  \vspace{-2mm}
  \caption{Edited on the ZsRE dataset, the general task performance of ROME and MEMIT with GPT2-XL and LLaMA-3 (8B) before and after the introduction of EAC, as the number of edits increases.}
  \label{general ability}
  \vspace{-3mm}
\end{figure*}

\subsection{Experimental Setup}

Experiments were conducted on three LLMs, GPT2-XL~\cite{radford2019language}, LLaMA-3 (8B)~\cite{llama3} and LLaMA-2 (13B)~\cite{DBLP:journals/corr/abs-2307-09288},
using ROME~\cite{DBLP:conf/nips/MengBAB22} and MEMIT~\cite{DBLP:conf/iclr/MengSABB23} as baseline editing methods. 
The editing performance was evaluated on two datasets: ZsRE~\cite{DBLP:conf/conll/LevySCZ17} and CounterFact~\cite{DBLP:conf/nips/MengBAB22},
using reliability, generalization, and locality metrics~\cite{DBLP:conf/emnlp/CaoAT21,DBLP:conf/iclr/MitchellLBFM22,DBLP:conf/nips/MengBAB22,DBLP:conf/iclr/MengSABB23,DBLP:conf/emnlp/YaoWT0LDC023}.
Four downstream tasks were selected to measure the general abilities of models before and after editing:
\textbf{Natural language inference (NLI)}, 
\textbf{Open-domain QA}, \textbf{Summarization}
and \textbf{Sentiment analysis}.
Readers can refer to Appendix~\ref{detail} for more details.

\subsection{Main Results}

This section illustrates the editing performance and downstream task performance of edited models with GPT2-XL and LLaMA-3 (8B) on the ZsRE dataset. Due to page limitation, results of other LLMs and datasets were put in Appendix~\ref{app}

\paragraph{Editing Performance}
In previous work, the evaluation of editing performance has primarily focused on single editing scenarios, meaning that only the success of editing a single fact is assessed.
However, in sequential editing, the goal is for the model to retain all prior knowledge. To evaluate this, a set of sequential edits was applied, and the final model's reliability, generalization, and locality were assessed.
Applying ZsRE as the editing dataset, Figure~\ref{edit-performance} shows the sequential editing performance of ROME and MEMIT on GPT2-XL and LLaMA-3 (8B) before and after the introduction of EAC. 
The dashed line represents the ROME or MEMIT, while the solid line represents the ROME or MEMIT applying the EAC.
As sequential edits increase, models using ROME or MEMIT methods show a significant decline in reliability, generalization, and locality, retaining only partial knowledge from the latest edits while forgetting earlier information.
Besides, as shown in Figure~\ref{edit-performance}, the introduction of EAC brings improvements in the editing performance in sequential editing scenarios. By reducing the non-trivial noise introduced with each edit, EAC helps the model to retain the knowledge more effectively compared to previous methods.

\paragraph{General Abilities}
Applying ZsRE as the editing dataset, Figure~\ref{general ability} shows the performance on general tasks of ROME and MEMIT on GPT2-XL and LLaMA-3 (8B) before and after the introduction of EAC. 
The dashed line represents the ROME or MEMIT, while the solid line represents the ROME or MEMIT applying the EAC.
It can be seen that, when using the ROME or the MEMIT for sequential editing, the performance of the edited models on various tasks fluctuates significantly and shows a downward trend as the number of edits increases. 
After applying EAC, the general abilities of the model on downstream tasks are well preserved. However, the performance of the model on downstream tasks inevitably declined when the number of sequential edits was high. This indicates that some non-trivial noise is still introduced with each edit even when applying EAC. As these non-trivial noises accumulate, the general abilities of the model are compromised.

\begin{figure}[t]
  \centering
  \subfigure{
  \includegraphics[width=0.40\textwidth]{figures/legend-aba.pdf}}
  \centering
  \subfigure{
  \includegraphics[width=0.22\textwidth]{figures/ROME-GPT2XL-ZsRE-aba.pdf}}
  \subfigure{
  \includegraphics[width=0.22\textwidth]{figures/ROME-LLaMA3-8B-ZsRE-aba.pdf}}
  % \vspace{-2mm}
  \caption{Ablation analysis of performance on open-domain-QA for EAC. Results were conducted with GPT2-XL and LLaMA-3 (8B) on the ZsRE dataset.}
  \vspace{-1mm}
  \label{aba}
\end{figure}

\subsection{Ablation Study}
To validate the effectiveness of EAC, we performed ablation tests by removing either the weighted-gradient saliency map or the scored elastic net from EAC.
As depicted in Figure~\ref{aba}, we find that both the weighted-gradient saliency maps and the score-based elastic net retain a certain level of the general abilities of the model. It can also be seen that removing either the weighted-gradient saliency map or the scored elastic net results in a decreased ability to preserve the general abilities of the model compared to EAC, illustrating the effectiveness of EAC.
In addition, we observe a more significant decrease in the general abilities of the model when the weighted-gradient saliency map is removed. This suggests that the weighted-gradient saliency map plays a crucial role in EAC by effectively reducing the norm of the update matrix, which achieves this by setting some dimensions of \( \mathbf{v}_* \) to zero where the editing anchors are located, thereby constraining the deviation of the edited matrix and finally preserving the general abilities of the model.

\begin{table}[t]
    \centering
    \resizebox{0.85\linewidth}{!}{
    \begin{tabular}{lcc}
        \toprule
        & \textbf{GPT2-XL} & \textbf{LLaMA3-8B} \\
        \midrule
        ROME & 6.70s & 27.53s \\
        ROME-EAC & 6.21s & 23.74s \\
        \hline
        MEMIT & 5.23s & 11.73s \\
        MEMIT-EAC & 5.92s & 12.66s \\
        \bottomrule
    \end{tabular}
    }
    \caption{Comparison of editing time between the EAC framework and original methods}
    \vspace{-2mm}
    \label{time}
\end{table}

\subsection{Time Analysis}
In the EAC framework, the original training process for updating new knowledge is divided into two stages: first, selecting the important anchors, and second, retraining to complete the knowledge update.
Using GPT2-XL as an example, the original ROME method applies 20 optimization steps to update knowledge. In contrast, the EAC framework allocates 10 optimization steps to identify important editing anchors, followed by another 10 steps of retraining to finalize the knowledge update.
Additionally, since we reuse the gradient information generated during the selection of editing anchors, the EAC framework remains largely consistent with the previous method in terms of editing time and computational resource consumption, without incurring any extra computational overhead. This result is presented in Table~\ref{time}.

\begin{figure}[t]
  \centering
  \subfigure{
  \includegraphics[width=0.22\textwidth]{figures/case-study-reliability.pdf}}
  \subfigure{
  \includegraphics[width=0.22\textwidth]{figures/case-study-locality.pdf}}
  \vspace{-2mm}
  \caption{Edited on the ZsRE dataset, the editing performance of different methods with GPT2-XL as the number of edits increases.}
  \label{case}
  \vspace{-3mm}
\end{figure}

\subsection{Editing Anchors Selecting Analysis}

In section \ref{method}, we employed a weighted-gradient saliency map to identify editing anchors, demonstrating the efficacy of this approach in subsequent experiments. Here, we delve deeper into the rationale behind using a weighted-gradient saliency map for determining these important anchors.
The weighted-gradient saliency map combines gradient sensitivity and vector magnitude to prioritize dimensions that significantly influence the knowledge vector, ensuring precise edits by focusing on areas both sensitive to changes and substantively important.
We validated this approach by comparing it to methods using random selection, gradients alone, or absolute values. Figure \ref{case} demonstrates that the weighted-gradient saliency map consistently outperforms other methods when applied to GPT2-XL on the ZsRE dataset. The superior performance of the weighted-gradient saliency map emphasizes its enhanced capability in precisely identifying key editing anchors within the model, ensuring greater accuracy and efficiency in the editing process.
