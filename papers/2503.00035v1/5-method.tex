\section{EAC: \underline{E}diting \underline{A}nchor \underline{C}ompression}
\label{method}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.48\textwidth]{figures/EAC.pdf}
  \vspace{-4mm}
  \caption{Proposed method: EAC. We first identify the key dimensions of the editing anchors using a weighted-gradient saliency map, followed by retraining on these dimensions to achieve the final optimization.}
  \vspace{-3mm}
  \label{EAC}
\end{figure}

In Section~\ref{analysis}, an in-depth analysis is provided on the factors that lead to the decrease in the general abilities of the model. 
Besides, it is found that the deviation of the edited parameter matrix could be constrained
by reducing the norm of the update matrix at each edit.
This helps maintain the semantic similarity of the facts recalled by the model before and after editing, ultimately preserving the general abilities of the edited model.
As depicted in Figure \ref{EAC}, a framework called EAC is proposed to compress information only in certain dimensions, thereby reducing the norm of the edited matrix and further constraining its deviation.

\subsection{Definition of Editing Anchors}
ROME uses an update matrix to insert a new knowledge triple \( t = (subject, relation, object) \). 
As mentioned in Section~\ref{sec_visual}, ROME calculates the update matrix by multiplying the pair \( (\mathbf{k}_*, \mathbf{v}_*) \), where \( \mathbf{k}_* \) identifies patterns of the input at the specified layer\footnotemark{} and \( \mathbf{v}_* \) is the fact recalled by the model.
Readers can refer to Appendix~\ref{b} for the details of ROME.
When injecting a new knowledge triple \( t = (subject, relation, object^*) \) to replace an old one \( t = (subject, relation, object) \), the specific part we aim to modify is the new relation \((relation, object^*) \), which is a property of the subject. It is believed that \( \mathbf{v}_* \) gathers all the information about how the model understands the subject and how it will respond thus we think that the new relation is primarily encoded in \( \mathbf{v}_* \).
Thus, EAC chooses to reduce the norm of \( \mathbf{v}_* \) for compression. Using a weighted gradient saliency map, EAC identifies high-scoring editing anchors crucial for encoding new relations. A scored elastic net is then applied to retrain and compress the editing information in key dimensions.
\footnotetext{Found by causal tracing methods~\cite{DBLP:conf/nips/MengBAB22}.}

\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/legend_edit.pdf}
  \vspace{-4mm}
\end{figure*}

\begin{figure*}[t]
  \centering
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-GPT2XL-ZsRE-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/ROME-LLaMA3-8B-ZsRE-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-GPT2XL-ZsRE-edit.pdf}}
  \subfigure{
  \includegraphics[width=0.23\textwidth]{figures/MEMIT-LLaMA3-8B-ZsRE-edit.pdf}}
  \vspace{-2mm}
  \caption{Edited on the ZsRE dataset, the sequential editing performance of ROME and MEMIT with GPT2-XL and LLaMA-3 (8B) before and after the introduction of EAC, as the number of edits increases.}
  \vspace{-3mm}
  \label{edit-performance}
\end{figure*}

\subsection{Weighted-gradient Saliency Map}\label{a}
To reduce the norm of \( \mathbf{v}_* \) while preserving as much editing information as possible about the new relation, the goal is to compress this information over the smallest possible dimension. Drawing inspiration from gradient-based input saliency maps~\cite{DBLP:journals/corr/SmilkovTKVW17, DBLP:conf/nips/AdebayoGMGHK18}, a question is posed that whether a \textit{weight saliency map} can be constructed to aid compression. 
In previous work, ROME set \( \mathbf{v}_* = \arg\min_z \mathcal{L}(\mathbf{z}) \)~\cite{DBLP:conf/nips/MengBAB22}. Similar to the input saliency map, the gradient of this loss function with respect to each feature is utilized, and the magnitude of the values of \( \mathbf{v}_* \) is weighted accordingly to serve as the score for each feature: 
\begin{equation}
\text{score} = \mathbf{v}_* \odot \nabla \mathcal{L}(\mathbf{z}),
\label{score}
\end{equation}
where \(\odot\) is element-wise product. For GPT2-XL, the vectors $\mathbf{v}_*$ and $\mathbf{z}$ have dimensions of $1600 \times $1, whereas for LLaMA-3 (8B), the dimensions of these vectors are $4096 \times $1.
Based on Eq.~(\ref{score}), the desired weighted-gradient saliency map is obtained by applying a hard threshold:
\begin{equation}
\mathbf{m}_S = \mathbf{1} \left( \left| \text{score} \right| \geq \gamma \right),
\label{map}
\end{equation}
where \(\mathbf{1}(\mathbf{g} \geq \gamma)\) is an element-wise indicator function, which yields a value of 1 for the \(i\)-th element if \(g_i \geq \gamma\) and 0 otherwise.
\(| \cdot |\) is an element-wise absolute value operation, and \(\gamma > 0\) is a hard threshold. In practice, the value of \(\gamma\) is chosen according to different models and methods.
Specifically, the value of \(\gamma\) is chosen to retain the editing performance of the model in single editing. For more details refer to Appendix \ref{threshhold}.

With the introduction of the weighted gradient saliency map, the dimension of \( \mathbf{v}_* \) is split into two parts: one part represents the dimensions where the important editing anchors are located and it will be retrained to encode new relation, while the other part is set to 0, thereby reducing the norm of \( \mathbf{v}_* \). Based on Eq.~(\ref{map}), the \( \mathbf{v'}_* \), can be expressed as:
\begin{equation}
\mathbf{v'}_* \leftarrow \mathbf{m}_S \odot (\Delta \mathbf{v}_* + \mathbf{v}_*) + (\mathbf{1} - \mathbf{m}_S) \odot \mathbf{0},
\label{v}
\end{equation}
where \(\mathbf{1}\) denotes an all-one vector and \(\mathbf{0}\) denotes an all-zero vector. \(\Delta  \mathbf{v}_* \) is the part of \( \mathbf{v}_* \) that requires updating during retraining. Eq.~(\ref{v}) demonstrates that during retraining, only the dimensions where these important anchors are located need to be retrained to compress the editing information.

\subsection{Retraining Based on Scored Elastic Net}
After choosing important anchors, retraining for $\mathbf{v}_*$ is performed in this section.
To further compress the editing information, inspired by~\citet{zou2005regularization}, a score-based elastic net is also introduced during retraining:
\begin{equation}
\mathcal{L}_{0}(\mathbf{z}) = \lambda \|\mathbf{z}\|_{1, \alpha} + \mu \|\mathbf{z}\|_2^2,
\label{net}
\end{equation}
where \(\lambda \) and \(\mu \) are the hyper-parameters that control the strength of regularization and \( \mathbf{z} \) is the vector that causes the network to predict the target object in response to the factual prompt. Detailed hyper-parameters can be referred to in Appendix~\ref{hy}. Considering that the score computed in Eq.~(\ref{score}) represents the importance of the anchors for encoding the new relation, a weighted L1 norm is utilized when computing the L1 norm:
\begin{equation}
\|\mathbf{z}\|_{1, \alpha} = \sum_{i=1}^n \alpha_i |z_i|.
\end{equation}

In practice, we set \(\mathbf{\alpha} = \frac{1}{\text{score} + \epsilon}\), a small positive number \(\epsilon \) is introduced to prevent the score from being zero. 
Applying an elastic network, we ultimately derived the loss function during the retraining process to get the $\mathbf{v'}_*$ in Eq.~(\ref{v}):
\begin{equation}
\mathcal{L}_{r}(\mathbf{z}) =  \mathcal{L}(\mathbf{z}) + \mathcal{L}_{0}(\mathbf{z}).
\end{equation}

It is worth noting that when we make optimization here, only the dimensions where the editing anchors identified in section~\ref{a} are modified.
By introducing the elastic net, L1 regularization enables refining the selection of the editing anchors identified through the weighted-gradient saliency map during the retraining process. Meanwhile, L2 regularization effectively prevents model overfitting and improves the model's stability.
Finally, we complete the optimization. For specific optimization details, we recommend interested readers to refer to Appendix~\ref{b}.
Furthermore, the scored elastic net can also be applied to the FT. Readers can refer to Appendix \ref{FT} for more details.
