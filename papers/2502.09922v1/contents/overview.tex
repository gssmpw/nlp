\section{\SysName Overview}
\label{sec:overview}

\if 0
\yuecomment{We've talked a lot about potential challenges and what it takes FaaScale to address, once in Intro/Background+Motivation, and another time in Design Overview. I feel the requirements in this section is inconsistent with those challenges identified previously. This might confuse reviewers as they read thru. Suggestion: Shrink the text for challenges in Sec 1 and 2, remove requirement text here in this section, and instead mention how different design choices/proposed techniques address aforementioned challenges. }
\PHM{\SysName Requirements.}
\SysName aims to exploit high-speed network and pipeline execution to deliver fast model scaling. 
Achieving this goal presents three requirements that guide our design.
\textbf{First}, \SysName must be able to accommodate any model scaling demand in dynamic environments, where the number of source nodes, destination nodes, and the model's storage tiers can change frequently.
\textbf{Second}, \SysName should perform fine-grained control over block-level model distribution and execution, which facilitates the strategic design of ``execute-while-load'' solutions.
\textbf{Finally}, \SysName should efficiently utilize network bandwidth resources to improve performance of model scaling.

 \fi
 
\PHM{Design choices.}
The key to achieving fast model scaling is efficient cross-node communication.
While collective communication libraries such as {\it NCCL}~\cite{nccl} are widely adopted in GPU clusters, they are typically optimized for long-running, static environments such as large-scale model training. 
% \yuecomment{We should find citations to backup the claim of NCCL slowness. I found a GitHub issue talking about nccl init cost and cited it here. Double check if proper.} 
For example, we find that {\it NCCL} lacks the flexibility to handle frequent reconfigurations of communication groups when scaling model-serving instances under dynamic workloads~\cite{nccl_cold_start_issue}, which introduces additional overhead that delays end-to-end model loading (see \S\ref{subsec:model_transfer_performance}).

Therefore, we opt to implement a lightweight, yet efficient, multicast framework in \SysName based on the binomial pipeline~\cite{binomial-pipe,rdmc} algorithm to achieve scalable model inference. 
This approach is well-suited to address the challenges outlined in \S\ref{sec:challenges}. 
Compared to other multicast solutions such as binary tree~\cite{wang_faasnet_nodate}, the binomial pipeline generally delivers superior multicast performance (see \S\ref{sec:evaluation}). 
By leveraging fast data transfer techniques like RDMA and GDR, \SysName can efficiently implement and optimize the binomial-pipeline-based multicast, achieving low-latency model loading (\textbf{\emph{C1}}). 
Additionally, this approach provides high flexibility to orchestrate fine-grained execution tasks at runtime and manage models across storage tiers, which facilitates dynamic model execution (\textbf{\emph{C2}}) and efficient model management (\textbf{\emph{C3}}).

% Combined with fast data passing techniques such as RDMA and GDR, \SysName can flexibly control model scaling and orchestrate execution tasks with high network bandwidth efficiency.

\begin{figure}
    \centering
    % \includegraphics[width=0.4\textwidth]{overview}
    % \includegraphics[width=0.4\textwidth]{figures/faascale_ov1.pdf} 
    \includegraphics[width=0.4\textwidth]{figures/overview_v3.pdf} 
    \vspace{-10pt} 
    \caption{\SysName architecture overview. 
    \textit{\textmd{In this example, Node A initiates a binomial pipeline multicast for a model partitioned into three model blocks. Each participating worker node transmits a model block in a sequential step (indicated by numbered labels along the data flow arrows). 
    % A receiver worker node forwards the blocks it has received to its neighbors.
    A receiver node forwards the blocks it has received to its neighbors (e.g., Node B forwards block \textbf{a} at steps 2 and 3).
    The color-coded model blocks correspond to the data flow paths.}}
    %The multicast data flow and model blocks are color-coded using the same code.}}
    %\todo{redraw this graph to: i. illustrate model multicast workflow steps; ii. fix issues of model blocks.}
    }
    \label{fig:overview}
    \vspace{-10pt} 
    % \vspace{-5pt} 
\end{figure}

\PHM{Overview.}
Fig.~\ref{fig:overview} illustrates an architecture overview of \SysName. 
\SysName runs a cluster manager to dispatch end-user queries to worker nodes, manage global resources, and coordinate model scaling and pipeline execution.
\SysName implements an efficient model scaling scheme---\AlgoName---on the model scaling and pipeline execution controllers. 
% In addition to routine cluster management tasks (e.g., request dispatcher and resource manager), there are two key components for achieving fast model scaling.
Specifically, the model scaling controller coordinates fine-grained model distribution across participating nodes, in which a model is partitioned into blocks and transmitted using a binomial-pipeline-based approach.
In this approach, the nodes are organized into a hypercube communication topology~\footnote{This is achievable in real-world GPU clusters, which often use optimized network topologies such as fat trees~\cite{fattree} to ensure efficient communication.}, where each node transmits model blocks to its adjacent nodes.
The number of time steps required to complete block transmission is proven to be optimal (see details in \cite{binomial-pipe}).
Additionally, the pipeline execution controller is responsible for distributing inference execution across nodes during model scaling.
It follows optimized block transfer orders to judiciously distribute block-level inference tasks among participating nodes to improve overall performance. (see details in \S\ref{sec:algo}).

Each worker node deploys user-provided models as model-serving instances and operates a node controller that synchronizes with the cluster manager, reports local status, and coordinates node-level tasks.
Additionally, \SysName runs a model manager at each node to track local resources such as GPUs and host memory and manage model instances.
The model manager is responsible for model execution and transmission tasks according to the instructions of the node controller.
It leverages GDR to efficiently exchange data across GPUs on different nodes, bypassing the data movement through the host to GPUs.
It also supports direct access to models stored in remote memory via RDMA.
These designs effectively improve network resource efficiency and distributed inference performance.

We next describe how \AlgoName achieves efficient model loading and dynamic model execution (\textbf{\emph{C1 and C2}}) in \S\ref{sec:algo}, and then discuss \SysName's model management (\textbf{\emph{C3}}) in \S\ref{sec:system}.

% We next detail \SysName's designs to address the aforementioned challenges (\S\ref{sec:challenges}). 
% \SysName enables scalable model distribution and distributed inference with \AlgoName (\textbf{\emph{C1 and C2}}) and employs a series of system optimizations to support efficient model management across storage tiers (\textbf{\emph{C3}}).
% % We will discuss \AlgoName and \SysName's system design in \S\ref{sec:algo} and \S\ref{sec:system}, respectively.

