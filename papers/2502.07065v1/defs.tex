% Revision colors

  \newcommand{\editcheck}[1]{\textcolor{red}{#1}}
  \newcommand{\edit}[1]{\textcolor{blue}{#1}}
 
  \newcommand{\ie}{\textit{i.e.}}
 
% \newcommand{\obs}{\mathsf{Obs}}
  \newcommand{\dist}[1]{\mathcal{D}(#1)}
%  \newcommand{\sa}{\gamma}
% \newcommand{\SA}{\Gamma}
  \newcommand{\sink}{\mathsf{sink}}

  \newcommand{\supp}{\mathsf{Supp}}
  \newcommand{\plays}{\mathsf{Plays}}

  
  \newcommand{\prefplays}{\mathsf{Prefs}}
 \newcommand{\proj}{\mathsf{Proj}}
 
% linear temporal logic 
% from Baier, Katoen
\newcommand{\truev}{\mathsf{true}}
\newcommand{\falsev}{\mathsf{false}}
\newcommand{\Always}{\Box \, }
\newcommand{\Eventually}{\Diamond \, }
\newcommand{\Next}{\bigcirc \, }
\newcommand{\Until}{\mbox{$\, {\sf U}\,$}}
\newcommand{\R}{\mbox{$\, {\sf R}\,$}}
\newcommand{\Unless}{\mbox{$\, {\sf W}\,$}}
\newcommand{\Model}{{\cal K}}
\newcommand{\cyl}{{\mathsf{Cyl}}}


\newcommand{\reals}{\mathbf{R}}
\newtheorem{theorem}{Theorem} 
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{claim}{Claim} 

\newtheorem{problem}{Problem}
\newtheorem{question}{Question}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}

\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}

% \acrodef{pomdp}[POMDP]{partially observable Markov decision process}
  \acrodef{mdp}[MDP]{Markov decision process} 

% \newcommand{\strictpref}{\triangleright}
% \newcommand{\weakpref}{\trianglerighteq}
% \newcommand{\indifferent}{\sim}
% \newcommand{\incomparable}{\bowtie}
% \newcommand{\decoy}{\mathsf{decoy}}

% \newcommand{\prefnodes}{\mathcal{W}}
% \newcommand{\prefnode}{W}
 
% \newcommand{\prefedges}{\mathcal{E}}
% \newcommand{\init}{I}
 \newcommand{\abs}[1]{\lvert #1 \rvert}
 
 % Used for optimization (by Shuo Han)
 \DeclareMathOperator*{\optmin}{\textrm{minimize}}
 \DeclareMathOperator*{\optmax}{\textrm{maximize}}
 \DeclareMathOperator*{\optmins}{\textrm{min.}}
 \DeclareMathOperator*{\optmaxs}{\textrm{max.}}
 \DeclareMathOperator*{\optst}{\textrm{subject to}}
 \DeclareMathOperator*{\optsts}{\textrm{s.t.}}
  \newcommand{\norm}[1]{\lVert #1 \rVert} 
 
%  % useful non-bold operators
 \newcommand{\eqbydef}{\mathrel{\stackrel{\Delta}{=}}}
 \newcommand{\eqbyset}{\mathrel{\stackrel{\mathrm{set}}{=}}}
 \newcommand{\argmax}{\mathop{\mathrm{argmax}}}
 \newcommand{\argmin}{\mathop{\mathrm{argmin}}}
 
  
  \newcommand{\Expect}{\mathbb{E}}

   % conditional preference

     \newcommand{\last}{\mathsf{last}}
\newcommand{\calA}{\mathcal{A}}
 \newcommand{\init}{\iota}
 
% partial observation 
  \newcommand{\obs}{\mathsf{obs}}
  \newcommand{\calP}{\mathcal{P}}
  \newcommand{\calS}{\mathcal{S}}

  \newcommand{\calAP}{\mathcal{AP}}

\newcommand{\prefvertices}{\mathbb{F}}
\newcommand{\prefedges}{\mathcal{E}}
\newcommand{\strictpref}{\triangleright}
 \newcommand{\incomparable}{\bowtie}
 % \acrodef{ltl}[LTL]{Linear Temporal Logic}
 %  \acrodef{ltlf}[LTLf]{Linear Temporal Logic over Finite Traces}
 % \acrodef{dfa}[DFA]{Deterministic Finite Automaton}
 % \acrodef{pdfa}[PDFA]{Preference DFA}
% \acrodef{asw}[ASW]{Almost-Sure Winning}


 
\newcommand{\mc}{\mathsf{MC}}
\renewcommand{\Pr}{\mathsf{Pr}}
\newcommand{\nash}{\pi_1^{\mathsf{NE}}}
% \newcommand{\nash22}{\pi_2^{2,\mathsf{NE}}}
 \newcommand{\probs}{\mathbf{P}}


\acrodef{mdp}[MDP]{Markov decision process}
\acrodef{hmm}[HMM]{hidden Markov model}
\acrodef{pomdp}[POMDP]{partially observable Markov decision process}

\newcommand{\Qstar}{Q^{\star}}
 

 \newcommand{\Ro}{\bar{R}}  % Original R_2 (o stands for ``original'')
\usepackage{todonotes}

% new notations for observable operators
\newcommand{\matA}{{\mathbf{A}}}
\newcommand{\matT}{{\mathbf{T}}}
\newcommand{\matO}{{\mathbf{O}}}