\section{Related Works}
\subsection{Adversarial Attack against Re-id}
Re-id models are widely deployed in surveillance systems with stringent security requirements, making their robustness against malicious attacks a critical concern. Unlike classification tasks, re-id is an image retrieval task, and numerous white-box attack methods leveraging adversarial feature similarity metrics have been proposed ____. Given that attackers often need to target unknown models and unseen queries in real-world scenarios, several studies ____ have explored cross-model and cross-dataset transferable attacks for black-box re-id systems.
Yang \etal ____ and Subramanyam ____ improved cross-dataset transferability by utilizing multi-source datasets in meta-learning framework for additive and generative attacks, respectively.
Wang \etal ____ presented a Mis-Ranking formulation and multi-stage discriminator network to extract general and transferable features to boost cross-dataset general attack learning. Ding \etal____ introduced a model-insensitive regularization technique designed to facilitate universal attacks across diverse CNN architectures. Meanwhile, Yang \etal____ proposed a combinatorial attack strategy that integrates functional color manipulation and universal additive perturbations to boost the transferability of attacks across both models and datasets.

\begin{figure*}[t]
    % \setlength{\abovecaptionskip}{-0.05cm}
    \setlength{\belowcaptionskip}{-0.3cm}
    \centering
    \includegraphics[width=1.0\linewidth]{figs/fig2.pdf}
    \caption{
        The overview of the proposed Attribute-aware Prompt Attack (AP-Attack) method for person re-id. Our AP-Attack follows two stages. First, attribute-aware inversion networks are trained in the contrastive learning manner with benign pedestrian images and composed text prompts. Then, the trained inversion networks are used to guide the prompt-driven semantic attack.
        The generated adversarial examples $x^\prime$, benign images $x$ and batch images $x_b$ are fed into surrogate model and VLM visual encoder to produce inverted semantics and surrogate features of them. 
        The adversarial generator is optimized by pushing the adversarial semantics away from the benign ones and pulling them towards the least similar semantics in semantic spaces of each pedestrian attribute and surrogate feature spaces.}
    \label{fig:2}
\end{figure*}

\subsection{VLM-guided Adversarial Attack}
Vision-language models have garnered significant attention for their ability to learn highly generalizable representations through contrastive pretraining on large-scale image-text pairs ____. 
% These models have demonstrated strong performance in capturing versatile features across modalities, making them valuable for a wide range of downstream tasks, including video understanding ____, image caption ____, and text-to-image synthesis ____. 
Given their broad generalization capacity and alignment of visual and language spaces, VLM have become an appealing target for adversarial attacks. Abhishek \etal ____ introduced GAMA, the first VLM-based attack targeting multi-object scenes, using text prompts to force adversarial images to align with the least similar text embeddings. Fang \etal ____ enhanced the transferability of multi-target adversarial attacks by incorporating VLM textual knowledge to exploit the rich semantic information of target categories. Ye \etal ____ devised an optimization strategy to enhance transferability through iterative attacks on visual inputs while defending text embeddings. Yang \etal ____ proposed PDCL-Attack to facilitate the generalization of classes text feature by prompt learning and formulated a prompt-driven contrastive loss to guide the attack training.
Notably, these VLM-based attack methods are tailored for classification task, leveraging class-specific text labels for guidance. However, re-id aims to distinguish individual identities within the single `person' class, making these approaches unsuitable. The PDCL-Attack method is an exception, as it applies prompt learning to generate prompts for each class. However, its reliance on global semantic features may lead to excessive optimization of highly discriminative features, limiting its effectiveness for thorough destroy for pedestrian images.

In contrast to current person re-id attacks and other VLM-based attacks, our approach seeks to thoroughly undermine fine-grained semantic features by leveraging attribute-aware textual inversion networks, utilizing the image-text comprehension capabilities of VLM.