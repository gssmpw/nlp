\section{Conclusion and Future Work}

We presented the first computationally efficient algorithm \texttt{DCK-UCB} (\Cref{alg}) for Continuous $K$-Max Bandits with value-index feedback, resolving fundamental challenges in handling general continuous outcome distributions in $K$-Max Bandits and achieving the first sublinear regret guarantees $\wt{\gO}(T^{3/4})$. 
% Our proposed algorithm \texttt{DCK-UCB} (\Cref{alg}) achieves $\wt{\gO}(T^{3/4})$ regret upper bound (\Cref{thm:main}) through two key innovations: a bias-corrected discretization method that allows a nearly-optimal offline oracle PTAS \citep{chen2016combinatorial} and a novel concentration analysis addressing non-deterministic tie-breaking effects inherent in continuous-to-discrete conversions. 
When considering exponential distributions as a special case of continuous $K$-Max bandits, we demonstrated that an MLE-based algorithm \texttt{MLE-Exp} (\Cref{alg:k-min}) can achieve the $\wt{\gO}(\sqrt{T})$ regret upper bound (\Cref{thm:kminexp}) even under full-bandit feedback, which further advances the general result.

Further enhancing the $\wt{\gO}(T^{3/4})$ regret for the general continuous distribution case is an interesting future direction. One potential avenue involves developing variance-aware algorithms that adapt to second-order statistics of the outcomes. Such methods might theoretically reduce the regret to $\wt{\cO}(T^{2/3})$ through refined analysis for the variance-adaptive exploration bonus terms, inspired by its successful applications in CMABs \citep{liu2023contextual,liu2024combinatorial}. However, such approaches face inherent challenges due to the biased estimations induced by nondeterministic tie-breaking, which create new concentration challenges for variance terms of biased observations. Overcoming these limitations may require developing new bias-corrected concentrations for variance estimators or alternative feedback models tailored to continuous outcomes. 
Other directions include developing lower bounds and relaxing the bi-Lipschitz assumption.


