%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\usepackage{geometry}
\geometry{a4paper, scale=0.7}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts

\usepackage{titletoc}
\usepackage[toc, page, header]{appendix} %%% MAKE SURE TO PUT THIS BEFORE hyperref PACKAGE

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 

\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue,urlcolor=black]{hyperref}


\newcommand{\theHalgorithm}{\arabic{algorithm}}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{natbib}

\usepackage{bbding}

\renewcommand{\algorithmiccomment}[1]{ \hfill $\triangleright$ { #1}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage[capitalize,noabbrev]{cleveref}

\input{math_commands}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newcommand{\compilehidecomments}{false}%HIDE comments
\ifthenelse{ \equal{\compilehidecomments}{true} }{%
	\newcommand{\wei}[1]{}
	\newcommand{\yu}[1]{}
	\newcommand{\siwei}[1]{}
    \newcommand{\longbo}[1]{}
}{
	\newcommand{\wei}[1]{{\color{blue}{[Wei: #1]}}}
	\newcommand{\yu}[1]{{\color{cyan}[\text{Yu:} #1]}}
	\newcommand{\siwei}[1]{{\color{red}[\text{Siwei:} #1]}}
    \newcommand{\longbo}[1]{{\color{orange}[\text{Longbo:} #1]}}
}

\title{Continuous K-Max Bandits}


% \usepackage{authblk}
%\author{Yu Chen \thanks{IIIS, Tsinghua University. Email: \texttt{chenyu23@mails.tsinghua.edu.cn}.}
%\and
%Longbo Huang \thanks{IIIS, Tsinghua University. Email: \texttt{longbohuang@tsinghua.edu.cn}.}
%\and
%Siwei Wang  \thanks{Microsoft Research Asia. Email: \texttt{siweiwang@microsoft.com}.}
%\and
%Wei Chen\thanks{Microsoft Research Asia. Email: \texttt{weic@microsoft.com}.}
%}



\author{Yu Chen$^{1}$\thanks{\ denotes equal contributions. Corresponding author: Wei Chen (\texttt{weic@microsoft.com})}
\hspace{0.1cm} 
Siwei Wang$^{2*}$\hspace{0.1cm} 
Longbo Huang$^{1}$\hspace{0.1cm}  
Wei Chen$^{2}$\Envelope
\\
   \normalfont $^1$IIIS, Tsinghua University \\
   % (\texttt{\{chenyu23@mails.tsinghua.edu.cn,}
   % \\\qquad\qquad\qquad\qquad\qquad\qquad
   % \texttt{longbohuang@tsinghua.edu.cn\}})\\
  $^2$Microsoft Research Asia 
  % (\texttt{\{siweiwang,weic\}@microsoft.com}) %\\
  %$^3$IIIS, Tsinghua University
  %(\texttt{longbohuang@tsinghua.edu.cn}) \\
  %$^4$Microsoft Research Asia
  %(\texttt{weic@microsoft.com})
  \\
  \texttt{chenyu23@mails.tsinghua.edu.cn} \\
  \texttt{siweiwang@microsoft.com} \\
  \texttt{longbohuang@tsinghua.edu.cn}\\
  \texttt{weic@microsoft.com}
}
\date{}

\begin{document}

\maketitle





\begin{abstract}
We study the $K$-Max combinatorial multi-armed bandits problem with continuous outcome distributions and weak value-index feedback: each base arm has an unknown continuous outcome distribution, and in each round the learning agent selects $K$ arms, obtains the maximum value sampled from these $K$ arms as reward and observes this reward together with the corresponding arm index as feedback. This setting captures critical applications in recommendation systems, distributed computing, server scheduling, etc. The continuous $K$-Max bandits introduce unique challenges, including discretization error from continuous-to-discrete conversion, non-deterministic tie-breaking under limited feedback, and biased estimation due to partial observability. Our key contribution is the computationally efficient algorithm \texttt{DCK-UCB}, which combines adaptive discretization with bias-corrected confidence bounds to tackle these challenges. For general continuous distributions, we prove that \texttt{DCK-UCB} achieves a $\widetilde{\mathcal{O}}(T^{3/4})$ regret upper bound, establishing the first sublinear regret guarantee for this setting. Furthermore, we identify an important special case with exponential distributions under full-bandit feedback. In this case, our proposed algorithm \texttt{MLE-Exp} enables $\widetilde{\mathcal{O}}(\sqrt{T})$ regret upper bound through maximal log-likelihood estimation, achieving near-minimax optimality. 

\end{abstract}

\input{tex_file/introduction}
\input{tex_file/formulation}
\input{tex_file/kmax}
\input{tex_file/kminexp}
\input{tex_file/conclusion}


% \section*{Impact Statement}
% This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

\bibliography{ref}
\bibliographystyle{apalike}


\newpage
\appendix
% \onecolumn
\appendixpage

\startcontents[section]
\printcontents[section]{l}{1}{\setcounter{tocdepth}{2}}
\newpage

\input{tex_file/appendix-kmax}
\input{tex_file/appendix-kminexp}





\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
