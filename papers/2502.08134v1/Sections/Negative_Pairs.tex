
\section{Crafting Effective Negative Pairs}
\label{sec: Negative_Pair}

\subsection{Hard Negative Selection}

Hard negatives are those negative samples that are particularly similar to the anchor (the positive sample) in the embedding space, making them more likely to be misclassified. By incorporating such samples, the model is forced to refine its representation, learning more discriminative features to distinguish between fine-grained differences. These hard negatives are then fed into the encoder along with the positive pair, as shown in Fig. 3(a).

MoCHi, \textit{(M)ixing (o)f (C)ontrastive (H)ard negat(i)ves} \cite{Hardnegativemixing}, creates hard negatives by combining features of existing hard negatives in the embedding space. It identifies existing negatives for a given anchor that are most similar to the candidate positive sample in the embedding space and combines these hard negatives at the feature level to create synthetic negatives that are even closer to the anchor, increasing the difficulty of the contrastive task.

Uncertainty and Representativeness Mixing (UnReMix) \cite{unremix} selects negative samples based on three key properties. Anchor similarity ensures that negative samples closely resemble the anchor but belong to different classes. Model uncertainty prioritizes negative samples with higher prediction uncertainty, focusing the learning process on less confident regions of the data space. Representativeness emphasizes selecting negatives that reflect the overall data distribution rather than outliers. Similarly, \cite{robinson2020contrastive} samples negatives close to the anchor in the embedding space.  These negatives are generated adversarially or synthesized through feature interpolation, promoting fine-grained learning. A balanced mix of hard and easy negatives ensures stability and prevents overfitting during training.

Yet another approach \cite{hu2021adco} follows a min-max optimization framework, where the encoder minimizes the contrastive loss by learning to separate positives from negatives while the negative adversaries maximize the loss by generating challenging and indistinguishable negatives.





\subsection{Removal of False Negatives}
False negatives are samples from different images with the same semantic content, therefore they should hold certain similarity. Contrasting false negatives induces two critical issues in representation learning: 1) discarding semantic information and 2) slow convergence due to the addition of noise in the learning process. For instance, a cat's head in one image might be attracted to its fur (positive pair) but repelled from the similar fur in another image of a cat (negative pair), creating conflicting objectives. Eliminating false negatives involves taking a batch of negative samples and removing those highly similar to positives, as shown in Figure 3(b). The rest of the samples in the batch undergo augmentations and are sent to the encoder along with the positive pairs.

\cite{huynh2022boosting} introduces methods to identify these false negatives and proposes two strategies to mitigate their impact: elimination and attraction. Elimination identifies and excludes potential false negatives from the negative sample set, preventing the model from learning misleading distinctions. In contrast, false negative attraction reclassifies them as positives(makes them true positives), encouraging the model to learn representations that acknowledge their semantic similarity. Similarly, \cite{chen2021incremental} dynamically detects false negatives based on semantic similarity and reclassifies them as positives, thus reducing noise in the learning process. 

\cite{chuang2020debiased} takes a different approach to mitigate the impact of false negatives in contrastive learning by introducing a re-weighted loss function. This loss adjusts the contribution of each negative sample based on its likelihood of being a true negative without requiring label information. The approach improves representation learning by minimizing the influence of false negatives, achieving better performance in self-supervised settings across various domains.
These techniques help ensure the negative pairs are relevant and the generated embeddings are aligned to the downstream task.


\subsection{Synthetic Hard Negatives}
Synthetic negatives can be created using various techniques, including generative models, feature space interpolation, or rule-based algorithms that modify existing data. Once created, their augmentation and positive pairs are sent to the encoder, as shown in Fig. 3(c).

\textit{Synthetic Hard Negative Samples for Contrastive Learning} \cite{dong2024synthetic} involves mixing existing negative samples in the feature space to create more challenging negatives synthetically. To address the issue of false negativesâ€”samples incorrectly labeled as negative but semantically similar to the anchor, this work incorporates a debiasing mechanism, ensuring the model focuses on truly dissimilar negative samples. 
%For a given anchor sample, the method selects the hardest negative samples from the available negative set based on their similarity to the anchor. 
The selected hard negatives are then combined through linear interpolation to create synthetic negative samples that are even closer to the anchor in the feature space. 
%This ensures that the generated negatives are challenging enough to improve the model's discriminative ability.

Similarly, another approach \cite{giakoumoglou2024synco} builds upon the MoCo framework \cite{he2020momentum} to create diverse synthetic hard negatives on the fly with minimal computational overhead. It generates negatives by interpolating between positive and negative samples in the feature space, extrapolating beyond the positive sample in the direction of a negative sample, applying small perturbations to positive samples to generate negatives, and using adversarial methods to craft indistinguishable negatives.