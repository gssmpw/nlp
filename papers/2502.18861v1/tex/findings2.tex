\section{Findings: Challenges of Integrating Online Restorative Justice Tools} \label{findings2}
While restorative justice tools may create opportunities within the outlined space, this doesn't come without drawbacks. Our second research question focuses on the challenges of embedding restorative justice principles within a technological framework, 
%deriving insights from participants' discussion and reflection on ApoloBot's deployment.
\revisionn{
informed primarily by participants’ broader discussions during Phase 1 and also by reflections on ApoloBot’s deployment during Phase 3.
}

\subsection{Adapting to the complex and unpredictable nature of interpersonal harm} 
\subsubsection{Contextual Awareness}
One fundamental challenge for restorative justice tools is capturing the contextual nuances of interpersonal harm. Technological tools, including bots, operate based on predefined sets of actions, which can fall short when handling complex human interactions. In the case of ApoloBot, moderators are required to specify one offender and one victim for the apology process. However, participants noted that real-life dynamics are not always so clear-cut. Conflicts can involve multiple offenders and victims, their roles can overlap as the case escalates, or victims may remain completely unidentified. This challenge raises questions of when and how to balance the use of automation with human judgment. 

\subsubsection{Timing} Interpersonal harm often arises spontaneously and escalates unpredictably, making it difficult to determine an optimal time for tool intervention. There exists a niche window for appropriate use: a late response may allow issues to escalate, requiring more serious moderation actions, while early intervention by proactive moderators may negate the need for tools. Similarly, participants highlighted tensions regarding harm frequency: More frequent harm means more chances to utilize these tools, but it may also indicate the server's more permissive norms toward negative behaviors that can diminish successful restorative interventions. Yet too little harm~---~and correspondingly fewer opportunities to use tools like ApoloBot~---~may lead moderators to prefer manual interventions since \textit{``If it only happens on occasion, it's much easier to take care of them ourselves.'' }(P3). However, some participants saw value in having restorative tools as a safeguard, even if rarely used: \textit{``Having a bot is like a preventive measure. You have it in case something happens, that's why everyone has anti-raid even if they've never been raided.''} (P6). 

\subsection{Handling stakeholders' dropouts}
Interpersonal harm involves multiple stakeholders, and beyond their willingness to participate, it's important to consider their willingness to commit to the process throughout. In any tool that requires sustained participation, dropout will occur, and it is not yet known what the impact of partially-completed apologies might be.

\subsubsection{Victims' reasons for dropout} Victims may change their minds as the situation develops, reconsidering whether an apology would suffice to address the harm done, or they may request an apology but then be unsatisfied with the response. In these cases, moderators might need to do follow-up to understand the issue and determine what alternative steps should be taken. The worst case might be when victims receive no response at all to a request for an apology~---~as opposed to a direct negative response~---~since they may lose trust in the system and experience further emotional harm. As P12 noted:
\begin{quote}
    \textit{``Let's say the victim in their request, they were very heartfelt and genuinely wanted an apology, and fully expecting the offender to provide it. But if they can't receive a response, maybe either the offender just ran away with it or they responded in a way that the moderator deemed harmful. It's often disheartening to know that you've kind of bared your heart open to someone and they've taken advantage of it.''}
\end{quote}
\subsubsection{Offenders' reasons for dropout} Offenders unwilling to apologize may not learn from their mistakes, but even those with the intent to apologize may not always do so effectively. Participants compared ApoloBot to an appeal system, a similar framework where banned users are given chances to request unbans. They observed that it is common to receive inadequate appeals, sometimes with satisfactory ones coming after multiple attempts as offenders receive feedback, reflect, and revise their submissions. Therefore it is likely that apologies might not be at their best quality on the first try, requiring further guidance from moderators. Similarly, when offenders want to mend the relationship but their apology is rejected, they may experience significant emotional distress.

These dropout situations necessitate more thorough intervention, as the tool alone may not fully resolve the issue. More extensive follow-up actions beyond merely accepting or declining apologies may be required, or moderators may need to engage in less structured approaches in handling such cases.

\subsection{Overcoming negative perceptions of technological tools} \label{challenge-perception}
Embedding restorative justice in technical tools such as Discord bots can help initiate and facilitate communication among members, yet this kind of mediation might be perceived negatively under certain conditions. Despite human involvement in crafting the messages (apology request and response), the delivery through a bot might reduce its perceived authenticity. P15 highlighted this concern: \textit{``I think it's just how people interpret bot interactions. And we're very much used to chatbots on websites that are not useful and aren't controlled by a real person overseeing them.''} This inherent skepticism towards bots is rooted in their common stereotype that bots are impersonal and unhelpful. On Discord, this is exacerbated by prominent bot issues such as scams, phishing, and hacking, making users highly cautious when interacting with new tools regardless of their purpose. P3 described how initial negative perception can manifest into misconception, which fueled further negativity during their ApoloBot deployment:
\begin{quote}
    \textit{``Unfortunately we didn't quite well inform people about what it was. And that led to a group of people that were in this sort of echo chamber, where they were sharing misinformation about the bot due to their false understanding of it. [...] The primary one was about data collection. From my understanding, they thought that the bot was automatically collecting data about what everyone said, like an AI tool almost. And then that spread between some people and they were concerned, and be like, we don't want that. What they mentioned was just flat out wrong so we had to come in later and correct in greater detail of what data is collected, what the bot is about, and how it works.''}
\end{quote}
As P3 reflected, this incident quickly spread, leading to large-scale resistance among members, even persisting after clarification. This demonstrated how negative perceptions can create lasting barriers to tool adoption, if not addressed early and thoroughly.

% \subsection{Potential exploitations/misuse}
% \todo{remove or combined above}% 

% \begin{itemize}
%     \item People can learn to break the system
%     \item e.g offender use chatgpt to write apology, not (just) harass victim but harass mods; victim attacks / makes fun of offender / reject apology on purpose
%     \item e.g even security - some hackings? to get their apology approved??
% \end{itemize}% 

% Addressing these challenges is crucial to harnessing the full potential of restorative justice tools. To mitigate these obstacles and enhance their effectiveness, we turn to design implications that could mitigate these issues and align the tool more closely with the needs and expectations of its users% 
