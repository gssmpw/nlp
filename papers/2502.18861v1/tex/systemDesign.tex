\section{System Design: ApoloBot}
\subsection{Context: Discord and Its Moderation Practices} \label{context}
In this study, we choose Discord as our research site due to its community-oriented social structure and the flexibility of its API for tool design. Unlike traditional platforms that emphasize individual profiles, Discord is centered around the concept of \textit{servers}, where communities are formed from small groups of friends to large circles with millions of people. Originally created for gamers as a third-party voice function, Discord servers now serve a variety of topics such as technology, art, and entertainment. Servers can be public~---~where a link is posted online for anyone to join~---~or private, with invitations more strictly limited. Within these spaces, members interact with each other in \textit{channels}, either through text or voice chat. Channels are areas in the server serving specific purposes, such as announcements, general chats, and topic-specific discussions. Moderators in these spaces are usually volunteers who are active community members, though those in some more formally structured servers may be paid. While their responsibilities vary from one server to another, the overarching goal is to ensure the community's safety and well-being as it grows. Moderators' duties may involve establishing community guidelines, engaging in conversations, and supporting members facing issues within the server. When incidents occur, moderators can take action using Discord's built-in functions like mute, ban, or message removal. Recently, Discord introduced AutoMod,\footnote{https://discord.com/tags/automod} an automated feature that assists moderators with tasks like content filters, action settings, infraction logging, and user verification. To further streamline and customize moderation efforts, third-party bots are extensively adopted, being used by nearly one-third of all Discord servers~\cite{Warren2021}. These bots perform various functions, including tracking server status, managing member activities, and issuing moderation actions, among many others. Popular examples are MEE6,\footnote{https://mee6.xyz/} Zeppelin,\footnote{https://zeppelin.gg/} Tatsu,\footnote{https://tatsu.gg/} and Dyno.\footnote{https://dyno.gg/} These automated solutions help alleviate the workload on human moderators, enabling them to focus on more significant issues while bots manage more routine tasks. Bots can also bring a sense of fun and engagement with features like welcome messages, role assignments, and customized activities. 

In addition to its community structure, Discord offers extensive APIs and interactive features for creating custom bots. These accessible resources add to our decision to utilize the platform and develop ApoloBot~---~a tool that embeds restorative justice principles into online community moderation. %we build a fully functional bot that can be added to any community via an invite link and is adaptable to various server setups. 

%Both of these factors–the widespread adoption of bots and the versatility of Discord development resources–motivate us to build on this technological framework and develop ApoloBot, a moderation tool that embeds restorative justice principles. The following sections detail the system implementation and workflow.

\begin{comment}
\subsection{Design Objectives}
Our research builds upon Xiao et al.’s case study examining the early opportunities and challenges for using restorative justice to address online interpersonal harm, also taking Discord as part of the research settings \cite{Xiao2023}. While the work focuses on a manual approach involving victim-offender conferences mediated by a facilitator, we take this further in a more technical approach. Utilizing ApoloBot as a tool dedicated to streamline the restoration process, we tackle the challenge of resource limitations highlighted in the study, thereby exploring additional factors for its effective implementation. We also draw from the challenges and implications of their work to shape our system’s design goals, using it as a primary reference alongside other related studies that inform our approach.

One of the significant challenges in implementing restorative justice is managing the conflicting interests among and within the involved stakeholders. As seen in Xiao et al.’s work, while several victims were open restorative approaches to address their needs and facilitate healing, concerns were raised regarding offenders’ readiness or whether restorative justice can fully resolve issues, particularly when deeper-rooted problems were involved. Offenders showed very little interest in the restorative process, as their attitude remain oriented toward avoiding punishment rather than acknowledging their wrongdoing and genuinely apologize. Our system should allow spaces for stakeholders to engage in meaningful conversations to the fullest extent possible without compelling their participation, which could lead to negative outcomes. 
\begin{quote}
\indent \textit{\textbf{Design Goal 1 (G1):} ApoloBot should be flexible, being able to accommodate the diverse needs and willingness of involved stakeholders.}
\end{quote}

Moderators are also important stakeholders, often acting as the facilitator guiding the restoration process. They meet offenders and victims to address their needs and discuss ways to resolve the harm. In online communities, they are typically responsible for determining the final outcome for offenders, be it punishment or remedy. However, adhering to restorative justice principles, resolution to harm should primarily be decided by victims and offenders \cite{Bolitho2017}. The facilitator’s main role is to give guidance, protect victims from potential harm or insincere remorse from offenders, and finally intervene only when both parties fail to reach an agreement. Ultimately, a balance is needed: while moderators should take part in the facilitation process, the input of both victims and offenders should also carry significant weight in forming the restoration outcome.

\begin{quote}
\textit{\textbf{Design Goal 2 (G2):} ApoloBot should aid moderators in facilitating the restoration process while also granting certain autonomy to users, ensuring that both victims and offenders have a voice.}
\end{quote}

Finally, the success of a tool is not solely about fulfilling functional purposes; it also depends on its adaptability to different communities’ preferences and values \cite{Jiang2023, Kiene2019}. Learning to adopt new tools presents further barriers such as unmatched tech literacy, misunderstanding with developers, unfamiliar communication norms, and increased workload \cite{Long2017, Kiene2019, Geiger2010, Jhaver2019, Seering2019}. While tools can help in addressing certain challenges, their effectiveness relies on how well it is perceived \cite{Orlikowski1992}, implemented, and maintained \cite{Jhaver2019}.

For restorative justice, these challenges are intensified by the stigma of the prevalent punitive model and extensive labor of restorative practices. To minimize these burdens, our focus is on developing tools that are easy to learn, complementing rather than replacing existing systems. In practice, a dual system incorporating punitive and restorative approaches is sometimes used \cite{Llewellyn1999}.

\begin{quote}
\textit{\textbf{Design Goal 3 (G3):} ApoloBot should be easy to learn and integrate with the existing moderation structure of the servers, serving as a valuable addition rather than a replacement.}
\end{quote}

These design goals represent a new set of guidelines for developing online restorative justice tools that fit within existing systems. We developed ApoloBot based on these guiding principles, and further implementation details will be discussed in the following sections.

\end{comment}

\subsection{System Implementation} \label{system} 
ApoloBot was developed with Javascript and operates on Node.js. It utilizes MongoDB as its database and Heroku as the hosting service. The discord.js library was employed to access necessary Discord APIs for managing user interactions and bot features. The bot’s core functionality is based on the slash command \textit{/apolomute}, for which syntax is shown in Figure \ref{fig:slashcmd}. Slash commands are familiar formats among Discord moderators, where punishments are typically executed via \textit{/mute} or \textit{/ban} commands provided by Discord's built-in system or other bots. Moderators can choose different slash commands based on the situation, allowing \textit{/apolomute} to work alongside other moderation commands. This flexibility makes ApoloBot easy to learn and integrate into any moderator's existing framework.

\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{fig/slashcmd.png}
  \caption{The slash command \textit{/apolomute} that is used in the primary workflow. The first four input fields are required, where the moderator specifies the involved offender and victim, along with mute duration and reason. Optionally, proof can be attached as an image, and moderator can choose to first review the victim's apology request by setting `review-request' to True.}
  \Description{The message at the top shows an example of a harmful interaction between two users, involving some insults. Below, there is a chat box where the slash command is inputted. The command begins with a slash (/), followed by its name (apolomute), and includes several required fields: offender, victim, duration, and reason. It also suggests optional fields such as proof and review-request above the chat box.}
  \label{fig:slashcmd}
\end{figure*}

\subsection{Workflow} 
ApoloBot's procedure draws inspiration from the concept of the \textit{victim-offender conference}, a model for online restorative justice practices explored in Xiao et al.’s case study~\cite{Xiao2023}. Within this framework, victims and offenders are encouraged to meet, reflect, and resolve the harm under the guidance of a facilitator, who is the moderator in this context. The moderator's role is to ensure that the process remains safe and constructive, with the final decision ideally determined by the victims and offenders. While the original approach is manual, ApoloBot facilitates a version of this process that is tracked and guided in a style familiar to moderators who are experienced with other Discord bots. 

\revision{
Commonly, commands like \textit{/mute} or \textit{/ban} are utilized as a standardized procedure to impose punishment terms on the offender following an incident of harm. However, this approach might perpetuate a punitive mindset that deters meaningful engagement when switching to restorative justice~\cite{Xiao2023}. Gradual changes are typical in real-world justice systems, and sometimes a dual system incorporating both punitive and restorative measures is employed to cater to the diverse stakeholder needs while adapting to established structures
~\cite{Llewellyn1999}. Building on this, ApoloBot's \textit{/apolomute} extends the conventional mute by offering a potential restorative interaction point, opening an avenue for apology and constructive resolution while retaining certain familiarity with the mute action.} Figure \ref{fig:workflow} outlines an overview of ApoloBot's primary workflow, incorporating the \textit{/apolomute} slash command.

\begin{figure*}[h!]
  \centering
  \includegraphics[width=\linewidth]{fig/workflow-final.png}
  \caption{ApoloBot's Primary Workflow. The diagram shows the different pathways ApoloBot can follow based on stakeholders' decisions to approve or decline their actions. The green blocks represent the interaction points for the moderator, who keeps up with ApoloBot through their log channels. The blue and red ones depict the interaction for the victim and the offender, respectively, in their private threads. Yellow blocks indicate the case is closed and no further steps will be taken.}
  \Description{The start block is in the top left, where "Moderator identifies bad behavior (from offender)" and the workflow is initiated. From here, the process might follow different pathways depending on stakeholders' participation. If everyone approves and responds to ApoloBot prompts, they will reach the end block in the bottom left where "Offender gets released from mute before the specified duration". Otherwise, they end up with the block in the top right, which indicates "Offender gets muted for the specified duration".}
  \label{fig:workflow}
\end{figure*}

The workflow begins similarly to \revision{many current moderator response flows:} upon recognizing inappropriate behavior, the moderator mutes the offender. However, ApoloBot adds a step by involving the victim to initiate the apology process with the offender, and moderators facilitate this by specifying both the victim and the offender in the slash command syntax (Fig \ref{fig:slashcmd}). Once the command is executed, ApoloBot creates two separate threads\footnote{https://support.discord.com/hc/en-us/articles/4403205878423-Threads-FAQ}~---~one for the victim and one for the offender~---~where the interaction between ApoloBot and these stakeholders will take place. For the moderators, they interface with ApoloBot through a dedicated log channel.

In the victim's private thread, ApoloBot informs them that the offender has been muted for harmful behavior and offers the option to request an apology. If chosen, this option grants the offender a second chance to make amends and potentially have the punishment lifted. If the victim chooses to proceed, they are prompted to enter their apology request via a popup textbox (Fig \ref{fig:private-thread-victim}). 

\begin{figure*}[btp]
  \centering
     \begin{subfigure}{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{fig/private-thread-victim.png}
         \caption{Victim's private thread for requesting an apology}
         \label{fig:private-thread-victim}
         \Description{The two pictures illustrate the interaction between ApoloBot and the victim in their private thread. The first picture shows the text message ApoloBot sends, which informs the victim about the case and asks if they want to request an apology. Two buttons below are provided for the victim's decision: "Yes" and "No". The second picture shows the subsequent screen after the victim selects "Yes". ApoloBot displays a popup text box, with a text field for the victim to fill in their apology request. In the bottom right, there is a "Submit" button to send this request.}
     \end{subfigure}
     \hfill
     \begin{subfigure}{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{fig/private-thread-offender.png}
         \caption{Offender's private thread for requesting an apology.}
         \label{fig:private-thread-offender}
         \Description{The two pictures illustrate the interaction between ApoloBot and the offender in their private thread. Similarly, the first picture shows ApoloBot's text message. It contains the quoted apology request from the victim, and asks if the offender wants to respond with an apology. This is followed by two "Yes" and "No" decision buttons. The second picture also shows the next screen after selecting "Yes", where ApoloBot shows a popup text box. The offender fills in their apology response in a text field, and sends this via the "Submit" button.}
     \end{subfigure}
  \caption{Examples of private threads ApoloBot created from the victim's side and the offender's side.}
  \Description{}
  \label{fig:private-threads}
\end{figure*}

Following this, ApoloBot notifies the offender in their private thread that their mute can be lifted if they deliver an appropriate apology to the victim. If the offender decides to comply, they are prompted to write their apology response via a similar popup textbox (Fig \ref{fig:private-thread-offender}). 

Throughout the process, moderators receive updates from ApoloBot at every step. After receiving the apology request and response, they are responsible for reviewing the offender’s response to ensure its appropriateness (Fig \ref{fig:logs}). If approved, the apology is forwarded to the victim, who then has the final say. If the victim accepts the apology, ApoloBot notifies moderators and they can unmute the offender accordingly. 

\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.6\textwidth]{fig/log.png}
  \caption{Examples of ApoloBot logs received by moderators.}
  \Description{The picture shows a series of logging messages sent by ApoloBot to the moderator, providing updates on a specific case. On the top bar, the name of the log channel is shown, followed by the thread name (update-case-5). The main interface presents messages in distinct blocks, each detailing information such as the victim and the offender's name, the current process step, and specific updates like the Victim Request or Offender Response. In the final (bottom) message block, it indicates that everyone in the process has approved, and includes a button labeled "Unmute Offender" that the moderator can click to perform the action.}
  \label{fig:logs}
\end{figure*}

This approach translates the traditional \textit{victim-offender conference} into a technical process via ApoloBot: The interactive exchange between offenders and victims allows each party to voice their perspectives when deciding the restoration outcome, and the facilitation of moderators ensures this process goes smoothly without incurring additional harm. 

At any stage, if the victim, the offender, or the moderator declines to proceed, or if the designated time expires, the process reverts to the standard punitive measures where the offender remains muted for the specified duration. This is in line with real-life restorative practices, where complete consensus may not always be feasible. 
\revision{Forcing forgiveness from victims or remorse from offenders, however, may compromise the victims' autonomy and lead to disingenuous offender responses~\cite{Llewellyn1999, Bazemore2015}.}
The system therefore supports partial participation, ensuring that engagement is voluntary and all stakeholders’ decisions are respected.