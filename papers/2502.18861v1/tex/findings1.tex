\section{Findings: The Opportunity Space for Online Restorative Justice Tools} \label{findings1}
Using ApoloBot as an example and starting point for discussing the broader landscape of online restorative justice tools, we present findings in relation to the opportunities and challenges highlighted by our research questions. First, this section addresses the potential for restorative justice tools \textbf{(RQ1)} by examining the opportunity space--a framework that outlines the conditions and environments where restorative justice tools can be applied effectively and bring positive impacts. Section \ref{findings2} then explores the challenges \textbf{(RQ2)} that accompany the integration of such tools.

We begin by analyzing the opportunity space, which encompasses three main scopes emerging from our interviews, with each serving distinct purposes: \textit{Community}, which influences initial adoption based on the tools' alignment with the community’s values; \textit{Moderation Practices}, determining how well they integrate into existing moderation workflows; and \textit{Case Scenarios}, focusing on the specific situations where they can be most effectively applied.

\subsection{Community: Considerations for Initial Adoption}
The decision to adopt restorative justice tools depends on specific community dynamics and characteristics. This section elaborates on the factors influencing communities' readiness for these tools, highlighting the conditions under which initial adoption is most feasible.

\subsubsection{Community Topics and Culture}
The perceived identity of a community is inseparable from the norms for behavior therein, guiding moderation practices. One recurring theme from participant interviews was the influence of a server’s primary focus or topic on the suitability of ApoloBot adoption. Per participants' responses, communities that are most likely to benefit from a restorative approach are ones with a more social focus or themed around human-centric topics. These include servers built around influential individuals or entities, such as content creators, companies, or collaborative platforms. In these spaces, tools are widely adopted for effective organization, and interaction quality among members is also highly valued as it directly impacts the reputation of the central figure or organization. P7, a content creator who moderates their own community, reflected: 
\begin{quote}

\textit{“I have my personal server that's based around the content I make. Here, me and the moderators try to make sure that we have a united fan base, since the more everyone gets along, the better it is for not only the community but also me as the creator, since I can have healthy and engaging audiences. [...] I noticed apologizing allows for really good reconciliation, so it was nice seeing this kind of system being able to make everyone happy in the end. Or at least in good standing with each other.''}

\end{quote}

Healthy resolutions facilitated by a restorative approach not only help the involved parties reconcile but also reflect positively on the influencer. P3 echoes this perspective: \textit{“[It will] align better with their brand, and it would spread, and people would talk about it, and that reinforces good brand equity.''} 

Similarly, moderators of communities that share common interests in topics valuing human interaction and inclusivity~---~such as language learning, mental health, or arts~---~see tools like ApoloBot as valuable for fostering their growth. P12 described these spaces as \textit{“where people are already intended to talk to each other and try to improve as a person''}. Restoration through apologies facilitates deep layers of communication and empathy, supporting these servers' vision of bettering members' well-being.

Conversely, communities that do not prioritize social interaction may find tools like ApoloBot less relevant. For example, servers dedicated to formal or ephemeral topics, like technical support or quick Q\&A exchange, lacked the sustained engagement and relational depth that restorative tools generally require. P11 provided the examples, stating \textit{“I don't think the idea of this bot helps since people are just in the server to solve a specific problem, or get an answer for a specific question, then just leave.”} In communities like this, members have little to no emotional investment in the server or toward each other: \textit{``People will be like `Why should I even apologize'?''} (P3). On the other hand, communities with large volumes of lower-quality social interaction~---~possibly due to negative norms associated with the genre~---~may also struggle to adopt this type of tool. P4, who moderates a server based on a major competitive game, expressed their frustration:

\begin{quote} \textit{“A lot of people get influenced by social media, and they have this mindset that it’s the norm to be toxic here. It’s very extreme, like if you imagine video games are commonly toxic then this game is ten times that. So they would come in the server with this idea in mind and be toxic, and of course they wouldn't even care to apologize even having the option to do so.”} 
\end{quote}

This highlights a fundamental challenge to the adoption of restorative tools; on platforms where inter-community mobility is high and commitment to each member is low, individuals may not be motivated to resolve conflicts constructively. P14 faced a similar issue moderating another gaming server with predominantly young members, describing that the combination of the game's nature and the immaturity of its players lead to people being \textit{``rebellious''} and \textit{``never feel[ing] remorse about what they do.''} 

In these servers, the high incidence of harm might introduce more opportunities for restorative justice tools to be utilized, yet the expected effectiveness might be limited. P14 explains the situation as having \textit{“a greater risk of people abusing the system, but a greater reward of people actually learning what they're doing wrong.”} In fact, many moderators weighed the ``risks'' more heavily than the ``rewards,'' which was a key factor in their decision not to proceed with deploying ApoloBot in Phase 2. In extreme cases, moderators pointed out that some members might not take it seriously, viewing it as a target for jokes or dismissing apologies as \textit{``weak''} or \textit{``cringe''}, further perpetrating the existing negative dynamics.

\subsubsection{Server Size}
The size of the server may also influence tool adoption: Mid-size servers with steady influx of new members are perceived to be the most ideal. They offer spaces where \textit{“there's enough room for people to disagree and potentially cause harm, and for moderators to adequately handle it''} (P3). In contrast, very large servers may experience overwhelming moderation workloads with fewer social commitments: \textit{``The chat goes 300 miles a second. And we look at something, [take] action, then move on with other stuff.'' }(P4) On the other hand, very small servers simply may not find the need for new tools, since moderators may have the capacity to facilitate conversations without needing technical support.

% In summary, the success of restorative tools adoption is closely tied to the community’s focus and its population size, which determine members' willingness to engage with the tool meaningfully. In places where inclusivity and constructive interactions are valued, ApoloBot can push forward these values, embracing a more supportive environment. This impact is especially pronounced in settings with moderate server sizes. In contrast, in communities where interactions are brief, impersonal, or rooted in unhealthy norms, these tools might not be as effective or welcomed. 

\subsection{Moderation Practice: Fitting into Current Strategies}
Moderators uphold community values through a variety of moderation strategies, which influence whether tools like ApoloBot can be compatible with their existing practices. This section explores how different approaches to moderation~---~viewed as trade-offs rather than strictly positive or negative~---~affect the practical implementation of restorative justice.
% A good fit means that ApoloBot extends moderators' existing practices, while a mismatch indicates potential irrelevance or opposition, as detailed below.

\subsubsection{Mediation Approach: Conversation vs. Action}

One critical perspective involves whether moderators' focus aligns with restorative justice values, or whether constructive conversations or punitive actions are prioritized. Successful integration of restorative justice tools requires more than preference; it involves adapting current practices to accommodate the contextual and emotional processes inherent in restorative justice principles. When discussing ApoloBot, moderators pointed out that it is \textit{``more than a binary decision of yes and no, accept or decline''} (P1), as a sense of sensibility is needed to discern first when to use the tool, and then how to evaluate apologies reasonably. This ability is more likely to be found in moderation teams that have established procedures and skills focused on fostering conversations. For instance, P3's workflow features a ``ladder of escalation'' including a defined set of steps that already align fairly well with principles in restorative justice: Interaction, Education, Action, and Moderation. ApoloBot was perceived to fit well within the first two steps where moderators engage with offenders before escalating to further punishments. By contrast, teams with reactive approaches to moderation may lack these perspectives, potentially leading to inefficient tool use and inadequate engagement from members. While these skills can be developed over time, doing so demands significant mental and physical labor, raising barriers for community moderators who are already stretched thin.

Perhaps surprisingly, our user study revealed that the tool appeals most to moderators who align with its values partially but not completely. Those who highly value interaction often prefer to handle conflicts manually, as P9 noted \textit{``Bots should only be assistive, and the key moderation "tool" should be how you portray yourself, and how you listen to other people''}. Conversely, some action-oriented moderators found potential in the tool. P6, whose moderation team previously experienced burnout from high interaction demands to a small moderation scale, sees ApoloBot as a way to ease this burden and re-engage in meaningful conversations with members.

\subsubsection{Flexibility: Fluid vs. Rule-based}

Moderation flexibility determines adaptability. Although apologies are familiar concepts and generally perceived positively, using them as structured tools to resolve online conflicts is not common. This novelty can be viewed in different ways~---~as an opportunity or as a challenge. For moderation teams with fluid dynamics, where procedures are more casual and less rigid, moderators can readily adjust their procedures to experiment with new approaches. Tools like ApoloBot provide offenders a chance to reconcile with victims, but their use is context-dependent and moderators must determine when to offer this leniency. Flexible teams provide time and space for restorative sessions to evolve, improving as moderators gain experience and trust in the process.

On the other hand, systematic and rule-based moderation structures~---~often found in very large or professional servers~---~may find the addition of tools like ApoloBot burdensome or disruptive. Rules on these servers are usually standardized, \textit{“It’s like black and white. You did this so you receive this, you follow the rules or you don't. There is less space to fit restorative justice in between”} (P3). P4 expressed how handling a large-scale server raises the bar for tool adoption and rule enforcement: 
\begin{quote} \textit{``In these places, being "flexible" might mean being messy since the moderation scale is just too large. Consistency and convenience are therefore things we value the most. ApoloBot poses a problem to both of these because firstly, different moderators might evaluate apologies differently, and secondly, the tool would require its own, independent category, which only certain dedicated moderators can handle. Given we already have so many other things going on with hundreds of channels and millions of members, I don't think this addition would be practical.''}
\end{quote}
Deviation from established norms in these servers requires significantly more commitment and resources, therefore moderators in these spaces are less likely to be enthusiastic about adopting tools like ApoloBot.

\subsubsection{Temporal Perspective: Long-term vs. Short-term Goals}
Finally, the moderators' temporal vision defines whether tools like ApoloBot are regarded as ``efficient'' for their moderation practice. ApoloBot is seen to be not favorably “efficient” in the immediate sense, as it takes time to mediate and evaluate ongoing communications among offenders and victims. Some moderators prefer prompt action, especially in highly active communities where interactions, including harmful ones, progress rapidly. \textit{“I’m just looking through the commands channel real quick and see, three days ago there were some guys spamming and being just weird like [sending] NSFW and the n-word. About three people within the span of not even one hour. Then we banned this guy for racism. A day after someone got warned for baiting, someone got banned for a DM spam. [...] People just do the craziest things, so we have to act fast.”} (P6) In these spaces, the high volume and limited time for action demands in-the-moment responses, reducing opportunities for facilitated discussions. On the other hand, some moderators in a more laid-back environment where immediate interventions are less critical, see the long-term ``efficiency'' in a comprehensive and educative approach. As P7 noted:

\begin{quote}
\textit{``Though it takes some time in the time being, making sure everyone gets along in the long run could potentially be more efficient. Because when you're punishing someone and you don't really care too much about apology, people still hold grudges and that could give a lot of drama and bad actors who can upset even more people. And that can create more moderation cases that could create more work for moderators. So it is likely, that by using this system you are removing a lot of future issues that could possibly happen.''}
\end{quote}

In this sense, moderators might spend additional time upfront, if feasible, which can potentially reduce recidivism and thus ease future moderation workload. This long-term investment allows time for tools like ApoloBot to effectively educate users, ultimately fostering more supportive and resilient communities.

\subsection{Case Scenarios: Conditions for Effective Usage}
Once adopted, restorative justice tools must be applied in the right contexts to maximize their impact. This section examines factors specific to the circumstances under which they can be used to resolve conflicts most effectively.

\subsubsection{Types of Interpersonal Harm} Moderators believe emotional and relational harms~---~such as jokes unintentionally coming off offensive, or criticism that turns into insults~---~are often seen as better intended and less serious, thus more fitting for applying restorative justice. These types of harm generally allow for some autonomy in decision-making, and tools like ApoloBot can provide a safe space for people to discuss their issues away from where the harm occurred, thereby helping to defuse emotions and prevent further rages. On the other hand, physical threats (e.g. doxxing) or financial issues (e.g. scams) are considered more severe harms, requiring more immediate and direct intervention. In these cases, initiating conversation might not be appropriate, as it's unlikely to adequately ``pay back'' the caused damage and could even exacerbate the situation. Moderators note that extreme cases may even require higher authorities, such as Discord support or law enforcement, to step in rather than relying on tools.

\subsubsection{Social Ties among Stakeholders} The effectiveness of restorative justice tools is notably enhanced when social ties are present but not overly strong, such as among new members. In these settings, \textit{``the bond is there to appreciate the restoration yet not too much to go out of their way apologizing for the action.''} (P3). Tools can help facilitate these interactions in a less confrontational manner, potentially repairing and strengthening relationships. P11, who successfully employed ApoloBot in several cases, reflected on this impact:

\begin{quote}
    \textit{``Normally, after someone offended others and their mute expired, we keep an eye on how they interact with people, especially the individual they harmed. So I'm seeing in cases I used ApoloBot, the interactions are different if you apologize versus if you don’t. With normal mutes, how these two individuals react after the incident is that they usually become non-friendly, or they hold their bad emotions since the offender wasn’t involved and encouraged to seek reconciliation. With the bot however, after some people had conflicts and they apologized, you could see them becoming normal to each other again since they got all the emotions out. It's something that made me a little bit happy, seeing people react positively afterward.''}
\end{quote}

P11's social game server, where members actively discuss gameplay though aren't closely connected, greatly benefited from ApoloBot in mending relationships after conflicts. In contrast, the tool was perceived as less beneficial at the extremes: With very weak social ties, both offenders and victims may be less concerned about their engagement due to the temporal and anonymous nature of online interactions, and with very strong ties, the involved users are either close friends who would resolve issues privately or users with ``bad blood'' who might refuse to communicate.

Overall, the opportunity space for restorative justice tools can be understood through three key perspectives: \textit{Where} (in which types of community), \textit{How} (through which moderation practices), and \textit{When} (under which scenarios) they are likely to be more or less beneficial. These factors shape the conditions for effective adoption, practice, and usage, as well as the anticipated outcomes and community reactions.

% These are the factors that define the adoption--when the bot is introduced to the community, practice--when the moderators utilize the tool within their mechanism, and usage--when it is used under specific scenarios. These utility space serves as a comprehensive guideline for the opportunities of where, by who and when ApoloBot and restorative justice tools in general can thrive in online communties. Alongside the opportunities, we would also then examine the challenges of integrating these tools as brought up by moderators through interviews and deployments. Finally, from understanding the processes and their challenges, we derive implications crucial for future work, focusing on the lessons learned from the system and areas for improvement.