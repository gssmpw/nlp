\section{Background} \label{sec:background}

\subsection{Silent Data Corruption Errors} \label{sec:sdc_background} 
Silent Data Corruption (SDC) errors are incorrect computation that silently occur during normal usage \cite{papadimitriousilentdatacorruptions2023}. Generally, SDCs can arise from hardware faults \cite{dixit2021silentdatacorruptionsscale, hochschild2021cores}, environmental factors like radiation \cite{ziegler1996terrestrial, mukherjee2005soft, baumann2005radiation}, or software bugs \cite{lou2022demystifying}. 
With growth of large scale distributed systems, SDC is observed to be caused by device-specific hardware defects which show errors at certain utilization levels or temperatures \cite{ dixit2021silentdatacorruptionsscale, hochschild2021cores, wang2023understandingsdc}. 

Our work lies in the broader area of understanding the effect of SDCs on deep learning and we leave a detailed discussion for the related work in Appendix \ref{appendix:sdc_related_work}.
There are two limitations in this area. 
First, fault-injection methods are commonly used for evaluation. Although SDC can be simulated at the hardware level \cite{rech2022reliability, liunderstandingerrorpropagation} or the software level \cite{he2020fidelity, agarwal2022lltfi}, simulated SDCs could be different from those observed in production. 
Second, most works study the impact of SDCs on model inference \cite{liunderstandingerrorpropagation, agarwal2023resilience, ma2023evaluatingenhancingrobustnessdeep} while few study the impact of SDCs on model training dynamics. Although some empirical findings of SDC like NaN (Not-a-Number) issues and degradation during training are reported \cite{adept-sdc, he2023understanding}, there is no work that attempts to characterize and break down the impacts of real-world SDCs especially on large language model training.

\subsection{Large Language Model Training}
In this work, we consider a Large Language Model (LLM) as a transformer decoder \cite{vaswani2017attentionneed}. Training an LLM at scale requires a combination of data parallelism and model parallelism. Tensor parallelism (TP) is a widely used model parallelism approach that partitions each individual layer of a model across accelerators \cite{shoeybi2020megatronlmtrainingmultibillionparameter}. For large-scale LLM training, tensor-parallel size is usually set as the number of accelerators within a node to leverage high bandwidth intra-node communication \cite{narayanan2021efficient}.

Given that hardware failure is usually flagged at the node level and majority of training failures are caused by one node \cite{wang2023gemini}, we focus on the impact of SDCs on the computation of a single node and use tensor parallelism only.

