\section{Implementation \& Experimental Setup}
\label{sec:evaluation}


\noindent
\textbf{Dataset.}
To comprehensively evaluate {\tool}, we have collected two datasets, \textit{i.e.,} a ground-truth dataset ($\mathcal{D}_{G}$) and a large-scale contracts dataset ($\mathcal{D}_L$).
Specifically, $\mathcal{D}_G$ consists of two sub-datasets.
$\mathcal{D}_{G1}$ comprises 84 attack events labeled as price manipulation, sourced from various mainstream platforms~\cite{Defihacklab, slowmist, rekt}, the publicly released datasets of FlashSyn~\cite{chen2024flashsyn} and DeFiRanger~\cite{wu2023defiranger}, and manually verified by two of our authors specializing in DeFi security\footnote{Seven attack incidents labeled by FlashSyn and DeFiRanger are excluded. Please refer to Table~\ref{tab:not_selected} in Appendix for the reasons.}.
Moreover, we heuristically take the number of transactions generated by a contract as the criterion to determine its benign nature. Thus, we use APIs from Etherscan~\cite{EthApi} and data from TokenTerminal~\cite{tokenter} to select the top 8,000 active contracts by transaction volume as non-malicious cases ($\mathcal{D}_{G2}$).
$\mathcal{D}_L$ encompasses all contracts deployed in the recent two years, from April 2022 to June 2024, covering over 770K contracts in total.
We deploy an Ethereum archive node using Geth~\cite{geth} to replay transactions and collect them.
Finally, to demonstrate {\tool}'s capability in real-time detection, we define the \textit{attack time window} as the period from the contract's deployment to the initiation of a price manipulation attack that results in a profitable transaction against the victim contract.


\noindent \textbf{Baseline Selection.}
To the best of our knowledge, there is no tool that supports detecting price manipulation attack contracts based solely on the contract bytecode.
To evaluate the effectiveness of {\tool}, we select three the most relevant state-of-the-art tools as baselines, \textit{i.e.,} DeFiRanger (DR)~\cite{wu2023defiranger}, FlashSyn (FS)~\cite{chen2024flashsyn}, and DeFiTainter (DT)~\cite{kong2023defitainter}.
Because DR and FS are close-sourced and detect price manipulation based on transaction data, we directly take the results from their papers.
Moreover, DT is an open-source tool that can detect the potential victims of price manipulation on the bytecode level. Thus, we provide all victims contract bytecode of incidents in $\mathcal{D}_{G1}$ to evaluate its effectiveness.
Note that though DeFiGuard~\cite{wang2024defiguard} claims it can extract behavioral features from transactions and use graph neural networks to identify price manipulation attacks, its model is close-sourced and it does not release the corresponding dataset. Thus, we exclude DeFiGuard from baselines.


\noindent \textbf{Implementation.}
Based on the facts and IR generated from Gigahorse~\cite{grech2019gigahorse}, {\tool} is implemented in Python3, comprising 1.8K lines of code. Additionally, {\tool} utilizes custom declarative rules to obtain more detailed data flow and call stack information, implemented through 500 lines of Datalog. 
All our experiments are conducted on a 96-core server equipped with dual Intel(R) Xeon(R) Gold 6248R CPUs and 256GB RAM running Ubuntu 22.04.1 LTS. The timeout for Gigahorse decompilation is set to 120 seconds.
The recursive cross-contract analysis depth in SMARTCAT is configurable and is set to three in the following evaluation.

\noindent \textbf{Research Questions.} We aim to explore the following research questions (RQs):

\begin{itemize}


\item[\textbf{RQ1}]  Is {\tool} effective and robust in identifying price manipulation attack contracts on the bytecode level?

\begin{itemize}
\item[\textbf{RQ1.1}] What about the performance improvements of {\tool} over baselines?
\item[\textbf{RQ1.2}] Do the introduced methods, \textit{i.e.,} argument recovery algorithm and sensitive path filtering module, contribute positively to the final results?
\item[\textbf{RQ1.3}] How robust is SMARTCAT against obfuscation?
\end{itemize}

\item[\textbf{RQ2}] How many price manipulation attack contracts exist in the wild? What are their characteristics?

\item[\textbf{RQ3}] Can {\tool} be taken as a real-time detector?

\end{itemize}

\section{RQ1: Effectiveness and Robustness}
\label{sec:rq1}



\begin{table}[t]
\caption{Comparison of detecting results on $\mathcal{D}_G$ among {\tool} and baselines. ST represents our tool {\tool}, ST w/o R, ST w/o S, and ST w/o B excludes the argument recovery algorithm module, the sensitive path module, and both of them, respectively.}
\vspace{-0.1in}
\centering
\label{tab:results}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}ccccccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Metrics}} & \multirow{2}{*}{\textbf{\#Detect}} & \multicolumn{5}{c}{\textbf{$\mathcal{D}_{G1}$}}                                                                    & \multicolumn{2}{c}{\textbf{$\mathcal{D}_{G2}$}} \\ \cmidrule(l){3-9} 
                                  &                                    & \textbf{TP} & \textbf{FN} & \textbf{Recall}   & \textbf{Time (s)} & \multicolumn{1}{c|}{\textbf{\#Alert}} & \textbf{FP}   & \textbf{Precision}       \\ \midrule
\textbf{ST}                       & \textbf{79}                        & \textbf{77} & \textbf{7}  & \textbf{91.7\%} & \textbf{32.18}   & \textbf{68}                           & \textbf{2}    & \textbf{99.975\%}   \\
\multicolumn{1}{l}{\textbf{ST w/o R}}                   & 49                                 & 47          & 37          & 56.0\%         & 28.79            & 40                                    & 2             & 99.975\%            \\
\multicolumn{1}{l}{\textbf{ST w/o S}}                   & 83                                 & 77          & 7           & 91.7\%          & 86.36            & 52                                    & 6             & 99.925\%            \\
\multicolumn{1}{l}{\textbf{ST w/o B} }                   & 53                                 & 47          & 37          & 56.0\%         & 79.59            & 30                                    & 6             & 99.925\%            \\ \midrule
\textbf{DR}                       & 23                                 & 23          & 19          & 54.8\%         & N/A              & N/A                                   & N/A           & N/A                \\
\textbf{FS}                       & 9                                  & 9           & 12          & 42.9\%         & N/A              & N/A                                   & N/A           & N/A                \\
\textbf{DT}                       & 60                                 & 14          & 70          & 16.7\%         & N/A              & N/A                                   & 46            & 99.425\%            \\ \bottomrule
\end{tabular}%
}
\vspace{-0.1in}
\end{table}


To answer RQ1, we apply {\tool} and other baselines on $\mathcal{D}_G$ to quantitatively evaluate their effectiveness. We also conduct an ablation study to evaluate the contribution of the argument recovery algorithm and sensitive path filtering to the final results.
Finally, we assess {\tool}'s robustness by applying it to obfuscated smart contracts.

\subsection{RQ1.1: Comparison with Baselines}
\noindent 
\textbf{Overall Results.}
Table~\ref{tab:results} illustrates the overall results of {\tool} and the other three baselines on $\mathcal{D}_G$\footnote{The detailed results are in Table~\ref{tab:detailed_results} in Appendix.}.
Because both DR and FS are close-sourced, we can only evaluate their performance according to the results in their papers.
According to their data, out of 42 and 21 incidents, DR and FS only detect 23 and 9 ones, respectively.
As for DT, it can only detect 14 vulnerable contracts out of 84 cases in $\mathcal{D}_{G1}$. We observe that DT cannot deal with recent attack incidents (see Table~\ref{tab:detailed_results} in Appendix). We speculate the reason is that it relies on manually crafted expert knowledge, while these new cases integrate more advanced and complicated business logic.
In contrast, {\tool} successfully identifies 77 price manipulation attack contracts and demonstrates its effectiveness on recent attack incidents.
In other words, in terms of recall, {\tool} (91.7\%) outperforms the other three baselines (54.8\%, 42.9\%, and 16.7\%) significantly.
As for the efficiency, the average detection time of {\tool} is only 32.18 seconds. According to the results, {\tool} can alert the attack within the attack time window for 68 out of 84 cases (81.0\%). For the remaining 16 cases, 7 are due to detection failures, while the other 9 have an attack window of less than 20 seconds, which poses further challenges to detection efficiency and also points out our future research direction.

As for $\mathcal{D}_{G2}$, among 8,000 benign contracts, {\tool} only generates 2 false positives. DT, however, produces 46 false positives. A manual review confirmed that these contracts do not contain vulnerabilities detected by DT.
This is because DT only considers the token balance of external addresses as a taint source without accounting for constraints such as slippage protection or maximum swap limits, leading to a higher rate of false positives.
Overall, {\tool} demonstrates a higher precision (99.975\% vs. 99.425\%) compared to the state-of-the-art baseline.


\noindent \textbf{False Negative Analysis}.
We manually investigate seven false negatives in $\mathcal{D}_{G1}$ and summarize three root causes.
First, {\tool} relies on the decompilation results of Gigahorse, which have inherent limitations. As its authors said~\cite{grech2019gigahorse}, Gigahorse cannot decompile all valid Ethereum contracts. For example, case \#1\footnote{Indexed in Table~\ref{tab:detailed_results} in Appendix, same notations hereafter.} is written in Vyper~\cite{vyper}, another valid programming language for Ethereum contracts but not widely-adopted, which is not supported by Gigahorse.
Moreover, Gigahorse cannot correctly decompile case \#51 even if we extend the timeout to 60 minutes.
Second, {\tool} depends on accurately recovering function calls and arguments. In cases \#19 and \#48, the attack contracts adopt obfuscation techniques in MEV bots~\cite{mevObfus}, dynamically passing offset values from \textit{Calldata} and calculating function selectors with predefined magic numbers, which invalidate {\tool}. 
In case \#18, the function arguments involve complex dynamic types or custom structures, which render our heuristic argument recovery algorithm ineffective, leading to the failure to correctly identify the semantics.
Third, {\tool} does not consider those attacks that require multiple transactions. In case \#23, the attacker completes the attack through two transactions, \textit{i.e.,} calling \texttt{stake()} to deposit and exchange tokens and then calling \texttt{harvest()} to execute the attack. Case \#28 is similar. {\tool} fails to detect these attacks because it focuses on those attack contracts that embed their logic within a single transaction for rapid exploitation.
We further discuss these limitations in \S\ref{sec:discuss}.

\begin{figure}[h]
\begin{lstlisting}[caption={The \texttt{swapTokenForFund()} function.}, label=lst:fpcode, belowskip=-2em]
function swapTokenForFund(uint256 tokenAmount) private {
    path[0] = address(this);
    path[1] = usdt;
    _swapRouter.swapExactTokensForXXX(amount1, 0, path, tokenDistributor);
    uint256 usdtBalance = USDT.balanceOf(tokenDistributor);
    USDT.transferFrom(tokenDistributor, address(this), usdtBalance);
    ...
    uint256 rewardUsdt = usdtBalance-fundUsdt-lpUsdt;
    if (rewardUsdt > 0 && usdt != _rewardToken) {
        path[0] = usdt;
        path[1] = _rewardToken;
        _swapRouter.swapExactTokensForXXX(rewardUsdt,0,path,address(this));}
}

\end{lstlisting}
\end{figure}

\noindent
\textbf{False Positive Analysis.}
As for the two false positives in $\mathcal{D}_{G2}$, further investigation reveals that both contracts implement the \texttt{swapTokenForFund()} function, as shown in Listing~\ref{lst:fpcode}.
Its token flow aligns with the indirect price manipulation behavior (step \textbf{i} to \textbf{iii} in \S\ref{sec:ipm}).
Specifically, the function first executes a swap operation to exchange for USDT tokens (L2-L4), which might affect its price in the liquidity pool (step \textbf{i}). It then transfers USDT from a third-party address to the contract (L5), potentially staking the tokens at an unfairly calculated price (step \textbf{ii}). Finally, the function calculates the reward tokens to be returned to the caller based on a predefined fee ratio (L7-L10) and returns a portion of the USDT to the liquidity pool (L12) (step \textbf{iii}). Consequently, {\tool} mistakenly identifies it as an attack contract.
The original intent of this function is to distribute the incoming \texttt{tokenAmount} by converting it to USDT, allocating portions to designated addresses, managing liquidity, and finally swapping any remaining USDT back to the contract.
Though we can add extra rules to eliminate such false positives, it may lead to other unexpected false negatives. As a detector specifically designed for identifying attack contracts with timely alerts, we choose to accept false alarms to mitigate possible attacks more proactively.


\subsection{RQ1.2: Ablation Study}
We perform an ablation study by removing the argument recovery algorithm (see \S\ref{lab:argu}) and the sensitive path filtering module (see \S\ref{sec:spf}) to evaluate their contributions.
As shown in Table~\ref{tab:results}, ST w/o R can only detect 47 attack contracts out of 84 cases in $\mathcal{D}_{G1}$, mainly due to its inability to accurately identify token actions for specific function calls, resulting in an incomplete TFG. This means that integrating the argument recovery algorithm introduces 63.8\% more true positive cases, while only introducing the runtime overhead of 3.4 seconds.
As for ST w/o S, the number of detected attacks on $\mathcal{D}_{G1}$ is consistent with {\tool}. However, removing it dramatically increases the average detection time by 1.7$\times$, \textit{i.e.,} 16 attacks cannot be alerted in time. 
Moreover, on $\mathcal{D}_{G2}$, ST w/o S introduces 4 additional false positives. 
We find that these four cases invoke the two false positives identified by {\tool}. Since all execution paths are treated as potentially sensitive paths, the cross-contract operations are also incorrectly considered part of the attack. This demonstrates that the sensitive path filtering module helps our tool focus on suspicious paths, significantly reducing cross-contract analysis time.
Intuitively, ST w/o B, which does not integrate both modules, performs poorly in terms of efficiency, precision, and recall, underlining the significance of integrating these two modules in {\tool}.


\subsection{RQ1.3: Robustness}

We further evaluate the robustness of {\tool} against code obfuscation.
Currently, two mature obfuscators for Ethereum smart contracts are available, \textit{i.e.,} BOSC~\cite{yu2022bytecode} and BiAn~\cite{zhang2023bian}.
As BOSC performs on the deployed bytecode but does not guarantee the deployability after obfuscation, we adopt BiAn as the obfuscator.
To be specific, BiAn performs source-level obfuscation with three modes: Layout Obfuscation (LAO), Data Flow Obfuscation (DFO), and Control Flow Obfuscation (CFO). We note that 1) the \texttt{replaceVarName} option of LAO changes external interface definitions, causing mismatched function selectors of cross-contract calls; and 2) the maintainer has also acknowledged that CFO is not yet functional~\cite{bian}. Thus, to ensure the contract functionality, we only consider LAO, DFO, and LDO (combined with LAO and DFO) as the obfuscation methods, consistent with a previous work~\cite{chen2021sadponzi}.
Since most attack contracts are only available as bytecode, we construct a dataset of 20 contracts by \textit{i.e.,} 1) reverse-engineering the bytecode of detected attack cases to reproduce their source code; and 2) modifying PoCs of attacks reported by security platforms~\cite{Defihacklab}.
We use Foundry~\cite{foundry} to deploy the obfuscated contracts on a forked private chain, simulating on-chain real-time detection scenarios. Note that the environment is reinitialized before testing each case to prevent caching from disturbing the final results.
As shown in Table~\ref{tab:robustness}, {\tool} accurately identifies all contracts obfuscated by all three modes with acceptable runtime overhead. Such robustness can be explained by two factors, \textit{i.e.,} 1) LAO's variable name replacement does not affect bytecode analysis; and 2) Gigahorse provides a robust data flow analysis, while {\tool} focuses on semantic information that remains unchanged during DFO.
We further discuss conducting obfuscation on attack contracts in \S\ref{sec:discuss}.



\begin{table}[t]
\centering
\caption{Performance of {\tool} under obfuscation.}
\label{tab:robustness}
\vspace{-0.1in}
\resizebox{0.7\columnwidth}{!}{%
\begin{tabular}{ccccc}
\toprule
\textbf{Mode}    & \textbf{None} & \textbf{LAO} & \textbf{DFO} & \textbf{LDO} \\ \midrule
\textbf{FN}      & 0 / 20          & 0 / 20         & 0 / 20         & 0 / 20         \\ 
\textbf{Avg. Time (s)} & 45.1      & 45.8         & 47.2         & 47.5         \\ 
\bottomrule
\end{tabular}%
}
\vspace{-0.1in}
\end{table}


\begin{tcolorbox}[title= Answer to RQ1, left=2pt, right=2pt, top=0.5pt,bottom=0.5pt, colback=gray!5,colframe=gray!80!black]
Based on our comprehensive dataset, {\tool} outperforms all state-of-the-art baselines, effectively identifying price manipulation attack contracts with 91.6\% recall and $\sim$100\% precision. Additionally, it can alert 81.0\% of attack contracts within the attack window and demonstrate robustness against obfuscation techniques. The ablation study confirms the significant role of the argument recovery algorithm and sensitive path filtering module.
\end{tcolorbox}



\section{RQ2: Real-world Price Manipulation}

To answer RQ2, we apply {\tool} on over 770K contracts in $\mathcal{D}_L$, and characterize the financial impacts of identified attack contracts. Moreover, we also quantify the efficiency of {\tool} on a large-scale experiment.
   

\noindent
\textbf{Overall Results.}
In total, we have identified 616 price manipulation attack contracts, none of which are linked with source code on Etherscan.
We utilized auxiliary information, like transaction traces and account labels to confirm the detection results. Specifically, we tracked whether transactions involved in any swap token operations and profited from price fluctuations. We also take advantage of labels on Etherscan~\cite{EthApi} and reports from security service platforms~\cite{Defihacklab, slowmist, rekt}. 

Among them, till May 2024, 214 have already launched the corresponding attack, accounting for 34.7\%, where 19 of them were reported in public. {\tool} can promptly raise alerts within the attack window for 195 cases (91.1\%), with an average detection time of 27.6 seconds.
Interestingly, out of 214 cases, we have investigated 40
failed attack contracts and 8 successful but no-profit contracts. After investigating their decompiled bytecode and transactions, we identified two primary reasons, \textit{i.e.,} 1) insufficient prerequisite conditions, such as inadequate funds to destabilize liquidity pools or lack of access control permissions, and 2) changes in on-chain states that caused attackers to miss profit opportunities.



For the remaining 402 cases without initiating attack transactions, to further analyze the effectiveness of our tool, we randomly sampled 20 contracts. Taking advantage of an online tool~\cite{dedaub}, we obtained the decompiled code of these contracts for examination. Inspired by previous studies~\cite{ren2024lookahead, forta}, we also consider flashloan services, deployer information, bytecode length, and function signatures. Ultimately, among the 20 sampled contracts, we confirmed 16 as price manipulation attack contracts as they demonstrated clear attack intent, such as implementing functions related to flashloan callback, asset transfer, and interaction with liquidity pool. The remaining 4 are inconclusive because either their code is obfuscated or there is no additional information about the deployer. We speculate there are two reasons why so many attack contracts remain in the pre-attack stage. On the one hand, to ensure timeliness and profitability, many attack contracts may deploy attack templates in advance, allowing attackers to initiate exploitation at any time by passing in the address of the target liquidity pool. On the other hand, we found delayed attacks in $\mathcal{D}_{G1}$, where one case occurred 44 days after deployment. Thus, we speculate attackers may have missed the opportunity or are still waiting for the ripe time to maximize their profits.



\noindent
\textbf{Financial Impacts.} 
In total, attackers have obtained \$9.25M in profits through 166 price manipulation attack contracts\footnote{214 cases without 40 failed and 8 no-profit cases.}, out of which \$0.96M are not reported at all (related to 147 successful contracts).
Though the reported attacks have accounted for 89.6\% of financial losses, we cannot neglect the impact of unreported ones.
Figure~\ref{fig:reported} illustrates the distribution of attack profits.
As we can see, price manipulation attacks have persisted alongside the growth of Ethereum, indicating that attackers have consistently targeted potential vulnerabilities in the DeFi ecosystem with the intent to steal funds. There is a noticeable trough in late-2022, which may be linked to the collapse of the FTX project and the increased scrutiny by the U.S. Securities and Exchange Commission on crypto institutions~\cite{ftx}. This has led to a more conservative approach to the development of the DeFi ecosystem. It reflects that the activity level of price manipulation attacks is closely related to the growth and evolution of DeFi.
Additionally, Figure~\ref{fig:pmtype} illustrates the number and profitability of the two types of price manipulation attacks. In total, 136 direct price manipulation (DPM) attack contracts generated a profit of \$8.60M, far exceeding the \$0.65M from 30 indirect price manipulation (IPM) attack contracts. This disparity arises because attackers often use flashloans to directly manipulate the number of tokens in liquidity pools, causing price fluctuations. In contrast, IPM attacks interact with third-party addresses, requiring more effort and costs for attackers.


\begin{figure}[t]
    \centering
    \subfigure[Distribution of profits for reported and unreported attack contracts.]{
        \centering
        \includegraphics[width=0.95\columnwidth]{Figure/sec5/loss_comparison.pdf}
        \label{fig:reported}
    }
    \subfigure[Distribution of profits for two types of price manipulation attack contracts, with numbers on bars indicating contract count.]{
        \centering
        \includegraphics[width=0.95\columnwidth]{Figure/sec5/loss_comparison_with_counts_adjusted.pdf}
        \label{fig:pmtype}
    }
    \vspace{-0.1in}
    \caption{Distribution of attack profits by deployment time.}
    \vspace{-0.1in}
    \label{fig:profit}
\end{figure}



\begin{figure}[t] 
\centering
\includegraphics[width=0.95\columnwidth]{Figure/sec5/cdf_plot_adjusted_major1.pdf} 
\vspace{-0.1in}
\caption{Distribution of contract runtimes.} 
\vspace{-0.1in}
\label{fig:cdf} 
\end{figure}


\begin{figure}[t] 
\centering
\includegraphics[width=0.95\columnwidth]{Figure/sec5/codeSize_scatter.pdf} 
\vspace{-0.1in}
\caption{The relationship between the consumed time and the length of the bytecode on each case. } 
\vspace{-0.1in}
\label{fig:byteCode_Time} 
\end{figure}

\noindent
\textbf{Efficiency.}
We further analyze the efficiency of {\tool} on $\mathcal{D}_L$. We sampled 15K contracts from $\mathcal{D}_L$, assigning a separate process to each contract for analysis. The distribution of the used time is shown in Figure~\ref{fig:cdf}. 
As we can see, 98.1\% contracts can be finished within 25 seconds. If we extend the runtime to 40.6 seconds, 99\% of the contracts can be covered.
Our statistics further show that the average time for a contract is only 12.1 seconds.
Figure~\ref{fig:byteCode_Time} illustrates the relationship between the consumed time and the length of the bytecode based on randomly sampled 1,000 contracts.
We can observe that there is no exponential relationship between these two metrics. This is because {\tool} only performs cross-contract analysis on nodes within sensitive paths during execution (see \S{\ref{sec:spf}}), thereby reducing the time overhead and improving its scalability.
For the top-left outliner that takes 226 seconds\footnote{Contract address: 0xA5C0D0CAf243697143ed9f06b259050A77cE5887}, we find that {\tool} does not perform additional cross-contract analysis. Instead, 158 seconds are spent on Gigahorse inlining small functions to produce a higher-level IR, and 65 seconds are used for generating facts for client execution.
The correlation analysis only illustrates the weak linear relationship between them, where $r$ is 0.306 with $p < 0.001$, further proving the efficiency of {\tool}.



\begin{tcolorbox}[title= Answer to RQ2, left=2pt, right=2pt, top=0.5pt,bottom=0.5pt, colback=gray!5,colframe=gray!80!black]
{\tool} has identified 616 price manipulation attack contracts in total, accounting for \$9.25M in financial losses, where only 19 cases were reported publicly.
Moreover, {\tool} can analyze 98.1\% of cases within 25 seconds, and there is only a weak linear relationship between the consumed time and bytecode length ($r = 0.306$ with $p < 0.001$), demonstrating the efficiency and scalability of {\tool} on real-world tasks.
\end{tcolorbox}


\section{RQ3: Real-time Detection}
To answer RQ3, we have deployed {\tool} on Ethereum and Binance Smart Chain (BSC) as a real-time detector since July 11th, 2024.
We monitor the latest blocks using Geth RPC nodes~\cite{geth} and extract contract bytecode from contract creation transactions. To accelerate the analysis, we have deployed 15 instances in parallel. Additionally, the number of deployed instances can be dynamically scaled based on the volume of newly created contracts.


\begin{table*}[t]
\caption{Successfully conducted price manipulation attacks alerted by {\tool}. All times are in 2024 and are presented in UTC. Numbers in parenthesis are time windows since deployment in seconds.}
\label{tab:rq3}
\vspace{-0.1in}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}clcccccc@{}}
\toprule
\textbf{Victim DApp} & \multicolumn{1}{c}{\textbf{Type}} & \multicolumn{1}{c}{\textbf{Deploy Time}} & \multicolumn{1}{c}{\textbf{Alert Time}} & \multicolumn{1}{c}{\textbf{Attack Time}} & \multicolumn{1}{c}{\textbf{Loss (\$)}} & \multicolumn{1}{c}{\textbf{Attack Transaction Hash}}               \\ \midrule
UPS (BSC)   &   IPM      & 07/12 11:09:12                           & 07/12 11:10:32 (80)                          & 07/12 11:12:24 (192)                                                          & 521K                                  & 0x1ddf415a4b18d25e87459ad1416077fe7398d5504171d4ca36e757b1a889f604 \\
TokenStake (BSC)  & DPM & 08/05 18:52:25                           & 08/05 18:55:02 (157)                          & 08/05 19:11:49 (1,164)                                                        & 110K                                  & 0x94ff0c3f3177a6ffd3365652ae2dc1f0a4ecf5f5758df1fdc3339303992a2ae4 \\
FXS (BSC)    &   DPM   & 08/21 11:56:43                           & 08/21 11:57:21 (38)                          & 08/21 11:58:04 (81)                                                          & 10K                                   & 0xa479ae7d0b53ec8049de7f4556aa9b1d406f51dacd027ebe60f9f45788b7deb2 \\ \bottomrule
\end{tabular}%
}
\vspace{-0.2in}
\end{table*}

\begin{table}[]
\caption{Failed and unfinished price manipulation attempts detected by {\tool}. Same notations with Table~\ref{tab:rq3}.}
\label{tab:rq3-2}
\vspace{-0.1in}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}cclccc@{}}
\toprule
\textbf{Status}                                                                    & \textbf{Address}  & \textbf{Type} & \textbf{Deploy Time} & \textbf{Alert Time}  & \textbf{Chain} \\ \midrule
\multirow{4}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Failed \\ (4)\end{tabular}}}    & 0xDd02...        & DPM & 07/26 06:50:35       & 07/26 06:52:05 (90)  & BSC            \\
                                                                                   & 0xE39b...  & IPM      & 08/02 18:37:06       & 08/02 18:37:32 (26)  & BSC            \\
                                                                                   & 0x5dB0...  & IPM      & 08/16 16:26:11       & 08/16 16:28:02 (111) & ETH            \\
                                                                                   & 0xbc3E... & DPM      & 08/25 08:14:38       & 08/25 08:16:43 (125) & BSC            \\ \midrule
\multirow{7}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Unfinished\\ (7)\end{tabular}}} & 0x0EBD...        & DPM & 07/17 05:41:52       & 07/17 05:42:39 (47)  & BSC            \\
                                                                                   & 0x7707... & DPM        & 08/05 19:17:58       & 08/05 19:19:56 (118) & BSC            \\
                                                                                   & 0xd270... & DPM       & 08/13 11:15:59       & 08/13 11:16:50 (51)  & ETH            \\
                                                                                   & 0x2F6C...  & DPM      & 08/13 15:26:45       & 08/13 15:31:14 (269) & BSC            \\
                                                                                   & 0x85Ea...  & DPM      & 08/16 08:16:47       & 08/16 08:17:49 (62)  & BSC            \\
                                                                                   & 0x02F8...  & DPM      & 08/17 09:01:02       & 08/17 09:03:53 (171) & BSC            \\
                                                                                   & 0x35Be...  & DPM      & 08/21 11:59:55       & 08/21 12:00:36 (41)  & BSC            \\ \bottomrule
\end{tabular}%
}
\vspace{-0.1in}
\end{table}

\noindent
\textbf{Overall Results.}
In total, {\tool} has reported 14 cases, as shown in Table~\ref{tab:rq3} and Table~\ref{tab:rq3-2}, illustrating the completed attacks and failed/unfinished ones, respectively.

As we can see from Table~\ref{tab:rq3}, three successful cases were all performed on BSC.
Compared to their corresponding attack window, we can conclude that {\tool} is efficient enough to identify contracts' semantics and raise alarms for the upcoming price manipulation attack.
According to our statistics, these three cases have resulted in financial losses worth more than \$641K.



Moreover, Table~\ref{tab:rq3-2} illustrates four failed and seven unfinished price manipulation attempts.
We manually investigated the bytecode and transaction of four failed attempts. We found that three of them reverted due to an inability to repay the flashloan, and one was due to running out of gas as a result of multiple transfer loops within the transaction.
As for all seven unfinished ones, we have observed explicit attack intent, as the ones we stated in the \textbf{Overall Results} part in RQ2.
Interestingly, we have noticed that the unfinished case located at \texttt{0xd270} has another contract (\texttt{0xb7f2}) with identical bytecode that is reported by Etherscan. We have noticed that \texttt{0xb7f2} is involved in a real-world price manipulation attack\footnote{Attack transaction hash: \href{https://etherscan.io/tx/0x758efef41e60c0f218682e2fa027c54d8b67029d193dd7277d6a881a24b9a561}{link}} which is identified in RQ2. The attack was launched 110 days after the contract deployment and led to around \$1.1M in financial losses. \texttt{0xd270} is deployed six minutes after the attack. 
Thus, we infer that \texttt{0xd270} is either another try from the same team and waiting for the ripe time, or a test contract used by the victim to analyze the cause of the attack.


% \begin{figure}[h]
\begin{lstlisting}[caption={Attack contract against UPS.}, label=lst:atkcode]
// Step_0: use flashloan to borrow BUSD token
function pancakeV3FlashCallback(uint256 varg0, uint256 varg1, bytes _) public nonPayable {
    v1 = BUSD.balanceOf(address(this));
    // Step_1: swap BUSD to UPS
    v2, v3 = sto_2.swapExactTokensForTokens(v1, 1, [BUSD, UPS], address(this), _);
    v4 = UPS.balanceOf(address(sto_0));
    // Step_2: Get UPS token from another contract
    UPS.transferFrom(sto_0, address(this), v4);
    v5 = UPS.balanceOf(address(sto_5)); 
    // Calculate swap amount for price manipulation
    v6 = (v5 - 1) * 20 / 19;
    // step_3: swap UPS to BUSD at a very low price
    v7, v8 = sto_2.swapExactTokensForTokens(v6, 1, [UPS, BUSD], address(this), _);
    BUSD.transfer(sto_9, varg1 + 1000);
    v9 = BUSD.balanceOf(address(this));
    BUSD.transfer(msg.sender, v9);
}
\end{lstlisting}
% \end{figure}

\noindent
\textbf{Case Study.}
To better illustrate the effectiveness of {\tool}, we conducted a case study of the attack against UPS on BSC (first data row in Table~\ref{tab:rq3}), which has led to \$521K financial losses.
Since the contract does not release its source code, we use an online tool~\cite{dedaub} to obtain its decompiled representation, as shown in Listing~\ref{lst:atkcode}. We perform some necessary simplifications to clearly demonstrate the attack. 



The attacker first borrows a large amount of BUSD tokens through a flashloan and then executes the attack logic in \texttt{pancakeV3FlashCallback()} (L2). The attacker swaps the borrowed BUSD tokens to UPS tokens and transfers them to the attack contract itself (L6). Another bunch of UPS tokens are transferred from a third-party address to the attack contract (L9). Finally, the attacker swaps all UPS tokens back to BUSD and transfers them to the call sender (L15 -- L19). This matches the pattern of indirect price manipulation (see \S\ref{sec:ipm}), thus {\tool} raises the alarm and marks the UPS token as the manipulated token.

\begin{lstlisting}[caption={Vulnerable \texttt{\_update()} in UPS.}, label=lst:vulcode]
function _update(address from, address to, uint256 amount) internal virtual override {
    if (inSwapAndLiquify || whiteMap[from] || whiteMap[to] || !(from == pairAddress || to == pairAddress)) {
        super._update(from, to, amount);
        ...
    } else if (to == pairAddress) {
        uint256 fee = amount * 5 / 100;
        if (!inSwapAndLiquify) {
        // Vulnerable point.
            _swapBurn(amount - fee);}}
    ...
}
\end{lstlisting}

To analyze the root cause of this attack, we have tracked to a customized \texttt{\_update()} function in the UPS's \texttt{transferFrom()} function, whose source code is shown in Listing~\ref{lst:vulcode}.
Specifically, it calculates the number of UPS token needed to burn based on an externally provided \texttt{amount} (L9). This operation affects the contract's reserve calculations, thereby manipulating the token exchange price. 
In this case, the attacker passed a predetermined number of UPS tokens, as shown at L13 in Listing~\ref{lst:atkcode}. This operation has led to the reservation of UPS token dropping to 1 during the second token exchange.
As a result, the attacker exchanges a large amount of BUSD by taking advantage of indirect price manipulation.


\begin{tcolorbox}[title= Answer to RQ3, left=2pt, right=2pt, top=0.5pt,bottom=0.5pt, colback=gray!5,colframe=gray!80!black]
Within 50 days, {\tool} has raised 14 alarms about potential price manipulation attacks on Ethereum and BSC 99 seconds after the corresponding contract deployment on average. Notably, these attacks have already led to \$641K financial losses, and seven of them are still waiting for their ripe time.
\end{tcolorbox}