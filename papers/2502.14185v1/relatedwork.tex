\section{Related work}
Research on human reactions to robotic failures and robotic explanations of failures has gained increasing attention in recent years. 
Understanding human reactions to robot failures is crucial for developing effective HRI systems. Several studies have examined how humans perceive and respond to robot errors in collaborative tasks. \cite{mirnig2017understanding} found that humans tend to attribute robot failures to technical issues rather than the robot's cognitive capabilities. However, \cite{desai2013impact} showed that repeated failures can negatively impact trust and acceptance of robots. The type and severity of failures also influence human perceptions, with task-related errors being more detrimental than social norm violations \cite{salem2015err}. Further, providing explanations for failures has been shown to improve human-robot interaction. \cite{wang2016impact} demonstrated that explanations can increase transparency and help calibrate trust in robotic systems. \cite{thielstrom2020generating} proposed an approach for generating explanations about action failures in cognitive robotic architectures. Recent work by \cite{liu2023reflect} has explored using large language models to generate informative failure explanations for robots.
Studying human reactions to robotic failures is also crucial for the creation of tailored explanations that address specific user concerns \cite{kwon2018expressing}, help maintain appropriate trust levels \cite{wang2016impact}, improve collaboration by anticipating and addressing reactions \cite{tabrez2019reactive}, and enhance the overall user experience by considering emotional and cognitive responses \cite{spitale2024err}. By incorporating these insights, explanation strategies can be designed, leading to more robust, trustworthy, and satisfying HRI, even when failures occur.

However, only a few publicly available datasets exist documenting human reactions to robotic failures, specifically those involving real robot-human interactions rather than humans viewing robot videos.
\cite{stiber2023react} introduced the REACT dataset, containing multimodal data of human reactions to various types of robot failures in a collaborative task.
Another dataset, not yet publicly available, ERR@HRI 2024 challenge dataset \cite{spitale2024err} provides multimodal non-verbal interaction data, including facial, speech, and pose features from interactions with a robotic coach, annotated with labels of robot mistakes and user reactions. However, these datasets primarily address the initial failure reactions, neglecting the human reactions after the robot explains the failure. As discussed in \cite{tabrez2019reactive,spitale2024err}, the explanations can be tailored not only based on specific human reactions to failures but also the human reactions to previous explanations provided by the robot for similar failure. Our dataset not only thoroughly documents the diverse human reactions to various robot failures but also captures the responses to different levels and strategies of explanations provided by the robot.