
\renewcommand\arraystretch{0.95}
\begin{table*}[!t]
  \centering
  \resizebox{\linewidth}{!}{
    \begin{tabular}{l*{11}c}
      \toprule
      Method & Aircraft & Caltech101 & Cars & DTD & EuroSAT & Flower102 & Food101 & Pets & SUN397 & UCF101 & \textit{Average} \\
      \midrule
      CLIP-ResNet-50 & 16.11 & 87.26 & 55.89 & 40.37 & 25.79 & 62.77 & 74.82 & 82.97 & 60.85 & 59.48 & 56.63 \\
      \midrule
      CoOp & 15.12 & 86.53 & 55.32 & 37.29 & 26.20 & 61.55 & 75.59 & 87.00 & 58.15 & 59.05 & 56.18 \\
      CoCoOp & 14.61 & 87.38 & 56.22 & 38.53 & 28.73 & 65.57 & 76.20 &  \underline{88.39} & 59.61 & 57.10 & 57.23 \\
      \midrule
      TPT & 17.58 & 87.02 & 58.46 & 40.84 & 28.33 & 62.69 & 74.88 & 84.49 & 61.46 & 60.82 & 57.66 \\
      DiffTPT & 17.60 & 86.89 &  {60.71} & 40.72 & 41.04 & 63.53 & \underline{79.21} & 83.40 &  {62.72} & 62.67 & 59.85 \\
      HisTPT & \textbf{18.10} & 87.20 & \underline
      {61.30} & 41.30 & \textbf{42.50} & 67.60 & \textbf{81.30} & 84.90 & \underline{63.50} & 64.10 & \underline{61.18} \\
      \midrule
       $\rm{TDA}^{*}$  & {17.61} &  \underline{89.70} & 57.78 &  \underline{43.74} & \underline{42.11} & \textbf{68.74} & 77.75 & 86.18 & 62.53 &  \underline{64.18}  &  {61.03}\\
       \rowcolor{gray!30} ${\mathbf{SOBA~(Ours)}}^{*}$ & \underline{17.70} & \textbf{90.18} & \textbf{61.40} & \textbf{44.80} & {41.51}	&  \underline{67.61} &  {77.82} & \textbf{88.69} & \textbf{65.65} & \textbf{66.77} & \textbf{62.20} \\
       
      \midrule
      \midrule
      CLIP-ViT-B/16 & 23.22 & 93.55 & 66.11 & 45.04 & 50.42 & 66.99 & 82.86 & 86.92 & 65.63 & 65.16 & 64.59 \\
      \midrule
      CoOp & 18.47 & 93.70 & 64.51 & 41.92 & 46.39 & 68.71 & 85.30 & 89.14 & 64.15 & 66.55 & 63.88 \\
      CoCoOp & 22.29 & 93.79 & 64.90 & 45.45 & 39.23 & 70.85 & 83.97 &  \underline{90.46} & 66.89 & 68.44 & 64.63 \\
      \midrule
      TPT & 24.78 & 94.16 & 66.87 & \underline{47.75} & 42.44 & 68.98 & 84.67 & 87.79 & 65.50 & 68.04 & 65.10 \\
      DiffTPT &  {25.60} & 92.49 & 67.01 & 47.00 & 43.13 & 70.10 & {87.23} & 88.22 & 65.74 & 62.67 &65.47 \\
      MTA & 25.32 & 94.13 & 68.05	& 45.59	& 38.71	& 68.26	& 84.95	& 88.22	& 64.98	& 68.11	& 64.63 \\
      MTA+Ensemble & 25.20 & 94.21 & {68.47} & 45.90 & 45.36 & 68.06 & 85.00 & 88.24	& 66.60 & 68.69 & 65.58  \\
       HisTPT & \textbf{26.90} & \underline{94.50} & \underline{69.20} & \textbf{48.90} & 49.70 & 71.20 & \textbf{89.30} & 89.10 & 67.20 & 70.10 & \underline{67.61} \\
      \midrule
      $\rm{TDA}^{*}$ & 23.91 &  \underline{94.24} & {67.28} &  {47.40} &  \underline{58.00} &  \underline{71.42} & 86.14 & 88.63 &  \underline{67.62} &  \underline{70.66} &  {67.53} \\
    \rowcolor{gray!30} ${\mathbf{SOBA~(Ours)}}^{*}$ & \underline{25.62} & \textbf{94.60} & \textbf{71.12} & 46.87 & \textbf{59.44} & \textbf{71.66} &  \underline{86.69} & \textbf{92.48}	& \textbf{70.63} &	\textbf{74.12}	& \textbf{69.32} \\
      \bottomrule
    \end{tabular}
  } 
  \caption{\textbf{Results on the Cross-Dataset Benchmark.}
  Compare the performance of our method with existing methods on Cross-Dataset benchmark. Our method achieves the highest average accuracy on both backbones. The best results are in \textbf{bold} and the second-best results are \underline{underlined}. Among the methods we compared, CoOp~\cite{coop} and CoCoOp~\cite{cocoop} are fine-tuned on the training set; TPT~\cite{tpt}, DiffTPT~\cite{difftpt} and HisTPT~\cite{histpt} require backpropagation to update the prompts; TDA~\cite{tda}, and our method do not require any backpropagation to update parameters.  \textit{Average} refers to the average accuracy across all datasets. ``*'' indicates that this method is a training-free approach in test-time adaptation task. 
  }
  \label{tab:cross-dataset}
  % \vspace{-1mm}
\end{table*}