\documentclass[twoside,11pt]{article}

\usepackage{blindtext}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

% Available options for package jmlr2e are:
%
%   - abbrvbib : use abbrvnat for the bibliography style
%   - nohyperref : do not load the hyperref package
%   - preprint : remove JMLR specific information from the template,
%         useful for example for posting to preprint servers.
%
% Example of using the package with custom options:
%
% \usepackage[abbrvbib, preprint]{jmlr2e}

\usepackage{jair2e}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{pifont}
\usepackage[dvipsnames]{xcolor}

% \DeclareLanguageMapping{english}{english-apa}
% \addbibresource{animesh.bib}
% \addbibresource{bib.bib}
% \addbibresource{john.bib}
% Definitions of handy macros can go here

% \newcommand{\dataset}{{\cal D}}
% \newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}

\usepackage{lastpage}
% \jmlrheading{23}{2022}{1-\pageref{LastPage}}{1/21; Revised 5/22}{9/22}{21-0000}{Author One and Author Two}

% Short headings should be running head and authors last names

\ShortHeadings{Giving AI Personalities Leads to More Human-Like Reasoning}{Nighojkar, Moydinboyev, Duong, Licato}
% \firstpageno{1}

\begin{document}

\title{Giving AI Personalities Leads to More Human-Like Reasoning}

\author{\name Animesh Nighojkar \email anighojkar@usf.edu\\
    \name Bekhzodbek Moydinboyev \email bmoydinboyev@usf.edu\\
    \name My Duong \email myduong@usf.edu\\
    \name John Licato \email licato@usf.edu\\
    \addr Advancing Machine and Human Reasoning (AMHR) Lab\\
    Department of Computer Science and Engineering, University of South Florida\\
    Tampa, FL, USA
}

% \author{(Authors Anonymized)}

% \editor{(TBA)}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
In computational cognitive modeling, capturing the full spectrum of human judgment and decision-making processes, beyond just optimal behaviors, is a significant challenge. This study explores whether Large Language Models (LLMs) can emulate the breadth of human reasoning by predicting both intuitive, fast System 1 and deliberate, slow System 2 processes. Unlike traditional AI research focused on optimizing accuracy, this paper investigates the potential of AI to mimic diverse reasoning behaviors across a human population, addressing what we call the {\em full reasoning spectrum problem}. We designed reasoning tasks using a novel generalization of the Natural Language Inference (NLI) format to evaluate LLMs' ability to replicate human reasoning. The questions were crafted to elicit both System 1 and System 2 responses. Human responses were collected through crowd-sourcing and the entire distribution was analyzed and modeled, rather than just the majority of the answers. We used personality-based prompting inspired by the Big Five personality model to elicit AI responses reflecting specific personality traits, capturing the diversity of human reasoning, and exploring how personality traits influence LLM outputs. Combined with genetic algorithms to optimize the weighting of these prompts, this method was tested alongside traditional machine learning models. The results show that LLMs can mimic human response distributions, with open-source models like Llama and Mistral unexpectedly outperforming proprietary GPT models. Personality-based prompting, especially when optimized with genetic algorithms, significantly enhanced LLMs' ability to predict human response distributions, suggesting that capturing suboptimal, naturalistic reasoning may require modeling techniques incorporating diverse reasoning styles and psychological profiles. The study concludes that personality-based prompting combined with genetic algorithms is promising for enhancing AI's \textit{human-ness} in reasoning, proposing a new methodology for studying and applying human reasoning by acknowledging and leveraging the vast differences in individual reasoning styles at a granular level.
\end{abstract}

\begin{keywords}
  Large Language Models (LLMs), Human-like reasoning, Cognitive biases, Personality prompting, Natural Language Inference (NLI), System 1 and System 2 reasoning
\end{keywords}

\input{latex/introduction}
\input{latex/background}
\input{latex/survey}
\input{latex/experiments}
\input{latex/conclusion}

% Acknowledgements and Disclosure of Funding should go at the end, before appendices and references`

\acks{This material is based on work supported by the National Science Foundation under Grant No. 2311286.}
% \acks{Anonymized}
\input{latex/appendix}

\clearpage
\vskip 0.2in
\bibliographystyle{apacite}
\bibliography{animesh,bib,john}

\end{document}
