\section{Modeling Experiments}\label{sec:experiments}

    The overarching aim of our modeling experiments is to predict how human votes are distributed across each item. We begin by predicting the mode of the distribution (majority vote, as discussed in Section \ref{sec:accuracy}), then proceed to estimate the variance among the votes (Section \ref{sec:var}), and ultimately aim to predict the entire distribution of human votes (Section \ref{sec:mimic}). None of these tasks can be considered inherently easier than the others due to the significant variability in human reasoning, as highlighted in Section \ref{subsec:dataset_characteristics}. Given our development of the 6-way scheme, which includes six labels as detailed in Section \ref{sec:data_collection}, we also compare the performance of LLMs on the more conventional NLI scheme: the 3-way classification (contradiction, neutral, and entailment). It is important to note that we collect human responses solely for the 6-way scheme and subsequently map these responses to the 3-way scheme by categorizing A and B as \textit{contradiction}, C and D as \textit{neutral}, and E and F as \textit{entailment}. All LLMs are tested separately on both the 3-way and 6-way schemes. We utilize both proprietary LLMs (GPT-3.5,\footnote{\url{https://platform.openai.com/docs/models/gpt-3-5-turbo}} GPT-4 \citep{openai_gpt-4_2023}, GPT-4o-mini\footnote{\url{https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/}}) and open-source LLMs (Gemma 2 27b \citep{gemma_2024}, Llama 3.1 8b, Llama 3.1 70b, Llama 3.1 405b,\footnote{\url{https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md}} Mistral 7b with direct performance optimization \citep{rafailov_direct_2023, Nous-Hermes-2-Mistral-7B-DPO}) to compare their performance against traditional (non-transformer-based) machine learning algorithms.

    \begin{table}
        \centering
        \begin{tabular}{ll}
            \toprule
            Trait & Prompt\\
            \midrule
             O+ & You're open to new experiences, creative, inventive, curious, and imaginative.\\
             O-- & You prefer routine and familiarity, consistent, conventional, and cautious.\\
             C+ & You're organized, efficient, reliable, and responsible.\\
             C-- & You're flexible, spontaneous, extravagant, and careless.\\
             E+ & You're friendly, outgoing, sociable, and energetic.\\
             E-- & You're reserved, quiet, introverted, and solitary.\\
             A+ & You're cooperative, warm, friendly, and compassionate.\\
             A-- & You're competitive, detached, critical, and judgemental.\\
             N+ & You're anxious, stressed, nervous, and emotionally sensitive.\\
             N-- & You're calm, stable, confident, and emotionally resilient.\\
             \bottomrule
        \end{tabular}
        \caption{Personality Prompts}
        \label{tab:prompts}
    \end{table}
    
    To predict the entire vote distribution using LLMs, we must prompt them in a way that allows the recreation of a vote distribution rather than producing a single vote per item. We do not fine-tune the LLMs because we do not have enough data to tune millions of parameters that we would need to tune even with techniques such as parameter-efficient fine-tuning \citep{ding_parameter-efficient_2023}. All the LLMs we use are chatbot models, which include a system prompt that influences the LLM's responses and a user prompt (both described below) that contains the specific query. We maintain consistency in the user prompt by limiting it to just the premise and hypothesis (we call these \textit{s1} and \textit{s2} in our prompts, not to be confused with System 1 and System 2, which are never shortened in this paper). We develop two distinct task definitions, one for each labeling scheme, and employ two different prompting styles. The task definitions are as follows:
    \begin{itemize}
        \item \textbf{6-way:}\\
            Assuming s1 is true, choose the statement that seems most accurate for s2:
            \begin{enumerate}[label=\Alph*.]
                \item Absolutely must be false
                \item Is more likely to be false
                \item Has strong reasons to be true and strong reasons to be false
                \item Has no reasons to be either true or false
                \item Is more likely to be true
                \item Absolutely must be true
            \end{enumerate}
        \item \textbf{3-way:}\\
            Choose one option about the inferential relationship between s1 and s2:\\
            Entailment: s2 entails s1\\
            Contradiction: s2 contradicts s1\\
            Neutral: Cannot pick either of the above or both are likely
    \end{itemize}
    The first prompting style, called \textit{base prompting}, simply explains the task and asks the LLM to provide its prediction. The exact base prompt is: \texttt{\{task definition\}} Pick exactly one option and write it on the first line. Do not write anything else.'' The second prompting style, \textit{personality prompting}, adds a brief description of the desired personality for the LLM to adopt, in addition to the base prompt. The personality prompt reads: ``Hereâ€™s your personality: \texttt{{personality}}. Focus on this personality and respond just like a person who has this personality. \texttt{\{task definition\}} Pick the first answer that you think of based on your personality and nothing else. Pick exactly one option and write it on the first line. Do not write anything else.'' The different personalities are derived from the Big Five personality traits (OCEAN model) \citep{roccas_big_2002}, with each trait simplified to a high (+) or low (--) value to create ten different personality prompts shown in Table \ref{tab:prompts}.

    For our experiments, we use the same set of responses generated by all LLMs. For base prompting, we obtain this set by prompting the LLM ten times with a temperature setting of 1 (to maximize response entropy) to generate a distribution with ten votes. For personality prompting, we use each of the ten personality prompts to generate ten votes, then select the majority vote from each prompt's votes to compile a set of ten votes. This approach yields ten votes each for the base and personality prompting styles. It is important to note that the LLMs are not fine-tuned for this task, in contrast to the classical machine learning algorithms, which are fine-tuned. This intentional disparity aims to test the LLMs' innate ability to replicate human responses.
    
    \subsection{Are human responses predictable?}\label{sec:accuracy}
        
        \begin{figure}[t]
             \centering
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/6way_part1_accuracy.png}
                 \caption{6-way System 1}
                 \label{fig:6way_S1_accuracy}
             \end{subfigure}
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/6way_part2_accuracy.png}
                 \caption{6-way System 2}
                 \label{fig:6way_S2_accuracy}
             \end{subfigure}
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/enc_part1_accuracy.png}
                 \caption{3-way System 1}
                 \label{fig:enc_S1_accuracy}
             \end{subfigure}
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/enc_part2_accuracy.png}
                 \caption{3-way System 2}
                 \label{fig:enc_S2_accuracy}
             \end{subfigure}
                \caption{Human gold label prediction accuracy of classical machine learning models using various input schemes: base features only (green diamond \textcolor{Green}{\ding{117}}), base features with count vectorization of premise and conclusion (purple cross \textcolor{Plum}{\ding{58}}), and base features with TFIDF encoding of premise and conclusion (orange X \textcolor{YellowOrange}{\ding{54}}). LLMs are also included with base prompting (blue circle \textcolor{blue}{\ding{108}}) and personality prompting with equal weights (red square \textcolor{Red}{\ding{110}}). Dashed line represents the majority baseline for the classification task.}
                \label{fig:accuracy}
        \end{figure}
        
        The task of predicting the mode (also referred to as the gold label) of human responses can be approached as a classification problem, since all categories are different from one another. While it can also be framed as a regression problem, this approach presents several challenges. First, NLI has classically been modeled as a classification task, and efforts to convert it to a regression problem \citep{chen_uncertain_2020} have faced significant difficulties \citep{nighojkar_no_2023}. Second, although our 6-way scale resembles a Likert scale, neither our 3-way nor our 6-way scale can be directly interpreted as a regression task because there is no intermediate value between 1 and 2 (or A and B) on our 6-way scale. The debate on whether Likert-like scales should be treated as regression is discussed in \citet{sullivan_analyzing_2013}.

        To process human responses for the 6-way classification scheme, we convert labels ranging from A to F into a categorical format corresponding to numbers 1 through 6. Similarly, for the 3-way scheme, the labels contradiction, neutral, and entailment are mapped to 1, 2, and 3, respectively. We use four classical machine learning algorithms: Stochastic Gradient Descent (SGD) \citep{JMLR:v15:gupta14a}, Decision Tree \citep{quinlan_induction_1986}, Random Forest \citep{tin_kam_ho_random_1998}, and a Feed-forward Neural Network \citep{schmidhuber_deep_2015}. Various statistics and features that might influence the predictability of responses are added to the dataset, including (1) the word count of premises and conclusions, (2) the perplexity of premises and conclusions, (3) the BLEU score between premise and conclusion, and (4) sentiment analysis of premises and conclusions using the VADER tool. Collectively, these are referred to as ``base input features.''
        
        Given that these algorithms cannot natively process raw text data, we tokenize the text to remove stopwords and punctuation, then encode the premises and conclusions using Bag-of-Words and TF-IDF \citep{robertson_understanding_2004}, converting the text into numerical representations. The choice of encoding is crucial, as it impacts the model's ability to capture linguistic nuances. Due to the limited data available, which restricts the size of the test set, we employ grid search to optimize these algorithms. The models are trained on a simple classification task, where they predict the gold label for human responses based on the input features, separately for both System 1 and System 2 responses. The performance of the best hyperparameter combinations, averaged across 5-fold cross-validation, is presented in Figure \ref{fig:accuracy}. For LLMs, we rely on the majority vote from ten base prompts and the majority vote from ten personality prompts for each item.
        
        This task primarily aims to predict the population-level gold label, and while it may oversimplify individual reasoning differences, addressing whether human responses are predictable is a critical step before conducting more sophisticated analyses. As anticipated, the accuracy for the 3-way scheme (Figures \ref{fig:enc_S1_accuracy} and \ref{fig:enc_S2_accuracy}) surpasses that of the 6-way scheme (Figures \ref{fig:6way_S1_accuracy} and \ref{fig:6way_S2_accuracy}). The majority vote baseline, which simply predicts the most common gold label in the dataset, achieves higher accuracy on System 1 for both schemes; however, classical ML algorithms only slightly outperform this baseline. The baseline accuracy significantly declines for System 2 in both the 6-way and 3-way schemes, suggesting greater diversity in human responses for System 2 compared to System 1. Despite this decline, the classical ML algorithms maintain performance levels close to those observed in System 1, indicating a consistent degree of predictability in both System 1 and System 2 responses, with predictability being higher in System 1. Notably, Figure \ref{fig:accuracy} reveals that LLMs perform nearly equally well in predicting gold labels for System 1 and System 2 responses, and they significantly surpass the baseline in System 2, emerging as the most effective at predicting the label most agreed upon by humans using System 2 reasoning. The fact that LLMs perform similarly on the 6-way scheme as they do on the 3-way scheme is also intriguing. Despite fewer choices in the 3-way scheme, which theoretically should make it easier, the LLMs' performance suggests that the increased granularity of the 6-way scheme may render human responses more predictable for LLMs than initially expected.
    
    \subsection{Is the variance in human responses predictable?}\label{sec:var}
    
        \begin{figure}[t]
             \centering
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/6way_part1_var_rmse.png}
                 \caption{6-way System 1}
                 \label{fig:6way_S1_rmse}
             \end{subfigure}
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/6way_part2_var_rmse.png}
                 \caption{6-way System 2}
                 \label{fig:6way_S2_rmse}
             \end{subfigure}
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/enc_part1_var_rmse.png}
                 \caption{3-way System 1}
                 \label{fig:enc_S1_rmse}
             \end{subfigure}
             \begin{subfigure}{0.49\textwidth}
                 \centering
                 \includegraphics[width=\textwidth]{images/enc_part2_var_rmse.png}
                 \caption{3-way System 2}
                 \label{fig:enc_S2_rmse}
             \end{subfigure}
                \caption{RMSE for predicting variance between human responses using classical machine learning models with various input schemes: base features only (green diamond \textcolor{Green}{\ding{117}}), base features with count vectorization of premise and conclusion (purple cross \textcolor{Plum}{\ding{58}}), and base features with TFIDF encoding of premise and conclusion (orange X \textcolor{YellowOrange}{\ding{54}}). LLMs are also included with base prompting (blue circle \textcolor{blue}{\ding{108}}) and personality prompting with equal weights (red square \textcolor{Red}{\ding{110}}). Dashed line represents the mean baseline and dotted line represents the median baseline for the regression task.}
                \label{fig:var}
        \end{figure}
        
        After determining that we can predict the human gold label on both System 1 and System 2 with accuracy exceeding the majority baseline, we proceed to predict the variance among all human responses for a given item. This variance is calculated by mapping the human responses onto a scale from 1 to 6, as described in Section \ref{sec:accuracy}. It is important to note that, for this task, we treat the responses as ordinal rather than nominal, since the objective is to predict the variance between the human responses. Given that we are treating this as a regression task, we use root mean squared error (RMSE) as the evaluation metric, where a lower value indicates better performance \citep{armstrong_error_1992}. As in Section \ref{sec:accuracy}, we employ four different machine learning algorithms: ridge regression \citep{hoerl_ridge_2000}, decision tree, random forest, and a feed-forward neural network. We conduct a grid search to optimize hyperparameters and report the average results of a 5-fold cross-validation, as shown in Figure \ref{fig:var}. For LLMs, we calculate the variance from ten votes using base prompting and ten votes using personality prompting to compare with the human variance for each item. The baselines in this analysis predict either the mean or the median variance across all items.
        
        Since the 3-way scheme offers fewer options, the variance values fall within a narrower range, leading to lower prediction errors compared to the 6-way scheme, which is consistent with expectations. In both schemes, traditional ML algorithms outperform the baselines, although the margin of improvement is minimal. For both schemes, the variance between LLM votes significantly differs from the variance between human responses, with this disparity being much larger than what was observed in the accuracy of predicting the gold label (Figure \ref{fig:accuracy}).This indicates that predicting variance is a highly challenging task for LLMs, especially without any fine-tuning.
    
    \subsection{Can AI mimic the entire human response distribution?}\label{sec:mimic}
        
        Given the contrasting results obtained from our initial two experiments, further investigation is required to evaluate the ability of LLMs to emulate human reasoning. Additionally, while maxima and variance provide insight into a distribution, they represent only two of its characteristics. To more comprehensively evaluate the similarity between the response distributions of LLMs and humans, we now focus on comparing the entire response distribution. The Wasserstein Distance \citep{dobrushin_prescribing_1970}, also known as Earth Mover's Distance (EMD), serves as a metric for quantifying the difference between probability distributions across a specified metric space --- in this instance, the set of labels in a 3-way or 6-way classification scheme. Conceptually, if each distribution is visualized as a unit mass of earth, the EMD reflects the minimal \textit{cost} required to transform one distribution into the other, considering both the amount of earth that needs to be moved and the mean distance it must be moved. This makes EMD particularly suitable for our case, as it is sensitive to the ordinal nature of the metric.
        
        Since EMD requires a probability distribution, we transform each set of human responses into a vector of size $k$ (three or six for the 3-way or 6-way scheme), where each entry represents the frequency of the corresponding label. We then normalize this vector to create a probability distribution. Notably, EMD has an unbounded range, so we convert it into a similarity measure ranging from 0 to 1, which we term Earth Mover's Similarity (EMS). Our similarity function, defined as: \[\textit{EMS}(D_1, D_2) = 100^{\textit{EMD}(D_1, D_2)}\] takes the two normalized probability distributions $D_1$ and $D_2$ as inputs. While $e$ is often used as the base for exponents, we chose a base of $100$ in this study to better distinguish variations, as using $e$ would compress the values of interest into a narrow range.
        
        In our comparison, we previously evaluated LLMs against traditional ML algorithms trained on our dataset. However, these algorithms do not generate a distribution of votes. In this experiment, we assign weights to each of the ten personality prompts and use a genetic algorithm to identify the optimal set of weights for each of the five folds (as in Experiments \ref{sec:accuracy} and \ref{sec:var}). For each fold, we again conduct a grid search to find the best hyperparameters (parent selection type and crossover type) for training the genetic algorithm, while fixing the number of generations at 8, the population per generation at 256, and the number of mating parents at 128. These parameters were chosen to balance computational costs with performance, though we did not do a rigorous comparison of all possible values due to computational cost limitations. We refer to this setup as personality prompting with a genetic algorithm, or \texttt{P-GA}. Additionally, we test a setup using personality prompting with equal weights, termed \texttt{P-EQ}.
        
        \begin{figure}
            \centering
            \begin{subfigure}[b]{0.49\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/6way_S1_EMS_boxplot.png}
                \caption{System 1 (6-way)}
                \label{fig:ems-s1-6}
            \end{subfigure}
            \begin{subfigure}[b]{0.49\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/6way_S2_EMS_boxplot.png}
                \caption{System 2 (6-way)}
                \label{fig:ems-s2-6}
            \end{subfigure}
            \begin{subfigure}[b]{0.49\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/3way_S1_EMS_boxplot.png}
                \caption{System 1 (3-way)}
                \label{fig:ems-s1-3}
            \end{subfigure}
            \begin{subfigure}[b]{0.49\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/3way_S2_EMS_boxplot.png}
                \caption{System 2 (3-way)}
                \label{fig:ems-s2-3}
            \end{subfigure}
            \caption{Earth Mover's Similarity (EMS) between human votes and model votes. `(B)' indicates base prompting (blue boxes), `(P-EW)' indicates personality prompting with equal weights (orange boxes) and `(P-GA)' indicates personality prompting with the genetic algorithm to fine-tune the weights of each prompt (green boxes).}
            \label{fig:ems}
        \end{figure}
        
        For a more thorough comparison, we compute three baselines. The \textit{uniform baseline} (blue box at the bottom of all plots in Figure \ref{fig:ems}) distributes probabilities equally across the label space (all six labels for 6-way and all three labels for 3-way). The \textit{normal distribution baseline} (orange box at the bottom of all plots in Figure \ref{fig:ems}) distributes probabilities normally around the mean of human votes, using the standard deviation of the human votes. The \textit{best ML models} baseline (dotted line in all plots in Figure \ref{fig:ems}) distributes probabilities around the mean predicted by the best ML model for the gold labels, with the standard deviation predicted by the best ML model for the variance.
        
        Figure \ref{fig:ems} presents box plots of EMS between human and model votes for each of the five folds' test sets. It is evident that LLMs significantly outperform the best ML models in mimicking the full distribution for both System 1 and System 2 in both the 3-way and 6-way schemes. The normal distribution baseline performs better on the 6-way scheme than on the 3-way scheme, possibly because the 3-way scheme has fewer labels and thus fewer data points from which to infer a normal probability distribution. For the 6-way scheme, personality prompting consistently outperforms or matches base prompting (markedly so for some architectures), with \texttt{P-GA} slightly outperforming \texttt{P-EQ}. The 3-way scheme is the only case where this trend does not hold, suggesting that personality prompting is more effective than base prompting at replicating the full human distribution, especially with the increased granularity of the 6-way scheme.
        
        Another notable trend is that no GPT architecture outperforms the best-performing open-source LLM. Most GPT models have EMS values comparable to or even lower than those of the best ML models in the 3-way scheme (Figures \ref{fig:ems-s1-3} and \ref{fig:ems-s2-3}). Mistral is the best model on 6-way System 1 (Figure \ref{fig:ems-s1-6}) with Llama being a close second; however, Llama surpasses Mistral on 6-way System 2 (Figure \ref{fig:ems-s1-6}). Llama models also perform best on the 3-way scheme (Figures \ref{fig:ems-s1-3} and \ref{fig:ems-s2-3}). Although Gemma never emerges as the top-performing model, it outperforms GPT-4 in the 6-way scheme (Figures \ref{fig:ems-s1-6} and \ref{fig:ems-s2-6}) and nearly all GPT models in the 3-way scheme (Figures \ref{fig:ems-s1-3} and \ref{fig:ems-s2-3}). The only exception is GPT-3.5, which surposses other, newer GPT models in the 3-way scheme (Figures \ref{fig:ems-s1-3} and \ref{fig:ems-s2-3}) but is outperformed by GPT-4o-mini in the 6-way scheme (Figures \ref{fig:ems-s1-6} and \ref{fig:ems-s2-6}).

        \paragraph{Data Availability Statement} All our code and data has been attached to this submission and \href{https://github.com/Advancing-Machine-Human-Reasoning-Lab/NSF-EAGER-NLI}{this GitHub repository} will be made public upon acceptance to make it available to the larger audience.