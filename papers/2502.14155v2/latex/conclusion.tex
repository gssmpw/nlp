\section{Conclusion}\label{sec:conclusion}

    This study advances the field of AI reasoning by shifting the focus from merely predicting a single answer chosen by the majority of humans to modeling the full distribution of human reasoning responses. Predicting this distribution---a challenge we call the ``full spectrum reasoning problem''---is not just a more comprehensive approach; it is essential for developing AI systems that can more accurately reflect the diversity and complexity of human thought. This is particularly important in applications where understanding the range of human reasoning, rather than simply selecting the most common response, is critical for tasks such as decision-making \citep{stone_artificial_2020, lai_towards_2023}, personalized interactions \citep{fitzpatrick_delivering_2017, araujo_speaking_2024}, and ethical AI deployment \citep{mittelstadt_principles_2019}.

    Our findings with personality prompting are especially promising, demonstrating that this approach can more closely align LLM outputs with human reasoning distributions while maintaining computational efficiency. Unlike base prompting, which requires multiple independent prompts to approximate a distribution, personality prompting allows for a more targeted generation of responses, using resources equivalent to base prompting but yielding more human-like results. The efficiency of our \texttt{P-GA} method, which leverages genetic algorithms to optimize personality prompts without the need for GPU resources, further underscores the practicality of our approach. Further investigation into different prompting styles \citep{liu_pre-train_2023, sahoo_systematic_2024} is necessary to assess how they compare to personality prompts.

    The broader implications of this work are significant. By providing a framework to evaluate the \textit{human-ness} of reasoning in both closed-source \citep{lieber_jamba_2024, templeton2024scaling} and open-source \citep{falcon40b, vicuna2023, workshop_bloom_2023} LLMs, our study enables a more nuanced assessment of AI models. Our finding that open-source models like Llama and Mistral exhibit reasoning patterns that align more with human cognition (at least with respect to the tasks we present here) than larger, proprietary models like GPT-4 challenges the assumption that larger parameter counts necessarily lead to more human-like AI. This insight is valuable not only for AI researchers but also for developers seeking to create more relatable and effective AI systems.

    Additionally, our results suggest intriguing avenues for future research. For instance, the participants generally refrained from choosing the middle two options (C or D) corresponding to neutral for all question types in both phases of our survey. This suggests an underlying bias that further research can confirm. The observed correlation between participants' System 1 and System 2 responses in Figure \ref{fig:tau} opens up the possibility of refining LLMs to better model individual cognitive processes. This could involve tailoring personality prompt weights to specific users, enhancing the accuracy and personalization of AI reasoning through techniques such as \textit{hyperparameter hypothesization} \citep{nighojkar_cognitive_2022, nighojkar_inference-centric_2024}.

    While our experimental design offers robustness by being independent of publicly available datasets, it also presents a limitation: the findings are contingent on the specific questions used. Nevertheless, we believe our experimental setup is more robust than those previously observed in this field of research \citep{hagendorff_human-like_2023} and can be scaled to larger datasets with relative ease, providing a strong foundation for further research in this area.

    In summary, this work represents a significant step towards AI that more faithfully emulates human reasoning, emphasizing the importance of predicting the full distribution of human responses rather than relying on simplified models of accuracy. This approach not only enriches our understanding of AI-human interaction but also lays the groundwork for more sophisticated and human-like AI systems in the future.