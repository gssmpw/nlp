\section{Overheads of Mapping/Thresholds Searcher and Precision Assigner}\label{app:overhead}

In this appendix, we report the overhead incurred by \FWName{'s} newly added components. Note that \FWName{'s} mapping/threshold learner and precision learner can both be done offline. The former only needs to be run for each model architecture, while the latter only needs to be run for each combination of model architecture and user-specified precision requirement.

\textbf{Mapping/Threshold Learner Overhead} We timed the overhead of our mapping/threshold learner on a single NVIDIA A100 SXM GPU with GPU memory. For each precision, we ran 2 iterations of the Lloyd-Max algorithm, which we found sufficient to push down the MSE and enhance task performance.  From the average of 10 runs, each run on Bart-Large, Llama2-7B, and Llama2-13B takes 111.46, 309.87, and 464.92 seconds, respectively. 



\textbf{Solver Overhead} We build our two-level ILP pipeline using the opensourced Coin-Or Branch and Cut (CBC) \cite{saltzman2002coin} solver via the Python-based modeling library PuLP \cite{mitchell2011pulp}. The experiments were run on a server with 2x Intel Xeon Gold 6342 CPUs. The solver uses 8 threads in parallel. We timed the overhead of running this two-level ILP pipeline for each combination of model architecture and precision requirement. From the average of 10 runs, each run on Bart-Large, Llama2-7B, and Llama2-13B takes 48.99 seconds, 319.13 seconds, and 665.93 seconds, respectively. Note that an exact (i.e., one-step) solver for the same problem would fail to finish in a reasonable amount of time. 

% \cyrus{do we need to cite th emodels here?}
% \qz{Add if we have these numbers.}