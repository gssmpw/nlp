\section{Ablation Studies} \label{app:ablation}
In this appendix, we perform ablation studies on the different components of \FWName{}. In particular, we compare the fine-tuning results with QLoRA, LoftQ, ours with only the precision assigner, and ours with both the precision assigner and the mapping/threshold searcher. Table \ref{tab:encdecablation} reports results of Bart-Large on XSUM and CNN/DailyMail. Table \ref{tab:llamaablation} reports results of Llama-2-7B on Wikitext2.

\begin{table}[ht!]
\centering
\resizebox{0.9\textwidth}{!}{%
\begin{tabular}{llcccccccccc}
\toprule
\multirow{2}{*}{\textbf{Technique}} & \multirow{2}{*}{\textbf{Metric}} 
& \multicolumn{5}{c}{\textbf{XSUM}} 
& \multicolumn{5}{c}{\textbf{CNN/DailyMail}} \\
\cmidrule(lr){3-7}\cmidrule(lr){8-12}
 & & \textbf{2} & \textbf{2.25} & \textbf{2.5} & \textbf{3} & \textbf{4}
   & \textbf{2} & \textbf{2.25} & \textbf{2.5} & \textbf{3} & \textbf{4} \\
\midrule

\multirow{3}{*}{\textbf{QLoRA}} 
 & \textbf{ROUGE1$\uparrow$} 
   & DNC & 16.3727 & 15.3282 & 17.6011 & 39.0742 
   & 4.8420 & 11.8987 & 13.6767 & 15.3374 & 41.1846 \\
 & \textbf{ROUGE2$\uparrow$} 
   & DNC & 2.2212 & 1.9712 & 2.6801 & 16.3124 
   & 0.0040 & 1.3188 & 1.0364 & 1.1239 & 18.3249 \\
 & \textbf{ROUGEL$\uparrow$} 
   & DNC & 12.8367 & 12.5547 & 13.9294 & 31.0891 
   & 4.3608 & 10.2535 & 9.9929 & 10.4375 & 27.5773 \\
\midrule

\multirow{3}{*}{\textbf{LoftQ}} 
 & \textbf{ROUGE1$\uparrow$} 
   & 31.8941 & 32.6153 & 33.7645 & 36.0222 & 40.3429
   & 38.8866 & 39.3648 & 39.8138 & 40.4684 & 41.1247 \\
 & \textbf{ROUGE2$\uparrow$} 
   & 10.1775 & 10.7005 & 11.7335 & 13.4883 & 17.0615
   & 16.4935 & 16.8711 & 17.1934 & 17.7529 & 18.2853 \\
 & \textbf{ROUGEL$\uparrow$} 
   & 24.5908 & 25.1533 & 26.2388 & 28.1558 & 31.9186
   & 25.8534 & 26.2877 & 26.5726 & 26.8812 & 27.5372 \\
\midrule

\multirow{3}{*}{\textbf{Ours, PA Only}} 
 & \textbf{ROUGE1$\uparrow$} 
   & 31.8941 & 36.4856 & 37.2861 & 38.1543 & 40.3429 
   & 38.8866 & 40.3669 & 40.6187 & 41.1820 & 41.1247 \\
 & \textbf{ROUGE2$\uparrow$} 
   & 10.1775 & 13.6310 & 14.3775 & 15.1856 & 17.0615 
   & 16.4935 & 17.6272 & 17.8600 & 18.3966 & 18.2853 \\
 & \textbf{ROUGEL$\uparrow$} 
   & 24.5908 & 28.4593 & 29.2036 & 29.9965 & 31.9186 
   & 25.8534 & 26.7442 & 26.9107 & 27.4180 & 27.5372 \\
\midrule

\multirow{3}{*}{\textbf{Ours, PA + MTSearch}} 
 & \textbf{ROUGE1$\uparrow$} 
   & 36.7454 & 37.2915 & 37.6897 & 38.8396 & 40.2669
   & 40.1489 & 41.0133 & 40.8819 & 40.8470 & 40.9493 \\
 & \textbf{ROUGE2$\uparrow$} 
   & 13.9324 & 14.3641 & 14.7587 & 15.6822 & 17.1800
   & 17.4843 & 18.1898 & 18.0609 & 18.1191 & 18.1223 \\
 & \textbf{ROUGEL$\uparrow$} 
   & 28.6133 & 29.1175 & 29.5275 & 30.5712 & 32.0614
   & 26.6717 & 27.2268 & 27.0113 & 27.2309 & 27.5392 \\
\bottomrule
\end{tabular}
}

\caption{Comparison of ROUGE scores with \textbf{Bart-Large} on \textbf{XSUM} and \textbf{CNN/DailyMail }under different techniques and combinations of techniques. \textbf{PA} refers to the two-level precision assigner. \textbf{MTSearch} refers to mapping and threshold search.}
\label{tab:encdecablation}
\vskip -0.2in
\end{table}



\begin{table}[ht!]
\centering
% Uncomment the line below if you need to shrink the table to fit text width
% \resizebox{\textwidth}{!}{%
\resizebox{0.75\textwidth}{!}{%
\begin{tabular}{l l c c c c c c c c c}
\toprule

\multirow{2}{*}{\textbf{Technique}} & \multirow{2}{*}{\textbf{Metric}} 
& \multicolumn{9}{c}{\textbf{Wikitext2}} \\
\cmidrule(lr){3-11}
 & & \textbf{1.5} & \textbf{1.75} & \textbf{1.8} & \textbf{1.9} 
   & \textbf{2} & \textbf{2.25} & \textbf{2.5} & \textbf{3} & \textbf{4} \\
\midrule

\multirow{2}{*}{\textbf{QLoRA}} 
 & Perplexity & - & - & - & - & 9.17 & 8.67 & 8.05 & 7.13 & 6.22 \\
 & Accuracy   & - & - & - & - & 0.526 & 0.534 & 0.546 & 0.566 & 0.583 \\
\midrule

\multirow{2}{*}{\textbf{LoftQ}} 
 & Perlexity & - & - & - & - & 8.63 & 8.22 & 7.72 & 6.87 & 5.26 \\
 & Accuracy  & - & - & - & - & 0.536 & 0.543 & 0.552 & 0.571 & 0.613 \\
\midrule

\multirow{2}{*}{\textbf{PA Only}} 
 & Perplexity & ND & ND & ND & ND & 8.63 & 8.22 & 7.75 & 6.75 & 5.26 \\
 & Accuracy   & ND & ND & ND & ND & 0.536 & 0.542 & 0.550 & 0.570 & 0.613 \\
\midrule

\multirow{2}{*}{\shortstack[l]{\textbf{PA}+\textbf{MTSearch}}} 
 & Perplexity & 9.38 & 7.76 & 7.50 & 7.13 & 6.60 & 6.40 & 6.23 & 5.84 & 5.25 \\
 & Accuracy   & 0.521 & 0.548 & 0.553 & 0.562 & 0.574 & 0.578 & 0.582 & 0.593 & 0.6123 \\
\bottomrule
\end{tabular}
} % End of \resizebox
\caption{Comparison of perplexity and accuracy of \textbf{Llama2-7B} on the \textbf{Wikitext2} dataset under different techniques and combinations of techniques. ``ND'' indicates no data, ``-'' indicates the techniques fail to support these precisions. \textbf{PA} refers to the two-level precision assigner. \textbf{MTSearch} refers to mapping and threshold search.}
\label{tab:llamaablation}
% \vskip -0.1in
\end{table}


We observe generally that the precision assigner gives a significant advantage for Bart-Large on summarization summarization tasks (Table \ref{tab:encdecablation}), whereas the mapping/threshold searcher yields significant gains for Llama-2-7B on Wikitext2 (Table \ref{tab:llamaablation}). Interestingly, the precision assigner only yields minimal advantage over LoftQ for Llama-2-7B on Wikitext2. 

In terms of applying the mapping/threshold searcher to Bart-Large (Table \ref{tab:encdecablation}), we see a less significant gain in the 2.5-4.0 precision range in comparison to the gains in the 2.0-2.5 precision range. This is in line with our intuition as at higher precision there are more mappings and thresholds for capturing distributions during quantization and dequantization; thereby, the tolerance for a less accurate combination of mappings and thresholds is higher.

We encourage future works to build upon \FWName{} and study the optimal precision assignment and mapping/threshold search algorithms for different types of architectures (\ie encoder-decoder, encoder-only, decoder-only). We will provide easy integration to new advances in our open-sourced repository.