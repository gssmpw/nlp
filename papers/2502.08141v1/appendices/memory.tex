\section{Memory Requirements}\label{app:memory}
In this appendix, we provide a detailed breakdown of memory footprints. 
Figure \ref{fig:finetuning_memory} shows the \textbf{\textit{fine-tuning}} memory footprint decompositions for \textbf{Llama-2-7B} and \textbf{Llama-2-13B}. Figure \ref{fig:inference_memory} shows the \textbf{\textit{inference}} memory decomposition for \textbf{Llama-2-7B} and \textbf{Llama-2-13B}. Figure \ref{fig:llama2_13b_memory} shows \textbf{\textit{both inference and fine-tuning}} memory footprint decomposition for \textbf{Llama-33B}.  For finetuning, we follow QLoRA's setup of using a batch size of 1 and sequence length of 512. Number labels on the bars are in MegaBytes (MB). Estimations are linear layer only (not attention).


\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.9\textwidth]{images/memory_usage_comparison.pdf}}
\caption{Decomposition of \textbf{\textit{finetuning}} memory footprint for Llama-2 7B and 13B under different bits per parameter.}
\label{fig:finetuning_memory}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.9\textwidth]{images/inference_memory.pdf}}
\caption{Decomposition of \textbf{\textit{inference}} memory footprint for Llama-2 7B and 13B under different bits per parameter.}
\label{fig:inference_memory}
\end{center}
\vskip -0.2in
\end{figure}


\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.85\textwidth]{images/llama_30b.pdf}}
\caption{Decomposition of memory footprint for Llama-33B under different bits per parameter.}
\label{fig:llama2_13b_memory}
\end{center}
\vskip -0.2in
\end{figure}

% \newpage
% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=0.6\columnwidth]{images/llama2_13b_memory.pdf}}
% \caption{Decomposition of \textbf{\textit{finetuning}} memory footprint for Llama-2-13B under different bits per parameters.}
% \label{fig:llama2_13b_memory_finetuning}
% \end{center}
% \vskip -0.2in
% \end{figure}


% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=0.6\columnwidth]{images/llama2_13b_inference_memory.pdf}}
% \caption{Decomposition of \textbf{\textit{inference}} memory footprint for Llama-2-13B under different bits per parameters.}
% \label{fig:llama2_13b_memory_inference}
% \end{center}
% \vskip -0.2in
% \end{figure}



% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=0.6\columnwidth]{images/llama_33b_memory.pdf}}
% \caption{Decomposition of \textbf{\textit{finetuning}} memory footprint for Llama-33B under different bits per parameters.}
% \label{fig:llama_33b_memory_finetuning}
% \end{center}
% \vskip -0.2in
% \end{figure}


% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=0.6\columnwidth]{images/llama_33b_inference_memory.pdf}}
% \caption{Decomposition of \textbf{\textit{inference}} memory footprint for Llama-33B under different bits per parameters.}
% \label{fig:llama_33b_memory_inference}
% \end{center}
% \vskip -0.2in
% \end{figure}


% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=0.6\columnwidth]{images/llama2_7b_memory.pdf}}
% \caption{Decomposition of \textbf{\textit{finetuning}} memory footprint for Llama-2-7B under different bits per parameters.}
% \label{fig:llama2_7b_memory_finetuning}
% \end{center}
% \vskip -0.2in
% \end{figure}


% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=0.6\columnwidth]{images/llama2_7b_inference_memory.pdf}}
% \caption{Decomposition of \textbf{\textit{inference}} memory footprint for Llama-2-7B under different bits per parameters.}
% \label{fig:llama2_7b_memory_inference}
% \end{center}
% \vskip -0.2in
% \end{figure}




\newpage