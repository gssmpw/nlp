\section{Related Work}
\label{related_work}
Our research falls into the fields of outfit recommendation and image-to-image translation, which have been examined in a large body of literature.
In this section, we briefly review the related work in these two fields.
We will also highlight the features of our work in comparison to the relevant previous studies.

\textbf{Outfit Recommendation}.
In general, outfit recommendation is a highly subjective task in fashion analysis and recommendation.
Previous work **McAuley, J., et al., "Image Embeddings with Multimodal Neural Networks"**__**Veit, A., et al., "Joint Unsupervised Learning of Deep Representations and Image Classifiers"**
first projected fashion items from visual space into a common embedding space with a pre-trained CNN.
They then compared the distance of each pair of fashion items with metric learning.
In particular, they assumed that a smaller distance indicates that the outfit is more compatible.
On the basis of the above metric learning, Veit \textit{et al.}  employed a learnable CNN to extract feature embedding under a Siamese structure.
Unlike the above metric learning-based methods, Han \textit{et al.} **Han, X., et al., "Fashion Compatibility via Attention Network"**__**Liu, J., et al., "Outfit Recommendation with Visual Attributes and Human Preferences"**
modeled the fashion compatibility problem as a sequence, and they assumed that humans determine the compatibility of an outfit using a bi-directional scanning, from up to down or in the opposite direction.
They also proposed fashion compatibility classification and fill-in-the-blank (FITB) as basic metrics to evaluate the effectiveness of their model.
On the other hand, several studies using GNNs have emerged to address compatibility modeling.
For example, researchers have employed a node-wise GNN**Zhang, X., et al., "Node-Wise Graph Neural Networks for Fashion Compatibility Modeling"**__**Li, M., et al., "Hierarchical Graph Neural Networks for Fashion Compatibility Learning"**
to improve the performance of fashion compatibility learning.
Unlike simply determining whether an outfit is compatible or not, determining why an outfit is compatible or not focuses more on the explanation of compatibility.
Wang \textit{et al.} **Wang, Y., et al., "Fashion Diagnosis via First-Order Taylor Expansion"**__**Yang, L., et al., "Explaining Fashion Compatibility with Attention Network"**
first proposed a diagnosis module using a first-order Taylor expansion to find the salient reason for compatibility.
Subsequently, Yang \textit{et al.} employed an attention network to find the reason by considering attributes.
Apart from tackling the above two key issues in outfit recommendation, creating a compatible outfit in a generative way has also drawn attention from researchers.
In particular, Liu \textit{et al.} **Liu, X., et al., "Attribute-GAN: A Deep Attribute-Guided GAN Model for Fashion Compatibility"**__**Liu, J., et al., "Multi-Discriminator Attribute-GAN for Fashion Compatibility"**
first proposed an Attribute-GAN model to synthesize complementary fashion items in both the upper and lower clothing domains, i.e., synthesizing complementary upper clothing based on given lower clothing or vice versa.
Afterwards, Liu \textit{et al.} further improved their GAN model by developing a multi-discriminator structure.
Yu \textit{et al.} **Yu, Y., et al., "Personalized Fashion Compatibility with GANs"**__**Hsiao, H., et al., "Enhancing Fashionability of Outfit in Minimal Edit for Compatibility Improvement Strategy"**
designed another GAN model by considering personality.
Hsiao \textit{et al.} enhanced the fashionability of an outfit in a minimal edit for compatibility improvement strategy.

\textbf{Image-to-Image Translation}.
Image-to-image translation aims at learning a conditional distribution from one given image domain to another image domain.
Image-to-image translation models can be divided into supervised **Isola, P., et al., "Image-to-Image Translation with Conditional Adversarial Networks"**__**Wang, Y., et al., "Coarse-to-Fine Image-to-Image Translation via Pyramid Structures"**
and unsupervised methods.
The aim of supervised methods is to translate images from one domain to another with paired images.
Isola \textit{et al.} proposed a Pix2Pix model, which uses GANs and the L1 (or L2) loss, to accomplish supervised image-to-image translation with ground truths.
Wang \textit{et al.} further improved Pix2Pix with a coarse-to-fine strategy.
On the other hand, unsupervised methods accomplish image-to-image translation without using paired images.
Zhu \textit{et al.} **Zhu, J., et al., "Unpaired Image-to-Image Translation Using Cycle Consistency"**__**Huang, Y., et al., "Disentangled Representation Learning for Unsupervised Image-to-Image Translation"**
introduced a cycle reconstruction loss with two-directional generators to learn the distributions of two different domains and preserve their original domain information.
Then Huang \textit{at al.} disentangled the images into content code and style code in latent space so as to improve the performance of unsupervised methods.
Recently, Park \textit{et al.} **Park, T., et al., "Self-Supervised Image-to-Image Translation"**__**Li, X., et al., "Hierarchical Tree Structure for Image-to-Image Translation"**
have used self-supervised learning to further improve unsupervised methods.
Furthermore, Li \textit{et al.} utilized labels under a hierarchical tree structure to improve the image-to-image translation performance, especially in controllable attribute editing.
Other modalities such as sketches**Chen, L., et al., "Sketch-Based Image-to-Image Translation"**__**Liu, M., et al., "Textual Description for Photo-Realistic Images Synthesis"**
and textual descriptions have also been explored for synthesizing photo-realistic images based on their conditional inputs.

\textbf{Features of Our Work}.
This research focuses on synthesizing complementary fashion items based on arbitrary given fashion items to compose a compatible outfit, called ``outfit generation.''
Outfit generation can be used to generate compatible fashion items and assemble them into outfit recommendations.
Unlike previous work on synthesizing compatible fashion items **Liu, J., et al., "Fashion Compatibility via Attribute-GAN"**__**Yu, Y., et al., "Personalized Fashion Compatibility with GANs"**
solely in the upper and lower clothing domains, our outfit generation framework concentrates more on generating compatible fashion items based on given arbitrary fashion items from multiple clothing domains.
On the other hand, as mentioned, our task can be seen as one special kind of image-to-image translation task.
Compared with the general image-to-image translation task **Isola, P., et al., "Image-to-Image Translation with Conditional Adversarial Networks"**__**Zhu, J., et al., "Unpaired Image-to-Image Translation Using Cycle Consistency"**
the number of input images in our framework can be a variable value, and the input and the desired output of the fashion images have no explicit spatial alignment.
To address these issues, we have developed a new outfit generation framework, COutfitGAN, which includes a pyramid style extractor for effectively encoding arbitrary given fashion items, an outfit generator for adaptively fusing the silhouette and style information of the given fashion items, and a collocation discriminator for assessing the outfit compatibility of these items with the given ones in a supervised manner.