% \vspace{-0.01in}
\section{Performance Evaluation}
%\vspace{-0.05in}
We evaluate the performance of ACCORD in 5G when serving the example MCA in two distinct scenarios, each representing a practical use case with unique characteristics and challenges.
%\vspace{-0.05in}
\subsection{Experiments}
%\vspace{-1mm}
The considered scenarios are simulated with gNB, UEs and MCA configurations mirroring those in the preliminary experiments (Sec.\,\ref{sec:preliminary_experiment}) but with different latency requirements in a reduced BW of 5\,MHz to show spectrum efficiency.\newline
\noindent $\bullet$ \textbf{Scenario A -  Stationary UEs: }
%This scenario simulates applications with stationary UEs, such as fixed traffic cameras for edge-assisted navigation. 
We consider two cases: (1) a single UE positioned 5000\,m from the gNB with a CQI of 10, and (2) two UEs at distances of 600\,m and 3600\,m, with CQIs of 15 and 8, respectively.\newline
\noindent $\bullet$ \textbf{Scenario B - Mobile UEs: }
%This scenario emulates applications involving mobile UEs, such as drone-based tracking. 
Here also we consider two cases: (1) a single UE moving away from the gNB at 60\,mph with decreasing CQI over time, and (2) two UEs, one with degrading CQI and the other with improving CQI.\newline
In both scenarios, the gNB and UEs are initialized with random configurations across all layers.\newline
\noindent $\bullet$ \textbf{DRL Architecture \& Training: }The DRL agent in ACCORD employs a DQN algorithm described in Sec.\,\ref{sec:solution}.B and Algorithm\,\ref{Algo:dqn} with the following hyper-parameters: batch size\,128, discount factor (gamma)\,0.2, replay memory capacity\,10,000, and Adam optimizer with a learning rate\,0.0001. The neural network architecture, depicted in Fig.\,\ref{fig:drl_agent_architecture}, utilizes a multilayer perceptron with ReLU activation functions, fully connected layers (FC) with 256 neurons each, and batch normalization (BN) after specific layers. The input to the network consists of key performance metrics collected every 10\,ms that form the State space described in Sec.\,\ref{sec:solution}.B.
%uplink transmitted bytes, MCS, CQI, and application-required latency. 
These metrics are aggregated over a 100\,ms window, preprocessed, and fed into the network as a vector of shape (40,1) for a single UE and (80,1) for two UEs. The network output is mapped to specific configurations across the PHY, MAC, RLC, and APP layers using a predefined codebook. Based on the selected action, the reward is generated using the reward function described in Sec.\,\ref{sec:solution}.B.

\begin{figure}[t!]
    \centering
    %\vspace{-3mm}
\includegraphics[trim=20 10 40 20,clip,width=\linewidth]{Figures/drl_figures/drl_network_1.pdf}
    \vspace{-5mm}
    \caption{MLP Model used for training the DQN in ACCORD.}
    \vspace{-2mm}
\label{fig:drl_agent_architecture}
\end{figure}

\begin{figure}[h!] % Force placement at the top of the column
    \centering
    %\vspace{-1mm} % Adjust as needed to control vertical spacing
    \begin{subfigure}{0.48\columnwidth} % Adjust width to fit within a single column
        \includegraphics[width=\linewidth]{Figures/drl_figures/1uestatic_rewards.pdf}
        \caption{Single static UE.}
        \label{fig:static_ue_a}
    \end{subfigure}
    \hspace{1mm} % Small horizontal space between subfigures
    \begin{subfigure}{0.48\columnwidth} % Adjust width to fit within a single column
        \includegraphics[width=\linewidth]{Figures/drl_figures/2uestaticandmobile_rewards_with_1UE.pdf}
        \caption{Multiple UEs, static\,\&\,mobile.}
        \label{fig:static_ue_b}
    \end{subfigure}
    \vspace{-5mm}
    \caption{Rewards achieved by the DRL agent for optimizing the network for different network setup scenarios considered.}
    \vspace{-3mm} % Reduce space after the figure
    \label{fig:rewards}
\end{figure}
\begin{comment}
\begin{table}[h]
\centering
\caption{Common DRL Hyperparameters and Values}
\begin{tabular}{ll}
\toprule
\textbf{Hyperparameters} & \textbf{Value} \\
\midrule
\multicolumn{2}{l}{\textbf{DQN Agent}} \\
Batch size & 128 \\
Gamma & 0.2 \\
Replay Memory capacity & 10000 \\
% Number of iterations & 400 \\
% Training steps & 100000 \\

\midrule
\multicolumn{2}{l}{\textbf{Optimizer}} \\
Optimizer & AdamOptimizer \\
Learning rate & $0.0001$ \\

\midrule
\multicolumn{2}{l}{\textbf{Neural Network (Fig. \ref{fig:drl_agent_architecture})}} \\
% Conv1D Layer & filters=32 \\
% & kernel size=$B=8$ \\
% & strides=$B=8$ \\
% & activation=ReLU \\
% Flatten Layer & 225 neurons \\
% Dense Layer 1 & 128 neurons \\
% Dense Layer 2 & 32 neurons \\
% Dense Layer 3 & 1400 neurons \\
\bottomrule
\end{tabular}
\label{tab:dqnparams}
\end{table}
\end{comment}
% \vspace{-2mm}
%\textbf{Evaluated DRL Architecture:}
%For training the DRL agent using the DQN algorithm described in section \ref{sec:solution}, the hyperparameters used were \texttt{Batch Size 128}, \texttt{Gamma 0.2}, \texttt{Replay memory} capacity \texttt{10000}, and \texttt{Adam optimizer} with learning rate \texttt{0.0001}. These hyperparameters are common to both scenarios considered and the multilayer perceptron architecture used is shown in Fig. \ref{fig:drl_agent_architecture}. For the input, we narrow down our metrics considered to the uplink transmitted bytes, MCS, CQI and the application required latency. These metrics are analyzed for every 10ms frame which contain 20 slots based on the periodicity we have chosen. These metrics are then accumulated for 100ms, are then preprocessed and then form a shape of (40,1) in the case of a single UE and (80,1), in the case of two UEs. The input is fed into the neural network to produce an action that corresponds to the optimal configuration across the layers of interest to minimize the latency. We have created a codebook that maps output of the neural network to these configurations.  Based on this selected action, the reward is generated using the reward function described in section \ref{sec:solution}.
% \vspace{-0.1in}

\begin{figure}[t!] % Adjust to place the figure at the top of the column
    \centering
    %\vspace{-2mm} % Adjust as necessary to control vertical spacing
    \begin{subfigure}{0.48\columnwidth} % Width adjusted for side-by-side placement in a column
        \includegraphics[width=\linewidth]{Figures/netwrk_perf/1uestatic_req_latencies.pdf}
        \caption{Single Static UE at a fixed location of 5000\,m from the gNB with a constant CQI of 10.}
        \label{fig:static_ues_a}
    \end{subfigure}
    \hspace{1mm} % Small horizontal space between the subfigures
    \begin{subfigure}{0.48\columnwidth} % Width adjusted for side-by-side placement in a column
        \includegraphics[width=\linewidth]{Figures/netwrk_perf/2uestatic_req_latencies.pdf}
        \caption{Two static UEs located 600m and 3600m from the gNB with CQI 15 and 8, respectively.}
        \label{fig:static_ues_b}
    \end{subfigure}
    \caption{Performance of various RAN configurations in meeting different latency requirements for static UEs.}
    \vspace{-3mm} % Reduce vertical space after the figure
    \label{fig:static_ues}
\end{figure}

\vspace{-0.2in}
\begin{figure*}[h!]
\centering
\begin{subfigure}{0.24\textwidth} % Adjusted to 0.23\textwidth for consistent layout
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/1uemobile_30ms.pdf}
    \caption{Latency \& CQI trends}
    \label{fig:1ue_time_cdf_plots_a}
\end{subfigure}\hfil % <-- added
\begin{subfigure}{0.22\textwidth} % Adjusted to 0.23\textwidth for consistent layout
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/1uemobile_30ms_cdf.pdf}
    \caption{30\,ms latency}
    \label{fig:1ue_time_cdf_plots_b}
\end{subfigure}\hfil % <-- added
\begin{subfigure}{0.24\textwidth} % Adjusted to 0.23\textwidth for consistent layout
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/1uemobile_18ms.pdf}
    \caption{Latency \& CQI trends}
    \label{fig:1ue_time_cdf_plots_c}
\end{subfigure}\hfil % <-- added
\begin{subfigure}{0.22\textwidth} % Adjusted to 0.23\textwidth for consistent layout
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/1uemobile_18ms_cdf.pdf}
    \caption{18\,ms latency}
    \label{fig:1ue_time_cdf_plots_d}
\end{subfigure}
%\vspace{-0.05in}
\caption{Performance of various RAN configurations in meeting various latency requirements (30\,ms \& 18\,ms) for a mobile single UE with varying CQI over time (Emulating a UE moving away from gNB).}
\vspace{-2mm}
\label{fig:1ue_time_cdf_plots}
\end{figure*}
\begin{figure*}[h!]
\centering
\begin{subfigure}{0.24\textwidth} % Adjusted width to fit four images in two columns
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/2uemobileue1_30ms.pdf}
    \caption{UE\,1 latency \& CQI trends.}
    \label{fig:2ue_time_cdf_plots_a}
\end{subfigure}\hfil
\begin{subfigure}{0.22\textwidth} % Adjusted width
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/2uemobileue1_30ms_cdf.pdf}
    \caption{30\,ms latency (UE1).}
    \label{fig:2ue_time_cdf_plots_b}
\end{subfigure}\hfil
\begin{subfigure}{0.24\textwidth} % Adjusted width
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/2uemobileue2_30ms.pdf}
    \caption{UE\,2 latency \& CQI trends.}
    \label{fig:2ue_time_cdf_plots_c}
\end{subfigure}\hfil
\begin{subfigure}{0.22\textwidth} % Adjusted width
    \includegraphics[width=\textwidth]{Figures/netwrk_perf/2uemobileue2_30ms_cdf.pdf}
    \caption{30\,ms latency (UE2).}
    \label{fig:2ue_time_cdf_plots_d}
\end{subfigure}
%\vspace{-0.05in}
\caption{Performance of various RAN configurations for two mobile UEs in meeting a latency requirement of 30\,ms. Both UEs have varying CQI over time (UE\,1 emulates moving away from gNB while UE\,2 emulates moving towards gNB).}
\vspace{-4mm}
\label{fig:2ue_time_cdf_plots}
\end{figure*}
\vspace{0.2in}
\noindent $\bullet$ \textbf{Learning Performance: }Fig.\,\ref{fig:rewards} illustrates the learning progress of the DRL agent in each scenario, indicated by the total reward accumulated per episode during training. For the single stationary UE scenario (Fig.\,\ref{fig:static_ue_a}), the agent exhibits rapid convergence to the maximum reward, 
%achieving it around episode 20 
for all the considered uplink latency thresholds (24\,ms, 30\,ms, and 40\,ms). With 150 iterations per episode and a maximum reward of 50 per iteration, the achievable maximum reward per episode is 7500. Similarly, for the multiple UEs scenario (Fig.\,\ref{fig:static_ue_b}), the agent demonstrates faster convergence in the static case compared to the mobile case. This observation validates the effectiveness of the DRL agent in learning optimal policies for both single and multiple UEs.
%while also highlighting the increased complexity associated with mobile environments. 
To facilitate learning in the more challenging mobile scenario, we employed longer training episodes, allowing the agent more time to explore the state-action space and adapt to the dynamic channel conditions.\newline

{\em These results underscore the capability of the DRL agent to effectively learn and adapt to diverse network conditions, optimizing configuration parameters across multiple layers to meet the different latency requirements of MCAs across multiple UEs. The observed convergence behavior further suggests the robustness and stability of the DRL in ACCORD.}
%of the DRL agent for optimizing our proposed ACCORD framework.
%shows the reward accumulated by the agent in each considered network scenario we described in the network setup during the training of the DRL agent. In Fig.\,\ref{fig:single_static_ue}, we can observe that in the static case, that the agent converges quickly to the maximum rewards at around episode 20 for all considered required application latency. In this case, the number of iterations for each episode was 150 and the maximum reward that can be gotten in an iteration is 50. Therefore, the maximum reward in an episode is 7500. 
%In the case of a mobile UE as shown in Fig. \ref{fig:rewards} (b), we can observe that it takes longer (Up to 50th episode) to converge to the maximum rewards and this is because as the UE moves away from the gNB, the signal quality degrades and changes over time, so the agent needs more time to converge. Also, we can see that the agent is able to achieve maximum rewards for latency requirements of 24 and 30ms but fails to reach the maximum rewards for the 18ms latency requirement. Here, the number of iterations was increased to 200 for each episode, leading to a maximum reward for an episode to be 10000. We would also observe in further analysis how this situation now either requires the increase in bandwidth or for the optimization of the application layer in addition to the PHY, MAC and RLC layers already being optimized. 
%Similarly, in Fig.\,\ref{fig:multiple_ues}, in the case of multiple UEs, for the static case, the agent converges faster compared to the mobile case, therefore validating the training for single and multiple UEs. In the case of multiple UEs, we train for longer iterations per episode for better learning.
\vspace{-0.01in}
\subsection{ACCORD Performance Results}
%\vspace{-0.05in}
%We now comment on the the performance of the agent in meeting different latency requirements for each network scenario we considered in comparison with the fixed cross-network configuration approach.
This section analyzes the performance of ACCORD in comparison to the fixed configuration approach of legacy 5G networks.\newline
%focusing on ACCORD's ability to meet diverse latency requirements across different scenarios.\newline
\noindent $\bullet$ \textbf{Observation (Scenario A - Stationary UEs): }Fig.\,\ref{fig:static_ues_a} illustrates the achieved latency for a single static UE under varying latency requirements (24\,ms, 30\,ms, and 40\,ms). ACCORD consistently outperforms the fixed configurations of legacy 5G networks, demonstrating its ability to use information from the context to dynamically adjust network parameters and closely match the desired latency. This adaptability is crucial in resource-constrained environments, as the framework avoids over-provisioning resources and efficiently utilizes available bandwidth. For instance, when the required latency is 24\,ms, ACCORD converges to a configuration of 5\,DL-5\,UL slots, Round Robin scheduling, and RLC buffer size of 6\,KB, to meet the target latency. Conversely, for a 40\,ms latency requirement, the agent selects a less resource-intensive configuration of 6\,DL-4\,UL slots, Round Robin scheduling, and a buffer size of 2\,KB.  This adaptive behavior contrasts with the fixed configurations, which often overshoot or undershoot the latency target, leading to either over-allocation of network resources or performance degradation. Similar trends are observed in Fig.\,\ref{fig:static_ues_b} for the multiple static UEs scenario.  Despite the varying channel conditions and individual latency requirements of the two UEs, ACCORD successfully meets the target latency of 24\,ms for both, demonstrating its ability to handle diverse user demands and optimize network resources accordingly.\newline

\vspace{-0.1in}
\noindent $\bullet$ \textbf{Observation (Scenario B - Single Mobile UE): }Fig. \ref{fig:1ue_time_cdf_plots_a} depicts the performance of ACCORD and two fixed 5G configurations in meeting the latency requirement of a single mobile UE.
%over a 2500\,ms period. 
As the UE moves away from the gNB, its channel quality given by the CQI degrades.
%from 15 to 10.  
While the fixed configurations can initially meet the latency requirement, their performance deteriorates as the CQI drops below 13. In contrast, ACCORD proactively adapts to the changing channel conditions and MCA context, dynamically adjusting network parameters to consistently maintain the desired latency. This adaptability is further evident in the statistical analysis presented in Fig.\,\ref{fig:1ue_time_cdf_plots_b}. The cumulative distribution function (CDF) of achieved latency demonstrates that ACCORD not only consistently meets the latency requirement but also operates close to the target without excessive over-provisioning of resources. For instance, ACCORD initially employs a configuration of 7\,DL-3\,UL slots, Proportional Fair scheduling, and a buffer size of 6\,KB at a CQI of 15. As the CQI degrades to 12 and the latency approaches the threshold, ACCORD incrementally increases the buffer size to 8\,KB and then 10\,KB.  With further CQI degradation, ACCORD switches to a new configuration with 6\,DL-4\,UL slots, Round Robin scheduling, and a buffer size of 2\,KB. This dynamic adaptation highlights ACCORD's ability to effectively utilize network resources and respond to changing channel conditions. Fig.\,\ref{fig:1ue_time_cdf_plots_c} examines a more stringent latency requirement, where the fixed configurations struggle to meet the target as the UE moves away from the gNB.  This scenario underscores the limitations of fixed configurations in dynamic environments, particularly with limited bandwidth (5\,MHz). To address this, the agent optimizes APP layer parameters, enabling it to consistently meet the latency requirement even with significant CQI degradation.

\noindent $\bullet$ \textbf{Observation (Scenario B - Multiple Mobile UEs):} Similar to the single mobile UE case, ACCORD outperforms the fixed 5G configurations in the multiple mobile UE scenario, effectively handling the complexities introduced by varying channel conditions and individual UE mobility patterns.\newline
%we compare two different fixed RAN configurations with the DRL agent in achieving the UE required latency for 2500 ms. As observed in the plot, we can see how the CQI of the UEs drops from 15 to 10 as the UE moves away from the gNB. The fixed configuration approach can meet the latency requirement up until the CQI drops to 13, whereas the agent was able to determine that that configuration was not optimal and generated the right configuration to meet the UE latency requirement and channel conditions. We can also analyze this result statistically as seen in Fig.\,\ref{fig:1ue_time_cdf_plots_b}, we can see that based on the required latency, the agent always achieves a latency that is not just less than the required latency but also as close as possible to the required latency thereby indicating that the agent also ensures that the network does not over-allocate resources to meet latency requirements. For instance, the agent initially converges to a configuration of 7 DL, 3 UL, PF, and a buffer size of 6 at CQI of 15, and at CQI of 12, as soon as the latency achieved tries to overshoot the required latency, the agent converges to a new configuration by first just increasing the buffer size to 8 and then 10. Then as the CQI keeps on degrading, increasing the buffer size does not help anymore so the agent then gets a new configuration that includes changing the slot configuration to 6 DL and 4 UL, then using RR and buffer size of 2.
%In Fig.\,\ref{fig:1ue_time_cdf_plots_c} (c), we analyze the performance when we use a lower latency threshold. As seen in the figure, the fixed configuration approach is hardly able to meet the desired latency requirement as the UE moves from the base station. 
%For the DRL agent, on the other hand, recall from Fig.\,\ref{fig:rewards_b}, the total rewards achieved for the 18ms latency requirement were very low as a result of just optimizing the PHY, MAC, and RLC layers. 
%In worst-case scenarios, after the CQI has degraded up to a certain point, there is no possible RAN configuration across these layers that can meet the desired latency given the limited BW of 5MHz that we considered. We either have to increase bandwidth or we then optimize the application layer by signaling the UE to change its application layer parameters. This is reflected in Fig.\,\ref{fig:1ue_time_cdf_plots_c}, we can see that in optimizing the application layer parameters, we can ensure that the UE latency requirement is met at all CQI levels. Similar to the statistical analysis for a single mobile UE, we can see that in the case of the two mobile UEs that the agents outperforms the fixed RAN configurations in all scenarios.
%\vspace{-0.1in}
Fig.\,\ref{fig:2ue_time_cdf_plots} illustrates the performance analysis for a scenario with two mobile UEs experiencing dynamic channel conditions due to their movement relative to the gNB. ACCORD successfully meets the latency requirements of both UEs by selecting unique configurations at the RLC layer while maintaining common configurations across the PHY and MAC layers.  This differentiation stems from the varying CQI levels experienced by each UE, with one moving away from the gNB (degrading CQI) and the other moving towards it (improving CQI).  Applying a uniform configuration across both UEs would fail to address their individual needs and maintain consistent latency performance.  ACCORD intelligently adjusts the RLC layer buffer size to compensate for the varying channel conditions, ensuring that both UEs meet their respective latency requirements despite the dynamic environment.  This result underscores the importance of learning and responding to individual UE channel conditions in a multi-user scenario.\newline
These results collectively demonstrate the efficacy of ACCORD in optimizing 5G network performance for mobile applications. The ability to dynamically adapt to changing channel conditions, efficiently utilize network resources and optimize application layer parameters positions it as a powerful solution for ensuring QoS with efficient spectrum utilization in dynamic and demanding 5G environments.

{\em Overall, ACCORD's ability to differentiate configurations at the RLC layer while maintaining common parameters at the PHY and MAC layers highlights its nuanced and efficient resource allocation capacity, enabling the framework to effectively manage diverse user demands and optimize network performance even in complex and dynamic environments.}
%Fig.\,\ref{fig:2ue_time_cdf_plots} presents the performance analysis for the scenario with two mobile UEs, each experiencing dynamic channel conditions due to their movement relative to the gNB. Remarkably, ACCORD successfully meets the latency requirements of both UEs by selecting configurations that are unique at the RLC layer but common across the PHY and MAC layers. This differentiated approach stems from the varying CQI levels experienced by each UE, with one moving away from the gNB (experiencing degrading CQI) and the other moving towards it (experiencing improving CQI). Applying a uniform configuration across both UEs would fail to address their individual needs and maintain consistent latency performance. ACCORD recognizes this and intelligently adjusts the RLC layer buffer size, to compensate for the varying channel conditions. This custom optimization ensures that both UEs meet their respective latency requirements despite the dynamic environment.\newline
%This result underscores the importance of learning and responding to individual UE channel conditions in a multi-user scenario. ACCORD's ability to differentiate configurations at the RLC layer while maintaining common parameters at the PHY and MAC layers highlights its nuanced and efficient resource allocation capacity. This adaptive behavior enables the framework to effectively manage diverse user demands and optimize network performance even in complex and dynamic environments.
%\vspace{-2mm}
