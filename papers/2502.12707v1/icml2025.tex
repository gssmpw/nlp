%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
\pdfoutput=1
\documentclass{article}

\input{math_commands.tex}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{array}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{pdfpages}
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage{adjustbox}
\usepackage{fancyhdr}
\usetikzlibrary{arrows.meta}
\graphicspath{{figures/}}
\usepackage{fancyhdr} % for custom headers and footers

\usepackage{pifont}
\usepackage{xcolor}
\newcommand{\cmark}{\textcolor{green!80!black}{\ding{51}}}
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{The CausalMan simulator}

\begin{document}

\twocolumn[
\icmltitle{CausalMan: A physics-based simulator for large-scale causality}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Nicholas Tagliapietra}{bosch,tud}
\icmlauthor{Juergen Luettin}{bosch}
\icmlauthor{Lavdim Halilaj}{bosch}
\icmlauthor{Moritz Willig}{tud}
\icmlauthor{Tim Pychynski}{bosch}
\icmlauthor{Kristian Kersting}{tud,hessian}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{tud}{Computer Science Department, TU Darmstadt, Germany}
\icmlaffiliation{bosch}{Bosch Center for Artificial Intelligence, Renningen, Germany}
\icmlaffiliation{hessian}{Hessian Center for AI (hessian.AI), Germany}

\icmlcorrespondingauthor{Nicholas Tagliapietra}{nicholas.tagliapietra@de.bosch.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
A comprehensive understanding of causality is critical for navigating and operating within today's complex real-world systems.
The absence of realistic causal models with known data generating processes complicates fair benchmarking. In this paper, we present the \textit{CausalMan} simulator, modeled after a real-world production line. The simulator features a diverse range of linear and non-linear mechanisms and challenging-to-predict behaviors, such as discrete mode changes. 
We demonstrate the inadequacy of many state-of-the-art approaches and analyze the significant differences in their performance and tractability, both in terms of runtime and memory complexity. As a contribution, we will release the \textit{CausalMan} large-scale simulator. We present two derived datasets, and perform an extensive evaluation of both.
\end{abstract}

\section{Introduction}
\begin{figure*}[ht]
\centering
\includegraphics[width=0.95\textwidth]{figures/causalman_medium_fully_observable_ground_truth.png}\label{fig:ground_truth_dataset1}
\caption{Complete Ground truth causal graph including hidden variables for CausalMan Medium. Observable variables are colored in orange, and latent ones are colored in blue. 419 of 605 (69.2\%) of variables are latent.}
\end{figure*}
The mastery of \textit{Causal Reasoning} is a long-standing challenge in AI, with the potential to drastically impact many disciplines including medicine, science, engineering, and social sciences. 
The development of agents with an understanding of causality enables them to go beyond statistical co-occurrences, and is connected with desirable abilities such as reasoning and Out-of-Distribution generalization~\citep{richens2024robust}. 
Using the tools of \textit{Causality} \citep{Pearl_2009} we can uncover the \textit{Data Generating Process} (DGP), and manipulate it to gain a better understanding of the system being modeled.
With \textit{Causal Inference} we can estimate the effect of interventions on a system while accounting, among others, for confounding biases and missing data \citep{mohan2019graphicalmodelsprocessingmissing}.
To make progress in this area, a fair and comprehensive evaluation of causal algorithms is crucial, as well as benchmark tests analyzing methods from different angles. 
Laying down a comparison across multiple domains, however, presents various challenges. From a practical perspective, one of the main obstacles that impedes progress in causality is the lack of public benchmarks supporting method evaluation~\citep{Cheng2022EvaluationMA}.
When benchmarking on real world data, the true DGP may be partially or even completely unknown.
Additionally, an individual can either be treated or not, which means that we cannot simultaneously observe both potential outcomes, implying that the ground truth values of the causal estimands are not known. 
Consequently, purely factual observational data is insufficient for evaluation due to the unavailability of counterfactual measurements. 
A similar challenge is indicated by~\cite{DBLP:conf/nips/GentzelGJ19}, who stressed the importance of evaluating on interventional measures and downstream tasks. 
In most cases, however, obtaining interventional data is not possible, unethical, or highly expensive.
Shifting to simulated data, \cite{DBLP:conf/nips/CurthSWS21} argued that algorithms matching the assumptions of the DGP are advantaged in those specific benchmarks, but results may not transfer to other scenarios.
Despite this, when correctly designed, simulation can be a powerful tool to benchmark causal models. 
Thanks to causally-plausible simulators, we can obtain any interventional distribution while retaining control on every parameter knob, with the possibility to study any valuable corner case.
Along this path, we can use simulations to gain insights on the behaviour of causal models at the intersection of non-linearity, causal in-sufficiency and high dimensionality.
For the latter, bringing causality to the large scale has been the main driver for a series of efforts \citep{tigas2022interventions} that tried to understand the scalability issues that several causal models have when dealing with thousands of variables, as well as their inference limitations when performed with finite resources.
Scalability is a challenge not only for inference tasks, but also throughout the whole field of causality. The related task of \textit{Causal Discovery} (CD) i.e.,\ recovering the causal diagram from data, suffers from similar burdens, where often mathematical guarantees are sacrificed in exchange of computational feasibility~\citep{zheng2018dagstearscontinuousoptimization}. 
Hereby, we investigate how those methods perform at large scale, and consequently aim to answer the question whether current approaches are adequate for realistic scenarios. 
Our doubt stems from the looming intractability that current methods possess \textit{by design} \citep{EITER200253} when carrying out certain tasks, both from a theoretical and practical viewpoint. Additionally, differently from other works which explore causality in medicine, genetics and ecology, we focus on the manufacturing domain, which has found only scattered applications in the past \citep{Vukovic2022CausalDI, g√∂bler2024causalassembly}. 
Furthermore, we try to motivate the statement that mathematically sound large-scale causality may require new methodologies and engineering breakthroughs that are not yet developed.

\textbf{Contributions} We begin with a description of the real-world scenario, describing many mechanisms which should not be ignored. Next, we derive a set of mathematical requirements which have to be fulfilled, which motivate the development of the CausalMan simulator, as they are absent in other publicly available datasets.
Specifically, our contribution is three-fold:
\begin{itemize}
    \item We develop a physics-based simulator within the manufacturing domain in close collaboration with domain experts. The simulator is designed to meet the requirements of real-world scenarios and presents challenges such as hybrid data types, causal insufficiency, conditional dependencies, and nonlinearities. We utilize the simulator to generate two large benchmark datasets. We use the simulator to derive two large size datasets. The simulator will be released, enabling researchers to generate new observational and interventional data.
    \item Using the aforementioned datasets, we define various exemplary tasks and observe that a wide range of causal models are computationally prohibitive for certain tasks, while others lack expressiveness.
    \item We perform similar analyses for causal discovery, comparing classic algorithms and recent learning-based methods. 
    \end{itemize}
\section{Related Work}
In this section we analyze related approaches relevant to our work and datasets, highlighting common points and dissimilarities. For more exhaustive surveys on the evaluation of causal models, we address the interested reader to \cite{Cheng2022EvaluationMA}, \cite{DBLP:journals/csur/GuoCLH020} and \cite{DBLP:journals/tkdd/YaoCLLGZ21}.

\textbf{Large-Scale Causality:} In \cite{notallcausalinferencezece}, a theoretical and empirical evaluation on simple causal graphs highlighted the intractability of marginal inference and the scaling laws of different causal models. When the goal is to reduce the complexity of different intractable queries, it is possible to adopt \textit{tractable probabilistic models} such as \textit{Sum-Product Networks} (SPNs) \citep{poon2012sumproductnetworksnewdeep}. Furthermore, it is possible to use SPNs to model causal phenomena \citep{zecevic2021interventional, structuralcausalcircuits, poonia2024chispn, pmlr-v246-busch24a}.

Leveraging its independence from combinatorial objects such as graphs, \textit{Rubin's Potential Outcomes} (PO) framework \citep{Imbens_Rubin_2015} can be used to tackle the scalability problem. However, a notable limitation of the PO framework is its reliance on assumptions like \textit{ignorability}, that is equivalent to unconfoundedness and is not suitable for our strongly confounded use-case.

In the realm of causal discovery, scaling is addressed with novel methodologies such as continuous optimization-based approaches \citep{NEURIPS2018notears, 10.5555/3495724.3497230, DBLP:conf/iclr/LachapelleBDL20} or divide-and-conquer approaches \citep{lopez2022factorgraphs, wu2024sea}. 
However, while easier to scale, they suffer from distinct vulnerabilities. 
~\cite{Reisach2021BewareOT} and ~\cite{Kaiser2021UnsuitabilityON} show that their performance is sensitive to the scale of the data, and can degrade to levels comparable to or worse than classic approaches after data normalization. On a similar note \cite{loh_mse_unsuitable} and \cite{seng2024learning} remarked the limitations of methods relying on mean squared error losses. 
Further, \cite{mamaghan2024evaluationbayesian} studied the drawbacks of common metrics when adopting a Bayesian approach.
%First, results suggest these methods may be exploiting patterns of increasing marginal variance in data to reconstruct a causal graph, without any guaranteed analysis at a Causal level. Consequently, their performance can be controlled by manipulating the scale of the data~\cite{Reisach2021BewareOT, Kaiser2021UnsuitabilityON}, degrading to levels comparable to or worse than classic approaches after data normalization. 
Those drawbacks of ML-Based approaches re-ignited interest in novel and more mathematically grounded methods such as \textit{Extremely Greedy Equivalence Search} (XGES) \cite{nazaret2024extremely} or \textit{Differential Adjacency Test} (DAT) \cite{amin2024scalableflexiblecausaldiscovery}. 
\begingroup
%\setlength{\tabcolsep}{10pt} % Default value: 6pt
\renewcommand{\arraystretch}{1.25} % Default value: 1
\begin{table*}[t]
\small
\centering
\begin{tabular}{p{2.5cm}|m{1.2cm}|m{1.2cm}|m{1.2cm}|m{1.2cm}|m{1.65cm}|m{1.5cm}} 
 & Nonlinear & Mixed types & Cond. dependencies & Causal insufficiency & Interventional data & Large-scale  \\
\hline
CausalMan (ours) & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
CausalChambers & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark \\
CausalAssembly & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark \\
CausalBench & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark \\
Neuropathic-pain & \cmark & \xmark & \xmark & \xmark & \cmark & \cmark \\
\end{tabular}
\caption{Comparison of CausalMan's main features with other available simulators or datasets.}
\label{table:causalman_comparison}
\end{table*}
\endgroup

\textbf{Datasets and Benchmarks:}
A wide variety of benchmarks for causal models are publicly available~\citep{asiadataset, alarmdataset, sachsdataset}.
However, only a limited number of them target large scale scenarios~\cite{diabetesdataset}, and an even smaller fraction involve hybrid domains, which is the focus of our datasets and experiments.
To compensate the lack of data, a common choice for analysing scaling laws for causal models is to generate random Erdos-Renyi~\citep{Erdos1984OnTE} or Scale-Free graphs~\citep{barabasi1999emergence} which, although easy to simulate, are far from reflecting the real world. 
Recent works provide datasets and methodologies to generate realistic synthetic and semi-synthetic data. 
Semi-synthetic DGPs tuned on real data, often along with the use of prior domain knowledge, are the focus of simulators such as \textit{CausalAssembly} ~\citep{g√∂bler2024causalassembly} for the manufacturing domain, or the \textit{Neuropathic Pain simulator} ~\citep{DBLP:conf/nips/Tu0BK019} in the medical domain. Further, semi-synthetic DGPs are used in \cite{Dorie2017AutomatedVD,Hahn2019AtlanticCI} and \cite{Shimoni2018BenchmarkingFF} to generate datasets with real observational data for the untreated individuals, coupled with simulated treated counterparts.
Contrary to those datasets, our data comprise additional layers of complexity by simulating mechanisms such as batching, hybrid data-types and conditional dependencies.
% Real Data
Concentrating on real world data, CausalBench ~\citep{Chevalley2022CausalBenchAL} is a large scale benchmark for single-cell perturbation experiments with interventional data gathered using gene-editing technologies. 
A different strategy is adopted by CausalChambers~\citep{gamella2024causalchambers}, which builds a real isolated physical system where physical mechanisms are known almost perfectly, giving a high degree of confidence on the exactness of the ground-truth Structural Causal Model. Additionally, \cite{pmlr-v236-mogensen24a, mhalla2020causalmechanismextremeriver} provide real-world datasets with a more or less justified ground-truth causal graph.
\section{Background} 
\label{sec:background}
\subsection{Causal Models} 
Modern causality in the Pearl sense relies on intuitive graphical representations of causal phenomena. 
Here, we assume that the underlying causal structure can be represented by a \textit{Directed Acyclic Graph} (DAG) $\displaystyle \gG = (E,V)$, where the sets $V = \{1, \dots, d\}$ and $E \subseteq V \times V $ are vertices and directed edges respectively. Direct causes of a node $v_i$ are called Parents and are denoted with $\displaystyle \parents_\gG (v_i)$.
We now define \textit{Structural Causal Models}, which incarnate the Pearlian notion of causality \citep{Pearl_2009} and defines the DGP.
\begin{definition} A \textit{Structural Causal Model} (SCM) is a 4-tuple $\mathcal{M} \coloneq (\textbf{U}, \textbf{V}, P_{\textbf{U}}, \mathcal{F})$ where $\textbf{U}$ is the set of exogenous variables that are related to external factors, $\textbf{V}$ is the set of endogenous variables that depend on other endogenous/exogenous ones, $P_\textbf{U}$ is the probability density function of the exogenous variable $\textbf{U}$, and
$\mathcal{F} = \{f_1, f_2, \dots, f_n\}$ is the set of \textit{Structural Equations}, where each element is a mapping such that $f_i : U_i \cup Pa_i \rightarrow V_i$, with $U_i \subseteq \textbf{U}$ and $V_i \subseteq \textbf{V}$. Each endogenous variable is related to a structural equation that determines its values. In practice, each node $v_i \in V$ can be expressed as $ v_i = f_i (u_i, Pa_i) $.
\end{definition}
Interestingly, the dependencies between variables described by the structural equations collectively induce a causal graph. 
%Looking at the dependencies between variables induced by each structural equation, it is possible to extract a causal graph for the phenomena being modeled. 
Additionally, when we assume that the dependency on exogenous variables is additive, i.e.\, in the form $ v_i = f_i (Pa_i) + u_i $, we say that the SCM adopts an \textit{Additive Noise Model} (ANM). 

Causal models can be used to model the effects of \textit{interventions} i.e.\, the manipulation of causal mechanisms. A causal model that is capable of modeling the effect of interventions is called an \textit{interventional model}. Moreover, an \textit{intervention} in a SCM consists in replacing one (or more) structural equation $f$ with a different function $\hat{f}$.When we exchange $\hat{f} = a$ with $a \in \mathbf{R}$, we call it an \textit{atomic} intervention.  An intervention on a SCM might induce a different causal graph than the original unintervened one.
In section~\ref{sec:experiments} we show how different causal models may have radically different properties and computational requirements for the same causal query.

Lastly, even though the complete description of the causal phenomenon is assumed to be a DAG, its marginalisations to lower dimensions may not be DAGs. Indeed, if a set of variables is marked as latent, the operation of marginalizing out latent variables is called \textit{latent projection} \citep{verma2013equivalencecausalmodels}, which can result in a graph containing directed but also bi-directed edges representing relationships without a clear causal direction, called \textit{Acyclic Directed Mixed Graph} (ADMG).
\subsection{Treatment Effect Estimation}
The most common tasks in \emph{Causal Inference} (CI) involves the prediction of the effect of one or multiple interventions on an outcome variable and assess its effectiveness i.e.,\ the \textit{Treatment effect}.
Treatment effect estimation is based on comparing a population of treated individuals with a reference control group that did not receive any treatment. We proceed by defining the \textit{Average Treatment Effect} (ATE) which describes how, on average, an individual responds to a specific treatment:
\begin{equation}
   ATE =  \mathbb{E} [Y(1) - Y(0)],
\end{equation}
where $Y (1)$ and $Y(0)$ indicate respectively the outcomes in presence or absence of a treatment.\\
When searching for fine-grained estimates, we can encounter scenarios where treatments will affect different sub-populations heterogeneously e.g. \textit{Heterogeneous Treatment Estimation} (HTE). To identify the treatment effect to such level of detail, we condition the ATE on $X = x$, and define the \textit{Conditional Average Treatment Effect} (CATE) as
\begin{equation}
    \tau (x) = \mathbb{E} [Y (1) - Y (0) | X = x].
\end{equation}
\section{Motivating scenario} \label{sec:dataset}
Manufacturing lines exhibit complex behaviors that pose significant challenges when performing a causal analysis. For this purpose, we start from a motivating real-world scenario, describing the system and the mechanisms that distinguish an assembly line. Further, we use this scenario to derive a set of requirements that should be fulfilled. Finally, we compare our requirements with publicly available solutions, and discuss where our simulator fits.
\begin{table*}[t]
\centering
\begin{tabular}{ p{1.5cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1.5cm}|p{1.5cm}} 
%\hline
 & \multicolumn{2}{|c|}{Full Graph} & \multicolumn{2}{c|}{Observable Graph} & \multicolumn{2}{c}{\#  Samples} \\
\hline
 Dataset & Nodes & Edges & Nodes & Edges & Obs. & Int. \\
\hline
Small & 157 & 121 & 53  & 95(13) & 717,962 & 622,385 \\ 
Medium & 605 & 1,014 & 186  & 381(172) & 717,911 & 620,537\\ 
%\hline
\end{tabular}
\caption{Overview of the two datasets. On the left column we list the information for the full causal graph, while on the right for the partially observable graph. In parentheses we have the number of bi-directed edges. All our experiments use the partially observable (therefore causal insufficient) causal graph.}
\label{table:dataset_recap}
\end{table*}

\subsection{Real-world system}
We study a production line that assembles \textit{magnetic valves} (MV) and \textit{hydraulic blocks} (HB) together, forming \textit{Hydraulic Units} (HU). 

\textbf{Hydraulic Units and Magnetic Valves:} An HU is a device used to control the flow of a fluid. It is composed by an \textit{Hydraulic Block} (HB) and by a certain number of \textit{Magnetic Valves}. An HB is a mechanical component with a different number of bores where, during the assembly process, MVs are inserted into them with a press-fitting machine. 
A \textit{Magnetic Valve} (MV) is the electromechanical component inside the HU thanks to which, after applying a voltage, it is possible to control the flow of a fluid. In practice, by energizing the MVs we can control whether the fluid can flow or not through the HU. Each individual MV and HU could be characterized for their material (elasticity and stiffness) or geometric (length and/or diameter) properties.s), or geometrical quantities (diameter, length).

\textbf{Press-fitting:} The \textit{Press-Fitting} (PF) machine applies a force which inserts the MV into a bore of the HU. The force will insert the MV into the bore, but it will also deform it. At the end of the process the bore will be deeper than before by a certain amount which is determined by the physical models (with some stochasticity). Part of the deformation is permanent, and another other part will disappear after the pressing force is removed at the end of the process, as it is related to the elasticity of the material. If the force is too high, we may cause a damage that will end in the component being scrapped. Faults can be related to the leakage of fluid through the MV and through the HU in situations where it is not supposed to happen. Those faults are often caused by anomalies during the press-fitting process, i.e.\, the pressing force is too high, or can be caused by some properties of the MV or HB not being ideal, making them easier to break during assembly. Further details in \ref{appendix:structural_equations}. 

\textbf{Anomaly detection} \label{sec:dataset_monitoring}
Production lines typically incorporate anomaly detection mechanisms for the purpose of identifying faulty parts that are not fit for use. In the best case scenario, a defective product should be caught soon and removed (scrapped) before reaching the end of the production line. 
Moreover, many attributes have to stay within specific ranges of values (See Fig. \ref{fig:monitoring} in the appendix). This is described with a boolean variable that can be either true or false depending on whether an attribute is within a \textit{Lower Tolerance Limit} (LTL) and an \textit{Upper Tolerance Limit} (UTL). Those tolerances vary depending on the type of component being produced (see Fig. \ref{fig:monitoring} and Sec. \ref{sec:appendix_conditional_depepdences}).
\begin{equation}\text{MpGood}_i = 
\begin{cases} 
True & \text{if } \text{LTL}_i \leq x_i \leq \text{UTL}_i, \\
False & \text{otherwise}.
\end{cases}
\end{equation}
At the end of every process, a \textit{logic AND} operation between every \textit{MpGood} (Mechanic-Part Good) variable is performed to check if all the attributes within the machines fall within the desired range. If that is true, the variable ProcessResult, which signals the quality conformance of the final product, will be \textit{True}, otherwise \textit{False}. If the process result is false, the component is scrapped because at least one of the parameters is not within the acceptable range. 

\textbf{Batching:} Production is subdivided in \textit{batches} i.e.,\ groups of parts being produced together and sharing similar properties. 
On the same production line there might be different batches producing different products. Being a unique production line, all batches share the same causal structure, but they might differ in terms of parametrization. For example, different products may have different geometrical characteristics, or material properties, or a different force applied during press-fitting, etc. %Interestingly, different products identify distinct sub-populations, providing an ideal playground for testing various HTE techniques. %In sec.\ref{appendix:sampling}, we describe how batching affects the sampling procedure for both observational and interventional data. 

\subsection{Key Requirements} \label{sec:dataset_data_requirements}
We translate the expected behavior of a production line into mathematical requirements. Those are:

\textbf{(R1) Large-Scale:} Manufacturing lines have a large number of parameters and sensor measurements which form an intricate causal structure. The majority of those are important and should be considered.
 
\textbf{(R2) Interventional Data:} It should be possible to arbitrarily inject anomalies into the system in the form of an intervention. 

\textbf{(R3) Mixed data-Types:}
Data from manufacturing scenarios includes continuous physical quantities, but also discrete ones such as boolean flags, or categorical identifiers for suppliers and component types. Hence, we need to consider mixed Data-types, e.g.\, continuous, discrete, booleans and categorical variables. 

\textbf{(R4) Conditional dependencies:} Many continuous variables depend on a combination of different discrete parents. For example, the material elasticity of a MV depend on its type and on which supplier produced it, as some suppliers might be better than others.
In mathematical terms, certain node distributions are determined (i.e.,\ caused) by specific combinations of categorical parents. Given a variable $n_i$, the hyper-parameters determining its distribution can change discretely depending on the value of different categorical parent nodes. In Sec.\ref{sec:appendix_conditional_depepdences} a more detailed explanation, and in Fig.\ref{fig:second_order_uncertainty} an illustration of this mechanism. 

\textbf{(R5) Structural Equations and noise models:} Accurate and physically-motivated structural equations enable to model many failure modes that are present in the real system. Most physical models underlying the press-fitting process are nonlinear. This includes the dependency on exogenous variables, hence we are not dealing with any underlying ANM. 

\textbf{(R6) Causal Insufficiency: }\label{sec:dataset_causal_insufficiency}Although all physical mechanisms are well-known, in the real system it is possible to measure only part of the variables, therefore it is necessary to mirror the observability of the real system, marking every simulated variable either as observable or hidden. 

\section{The CausalMan simulator}

We analyse currently available simulators in connection with our requirements.  CausalChambers offers a causal model and realistic data, but is tailored for time-series and does not model large size graphs. The Neuropathic Pain Simulator is both causal and large-scale, and focuses on the medical domain, yet it is limited to binary variables. CausalAssembly is a large-scale simulator with mixed data types which permits the sampling of interventional data. However, it emphasizes causal sufficiency, lacks explicit physical models (which are instead learned), and does not account for conditional dependencies. CausalBench provides a suite of datasets centered on gene expression and interventional data, but it lacks heterogeneous data types, conditional dependencies, and large-scale capabilities. Table \ref{table:causalman_comparison} provides a comparison of those simulators.
Our \textit{CausalMan simulator} has been specifically designed to fulfill the requirements outlined in Sec.\ref{sec:dataset_data_requirements}. CausalMan is based on physical models derived from first principles (described in \ref{appendix:structural_equations}), and includes mechanisms such as conditional dependences (R4) related to suppliers and product types. 
Domain experts have been heavily involved during the entire workflow, including the definition of all physical models (R5) involved in the production life-cycle, and the validation/fine-tuning of simulation hyper-parameters. Suppliers or product types are represented by categorical variables, and physical quantities by continuous ones (R3). Each variable is classified as either observable or latent (R6). Additionally, we simulate a batching mechanism which also influences the sampling process (Sec.\ref{appendix:sampling}). This simulator permits to derive different datasets, reaching possibly hundreds of variables (R1). Since the underlying DGP is based on SCMs, it is possible to arbitrarily apply interventions (R2). For interventions, they can be hard/soft, single, multiple, and even on latent variables.

Lastly, we provide two large-size SCMs obtained from different configuration of the simulator. On \textit{CausalMan Small} we have a DGP of moderate size with 53 variables, whereas on \textit{CausalMan medium} we aim at the large-scale, and provide a DGP with 186 variables. On Table \ref{table:dataset_recap} we provide an overview on the scale of our datasets. 

\section{Experiments} \label{sec:experiments}
In this section we describe the general experimental setting, including the chosen causal models and causal discovery algorithms. Additional implementation details are present in \ref{sec:appendix_implementation}, including how data is pre-processed and numerically embedded.
\subsection{Causal Models}
We perform experiments on a representative set of causal models, with the goal of highlighting the different characteristics that those methods possess by design. We test \textit{Causal Bayesian Networks} (CBN) \citep{bareinboimpch}, \textit{Neural Causal Models} (NCM) \cite{xia2022causalneuralconnectionexpressivenesslearnability}, Normalizing Flows-based models such as \textit{CAREFL} \citep{careflkhemakhem2021} and \textit{Causal Normalizing Flows} \citep{causalnormjavaloy2023}, and \textit{Variational Causal Graph Autoencoders} (VACA) \citep{vacasanchezmartin2021}.
Lastly, when estimating treatment effects, we also consider regression-based techniques such as \textit{Linear} and \textit{Logistic Regression}. 
In appendix \ref{sec:appendix_causal_models} we provide a description of the chosen models. Below, we formulate four different interventional tasks, which reflect possible interventions or anomalies that may occur in the real world. We focus both on the accuracy of the single interventional distribution and also on the final ATE and CATE estimates. Moreover, we remark that all our experiments use the ADMG obtained after a latent projection to marginalize out latent variables (See Table \ref{table:dataset_recap} for more details). 

\textbf{Task 1:} In the \textit{first interventional task}, the treatment is an intervention on a lower tolerance value, which is raised to a higher value, with control value set to a lower one. 
The target variable is discrete, and is a grandparent of the outcome variable, 
\begin{align*}
    \text{ATE} = \mathbb{E}[Y | do(PF\_M1\_T1\_Force\_LTL=18000)] \\- \mathbb{E}[Y | do(PF\_M1\_T1\_Force\_LTL=15000)].
\end{align*}
After the treatment, the true interventional distribution has a higher probability of being 0 compared to the observational distribution, as the window of accepted values is narrower. 
In practical words, the intervention makes all samples to be classified as not good (ProcessResult = False). 

\textbf{Task 2:} We perform a \textit{second interventional task} with the goal of understanding the effect of increasing the press-fitting force (further information in Sec. \ref{appendix:structural_equations}). 
\begin{align*}
    \text{ATE} = \mathbb{E}[Y | do(PF\_M1\_T1\_Force=30000)] \\- \mathbb{E}[Y | do(PF\_M1\_T1\_Force=16000)]
\end{align*}
In this second task, the treatment increases the force value to a very high value, while the control intervention remains in the desired range. For certain types of product, the force is now set outside of the ideal range.
The force variable has multiple bi-directed edges with other variables describing the PF process. Moreover, it is also an ancestor for other variables, therefore an extreme intervention can cause a chain of outlier values to propagate towards other physical quantities that depend on it (For example $s_{grad}$ and $F_{max}$). 

\textbf{Task 3 and 4:} Interventions on parameters may have heterogeneous effects across different sub-populations. Consequently, ATE estimates provide a general insight on the behavior of the system, but cannot capture how different sub-populations react to the treatment, which is why in this case study we adopt a more targeted approach by estimating different CATEs. 
In our dataset, we can think of product types as sub-populations, where interventions on parameters can impact positively the quality of one product while degrading another. 
Therefore, we repeat the same interventional experiments as in task 1 and 2, \textit{while conditioning} on a categorical variable (the product type).

\subsection{Causal Discovery} \label{sec:causal_discovery}
Similarly, we perform Causal Discovery on our datasets using multiple algorithms.
We test classic methods such as the \textit{Peter-Clark} (PC) algorithm \citep{10.7551/mitpress/1754.001.0001}, its variant \textit{PC-Stable} 
\citep{10.5555/2627435.2750365}, and \textit{Linear Non-Gaussian Additive Noise Models} (LiNGAM) \citep{lingam}. For learning-based approaches, we test NOTEARS \citep{DBLP:conf/nips/ZhengARX18}, GOLEM \citep{10.5555/3495724.3497230}, DAG-GNN \cite{pmlr-v97-yu19a} and GranDAG \citep{DBLP:conf/iclr/LachapelleBDL20}. Additionally we capture metrics for a random \textit{Erdos-Renyi DAG} in every experiment to establish how distant those methods are from random guessing. 
\subsection{Metrics}

In a simulated environment, ground truth quantities are available. Therefore, for causal inference tasks we measure the distance between the estimated interventional distributions and the ground truth ones using the Mean Squared Error (MSE), Jensen-Shannon Divergence (JSD) \citep{jensenshannondivergence} and Maximum Mean Discrepancy (MMD) \citep{JMLR:v13:gretton12a}. 
For treatment effects, we measure the MSE between the estimated effect and the ground truth one. 
For causal discovery, we measure the Structural Hamming Distance (SHD), Structural Intervention Distance (SID) \citep{peters2014structuralinterventiondistancesid}, parent-Separation Distance (p-SD) \citep{wahl2024separationbaseddistancemeasurescausal}, Precision and Recall, as described in \ref{sec:appendix_metrics}.
Lastly, we also consider runtime metrics such as training and discovery time, and CPU/GPU memory usage for each model. For reproducibility, each experiment is repeated 5 times with different random seeds. In our results we average each metric across the seeds and report its mean and SD. Additional details on the hardware are listed in appendix \ref{sec:appendix_implementation}.
\section{Results and Discussion}

\begin{table*}[h] 
\small
\centering
\begin{tabular}{ p{1.5cm}|p{1.9cm}|p{1.9cm}|p{1.9cm}|p{1.9cm}|p{1.9cm} }
 %\hline
 Causal Model & ATE MSE & CATE MSE & JS-Div Tr. & MSE & MMD\\
 \hline
 NCM   & 1.115(0.118) & 1.665(0.159) & 0.206(0.005) & \textbf{0.172(0.001)} &  0.259(0.018) \\
 CAREFL & \textbf{0.982(0.223)} & \textbf{1.539(0.635)} & 0.164(0.105) & 0.279(0.197) &  NaN \\
 CNF   & 1.218(0.012) & 1.784(0.082) & 0.297(0.003) & 0.535(0.007) &  NaN \\
 VACA  & 1.214(0.009)   & 1.890(0.163) &\textbf{ 0.163(0.003)} & 0.265(0.006) &   \textbf{0.244(0.009)} \\
 Linear r. & 4.748(0.142)   & - & - & -  &  -\\
 Logistic r.& 0.992(0.015)   & - & - & -  &  -\\
 %\hline
\end{tabular}
\caption{CausalMan Small. Results for the second treatment effect estimation task using $n = 50.000$ samples and the ground truth ADMG. Linear regression is disadvantaged due to the presence of hidden confounders and nonlinear causal mechanisms. Sampling instabilities prevented the evaluation of MMD on CNF and CAREFL.}\label{table:effect_estimation_small_results_3}
\end{table*}

Given the intricate nature of the DGPs involved, it is unknown how most causal models will perform, as the mathematical assumptions on which most causal models rely are not fulfilled. Furthermore, identifiability is likely to not hold anymore. Therefore, we formulate the following research questions: 
\textbf{(Q1)} To what extent do causal models yield accurate estimates in large-scale scenarios? 
\textbf{(Q2)} What is the computational feasibility of implementing causal models in large-scale contexts? 
\textbf{(Q3)} Do available causal discovery methods generate sufficiently accurate causal graphs? 
\textbf{(Q4)} How effectively do causal discovery methods adapt to the challenges presented by large-scale scenarios?
\subsection{Causal Inference} \label{sec:effect_estimation_findings}
\textbf{Performance}: Table \ref{table:effect_estimation_results} shows the causal inference performance for the first two effect estimation tasks. 
All models are far from providing a positive answer to our first research question (Q1). 
In fig. \ref{fig:task_3_causalman_small} and table \ref{table:effect_estimation_small_results_3} we can indeed see that all interventional tasks are far from being solved. All causal models fail to reproduce simple interventional distributions. A similar behavior is present when estimating ATEs and CATEs as well.
Furthermore, all results transfer to CausalMan Medium.
On the first interventional task, most models provide inaccurate results, including regression-based methods. On the second task, which deals with an higher amount of confounded and nonlinear causal mechanisms, the deterioration of regression-based methods is evident. Although models based on normalizing flows (CAREFL and Causal Normalizing Flows) are consistently marginally more accurate, they are still unable to provide a satisfactory solution to the new challenges presented by this simulator.
An additional consideration is that, as shown in Figures \ref{fig:ate_mse_vs_size}, \ref{fig:shd_vs_dataset_size_1}, and \ref{fig:shd_vs_dataset_size_2}, all models did not improve significantly with the increase in size of the dataset.

Lastly, in appendix \ref{sec:appendix_additional_task} we study an additional interventional task which, although it is more constructed, studies a corner case where the intervened variable is a direct parent of the outcome. In that scenario, we can observe that a simple linear regression can outperform all other causal models. 
\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{figures/task_3_causalman_small_svg-tex.pdf} 
\caption{CausalMan Small. Performance for ATE MSE vs. dataset size on the second interventional task. On nontrivial tasks with large amount of nonlinearities and confounders, linear regression is clearly in disadvantage.}
\label{fig:task_3_causalman_small}
\vspace{-0.5cm}
\end{figure}

\textbf{Computational Scaling:} From a computational perspective, the results reveal an interesting and diverse landscape of model behavior. Methods based on normalizing flows or regression can provide a positive answer to (Q2), while all other learning-based models require prohibitive amounts of compute.
The computationally heaviest models are CBNs. For CBNs, which are capable of handling only discrete variables, continuous variables have been uniformly quantized in a finite number of steps. However, this design choice is associated with an explosion in memory requirements during the fitting process. This is due to the combination of a high number of states and the in-degree (e.g,\ parents) of some nodes, which leads to an exponential increase in the number of conditional probability distributions to be estimated. To limit memory requirements, we restrict the number of quantization steps to 20, as a higher number would lead to memory demands that are impossible to satisfy. 
No experiments were possible on CausalMan medium for the same reason, even after aggressively quantizing the training data.

Contrarily, deep models follow different scaling laws, as their complexity is mainly related to their architecture and the number of parameters in the network, rather than to the number of nodes. % in the network. 
In other words, large-scale causality does not directly imply a higher number of parameters, but larger causal graphs may require a higher model capacity, and consequently bigger neural networks. 
Among deep models, NCMs are proven to be the most computationally expensive. 
Figure~\ref{fig:runtime_vs_dataset_size} shows a long runtime and significant memory demands (Fig. \ref{fig:memory_usage_dataset1}) for training, thus limiting possible applications to large-size causal graphs. CAREFL and CNF showed more convenient scaling laws with respect to the dataset size (Fig. ~\ref{fig:runtime_vs_dataset_size}), and lower memory requirements (Fig. \ref{fig:memory_usage_dataset1}) with CausalMan medium. Overall, CAREFL and CNF have the potential to scale (computationally) to an even higher number of nodes, whereas NCM appear limited.  

\subsection{Causal Discovery} \label{sec:findings_causal_discovery}
Tables \ref{table:causal_discovery_small} and \ref{table:causal_discovery_medium} show results for causal discovery, and Sec.~\ref{sec:appendix_additional_results} provides additional results. 
Similarly, the answer to (Q3) is also negative. All algorithms are far from providing an accurate reconstruction of the causal graph on both datasets. 
Interestingly, we can see in tables \ref{table:causal_discovery_small} and Fig. \ref{fig:shd_bar_comparison}, that CausalMan Small constitutes an intermediate ground where classic methods such as PC or LiNGAM algorithms remain competitive with ML-Based methods. In this dataset, classic methods can still manage the dimensionality of the problem, both performance-wise and resource-wise.  In contrast, when scaling to CausalMan Medium, their limitations are visible in Fig. \ref{fig:shd_bar_comparison} and \ref{fig:discovery_time_10000_double_bar}, where classic methods fall behind.
Moreover, the SHD performance of all methods on all datasets is almost independent of the dataset size (Figure  \ref{fig:shd_vs_dataset_size_1} and  \ref{fig:shd_vs_dataset_size_2}), suggesting a limited capacity of leveraging large amounts of data.

Resource-wise, the answer to (Q4) is negative for classic methods, while learning-based methods might provide a viable approach. We observe strong scaling issues for constraint-based methods in Fig.\ref{fig:discovery_time_10000_double_bar}, where their runtime is multiplied by 20 to 40 times upon tripling the nodes in the graph. The decreasing performance of the PC algorithm on the second dataset can also be explained by the inapplicability of conditional independence tests on large graphs, as the probability of finding a d-separating set is infinitesimal as the number of variables tends to infinity~\citep{feigenbaum2023unlikelihooddseparation}. For methods based on continuous optimization, the growth in compute requirements is significantly smaller, and scaled almost linearly with the number of nodes.
Additionally, Fig.~\ref{fig:runtime_vs_dataset_size} indicates additional scaling limitations, this time with respect to the dataset size, where another significant increase in computation resources occurs. As before, this is not a problem for learning-based methods.
\begin{figure}[t]
\includegraphics[width=0.5\textwidth]{figures/double_bar_discovery_time_dataset_size_10000_svg-tex.pdf}
\caption{Time to discover a Causal graph with $n = 10.000$ samples. Methods thriving on CausalMan Small may be computationally impractical on CausalMan Medium.}
\vspace{-0.5cm}
\label{fig:discovery_time_10000_double_bar}
\end{figure}
Our analysis demonstrates that current CD methods, when dealing with large graphs, can only be part of an exploratory analysis, and are still far from providing a stand-alone method for reconstructing an accurate causal diagram. Moreover, our results support that the current best approach relies on an iterative \textit{human-in-the-loop} process, based on the combination of CD methods and expert knowledge. 
\section{Conclusions}
We introduced a simulator in the manufacturing field, from which two novel datasets are extracted. The simulator is based on physical models derived from first principles, and the integration of domain knowledge from experts received the highest priority when building the DGP. We envision that our benchmarks will serve as a playground to build causal models that can tackle the complexity of the real world, where most assumptions made by causal models no longer hold. Moreover, although much progress has been made in causal modeling, our research questions received mostly negative answers. 

\textbf{Limitations:} From a simulation perspective, although we modeled the system with a high degree of realism, it still inherits all the modeling assumptions of the underlying SCMs. From a benchmarking perspective, since the models performed far from optimal, we did not test the most complex queries possible, as they are out of reach for all tested models
Furthermore, accurate estimates of ATE or CATE may not always be enough to satisfy real-world use cases. 

\newpage
\section*{Impact Statement}

Releasing simulators and datasets with a high degree of realism has often limitations due to privacy and confidential reasons. Indeed, especially in the industry, it can be challenging to make such data available without incurring in a leak of important information. For those reasons, there are only a limited number of public datasets which can offer a comparable degree of realism, and peculiar mechanisms.  
Consequently, releasing this simulator has the potential to stimulate research in large-scale causality. Moreover, the widespread implementation of causal models in real-world scenarios can yield significant societal benefits. Causal models, compared to non-causal ones, provide more fairness and interpretability, enhance out-of-distribution generalization, and ultimately contribute to the development of safer and more robust systems. 

\section*{Acknowledgments}

We acknowledge support from Robert Bosch GmbH and from the HMWK project ‚ÄúThe Third Wave of Artificial Intelligence - 3AI‚Äù.

\bibliography{icml2025}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\include{appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
