@inproceedings{Azar2023AGT,
  author       = {Mohammad Gheshlaghi Azar and
                  Zhaohan Daniel Guo and
                  Bilal Piot and
                  R{\'{e}}mi Munos and
                  Mark Rowland and
                  Michal Valko and
                  Daniele Calandriello},
  title        = {A General Theoretical Paradigm to Understand Learning from Human Preferences},
  booktitle    = {International Conference on Artificial Intelligence and Statistics,
                  2-4 May 2024, Palau de Congressos, Valencia, Spain},
  volume       = {238},
  pages        = {4447--4455},
  publisher    = {{PMLR}},
  year         = {2024},
}

@article{Bradley1952RankAO,
  title   = {Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons},
  author  = {Ralph Allan Bradley and Milton E. Terry},
  journal = {Biometrika},
  year    = {1952},
  volume  = {39},
  pages   = {324}
}

@inproceedings{Dubois2023Alice,
  author       = {Yann Dubois and
                  Chen Xuechen Li and
                  Rohan Taori and
                  Tianyi Zhang and
                  Ishaan Gulrajani and
                  Jimmy Ba and
                  Carlos Guestrin and
                  Percy Liang and
                  Tatsunori B. Hashimoto},
  title        = {AlpacaFarm: {A} Simulation Framework for Methods that Learn from Human
                  Feedback},
  booktitle    = {Proc. of NeurIPS},
  year         = {2023},
}

@inproceedings{Ethayarajh2024KTOMA,
  author       = {Kawin Ethayarajh and
                  Winnie Xu and
                  Niklas Muennighoff and
                  Dan Jurafsky and
                  Douwe Kiela},
  title        = {Model Alignment as Prospect Theoretic Optimization},
  booktitle    = {Proc. of ICML},
  year         = {2024},
}

@inproceedings{Gao2022ScalingLF,
  title={Scaling Laws for Reward Model Overoptimization},
  author={Leo Gao and John Schulman and Jacob Hilton},
  booktitle={Proc. of ICLR},
  year={2022},
}

@inproceedings{Hong2024ORPOMP,
  author       = {Jiwoo Hong and
                  Noah Lee and
                  James Thorne},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {{ORPO:} Monolithic Preference Optimization without Reference Model},
  booktitle    = {Proc. of EMNLP},
  pages        = {11170--11189},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
}

@inproceedings{Korbak2022RLWK,
  title={RL with KL penalties is better viewed as Bayesian inference},
  author={Tomasz Korbak and Ethan Perez and Christopher L. Buckley},
  booktitle={Proc. of EMNLP},
  year={2022}
}

@inproceedings{Meng2024SimPO,
  author       = {Yu Meng and
                  Mengzhou Xia and
                  Danqi Chen},
  title        = {SimPO: Simple Preference Optimization with a Reference-Free Reward},
  booktitle    = {Proc. of NeurIPS},
  year         = {2024},
}

@inproceedings{Ouyang2022TrainingLM,
  title     = {Training language models to follow instructions with human feedback},
  author    = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke E. Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Francis Christiano and Jan Leike and Ryan J. Lowe},
  booktitle = {Proc. of NeurIPS},
  year      = {2022}
}

@inproceedings{Park2024DisentanglingLF,
  author       = {Ryan Park and
                  Rafael Rafailov and
                  Stefano Ermon and
                  Chelsea Finn},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Disentangling Length from Quality in Direct Preference Optimization},
  booktitle    = {Proc. of ACL Findings},
  pages        = {4998--5017},
  year         = {2024},
}

@inproceedings{Rafailov2023DirectPO,
  title     = {Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author    = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
  booktitle = {Proc. of NeurIPS},
  year      = {2023}
}

@article{Schulman2017Proximal,
  author       = {John Schulman and
                  Filip Wolski and
                  Prafulla Dhariwal and
                  Alec Radford and
                  Oleg Klimov},
  title        = {Proximal Policy Optimization Algorithms},
  journal      = {CoRR},
  volume       = {abs/1707.06347},
  year         = {2017},
}

@article{Wu2023PairwisePP,
  title={Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment},
  author={Tianhao Wu and Banghua Zhu and Ruoyu Zhang and Zhaojin Wen and Kannan Ramchandran and Jiantao Jiao},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.00212},
}

@inproceedings{Xu2024ContrastivePO,
  author       = {Haoran Xu and
                  Amr Sharaf and
                  Yunmo Chen and
                  Weiting Tan and
                  Lingfeng Shen and
                  Benjamin Van Durme and
                  Kenton Murray and
                  Young Jin Kim},
  title        = {Contrastive Preference Optimization: Pushing the Boundaries of {LLM}
                  Performance in Machine Translation},
  booktitle    = {Proc. of ICML},
  year         = {2024},
}

@inproceedings{wang-etal-2024-hybrid,
    title = "Hybrid Alignment Training for Large Language Models",
    author = "Wang, Chenglong  and
      Zhou, Hang  and
      Chang, Kaiyan  and
      Li, Bei  and
      Mu, Yongyu  and
      Xiao, Tong  and
      Liu, Tongran  and
      Zhu, JingBo",
    booktitle = {Proc. of ACL Findings},
    year = {2024},
    pages = {11389--11403},
}

@inproceedings{wang2024esrl,
  author       = {Chenglong Wang and
                  Hang Zhou and
                  Yimin Hu and
                  Yifu Huo and
                  Bei Li and
                  Tongran Liu and
                  Tong Xiao and
                  Jingbo Zhu},
  title        = {{ESRL:} Efficient Sampling-Based Reinforcement Learning for Sequence
                  Generation},
  booktitle    = {Proc. of AAAI},
  year         = {2024},
}

