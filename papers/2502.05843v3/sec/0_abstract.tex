\begin{abstract}
%
% origin
% Anomaly event detection plays a crucial role in various real-world applications. 
% However, current approaches predominantly rely on supervised learning, which faces significant challenges: the requirement for extensive labeled training data and lack of interpretability in decision-making processes. 
% To address these limitations, we present a training-free framework that integrates open-set object detection with symbolic regression, powered by Large Language Models (LLMs) for efficient symbolic pattern discovery. 
% The LLMs guide the symbolic reasoning process, establishing logical relationships between detected entities. 
% Through extensive experiments across multiple domains, our framework demonstrates several key advantages: (\romannumeral 1) achieving superior detection accuracy through direct reasoning without any training process; (\romannumeral 2) providing highly interpretable logical expressions that are readily comprehensible to humans; and (\romannumeral 3) requiring minimal annotation effort - approximately 1\% of the data needed by traditional training-based methods.
% To facilitate comprehensive evaluation and future research, we introduce two datasets: a large-scale private dataset containing over 110,000 annotated images covering various anomaly scenarios including construction site safety violations, illegal fishing activities, and industrial hazards, along with a public benchmark dataset of 5,000 samples with detailed anomaly event annotations.
%
% modified_ver1
% We present a novel framework that expands the capability of standard object detectors beyond mere object recognition to complex event understanding through LLM-guided symbolic reasoning. While object detectors excel at answering "what exists in images," they struggle with understanding "what is happening" - the relationships, interactions, and events occurring between detected entities. Our key innovation bridges this gap by integrating symbolic reasoning with the rich world knowledge embedded in Large Language Models to derive interpretable logical expressions that capture complex visual relationships. 
% The framework operates by first extracting visual entities using any open-vocabulary object detector. Then, rather than requiring task-specific training, we employ LLM-guided symbolic reasoning to discover meaningful patterns and relationships among these entities. This approach enables object detectors to recognize complex events, logical relationships, and contextual patterns without additional training data. Our method significantly enhances detector capabilities while maintaining complete interpretability through human-readable logical expressions.
% Experiments across diverse datasets demonstrate that our framework successfully enhances multiple object detector architectures (APE, GLIP, YOLO-World) to recognize complex events like illegal fishing activities (achieving 75\% AUROC, a +8.36\% improvement), construction safety violations (+15.77\%), and abnormal crowd behaviors (+23.16\%). These improvements remain consistent across multiple detector architectures (APE, GLIP, YOLO-World), matching specialized event recognition systems without their training requirements. Our work reveals that standard object detectors inherently possess sophisticated visual understanding capabilities—previously inaccessible through traditional methods—that can be unlocked through interpretable, LLM-guided symbolic reasoning, effectively bridging the gap between object detection and event understanding.
%
% modified_ver2
Current object detectors excel at entity localization and classification, yet exhibit inherent limitations in event recognition capabilities. 
This deficiency arises from their architecture's emphasis on discrete object identification rather than modeling the compositional reasoning, inter-object correlations, and contextual semantics essential for comprehensive event understanding. 
To address this challenge, we present a novel framework that expands the capability of standard object detectors beyond mere object recognition to complex event understanding through LLM-guided symbolic reasoning. 
% 
%Our key innovation lies in bridging the semantic gap between object detection and event understanding without requiring expensive task-specific training. First, we extract visual entities using any open-vocabulary object detector, maintaining the flexibility to utilize various detection architectures. Then, we employ symbolic regression with large language models to discover human-readable logical expressions that map objects to higher-level events. These symbolic rules identify meaningful relationships among detected entities, transforming low-level visual perception into semantic event understanding. Our method provides strong interpretability and transferability.
Our key innovation lies in bridging the semantic gap between object detection and event understanding without requiring expensive task-specific training. 
The proposed plug-and-play framework interfaces with any open-vocabulary detector while extending their inherent capabilities across architectures. 
At its core, our approach combines (\romannumeral1) a symbolic regression mechanism exploring relationship patterns among detected entities and (\romannumeral2) a LLM-guided strategically guiding the search toward meaningful expressions. 
These discovered symbolic rules transform low-level visual perception into interpretable event understanding, providing a transparent reasoning path from objects to events with strong transferability across domains.
%
We compared our training-free framework against specialized event recognition systems across diverse application domains. 
Experiments demonstrate that our framework enhances multiple object detector architectures to recognize complex events such as illegal fishing activities ($\textbf{75\%}$ AUROC, $\textbf{+8.36\%}$ improvement), construction safety violations ($\textbf{+15.77\%}$), and abnormal crowd behaviors ($\textbf{+23.16\%}$). 
% TODO: modified to anonymous repo
Code is available at \href{https://anonymous.4open.science/status/SymbolicDet-main-CD60}{here}.

\end{abstract}