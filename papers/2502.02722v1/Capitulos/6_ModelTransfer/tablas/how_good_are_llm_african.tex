\definecolor{Color}{gray}{0.9}
\begin{table}[htb]
    \begin{center}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{llrrrrrrrrrrrrrrrrrrrr}
    \toprule
    \textbf{Model} &\textbf{Size} &\textbf{amh} &\textbf{bam}  &\textbf{bbj} &\textbf{ewe} &\textbf{hau} &\textbf{ibo} &\textbf{kin} &\textbf{lug} &\textbf{luo} &\textbf{mos} &\textbf{nya} &\textbf{pcm} &\textbf{sna} &\textbf{swa} &\textbf{tsn} &\textbf{twi} &\textbf{wol} &\textbf{xho} &\textbf{yor} &\textbf{zul} \\
    \midrule
    \multicolumn{2}{l}{\texttt{Fine-tune: SotA}} \\
    \rowcolor{Color}
    AfroXLMR-large & 550M & \textbf{78.0}  &\textbf{79.0} &\textbf{90.3} &75.2 &\textbf{85.4} &\textbf{88.9} &\textbf{86.8} &\textbf{88.9} &\textbf{75.3} &\textbf{73.5} &\textbf{92.4} &\textbf{90.0} &\textbf{96.1} &\textbf{92.7} &\textbf{88.9} &\textbf{79.2} &\textbf{83.8} &\textbf{89.2} &\textbf{67.9} &\textbf{90.6} \\
    \midrule
    \multicolumn{2}{l}{\texttt{Prompting of LLMs}} \\
    GPT-4 & - &28.5  &52.7 &50.3 &\textbf{75.6} &64.9 &56.0 &55.1 &73.3 &49.8 &60.2 &63.6 &64.7 &33.4 &71.5 &64.6 &58.6 &67.9 &28.4 &58.3 &34.9 \\
    AYA & - &14.1 &7.1 &20.0 &26.5 &34.5 &28.2 &30.8 &16.3 &12.7 &34.4 &21.7 &27.4 &13.4\definecolor{Color}{gray}{0.9} &35.6 &29.4 &18.9 &14.5 &4.2 &17.5 &11.4  \\
    mT0 & 13B &0.0 &0.0 &0.0 &0.1 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0  \\
    mT0-MT & 13B &0.0 &0.0 &0.0 &0.1 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0 &0.0  \\
    LLaMa 2 & 13B &0.0 &13.8 &12.3 &25.1 &22.1 &22.0 &23.1 &27.5 &19.0 &11.0 &20.0 &27.5 &11.3 &25.8 &26.2 &20.7 &16.0 &8.1 &15.1 &9.0  \\
    \bottomrule
    \end{tabular}
    }
    \caption{Comparison of F1-score of various LLMs with that of the current state of the art result in Masakhaner 2.0. Table reproduced from \cite{DBLP:conf/africanlp/OjoO23}.
    }
    \label{tab6:howgoodafrican}
    \end{center}

    \end{table}