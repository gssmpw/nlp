[
  {
    "index": 0,
    "papers": [
      {
        "key": "xiao2024efficient",
        "author": "Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis",
        "title": "Efficient Streaming Language Models with Attention Sinks"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "han2024lm",
        "author": "Han, Chi  and\nWang, Qifan  and\nPeng, Hao  and\nXiong, Wenhan  and\nChen, Yu  and\nJi, Heng  and\nWang, Sinong",
        "title": "{LM}-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ge2023model",
        "author": "Ge, Suyu and Zhang, Yunan and Liu, Liyuan and Zhang, Minjia and Han, Jiawei and Gao, Jianfeng",
        "title": "Model tells you what to discard: Adaptive kv cache compression for llms"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhang2024h2o",
        "author": "Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\\'e}, Christopher and Barrett, Clark and others",
        "title": "H2o: Heavy-hitter oracle for efficient generative inference of large language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "li2024snapkv",
        "author": "Li, Yuhong and Huang, Yingbing and Yang, Bowen and Venkitesh, Bharat and Locatelli, Acyr and Ye, Hanchen and Cai, Tianle and Lewis, Patrick and Chen, Deming",
        "title": "SnapKV: LLM Knows What You are Looking for Before Generation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "yang2024pyramidinfer",
        "author": "Yang, Dongjie  and\nHan, Xiaodong  and\nGao, Yan  and\nHu, Yao  and\nZhang, Shilin  and\nZhao, Hai",
        "title": "{P}yramid{I}nfer: Pyramid {KV} Cache Compression for High-throughput {LLM} Inference"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zhang2024pyramidkv",
        "author": "Cai, Zefan and Zhang, Yichi and Gao, Bofei and Liu, Yuliang and Liu, Tianyu and Lu, Keming and Xiong, Wayne and Dong, Yue and Chang, Baobao and Hu, Junjie and others",
        "title": "Pyramidkv: Dynamic kv cache compression based on pyramidal information funneling"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "sang1999representing",
        "author": "Tjong Kim Sang, Erik F.  and\nVeenstra, Jorn",
        "title": "Representing Text Chunks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "shicontext",
        "author": "Shi, Weijia and Min, Sewon and Lomeli, Maria and Zhou, Chunting and Li, Margaret and Lin, Xi Victoria and Smith, Noah A and Zettlemoyer, Luke and Yih, Wen-tau and Lewis, Mike",
        "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "fei-etal-2024-extending",
        "author": "Fei, Weizhi  and\nNiu, Xueyan  and\nZhou, Pingyi  and\nHou, Lu  and\nBai, Bo  and\nDeng, Lei  and\nHan, Wei",
        "title": "Extending Context Window of Large Language Models via Semantic Compression"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "yepes2024financialreportchunkingeffective",
        "author": "Antonio Jimeno Yepes and Yao You and Jan Milczek and Sebastian Laverde and Renyu Li",
        "title": "Financial Report Chunking for Effective Retrieval Augmented Generation"
      },
      {
        "key": "smith2024evaluating",
        "author": "Smith, Brandon and Troynikov, Anton",
        "title": "Evaluating Chunking Strategies for Retrieval"
      },
      {
        "key": "anthropic_contextual_retrieval_2024",
        "author": "Anthropic",
        "title": "Introducing Contextual Retrieval"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "pan2024lisa",
        "author": "Pan, Rui and Liu, Xiang and Diao, Shizhe and Pi, Renjie and Zhang, Jipeng and Han, Chi and Zhang, Tong",
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Edward J. Hu and\nYelong Shen and\nPhillip Wallis and\nZeyuan Allen{-}Zhu and\nYuanzhi Li and\nShean Wang and\nLu Wang and\nWeizhu Chen",
        "title": "LoRA: Low-Rank Adaptation of Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "you2019lamb",
        "author": "Yang You and\nJing Li and\nSashank J. Reddi and\nJonathan Hseu and\nSanjiv Kumar and\nSrinadh Bhojanapalli and\nXiaodan Song and\nJames Demmel and\nKurt Keutzer and\nCho{-}Jui Hsieh",
        "title": "Large Batch Optimization for Deep Learning: Training {BERT} in 76\nminutes"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "chuang2023dola",
        "author": "Chuang, Yung-Sung and Xie, Yujia and Luo, Hongyin and Kim, Yoon and Glass, James and He, Pengcheng",
        "title": "Dola: Decoding by contrasting layers improves factuality in large language models"
      }
    ]
  }
]