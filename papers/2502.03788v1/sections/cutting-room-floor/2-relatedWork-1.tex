\section{Related Work}

\subsection{Advancements in AI and Agentic Workflows for Code Generation}

Since the training process of GPT-3.5 incorporated a substantial amount of code data to enhance the logical reasoning capabilities of language models \cite{chenEvaluatingLargeLanguage2021}, code generation has become closely intertwined with language modeling. With the emergence of models that place a stronger emphasis on reasoning, these capabilities continue to evolve. According to the SWE-bench benchmark, which simulates human programmers' problem-solving workflows, AI programming performance increased from below 2\% in December 2023 \cite{jimenez2024swebench} to over 60\% by February 2025\footnote{https://www.swebench.com/}.

However, simply reinforcing the reasoning ability of language models primarily advances lower-level software development tasks such as auto-completion and refactoring. To enhance automation in real-world software and system development, researchers have introduced various agentic workflows, including OpenHands \cite{openhands}, an open-source coding agent designed for end-to-end development, and Agent Company, which simulates the operation of a software company \cite{xu2024theagentcompany}. Nonetheless, as of February 2025, even the most sophisticated agentic workflows remain unable to fully realize end-to-end programming\footnote{https://www.swebench.com/}, let alone organization-level agency\footnote{https://the-agent-company.com/}. 

Within code generation and system development, front-end code generation—such as website development—often demonstrates stronger performance than back-end development, largely due to the modular nature of front-end components \cite{}. Research in this domain has examined reconstructing HTML/CSS structures from UI screenshots using computer vision techniques \cite{soseliaLearningUItoCodeReverse2023}, implementing hierarchical decomposition strategies for interface elements to optimize UI code generation \cite{wanAutomaticallyGeneratingUI2024}, and improving model specialization through domain-specific fine-tuning for UI generation \cite{wuUICoderFinetuningLarge2024}. To systematically evaluate front-end code generation, specialized benchmarks have been developed to assess the quality of HTML, CSS, and JavaScript implementations \cite{siDesign2CodeHowFar2024}. To investigate the societal impact of this notable improvement in AI programming capabilities, we focus on the task of website generation, where current AI systems are relatively close to achieving near end-to-end automation.

\subsection{Beyond Templates: AI-Powered, User-Centric UI}

With the continuing development of AI-driven user interface (UI) generation, users increasingly seek more personalized and diverse expressions rather than relying solely on conventional template reuse. Recent advances have led to adaptive UI generation systems like FrameKit, which allows end users to manually design keyframes and generate multiple interface variants \cite{wu_framekit_2024}. PromptInfuser goes a step further by enabling runtime dynamic input and generation of UI content \cite{petridisPromptInfuserHowTightly2024}. In this context, AI tools have been shown to offer inspiration for professional designers \cite{luBridgingGapUX2022}. For instance, DesignAID \cite{cai_designaid_2023} demonstrates that generative AI can provide conceptual directions and stimulate creativity at early design stages. Misty supports remixing concepts by allowing users to blend example images with the current UI, thereby enabling flexible conceptual exploration \cite{luMistyUIPrototyping2024}.

Beyond offering inspiration, AI can also provide real-time design feedback to guide iterative refinement and error correction \cite{duan_towards_2023}, such as handling CSS styling in simple websites and optimizing specific UI components \cite{liUsingLLMsCustomize2023}. It is capable of evaluating UI quality and relevance, offering suggestions at various design stages \cite{wuUIClipDatadrivenModel2024}, and even detecting potential development or UI issues in advance \cite{petridisPromptInfuserHowTightly2024}. Automated heuristic evaluations generated by AI can provide more precise assessments and recommendations, thereby streamlining the iterative process \cite{duanGeneratingAutomaticFeedback2024}. When combined with traditional heuristic rules, AI has been shown to increase the effectiveness of UI error detection and correction \cite{lu_ai_2024}. Integrating prototype-checking techniques into the UI generation workflow can further enhance automatic repair capabilities \cite{xiaoPrototype2CodeEndtoendFrontend2024}.

\subsection{Change in Creativity Workflow}

% Creativity is inherently iterative, requiring the decomposition of complex tasks into manageable steps—a principle that has guided recent advances in AI-assisted workflows. Prior studies have shown that breaking down problems can enhance both the interpretability and controllability of AI-generated results, enabling users to steer the process more effectively \cite{weiChainofThoughtPromptingElicits}. Chain-of-thought reasoning and multi-step problem-solving approaches have proven particularly impactful, leading to deeper insights and more precise outcomes across creative domains \cite{palaniEvolvingRolesWorkflows2024}.

% In the context of frontend design, early research explored workflows that progress ``from sketch to writing,” demonstrating how iterative refinement can bolster the generative process by aligning outputs more closely with user intentions \cite{chungTaleBrushVisualSketching2022}. Furthermore, research on design-inspiration tools indicates that generative AI can serve as a powerful catalyst in the early stages of ideation. One such approach, DesignAID \cite{cai_designaid_2023}, leverages semantic diversity in AI outputs to provide designers with a wide range of conceptual directions and inspiration. By aiding in the exploration of more varied design possibilities, such tools underscore AI's role as a creative partner rather than a replacement for human ingenuity. These studies illustrate the potential for AI to serve not as a replacement but as a collaborator in creative endeavors, fostering human–AI partnerships that amplify user agency.

% Our study builds on this body of work by introducing Frontend Diffusion, a system that transcends mere code generation to support an interactive, multi-stage workflow. By integrating sketch-based inputs, multimodal interactions (e.g., sketches and textual prompts), and iterative refinements, our approach empowers users to co-create UIs with AI, addressing limitations in flexibility and control. This collaborative, exploratory workflow enables developers to actively shape the design process rather than passively receiving generated outputs, bridging critical gaps in the usability of generative systems. Furthermore, Frontend Diffusion redefines the creative process by positioning AI as an interactive partner, allowing users to iteratively refine designs, adapt them to evolving needs, and amplify their creative agency.