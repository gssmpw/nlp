\section{Related Work}

\subsection{Advancements in AI and Agentic Workflows for Code Generation}

Since the training process of GPT-3.5 incorporated a substantial amount of code data to enhance the logical reasoning capabilities of language models \cite{chenEvaluatingLargeLanguage2021}, code generation has become closely intertwined with language modeling. With the emergence of models that place a stronger emphasis on reasoning, these capabilities continue to evolve. According to the SWE-bench benchmark, which simulates human programmers' problem-solving workflows, AI programming performance increased from below 2\% in December 2023 \cite{jimenez2024swebench} to over 60\% by February 2025\footnote{https://www.swebench.com/}.

However, simply reinforcing the reasoning ability of language models primarily advances lower-level software development tasks such as auto-completion and refactoring. To enhance automation in real-world software and system development, researchers have introduced various agentic workflows, including OpenHands \cite{openhands}, an open-source coding agent designed for end-to-end development, and Agent Company, which simulates the operation of a software company \cite{xu2024theagentcompany}. Nonetheless, as of February 2025, even the most sophisticated agentic workflows remain unable to fully realize end-to-end programming\footnote{https://www.swebench.com/}, let alone organization-level agency\footnote{https://the-agent-company.com/}. 

Within code generation and system development, front-end code generation—such as website development—often demonstrates stronger performance than back-end development. Research in this domain has examined reconstructing HTML/CSS structures from UI screenshots using computer vision techniques \cite{soseliaLearningUItoCodeReverse2023}, implementing hierarchical decomposition strategies for interface elements to optimize UI code generation \cite{wanAutomaticallyGeneratingUI2024}, and improving model specialization through domain-specific fine-tuning for UI generation \cite{wuUICoderFinetuningLarge2024}. To systematically evaluate front-end code generation, specialized benchmarks have been developed to assess the quality of HTML, CSS, and JavaScript implementations \cite{siDesign2CodeHowFar2024}. To investigate the societal impact of this notable improvement in AI programming capabilities, we focus on the task of website generation, where current AI systems are relatively close to achieving near end-to-end automation.

\subsection{Beyond Templates: AI-Powered, User-Centric UI}

With the continuing development of AI-driven user interface (UI) generation, users increasingly seek more personalized and diverse expressions rather than relying solely on conventional template reuse. Recent advances have led to adaptive UI generation systems like FrameKit, which allows end users to manually design keyframes and generate multiple interface variants \cite{wu_framekit_2024}. PromptInfuser goes a step further by enabling runtime dynamic input and generation of UI content \cite{petridisPromptInfuserHowTightly2024}. In this context, AI tools have been shown to offer inspiration for professional designers \cite{luBridgingGapUX2022}. For instance, DesignAID \cite{cai_designaid_2023} demonstrates that generative AI can provide conceptual directions and stimulate creativity at early design stages. Misty supports remixing concepts by allowing users to blend example images with the current UI, thereby enabling flexible conceptual exploration \cite{luMistyUIPrototyping2024}.

Beyond offering inspiration, AI can also provide real-time design feedback to guide iterative refinement and error correction \cite{duan_towards_2023}, such as handling CSS styling in simple websites and optimizing specific UI components \cite{liUsingLLMsCustomize2023}. It is capable of evaluating UI quality and relevance, offering suggestions at various design stages \cite{wuUIClipDatadrivenModel2024}, and even detecting potential development or UI issues in advance \cite{petridisPromptInfuserHowTightly2024}. Automated heuristic evaluations generated by AI can provide more precise assessments and recommendations, thereby streamlining the iterative process \cite{duanGeneratingAutomaticFeedback2024}. When combined with traditional heuristic rules, AI has been shown to increase the effectiveness of UI error detection and correction \cite{lu_ai_2024}. Integrating prototype-checking techniques into the UI generation workflow can further enhance automatic repair capabilities \cite{xiaoPrototype2CodeEndtoendFrontend2024}.

\subsection{Improving the Creative Workflow with AI}

In many creativity workflows, a prolonged progression from ideation, prototyping, and development to iteration is required \cite{palaniEvolvingRolesWorkflows2024}. Those creative processes are frequently constrained by multiple intricate steps that limit users' expressive capabilities. For example, the complexity and associated costs of developing a personal website often deter individuals from undertaking this process, prompting many to resort to standardized website templates for personal websites. However, GenAI can assist with the creativity workflow from various angles \cite{wanItFeltHaving2024,palaniEvolvingRolesWorkflows2024,longNotJustNovelty2024}. First, GenAI such as text-to-image generation can reduce the time needed to produce high-fidelity outcomes. This enables creators to focus on refining the gap between the high-fidelity results and their envisioned expectations, rather than expending effort on how to achieve high fidelity in the first place \cite{edwardsSketch2PrototypeRapidConceptual2024}. Besides, AI lowers the cost of experimenting with new ideas, thereby minimizing the psychological barriers to conducting trial and error with unconventional concepts \cite{palaniEvolvingRolesWorkflows2024}. When users are uncertain about what they want or have only a broad concept lacking specific details, AI can offer inspiration \cite{rickSupermindIdeatorExploring2023}. Moreover, AI can facilitate parallel prototyping by presenting multiple design directions simultaneously, allowing creators to compare and refine a range of diverse design solutions \cite{dowParallelPrototypingLeads2010}.