\section{Results}
\label{sec:results}

\FloatBarrier
\begin{figure}
  \centering
  \includegraphics[width=0.95\textwidth]{figures/Framework.png}
    \caption{Overview of the results section: 1) AI as a human capability enhancer, not a replacement 2) bidirectional human-AI alignment.}
    \Description{Framework for the results section}
    \label{fig:framework}
  \end{figure}
  
We identified two major themes in our results. First, participants consistently viewed AI tools as augmenting human abilities rather than replacing them. Second, the interaction between users and AI revealed a process of bidirectional human-AI alignment. The result overview is shown in Figure \ref{fig:framework}. 

\begin{figure}
  \centering
\includegraphics[width=1\textwidth]{figures/Examples.png}
  % \includegraphics[bb=0 0 600 400, natwidth=600, natheight=400, width=\textwidth]{figures/Examples.png}
    \caption{Website examples created by researchers and designers grouped by education level.}
    \Description{Website examples created by researchers and designers grouped by education level.}
\label{fig:website_example}
  \end{figure}
  
  \begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/Brainstorm.png}
      \caption{Examples of participant's sketch (P8) on the system for brainstorming of the homepage personal website.}
      \Description{Example of participant brainstorming of website.}
      \label{fig:brainstorm}
    \end{figure}

\subsection{AI as A Human Capability Enhancer, Not a Replacement}
All participants consistently viewed AI tools as enhancing rather than replacing human capabilities in frontend development and design. Participants found these tools served as a starting point and source of inspiration, with humans still needed for refinement and final decision-making. Participants described that this tool heightened people's desire for a more robust digital presence: ``Without this tool, maybe very few people would have their own website; but once it's available, everyone might want one as a digital business card... With such tools, everyone can become a designer, frontend developer, or product manager, thereby driving the creation of more interesting products." (P3)

The frontend generation tool's ability to implement unconventional requests while maintaining user agency was valued by P9: ``it's actually picking up intention... it's not going to try to second guess me," while P10 emphasized the irreplaceable role of humans as requirement providers, noting that ``even the user doesn't have a standard perspective. The users are like the client, and this tool is like the contractor."

\subsubsection{Website Generation Beyond Templates}

The AI-powered generation approach demonstrated advantages over traditional website templates. P2 argued that the tool proves more efficient than searching through templates, which often requires trial and error: ``With templates, you spend time reviewing different options, and even after selection, you must understand their code structure. This tool generates clean, targeted output without unnecessary elements." P5 observed that website templates can constrain thinking: ``Using a GitHub framework means starting with an existing template, which influences how you present yourself. This tool removes that template-imposed limitation on creative thinking."

P7 compared it favorably to website builders: ``For those without UI design experience who struggle with platforms like Wix - which has numerous options requiring drag-and-drop interactions and color decisions - this tool streamlines the process by handling color schemes automatically. When I needed a floating music player, instead of searching through component libraries, the tool generated one directly with multiple variations."

The tool showed promise in creating personalized academic websites. P5 critiqued current academic websites: ``Existing personal websites often appear standardized in style, structure, and content. Many researchers' sites follow similar templates without reflecting their interdisciplinary backgrounds and interests. For interdisciplinary researchers, websites should be more comprehensive, demonstrating engagement across different domains rather than merely listing publications and projects." They mentioned that for researchers working with VR, AR, or multimodal content, traditional flat presentations prove insufficient. Future tools should support more immersive and diverse presentation methods to fully communicate research domains, methodologies, and outcomes.
                
\subsubsection{Supporting Ideation, Team Brainstorming and Self-Reflection}
The tool effectively facilitated both collaborative ideation and individual reflection processes. In team settings, it enabled efficient prototyping and concept exploration. As P8 described, ``I wasn't anticipating a perfect prototype generation, but during the sketching phase, it serves as an instrumental aid in my brainstorming process" (as shown in Figure \ref{fig:brainstorm}). They elaborated on its collaborative applications: ``It provides accessibility and facilitates communication. In group projects, team members can individually contribute through text or sketches, collectively evaluate outcomes, and iteratively build upon selected concepts - making it particularly suitable for brainstorming sessions."

For UI/UX practitioners, the tool expedites concept visualization. P2 observed: ``It proves especially valuable for designers because when they can articulate their intentions precisely or have an initial draft, they can visualize outcomes promptly without frontend development dependencies. While the output might approximate 60-70\% of the final implementation, it accelerates idea communication in both upward reporting and general presentations."

The tool extends beyond external presentation to function as a medium for self-reflection. P5 elaborated on this fundamental aspect:

\begin{quote}
``From my perspective, a personal blog's essential function lies in its capacity to aggregate and synthesize existing knowledge. This utility isn't necessarily directed toward public consumption - it may serve primarily as a tool for self-examination, illuminating the processes of my internal thought world... The act of presenting to oneself necessarily precedes external presentation to the broader audience." (P5)
\end{quote}

The tool's rapid prototyping capabilities support this introspective process. As P5 explained, ``It facilitates the clarification of how one wishes to present their professional identity and understand it internally. Subsequently, with a defined target audience, one can appropriately adapt this self-presentation for integration into the social context." This capability particularly benefits creative professionals, as P12 noted: ``I have some art friends. A lot of their portfolios are pretty creative. I probably recommend it for that." They emphasized its accessibility for non-technical creators to generate initial design frameworks without requiring direct HTML/CSS implementation.

\subsubsection{Empowering User Interface Development}

For experienced developers, AI code generation serves as a powerful accelerator in the development process. P8, P10, P11, and P13 emphasized that users with foundational web development knowledge can effectively leverage and modify AI-generated code to achieve sophisticated results. As P11 noted, ``You need to understand the basic components of a webpage, like its structure. This helps you achieve your desired results more quickly." This knowledge becomes particularly important for implementing complex or innovative designs, where users must articulate requirements using appropriate technical terminology. P8 elaborated on this point:

\begin{quote}
  ``To achieve more specific outcomes, some UI/UX knowledge is essential. For instance, when implementing complex animations like a rotating solar system, rather than using general descriptions, I would specify technical requirements like 'I want one sphere rotating around another sphere.' The AI tool can then better interpret these technical terms like `rotate' to generate the appropriate code." (P8)
\end{quote}

For novices and those less experienced with frontend development, the tool serves a different but equally valuable purpose - providing emotional support and reducing the stress typically associated with web development. P13 highlighted this benefit:

\begin{quote}
``Frontend development can be very frustrating for some people. It can be very painful. People might literally pull their hands up. So this can certainly be a great stress elimination... I prefer back-end programming. I like writing algorithms... I'm not a big fan of frontend development. And when I was learning front, when I was trying to write frontend code for the first few times, I found it very frustrating.'' (P13)
\end{quote}

The tool is particularly empowering for those without UI design experience, acting as a bridge to overcome their limitations in visual design. P7 described how the tool compensates for their lack of design expertise while boosting their confidence in website creation:

\begin{quote}
``As a non-design person, it enhances and complements my poor sense of color and form. It helps design a website I like based on my needs... I don't need to find third-party paid platforms anymore. Now I can design a website I like through such simple operations... It has greatly enhanced my capability and desire to showcase myself through a website.'' (P7)
\end{quote}

\subsubsection{Potential Educational Applications}
The tool demonstrated educational value by enabling users to learn through observation and experimentation. P11 emphasized how examining the generated code facilitated learning: ``By studying the code it generates, one can understand how the page is constructed... When I cannot envision certain animations, it provides exemplary solutions that I can learn from regarding how such effects are created."

P6 conceptualized the tool as an educational mentor rather than a replacement, noting that it removes mundane implementation tasks while serving as a learning platform. They envisioned it as guiding users toward professional standards through demonstration and instruction, rather than simply automating the design process. This mentorship extends to providing role-based feedback, with P6 suggesting that the tool could act as different professional personas (like recruiters or UX directors) to critique the website's design and content: ``Because I want to see what recruiters and consultants want... if there's a way that the AI can advise me, not just with the visual, but just with the overall look and feel and content of it. Let's say you're a business looking at my UX research portfolio or description of my career, then is this an OK page for that kind of thing?" The tool also proved effective at overcoming procrastination barriers. As P6 explained:

\begin{quote}
``And for a first pass, I think it does fairly well in helping you. Like I said, I wanted to do a website for a long time, and I haven't done it. So just to kind of break the barrier of getting something down and start thinking about it, this would be pretty helpful... The tool should help me learn by taking a model of a professional designer and how they would think about things, and then nudge me towards doing some of the more professional stuff." (P6)
\end{quote}

\subsubsection{Potential Research Applications}
The tool demonstrated value for research applications. For researchers working with specific user groups, the tool's ability to generate accessible code was beneficial. As P2 explained:

\begin{quote}
``My users are blind users, so I need the frontend to be sufficiently simple for screen readers like Voiceover to work effectively. If it can generate HTML that is both simple and well-structured, it would enhance my productivity." (P2)
\end{quote}

The tool also exhibited promise in expediting research prototyping processes. P7 described its utility in experimental settings: ``It proved immensely helpful when we needed to create an audio recording experiment website. Previously, we spent extensive time trying to build it with Wix... In 2020, it took me an exceptionally long time to set it up. This tool makes it much simpler - just designing the interface saved me substantial time, especially for components like the music bar and audio elements."

The tool's flexibility and accessibility encouraged researchers to explore diverse presentation formats. As P7 noted, ``Instead of being limited to basic presentations, this opens up more channels. Why not create an HTML report? It's not restricted to personal websites - it could be a report format as well."

Looking toward future developments, participants expressed optimism about the tool's evolving capabilities. P4 observed, ``This tool has room for growth. As it becomes more powerful, it will become increasingly compelling."    

\subsection{Bidirectional Human-AI Alignment}

We observed a bidirectional human-AI alignment process in the user interview: \textit{AI-initiated alignment} (from AI to human), which includes onboarding support for new users and prompt guidance and refinement, where AI helps facilitate more explicit user expression of ideas; and \textit{human-initiated alignment} (from human to AI), which includes fine-grained user control over details and harnessing and combining AI's unexpected creative sparks, where users communicate their expectations and aesthetic preferences through interactions with AI. Within these interactions, there exist both possibilities and challenges in conveying dynamic and interactive behaviors, as well as requirements for multimodal inputs to enhance AI's understanding and anticipation of user intent. Users acknowledged the importance of understanding this bidirectional alignment process: "It's not like a steep learning curve. It's not super challenging. But it's interesting to learn how the system thinks and then trying to match what you're thinking to it." (P9)


\subsubsection{AI-initiated Alignment: Onboarding Support for New Users}
While users expressed optimism about AI tools' potential, P1, P10, P11, P12 emphasized the necessity of educational guidance such as example websites (P1, P12), demo videos (P10), tutorials of website components (P11, P12). They can help users better comprehend tool capabilities and feasibility, indicating users need to establish appropriate mental models and operational habits for effective utilization.

P1 described the challenge of structuring website content without prior planning: ``I do think another thing that was challenging was coming up with a certain format for the website, just because I don't have one yet and I don't really know what a website, or what a grad student's website should entail at this point." P12 emphasized the value of concrete examples: ``Even a tutorial or an example of, like, hey, this is what one person put and this is what - this is all the different images that came out from it. This is an example of what AI can do in this context. I think having that as a reference point for me to look at and say, okay, so the AI can develop - can be this creative even when given this."

\subsubsection{ AI-initiated: Prompt Guidance and Refinement}
P3 and P6 identified prompt formulation as a key challenge requiring time and effort. P6 explained: ``The little bit of challenge comes with figuring out how to prompt it, because sometimes you need to have some prior experience to know what to expect to minimize the number of iterations. So I didn't know whether I should use certain key terminology, like cards or models or something like that."

P9 and P10 suggested incorporating interactive guidance: ``Do you know Clippy? The little guy that pops up and tells you things. So if you had Clippy, like, oh, did you think about adding colors? Did you think about specifying? So the poking you to do more." (P9)

Moreover, P2, P3, P9, P10, P11 and P12 expressed a preference for iterative refinement capabilities rather than one-time generation. They sought to continuously adjust, replace, and combine advantageous elements from different versions to arrive at a satisfactory final product. In other words, these AI tools should function as partners for ongoing dialogue and evolution, rather than providers of one-off solutions.

For example, P2 and P9 advocated for more direct manipulation capabilities: ``It modularizes everything so I can directly manipulate it in the graphical interface, adjust it to what I want... If I'm 70\% satisfied with the current version, I can reorganize it further." (P2)

The participants also emphasized that AI should engage in clarifying dialogues with users when faced with uncertainty, rather than making assumptions. P1 noted: ``I definitely think that it should ask maybe follow-up questions when generating the response... Like, follow up questions to maybe prompt the user to specify what they want." P8 suggested that the tool could enhance iteration efficiency by posing confirmatory questions during generation, such as whether the output meets expectations or if users would like to explore alternative styles.

\subsubsection{User-initiated: Fine-Grained User Control Over Details}

Users expressed a need for more granular control over intent expression. P2 noted that the current system only allows high-level requirements specification without detailed control over individual page elements; if the users are able to provide more precise parameters or specific regions, the generated pages would better align with user requirements. Similarly, P6 advocated for hierarchical prompting for different page sections: ``I wonder if you can have a general prompt and then prompt also in the specific section with a little tag." For minimalist design practitioners, precision in visual elements emerged as crucial. P10 elaborated: ``For those who pursue minimalism, attention to detail is paramount" - emphasizing the importance of granular control over typography, color schemes, and element properties like border radius.

As another way of fine-grained user control, the participants also wanted to preview intermediate steps before generating the whole website: ``And I would like to add, one feature that I would like to add is give me a choice of colors. If I'm specifying Indian vegetarian cuisine, it has automatically assumed orange, yellow, green, all those colors... I would like to see some variations before, some color recommendations before the website is generated. If I can also view some image suggestions... So we can automatically obtain a set of images that I can view before generating the website." (P13)

As the capabilities of smaller size language models improve, P2 suggested that language models running on local devices could conduct ``last-mile'' tweakings such as importing personal infromation: ``Some users may be hesitant to share their materials directly with AI systems. They might prefer generating just the structure, then populating it with their information locally... You could have a large model generate an overall template that's sophisticated and well-structured, clearly indicating where user information should go, then use a local small model to input the personal content without uploading sensitive materials to servers." Another method of fine-grained control is ``hierarchical prompting" mentioned by P8, where user requirements could be specified in multiple layers. For example, users could specify the overall layout and then specify the details of each section.

\subsubsection{User-initiated: Harnessing and Combining AI's Unexpected Creative Sparks}
P3 and P11 found the AI-generated outputs exceeded user expectations by incorporating unanticipated design elements and dynamic effects:

\begin{quote}
``The AI's knowledge base may exceed humands, potentially offering unexpected ideas... It introduces dynamic effects that I hadn't considered when creating static sketches... For a personal website, having these animations automatically incorporated is quite valuable." (P11)
\end{quote}

Based on the creative pieces generated by AI as ``serendipitous sparks", P4, P6, P11 and P13 expressed interest in features that would enable combining elements from multiple generations: ``With three or four versions, I might appreciate certain design elements from each. How could we combine them? Perhaps through editing capabilities, comments, or drag-and-drop functionality? (P4)" And P6 proposed a ``remix" feature based on previously generated or community-shared designs.

\subsubsection{Possibilities and Challenges in Communicating Dynamic and Interactive Behaviors}

The communication of dynamic interactions and complex behavioral logic through static sketches and text presented both possibilities and challenges. P7 noted how textual descriptions enhanced design specifications of dynamic interactions: ``While my color instructions were minimal, the system comprehended that I wanted vibrant colors and a clean design. Although my sketch was static, it understood which elements should be dynamic, such as the floating music player that follows page scrolling - an option I hadn't explicitly requested but found valuable." On the other hand, P12 tried to indicate toggling function with lines but failed: ``The underlines here aren't actual content but rather elements meant to be toggled - expressing such toggle requirements in sketches poses a challenge." This revealed current limitations in AI tools' ability to comprehend complex interactive intentions, suggesting the need for new methods such as flowcharts or state transition diagrams to convey complex interaction patterns in websites. Moreover, the AI tool needs to provide examples of what the website could achieve for dynamic interactions: ``As technology evolves, the AI tool may support more dynamic effects, though this remains an area of uncertainty for us." (P5)

\subsubsection{Requirements of Multimodal Inputs}

Individual difference were demonstrated in participants' preferences of expressing their design intent through sketches and text. Some found value in an iterative process combining both modalities. As P7 who preferred a text-based expression explained: ``As someone without design experience, I find expressing ideas through text more direct than drawing", and ``I typically begin by writing to establish a general idea, then create sketches to visualize it, followed by textual elaboration to capture details that sketches cannot express." P7 elaborated on their workflow with this tool: ``I find the workflow effective - starting with sketching, then adding textual descriptions. Since sketches are static, it's challenging to convey aspects like draggable elements or fixed components. The text allows me to specify which parts should be fixed and which should be dynamic."

As a comparison, P11 noted that sketch input enhanced the tool's comprehension of user intent: ``Compared to pure textual descriptions, sketches enable the tool to better capture spatial layouts and component relationships, leading to more accurate representations of user requirements."

Besides sketches and text descriptions, users expressed interests in leveraging more diverse input methods and modalities, including uploading galleries (P8, P10) and screenshots (P11), and referencing existing websites (P11). This addresses a potential direction for future AI design tools to support multimodal inputs to accommodate users' varied creative sources and generate designs closer to users' expectations.

Several participants advocated for enhanced graphical capabilities. P2 observed that the current drawing and editing functionalities are more constrained compared to professional design tools like Figma, with limited graphical elements and customization options. P3, P10 and P12 suggested expanding beyond basic shapes (rectangles, circles, lines, text) to include additional elements like triangles and rounded rectangles.