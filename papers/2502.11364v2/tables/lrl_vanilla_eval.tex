\begin{table*}[!htbp]
\setlength{\tabcolsep}{4pt}
    \small
    \centering
    \alternaterowcolors
\begin{tabular}{l||cccc|l||cccc|l||l}
\toprule
\textbf{Acc $(\%)_{\Delta{\color{ForestGreen}\uparrow}{\color{OrangeRed}\downarrow}}$}                                       & \multicolumn{5}{c||}{\textbf{\mgsm}}         & \multicolumn{5}{c||}{\textbf{\xlwic}}        & \multicolumn{1}{c}{\textbf{\xcopa}} \\ 
 &
\textbf{bn} &
\textbf{sw} &
\textbf{te} &
\textbf{th} &
  \multicolumn{1}{l||}{\textbf{LRL Avg}} &
\textbf{bg} &
\textbf{et} &
\textbf{fa} &
\textbf{hr} &
  \multicolumn{1}{l||}{\textbf{LRL Avg}} &
  \multicolumn{1}{l}{\textbf{LRL Avg}} \\ \midrule

\multicolumn{12}{l}{\textbf{\llamaThreeOne}} \\

\english                                         & 52.40     & 67.20 & 39.60 & 69.20 & 57.10       & 51.54 & 44.62 & 29.74 & 51.79 & 44.42 & 55.91           \\
\multilingual                                    & 68.00     & 68.80 & 55.60 & 71.60 & \increase{66.00}{8.90}[***] & 57.69 & 55.13 & 57.95 & 56.92 & \increase{57.05}{12.63}[***] & \increase{66.11}{10.20}[***]          \\
\native                                          & 67.20     & 72.40 & 58.00 & 76.40 & \increase{68.50}{11.40}[***] & 61.79 & 62.05 & 62.31 & 57.18 & \increase{62.88}{18.46}[***] & \increase{71.63}{15.72}[***]      \\ \midrule


\multicolumn{12}{l}{\textbf{\qwenTwo}} \\
\english                                         & 57.20     & 20.80 & 23.20 & 73.60 & 43.70          & 28.21  & 56.92 & 63.33 & 54.87 & 48.46 & 62.29           \\
\multilingual                                     & 64.80     & 28.40 & 23.60 & 73.20 & \increase{47.50}{3.80}[**] & 53.59 & 58.46 & 60.26 & 54.36 & \increase{56.28}{7.82}[***] & \increase{63.83}{1.54}[*]          \\
\native                                          & 72.00     & 32.40 & 40.40 & 76.80 & \increase{55.40}{11.70}[***] & 55.13 & 59.23 & 63.08 & 54.62 & \increase{57.76}{9.30}[***] & \increase{67.63}{5.34}[***]          \\ \midrule


\multicolumn{12}{l}{\textbf{\gptThreeFive}} \\
\english                                         & 39.60     & 63.60 & 12.80 & 60.80 & 44.20 & 54.36     & 54.62 & 54.10 & 51.79 & 53.72 & 63.43           \\
\multilingual                                       & 54.40     & 68.00 & 24.40 & 57.20 & \increase{51.00}{6.80}[***] & 52.82     & 60.00 & 54.36 & 56.41 & \increase{55.90}{2.18}[**] & \decrease{62.71}{0.72}        \\
\native                                          & 57.20     & 73.60 & 30.00 & 58.80 & \increase{54.90}{10.70}[***] & 54.62     & 59.49 & 58.46 & 60.26 & \increase{58.21}{4.49}[***] & \increase{67.17}{3.74}[***]          \\ \bottomrule
\end{tabular}
    \caption{Accuracies on LRLs of \english, \multilingual and \native modes across $3$ MLLMs of $3$ datasets. Please refer to \cref{tab:lang25} for language code-to-name mapping.  Avg represents the average accuracy of the LRLs. Subscript indicate the performance \textcolor{ForestGreen}{increase$\uparrow$} (or \textcolor{OrangeRed}{decrease$\downarrow$}) of \multilingual and \native compared to \english. Superscripts are significance levels (in terms of $p$-value) of the same comparison --- *: $p<0.05$; **: $p<0.01$; ***: $p<0.001$. Raw evaluation accuracies and hypothesis test results for all MLLMs and all languages are in \cref{tab:vanilla_eval:mgsm,tab:vanilla_eval:xcopa,tab:vanilla_eval:xlwic} and \cref{tab:hyp_test:vanilla_eval:mgsm,tab:hyp_test:vanilla_eval:xcopa,tab:hyp_test:vanilla_eval:xlwic} in \cref{app:expt:vanilla}, respectively.}
    \vspace{-5pt}
    \label{tab:lrl_vanilla_eval}
\end{table*}






