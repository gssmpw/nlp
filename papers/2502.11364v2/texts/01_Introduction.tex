\section{Introduction}

\begin{figure}[!t]
    \centering
    \begin{subfigure}[b]{\columnwidth} 
        \centering
        \includegraphics[width=\linewidth]{figures/illustration_english.pdf}
        \captionsetup{skip=3pt}
        \caption{\english ICL Mode}
        \label{fig:pull:english}
    \end{subfigure}

    \vspace{0.0cm} 
    \begin{subfigure}[b]{\columnwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/illustration_multilingual.pdf}
        \captionsetup{skip=3pt}
        \caption{\multilingual ICL Mode}
        \label{fig:pull:multilingual}
    \end{subfigure}

    \caption{
        Illustration of two ICL modes. After providing a few-shot prompt, we evaluate LLM in the same domain in various languages. In a controlled experiment, each demonstration in (a) and (b) shares the same meaning, albeit in different languages. Contents and languages of demonstrations are randomly sampled from a training set and a preset high-resource language list, respectively. We find that the \multilingual ICL mode (b) is more effective in helping the LLM solve tasks in different languages compared to the \english ICL mode (a).
        \label{fig:pull}
    }
    \vspace{-5pt}
\end{figure}


\noindent In-context learning \citep[ICL;][]{lm_are_few_shot_learner} has become a widely adopted technique in natural language processing with large language models \cite[LLMs;][\textit{inter alia}]{llama2,palm,llama3,qwen2,qwen2.5}, which enables LLMs to learn to solve problems by analogy from a few input-output examples (i.e., demonstrations) without updating model parameters.
As a generic method, ICL has also been effective in improving the cross-lingual performance of multilingual LLMs \citep[MLLMs; ][]{lm_few_shot_multilingual_learner,mega,mgsm,few_shot_multilingual_nlu,buffet}.

Prior work has introduced two common ICL strategies for non-English languages: (i) translating the target question into English and performing English-only ICL \citep[\textit{inter alia}]{mgsm,mega,few_shot_multilingual_nlu}, and (ii) providing demonstrations in the target language \cite[\textit{in-language demonstrations;}][]{polyglot_prompt,cross_lingual_prompting,not_all_language_are_created_equal,plug}.
Both strategies have critical shortcomings: (i) may suffer from information loss in translation due to nuanced language gap \citep{dont_trust_when_question_not_in_english,roles_of_english} or the unavailability of high-quality translation systems for extremely low-resource languages (LRLs), whereas (ii) may become infeasible due to data scarcity in LRLs.
As alternatives, when presenting LLMs with problems in the target language, English demonstrations (\cref{fig:pull:english}) lead to poor performance on LRLs, whereas demonstrations in multiple high-resource languages (HRLs; \cref{fig:pull:multilingual}) can be more effective, even when there is little alphabetical overlap between the demonstration and target languages \citep{mgsm}; however, the underlying reasons on why it works remain unclear.

In this work, we systematically analyze multilingual ICL through a set of controlled experiments.
Each test question is paired with a set of semantically equivalent demonstrations, while the demonstration languages vary according to different ICL modes (\cref{sec:setup:prompts}).
We compare the performance differences across four ICL modes (\cref{sec:icl_mode_eval:multilingual_vs_english,sec:icl_mode_eval:monolingual}): English, individual-HRL, multilingual (i.e., mixed HRLs), and in-language demonstrations (\cref{fig:icl_modes}).
To disentangle the impact of demonstration language from other confounding factors (e.g., interactions between demonstration languages and in-domain demonstrations), we conduct additional control experiments by adding irrelevant sentences in various languages into English-only in-domain demonstrations (\cref{sec:icl_mode_eval:cis}).
% \freda{Yilei, could you cite each subsection here accordingly?}
We find that
\begin{itemize}[leftmargin=*,topsep=0pt,itemsep=-4pt]
    \item In-context demonstrations in HRLs, especially in languages with non-Latin writing systems such as Chinese and Japanese, can more effectively transfer knowledge compared to English ICL mode, leading to performance improvement in answering questions in all languages, especially in LRLs.
          This finding is generalizable enough across different domains and various LLMs.
    \item Demonstrations in mixed HRLs are more robust and effective compared to those in a single HRL, in terms of average accuracy boosting on different tasks. This strategy is favored.
    \item Surprisingly, simply introducing another non-English language (not necessarily in the demonstration) in the prompt could lead to performance improvement, albeit the improvement is not as significant as the aforementioned strategies.
\end{itemize}