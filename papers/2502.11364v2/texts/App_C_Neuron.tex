\section{ICL Behavioral Analysis} \label{app:neuron}
\subsection{Specilized Neuron}
Inspired by the universal concept space \cite{llama_english_epfl, neuron_plnd, semantic_hub}, we hypothesize that MLLMs could activate more cross-lingual capabilities by aligning different linguistic representations. To validate the above hypothesis, we seek to find patterns in neuron behavior between ICL modes. Following \citet{neuron_specialization_translation,language_specific_neuron_msra,language_specific_neuron_tokyo,neuron_pim,neuron_plnd,neuron_sft}, we look at the activations of neurons in the multilayer perceptron (MLP, or \textit{Feedforward Network, FFN}) modules of the MLLMs.

\subsubsection{Identifying Top-Activated Neurons}
Each neuron in every MLP layer of the model is assigned a dedicated counter, initialized to $0$. During vanilla evaluation, we monitor the activation of every neuron in the forward pass. Since LLMs typically employ ReLU-like \cite{relu} activation functions (e.g., SwiGLU \cite{glu} for \textsf{Llama} series), a positive activation value can be interpreted as the neuron being ``activated''. If a neuron is ``activated'', we increment the corresponding counter by $1$, otherwise no action. To ensure balanced input across our three datasets, we curated a \combined dataset, see \cref{app:dataset} for details. After processing the inputs of a single ICL mode, each neuron accumulates an  ``activated'' count. The neurons with the highest counts are identified as specialized neurons attributed to this ICL mode.


We employ two methods for selecting the most activated neurons. Top-$k$ selects neurons in the top $k$ percentile \cite{language_specific_neuron_msra}, while top-$p$ selects neurons progressively until their cumulative activation counts reach $p\ (\%)$ of the sum of all activation values \cite{neuron_specialization_translation}. 



\subsection{\multilingual-specific Neurons Overlap Most with \native-specific Neurons}
\input{tables/neuron_statistics}
We examined the overlaps among the most-activated neurons (\textit{specialized neurons}) across different ICL modes by calculating the Intersection over Union (IoU) scores. For ICL modes $M_1$ and $M_2$, with specialized neurons denoted as sets $S_1$ and $S_2$, their overlap is quantified by \cref{eq:iou}:

\begin{equation}
    \begin{aligned}
    \operatorname{IoU}\left(S_1, S_2\right)=\frac{\left|S_1 \cap S_2\right|}{\left|S_1 \cup S_2\right|}.
    \end{aligned}
    \label{eq:iou}
\end{equation}

Prior research \cite{language_specific_neuron_msra,neuron_plnd} has discovered that \textit{language-specific neurons} are located primarily in the models' top and bottom layers. Because we want to explain the multilingual reasoning capabilities of a model, we only consider neurons that belong to a certain prefix or suffix of the models' layers in an effort to restrict our selected neuron sets to be mainly language-specific neurons. 

The similarity in performance between \multilingual and \native can be explained by the high overlap in the sets of most-activated neurons. On the other hand, the poorer performance of \english can be explained by the low overlap between \english most-activated neurons and other ICL modes . 

The same experiment was also performed but with  \multilingual replaced by HRL \chinese. In this case, the patterns were less obvious and model-specific. This result aligns with our findings in vanilla evaluation that \english $\le$ Non-\english HRL \monolingual $\le$ \multilingual (\cref{sec:mono_vs_multilingual_results}).

We further split this neuron experiment to either use only LRL or HRL ICL modes when recording neuron activations. We observed that HRL tends to activate similar neurons between \native and \multilingual, whereas LRL tends to activate similar neurons between \english and \multilingual.



\input{tables/appendix/mgsm_vanilla_eval}
\input{tables/appendix/xcopa_vanilla_eval}
\input{tables/appendix/xlwic_vanilla_eval}
\input{tables/appendix/mgsm_vanilla_eval_hyp_test}
\input{tables/appendix/xcopa_vanillia_eval_hyp_test}
\input{tables/appendix/xlwic_vanilla_eval_hyp_test}

\input{tables/appendix/mgsm_cis}
\input{tables/appendix/xcopa_cis}
\input{tables/appendix/xlwic_cis}
\input{tables/appendix/mgsm_cis_hyp_test}
\input{tables/appendix/xcopa_cis_hyp_test}
\input{tables/appendix/xlwic_cis_hyp_test}