\section{Related Work}


Generative AI tools for coding have advanced significantly in recent years. In \cite{chen2021evaluatinglargelanguagemodels}, GitHub Copilot powered by Codex is evaluated and shown impressive improvement over GPT-3 and GPT-J.  
In \cite{Li2022}, the authors introduce AlphaCode for competition-Level coding. In simulated evaluations using the Codeforces platform, AlphaCode achieved on average a ranking of top 54.3\% generation. 

In \cite{becker2023programming}, challenges and opportunities in AI for coding in the context of education are discussed.  

Our work is inspired by \cite{shi2024languagemodelssolveolympiad} that introduced the USACO benchmark with 307 problems, and evaluated AI coding abilities on these problems. We build upon the prompts provided in the paper, as well as an updated version of their text corpus for Retrieval-Augmented Generation. The main difference is the question we asked in this work. While \cite{shi2024languagemodelssolveolympiad} aims to solve an entire problem, we focus on whether and how much can AI tools help human coders in solving the problem. 
