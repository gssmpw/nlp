
\documentclass{article} % For LaTeX2e
%change back to iclr for camera-ready
\usepackage{arxiv,times}%\usepackage{iclr2025_conference,times}
%\usepackage[table]{xcolor}   % for row coloring
\usepackage[most]{tcolorbox}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{graphicx} 
\usepackage{subcaption}
\usepackage{float}
\usepackage{fancybox} % For creating borders
\usepackage{booktabs} 
\usepackage{listings}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}


\title{KGGen: Extracting Knowledge Graphs from Plain Text with Language Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Belinda Mo$^{*1}$, Kyssen Yu$^{*2}$, Joshua Kazdan\thanks{Equal Contribution.}\ $^{\ 1}$, Proud Mpala$^{1}$, Lisa Yu$^{2}$, Chris Cundy$^{3}$, \\ \newline \textbf{Charilaos Kanatsoulis}$^{1}$,   \textbf{Sanmi Koyejo}$^{1}$
\\ $^{1}$Stanford University  {\quad} 
$^{2}$University of Toronto {\quad} $^{3}$ FAR AI
\\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Recent interest in building foundation models for KGs has highlighted a fundamental challenge: knowledge-graph data is relatively scarce.  The best-known KGs are primarily human-labeled, created by pattern-matching, or extracted using early NLP techniques.  While human-generated KGs are in short supply, automatically extracted KGs are of questionable quality.  We present a solution to this data scarcity problem in the form of a text-to-KG generator (KGGen), a package that uses language models to create high-quality graphs from plaintext.  Unlike other KG extractors, KGGen clusters related entities to reduce sparsity in extracted KGs.  KGGen is available as a Python library (\texttt{pip install kg-gen}), making it accessible to everyone.  Along with KGGen, we release the first benchmark, Measure of of Information in Nodes and Edges (MINE), that tests an extractor's ability to produce a useful KG from plain text.  We benchmark our new tool against existing extractors and demonstrate far superior performance.  
\end{abstract}

\renewcommand{\thefootnote}{} % Remove footnote number
\footnotetext{Code for this project can be found at \url{https://github.com/stair-lab/kg-gen}}
\renewcommand{\thefootnote}{\arabic{footnote}}
\section{Introduction}

Knowledge graph (KG) applications and Graph Retrieval-Augmented Generation (RAG) systems are increasingly bottlenecked by the scarcity and incompleteness of available KGs. KGs consist of a set of subject-predicate-object triples, and have become a fundamental data structure for information retrieval \citep{Schneider1973}. Most real-world KGs, including Wikidata \citep{wikidata}, DBpedia \citep{dbpedia}, and YAGO \citep{yago}, are far from complete, with many missing relations between entities \citep{quality_wikidata}. The lack of domain-specific and verified graph data poses a serious challenge for downstream tasks such as KG embeddings, graph RAG, and synthetic graph training data.

%KG embeddings are one useful application. 
Embedding algorithms such as TransE \citep{TransE} rely on abundant relational data to learn high-quality KG representations. In particular, TransE represents relationships as vector translations between entity embeddings and has demonstrated strong performance in link prediction when trained on large KGs (e.g., 1M entities and 17m training samples). However, if the KG is sparse or incomplete, embedding models struggle -- they cannot learn or infer missing links effectively, degrading performance on knowledge completion and reasoning tasks \citep{pujara-etal-2017-sparsity, pote2024surveyembeddingmodelsknowledge}.

Consider retrieval-augmented generation (RAG) with a language model (LM) -- this requires a rich external knowledge source to ground its responses. For instance, GraphRAG integrates a KG into the RAG pipeline \citep{Edge2024GraphRAG}. In GraphRAG, a language model (LM) like GPT-4o is used to extract a KG from a text corpus automatically, and this graph is used for retrieval and reasoning. This structured, graph-based augmentation has been shown to improve multi-hop reasoning and synthesis of information across documents \citep{larson2024graphrag}. By traversing relationships in the constructed graph, GraphRAG can ``connect the dots" between disparate pieces of information, outperforming baseline RAG that relies only on semantic search over text.  However, GraphRAG's performance ultimately depends on the quality of the extracted graph \citep{zhang2024mindfulrag}. In practice, automatically constructed graphs can be noisy and incomplete -- some false nodes and edges may be introduced and some important ones omitted, which can hinder downstream reasoning \citep{thakur2024impossible}. %A sparse KG provides limited facts for retrieval, leading the model to product incomplete answers or fall back on hallucinations when required information is absent.

An emerging line of work that builds on graph-based RAG trains neural networks on KG retrieval. For example, GFM-RAG (Graph Foundation Model for RAG) \citep{luo2025gfmraggraphfoundationmodel} trains a dedicated graph neural network on an extensive collection of KGs, encompassing 60 graphs with over 14 million triples to serve as a foundation model for graph-based retrieval. By learning from diverse KGs, GFM-RAG's retriever can generalize to unseen graphs and better handle the noise/incompleteness in automatically extracted KGs. These efforts underscore the importance of having dense, well-connected KGs to feed into RAG systems. 

In this work, we propose KGGen (Text-to-Knowledge-Graph), a package that leverages LMs and a clustering algorithm to extract high-quality, dense KGs from text. KGGen addresses knowledge scarcity by enabling the automatic construction of KGs from any textual source rather than being limited to pre-existing databases like Wikipedia. The package uses an LM-based extractor to read unstructured text and predict subject-predicate-object triples to capture entities and relations. KGGen then applies an iterative LM-based clustering to refine the raw graph. Inspired by crowd-sourcing strategies for entity resolution \citep{crowd_sourcing}, the clustering stage has an LM examine the set of extracted nodes and edges to identify which ones refer to the same underlying entities or concepts. Variations in tense, plurality, stemming, or capitalization are normalized in this process - e.g., ``labors" might be clustered with ``labor" and ``New York City" with ``NYC." The resulting KG has far less redundancy and is densely interlinked, making it suitable for downstream use. 

In addition to KGGen, we provide the first benchmark to measure text-to-knowledge-graph extraction.  Our benchmark feeds $100$ Wikipedia-length articles into a KG extractor, then uses RAG to answer questions about the articles.  On our benchmark, KGGen outperforms leading existing text-to-KG extractors by $18\%$. KGGen paves the way for a data-rich future when training next-generation KG foundation models and RAG systems.  

To summarize our contributions:

\begin{enumerate}
    \item We introduce KGGen, an open-source package that uses LMs to extract high-quality KGs from plain text.  Our package is available as a Python library. 
    \item We develop the first-ever benchmark for text-to-KG extractors, allowing for a fair comparison of existing methods.
    \item We show that KGGen outperforms existing extraction methods by $18\%$ on this benchmark, exhibiting its potential to produce functional KGs using LMs.
\end{enumerate}








% \begin{table}[t]
% \caption{Sample table title}
% \label{sample-table}
% \begin{center}
% \begin{tabular}{ll}
% \multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
% \\ \hline \\
% Dendrite         &Input terminal \\
% Axon             &Output terminal \\
% Soma             &Cell body (contains cell nucleus) \\
% \end{tabular}
% \end{center}
% \end{table}

%\section{Problem Statement}




\section{Existing Methods}
Before describing KGGen, we explain the two leading existing methods for extracting KGs from plain text, which will serve as a basis for comparison throughout the rest of this paper.

\subsection{OpenIE} Open Information Extraction (OpenIE) was implemented by Stanford CoreNLP based on \citet{angeli-etal-2015-leveraging}. It first generates a ``dependency parse" for each sentence using the Stanford CoreNLP pipeline.
A learned classifier then traverses each edge in the dependency parse, deciding whether to create (Yield), continue (Recurse), or stop processing a clause.
These decisions split complex sentences into shorter, self-contained clauses.  From these clauses, the system produces (\emph{subject, relation, object}) tuples, each accompanied by a confidence score. Because OpenIE does not require its input text to have a specific structure, OpenIE can handle text in any format.

\subsection{GraphRAG} Microsoft developed GraphRAG, which integrated graph-based knowledge retrieval with language models (LMs) \cite{larson2024graphrag}.  As a first step, GraphRAG provides functionality for generating KGs from plain text to use as its database. In this process, GraphRAG creates a graph by prompting LMs to extract node-entities and relationships between these entities to serve as edges between the nodes. Throughout this extraction, few-shot prompting provides the LM with examples of ``good" extractions. GraphRAG aggregates well-connected nodes into ``communities" and generates a summary for each community to remove redundancy. The final graph consists of the communities as nodes and sentences summarizing their relationships as edges.

\section{KGGen: KGs From Plain Text}
%This section describes our novel method for extracting functional KGs from plain text.

Unlike most previous methods of LLM-based KG extraction, we rely on a multi-stage approach involving an LLM (in our case, GPT-4o) to (1) extract entity and relations from each source text, (2) aggregate graphs across sources and (3) iteratively cluster entities and relations. We implement these stages in a modular fashion via a new \texttt{kg-gen} Python toolkit consisting of a `generate` module for extraction, an `aggregate` module for source consolidation, and a `cluster` module for dynamic entity resolution. We use the DSPy framework throughout these stages to define signatures that ensure that LLM responses are consistent JSON-formatted outputs. In our case, we use GPT-4o, although the implementation may be used with any model supported by DSPy. 

We impose strong constraints on the LLM via prompting to reduce the likelihood of semantically dissimilar duplicate entities.  We introduce multiple passes through our extracted edges and relations to cluster similar entities and consolidate the number of edge types.  Consolidation and clustering prevent the formation of sparse KGs, which may produce meaningless KG embeddings under standard algorithms such as TransE.

Our extraction method involves several steps, which we outline below. The exact prompts for each step can be found in Appendix \ref{app:prompts}, and the process is illustrated in Figure \ref{fig:extraction_method_schematic}.

\subsection{Entity and Relation Extraction (`generate`) }
The first stage takes unstructured text as input and produces an initial knowledge graph as extracted triples. We invoke the GPT-4o model for each input text through a DSPy signature that instructs the model to output detected entities in a structured format. Then, we invoke a second LLM call through DSPy that instructs the model to output the subject-predicate-object relations, given the set of entities and source text. We find this 2-step approach works better to ensure consistency between entities. 

\subsection{Aggregation (`aggregate`)}
After extracting triples from each source text, we collect all the unique entities and edges across all source graphs and combine them into a single graph.  All entities and edges are normalized to be in lowercase letters only. The aggregation step reduces redundancy in the KG. Note that the aggregation step does not require an LLM.

\subsection{Entity and Edge Clustering (`cluster`)}
After extraction and aggregation, we typically have a raw graph containing duplicate or synonymous entities and possibly redundant edges. The clustering stage is a key innovation in our KG extraction methodology that aims to merge nodes and edges representing the same real-world entity or concept. We take an iterative LLM-based approach to clustering, inspired by how a group of humans might gradually agree on consolidating terms. Rather than attempting to solve the entire clustering in one shot (which is intractable for an extensive list of entities), KGGen performs a sequential series of clustering operations for entities: 

\begin{enumerate}
  \item The entire entities list is passed in context to the LLM, and it attempts to extract a single cluster. An optional cluster-instruction string may be passed to decide how to cluster. The default instructions account for close synonyms and differences in tense and plurality.
  \item Validate the single cluster using an LLM-as-a-Judge call with a binary response. If it passes, then add the cluster and remove the cluster entities from the entities list.
  \item Assign a label to the cluster that most closely captures the shared meaning of entities in the cluster.
  \item Repeat steps 1--3 until $n$ loops happen without a successful cluster extraction.
  \item Remaining entities are checked batch-by-batch, with batch size $b$, for whether they should be added to an existing cluster.
  \item For each new addition to a cluster, validate the cluster once more using an LLM-as-a-Judge call with a binary response.
  \item Repeat steps 5--6 until there are no remaining entities to check.
\end{enumerate}

The same operations are performed on edges, albeit with slightly modified prompts. 
 
 The clustering process allows us to create dense KGs that admit meaningful embeddings.  To give a real example of the usefulness of our process, in one of our raw KGs, we found the entities ``vulnerabilities", ``vulnerable", and ``weaknesses".  Although these are different words, they have similar meanings and should be viewed as equivalent in our KG.  
 \begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{T2KG_method.png} % Replace with the path to your image
    \caption{KGGen extraction method}
    \label{fig:extraction_method_schematic}
\end{figure}

\section{A Benchmark for Extraction Performance}
Although a handful of existing methods attempt to extract KGs from plain text, it is difficult to measure progress in the field due to the lack of existing benchmarks. To remedy this, we produce the Measure of Information in Nodes and Edges (MINE), the first benchmark that measures a knowledge-graph extractor's ability to capture and distill a body of text into a KG. 

\subsection{MINE Description}
MINE involves generating KGs for 100 articles, each representing a distinct source of textual data. Each article is approximately 1,000 words long and is generated by an LLM based on a diverse list of 100 topics that range from history and art to science, ethics, and psychology. To evaluate the quality of the generated KGs, we develop a metric to assess how effectively they capture critical information from the articles.

We extract 15 facts--here defined as statements present in the plain text article--from each article by providing an LLM with the article and the extraction prompt found in Appendix \ref{app: MINE prompts}. We manually verify that the 15 facts are accurate and contained in the article. MINE assesses how well a text-to-KG extractor captures the information present in the text by determining whether these 15 facts are captured by the KG generated from the article.

For each article, KGs are generated using using the plain-text-to-KG method being benchmarked. The nodes of the resulting KGs are then vectorized using the all-MiniLM-L6-v2 model from SentenceTransformers, enabling us to use cosine similarity to assess semantic closeness between the short sentence information and the nodes in the graph.

For each KG generation method, the KG for each article is queried for each of the 15 facts from that article. We do this by determining the top-k nodes most semantically similar to each fact. Next, we determine all the nodes within two relations of one of the top k-nodes. Finally, we return all these nodes along with their relations as the result of the query. This result is subsequently evaluated using an LLM, provided it is queried for and a specific prompt to produce a binary output: 1 if the fact could be inferred from only the information in the queried nodes and relations, and zero otherwise. The prompt can be found in Appendix \ref{app: MINE prompts}.

The final MINE score of each KG generator on a given article was calculated as the percentage of 1s across all 15 evaluations. This systematic approach objectively compares the methods based on their ability to capture and retrieve information from the articles accurately.

This evaluation process is illustrated in Figure \ref{fig:evaluation_methodology_schematic}.
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{eval_proccess.png} % Replace with the path to your image
    \caption{Evaluation process used in MINE}
    \label{fig:evaluation_methodology_schematic}
\end{figure}

\section{Results} 
We use MINE to benchmark KGGen against leading existing methods of plain-text-to-KG extraction: OpenIE \cite{angeli-etal-2015-leveraging} and GraphRAG \cite{larson2024graphrag}. After providing this quantitative comparison of extraction fidelity, we present qualitative results demonstrating the advantages of KGGen over past methods.

\subsection{Evaluations on MINE}
Figure \ref{fig:results} displays accuracies from KGGen, OpenIE, and GraphRAG on MINE.  Figure \ref{fig:extracted_relations_example} shows an example query from MINE and relevant relations extracted by KGGen, OpenIE, and GraphRAG.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{Figure_1.png} % Replace with the path to your image
    \caption{Distribution of MINE scores across 100 articles for GraphRAG, OpenIE, and KGGen.  Dotted vertical lines show average performance.  KGGen scored $66.07\%$ on average, significantly outperforming GraphRag $47.80\%$ and OpenIE $29.84\%$. }
    \label{fig:results}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{MINE_examples.png}
    \caption{An example query from the MINE benchmark, along with relevant relations in the KGs extracted by KGGen, GraphRAG, and OpenIE.  Note that the relation triples extracted by KGGen contain the fact being queried for, whereas the KGs extracted by GraphRAG and OpenIE do not.  The relation types extracted by KGGen are more concise and generalize more easily than those from GraphRAG and OpenIE.  The full article that these relations were extracted from can be found in Appendix \ref{app:MINE_example}.}
    \label{fig:extracted_relations_example}
\end{figure}

%Figure \ref{fig:results} illustrates the distribution of the percentage of information captured by the KGs across all articles for the three methods: KGGen, OpenIE, and GraphRAG. KGGen scores 66.07\%, a significant improvement over the competition: OpenIE scores 29.84\%, and GraphRAG scores 47.80\%.

\subsection{Qualitative Results}


As seen in Figure \ref{fig:visualization_GraphRag} and \ref{fig:visualization2_GraphRag}, GraphRAG often generates a minimal number of nodes and connections for an entire article. This sparsity results in the omission of critical relationships and information. For compression, Figure \ref{fig:visualization_t2kg} and \ref{fig:visualization2_t2kg} illustrate sections of the KGs generated by KGGen for the same articles. Figure \ref{fig:visualization_OpenIE} illustrates one of many issues in OpenIE's KGs. Firstly, most nodes are unreasonably long, incoherent phrases. Many of these nodes are redundant copies of one another, adding unnecessary complexity to the graph. Additionally, as seen in \ref{fig:visualization2_OpenIE} OpenIE frequently produces generic nodes such as ``it" and ``are." Due to their frequency, these nodes, which contain no useful information, often end up as some of the most well-connected nodes in the graph. By contrast, KGGen consistently generates KGs that are dense and coherent, effectively capturing critical relationships and information from the articles. 
%\vspace{-80pt}
\begin{figure}[h!]
    \centering
    % Subfigure 1
    \begin{subfigure}[t]{0.3\textwidth} % Top alignment and width
        \centering
        \setlength{\fboxsep}{0.5pt} % Padding between border and image
        \setlength{\fboxrule}{0.5pt} % Border thickness
        \fbox{\includegraphics[width=4.5cm, height=3.7cm]{a.png}} % Fixed width and height for uniform size
        \caption{Section of KG generated by KGGen on ``How Music Influences Mood"}
        \label{fig:visualization_t2kg}
    \end{subfigure}
    \hfill
    % Subfigure 2
    \begin{subfigure}[t]{0.3\textwidth} % Top alignment and width
        \centering
        \setlength{\fboxsep}{0.5pt} % Padding between border and image
        \setlength{\fboxrule}{0.5pt} % Border thickness
        \fbox{\includegraphics[width=4.5cm, height=3.7cm]{c.png}} % Fixed width and height for uniform size
        \caption{Full KG generated by GraphRAG on ``How Music Influences Mood"}
        \label{fig:visualization_GraphRag}
    \end{subfigure}
    \hfill
    % Subfigure 3
    \begin{subfigure}[t]{0.3\textwidth} % Top alignment and width
        \centering
        \setlength{\fboxsep}{0.5pt} % Padding between border and image
        \setlength{\fboxrule}{0.5pt} % Border thickness
        \fbox{\includegraphics[width=4.5cm, height=3.7cm]{b.png}} % Fixed width and height for uniform size
        \caption{Section of KG generated by OpenIE, on ``How Music Influences Mood", with most node labels omitted for readability.}
        \label{fig:visualization_OpenIE}
    \end{subfigure}

    \begin{subfigure}[t]{0.3\textwidth} % Top alignment and width
        \centering
        \setlength{\fboxsep}{0.5pt} % Padding between border and image
        \setlength{\fboxrule}{0.5pt} % Border thickness
        \fbox{\includegraphics[width=4.5cm, height=3.7cm]{d.png}} % Fixed width and height for uniform size
        \caption{Section of KG generated by KGGen on ``The Chemistry of Cooking"}
        \label{fig:visualization2_t2kg}
    \end{subfigure}
    \hfill
    % Subfigure 2
    \begin{subfigure}[t]{0.3\textwidth} % Top alignment and width
        \centering
        \setlength{\fboxsep}{0.5pt} % Padding between border and image
        \setlength{\fboxrule}{0.5pt} % Border thickness
        \fbox{\includegraphics[width=4.5cm, height=3.7cm]{f.png}} % Fixed width and height for uniform size
        \caption{Full KG generated by GraphRAG on ``The Chemistry of Cooking"}
        \label{fig:visualization2_GraphRag}
    \end{subfigure}
    \hfill
    % Subfigure 3
    \begin{subfigure}[t]{0.3\textwidth} % Top alignment and width
        \centering
        \setlength{\fboxsep}{0.5pt} % Padding between border and image
        \setlength{\fboxrule}{0.5pt} % Border thickness
        \fbox{\includegraphics[width=4.5cm, height=3.7cm]{e.png}} % Fixed width and height for uniform size
        \caption{Section of KG generated by OpenIE on ``The Chemistry of Cooking"}
        \label{fig:visualization2_OpenIE}
    \end{subfigure}

    \caption{Visual comparison of KGs generated using KGGen, GraphRAG, and OpenIE.  Results show that KGGen discovers more informative nodes to estimate a richer graph compared to GraphRAG, and collapses synonyms to discover a more informative graph than OpenIE.}
    \label{fig:visualization_of_kgs}
\end{figure}
\section{Future Work}
We propose MINE -- the first benchmark for KG extraction from plain text.  To solve the data-shortage hindering development of graph-based foundation models, we present KGGen, a plain-text-to-KG extractor that outperforms existing approaches by up to $18\%$ on MINE.  

Although KGGen beats existing methods by significant margins, the graphs still exhibit problems, like over or under-clustering.  More research into better forms of clustering could improve the quality of our KGs.  Additionally, our benchmark, MINE, currently measures performance on relatively short corpora, whereas KGs are primarily used to handle massive amounts of information efficiently.  Future expansions of our benchmark could focus on larger corpora to better measure the practicality of different extraction techniques.  
%Several labs are already using our KG-extractor to construct data for use in training RAG foundation models; we look forward to seeing the impact that KGGen and other KG extractors will have on these future foundation models.

\section{Related Work}

Interest in automated methods to produce structured text to store ontologies dates back to at least 2001 when large volumes of plain text began to flood the fledgling internet \citep{early_ontologies}. KG extraction from unstructured text has seen significant advances through rule-based and LM-powered approaches in the last 15 years.  Early work \citep{yago} used hard-coded rules to develop YAGO, a KG extracted from Wikipedia containing over five million facts, and rules-based extraction still has appeal for those producing KGs in multi-modal domains today \citep{Norabid2022RulebasedTE, rules_music}.  With the development of modern natural language processing, hard-coded rules generally ceded to more advanced approaches based on neural networks.  For instance, OpenIE \citep{angeli-etal-2015-leveraging} provides a two-tiered extraction system: first, self-contained clauses are identified by a classifier; then, Angeli et al. run natural logic inference to extract the most representative entities and relations from the identified clauses.  Stanford KBP \citep{Angeli2013Stanfords2K} presents another seminal early approach to using deep networks for entity extraction.  

As early as 2015, some hypothesized that extracting KGs would go hand-in-hand with developing better language models \citep{Domeniconi}.  More recently, evidence has emerged that transformer-based architectures can identify complex relationships between entities, leading to a wave of transformer-based KG extraction techniques, which range from fully automatic \citep{qiao2022joint, Arsenyan2023LargeLM, Zhang2024ExtractDC} to human-assisted \citep{Kommineni2024FromHE}.  Our contribution to the extraction literature is to build KGs conducive to embedding algorithms such as TransE and TransR \citep{TransE, TransR}.  We observed that when one extracts KGs from plaintext, the nodes and relations are often so specific that they are unique.  This causes the estimation of embeddings to be under-specified.  We develop a method for automatic KG extraction from plain text that clusters similar nodes and edges to prevent this under-specification. This leads to a KG with better connectivity and more functional nodes and edges. 

Evaluating the quality of knowledge graphs is important to ensure usefulness and reliability in downstream applications. Early evaluation methods focused primarily on directly assessing aspects such as completeness and connectivity or using rule-based statistical methods, while recent approaches emphasize usability in downstream applications and incorporation of semantic coherence\citep{xue2023knowledge}. 

In the late 2000s, research focused on assessing the correctness and consistency of KGs. The evaluations relied on expert annotations by selecting random facts from the generated KG and then calculating the accuracy of those facts. \citep{yago} This proved to be laborious and prone to errors. This led to accuracy approximation methods like KGEval \citep{ojha-talukdar-2017-kgeval} and Two-State Weight Clustering Sampling(TWCS) \citep{gao2018efficientKGeval}, which employed sampling methods with statistical guarantees as well as use less annotation labor. As the KGs became larger and more diverse, particularly with the rise of automated extraction techniques from web data, this generated more pressure on annotators, leading to methods like Monte-Carlo search being used for the interactive annotation of triples \citep{qi2022optimizedhumancollab}. Furthermore, because accuracy alone did not fully capture the complexity of the knowledge graph, more evaluation metrics like completeness were used to characterize the quality of knowledge graphs. \citep{SubhiIssaKnowledgeGraphCompleteness}. 

% In recent years, the focus has shifted towards evaluating KGs for their role in downstream AI applications such as natural language processing and recommendation systems. [CITE]. As a result, semantic coherence and usability have become a key criteria in evaluating the quality of the extracted knowledge graphs[CITE].

In recent years, the evaluation of knowledge graphs (KGs) has increasingly focused on their role in downstream AI applications, such as augmenting language models \citep{decadeofkginnlp} and recommendation systems \citep{he2020lightgcn}. As a result, semantic coherence and usability have become key criteria for assessing the quality of extracted knowledge graphs.

Two notable approaches to KG evaluation are the LP-Measure and the triple trustworthiness measurement (KGTtm) model. LP-Measure assesses tDhe quality of a KG through link prediction tasks, eliminating the need for human labor or a gold standard \citep{zhu2023assessing}. This method evaluates KGs based on their consistency and redundancy by removing a portion of the graph and testing whether the removed triples can be recovered through link prediction tools. Empirical evidence suggests that LP-Measure can effectively distinguish between ``good" and ``bad" KGs. The KGTtm model, on the other hand, evaluates the coherence of triples within a knowledge graph \cite{jia2019triple}. Based on these evaluation methods, frameworks like Knowledge Graph Evaluation via Downstream Tasks(KGrEaT) and DiffQ(differential testing) emerged. KGrEaT provides a comprehensive assessment of KGs by evaluating their performance on downstream tasks such as classification, clustering, and recommendation \citep{heist2023kgreat} rather than focusing solely on correctness or completeness. In contrast, DiffQ uses embedding models to evaluate the KG's quality and assign a DiffQ Score, resulting in improved KG quality assessment. \cite{tan2024diffq} 

This shift towards task-based evaluation underscores the importance of usability and accessibility in KGs. Factors such as expressiveness, context information, and ease of integration into downstream AI applications are now central to evaluating their quality and effectiveness.

\section{Acknowledgments}
JK acknowledges support from NSF grant number DGE-1656518.  SK acknowledges support from NSF 2046795 and 2205329, the MacArthur Foundation, Stanford HAI, and Google Inc.

\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\appendix
\section{Prompts for KG Extraction} \label{app:prompts}

This section provides the exact prompts used to extract KG's from the text.  

The initial KG is extracted using the following two prompts.  
\begin{tcolorbox}[
  colframe=black,    % Border color
  colback=gray!10,   % Background color
  boxrule=0.5mm,     % Border thickness
  arc=0mm,           % Square corners
  width=\textwidth,  % Box width
  enhanced,          % For better alignment
  left=5mm,          % Inner left margin
  right=5mm,         % Inner right margin
  top=3mm,           % Inner top margin
  bottom=3mm         % Inner bottom margin
]
\textbf{Prompt for extracting entities:}
\texttt{Extract key entities from the given text. Extracted entities are nouns, verbs, or adjectives, particularly regarding sentiment. This is for an extraction task, please be thorough and accurate to the reference text.}
\\

\textbf{Prompt for extracting relations:}
\texttt{Extract subject-predicate-object triples from the assistant message. A predicate (1-3 words) defines the relationship between the subject and object. Relationship may be fact or sentiment based on assistant's message. Subject and object are entities. Entities provided are from the assistant message and prior conversation history, though you may not need all of them. This is for an extraction task, please be thorough, accurate, and faithful to the reference text.}
\end{tcolorbox}

After extracting the entities and relations from each unit of text, we begin the clustering process, which is performed using the following prompts. 

\begin{tcolorbox}[
  colframe=black,    % Border color
  colback=gray!10,   % Background color
  boxrule=0.5mm,     % Border thickness
  arc=0mm,           % Square corners
  width=\textwidth,  % Box width
  enhanced,          % For better alignment
  left=5mm,          % Inner left margin
  right=5mm,         % Inner right margin
  top=3mm,           % Inner top margin
  bottom=3mm         % Inner bottom margin
]
\textbf{Prompt for clustering entities: }\\
\texttt{Find ONE cluster of related entities from this list.
A cluster should contain entities that are the same in meaning, with different: \\
- tenses \\
- plural forms \\
- stem forms \\ 
- upper/lower cases \\
Or entities with close semantic meanings. \\
Return only if you find entities that clearly belong together. \\
If you can't find a clear cluster, return an empty list.}\\

\textbf{Prompt for validating node clusters:} \\
\texttt{Verify if these entities belong in the same cluster.\\
A cluster should contain entities that are the same in meaning, with different:\\
- tenses\\
- plural forms\\
- stem forms\\
- upper/lower cases\\
Or entities with close semantic meanings.\\
Return the entities that you are confident belong together as a single cluster.\\
If you're not confident, return an empty list.}\\
\\

\textbf{Prompt for clustering edges}\\
\texttt{Find ONE cluster of closely related predicates from this list.\\
A cluster should contain predicates that are the same in meaning, with different:\\
- tenses\\
- plural forms\\
- stem forms\\
- upper/lower cases\\
Predicates are the relations between subject and object entities. Ensure that the predicates in the same cluster have very close semantic meanings to describe the relation between the same subject and object entities.\\
Return only if you find predicates that clearly belong together.\\
If you can't find a clear cluster, return an empty list.}\\
\\
\textbf{Prompt for validating cluster edges}\\
\texttt{Verify if these predicates belong in the same cluster.\\
A cluster should contain predicates that are the same in meaning, with different:\\
- tenses\\
- plural forms\\
- stem forms\\
- upper/lower cases\\
Predicates are the relations between subject and object entities. Ensure that the predicates in the same cluster have very close semantic meanings to describe the relation between the same subject and object entities.\\
Return the predicates that you are confident belong together as a single cluster. \\
If you're not confident, return an empty list.}
\\
\end{tcolorbox}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Validation of KG Extraction} \label{app:textbook_generations}

This section provides the LLM generations used to validate our KG extraction method.  

\begin{tcolorbox}[
  colframe=black,    % Border color
  colback=gray!10,   % Background color
  boxrule=0.5mm,     % Border thickness
  arc=0mm,           % Square corners
  width=\textwidth,  % Box width
  enhanced,          % For better alignment
  left=5mm,          % Inner left margin
  right=5mm,         % Inner right margin
  top=3mm,           % Inner top margin
  bottom=3mm         % Inner bottom margin
]
\textbf{Prompt for extracting entities:}
\texttt{Extract key entities from the given text. Extracted entities are nouns, verbs, or adjectives, particularly regarding sentiment. This is for an extraction task, please be thorough and accurate to the reference text.}
\\

\textbf{Prompt for extracting relations:}
\texttt{Extract subject-predicate-object triples from the assistant message. A predicate (1-3 words) defines the relationship between the subject and object. Relationship may be fact or sentiment based on assistant's message. Subject and object are entities. Entities provided are from the assistant message and prior conversation history, though you may not need all of them. This is for an extraction task, please be thorough, accurate, and faithful to the reference text.}
\end{tcolorbox}

\section{Prompts for MINE} \label{app: MINE prompts}

This section provides the LLM prompts used by MINE to evaluate KGs.

\begin{tcolorbox}[
  colframe=black,    % Border color
  colback=gray!10,   % Background color
  boxrule=0.5mm,     % Border thickness
  arc=0mm,           % Square corners
  width=\textwidth,  % Box width
  enhanced,          % For better alignment
  left=5mm,          % Inner left margin
  right=5mm,         % Inner right margin
  top=3mm,           % Inner top margin
  bottom=3mm         % Inner bottom margin
]

\textbf{Prompt for extracting a fact from article:}
\texttt{Extract 15 basic, single pieces of information from the following text that describe how one object relates to another. Present the pieces of info in short sentences and DO NOT include info not directly present in the text. Your output should be of the form [ "info1", "info2" ,..., "info15" ]. "Make sure the strings are valid Python strings."}
\end{tcolorbox}

\begin{tcolorbox}[
  colframe=black,    % Border color
  colback=gray!10,   % Background color
  boxrule=0.5mm,     % Border thickness
  arc=0mm,           % Square corners
  width=\textwidth,  % Box width
  enhanced,          % For better alignment
  left=5mm,          % Inner left margin
  right=5mm,         % Inner right margin
  top=3mm,           % Inner top margin
  bottom=3mm         % Inner bottom margin
]

\textbf{Prompt for evaluating if a fact is contained in the query result:}
\texttt{\\ROLE: "You are an evaluator that checks if the correct answer can be deduced from the information in the context.\\ TASK: Determine whether the context contains the information stated in the correct answer. \\
Respond with "1" if yes, and "0" if no. Do not provide any explanation, just the number.\\}
\end{tcolorbox}
% \begin{algorithm}[h]
% \caption{Edge Imputation Using TransR Embeddings}
% \label{alg:edge_imputation}
% \begin{algorithmic}[1]
% \REQUIRE KG $G$, TransR embeddings $E_{entities}$, $E_{relations}$, clustering labels $C$, proportion $p$
% \STATE $topKnewTriples \leftarrow \{\} $
% \FOR{each cluster $c \in C$}
%     \STATE $S_c \leftarrow$ pairs of entities from cluster $c$
%     \FOR{each entity pair $(e_i, e_j) \in S_c$}
%         \STATE $S_r \leftarrow \text{sample } m \text{ relations}$
%         \FOR{each relation $r \in S_r$}
%             \STATE $score \leftarrow \text{Compute triple scores using } (e_i, r, e_j) $
%             \STATE $topKnewTriples \leftarrow \text{ update top k triples given new score} $
%         \ENDFOR
%     \ENDFOR
% \ENDFOR
% \end{algorithmic}
% \end{algorithm}

\section{Example Article from MINE} \label{app:MINE_example}
This section provides the article that the example fact is from.
\begin{tcolorbox}[
  colframe=black,    % Border color
  colback=gray!10,   % Background color
  boxrule=0.5mm,     % Border thickness
  arc=0mm,           % Square corners
  width=\textwidth,  % Box width
  enhanced,          % For better alignment
  left=5mm,          % Inner left margin
  right=5mm,         % Inner right margin
  top=3mm,           % Inner top margin
  bottom=3mm         % Inner bottom margin
]
\textbf{Title:  }
\texttt{The Rise of Cryptocurrencies\\}
\textbf{\\Content: }
\texttt{   Cryptocurrencies have taken the financial \\world by storm in recent years, revolutionizing the way we think about money and transactions. From the creation of Bitcoin in 2009 by an anonymous individual or group known as Satoshi Nakamoto, to the thousands of altcoins that have since emerged, cryptocurrencies have become a significant player in the global economy.One of the key factors contributing to the rise of cryptocurrencies is the decentralized nature of these digital assets. Unlike traditional fiat currencies that are controlled by governments and central banks, cryptocurrencies operate on a peer-to-peer network, allowing for transactions to occur directly between users without the need for intermediaries. This decentralization not only provides users with more control over their funds but also enhances security and privacy.Another driving force behind the popularity of cryptocurrencies is the technology that underpins them â€“ blockchain. Blockchain is a distributed ledger technology that ensures the transparency and immutability of transactions on the network. Each transaction is recorded in a block and linked to the previous block, forming a chain of blocks that cannot be altered once validated by the network. This technology has been instrumental in building trust and confidence in cryptocurrencies, as it eliminates the need for a trusted third party to oversee transactions. The concept of decentralization and blockchain technology has also paved the way for various applications beyond just digital currencies. Smart contracts, for example, are self-executing contracts with the terms of the agreement directly written into code. These contracts automatically enforce and execute themselves when predefined conditions are met, eliminating the need for intermediaries and streamlining processes in various industries. Cryptocurrencies have also gained traction due to their potential for financial inclusion. In many parts of the world, traditional banking services are inaccessible or too costly for a significant portion of the population. Cryptocurrencies offer a way for individuals to access financial services, such as transferring money and making payments, without the need for a traditional bank account. This has the potential to empower individuals in underserved communities and drive economic growth. The volatile nature of cryptocurrencies has attracted both investors seeking high returns and speculators looking to capitalize on price fluctuations. The rapid appreciation of certain cryptocurrencies, such as Bitcoin, has led to a surge in interest from retail and institutional investors alike. While this volatility presents opportunities for profit, it also poses risks, as prices can fluctuate dramatically in a short period. Regulation has been a contentious issue in the cryptocurrency space, with governments and regulatory bodies grappling with how to oversee this emerging asset class. 
}
\end{tcolorbox}

\begin{tcolorbox}[
  colframe=black,    % Border color
  colback=gray!10,   % Background color
  boxrule=0.5mm,     % Border thickness
  arc=0mm,           % Square corners
  width=\textwidth,  % Box width
  enhanced,          % For better alignment
  left=5mm,          % Inner left margin
  right=5mm,         % Inner right margin
  top=3mm,           % Inner top margin
  bottom=3mm         % Inner bottom margin
]
\texttt{Some countries have embraced cryptocurrencies and blockchain technology, recognizing their potential for innovation and economic growth. Others have taken a more cautious approach, citing concerns about money laundering, tax evasion, and consumer protection. Despite the challenges and uncertainties surrounding cryptocurrencies, their rise has been undeniable. As more individuals and businesses adopt digital currencies for transactions and investments, the landscape of finance is evolving rapidly. The future of cryptocurrencies remains uncertain, but their impact on the financial world is already profound. In conclusion, the rise of cryptocurrencies can be attributed to their decentralized nature, blockchain technology, financial inclusion potential, investment opportunities, and regulatory challenges. As these digital assets continue to gain acceptance and adoption, they are reshaping the way we think about money and finance. Whether cryptocurrencies will become mainstream or remain on the fringes of the financial system remains to be seen, but their impact is undeniable and will likely continue to unfold in the years to come.
}
\end{tcolorbox}

\end{document}
