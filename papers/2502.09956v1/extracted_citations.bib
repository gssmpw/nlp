@article{Angeli2013Stanfords2K,
  title={Stanford's 2013 KBP System},
  author={Gabor Angeli and Arun Tejasvi Chaganty and Angel X. Chang and Kevin Scott Reschke and Julie Tibshirani and Jean Wu and Osbert Bastani and Keith Siilats and Christopher D. Manning},
  journal={Theory and Applications of Categories},
  year={2013},
  url={https://api.semanticscholar.org/CorpusID:14273633}
}

@inproceedings{Arsenyan2023LargeLM,
  title={Large Language Models for Biomedical Knowledge Graph Construction: Information extraction from EMR notes},
  author={Vahan Arsenyan and Spartak Bughdaryan and Fadi Shaya and Kent Small and Davit Shahnazaryan},
  booktitle={Workshop on Biomedical Natural Language Processing},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:256390090}
}

@inproceedings{Domeniconi,
author = {Domeniconi, Giacomo and Moro, Gianluca and Pasolini, Roberto and Sartori, Claudio},
year = {2015},
month = {07},
pages = {},
title = {A Study on Term Weighting for Text Categorization: A Novel Supervised Variant of tf.idf},
doi = {10.5220/0005511900260037}
}

@article{Kommineni2024FromHE,
  title={From human experts to machines: An LLM supported approach to ontology and knowledge graph construction},
  author={Vamsi Krishna Kommineni and Birgitta K{\"o}nig-Ries and Sheeba Samuel},
  journal={ArXiv},
  year={2024},
  volume={abs/2403.08345},
  url={https://api.semanticscholar.org/CorpusID:268379482}
}

@article{Norabid2022RulebasedTE,
  title={Rule-based Text Extraction for Multimodal Knowledge Graph},
  author={Idza Aisara Norabid and Fariza Fauzi},
  journal={International Journal of Advanced Computer Science and Applications},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:249304784}
}

@Article{SubhiIssaKnowledgeGraphCompleteness,
  author={Issa, Subhi and Adekunle, Onaopepo and Hamdi, Fayçal and Cherfi, Samira Si-Said and Dumontier, Michel and Zaveri, Amrapali},
  journal={IEEE Access}, 
  title={Knowledge Graph Completeness: A Systematic Literature Review}, 
  year={2021},
  volume={9},
  number={},
  pages={31322-31339},
  keywords={Data integrity;Linked data;Systematics;Measurement;Bibliographies;Tools;Search problems;Assessment;completeness;data quality;KG;knowledge graph;linked data;LOD;metrics;survey;systematic literature review},
  doi={10.1109/ACCESS.2021.3056622}, 
  url = {https://ieeexplore.ieee.org/document/9344615}}

@inproceedings{TransE,
author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Dur\'{a}n, Alberto and Weston, Jason and Yakhnenko, Oksana},
title = {Translating embeddings for modeling multi-relational data},
year = {2013},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.},
booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2787–2795},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'13}
}

@inproceedings{TransR,
author = {Lin, Yankai and Liu, Zhiyuan and Sun, Maosong and Liu, Yang and Zhu, Xuan},
title = {Learning entity and relation embeddings for knowledge graph completion},
year = {2015},
isbn = {0262511290},
publisher = {AAAI Press},
abstract = {Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH. The source code of this paper can be obtained from https://github.com/mrlyk423/relation_extraction.},
booktitle = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence},
pages = {2181–2187},
numpages = {7},
location = {Austin, Texas},
series = {AAAI'15}
}

@inproceedings{Zhang2024ExtractDC,
  title={Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction},
  author={Bowen Zhang and Harold Soh},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:268987666}
}

@inproceedings{angeli-etal-2015-leveraging,
    title = "Leveraging Linguistic Structure For Open Domain Information Extraction",
    author = "Angeli, Gabor  and
      Johnson Premkumar, Melvin Jose  and
      Manning, Christopher D.",
    editor = "Zong, Chengqing  and
      Strube, Michael",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-1034",
    doi = "10.3115/v1/P15-1034",
    pages = "344--354",
}

@inproceedings{decadeofkginnlp,
author = {Schneider, Phillip and Schopf, Tim and Vladika, Juraj and Galkin, Mikhail and Simperl, Elena and Matthes, Florian},
year = {2022},
month = {11},
pages = {},
title = {A Decade of Knowledge Graphs in Natural Language Processing: A Survey},
doi = {10.18653/v1/2022.aacl-main.46}
}

@article{early_ontologies,
author = {Maedche, Alexander and Staab, Steffen},
year = {2001},
month = {03},
pages = {72-79},
title = {Ontology Learning for the Semantic Web},
volume = {16},
journal = {IEEE Intelligent Systems},
doi = {10.1109/5254.920602}
}

@article{gao2018efficientKGeval,
  title={Efficient Knowledge Graph Accuracy Evaluation},
  author={Gao, Junyang and Li, Xian and Xu, Yifan Ethan and Sisman, Bunyamin and Dong, Xin Luna and Yang, Jun},
  journal={ACM Transactions on Information Systems},
  volume={36},
  number={2},
  pages={1--21},
  year={2018},
  publisher={ACM},
  doi={10.14778/3342263.3342642},
  url={https://dl.acm.org/doi/pdf/10.14778/3342263.3342642},
  note={Duke University and Amazon.com}
}

@inproceedings{he2020lightgcn,
  title={LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation},
  author={He, Xiangnan and Deng, Kuan and Wang, Xiang and Li, Yan and Zhang, YongDong and Wang, Meng},
  booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '20)},
  year={2020},
  pages={639--648},
  publisher={ACM},
  doi={10.1145/3397271.3401063},
  url={https://doi.org/10.1145/3397271.3401063}
}

@inproceedings{heist2023kgreat,
  title={KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks},
  author={Heist, Nicolas and Hertling, Sven and Paulheim, Heiko},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23)},
  year={2023},
  pages={3938--3942},
  publisher={ACM},
  doi={10.1145/3583780.3615241},
  url={https://doi.org/10.1145/3583780.3615241},
  note={Published on 21 October 2023}
}

@inproceedings{jia2019triple,
  title={Triple Trustworthiness Measurement for Knowledge Graph},
  author={Jia, Shengbin and Xiang, Yang and Chen, Xiaojun and Wang, Kun and Shijia},
  booktitle={Proceedings of the World Wide Web Conference (WWW '19)},
  pages={2865--2871},
  year={2019},
  publisher={ACM},
  doi={10.1145/3308558.3313586},
  url={https://doi.org/10.1145/3308558.3313586},
  month={May}
}

@inproceedings{ojha-talukdar-2017-kgeval,
    title = "{KGE}val: Accuracy Estimation of Automatically Constructed Knowledge Graphs",
    author = "Ojha, Prakhar  and
      Talukdar, Partha",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1183/",
    doi = "10.18653/v1/D17-1183",
    pages = "1741--1750",
    abstract = "Automatic construction of large knowledge graphs (KG) by mining web-scale text datasets has received considerable attention recently. Estimating accuracy of such automatically constructed KGs is a challenging problem due to their size and diversity. This important problem has largely been ignored in prior research {--} we fill this gap and propose KGEval. KGEval uses coupling constraints to bind facts and crowdsources those few that can infer large parts of the graph. We demonstrate that the objective optimized by KGEval is submodular and NP-hard, allowing guarantees for our approximation algorithm. Through experiments on real-world datasets, we demonstrate that KGEval best estimates KG accuracy compared to other baselines, while requiring significantly lesser number of human evaluations."
}

@inproceedings{qi2022optimizedhumancollab,
  title={Evaluating Knowledge Graph Accuracy Powered by Optimized Human-Machine Collaboration},
  author={Qi, Yifan and Zheng, Weiguo and Hong, Liang and Zou, Lei},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22)},
  year={2022},
  pages={1368--1378},
  publisher={ACM},
  doi={10.1145/3534678.3539233},
  url={https://doi.org/10.1145/3534678.3539233}
}

@article{qiao2022joint,
  title={A joint model for entity and relation extraction based on {BERT}},
  author={Qiao, Bin and Zou, Zhiliang and Huang, Yurong and Wang, Buyue and Yu, Changlong},
  journal={Neural Computing and Applications},
  volume={34},
  number={5},
  pages={3471--3483},
  year={2022},
  publisher={Springer},
  doi={10.1007/s00521-021-05815-z},
  url={https://doi.org/10.1007/s00521-021-05815-z},
  abstract={Recently, pre-trained language models have made breakthroughs in many natural language processing tasks. However, the pre-trained language model for entity and relation extraction still faces several challenges. In this paper, we propose a joint model for entity and relation extraction based on BERT called JMEBERT. Specifically, we first design a multi-task learning framework to combine the pre-trained language model and entity and relation extraction tasks. Then, we design an effective fusion method for entity and relation extraction, which can effectively combine the entity and relation extraction results. Finally, we design a training strategy that can effectively train the model. Experimental results on two public datasets show that our proposed model outperforms the baseline models and achieves state-of-the-art performance.},
  keywords={Entity and relation extraction, Pre-trained language model, Multi-task learning, Natural language processing},
  issn={1433-3058}
}

@inproceedings{rules_music,
author = {Oramas, Sergio and Sordo, Mohamed and Espinosa-Anke, Luis},
title = {A Rule-Based Approach to Extracting Relations from Music Tidbits},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2741709},
doi = {10.1145/2740908.2741709},
abstract = {This paper presents a rule based approach to extracting relations from unstructured music text sources. The proposed approach identifies and disambiguates musical entities in text, such as songs, bands, persons, albums and music genres. Candidate relations are then obtained by traversing the dependency parsing tree of each sentence in the text with at least two identified entities. A set of syntactic rules based on part of speech tags are defined to filter out spurious and irrelevant relations. The extracted entities and relations are finally represented as a knowledge graph. We test our method on texts from songfacts.com, a website that provides tidbits with facts and stories about songs. The extracted relations are evaluated intrinsically by assessing their linguistic quality, as well as extrinsically by assessing the extent to which they map an existing music knowledge base. Our system produces a vast percentage of linguistically correct relations between entities, and is able to replicate a significant part of the knowledge base.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {661–666},
numpages = {6},
keywords = {music, open information extraction, relation extraction},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@article{tan2024diffq,
  title={Towards assessing the quality of knowledge graphs via differential testing},
  author={Tan, Jiajun and Wang, Dong and Sun, Jingyu and Liu, Zixi and Li, Xiaoruo and Feng, Yang},
  journal={Available online, Version of Record},
  year={2024},
  note={Received 3 October 2023, Revised 15 June 2024, Accepted 26 June 2024, Available online 29 June 2024},
  publisher={Elsevier},
  url={https://doi.org/10.1016/j.jss.2024.07.005}
}

@article{xue2023knowledge,
  title={Knowledge Graph Quality Management: A Comprehensive Survey},
  author={Xue, Bingcong and Zou, Lei},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={35},
  number={5},
  pages={4969--4988},
  year={2023},
  month={May},
  publisher={IEEE},
  doi={10.1109/TKDE.2022.3150080},
  url={https://doi.org/10.1109/TKDE.2022.3150080},
  issn={1041-4347},
  eissn={1558-2191},
  note={Published on 10 February 2022}
}

@inproceedings{yago,
author = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum, Gerhard},
title = {Yago: a core of semantic knowledge},
year = {2007},
isbn = {9781595936547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1242572.1242667},
doi = {10.1145/1242572.1242667},
abstract = {We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95\%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques.},
booktitle = {Proceedings of the 16th International Conference on World Wide Web},
pages = {697–706},
numpages = {10},
keywords = {WordNet, wikipedia},
location = {Banff, Alberta, Canada},
series = {WWW '07}
}

@inproceedings{zhu2023assessing,
  title={Assessing the Quality of a Knowledge Graph via Link Prediction Tasks},
  author={Zhu, Ruiqi and Bundy, Alan and Pan, Jeff and Nuamah, Kwabena and Wang, Fangrong and Li, Xue and Xu, Lei and Mauceri, Stefano},
  booktitle={Proceedings of the 7th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2023)},
  year={2023},
  pages={1--10},
  address={Seoul, Republic of Korea},
  month={December},
  publisher={ACM},
  doi={10.1145/3639233.3639357},
  url={https://doi.org/10.1145/3639233.3639357},
  note={School of Informatics, University of Edinburgh, United Kingdom; Huawei Ireland Research Centre, Ireland}
}

