\section{Related Work}
\label{sec:related}



\paragraph{PSF of Imaging Systems}

The PSF of an imaging system is multi-dimensional and complex, arising and accumulating throughout the imaging process.

A typical color imaging pipeline comprises three key components: a lens, a sensor with a color filter array, and an image signal processor (ISP)~\cite{ramanath2005color,brown2019color,delbracio2021mobile}. Each component significantly influences the PSF of the system.

The lens degrades image quality, and manufacturing imperfections can exacerbate this degradation. Optical aberrations such as spherical, coma, astigmatism, field curvature\cite{hopkins1985image,wyant1992basic} cause blurring, with chromatic aberrations leading to color misalignment and fringing~\cite{sasian2012introduction}. Together, these aberrations result in spatially variant degradation that differs across color channels. 

The color filter array employs pixel-level filters to capture color, inevitably causing information loss during raw image capture. The ISP processes this raw data into a final image through operations such as gain adjustment, demosaicing, color correction, white balance, gamma correction, and tone mapping. These nonlinear processes further complicate the characterization of image degradation.

In this work, we treat the PSF of an imaging system as an integrated whole and estimate it directly from the final captured image.


\paragraph{Models for PSF}

PSF modeling approaches fall into three categories~\cite{lin2023learning}: non-parametric, parametric, and optical simulation-based methods.

Non-parametric models represent blur as a 2D distribution, disregarding interpixel relationships within a field and connections across fields. These models sparsely sample spatially variant PSF across the field of view. Consequently, their sparse and independent nature limits their ability to capture the high-dimensional characteristics of PSF within imaging systems.

Parametric models, such as heteroscedastic Gaussian~\cite{delbracio2021polyblur,eboli2022fast} and Efficient Filter Flow~\cite{schuler2012blind}, use a limited set of parameters, which can oversimplify the PSF. More advanced methods, including Zernike polynomials~\cite{niu2022zernike} and Seidel aberrations~\cite{zhou2024revealing}, incorporate wavefront aberrations and diffraction effects. These models establish field-dependent relationships~\cite{gray2012analytic,zhou2024revealing}, enabling dense PSF estimation with minimal measurements. However, the complexity of Zernike polynomials may hinder practical use, whereas Seidel aberrations offer a simpler parameterization for system aberrations.

Optical simulation models rely on detailed lens design parameters to generate PSF through ray-tracing or diffraction propagation~\cite{baker2003mathematical} under various configurations. However, acquiring accurate lens parameters can be challenging due to intellectual property restrictions.

\paragraph{PSF Estimation}
Many techniques have been developed to estimate the PSF~\cite{jemec20172d,lin2023learning,liang2021mutual,liaudat2023rethinking,eboli2022fast,chen2021extreme,chen2022computational,qiao2024deep,shih2012image,mosleh2015camera,kee2011modeling}. Accurately estimating PSF in real-world imaging systems often requires real captures due to factors such as manufacturing errors, variability in assembly and changes in system performance over time. Among these techniques, there is a significant focus on learning-based methods that utilize real captures. 

Among these learning-based methods, one category employs non-parametric PSF models, such as applying a degradation framework to learn PSF with optical geometric priors~\cite{chen2021extreme}. However, this approach lacks guarantees of smooth transitions both within the PSF and across the field of view. To address these smoothness issues, a recent method uses a multi-layer perceptron to provide a continuous PSF representation\cite{lin2023learning}. The primary challenge of this approach lies in the complex alignment needed between blurred and sharp patterns, involving procedures such as homography-based perspective projection, lens distortion correction, and radiometric compensation.

Another category adopts a parametric PSF model, such as using a heteroscedastic Gaussian with parameters estimated from closed-form equations based on image gradients. However, this model can be overly restrictive, particularly for first-entry lenses where the blur may not conform to a Gaussian kernel~\cite{eboli2022fast}.

In summary, employing an accurate parametric PSF model is critical for precise estimation. Furthermore, robust and simplified measurements are preferred for operational efficiency. 

