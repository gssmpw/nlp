\section{Related Work}
\label{related}

\begin{comment}
In any supervised learning system (regression or classification), the data come in pairs: predictors ($\X$, inputs) and response ($Y$, output). Either can be continuous or categorical or mixed. To model uncertainty in the data generating process, one can assume that both $\X$ and $Y$ are stochastic; i.e., they have a joint distribution, or that $Y$ is stochastic given the observed $\X$. 
In the latter case, where $\X$ is assumed to be fixed, several machine learning approaches enter predictor randomness in the model indirectly by assuming the parameters are random. This is the setting of Bayesian Neural Networks (BNNs) (see, e.g., \cite{Arbeletal2023,Deshpandeetal2022,GalGhahramani2016,KendallGal2017,Ghahramani2015}) and associated Variational Inference (VI) \cite{HintonvanCamp1993,Graves2011}. BNNs target what is called \textit{epistemic} or model uncertainty (whether the right model is fitted) and indirectly \textit{aleatoric} uncertainty; i.e., noise inherent in the observations resulting from the inputs being a sample from an unknown population. Epistemic uncertainty is modeled by placing a prior distribution over a model's parameters ($\Thetabf$ in \eqref{eq:reg-model}), and then estimating the posterior distribution of $\Thetabf$ given $\X$ and $Y$ using Markov Chain Monte Carlo (MCMC) or Variational Inference (VI). Aleatoric uncertainty is modeled at the backend by placing a distribution over the output of the model. For example, the outputs are modeled as corrupted with Gaussian random noise. Training of BNNs is challenging due to computational complexity.


To accommodate noisy data or aleatoric uncertainty (random input) in NNs directly, sampling-based and pdf approximation-based methods have been proposed. The former propagate randomness by mapping a set of samples through the NN based on which either features (e.g. moments) of the output distribution or the output distribution itself is derived. Monte Carlo simulation is used to draw random samples from the input  distribution, which are consequently propagated through the neural network to aggregate an output distribution. The training of large NNs is already computationally costly, and repeating this process a large number of times compounds the computational complexity without addressing the fundamental issue of the noise in the data deriving from their being a sample from a much larger population 
(see, e.g., \citet{Abdelazizetal2015,Jietal2020}). The core idea of pdf approximation-based methods is to assume the input, or the hidden layers of a NN have specific distributions. For example, \citet{Abdelazizetal2015} assume the distribution in each layer to be Gaussian and study their propagation through sigmoid NNs. \citet{ZhangShin2021} approximate input distributions with Gaussian Mixture Models. 
However, these methods suffer from significant approximation errors and are unable to accurately quantify predictive uncertainty in the NN output due to restrictive assumptions about the distributions in the input, their parameters, and hidden, or output layer. % (e.g., the assumption of any post-activation distribution being a Gaussian).
A summary of approaches to uncertainty estimation in neural networks can be found in \cite{Sickingetal2022} and a review in \cite{Gawlikowskietal2023}. 
\end{comment}

The literature on NN verification is not directly related to ours as it has been devoted to standard non-stochastic input NNs, where the focus is on establishing guarantees of local robustness. This line of work develops testing algorithms for whether the output of a NN stays the same within a specified neighborhood of the deterministic input (see, e.g., \citet{Gowaletal_2018,Xuetal_2020,Zhangetal2018,Zhangetal2020,Shietal2024,Buneletal_2019,Ferrarietal_2022,Katzetal_2017,Katzetal_2019,Wuetal_2024}). 

To handle noisy data or aleatoric uncertainty (random input) in NNs, two main approaches have been proposed: sampling-based and probability density function (pdf) approximation-based. Sampling-based methods use Monte Carlo simulations to propagate random samples through the NN (see, e.g., \citet{Abdelazizetal2015,Jietal2020}), but the required replications to achieve similar accuracy to theoretical approaches such as ours, as can be seen in Table \ref{tab:sim1}, can be massive. Pdf approximation-based methods assume specific distributions for inputs or hidden layers, such as Gaussian \cite{Abdelazizetal2015} or Gaussian Mixture Models \cite{ZhangShin2021}, but these methods often suffer from significant approximation errors and fail to accurately quantify predictive uncertainty. Comprehensive summaries and reviews of these approaches can be found in sources like \citet{Sickingetal2022} and  \citet{Gawlikowskietal2023}.


\begin{comment}
\efi{Is this local robustness really relevant to our paper? Seems to me it's about "deterministic" robustness.} The local robustness property in classification problems can be formulated as follows.
A neural network $f$ is locally robust at $x_{0}$  if
\begin{align*}
\forall x: \parallel x - x_{0}\parallel \leq \epsilon \xrightarrow[]{} f(x) = f(x_{0})
\end{align*}
 for some positive $\epsilon$ ($\epsilon$-robust),   where $\parallel \cdot \parallel$ is some distance measure. 
%\end{definition}
It is typical to consider $l_{1}$, $l_{2}$ or $l_{\infty}$ norms as distance measures, with the latter % $l_{\infty}$ norm is
being the most popular.

Interval Bound Propagation (IBP) \cite{Gowaletal_2018} provides certified robustness against \textit{nonrandom} adversarial perturbations by deriving constant-type bounds for output neurons based on input ranges. Linear Relaxation Perturbation Analysis (LiRPA) \cite{Xuetal_2020} generalizes bounds computation using a graph-based approach, expressing neural networks as computational graphs to construct affine bounds for intermediate nodes. CROWN and CROWN-IBP \cite{Zhangetal2018,Zhangetal2020} certify robustness for neural networks with general activation functions. CROWN bounds non-piecewise-linear activations using linear and quadratic functions, while CROWN-IBP combines IBP's efficiency with CROWN's tighter linear relaxation bounds.  GenBaB \cite{Shietal2024} extends branch-and-bound (BaB) frameworks \cite{Buneletal_2019,Ferrarietal_2022} to verify neural networks with general nonlinearities by combining linear bound propagation and optimized branching strategies, supporting activations like Sigmoid, Tanh, GeLU, and multidimensional operations. Finally, SMT-based frameworks like Reluplex \cite{Katzetal_2017} and Marabou \cite{Katzetal_2019,Wuetal_2024} verify neural networks by transforming property queries into constraint satisfaction problems, handling diverse activation functions and topologies with parallel execution for scalability.
\end{comment}


In the context of verifying neural network properties within a probabilistic framework,  \cite{Wengetal2019} proposed PROVEN, a general probabilistic framework that ensures robustness certificates for neural networks under Gaussian and Sub-Gaussian input perturbations with bounded support with a given probability. It employs CROWN \cite{Zhangetal2018,Zhangetal2020} to compute deterministic affine bounds and subsequently leverages straightforward probabilistic techniques based on Hoeffding's inequality \cite{Hoeffding1963}.  PROVEN provides a probabilistically sound solution to ensuring the output of a NN is the same for small input perturbations with a given probability, its effectiveness hinges on the activation functions used. It cannot refine bounds or handle various input distributions, which may limit its ability to capture all adversarial attacks or perturbations in practical scenarios.

The most relevant published work to ours we could find in the literature is \citet{Krapfetal2024}. They propagate input densities through NNs with piecewise linear activations like ReLU, without needing sampling or specific assumptions beyond bounded support. Their method calculates the propagated pdf in the output space using the ReLU structure. They estimate the output pdf, which is shown to be very close to a pdf estimate obtained by Monte Carlo simulations. Despite its originality, the approach has drawbacks, as they compare histograms rather than the actual pdfs in their experiments. Theorem 5 (App. C) in \cite{Krapfetal2024} suggests approximating the distribution with fine bin grids and input subdivisions, but this is practically difficult. Without knowledge of the actual distribution, it is challenging to define a sufficiently ``fine'' grid. In contrast, we compute exact bounds of the true output cdf over its entire support (at any point, no grid required), representing the maximum error over its support, and show %pointwise 
convergence to the true cdf. %, with uniform convergence when the output cdf is continuous.
\citet{Krapfetal2024} use a piecewise constant approximation for input pdfs, which they motivate by their Lemma 3 (App. C) to deduce that exact propagation of piecewise polynomials through a neural network cannot be done. 
We demonstrate that it is feasible and provide a method for exact integration over polytopes. Additionally, their approach is limited to networks with piecewise linear activations, excluding locally nonlinear functions. In contrast, our method adapts to CNNs and any NN with continuous, monotonic piecewise differentiable activations.