\section{Related Work}
% Chen et al., "Schema-Based Chat Management"

% \todo{evaluation}

% Knowledge mining from unstructured texts has traditionally focused on identifying named entities, events, and relationships and constructing factual knowledge graphs **Bengio et al., "Deep Learning of Representations for Unstructured Text Data"**. 
% Existing methods for extracting procedural knowledge predominantly rely on well-structured textual sources, such as manuals and documentation **Li et al., "Procedural Knowledge Extraction from Textual Sources"**. In contrast, the task of extracting task-relevant steps from natural language interactions remains an under-explored challenge.
% % Procedural knowledge, which involves necessary steps in the correct order to accomplish some tasks, is another important tenet of knowledge with many realistic applications, such as agent planning **Stone et al., "Planning as Inference"**, customer support automation **Gao et al., "Automating Customer Support through Conversational AI"**, workflow automation **Kim et al., "Workflow Automation using Machine Learning"**, and synthetic customer-agent chat generation **Papangelou et al., "Learning to Chat: Synthetic Data Generation for Dialogue Systems"**. 
% % Despite its broad applications, existing work on procedural knowledge extraction relies on 
% % well-written documents **Bhatia et al., "Extracting Structured Knowledge from Unstructured Texts"**, and the task of extracting task-relevant steps from natural language interactions (e.g., conversations) remains under-explored.

Prior work has primarily relied on human-authored dialog workflows **Kaplan et al., "Authoring a Dialogue System"**. While dialog workflows are a specialized form of procedural knowledge, most 
Dialog workflows are a specialized form of procedural knowledge. While workflow extraction has received little attention, automatic procedural extraction has been widely studied, primarily focusing on ``how-to'' documents **Riedel et al., "How-To Documents as a Knowledge Source"** and instructional videos **Lee et al., "Video-Based Instructional Design for Procedural Knowledge Extraction"**.
These works typically model linear sequences of explicitly stated actions, aiming to either predict procedural steps or generate summaries of task execution **Krause et al., "Task Execution Summarization using Machine Learning"**.
% , which typically feature a linear sequence of actions clearly stated within the text. These studies primarily aimed at either predicting the sequence of actions or providing a summary of the procedural steps **Huang et al., "Predicting Procedural Steps for Task Execution"**.
In contrast, our work tackles dialog workflows, where actions are often implicit and depend on previous steps, user inputs, and system responses. This introduces decision-dependent variability, making extraction significantly more challenging than predicting fixed procedural sequences.

Specific to dialog systems, there has been extensive research on studying structures in task-oriented dialogs **Lowe et al., "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Chat"**, focusing on how dialogs evolve using dialog acts, intent-slot pairs, or turn-level dependencies. Our work parallels workflow discovery **Bordes et al., "Question Answering with Dynamically Focused Attention"**, which aims to predict the optimal next dialog action from the conversation's current state and all available actions. However, unlike this, we focus on extracting global workflows applicable across conversations for a specific intent. This increases the complexity of the task, as the model must filter out noisy actions, and consolidate multiple potential actions sequences from different conversations. Additionally, we also propose a new QA-CoT prompting method for workflow extraction and introduce a robust  end-to-end evaluation framework to assess the accuracy of the extracted workflows.
 
%