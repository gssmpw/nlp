\section{Discussion}
Our case studies highlight the effectiveness and generalizability of our appoach. With \textsc{FINCH}, we found a wide variety of feature interactions in multiple data sets, without being limited to only two dimensions. 
All the experts were motivated to use our tool and noted in the final questionnaire that it was useful for their goals. The only limitation mentioned was that the tool is designed exclusively for tabular data, while experts also need tools for other data types, such as images.

The core idea of using subsets was intuitive to all participants, but clearly specifying what is included in the current subset proved crucial. The tools' options for calibrating trust, like ground truth and uncertainty visualizations, were 
well-received and deemed important. 
A limitation of the ground truth view is the impact of mean approximation on the ground truth curve; limited ground truth values per feature may not accurately represent the true mean, affecting result interpretation. Nevertheless, this view offers valuable insight into whether discrepancies arise from the model or the data.
The most complex view was separating the main and interaction effects, which participants found challenging. Effectively using this view may require significant reworking or a more extensive tutorial. 

However, experts indicated that more global and quantitative data, such as R² scores, are needed to fully assess a model's trustworthiness.
The experts also shared several suggestions for improving the tool, mostly focusing on providing clearer descriptions and enhancing the tool's interactivity. We observed all experts frequently adjusting feature values to see how predictions changed, underscoring the necessity and significant potential for interactive explanations in this context.
 
Overall, the tool was well received, and expert feedback confirmed that it met our requirements. The only questionnaire with varied responses was the ESC, reflecting the tool's specific focus. While the tool was seen as useful, it was not intended or perceived as providing complete explanations or fully assessing the model’s trustworthiness; global explanations are more suitable for that purpose. Instead, the tool successfully achieved its stated goals, and feedback on those objectives was highly positive.

