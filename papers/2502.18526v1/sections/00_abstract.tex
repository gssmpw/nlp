% Problem: 
% - (V2B) modeling (MDP)  EV charging at smart buildings is difficult because of several factors. Heteregenous chargers, constraints and requiremnets from stakeholders, inherent uncertainty from different sources etc... multi-agent cooperative optimization, 
% - traditional solutions such as ... insufficient because ...thus, RL. however, existing RL solutions fall short ...

% Method: 
% - We propose RL DDPG, what we did differently (what DDPG does exactly, or might remove DDPG)
% - action masking, guidance, forecast...
% - this section of abstract should be more descriptive.

% Results:
% - We validated our approach against real data from \nissan{} Charger setup in SCSV. 9 months, against (heuristics) & traditional approaches. 

% Conclusion:
% - Our approach is able to save \nissan{} \$X dollars compared fast charge.
%  (remove last sentences in current abstract)

% Problem
% By utilizing Electric Vehicles (EVs) as adaptive energy reservoirs, smart building owners have the opportunity to minimize energy costs. 
% By using Electric Vehicles (EVs) as energy reservoirs, smart building owners can optimize energy consumption by storing excess power during low-demand periods and supplying it during peak times. This reduces grid reliance, lowers costs, and mitigates demand charges by charging EVs during off-peak hours and discharging energy during peak periods. 
% However, this also presents significant challenges. The complexity of this Vehicle-to-Building (V2B) problem arises from multi-agent cooperative optimization, uncertainties in EV user behavior, and the influence of demand charges, which penalize peak consumption over monthly billing periods. 
% {\color{black} By using electric vehicles (EVs) as energy reservoirs, smart building owners can optimize energy consumption by storing excess electrical energy. This strategy reduces reliance on the power grid, and lowers electricity costs by EV charging schedules, as seen in Vehicle-to-Building (V2B) processes. However, V2B charging optimization presents significant challenges as we need to consider multiple agents including heterogeneous chargers, uncertainties in EV user behavior, and the impact of demand charges, which penalize peak consumption over long-term (monthly) billing periods. 
% % Current state-of-the-art 
% Traditional solutionsâ€”such as offline Mixed Integer Linear Programming (MILP) optimization, scheduling methods, and control-based approaches fall short in real-time decision-making under dynamic changes in the environment. Existing Reinforcement Learning (RL) methods for making online decisions struggle with large state-action spaces. They often fail to address decision-making problems with multiple agents in continuous action spaces, especially when considering long-term rewards, i.e., monthly billing cycle. 
% % Method
% In this paper, teams from academia and an \nissan{} introduce a novel RL framework to optimize the V2B charging process. We model these interactions as a Markov Decision Process (MDP), incorporating real-world data on EV arrivals, departures, user charging requirements, building power usage, and electricity pricing. Our approach utilizes the Deep Deterministic Policy Gradient (DDPG) algorithm. It is enhanced by action masking (to limit action-space exploration and ensure valid actions), and policy guidance (to direct RL training effectively).
% % Results
% We validated this approach using data from the EV manufacturer's smart office in Santa Clara, California, USA. We achieve savings of approximately \$1,270 over nine months compared to traditional fast charging procedures, while meeting all user charging requirements. Our method demonstrates strong generalizability to diverse real-world scenarios.
{\color{black} 
%Strategic aggregation and utilization of electric vehicle batteries as energy reservoirs to optimize and smoothen power grid demand is highly beneficial to smart and connected communities, particularly large office buildings, which often provide charging access to their employees as part of facilities. This involves optimizing vehicle charging and discharging to reduce the overall energy bought during peak use (i.e., when energy is more expensive) and the building's net peak demand, which is monitored over an extended period (e.g., a month). 
Strategic aggregation of electric vehicle batteries as energy reservoirs can optimize power grid demand, benefiting smart and connected communities, especially large office buildings that offer workplace charging. 
%This involves optimizing vehicle charging and discharging to reduce the overall energy bought during peak use (i.e., when energy is more expensive) and the building's net peak demand, which is monitored over an extended period (e.g., a month).  
This involves optimizing charging and discharging to reduce peak energy costs and net peak demand, monitored over extended periods (e.g., a month), which involves making sequential decisions under uncertainty and delayed and sparse rewards, a continuous action space, and the complexity of ensuring generalization across diverse conditions. Existing 
% modeling paradigms, e.g., single-shot mixed integer linear programming (MILP), and 
algorithmic approaches, e.g., heuristic-based strategies, fall short in addressing real-time decision-making under dynamic conditions, and traditional reinforcement learning (RL) models struggle with large state-action spaces, multi-agent settings, and the need for long-term reward optimization. To address these challenges, we introduce a novel RL framework that combines the Deep Deterministic Policy Gradient approach (DDPG) with action masking and efficient MILP-driven policy guidance. Our approach balances the exploration of continuous action spaces to meet user charging demands. 
Using real-world data from a major electric vehicle manufacturer, we show that our approach comprehensively outperforms many well-established baselines and several scalable heuristic approaches, 
achieving significant cost savings while meeting all charging requirements. Our results show that the proposed approach is one of the first scalable and general approaches to solving the V2B energy management challenge.
%A key contribution of our work is the development of a set of criteria to identify when RL models are unlikely to generalize for a given period, especially in the presence of out-of-distribution data. This allows for proactive adaptation and ensures the robustness of our solution.  
% \ad{commenting out the out of distribution part} 
% and show that the proposed approach significantly outperforms   framework was validated using real-world data from a major electric vehicle manufacturer, 
% means optimally charging and then discharging the vehicles, ensuring that the users leave with expected charge levels while accounting for the heterogeneity of charging infrastructures and the uncertainty of the arrival and departure of vehicles. At the same time, it is imperative to ensure that overall energy bought during peak use (i.e., when energy is more expensive) is reduced and the net peak demand of the building, which is monitored over a month, is reduced. 
% strong generalization to real-world conditions, offering a scalable and efficient solution to V2B energy management challenges.
}