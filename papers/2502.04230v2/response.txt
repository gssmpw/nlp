\section{Related Work}
\label{sec.related}

\header{Audio Watermarking} Audio watermarking has evolved significantly from traditional signal processing to modern deep learning approaches. Early rule-based methods focused on embedding watermarks in time or frequency domains through hand-crafted techniques **Fukuda, "Audio Watermarking by Embedding a Pseudo-Random Sequence"**__. A notable example is AudiowMark ____, which embeds a 128-bit message using convolutional coding and selective frequency band modifications. While sophisticated, these hand-crafted approaches often struggle with robustness against challenging transformations like neural audio codecs ____ **Tucker-Alper, "Robust Neural Audio Watermarking Using Convolutional Coding"**__. Deep neural networks (DNNs) have enabled more robust end-to-end watermarking systems that can generalize to unseen transformations ____. WavMark ____ introduced an invertible neural architecture for joint detection and attribution with 16-bit synchronization codes. While achieving strong performance, its brute-force decoding and architectural constraints limit scalability. AudioSeal ____ addressed these limitations with a generator-detector design with separate detection and message decoding. However, this improved detection came at the cost of attribution accuracy. Our work focuses on enabling both robust detection and accurate attribution through a more efficient architecture design with psychoacoustic-inspired quality loss.

\header{Source Attribution} A central objective in copyright protection is the ability to trace and verify the origin of creative works, which remains challenging in the realm of generative audio. Recent efforts have highlighted the necessity of robust source attribution mechanisms that work reliably across different transformations. For instance, **Agnew et al., "Audio Dataset Audit: Uncovering Intellectual Property Infringements"** ____ performed an extensive audit of popular audio datasets and revealed serious intellectual property infringements, underscoring the urgency for transparent dataset documentation and reliable authorship checks. In the music domain specifically, **Barnett et al., "Source Attribution in Generative Music Models using Audio Embeddings"** ____ advanced source attribution by leveraging audio embeddings to identify influential training data in generative music models, enabling a more transparent ``musical roots'' analysis. Such embedding-based similarity checks align with the broader push for dataset auditing, as reflected in **Du et al., "Holistic Copyright Auditing Mechanisms for Machine Learning Processes"** ____ , who argue for holistic copyright auditing mechanisms throughout the existing machine learning processes. In this work, we propose a neural watermarking system that achieves SoTA message decoding performance, which is an essential step toward robust source attribution.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/archs-jan16.pdf}
    \caption{
        \textbf{System Diagram for \ours.} \ours consists of a watermark generator and a watermark detector, with a shared embedding table that facilitates message decoding through a cross-attention module. In the generator part, we first employ an encoder network to encode the audio latent and then apply a temporal modulation to hide the message. The modulated latent is then fed into a decoder to produce the watermark residual. In the detector part, a linear detection head is used for detecting the presence of watermarks, and a cross-attention module with the shared embedding table is used for message decoding. 
    }
    \label{fig:framework}
\end{figure*}