\section{Related Work}
\label{sec.related}

\header{Audio Watermarking} Audio watermarking has evolved significantly from traditional signal processing to modern deep learning approaches. Early rule-based methods focused on embedding watermarks in time or frequency domains through hand-crafted techniques \cite{zhang2020time, hu2020selection, zhang2017robust, qin2022lattice}. A notable example is AudiowMark \cite{Westerfeld_audiowmark}, which embeds a 128-bit message using convolutional coding and selective frequency band modifications. While sophisticated, these hand-crafted approaches often struggle with robustness against challenging transformations like neural audio codecs \citep{defossez2022high}. Deep neural networks (DNNs) have enabled more robust end-to-end watermarking systems that can generalize to unseen transformations \citep{san2024proactive,chen2023wavmark,liu2023detecting}. WavMark \cite{chen2023wavmark} introduced an invertible neural architecture for joint detection and attribution with 16-bit synchronization codes. While achieving strong performance, its brute-force decoding and architectural constraints limit scalability. AudioSeal \cite{san2024proactive} addressed these limitations with a generator-detector design with separate detection and message decoding. However, this improved detection came at the cost of attribution accuracy. Our work focuses on enabling both robust detection and accurate attribution through a more efficient architecture design with psychoacoustic-inspired quality loss.

\header{Source Attribution} A central objective in copyright protection is the ability to trace and verify the origin of creative works, which remains challenging in the realm of generative audio. Recent efforts have highlighted the necessity of robust source attribution mechanisms that work reliably across different transformations. For instance, Agnew et al.~\cite{agnew2024sound} performed an extensive audit of popular audio datasets and revealed serious intellectual property infringements, underscoring the urgency for transparent dataset documentation and reliable authorship checks. In the music domain specifically, Barnett et al.~\cite{barnett2024exploring} advanced source attribution by leveraging audio embeddings to identify influential training data in generative music models, enabling a more transparent ``musical roots'' analysis. Such embedding-based similarity checks align with the broader push for dataset auditing, as reflected in Du et al.~\cite{du2024sok}, who argue for holistic copyright auditing mechanisms throughout the existing machine learning processes. In this work, we propose a neural watermarking system that achieves SoTA message decoding performance, which is an essential step toward robust source attribution.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/archs-jan16.pdf}
    \caption{
        \textbf{System Diagram for \ours.} \ours consists of a watermark generator and a watermark detector, with a shared embedding table that facilitates message decoding through a cross-attention module. In the generator part, we first employ an encoder network to encode the audio latent and then apply a temporal modulation to hide the message. The modulated latent is then fed into a decoder to produce the watermark residual. In the detector part, a linear detection head is used for detecting the presence of watermarks, and a cross-attention module with the shared embedding table is used for message decoding. 
    }
    \label{fig:framework}
\end{figure*}