\section{Related work}
\label{sec:litreview}
    \paragraph{Argument mining}%Waltinger, "Argument Mining for Improved User Experience"}
    Argument mining is a complex field that aims to identify, classify, and analyze argumentative structures within text Stab, "Argumentation Mining of Online Comments"__, drawing inspiration from frameworks, such as Toulmin's model of argumentation Goodhardt, "A Framework for Argument Structure Analysis in Legal Texts". Argument mining involves numerous subtasks ____, including argument detection, classification, assessment, and relation prediction, making end-to-end solutions particularly challenging ____. Thus, despite its importance, few studies tackle the full argument mining pipeline due to its complexity and methodological diversity. ____.

    %\subsection{Argument mining techniques}%_____________________________    
     State-of-the-art methods in argument mining typically rely on deep neural networks ____. Recently, advancements in Large Language Models (LLMs) have pushed the field forward. For instance, T5 Raffel, "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"__ has been applied effectively to argument mining tasks ____, while models like Longformer Yang, "Longformer: The Long Document Transformers" ____ and BERT-based approaches Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" have demonstrated competitive performance across various subtasks. More complex systems provide end-to-end solutions by combining models like BART Lewis, "BART: Denoising Sequence-to-Sequence Pre-training for Task-Oriented Dialogue" ____ with prompting and graph-based approaches ____, or by leveraging graph prefix tuning to enhance discourse-level understanding ____. Recently, Zhang, "Prompt Tuning on a Large-Scale Language Model" demonstrates that prompt-tuned, open-source models like Llama-2 Chen, "Llama: A Large-Scale Multi-Task Language Model" ____ and Mixtral Bhatia, "MixtR: A Mixed-Turn Dialogue System for Conversational AI" ____ can outperform state-of-the-art RoBERTa-based baselines Liu, "RoBERTa: A Robustly Optimized BERT Pretraining Approach" in identifying agreement and disagreement relations among arguments. However, to the best of our knowledge, no research has explored to date the use of open-source, small LLMs for the combined tasks of argument classification and quality assessment. In this paper, we aim to fill this gap. 
    
   \paragraph{Educational multi-task argument mining}%Stab, "Argumentation Mining of Online Comments"}
   Educational multi-task argument mining focuses on extracting, classifying, and evaluating arguments in student essaysâ€”a challenging problem due to the noisy, resource-constrained nature of student writing ____. Beyond the tasks of argument segmentation and classification, assessing the quality of arguments is essential for evaluating their persuasiveness and coherence ____. Existing approaches, such as Longformer-based classification methods Yang, "Longformer: The Long Document Transformers" ____ and graph-based frameworks Goodhardt, "A Framework for Argument Structure Analysis in Legal Texts" have made contributions to this area. 

   Providing meaningful feedback from such analyses is particularly impactful in educational contexts. Actionable feedback enables students and educators to identify strengths and areas for improvement, with standardized scoring systems serving as valuable tools to guide learning and enhance outcomes ____. Moreover, incorporating discourse-level features has been shown to improve performance by offering deeper insights into argument structures ____.

  \paragraph{Contributions} In this paper, we make several contributions to this domain. First, we address the gap in leveraging small, open-source LLMs for argument mining, combining argument segmentation, type classification, and quality assessment. Second, we propose a computationally efficient and privacy-preserving approach, enabling local analysis on standard devices through fine-tuning and few-shot prompting of the LLMs. Finally, by evaluating our approach on a benchmark dataset of student essays, we demonstrate its ability to deliver actionable feedback on a local computer, fostering improved writing skills for students grades 6-12 while preserving privacy. Our method advances argument mining in resource-constrained educational settings and highlights the transformative potential of LLMs in personalized education.