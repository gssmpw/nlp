

% \begin{figure*}[h]
% \minipage{0.48\textwidth}
%   \includegraphics[width=\linewidth]{final_results/ICP_shift_rotation.png}
% \endminipage\hfill
% \minipage{0.48\textwidth}
%   \includegraphics[width=\linewidth]{final_results/color_ICP_shift_rotation.png}
% \endminipage\hfill

% \caption{Comparison of ICP and Coloured ICP results across different shifts and rotations. The results highlight the RMSE and success rate differences between the two methods under varying conditions.}
% \label{fig:both_shift_rotation_results}
% \end{figure*}
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{final_results/source_target_generalization.png}
    \caption{The process of target generation}
    \label{fig:target_generation_process}
\end{figure}
\textbf{Synthetic Data} The initial set of experiments focuses on generating synthetic point cloud data to evaluate the performance of Coloured ICP algorithm. Using synthetic data guarantees precise ground truth values for the target positions and orientations. It also allows us to explore the iterative algorithm under a variety of initial configurations of translation and orientation. We can also control the amount of noise the simulated LIDAR data.
As we vary translation, orientation, and noise our evaluation criteria are: 
\begin{itemize}
    \item \textbf{Root Mean Squared Error (RMSE)}: The error between the source and target checkerboards after alignment. The error is expressed as a fraction of the target size.
    \item \textbf{Success of measurement}: Defined as a case where ICP or Coloured ICP converges with RMSE less than 15\% of one side of the source checkerboard (geometric success) and the colour matching score exceeds 0.5 (colour success), with both conditions satisfied.
\end{itemize}

We vary the initial translation of the template in relative terms of the size of the target from 0\% (full overlap) to 150\% (no overlap) in steps of 10\%, applying both in-plane and out-plane rotations with the same degree of rotation for each (see Figure \ref{fig:target_generation_process}). We conduct experiments by randomly selecting translation directions while increasing the shift and rotation magnitudes. For each configuration, we perform 100 experiments and compute the statistics for the criteria above.



\begin{figure}[h]
    \centering
    \subfigure[Before RANSAC]{
        \includegraphics[width=0.45\linewidth]{visuals/before_ransac.png}
    }
    \hfill
    \subfigure[After RANSAC]{
        \includegraphics[width=0.45\linewidth]{visuals/after_ransac.png}
    }
    \caption{Effect of RANSAC filtering. (a) Before RANSAC: Numerous outliers are present particularly in the black regions, affecting the alignment. (b) After RANSAC: The outliers are removed, leading to a cleaner point cloud and improved registration quality.}
    \label{fig:ransac_before_after}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[Before binarisation]{
        \includegraphics[width=0.45\linewidth]{visuals/before_binarisation.png}
    }
    \hfill
    \subfigure[After binarisation]{
        \includegraphics[width=0.45\linewidth]{visuals/after_binarisation.png}
    }
    \caption{Effect of binarisation on point cloud processing using Otsu's method}
    \label{fig:binarisation}
\end{figure}


\begin{figure*}[h]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{final_results/ICP_shift_rotation.png}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{final_results/color_ICP_shift_rotation.png}
\endminipage\hfill

\caption{Comparison of ICP and Coloured ICP results across different shifts and rotations. The results highlight the RMSE and success rate differences between the two methods under varying conditions.}
\label{fig:both_shift_rotation_results}
\end{figure*}

The experiments on simulated data will be followed up with tests on real LIDAR data captured with a Livox MID-360 sensor. Figure \ref{fig:target_visual} shows a visual representation of the problem we are tackling, with the rightmost scan being the most challenging situation. 

\textbf{Real Data} In order to evaluate the proposed checkerboard registration method in real-world scenarios, we collected indoor point cloud data using our Livox LiDAR sensors. The scanned scene includes a physical checkerboard composed of black and white squares. As we are not aware of commercial reference software that can be applied to arbitrary unordered point clouds, we do not have ground truth values for this experiment. Therefore, we conduct a second experiment on a dataset acquired of the same scene with a Leica RTC 360 survey-grade terrestrial laser scanner. We use vendor-provided software Leica Register360 to measure the centres of the targets in the scene. This provides ground truth values, albeit on an ordered and rather noise-free point cloud.

We first isolate the region of interest from the raw LiDAR data by cropping a bounding box around the checkerboard's assumed initial location. The synthetic checkerboard template is initialised near the assumed position of the real checkerboard. To match the scale and geometry of the real chequerboard, we resized the synthetic model to the a priori known physical dimensions of the realcheckerboard. In order to leverage colour-based registration, we convert intensity information of the synthetic checkerboard into corresponding RGB values. Following the extraction of the real checkerboard and the preparation of the synthetic one, we perform a first alignment step using Point-to-Plane Iterative Closest Point (ICP). 

Due to the nature of LiDAR sensing, black surfaces generally exhibit lower reflectivity compared to white surfaces, often leading to weaker return signals and higher measurement noise. In our Livox sensor data, the black squares on the checkerboard display significantly more noise and outlier points than the white squares. There are already previous reports on the issues around the intensity values and effects on ranging accuracy of this category of LiDAR sensors \citep{zhang_investigation_2023}.

To mitigate the impact of the noise on point cloud registration, we apply a RANSAC-based outlier removal step on the extracted real checkerboard. This is to eliminate outliers, predominantly over the black squares. 

It is well known from template matching in images that differences in colour or grey values between source and target need to be considered. For example, in least-squares matching this is often achieved with estimating an offset and scale factor for the intensity. However, in \citep{park_colored_2017} the photometric cost function is formulated as the squared differences of intensity values. We must therefore adapt the intensities before Coloured ICP is applied.

%However, two issues arise: (1) the number of black points in the dataset was drastically reduced and (2) since the original greyscale or intensity values were continuous, it complicates finding colour correspondences. 

% \begin{figure}[t]
%     \subfigure[RMSE of Coloured ICP ]{
%         \includegraphics[width=1\columnwidth]{final_results/RMSE_noise_shift_rot.png}
%     }
%     \subfigure[Success Rate of Coloured ICP ]{
%         \includegraphics[width=1\columnwidth]{final_results/SR_noise_shift_rot.png}
%     }

%     \caption{Results of Coloured ICP with noise in the target data. (a) RMSE across different shifts and rotations.(lower values indicate better performance) (b) Success Rate across different shifts and rotations.(higher values indicate better performance)}
%     \label{fig:both_shift_rotation_noise_results}
% \end{figure}

To address these problems, we perform a binarisation of the point cloud intensities using Otsuâ€™s method. This binarised representation facilitated the identification of corresponding points during Coloured ICP, ensuring more accurate and robust registration by reducing ambiguity in grayscale intensity variations.

With the pre-processed real checkerboard (noise reduction and binarisation) and the synthetic checkerboard, we execute Coloured ICP to further refine the alignment. The full workflow with example data is shown in Figure \ref{fig:Registration_visualisation}.


