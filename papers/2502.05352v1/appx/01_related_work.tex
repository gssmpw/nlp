\section{Related Work}
\textbf{LM and agents for resolving IT automation tasks.}
There is a surge in use of AI/ML for handling IT automation tasks.
We describe related work for each persona.

\subsection{Site Reliability Engineering}
IT scenario\footnote{We use the term scenario broadly to refer to failures, performance problems, compliance issues and, cost anomalies.} resolution encompasses tasks such as detection (e.g., identifying anomalies or outages)~\cite{10.1145/2829988.2787496, leners2011detecting, sigelman2010dapper, fonseca2007x}, diagnosis (e.g., pinpointing root causes through metrics and logs)~\cite{tan2019netbouncer,jha2020live, ma2014node, PyRCA}, and mitigation (e.g., operational fixes or code changes). 
These efforts often rely on supporting tasks like ticket analysis and routing~\cite{gao2020scouts,liu2023ticket, arzani2016taking}, anomaly detection~\cite{TSBench}, topology extraction~\cite{ashok2024traceweaver, chakraborty2023causil, pham2024root, yao2024chain}, causal~\cite{budhathoki2022causal, dowhy, ikram2022root, chakraborty2023causil} and interventional~\cite{wang2023fault, bagehorn2022fault} analysis using IT data.
Clearly, there is significant research in this area, fully automating incident resolution or providing actionable insights to humans remains elusive due to the complexity of real-world systems, the variability of incidents, and the challenge of incorporating contextual knowledge into AI systems~\cite{jha2020live}. 
Recent advances in language models (LMs) have led to their adoption of ticket data analysis and diagnosis tasks~\cite{roy2024exploringllmbasedagentsroot, 10172904,cloudatlas, chen2023empowering, rcaflash}. 
Most notable examples include Cloud Atlas use LLMs for causal graph construction~\cite{cloudatlas}, RCACopilot for ticket analysis~\cite{chen2023empowering} with the aim to diagnose and mitigate incidents.
However, they achieve poor performance compared to other techniques. For example, \cite{roy2024exploringllmbasedagentsroot} shows that chain-of-thought only achieves accuracy of 35\%. 
More recently, LMs are used in agentic workflows, engaging with real or virtual environments, using several tools at their disposal, for tasks like web navigation~\cite{workarena2024, workarena++, koh2024visualwebarena}, system control~\cite{sahu2024insightbench, rcaflash, aiopslab}, and code generation~\cite{yang2024swe}. 
However, the initial results of these works show a high variability in the success rate \textemdash 35\% in InsightBench~\cite{workarena++} and the ReAct-based agent for ticket data analysis~\cite{roy2024exploringllmbasedagentsroot} to 100\% in Flash~\cite{aiopslab} for incident resolution despite the fact that %
it is a much harder task than identifying planted insights in tabular and ticket data. 
Our own results in this work suggest that LLMs and agents struggle to consistently complete incident resolution tasks.
\textit{We assert that the variability in success rate exists because of difference in realism of these datasets.}
This highlights the urgent need for standardized and open source benchmarks to evaluate and improve the efficacy of AI methods on incident resolution tasks effectively.

\textbf{SRE-focused Benchmarks}
The benchmarking landscape for IT operations (ITOps) tasks is still in its early stages, with a few existing efforts addressing specific aspects of the domain. 
AIOpsLab~\cite{aiopslab} focuses on resolving IT incidents  \textit{only} for SRE personas, covering nine distinct problems created in a real environment. 
It does not follow SRE best practices for system and application observability, e.g., using an alert management system, lacks comprehensive coverage analysis, and a leaderboard for systematic automated evaluation. 

InsightBench~\cite{sahu2024insightbench} targets the analysis of ServiceNow ticket data, a critical supporting task for incident routing and finding relevant past incidents, but its reliance on synthetic data and the lack of a real environment limit its applicability to agentic workflows. 
Similarly, TSB-AD~\cite{liu2024elephant} is designed for univariate and multivariate anomaly detection, a core task for incident detection. However, it is limited to synthetic data and focuses only on anomaly detection.


\subsection{Compliance}
Compliance automation software is emerging to help businesses streamline and automate compliance processes, reducing the need for manual monitoring and tracking of regulations. This ensures continuous adherence to laws. In particular, compliance as code is a very recent development in the IT industry motivated by companies and audit agencies shifting from annual audits to expectations of continuous and automated measurement of compliance to maintain control of their regulated environments' posture and risks for cyberattacks. 

Recent works~\cite{survey, change-iaai2022} have applied AI/ML techniques to speed up these tasks, focusing on mapping regulatory requirements to standard control frameworks such as NIST 800-53~\cite{nist800-53catalog}. Our agentic automation in the current \bench solution pioneers this type of effort to author compliance artifacts through AI / ML by bridging compliance as code into policy as code. Policy engines have a longer history in the IT industry compared to compliance as code; however, emerging general usage policy engines such as~\cite{Intro:OPA} try to address the need for a common framework for continuous compliance. 
We are not aware of any effort -albeit critical and needed- related to benchmarking of compliance automation software, whether with or without agentic support.

\subsection{FinOps}
The area of IT cost management encompasses multiple disciplines, namely FinOps, IT Financial Management (ITFM), Technology Business Management (TBM) and Porfolio Businesss Management (PBM). At present, the FinOps domain typically deals with cloud costs \cite{cloud_finops_2nd, OptITfinops}, which includes compute nodes, memory, other storage, networking, etc., that are incurred with one of the hyperscalers.  ITFM includes on-prem infrastructure, licensing, labor, procured services, tech support, etc. The \href{https://www.tbmcouncil.org/}{TBM Council} provides a standard taxonomy to describe cost sources, technologies, IT resources (IT towers), applications, and services. In addition, there are industry-specific extensions to the taxonomy, such as for healthcare, banking, etc. In essence, this taxonomy provides a generally accepted way of categorizing and reporting IT costs and other metrics. PBM refers to the practice of managing a collection of projects and programs within an organization, ensuring alignment with the overall business strategy and maximizing their collective value by allocating resources efficiently. The FinOps Foundation has indicated that over time it will include elements from ITFM, TBM, and PBM.


Currently, for FinOps, there is no benchmark that fits the definition of benchmark that we are using in this paper. However, over the years, the FinOps Foundation \cite{finopsbench} has compiled several KPIs that can form the basis for use cases and scenarios for a FinOps benchmark. 
Current FinOps Foundation KPIs include:
\begin{itemize}[left=0pt, topsep=0pt, partopsep=0pt, itemsep=0pt, parsep=0pt]
\item Usage or Spend Apportionment Validation
\item Total Unpredicted Variance of Spend
\item Percent of Compute Spend Covered by Commitment Discounts
\item Effective Savings Rate Percentage 
\item Percentage of Commitment Discount Waste
\item Percent of Unused Resources
\item Auto-scaling Efficiency Rate 
\item Forecast Accuracy Rate (Usage, Spend) 
\item Percentage of Unallocated Shared CSP Cloud Cost
\item Percentage Variance of Budgeted vs. Forecasted CSP Cloud Spend
\item Percentage of CSP Cloud Costs that are Tagging Policy Compliant
\item Percent Storage on Frequent Access Tier  
\item Percentage of Legacy Resource
\end{itemize}

With the advent of the cloud, the academic and industrial research communities have also been active in investigating ways to optimize costs while balancing multiple objectives.
Recent works in the space of FinOps have focused on applying machine learning and mathematical optimization techniques \cite{containerfinops, OptITfinops} to better serve customers' cloud infrastructure needs while offering them insights and recommendations on how they could optimize their overall cloud spend. \cite{snapefinops} addresses the issue of helping customers make trade-offs between cost and resource availability in the presence of offerings such as spot VMs which are cheaper than on-demand VMs but have reduced availability. They propose a framework that uses constrained reinforcement learning to optimize cost and availability by identifying an optimal mix of on-demand VMs and spot VMs. %
Papers such as \cite{Resourcescalingfinops, forecastingfinops, autoscalingfinops} propose forecasting algorithms to scale cloud resources for service level objectives, contributing to the broader field of FinOps-driven cost optimization.
\cite{Resourcecostoptfinops} uses anomaly detection, machine learning, and particle swarm optimization to achieve a cost-optimal cloud resource configuration. \cite{Costoptfinops} analyze the process of using cloud storage to explore opportunities, motivations, and challenges of cost optimization from user perspectives. \cite{Inventoryfinops} focuses on finding the optimal combination of on-demand and reserved instances, such that the demand is satisfied and the costs minimized. They model this optimization problem as a stochastic inventory control problem. 

\cite{CCOfinops} introduces a scalable cost optimizer that determines the most cost-effective deployment strategy for workloads on public or hybrid clouds, considering resource requirements and constraints to minimize costs.
In FinOps, there is an urgent need to move beyond comparative scorecards and broad taxonomies to specific use cases that test the ability of automated agents to optimize IT investments and reduce resource waste. %
To our knowledge, no benchmarks exist for use cases like forecasting, anomaly detection, or cost optimization, nor are there standardized methods to evaluate these techniques with or without agentic support. We are confident that \bench will unite research and development communities to tackle real-world problems through the power of AI and optimization.
