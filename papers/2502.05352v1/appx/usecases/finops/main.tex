\section{Financial Operations}
\label{appx:finops}

\subsection{Background}
\label{ss:finops-background}

FinOps (Finance + Operations) is an operational framework and cultural practice which maximizes the business value of cloud and creates shared financial accountability. One of the primary objective is to enable timely data-driven decision making  by fostering collaboration between engineering, finance, and business teams.  FinOps comprises of three iterative phases - Inform (Visibility \& Allocation), Optimize (Rates \& Usage), and Operate (Continuous Improvement \& Usage). 
Importantly, success in FinOps hinges on making iterative changes using real-time insights with data gathered from Application Performance Management (APM), Application Resource Management (ARM), and Finance (Cloud Cost Management)~\cite{cloud_finops_2nd}. 


Contrary to common belief, FinOps is about maximizing business value and not just about reducing operating costs.
The 2024 State of FinOps Report ~\cite{finops_data, finops_insights_2024} gathered data from 1,245  respondents with an average annual cloud spend per company of \$44M, with some companies reporting up to \$1B+ in annual cloud spend, total cloud spend \$55B. This study showed a shift from previous years, with reducing waste and managing commitments becoming new leading key priorities across the board. 
Management of cloud discount programs (such as Savings Plans and Reserved Instances), and accurate forecasting of spend remained high on the list. 
 Other areas such as increased Automation, AI costs, and sustainability registered growing interest.
\subsubsection{Key terms}
FinOps is performed by working iteratively on the Framework Capabilities through three phases \cite{finopsbenchkpis} namely, Inform, Optimize and Operate, which are described below:
\begin{enumerate}[labelwidth=*, labelindent=0pt, leftmargin=*, label=(\arabic*),itemsep=0mm]
\item The Inform phase involves identifying data sources for cloud cost, usage and efficiency data. This data is then used for budgeting, allocation, forecasting, analysis and reporting. 
\item The Optimize phase identifies opportunities to improve cloud efficiency using the data and capabilities developed in the Inform Phase.
\item The Operate phase implements operationalizes FinOps using the data and capabilities developed in the Inform and Optimize phase. 
\end{enumerate}
Some of the common KPIs in the FinOps that are amenable to optimization (full set is listed in https://www.finops.org/wg/finops-kpis/) include
\begin{enumerate}[labelwidth=*, labelindent=0pt, leftmargin=*, label=(\arabic*),itemsep=0mm]
    \item Percentage Resource Utilization - This is the amount of resources utilized as a percentage of the the total capacity allocated.
    \item Total Unpredicted Variance of Spend - Measures the unpredicted variance of cost associated with CSP Cloud usage recorded over a given period of time.
    \item Auto-scaling Efficiency Rate -  Maximum capacity cost of running workload to meet workload demand / Cost of running workload with auto-scaling to meet same workload demand.
    \item Forecast Accuracy Rate (Usage) - Compares forecasted vs. actual cloud usage (vCPUs, Memory, etc) over a specific period (e.g., day, month, quarter).
    \item Forecast Accuracy Rate (Spend)- This metric compares forecasted vs. actual cloud spend over a specific period (e.g., day, month, quarter).
    \item Percent of Compute Spend Covered by Commitment Discounts - Measures the percentage of compute cost (excluding Spot) covered by commitment discount for a specific time period.
    \item Percentage of Commitment Discount Waste - The percentage of commitments not applied to on-demand spend.
    \item Percent of Unused Resources - Measure of unused cloud resources, e.g., unattached/orphaned storage volumes, load balancers, EIPS, Network gateways, snapshots.
    \item Percentage of Unallocated Shared CSP Cloud Cost - This measurement refers to expenses that cannot be directly attributed to a specific project, team, or department within an organization.
    \item Percentage Variance of Budgeted vs. Forecasted CSP Cloud Spend - Measures the difference between budgeted costs and the forecasted costs for using CSP cloud services
    \item Effective Savings Rate Percentage - Actual Spend with Discounts / Equivalent Spend at On Demand Rate
    \item Percentage of CSP Cloud Costs that are Tagging Policy Compliant - Total Costs Associated with Tagging Policy Compliant CSP Cloud Resources During a Period of Time / Total CSP Cloud Costs During a Period of Time. 
    \item Percent Storage on Frequent Access Tier - Number of GB in Standard (or “frequently accessed” tiers vs. total GBs stored)
    \item Percentage of Carbon Associated with Untagged CSP Cloud Resources
\end{enumerate}
There are several analogous KPIs related to carbon footprints instead of dollar costs. 
In the current version of the bench our scenarios have used an alert based on variance in spend. The remaining KPIs offer a rich basis for formulating many additional scenarios.
\subsection{Motivating Example and FinOps Tasks}
\label{ss:finops-tasks}
\Cref{tab:optimization_use_case_demand} shows an exemplar budget overrun incident with the steps for diagnosis and resolution. 
In this incident, FinOps practitioners were notified of an ~\textemdash unusual cost increase (>20\% more than last week's average)~\textemdash alert by OpenCost.
The increase is mainly caused by the increase in replica counts as a result of an observed load spike.
The autoscaler increased the number of replicas to serve the demand as expected.
However, budget thresholds are not updated which causes false alerts. 
Agent finds out that the application is healthy and recommends updating budget alerts based on the new load level. 
Similarly, Table~\ref{tab:optimization_use_case_autoscaler} demonstrates a sample scenario where a budget overrun alert has been generated due to increased replicas. 
However, in this scenario application services are scaled up significantly despite low utilization in containers. 
Agent finds out autoscaler scaled up the application at low utilization thresholds and analyze the autoscaler configuration. 
It detects low thresholds for scale up policy and recommends updating autoscaler accordingly. 




\begin{table*}[ht!]
    \small
    \centering
    \begin{threeparttable}
        \caption{Optimization Use Case: Increased Cost Alert - Increasing Demand}
        \label{tab:optimization_use_case_demand}
        \begin{tabular}{m{0.3\textwidth}m{0.65\textwidth}}
            \toprule
            \textbf{Optimization Use Case} & \textbf{Details} \\
            \midrule
            Triggering Alert & Cost increase alert for an application “Foo”.  \\
            Summary & Cost alert was seen on application “Foo”. The increase was 20\% higher than the expected budget. Investigations reveal that the application is healthy and cost increase is caused by load increase. Client budget is flexible and thus cost alert is updated accordingly to increase the threshold. Long term fix requires additional check in CI/CD pipeline and possible automation of budget adjustments.   \\
            Time to detection & 7 days (Current practices to observe utilization metrics for cost analysis \\
            Time to diagnose & 60 minutes \\
            Time to mitigate & 15 minutes \\
            Event Type & An alert is generated to show there is more than 20\% increase in expected cost.\\
            Cost Overrun & 20\% increase in cost\\
            Diagnosis Steps & 
            \begin{itemize}[left=0pt, topsep=0pt, partopsep=0pt, itemsep=0pt, parsep=0pt]
                \item Checked infrastructure size changes. e.g. Increase in replica counts in Kubernetes cluster.
                \item Found replica counts are greater than historical average.
                \item Checked whether there is a legit increase in application load.
                \item Found there is a stable increase in the application load and the cost increase is acceptable.
                \item Checked budget constraints of the application.
                \item Found application budget is flexible for scaling up.
            \end{itemize} \\
            Resolution Plan & \begin{itemize}[left=0pt, topsep=0pt, partopsep=0pt, itemsep=0pt, parsep=0pt]
                \item Calculated the new cost alert thresholds.
                \item  Update cost alert budget thresholds to accommodate new stable load level to prevent false alerts.
            \end{itemize} \\ 
            Long Term Improvements & Created playbooks to ensure such handling such adjustments are automated. \\
            \bottomrule
        \end{tabular}
    \end{threeparttable}
\end{table*}


\begin{table*}[ht!]
    \small
    \centering
    \begin{threeparttable}
        \caption{Optimization Use Case: Increased Cost Alert - Faulty Auto-scaler}
        \label{tab:optimization_use_case_autoscaler}
        \begin{tabular}{m{0.3\textwidth}m{0.65\textwidth}}
            \toprule
            \textbf{Optimization Use Case} & \textbf{Details} \\
            \midrule
            Triggering Alert & Cost increase alert for an application “Foo”.  \\
            Summary & Cost alert was seen on application “Foo”. The increase was 20\% higher than the expected budget. Investigations reveal that auto scaler was misconfigured. SREs manually updated the auto scaling configuration by changing the scale up policy. Long term fix requires additional check in CI/CD pipeline.  \\ \\
            Time to detection & 7 days (Current practices to observe utilization metrics for cost analysis  \\
            Time to diagnose & 60 minutes \\
            Time to mitigate & 15 minutes \\
            Event Type & An alert is generated to show there is more than 20\% increase in expected cost.\\
            Cost Overrun & 20\% increase in cost\\ \\
            Diagnosis Steps & 
            \begin{itemize}[left=0pt, topsep=0pt, partopsep=0pt, itemsep=0pt, parsep=0pt]
                \item Checked infrastructure size anomalies, e.g., increase in replica counts in Kubernetes cluster.
                \item Found replica counts are greater than historical average.
                \item Checked whether there is a legit increase in application load.
                \item Found an increase in load and pending containers.
                \item  Checked utilization of containers
                \item Found low utilization
                \item Checked autoscaler for scaling policy
                \item Found low threshold for scale up rules
            \end{itemize} \\
            Resolution Plan & \begin{itemize}[left=0pt, topsep=0pt, partopsep=0pt, itemsep=0pt, parsep=0pt]
                \item Configure auto scaler to update scaling policies.
                \item Manually delete extra replicas.
            \end{itemize} \\ 
            Long Term Improvements & Created playbooks to ensure such misconfigurations do not happen for future deployments. \\
            \bottomrule
        \end{tabular}
    \end{threeparttable}
\end{table*}



\subsection{\bench Architecture for Constructing FinOps Task Scenarios}
\label{ss:finops-bench}
We have extensively leveraged the set up that we established for the SRE scenarios. We employ OpenCost to monitor costs and raise an alert when the predefined budget and efficiency thresholds are crossed. 
OpenCost is an opensource tool which distributes the cost of a virtual machine/node to the Kubernetes deployments running on it based on the allocated resources. It selects higher of utilization or request numbers of each container and distributes the cost using a load distribution policy. 
In our experiments, we have forced a custom pricing model which mainly includes hourly CPU cost rate for a single core and memory cost rate per 1 GB memory. Other pricing components such as networking cost and spot instance pricing are not the main scope of our evaluated scenarios. Thus, we have included negligible costs for these components. 
We mimic real world scenarios as explained in SRE scenarios by including cost variation alerts. 





\subsection{Evaluation}
We have used the same evaluation framework used in SRE-bench by including OpenCost and cost alerts in the scenarios. 

\subsubsection{Evaluation Metrics}
We evaluate each LLM-based agents on two primary tasks: (i) diagnosis and (ii) mitigation.

\textbf{Diagnosis.}
The agent is evaluated on diagnosis by its ability to provide accurate \textit{root cause} of budget alerts.
Diagnosis includes the analysis steps that the agent follows to identify the root cause of the budget alerts.
Agent performance in diagnosis is measured using pass@1 scores that indicate the accuracy of the root cause analysis provided to the SREs. 


\textbf{Mitigation.}
Mitigation involves recommending resolution steps for incidents to clear the alerts and optimizing cost and efficiency of the application.  
We evaluate the agents with the success rate using pass@1 score and using proximity scores to analyze the performance of agents to achieve optimal cost and efficiency metrics defined in Section~\ref{s:finopsMetricDef}.
Both diagnosis and mitigation evaluations can be expanded in the future to automatically measure the performance of agents using LLM-as-a-judge similar to SRE-bench evaluations.

\subsubsection{Metric definitions}
\label{s:finopsMetricDef}
\textbf{pass@1.}
We use the same metric defined in Section~\ref{sss:eval-metrics} for both diagnosis and mitigation steps recommended by the agents. 

\textbf{Proximity metrics.} To analyze the performance of agents in achieving optimal cost and efficiency, we defined proximity scores for hourly CPU cost, hourly memory cost, workload CPU efficiency, and workload memory efficiency. Proximity scores indicates the performance by calculating the proportional absolute difference between observed and optimal values for the measured cost or efficiency metric. We subtract the proportional value from 1 such that having proximity score of 1 indicates achieving the optimal performance. Proximity scores are calculates as follows:

$$\text{proximity}\_i = 1 - \frac{| \text{observed}\_i - \text{optimal} |}{\text{optimal}}$$
where $i$ represents the experiment trial, $observed$ is the retrieved value for the measured metric, and $optimal$ is the value given in the ground truth for the same field.


\textbf{Hourly CPU cost:} The cost of allocating a single CPU core for an hour. We used custom pricing policy through opencost to ensure the ground truth values are not affected by changes in pricing between different cloud providers and on-premise deployments. \\

\textbf{Hourly Memory cost:} The cost of allocating 1 GB of memory. It also uses custom pricing policy. \\

\textbf{Workload CPU efficiency:} We take the average CPU efficiency of all containers of the application. We calculate CPU efficiency by dividing the CPU utilization of a container by the request amount. For instance, if the CPU request is 100m in the deployment configuration but the container uses 50m, the efficiency is calculated as 50.\\

\textbf{Workload memory efficiency:} It is calculated in the same way with CPU efficiency by dividing the utilization by requested memory amount. \\

We take the arithmetic mean of all runs for each metric and calculates the standard deviation. We present our results in Table~\ref{tab:finopsagent-eval}.



\subsection{Example Trajectories}
\label{ss:finops-trajectories}


FinOps issues are highly connected to used infrastructure and deployment configurations and policies for Kubernetes deployments. 
Agents commonly need to use the same tools as SRE-agent to understand the status of underlying infrastructure and deployment configuration of the application to identify the root cause of a FinOps concern. 
Similarly, to investigate budget variations accurately, they need analyzing load and utilization patterns to avoid diverging to irrelevant resolution recommendation. 
Figure~\ref{fig:finops-bad-trajectory} shows a trajectory for Scenario 37 where agent starts retrieving the alerts and observing CPU hourly cost has exceeded the budget threshold.
It continues checking deployment details using NL2Kubectl tool and retrieve replica counts for each deployment. 
Due to high number of replicas in adservice, it considers scaling down the adservice deployment. 
Missing utilization checks and not analyzing the deployment details caused agent to an inaccurate diagnosis and led to scaling down recommendation despite the high load for the application. 
In a correct trajectory, an agent would analyze the utilization and decides the high load in the system and would recommend changing the budget alert thresholds if total budget allocation allows or analyze the deployments which could be scaled down without hurting the application performance. 

\begin{figure}[hbtp]
    \centering
    \includegraphics[width=0.8\linewidth]{appx/usecases/finops/figures/wrongTrajectory.png}
    \caption{Sample Trajectory of unusual cost variation use case.} 
    \label{fig:finops-bad-trajectory}
\end{figure} 
