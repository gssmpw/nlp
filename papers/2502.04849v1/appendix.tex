\appendix

\section{Proof of Section~\ref{sec:discretization}}

We define several stochastic processes associated with the backward process $X_t^{\leftarrow}$ and the sample path $\vartheta_n$. First, recall that $X_t^{\leftarrow}$ is described by the following SDE:
\begin{align*}
    \rmd X_t^{\leftarrow}=\left(\dfrac{1}{2}X_t^{\leftarrow}+\nabla\log p_t(X_t^{\leftarrow})\right)\rmd t+\rmd W_t,\quad X_0^{\leftarrow}\sim p_T
\end{align*}
and $\{\vartheta_n^{\alpha},0\leqslant n\leqslant N\}$ satisfies the iterative law:
\begin{align*}
    \vartheta_{n+1}^{\alpha}=\mathcal{G}_h^{\alpha}(\vartheta_n^{\alpha},\{W_t\}_{nh\leqslant t\leqslant (n+1)h}),
\end{align*}
where $\alpha\in\{\sf EM,\sf EI,\sf REM,\sf REI,\sf SO\}$.

Based on $X_t^{\leftarrow}$, we define the following two processes, $\{Y_t,0\leqslant t\leqslant T\}$ and $\{\tilde{Y}_t,0\leqslant t\leqslant h\}$. $Y_t$ satisfies the SDE
\begin{align*}
    \rmd Y_t=\left(\dfrac{1}{2}Y_t+\nabla\log p_{T-t}(Y_t)\right)\rmd t+\rmd W_t,\quad Y_0\sim\hat p_T.
\end{align*}
$\tilde Y_t$ actually relies on $X_t^{\leftarrow}$ on the time interval $[nh,(n+1)h]$ for each $n$. However, we only need this notation in the proof of one-step discretization error, then we allow for some slight abuse of notation by omitting $n$, since it will not lead to any confusion. Therefore, $\{\tilde Y_t,0\leqslant t\leqslant h\}$ satisfies
\begin{align}
    \rmd\tilde Y_t=\left(\dfrac{1}{2}\tilde Y_t+\nabla\log p_{T-t}(\tilde Y_t)\right)\rmd t+\rmd W_t,\quad \tilde Y_0=\vartheta_n.
    \label{eq:tildeY}
\end{align}

Recall that we have defined two processes $\vartheta_{n+u}^{\sf REM}$ and $\vartheta_{n+u}^{\sf REI}$ in Section~\ref{sec:REM} and~\ref{sec:REI}, that is, for any $u\in[0,1]$ and $n=0,\cdots,N$, 
\begin{align*}
    \vartheta^{\sf REM}_{n+u}&:= (1+\frac{uh}{2})\vartheta_n^{\sf REM}+uhs_*(T-nh,\vartheta_n^{\sf REM})+\sqrt{uh}\xi_n\,,\\
    \vartheta_{n+u}^{\sf REI}&:=e^{uh/2}\vartheta^{\sf REI}_{n}+2(e^{uh/2}-1)s_*(T-nh,\vartheta^{\sf REI}_{n})+\sqrt{e^{uh}-1}\xi'_n\,.
\end{align*}

This section is devoted to proving the convergence rate of the diffusion model under various discretization schemes. 
To this end, we need the following auxiliary lemmas.
\begin{lemma}[Lemma 12 in~\cite{Gao2023WassersteinCG}]{\label{lem:GaoLt}}
    Suppose that Assumption~\ref{asm:p0scLipx} holds. Then, $\nabla\log p_t(x)$ is $L(t)$-Lipschitz, where $L(t)$ is given by 
    \begin{align*}
        L(t)=\min\{(1-e^{-t})^{-1},e^tL_0\}=
        \begin{cases}e^tL_0 & \text{ if }~t\leqslant \log(1+\frac{1}{L_0})\\
        (1-e^{-t})^{-1} & \text{ if }~t>\log(1+\frac{1}{L_0})
        \end{cases}\,.
    \end{align*}  
    Therefore, 
    \begin{align*}
        L(t)\leqslant  L_0+1\,.
    \end{align*}
\end{lemma}
\begin{lemma}[Proposition 10 in~\cite{Gao2023WassersteinCG}]{\label{lem:Gaomt}}
    Suppose that Assumption~\ref{asm:p0scLipx} holds. Then, $\nabla\log p_t(x)$ is $m(t)$-strongly log-concave, where $m(t)$ is given by
    \begin{align*}
        m(t)=\dfrac{1}{e^{-t}/m_0+(1-e^{-t})}\,.
    \end{align*}
    Therefore, 
    \begin{align*}
        m(t)\geqslant \min\{1,m_0\}\,.
    \end{align*}
\end{lemma}
Combining these two lemmas, we conclude that the Hessian matrix of $\log p_t$ satisfies the following condition
\begin{align*}
    -L(t)I_d \preccurlyeq \nabla^2\log p_t(\cdot)\preccurlyeq -m(t)I_d.
\end{align*}

We will frequently use Gr{\"o}nwall's inequality in the proof. 
Below, we present a specialized form tailored to the relevant processes.
\begin{lemma}
    \label{lem:Gron}
    Suppose the Assumption~\ref{asm:p0scLipx} holds, consider two stochastic processes $H_t$ and $G_t$ defined on the time interval $[t_1,t_2]$, if they satisfy the same SDE, especially motivated by the same Brownian motion, which means that
    \begin{align*}
        \rmd H_t=\Big(\dfrac{1}{2}H_t+\nabla\log p_{T-t}(H_t)\Big)\rmd t+\rmd W_t,\\
        \rmd G_t=\Big(\dfrac{1}{2}G_t+\nabla\log p_{T-t}(G_t)\Big)\rmd t+\rmd W_t.
    \end{align*}
    then for each $t\in[t_1,t_2]$, 
    \begin{align*}
        \l|H_t-G_t\r|_{\Ltwo}\leqslant e^{-\int_{t_1}^{t}(m(T-s)-\frac{1}{2})\rmd s}\l|H_{t_1}-G_{t_1}\r|_{\Ltwo}.
    \end{align*}
\end{lemma}
Applying Lemma~\ref{lem:Gron} to different processes and time intervals, we derive the following inequalities essential for our proof.
\begin{align}
    \l|Y_{nh+t}-\tilde{Y}_t\r|_{\Ltwo}\leqslant e^{-\int_{nh}^{nh+t}(m(T-s)-\frac{1}{2})\rmd s}\l|Y_{nh}-\tilde{Y}_0\r|_{\Ltwo},\quad\forall t\in[0,h].\label{eq:Gron1}\\
    \l|Y_t-X_t^{\leftarrow}\r|_{\Ltwo}\leqslant e^{-\int_0^{t}(m(T-s)-\frac{1}{2})\rmd s}\l|Y_0-X_0^{\leftarrow}\r|_{\Ltwo},\quad\forall t\in[0,T].\label{eq:Gron2}
\end{align}
which follow from the fact that $\{Y_t,0\leqslant t\leqslant T\}$, $\{\tilde{Y}_t,0\leqslant t\leqslant h\}$, $\{X_t^{\leftarrow},0\leqslant t\leqslant T\}$ all satisfy the same SDE as in Lemma~\ref{lem:Gron}, by applying a time-shifting operator to $\tilde{Y}_t$.\\

\subsection{Proof of Theorem~\ref{thm:EM}}
In this part, we provide the proof of Theorem~\ref{thm:EM}. To achieve this, we first prove the one-step discretization error in the following proposition.

\begin{proposition}
    \label{prop:EM}
    Suppose that Assumption~\ref{asm:p0scLipx},~\ref{asm:scLipt} and~\ref{asm:scoreerr} are satisfied. 
    Then, the following two claims hold.
    \begin{enumerate}[label=\textbf{(\arabic*)}, leftmargin=2em]
        \item \label{item:EMtilde} Firstly, it holds that
        \begin{align*}
            \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EM}\r|_{\Ltwo}\leqslant& h^2(C_1(n)^2+M_1)\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\\
            &+h^2\left[C_1(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+M_1\left(1+C_2(n)+C_4\right)\right]\\
            &+h^{3/2}\sqrt{d}C_1(n)\\
            &+h\varepsilon_{sc},
        \end{align*}
        where
        \begin{align*}
            C_1(n)&=\dfrac{1}{2}+\dfrac{1}{h}\int_{nh}^{(n+1)h}L(T-t)\rmd t,\\
            C_2(n)&=e^{-\int_0^{nh}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_0-X_T\r|_{\Ltwo},\\
            C_3(n)&=\dfrac{1}{h}\int_{nh}^{(n+1)h}(dL(T-t))^{1/2}\rmd t,\\
            C_4&=\sup_{0\leqslant t\leqslant T}\l|X_t\r|_{\Ltwo}.
        \end{align*}
        \item \label{item:EMYt}
        As a result, 
        \begin{align*}
            \l|Y_{(n+1)h}-\vartheta_{n+1}^{\sf EM}\r|_{\Ltwo}\leqslant r_n^{\sf EM}\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}+h^2C_n^{\sf EM}+h^{3/2}\sqrt{d}C_1(n)+h\varepsilon_{sc},
        \end{align*}
        where
        \begin{align*}
            r_n^{\sf EM}&=e^{-\int_{nh}^{(n+1)h}(m(T-t)-\frac{1}{2})\rmd t}+h^2(C_1(n)^2+M_1),\\
            C_n^{\sf EM}&=C_1(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+M_1\left(1+C_2(n)+C_4\right).
        \end{align*}
    \end{enumerate}
\end{proposition}
\begin{proof}
We prove the two claims sequentially.\\
\textbf{Proof of Claim~\ref{item:EMtilde}}. Rewrite display~\eqref{eq:tildeY} in the integral form,
\begin{align*}
    \tilde{Y}_h=\tilde{Y}_0+\int_{0}^{h}\left(\dfrac{1}{2}\tilde{Y}_t+\nabla\log p_{T-nh-t}(\tilde{Y}_t)\right)\rmd t+\int_{nh}^{(n+1)h}\rmd W_t \,.
\end{align*}
For Euler-Maruyama method, we can write $\vartheta_{n+1}^{\sf EM}$ in integral form as follows
\begin{align*}
    \vartheta_{n+1}^{\sf EM}=\vartheta_n^{\sf EM}+\int_{nh}^{(n+1)h}\left(\dfrac{1}{2}\vartheta_n^{\sf EM}+s_*(T-nh,\vartheta_n^{\sf EM})\right)\rmd t+\int_{nh}^{(n+1)h}\rmd W_t.
\end{align*}
Note that $\tilde Y_0=\vartheta_n^{\sf EM}$, then, it holds that
\begin{equation}
    \begin{aligned}
        \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EM}\r|_{\Ltwo}=&\left\lVert\dfrac{1}{2}\int_0^h(\tilde{Y}_t-\vartheta_n^{\sf EM})\rmd t+\int_0^h(\nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf EM}))\rmd t\right\rVert_{\Ltwo}\\
        \leqslant&\underbrace{\left\lVert\dfrac{1}{2}\int_0^h(\tilde{Y}_t-\tilde{Y}_0)\rmd t+\int_0^h(\nabla\log p_{T-nh-t}(\tilde{Y}_t)-\nabla\log p_{T-nh-t}(\tilde{Y}_0)\rmd t\right\rVert_{\Ltwo}}_{\text{\large I}}\\
        &+\underbrace{\left\lVert \int_0^h(\nabla\log p_{T-nh-t}(\vartheta_n^{\sf EM})-\nabla\log p_{T-nh}(\vartheta_n^{\sf EM}))\rmd t\right\rVert_{\Ltwo}}_{\text{\large II}}\\
        &+\underbrace{\left\lVert\int_0^h(\nabla\log p_{T-nh}(\vartheta_n^{\sf EM})-s_*(T-nh,\vartheta_n^{\sf EM}))\rmd t\right\rVert_{\Ltwo}}_{\text{\large III}}.
    \end{aligned}
    \label{eq:decomp}
\end{equation}
Here, we decompose the term $ \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EM}\r|_{\Ltwo}$ into a sum of three terms and then control each term individually.\\
For the term \text{I} of inequality~\eqref{eq:decomp}, by Assumption~\ref{asm:p0scLipx} and  Lipschitzness of $\nabla\log p_t$, we obtain 
\begin{align*}
    \rm{I}&=\left\lVert\dfrac{1}{2}\int_0^h(\tilde{Y}_t-\tilde{Y}_0)\rmd t+\int_0^h(\nabla\log p_{T-nh-t}(\tilde{Y}_t)-\nabla\log p_{T-nh-t}(\tilde{Y}_0)\rmd t\right\rVert_{\Ltwo}\\
    &\leqslant \dfrac{1}{2}\int_0^h\l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}\rmd t+\int_0^hL(T-nh-t)\l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}\rmd t\\
    &\leqslant \left(\dfrac{1}{2}h+\int_{nh}^{(n+1)h}L(T-t)\rmd t\right)\sup_{0\leqslant t\leqslant h}\l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}.
\end{align*}
We then proceed to derive the upper bound for the term $\sup_{0\leqslant t\leqslant h}\l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}$.
\begin{lemma}
    \label{lem:supYtY0}
    When $p_0$ satisfies Assumption~\ref{asm:p0scLipx}, it holds that
    \begin{align*}
        \sup_{0\leqslant t\leqslant h}\l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}\leqslant &\left(\dfrac{1}{2}h+\int_{nh}^{(n+1)h}L(T-t)\rmd t\right)\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\\
        +&\left(\dfrac{1}{2}h+\int_{nh}^{(n+1)h}L(T-t)\rmd t\right)e^{-\int_0^{nh}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_0-X_T\r|_{\Ltwo}\\
        +&\dfrac{1}{2}h\sup_{0\leqslant t\leqslant T}\l|X_t\r|_{\Ltwo}+\int_{nh}^{(n+1)h}(dL(T-t))^{1/2}\rmd t+\sqrt{dh}.
    \end{align*}
\end{lemma}
Notice that we have no initial limit on the $\tilde{Y}_t$ in Lemma~\ref{lem:supYtY0}, which means that we can use this lemma to any discretization scheme.\\
For the term \text{II} of \eqref{eq:decomp}, we first rely on Assumption~\ref{asm:scLipt} to derive
\begin{align*}
   \rm{II} &=\left\lVert \int_0^h(\nabla\log p_{T-nh-t}(\vartheta_n^{\sf EM})-\nabla\log p_{T-nh}(\vartheta_n^{\sf EM}))\rmd t\right\rVert_{\Ltwo}\\
    &\leqslant \int_0^h\l|\nabla\log p_{T-nh-t}(\vartheta_n^{\sf EM})-\nabla\log p_{T-nh}(\vartheta_n^{\sf EM})\r|_{\Ltwo}\rmd t\\
    &\leqslant h^2M_1(1+\l|\vartheta_n^{\sf EM}\r|_{\Ltwo}).
\end{align*}
Using the triangle inequality and \eqref{eq:Gron2}, we obtain
\begin{equation}
    \begin{aligned}
        \l|\vartheta_n^{\sf EM}\r|_{\Ltwo}\leqslant&\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}+\l|Y_{nh}-X_{nh}^{\leftarrow}\r|_{\Ltwo}+\l|X_{nh}^{\leftarrow}\r|_{\Ltwo}\\
        \leqslant&\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}+e^{-\int_0^{nh}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_0-X_T\r|_{\Ltwo}+\sup_{0\leqslant t\leqslant T}\l|X_t\r|_{\Ltwo}
    \end{aligned}
    \label{eq:hatyn}
\end{equation}
For the term \text{III} of \eqref{eq:decomp}, it follows from Assumption~\ref{asm:scoreerr} that 
\begin{align*}
    \rm{III}=&\left\lVert\int_0^h(\nabla\log p_{T-nh}(\vartheta_n^{\sf EM})-s_*(T-nh,\vartheta_n^{\sf EM}))\rmd t\right\rVert_{\Ltwo}\\
    &\leqslant\int_0^h\l|\nabla\log p_{T-nh}(\vartheta_n^{\sf EM})-s_*(T-nh,\vartheta_n^{\sf EM})\r|_{\Ltwo}\rmd t\\
   &\leqslant h\varepsilon_{sc}.
\end{align*}
Combining these terms above, we obtain that
\begin{equation}
    \begin{aligned}
        \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EM}\r|_{\Ltwo}\leqslant& h^2(C_1(n)^2+M_1)\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\\
        &+h^2\left[C_1(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+M_1\left(1+C_2(n)+C_4\right)\right]\\
        &+h^{3/2}\sqrt{d}C_1(n)\\
        &+h\varepsilon_{sc},
    \end{aligned}
    \label{eq:EM2term}
\end{equation}
where
\begin{align*}
    C_1(n)&=\dfrac{1}{2}+\dfrac{1}{h}\int_{nh}^{(n+1)h}L(T-t)\rmd t,\\
    C_2(n)&=e^{-\int_0^{nh}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_0-X_T\r|_{\Ltwo},\\
    C_3(n)&=\dfrac{1}{h}\int_{nh}^{(n+1)h}(dL(T-t))^{1/2}\rmd t,\\
    C_4&=\sup_{0\leqslant t\leqslant T}\l|X_t\r|_{\Ltwo}.
\end{align*}
This completes the proof of Claim~\ref{item:EMtilde}.

\noindent \textbf{Proof of Claim~\ref{item:EMYt}}. By the triangle inequality, we have
\begin{align}
    \label{eq:EM1}
    \l|Y_{(n+1)h}-\vartheta_{n+1}^{\sf EM}\r|_{\Ltwo}\leqslant \l|Y_{(n+1)h}-\tilde{Y}_{h}\r|_{\Ltwo}+\l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EM}\r|_{\Ltwo}.
\end{align}
Applying \eqref{eq:Gron1} to the first term of \eqref{eq:EM1}, we obtain that
\begin{equation}
    \l|Y_{(n+1)h}-\tilde{Y}_h\r|^2\leqslant e^{-\int_{nh}^{(n+1)h}(2m(T-t)-1)\rmd t}\l|Y_{nh}-\tilde{Y}_0\r|^2.
    \label{eq:err1}
\end{equation}
Notice that $\tilde{Y}_0=\vartheta_n^{\sf EM}$, it then follows that
\begin{align*}
    \l|Y_{(n+1)h}-\tilde{Y}_h\r|_{\Ltwo}\leqslant e^{-\int_{nh}^{(n+1)h}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}.
\end{align*}
Claim~\ref{item:EMYt} follows directly from our previous results and Claim~\ref{item:EMtilde}.
Since this step is independent of the discretization method, it applies to all the schemes discussed in this section. In the following analysis, we omit this step and proceed directly with the proof of the first claim.
\end{proof}

We now proceed to derive the upper bound of the Wasserstein distance between the sample distribution generated after $N$ iterations and the target distribution $p_0$, based on the one-step discretization error bound given by Proposition~\ref{prop:EM}.

First, note that
\begin{align*}
    \wass_2(\law(\vartheta_N^{\sf EM}),p_0)\leqslant \l|\vartheta_N^{\sf EM}-X_0\r|_{\Ltwo}\leqslant\l|Y_{Nh}-\vartheta_N^{\sf EM}\r|_{\Ltwo}+\l|Y_{Nh}-X_0\r|_{\Ltwo}.
\end{align*}
Invoking Proposition~10 of~\cite{gao2023wasserstein}, we have
\begin{align}
    \l|Y_{Nh}-X_0\r|_{\Ltwo}\leq e^{-\int_0^Tm(t)\rmd t}\l|X_0\r|_{\Ltwo}.
    \label{eq:Wassterm1}
\end{align}
According to Proposition~\ref{prop:EM}, by induction, we obtain that
\begin{equation}
    \begin{aligned}
        \l|Y_{Nh}-\vartheta_N^{\sf EM}\r|_{\Ltwo}\leqslant& r_{N-1}^{\sf EM}\l|Y_{(N-1)h}-\vartheta_{N-1}^{\sf EM}\r|_{\Ltwo}+\left(h^2C_{N-1}^{\sf EM}+h^{3/2}\sqrt{d}C_1(N-1)+h\varepsilon_{sc}\right)\\
        \leqslant&\left(\prod_{j=0}^{N-1}r_j^{\sf EM}\right)\l|Y_0-\vartheta_0^{\sf EM}\r|_{\Ltwo}+\sum_{k=0}^{N-1}\left(\prod_{j=k+1}^{N-1}r_j^{\sf EM}\right)\left(h^2C_k^{\sf EM}+h^{3/2}\sqrt{d}C_1(k)+h\varepsilon_{sc}\right)\\
        =&\sum_{k=0}^{N-1}\left(\prod_{j=k+1}^{N-1}r_j^{\sf EM}\right)\left(h^2C_k^{\sf EM}+h^{3/2}\sqrt{d}C_1(k)+h\varepsilon_{sc}\right),
    \end{aligned}
    \label{eq:Wassinduction}
\end{equation}
where we define $\prod_{j=N}^{N-1}r_j^{\sf EM}=1$.
Notice that 
\begin{align*}
    \prod_{j=k+1}^{N-1}r_j^{\sf EM}=&\prod_{j=k+1}^{N-1}(e^{-\int_{jh}^{(j+1)h}(m(T-t)-\frac{1}{2})\rmd t}+h^2(C_1(k)^2+M_1))\\
    \lesssim& \prod_{j=k+1}^{N-1}e^{-h(m_{\min}-\frac{1}{2})}=e^{h(m_{\min}-\frac{1}{2})(N-k-1)}.
\end{align*}
Therefore, we have
\begin{equation}
    \begin{aligned}
        \l|Y_{Nh}-\vartheta_N^{\sf EM}\r|_{\Ltwo}\lesssim& \sum_{k=0}^{N-1}e^{-h(m_{\min}-\frac{1}{2})(N-k-1)}\left(h^2C_k^{\sf EM}+h^{3/2}\sqrt{d}C_1(k)+h\varepsilon_{sc}\right)\\
        \leqslant& \dfrac{1}{1-e^{h(m_{\min}-\frac{1}{2})}}\left(h^2\max_{0\leqslant k\leqslant N-1}C_k^{\sf EM}+h^{3/2}\sqrt{d}\max_{0\leqslant k\leqslant N-1}C_1(k)+h\varepsilon_{sc}\right)\\
        \lesssim&\dfrac{1}{m_{\min}-1/2}\left(\sqrt{dh}\max_{0\leqslant k\leqslant N-1}C_1(k)+\varepsilon_{sc}\right).
    \end{aligned}
    \label{eq:Wassterm2}
\end{equation}
Recall the definition of $C_1(k)$ and the upper bound of $L(t)$, it follows that
\begin{align*}
    \max_{0\leqslant k\leqslant N-1}C_1(k)\leqslant \dfrac{1}{2}+L_{\max},
\end{align*}
and thus we obtain that
\begin{align*}
    \l|Y_{Nh}-\vartheta_N^{\sf EM}\r|_{\Ltwo}\lesssim \sqrt{dh}\cdot\dfrac{L_{\max}+1/2}{m_{\min}-1/2}+\varepsilon_{sc}\cdot\dfrac{1}{m_{\min}-1/2}\,.
\end{align*}
Plugging this back into the previous display then we have
\begin{align*}
    \wass_2(\law(\vartheta_N^{\sf EM}),p_0)\lesssim e^{-\int_0^Tm(t)\rmd t}\l|X_0\r|_{\Ltwo}+\sqrt{dh}\cdot\dfrac{L_{\max}+1/2}{m_{\min}-1/2}+\varepsilon_{sc}\cdot \dfrac{1}{m_{\min}-1/2}\,,
\end{align*}
which completes the proof of Theorem~\ref{thm:EM}.


\subsection{Proof of Theorem~\ref{thm:EI}}
This part aims to prove the Wasserstein convergence result for the Exponential Integrator (EI) scheme. 
We will prove this theorem using the same method as in Theorem~\ref{thm:EM}. Following this approach, we first establish the one-step discretization error in the proposition below.
\begin{proposition}
    \label{prop:EI}
    Suppose that Assumption~\ref{asm:p0scLipx},~\ref{asm:scoreerr} and~\ref{asm:scLipt} hold, then one-step discretization error for Exponential Integrator scheme is obtained from the following two bounds.
    \begin{enumerate}[label=\textbf{(\arabic*)},leftmargin=2em]
        \item \label{item:EItilde} It holds that
        \begin{align*}
            \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EI}\r|_{\Ltwo}\leqslant&h^2\left(C_5(n)C_1(n)+M_1\dfrac{2(e^{h/2}-1)}{h}\right)\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\\
            &+h^2\left[C_5(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+\dfrac{2(e^{h/2}-1)}{h}M_1(1+C_2(n)+C_4)\right]\\
            &+h^{3/2}\sqrt{d}C_5(n)\\
            &+h\cdot\dfrac{2(e^{h/2}-1)}{h}\varepsilon_{sc},
        \end{align*}
        where
        \begin{align*}
            C_5(n)=\dfrac{1}{h}\int_{nh}^{(n+1)h}e^{\frac{1}{2}((n+1)h-t)}L(T-t)\rmd t\approx C_1(n)-\dfrac{1}{2}\,.
        \end{align*}
        \item \label{item:EIYt} Therefore, we have the bound for one-step discretization error
        \begin{align*}
            \l|Y_{(n+1)h}-\vartheta_{n+1}^{\sf EI}\r|_{\Ltwo}\leqslant r_n^{\sf EI}\l|Y_{nh}-\vartheta_n^{\sf EI}\r|_{\Ltwo}+h^2C_n^{\sf EI}+h^{3/2}\sqrt{d}C_5(n)+h\cdot\dfrac{2(e^{h/2}-1)}{h}\varepsilon_{sc},
        \end{align*}
        where
        \begin{align*}
            r_n^{\sf EI}=&e^{-\int_{nh}^{(n+1)h}(m(T-t)-\frac{1}{2})\rmd t}+h^2\left(C_5(n)C_1(n)+M_1\dfrac{2(e^{h/2}-1)}{h}\right),\\
            C_n^{\sf EI}=&C_5(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+\dfrac{2(e^{h/2}-1)}{h}M_1(1+C_2(n)+C_4).
        \end{align*}
    \end{enumerate}
Here, the constants $C_i,i=1,2,3,4$ are as defined in Proposition~\ref{prop:EM}.
\end{proposition}
\begin{proof}
We prove two claims in succession.\\
\textbf{Proof of Claim~\ref{item:EItilde}.} Consider the process defined in \eqref{eq:tildeY}, which satisfies the SDE  
\begin{align*}
    \rmd\tilde{Y}_t=\left[\dfrac{1}{2}\tilde{Y}_t+\nabla\log p_{T-nh-t}(\tilde{Y}_t)\right]\rmd t+\rmd W_t,
\end{align*}
Instead of integrating both sides of the SDE, we use \text{It\^o}'s formula to $e^{-\frac{t}{2}}\tilde Y_t$, then we have
\begin{align*}
    \rmd (e^{-\frac{t}{2}}\tilde Y_t)=-\dfrac{1}{2}e^{-\frac{t}{2}}\tilde Y_t+e^{-\frac{t}{2}}\rmd \tilde Y_t=e^{-\frac{t}{2}}\left(\nabla\log p_{T-nh-t}(\tilde Y_t)\rmd t+\rmd W_t\right),
\end{align*}
and we notice that we can write it in an integral form.  
\begin{align*}
    \tilde{Y}_t=e^{t/2}\tilde{Y}_0+\int_0^te^{\frac{1}{2}(t-s)}\nabla\log p_{T-nh-s}(\tilde{Y}_{s})\rmd s+\int_{nh}^{nh+t}e^{\frac{1}{2}((n+1)h-s)}\rmd W_s.
\end{align*}  
Then we obtain that
\begin{align*}
    \tilde{Y}_h-\vartheta_{n+1}^{\sf EI}=\int_0^he^{\frac{1}{2}(h-t)}(\nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf EI}))\rmd t.
\end{align*}
We make decomposition the same as the one in \eqref{eq:decomp}, that is
\begin{align*}
    \nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf EI})
    &= \nabla\log p_{T-nh-t}(\tilde{Y}_t)-\nabla\log p_{T-nh-t}(\tilde{Y}_0)\\
    & \quad +\nabla\log p_{T-nh-t}(\vartheta_n^{\sf EI})-\nabla\log p_{T-nh}(\vartheta_n^{\sf EI})\\
    & \quad +\nabla\log p_{T-nh}(\vartheta_n^{\sf EI})-s_*(T-nh,\vartheta_n^{\sf EI}).
\end{align*}
It then follows that
\begin{align*}
    \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EI}\r|_{\Ltwo}\leqslant& \int_0^he^{\frac{1}{2}(h-t)}\l|\nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf EI})\r|_{\Ltwo}\rmd t\\
    \leqslant& \int_0^he^{\frac{1}{2}(h-t)}\l|\nabla\log p_{T-nh-t}(\tilde{Y}_t)-\nabla\log p_{T-nh-t}(\tilde{Y}_0)\r|_{\Ltwo}\rmd t\\
    &+\int_0^he^{\frac{1}{2}(h-t)}\l|\nabla\log p_{T-nh-t}(\vartheta_n^{\sf EI})-\nabla\log p_{T-nh}(\vartheta_n^{\sf EI})\r|_{\Ltwo}\rmd t\\
    &+\int_0^he^{\frac{1}{2}(h-t)}\l|\nabla\log p_{T-nh}(\vartheta_n^{\sf EI})-s_*(T-nh,\vartheta_n^{\sf EI})\r|_{\Ltwo}\rmd t.
\end{align*}
Note that apart from the exponential term $e^{\frac{1}{2}(h-t)}$, the derivation of the remaining parts is completely consistent with that of \eqref{eq:decomp}, until we encounter the term involving $\vartheta_n^{\sf EI}$, at which point we obtain
\begin{align*}
    \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EI}\r|_{\Ltwo}\leqslant& \left(\int_0^he^{\frac{1}{2}(h-t)}L(T-nh-t)\rmd t\right)\sup_{0\leqslant t\leqslant h}\l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}\\
    &+ \left(\int_0^he^{\frac{1}{2}(h-t)}\rmd t\right)M_1h\Big(1+\l|\vartheta_n^{\sf EI}\r|_{\Ltwo}\Big)\\
    &+ \left(\int_0^he^{\frac{1}{2}(h-t)}\rmd t\right)\varepsilon_{sc}.
\end{align*}
By Lemma~\ref{lem:supYtY0}, we can bound the first term on the right-hand side of the previous display.
Moreover, from~\eqref{eq:hatyn}, $\l|\vartheta_n^{\sf EI}\r|_{\Ltwo}$ 
can be bounded similarly. Substituting all coefficients with $C_i(n)$ from Proposition~\ref{prop:EM}, we obtain
\begin{align*}
    \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf EI}\r|_{\Ltwo}\leqslant & h^2\cdot C_5(n)\left[ C_1(n)\l|Y_{nh}-\vartheta_n^{\sf EI}\r|_{\Ltwo}+C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right]\\
    &+h^2\cdot \dfrac{2(e^{h/2}-1)}{h}M_1\left[1+\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}+C_2(n)+C_4\right]\\
    &+h^{3/2}\sqrt{d}C_5(n)\\
    &+h\cdot\dfrac{2(e^{h/2}-1)}{h}\varepsilon_{sc}\\
    =&h^2\left(C_5(n)C_1(n)+M_1\dfrac{2(e^{h/2}-1)}{h}\right)\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\\
    &+h^2\left[C_5(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+\dfrac{2(e^{h/2}-1)}{h}M_1(1+C_2(n)+C_4)\right]\\
    &+h^{3/2}\sqrt{d}C_5(n)\\
    &+h\cdot\dfrac{2(e^{h/2}-1)}{h}\varepsilon_{sc},
\end{align*}
where
\begin{align*}
    C_5(n)=\dfrac{1}{h}\int_{nh}^{(n+1)h}e^{\frac{1}{2}((n+1)h-t)}L(T-t)\rmd t\approx C_1(n)-\dfrac{1}{2}.
\end{align*} 

\noindent\textbf{Proof of Claim~\ref{item:EIYt}.} The proof is omitted for brevity, as it merely requires incorporating $\l|Y_{(n+1)h}-\tilde Y_h\r|_{\Ltwo}$ into the conclusion of Claim~\ref{item:EItilde}, following a similar argument as in the proof of Claim~\ref{item:EMYt} in Proposition~\ref{prop:EM}.

\end{proof}

For the proof of Theorem~\ref{thm:EI}, recall that in the proof of Theorem~\ref{thm:EM}, the three key steps~\eqref{eq:Wassterm1},~\eqref{eq:Wassinduction} and~\eqref{eq:Wassterm2} lead to the desired result. 
We now revisit these steps within the framework of other discretization schemes.

Since \eqref{eq:Wassterm1} is independent of the discretization scheme, we can directly apply it throughout the proofs of Theorems~\ref{thm:EI},~\ref{thm:RMPEM},~\ref{thm:RMPEI} and~\ref{thm:2order}. 
For \eqref{eq:Wassinduction}, we note that the $h^2$ term in $r_j^{\alpha}$ is neglected, which results in the same upper bound for $\prod_{j=k+1}^{N-1}r_j^{\alpha}$ across all discretization schemes.


Given the consistency of these two steps, for the remaining discretization schemes, we can directly derive an analogue of \eqref{eq:Wassterm2} from Claim~\ref{item:EIYt}. Therefore, in the subsequent proofs of these theorems, after establishing the corresponding proposition, we proceed directly from an expression similar to \eqref{eq:Wassterm2}.


For this theorem, we begin the proof with the following inequality
\begin{align*}
    \l|Y_{Nh}-\vartheta_N^{\sf EI}\r|_{\Ltwo}
    &\lesssim \dfrac{1}{m_{\min}-1/2}\left(hC_n^{\sf EI}+h^{1/2}\sqrt{d}\max_{0\leqslant k\leqslant N-1}C_5(k)+\varepsilon_{sc}\right)\\
    &\lesssim \dfrac{1}{m_{\min}-1/2}\left(\sqrt{dh}\max_{0\leqslant k\leqslant N-1}C_5(k)+\varepsilon_{sc}\right)\\
    &\leqslant \sqrt{dh}\cdot\dfrac{L_{\max}}{m_{\min}-1/2}+\varepsilon_{sc}\cdot\dfrac{1}{m_{\min}-1/2}.
\end{align*}
Combining this with the bound of $\l|X_0-Y_{Nh}\r|_{\Ltwo}$, we obtain
\begin{align*}
    \wass_2(\law(\vartheta_N^{\sf EI}),p_0)\lesssim e^{-m_{\min}T}\l|X_0\r|_{\Ltwo}+\sqrt{dh}\cdot\dfrac{L_{\max}}{m_{\min}-1/2}+\varepsilon_{sc}\cdot\dfrac{1}{m_{\min}-1/2}
\end{align*}
as desired.

\subsection{Proof of Theorem~\ref{thm:RMPEM}}
\label{app:REM}
In this section, we prove the Wasserstein distance between the generated distribution~$\law(\vartheta_N^{\sf REM})$ and the target distribution.
The following proposition is established for the one-step discretization error.
\begin{proposition}
    \label{prop:RMPEM}
    Suppose that Assumptions~\ref{asm:p0scLipx},~\ref{asm:scLipt} and~\ref{asm:score4RMP} are satisfied, the following two claims hold.
    \begin{enumerate}[label=\textbf{(\arabic*)}, leftmargin=2em]
        \item \label{item:REMtilde}
       It holds that
        \begin{align*}
            &\quad\l|\tilde{Y}_h-\vartheta_{n+1}^{\sf REM}\r|_{\Ltwo}\\
            &\leqslant h^2\Bigg\{\left[\int_0^1\int_0^1\left[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\right]^2\rmd u\rmd v\right]^{1/2}\\
            &\qquad\qquad+\dfrac{1}{4\sqrt{3}}L(T-nh)+\dfrac{1}{8\sqrt{3}}\Bigg\}\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
            &\quad+h^2\Bigg\{\bigg\{\int_0^1\int_0^1\bigg\{(u-v)\left[\left(\dfrac{1}{2}+L(T-nh)\right)C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]L(T-(n+u)h)\\
            &\qquad\qquad+M_1(1+C_2(n)+C_4)\bigg\}^2\rmd u\rmd v\bigg\}^{1/2}\\
            &\qquad \quad+\dfrac{1}{8\sqrt{3}}(C_2(n)+C_4)+\dfrac{1}{4\sqrt{3}}\left(L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right)\Bigg\}\\
            &\quad +h^{3/2}\Bigg\{\sqrt{d}\left[\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd  v\right]^{1/2}+\dfrac{1}{2\sqrt{3}}\Bigg\}\\
            &\quad +2h\varepsilon_{sc}.
        \end{align*}
        \item \label{item:REMYt}
       Moreover, it holds that
        \begin{align*}
            \l|Y_{(n+1)h}-\vartheta_{n+1}^{\sf REM}\r|\leqslant r_n^{\sf REM}\l|Y_{nh}-\vartheta_n\r|_{\Ltwo}+h^2C_{n,1}^{\sf REM}+h^{3/2}C_{n,2}^{\sf REM}+3h\varepsilon_{sc},
        \end{align*}
        where
        \begin{align*}
            r_n^{\sf REM}&=e^{-\int_{nh}^{(n+1)h}(m(T-t)-\frac{1}{2})\rmd t}\\
            &\quad +h^2\Bigg\{\left[\int_0^1\int_0^1\left[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\right]^2\rmd u\rmd v\right]^{1/2}\\
            &\qquad\qquad+\dfrac{1}{4\sqrt{3}}L(T-nh)+\dfrac{1}{8\sqrt{3}}\Bigg\},\\
            C_{n,1}^{\sf REM}=&\bigg\{\int_0^1\int_0^1\bigg\{(u-v)\left[\left(\dfrac{1}{2}+L(T-nh)\right)C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]L(T-(n+u)h)\\
            &\qquad\qquad\quad+M_1(1+C_2(n)+C_4)\bigg\}^2\rmd u\rmd v\bigg\}^{1/2}\\
            &\quad+\dfrac{1}{8\sqrt{3}}(C_2(n)+C_4)+\dfrac{1}{4\sqrt{3}}\left(L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right)\\
            C_{n,2}^{\sf REM}=&\sqrt{d}\left[\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd v\right]^{1/2}+\dfrac{1}{2\sqrt{3}}.
        \end{align*}
    \end{enumerate}
\end{proposition}


\begin{proof}[Proof of Proposition~\ref{prop:RMPEM}]\\
\noindent \textbf{Proof of Claim~\ref{item:REMtilde}.} We make the following decomposition of one-step discretization error
\begin{align}
    \label{eq:REMdecom}
    \l|\tilde{Y}_{h}-\vartheta_{n+1}^{\sf REM}\r|_{\Ltwo}\leqslant\l|\tilde{Y}_h-\mathbb{E}_{U_n}\big[\vartheta_{n+1}^{\sf REM}\big]\r|_{\Ltwo}+\l|\mathbb{E}_{U_n}\big[\vartheta_{n+1}^{\sf REM}\big]-\vartheta_{n+1}^{\sf REM}\r|_{\Ltwo}.
\end{align}

We first derive the upper bound for the term~$\l|\tilde{Y}_h-\mathbb{E}_{U_n}\big[\vartheta_{n+1}^{\sf REM}\big]\r|_{\Ltwo}$. 
By the definitions of $\vartheta_n^{\sf REM}$ and $\tilde Y_h,$ we have
\begin{align*}
    &\l|\tilde{Y}_{h}-\mathbb{E}_{U_n}\big[\vartheta_{n+1}^{\sf REM}\big]\r|_{\Ltwo}\\
    =&\left\lVert \dfrac{1}{2}\int_0^h\tilde{Y}_t\rmd t+\int_0^h\nabla\log p_{T-nh-t}(\tilde{Y}_t)\rmd t-\dfrac{1}{2}h\mathbb{E}_{U_n}(\vartheta_{n+U}^{\sf REM})-h\mathbb{E}_{U_n}[s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM}])\right\rVert_{\Ltwo}\,.
\end{align*}
Notice that 
\begin{align*}
\int_0^h\tilde{Y}_t\rmd t = h\mathbb{E}_{U_n}[\tilde{Y}_{U_nh}],\qquad \int_0^h\nabla\log p_{T-nh-t}(\tilde{Y}_t)\rmd t= h\mathbb{E}_{U_n}[\nabla\log p_{T-(n+U_n)h}(\tilde{Y}_{U_nh})]\,.
\end{align*}
Plugging this back into the previous display then gives
\begin{align*}
 &\l|\tilde{Y}_{h}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REM}]\r|_{\Ltwo}\\
 =&\,\,\left\lVert \dfrac{1}{2}h\mathbb{E}_{U_n}[\tilde{Y}_{U_nh}]+h\mathbb{E}_{U_n}[\nabla\log p_{T-(n+U_n)h}(\tilde{Y}_{U_nh})]-\dfrac{1}{2}h\mathbb{E}_{U_n}(\vartheta_{n+U}^{\sf REM})-h\mathbb{E}_{U_n}(s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM}))\right\rVert_{\Ltwo}\\
    \leqslant&\,\,\dfrac{1}{2}h\left\lVert\mathbb{E}_{U_n}[\tilde{Y}_{U_nh}-\vartheta_{n+U_n}^{\sf REM}]\right\rVert_{\Ltwo}+h\left\lVert\mathbb{E}_{U_n}[\nabla\log p_{T-(n+U_n)h}(\tilde{Y}_{U_nh})-s_*(T-(n+U_n)h,\vartheta_{n+U_n}^{\sf REM})]\right\rVert_{\Ltwo}.
\end{align*}
By the definition of $\tilde{Y}_{U_nh}$ and $\vartheta_{n+U_n}^{\sf REM}$, we have
\begin{align*}
    &\left\lVert \mathbb{E}_{U_n}[\tilde{Y}_{U_nh}-\vartheta_{n+U_n}^{\sf REM}]\right\rVert_{\Ltwo}\\
    =&\,\,\left\lVert\mathbb{E}_{U_n}\left[ \dfrac{1}{2}\int_0^{U_nh}(\tilde{Y}_t-\vartheta_n^{\sf REM})\rmd t+\int_0^{U_nh}(\nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf REM}))\rmd t\right]\right\rVert_{\Ltwo}\\
    \leqslant &\,\, \left\lVert\mathbb{E}_{U_n}\left[ \dfrac{1}{2}\int_0^{U_nh}\l|\tilde{Y}_t-\vartheta_n^{\sf REM}\r|\rmd t+\int_0^{U_nh}\l|\nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf REM})\r|\rmd t\right]\right\rVert_{\Ltwo}\\
    \leqslant &\,\,\left\lVert\mathbb{E}_{U_n}\left[\dfrac{1}{2}\int_0^{h}\l|\tilde{Y}_t-\vartheta_n^{\sf REM}\r|\rmd t+\int_0^h\l|\nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf REM})\r|\rmd t\right]\right\rVert_{\Ltwo}\\
    \leqslant &\,\,\dfrac{1}{2}\int_0^h\l|\tilde{Y}_t-\vartheta_n^{\sf REM}\r|_{\Ltwo}\rmd t+\int_0^h\l|\nabla\log p_{T-nh-t}(\tilde{Y}_t)-s_*(T-nh,\vartheta_n^{\sf REM})\r|_{\Ltwo}\rmd t.
\end{align*}
The second inequality arises because the integrand is non-negative, the last inequality follows from the fact that the random variables inside the inner expectation $\mathbb{E}_{U_n}$ are independent of $U_n$, and thus the inner expectation can be ignored. Then using the same argument as in the proof of Proposition~\ref{prop:EM}, especially adopting the same procedure as the one following \eqref{eq:decomp}, we can apply the conclusion of Proposition~\ref{prop:EM} to the term above, then we obtain that
\begin{align*}
    \l|\mathbb{E}_{U_n}\big[\tilde{Y}_{U_nh}-\vartheta_{n+U_n}^{\sf REM}\big]\r|_{\Ltwo}
    &\leqslant \left(\dfrac{1}{2}h+\int_{nh}^{(n+1)h}L(T-t)\rmd t\right)\sup_{0\leqslant t\leqslant h}\l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}\\
    & \quad +\int_{nh}^{(n+1)h}\l|\nabla\log p_{T-nh-t}(\vartheta_n^{\sf REM})-s_*(T-nh,\vartheta_n^{\sf REM})\r|_{\Ltwo}\rmd t\\
   & \leqslant h^2(C_1(n)^2+M_1)\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &\quad +h^2\left[C_1(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+M_1(1+C_2(n)+C_4)\right]\\
    &\quad +h^{3/2}\sqrt{d}C_1(n)\\
    &\quad +h\varepsilon_{sc}\\
    &\mathop{=}^{\triangle}h^2r_1\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}+h^2r_2+h^{3/2}\sqrt{d}C_1(n)+h\varepsilon_{sc},
\end{align*}
where
\begin{align*}
    r_1=&C_1(n)^2+M_1,\\
    r_2=&C_1(n)\left(C_1(n)C_2(n)+\dfrac{1}{2}C_4+C_3(n)\right)+M_1(1+C_2(n)+C_4).
\end{align*}
We now derive the upper bound of the second term in \eqref{eq:REMdecom}.
Note that
\begin{align}
    &\left\lVert\mathbb{E}_{U_n}\big[\nabla\log p_{T-(n+U_n)h}(\tilde{Y}_{(n+U_n)h})-s_*(T-(n+U_n)h,\vartheta_{n+U_n}^{\sf REM})\big]\right\rVert_{\Ltwo}\\
    = & \,\,\left\lVert \int_0^1\Big(\nabla\log p_{T-(n+u)h}(\tilde{Y}_{(n+u)h})-s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM}) \Big)\rmd u \right\rVert_{\Ltwo}\\
    \leqslant &\int_0^1\left\lVert \nabla\log p_{T-(n+u)h}(\tilde{Y}_{(n+u)h})-s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM})\right\rVert_{\Ltwo}\rmd u\\
    \leqslant &\int_0^1\Bigg(\l|\nabla\log p_{T-(n+u)h}(\tilde{Y}_{(n+u)h})-\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REM})\r|_{\Ltwo}\\
    &\quad\qquad+\l|\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REM})-s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM})\r|_{\Ltwo}\Bigg)\rmd u\\
    \leqslant &\int_0^1L(T-(n+u)h)\l|\tilde{Y}_{(n+u)h}-\vartheta_{n+u}^{\sf REM}\r|_{\Ltwo}\rmd u+\varepsilon_{sc},
\label{eq:help2}
\end{align}
the second inequality follows from the triangle inequality, and the last inequality depends on Assumption~\ref{asm:p0scLipx} and~\ref{asm:score4RMP}. By \eqref{eq:EM2term}, changing the value of $h$ to $uh$, we have
\begin{align}
    \l|\tilde{Y}_{(n+u)h}-\vartheta_{n+u}^{\sf REM}\r|_{\Ltwo}
    &\leqslant (uh)^2(C_{1,n}(u)^2+M_1)\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &\quad +(uh)^2\left[C_{1,n}(u)\left(C_{1,n}(u)C_2(n)+\dfrac{1}{2}C_4+C_{3,n}(u)\right)+M_1(1+C_2(n)+C_4)\right]\\
    &\quad +(uh)^{3/2}\sqrt{d}C_{1,n}(u)\\
    &\quad+ uh\varepsilon_{sc},
    \label{eq:help1}
\end{align}
where $C_{1,n}(u)$ and $C_{3,n}(u)$ is the $uh$-version of $C_1(n)$ and $C_3(n)$, respectively, that is
\begin{align*}
    C_{1,n}(u)=&\dfrac{1}{2}+\dfrac{1}{uh}\int_{nh}^{(n+u)h}L(T-t)\rmd t,\\
    C_{3,n}(u)=&\dfrac{1}{uh}\int_{nh}^{(n+u)h}(dL(T-t))^{1/2}\rmd t,
\end{align*}
Plugging the previous display~\eqref{eq:help1} back into display~\eqref{eq:help2}, then rearranging and simplifying the expression, yields
\begin{align*}
    &\left\lVert\mathbb{E}_{U_n}[\nabla\log p_{T-(n+U_n)h}(\tilde{Y}_{(n+U_n)h})-s_*(T-(n+U_n)h,\vartheta_{n+U_n}^{\sf REM})]\right\rVert_{\Ltwo}\\
   & \leqslant h^2\left(\int_0^1L(T-(n+u)h)u^2(C_{1,n}(u)^2+M_1)\rmd u\right)\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\\
    &\quad +h^2\left\{\int_0^1L(T-(n+u)h)u^2\left[C_{1,n}(u)\left(C_{1,n}(u)C_2(n)+\dfrac{1}{2}C_4+C_{3,n}(u)\right)+M_1(1+C_2(n)+C_4)\right]\rmd u\right\}\\
    &\quad +h^{3/2}\left(\int_0^1L(T-(n+u)h)u^{3/2}\rmd u\right)\sqrt{d}C_1(n)\\
    &\quad +h\left(\int_0^1L(T-(n+u)h)u\rmd u\right)\varepsilon_{sc}\\
    &\quad +\varepsilon_{sc}\\
    & \mathop{=}^{\triangle}h^2r_3\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}+h^2r_4+h^{3/2}r_5+hr_6\varepsilon_{sc}+\varepsilon_{sc},
\end{align*}
where
\begin{align*}
    r_3&=\int_0^1L(T-(n+u)h)u^2(C_{1,n}(u)^2+M_1)\rmd u,\\
    r_4&=\int_0^1L(T-(n+u)h)u^2\left[C_{1,n}(u)\left(C_{1,n}(u)C_2(n)+\dfrac{1}{2}C_4+C_{3,n}(u)\right)\right]\rmd u+M_1(1+C_2(n)+C_4),\\
    r_5&=\left(\int_0^1L(T-(n+u)h)u^{3/2}\rmd u\right)\sqrt{d}C_1(n),\\
    r_6&=\int_0^1L(T-(n+u)h)u\rmd u.
\end{align*}
From the bounds we have obtained for two terms, it follows that
\begin{align*}
    &\l|\tilde{Y}_{h}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REM}]\r|_{\Ltwo}\\
    \leqslant& \,h^3(\dfrac{1}{2}r_1+r_3)\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}+h^3(\dfrac{1}{2}r_2+r_4)+h^{5/2}(\dfrac{1}{2}\sqrt{d}C_1(n)+r_5)+h^2(\dfrac{1}{2}+r_6)\varepsilon_{sc}+h\varepsilon_{sc}.
\end{align*}
Considering the second term of one-step discretization error
\begin{equation}
    \begin{aligned}
        &\vartheta_{n+1}^{\sf REM}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REM}]\\
        =&\,\dfrac{1}{2}h\left[\vartheta_{n+U}^{\sf REM}-\mathbb{E}_{U_n}[\vartheta_{n+U}^{\sf REM}]\right]+h\left[s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM})-\mathbb{E}_{U_n}[s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM})]\right]\\
        =&\,\dfrac{1}{2}h\left[\dfrac{1}{2}h(U_n-\dfrac{1}{2})\vartheta_n^{\sf REM}+h(U_n-\dfrac{1}{2})s_*(T-nh,\vartheta_n^{\sf REM})\right]\\
        &+\dfrac{1}{2}h\left[\int_{nh}^{(n+U_n)h}\rmd W_t-\int_0^1\left(\int_{nh}^{(n+u)h}\rmd W_t\right)\rmd u\right]\\
        &+h\left[s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM})-\mathbb{E}_{U_n}[s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM})]\right].
    \end{aligned}
    \label{eq:REMdecom2}
\end{equation}
The second equality follows from the fact that
\begin{align*}
    \mathbb{E}_{U_n}[\vartheta_{n+U}^{\sf REM}]&=\vartheta_n^{\sf REM}+\dfrac{1}{2}h\mathbb{E}_{U_n}[U_n]\vartheta_n^{\sf REM}+h\mathbb{E}_{U_n}[U_n]s_*(T-nh,\vartheta_n^{\sf REM})+\mathbb{E}_{U_n}\int_{nh}^{(n+U_n)h}\rmd W_t\\
    &=\vartheta_n^{\sf REM}+\dfrac{1}{4}h\vartheta_n^{\sf REM}+\dfrac{1}{2}hs_*(T-nh,\vartheta_n^{\sf REM})+\int_0^1\left(\int_{nh}^{(n+u)h}\rmd W_t\right)\rmd u,
\end{align*}
since $U_n$ is independent of $\vartheta_n^{\sf REM}$.\\
We proceed to bound each term in \eqref{eq:REMdecom2}. For the first term, still notice that the independence between $U_n$ and $\vartheta_n^{\sf REM}$, then we find that
\begin{align*}
    \l|(U_n-\dfrac{1}{2})\vartheta_n^{\sf REM}\r|_{\Ltwo}&=\bigg\{\mathbb{E}\left[\mathbb{E}_{U_n}\left\lVert (U_n-\dfrac{1}{2})\vartheta_n^{\sf REM}\right\rVert^2\right]\bigg\}^{1/2}\\
    &=\bigg\{\mathbb{E}\left[\mathbb{E}_{U_n}[(U_n-\dfrac{1}{2})^2]\cdot\left\lVert\vartheta_n^{\sf REM}\right\rVert^2\right]\bigg\}^{1/2}\\
    &=\bigg\{\mathbb{E}\left[\dfrac{1}{12}\l|\vartheta_n^{\sf REM}\r|^2\right]\bigg\}^{1/2}\\
    &=\dfrac{1}{2\sqrt{3}}\l|\vartheta_n^{\sf REM}\r|_{\Ltwo}.
\end{align*}
The bounding of another part of the first term follows in a similar manner, we obtain that 
\begin{align*}
    \l|(U_n-\dfrac{1}{2})s_*(T-nh,\vartheta_n^{\sf REM})\r|_{\Ltwo}=\dfrac{1}{2\sqrt{3}}\l|s_*(T-nh,\vartheta_n^{\sf REM})\r|_{\Ltwo}.
\end{align*}
For the second term of \eqref{eq:REMdecom2}, notice that due to It\^o's isometry formula, for any well-defined stochastic process $X_t$ and its It\^o stochastic integral $I_t(X)=\int_0^tX_u\rmd M_u$, we have
\begin{align}
    \label{eq:Itoiso}
    \mathbb{E}[I_t(X)^2]=\mathbb{E}\int_0^tX_u^2\rmd\langle M \rangle_u,
\end{align}
then we can establish a lemma.
\begin{lemma}
    \label{lem:Brown1}
    Suppose $W_t$ is a $d$-dim standard Brownian motion, then
    \begin{align*}
        \left\lVert\int_{nh}^{(n+U_n)h}\rmd W_t-\int_0^1\left(\int_{nh}^{(n+u)h}\rmd W_t\right)\rmd u\right\rVert_{\Ltwo}^2\leqslant\dfrac{h}{3}.
    \end{align*}
\end{lemma}
For the third term of \eqref{eq:REMdecom2},  we get
\begin{align*}
    &\left\lVert s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM})-\mathbb{E}_{U_n}[s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM})]\right\rVert_{\Ltwo}\\
    = &\,\left\lVert \int_0^1 s_*(T-(n+U_n)h,\vartheta_{n+U}^{\sf REM})-s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REM})\rmd v\right\rVert_{\Ltwo} \\
    = &\,\bigg\{\mathbb{E}\int_0^1\left[\int_0^1s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM})-s_*(T-(n+v)h,y_{(n+v)h}^{})\rmd v\right]^2\rmd u\bigg\}^{1/2}\\
    \leqslant &\,\bigg\{\mathbb{E}\int_0^1\int_0^1 \left[s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM})-s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REM})\right]^2\rmd u\rmd v\bigg\}^{1/2}\\
    = &\,\bigg\{\int_0^1\int_0^1\left\lVert s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM})-s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}^2\rmd u\rmd v\bigg\}^{1/2}.
\end{align*}
Then by the triangle inequality and Assumption~\ref{asm:score4RMP}, we have
\begin{equation}
    \begin{aligned}
        &\left\lVert s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM})-s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}\\
        \leqslant&\,\left\lVert s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REM})-\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REM})\right\rVert_{\Ltwo}\\
        &+\left\lVert s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REM})-\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}\\
        &+\left\lVert\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REM})-\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}\\
        \leqslant& \,2\varepsilon_{sc}+\left\lVert\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REM})-\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}.
    \end{aligned}
    \label{eq:diffmatch}
\end{equation}
Combining the three terms of \eqref{eq:REMdecom2} together, we have
\begin{align*}
    \l|\vartheta_{n+1}^{\sf REM}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REM}]\r|_{\Ltwo}
   & \leqslant \dfrac{1}{8\sqrt{3}}h^2\l|\vartheta_n^{\sf REM}\r|_{\Ltwo}+\dfrac{1}{4\sqrt{3}}h^2\l|s_*(T-nh,\vartheta_n^{\sf REM})\r|_{\Ltwo}+\dfrac{1}{2\sqrt{3}}h^{3/2}\\
    &\quad +h\bigg\{\int_0^1\int_0^1\left\lVert \nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REM})-\nabla\log p_{T-(n+u)h}(\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}^2\rmd u\rmd v\bigg\}^{1/2}\\
    &\quad +2h\varepsilon_{sc}.
\end{align*}
By applying the same technique used in the proofs of Proposition~\ref{prop:EM} and Proposition~\ref{prop:EI}, the upper bounds for $\l|\vartheta_n^{\sf REM}\r|_{\Ltwo}$ and $\l|s_*(T-nh,\vartheta_n^{\sf REM})\r|_{\Ltwo}$ follows readily. Thus, the proposition follows immediately from the bound on the second last term. 
We now consider the case for $u>v$, due to Assumptions~\ref{asm:p0scLipx} and~\ref{asm:scLipt},
\begin{align*}
    &\left\lVert\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REM})-\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}\\
    \leqslant &\,\, L(T-(n+u)h)\l|\vartheta_{n+u}^{\sf REM}-\vartheta_{n+v}^{\sf REM}\r|_{\Ltwo}+M_1h\Big(1+\l|\vartheta_{n+v}^{\sf REM}\r|_{\Ltwo}\Big).
\end{align*}
Since
\begin{align*}
    \l|\vartheta_{n+u}^{\sf REM}-\vartheta_{n+v}^{\sf REM}\r|_{\Ltwo}
    &\leqslant \dfrac{1}{2}(u-v)h\l|\vartheta_n^{\sf REM}\r|_{\Ltwo}+(u-v)h\l|s_*(T-nh,\vartheta_{n}^{\sf REM})\r|_{\Ltwo}+\left\lVert\int_{(n+v)h}^{(n+u)h}\rmd W_t\right\rVert_{\Ltwo}\\
    & \leqslant  \dfrac{1}{2}(u-v)h\left(\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}+C_2(n)+C_4\right)\\
    &\quad  +(u-v)h\left[\varepsilon_{sc}+L(T-nh)\left(\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}+C_2(n)\right)+(dL(T-nh))^{1/2}\right]\\
    &\quad +\sqrt{(u-v)h}\\
    &\leqslant  (u-v)h\left[\dfrac{1}{2}+L(T-nh)\right]\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &\quad +(u-v)h\left[(\dfrac{1}{2}+L(T-nh))C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]\\
    &\quad +\sqrt{(u-v)dh}+(u-v)h\varepsilon_{sc}.
\end{align*}
The second inequality follows from \eqref{eq:hatyn}, Assumptions~\ref{asm:p0scLipx},~\ref{asm:scoreerr} and Lemma~\ref{lem:Enabla}. Similarly,
\begin{align*}
    \l|\vartheta_{n+v}^{\sf REM}\r|_{\Ltwo}
    &\leqslant \l|\vartheta_{n+v}^{\sf REM}-\vartheta_{n}^{\sf REM}\r|_{\Ltwo}+\l|\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &\leqslant vh\left[\dfrac{1}{2}+L(T-nh)\right]\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &\quad +vh\left[(\dfrac{1}{2}+L(T-nh))C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]\\
    &\quad +\sqrt{vdh}+vh\varepsilon_{sc}\\
    &\quad +\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}+C_2(n)+C_4.
\end{align*}
Therefore, we obtain that
\begin{align*}
    &\left\lVert \nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REM})-\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}\\
    \leqslant & h\bigg\{(u-v)\left[\dfrac{1}{2}+L(T-nh)\right]L(T-(n+u)h)+M_1\bigg\}\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &+h^2M_1v\left[\dfrac{1}{2}+L(T-nh)\right]\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &+h^2vM_1\left[\left(\dfrac{1}{2}+L(T-nh)\right)C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]\\
    &+h^{3/2}M_1\sqrt{vd}\\
    &+h\bigg\{(u-v)\left[\left(\dfrac{1}{2}+L(T-nh)\right)C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]L(T-(n+u)h)\\
    &\qquad+M_1(1+C_2(n)+C_4)\bigg\}\\
    &+h^{1/2}L(T-(n+u)h)\sqrt{(u-v)d}\\
    &+h(u-v)L(T-(n+u)h)\varepsilon_{sc}+h^2M_1v\varepsilon_{sc}.
\end{align*}
We claim that we only consider the lowest order of each part, which means the relative higher order term with the combination of $d$ and $h$ will be ignored. Then take the supremum with respect to $v$, which indicates that
\begin{equation}
    \begin{aligned}
        &\bigg\{\int_0^1\int_0^1\left\lVert \nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REM})-\nabla\log p_{T-(n+u)h}(\vartheta_{n+v}^{\sf REM})\right\rVert_{\Ltwo}^2\rmd u\rmd v\bigg\}^{1/2}\\
        \leqslant& \, h\bigg\{\int_0^1\int_0^1\left[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\right]^2\rmd u\rmd v\bigg\}^{1/2}\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
        &+h^{1/2}\sqrt{d}\left[\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd v\right]^{1/2}\\
        &+h\left[\int_0^1\int_0^1(u-v)^2L(T-(n+u)h)^2\rmd u\rmd v\right]^{1/2}\varepsilon_{sc}.
    \end{aligned}
    \label{eq:diffscore}
\end{equation}
Combining the above,
\begin{align*}
    &\l|\vartheta_{n+1}^{\sf REM}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REM}]\r|_{\Ltwo}\\
    \leqslant & \,\,\dfrac{1}{8\sqrt{3}}h^2\left(\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}+C_2(n)+C_4\right)\\
    &+\dfrac{1}{4\sqrt{3}}h^2\left[\varepsilon_{sc}+L(T-nh)\left(\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}+C_2(n)\right)+(dL(T-nh))^{1/2}\right]\\
    &+\dfrac{1}{2\sqrt{3}}h^{3/2}\\
    &+ h^2\bigg\{\int_0^1\int_0^1\left[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\right]^2\rmd u\rmd v\bigg\}^{1/2}\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &+h^2\bigg\{\int_0^1\int_0^1\bigg\{(u-v)\left[\left(\dfrac{1}{2}+L(T-nh)\right)C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]L(T-(n+u)h)\\
    &\qquad\qquad+M_1(1+C_2(n)+C_4)\bigg\}^2\rmd u\rmd v\bigg\}^{1/2}\\
    &+h^{3/2}\sqrt{d}\left[\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd v\right]^{1/2}\\
    &+h^2\left[\int_0^1\int_0^1(u-v)^2L(T-(n+u)h)^2\rmd u\rmd v\right]^{1/2}\varepsilon_{sc}\\
    &+2h\varepsilon_{sc}\\
    \lesssim& \,\,h^2\bigg\{\left[\int_0^1\int_0^1\left[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\right]^2\rmd u\rmd v\right]^{1/2}\\
    &\quad+\dfrac{1}{4\sqrt{3}}L(T-nh)+\dfrac{1}{8\sqrt{3}}\bigg\}\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &+h^2\bigg\{\bigg\{\int_0^1\int_0^1\bigg\{(u-v)\left[\left(\dfrac{1}{2}+L(T-nh)\right)C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]L(T-(n+u)h)\\
    &\qquad\qquad\qquad+M_1(1+C_2(n)+C_4)\bigg\}^2\rmd u\rmd v\bigg\}^{1/2}\\
    &\qquad\quad+\dfrac{1}{8\sqrt{3}}(C_2(n)+C_4)+\dfrac{1}{4\sqrt{3}}(L(T-nh)C_2(n)+(dL(T-nh))^{1/2})\bigg\}\\
    &+h^{3/2}\bigg\{\sqrt{d}\left[\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd v\right]^{1/2}+\dfrac{1}{2\sqrt{3}}\bigg\}\\
    &+2h\varepsilon_{sc}.
\end{align*}
Compared to the term  $\tilde{Y}_h-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REM}]$, we can focus on the lower-order terms, ignoring the score matching error. Therefore, we have
\begin{align*}
    &\l|\tilde{Y}_{(n+1)h}-\vartheta_{n+1}^{\sf REM}\r|_{\Ltwo}\\
    \leqslant &\,\,h^2\Bigg\{\left[\int_0^1\int_0^1\left[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\right]^2\rmd u\rmd v\right]^{1/2}\l|Y_{nh}-\vartheta_n^{\sf REM}\r|_{\Ltwo}\\
    &\qquad+\dfrac{1}{4\sqrt{3}}L(T-nh)+\dfrac{1}{8\sqrt{3}}\Bigg\}\\
    &+h^2\Bigg\{\bigg\{\int_0^1\int_0^1\bigg\{(u-v)\left[\left(\dfrac{1}{2}+L(T-nh)\right)C_2(n)+\dfrac{1}{2}C_4+(dL(T-nh))^{1/2}\right]L(T-(n+u)h)\\
    &\qquad\qquad+M_1(1+C_2(n)+C_4)\bigg\}^2\rmd u\rmd v\bigg\}^{1/2}\\
    &\qquad \quad+\dfrac{1}{8\sqrt{3}}(C_2(n)+C_4)+\dfrac{1}{4\sqrt{3}}\left(L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right)\Bigg\}\\
    &+h^{3/2}\Bigg\{\sqrt{d}\left[\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd v\right]^{1/2}+\dfrac{1}{2\sqrt{3}}\Bigg\}\\
    &+3h\varepsilon_{sc}.
\end{align*}
\end{proof}
Returning to the proof of Theorem~\ref{thm:RMPEM}, by the conclusion of Proposition~\ref{prop:RMPEM}, we have
\begin{align*}
    \l|Y_{Nh}-\vartheta_N^{\sf REM}\r|_{\Ltwo}
    &\lesssim \dfrac{1}{m_{\min}-1/2}\left(h\max_{0\leqslant k\leqslant N-1}C_{k,1}^{\sf REM}+h^{1/2}\max_{0\leqslant k\leqslant N-1}C_{k,2}^{\sf REM}+3\varepsilon_{sc}\right)\\
    &\lesssim \sqrt{h}\cdot\dfrac{\sqrt{d/3}L_{\max}+\frac{1}{2\sqrt{3}}}{m_{\min}-1/2}+\varepsilon_{sc}\cdot\dfrac{3}{m_{\min}-1/2}.
\end{align*}
This completes the proof of Theorem~\ref{thm:RMPEM}.


\subsection{Proof of Theorem~\ref{thm:RMPEI}}
\label{proof:RMPEI}
We begin with the following proposition.
\begin{proposition}
    \label{prop:RMPEI}
    Suppose that Assumptions~\ref{asm:p0scLipx},~\ref{asm:scLipt} and~\ref{asm:score4RMP} are satisfied, the following two claims hold
    \begin{enumerate}[label=\textbf{(\arabic*)}, leftmargin=2em]
        \item \label{item:REItilde} It holds that
        \begin{align*}
            &\l|\tilde{Y}_h-\vartheta_{n+1}^{\sf REI}\r|_{\Ltwo}\\
            \leqslant&\,\,h^2\Bigg\{\int_0^1\int_0^1\bigg[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\\
            &\qquad+\dfrac{1}{2}|u-v|L(T-(n+v)h)r_n^{\sf EI}(v)\bigg]^2\rmd u\rmd v\Bigg\}^{1/2}\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}\\
            &\quad +h^2\Bigg\{\dfrac{e^{\frac{1}{2}(1-v)h}-e^{\frac{1}{2}(1-u)h}}{h}e^{\frac{1}{2}vh}L(T-(n+u)h)\left[C_2(n)+C_4+2L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right]\\
            &\qquad\quad +e^{\frac{1}{2}(1-u)h}M_1\left[1+2e^{\frac{1}{2}vh}\left(L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right)+C_2(n)+C_4\right]\\
            &\qquad\quad +\dfrac{|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}|}{h}\left(L(T-(n+v)h)C_2(n)+(dL(T-(n+v)h))^{1/2}\right)\Bigg\}\\
            &\quad +h^{3/2}\sqrt{d}\bigg\{\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd v\bigg\}^{1/2}\\
            &\quad +3h\varepsilon_{sc}.
        \end{align*}
        \item \label{item:REIYt}
        Furthermore, it holds that
        \begin{align*}
            \l|Y_{(n+1)h}-\vartheta_{n+1}^{\sf REI}\r|_{\Ltwo}\leqslant r_n^{\sf REI}\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}+h^2C_{n,1}^{\sf REI}+h^{3/2}C_{n,2}^{\sf REI}+3h\varepsilon_{sc}\,,
        \end{align*}
        where
        \begin{align*}
            r_n^{\sf REI}&=e^{-\int_{nh}^{(n+1)h}(m(T-t)-\frac{1}{2})\rmd t}\\
            &\quad +h^2\bigg\{\int_0^1\int_0^1\bigg[|u-v|L(T-(n+u)h)(\dfrac{1}{2}+L(T-nh))\\
            &\qquad\qquad\qquad\qquad+M_1+\dfrac{1}{2}|u-v|L(T-(n+v)h)r_n^{\sf EI}(v)\bigg]^2\rmd u\rmd v\bigg\}^{1/2},\\
            C_{n,1}^{\sf REI}&=\dfrac{e^{\frac{1}{2}(1-v)h}-e^{\frac{1}{2}(1-u)h}}{h}e^{\frac{1}{2}vh}L(T-(n+u)h)\left[C_2(n)+C_4+2L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right]\\
            &\quad +e^{\frac{1}{2}(1-u)h}M_1\left[1+2e^{\frac{1}{2}vh}\left(L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right)+C_2(n)+C_4\right]\\
            &\quad +\dfrac{|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}|}{h}\left(L(T-(n+v)h)C_2(n)+(dL(T-(n+v)h))^{1/2}\right),\\
            C_{n,2}^{\sf REI}&=\sqrt{d}\bigg\{\int_0^1\int_0^1L(T-(n+u)h)^2|u-v|\rmd u\rmd v\bigg\}^{1/2}.
        \end{align*}
    \end{enumerate}
\end{proposition}
\begin{proof}[Proof of Proposition~\ref{prop:RMPEI}]
This proposition can be proven following the same approach as in the proof of Proposition~\ref{prop:RMPEM}, with the only difference being the inclusion of the exponential coefficient term. 
However, this term does not significantly affect the overall proof.\\
Similarly, we make a decomposition as
\begin{align}
    \label{eq:REIdecom}
    \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf REI}\r|_{\Ltwo}\leqslant&\l|\tilde{Y}_h-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REI}]\r|_{\Ltwo}+\l|\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REI}]\r|_{\Ltwo}.
\end{align}
Note that
\begin{align*}
    \tilde{Y}_h-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REI}]&=\int_0^he^{\frac{1}{2}(h-t)}\nabla\log p_{T-nh-t}(\tilde{Y}_t)\rmd t-h\mathbb{E}_{U_n}\left[e^{\frac{1}{2}(1-U_n)h}s_*(T-nh-U_nh,\vartheta_{n+U_n}^{\sf REI})\right]\\
    &=h\int_0^1e^{\frac{1}{2}(1-u)h}\left(\nabla\log p_{T-nh-uh}(\tilde{Y}_{uh})-s_*(T-nh-uh,\vartheta_{n+u}^{\sf REI})\right)\rmd u\\
    &=h\int_0^1e^{\frac{1}{2}(1-u)h}\left(\nabla\log p_{T-nh-uh}(\tilde{Y}_{uh})-\nabla\log p_{T-nh-uh}(\vartheta_{n+u}^{\sf REI})\right)\rmd u\\
    &\quad +h\int_0^1e^{\frac{1}{2}(1-u)h}\left(\nabla\log p_{T-nh-uh}(\vartheta_{n+u}^{\sf REI})-s_*(T-nh-uh,\vartheta_{n+u}^{\sf REI})\right)\rmd u.
\end{align*}
Then, we obtain 
\begin{align*}
    &\l|\tilde{Y}_h-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REI}]\r|_{\Ltwo}\\
    \leqslant &\,\, h\int_0^1\left\lVert e^{\frac{1}{2}(1-u)h}(\nabla\log p_{T-nh-uh}(\tilde{Y}_{uh})-s_*(T-nh-uh,\vartheta_{n+u}^{\sf REI}))\right\rVert_{\Ltwo}\rmd u\\
    \leqslant & \,\,h\int_0^1e^{\frac{1}{2}(1-u)h}L(T-nh-uh)\l|\tilde{Y}_{uh}-\vartheta_{n+u}^{\sf REI}\r|_{\Ltwo}\rmd u+h\int_0^1e^{\frac{1}{2}(1-u)h}\rmd u\,\varepsilon_{sc}\\
    \leqslant & \,\,h^3\int_0^1e^{\frac{1}{2}(1-u)h}L(T-nh-uh)u^2\left( C_{5,n}(u)C_{1,n}(u)+M_1\dfrac{2(e^{uh/2}-1)}{uh}\right)\rmd u\,\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}\\
    & +h^3\int_0^1e^{\frac{1}{2}(1-u)h}L(T-nh-uh)u^2\bigg[C_{5,n}(u)\left(C_{1,n}(u)C_2(n)+\dfrac{1}{2}C_4+C_{3,n}(u)\right)\\
    & \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad+\dfrac{2(e^{uh}-1)}{uh}M_1(1+C_2(n)+C_4)\bigg]\rmd u\\
    &+h^{5/2}\int_0^1e^{\frac{1}{2}(1-u)h}L(T-nh-uh)u^{3/2}C_{5,n}(u)\rmd u\,\sqrt{d}\\
    & +h^2\int_0^1e^{\frac{1}{2}(1-u)h}L(T-nh-uh)\dfrac{2(e^{uh/2}-1)}{h}\rmd u\,\varepsilon_{sc}+h\dfrac{2(e^{h/2}-1)}{h}\varepsilon_{sc},
\end{align*}
where
\begin{align*}
    C_{5,n}(u)&=\dfrac{1}{uh}\int_{nh}^{(n+u)h}e^{\frac{1}{2}((n+u)h-t)}L(T-t)\rmd t.
\end{align*}
In the third inequality, we can directly bound $\l|\tilde{Y}_{uh}-\vartheta_{n+u}^{\sf REI}\r|_{\Ltwo}$, as it is a special case of Proposition~\ref{prop:EI}, where the step size is replaced by $uh$.\\
For the second term of \eqref{eq:REIdecom}, we have
\begin{align*}
    &\vartheta_{n+1}^{\sf REI}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REI}]\\
    =& \,\, he^{\frac{1}{2}(1-U_n)h}s_*(T-nh-U_nh,\vartheta_{n+U}^{\sf REI})-h\mathbb{E}_{U_n}\left[e^{\frac{1}{2}(1-U_n)h}s_*(T-nh-U_nh,\vartheta_{n+U}^{\sf REI})\right]\\
    =&\,\,h\int_0^1\left[e^{\frac{1}{2}(1-U_n)h}s_*(T-nh-U_nh,\vartheta_{n+U_n}^{\sf REI})-e^{\frac{1}{2}(1-v)h}s_*(T-nh-vh,\vartheta_{n+v}^{\sf REI})\right]\rmd v\,.
\end{align*}
Similar to display~\eqref{eq:diffmatch}, we then obtain
\begin{align*}
    &\left\lVert\vartheta_{n+1}^{\sf REI}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REI}]\right\rVert_{\Ltwo}\\
    \leqslant &\,\,\bigg\{\mathbb{E}\int_0^1\left[h\int_0^1e^{\frac{1}{2}(1-u)h}s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REI})-e^{\frac{1}{2}(1-v)h}s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REI})\rmd v\right]^2\rmd u\bigg\}^{1/2}\\
    \leqslant & \,\, h\bigg\{\int_0^1\int_0^1\left\lVert e^{\frac{1}{2}(1-u)h}s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REI})-e^{\frac{1}{2}(1-v)h}s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}^2\rmd u\rmd v\bigg\}^{1/2}\\
    \leqslant & \,\, h\bigg\{\int_0^1\int_0^1\left\lVert e^{\frac{1}{2}(1-u)h}\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REI})-e^{\frac{1}{2}(1-v)h}\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}^2\rmd u\rmd v\bigg\}^{1/2}\\
    &+2h\left(\int_0^1e^{(1-u)h}\rmd u\right)^{1/2}\varepsilon_{sc},
\end{align*}
Using the same strategy as in display~\eqref{eq:diffscore}, we arrive at
\begin{align*}
    &\left\lVert e^{\frac{1}{2}(1-u)h}\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REI})-e^{\frac{1}{2}(1-v)h}\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}\\
    \leqslant &\,\, e^{\frac{1}{2}(1-u)h}\left\lVert \nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REI})-\nabla\log p_{T-(n+u)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}\\
    &+e^{\frac{1}{2}(1-u)h}\left\lVert \nabla\log p_{T-(n+u)h}(\vartheta_{n+v}^{\sf REI})-\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}\\
    &+\left|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}\right|\left\lVert \nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}\\
    \leqslant & \,\,e^{\frac{1}{2}(1-u)h}L(T-(n+u)h)\l|\vartheta_{n+u}^{\sf REI}-\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo}\\
    &+e^{\frac{1}{2}(1-u)h}M_1h(1+\l|\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo})\\
    &+\left|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}\right|\left[L(T-(n+v)h)\left(\l|Y_{(n+v)h}-\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo}+C_2(n)\right)+(dL(T-(n+v)h))^{1/2}\right].
\end{align*}
The second inequality follows from Assumptions~\ref{asm:p0scLipx} and~\ref{asm:scLipt}. 
We bound the term $\left\lVert \nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}$ by decomposing it as follows
\begin{align*}
    \left\lVert\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}
    &\leqslant \left\lVert\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})-\nabla\log p_{T-(n+v)h}(Y_{(n+v)h})\right\rVert_{\Ltwo}\\
    &\quad+\l|\nabla\log p_{T-(n+v)h}(Y_{(n+v)h})-\nabla\log p_{T-(n+v)h}(X_{((n+v)h)}^{\leftarrow})\r|_{\Ltwo}\\
    &\quad +\l|\nabla\log p_{T-(n+v)h}(X_{T-(n+v)h})\r|_{\Ltwo}.
\end{align*}
Without loss of generality, we consider the case where $u>v$; the other case follows similarly.
\begin{equation}
    \begin{aligned}
        &\l|\vartheta_{n+u}^{\sf REI}-\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo}\\
        =&\,\,(e^{\frac{1}{2}uh}-e^{\frac{1}{2}vh})\l|\vartheta_n^{\sf REI}\r|_{\Ltwo}+\int_{vh}^{uh}e^{\frac{1}{2}t}\rmd t\l|s_*(T-nh,\vartheta_n^{\sf REI})\r|_{\Ltwo}\\
        &+\left\lVert\int_{nh}^{(n+u)h}e^{\frac{1}{2}((n+u)h-t)}\rmd W_t-\int_{nh}^{(n+v)h}e^{\frac{1}{2}((n+v)h-t)}\rmd W_t\right\rVert_{\Ltwo}\\
        \leqslant& \,\,\big(e^{\frac{1}{2}(u-v)h}-1\big)e^{\frac{1}{2}vh}\left(\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}+C_2(n)+C_4\right)\\
        &+2\big(e^{\frac{1}{2}(u-v)h}-1\big)e^{\frac{1}{2}vh}\left[\varepsilon_{sc}+L(T-nh)\left(\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}+C_2(n)\right)+(dL(T-nh))^{1/2}\right]\\
        &+\left[(e^{uh}-1)+(e^{vh}-1)-2(e^{\frac{u+v}{2}h}-e^{\frac{u-v}{2}h})\right]^{1/2}\sqrt{d}.
    \end{aligned}
    \label{eq:yEIdiff}
\end{equation}
Here, we apply the formula in \eqref{eq:Itoiso} to bound the last term.
\begin{align*}
    &\left\lVert\int_{nh}^{(n+u)h}\textbf{1}_{\{t\leqslant(n+v)h\}}(e^{\frac{1}{2}((n+u)h-t)}-e^{\frac{1}{2}((n+v)h-t)})+\textbf{1}_{\{t>(n+v)h\}}e^{\frac{1}{2}((n+u)h-t)}\rmd W_t\right\rVert_{\Ltwo}\\
    =&\,\,\sqrt{d}\left[\int_{nh}^{(n+v)h}(e^{\frac{1}{2}((n+u)h-t)}-e^{\frac{1}{2}((n+v)h-t)})^2\rmd t+\int_{(n+v)h}^{(n+u)h}e^{(n+u)h-t}\rmd t\right]^{1/2}\\
    =&\,\,\sqrt{d}\left[(e^{uh}-1)+(e^{vh}-1)-2(e^{\frac{u+v}{2}h}-e^{\frac{u-v}{2}h})\right]^{1/2},
\end{align*}
We then bound the term $\l|\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo}$ following display~\eqref{eq:yEIdiff} above. 
To this end, let $u=0$, we then have
\begin{align*}
    \l|\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo}
    &\leqslant (e^{\frac{1}{2}vh}-1)(\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}+C_2(n)+C_4)\\
    &\quad+2(e^{\frac{1}{2}vh}-1)\left[\varepsilon_{sc}+L(T-nh)\left(\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}+C_2(n)\right)+(dL(T-nh))^{1/2}\right]\\
    &\quad +\sqrt{d}(e^{vh}-1)^{1/2}\\
    &\quad +\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}+C_2(n)+C_4.
\end{align*}
Additionally, we can bound $\l|Y_{(n+v)h}-\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo}$, as it is a special case of the one-step discretization error under the Exponential Integrator scheme, where the step size is replaced by $vh$.
Specifically, we have
\begin{align*}
    &\l|Y_{(n+v)h}-\vartheta_{n+v}^{\sf REI}\r|_{\Ltwo}\\
    \leqslant &\,\,r_n^{\sf EI}(v)\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}+h^2C_n^{\sf EI}(v)+h^{3/2}u^{3/2}\sqrt{d}C_{5,n}(v)+vh\dfrac{2(e^{\frac{1}{2}vh}-1)}{vh}\varepsilon_{sc},
\end{align*}
where
\begin{align*}
    r_n^{\sf EI}(v)&=e^{-\int_{nh}^{(n+v)h}(m(T-t)-\frac{1}{2})\rmd t}+v^2h^2\left(C_{5,n}(v)C_{1,n}(v)+M_1\dfrac{2(e^{\frac{1}{2}vh}-1)}{vh}\right),\\
    C_n^{\sf EI}(v)&=C_{5,n}(v)\left(C_{1,n}(v)C_2(n)+\dfrac{1}{2}C_4+C_{3,n}(v)\right)+\dfrac{2(e^{\frac{1}{2}vh}-1)}{vh}M_1(1+C_2(n)+C_4).
\end{align*}
Then, we obtain
\begin{align*}
    &\left\lVert e^{\frac{1}{2}(1-u)h}\nabla\log p_{T-(n+u)h}(\vartheta_{n+u}^{\sf REI})-e^{\frac{1}{2}(1-v)h}\nabla\log p_{T-(n+v)h}(\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}\\
    \leqslant & \,\,\Bigg\{2(e^{\frac{1}{2}(1-v)h}-e^{\frac{1}{2}(1-u)h})e^{\frac{1}{2}vh}L(T-(n+u)h)\left[\dfrac{1}{2}+L(T-nh)\right]\\
    &\quad +e^{\frac{1}{2}(1-u)h}M_1h\left[(e^{\frac{1}{2}vh}-1)+2(e^{\frac{1}{2}vh}-1)L(T-nh)+1\right]\\
    &\quad +\left|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}\right|L(T-(n+v)h)r_n^{\sf EI}(v)\Bigg\}\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}\\
    &+h^3L(T-(n+v)h)\dfrac{|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}|}{h}C_n^{\sf EI}(v)\\
    &+h^{5/2}L(T-(n+v)h)\dfrac{|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}|}{h}u^{3/2}\sqrt{d}C_{5,n}(v)\\
    &+h^2M_1e^{\frac{1}{2}(1-u)h}\dfrac{e^{\frac{1}{2}vh}-1}{h}(C_2(n)+C_4)\\
    &+h^{3/2}M_1e^{\frac{1}{2}(1-u)h}\sqrt{vd}\left(\dfrac{e^{vh}-1}{vh}\right)^{1/2}\\
    &+h\bigg\{\dfrac{e^{\frac{1}{2}(1-v)h}-e^{\frac{1}{2}(1-u)h}}{h}e^{\frac{1}{2}vh}L(T-(n+u)h)\left[C_2(n)+C_4+2L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right]\\
    &\quad\quad +e^{\frac{1}{2}(1-u)h}M_1\left[1+2e^{\frac{1}{2}vh}\left(L(T-nh)C_2(n)+(dL(T-nh))^{1/2}\right)+C_2(n)+C_4\right]\\
    &\quad\quad +\dfrac{|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}|}{h}\left(L(T-(n+v)h)C_2(n)+(dL(T-(n+v)h))^{1/2}\right)\bigg\}\\
    &+h^{1/2}L(T-(n+u)h)e^{\frac{1}{2}(1-u)h}\left[\dfrac{(e^{uh}-1)+(e^{vh}-1)-2(e^{\frac{u+v}{2}h}-e^{\frac{u-v}{2}h})}{h}\right]^{1/2}\sqrt{d}\\
    &+h^2\varepsilon_{sc}L(T-(n+v)h)\dfrac{|e^{\frac{1}{2}(1-u)h}-e^{\frac{1}{2}(1-v)h}|}{h}\dfrac{2(e^{\frac{1}{2}vh}-1)}{h}\\
    &+h\varepsilon_{sc}\cdot 2e^{\frac{1}{2}(1-u)h}\left[L(T-(n+u)h)\dfrac{e^{\frac{1}{2}uh}-e^{\frac{1}{2}vh}}{h}+M_1e^{\frac{1}{2}vh}\right].
\end{align*}
Ignoring the higher-order terms, we take the supremum with respect to $v$ and substitute it back into the original expression, yielding
\begin{align*}
    &\l|\vartheta_{n+1}^{\sf REI}-\mathbb{E}_{U_n}[\vartheta_{n+1}^{\sf REI}]\r|_{\Ltwo}\\
    \leqslant& \,\,h\bigg\{\int_0^1\int_0^1\left\lVert e^{\frac{1}{2}(1-u)h}s_*(T-(n+u)h,\vartheta_{n+u}^{\sf REI})-e^{\frac{1}{2}(1-v)h}s_*(T-(n+v)h,\vartheta_{n+v}^{\sf REI})\right\rVert_{\Ltwo}^2\rmd u\rmd v\bigg\}^{1/2}\\
    \leqslant& \,\,h^2\bigg\{\int_0^1\int_0^1\big[|u-v|L(T-(n+u)h)\left(\dfrac{1}{2}+L(T-nh)\right)+M_1\\
    &\qquad\qquad +\dfrac{1}{2}|u-v|L(T-(n+v)h)r_n^{\sf EI}(v)\big]^2\rmd u\rmd v\bigg\}^{1/2}\l|Y_{nh}-\vartheta_n^{\sf REI}\r|_{\Ltwo}\\
    &\quad +h^{3/2}\bigg\{\int_0^1\int_0^1dL(T-(n+u)h)^2|u-v|\rmd u\rmd v\bigg\}^{1/2} +2h\varepsilon_{sc},.
\end{align*}
This completes the proof.

\end{proof}
Now, we have
\begin{align*}
    \l|Y_{Nh}-\vartheta_N^{\sf REI}\r|_{\Ltwo}
    &\lesssim \,\,\dfrac{1}{m_{\min}-1/2}\left(h\max_{0\leqslant k\leqslant N-1}C_{n,1}^{\sf REI}+\sqrt{h}\max_{0\leqslant k\leqslant N-1}C_{n,2}^{\sf REI}+3\varepsilon_{sc}\right)\\
    &\lesssim\,\,\sqrt{dh}\dfrac{L_{\max}}{\sqrt{3}(m_{\min}-1/2)}+\varepsilon_{sc}\dfrac{3}{m_{\min}-1/2}\,.
\end{align*}
The desired result follows readily.

\section{The proof of the upper bound of error of the second-order acceleration scheme}
This section is dedicated to proving the Wasserstein convergence result for second-order acceleration. To this end, we first establish the following proposition.
\begin{proposition}
    \label{prop:2order}
    Suppose that Assumptions~\ref{asm:p0scLipx},~\ref{asm:scoreerr},~\ref{asm:scerr4SO},~\ref{asm:scLipx4SO},~\ref{asm:scLipt4SO} are satisfied, the following results hold. 
    \begin{enumerate}[label=\textbf{(\arabic*)}, leftmargin=2em]
        \item \label{item:SOtilde}
        First, we have an upper bound for $\l|\tilde Y_h-\vartheta_{n+1}^{\sf SO}\r|_{\Ltwo}$ as follows,
        \begin{align*}
            \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf SO}\r|_{\Ltwo}\leqslant&A_{n,1}e^{(L(nh)-\frac{1}{2})h}h^2\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+A_{n,2}e^{(L(nh)-\frac{1}{2})h}h^2\\
            &+\left(h\varepsilon_{sc}+\dfrac{2}{3}h^{3/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}h^2\varepsilon_{sc}^{(M)}\right)e^{(L(T-nh)-\frac{1}{2})h},
        \end{align*}
        where
        \begin{align*}
            A_{n,1}=\sup_{nh\leqslant t\leqslant (n+1)h}&\dfrac{1}{t^2}\int_0^t\Big(\int_0^s\big[(1+L(T-nh-u))L(T-nh-u)\\
            &\qquad \qquad\qquad+(1+L(T-nh))L(T-nh)\big]\rmd u\Big)\rmd s,\\
            A_{n,2}=\sup_{nh\leqslant t\leqslant (n+1)h}&\dfrac{1}{t^2}\bigg[\int_0^t\Big(\int_0^s\big[(1+L(T-nh-u))L(T-nh-u)\\
            &\qquad \qquad\qquad+(1+L(T-nh))L(T-nh)\big]\rmd u\Big)\rmd s\cdot C_2(n)\\
            &\qquad+\sqrt{d}\int_0^t\Bigg(\int_0^s\Big[\Big(\dfrac{1}{2}+L(T-nh-u)\Big)L(T-nh-u)^{1/2}\\
            &\qquad\qquad \qquad\qquad+\Big(\dfrac{1}{2}+L(T-nh)\Big)L(T-nh)^{1/2}\Big]\rmd u\Bigg)\rmd s\\
            &\qquad+\int_0^t\left(\int_0^s\dfrac{1}{2}(L(T-nh-u)+L(T-nh))\rmd u\right)\rmd s\cdot C_4\bigg]\\
            &+\dfrac{\sqrt{2}}{4}L_F+\dfrac{3}{2}dL_F.
        \end{align*}
        \item \label{item:SOYt}
        Furthermore, it holds that
        \begin{align*}
            \l|Y_{(n+1)h}-\vartheta_{n+1}^{\sf SO}\r|_{\Ltwo}
            &\leqslant r_n^{\sf SO}\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+h^2C_n^{\sf SO}\\
            &\quad +\left[h\varepsilon_{sc}+\dfrac{2}{3}h^{3/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}h^2\varepsilon_{sc}^{(M)}\right]e^{(L(T-nh)-\frac{1}{2})h},
        \end{align*}
        where
        \begin{align*}
            r_n^{\sf SO}=&e^{-\int_{nh}^{(n+1)h}(m(T-t)-\frac{1}{2})\rmd t}+h^2A_{n,1}e^{(L(T-nh)-\frac{1}{2})h}\\
            C_n^{\sf SO}=&A_{n,2}e^{(L(T-nh)-\frac{1}{2})h}\,.
        \end{align*}
    \end{enumerate}
\end{proposition}
\begin{proof}
Recall the expression in display~\eqref{eq:SOxt}, which states that
\begin{align*}
    x_t=\vartheta_n^{\sf SO}+\int_{nh}^{t}\left(\dfrac{1}{2}\vartheta_n^{\sf SO}+\nabla \log p_{T-nh}(\vartheta_n^{\sf SO})+L_n(x_s-\vartheta_n^{\sf SO})+M_n(s-nh)\right)\rmd s+\int_{nh}^{t}\rmd W_s
\end{align*}
with
\begin{align*}
    L_n&=\dfrac{1}{2}I_d+\nabla^2\log p_{T-nh}(\vartheta_n^{\sf SO})\in\mathbb{R}^{d\times d},\\
    M_n&=\dfrac{1}{2}\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh}(\vartheta_n^{\sf SO})-\dfrac{\partial}{\partial t}\nabla\log p_{T-nh}(\vartheta_n^{\sf SO})\in\mathbb{R}^d.
\end{align*}
Plugging the estimates of $\nabla \log p_{T-nh}(\vartheta_n^{\sf SO}),L_n$ and $M_n$ into the previous display yields the following process for $x_t^{\sf SO}$ 
\begin{align*}
    x_t^{\sf SO}&=\vartheta_n^{\sf SO}+\int_{nh}^t\dfrac{1}{2}\vartheta_n^{\sf SO}+s_*(T-nh,\vartheta_n^{\sf SO})\rmd s\\
    &\quad +\int_{nh}^ts_*^{(L)}(T-nh,\vartheta_n^{\sf SO})(x_s^{\sf SO}-\vartheta_n^{\sf SO})+s_*^{(M)}(T-nh,\vartheta_n^{\sf SO})(s-nh)\rmd s+\int_{nh}^t\rmd W_s\,.
\end{align*}
Then, we obtain 
\begin{align*}
    x_t^{\sf SO}-x_t&=(t-nh)(s_*(T-nh,\vartheta_n^{\sf SO})-\nabla\log p_{T-nh}(\vartheta_n^{\sf SO}))\\
    &\quad +(s_*^{(L)}(T-nh,\vartheta_n^{\sf SO})-L_n)\int_{nh}^t(x_s^{\sf SO}-\vartheta_n^{\sf SO})\rmd s+L_n\int_{nh}^t(x_s^{\sf SO}-x_s)\rmd s\\
    &\quad +(s_*^{(M)}(T-nh,\vartheta_n^{\sf SO})-M_n)\cdot\dfrac{1}{2}(t-nh)^2.
\end{align*}
Notice that
\begin{align}
    \label{eq:SOterm1}
    \l|L_n\r|_{\Ltwo}=\l|\dfrac{1}{2}I_d+\nabla^2\log p_{T-nh}(\vartheta_n^{\sf SO})\r|_{\Ltwo}\leq L(T-nh)-\dfrac{1}{2}.
\end{align}
Combining this with  Assumptions~\ref{asm:scoreerr} and~\ref{asm:scerr4SO} then provides us with
\begin{align*}
    &\l|x_t^{\sf SO}-x_t\r|_{\Ltwo}\\
    \leqslant&\,\, (t-nh)\varepsilon_{sc}+\varepsilon_{sc}^{(L)}\int_{nh}^t\l|x_s^{\sf SO}-\vartheta_n^{\sf SO}\r|_{\Ltwo}\rmd s+\l|L_n\r|_{\Ltwo}\int_{nh}^t\l|x_s^{\sf SO}-x_s\r|\rmd s+\dfrac{1}{2}(t-nh)^2\varepsilon_{sc}^{(M)}\\
    \lesssim& \,\, \Big(L(T-nh)-\dfrac{1}{2}\Big)\int_{nh}^t\l|x_s^{\sf SO}-x_s\r|\rmd s+(t-nh)\varepsilon_{sc}+\dfrac{2}{3}(t-nh)^{3/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}(t-nh)^2\varepsilon_{sc}^{(M)}.
\end{align*}
We need the following Gr{\"o}nwall-type inequality to handle this integral inequality.
\begin{lemma}
    \label{lem:Gron2}
    Let $z(t)\geqslant t_0$ satisfy the following inequality:
    \begin{align*}
        z(t)\leqslant \alpha(t)+\int_{t_0}^t\beta(s)z(s)\rmd s,\quad t\geqslant t_0,
    \end{align*}
    where $\beta(s)$ is non-negative, and $t_0$ is the initial time. Then, the solution $z(t)$ satisfies the following bound:
    \begin{align*}
        z(t)\leqslant \alpha(t)+\int_{t_0}^t\alpha(s)\beta(s)\exp\left(\int_s^t\beta(r)\rmd r\right)\rmd s,\quad t\geqslant t_0.
    \end{align*}
    Additionally, if $\alpha(t)$ is non-decreasing function, then
    \begin{align*}
        z(t)\leqslant\alpha(t)\exp\left(\int_{t_0}^t\beta(s)\rmd s\right),\quad t\geqslant t_0.
    \end{align*}
\end{lemma}
Let 
\begin{align*}
z(t)&=\l|x_t^{\sf SO}-x_t\r|_{\Ltwo}\\
\alpha(t)&=(t-nh)\varepsilon_{sc}+\dfrac{2}{3}(t-nh)^{3/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}(t-nh)^2\varepsilon_{sc}^{(M)}\\
\beta(t)&=L(T-nh)-\dfrac{1}{2}\,,
\end{align*}
and set $t_0=nh$. By Lemma~\ref{lem:Gron2}, we have
\begin{align}
    \label{eq:SO1}
    \l|\vartheta_{n+1}^{\sf SO}-x_{(n+1)h}\r|_{\Ltwo}\leqslant\left(h\varepsilon_{sc}+\dfrac{2}{3}h^{3/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}h^2\varepsilon_{sc}^{(M)}\right)e^{(L(T-nh)-\frac{1}{2})h}.
\end{align}
The original SDE can be rewritten as follows
\begin{align*}
\tilde{Y}_t=\tilde{Y}_0+\int_0^t\Big(\dfrac{1}{2}\tilde{Y}_s+\nabla\log p_{T-nh-s}(\tilde{Y}_s)\Big)\rmd s+\int_{nh}^{nh+t}\rmd W_s.
\end{align*}
Combining this with the definition of $x_{t}$ in~\eqref{eq:SOxt}, we then have
\begin{align*}
\tilde{Y}_t-x_{nh+t}&=\int_0^t\left(\dfrac{1}{2}\tilde{Y}_s+\nabla\log p_{T-nh-s}(\tilde{Y}_s)-\dfrac{1}{2}\vartheta_n^{\sf SO}-\nabla\log p_{T-nh}(\vartheta_n^{\sf SO})-L_n(x_{nh+s}-\vartheta_n^{\sf SO})-M_ns\right)\rmd s\\
&=\int_0^tL_n(\tilde Y_s-x_{nh+s})\rmd s+\int_0^t\left(\dfrac{1}{2}\tilde Y_s+\nabla\log p_{T-nh-s}(\tilde Y_s)-\dfrac{1}{2}\vartheta_n^{\sf SO}-\nabla\log p_{T-nh}(\vartheta_n^{\sf SO})\right)\rmd s\\
&\quad -\int_0^t\left(\int_0^s L_n\rmd \tilde Y_u\rmd u\right)\rmd s-\int_0^t\left(\int_0^s M_n\rmd u\right)\rmd s\\
&=\int_0^t L_n(\tilde Y_s-x_{nh+s})\rmd s+\int_0^t\left(\int_0^s\rmd\left(\dfrac{1}{2}\tilde Y_u+\nabla\log p_{T-nh-u}(\tilde Y_u)\right)\right)\rmd s\\
&\quad -\int_0^t\left(\int_0^s L_n\rmd \tilde Y_u\rmd u\right)\rmd s-\int_0^t\left(\int_0^s M_n\rmd u\right)\rmd s\,.
\end{align*}
We then apply the \text{It\^o} formula to the term $\rmd\left(\dfrac{1}{2}\tilde Y_u+\nabla\log p_{T-nh-u}(\tilde Y_u)\right)$. Recall the definitions of $L_n$ and $M_n$, and after rearranging the expression, we obtain
\begin{align*}
\tilde Y_t-x_{nh+t}&=\underbrace{\int_0^tL_n(\tilde{Y}_s-x_{nh+s})\rmd s}_{\text{\large I}}
+\underbrace{\int_0^t\left(\int_0^s\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\rmd\tilde{Y}_u\right)\rmd s}_{\text{\large II}}\\
&\quad +\underbrace{\int_0^t\left(\int_0^s\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh-u}(\tilde{Y}_u)-\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh}(\tilde{Y}_0)\rmd u\right)\rmd s}_{\text{\large III}}\\
&\quad -\underbrace{\int_0^t\left(\int_0^s\partial_t\nabla\log p_{T-nh-u}(\tilde{Y}_u)-\partial_t\nabla\log p_{T-nh}(\tilde{Y}_0)\rmd u\right)\rmd s}_{\text{\large IV}}\,.
\end{align*}
In what follows, we derive the upper bounds for each term on the right-hand side of the previous display. 

\noindent \textbf{Upper bound for term~$\rm I$:}
The upper bound of the term~$\rm I$ follows directly from the fact that 
\begin{align*}
\l|L_n\r|_{\Ltwo}\leqslant L(T-nh)-\dfrac{1}{2}\,.
\end{align*}

\noindent \textbf{Upper bound for term~$\rm II$:}
To derive the upper bound for the second term, we expand the term $\rmd \tilde{Y}_u$, yielding
\begin{align*}
    &\left\lVert\int_0^s\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\rmd\tilde{Y}_u\right\rVert_{\Ltwo}\\
    \leqslant&\,\,\left\lVert\int_0^s\big(\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\big)\Big(\dfrac{1}{2}\tilde{Y}_u+\nabla\log p_{T-nh-u}(\tilde{Y}_u)\Big)\rmd u\right\rVert_{\Ltwo}\\
    &\quad +\left\lVert\int_0^s\big(\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\big)\rmd W_u\right\rVert_{\Ltwo}\\
    \leqslant&\,\,\int_0^s\left\lVert\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\right\lVert_{\Ltwo}\cdot\left\lVert\dfrac{1}{2}\tilde{Y}_u+\nabla\log p_{T-nh-u}(\tilde{Y}_u)\right\rVert_{\Ltwo}\rmd u\\
    &\quad +\left(\int_0^s\l|\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\r|_{\Ltwo}^2\rmd u\right)^{1/2}.
\end{align*}
The second inequality follows from display~\eqref{eq:Itoiso}.
We note that by Assumptions~\ref{asm:scLipx4SO} and~\ref{asm:scLipt4SO}, it holds that
\begin{align*}
    &\l|\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\r|_{\Ltwo}\\
    \leqslant& \l|\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_u)\r|_{\Ltwo}+\l|\nabla^2\log p_{T-nh}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\r|_{\Ltwo}\\
    \leqslant& M_2h(1+\l|\tilde{Y}_u\r|_{\Ltwo})+L_F\l|\tilde{Y}_u-\tilde{Y}_0\r|_{\Ltwo}\\
    \leqslant& M_2h+(L_F+M_2h)\l|\tilde{Y}_u-\tilde{Y}_0\r|_{\Ltwo}+M_2h\l|\vartheta_n^{\sf SO}\r|_{\Ltwo}\\
    \lesssim& L_F\sqrt{u},
\end{align*}
Combining this with the previous display provides us with
\begin{align*}
\l|\int_0^s\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\rmd \tilde Y_u\r|_{\Ltwo}
&\lesssim \int_0^sL_F\sqrt{u}\cdot\left\lVert\dfrac{1}{2}\tilde{Y}_u+\nabla\log p_{T-nh-u}(\tilde{Y}_u)\right\rVert_{\Ltwo}\rmd u\\
&\quad +\left(\int_0^sL_F^2u\rmd u\right)^{1/2}\,.
\end{align*}
Hence, we obtain 
\begin{equation}
    \begin{aligned}
        \rm{II}&=\left\lVert\int_0^t\left(\int_0^s\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\rmd\tilde{Y}_u\right)\rmd s\right\rVert_{\Ltwo}\\
        &\leqslant\int_0^t\left\lVert\int_0^s\nabla^2\log p_{T-nh-u}(\tilde{Y}_u)-\nabla^2\log p_{T-nh}(\tilde{Y}_0)\rmd\tilde{Y}_u\right\rVert_{\Ltwo}\rmd s\\
        &\leqslant \int_0^t\left[\int_0^sL_F\sqrt{u}\cdot\left\lVert\dfrac{1}{2}\tilde{Y}_u+\nabla\log p_{T-nh-u}(\tilde{Y}_u)\right\rVert_{\Ltwo}\rmd u+\left(\int_0^sL_F^2u\rmd u\right)^{1/2}\right]\rmd s\\
        &\lesssim \dfrac{\sqrt{2}}{4}L_Ft^2.
    \end{aligned}
    \label{eq:SOterm2}
\end{equation}


\noindent \textbf{Upper bound for term~$\rm III$:}
To derive the upper bound for term~$\rm III$, we require the following lemma to relate the Lipschitz continuity of $\nabla^2\log p_t(x)$  to the bound on the third-order derivatives of $\log p_t(x)$.
\begin{lemma}
    Let $f\in C^3(\mathbb{R}^d)$. Suppose that the Hessian matrix $\nabla^2f(x)$ is $L_F$-Lipschitz continuous with respect to the Frobenius norm. That is, for all $x,y\in\mathbb{R}^d$, the following inequality holds,
    \begin{align*}
        \l|\nabla^2f(x)-\nabla^2f(y)\r|_F\leqslant L_F\l|x-y\r|_2.
    \end{align*}
    Then, the Frobenius norm of the third-order derivative tensor $\nabla^3f(x)$ is bounded above by $\sqrt{d}L_F$ for all $x\in\mathbb{R}^d$. Formally,
    \begin{align*}
        \l|\nabla^3f(x)\r|_F\leqslant \sqrt{d}L_F,
    \end{align*}
    where each element of $\nabla^3f(x)$ is a third-order derivative of $f$.
    \label{lem:Frob}
\end{lemma}
Lemma~\ref{lem:Frob} indicates that the third-order derivatives of the score function are all bounded by the constant $L_F$, therefore we obtain the following result.
\begin{align*}
    \left\lVert\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_t(x)\right\rVert^2
    &=\sum_{i=1}^d\left(\sum_{j=1}^d\dfrac{\partial^3}{\partial x_i\partial x_i\partial x_j}\log p_t(x)\right)^2\\
    &\leqslant d\sum_{i=1}^d\sum_{j=1}^d\left(\dfrac{\partial^3}{\partial x_i\partial x_i\partial x_j}\log p_t(x)\right)^2\\
    &\leqslant
    d\left\lVert\nabla^3\log p_t(x)\right\rVert_F^2\\
    &\leqslant d^2L_F^2.
\end{align*}
It then follows that
\begin{equation}
    \begin{aligned}
        \rm{III}&=\l|\int_0^t\left(\int_0^s\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh-u}(\tilde{Y}_u)-\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh}(\tilde{Y}_0)\rmd u\right)\rmd s\r|_{\Ltwo}\\
        &\leqslant\int_0^t\int_0^s\l|\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh-u}(\tilde{Y}_u)\r|_{\Ltwo}+\l|\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh}(\tilde{Y}_0)\r|_{\Ltwo}\rmd u\rmd v\\
        &\leqslant \int_0^t\int_0^s 2dL_F\rmd u\rmd v\\
        &=dL_Ft^2.
    \end{aligned}
    \label{eq:SOterm3}
\end{equation}

\noindent \textbf{Upper bound for term~$\rm IV$:}
In Section~\ref{sec:accleration}, it is noted that the partial derivative of $\nabla\log p_t$ with respect to $t$ can be estimated without requiring additional assumptions. 
This is achieved by transforming the $t$-derivative into $x$-derivative via the Fokker-Planck equation, as detailed below.
\begin{align}
    \label{eq:Fokker}
    \partial_t p_t(x)=\dfrac{d}{2}p_t(x)+\dfrac{1}{2}x^\top\nabla p_t(x)+\dfrac{1}{2}\sum_{i=1}^d \dfrac{\partial^2p_t(x)}{\partial x_i^2}.
\end{align}
We need the following auxiliary lemma. 
\begin{lemma}
    \label{lem:Fokker}
    Let $p_t$ be the probability density function of $X_t$, then
    \begin{align*}
        \sum_{i=1}^d\dfrac{\partial^2 p_t(x)}{\partial x_i^2}\cdot\dfrac{1}{p_t(x)}&=\Tr\left(\nabla^2\log p_t(x)\right)+\l|\nabla\log p_t(x)\r|^2,\\
        \nabla\left(\sum_{i=1}^d\dfrac{\partial^2p_t(x)}{\partial x_i^2}\right)\cdot\dfrac{1}{p_t(x)}&=\nabla\left(\Tr(\nabla^2\log p_t(x))\right)+\nabla(\l|\nabla\log p_t(x)\r|^2)\\
        &\quad+\left[\Tr(\nabla^2\log p_t(x))+\l|\nabla\log p_t(x)\r|^2\right]\cdot\nabla\log p_t(x).
    \end{align*}
\end{lemma}
We begin by taking the gradient of $\log p_t$, and then compute the partial derivative of $\nabla \log p_t$ with respect to $t$. This results in
\begin{align*}
    \partial_t\nabla\log p_t(x)=\partial_t\left(\dfrac{\nabla p_t(x)}{p_t(x)}\right)=\dfrac{\partial_t\nabla p_t(x)}{p_t(x)}-\dfrac{\nabla p_t(x)}{p_t(x)}\cdot\dfrac{\partial_t p_t(x)}{p_t(x)}.
\end{align*}
Under certain regularity conditions, we can interchange the operators $\partial_t$ and $\nabla$ in the term $\partial_t\nabla p_t(x)$, and substitute $\partial_t p_t(x)$ by \eqref{eq:Fokker}, it follows that
\begin{align*}
    \partial_t\nabla\log p_t(x)=\dfrac{\nabla\partial_t p_t(x)}{p_t(x)}-\nabla\log p_t(x)\cdot\left(\dfrac{d}{2}+\dfrac{1}{2}x^\top\nabla\log p_t(x)+\dfrac{1}{2}\sum_{i=1}^d\dfrac{\partial^2p_t(x)}{\partial x_i^2}\cdot\dfrac{1}{p_t(x)}\right)\,.
\end{align*}
and 
\begin{align*}
    \dfrac{\nabla\partial_tp_t(x)}{p_t(x)}&=\dfrac{1}{p_t(x)}\cdot\nabla\left(\dfrac{d}{2}p_t(x)+\dfrac{1}{2}x^\top\nabla p_t(x)+\dfrac{1}{2}\sum_{i=1}^d \dfrac{\partial^2p_t(x)}{\partial x_i^2}\right)\\
    &=\dfrac{d}{2}\dfrac{\nabla p_t(x)}{p_t(x)}+\dfrac{1}{2}\dfrac{\nabla p_t(x)}{p_t(x)}+\dfrac{1}{2}\dfrac{\nabla^2 p_t(x)x}{p_t(x)}+\dfrac{1}{2}\nabla\left(\sum_{i=1}^d\dfrac{\partial^2 p_t(x)}{\partial x_i^2}\right)\cdot\dfrac{1}{p_t(x)}\\
    &=\dfrac{d+1}{2}\nabla\log p_t(x)+\dfrac{1}{2}\dfrac{\nabla^2 p_t(x)x}{p_t(x)}+\dfrac{1}{2}\nabla\left(\sum_{i=1}^d\dfrac{\partial^2 p_t(x)}{\partial x_i^2}\right)\cdot\dfrac{1}{p_t(x)}\,.
\end{align*}
Therefore, we obtain that
\begin{align*}
    \partial_t\nabla\log p_t(x)&=\dfrac{d+1}{2}\nabla\log p_t(x)+\dfrac{1}{2}\dfrac{\nabla^2 p_t(x)x}{p_t(x)}+\dfrac{1}{2}\nabla\left(\sum_{i=1}^d\dfrac{\partial^2 p_t(x)}{\partial x_i^2}\right)\cdot\dfrac{1}{p_t(x)}\\
    &\quad -\nabla\log p_t(x)\cdot\left(\dfrac{d}{2}+\dfrac{1}{2}x^\top\nabla\log p_t(x)+\dfrac{1}{2}\sum_{i=1}^d\dfrac{\partial^2p_t(x)}{\partial x_i^2}\cdot\dfrac{1}{p_t(x)}\right)\\
    &=\dfrac{1}{2}\nabla\log p_t(x)+\dfrac{1}{2}\left(\dfrac{\nabla^2p_t(x)x}{p_t(x)}-\nabla\log p_t(x)\nabla\log p_t(x)^\top x\right)\\
    &\quad +\dfrac{1}{2}\nabla\left(\sum_{i=1}^d\dfrac{\partial^2 p_t(x)}{\partial x_i^2}\right)\cdot\dfrac{1}{p_t(x)}-\dfrac{1}{2}\nabla\log p_t(x)\sum_{i=1}^d\dfrac{\partial^2p_t(x)}{\partial x_i^2}\cdot\dfrac{1}{p_t(x)}\,.
\end{align*}
By Lemma~\ref{lem:Fokker}, the last two terms above can be calculated. Additionally, it holds that
\begin{align*}
    \nabla^2\log p_t(x)=\dfrac{\nabla^2p_t(x)}{p_t(x)}-\dfrac{\nabla p_t(x)\nabla p_t(x)^\top}{p_t(x)^2}\,.
\end{align*}
Thus, $\partial_t\nabla\log p_t(x)$ can be simplified to
\begin{align*}
    \partial_t\nabla\log p_t(x)&=\dfrac{1}{2}\nabla\log p_t(x)+\dfrac{1}{2}\nabla^2\log p_t(x)x\\
    &\quad +\dfrac{1}{2}\left[\nabla\left(\Tr(\nabla^2\log p_t(x))\right)+\nabla(\l|\nabla\log p_t(x)\r|^2)\right]\\
    &\quad+\dfrac{1}{2}\left(\Tr(\nabla^2\log p_t(x))+\l|\nabla\log p_t(x)\r|^2\right)\cdot\nabla\log p_t(x)\\
    &\quad -\dfrac{1}{2}\nabla\log p_t(x)\left(\Tr(\nabla^2\log p_t(x))+\l|\nabla\log p_t(x)\r|^2\right)\\
    &=\dfrac{1}{2}\nabla\log p_t(x)+\dfrac{1}{2}\nabla^2\log p_t(x)x+\dfrac{1}{2}\nabla(\Tr(\nabla^2\log p_t(x)))+\dfrac{1}{2}\nabla(\l|\nabla\log p_t(x)\r|^2).
\end{align*}
Then, it follows that
\begin{align*}
    &\l|\partial_t\nabla\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}\\
    \leqslant&\,\, \dfrac{1}{2}\l|\nabla\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}+\dfrac{1}{2}\l|\nabla^2\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}\l|\tilde Y_u\r|_{\Ltwo}\\
    &+\dfrac{1}{2}\l|\sum_{j=1}^d\dfrac{\partial^2}{\partial x_j^2}\nabla\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}+\l|\nabla^2\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}\l|\nabla\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}\\
    \leqslant&\,\, \dfrac{1}{2}\l|\nabla\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}+\dfrac{1}{2}L(T-nh-u)\l|\tilde Y_u\r|_{\Ltwo}\\
    &+\dfrac{1}{2}dL_F+L(T-nh-u)\l|\nabla\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}\,.
\end{align*}
The second inequality follows from Assumption~\ref{asm:p0scLipx} and \eqref{eq:SOterm3}. 
The bounds for $\l|\tilde Y_u\r|_{\Ltwo}$ and $\l|\nabla\log p_{T-nh-u}(\tilde Y_u)\r|_{\Ltwo}$ can be derived according to the proof of Lemma~\ref{lem:supYtY0}. 
We then find
\begin{align}
    &\l|\partial_t\nabla\log p_{T-nh-u}(\tilde{Y}_u)\r|_{\Ltwo}\\
    \leqslant&\,\,\dfrac{1}{2}\l|\nabla\log p_{T-nh-u}(\tilde{Y}_u)\r|_{\Ltwo}+\dfrac{1}{2}L(T-nh-u)\l|\tilde{Y}_u\r|_{\Ltwo}+\dfrac{1}{2}dL_F+L(T-nh-u)\l|\nabla\log p_{T-nh-u}(\tilde{Y}_u)\r|_{\Ltwo}\\
    \leqslant&\,\,\Big(\dfrac{1}{2}+L(T-nh-u)\Big)\left[L(T-nh-u)(\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+C_2(n))+\big(dL(T-nh-u)\big)^{1/2}\right]\\
    &+\dfrac{1}{2}L(T-nh-u)\Big(\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+C_2(n)+C_4\Big)\\
    &+\dfrac{1}{2}dL_F\,.
\end{align}
Therefore, we obtain
\begin{equation}
    \begin{aligned}
        &\l|\int_0^t\left(\int_0^s\partial_t\nabla\log p_{T-nh-u}(\tilde{Y}_u)-\partial_t\nabla\log p_{T-nh}(\tilde{Y}_0)\rmd u\right)\rmd s\r|_{\Ltwo}\\
        \leqslant& \int_0^t\int_0^s\l|\partial_t\nabla\log p_{T-nh-u}(\tilde{Y}_u)\r|_{\Ltwo}+\l|\partial_t\nabla\log p_{T-nh}(\tilde{Y}_0)\r|_{\Ltwo}\rmd u\rmd s\\
        \leqslant& \int_0^t\left(\int_0^s\left[(1+L(T-nh-u))L(T-nh-u)+(1+L(T-nh))L(T-nh)\right]\rmd u\right)\rmd s\cdot \l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}\\
        &+\int_0^t\left(\int_0^s\left[(1+L(T-nh-u))L(T-nh-u)+(1+L(T-nh))L(T-nh)\right]\rmd u\right)\rmd s\cdot C_2(n)\\
        &+\sqrt{d}\int_0^t\left(\int_0^s\left[(\dfrac{1}{2}+L(T-nh-u))L(T-nh-u)^{1/2}+(\dfrac{1}{2}+L(T-nh))L(T-nh)^{1/2}\right]\rmd u\right)\rmd s\\
        &+\int_0^t\left(\int_0^s\dfrac{1}{2}(L(T-nh-u)+L(T-nh))\rmd u\right)\rmd s\cdot C_4\\
        &+\dfrac{1}{2}dL_Ft^2\,.   \label{eq:SOterm4}
    \end{aligned}
\end{equation}
For simplicity, we focus on the lowest-order term. Recall equations \eqref{eq:SOterm1}, \eqref{eq:SOterm2}, \eqref{eq:SOterm3}, and \eqref{eq:SOterm4}, which lead to the following expression
\begin{align*}
    \l|\tilde{Y}_t-x_{nh+t}\r|_{\Ltwo}\leqslant& \Big(L(T-nh)-\dfrac{1}{2}\Big)\int_0^t\l|\tilde{Y}_s-x_{nh+s}\r|_{\Ltwo}\rmd s+\Big(A_{n,1}\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+A_{n,2}\Big)\cdot t^2,
\end{align*}
where
\begin{align*}
    A_{n,1}=\sup_{nh\leqslant t\leqslant (n+1)h}&\dfrac{1}{t^2}\int_0^t\left(\int_0^s\left[(1+L(T-nh-u))L(T-nh-u)+(1+L(T-nh))L(T-nh)\right]\rmd u\right)\rmd s,\\
    A_{n,2}=\sup_{nh\leqslant t\leqslant (n+1)h}&\dfrac{1}{t^2}\bigg[\int_0^t\left(\int_0^s\left[(1+L(T-nh-u))L(T-nh-u)+(1+L(T-nh))L(T-nh)\right]\rmd u\right)\rmd s\cdot C_2(n)\\
    &+\sqrt{d}\int_0^t\left(\int_0^s\left[(\dfrac{1}{2}+L(T-nh-u))L(T-nh-u)^{1/2}+(\dfrac{1}{2}+L(T-nh))L(T-nh)^{1/2}\right]\rmd u\right)\rmd s\\
    &+\int_0^t\left(\int_0^s\dfrac{1}{2}(L(T-nh-u)+L(T-nh))\rmd u\right)\rmd s\cdot C_4\bigg]\\
    &+\dfrac{\sqrt{2}}{4}L_F+\dfrac{3}{2}dL_F.
\end{align*}
By Lemma~\ref{lem:Gron2}, let
\begin{align*}
    z(t)&=\l|\tilde Y_t-x_{nh+t}\r|_{\Ltwo}\\
    \alpha(t)&=(A_{n,1}\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+A_{n,2})\cdot t^2\\
    \beta(t)&=L(T-nh)-\dfrac{1}{2}
\end{align*}
set $t_0=nh$, we then obtain
\begin{align*}
    \l|\tilde{Y}_h-x_{(n+1)h}\r|_{\Ltwo}&\leqslant (A_{n,1}\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+A_{n,2})h^2\exp\left((L(T-nh)-\dfrac{1}{2})h\right)\\
    &=A_{n,1}e^{(L(T-nh)-\frac{1}{2})h}h^2\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+A_{n,2}e^{(L(T-nh)-\frac{1}{2})h}h^2.
\end{align*}
Invoking display~\eqref{eq:SO1}, we  arrive at
\begin{align*}
    \l|\tilde{Y}_h-\vartheta_{n+1}^{\sf SO}\r|_{\Ltwo}&\leqslant\l|\tilde{Y}_h-x_{(n+1)h}\r|_{\Ltwo}+\l|\vartheta_{n+1}^{\sf SO}-x_{(n+1)h}\r|_{\Ltwo}\\
    &\leqslant A_{n,1}e^{(L(T-nh)-\frac{1}{2})h}h^2\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+A_{n,2}e^{(L(T-nh)-\frac{1}{2})h}h^2\\
    &\quad +\left[h\varepsilon_{sc}+\dfrac{2}{3}h^{3/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}h^2\varepsilon_{sc}^{(M)}\right]e^{(L(T-nh)-\frac{1}{2})h}
\end{align*}
Furthermore, we can bound the coefficients~$A_{n,1}$ and $A_{n,2}$ as follows.
\begin{align*}
    A_{n,1}&\leqslant\dfrac{1}{t^2}\int_0^t\left(\int_0^s2(1+L_{\max})L_{\max}\rmd u\right)\rmd s=(1+L_{\max})L_{\max},\\
    A_{n,2}&\leqslant(1+L_{\max})L_{\max}C_2(n)+\sqrt{d}(\dfrac{1}{2}+L_{\max})L_{\max}^{1/2}+\dfrac{1}{2}L_{\max}C_4+\dfrac{\sqrt{2}}{4}L_F+\dfrac{3}{2}dL_F\\
    &\lesssim\sqrt{d}(\dfrac{1}{2}+L_{\max})L_{\max}^{1/2}+\dfrac{3}{2}dL_F.
\end{align*}
Collecting all the pieces then gives
\begin{align*}
    \l|Y_{nh}-\vartheta_{n+1}^{\sf SO}\r|_{\Ltwo}\leqslant r_n^{\sf SO}\l|Y_{nh}-\vartheta_n^{\sf SO}\r|_{\Ltwo}+C_n^{\sf SO}h^2+\left[h\varepsilon_{sc}+\dfrac{2}{3}h^{3/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}h^2\varepsilon_{sc}^{(M)}\right]e^{(L(T-nh)-\frac{1}{2})h},
\end{align*}
where
\begin{align*}
    r_n^{\sf SO}&=e^{-\int_{nh}^{(n+1)h}(m(T-t)-\frac{1}{2})\rmd t}+A_{n,1}e^{(L(T-nh)-\frac{1}{2})h}h^2,\\
    C_n^{\sf SO}&=A_{n,2}e^{(L(T-nh)-\frac{1}{2})h}\,.
\end{align*}

\end{proof}
From the result above, we finally obtain
\begin{align*}
    \l|Y_{Nh}-\vartheta_N^{\sf SO}\r|_{\Ltwo}&\lesssim \dfrac{1}{m_{\min}-1/2}\left[h\max_{0\leqslant k\leqslant N-1}C_k^{\sf SO}+\left(\varepsilon_{sc}+\dfrac{2}{3}h^{1/2}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}h\varepsilon_{sc}^{(M)}\right)e^{(L_{\max}-\frac{1}{2})h}\right]\\
    &\lesssim h\cdot\dfrac{(\sqrt{d}L_{\max}^{3/2}+3dL_F/2)e^{(L_{\max}-\frac{1}{2})h}}{m_{\min}-1/2}+\left(\varepsilon_{sc}+\dfrac{2}{3}\sqrt{h}\varepsilon_{sc}^{(L)}+\dfrac{1}{2}h\varepsilon_{sc}^{(M)}\right)e^{(L_{\max}-\frac{1}{2})h}\,.
\end{align*}
This completes the proof of Theorem~\ref{thm:2order}.

\section{Proof of Auxiliary Lemma}
\subsection{Proof of Lemma~\ref{lem:Gaomt}}
We have
\begin{align*}
    \dfrac{\rmd\l|H_t-G_t\r|^2}{\rmd t}&=2 \inprod{H_t-G_t}{\dfrac{\rmd(H_t-G_t)}{\rmd t}}\\
    &=2 \inprod{ H_t-G_t}{\dfrac{1}{2}(H_t-G_t)+\big(\nabla\log p_{T-t}(H_t)-\nabla\log p_{T-t}(G_t)\big)}\\
    &=\l|H_t-G_t\r|^2+2\langle H_t-G_t,\nabla\log p_{T-t}(H_t)-\nabla\log p_{T-t}(G_t)\rangle\\
    &\leqslant \big(1-2m(T-t)\big)\l|H_t-G_t\r|^2.
\end{align*}
The last inequality follows from Lemma~\ref{lem:GaoLt}. 
Then, we take the derivative of $e^{-\int_{t_1}^t(2m(T-s)-1)\rmd s}\l|H_t-G_t\r|^2$
\begin{align*}
    &\dfrac{\rmd}{\rmd t} \Big(e^{\int_{t_1}^t(2m(T-s)-1)\rmd s}\l|H_t-G_t\r|^2\Big)\\
    =&\,\,(2m(T-t)-1)e^{-\int_{t_1}^t(2m(T-s)-1)\rmd s}\l|H_t-G_t\r|^2+e^{-\int_{t_1}^t(2m(T-s)-1)\rmd s}\dfrac{\rmd\l|H_t-G_t\r|^2}{\rmd t}\\
    \leqslant& \,\,0.
\end{align*}
Therefore, we obtain that
\begin{align*}
    e^{\int_{t_1}^t(2m(T-s)-1)\rmd s}\l|H_t-G_t\r|^2\leqslant \l|H_{t_t}-G_{t_1}\r|^2. 
\end{align*}
taking the expectation of both sides and then applying the square root yields the desired result.


\subsection{Proof of Lemma~\ref{lem:supYtY0}}
By the definition of $\tilde{Y}_h$, we have
\begin{align*}
    \l|\tilde{Y}_t-\tilde{Y}_0\r|_{\Ltwo}
    &=\left\lVert\int_0^t(\dfrac{1}{2}\tilde{Y}_s+\nabla\log p_{T-nh-s}(\tilde{Y}_s))\rmd s+\int_{nh}^{nh+t}\rmd W_s\right\rVert_{\Ltwo}\\
   & \leqslant \int_0^t\dfrac{1}{2}\l|\tilde{Y}_s\r|_{\Ltwo}\rmd t+\int_0^t\l|\nabla\log p_{T-nh-s}(\tilde{Y}_s)\r|_{\Ltwo}\rmd s+\left\lVert\int_{nh}^{nh+t}\rmd W_s\right\rVert_{\Ltwo}\,.
\end{align*}
To bound the first term, we observe that for any $s\in[0,h]$, the following holds
\begin{align*}
\l|\tilde{Y}_s\r|_{\Ltwo}
&\leqslant \l|Y_{nh+s}\r|_{\Ltwo}+\l|\tilde{Y}_s-Y_{nh+s}\r|_{\Ltwo}\\
    &\leqslant \l|Y_{nh+s}-X_{nh+s}^{\leftarrow}\r|_{\Ltwo}+\l|X_{nh+s}^{\leftarrow}\r|_{\Ltwo}+\l|\tilde{Y}_s-Y_{nh+s}\r|_{\Ltwo}\\
    &\leqslant e^{-\int_0^{nh+s}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_0-X_0^{\leftarrow}\r|_{\Ltwo}+\l|X_{T-(nh+s)}\r|_{\Ltwo}+e^{-\int_{nh}^s(m(T-u)-\frac{1}{2})\rmd u}\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\\
    &\leqslant  e^{-\int_0^{nh}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_0-X_T\r|_{\Ltwo}+\sup_{0\leqslant t\leqslant T}\l|X_t\r|_{\Ltwo}+\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}\,.
\end{align*}
Here, the second inequality follows from the \text{Gr{\"o}nwall} inequality applied on $\l|Y_{nh+s}-X_{nh+s}^{\leftarrow}\r|_{\Ltwo}$ and $\l|\tilde{Y}_s-Y_{nh+s}\r|_{\Ltwo}$, and the fact that $\l|X_t\r|_{\Ltwo}=\l|X_{T-t}^{\leftarrow}\r|_{\Ltwo}$.
To bound the second term, we need the following lemma.
\begin{lemma}
    \label{lem:Enabla}
    If the target distribution~$p_0$ satisfies Assumption~\ref{asm:p0scLipx}, it holds that
    \begin{align*}
        \l|\nabla\log p_{t}(X_t)\r|_{\Ltwo}\leqslant (dL(t))^{1/2}.
    \end{align*}
\end{lemma}
According to Lemma~\ref{lem:Enabla}, it follows that
\begin{align*}
    &\l|\nabla\log p_{T-nh-s}(\tilde{Y}_s)\r|_{\Ltwo}\\
    \leqslant&\,\,\l|\nabla\log p_{T-nh-s}(\tilde{Y}_s)-\nabla\log p_{T-nh-s}(X_{nh+s}^{\leftarrow})\r|_{\Ltwo}+\l|\nabla\log p_{T-nh-s}(X_{nh+s}^{\leftarrow})\r|_{\Ltwo}\\
    \leqslant& \,\,L(T-nh-s)\l|\tilde{Y}_s-X_{nh+s}^{\leftarrow}\r|_{\Ltwo}+(dL(T-nh-s))^{1/2}\\
    \leqslant&\,\,L(T-nh-s)\l|\tilde{Y}_0-X_{nh}^{\leftarrow}\r|_{\Ltwo}+(dL(T-nh-s))^{1/2}\\
    \leqslant&\,\,L(T-nh-s)\left(\l|\tilde{Y}_0-Y_{nh}\r|_{\Ltwo}+\l|Y_{nh}-X_{nh}^{\leftarrow}\r|_{\Ltwo}\right)+(dL(T-nh-s))^{1/2}\\
    \leqslant& \,\,L(T-nh-s)\left(\l|Y_{nh}-\vartheta_n^{\sf EM}\r|_{\Ltwo}+e^{-\int_0^{nh}(m(T-t)-\frac{1}{2})\rmd t}\l|Y_0-X_T\r|_{\Ltwo})+(dL(T-nh-s)\right)^{1/2}.
\end{align*}
Here, we use the fact that $\tilde{Y}_0=\vartheta_n^{\sf EM}$, and \text{Gr{\"o}nwall} inequality are used in the third inequality and the last one. This completes the proof.

\subsection{Proof of Lemma~\ref{lem:Brown1}}
For the stochastic integral of process $X$, we have
\begin{align*}
    \mathbb{E}(I_t(X))^2=\mathbb{E}\int_0^tX_u^2d\langle M \rangle_u.
\end{align*}
Then, we obtain 
\begin{align*}
    &\left\lVert\int_{nh}^{(n+U_n)h}\rmd W_t-\int_0^1\left(\int_{nh}^{(n+u)h}\rmd W_t\right)\rmd u\right\rVert_{\Ltwo}^2\\
    =&\,\,\mathbb{E}\left(\int_0^1\int_{nh}^{(n+1)h}-\textbf{1}_{\{U_n\leqslant u\}}\textbf{1}_{\{(n+U_n)h\leqslant t\leqslant (n+u)h\}}+\textbf{1}_{\{U_n>u\}}\textbf{1}_{\{(n+u)h\leqslant t\leqslant (n+U_n)h\}}\rmd W_t\rmd u\right)^2\\
    \leqslant&\,\,\int_0^1\mathbb{E}\left(\int_{nh}^{(n+1)h}-\textbf{1}_{\{U_n\leqslant u\}}\textbf{1}_{\{(n+U_n)h\leqslant t\leqslant (n+u)h\}}+\textbf{1}_{\{U_n>u\}}\textbf{1}_{\{(n+u)h\leqslant t\leqslant (n+U_n)h\}}\rmd W_t\right)^2\rmd u\\
    = & \,\,\int_0^1\left(\mathbb{E}\int_{nh}^{(n+1)h}\textbf{1}_{\{U_n\leqslant u\}}\textbf{1}_{\{(n+U_n)h\leqslant t\leqslant (n+u)h\}}+\textbf{1}_{\{U_n>u\}}\textbf{1}_{\{(n+u)h\leqslant t\leqslant(n+U_n)h\}}\rmd t\right)\rmd u\\
    = & \,\,\int_0^1\left(\mathbb{E}\left(\textbf{1}_{\{U_n\leqslant u\}}(u-U_n)h+\textbf{1}_{\{U_n>u\}}(U_n-u)h\right)\right)\rmd u\\
    =&\,\,h\int_0^1\Big(u^2-u+\dfrac{1}{2}\Big)\rmd u\\
    =&\,\,\dfrac{1}{3}h.
\end{align*}

\subsection{Proof of Lemma~\ref{lem:Gron2}}
Define the function $w(s)$ via
\begin{align*}
    w(s)=\exp\left(-\int_{t_0}^s\beta(r)dr\right)\int_{t_0}^s\beta(r)z(r)\rmd r,\quad \forall s\geqslant t_0.
\end{align*}
Differentiating this function gives
\begin{align*}
    w'(s)=\left(z(s)-\int_{t_0}^s\beta(r)z(r)\rmd r\right)\beta(s)\exp\left(-\int_{t_0}^s\beta(r)\rmd r\right)\leqslant \alpha(s)\beta(s)\exp\left(-\int_{t_0}^s\beta(r)\rmd r\right).
\end{align*}
Note that $w(t_0)=0$. Integrating the function $w$ from $t_0$ to $t$ yields
\begin{align*}
    w(t)\leqslant \int_{t_0}^t\alpha(s)\beta(s)\exp\left(-\int_{t_0}^s\beta(r)\rmd r\right)\rmd s.
\end{align*}
By the definition of $w(s)$, we also have
\begin{align*}
    \int_{t_0}^t\beta(s)z(s)\rmd s=\exp\left(\int_{t_0}^t\beta(r)\rmd r\right)w(t).
\end{align*}
Combining the previous two displays provides us with
\begin{align*}
    \int_{t_0}^t\beta(s)z(s)\rmd s\leqslant\int_{t_0}^t\alpha(s)\beta(s)\exp\left(\int_s^t\beta(r)\rmd r\right)\rmd s.
\end{align*}
By substituting this estimate into the inequality, we can obtain the first desired result.
Furthermore, if $\alpha$ is non-decreasing, then for any $s\leqslant t$, it holds that $\alpha(s)\leqslant \alpha(t)$.
This leads to 
\begin{align*}
    z(t)\leqslant \alpha(t)+\alpha(t)\int_{t_0}^t\beta(s)\exp\left(\int_s^t\beta(r)\rmd r\right)\rmd s.
\end{align*}
which can be simplified to
\begin{align*}
    z(t)\leqslant \alpha(t)\exp\left(\int_{t_0}^t\beta(r)\rmd r\right),\quad t\geqslant t_0.
\end{align*}
This completes the proof.

\subsection{Proof of Lemma~\ref{lem:Frob}}
Let $f \in C^3(\mathbb{R}^d)$ and assume that its Hessian matrix is $L_F$-Lipschitz continuous with respect to the Frobenius norm; that is, for all $x,y \in \mathbb{R}^d$ we have
\begin{align*}
    \l|\nabla^2 f(x) - \nabla^2 f(y)\r|_F \leqslant L_F \l|x-y\r|_2.
\end{align*}
Denote by $\{e_1, e_2, \cdots, e_d\}$ the standard orthonormal basis of $\mathbb{R}^d$. For any fixed $x \in \R^d$ and any index $i \in \{1,\cdots,d\}$, consider the directional derivative of the Hessian in the direction $e_i$:
\begin{align*}
    \partial_i \nabla^2 f(x) := \lim_{h \to 0} \frac{\nabla^2 f(x+he_i) - \nabla^2 f(x)}{h}.
\end{align*}
By the Lipschitz continuity of $\nabla^2 f$, for any nonzero $h$ we have
\begin{align*}
\l|\dfrac{\nabla^2 f(x+he_i) - \nabla^2 f(x)}{h}\r|_F \leqslant \dfrac{L_F |h|}{|h|} = L_F.
\end{align*}
Taking the limit as $h \to 0$ yields
\begin{align*}
    \l|\partial_i \nabla^2 f(x)\r|_F \leqslant L_F.
\end{align*}
Note that the matrix $\partial_i \nabla^2 f(x)$ is the $i$-th slice of the third-order derivative tensor $\nabla^3 f(x)$, its $(j,k)$-entry is $\dfrac{\partial^3 f(x)}{\partial x_i\,\partial x_j\,\partial x_k}$.

By the definition of Frobenius norm, we have
\begin{align*}
    \l|\nabla^3 f(x)\r|_F^2 = \sum_{i=1}^d \l|\partial_i \nabla^2 f(x)\r|_F^2\,.
\end{align*}
It then follows that
\begin{align*}
\l|\nabla^3 f(x)\r|_F^2 \leqslant \sum_{i=1}^d L_F^2 = d\,L_F^2.
\end{align*}
Taking the square root of both sides, we obtain
\begin{align*}
\l|\nabla^3 f(x)\r|_F \leqslant \sqrt{d}\, L_F.
\end{align*}
This completes the proof.

\subsection{Proof of Lemma~\ref{lem:Fokker}}
Notice that
\begin{align*}
    \nabla^2\log p_t(x)=&-\dfrac{1}{p_t(x)^2}\nabla p_t(x)\nabla p_t(x)^\top+\dfrac{1}{p_t(x)}\nabla^2p_t(x)\\
    =&-\nabla\log p_t(x)\nabla\log p_t(x)^\top+\dfrac{1}{p_t(x)}\nabla^2 p_t(x),
\end{align*}
which indicates
\begin{align*}
    \dfrac{1}{2}\sum_{i=1}^d\dfrac{\partial^2 p_t(x)}{\partial x_i^2}\cdot\dfrac{1}{p_t(x)}
    &=\dfrac{1}{2}\Tr\left(\dfrac{1}{p_t(x)}\nabla^2p_t(x)\right)\\
    &=\dfrac{1}{2}\Tr\Big(\nabla^2\log p_t(x)+\nabla\log p_t(x)\nabla\log p_t(x)^\top\Big)\\
    &=\dfrac{1}{2}\Tr\big(\nabla^2\log p_t(x)\big)+\dfrac{1}{2}\l|\nabla\log p_t(x)\r|^2,
\end{align*}
Additionally, we have
\begin{align*}
    \nabla\left(\dfrac{\partial^2\log p_t(x)}{\partial x_i^2}\right)&=\nabla\left(\dfrac{\partial^2p_t(x)}{\partial x_i^2}\cdot\dfrac{1}{p_t(x)}-\left(\dfrac{\partial p_t(x)}{\partial x_i}\cdot\dfrac{1}{p_t(x)}\right)^2\right)\\
    &=\nabla\left(\dfrac{\partial^2p_t(x)}{\partial x_i^2}\right)\cdot\dfrac{1}{p_t(x)}-\dfrac{\partial^2p_t(x)}{\partial x_i^2}\cdot\dfrac{1}{p_t(x)}\cdot\nabla\log p_t(x)-\nabla\left(\left(\dfrac{\partial\log p_t(x)}{\partial x_i}\right)^2\right)\,.
\end{align*}
Then, we obtain
\begin{align*}
    &\nabla\left(\sum_{i=1}^d\dfrac{\partial^2p_t(x)}{\partial x_i^2}\right)\cdot\dfrac{1}{p_t(x)}\\
    =&\nabla\left(\Tr(\nabla^2\log p_t(x))\right)+\left[\Tr(\nabla^2\log p_t(x))+\l|\nabla\log p_t(x)\r|^2\right]\cdot\nabla\log p_t(x)+\nabla(\l|\nabla\log p_t(x)\r|^2).
\end{align*}

\subsection{Proof of Lemma~\ref{lem:Enabla}}
Note that
\begin{align*}
    \mathbb{E}(\l|\nabla\log p_t(X_t)\r|^2)=&\int_{\mathbb{R}^d}\l|\nabla\log p_t(x)\r|^2p_t(x)\rmd x\\
    =&\lim_{R\to\infty}\int_{B(0,R)}\langle\nabla\log p_t(x),\nabla\log p_t(x)\rangle p_t(x)\rmd x\\
    =&\lim_{R\to\infty}\int_{B(0,R)}\langle\nabla\log p_t(x),\nabla p_t(x)\rangle \rmd x\,,
\end{align*}
where $B(0,R)$ denotes the Euclidean ball with radius $R>0$ centered at the origin.
Using integration by parts, we then obtain
\begin{align*}
    \mathbb{E}(\l|\nabla\log p_t(X_t)\r|^2)&=\lim_{R\to\infty}\int_{B(0,R)}-p_t(x)\Delta\log p_t(x)\rmd x+\int_{\partial B(0,R)}p_t(x)\dfrac{\partial \log p_t(x)}{\partial \vec{n}}\rmd S\\
    &=\int_{\mathbb{R}^d}p_t(x)\cdot(-\Delta\log p_t(x))\rmd x\\
    &\leqslant d L(t),
\end{align*}
where $\dfrac{\partial f}{\partial\vec{n}}=\nabla f\cdot\vec{n}$ represents the directional derivative along the normal vector $\vec{n}$ and $\rmd S$ denotes the surface integral over the spherical surface. Here we use the fact that $p_t(x)$ converges to $0$ at an exponential rate as $\l|x\r|$ approaches infinity, and the fact that
\begin{align*}
-\Delta\log p_t(x)=-\Tr(\nabla^2\log p_t(x))\in [0,dL(t)]  \,,
\end{align*}
which follows from Lemma~\ref{lem:GaoLt}.

\section{Numerical Studies}
\label{app:simulation}
We apply the five schemes to the posterior density of penalized logistic regression, defined by $p_0(\theta)\propto \exp(-f(\theta))$
with the potential function
\begin{align*}
	f(\theta)=\dfrac{\lambda}{2}\|\theta\|^2+\dfrac{1}{n_{\sf data}}\sum_{i=1}^{n_{\sf data}}\log(1+\exp(-y_ix_i^\top \theta)),
\end{align*}
where $\lambda>0$ denotes the tuning parameter. The data $\{x_i,y_i\}_{i=1}^{n_{\sf data}}$, composed of binary labels $y_i\in\{-1,1\}$ and features $x_i\in\mathbb{R}^d$ generated from $x_{i,j}\mathop{\sim}\limits^{iid}\mathcal{N}(0,\sigma^2)$.

\subsection{Calculation}
In this part, we derive explicit formulas for each coefficient term we need. First, the score function can be computed as
\begin{align*}
    \nabla\log p_0(\theta)
    &=-\left(\lambda \theta+\dfrac{1}{n_{\sf data}}\sum_{i=1}^{n_{\sf data}}\dfrac{-y_ix_i\exp(-y_ix_i^\top \theta)}{1+\exp(-y_ix_i^\top \theta)}\right)\\
    &=-\left(\lambda \theta+\dfrac{1}{n_{\sf data}}\sum_{i=1}^{n_{\sf data}}\dfrac{-y_ix_i}{1+\exp(y_ix_i^\top \theta)}\right).
\end{align*}
For simplicity, we denote the logistic sigmoid function $\sigma(u)=\dfrac{1}{1+e^{-u}}$, then
\begin{align*}
	\nabla\log p_0(\theta)=-\left(\lambda \theta+\dfrac{1}{n_{\sf data}}\sum_{i=1}^{n_{\sf data}}-y_ix_i\sigma(-y_ix_i^\top \theta)\right).
\end{align*}
Since $\sigma'(u)=\sigma(u)[1-\sigma(u)]$, we have
\begin{align*}
	\nabla^2\log p_0(\theta)
    =&-\left(\lambda I_d+\dfrac{1}{n_{\sf data}}\sum_{i=1}^{n_{\sf data}}y_i^2\sigma(-y_ix_i^\top \theta)\left[1-\sigma(-y_ix_i^\top \theta)\right]x_ix_i^\top\right)\\
	=&-\lambda I_d-\dfrac{1}{n_{\sf data}}\sum_{i=1}^{n_{\sf data}}\sigma(-y_ix_i^\top \theta)\left[1-\sigma(-y_ix_i^\top \theta)\right]x_ix_i^\top.
\end{align*}
As $x_ix_i^\top\succcurlyeq 0$, $\nabla^2\log p_0(\theta)\preccurlyeq-\lambda I_d$. We also have that $\sigma(1-y_ix_i^\top \theta)\in(0,1)$, then
\begin{align*}
	\nabla^2\log p_0(\theta)\succcurlyeq&-\lambda I_d-\dfrac{1}{4n_{\sf data}}\sum_{i=1}^{n_{\sf data}}x_ix_i^\top\\
    \succcurlyeq&-(\lambda+\dfrac{1}{n_{\sf data}}\lambda_{\max}(\sum_{i=1}^{n_{\sf data}}x_ix_i^\top))I_d\,.
\end{align*}
Therefore, 
\begin{align*}
	m_0=\lambda,\quad L_0=\lambda+\dfrac{1}{n_{\sf data}}\lambda_{\max}(\sum_{i}^{n_{\sf data}}x_ix_i^\top).
\end{align*}
Recall that the transition probability $p_{t|0}(\theta_t|\theta_0)=\phi(\theta_t;\mu_t,\Sigma_t)$, where $\mu_t=e^{-\frac{1}{2}t}\theta_0,\Sigma_t=(1-e^{-t})I_d$, and $\phi(\theta,\mu,\Sigma)$ denotes the probability density function of $\mathcal{N}(\mu,\Sigma)$, then we have
\begin{align*}
	p_t(\theta_t)&=\int_{\mathbb{R}^d}p_{t|0}(\theta_t|\theta_0)p_0(\theta_0)\rmd \theta_0\\
	&=\int_{\mathbb{R}^d}\dfrac{1}{\sqrt{(2\pi)^d|\Sigma_t|}}\exp(-\dfrac{1}{2}(\theta_t-\mu_t)^\top\Sigma_t^{-1}(\theta_t-\mu_t))p_0(\theta_0)\rmd \theta_0\\
	&=\int_{\mathbb{R}^d}\dfrac{1}{\left[2\pi(1-e^{-t})\right]^{d/2}}\exp(-\dfrac{1}{2(1-e^{-t})}\|\theta_t-e^{-\frac{1}{2}t}\theta_0\|^2)p_0(\theta_0)\rmd \theta_0\\
	&=\dfrac{1}{\left[2\pi(1-e^{-t})\right]^{d/2}}\mathbb{E}_{\theta_0\sim p_0}\left[\exp(-\dfrac{1}{2(1-e^{-t})}\|\theta_t-e^{-\frac{1}{2}t}\theta_0\|^2)\right]\,.
\end{align*}
Hence,
\begin{align*}
	\nabla p_t(\theta_t)&=\dfrac{1}{\left[2\pi(1-e^{-t})\right]^{d/2}}\mathbb{E}_{\theta_0\sim p_0}\left[\nabla\left(\exp(-\dfrac{1}{2(1-e^{-t})}\|\theta_t-e^{-\frac{1}{2}t}\theta_0\|^2)\right)\right]\\
	&=\dfrac{1}{\left[2\pi(1-e^{-t})\right]^{d/2}}\mathbb{E}_{\theta_0\sim p_0}\left[\exp(-\dfrac{1}{2(1-e^{-t})}\|\theta_t-e^{-\frac{1}{2}t}\theta_0\|^2)\cdot\dfrac{-(\theta_t-e^{-\frac{1}{2}t}\theta_0)}{1-e^{-t}}\right],\\
	\nabla^2 p_t(\theta_t)&=\dfrac{1}{\left[2\pi(1-e^{-t})\right]^{d/2}}\mathbb{E}_{\theta_0\sim p_0}\bigg[\exp(-\dfrac{1}{2(1-e^{-t})}\|\theta_t-e^{-\frac{1}{2}t}\theta_0\|^2)\\
    &\qquad\qquad\qquad\qquad\qquad\cdot\bigg(\dfrac{(\theta_t-e^{-\frac{1}{2}t}\theta_0)(\theta_t-e^{-\frac{1}{2}t}\theta_0)^\top}{(1-e^{-t})^2}-\dfrac{1}{1-e^{-t}}I_d\bigg)\bigg].
\end{align*}
We can approximate $p_t(\theta_t),\nabla p_t(\theta_t)$ and $\nabla^2 p_t(\theta_t)$ or even higher order derivative tensor of $p_t(\theta_t)$ by Monte Carlo method, therefore, we can compute score function and its high order derivative by
\begin{align*}
	\nabla\log p_t(\theta_t)=\dfrac{\nabla p_t(\theta_t)}{p_t(\theta_t)},\quad \nabla^2\log p_t(\theta_t)=\dfrac{\nabla^2 p_t(\theta_t)}{p_t(\theta_t)}-\dfrac{\nabla p_t(\theta_t)\nabla p_t(\theta_t)^\top}{p_t(\theta_t)^2}\,.
\end{align*}

\subsection{Implementation}
In the numerical studies, we set $T=10$, and the number of Monte Carlo iterations is chosen as the floor of $T/h$, where $h$ varies according to the step size indicated in the figure.
