\vspace{-1mm}
\section{Introduction}
\label{sec:intro} 
Metric-scale dense depth provides precise spatial structure of a scene, crucial for physically accurate applications such as 3D scene understanding~\cite{jiyeon2024unidvps}, 3D reconstruction~\cite{choe2021volumefusion}, and robotic grasping~\cite{viereck2017learning}. 
This depth information is essential for achieving reliable and robust performance across real-world perception and interaction, where 
failures can lead to significant risks.
However, acquiring dense metric depth map in practical settings is challenging, as depth measurements captured by depth sensing approaches -- long-range sensors (\eg, LiDAR)~\cite{Ma2017SparseToDense} 
and SLAM/VIO systems~\cite{wong2021unsupervised} -- are sparse 
potentially leading to safety risks.
To complement this limitation, depth completion has been studied, which aims to complete the dense metric depth map from sparse measurements.

However, depth completion is an ill-posed problem requiring prior knowledge and additional cues, \eg, RGB images as guidance~\cite{Ma2017SparseToDense, hu2021penet, guidenet, qiu2019deeplidar}. 
Previous studies~\cite{park2020nonlocal, zhang2023completionformer, wong2021unsupervised, wang2023lrru} 
have focused on learning how to propagate sparse metric depth into a dense map according to the color or texture proximity.
They are trained with paired dense depth maps and corresponding RGB images to learn 
depth affinity as prior knowledge, where
the depth affinity represents the relationship between depth values in a scene
based on spatial and structural features.
Since previous methods~\cite{zhang2023completionformer, wong2021unsupervised} focused on
learning depth affinity within in-domain settings, 
they exhibit poor depth affinity
in out-of-domain scenarios (see \Fref{fig:teaser}).
To address this, \citet{park2024testtime} 
proposed a test-time adaptation method that fine-tunes part of a pre-trained depth completion model using sparse depth.
Nevertheless, This approach is less effective in out-of-domain scenarios due to the limited generalizability of the base depth completion model.

With the emergence of foundation models~\cite{caron2021emerging, rombach2022highresolution}, which learn comprehensive knowledge from large image data (referred to as image prior), these models have been frequently utilized as powerful prior to improve generalizability, enabling them to be applicable across diverse tasks and domains~\cite{lee2024dmp, yang2023diffusion, liu2023grounding}.
We bring this versatile capability to the depth completion problem.
In this regime, we propose 
zero-shot depth completion via a test-time alignment,
which is generalizable to any domain by leveraging the rich semantic and structural understanding of the foundation model.

Specifically, we use pre-trained monocular depth diffusion models \cite{ke2023repurposing, gui2024depthfm} as depth prior, 
demonstrating generalizability and facilitating high-quality depth estimation.
Most monocular depth estimation models~\cite{Ranftl2022midas, ke2023repurposing, depthanything, gui2024depthfm} operate in the affine-invariant depth space, where depth values are consistent up to offset and scale.
While this approach enables training on large-scale dataset with diverse scene contents and varying camera intrinsics~\cite{ke2023repurposing}, it inherently introduces scale ambiguity, making fully accurate monocular metric depth estimation to be considered infeasible~\cite{yin2023metric}.
Meanwhile, depth completion is free from scale ambiguity thank to sparse measurements of metric depths, but lacks generalizability and depth quality~\cite{park2024testtime}.
Motivated by these trade-offs, we align the affine-invariant depth prior with sparse measurements in the metric depth space, achieving generalizable and well-structured depth completion.
By performing this alignment at test time, we can complete the metric depth map from any pair of RGB and synchronized sparse depth data, \ie, zero-shot.
Figure~\ref{fig:teaser} illustrates the robustness of our method in the out-of-domain scenarios.

To this end, we propose a test-time alignment method that guides the reverse sampling process of the diffusion model
by incorporating optimization loops to enforce the given sparse depth as hard constraints. 
We also introduce a prior-based outlier filtering method to ensure reliable measurements and a new loss function to maintain the structural prior inherent in the depth prior.
Our method demonstrates superior generalization ability across various domain datasets~\cite{silberman2012nyu, mccormac2017scenenet, sun2020waymo, caesar2020nuscene}, including both indoor and outdoor environments.
Our contribution points are as follows:

% Contribution points
\begin{itemize}
    \setlength\itemsep{0.3em}
    \item 
    We propose a novel zero-shot depth completion method that leverages foundation model prior to enhance domain generalization while capturing detailed scene structure.
    
    \item 
    We introduce a test-time alignment that uses sparse measurements as hard constraint to guide the diffusion sampling process, aligning with an affine-invariant depth prior.

    \item 
    We present a prior-based outlier filtering algorithm to improve the reliability of sparse measurements,
    enhancing the robustness of our method using 
    sparse depth guidance.    
\end{itemize}