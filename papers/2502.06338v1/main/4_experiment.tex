\input{Tables/efficiency}
\section{Experiments}
In this section, we demonstrate the effectiveness of our prior-based depth completion method in indoor (NYUv2~\cite{silberman2012nyu}, SceneNet~\cite{mccormac2017scenenet}, VOID~\cite{wong2020void}) and outdoor (Waymo~\cite{sun2020waymo}, nuScenes~\cite{caesar2020nuscene}, KITTI DC~\cite{uhrig2017sparsity}) scenarios, through both quantitative and qualitative evaluations. 
For evaluation, we use the Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE), both standard metrics in depth completion where lower values indicate better performance.
The results are reported in meters.
Further details are provided in the supplementary material.

\subsection{Domain Generalization}
\label{sec:exp_domain}
\Tref{tab:generalization} summarizes the domain generalization performance of our method and previous test-time adaptation methods~\cite{wang2021tent,wang2022continual, park2024testtime} on indoor (NYU, SceneNet) and outdoor (Waymo, nuScenes).
Across various datasets, our prior-based approach consistently achieves the best or second-best performance.
 Notably, unlike test-time adaptation methods relying on pre-trained depth completion models in metric depth space, our method operates in affine-invariant depth space while achieving impressive performance.
Additionally, we demonstrate the model generality of our method by applying it to two depth diffusion models, Marigold~\cite{ke2023repurposing} and DepthFM~\cite{gui2024depthfm}, as shown in \Tref{tab:generalization}.
\Tref{tab:efficiency} further presents the inference time of our method across base models and sampling steps, demonstrating its potential for improving efficiency with minimal performance.
We also observe that our method captures details on the scene, reflecting true performance and demonstrating robust domain generalization as shown in~\Fref{fig:qualitative_adapt_outdoor} and \ref{fig:qualitative_adapt_indoor}.
We provide additional qualitative results in supplementary material.
\input{Figures/qualitative_adapt_outdoor}
\input{Figures/qualitative_adapt_indoor}

In the outdoor datasets, the ground truth is obtained by accumulating LiDAR points after removing those corresponding to moving objects, which can lead to variations in the ground truth. 
For a more reliable benchmark, we use the ground truth provided by \citet{park2024testtime} for the Waymo and by \citet{huang2022pcacc} for the nuScenes.
In the supplementary material, we discuss in detail the differences in ground truth acquisition methods and their impact on the performance of depth completion methods.

\input{Tables/depthprior}
\subsection{Comparison with Depth-Prior-Based Methods}
We compare our depth-prior-based method, which leverages depth diffusion models~\cite{ke2023repurposing, gui2024depthfm}, with other depth completion methods utilizing depth foundation models.
Each method relies on different depth foundation models: VPP4DC~\cite{bartolomei2024vpp4dc} employs a stereo matching network~\cite{lipson2021raft}, DepthPrompting~\cite{park2024depthprompting} utilizes ResNet34~\cite{he2016resnet} to extract depth features~\cite{lu2020depth, qiu2019deeplidar}, and UniDC~\cite{park2024unidc} leverages DepthAnything~\cite{depthanything}. 
\Tref{tab:depthprior} shows the effectiveness of our method leveraging depth diffusion models.



\subsection{Comparison with Unsupervised Methods}
\input{Tables/sparse_only_table}
We compare our zero-shot depth completion method with unsupervised methods~\cite{wong2021unsupervised, ma2018self, wong2021scaffnet} trained on the split training dataset of each benchmark, \ie, in-domain training.
As shown in~\Tref{tab:unsup_comparison}, our method demonstrates favorable performance without dense depth data, multi-view, and in-domain training on KITTI DC and VOID. 
Additionally, our method achieves comparable performance when adopting manual filtering, that is, the outlier filtering method suggested by each benchmark.
Figure~\ref{fig:unsup_in} shows qualitative results of ours and unsupervised methods. 
Our method achieves higher-fidelity depth completion, preserving the depth affinity better than other unsupervised methods.

\subsection{Ablation Studies}
\input{Figures/unsup_in}
% \input{Tables/ablation_method}
% \input{Figures/r-ssim}
\input{Figures/ablation}
\Tref{tab:ablation_method} shows ablation studies to assess the efficacy of the test-time alignment method, R-SSIM loss, and outlier filtering algorithm.
The ablation studies are conducted on both indoor (VOID) and outdoor (KITTI DC) datasets.
Compared to other sampling methods, \ie, no guidance and the guided sampling~\cite{bansal2024universal}, the proposed test-time alignment method brings significant performance gain. The R-SSIM loss further enhances the performance and has a remarkable effect on preserving depth affinity.
The prior-based outlier filtering is more effective on the outdoor dataset 
than on the indoor dataset, as the sparse depth in the indoor dataset consists of
reliable points sampled from the ground truth.
We also qualitatively ablate the performance of the R-SSIM loss as shown in \Fref{fig:r-ssim}, highlighting how it effectively regularizes diffusion structural prior, leading to sharpen details.

