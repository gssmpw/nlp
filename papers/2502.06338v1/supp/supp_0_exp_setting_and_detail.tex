\section{Experiment Setting and Details}
\label{sec:dataset}
In this section, we provide the details of zero-shot depth completion via test-time alignment and dataset configuration of the divese test datasets.


\subsection{Test-Time Alignment Details in Our Method}
\noindent When we use Marigold~\cite{ke2023repurposing} for the affine-invariant depth diffusion model, our detailed settings are described below.
In the test-time alignment process, optimization starts after the first third of the total 50 reverse sampling steps and is performed every 5 steps thereafter.
Each optimization loop runs for 200 iterations. 
When we use DepthFM~\cite{gui2024depthfm} for the affine-invariant depth diffusion model, our detailed settings are described below.
DepthFM generally takes 1-2 steps for generative sampling acceleration. In the test-time alignment process, our optimization loop operates at all sampling steps. We present the results for each number of sampling steps in the main paper.

\noindent We set the weights of loss function, $\lambda_{smooth}$ and $\lambda_{r-ssim}$, to 0.2 and 0.3, respectively, and adjust them according to the dataset.
For high-resolution image data, such as from Waymo (1920x1280)~\cite{sun2020waymo} and nuScenes (1600x900)~\cite{caesar2020nuscene}, we optimize using $2\times$ downsampled images and then upsample them via bilinear interpolation. 
For our prior-based outlier filtering method, we segment superpixels into 200 segments. 



\input{supp_figures/nu_wrong}
\subsection{Dataset Configurations}
For the domain generalization experiments, we use NYUv2~\cite{silberman2012nyu} and SceneNet~\cite{mccormac2017scenenet} as indoor datasets and nuScenes~\cite{caesar2020nuscene} and Waymo~\cite{sun2020waymo} as outdoor datasets.
We strictly follow the dataset configurations for the test-time scenario as suggested in ProxyTTA~\cite{park2024testtime}.
For indoor datasets, sparse depth maps are generated using a SLAM/VIO style with the Harris corner detector~\cite{harris1988combined}, based on dense depth maps acquired from RGB-D sensors like the Microsoft Kinect or simulation systems.
For outdoor datasets, sparse depth maps are acquired through long-range sensors, such as LiDAR.

\input{supp_tables/nu_table}
