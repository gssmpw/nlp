% \input{supp_figures/waymo}
% \input{supp_figures/scenenet}
\input{supp_figures/qual_domain}

\section{Additional Qualitative Results}
In this section, we provide additional qualitative results corresponding to the experiments discussed in each subsection of the main paper.

\para{Domain generalization}
We provide additional qualitative results for dataset not covered in the main paper, such as SceneNet~\cite{mccormac2017scenenet} and Waymo~\cite{sun2020waymo}, in \Fref{fig:qual_scenenet} and \ref{fig:qual_waymo}.
Most existing pre-trained depth completion models tend to fail when faced with the difficult conditions typically encountered in real-world environments.
We also demonstrate the robust performance of our prior-based method in extreme environments, such as rain or nighttime, as shown in Fig.\ref{fig:qual_scenenet} and \ref{fig:qual_waymo}.
Additional results for these scenes will also be provided in the supplementary video.
% By mixing latents across consecutive frames, as suggested in [Reference], we can efficiently achieve temporally consistent results.
% % https://huggingface.co/docs/diffusers/using-diffusers/marigold_usage 이걸 레퍼런스로 달고싶습니다

\input{supp_figures/unsup_out}
\para{Comparison with unsupervised methods on KITTI}
In \Fref{fig:unsup_out}, we provide a qualitative comparison on the KITTI DC dataset, an outdoor dataset not included in the main paper. Despite using only a monocular RGB view and sparse depth, unlike previous unsupervised methods~\cite{ma2018self, wong2021unsupervised}, we also complete a well-structured depth map
% KITTI에 대해서 추가 결과 제공. - figure

% (Optional) 3D unproject결과 NuScene / nyu에 대해서 추가 제공 - figure
