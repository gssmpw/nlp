% \setcounter{footnote}{0} 
\definecolor{tabfirst}{rgb}{1, 0.7, 0.7} % red
\definecolor{tabsecond}{rgb}{1, 0.85, 0.7} % orange
\definecolor{tabthird}{rgb}{1, 1, 0.7} % yellow
\newcommand{\mystrut}{\rule[-0.4ex]{0pt}{1.7ex}}
\newcommand{\highlight}[2]{\colorbox{#1}{\mystrut#2}}

% \newcommand{\mystrut}{\rule[-0.2ex]{0pt}{0.5ex}}
% \newcommand{\highlight}[2]{\colorbox{#1}{\rule[-0.3ex]{0pt}{0.1ex}\strut #2}}

\begingroup
\setlength{\tabcolsep}{12pt}
\begin{table*}[t]
\centering
\renewcommand{\arraystretch}{1.1} % Adjust the row height factor
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{m{2.5cm} cc cc cc cc }
    \toprule
    \multirow{3}[3]{*}{Method} & \multicolumn{4}{c}{Indoor} & \multicolumn{4}{c}{Outdoor} \\
    \cmidrule(lr){2-5} \cmidrule(lr){6-9} 
    & \multicolumn{2}{c}{NYUv2} & \multicolumn{2}{c}{SceneNet}
    & \multicolumn{2}{c}{Waymo} & \multicolumn{2}{c}{nuScenes} \\
     \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
    & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE \\
    \midrule 
    % Sparse-to-Dense~\cite{Ma2017SparseToDense} & & &\\
     Pre-trained %\footnotemark[2]
     & 0.446 & 0.189 & 0.443 & 0.173
     & 2.821 & 1.514
     & 3.998 & 1.967 \\ 
     BNAdapt
     & 0.410 & 0.189 & 0.446 & 0.176
    & 2.194 & \cellcolor{tabthird}1.122
    & 1.801 & 0.828\\ 
     CoTTA
     & 0.376 & 0.147 & 0.405 & 0.136
     & 2.652 & 1.227
     & 2.668 & 1.222 \\ 
     ProxyTTA
     & \cellcolor{tabthird}0.203 & \cellcolor{tabthird}0.095 & \cellcolor{tabthird}0.357 & \cellcolor{tabthird}0.125
    & \cellcolor{tabthird}2.178 & \cellcolor{tabfirst}0.971
    & \cellcolor{tabthird}1.755 & \cellcolor{tabthird}0.799\\ 
    \midrule
    Ours~(+Marigold)
    & \cellcolor{tabsecond}0.149 & \cellcolor{tabfirst}0.059 & \cellcolor{tabsecond}0.207 & \cellcolor{tabsecond}0.099 
    & \cellcolor{tabfirst}2.115 & \cellcolor{tabsecond}1.121
    & \cellcolor{tabfirst}1.561 & \cellcolor{tabfirst}0.561\\
    Ours~(+DepthFM)
    & \cellcolor{tabfirst}0.145 & \cellcolor{tabsecond}0.077 & \cellcolor{tabfirst}0.178 & \cellcolor{tabfirst}0.081 
    & \cellcolor{tabsecond}2.162 & 1.133
    & \cellcolor{tabsecond}1.622 & \cellcolor{tabsecond}0.618\\
    % & \textbf{1.516} & \textbf{0.561} & \TODO{} & \TODO{} & \textbf{0.149} & \textbf{0.059} & 0.413 & 0.243 \\ 
    \bottomrule
    \end{tabular}
    }
\caption{\textbf{Quantitative comparison of generalizable performance.}
We evaluate the generalizability of our method by comparing it with test-time adaptation methods across various domain datasets.
% \textbf{Bold} denotes best and \textit{Italics} second-best. 
In this table, the pre-trained depth completion model is CostDCNet~\cite{kam2022costdcnet}, trained on KITTI DC for outdoor and VOID for indoor adaptation.
It is used for each adaptation method---BNAdapt~\cite{wang2021tent}, CoTTA~\cite{wang2022continual}, and ProxyTTA~\cite{park2024testtime}---excluding ours, for adapting to each domain.
The first best is marked in \highlight{tabfirst}{red}, the second in \highlight{tabsecond}{orange}, and the third in \highlight{tabthird}{yellow}.
}
\label{tab:generalization}
\vspace{-5pt}
\end{table*}
\endgroup





% % \setcounter{footnote}{0} 
% \definecolor{tabfirst}{rgb}{1, 0.7, 0.7} % red
% \definecolor{tabsecond}{rgb}{1, 0.85, 0.7} % orange
% \definecolor{tabthird}{rgb}{1, 1, 0.7} % yellow
% \newcommand{\mystrut}{\rule[-0.4ex]{0pt}{1.7ex}}
% \newcommand{\highlight}[2]{\colorbox{#1}{\mystrut#2}}

% % \newcommand{\mystrut}{\rule[-0.2ex]{0pt}{0.5ex}}
% % \newcommand{\highlight}[2]{\colorbox{#1}{\rule[-0.3ex]{0pt}{0.1ex}\strut #2}}

% \begingroup
% \setlength{\tabcolsep}{12pt}
% \begin{table*}[t]
% \centering
% \renewcommand{\arraystretch}{1.1} % Adjust the row height factor
%     \resizebox{0.9\linewidth}{!}{
%     \begin{tabular}{m{2.5cm} cc cc cc cc }
%     \toprule
%     \multirow{3}[3]{*}{Method} & \multicolumn{4}{c}{Indoor} & \multicolumn{4}{c}{Outdoor} \\
%     \cmidrule(lr){2-5} \cmidrule(lr){6-9} 
%     & \multicolumn{2}{c}{NYUv2} & \multicolumn{2}{c}{SceneNet}
%     & \multicolumn{2}{c}{Waymo\footnotemark[2]} & \multicolumn{2}{c}{nuScenes} \\
%      \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
%     & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE \\
%     \midrule 
%     % Sparse-to-Dense~\cite{Ma2017SparseToDense} & & &\\
%      Pre-trained %\footnotemark[2]
%      & 0.446 & 0.189 & 0.443 & 0.173
%      & 3.078 & 1.175
%      & 6.630 & 2.656 \\ 
%      BNAdapt
%      & 0.410 & 0.189 & 0.446 & 0.176
%     & \cellcolor{tabthird}1.877 & \cellcolor{tabthird}0.596
%     & 6.391 & 2.306\\ 
%      CoTTA
%      & \cellcolor{tabthird}0.376 & \cellcolor{tabthird}0.147 & \cellcolor{tabthird}0.405 & \cellcolor{tabthird}0.136
%      & 2.140 & 0.689
%      & \cellcolor{tabthird}6.099 & \cellcolor{tabthird}2.676 \\ 
%      ProxyTTA
%      & \cellcolor{tabsecond}0.203 & \cellcolor{tabsecond}0.095 & \cellcolor{tabsecond}0.357 & \cellcolor{tabsecond}0.125
%     & \cellcolor{tabfirst}1.580 & \cellcolor{tabfirst}0.466
%     & \cellcolor{tabfirst}5.509 & \cellcolor{tabfirst}2.062\\ 
%     \midrule
%     Ours
%     & \cellcolor{tabfirst}0.149 & \cellcolor{tabfirst}0.059 & \cellcolor{tabfirst}0.207 & \cellcolor{tabfirst}0.099 
%     & \cellcolor{tabsecond}1.873 & \cellcolor{tabsecond}0.590
%     & \cellcolor{tabsecond}5.876 & \cellcolor{tabsecond}2.499\\
%     % & \textbf{1.516} & \textbf{0.561} & \TODO{} & \TODO{} & \textbf{0.149} & \textbf{0.059} & 0.413 & 0.243 \\ 
%     \bottomrule
%     \end{tabular}
%     }
% \caption{\textbf{Quantitative comparison on generalizable performance.}
% We evaluate the generalizability of our method by comparing it with test-time adaptation methods on various domain datasets.
% % \textbf{Bold} denotes best and \textit{Italics} second-best. 
% In this table, the pre-trained depth completion model is CostDCNet~\cite{kam2022costdcnet}, trained on KITTI DC for outdoor and VOID for indoor adaptation.
% It is used for each adaptation method---BNAdapt~\cite{wang2021tent}, CoTTA~\cite{wang2022continual} and ProxyTTA~\cite{park2024testtime}---excluding ours, for adapting to each domain.
% The first best is \highlight{tabfirst}{red}, the second is \highlight{tabsecond}{orange}, and the third is \highlight{tabthird}{yellow}.
% }
% \label{tab:generalization}
% \vspace{-5pt}
% \end{table*}
% \endgroup

 % \footnotetext[2]{
 % The pre-trained model is CostDCNet~\cite{kam2022costdcnet}, trained on KITTI DC for outdoor and VOID for indoor adaptation. It is used for each adaptation method excluding ours, with reported performance using the best results from Park \etal~\cite{park2024testtime}.
 % }
