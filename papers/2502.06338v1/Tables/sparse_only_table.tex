\begin{table*}[t]
\centering
\renewcommand{\arraystretch}{1.1} 
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{m{3.6cm} ccc cc cc }
    \toprule
    \multirow{2}[2]{*}{Method} & \multicolumn{3}{c}{Features} & \multicolumn{2}{c}{KITTI DC} & \multicolumn{2}{c}{VOID} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} % column name mid rule
    & \makecell{Sparse Depth \\ Supervision} & 
    \makecell{Photometric \\ Consistency Loss} &
    \makecell{In-domain \\ Training} 
    & RMSE & MAE & RMSE & MAE \\
    \midrule 
    Self-S2D & {\textcolor{green(ncs)}{\cmark}}  &
    {\textcolor{green(ncs)}{\cmark}} (two-view)
    & 
    {\textcolor{green(ncs)}{\cmark}} 
    & 1.384 & 0.358 & 0.243 & 0.178\\ 
    VOICED & {\textcolor{green(ncs)}{\cmark}}
    &
    \phantom{--}{\textcolor{green(ncs)}{\cmark}} (multi-view)
    & 
    {\textcolor{green(ncs)}{\cmark}}  
    &
    1.230 & 0.308 & 0.169 & 0.085\\ 
    ScaffNet & {\textcolor{green(ncs)}{\cmark}}

    &
    \phantom{--}{\textcolor{green(ncs)}{\cmark}} (multi-view)
    & 
    {\textcolor{green(ncs)}{\cmark}} 
    &
    1.182 & 0.286 & 0.119 & 0.059\\ 
    KBNet & {\textcolor{green(ncs)}{\cmark}} 

    &
    \phantom{--}{\textcolor{green(ncs)}{\cmark}} (multi-view)
    & 
    {\textcolor{green(ncs)}{\cmark}} 
    &
    1.126 & 0.260 & 0.095 & 0.039\\ 
    SPTR & {\textcolor{green(ncs)}{\cmark}} 
    &
    \phantom{--}{\textcolor{green(ncs)}{\cmark}} (multi-view)
    & 
    {\textcolor{green(ncs)}{\cmark}} 
    &
    1.111 & 0.254 & 0.091 & 0.040\\ 
    \midrule
    Ours w/ ~Our Filtering & & & & 1.413 & 0.397 & 0.111& 0.044\\ 
    Ours w/ ~Manual Filtering & \multirow{-2}{*}{\textcolor{green(ncs)}{\cmark}} & \multirow{-2}{*}{\phantom{-}\textcolor{red}{\xmark} (monocular)} & \multirow{-2}{*}{\textcolor{red}{\xmark}} & 1.198 & 0.287 & 0.112& 0.045\\ 
    \bottomrule

    \end{tabular}
    }
   \vspace{-3pt}
\caption{\textbf{Quantitative comparison with unsupervised methods.}
Despite weaker settings, our method performs comparably to unsupervised methods (Self-S2D~\cite{ma2018self}, VOICED~\cite{wong2020void}, ScaffNet~\cite{wong2021scaffnet}, KBNet~\cite{wong2021unsupervised}, and SPTR~\cite{sptr}) when sparse depth, \ie the supervision signal, is reliable.
 To demonstrate this, we ablate two filtering methods: our prior-based filtering and manual filtering, which is the outlier filtering method suggested by each benchmark.
 % \hs{
 In this table, our method uses Marigold~\cite{ke2023repurposing} as the base model.}
% }
\label{tab:unsup_comparison}
\vspace{-2mm}
\end{table*}

