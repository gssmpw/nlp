\documentclass[reprint,aps,pre]{revtex4-2}

\usepackage{amsmath,amsfonts,amscd,amssymb,graphicx,subeqnar}

\input{z_vardef}

\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{upgreek}% Up greek
%\usepackage{subeqnar}
\usepackage[percent]{overpic}
\usepackage{color}
%\usepackage[justification=justified,format=plain]{caption}
%\usepackage{subcaption}
\usepackage{adjustbox}
%\usepackage[caption=false]{subfig}
\usepackage{rotating}
\usepackage{float}
\makeatletter
\let\newfloat\newfloat@ltx
\makeatother
\usepackage{algorithm}
\usepackage{algpseudocode}
\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\Input{\item[\algorithmicinput]}
\usepackage{soul}
\usepackage{stackengine}
\def\stackalignment{l}

\usepackage{tikz-cd} % for commutative diagram

\usepackage[hypertexnames=false,
            colorlinks=true,
            linkcolor=blue,
            citecolor=blue,
            urlcolor=blue]
            {hyperref} % blue hyperrefs

\usepackage{tikz}
\definecolor{red}{rgb}{0.8500, 0.3250, 0.0980}
\definecolor{green}{rgb}{0.4660, 0.6740, 0.1880}
\definecolor{yellow}{rgb}{0.9290, 0.6940, 0.1250}
\definecolor{blue}{rgb}{0, 0.4470, 0.7410}
%%%%% some new settings
\usepackage{titlesec}
\usepackage{colortbl}
\titleformat*{\subsection}{\bfseries\raggedright}
\setlength{\parskip}{10pt}
%\raggedend
\usepackage{makecell}
\usepackage{hyperref}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{Inverse Design with Dynamic Mode Decomposition}

\author{Yunpeng Zhu$^{1,*}$, Liangliang Cheng$^{2,*}$, Anping Jing$^{3}$, Hanyu Huo$^{4}$, Ziqiang Lang$^{5}$, Bo Zhang$^{3}$, J. Nathan Kutz$^{6,*}$}

\affiliation{$^{1,*}$School of Engineering and Material Science, Queen Mary University of London, London, E1 4NS, UK}
\affiliation{$^{2}$ENTEG, Faculty of Science and Engineering, University of Groningen, Groningen, 9747 AG, The Netherlands}
\affiliation{$^{3}$School of Mechanical Engineering, Ningxia University, Yinchuan, 750021, China}
\affiliation{$^{4}$School of Chemistry and Material Science, University of Science and Technology of China, Hefei, 230026, China}
\affiliation{$^{5}$\mbox{School of Electrical and Electronic Engineering, The University of Sheffield, Sheffield, S10 2TN, UK}}
\affiliation{$^{6,*}$Department of Applied Mathematics and Electrical and Computer Engineering, University of Washington, Seattle, WA USA} % 
\email{yunpeng.zhu@qmul.ac.uk; \\ liangliang.cheng@rug.nl; \\ kutz@uw.edu} 
   %\emai{dsashid@uw.edu}


\begin{abstract}
%
We introduce a computationally efficient method for the automation of inverse design in science and engineering.  Based on simple least-square regression, the underlying dynamic mode decomposition algorithm can be used to construct a low-rank subspace spanning multiple experiments in parameter space.  The proposed {\em inverse design dynamic mode composition} (ID-DMD) algorithm leverages the computed low-dimensional subspace to enable fast digital design and optimization on laptop-level computing, including the potential to prescribe the dynamics themselves.  Moreover, the method is robust to noise,  physically interpretable, and can provide uncertainty quantification metrics.  The architecture can also efficiently scale to large-scale design problems using randomized algorithms in the ID-DMD. The simplicity of the method and its implementation are highly attractive in practice, and the ID-DMD has been demonstrated to be an order of magnitude more accurate than competing methods while simultaneously being 3-5 orders faster on challenging engineering design problems ranging from structural vibrations to fluid dynamics. Due to its speed, robustness, interpretability, and ease-of-use, ID-DMD in comparison with other leading machine learning methods represents a significant advancement in data-driven methods for inverse design and optimization, promising a paradigm shift in how to approach inverse design in practice.
%
\end{abstract}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SECTION 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{INTRODUCTION} \label{intro}

%P1 - Overview and statement of what we do
Two of the most common tasks in engineering revolve around control and design. For inverse design, which is the focus of our work, empirical methods have been used since the invention of tools, i.e. trial-and-error and experimentation. Design of experiments~\cite{fisher1966design,martins2021engineering} was the first formal mathematical architecture and principled approach to the inverse design problem. Early efforts in design used governing equations, design principles and experiments in an integrated fashion to enact the design of experiments. In the last two decades, this process has been accelerated through advanced computational techniques (i.e. finite element methods) and their reduced order modeling counterparts~\cite{cook2007concepts,touze2021model}. More recently, data-driven methods and machine learning have allowed for training models on high-fidelity simulations in order to accelerate inverse design~\cite{Billings2003design,lu2021physics,li2023fourier,allen2022physical}. In this case, the training time can be computationally intensive, but deployment can then be efficient. Here, we introduce a new data-driven strategy which is a direct least-square regression to an optimized system model, i.e. there is no expensive training. The proposed {\em inverse design dynamic mode composition} (ID-DMD) algorithm leverages a computed low-dimensional linear subspace to enable fast digital design and optimization which is orders of magnitude faster than competing data-driven and computational design methods. ID-DMD is a significant new inverse design paradigm which shapes the design process and workflow 
%(i.e. it should be the first algorithm attempted in the inverse design optimization process) 
due to its demonstrated robustness, computational efficiency, scalability, ease of implementation, and interpretability. 


% P3 - inverse design traditional
Inverse design involves optimizing design parameters or system characteristics to meet specific performance goals. Over a long period of time, inverse design predominantly relied on empirical methods supported by the design of experiments~\cite{martins2021engineering}, established design principles~\cite{yan2019aerodynamic}, and governing equations, such as {\em Ordinary Differential Equations} (ODEs) and {\em Partial Differential Equations} (PDEs)~\cite{leveque2007finite}. However, these early techniques are either expensive or of low fidelity. Advanced computational techniques (i.e. finite difference, finite element, and boundary element)~\cite{gupta2022finite} have since addressed many of these shortcomings by enabling high-fidelity numerical simulations of complex systems. Accurate simulations allow designers to leverage optimal search algorithms~\cite{deb2012optimization}, such as Newton’s methods, Lagrange Multipliers, and evolutionary algorithms, to achieve target system properties within a given design space. Although reduced order models accelerate numerical simulations through dimensional reduction approaches, such as Principal Component Analysis (PCA)~\cite{lang2009reduced} and Proper Orthogonal Decomposition (POD)~\cite{ghoman2012pod}, inverse design based on numerical simulations remains inherently resource-intensive and time-consuming, especially for large-scale, multi-physics, and highly complex systems.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE1
  \begin{figure*}[t]
      \centering
      \includegraphics[width=\textwidth]{Fig1.png}
      \caption{
     The inverse design of airfoil pitched angle using ID-DMD. (a) Collect vorticity simulation data as snapshots across varying pitched angles $\theta$, with additional noise levels up to 15\%. (b) Identify ID-DMD to capture the underlying dynamics of the system. (c) Perform model validation by evaluating vorticity predictions at different pitched angles. (d) Utilize the validated ID-DMD for airfoil pitched angle optimization. The design target is to achieve a preferred wavelength $\lambda$, while minimizing the airflow power ${P}_\text{air}$ across the fluid filed within the blue dotted box. (e) The design is robust to noise and stable with narrow uncertainty boundaries.
      }
      \label{fig_1}
  \end{figure*}

% P4 - inverse design:  data-driven and ML
% cite PINNS, NIF, FNO, DeepO
The landscape of inverse design recently experienced a significant shift with the emergence of data-driven approaches and scientific machine learning. 
%
% P2 - AI + ML overivew in science
Advanced machine learning and AI algorithms are empowering machine intelligence broadly across science and engineering disciplines. Such algorithms are leveraging both data and computations in order to train algorithms which are currently being deployed and tested in real-world environments. The majority of these technologies have revolved around discovery, forecasting (time-series) and control. Typical machine learning approaches, such as Convolutional Neural Networks (CNN)~\cite{gu2018recent}, deep reinforcement learning~\cite{sutton2018reinforcement} and deep Model Predictive Control (MPC)~\cite{lenz2015deepmpc}, improve decision-making and system control in games~\cite{silver2018general}, robotics~\cite{kober2013reinforcement}, industrial automation~\cite{salzmann2023real}, and process control~\cite{lenz2015deepmpc}. Moreover, generative learning approaches that include Autocoder-based methods (latent space roll outs)~\cite{schmidt2009distilling} and
transformer and foundation models~\cite{khan2022transformers,bommasani2021opportunities} enable large data analysis for language processing~\cite{wolf2020transformers}, computer vision~\cite{khan2022transformers}, and speech recognition~\cite{kim2022squeezeformer}. However, all these algorithms require large training data sets and are rarely applied to system designs. Further, they are expensive to train and largely black-box.

In regard to design, machine learning and AI algorithms develop surrogate models that act as efficient simulators, replacing complex numerical simulations to expedite the inverse design process. A dominant approach within this domain is operator learning, which includes approaches such as Physics-Informed Neural Networks (PINNs)~\cite{lu2021physics}, Deep Operator Networks (DeepONet)~\cite{lu2022multifidelity}, Neural Implicit Flow (NIF)~\cite{pan2023neural} and Fourier Neural Operators (FNOs)~\cite{li2023fourier}. One may employ PINNs as a solver when the governing differential equations of a system are known in advance. In contrast, DeepONet, NIF, and FNO were designed to learn system dynamic responses, purely rely on data, and function as a simulator. Specifically, DeepONet introduces a unique architecture comprising two sub-networks: the branch net, which processes input functions and initial conditions, and the trunk net, which handles output locations and design parameters~\cite{shukla2024deep}. This framework allows DeepONet to predict system dynamics by integrating information from the branch and trunk nets, enabling applications in system design. The NIF extends DeepONet by utilizing fully connected architectures for both the branch and trunk networks, enhancing its flexibility and generalization capabilities. Furthermore, FNO incorporates the Fourier transform into its network architecture, enabling it to learn resolution-invariant operators~\cite{kovachki2021universal}. In its continuous form, FNO can be seen as a special case of DeepONet~\cite{lu2022comprehensive}. Recently, DeepMind introduced a data-driven inverse design method using Graph Neural Networks (GNN)~\cite{allen2022physical}. The GNN-based design integrates finite element meshes with GNN to facilitate efficient geometry and shape optimization for fluid dynamic systems. The existing data-driven inverse design approaches have demonstrated efficiency in inverse design once the networks are properly trained~\cite{zhang2024blending}. However, their complex structures often lead to slow training and simulation processes using high-performance computers relying on GPU or TPU computations. Furthermore, the black-box nature of neural networks limits their physical interpretability, which can impede their ability to generate robust and reliable designs when working with noisy data.


% P5 - what we do -- list out benefits and background DMD
Unlike conventional neural network-based data-driven methods, {\em Dynamic Mode Decomposition} (DMD)~\cite{brunton2022data} offers a distinctive network-free approach for capturing complex system dynamics through a linear operator approximation. The DMD enables a state-space representation of dynamic systems that can be readily applied for system analysis and control~\cite{tu2013dynamic,proctor2016dynamic,lusch2018deep,han2020dynamic}. Yet, no results have demonstrated the application of DMD in the inverse design of dynamic systems. In this work, we propose an ID-DMD algorithm that designers should first attempt on a personal device (i.e. laptop) before developing more complicated approaches.  
%
The algorithm, which is illustrated in Fig.\ref{fig_1} and detailed in the results, demonstrates the ID-DMD optimization for the shape of a simple pitched airfoil. 
%
The ID-DMD applies simple least-square regression to best-fit linear dynamics across different design parameters. It utilizes a low-rank subspace encompassing multiple experimental parametrizations to enhance computational efficiency. Moreover, the ID-DMD explicitly reconstructs system dynamics with stable modes to ensure reliability. The efficiency and accuracy of the ID-DMD allow the use of optimization algorithms for the fit-for-purpose inverse design in a similar way to numerical design. The results demonstrate that ID-DMD offers several advantages:

\noindent (i) The ID-DMD enables efficient CPU-based training that is orders of magnitude faster and an order more accurate than existing data-driven approaches. 

\noindent (ii) The ID-DMD is scalable in order to handle complex design challenges across different types of challenging data from structural vibrations to fluid dynamics.

\noindent (iii) The ID-DMD is physically interpretable, securing long-term predictions over time and extrapolation of design parameters outside the training range.

\noindent (iv) The ID-DMD demonstrates robustness to noise and can provide uncertainty quantification metrics using integrated bagging methods.

\noindent (v) The ID-DMD uniquely enables the design of system by prescribing intrinsic  dynamics rather than just output responses. 

\noindent
These demonstrated advantages in speed, robustness, interpretability, and ease-of-use, make ID-DMD a significant advancement in data-driven methods for inverse design and optimization, especially in comparison with other leading paradigms of PINNs, FNO, DeepONet, and NIF.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SECTION 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{RESULTS}

Denote  $\{\mathbf{x}_{k},\mathbf{x}_{k-1}\}\in \mathbb{R}^{m}$ is a pair of time-evolving snapshots that represent the system's states,  where $m$ is the dimension of the state vector,  $k$ represents the discrete time, $\mathbf{x}_{k}=\mathbf{x}(k\Delta t)$ with the sampling time $\Delta t$. The best-fit linear operator between the snapshot pairs, known as a DMD approximation, represents the system’s underlying dynamics by a linear model. In ID-DMD, the linear operator is parametrized as a linear-in-parameter matrix, such that the ID-DMD representation of a dynamic system is written as

\begin{equation}  
\begin{aligned}
  & \mathbf{x}_{k}=(\mathbf{A}_{0}+{\varepsilon_{1}}{\mathbf{A}_{1}}+{\varepsilon_{2}}{\mathbf{A}_{2}}+\cdots ){\mathbf{x}_{k-1}} \\ 
\end{aligned} \label{eq1}
\end{equation}

\noindent where $\mathbf{A}_{0},\mathbf{A}_{1},\mathbf{A}_{2},...\in {{\mathbb{R}}^{m\times m}}$ are linear operators that relate the two state vectors $\mathbf{x}_{k}$ and $\mathbf{x}_{k-1}$;  and $\varepsilon_{1},\varepsilon_{2},\ldots$ are the system design parameters. Eq.(\ref{eq1}) is also known as a parametric state space model~\cite{benner2015survey} in control theory for discrete-time systems.

The primary goal of the ID-DMD is to identify linear operators that comprehensively capture system dynamics, enabling accurate predictions of system responses across different design parameters. Here, we utilize a Singular Value Decomposition (SVD)-based dimensional reduction approach\cite{brunton2016compressed} to directly identify a low-rank sub-space representation of the high-dimensional ($m\times m$) linear operator.  We evaluate the dominant eigenvectors ${{\bm{\upphi}}_{j}}$ and eigenvalues ${{s}_{j}}$ of the linear operator ${\mathbf{A}_{0}}+{{\varepsilon}_{1}}{\mathbf{A}_{1}}+{{\varepsilon }_{2}}{\mathbf{A}_{2}}+\cdots$ , where $j\in {{\mathbb{Z}}^{+}}$ represents the order of the modes ranging from 1 to a sufficiently high rank (See Methods and \textcolor{blue}{Section 1 in Supplementary Materials}) so as to enable the prediction of the system states through

\begin{equation}  
\mathbf{x}_{k}=\sum\limits_{j\in {{\mathbb{Z}}^{+}}}{{{\bm{\upphi}}_{j}}{{\text{e}}^{{{s}_{j}}(k-1)}}{{b}_{j}}}=\mathbf{\Phi}\exp [\mathbf{S}(k-1)]\mathbf{b} \label{eq2}
\end{equation} 

\noindent where $\mathbf{b}={{\mathbf{\Phi}}^{\dagger}}{{\mathbf{x}}_{1}}$ with ${\mathbf{x}}_{1}$ representing the initial states of the system; $\mathbf{S}$ is a diagonal matrix containing the complex frequencies ${s}_{j}=\sigma_{j}+\text{j}{\omega_{j}}$ with $\omega_{j}$ being the frequency and $\sigma_{j}$ being the decay rate.

For nonlinear systems, we apply the Koopman operator theory\cite{nathan2018applied} to project the system’s state measurements into a higher-dimensional space. This projection enables the approximation of the system’s nonlinear dynamics in a linear space. In this case, the ID-DMD representation for nonlinear systems is:

\begin{equation}
\psi({{\mathbf{x}}_{k}})=({{\mathbf{A}}_{{\upkappa},{0}}}+{{\varepsilon }_{1}}{\mathbf{A}_{{\upkappa},{1}}}+{{\varepsilon }_{2}}{\mathbf{A}_{{\upkappa},{2}}}+\cdots)\psi({{\mathbf{x}}_{k-1}}) \label{eq3}
\end{equation}

\noindent where $\psi$ is known as observables mapping the states ${{\mathbf{x}}_{k}}$ to a high-dimensional space. The Koopman operators ${{\mathbf{A}}_{{\upkappa},{0}}},{\mathbf{A}_{{\upkappa},{1}}},{\mathbf{A}_{{\upkappa},{2}}},...$ are linear operators acting on the observables.

An optimization problem can then be formulated for the inverse design of either state-related performances (e.g., output amplitude, power) or intrinsic dynamic properties (e.g., natural frequencies, stability)~\cite{zhu2017design} as:

\begin{equation}
\bm{\upepsilon}_\text{d}=\arg \underset{{\bm{\upepsilon}_{\min}}\le \bm{\upepsilon}\le {{\bm{\upepsilon}}_{\max}}}{\mathop{\min}}\,L(\bm{\upepsilon})\ \ \ \ \text{s}\text{.t}\text{.}\ g(\bm{\upepsilon})\le 0,\ h(\bm{\upepsilon})=0  \label{eq4}
\end{equation}

\noindent where $\bm{\upepsilon}=\{{{\varepsilon}_{1}},{{\varepsilon}_{2}},\ldots \}$ is the design variable vector, $\bm{\upepsilon}_{\min}$ and $\bm{\upepsilon}_{\max}$ are the lower bounds and upper bounds of the design parameters, respectively. $\bm{\upepsilon}_\text{d}$ is the optimal design result. $L(\bm{\upepsilon})$ is the loss function for the optimal design problem.  $g(\bm{\upepsilon})$ and $h(\bm{\upepsilon})$ are inequality and equality constraints, respectively. Optimal searching algorithms can be applied to achieve optimal solutions tailored to the desired system performance. 
%

In the following studies, we will demonstrate that the ID-DMD can effectively represent a wide range of complex dynamic systems, including those with both low- and high-dimensional properties. The ID-DMD offers a significant advancement by simplifying the data-driven modeling process while maintaining high efficiency, interpretability and precision, making it a powerful tool for modern inverse design and optimization.

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% SUB-SECTION 2.1
\subsection{Inverse Design of Airfoil Pitched Angle}

The airfoil geometry and shape optimization is a typical example of the inverse design of a complex dynamic system\cite{secanell2006design,de2019airfoil}, making it an ideal case to illustrate the overall design process using ID-DMD.  Here, we demonstrate the design of airfoil pitched angle $\theta$ through the ID-DMD in Fig.\ref{fig_1}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE1
%  \begin{figure*}[t]
%      \centering
%      \includegraphics[width=\textwidth]{Fig1.png}
%      \caption{
%     The inverse design of airfoil pitched angle using ID-DMD. (a) Collect vorticity simulation data as snapshots across varying pitched angles $\theta$, with additional noise levels up to 15\%. (b) Identify ID-DMD to capture the underlying dynamics of the system. (c) Perform model validation by evaluating vorticity predictions at different pitched angles. (d) Utilize the validated ID-DMD for airfoil pitched angle optimization. The design target is to achieve a preferred wavelength $\lambda$, while minimizing the airflow power ${P}_\text{air}$ across the fluid filed within the blue dotted box. (e) The design is robust to noise and stable with narrow uncertainty boundaries.
%      }
%      \label{fig_1}
%  \end{figure*}

In this example, the shape of the airfoil is simplified to an ellipse as demonstrated in \textcolor{blue}{Fig.S1}. The airflow around the ellipse is simulated at several different pitch angles across the design space ranging from $\theta \in [2, 12]^\circ$ . The training datasets for ID-DMD modeling are snapshots of the steady-state vorticity, spanning  $t\in [20, 50]\text{s}$ at uniformly distributed angles $\theta =\{2, 4, 6, 8, 10, 12\}^\circ$.  

We assume the target airflow dynamics exhibit minimum power ${P}_\text{air}$ with a specified wavelength requirement of $\lambda>3.35$. Here, ${P}_\text{air}$ is defined as the root mean value of the sum square vorticity over time. The optimal airfoil pitched angle that meets the required dynamic properties is obtained as $\theta=7^\circ$ by solving the optimization problem in  Fig.\ref{fig_1}(d). The predicted vorticities at the designed angle are shown in \textcolor{blue}{Fig.S2}. In addition, we also quantify the uncertainties of the ID-DMD-based design using the bagging approach\cite{sashidhar2022bagging}. The results show that (i) ID-DMD can reliably predict vorticities at any pitch angle within the design space, even in the presence of significant noise, and (ii) ID-DMD maintains stability with narrow uncertainty boundaries across the design space.

The ID-DMD approach significantly accelerates the inverse design process for complex dynamic systems. In this example, the greedy search design based on the ID-DMD ($\sim$30s) is about 100 times faster compared to that of finite element simulations executed via CPU computation (Intel Core i7 @ 1.20GHz) using MATLAB. Details of the modeling and design process are discussed in \textcolor{blue}{Section 2 in Supplementary Materials}.

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% SUB-SECTION 2.2
\subsection{Applications to Challenging Dynamic Systems}
Tab.\ref{tab.1} applies the proposed ID-DMD to a wide range of challenging dynamic systems from physics to engineering applications. The selected examples are from simulation and experimental studies, covering linear and nonlinear dynamics and transient to periodic behaviors.

The selected systems in the first two rows of Tab.\ref{tab.1}, involving a nonlinearly damped building and a Van de Pol equation, are of low-dimension with the number of snapshots exceeding the number of states. The following examples from the incident jet to droplet control represent high-dimensional dynamic systems, where the number of snapshots is smaller than the number of states. Settings for the ID-DMD modeling are listed in \textcolor{blue}{Tabs.S1-S7}. The prediction results in Tab.\ref{tab.1}, as well as \textcolor{blue}{Figs.S3-S6}, show that the ID-DMD accurately reconstructs a wide range of complex dynamic systems under design parameters that were not seen in the training data.  Notably, the droplet control in the final row is an experimental study,  The experimental setup is shown in \textcolor{blue}{Fig.S7}, and the results illustrate the method’s potential for practical engineering applications. 

The approach can scale with randomized SVD algorithms~\cite{halko2011finding} or parallel QR~\cite{eiximeno2024pylom} to effectively study significantly high-dimensional systems, including 3D spatio-temporal dynamics and multi-modality data. Further details on the ID-DMD representation for all examples are provided in the \textcolor{blue}{Section 3 in Supplementary Materials}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TABLE 2.1-2
%\newpage
%\onecolumngrid
  \definecolor{Myellow}{rgb}{0.8,0.75,0.4}
  \linespread{1.5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Table 2.1 design
  \begin{table*}[!htb] 
    \begin{minipage}{\textwidth}
      \centering    
\noindent
\caption{Application of ID-DMD to complex dynamic systems}
\label{tab.1}

    \begin{tabular}{p{2.4cm} p{6.4cm} p{8.6cm}}

\rowcolor{Myellow!50}
\hline
\makecell[c] {Systems} & \makecell[c] {ID-DMD} & \makecell[c]{Validation} \\

\hline
\makecell[c]{Nonlinear \\ building}
& \makecell[l]{
$\psi (\mathbf{x}_{k})=(\mathbf{A}_{\upkappa,{0}}+{c_\text{non}}{\mathbf{A}_{\upkappa,{1}}})\psi (\mathbf{x}_{k-1})$ \\
$c_\text{non}$ - Nonlinear damping ratio
} & \makecell[c]{
\includegraphics[width=0.45\textwidth]{Tab1_3.png} 
} \\

\rowcolor{Myellow!10}
\makecell[c]{Van de Pol}
& \makecell[l]{
$\psi (\mathbf{x}_{k})=({\mathbf{A}_{\upkappa,{0}}}+\mu {\mathbf{A}_{\upkappa,{1}}}+\bar\omega {\mathbf{A}_{\upkappa,{2}}})\psi (\mathbf{x}_{k-1})$ \\
$\mu$ - Nonlinear parameter \\
$\bar\omega$ - Frequency component
}& \makecell[c]{
\includegraphics[width=0.45\textwidth]{Tab2_3.png} 
} \\

\makecell[c]{Incident-jet}
& \makecell[l]{
${{\mathbf{x}}_{k}}=(\mathbf{A}_0+k_\text{t}{\mathbf{A}_1}){{\mathbf{x}}_{k-1}}$ \\
$k_\text{t}$ - Thermal conductivity
}
& \makecell[c]{
\includegraphics[width = 0.46\textwidth]{Tab3_3.png}
} \\

\rowcolor{Myellow!10}
\makecell[c]{1-D Burgers'}
& \makecell[l]{
${{\mathbf{x}}_{k}}=(\mathbf{A}_0+v{\mathbf{A}_1}){{\mathbf{x}}_{k-1}}$ \\
$v$ - Viscosity
}
& \makecell[c]{
\includegraphics[width = 0.46\textwidth]{Tab4_3.png}
} \\

\makecell[c]{Cavity flow} 
& \makecell[l]{
${\mathbf{x}_{k}}=(\mathbf{A}_0+v_\text{s}{\mathbf{A}_1}+R_\text{e}{\mathbf{A}_2}){\mathbf{x}_{k-1}}$\\
$v_\text{s}$ - Flow speed \\
$R_\text{e}$ - Reynolds number
}
& \makecell[c]{
\includegraphics[width = 0.46\textwidth]{Tab5_3.png}
} \\

\rowcolor{Myellow!10}
\makecell[c]{Smoke plume}
& \makecell[l]{
${\mathbf{x}_{k}}=(\mathbf{A}_0+r_\text{d}{\mathbf{A}_1}){\mathbf{x}_{k-1}}$ \\
$r_\text{d}$ - Radius of the light
}
& \makecell[c]{
\includegraphics[width = 0.46\textwidth]{Tab6_3.png}
} \\

\makecell[c]{Droplet control}& \makecell[l]{
${\mathbf{x}_{k}}=(\mathbf{A}_0+{{V}_{\text{t}}}{\mathbf{A}_1}){\mathbf{x}_{k-1}}$ \\
$V_\text{t}$ - Driving voltage
}
& \makecell[c]{
\includegraphics[width = 0.46\textwidth]{Tab7_3.png}
} \\

\hline
\end{tabular}
      
    \end{minipage}
  \end{table*}
\linespread{1}
%\vspace{4mm}
%\twocolumngrid

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% SUB-SECTION 2.3
\subsection{Extrapolation Capacity and Efficiency}

The proposed ID-DMD method allows for extrapolation across both time and design parameter spaces. This property demonstrates the fundamental difference between the ID-DMD and other machine learning approaches. In this section, we discuss the ID-DMD representation of 1-D Burgers’ equation, comparing it with various operator learning approaches involving PINNs, NIF, Physics-Informed DeepONet (PI-DON), and FNO. All these approaches are extended to enable the parametric simulation of dynamic systems as illustrated in \textcolor{blue}{Fig.S8} and \textcolor{blue}{Tab.8}.

The 1-D Burgers’ equation is defined as~\cite{wang2021learning}:

\begin{equation}
\left\{ \begin{aligned}
  & \frac{\partial s}{\partial t}+s\frac{\partial s}{\partial x}-v\frac{{{\partial}^{2}}s}{\partial {x^{2}}}=0 \\ 
 & s(x,0)=u(x) \\ 
\end{aligned} \right.,\ x\in [0,1] \label{eq5}
\end{equation}

\noindent with periodic boundary conditions

\begin{equation}
s(0,t)=s(1,t)\  \text{and}\  \frac{\partial s(0,t)}{\partial x}=\frac{\partial s(1,t)}{\partial x} \label{eq6}
\end{equation}

\noindent where the initial condition $u(x)$ is generated from a Gaussian random field $u\sim N(0,{{25}^{2}}{{(-\Delta +{{5}^{2}}\mathbf{I})}^{-2}})$ satisfying the periodic boundary conditions. Here, $\Delta$ is the Laplacian operator, and $\mathbf{I}$ is the identity matrix.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE4
\begin{figure*}[!t]
      \centering
      \includegraphics[width=\textwidth]{Fig2.png}
      \caption{
       Interpolation and extrapolation of the 1-D Burgers’ equation using the ID-DMD, PI-DON, PINNs, NIF, and FNO.  (a) Interpolation prediction results for $v=0.02$ and $t\in [0,1]\text{s}$ using different advanced data-driven methods. (b) Relative errors for the interpolation results. (c) Extrapolation prediction results for $v=0.01$ and $t\in [0,3]\text{s}$ using different advanced data-driven methods. (d) Relative errors for the extrapolation results. 
      }
      \label{fig_2}
\end{figure*}

Fig.\ref{fig_2}  presents a comprehensive comparison of prediction performance across five advanced methods: ID-DMD, PI-DON, PINNs, NIF, and FNO. All models are trained under the same initial conditions, spanning $v\in \left[ 0.014,0.046 \right]$ and $t\in [0,1]\text{s}$ , with spatial resolution defined as $x=[0:0.1:1]$. We examine both the interpolation ($v=0.02$ and $t\in [0,1]\text{s}$ ) and extrapolation ($v=0.01$ and $t\in [0,3]\text{s}$)  performances. Notably, the proposed ID-DMD consistently outperforms its counterparts, delivering the most precise prediction results across both tasks. 

In the interpolation task, all five methods demonstrate strong predictive accuracy for the responses of the Burgers' equation. While the PINNs shows the highest maximum relative error among the approaches, its overall prediction performance remains satisfactory and reliable.

For the extrapolation task, it is evident that all network-based methods (PI-DON, PINNs, NIF, and FNO) struggle with long-term predictions. In contrast, the ID-DMD method excels due to its physically meaningful approach to predicting time series data based on dynamic modes. These modes effectively capture the underlying system dynamics, whereas network-based approaches treat time as a static variable, making long-term prediction a challenging extrapolation problem. 

In general, systems that exhibit periodic or damped behavior can be accurately represented by a finite number of modes, enabling ID-DMD to achieve reliable long-term predictions.  Additionally, the linear-in-parameter structure of the ID-DMD model ensures stable extrapolation over design parameters, further highlighting its robustness and effectiveness in studying dynamic systems.

The ID-DMD demonstrates remarkable efficiency compared to other machine learning approaches, owing to its simple model structure and lightweight identification process. Tab.\ref{tab.2} highlights its superior performance in both training and simulation speeds, along with accuracy in interpolation and extrapolation predictions  (See details in \textcolor{blue}{Section 4 in the Supplementary Materials}).

 It is clear that training the parametric 1-D Burgers' equation using operator learning requires at least 6.5 minutes (PINNs) on a GPU (Tesla T4 @ 16GB). In contrast, the ID-DMD achieves an $\sim\times 10^4$ improvement in speed, completing the process in just 0.02 seconds on a CPU (Intel Core i7-1160G7 @ 16GB). Furthermore, once trained, the ID-DMD delivers comparable simulation speed ($\sim 0.0005 \text{s}$) to all other operator learning approaches, along with the highest prediction accuracies in both interpolation and extrapolation tasks.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TABLE 1-2
%\newpage
%\onecolumngrid
  \linespread{1.5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Table 1 design
\begin{table*}[!t] 
      \centering    
\noindent
\caption{Comparison with advanced data-driven approaches}
\label{tab.2}

    \begin{tabular}{|p{2.5cm}|p{3.5cm}|p{3.5cm}|p{3.5cm}|p{3.5cm}|}

\hline
\makecell[c] {Methods} & \makecell[c] {Training\\time ($\sim$)} & \makecell[c]{Simulation\\time ($\sim$)} & \makecell[c]{Max relative error \\(Interpolation)}& \makecell[c]{Max relative error \\ (Extrapolation)}\\

\hline
\makecell[c] {ID-DMD} & \makecell[c] {\textbf{0.02s (CPU)}} & \makecell[c]{\textbf{0.0005s (CPU)}} & \makecell[c]{\textbf{0.024}}& \makecell[c]{\textbf{0.21}}\\

\hline
\makecell[c] {PI-DON} & \makecell[c] {10.65min (GPU)} & \makecell[c]{\textbf{0.0005s (CPU)}} & \makecell[c]{0.047}& \makecell[c]{2.2}\\

\hline
\makecell[c] {PINNs} & \makecell[c] {6.5min (GPU)} & \makecell[c]{0.005s (CPU)} & \makecell[c]{0.6}& \makecell[c]{3.3}\\

\hline
\makecell[c] {NIF} & \makecell[c] {16.5min (GPU)}& \makecell[c]{1s (CPU)} & \makecell[c]{0.09}& \makecell[c]{6}\\

\hline
\makecell[c] {FNO} & \makecell[c] {66.6min (GPU)} & \makecell[c]{0.6s (CPU)} & \makecell[c]{0.28}& \makecell[c]{0.81}\\

\hline
\end{tabular}
\end{table*}
\linespread{1}

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% SUB-SECTION 2.4
\subsection{Physical Interpretability}
This section explains how the ID-DMD is capable of representing a complex dynamic system while also being physically interpretable. In contrast to other data-driven models based on existing operator learning and neural networks, which tend to be complex and operate as black boxes, the ID-DMD is inherently transparent. 

For linear dynamic systems represented by ODE or PDEs, the ID-DMD remains the consistent parametric structure with a discretized physical state space model. Eigenvectors and eigenvalues of the linear operator directly represent system dynamics to enable a straightforward design and optimization. For example, the {\em pole placement} of a 4-DoF linear building system is demonstrated in \textcolor{blue}{Fig.S9}, where the bottom linear stiffness is used as a design parameter. In this example, the state vectors $\mathbf{x}_{k}$ are formulated from the building’s responses ${y_1}(k),{y_2}(k),{y_3}(k),{y_4}(k)$, along with their time-delay embeddings ${y_i}(k-1),{y_i}(k-2),...$, where $i=1,2,3,4$. Using the ID-DMD with the settings in \textcolor{blue}{Tab.S9}. The design target is to achieve the desired first resonant frequency of $10\ \text{rad/s}$ by designing the bottom linear stiffness. The design result is the linear stiffness equal to $2.82\times {10^9}\ {\text{N}}/{\text{m}}$ with a standard deviation of $\pm 0.14\times {{10}^{7}}$. The estimated resonant frequencies of all four modes of the designed system show a maximum relative error of 0.17\%.

Here, we focus more on the interpretability of nonlinear systems, where additional steps are required to project the system’s state measurements into a higher-dimensional linear space. This can be achieved by employing the Koopman operator, making it possible to formulate the ID-DMD representation for nonlinear systems as Eq.(\ref{eq3}).

In this section, we explore the ID-DMD modeling of a nonlinearly damped ODE:

\begin{equation}
\frac{{{\text{d}}^{2}}y}{\text{d}{{t}^{2}}}+0.03\frac{\text{d}y}{\text{d}t}+100y+{{c}_{3}}(\frac{\text{d}y}{\text{d}t}){}^{3}=0 \label{eq7} 
\end{equation}

\noindent where ${{c}_{3}}$ represents the nonlinear damping and serves as the design parameter. The ID-DMD model of the nonlinearly damped differential equation is $\psi({{\mathbf{x}}_{k}})=({{\mathbf{A}}_{{\upkappa},{0}}}+{{c}_{3}}{\mathbf{A}_{{\upkappa},{1}}})\psi({{\mathbf{x}}_{k-1}})$, where the observables are obtained from the polynomial projection as $\psi({\mathbf{x}}_{k})={[y(k), y(k-1),{{y}^{2}}(k), y(k)y(k-1),{{y}^{2}}(k-1),\ldots ]}^{\text{T}}$ up to the 8th order with in total 45 observables. Settings for ID-DMD identification are shown in \textcolor{blue}{Tab.S10}. Here, Fig.\ref{fig_3} illustrates how the ID-DMD characterizes and designs system dynamics under various nonlinear damping values.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE3
\begin{figure*}[!bt]
    \centering
    \includegraphics[width=\textwidth]{Fig3.png}
    \caption{
    Evaluate the first three order modes from the polynomial-projected Koopman operator. (a) The dominant modes and their corresponding characteristic frequencies can be identified from the imaginary part of the eigenvalues in the ID-DMD framework. These dominant modes remain stable across varying design parameters, representing the true dynamics of the system. In contrast, other modes that do not exhibit this stability are classified as spurious modes. (b) The modes of the system with (i) The first mode arises from the linear states, corresponding to the natural frequency of $\omega_\text{e}=10\ \text{rad/s}$. (ii) The second mode results from the squared projection of the states, occurring at the second-order modulation frequency $\omega_\text{e} =20\ \text{rad/s}$. (iii) The third mode, at $\omega_\text{e}=30\ \text{rad/s}$, is contributed by both the linear states and cubic projection of the states. (c) System response spectrum of $y(k)$ under $c_3=15$ and an input excitation $u(t)=\cos(10t)$. (d)  Design the energy dissipation of ${\eta}_{\text{E}}>30\%$ with ${{c}_{3}}>12.6$
    }
    \label{fig_3}
\end{figure*}
%\vspace{-4mm}

Frequency modulation achieving super- and sub-harmonics is a well-known characteristic of nonlinear systems. Fig.\ref{fig_3}(a) demonstrates the dominant and spurious modes of the ID-DMD.  In Fig.\ref{fig_3}(b), the second mode at $\omega_\text{e}=20\ \text{rad/s}$ does not affect the system's linear state $y(k)$, which means there is no second-order modulation in the system response as shown in Fig.\ref{fig_3}(c). The nonlinear damping increases energy dissipation within the system without affecting the system's settling time~\cite{lang2009theoretical}.  This unique property has been applied in engineering practice, particularly in vibration control and wide-band vibration isolation~\cite{zhu2022beneficial}. The energy dissipation ${{\eta }_{\text{E}}}$ is defined as the energy difference between linear and nonlinear system responses over the energy of the linear response.  A design achieving energy loss greater than $30\%$ is illustrated in Fig.\ref{fig_3}(d). The robustness of the design is evaluated through uncertainty quantification performed using the bagging process. The results shown in Fig.\ref{fig_3} can be readily verified by analytically solving the differential equation Eq.(\ref{eq5}) as detailed in \textcolor{blue}{Section 5 in the Supplementary Materials}.

For more complex nonlinear systems, other projections, i.e., encoding-decoding networks~\cite{takeishi2017learning}, can be applied to implement the ID-DMD using the same method.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SECTION 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
ID-DMD is a data-driven, physically interpretable modeling and design framework that can be applied to a broad range of complex dynamic systems at a fraction of the computing cost of competing methods. As parametric modeling is gaining recognition as a promising research direction for system design and optimization, many studies have explored network learning approaches. However, these methods often require the training of complex network structures, and the parametric models themselves tend to function as black boxes. The ID-DMD shows that the dynamic world is not as complex as might be presumed. It demonstrates that parametric data-driven models can be both simple and powerful, offering clear insights into system dynamics. Since ID-DMD can accurately predict system behavior across an underlying parameter space, it has the potential to replace cumbersome numerical simulators, thereby accelerating the analysis and design of dynamic systems. 

This study focuses on the foundational form of ID-DMD, which uses a polynomial extension of states and a linear-in-parameter model structure. While this approach is naive, it encounters limitations when handling discontinuous dynamics and severe nonlinearities. For example, modeling bifurcations, such as those arising from the Kuramoto-Sivashinsky equation, is challenging. Moreover, optimizing structures and geometries across a large nonlinear design space remains difficult with the current ID-DMD approach. However, these issues are less critical in engineering practice, as optimization is typically performed in the neighbour of existing pre-designed configurations~\cite{khuri2010response,schoukens2009robustness}.  In the case of design-from-scratch involving wide-range optimizations, the limitations are expected to be addressed as ID-DMD evolves to a more complete model structure

\begin{equation*}
\psi ({{\mathbf{x}}_{k}})=({{\mathbf{A}}_{{\upkappa},{0}}}+{{f}_{1}}(\bm{\upepsilon}){\mathbf{A}_{{\upkappa},{1}}}+{{f}_{2}}(\bm{\upepsilon}){\mathbf{A}_{{\upkappa},{2}}}+\cdots )\psi({{\mathbf{x}}_{k-1}})
\end{equation*}

\noindent where ${{f}_{i}}(\bm{\upepsilon}),\ i\in {{\mathbb{Z}}^{+}}$ are arbitrary differentiable functions of design parameters, offering a path toward overcoming these challenges and expanding its applicability via auxiliary function learning~\cite{lusch2018deep}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SECTION 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}
Existing parametric linear operator identification often requires point-wise regression for high-dimensional matrices~\cite{huhn2023parametric,andreuzzi2023dynamic}. In these studies, each sub-DMD model uses a different projection matrix, resulting in linear operators that are inconsistent and cannot be interpolated. To overcome these issues, the ID-DMD algorithm consists of four key steps: (i) Formulating the regression matrix from the collected snapshots, (ii) Performing dimensionality reduction for ID-DMD, (iii) Predicting system responses, and (iv) Implementing optimal design and uncertainty quantification. Each of these steps is explained in detail below.

\subsection{The regression matrix}
The ID-DMD begins by gathering all the spatio-temporal series data and organizing them into a matrix, denoted as $\mathbf{X}$, where each column represents the states or observables, and the number of columns corresponds to the length of the time series. Under the $l\in {{\mathbb{Z}}^{+}}$th set of design parameter values, the parametric model can be represented in matrix form as:

\begin{equation}
\begin{aligned}
  & {\mathbf{{X}'}}_{(l)}={\mathbf{A}_{0}}{\mathbf{X}_{(l)}}+{\bar{\varepsilon}_{1,(l)}}{\mathbf{A}_{\text{1}}}{\mathbf{X}_{(l)}}+{{\bar{\varepsilon}}_{2,(l)}}{\mathbf{A}_{\text{2}}}{\mathbf{X}_{(l)}}+\cdots \\ 
 & \ \ \ \ =\mathbf{\Theta}{\mathbf{E}_{(l)}} \\ 
\end{aligned} \label{eq8}
\end{equation}

\noindent Here, $\mathbf{X'}=[\begin{matrix}
   {\mathbf{x}_{2}} & {\mathbf{x}_{3}} & \cdots   \\
\end{matrix}]$ is the matrix representing the states at the next time step of $\mathbf{{X}}=[\begin{matrix}
   {\mathbf{x}_{1}} & {\mathbf{x}_{2}} & \cdots   \\
\end{matrix}]$. $\mathbf{\Theta }=[\begin{matrix}
   {{\mathbf{A}}_{0}} & {{\mathbf{A}}_{1}} & {{\mathbf{A}}_{2}} & \cdots \\
\end{matrix}]$, and $\mathbf{E}$ is the regressor matrix that incorporates the design parameters and the state matrix. $\bar{\varepsilon }_{i}={\alpha _{i}}{\varepsilon _{i}},\ i\in {\mathbb{Z}^{+}}$ are scaled design parameters to ensure well-conditioned matrices for calculation, where $\alpha_{i}$ are scaling factors.

The regression matrix for the ID-DMD is formulated by combining all data matrices across different design parameter sets. The newly formed regression matrix is $\mathbf{Z}=\mathbf{\Theta \Xi }$, where $\mathbf{Z}=[\begin{matrix}
   {{{\mathbf{{X}'}}}_{(1)}} & {{{\mathbf{{X}'}}}_{(2)}} & \cdots \\
\end{matrix}]$ and the regressor is $\mathbf{\Xi }=[\begin{matrix}
   {{\mathbf{E}}_{(1)}} & {{\mathbf{E}}_{(2)}} & \cdots \\
\end{matrix}]$.

\subsection{Dimensional reduction }

The core idea of ID-DMD is to find a truncated unitary matrix $\mathbf{U}\in {{\mathbb{C}}^{m\times {{r}_{\text{Z}}}}}$, which reduces the dimensionality of the regression matrix $\mathbf{Z}$ via the SVD $\mathbf{Z }\approx {\mathbf{U}}{\mathbf{\Sigma}}{\mathbf{V}}^{*}$. Here,  “*” is the complex conjugate transpose. $\mathbf{U}$ contains the basis vectors that project the high-dimensional data into a lower-dimensional space, where ${{r}_{\text{Z}}}\le m$, with $m$ being the number of states. Additionally, ID-DMD requires a truncated SVD of the regressor matrix $\mathbf{\Xi }\approx {{\mathbf{U}}_{\Xi}}{{\mathbf{\Sigma}}_{\Xi}}{{\mathbf{V}}_{\Xi}}^{*}$, where the unitary matrix ${{\mathbf{U}}_{\Xi}}$ is truncated with ${{r}_{\Xi}}$ columns.

In this study, ${{r}_{\text{Z}}}$ and ${{r}_{\Xi}}$ are set equal, though they can be adjusted differently as hyper-parameters. These hyper-parameters can be determined by using  The ${{\mathbf{U}}_{\Xi}}$ matrix is divided into several row blocks, represented by ${{\mathbf{U}}_{\Xi,i}}\in {{\mathbb{C}}^{m\times {{r}_{\Xi}}}},\ i\in \mathbb{Z}$, each corresponding to a linear operator ${{\mathbf{A}}_{i}}$ of the system. By projecting the full linear operators into the lower-dimensional through

\begin{equation}
    {{\mathbf{\tilde{A}}}_{i}}={{\mathbf{U}}^{*}}{{\mathbf{A}}_{i}}\mathbf{U}={{\mathbf{U}}^{*}}\mathbf{Z}{{\mathbf{V}}_{\Xi}}{{\mathbf{\Sigma }}_{\Xi}}^{-1}{{\mathbf{U}}_{\Xi,i}}^{*}\mathbf{U} \label{eq9}
\end{equation}

\noindent the eigenvalues and eigenvectors of the system under specific design parameters are evaluated from the reduced operator ${{\mathbf{\tilde{A}}}_{0}}+{{\bar{\varepsilon }}_{1}}{{\mathbf{\tilde{A}}}_{1}}+{{\bar{\varepsilon }}_{2}}{{\mathbf{\tilde{A}}}_{2}}+\cdots$ without working with the full system operator. 

The eigenvalues $\mathbf{\Lambda}\in {{\mathbb{C}}^{{{r}_{\text{Z}}}\times {{r}_{\text{Z}}}}}$ of the reduced operator are retained as those of the full operator. The eigenvectors $\mathbf{\Phi}$, which represent the system’s dynamic modes, are reconstructed from the eigenvectors $\mathbf{W}$ of the reduced operator either via the projected DMD ($\mathbf{\Phi }=\mathbf{UW}$) or the exact DMD~\cite{tu2013dynamic}

\begin{equation*}
    \mathbf{\Phi}=\mathbf{Z}{\mathbf{V}_{\Xi}}{\mathbf{\Sigma}_{\Xi}}^{-1}({\mathbf{U}_{\Xi,0}}^\text{*}+{\bar{\varepsilon}_{1}}{\mathbf{U}_{\Xi,1}}^\text{*}+{\bar{\varepsilon}_{2}}{\mathbf{U}_{\Xi,2}}^\text{*}+\cdots)\mathbf{UW}
\end{equation*}

\subsection{Reconstruction and prediction}

Once the eigenvalues and eigenvectors are determined, we can reconstruct the system states using Eq.(\ref{eq2}), summarizing over $j=1,\ldots,{{r}_{Z}}$. The complex frequency ${{s}_{j}}$ is calculated as ${{s}_{j}}=\Delta {{t}^{-1}}\log ({{\mathbf{\Lambda }}_{(j,j)}})$, where ${{\mathbf{\Lambda }}_{(j,j)}}$ are the diagonal entries of the eigenvalues. In physics, if the complex frequency has a positive real part, the system becomes unstable and diverges. To prevent this, we set ${{\sigma }_{j}}=0$ if ${{\sigma }_{j}}>0$, ensuring stability. This study assumes that the initial system states are known a priori for all predictions. 

\subsection{Design and uncertainty quantification}

One can formulate an optimization problem that the cost function can readily be evaluated from the ID-DMD. Inverse design is done by solving the optimization problem. Uncertainties matrices of the design are assessed by integrating the bagging approach into the ID-DMD~\cite{sashidhar2022bagging}. In this process, random subsets of corresponding columns are selected from the data matrices $\mathbf{X'}$ and $\mathbf{X}$ to construct and implement multiple runs of the ID-DMD. In this study, half of the columns were randomly selected to quantify the design uncertainties. Solving the optimization problem based on these ID-DMD realizations will produce a set of optimal design results. These results are then aggregated and analyzed statistically to estimate the uncertainty matrices, providing a comprehensive evaluation of the reliability of the inverse design process. 

All data, along with the MATLAB and Python codes, are available on GitHub: \url{https://github.com/YZ-Vista/Data-driven-dynamics_ID-DMD}

\vspace{10mm}

\setlength{\parindent}{0pt}

\section*{Acknowledgments}
We acknowledge support from the National Science Foundation AI Institute in Dynamic Systems (grant number 2112085). JNK further acknowledges support from the Air Force Office of Scientific Research (FA9550-19-1-0011). YPZ acknowledges support from the Queen Mary University of London Startup Funding (SEM9307B). ZQL acknowledges support from the UK EPSRC project (EP/R032793/1). BZ acknowledges support from the National Natural Science Foundation of China (1223  2013) and the Natural Science Foundation of Ningxia (2022AAC2003).

\appendix
\include{main_SI}

\section*{References}
\bibliographystyle{unsrt}
\bibliography{mainNotes,mainNotes_SI}

\end{document}
