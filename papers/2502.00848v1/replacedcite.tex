\section{Related Work}
\subsection{Text-to-Image Generation}
The U-Net-based Stable Diffusion models____ first perform universal image generation from text prompts, which typically trained on large scale text-image paired dataset, \aka, LIANG 5B____. After the proposal of the Diffusion Transformer (DiT)____, some research, such as Stable Diffusion V3____ and Flux____, utilize DiT as the backbone to develop DiT-based Diffusion Models for text-to-image generation. Recently, with the success of auto-regressive (AR) modeling in the natural language processing____, some works have explored how to combine auto-regressive models with diffusion models to improve the understanding capability and further build a unified multi-modal model for both understanding and generation____. These AR-based models, such as OmniGen____ and Emu____, also show notable performance on the text-to-image task. While these methods have achieved strong performance in text-to-image generation, they store all the knowledge in their pre-trained parameters, which leads to hallucinations and distortions when generating realistic objects. To address this limitation, we propose the real-object-based RAG framework to integrate missing knowledge and improve the ability to generate realistic images.

\subsection{Retrieval-augmented Generation}
Retrieval-augmented generation has shown promise with NLP____. To incorporate external knowledge into a LLM____, these methods retrieve documents relevant to inputs from an external database, subsequently, the LLM utilizes the recalled documents as references to generate accurate results. The external knowledge used is typically a text database____. However, the text database is not direct and controllable for realistic image generation____. In this paper, we conduct a vision-based, real-object-based database, which is collected by realistic images from public real-world datasets, including ImageNet____, Stanford Cars____, Stanford Dogs____, and Oxford Flowers____. In this way, we augment the realism of the generative images with the real-object-based database.
% with the real-object database.

\subsection{Contrastive Learning for Retrieval}
Contrastive learning has emerged as a powerful method for retrieval tasks, leveraging the principle of learning representations by contrasting positive and negative samples____. The approach aims to map semantically similar data points closer in the embedding space while simultaneously pushing dissimilar data points apart. Methods such as SimCLR____ and MoCo____ have popularized this framework in vision tasks, whereas in the domain of multi-modal retrieval, models including CLIP____ have demonstrated their effectiveness by aligning textual and visual representations. Recent research has extended contrastive learning to various modalities, such as audio____, video____, point cloud____, and tactile data____, thereby enhancing cross-modal retrieval capabilities. These methods often incorporate techniques (e.g., hard negative mining____ and balanced learning____) to improve the quality of the learned embedding space.
Despite its success in query-document matching, images that best match a text prompt may not be the most valuable references for text-to-image generative models____. Consequently, we propose a self-reflective contrastive learning approach, which retrieves images containing the missing knowledge of the generative models rather than selecting the most relevant images.