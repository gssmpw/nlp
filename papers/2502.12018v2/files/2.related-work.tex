\section{Related Work}

\subsection{Reasoning Framework}

Inspired by cognitive operations~\cite{Smelser2001Cognitive} in human reasoning—such as step-by-step decomposition~\cite{Wei2022cot, zhou2023least, wang2023planandsolve, hao2024llm}, reflective refinement~\cite{Madaan2023selfrefine, zheng2024stepback, zheng2023progressive}, and aggregation ensemble~\cite{Wang2023cotsc, jiang2023llmblender, yao2025determine}—various prompting strategies have been widely applied to enhance the reasoning capabilities of large language models (LLMs). Reasoning frameworks leverage structured assumptions, such as chains, graphs, and trees~\cite{Yao2023tot, Besta2024got, zhang2024tse}, to organize these strategies, thereby effectively exploring and modeling the reasoning space. For instance, chain-based approaches decompose complex problems into sequential subtasks~\cite{Wei2022cot, zhou2023least, wang2023planandsolve}, while tree- and graph-based formalisms enable systematic exploration of multiple reasoning paths with dynamic adaptability~\cite{Yao2023tot, Besta2024got}. Such frameworks augment LLMs’ reasoning across domains, integrating principles that enhance performance in agentic workflows like code generation, question answering, and data science applications~\cite{Hong2024metagpt, Hong2024data, zhang2025evoflow, zhang2024mobileexperts}. By structuring the reasoning process, these methods provide a robust foundation for LLMs to tackle intricate tasks with improved coherence and reliability.

Compared to the ongoing efforts to design increasingly complex structures, several attempts have explored a Markov reasoning process or atomic reasoning steps. However, these approaches often suffer from a lack of generalizability and true atomic design~\cite{Xin2024atomr, Xiang2024AtomThink, Zhou2024selfdiscover, xiang2025can}. For example, the definition of states and transitions remains task-specific and disrupts potential parallelism~\cite{hao2023rap, Yang2024mcot, Zekri2024Large}. In contrast, our approach utilizes a Directed Acyclic Graph (DAG) composed of subproblem nodes and dependency edges to accommodate a wide variety of tasks. By decomposing and contracting the DAG, our method isolates independent subproblems while preserving support for parallelism. Furthermore, our approach defines atomic units as questions that trigger reasoning, aligning naturally with real reasoning scenarios and effectively separating information from historical dependencies.

\subsection{Test-time Scaling}
Test-time scaling approaches have demonstrated the value of extended computation during inference. Framework-based approaches enhance LLM reasoning performance by extending inference through external systems, incorporating techniques like cognitive operations and external tool invocation~\cite{Zhang2024aflow, Falcon2024archon, Chen2024more}. However, these methods do not improve the inherent reasoning capabilities of LLMs at the model level. To address this gap, supervised fine-tuning on long chain-of-thought trajectoris has proven effective at enhancing models' capabilities to conduct extended reasoning~\cite{ye2025limo, yeo2025demystifying, yao2025unveiling}. Building on this foundation, reinforcement learning methods have enabled models to automatically learn to extend chains of thought, with the potential to emerge some autonomous cognitive operations~\cite{team2025kimi, zeng2025simplerl, deepseekR1Model, yu2025dapo}.

However, these approaches universally retain extensive historical information throughout the reasoning process, resulting in computational inefficiency and potential interference with effective reasoning. In contrast, \our introduces an approach that integrates a Markovian perspective with an atomized perspective, eliminating the need for historical dependency tracking by decomposing the reasoning process into independent atomic reasoning units. This ingenious unification of the two properties enables \our to concentrate computational resources on the current state, thereby achieving more efficient resource allocation, while the atomic state definition provides plug-in compatibility with existing test-time scaling methods.