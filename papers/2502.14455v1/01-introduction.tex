\section{Introduction} \label{sec:intro}

Heterogeneous ground-aerial autonomous robots combine the advantages of both (i.e., agile flying drones and high-payload ground vehicles) and mitigate the limits of each, i.e., reduced payloads and exploration speed respectively, leading to efficient autonomous transportation systems~\cite{chatziparaschis2020aerial, 8955969}.
Many different transportation applications can benefit from this pattern, from warehouse management~\cite{inproceedings_warehouse} to traffic monitoring and control~\cite{rodic2012ambientally}, precision agriculture~\cite{9177181}, and emergency response scenarios~\cite{rajapakshe2023coll}.
In all these cases, combining accurate analysis (e.g., from a flying drone) with decentralized decision-making processes (e.g., optimal path planning) leads not only to the obvious economic advantage of reducing costs (e.g., transportation and delivery costs) but also to additional social and environmental benefits, of saved time and resources.

This work addresses smart farming crop production, enabling prompt, precise, and efficient treatments in cultivated fields.
To reach the goal of timely fine-grained treatments (up to single plants) in the event of pest outbreaks, accurate pest detection and optimal planning of routes for slow machinery are of the essence.
Reducing the use of pesticides not only brings economic benefits for farmers but also reduces the environmental impact of mass production.
This work addresses this challenge by designing a two-level autonomous transportation system.
The forefront is represented by a fleet of miniaturized autonomous unmanned aerial vehicles (UAVs), a new class of inexpensive airborne called nano-UAVs~\cite{9474262, lamberti2024sim} as big as the palm of one hand, i.e., sub-\SI{50}{\gram} weight and less than \SI{10}{\centi\meter} in diameter.
Instead, on the ground, we rely on an automated tractor acting as the backbone for the heavy-duty job~\cite{applmech3030049, tahmasebi2022autonomous}, i.e., pest control in the environment.
Thanks to their agility, nano-UAVs can quickly act as probes to comb vast cultivated areas, looking for the first signs of pest outbreaking, leaving the fine-grained treatment (e.g., spraying chemicals) to the bulky and slow tractor.

However, the agility of nano-UAVs comes with ultra-constrained onboard resources, such as simple sensors, a few tens of \SI{}{\mega\byte} of memory, and sub-\SI{100}{\milli\watt} for the onboard computational power~\cite{palossi2019open}.
Nevertheless, our nano-UAVs are required to \textit{i}) analyze, in real-time, images acquired on board for detecting harmful insects, and \textit{ii}) fly autonomously, following a pre-defined path but avoiding collisions with unexpected dynamic obstacles.
To cope with this scenario, we employ a commercial off-the-shelf (COTS) Crazyflie nano-UAV featuring an STM32 microcontroller unit (MCU) and extended with a low-resolution camera, an 8$\times$8 Time-of-Flight (ToF) depth sensor, and an ultra-low power Greenwaves Technologies (GWT) GAP9 multi-core System-on-Chip (SoC).

We address the former task by optimizing and deploying a State-of-the-Art (SoA) vision-based deep learning model, i.e., SSDLite-MobileNetV3~\citep{howard2019searching}, re-trained for pest detection and running on the GAP9 SoC.
Instead, the latter task is handled with a \textit{global+local path planning} approach~\cite{marin2018global}, where both planners are based on the A* algorithm~\cite{hart1968formal}, a graph-based path planning algorithm.
The vast cultivated field is split into 40$\times$\SI{40}{\meter} areas due to the limited battery lifetime of nano-UAVs (i.e., $\sim$\SI{6}{\minute}).
For each area, we convert a static 2D occupancy map~\cite{30720} of the field (i.e., a vineyard in our case) in an 8-connected graph~\cite{HALIN1969150}.
Before the mission starts, the global path planner computes the optimal path for each nano-UAV on such a graph, enforcing the complete exploration of the area.
Then, during the mission, the local planner, running on the STM32 aboard our nano-UAVs, takes in input a local occupancy map of 4$\times$\SI{4}{\meter} continuously updated from the onboard depth sensor.
Therefore, the local planner can adjust the path if a new obstacle lies on the pre-computed global path.
Thanks to the real-time performance of the local planner up to \SI{50}{\hertz}, we achieve the desired reactive obstacle avoidance functionality.

Our main contribution is a novel integrated transportation system that combines autonomous ground and aerial vehicles. 
We design, optimize, and deploy a SoA convolutional neural network (CNN) capable of achieving up to 0.79 mean average precision (mAP) for accurate pest detection, along with a local path planner for obstacle avoidance, both implemented on the two MCUs of our nano-UAV. 
We conduct a thorough evaluation of the CNNâ€™s classification and inference performance, including power consumption measurements on the GAP9 SoC, which operates within \SI{33}{\milli\watt} while achieving a throughput of \SI{6.8}{frame/\second}. 
Additionally, we implement and validate the complete transportation system in the Webots\footnote{https://cyberbotics.com/} simulator, including sensor interfacing and executing the global and local path planning algorithms.
Our findings demonstrate that the proposed ground-aerial transportation system significantly outperforms traditional methods relying only on a single tractor for pest detection and treatment by reducing exploration time up to \SI{20}{\hour}, assuming an area of 200$\times$\SI{200}{\meter} and a mean speed of \SI{0.2}{\meter/\second}~\cite{9177181}.