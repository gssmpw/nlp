% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\begin{document}
%
\title{Safety Evaluation of DeepSeek Models in Chinese Contexts}
% %
\titlerunning{Safety Evaluation of DeepSeek Models in Chinese Contexts}


\author{Wenjing Zhang\inst{1,2} \and Xuejiao Lei\inst{1,2} \and Zhaoxiang Liu\inst{*1,2} \and Ning Wang\inst{1,2} \and Zhenhong Long\inst{1,2} \and Peijun Yang\inst{1,2} \and Jiaojiao Zhao\inst{1,2} \and Minjie Hua\inst{1,2} \and Chaoyang Ma\inst{1,2} \and  Kai Wang\inst{1,2} \and Shiguo Lian\inst{*1,2}}


%
\authorrunning{W. Zhang et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Unicom Data Intelligence, China Unicom \and
Data Science \& Artifical Intelligence Research Institute,  China Unicom \\
\email{\{zhangwj1503,leixj15,liuzx178,wangn85,longzh8,yangpj16,zhaojj225,\\huamj5,macy87,wangk115,liansg\}@chinaunicom.cn \\
\inst{*}Corresponding author(s)
}
}

\maketitle              % typeset the header of the contribution
%
\begin{abstract}
% Recently, the DeepSeek series of models, leveraging their exceptional reasoning capabilities and open-source strategy, are reshaping the global AI landscape. However, despite these advantages, they exhibit significant safety deficiencies. Recently, research conducted by Robust Intelligence, a subsidiary of Cisco, in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1 has a 100\% attack success rate when processing harmful prompts. Additionally, multiple safety companies and research institutions have confirmed the existence of critical safety vulnerabilities in this model. As representative models demonstrating robust performance in Chinese and English, the safety assessments of DeepSeek models are equally crucial in both language contexts. However, current experiments and research have predominantly focused on safety evaluations in English environments, leaving a gap in comprehensive and granular assessments of their safety performance in Chinese contexts. In response to this research gap, this study introduces CHiSafetyBench, a dedicated safety evaluation benchmark for Chinese. This benchmark systematically assesses the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, revealing their performance across different safety categories. The experimental results quantitatively highlight the deficiencies of these two models in Chinese contexts, providing crucial references for subsequent model improvements and optimizations.

Recently, the DeepSeek series of models, leveraging their exceptional reasoning capabilities and open-source strategy, is reshaping the global AI landscape. Despite these advantages, they exhibit significant safety deficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco, in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1 has a 100\% attack success rate when processing harmful prompts. Additionally, multiple safety companies and research institutions have confirmed critical safety vulnerabilities in this model. As models demonstrating robust performance in Chinese and English, DeepSeek models require equally crucial safety assessments in both language contexts. However, current research has predominantly focused on safety evaluations in English environments, leaving a gap in comprehensive assessments of their safety performance in Chinese contexts. In response to this gap, this study introduces CHiSafetyBench, a Chinese-specific safety evaluation benchmark. This benchmark systematically evaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, revealing their performance across safety categories. The experimental results quantify the deficiencies of these two models in Chinese contexts, providing key insights for subsequent improvements. It should be noted that, despite our efforts to establish a comprehensive, objective, and authoritative evaluation benchmark, the selection of test samples, characteristics of data distribution, and the setting of evaluation criteria may inevitably introduce certain biases into the evaluation results. We will continuously optimize the evaluation benchmark and periodically update this report to provide more comprehensive and accurate assessment outcomes. Please refer to the latest version of the paper for the most recent evaluation results and conclusions.


\end{abstract}
%
%
%
\section{Introduction}
% Ability
% Large language models have demonstrated remarkable effectiveness in complex reasoning\cite{patil2025reasoning,qwq-32b-preview}, natural language understanding\cite{xu2024ie}, and natural language generation\cite{achiam2023gpt,llama3}. As an open-source large language model, DeepSeek-R1\cite{guo2025deepseekr1} is reshaping the landscape of the global AI field with its exceptional reasoning capabilities. This model is based on a 671 billion-parameter Mixture of Experts (MoE) architecture\cite{cai2024moesurvey,liu2024moesurvey} and employs unique reinforcement learning techniques, performing outstandingly in multiple domains including mathematical reasoning, code generation, and natural language processing. In the American Invitational Mathematics Examination 2024 (AIME 2024)\cite{AIME2024}, DeepSeek-R1 achieved an accuracy rate of 79.8\%, slightly outperforming OpenAI's o1\cite{o1} model. On the Codeforces platform, its performance surpassed 96.3\% of human programmers. The impact of DeepSeek-R1 is not only reflected in technological innovation but also in its open-source strategy, which has effectively promoted the popularization of AI technology, broken the monopoly of closed-source models, and attracted widespread attention from developers and enterprises worldwide. Additionally, its low-cost training and deployment strategies provide accelerated momentum for the global application of DeepSeek-R1.

Large language models have demonstrated remarkable efficacy in fields such as complex reasoning\cite{patil2025reasoning,qwq-32b-preview}, natural language understanding\cite{xu2024ie}, and natural language generation\cite{llama3,achiam2023gpt}, emerging as a pivotal force driving the development of artificial intelligence technology. Against this backdrop, DeepSeek has rapidly emerged over the past two years as a rising star in the industry. The company has recently unveiled the DeepSeek-V3\cite{liu2024deepseekv3} and DeepSeek-R1\cite{guo2025deepseekr1} versions of its large language models, marking a new leap in its technical capabilities. Notably, DeepSeek-R1, as an open-source large language model, is reshaping the global AI landscape with its exceptional reasoning abilities. Based on a Mixture of Experts(MoE) architecture\cite{cai2024moesurvey,liu2024moesurvey} with 671 billion parameters and utilizing unique reinforcement learning techniques, DeepSeek-R1 excels in various domains, including mathematical reasoning, code generation, and natural language processing. For instance, in the American Invitational Mathematics Examination 2024 (AIME 2024)\cite{AIME2024}, DeepSeek-R1 achieved the accuracy of 79.8\%, slightly outperforming OpenAI o1\cite{o1}. Additionally, on the Codeforces platform, its performance surpassed that of 96.3\% of human programmers. The impact of DeepSeek-R1 is evident not only in technological innovation but also in its open-source strategy, which has significantly promoted the popularization of AI technology, broken the monopoly of closed-source models, and garnered widespread attention from developers and enterprises worldwide. Furthermore, its low-cost training and deployment strategies have accelerated the global application of DeepSeek-R1.


As the capabilities of DeepSeek-R1 become widely applied, concerns about its safety are increasingly coming to the forefront. Recently, Robust Intelligence, a division of Cisco\cite{cisco}, in collaboration with the University of Pennsylvania, conducted an in-depth study on the safety of DeepSeek-R1, revealing critical safety flaws in the model. The research team comprehensively tested DeepSeek-R1 using 50 harmful prompts from the HarmBench dataset\cite{harmbench}, and the results were alarming: DeepSeek-R1 failed to successfully block any of the harmful prompts, resulting in a 100\% attack success rate. Enkrypt AI\cite{EnkryptAI}, a leading global platform for AI safety and compliance, also released its red teaming report focusing on DeepSeek technology. The report pointed out that DeepSeek-R1 has severe ethical and security vulnerabilities. Through in-depth analysis, researchers found that the model exhibits high levels of bias, is prone to generating unsafe code, and may produce harmful and toxic content, such as hate speech, threats, self-harm, and explicit or crime-related material. Additionally, several other safety companies and research institutions\cite{adversaai,arrieta2025o3,chatterbox}, including Adversa AI and Chatterbox Labs, a specialist in measuring and quantifying AI risks, have also tested the safety of DeepSeek-R1. These tests similarly concluded that it contains significant safety vulnerabilities, further confirming the safety issues associated with DeepSeek-R1.

% However, most current experiments and research primarily focus on safety evaluations within English contexts, lacking comprehensive and fine-grained assessments of safety performance in Chinese contexts. In light of this research gap, this study conducts a multi-level and fine-grained safety evaluation of models based on the hierarchical safety taxonomy stipulated in the "Basic Safety Requirements for Generative Artificial Intelligence Services" standard recently issued by the Chinese government. Specifically, this paper employs CHiSafetyBench, a Chinese safety benchmark built according to this standard, to systematically and comprehensively evaluate the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, aiming to reveal their performance capabilities across different Chinese safety categories. The experimental results quantitatively expose the shortcomings of these two models in terms of safety performance in Chinese contexts, providing guidance for subsequent model optimization and protection. To our knowledge, we are the first research team to successfully implement a safety evaluation of DeepSeek-R1 in Chinese.

Currently, most experiments and research primarily focus on safety evaluations within English contexts, lacking comprehensive and fine-grained assessments of safety performance in Chinese contexts. To address this research gap, this study conducts a multi-level and fine-grained safety evaluation of models based on the hierarchical safety taxonomy defined in the "Basic Safety Requirements for Generative Artificial Intelligence Services" standard issued by the Chinese government. Specifically, this paper employs CHiSafetyBench, a Chinese safety benchmark built according to this standard. This benchmark is used to systematically evaluate the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, revealing their performance across different safety categories. The experimental results quantify the shortcomings of these two models in Chinese safety performance, offering insights for subsequent optimization and protection. 
It is important to emphasize that the selection of test samples and the design of evaluation criteria will inevitably introduce certain biases into the evaluation results. To address this, we will continue to optimize this evaluation work to enhance its comprehensiveness and reliability as much as possible.
To our knowledge, we are the first to conduct a safety evaluation of DeepSeek-R1 in Chinese.


\section{Experiments}
\subsection{Experimental Setup}
% This study conduct a systematic and comprehensive safety evaluation of the latest and most representative models in the DeepSeek series, namely DeepSeek-R1 (671B) and DeepSeek-V3, with a focus on Chinese contexts. Building upon this foundation, to further objectively compare the safety performance of the DeepSeek series models, we also select a series of widely recognized models proficient in generating Chinese content as auxiliary comparison subjects. These auxiliary models encompass 10 large language models from 4 different series that provide good support for Chinese, specifically including: the Baichuan series (Baichuan2-7B-Chat, Baichuan2-13B-Chat), the ChatGLM series (ChatGLM3-6B), the Qwen series (Qwen1.5-7B-Chat, Qwen1.5-14B-Chat, Qwen1.5-32B-Chat, Qwen1.5-72B-Chat, Qwen1.5-110B-Chat), and the Yi series (Yi-6B-Chat, Yi-34B-Chat).

This study conducts a systematic and comprehensive safety evaluation of the latest and most representative models in the DeepSeek series, namely DeepSeek-R1 (671B) and DeepSeek-V3, with a focus on Chinese contexts. Building upon this foundation, we further objectively compare the safety performance of the DeepSeek series models by selecting a series of widely recognized models with strong Chinese capabilities as auxiliary comparison subjects. These auxiliary models include 10 large language models from 4 different series: the Baichuan series (Baichuan2-7B-Chat, Baichuan2-13B-Chat), the ChatGLM series (ChatGLM3-6B), the Qwen series (Qwen1.5-7B-Chat, Qwen1.5-14B-Chat, Qwen1.5-32B-Chat, Qwen1.5-72B-Chat, Qwen1.5-110B-Chat), and the Yi series (Yi-6B-Chat, Yi-34B-Chat).

\subsection{Evaluation Benchmark}
In the realm of safety evaluation, we employ CHisafetybench~\cite{zhang2024chisafetybench} as our benchmark to conduct a comprehensive assessment of the model across 5 major safety areas in Chinese contexts: discrimination, violation of values, commercial violations, infringement of rights, and security requirements for specific services. This benchmark encompasses two types of evaluation tasks: multiple-choice questions for risk content identification and risky questions for refusal to answer, enabling a multi-faceted evaluation. Specifically, the multiple-choice questions utilize accuracy(ACC) as the evaluation metric, while the risky questions are comprehensively assessed through indicators such as the rejection rate(RR-1), the responsibility rate(RR-2), and the harm rate(HR). The safety evaluation benchmark used in this study includes two core tasks: firstly, assessing the model's ability to identify risky content through multiple-choice questions; and secondly, evaluating its capability to reject risky queries and provide positive guidance.


\subsection{Evaluation for Risk Content Identification}
\begin{table*}[t!]
\centering
\resizebox{\textwidth}{!}{
    % \small
    \renewcommand\arraystretch{1.1} 
    \setlength{\tabcolsep}{4mm}{} 
    \begin{tabular}{l|c|c|c|c|c|c}
    \hline
        \textbf{} & \textbf{Overall} & \textbf{DI} & \textbf{VV} & \textbf{CV} & \textbf{IR} & \textbf{SR} \\ \hline
        Baichuan2-7B-Chat & 50.03\% & 26.09\% & 83.46\% & 50.39\% & 45.35\% & 42.42\% \\
Baichuan2-13B-Chat & 79.83\% & 78.26\% & 89.22\% & 96.06\% & 70.14\% & 42.42\% \\ \hline
ChatGLM3-6B & 41.16\% & 12.39\% & 78.70\% & 42.91\% & 36.90\% & 34.34\% \\ \hline
Qwen1.5-7B-Chat & 79.39\% & 60.65\% & 93.23\% & 94.49\% & 82.54\% & 60.61\% \\
Qwen1.5-14B-Chat & 88.39\% & \textbf{86.52\%} & 93.48\% & 96.46\% & 87.32\% & 42.42\% \\
Qwen1.5-32B-Chat & 87.30\% & 85.43\% & \textbf{93.73\%} & \textbf{97.24\%} & 95.77\% & 74.75\% \\
Qwen1.5-72B-Chat & \textbf{91.13\%} & 85.87\% & 92.48\% & 96.85\% & \textbf{96.34\%} & 68.69\% \\
Qwen1.5-110B-Chat & 90.62\% & 74.35\% & 92.23\% & 94.09\% & 94.08\% & 66.67\% \\ \hline
Yi-6B-Chat & 86.01\% & 85.00\% & 90.73\% & 94.49\% & 78.59\% & 62.63\% \\
Yi-34B-Chat & 68.54\% & 40.43\% & 87.72\% & 79.13\% & 77.18\% & 63.64\% \\
\hline
        \textbf{DeepSeek-V3} &  84.17\% & 66.96\%& 91.98\%& 96.85\%& 87.32\%&  88.89\%\\ 
        \textbf{DeepSeek-R1} &   71.41\% &  50.22\%& 64.91\%&  89.37\%&  86.76\%&  \textbf{94.95\%}\\ 
        \hline

    \end{tabular}
    }
\caption{ACC for MCQ to evaluate risk content identification capabilities. Wherein, DI stands for Discrimination, VV represents Violation of Values, CV signifies Commercial Violations, IR signifies Infringement of Rights, and SR denotes Security Requirements for Specific Services. The optimal values under the current metric are highlighted bold.}
\label{tab:question-type}
\end{table*}


% The evaluation results for the multiple-choice questions are presented in Table 1. The results indicate that the overall safety performance of the DeepSeek series models is relatively moderate. Specifically, the overall ACC of DeepSeek-R1 (671B) and DeepSeek-V3 are only 71.14\% and 84.17\%, respectively, which are 19.72\% and 6.96\% lower than the top-performing Qwen1.5-72B-Chat. 

% Across various risk subcategories, the DeepSeek-R1 model performs particularly poorly in the Discrimination and Values of Violations categories, with ACC of 50.22\% and 64.91\%, respectively, which are 36.30\% and 28.82\% lower than the best-performing Qwen series models. DeepSeek-V3 also exhibits significant deficiencies in the Discrimination category, with ACC of 66.96\%, which is 19.56\% lower than the top-performing Qwen1.5-14B-Chat. This suggests that the Discrimination category is a common weakness in the DeepSeek models that has not been effectively mitigated. 

% Additionally, compared to DeepSeek-V3, the safety capability of DeepSeek-R1 shows a notable decline, with a 12.76\% drop in overall accuracy and decreased ACC in four 4 of 5 dimensions to varying degrees. For further reference, we have also listed the ACC of the DeepSeek series models and four additional series models for identifying 31 detailed risk content categories, as shown in Figure 1.

The evaluation results for the multiple-choice questions are presented in Table 1. The results indicate that the overall safety performance of the DeepSeek series models is relatively moderate. Specifically, the overall ACC of DeepSeek-R1 and DeepSeek-V3 are 71.14\% and 84.17\%, respectively. These values are 19.72\% and 6.96\% lower than the top-performing Qwen1.5-72B-Chat.

\begin{figure*}[h!]
\small
\centering
\includegraphics[width=0.85\textwidth]{appendix/31-acc.png}
\caption{ACC for 12 models across 31 risk categories on the MCQ subset.} \label{fig4}
\end{figure*}

Across various risk categories, the DeepSeek-R1 model performs particularly poorly in the discrimination and values of violations categories, with ACC of 50.22\% and 64.91\%, respectively. These values are 36.30\% and 28.82\% lower than the best-performing Qwen series models. DeepSeek-V3 also exhibits significant deficiencies in the discrimination category, with ACC of 66.96\%, which is 19.56\% lower than the top-performing Qwen1.5-14B-Chat. These results indicate that the discrimination category remains a common weakness in the DeepSeek models, which has not been effectively addressed.



Additionally, compared to DeepSeek-V3, the safety capability of DeepSeek-R1 shows a notable decline, with a 12.76\% drop in overall ACC and decreased ACC in 4 out of 5 dimensions. For further reference, Figure 1 lists the ACC of the DeepSeek series models and four additional models across 31 detailed risk content categories.



\subsection{Evaluation for Refusal to Answer}

\begin{table*}[t!]
\centering
\resizebox{\textwidth}{!}{
    % \small
    \renewcommand\arraystretch{1.35} 
    \setlength{\tabcolsep}{1.0mm}{} 
    \begin{tabular}{l|ccc|ccc|ccc}
    \hline
        \textbf{} & \multicolumn{3}{c|}{\textbf{Overall}} & \multicolumn{3}{c|}{\textbf{Discrimination}} & \multicolumn{3}{c}{\textbf{Violation of Values}}\\ 
         & RR-1 & RR-2 & HR & RR-1 & RR-2 & HR & RR-1 & RR-2 & HR  \\ \hline

Baichuan2-7B-Chat & 72.29\% & 72.29\% & 0.65\% & 52.55\% & 52.55\% & 0.51\% & 86.84\% & 86.84\% & 0.75\% \\ 
Baichuan2-13B-Chat & 77.06\% & 76.84\% & 0.43\% & 58.67\% & 58.16\% & 1.02\% & 90.60\% & 90.60\% & \textbf{0.00\%}   \\  \hline
ChatGLM-6B & 72.08\% & 72.08\% & 1.95\% & 51.53\% & 51.53\% & 1.53\% & 87.22\% & 87.22\% & 2.26\%  \\ 
ChatGLM2-6B & 71.43\% & 71.21\% & 1.08\% & 47.96\% & 47.96\% & 1.02\% & 88.72\% & 88.35\% & 1.13\%  \\ 
ChatGLM3-6B & 73.38\% & 73.38\% & 1.08\% & 52.55\% & 52.55\% & 1.02\% & 88.72\% & 88.72\% & 1.13\%   \\ \hline
Qwen1.5-7B-Chat & 73.59\% & 73.59\% & 0.43\% & 54.59\% & 54.59\% & 0.51\% & 87.59\% & 87.59\% & 0.38\% \\ 
Qwen1.5-14B-Chat & 73.16\% & 73.16\% & 0.22\% & 53.57\% & 53.57\% & 0.51\% & 87.59\% & 87.59\% & \textbf{0.00\%}  \\ 
Qwen1.5-32B-Chat & \textbf{77.71\%} & \textbf{77.27\%} & 0.22\% & \textbf{59.69\%} & \textbf{59.18\%} & \textbf{0.00\%} & 90.98\% & 90.60\% & 0.38\%  \\ 
Qwen1.5-72B-Chat & 73.81\% & 73.81\% & 0.22\% & 52.55\% & 52.55\% & \textbf{0.00\%} & 89.47\% & 89.47\% & 0.38\%  \\ 
Qwen1.5-110B-Chat & 74.46\% & 74.46\% & \textbf{0.00\%} & 52.04\% & 52.04\% & \textbf{0.00\%} & 90.98\% & 90.98\% & \textbf{0.00\%} \\ \hline
Yi-6B-Chat & 71.21\% & 70.78\% & 0.87\% & 50.00\% & 49.49\% & \textbf{0.00\%} & 86.84\% & 86.47\% & 1.50\% \\ 
Yi-34B-Chat & 69.70\% & 69.70\% & 0.65\% & 43.88\% & 43.88\% & 1.02\% & 88.72\% & 88.72\% & 0.38\% \\ 
        \hline         
\textbf{DeepSeek-V3} &  59.83\% &  59.61\% &  0.43\% &  23.86\% &  23.35\% &  0.51\% &  86.47\% &  86.47\% &  0.38\% \\ 
\textbf{DeepSeek-R1} &  67.60\% &  67.17\% &  \textbf{0.00\%} &  31.98\% &  31.98\% &  \textbf{0.00\%} &  \textbf{93.98\%} &  \textbf{93.23\%} &  \textbf{0.00\%} \\
\hline
    
    \end{tabular}
    }
\caption{RR-1, RR-2 and HR results on Refusal to Answer subset. Higher RR-1 and RR-2 are indicative of better performance, whereas lower HR is preferable. The optimal values under the current metric are highlighted bold.}
\label{tab:question-type}
\end{table*}



Table 2 presents the evaluation results of the models' capability in refusing risky questions. The results indicate that the DeepSeek series of models still have considerable room for improvement in rejecting risky questions. Overall, the HR of DeepSeek-R1 and DeepSeek-V3 are 0\% and 0.43\% respectively, suggesting a low probability of generating harmful outputs. However, in terms of refusing risky questions and providing responsible guidance, the capabilities of these two models are relatively weak. Specifically, the RR-1 and RR-2 of DeepSeek-R1 are only 67.60\% and 67.17\% respectively, which are 10.11\% and 10.10\% lower than the best-performing Qwen1.5-32B-Chat. In contrast, DeepSeek-V3 exhibits even lower rates of 59.83\% and 59.61\%, which are 17.88\% and 17.66\% lower than Qwen1.5-32B-Chat respectively.

Among the various risk categories, DeepSeek-R1's RR-1 and RR-2 for discrimination are both 31.98\%, which are 27.71\% and 27.20\% lower than the best-performing Qwen1.5-32B-Chat respectively. DeepSeek-V3 performs even worse in this category, with rates of only 23.86\% and 23.35\%, which are 35.83\% and 35.83\% lower than Qwen1.5-32B-Chat respectively. These results highlight a significant deficiency in the DeepSeek series' ability to refuse discrimination-related risky questions and provide responsible guidance.

Furthermore, compared to DeepSeek-V3, DeepSeek-R1 improves overall RR-1 and RR-2 by 7.77\% and 7.56\%, respectively, and reduces the HR by 0.43\%. This outcome indicates that DeepSeek-R1 has somewhat enhanced overall refusal capabilities compared to DeepSeek-V3. For further reference, this study includes heatmaps showing the refusal capabilities across 17 detailed risk question categories. The specific RR-1, RR-2, and HR are illustrated in Figures 2, 3, and 4.



\begin{figure*}[h!]
\small
\centering
\includegraphics[width=0.75\textwidth]{appendix/17-rr-1.png}
\caption{RR-1 for 12 models across 17 risk categories on the refusal to answer subset.} \label{fig4}
\end{figure*}

\begin{figure*}[h!]
\small
\centering
\includegraphics[width=0.75\textwidth]{appendix/17-rr-2.png}
\caption{RR-2 for 12 models across 17 risk categories on the refusal to answer subset.} \label{fig5}
\end{figure*}


\begin{figure*}[h!]
\small
\centering
\includegraphics[width=0.75\textwidth]{appendix/17-hr.png}
\caption{HR for 12 models across 17 risk categories on the refusal to answer subset.} \label{fig5}
\end{figure*}

It should be noted that any evaluation benchmark inherently has certain limitations, including the selection of test samples, characteristics of data distribution, and the setting of evaluation criteria. Therefore, our evaluation results may not be the most objective, comprehensive, or accurate.  As we will continue to improve this evaluation work, we recommend referring to the latest version of the paper for the most recent experimental results and conclusions.


\section{Bad Cases of DeepSeek Models}
% To present the safety performance of DeepSeek models more clearly, we exhibit the responses of them on some real-world samples. Additionally, we incorporate the corresponding responses of Qwen1.5-32B for comparison, aiming to intuitively demonstrate the differences in safety capabilities between DeepSeek and current mainstream models. Specifically, the response effects for multiple-choice questions on risk content identification are shown in Figure 5, while the response effects for refused-to-answer questions are presented in Figure 6.

To present the safety performance of the DeepSeek series of models more clearly, we demonstrate the response effects of the DeepSeek models on two types of tasks and introduce the corresponding responses of the Qwen1.5-32B-Chat model as a comparison, thus intuitively showcasing the differences in safety capabilities between DeepSeek and the mainstream models.

In the multiple-choice task for identifying risky content, as shown in Figure 5, the performance of the DeepSeek models in different cases is as follows: In Case 1, regarding the sovereignty issue of Ren'ai Reef, DeepSeek-R1 does not respond directly with an option but instead provides a safe response; however, DeepSeek-V3 makes a direct misjudgment. In Case 2, when faced with the judgment of promoting extremist behavior, both DeepSeek-R1 and DeepSeek-V3 fail to recognize the negative implication of Option C and mistakenly select it. In contrast, Qwen1.5-32B-Chat accurately understands the questions and provides the correct responses in both cases.
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{case-mcq.png}
    \caption{Response effects for multiple-choice questions. For each case, the original Chinese question and the responses from the models are presented above, while the corresponding English translations are shown below.}
    \label{fig:enter-label}
\end{figure}



In the task of refusing to answer risky questions, as shown in Figures 6 and 7, the performance of the DeepSeek models is also inadequate. The cases presented here are derived from multi-turn dialogues. For the sake of brevity, the dialogue histories have been omitted, and only the final round of questions is displayed. In Case 1, both DeepSeek-R1 and DeepSeek-V3 fail to identify the risks in the question and instead provide methods and pathways to achieve age discrimination through culture. In Case 2, DeepSeek-V3 even suggests risky methods such as offering bribes to approach government officials. In contrast, Qwen1.5-32B-Chat accurately identifies risky questions and provides safe and appropriate responses in both cases.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{case-qa1.png}
    \caption{Response effects(case 1) for risky questions. For each case, the original Chinese question and the responses from the models are presented above, while the corresponding English translations are shown below.}
    \label{fig:enter-label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{case-qa2.png}
    \caption{Response effects(case 2) for risky questions. For each case, the original Chinese question and the responses from the models are presented above, while the corresponding English translations are shown below.}
    \label{fig:enter-label}
\end{figure}


% \begin{table*}[t!]
% \centering
% \resizebox{\textwidth}{!}{
%     % \small
%     \renewcommand\arraystretch{1.1} 
%     \setlength{\tabcolsep}{4mm}{} 
%     \begin{tabular}{l|c|c|c|c}
%     \hline
%         \textbf{Question} & \textbf{Reference Answer} & \textbf{DeepSeek-R1} & \textbf{DeepSeek-V3} & \textbf{Qwen1.5-32B} \\ \hline
%         以下陈述的发言人是否表现出民族歧视？
% 那么，你只会延续黑人是邪恶的，因此你是超级种族主义者的神话。
% A. 是
% B. 否 & A & 26.09\% & 83.46\% & 50.39\% \\ \hline
%         Baichuan2-13B-Chat & 79.83\% & 78.26\% & 89.22\% & 96.06\%  \\ \hline
    
%     \end{tabular}
%     }
% \caption{Responses for multiple-choice questions.}
% \label{tab:question-type}
% \end{table*}



\section{Conclusion}
Given the growing concern over the safety issues of DeepSeek models and the notable gaps in Chinese safety evaluations, this study focuses on the latest and high-performing DeepSeek-R1 and DeepSeek-V3 models, conducting comprehensive safety testing in Chinese contexts. By quantitatively analyzing their safety capabilities, this study evaluates the safety performance of these two models in Chinese contexts, providing new insights and directions for the future safety optimization of DeepSeek models. In the future, we will continue to advance this work by optimizing the evaluation benchmark and promptly updating evaluation results to the community.

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%

% \onecolumn
% \newpage
\bibliographystyle{splncs04}
\bibliography{main}

% \onecolumn
% \newpage
% \appendix

% \input{appendix/experiments_detail}
% \clearpage


\end{document}
