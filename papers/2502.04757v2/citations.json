[
  {
    "index": 0,
    "papers": [
      {
        "key": "li2025images",
        "author": "Li, Yifan and Guo, Hangyu and Zhou, Kun and Zhao, Wayne Xin and Wen, Ji-Rong",
        "title": "Images are achilles\u2019 heel of alignment: Exploiting visual vulnerabilities for jailbreaking multimodal large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "gong2023figstep",
        "author": "Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun",
        "title": "Figstep: Jailbreaking large vision-language models via typographic visual prompts"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "qi2023visual",
        "author": "Qi, Xiangyu and Huang, Kaixuan and Panda, Ashwinee and Henderson, Peter and Wang, Mengdi and Mittal, Prateek",
        "title": "Visual Adversarial Examples Jailbreak Aligned Large Language Models"
      },
      {
        "key": "shayegani2023jailbreak",
        "author": "Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael",
        "title": "Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "siuo2024",
        "author": "Wang, Siyin and Ye, Xingsong and Cheng, Qinyuan and Duan, Junwen and Li, Shimin and Fu, Jinlan and Qiu, Xipeng and Huang, Xuanjing",
        "title": "Cross-modality safety alignment"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "vlguard2024",
        "author": "Yongshuo Zong and Ondrej Bohdal and Tingyang Yu and Yongxin Yang and Timothy Hospedales",
        "title": "Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "mmsafetybench2025",
        "author": "Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Mm-safetybench: A benchmark for safety evaluation of multimodal large language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "mllmguard2024",
        "author": "Tianle Gu and Zeyang Zhou and Kexin Huang and Liang Dandan and Yixu Wang and Haiquan Zhao and Yuanqi Yao and xingge qiao and Keqing wang and Yujiu Yang and Yan Teng and Yu Qiao and Yingchun Wang",
        "title": "{MLLMG}uard: A Multi-dimensional Safety Evaluation Suite for Multimodal Large Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "spavl2024",
        "author": "Zhang, Yongting and Chen, Lu and Zheng, Guodong and Gao, Yifeng and Zheng, Rui and Fu, Jinlan and Yin, Zhenfei and Jin, Senjie and Qiao, Yu and Huang, Xuanjing and others",
        "title": "SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "jailbreak28k2024",
        "author": "Weidi Luo and Siyuan Ma and Xiaogeng Liu and Xiaoyu Guo and Chaowei Xiao",
        "title": "JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "siuo2024",
        "author": "Wang, Siyin and Ye, Xingsong and Cheng, Qinyuan and Duan, Junwen and Li, Shimin and Fu, Jinlan and Qiu, Xipeng and Huang, Xuanjing",
        "title": "Cross-modality safety alignment"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "vlguard2024",
        "author": "Yongshuo Zong and Ondrej Bohdal and Tingyang Yu and Yongxin Yang and Timothy Hospedales",
        "title": "Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models"
      },
      {
        "key": "jailbreak28k2024",
        "author": "Weidi Luo and Siyuan Ma and Xiaogeng Liu and Xiaoyu Guo and Chaowei Xiao",
        "title": "JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks"
      },
      {
        "key": "mmsafetybench2025",
        "author": "Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Mm-safetybench: A benchmark for safety evaluation of multimodal large language models"
      },
      {
        "key": "spavl2024",
        "author": "Zhang, Yongting and Chen, Lu and Zheng, Guodong and Gao, Yifeng and Zheng, Rui and Fu, Jinlan and Yin, Zhenfei and Jin, Senjie and Qiao, Yu and Huang, Xuanjing and others",
        "title": "SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model"
      },
      {
        "key": "rtvlm2024",
        "author": "Li, Mukai  and\nLi, Lei  and\nYin, Yuwei  and\nAhmed, Masood  and\nLiu, Zhenguang  and\nLiu, Qi",
        "title": "Red Teaming Visual Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "inan2023llamaguard",
        "author": "Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others",
        "title": "Llama guard: Llm-based input-output safeguard for human-ai conversations"
      },
      {
        "key": "chi2024llamaguardvision",
        "author": "Chi, Jianfeng and Karn, Ujjwal and Zhan, Hongyuan and Smith, Eric and Rando, Javier and Zhang, Yiming and Plawiak, Kate and Coudert, Zacharie Delpierre and Upasani, Kartikeya and Pasupuleti, Mahesh",
        "title": "Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding Conversations"
      },
      {
        "key": "mllmguard2024",
        "author": "Tianle Gu and Zeyang Zhou and Kexin Huang and Liang Dandan and Yixu Wang and Haiquan Zhao and Yuanqi Yao and xingge qiao and Keqing wang and Yujiu Yang and Yan Teng and Yu Qiao and Yingchun Wang",
        "title": "{MLLMG}uard: A Multi-dimensional Safety Evaluation Suite for Multimodal Large Language Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "strongreject2024",
        "author": "Alexandra Souly and Qingyuan Lu and Dillon Bowen and Tu Trinh and Elvis Hsieh and Sana Pandey and Pieter Abbeel and Justin Svegliato and Scott Emmons and Olivia Watkins and Sam Toyer",
        "title": "A Strong{REJECT} for Empty Jailbreaks"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "strongreject2024",
        "author": "Alexandra Souly and Qingyuan Lu and Dillon Bowen and Tu Trinh and Elvis Hsieh and Sana Pandey and Pieter Abbeel and Justin Svegliato and Scott Emmons and Olivia Watkins and Sam Toyer",
        "title": "A Strong{REJECT} for Empty Jailbreaks"
      },
      {
        "key": "o12024",
        "author": "OpenAI",
        "title": "OpenAI o1 System Card"
      },
      {
        "key": "guan2024deliberative",
        "author": "Guan, Melody Y and Joglekar, Manas and Wallace, Eric and Jain, Saachi and Barak, Boaz and Heylar, Alec and Dias, Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and others",
        "title": "Deliberative alignment: Reasoning enables safer language models"
      }
    ]
  }
]