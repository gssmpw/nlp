

\section{Conclusion}
\label{sec:conclusion}
In this paper, we propose the ELITE evaluator, an enhanced rubric-based evaluation method for assessing the safety of responses generated by VLMs. Furthermore, we introduce the ELITE benchmark, a high-quality safety benchmark of 4,587 image-text pairs filtered using the ELITE evaluator, including 1,054 in-house generated pairs designed to elicit harmful responses for robust safety evaluations of VLMs. Through experiments, we demonstrate the quality of the ELITE benchmark by comparing it with existing benchmarks and show that the ELITE evaluator aligns more closely with human judgments than existing safety evaluation methods. Our experiments highlight the need for overall improvement in safety alignment, and through this work, we aim to strengthen the safety of VLMs.