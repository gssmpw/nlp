

\section{Conclusion}

In this paper, we presented Language-TPP, a unified framework that bridges TPPs with LLMs for modeling event sequences with both temporal and textual information. By introducing specialized byte-tokens for temporal encoding and leveraging text templates for event representation, our framework enables seamless integration of TPPs with standard LLM architectures. Extensive experiments demonstrate that Language-TPP achieves state-of-the-art performance on conventional TPP tasks while enabling high-quality event description generationâ€”a capability previously unexplored in TPP literature. Our results highlight the mutual benefits of combining temporal dynamics with LLMs, suggesting promising directions for future research in multi-modal event sequence modeling.

\textbf{Limitations and future work:} one limitation of the proposed model is the potential context length explosion when processing events with lengthy textual descriptions. Additionally, the current framework may face scalability issues when handling extremely large-scale event sequences with other modalities, such as images and audio. Future work could address these limitations through more sophisticated encoding strategies and attention mechanisms, while also exploring more complex multi-modal information.%


\section*{Impact Statement}
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.