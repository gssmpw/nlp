
 \begin{figure*} [ht]
  \label{fig:pipeline}
  \centering
  \includegraphics[width=\textwidth]{figs/pipeline.jpg}
  \vspace{-15pt}
  \captionof{figure}{We propose a novel BEAM method to produce Gaussian sequences. We first use tracking results of joint Gaussians and a normal regularizer to obtain our 4D Gaussians with consistent geometry. Then we infer roughness using a generative model and apply ray tracing to compute the 2D base color and AO maps, which are then used to optimize the corresponding Gaussian attributes. Our results can be rendered under varying lighting conditions using both real-time and offline rendering.} 
  \label{fig_pipeline}
  \vspace{-7pt}
\end{figure*}
\section{Related Work} 
\paragraph{Human Modeling}
In the field of Human Modeling, numerous methods~\cite{sun2021neural,suo2021neuralhumanfvv,zhao2022human,fridovich2023k} have been proposed to address these challenges. Li~\cite{Temporally} integrates temporal denoising into non-rigid mesh template tracking to capture detailed geometry, while High-quality FVV~\cite{collet2015high} compactly represents human performance using tracked mesh sequences and textured video.

With the advancement of neural rendering techniques~\cite{nerf}, several works have incorporated time as a latent variable to handle dynamic scenes~\cite{pumarola2021d,xian2021space,tretschk2021non}. Meanwhile, other approaches~\cite{peng2021neural,weng2022humannerf,zheng2023avatarrex,habermann2023hdhumans,sun2024real,zhu2024trihuman,pang2024ash} leverage the human parametric model~\cite{loper2023smpl} to reconstruct the animatable avatar. Furthermore, some hybrid methods~\cite{yu2021function4d, jiang2022neuralhofusion,jiang2023instant} combine explicit volumetric fusion with implicit neural techniques to capture more details. 
Additionally, several methods~\cite{wang2023neural,icsik2023humanrf,jiang2023instant,shao2023tensor4d,song2023nerfplayer} significantly accelerate training and rendering speed, by leveraging advanced data structures such as voxel grids~\cite{fridovich2022plenoxels}, hash tables~\cite{muller2022instant}, and tensor decomposition~\cite{chen2022tensorf}.
Recently, 3DGS~\cite{gaussiansplatting} ensures both high quality and fast rendering, while dynamic variants~\cite{sun20243dgstream,wu20244d,luiten2024dynamic,huang2024sc,yang20244d,jiang2024hifi4g,duan20244d,xu2024representing,li2023spacetime} enable complex 4D scene reconstruction for advanced human modeling. DualGS~\cite{jiang2024robust} uses joint and skin Gaussians to capture motion and detailed appearance. However, these approaches fail to recover detailed geometry and do not support relighting.

\paragraph{Human Relighting}
Human Relighting aims to manipulate the reflectance field of the human surface, enabling an immersive fusion with novel illumination. Conventional methods~\cite{chabert2006relighting,debevec2012light,debevec2000acquiring,debevec2002lighting,guo2019relightables,hawkins2001photometric,wenger2005performance,weyrich2006analysis} use LightStage systems to capture human reflectance characteristics, requiring costly controlled lighting and dense camera arrays that are not widely accessible. In 2D image-based relighting tasks, previous methods~\cite{Kanamori_Endo_2018, Tajima_Kanamori_Endo_2021}rely on convolutional networks for inference, while recent diffusion-based approaches~\cite{ding2023diffusionriglearningpersonalizedpriors, Zeng_2024} leverage generative models to learn complex light interactions across large datasets. However, the lack of a 3D representation makes it challenging to maintain 3D consistency of lighting. In addition, some neural relighting methods~\cite{boss2021nerd,zhang2021nerfactor,zeng2023relighting} use NeRF~\cite{nerf} for 3D reconstruction of material properties and lighting effects. However, their rendering quality is inadequate and hard to integrate with traditional CG pipelines.
Recent methods~\cite{gao2025relightable,jiang2024gaussianshader,liang2024gs, gu2024irgs} leverages 3DGS representation for relighting due to its ability to reconstruct fine details and interaction in CG engines. 
For human performance relighting, researchers~\cite{chen2022relighting4d, xu2024relightable, li2024animatablegaussians, chen2024meshavatar, zheng2025physavatar, luvizon2024relightableneuralactorintrinsic} extend mesh-based and neural relighting methods by incorporating body pose priors~\cite{loper2023smpl, jiang2024smplx}. However, avatars relying on skeletal priors struggle with complex clothing, wrinkles, and human-object interactions.


























