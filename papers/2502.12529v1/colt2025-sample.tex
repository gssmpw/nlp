\documentclass[preprint,12pt]{colt2025}
\include{command}
\usepackage{algorithm}
\usepackage{algpseudocode}
\title[Alternating Regret for Online Convex Optimization]{Alternating Regret for Online Convex Optimization}
\usepackage{times}

\coltauthor{%
 \Name{Soumita Hait\nametag{\thanks{Authors are listed in alphabetical order.}}} \Email{hait@usc.edu}\\
 \addr University of Southern California
 \AND
 \Name{Ping Li\nametag{\footnotemark[1]}} \Email{pinglee@stu.sufe.edu.cn}\\
 \addr Shanghai University of Finance and Economics%
 \AND
 \Name{Haipeng Luo\nametag{\footnotemark[1]}} \Email{haipengl@usc.edu}\\
 \addr University of Southern California%
 \AND
 \Name{Mengxiao Zhang\nametag{\footnotemark[1]}} \Email{mengxiao-zhang@uiowa.edu}\\
 \addr University of Iowa
}

\begin{document}

\maketitle

\begin{abstract}%
Motivated by alternating learning dynamics in two-player games, a recent work by \citet{cevher2024alternation} shows that $o(\sqrt{T})$ alternating regret is possible for any $T$-round adversarial Online Linear Optimization (OLO) problem, and left as an open question whether the same is true for general Online Convex Optimization (OCO).
We answer this question in the affirmative by showing that 
the continuous Hedge algorithm achieves $\tilde{\mathcal{O}}(d^{\frac{2}{3}}T^{\frac{1}{3}})$ alternating regret for any adversarial $d$-dimensional OCO problems.
We show that this implies an alternating learning dynamic that finds a Nash equilibrium for any convex-concave zero-sum games or a coarse correlated equilibrium for any convex two-player general-sum games at a rate of $\tilde{\mathcal{O}}(d^{\frac{2}{3}}/T^{\frac{2}{3}})$.
To further improve the time complexity and/or the dimension dependence, we propose another simple algorithm, Follow-the-Regularized-Leader with a regularizer whose convex conjugate is 3rd-order smooth, for OCO with smooth and self-concordant loss functions (such as linear or quadratic losses).
We instantiate our algorithm with different regularizers and show that, for example, when the decision set is the $\ell_2$ ball, our algorithm achieves $\tilde{\mathcal{O}}(T^{\frac{2}{5}})$ alternating regret with no dimension dependence (and a better $\tilde{\mathcal{O}}(T^{\frac{1}{3}})$ bound for quadratic losses).
We complement our results by showing some algorithm-specific alternating regret lower bounds, including a somewhat surprising $\Omega(\sqrt{T})$ lower bound for a Regret Matching variant that is widely used in alternating learning dynamics.
\end{abstract}

\begin{keywords}%
Online Convex Optimization, alternating regret, alternating learning dynamics
\end{keywords}

\input{intro}
\input{preliminary}
\input{upper_bound}
\input{FTRL_SC}
\input{lower_bound}
\input{conclusion}

\bibliography{ref}
\newpage
\appendix

\input{appendix_pre}
\input{appendix_general_oco}
\input{appendix_scb}
\input{appendix_alt_oco}
\input{appendix_lower_bound}

\end{document}
