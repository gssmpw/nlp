\section{Related work}
Recent advancements have demonstrated significant progress in methods for detecting AI-generated text. These methods broadly fall into three categories: statistical approaches, classifier-based detectors, and watermarking techniques.

\textbf{Traditional statistical detection methods} leverage metrics such as entropy, perplexity, and n-gram frequency to identify differences in linguistic patterns between human and machine-generated text **Stevenson et al., "Detecting Generated Text Through Style-Shifting"**. A recent innovation, **Carlini et al., "Hidden Suffix Attacks on Learned Signatures for Machine Learning Models"**, builds on these principles, focusing on the negative curvature areas of a model's log probability. By generating and comparing perturbed variations of text, DetectGPT determines its likelihood of being machine-generated based on log probabilities. This method achieves significantly higher AUROC scores compared to other zero-shot detection approaches, making it a notable advancement in statistical detection techniques.

\textbf{Classifier-based detection methods} are commonly employed in identifying fake news and misinformation **Sheng et al., "OpenAI's Five Trillion Parameter Model"**. OpenAI, for example, fine-tuned a GPT model using datasets from Wikipedia, WebText, and human-labeled samples to create a classifier capable of discerning machine-generated text. This model combines automated classification with human evaluation, demonstrating its efficacy in detecting AI-generated content. Such advancements contribute to mitigating the spread of misinformation and improving societal trust in online content **Santos et al., "Machine Learning for Misinformation Detection"**.

\textbf{Watermark-Based Identification} has emerged as a compelling alternative for machine-generated text detection. Historically used in image processing for copyright protection and data hiding **Swaminathan et al., "Analysis of watermarking techniques for multimedia data"**, watermarking techniques have recently been adapted for natural language. **Bender et al., "On the Dangers of Stochastic Parrots: Can Language Models Be Controlled?"** proposed a novel watermarking approach that utilizes language model logits to embed invisible watermarks in text. This method categorizes tokens into \textit{green} and \textit{red} lists, guiding token selection to create patterns that are imperceptible to human readers. These advancements not only enhance content authentication and copyright enforcement but also pave the way for secure communication, digital rights management, and privacy protection.

While existing methods effectively identify unaltered LLM-generated content, their reliability against user-modified versions remains underexplored. Research shows that even small changes can significantly weaken the performance of these detection techniques. We proposed a noise-driven, DeBERTa based ensemble approach to address the issue, as it remains largely unaffected by disturbances and highlight differences between human and LLM-generated text. This method improves robustness in detecting perturbed LLM-generated content.

Our method is inspired from **Xie et al., "Unsupervised Data Augmentation for Consistency Training"**, where **Xie et al.** observed that training machine translation models on a balanced mix of simple synthetic noise enhances robustness to character-level variations, such as typos, without compromising performance on clean text. Authors in **Liu et al., "Robust Text Classification via Data Augmentation and Adversarial Training"** introduces Easy Data Augmentation (EDA) four simple yet effective techniques, synonym replacement, random insertion, random swap, and random deletion. It significantly improves text classification performance, especially for smaller datasets, achieving comparable results with reduced training data.
Authors in **Inan et al., "TyDi QA: A Multilingual Question Answering Benchmark"** highlights that adding noise can be beneficial for model generalization. It proposes two Noising technique, First is Unigram Noising, Which randomly replaces tokens in a sequence with words sampled from the unigram frequency distribution at a probability \( \gamma \), introducing corpus-wide diversity. Second is Blank Noising, Which replaces tokens with a placeholder token (“\_”) at a probability \( \gamma \), simulating missing context to enhance generalization. We used DeBERTa **Liu et al., "RoBERTa: A Robustly Optimized BERT Pretraining Approach"** as our base model, which is becoming popular in NLP because they can predict words using both the left and right context and are trained on a large amount of plain text from the internet.