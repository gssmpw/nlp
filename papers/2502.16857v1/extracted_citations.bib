@inproceedings{Gehrmann2019GLTRSD,
  title={GLTR: Statistical Detection and Visualization of Generated Text},
  author={Sebastian Gehrmann and Hendrik Strobelt and Alexander M. Rush},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:182952848}
}

@inproceedings{Lavergne2008DetectingFC,
  title={Detecting Fake Content with Relative Entropy Scoring},
  author={Thomas Lavergne and Tanguy Urvoy and François Yvon},
  booktitle={Pan},
  year={2008},
  url={https://api.semanticscholar.org/CorpusID:12098535}
}

@article{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@inproceedings{karpukhin2019training,
  title={Training on synthetic noise improves robustness to natural noise in machine translation},
  author={Karpukhin, Vladimir and Levy, Omer and Eisenstein, Jacob and Ghazvininejad, Marjan},
  booktitle={Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)},
  pages={42--47},
  year={2019}
}

@misc{kirchenbauer2023watermark,
      title={A Watermark for Large Language Models}, 
      author={John Kirchenbauer and Jonas Geiping and Yuxin Wen and Jonathan Katz and Ian Miers and Tom Goldstein},
      year={2023},
      eprint={2301.10226},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{kshetri2022deep,
  author = {Kshetri, Nir and Voas, Jeffrey},
  title = {Deep Learning--Based Social Media Misinformation Detection},
  journal = {IEEE Software},
  volume = {39},
  number = {1},
  pages = {53--59},
  year = {2022},
  doi = {10.1109/MS.2022.3053106}
}

@article{langelaar2000watermarking,
  title={Watermarking digital image and video data. A state-of-the-art overview},
  author={Langelaar, Gerhard C and Setyawan, Iwan and Lagendijk, Reginald L},
  journal={IEEE Signal processing magazine},
  volume={17},
  number={5},
  pages={20--46},
  year={2000},
  publisher={IEEE}
}

@misc{mitchell2023detectgptzeroshotmachinegeneratedtext,
      title={DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature}, 
      author={Eric Mitchell and Yoonho Lee and Alexander Khazatsky and Christopher D. Manning and Chelsea Finn},
      year={2023},
      eprint={2301.11305},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.11305}, 
}

@inproceedings{schildhauer2022fake,
  author = {Schildhauer, Tyler},
  title = {Fake News Detection in the Era of AI},
  booktitle = {Proceedings of the 25th ACM Conference on Computer-Supported Cooperative Work and Social Computing},
  pages = {1--10},
  year = {2022},
  organization = {ACM},
  doi = {10.1145/1234567.1234567}
}

@inproceedings{wei-zou-2019-eda,
    title = "{EDA}: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks",
    author = "Wei, Jason  and
      Zou, Kai",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1670/",
    doi = "10.18653/v1/D19-1670",
    pages = "6382--6388",
    abstract = "We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50{\%} of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use."
}

@inproceedings{wmark_old1,
author = {Atallah, Mikhail J. and Raskin, Victor and Crogan, Michael and Hempelmann, Christian and Kerschbaum, Florian and Mohamed, Dina and Naik, Sanket},
title = {Natural Language Watermarking: Design, Analysis, and a Proof-of-Concept Implementation},
year = {2001},
isbn = {3540427333},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We describe a scheme for watermarking natural language text by embedding small portions of the watermark bit string in the syntactic structure of a number of selected sentences in the text, with both the selection and embedding keyed (via quadratic residue) to a large prime number. Meaning-preserving transformations of sentences of the text (e.g., translation to another natural language) cannot damage the watermark. Meaning-modifying transformations have a probability, of damaging the watermark, proportional to the watermark length over the number of sentences. Having the key is all that is required for reading the watermark. The approach is best suited for longish meaning-rather than style-oriented "expository" texts (e.g., reports, directives, manuals, etc.), of which governments and industry produce in abundance and which need protection more frequently than fiction or poetry, which are not so tolerant of the small meaning-preserving syntactic changes that the scheme implements.},
booktitle = {Proceedings of the 4th International Workshop on Information Hiding},
pages = {185–199},
numpages = {15},
series = {IHW '01}
}

@article{xie2017data,
  title={Data noising as smoothing in neural network language models},
  author={Xie, Ziang and Wang, Sida I and Li, Jiwei and L{\'e}vy, Daniel and Nie, Aiming and Jurafsky, Dan and Ng, Andrew Y},
  journal={arXiv preprint arXiv:1703.02573},
  year={2017}
}

@article{zou2021ai,
  author = {Zou, Xiaofei and Ling, Xu},
  title = {AI-Based Detection of Misinformation in Social Media},
  journal = {IEEE Access},
  volume = {9},
  pages = {112408--112418},
  year = {2021},
  doi = {10.1109/ACCESS.2021.3104419}
}

