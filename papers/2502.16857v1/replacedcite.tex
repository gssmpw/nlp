\section{Related work}
Recent advancements have demonstrated significant progress in methods for detecting AI-generated text. These methods broadly fall into three categories: statistical approaches, classifier-based detectors, and watermarking techniques.

\textbf{Traditional statistical detection methods} leverage metrics such as entropy, perplexity, and n-gram frequency to identify differences in linguistic patterns between human and machine-generated text ____. A recent innovation, DetectGPT ____, builds on these principles, focusing on the negative curvature areas of a model's log probability. By generating and comparing perturbed variations of text, DetectGPT determines its likelihood of being machine-generated based on log probabilities. This method achieves significantly higher AUROC scores compared to other zero-shot detection approaches, making it a notable advancement in statistical detection techniques.

\textbf{Classifier-based detection methods} are commonly employed in identifying fake news and misinformation ____. OpenAI, for example, fine-tuned a GPT model using datasets from Wikipedia, WebText, and human-labeled samples to create a classifier capable of discerning machine-generated text. This model combines automated classification with human evaluation, demonstrating its efficacy in detecting AI-generated content. Such advancements contribute to mitigating the spread of misinformation and improving societal trust in online content ____.

\textbf{Watermark-Based Identification} has emerged as a compelling alternative for machine-generated text detection. Historically used in image processing for copyright protection and data hiding ____, watermarking techniques have recently been adapted for natural language. ____ proposed a novel watermarking approach that utilizes language model logits to embed invisible watermarks in text. This method categorizes tokens into \textit{green} and \textit{red} lists, guiding token selection to create patterns that are imperceptible to human readers. These advancements not only enhance content authentication and copyright enforcement but also pave the way for secure communication, digital rights management, and privacy protection.

While existing methods effectively identify unaltered LLM-generated content, their reliability against user-modified versions remains underexplored. Research shows that even small changes can significantly weaken the performance of these detection techniques. We proposed a noise-driven, DeBERTa based ensemble approach to address the issue, as it remains largely unaffected by disturbances and highlight differences between human and LLM-generated text. This method improves robustness in detecting perturbed LLM-generated content.

Our method is inspired from ____, where ____ observed that training machine translation models on a balanced mix of simple synthetic noise enhances robustness to character-level variations, such as typos, without compromising performance on clean text. Authors in ____ introduces Easy Data Augmentation (EDA) four simple yet effective techniques, synonym replacement, random insertion, random swap, and random deletion. It significantly improves text classification performance, especially for smaller datasets, achieving comparable results with reduced training data.
Authors in ____ highlights that adding noise can be beneficial for model generalization. It proposes two Noising technique, First is Unigram Noising, Which randomly replaces tokens in a sequence with words sampled from the unigram frequency distribution at a probability \( \gamma \), introducing corpus-wide diversity. Second is Blank Noising, Which replaces tokens with a placeholder token (“\_”) at a probability \( \gamma \), simulating missing context to enhance generalization. We used DeBERTa ____ as our base model, which is becoming popular in NLP because they can predict words using both the left and right context and are trained on a large amount of plain text from the internet.