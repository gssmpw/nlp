@article{lynch2023interactive,
  title={Interactive language: Talking to robots in real time},
  author={Lynch, Corey and Wahid, Ayzaan and Tompson, Jonathan and Ding, Tianli and Betker, James and Baruch, Robert and Armstrong, Travis and Florence, Pete},
  journal={IEEE Robotics and Automation Letters},
  year={2023},
  publisher={IEEE}
}

@book{kahneman2011thinking,
  added-at = {2013-01-10T15:41:11.000+0100},
  address = {New York},
  author = {Kahneman, Daniel},
  biburl = {https://www.bibsonomy.org/bibtex/2f322864169411fd5914f3fa5488e288c/schmidt2},
  description = {Thinking, Fast and Slow: Amazon.de: Daniel Kahneman: Englische Bücher},
  interhash = {a1400a299a00de009ec8eda73e6289af},
  intrahash = {f322864169411fd5914f3fa5488e288c},
  isbn = {9780374275631 0374275637},
  keywords = {bib books psychology thinking toread},
  publisher = {Farrar, Straus and Giroux},
  refid = {706020998},
  timestamp = {2013-01-10T15:41:11.000+0100},
  title = {Thinking, fast and slow},
  year = 2011
}

@inproceedings{jang2022bc,
  title={Bc-z: Zero-shot task generalization with robotic imitation learning},
  author={Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={991--1002},
  year={2022},
  organization={PMLR}
}

@article{wen2024tinyvla,
  title={Tinyvla: Towards fast, data-efficient vision-language-action models for robotic manipulation},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Zhu, Minjie and Wu, Kun and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and others},
  journal={arXiv preprint arXiv:2409.12514},
  year={2024}
}

@article{liu2024rdt,
  title={Rdt-1b: a diffusion foundation model for bimanual manipulation},
  author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2410.07864},
  year={2024}
}

@article{li2024cogact,
  title={CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation},
  author={Li, Qixiu and Liang, Yaobo and Wang, Zeyu and Luo, Lin and Chen, Xi and Liao, Mozheng and Wei, Fangyun and Deng, Yu and Xu, Sicheng and Zhang, Yizhong and others},
  journal={arXiv preprint arXiv:2411.19650},
  year={2024}
}

@article{zheng2025universal,
  title={Universal Actions for Enhanced Embodied Foundation Models},
  author={Zheng, Jinliang and Li, Jianxiong and Liu, Dongxiu and Zheng, Yinan and Wang, Zhihao and Ou, Zhonghong and Liu, Yu and Liu, Jingjing and Zhang, Ya-Qin and Zhan, Xianyuan},
  journal={arXiv preprint arXiv:2501.10105},
  year={2025}
}

@inproceedings{o2024open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models: Open x-embodiment collaboration 0},
  author={O’Neill, Abby and Rehman, Abdul and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and Jain, Ajinkya and others},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6892--6903},
  year={2024},
  organization={IEEE}
}

@article{pertsch2025fast,
  title={FAST: Efficient Action Tokenization for Vision-Language-Action Models},
  author={Pertsch, Karl and Stachowicz, Kyle and Ichter, Brian and Driess, Danny and Nair, Suraj and Vuong, Quan and Mees, Oier and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2501.09747},
  year={2025}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International conference on machine learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@article{stepputtis2020language,
  title={Language-conditioned imitation learning for robot manipulation tasks},
  author={Stepputtis, Simon and Campbell, Joseph and Phielipp, Mariano and Lee, Stefan and Baral, Chitta and Ben Amor, Heni},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13139--13150},
  year={2020}
}

@article{lynch2020grounding,
  title={Grounding language in play},
  author={Lynch, Corey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:2005.07648},
  volume={40},
  number={396},
  pages={105},
  year={2020}
}

@inproceedings{brohan2023can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others},
  booktitle={Conference on robot learning},
  pages={287--318},
  year={2023},
  organization={PMLR}
}

@article{shi2024yell,
  title={Yell at your robot: Improving on-the-fly from language corrections},
  author={Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2403.12910},
  year={2024}
}

@article{brohan2022rt,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022}
}

@article{black2024pi_0,
  title={$\pi_0$: A Vision-Language-Action Flow Model for General Robot Control},
  author={Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and others},
  journal={arXiv preprint arXiv:2410.24164},
  year={2024}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}


@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@inproceedings{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@inproceedings{liu2024moka,
  title={Moka: Open-vocabulary robotic manipulation through mark-based visual prompting},
  author={Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey},
  booktitle={First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024},
  year={2024}
}

@article{nasiriany2024pivot,
  title={Pivot: Iterative visual prompting elicits actionable knowledge for vlms},
  author={Nasiriany, Soroush and Xia, Fei and Yu, Wenhao and Xiao, Ted and Liang, Jacky and Dasgupta, Ishita and Xie, Annie and Driess, Danny and Wahid, Ayzaan and Xu, Zhuo and others},
  journal={arXiv preprint arXiv:2402.07872},
  year={2024}
}

@article{chen2024automating,
  title={Automating Robot Failure Recovery Using Vision-Language Models With Optimized Prompts},
  author={Chen, Hongyi and Yao, Yunchao and Liu, Ruixuan and Liu, Changliu and Ichnowski, Jeffrey},
  journal={arXiv preprint arXiv:2409.03966},
  year={2024}
}

@article{shah2024bumble,
  title={BUMBLE: Unifying Reasoning and Acting with Vision-Language Models for Building-wide Mobile Manipulation},
  author={Shah, Rutav and Yu, Albert and Zhu, Yifeng and Zhu, Yuke and Mart{\'\i}n-Mart{\'\i}n, Roberto},
  journal={arXiv preprint arXiv:2410.06237},
  year={2024}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@article{wang2024llm,
  title={LLM\^{} 3: Large Language Model-based Task and Motion Planning with Motion Failure Reasoning},
  author={Wang, Shu and Han, Muzhi and Jiao, Ziyuan and Zhang, Zeyu and Wu, Ying Nian and Zhu, Song-Chun and Liu, Hangxin},
  journal={arXiv preprint arXiv:2403.11552},
  year={2024}
}

@article{liu2024ok,
  title={Ok-robot: What really matters in integrating open-knowledge models for robotics},
  author={Liu, Peiqi and Orru, Yaswanth and Vakil, Jay and Paxton, Chris and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2401.12202},
  year={2024}
}

@article{stone2023open,
  title={Open-world object manipulation using pre-trained vision-language models},
  author={Stone, Austin and Xiao, Ted and Lu, Yao and Gopalakrishnan, Keerthana and Lee, Kuang-Huei and Vuong, Quan and Wohlhart, Paul and Kirmani, Sean and Zitkovich, Brianna and Xia, Fei and others},
  journal={arXiv preprint arXiv:2303.00905},
  year={2023}
}

@article{qiu2024open,
  title={Open-vocabulary mobile manipulation in unseen dynamic environments with 3d semantic maps},
  author={Qiu, Dicong and Ma, Wenzong and Pan, Zhenfu and Xiong, Hui and Liang, Junwei},
  journal={arXiv preprint arXiv:2406.18115},
  year={2024}
}

@article{zhi2024closed,
  title={Closed-loop open-vocabulary mobile manipulation with gpt-4v},
  author={Zhi, Peiyuan and Zhang, Zhiyuan and Han, Muzhi and Zhang, Zeyu and Li, Zhitian and Jiao, Ziyuan and Jia, Baoxiong and Huang, Siyuan},
  journal={arXiv preprint arXiv:2404.10220},
  year={2024}
}

@article{liu2023interactive,
  title={Interactive robot learning from verbal correction},
  author={Liu, Huihan and Chen, Alice and Zhu, Yuke and Swaminathan, Adith and Kolobov, Andrey and Cheng, Ching-An},
  journal={arXiv preprint arXiv:2310.17555},
  year={2023}
}

@article{dai2024racer,
  title={RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning},
  author={Dai, Yinpei and Lee, Jayjun and Fazeli, Nima and Chai, Joyce},
  journal={arXiv preprint arXiv:2409.14674},
  year={2024}
}

@article{xiao2024robi,
  title={Robi Butler: Remote Multimodal Interactions with Household Robot Assistant},
  author={Xiao, Anxing and Janaka, Nuwan and Hu, Tianrun and Gupta, Anshul and Li, Kaixin and Yu, Cunjun and Hsu, David},
  journal={arXiv preprint arXiv:2409.20548},
  year={2024}
}

@inproceedings{swadzba2009computational,
  title={A computational model for the alignment of hierarchical scene representations in human-robot interaction},
  author={Swadzba, Agnes and Vorwerg, Constanze and Wachsmuth, Sven and Rickheit, Gert},
  booktitle={Twenty-First International Joint Conference on Artificial Intelligence},
  year={2009},
  organization={Citeseer}
}

@inproceedings{matuszek2013learning,
  title={Learning to Parse Natural Language Commands to a Robot Control System},
  author={Matuszek, Cynthia and Herbst, Evan and Zettlemoyer, Luke and Fox, Dieter},
  booktitle={Experimental Robotics: The 13th International Symposium on Experimental Robotics},
  volume={88},
  pages={403},
  year={2013},
  organization={Springer}
}

@inproceedings{namasivayam2023learning,
  title={Learning neuro-symbolic programs for language guided robot manipulation},
  author={Namasivayam, K and Singh, Himanshu and Bindal, Vishal and Tuli, Arnav and Agrawal, Vishwajeet and Jain, Rahul and Singla, Parag and Paul, Rohan},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7973--7980},
  year={2023},
  organization={IEEE}
}

@inproceedings{patki2019inferring,
  title={Inferring compact representations for efficient natural language understanding of robot instructions},
  author={Patki, Siddharth and Daniele, Andrea F and Walter, Matthew R and Howard, Thomas M},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={6926--6933},
  year={2019},
  organization={IEEE}
}

@article{belkhale2024rt,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}
@article{singh2024lgr2,
  title={LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning},
  author={Singh, Utsav and Bhattacharyya, Pramit and Namboodiri, Vinay P},
  journal={arXiv preprint arXiv:2406.05881},
  year={2024}
}

@inproceedings{mccallum2023feedback,
  title={Is feedback all you need? Leveraging natural language feedback in goal-conditioned RL},
  author={McCallum, Sabrina and Taylor-Davies, Max and Albrecht, Stefano and Suglia, Alessandro},
  booktitle={NeurIPS 2023 Workshop on Goal-Conditioned Reinforcement Learning}
}

@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}

@inproceedings{chi2023diffusionpolicy,
	title={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
	booktitle={Proceedings of Robotics: Science and Systems (RSS)},
	year={2023}
}

@inproceedings{octo_2023,
    title={Octo: An Open-Source Generalist Robot Policy},
    author = {{Octo Model Team} and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Charles Xu and Jianlan Luo and Tobias Kreiman and {You Liang} Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine},
    booktitle = {Proceedings of Robotics: Science and Systems},
    address  = {Delft, Netherlands},
    year = {2024},
}

@article{beyer2024paligemma,
  title={Paligemma: A versatile 3b vlm for transfer},
  author={Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others},
  journal={arXiv preprint arXiv:2407.07726},
  year={2024}
}

@article{stephan2024rlvf,
  title={Rlvf: Learning from verbal feedback without overgeneralization},
  author={Stephan, Moritz and Khazatsky, Alexander and Mitchell, Eric and Chen, Annie S and Hsu, Sheryl and Sharma, Archit and Finn, Chelsea},
  journal={arXiv preprint arXiv:2402.10893},
  year={2024}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{zawalski2024robotic,
  title={Robotic control via embodied chain-of-thought reasoning},
  author={Zawalski, Micha{\l} and Chen, William and Pertsch, Karl and Mees, Oier and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2407.08693},
  year={2024}
}

@article{fu2024mobile,
  title={Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation},
  author={Fu, Zipeng and Zhao, Tony Z and Finn, Chelsea},
  journal={arXiv preprint arXiv:2401.02117},
  year={2024}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}
