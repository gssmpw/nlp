[
  {
    "index": 0,
    "papers": [
      {
        "key": "brohan2023rt",
        "author": "Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others",
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control"
      },
      {
        "key": "wen2024tinyvla",
        "author": "Wen, Junjie and Zhu, Yichen and Li, Jinming and Zhu, Minjie and Wu, Kun and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and others",
        "title": "Tinyvla: Towards fast, data-efficient vision-language-action models for robotic manipulation"
      },
      {
        "key": "kim2024openvla",
        "author": "Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others",
        "title": "OpenVLA: An Open-Source Vision-Language-Action Model"
      },
      {
        "key": "black2024pi_0",
        "author": "Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and others",
        "title": "$\\pi_0$: A Vision-Language-Action Flow Model for General Robot Control"
      },
      {
        "key": "liu2024rdt",
        "author": "Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun",
        "title": "Rdt-1b: a diffusion foundation model for bimanual manipulation"
      },
      {
        "key": "li2024cogact",
        "author": "Li, Qixiu and Liang, Yaobo and Wang, Zeyu and Luo, Lin and Chen, Xi and Liao, Mozheng and Wei, Fangyun and Deng, Yu and Xu, Sicheng and Zhang, Yizhong and others",
        "title": "CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation"
      },
      {
        "key": "o2024open",
        "author": "O\u2019Neill, Abby and Rehman, Abdul and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and Jain, Ajinkya and others",
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models: Open x-embodiment collaboration 0"
      },
      {
        "key": "zawalski2024robotic",
        "author": "Zawalski, Micha{\\l} and Chen, William and Pertsch, Karl and Mees, Oier and Finn, Chelsea and Levine, Sergey",
        "title": "Robotic control via embodied chain-of-thought reasoning"
      },
      {
        "key": "zheng2025universal",
        "author": "Zheng, Jinliang and Li, Jianxiong and Liu, Dongxiu and Zheng, Yinan and Wang, Zhihao and Ou, Zhonghong and Liu, Yu and Liu, Jingjing and Zhang, Ya-Qin and Zhan, Xianyuan",
        "title": "Universal Actions for Enhanced Embodied Foundation Models"
      },
      {
        "key": "pertsch2025fast",
        "author": "Pertsch, Karl and Stachowicz, Kyle and Ichter, Brian and Driess, Danny and Nair, Suraj and Vuong, Quan and Mees, Oier and Finn, Chelsea and Levine, Sergey",
        "title": "FAST: Efficient Action Tokenization for Vision-Language-Action Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "huang2022language",
        "author": "Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor",
        "title": "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents"
      },
      {
        "key": "brohan2023can",
        "author": "Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others",
        "title": "Do as i can, not as i say: Grounding language in robotic affordances"
      },
      {
        "key": "liang2023code",
        "author": "Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy",
        "title": "Code as policies: Language model programs for embodied control"
      },
      {
        "key": "shah2024bumble",
        "author": "Shah, Rutav and Yu, Albert and Zhu, Yifeng and Zhu, Yuke and Mart{\\'\\i}n-Mart{\\'\\i}n, Roberto",
        "title": "BUMBLE: Unifying Reasoning and Acting with Vision-Language Models for Building-wide Mobile Manipulation"
      },
      {
        "key": "singh2023progprompt",
        "author": "Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh",
        "title": "Progprompt: Generating situated robot task plans using large language models"
      },
      {
        "key": "wang2024llm",
        "author": "Wang, Shu and Han, Muzhi and Jiao, Ziyuan and Zhang, Zeyu and Wu, Ying Nian and Zhu, Song-Chun and Liu, Hangxin",
        "title": "LLM\\^{} 3: Large Language Model-based Task and Motion Planning with Motion Failure Reasoning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "huang2023voxposer",
        "author": "Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li",
        "title": "Voxposer: Composable 3d value maps for robotic manipulation with language models"
      },
      {
        "key": "liu2024moka",
        "author": "Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey",
        "title": "Moka: Open-vocabulary robotic manipulation through mark-based visual prompting"
      },
      {
        "key": "nasiriany2024pivot",
        "author": "Nasiriany, Soroush and Xia, Fei and Yu, Wenhao and Xiao, Ted and Liang, Jacky and Dasgupta, Ishita and Xie, Annie and Driess, Danny and Wahid, Ayzaan and Xu, Zhuo and others",
        "title": "Pivot: Iterative visual prompting elicits actionable knowledge for vlms"
      },
      {
        "key": "chen2024automating",
        "author": "Chen, Hongyi and Yao, Yunchao and Liu, Ruixuan and Liu, Changliu and Ichnowski, Jeffrey",
        "title": "Automating Robot Failure Recovery Using Vision-Language Models With Optimized Prompts"
      },
      {
        "key": "liu2024ok",
        "author": "Liu, Peiqi and Orru, Yaswanth and Vakil, Jay and Paxton, Chris and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel",
        "title": "Ok-robot: What really matters in integrating open-knowledge models for robotics"
      },
      {
        "key": "stone2023open",
        "author": "Stone, Austin and Xiao, Ted and Lu, Yao and Gopalakrishnan, Keerthana and Lee, Kuang-Huei and Vuong, Quan and Wohlhart, Paul and Kirmani, Sean and Zitkovich, Brianna and Xia, Fei and others",
        "title": "Open-world object manipulation using pre-trained vision-language models"
      },
      {
        "key": "qiu2024open",
        "author": "Qiu, Dicong and Ma, Wenzong and Pan, Zhenfu and Xiong, Hui and Liang, Junwei",
        "title": "Open-vocabulary mobile manipulation in unseen dynamic environments with 3d semantic maps"
      },
      {
        "key": "zhi2024closed",
        "author": "Zhi, Peiyuan and Zhang, Zhiyuan and Han, Muzhi and Zhang, Zeyu and Li, Zhitian and Jiao, Ziyuan and Jia, Baoxiong and Huang, Siyuan",
        "title": "Closed-loop open-vocabulary mobile manipulation with gpt-4v"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "huang2022language",
        "author": "Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor",
        "title": "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents"
      },
      {
        "key": "brohan2023can",
        "author": "Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others",
        "title": "Do as i can, not as i say: Grounding language in robotic affordances"
      },
      {
        "key": "liang2023code",
        "author": "Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy",
        "title": "Code as policies: Language model programs for embodied control"
      },
      {
        "key": "shah2024bumble",
        "author": "Shah, Rutav and Yu, Albert and Zhu, Yifeng and Zhu, Yuke and Mart{\\'\\i}n-Mart{\\'\\i}n, Roberto",
        "title": "BUMBLE: Unifying Reasoning and Acting with Vision-Language Models for Building-wide Mobile Manipulation"
      },
      {
        "key": "singh2023progprompt",
        "author": "Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh",
        "title": "Progprompt: Generating situated robot task plans using large language models"
      },
      {
        "key": "wang2024llm",
        "author": "Wang, Shu and Han, Muzhi and Jiao, Ziyuan and Zhang, Zeyu and Wu, Ying Nian and Zhu, Song-Chun and Liu, Hangxin",
        "title": "LLM\\^{} 3: Large Language Model-based Task and Motion Planning with Motion Failure Reasoning"
      },
      {
        "key": "huang2023voxposer",
        "author": "Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li",
        "title": "Voxposer: Composable 3d value maps for robotic manipulation with language models"
      },
      {
        "key": "liu2024moka",
        "author": "Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey",
        "title": "Moka: Open-vocabulary robotic manipulation through mark-based visual prompting"
      },
      {
        "key": "nasiriany2024pivot",
        "author": "Nasiriany, Soroush and Xia, Fei and Yu, Wenhao and Xiao, Ted and Liang, Jacky and Dasgupta, Ishita and Xie, Annie and Driess, Danny and Wahid, Ayzaan and Xu, Zhuo and others",
        "title": "Pivot: Iterative visual prompting elicits actionable knowledge for vlms"
      },
      {
        "key": "chen2024automating",
        "author": "Chen, Hongyi and Yao, Yunchao and Liu, Ruixuan and Liu, Changliu and Ichnowski, Jeffrey",
        "title": "Automating Robot Failure Recovery Using Vision-Language Models With Optimized Prompts"
      },
      {
        "key": "liu2024ok",
        "author": "Liu, Peiqi and Orru, Yaswanth and Vakil, Jay and Paxton, Chris and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel",
        "title": "Ok-robot: What really matters in integrating open-knowledge models for robotics"
      },
      {
        "key": "stone2023open",
        "author": "Stone, Austin and Xiao, Ted and Lu, Yao and Gopalakrishnan, Keerthana and Lee, Kuang-Huei and Vuong, Quan and Wohlhart, Paul and Kirmani, Sean and Zitkovich, Brianna and Xia, Fei and others",
        "title": "Open-world object manipulation using pre-trained vision-language models"
      },
      {
        "key": "qiu2024open",
        "author": "Qiu, Dicong and Ma, Wenzong and Pan, Zhenfu and Xiong, Hui and Liang, Junwei",
        "title": "Open-vocabulary mobile manipulation in unseen dynamic environments with 3d semantic maps"
      },
      {
        "key": "zhi2024closed",
        "author": "Zhi, Peiyuan and Zhang, Zhiyuan and Han, Muzhi and Zhang, Zeyu and Li, Zhitian and Jiao, Ziyuan and Jia, Baoxiong and Huang, Siyuan",
        "title": "Closed-loop open-vocabulary mobile manipulation with gpt-4v"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "swadzba2009computational",
        "author": "Swadzba, Agnes and Vorwerg, Constanze and Wachsmuth, Sven and Rickheit, Gert",
        "title": "A computational model for the alignment of hierarchical scene representations in human-robot interaction"
      },
      {
        "key": "matuszek2013learning",
        "author": "Matuszek, Cynthia and Herbst, Evan and Zettlemoyer, Luke and Fox, Dieter",
        "title": "Learning to Parse Natural Language Commands to a Robot Control System"
      },
      {
        "key": "namasivayam2023learning",
        "author": "Namasivayam, K and Singh, Himanshu and Bindal, Vishal and Tuli, Arnav and Agrawal, Vishwajeet and Jain, Rahul and Singla, Parag and Paul, Rohan",
        "title": "Learning neuro-symbolic programs for language guided robot manipulation"
      },
      {
        "key": "patki2019inferring",
        "author": "Patki, Siddharth and Daniele, Andrea F and Walter, Matthew R and Howard, Thomas M",
        "title": "Inferring compact representations for efficient natural language understanding of robot instructions"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "liu2023interactive",
        "author": "Liu, Huihan and Chen, Alice and Zhu, Yuke and Swaminathan, Adith and Kolobov, Andrey and Cheng, Ching-An",
        "title": "Interactive robot learning from verbal correction"
      },
      {
        "key": "xiao2024robi",
        "author": "Xiao, Anxing and Janaka, Nuwan and Hu, Tianrun and Gupta, Anshul and Li, Kaixin and Yu, Cunjun and Hsu, David",
        "title": "Robi Butler: Remote Multimodal Interactions with Household Robot Assistant"
      },
      {
        "key": "shi2024yell",
        "author": "Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea",
        "title": "Yell at your robot: Improving on-the-fly from language corrections"
      },
      {
        "key": "belkhale2024rt",
        "author": "Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa",
        "title": "Rt-h: Action hierarchies using language"
      },
      {
        "key": "singh2024lgr2",
        "author": "Singh, Utsav and Bhattacharyya, Pramit and Namboodiri, Vinay P",
        "title": "LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning"
      },
      {
        "key": "mccallum2023feedback",
        "author": "McCallum, Sabrina and Taylor-Davies, Max and Albrecht, Stefano and Suglia, Alessandro",
        "title": "Is feedback all you need? Leveraging natural language feedback in goal-conditioned RL"
      },
      {
        "key": "driess2023palm",
        "author": "Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others",
        "title": "Palm-e: An embodied multimodal language model"
      },
      {
        "key": "dai2024racer",
        "author": "Dai, Yinpei and Lee, Jayjun and Fazeli, Nima and Chai, Joyce",
        "title": "RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liu2023interactive",
        "author": "Liu, Huihan and Chen, Alice and Zhu, Yuke and Swaminathan, Adith and Kolobov, Andrey and Cheng, Ching-An",
        "title": "Interactive robot learning from verbal correction"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "shi2024yell",
        "author": "Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea",
        "title": "Yell at your robot: Improving on-the-fly from language corrections"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "dai2024racer",
        "author": "Dai, Yinpei and Lee, Jayjun and Fazeli, Nima and Chai, Joyce",
        "title": "RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "swadzba2009computational",
        "author": "Swadzba, Agnes and Vorwerg, Constanze and Wachsmuth, Sven and Rickheit, Gert",
        "title": "A computational model for the alignment of hierarchical scene representations in human-robot interaction"
      },
      {
        "key": "matuszek2013learning",
        "author": "Matuszek, Cynthia and Herbst, Evan and Zettlemoyer, Luke and Fox, Dieter",
        "title": "Learning to Parse Natural Language Commands to a Robot Control System"
      },
      {
        "key": "namasivayam2023learning",
        "author": "Namasivayam, K and Singh, Himanshu and Bindal, Vishal and Tuli, Arnav and Agrawal, Vishwajeet and Jain, Rahul and Singla, Parag and Paul, Rohan",
        "title": "Learning neuro-symbolic programs for language guided robot manipulation"
      },
      {
        "key": "patki2019inferring",
        "author": "Patki, Siddharth and Daniele, Andrea F and Walter, Matthew R and Howard, Thomas M",
        "title": "Inferring compact representations for efficient natural language understanding of robot instructions"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "liu2023interactive",
        "author": "Liu, Huihan and Chen, Alice and Zhu, Yuke and Swaminathan, Adith and Kolobov, Andrey and Cheng, Ching-An",
        "title": "Interactive robot learning from verbal correction"
      },
      {
        "key": "xiao2024robi",
        "author": "Xiao, Anxing and Janaka, Nuwan and Hu, Tianrun and Gupta, Anshul and Li, Kaixin and Yu, Cunjun and Hsu, David",
        "title": "Robi Butler: Remote Multimodal Interactions with Household Robot Assistant"
      },
      {
        "key": "shi2024yell",
        "author": "Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea",
        "title": "Yell at your robot: Improving on-the-fly from language corrections"
      },
      {
        "key": "belkhale2024rt",
        "author": "Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa",
        "title": "Rt-h: Action hierarchies using language"
      },
      {
        "key": "singh2024lgr2",
        "author": "Singh, Utsav and Bhattacharyya, Pramit and Namboodiri, Vinay P",
        "title": "LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning"
      },
      {
        "key": "mccallum2023feedback",
        "author": "McCallum, Sabrina and Taylor-Davies, Max and Albrecht, Stefano and Suglia, Alessandro",
        "title": "Is feedback all you need? Leveraging natural language feedback in goal-conditioned RL"
      },
      {
        "key": "dai2024racer",
        "author": "Dai, Yinpei and Lee, Jayjun and Fazeli, Nima and Chai, Joyce",
        "title": "RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "liu2023interactive",
        "author": "Liu, Huihan and Chen, Alice and Zhu, Yuke and Swaminathan, Adith and Kolobov, Andrey and Cheng, Ching-An",
        "title": "Interactive robot learning from verbal correction"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "shi2024yell",
        "author": "Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea",
        "title": "Yell at your robot: Improving on-the-fly from language corrections"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "dai2024racer",
        "author": "Dai, Yinpei and Lee, Jayjun and Fazeli, Nima and Chai, Joyce",
        "title": "RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "liu2023interactive",
        "author": "Liu, Huihan and Chen, Alice and Zhu, Yuke and Swaminathan, Adith and Kolobov, Andrey and Cheng, Ching-An",
        "title": "Interactive robot learning from verbal correction"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "liu2023interactive",
        "author": "Liu, Huihan and Chen, Alice and Zhu, Yuke and Swaminathan, Adith and Kolobov, Andrey and Cheng, Ching-An",
        "title": "Interactive robot learning from verbal correction"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "shi2024yell",
        "author": "Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea",
        "title": "Yell at your robot: Improving on-the-fly from language corrections"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "dai2024racer",
        "author": "Dai, Yinpei and Lee, Jayjun and Fazeli, Nima and Chai, Joyce",
        "title": "RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning"
      }
    ]
  }
]