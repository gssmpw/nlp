%%%% ijcai24.tex

\typeout{IJCAI--24 Instructions for Authors}

% These are the instructions for authors for IJCAI-24.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% \usepackage{tikz}
% \usetikzlibrary{positioning, arrows.meta}
% The file ijcai24.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai24}
\usepackage{amssymb}
% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{xtab}
\usepackage{url}
\usepackage{tikz}
\usetikzlibrary{mindmap,trees}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usetikzlibrary{positioning, shapes.multipart}

\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{positioning, shapes.multipart}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}
\usepackage{xcolor}
\usepackage{array}
\usepackage{amsmath} % 支持高级数学符号
\usepackage{amssymb} % 支持更多数学符号

\usepackage[edges]{forest}
\usetikzlibrary{arrows.meta, positioning}
\newtheorem{property}{\bf Property}[section]
\newtheorem{assumption}{\bf Assumption}[section]
\newtheorem{theorem}{\bf{Theorem}}[section]
\newtheorem{definition}{\bf{Definition}}[section]
\newtheorem{lemma}{\bf{Lemma}}[section]
\newtheorem{corollary}{\bf Corollary}[section]
\newtheorem{proposition}[theorem]{\bf{Proposition}}
\newcommand{\DEL}[1]{\iffalse #1 \fi}
\newcommand{\bl}{\color{blue}}
\newcommand{\rd}{\color{red}}
\newcommand{\journal}{\color{black}}
\usepackage{tikz}
\usetikzlibrary{trees}
% Comment out this line in the camera-ready submission
% \linenumbers

\newcommand{\qiu}[1]{\textcolor{blue}{(\textbf{Qiu:~#1})}}

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider collaborated on their preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2024.0)
}

\title{A Decade of Metric Differential Privacy: Advancements and Applications}


\author{
Xinpeng Xie$^1$
\and
Chenyang Yu$^1$\and
Yan Huang$^1$\and
Yang Cao$^2$ \and 
Chenxi Qiu$^1$ \\
\affiliations
$^1$University of North Texas\\
$^2$Institute of Science Tokyo\\
\emails
\{xinpengxie, chenyangyu\}@my.unt.edu,
yan.huang@unt.edu, 
cao@c.titech.ac.jp,
chenxi.qiu@unt.edu
}


\begin{document}

\maketitle

\begin{abstract}
% Metric differential privacy has shown its significance and potential in the field of data privacy. This survey provides a comprehensive overview of metric differential privacy, highlighting its theoretical foundations, key methods and techniques, applications, challenges, and future directions. 

\emph{Metric Differential Privacy (mDP)} builds upon the core principles of \emph{Differential Privacy (DP)} by incorporating various distance metrics, which offer adaptable and context-sensitive privacy guarantees for a wide range of applications, such as location-based services, text analysis, and image processing. Since its inception in 2013, mDP has garnered substantial research attention, advancing theoretical foundations, algorithm design, and practical implementations. Despite this progress, existing surveys mainly focus on traditional DP and local DP, and they provide limited coverage of mDP. This paper provides a comprehensive survey of mDP research from 2013 to 2024, tracing its development from the foundations of DP. We categorize essential mechanisms, including \emph{Laplace}, \emph{Exponential}, and \emph{optimization-based approaches}, and assess their strengths, limitations, and application domains. Additionally, we highlight key challenges and outline future research directions to encourage innovation and real-world adoption of mDP. This survey is designed to be a valuable resource for researchers and practitioners aiming to deepen their understanding and drive progress in mDP within the broader privacy ecosystem.
\end{abstract}

\vspace{-0.1in}
\section{Introduction}
\emph{Differential Privacy (DP)} \cite{dwork2014algorithmic} is a widely recognized paradigm for protecting individual data, offering mathematically proven privacy guarantees. It intentionally introduces noise into sensitive data, ensuring a consistent level of indistinguishability across queries on ``neighboring databases'' that differ by at most one entry, thus making it hard to deduce any individual entry from comparative database queries. However, the original definition of DP is difficult to apply in contexts where data similarity is assessed using different distance metrics beyond mere entry counts, or where a finer spectrum % \qiu{nuanced understanding?} 
of indistinguishability among data points is required. For instance, in scenarios like obfuscating a geo-location, discerning whether a location is within a 1-kilometer radius versus a 100-kilometer radius is difficult to capture by DP \cite{ImolaUAI2022}. 

Accordingly, computer scientists and statisticians have proposed a new privacy criterion called \emph{metric Differential Privacy (mDP)} \cite{Chatzikokolakis-PETS2013}, which extends DP's concept of ``neighboring databases'' to include various distance metrics. This enhancement increases DP's flexibility and applicability in broader domains, including obfuscating sensitive geo-location data \cite{Andres-CCS2013}, word embeddings \cite{feyisetan2021private}, speech processing \cite{han2020voice} and image data \cite{fan2019practical,chen2021perceptual}. 
Since mDP was first introduced in 2013, a substantial body of work has been devoted to studying mDP. Figure \ref{fig:mDPhistory} showcases the historical development of publications in various fields of mDP from 2013 to 2024, with stacked bars representing the number of papers published annually across domains such as location, text, image, and voice. An upward trend is evident, % especially in recent years, 
indicating increasing research interest and diversity in applications of mDP. \looseness = -1



\begin{figure}
    \centering
    \includegraphics[width=0.94\linewidth]{fig/relatedwork}
    \caption{Growing adoption of mDP across multiple application domains.}
    \vspace{-0.10in}
    \label{fig:mDPhistory}
    \vspace{-0.12in}
\end{figure}

Despite this extensive body of work—spanning theoretical foundations, algorithm development, and practical applications—a comprehensive review dedicated specifically to mDP is still lacking. Previous surveys have focused on DP and local DP, providing insights into various adaptations and applications, but not specifically on mDP. For example, \cite{zhao2022survey} provided an overview of DP and local DP approaches for protecting unstructured data content such as images, audio, and text, focusing on the challenges and utility analysis, and briefly mentioned mDP as a small part of their discussion. \cite{zhao2024scenario} summarized DP adaptations for local data privacy and statistical dataset privacy, emphasizing scenario-based adaptations and practical applications, and included mDP as a minor component. However, these surveys do not provide an in-depth exploration of the unique aspects and advancements in mDP, necessitating a dedicated review of its theoretical and practical developments.

To bridge this gap, we provide a comprehensive survey of mDP developments from 2013 to 2024, detailing key mechanisms and their applications. We begin by introducing how mDP extends from traditional global and local DP in \textbf{Section \ref{sec:DP2mDP}}, underscoring mDP's unique challenges. We then introduce the three primary mDP mechanisms, including the \emph{Laplace mechanism}, \emph{Exponential mechanism}, and \emph{optimization-based approaches} in \textbf{Section \ref{sec:mechanism}}. Next, we %systematically analyze and compare recent mDP research in terms of adaptability, utility-preserving, and time efficiency in \textbf{Section \ref{sec:comparison}}, and 
introduce the application domains of mDP in \textbf{Section \ref{sec:applications}} and identify current hurdles and potential future research directions in \textbf{Section \ref{sec:future}}. Finally, we make a conclusion in \textbf{Section \ref{sec:conclusions}}. 


\vspace{-0.1in}
\section{From DP to mDP}
\label{sec:DP2mDP}
In its original form  \cite{Dwork-TC2006}, DP employs data perturbation to ensure a consistent level of indistinguishability for queries across ``neighboring databases,'' defined as databases that differ by only a single entry (i.e., with a \emph{Hamming distance} of one). mDP, which is also called \emph{Lipschitz privacy} \cite{koufogiannis2015optimality}, $d_\mathcal{X}$-privacy \cite{feyisetan2020privacy}, and \emph{smooth DP} \cite{dharangutte2023integer}, expand this concept to consider distances between records within a general metric space, rather than restricting it to the Hamming distance.

Formally, we can represent a randomized mechanism as a \emph{probabilistic mapping} $\mathcal{M}:~\mathcal{X} \rightarrow \mathcal{Y}$, where $\mathcal{X}$ and $\mathcal{Y}$ are the \emph{secret data domain} and the \emph{perturbed data domain}, respectively. Within the secret data domain $\mathcal{X}$, a distance measure $d_{\mathcal{X}}: \mathcal{X}^2 \rightarrow \mathbb{R}$ is used to quantify the distance between any two records $x, x' \in \mathcal{X}$, denoted by $d_{\mathcal{X}}(x, x')$. \looseness = -1 
\begin{definition}
\label{def:metricDP}
\textbf{$(\epsilon, d_{\mathcal{X}})$-mDP}.  
A randomized mechanism $\mathcal{M}: \mathcal{X} \rightarrow \mathcal{Y}$ with domain $\mathcal{X}$ and range $\mathcal{Y}$ satisfies $(\epsilon, d_{\mathcal{X}})$-mDP if for any output $\mathcal{Y}' \subseteq \mathcal{Y}$, and any two records $x, x' \in \mathcal{X}$, 
\vspace{-0.04in}
\begin{equation}
\label{eq:DP}
\frac{\Pr\left[\mathcal{M}(x) \in \mathcal{Y}'\right]}{\Pr\left[\mathcal{M}(x') \in \mathcal{Y}'\right]} \leq e^{\epsilon d_{\mathcal{X}}(x, x')}, ~\forall \mathcal{Y}' \subseteq \mathcal{Y}. 
\vspace{-0.00in}
\end{equation}
where $\epsilon > 0$ is the \textbf{privacy budget}.
\end{definition}
Intuitively, mDP ensures that \emph{small changes in the input $x$ of the perturbation method $\mathcal{M}$ lead to only bounded changes in the probability distribution of the output $\mathcal{M}(x)$}, thereby providing privacy guarantees for the input $x$ within the corresponding distance metric space. 

% \begin{itemize}
%     \item \textbf{Mathematical Definition}: Provide the formal definition and properties of differential privacy. 


    
% \textbf{Unique Aspects of Metric Differential Privacy:} 

% \emph{Metric Differential Privacy} extends traditional Differential Privacy by incorporating distance metrics, allowing for privacy mechanisms that take into account the degree of similarity between data points. This nuanced approach provides finer-grained privacy control compared to global DP, which applies uniform noise across all data regardless of sensitivity, and local DP, which perturbs individual data points independently without considering relationships between them.
% With mDP, noise is adapted based on the distance between data points: data points that are close receive less noise, while those farther apart are perturbed more. This adaptive mechanism helps maintain a better balance between privacy and utility, as it avoids the excessive noise that global DP might introduce for less sensitive data and the excessive perturbation of local DP that can reduce accuracy.

% Metric DP’s flexibility in defining custom distance metrics also makes it adaptable to a wide range of applications, such as location-based services, graph-structured data, and spatiotemporal datasets. By tailoring the noise mechanism based on the distance between data points, mDP can offer fine-grained privacy protection that scales effectively across complex data structures. This adaptability allows mDP to provide more efficient privacy-utility trade-offs compared to the uniform and often rigid frameworks of global and local DP.

% \subsection{Relationship Between mDP and Traditional DP}
\paragraph{mDP vs. local DP.} mDP defined in \emph{Definition \ref{def:metricDP}} is closely related to the definition of \emph{local DP} \cite{KasiviswanathanJoC}, where a random mechanism $\mathcal{M}$ is applied independently to each element of a database. The distinction between mDP and local DP lies in the inclusion of the distance metric $d_{\mathcal{X}}(x, x')$ in the mDP formulation, which is absent in local DP. This inclusion requires the perturbation mechanism to ensure indistinguishability for elements $x, x' \in \mathcal{X}$ based on their distance $d_{\mathcal{X}}(x, x')$, demanding a more precise control of data perturbation. In addition, mDP retains its properties under both \emph{post-processing} and the \emph{sequential composition} of mechanisms like traditional DP \cite{ImolaUAI2022}.


\DEL{
\begin{table}[t]
\scriptsize    
\centering
\begin{tabular}{p{2.0cm}|p{1.2cm}|p{4.5cm}}
% \hline
\toprule
\textbf{Paper} & \textbf{Distance Type} & \textbf{Application: Description} \\ \hline
\hline
PETS 2013 \cite{Chatzikokolakis-PETS2013}, PETS 2014 \cite{chatzikokolakis2014predictive}, CCS 2014 \cite{fawaz2014location} & Euclidean Distance & Location: Measures the displacement between two locations in a continuous space, considering each coordinate dimension independently. \\ \hline

CDC 2014 \cite{wang2014entropy} & Manhattan Distance & Control Systems: Measures the total absolute difference across all coordinate dimensions. \\ \hline

arXiv 2018 \cite{fernandes2018author}, POST 2019 \cite{fernandes2019generalised} & Word Mover's Distance (Kantorovich Distance) & Text: Measures the minimum transport cost needed to move words from one text document to another, based on semantic similarity in an embedding space. \\ \hline

FOCS 2018 \cite{borgs2018revealing} & Node-Distance & Graph: Measures the minimum number of node modifications such as additions, deletions, or substitutions needed to transform one graph structure into another. \\ \hline

VLDB 2015 \cite{haney2015design}, TMC 2020 \cite{Qiu-TMC2022}, ESORICS 2020 \cite{cao2020pglp}, TITS 2022 \cite{ma2022personalized} & Shortest Path Distance & Location: Measures the minimum travel distance between two points along a network, considering the road or graph structure connecting them. \\ \hline

ICDM 2019 \cite{Feyisetan-ICDM2019} & Hyperbolic Distance & Text: Measures distances in a hyperbolic space, capturing hierarchical relationships where distances grow exponentially as nodes move outward from the center. \\ \hline

ESORICS 2019 \cite{kawamoto2019local} & Wasserstein Distance & Location: Measures the minimal cost of transforming one probability distribution into another, based on optimal transport theory. \\ \hline

arXiv 2020 \cite{xu2020differentially}, TKDE 2023 \cite{zhao2022geo} & Regularized Mahalanobis Norm & Text, Location: Measures distance while considering correlations between features, regularized to balance sensitivity and robustness in privacy mechanisms. \\ \hline

ICME 2020 \cite{han2020voice}, CCS 2021 \cite{weggenmann2021differential}, ESORICS 2021 \cite{fernandes2021locality} & Angular Distance & Voice, Location: Measures the difference in orientation between vectors, often using cosine similarity to quantify differences in feature representations. \\ \hline

SEBD 2023 \cite{boninsegna2023locality} & Fréchet Distance & Location: Measures the similarity between two curves by considering the minimal effort required to continuously transform one into the other while maintaining order. \\ \hline

arXiv 2024 \cite{brauer2024time} & Temporal Distance & Location: Measures the difference between time points or temporal sequences, capturing the deviation in timestamps along trajectories. \\ 
\toprule
% \hline
\end{tabular}
\vspace{-0.05in}
\caption{Metric definitions in mDP works.}
\label{tab:mDP-distances}
\vspace{-0.15in}
\end{table}}

\begin{table*}[t]
\scriptsize    
\centering
\begin{tabular}{p{4.8cm}|p{2.2cm}|p{9.5cm}}
% \hline
\toprule
\textbf{Paper} & \textbf{Distance Type} & \textbf{Application: Description} \\ \hline
\hline
PETS 2013 \cite{Chatzikokolakis-PETS2013}, PETS 2014 \cite{chatzikokolakis2014predictive}, CCS 2014 \cite{fawaz2014location}, UAI \cite{ImolaUAI2022}, ICDM 2019 \cite{Feyisetan-ICDM2019} & Euclidean Distance & Location-based services (LBS) and natural language processing (NLP): $d_{\mathcal{X}}(x, x') = \sqrt{\sum_{i}(x_i - x'_i)^{2}}$ quantifies the straight-line displacement between two data points $x, x'$, where $x_i$ and $x'_i$ represent the $i$-th coordinate of $x$ and $x'$, respectively \\ \hline

CDC 2014 \cite{wang2014entropy} & Manhattan Distance & Control Systems: $d_{\mathcal{X}}(x, x') = \sum_{i}|x_i - x'_i|$ measures the total absolute difference across all coordinate dimensions. \\ \hline

arXiv 2018 \cite{fernandes2018author}, POST 2019 \cite{fernandes2019generalised} & Word Mover's Distance (Kantorovich Distance) & NLP: $d_{\mathcal{X}}(x, x')$ measures the minimum transport cost needed to move words from one text document $x$ to another $x'$. The cost is computed based on the semantic similarity of the words, measured using distances between their vector representations in a shared embedding space.\\ \hline

FOCS 2018 \cite{borgs2018revealing} & Node-Distance & Graph processing: $d_{\mathcal{X}}(x, x')$ measures the minimum number of node modifications such as additions, deletions, or substitutions needed to transform one graph structure $x$ into another $x'$. \\ \hline

VLDB 2015 \cite{haney2015design}, TMC 2020 \cite{Qiu-TMC2022}, ESORICS 2020 \cite{cao2020pglp}, TITS 2022 \cite{ma2022personalized} & Shortest Path Distance & LBS: $d_{\mathcal{X}}(x, x')$ measures the minimum travel distance between two points $x, x'$ along a network, considering the road or graph structure connecting them. \\ \hline

% ICDM 2019 \cite{Feyisetan-ICDM2019} & Hyperbolic Distance & Text: Measures distances in a hyperbolic space, capturing hierarchical relationships where distances grow exponentially as nodes move outward from the center. \\ \hline

ESORICS 2019 \cite{kawamoto2019local} & Wasserstein Distance & LBS: $d_{\mathcal{X}}(x, x')$ measures the minimal cost of transforming one probability distribution $x$ into another $x'$, based on optimal transport theory. \\ \hline

arXiv 2020 \cite{xu2020differentially}, TKDE 2023 \cite{zhao2022geo} & Regularized Mahalanobis Norm & LBS and NLP: $d_{\mathcal{X}}(x, x')$ measures distance between $x$ and $x'$ while considering correlations between their features, regularized to balance sensitivity and robustness in privacy mechanisms. \\ \hline

ICME 2020 \cite{han2020voice}, CCS 2021 \cite{weggenmann2021differential}, ESORICS 2021 \cite{fernandes2021locality} & Angular Distance & Voice processing and LBS: $d_{\mathcal{X}}(x, x')$ measures the difference in orientation between vectors $x, x'$, often using cosine similarity to quantify differences in feature representations. \\ \hline

SEBD 2023 \cite{boninsegna2023locality} & Fréchet Distance & LBS: $d_{\mathcal{X}}(x, x')$ measures the similarity between two curves $x, x'$ by considering the minimal effort required to continuously transform one into the other while maintaining order. \\ \hline

arXiv 2024 \cite{brauer2024time} & Temporal Distance & LBS: $d_{\mathcal{X}}(x, x')$ measures the difference between time points or temporal sequences $x$ and $x'$,  capturing the deviation in timestamps along trajectories. \\ 
\toprule
% \hline
\end{tabular}
\vspace{-0.05in}
\caption{Metric distance definitions and descriptions in mDP works.}
\label{tab:mDP-distances}
\vspace{-0.15in}
\end{table*}


\begin{figure*}
    \centering
    \includegraphics[width=0.95\linewidth]{fig/flow_simplified}
    \vspace{-0.05in}
    \caption{The evolvement of the three categories of mDP mechanisms during years 2013 -- 2024 (due to the limited space, we label each work by [Last name of the first author, publication year].}
    \label{fig:relatedwork}
    \vspace{-0.08in}
\end{figure*}

Compared to local DP, mDP offers several \textbf{advantages}:

\emph{(1) Enhanced data utility for high-dimensional data}: Local DP often results in substantial utility loss when applied to high-dimensional or continuous data, as preserving privacy requires the addition of exponentially large amounts of noise \cite{yangarXiv2020}. In contrast, mDP leverages distance metrics to add noise adaptively, based on the similarity between data points. By restricting the level of indistinguishability between similar points, mDP preserves key patterns and relationships within the original data, thereby maintaining higher utility for downstream tasks. This makes mDP particularly effective for high-dimensional applications, including image data, audio signals, and text embeddings \cite{fawaz2014location}.

\emph{(2) Context-specific privacy mechanisms}: mDP supports the design of privacy mechanisms tailored to specific distance metrics relevant to the data domain. For instance, in geographic data, Euclidean distance/haversine distance can be used to preserve spatial relationships \cite{Andres-CCS2013}, whereas in text data, Word Mover’s Distance (i.e., the minimum ``cost'' needed to transform one document's word distribution into the other) is more appropriate for measuring the semantic distance between documents \cite{fernandes2018author}. This context-specific criterion allows the privacy mechanisms to better align with the data's characteristics, enhancing both privacy and utility compared to the generic noise addition in local DP \cite{chen2021perceptual}. Table \ref{tab:mDP-distances} summarizes the various distance metric definitions used in existing mDP-related works.

\emph{(3) Fine-grained privacy-utility trade-offs}: % mDP is well suited for data types that do not conform neatly to the "one-record difference" assumption in traditional DP—such as continuous geographic coordinates, audio and speech embeddings, or image embeddings. It thus supports a wider range of applications, from location obfuscation to privacy-preserving machine learning on high-dimensional feature spaces.
mDP allows for more nuanced control over the privacy-utility balance by adjusting the noise level under the distance metric. This flexibility enables practitioners to achieve a better trade-off between privacy and utility tailored to specific application requirements, something that LDP's rigid noise mechanisms might not provide \cite{ImolaUAI2022}.








% \textbf{(3) Improved utility}: Since mDP avoids adding unnecessary noise to less sensitive data, it often achieves better utility compared to global DP, which applies uniform noise regardless of data sensitivity. This is particularly beneficial in applications where preserving the accuracy of similar data points is crucial. {\rd (need to discuss)}

 
% \textbf{(4) Enhanced privacy guarantees}: By considering the relationships between data points, mDP can offer stronger privacy guarantees in scenarios where traditional DP mechanisms may fall short, such as when the notion of neighboring databases needs to account for more than just single-entry differences. {\rd (need to discuss)} 






%\item \textbf{Mathematical Tools and Theories}: Explain relevant mathematical concepts such as distance functions and sensitivity analysis.
% \end{itemize}

\vspace{-0.05in}
\section{Key Data Perturbation Mechanisms in mDP}
\label{sec:mechanism}
\vspace{-0.05in}
In this section, we review the key mechanisms that have driven the development of mDP, including the Laplace mechanism in \textbf{Section \ref{subsec:laplace}}, the Exponential mechanism in \textbf{Section \ref{subsec:exponential}}, and optimization-based approaches in \textbf{Section \ref{subsec:optimization}}. We also provide a comparison of these mechanisms in \textbf{Section \ref{subsec:comparison}}. Figure \ref{fig:relatedwork} illustrates the evolution of these three categories over time.

% \subsection{Laplace Mechanism}
% The Laplace mechanism is central to the development of mDP, allowing noise to be added proportionally to the distance between data points. The mechanism was first introduced in the context of Geo-Ind by \cite{Andres-CCS2013}, where it was applied to protect location data by ensuring that closer locations experience less perturbation. The noise is generated based on the following two-dimensional Laplace distribution:

% \begin{equation} M_{\text{planar}}(r, \theta) = \frac{\epsilon^2 r}{2\pi} \exp(-\epsilon r) \end{equation}

% Here, $r$ is the distance from the true location, and $\theta$ is the angle. This ensures that noise is uniformly distributed around the true location, with larger distances receiving more perturbation, preserving utility while protecting privacy.

% Building on this, \cite{koufogiannis2015optimalitylaplace} demonstrated that the Laplace mechanism is optimal under the mDP framework by introducing Lipschitz privacy. They showed that for identity queries in high-dimensional spaces, such as GPS traces, the Laplace mechanism minimizes mean squared error, further strengthening its role in privacy protection. Later, \cite{koufogiannis2016location} extended this by proposing locally Lipschitz privacy, adapting the level of privacy based on environmental factors like population density. This adaptation makes the mechanism more flexible, providing stronger privacy in sparsely populated areas while relaxing privacy in denser regions.

% The Laplace mechanism was not limited to spatial data but found extensions in other domains as well. For instance, \cite{fernandes2018author} applied mDP to textual data, where the mechanism was adapted to the word embedding space using Word Mover’s Distance (WMD) to protect author identity while preserving the semantic content of text. This highlighted the mechanism's versatility in handling unstructured data. \cite{alvim2018metric} introduced $d_{\mathcal{X}}$-privacy, which uses Kantorovich lifting to measure distances between probability distributions, extending the Laplace mechanism to more general metric spaces such as energy consumption data. \cite{Feyisetan-ICDM2019} further adapted this mechanism to hyperbolic space, capturing hierarchical relationships in high-dimensional text data. This extension demonstrated the mechanism’s effectiveness in tasks such as text classification and author attribution, balancing privacy and utility across a range of applications.

% An important extension of the Laplace mechanism was proposed by \cite{raskhodnikova2016lipschitz} for node-private graph statistics. They developed Lipschitz extensions for efficiently computing graph statistics, such as degree distributions, which are sensitive to node-level changes. By using the Laplace mechanism, they ensured differential privacy for graph data by adding noise proportional to the Lipschitz constant of the graph statistics. This advancement highlighted the utility of the mechanism in preserving privacy in node-private algorithms, especially in sparse graphs with scale-free distributions.

% The Laplace mechanism has also been adapted to handle dynamic data and specific use cases. \cite{cunha2019clustering} introduced clustering Geo-Ind, which groups nearby locations and reports the same obfuscated point for them, reducing the risk of tracking attacks in continuous location reporting. Similarly, \cite{fan2018time} applied the Laplace mechanism to time series data using the Discrete Cosine Transform (DCT) to balance privacy and utility, protecting against adversaries with general knowledge of data patterns.

% Further expanding its application,  \cite{fernandes2021locality} applied the mechanism to high-dimensional data through locality-sensitive hashing (LSH), improving privacy-utility trade-offs in friend-matching tasks.

% Optimizing the Laplace mechanism in dynamic environments has also been a focus of research. \cite{mendes2018effect} explored how update frequency affects the balance between privacy and utility in mobility traces, showing that adjusting the frequency of updates can help maintain privacy without significantly compromising utility. This was further explored by \cite{mendes2020impact}, who found that reducing the frequency of location updates can effectively reduce privacy leakage.

% In addition, the Laplace mechanism has also been applied to continuous queries within the mDP framework. \cite{fernandes2021laplace} demonstrated the mechanism’s optimal utility for such queries, particularly when using the Kantorovich-Rubinstein distance, solidifying its effectiveness in continuous data scenarios. Separately, \cite{brauer2024time} extended the mechanism to protect the temporal dimension of trajectory data by introducing deterministic and stochastic time shifts to obfuscate timestamps and prevent re-identification attacks while maintaining data utility.


% \subsection{Attack model}
% the authors of [10Shokri, R., Theodorakopoulos, G., Le Boudec, J.Y., Hubaux, J.P. (2011): Quantifying location privacy. In: Proceedings of the 2011 IEEE Symposium on Security and Privacy (SP’11), 247–262] have proposed an intuitive probabilistic metric for measuring the location privacy, which has been used in their subsequent work [8, 26[26] Shokri, R., Theodorakopoulos, G., Troncoso, C., Hubaux, J.P., Le Boudec, J.Y. (2012): Protecting location privacy: Optimal strategy against localization attacks. In: Proceedings of the 2012 ACM Conference on Computer and Communications Security (CCS’12), 617–627.].

% The two main attacks on users’ location privacy are tracking and identification attacks. Whereas identification attacks aim at deanonymizing location traces, tracking attacks aim at de-obfuscating location traces. In this section we mainly focus on de-obfuscation attacks. De-obfuscation mechanisms are mechanisms used by an adversary that take obfuscated geolocation data and try to go back as close as possible to the original location data.
% The main  application of d-privacy is to protect from attacks such as  stalking, inference of sensitive information associated with  exact locations, etc, but it can also be used to protect from  re-identification attacks based on the adversary’s knowledge  of the mobility habits of an individual

% a user’s location information can be used for an attacker to infer the user’s attributes (e.g., age, gender, social status, and residence area) or activities (e.g., working, sleeping, and shopping) [6,7,8,9]. For example, when an attacker knows the distribution of residence locations, he may detect whether given users are at home or outside home after observing their obfuscated locations. For another example, an attacker may learn whether users are rich or poor by observing their obfuscated behaviors. These attributes can be used by robbers hence should be protected from them. Privacy issues of such attribute inference are also known in other applications, including recommender systems [10,11] and online social networks [12,13]

% The existence of a movement pattern is considered as the reason of the correlation of a user’s trajectory locations. As a result of the partial disclosure of the user’s location by location privacy mechanisms, the correlation among the reported locations of a user’s trajectory is also expected. Hence, exploiting the potential correlation to predict the user’s next location can be utilized for different purposes. For example, the performance of some systems can be optimized (e.g. the response time) if the user’s next location can be predicted in advance. On the other hand, adversaries may exploit this correlation to reduce the estimation error of predicting the user’s locations. A location tracking attack was proposed in [2]. The attack is implemented by linking the subsequent anonymized correlated cloaking regions using different pseudonyms to a single user. Ghinita et al. introduced the maximum movement boundary attack [30]. An adversary uses the maximum speed knowledge to analyze the reported cloaking regions and calculate the maximum movement boundary area. The calculated area is then used to improve the precision of the user’s location. In [31], the region intersection attack was proposed. An adversary uses the user’s subsequent  cloaking regions to find their intersection in order improve the precision of the user’s location. Troja and Bakiras used a PIR based mechanism to preserve the location privacy for database-driven dynamic spectrum access services [32]. To reduce the PIR queries cost and response time, a trajectory prediction method based on the user’s real locations is used to predict the next possible cells to be visited by the user. In [10], a cooperative k-anonymity mechanism is proposed based on partitioning the road networks as a Voronoi graph. To improve the performance of the mechanism, predicting the users’ moving direction is used to create the k-anonymity groups of users. A semantic trajectory mining mechanism for location prediction was proposed in [33]. The objective of such mechanisms is to extract useful information for marketing purposes. The mechanism creates clusters of similar users and then predicts the user’s next destination using the semantic characteristics of users’ trajectories of the same cluster’s users. PLP was proposed as an indoor crowdsensing scheme which preserves the location privacy by filtering the user's stream sent to the crowdsensing server [34]. It models the potential correlation among the user’s locations and filters any locations can lead to disclosing the user’s private locations. In [35], a privacy budget manager for Geo-Ind mechanism was proposed. A ‘parrot’ prediction function is used to estimate the new obfuscated location which returns the last reported obfuscated location as the predicted location. A test mechanism is used to examine the predicted location’s quality, such that if its quality is accepted, then the predicted location is sent to the LBS. If not, the user’s location is sanitized using the noise mechanism.

% some authors have proposed to quantify location privacy as the estimation error of the adversary when performing an inference attack [10, 8]. For instance, the main objective of the inference attack could be to deduce the true location of the user from the observed one or to re-identify the user based on the location disclosed. However, one of the drawbacks of this approach is that it needs to make strong assumptions on the knowledge available to the adversary to reason on the offered privacy level. For instance, in [10] the knowledge of the adversary is represented as a Markov model while in [8] the adversary is assumed to know the geographical distribution of users across different regions as well as their mobility patterns. Thus, while this approach is an important step towards the formalization of location privacy, the privacy guarantees offered are highly dependent on the prior knowledge of the adversary.

\subsection{Laplace Mechanism}
\label{subsec:laplace}
The Laplace mechanism is one of the most widely used data perturbation techniques, originally developed to achieve DP \cite{Dwork-TC2006}. It adds noise $w$ to the output of the query function $f(x)$, i.e., 
$\mathcal{M}(f(x)) = f(x)+w$, where $w$ is sampled from a Laplace distribution with a probability density function
\vspace{-0.05in}
\begin{equation}
\textstyle \Pr\left[\mathcal{M}(f(x)) = f(x)+w\right] % = \mathrm{Lap}(x) 
= \frac{\epsilon}{2\Delta f} e^{-\frac{\epsilon |w|}{\Delta f}}.
\vspace{-0.00in}
\end{equation}
Here, $\Delta f = \sup_{x, x' \in \mathcal{X}, d_{\mathrm{h}}(x, x')=1} |f(x) - f(x')|$ represents the global sensitivity of $f$, which measures the maximum change in the function's output between neighboring datasets ($d_{\mathrm{h}}(x, x')$ denotes the Hamming distance between $x$ and $x'$).

The Laplace mechanism can naturally adapt to various metrics by appropriately scaling the noise \cite{McSherry-FOCS2007}. To extend Laplace for mDP, \cite{Chatzikokolakis-PETS2013} first proposed scaling the noise based on the metric $d_{\mathcal{X}}$ instead of the global sensitivity $\Delta f$, where $d_{\mathcal{X}}(x, y)$ quantifies the distinguishability between any two records $x, y\in \mathcal{X}$. The resulting probability density function is expressed as 
\vspace{-0.04in}
\begin{equation}
\Pr\left[\mathcal{M}(x) = y\right] = \lambda e^{-d_{\mathcal{X}}(x, y)}.
\vspace{-0.00in}
\end{equation}
Following this work, \cite{Andres-CCS2013} %first applied mDP for geo-location privacy protection by 
introduced polar Laplace noise to achieve \emph{geo-indistinguishability (Geo-Ind)}. This approach employs a two-dimensional Laplace distribution centered at the true location $x$, with a probability function given by 
$\Pr\left[\mathcal{M}(x) = y\right] = \frac{\epsilon^2}{2\pi} e^{-\epsilon \|x - y\|_2}$.  
% This adaptation ensures privacy while considering spatial metrics and has been widely adopted for location-based privacy applications.
% \begin{equation}
%\label{eq:geoind}
%D_\epsilon(x, y) = \frac{\epsilon^2}{2\pi} e^{-\epsilon d(x, y)},
%\end{equation}
% where $s \in \mathcal{X}$ and $o \in \mathcal{Y}$ are the true location and the perturbed location, $\epsilon > 0$ is the privacy budget, and $d(x, y)$ is the distance between $x$ and $y$. 
% This mechanism ensures privacy by exponentially decreasing the probability density as the distance $d(x, y)$ increases. 



% Following \cite{Andres-CCS2013}, a rich body of research works have applied Laplace mechanism to achieve mDP (or Geo-Ind) for location privacy protection. Particularly, a line of works extends Laplace mechanism by considering multiple/continuous location reports. For instance, \cite{chatzikokolakis2014predictive} first extends Geo-Ind from sporadic location privacy to mobility trace privacy protection, introducing a predictive approach that leverages the correlations of multiple location reports to  enhance privacy and efficiency over independent noise methods. \cite{hua2017geo} and \cite{ma2018agent} further optimized adaptive noise techniques, focusing on frequent and continuous location queries to enhance privacy while maintaining utility. \cite{li2023privacy} and \cite{brauer2024time} used Laplace-based temporal perturbations to protect the privacy of movement patterns. These techniques gained particular relevance during the COVID-19 pandemic, where they were used to track contact with respect to privacy.  \cite{li2023accurate} utilized Laplace noise to ensure privacy in trajectory-based contact tracing systems, highlighting its potential in public health applications. More recently, \cite{yu2023privacy} introduced a longitudinal Laplace-based Geo-Ind mechanism designed to protect trajectory privacy in location-based advertising. This approach provides privacy guarantees over extended time frames while supporting personalized ad delivery. In a related development, \cite{min2023personalized} proposed a 3D location privacy framework that combines Laplace noise with distortion-based geo-perturbation to offer customized privacy guarantees.  




Since its introduction, the Laplace mechanism has been widely applied to achieve mDP (or Geo-Ind) for location privacy protection. Early efforts like \cite{elsalamouny2016differential} focused on sporadic location reports, but subsequent research expanded its scope to address challenges posed by continuous or frequent location tracking. For example, \cite{chatzikokolakis2014predictive} extended Geo-Ind beyond sporadic location privacy to cover entire mobility traces. They proposed a predictive approach that leverages correlations among multiple location reports, improving both privacy and efficiency compared to independent noise-based methods. \cite{hua2017geo} and \cite{ma2018agent} refined adaptive noise techniques to handle frequent and continuous location queries, aiming to balance enhanced privacy protection and maintaining utility. % \looseness = -1

More recent studies have explored Laplace-based temporal perturbations to protect movement patterns, with significant applications during the COVID-19 pandemic for privacy-preserving contact tracing. For example, \cite{li2023privacy} and \cite{brauer2024time} demonstrated the effectiveness of these methods in protecting sensitive mobility data. Meanwhile, \cite{li2023accurate} showcased how Laplace noise can be applied to trajectory-based contact tracing systems, highlighting its importance in public health applications. Further extending this concept, \cite{yu2023privacy} introduced a longitudinal Laplace-based mechanism for location-based advertising. This approach ensures privacy protection over extended periods while enabling personalized ad delivery. 

% Complementing these efforts, \cite{min2023personalized} proposed a 3D location privacy framework that combines Laplace noise with distortion-based geo-perturbation, enabling customized privacy guarantees tailored to individual needs.



% Besides protecting trajectories, Laplace has been extended in other aspects in location privacy protection. For instance,  \cite{elsalamouny2016differential} introduces $(D, \epsilon)$-privacy, a relaxed Geo-Ind for protecting geo-location data, and proposes the stepping noise function as a tailored variant of the Laplace noise mechanism. Besides using Laplace, \cite{koufogiannis2016location} established a connection between DP and the eikonal equation, and proposed a method for computing such privacy-preserving mechanisms.  \cite{min20213d} and \cite{fathalizadeh2023indoor} directed their efforts towards high resolution indoor privacy. They extended Geo-Ind from 2D to 3D spaces, which represented a significant evolution from earlier 2D proximity-based approaches to more complex indoor navigation scenarios. \cite{min2024semantic} developed a semantic Geo-Ind mechanism. This mechanism adjusts noise levels based on contextual semantics, achieving a balance between privacy protection and service utility in mobile networks.

% Beyond geo-location data protection, 

Furthermore, the versatility of the Laplace mechanism is evident through its applications beyond spatial data, including textual data \cite{fernandes2018author}, image data \cite{chen2021perceptual}, blockchain systems \cite{yang2021blockchain}. A more detailed description of Laplace mechanisms in these applications can be found in \textbf{Section \ref{subsec:applications}}.









% For textual data, \cite{fernandes2018author} applied the Laplace mechanism to the Word Mover distance to protect author identities. This approach anonymized sensitive author information while preserving semantic integrity. Similarly, \cite{arnold2023guiding} advanced text privatization by incorporating Laplace noise guided by syntactic structures, ensuring both semantic coherence and privacy, and furthering the use of differential privacy in natural language processing. For image data, \cite{chen2021perceptual} introduced PI-Net, a framework based on the Laplace mechanism to obfuscate facial images. This method preserved semantic content while allowing for controllable obfuscation levels, addressing privacy concerns in sensitive image datasets. In federated learning, \cite{galli2023advancing} used Laplace-based noise addition to preserve privacy at a group level. This study balanced model accuracy with privacy guarantees, offering insight into collaborative learning that preserves privacy. The integration of blockchain with Laplace mechanisms was explored by \cite{yang2021blockchain}, which combined decentralized technology with privacy-preserving noise addition to protect user location in indoor environments. This combination of blockchain and privacy mechanisms opened new avenues for secure data sharing in environments with untrusted entities.

%Laplace has been extended to other aspects of location privacy. For instance, \cite{elsalamouny2016differential} introduced $(D, \epsilon)$-privacy, a relaxed form of Geo-Ind, along with the step noise function as a tailored variant of Laplace noise. % \cite{koufogiannis2016location} connected mDP to the Eikonal equation and proposed methods for designing such mechanisms. In the context of high-resolution indoor privacy, \cite{min20213d} and \cite{fathalizadeh2023indoor} extended Geo-Ind from 2D to 3D spaces, addressing complex indoor navigation scenarios. Additionally, \cite{min2024semantic} developed a semantic Geo-Ind mechanism that adapts noise levels based on contextual semantics, balancing privacy with service utility in mobile networks. \looseness = -1






% % \paragraph{Location-Based Advertising and 3D Privacy}
% Overall, the evolution of the Laplace mechanism in mDP reveals a rich trajectory of innovation, with applications ranging from mobility and location privacy to text, image, and trajectory privacy. These contributions have collectively expanded the mechanism's applicability to diverse data domains, highlighting its adaptability and resilience in addressing emerging privacy needs.





% \subsection{Exponential Mechanism}
% The Exponential Mechanism, introduced by \cite{McSherry-FOCS2007}, plays a key role in extending differential privacy to discrete or non-numerical data by selecting an output based on a utility function. This utility function quantifies the quality of each potential outcome, and the probability of selecting a particular outcome is determined by:

% \begin{equation}
% Pr[M(x) = r] \propto \exp\left(\frac{\epsilon \cdot u(x, r)}{2 \Delta u}\right)
% \end{equation}

% Here, $u(x, r)$ is the utility function for the outcome $r$ given input $x$, and $\Delta u$ represents the sensitivity of the utility function, controlling how much it can change when a single entry in $x$ is altered. 

% Building on this foundational work, \cite{chatzikokolakis2015constructing} applied the Exponential Mechanism to location privacy by introducing an elastic distinguishability metric. This adaptation allows for the noise added to location data to be adjusted based on local density, offering a more refined approach to balancing privacy and utility. In this model, densely populated areas can tolerate lower privacy levels without significant utility loss, while sparsely populated areas receive stronger privacy guarantees. 

% Expanding on this, \cite{takagi2019geo} introduced Geo-Graph-Indistinguishability (GeoGI), which adapts the Exponential Mechanism to the road network structure in LBS applications. Traditional methods often fail to account for the intricacies of road networks, where travel distances follow specific paths. GeoGI incorporates the shortest path distance within a road network into the privacy model, improving the utility of applications like k-nearest neighbor searches by ensuring that the perturbed locations reflect the network structure. 

% both/ Further advancements were made by \cite{Yu-NDSS2017}. They proposed the PIVE framework, which dynamically adjusts privacy levels based on user preferences and prior knowledge. By integrating the Exponential Mechanism with Geo-Ind and expected inference error, PIVE allows for real-time adjustments to privacy protection, offering greater flexibility in dynamic environments. This is particularly useful in scenarios where users' privacy needs change over time or across different locations, ensuring that privacy protection remains robust against adversarial models like Bayesian inference attacks.

% The versatility of the Exponential Mechanism extends beyond location privacy. \cite{feyisetan2020privacy} demonstrated its application in protecting textual data through word embeddings. By perturbing word vectors in a high-dimensional embedding space, the mechanism ensures privacy without significantly compromising the utility of the data. This approach was particularly effective in NLP tasks such as sentiment analysis and question answering, where maintaining the semantic integrity of text is crucial. The Exponential Mechanism allows for the selection of replacement words based on their proximity in the embedding space, ensuring that the overall meaning of the text is preserved while protecting sensitive information.

% \cite{feyisetan2020research} further enhanced this application by addressing the issue of noise modulation in high-density regions of the embedding space. Their approach adjusts the amount of noise added based on the density of the word embeddings, reducing unnecessary perturbation in denser areas, thereby improving the privacy-utility trade-off. This refinement is particularly valuable in tasks such as text generation, where the quality of the generated text heavily depends on the subtle relationships between words. By optimizing the noise distribution, this work ensures that privacy protection does not come at the expense of text coherence.

% In the domain of cybersecurity, \cite{gursoy2019secure} introduced a variant of the Exponential Mechanism to address the specific privacy challenges posed by small user populations. Their Condensed Local Differential Privacy (CLDP) framework applies the Exponential Mechanism to perturb ordinal and non-ordinal data sequences, systematically favoring outputs that are closer to the original input. This ensures higher utility in tasks such as ransomware detection and identifying vulnerable operating systems, even when traditional privacy-preserving methods struggle due to the small size of the user base.

% In another extension, \cite{roy2022strengthening} combined the Exponential Mechanism with order-preserving encryption (OPE) to protect against inference attacks in encrypted data. The $OP_{\epsilon}$ scheme introduced noise while preserving the order of the encrypted values, making it particularly useful for secure range queries in encrypted databases. This method ensures that while privacy is maintained, the utility of the ordered data is not compromised, thus providing a robust solution for managing sensitive data in security-critical applications.

% \cite{Carvalho2021TEMHU} developed the Truncated Exponential Mechanism (TEM) to address privacy concerns in textual data. TEM dynamically adjusts the amount of noise added based on the density of the embedding space, ensuring that regions with more closely packed data points receive less noise. This approach was particularly effective in tasks such as sentiment analysis and privacy-preserving text classification, where TEM outperformed traditional methods like Madlib, offering a better privacy-utility trade-off.

\subsection{Exponential Mechanism}
\label{subsec:exponential}


The \emph{Exponential Mechanism (EM)}, another widely used method for ensuring DP \cite{McSherry-FOCS2007}, has since been adapted to mDP \cite{chatzikokolakis2015constructing}. Unlike Laplace, which adds noise directly to the data values, EM selects an output probabilistically from \emph{a discrete set} based on a quality score. This makes it particularly well-suited for applications that aim to choose an element from a finite set rather than perturbing continuous data. % , $\epsilon > 0$ is the privacy budget, and $d(x, y)$ represents the distance between $x$ and $s'$ in the metric space. 
% This mechanism satisfies $(\epsilon, d_{\mathcal{X}})$-mDP by ensuring that the probability of selecting $y$ decreases exponentially with its distance $d(x, y)$ from the input $x$, {\rd thus achieving privacy guarantees in the metric space}.


The initial adaptation of EM in mDP was by \cite{chatzikokolakis2015constructing}, which proposed an elastic distinguishability metric that adjusts geometric distance based on area density. This allows the mechanism to vary noise levels while maintaining uniform privacy across all regions. Formally, given an input $x \in \mathcal{X}$, the mechanism selects an output $y \in \mathcal{Y}$ with probability:
\begin{equation}
\label{eq:exp_mech}
\Pr\left[\mathcal{M}(x) = y\right] = a_x e^{-\frac{1}{2}\epsilon d(x, y)},
\end{equation}
where $a_x = \left( \sum_{y' \in \mathcal{Y}} e^{-\frac{1}{2}\epsilon d(x, y')} \right)^{-1}$ is the normalization constant ensuring the probabilities sum to 1, and $d(x, y)$ measures the distance between $x$ and $y$. 
% who proposed elastic metrics for Geo-Ind. This work demonstrated how dynamical adjustment of noise levels based on geographic density could enhance privacy protection without compromising utility. 

Following this work, EM has been extensively adapted for location privacy. For example, \cite{Yu-NDSS2017} developed the PIVE framework, which combines Geo-Ind with another privacy criterion, \emph{expected inference error (EIE)}, to dynamically adjust privacy guarantees based on user-defined thresholds. 
\cite{gursoy2019secure} extended EM to \emph{condensed local DP} mechanisms for datasets involving a small population. In this adaptation, similar outputs are systematically prioritized over distant ones by applying condensed probability during the perturbation process. 
% improving its utility in {\bl sensitive domains}.
% In a subsequent study, \cite{takagi2020poster} developed a method to optimize the location obfuscation of user locations for road networks, achieving preservation of privacy without compromising the functionality of the service. 
\cite{niu2020eclipse} used EM for trajectory privacy in ride-sharing applications, protecting user mobility patterns. \cite{ren2022distpreserv} proposed an EM framework to preserve the statistical consistency and distributional properties of the original data while ensuring privacy in location-based services (LBS). 
% These foundational studies established EM's theoretical underpinnings for spatial and graph-based applications. 

Meanwhile, \emph{dynamic EM} adaptations have also been designed to address evolving privacy challenges. 
For example, \cite{dong2019preserving} integrated EM into dynamic spectrum sharing frameworks to protect the privacy of primary users under Geo-Ind constraints during auction-based allocations. 
\cite{niu2020eclipse} developed an EM-based method called Eclipse, which dynamically modulates privacy protections to mitigate risks posed by long-term observation attacks. 






% \looseness = -1


EM's adaptability has also proven important for textual and graph data privacy. For textual data, \cite{wang2017local} proposed the Subset Exponential Mechanism (SEM), which tailors EM for ordinal data by incorporating a structured probability assignment.
 \cite{feyisetan2020privacy} leveraged EM to perturb text embeddings, ensuring privacy protection without compromising semantic coherence. % \cite{yue2021differential} introduced mechanisms for selecting sanitized text tailored to tasks such as sentiment analysis and classification. 
 Recent advancements include \cite{Carvalho2021TEMHU}'s \emph{Truncated Exponential Mechanism (TEM)}, which modulates noise based on embedding density, and \cite{meisenbacher20241}'s 1-Diffractor, which simplifies computations by reducing text embeddings to a single dimension while maintaining privacy.

For graph data, EM has been effectively applied to protect the privacy of critical infrastructure networks. For example, \cite{raskhodnikova2016lipschitz} generalized EM to node-private graph statistics by employing Lipschitz extensions, enabling the handling of sensitivity variations in diverse graph queries, including subgraph counts and degree distributions. \cite{fioretto2019privacy} used EM to obfuscate both the structure and sensitive attributes of such networks. For datasets with mixed sensitivity, \cite{kamalaruban2020not} proposed selective privacy frameworks that prioritize protecting sensitive attributes during queries and synthetic data generation, achieving optimal trade-offs between privacy and utility through EM. 

% \subsection{Optimization}
% In the previous sections, we discussed how the Laplace and Exponential mechanisms achieve mDP by adding noise to protect sensitive data. While effective, these approaches may not always provide the optimal balance between privacy and utility. To address this limitation, linear programming provides a powerful optimization tool for solving privacy-constrained problems, allowing for more precise control over the trade-off between privacy protection and utility. In this section, we examine the application of linear programming in mDP, as initially introduced by \cite{shokri2012protecting}, and how it optimizes privacy mechanisms for different data structures.

% The problem of determining the optimal LPPM can be formulated as a linear programming (LP) problem, where the goal is to maximize privacy while maintaining service quality within a user-defined threshold. Privacy is quantified through a distortion function $ dp(r, r') $, which measures the difference between the true location $ r $ and the adversary's estimate $ r' $. Service quality degradation is captured by a function $ dq(r, r') $, representing the impact of location obfuscation. The optimization is governed by two main constraints:

% \begin{enumerate}
%     \item Service Quality: 
%     $ Q_{\text{loss}}(f) \leq Q_{\text{max}} $
%     ensuring that service quality loss does not exceed a specified threshold.
    
%     \item Privacy Maximization: 
%     The user maximizes privacy by selecting an optimal obfuscation function $ f(r'|r) $ to minimize the expected privacy loss, while the adversary seeks to minimize privacy by estimating the true location $ r $. The expected privacy loss is expressed as:
%     $
%     \sum_{r} P(r) \sum_{r'} f(r'|r)  dp(r, r'),
%     $
%     where $ P(r) $ is the probability distribution of the user's true location, and $ dp(r, r') $ is the distortion function that measures the difference between the true location $ r $ and the adversary's estimate $ r' $.

% \end{enumerate}

% The optimal solution balances the trade-off between privacy and service quality, using linear programming to compute the most effective LPPM against an adversary's optimal attack.

% \cite{shokri2014privacy} formulates the problem of designing optimal user-centric obfuscation mechanisms using LP. The objective is to maximize utility while simultaneously providing dual privacy guarantees: differential privacy and distortion privacy. The obfuscation mechanism is modeled as a leader-follower Stackelberg game, where the user (leader) selects a strategy to obfuscate their data, and the adversary (follower) responds with the best possible inference attack. The authors demonstrate that their LP-based approach achieves the highest privacy guarantees without increasing the utility cost compared to mechanisms that protect only differential privacy or distortion privacy .

% \cite{wang2016differential}proposes a differential location privacy framework for Sparse Mobile Crowdsensing (MCS), balancing privacy protection with data quality. The authors introduce an LP approach to select the optimal location obfuscation matrix that satisfies ${\epsilon}$-differential privacy. Their framework minimizes data quality loss by solving an LP-based optimization problem that accounts for the uncertainty introduced by location obfuscation. Additionally, a fast approximation of this optimization is proposed, allowing for scalability to larger datasets while maintaining privacy guarantees.

% \cite{chatzikokolakis2017efficient} presents methods to improve the utility of location obfuscation mechanisms, with a focus on Geo-Ind. The paper explores how optimal mechanisms can be derived using LP for small domains, though computational complexity limits their practical application. The authors propose efficient utility improvements through remapping techniques, significantly enhancing the utility of direct methods like the planar Laplace mechanism, while maintaining privacy guarantees. 

% \cite{wang2017location} introduces a privacy-preserving task allocation framework for mobile crowdsensing using differential geo-obfuscation. To minimize the selected workers' travel distance under privacy constraints, the authors propose a mixed-integer nonlinear programming (MINLP) problem, which is decomposed into two LPs using Benders Decomposition. The approach balances location privacy with utility by iteratively optimizing the obfuscation function and task allocation, ensuring differential privacy without relying on third-party entities. 


% \cite{Yu-NDSS2017} introduces the PIVE framework for location privacy, which integrates Geo-Ind and expected inference error. They propose a two-phase approach, where the first phase uses LP to optimize the user's privacy by selecting a protection location set that maximizes the expected inference error under a user-defined error bound. This LP-based optimization ensures that the protection set minimizes service quality loss while maintaining privacy. The second phase employs the exponential mechanism to generate pseudo-locations that achieve differential privacy within the selected protection location set.

% \cite{oya2017back} revisits the design of optimal location privacy-preserving mechanisms, critiquing existing approaches that focus solely on maximizing adversary estimation error. The authors argue that these mechanisms often neglect other important privacy metrics. To address this, they propose a multi-criteria approach incorporating both the conditional entropy and worst-case quality loss as auxiliary metrics. Using LP, they demonstrate how the remapping technique can optimize Geo-Ind while also enhancing utility. Experimental results on real-world datasets validate that the proposed mechanisms outperform traditional approaches across multiple privacy dimensions.

% \cite{Qiu-TMC2022} addresses the problem of location privacy in vehicle-based spatial crowdsourcing and proposes a framework to minimize the loss of quality of service (QoS) while preserving location privacy using Geo-Ind. The authors transform the vehicle-based location privacy problem into a LP formulation through discretization of the road network, allowing the optimization to be solved efficiently. A constraint reduction method is also proposed to improve the computational efficiency of the LP problem, significantly reducing the number of constraints without compromising optimality. 

% \cite{imola2022balancing} addresses the utility-scalability tradeoff in mDP. The authors propose a method to reduce the size of the LP used to generate mDP mechanisms by introducing constraints based on the exponential mechanism. This approach substantially decreases the number of variables and constraints in the LP, making it computationally feasible for large metric spaces. The paper also provides a lower bound on the achievable utility of mDP mechanisms and demonstrates through experiments that the proposed method improves scalability while maintaining near-optimal utility in both text and geolocation applications.

% \cite{pappachan2022user} introduces the CORGI framework, which leverages LP to generate location obfuscation matrices that satisfy Geo-Ind. The framework allows users to customize their privacy levels while ensuring that the location obfuscation process is computationally efficient. To enhance scalability, the authors propose a graph-based approximation that reduces the number of constraints in the LP, allowing the framework to be applied to large-scale datasets without sacrificing privacy guarantees. 

% \cite{qiu2024fine} proposes a fine-grained geo-obfuscation mechanism to protect workers’ location privacy in time-sensitive spatial crowdsourcing applications. The authors use LP to minimize quality loss while ensuring Geo-Ind. The framework introduces a peer location set for each worker, constraining the obfuscation range to locations with similar traveling costs. To improve computational efficiency, the paper implements a constraint reduction technique and a column generation algorithm, significantly reducing the size of the LP problem without compromising optimality. 

% \cite{qiu2024enhancing} enhances the scalability of LP-based mDP mechanisms by introducing a novel dataset partitioning technique and applying Benders Decomposition. This approach partitions the secret dataset into smaller, more manageable subsets, where each subset is optimized individually using LP. The Benders Decomposition framework allows efficient coordination between subsets while maintaining privacy constraints across them. 

\subsection{Optimization based Mechanism}

\label{subsec:optimization}


% Unlike traditional DP, a key research question in mDP is \emph{how to minimize data utility loss caused by data perturbation in downstream tasks.} % Compared to DP, solving such a problem poses additional challenges due to the nuanced levels of indistinguishability required between secret records and the varied utility losses associated with perturbations in different directions and magnitudes \cite{Qiu-TMC2022}. 
While Laplace and EM effectively achieve mDP, they may not always provide the optimal balance between privacy and utility as they base noise probability on perturbation magnitude $d(x, y)$, which doesn’t fully capture the varied utility losses caused by perturbation in different directions. To tackle this issue, many recent efforts have increasingly focused on optimization-based approaches. 

Given the computational challenges of optimizing $\mathcal{M}$ when the secret data domain $\mathcal{X}$ and the perturbation data domain $\mathcal{Y}$ are continuous, a common strategy is to discretize both $\mathcal{X}$ and $\mathcal{Y}$ into finite sets \cite{ImolaUAI2022}. Under this framework, the random mechanism $\mathcal{M}$ is represented as a stochastic \emph{perturbation matrix} $\mathbf{Z} = \left[z_{x,y}\right]_{(x,y) \in \mathcal{X}\times \mathcal{Y}}$, where each entry $z_{x,y} = \Pr[\mathcal{M}(x) = y]$ denotes the probability of selecting $y \in \mathcal{Y}$ as the perturbed output for a given real input $x \in \mathcal{X}$. The perturbation matrix $\mathbf{Z}$ can then be optimized by solving the following \emph{linear programming (LP)} problem: 
 \looseness = -1
\normalsize
\small
\begin{eqnarray}
\label{eq:optimal_mech}
\min && \sum_{s \in \mathcal{X}, y \in \mathcal{Y}} \pi_x z_{x, y} c_{x, y} \\
\text{s.t. } && z_{x, y} \leq e^{\epsilon  d_{\mathcal{X}}(x, x')} z_{x', y}, \forall x, x' \in \mathcal{X}, y \in \mathcal{Y}, \\
    && \sum_{y \in \mathcal{Y}} z_{x, y} = 1, \forall x \in \mathcal{X}, z_{x, y} \geq 0, \forall (x, y) \in \mathcal{X}\times \mathcal{Y}
\end{eqnarray}
\normalsize
Here, $c_{x, y}$ represents the utility loss caused by perturbed data $y$ given the real data $x$, and $\pi_x$ is the prior distribution of $x$ over the input domain $\mathcal{X}$.  % The mechanism $K$, obtained by solving the above optimization problem, guarantees $(\epsilon, d_{\mathcal{X}})$-mDP (or $\epsilon$-GeoInd) while providing optimal utility.

The earliest optimization-based data perturbation mechanism dates back to 2014 when \cite{bordenabe2014optimal} proposed maximizing utility while preserving Geo-Ind by formulating the problem as an LP. Building on this foundation, \cite{chatzikokolakis2015constructing} introduced a game-theoretic framework for user-centric obfuscation mechanisms, modeled as a Stackelberg game between the user and an adversary. To further improve efficiency, \cite{chatzikokolakis2017efficient} developed a Bayesian remapping technique designed to enhance utility while significantly reducing the computational complexity of location privacy mechanisms. 
% A widely used approach is to discretize both the secret data domain and its perturbed data domain into finite sets, enabling explicit measurement of utility loss for different perturbation choices \cite{ImolaUAI2022}. In this approach, the task of determining the probability of each perturbation choice can be formulated as a \emph{mathematical optimization} problem, with the objective to minimize the expected utility loss while satisfying the mDP constraints between secret records \cite{fawaz2014location}. 
% Moreover, significant efforts have been made to optimize spatial and mobile crowd-sourcing mechanisms. 
\cite{wang2017location} developed a \emph{mixed integer nonlinear programming (MINLP)} model to optimize travel distances under differentially private geo-obfuscation.

More recently, \cite{zhang2022task} proposed a group-based noise addition mechanism to minimize travel distances under Geo-Ind. For cooperative localization, \cite{yu2023balancing} introduced a bilevel optimization framework to balance accuracy and privacy by analyzing temporal correlations. \cite{min2023geo} employed reinforcement learning with the A3C algorithm to optimize server profit and location privacy in 3D spatial scenarios. 
% Expanding on the idea of contextual privacy, \cite{yan2022perturb} integrated location semantics into perturbation mechanisms, reducing the risks of inference attacks while maintaining spatial relationships. Furthermore, 
\cite{Pappachan-EDBT2023} introduced a customizable framework that employs graph-based approximations to enable user-defined obfuscation preferences with low computational overhead. For time-sensitive applications, \cite{qiu2024fine} proposed a fine-grained geo-obfuscation method that confines perturbations to peer location sets, thereby reducing the estimation error of travel distances under strict time constraints.




% In mobile crowdsensing, \cite{wang2016differential} applied LP to balance privacy protection and data quality, proposing a scalable solution for large datasets. Similarly, \cite{chatzikokolakis2017efficient} introduced remapping techniques to enhance Geo-Ind, using LP to improve utility in small domains.

% For task allocation in crowdsensing, \cite{wang2017location} utilized mixed-integer nonlinear programming, decomposing the problem into LPs to balance privacy and task efficiency. \cite{Yu-NDSS2017} integrated LP with the Exponential Mechanism in the PIVE framework, allowing dynamic adjustment of privacy levels based on user preferences.

% Expanding the scope of privacy metrics, \cite{oya2017back} proposed a multi-criteria LP approach, optimizing Geo-Ind through conditional entropy and quality loss metrics. \cite{Qiu-TMC2022} applied LP to vehicle-based crowdsourcing, improving efficiency through constraint reduction.

% To address scalability challenges, \cite{imola2022balancing} introduced an LP approach that reduces complexity using the Exponential Mechanism. \cite{pappachan2022user} applied graph-based approximations in the CORGI framework to efficiently handle large-scale data while maintaining privacy protections. Further refining these techniques, \cite{qiu2024fine} and \cite{qiu2024enhancing} employed LP with constraint reduction and Benders Decomposition, improving privacy in time-sensitive crowdsourcing and large datasets.
% AA studies xx problem; proposes xxx solution.
\vspace{-0.00in}
\subsection{Comparison}
\label{subsec:comparison}



In comparing Laplace, EM, and optimization-based mechanisms, each has strengths and weaknesses regarding \emph{adapatibility}, \emph{utility-preserving}, and \emph{time-efficiency}.

\paragraph{Adapatibility.} Currently, the Laplace mechanism remains the most widely used data perturbation method in mDP due to its simplicity and time-efficient implementation—adding Laplace noise directly to data values. Among the 132 references collected summarized by our work\footnote{The details can be found on GitHub \url{https://github.com/Kerwinxxp/metricDP/tree/main}}, 70 focus specifically on Laplace-based data perturbation, while 30 and 32 focus on EM and optimization-based approaches, respectively. 
However, as highlighted by \cite{Carvalho2021TEMHU}, Laplace is less effective for structured or combinatorial outputs (e.g., graphs and word embeddings) because directly adding noise can compromise structural integrity and overlook data density in the metric space. For instance, word embeddings exist in a discrete finite field, making it unlikely for a noisy vector to correspond to a valid word. To address this, \cite{fernandes2018author,Feyisetan-ICDM2019} employed nearest neighbor approximations for the noisy vectors. These approaches treat the representation space as non-sensitive, which might overlook privacy loss during the nearest neighbor search. In such scenarios, EM \cite{Carvalho2021TEMHU} and optimization-based methods \cite{ImolaUAI2022} offer greater flexibility, especially for non-numeric outputs or selections from finite sets. 



\paragraph{Utility-preserving.} % In the Laplace mechanism, the noise added does not account for the density of the region where the vector resides, potentially reducing the utility of data perturbation. In such scenarios, EM \cite{Carvalho2021TEMHU} offers greater flexibility and often achieves higher utility, especially for non-numeric outputs or selections from finite sets. % Despite its advantages in specialized applications, EM is less commonly used than the versatile Laplace mechanism. 
% In contrast, optimization-based mechanisms are characterized by their higher computational costs, which typically range from $O(n^2)$ to $O(n^3)$. Early works, such as %those of Shokri et al. \cite{shokri2012protecting} and Koufogiannis et al. \cite{bordenabe2014optimal}, leveraged LP to optimize privacy guarantees, but encountered significant scalability challenges. The high complexity of these mechanisms limits their applicability to large-scale datasets. Despite these challenges, LP mechanisms offer the advantage of providing precise privacy guarantees and better utility due to their ability to finely control the privacy-utility trade-off.
% However, like Laplace, EM selects perturbed data based on perturbation magnitude $d(x, y)$, which doesn’t fully capture the varied utility losses caused by perturbation in different directions. In contrast, optimization-based mechanism can achieve a lower data utility loss, as it consider utility loss of each possible perturbation choice, including both magnitude and directions, therefore achieving lowest expected utility loss. 
The Laplace mechanism adds noise without considering the region's density where the vector resides, potentially reducing the utility of data perturbation. In such cases, EM \cite{Carvalho2021TEMHU} provides greater flexibility and often delivers higher utility, particularly for non-numeric outputs or selections from finite sets. However, similar to the Laplace mechanism, EM selects perturbed data based solely on the perturbation magnitude $d(x, y)$, which does not fully account for the varied utility losses caused by perturbations in different directions. In contrast, optimization-based mechanisms can achieve lower data utility loss by explicitly considering the utility loss of each possible perturbation choice, including both magnitude and direction. This approach enables these mechanisms to minimize the expected utility loss, thereby achieving superior performance.


% but it often faces a polynomial explosion of decision variables, limiting their application to small-scale secret data domain (with the size up to around 1,000 records \cite{qiu2024enhancing}), and rendering them impractical for large-scale or expanding datasets \cite{feyisetan2020privacy}. 

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{fig/relatedworks_scale_simplified}
    \vspace{-0.05in}
    \caption{Size of the secret data domains of the different optimization-based mechanisms}
    \label{fig:LPscale}
    \vspace{-0.05in}
\end{figure}

\paragraph{Time-efficiency and scalability.} Both the Laplace mechanism and the EM algorithm are recognized for their scalability and relatively low computational complexity, making them practical for processing large datasets. Their typical computational complexity ranges between $O(1)$ and $O(n^2)$, where $n$ denotes the size of secret data domain (i.e., $|\mathcal{X}|=n$). For example, the Laplace mechanism proposed by \cite{Andres-CCS2013} and the EM algorithm introduced by \cite{chatzikokolakis2015constructing} demonstrate time complexities of $O(1)$ and $O(n)$, respectively, when used to protect location data in a 2-dimensional plane. Subsequent studies, such as \cite{mendes2018effect} and \cite{takagi2019geo}, reveal that in high-dimensional settings, both methods can experience higher time complexities, often escalating to $O(n^2)$ or beyond. To address these computational challenges, researchers commonly employ clustering techniques or greedy algorithms, effectively reducing the computational burden and enabling the Laplace mechanism and EM algorithm to scale efficiently for large datasets.  \looseness = -1

As opposed to Laplace and EM, optimization-based methods remain limited to small-scale secret data domains, although recent works have made efforts to improve scalability. For instance, \cite{AhujaEDBT2019} proposed a multi-step algorithm that protects location data under Geo-Ind by leveraging a hierarchical index structure. Similarly, \cite{ImolaUAI2022} proposed a hybrid approach that applies EM to data with minimal utility impact and LP to data with greater utility sensitivity, improving computational efficiency while preserving privacy guarantees in large metric spaces. % \cite{biswas2022privic} introduced an incremental data collection mechanism combining the Blahut-Arimoto algorithm and iterative Bayesian updates. 
Another line of work, including \cite{Qiu-TMC2022,qiu2024enhancing,qiu-PETS2025}, employed optimization decomposition techniques such as Dantzig–Wolfe decomposition and Benders decomposition to break down large-scale LP problems into smaller, manageable subproblems, thereby improving the scalability of these solutions. Figure \ref{fig:LPscale} illustrates the comparison of secret data domain sizes across various LP-based methods. \looseness = -1 % Subsequently, \cite{Qiu-TMC2022} further reduced the LP's constraint set without sacrificing optimality by exploiting the transitivity property of geo-indistinguishability within road networks.
% Later, \cite{} introduced a partitioning strategy combined with Benders decomposition to address the scalability issues of LP-based mDP mechanisms. By dividing the dataset into smaller subsets and solving subproblems iteratively, the framework enables efficient computation while maintaining privacy guarantees across the entire dataset.
% \cite{qiu-PETS2025} proposed Locally Relevant Geo-obfuscation (LR-Geo), a scalable optimization framework that restricts computations to locally relevant locations. By combining Benders decomposition with linear programming, LR-Geo achieves efficient geo-obfuscation without compromising privacy guarantees, enabling scalability for large-scale applications.




% Different from Laplace and EM, scalability and computational efficiency are also critical challenges in mDP. To address these challenges, %\cite{ahuja2019utility} introduced a scalable and utility-preserving technique to protect location data in Geo-Ind. 
% \cite{Qiu-CIKM2020} first employed Dantzig-Wolfe decomposition to reduce the time complexity of LP, facilitating privacy-preserving task allocation on a large scale. Following \cite{Qiu-CIKM2020}, \cite{Qiu-TMC2022} leveraged the transitivity property of Geo-Ind within road networks to further reduce the LP constraint set without compromising optimality. 
% In a complementary approach, \cite{ImolaUAI2022} introduced EM constraints to perturbed locations with less impact on utility, enhancing the computational efficiency of LP and maintaining privacy guarantees in large metric spaces. Meanwhile, \cite{biswas2022privic} developed an incremental data collection mechanism that integrated the Blahut-Arimoto algorithm with iterative Bayesian updates. More recently, \cite{qiu2024enhancing} proposed a partitioning strategy combined with Benders decomposition. Building on insights from \cite{ImolaUAI2022} and \cite{qiu2024enhancing}, \cite{qiu-PETS2025} introduced Locally Relevant Geo-obfuscation (LR-Geo), a scalable optimization framework that confines computations to locally relevant locations. Fig. \ref{fig:LPscale} compares the sizes of the secret data domains across different LP-based methods.



% Subsequent research has focused on improving the scalability of LP-based mechanisms. \cite{Qiu-TMC2022} introduced constraint reduction techniques, successfully decreasing computational overhead and making LP mechanisms more practical for large-scale applications. Further enhancements, such as Benders' decomposition \cite{qiu2024enhancing} and localized optimization strategies \cite{qiu-PETS2025}, have significantly reduced computational costs, allowing LP mechanisms to handle larger datasets effectively while maintaining strong privacy guarantees.
% % Comparison: 
% \subsection{Time Complexity, Scalability and Utility}
% \subsubsection{Laplace Mechanism}
% Laplace mechanisms typically exhibit a computational complexity of $O(n)$, rendering them efficient and practical for datasets of moderate size. For instance, Andres et al. \cite{Andres-CCS2013} introduced the Geo-Ind mechanism with $O(1)$ complexity, applying Laplace noise to ensure privacy in location-based services. Several extensions, such as those by Koufogiannis and Pappas \cite{koufogiannis2016location}, adjust privacy levels dynamically while maintaining scalability.

% Despite their efficacy in providing privacy guarantees with relatively low complexity, Laplace mechanisms face scalability challenges as the dataset dimensionality increases. Mendes et al. \cite{mendes2018effect} demonstrated that the frequency of updates can significantly affect privacy, particularly in high-dimensional settings. Clustering approaches, like those by Cunha et al. \cite{cunha2019clustering}, mitigate these issues by reducing noise through grouping, thereby enhancing scalability to $O(k)$, where $k$ is the number of clusters.

% Certain Laplace-based mechanisms with higher complexity ($O(n^2)$), such as those by Kawamoto and Murakami \cite{kawamoto2019local}, achieve finer privacy guarantees but at the expense of increased computational cost, illustrating the trade-off between privacy strength and scalability.

% \subsubsection{Exponential Mechanism}
% Exponential mechanisms exhibit a range of complexities from linear to quadratic, depending on the utility function and the optimization techniques employed. Mechanisms such as those introduced by Chatzikokolakis et al. \cite{chatzikokolakis2015constructing} achieve $O(n)$ complexity, ensuring efficient scalability across diverse environments.

% However, exponential mechanisms may encounter increased computational complexity in specific scenarios. Takagi et al. \cite{takagi2019geo} proposed an approach with $O(n^2)$ complexity for optimizing over road networks, leveraging a greedy algorithm to reduce computational load, thus improving scalability for larger networks. More sophisticated methods, like those developed by Gursoy et al. \cite{gursoy2019secure}, confront challenges in high-dimensional scenarios, even as they offer stronger privacy guarantees.

% In specialized applications, combining the Exponential Mechanism with other techniques—such as Roy et al. \cite{roy2022strengthening} integrating order-preserving encryption—has led to efficient solutions with complexities like $O(n \log n)$, making them practical for encrypted database environments.



% \subsubsection{Linear Programming Mechanism}
% Linear programming (LP) mechanisms in mDP provide precise privacy guarantees but come with higher computational costs, typically ranging from $O(n^2)$ to $O(n^3)$. The evolution of optimization strategies has made LP-based mechanisms viable for broader applications by balancing privacy, utility, and scalability.

% Most LP-based mechanisms initially faced high computational complexity, which posed significant scalability challenges, especially for large-scale datasets. Early works, such as Shokri et al. \cite{shokri2012protecting} and Koufogiannis et al. \cite{koufogiannis2015optimality}, used LP to optimize noise distributions and adversary error, but these approaches had complexities of $O(n^2)$, making them computationally demanding for extensive data. Shokri et al. \cite{shokri2014privacy} further introduced a game-theoretic approach with a complexity of $O(n^3)$, which provided fine-grained privacy control but faced significant scalability issues.

% Subsequent research focused on improving scalability by introducing more effective optimization strategies. Wang et al. \cite{wang2016differential} developed an LP framework for differential location privacy in sparse mobile crowdsensing, achieving a complexity of $O(n^2)$. However, it still faced challenges with larger settings, highlighting the need for further optimization.

% Wang et al. \cite{wang2017location} attempted to tackle scalability for task allocation in mobile crowdsensing by employing LP, but the complexity remained $O(n^3)$, demonstrating that additional innovations were necessary to make these approaches scalable for extensive datasets.

% Recognizing these limitations, Qiu et al. \cite{Qiu-TMC2022} introduced constraint reduction techniques, which successfully reduced computational overhead by decreasing the number of constraints. This made LP-based Geo-Ind mechanisms more practical for large-scale applications by achieving better efficiency while preserving privacy.

% To further mitigate scalability issues, Imola et al. \cite{imola2022balancing} employed dataset partitioning, enabling LP mechanisms to handle larger datasets more effectively while maintaining privacy guarantees. Although this did not reduce the theoretical complexity, it improved practical applicability by managing smaller subsets of data.

% Pappachan et al. \cite{pappachan2022user} proposed CORGI, a framework using LP to generate customizable location obfuscation functions with a complexity of $O(n^3)$. Despite the high complexity, CORGI's flexibility in offering fine-grained privacy control and user customization made it valuable in specific scenarios, though scalability remained a challenge.

% Qiu et al. \cite{qiu2024enhancing} then introduced Benders decomposition to break down the LP problem into smaller, manageable sub-problems. This reduced decision variables, enhancing computational efficiency and addressing scalability issues more effectively than previous approaches.

% In another step towards improving efficiency, Qiu et al. \cite{qiu2024fine} introduced a fine-grained geo-obfuscation mechanism for time-sensitive spatial crowdsourcing. By employing constraint simplification, they managed to reduce decision variables, thus enhancing computational efficiency in real-time applications, making LP more suitable for immediate-use scenarios.

% Subsequently, Qiu et al. \cite{qiu-PETS2025} introduced localized optimization strategies that confined the optimization scope to smaller, relevant regions. This significantly reduced computational costs while maintaining strong privacy guarantees, making LP mechanisms more practical for large-scale applications requiring both efficiency and privacy.

% % Laplace Mechanism
% In discussing the complexity and scalability of mDP mechanisms, the majority of the Laplace mechanisms exhibit a computational complexity of $O(n)$, which makes them efficient and practical for low to moderate-sized data scenarios. 

% For most Laplace mechanism-based cases, mechanisms with a complexity of $O(n)$ demonstrate good scalability. For instance, Andres et al. \cite{Andres-CCS2013} proposed the Geo-Ind mechanism with a complexity of $O(1)$, primarily used to ensure privacy in location-based services by adding Laplace noise. Building upon this mechanism, Koufogiannis and Pappas \cite{koufogiannis2016location} introduced location-dependent privacy, which dynamically adjusts privacy levels based on geographic regions. With a complexity of $O(n)$, it effectively scales across environments of varying densities. Similarly, Fernandes et al. \cite{fernandes2018author} and Alvim et al. \cite{alvim2018metric} presented generalized differential privacy for author obfuscation and statistical data collection, both of which have a complexity of $O(n)$, allowing them to provide privacy protection across different data dimensions and environments.

% However, as the data dimensionality increases, the computational burden and complexity of these Laplace mechanism-based approaches also increase significantly. For example, Mendes et al. \cite{mendes2018effect} investigated the effect of update frequency on Geo-Ind and found that in high-frequency update scenarios, mechanisms with a complexity of $O(n)$ may face increased privacy leakage, impacting scalability. Fan and Bonomi \cite{fan2018time} encountered similar challenges in time series data sanitization, where $O(n)$ complexity is suitable for small datasets, but computational costs rise sharply for large-scale time series.

% To address these limitations, some researchers proposed clustering methods. Cunha et al. \cite{cunha2019clustering} introduced clustering Geo-Ind, which reduces the amount of noise by grouping nearby locations together, achieving a complexity of $O(k)$, where $k$ is the number of clusters. Additionally, Fernandes et al. \cite{fernandes2019generalised} developed a new mDP mechanism for text document processing, which involves handling high-dimensional feature spaces and thus presents challenges when applied to large-scale documents, but remains efficient for low-dimensional data.

% Nonetheless, certain Laplace mechanism based approaches with a complexity of $O(n^2)$ have demonstrated unique advantages in terms of privacy protection and utility. For instance, Kawamoto and Murakami \cite{kawamoto2019local} proposed a local obfuscation mechanism for hiding probability distributions based on the Wasserstein distance. While the complexity is higher, this mechanism provides fine-grained privacy, particularly suitable for scenarios requiring accurate distribution handling. Similarly, Kamalaruban et al. \cite{kamalaruban2020not} introduced $d_{X}$-private mechanisms for linear queries. Despite the $O(n^2)$ complexity, these mechanisms allow flexible privacy budget allocation across different attributes, achieving a nuanced balance between privacy and utility. These high-complexity mechanisms are valuable in cases where higher privacy requirements must be met, providing superior utility and stronger privacy guarantees at the cost of increased computational effort.


% % Exponential Mechanism

% For most Exponential mechanism-based cases, mechanisms exhibit a range of complexities depending on the specific implementation and optimization goals. Generally, the complexity is either linear or quadratic, influenced by the complexity of utility functions and specific optimization methods employed.

% For instance, Chatzikokolakis et al. \cite{chatzikokolakis2015constructing} introduced an elastic distinguishability metric for location privacy, with a complexity of $O(n)$. This mechanism adapts noise levels based on varying population densities, providing better utility compared to uniform noise addition. The efficient adaptation ensures good scalability across different environments.

% Alvim et al. \cite{alvim2018metric} extended local differential privacy (LDP) to metric spaces, focusing on optimizing the privacy-utility trade-off. The mechanism’s complexity is $O(n)$, allowing efficient handling of local queries. This scalability makes it well-suited for applications such as location-based services, where privacy needs to be balanced with service quality.

% Takagi et al. \cite{takagi2019geo} proposed Geo-Graph-Indistinguishability (GeoGI), which extends traditional Geo-Ind to road networks by using shortest path distances. The complexity of this approach is $O(n^2)$ when computing optimal solutions, but the use of a greedy algorithm reduces the computational burden, making it feasible for larger road networks. This mechanism improves utility in location-based services by leveraging network structures.

% However, as data complexity or dimensionality increases, exponential mechanisms can face increased computational costs, similar to Laplace-based mechanisms. For example, Gursoy et al. \cite{gursoy2019secure} introduced Condensed Local Differential Privacy (CLDP) for secure and utility-aware data collection, with a complexity of $O(n^2)$. The increased complexity provides stronger privacy guarantees, particularly for small populations, but scalability is managed through efficient protocol designs that handle both ordinal and non-ordinal data types.

% To address challenges in scalability for high-dimensional data, Feyisetan et al. \cite{feyisetan2020privacy} introduced a calibrated multivariate perturbation mechanism, which maintains a complexity of $O(n)$. This mechanism ensures utility in tasks such as clustering and sentiment analysis for moderate-dimensional text datasets, though it may face challenges in more complex or higher-dimensional spaces.

% In more specific applications, Roy et al. \cite{roy2022strengthening} combined the Exponential Mechanism with order-preserving encryption (OPE), achieving a complexity of $O(n \log n)$. This combination is well-suited for database applications, enabling efficient range queries while preserving privacy, making it practical for encrypted database settings.

% Finally, Carvalho et al. \cite{Carvalho2021TEMHU} proposed the Truncated Exponential Mechanism (TEM), which adjusts noise levels in densely packed regions of the embedding space. With a complexity of $O(n)$, TEM provides high utility for tasks such as privacy-preserving text classification and sentiment analysis while maintaining efficient scalability.

% In summary, most exponential mechanisms demonstrate linear or quadratic complexity, balancing privacy and utility for various application contexts. Lower complexity approaches ensure practical scalability in moderate-sized environments, while higher complexity mechanisms, such as those involving $O(n^2)$, are suited for specialized scenarios where robust privacy guarantees are necessary.



% % Linear Programming Mechanism
% Shokri et al. \cite{shokri2012protecting} introduced an LP-based approach for optimizing location privacy against localization attacks. The mechanism formalizes privacy constraints as a Stackelberg game, with a complexity of $O(n^2)$. This high complexity presents challenges for large-scale applications, but it provides robust privacy by maximizing adversary error while ensuring user utility.

% Koufogiannis et al. \cite{koufogiannis2015optimality} studied the optimality of the Laplace mechanism in differential privacy by using linear programming (LP) to analyze and optimize noise distributions. The mechanism has a time complexity of $O(n^2)$, which poses scalability challenges when dealing with large-scale or high-dimensional data. However, through a well-designed noise optimization strategy, the Laplace mechanism is able to achieve effective privacy protection while maintaining good utility. Despite its higher complexity, this method demonstrates significant advantages in privacy guarantees and utility optimization, especially in scenarios requiring precise privacy budget allocation.

% shokri2014privacy et al. \cite{shokri2014privacy} proposed a game-theoretic approach for user-centric data obfuscation, using LP to determine optimal obfuscation strategies. The complexity is $O(n^3)$, which provides fine-grained control over privacy but presents scalability issues for very large datasets.

% Wang et al. \cite{wang2016differential} developed an LP framework for differential location privacy in sparse mobile crowdsensing. The complexity of this approach is $O(n^2)$ due to the optimization of privacy constraints while balancing data utility, which poses challenges for scaling in larger settings but achieves effective privacy guarantees for spatial data.

% Yu et al. \cite{Yu-NDSS2017} introduced a dynamic differential location privacy mechanism that employs LP for personalized error bounds. The complexity is $O(n^2)$, which enables balancing between privacy and personalized utility needs, but the computational cost increases with larger datasets.

% Chatzikokolakis et al. \cite{chatzikokolakis2017efficient} proposed an efficient LP approach to improve utility for Geo-Ind, with a complexity of $O(n^2)$. The mechanism focuses on optimizing noise distribution while maintaining reasonable scalability for small to moderate-sized datasets.

% Wang et al. \cite{wang2017location} used LP to allocate tasks in mobile crowdsensing, ensuring location privacy via differential geo-obfuscation. The complexity is $O(n^3)$, which allows for detailed privacy control but results in limited scalability when applied to extensive datasets.

% Qiu et al. \cite{Qiu-TMC2022} presented an LP-based Geo-Ind mechanism for vehicle-based spatial crowdsourcing. The mechanism has a complexity of $O(K^3)$, where $K$ represents the number of road intervals. This high computational cost poses scalability issues, but a constraint reduction technique significantly improves time efficiency by reducing the number of constraints, achieving an average improvement of 87.9% in computational efficiency.


% Imola et al. \cite{imola2022balancing} introduced a mechanism to balance utility and scalability for metric differential privacy (mDP) using LP, with a complexity of $O(n^2)$. By leveraging efficient partitioning and optimization strategies, the mechanism addresses scalability concerns effectively, particularly for large-scale datasets.

% Qiu et al. \cite{qiu2022trafficadaptor} proposed an adaptive obfuscation strategy for vehicle location privacy that leverages linear programming to generate fake trajectories in line with realistic traffic flows. The mechanism achieves a complexity of $O(n^3)$, primarily due to the iterative optimization required for aligning obfuscation paths with traffic patterns. While the complexity presents scalability challenges for large road networks, the mechanism effectively balances privacy and utility, particularly under traffic flow-aware attacks, ensuring both privacy and quality of service (QoS).

% Pappachan et al. \cite{pappachan2022user} proposed CORGI, a framework that employs linear programming to generate customizable location obfuscation functions. The LP formulation ensures robust privacy guarantees even under user customization. The complexity of the approach is $O(n^3)$, which arises from the iterative optimization process to maintain Geo-Ind while allowing customization. Although the complexity is high, this mechanism effectively balances user-defined privacy settings with strong privacy guarantees, making it scalable for moderately sized datasets.

% Qiu et al. \cite{qiu2024enhancing} proposed enhancing the scalability of mDP via secret dataset partitioning and Benders decomposition. The mechanism uses a linear programming (LP) approach with a time complexity of $O(n^3)$, where $n$ is the size of the dataset. By introducing Benders decomposition, the number of decision variables in the LP problem is significantly reduced, effectively decreasing computational complexity and enhancing scalability. The use of secret dataset partitioning further reduces the computational burden while maintaining privacy, making this method more scalable for large-scale datasets.

% Qiu et al. \cite{qiu2024fine} introduced a fine-grained geo-obfuscation mechanism to protect workers' location privacy in time-sensitive spatial crowdsourcing. The mechanism leverages linear programming (LP) with a time complexity of $O(n^2)$. To address scalability challenges, a constraint simplification technique is employed, reducing the number of decision variables, which helps in maintaining feasible computational requirements for time-sensitive tasks. This mechanism strikes a balance between providing fine-grained privacy protection and ensuring scalability for large-scale, real-time spatial crowdsourcing applications.

% Qiu et al. \cite{qiu-PETS2025} proposed a scalable optimization mechanism for locally relevant geo-location privacy using linear programming (LP). The mechanism has a time complexity of $O(n^2)$, with $n$ representing the number of data points. To improve scalability, Qiu introduced a localized optimization strategy, which limits the scope of optimization to smaller, relevant regions rather than applying a global optimization approach. This significantly reduces computational costs while maintaining strong privacy guarantees, making the mechanism well-suited for large-scale, location-based applications that require efficiency without compromising privacy.

\vspace{-0.1in}
% \subsection{Discrete vs. Continuous}
\section{Applications}
\label{sec:applications}

Since mDP was first introduced in 2013 by \cite{Chatzikokolakis-PETS2013}, it has demonstrated its versatility and effectiveness across a range of application domains, driven by its ability to adapt privacy guarantees to specific distance metrics. The historical growth in mDP publications, illustrated in Figure \ref{fig:mDPhistory}, underscores its predominant use in location-based applications, while emerging interest in other domains such as text, image, and voice data reflects its expanding impact. 

\vspace{-0.03in}
\subsection{Application Domains}
\label{subsec:applications}
\vspace{-0.00in}


% Fig. \ref{fig:mDPhistory} showcases the historical development of publications in various fields of mDP from 2012 to 2024, with stacked bars representing the number of papers published annually across domains such as Location, Text, Image, and others.  While research on location privacy remains predominant, other fields like text and general applications have gained attention, demonstrating mDP's versatility in delivering tailored privacy guarantees. Emerging areas such as voice and image underscore the growing recognition of mDP's utility beyond traditional applications, signaling continuous innovation in protecting various types of sensitive data. % This recent surge, particularly after 2020, aligns with increased awareness of privacy-preserving technologies and stricter data privacy regulations. % An upward trend is evident, especially in recent years, indicating increasing research interest and diversity in applications of mDP.

% Location Privacy
\paragraph{Location privacy.}  As of now, the most extensively studied domain in mDP is location privacy. The use of mDP for location privacy can date back to 2013, introduced by \cite{Andres-CCS2013}, which first extends DP to Geo-Ind and employs the Laplace mechanism (polar Laplace noise) to perturb users' location on a 2-dimensional space. 
Following this work, a rich body of Laplace, EM, and Optimization-based approaches 
further enhanced these techniques by considering diverse privacy and utility demands in different LBS applications, including \emph{mobile spatial crowdsourcing (MSC)} and \emph{intellignent transportation system (ITS)}. For instance,  in MSC, mDP has been instrumental in addressing task allocation challenges while protecting worker location privacy. Mechanisms such as differential geo-obfuscation \cite{wang2017location} achieve a balance between privacy and utility by optimizing travel distances for task assignments. \cite{zhang2022area} proposed a mechanism that balances location privacy with efficient area coverage during task allocation. This approach was later refined by \cite{ma2022personalized}, who introduced personalized noise addition frameworks, enabling privacy guarantees tailored to individual user preferences. Additionally, \cite{zhang2022geo} integrated EM with evolutionary algorithms for the allocation of privacy-preserving tasks, optimizing performance under privacy constraints. Recent advancements include reinforcement learning-based techniques (e.g. \cite{min2023geo}) and scalable optimization methods (e.g. \cite{Qiu-TMC2022}) designed to handle large-scale crowdsourcing environments effectively.


To protect vehicles' location privacy, \cite{takagi2019geo} applied road network metrics to improve obfuscation in constrained spatial environments. These methods, combined with dynamic adaptations like \cite{Yu-NDSS2017}, enable real-time, context-aware privacy guarantees tailored to user preferences. \cite{takagi2019geo} extended Geo-Ind to road networks by introducing \emph{Geo-Graph-Indistinguishability}, which replaced the Euclidean distance with the shortest path metrics considering that vehicles' mobility restriction over the road network. \cite{li2020perturbation} introduced the ``Perturbation-Hidden'' mechanism, using EM to inject noise into vehicle location data. This approach balanced privacy with the accuracy demands of LBS in the Internet of Vehicles, preventing tracking and inference attacks while preserving utility. 





% For spatial data with varying regional privacy demands, \cite{zhang2024dpive} proposed DPIVE, a regionalized mechanism that divides locations into \emph{Protection Location Sets (PLSs)}, applying EM within each set to provide fine-grained privacy guarantees. 



\paragraph{Text perturbation.} The application of mDP has also been explored in the domain of text perturbation. \cite{fernandes2018author} applied the Laplace mechanism to the Word Mover distance to anonymize author identities while preserving semantic integrity. Similarly, \cite{arnold2023guiding} advanced text privatization by incorporating Laplace noise guided by syntactic structures, ensuring semantic coherence alongside privacy and extending the application of differential privacy in natural language processing. However, Laplace mechanisms are less effective for perturbing word embeddings, as directly adding noise to vectors in a discrete finite field often results in invalid words. To address this limitation, \cite{fernandes2018author} and \cite{Feyisetan-ICDM2019} proposed using nearest neighbor approximations for noisy vectors, treating the representation space as non-sensitive and avoiding privacy loss during nearest neighbor searches. Despite these innovations, these methods often neglect the density of the embedding space, potentially leading to reduced utility. In such cases, EM provides greater flexibility and higher utility, particularly for non-numeric outputs or selections from finite sets. 
For example, \cite{wang2017local} applied SEM to estimate ordinal data distributions, effectively utilizing the data's intrinsic order to reduce estimation error while preserving privacy.
 \cite{feyisetan2020privacy} leveraged EM to perturb text embeddings, ensuring privacy protection without compromising semantic coherence. %\cite{yue2021differential} introduced mechanisms for selecting sanitized text tailored to tasks such as sentiment analysis and classification. 
 Recent advancements include \cite{Carvalho2021TEMHU}'s \emph{Truncated Exponential Mechanism (TEM)}, which modulates noise based on embedding density, and \cite{meisenbacher20241}'s 1-Diffractor, which simplifies computations by reducing text embeddings to a single dimension while maintaining privacy.

\vspace{-0.03in}
\paragraph{Other applications.} More recently, mDP has been applied beyond spatial and textual data, extending to images, networking, blockchain, and other structured data. For example, \cite{han2020voice} used mDP to protect biometric data within multimedia datasets. \cite{chen2021perceptual} introduced PI-Net, a framework based on the Laplace mechanism to obfuscate facial images. This method preserves semantic content while allowing for controllable obfuscation levels, addressing privacy concerns in sensitive image datasets. In federated learning, \cite{galli2023advancing} uses Laplace-based noise addition to preserve privacy at a group level. This study balances model accuracy with privacy guarantees, offering insight into collaborative learning that preserves privacy.
The integration of blockchain with Laplace mechanisms was explored by \cite{yang2021blockchain}, which combined decentralized technology with privacy-preserving noise addition to protect user location in indoor environments. This combination of blockchain and privacy mechanisms opens new avenues for secure data sharing in environments with untrusted entities.


% {\rd In the domain of image privacy, frameworks such as PI-Net (\cite{chen2021perceptual}) apply Laplace noise to obscure sensitive visual information effectively. }

% We then provide comparative analyses of these mechanisms in terms of their complexity (Section \ref{subsec:complexity}) and contextual suitability (Section \ref{subsec:context}). Additionally, we discuss their contributions to the progression of mDP and examine their applications across various domains (Section \ref{subsec:applications}).
\subsection{Context-Aware mDP Mechanisms}
\label{subsec:context}
Notably, mDP has evolved through applications that dynamically adjust privacy protections based on contextual information or user behavior. Particularly, \cite{chatzikokolakis2014predictive} first introduced a predictive mDP mechanism that adjusts noise levels according to historical mobility patterns, enhancing privacy protection in mobility trace data. After that, \cite{haney2015design} and \cite{Reza-PoPET2015} explored policy-driven and game-theoretic approaches to privacy settings, enabling customized configurations aligned with user-specific policies or threat models. \cite{Yu-NDSS2017} proposed a mechanism to adjust noise levels based on user preferences, offering flexible privacy guarantees in location-based services (LBS).
\cite{eltarjaman2017location} proposed a rank-based approach that modulates privacy protections based on query importance in geo-query systems. This method balances privacy and utility by prioritizing more accurate responses for top-ranked queries. % Building on the Geo-Ind model, \cite{takagi2019geo} introduced the Geo-Graph-Indistinguishability model, which adapts privacy protections dynamically by considering traffic flow and network conditions. This approach effectively protects privacy while maintaining the efficiency of location-based services under varying traffic scenarios.

More recently, \cite{cao2020pglp} proposed PGLP, a framework allowing users to define privacy settings based on their location history or preferences, ensuring privacy tailored to individual needs. \cite{zhao2022geo} introduced Geo-Ellipse Indistinguishability, incorporating community-level covariance matrices to provide privacy adapted to data dispersion and orientation in spatial datasets. Furthermore, \cite{Pappachan-EDBT2023} developed a customizable geo-obfuscation framework using a tree-structured organization of locations at varying granularity levels, enabling privacy based on diverse user demands. \cite{odoh2024group} presented a group-wise k-anonymity scheme combined with differential privacy, dynamically considering group characteristics to enhance protections against inference attacks and provide robust privacy guarantees.





\iffalse
 
[CCS2013] Formalized the concept of \textcolor{red}{Geo-Indistinguishability} as an extension of differential privacy for spatial data. And proposed a mechanism using a planar Laplace distribution to achieve Geo-Indistinguishability. Also demonstrated how this mechanism can enhance location-based services with privacy guarantees without sacrificing service quality.

[CCS2014] Introduced LP-Guardian, a framework designed to protect smartphone location privacy. This approach uses customizable anonymization techniques tailored to different apps' needs, protecting against tracking, profiling, and identification threats. It showed that privacy could be maintained without significant loss of app functionality or user experience, making it a practical solution for real-world use.

[PETS2015a] Introduced the concept of elastic distinguishability metrics to address the uniformity problem in Geo-Ind for location privacy. Proposed a graph-based algorithm that adapts noise levels based on local characteristics, providing better privacy in both dense and sparse areas. Demonstrated how this approach improves privacy without compromising utility, especially in varying urban and rural environments, using real-world datasets.

[PETS2015b] Formalized the concept of privacy games as a user-centric data obfuscation mechanism designed to balance privacy and utility. The paper proposed a game-theoretic approach, using a Stackelberg game, to model the interaction between users and adversaries, optimizing obfuscation strategies to minimize utility loss while ensuring both differential privacy and distortion privacy. It demonstrated how these joint mechanisms could provide robust protection against adaptive inference attacks without compromising service quality.

[ICDM2016] Introduced a differential location privacy framework for Sparse Mobile Crowdsensing, focusing on reducing data quality loss caused by location obfuscation. The framework combines a data adjustment function, optimal location obfuscation, and an uncertainty-aware inference algorithm. Evaluations demonstrated that this approach reduces data quality loss by up to 42\%, making it more effective than traditional differential privacy methods, especially in urban sensing tasks.

[WWW2017] Proposed a location privacy-preserving task allocation framework for Mobile Crowdsensing that uses differential geo-obfuscation to protect users' location privacy without involving third parties. The framework optimizes task allocation by minimizing travel distance while ensuring differential privacy. Evaluation showed that this approach reduced the average travel distance by up to 45\% compared to the state-of-the-art Laplace obfuscation method.    

[NDSS2017] Formalized the concept of Dynamic Differential Location Privacy with personalized error bounds. Proposed a two-phase framework, PIVE, that combines Geo-Ind and expected inference error to protect location privacy against inference attacks. The approach dynamically adjusts noise levels based on user-defined privacy preferences and prior adversary knowledge, demonstrating improved privacy protection without compromising service quality in dynamic environments.

[PETS2020] Investigated the impact of location report frequency on the privacy level of Geo-Indistinguishability in location-based services. The study proposed a method to evaluate privacy degradation over time using different report frequencies. It demonstrated that while localization attacks are consistent across frequencies, tracking attacks are less effective as the reporting frequency decreases. This work provides insights into balancing privacy and service quality based on user reporting behavior.

[TMC2020] Introduced a location obfuscation strategy tailored for Vehicle-based Spatial Crowdsourcing using Geo-Indistinguishability. The study proposed a discretization method and a linear programming approach to minimize quality-of-service (QoS) loss while preserving location privacy. Experimental results demonstrated that the method outperforms existing strategies in terms of both QoS and privacy, particularly in road network environments where traditional 2D plane-based methods are less effective.

[Sigspatial2022] Introduced TrafficAdaptor, an adaptive obfuscation strategy for vehicle location privacy against traffic flow-aware attacks. The strategy uses fake trajectories that follow realistic traffic patterns to confuse adversaries while maintaining service quality. Experimental results showed that this approach effectively mitigates location tracking risks, offering better protection than traditional methods by leveraging real-world traffic data.

[UAI2022] Addressed the challenge of balancing utility and scalability in Metric Differential Privacy. They proposed a method that reduces the size of the linear program used to generate mDP mechanisms by incorporating constraints based on the exponential mechanism. The approach demonstrated improved scalability without sacrificing utility, making it possible to handle larger metric spaces while maintaining privacy guarantees.

[EDBT2023] Introduced CORGI, a framework for generating location obfuscation functions that allow user customization while maintaining strong privacy guarantees. The system employs a tree-based structure to facilitate the customization of obfuscation parameters by users, balancing the trade-offs between privacy, utility, and personalization. Experimental results showed that CORGI's obfuscation functions remain robust even after user customization, outperforming traditional approaches in both privacy preservation and utility retention.

[EDBT2024] Introduced a fine-grained geo-obfuscation strategy to protect workers' location privacy in time-sensitive spatial crowdsourcing applications. The proposed method limits obfuscation to peer locations with similar travel costs, minimizing quality loss while satisfying Geo-Ind. This approach demonstrated significant improvements in reducing travel cost estimation errors and maintaining privacy protection in both simulation and real-world experiments.

[TrustNLP2021] Introduced a framework for the private release of text embedding vectors using Lipschitz privacy. This approach projects high-dimensional embeddings to a lower-dimensional space and adds calibrated noise, addressing privacy concerns like data reconstruction and attribute inference. It demonstrated that privacy could be preserved without significant loss of utility in NLP tasks, offering a practical solution for real-world applications.

\textcolor{red}{new}


[PETS 2013] Formalized the concept of differential privacy as an extension of differential privacy using metrics. The paper proposed a mechanism using planar Laplace distribution to achieve this extended privacy concept, demonstrating how this mechanism can enhance location-based services and other applications by providing robust privacy guarantees without sacrificing utility. This approach not only preserves privacy but also ensures that the services remain effective and accurate. 
[method: Lap/Exp] [model: Protection] [Application area: statistical databases, location-based services, and smart metering]

[NDSS 2017/Not All Attributes are Created Equal: Differential Privacy for Data-Driven Applications] Formalized the concept of differential privacy for data-driven applications, examining how not all attributes contribute equally to privacy risks. The paper proposes a mechanism using differential privacy techniques to prioritize attribute protection based on their sensitivity and impact on privacy risks. It demonstrates how this selective protection can enhance data utility in applications like personalized advertising without sacrificing user privacy. The approach efficiently balances privacy with data utility by selectively applying noise to more sensitive attributes.
[method: Lap]
[model: Protection]
[Application area: data-driven applications, personalized services]

[\textcolor{red}{ICDE 2019}/PriSTE: From Location Privacy to Spatiotemporal Event Privacy] This paper extends the concept of differential privacy to spatiotemporal events, introducing a framework that captures both spatial and temporal dimensions of privacy. The proposed model uses optimization-based approaches to ensure privacy across varying spatiotemporal scales, thus enhancing applications in mobile and location-based services. The framework aims to provide a balanced approach to privacy that accommodates the dynamic nature of spatiotemporal data.
[method: LP]
[model: Protection]
[Application area: location-based services, mobile applications]

[CCS 2014/Optimal Geo-Indistinguishable Mechanisms for Location Privacy] This paper enhances the concept of Geo-Ind as a stronger, more flexible alternative to traditional differential privacy for location data. It proposes a mechanism that uses optimization techniques to achieve the best possible utility for geo-indistinguishable privacy. The mechanism is shown to significantly improve the privacy-utility tradeoff for location-based applications, making it possible to provide high-quality services without compromising user privacy.
[method: LP]
[model: Protection]
[Application area: location-based services]

[\textcolor{red}{DBSec 2019}/Geo-Graph-Indistinguishability: Protecting Location Privacy for LBS over Road Networks] The paper extends the concept of Geo-Ind to road network environments, introducing a new notion called Geo-Graph-Indistinguishability (GeoGI). It proposes a graph exponential mechanism (GEM) that considers the structure of the road network, ensuring that location privacy is maintained in a more context-sensitive manner. This mechanism enhances location-based services by aligning privacy protections with the actual routes users may take, thereby improving both privacy and utility compared to traditional planar Laplace mechanisms.
[method: Exp]
[model: Protection]
[Application area: location-based services on road networks]

[Pets 2017/Efficient Utility Improvement for Location Privacy] This research addresses the efficiency of privacy-preserving mechanisms in location-based services, specifically aiming to enhance utility without significantly compromising privacy. By employing optimization-based methods, the study shows how adjustments to differential privacy applications can lead to better performance in real-world LBS scenarios where service quality is critical.
[method: Exp]
[model: Protection]
[Application area: location-based services focusing on utility improvement]

\begin{itemize}
    \item \textbf{Application Domains}:
    \begin{itemize}
        \item \textbf{Domain-Specific Applications}: List various fields where metric differential privacy has been applied, such as healthcare, finance, and social networks.
        \item \textbf{Case Studies}: Provide detailed analyses of specific cases, showing the practical effectiveness of metric differential privacy.
    \end{itemize}
    \item \textbf{Challenges and Solutions}:
    \begin{itemize}
        \item \textcolor{red}{\textbf{Challenges}: Discuss the major challenges in metric differential privacy research, such as computational complexity and the trade-off between data utility and privacy.}
        \item \textbf{Potential Solutions}: Suggest possible solutions and future research directions to address these challenges.
    \end{itemize}
\end{itemize}

\fi

% \newpage 
% \begin{table*}[ht]
% \centering
% \caption{Comparison of related works (more details can be found in ``relatedwork\_comparison.xlsx'').}
% \small
% \begin{tabular}{|c|c|c|c|c|c|c|p{6cm}|}
% \hline
% \textbf{Paper} & \textbf{Lap} & \textbf{Exp} & \textbf{LP} & \textbf{Scalability} & \textbf{Threat} & \textbf{Protection} & \textbf{Application} \\ \hline
% CCS \cite{shokri2012protecting} &  &  & \checkmark & 30 & \checkmark & \checkmark & Location privacy protection, especially for users accessing location-based services. \\ \hline
% CCS \cite{andres2013geo} & \checkmark &  & \checkmark & -- &  & \checkmark & Enhancing LBS, particularly in retrieving points of interest (POI) privately. \\ \hline
% CCS \cite{fawaz2014location} &  & \checkmark &  & 50 &  & \checkmark & Smartphone apps, user location privacy. \\ \hline
% PETS \cite{shokri2015privacy} &  &  &  & 300 &  & \checkmark & Location-based services, privacy in urban/rural areas. \\ \hline
% PETS \cite{chatzikokolakis2015constructing} &  & \checkmark &  & -- &  & \checkmark & Location privacy, adapting to diverse user privacy needs. \\ \hline
% ICDM \cite{wang2016differential} &  &  & \checkmark & 57 &  & \checkmark & Mobile crowdsensing, location privacy in sparse data scenarios. \\ \hline
% WWW \cite{wang2017location} & \checkmark & \checkmark &  & 16 &  & \checkmark & Mobile crowdsensing, privacy-preserving task allocation. \\ \hline
% NDSS 2017 &  & \checkmark &  & 50 &  & \checkmark & Location privacy with dynamic and personalized error bounds. \\ \hline
% TMC 2020 &  &  & \checkmark & 300--400 &  & \checkmark & Vehicle-based spatial crowdsourcing, location privacy for drivers. \\ \hline
% PETS 2020 & \checkmark &  &  & -- &  & \checkmark & Geo-indistinguishability, adjusting privacy level based on report frequency. \\ \hline
% SIGSPATIAL 2022 &  &  & \checkmark & 100 & \checkmark & \checkmark & Vehicle location privacy, adaptive obfuscation against traffic flow analysis. \\ \hline
% UAI 2022 &  & \checkmark &  & 400 &  & \checkmark & Metric differential privacy, balancing utility and scalability in various metric spaces like text and geolocation data. \\ \hline
% EDBT 2023 &  & \checkmark &  & 70 &  & \checkmark & Customizable Geo-Ind for user location privacy in mobile and web applications. \\ \hline
% EDBT 2024 &  &  & \checkmark & 300--400 &  & \checkmark & Worker location privacy in time-sensitive spatial crowdsourcing. \\ \hline
% \end{tabular}
% \end{table*}


\vspace{-0.05in}
\section{Future Prospects}
\label{sec:future}
The field of mDP has made significant progress over the past decade, but there are still many opportunities for advancement. Below, we outline key future directions for further development.

\vspace{-0.00in}
\paragraph{Scalability and practical deployment.} Scalability remains a major challenge for utility-preserving mDP, particularly with increasingly large and high-dimensional datasets. A promising future direction is to develop more efficient optimization methods that reduce computational overhead and can handle real-world, large-scale deployments. Simplified models that approximate mDP while maintaining acceptable privacy guarantees could also improve practicality for industrial applications. Techniques such as optimization decomposition have been explored to enhance scalability \cite{qiu2024enhancing,qiu-PETS2025}, but further advancements are needed to make these methods more widely applicable.

\vspace{-0.00in}
\paragraph{Utility-preserving text data protection.} While mDP research has traditionally focused on location data, there is a growing body of work exploring its application for protecting textual data to address privacy concerns in Large Language Models (LLMs). However, challenges remain in balancing privacy and utility, as excessive noise can degrade the quality of generated text, especially in nuanced contexts. The high dimensionality of LLMs and the complex dependencies between parameters complicate the direct application of mDP, requiring new techniques like adaptive noise mechanisms or task-specific privacy optimizations. Ensuring scalability for large-scale training and addressing privacy guarantees for compositional outputs are also critical hurdles. 

Furthermore, the rapid advancement of deep neural networks highlights limitations in the traditional mDP framework, which was designed primarily for statistical models, making it potentially insufficient to protect users' data against sophisticated attacks. This necessitates the development of new threat models and designing advanced countermeasures tailored to the unique vulnerabilities and complexities of deep learning systems, ensuring effective privacy protections in evolving applications.

% Integrating mDP with machine learning models, particularly those in deep learning, is crucial for enhancing privacy without sacrificing model performance. Future research should focus on embedding mDP in training processes to protect sensitive data while maintaining model accuracy. There is also a need for privacy-preserving mechanisms that are specifically tailored to work with federated learning frameworks, which inherently deal with decentralized and privacy-sensitive data. Recent work has shown promise in applying mDP to federated learning scenarios to ensure privacy at both individual and group levels \cite{galli2023advancing}.
% involves leveraging mDP to protect sensitive data during training or inference by adding calibrated noise to embeddings, attention weights, or outputs, ensuring privacy-preserving responses while maintaining utility. mDP’s ability to account for distances in semantic spaces aligns well with LLMs, as it can preserve the relational structure of word embeddings or contextual representations. However, challenges include balancing privacy and utility, as excessive noise can degrade the quality of generated text, especially in nuanced contexts. Additionally, the high dimensionality of LLMs and the complex dependencies between parameters complicate the direct application of mDP, requiring innovative techniques like adaptive noise mechanisms or task-specific privacy optimizations. Ensuring scalability for large-scale training and addressing privacy guarantees for compositional outputs are also critical hurdles.
\vspace{-0.00in}
\paragraph{Adaptive context-aware mechanisms.} The development of adaptive, context-aware mechanisms is a promising direction for mDP. Future research should explore how privacy levels can be dynamically adjusted based on real-time contextual information, such as user behavior or data sensitivity. This would involve leveraging AI techniques to intelligently modulate privacy levels, ensuring a better balance between utility and privacy in diverse scenarios. Context-aware approaches like Geo-Ellipse-Indistinguishability \cite{zhao2022geo} have demonstrated the benefits of adjusting privacy parameters based on spatial contexts, and similar techniques could be expanded to other domains.

\vspace{-0.00in}
\paragraph{Enhancing theoretical foundations.} Further theoretical advancements are needed to deepen the understanding of mDP, particularly in the trade-offs between privacy, utility, and efficiency. Research could explore new types of distance metrics and theoretical models that better capture real-world data relationships. Additionally, establishing tighter bounds on privacy guarantees can help guide the practical implementation of mDP in various applications. Existing works like \cite{boedihardjo2024metric} have explored new metrics for privacy-utility trade-offs, but further development is needed to establish comprehensive theoretical frameworks.






% \begin{table*}[h!]
% \centering
% \begin{tabular}{|p{2cm}|p{5.2cm}|p{8.5cm}|}
% \hline
% \textbf{Paper} & \textbf{Problem Addressed} & \textbf{Methodology} \\
% \hline
% CCS (2012) & Considers user-adversary interactions to protect location privacy in LBS. & Uses a Stackelberg Bayesian game model to find the optimal LPPM and inference attack, maximizing the adversary's error while maintaining service quality for the user. \\
% \hline
% CCS (2013) & Provides location privacy for location-based systems. & Applies Geo-Ind by adding noise to location data, ensuring privacy while maintaining utility through differential privacy techniques. \\
% \hline
% CCS (2014) & Protects smartphone users' location privacy. & Combines anonymization and obfuscation techniques to enable access to location-based services without revealing precise user locations. \\
% \hline
% Shokri (2015) & Proposes a user-centric data obfuscation mechanism based on privacy games to protect user privacy. & Optimizes privacy protection mechanisms using game theory, allowing users to effectively control privacy risks. \\
% \hline
% PETS (2015) & Addresses location privacy with elastic distinguishability metrics. & Utilizes an adaptive metric mechanism that adjusts to different user privacy needs. \\
% \hline
% ICDM (2016) & Focuses on location privacy issues in sparse mobile crowdsensing. & Applies differential privacy and combines data adjustment functions with linear programming to reduce data quality loss. \\
% \hline
% WWW (2017) & Protects location privacy in mobile crowdsensing task allocation. & Implements a differential geo-obfuscation strategy to optimize privacy protection and reduce the risk of data leakage. \\
% \hline
% NDSS (2017) & Provides dynamic differential location privacy with personalized error bounds. & Dynamically adjusts privacy protection strength to fit users' personalized needs in dynamic environments. \\
% \hline
% PETS (2020) & Investigates the impact of report frequency on the privacy level of Geo-Ind. & Adjusts privacy protection intensity based on report frequency. \\
% \hline
% TMC (2020) & Protects vehicle location privacy in spatial crowdsourcing. & Utilizes an adaptive obfuscation strategy based on Geo-Ind to counter traffic flow analysis. \\
% \hline
% SIGSPATIAL (2022) & Addresses traffic flow analysis attacks on vehicle location privacy. & Develops an adaptive obfuscation algorithm to protect vehicle location privacy from traffic flow analysis attacks. \\
% \hline
% UAI (2022) & Balances utility and scalability in metric differential privacy. & Reduces the size of the linear programming used in mDP mechanisms to achieve a better tradeoff between utility and scalability. \\
% \hline
% EDBT (2023) & Provides customizable and robust Geo-Ind for location privacy. & Allows user customization of geo-privacy mechanisms, enhancing flexibility and robustness. \\
% \hline
% EDBT (2024) & Protects workers' location privacy in time-sensitive spatial crowdsourcing. & Proposes a fine-grained geo-obfuscation strategy for worker location privacy while optimizing scalability. \\
% \hline
% \end{tabular}
% \caption{Comparison of Matrix Differential Privacy Related Works}
% \end{table*}
\vspace{-0.02in}
\section{Conclusion}
\label{sec:conclusions}
% This survey has provided a comprehensive overview of the development of mDP from its foundations in DP to the most recent advancements in mechanism design and practical implementations. We have categorized the primary mechanisms driving progress in mDP—namely the Laplace Mechanism, Exponential Mechanism (EM), and Optimization-based Mechanisms—and compared their strengths, limitations, and scalability. Additionally, we have highlighted key applications, including location privacy, text perturbation, and multimedia protection, demonstrating the growing versatility and adoption of mDP.

Over the past decade, mDP has evolved into a crucial extension of traditional DP, offering flexible, distance-based privacy guarantees that address the diverse requirements of applications such as location-based services, text processing, and multimedia privacy. This survey has highlighted the development of key mDP mechanisms, including the Laplace mechanism, Exponential mechanism, and optimization-based approaches, as well as their applications and scalability. 

While significant progress has been made, challenges persist, particularly in scaling mDP for large datasets, preserving data utility across various domains, and dynamically adapting privacy protections based on context. Addressing these challenges through future research in efficient optimization, adaptive context-aware mechanisms, and deeper theoretical models will be essential to fully realize mDP’s potential in protecting privacy in emerging fields like large-scale machine learning, real-time systems, and personalized data protection.



%\begin{itemize}
%    \item \textbf{Summary}: Summarize the main content and contributions of the survey.
%    \item \textbf{Emphasis on Importance}: Reiterate the importance and potential of metric differential privacy.
%\end{itemize}


% \qiu{Each references should have ``year''}
\clearpage 


\bibliographystyle{named}
\bibliography{bibshort}


\DEL{
\clearpage 
\appendix
\section{Laplace Mechanism}
The Laplace mechanism is among the most widely used data perturbation techniques, originally developed to achieve differential privacy (DP) \cite{Dwork-TC2006}. It perturbs the output of a query function $f(x)$ by adding noise $x$, resulting in:
\[
\mathcal{M}(f(x)) = f(x) + x,
\]
where $x$ is drawn from a Laplace distribution with a probability density function:
\[
\mathrm{Lap}(x) = \frac{\epsilon}{2\Delta f} e^{-\frac{\epsilon |x|}{\Delta f}}.
\]
Here, $\Delta f = \sup_{x, y \in \mathcal{X}} |f(x) - f(x')|$ represents the global sensitivity of $f$, measuring the maximum possible change in the function's output between neighboring datasets.

The Laplace mechanism naturally adapts to various metrics by appropriately scaling the noise \cite{McSherry-FOCS2007}. To extend it for metric differential privacy (mDP), \cite{Chatzikokolakis-PETS2013} proposed scaling the noise based on a metric $d_{\mathcal{X}}$ instead of the global sensitivity $\Delta f$. This metric, $d_{\mathcal{X}}(s, x)$, quantifies the distinguishability between $x$ and $x$. The resulting probability density function is expressed as:
\[
\mathrm{Lap}(x) = \lambda(x) e^{-d_{\mathcal{X}}(s, x)}.
\]
Building on this, \cite{Andres-CCS2013} introduced polar Laplace noise to achieve \emph{geo-indistinguishability (Geo-Ind)}. This approach employs a two-dimensional Laplace distribution centered at the true location $x$, with a probability function given by:
\[
\Pr\{\mathcal{M}(x) = y\} = \frac{\epsilon^2}{2\pi} e^{-\epsilon d(x, y)}.
\]

Following \cite{Andres-CCS2013}, numerous studies have applied the Laplace mechanism to achieve Geo-Ind. For example, \cite{chatzikokolakis2014predictive} tailored Laplace noise for synthetic route generation in smartphone applications, while \cite{wang2014entropy} proposed an entropy-minimizing mechanism that combines Laplace noise with system feedback control. Other notable works include \cite{arcolezi2021preserving}, which adapted Geo-Ind for emergency location sharing, and \cite{shi2021clap}, which tailored it for incentivized crowdsensing platforms. \cite{min20213d} extended Geo-Ind to three-dimensional indoor spaces to address challenges in high-resolution spatial data. Similarly, \cite{min2023personalized} developed personalized 3D location privacy techniques using distortion-based geo-perturbation. \cite{yang2021blockchain} integrated blockchain technology with Laplace noise for secure indoor data anonymization.

Beyond basic Geo-Ind, advanced use cases have emerged in trajectory and mobility trace privacy. For instance, \cite{chatzikokolakis2014predictive} generalized Geo-Ind to mobility trace privacy by leveraging predictive correlations across multiple location reports. \cite{mendes2018effect} examined update frequencies and proposed adaptive noise calibration to balance privacy and utility.

Protecting trajectory data became particularly critical during the COVID-19 pandemic. \cite{li2023accurate} proposed a Laplace-based mechanism for accurate contact tracing, while \cite{yu2023privacy} developed longitudinal Geo-Ind to protect trajectory privacy in advertising systems. Other studies, such as \cite{li2023privacy} and \cite{duarte2024privacy}, refined these approaches by employing tailored metrics and adaptive noise for trajectory publishing tasks. \cite{brauer2024time} introduced temporal perturbation strategies to obfuscate trajectories while preserving their analytical utility.

Laplace-based methods have also been adapted for continuous queries in real-time services. \cite{hua2017geo} and \cite{ma2018agent} refined adaptive noise techniques to optimize privacy-utility trade-offs in continuous location reporting. Similarly, \cite{huang2016eppd} developed a proximity testing framework utilizing Laplace noise to ensure privacy during frequent spatial closeness verifications.

Beyond location privacy, federated learning systems have benefited from Laplace-based mechanisms. \cite{galli2023advancing} introduced group-level privacy by adding Laplace noise to aggregated data, and \cite{galli2023group} further refined these techniques to preserve privacy without compromising model performance in collaborative learning scenarios.

The theoretical foundations of the Laplace mechanism have been extended to diverse applications. \cite{koufogiannis2015optimality} and \cite{fernandes2021laplace} demonstrated its utility-optimality for continuous query functions, while \cite{elsalamouny2018optimal} derived optimal noise functions for location privacy. \cite{pankova2022interpreting} analyzed privacy-utility trade-offs for categorical and numerical attributes. \cite{min2024semantic} proposed a semantic Geo-Ind mechanism, adjusting noise levels based on contextual semantics.

For incremental and temporal data, the Laplace mechanism has been adapted to address evolving privacy challenges. \cite{Koufogiannis-JPC2017} introduced incremental data release mechanisms to ensure privacy at each stage of data publication. \cite{xiang2020linear} optimized Laplace noise for temporal queries under metric-based local differential privacy. \cite{kamalaruban2020not} proposed dx-privacy, combining tailored Laplace noise with selective constraints for enhanced privacy protection.

In time-series data, \cite{fan2018time} applied Laplace mechanisms to preserve temporal patterns while ensuring privacy. \cite{brauer2024time} further refined temporal perturbation techniques to improve privacy preservation for trajectory data.

Beyond numerical data, the Laplace mechanism has been applied to text, image, and IoT privacy. For text data, \cite{fernandes2018author} utilized Laplace noise for semantic integrity in author anonymization, while \cite{fernandes2019generalised} balanced semantic coherence with privacy guarantees. In image privacy, \cite{chen2021perceptual} developed PI-Net, which integrates perceptual distances to obfuscate sensitive visual content. For IoT applications, \cite{liu2018epic} combined Laplace noise with linear programming to mitigate privacy risks in smart home environments.

Crowdsensing and task allocation systems have also leveraged Laplace mechanisms effectively. \cite{huang2019incentivizing} applied Laplace noise to obfuscate user locations in crowdsensing tasks, while \cite{shi2021clap} proposed contract-based mechanisms to ensure fairness in reward distribution. \cite{wang2018personalized} and \cite{To-ICDE2018} developed personalized frameworks for task allocation, optimizing privacy with Laplace-based perturbation techniques.




\section{laplace}
The Laplace mechanism is one of the most widely used data perturbation techniques, originally developed to achieve DP \cite{Dwork-TC2006}. It adds noise $x$ to the output of the query function $f(x)$, i.e., 
$\mathcal{M}(f(x)) = f(x)+x$, where $x$ is sampled from a Laplace distribution with a probability density function
$\mathrm{Lap}(x) = \frac{\epsilon}{2\Delta f} e^{-\frac{\epsilon |x|}{\Delta f}}$. Here, $\Delta f = \sup_{x, y \in \mathcal{X}} |f(x) - f(x')|$ represents the global sensitivity of $f$, which measures the maximum change in the function's output between neighboring datasets.

The Laplace mechanism can naturally adapt to various metrics by appropriately scaling the noise \cite{McSherry-FOCS2007}. Specifically, to extend Laplace for mDP, \cite{Chatzikokolakis-PETS2013} first proposed scaling the noise based on the metric $d_{\mathcal{X}}$ instead of the global sensitivity $\Delta f$, where $d_{\mathcal{X}}(s, x)$ quantifies the distinguishability between $x$ and $x$. The resulting probability density function is expressed as 
$\mathrm{Lap}(x) = \lambda(x) e^{-d_{\mathcal{X}}(s, x)}$.  Following this work, \cite{Andres-CCS2013} %first applied mDP for geo-location privacy protection by 
introducing polar Laplace noise to achieve \emph{geo-indistinguishability (Geo-Ind)}. This approach employs a two-dimensional Laplace distribution centered at the true location $x$, with a probability function given by 
$\Pr\left[\mathcal{M}(x) = y\right] = \frac{\epsilon^2}{2\pi} e^{-\epsilon d(x, y)}$.  

Following \cite{Andres-CCS2013}, many studies have applied the Laplace mechanism for Geo-Ind. \cite{chatzikokolakis2014predictive} tailored Laplace noise for synthetic route generation in smartphone applications. \cite{wang2014entropy} proposed an entropy-minimizing mechanism combining Laplace noise with system feedback control. \cite{arcolezi2021preserving} and \cite{shi2021clap} adapted Geo-Ind for emergency location sharing and incentivized crowdsensing platforms, respectively. \cite{min20213d} extended Geo-Ind to three-dimensional indoor spaces, addressing challenges in high-resolution spatial data. Similarly, \cite{min2023personalized} developed personalized 3D location privacy using distortion-based geo-perturbation techniques. \cite{yang2021blockchain} integrated blockchain with Laplace noise for secure indoor data anonymization.

Beyond basic Geo-Ind, more advanced use cases emerged in trajectory and mobility trace privacy. For mobility traces, \cite{chatzikokolakis2014predictive} generalized Geo-Ind to mobility trace privacy by incorporating predictive correlations across multiple reports. Similarly, \cite{mendes2018effect} examined update frequencies and suggested adaptive noise calibration to balance privacy and utility.

Trajectory data presented a further challenge for privacy preservation, particularly during the COVID-19 pandemic. For example, \cite{li2023accurate} proposed a Laplace-based mechanism for accurate contact tracing. Building on this, \cite{yu2023privacy} developed longitudinal Geo-Ind to protect trajectory privacy in advertising systems. Other studies, such as \cite{li2023privacy} and \cite{duarte2024privacy}, refined these approaches by applying tailored metrics and adaptive noise to trajectory publishing tasks. \cite{brauer2024time} introduced temporal perturbation strategies to obfuscate trajectories while preserving their analytical utility.

Laplace-based approaches also addressed continuous queries in real-time services. For instance, \cite{hua2017geo} and \cite{ma2018agent} refined adaptive noise techniques to optimize privacy-utility trade-offs. Similarly, \cite{huang2016eppd} developed a proximity testing framework that utilized Laplace noise to ensure privacy during frequent spatial closeness verifications.

Expanding beyond location privacy, federated learning systems have also benefited from the Laplace mechanism. In federated learning, \cite{galli2023advancing} proposed Laplace-based mechanisms for group privacy by introducing noise at the group level. \cite{galli2023group} refined these mechanisms to improve collaborative learning privacy without compromising model performance.

The theoretical foundation of the Laplace mechanism has been further developed to reinforce its utility in diverse applications. \cite{koufogiannis2015optimality} and \cite{fernandes2021laplace} demonstrated its utility-optimality for continuous query functions. \cite{elsalamouny2018optimal} derived optimal noise functions for location privacy. \cite{pankova2022interpreting} analyzed privacy-utility trade-offs for categorical and numerical attributes. \cite{min2024semantic} proposed a semantic Geo-Ind mechanism adapting noise levels based on contextual semantics.

In scenarios involving incremental and temporal data, the Laplace mechanism has been adapted to address evolving privacy challenges. \cite{Koufogiannis-JPC2017} introduced incremental data release mechanisms ensuring privacy at each stage. \cite{xiang2020linear} optimized Laplace noise for temporal queries under metric-based local differential privacy. \cite{kamalaruban2020not} developed dx-privacy combining tailored Laplace noise with selective constraints.

For time-series data, \cite{fan2018time} applied Laplace mechanisms to preserve temporal patterns while ensuring privacy. \cite{brauer2024time} further refined temporal perturbation for trajectory data.

Additionally, the Laplace mechanism has been applied across various domains, including text, image, and IoT privacy. For text data, \cite{fernandes2018author} utilized Laplace noise for semantic integrity in author anonymization. \cite{fernandes2019generalised} balanced semantic coherence with privacy guarantees. \cite{arnold2023guiding} used syntactic structures to guide noise addition.

For image privacy, \cite{chen2021perceptual} developed PI-Net, integrating perceptual distances to obfuscate sensitive content. For IoT, \cite{liu2018epic} combined Laplace noise with linear programming to address privacy risks in smart homes.

Crowdsensing applications and task allocation systems have also incorporated Laplace-based techniques to protect user privacy effectively. \cite{huang2019incentivizing} applied Laplace mechanisms to obfuscate user locations in crowdsensing. \cite{shi2021clap} proposed contract-based mechanisms ensuring fairness in reward distribution. \cite{wang2018personalized} and \cite{To-ICDE2018} developed personalized frameworks optimizing task allocation with Laplace noise.

\section*{Acknowledgments}
We acknowledge the contributions and support of our colleagues and institutions in the preparation of this survey.

\begin{table*}[h!]
\centering
\footnotesize % 调整字体大小
\begin{tabular}{p{5.1cm}|p{4.0cm}|p{6.5cm}}
\hline
References & Perturbation probability distribution $\Pr\left[\mathcal{M}(x) = y\right] $ & Description \\ \hline \hline
PETS 2013 \cite{Chatzikokolakis-PETS2013}& $\lambda e^{-\epsilon d(x, y)}$ 
& Defines a Laplace mechanism over a metric space. The mechanism outputs $x$ with probability proportional to $e^{-\epsilon d(x, y)}$, ensuring metric privacy. \\ \hline

CCS 2013 \cite{Andres-CCS2013}, PETS 2014 \cite{chatzikokolakis2014predictive}, ToDP 2016 \cite{elsalamouny2016differential}, TIFS 2017 \cite{tong2017jointly}, TIFS 2018 \cite{hua2017geo}, CVPR 2021 \cite{chen2021perceptual}, ADMA 2023 \cite{li2023privacy},ToSP 2023 \cite{yu2023balancing}& $\frac{\epsilon^2}{2\pi} e^{-\epsilon \|x - y\|_2}$ 
& Defines the Laplace mechanism for planar geo-indistinguishability, where noise is calibrated to the Euclidean distance $\|x - y\|_2$. \\ \hline

CDC 2014 \cite{wang2014entropy}, BigData 2018 \cite{To-ICDE2018}& $\left(\frac{\epsilon}{2}\right)^n e^{-\epsilon \|x - y\|_1}$
& Extends the Laplace mechanism to $n$-dimensional data. The noise follows a multivariate Laplace distribution calibrated to $\ell_1$-norm sensitivity. \\ \hline

arXiv 2015 \cite{koufogiannis2015optimality}, VLDB 2015 \cite{haney2015design}, JPC 2016 \cite{Koufogiannis-JPC2017}, & $\frac{\epsilon}{2} e^{-\epsilon |x - y|}$ 
& Demonstrates the optimality of Laplace noise under metric privacy constraints. This noise minimizes the mean squared error for $\epsilon$-Lipschitz mechanisms. \\ \hline

POST 2019 \cite{fernandes2019generalised}& $c_{\epsilon}^n e^{-\epsilon \|x - y\|_2}$, where $c_{\epsilon}^n = \frac{\epsilon^n}{(n-1)!\delta^n}$ 
& Proposes the $n$-dimensional Laplace mechanism with noise added to a vector $x \in \mathbb{R}^n$. The noise is sampled in polar coordinates, where the radius $r$ is drawn from a Gamma distribution $\text{Gam}_\delta^n(r)$ and the direction $p$ is uniformly sampled over the unit hypersphere $B^n$. \\ \hline
ESORICS 2019 \cite{kawamoto2019local}, IET Blockchain 2021 \cite{yang2021blockchain}& $\frac{\epsilon^2}{2\pi} \frac{1}{1 - (1 + \epsilon R)e^{-\epsilon R}} e^{-\epsilon d(x, y)}$ 
& Proposes the Truncated Laplace Mechanism for achieving truncated geo-indistinguishability, confining noise addition to a bounded radius $R$. \\ \hline
ESORICS 2021 \cite{fernandes2021locality}, ICISSP 2023 \cite{galli2023group}& $\frac{1}{C_{\epsilon}} e^{-\epsilon d(x, y)}$, where $C_{\epsilon} = \int_{x \in \mathcal{X}} e^{-\epsilon d(x, y)} dx$ 
& Generalizes the Laplace mechanism to arbitrary metric spaces, achieving $(\epsilon, d_{\mathcal{X}})$-privacy with applications in various domains. \\ \hline
TWC 2022 \cite{min20213d}& $A e^{-\epsilon d_3(x_1, y)}$,  where $d_3(x_1, y)$ is the Euclidean distance in $\mathbb{R}^3$ & Proposes a three-variates Laplacian mechanism centered at $x_1 \in \mathbb{R}^3$. The probability density function (PDF) of the mechanism perturbs $x_1$ to $y$ based on the Euclidean distance $d_3(x_1, y)$. In the spherical coordinate system $(r, \theta, \psi)$, the PDF is reformulated as $D_{\epsilon}(r, \theta, \psi) = \frac{1}{4\pi^2 \epsilon^3} r^2 e^{-\epsilon r}$, where $r$ represents the distance, $\theta$ is the polar angle, and $\psi$ is the azimuth angle. This adaptation simplifies noise generation and improves efficiency for location privacy applications. \\ \hline
CSUS 2024 \cite{brauer2024time} & $\lambda(y) e^{-\epsilon d(x, y)}$, where $\lambda(y) = \frac{\epsilon}{2}$ & Proposes a Laplace mechanism variant for temporal data, where the sensitive information is the timestamp $t$ at which an event occurred. The mechanism perturbs $x$ to $y$ based on the temporal distance $d(x, y) = |x - y|$. This $\epsilon$-temporal trajectory indistinguishability ensures privacy by calibrating noise to the temporal domain, with a scaling function $\lambda(y)$. \\ \hline
\end{tabular}
\caption{Summary of Laplace Mechanism \qiu{add references in the table}}
\label{tab:privacy_summary}
\end{table*}

\begin{table*}[h!]
\centering
\footnotesize % 调整字体大小

\begin{tabular}{p{3.5cm}|p{4.0cm}|p{9.5cm}}
\hline
References & Perturbation probability distribution $\Pr\left[\mathcal{M}(x) = y\right]$ & Description \\ \hline \hline
PETS 2015 \cite{chatzikokolakis2015constructing}, NDSS 2017 \cite{Yu-NDSS2017}, IJCAI 2019 \cite{fioretto2019privacy}, ToVT 2019 \cite{dong2019preserving}, TMC 2022 \cite{niu2020eclipse}& $c_x e^{-\frac{1}{2} d(x, y)}$, where $c_x = \left(\sum_{y' \in \mathcal{Y}} e^{-\frac{1}{2} d_{\mathcal{X}}(x, y')}\right)^{-1}$ & Proposes a variant of the Exponential Mechanism for arbitrary distinguishability metrics $d_{\mathcal{X}}$. The mechanism outputs $z$ with probability proportional to $e^{-\frac{1}{2} d(x, y)}$, satisfying $d_{\mathcal{X}}$-privacy. This is the earliest formulation of the Exponential Mechanism in a normalized probability form and serves as the foundation for subsequent adaptations. \\ \hline

TDSC 2019 \cite{gursoy2019secure}& $\frac{e^{-\frac{\alpha  d(x, y)}{2}}}{\sum_{y' \in \mathcal{Y}} e^{-\frac{\alpha  d(x, y')}{2}}}$ & Proposes the Exponential Mechanism for achieving $\alpha$-Condensed Local Differential Privacy (CLDP). Unlike traditional Exponential Mechanisms, this method adjusts the sensitivity to fit local privacy needs within a metric space. The normalization factor ensures probabilities sum to 1 while introducing new privacy concepts specifically tailored for local privacy. \\ 
\hline
UAI 2022 \cite{ImolaUAI2022}& $\frac{Y_y  e^{-\frac{\epsilon  d(x, y)}{2}}}{\sum_{y' \in \mathcal{Y}} Y_{y'}  e^{-\frac{\epsilon  d(x, y')}{2}}}$ & Proposes a Weighted Exponential Mechanism (ExpMech\(_Y\)) to balance the probabilities assigned to outputs by introducing positive weights $Y = (Y_1, Y_2, \dots, Y_n) \in (\mathbb{R}^+)^n$. This mechanism solves the "black hole" problem in dense metric spaces by assigning weights to outputs, achieving better utility while maintaining $\epsilon$-privacy. \\ \hline
SDM 2023 \cite{Carvalho2021TEMHU}& $\propto  \exp\left(-\frac{\epsilon}{2}  d(x, y)\right)$, if $z \in L_x$; \newline $\propto \exp\left(-\gamma + \frac{2 \ln(|\mathcal{Y}| - |L_x|)}{\epsilon}\right)$, if  $z = \perp$. & Proposes the Metric Truncated Exponential Mechanism (TEM), which adapts the Exponential Mechanism for metric-DP with truncation and Gumbel noise. The novelty lies in truncating the candidate output space to a subset $L_x = \{z \in \mathcal{Y} \mid d(x, y) \leq \gamma\}$ and handling out-of-threshold elements through a special $\perp$ element. By adding Gumbel noise, this mechanism improves utility for text-based metric-DP applications. \\ \hline

\end{tabular}
\caption{Summary of Exponential Mechanism}
\label{tab:privacy_summary_1}
\end{table*}



\begin{table*}
\scriptsize    
\centering
\begin{tabular}{|p{4.1cm}|p{3cm}|p{5cm}|p{4cm}|}
\hline
\textbf{Paper} & \textbf{Distance} & \textbf{Formula} & \textbf{Explanation} \\ \hline
PETS 2013 \cite{Chatzikokolakis-PETS2013}, PETS 2014 \cite{chatzikokolakis2014predictive}, CCS 2014 \cite{fawaz2014location} & Euclidean Distance & $d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$ & Measures the straight-line distance between two points in $n$-dimensional space. Commonly used in geo-location privacy to quantify spatial proximity. \\ \hline

CDC 2014 \cite{wang2014entropy}& Manhattan Distance & $d(x, y) = \sum_{i=1}^n |x_i - y_i|$ & Measures the distance between two points in a grid-based layout, summing absolute differences along each axis. Used in privacy scenarios where the grid structure is natural. \\ \hline

VLDB 2015 \cite{haney2015design}& Graph Distance & $d_G(x, y)$ & Defines the distance between two nodes $x$ and $y$ in a graph $G$ as the length of the shortest path connecting them. This graph is a policy graph that encodes domain-specific policies about node relationships. \\ \hline

INFOCOM 2017 \cite{wang2017local}& Categorical Distance & $d(x, y) = |x - y|$ & For ordinal categories, the distance is determined by the absolute difference between the indices of two categories. This assumes a linear ordering of the categories. \\ \hline

arXiv 2018 \cite{fernandes2018author}, CSF 2018\cite{alvim2018metric}, POST 2019 \cite{fernandes2019generalised}& Word Mover's Distance (Kantorovich distance) & $d_w(x, y) = \min_{T \geq 0} \sum_{i,j} T_{ij} C_{ij}$, subject to $\sum_j T_{ij} = \frac{1}{a} \, \forall i$, $\sum_i T_{ij} = \frac{1}{b} \, \forall j$ & Measures the cost of transforming one distribution $x$ into another $y$. $T_{ij}$ denotes how much of mass $i$ in $x$ is moved to mass $j$ in $y$, and $C_{ij}$ represents the cost of moving mass $i$ to mass $j$. \\ \hline

FOCS 2018 \cite{borgs2018revealing} & Node-Distance & $d(x, y) = \min \{ \text{number of nodes in } x \text{ to modify to obtain } y \}$ & Measures the minimum number of nodes in graph $x$ that need to be modified to transform it into graph $y$. \\ \hline

DBSec 2019 \cite{takagi2019geo}, TMC 2020\cite{Qiu-TMC2022}, ESORICS 2020 \cite{cao2020pglp}, TITS 2022 \cite{ma2022personalized}, SIGSPATIAL 2022 \cite{qiu2022trafficadaptor} & Shortest Path Distance & $d_s(x, y) = \min \{\text{length of all paths connecting } x \text{ and } y \}$ & Represents the shortest path length between nodes $x$ and $y$ in a weighted, undirected graph $(V, E)$. This distance is based on the road network and considers the minimum cumulative weight of edges connecting the two nodes. \\ \hline

ICDM 2019 \cite{Feyisetan-ICDM2019} & Hyperbolic Distance & $d(x, y) = \operatorname{arcosh}\left(1 + 2\frac{\lVert x - y \rVert^2}{(1 - \lVert x \rVert^2)(1 - \lVert y \rVert^2)}\right)$ & Defined in the Poincaré ball model of hyperbolic space, where $\lVert \cdot \rVert$ represents the Euclidean norm. \\ \hline

ESORICS 2019 \cite{kawamoto2019local}& Wasserstein Distance & $W_\infty(x, y) = \min_{\gamma \in \text{cp}(x, y)} \max_{(x', y') \in \text{supp}(\gamma)} d(x', y')$ & Measures the highest cost of transporting probability mass between two distributions $x$ and $y$. \\ \hline

arXiv 2020 \cite{xu2020differentially}, TKDE 2023 \cite{zhao2022geo} & Regularized Mahalanobis Norm & $\|x\|_{RM} = \sqrt{x^\top \{ \lambda \Sigma + (1 - \lambda) \mathbf{I}_m \}^{-1} x}$ & Defines a regularized Mahalanobis distance metric for elliptical noise calibration. \\ \hline

ICME 2020 \cite{han2020voice}, CCS 2021 \cite{weggenmann2021differential}, ESORICS 2021 \cite{fernandes2021locality}& Angular Distance & $d(x, y) = \frac{\arccos(\cos \text{similarity } \langle x, y \rangle)}{\pi}$ & Defines the angular distance between two vectors $x$ and $y$. \\ \hline

CVPR 2021 \cite{chen2021perceptual} & Perceptual Distance & $d(x, y) = \|x - y\|_2$ & Defines the perceptual distance as the Euclidean distance between two latent codes $x$ and $y$ in the latent space learned by a GAN model, capturing perceptual similarity between images. \\ \hline

SEBD 2023 \cite{boninsegna2023locality} & Fréchet Distance & $d(x, y) = \min_{T \in \mathcal{T}} \max_{(i, j) \in T} \|x_i - y_j\|$ & Defines the Fréchet distance between two curves $x$ and $y$. \\ \hline

arXiv 2024 \cite{brauer2024time} & Temporal Distance & $d(x, y) = |x - y|$ & Defines the temporal distance between two timestamps $x$ and $y$. \\ \hline
\end{tabular}
\caption{Summary of Metric Definitions in Metric Differential Privacy}
\label{tab:metric-dp-distances}
\end{table*}
}


\newpage 
%% The file named.bst is a bibliography style file for BibTeX 0.99c






\end{document}


% \subsection{Laplace Mechanism }
% \section{Key Mechanisms in Metric Differential Privacy} In this section, we explore the key mechanisms that have driven the development of mDP. These mechanisms have been adapted and extended to accommodate different distance metrics. We will examine the most prominent mechanisms, including the Laplace mechanism, the Exponential mechanism, and approaches based on linear programming, highlighting their roles in advancing mDP and their applications across various domains.

% \subsection{Laplace Mechanism}
% In mDP, the Laplace mechanism is extended to account for the distance between data points, allowing the noise added to be proportional to this distance. Below are key papers that have adapted or extended the Laplace mechanism, along with their main contributions.

% A common application of this mechanism in mDP is Geo-Ind \cite{Andres-CCS2013}, which protects location data. The Laplace mechanism is adapted to generate noise in a two-dimensional space, with the magnitude of noise scaled by the distance between locations. The two-dimensional Laplace distribution is defined as:
% \begin{equation}
% M_{\text{planar}}(r, \theta) = \frac{\epsilon^2 r}{2\pi} \exp(-\epsilon r)    
% \end{equation}
% Here, $r$ is the distance from the true location, and $\theta$ is the angle, ensuring uniform distribution around the true location with increasing noise for larger distances.

% Building upon \cite{Andres-CCS2013}, Koufogiannis et al. \cite{koufogiannis2015optimality} focused on the optimality of the Laplace mechanism in mDP. They introduced Lipschitz privacy, and proved that the Laplace mechanism minimizes mean-squared error for identity queries in both $\ell_1$ and $\ell_2$-norms, particularly for high-dimensional data like GPS traces. This work strengthens the theoretical foundation for applying the Laplace mechanism in metric spaces, complementing the earlier practical application in Geo-Ind.

% In \cite{koufogiannis2016location}, Koufogiannis et al. extended Lipschitz privacy to locally Lipschitz privacy, which adapts privacy levels based on factors such as population density. This model ensures stronger privacy in sparsely populated areas and relaxed privacy in denser areas, making it context-aware.

% Moving beyond location data, Fernandes et al. \cite{fernandes2018author} applied mDP to author obfuscation in text documents. Using Word Mover’s Distance (WMD), they showed how the Laplace mechanism can protect author identities while preserving the semantic content of documents. They adapted the Laplace mechanism to the word embedding space, where the noise is added based on the distance between word vectors.

% Alvim et al. \cite{alvim2018metric} extended mDP by introducing $d_{x}$-privacy, which incorporates Kantorovich lifting to measure the distance between probability distributions instead of individual data points. This innovation allows for more general metric spaces, improving the balance between privacy and utility in datasets like location and energy consumption data.

% Mendes et al. \cite{mendes2018effect} explored how the update frequency of location data affects privacy and utility when using the Planar Laplace mechanism. By adjusting the frequency of location updates, they demonstrated that privacy can be maintained without significantly impacting utility, especially in applications like mobility traces.

% Fan et al. \cite{fan2018time} extended the Laplace mechanism to k-dimensional space for time series data sanitization. By applying the Discrete Cosine Transform (DCT), they balanced privacy and utility in time series data, protecting against adversaries that may have knowledge of the general patterns but not specific values.

% Cunha et al. \cite{cunha2019clustering} proposed clustering Geo-Ind, which improves the original Planar Laplace mechanism by clustering nearby locations and reporting the same obfuscated point for them. This approach reduces the risk of tracking attacks in continuous location reporting scenarios while maintaining utility.

% In \cite{fernandes2019generalised}, Fernandes et al. applied mDP to text document processing to protect author identity while preserving document utility. They adapted the Laplace mechanism to the word embedding space, adding noise proportional to the semantic distances between words to balance privacy and utility.

% Feyisetan et al. \cite{Feyisetan-ICDM2019} introduced dX-privacy, an extension of mDP in hyperbolic space, which better encodes hierarchical relationships between words. They adapted the Laplace mechanism to this space to ensure stronger privacy guarantees, especially in text classification and author attribution tasks.

% Kawamoto \cite{kawamoto2019local} extended mDP by introducing extended differential privacy (XDP), which incorporates a distance metric to control privacy loss for probability distributions. The authors adapted the Laplace mechanism using the Wasserstein distance to protect user attributes in location data, and proposed the tupling mechanism to further improve the trade-off between privacy and utility.

% Xiang et al. \cite{xiang2020linear} proposed Metric-LDP, which extends local differential privacy by incorporating metrics to adjust privacy levels based on the proximity of data points. They applied the Laplace mechanism to range queries and linear counting tasks, demonstrating significant utility improvements by tuning the privacy-utility trade-off.

% Mendes et al. \cite{mendes2020impact} investigated the effect of varying location update frequencies on privacy in the Planar Laplace mechanism under the mDP framework. They demonstrated that adjusting the update frequency helps balance privacy and utility, with lower frequencies leading to reduced privacy leakage.

% Qiu and Squicciarini \cite{Qiu-TMC2022} extended Geo-Ind to vehicle-based spatial crowdsourcing, focusing on minimizing Quality of Service (QoS) loss while ensuring privacy. By incorporating vehicle movement constraints within road networks, they adapted the Laplace mechanism to consider path distances rather than Euclidean distances.

% Fernandes et al. \cite{fernandes2021locality} extended mDP to high-dimensional data using locality-sensitive hashing (LSH). They proposed a novel method that combines LSH with the Laplace mechanism to protect user data in friend-matching tasks, achieving better privacy-utility trade-offs compared to previous methods.

% Feyisetan et al. \cite{feyisetan2021private} introduced PRIVEMB, a mechanism for the private release of text embedding vectors by leveraging Lipschitz privacy (mDP). They used the Laplace mechanism after applying dimensionality reduction to protect embeddings while preserving their utility in NLP tasks.

% Fernandes et al. \cite{fernandes2021laplace} demonstrated that the Laplace mechanism achieves optimal utility for continuous queries within the framework of mDP. They compared the performance of the Laplace and Geometric mechanisms, showing that the Laplace mechanism outperforms in continuous data scenarios, particularly when using Kantorovich-Rubinstein distance.

% Galli et al. \cite{galli2023advancing} introduced a method for personalized federated learning that incorporates mDP to ensure group privacy. They applied the Laplace mechanism in Euclidean space to protect model parameters while enabling personalized training based on clusters of clients, improving both privacy and fairness.

% Brauer et al. \cite{brauer2024time} introduced a method for protecting the temporal dimension of trajectory data using the Laplace mechanism. They developed two approaches—deterministic and stochastic time shifts—to obfuscate timestamps while preserving data utility. The stochastic approach, based on mDP, adapts the Laplace mechanism to prevent re-identification attacks in dynamic environments.

