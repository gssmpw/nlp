% add significance
\begin{table*}[ht]
  
  \centering
  \resizebox{\linewidth}{!}{
  % \renewcommand{\arraystretch}{1.5} % 增加行高
  % \footnotesize % 调整字体大小为小号
  % \scriptsize
  %\setlength{\tabcolsep}{5pt} % 调整列与列之间的间距
  % \resizebox{\linewidth}{!}{
  \begin{tabular}{l|c|cc|cccccc|cc} 
    
    \hline
    % \cline{3-7}
    % & \multicolumn{4}{c|}{\textbf{Original Query}} & \textbf{Classical QE} & \multicolumn{6}{c}{\textbf{LLM-based QE}}\\
    % \multirow{2}{*}{\textbf{Model($\rightarrow$) }} & \multirow{2}{*}{\textbf{BM25}} & \multicolumn{5}{c}{\textbf{Finetuned Dense Retrievers}}\\
    % & & DPR & ANCE & Contriever & BGE & QE-LLaMA\\
    % \cline{3-7}
    \multirow{2}{*}{\textbf{Task }} & \multirow{2}{*}{\textbf{BM25}} & \multicolumn{8}{c|}{\textbf{Unsupervised Dense Retrievers}}& \multicolumn{2}{c}{\textbf{Supervised Dense Retrievers}}\\ \cline{3-12}
     &   & \textbf{coCondenser} & \textbf{Contriever}\rlap{$\text{}^{\dagger}$} & \textbf{PRF}\rlap{$\text{}^{\diamond}$} & \textbf{Q2Q} & \textbf{Q2E} & \textbf{Q2C} & \textbf{Q2D}\rlap{$\text{}^{\mathsection}$} & \textbf{LLM-QE} & \textbf{Contriever}\rlap{$\text{}^{\mathparagraph}$}  & \textbf{LLM-QE}\\
     \hline
    
    MS MARCO           & 22.8          & 16.2         & 20.55\rlap{$\text{}^{\diamond}$}         & 16.66  & 22.07          & 21.38         & 22.10         & 23.00\rlap{$\text{}^{\dagger \diamond}$}        & 25.20\rlap{$\text{}^{\dagger \diamond \mathsection}$}          & \uline{34.33}  & \textbf{34.70} \\
    Trec-COVID         & \uline{65.6}  & 40.4         & 27.45         & 27.71  & 38.76          & 48.64         & 58.81         & 57.25\rlap{$\text{}^{\dagger \diamond}$}        & 59.66\rlap{$\text{}^{\dagger \diamond}$}          & 34.16  & \textbf{68.62}\rlap{$\text{}^{\mathparagraph}$}  \\
    NFCorpus           & 32.5          & 28.9         & 31.73\rlap{$\text{}^{\diamond}$}         & 27.49  & 31.53          & 32.90         & 32.80         & 33.20\rlap{$\text{}^{\dagger \diamond}$}        & \textbf{33.61}\rlap{$\text{}^{\dagger \diamond}$} & 32.71   & \uline{33.47} \\
    NQ                 & 32.9          & 17.8         & 25.37\rlap{$\text{}^{\diamond}$}         & 20.98  & 34.80          & 29.05         & 36.82         & 38.91\rlap{$\text{}^{\dagger \diamond}$}        & \uline{43.26}\rlap{$\text{}^{\dagger \diamond \mathsection}$}  & 34.02  & \textbf{51.47}\rlap{$\text{}^{\mathparagraph}$} \\
    HotpotQA           & 60.3          & 34.0         & 48.07\rlap{$\text{}^{\diamond}$}         & 40.43  & 56.15          & 46.15         & 59.82         & 61.84\rlap{$\text{}^{\dagger \diamond}$}        & \uline{65.82}\rlap{$\text{}^{\dagger \diamond \mathsection }$}  & 58.78   & \textbf{67.44}\rlap{$\text{}^{\mathparagraph}$} \\
    FiQA               & 23.6          & 25.1         & 24.50\rlap{$\text{}^{\diamond}$}         & 19.65  & 26.69          & 25.20         & 27.23         & 27.38\rlap{$\text{}^{\dagger \diamond}$}        & \uline{30.12}\rlap{$\text{}^{\dagger \diamond \mathsection}$}  & 28.04  & \textbf{33.48}\rlap{$\text{}^{\mathparagraph}$} \\
    ArguAna            & 31.5          & 44.4         & 37.90         & 38.19  & 42.89          & 43.24         & 41.83         & 42.90\rlap{$\text{}^{\dagger \diamond}$}        & 43.06\rlap{$\text{}^{\dagger \diamond}$}          & \uline{52.70} & \textbf{52.92} \\
    Touche-2020        & \textbf{36.7} & 11.7         & 16.68\rlap{$\text{}^{\diamond}$}         & 14.26  & 12.93          & 18.01         & 23.12         & 26.33\rlap{$\text{}^{\dagger \diamond}$}        & 24.34\rlap{$\text{}^{\dagger \diamond}$}          & 10.46  & \uline{26.61}\rlap{$\text{}^{\mathparagraph}$}  \\
    CQADupStack        & 29.9          & 30.9         & 28.43\rlap{$\text{}^{\diamond \mathsection}$}         & 23.18  & 25.21          & 26.74         & 21.90         & 24.69\rlap{$\text{}^{\diamond}$}        & 27.84\rlap{$\text{}^{\diamond \mathsection}$}          & \uline{31.60}
    & \textbf{33.35}\rlap{$\text{}^{\mathparagraph}$} \\
    Quora              & 78.9          & 82.1         & \uline{83.50}\rlap{$\text{}^{\diamond \mathsection}$} & 81.43  & 81.65          & 82.28         & 80.80         & 81.53        & 82.54\rlap{$\text{}^{\diamond \mathsection}$}          & \textbf{85.53}  & 81.96          \\
    DBPedia            & 31.3          & 21.5         & 29.16\rlap{$\text{}^{\diamond}$}         & 23.43  & 32.18          & 29.13         & 34.27         & 36.10\rlap{$\text{}^{\dagger \diamond}$}        & \uline{38.20}\rlap{$\text{}^{\dagger \diamond \mathsection}$}  & \textbf{38.22}  & 37.77 \\
    Scidocs            & 15.8          & 13.6         & 14.91\rlap{$\text{}^{\diamond}$}         & 13.51  & 15.32          & 15.12         & 15.17         & 15.52\rlap{$\text{}^{\dagger \diamond}$}        & \uline{16.63}\rlap{$\text{}^{\dagger \diamond \mathsection}$}  & 15.67  & \textbf{17.27}\rlap{$\text{}^{\mathparagraph}$} \\
    FEVER              & 75.3          & 61.5         & 68.20\rlap{$\text{}^{\diamond}$}         & 58.95  & 70.07          & 66.93         & 75.36         & 78.62\rlap{$\text{}^{\dagger \diamond}$}        & \uline{82.80}\rlap{$\text{}^{\dagger \diamond \mathsection}$}  & 82.49  & \textbf{85.03}\rlap{$\text{}^{\mathparagraph}$} \\
    Climate-FEVER      & 21.4          & 16.9         & 15.50\rlap{$\text{}^{\diamond}$}         & 13.52  & 15.40          & 15.02         & 22.28         & 19.43\rlap{$\text{}^{\dagger \diamond}$}        & 21.16\rlap{$\text{}^{\dagger \diamond \mathsection}$}          & \uline{23.04}   & \textbf{23.08} \\
    Scifact            & 66.5          & 56.1         & 64.92\rlap{$\text{}^{\diamond}$}         & 60.56  & 67.05          & 66.73         & 66.35         & 66.52\rlap{$\text{}^{\diamond}$}        & \uline{67.74}\rlap{$\text{}^{\dagger \diamond}$}  & \textbf{68.64}  & 66.28          \\
    \hline
    Avg. BEIR14        & 43.0          & 34.6         & 36.88{$\text{}^{\diamond}$}         & 33.09  & 39.33          & 38.94         & 42.61         & 43.59\rlap{$\text{}^{\dagger \diamond}$}        & \uline{45.48}\rlap{$\text{}^{\dagger \diamond \mathsection}$}  & 42.59  & \textbf{48.48}\rlap{$\text{}^{\mathparagraph}$} \\
    Avg. All           & 41.7          & 33.4         & 35.79{$\text{}^{\diamond}$}         & 32.00  & 38.18          & 37.77         & 41.24         & 42.21\rlap{$\text{}^{\dagger \diamond}$}        & \uline{44.13}\rlap{$\text{}^{\dagger \diamond \mathsection}$}  & 42.04  & \textbf{47.56}\rlap{$\text{}^{\mathparagraph}$} \\
    % \hline
    Best on            & 1             & 0            & 0             & 0      & 0              & 0             & 0             & 0            & 1              & 3  
    & \textbf{10}             \\
    \hline
     
  \end{tabular}}
  \caption{Overall Performance of LLM-QE. We follow previous work~\cite{izacard2021unsupervised} and report the average performance across 14 BEIR tasks (BEIR14) and all tasks (All). \textbf{Bold} and \uline{underlined} scores indicate the best and second-best results. $\dagger$, $\diamond$, and $\mathsection$ denote significant improvements over Contriver, PRF, and Q2D in the unsupervised setting, while $\mathparagraph$ indicates a significant improvement over Contriver in the supervised setting.}
  \label{tab:overall}
\end{table*}

% \end{document}




% \begin{table*}[ht]
%   \label{tab:overall}
%   \centering
%   % \renewcommand{\arraystretch}{1.5} % 增加行高
%   % \footnotesize % 调整字体大小为小号
%   \scriptsize
%   % \setlength{\tabcolsep}{4pt} % 调整列与列之间的间距
%   % \resizebox{\linewidth}{!}{
%   \begin{tabular}{l|cccc|c|cccc|c|c} 
    
%     \hline
%     % \cline{3-7}
%     & \multicolumn{4}{c|}{\textbf{Original Query}} & \textbf{Classical QE} & \multicolumn{6}{c}{\textbf{LLM-based QE}}\\
%     % \multirow{2}{*}{\textbf{Model($\rightarrow$) }} & \multirow{2}{*}{\textbf{BM25}} & \multicolumn{5}{c}{\textbf{Finetuned Dense Retrievers}}\\
%     % & & DPR & ANCE & Contriever & BGE & QE-LLaMA\\
%     % \cline{3-7}
%     & {} & \multicolumn{9}{c}{\textbf{Unsupervised Dense Retrievers}}& \textbf{Fintuned}\\
%     {\textbf{Task }} & \textbf{BM25}  & \textbf{coCondenser} & \textbf{Contriever} & \textbf{Anchor-DR}  & \textbf{PRF} & \textbf{Q2Q} & \textbf{Q2E} & \textbf{Q2C} & \textbf{Q2D} & \textbf{LLM-QE} & \textbf{LLM-QE*}\\
%      \hline
    
%     MS MARCO           & 22.8          & 16.2         & 20.55         & \uline{26.15}  & 16.66  & 22.07          & 21.38         & 22.10         & 23.00        & & \textbf{33.08} \\
%     Trec-COVID         & 65.6          & 40.4         & 27.45         & \textbf{72.16} & 27.71  & 38.76          & 48.64         & 58.81         & 57.25        & & \uline{71.07}  \\
%     NFCorpus           & 32.5          & 28.9         & 31.73         & 30.70          & 27.49  & 31.53          & 32.90         & 32.80         & \uline{33.20}& & \textbf{33.83} \\
%     NQ                 & 32.9          & 17.8         & 25.37         & 28.83          & 20.98  & 34.80          & 29.05         & 36.82         & \uline{38.91}& & \textbf{49.38} \\
%     HotpotQA           & 60.3          & 34.0         & 48.07         & 53.81          & 40.43  & 56.15          & 46.15         & 59.82         & \uline{61.84}& & \textbf{64.34} \\
%     FiQA               & 23.6          & 25.1         & 24.50         & 23.79          & 19.65  & 26.69          & 25.20         & 27.23         & \uline{27.38}& & \textbf{34.51} \\
%     ArguAna            & 31.5          & \uline{44.4} & 37.90         & 28.39          & 38.19  & 42.89          & 43.24         & 41.83         & 42.90        & & \textbf{51.82} \\
%     Touche-2020        & \textbf{36.7} & 11.7         & 16.68         & 21.85          & 14.26  & 12.93          & 18.01         & 23.12         & 26.33        & & \uline{28.57}  \\
%     CQADupStack        & 29.9          & \uline{30.9} & 28.43         & 28.82          & 23.18  & 25.21          & 26.74         & 21.90         & 24.69        & & \textbf{32.90} \\
%     Quora              & 78.9          & 82.1         & \uline{83.50} & \textbf{85.57} & 81.43  & 81.65          & 82.28         & 80.80         & 81.53        & & 83.19          \\
%     DBPedia            & 31.3          & 21.5         & 29.16         & 34.61          & 23.43  & 32.18          & 29.13         & 34.27         & \uline{36.10}& & \textbf{37.79} \\
%     Scidocs            & \uline{15.8}  & 13.6         & 14.91         & 13.42          & 13.51  & 15.32          & 15.12         & 15.17         & 15.52        & & \textbf{17.49} \\
%     FEVER              & 75.3          & 61.5         & 68.20         & 72.15          & 58.95  & 70.07          & 66.93         & 75.36         & \uline{78.62}& & \textbf{85.49} \\
%     Climate-FEVER      & 21.4          & 16.9         & 15.50         & 18.87          & 13.52  & 15.40          & 15.02         & \uline{22.28} & 19.43        & & \textbf{23.08} \\
%     Scifact            & 66.5          & 56.1         & 64.92         & 58.84          & 60.56  & \textbf{67.05} & \uline{66.73} & 66.35         & 66.52        & & 66.63          \\
%     \hline
%     Avg. BEIR14        & 43.0          & 34.6         & 36.88         & 40.84          & 33.09  & 39.33          & 38.94         & 42.61         & \uline{43.59}& & \textbf{48.58} \\
%     Avg. All           & 41.7          & 33.4         & 35.79         & 39.86          & 32.00  & 38.18          & 37.77         & 41.24         & \uline{42.21}& & \textbf{47.54} \\
%     Best on            & 1             & 0            & 0             & 2              & 0      & 1              & 0             & 0             & 0            & & 11             \\
%     \hline
     
%   \end{tabular}
%   \caption{Overall Performance on MS MARCO and BEIR under nDCG@10. We follow previous work~\cite{izacard2021unsupervised} and report the average performance on 14 BEIR tasks (BEIR14) and MSMARCO (All). The results of ANCE, Contriever and bge-Large are evaluated using their released checkpoints. The results of other baselines are copied from their original papers. Bold and underlined scores indicate the best and second best results, respectively. ${\dagger}$, ${\ddagger}$ and ${\mathsection}$ indicate statistically significant improvements over $\text{ANCE}^{\dagger}$, $\text{Contriever}^{\ddagger}$ and $\text{bge-Large}^{\mathsection}$, respectively. }
% \end{table*}
