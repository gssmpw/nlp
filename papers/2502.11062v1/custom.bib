% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{lu2023instag,
  title={\# instag: Instruction tagging for analyzing supervised fine-tuning of large language models},
  author={Lu, Keming and Yuan, Hongyi and Yuan, Zheng and Lin, Runji and Lin, Junyang and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren},
    year={2023},
  booktitle={The Twelfth International Conference on Learning Representations}
}
@inproceedings{bhattexperimental,
    title = "An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models",
  author={Bhatt, Gantavya and Chen, Yifang and Das, Arnav M and Zhang, Jifan and Truong, Sang T and Mussmann, Stephen and Zhu, Yinglun and Bilmes, Jeffrey and Du, Simon S and Jamieson, Kevin and others},
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.findings-acl.390",
    pages = "6549--6560",
}
@article{chen2023maybe,
  title={Maybe only 0.5\% data is needed: A preliminary exploration of low training data instruction tuning},
  author={Chen, Hao and Zhang, Yiming and Zhang, Qi and Yang, Hantao and Hu, Xiaomeng and Ma, Xuetao and Yanggong, Yifan and Zhao, Junbo},
  journal={arXiv preprint arXiv:2305.09246},
  year={2023}
}
@inproceedings{xialess,
  title={LESS: Selecting Influential Data for Targeted Instruction Tuning},
    year={2024},
  author={Xia, Mengzhou and Malladi, Sadhika and Gururangan, Suchin and Arora, Sanjeev and Chen, Danqi},
  booktitle={Forty-first International Conference on Machine Learning}
}
@inproceedings{joaquin2024in2core,
  title={In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models},
  author={Joaquin, Ayrton and Wang, Bin and Liu, Zhengyuan and Muller, Philippe and Asher, Nicholas and Lim, Brian and Chen, Nancy},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={10324--10335},
  year={2024}
}
@article{zhao2024beyond,
  title={Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency},
  author={Zhao, Hanyu and Du, Li and Ju, Yiming and Wu, Chengwei and Pan, Tengfei},
  journal={arXiv preprint arXiv:2409.07045},
  year={2024}
}
@article{zhaodeciphering,
    title = "Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning",
    author = "Yang,Zhao and Li,Du and Xiao,Ding and Kai,Xiong and Zhouhao,Sun and Jun,Shi and Ting,Liu and Bing,Qin",
    journal = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.559/",
    doi = "10.18653/v1/2024.findings-acl.559",
    pages = "9386--9406",
}
@article{wu2024icons,
  title={ICONS: Influence Consensus for Vision-Language Data Selection},
  author={Wu, Xindi and Xia, Mengzhou and Shao, Rulin and Deng, Zhiwei and Koh, Pang Wei and Russakovsky, Olga},
  journal={arXiv preprint arXiv:2501.00654},
  year={2024}
}
@inproceedings{jainimproving,
  title={Improving Subgroup Robustness via Data Selection},
  year={2024},
  author={Jain, Saachi and Hamidieh, Kimia and Georgiev, Kristian and Ilyas, Andrew and Ghassemi, Marzyeh and Madry, Aleksander},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}
}
@article{zhao2024supervised,
  title={Supervised Fine-Tuning Achieve Rapid Task Adaption Via Alternating Attention Head Activation Patterns},
  author={Zhao, Yang and Du, Li and Ding, Xiao and Xiong, Kai and Liu, Ting and Qin, Bing},
  journal={arXiv preprint arXiv:2409.15820},
  year={2024}
}

@article{zhang2023instruction,
  title={Instruction tuning for large language models: A survey},
  author={Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others},
  journal={arXiv preprint arXiv:2308.10792},
  year={2023}
}

@article{chen2023maybe,
  title={Maybe only 0.5\% data is needed: A preliminary exploration of low training data instruction tuning},
  author={Chen, Hao and Zhang, Yiming and Zhang, Qi and Yang, Hantao and Hu, Xiaomeng and Ma, Xuetao and Yanggong, Yifan and Zhao, Junbo},
  journal={arXiv preprint arXiv:2305.09246},
  year={2023}
}
@article{xie2023data,
  title={Data selection for language models via importance resampling},
  author={Xie, Sang Michael and Santurkar, Shibani and Ma, Tengyu and Liang, Percy S},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={34201--34227},
  year={2023}
}
@article{hubotter2024efficiently,
  title={Efficiently learning at test-time: Active fine-tuning of llms},
  author={H{\"u}botter, Jonas and Bongni, Sascha and Hakimi, Ido and Krause, Andreas},
  journal={arXiv preprint arXiv:2410.08020},
  year={2024}
}
@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}
@article{wu2023bloomberggpt,
  title={Bloomberggpt: A large language model for finance},
  author={Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
  journal={arXiv preprint arXiv:2303.17564},
  year={2023}
}
@inproceedings{zhang2023xuanyuan,
  title={Xuanyuan 2.0: A large chinese financial chat model with hundreds of billions parameters},
  author={Zhang, Xuanyu and Yang, Qing},
  booktitle={Proceedings of the 32nd ACM international conference on information and knowledge management},
  pages={4435--4439},
  year={2023}
}

@article{zhang2024instructedit,
  title={Instructedit: Instruction-based knowledge editing for large language models},
  author={Zhang, Ningyu and Tian, Bozhong and Cheng, Siyuan and Liang, Xiaozhuan and Hu, Yi and Xue, Kouying and Gou, Yanjie and Chen, Xi and Chen, Huajun},
  journal={arXiv preprint arXiv:2402.16123},
  year={2024}
}

@article{ji2021survey,
  title={A survey on knowledge graphs: Representation, acquisition, and applications},
  author={Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={33},
  number={2},
  pages={494--514},
  year={2021},
  publisher={IEEE}
}
@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@inproceedings{longpre2023flan,
  title={The flan collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  booktitle={International Conference on Machine Learning},
  pages={22631--22648},
  year={2023},
  organization={PMLR}
}
@article{liu2024less,
  title={Less is More: Data Value Estimation for Visual Instruction Tuning},
  author={Liu, Zikang and Zhou, Kun and Zhao, Wayne Xin and Gao, Dawei and Li, Yaliang and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2403.09559},
  year={2024}
}
@article{peng2023instruction,
  title={Instruction tuning with gpt-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}
@article{wang2024survey,
  title={A Survey on Data Selection for LLM Instruction Tuning},
  author={Wang, Jiahao and Zhang, Bolin and Du, Qianlong and Zhang, Jiajun and Chu, Dianhui},
  journal={arXiv preprint arXiv:2402.05123},
  year={2024}
}
@incollection{kurita2021principal,
  title={Principal component analysis (PCA)},
  author={Kurita, Takio},
  booktitle={Computer vision: a reference guide},
  pages={1013--1016},
  year={2021},
  publisher={Springer}
}
@article{amari1993backpropagation,
  title={Backpropagation and stochastic gradient descent method},
  author={Amari, Shun-ichi},
  journal={Neurocomputing},
  volume={5},
  number={4-5},
  pages={185--196},
  year={1993},
  publisher={Elsevier}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}
@article{suzgun2022challenging,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}
@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}
@article{rein2023gpqa,
  title={Gpqa: A graduate-level google-proof q\&a benchmark},
  author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2311.12022},
  year={2023}
}
@article{cobbe2021gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}
@article{hendryckstest2021,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}
@inproceedings{johnson1984extensions,
  title={Extensions of Lipshitz mapping into Hilbert space},
  author={Johnson, William B},
  booktitle={Conference modern analysis and probability, 1984},
  pages={189--206},
  year={1984}
}
@article{park2023trak,
  title={Trak: Attributing model behavior at scale},
  author={Park, Sung Min and Georgiev, Kristian and Ilyas, Andrew and Leclerc, Guillaume and Madry, Aleksander},
  journal={arXiv preprint arXiv:2303.14186},
  year={2023}
}
@article{wang2023far,
  title={How far can camels go? exploring the state of instruction tuning on open resources},
  author={Wang, Yizhong and Ivison, Hamish and Dasigi, Pradeep and Hessel, Jack and Khot, Tushar and Chandu, Khyathi and Wadden, David and MacMillan, Kelsey and Smith, Noah A and Beltagy, Iz and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={74764--74786},
  year={2023}
}
@article{choe2024your,
  title={What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions},
  author={Choe, Sang Keun and Ahn, Hwijeen and Bae, Juhan and Zhao, Kewen and Kang, Minsoo and Chung, Youngseog and Pratapa, Adithya and Neiswanger, Willie and Strubell, Emma and Mitamura, Teruko and others},
  journal={arXiv preprint arXiv:2405.13954},
  year={2024}
}
@article{hammoudeh2024training,
  title={Training data influence analysis and estimation: A survey},
  author={Hammoudeh, Zayd and Lowd, Daniel},
  journal={Machine Learning},
  volume={113},
  number={5},
  pages={2351--2403},
  year={2024},
  publisher={Springer}
}
@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}
@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 07,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v0.4.3},
  doi          = {10.5281/zenodo.12608602},
  url          = {https://zenodo.org/records/12608602}
}
@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
  url={http://arxiv.org/abs/2403.13372}
}
@inproceedings{rajbhandari2020zero,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}
@article{hadi2023survey,
  title={A survey on large language models: Applications, challenges, limitations, and practical usage},
  author={Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  journal={Authorea Preprints},
  year={2023},
  publisher={Authorea}
}
@article{tsai2024code,
  title={Code less, align more: Efficient llm fine-tuning for code generation with data pruning},
  author={Tsai, Yun-Da and Liu, Mingjie and Ren, Haoxing},
  journal={arXiv preprint arXiv:2407.05040},
  year={2024}
}
@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}