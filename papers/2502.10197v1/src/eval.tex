\section{Experimental Evaluation} \label{sec:eval}
 
We evaluate a diverse set of LLMs on \mc across various settings.
We present our main results on reasoning models (\cref{sec:main_results}), results with code agents (\cref{sec:alternative_eval}), error analysis of common failures (\cref{sec:error_analysis}), effects of contamination (\cref{sec:contamination}), and robustness of the models to variations (\cref{sec:problem_variations}). 
For readability, we adopt shortened names for some models. You can find this and other details of the experimental setup in \cref{app:exp_details}. 



\input{src/eval4_1.tex}
\input{src/eval4_2.tex}
\input{src/eval4_3.tex}
\input{src/eval4_4.tex}
\input{src/eval4_5.tex}
