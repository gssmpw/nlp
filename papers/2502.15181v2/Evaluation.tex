\section{Evaluation}
\label{sec:eval}

We evaluate the robustness of \rpt-integrated \duckdb in this section\footnote{Our source code can be found in https://github.com/zzjjyyy/PredTransDuckDB}. We conduct the experiments on a physical machine with two $\text{Intel}^\text{\textregistered} \text{Xeon}^\text{\textregistered}$ Platinum 8474C @ 2.1GHz, 512GB DDR5 RAM, and 8TB Samsung 870 QVO SATA III 2.5" SSD. The operating system is Debian 12.5. We compare vanilla \duckdb (labeled as \duckdb) against \duckdb equipped with \rpt (labeled as \rpt) using four standard benchmarks: \tpch (SF = 100)~\cite{TPCH}, Join Order Benchmark (\job)~\cite{JOB}, \tpcds (SF = 100)~\cite{TPCDS}, and \dsb (SF = 100)~\cite{DSB}. We run the experiments under \duckdb's main-memory setting where the tables are pre-loaded and decompressed in the buffer pool. We examine the case where the base tables and intermediate results do not fit in memory in~\cref{sec:eval:on-disk}. We execute the queries using a single thread except for the multi-threaded experiments in \cref{sec:eval:multi-thread}.

\subsection{End-to-end Robustness}
\label{sec:eval:end-to-end}

In the following experiments, we modified \duckdb's optimizer to generate random join orders. For each evaluated query, we generate $N$ random \emph{left-deep} plans and $N$ random \emph{bushy} plans, where $N$ is proportional to the number of joins $m$ in that query. Specifically, we set $N = 20$ for the simplest 3-join queries and $N = 1000$ for the most complex query (i.e., Query 29 from JOB) with 17 joins, and therefore $N = 70m - 190$ for $3 \le m \le 17$. To produce a left-deep plan, we randomly pick a base table that is joinable\footnote{Has an edge in the join graph, i.e., no Cartesian product.} with the current (intermediate) table as the right-most leaf at each iteration. For bushy plans, we randomly remove two joinable tables from the candidate set (which initially contains all base tables) and insert their intermediate table back at each iteration until the set contains only one element (i.e., the final plan). 


\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.34\linewidth}
        \includegraphics[width=\linewidth]{./pic/individual-left-deep-a.pdf}
        \caption{\tpch}
        \label{fig:eval-left-deep-tpch}
    \end{subfigure}
    \begin{subfigure}{0.64\linewidth}
        \includegraphics[width=\linewidth]{./pic/individual-left-deep-b.pdf}
        \caption{\job}
        \label{fig:eval-left-deep-job}
    \end{subfigure}
    \begin{subfigure}{0.96\linewidth}
        \includegraphics[width=\linewidth]{./pic/individual-left-deep-c.pdf}
        \caption{\tpcds}
        \label{fig:eval-left-deep-tpcds}
    \end{subfigure}
    \caption{Distribution of the execution time of random left-deep plans for each query in \tpch, \job, and \tpcds \textnormal{-- Normalized by the execution time of default \duckdb. The figure is log-scaled. The box denotes 25- to 75-percentile (with the orange line as the median), while the horizontal lines denote min and max (excluding outliers). `*' indicates timeouts. Cyclic queries are in red.}}
    \label{fig:eval-left-deep}
\end{figure*}


\begin{table}[t!]
\begin{center}
    \caption{Robustness Factors for left-deep joins.}
    \begin{tabular}{p{33pt}|p{12pt}p{12pt}p{12pt}|p{12pt}p{12pt}p{13pt}|p{12pt}p{12pt}p{12pt}}
    \toprule
    \centering \robustmetric & \multicolumn{3}{|c|}{\tpch} & \multicolumn{3}{|c|}{\job} & \multicolumn{3}{|c}{\tpcds} \\
                             & Avg & Min & Max             & Avg    & Min  & Max       & Avg  & Min & Max            \\
    \midrule
    \centering \duckdb       & 2.7 & 1.2 & 9.3             & 30.4   & 1.1  & 371       & 7.2  & 1.0 & 224            \\
    \centering \textbf{\rpt} & 1.3 & 1.2 & 1.5             & 1.2    & 1.0  & 1.6       & 1.1  & 1.0 & 1.5            \\
    \bottomrule
    \end{tabular}
    \label{tab:RF-left-deep}
\end{center}
\end{table}

\begin{table}[t!]
\begin{center}
    \caption{Robustness Factors for bushy joins.}
    \begin{tabular}{p{33pt}|p{12pt}p{12pt}p{12pt}|p{12pt}p{12pt}p{13pt}|p{12pt}p{12pt}p{12pt}}
    \toprule
    \centering \robustmetric & \multicolumn{3}{|c|}{\tpch} & \multicolumn{3}{|c|}{\job} & \multicolumn{3}{|c}{\tpcds} \\
                             & Avg & Min & Max             & Avg    & Min  & Max       & Avg & Min & Max              \\
    \midrule
    \centering \duckdb         & 5.1 & 1.2 & 13.7            & 120   & 1.1  & 1747       & 35.0 & 1.0 & 1226            \\
    \centering \textbf{\rpt}          & 1.8 & 1.2 & 3.0             & 1.6   & 1.1  & 7.7        & 1.8  & 1.0 & 4.2             \\
    \bottomrule
    \end{tabular}
    \label{tab:RF-bushy}
\end{center}
\end{table}

\begin{table}[t!]
\begin{center}
    \caption{Average speedups over \duckdb (optimizer's plan)}
    \begin{tabular}{c|c|c|c|c}
    \toprule
    \centering Speedup        & \tpch          & \job               & \tpcds        & \dsb          \\
    \midrule
    \centering Bloom Join     & $1.15\times$   & $1.13\times$       & $1.05\times$  & $1.06\times$  \\
    \centering \pt            & $1.45\times$   & $1.46\times$       & $1.27\times$  & $1.18\times$  \\
    \centering \textbf{\rpt}  & $1.44\times$   & $1.46\times$       & $1.56\times$  & $1.54\times$  \\
    \bottomrule
    \end{tabular}
    \label{tab:rpt-perf}
\end{center}
\end{table}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.34\linewidth}
        \includegraphics[width=\linewidth]{./pic/individual-bushy-a.pdf}
        \caption{\tpch}
        \label{fig:eval-bushy-tpch}
    \end{subfigure}
    \begin{subfigure}{0.64\linewidth}
        \includegraphics[width=\linewidth]{./pic/individual-bushy-b.pdf}
        \caption{\job}
        \label{fig:eval-bushy-job}
    \end{subfigure}
    \caption{Distribution of the execution time of random bushy plans for each query in \tpch and \job \textnormal{-- Normalized by the execution time of default \duckdb. The figure is log-scaled. The box denotes 25- to 75-percentile (with the orange line as the median), while the horizontal lines denote min and max (excluding outliers). `*' indicates timeouts. Cyclic queries are in red.}}
    \label{fig:eval-bushy}
\end{figure*}


\subsubsection{Acyclic Queries (left-deep)}
\cref{fig:eval-left-deep} shows the distribution of the end-to-end execution time of the random left-deep plans for each query. We omit queries in \tpch with less than two joins because they are trivial in terms of join ordering. For \job queries, we present one result for each of the 33 query templates. The execution times (for the baseline and \rpt) for each query are normalized by the time $t_{opt}$ of \duckdb running its default optimizer's plan. The figure is in \emph{log scale} with the normalization line (i.e., horizontal zero) highlighted. We set the timeout to $1000 \times t_{opt}$. The `*' above a bar indicates that at least one of the random plans incurs a timeout for this query. Cyclic queries are marked by red query numbers.

We observe impressive join order robustness when using \rpt in \duckdb for \emph{all} acyclic queries. To quantify this, we define the \emph{Robustness Factor} (\robustmetric) as the ratio between the maximum and the minimum execution time. \cref{tab:RF-left-deep} presents the average, min, and max RFs for \duckdb and \rpt in each benchmark. The average RF for \duckdb with \rpt is consistently near 1 with the max (i.e., worst-case) RF = 1.473 for Query 13 in \tpcds. This is orders-of-magnitude more robust compared to the baseline. 

Additionally, applying \rpt improves the end-to-end query performance for most queries in the benchmarks (most \rpt boxes are below 0 in \cref{fig:eval-left-deep}). \cref{tab:rpt-perf} presents the average speedups of \rpt over the default \duckdb running its optimizer's plan (i.e., $t_{opt}$). We also included Bloom Join~\cite{bloomjoin} and the original \PT~\cite{yang2023PT} (\pt) as references\footnote{The execution time of each query can be found in Appendix A}. Besides robustness guarantees, applying \rpt reduces the execution time per query by $\approx1.5\times$ on average (geometric mean). Bloom join only achieves a marginal speedup over the baseline, and it does not improve join-order robustness\footnote{The full robustness results for Bloom join and \pt can be found in Appendix B}. \rpt outperforms the original \pt in \tpcds and \dsb thanks to the \texttt{\TreeStruct} algorithm. More importantly, \rpt guarantees query robustness. \cref{fig:RPTisBetter} shows selected queries from \job and \tpcds where the performance of the original \pt is sensitive to different join orders. The root cause is that the transfer schedules produced by \pt can lead to an incomplete reduction in the semi-join phase, as discussed in~\cref{sec:modeling:transfer}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{pic/RPTisBetter.pdf}
    \caption{The distribution of the execution time of \pt and \rpt with random left deep plans for the selected query in \job and \tpcds \textnormal{-- Normalized by the execution time of \rpt with the optimizer's join order. The figure is log-scaled.}}
    \label{fig:RPTisBetter}
\end{figure}

The above results are encouraging. They show that join order optimization might no longer be a critical challenge at least for acyclic queries (which are the majority) if we implement joins using \rpt. In fact, the execution time of \rpt using the optimizer's join order is within the horizontal lines (i.e., min to max excluding outliers) for \emph{every} acyclic query in \cref{fig:eval-left-deep}. Future optimizers could, therefore, become much more efficient: they can better tolerate cardinality estimation errors, and they require simpler join enumeration algorithms because a left-deep plan is already good enough. 

A few acyclic queries (13, 29, and 48) in \tpcds have slightly larger variances than the others in \cref{fig:eval-left-deep-tpcds}. Query 13 and 48 include predicates that cannot be pushed down before the tables are joined in \duckdb, e.g., ($R.a$ < 100 AND $S.b$ < 200) OR ($R.a$ > 500 AND $S.b$ > 400). It is preferable to join $R$ and $S$ earlier if the predicate is selective. Query 29 is acyclic but not $\gamma$-acyclic. According to the analysis in \cref{sec:modeling:join}, certain join orders are unsafe. Although these special cases exhibit adequate robustness with random plans, they can still benefit from the optimizer.

\subsubsection{Acyclic Queries (bushy)}
We show the distribution of the end-to-end execution time of random bushy plans in \cref{fig:eval-bushy} with the robustness factors summarized in \cref{tab:RF-bushy}. We omit results for individual queries of \tpcds in \cref{fig:eval-bushy}\footnote{They can be found in Appendix C}. When including bushy plans, \rpt exhibits similar robustness measures against random join orders as in the left-deep case, with the average RF < 1.8 and the max RF = 7.7 for Query 17e in \job. 


We notice a slight robustness degradation for a few queries (e.g., \tpch Q7 and \job 16b, 17e) when switching from left-deep to bushy plans. They share the common reason that the optimizer mistakenly placed the larger table on the build side of hash joins in the worst plans (out of random bushy plans). As shown in \cref{fig:wrong-build-side}, for example, picking the wrong build side for the top hash join alone in JOB 17e slows down the query by $37\%$. Such a mistake is unlikely in a left-deep plan because each base table (i.e., build side) is typically filtered heavily in the transfer phase of \rpt while the size of the intermediate result (i.e., probe side) increases monotonically in the join phase.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{./pic/bushy-left.pdf}
    \caption{Speed up of bushy over left-deep plans. \textnormal{-- We draw the minimum execution time of \rpt out of random left-deep/bushy plans as well as the execution time of \rpt with the optimizer's left-deep/bushy plan for each query in \tpch and \job.}}
    \label{fig:left-bushy}
\end{figure*}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{./pic/Bad-robust.pdf}
    \caption{Slowdown caused by picking the wrong build side of a hash join (JOB 17e) \textnormal{-- (a) is a random plan with the incorrect build side for the top HJ; (b) is the fixed plan with the build side and probe side flipped.}}
    \label{fig:wrong-build-side}
\end{figure}

To demonstrate the performance gain of considering bushy plans, we select the best (i.e., with minimum execution time) random left-deep plan and the best random bushy plan for each query and compare their performance in \cref{fig:left-bushy}. We also include the left-deep plan and the bushy plan produced by \duckdb's optimizer for each query (labeled as Optimizer's Left Deep and Optimizer's Bushy, respectively) as references in the figure. We observe that considering bushy plans in the join phase of \rpt only speeds up the end-to-end execution by $6\%$ and $11\%$ for \tpch and \job, respectively compared to left-deep. Most optimizer's plans are slightly slower than the best ones from our randomly generated join orders, but the relative speedups of considering bushy plans remain small ($10\%$ for \tpch and $5\%$ for \job).
The semi-join reduction carried out in the transfer phase of \rpt significantly reduces the benefit of exploring a larger plan enumeration space. Therefore, we conclude that it is unnecessary to explore bushy plans when applying \RPT because bushy plans could sacrifice robustness for modest performance improvement.


\subsubsection{Cyclic Queries}
\rpt does not provide robustness guarantees for cyclic queries, as shown by the red-labeled queries in \cref{fig:eval-left-deep} and \cref{fig:eval-bushy} (i.e., \tpch Q5, \tpcds 19, 24, 46, 64, 68, 72, and 85). Although \rpt improves the execution time in most cases, the performance gap between the best and worst plans for a cyclic query is still huge. We propose that a robust execution engine in the future should adopt a hybrid approach to handle joins: executing the cyclic part of the query using worst-case optimal joins while processing the rest with \RPT.

\subsubsection{Case Study}
We present a case study on \job 2a to better illustrate the robustness guarantees brought by \rpt. \cref{fig:case} shows the best and worst left-deep plans for the baseline and \rpt (join phase only) with the size of each base or intermediate table marked. Without \rpt, the worst join order produces $179\times$ more intermediate tuples than the best. The worst join order suffers from the ``diamond problem'' described in \cite{birler2024robust}: small input $\rightarrow$ large intermediate result $\rightarrow$ small output, thus wasting computation. In comparison, the ratio of total intermediate results between the worst and best plans reduces to $1.2\times$ with \rpt. No matter what the join order is, the size of each intermediate table is bounded by the output size (i.e., 7.8k) and is monotonically increasing as the query executes.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{./pic/CaseStudy.pdf}
    \caption{Case study on the robustness of JOB 2a \textnormal{-- We consider the reduced tables in \rpt (i.e., filtered base tables after the transfer phase) as intermediate results here.}}
    \label{fig:case}
\end{figure}

We also notice that even the best plan from the baseline must process a much larger ($\approx$$5\times$) intermediate result than any \rpt plan. This is because \rpt has a strict complexity supremacy over the baseline. \cref{fig:worst-supremacy} shows an example where query $R \Join S \Join T$ outputs nothing but any baseline plan (\NoPT) must process $N^2/2$ tuples, a quadratic explosion compared to \rpt plans. This example can be extended to create an exponential explosion as the number of tables increases. In comparison, \YannAlg guarantees that the size of $\sum$intermediate results for \rpt can be at most $n\times$ the output size, where $n$ is the number of joins.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.8\linewidth]{pic/worst-supremacy.pdf}
    \caption{An example query (with an empty output) where any \NoPT plan must process $N^2/2$ tuples.}
    \label{fig:worst-supremacy}
\end{figure}

\subsection{Robustness of \TreeStruct}
\label{sec:eval:largestroot}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.39\linewidth}
        \includegraphics[width=\linewidth]{./pic/transfer-algorithm-robustness-a.pdf}
        \caption{TPC-H}
        \label{fig:transfer-robustness-tpch}
    \end{subfigure}
    \begin{subfigure}{0.57\linewidth}
        \includegraphics[width=\linewidth]{./pic/transfer-algorithm-robustness-b.pdf}
        \caption{JOB}
        \label{fig:transfer-robustness-job}
    \end{subfigure}
    \caption{Distribution of the execution time of 50 random \TreeStruct transfer graphs for each query in \tpch and \job \textnormal{-- The box denotes 25- to 75-percentile (with the orange line as the median), while the horizontal lines denote min and max (excluding outliers).}}
    \label{fig:transfer-robustness}
\end{figure*}

We next zoom in to evaluate the robustness of the transfer phase in \rpt (i.e., the \TreeStruct algorithm). We modified \TreeStruct to generate 50 random join trees, but each of them still has the largest relation as the root. Specifically, we replaced the original \cref{step:choose} in \TreeStruct with ``Find an edge $e = \{R,S\} \in E(G_q)$ such that $R\in\mathcal R\setminus \mathcal R',S\in\mathcal R'$''. We fix the join order in each run to be the one produced by \duckdb's default optimizer. Other experiment settings follow those in \cref{sec:eval:end-to-end}.

\Cref{fig:transfer-robustness} shows the distribution of the end-to-end execution time with random \TreeStruct transfer graphs for each query in \tpch and \job. The 50 execution times for each query are normalized by the query time achieved using the unmodified \TreeStruct. We observe that the performance of the queries is robust against different transfer graphs (i.e., join trees for acyclic queries) as long as the algorithm keeps the largest relation at the root. Additionally, we notice that most boxes in \cref{fig:transfer-robustness} are above 1.0 (i.e., slower than the original \TreeStruct), indicating that the edge-picking heuristic used in \cref{step:choose} of \TreeStruct is effective in speeding up the transfer phase of \rpt.

\subsection{Robustness with Multi-Threaded Execution}
\label{sec:eval:multi-thread}

We repeat the left-deep experiments (i.e., \cref{fig:eval-left-deep}) in \cref{sec:eval:end-to-end} with 32 threads to investigate how multi-threaded execution affects the robustness of \rpt. As shown in \cref{fig:eval-32-threads}, \rpt still exhibits outstanding query robustness with orders-of-magnitude improvement over the baseline on the Robustness Factor (\robustmetric). Compared to \cref{fig:eval-left-deep}, we notice that the variance of the execution times across different left-deep plans increases for some of the queries when switching from single-threaded to multi-threaded execution. This is because some random left-deep plans placed a relatively small (reduced) table on the probe side of the long (probing) pipeline, which does not have enough data chunks to distribute across 32 parallel threads to fully utilize the computation. The problem is orthogonal to the robustness guarantees offered by \rpt.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.37\linewidth}
        \includegraphics[width=\linewidth]{./pic/tpch-left-deep-32-threads.pdf}
        \caption{\tpch (32 threads)}
        \label{fig:eval-32-threads-tpch}
    \end{subfigure}
    \begin{subfigure}{0.62\linewidth}
        \includegraphics[width=\linewidth]{./pic/job-left-deep-32-threads.pdf}
        \caption{\job (32 threads)}
        \label{fig:eval-32-threads-job}
    \end{subfigure}
    \caption{Distribution of multi-threaded execution time of random left-deep plans for each acyclic query in \tpch and \job \textnormal{-- Normalized by the execution time of default \duckdb. The figure is log-scaled. The box denotes 25- to 75-percentile (with the orange line as the median), while the horizontal lines denote min and max (excluding outliers).}}
    \label{fig:eval-32-threads}
\end{figure*}

\subsection{Performance with Data On Disk}
\label{sec:eval:on-disk}

We extend our evaluation to the case where (1) the base tables reside on disk (labeled as ``on-disk''), and (2) some intermediate results of \rpt do not fit in memory (labeled as ``+spill''). The intermediate results of \rpt refer to the materialized data chunks that contain the remaining tuples after the forward pass in the semi-join phase. We evaluate the optimizer's plan for \duckdb and \rpt for each query in \tpch and \job. For ``+spill'', we configure the available memory to be $\approx50\%$ of \rpt's peak memory usage for each query and make sure that the spilled data reside on disk. As shown in~\cref{fig:on-disk}, \rpt still archives an average (geometric mean) speedup of $1.3\times$ and $1.5\times$ over the default \duckdb for the ``on-disk'' and ``on-disk+spill'' cases, respectively. Although the backward pass in the semi-join phase of \rpt incurs repeated data accesses, the overhead is small. This is because (1) the volume of the materialized data after the forward pass is small due to the selective semi-join filters, and (2) the backward-pass scans on the materialized data are sequential.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.46\linewidth}
        \includegraphics[width=\linewidth]{./pic/TPCH-on-disk.pdf}
        \caption{\tpch}
    \end{subfigure}
    \begin{subfigure}{0.51\linewidth}
        \includegraphics[width=\linewidth]{./pic/job-on-disk.pdf}
        \caption{\job}
    \end{subfigure}
    \caption{Comparison of the execution time of \duckdb and \rpt (with optimizer's plan) for each query in \tpch and \job when the base tables reside on disk (on-disk) + the intermediate results do not fit in memory (+spill) \textnormal{-- Normalized by the execution time of default \duckdb with base tables on disk.}}
    \label{fig:on-disk}
\end{figure*}

\subsection{Performance of Bloom Filters}
\label{sec:eval:bloomfilter}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{./pic/BF-Probe.pdf}
    \caption{Microbenchmark on Bloom Probe vs. Hash Probe \textnormal{-- We fix the probe side to 1 billion entries while varying the size of the build side on the x-axis.}}
    \label{fig:bf-probe}
\end{figure}

We presented in \cref{fig:eval-left-deep} that \rpt improves the overall query performance by $\approx$$1.5\times$ besides robustness, and our performance breakdown shows that the \BF operations in the transfer phase of \rpt account for on average $28\%$, $12\%$, and $46\%$ of the total execution time in \tpch, \job, and \tpcds, respectively. In this section, we evaluate the performance gap between \BF probes and hash table probes through a microbenchmark. We create a synthetic dataset with two single-column tables. We fix the size of the probe-side table to 1 billion rows while varying the size of the build-side table. The integer values of each column are uniformly distributed between $0$ and $2^{30}$.

\cref{fig:bf-probe} reports the execution time of performing 1 billion probes on hash tables or \BFs with different sizes. We use \duckdb's vectorized hash table implementation for hash probes and our modified version of Arrow's blocked \BF for Bloom probes. The blue (red) vertical lines denote the points where the size of the hash table (\BF) exceeds L1, L2, and L3 caches. We observe that the SIMD version of Bloom probes outperforms vectorized hash probes by $2-7\times$. The performance gap grows as the size of the hash table / \BFs increases, indicating a potentially greater performance advantage of \rpt on larger datasets.