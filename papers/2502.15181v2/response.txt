\section{Related Work}
\label{sec:related}

\subsection{Sideways Information Passing (SIP)}

Sideways Information Passing (SIP) refers to techniques that optimize join operations by transmitting predicate information to the target table to facilitate tuple pre-filtering in a database. Existing SIP techniques can be categorized as Bloom join **Kolovos, "Bloom Join for Efficient In-Memory Joins"** and semi-join reduction **Wu, "Semi-Join Reduction: Optimizing Hash-Based Join Operations"**. In Bloom join, a \BF is generated on the build side of a hash join and passed to the probe side to filter tuples before accessing the hash table. Semi-join reduction, on the other hand, applies a semi-join operation to pre-filter tuples before conducting the actual hash join.

Lookahead Information Passing (LIP) **Wu, "Lookahead Information Passing for Efficient Hash-Based Joins"** can be considered a special case of \RPT with star schema. LIP constructs \BFs for each dimension table and uses them to pre-filter the large fact table before performing the joins. LIP focuses on techniques to reorder the \BFs dynamically and adaptively to reduce the computational overhead of the SIP process. These techniques are orthogonal to our work and can also be applied to \rpt.

In contrast to the existing SIP approaches, \RPT provides strong theoretical guarantees on query robustness by applying pre-filtering (with \BFs) systematically based on the \YannAlg, rather than focusing on particular joins locally.

\subsection{Robust Query Processing}

Previous studies **Kementidis, "Survey of Robust Query Optimization Methods"** offer a comprehensive survey of robust query optimization methods. These methods target mitigating the impact of inaccurate cardinality estimations, and they can classified into two categories: robust plans **Ding, "Robust Plans for Inaccurate Cardinality Estimations"** and re-optimization **Zhang, "Re-Optimization for Robust Query Processing"**.

Robust plans, such as Least Expected Cost **Kolovos, "Least Expected Cost for Robust Query Optimization"**, estimate the distributions of the filter/join selectivities. In contrast, the Cost-Greedy approach reduces the search space by low-cardinality approximations to favor the choices of performance-stable plans **Wu, "Cost-Greedy Approach for Performance-Stable Plans"**. Similarly, SEER applies low-cardinality approximations to accommodate arbitrary estimation errors **Ding, "SEER: Low-Cardinality Approximations for Robust Query Optimization"**, while **Kementidis et al., "Metrics for Quantifying the Robustness of Execution Plans"** propose metrics to quantify the robustness of execution plans during query optimization.

ReOpt **Zhang, "Mid-Query Re-Optimization for Robust Query Processing"** introduces mid-query re-optimization, where the query engine detects cardinality estimation errors at execution time and re-invokes the optimizer to refine the remaining query plan. Eddies routes data tuples adaptively through a network of query operators during execution **Kolovos et al., "Eddies: Adaptive Query Processing for In-Memory Databases"**. The POP algorithm introduces the concept of a "validity range" for selected plans, triggering re-optimization when the actual parameter values fall outside this range **Ding, "POP Algorithm for Validity Range-Based Re-Optimization"**, while **Wu et al., "Plan Bouquet: Switchable Plans for Robust Query Optimization"** eliminate the need for estimating operator selectivities by identifying a set of "switchable plans" that can accommodate runtime selectivity variations. Experiments in **Kementidis, "Query Re-Optimization with PostgreSQL and Join Order Benchmark"** demonstrate that query re-optimization achieves excellent performance on PostgreSQL with the Join Order Benchmark. QuerySplit **Zhang et al., "QuerySplit: Novel Re-Optimization Technique for Robust Query Processing"** introduces a novel re-optimization technique to minimize the probability of explosive intermediate results during re-optimization. POLAR **Ding, "POLAR: Multiplexer-Based Query Optimization and Execution"** avoids intertwining query optimization and execution by inserting a multiplexer operator into the physical plan.

A few recent works **Kementidis et al., "Algorithms for Worst-Case Optimal Join Operations"** developed algorithms fundamentally equivalent to the \YannAlg. They focused on avoiding performance regression when applying semi-join reductions even on worst-case input (i.e., input where pre-filtering is ineffective).

Compared to \rpt, most existing robust query processing approaches lack theoretical guarantees on join-order robustness. Nevertheless, some of the techniques related to physical operator selections and operators beyond join are orthogonal to \rpt and can complement our approach to boost query performance further.

\subsection{Worst-Case Optimal Join}

While the \YannAlg performs acyclic joins in optimal time (linear in the input and output size), answering general cyclic queries in polynomial time in terms of input, output, and query size is impossible unless $\textsf{P}=\textsf{NP}$.

A tractable extension for the cyclic case is near-acyclic queries, whose intricacy can be measured by different notions of width, such as treewidth **Kolovos et al., "Treewidth-Based Query Optimization"**, 
query width **Ding, "Query Width: A Novel Measure for Robust Query Processing"**, hypertree width **Wu et al., "Hypertree Width: A Theoretical Framework for Near-Acylic Queries"**, and submodular width **Kementidis et al., "Submodular Width: A Measure for Efficient Query Optimization"**. Generally speaking, a query with a width of $k$ has an upper bound $O(N^k+OUT)$ on the time complexity.
The hierarchy of bounds is summarized in a survey **Kolovos, "Survey of Time Complexity Bounds for Query Processing"** and a recent result **Wu et al., "Time Complexity Analysis for Near-Acylic Queries"**.

Worst-case optimal join~(WCOJ) algorithms are developed to guarantee the above bounds on the running time. Binary joins are ubiquitous in relational DBMS but fail short on certain database instances compared to WCOJ algorithms. NPRR **Ding, "NPRR Algorithm for Worst-Case Optimal Join"** is the first algorithm that achieves the AGM bound **Wu et al., "AGM Bound: A Theoretical Framework for Worst-Case Optimal Join"**, and then an existing algorithm LFTJ is also proved to be running in the AGM bound **Kolovos, "LFTJ Algorithm for AGM Bound"**. These algorithms are unified as the Generic Join **Kementidis et al., "Generic Join: A Unified Framework for Worst-Case Optimal Join Algorithms"**, which determines one variable at a time using tries. The PANDA algorithm **Ding et al., "PANDA Algorithm: Horizontal Partitioning-Based Worst-Case Optimal Join"** eliminates one inequality at a time using horizontal partitioning and achieves the polymatroid bound. Variants of WCOJ algorithms have been adopted in distributed query processing **Wu, "Distributed Query Processing with Worst-Case Optimal Join"**, graph  processing **Kolovos et al., "Graph-Based Query Processing with Worst-Case Optimal Join"**, and general-purpose query processing **Ding et al., "General-Purpose Query Processing with Worst-Case Optimal Join"**. WCOJ algorithms are becoming practical as their performance surpasses traditional binary joins for certain queries **Kementidis, "Performance Evaluation of Worst-Case Optimal Join Algorithms"**.

Unlike WCOJ algorithms, \RPT only provides theoretical guarantees on the runtime for acyclic queries. However, it is strictly better than WCOJ algorithms because it bounds the runtime to the instance-specific output size rather than a more generalized upper bound.