\section{Introduction}
\label{sec:intro}

A query optimizer is a critical and perhaps most difficult component to develop in a relational database management system (RDBMS). Despite decades of research and practice, modern query optimizers are still far from reliable~\cite{leis2015HowGood}. Among the many challenges, join ordering is the crown jewel of query optimization. Determining an optimal join order requires not only an efficient algorithm to search the enormous plan space but also an accurate cardinality estimation of the intermediate results. The latter is extremely difficult despite recent efforts to bring machine learning techniques to the problem~\cite{2020are_we_ready, lehmann2023IsLearned}. The reality is that the optimizers today constantly generate plans that are orders of magnitude slower than optimal~\cite{2014optimizationsolved?, 2019tutorial_robust, 2021survey_optimizer}.

Prior research on robust query processing typically approaches the problem in two ways. The first is to prefer plans with more stable performance against cardinality estimation uncertainties during query optimization~\cite{2002LEC, 2005RCE, 2007plan_diagram, 2008strict_plan_diagram}. Such a ``conservative'' plan, however, often sacrifices query performance, and there is no theoretical guarantee of the plan's robustness. Another approach (i.e., re-optimization) is to collect the true cardinalities of intermediate results and reinvoke the optimizer at query execution time to generate better (remaining) plans~\cite{1998reopt, 2000eddies, 2004pop, Perron19, 2023reopt_zhao, justen2024polar}. Nonetheless, the overhead of materializing the intermediate results at pre-defined re-optimization points often offsets the benefit of switching to a more efficient plan.

Fortunately, the seminal \YannAlg offers encouraging theoretical results~\cite{yannakakis1981YA}. The algorithm guarantees a complexity linear to the input + output size for any acyclic query regardless of its join order. The key idea is to perform a full semi-join reduction on the input relations (i.e., the semi-join phase) before joining them (i.e., the join phase) so that the remaining tuples must appear in the query's final output. Despite the appealing theoretical guarantee, \YannAlg received few adoptions because of the costly semi-join operation.

The recent \PT (PT) algorithm proposes to speed up the above semi-joins by building \BFs instead of full hash tables~\cite{yang2023PT}. The original paper focused on the impressive performance advantages of the technique with an order-of-magnitude improvement over the default query plans on a prototype system. Although \PT was inspired by the \YannAlg, it fails to inherit the strong theoretical guarantee for acyclic queries because the algorithm does not ensure a full reduction of the input relations.

In this paper, we rediscover \PT from a robustness point of view. We propose \textbf{\RPT} (\rpt) with two new algorithms on top of the original PT to guarantee join-order robustness. We first introduce the \TreeStruct algorithm, which finds a \emph{join tree} of an acyclic query by constructing a maximum spanning tree on its weighted join graph, to warrant a full reduction in the semi-join phase (aka transfer phase in \rpt). To guarantee the robustness in the join phase of \rpt, we propose the \SafeSubJoin algorithm to verify the ``safety'' of a join order (i.e., its runtime cost is at most a constant factor away from the optimal) if the query is not $\gamma$-acyclic.

We implemented the \RPT algorithm in \duckdb, a state-of-the-art in-process analytical database management system. The modifications to \duckdb were non-invasive: we introduced two new operators for building and probing \BFs and inserted an \rpt optimization step/submodule into the optimizer's workflow. Our evaluation includes the three most widely used benchmarks for analytical workloads: \tpch~\cite{TPCH}, \job~\cite{JOB}, and \tpcds~\cite{TPCDS}. We measure the \emph{join-order robustness} of a query using the performance gap between executing different random join orders. The smaller the gap, the more robust the query.

The experimental results are promising. Compared to the baseline (i.e., \duckdb without \rpt integrated), \rpt improves the robustness factor (i.e., ratio between the maximum and minimum execution time out of 200 random join orders) by orders of magnitude for acyclic queries (which accounts for $94\%$ of the queries in the benchmarks). \rpt allows most queries to have a robustness factor close to 1, and the largest performance gap between the best and worst join orders is only $2.8\times$ among all the acyclic queries in \tpch, \job, and \tpcds. We then zoomed in and verified the robustness of the \TreeStruct algorithm. Furthermore, applying \rpt improves the end-to-end execution time per query by $\approx$$1.5\times$ (geometric mean) over the baseline. We also concluded that it is not worthwhile to consider bushy plans for \rpt because they brought little performance gain compared to left-deep in our evaluation.

%The implications of our results might be fundamental to designing future query engines and optimizers.
The implications of our results could impact the design of future query engines and optimizers. With \RPT, join order optimization is no longer a critical challenge for acyclic queries because of \rpt's strong theoretical guarantee and practical efficiency. Future optimizers could limit their search space to left-deep plans (or simply pick a random join order) and become much more tolerant against cardinality estimation errors. Despite our promising results in achieving practical join order robustness, whether an instance-optimal join algorithm exists for cyclic queries remains an open problem.

We make three primary contributions in this paper. First, we propose two new algorithms (with rigorous proofs) to make \PT robust against arbitrary join orders. Second, we show that our \RPT algorithm is easy to integrate by implementing it in \duckdb, a state-of-the-art analytical system. Finally, we discover through experiments that \rpt exhibits outstanding robustness while improving the overall query performance at the same time, a big step toward solving the practical join ordering problem.


% \yxy{Here are some ideas on the storyline in the intro. \\
%  - Join ordering has been a crucial part of query optimizations since good query performance heavily rely on efficient and accurate identification of good join orders. A huge amount of prior research exists (need to cite a lot of paperse here) in this space. Yet, no perfect solution exists. \\
%  - A line of existing work targeted \textit{robust query processing}---query performance is insensitive to the join order, thereby largely eliminating the challenges imposed by join ordering. [Talk about Yannakakis and LIP and point out their limitations. I believe there are more prior works talking about robustness; cite them as well.] \\
%  - Recent work PT showed great promise in achieving robust query processing. The original paper didn't focus on robustness, and some design decisions (like small to large) sacrifice robustness. We make the following contributions\\
%    + Integrate PT into DuckDB and fully optimize its performance. \\
%    + Refine the transfer heuristics to achieve much better robustness \\
%    + Extensively evaluate [and analyze theoretically] PT over standard benchmarks like TPC-H and JOB. \\
%    + Our evaluation demonstrates that [summarize the fantastic results]
%  }


% Query optimizer is a critical component of modern relational database management systems (RDBMSs). A particularly challenging part of an optimizer is to determine the \textit{optimal join order} for a query---a bad join order can be orders-of-magnitude slower than a good join order due to very large intermediate tables~\cite{selinger1979}. In a typical optimizer, identifying a good join order requires an accurate estimation of cardinalities of intermediate tables and an efficient method to enumerate the enormous search space~\cite{chaudhuri2009rethink}. Unfortunately, all of these tasks remain extremely difficult even after decades of research~\cite{2019MSCN, 2019Naru, 2019light_ML, halford2019bayesian, 2020deepdb, zhu2020flat, 2020deep, park2020quicksel, shetiya2020astrid, yang2020neurocard, liu2021fauce, wu2021unified} and even modern optimizers constantly generate join orders that deliver bad performance~\cite{leis2015HowGood}.

% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=\linewidth]{./pic/Q8.pdf}
%     \caption{Execution time distribution with random join orders of TPC-H Q8 in NoPT and PT when considering left deep.}
%     \label{fig:Q8}
% \end{figure}

% A line of prior research has strived to eliminate the requirement of join order optimization through a notion called \textit{robust query processing}.
% % However, there is yet no consensus on a formal definition of what robustness is for.\yxy{I don't think we need to define the term "robustness"; it is a generic word that does not require a specific meaning. We just achieve a specific robustness property}
% Currently, the research on robust query processing is trying to make the query execution robust to cardinality estimation errors such that any degree of estimation error will deliver acceptable performance~\cite{2002LEC, 2007plan_diagram, 2008strict_plan_diagram, 2009BoundedImpact, 2016planbouquets, 2017SpillBound, 2018FrugalSpillBound, 1998reopt, 1999reopt_shared_nothing, 2000eddies, 2004pop, 2007pop_parallel, 2012reopt_recursive, 2023reopt_zhao}. The current robust query processing can be categorized into two kinds: one is choosing a plan that is more unlikely to be influenced by the cardinality variation. However, a performance gap between a "stable" plan and a good one can exist. Another one is to re-optimize the execution plan when an estimation error is detected during runtime. But it can result in a bad execution performance when producing a large intermediate result at the first step~\cite{2023reopt_zhao}. And we can find that the current definition of robust query processing cannot exclude the join order optimization, i.e., the performance gap between different join orders still exists.

% In this paper, we make query execution robust for any join order, which is different from the previous studies on robust query processing, significantly advancing towards the exclusion of join order optimization. To make query execution robust for any join order, \YannAlg~\cite{yannakakis1981YA} is a seminal theoretical result that allows any acyclic query to finish in $O(OUT)$ time, where $OUT$ is the size of query output.
% %\sk{We need to agree on whether we consider coefficients on $OUT$. Bad join orders can cause the algorithm to scan $OUT$ tuples at each join, so that's a factor of $n-1$, where $n$ is the number of tables. Careful implementations based on tries can eliminate this factor, but they cannot avoid another factor $\left|\text{attr}\right|$ since we need $O(\left|\text{attr}\right|)$ time to print each tuple. But then $\left|\text{attr}\right|\ge n$ and the factor of $n$ can be covered. So the exact complexity can be $n*OUT$, $\left|\text{attr}\right|*OUT$, etc., depending on the implementation.}
% \sk{Regarding query size as constant.}
% The \YannAlg achieves this goal through reorganizing and adding a series of semi-joins into the query plan, to pre-filter rows that do not contribute to the final join output. In practice, however, these semi-join operators always introduce significant performance overhead, limiting the applicability of the technique in real systems.
% % Another prominent prior work is Lookahead Information Passing (LIP)~\cite{zhu2017LIP, gaffney2022sqlite} that uses Bloom joins~\cite{bloomjoin} to improve query robustness in practical systems; the technique, however, works only for star-schema workloads and thus has limited application scenarios. 

% A line of prior research has strived to eliminate the requirement of join order optimization through a notion called \textit{robust query processing}, where the runtime of a query is robust to join orders such that any order will deliver acceptable performance~\cite{2002LEC, 2007plan_diagram, 2008strict_plan_diagram, 2009BoundedImpact, 2016planbouquets, 2017SpillBound, 2018FrugalSpillBound, 1998reopt, 1999reopt_shared_nothing, 2000eddies, 2002reopt_multi_usr, 2004pop, 2007pop_parallel, 2012reopt_recursive, 2013continuous_reopt, 2023reopt_zhao}. Among these, the Yannakakis algorithm~\cite{yannakakis1981YA} is a seminal theoretical result that allows any acyclic query to finish in \texttt{O(OUT)} time, where \texttt{OUT} is the size of query output. The Yannakakis algorithm achieves this goal through reorganizing and adding a series of semi-joins into the query plan, to pre-filter rows that do not contribute to the final join output. In practice, however, these semi-join operators always introduce significant performance overhead, limiting the applicability of the technique in real systems. Another prominent prior work is Lookahead Information Passing (LIP)~\cite{zhu2017LIP, gaffney2022sqlite} that uses Bloom joins~\cite{bloomjoin} to improve query robustness in practical systems; the technique, however, works only for star-schema workloads and thus has limited application scenarios. 

% Recently, a new multi-join query optimization technique, \PT (PT)~\cite{yang2023PT}, was proposed. At a high-level, \PT replaces the semi-joins in the \YannAlg with Bloom filters to pre-filter majority of rows that do not contribute to the final join output, and introduces minimal performance overhead due to the high efficiency of Bloom filters in contrast to semi-joins. \PT can be applied to any query types (not only star-schema workloads) and showed significant performance improvement in a research prototype DBMS called FPDB~\cite{fpdb}.Another advantage of \PT is its non-invasive nature, as it does not require altering the join order optimizer or modifying existing operator implementations. It simply introduces two bloom filter-related operations into the execution plan.

% The prior work on \PT~\cite{yang2023PT} mainly focused on analyzing its performance advantages. In this work, we make the key observation that \PT is making a big step forward towards robust query processing, which paves the way for the complete elimination of join order optimization. Intuitively, since majority of rows that do not contribute to query result are pre-filtered, the intermediate tables will be bounded in size regardless of the selected join order, such that any join order will deliver relatively good performance. 

% As an example, Figure~\ref{fig:Q8} shows the runtime of TPC-H Q8 in DuckDB with and without \PT\footnote{The detailed experimental setup can be found in \cref{sec:eval}}. For each case, we report the query runtime for 200 randomly generated left-deep join orders. When \PT is not applied (NoPT), the fastest join order is $10\times$ faster than the slowest join order. After applying \PT, not only the query execution time is reduced by $2\times$, but the variability among different join orders disappears---the fastest join order is only 1.25x faster than the slowest join order. In other words, the query is made very robust to join ordering after \PT is applied! 

% In this paper, we aim to thoroughly analyze the robustness of \PT both practically and theoretically. On the practical side, we identify two limitations in the original \PT paper~\cite{yang2023PT}. First, the transfer heuristic was from small tables to large tables. We observe that such a transfer order can sometimes lead to query plans that are not robust. We propose a different heuristic that improves the robustness of \PT and yet captures the insight behind the original small-to-large heuristic. Second, \PT was originally implemented in FPDB~\cite{fpdb}, which was built for the cloud setting but was not optimized for in-memory databases. In this work, we integrate \PT into DuckDB~\cite{duckdb}, a widely-adopted practical analytics database that is highly optimized in performance. 

% We thoroughly evaluate the robustness of \PT using TPC-H~\cite{TPCH}, Join-Order Benchmark (JOB)~\cite{JOB}, and TPC-DS~\cite{TPCDS}. We look into both left-deep and bushy join orders, and consider both cyclic and acyclic queries. On average across all the queries, \PT can speed up query execution time by $1.5\times$. More importantly, it significantly improves the robustness of all the queries, by reducing the performance variability among different left-deep join orders from $2.7\times$ to $1.2\times$ in TPC-H ($2\times$ reduction), $22\times$ to $1.3\times$ in JOB ($17\times$ reduction) and $10\times$ to $1.4\times$ in TPC-DS ($7\times$ reduction). After applying \PT, the runtime difference between the fastest and the slowest join order is merely $2\times$ for the benchmarks, demonstrating that join order may no longer be a significant issue in query optimization.


% We now summarize the contributions in this paper.
% \begin{enumerate}
%     \item We integrate and fully optimize \PT in DuckDB, a highly optimized open-source in-memory database. 
%     %\yxy{We need a paragraph somewhere to discuss the theoretical analysis of PT.}
%     % \item \yxy{say something about the theoretical analysis?}\sk{We provide initial results on the theoretical performance comparison between PT and NoPT and show that not only PT is less  than NoPT}
%     \item We enhance the original \PT algorithm with theoretical guarantees for safe join orders.
%     \item We extensively evaluate \PT in DuckDB and demonstrate that \PT reduces query execution time by $1.5\times$ and performance variability by $30\times$ in JOB, $2\times$ in TPC-H and $7\times$ TPC-DS.
% \end{enumerate}

% The paper is organized as follows. In \cref{sec:prelim}, we introduce the preliminary used in this paper. In \Cref{sec:modeling}, we provide the theoretical guarantee for the join order robustness of \PT. In \cref{sec:impl}, We describe how we integrate \PT into DuckDB. In \cref{sec:eval}, we re-evaluate \PT performance and use empirical evidence to prove that \PT can be used to reduce the impact of different join orders and greatly improve the robustness of join orders in real-world applications. In \cref{related}, We discuss the related work. In \cref{Conclusion}, we conclude our results and point out our future work. \hz{Huanchen will come back to fix the intro.}

