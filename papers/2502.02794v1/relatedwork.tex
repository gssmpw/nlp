\section{Background and Related Work}
% 개념, metamorphic, prompt engineering
\label{sec:background}

% Existing survey work~\cite{fan2023large} noted that \emph{Test Correctness}, or Oracle Problem\fixme{Oracle Problem}, is one of the challenge for not only the traditional test generation technique but also for the LLM-based software testing.


\subsection{Code-and-Documentation Inconsistency}

Code documentation refers to the descriptions of specifications and requirements of the program, or explanations of the source code, written with the purpose of improving code readability, facilitating easier maintenance, supporting collaboration among developers, and enhancing code reusability. However, it is common for documentation and source code to become out-of-sync over time, which can happen when only code is updated without the documentation or vice versa~\cite{evolutionOfCodeComments}. Analyzing the consistency between documentation and source code has traditionally been a challenging task. Some approaches have used rule-based methods to detect specific types of inconsistencies, such as issues related to locking~\cite{tan2007icomment}, interrupt-related concurrency bugs~\cite{tan2011acomment}, null value-related exceptions~\cite{tan2012tcomment}, and identifier renaming~\cite{ratol2017detecting}. Other techniques have treated the inconsistency detection problem as a text similarity problem, employing machine learning models~\cite{corazza2018coherence, panthaplackel2021deep, rabbi2020detecting}, which often requires a dedicated training step.

Recently, LLMs have shown remarkable capabilities in understanding both natural and programming languages, enabling them to be applied to tasks such as code generation from specifications~\cite{li2022competition, shin2023prompt} or document generation from source code~\cite{sun2023automatic, ahmed2023improving, shin2023prompt}. This suggests that checking the consistency between code and documentation is now becoming increasingly feasible. For example, a recent study shows that GPT-4~\cite{achiam2023gpt} can identify subtle inconsistencies between code and its documentation~\cite{li2024mutation}. However, this study does not focus directly on the problem of inconsistency detection, but rather uses it as a means of assessing the code understanding capabilities of LLMs. In comparison, we propose a novel LLM-based approach that checks the consistency between program behavior (captured by regression tests) and their specifications captured in documentation, rather than directly comparing source code and documentation. We also introduce the concept of metamorphic prompting. 

% identifying the consistency between two artifacts becoming 


% However, LLMs have limitations in the number of tokens they can accommodate, and overly complex prompts can degrade their performance. %Therefore, relying solely on source code and documentation as prompts has its limitations. Furthermore, understanding a program's behavior based on the source code is inefficient. Hence, we propose generating regression tests based on the source code to create input-output pairs and verify their consistency with the documentation.
        
% \subsection{Large Language Models}
% LLMs are a type of Artificial Intelligence (AI) model that is trained on a massive amount of text datasets, containing text from online articles, books, and even program source code. This allows them to learn patterns and semantics of language. Since its emergence around 2019, LLMs have been increasingly applied in the field of Software Engineering (SE)~\cite{fan2023large, zhang2023survey} such as code generation~\cite{li2022competition} or test generation~\cite{lemieux2023codamosa, kang2023large}.
% % One of the key tasks in LLM for SE is software test generation, and many researches already have shown promising results. For example, combining LLMs with existing test generation tools, such as EvoSuite~\cite{Evosuite}, demonstrates higher coverage than LLM-only or traditional baselines\fixme{CODAMOSA}. LLMs have also shown promise in automatically generating tests from natural language bug reports, successfully reproducing around one-third of the reported failures\fixme{LIBRO}.

% However, despite these advances and promises, LLMs are not without weaknesses. A particularly critical issue is the tendency towards \emph{hallucinations}, where models produce outputs that are plausible yet factually incorrect. To mitigate hallucination, techniques such as self-consistency~\cite{wang2022self} and Chain-of-Thought (CoT)~\cite{wei2022chain} prompting have been actively employed. Self-consistency improves the reliability of LLMs by querying the model multiple times with the same question and identifying the most consistent answer, while CoT prompting enhances the accuracy of answers by having the model break down a complex problem into a step-by-step sequence of intermediate reasoning steps, rather than just providing a final answer.
% In our work, we also leverage these techniques to make the use of LLMs more reliable and trustworthy when evaluating the consistency between the generated test oracles and program documentation. This reduces the likelihood of hallucinations or factually incorrect information being presented to users.


\subsection{Metamorphic Testing}
Metamorphic testing~\cite{segura2016survey} is a testing technique that aims to reveal faults when there is no explicit test oracle. In metamorphic testing, the correctness of a program is not based on the expected output (from oracles): rather, it is based on the relationships between different inputs and their corresponding outputs, known as Metamorphic Relations (MRs). For example, in a program that calculates the square of a number, i.e., $f(x) = x^2$, the metamorphic relation could be that the square of the negative of a number is equal to the square of the number, i.e, $a = -b \rightarrow f(a) = f(b)$. Metamorphic testing has been successfully applied to machine learning models~\cite{applis2021assessing, murphy2008properties, xie2011testing}, which are essentially untestable~\cite{Weyuker1982aa}.

In our work, we use the concept of metamorphic testing to assess the reliability of LLMs in identifying inconsistencies between program specifications and behavior. 
% Specifically, we focus on the MRs that exist between different types of assertion statements in regression tests, which capture the current program behavior.
 % The key idea is that if a program's behavior satisfies certain MRs, then an LLM's responses should also exhibit the same MRs when presented with inverted queries. 
By examining the alignment of the LLM's responses with the expected MRs, we can assess the model's reliability and consistency in comprehending the underlying relationships between the program documentation and behavior. Note that this approach can also be seen as a form of LLM self-consistency, as the LLM should produce opposite outputs for inverted queries if it is truly consistent.



% \begin{figure*}
%     \centering
%     \includegraphics[width=0.9\textwidth]{image/overview.pdf}
%     \caption{Overview of \name}
%     \label{fig:overview}
% \end{figure*}