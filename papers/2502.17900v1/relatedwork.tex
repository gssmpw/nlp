\section{Related Work}
% \label{sec: realted}

% \subsection{ECG Representation Learning}
% Recently, ECG self-supervised learning (eSSL) has shown promise in learning ECG representations from unannotated signals~\citep{lai2023practical, simclr, sangha2024biometric}. Contrastive methods such as CLOCS~\citep{clocs} and ASTCL~\citep{astcl} explore temporal and spatial invariance, while generative techniques~\citep{zhang2022maefe, sawano2022masked, stmem, jinreading} focus on masked segment reconstruction. However, both approaches often lack clinical domain knowledge and are limited to single-modality settings, restricting the quality of learned representations. 

% Multimodal learning has shown success in multiple biomedical applications~\citep{wan2023med,liu2023g2d,wu2023medklip}. However, ECG signals pose unique challenges due to their complex spatial-temporal structure, necessitating well-tailored modeling. As a result, few studies have explored multimodal ECG learning. \citep{lalam2023ecg,yu2024ecg} demonstrated the effectiveness of combining ECG and EHR data using large language models (LLMs) to rewrite textual reports. However, their work is restricted to private datasets, making reproducing and comparisons challenging. Other works such as \citep{li2023frozen,liu2023etp} explored multimodal ECG learning for zero-shot classification. However, their methods were over simplistic: They align signals with text without sufficiently capturing the distinctiveness of individual ECG leads, and rely on naive category names as prompts, which fail to capture relative patterns, leading to suboptimal performance. Their limited evaluations on small datasets also fall short of fully assessing multimodal ECG learning in real-world scenarios.
% Additionally, works such as \citep{zhao2024ecg,wan2024electrocardiogram} focus on ECG-to-text generation tasks, but their results are not publicly accessible, making reproducing and comparisons difficult.

% MERL~\citep{merl} is the first open-source study to demonstrate the potential of ECG multimodal learning in zero-shot classification and linear probing across diverse datasets. Therefore, we mainly compare our work to MERL. However, like other methods, MERL relies on all 12 ECG leads as input and cannot handle arbitrary lead combinations, limiting its applicability in real-world clinical scenarios where all 12 leads may not always be available \citep{jahrsdoerfer2005clinical,madias2003comparison,fontana2019clinical,maheshwari2014accurate}

% \subsection{Knowledge Enhanced Medical Multimodal Learning}
% Leveraging medical knowledge to improve medical multimodal learning has advanced significantly, particularly in the radiograph domain, with methods like MedKLIP, KAD, and MAVL \citep{kad,wu2023medklip,phan2024decomposing}. These approaches focus on extracting structured knowledge, such as clinical entities from free-text radiology reports, and using this information as an additional supervisory signal to guide multimodal learning. Many models mimic radiological practices or modify structures based on diagnostic routines \citep{li2019attention,huang2020dual,kad,wu2023medklip}. However, they rely heavily on well-annotated knowledge graphs, such as RadGraph \citep{delbrouck2024radgraph} and Chest ImaGenome \citep{wu2021chest}, which require substantial human annotation and are limited to the radiology domain.
% Due to the distinct nature of ECG signals compared to radiographs, the above pipelines cannot be directly adapted for ECG multimodal learning. 
% Furthermore, CVD has a clear hierarchical structure because conditions can have multiple subtypes, such as myocardial infarction, which can be further classified as inferior or anterior myocardial infarction \citep{thygesen2018fourth}. Unlike lung diseases, typically categorized by morphological or pathological patterns rather than distinct region based subtypes \citep{king2017approach}, directly using only the entity from an ECG report can lead to information loss by ignoring the superclass or subtypes.

% \subsection{Challenge in Partial Leads ECG Input}
% Currently, full 12 leads ECG data dominates publicly accessible ECG datasets \citep{mimicecg,ribeiro2020automatic,moura2023harvard}. However, in real clinical scenarios, obtaining a standard 12 leads ECG can be excessive and often requires advanced clinical knowledge, which may not always be readily available \citep{chamadiya2013textile,alizadeh2020multichannel,dai2016low}. This makes partial-lead ECG data both crucial and common for practical applications. Despite its importance, partial leads issue is often overlooked and remain unaddressed in existing ECG multimodal representation learning studies. 
% To handle partial lead inputs across various downstream tasks, in this work, we design lead-specific processing and dynamic lead masking strategies that enable our model to accept any combination of ECG leads as input.  adaptable to various clinical scenarios \citep{jahrsdoerfer2005clinical,madias2003comparison,fontana2019clinical,maheshwari2014accurate}. We evaluate our model on extensive downstream tasks with partial lead inputs, demonstrating its ability to recognize and adapt to the lead-specific nature of ECG signals.

\begin{figure*}[t!]
    \centering
    \vspace{-5pt}
    \includegraphics[width=0.95\linewidth]{figures/framework.png}
    \vspace{-8pt}
    \caption{
    Comparison between classical ECG multimodal learning and our K-MERL framework.  
\textbf{(a):} The classical approaches (e.g., MERL \citep{merl}) are suboptimal: they processes all leads in a lead-agnostic manner and naively align ECG signals directly free-text reports.  
\textbf{(b):} K-MERL introduces lead-specific processing and lead \& segment masking to capture spatial-temporal patterns unique to each lead. It also extracts cardiac-related entities from reports as structured knowledge and aligns them with ECG features to enhance multimodal learning, thereby reducing the complexity introduced by the grammatical structure of free-text reports.
    }
    \label{fig: framework}
    \vspace{-15pt}
\end{figure*}