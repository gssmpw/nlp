\section{Related works}
AI-driven artistic style transfer has grown significantly in recent years, driven by advances in deep learning and generative models. Several works have explored the capabilities, limitations, and applications of AI-generated imagery. Our work contributes with a comprehensive evaluation of multiple generative models, emphasizing their adherence to artistic style and prompt fidelity.

Early works such as Gatys et al. \cite{Gatys_neural_representation} laid the foundation for neural style transfer, introducing methods that blend content and style representations from convolutional neural networks. Subsequent research expanded on these concepts, improving efficiency and control over style application \cite{Huang_style_transfer_normalization}. More recently diffusion-based models have demonstrated superior results in high-fidelity artistic synthesis, allowing for more nuanced style adaptation. Our study build upon these advancements but diverges in its focus on evaluating multiple state-of-the-art models across diverse artistic styles and historical periods. This allows for a broader assessment of model performance. 

One major area of focus has been figuring out how to evaluate and detect AI-generated images. For instance, studies like CIFAKE by Bird and Lotfi \cite{cifake} and GenImage by Zhu et al. \cite{genimage} have worked on measuring how realistic synthetic images are and developing techniques to tell them apart form human-made art. Similarly, Li et al. \cite{AIart} explored the world of adversarial AI-generated art, shedding light on the challenges of authentication and detection. These efforts are vital for assessing the authenticity of generated works, particularly in contexts where human perception plays a critical role. 

To support this kind of research, several large scale datasets have been created.
\begin{itemize}
    \item \textbf{ArtiFact Dataset:}\cite{artifact_dataset} This is a diverse mix of real and synthetic images, covering everything from human faces to animals to landscapes, vehicles and artworks. It includes images synthesized by 25 different methods, including 13 GAN-based models and 7 diffusion models.
    \item \textbf{WildFake Dataset:}\cite{wildfake_dataset} A dataset designed to assess the generalizability of AI-generated image detection models. It contains fake images sourced from the open-source community, covering various styles and synthesis methods.
    \item \textbf{TWIGMA Dataset:}\cite{twigma_dataset} A large-scale collection of AI-generated images scraped from Twitter, from 2021 to 2023, including metadata such as tweet text, engagement metrics and associated hashtags.
\end{itemize}
While these studies focus on detecting AI-generated images we focus on examining how convincingly these images replicate human-created art. Through public perception surveys, we assess whether generated paintings can be mistaken for human artwork providing insights into the models' ability to deceive the viewer aesthetically rather than algorithmically. 

Beyond detection, generated images are increasingly used as data sources for synthetic training and research applications. The work of Yang et al. \cite{aigen}
discusses the implications of using AI-generated images for training machine learning models. They explore the potential of synthetic datasets to enhance machine learning capabilities while also addressing concerns related to biases, authenticity, and ethical challenges.

Another direction in the field is the use of diffusion models for artistic style transfer. Researchers such as Chung et al. \cite{Style_injection} and Zhang et al. \cite{Step-aware} \cite{ArtBank} have introduced training-free methods and pre-trained diffusion models specifically designed for style adaptation. These works highlight the effectiveness of modern diffusion-based architectures in achieving high-fidelity artistic synthesis while maintaining flexibility for style injection. Furthermore, the work of Png et al. \cite{FeaST} proposes a feature-guided approach that improves control over the stylistic aspects of the generated output. 

The creative applications of generative AI has also been widely discussed. Haase et al. \cite{inspiring-Haase} explore the role of generated imagery in inspiring human creativity, particularly in design workflows. Similarly Barros and Ai \cite{designing-barros} investigate the integration of text-to-image models in industrial design, while Vartiainen and Tedre \cite{craft-edu} examine their use in craft education. We complement these works by examining the limitations of generative tools in artistic fidelity, particularly their struggle with maintaining compositional balance, avoiding anachronisms, and ensuring stylistic coherence. We highlight critical shortcomings such as overuse of hyperrealism, anatomical distortions and misinterpretations of historical context, which could be key obstacles to seamless integration into professional artistic workflow.  

Furthermore, a growing body of work focuses on understanding the emergent capabilities of large language models and their application in aesthetic evaluation. Studies such as those by Wei et al. \cite{emergent} and Du et al. \cite{loss_perspective} discuss how LLMs develop new abilities, such as the preference for certain artistic styles. Wang et al. \cite{evaluation-metrics} analyze evaluation metrics for generative images, offering insights on how to assess AI-generated art both quantitatively and qualitatively. These studies can be expanded with our proposed dataset, which unlike other existing ones is a controlled dataset of synthetic artworks.