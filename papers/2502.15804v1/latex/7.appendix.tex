\appendix

\section{Value of Per-Head KV Cache Compression Methods}

Table~\ref{tab:KV_Methods} presents the performance of common KV cache compression methods on the LongBench v1 \cite{bai2024longbenchbilingualmultitaskbenchmark} dataset. We tested different KV cache compression methods on Llama-3.1-8B-Instruct with KV Cache budgets set to 128, 256, 512, 1024, and 2048. As described in Table~\ref{tab:KV_Methods}, across various KV cache budget settings, Ada-SnapKV (the optimized version of SnapKV based on Ada-KV) achieved higher average scores than other methods on multiple tasks in the Longbench v1 dataset.

\begin{table*}[htbp]
    \centering
    \renewcommand{\arraystretch}{1.1} 
    \setlength{\tabcolsep}{4pt} 
    \begin{adjustbox}{max width=\textwidth}
    \begin{tabular}{ccccccccccccccccccc}
        \toprule
        \multirow{2}{*}{Method} & 
        \multicolumn{3}{c}{Single-Doc QA} & 
        \multicolumn{3}{c}{Multi-Doc QA} & 
        \multicolumn{3}{c}{Summarization} & 
        \multicolumn{3}{c}{Few-shot Learning} & 
        \multicolumn{2}{c}{Synthetic} & 
        \multicolumn{2}{c}{Coding} & 
        \multirow{2}{*}{Ave. Score} \\
        \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-15}  \cmidrule(lr){16-17}
        & NtrQA & Qasper & MF-en & HotpotQA & 2WikiMQA & Musique & GovReport & QMSum & MultiNews & TREC & TriviaQA & SAMSum & PCount & PRe & LCC & RB-P \\
        \midrule
        \multicolumn{17}{c}{KV Budget = 128 } \\
        StreamingLLM & 13.57 & 11.48 & 24.47 & \textbf{34.25} & \textbf{25.35} & \textbf{11.31} & \textbf{20.06} & \textbf{17.39} & 17.80 & \textbf{30.50} & 50.14 & 35.33 & \textbf{3.00} & 5.50 & 15.50 & 60.25 & 23.49\\
        Pyramid & \textbf{13.91} & \textbf{13.05} & \textbf{18.71} & 27.43 & 14.36 & 6.35 & 17.93 & 17.25 & 19.52 & 21.00 & 89.09 & \textbf{38.03} & 1.11 & 5.00 & 61.93 & 57.00 & 26.35 \\
        SnapKV & 12.23 & 11.88 & 17.93 & 25.32 & 12.41 & 8.20 & 17.88 & 16.84 & 19.44 & 22.00 & 90.97 & 37.83 & 2.50 & \textbf{5.50} & 61.62 & \textbf{57.54} & 26.26 \\
        Ada-SnapKV & 13.52 & 12.79 & 18.30 & 28.94 & 14.13 & 9.35 & 19.04 & 17.26 & \textbf{19.94} & 25.00 & \textbf{91.44} & 37.96 & 1.54 & 4.00 & \textbf{63.34} & 56.39 & \textbf{27.06} \\
        \midrule
        \multicolumn{17}{c}{KV Budget = 256 } \\
        StreamingLLM & 14.25 & 12.92 & \textbf{28.75} & 31.80 & \textbf{19.19} & \textbf{11.39} & \textbf{22.86} & 17.26 & 22.73 & \textbf{44.00} & 52.80 & 38.77 & 4.00 & 9.00 & 16.11 & 59.79 & 25.35 \\
        Pyramid & 13.57 & \textbf{17.36} & 19.29 & 30.95 & 18.10 & 8.21 & 20.30 & 17.65 & 20.90 & 26.00 & 90.94 & 40.02 & 4.73 & 4.50 & 64.71 & 55.06 & 28.27 \\
        SnapKV & 14.82 & 16.32 & 18.44 & 29.53 & 14.25 & 9.26 & 20.32 & 17.56 & 21.70 & 28.50 & 91.49 & 40.15 & 4.12 & 5.00 & 64.60 & \textbf{54.78} & 28.18 \\
        Ada-SnapKV & \textbf{15.19 }& 15.97 & 20.05 & \textbf{35.08} & 16.31 & 8.32 & 21.31 & \textbf{17.99} & \textbf{22.11} & 33.00 & \textbf{91.68} &\textbf{ 41.28} & \textbf{5.93} & \textbf{5.50} & \textbf{66.14} & 54.76 & \textbf{29.41} \\
        \midrule
        \multicolumn{17}{c}{KV Budget = 512 } \\
        StreamingLLM & 14.47 & 16.86 & \textbf{34.18} & 31.88 & 18.76 & \textbf{11.80} & \textbf{26.01} & 18.20 & \textbf{25.10} & \textbf{53.00} & 60.04 & 41.23 & 4.00 & 9.50 & 19.74 & \textbf{57.87} & 27.66 \\
        Pyramid & 15.67 & 21.59 & 23.56 & 35.63 & \textbf{24.36} & 9.77 & 22.18 & 19.05 & 23.25 & 34.00 & 91.11 & 42.44 & 4.61 & \textbf{17.50} & 65.87 & 54.41 & 31.56 \\
        SnapKV & 15.22 & 22.90 & 23.41 & 33.00 & 22.54 & 8.91 & 22.63 & 18.31 & 23.50 & 35.00 & 91.39 & 41.85 & 4.50 & 15.50 & \textbf{66.79} & 53.75 & 31.20 \\
        Ada-SnapKV & \textbf{17.72} & \textbf{24.22} & 25.38 & \textbf{38.00} & 23.47 & 9.25 & 23.55 & \textbf{18.91} & 23.82 & 43.00 & \textbf{92.14} & \textbf{42.81} & \textbf{6.34} & 15.00 & 66.12 & 55.32 & \textbf{32.82} \\
        \midrule
        \multicolumn{17}{c}{KV Budget = 1024 } \\
        StreamingLLM & 13.36 & 21.55 & \textbf{41.70} & 32.80 & 22.63 & 12.88 & 28.40 & 19.36 & \textbf{25.93} & \textbf{62.00} & 75.54 & 41.76 & 2.00 & 11.00 & 22.91 & \textbf{57.05} & 30.68 \\
        Pyramid & 16.67 & 29.11 & 28.74 & 40.13 & 27.89 & 13.43 & 24.63 & 20.36 & 25.01 & 43.00 & 91.86 & 43.48 & \textbf{6.78} & 52.50 & 65.34 & 54.87 & 36.49 \\
        SnapKV & 19.57 & 31.67 & 31.52 & \textbf{42.04} & 27.89 & 12.94 & 25.31 & 19.66 & 25.12 & 48.50 & 91.37 & 42.83 & 5.99 & \textbf{56.00} & \textbf{66.56} & 53.97 & 37.56 \\
        Ada-SnapKV & \textbf{19.74} & \textbf{30.47} & 31.42 & 40.82 & \textbf{28.98} & \textbf{16.07} & \textbf{25.35} & \textbf{20.57} & 25.57 & 53.50 & \textbf{91.76} & \textbf{43.81} & 4.63 & 53.50 & 65.75 & 55.90 & \textbf{37.99} \\
        \midrule
        \multicolumn{17}{c}{KV Budget = 2048 } \\
        StreamingLLM & 16.86 & 31.83 & \textbf{48.22} & 33.59 & 29.36 & 15.74 & \textbf{30.11} & 20.89 & 26.68 & \textbf{65.50} & \textbf{92.49} & 44.12 & 5.25 & 21.00 & 39.75 & \textbf{56.66} & 36.13 \\
        Pyramid & 21.16 & 36.66 & 37.56 & 43.28 & 36.25 & \textbf{19.72} & 27.90 & 21.73 & 26.35 & 53.00 & 92.36 & \textbf{44.61} & 6.94 & \textbf{89.50} & 64.23 & 53.11 & 42.15 \\
        SnapKV & 21.24 & 39.86 & 38.21 & 45.96 & 35.36 & 21.20 & 28.68 & 21.49 & 26.50 & 58.00 & 92.36 & 44.06 & 6.31 & 88.50 & \textbf{64.26} & 53.73 & 42.86 \\
        Ada-SnapKV & \textbf{22.42} & \textbf{40.26} & 40.13 & \textbf{49.60} & \textbf{38.23} & 19.70 & 28.49 & \textbf{21.76} & \textbf{26.77} & 61.50 & 92.35 & 44.04 & \textbf{8.27 }& 85.00 & 64.11 & 54.09 & \textbf{43.55} \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{    Comparison of Common KV Cache Compression Methods.
    % All these methods were tested on the Llama-3.1-8B-Instruct using the LongBench v1 dataset, and the KV Cache budget is set to 128, 256, 512, 1024, and 2048 respectively.
    }
    \label{tab:KV_Methods}
\end{table*}

\section{Common KV Cache Compression Methods with Tensor Parallelism}

Figure~\ref{fig:KV_methods_with_TP} shows the combination of common KV cache compression methods with tensor parallelism. As can be seen from the figure, the traditional Balanced (Fair) Per-Head Compression methods result in a balanced computational load after the partitioning in tensor parallelism. In these methods, each part of the parallel computation bears a relatively equal amount of work. On the contrary, the Imbalanced (Unfair) Per-Head Compression methods lead to an unbalanced computational load.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{latex/KV_methods_with_TP.png}
    \caption{Common KV Cache Compression Methods with Tensor Parallelism}
    \label{fig:KV_methods_with_TP}
\end{figure*}
