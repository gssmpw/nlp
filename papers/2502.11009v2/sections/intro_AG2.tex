\section{Introduction}\label{sec:intro}

Differential Privacy (DP)~\cite{dwork2006calibrating} has become the de facto standard for querying sensitive databases and has been adopted by various industry and government bodies~\cite{abowd2018us,erlingsson2014rappor,ding2017collecting}. 
DP offers high utility for aggregate data releases while ensuring strong guarantees on individuals' sensitive data. 
The laudable progress in DP study, as demonstrated by multiple recent works~\cite{zhang2015private,zhang2017privbayes,kotsogiannis2019privatesql,abs-1802-06739,gupta2010differentially,ZhangXX16}, has made it approachable and useful in many common scenarios. 
A standard DP mechanism adds noise to the query output, constrained by a privacy budget that quantifies the permitted privacy leakage. Once the privacy budget is exhausted, no more queries can be answered directly using the database. 
% However, users who employ databases protected by DP cannot observe it directly or verify its quality, thus having to `blindly' rely on it. 
However, while DP ensures data privacy, it limits users' ability to directly observe or assess data quality, leaving them to rely on the data without direct validation. 

% Data quality has been thoroughly studied for databases without privacy concerns, 
% as databases that lack quality and consistency cannot be used to derive trustworthy conclusions and train reliable models. 
% A significant portion of previous work has been devoted to various integrity constraints that can capture quality issues, such as functional dependencies, conditional functional dependencies~\cite{bohannon2007conditional}, and denial constraints~\cite{ChomickiM05}, as well as various algorithms for repairing data quality issues by employing these constraints~\cite{LivshitsKR20,ChuIP13,GiladDR20,RekatsinasCIR17}. These works propose several models for changing the database to repair it, including tuple deletion~\cite{LivshitsKR20,GiladDR20} which is the most basic model for data repairing, and cell value updates~\cite{ChuIP13,RekatsinasCIR17} which is a more granular manner of changing the data. Regardless of the employed model, the goal is for the changed dataset to comply with the given constraints. 
% While these works have paved the way for improving data quality, they do not focus on the scenario where DP standards apply to the database, and in particular, where users cannot see the data or even change it. 
% While these approaches effectively repair data to meet quality standards, they do not address cases where DP must be maintained. This leaves a gap in scenarios where users need to measure inconsistency without directly accessing or modifying sensitive data. 
\common{
The utility of such sensitive data primarily depends on its quality. Therefore, organizations that build these applications spend vast amounts of money on purchasing data from private data marketplaces~\cite{liu2021dealer, DBLP:conf/infocom/SunCLH22, DBLP:journals/corr/abs-2210-08723,DBLP:journals/tdsc/XiaoLZ23}. These marketplaces build relationships and manage monetary transactions between data owners and buyers. These buyers are often organizations that want to develop applications such as machine learning models or personalized assistants. Before the buyer purchases a dataset at a specific cost, they may want to ensure the data is suitable for their use case, adhere to particular data quality constraints, and be able to profile its quality to know if the cost reflects the quality. 
% Similarly, the data owners want the best price for their datasets, which naturally creates a problem where the cost of the dataset needs to be aligned according to the amount of errors in the dataset. 
% One way to profile data by assessing its quality is by leveraging \emph{inconsistency measures}.


{\em To address such scenarios, we consider the problem of assessing the quality of databases protected by DP.} 
Such quality assessment will allow users to decide whether they can rely on the conclusions drawn from the data or whether the suggested data is suitable for them. 
To solve this problem, we must tackle several challenges. First, since DP protects the database, users can only observe noisy aggregate statistics, which can be challenging to summarize into a quality score. Second, if the number of constraints is large (e.g., if they were generated with an automatic system~\cite{BleifussKN17,DBLP:journals/pvldb/LivshitsHIK20,PenaAN21}), translating each constraint to an SQL {\tt COUNT} query and evaluating it over the database with a DP mechanism may lead to low utility since the number of queries is large, allowing for only a tiny portion of the privacy budget to be allocated to each query. }

Hence, our proposed solution employs \emph{inconsistency measures}~\cite{thimm2017compliance, parisi2019inconsistency, LivshitsKTIKR21,DBLP:conf/sum/Bertossi18,DBLP:conf/ecsqaru/GrantH13,DBLP:journals/ijar/GrantH23,LivshitsK22,LivshitsBKS20} 
% \benny{Many more - \cite{DBLP:conf/sum/Bertossi18,DBLP:conf/ecsqaru/GrantH13,DBLP:journals/ijar/GrantH23,LivshitsK22,LivshitsBKS20}}
that quantify data quality with a single number for all constraints, essentially yielding {\em a data quality score.} This approach aligns well with DP, as such measures give a single aggregated numerical value representing data quality, regardless of the given number of constraints. 
As inconsistency measures, we adopt the ones studied by \citet{LivshitsKTIKR21} following earlier work on the topic~\cite{thimm2017compliance, parisi2019inconsistency, 
DBLP:conf/sum/Bertossi18,DBLP:conf/ecsqaru/GrantH13}. 
This work discusses and studies five measures, including (1) the {\em drastic measure}, a binary indicator for whether the database contains constraint violations, the (2) \emph{maximal consistency measure}, counting the number of maximal tuple sets for which addition of a single tuple will cause a violation, the (3) {\em minimal inconsistency measure}, counting the number of minimal tuple sets that violate a constraint, 
the (4) \emph{problematic measure}, counting the number of constraint violations, the (5) \emph{minimal repair measure}, counting the minimal tuple deletions needed to achieve consistency. 
These measures apply to various inconsistency measures that have been studied in the literature of data quality management, including functional dependencies, the more general conditional functional dependencies~\cite{bohannon2007conditional}, and the more general denial constraints~\cite{ChomickiM05}.
We show that the first two measures are incompatible for computation in the DP setting (\Cref{sec:hardness}), focusing throughout the paper on the latter three. 

An approach that one may suggest to computing the inconsistency measures in a DP manner is to translate the measure into an SQL query and then compute the query using an SQL engine that respects DP~\cite{tao2020computing,dong2022r2t,kotsogiannis2019privatesql,johnson2018towards}. Specifically relevant is R2T~\cite{dong2022r2t}, the state-of-the-art DP mechanism for SPJA queries, including self-joins. Nevertheless, when considering the three measures of inconsistency we focus on, this approach has several drawbacks. One of these measures (number of problematic tuples) requires the SQL {\tt DISTINCT} operator that R2T cannot handle. In contrast, another measure (minimal repair) cannot be expressed at all in SQL, making such engines irrelevant. 

Contrasting the first approach, the approach we propose and investigate here models the violations of the integrity constraints as a \emph{conflict graph} and applies DP techniques for graph statistics. In the conflict graph, nodes are tuple identifiers, and there is an edge between a pair of tuples if this pair violates a constraint. 
Then, each inconsistency measure can be mapped to a specific graph statistic. 
Using this view of the problem allows us to leverage prior work on releasing graph statistics with DP~\cite{hay2009accurate,KasiviswanathanNRS13,day2016publishing} and develop tailored mechanisms for computing inconsistency measures with DP. 

To this end, we harness graph projection techniques from the state-of-the-art DP algorithms~\cite{day2016publishing} that truncate the graph to achieve DP. While these algorithms have proven effective in prior studies on social network graphs, they may encounter challenges with conflict graphs arising from their unique properties. To overcome this, we devise a novel optimization for choosing the truncation threshold. 
We further provide a DP mechanism for the minimal repair measure that augments the classic 2-approximation of the vertex cover algorithm~\cite{vazirani1997approximation} to restrict its sensitivity and allow effective DP guarantees with high utility. 
Our experimental study shows that our novel algorithms prove efficacious for different datasets with various conflict graph sizes and sparsity levels. 

%As mentioned, one approach is to treat each inconsistency measure as an SQL query \benny{Not sure for two of the five, e.g., repair} and answer these queries using DP SQL mechanisms~\cite{tao2020computing,dong2022r2t,kotsogiannis2019privatesql,johnson2018towards}. Queries expressing these measures require self-joins and include complex {\tt OR} conditions. However, the state-of-the-art DP mechanism for self-join queries, R2T~\cite{dong2022r2t}, only supports measures that can be expressed as SPJA queries.  Measures that require specific operators, like {\tt DISTINCT} or {\tt GROUP BY}, cannot be handled by R2T.\benny{It makes it sound like the problem is at the very low level of technicalities... nothing fundamental} Moreover, even for measures compatible with R2T, the accuracy of the results varies widely over different datasets, as shown by \Cref{ex:motivation} in the sequel. 




%We formally define the problem of computing inconsistency measures while satisfying DP and choose the measures suitable for computation with DP from those proposed in prior work~\cite{LivshitsKTIKR21} by analyzing their sensitivity and computational cost. We then devise novel DP mechanisms to estimate these measures effectively. 



\begin{table}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{DP Algorithms} & \textbf{Adult~\cite{misc_adult_2}}                  & \textbf{Flight~\cite{flight}}                 & \textbf{Stock~\cite{oleh_onyshchak_2020}}                  \\ \hline
\textbf{R2T~\cite{dong2022r2t}}           & $0.17\pm 0.01$ & $0.12\pm0.03$ & $123.19\pm 276.73$    \\ \hline
\textbf{This work}  & $0.10 \pm 0.05$ & $0.10 \pm 0.20$  & $0.07\pm 0.08$ \\ \hline
\end{tabular}
  \caption{Relative errors for a SQL approach vs our approach to compute the minimal inconsistency measure at $\epsilon=1$} \label{tab:intro_comparison}
\end{table}

Beyond handling the two inconsistency measures that R2T cannot handle, our approach provides considerable advantages even for the one R2T can handle (number of conflicts). 
%\begin{example}\label{ex:motivation}
For illustration, \Cref{tab:intro_comparison} shows the results of evaluating R2T~\cite{dong2022r2t} on three datasets with the same privacy budget of $1$ for this measure. Though R2T performed well for the Adult and Flight datasets, it reports more than 120\% relative errors for the Stock dataset with very few violations. 
On the other hand, our approach demonstrates strong performance across all three datasets.
%\end{example}


The main contributions of this paper are as follows.
First, we formulate the novel problem of computing inconsistency measurements with DP for private datasets and discuss the associated challenges, including a thorough analysis of the sensitivity of each measure.
Second, we devise several algorithms that leverage the conflict graph and algorithms for releasing graph statistics under DP to estimate the measures that we have determined are suitable. Specifically, we propose a new optimization for choosing graph truncation threshold that is tailored to conflict graphs and augment the classic vertex cover approximation algorithms to bound its sensitivity to $2$ to obtain accurate estimates of the measures. 
    % \item We demonstrate that two of five such measures are incompatible in the DP setting, while the other three can be computed by formulating the problem using conflict graphs.
    % \item We identify high sensitivity as a challenge in computing some of these measures for practical settings and propose optimizations using the integrity constraints to mitigate this challenge.
Third, we present experiments on five real-world datasets with varying sizes and densities to show that the proposed DP algorithms are efficient in practice. Our average error across these datasets is 1.3\%-67.9\% compared to the non-private measure.
%\squishend
