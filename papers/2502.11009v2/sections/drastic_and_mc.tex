\paratitle{Infeasibility of $\drastic$ and $\maxconsistency$}\label{sec:hardness}
\benny{I propose to have this short section as an ending subsection of Section 2, and try to shorten it, since the message here is rather thin.}

We note that two of the inconsistency measures, the drastic measure \drastic\ and the maximal consistency measures \maxconsistency\  are less suitable in terms of computation cost and information gain under DP. 

The drastic measure \drastic\ is a binary measure that outputs $1$ if at least one conflict exists in the dataset; otherwise, $0$. The sensitivity of this measure is $1$ as adding or removing one row from the dataset could change the measure from $0$ to $1$ or vice versa. Adding DP noise for such a binary measure renders it meaningless, as shown in Example~\ref{example:drastic}.

\begin{example}\label{example:drastic}
    Consider the running example as shown in Example~\ref{example:running_example}. The three-row dataset has no conflicts, hence the drastic measure $\drastic = 0$. However, adding one row (fourth row) that violates the others changes the measure to $1$. 
\end{example}

One way to compute the \drastic\ measure could be to consider a proxy of \drastic\ by employing a threshold-based approach that relies on \problematic\ or \mininconsistency. For example, if these measures are below a certain given number, we return $0$ and, otherwise, return $1$. A recent work~\cite{PatwaSGMR23} addresses similar problems for synthetic data generation by employing the exponential mechanism. However, since we focus on measures that are directly computable in the DP setting, we leave this intriguing subject for future work. 

% For such a binary measure with sensitivity equal to $1$, adding DP noise renders it completely meaningless. 
% \begin{proposition}\label{prop:sens_drastic}
%     The sensitivity of $\drastic$ is $1$. 
% \end{proposition}
% \proof
% Adding or removing one tuple from the dataset will affect the addition or removal of all conflicts related to it in the dataset. In the worst case, this tuple could remove all conflicts in the dataset, and the $\drastic$ could go from 1 to 0 or vice versa.\qed

% As per ~\cref{prop:sens_drastic}, the sensitivity of $\drastic$ is equal to 1, and adding DP noise renders the measure meaningless as even adding slight noise ruins the measure.
On the other hand, computing the \maxconsistency\ measure is \#P-complete problem~\cite{LivshitsBKS20}. Prior work shows that it can be calculated for selected scenarios as the maximal independent sets for a conflict graph $\graph$ if the dataset has only FDs in the constraint set $\constraintset$ and $\graph$ is $P_4$-free~\cite{KimelfeldLP20}. However, we observe that computing the maximal independent sets with DP even has high sensitivity.

\begin{proposition}~\label{prop:sens_maxconsistency}
     The sensitivity of $\maxconsistency$ is exponential in $|V|$, where $|V|$ is the number of vertices. 
\end{proposition}
\proof
The maximum number of maximal independent sets~\cite{moon1965cliques, GriggsGG88} $f(n)$ for a graph with $n$ vertices is given by :  If $n \geqq 2$, then $f(n)= \begin{cases}3^{n / 3}, & \text { if } n \equiv 0(\bmod 3) \text {; } \\ 4.3^{[n / 3]-1}, & \text { if } n \equiv 1(\bmod 3) \text {; } \\ 2.3^{[n / 3]}, & \text { if } n \equiv 2(\bmod 3) .\end{cases}$
Using the above result, we can see that adding or removing a node in the graph can affect the total number of maximal independent sets in the order of $3^{|V|}$.
\qed

As we see in Proposition~\ref{prop:sens_maxconsistency}, the sensitivity for computing $\maxconsistency$ is exponential to the number of nodes in $\graph$, and therefore, the DP estimate will have no utility. \xh{This conclusion is based on using "Laplace mechanism", but will there be other DP algorithms for that?} Due to these hardness results, we defer the $\drastic$ and $\maxconsistency$ for future work. 