\onecolumn
\begin{center}
    \LARGE{
    \textbf{Computing Inconsistency Measures Under Differential Privacy} }\\
    \normalsize{Revision Letter} \\
    \textit{\normalsize{SIGMOD'24, Paper 1355}} 
\end{center}

\newcommand{\review}[1]{{\textit {\color{gray} ``#1''}}\vspace{1mm}}


We thank the reviewers for their insightful and thoughtful comments. In response to them, we have made the following major changes:

\common{
\begin{itemize}
\item {\bf Emphasize the motivation:} We have enhanced the motivation for computing inconsistency measures under differential privacy by adding a discussion about the scenario of the private data marketplace and a use case showing how such inconsistency measures can help estimate data quality in Section~\ref{sec:intro}. Such quality estimation can help assess the suitability of the private dataset before a buyer's purchase from the data marketplace.
\item {\bf Discussions and explanations of our model and results:} We have addressed nuances about our model and results in detailed discussions and proof sketches. Our discussions include possible extensions of our model to the multiple-relation scenario and explain our propositions, utility bounds, and algorithms. In particular, we have added proof sketches for all theorems/lemmas, improved clarification about utility bound for Thereom~\ref{thm:graph_general_utility}, and added discussions on multi-table synthesis in Section~\ref{sec:future}, threshold strategy for DCs in Section~\ref{sec:dc_aware} and inadequency of $\drastic$ and $\maxconsistency$ in Section~\ref{sec:hardness}. 
\item {\bf Scalability experiments:} We have added experiments that show the behavior of our algorithms in terms of scalability, examining settings with larger datasets and an increasing number of constraints. Specifically, we add three runtime analysis experiments by the varying dataset size on the Tax~\cite{nyctaxi} dataset, the number of constraints on Flight~\cite{flight} dataset, and the graph density by changing the datasets. These experiments refer to Figure~\ref{fig:runtime} in Section~\ref{sec:experiments} and Figure~\ref{fig:time_datasets_rev} in Appendix A.4. 
\end{itemize}
}

Please find our detailed response to each reviewer's comments below. In the paper, we highlight our revisions from Reviewer 1 in \reva{green}, Reviewer 2 in \revb{pink}, Reviewer 3 in \revc{red}, and all common revisions in \common{purple}. We have shortened and modified some previous text to fit the page limit.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% REVIEWER 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{Reviewer 1}

\paragraph{Comment R1.O1} 
\review{There is no reference to a clear real-life use-case in which inconsistency measures over a private dataset should be provided to an untrusted recipient. Could you please add a reference to at least one such real-life use-case?}

\paragraph{Response}
\reva{
{\em We have added a discussion and a use-case use case in \Cref{sec:intro} to motivate private inconsistency measures using private marketplaces and show how they can gauge the dataset quality in such scenarios.} 

``The utility of sensitive data primarily depends on its quality. Therefore, organizations that build these applications spend vast amounts of money on purchasing data from private data marketplaces~\cite{liu2021dealer, DBLP:conf/infocom/SunCLH22, DBLP:journals/corr/abs-2210-08723,DBLP:journals/tdsc/XiaoLZ23}. These marketplaces build relationships and manage monetary transactions between data owners and buyers. The buyers are often organizations that want to develop applications such as machine learning models or personalized assistants. Before the buyer purchases a dataset at a specific cost, they may want to ensure the data is suitable for their use case, adhere to particular data quality constraints, and be able to profile its quality to know if the cost reflects the quality. 


To address such scenarios, we consider the problem of assessing the quality of databases protected by DP. 
Such quality assessment will allow users to decide whether they can rely on the conclusions drawn from the data or whether the suggested data is suitable for them. ''
% To solve this problem, we must tackle several challenges. First, since DP protects the database, users can only observe noisy aggregate statistics, which can be challenging to summarize into a quality score. Second, if the number of constraints is large (e.g., if they were generated with an automatic system~\cite{BleifussKN17,DBLP:journals/pvldb/LivshitsHIK20,PenaAN21}), translating each constraint to an SQL {\tt COUNT} query and evaluating it over the database with a DP mechanism may lead to low utility since the number of queries is large, allowing for only a tiny portion of the privacy budget to be allocated to each query. 
}
% \benny{The extension from yes/no to quantity is indeed an elegant extension. But it is not enough. This paper is not just an elegant mathematical exercise. We need to emphasize the importance of extending from yes/no to measuring inconsistency. A yes/no answer 
%  does not distinguish between a database that vastly violates the user-provided constraints and one that mildly violates them and, hence, can be easily fixed or used as is. Also - one can say that data on the marketplace is clean; we can then say that it may be clean w.r.t.~the provider's constraints, but now the user can provide her own constraints and inspect the database accordingly.}

\ \\
\paragraph{Comment R1.O2} \review{ In Theorem 2, the utility bound holds with a probability of at least $1-\beta$ where $\beta=1/sqrt(2)=4.113$. Hence $1-\beta=0.757$, which is not very high. What happens when the bound does not hold? Is there a smooth decrease in utility? Can there be catastrophic failures?}

\paragraph{Response}
\reva{{\em We have clarified this in a discussion below \Cref{thm:graph_general_utility}.} 

``The $\beta$ parameter in the theorem is a controllable probability parameter. According to the accuracy requirements of a user's analysis, one may set $\beta$ as any value less than this upper bound. For example, if we set $\beta=0.01$, then our theoretical analysis of Algorithm~\ref{algo:expo_mech_basic} that says the algorithm's output being close to the true answer will hold with a probability of $1-\beta = 0.99$. We also show a plot to show the trend of the utility analysis as a function of $\beta$ in Appendix A.5 in the full version~\cite{full_paper}.''}
% \benny{I don't understand this answer. Do we we control over $\beta$? If so, why do we need $\frac{1}{e^{\sqrt{2}}}$ for? What is its purpose? Also, why do you say ``in practice'' here? Is it false in theory?}}

\ \\
\paragraph{Comment R1.O3} \review{The approaches proposed seem to be limited to a single table. What happens with tuples spread in several tables related by primary/foreign keys? Does it impact the sensitivity?}

\paragraph{Response}
\reva{
{\em We have included an in-depth discussion about the types of constraints supported by our model and a mapping of the challenges stemming from the multiple-table scenario in our new future work section (\Cref{sec:future}).} 

``Our approach can be extended to multi-relational tables as long as we can create conflict graphs representing the violations. 
However, in the multi-table setting, we must consider additional constraints that require tackling several challenges. In particular, these challenges may arise when we have non-binary or non-anti-monotonic constraints. Non-binary constraints with more than two tuples participating in a constraint lead to hypergraphs, and constraints like foreign key and inclusion constraints are non-anti-monotonic. They thus cannot be represented as conflict graphs. Such constraints are out of the scope of our work and need to be considered outside of the conflict graph realm. Furthermore, in the context of differential privacy, constraints on multi-relational tables also have implications for defining neighboring datasets and sensitivity that must be carefully considered.''}



% and their implications to differential privacy}

\ \\
\paragraph{Comment R1.O4} \review{Some lemma refer the reader to the extended version for the proof. For self-containment reasons, it would be nice to include at least a sketch for each proof in order to let busy readers easily intuite the proofs.}

\reva{
% \xh{add "$\backslash$ em" for consistent style}
Following this comment, {\em we have added 
proof sketches for all theorems and lemmas presented in the paper (\Cref{thm:privacy_proof_dc_oblivious,lemma:sensitivity,lemma:sens_quality,thm:privacy_proof_dc_aware,lemma:sens_quality_2stepEM}). }
}

\paragraph{Comment R1.O5} \review{In Theorem 5 the utility guarantees seem to be a bit overlooked. Theorem 5 claims that “ Algorithm 4 […] always outputs the size of a 2-approximate vertex cover of graph”. Am I missing something or is the Laplace perturbation of the size ignored? Also, could explainations to the following claim be given: “hence has the same utility as the original 2-approximation algorithm.”. How can that be given the Laplace perturbation? }

\paragraph{Response}
\reva{
{\em We have revised the phrasing of the theorem so that the new Theorem~\ref{thm:vertex_cover_priv_util_analysis} statement is as follows: }
``Algorithm~\ref{algo:dp_vertexcover} satisfies $\epsilon$-node DP and, prior to adding noise in line 7, obtains a 2-approximation vertex cover size."}


\paragraph{Comment R1.O6} \review{Minor remark: “fails miserably”: could more respectful words be used?}

\paragraph{Response}
\reva{
% \xh{add "$\backslash$ em" for consistent style}
We replaced this term with the phrase `falls short' {\em in \Cref{sec:results}.}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% REVIEWER 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{Reviewer 2}

\paragraph{Comment R2.O1} \review{The motivation for computing inconsistency measures under differential privacy is insufficiently articulated. It would be valuable to clarify why protecting inconsistency measures with differential privacy is a critical concern, particularly in real-world applications. For instance, how does this work benefit stakeholders or practitioners in specific fields where inconsistency measurement and data privacy intersect? Without this clarity, it is challenging to understand the practical importance or potential impact of the research.}

\paragraph{Response}
\revb{
{\em We have added a discussion and a use-case in \Cref{sec:intro} to motivate private inconsistency measures using private marketplaces and show how they can gauge the dataset quality in such scenarios.} Please see the response to R1.O1 for more details.  
% The utility of such sensitive data primarily depends on its quality. Therefore, organizations that build these applications spend vast amounts of money on purchasing data from private data marketplaces~\cite{liu2021dealer, DBLP:conf/infocom/SunCLH22, DBLP:journals/corr/abs-2210-08723,DBLP:journals/tdsc/XiaoLZ23}. These marketplaces build relationships and manage monetary transactions between data owners and buyers. These buyers are often organizations that want to develop applications such as machine learning models or personalized assistants. Before the buyer purchases a dataset at a specific cost, they may want to ensure the data is suitable for their use case, adhere to particular data quality constraints, and be able to profile its quality to know if the cost reflects the quality. 
}


\paragraph{Comment R2.O2} \review{The paper’s focus on single-relation databases is quite restrictive and does not reflect the complexity of many real-world databases that consist of multiple relational tables. It would be helpful if the authors could discuss the feasibility of extending their approach to multi-relation settings, as these are more common in practical applications. If such an extension is infeasible, a discussion on the technical challenges and limitations would provide context and help readers understand the constraints of the proposed methods.}

\paragraph{Response}
\revb{
{\em We have included an in-depth discussion about the types of constraints supported by our model and a mapping of the challenges stemming from the multiple-table scenario in a new future work section (\Cref{sec:future}). }

``Our approach can be extended to multi-relational tables as long as we can create conflict graphs representing the violations. 
However, in the multi-table setting, we must consider additional constraints that require tackling several challenges. ''
% In particular, these challenges may arise when we have non-binary or non-anti-monotonic constraints. Non-binary constraints with more than two tuples participating in a constraint lead to hypergraphs, and constraints like foreign key and inclusion constraints are non-anti-monotonic. They thus cannot be represented as conflict graphs. Such constraints are out of the scope of our work and need to be considered outside of the conflict graph realm. Furthermore, in the context of differential privacy, constraints on multi-relational tables also have implications for defining neighboring datasets and sensitivity that must be carefully considered.
Please see the response to R1.O3 for more details. 
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% REVIEWER 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{Reviewer 3}

\paragraph{Comment R3.O1} \review{The optimization for computing the inconsistency measures works for Functional Dependencies, not DCs due to high sensitivity. The authors propose a fallback for dense graphs, but it seems to introduce significant noise. Developing a more robust strategy for handling DCs could improve utility and broaden the method’s applicability.}

\paragraph{Response}
\revc{
% \xh{add "$\backslash$ em" for consistent style}
{\em We have clarified and added a discussion on the importance of a more robust strategy for DCs in Section~\ref{sec:dc_aware} under the `Extension to general DCs' paragraph.}

``Despite being tailored for FDs, we show that, in practice, our approach has good performance for DCs as well. In \Cref{sec:experiments}, we show that this approach works well for the dense Adult~\cite{adult} dataset where we compute the $\problematic$ using this strategy in Figure~\ref{fig:comparing_strategies}. Developing a specific strategy for DCs is an important direction of future work.''}


% \benny{I also fail to follow the answer. We should say that the more general approach is something we develop in current and future work, and it seems to carry significant challenges that justify the separation between the graph approach (this paper) and more general approaches (future work).}


\paragraph{Comment R3.O2} \review{The discussion on the inadequacy of
I\_D and I\_MD seems somewhat flawed. Specifically for I\_MD, the fact that it is computationally hard does not justify overlooking it. It is a meaningful measure, and its release under DP remains valuable.}

% As stated in the "Inadequacy of $\drastic$ and $\maxconsistency$`` paragraph of Section 3 \ag{Reference?}, the $\maxconsistency$ measure is not only hard to compute but is hard also because of its high sensitivity. This is essentially because the $\maxconsistency$ measure requires the computation of the total number of maximal cliques which is a hard task to even approximate \sm{add citation}. We will clarify this in the next version.
\paragraph{Response}
\revc{
{\em We have clarified and emphasized the discussion on $\drastic$ and $\maxconsistency$ in the paragraph titled 'Inadequacy of $\drastic$ and $\maxconsistency$' in \Cref{sec:hardness}.}

``The \maxconsistency\ measure that computes the total number of independent sets in the conflict graph has both computational and high sensitivity issues. First, prior work~\cite{LivshitsBKS20} showed that computing \maxconsistency\ is \#P-complete and even approximating it is an NP-hard problem~\cite{DBLP:conf/ijcai/Roth93}. Even for special cases where \maxconsistency\ can be polynomially computed (when $\graph$ is $P_4$-free~\cite{KimelfeldLP20}), we show in Proposition~\ref{prop:sensitivity} that its sensitivity is exponential in the number of nodes of $\graph$. This significantly diminishes the utility of its DP estimate. Due to these challenges, we defer the study of $\drastic$ and $\maxconsistency$ to future work.''}



\paragraph{Comment R3.O3} \review{The paper doesn’t include any experiments on runtime or scalability, particularly for the graph projection approach and the exponential mechanism (EM) optimizations, which are likely the most computationally expensive. Adding this analysis with larger datasets would help show how well these methods scale to larger datasets in practical applications.}

\paragraph{Response}
\revc{

{\em We have added experiments to show the runtime for our approach as a function of dataset size and number of DCs.  
% \Cref{fig:runtime_revision} 
\Cref{fig:runtime} 
presents the runtime of our methods for each measure. Our analysis can be found in the paragraph titled `Runtime and scalability analysis' in \Cref{sec:results}. }

``We fix the privacy budget $\epsilon=1$ and run three experiments by varying the graph size, numbers of DCs, and dataset. For the first experiment, we use our largest dataset, Tax, and vary the number of nodes from $10^2$ to $10^6$. RNoise uses  $\alpha=0.005$ in the left plot and $\alpha=0.01$ in the center plot. We observe that the number of edges scales exponentially when we increase the number of nodes, and the time taken by our algorithm is proportional to the graph size. With a graph of $10^2$ nodes and $\leq 10$ edges, our algorithm takes $10^{-3}$ seconds and goes up to $4500$ seconds with $10^6$ nodes and $322$ million edges. We omit the experiment with $10^6$ nodes and $\alpha=0.01$ as the graph size for this experiment went over 30GB and was not supported by the pickle library we use to save our graph. This is not an artifact of our algorithm and can be scaled in the future using other graph libraries. 

For our second experiment, we choose a subset of $10k$ rows of the Flight dataset and vary the number of DCs to $13$ with $\alpha=0.005$. With one DC and $\alpha=0.005$, our algorithm takes approximately 5 seconds for $\mininconsistency$ and $\problematic$ and $\leq 1$ second for $\repair$, and goes up to $25$ seconds and $5$ seconds, respectively, for $\alpha=0.065$ and 13 DCs. We also notice some dips in the trend line (e.g., at 10 and 13 constraints) because the exponential mechanism chooses larger thresholds at those points, and the edge addition algorithm takes slightly longer with chosen thresholds. 

In our third experiment, we do a runtime analysis by varying the dataset and show the result in  Figure~\ref{fig:time_datasets_rev}. We fix the total number of nodes to 10k and noise to RNoise at $\alpha=0.001$ and vary the dataset. The x-axis is ordered according to the density of the dataset. We observe that the runtime is proportional to the density of the dataset and increases exponentially with the total number of edges in the graph. As the results are similar, we defer this experiment to Appendix A.4 in the full version~\cite{full_paper} due to space constraints.''
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{images/runtime/time_datasets.png}
    \caption{\revc{Runtime analysis for all measures by varying datasets.}}
    \label{fig:time_datasets_rev}
\end{figure} 
}
% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{images/runtime/combined_plot.png}
%     % \includegraphics[width=.32\linewidth]{images/runtime/time_0.5.png}
%     % \includegraphics[width=.32\linewidth]{images/runtime/time_1.0.png}
%     % \includegraphics[width=.32\linewidth]{images/runtime/time_flight.png}
%     \includegraphics[width=0.4\linewidth]{images/runtime/legend_time.png}
%     \caption{\revc{Runtime analysis for all measures. Varying graph size on Tax dataset with RNoise $\alpha=0.005$ (left) and $\alpha=0.01$ (center) and varying \#DCs for Flight dataset (right). $\mininconsistency$ and $\problematic$ plots have y-axis in the log scale.}}
%     \label{fig:runtime_revision}
%     % Comparing different baselines at varying privacy budget.
% \end{figure}
 
%\newpage 

\setcounter{page}{1}