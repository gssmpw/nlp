\section{DP Graph Projection for $\mininconsistency$ and $\problematic$}\label{sec:graph-algorithms-graphproj}


Computing graph statistics such as edge count and degree distribution while preserving node-differential privacy (node-DP) is a well-explored area~\cite{day2016publishing, KasiviswanathanNRS13, blocki2013differentially}. 
Hence, in this section, we leverage the state-of-the-art node-DP approach for graph statistics to analyze the inconsistency measures $\mininconsistency$ and $\problematic$ as graph statistics on the conflict graph $\graph$. However, the effectiveness of this approach hinges on carefully chosen parameters.  We introduce two optimization techniques that consider the integrity constraints to optimize parameter selection and enhance the algorithm's utility.

%We begin by outlining the algorithms for the minimum inconsistency measure $\mininconsistency$ (i.e., the number of edges in $\graph$). Subsequently, we discuss the necessary modifications to adapt these algorithms for the problematic measure $\problematic$ (i.e., the number of nodes with positive degrees).


%In this section, we present how to differentially privately compute the minimum inconsistency measure $\mininconsistency$ using the conflict graph $\graph$ instead of the original database $D$.  We will begin by outlining a general differentially private algorithm that uses graph projection techniques to achieve better utility than the basic Laplace mechanism. The choice of parameters for this algorithm is crucial for its utility. Hence, we will introduce two optimization techniques based on the constraints given for the database $D$ to enhance the parameter selection process and, consequently, improve the algorithm's utility.

\subsection{Graph Projection Approach for \mininconsistency\ and \problematic} 
A primary utility challenge in achieving node-DP for graph statistics is their high sensitivity. In the worst case, removing a single node from a graph of $n$ nodes can result in removing $(n-1)$ edges. To mitigate this issue, the state-of-the-art approach~\cite{day2016publishing} first projects the graph $\mathcal{G}$ onto a $\theta$-bounded graph $\mathcal{G}_{\theta}$, where the maximum degree is no more than $\theta$. Subsequently, the edge count of the transformed graph is perturbed by the Laplace mechanism with a sensitivity value of less than $n$. However, the choice of $\theta$ is critical for accurate estimation. 
A small $\theta$ reduces Laplace noise due to lower sensitivity, but results in significant edge loss during projection. Conversely, a $\theta$ close to $n$ preserves more edges but increases the Laplace noise. Prior work addresses this balance using the exponential mechanism (EM) to prefer a $\theta$ that minimizes the combined errors arising from graph projection and the Laplace noise. 



\begin{algorithm}[t]
\caption{Graph projection approach for $\mininconsistency$ and $\problematic$}
\label{algo:graph_general}
    \KwData{Dataset $D$, constraint set $\constraintset$, candidate set $\Theta$, privacy budgets $\epsilon_1$ and $\epsilon_2$}
    \KwResult{DP inconsistency measure for $\mininconsistency$ or $\problematic$}
    
    Construct the conflict graph $\graph$\\
    
    Sample $\theta^*$ from $\Theta$  with a $\epsilon_1$-DP mechanism \commenttext{// Basic EM (Algorithm~\ref{algo:expo_mech_basic}); Optimized EM (Algorithm~\ref{algo:em_opt})}\
    
    Compute $\theta^*$-bounded graph $\mathcal{G}_{\theta^*} \gets \pi_{\theta^*}(\graph)$  
     \commenttext{// Edge addition algorithm~\cite{day2016publishing}}\\
    
    {\bf Return} $f(\mathcal{G}_{\theta^*})+\text{Lap}(\frac{\theta^*}{\epsilon_2})$
    \commenttext{//
    $f(\cdot)$ returns edge count for $\mininconsistency$ and the number of nodes with positive degrees for $\problematic$} \end{algorithm}

We outline this general approach in Algorithm~\ref{algo:graph_general}. This algorithm takes in the dataset $D$, the constraint set $\constraintset$, a candidate set $\Theta$ for degree bounds, and privacy budgets $\epsilon_1$ and $\epsilon_2$. These privacy budgets are later composed to get a final guarantee of $\epsilon$-DP.
We start by constructing the conflict graph $\graph$ generated from the input dataset $D$ and constraint set $\constraintset$ (line 1), as defined in \Cref{sec:prelim-integrity-constraints}. 
Next, we sample in a DP manner a value of $\theta^*$ from the candidate set $\Theta$ with the privacy budget $\epsilon_1$ (line 2). A baseline choice is an exponential mechanism detailed in Algorithm~\ref{algo:expo_mech_basic} to output a degree that minimizes the edge loss in a graph and the Laplace noise.
In line 3, we compute a bounded graph $\mathcal{G}_{\theta^*}$ using the edge addition algorithm~\cite{day2016publishing}, we compute a $\theta^*$-bounded graph $\mathcal{G}_{\theta^*}$ (detailed in Section~\ref{sec:prelim}). Finally, we perturb the true measure (either the number of edges for $\mininconsistency$ or the number of positive degree nodes for $\problematic$) on the projected graph, denoted by $f(\mathcal{G}_{\theta^*})$, by adding Laplace noise using the other privacy budget $\epsilon_2$ (line 4). 

The returned noisy measure at the last step has two sources of errors: (i) the bias incurred in the projected graph, i.e.,  $f(\mathcal{G})-f(\mathcal{G}_{\theta^*})$, and (ii) the noise from the Laplace mechanism with an expected square root error ${\sqrt{2}\theta^*}/{\epsilon_2}$. Both errors depend on the selected parameter $\theta^*$, and it is vital to select an optimal $\theta^*$ that minimizes the combined errors. Next, we describe a DP mechanism that helps select this parameter. 


\begin{algorithm}[b]
\caption{EM-based first try for parameter selection}
\label{algo:expo_mech_basic}
    \KwData{Graph $\mathcal{G}$, candidate set $\Theta$, quality function $q$, privacy budget $\epsilon_1, \epsilon_2$ }
    \KwResult{Candidate $\theta^*$}
    Find the maximum value in $\Theta$ as $\theta_{\max}$ \\
    For each $\theta_i \in \Theta$, compute $q_{\epsilon_2}(\mathcal{G}, \theta_i)$ 
    \commenttext{// See Equation~\eqref{eq:quality_function}}
    \\
    %Pick $\theta^*$ with prob $\propto \exp( \frac{\epsilon_1 q(\mathcal{G}, \theta_i, \theta_{max}, \epsilon_2)}{2\Delta_q})$ \\
    Sample $\theta^*$ with prob $\propto \exp( \frac{\epsilon_1 q_{\epsilon_2}(\mathcal{G}, \theta_i)}{2\theta_{\max}})$ \\
    {\bf Return} $\theta^*$
\end{algorithm}

\paratitle{EM-based first try for parameter selection} 
% The exponential mechanism (EM) is a popular algorithm for choosing hyper-parameters like $\theta$ for a degree-bounded graph. For this case, 
The EM (Definition~\ref{def:EM}) specifies a quality function $q(\cdot,\cdot)$ that maps a pair of a database $D$ and a candidate degree $\theta$ to a numerical value. The optimal $\theta$ value for a given database $D$ should have the largest possible quality value and, hence, the highest probability of being sampled. We also denote $\theta_{\max}$ the largest degree candidate in $\Theta$ and use it as part of the quality function to limit its sensitivity.


%Algorithm~\ref{algo:expo_mech_basic}. Given a candidate set $\Theta$ and a quality function $q(\mathcal{G}, \theta) \in \mathbb{R}$ and corresponding scores for each candidate, exponential mechanism picks a candidate $\theta^* \in \Theta$ that has the highest score with high probability.

The quality function we choose to compute the inconsistency measures includes two terms: for each $\theta\in \Theta$,
\begin{equation}~\label{eq:quality_function}
    q_{\epsilon_2}(\mathcal{G}, \theta) = - e_{\text{bias}}(\mathcal{G}, \theta) - {\sqrt{2}\theta}/{\epsilon_2}
\end{equation}
where the first term $e_{\text{bias}}$  captures the bias in the projected graph, and the second term ${\sqrt{2}\theta}/{\epsilon_2}$ captures the error from the Laplace noise at budget $\epsilon_2$. For the minimum inconsistency measure $\mininconsistency$, we define the bias term as
\begin{equation}
e_{\text{bias}}(\mathcal{G},\theta) = |\mathcal{G}_{\theta_{\max}}.E| - |\mathcal{G}_\theta.E|    
\end{equation}
i.e., the number of edges truncated at degree $\theta$ as compared to that at degree $\theta_{\max}$. For the problematic measure $\problematic$, we have 
\begin{equation}
e_{\text{bias}}(\mathcal{G}, \theta) = 
|\mathcal{G}_{\theta_{\max}}.V_{>0}| - |\mathcal{G}_{\theta}.V_{>0}|    
\end{equation} 
where $\mathcal{G}_\theta.V_{>0}$ denote the nodes with positive degrees. 

\begin{example}~\label{example:quality_function}
    Consider the same graph as Example~\ref{example:running_example} and a candidate set $\Theta = [1, 2, 3]$ to compute the $\mininconsistency$ measure (number of edges) with $\epsilon_2=1$. For the first candidate $\theta = 1$, as node 4 has degree 3, the edge addition algorithm would truncate 2 edges, for $\theta = 2$, 1 edge would be truncated and for $\theta = 3$, no edges would be truncated. We can, therefore, compute each term of the quality function for each $\theta$ given in Table~\ref{tab:example_quality_function}.  
    \begin{table}[]
        \centering
        \begin{tabular}{|c|c|c|c|}
             \hline
             $\theta$ & $e_{\text{bias}}$ & ${\sqrt{2}\theta}/{\epsilon_2}$ & q  \\
             \hline
             1 & 2 & $\sqrt{2}$ & $-2 - \sqrt{2}$\\
             2 & 1 & $2\sqrt{2}$ &  $-1 - 2\sqrt{2}$\\
             3 & 0 & $3\sqrt{2}$ & $-3\sqrt{2}$\\
             \hline
        \end{tabular}
        \caption{Quality function computation for $\mininconsistency$ for the conflict graph in Figure~\ref{fig:db_to_graph} when $\epsilon_2=1$}
        \label{tab:example_quality_function}
    \end{table}
    For this example, we see that $\theta=1$ has the best quality even if it truncates the most number of edges as the error from Laplace noise overwhelms the bias error.
\end{example}

We summarize the basic EM for the selection of the bounded degree in Algorithm~\ref{algo:expo_mech_basic}.
This algorithm has a complexity of $O(|\Theta|m)$, where $m$ is the edge size of the graph, as computing the quality function for each $\theta$ candidate requires running the edge addition algorithm once. The overall Algorithm~\ref{algo:graph_general} has a complexity of $O(|\Sigma|n^2+|\Theta|m)$, where the first term is due to the construction of the graph.

\paratitle{Privacy analysis}
The privacy guarantee of \cref{algo:graph_general} depends on the budget spent for the exponential mechanism and the Laplace mechanism, as summarized below. 
\begin{theorem}\label{thm:privacy_proof_dc_oblivious}
    ~\cref{algo:graph_general} satisfies $(\epsilon_1 + \epsilon_2)$-node DP for $\graph$ and $(\epsilon_1 + \epsilon_2)$-DP for the input database $D$.
\end{theorem}

\reva{
\begin{proof}[Proof sketch]
The proof is based on the sequential composition of two DP mechanisms as stated in Proposition~\ref{prop:DP-comp-post}.
\end{proof}
}

 As stated below, we just need to analyze the sensitivity of the quality function in the exponential mechanism and the sensitivity of the measure over the projected graph. 



\begin{lemma}\label{lemma:sensitivity}
    The sensitivity of $f\circ\pi_\theta(\cdot)$ in Algorithm~\ref{algo:graph_general} is $\theta$, where $\pi_\theta$ is the edge addition algorithm with the input $\theta$ and $f(\cdot)$ counts edges for $\mininconsistency$ and nodes with a positive degrees for $\problematic$.
\label{lemma:sens_lap}
\end{lemma}

\reva{
\begin{proof}[Proof sketch]
For $\problematic$, we can analyze a worst-case scenario where the graph is a star with $n$ nodes such that there is an internal node connected to all other $n-1$ nodes, and the threshold $\theta$ for edge addition is $n$. The edge addition algorithm would play a minimal role, and no edges would be truncated. For a neighboring graph that differs on the internal node, all edges of the graph are removed (connected to the internal node), and the $\problematic = 0$ (no problematic nodes), making the sensitivity for $\problematic$ in this worst-case $=n$.

For $\mininconsistency$, the proof is similar to prior work~\cite{day2016publishing} for publishing degree distribution that uses stable ordering to keep track of the edges for two neighboring graphs. We need to analyze the changes made to the degree of each node by adding one edge at a time for two graphs $\mathcal{G}$ and its neighboring graph $\mathcal{G}'$ with an additional node $v^+$. The graphs have the stable ordering of edges (\cref{def:stable_ordering}) $\Lambda$ and $\Lambda'$, respectively.  Assuming the edge addition algorithm adds a set of $t$ extra edges incident to $v^+$ for $\mathcal{G}'$, we can create $t$ intermediate graphs and their respective stable ordering of edges that can be obtained by removing from the stable ordering $\Lambda'$ each edge $t$ and others that come after $t$ in the same sequence as they occur in $\Lambda'$. We analyze consecutive intermediate graphs, their stable orderings, and the edges actually that end up being added by the edge addition algorithm. As the edge addition algorithm removes all edges of a node once an edge incident is added, we observe that only one of these $t$ edges is added. All other edges incident to $v^+$ are removed. We prove this extra edge leads to decisions in the edge addition algorithm that always restricts such consecutive intermediate graphs to differ by at most $1$ edge. This proves the lemma for $\mininconsistency$ as at most $t$ (upper bounded by $\theta$) edges can differ between two neighboring graphs. 
\end{proof}
}

\ifpaper
The full proof for the above lemma can be found in the full paper~\cite{full_paper}. 
\else
\fi
We now analyze the sensitivity of the quality function using both measures' sensitivity analysis.


\begin{lemma} \label{lemma:sens_quality}
The sensitivity of the quality function $q_{\epsilon_2}(\mathcal{G}, \theta_i)$ in Algorithm~\ref{algo:expo_mech_basic} defined in Equation~\eqref{eq:quality_function} is $\theta_{\max}=\max(\Theta)$. 
% for both $\mininconsistency$ and $\problematic$ .
\end{lemma}

\reva{
\begin{proof}[Proof sketch]
We prove the theorem for the $\mininconsistency$ measure and show that it is similar for $\problematic$. The sensitivity of the quality function is computed by comparing the respective quality functions of two neighboring graphs $\mathcal{G}$ and $\mathcal{G}'$ with an extra node. It is upper bound by the difference of two terms $\left(|\mathcal{G}'_{\theta_{\max}}.E| - |\mathcal{G}_{\theta_{\max}}.E|\right) - \left(|\mathcal{G}'_\theta.E| - |\mathcal{G}_\theta.E|\right)$. The first term $\left(|\mathcal{G}'_{\theta_{\max}}.E| - |\mathcal{G}_{\theta_{\max}}.E|\right)$ is the sensitivity of the measures, as already proved by Lemma~\ref{lemma:sens_lap} is equal to $\theta_{max}$. The second term $\left(|\mathcal{G}'_\theta.E| - |\mathcal{G}_\theta.E|\right)$ is always $\geq 0$ as  $|\mathcal{G}'_\theta.E| \geq |\mathcal{G}_\theta.E|$ as discussed in the proof for Lemma~\ref{lemma:sens_lap}.
\end{proof}
}

\ifpaper
\else
Proofs for \cref{thm:privacy_proof_dc_oblivious}, \cref{lemma:sens_quality}, and \cref{lemma:sens_lap} can be found in \cref{app:graph_general}.
\fi

\eat{
\begin{proof}
% \xh{double check the proof, there are a few issues.
% \begin{itemize}
% %    \item Check if Eqn 2 or Eqn 3. I think it should be Eqn 3.
%     \item The 2nd last inequality is incorrect; $ \theta_i$ is an upper bound, and subtracting an upper bound will not preserve $\leq$. Simply directly drop the 2nd term if it is non-negative.
%     \item mention the analysis applies to $\problematic$.
%  %   \item One important point is missing from the current proof is the reasoning for the 2nd last inequality $|\mathcal{G}'_{\theta_{\max}}.E| - |\mathcal{G}_{\theta_{\max}}.E| \leq \theta_{\max}$. This is actually related to the sensitivity of the measure over the projected graph (Lemma~\ref{lemma:sens_lap}. It should be highlighted.
% \end{itemize}}
We prove the lemma for the $\mininconsistency$ measure and show that it is similar for $\problematic$. Let us assume that $\mathcal{G}$ and $\mathcal{G}'$ are two neighbouring graphs and $\mathcal{G}'$ has one extra node $v^*$. 
    \begin{equation*}
        \begin{split}
            &\|q_{\epsilon_2}(\mathcal{G}, \theta) - q_{\epsilon_2}(\mathcal{G}^\prime, \theta)\| \leq -|\mathcal{G}_{\theta_{\max}}.E| + |\mathcal{G}_{\theta}.E| - \sqrt{2}\frac{\theta}{\epsilon_1} \\ &+ |\mathcal{G}'_{\theta_{\max}}.E| - |\mathcal{G}'_{\theta}.E| + \sqrt{2}\frac{\theta}{\epsilon_1} \\
            &\leq \left(|\mathcal{G}'_{\theta_{\max}}.E| - |\mathcal{G}_{\theta_{\max}}.E|\right) - \left(|\mathcal{G}'_\theta.E| - |\mathcal{G}_\theta.E|\right)\\
            &\leq \theta_{\max} - \left(|\mathcal{G}'_\theta.E| - |\mathcal{G}_\theta.E|\right) 
            \leq \theta_{\max}    
        \end{split}
    \end{equation*}
    The second last inequality is due to Lemma~\ref{lemma:sens_lap} that states that $|\mathcal{G}'_{\theta_{max}}.E| - |\mathcal{G}_{\theta_{max}}.E| \leq \theta_{max}$. The last inequality is because $|\mathcal{G}'_\theta.E| \geq |\mathcal{G}_\theta.E|$. Note that the neighboring graph $\mathcal{G}'$ contains all edges of $\mathcal{G}$ plus extra edges of the added node $v^*$. Due to the stable ordering of edges in the edge addition algorithm, each extra edge of $v^*$ either substitutes an existing edge or is added as an extra edge in $\mathcal{G}_\theta$. Therefore, the total edges $|\mathcal{G}'_\theta.E|$ is equal or larger than $|\mathcal{G}_\theta.E|$. We elaborate this detail further in the proof for Lemma~\ref{lemma:sens_lap}. For the $\problematic$ measure, the term in the last inequality changes to $|\mathcal{G}'_\theta.V_{>0}| - |\mathcal{G}_\theta.V_{>0}|$ and is also non-negative because $\mathcal{G}'$ contains an extra node that can only add and not subtract from the total number of nodes with positive degree.
\end{proof}
}




\eat{
\xh{Condense the lemmas below and move the proofs to the appendix, and comment it's quite similar to prior work~\cite{day2016publishing}.}

\begin{proof}
    In \cref{algo:graph_general}, Line 1 uses the exponential mechanism with $\epsilon_1$ to calculate $\theta^*$. This theta value is then used to compute the bounded graph, and finally, the inconsistency measure value is released with Laplace noise of $\epsilon_2$. Therefore, using composition properties of DP, \cref{algo:dc_oblivious} satisfies $\epsilon_1 + \epsilon_2$-node DP.
\end{proof}

The inconsistency measures $\mininconsistency$ and $\problematic$ can be directly computed on the bounded graph. For the $\mininconsistency$, we compute the total number of edges $\pi_\theta(\mathcal{G})$. The sensitivity analysis of $\mininconsistency$ on $\pi_\theta(\mathcal{G})$ is detailed in \cref{lemma:sens_mininconsistency}.

\begin{lemma}
    The sensitivity of $\mininconsistency(\pi_\theta(\mathcal{G}))$ is $\theta$, where $\pi_\theta$ is the edge addition algorithm with the user input $\theta$.
        % $$\| \mininconsistency(\pi_{\theta}^\Lambda(\mathcal{G})) - \mininconsistency(\pi_{\theta}^\Lambda(\mathcal{G}^\prime)) \| \leq \theta$$ 
    \label{lemma:sens_mininconsistency}
\end{lemma}

\ifpaper
The lemma can be proved by analyzing the changes made to the degree of each node in the graph by adding one edge at a time. The stable ordering of the edges allows us to keep track of the edges for two neighbouring graphs. Due to space constraints, we defer the proof to the full paper.  
\else
\proof
Let's assume without loss of generality that
$\mathcal{G}^{\prime}=\left(V^{\prime}, E^{\prime}\right)$ has an additional node $v^{+}$compared to $\mathcal{G}=$ $(V, E)$, i.e., $V^{\prime}=V \cup\left\{v^{+}\right\}, E^{\prime}=E \cup E^{+}$, and $E^{+}$is the set of all edges incident to $v^{+}$in $\mathcal{G}^{\prime}$. Let $\Lambda^{\prime}$ be the stable orderings for constructing $\pi_\theta\left(\mathcal{G}^{\prime}\right)$, and $t$ be the number of edges added to $\pi_\theta\left(\mathcal{G}^{\prime}\right)$ that are incident to $v^{+}$. Clearly, $t \leq \theta$ because of the $\theta$-bounded algorithm. Let $e_{\ell_1}^{\prime}, \ldots, e_{\ell_t}^{\prime}$ denote these $t$ edges in their order in $\Lambda^{\prime}$. Let $\Lambda_0$ be the sequence obtained by removing from $\Lambda^{\prime}$ all edges incident to $v^{+}$, and $\Lambda_k$, for $1 \leq k \leq t$, be the sequence obtained by removing from $\Lambda^{\prime}$ all edges that both are incident to $v^{+}$and come after $e_{\ell_k}^{\prime}$ in $\Lambda^{\prime}$. Let $\pi_\theta^{\Lambda_k}\left(\mathcal{G}^{\prime}\right)$, for $0 \leq k \leq t$, be the graph reconstructed by trying to add edges in $\Lambda_k$ one by one on nodes in $\mathcal{G}^{\prime}$, and $\lambda_k$ be the sequence of edges from $\Lambda_k$ that are actually added in the process. Thus $\lambda_k$ uniquely determines $\pi_\theta^{\Lambda_k}\left(\mathcal{G}^{\prime}\right)$; we abuse the notation and use $\lambda_k$ to also denote $\pi_\theta^{\Lambda_k}\left(\mathcal{G}^{\prime}\right)$. We have $\lambda_0=\pi_\theta(\mathcal{G})$, and $\lambda_t=\pi_\theta\left(\mathcal{G}^{\prime}\right)$.

In the rest of the proof, we show that $\forall k$ such that $1 \leq k \leq t$, at most 1 edge will differ between $\lambda_k$ and $\lambda_{k-1}$. This will prove the lemma because there are at most $t$ (upper bounded by $\theta$) edges that are different between $\lambda_t$ and $\lambda_0$.

To prove that any two consecutive sequences differ by at most 1 edge, let's first consider how the sequence $\lambda_k$ differs from $\lambda_{k-1}$. Recall that by construction, $\Lambda_k$ contains one extra edge in addition to $\Lambda_{k-1}$ and that this edge is also incident to $v^*$. Let that additional differing edge be $e_{\ell_k}^\prime = (u_j, v^+)$. In the process of creating the graph $\pi_\theta^{\Lambda_k}(\mathcal{G}^{\prime})$, each edge will need a decision of either getting added or not. The decisions for all edges coming before $e_{\ell_k}^{\prime}$ in $\Lambda^{\prime}$ must be the same in both $\lambda_k$ and $\lambda_{k-1}$. Similarly, after $e_{\ell_k}^{\prime}$, the edges in $\Lambda_k$ and $\Lambda_{k-1}$ are exactly the same. However, the decisions for including the edges after $e_{\ell_k}^{\prime}$ may or may not be the same. Assuming that there are a total of $s \geq 1$ different decisions, we will observe how the additional edge $e_{\ell_k}^{\prime}$ makes a difference in decisions. 


When $s=1$, the only different decision must be regarding differing edge $e_{\ell_k}^\prime = (u_j, v^+)$ and that must be including that edge in the total number of edges for $\lambda_k$. Also note that due to this addition, the degree of $u_j$ gets added by 1 which did not happen for $\lambda_{k-1}$. When $s>1$, the second different decision must be regarding an edge incident to $u_j$ and that is because degree of $u_j$ has reached $\theta$, and the last one of these, denoted by $(u_j, u_{i \theta})$ which was added in $\lambda_{k-1}$, cannot be added in $\lambda_k$. In this scenario, $u_j$ has the same degree (i.e., $\theta$ ) in both $\lambda_k$ and $\lambda_{k-1}$. Now if $s$ is exactly equal to 2, then the second different decision must be not adding the edge $(u_j, u_{i \theta})$ to $\lambda_k$. Again, note here that as $(u_j, u_{i \theta})$ was not added in $\lambda_k$ but was added in $\lambda_{k-1}$, there is still space for one another edge of $u_{i \theta}$. If $s>2$, then the third difference must be the addition of an edge incident to $u_{i \theta}$ in $\lambda_k$. This process goes on for each different decision in $\lambda_k$ and $\lambda_{k-1}$. Since the total number of different decisions $s$ is finite, this sequence of reasoning will stop with a difference of at most 1 in the total number of the edges between $\lambda_{k-1}$ and $\lambda_k$.
\qed
\fi

For the $\problematic$ measure, that is the total number of nodes in the graph that have a positive degree, we compute the number of nodes in the $\pi_\theta(\mathcal{G})$ that have degree 0 and subtract it from the total nodes in the graph. The sensitivity analysis of $\problematic$ is given by ~\cref{lemma:sens_problematic}. 

\begin{lemma}
    The sensitivity of $\problematic(\pi_\theta(\mathcal{G}))$ is $\theta$, where $\pi_\theta$ is the edge addition algorithm with user input $\theta$.
        % $$\| \problematic(\pi_\theta(\mathcal{G})) - \problematic(\pi_\theta(\mathcal{G}^\prime)) \| \leq \theta$$ 
    \label{lemma:sens_problematic}
\end{lemma}

\proof
Assume, in the worst case, the graph $\mathcal{G}$ is a star graph with $n$ nodes such that there exists an internal node that is connected to all other $n-1$ nodes. In this scenario, there are no nodes that have 0 degrees, and the $\problematic$ measure $= n-0 = 0$. If the neighbouring graph $\mathcal{G}^\prime$ differs on the internal node, all edges of the graph are removed are the $\problematic = n$. The edge addition algorithm $\pi_\theta$ would play a minimal role here as $\theta$ could be equal to $n$.
\qed




In Lemma~\ref{lemma:sens_quality}, we show the sensitivity computation for the quality function for the $\mininconsistency$ measure. The $\problematic$ measure has a similar analysis. 

\begin{lemma}
    For any two neighbouring graphs $\mathcal{G}$ and $\mathcal{G}^\prime$, the sensitivity of the quality function $q(\mathcal{G}, \theta_i)$ equals $\theta_{max}$,
    % $$\|q(\mathcal{G}, \theta_i) - q(\mathcal{G}^\prime, \theta_i)\| \leq \theta_{max}$$
    where $\theta_{max}$ is the maximum theta value over all candidate values $\theta_i \in \Theta$.
\end{lemma}\label{lemma:sens_quality}
}

%\subsubsection{Utility analysis}\label{sec:dc_oblivious_privay_util}

%For the utility analysis of \cref{algo:dc_oblivious}, we analyze the utility of the exponential mechanism that outputs the best value of $\theta^*$. As per Theorem~\ref{thm:utility_expo}, the exponential mechanism allows us to privately select an object $\theta$ from a set of objects $\Theta$ with a score comparable to the best score $OPT$ in $\Theta$ with an error that depends on the sensitivity, privacy budget $\epsilon$ and the total number of candidates $|\Theta|$. 
\paratitle{Utility analysis}
The utility of Algorithm~\ref{algo:graph_general} is directly encoded by the quality function of the exponential mechanism in Algorithm~\ref{algo:expo_mech_basic}. 
We first define the best possible quality function value for a given database and its respective graph as 
\begin{equation}
    q_{\opt}(D,\epsilon_2) = \max_{\theta\in \Theta} q_{\epsilon_2}(\graph,\theta)
\end{equation}
and the set of degree values that obtain the optimal quality value as 
\begin{equation}
 \Theta_{\opt} = \{\theta\in \Theta: q_{\epsilon_2}(\graph,\theta) = q_{\opt}(D,\epsilon_2) \}.   \end{equation} 
However, we define $e_{\text{bias}}$ as the difference in the number of edges or nodes in the projected graph $\mathcal{G}_{\theta}$ compared to that of $\mathcal{G}_{\theta_{\max}}$, instead of $\mathcal{G}$. This is to limit the sensitivity of the quality function. To compute the utility, we slightly modify the quality function without affecting the output of the exponential mechanism. 
\begin{equation}
    \tilde{q}_{\epsilon_2}(\mathcal{G},\theta) = q_{\epsilon_2}(\mathcal{G},\theta) + f(\mathcal{G}_{\theta_{\max}}) - f(\graph),
\end{equation}
where $f(\cdot)$ returns edge count for $\mininconsistency$ and the number of nodes with positive degrees for $\problematic$.
This modified quality function should give the same set of degrees $\Theta_{\opt}$ with optimal values equal to 
\begin{equation}
    \tilde{q}_{\opt}(D,\epsilon_2) = \max_{\theta\in \Theta} q_{\epsilon_2}(\graph,\theta) + f(\graph_{\theta_{\max}}) - f(\graph).
\end{equation}


Then, we derive the utility bound for Algorithm~\ref{algo:graph_general} based on the property of the exponential mechanism as follows. 


\begin{theorem}\label{thm:graph_general_utility} On any database instance $D$ and its respective conflict graph $\graph$, let $o$ be the output of Algorithm~\ref{algo:graph_general} with Algorithm~\ref{algo:expo_mech_basic} over $D$.  
Then,  with a probability of at least $1-\beta$, we have 
\begin{equation}
|o-a| \leq -\tilde{q}_{\opt}(D,\epsilon_2) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{2|\Theta|}{|\Theta_{\opt}|\cdot \beta}) 
\end{equation}
where $a$ is the true inconsistency measure over $D$ and $\beta\leq \frac{1}{e^{\sqrt{2}}}$.
%\benny{I don't get this $\beta$. Where is it coming from? Is it our choice? Why not choose $\beta=0$? Do you mean that such $\beta$ exists? Please clarify.} \xh{$\beta$ affects the 2nd term, as beta goes smaller, the error bound increases. Add a proof sketch to give the intuition for the proof} \sm{I have added more information about $\beta$ in the proof sketch.}
\end{theorem}

% \begin{proof}[Proof sketch]
% \ag{add}
% \end{proof}

\ifpaper
\begin{proof}[Proof Sketch]
   We use the probabilistic utility bound of the exponential mechanism~\cite{mcsherry2007mechanism} that guarantees that a suitable candidate is sampled with probability $1-\beta$ for a given quality function. To prove the bound, we utilize the optimal quality function $\tilde{q}_{\opt}(D)$  and the error from the Laplace mechanism with the exponential mechanism's utility bound. The full proof is in the full version~\cite{full_paper}.
\end{proof}
\else
The proof can be found in ~\cref{app:graph_general_utility}.
\eat{
\begin{proof}
By the utility property of the exponential mechanism~\cite{mcsherry2007mechanism}, with at most probability $\beta/2$, Algorithm~\ref{algo:expo_mech_basic} will sample a bad $\theta^*$ with a  quality value as below
\begin{equation}
    q_{\epsilon_2}(\graph,\theta^*) \leq q_{\opt}(D,\epsilon_2) - \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{2|\Theta|}{|\Theta_{\opt}|\beta})
\end{equation}
which is equivalent to 
\begin{equation}\label{eq:goodtheta}
    e_{\text{bias}}(\mathcal{G},\theta^*)  \geq -q_{\opt}(D,\epsilon_2) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{2|\Theta|}{|\Theta_{\opt}|\beta}) -  \frac{\sqrt{2}\theta^*}{\epsilon_2}.
\end{equation}

With probability $\beta/2$, where $\beta\leq \frac{1}{e^{\sqrt{2}}}$,
we have 
\begin{equation}    
\text{Lap}(\frac{\theta^*}{\epsilon_2}) \geq
      \frac{\ln(1/\beta)\theta^{*}}{\epsilon_2} \geq \frac{\sqrt{2}\theta^*}{\epsilon_2}
      \end{equation}
Then, by union bound, with at most probability $\beta$, we have 
\begin{eqnarray}
   && |o-a| \nonumber\\
       &=& 
|f(\mathcal{G}_{\theta^*})+\text{Lap}(\frac{\theta^*}{\epsilon_2})-a|
            \nonumber  \\
    &\geq& a- f(\mathcal{G}_{\theta^*})+ \frac{\sqrt{2}\theta^*}{\epsilon_2}
 \nonumber \\
    &=& f(\mathcal{G})-f(\mathcal{G}_{\theta^*})+
     \frac{\sqrt{2}\theta^*}{\epsilon_2} \nonumber \\
    &=& f(\mathcal{G})-f(\mathcal{G}_{\theta_{\max}}) +
f(\mathcal{G}_{\theta_{\max}}) - f(\mathcal{G}_{\theta^*})
 +    \frac{\sqrt{2}\theta^*}{\epsilon_2} \nonumber\\    
    &=& f(\mathcal{G})-f(\mathcal{G}_{\theta_{\max}}) +
        e_{\text{bias}}(\mathcal{G},\theta^*)  + \frac{\sqrt{2}\theta^*}{\epsilon_2} \nonumber\\
     &\geq& -q_{\opt}(D,\epsilon_2) + f(\mathcal{G})-f(\mathcal{G}_{\theta_{\max}}) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{2|\Theta|}{|\Theta_{\opt}|\beta})  \nonumber \\
      &=& -\tilde{q}_{\opt}(D,\epsilon_2) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{2|\Theta|}{|\Theta_{\opt}|\beta})
\end{eqnarray}
\end{proof}
}
\fi

This theorem indicates that the error incurred by Algorithm~\ref{algo:graph_general} with Algorithm~\ref{algo:expo_mech_basic} is directly proportional to the log of the candidate size $|\Theta|$ and the sensitivity of the quality function. \reva{The $\beta$ parameter in the theorem is a controllable probability parameter. According to the accuracy requirements of a user's analysis, one may set $\beta$ as any value less than this upper bound. For example, if we set $\beta=0.01$, then our theoretical analysis of Algorithm 2 that says the algorithm's output being close to the true answer will hold with a probability of $1-\beta = 0.99$. We also show a plot to show the trend of the utility analysis as a function of $\beta$ in Appendix A.5~\cite{full_paper}.} Without prior knowledge about the graph, $\theta_{\max}$ is usually set as the number of nodes $n$, and $\Theta$ includes all possible degree values up to $n$, resulting in poor utility. 
Fortunately, for our use case, the edges in the graph arise from the DCs that are available to us. In the next section, we show how we can leverage these constraints to improve the utility of our algorithm by truncating candidates in the set $\Theta$.





\eat{
\begin{theorem}\label{thm:utility_proof}
Let $\mathcal{G}(V, E)$ be a private graph, and $OPT(\mathcal{G})=\max _{\theta \in \Theta} q(\mathcal{G}, \theta, |V|, \epsilon_1, \epsilon_2)$ be the quality attained by the best object $\theta$ with respect to the dataset $\mathcal{G}$ due to Algorithm~\ref{algo:dc_oblivious}, $M(\mathcal{G})$. If the set of objects that achieve the $OPT(\mathcal{G})$, $\Theta^*=\{\theta \in \Theta: q(\mathcal{G}, \theta, |V|, \epsilon_1, \epsilon_2)=OPT(\mathcal{G})\}$ has size $|\Theta^*| \geq 1$. Then
$$ \Pr \left[q(\mathcal{G}, M(\mathcal{G}), |V|, \epsilon_1, \epsilon_2) \leq OPT (\mathcal{G}) - \frac{2|V|}{\epsilon_1} (\ln |\Theta| + t) \right] \leq \exp(-t)$$,
where $\epsilon_1$ and $\epsilon_2$ are the privacy budgets for the exponential mechanism and measure calculation respectively, $q$ is the quality function that measures the quality of the minimum inconsistency measure $\mininconsistency$.
\end{theorem}


\proof

The result can be obtained by plugging in the sensitivity value of the utility function $\Delta_q = \theta_{max} = |V| $ to \cref{thm:utility_expo}. 

% \begin{equation*}
%     \begin{split}
%         \Pr\left[q(\mathcal{G}, M(\mathcal{G}), |V|, \epsilon_1, \epsilon_2) \leq OPT (\mathcal{G}) - \frac{2|V|}{\epsilon_1} (\ln |\Theta| + t) \right] \leq \exp(-t)
%     \end{split}
% \end{equation*}
\qed

According to Theorem~\ref{thm:utility_proof}, the utility of Algorithm~\ref{algo:dc_oblivious} is directly proportional to the number of candidates $|\Theta|$ and the sensitivity of the quality function equivalent to number of nodes in the graph $|V|$. However, in practice, these values can be extremely large depending on the density of the graph, which is an artifact of the number of conflicts in the dataset. Luckily, for our use case, these conflicts arise from the denial constraints in the constraint set $\constraintset$ that are available to us. In the next section, we show how we can make use of these constraints to improve the utility of our algorithm by truncating candidates in the set $\Theta$.

}



\input{sections/dc_aware}











% \subsection{Leveraging Graph Projection for Minimizing Inconsistency and Problematic Nodes}\label{sec:graph-algorithms-graphproj}

% The measures of minimizing inconsistency ($\mininconsistency$) and identifying problematic nodes essentially pertain to the total number of edges ($|E|$) and the total number of nodes with positive degrees respectively in the conflict graph ($\graph(V, E)$). Both these measures are sensitive to the number of vertices in $\graph$ and can be significantly improved using graph projection algorithms. Due to space constraints, we will focus on the $\mininconsistency$ measure, which computes the total number of edges, discuss the associated challenges, and defer discussion on the problematic nodes measure which faces similar challenges.

% Several graph projection algorithms exist~\cite{kasiviswanathan2013analyzing, blocki2013differentially}, among which the "edge addition" algorithm~\cite{day2016publishing} stands out for its effectiveness in preserving most of the underlying graph structure. This algorithm takes as input the graph $\mathcal{G}= \graph = (V, E)$, a bound on the maximum degree of each vertex ($\theta$), and a stable ordering of the edges ($\Lambda$) to output a projected $\theta$-bounded graph ($\mathcal{G}\theta$). The algorithm operates by adding edges in the same order as $\Lambda$ such that each node has a maximum degree of $\theta$.
% Utilizing this algorithm, we first compute the $\theta$-bounded graph, $\mathcal{G}\theta(V, E)$, and then compute the measures by adding Laplace noise proportional to the new sensitivity. The sensitivity analysis of $\mininconsistency$ on the $\theta$-bounded graph $\mathcal{G}_\theta$ is detailed in \cref{lemma:sens_mininconsistency}.

% \begin{lemma}
%     For any $\mathcal{G}, \mathcal{G}^\prime$ that differ in one node an user input $\theta$, we have
%     \begin{equation*}
%         \| \text{\mininconsistency}(\mathcal{G}_\theta) - \text{\mininconsistency}(\mathcal{G}^\prime_\theta) \| \leq \theta
%     \end{equation*}
%     \label{lemma:sens_mininconsistency}
% \end{lemma}

% Due to space constraints, we defer the proof to the appendix. Accurate estimation of the measure necessitates selecting an appropriate value for $\theta$. $\theta$ serves as a user-defined hyperparameter and may vary significantly across datasets. Higher values of $\theta$ may preserve more edges of the original graph but introduce higher error from the Laplace noise, whereas smaller values of $\theta$ may have lower Laplace noise error but truncate a significant number of edges, thereby introducing substantial error as well.

% The exponential mechanism is a popular algorithm for choosing hyperparameters like $\theta$. However, it faces challenges in our use case. Firstly, the candidate set size ($\Theta$) is extensive, as the optimal $\theta$ value depends on the density of the conflict graph, varying excessively across datasets. Secondly, the sensitivity of the quality function $q(\mathcal{G}, \theta_i)$ is high. For instance, for the $\mininconsistency$ measure, the quality function depends on the total number of edges not truncated, with sensitivity proportional to the number of vertices ($|V|$). We explore an alternative heuristic approach based on the frequency of participating attributes in the constraint set $\constraintset$.

% The $\theta$ value is dependent on the density of the conflict graph and is influenced by the number of conflicts in the dataset, arising from the denial constraints in $\constraintset$. One strategy involves setting $\theta$ as the maximum frequency of any value occurring in the dataset over the participating attributes in $\constraintset$. However, this approach may leak privacy, necessitating the privatization of the $\theta$ value using part of the privacy budget. Fortunately, the sensitivity for this computation is low (1), as adding or removing a row can affect the maximum frequency by a maximum of 1. We demonstrate the performance of these strategies experimentally for choosing $\theta$ in Section~\ref{sec:experiments}.

% We observe that the $\theta$ value depends on the density of the conflict graph and is an artifact of the number of conflicts in the dataset. These conflicts arise from the denial constraints in the constraint set $\constraintset$. Each violating tuple in the dataset adds conflicts equivalent to the frequency of similar tuples occurring in the dataset. Therefore, one strategy can be to choose the $\theta$ value as the maximum frequency of any value occurring in the dataset over the participating attributes in the constraint set. It is however important to note here that the frequency may leak privacy and the $\theta$ value calculated using this strategy needs to be privatized using part of the privacy budget. Luckily, the sensitivity for this computation is 1 as adding or removing a row can affect the maximum frequency by a maximum of 1. We demonstrate the performance of these above strategies experimentally for choosing $\theta$ in Section~\ref{sec:experiments}. 

