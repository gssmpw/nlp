\begin{theorem}\label{thm:graph_general_utility} On any database instance $D$ and its respective conflict graph $\graph$, let $o$ be the output of Algorithm~\ref{algo:graph_general} with Algorithm~\ref{algo:expo_mech_basic} over $D$.  
Then,  
the root mean squared error (RMSE) of $o$ is bounded as follows %\sm{$\max(\Theta)$ is previously referred to as $\theta_{max}$. also what is $\Theta^*$. should it be $\theta^*$?}
\begin{equation}
\text{RMSE}(o) = \mathbb{E}[(o-a)^2]^{1/2}  \leq -\tilde{q}_{\opt}(D) + \frac{8 \theta_{\max}}{\epsilon_1} (\ln \frac{|\Theta|n}{|\Theta_{\opt}|}) + 1
\end{equation}
%with probability at least $1-\beta$,
%\begin{equation}|o-a|\leq -q^*(D) + \frac{2 \max(\Theta)}{\epsilon_1} (\ln \frac{|\Theta|}{|\Theta^*|\beta}) + xx \end{equation}
where $a$ is the true inconsistency measure over $D$ and $n=|D|$. 
\end{theorem}
\begin{proof}
By the utility property of the exponential mechanism~\cite{mcsherry2007mechanism}, with at least probability $1-\beta$, Algorithm~\ref{algo:expo_mech_basic} will sample a good $\theta^*$ with a minimum quality value as below
\begin{equation}
    q_{\epsilon_2}(\graph,\theta^*) \geq q_{\opt}(D) - \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{|\Theta|}{|\Theta^*|\beta})
\end{equation}
which is equivalent to 
\begin{equation}\label{eq:goodtheta}
    e_{\text{bias}}(\mathcal{G},\theta^*)  \leq -q_{\opt}(D) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{|\Theta|}{|\Theta_{\opt}|\beta}) -  \frac{\sqrt{2}\theta^*}{\epsilon_2}.
\end{equation}

Condition on this good $\theta^*$, the expected square error is 
\begin{eqnarray}
   && \mathbb{E}[(o-a)^2 ~|~\theta^* \text{is good that satifies Eqn.~\eqref{eq:goodtheta}}]\nonumber \\
       &\leq& 
       \mathbb{E}[(f(\mathcal{G}_{\theta^*})+\text{Lap}(\theta^*/\epsilon_2)-a)^2]
            \nonumber  \\
    &\leq& (f(\mathcal{G}_{\theta^*})-a)^2+
       \mathbb{E}[\text{Lap}(\theta^*/\epsilon_2))^2] \nonumber \\
    &=& (f(\mathcal{G})-f(\mathcal{G}_{\theta^*}))^2+
      \frac{2\theta^{*2}}{\epsilon_2^2} \nonumber \\
    &\leq& (f(\mathcal{G})-f(\mathcal{G}_{\theta_{\max}}) +
f(\mathcal{G}_{\theta_{\max}}) - f(\mathcal{G}_{\theta^*})
 +    \frac{\sqrt{2}\theta^*}{\epsilon_2})^2  \nonumber\\    
    &=& (f(\mathcal{G})-f(\mathcal{G}_{\theta_{\max}}) +
        e_{\text{bias}}(\mathcal{G},\theta^*)  + \frac{\sqrt{2}\theta^*}{\epsilon_2})^2 \nonumber\\
     &\leq& (-q_{\opt}(D) + f(\mathcal{G})-f(\mathcal{G}_{\theta_{\max}}) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{|\Theta|}{|\Theta^*|\beta}))^2  \nonumber \\
      &=& (-\tilde{q}_{\opt}(D) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{|\Theta|}{|\Theta_{\opt}|\beta}))^2 
\end{eqnarray}

With probability $\beta$, Algorithm~\ref{algo:expo_mech_basic} will sample a poor $\theta^*$ with quality value bounded by the sum of two naive upper bounds: (i) the largest possible bias $\mathcal{G}_{\theta=0}$ and (ii) the largest possible noise at $\theta_{\max}$, i.e., $(a+\frac{\sqrt{2}\theta_{\max}}{\epsilon_2})\leq \frac{n(n-1)}{2}+\frac{\sqrt{2}n}{\epsilon_2}\leq n^2$ (assume we have $\epsilon_2>2\sqrt{2}/n$). \xh{get a tighter bound?}

Set $\beta=\frac{1}{n^4}$, we have the 
\begin{eqnarray}
    && \mathbb{E}[(o-a)^2] \nonumber  \\
   &=& (1-\beta) \cdot \mathbb{E}[(o-a)^2 ~|~\theta^* \text{is good that satisfies Eqn.~\eqref{eq:goodtheta}}] \nonumber \\ 
   && + \beta \cdot \mathbb{E}[(o-a)^2 ~|~\theta^* \text{is not good}]  \nonumber \\
      &\leq& (-\tilde{q}_{\opt}(D) + \frac{2 \theta_{\max}}{\epsilon_1} (\ln \frac{|\Theta|}{|\Theta_{\opt}|\beta}))^2 (1-\beta) + n^4 \beta     
      \nonumber \\
    &\leq&  (-\tilde{q}_{\opt}(D) + \frac{8 \theta_{\max}}{\epsilon_1} (\ln \frac{|\Theta|n}{|\Theta_{\opt}|})+1)^2  
\end{eqnarray}
\end{proof}