% Article based on SIAM Article Template
\newif\ifarxiv
%\arxivfalse
\arxivtrue






\ifarxiv

\documentclass{article}

\usepackage[colorlinks=True,allcolors=blue]{hyperref}
\usepackage{amsthm}
\input{preamble.tex}
\newtheorem{definition}{Definition}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{example}{Example}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}[proposition]{Lemma}
\newtheorem{theorem}[proposition]{Theorem}
\newtheorem{corollary}[proposition]{Corollary}
%\theoremstyle{plain}
%\newtheorem{remark}{Remark}[section]

\title{\LARGE \bf Rough Stochastic Pontryagin Maximum Principle\\and an Indirect Shooting Method} 

\author{Thomas Lew\footnote{Toyota Research Institute. Email: thomas.lew@tri.global}}






\else

\documentclass[review,hidelinks,onefignum,onetabnum]{siamart250211}
\newsiamthm{assumption}{Assumption}

\input{shared}

\headers{Rough Stochastic Pontryagin Maximum Principle}{T. Lew}
\title{Rough Stochastic Pontryagin Maximum Principle\\and an Indirect Shooting Method\thanks{Submitted to the editors on March 15, 2025.}
}
% Authors: full names plus addresses.
\author{Thomas Lew\thanks{Toyota Research Institute, Los Altos, CA 
  (\email{thomas.lew@tri.global}).}}



\fi





% The next statement enables references to information in the
% supplement. See the xr-hyperref package for details.

\ifarxiv
\else
%\externaldocument[][nocite]{supplement}
\externaldocument{supplement}
\fi

% FundRef data to be entered by SIAM
%<funding-group specific-use="FundRef">
%<award-group>
%<funding-source>
%<named-content content-type="funder-name"> 
%</named-content> 
%<named-content content-type="funder-identifier"> 
%</named-content>
%</funding-source>
%<award-id> </award-id>
%</award-group>
%</funding-group>


\begin{document}

\maketitle

% REQUIRED
\begin{abstract}
We derive first-order Pontryagin optimality conditions for stochastic optimal control with deterministic control inputs for systems modeled by rough differential equations (RDE) driven by Gaussian rough paths. 
This   Pontryagin Maximum Principle (PMP) 
applies to systems following stochastic differential equations (SDE) 
driven by Brownian motion, yet % 
it does not rely on forward-backward SDEs and involves the same Hamiltonian as the deterministic PMP. 
The proof consists of first deriving various  integrable error bounds for solutions to nonlinear and linear RDEs by leveraging recent results on Gaussian rough paths. 
The PMP then   
follows using standard techniques based on needle-like variations. % 
As an application, we propose the first indirect shooting method for nonlinear stochastic optimal control and show that it converges $10\times$ faster than a direct method on a  stabilization task.
\end{abstract}

\ifarxiv

\setcounter{tocdepth}{2}
\tableofcontents
 \newpage



\else

% REQUIRED
\begin{keywords}
Stochastic optimal control, Pontryagin maximum principle, rough path theory
\end{keywords}

% REQUIRED
\begin{MSCcodes}
60L20, 
93E03, 
93E20
\end{MSCcodes}

\fi

\section{Introduction and main results}\label{sec:introduction} 
Stochastic optimal control has found numerous applications  % 
such as in finance \cite{Guasoni2006}, aerospace \cite{Leparoux2024}, robotics \cite{Blackmore2011}, automotive \cite{LewMPC2024}, and biology \cite{Berret2020}. % 
Stochastic optimal control problems 
typically % 
involve % 
a  dynamical system described by a % 
stochastic differential equation (SDE)
\begin{align}
\label{eq:SDE} 
\dd x_t = b(t,x_t,u_t)\dd t + \sigma(t,x_t)\circ\dd B_t, \quad t\in[0,T],
\end{align}
% 
% 
% 
 in Stratonovich or It\^o form, 
% 
% 
% 
% 
% 
% 
% 
% 
% 
where $x_t$ is the state of the system at time $t$, 
% 
$u_t$ is the control input, 
$b$ is the drift, $\sigma$ is the diffusion, $B$ is a Brownian motion, $T$ is the final time, 
% 
and consist of optimizing an objective $\E[\int_0^T f(t,x_t,u_t)\dd t+g(x_T)]$  over a set of control input trajectories subject to state and control constraints. 

% 
% 
% 
% 
% 

By now, a rich literature on stochastic optimal control is available, with optimality conditions characterized by the dynamic programming principle as Hamilton-Jacobi-Bellman (HJB) partial differential equations (PDEs) \cite{Lions1983,Peng1992,Yong1999}, and by the Pontryagin Maximum Principle (PMP) as forward-backward stochastic differential equations (FBSDEs)  \cite{Peng1990,Yong1999,Frankowska2018,Bonalli2023}. 
For  % 
problems with linear dynamics and linear-quadratic costs, both approaches lead to tractable  solutions characterized by stochastic Riccati equations \cite{Bismut1976,Peng1992,Tang2003}. 
However, for general nonlinear problems, solving HJB-PDEs or FBSDEs remains computationally challenging for high-dimensional state spaces, despite recent progress  \cite{Kushner2001,Gobet2016,BonalliLewESAIM2022,E2017}.  
% 
In practice, % 
an effective approach consists of optimizing over a class of solutions $u_t^\theta$ % 
parameterized by finitely-many parameters $\theta\in\R^k$ \cite{Gobet2005,Massaroli2022} (see \cite{LiSDEs2020,Kidger2022} for machine learning applications). However, restricting % 
solutions to a finite-dimensional space may obscure the structure of solutions and lead to suboptimality. 
% 
For example, in deterministic optimal control, the PMP can provide closed-form expressions for optimal controls, such as bang-bang controls \cite{Leparoux2022}, that drastically reduce the search space % 
and guide the design of indirect methods \cite{Trelat2012,Bonalli2018} for efficient and accurate numerical resolution. 
% 
Thus, in this work, our main motivation  is to derive % 
a stochastic PMP that is as close as possible to the deterministic PMP. In particular, we seek optimality conditions that are interpreted pathwise and do not rely on FBSDEs, % 
to guide  the  future development of efficient algorithms inspired by deterministic optimal control techniques. 

 

Rough path theory \cite{Lyons2002,Lyons2007,Friz2010,Friz2020,Allan2021} provides a deterministic framework of  \textit{pathwise} integration against irregular signals such as sample paths of Brownian motion and has been recognized as a robust tool for stochastic calculus. 
% 
% 
% 
% 
Pathwise stochastic optimal control \cite{HADavis1992,Rogers2007,Bhauryal2024} has been studied using rough path theory in \cite{Diehl2016,Allan2020}, but this formulation results in anticipative controls. % 
In contrast, we focus on optimizing objectives averaged over random realizations of the driving rough path under deterministic open-loop controls, which is a more standard formulation % in stochastic optimal control
 as  open-loop controls are practical for implementation
% 
\cite{Blackmore2011,Berret2020,Leparoux2024,LewMPC2024}. However, using rough path theory in this classical setting presents two main challenges. 
% 
First, we cannot directly use the techniques for proving the PMP from \cite{Diehl2016} as  state constraints are not accounted for.  
% 
Second, the pathwise error bounds for solutions to RDEs  in \cite{Diehl2016,Allan2020}  % 
are too crude to be integrable in general, % 
so they  cannot be used in our setting that requires error bounds with integrable constants.  
To address the first challenge, we adapt 
% 
% 
% 
standard arguments for proving the deterministic PMP via needle-like variations and Brouwer's fixed point theorem \cite{LeeMarkus1967,Agrachev2004,Bonnard2005,BonalliLewESAIM2022}. % 
To address the second challenge, we derive finer error bounds % 
by leveraging greedy partitions and favorable integrability properties of Gaussian rough paths \cite{Cass2013,Friz2013}.

\textbf{Problem setting}. We % 
 consider 
stochastic optimal control problems (\ocp) with deterministic controls% 
\begin{equation}\label{OCP}% 
\tag{\ocp}
\begin{cases}
\min\limits_{u\in L^\infty([0,T],U)} \qquad 
	&\E\left[
\int_0^T f(t,x_t,u_t)\dd t+g(x_T)\right]
\\
\ \ \textrm{such that} \quad\ \  
&
x_t = x_0+\int_0^t b(s,x_s,u_s)\dd s +\int_0^t  \sigma(s,x_s)\dd\mbB_s,
\quad t\in[0,T],
\\[1mm]
&\E\left[h(x_T)\right]=0,
\end{cases}
\end{equation}
where the  differential 
equation $\dd x_t = b(t,x_t,u_t)\dd t +\sigma(t,x_t)\dd\mbB_t$  is a random rough differential equation (RDE) % 
defined pathwise  \cite{Lyons2002,Lyons2007,Friz2010,Friz2020,Allan2021} as in Theorem \ref{thm:rdes:integrable}, and the sample paths of the stochastic process $\mbB$ are Gaussian rough paths  \cite{Cass2013,Friz2013,Friz2020} as in Theorem \ref{thm:gaussian_rough_paths}, see Assumption \ref{assum:pmp} for definitions. 
% 
In particular, if $\mbB=(B,\bB)$ is the Stratonovich lift of a Brownian motion $B$, then the RDE in \ocp % 
is equivalent to the Stratonovich SDE in \eqref{eq:SDE}  \cite[Theorem 9.1]{Friz2020} and  \ocp is a classical optimal control problem.
% 
% 

\textbf{Main contributions}. 
First, we prove the well-posedness and various regularity and integrability results for solutions to (random) RDEs  under regularity assumptions on $(b,\sigma,\mbB)$, see for example Proposition \ref{prop:rdes:error_bound:entire_interval} and Theorem \ref{thm:rdes:integrable}. Such RDEs are outside the scope of classical results in rough path theory due to the presence of the  control input $u$ which is potentially irregular, and previous error bounds in \cite{Diehl2016,Allan2020} that are derived pathwise for a deterministic rough path $\mbB$ are not integrable in general, even if $\mbB$ is the Stratonovich lift of a Brownian motion. % 
% 

Second, we derive the first-order necessary optimality conditions for \ocp stated below. 
Notations are described in Section \ref{sec:preliminaries}. The assumptions are stated in Assumption \ref{assum:pmp} in Section \ref{sec:pmp_proof}.
% 
\begin{theorem}[Rough Stochastic Pontryagin Maximum Principle (\PMP)]\label{thm:pmp}\label{PMP} 
Define $T,\ell,U,\Omega,\Prob,b,\sigma,f$, $g,h,x_0$, the  enhanced Gaussian process $\mbB$ % 
as in  Assumption \ref{assum:pmp}, % 
% 
and 
 the Hamiltonian 
% 
% 
% 
% 
% 
% 
\begin{align}\label{eq:hamiltonian}
H:[0,T]\times\R^n\times U\times\R^n\times\R\to\R,\  (t,x,u,p,\mathfrak{p}_0)\mapsto p^\top b(t,x,u)+\mathfrak{p}_0f(t,x,u).
\end{align}
Let $(x,u)\in L^\ell(\Omega,C([0,T],\R^n))\times L^\infty([0,T],U)$ be an optimal solution to \ocp, where  $x$ solves the random RDE in \ocp  in the pathwise sense of Theorem \ref{thm:rdes:integrable}. 

Then, there exists a stochastic process $p\in L^\ell(\Omega,C([0,T],\R^n))$, called adjoint vector, 
and 
non-trivial Lagrange multipliers $(\mathfrak{p}_0,\dots,\mathfrak{p}_r)\in\{-1,0\}\times \R^r$ % 
 % 
such that:
\begin{enumerate}[label=(\roman*)]
\item \textbf{Adjoint equation}: for some initial conditions $p_0\in L^\ell(\Omega,\R^n)$, the adjoint vector solves the random RDE % 
% 
% 
\footnote{Each component of the  term $\frac{\partial\sigma}{\partial x}(t,x)^\top p\in\R^{n\times d}$ in  the adjoint equation \eqref{eq:spmp:pmp_equations} is % 
$\big[\frac{\partial\sigma}{\partial x}(t,x)^\top p\big]_{ij}
=
\sum_{k=1}^n 
\frac{\partial\sigma_{kj}}{\partial x_i}(t,x) [p]_k$.}
% 
% 
% 
% 
% 
% 
% 
\begin{align}\label{eq:spmp:pmp_equations}
p_t
=
p_0
-\int_0^t\frac{\partial H}{\partial x}(s,x_s,u_s,p_s,\mathfrak{p}_0)\dd s
-
\int_0^t
\frac{\partial\sigma}{\partial x}(s,x_s)^\top p_s\dd\mbB_s,
\quad 
t\in[0,T]
\end{align}
in the pathwise sense of Theorem \ref{thm:rdes:integrable}.
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\item \textbf{Transversality condition}: almost surely, the final value of the adjoint vector satisfies
\begin{gather}
\label{eq:spmp:transversality_condition:pT} 
p_T
=
\mathfrak{p}_0
\frac{\partial g}{\partial x}(x_T)
+
\sum_{i=1}^r
\mathfrak{p}_i
\frac{\partial h_i}{\partial x}(x_T).
\end{gather}
% 
\item \textbf{Maximality condition}: for almost every $t\in[0,T]$, the optimal control  satisfies
\begin{align}\label{eq:spmp:maximizality_condition}
u_t
=
\mathop{\arg\max}_{v\in U}\,
\E\left[
H(t,x_t,v,p_t,\mathfrak{p}_0)
\right].
% 
\end{align} 
% 
\end{enumerate}
\end{theorem}
The similarity to the deterministic setting is striking. The Hamiltonian $H$ remains unchanged, the adjoint equation is interpreted pathwise and has the same drift term $-\frac{\partial H}{\partial x}$, 
the transversality condition is identical (pathwise almost surely), and 
the only difference in the maximality condition 
% 
is an expected value. 
The adjoint equation \eqref{eq:spmp:pmp_equations} is \textit{not} an FBSDE, which is the key to unlock a practical indirect shooting method. 




 
\textbf{Indirect shooting method}. These optimality conditions % 
inform the design of % 
an indirect  method for nonlinear stochastic optimal control. That is, % 
if we approximate all expectations in \ocp and \pmp using sample average (Monte Carlo) estimates for a sample size $M$, the search for (approximate) solutions to \ocp amounts to finding multipliers $(\mathfrak{p}_j)_{j=1}^r\in\R^r$ and initial values of the adjoint vector  $(p_0^i)_{i=1}^M\in\R^{Mn}$ satisfying
\begin{align*}
\begin{bmatrix}
\frac{1}{M}\sum_{i=1}^Mh(x_T^i)
\\
\mathfrak{p}_0
\frac{\partial g}{\partial x}(x_T^1)
+
\sum_{j=1}^r
\mathfrak{p}_j
\frac{\partial h_j}{\partial x}(x_T^1)
\\
\vdots
\\
\mathfrak{p}_0
\frac{\partial g}{\partial x}(x_T^M)
+
\sum_{j=1}^r
\mathfrak{p}_j
\frac{\partial h_j}{\partial x}(x_T^M)
\end{bmatrix}
{=}
\begin{bmatrix}
0
\\[2pt]
p_T^1
\\[2pt]
\vdots
\\[2pt]
p_T^M
\end{bmatrix}
% 
% 
%\, 
\text{where}
% 
% 
\begin{cases}
x_T^i = x_0^i+
\int_0^T\hspace{-1pt}
b(t,x_t^i,u_t^M)\dd t +
\int_0^T\hspace{-1pt}
\sigma(t,x_t^i)\dd\mbB_t^i
\\[2mm]
p_T^i
=
p_0^i
-\int_0^T\hspace{-1pt}
\frac{\partial H}{\partial x}(t,x_t^i,u_t^M,p_t^i,\mathfrak{p}_0)\dd t
-
\int_0^T\hspace{-1pt}
\frac{\partial\sigma}{\partial x}(t,x_t^i)^\top\hspace{-1pt} p_t^i\dd\mbB_t^i
\\[1mm]
% 
u_t^M=
\mathop{\arg\max}\limits_{v\in U}
\frac{1}{M}\sum\limits_{i=1}^M
H(t,x_t^i,v,p_t^i,\mathfrak{p}_0)
\text{ for a.e. }
t\in[0,T].
\end{cases}
\hspace{-4mm}
\end{align*} 
% 
Assuming that the maximality condition gives a closed-form expression of the control $u_t^M$ as a function of $(x_t^i,p_t^i)_{i=1}^M$ (e.g., as is often the case for control-affine systems), the final values $(x_T^i,p_T^i)_{i=1}^M$ can be computed as a function of $(p_0^i)_{i=1}^M$ by integrating the corresponding RDEs pathwise. Then, solutions $\big((\mathfrak{p}_j)_{j=1}^r,(p_0^i)_{i=1}^M\big)\in\R^{r+Mn}$ to this system of $(r+Mn)$ equations can be efficiently found via  a root-finding Newton method. 


\begin{figure}[t]
\centering
\rotatebox{90}{\quad\quad\hspace{0pt}
\fbocp
\quad\hspace{-7pt}
\olocp}
\hspace{1mm}
\includegraphics[width=0.95\textwidth,trim={5mm 6mm 5mm 5mm},clip]{figs/openloop_feedback.png}
\vspace{-1mm}
\caption{Solutions to the open-loop (\olocp) and feedback (\fbocp) optimal control problems in Section \ref{sec:example} computed using the \texttt{Indirect} method. For \fbocp, we plot the closed-loop control trajectories $u_t^i=K_tx_t^i$.}
\vspace{-2mm}
\label{fig:openloop_feedback}
\end{figure}


This approach is %commonly 
known as an indirect shooting method in deterministic optimal control \cite{Trelat2012}, and is a natural extension to the stochastic setting using \pmp and a sample average approximation  \cite{Phelps2016,Shapiro2021,Lew2024,Melnikov2024}. 
To our knowledge, this method has not appeared in the literature yet, % 
% 
as previous optimality conditions  rely on FBSDEs that introduce greater complexity. 
Indeed, previous indirect methods use deep learning to solve the FBSDEs from the classical stochastic PMP \cite{Pereira2019,Carmona2021,E2017}, whereas this indirect method does not require training a
neural network and uses a Newton method instead.  
 While we do not derive guarantees for this method (such as asymptotic optimality) %(e.g., asymptotic optimality or robustness to discretization) 
 and thus treat it as a heuristic informed by \pmp, we evaluate it on an example in Section \ref{sec:example} and show that it is substantially faster ($10\times$ speedup) % 
 than  a direct method \cite{Lew2024} solving the sample average approximation of \ocp via sequential quadratic programming. 

%
Figure \ref{fig:openloop_feedback} shows the solutions returned by this indirect method for two problems without final cost and state constraints ($g=h=0$), see Section \ref{sec:example}. The sample paths of the adjoint vector start from different initial conditions $p^i_0$ and are all zero at the final time ($p^i_T=0$) to satisfy the transversality condition \eqref{eq:spmp:transversality_condition:pT}.

% 
% 
% 
% 
% 
\textbf{Connections to classical stochastic optimal control}. 
If $B$ is a Brownian motion with filtration $(\F_t)_{t\in[0,T]}$, the initial conditions $x_0$ are $\F_0$-measurable, and  $\mbB$ is the Stratonovich lift of $B$, then \ocp is equivalent to the classical stochastic optimal control problem
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\begin{align*}
\min\limits_{u\in L^\infty([0,T],U)} \,
\E\bigg[
\int_0^T \hspace{-1mm}
f(t,x_t,u_t)\dd t+g(x_T)
\bigg]
\  \textrm{s.t.} \   \,
x_t = x_0+\int_0^t b(s,x_s,u_s)\dd s +\int_0^t  \sigma(s,x_s){\circ}\dd B_s,
\ 
\E\left[h(x_T)\right]=0
\end{align*}
% 
with  a Stratonovich SDE. % 
Thus, Theorem \ref{thm:pmp} applies to this standard setting % 
with the following observations.  
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\begin{itemize}
\item \textit{Pathwise adjoint equation}:  The  adjoint equation \eqref{eq:spmp:pmp_equations} is still understood pathwise in the rough path sense, as the adjoint vector $p$ is defined pathwise with initial conditions $p_0$ that depend on the entire path of $\mbB$ (i.e., $p_0$ is not $\F_0$-measurable, so \eqref{eq:spmp:pmp_equations} cannot be replaced by a Stratonovich SDE), 
see Section \ref{sec:pmp_proof}. % 
Rough path theory is a natural framework to make sense of this equation. In contrast,  the classical stochastic PMP \cite{Peng1990,Yong1999,Bonalli2023} relies on It\^o calculus and FBSDEs.  % 
% 
\item 
\textit{Gaussian rough paths}: 
Our results hold for a large class of Gaussian rough paths (see Assumption \ref{assum:Gaussian_lift} and the many examples in \cite{Friz2016}). % 
For example, fractional Brownian motion (fBM) satisfies our assumptions \cite{Bayer2016} and has  applications in finance \cite{Guasoni2006}, yet fBM (except for Brownian motion) is not a semimartingale \cite{Bayer2016} and thus cannot be handled via It\^o (or Stratonovich) integration.  
% 
\item \textit{Regularity of the diffusion $\sigma$}: % 
% 
Our results rely on stronger regularity assumptions on $\sigma$ than the classical PMP. % 
Informally, 
% 
% 
rough path theory cannot distinguish between It\^o and Stratonovich integration, and an It\^o SDE can be written as a Stratonovich SDE with a correction term involving derivatives of $\sigma$, so we expect smoothness assumptions on $\sigma$ to be stronger than if using It\^o calculus \cite[Section 4.1]{Perkowski2016}. On the other hand, these assumptions unlock stronger pathwise regularity results with respect to the driving process $\mbB$ (for example, Proposition \ref{prop:rdes:error_bound:entire_interval}) that may be of independent interest. % 

\item \textit{Independence of the diffusion $\sigma$ on the control $u$}: Our results rely on the independence of $\sigma$ on  $u$, as allowing a dependence on the control $u$ may lead to a degenerate formulation  with irregular controls as described in \cite{Diehl2016,Allan2020}, and rough path theory relies on coefficients that are smooth-enough in time. 



% 
% 
% 
% 
\item \textit{Feedback control}: 
We only optimize over deterministic open-loop controls $u$, which ensures that solutions are non-anticipative and  can  be implemented in applications.  
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
However, considering open-loop controls is more restrictive than optimizing over % 
stochastic non-anticipative feedback controls. We leave this generalization to future work, e.g., via pathwise approaches \cite{Diehl2016,Allan2020} or suitable non-anticipative parameterizations \cite{Gobet2005,Massaroli2022,Bank2024}. 
Solving open-loop stochastic optimal control problem  remains computationally challenging today and % 
in practice, a feedback controller is often pre-specified and  open-loop controls are recomputed in real-time in a receding horizon via model predictive control \cite{Houska2018,LewMPC2024}, which yields feedback and is often  effective. 
% 
\pmp does inform the search of optimal closed-loop controls with fixed parameterization, see Section \ref{sec:example} for a feedback optimization example. 
\end{itemize}

% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 




\textbf{Sketch of proof and paper outline}. We adapt the proof of the deterministic PMP based on needle-like variations   \cite{LeeMarkus1967,Agrachev2004,Bonnard2005,BonalliLewESAIM2022} to the stochastic setting by leveraging recent results in rough path theory \cite{Cass2013,Friz2013} to enable a pathwise analysis. % 
The main steps of the proof of \pmp and the paper outline are below.
\begin{itemize}
\item In Section \ref{sec:preliminaries}, we review concepts in rough path theory  and Gaussian rough paths. %In particular, g
Given a rough path $\mbX$, we will partition the interval $[0,T]$ with a greedy partition \cite{Cass2013,Friz2013} of $N_{\alpha}(\mbX)$ increments whose size is a function of the $p$-variation of the rough path $\mbX$. Importantly, for Gaussian rough paths $\mbX=\mbB(\omega)$, the number of increments $N_{\alpha,[0,T]}(\mbB)$ enjoys favorable integrability properties. % 
\item In Section \ref{sec:rdes}, we first prove existence and unicity of solutions to nonlinear and linear RDEs, used to describe the evolution of the dynamical system in \ocp and the adjoint equation \eqref{eq:spmp:pmp_equations}. 
Such results are slightly outside the scope of classical results in rough path theory due to the presence of the control $u$ (results in \cite{Diehl2016,Allan2020} do not directly apply since $(b,\sigma)$ are time-varying and the map $t\mapsto b(t,\cdot,u_t)$ is not smooth enough  to append time $t$ to the state $x$ and use previous  results). 
% 
Then, we derive error bounds for RDEs using  greedy partitions and the quantity $N_{\alpha}(\mbB)$, % 
% 
and 
% 
% 
% 
 obtain the integrability of solutions to random RDEs driven by Gaussian rough paths and of their Jacobian (Theorem \ref{thm:rdes:integrable}), and integrable error bounds for  solutions to RDEs with different control inputs  and initial conditions (Corollary \ref{cor:rdes:integrable:error_bound}).

% 
% 

\item In Section \ref{sec:pmp}, 
% 
% 
% 
% 
we state the assumptions for \pmp (Assumption \ref{assum:pmp}) and prove the result. The proof uses a standard technique based on needle-like variations and a separation hyperplane argument using Brouwer's fixed point theorem \cite{LeeMarkus1967,Agrachev2004,Bonnard2005}. The main differences with classical proofs of the PMP of It\^o type \cite{BonalliLewESAIM2022} are the pathwise use of It\^o's Lemma for rough paths (Lemma \ref{lem:rough_path:ito_formula}) and defining the adjoint vector pathwise using a rough  differential equation instead of  an FBSDE. 
\end{itemize}
We implement the indirect shooting method  on an example in Section \ref{sec:example} and conclude in Section \ref{sec:conclusion}. Additional proofs are provided in the  
\ifarxiv
appendix.
\else
supplementary material.
\fi


\section{Preliminaries}\label{sec:preliminaries}
%\textbf{Notations.} 
We use the following standard notations  \cite{Bugini2024}. 
Given $a,b\in\R\cup\{\infty\}$, $a\wedge b:=\min(a,b)$. 
Given $a,b\in\R^n$, we write $a^\top b=\sum_{i=1}^na_ib_i$ for the inner product.  
The Kronecker product is denoted by $\otimes$. 
Let   $E,\tilde{E},F$  be  Banach spaces (usually $E=\R^n$).  
The space of linear and continuous functions from $E$ to $F$ is denoted by $\L(E,F)$ and is 
% 
endowed with the norm $\|A\|=\sup_{x\in E,\|x\|\leq 1}\|A(x)\|$ such that $\|Ax\|\leq\|A\|\|x\|$ for any $A\in\L(E,F)$ and $x\in E$. We use the usual identifications $\L(\R^n,\R^m)\cong\R^n\otimes\R^m\cong\R^{n\times m}$ where $\R^{n\times m}$ is the matrix space, 
and 
$\L(E\otimes\tilde{E},F)\cong\L(E,\L(\tilde{E},F))\cong\L^2(E\times\tilde{E},F)$ is the space of bilinear and continuous maps from $E\times\tilde{E}$ to $F$. 
Given a function $f:E\to F$, we write $\|f\|_\infty:=\sup_{x\in E}\|f(x)\|$, and say that $f$ is bounded if $\|f\|_\infty<\infty$. 
Given $g:E\to\R$, we write $f(x)=o(g(x))$ if $\|f(x)\|/\|g(x)\|\to 0$ as $x\to 0$. 
A function $f:E\to F$ is said to be continuously differentiable  (in Fr\'echet sense) if there exists
a continuous map $\nabla f: E\to \L(E, F)$ such that $f(y) - f(x) - \nabla f(x)(y - x) = o(\|y - x\|)$. Partial derivatives and higher order derivatives $\nabla^k f$ are defined as usual.  
Given $n\in\N$, % 
% 
$C^n=C^n(E,F)$  denotes the space of continuous functions $f:E\to F$ that are $n$-times continuously differentiable, 
% 
and $C_b^n=C_b^n(E,F)$ denotes 
the space of bounded functions $f\in C^n(E,F)$   with bounded derivatives. 
 % 
The space $C_b^n$ is 
endowed with the norm
$\|f\|_{C_b^n}:=\|f\|_\infty+\|\nabla f\|_\infty+\dots+\|\nabla^n f\|_\infty<\infty$. 
%Any function $f\in C_b^n$ satisfies the mean value theorem $
%f(x+h)=f(x)
%+
%\frac{1}{k!}\sum_{k=1}^{n-1}\nabla^k f(x)h^{\otimes k}
%+
%\frac{1}{(n-1)!}
%\int_0^1
%\nabla^nf(x+\theta h)
%h^{\otimes n}
%(1-\theta)^{n-1}\dd\theta$. 
%% 

Let $T>0$. For any interval $I=[s,t]\subseteq[0,T]$, we write $|I|=|t-s|$. Given a path $X:[0,T]\to\R^n$, its increments are denoted by $X_{s,t}:=X_t-X_s$ for any $s,t\in[0,T]$. We denote by $\Delta_{[0,T]} := \{(s,t):0\leq s\leq t\leq T\}$  the standard $2$-simplex.  
% 
% 
Let $C([0,T],\R^n)$ be the set of continuous maps $x:[0,T]\to\R^n$ and $(\Omega,\F,\Prob)$ be a probability space. % 
% 
% 
% 
% 
% 
% 
% 
% 
% 
For $\ell\in\N$, we denote by 
$L^\ell(\Omega,\R^n)$ the set of random variables $x:\Omega\to\R^n$ such that $\E[\|x\|^\ell]<\infty$, and 
by $L^\ell(\Omega,C([0,T],\R^n))$ the set of stochastic processes with continuous sample paths $x:\Omega\to C([0,T],\R^n)$ such that $\E[\|x\|_\infty^\ell]<\infty$. 
Given $U\subseteq\R^n$, we denote by  $L^\infty([0,T],U)$ the set of measurable maps $u:[0,T]\to U$ with $\|u\|_{L^\infty([0,T],U)}:=\inf\{C : \|u_t\|\leq C\text{ for almost every }t\in[0,T]\}<\infty$. 
Throughout derivations, we denote by $C_a$  a constant that depends only on $a$ and can change line by line. 


\subsection{Rough paths, controlled rough paths, and rough integration}\label{sec:preliminaries:rough_paths}

We recall concepts in rough path theory \cite{Friz2010,Friz2020,Allan2021}. 
The main tool we use for  quantifying the regularity of a path $X:[0,T]\to\R^n$ is the notion of  % 
 $p$-variation, which  bounds the sum  of increments $\|X_{s,t}\|^p$ of $X$ over arbitrary partitions of $[0,T]$. For example, Lipschitz continuous paths $X$ have finite $1$-variation, and sample paths $B_{s,t}(\omega)$ of Brownian motion have finite $p$-variation for $p>2$ almost surely. 
Rough path theory can also be studied using  $\frac{1}{p}$-H\"older continuity properties (note that a path that is $\frac{1}{p}$-H\"older continuous has finite $p$-variation), but the resulting analysis gives bounds that are generally not integrable (see Section \ref{sec:preliminaries:greedy_gaussian_paths} for further discussion), which motivates using a rough path analysis via $p$-variation properties.

% 
\begin{definition}[$p$-variation]
Let $p\geq 1$ and $T>0$. The $p$-variation  of a path $X:[0,T]\to\R^n$  is defined as
$$
\|X\|_p
:=
\|X\|_{p,[0,T]},
\ \ \text{where }\ \,
\|X\|_{p,[s,t]}
:=
\bigg(
\sup_{\pi\in\mathcal{P}([s,t])}\sum_{[u,v]\in\pi}\|X_{u,v}\|^p
\bigg)^{\frac{1}{p}}
\  
\text{for any $[s,t]\subseteq[0,T]$},
$$
where  $\mathcal{P}([s,t])$ denotes the set of all partitions of $[s,t]$, 
and the supremum is over all partitions $\pi$ of $[s,t]$.  

The set $\C^p=\C^p([0,T],\R^n)$ denotes the space of $\R^n$-valued continuous paths of finite $p$-variation, that is, continuous paths  $X:[0,T]\to\R^n$ such that $\|X\|_p<\infty$. 
\end{definition}

  \begin{lemma}[Stitching a partition of an interval {\cite[Lemma 2.3]{Allan2020}}]\label{lem:pvar:intervals}
 Let $p\geq 1$, $T>0$,  $0=t_0<t_1<\dots<t_n=T$ be a partition of $[0,T]$, and  $X:[0,T]\to\R^n$ be a path. Then, $
\|X\|_{p,[0,T]}\leq n\big(
\sum_{i=1}^n\|X\|_{p,[t_{i-1},t_i]}^p
\big)^{1/p}$. 
\end{lemma}


\begin{lemma}[Inequalities for  $p$-variations]
\label{lem:pvariation:inequalities}
Let $T>0$, $p\geq 1$, and $X\in\C^p([0,T],\R^d)$. Then,
\begin{equation}
\label{eq:path_finite_var:infty_ineq}
\|X\|_\infty\leq
\|X_0\|+\|X\|_p.
\end{equation}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Let $X:[0,T]\to\R^d$, $Y^1,\dots,Y^n\in\C^p([0,T],\R^d)$, 
and $c\geq 0$. 
Then, there exists a constant $C_p\geq 1$ such that
% 
% 
% 
% 
% 
% 
% 
% 
% 
\begin{equation}
\label{eq:path_finite_var:sum_pvars}
\|X_{s,t}\|\leq \sum_{i=1}^n\|Y^i_{s,t}\|
+
c|t-s|
\ \forall s,t\in[0,T]
\implies 
\|X\|_p\leq C_p
\left(
\sum_{i=1}^n\|Y^i\|_p+c\,T
\right).
\end{equation}
Let $p\geq 2$, $X:[0,T]\to\R^d$, $Y^i,\tilde{Y}^i\in\C^p$ for $i=1,\dots,n$, $Z^j\in\C^\frac{p}{2}$ for $j=1,\dots,m$. % 
Then, $\|X\|_p\leq\|X\|_\frac{p}{2}$, and there exists a constant $C_p\geq 1$ such that
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
{\small
\begin{equation}\label{eq:path_finite_var:sum_p/2vars}
\|X_{s,t}\|\leq \sum_{i=1}^n\|Y^i_{s,t}\|\|\tilde{Y}^i_{s,t}\|
+\sum_{j=1}^m\|Z^j_{s,t}\|
+
c|t-s|
\ \forall s,t\in[0,T]
\implies 
\|X\|_\frac{p}{2}\leq C_p\left(\sum_{i=1}^n\|Y^i\|_p\|\tilde{Y}^i\|_p+\sum_{j=1}^m\|Z^j\|_\frac{p}{2}+c\,T
\right).
\end{equation}
}% 
Let $p\geq 1$, $\sigma\in C^1_b([0,T]\times\R^n,\R^m)$, and $X\in\C^p([0,T],\R^n)$.  Then, there exists  $C_p\geq 1$ such that
\begin{equation}\label{eq:sigma(.,X):pvar}
\|\sigma(\cdot,X)\|_p\leq C_p\|\sigma\|_{C^1_b}(\|X\|_p+T).
\end{equation}
Moreover, if $\sigma\in C^2_b$ and $X,\tilde{X}\in\C^{p}$, then there exists  $C_p\geq 1$ such that
\begin{equation}\label{eq:Delta_sigma(.,X):pvar}
\|\sigma(\cdot,X_\cdot)-\sigma(\cdot,\tilde{X}_\cdot)\|_p\leq 
C_p\|\sigma\|_{C^2_b}
(
1 + \|X\|_p+\|\tilde{X}\|_p
+
T
)
(\|X_0-\tilde{X}_0\|+\|X-\tilde{X}\|_p).
\end{equation}
 \end{lemma}
 The results in Lemma \ref{lem:pvariation:inequalities} are standard and are proved in the 
 \ifarxiv
appendix.
\else
supplementary material.
\fi
% 
% 
% 
 

  
 \begin{definition}[Rough path]
 Let $p\in[2,3)$ and $T>0$. A $p$-rough path is a pair $\mbX=(X,\bX)$ that consists of a path $X:[0,T]\to\R^d$ and its enhancement $\bX:\Delta_{[0,T]}\to\R^{d\times d}$ that satisfy Chen's relation	 
\begin{equation}\label{eq:chen's_relation}
% 
\bX^{ij}_{s,t}=\bX^{ij}_{s,r}+\bX^{ij}_{r,t}+X^i_{s,r} X^j_{r,t}
\end{equation}
for all $1\leq i,j\leq d$ and $0\leq s\leq r\leq t\leq T$,
and that has finite inhomogeneous $p$-variation rough path norm:
$$
\|\mbX\|_p:=\|X\|_p+\|\bX\|_{\frac{p}{2}}<\infty,
\quad\text{where}\quad
\|\bX\|_{\frac{p}{2},[s,t]}:=\bigg(\sup_{\pi\in\mathcal{P}([s,t])}\sum_{[u,v]\in\pi}
\|\bX_{u,v}\|^{\frac{p}{2}}\bigg)^{\frac{2}{p}}
\  
\text{for any $[s,t]\subseteq[0,T]$},
$$
and $\|\bX\|_{\frac{p}{2}}:=\|\bX\|_{\frac{p}{2},[0,T]}$. We also write $\|\mbX\|_{p,[s,t]}:=\|X\|_{p,[s,t]}+\|\bX\|_{\frac{p}{2},[s,t]}$ for any $[s,t]\subseteq[0,T]$. 

A geometric $p$-rough path is a  $p$-rough path $\mbX=(X,\bX)$ that additionally satisfies
\begin{equation}\label{eq:rough_path:integration_by_parts}
% 
% 
\bX^{ij}_{s,t}+\bX^{ji}_{s,t}=X^i_{s,t}X^j_{s,t}
\end{equation}
 for all $1\leq i,j\leq d$ and $(s,t)\in\Delta_{[0,T]}$. % 
% 
 
The sets $\sC^p=\sC^p([0,T],\R^d)$ and $\sC^p_g=\sC^p_g([0,T],\R^d)$ denote the sets of $p$-rough paths and of geometric $p$-rough paths, respectively. 
% 

Given two rough paths $\mbX=(X,\bX)\in\sC^p$ and $\widetilde{\mbX}=(\tilde{X},\tilde{\bX})\in\sC^p$, we define $\Delta X:=X-\tilde{X}$, $\Delta\bX:=\bX-\tilde{\bX}$, and % 
\vspace{-2mm}
\begin{align*}
\|\Delta\mbX\|_p:=\|\Delta X\|_p+\|\Delta\bX\|_{\frac{p}{2}}.
\end{align*}
 \end{definition}

Clearly, $\sC^p_g\subset\sC^p$. % 
As an example, the sample paths $\mbX=\mbB(\omega)$ of the Stratonovich lift $\mbB=(B,\bB)$ of a Brownian motion $B$, where $\bB$ is defined by the Stratonovich integrals $\bB_{s,t}^{ij}:=\int_s^tB_{s,u}^i\circ\dd B_u^j$, are geometric rough paths ($\mbB(\omega)\in\sC^p_g$ almost surely). 
The sample paths  of the It\^o lift $\widetilde{\mbB}=(B,\widetilde{\bB})$ of $B$ (with $\widetilde{\bB}$ defined by It\^o integration  $\widetilde{\bB}_{s,t}^{ij}:=\int_s^tB_{s,u}^i\dd B_u^j$) are rough paths ($\widetilde{\mbB}(\omega)\in\sC^p$ almost surely), 
but they are not geometric. 
A key property of geometric rough paths is % 
the chain rule (see Lemma \ref{lem:rough_path:ito_formula}), as a consequence of It\^o's lemma.


\begin{definition}[Controlled rough paths] 
 Let $p\in[2,3)$, $T>0$, and $\mbX=(X,\bX)\in\sC^p([0,T],\R^d)$ be a $p$-rough path. A controlled $p$-rough path (with respect to $X$) is a pair
$$
(Y,Y')\in\C^p([0,T],\R^n)\times\C^p([0,T],\R^{n\times d}),
$$
% 
% 
% 
% 
% 
where $Y'$ is called the Gubinelli derivative of $Y$, such that the remainder term $R^Y:\Delta_{[0,T]}\to\R^n$ given by
\begin{equation}\label{eq:remainder}
R^Y_{s,t}:=Y_{s,t}-Y'_sX_{s,t}
\end{equation}
satisfies $\|R^Y\|_{\frac{p}{2}}<\infty$. 
% 
% 
% 
% 
% 

The set $\sD^p_X=\sD^p_X([0,T],\R^n)$ denotes the set of controlled $p$-rough paths with respect to $X$). 
% 
\end{definition}
A controlled rough path $(Y,Y')\in\sD^p_X$ looks like $X$ over short intervals: $Y_t\approx Y_s+Y'_sX_{s,t}$ for small $|t-s|$. 
For example, $(f(X),\nabla f(X))$ is a controlled rough path if $f\in C^2$.  Controlled rough paths % 
are sufficiently smooth (with respect to the rough path $\mbX$) to allow for a notion of \textit{rough integral} against $\mbX$, defined below.

\begin{proposition}[Rough integration {\cite[Proposition 2.6]{Friz2018}}]
\label{prop:rough_integral_welldefined:error_bound}
Let $p\in[2,3)$, $T>0$, $\mbX=(X,\bX)\in\sC^p([0,T],\R^d)$ be a rough path, and $(Y,Y')\in\sD^p_X([0,T],\R^{n\times d})$  be a controlled rough path. Then, the rough integral of $(Y,Y')$ against $\mbX$, defined as the limit over all partitions $\pi$ of $[0,T]$ with vanishing mesh size
\begin{equation}\label{eq:rough_int}
\int_0^TY_r\dd\mbX_r
:=
\lim_{|\pi|\to0}\sum_{[s,t]\in\pi}Y_sX_{s,t}+Y'_s\bX_{s,t},
\end{equation} 
exists\footnote{We use the identification $\R^{n\times d\times d}=\L(\R^{d \times d},\R^n)$ to make sense of the last term $Y'_s\bX_{s,t}$.}. Moreover, for any $0\leq s<t\leq T$, we have the estimate % 
\begin{equation}\label{eq:rough_int:error_bound}
\left\|\int_s^tY_r\dd\mbX_r-Y_sX_{s,t}-Y'_s\bX_{s,t}\right\|\leq C_p(\|R^Y\|_{\frac{p}{2},[s,t]}\|X\|_{p,[s,t]}+\|Y'\|_{p,[s,t]}\|\bX\|_{\frac{p}{2},[s,t]})
\end{equation} 
 for a constant $C_p$ that only depends on $p$.
\end{proposition} 
For intuition, let $X$ be a scalar-valued path that is sufficiently smooth so that $\bX_{s,t}:=\int_s^t(X_r-X_s)\dd X_r$ is well-defined and $(Y,Y')=(f(X),\nabla f(X))$ with $f\in C^2$ is a controlled path. Then, a Taylor approximation gives
$\int_s^tf(X_r)\dd X_r\approx f(X_s)\int_s^t\dd X_r+\nabla f(X_s)\int_s^t(X_r-X_s)\dd X_r=Y_sX_{s,t}+Y'_s\bX_{s,t}$, which is like the left hand side of \eqref{eq:rough_int:error_bound}. 
The rough integral generalizes this intuition to cases where $X$ is too irregular for the integral $\int_s^tX_{s,r}\dd X_r$ to be well-defined (e.g., if $X$ is a sample of Brownian motion): 
We first define  the enhancement $\bX$ and then define the rough integral of $(Y,Y')$ against $(X,\bX)$  by \eqref{eq:rough_int}.
% 
The term $Y'_s\bX_{s,t}$ is key to ensuring that  \eqref{eq:rough_int} is well-posed and different choices of $\bX$ (e.g., via It\^o or Stratonovich integrals) give different results.

Next, we give a few useful results about rough integration and functions of controlled rough paths. 
Let  $(X,\bX)\in\sC^p$ and $(\tilde{X},\tilde{\bX})\in\sC^p$ be two rough paths,  and  
$(Y,Y')\in\sD^p_X$ and $(\tilde{Y},\tilde{Y}')\in\sD^p_{\tilde{X}}$ be two controlled rough paths. 
We write $\Delta X=X-\tilde{X}$ and similarly for $\Delta Y,\Delta Y',\Delta R^Y$, and as in \cite{Friz2018}, we define 
\begin{align*}
M_{Y'}&:=\|Y_0'\|+\|Y'\|_p,
&& 
\hspace{-4mm}
K_Y:= \|Y_0'\|+\|Y'\|_p+\|R^Y\|_\frac{p}{2} =  M_{Y'}+\|R^Y\|_\frac{p}{2},
\\
\Delta M_{Y'} &:= \|\Delta Y_0'\|+\|\Delta Y'\|_p,
&&
\hspace{-4mm}
\Delta K_Y := \|\Delta Y_0'\|+\|\Delta Y'\|_p+\|\Delta R^Y\|_\frac{p}{2}=\Delta M_{Y'}+\|\Delta R^Y\|_\frac{p}{2}.
\end{align*} 


\begin{lemma}[Stability of rough integration {\cite[Lemma 3.4]{Friz2018}}]
\label{lem:rough_int_stability}
Let $p\in[2,3)$, $T>0$,  
 $\mbX=(X,\bX)\in\sC^p$ and $\widetilde{\mbX}=(\tilde{X},\tilde{\bX})\in\sC^p$ be two $p$-rough paths,  and  
$(Y,Y')\in\sD^p_X$ and $(\tilde{Y},\tilde{Y}')\in\sD^p_{\tilde{X}}$ be two controlled $p$-rough paths. Then,
$
(Z,Z'):=\big(
\int_0^\cdot Y_s\dd\mbX_s,Y
\big) \in\sD^p_X$ and $(\tilde{Z},\tilde{Z}'):=\big(\int_0^\cdot \tilde{Y}_s\dd\widetilde{\mbX}_s,\tilde{Y}\big) \in\sD^p_{\tilde{X}}.
$
Moreover, % 
\begin{align}
% 
% 
% 
% 
\label{lem:rough_int_stability:remainder}
\|R^{\int_0^\cdot Y_s\dd\mbX_s}-R^{\int_0^\cdot \tilde{Y}_s\dd\widetilde{\mbX}_s}\|_{\frac{p}{2}}
&\leq 
C_p
(1+\|\mbX\|_p+\|\widetilde{\mbX}\|_p)
\big(K_{\tilde{Y}}\|\Delta\mbX\|_p+\|\mbX\|_p\Delta K_Y\big),
\end{align}
\end{lemma}



\begin{lemma}[$(\sigma(\cdot,Y),\nabla \sigma(\cdot,Y)Y')$ is a controlled path]\label{lem:rough_path:sigma(.,Y):controlled}
Let $p\in[2,3)$, $T>0$, $\sigma\in C^2_b([0,T]\times\R^n,\R^{n\times d})$, 
$\mbX=(X,\bX)\in\sC^p([0,T],\R^d)$ be a $p$-rough path, and 
$(Y,Y')\in\sD^p_X([0,T],\R^n)$ be a controlled $p$-rough path. Then, 
$(\sigma(\cdot,Y_\cdot),\sigma(\cdot,Y_\cdot)')
:=
\big(\sigma(\cdot,Y_\cdot),\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot)Y'_\cdot
\big)\in\sD^p_X$.  
Moreover, there exists $C_p\geq 1$ such that 
\begin{align}
\label{eq:controlled_path:pvar_norm}
\|Y\|_p&\leq C_p(\|Y'\|_\infty\|X\|_p+\|R^Y\|_\frac{p}{2})
\\
\label{eq:|Y|_p_ineq}
&\leq C_p(1+\|X\|_p)K_Y,
\\
\label{eq:sigma(.,Y):pvar}
\|\sigma(\cdot,Y_\cdot)\|_p&\leq 
C_p\|\sigma\|_{C^1_b}
(
M_{Y'}\|X\|_p+\|R^Y\|_\frac{p}{2}
+
T
),
\\
\label{eq:sigma(.,Y)':pvar}
\|\sigma(\cdot,Y_\cdot)'\|_p&\leq 
C_p\|\sigma\|_{C^2_b}
K_Y(1+K_Y+T)(1+\|X\|_p),
\\
\label{eq:RY:p/2var:Y^2+RY+T}
\|R^{\sigma(\cdot,Y_\cdot)}\|_\frac{p}{2}&\leq
C_p\|\sigma\|_{C^2_b}(
\|Y\|_p^2
+
\|R^Y\|_\frac{p}{2}
+
T
)
\\
\label{eq:RY:p/2var:KYs}
&\leq
C_p\|\sigma\|_{C^2_b}
(
K_Y(1+
K_Y)(1+\|X\|_p)^2
+
T
).
\end{align}
\end{lemma}
We prove Lemma \ref{lem:rough_path:sigma(.,Y):controlled} in the \ifarxiv
appendix.
\else
supplementary material.
\fi
For time-invariant maps $\sigma(t,x)=\sigma(x)$, these results are standard, see e.g. \cite[Lemmas 3.5 and 3.6]{Friz2018}.
% 
% 
% 
% 

% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\begin{remark}[Smoothness of $\sigma$]\label{remark:sigma_smoothness}
The assumption $\sigma\in C^2_b$ implies that  
{\small $\|
\sigma
\|_\infty
+
\|
\frac{\partial\sigma}{\partial t}
\|_\infty
+
\|
\frac{\partial\sigma}{\partial x}
\|_\infty
+
\|
\frac{\partial^2\sigma}{\partial t^2}
\|_\infty
+
\|
\frac{\partial^2\sigma}{\partial x^2}
\|_\infty
+
\|
\frac{\partial^2\sigma}{\partial x \partial t}
\|_\infty
$} %
 is bounded. % 
It is stronger than assumptions on $\sigma$  used for classical PMPs derived via It\^o calculus due to the use of rough path theory, see  Section \ref{sec:introduction} and \cite[Section 4.1]{Perkowski2016}. 
It can be relaxed to assuming that   $\sigma(t,\cdot)\in C_b^2$ for almost every (a.e.) $t\in[0,T]$ and that $\sigma(\cdot,x)$ is uniformly \smash{$\frac{2}{p}$}-H\"older continuous. Under this assumption and similar ones on derivatives $\frac{\partial^k\sigma}{\partial x^k}$, most results in this work still hold by replacing terms in $T$ by terms in $T^\frac{2}{p}$. However, the assumption of $\frac{2}{p}$-H\"older continuity in $t$ is only barely weaker that assuming Lipschitz continuity  (in particular, $\sigma(t,x)=B_t(\omega)$ with $X=B(\omega)$ a sample path of Brownian motion is not $\frac{2}{p}$-H\"older continuous), so we assume that $\sigma\in C_b^n$ to simplify notations and results. % 
Assuming a controlled structure $\sigma_t(\cdot)\approx \sigma_s(\cdot)+\sigma'_s(\cdot)(X_t-X_s)$ \cite{Friz2024,Bugini2024}  could be considered in future work. See also Remark \ref{remark:sigma_smoothness:2}.
\end{remark}
The next result gives a chain rule for functions of  controlled rough paths and geometric rough paths.
\begin{lemma}[It\^o's formula for geometric rough paths]
\label{lem:rough_path:ito_formula}
Let $p\in[2,3)$, $T>0$, $f\in C^3$, 
$\mbX\in\sC^p_g([0,T],\R^d)$ be a geometric $p$-rough path, and 
$(Y,Y')\in\sD^p_X([0,T],\R^n)$ be a controlled $p$-rough path such that 
$$
Y_t=Y_0+\int_0^tY'_s\dd\mbX_s+\Gamma_t 
\ \text{ for all }t\in[0,T],
$$
for a path of finite $\frac{p}{2}$-variation $\Gamma\in\C^{\frac{p}{2}}([0,T],\R^n)$ and a controlled $p$-rough path  $(Y',Y'')\in\sD^p_X([0,T],\R^{n\times d})$.  
Then, 
\begin{equation}\label{eq:rough_path:ito_formula}
f(Y_t)=f(Y_0)+\int_0^t\nabla f(Y_u)Y'_u\dd\mbX_u
+\int_0^t\nabla f(Y_u)\dd\Gamma_u
\end{equation}
for all $t\in[0,T]$, where the first integral is a rough integral, and the second integral is a Young integral.
\end{lemma}
Lemma \ref{lem:rough_path:ito_formula} is standard. It is a particular case of  \cite[Theorem 7.7]{Friz2020}, assuming that the rough path $\mbX$ is geometric so its bracket is zero. Although \cite[Theorem 7.7]{Friz2020} is formulated for $\frac{1}{p}$- and $\frac{2}{p}$-H\"older continuous paths, the proof follows similarly for   finite $p$- and $\frac{p}{2}$-variation paths. It is in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi








\subsection{The greedy partition and Gaussian rough paths}\label{sec:preliminaries:greedy_gaussian_paths}
% 
% 
% 
% 
To prove \PMP, we will use short variations  around the optimal solution % 
 %(the so-called needle-like variations, 
 (see Proposition \ref{prop:linear_variation}), % 
% 
and show that the difference between the solutions to the corresponding rough differential equations is small \textit{in expectation}  over the driving signal $\mbX=\mbB(\omega)$ and initial conditions $x_0$. % 
An immediate 
challenge with this approach is that classical error bounds in rough path theory depend on constants that are typically not integrable \cite{Bayer2016,Cass2017}, as they depend exponentially on the $p$-variation rough path norm  $\|\mbX\|_p$ (see for example \cite[Theorem 3.9]{Friz2018}) or on the exponential of the $\frac{1}{p}$-H\"older constant of $\mbX$ (see e.g. the proof of \cite[Theorem 7.9]{Allan2021} or \cite[Theorem 8.5]{Friz2020}). % 
Thus, we cannot use classical error bounds from rough path theory % 
in the proof of \pmp, as they may not be integrable.

A solution to this challenge was identified in \cite{Cass2013} and refined  in \cite{Friz2013}. % 
It consists of % 
using a quantity $N_\alpha(\mbX)$ that   counts the number of $\alpha$-increments of the homogeneous rough path norm of $\mbX$ over an interval (Definition \ref{def:Nalpha}). Importantly,  for particular \textit{Gaussian rough paths} $\mbB(\omega)$, the exponential of $N_\alpha(\mbB)$ is integrable (Theorem \ref{thm:gaussian_rough_paths}). 
Thus, in this work, we use ideas in \cite{Cass2013,Friz2013} (see also \cite{Bayer2016,Riedel2017,Cass2017,Cass2019}) and derive finer error bounds as a function of $N_\alpha(\mbB)$, which will give us integrable bounds that can be used to prove \pmp. % that are integrable for particular Gaussian rough paths. % 


 
% 

% 
% 
% 
% 
% 
% 
% 
% 

% 
% 
% 
% 
% 
% 
% 
% 
% 

\begin{definition}[Control, greedy partition, and homogeneous $p$-variation rough path norm]\label{def:Nalpha}
Let $T>0$. A control is a continuous map $w:\Delta_{[0,T]}\to\R$  such that $w(t,t)=0$ and $w(s,t)+w(t,u)\leq w(s,u)$ for any $0\leq s\leq t\leq u\leq T$. 
% 
Given a control $w$, a resolution $\alpha>0$ and $[s,t]\subseteq[0,T]$, we  define the sequence
\begin{align*}
\tau_0&=s,
\qquad
\tau_{i+1}=\inf\{u : w(\tau_i,u)\geq \alpha, \tau_i<u\leq t\}\wedge t\ \, \text{for} \ \, i\in\N,
\end{align*}
with the convention $\inf\emptyset=+\infty$, and
$$
N_{\alpha,[s,t]}(w):=\sup \{n\in\N\cup \{0\}:\tau_n< t\}.
$$
The \textit{greedy partition} of the interval $[s,t]$ is defined as the partition
$$
% 
\{\tau_i, i=0,1,\dots,N_{\alpha,[s,t]}(w)+1\}.
$$
% 
% 
% 
% 
Given $p\in[2,3)$ and $\mbX\in\sC^p$, % 
the control  $w_\mbX$ % 
and $N_{\alpha,[s,t]}(\mbX)$  are defined using the homogeneous $p$-variation rough path norm $\opnorm*{\mbX}_{p}:=\|X\|_{p}+\|\bX\|_{\frac{p}{2}}^\frac{1}{2}$ as  $
w_\mbX(s,t)
:=
\|X\|_{p,[s,t]}^p+\|\bX\|_{\frac{p}{2},[s,t]}^\frac{p}{2}$ and $N_{\alpha,[s,t]}(\mbX):=N_{\alpha,[s,t]}(w_\mbX)$.
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\end{definition} 
The \textit{control} $w$ in Definition \ref{def:Nalpha} should not be confused with the \textit{control input} $u$ in \ocp. The distinction should be clear from context: $w$ bounds variations of $\mbX$, whereas $u$ steers the dynamical system in \ocp. 









Our error bounds for solutions to RDEs will depend on (1) the inhomogeneous  rough path norm $\|\mbX\|_p$ due to oscillations of the driving signal $\mbX$ (see \eqref{eq:rough_int:error_bound} and \eqref{lem:rough_int_stability:remainder} which contain terms in  $\|\mbX\|_p$), and on  (2) terms increasing linearly over time  due to the drift $b(t,Y,u)$ and the time-varying diffusion $\sigma(t,Y)$  (see  Lemma \ref{lem:bounds_int_b_ds}, and \eqref{eq:sigma(.,Y):pvar} and \eqref{eq:RY:p/2var:Y^2+RY+T} which contain terms in $+T$). These terms relate 
% 
% 
to the control  $w_\mbX(\cdot)$ and to $N_\alpha(\mbX)$ via Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals},  
% 
using two  lemmas that are similar to \cite[Lemma 4.9]{Cass2013} and \cite[Lemma 5]{Bayer2016}. 
The proofs of Lemmas \ref{lem:Nalpha<=w(0,T)} and   \ref{lem:sum_Nalpha} and of Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals} below are provided in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi

\begin{lemma}\label{lem:Nalpha<=w(0,T)}
Let $T>0$, $w:\Delta_{[0,T]}\to\R$ be a control, and $\alpha>0$. Then, $\alpha N_{\alpha,[0,T]}(w)\leq w(0,T)$. 
\end{lemma}
\begin{lemma}\label{lem:sum_Nalpha}
Let $T>0$, $C\geq1$ be a constant, $w_1,\dots,w_n:\Delta_{[0,T]}\to\R$ be $n$ controls,  and  $w:\Delta_{[0,T]}\to\R$ be the control defined by $w(s,t)=C\sum_{j=1}^n w_j(s,t)$. 
Then, for any $\alpha>0$ and $[s,t]\subseteq[0,T]$,
\begin{equation}\label{eq:Nalpha(w)<=sumNalpha(wj)}
N_{\alpha,[s,t]}(w)
\leq
C\bigg(
2\sum_{j=1}^nN_{\alpha,[s,t]}(w_j)+n
\bigg).
\end{equation}
\end{lemma}

\begin{corollary}\label{cor:Nalpha:NX_NXtilde_NT:small_intervals}
Let $p\in[2,3)$, $T>0$, $\mbX,\widetilde{\mbX}\in\sC^p$, $C_p=6^p$, and define the control  $w:\Delta_{[0,T]}\to\R$  by 
$$
w(s,t)=C_p(w_\mbX(s,t)+w_{\widetilde{\mbX}}(s,t)+|t-s|).
$$
Then,  for any $\alpha>0$ and  $[s,t]\subseteq[0,T]$,
\begin{equation}\label{eq:Nalpha<=3CpNalpha_X_and_time}
N_{\alpha,[s,t]}(w)\leq 5C_p(
N_{\alpha,[s,t]}(\mbX)+N_{\alpha,[s,t]}(\widetilde{\mbX})+|t-s|/\alpha+1
).
\end{equation}
% 
Moreover, given   $0<\alpha\leq 1$  and   any interval $[s,t]\subseteq[0,T]$ small-enough so that  $w(s,t)\leq \alpha$, we have
\begin{equation}\label{eq:|X|+|Xtilde|+|dt|<=alpha^p}
\|\mbX\|_{p,[s,t]}+\|\widetilde{\mbX}\|_{p,[s,t]}+|t-s|\leq
 \alpha^\frac{1}{p}.
\end{equation}
% 
% 
% 
% 
% 
% 
% 
Finally, for $0<\alpha\leq 1$ and any interval $[s,t]\subseteq[0,T]$, with $C_{p,\alpha}=6e\alpha^\frac{1}{p}$,
\begin{equation}\label{eq:||X||_p<=exp(N_alpha^p)}
\|\mbX\|_{p,[s,t]}+\|\widetilde{\mbX}\|_{p,[s,t]}+|t-s|
\leq 
C_{p,\alpha}\exp\left(N_{\alpha,[s,t]}(w)\right).
\end{equation}
\end{corollary}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Next, we introduce \textit{enhanced Gaussian processes}, which are stochastic processes $\mbB=(B,\bB)$ that consist 
of a Gaussian process $B$ and of its enhancement $\bB$ defined so that  the sample paths $\mbB(\omega)=(B(\omega),\bB(\omega))$ are geometric rough paths. The sample paths $\mbB(\omega)$ are  called \textit{Gaussian rough paths}. An example of enhanced Gaussian process is  the Stratonovich lift  of a Brownian motion. % the Stratonovich lift $\mbB$ of a Brownian motion $B$, where $\bB$ is defined by the Stratonovich integrals $\bB_{s,t}^{ij}:=\int_s^tB_{s,u}^i\circ\dd B_u^j$. 
% 
% 
% 
The next assumption ensures that a Gaussian process $B$ can be lifted to an enhanced Gaussian process $\mbB=(B,\bB)$, and that the exponential of $N_{\alpha}(\mbB)$ (which will appear in our analysis through applications of \eqref{eq:Nalpha<=3CpNalpha_X_and_time} and \eqref{eq:||X||_p<=exp(N_alpha^p)}) is integrable. 
This assumption is considered in \cite{Friz2016,Bayer2016}, and is verified for a large number of Gaussian processes \cite{Friz2016}. % 
 
  
 
% 
% 
% 
% 





% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 

 
% 

 

% 
% 
% 
% 
% 
% 
% 
% 

% 
% 
% 
% 

% 
% 
% 


\begin{assumption}[Gaussian process with regular covariance {\cite[Condition 10]{Bayer2016}}]\label{assum:Gaussian_lift}
 Let $T>0$ and $B = (B_1,\dots,B_d)$ % 
 be a centered, continuous, $\R^d$-valued Gaussian process with independent components. Assume that the covariance of every component has H\"older dominated finite mixed $(1, \rho)$-variation for some $\rho\in[1,2)$ on $[0,T]^2$, that is, there exists $K<\infty$ such that for $k =1,\dots,d$, 
uniformly over
$0\leq s < t\leq T$, 
$\sup_{(t_i)\in\mathcal{P}([s,t]),(t_j')\in\mathcal{P}([s,t])
}
(\sum_{t_j'}(\sum_{t_i}
\E[B_{t_i,t_{i+1}}^kB_{t_j',t_{j+1}'}^k]
)^\rho
)^\frac{1}{\rho}\leq K|t-s|^\frac{1}{\rho}.
$
%$$
%\sup_{\substack{
%(t_i)\in\mathcal{P}([s,t])
%\\
%(t_j')\in\mathcal{P}([s,t])
%}
%}
%\left(\sum_{t_j'}\left(\sum_{t_i}
%\E\left[B_{t_i,t_{i+1}}^kB_{t_j',t_{j+1}'}^k\right]
%\right)^\rho
%\right)^\frac{1}{\rho}\leq K|t-s|^\frac{1}{\rho}.
%$$
% 
% 
\end{assumption} 
\begin{theorem}[Enhanced Gaussian process and Gaussian rough paths] % 
\label{thm:gaussian_rough_paths}
Let $T>0$, $\rho\in[1,\frac{3}{2})$, $p\in(2\rho,3)$, $(\Omega,\F,\Prob)$ be a probability space, and $B$  be a centered, continuous, $\R^d$-valued Gaussian process with independent components   satisfying Assumption \ref{assum:Gaussian_lift} for $\rho$. 
% 
% 
% 
Then, there exists a unique stochastic process  $\mbB=(B,\bB)$  
 that is the natural lift of $B$, and whose sample paths are geometric $p$-rough paths, that is, $\mbB(\omega)=(B(\omega),\bB(\omega))\in\sC^p_g([0,T],\R^d)$ almost surely. 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Moreover, for any $\alpha>0$ and $D\geq 0$, 
\begin{equation}\label{eq:gaussian_rough_paths:E[exp(Nalpha)]<infty}
\E\left[\exp\left(DN_{\alpha,[0,T]}(\mbB)\right)\right]<\infty.
\end{equation}
% 
$\mbB$ is called % 
enhanced Gaussian process, and its sample paths $\mbB(\omega)$ are called Gaussian rough paths.
\end{theorem}
The first claim of Theorem \ref{thm:gaussian_rough_paths} is in \cite[Theorem
15.33]{Friz2010}  (or \cite[Theorem 10.4]{Friz2020}, see also \cite[Corollary 2.3]{Friz2016}), 
and the second follows from results in \cite{Friz2013} (see also \cite[Theorem 11]{Bayer2016}). Further details for the proof are provided in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi
% 
% 
% 
% 
% 

In Theorem \ref{thm:gaussian_rough_paths}, the enhancement $\bB$ in the ``natural'' lift $\mbB=(B,\bB)$ can be defined in various equivalent ways, % 
 see \cite[Remark 10.7]{Friz2020}. In \cite[Theorem 10.4]{Friz2020},  the diagonal elements of $\bB$ are defined as $\bB^{ii}_{s,t}=\frac{1}{2}(B_{s,t}^i)^2$, the  off-diagonal terms 
 $\bB^{ij}$ are defined as an $L^2$ limit  $\bB_{s,t}^{ij}:=\lim_{|\pi|\to 0}\sum_{[u,v]\in\pi}B^i_{s,u}B^j_{u,v}$, and the other terms $\bB^{ji}$ are defined as $\bB^{ji}_{s,t}:=-\bB^{ij}_{s,t}+B^i_{s,t}B^j_{s,t}$, so that the algebraic conditions \eqref{eq:chen's_relation} and \eqref{eq:rough_path:integration_by_parts} are satisfied. % 
 See also other equivalent definitions in \cite[Exercise 10.11]{Friz2020} and in \cite[Theorem
15.33]{Friz2010}. 
% 
% 
% 
 
% 
% 
% 
% 
% 
% 
% 
% 


% 
% 
% 
% 
% 
% 
% 

 

% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 



 




 

 
\section{Rough differential equations (RDEs) and error bounds}\label{sec:rdes}
In this section, we study the RDEs% properties of solutions to the rough differential equations (RDE)
\begin{align}
\label{eq:RDE}
Y_t&=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s,
\qquad\qquad\ \ \, t\in[0,T].
\\
\label{eq:RDE:linear}
V_t &=v +  
\int_0^t
\frac{\partial b}{\partial x}(s,Y_s,u_s)V_s\dd s
+  
\int_0^t
\frac{\partial\sigma}{\partial x}(s,Y_s)V_s\dd\mbX_s,
\quad t\in[0,T].
\end{align}
First, in Section \ref{sec:rdes:calculus}, we provide additional results  for controlled rough paths and rough integrals. 
In Section \ref{sec:rdes:existence_unicity}, we show that  solutions to the RDEs \eqref{eq:RDE} and \eqref{eq:RDE:linear} exist and are unique.
In Sections \ref{sec:rdes:bounds} and \ref{sec:rdes:bounds:linear}, we derive bounds for the solutions to these RDEs  by leveraging greedy partitions. Finally, in Section \ref{sec:rdes:random_integrable}, we study  solutions to random RDEs driven by Gaussian rough paths $\mbX=\mbB(\omega)$ and derive integrable errors bounds. For conciseness, the proofs of various results are in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi
 
\subsection{Calculus with rough paths: controlled rough paths and rough integration}\label{sec:rdes:calculus}
The lemmas in this section are variations of results in \cite[Section 3.2]{Friz2018} to highlight constants and to support a diffusion $\sigma$ that is time-varying.  Their long but straightforward proofs are provided in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi

\begin{lemma}[Products of controlled paths are controlled paths]\label{lem:control_path:product}
Let $p\in[2,3)$, $T>0$, $\mbX=(X,\bX)\in\sC^p$, and $(Y,Y'),(Z,Z')\in\sD^p_X$ be two controlled rough paths. Then, $(YZ,(YZ)')\in\sD^p_X$ with Gubinelli derivative 
$(YZ)'=ZY'+YZ'$. 
Moreover,
\begin{align}
\label{lem:control_path:product:YZ_p}
\|YZ\|_p
&\leq
C_p(\|Y\|_\infty\|Z\|_p+\|Z\|_\infty\|Y\|_p),
\\
\label{lem:control_path:product:(YZ)'_p}
\|(YZ)'\|_p
&\leq
C_p(\|Z\|_\infty\|Y'\|_p+\|Y'\|_\infty\|Z\|_p+\|Y\|_\infty\|Z'\|_p+\|Z'\|_\infty\|Y\|_p),
\\
\label{lem:control_path:product:R^YZ_p/2}
\|R^{YZ}\|_\frac{p}{2}
&\leq
C_p(\|Y\|_\infty\|R^Z\|_\frac{p}{2}+\|R^Y\|_\frac{p}{2}\|Z\|_\infty+\|Y\|_p\|Z\|_p).
\end{align}
\end{lemma}



\begin{lemma}[Error bounds for controlled paths]\label{lem:rough_path:f(Y)'-f(tilde(Y))'} 
Let $p\in[2,3)$, $T>0$, $\mbX=(X,\bX)\in\sC^p$ and $\widetilde{\mbX}=(\tilde{X},\tilde{\bX})\in\sC^p$,  
 $(Y,Y')\in\sD^p_X$ and $(\tilde{Y},\tilde{Y}')\in\sD^p_{\tilde{X}}$,  and $\sigma\in C^3_b$. Then, 
\begin{align}\label{eq:controlled_path:Y-Ytilde_p}
\|Y-\tilde{Y}\|_p
&\leq 
C_p\big(\Delta M_{Y'}\|X\|_p+M_{\tilde{Y}'}\|\Delta X\|_p+\|\Delta R^Y\|_\frac{p}{2}\big),
\\
\label{eq:controlled_path:sigma(Y)-sigma(Ytilde)_p}
\|\sigma(\cdot,Y)'-\sigma(\cdot,\tilde{Y})'\|_p
&\leq
C_p\|\sigma\|_{C_b^3}
(1+
K_Y+K_{\tilde{Y}}
)^3
(1+\|X\|_p+\|\tilde{X}\|_p)^3
(
1+T
)
\big(
\\
\nonumber
&\qquad\qquad\qquad\qquad
\|\Delta X\|_p
+
\|\Delta Y_0\|
+
\|\Delta R^Y\|_\frac{p}{2}
+
\|\Delta Y'_0\|
+
\|\Delta Y'\|_p
\big),
\\
\label{eq:controlled_path:R^sigma(Y)-R^sigma(Ytilde)_p/2}
\|R^{\sigma(\cdot,Y)}-R^{\sigma(\cdot,\tilde{Y})}\|_\frac{p}{2}
&\leq 
C_p\|\sigma\|_{C^3_b}
(1+K_Y+K_{\tilde{Y}})^3
(1+\|X\|_p+\|\tilde{X}\|_p)^2
	(
1+T
)
(
\\
\nonumber
&\qquad\qquad\qquad\qquad
\|\Delta Y_0\|+\|\Delta R^Y\|_\frac{p}{2}+\Delta M_{Y'}\|X\|_p+\|\Delta X\|_p).
\end{align}
\end{lemma}
\begin{remark}[Smoothness of $\sigma$]\label{remark:sigma_smoothness:2}
As discussed in Remark \ref{remark:sigma_smoothness}, the assumption that $\sigma$ is smooth in $t$ can be relaxed to assuming that $\sigma(\cdot,x)$ is uniformly \smash{$\frac{2}{p}$}-H\"older continuous. 
% 
% 
% 
% 
% 
% 
% 
However, the proof of the inequality \eqref{eq:controlled_path:R^sigma(Y)-R^sigma(Ytilde)_p/2} for $\|R^{\sigma(\cdot,Y)}-R^{\sigma(\cdot,\tilde{Y})}\|_\frac{p}{2}$ breaks under weaker regularity assumptions. In particular, it breaks if we only assume that $
\|
\sigma(t,x)-
\sigma(s,x)
\|
\leq C|t-s|^{\frac{1}{2}-\epsilon} 
$ (e.g., if $\sigma(t,x)=B_t(\omega)$ is a sample path of  Brownian motion).
\end{remark}



\begin{lemma}[The rough integral $\int\sigma(Y)\dd\mbX$ defines a controlled path]\label{lem:rough_path:intfdX:error_bounds}
Let $p\in[2,3)$, $T>0$, $\mbX=(X,\bX)\in\sC^p$, $(Y,Y')\in\sD^p_X$, and $\sigma\in C^2_b$.  Then, 
$(Z,Z'):=\left(
\int_0^\cdot \sigma(s,Y_s)\dd\mbX_s,\sigma(\cdot,Y_\cdot)
\right)\in\sD^p_X$, 
and   
\begin{align}\label{eq:rough_path:R^int_sig_dX:p/2}
\|R^{\int_0^\cdot \sigma(s,Y_s)\dd\mbX_s}\|_{\frac{p}{2}}&\leq 
C_p\|\sigma\|_{C_b^2}(1+K_Y)^2(1+\|X\|_p)^2(1+T)
\|\mbX\|_p.
\end{align}
\end{lemma}



\begin{lemma}[Error bounds for $(\int\sigma(Y)\dd\mbX-\int\sigma(\tilde{Y})\dd\widetilde{\mbX})$]\label{lem:rough_path:intfdX_fY:error_bounds}
Let $p\in[2,3)$, $T>0$, $\mbX=(X,\bX)\in\sC^p$ and $\widetilde{\mbX}=(\tilde{X},\tilde{\bX})\in\sC^p$,  
$(Y,Y')\in\sD^p_X$ and $(\tilde{Y},\tilde{Y}')\in\sD^p_{\tilde{X}}$,  and $\sigma\in C^3_b$. Then,
%$
%(Z-\tilde{Z},Z'-\tilde{Z}'):=(
%\int_0^\cdot \sigma(s,Y_s)\dd\mbX_s-\int_0^\cdot \sigma(s,\tilde{Y}_s)\dd\widetilde{\mbX}_s,\sigma(\cdot,Y)-\sigma(\cdot,\tilde{Y})
%) 
%$  
%satisfies 
\begin{align}\label{eq:rough_path:intfdX_fY:delta_sigma}
\|\sigma(\cdot,Y)-\sigma(\cdot,\tilde{Y})\|_p
&\leq 
C_p\|\sigma\|_{C^2_b}
(1 + K_Y+K_{\tilde{Y}})^2
(1+\|X\|_p+\|\tilde{X}\|_p+T)
\big(
\\
\nonumber
&\hspace{1.7cm}\|\Delta X\|_p+\|\Delta Y_0\|+(\|\Delta Y_0'\|+\|\Delta Y'\|_p)\|X\|_p+\|\Delta R^Y\|_\frac{p}{2}\big),
\\
\label{eq:rough_path:intfdX_fY:delta_R}
\|R^{\int_0^\cdot \sigma(s,Y_s)\dd\mbX_s}-R^{\int_0^\cdot \sigma(s,\tilde{Y}_s)\dd\widetilde{\mbX}_s}\|_{\frac{p}{2}}
&\leq 
C_p\|\sigma\|_{C_b^3}
(1+K_Y+K_{\tilde{Y}}+T)^3(1+\|\mbX\|_p+\|\widetilde{\mbX}\|_p)^4
(1+T)
\big(
\\
\nonumber
&\hspace{-33mm}
\|\Delta\mbX\|_p+
\|\mbX\|_p(\|\Delta Y_0\|+\|\Delta Y_0'\|+\|\Delta R^Y\|_\frac{p}{2}+\|\Delta Y'\|_p+(\|\Delta Y_0'\|+\|\Delta Y'\|_p)\|X\|_p+\|\Delta X\|_p)
\big).
\end{align}
\end{lemma}

\subsection{Rough differential equations: existence and unicity of solutions}\label{sec:rdes:existence_unicity}

In this section, we study existence and unicity of solutions to the  RDEs \eqref{eq:RDE} and \eqref{eq:RDE:linear}. 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Since these RDEs include a drift term $\int_0^\cdot b(t,Y_t,u_t)\dd t$, we use the following assumption and lemma to bound its $\frac{p}{2}$-variation. % 
\begin{assumption}[Regularity of $b$]\label{assumption:b}% 
Let $T>0$ and $U\subseteq\R^m$. 
The map $b:[0,T]\times\R^n\times U\to\R^n$ satisfies:
\begin{itemize}
\item 
$
b(\cdot, x, u):[0,T]\to\R^n
$ 
is measurable for all $(x,u)\in\R^n\times U$,
\item 
$
b(t,\cdot,\cdot):\R^n\times U\to\R^n
$
is continuous for almost every $t\in[0,T]$,
\item $b$ is bounded and Lipschitz in $x$: 
There exists a constant $C_b\geq 0$ such that 
$\|b(t,x,u)\|\leq C_b$ and   
$\|b(t,x,u)-b(t,\tilde{x},u)\|\leq C_b\|x-\tilde{x}\|$ for almost every $t\in[0,T]$, all $x,\tilde{x}\in\R^n$ and all $u\in U$.
% 
% 
% 
% 
\end{itemize}
\end{assumption} 



\begin{lemma}[$p$-variations of Lebesgue integrals]\label{lem:bounds_int_b_ds}
Let $p\in[2,3)$, $T>0$, $U\subseteq\R^m$, % 
 $b:[0,T]\times\R^n\times U\to\R^n$ satisfy Assumption \ref{assumption:b},  
$Y,\tilde{Y}:[0,T]\to\R^n$ be two continuous paths, and $u,\tilde{u}\in L^\infty([0,T],U)$. Then,  
\begin{align}\label{eq:bounds_int_b_ds}
% 
\left\|\int_0^\cdot b(s,Y_s,u_s)\dd s\right\|_\frac{p}{2} &\leq C_{p,b}T,
\  \ \text{and} \ \ \ 
\left\|\int_0^\cdot (b(s,Y_s,u_s)-b(s,\tilde{Y}_s,u_s))\dd s\right\|_\frac{p}{2} \leq C_{p,b}T\|Y-\tilde{Y}\|_\infty.
\end{align}
Moreover, if $b$ is also Lipschitz in $u$, so that  $\|b(t,x,u)-b(t,x,\tilde{u})\|\leq C_b\|u-\tilde{u}\|$ 
for almost every $t\in[0,T]$, all $x\in\R^n$, and all $u,\tilde{u}\in U$, then 
\begin{align}\label{eq:bounds_int_b_ds:dy_du}
\left\|\int_0^\cdot (b(s,Y_s,u_s)-b(s,\tilde{Y}_s,\tilde{u}_s))\dd s\right\|_\frac{p}{2} 
\leq 
C_{p,b}T
\big(
\|Y-\tilde{Y}\|_\infty
+
\|u-\tilde{u}\|_{L^\infty([0,T],U)}
\big).
\end{align}
\end{lemma}
% 
% 
% 
\begin{proof}
 By our assumptions,  $\int_0^t b(s,Y_s,u_s)\dd s$ and $\int_0^t b(s,\tilde{Y}_s,u_s)\dd s$ are well-defined Lebesgue integrals. % 
Given $s,t\in[0,T]$, % 
we obtain  $\|\int_s^t b(r,Y_r,u_r)\dd r\|
\leq C_b|t-s|$  
% 
and 
$\|\int_s^t (b(r,Y_r,u_r)-b(r,\tilde{Y}_r,u_r))\dd r\|
% 
\leq C_b\|Y-\tilde{Y}\|_\infty|t-s|$, 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
and assuming that $b$ is moreover Lipschitz in $u$, 
$\|\int_s^t (b(r,Y_r,u_r)-b(r,\tilde{Y}_r,\tilde{u}_r))\dd r\|
\leq C_b(\|Y-\tilde{Y}\|_\infty+\|u-\tilde{u}\|_\infty)|t-s|$. 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
The desired inequalities then follow from \eqref{eq:path_finite_var:sum_p/2vars} in  Lemma \ref{lem:pvariation:inequalities}.
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\end{proof}

\begin{remark}[On the boundedness of the drift $b$]\label{remark:b_bounded}
We assume that  $b$ is bounded, which is stronger than making a linear growth assumption (LG) in $x$ (i.e., $\|b(t,0,u)\|\leq C_b$, so that $\|b(t,x,u)\|\leq C_b(1+\|x\|)$), under which the bound in \eqref{eq:bounds_int_b_ds} becomes $\|\int_0^\cdot b(s,Y_s,u_s)\dd s\|_\frac{p}{2} \leq C_{p,b}(1+\|Y\|_\infty)T$. However, the proof of Theorem \ref{thm:rdes:existence_unicity} about existence and unicity of solutions to  nonlinear RDEs  breaks under LG, because it relies on a fixed point argument and on stitching solutions on intervals $[0,t]$ whose size is independent of the initial conditions, and the size of these intervals does depend on the initial conditions under LG. Similarly, our bounds for nonlinear RDEs (e.g., in Theorem \ref{thm:rdes:integrable})  assume that $b$ is bounded, as they rely on bounding $p$- and $\frac{p}{2}$-variations of solutions to nonlinear RDEs over short intervals, and these $p$-variations would otherwise depend on the initial conditions under LG. 
For these reasons, the case where $b$ is linear in $x$ (which does not satisfy Assumption \ref{assumption:b}) is handled by a separate analysis for linear RDEs, see  Theorems \ref{thm:rde:linear:existence_uniqueness}  and  \ref{thm:rdes:integrable}.
\end{remark}


\subsubsection{Nonlinear rough differential equations}\label{sec:rdes:existence_unicity:nonlinear}
\begin{theorem}[Nonlinear RDE \eqref{eq:RDE}: existence and unicity of solutions]
\label{thm:rdes:existence_unicity}
% 
Let $p\in[2,3)$, $T>0$, $y\in\R^n$, $U\subseteq\R^m$, $u\in L^\infty([0,T],U)$, 
$b:[0,T]\times\R^n\times U\to\R^n$ satisfy Assumption \ref{assumption:b},  $\sigma\in C_b^3([0,T]\times\R^n,\R^{n\times d})$, and   
$\mbX=(X,\bX)\in\sC^p([0,T],\R^d)$ be a $p$-rough path.

Then, there exists a unique %controlled $p$-rough path 
solution $(Y,Y')\in\sD^p_X([0,T],\R^n)$ with $Y'=\sigma(\cdot,Y)$ to the nonlinear RDE $Y_t=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s$ in \eqref{eq:RDE},
%\begin{equation}\tag{\ref{eq:RDE}}
%Y_t=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s,
%\qquad t\in[0,T],
%\end{equation}
%such that $Y'=\sigma(\cdot,Y)$, 
where $(\sigma(\cdot,Y),\sigma(\cdot,Y)')=(\sigma(\cdot,Y),\frac{\partial\sigma}{\partial x}(\cdot,Y)Y')\in\sD^p_X$.  
\end{theorem}
The proof of Theorem  \ref{thm:rdes:existence_unicity} relies on a classical fixed point argument and is in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi
 We adapt arguments in the proof of \cite[Theorem 2.5]{Allan2020} and \cite[Theorem 3.8]{Friz2018} for our different problem setting with time-varying coefficients $(b,\sigma)$ and a control $u$ that is not smooth but  is not in the diffusion $\sigma$.



\subsubsection{Linear rough differential equations}\label{sec:rdes:existence_unicity:linear}
Existence and unicity of solutions to the linear RDE \eqref{eq:RDE:linear} does not follow from Theorem \ref{thm:rdes:existence_unicity}, since the coefficients of a linear RDE are not bounded a-priori. First, we prove the existence and unicity of solutions to generic linear RDEs with drift (Theorem \ref{thm:rde:linear:existence_uniqueness}). Then, we apply it to the linear RDE \eqref{eq:RDE:linear} (Corollary \ref{cor:rde:linear:existence_uniqueness}).  Such a result can be considered standard, % 
although we could not find a result  in the literature that can handle a time-varying diffusion and an irregular drift. 
% 

Note that Theorem \ref{thm:rde:linear:existence_uniqueness} for linear RDEs does not rely on Theorem \ref{thm:rdes:existence_unicity}, so 
Theorem \ref{thm:rde:linear:existence_uniqueness} ensures that the RDE \eqref{eq:RDE} has a unique solution if $b$ is linear but is not bounded, see Remark \ref{remark:b_bounded}.  


% 


% 

\begin{theorem}[Linear RDEs: existence and unicity of solutions]\label{thm:rde:linear:existence_uniqueness}
Let $p\in[2,3)$,  $T>0$,  $v\in\R^n$ be an initial condition, $A\in L^\infty([0,T],\R^{n\times n})$ be an integrable map, 
$\mbX\in\sC^p_g([0,T],\R^d)$ be a geometric $p$-rough path, 
and $(\Sigma,\Sigma')\in\sD_X^p([0,T],\R^{n\times d \times n})$   be a controlled $p$-rough path.   
Then, there exists a unique solution $(V,V')\in\sD^p_X([0,T],\R^n)$ with $V'=\Sigma V$ to the linear RDE 
% 
\begin{align}
\label{eq:rde_linear}
V_t &=v +  
\int_0^t
A_sV_s\dd s
+  
\int_0^t
\Sigma_sV_s\dd\mbX_s,
\qquad t\in[0,T].
\end{align}  
% 
% 
\end{theorem}

% 
The proof %of Theorem \ref{thm:rde:linear:existence_uniqueness} 
consists of rewriting the linear RDE \eqref{eq:rde_linear} as a linear RDE with constant coefficients driven by a new geometric rough path % 
and concluding with \cite[Theorem 10.53]{Friz2010}, 
% 
% 
see  the 
\ifarxiv
appendix.
\else
supplementary material.
\fi  
% 


\begin{assumption}[Stronger regularity of $b$]\label{assumption:b:stronger:linear_rde}
Let $T>0$, $U\subseteq\R^m$, and  $b:[0,T]\times\R^n\times U\to\R^n$ satisfy
\begin{itemize} 
\item 
$b(\cdot, x, u):[0,T]\to\R^n$  is  measurable for all $(x,u)\in\R^n\times U$,  
\item  
$b(t,\cdot,\cdot):\R^n\times U\to\R^n$ 
is continuous for almost every $t\in[0,T]$,
\item 
$b(t,\cdot,u):\R^n\to\R^n$  is continuously differentiable  for almost every $t\in[0,T]$  and  all $u\in U$,  
\item % 
$\big\|\frac{\partial b}{\partial x}(t,x,u)\big\|\leq C_b$ for almost every $t\in[0,T]$ and all $(x,u)\in\R^n\times U$ for some constant $C_b\geq 0$.
\end{itemize}
\end{assumption}
\begin{corollary}[Linearized RDE \eqref{eq:RDE:linear}: existence and unicity of solutions]\label{cor:rde:linear:existence_uniqueness}
Let $p\in[2,3)$,  $T>0$,  $v\in\R^n$, $U\subseteq\R^m$, 
$u\in L^\infty([0,T],U)$, 
$b:[0,T]\times\R^n\times U\to\R^n$  satisfy  Assumption \ref{assumption:b:stronger:linear_rde}, 
$\sigma\in C_b^3([0,T]\times\R^n,\R^{n\times d})$, 
$\mbX\in\sC^p_g([0,T],\R^d)$ be a geometric $p$-rough path, and 
$(Y,Y')\in\sD^p_X([0,T],\R^n)$ be a controlled $p$-rough path.  
% 
Then, there exists a unique solution $(V,V')\in\sD^p_X([0,T],\R^n)$ with $V'=\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot)V_\cdot$ to the linear RDE $V_t =v +  
\int_0^t
\frac{\partial b}{\partial x}(s,Y_s,u_s)V_s\dd s
+  
\int_0^t
\frac{\partial\sigma}{\partial x}(s,Y_s)V_s\dd\mbX_s$ in \eqref{eq:RDE:linear}. 
%\begin{align}
%\tag{\ref{eq:RDE:linear}}
%V_t &=v +  
%\int_0^t
%\frac{\partial b}{\partial x}(s,Y_s,u_s)V_s\dd s
%+  
%\int_0^t
%\frac{\partial\sigma}{\partial x}(s,Y_s)V_s\dd\mbX_s,
%\quad t\in[0,T].
%\end{align} 
\end{corollary}
\begin{proof}
By Assumption \ref{assumption:b:stronger:linear_rde}, $\frac{\partial b}{\partial x}(\cdot,Y_\cdot,u_\cdot)\in L^\infty([0,T],\R^{n\times n})$. By Lemma \ref{lem:rough_path:sigma(.,Y):controlled}, $\big(\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot),\frac{\partial^2\sigma}{\partial x^2}(\cdot,Y_\cdot)Y'_\cdot\big)\in\sD_X^p([0,T],\R^{n\times d\times n})$. The conclusion then follows from Theorem \ref{thm:rde:linear:existence_uniqueness}.
\end{proof}



























\subsection{Bounds on solutions to nonlinear RDEs}\label{sec:rdes:bounds}
In this section, we derive bounds for solutions to the nonlinear RDE \eqref{eq:RDE} by leveraging greedy partitions and the quantity $N_{\alpha,[0,T]}(\mbX)$ in Definition \ref{def:Nalpha}.  The first step consists of deriving bounds that are independent of $\|\mbX\|_p$ and $T$ over intervals short-enough. 
The size $\alpha$ of these intervals is then used to define a greedy partition and derive finer bounds over the entire interval $[0,T]$ as a function of the quantity $N_{\alpha,[0,T]}(\mbX)$. Importantly, the final bounds in Lemma \ref{lem:rdes:bound:entire_interval} and Proposition \ref{prop:rdes:error_bound:entire_interval}
are integrable for Gaussian rough paths $\mbX=\mbB(\omega)$, see Theorem \ref{thm:gaussian_rough_paths} and Theorem \ref{thm:rdes:integrable}.  

For conciseness, the proofs of multiple results in this section are in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi
\subsubsection{Error bounds on short intervals}\label{sec:rdes:bounds:short}
\begin{proposition}[Bounds for solutions to RDEs on short intervals]\label{prop:bounds_pvars_solutions_RDEs}
Let $p,T,y,U,u,b,\sigma,\mbX,Y,Y'$ be as in Theorem \ref{thm:rdes:existence_unicity}, where $b$ satisfies Assumption \ref{assumption:b}, $\sigma\in C_b^3$, and $(Y,Y')\in\sD^p_X$ solves the RDE \eqref{eq:RDE}. 
% 
% 
% 
% 
Then,
\begin{align}
\label{eq:bounds_pvars_solutions_RDEs:sigma(Y)'_p}
\|\sigma(\cdot,Y)'\|_p &\leq C_{p,\sigma}(\|Y\|_p+T).
% 
% 
\end{align}
Moreover, there exists two constants $C_{p,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$ such that 
\begin{align}
\label{eq:bounds_pvars_solutions_RDEs:small_intervals:Y}
\|Y\|_{p,I} &\leq C_{p,b,\sigma},
\\
\label{eq:bounds_pvars_solutions_RDEs:small_intervals:R}
\|R^Y\|_{\frac{p}{2},I} &\leq C_{p,b,\sigma},
\\
\label{eq:bound:KY}
K_{Y,I}= \|Y_{t_0}'\|+\|Y'\|_{p,I}+\|R^Y\|_{\frac{p}{2},I}
&\leq
C_{p,b,\sigma}.
\end{align}
for any interval $I=[t_0,t_1]\subseteq[0,T]$ small-enough so that  $
\|\mbX\|_{p,I}+|I|\leq
 \alpha_{p,b,\sigma}^\frac{1}{p}$. 
\end{proposition}
 To show Proposition \ref{prop:bounds_pvars_solutions_RDEs}, we take inspiration from the proof of  \cite[Proposition 2.4]{Allan2020}. The main differences are handling a time-varying diffusion $\sigma(\cdot,Y)$ and using an interval $I$ small-enough so that the quantities in   \eqref{eq:bounds_pvars_solutions_RDEs:small_intervals:Y}-\eqref{eq:bound:KY} are bounded by a constant  that only depends on $(p,b,\sigma)$ and not on $(X,Y,I)$. 



\begin{proposition}
[Error bound for solutions to RDEs on short intervals]\label{prop:rdes:error_bound}
% 
Let $p\in[2,3)$, $T>0$, $y,\tilde{y}\in\R^n$, $U\subseteq\R^m$, 
$u,\tilde{u}\in L^\infty([0,T],U)$, 
$b:[0,T]\times\R^n\times U\to\R^n,(t,x,u)\mapsto b(t,x,u)$ satisfy Assumption \ref{assumption:b} and be Lipschitz in $u$, 
$\sigma\in C_b^3([0,T]\times\R^n,\R^{n\times d})$,  
$\mbX,\widetilde{\mbX}\in\sC^p([0,T],\R^d)$ be two $p$-rough paths, 
 $(Y,Y')\in\sD^p_X([0,T],\R^n)$ and $(\widetilde{Y},\widetilde{Y}')\in\sD^p_{\tilde{X}}([0,T],\R^n)$ with $(Y',\widetilde{Y}')=(\sigma(\cdot,Y_\cdot),\sigma(\cdot,\widetilde{Y}_\cdot))$ be the solutions to the RDEs 
\begin{align*}
Y_t=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s,
\quad
\widetilde{Y}_t=\tilde{y}+\int_0^tb(s,\widetilde{Y}_s,\tilde{u}_s)\dd s+\int_0^t\sigma(s,\widetilde{Y}_s)\dd\widetilde{\mbX}_s,
\quad t\in[0,T].
\end{align*}
Then, there exists two constants $C_{p,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$ such that
\begin{gather}\label{eq:bounds_pvars_solutions_RDEs:small_intervals:combined}
\|Y\|_{p,I},\, 
\|\widetilde{Y}\|_{p,I},\, 
\|R^Y\|_{\frac{p}{2},I},\, 
\|R^{\widetilde{Y}}\|_{\frac{p}{2},I},\, 
K_{Y,I},\, 
K_{\widetilde{Y},I}\leq
C_{p,b,\sigma},
\quad\text{and}
\\[2mm]
% 
\label{eq:RDE:DY'+dRY:close}
\|Y'-\widetilde{Y}'\|_{p,I}+\|R^Y-R^{\widetilde{Y}}\|_{\frac{p}{2},I}
\leq
C_{p,b,\sigma}(\|Y_{t_0}-\widetilde{Y}_{t_0}\|
+
\|\Delta\mbX\|_{p,I}
+
|I|\|u-\tilde{u}\|_{L^\infty(I,U)}),
\end{gather}
for any interval $I=[t_0,t_1]\subseteq[0,T]$ such that $\|\mbX\|_{p,I}+\|\widetilde{\mbX}\|_{p,I}+|I|\leq
 \alpha_{p,b,\sigma}^\frac{1}{p}$.
% 
% 
% 
% 
\end{proposition}
The proof of Proposition \ref{prop:rdes:error_bound} takes similar steps as in the proofs of \cite[Proposition 2.6]{Allan2020} and \cite[Theorem 3.9]{Friz2018}, and as  when proving the contractivity of $\M_t$ for Theorem \ref{thm:rdes:existence_unicity}. The main differences compared to prior work are using bounds with $\sigma(\cdot,Y)$ that 
is time-varying and working on short-enough intervals to obtain a bound with a constant $C_{p,b,\sigma}$ that only depends on $(p,b,\sigma)$, and not on $(X,\tilde{X},Y,\widetilde{Y},I)$. This last difference is the key to obtain integrable bounds. 












\subsubsection{Error bounds on long intervals}\label{sec:rdes:bounds:long}
 
\begin{lemma}[Boundedness of solutions to RDEs]\label{lem:rdes:bound:entire_interval}
% 
Let $p,T,y,U,u,b,\sigma,\mbX,Y,Y'$ be as in Theorem \ref{thm:rdes:existence_unicity}, where $b$ satisfies Assumption \ref{assumption:b}, $\sigma\in C_b^3$, and $(Y,Y')\in\sD^p_X$ solves the RDE \eqref{eq:RDE}.  
% 
Define $N_{\alpha,[0,T]}(\mbX)$ as in Definition \ref{def:Nalpha}. 
% 
% 
% 
% 
 % 
Then, there exist constants $C_{p,T,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$ such that  
\begin{align}
\label{eq:RDE:Yp_Y'p_RYp/2:bound:full_interval}
\|Y\|_{p,[0,T]}+
\|Y'\|_{p,[0,T]}+
\|R^Y\|_{\frac{p}{2},[0,T]}
&\leq
C_{p,T,b,\sigma}\exp\left(
C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)
\right),
\\
\label{eq:RDE:Y:bound:full_interval}
\|Y\|_{\infty,[0,T]}
&\leq
C_{p,T,b,\sigma}\exp\left(
C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)
\right)+\|y\|.
\end{align}
% 
\end{lemma}
\begin{proof}
Define $N_{\alpha,I}(w)$ and $w$ as in Definition \ref{def:Nalpha} and Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals}, respectively. 
% 
Let $C_{p,b,\sigma}\geq 1$ and $\alpha_{p,b,\sigma}>0$ be the constants in Proposition \ref{prop:bounds_pvars_solutions_RDEs}, 
and $I=[s,t]\subseteq[0,T]$ be any interval such that $w(s,t)\leq\alpha:=\alpha_{p,b,\sigma}$. 
Then, by   Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals}, $
\|\mbX\|_{p,I}+|I|
\mathop{\leq}\limits^{\eqref{eq:|X|+|Xtilde|+|dt|<=alpha^p}}
 \alpha_{p,b,\sigma}^\frac{1}{p}$, so  Proposition \ref{prop:bounds_pvars_solutions_RDEs} implies that % 
$\|Y\|_{p,I} 
\mathop{\leq}\limits^{\eqref{eq:bounds_pvars_solutions_RDEs:small_intervals:Y}}
C_{p,b,\sigma}$
and $\|Y'\|_{p,I}+\|R^Y\|_{\frac{p}{2},I}
\mathop{\leq}\limits^{\eqref{eq:bound:KY}} C_{p,b,\sigma}$.
%$$
%\|Y\|_{p,I} 
%\mathop{\leq}^{\eqref{eq:bounds_pvars_solutions_RDEs:small_intervals:Y}}
%C_{p,b,\sigma}
%\quad\text{and}\quad
%\|Y'\|_{p,I}+\|R^Y\|_{\frac{p}{2},I}
%\mathop{\leq}^{\eqref{eq:bound:KY}} C_{p,b,\sigma}.
%$$
% 
% 
Thus, as defined in Definition \ref{def:Nalpha}, with $N=N_{\alpha,[0,T]}(w)$, the partition 
 $\{\tau_i, i=0,1,\dots,N+1\}$ 
of the interval $[0,T]$, which satisfies $w(\tau_i,\tau_{i+1})\leq \alpha$ for all $i$,  is such that 
 $$
\|Y\|_{p,[0,T]}\leq (N+1)(
\sum_{i=0}^N\|Y\|_{p,[\tau_i,\tau_{i+1}]}^p
)^\frac{1}{p}
\leq (N+1)
\sum_{i=0}^N\|Y\|_{p,[\tau_i,\tau_{i+1}]}\leq (N+1)^2C_{p,b,\sigma}
\leq
2e\exp(N)C_{p,b,\sigma},
$$
where the first inequality follows from  Lemma \ref{lem:pvar:intervals}. The same inequality holds for $\|Y'\|_{p,[0,T]}$ and $\|R^Y\|_{\frac{p}{2},[0,T]}$ (note that Lemma \ref{lem:pvar:intervals} can also   be used to bound $\|R^Y\|_{\frac{p}{2},[0,T]}$). The desired first inequality \eqref{eq:RDE:Yp_Y'p_RYp/2:bound:full_interval} then follows from $\exp(N)\leq \exp(5C_p(
N_{\alpha,[0,T]}(\mbX)+T/\alpha+1))\leq C_{p,T,b,\sigma,\alpha}\exp(C_pN_{\alpha,[0,T]}(\mbX))$ by \eqref{eq:Nalpha<=3CpNalpha_X_and_time}. 
Finally, the desired inequality \eqref{eq:RDE:Y:bound:full_interval} follows from $\|Y\|_{\infty,[0,T]}\leq \|Y\|_{p,[0,T]}+\|Y_0\|$ by  \eqref{eq:path_finite_var:infty_ineq}, and we conclude.
\end{proof} 
Proposition \ref{prop:rdes:error_bound:entire_interval} below is the main result of this section. It is similar to \cite[Theorem 4]{Bayer2016}, but includes  
a drift term % 
with a control input $u$ and a time-varying diffusion $\sigma$.  
Its proof is similar to the proof of Lemma \ref{lem:rdes:bound:entire_interval} by appropriately  replacing inequalities   but is slightly longer, so we provide it in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi
\begin{proposition}
[Error bound for solutions to RDEs on long intervals]\label{prop:rdes:error_bound:entire_interval}
% 
Define $p,T,y,\tilde{y},U,u,\tilde{u},b,\sigma$, $\mbX,\widetilde{\mbX}$
% 
as in Proposition \ref{prop:rdes:error_bound}, 
where $b$ satisfies Assumption \ref{assumption:b} and is Lipschitz in $u$ and $\sigma\in C_b^3$, and let $(Y,Y')\in\sD^p_X$ and $(\widetilde{Y},\widetilde{Y}')\in\sD^p_{\widetilde{X}}$  with $Y'=\sigma(\cdot,Y_\cdot)$ and $\widetilde{Y}'=\sigma(\cdot,\widetilde{Y}_\cdot)$ 
be the solutions to the RDEs
% 
% 
% 
% 
% 
% 
\begin{align*}
Y_t=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s,
\quad
\widetilde{Y}_t=\tilde{y}+\int_0^tb(s,\widetilde{Y}_s,\tilde{u}_s)\dd s+\int_0^t\sigma(s,\widetilde{Y}_s)\dd\widetilde{\mbX}_s,
\quad t\in[0,T].
\end{align*} 
% 
Then, there exist constants $C_{p,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$ such that  
for any interval $I=[t_0,t_1]\subseteq[0,T]$, 
\begin{align}\label{eq:RDE:DY'+dRY:close:full_interval}
\|Y'-\widetilde{Y}'\|_{p,I}+\|R^Y-R^{\widetilde{Y}}\|_{\frac{p}{2},I}
&\leq
C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}N_{\alpha_{p,b,\sigma},I}(w)
\right)(\|\Delta Y_{t_0}\|
+
\|\Delta \mbX\|_{p,I}
+
|I|\|\Delta u\|_{L^\infty,I}
)
\\
\label{eq:RDE:DY:close:full_interval}
\|Y-\widetilde{Y}\|_{\infty,I} 
&\leq
C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}N_{\alpha_{p,b,\sigma},I}(w)
\right)(\|\Delta Y_{t_0}\|
+
\|\Delta \mbX\|_{p,I}
+
|I|\|\Delta u\|_{L^\infty,I}
)
\end{align}
where $\|\Delta u\|_{L^\infty,I}=\|u-\tilde{u}\|_{L^\infty(I,U)}$, and $(N_{\alpha_{p,b,\sigma},I}(w),w)$ are  defined in Definition \ref{def:Nalpha} and Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals}. % 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 

Moreoever, if $u$ and $\tilde{u}$ only differ on a subinterval $J\subseteq I$, i.e., $u_t=\tilde{u}_t$ for almost all $t\in I\setminus J$, then
\begin{align}\label{eq:RDE:DY'+dRY:close:full_interval:u_subinterval}
\|Y'-\widetilde{Y}'\|_{p,I}+\|R^Y-R^{\widetilde{Y}}\|_{\frac{p}{2},I}
&\leq
C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}N_{\alpha_{p,b,\sigma},I}(w)
\right)(\|\Delta Y_{t_0}\|
+
\|\Delta \mbX\|_{p,I}
+
|J|\|\Delta u\|_{L^\infty,I}
)
\\
\label{eq:RDE:DY:close:full_interval:u_subinterval}
\|Y-\widetilde{Y}\|_{\infty,I} 
&\leq
C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}N_{\alpha_{p,b,\sigma},I}(w)
\right)(\|\Delta Y_{t_0}\|
+
\|\Delta \mbX\|_{p,I}
+
|J|\|\Delta u\|_{L^\infty,I}
)
\end{align}
for some constants $C_{p,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$. 
\end{proposition}


% 
% 
% 
% 
% 
% 
% 

\subsection{Bounds on  solutions to linear RDEs and on the Jacobian flow}\label{sec:rdes:bounds:linear}
Next, we derive bounds on solutions to linear RDEs and on the Jacobian flow of nonlinear RDEs, stated in Lemmas \ref{lem:rde:linear:bounded_solutions} and  \ref{lem:rde:linearized:bounded_solutions}.   
For conciseness, the proofs of these results are provided in the 
\ifarxiv
appendix.
\else
supplementary material.
\fi  

%\begin{lemma}[Rough Gr\"onwall Lemma {\cite[Lemma 2.12]{Deya2019}}]
%\label{lem:rough_gronwall}
%Let $p\geq 1$, $T>0$, $C_1,\alpha>0$, $Y\in C([0,T],\R^n)$, and $w_1,w_2$  be two controls on $[0,T]$ (see Definition \ref{def:Nalpha}) such that
%$$
%\|Y_{s,t}\|\leq C_1\|Y\|_{\infty,[0,t]}w_1(s,t)^\frac{1}{p}+w_2(s,t)
%\ \ \text{for any } [s,t]\subseteq[0,T] \text{ such that }w_1(s,t)\leq \alpha,
%$$
%and define $C_2=\min(1, 1/(\alpha(2C_1\exp(2))^p))$. 
%Then,
%$$
%\|Y\|_{\infty,[0,T]}
%\leq
%2\exp\left(\frac{w_1(0,T)}{C_2\alpha}\right)
%\left(
%\|Y_0\|
%+
%\left\|w_2(0,\cdot)\exp\left(-w_1(0,\cdot)/(C_2 \alpha)\right)
%\right\|_{\infty,[0,T]}
%\right).
%$$
%\end{lemma} 


Lemma \ref{lem:rde:linear:bounded_solutions} below is similar to \cite[Proposition 8.13]{Friz2020} stated for $\frac{1}{p}$-H\"older continuous rough paths.  
The main differences are that the bounds in Lemma \ref{lem:rde:linear:bounded_solutions} are integrable for Gaussian rough paths $\mbX=\mbB(\omega)$ (see Theorem \ref{thm:gaussian_rough_paths} and Theorem \ref{thm:rdes:integrable}) and that Lemma \ref{lem:rde:linear:bounded_solutions} handles time-varying vector fields. 
The proof of Lemma \ref{lem:rde:linear:bounded_solutions} %follows similar steps as  the proof of Proposition \ref{prop:rdes:error_bound:entire_interval} and additionally 
relies on a  Gr\"onwall Lemma for rough paths \cite[Lemma 2.12]{Deya2019}.
\begin{lemma}[Boundedness of solutions to linear RDEs]\label{lem:rde:linear:bounded_solutions}
Let $p,T,y,A,\mbX,\Sigma,\Sigma'$ be as in Theorem \ref{thm:rde:linear:existence_uniqueness}, where $A\in L^\infty$, $(\Sigma,\Sigma')\in\sD_X^p$, and  $(V,V')\in\sD^p_X$ solves the linear RDE  \eqref{eq:rde_linear}.  
% 
Define $N_{\alpha,[0,T]}(\mbX)$ as in Definition \ref{def:Nalpha}. 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Assume that  there exists two constants $C_\Sigma\geq 1$ and $0<\alpha_\Sigma<1$ such that 
\begin{align*} 
\|\Sigma\|_{\infty,I} + \|\Sigma\|_{p,I} +\|\Sigma'\|_{p,I}+\|R^\Sigma\|_{\frac{p}{2},I}
&\leq
C_\Sigma
\end{align*}
for any interval $I\subseteq[0,T]$ such that $\|\mbX\|_{p,I}+|I|\leq
 \alpha_\Sigma^{\frac{1}{p}}$.  
Then,  
% 
% 
% 
\begin{align}
\label{eq:RDE:linear:Vp_V'p_RVp/2:bound}
\|V\|_{p,[0,T]}+
\|V'\|_{p,[0,T]}+
\|R^V\|_{\frac{p}{2},[0,T]}
&\leq 
C_{p,T,A,\Sigma}\exp\left(C_{p,T,A,\Sigma}N_{\alpha_{p,A,\Sigma},[0,T]}(\mbX)\right)\|v\|,
\\
\label{eq:RDE:linear:V:bound}
\|V\|_{\infty,[0,T]}
&\leq 
C_{p,T,A,\Sigma}\exp\left(C_{p,T,A,\Sigma}N_{\alpha_{p,A,\Sigma},[0,T]}(\mbX)\right)\|v\|,
\end{align}
where the constants $C_{p,T,A,\Sigma}\geq 1$ and $0<\alpha_{p,A,\Sigma}\leq\alpha_\Sigma$    only depend on $(p,T,\|A\|_\infty,C_\Sigma,\alpha_\Sigma)$. 
% 
% 
% 
\end{lemma}




Lemma \ref{lem:rde:linearized:bounded_solutions} is similar to \cite[Theorem 6.5]{Cass2013} (see also \cite[Proposition 5]{Friz2013}), generalizing it to RDEs with  drift $b$, control input $u$, and time-varying diffusion $\sigma$. Note that the bounds \eqref{eq:rde:linearized:Vp_V'p_RVp/2:bound} and \eqref{eq:rde:linearized:bounded_solutions} do not depend on $Y$: This fact is used in the proof of Lemma \ref{lem:rde:linearized:continuous} that gives the continuity of the map $(y,\mbX,u)\mapsto V$.
\begin{lemma}[Boundedness of the Jacobian flow]
\label{lem:rde:linearized:bounded_solutions}
Let $p\in[2,3)$,  $T>0$,  $y,v\in\R^n$, $U\subseteq\R^m$, 
$u\in L^\infty([0,T],U)$, 
$b:[0,T]\times\R^n\times U\to\R^n$  satisfy  Assumption \ref{assumption:b:stronger:linear_rde}, 
$\sigma\in C_b^3([0,T]\times\R^n,\R^{n\times d})$,  
$\mbX\in\sC^p_g([0,T],\R^d)$, 
and $(Y,Y'),(V,V')\in\sD^p_X([0,T],\R^n)$ 
with $Y'=\sigma(\cdot,Y_\cdot)$ and $V'=\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot)V_\cdot$ 
% 
be the solutions to the  RDEs $Y_t=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s$ in \eqref{eq:RDE}  and  $V_t =v +  
\int_0^t
\frac{\partial b}{\partial x}(s,Y_s,u_s)V_s\dd s
+  
\int_0^t
\frac{\partial\sigma}{\partial x}(s,Y_s)V_s\dd\mbX_s$ in \eqref{eq:RDE:linear}. 
%\begin{align*} 
%Y_t&=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s,
%\ \ 
%V_t =v +  
%\int_0^t
%\frac{\partial b}{\partial x}(s,Y_s,u_s)V_s\dd s
%+  
%\int_0^t
%\frac{\partial\sigma}{\partial x}(s,Y_s)V_s\dd\mbX_s,
%% 
%% 
%% 
%% 
%% 
%% 
%% 
%\end{align*} 
%where $t\in[0,T]$.   
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Then, there exists two constants $C_{p,T,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$ such that 
% 
% 
% 
\begin{align}
\label{eq:rde:linearized:Vp_V'p_RVp/2:bound}
\|V\|_{p,[0,T]}+
\|V'\|_{p,[0,T]}+
\|R^V\|_{\frac{p}{2},[0,T]}
&\leq 
C_{p,T,b,\sigma}\exp\left(C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)\right)\|v\|,
\\
\label{eq:rde:linearized:bounded_solutions}
\|V\|_{\infty,[0,T]}
&\leq 
C_{p,T,b,\sigma}\exp\left(C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)\right)\|v\|,
\end{align} 
where 
% 
% 
$N_{\alpha,[0,T]}(\mbX)$ is defined in Definition \ref{def:Nalpha}.
\end{lemma} 














\subsection{Integrability of solutions to nonlinear and linear RDEs}\label{sec:rdes:random_integrable}
Finally, we combine the results from the previous sections to show that pathwise solutions  to nonlinear and linear RDEs driven by Gaussian rough paths $\mbB(\omega)$ are  integrable. First, in Lemmas \ref{lem:rdes:continuity} and  \ref{lem:rde:linearized:continuous}, we show the continuity of the It\^o-Lyons map $(y,\mbX)\mapsto Y_{(y,\mbX)}$, that is, that solutions to RDEs are continuous with respect to the initial conditions and the driving rough path. With this result follows the measurability of the map $\omega\mapsto Y_{(y(\omega),\mbB(\omega))}$ that assigns the pathwise solution to a random RDE driven by a Gaussian rough path $\mbX=\mbB(\omega)$. Thanks to the favorable integrability properties of enhanced Gaussian processes $\mbB$ in Theorem \ref{thm:gaussian_rough_paths}, we conclude that such solutions are integrable in Theorem \ref{thm:rdes:integrable}. These results will be used throughout  the proof of \pmp, e.g., to make sense of the maximality condition \eqref{eq:spmp:maximizality_condition} that involves $\E\left[
H(t,x_t,v,p_t,\mathfrak{p}_0)
\right]$.







\begin{lemma}
[Continuity of solutions to RDEs]\label{lem:rdes:continuity}
% 
% 
Define $p,T,y,\tilde{y},U,u,\tilde{u},b,\sigma,\mbX,\widetilde{\mbX}$
% 
as in Proposition \ref{prop:rdes:error_bound}, 
where $b$ satisfies Assumption \ref{assumption:b} and is Lipschitz in $u$ and $\sigma\in C_b^3$, 
let $(Y,Y')\in\sD^p_X$ and $(\widetilde{Y},\widetilde{Y}')\in\sD^p_{\widetilde{X}}$  with $Y'=\sigma(\cdot,Y_\cdot)$ and $\widetilde{Y}'=\sigma(\cdot,\widetilde{Y}_\cdot)$  be the solutions to the RDEs
% 
% 
% 
% 
% 
% 
% 
\begin{align*}
Y_t=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s,
\quad
\widetilde{Y}_t=\tilde{y}+\int_0^tb(s,\widetilde{Y}_s,\tilde{u}_s)\dd s+\int_0^t\sigma(s,\widetilde{Y}_s)\dd\widetilde{\mbX}_s,
\quad t\in[0,T],
\end{align*} and assume that there exists a constant $M\geq 0$ such that   $\|\mbX\|_p,\|\widetilde{\mbX}\|_p\leq M$. Then,% 
\begin{align}
\label{eq:RDE:DY'+dRY:close:full_interval:continuity}
\|Y'-\widetilde{Y}'\|_{p,[0,T]}+
\|R^Y-R^{\widetilde{Y}}\|_{\frac{p}{2},[0,T]}
&\leq 
C_{p,T,b,\sigma,M}
\left(
\|y-\tilde{y}\| 
+
\|\Delta \mbX\|_{p,[0,T]}
 + 
 T\|u-\tilde{u}\|_{L^\infty([0,T],U)}
\right),
\\
\label{eq:RDE:DY:close:full_interval:continuity}
\|Y-\widetilde{Y}\|_{\infty,[0,T]}
&\leq 
C_{p,T,b,\sigma,M}
\left(
\|y-\tilde{y}\|
+
\|\Delta \mbX\|_{p,[0,T]}
 + 
 T\|u-\tilde{u}\|_{L^\infty([0,T],U)}
\right)
\end{align}
for a constant $C_{p,T,b,\sigma,M}\geq 0$.
\end{lemma}
\begin{proof}
First, the RDEs have unique solutions $(Y,Y')\in\sD^p_X$  and $(\widetilde{Y},\widetilde{Y}')\in\sD^p_{\widetilde{X}}$ thanks to Theorem \ref{thm:rdes:existence_unicity}. Let $\alpha=\alpha_{p,b,\sigma}$ be as in Proposition \ref{prop:rdes:error_bound:entire_interval}, and $I=[0,T]$. 
% 
By Lemma \ref{lem:Nalpha<=w(0,T)}, $\alpha N_{\alpha,[0,T]}(\mbX)\leq w_\mbX(0,T)=\|X\|^p_p+\|\bX\|_\frac{p}{2}^\frac{p}{2}
\leq M^p+M^\frac{p}{2}$. By  \eqref{eq:Nalpha<=3CpNalpha_X_and_time} in Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals}, $N_{\alpha,[0,T]}(w)\leq 5C_p(
N_{\alpha,[0,T]}(\mbX)+N_{\alpha,[0,T]}(\widetilde\mbX)+T/\alpha+1
)$. Thus, $N_{\alpha,[0,T]}(w)\leq C$ for a constant $C$ that depends only on $(p,T,b,\sigma,M)$. Finally, the inequalities \eqref{eq:RDE:DY'+dRY:close:full_interval:continuity} and \eqref{eq:RDE:DY:close:full_interval:continuity} follow from \eqref{eq:RDE:DY'+dRY:close:full_interval} and \eqref{eq:RDE:DY:close:full_interval} for a new constant $C_{p,T,b,\sigma,M}\geq 0$. 
\end{proof}



The continuity of solutions to  linearized RDEs is proved under the following stronger assumption. 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\begin{assumption}[Stronger regularity of $b$]\label{assumption:b:stronger}
Let $T>0$,  $U\subseteq\R^m$, and $b:[0,T]\times\R^n\times U\to\R^n$. The map $b$ satisfies Assumption \ref{assumption:b:stronger:linear_rde} and is such that 
%there exists a constant $C_b\geq 0$ such that 
$\|b(t,x,u)\|+\big\|\frac{\partial b}{\partial x}(t,x,u)\big\| \leq C_b$ 
and 
$\big\|\frac{\partial b}{\partial x}(t,x,u)-\frac{\partial b}{\partial x}(t,\tilde{x},u)\big\|\leq C_b\|x-\tilde{x}\|$ for some constant $C_b\geq 0$, almost every $t\in[0,T]$, all $x,\tilde{x}\in\R^n$, and all $u\in U$.
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\end{assumption}

\begin{lemma}[Continuity of the Jacobian flow]\label{lem:rde:linearized:continuous}
Define $p,T,y,\tilde{y},u,\tilde{u},b,\sigma,\mbX,\widetilde{\mbX},Y,Y',\widetilde{Y},\widetilde{Y}',M$ as in Lemma \ref{lem:rdes:continuity}, and assume that $b$ satisfies Assumption \ref{assumption:b:stronger}, 
that $(t,x,u)\mapsto \frac{\partial b}{\partial x}(t,x,u)$ is Lipschitz in $u$, 
 and that $\mbX,\widetilde{\mbX}\in\sC^p_g$ are geometric. 
Let $v\in C_b^1(\R^n,\R^n)$ and  $(V,V')\in\sD^p_X([0,T],\R^n)$ and $(\tilde{V},\tilde{V}')\in\sD^p_{\widetilde{X}}([0,T],\R^n)$ 
with $V'=\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot)V_\cdot$  and $\widetilde{V}'=\frac{\partial\sigma}{\partial x}(\cdot,\widetilde{Y}_\cdot)\widetilde{V}_\cdot$  
be the solutions to the linear RDEs 
{\small
\begin{align*}
V_t &= 
v(y)
+
\int_0^t
\frac{\partial b}{\partial x}(s,Y_s,u_s)V_s\dd s +
\int_0^t
\frac{\partial\sigma}{\partial x}(s,Y_s)V_s\dd\mbX_s
\  \text{and}\  
\widetilde{V}_t = 
v(\tilde{y})
+
\int_0^t
\frac{\partial b}{\partial x}(s,\widetilde{Y}_s,\tilde{u}_s)\widetilde{V}_s\dd s +
\int_0^t
\frac{\partial\sigma}{\partial x}(s,\widetilde{Y}_s)\widetilde{V}_s\dd\widetilde{\mbX}_s
\end{align*}
}% 
where  $t\in[0,T]$.
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Then,  for a constant $C_{p,T,b,\sigma,v,M}\geq 0$,
\begin{align*}
\|V'-\widetilde{V}'\|_{p,[0,T]}+
\|R^V-R^{\widetilde{V}}\|_{\frac{p}{2},[0,T]}
&\leq 
C_{p,T,b,\sigma,v,M}
\left(
\|y-\tilde{y}\| 
+
\|\Delta \mbX\|_{p,[0,T]}
 + 
 T\|u-\tilde{u}\|_{L^\infty([0,T],U)}
\right),
\\
\|V-\widetilde{V}\|_{\infty,[0,T]}&\leq 
C_{p,T,b,\sigma,v,M}
\left(
\|y-\tilde{y}\| 
+
\|\Delta \mbX\|_{p,[0,T]}
 + 
 T\|u-\tilde{u}\|_{L^\infty([0,T],U)}
\right).
\end{align*}
\end{lemma}
\begin{proof}
First, the linear RDEs also have unique solutions $(V,V')\in\sD^p_X$ and $(\tilde{V},\tilde{V}')\in\sD^p_{\widetilde{X}}$ thanks to Corollary  \ref{cor:rde:linear:existence_uniqueness}.  
Second, by Lemma \ref{lem:rde:linearized:bounded_solutions},  
there exists two constants $C_{p,T,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$  (importantly, they do not depend on $Y,\widetilde{Y}$) such that 
$$
\|V\|_{\infty,[0,T]}+\|V'\|_{\infty,[0,T]}\leq C_{p,T,b,\sigma}\exp\left(C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)\right)\|v(y)\|,
$$ 
and similarly for $\|\widetilde{V}\|_{\infty,[0,T]}+\|\widetilde{V}'\|_{\infty,[0,T]}$. 
By Lemma \ref{lem:Nalpha<=w(0,T)}, $\alpha_{p,b,\sigma} N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)\leq w_\mbX(0,T)=\|X\|^p_p+\|\bX\|_\frac{p}{2}^\frac{p}{2}
\leq M^p+M^\frac{p}{2}$, since $\|\mbX\|_p=\|X\|_p+\|\bX\|_\frac{p}{2}\leq M$.  Thus,
$$
\|V\|_{\infty,[0,T]}+\|V'\|_{\infty,[0,T]}+\|\widetilde{V}\|_{\infty,[0,T]}+\|\widetilde{V}'\|_{\infty,[0,T]}\leq C_{p,T,b,\sigma,v,M}.
$$
Thus, we may assume that $(V,V')$ and $(\widetilde{V},\widetilde{V}')$ solve the nonlinear RDEs
\begin{align*}
V_t &=v(Y_0) +  
\int_0^t
\hat{b}(s,(Y_s,V_s),u_s)\dd s
+  
\int_0^t
\hat\sigma(s,(Y_s,V_s))\dd\mbX_s,
\quad t\in[0,T]
% 
% 
% 
% 
% 
% 
% 
\end{align*}  
(and similarly for $\widetilde{V}$) for some bounded coefficients $(\hat{b},\hat\sigma)$, where $\hat{b}:[0,T]\times\R^{2n}\times U\to\R^n$ satisfies Assumption \ref{assumption:b} and is Lipschitz in $u$, and $\hat\sigma\in C_b^3([0,T]\times\R^{2n},\R^{n\times d})$. Thus, the pair $((Y,V),(Y',V'))$ solves the RDE
\begin{align*}
\begin{bmatrix}
Y_t \\ V_t
\end{bmatrix} &=
\begin{bmatrix}
y \\ v(y)
\end{bmatrix} +  
\int_0^t
\begin{bmatrix}
b(s,Y_s,u_s) \\ \hat{b}(s,(Y_s,V_s),u_s)
\end{bmatrix}
\dd s
+  
\int_0^t
\begin{bmatrix}
\sigma(s,Y_s) \\ 
\hat\sigma(s,(Y_s,V_s))
\end{bmatrix}
\dd\mbX_s,
\end{align*}  
and similarly for $(\widetilde{Y},\widetilde{V})$. Then using \eqref{eq:RDE:DY'+dRY:close:full_interval:continuity} and  \eqref{eq:RDE:DY:close:full_interval:continuity} in Lemma \ref{lem:rdes:continuity},
% 
% 
% 
\begin{align*} 
\|(Y,V)-(\widetilde{Y},\widetilde{V})\|_{\infty,[0,T]} 
&\leq
C_{p,T,b,\sigma,v,M}(
\|(y,v(y))-(\tilde{y},v(\tilde{y}))\|
+
\|\Delta\mbX\|_{p,[0,T]}
+
T\|u-\tilde{u}\|_{L^\infty([0,T],U)}
),
\end{align*}
and similarly for $\|(Y',V')-(\widetilde{Y}',\widetilde{V}')\|_{p}+\|R^{(Y,V)}-R^{(\widetilde{Y},\widetilde{V})}\|_{\frac{p}{2}}$,
from which we deduce the desired result.
\end{proof} 


 



\begin{theorem}[Integrability of pathwise solutions to random RDEs]\label{thm:rdes:integrable} 
Let $T>0$, $\rho\in[1,\frac{3}{2})$, $p\in(2\rho,3)$,  $(\Omega,\F,\Prob)$ be a probability space, $B$ be a centered, continuous, $\R^d$-valued Gaussian process with independent components satisfying Assumption \ref{assum:Gaussian_lift} for $\rho$, and $\mbB$ be the associated enhanced Gaussian process in Theorem \ref{thm:gaussian_rough_paths}. 
% 
Let $\ell\geq1$,  $y,\tilde{y}\in L^\ell(\Omega,\R^n)$, $U\subseteq\R^m$, 
$u\in L^\infty([0,T],U)$, 
$b:[0,T]\times\R^n\times U\to\R^n$ satisfy Assumption \ref{assumption:b},  
$\sigma\in C_b^3([0,T]\times\R^n,\R^{n\times d})$,  
and for almost every $\omega\in\Omega$, define $(Y(\omega),Y'(\omega))\in\sD^p_{B(\omega)}([0,T],\R^n)$ with $Y'(\omega)=\sigma(\cdot,Y_\cdot(\omega))$ as the solution to the nonlinear RDE
\begin{align*}
Y_t(\omega)&=y(\omega)+\int_0^tb(s,Y_s(\omega),u_s)\dd s+\int_0^t\sigma(s,Y_s(\omega))\dd\mbB_s(\omega),
\quad\ \ t\in[0,T].
\end{align*} 
Then, $Y\in L^\ell(\Omega,C([0,T],\R^n))$. 
% 

Moreover, let $v\in C_b^1(\R^n,\R^n)$,   
 assume that 
$b$  satisfies  Assumption \ref{assumption:b:stronger}, and for almost every $\omega\in\Omega$, define $(V(\omega),V'(\omega))\in\sD^p_{B(\omega)}([0,T],\R^n)$ with $V'(\omega)=\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot(\omega))V_\cdot(\omega)$ as the solution to the linear RDE
\begin{align*}
% 
V_t(\omega) &=v(\tilde{y}(\omega)) +  
\int_0^t
\frac{\partial b}{\partial x}(s,Y_s(\omega),u_s)V_s(\omega)\dd s
+  
\int_0^t
\frac{\partial\sigma}{\partial x}(s,Y_s(\omega))V_s(\omega)\dd\mbB_s(\omega),
\quad t\in[0,T].
\end{align*}   
Then, $V\in L^\ell(\Omega,C([0,T],\R^n))$.
\end{theorem}
\begin{proof}
We first prove that $Y\in L^\ell(\Omega,C([0,T],\R^n))$. %The proof for $V$ is identical. 
Note that the assumption that $b$ is Lipschitz in the control input $u$ is not needed, as Lemma \ref{lem:rdes:continuity} and other  results used below still hold without this assumption since the control $u=\tilde{u}$ is fixed. 



\textit{1) Measurability}: As is standard in rough path theory, we express the solution map $Y$ as a composition of the measurable map $(y,\mbB):\Omega\to\R^n\times\sC^p_g$ and the pathwise solution to the RDE \eqref{eq:RDE}, which is continuous with respect to the initial condition and the driving signal.  First, 
 $(\sC^p_g,d_p)$ is a (complete) metric space (with  Borel sets defined by its metric topology), where  
$d_p(\mbX,\widetilde\mbX):=\|\Delta X_0\|+\|\Delta\mbX\|_p$ denotes the inhomogeneous rough path metric. 
% 
By Theorem \ref{thm:gaussian_rough_paths}, the map
\begin{align*}
\mbB:
\, 
(\Omega,\F,\Prob)&\to
(\sC^p_g([0,T],\R^d),d_p),
\  
\omega\mapsto \mbB(\omega)=(B(\omega),\bB(\omega))
\end{align*}
is measurable. Also, by Theorem \ref{thm:rdes:existence_unicity}, for any  initial conditions $\bar{y}\in\R^n$ and   geometric $p$-rough path $\mbX\in \sC_g^p$, the RDE   \eqref{eq:RDE} has a unique solution, denoted by $\big(\widehat{Y}_{(\bar{y},\mbX)},(\widehat{Y}_{(\bar{y},\mbX}))'\big)\in\sD^p_X$, so the map 
\begin{align*} 
\widehat{Y}_{(\cdot,\cdot)}:
\,
 \left(
\R^n\times \sC^p_g([0,T],\R^d),
\|\cdot\|\oplus d_p
\right)
&\to  
\left(C([0,T],\R^n),\|\cdot\|_\infty\right),
\ 
(\bar{y},\mbX)\mapsto \widehat{Y}_{(\bar{y},\mbX)}
\end{align*} 
is well-defined, where $\|\cdot\|\oplus d_p$ is the product metric.  
Moreover, if $\bar{y},\tilde{y}\in\R^n$ and $\mbX,\widetilde{\mbX}\in \sC_g^p$ satisfy  $\|\mbX\|_p,\|\widetilde{\mbX}\|_p\leq M$ for some $M\geq 0$, then  $\big\|\widehat{Y}_{(\bar{y},\mbX)}-\widehat{Y}_{(\tilde{y},\widetilde\mbX)}\big\|_\infty\leq 
C_{p,T,b,\sigma,M}
\left(
\|\bar{y}-\tilde{y}\| 
+
\|\Delta\mbX\|_p
\right)$ by \eqref{eq:RDE:DY:close:full_interval:continuity} in Lemma \ref{lem:rdes:continuity}, 
so the map $\widehat{Y}_{(\cdot,\cdot)}$ is continuous. 
Thus,  the map
\begin{align*}
Y:% 
\,
(\Omega,\F,\Prob)&\to
\left(C([0,T],\R^n),\|\cdot\|_\infty\right),
\ 
\omega\mapsto \widehat{Y}_{(y(\omega),\mbB(\omega))} 
\end{align*}
is measurable, since it is the composition of the measurable map $(y(\cdot),\mbB(\cdot))$ and the  continuous map $\widehat{Y}_{(\cdot,\cdot)}$.

\textit{2) Integrability}: 
By Lemma \ref{lem:rdes:bound:entire_interval},  there exist constants $C_{p,T,b,\sigma}\geq 1$ and $0<\alpha_{p,b,\sigma}<1$ such that  
\begin{align*}
\|Y\|_{\infty,[0,T]}
&\mathop{\leq}^{\eqref{eq:RDE:Y:bound:full_interval}}
C_{p,T,b,\sigma}\exp\left(
C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbB)
\right)+\|y\|
\end{align*}
almost surely, 
where $N_{\alpha,I}(\mbB)$ is defined in Definition \ref{def:Nalpha}. $\E[\|Y\|_\infty^\ell]<\infty$ then follows from Theorem \ref{thm:gaussian_rough_paths}.

Thus, $Y\in L^\ell(\Omega,C([0,T],\R^n))$. 

The proof that $V\in L^\ell(\Omega,C([0,T],\R^n))$ is identical, using Corollary \ref{cor:rde:linear:existence_uniqueness} (instead of Theorem \ref{thm:rdes:existence_unicity}), 
Lemma \ref{lem:rde:linearized:continuous} (instead of Lemma \ref{lem:rdes:continuity}) 
and Lemma \ref{lem:rde:linearized:bounded_solutions} (instead of Lemma \ref{lem:rdes:bound:entire_interval}).
\end{proof}


\begin{corollary}[Integrable error bound]\label{cor:rdes:integrable:error_bound} 
Define 
$T,p,\Omega,\F,\Prob,\mbB,\ell,y,\tilde{y},U,\sigma$
as in Theorem \ref{thm:rdes:integrable} with $\ell>1$,  
let $u,\tilde{u}\in L^\infty([0,T],U)$, 
 $b:[0,T]\times\R^n\times U\to\R^n,(t,x,u)\mapsto b(t,x,u)$ satisfy Assumption \ref{assumption:b} and be Lipschitz in $u$, 
and  $Y,\widetilde{Y}\in L^\ell(\Omega,C([0,T],\R^n))$ be the pathwise solutions to the random nonlinear RDEs
\begin{align*}
Y_t&=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbB_s,
\quad
\widetilde{Y}_t=\tilde{y}+\int_0^tb(s,\widetilde{Y}_s,\tilde{u}_s)\dd s+\int_0^t\sigma(s,\widetilde{Y}_s)\dd\mbB_s,
\quad t\in[0,T].
\end{align*} 
as in Theorem \ref{thm:rdes:integrable}. 
% 
Then, there exist constants $C:=C_{p,\ell,T,b,\sigma}\geq 1$ and  $0<\alpha:=\alpha_{p,b,\sigma}<1$ such that  
\begin{align*}
% 
\E\big[
\|Y-\widetilde{Y}\|_{\infty,[0,T]} 
\big]
&\leq
C
\E\left[
\exp\left(
CN_{\alpha,[0,T]}(\mbB)
\right)\right]^\frac{\ell}{\ell-1}
\big(
\E\big[\|y-\tilde{y}\|^\ell\big]^\frac{1}{\ell}
+
T\|u-\tilde{u}\|_{L^\infty([0,T],U)}
\big),
\end{align*}
where $\E[\exp(CN_{\alpha,[0,T]}(\mbB))]<\infty$. 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\end{corollary}
\begin{proof}
First, $\E[\exp(DN_{\alpha,[0,T]}(\mbB))]<\infty$ for any $D\geq 0$ and $\alpha>0$ by Theorem \ref{thm:gaussian_rough_paths}. 
Second, H\"older's inequality gives  $\E[\exp(DN_\alpha)\|\Delta y\|]\leq \E[\exp(\frac{\ell}{\ell-1} DN_\alpha)]^\frac{\ell-1}{\ell}\E[\|\Delta y\|^\ell]^\frac{1}{\ell}$ and similarly for $\E[\exp(DN_\alpha)T\|\Delta u\|_{L^\infty}]$. 
% 
Finally, the desired inequality  % 
follows from \eqref{eq:RDE:DY:close:full_interval} % 
in Proposition \ref{prop:rdes:error_bound:entire_interval} and  
 $N_{\alpha,[0,T]}(w)\leq C_p(
N_{\alpha,[0,T]}(\mbB)+T/\alpha+1
)$ by \eqref{eq:Nalpha<=3CpNalpha_X_and_time} in Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals}.
\end{proof}




















% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 













\section{The  Pontryagin Maximum Principle (\pmp)}\label{sec:pmp}

We now prove \pmp (Theorem \ref{thm:pmp}). First, in Section \ref{sec:linearization}, we consider particular variations of solutions to RDEs, called \textit{needle-like variations} \cite{Pontryagin1986,LeeMarkus1967,Agrachev2004,Bonnard2005}, and show that these variations can be approximated well using the solution to a linearized RDE (Lemma \ref{lem:needle_like_error:etas}) along the optimal solution $(x,u)$ to \ocp. The use of needle-like variations is a standard method for deriving a PMP that can handle the control constraints $u_t\in U$. 
Finally, in Section \ref{sec:pmp_proof}, we state the main assumptions for  \pmp and prove the result. 


\subsection{Needle-like variations}\label{sec:linearization}

% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 




% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 



% 

% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
 



The  needle-like variations rely on the concept of a Lebesgue point. %t, defined below.  % 

\begin{definition}[Lebesgue point]\label{def:lebesgue_point}
Let % 
$T>0$, % 
$U\subseteq\R^m$, 
$u\in L^\infty([0,T],U)$, 
% 
$b:[0,T]\times\R^n\times U\to\R^n$ satisfy  Assumption \ref{assumption:b}, % 
and $Y:[0,T]\to\R^n$ be continuous. 
% 
% 
We say that $t_1\in[0,T]$ is a Lebesgue point of $b$ for $u$ if
$
\lim_{h\to0}\frac{1}{h}\int_{t_1}^{t_1+h}b(t,Y_t,u_t)\dd t= b(t_1,Y_{t_1},u_{t_1})
$. 
Equivalently, $\big\| \int_{t_1}^{t_1+h}b(t,Y_t,u_t)\dd t- h\, b(t_1,Y_{t_1},u_{t_1})\big\|=o(h)$.  
\end{definition}
\begin{proposition}
[Needle-like variations and linearized RDEs]
\label{prop:linear_variation}  
% 
Let $p\in[2,3)$, $T>0$, $y\in\R^n$, $U\subseteq\R^m$, 
$u\in L^\infty([0,T],U)$, 
$b:[0,T]\times\R^n\times U\to\R^n,(t,x,u)\mapsto b(t,x,u)$   satisfy Assumption \ref{assumption:b:stronger}  and be Lipschitz in $u$, $\sigma\in C_b^4([0,T]\times\R^n,\R^n)$, and 
$\mbX\in\sC^p_g([0,T],\R^d)$ be a geometric $p$-rough path. 
% 
% 
% 
% 
% 
% 
Given a Lebesgue point $t_1\in[0,T]$ of $b$ for $u$, $\eta_1\in[0,T-t_1]$, and $\bar{u}_1\in U$, define the needle-like variation $\pi_1=(t_1,\eta_1,\bar{u}_1)$ of $u$ by 
 $$
 u^{\pi_1}_t=\begin{cases}
 \bar{u}_1\quad&\text{if }t\in[t_1,t_1+\eta_1],
 \\
 u_t&\text{otherwise}.
 \end{cases}
 $$ 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Let $(Y,Y')\in\sD^p_X$  and $(Y^{\pi_1},(Y^{\pi_1})')\in\sD^p_X$ with $Y'=\sigma(\cdot,Y_\cdot)$ and 
 $(Y^{\pi_1})'=\sigma(\cdot,Y^{\pi_1}_\cdot)$ solve the RDEs 
\begin{align*}
Y_t&=y+\int_0^tb(s,Y_s,u_s)\dd s+\int_0^t\sigma(s,Y_s)\dd\mbX_s,
\ \ 
Y^{\pi_1}_t=y+\int_0^tb(s,Y^{\pi_1}_s,u^{\pi_1}_s)\dd s+\int_0^t\sigma(s,Y^{\pi_1}_s)\dd\mbX_s,
\ \ 
t\in[0,T],
\end{align*}
 and $(V^{\pi_1},(V^{\pi_1})')\in\sD^p_X$ with $(V^{\pi_1})'=\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot)V^{\pi_1}_\cdot$ solve the linear RDE
\begin{subequations}\label{eq:rde:linear_variation}
\begin{align}
V^{\pi_1}_t&=b(t_1,Y_{t_1},\bar{u}_1)-b(t_1,Y_{t_1},u_{t_1}),
&&t\in[0,t_1],
\\
V^{\pi_1}_t &= 
V^{\pi_1}_{t_1}
+
\int_{t_1}^t
\frac{\partial b}{\partial x}(s,Y_s,u_s)V^{\pi_1}_s\dd s +
\int_{t_1}^t
\frac{\partial\sigma}{\partial x}(s,Y_s)V^{\pi_1}_s\dd\mbX_s,
 &&t\in[t_1,T].
\end{align}
\end{subequations}
Then, 
there exists constants $C_{p,T,b,\sigma}>0$ and $0<\alpha_{p,b,\sigma}<1$ such that % 
\begin{align}
\label{eq:needle_like_deltasols}
\|Y^{\pi_1}-Y\|_{\infty,[0,T]}
&\leq 
C_{p,T,b,\sigma}\exp\left(
C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)
\right)
\eta_1,
% 
% 
\\
\label{eq:needle_like_deltasols_variation}
\|Y^{\pi_1}-Y-\eta_1V^{\pi_1}\|_{\infty,[t_1,T]}&\leq C_{p,T,b,\sigma}\exp\left(
C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)
\right)
\eta_1^2,
\end{align}
% 
% 
where $N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)$ is defined in Definition \ref{def:Nalpha}. % 
\end{proposition} 
\begin{proof}
There exists unique solutions $Y,Y^{\pi_1},V^{\pi_1}$ to the RDEs  
% 
thanks to Theorem \ref{thm:rdes:existence_unicity} and  Corollary \ref{cor:rde:linear:existence_uniqueness}. 


 
The inequality \eqref{eq:needle_like_deltasols} follows from \eqref{eq:RDE:DY:close:full_interval:u_subinterval} in Proposition \ref{prop:rdes:error_bound:entire_interval}  and 
 $N_{\alpha,[0,T]}(w)\leq C_p(
N_{\alpha,[0,T]}(\mbX)+T/\alpha+1
)$ by \eqref{eq:Nalpha<=3CpNalpha_X_and_time} in Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals}, where   $N_{\alpha,[0,T]}(w)$ and $w$ are  defined in Definition \ref{def:Nalpha} and in Corollary \ref{cor:Nalpha:NX_NXtilde_NT:small_intervals}. %, respectively. 

% 
% 
% 


% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 


% 
% 
% 

In the remainder of the proof, we show the inequality  \eqref{eq:needle_like_deltasols_variation}. 
For conciseness, we denote $\Delta Y=Y^{\pi_1}-Y$,  $\Delta R^Y=R^{\Delta Y}=R^Y-R^{Y^{\pi_1}}$, $(b(x,u),\sigma(x))$ for $(b(t,x,u),\sigma(t,x))$, and similarly for derivatives and $$
\Delta:=Y^{\pi_1}-Y
-
\eta_1V^{\pi_1}.
$$ 
Let $t\geq t_1+\eta_1$.  We have
\begin{align*}
\Delta Y_t
&=
\int_{t_1}^t
b(Y^{\pi_1}_s,u^{\pi_1}_s)
\dd s
-
\int_{t_1}^t
b(Y_s,u_s)
\dd s
+
\int_{t_1}^t
(
\sigma(Y^{\pi_1}_s)-\sigma(Y_s)
)\dd\mbX_s
\\
&=
\int_{t_1}^{t_1+\eta_1}
b(Y^{\pi_1}_s,\bar{u}_1)
\dd s
+
\int_{t_1+\eta_1}^t
b(Y^{\pi_1}_s,u_s)
\dd s
-
\int_{t_1}^t
b(Y_s,u_s)
\dd s
+
\int_{t_1}^t
(
\sigma(Y^{\pi_1}_s)-\sigma(Y_s)
)
\dd\mbX_s
\\
&=
\int_{t_1}^{t_1+\eta_1}
(
b(Y^{\pi_1}_s,\bar{u}_1)
-
b(Y^{\pi_1}_s,u_s)
)
\dd s
+
\int_{t_1}^t
(
b(Y^{\pi_1}_s,u_s)
-
b(Y_s,u_s)
)
\dd s
+
\int_{t_1}^t
(
\sigma(Y^{\pi_1}_s)-\sigma(Y_s)
)
\dd\mbX_s,
\end{align*} 
so that, 
since $V^{\pi_1}_t = V^{\pi_1}_{t_1}+ 
\int_{t_1}^t\frac{\partial b}{\partial x}(Y_s,u_s)V^{\pi_1}_s\dd s+
\int_{t_1}^t\frac{\partial\sigma}{\partial x}(Y_s)V^{\pi_1}_s\dd\mbX_s$,
\begin{align*}
\Delta_t
&=
\int_{t_1}^{t_1+\eta_1}
(
b(Y^{\pi_1}_s,\bar{u}_1)
-
b(Y^{\pi_1}_s,u_s)
)
\dd s
-\eta_1V^{\pi_1}_{t_1}
+ 
\int_{t_1}^t
\left(
b(Y^{\pi_1}_s,u_s)
-
b(Y_s,u_s)
-
\eta_1\frac{\partial b}{\partial x}(Y_s,u_s)V^{\pi_1}_s
\right)
\dd s
\\
&\qquad+
\int_{t_1}^t
\left(
\sigma(Y^{\pi_1}_s)-\sigma(Y_s)
-
\eta_1\frac{\partial\sigma}{\partial x}(Y_s)V^{\pi_1}_s
\right)\dd\mbX_s.
\end{align*}
Next, by Taylor's Theorem \cite{Folland1990},
$b(Y^{\pi_1},u)
-
b(Y,u)
=
\frac{\partial b}{\partial x}(Y,u)
\Delta Y
+
\int_0^1
\big(
\frac{\partial b}{\partial x}(Y+\theta\Delta Y,u)-\frac{\partial b}{\partial x}(Y,u)
\big)
\dd\theta
\Delta Y$, 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
and similarly for $\sigma(Y^{\pi_1})
-
\sigma(Y)$ by the mean value theorem, 
\begin{align}\label{eq:Delta(t):full}
\Delta_t
&=
\int_{t_1}^{t_1+\eta_1}
(
b(Y^{\pi_1}_s,\bar{u}_1)
-
b(Y^{\pi_1}_s,u_s)
)
\dd s
-\eta_1V^{\pi_1}_{t_1}
+
\int_{t_1}^t
\int_0^1
\bigg(
\frac{\partial b}{\partial x}(Y_s+\theta\Delta Y_s,u_s)-\frac{\partial b}{\partial x}(Y_s,u_s)
\bigg)
\dd\theta
\Delta Y_s
\dd s
\\
\nonumber
&
\quad+
\int_{t_1}^t
\int_0^1\frac{\partial^2\sigma}{\partial x^2}(Y_s+\theta\Delta Y_s))(1-\theta)\dd\theta
\Delta Y^{\otimes 2}_s
\dd\mbX_s 
+
\left(
\int_{t_1}^t
\frac{\partial b}{\partial x}(Y_s,u_s)
\Delta(s)
\dd s+
\int_{t_1}^t
\frac{\partial\sigma}{\partial x}(Y_s)
\Delta_s
\dd\mbX_s
\right).
\end{align}
Next, we show that the first three terms are $o(\eta_1)$  in the following sense:
\begin{align}\label{eq:needlelike:o(eta1)}
A=o(\eta_1)\quad\text{if}\quad 
\|A\|&\leq 
C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}
N_{\alpha_{p,b,\sigma},[0,T]}(w)
\right)
\eta_1^2.
\end{align}
% 
First,
since $t_1$ is a Lebesgue point  and $Y^{\pi_1}_{t_1}=Y_{t_1}$,
\begin{align}
% 
\int_{t_1}^{t_1+\eta_1}
(
b(Y^{\pi_1}_s,\bar{u}_1)
-
b(Y^{\pi_1}_s,u_s)
)
\dd s
-\eta_1V^{\pi_1}_{t_1}
&=
\eta_1(
b(Y_{t_1},\bar{u}_1)
-
b(Y_{t_1},u_{t_1})
)-\eta_1V^{\pi_1}_{t_1}
+
o(\eta_1)
=
o(\eta_1).
\label{eq:Delta(t):term1}
\end{align}
Second, 
$\frac{\partial b}{\partial x}(x,u)$ is Lipschitz in $x$ and $\|\Delta Y\|_\infty^2=o(\eta_1)$ by \eqref{eq:RDE:DY:close:full_interval:u_subinterval}, so  
\begin{equation}
\label{eq:Delta(t):term2}
% 
% 
% 
% 
\int_{t_1}^t
\int_0^1
\bigg(
\frac{\partial b}{\partial x}(Y_s+\theta\Delta Y_s,u_s)-\frac{\partial b}{\partial x}(Y_s,u_s)
\bigg)
\dd\theta
\Delta Y_s
\dd s
=o(\eta_1).
\end{equation}
% 
Third, we bound the last rough integral, noting that
\begin{equation}\label{eq:RDE:DY'+dRY:close:full_interval:needle_like}
\|\Delta Y'\|_p
+
\|\Delta R^Y\|_\frac{p}{2}
+
\|\Delta Y\|_\infty
+
\|\Delta Y\|_p
\mathop{\leq}^{\eqref{eq:RDE:DY'+dRY:close:full_interval:u_subinterval},\eqref{eq:RDE:DY:close:full_interval:u_subinterval},
(\eqref{eq:controlled_path:pvar_norm},  \eqref{eq:||X||_p<=exp(N_alpha^p)})}
C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(w)
\right)
\eta_1.
\end{equation} 
Next, we define  $W_t = \Delta Y_t\otimes\Delta Y_t$ and $Z_t=
\int_0^1\frac{\partial^2\sigma}{\partial x^2}(Y_t+\theta\Delta Y_t)(1-\theta)\dd\theta$.
%\begin{align*}
%W_t = \Delta Y_t\otimes\Delta Y_t
%\quad\text{and }\quad
%Z_t=
%\int_0^1\frac{\partial^2\sigma}{\partial x^2}(Y_t+\theta\Delta Y_t)(1-\theta)\dd\theta.
%\end{align*}
By Lemma \ref{lem:control_path:product}, $(W,W')\in\sD^p_X$ is a controlled path with Gubinelli derivative $ 
W'=2\Delta Y\otimes \Delta Y'$,
\begin{subequations}\label{eq:ineqs:W}
\begin{align}
\|W'\|_p
&\mathop{\leq}^{\eqref{lem:control_path:product:(YZ)'_p}}
C_p(\|\Delta Y\|_\infty+\|\Delta Y\|_p+\|\Delta Y'\|_p+\|\Delta Y'\|_\infty)^2
\mathop{=}^{\eqref{eq:RDE:DY'+dRY:close:full_interval:needle_like}}
o(\eta_1),
\\
\|R^{W}\|_\frac{p}{2}
&\mathop{\leq}^{\eqref{lem:control_path:product:R^YZ_p/2}}
C_p(\|\Delta Y\|_\infty\|R^{\Delta Y}\|_\frac{p}{2}+\|\Delta Y\|_p^2)
\mathop{=}^{\eqref{eq:RDE:DY'+dRY:close:full_interval:needle_like}}
o(\eta_1),
\\
\|W\|_p
&\mathop{\leq}^{\eqref{eq:controlled_path:pvar_norm}}
C_p(\|W'\|_\infty\|X\|_p+\|R^W\|_\frac{p}{2})
\mathop{=}^{\eqref{eq:RDE:DY'+dRY:close:full_interval:needle_like},\eqref{eq:||X||_p<=exp(N_alpha^p)}}o(\eta_1),
\\
\|W\|_\infty
&\mathop{=}^{\eqref{eq:RDE:DY:close:full_interval:u_subinterval}}
o(\eta_1).
\end{align}
\end{subequations}
By Lemma \ref{lem:rough_path:sigma(.,Y):controlled}, $(Z,Z')\in\sD^p_X$ is also a controlled path, since $\frac{\partial^2 \sigma}{\partial x^2}\in C^2_b$ as $\sigma\in C^4_b$. 
By Lemma \ref{lem:control_path:product}, $(ZW,(ZW)')\in\sD^p_X$ is a controlled path with Gubinelli derivative  $
(ZW)'=WZ'+ZW'$, and   
\begin{subequations}\label{eq:ineqs:ZW}
\begin{align}
\|(ZW)'\|_p
&\mathop{\leq}^{\eqref{lem:control_path:product:(YZ)'_p}}
C_p(\|W\|_\infty\|Z'\|_p+\|Z'\|_\infty\|W\|_p+\|Z\|_\infty\|W'\|_p+\|W'\|_\infty\|Z\|_p)
\mathop{=}^{\eqref{eq:ineqs:W}}
o(\eta_1),
\label{eq:ineqs:ZW:||(ZW)'||_p}
\\
\|R^{ZW}\|_\frac{p}{2}
&\mathop{\leq}^{\eqref{lem:control_path:product:R^YZ_p/2}}
C_p(\|Z\|_\infty\|R^W\|_\frac{p}{2}+\|R^Z\|_\frac{p}{2}\|W\|_\infty+\|Z\|_p\|W\|_p)
\mathop{=}^{\eqref{eq:ineqs:W}}
o(\eta_1),
\\
\|(ZW)'\|_\infty
&\mathop{\leq}^{\eqref{eq:path_finite_var:infty_ineq}}
\|(ZW)'_0\|+\|(ZW)'\|_p
\mathop{=}^{\eqref{eq:ineqs:ZW:||(ZW)'||_p}}
o(\eta_1),
\end{align}
\end{subequations}
where the quantities $\|Z\|_p,\|Z'\|_p,\|Z'\|_\infty,\|R^Z\|_{\frac{p}{2}}$ can be bounded by $C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(w)
\right)$ using   \eqref{eq:RDE:Yp_Y'p_RYp/2:bound:full_interval} and \eqref{eq:RY:p/2var:Y^2+RY+T}.  
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Thus, for any $s,t>t_1$, 
\begin{align}
\left\|\int_s^tZ_sW_s\dd\mbX_s\right\|
&\mathop{\leq}^{\eqref{eq:rough_int:error_bound}}
\|Z_sW_sX_{s,t}\|+\|(ZW)'_s\bX_{s,t}\|+ C_p(\|R^{ZW}\|_{\frac{p}{2},[s,t]}\|X\|_{p,[s,t]}+\|(ZW)'\|_{p,[s,t]}\|\bX\|_{\frac{p}{2},[s,t]})
\nonumber
\\
&\leq
C_p\|\mbX\|_p(\|Z\|_{\infty,[s,t]}\|W\|_{\infty,[s,t]}+\|(ZW)'\|_{\infty,[s,t]}+\|R^{ZW}\|_{\frac{p}{2},[s,t]}+\|(ZW)'\|_{p,[s,t]})
\nonumber
\\
&\mathop{=}^{\eqref{eq:||X||_p<=exp(N_alpha^p)},\eqref{eq:ineqs:W},\eqref{eq:ineqs:ZW}}
o(\eta_1),
\ \  \text{so that }
\nonumber
\\
\label{eq:Delta(t):term3}
&\quad
\int_{t_1}^t
\int_0^1\frac{\partial^2\sigma}{\partial x^2}(Y+\theta\Delta Y))(1-\theta)\dd\theta
\Delta Y^{\otimes 2}
\dd\mbX_s
=o(\eta_1).
\end{align}
Thus, using (\eqref{eq:Delta(t):term1},\eqref{eq:Delta(t):term2},\eqref{eq:Delta(t):term3}),  \eqref{eq:Delta(t):full} can be written as
\begin{align*}
\Delta_t
&=
o(\eta_1) + 
\int_{t_1}^t
\frac{\partial b}{\partial x}(s,Y_s,u_s)
\Delta_s
\dd s
+
\int_{t_1}^t
\frac{\partial\sigma}{\partial x}(s,Y_s)
\Delta_s
\dd\mbX_s,
\end{align*}
where 
$
\|o(\eta_1)\|
\mathop{=}\limits^{\eqref{eq:needlelike:o(eta1)}}
C_{p,b,\sigma}\exp\left(
C_{p,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(w)
\right)
\eta_1^2
\mathop{\leq}\limits^{\eqref{eq:Nalpha<=3CpNalpha_X_and_time}}
C_{p,T,b,\sigma}\exp\left(
C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)
\right)
\eta_1^2$. 
% 
% 
% 
Finally, 
\begin{align*}
\|\Delta\|_{\infty,[t_1,T]}
&\mathop{\leq}^{\eqref{eq:rde:linearized:bounded_solutions}}
C_{p,T,b,\sigma}\exp\left(C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)\right)\|o(\eta_1)\|
\leq 
C_{p,T,b,\sigma}\exp\left(C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)\right)\eta_1^2
\end{align*} 
by  Lemma  \ref{lem:rde:linearized:bounded_solutions},   which concludes the proof.
\end{proof}

%\blue{
Proposition \ref{prop:linear_variation}  can be extended to needle-like variations with multiple spikes, see Corollary \ref{cor:needle_like_error:etas} in the
 \ifarxiv
appendix.
\else
supplementary material.
\fi 
By combining this result with Theorem \ref{thm:gaussian_rough_paths} and Theorem  \ref{thm:rdes:integrable}, we obtain:
%}


%\begin{corollary}[Needle-like variations]\label{cor:needle_like_error:etas}
%Define $p,T,y,U,u,b,\sigma,\mbX,N_{\alpha,[0,T]}(\mbX),Y,Y'$  as in Proposition \ref{prop:linear_variation}. Given $q\in\N$, let $0<t_1<\dots<t_q<T$ be Lebesgue points of $b$ for $u$ (Definition \ref{def:lebesgue_point}), 
%$\bar{u}_1,\dots,\bar{u}_q\in U$, 
% $0\leq \eta_i< t_{i+1}-t_i$ for $i=1,\dots, q-1$ and $0\leq\eta_q< T-t_q$, and define the needle-like variation $\pi=\{t_1,\dots,t_q,\eta_1,\dots,\eta_q,\bar{u}_1,\dots,\bar{u}_q\}$ of $u$ as the control $u^\pi$ defined by% 
% $$
% u^\pi_t=\begin{cases}
% \bar{u}_i\quad&\text{if }t\in[t_i,t_i+\eta_i],
% \\
% u_t&\text{otherwise}.
% \end{cases}
% $$ 
%Let $(Y^\pi,(Y^\pi)')\in\sD^p_X$ and  $(V^{\pi_i},(V^{\pi_i})')\in\sD^p_X$ for $i=1,\dots,q$ be the unique solutions to the RDEs
%\begin{align*}
%Y^\pi_t&=y+\int_0^tb(s,Y^\pi_s,u^\pi_s)\dd s+\int_0^t\sigma(s,Y^\pi_s)\dd\mbX_s,
% &&\hspace{-10mm}
% t\in[0,T], 
%\\
%V^{\pi_i}_t &= 
%V^{\pi_i}_{t_i}
%+
%\int_{t_i}^t
%\frac{\partial b}{\partial x}(s,Y_s,u_s)V^{\pi_i}_s\dd s +
%\int_{t_i}^t
%\frac{\partial\sigma}{\partial x}(s,Y_s)V^{\pi_i}_s\dd\mbX_s,
% &&\hspace{-10mm}
% t\in[t_i,T],
%\\
%V^{\pi_i}_t&=b(t_i,Y_{t_i},\bar{u}_i)-b(t_i,Y_{t_i},u_{t_i}),
% &&\hspace{-10mm}
% t\in[0,t_i].
%\end{align*}
%with  
% $(Y^{\pi_1})'=\sigma(\cdot,Y^{\pi_1}_\cdot)$  and   $(V^{\pi_1})'=\frac{\partial\sigma}{\partial x}(\cdot,Y_\cdot)V^{\pi_1}_\cdot$. 
% % 
%Then, there exists constants $C_{p,T,b,\sigma}>0$ and $0<\alpha_{p,b,\sigma}<1$ such that % 
%\begin{align}
%\label{eq:needle_like_deltasols:multi}
%\|Y^\pi-Y\|_{\infty,[0,T]}
%&\leq 
%C_{p,T,b,\sigma}\exp\left(
%C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)
%\right)
%\sum_{i=1}^q\eta_i,
%\\
%\label{eq:needle_like_deltasols_variation:multi}
%\Big\|Y^\pi-Y-\sum_{i=1}^q\eta_iV^{\pi_i}\Big\|_{\infty,[t_1,T]}&\leq 
%C_{p,T,b,\sigma}\exp\left(
%C_{p,T,b,\sigma}N_{\alpha_{p,b,\sigma},[0,T]}(\mbX)
%\right)
%\sum_{i,j=1}^q\eta_i\eta_j.
%\end{align}
%\end{corollary}
%% 
%As in the deterministic case, Corollary \ref{cor:needle_like_error:etas} follows by  induction, using Proposition \ref{prop:linear_variation} for the case $q=1$ with one variation $\pi_1=\{t_1,\eta_1,\bar{u}_1\}$. We provide the proof in the 
%\ifarxiv
%appendix.
%\else
%supplementary material.
%\fi
% 
 





 

 
 
 
\begin{lemma}[Needle-like variation formula for random RDEs]\label{lem:needle_like_error:etas}
Let %$T>0$, 
$\rho\in[1,\frac{3}{2})$, $p\in(2\rho,3)$, %, and $\ell\geq 1$. %Let $U,u,b,\sigma$ and  $u^\pi$ be the control associated to the needle-like variation $\pi=\{t_1,\dots,t_q,\eta_1,\dots,\eta_q,\bar{u}_1,\dots,\bar{u}_q\}$ of $u$  as in Corollary \ref{cor:needle_like_error:etas}.  
and define $T,U,u,b,\sigma$ as in Proposition \ref{prop:linear_variation}.
Given $q\in\N$, let $0<t_1<\dots<t_q<T$ be Lebesgue points of $b$ for $u$ (Definition \ref{def:lebesgue_point}), 
$\bar{u}_1,\dots,\bar{u}_q\in U$, 
 $0\leq \eta_i< t_{i+1}-t_i$ for $i=1,\dots, q-1$ and $0\leq\eta_q< T-t_q$, and define the needle-like variation $\pi=\{t_1,\dots,t_q,\eta_1,\dots,\eta_q,\bar{u}_1,\dots,\bar{u}_q\}$ of $u$ as the control $u^\pi$ defined by% 
 $$
 u^\pi_t=\begin{cases}
 \bar{u}_i\quad&\text{if }t\in[t_i,t_i+\eta_i],
 \\
 u_t&\text{otherwise}.
 \end{cases}
 $$ 
% 
Let $\Omega,\F,\Prob,B,\mbB,\ell,y,Y,Y'$ be as in Theorem \ref{thm:rdes:integrable}, with  $\mbB=(B,\bB)$ an enhanced Gaussian process and $(Y(\omega),Y'(\omega))\in\sD^p_{B(\omega)}([0,T],\R^n)$  the pathwise solution to the RDE
\begin{align}
\tag{\ref{eq:RDE}}
Y_t(\omega)&=y(\omega)+\int_0^tb(s,Y_s(\omega),u_s)\dd s+\int_0^t\sigma(s,Y_s(\omega))\dd\mbB_s(\omega),
\quad\ \ t\in[0,T].
\end{align}  
As in Theorem \ref{thm:rdes:integrable}, 
let $(Y^\pi(\omega),(Y^\pi(\omega))')\in\sD^p_{B(\omega)}([0,T],\R^n)$ be the pathwise solution to the RDE
\begin{align*} 
Y^\pi_t(\omega)=y(\omega)+\int_0^tb(s,Y^\pi_s(\omega),u^\pi_s)\dd s+\int_0^t\sigma(s,Y^\pi_s(\omega))\dd\mbB_s(\omega),
\  t\in[0,T],
\end{align*}
and for $i=1,\dots,q$, let $(V^{\pi_i}(\omega),(V^{\pi_i}(\omega))')\in\sD^p_{B(\omega)}([0,T],\R^n)$ be the pathwise solutions to the RDEs 
\begin{subequations}
\begin{align*}
V^{\pi_i}_t(\omega) &= 
V^{\pi_i}_{t_i}(\omega)
+
\int_{t_i}^t
\frac{\partial b}{\partial x}(s,Y_s(\omega),u_s)V^{\pi_i}_s(\omega)\dd s +
\int_{t_i}^t
\frac{\partial\sigma}{\partial x}(s,Y_s(\omega))V^{\pi_i}_s(\omega)\dd\mbB_s(\omega),
 &&t\in[t_i,T],
\\
V^{\pi_i}_t(\omega)&=b(t_i,Y_{t_i}(\omega),\bar{u}_i)-b(t_i,Y_{t_i}(\omega),u_{t_i}),
&&t\in[0,t_i],
\end{align*}
\end{subequations}
with $Y,Y^\pi,V^{\pi_1},\dots,V^{\pi_q}\in L^\ell(\Omega,C([0,T],\R^n))$.  
% 
Let $\varphi:\R^n\to\R^{\tilde{q}}$ be continuously differentiable and satisfy $\big\|\frac{\partial\varphi}{\partial x}(x)\big\|
% 
\leq C_\varphi$ 
and 
$\big\|\frac{\partial\varphi}{\partial x}(x)-\frac{\partial\varphi}{\partial x}(\tilde{x})\big\|\leq C_\varphi\|x-\tilde{x}\|$ for all $x,\tilde{x}\in\R^n$ for some constant $C_\varphi<\infty$. 
% 
 Then, 
\begin{align}
\label{eq:needle_like_deltasols:B}
\E\left[
\left\|
\varphi(Y^\pi)-\varphi(Y)
\right\|_{\infty,[0,T]}
\right]
&\leq 
C\,
\E\left[\exp(CN_{\alpha,[0,T]}(\mbB))\right]
\sum_{i=1}^q\eta_i,
\\
\label{eq:needle_like_deltasols_variation:B}
\E\bigg[
\bigg\|
\varphi(Y^\pi)-\varphi(Y)-\sum_{i=1}^q\eta_i\frac{\partial\varphi}{\partial x}(Y)V^{\pi_i}
\bigg\|_{\infty,[t_q,T]}
\bigg]
&\leq 
C\,
\E\left[\exp(CN_{\alpha,[0,T]}(\mbB))\right]
\sum_{i,j=1}^q\eta_i\eta_j, 
\end{align}
where $0<C<\infty$ and $0<\alpha<1$ are constants  that depend only on $(p,T,b,\sigma,\varphi)$, and $\E\left[\exp(CN(\mbB))\right]<\infty$.
\end{lemma}
\begin{proof}
For conciseness, we only prove the case $q=1$ corresponding to  one variation  $\pi_1:=\{t_1,\eta_1,\bar{u}_1\}$ of the control input $u$, as the case $q\geq2$ follows by using Corollary \ref{cor:needle_like_error:etas} instead of Proposition \ref{prop:linear_variation}. Also, note that  Theorem \ref{thm:rdes:integrable} ensures that the pathwise solutions to the RDEs are well-defined and integrable.
 
% 
By Proposition \ref{prop:linear_variation}, there exist constants $C>0$ and $0<\alpha<1$ that  depend on $(p,T,b,\sigma)$ such that 
\begin{align*}  
\|Y^{\pi}-Y\|_{\infty,[0,T]}
&\mathop{\leq}^{\eqref{eq:needle_like_deltasols}} 
C\exp\left(
CN_{\alpha,[0,T]}(\mbB)
\right)
\eta_1,
\quad
\|Y^{\pi}-Y-\eta_1V^{\pi_1}\|_{\infty,[t_1,T]}
\mathop{\leq}^{\eqref{eq:needle_like_deltasols_variation}}
C\exp\left(
CN_{\alpha,[0,T]}(\mbB)
\right)
\eta_1^2
\end{align*}
almost surely, 
and where $\E\left[\exp(CN_{\alpha,[0,T]}(\mbB))\right]<\infty$ by Theorem \ref{thm:gaussian_rough_paths}. % 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Also, with $\Delta Y:=Y^{\pi}-Y$, by the mean value theorem and   Taylor's Theorem \cite{Folland1990},  
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
since $\frac{\partial\varphi}{\partial x}$ is Lipschitz,
% 
% 
\begin{align*}
\|\varphi(Y^{\pi})-\varphi(Y)\|
&=
\left\|
\int_0^1\frac{\partial\varphi}{\partial x}(Y+\theta\Delta Y)\dd\theta\Delta Y
\right\|
\leq C_\varphi\|\Delta Y\|.
\\
% 
% 
% 
\left\|
\varphi(Y^{\pi})-\varphi(Y)-\eta_1\frac{\partial\varphi}{\partial x}(Y)V^{\pi_1}
\right\|
&=
\left\|
\frac{\partial\varphi}{\partial x}(Y)
(\Delta Y-\eta_1V^{\pi_1})
+
% 
\int_0^1
\bigg(
\frac{\partial\varphi}{\partial x}(Y+\theta\Delta Y)-\frac{\partial \varphi}{\partial x}(Y)
\bigg)
\dd\theta
\Delta Y
% 
% 
\right\|
\\
&\leq 
C_\varphi(\|\Delta Y-\eta_1V^{\pi_1}\|+\|\Delta Y\|^2).
\end{align*}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
The desired inequalities \eqref{eq:needle_like_deltasols:B} and \eqref{eq:needle_like_deltasols_variation:B} follow from the previous inequalities. 
\end{proof}















































































\subsection{Proof of the  Pontryagin Maximum Principle}\label{sec:pmp_proof}

We prove \pmp under the assumptions below. 


\begin{assumption}[Assumptions for \ocp and \pmp (Theorem \ref{thm:pmp})]
\label{assum:pmp}
Let $T>0$, $\rho\in[1,\frac{3}{2})$, $p\in(2\rho,3)$, 
$\ell\geq 2$, 
$U\subseteq\R^m$,  
and $(\Omega,\F,\Prob)$ be a probability space. 
% 
\begin{itemize}
\item The drift   $b:[0,T]\times\R^n\times U\to\R^n$ and cost  $f:[0,T]\times\R^n\times U\to\R$  
% 
% 
% 
% 
% 
satisfy Assumption \ref{assumption:b:stronger} and are Lipschitz in $u$ for a constant $C_{b,f}\geq 0$, that is:
% 
% 
% 
% 
% 
% 
% 
% 
\begin{itemize} 
\item 
$b(\cdot, x, u):[0,T]\to\R^n$  is  measurable for all $(x,u)\in\R^n\times U$,  
\item  
$b(t,\cdot,\cdot):\R^n\times U\to\R^n$ 
is continuous for almost every $t\in[0,T]$,
\item 
$b(t,\cdot,u):\R^n\to\R^n$  is  continuously differentiable  for almost every $t\in[0,T]$  and  all $u\in U$,  
\item 
$\|b(t,x,u)\|+\big\|\frac{\partial b}{\partial x}(t,x,u)\big\| \leq C_{b,f}$ 
and 
$\big\|\frac{\partial b}{\partial x}(t,x,u)-\frac{\partial b}{\partial x}(t,\tilde{x},u)\big\|\leq C_{b,f}\|x-\tilde{x}\|$  
for almost every $t\in[0,T]$, all $x,\tilde{x}\in\R^n$, and all $u\in U$,
\item % 
$\|b(t,x,u)-b(t,x,\tilde{u})\|\leq C_{b,f}\|u-\tilde{u}\|$ for almost every $t\in[0,T]$, all $x\in\R^n$, and all $u,\tilde{u}\in U$,
\end{itemize}
and similarly for $f$.


% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\item The diffusion $\sigma:[0,T]\times\R^n\to\R^{n\times d}$ satisfies $\sigma\in C^4_b([0,T]\times\R^n,\R^{n\times d})$.
\item The terminal cost $g:\R^n\to\R$ and constraints $h:\R^n\to\R^r$ are continuously differentiable and % 
% 
% 
satisfy 
$\big\|\frac{\partial g}{\partial x}(x)\big\|+\big\|\frac{\partial h}{\partial x}(x)\big\|
\leq C_{g,h}$
and 
$\big\|\frac{\partial g}{\partial x}(x)-\frac{\partial g}{\partial x}(\tilde{x})\big\|
+
\big\|\frac{\partial h}{\partial x}(x)-\frac{\partial h}{\partial x}(\tilde{x})\big\|
\leq C_{g,h}\|x-\tilde{x}\|$ for all $x,\tilde{x}\in\R^n$ 
for a constant $C_{g,h}>0$.


% 
\item The initial conditions $x_0$ satisfy $x_0\in L^\ell(\Omega,\R^n)$.
\item $B:\Omega\to C([0,T],\R^d)$  is a centered, continuous, $\R^d$-valued Gaussian process with independent components   satisfying Assumption \ref{assum:Gaussian_lift} for $\rho$, and the driving signal 
$\mbB=(B,\bB):\Omega\to\sC^p_g([0,T],\R^d)$ is the enhanced Gaussian process in Theorem \ref{thm:gaussian_rough_paths} associated  to $B$ that satisfies \eqref{eq:gaussian_rough_paths:E[exp(Nalpha)]<infty}.
\end{itemize}
\end{assumption}



% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 


These assumptions on $(b,f)$ are reasonable, see for instance \cite{Diehl2016,Allan2020,BonalliLewESAIM2022} that make similar assumptions. 
The boundedness assumption on $b$ holds for control-affine drifts $b(t,x,u)=b_0(t,x)+b_1(t,x)u$ if  $(b_0,b_1)$ satisfy Assumption \ref{assumption:b:stronger} and  $U$ is bounded, and similarly for  $f$ if it is quadratic in  $u$ and $U$ is bounded.  See also
Remark \ref{remark:b_bounded} for technical considerations.  
Assuming  boundedness is reasonable in applications, as dynamical systems are often constrained to operate in a bounded set of  conditions representing physical constraints (i.e., $x_t\in\mathcal{X}$ with $\mathcal{X}\subset\R^n$ a compact set). 
% 
% 
% 
% 
 The assumption
$\sigma\in C^4_b$ is discussed in Remarks \ref{remark:sigma_smoothness} and \ref{remark:sigma_smoothness:2}: It is stronger than assumptions used in standard PMPs using It\^o calculus due to the use of rough path theory. % 
As discussed in Sections \ref{sec:introduction} and \ref{sec:preliminaries}, the class of enhanced Gaussian processes $\mbB=(B,\bB)$ from Theorem \ref{thm:gaussian_rough_paths} is large (see the many examples in \cite{Friz2016}) and covers scenarios where $B$ is not a semimartingale (such as with fractional Brownian motion) that cannot be tackled via It\^o calculus. In particular, the Stratonovich lift of Brownian motion satisfies this assumption. % 

% 
% 
% 
% 
% 
% 
% 
% 
% 
\textbf{Proof sketch}: We now  prove Theorem \ref{thm:pmp} in the following steps:
\begin{itemize}
  \setlength\itemsep{0pt}
\item \textit{Augmented state, needle-like variations, and end-point mapping}: We define an augmented state $\tilde{x}=(x,x^0)$ that contains the state $x$ and its associated cost $x^0$,  the needle-like variations $u^\pi$ around the optimal control $u$, and the  end-point mapping $F^q$ that evaluates variations of the expected  terminal cost and constraints as the needle-like variation $\pi$ changes.
\item \textit{Variational linearization and separation argument}: We evaluate the end-point mapping $F^q$ around the optimal control $u$, and argue by contradiction to deduce the existence of the non-trivial Lagrange multiplier $(\mathfrak{p}_0,\dots,\mathfrak{p}_r)$ using a hyperplane separation argument based on Brouwer's fixed point theorem.
\item \textit{Adjoint RDE dynamics \eqref{eq:spmp:pmp_equations} and transversality condition \eqref{eq:spmp:transversality_condition:pT}}: We define the adjoint vector $p$ as the solution to the random linear RDE \eqref{eq:spmp:pmp_equations}, using the backward representation of rough integrals  \cite[Proposition 5.12]{Friz2020} to ensure that the terminal value $p_T$ satisfies the   transversality condition \eqref{eq:spmp:transversality_condition:pT}.
\item \textit{Maximality condition \eqref{eq:spmp:maximizality_condition}}: We use a contradiction argument by combining the inequality from the previous hyperplane separation theorem with  It\^o's lemma to deduce the maximality condition \eqref{eq:spmp:maximizality_condition}.
\end{itemize}
The main differences with standard proofs of previous stochastic PMPs \cite{Peng1990,Yong1999,BonalliLewESAIM2022} are 
\begin{itemize}
  \setlength\itemsep{0pt}
\item using random linear RDEs to evaluate the effect of needle-like variations  (here, the integrability of our bounds using greedy partitions and the integrability properties of Gaussian rough paths is key), 
\item defining the adjoint vector using a random RDE instead of FBSDEs (switching between forward and backward integration is done via \cite[Proposition 5.12]{Friz2020}, noting that rough path theory does not rely on non-anticipativity or martingale arguments), and 
\item deducing the maximality condition using a pathwise use of It\^o's lemma  % 
to   mimic the proof of the deterministic PMP (i.e., the chain rule of It\^o's lemma gives us $\tilde{p}_t^\top \tilde{v}_t=\tilde{p}_T^\top \tilde{v}_T$ for all $t\in[0,T]$ almost surely \eqref{eq:pmp:proof:pv=cst} as in the deterministic setting, e.g., see \cite[page 254]{LeeMarkus1967} or  \cite[page 161]{Bonnard2005}).  
\end{itemize}

\textbf{Preliminary step -- Augmented state, needle-like variations, and end-point mapping.}
% 
For any control $v\in L^\infty([0,T],U)$, consider the cost-augmented state $\tilde{x}_t = (x_t,x^0_t)$ and the random RDE 
\begin{align}
\label{eq:sde:cost_augmented}
\tilde{x}_t 
&=
\tilde{x}_0 + 
\int_0^t
\tilde{b}(s,\tilde{x}_s,v_s)\dd s + 
\int_0^t
\tilde{\sigma}(s,\tilde{x}_s)\dd\mbB_s
= 
\begin{bmatrix}
x_0
\\
0
\end{bmatrix}
+
\int_0^t
\begin{bmatrix}
b(s,x_s,v_s)
\\
f(s,x_s,v_s)
\end{bmatrix}\dd s + 
\int_0^t
\begin{bmatrix}
\sigma(s,x_s) \\ 0
\end{bmatrix}\dd\mbB_s,
\ t\in[0,T],
\end{align}
which has a well-defined solution $\tilde{x}^v=(x^v,x^{0,v})\in L^\ell(\Omega,C([0,T],\R^{n+1}))$ by Theorem \ref{thm:rdes:integrable} with  almost surely 
 $(\tilde{x}^v(\omega),(\tilde{x}^v(\omega))')\in\sD^p_{B(\omega)}([0,T],\R^{n+1})$. 
The first $n$ components $x^v$ of $\tilde{x}^v$ is the state trajectory associated to the control $v$, and  the last component $x^{0,v}$ of $\tilde{x}^v$ is the accumulated cost over the trajectory $(x^v,v)$. 
Given the optimal control $u$ that solves \ocp, $\tilde{x}:=\tilde{x}^u$ denotes the optimal cost-augmented state trajectory. 

Next, we define the needle-like variations of   the optimal control $u$ as in Lemma \ref{lem:needle_like_error:etas}. Given $q\in\N$, let $0<t_1<\dots<t_q<T$ be Lebesgue points of $b$ for $u$ (Definition \ref{def:lebesgue_point}), 
$\bar{u}_1,\dots,\bar{u}_q\in U$, 
 $0\leq \eta_i< t_{i+1}-t_i$ for $i=1,\dots, q-1$ and $0\leq\eta_q< T-t_q$, and define the needle-like variation $\pi=\{t_1,\dots,t_q,\eta_1,\dots,\eta_q,\bar{u}_1,\dots,\bar{u}_q\}$ of $u$ as the control $u^\pi$ defined by% 
 $$
 u^\pi_t=\begin{cases}
 \bar{u}_i\quad&\text{if }t\in[t_i,t_i+\eta_i],
 \\
 u_t&\text{otherwise}.
 \end{cases}
 $$
Let $\tilde{x}^\pi:=\tilde{x}^{u^\pi}$ be the solution to the random RDE \eqref{eq:sde:cost_augmented} associated to the control $u^\pi$. 
 As shown in  Lemma \ref{lem:needle_like_error:etas},  the difference $x^\pi-x$ can be approximated using the pathwise solutions $\tilde{v}^{\pi_i}\in L^\ell(\Omega,C([t_i,T],\R^{n+1}))$ to the random linear RDEs 
\begin{align}\label{eq:sde:cost_augmented:linear}
\tilde{v}^{\pi_i}_t 
&=
\tilde{b}(t_i,\tilde{x}_{t_i},\bar{u}_i)
-
\tilde{b}(t_i,\tilde{x}_{t_i},u_{t_i})
 + 
\int_{t_i}^t
\frac{\partial\tilde{b}}{\partial\tilde{x}}(s,\tilde{x}_s,u_s)
\tilde{v}^{\pi_i}_s
\dd s + 
\int_{t_i}^t
\frac{\partial\tilde{\sigma}}{\partial\tilde{x}}(s,\tilde{x}_s)
\tilde{v}^{\pi_i}_s
\dd\mbB_s,
\quad t\in[t_i,T],
\end{align}
where $i=1,\dots,q$ and $(\tilde{v}^{\pi_i}(\omega),(\tilde{v}^{\pi_i}(\omega))')\in\sD^p_{B(\omega)}$ almost surely.   
% 
 % 
 Next, we define the map
$$
\widetilde\Phi:\R^{n+1}\to\R^{r+1}, \
 \tilde{x}=(x,x^0)
\mapsto
\big(
h(x), \, x^0+g(x)
\big),
$$
which evaluates the terminal constraint and total cost associated to \ocp for an augmented state $\tilde{x}$. 
% 
Also,  with  $
\R_+^q=\left\{\eta=(\eta_1,\dots,\eta_q)\in\R^q: \eta_1\geq 0,\dots,\eta_q\geq 0\right\}$, 
$\delta=\min\{t_{i+1}-t_i, T-t_q, i=1,\dots, q\}$ and $B^q_\delta=\{\eta\in\R^q:\|\eta\|<\delta\}$, we define the end-point mapping  $F^q:B^q_\delta\cap\R^q_+\to\R^{r+1}$ by 
\begin{equation}\label{eq:spmp:needlelike_endpoint_mapping}
% 
% 
% 
F^q(\eta)
=
\E\left[
\widetilde\Phi\left(\tilde{x}^\pi_T\right)
-
\widetilde\Phi\left(\tilde{x}_T\right)
\right]
=
\begin{bmatrix}
\E\big[
h(x^\pi_T)-h(x_T)
\big]
\\
\E\big[x^{\pi,0}_T+g(x^\pi_T)
-
(x_T^0+g(x_T))\big]
\end{bmatrix}
\end{equation}
which satisfies $F^q(0)=0$, 
and  the linear map $\dd F_0^q:\R^q_+\to\R^{r+1}$ by
\begin{equation}\label{eq:end_point_mapping:differential}
\dd F_0^q(\eta)=
\sum_{i=1}^q\eta_i
\E\left[
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T)
\tilde{v}^{\pi_i}_T
\right].
\end{equation}
The map 
$\dd F_0^q$ is the Gateaux differential of $F^q$ at $0$ in the direction $\eta$:% 
\begin{equation}\label{eq:end_point_mapping:gateaux_differentiable}
\lim_{ \alpha>0, \, \alpha\to 0 }
\frac{F^q(\alpha\eta)}{\alpha}=
\dd F^q_0(\eta)
\
\text{ for any }\eta\in\R^q_+.
\end{equation}
Indeed,  by Lemma \ref{lem:needle_like_error:etas} and Jensen's inequality,  for a constant $C>0$  and $\alpha>0$ small-enough, 
$$
\big\|
F^q(\alpha\eta)-\dd F_0^q(\alpha\eta)
\big\|
\leq
\E\bigg[
\bigg\|
\widetilde\Phi\left(\tilde{x}^\pi_T\right)
-
\widetilde\Phi\left(\tilde{x}_T\right)
-
\sum_{i=1}^q\alpha\eta_i
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T)
\tilde{v}^{\pi_i}_T
\bigg\|
\bigg]
\mathop{\leq}^{\eqref{eq:needle_like_deltasols_variation:B}}
C \sum_{i,j=1}^q\alpha^2\eta_i\eta_j,
$$
so   \eqref{eq:end_point_mapping:gateaux_differentiable} follows after dividing by $\alpha$ and taking the limit as $\alpha\to 0$.  
 
Note also that multiple derivatives in $(\tilde{b},\tilde{\sigma},\widetilde\Phi)$ are zero as they do not depend on $x^0$, so
\begin{equation}\label{eq:tilde_b_sig_Phi}
\frac{\partial\tilde{b}}{\partial\tilde{x}}(t,x,u)^\top
=
\begin{bmatrix}
\frac{\partial b}{\partial x}(t,x,u) & \frac{\partial f}{\partial x}(t,x,u) 
\\
0 & 0
\end{bmatrix},
\quad
\frac{\partial\tilde\sigma}{\partial\tilde{x}}(t,x)^\top
=
\begin{bmatrix}
\frac{\partial\sigma}{\partial x} & 0 
\\
0 & 0
\end{bmatrix},
\quad
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(x)=\begin{bmatrix}
\frac{\partial h}{\partial x}(x) & 0 
\\
\frac{\partial g}{\partial x}(x) & 1
\end{bmatrix}.
\end{equation}

 
\textbf{Step 1) -- Variational linearization and separation argument.}
% 
The first step of the proof %of \pmp 
proceeds by contradiction, using the end-point mapping $F^q$ % 
and a Brouwer fixed point argument.  We start by defining the 
% 
% 
% 
% 
% 
 % 
 % 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
closed convex cone
$$
K=
\overline{
\left\{
\sum_{i=1}^q\alpha_i
\E\left[
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T)
\tilde{v}^{\pi_i}_T
\right]
\,:\,
\alpha_i\geq 0,
\
\pi_i\text{ is a needle-like variation of $u(\cdot)$},
\
q\in\N
\right\}
},
$$
and note that 
$K\subset\R^{r+1}$. Indeed, by contradiction,  if $K=\R^{r+1}$, then  $\dd F_0^q(\R^q_+)=K=\R^{r+1}$, so $0\in\Int(F^q(B^q_\delta\cap\R^q_+))$ by \cite[Lemma 12.4]{Agrachev2004} (whose proof relies on Brouwer's fixed point theorem). % 
In particular, there exists another feasible trajectory $(x^\pi,u^\pi)$ with a strictly lower cost $\E[x^{\pi,0}_T+g(x^\pi_T)]<\E[x^0_T+g(x_T)]$, so $(x,u)$ is not optimal, which is a contradiction. 
%
Thus, $K\subset\R^{r+1}$. 

\begin{figure}[t]
\centering
\includegraphics[width=0.4\textwidth]{figs/pontryagin_cone_optimal.jpg}
\caption{Separation hyperplane argument at the optimal trajectory $(x,u)$. The blue region is the reachable set  $\{\E[\widetilde\Phi(\tilde{x}^v)], v\in L^\infty([0,T],U)\}$. The cone  $K\subset\R^{r+1}$, otherwise we would be able to find  a feasible trajectory $(x^v,v)$ with lower cost, so $(x,u)$ would not be optimal.}
\label{fig:comparison}
\end{figure}

By the  hyperplane separation theorem, there exists a non-zero vector $\mathfrak{p}=(\mathfrak{p}_1,\dots,\mathfrak{p}_r,\mathfrak{p}_0)\in\R^{r+1}$   such that $\mathfrak{p}_0\leq 0$ and 
$\mathfrak{p}^\top z
\leq 
0$ for all $z\in K$. By renormalizing $\mathfrak{p}$, we may assume that $\mathfrak{p}_0\in\{0,-1\}$. The condition $\mathfrak{p}^\top z
\leq 
0$ for all $z\in K$ can be written as 
\begin{equation}\label{eq:spmp:proof:mu^TEgradPhiv<=0}
\mathfrak{p}^\top\,
\E\left[
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T)
\tilde{v}^{\pi_1}_T
\right]
\leq 
0
\ \ 
\text{for all needle-like variations $\pi_1=(t_1,\eta_1,\bar{u}_1)$ of $u$}.
\end{equation} 
% 


\textbf{Step 2) -- Adjoint equation \eqref{eq:spmp:pmp_equations} and transversality condition \eqref{eq:spmp:transversality_condition:pT}.}
% 
% 
Define the reversed processes $\big(\overleftarrow{\ \tilde{x}_t},\overleftarrow{\ u_t^{\phantom{a}}},\overleftarrow{\mbB}_t\big)
:=
\big(\tilde{x}_{T-t},u_{T-t},\mbB_{T-t}\big)$. Then, using Theorem \ref{thm:rdes:integrable} 
(with minor modifications, noting with \cite[Proposition 5.12]{Friz2020} that $\overleftarrow{\tilde{x}}$ is the pathwise solution to an RDE driven by $\overleftarrow{\mbB}$, and since  including a drift term in \cite[Proposition 5.12]{Friz2020} poses no difficulty as  linear RDEs with drift can be rewritten as driftless linear RDEs along a new geometric rough path as in the proof of Theorem \ref{thm:rde:linear:existence_uniqueness}), 
we define the pathwise solution $\overleftarrow{\tilde{p}}\in L^\ell(\Omega,C([0,T],\R^{n+1}))$ to the random linear RDE
\begin{align*}
\overleftarrow{\ \tilde{p}_t}
 &=
\mathfrak{p}^\top \frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T) 
+ \int_0^t
\frac{\partial\tilde{b}}{\partial\tilde{x}}
\big(
s,
\overleftarrow{\ \tilde{x}_s},
\overleftarrow{\ u_s^{\phantom{a}}}
\big)^\top
\overleftarrow{\ \tilde{p}_s}\dd s
+
\int_0^t
\frac{\partial\tilde{\sigma}}{\partial\tilde{x}}\big(s,\overleftarrow{\ \tilde{x}_s}\big)^\top \overleftarrow{\ \tilde{p}_s}\dd\overleftarrow{\mbB}_s,
\quad
t\in[0,T],
\end{align*}
where  $\big(\overleftarrow{\tilde{p}}(\omega),\overleftarrow{\tilde{p}}(\omega)'\big)\in\sD_{\overleftarrow{B}(\omega)}^p$ almost surely. 
% 
% 
Next, we define the adjoint vector $\tilde{p}\in L^\ell(\Omega,C([0,T],\R^n))$ by $(\tilde{p}_t,\tilde{p}_t'):=\big(\overleftarrow{\tilde{p}}_{T-t},\overleftarrow{\tilde{p}}'_{T-t}\big)$ for all $t\in[0,T]$ almost surely. 
By \cite[Proposition 5.12]{Friz2020}, % 
the sample paths satisfy $(\tilde{p}(\omega),\tilde{p}(\omega)')\in\sD^p_{B(\omega)}$ almost surely and solve the linear RDE 
\begin{align*}
 \tilde{p}_t(\omega)&=
\tilde{p}_0(\omega)
-\int_0^t
\frac{\partial\tilde{b}}{\partial\tilde{x}}(s,\tilde{x}_s(\omega),u_s)^\top
\tilde{p}_s(\omega)\dd s
-
\int_0^t
\frac{\partial\tilde{\sigma}}{\partial\tilde{x}}(s,\tilde{x}_s(\omega))^\top \tilde{p}_s(\omega)\dd\mbB_s(\omega),
\quad
t\in[0,T],
\end{align*}
with $\tilde{p}_0=\overleftarrow{\ \tilde{p}_T}\in L^\ell(\Omega,\R^{n+1})$,
 which gives  the adjoint equation \eqref{eq:spmp:pmp_equations}, since multiple derivatives in $(\tilde{b},\tilde{\sigma})$ are zero by \eqref{eq:tilde_b_sig_Phi}. Also,  $\tilde{p}_T=\overleftarrow{\ \tilde{p}_0}=\mathfrak{p}^\top
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T) $ gives the transversality condition \eqref{eq:spmp:transversality_condition:pT}  
\begin{align*} 
\tilde{p}_T
&= 
\mathfrak{p}^\top
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T) 
\mathop{=}^{\eqref{eq:tilde_b_sig_Phi}}
\left(
\sum_{i=1}^r\mathfrak{p}_i
\frac{\partial h_i}{\partial x}(x_T)
+
\mathfrak{p}_0  
\frac{\partial g}{\partial x}(x_T),
\ 
\mathfrak{p}_0
\right)
\ \text{ almost surely}.
\end{align*}   
Also $\dd p^0_t=0$ by \eqref{eq:tilde_b_sig_Phi}, so  $p^0_t=\mathfrak{p}_0$ for all $t\in[0,T]$. 

% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 

 


\textbf{Step 3) -- Maximality condition \eqref{eq:spmp:maximizality_condition}.} 
We observe that $
\tilde{v}^{\pi_1}_t{}^\top
\frac{\partial\tilde{b}}{\partial\tilde{x}}^\top\tilde{p}_t
=
\sum_{j=1}^n
[\tilde{v}^{\pi_1}_t]_j
\sum_{i=1}^n
\frac{\partial\tilde{b}_i}{\partial\tilde{x}_j}[\tilde{p}_t]_i
=
\tilde{p}_t{}^\top
\frac{\partial\tilde{b}}{\partial\tilde{x}}\tilde{v}^{\pi_1}_t$  
and  
$
\tilde{v}^{\pi_1}_t{}^\top
\frac{\partial\tilde{\sigma}}{\partial\tilde{x}}^\top\tilde{p}_t
=
\sum_{i=1}^n
[\tilde{v}^{\pi_1}_t]_i
\sum_{k=1}^n
\frac{\partial\tilde{\sigma}_{k\cdot}}{\partial\tilde{x}_i}[\tilde{p}_t]_k
=
\tilde{p}_t^\top
\frac{\partial\tilde{\sigma}}{\partial\tilde{x}}
\tilde{v}^{\pi_1}_t
$  
where $(\frac{\partial\tilde{b}}{\partial\tilde{x}},\frac{\partial\tilde\sigma}{\partial\tilde{x}})
=
(\frac{\partial\tilde{b}}{\partial\tilde{x}}(t,\tilde{x}_t,u_t),\frac{\partial\tilde\sigma}{\partial\tilde{x}}(t,\tilde{x}_t))$ for conciseness. 
Then, by It\^o's lemma (Lemma \ref{lem:rough_path:ito_formula}), almost surely, for any $s,t\in[0,T]$, % 
% 
% 
 \begin{align}\label{eq:pmp:proof:pv=cst}
 \hspace{-2pt}
\tilde{p}_t^\top 
\tilde{v}^{\pi_1}_t
=
\tilde{p}_s^\top
\tilde{v}^{\pi_1}_s
+
\int_s^t
\tilde{v}^{\pi_1}_r{}^\top
\bigg(-
\frac{\partial\tilde{b}}{\partial\tilde{x}}^\top\tilde{p}_r\dd r - \frac{\partial\tilde{\sigma}}{\partial\tilde{x}}^\top\tilde{p}_r\dd\mbB_r
\bigg)+
\int_s^t
\tilde{p}_r^\top
\bigg(
\frac{\partial\tilde{b}}{\partial\tilde{x}}\tilde{v}^{\pi_1}_r\dd r + \frac{\partial\tilde{\sigma}}{\partial\tilde{x}}
\tilde{v}^{\pi_1}_r\dd\mbB_r
\bigg)
=\tilde{p}_s^\top
\tilde{v}^{\pi_1}_s.
\end{align}
Thus, $\E\left[
\tilde{p}_t^\top
\tilde{v}^{\pi_1}_t
\right]
=
\E\left[
\tilde{p}_T^\top
\tilde{v}^{\pi_1}_T
\right]
=
\E\left[
\mathfrak{p}^\top
\frac{\partial\widetilde\Phi}{\partial\tilde{x}}(\tilde{x}_T)
\tilde{v}^{\pi_1}_T
\right]$ for almost every $t\in[0,T]$, with  $\E\left[
\tilde{p}_t^\top
\tilde{v}^{\pi_1}_t
\right]<\infty$ by H\"older's inequality since $\tilde{p}_t,\tilde{v}_t\in L^\ell(\Omega,\R^{n+1})$ with $\ell\geq 2$. We combine this result with \eqref{eq:spmp:proof:mu^TEgradPhiv<=0} and obtain 
\begin{equation}\label{eq:spmp:proof:pv_neq0_for_maximality}
\E\left[
\tilde{p}_t^\top
\tilde{v}^{\pi_1}_t
\right]
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\leq 0
\ \ \text{for a.e. }t\in[0,T],
\   
\text{for any needle-like variations $\pi_1=(t_1,\eta_1,\bar{u}_1)$ of $u$}.
\end{equation}

 
Finally, by contradiction, suppose that \eqref{eq:spmp:maximizality_condition} does not hold. Then, there exists a control $u^1(\cdot)$ and a subset of $[0,T]$ of positive measure on which
$$
\E\left[H(t,x_t,p_t,\mathfrak{p}_0,u_t)\right]
<
\E\left[H(t,x_t,p_t,\mathfrak{p}_0,u^1_t)\right].
$$
Let $t_1$ be a Lebesgue point of this subset of $[0,T]$. Then, 
$$
\E\left[
\tilde{p}_{t_1}^\top \tilde{b}(t_1,x_{t_1},u_{t_1})
\right]
<
\E\left[
\tilde{p}_{t_1}^\top \tilde{b}(t_1,x_{t_1},\bar{u}_1)
\right]
$$
for some $\bar{u}_1\in U$. Then, if we define the needle-like variation $\pi_1=(t_1,1,\bar{u}_1)$ with associated variation vector $\tilde{v}^{\pi_1}$, we obtain
$$
\E\left[
\tilde{p}_{t_1}^\top 
	\left(\tilde{b}(t_1,x_{t_1},\bar{u}_1)-\tilde{b}(t_1,x_{t_1},u_{t_1})\right)
\right]
	=
\E\left[
\tilde{p}_{t_1}^\top \tilde{v}^{\pi_1}_{t_1}
\right]
>0,
$$
which contradicts \eqref{eq:spmp:proof:pv_neq0_for_maximality}. Thus, the maximality condition \eqref{eq:spmp:maximizality_condition} holds, which concludes the proof of \pmp.
 


























% 
\newpage
\section{Numerical example}\label{sec:example}
As a brief application of \pmp, we implement the indirect shooting method presented in Section \ref{sec:introduction} %the introduction (Section \ref{sec:introduction})
 for a % 
regulation task. % 
We consider the open-loop (OL) 
optimal control problem (OCP)
\begin{equation}\label{OLOCP}% 
\tag{\olocp}
\begin{cases}
\min\limits_{u\in L^\infty([0,T],\R^m)} \qquad 
	&\E\left[
\int_0^T \frac{1}{2}(x_t^\top Q x_t +u_t^\top R u_t)\dd t
\right]
\\
\ \ \textrm{such that} \quad\ \  
&
x_t = x_0+\int_0^t (A(x_s)x_s+\bar{B}u_s)\dd s +\int_0^t  \sigma(x_s)\circ\dd B_s,
\quad t\in[0,T],
\end{cases}
\end{equation}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
where $n=m=3$, $A(x)=-J^{-1}S(x)J$ with $ 
S(x)=
\SmallMatrix{
0&-x_3&x_2
\\
x_3&0&-x_1
\\
-x_2&x_1&0
}$ and  
$J=\text{diag}(J_1,J_2,J_3)=\SmallMatrix{
3&0&0
\\
0&2&0
\\
0&0&4
}$, 
$\bar{B}=J^{-1}$, 
% 
$\sigma(x)=0.4\,\textrm{diag}(x)$, 
$R=\text{diag}(R_1,R_2,R_3)=3I_{3\times 3}$,  
$Q=10I_{3\times 3}$,  
% 
$x_0=\frac{\pi}{180}(-1, -4.5, 4.5)$,   
$B$ is a  standard $n$-dimensional Brownian motion, and the SDE is a Stratonovich SDE. 
% 
This problem may represent a stabilization task for the angular velocity of a spacecraft with nonlinear rigid body dynamics. 
By composing all functions in % 
\olocp with a smooth cut-off function, % 
% 
we may assume that Assumption \ref{assum:pmp} holds, so candidate optimal solutions are described by \pmp: % 
% 
\begin{align*}
% 
&\begin{cases}
H(x,u,p,\mathfrak{p}_0) 
=
p^\top(A(x)x+\bar{B}u)
-
\frac{1}{2}(x^\top Q x +u^\top R u),
\\
\frac{\partial H}{\partial u}
=
p^\top B
-
u^\top R
\mathop{\implies}\limits^\eqref{eq:spmp:maximizality_condition} 
u_t
=
R^{-1}
\bar{B}^\top\E\left[
p_t
\right],
% 
\\
p_T
\mathop{=}\limits^\eqref{eq:spmp:transversality_condition:pT} 
0,
\end{cases}
\end{align*}
where $\mathfrak{p}_0=-1$ since there are no final state constraints.  
% 

 
\textbf{Numerical resolution:} 
We consider two algorithms that use $M\in\N$ independent samples $B^i$ of $B$. 
% 
% 
% 
% 
\begin{enumerate}[leftmargin=5mm]
\item[1)] Direct method (\texttt{Direct}): We search for the control $u\in L^\infty([0,T],\R^m)$ and the sample paths $(x^i)_{i=1}^M\in C([0,T],\R^{Mn})$ that solve the sample average approximation 
\begin{equation*}
\min\limits_u \  
\frac{1}{M}\sum_{i=1}^M
\int_0^T \frac{1}{2}(x_t(\omega^i)^\top Q x_t(\omega^i) +u_t^\top R u_t)\dd t 
\ \ \ \textrm{s.t.} \ \ \   
x_t^i = x_0+\int_0^t(A(x_s^i)x_s^i+\bar{B}u_s)\dd s + \int_0^t\sigma(x_s^i)\circ \dd B_s^i.
\end{equation*}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Numerically, we discretize the problem with $(N+1)\in\N$ nodes by optimizing over  $\hat{u}=(\hat{u}_0,\dots,\hat{u}_N)\in\R^{(N+1)m}$ and $(\hat{x}^i)_{i=1}^M=((\hat{x}^i_0,\dots,\hat{x}^i_N))_{i=1}^M\in\R^{M(N+1)n}$ and discretizing the SDE with % 
a Milstein scheme. % 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
We solve the resulting finite-dimensional optimization problem  via sequential quadratic programming (SQP) \cite[Chapter 18]{2006}. We do not enforce trust region constraints nor use a linesearch and thus always take full steps at each SQP iteration. We return a solution once the difference between SQP iterates $\Delta:=(\Delta\hat{u},(\Delta\hat{x}^i)_{i=1}^M)$ satisfies $\|\Delta\|_\infty<\epsilon$. 
This method is  in \cite[Section 6.2]{Lew2024}.
% 
% 
% 
\item[2)] Indirect shooting method (\texttt{Indirect}): % 
We search for  adjoint vector initial  values $(p_0^i)_{i=1}^M\in\R^{Mn}$ 
satisfying
\begin{align}\label{eq:example:shooting_problem}
\begin{bmatrix}
p_T^1
\\
\vdots
\\
p_T^M
\end{bmatrix}
% 
=
0,
% 
% 
\ 
\text{ where }
% 
% 
\begin{cases}
x_T^i = x_0+\int_0^T 
(A(x_t^i)x_t^i+\bar{B}u_t^M)
\dd t +\int_0^T  \sigma(x_t^i)\dd\mbB_t^i,
\\[1mm]
p_T^i
=
p_0^i
-\int_0^T\frac{\partial H}{\partial x}(x_t^i,u_t^M,p_t^i,\mathfrak{p}_0)\dd t
-
\int_0^T
\frac{\partial\sigma}{\partial x}(x_t^i)^\top p_t^i\dd\mbB_t^i,
\\ 
u_t^M=R^{-1}\bar{B}^\top 
\left(\frac{1}{M}\sum\limits_{i=1}^M
p_t^i\right)
\text{ for a.e. }
t\in[0,T],
\end{cases}
\end{align} 
where the $\mbB^i$'s are the Stratonovich  lifts of the $B^i$'s.  
% 
% 
We define the map $$F:\, \R^{Mn}\to\R^{Mn},\  
% 
(p_0^i)_{i=1}^M
% 
\mapsto
% 
% 
% 
% 
% 
% 
% 
% 
(p_T^i)_{i=1}^M$$ that solves the coupled RDE in \eqref{eq:example:shooting_problem} from initial  values $(p_0^i)_{i=1}^M$ and returns $(p_T^i)_{i=1}^M$.  % 
Numerically, we integrate the RDE in \eqref{eq:example:shooting_problem} using the estimate \eqref{eq:rough_int:error_bound} for rough integrals, see the 
\ifarxiv
appendix
\else
supplementary material
\fi 
for details. 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
Then, we solve the equation $F\left( (p_0^i)_{i=1}^M \right)=0$ via Newton's method by iteratively defining 
$$
({}^{(\ell+1)}p_0^i)_{i=1}^M=
({}^{(\ell)}p_0^i)_{i=1}^M
-
\left(
% 
\nabla F\left(({}^{(\ell)}p_0^i)_{i=1}^M\right)
\right)
^{-1}
F\left(({}^{(\ell)}p_0^i)_{i=1}^M\right)
\qquad
\ell=0,1,\dots,
$$ 
starting from an initial guess $({}^{(0)}p_0^i)_{i=1}^M$. 
We return a solution $({}^{(\ell)}p_0^i)_{i=1}^M$ once $\|F(({}^{(\ell)}p_0^i)_{i=1}^M\|_\infty < \epsilon$. 
\end{enumerate}
% 
The two methods are implemented in Python using \texttt{JAX} \cite{jax2018github}. % 
The quadratic programs at each SQP iteration of \texttt{Direct} are solved using \texttt{OSQP} \cite{osqp2020}. 
The tolerance threshold is set to $\epsilon=10^{-6}$. 
We use zero initial guesses for both methods. 
% 
We checked that solutions returned by the \texttt{Direct}  and \texttt{Indirect} methods are close to each other. 
Computation times are measured on a laptop with
an 1.10GHz Intel Core i7-10710U CPU.  
Our implementation is available at \blue{\url{https://github.com/ToyotaResearchInstitute/rspmp}}.


\textbf{Results}: A solution to \olocp for $(T,M,N)=(2,10,40)$ is reported in Figure \ref{fig:openloop_feedback}. The  state and control trajectories converge to zero over time (in average for the state trajectories) to minimize the cost. The adjoint vector trajectories $p^i$ start from different initial conditions $p_0^i$ and are all zero at the final time ($p_T^i=0$) to satisfy  the transversality condition  of \PMP. 


We report median computation times and costs over $20$ runs of each method in Figure \ref{fig:comparison}. 
The proposed \texttt{Indirect} method is about $10\times$ faster than the \texttt{Direct} method. % 
% 
Also, the costs associated to the solutions to the sampled problems decrease % 
as the sample size $M$ increases. % 
Solutions are sensitive to the sample size, and computing low-cost solutions with high certainty over the sampling procedure is achievable with a reasonable sample size ($M=10$) for this problem.

 \textbf{Discussion}: % 
First, results in Figure \ref{fig:comparison} (right) suggest that the proposed method may be asymptotically optimal, since the cost and its variance decrease as the sample size $M$ increases. Proving such asymptotic optimality properties of the method for certain classes of problems  is of interest for future work.  
Second, the \texttt{Indirect} method is significantly faster than the \texttt{Direct} method, thanks to leveraging the structure of the problem encoded in \pmp % 
to optimize over only the $Mn$ variables $p_0^i$ for the \texttt{Indirect} method versus optimizing over the $M(N+1)n+(N+1)m$ variables $(\hat{x}^i,\hat{u}^i)$ for the \texttt{Direct} method.  
However, indirect methods  typically have higher numerical sensitivity to the choice of initial guess.  % 
This tradeoff is well-known in the deterministic optimal control literature, motivating the future development of multiple shooting and homotopy methods \cite{Trelat2012,Bonalli2018} for stochastic optimal control. 



\begin{figure}[t]
%\centering
%\rotatebox{90}{\quad\quad\hspace{0pt}
%\fbocp
%\quad\hspace{-7pt}
%\olocp}
%\hspace{1mm}
%\includegraphics[width=0.95\textwidth,trim={5mm 6mm 5mm 5mm},clip]{figs/openloop_feedback.png}
%\caption{Solutions to the open-loop (\olocp, Top) and feedback (\fbocp, Bottom) optimal control problems computed using the \texttt{Indirect} method. For \fbocp, we plot the closed-loop control trajectories $u_t^i=K_tx_t^i$.}
%\label{fig:openloop_feedback}
% 
%\vspace{3mm}
% 
\centering
\includegraphics[width=0.59\textwidth,trim={4mm 5mm 15mm 5mm},clip]{figs/comparison.png}
\includegraphics[width=0.4\textwidth,trim={5mm 5mm 5mm 5mm},clip]{figs/sample_sizes_sweep.png}
\caption{
\textbf{Left}: Median computation time for the \texttt{Direct} and \texttt{Indirect} methods for $T=3$ and varying sample sizes $M$ and horizons $N$. 
\textbf{Right}: Median cost with $\pm$ one median absolute deviation intervals of the solution returned by the \texttt{Indirect} method for different samples sizes for $N=40$, evaluated using $10^4$ Monte Carlo samples.}
\label{fig:comparison}
\end{figure}

 
\textbf{Feedback optimization:} 
Next, we consider the feedback (FB) optimal control problem (OCP)
\begin{equation}
\label{FBOCP}% 
\tag{\fbocp}
\begin{cases}
\min\limits_{k\in L^\infty([0,T],\R^m)} \qquad 
	&\E\left[
\int_0^T \frac{1}{2}(x_t^\top Q x_t +x_t^\top K_t^\top R K_t x_t)\dd t
\right]
\\
\ \ \textrm{such that} \quad\ \  
&
x_t = x_0+\int_0^t (A(x_s)+\bar{B}K_s)x_s\dd s +\int_0^t  \sigma(x_s)\circ\dd B_s,
\quad t\in[0,T],
\end{cases}
\end{equation}
where we optimize  over the diagonal feedback gain $K_t=\text{diag}(k_t)\in\R^{m\times m}$. 
The problem \fbocp derives from \olocp by considering the feedback control $u=Kx$ and optimizing over the gains $K$. Since the gains $k$ are deterministic, the resulting feedback control law $u=Kx$ is causal and this formulation fits within our framework. 
Candidate optimal solutions are described by \pmp: 
\begin{align*} 
\fbocp:
&\begin{cases}
H(x,k,p,\mathfrak{p}_0)
=
p^\top(A(x)+\bar{B}K)x
-
\frac{1}{2}(x^\top Q x +x^\top K^\top RK x),
\\
\frac{\partial H}{\partial k}
=
(1/J_j)p_jx_j
-
k_jR_jx_j^2
\mathop{\implies}\limits^\eqref{eq:spmp:maximizality_condition} 
k_{j,t}
=
(J_jR_j)^{-1}\E\left[
p_{j,t}x_{j,t}
\right]
/
\E\left[(x_{j,t})^2\right], \  j=1,2,3,
% 
\\
p_T
\mathop{=}\limits^\eqref{eq:spmp:transversality_condition:pT} 
0.
\end{cases}
\end{align*}
Using these necessary conditions, we implement the % 
\texttt{Indirect} shooting method % 
presented previously  % 
and solve  \fbocp for $(T,M,N)=(2,10,40)$ from a zero initial guess $({}^{(0)}p_0^i)_{i=1}^M$. 
We find that solving \fbocp is numerically sensitive to the choice of initial guess. % 
Thus, using a homotopy method, we solve \fbocp for $R_j\in\{100, 99.9,\dots,3\}$, using the solution $({}^{(0)}p_0^i)_{i=1}^M$ computed for the previous value of $R$ as an initial guess for each solve via Newton's method. 

Results in Figure \ref{fig:openloop_feedback} show that  state trajectories solving \fbocp  have slightly lower variance than those solving \olocp, which is the result of optimizing over a state feedback control trajectory. % 








\section{Conclusion and outlook}\label{sec:conclusion} 
The optimality conditions in \pmp provide new insights onto the structure of solutions to stochastic optimal control problems when optimizing over deterministic open-loop controls or  parameterized feedback controls. % 
% 
% 
% 
% 
By using rough path theory, the results and analysis rely on a pathwise analysis instead of FBSDEs, % 
and can handle Gaussian processes $B$ that are not semimartingales  that cannot be tackled via It\^o calculus, % 
at the expense of stronger regularity assumptions on the diffusion  $\sigma$. 
The main motivation for deriving \pmp is the development of new algorithms for stochastic optimal control that 
% 
can more easily borrow ideas from the deterministic optimal control literature, % 
% 
such as indirect shooting methods.

The following directions of future research are interesting.  
% 
% 
First, extending our results to the case where the diffusion $\sigma$ depends on the control is non-trivial, as  it may lead to a degenerate formulation  with irregular controls as described in \cite{Diehl2016,Allan2020}, and % 
rough path theory relies on coefficients that are smooth-enough in time. 
% 
% 
% 
% 
Second, extending \pmp to tackle more general settings such as risk-averse optimal control problems \cite{LewMPC2024,Bonalli2023} would  provide valuable insights and be useful in applications. 
% 
Finally, while the proposed indirect shooting method % 
% 
works well on the example in Section \ref{sec:example}, proving theoretical properties for the method such as asymptotic optimality \cite{Phelps2016,Shapiro2021,Lew2024,Melnikov2024} or robustness to discretization \cite{Allan2023} remains an open problem. % 
As % 
the unknown initial value of the adjoint vector $p_0$ is a random variable (i.e., the search space is  infinite-dimensional, as opposed to the deterministic setting where $p_0\in\R^n$), future analysis of the proposed indirect method may require innovative proof techniques and inspire  faster and more robust algorithms. 





\subsection*{Acknowledgements}
% 
T.L. would like to thank Riccardo Bonalli for many stimulating discussions on the  deterministic and stochastic PMPs  
and his helpful feedback. 


























 


\ifarxiv
% only include appendix in main document if on Arxiv.
% only include appendix in main document if on Arxiv.
% only include appendix in main document if on Arxiv.

\newpage
\appendix

\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}
\input{appendix}

\newpage
\renewcommand{\baselinestretch}{0.95}
\bibliographystyle{IEEEtran}
\bibliography{main}

\else


\bibliographystyle{siamplain}
\bibliography{main}

\fi
\end{document}
