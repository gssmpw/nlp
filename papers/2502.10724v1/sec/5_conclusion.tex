\section{Conclusion and Limitations}
\label{sec:conclusion}
We propose a novel text-guided test-time adaptation framework for solving 3D human pose estimation on unseen videos. 
Previous methods employ temporal smoothing to
mitigate the impact of noisy 2D labels and depth ambiguity,
but this often leads to average results and even stationary poses
when 2D evidence is lacking. 
We address them by incorporating motion semantics from a well-trained motion-text space, refining 3D pose predictions in a correct semantic solution space.  
Moreover, the text-aligned motion predictions will be used to update 2D labels, enhancing the model understanding of the true motion.
Our method ensures semantically consistent pose predictions across video sequences, outperforming state-of-the-art methods in both quantitative and qualitative evaluations. 

However, our work has certain limitations: the refined motion under occlusion may not fully capture the actual pattern of the subject, with discrepancies in step frequency or duration.
In addition, the reliance on MotionCLIP limits adaptability to new motion descriptions. These challenges highlight the need for better adaptation strategies and advanced motion-language models. 