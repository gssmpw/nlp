\section{Introduction}
\label{sec:intro}

3D human pose estimation from images and videos is applicable for many scenarios, including human-computer interactions~\cite{zheng2023realistic}, robots~\cite{gong2022posetriplet}, and digital human assets~\cite{moon2024expressive}. 
It is a challenging task because 3D ground truth labels are hard to acquire for arbitrary visual data. Common methods are trained on MoCap datasets~{\cite{mahmood2019amass}}, which provide accurate 3D labels but are limited in pose and appearance.  As such, these methods may easily fail on in-the-wild images during inference~{\cite{boa,iso,DAPA,cycleadapt}. 

This paper tackles the adaptation of 3D human pose estimation models to in-the-wild videos. 
A practical alternative to improve predictions is Test-Time Adaptation (TTA).  TTA directly uses the (unlabeled) target sequences
to fine-tune the pre-trained model during inference.
{Often, pre-trained models exhibit a misalignment between their projected keypoints and 2D image evidence.}
Based on this result, previous TTA methods~\cite{dynaboa, cycleadapt} usually penalize the distance between the 2D-projections and 2D evidence provided by either ground truth or estimated 2D poses. 
However,
such a scheme has two main challenges: 1) Depth ambiguity, which arises because 
{numerous 3D pose solutions correspond to the same 2D pose.} This ambiguity may improve 2D alignment but worsen 3D accuracy and plausibility. (2) Missing 2D keypoints, 
\eg under occlusions and truncations.  These keypoints have no guidance for improvement.


\begin{figure}[!t]
    \centering
        \includegraphics[width=0.95\linewidth]{Figs/teaser1.pdf}
    \caption{We provide two examples to illustrate the issues in TTA methods. Compared to CycleAdapt~\cite{cycleadapt}, our method enables accurate bending of the legs in the ``climbing-the-stairs" scenario and ``walking'' in the occluded scenario, demonstrating the effectiveness of incorporating semantics-aware motion information for both visible and occluded keypoints.
    }
    \label{fig:teaser}
    \vspace{-0.2cm}
\end{figure}

To alleviate the above issues, several works~\cite{dynaboa,cycleadapt} leverage temporal information from the target videos.
One strategy is to limit the 
prediction velocity, 
as a weak regularizer to narrow the feasible solution space~\cite{dynaboa}.
Another is motion denoising, which enforces a prior that predictions should remain close to the original or neighboring predictions~\cite{cycleadapt}.
These improvements are rooted in the fact that denoising and smoothing the sequential predictions can filter out poor results. 
However, temporal smoothing may settle the sequence towards an average pose. 
Consider the upper panel of Fig.~\ref{fig:teaser}. 
The state-of-the-art CycleAdapt~\cite{cycleadapt} aligns the 3D mesh 
to the visual 2D evidence, but results in the wrong pose where the legs are straight. 
With some semantic knowledge of the man's activity (climbing stairs), it is clear that his knees should be bent.  

With this motivation in mind, we develop a semantics-aware motion prior to guide 3D predictions. 
We leverage vision-language models to describe the action of a given segment.  This action text is projected with the predicted motion into a motion and text aligned representation space.  Specifically, we use MotionCLIP~\cite{motionclip}, with motion auto-encoder that aligns a motion manifold with the semantically-structured CLIP space~\cite{clip}.  In our TTA, we align the estimated 3D pose sequence with the semantically identified action through a dedicated regularizer. 
In the ``climbing-the-stairs'' example, the predicted motion originally resembles ``sliding", but after introducing our motion-text alignment, the resulting poses are adapted to have bent knees and match the true motion of stair climbing. 

{TTA can easily be influenced by challenging samples. For example, when there are occlusions, or truncation, there is no 2D evidence available for adaptation. Under such circumstances, the model lacks guidance on what to predict.
}
The lower panel of Fig.~\ref{fig:teaser} shows an example of a person walking, with the lower body occluded for the entire segment. CycleAdapt predicts a motion with a static lower body.
In such cases, where 2D evidence is fully lacking, we observe that previous alignment in the motion-text space alone is insufficient for adaptation.  This motivates us to strengthen the supervision by storing 2D predictions with high quality as exemplars and regard them as 2D pseudo labels in the subsequent optimization. 
Specifically, for the keypoints not provided with 2D evidence, we
examine the similarity between the predicted motion and its text label in the feature space; if it exceeds a certain threshold, these keypoints will be completed by the 2D projection of model predictions.
With 2D missing keypoints filled by text-aligned motion, we can offer stronger supervision on occluded or truncated body parts.



At the heart of our method is a 
semantics-aware motion prior 
that supports test-time adaptation for 3D human pose estimation. The prior 
effectively complements 2D projected supervision and remedies over-smoothing. 
When 2D keypoints are available, 
motion-text alignment
greatly reduces the ambiguous 3D solution space; when they are unavailable, 
text-aligned motion prediction
provides useful 2D projected poses to complete the missing information. In summary, we 

\begin{itemize}
    \item Highlight the interesting and significant problem of motion semantics,
    which existing TTA literature ignores or exacerbates;
    \item 
    Propose a novel high-level motion semantics prior for TTA, by leveraging a motion-language model; 
    \item {Propose a text-aligned motion predictions to complete 2D poses in occlusion or truncation cases, significantly improving performance up to  \textbf{12.5\%} PA-MPJPE improvement on these challenging cases.
    }
\end{itemize}

