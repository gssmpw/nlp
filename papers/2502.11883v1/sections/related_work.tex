\section{Related Work}\label{sec:related_work}

\textbf{Beyond-Accuracy in IR.} In modern IR systems, beyond-accuracy objectives play a crucial role in building a more effective and responsible ecosystem~\cite{kaminskas2016diversity, de2023beyond}. Beyond-accuracy objectives primarily include diversity~\cite{PM2_12_sigir}, fairness~\cite{xu2023p, fairrec}, novelty~\cite{hurley2011novelty}, and serendipity~\cite{zhang2012auralist}. Among these factors, this toolkit primarily focuses on fairness and diversity.

%, while they both aim to support underrepresented user and items, have gained increasing attention in recent years~\cite{li2022fairness, santos2010exploiting, PM2_12_sigir}.

\noindent\textbf{Fairness and diversity in IR.} Fairness and diversity are gaining increasing attention in the IR field, as both seek to support underrepresented user and item groups~\cite{li2022fairness, LLM4FairSurvey, wang2021user, PM2_12_sigir}. Previous studies have often explored fairness and diversity from the perspectives of different stakeholders, such as users and items~\cite{abdollahpouri2020multistakeholder}, as well as at varying granularities, including both group-level and individual-level fairness~\cite{biega2018equity, xu2023p}. Based on different stages in the IR pipeline, previous methods are often categorized into three types: pre-processing~\citep{rus2024study}, in-processing~\citep{APR, FairNeg, Reg}, and post-processing approaches~\cite{xu2023p, TaxRank, PM2_12_sigir, dang2012diversity}. As for the evaluation, they are also based on different metrics, including the Gini index~\cite{nips21welf}, MMF~\cite{xu2023p} in recommendation, and $\alpha$-nDCG~\cite{andcg_08_sigir}, NRBP~\cite{nrbp_09_ictir} in search. However, fairness and diversity often lack unified evaluation settings. This paper introduces FairDiverse, a benchmarking toolkit designed to comprehensively assess different models under different IR tasks.

\noindent\textbf{Fairness and diversity toolkits.} Most fairness and diversity toolkits are implemented under classification tasks. For example, FFB~\cite{han2023ffb} implements diverse in-processing models for addressing group fairness problems. Fairlearn\cite{bird2020fairlearn},  AIF360\cite{aif360-oct-2018} and Aequitas\cite{jesus2024aequitas} implement the unfairness mitigation algorithms using Scikit-learn~\cite{kramer2016scikit} API design. However, these methods cannot be directly applied to ranking tasks. Although some toolkits~\cite{recbole2.0} have been proposed to incorporate fairness and diversityd in IR, they primarily focus on recommendation tasks and implement only a limited number of in-processing models. Our toolkit, FairDiverse, offers the most extensive collection of models, covering a wide range of fairness- and diversity-aware algorithms across both search and recommendation tasks. Moreover, FairDiverse is highly extensible, offering flexible APIs for easy integration of new fairness- and diversity-aware IR models, unlike other toolkits with complex class inheritance.