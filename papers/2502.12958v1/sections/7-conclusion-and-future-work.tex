\section{Conclusion and Future Work}

This study introduces \model{}, a model-agnostic and prior-knowledge-free targeted poisoning attack for practical federated recommender systems (FRS). 
We propose \modelI{} and \modelII{} as two diverse solutions to increase the exposure of target items based on effectively mining popular items during FRS training. Existing federated defenses have been found ineffective against \model{}, leading us to propose a new defense method with two well-designed regularization terms. Extensive experiments across model types, datasets, attacks, and defenses have validated the efficacy of our proposals.

For future work, it is interesting to explore collaborative defense methods that combine both server-side and client-side strategies. 
% \changeone{Moreover, our defense is effective against existing targeted\rone{R1.O2} model poisoning attacks, but the future exploration of more general defenses that adapt to untargeted model poisoning attacks is warranted.} 
It is also interesting to extend our attack and defense methods to content-based federated recommendations.

% \vfill
\section*{Acknowledgment}
This work is supported by the National Key R\&D Program of China (No.~2022YFB3304100), the Pioneer R\&D Program of Zhejiang (No.~2024C01021), and the Major Research Program of Zhejiang Provincial Natural Science Foundation (No.~LD24F020015).
% This work is supported by the National Key R\&D Program of China (No.2022YFB3304100) and Fundamental Research Funds for the Central Universities.