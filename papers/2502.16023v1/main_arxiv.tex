\documentclass{article} % For LaTeX2e
\usepackage{geometry}
 \geometry{
      a4paper,
      left=20mm,         
      right=20mm,        
      top=20mm,
      bottom=25mm
}

\usepackage[numbers, compress]{natbib}
\usepackage{url}
\usepackage{float}

\usepackage{algpseudocode}
\usepackage[linesnumbered,lined,boxed,commentsnumbered,ruled,longend]{algorithm2e}
% \usepackage{algorithm}
% \usepackage{algorithmic}

%----------------------------------------%
% CUSTOM PACKAGES 
%----------------------------------------%
\usepackage{adjustbox}
 \usepackage[table,xcdraw]{xcolor}         % colors
	\definecolor{darkcerulean}{rgb}{0.03, 0.27, 0.49}
	\definecolor{smokyblack}{rgb}{0.06, 0.05, 0.03}
	\definecolor{warmblack}{rgb}{0.0, 0.26, 0.26}
	\definecolor{cobalt}{rgb}{0.0, 0.28, 0.67}
	\definecolor{darkerred}{RGB}{139, 0, 0}
	\definecolor{darkergreen}{RGB}{0, 100, 0}
	\definecolor{warmred}{RGB}{205, 92, 92} 
	\definecolor{warmgreen}{RGB}{34, 139, 34} 
	\definecolor{warmblue}{RGB}{70, 130, 180} 
	\definecolor{arrowredfig1}{HTML}{B85450} 
	\definecolor{expertfig1}{HTML}{6A9153}  % Use boarder colour for legibility
	\definecolor{mixturefig1}{HTML}{6C8EBF} % Use boarder colour for legibility
	\definecolor{ForestGreen}{RGB}{34,139,34}
	\definecolor{Goldenrod}{RGB}{218,165,32}
	\definecolor{Crimson}{RGB}{220,20,60}
    
\usepackage[colorlinks=true,
            linkcolor=cobalt,
            urlcolor=darkcerulean,
            citecolor=warmblack]{hyperref}
\newcommand{\colorwblk}[1]{\textcolor{warmblack}{\textbf{#1}}}
\newcommand{\colorwr}[1]{\textcolor{warmred}{#1}}
\newcommand{\colorwg}[1]{\textcolor{warmgreen}{#1}}
\newcommand{\colorwb}[1]{\textcolor{warmblue}{#1}}
\newcommand{\colordr}[1]{\textcolor{darkerred}{#1}}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{epigraph}
\usepackage{array}

\usepackage{graphicx}
%\graphicspath{{figs/}}
\usepackage{caption}        % captioning in subfigures
\usepackage{sidecap}        % SCfigure
\usepackage{subcaption}

\usepackage[normalem]{ulem}	% for strike-out text use \sout{text}
\usepackage[toc,page]{appendix}	%for appendices
\usepackage{blindtext}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\newcommand\ci{\perp\!\!\!\perp} %conditional indepencde command

% Commands for the table------------------------------------
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\def\eg{e.g\onedot}
\def\Eg{E.g\onedot}
% ----------------------------------------------------------

\usepackage{wrapfig}
\usepackage[bottom]{footmisc}
\usepackage{color,soul}
\usepackage{nicematrix,tikz} % for wall tables
\usepackage{ulem}  % better underlines
\setcitestyle{square}
\setcitestyle{citesep={,}}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{authblk}
\renewcommand\Affilfont{\itshape\small}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage{float}
\usepackage{multirow}
\usepackage{pifont}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{geometry}
\usepackage{tabularx}
\usepackage{array}
\usepackage{ragged2e} % For text alignment


%%% Editing + Comments %%% 
\usepackage{soul}
\newcommand{\algoacronym}[1][\colorwblk{ContraSim}]{#1}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\setlength{\textfloatsep}{10pt} % Adjust the value as needed

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
\input{custom_packages}

%%% PREAMBLE START %%%%% 
\title{ContraSim: Contrastive Similarity Space Learning for Financial Market Predictions}

\newcommand{\emailsuffix}[2]{\thanks{Emails: \texttt{\{#1\}@#2}}}

\author[2]{Nicholas Vinden\thanks{Email: \texttt{nvinden@uguelph.ca}}}
\author[1,4]{Raeid Saqur\thanks{Email: \texttt{raeidsaqur@cs.toronto.edu}}}
\author[1]{Zining Zhu\thanks{Email: \texttt{zining@cs.toronto.edu}}}
\author[3,4]{Frank Rudzicz\thanks{Email: \texttt{frank@dal.ca}}}

\affil[1]{Department of Computer Science, University of Toronto}
\affil[2]{Department of Computer Science, University of Guelph}
\affil[3]{Faculty of Computer Science, Dalhousie University}
\affil[4]{Vector Institute for Artificial Intelligence}

\date{}
%%% PREAMBLE END %%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% DOCUMENT START %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle

\begin{abstract}
We introduce the \textbf{Contrastive Similarity Space Embedding Algorithm} (\colorwblk{\algoacronym}), a novel framework for uncovering the global semantic relationships between daily financial headlines and market movements. ContraSim operates in two key stages: 
\textbf{(I)} Weighted Headline Augmentation, which generates augmented financial headlines along with a semantic fine-grained similarity score, and \textbf{(II)} Weighted Self-Supervised Contrastive Learning (WSSCL), an extended version of classical self-supervised contrastive learning that uses the similarity metric to create a refined weighted embedding space. This embedding space clusters semantically similar headlines together, facilitating deeper market insights. Empirical results demonstrate that integrating ContraSim features into financial forecasting tasks improves classification accuracy from WSJ headlines by 7\%. Moreover, leveraging an information density analysis, we find that the similarity spaces constructed by ContraSim intrinsically cluster days with homogeneous market movement directions, indicating that ContraSim captures market dynamics independent of ground truth labels. Additionally, ContraSim enables the identification of historical news days that closely resemble the headlines of the current day, providing analysts with actionable insights to predict market trends by referencing analogous past events.
\end{abstract}

%----------------------------------------%
% FLATTENED CONTENT FROM: {ICLR-25/sections/01_intro.tex}
%----------------------------------------%

\section{Introduction}\label{sec:intro}

\begin{figure}[ht] 
    \centering 
    \includegraphics[width=0.8\textwidth]{figs/nvinden_main/Intro_New.drawio.png} % Adjust the width as needed
    \vspace{1pt}
    \caption{Overview of our proposed Contrastive Similarity (ContraSim) embedding approach. \textbf{In training}, we use a LLaMA chat model to generate augmented financial news headlines with varying degrees of semantic similarity to the original. We then use a Weighted Self-Supervised Contrastive Learning (WSSCL) approach to create an embedding space that clusters semantically similar prompts closer together. \textbf{In deployment}, the embeddings from the similarity space, can be used to i) Make better predictions on the direction of today's stock movement, ii) Find the most similar financial news to today's.} % The caption goes here
    \label{fig:Intro} 
\end{figure}
%\vspace{-10pt} % Adjust this value as needed (e.g., -10pt to reduce space)

With the rapid advancements in the capabilities of Large Language Models (LLMs), researchers have significantly enhanced their ability to analyze and leverage the semantic richness of textual data for various downstream tasks. Mature fields such as Sentiment Analysis \cite{devlin2019bert}, Spam Detection \cite{aggarwal2022spam}, Machine Translation \cite{vaswani2017attention}, and many more \cite{liu2019roberta, brown2020gpt3, radford2019gpt2} have been completely revolutionized by the advent of deep LLMs. Likewise, because a key source of information in the domain of financial market movement prediction is encoded in textual representations (news, reports, social media, etc.), a predictable field of study has been how LLMs can be used to better predict market movement. %Predictably, with increased knowledge representation algorithms, researchers have tried to use these algorithms as a way to build better financial forecasting models to see if it is possible to  ``beat the market''. 

It is known that the direction of a stock's price is impacted by a plethora of temporally linked features, like overall market movement, industry trends and company-specific news. It has been a daunting task for researchers to build machine learning algorithms that are able to interpret the complex and noisy feature space of textual financial news, to repeatedly perform well in market movement prediction. Previous models created the majority of their predictive powers by solely looking at historic financial indicators \cite{fischer2018deep, sezer2018tensor}. However, with LLM's ability to create dense feature representations from human text, composite models that utilize financial indicators in conjunction with news and social-media posts were able to improve predictive performance \cite{saqur2024teachesrobotswalkteaches, liu2021financial}. Multiple projects have found success doing this by using a mixture of classical and deep learning approaches \cite{ding2015deep, fischer2018deep, hu2018deep, sezer2018tensor, xu2018sentiment, liu2021financial}. State of the art approaches to stock market prediction is outlined in section \ref{sec:preliminaries}.

While composite models that blend financial indicators with language features have improved market movement predictions, they often function as “black boxes.” They predict market changes without offering any insight into why a particular prediction was made, making them less useful for financial analysts seeking interpretability. To address this, we propose a Contrastive Self-Supervised Learning approach that not only enhances market movement predictions using financial text data but also preserves interpretability. Our method aims to: a) predict the current day's market direction using Wall Street Journal (WSJ) headlines \cite{wsj}, and b) provide a ranked list of similar past financial news events.

The idea behind our approach is straightforward. We treat a day's news as a combined list of all WSJ (and other relevant, reputable sources) headlines for that day. For example, a headline like ``\textit{Canadian Crude Prices Hit by Keystone Pipeline Shutdown}'' (2019-11-05) serves as input, much like other models. However, in addition to predicting market changes, our approach also identifies other days when similar events occurred. For instance, the most similar past headline might be ``\textit{Russian Pipeline Shutdown Shifts Balance in Oil Market}'' (2019-05-22). This method offers a balance of interpretability and simplicity, allowing analysts to identify patterns in current news and historical contexts without relying on a complex “Explainable AI” (XAI) component.

We propose ContraSim, a method that leverages a novel textual augmentation algorithm powered by LLMs to generate diverse news headlines with varying degrees of semantic similarity to the original. Augmented headlines are assigned similarity scores ranging from 1.0 (high semantic alignment) to 0.0 (completely disjoint meaning). Using these augmented pairs, we introduce Weighted Self-Supervised Contrastive Learning (WSSCL) to build an embedding space where semantically similar headlines are naturally clustered. This embedding algorithm enables the calculation of similarity scores between any two real-world headlines based on their semantic proximity.

This approach is validated through two key findings: a) WSSCL inherently groups headlines associated with similar market directions closer in the embedding space. Even without explicit market movement labels, the model intuitively captures the relationship between headlines and market behavior using an information-gain framework, and b) a large language model (LLM) trained with WSSCL-enhanced embeddings outperforms an LLM relying solely on raw financial headlines for market movement prediction, demonstrating the added value of this semantic embedding strategy.


\paragraph{Contributions}: We introduce the \textit{Contrastive Similarity Space Embedding Algorithm} (\colorwblk{ContraSim}), a method that generates headline augmentations with meaningful and nuanced similarity coefficients. We demonstrate that:

\begin{enumerate}[label=\roman*), left=0pt] 
    \item ContraSim enables inter-day financial comparisons, allowing forecasters to identify historic market days similar to the current day.
    \item ContraSim learns a mapping between news headlines and market direction in an unsupervised manner. This is evidenced by emergent structures in the embedding space that increase global insight into stock movement -- i.e., by identifying similar prompts, we gain insight into why stocks move.
    \item The similarity embedding spaces created by ContraSim enhance the performance of financial forecasting classification algorithms when used together.
\end{enumerate}

\paragraph{Organization:} Section \S\ref{sec:preliminaries} reviews the foundational concepts and situates our work within the existing literature. Section \S\ref{sec:methods} describes the proposed methodologies in detail. Section \S\ref{sec:results} presents our experimental setup, empirical findings, and a discussion of training details, along with directions for future research. Additional details, including a comprehensive explanation of headline transformations (\S\ref{app:headline_transformations}), an analysis of how augmentation actions influence similarity (\S\ref{app:augmentation_actions}), and dataset descriptions (\S\ref{app:sec:datasets}), are provided in the appendix.

%----------------------------------------%
% FLATTENED CONTENT FROM: {ICLR-25/sections/02_preliminaries.tex}
%----------------------------------------%

\section{Related Works}\label{sec:preliminaries}

\paragraph{Machine Learning in Financial Forecasting}
Early approaches to predicting stock market movements relied heavily on classical statistical models. One foundational method, the Autoregressive Integrated Moving Average (ARIMA) \cite{box1970time}, utilized time series data to forecast trends. Subsequent models, such as \textit{Generalized Autoregressive Conditional Heteroskedasticity} (GARCH)~\cite{bollerslev1986generalized}, \textit{Vector Autoregression} (VAR)~\cite{sims1980macroeconomics}, and \textit{Holt-Winters exponential smoothing}~\cite{holt1957forecasting}, extended these capabilities by capturing more intricate patterns in financial time series. Other notable contributions include techniques for cointegration analysis \cite{engle1987cointegration}, Kalman filtering \cite{kalman1960new}, and Hamilton’s regime-switching models \cite{hamilton1989new}.

While effective, these classical models were primarily limited to tabular datasets and struggled with nonlinear relationships and multimodal inputs. The rise of Large Language Models (LLMs) transformed financial forecasting by enabling the incorporation of richer, more complex data sources. For example, integrating financial news articles \cite{yang2020finbert}, sentiment analysis \cite{yang2020finbert}, social media activity \cite{bollen2011twitter}, and earnings call transcripts \cite{tsai2016forecasting} significantly enhanced market movement predictions, demonstrating the versatility and power of LLMs in handling diverse financial modalities.

\paragraph{Contrastive Learning} 
Contrastive learning has emerged as a powerful paradigm in unsupervised and self-supervised learning, focusing on representation learning through comparisons. The core idea is to bring similar data points closer in the representation space while distancing dissimilar ones. A key milestone in this field was SimCLR \cite{chen2020simple}, which used data augmentations and contrastive loss to learn high-quality representations without requiring labels. MoCo~\cite{he2020momentum} further advanced this approach by introducing a memory bank to efficiently manage negative examples, making it more scalable for larger datasets.

Recent innovations like SimSiam \cite{chen2021exploring} have shown that competitive representations can be learned without relying on negative pairs, streamlining computation and improving accessibility. These advancements are particularly relevant for financial applications, where large-scale and heterogeneous datasets are common, enabling contrastive learning to uncover nuanced relationships in financial data.
% More recent advancements such as SimSiam \cite{chen2021exploring} have shown that competitive representations can be learned without negative pairs, further improving efficiency and reducing computational requirements, making it more accessible for large-scale datasets commonly found in financial applications.


%----------------------------------------%
% FLATTENED CONTENT FROM: {ICLR-25/sections/03_IG-CluPE.tex}
%----------------------------------------%

\section{Methods} \label{sec:methods}

In this section, we introduce ContraSim, a self-supervised contrastive learning algorithm that creates augmented news headlines with fine-grained degrees of similarity to the base. Then using a weighted self-supervised learning paradigm, we create an embedding space, where semantically similar news headlines are clustered together. Additionally, we outline how we can measure the efficacy of ContraSim by using an information density approach in our similarity space to see if there is inherent market-movement knowledge being learned by optimizing for news headline similarity.

\subsection{ContraSim: Contrastive Similarity Space Embedding Algorithm}

Here, we formulate the news headline augmentation pipeline and the Weighted Self-Supervised Contrastive Learning (WSSCL) approach that in tandem generate the ContraSim. The contrastive similarity space, generated from ContraSim, is optimized to put the headlines with semantically similar news into local proximity. 

We define the Daily-News Set (DNS) dataset as:

\begin{equation}
\mathcal{D}_{\text{DNS}} = \{(d_i, \mathcal{N}_i) \mid i = 1, 2, \dots, n\}, \quad \text{where } \mathcal{N}_i = (h_{i1}, h_{i2}, \dots, h_{im})
\label{eq:training_set}
\end{equation}

Where, $n$ is the total number of news headlines within the news headline dataset, $\mathcal{N}_i$ is news headline object containing a tuple of headlines strings $h$, and $d_i$ is the corresponding date identifier string for a day $i$. 

In this context, a \textbf{Daily News-Set (DNS)} is a collection of WSJ~\cite{wsj} headlines from a specific day. Later in this paper we explore using Social Media posts to form a DNS, and also explore how well ContraSim performs on other non-financial textual domains (e.g. list of movie reviews).

\paragraph{1. Defining the Augmentation Objective} 
Below, we propose a stochastic transformation $T: \mathcal{N} \to (s, \hat{\mathcal{N}})$, where $\mathcal{N}$ is an input DNS, $\hat{\mathcal{N}}$ is the augmented DNS, and $s \in [0.0, 1.0]$ represents the similarity score between $\mathcal{N}$ and $\hat{\mathcal{N}}$. In subsection 3. we further discuss our implementation details and our process of measuring inter-DNS semantic similarity. 

The dominant strategy for creating contrastive embedding spaces defines inter-object relationships in binary terms: two objects are either within the same class or outside the same class. However, for this objective, we do not have access to binary class labels between daily news sets, as the similarity between daily news sets is inherently continuous and varies along a continuous spectrum. Weighted contrastive approaches, such as \cite{weightedContrastive}, better align with this setting by leveraging nuanced similarity scores to guide the embedding space construction, enabling more accurate representation of the semantic relationships between augmented DNS. 

\paragraph{2. Generating Augmented Daily News Sets} 
Augmented DNS are generated through the following discrete actions: i) Rewording an original headline (\textbf{Re}), ii) Generating a semantically shifted version (\textbf{S}), iii) Negating an original headline (\textbf{N}), and iv) Selecting a random headline from a different day (\textbf{Ra}).

To achieve these transformations, we leveraged the LLaMA-3-7b-chat model \cite{llama2-touvron2023llama}, prompting it with carefully crafted instructions tailored to each specific action. For rewording (\textbf{Re}), the model was prompted to retain the original meaning of the headline while rephrasing it with alternative wording and sentence structure. For semantic-shifting (\textbf{S}), the prompt instructed the model to subtly alter the meaning of the headline, introducing slight semantic deviations while maintaining topical relevance. For negation (\textbf{N}), the model was guided to generate a headline that conveyed the direct opposite meaning of the original. By using these tailored prompts, the LLaMA model provided high-quality augmented news headlines that covered a broad spectrum of semantic variations. 

To ensure the quality of LLM-generated headline augmentations, we employ an off-the-shelf fine-tuned BERT model as a discriminator to verify semantic consistency. This model takes the base and augmented headlines as inputs and outputs a semantic similarity score, bounded between 0 and 1. The score thresholds define stricter guidelines for each augmentation action, where negated, semantically-shifted, and reworded headlines must fall in ranges (0, 0.33), (0.33, 0.66), and (0.66, 1.00) respectively. This approach provides a well-defined, quantitative framework for categorizing augmentations. It not only enforces consistency in semantic relationships but also ensures that the augmented headlines are reliable and aligned with the intended transformations.

A further exploration on the specifics of the three (steps (i)-(iii)) headline transformations are expanded upon in appendix section \ref{app:headline_transformations}. Table~\ref{tab:headline_transformations} depict a pedagogical example illustrating these transformations:

% \textbf{Original Headline:} \textit{Johnson \& Johnson to Buy Surgical Robotics Maker Auris}
% \begin{enumerate}
%     \item \textbf{Reworded:} \textit{Auris Acquired by Pharmaceutical Giant Johnson \& Johnson}
%     \item \textbf{Semantically-Shifted:} \textit{Abbott Laboratories Acquires Medical Imaging Specialist Siemens Healthineers}
%     \item \textbf{Negated:} \textit{Auris to Sell Off Stake in Surgical Robotics Business to Johnson \& Johnson}
% \end{enumerate}

\begin{table}[h!]
    \centering
    \setlength{\arrayrulewidth}{0.5mm} % Increase thickness of table lines
    \renewcommand{\arraystretch}{1.2} % Increase the row height
    \begin{tabular}{@{}>{\bfseries}lp{0.75\textwidth}@{}}
        \toprule
        \textbf{Transformation Action} & \textbf{Example Headline} \\ 
        \midrule
        \textbf{Original} & \textit{Johnson \& Johnson to Buy Surgical Robotics Maker Auris} \\ 
        \textbf{Reworded (Re)} & \textit{Auris Acquired by Pharmaceutical Giant Johnson \& Johnson} \\ 
        \textbf{Semantically-Shifted (S)} & \textit{Abbott Laboratories Acquires Medical Imaging Specialist Siemens Healthineers} \\ 
        \textbf{Negated (N)} & \textit{Auris to Sell Off Stake in Surgical Robotics Business to Johnson \& Johnson} \\ 
        \bottomrule
    \end{tabular}
    \caption{Example transformations of a news headline using the LLaMA-3-7b-chat model.}
    \label{tab:headline_transformations}
\end{table}

The final augmentation action \textbf{Ra}, is a function that randomly selects a headline from the training split (ignoring headlines within the base DNS $\mathcal{N}$). This acts similarly to randomly sampling negatives in a traditional contrastive learning mechanism.

Our augmentation stochastic transformation $T: \mathcal{N} \to (s, \hat{\mathcal{N}})$, generates augmented DNS defined fully in Appendix \ref{app:headline_transformations}. However, the intuition is quite straightforward. For each DNS, we can generate an augmentation by: 1) Determine the number of headlines in the augmented DNS ($\hat{\mathcal{N}}$) by sampling from the global distribution 2) For each augmented headline $\in \hat{\mathcal{N}}$, randomly sample an augmentation action from $P_{actions}$ 3) Perform the sampled augmentation action. Note that the actions \textbf{Re}, \textbf{S}, and \textbf{N} each randomly sample a headline from the base DNS ($\mathcal{N}$), and use that to create an augmented headline. 4) Randomly shuffle the order of the augmented headlines in $\hat{\mathcal{N}}$.

In our experiments we set $P_{actions}$ such that: $P(\textbf{Re}) = 0.05$, $P(\textbf{S}) = 0.025$, $P(\textbf{N}) = 0.05$, and $P(\textbf{Ra}) = 0.775$. These values were used because augmented DNS produced a similarity score distribution with a high skew to negative scores (as common in many contrastive learning frameworks), while also not overly depending on negative action augmentations. We leave finetuning this probability distribution as a task for future work.

\paragraph{3. Generating Similarity Scores}

For each augmented news headline \( \hat{\mathcal{N}} \), we calculate the similarity score \( S(\hat{\mathcal{N}}) \) using a logarithmic weighting function:
\begin{equation}
S(\hat{\mathcal{N}}) = \ln\left(1 + \frac{\sum_{a \in \hat{\mathcal{N}}_{A}} Sim(a)}{S_{\text{max}}} \cdot (e - 1)\right)
\label{eq:similarity_score}
\end{equation}

where \( a \) is an augmentation action within the list of augmentation action tuple \( \hat{\mathcal{N}}_{A} \), \( S_{\text{max}} \) is the maximum possible total score to normalize the sum to the range \([0, 1]\), and \( Sim(.) \) is the function mapping each augmentation action to its corresponding similarity score, such that:

\[
Sim(\textbf{Re}) = 1.0, \quad Sim(\textbf{S}) = 0.5, \quad Sim(\textbf{N}) = 0.0, \quad Sim(\textbf{Ra}) = 0.0
\]

% Inside your document
\begin{wraptable}{r}{0.4\textwidth} % 'r' for right side, 0.5\textwidth for table width
\centering
\begin{tabular}{c|cccc|c}
\toprule
\textbf{} & \textbf{\textcolor{ForestGreen}{Re}} & \textbf{\textcolor{Goldenrod}{S}} & \textbf{\textcolor{Crimson}{N}} & \textbf{\textcolor{Crimson}{Ra}} & \textbf{$S(\hat{\mathcal{N}})$} \\
\midrule
$\hat{\mathcal{N}_1}$ & \textcolor{ForestGreen}{15} & \textcolor{Goldenrod}{1} & \textcolor{Crimson}{0} & \textcolor{Crimson}{15} & \textcolor{ForestGreen}{1.00} \\
$\hat{\mathcal{N}_2}$ & \textcolor{ForestGreen}{5} & \textcolor{Goldenrod}{3} & \textcolor{Crimson}{1} & \textcolor{Crimson}{21} & \textcolor{Goldenrod}{0.53} \\
$\hat{\mathcal{N}_3}$ & \textcolor{ForestGreen}{1} & \textcolor{Goldenrod}{4} & \textcolor{Crimson}{4} & \textcolor{Crimson}{17} & \textcolor{Goldenrod}{0.29} \\
$\hat{\mathcal{N}_4}$ & \textcolor{ForestGreen}{0} & \textcolor{Goldenrod}{0} & \textcolor{Crimson}{1} & \textcolor{Crimson}{26} & \textcolor{Crimson}{0.00} \\
\bottomrule
\end{tabular}
\caption{List of augmentation actions from a base daily news set, and their accompanying similarity score.}
\label{tab:sim_scores_per_token_list}
\end{wraptable}

\textbf{Intuition}: The goal of generating a similarity score is to create a metric between 0.0 and 1.0 that measures how similar a DNS is semantically to its augmentation. When comparing two headlines, we assign high similarity if they are rephrased but semantically identical to each other (\textbf{Re}), medium similarity if they are semantically-shifted (\textbf{S}), and low similarity if they are semantic opposites (\textbf{N}) or completely different (\textbf{Ra}).

A simple approach to generating a similarity scores between a DNS and its augmentation could be to take the simple mean of all of the augmentation action scores. However, if we observe that two DNS each have a headline that is semantically identical but just reworded, then we want to take note that those DNS are so similar. Equation \ref{eq:similarity_score}, skews the similarity scores such that actions with higher similarity scores have an exponentially larger effect in DNS similarity, than semantically different actions. An example of similarity scores is outlined in table \ref{tab:sim_scores_per_token_list}. There, we see that if we have an augmented DNS, $\hat{\mathcal{N_1}}$, that has 15 semantically identical headlines to the base DNS, then the similarity score should be very high. Furthermore, $\hat{\mathcal{N_4}}$ is a headline with one semantically negated headline from the original, and the rest are completely disjoint headlines, and so it has a very low semantic similarity. 

\subsection{Weighted Self-Supervised Contrastive Learning (WSSCL)}

With augmented daily news sets (DNS) generated from the training set, and similarity scores assigned to each anchor-augmentation DNS pair, we can now proceed to construct the similarity embedding space using a weighted self-supervised contrastive learning approach.

Our embedding space optimization task is inspired by Supervised Contrastive Learning \cite{khosla2021supervisedcontrastivelearning}, but is augmented to allow for regressive similarity measurements between anchor and augmented projections instead of binary positive / negative labels. Our representation learning framework consists of 3 components, the \textbf{Encoder Network}, the \textbf{Projection Network}, and the \textbf{Classification Networks}:

\textbf{Encoder Network}: $e = Enc(x)$ is a LLaMA-3 \cite{meta2024llama3} 7 billion parameter chat model. It was fine-tuned to predict market movement direction (\textit{Fall}, \textit{Neutral}, or \textit{Rise}) from the NIFTY-SFT dataset \cite{fin-dataset_saqur2024nifty}. Additional details of SFT implementation are available from \cite{saqur2024teachesrobotswalkteaches}. Concatenated daily news sets are tokenized and propagated through the encoder network, and the mean values from the last hidden layer are returned, such that \( e = \text{Enc}(x) \in \mathbb{R}^{D_E} \). \( e \) is then normalized to a hypersphere, which in our implementation had dimensions of 4096.

\textbf{Projection Network}: $p = Proj(e)$ is a feedforward neural network with a single hidden layer, and a shape of (4096, 256, 128), and a single ReLU nonlinearlity unit. The role of this network is to project embeddings \( e \) into our embedding space. After projection, the output values are again normalized. We found negligible effects on the quality of the embedding space by increasing the complexity of the projection network.

\textbf{Classification Networks}: $Class_{Proj}(p)$, $Class_{SFT}(x)$ and $Class_{Both}(p, x)$, are tasked with classifying the market movement as rising, falling or neutral. $Class_{Proj}$ takes the projections from the embedding space as an input and $Class_{SFT}$ takes the final hidden states from a separate LLM finetuned for market prediction. $Class_{Both}(p, x)$ takes both projection and SFT embeddings as inputs. Training of the classification networks is done after the projection network is optimized. Note that for training of the classification networks all augmentations are discarded, and our classifiers are optimized on real news headlines only.

The optimization task we define for our projection network are defined the Weighted Similarity Contrastive Loss (Equation \ref{eq:weighted_similarity_contrastive_loss}).

\begin{equation}
\mathcal{L}_{\text{WSCL}} = \frac{1}{|\mathcal{D}_{news headlines}|} \sum_{i=1}^{N} \sum_{j=1}^{M_i} \left[ s_{ij} \cdot d_{ij}^2 + (1 - s_{ij}) \cdot \max(0, \delta - d_{ij})^2 \right],
\label{eq:weighted_similarity_contrastive_loss}
\end{equation}

Where, $N$: Total number of anchor news headlines in a batch, $M_i$: Number of augmented samples for anchor $i$, $d_{ij} = ||\mathbf{p}_i - \mathbf{q}_{ij}||_2$,  $s_{ij} \in [0, 1]$: Similarity score between the anchor and augmented embeddings, and $\delta$ is the hyperparameter defining the contrastive margin.

The proposed loss (\(\mathcal{L}_{\text{WSCL}}\)) extends the classical triplet loss by incorporating a fuzzy similarity score \(s_{ij} \in [0, 1]\), enabling a more nuanced handling of relationships between anchor and augmented samples. This formulation draws inspiration from the traditional triplet loss introduced by \cite{schroff2015facenet}. in FaceNet, which minimizes the distance between anchor-positive pairs while maximizing the distance between anchor-negative pairs using a fixed margin. By replacing binary labels with continuous similarity values, \(\mathcal{L}_{\text{WSCL}}\) facilitates a finer gradient flow and captures graded relationships, making it particularly suitable for tasks involving regressive or weighted similarity measures.

The \textbf{pull loss} term, $s_{ij} \cdot d_{ij}^2$, minimizes the distance between anchor and augmented embeddings when $s_{ij}$ is high (e.g., $s_{ij} \approx 1.0$). Conversely, the \textbf{push loss} term, $(1 - s_{ij}) \cdot \max(0, \delta - d_{ij})^2$, increases the distance between embeddings when $s_{ij}$ is low (e.g., $s_{ij} \approx 0.0$), ensuring proper separation within the embedding space. 

In addition to \(\mathcal{L}_{\text{WSCL}}\), the Continuously Weighted Contrastive Loss (CWCL) proposed by \cite{srinivasa2023cwclcrossmodaltransfercontinuously} is another approach for weighted similarity learning. Unlike \(\mathcal{L}_{\text{WSCL}}\), CWCL uses cosine similarity instead of Euclidean distance and incorporates a softmax normalization across all pairs in the batch to enforce global consistency. The CWCL loss is defined as:

\begin{equation}
\mathcal{L}_{\text{CWCL}} = -\frac{1}{|\mathcal{D}_{news headlines}|} \sum_{i=1}^{N} \sum_{j=1}^{M_i} s_{ij} \cdot \log \frac{\exp(-d_{ij} / \tau)}{\sum_{k=1}^{M_i} \exp(-d_{ik} / \tau)},
\label{eq:cwcl_loss}
\end{equation}

Where \(\tau\) is the temperature scaling parameter that controls the sharpness of the distribution. CWCL allows for fine-grained alignment of embeddings by normalizing similarity scores within the batch, providing a complementary perspective to the pull-push mechanics of \(\mathcal{L}_{\text{WSCL}}\).

Both approaches aim to improve the representation of graded relationships in embedding spaces but differ in their distance metrics and weighting strategies. In Section \ref{sec:results}, we explore each loss function and measure which one performs better on our evaluation tasks.

It is notable that for the WSSCL task, the ground truth market direction corresponding to the DNS's day is not used at all in clustering. The ground truth market direction is saved only for our evaluation tasks (see subsection \ref{subsec:evaluation}). This is so we can measure if the self-supervised task, optimized only for similarity inherently encodes market direction features, without giving them specifically. This lends credence to the idea that through WSSCL information on markets is created.


\subsection{Evaluating Similarity Space Information Richness}\label{subsec:evaluation}

To measure the efficacy of ContraSim, we employ two approaches. The first is the most straightforward: we train a market movement prediction algorithm using both ContraSim embeddings and a baseline without ContraSim embeddings, and evaluate its downstream classification performance.

The second approach involves analyzing how our projection network ($Proj(e)$) embeds real-world daily news sets (DNS). Using information-dense metrics, we evaluate whether the model inherently clusters DNS associated with the same market direction closer together. For instance, if the similarity space places headlines corresponding to rising markets near one another, it suggests that meaningful information is being captured. This clustering behavior is quantified using four information-dense metrics:

\textbf{1) Geometric K-Nearest Neighbors (g-KNN):} This metric evaluates the quality of local label distributions by measuring the entropy of the labels among the \(k\)-nearest neighbors of each data point, averaged over the dataset. It provides insights into the local clustering structure of the embedding space \cite{Lord_2018}. \textbf{2) Nearest Neighbor Accuracy:} This metric assesses the proportion of data points whose closest neighbor shares the same category label, offering a direct measure of clustering performance. \textbf{3) Kullback-Leibler (KL) Divergence:} This metric quantifies the difference between the local label distribution among the \(k\)-nearest neighbors and the global label distribution, highlighting the extent to which local clusters deviate from random chance \cite{shlens2014noteskullbackleiblerdivergencelikelihood}. \textbf{4) Jensen-Shannon Divergence (JSD):} This symmetric and bounded metric evaluates the similarity between local and global label distributions, enhancing interpretability. It is widely recognized for its effectiveness in quantifying clustering quality and information richness in embedding spaces \cite{lin1991jsd}.

%----------------------------------------%
% FLATTENED CONTENT FROM: {ICLR-25/sections/04_experiments.tex}
%----------------------------------------%

\section{Experimental Results and Interpretations} \label{sec:results}

In this section, we evaluate the performance and interpretability of the ContraSim framework across multiple datasets and tasks. The experiments are designed to assess both the downstream classification capabilities of ContraSim embeddings and the inherent clustering properties of the generated similarity space. By testing on datasets from diverse domains—financial news (NIFTY-SFT, BigData22) and movie reviews (IMDB)—we aim to demonstrate the generalizability of ContraSim beyond financial prediction tasks. Additionally, we utilize a range of quantitative metrics, including accuracy, F1 score, and embedding space density metrics, to measure the quality and effectiveness of the embeddings. These evaluations provide insights into the practical utility of ContraSim for supervised learning and its ability to create meaningful representations that capture domain-specific nuances.


\subsection{Datasets}
For each of these experiments, we compare results on 3 datasets: NIFTY-SFT \cite{saqur2024niftyfinancialnewsheadlines}, BigData22 \cite{fin-dataset_bigdata22_soun2022accurate}, and the IMDB review dataset \cite{maas-EtAl:2011:ACL-HLT2011}. A full analysis of this is outlined in Table \ref{tab:datasets_for_embedding}. \textbf{NIFTY-SFT} \cite{saqur2024niftyfinancialnewsheadlines} is the collection of WSJ headlines \cite{wsj} collected and concatenated together alongside the movement of the US equities market (ticker: \$SPY)  for the corresponding day. \textbf{BigData22} \cite{fin-dataset_bigdata22_soun2022accurate} likewise is a financial news headline dataset, but news headlines are composed of tweets as apposed to WSJ headlines. Finally, we evaluate with the \textbf{IMDB review} dataset, which is a collection of human-written reviews for a list of movies alongside the movie's overall review score. An extended analysis of the datasets used is available in Appendix \ref{app:sec:datasets}.

For the IMDB review example, we define a news headline as the concatenated movie reviews, and the prediction task into \textit{Low} (0.0 - 5.5 stars), \textit{Medium} (5.6 - 7.5 stars) and \textit{High} (7.6 - 10.0 stars). We evaluate ContraSim on this dataset to assess its generalizability to orthogonal tasks beyond financial domain prediction.
% We explore using ContraSim on this dataset for two primary reasons: 1) To tease at the utility of a ContraSim framework on tasks outside of the domain of finanical prediction analysis 2) To explore how well ContraSim performs on a task that is easier than predicting the stock market.

\begin{table}[ht]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Dataset} & \textbf{Problem Domain} & \textbf{Headlines/Reviews} & \textbf{Days/Movies} & \textbf{Date Range} \\
\midrule
NIFTY-SFT & Financial Headlines & 18,746 & 2,111 &  2010/01/06-2017/06/27 \\
BigData22 & Financial Tweets & 272,762 & 7,164  & 2019/07/05, 2020/06/30 \\
IMDB Review & Movie Reviews & 50,000 & 1,000 & 1874, 2020 \\
\bottomrule
\end{tabular}
\caption{Summary of the datasets used in the experiments, including their problem domain, the number of headlines, the number of days, and the date range.}
\label{tab:datasets_for_embedding}
\end{table}

%\todo[inline]{Add a figure with the PCA embeddings once training is complete.}
% \paragraph{Results}
\subsection{Results}

\begin{wraptable}{r}{0.65\textwidth}
\centering
\small % This reduces the font size slightly
\begin{tabular}{l|rrr}
\toprule 
              \textbf{Model} & \textbf{NIFTY-SFT} & \textbf{BigData22} & \textbf{IMDB} \\ 
\midrule
Baseline       & .3333 / .3333       & .5000 / .5000      & .3333 / .3333 \\ 
\midrule
$Class_{CWCL}$ & .3512 / .3433       & .5005 / .5016      & .3900 / .3897 \\ 
$Class_{WSCL}$ & .3505 / .3336       & .5014 / .5019      & .4044 / .3992 \\ 
\midrule
$Class_{LLM}$  & .3522 / .3833       & .5150 / \textbf{.5094} & .4518 / .4124 \\ 
\midrule
$Class_{LLM + CWCL}$ & \textbf{.3779} / \textbf{.3712} & .5156 / \underline{.5089} & \textbf{.5198} / \textbf{.4620} \\ 
$Class_{LLM + WSCL}$ & \underline{.3678} / \underline{.3680} & \textbf{.5167} / \underline{.5090} & \underline{.5103} / .4498 \\ 
\bottomrule
\end{tabular}
\caption{Accuracies and F1 scores \textbf{(Accuracy / F1 Score)} for classification models across the three datasets. The NIFTY-SFT and IMDB datasets were subsetted to achieve a (33\%, 33\%, 33\%) split. The BigData22 dataset with only \textit{Fall} and \textit{Rise} labels was subsetted to (50\%, 50\%). Best results and approximately equal to best are in \textbf{bold} and \underline{underline} respectively.}
\label{tab:accuracy_results}
\end{wraptable}


Table \ref{tab:accuracy_results} demonstrates that combining similarity space projections with LLM embeddings improves the classification of news headlines into rising, neutral, or falling categories. Specifically, applying this conjunctive approach to the NIFTY-SFT dataset results in a balanced accuracy of 37.79\%, reflecting a 13\% increase over the baseline and a 7\% improvement compared to using only LLM embeddings. In contrast, the model trained exclusively on projections performed slightly better than the baseline. Similarly, on the IMDB dataset, the composite model outperformed the baseline LLM, achieving a 6.8\% increase in accuracy and a 0.0496 improvement in F1 score. However, for the Bigdata22 dataset, no significant differences in accuracy or F1 score were observed between the models. Similar performance was found across each of the losses.

Table \ref{tab:knn_results} presents embedding space density metrics for the baseline model and our similarity space projections, evaluated across three datasets. The results demonstrate that the ContraSim embedding space, optimized through WSSCL and CWCL losses, consistently outperforms the baseline in g-KNN, KNN, KL-Divergence, and JSD metrics. Notably, the $\mathcal{L}_{\text{WSCL}}$ projection achieves the highest g-KNN and KNN scores on the NIFTY-SFT dataset, indicating better local neighborhood density and improved separability in the embedding space. Similarly, $\mathcal{L}_{\text{WSCL}}$ and $\mathcal{L}_{\text{CWCL}}$ models are competitive, with $\mathcal{L}_{\text{WSCL}}$ excelling in KL-Divergence and JSD scores on BigData22, suggesting enhanced distributional alignment.

These results provide strong evidence that the WSSCL process inherently generates informative market representations without requiring ground truth labels. Moreover, the competitive performance of the $\mathcal{L}_{\text{WSCL}}$ models across datasets underscores their ability to generalize across diverse textual domains, reinforcing the utility of similarity space projections for various tasks.


%%%%%% TABLE 5 (CLUSTERING ACCURACY) - START  %%%%%%%%%%%
\begin{table}[ht]
\centering
\begin{tabular}{ll|cccc}
\toprule
% \textbf{Dataset} & \textbf{Model} & \textbf{g-KNN (k=5)} & \textbf{KNN (k=5)} & \textbf{KL-Divergence} & \textbf{JSD} \\
\textbf{Dataset} & \textbf{Model} & \textbf{g-KNN (k=5)  ($\uparrow$)} & \textbf{KNN (k=5) (↑)} & \textbf{KL-Divergence (↑)} & \textbf{JSD (↑)} \\ 
\midrule
\multirow{3}{*}{\textbf{NIFTY-SFT}} 
    & Baseline & .5916 & .4668 & .3539 & .1054 \\ 
    & $\mathcal{L}_{\text{CWCL}}$ & .7647 & .4732 & \textbf{.3821} & \textbf{.1164} \\ 
    & $\mathcal{L}_{\text{WSCL}}$ & \textbf{.7219} & \textbf{.5205} & .3740 & .1144 \\ 
\midrule
\multirow{3}{*}{\textbf{BigData22}} 
    & Baseline & .7951 & .5506 & .1499 & .0452 \\ 
    & $\mathcal{L}_{\text{CWCL}}$ & \textbf{.9084} & \textbf{.7101} & .2030 & .0607 \\ 
    & $\mathcal{L}_{\text{WSCL}}$ & .8590 & .5507 & \textbf{.2246} & \textbf{.0640} \\ 
\midrule
\multirow{3}{*}{\textbf{IMDB}} 
    & Baseline & .7456 & .5781 & .2919 & .0818 \\ 
    & $\mathcal{L}_{\text{CWCL}}$ & .7626 & \textbf{.7500} & \textbf{.3957} & \textbf{.1120} \\ 
    & $\mathcal{L}_{\text{WSCL}}$ & \textbf{.8252} & .6875 & .3024 & .0908 \\ 
\bottomrule
\end{tabular}
\caption{Comparison of Baseline and Projection models across datasets and evaluation metrics. Note that finding true baseline values for these metrics on unbalanced sets of labels is nontrivial and out of scope for this paper. As a result, estimated baseline values are the mean of 1000 cases of randomly distributed points following the respective label splits for each dataset. The best results are in \textbf{bold}.}
\label{tab:knn_results}
\end{table}

\subsection{Training Details}

The projection network was trained for 50 epochs using \( \mathcal{L}_{\text{CWCL}}\) and \(\mathcal{L}_{\text{WSCL}} \) losses, with a learning rate of 0.001 and a batch size of 2. We optimized using the Adam optimizer (\( \beta_1 = 0.9, \beta_2 = 0.999 \)). A cosine annealing schedule was applied to adjust the learning rate, and gradient clipping with a norm of 1.0 ensured training stability. The datasets were split into 80\% training, 10\% validation, and 10\% test sets, and augmentation probabilities were tuned to maximize similarity learning. 


\section{Future Work}

Future research should explore applying ContraSim to diverse domains such as healthcare, legal, and social media datasets to evaluate its generalizability across varying text types and contexts. Additionally, incorporating advanced LLMs like GPT-4 may enhance embedding quality and clustering performance. Investigating the integration of techniques such as hard negative mining, dynamic temperature scaling, and multi-task learning with ContraSim could further refine its representation capabilities. Lastly, extending ContraSim to real-time financial forecasting applications and unsupervised learning scenarios may yield insights into dynamic market behavior.


%\paragraph{Reproducibility Statement} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \clearpage
\bibliographystyle{plain}
\bibliography{refs/main_arxiv}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% APPENDIX START %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendixpage
\DoToC
\appendix
\clearpage

\section{Headline Transformations}\label{app:headline_transformations}

\subsection{Outlining the Headline Transformation Algorithm}

In Algorithm \ref{alg:news_headline_augmentation}, we outline the steps for generating augmented DNS, from the corpus of news headlines. Note that the details of the augmentation actions are shown in subsection \ref{subsec:headline_aug}.


\begin{algorithm}[htbp!]
\caption{Stochastic Daily News Set Augmentation Transformation \( T \)}
\label{alg:news_headline_augmentation}
\DontPrintSemicolon % Removes semicolons for a cleaner look
\KwIn{Original news headline \( \mathcal{N} = (h_{1}, h_{2}, \dots, h_{m}) \)} 
\KwIn{Action distribution \( P_{\text{actions}} \) over actions \( \{\textbf{Re}, \textbf{S}, \textbf{N}, \textbf{Ra}\} \)}
\KwOut{Augmented news headline \( (\hat{\mathcal{N}}, s) \) with similarity score \( s \)}

Sample \( n \sim \text{Distribution of news headline lengths in corpus} \)\;
Initialize \( \hat{\mathcal{N}} \gets \emptyset \), \( S \gets 0 \)\;

\For{\( i \gets 1 \) \KwTo \( n \)}{
    Sample \( a_i \sim P_{\text{actions}} \)\;
    \uIf{\( a_i \in \{\textbf{Re}, \textbf{S}, \textbf{N}\} \)}{
        Sample headline \( h \sim \mathcal{N} \)\;
    }
    \ElseIf{\( a_i = \textbf{Ra} \)}{
        Sample random headline \( h \sim \text{corpus} \)\;
    }
    \uIf{\( a_i = \textbf{Re} \)}{ 
        \( h' \gets \text{Reword}(h) \)\;
        \( S \gets S + 1.0 \)\;
    }
    \ElseIf{\( a_i = \textbf{S} \)}{
        \( h' \gets \text{SemanticShift}(h) \)\;
        \( S \gets S + 0.5 \)\;
    }
    \ElseIf{\( a_i = \textbf{N} \)}{
        \( h' \gets \text{Negate}(h) \)\;
        \( S \gets S + 0.0 \)\;
    }
    \ElseIf{\( a_i = \textbf{Ra} \)}{
        \( h' \gets h \)\;
        \( S \gets S + 0.0 \)\;
    }
    Append \( h' \) to \( \hat{\mathcal{N}} \)\;
}
Shuffle \( \hat{\mathcal{N}} \)\;
Compute similarity score \( s \gets S(N) \)\;

\Return \( (\hat{\mathcal{N}}, s) \)\;
\label{alg:headline_aug}
\end{algorithm}

\subsection{Headline Augmentation} \label{subsec:headline_aug}

In this section, we outline the steps of generating the headline augmentations. In Tables \ref{tab:headline_rephrasing}, \ref{tab:headline_rephrasing_adviser2}, and \ref{tab:headline_rephrasing_oil}, we outline the prompts used to generate the reworded, semantically-shifted, and negated augmentations. Then, we show the quality control mechanism used to ensure semantic alignment between desired semantic similarity and actual semantic similarity of augmented headlines.

\begin{table}[ht]
\centering
\begin{tabular}{>{\raggedleft\arraybackslash}p{0.10\textwidth} p{0.75\textwidth}}
\toprule
 & \textbf{Original Headline} \\
 & ``Johnson \& Johnson to Buy Surgical Robotics Maker Auris'' \\
\midrule

% Re-worded Augmentation
 & \textbf{Reworded Augmentation} \\
\textbf{System} & \textit{Please reword this headline for me, preserving the exact semantic meaning perfectly. Your returned headline should contain the exact information with no meaning added or subtracted, but just rephrased. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "Johnson \& Johnson to Buy Surgical Robotics Maker Auris" \\
\textbf{Responses} & 1. Auris Acquired by Pharmaceutical Giant Johnson \& Johnson \newline
2. Auris Acquired by Pharmaceutical Giant Johnson \& Johnson in Deal Involving Surgical Robot Technology \newline
3. Auris Acquired by Pharmaceutical Giant Johnson \& Johnson in Deal Involving Surgical Robot Manufacturer \newline
4. Auris Manufacturer of Surgical Robots Acquired by Johnson \& Johnson \newline
5. Auris Medical Acquired by Pharmaceutical Giant Johnson \& Johnson in Deal Involving Surgical Robotics Manufacturer \\
\midrule

% Slight Ablation Augmentation
& \textbf{Semantic-Shift Augmentation} \\
\textbf{System} & \textit{Please modify this headline slightly, so it is about something related but different. If the headline is good news, ensure it remains good news, and if it is bad news, ensure it remains bad news. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "Johnson \& Johnson to Buy Surgical Robotics Maker Auris" \\
\textbf{Responses} & 1. Abbott Laboratories Acquires Medical Imaging Specialist Siemens Healthineers \newline
2. J\&J Acquires Medtech Firm Verb for Improved Cancer Treatment Options \newline
3. J\&J Acquires Orthopedic Implant Company Zimmer Biomet in \$14 Billion Deal \newline
4. J\&J Acquires Orthopedic Implant Company DePuy Synthes for \$21 Billion \newline
5. J\&J Acquires Medtech Company Verb Surgical in \$3 Billion Deal \\
\midrule

% Negative Augmentation
& \textbf{Negative Augmentation} \\
\textbf{System} & \textit{Please reword this headline for me such that the information is the same except that it now is about the opposite meaning. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "Johnson \& Johnson to Buy Surgical Robotics Maker Auris" \\
\textbf{Responses} & 1. Auris to Sell Off Stake in Surgical Robotics Business to Johnson \& Johnson \newline
2. Auris Abandons Plans to Acquire Surgical Robot Business from Johnson \& Johnson \newline
3. Auris to Sell Majority Stake to Rival of Johnson \& Johnson's Surgical Robot Division \newline
4. Auris Acquires Surgical Robotics Leader Johnson \& Johnson \newline
5. Auris Abandons Plans to Acquire Surgical Robotics Giant Johnson \& Johnson \\
\bottomrule
\end{tabular}
\caption{Rephrasing, slight ablation, and negative modification of the headline "Johnson \& Johnson to Buy Surgical Robotics Maker Auris." Each augmentation displays the system prompt, user-provided headline, and model-generated responses listed with numbers.}
\label{tab:headline_rephrasing}
\end{table}

\clearpage

\begin{table}[ht]
\centering
\begin{tabular}{>{\raggedleft\arraybackslash}p{0.10\textwidth} p{0.75\textwidth}}
\toprule
 & \textbf{Original Headline} \\
 & ``Adviser Profile: Easing Client Worries in Uncertain Times'' \\
\midrule

% Re-worded Augmentation
 & \textbf{Reworded Augmentation} \\
\textbf{System} & \textit{Please reword this headline for me, preserving the exact semantic meaning perfectly. Your returned headline should contain the exact information with no meaning added or subtracted, but just rephrased. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "Adviser Profile: Easing Client Worries in Uncertain Times" \\
\textbf{Responses} & 1. Finding Calm Amidst Turmoil: A Trustworthy Adviser's Approach to Alleviating Clients' Concerns \newline
2. Managing Fears and Concerns of Clients Amidst Unpredictable Circumstances \newline
3. Managing Client Anxiety Amidst Unpredictable Circumstances \newline
4. Navigating Client Concerns Amid Unpredictable Circumstances \newline
5. Managing Clients' Concerns Amidst Unpredictable Circumstances \\
\midrule

% Slight Ablation Augmentation
& \textbf{Semantic-Shift Augmentation} \\
\textbf{System} & \textit{Please modify this headline slightly, so it is about something related but different. If the headline is good news, ensure it remains good news, and if it is bad news, ensure it remains bad news. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "Adviser Profile: Easing Client Worries in Uncertain Times" \\
\textbf{Responses} & 1. Financial Planner Profile: Boosting Clients' Confidence Amid Market Volatility \newline
2. Financial Planner Spotlight: Calming Investor Fears Amid Market Volatility \newline
3. Financial Planner Spotlight: Boosting Investor Confidence Amid Market Volatility \newline
4. Financial Planner Spotlight: Offering Calming Expertise Amid Market Volatility \newline
5. Financial Planner Focuses on Building Trust Amid Market Volatility \\
\midrule

% Negative Augmentation
& \textbf{Negative Augmentation} \\
\textbf{System} & \textit{Please reword this headline for me such that the information is the same except that it now is about the opposite meaning. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "Adviser Profile: Easing Client Worries in Uncertain Times" \\
\textbf{Responses} & 1. Adviser Profile: Exacerbating Client Fears in Turbulent Eras \newline
2. Adviser Profile: Exacerbating Client Fears in Chaotic Situations \newline
3. Adviser Profile: Exacerbating Client Fears in Unpredictable Circumstances \newline
4. Adviser Profile: Exacerbating Client Fears in Certain Circumstances \newline
5. Adviser Profile: Exacerbating Client Fears in Turbulent Eras \\
\bottomrule
\end{tabular}
\caption{Rephrasing, slight ablation, and negative modification of the headline "Adviser Profile: Easing Client Worries in Uncertain Times." Each augmentation displays the system prompt, user-provided headline, and model-generated responses listed with numbers.}
\label{tab:headline_rephrasing_adviser2}
\end{table}

\clearpage

\begin{table}[ht]
\centering
\begin{tabular}{>{\raggedleft\arraybackslash}p{0.10\textwidth} p{0.75\textwidth}}
\toprule
 & \textbf{Original Headline} \\
 & ``U.S. Oil Producers Find a Surprise New Market: China'' \\
\midrule

% Re-worded Augmentation
 & \textbf{Reworded Augmentation} \\
\textbf{System} & \textit{Please reword this headline for me, preserving the exact semantic meaning perfectly. Your returned headline should contain the exact information with no meaning added or subtracted, but just rephrased. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "U.S. Oil Producers Find a Surprise New Market: China" \\
\textbf{Responses} & 1. China Becomes an Unexpected Customer Base for U.S. Oil Producers \newline
2. China Becomes an Unexpected Buyer of U.S. Crude Oil Supplies \newline
3. China Emerges as an Unexpected Buyer of U.S.-Produced Crude Oil \newline
4. China Becomes an Unexpected Buyer of U.S. Crude Oil Supplies \newline
5. China Becomes an Unexpected Customer for U.S. Oil Producers \\
\midrule

% Slight Ablation Augmentation
& \textbf{Semantic-Shift Augmentation} \\
\textbf{System} & \textit{Please modify this headline slightly, so it is about something related but different. If the headline is good news, ensure it remains good news, and if it is bad news, ensure it remains bad news. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "U.S. Oil Producers Find a Surprise New Market: China" \\
\textbf{Responses} & 1. U.S. Farmers Discover Surprising Boost in Exports to Asia \newline
2. U.S. Farmers Reap Unexpected Benefits from Growing Trade Ties with China \newline
3. China's Energy Crisis Eases as U.S. Oil Suppliers Step Up Deliveries \newline
4. U.S. Farmers Discover Unexpected Export Boom in Asia \newline
5. U.S. Natural Gas Exporters Strike Gold in Growing Asian Demand \\
\midrule

% Negative Augmentation
& \textbf{Negative Augmentation} \\
\textbf{System} & \textit{Please reword this headline for me such that the information is the same except that it now is about the opposite meaning. Please generate the headline, and return only that with no other text. Thanks.} \\
\textbf{User} & "U.S. Oil Producers Find a Surprise New Market: China" \\
\textbf{Responses} & 1. China's Oil Consumers Struggle to Fill Gap as U.S. Supplies Dry Up \newline
2. China's Oil Demand Plummets, U.S. Producers Struggle to Fill Surplus Capacity \newline
3. China's Oil Consumption Plummets, Leaving U.S. Producers Scrambling to Fill Empty Pipelines \newline
4. China's Oil Importers Face Surprising Drought as U.S. Supplies Dry Up \newline
5. China's Oil Consumption Plummets as U.S. Producers Fail to Break into the Market \\
\bottomrule
\end{tabular}
\caption{Rephrasing, slight ablation, and negative modification of the headline "U.S. Oil Producers Find a Surprise New Market: China." Each augmentation displays the system prompt, user-provided headline, and model-generated responses listed with numbers.}
\label{tab:headline_rephrasing_oil}
\end{table}

\clearpage

\subsection{Quality Monitoring System for Augmentations}
\label{app:quality_monitoring}

To ensure that the generated semantic augmentations align with the desired levels of semantic similarity, we employ a robust quality monitoring system. This system leverages a fine-tuned BERT model as a discriminator to validate the semantic relationships between base headlines and their augmentations. The primary objective is to confirm that the augmentations adhere to the predefined similarity thresholds associated with each augmentation action.

\paragraph{1. Similarity Score Validation} 
The discriminator model evaluates the similarity between a base headline and its augmented counterpart, producing a score in the range \([0, 1]\). These scores are compared against action-specific thresholds to classify the augmentations:
\begin{itemize}
    \item \textbf{Reworded (Re):} Similarity scores must fall within the range \([0.66, 1.00]\), indicating high semantic alignment with minimal alteration in meaning.
    \item \textbf{Semantically-Shifted (S):} Scores between \([0.33, 0.66]\) reflect moderate semantic divergence while maintaining topical relevance.
    \item \textbf{Negated (N):} Scores in \([0, 0.33]\) denote significant semantic contrast or opposing meanings.
\end{itemize}

\paragraph{2. System Workflow} 
The process begins by passing the base and augmented headlines through the fine-tuned BERT model, which computes similarity scores using cosine similarity of their embeddings. These scores are then compared against the specified thresholds. If an augmentation fails to meet the desired threshold for its action type, it is flagged for review or discarded.

\paragraph{3. Feedback Mechanism} 
To iteratively refine the augmentation process, the quality monitoring system provides feedback to the generation pipeline. For instance, if a significant portion of reworded augmentations falls below the required threshold, the prompts for the augmentation model are adjusted, or additional constraints are imposed during headline generation.

\paragraph{4. Ensuring Semantic Coherence} 
The quality monitoring system serves a dual purpose: it enforces the semantic coherence of augmentations and ensures that the resulting augmented dataset aligns with the intended distribution of similarity scores. This guarantees that the augmented daily news sets (DNS) maintain the desired variability and semantic relationships required for effective contrastive learning.

This monitoring system plays a critical role in maintaining the integrity of the augmentation pipeline, thereby enhancing the reliability and utility of the ContraSim embedding space.


\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/nvinden_appx/sim\_scores\_for\_negative-headlines.png}
        \caption{Negated Headlines}
        \label{fig:sub1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/nvinden_appx/sim\_scores\_for\_ablation-headlines.png}
        \caption{Semantically-Shifted Headlines}
        \label{fig:sub2}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/nvinden_appx/sim\_scores\_for\_rephrased-headlines.png}
        \caption{Rephrased Headlines}
        \label{fig:sub3}
    \end{subfigure}
    \caption{Distribution of similarity scores for augmented headlines across different augmentation actions. Each histogram represents the frequency distribution of similarity scores produced by the quality monitoring system for a specific augmentation type: (a) Negated Headlines, showing a concentration of scores in the low similarity range (\([0, 0.33]\)); (b) Semantically-Shifted Headlines, with scores distributed in the mid-range (\([0.33, 0.66]\)); and (c) Rephrased Headlines, exhibiting high similarity scores (\([0.66, 1.00]\)). These distributions validate that the augmentations align with their intended semantic similarity thresholds.}
    \label{fig:global}
\end{figure}

\clearpage



\section{How Augmentation Actions Affect News Headline Similarity}\label{app:augmentation_actions}

In this section, we investigate the effects of different augmentation strategies on news headline similarity within embedding space. The goal of this experiment was to quantify how rephrasing, semantic shifts, and negations impact the embedding distances of news headlines.

We began by selecting a dataset of daily news headlines, ensuring a diverse and representative sample of financial and general news topics. For each experiment:
\begin{enumerate}
    \item \textbf{Two random days} were selected from the dataset.
    \item \textbf{A headline} from one of these days was chosen as the base headline.
    \item The chosen headline was subjected to one of the following augmentation actions using our algorithm:
        \begin{itemize}
            \item \textbf{Rephrasing (Re):} Preserves the original semantic meaning but alters the phrasing.
            \item \textbf{Semantic Shift (S):} Introduces slight changes in meaning while maintaining topic relevance.
            \item \textbf{Negation (N):} Alters the meaning to convey the opposite sentiment or direction.
        \end{itemize}
    \item The base and augmented headlines were embedded into a semantic space using a pre-trained language model fine-tuned with Weighted Self-Supervised Contrastive Learning (WSSCL).
    \item The change in embedding space distance was measured between the base and augmented headlines.
\end{enumerate}

The average shifts in embedding distances, quantified as cosine similarity changes, were as follows:
\begin{itemize}
    \item \textbf{Rephrased:} \( +0.146 \)
    \item \textbf{Semantic-Shifted:} \( +0.043 \)
    \item \textbf{Negated:} \( -0.0642 \)
\end{itemize}

\paragraph{Rephrased Headlines:} Rephrased headlines showed the largest positive shift in embedding distances (\( +0.146 \)), indicating that while the phrasing varied, the core semantic content remained highly aligned. This demonstrates that rephrasing maintains the essence of the original headline, making it the most semantically consistent transformation.

\paragraph{Semantic Shifts:} Semantic-shifted headlines exhibited a moderate positive shift (\( +0.043 \)). This suggests that while some semantic information diverged, the augmented headlines still retained a level of topical similarity to the base headline. The variability in these distances reflects the subtle nuances introduced by the algorithm.

\paragraph{Negated Headlines:} Negated headlines displayed a negative shift (\( -0.0642 \)), indicating an intentional movement away from the base headline's meaning. This highlights the algorithm's capacity to generate semantically contrasting headlines effectively. The relatively small magnitude of this shift suggests that negation preserves certain structural or contextual elements, even when the semantic intent is inverted.

The results underline the versatility and precision of our augmentation strategies:
\begin{itemize}
    \item \textbf{Rephrasing} can be leveraged for tasks requiring high semantic consistency.
    \item \textbf{Semantic Shifting} introduces controlled variability, useful for contrastive learning applications.
    \item \textbf{Negation} is effective for generating challenging counterexamples in adversarial tasks or for enhancing model robustness.
\end{itemize}

These findings validate the embedding model's sensitivity to nuanced semantic changes and demonstrate the utility of augmentation actions in crafting datasets for contrastive and supervised learning paradigms.



%

%----------------------------------------%
% FLATTENED CONTENT FROM: {ICLR-25/sections/51_appendix_embd.tex}
%----------------------------------------%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% APPENDIX: EMBEDDINGS DISCUSSION  %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%----------------------------------------%
% FLATTENED CONTENT FROM: {ICLR-25/sections/52_appendix_datasets.tex}
%----------------------------------------%

\section{Datasets}\label{app:sec:datasets}

\subsection{NIFTY-SFT Dataset}\label{app:nifty-dataset}

The \textbf{N}ews-\textbf{I}nformed \textbf{F}inancial \textbf{T}rend \textbf{Y}ield (NIFTY) dataset~\cite{fin-dataset_saqur2024nifty} is a processed and curated daily news headlines dataset for the stock (US Equities) market price movement prediction task. NIFTY is comprised of two related datasets, \href{https://huggingface.co/datasets/raeidsaqur/NIFTY}{NIFTY-LM} and \href{https://huggingface.co/datasets/raeidsaqur/nifty-rl}{NIFTY-RL}. In this section we outline the composition of the two datasets, and comment on additional details.

\paragraph{ Dataset statistics }
Table~\ref{table:NIFTY-stats} and Table~\ref{table:NIFTY-date-ranges} present pertinent statistics related to the dataset.

\setlength{\tabcolsep}{4pt} % Adjust the space between columns
\renewcommand{\arraystretch}{1.2}
\begin{table}[ht]
\centering
\begin{minipage}[t]{0.48\textwidth}
    \centering
    \caption{Statistics and breakdown of splits sizes}
    \label{table:NIFTY-stats}
    \vspace{0.5em}
    \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{lc}
    \toprule
    Category & Statistics \\
    \midrule
    Number of data points & 2111 \\
    Number of Rise/Fall/Neutral label & 558 / 433 / 1122 \\
    Train/Test/Evaluation split & 1477 / 317 / 317 \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
\end{minipage}%
\hfill
\begin{minipage}[t]{0.48\textwidth}
    \centering
    \caption{Date Ranges of news headlines in splits}
    \label{table:NIFTY-date-ranges}
    \vspace{0.5em}
    \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{lcc}
    \toprule
    Split & Num. Samples & Date range \\
    \midrule
    Train & 1477 & 2010-01-06 to 2017-06-27 \\
    Valid & 317 & 2017-06-28 to 2019-02-12 \\
    Test & 317 & 2019-02-13 to 2020-09-21 \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
\end{minipage}
\end{table}


%%%%%%%% Prompt sub-figures (1 col) %%%%%%%%
\begin{figure}[ht]
% \vskip 0.2in
\centering
    \begin{subfigure}{\columnwidth}
      \centering
      \includegraphics[width=\linewidth]{figs/nifty-query-question.pdf}
      \caption{Instruction component of a $\pi_{LM}$ policy query $x_q$.}
      \label{fig:nifty-question}
    \end{subfigure}
\vskip 0.1in
    \begin{subfigure}{\columnwidth}
      \centering
      \includegraphics[width=\linewidth]{figs/nifty-query-context.pdf}
      \caption{The market's \textbf{history} is provided as the past $t$ days of numerical statistics like the (OHLCV) price (in blue) and common technical indicators (in orange) (e.g. moving averages) data.}
      \label{fig:nifty-context}
    \end{subfigure}
\caption{Breaking down the instruction or prompt prefix, and market context components of a prompt, $x_p$.}
\label{fig:nifty-query}
\end{figure}
%%%%%%%% FIGURE END %%%%%%%%%%%%%%

\subsubsection{NIFTY-LM: SFT Fine-tuning Dataset}

The NIFTY-LM prompt dataset was created to finetune and evaluate LLMs on predicting future stock movement given previous market data and news headlines. 
The dataset was assembled by aggregating information from three distinct sources from January 6, 2010, to September 21, 2020. The compilation includes headlines from The \textbf{Wall Street Journal} and \textbf{Reuters News}, as well as market data of the \$SPY index from \textbf{Yahoo Finance}. The NIFTY-LM dataset consists of:

% \setitemize{label=\textbullet, leftmargin=*, nolistsep}
\begin{itemize}
    \item \textbf{Meta data}: Dates and data ID.
    \item \textbf{Prompt ($x_p$)}: LLM question ($x_{question}$), market data from previous days ($x_{context}$), and news headlines ($x_{news}$).
    \item \textbf{Response}: Qualitative movement label ($x_r$) $\in{} \{Rise, Fall, Neutral\}$, and percentage change of the closing price of the \$SPY index.
\end{itemize}

To generate LLM questions, ($\boldsymbol{x_{question}}$), the authors used the self-instruct \cite{wang2023selfinstruct} framework and OpenAI GPT4 to create 20 synthetic variations of the instruction below:

\begin{quote}
Create 20 variations of the instruction below. \newline
Examine the given market information and news headlines data on DATE to forecast whether the \$SPY index will rise, fall, or remain unchanged. If you think the movement will be less than 0.5\%, then return 'Neutral'. Respond with Rise, Fall, or Neutral and your reasoning in a new paragraph.
\end{quote}


Where \texttt{DATE} would be substituted later, during the training phase with a corresponding date.

\paragraph{Context} The key `context' ($\boldsymbol{x_{context}}$) was constructed to have newline delimited market metrics over the past T ($\approx$ 10) days (N.B. Not all market data for the past days for were available and therefore prompts might have less than 10 days of market metrics.). 

Table~\ref{tab:dataset_columns} show the details of financial context provided in each day's sample.
\begin{table}[h]
\centering
\caption{Summary of the dataset columns with their respective descriptions.}
\label{tab:dataset_columns}
\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Column Name}                  & \textbf{Description}                                                     \\ \midrule
Date                                  & Date of the trading session                                              \\
Opening Price                         & Stock's opening market price                                             \\
Daily High                            & Highest trading price of the day                                         \\
Daily Low                             & Lowest trading price of the day                                          \\
Closing Price                         & Stock's closing market price                                             \\
Adjusted Closing Price                & Closing price adjusted for splits and dividends                         \\
Volume                                & Total shares traded during the day                                       \\
Percentage Change                     & Day-over-day percentage change in closing price                         \\
MACD                                  & Momentum indicator showing the relationship between two moving averages \\
Bollinger Upper Band                  & Upper boundary of the Bollinger Bands, set at two standard deviations above the average \\
Bollinger Lower Band                  & Lower boundary, set at two standard deviations below the average         \\
30-Day RSI                            & Momentum oscillator measuring speed and change of price movements       \\
30-Day CCI                            & Indicator identifying cyclical trends over 30 days                      \\
30-Day DX                             & Indicates the strength of price trends over 30 days                     \\
30-Day SMA                            & Average closing price over the past 30 days                             \\
60-Day SMA                            & Average closing price over the past 60 days                             \\ \bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\paragraph{News Headlines} $\boldsymbol{(x_{news})}$: Final list of filtered headlines from the aggregation pipeline. The non-finance related headlines were filtered out by performing a similarity search with SBERT model, "all-MiniLM-L6-v2" \cite{reimers2019sentencebert}.  Each headline was compared to a set of artificially generated financial headlines generated by GPT-4, with the prompt \textit{"Generate 20 financial news headlines"}. Headlines with a similarity score below 0.2, were excluded from the dataset. 
To respect the prompting `context length' of LLMs, in instances where the prompt exceeded a length of 3000 words, a further refinement process was employed. This process involved the elimination of words with a tf-idf \cite{tfidf} score below 0.2 and truncating the prompt to a maximum of 3000 words.

It is also important to note that the dataset does not encompass all calendar dates within the specified time range. This limitation emanates from the trading calendar days, and absence of relevant financial news headlines for certain dates. 

\paragraph{Label} $\boldsymbol{(x_{r})}$: The label is determined by the percentage change in closing prices from one day to the next, as defined in equation \ref{eq:PCT}. This percentage change is categorized into three labels: \{Rise, Fall, Neutral\}, based on the thresholds specified in equation \ref{eq:label}.

\begin{equation}
    PCT_{\text{change}} = \left( \frac{\text{Closing Price}_{t} - \text{Closing Price}_{t-1}}{\text{Closing Price}_{t-1}} \right) \times 100\%
\label{eq:PCT}
\end{equation}

\begin{equation}
    x_r = 
    \begin{cases}
        \text{Fall} & \text{if } PCT_{\text{change}} < -0.5\% \\
        \text{Neutral} & \text{if } -0.5\% \leq PCT_{\text{change}} \leq 0.5\% \\
        \text{Rise} & \text{if } PCT_{\text{change}} > 0.5\%
    \end{cases}
\label{eq:label}
\end{equation}

\subsection{BigData22 Dataset}

The BigData22 dataset is a comprehensive collection of financial tweets compiled between July 2019 and June 2020, designed to analyze the correlation between social media sentiment and financial market movements. It includes over 272,000 tweets distributed across 7,164 distinct trading days. Each tweet is annotated with one of two market movement labels: \textit{Fall} or \textit{Rise}, based on the performance of financial indices on the corresponding day.

BigData22 provides a unique perspective on market sentiment by focusing exclusively on social media platforms, contrasting with datasets like NIFTY-SFT that rely on curated headlines from reputable financial news outlets. While the reliance on social media introduces a higher degree of noise, it also brings diversity and real-time sentiment shifts into the dataset. This makes it an excellent benchmark for evaluating the robustness and adaptability of models like ContraSim, particularly in handling noisy, unstructured data with high variability.

Additionally, the dataset includes metadata such as timestamps and tweet authors, allowing researchers to explore temporal trends and user-specific sentiment biases. This temporal richness is especially valuable for studying dynamic sentiment patterns in financial contexts and assessing model performance in capturing short-term fluctuations influenced by social media activity.

\subsection{IMDB Reviews Dataset}

The IMDB Reviews dataset is a widely used benchmark for sentiment analysis tasks, comprising 50,000 movie reviews, each accompanied by a sentiment score ranging from 0 to 10. The reviews are equally divided into training and testing sets, ensuring a balanced evaluation of model performance. For this project, the sentiment scores are grouped into three categories: \textit{Low} (0.0-5.5), \textit{Medium} (5.6-7.5), and \textit{High} (7.6-10.0), creating a classification task to predict the overall sentiment of a review.

This dataset is particularly valuable for testing the generalizability of ContraSim beyond financial forecasting. Unlike financial datasets, which often feature structured news or market data, the IMDB dataset focuses on user-generated content with a wide range of writing styles and subjective expressions. By evaluating ContraSim on this dataset, we can assess its ability to adapt to orthogonal tasks, such as opinion mining and sentiment classification, that require capturing nuanced semantic relationships in text.

The diversity in review content, ranging from casual remarks to in-depth critiques, challenges the model to effectively distinguish between sentiment categories. This provides insights into ContraSim's capability to learn and represent global semantic structures across domains, making it a valuable tool for applications extending beyond finance, such as media analytics and customer feedback analysis.


\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% DOCUMENT END   %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}
