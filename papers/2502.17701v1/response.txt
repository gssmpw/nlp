\section{Related Work}
\vspace{-0.2cm}

\subsection{Wildfire Evacuation Decision Prediction}
\vspace{-0.2cm}
Recent research has employed multiple methods to predict wildfire evacuation decisions.
Bhaduri, "A latent class approach for predicting diverse wildfire evacuation decisions in three U.S. fire-prone counties"__Shrestha, "Predicting risk perception, evacuation decision, and delay time using logistic and linear regression"
Kulig, "Benchmarking machine learning approaches for predicting wildfire evacuation behavior: A case study of the 2019 Kincade Fire"__Rorigueras, "The Wildfire Decision Model (WDM) calibrated via Hybrid Choice Models (HCM): Incorporating latent factors like risk perception and prior experience"
Papathansiou, "Integrating risk perception and threat assessment as latent variables into an HCM framework for more accurate wildfire evacuation decision predictions"__Kulig, "A hybrid choice model approach to predict wildfire evacuation decisions in three U.S. fire-prone counties"

\vspace{-0.2cm}
\subsection{LLMs for Human Decision and Behavior Prediction}
\vspace{-0.2cm}
Current work increasingly leverages LLMs to model and predict human decisions. 
BigToM, "Evaluating Large Language Models' Theory-of-Mind (ToM) reasoning via causal templates"__SUVA, "Probabilistic modeling and behavioral economics games for understanding prosocial and group-identity effects in LLMs"
DEBATunE, "A multi-agent debate process for data synthesis on controversial debate topics using supervised fine-tuning to simulate behaviors"__ToM, "Open-ended social reasoning from Reddit's ChangeMyView posts: Prompt tuning with human intentions and emotions boosts performance"
T4D, "Converting mental state inferences into strategic action in LLMs: The challenge of structured guidance"__LELMA, "Integrating symbolic AI to verify logical consistency in social simulations like the Prisonerâ€™s Dilemma using self-refinement methods"
SimpleToM, "Deliberate prompting for accurate moral or behavioral judgments in LLMs: A critical evaluation"__Shenoy, "The Value Injection Method (VIM): Embedding human core values to enhance opinion and choice prediction in LLMs"
Zhang, "Instruction tuning and prompting do not inherently offer better alignment with human cognition than direct probability outputs from base LLMs"__Sreedhar et al., "Multi-agent configurations in the Ultimatum Game: Negotiation leads to more human-like strategic reasoning in LLMs"
Puri, "Arithmetic-trained LLMs surpass classic decision-theoretic models when evaluating risky and time-delayed choices"__Bhattacharya, "A core limitation of LLMs: Systematically assuming people behave more rationally than they do, underestimating well-documented human biases"