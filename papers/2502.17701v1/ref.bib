% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@misc{zhou2023farlargelanguagemodels,
      title={How FaR Are Large Language Models From Agents with Theory-of-Mind?}, 
      author={Pei Zhou and Aman Madaan and Srividya Pranavi Potharaju and Aditya Gupta and Kevin R. McKee and Ari Holtzman and Jay Pujara and Xiang Ren and Swaroop Mishra and Aida Nematzadeh and Shyam Upadhyay and Manaal Faruqui},
      year={2023},
      eprint={2310.03051},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.03051}, 
}

@article{KULIGOWSKI2022105541,
title = {Modeling evacuation decisions in the 2019 Kincade fire in California},
journal = {Safety Science},
volume = {146},
pages = {105541},
year = {2022},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105541},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521003842},
author = {Erica D. Kuligowski and Xilei Zhao and Ruggiero Lovreglio and Ningzhe Xu and Kaitai Yang and Aaron Westbury and Daniel Nilsson and Nancy Brown},
keywords = {Wildfires, Evacuation, Egress modeling, Decision-making, WUI, Bushfires},
abstract = {}
}

@article{FORRISTER2024100729,
title = {Analyzing Risk Perception, Evacuation Decision and Delay Time: A Case Study of the 2021 Marshall Fire in Colorado},
journal = {Travel Behaviour and Society},
volume = {35},
pages = {100729},
year = {2024},
issn = {2214-367X},
doi = {https://doi.org/10.1016/j.tbs.2023.100729},
url = {https://www.sciencedirect.com/science/article/pii/S2214367X23001801},
author = {Ana Forrister and Erica D. Kuligowski and Yuran Sun and Xiang Yan and Ruggiero Lovreglio and Thomas J. Cova and Xilei Zhao},
keywords = {Wildfires, Evacuation, Decision-making, WUI, Bushfires, Delay Time},
abstract = {}
}

@misc{zhang2024personalizationlargelanguagemodels,
      title={Personalization of Large Language Models: A Survey}, 
      author={Zhehao Zhang and Ryan A. Rossi and Branislav Kveton and Yijia Shao and Diyi Yang and Hamed Zamani and Franck Dernoncourt and Joe Barrow and Tong Yu and Sungchul Kim and Ruiyi Zhang and Jiuxiang Gu and Tyler Derr and Hongjie Chen and Junda Wu and Xiang Chen and Zichao Wang and Subrata Mitra and Nedim Lipka and Nesreen Ahmed and Yu Wang},
      year={2024},
      eprint={2411.00027},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.00027}, 
}

@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{mccaffrey2018should,
  title={Should I stay or should I go now? Or should I wait and see? Influences on wildfire evacuation decisions},
  author={McCaffrey, Sarah and Wilson, Robyn and Konar, Avishek},
  journal={Risk analysis},
  volume={38},
  number={7},
  pages={1390--1404},
  year={2018},
  publisher={Wiley Online Library}
}

@article{stasiewicz2021preparing,
  title={Preparing for wildfire evacuation and alternatives: Exploring influences on residents’ intended evacuation behaviors and mitigations},
  author={Stasiewicz, Amanda M and Paveglio, Travis B},
  journal={International Journal of Disaster Risk Reduction},
  volume={58},
  pages={102177},
  year={2021},
  publisher={Elsevier}
}

@article{lindell2012protective,
  title={The protective action decision model: Theoretical modifications and additional evidence},
  author={Lindell, Michael K and Perry, Ronald W},
  journal={Risk Analysis: An International Journal},
  volume={32},
  number={4},
  pages={616--632},
  year={2012},
  publisher={Wiley Online Library}
}

@article{sun4953233investigating,
  title={Investigating wildfire evacuation decisions using hybrid choice modeling},
  author={Sun, Yuran and Lovreglio, Ruggiero and Kuligowski, Erica and Morrison, Rosie and Cova, Thomas and Zhao, Xilei},
  journal={Available at SSRN 4953233},
  year={2024},
}

@article{lovreglio2020calibrating,
  title={Calibrating the Wildfire Decision Model using hybrid choice modelling},
  author={Lovreglio, Ruggiero and Kuligowski, Erica and Walpole, Emily and Link, Eric and Gwynne, Steve},
  journal={International Journal of Disaster Risk Reduction},
  volume={50},
  pages={101770},
  year={2020},
  publisher={Elsevier}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wong2020review,
  title={Review of California wildfire evacuations from 2017 to 2019},
  author={Wong, Stephen D and Broader, Jacquelyn C and Shaheen, Susan A},
  year={2020}
}

@article{kuligowski2022modeling,
  title={Modeling evacuation decisions in the 2019 Kincade fire in California},
  author={Kuligowski, Erica D and Zhao, Xilei and Lovreglio, Ruggiero and Xu, Ningzhe and Yang, Kaitai and Westbury, Aaron and Nilsson, Daniel and Brown, Nancy},
  journal={Safety science},
  volume={146},
  pages={105541},
  year={2022},
  publisher={Elsevier}
}

@article{forrister2024analyzing,
  title={Analyzing risk perception, evacuation decision and delay time: a case study of the 2021 Marshall Fire in Colorado},
  author={Forrister, Ana and Kuligowski, Erica D and Sun, Yuran and Yan, Xiang and Lovreglio, Ruggiero and Cova, Thomas J and Zhao, Xilei},
  journal={Travel behaviour and society},
  volume={35},
  pages={100729},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{topsakal2023creating,
  title={Creating large language model applications utilizing langchain: A primer on developing llm apps fast},
  author={Topsakal, Oguzhan and Akinci, Tahir Cetin},
  booktitle={International Conference on Applied Engineering and Natural Sciences},
  volume={1},
  number={1},
  pages={1050--1056},
  year={2023}
}

@article{mcgee2019residents,
  title={Residents’ wildfire evacuation actions in Mishkeegogamang Ojibway Nation, Ontario, Canada},
  author={McGee, Tara K and Nation, Mishkeegogamang Ojibway and Christianson, Amy Cardinal},
  journal={International journal of disaster risk reduction},
  volume={33},
  pages={266--274},
  year={2019},
  publisher={Elsevier}
}

@article{edgeley2019exploring,
  title={Exploring influences on intended evacuation behaviors during wildfire: What roles for pre-fire actions and event-based cues?},
  author={Edgeley, Catrin M and Paveglio, Travis B},
  journal={International journal of disaster risk reduction},
  volume={37},
  pages={101182},
  year={2019},
  publisher={Elsevier}
}

@article{naushirvanov2024evacuation,
  title={Evacuation patterns and socioeconomic stratification in the context of wildfires in Chile},
  author={Naushirvanov, Timur and Elejalde, Erick and Kalimeri, Kyriaki and Omodei, Elisa and Karsai, M{\'a}rton and Ferres, Leo},
  journal={arXiv preprint arXiv:2410.06017},
  year={2024}
}

@article{gandhi2024understanding,
  title={Understanding social reasoning in language models with language models},
  author={Gandhi, Kanishk and Fr{\"a}nken, Jan-Philipp and Gerstenberg, Tobias and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{leng2023llm,
  title={Do LLM Agents Exhibit Social Behavior?},
  author={Leng, Yan and Yuan, Yuan},
  journal={arXiv preprint arXiv:2312.15198},
  year={2023}
}

@article{liu2024exploring,
  title={Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View},
  author={Liu, Xuan and Zhang, Jie and Guo, Song and Shang, Haoyang and Yang, Chengxu and Zhu, Quanyan},
  journal={arXiv preprint arXiv:2405.14744},
  year={2024}
}

@article{amirizaniani2024llms,
  title={Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses},
  author={Amirizaniani, Maryam and Martin, Elias and Sivachenko, Maryna and Mashhadi, Afra and Shah, Chirag},
  journal={arXiv preprint arXiv:2406.05659},
  year={2024}
}

@article{mensfelt2024logic,
  title={Logic-enhanced language model agents for trustworthy social simulations},
  author={Mensfelt, Agnieszka and Stathis, Kostas and Trencsenyi, Vince},
  journal={arXiv preprint arXiv:2408.16081},
  year={2024}
}

@article{zhou2023far,
  title={How FaR Are Large Language Models From Agents with Theory-of-Mind?},
  author={Zhou, Pei and Madaan, Aman and Potharaju, Srividya Pranavi and Gupta, Aditya and McKee, Kevin R and Holtzman, Ari and Pujara, Jay and Ren, Xiang and Mishra, Swaroop and Nematzadeh, Aida and others},
  journal={arXiv preprint arXiv:2310.03051},
  year={2023}
}

@article{gu2024simpletom,
  title={SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs},
  author={Gu, Yuling and Tafjord, Oyvind and Kim, Hyunwoo and Moore, Jared and Bras, Ronan Le and Clark, Peter and Choi, Yejin},
  journal={arXiv preprint arXiv:2410.13648},
  year={2024}
}

@article{zahura2024impact,
  title={Impact of topography and climate on post-fire vegetation recovery across different burn severity and land cover types through random forest},
  author={Zahura, Faria Tuz and Bisht, Gautam and Li, Zhi and McKnight, Sarah and Chen, Xingyuan},
  journal={Ecological Informatics},
  volume={82},
  pages={102757},
  year={2024},
  publisher={Elsevier}
}

@article{jain2020review,
  title={A review of machine learning applications in wildfire science and management},
  author={Jain, Piyush and Coogan, Sean CP and Subramanian, Sriram Ganapathi and Crowley, Mark and Taylor, Steve and Flannigan, Mike D},
  journal={Environmental Reviews},
  volume={28},
  number={4},
  pages={478--505},
  year={2020},
  publisher={NRC Research Press 1840 Woodward Drive, Suite 1, Ottawa, ON K2C 0P7}
}

@article{fan2024explainable,
  title={Explainable AI Integrated Feature Engineering for Wildfire Prediction},
  author={Fan, Di and Biswas, Ayan and Ahrens, James Paul},
  journal={arXiv preprint arXiv:2404.01487},
  year={2024}
}

@article{ustek2024deep,
  title={Deep autoencoders for unsupervised anomaly detection in wildfire prediction},
  author={{\"U}stek, {\.I}rem and Arana-Catania, Miguel and Farr, Alexander and Petrunin, Ivan},
  journal={Earth and Space Science},
  volume={11},
  number={11},
  pages={e2024EA003997},
  year={2024},
  publisher={Wiley Online Library}
}


@article{tapley2023reinforcement,
  title={Reinforcement Learning for Wildfire Mitigation in Simulated Disaster Environments},
  author={Tapley, Alexander and Dotter, Marissa and Doyle, Michael and Fennelly, Aidan and Gandikota, Dhanuj and Smith, Savanna and Threet, Michael and Welsh, Tim},
  journal={arXiv preprint arXiv:2311.15925},
  year={2023}
}

@article{mockrin2018does,
  title={Does wildfire open a policy window? Local government and community adaptation after fire in the United States},
  author={Mockrin, Miranda H and Fishler, Hillary K and Stewart, Susan I},
  journal={Environmental management},
  volume={62},
  pages={210--228},
  year={2018},
  publisher={Springer}
}

@article{momin2024community,
  title={Community-based Behavioral Understanding of Crisis Activity Concerns using Social Media Data: A Study on the 2023 Canadian Wildfires in New York City},
  author={Momin, Khondhaker Al and Hasnine, Md Sami and Sadri, Arif Mohaimin},
  journal={arXiv preprint arXiv:2402.01683},
  year={2024}
}

@article{arora2023language,
  title={Language models enable simple systems for generating structured views of heterogeneous data lakes},
  author={Arora, Simran and Yang, Brandon and Eyuboglu, Sabri and Narayan, Avanika and Hojel, Andrew and Trummer, Immanuel and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2304.09433},
  year={2023}
}

@article{fang2024large,
  title={Large language models (LLMs) on tabular data: Prediction, generation, and understanding-a survey},
  author={Fang, Xi and Xu, Weijie and Tan, Fiona Anting and Zhang, Jiani and Hu, Ziqing and Qi, Yanjun Jane and Nickleach, Scott and Socolinsky, Diego and Sengamedu, Srinivasan and Faloutsos, Christos and others},
  year={2024}
}

@article{jha2024characterizing,
  title={Characterizing prompt compression methods for long context inference},
  author={Jha, Siddharth and Erdogan, Lutfi Eren and Kim, Sehoon and Keutzer, Kurt and Gholami, Amir},
  journal={arXiv preprint arXiv:2407.08892},
  year={2024}
}

@article{fei2025efficient,
  title={Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference},
  author={Fei, Weizhi and Niu, Xueyan and Xie, Guoqing and Liu, Yingqing and Bai, Bo and Han, Wei},
  journal={arXiv preprint arXiv:2501.12959},
  year={2025}
}

@inproceedings{xu-etal-2024-opentom,
    title = "{O}pen{T}o{M}: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models",
    author = "Xu, Hainiu  and
      Zhao, Runcong  and
      Zhu, Lixing  and
      Du, Jinhua  and
      He, Yulan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.466/",
    doi = "10.18653/v1/2024.acl-long.466",
    pages = "8593--8623",
    abstract = "Neural Theory-of-Mind (N-ToM), machine`s ability to understand and keep track of the mental states of others, is pivotal in developing socially intelligent agents. However, prevalent N-ToM benchmarks have several shortcomings, including the presence of ambiguous and artificial narratives, absence of personality traits and preferences, a lack of questions addressing characters' psychological mental states, and limited diversity in the questions posed. In response to these issues, we construct OpenToM, a new benchmark for assessing N-ToM with (1) longer and clearer narrative stories, (2) characters with explicit personality traits, (3) actions that are triggered by character intentions, and (4) questions designed to challenge LLMs' capabilities of modeling characters' mental states of both the physical and psychological world. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling certain aspects of mental states in the physical world but fall short when tracking characters' mental states in the psychological world."
}

@inproceedings{wu-etal-2023-hi,
    title = "Hi-{T}o{M}: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models",
    author = "Wu, Yufan  and
      He, Yinghui  and
      Jia, Yilin  and
      Mihalcea, Rada  and
      Chen, Yulong  and
      Deng, Naihao",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.717/",
    doi = "10.18653/v1/2023.findings-emnlp.717",
    pages = "10691--10706",
    abstract = "Theory of Mind (ToM) is the ability to reason about one`s own and others' mental states. ToM plays a critical role in the development of intelligence, language understanding, and cognitive processes. While previous work has primarily focused on first and second-order ToM, we explore higher-order ToM, which involves recursive reasoning on others' beliefs. {\%}We also incorporate a new deception mechanism in ToM reasoning. We introduce Hi-ToM, a Higher Order Theory of Mind benchmark. Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs. We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP."
}

@article{zhang2024personalization,
  title={Personalization of large language models: A survey},
  author={Zhang, Zhehao and Rossi, Ryan A and Kveton, Branislav and Shao, Yijia and Yang, Diyi and Zamani, Hamed and Dernoncourt, Franck and Barrow, Joe and Yu, Tong and Kim, Sungchul and others},
  journal={arXiv preprint arXiv:2411.00027},
  year={2024}
}

@article{jang2023personalized,
  title={Personalized soups: Personalized large language model alignment via post-hoc parameter merging},
  author={Jang, Joel and Kim, Seungone and Lin, Bill Yuchen and Wang, Yizhong and Hessel, Jack and Zettlemoyer, Luke and Hajishirzi, Hannaneh and Choi, Yejin and Ammanabrolu, Prithviraj},
  journal={arXiv preprint arXiv:2310.11564},
  year={2023}
}

@inproceedings{nguyen2024predicting,
  title={Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning},
  author={Nguyen, Thuy Ngoc and Jamale, Kasturi and Gonzalez, Cleotilde},
  booktitle={Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  volume={12},
  pages={126--136},
  year={2024}
}

@article{liu2024large,
  title={Large language models assume people are more rational than we really are},
  author={Liu, Ryan and Geng, Jiayi and Peterson, Joshua C and Sucholutsky, Ilia and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2406.17055},
  year={2024}
}

@article{lee2024reasoning,
  title={Reasoning abilities of large language models: In-depth analysis on the abstraction and reasoning corpus},
  author={Lee, Seungpil and Sim, Woochang and Shin, Donghyeon and Seo, Wongyu and Park, Jiwon and Lee, Seokki and Hwang, Sanha and Kim, Sejin and Kim, Sundong},
  journal={ACM Transactions on Intelligent Systems and Technology},
  year={2024},
  publisher={ACM New York, NY}
}

@article{huang2022towards,
  title={Towards reasoning in large language models: A survey},
  author={Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2212.10403},
  year={2022}
}

@article{hu2024quantifying,
  title={Quantifying the persona effect in llm simulations},
  author={Hu, Tiancheng and Collier, Nigel},
  journal={arXiv preprint arXiv:2402.10811},
  year={2024}
}

@article{upadhayay2024cognitive,
  title={Cognitive overload attack: Prompt injection for long context},
  author={Upadhayay, Bibek and Behzadan, Vahid and Karbasi, Amin},
  journal={arXiv preprint arXiv:2410.11272},
  year={2024}
}

@misc{Anthropic2024,
  author       = {Anthropic},
  year         = {2024},
  title        = {Claude 3.5 sonnet},
  howpublished = {\url{https://www.anthropic.com/news/}}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@misc{OpenAI2025,
  author       = {OpenAI},
  year         = {2025},
  title        = {OpenAI o3-mini},
  howpublished = {\url{https://openai.com/index/openai-o3-mini/}}
}

@misc{schleuss2018carrfiremap,
  author       = {Jon Schleuss and Kyle Kim and Priya Krishnakumar},
  title        = {Here’s where the Carr fire destroyed homes in Northern California},
  year         = {2018},
  url          = {https://www.latimes.com/projects/la-me-carr-fire-map/},
}

@article{moser2024understanding,
  title={Understanding threat appraisal and protective action concerning forest fires in low-exposure regions: an application of the protective action decision model},
  author={Moser, Stephanie and Kearney, Norman and Michel, Fabian and Valerius, Karsten and Liechti, Karina},
  journal={Journal of Risk Research},
  pages={1--25},
  year={2024},
  publisher={Taylor \& Francis}
}

@article{SUN2024106557,
title = {Social vulnerabilities and wildfire evacuations: A case study of the 2019 Kincade fire},
journal = {Safety Science},
volume = {176},
pages = {106557},
year = {2024},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2024.106557},
url = {https://www.sciencedirect.com/science/article/pii/S0925753524001474},
author = {Yuran Sun and Ana Forrister and Erica D. Kuligowski and Ruggiero Lovreglio and Thomas J. Cova and Xilei Zhao},
}

@misc{nbcnews_california_wildfires_2025,
    author = {Tim Stelloh and Marlene Lenthang and Rebecca Cohen and Phil Helsel},
    title = {California wildfires: What we know about L.A.-area fires, what caused them, who is affected and more},
    year = {2025},
    url = {https://www.nbcnews.com/news/us-news/california-wildfires-what-we-know-palisades-eaton-los-angeles-rcna188239},
    note = {Accessed: 2025-02-11}
}


@inproceedings{park2024rlhf,
  title={Rlhf from heterogeneous feedback via personalization and preference aggregation},
  author={Park, Chanwoo and Liu, Mingyang and Kong, Dingwen and Zhang, Kaiqing and Ozdaglar, Asuman E},
  booktitle={ICML 2024 Workshop: Aligning Reinforcement Learning Experimentalists and Theorists},
  year={2024}
}

@inproceedings{kang-etal-2023-values,
    title = "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
    author = "Kang, Dongjun  and
      Park, Joonsuk  and
      Jo, Yohan  and
      Bak, JinYeong",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.961/",
    doi = "10.18653/v1/2023.emnlp-main.961",
    pages = "15539--15559"
}

@inproceedings{kuribayashi-etal-2024-psychometric,
    title = "Psychometric Predictive Power of Large Language Models",
    author = "Kuribayashi, Tatsuki  and
      Oseki, Yohei  and
      Baldwin, Timothy",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.129/",
    doi = "10.18653/v1/2024.findings-naacl.129",
    pages = "1983--2005"
}

@article{sreedhar2025simulating,
  title={Simulating Strategic Reasoning: Comparing the Ability of Single LLMs and Multi-Agent Systems to Replicate Human Behavior},
  author={Sreedhar, Karthik and Chilton, Lydia},
  year={2025}
}

@article{zhu2024language,
  title={Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice},
  author={Zhu, Jian-Qiao and Yan, Haijiang and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2405.19313},
  year={2024}
}

@article{sun2024social,
  title={Social vulnerabilities and wildfire evacuations: A case study of the 2019 Kincade fire},
  author={Sun, Yuran and Forrister, Ana and Kuligowski, Erica D and Lovreglio, Ruggiero and Cova, Thomas J and Zhao, Xilei},
  journal={Safety Science},
  volume={176},
  pages={106557},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{einstein2022prioritizing,
  title={Prioritizing emergency evacuations under compounding levels of uncertainty},
  author={Einstein, Lisa J and Moss, Robert J and Kochenderfer, Mykel J},
  booktitle={2022 IEEE Global Humanitarian Technology Conference (GHTC)},
  pages={265--272},
  year={2022},
  organization={IEEE}
}

@book{collins2018evacuation,
  title={Evacuation behavior measured during an evacuation order: an assessment of the effects of social connections on the decision to evacuate},
  author={Collins, Jennifer and Ersing, Robin L and Polen, Amy and Saunders, Michelle},
  year={2018},
  publisher={Natural Hazards Center}
}

@article{hong2020modeling,
  title={Modeling and predicting evacuation flows during hurricane Irma},
  author={Hong, Lingzi and Frias-Martinez, Vanessa},
  journal={EPJ Data Science},
  volume={9},
  number={1},
  pages={29},
  year={2020},
  publisher={Springer Berlin Heidelberg}
}

@article{xu2023predicting,
  title={Predicting and assessing wildfire evacuation decision-making using machine learning: Findings from the 2019 kincade fire},
  author={Xu, Ningzhe and Lovreglio, Ruggiero and Kuligowski, Erica D and Cova, Thomas J and Nilsson, Daniel and Zhao, Xilei},
  journal={Fire Technology},
  volume={59},
  number={2},
  pages={793--825},
  year={2023},
  publisher={Springer}
}

@article{petrov2024limited,
  title={Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis},
  author={Petrov, Nikolay B and Serapio-Garc{\'\i}a, Gregory and Rentfrow, Jason},
  journal={arXiv preprint arXiv:2405.07248},
  year={2024}
}

@article{tjuatja2023llms,
  title={Do LLMs exhibit human-like response biases? A case study in survey design},
  author={Tjuatja, Lindia and Chen, Valerie and Wu, Sherry Tongshuang and Talwalkar, Ameet and Neubig, Graham},
  journal={arXiv preprint arXiv:2311.04076},
  year={2023}
}

@article{macmillan2024ir,
  title={(Ir) rationality and cognitive biases in large language models},
  author={Macmillan-Scott, Olivia and Musolesi, Mirco},
  journal={Royal Society Open Science},
  volume={11},
  number={6},
  pages={240255},
  year={2024},
  publisher={The Royal Society}
}

@article{zhao2022estimating,
  title={Estimating wildfire evacuation decision and departure timing using large-scale GPS data},
  author={Zhao, Xilei and Xu, Yiming and Lovreglio, Ruggiero and Kuligowski, Erica and Nilsson, Daniel and Cova, Thomas J and Wu, Alex and Yan, Xiang},
  journal={Transportation research part D: transport and environment},
  volume={107},
  pages={103277},
  year={2022},
  publisher={Elsevier}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{renze2024self,
  title={Self-Reflection in LLM Agents: Effects on Problem-Solving Performance},
  author={Renze, Matthew and Guven, Erhan},
  journal={arXiv preprint arXiv:2405.06682},
  year={2024}
}

@article{li2024hindsight,
  title={When hindsight is not 20/20: Testing limits on reflective thinking in large language models},
  author={Li, Yanhong and Yang, Chenghao and Ettinger, Allyson},
  journal={arXiv preprint arXiv:2404.09129},
  year={2024}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{levy2024tasktokensimpactinput,
      title={Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models}, 
      author={Mosh Levy and Alon Jacoby and Yoav Goldberg},
      year={2024},
      eprint={2402.14848},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.14848}, 
}

@misc{li2024longcontextllmsstrugglelong,
      title={Long-context LLMs Struggle with Long In-context Learning}, 
      author={Tianle Li and Ge Zhang and Quy Duc Do and Xiang Yue and Wenhu Chen},
      year={2024},
      eprint={2404.02060},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.02060}, 
}

@misc{qian2024longllmsnecessitylongcontexttasks,
      title={Are Long-LLMs A Necessity For Long-Context Tasks?}, 
      author={Hongjin Qian and Zheng Liu and Peitian Zhang and Kelong Mao and Yujia Zhou and Xu Chen and Zhicheng Dou},
      year={2024},
      eprint={2405.15318},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.15318}, 
}

@article{qin2024large,
  title={Large language models meet nlp: A survey},
  author={Qin, Libo and Chen, Qiguang and Feng, Xiachong and Wu, Yang and Zhang, Yongheng and Li, Yinghui and Li, Min and Che, Wanxiang and Yu, Philip S},
  journal={arXiv preprint arXiv:2405.12819},
  year={2024}
}

@article{xie2011values,
  title={Values and limitations of statistical models},
  author={Xie, Yu},
  journal={Research in social stratification and mobility},
  volume={29},
  number={3},
  pages={343--349},
  year={2011},
  publisher={Elsevier}
}

@article{turpin2023language,
  title={Language models don't always say what they think: Unfaithful explanations in chain-of-thought prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={74952--74965},
  year={2023}
}

@article{strahan2019protective,
  title={The protective action decision model: When householders choose their protective response to wildfire},
  author={Strahan, Ken and Watson, Stuart J},
  journal={Journal of Risk Research},
  volume={22},
  number={12},
  pages={1602--1623},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{santana2021psychological,
  title={Psychological factors and social processes influencing wildfire smoke protective behavior: Insights from a case study in Northern California},
  author={Santana, Francisca N and Gonzalez, David JX and Wong-Parodi, Gabrielle},
  journal={Climate Risk Management},
  volume={34},
  pages={100351},
  year={2021},
  publisher={Elsevier}
}

@article{lovreglio2019modelling,
  title={A modelling framework for householder decision-making for wildfire emergencies},
  author={Lovreglio, Ruggiero and Kuligowski, Erica and Gwynne, Steve and Strahan, Ken},
  journal={International Journal of Disaster Risk Reduction},
  volume={41},
  pages={101274},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{li2023reflectiontuning,
  title={Reflection-Tuning: Recycling Data for Better Instruction-Tuning},
  author={Ming Li and Lichang Chen and Jiuhai Chen and Shwai He and Tianyi Zhou},
  booktitle={NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following},
  year={2023},
  url={https://openreview.net/forum?id=xaqoZZqkPU}
}

@inproceedings{li-etal-2024-selective,
    title = "Selective Reflection-Tuning: Student-Selected Data Recycling for {LLM} Instruction-Tuning",
    author = "Li, Ming  and
      Chen, Lichang  and
      Chen, Jiuhai  and
      He, Shwai  and
      Gu, Jiuxiang  and
      Zhou, Tianyi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.958",
    pages = "16189--16211",
}

@misc{xu2024surveyknowledgedistillationlarge,
      title={A Survey on Knowledge Distillation of Large Language Models}, 
      author={Xiaohan Xu and Ming Li and Chongyang Tao and Tao Shen and Reynold Cheng and Jinyang Li and Can Xu and Dacheng Tao and Tianyi Zhou},
      year={2024},
      eprint={2402.13116},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13116}, 
}

@misc{sun2023aligninglargemultimodalmodels,
      title={Aligning Large Multimodal Models with Factually Augmented RLHF}, 
      author={Zhiqing Sun and Sheng Shen and Shengcao Cao and Haotian Liu and Chunyuan Li and Yikang Shen and Chuang Gan and Liang-Yan Gui and Yu-Xiong Wang and Yiming Yang and Kurt Keutzer and Trevor Darrell},
      year={2023},
      eprint={2309.14525},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.14525}, 
}

@misc{Kuligowski2021,
  author       = {Kuligowski, Erica D. and Lovreglio, Ruggiero and Zhao, Xilei and Yan, Xiang and Cova, Thomas J. and Nilsson, Daniel},
  title        = {2021 Marshall Fire Evacuation Household Survey},
  year         = {2021},
  howpublished = {\url{https://github.com/EvacuationBehavior/2021-Marshall-Fire-Survey-Study/blob/main/2021%20Marshall%20Fire%20Evacuation%20Household%20Survey.pdf}},
  note         = {Accessed: 2025-02-15}
}

@inproceedings{li-etal-2024-llms-speak,
    title = "Can {LLM}s Speak For Diverse People? Tuning {LLM}s via Debate to Generate Controllable Controversial Statements",
    author = "Li, Ming  and
      Chen, Jiuhai  and
      Chen, Lichang  and
      Zhou, Tianyi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.956",
    pages = "16160--16176",
}

@article{li2024happened,
  title={What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective},
  author={Li, Ming and Li, Yanhong and Zhou, Tianyi},
  journal={arXiv preprint arXiv:2410.23743},
  year={2024}
}

@inproceedings{li-etal-2024-quantity,
    title = "From Quantity to Quality: Boosting {LLM} Performance with Self-Guided Data Selection for Instruction Tuning",
    author = "Li, Ming  and
      Zhang, Yong  and
      Li, Zhitao  and
      Chen, Jiuhai  and
      Chen, Lichang  and
      Cheng, Ning  and
      Wang, Jianzong  and
      Zhou, Tianyi  and
      Xiao, Jing",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.421",
    pages = "7595--7628",
}

@inproceedings{li-etal-2024-superfiltering,
    title = "Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning",
    author = "Li, Ming  and
      Zhang, Yong  and
      He, Shwai  and
      Li, Zhitao  and
      Zhao, Hongyu  and
      Wang, Jianzong  and
      Cheng, Ning  and
      Zhou, Tianyi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.769",
    pages = "14255--14273",
}
