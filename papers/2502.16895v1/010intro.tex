
Analogy facilitates the comprehension of complex concepts by associating them with familiar ones~\cite{gentner_structure_1997,davies_analogy_1985,gentner_computational_2011,mitchell_abstraction_2021}. 
%It plays a crucial role across various fields, enhancing creativity~\cite{holyoak_mental_1996,goel_design_1997,kao_how_2020}, aiding communication~\cite{casarett_can_2010,galesic_using_2013}, and particularly in education~\cite{vendetti_analogical_2015, thagard_analogy_1992, richland_analogy_2015,treagust_science_1992, gray_teaching_2021, oliva_teaching_2007}.
It plays a crucial role across various domains, particularly in education, science and problem-solving~\cite{vendetti_analogical_2015, thagard_analogy_1992, richland_analogy_2015,treagust_science_1992, gray_teaching_2021, oliva_teaching_2007}. 
It enhances cognitive processes such as creativity~\cite{holyoak_mental_1996,goel_design_1997,kao_how_2020}, aids in effective communication~\cite{casarett_can_2010,galesic_using_2013}, and facilitates the learning and understanding of complex concepts.
Analogies, such as ``water waves'' for ``light waves'', ``the solar system'' for ``atomic structure'', and ``hydraulic pump'' for ``heart'' are frequently employed in textbooks and classroom teaching to assist students in understanding scientific concepts.
Analogies can boost student understanding of concepts by opening new perspectives, making abstract ideas more relatable by connecting them to familiar situations, assisting in visualizing these concepts, sparking studentsâ€™ interest and motivation, and taking into account their previous knowledge to reveal any misconceptions~\cite{duit1991role}.
 
The rapid advancement of Large Language Models (LLMs) has led researchers to employ these models in generating analogies that enhance concept comprehension~\cite{openai_gpt-4_2023}.
%Unlike language models (LMs) that primarily address word-pairing analogies (\eg, ``king is to man as queen is to woman'')~\cite{mikolov_linguistic_2013,boteanu_solving_2015,gladkova_analogy-based_2016,chen_e-kar_2022}, LLMs are capable of creating more complex, free-form natural language analogies~\cite{bhavya_analogy_2022}.
Unlike smaller language models (LMs), such as BERT~\cite{devlin-etal-2019-bert} and GPT-2~\cite{radford2019language}, that primarily address word-pairing analogies (\eg, ``king is to man as queen is to woman'')~\cite{mikolov_linguistic_2013,boteanu_solving_2015,gladkova_analogy-based_2016,chen_e-kar_2022}, LLMs are capable of creating more complex, free-form natural language analogies~\cite{bhavya_analogy_2022}.
In specific use cases, for example, researchers have explored using LLMs to generate biologically inspired analogies to foster scientific ideation~\cite{kang_biospark_2024} and to transform abstract data into vivid data analogies that enhance the understanding of readers~\cite{chen_beyond_2024}.


%Initial research has explored using LLMs in education to assist students and teachers by generating concept-related analogies~\cite{bhavya2024analego}.
Initial research has explored the use of LLMs to generate concept-related analogies to assist students and teachers~\cite{bhavya2024analego}.
However, the effectiveness of LLM-generated analogies in educational settings remains underexplored, highlighting the need for a thorough evaluation to guide teachers and students in their practical application. 
% Therefore, a thorough evaluation of these analogies can provide valuable guidelines for teachers and students on their effective use. 
We draw on two traditional education scenarios on evaluating human-made analogies to assess LLM-generated analogies: students solving problems using analogies without human intervention~\cite{thagard_analogy_1992,gick_analogical_1980,gick_schema_1983, brown_analogical_1989}, and teachers employing analogies in the classroom~\cite{vendetti_analogical_2015,richland_analogy_2004,oliva_teaching_2007}.
Evaluating LLM-generated analogies in the first scenario determine their effectiveness in assisting students with problem-solving by accuracy.
It also offer insights for developing LLM-assisted self-learning tools~\cite{gao2024fine, Lyu2024evaluating} that produce more beneficial educational analogies.
In the second scenario, evaluation helps to understand the needs and practical effectiveness of LLM-generated analogies in real classroom practices with teachers' instruction.
\chirev{It also provides insights of needs for developing LLM-assisted tools to help teachers teach with analogies.
Therefore, we aim first to evaluate the effectiveness of LLM-generated educational analogies in helping students grasp scientific concepts across two distinct educational settings. 
Based on the findings, we then consider developing a practical system to explore the practical application of LLMs for analogy generation in supporting teachers and students.
}
% \szk{It feels a bit repetitive with Sec. 3.}
% Therefore, in this paper, we aim to evaluate the effectiveness of LLM in generating educational analogies that help students grasp scientific concepts in two distinct educational settings.


% \szk{Should the challenges be written more simply? Things like no benchmarks, need for human studies, need for tailored methods, etc., seem a bit unnecessary? Directly say what the previous study did, but education did not; considering the differences between the field and target users,  other studies are not directly transferable, and then raise RQs? \textbf{We also need to leave space in the Introduction to explain how to implement the practical system (purpose and specific practices).}} 
% However, evaluating LLM-generated analogies in education presents several challenges. 
% First, benchmark-based evaluation is not feasible due to the lack of clear ground truth, requiring reliance on manual annotation~\cite{sultan_life_2022}.
% Second, LLM researchers may evaluate the quality of analogies differently than teachers and students, necessitating human-subjective studies with diverse participants to verify practical use. 
% Additionally, the two educational settings mentioned above require tailored methods for generating and evaluating analogies with LLMs.
\chirev{Evaluating LLM-generated analogies in practical applications is challenging, requiring manual annotation~\cite{sultan_life_2022} and human-subject study involving diverse participants across varied settings.}
Previous studies have evaluated the use of LLM-generated analogies in creative tasks, such as design problem reformulation~\cite{ding_fluid_2023}. 
However, due to the varied participants and cognitive demands of education, the methodologies and findings from these domains are not transferable to educational settings.
To address the gap, we answered the following research questions (\textbf{RQ}s): 
\begin{itemize}
    \item \textbf{RQ1:} How effective are LLM-generated analogies for student understanding without human intervention? 
    \item \textbf{RQ2}: What kind of analogies do teachers need LLMs to generate for classroom practice?
    \item \textbf{RQ3}: How effective are these LLM-generated analogies for classroom practice with teacher intervention?
\end{itemize}

To answer these \textbf{RQ}s, we design a two-stage study to evaluate the effectiveness of LLM-generated analogies in helping students understand scientific concepts in educational settings.
We use GPT-4o~\cite{openai_gpt-4_2023}, the state-of-the-art LLM, to generate analogies for concepts in physics and biology, and conduct human-subject study in a \chifinal{Chinese} high school.
We addressed \textbf{RQ1} through a controlled in-class students test in \textbf{Study I}: the experimental group used both textbook explanations and carefully generated analogies to answer questions about unknown concepts, while the control group relied only on textbook explanations.
The effectiveness of LLM-generated analogies was primarily measured by accuracy, with self-confidence rating evaluating students' subjective satisfaction. 
Interviews with participating students provided additional insights.
In \textbf{Study II}, we conducted pre-class interviews with teachers and senior students to understand the need for LLM-generated analogies in classroom teaching (\textbf{RQ2}). 
Interview findings helped us design the following field study and refine analogy generation.
We then carried out a one-week field study with twelve lessons in which teachers selected and modified the generated analogies based on their needs, using them in one class while maintaining regular teaching in the other.
Through observations and teacher interviews, we qualitatively evaluated the effectiveness of LLM-generated analogies for classroom teaching with teacher intervention (\textbf{RQ3}).

\chirev{Based on the findings from both studies, we designed an interactive system that uses LLM to assist teachers in preparing analogies. 
We first interviewed two teachers to assess what they want from the system. 
Using insights from the interviews and studies, we defined the design requirements to guide system development.
We invited six physics and biology teachers from different schools to participate in the system evaluation. 
After tutorial and free exploration to confirm their familiarity with the system, teachers used the system to create analogy of scientific concepts for teaching over a week. 
Based on users' data records and interviews, we demonstrated the practical effectiveness of LLMs in supporting teaching by analogy and then discussed future research directions.
}


The main \textbf{contributions} are summarized as follows:
\begin{itemize}
    \item We are among the first to design and conduct a two-stage study, comprising a controlled experiment and a field study, to evaluate the effectiveness of LLM-generated analogies in student understanding and classroom practice.
    \item We contribute \chirev{empirical evidence and} new knowledge into educational LLM-generated analogies, revealing that their effectiveness without intervention \chirev{varies} on subject characteristics and can lead to student overconfidence, while in classroom practice, analogies are refined by teachers to align with their teaching focus and preference, enhancing both classroom and homework performance and inspiring new teaching methods.
    \item \chirev{Based on empirical evidence and new knowledge, we developed a practical system to help teachers build analogies of scientific concepts, conducted a system evaluation demonstrating its effectiveness, and provided design implications for future development and evaluation of LLM-assisted education with analogy.}
\end{itemize}

%\textbf{1)} Conducting a two-stage study, comprising a controlled experiment and a field study, to evaluate the effectiveness of LLM-generated analogies in student understanding and classroom practice, providing new empirical evidence; 
%\textbf{2)} Contributing new knowledge into educational LLM-generated analogies, revealing that their effectiveness without intervention depends on subject characteristics and can lead to student overconfidence, while in classroom practice, analogies are refined by teachers to align with their teaching focus and preference, enhancing both classroom and homework performance and inspiring new teaching methods;
%\textbf{3)} Providing insights and design implications for future developing and evaluating educational LLM-generated analogies and LLM-assisted education.
% Our primary findings were as follows: 
% For \textbf{RQ1}, we found that LLMs can generate effective analogies for biological concepts, which generally help students understand detailed concept explanations and significantly improve test accuracy. 
% However, LLMs often produce incorrect analogies for abstract physical concepts lacking real-life counterparts that are less effective for enhancing understanding.
% Besides, without teachers' guidance, there is a risk that students may rely on incomplete information in the generated analogies and thus overestimate their understanding.
% For \textbf{RQ2}, we observed that physics teachers prefer analogies based on other physical concepts to express similar abstract features, while biology teachers favor those drawn from daily life. 
% LLM-generated analogies should reflect teachers' specific needs and teaching focus, though they need not be perfect, as teachers can refine them.
% For \textbf{RQ3}, we found that teachers were willing to select and modify LLM-generated analogies to ensure they were clear and engaging.
% LLM-generated analogies helped maintain student focus and enhance classroom and homework performance, inspiring teachers to create new analogies and rethink their teaching methods.


% To address this, we adapted the previous method of classifying and coding analogies and comparing the correlation between each category and human feedback, while incorporating additional considerations specific to educational scenarios in both methods of analogy generation and evaluation, as detailed below.
%Therefore, in this study, we are motivated to conduct a comprehensive evaluation of the effectiveness of LLM in generating analogies in education to help students understand concepts.%LLMs can create free-form natural language analogies~\cite{bhavya_analogy_2022}. 
%used in textbooks and by teachers in class to help students grasp scientific concepts~\cite{oliva_teaching_2007}.
%Analogy aids in the understanding of complex concepts by linking them to familiar ones~\cite{gentner_structure_1997,davies_analogy_1985,gentner_computational_2011,mitchell_abstraction_2021}. 
%Its importance spans various disciplines, including boosting creativity~\cite{holyoak_mental_1996,goel_design_1997,kao_how_2020}, communication~\cite{casarett_can_2010,galesic_using_2013}, and especially education~\cite{vendetti_analogical_2015, thagard_analogy_1992, richland_analogy_2015,treagust_science_1992, gray_teaching_2021, oliva_teaching_2007}.
%With the recent rapid development of Large Language Models (LLMs)~\cite{openai_chatgpt_2022,openai_gpt-4_2023}, researchers have started using LLMs to generate analogies that promote concept understanding.
% In the initial phase (Study I), we first enhanced the quality of analogies by incorporating sound principles into the prompt template and employing the strategy of over-generation followed by filtering~\cite{yuan-etal-2023-distilling}. 
% Specifically, we first referred to common principles for good analogies to create a carefully designed prompt template. 
% Using this template, we generated 30 analogies for 10 concepts and manually annotated them for errors. 
% We then analyzed the results of this annotation to formulate new principles, which we incorporated into the prompt template for regenerating the analogies.
% After another round of filtering by GPT-4, 10 analogies were automatically selected. 
% We further analyzed the patterns of these regenerated analogies and selected 4 analogies as supplementary materials for high school students to use while answering scientific questions.
% Finally, we conducted an experiment involving 2 groups of students: one with textbook explanations, and another with textbook explanations and analogy assistance. 
% After the testing, we interviewed six students who shared their difficulties during the test and explained how the materials were helpful.
% By analyzing feedback regarding the accuracy of students' answers and their ratings of the materials along with feedback gathered from interviews, we assessed the impact of the quality of LLM-generated analogies on students' conceptual understanding.

% In Study II, we conducted semi-structured interviews with two teachers and two students to identify the specific needs for analogies in classroom teaching. 
% During the pre-class interviews, we also presented the analogies generated in Study I to understand their comments and expectations for LLM-generated analogies. 
% The findings of the interviews were summarized as requirements for refining the prompt template to generate analogies for concepts provided by teachers. 
% Subsequently, teachers selected and refined these newly generated analogies based on their teaching styles and used them in class while teaching these concepts. 
% They evaluated the usefulness of the analogies by asking students questions, assigning exercises, and observing students' reactions, then shared their insights with us in post-class interviews.