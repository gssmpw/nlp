% In this section, we designed an LLM-assisted system for teachers and conducted a system evaluation to understand the practical effectiveness of LLM in helping analogical teaching.
In this section, we transformed key study findings into an LLM-assisted system for teachers and conducted a system evaluation, highlighting its contribution to teaching by analogy in education.

\subsection{System Design}
% We first confirmed the necessity and functionality of the system by interviewing T1 and T2 and identified design requirements based on interview results and study findings. 
% We then designed a system for teachers to create analogies.
This subsection details the interview for deriving design requirements and system workflow as below.

\subsubsection{Interview}
Given that Study II showed teachers prepared analogies during lesson planning, we first determined the system's necessity and functionality through 20-minute one-on-one online interviews with T1 and T2 via Tencent Meeting. 
The interview mainly consists of two questions. 1) Necessity: Is providing an LLM-assisted analogy generation system necessary for teachers to prepare lessons? 2) Functionality: What functions do they expect?
% Should the system focus on generating analogies for specific concepts, or expand its functionality to create complete lesson plans that integrate analogies?

Both teachers affirmed the first question, expressing a desire to operate the system themselves to gain hands-on experience and long-term support from LLMs.
Regarding the second question, both teachers expressed a preference for the analogy generation mode in Study II. 
They suggested that after specifying the required concepts, the system should generate accurate analogies tailored to their needs, allowing for refinement and management. 
They also noted that in Study II, analogies function as plug-and-play modules to replace or enhance original explanations of scientific concepts, so the generation process need not account for other lesson plan content at this stage.
% For the second question, both teachers noted that in Study II, they only replaced or enhanced their original explanations of scientific concepts with LLM-generated analogies, without altering their lesson plans. 
% Analogies were treated as plug-and-play modules with minimal interaction with the overall plans. 
% Additionally, both emphasized that lesson plans reflect their teaching expertise and core competitiveness, and they currently see no need for LLM-generated lesson plans with analogies.


\subsubsection{Design Requirements}
After confirming the necessity and functionality, we identified three design requirements as below and confirmed them with T1 and T2.

\textbf{R1: It should incorporate principles and strategies identified in previous studies to help generate accurate analogies tailored to teacher needs.}
The general principles identified in Study I (Tab.~\ref{tab:instruction_prompt}) should be integrated into the prompt by default to enhance the accuracy.
The system should allow teachers to select useful prompting strategies identified in Study II and incorporate them into generation following the practice of data preparation of Study II (Sec.~\ref{sec:study22_data_preparation}) to better tailor analogies to their needs.

\textbf{R2: It should enable teachers to input their expectations or automatically generate personalized principles for creating analogies.}
As identified in Study II interviews (Sec.~\ref{sec:study21_findings_and_derived_requirments}), the workflow should allow teachers to input concepts they believe require analogies to be generated.
Besides, to ensure personalized needs, it should also accept user-inputted new principles tailored to their needs and even automatically generate tailored principles from user comments on generated analogies for the prompt (Tab.~\ref{tab:instruction_prompt}).

\textbf{R3: It should allow users to make manual changes and feedback to manage their analogies.}
In Study II, teachers showed a strong willingness and ability to refine and manage generated analogies (Sec.~\ref{sec:study22_results_analysis}), highlighting the need for a system that allows direct editing.
As prompt evolution in Study I showed limited improvement (Tab.~\ref{tab:error_rates}), and teachers found conversational refinement challenging in pre-class interviews in Study II (Tab.~\ref{tab:findings_in_study2_pre_class_interview}), conversational modifications by LLMs are unnecessary.
The system should also enable teachers to manage analogies by classifying them into four categories (useful, inspiring, refinable, and useless) and storing all except the useless ones.


% Instead, the system might summarize personalized principles from teacher feedback to better tailor analogy generation to their specific needs.


% \textbf{It should focus on assisting with analogy preparation rather than generating entire lesson plans.} 
% Given that Study II showed teachers prepared analogies during lesson planning, we asked T1 and T2 about the link between lesson plans and analogies and the need for automatically generating lesson plans with analogies.
% Both teachers noted that in Study II, they only replaced or enhanced their original explanations of scientific concepts with LLM-generated analogies, without altering their lesson plans. 
% Analogies were treated as plug-and-play modules with minimal interaction with the overall plans. 
% Additionally, both emphasized that lesson plans reflect their teaching expertise and core competitiveness, and they currently see no need for LLM-generated lesson plans with analogies.
% \szk{add the corresponding discussion about LLM4lessonplanning.}



\subsubsection{System Workflow}
\label{sec:workflow}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{figure/revsystem.pdf}
    \caption{\chirev{Our system interface (top) and workflow (bottom). In each round, teachers use Configuration Panel (A) to select strategies (A1) and manage principles (A2) for generation. After entering scientific concepts (B1), they provide feedback (B2), edit (B3), and comment (B4) to each generated analogy in Generation Panel (B). Clicking the ``Save'' button makes the system generate new principles by LLM in Configuration Panel and store approved analogies in Library Panel (C), where teachers may export saved analogies.}}
    \label{fig:system}
    \Description{This figure shows our system interface which allows teachers to interact with three main panels. In Configuration Panel, teachers select strategies and manage principles for analogy generation. They then enter scientific concepts, provide feedback, make manual editing, and add comments to the generated analogies in Generation Panel. Clicking the ``Save'' button enables the system to generate new principles in Configuration Panel and store approved analogies in Library Panel, where all saved analogies can be exported at any time.
    }
\vspace*{-10pt}
\end{figure*}

Based on the design requirements, we built an LLM-assisted system (Fig.~\ref{fig:system}) for teachers to create and refine analogies for teaching. 
Teachers begin by registering an account and follow a workflow as below.

\textbf{Configure strategies and principles for analogy generation.} 
After selecting a teaching subject during registration, the system provides prompting strategies in Configuration Panel (Fig.~\ref{fig:system}A) based on the chosen subject. 
Teachers can click on these strategies for generating analogies (\textbf{R1}).
The principle list starts blank, allowing teachers to manually add or select principles as needed (\textbf{R2}). 
When the user hovers over a principle, they could edit or delete it freely.

\textbf{Generate analogies and provide feedback}. Teachers then input a scientific concept in Generation Panel (Fig.~\ref{fig:system}B) and click the ``Generate'' button (\textbf{R2}). 
The system will provide three cards with generated analogies. 
Each card has four feedback options in the top-right corner: useful, inspiring, refinable, and useless. 
Teachers need to select one feedback option for each analogy card and may edit analogies as needed and provide text comments (\textbf{R3}).

\textbf{Save analogies, optionally generate new principles, and restart.} When saving, modified analogies (excluding those marked as useless) are stored in Library Panel (Fig.~\ref{fig:system}C), along with the corresponding concept (\textbf{R3}). 
If teachers enable the ``Comment-based summarization'' feature in Configuration Panel (Fig.~\ref{fig:system}A), the system will summarize new principles from comments on the three analogies by LLMs and add them to the principles list (\textbf{R2}). 
Teachers can edit or delete any generated principles or disable the automatic summarization feature at any time.
After saving, the system clears the concepts and analogies in Generation Panel (Fig.~\ref{fig:system}B), allowing users to restart. 
Teachers can reconfigure the strategy list, and add, delete, select, or modify the principle list for the new round.

Besides, teachers click right buttons of text for strategies (Fig.~\ref{fig:system}A1), principles (Fig.~\ref{fig:system}A2), and approved analogies (Fig.~\ref{fig:system}C) to view or collapse text, reducing clutter. 
All approved analogies stored in Library Panel can be exported to PDF for teachers' usage.
% Users' interaction logs will be recorded, including modifications and feedback to analogies and modifications and selections of principles.


We implemented the system as a Vue-based web application with a Python Flask backend. More implementation details, such as prompts for automatically generated principles, are provided in the supplementary material.


\subsection{System Evaluation}
This subsection details the participants, procedure, and findings of the system evaluation.
\subsubsection{Participants}
We invited 6 high school physics and biology teachers from 5 schools, including T1 and T2, along with 4 new teachers from different schools to increase diversity. 
The physics teachers had 7 years (T1), 3 years (T3), and 4 years (T5) of experience, while the biology teachers had 4 years (T2), 2 years (T4), and 25 years (T6) of experience. All participants received a \$20 gift card as compensation.

\subsubsection{Procedure}
Our study consists of a tutorial, free exploration, one-week usage, and an interview.

\textbf{Tutorial.} We conducted one-on-one online interviews with each teacher other than T1 and T2 via Tencent Meeting, lasting 20 minutes. 
We briefly revisited Steps 1 and 3 from Study II (Sec.~\ref{sec:study21}) to understand their experience with analogical teaching and AI, and to ensure they were familiar with the study background.

\textbf{Free exploration.} Following the tutorial, we continued the interview with each teacher to demonstrated the basic functionality of the system according to the workflow, after which the teachers were encouraged to explore the system freely. 
During this exploration phase, we prompted them to think aloud and we answered any questions they had to make sure they understand how to use the system. 
This process lasted about 20 minutes. 

\textbf{One-week usage.} Before using the system, we informed the teachers that it would collect data on the analogies and principles they generated, as well as their feedback, manual edits, comments, and other interaction data for research purposes. 
All of them provided informed consent. 
We then asked the teachers to use the system to generate analogies to support their lesson preparation for one week.
The frequency of system use and the content of lesson preparation were determined by the teachers themselves, although we encouraged them to use the system frequently.


\textbf{Interview.}
After one-week usage, we conducted one-on-one semi-structured online interviews with each teacher via Tencent Meeting, lasting nearly 40 minutes each. 
During the interviews, we asked each teacher the following questions: course coverage (Q1), system usability (Q2), satisfaction with the generated analogies (Q3), satisfaction with the generated principles (Q4), satisfaction with the edited analogies (Q5), satisfaction with the edited principles (Q6), and the significance of the system for their future lesson preparation and teaching (Q7).

% \subsubsection{Data Analysis}

% \textbf{Quantitative analysis of user logs.}

% \textbf{Qualitative analysis of interviews.}

\enlargethispage{10pt}


\subsubsection{Findings}
\label{sec:system_findings}
Based on user interaction data and interview results of Q1-Q7, we summarize the following findings.

\textbf{The system's usability and the usefulness of generated analogies were well-received by teachers (Q1-Q3).} 
Teachers reported that they used the system to generate analogies for lessons spanning from one month to half a semester, aiding both reflection on past lessons and preparation for upcoming ones. 
All teachers agreed that the system was easy to use, even if they had nearly no experience using AI (T3, T5, T6).
They generated 15 to 42 analogies (15, 15, 21, 24, 24, 42), with 40\% to 80\% marked as non-useless (``useful'', ``refinable'', ``inspiring'') across users (40\%, 58.3\%, 61.9\%, 64.3\%, 66.7\%, 80\%). 
They all agreed that although many of the generated analogies had various issues, overall, they helped expand their lesson planning ideas and inspired greater use of analogies in teaching.
For example, the system analogizes ``phase difference'' to ``some students doing radio gymnastics faster or slower than classmates.'' T3 said, ``\textit{I hadn’t thought of that, but it’s great, and since my class is right after gymnastics session, I’ll definitely use it.}''
Besides, physics teachers noted that they understood the system’s inability to provide suitable analogies for some complex concepts, as such analogies might not exist anyway.
% Instead of getting stuck, they pragmatically explored analogies for other concepts and got lots of help.
% For example, T3 noted that while the continuous generation of useless analogies could be frustrating, it was often due to the lack of suitable analogies for certain concepts, so he would try other concepts instead of getting stuck.


\textbf{Teachers tried to improve analogy quality by incorporating generated principles or directly regenerating analogies (Q4).} 
Five teachers (excluding T4) continuously enabled the automatic principle generation feature and actively input their comments, producing 10 to 30 principles (10, 13, 17, 18, 30) and incorporating at least half into analogy generation.
They all praised the quality of the principles, with T1 saying, ``\textit{The system infers general principles from my vague intents on comments on specific analogies.}''
For usability of this feature, T3 noted, ``\textit{It doesn’t matter if too many principles are generated during the usage. I just delete the redundant ones—it’s more convenient than summarizing myself.}'' 
For its effectiveness in analogy generation, T1 and T5 felt the principles improved analogy quality, while T3 and T6 were unsure but still incorporated them because ``\textit{adding more correct terms can't hurt.}''
On the contrary, T4 preferred regenerating analogies directly without commenting on analogies and generating principles, saying, ``\textit{If the analogies aren't good, I just regenerate them a few more times as I know the randomness of AI.}''
Only T4 manually added principles at the beginning of usage, while all teachers found it inconvenient and difficult as noted by T3 and T1.

\textbf{The generated analogies and principles benefit teachers more than just concept explanations (Q7).} 
1) The principles help shape teaching expertise. 
T1 said, ``\textit{I can learn teaching techniques from the generated principles, and after using the system for a while, I could even write a teaching paper. It’s like having a discussion about teaching with another experienced teacher. While the principles may not immediately impact teaching, the long-term accumulation is valuable.}'' 
2) The analogies supplement the teacher's knowledge base. 
T6 noted that the generated analogies broaden a teacher's perspective, and saving more analogies gradually builds their teaching knowledge system, which help teachers adapt to different teaching situations. 
3) The analogies also inspire quiz and test creation.
T2 said, ``\textit{Even if some analogies aren't ideal, I save them because having students identify errors helps their learning.}'' T3 stated, ``\textit{Some of the generated `analogies' is example-based explanation, but I save it because these real-life examples can be used to set questions.}''


\textbf{Teachers typically organize analogies externally rather than refining them within the system and there is potential over-reliance (Q5-Q6).}
Despite marking large proportion of generated analogies as ``refinable'' (Mean = 21.4\%) and ``inspiring'' (Mean = 13.8\%), only T1 and T4 edited 1 analogy in the system, respectively. 
T6 explained, ``\textit{Manually modifying so much text is too burdensome for older teachers.}'' 
However, all teachers reported improving analogies to fit their needs through external modifications.
T5 noted that his lesson preparation habit is to record keywords in electronic notes, so the analogies in the system only serve as explanation and inspiration, which he then reorganizes in his notes.
Similarly, T1 and T6 preferred recording analogies in paper notebooks. 
This separation between analogy generation and actual lesson preparation may make it difficult to supervise teachers’ behaviors in teaching and potentially lead to teachers' over-reliance on generated analogies.
This issue may be more pronounced for users like T4, who prefer to regenerate analogies directly without providing any comment, compared to teachers who actively engage by entering comments in the system.
