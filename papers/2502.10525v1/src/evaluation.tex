\section{Evaluation}
\label{sec:eval}

\input{tables/main_table_colored.tex}
In this section, we present the results of our experimental evaluation of the durability of OSM watermarks (\cref{sec:methods}) against common model modifications (\cref{sec:durability}), with our results highlighting that durable OSM watermarking is still an open challenge.
We defer omitted experimental details to \cref{app:experimental_details} and present additional in-depth results for each model modification in \cref{sec:deep_dives}. 

\paragraph{Methods}
We evaluate \KGW with $\delta = 2$, $\gamma = 0.25$, and $k = 1$, and \KTH with key size 256 and no key shift.
We do not evaluate distilled AAR~\citep{aar} as it highly degrades text quality~\citep{learnability}.
For \unremovable, we set $\sigma = 0.6$, and do not evaluate it against pruning, as current pruning methods assume no architectural changes. 
For \gaussmark we set $\sigma = 0.018$ and apply it to the up-projection matrix (\texttt{up\_proj}) of the MLP layer in the $31$st attention block.
We omit the RL-based watermark, as we were unable to train it to a sufficient text quality.

\paragraph{Variant: targeted distillation}
In addition to methods from prior work, we evaluate an additional variant of \KGW that leverages \emph{contrastive task vectors} (\textsc{CTV}) \citep{task_vector, ctv} in an aim to improve durability.
Namely, we first apply \KGW to $\theta_0$ to obtain $\theta_1$. 
Then, we finetune $\theta_1$ on a broad-domain dataset (\textsc{OpenWebText}, see \cref{app:experimental_details}) to obtain $\theta_2$ where the watermark has been removed.
Let $\tau$ denote the following boolean mask of the model weights: 
\begin{equation}
    \label{eq:ctv}
    \tau = |\theta_1 - \theta_0| > |\theta_2 - \theta_0|.
\end{equation}
Intuitively, weights where $\tau$ is false were leveraged to remove the watermark---we aim to avoid relying on such weights in our final model by (again) applying \KGW to $\theta_0$ only where $\tau$ is true. 

\paragraph{Model modifications}
For each modification from \cref{sec:durability}, we evaluate a range of representative settings.
For quantization, we use 4-bit and 8-bit variants, using \textsc{HGG}, \textsc{LLM.int8()}, \textsc{GPTQ}, and \textsc{AWQ} methods---going below $4$ bits significantly degraded text quality in our experiments.
We evaluate pruning with sparsity ratios $\rho$ $\in \{0.2,0.5\}$ using unstructured pruning methods \textsc{Wanda}, \textsc{GBLM}, and \textsc{SparseGPT}. 
For merging, we merge the watermarked model with the base model using \textsc{SLERP} with interpolation ratios $t \in \{0.1,0.3,0.5,0.7,0.9\}$.
Finally, we consider full finetuning and parameter-efficient \textsc{LoRA}, both on broad-domain \textsc{OpenWebText}~\citep{openwebtext} (Reddit, completions) and task-specific \textsc{OpenMathInstruct}~\citep{openmathinstruct} (math, instruction tuning).

We use the \llama model in all experiments, watermark it, apply the model modification, and generate $100$ completions of length $200$ by prompting with the first $50$ tokens of each entry in the RealNewsLike split of C4~\citep{c4}, as in prior work~\citep{kgw}.  
For each completion, we evaluate the watermark strength (TPR at $5$\% FPR, see~\cref{app:experimental_details}) and median quality (PPL using \textsc{LLama3-8B}) to ensure that our modifications sufficiently retain text quality.
 
 
\paragraph{Results: OSM watermarks lack durability}
In \cref{tab:main_results_table}, we present our main results. 
Colors correspond to different TPR ranges (\textcolor{green!70!black}{green}: above $0.9$, \textcolor{yellow!70!black}{yellow}: between $0.8$ and $0.9$, \textcolor{red!70!black}{red}: below $0.8$).

First, we observe that nearly all tested schemes are durable to quantization, irrespective of the quantization method, and even at $4$ bits. 
Similar results hold for pruning, where all schemes are highly durable for $\rho=0.2$ and remain significantly durable up to a sparsity ratio of $0.5$. 
This intuitively follows from the fact that both quantization and pruning directly aim to minimize the distortion between quantized and original model, thereby also preserving the embedded watermark.

For merging with the unwatermarked model using \textsc{SLERP}, we can observe that weight-editing watermarks are, on average, more durable than distillation-based ones.
For \unremovable, these good results are expected, as merging the bias layer with the null vector (i.e., the bias layer of the unwatermarked model) is equivalent to applying the same noise $\varepsilon$ but with a scaled standard deviation
\begin{equation}
    \varepsilon_{\text{SLERP}}(t) = \sin[(1-t)\frac{\pi}{2}] \varepsilon.
\end{equation}
Still, for $t \geq 0.7$ all methods struggle to retain the watermark.
Interestingly, we see that \textsc{KGW-D+CTV} is slightly more durable than \KGW, suggesting that the contrastive task vectors can indeed improve durability, presumably as they localize the watermark to fewer parameters---however, this modification is ultimately ineffective, as it does not improve strength across other model modifications.

Most importantly, we find that for full finetuning on \textsc{OpenWebText}, \textbf{none of the tested watermarking schemes are durable}: after only $500$ steps of gradient descent, the TPR drops significantly to a point where the watermark seizes to be useful.  
Similar results hold for LoRA finetuning on \textsc{OpenWebText}, where only \unremovable remains high TPR after $500$ steps before dropping significantly after $2500$ steps of finetuning. As in the other cases, this can be explained by the architectural modifications of \unremovable: LoRA finetuning does not directly modify the (usually not present) last layer bias and, therefore, cannot directly modify the watermarked part of the model.

We extend these results by including finetuning experiments with the domain-specific dataset \textsc{OpenMathInstruct}, modeling a realistic use-case where a user would finetune an OSM on an expert task.
Across all schemes, we find higher durability compared to \textsc{OpenWebText}, especially for \textsc{LoRA}.
Note that we still evaluate the watermark strength on the general domain C4 test set---as we show in \cref{sec:deep_dives}, there is a significant drop in watermark strength when evaluated on the math domain. 
This points to an interesting phenomenon of \emph{domain-specificity} of OSM watermarks: watermark strength more quickly degrades on domains specifically targeted by finetuning. 

Overall, we conclude that while prior work proposed a range of OSM watermarking methods with varying tradeoffs, no method is currently sufficiently durable.
Given the real-world prominence of such model modifications, ensuring durability against them remains an open and critical challenge for future research---here our proposed evaluation setup provides an easy way to compare future work.
