\section{Requirements for Watermarking of Open-source Models}
\label{sec:requirements}

We first recall generation-time watermarks and their requirements (\cref{ssec:requirements_post_hoc}) and detail the challenges faced by OSM watermarks, along with the new requirements induced by those challenges (\cref{ssec:osm_watermark_requirements}).

\paragraph{Notation}
We define an LLM as an autoregressive model over a vocabulary $\Sigma$, parameterized by its weights $\theta \in \Theta$ where usually $\Theta \subset \mathbb{R}^d$.
Given a text $x \in \Sigma^*$, with $\Sigma^*$ the Kleene closure of $\Sigma$, the next token distribution according to the LLM is given by $p_{\theta}(.|x_{<t})$. 
We also refer to $y(x, \theta)$ as a sampled completion from the model $\theta$ for the prompt $x$.
Lastly, we note $p_{\theta}(x):= \prod_{t=1}^{|x|} p_{\theta}(x_t|x_{<t})$.

\subsection{Established Requirements for Generation-time Watermarks}
\label{ssec:requirements_post_hoc}

Next, we introduce generation-time watermarking methods and recall the requirements that have been established in prior work.

\paragraph{Generation-time watermarks} 
A generation-time watermark $w$ is defined by a triple $(f_w, \xi_w, \mathcal{D}_w)$. 
$\xi_w \in \mathbb{N}$ is a private key (used to seed a pseudo-random function).
$f_w$ is a mapping from $\Delta(\Sigma) \times \Sigma^* \times \mathbb{N}$ to $\Delta(\Sigma)$ that takes a next-token probability distribution, a sequence of tokens, and the private key, and returns a watermarked next-token probability distribution.
Lastly, $\mathcal{D}_w: \Sigma^* \times \mathbb{N} \rightarrow \{0,1\}$ is a \emph{watermark detector} that, given a text $x$ and the private key $\xi_w$, returns $1$ if $x$ is watermarked and $0$ otherwise. 
Hence, given a model $\theta$ and a text $x$, to generate watermarked text, at each step $t$ of the generation process, instead of sampling the next token from $p_{\theta}(.|x_{<t})$ we sample the next token from $f_w(p_{\theta}(.|x_{<t}), x_{<t}, \xi_w)$.
We may omit the dependency on $x_{<t}$ in $f_w$ by writing $f_w(p_{\theta}(.|x_{<t}), \xi_w)$.

\paragraph{Requirements} 
On top of watermark strength, \ie
the ability of the watermarking algorithm to produce text in which the watermark is detectable, four key requirements of watermarks have been identified in previous works \citep{stanford,unbiased,dipmark}.
\begin{enumerate}
    \item \emph{Quality}: A watermark should not significantly degrade the quality of the model outputs.  
    A proxy for quality in the literature is distortion-freeness \citep{stanford,unbiased,orzamir,dathathri2024scalable}.  
    In expectation over the private key $\xi$, the next-token distribution (or, in the stronger case, the next-sequence-of-tokens distribution) should be the same between the original model and the watermarked model.
    \item \emph{Robustness} \citep{kgw2}: Given a watermarked text $x$, robustness measures how edits to the text (\eg token or word insertion, deletion, substitution, and paraphrasing) affect the accuracy of the watermark detector.
    \item \emph{Undetectability} \citep{orzamir,crafted_prompt,detection}: Measures the ability of third-party actors to detect the presence of the watermark without the private key.  
    \item \emph{Security}: This encompasses the vulnerability of the watermarking algorithm to spoofing and stealing attacks \citep{watermark_stealing,bileve,strengths}, where a third party tries to impersonate the watermark without having the private key $\xi_w$.
\end{enumerate}


\subsection{How does the Open-source Setting Differ?}
\label{ssec:osm_watermark_requirements}

With an open-source model $\theta$, the end user has direct access to $p_{\theta}(.|x_{<t})$.
Hence, a malicious user can choose to sample the next token directly according to $p_{\theta}(.|x_{<t})$ rather than $f_w(p_{\theta}(.|x_{<t}), \xi)$, thereby producing non-watermarked text.
Thus, for an open-source model, the watermark must be directly embedded into the model's weights (\ie $p_{\theta}(.|x_{<t})$). 
This conceptual difference from generation-time watermarks requires an updated and newly interpreted set of requirements.

\paragraph{OSM watermarks}
We define a watermark for open-source models $w$ as a triple $(g_w, \xi_w, \mathcal{D}_w)$, where $\xi_w \in \mathbb{N}$ is a private key, $g_w: \Theta \times \mathbb{N} \rightarrow \Theta$ is a mapping from the initial model to its watermarked version, and $\mathcal{D}_w$ is the watermark detector.
This means that the watermark is now embedded into the weights of the model and sampling text according to $p_{\theta}(.|x_{<t})$ generates watermarked text.

\paragraph{Requirements for OSM watermarks}
Based on the requirements for generation-time watermarks, previous works have already identified \textit{Quality} and \textit{Robustness} as requirements that directly extend to OSM watermarks.  
\textit{Undetectability} has not been addressed in prior works but similarly remains an important concern. 
In particular, distillation-based OSM watermarks (see \cref{sec:methods}) inherit the detectability issues of the generation-time watermark they are distilling \citep{detection,crafted_prompt}.
The other current OSM watermarks that we introduce in \cref{sec:methods} either have similar issues or, while no detection methods on them have been demonstrated, also do not offer guarantees of undetectability.

In contrast to generation-time watermarks, \textit{Security}, in particular spoofing, is not considered a fundamental issue for OSM watermarks.
For standard LLM watermarks, spoofing undermines the model provider's credibility, allowing attackers to produce malicious texts falsely attributed to them. As the user has direct control over the OSM watermarked model, more powerful and easier jailbreaking attacks \citep{prefill_jailbreak} directly enable the generation of harmful watermarked text from such models. 
Independently, spoofing threatens the integrity of multi-bit watermarks \citep{multibit1,multibit2,multibit3} by enabling impersonation---this is not applicable to OSMs, where generally only a single fixed model is released. 

\paragraph{OSM watermark durability}
The watermarked model being open-source introduces an additional key requirement: \emph{durability} against model modifications (see \cref{sec:durability}).
Durability measures how edits to the model parameters affect watermark detection.
As discussed in \cref{sec:intro}, no generation-time watermark is durable in this way, as it can be easily removed by changing the sampling algorithm.
In prior works, durability has either been defined in unrealistic scenarios \citep{unremovable}, tested against incomplete adversaries \citep{learnability}, or not considered at all.
Yet, we argue that a thorough consideration of durability is crucial for OSM watermarks, as one primary use case for open-source models is for users to share and deploy edited versions, as evidenced by almost $200$ thousand models hosted on Hugging Face, with over $200$M downloads.
Hence, having a well-defined and systematically evaluated notion of durability is crucial to guide OSM watermark research.
