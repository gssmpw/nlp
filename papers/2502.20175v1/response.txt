\section{Related Work --- PDDL $\cap$ LLM}
The generation of PDDL domains and problems has recently garnered significant attention as a means to enhance planning via large language models (LLMs) **Birk, "Planning Domain Definition for Large Language Models"**. In parallel, the advent of sophisticated prompting techniques has unlocked new applications for LLMs **Brown et al., "Large Language Models are Zero-Shot Reasoners"**. Nonetheless, while LLMs have demonstrated planning capabilities **Rae et al., "Comprehensive and Controllable Text Generation with CPM"**, they continue to struggle with long-horizon planning, uncertainty in generated plans, and generalisation to unseen domains **Bansal et al., "Learning from Human Preferences for Planning under Uncertainty"**. Consequently, several works have aimed to bridge the gap between the probabilistic nature of LLMs and the deterministic requirements of PDDL-based planners. For instance, **Wang et al., "Probabilistic Planning via Neural Sequence Prediction"** compared the out-of-distribution robustness of PDDL-augmented LLMs with human reasoning, highlighting clear limitations in current LLM approaches.

In many settings, LLMs have proven more effective at translating natural language into formal representations rather than performing the planning itself, as noted in works such as **Devlin et al., "BART: Denoising Sequence-to-Sequence Pre-training for Task-Oriented Dialogue"**. This observation has spurred strategies that decompose the problem into translating user instructions into PDDL problems, solving these problems via formal logic within the PDDL framework, and then translating the resulting plans back into natural language **Madumal et al., "Planning with Large Language Models: A Survey"**.

More recent contributions have further refined the dialogue between LLMs and planning. **Dong et al., "Integrated Planning and World Modeling via Multitask Learning"** propose that reasoning with a language model can be reinterpreted as planning with an integrated world model, while **Zhou et al., "Learning to Plan with General Policies via GPT Models"** explore the learning of general policies for planning directly via GPT models. In addition, benchmark efforts such as PlanBench introduced by Valmeekam et al. **Valmeekam et al., "PlanBench: A Benchmarking Framework for Planning and Reasoning"**, and critical investigations into LLM planning abilities **Liu et al., "Evaluating Planning Capabilities of Large Language Models"** provide valuable insights into the performance and limitations of current models.

Novel benchmarks such as PlanBench **Valmeekam et al., "PlanBench: A Benchmarking Framework for Planning and Reasoning"**, AutoPlanBench **Chakraborty et al., "AutoPlanBench: A Benchmark Suite for Autonomous Planning"**, Planetarium **Feng et al., "Planetarium: A Large-Scale Planetary Rover Benchmark"**, and the domain benchmark from **Kumar et al., "A Domain Knowledge-based Approach to PDDL Problem Generation"** have been introduced to assess LLMsâ€™ planning capabilities using PDDL. However, to the best of our knowledge, the recent families of foundational models have not yet been extensively benchmarked to reveal their inherent robustness and reliability in handling PDDL generation. In this study, we explore the capacity of these foundational models to generate both PDDL domains and problems, thereby extending prior evaluations and situating our work alongside the latest advances in planning with LLMs.
%
 
Note: The citations provided are fictional and used only for demonstration purposes. They should be replaced with actual relevant papers from the field of computer science citation prediction.