\section{Related Work --- PDDL $\cap$ LLM}
The generation of PDDL domains and problems has recently garnered significant attention as a means to enhance planning via large language models (LLMs) \cite{Strobel_2020,silver2020pddlgym,silver2022pddl,vyas2025hive}. In parallel, the advent of sophisticated prompting techniques has unlocked new applications for LLMs \cite{survey-prompting-2023,graux2024prompteng}. Nonetheless, while LLMs have demonstrated planning capabilities \cite{huang2024understanding}, they continue to struggle with long-horizon planning, uncertainty in generated plans, and generalisation to unseen domains \cite{robovqa2023arxiv}. Consequently, several works have aimed to bridge the gap between the probabilistic nature of LLMs and the deterministic requirements of PDDL-based planners. For instance, \citet{collinsWong2022} compared the out-of-distribution robustness of PDDL-augmented LLMs with human reasoning, highlighting clear limitations in current LLM approaches.

In many settings, LLMs have proven more effective at translating natural language into formal representations rather than performing the planning itself, as noted in works such as \citet{htn2pddl,Helmert2009ConciseFR,xie2023translatingnaturallanguageplanning}. This observation has spurred strategies that decompose the problem into translating user instructions into PDDL problems, solving these problems via formal logic within the PDDL framework, and then translating the resulting plans back into natural language \cite{ijcai2023p839,Liu2023LLMPEL,dagan2023dynamicplanningllm,silver2024generalized,gestrin2024towards,mahdavi2024leveragingenvironmentinteractionautomated,zhang-etal-2024-pddlego}.

More recent contributions have further refined the dialogue between LLMs and planning. \cite{hao-etal-2023-reasoning} propose that reasoning with a language model can be reinterpreted as planning with an integrated world model, while \cite{rossetti2024learning} explore the learning of general policies for planning directly via GPT models. In addition, benchmark efforts such as PlanBench introduced by Valmeekam et al. \cite{valmeekam2023planbench} and critical investigations into LLM planning abilities \cite{valmeekam2023planbench} provide valuable insights into the performance and limitations of current models.

Novel benchmarks such as PlanBench \cite{valmeekam2023planbench}, AutoPlanBench \cite{AutoPlanBench}, Planetarium \cite{zuo2024planetarium}, and the domain benchmark from \citet{oswald2024large} have been introduced to assess LLMsâ€™ planning capabilities using PDDL. However, to the best of our knowledge, the recent families of foundational models have not yet been extensively benchmarked to reveal their inherent robustness and reliability in handling PDDL generation. In this study, we explore the capacity of these foundational models to generate both PDDL domains and problems, thereby extending prior evaluations and situating our work alongside the latest advances in planning with LLMs.
%