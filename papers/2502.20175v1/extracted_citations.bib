@misc{AutoPlanBench,
      title={AutoPlanBench: Automatically generating benchmarks for LLM planners from PDDL}, 
      author={Katharina Stein and Daniel Fišer and Jörg Hoffmann and Alexander Koller},
      year={2024},
      eprint={2311.09830},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.09830}, 
}

@article{Helmert2009ConciseFR,
  title={Concise finite-domain representations for PDDL planning tasks},
  author={Malte Helmert},
  journal={Artif. Intell.},
  year={2009},
  volume={173},
  pages={503-535},
  url={https://api.semanticscholar.org/CorpusID:9377590}
}

@article{Liu2023LLMPEL,
  title={LLM+P: Empowering Large Language Models with Optimal Planning Proficiency},
  author={B. Liu and Yuqian Jiang and Xiaohan Zhang and Qian Liu and Shiqi Zhang and Joydeep Biswas and Peter Stone},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.11477},
  url={https://api.semanticscholar.org/CorpusID:258298051}
}

@inbook{Strobel_2020,
   title={MyPDDL: Tools for Efficiently Creating PDDL Domains and Problems},
   ISBN={9783030385613},
   url={http://dx.doi.org/10.1007/978-3-030-38561-3_4},
   booktitle={Knowledge Engineering Tools and Techniques for AI Planning},
   publisher={Springer International Publishing},
   author={Strobel, Volker and Kirsch, Alexandra},
   year={2020},
   pages={67–90} }

@misc{collinsWong2022,
  doi = {10.48550/ARXIV.2205.05718},
  
  url = {https://arxiv.org/abs/2205.05718},
  
  author = {Collins, Katherine M. and Wong, Catherine and Feng, Jiahai and Wei, Megan and Tenenbaum, Joshua B.},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Symbolic Computation (cs.SC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks},
  
  publisher = {CogSci},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{dagan2023dynamicplanningllm,
      title={Dynamic Planning with a LLM}, 
      author={Gautier Dagan and Frank Keller and Alex Lascarides},
      year={2023},
      eprint={2308.06391},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.06391}, 
}

@inproceedings{graux2024prompteng,
  title={{[PromptEng] First International Workshop on Prompt Engineering for Pre-Trained Language Models}},
  author={Graux, Damien and Montella, S{\'e}bastien and Jabeen, Hajira and Gardent, Claire and Pan, Jeff Z},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1311--1312},
  year={2024}
}

@inproceedings{hao-etal-2023-reasoning,
    title = "Reasoning with Language Model is Planning with World Model",
    author = "Hao, Shibo  and
      Gu, Yi  and
      Ma, Haodi  and
      Hong, Joshua  and
      Wang, Zhen  and
      Wang, Daisy  and
      Hu, Zhiting",
    booktitle = "EMNLP",
    month = dec,
    year = "2023",
    address = "Singapore",
    doi = "10.18653/v1/2023.emnlp-main.507",
    pages = "8154--8173",
    abstract = "Large language models (LLMs) have shown remarkable reasoning capabilities, particularly with Chain-of-Thought-style prompts. However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks or performing complex math or logical reasoning. This is due to LLMs' absence of an internal world model for predicting world states (e.g., environment status, variable values) and simulating long-term action outcomes of actions. This prevents LLMs from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new LLM reasoning framework, Reasoning via Planning (RAP). RAP repurposes the LLM as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monte Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the LLM (as agent) incrementally builds a reasoning tree under the guidance of the LLM (as world model) and task-specific rewards, properly balancing exploration v.s. exploitation to achieve a high-reward reasoning path efficiently. We apply RAP to a variety of challenging reasoning problems, such as plan generation, math reasoning, and logical inference. Empirical results demonstrate the superiority of RAP over various strong baselines, including CoT and least-to-most prompting with self-consistency, e.g., RAP on LLaMA-33B surpasses CoT on GPT-4 with 33{\%} relative improvement in plan generation."
}

@inproceedings{htn2pddl,
author = {Alford, Ronald and Kuter, Ugur and Nau, Dana},
year = {2009},
month = {01},
pages = {1629-1634},
title = {Translating HTNs to PDDL: A small amount of domain knowledge can go a long way},
journal = {IJCAI International Joint Conference on Artificial Intelligence}
}

@article{huang2024understanding,
  title={Understanding the planning of {LLM} agents: A survey},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={arXiv preprint arXiv:2402.02716},
  year={2024}
}

@inproceedings{ijcai2023p839,
  title     = {Plansformer Tool: Demonstrating Generation of Symbolic Plans Using Transformers},
  author    = {Pallagani, Vishal and Muppasani, Bharath and Srivastava, Biplav and Rossi, Francesca and Horesh, Lior and Murugesan, Keerthiram and Loreggia, Andrea and Fabiano, Francesco and Joseph, Rony and Kethepalli, Yathin},
  booktitle = {{IJCAI-23}},
  publisher = {IJCAI Organization},
  editor    = {Edith Elkind},
  pages     = {7158--7162},
  year      = {2023},
  month     = {8},
  doi       = {10.24963/ijcai.2023/839}
}

@misc{mahdavi2024leveragingenvironmentinteractionautomated,
      title={Leveraging Environment Interaction for Automated {PDDL} Generation and Planning with Large Language Models}, 
      author={Sadegh Mahdavi and Raquel Aoki and Keyi Tang and Yanshuai Cao},
      year={2024},
      eprint={2407.12979},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.12979}, 
}

@inproceedings{oswald2024large,
  title={{Large Language Models as Planning Domain Generators}},
  author={Oswald, James and Srinivas, Kavitha and Kokel, Harsha and Lee, Junkyu and Katz, Michael and Sohrabi, Shirin},
  booktitle={Proceedings of the Int. Conference on Automated Planning and Scheduling},
  volume={34},
  pages={423--431},
  year={2024}
}

@inproceedings{robovqa2023arxiv,
    title={RoboVQA: Multimodal Long-Horizon Reasoning for Robotics},
    author={Pierre Sermanet and Tianli Ding and Jeffrey Zhao and Fei Xia and \ldots and Yuan Cao},
    booktitle={arXiv preprint arXiv:2311.00899},
    year={2023}
}

@inproceedings{rossetti2024learning,
  title={Learning General Policies for Planning through GPT Models},
  author={Rossetti, Nicholas and Tummolo, Massimiliano and Gerevini, Alfonso Emilio and Putelli, Luca and Serina, Ivan and Chiari, Mattia and Olivato, Matteo},
  booktitle={ICAPS},
  volume={34},
  pages={500--508},
  year={2024}
}

@inproceedings{silver2020pddlgym,
  author    = {Tom Silver and Rohan Chitnis},
  title     = {PDDLGym: Gym Environments from PDDL Problems},
  booktitle = {Int. Conference on Automated Planning and Scheduling (ICAPS) PRL Workshop},
  year      = {2020},
  url       = {https://github.com/tomsilver/pddlgym},
}

@inproceedings{silver2024generalized,
  author={Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Josh and Kaelbling, Leslie and Katz, Michael},
  title={Generalized planning in {PDDL} domains with pretrained large language models},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2024},
}

@article{survey-prompting-2023,
author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
title = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3560815},
doi = {10.1145/3560815},
abstract = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website including constantly updated survey and paperlist.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {195},
numpages = {35},
keywords = {Pre-trained language models, prompting}
}

@misc{valmeekam2023planbench,
      title={PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change}, 
      author={Karthik Valmeekam and Matthew Marquez and Alberto Olmo and Sarath Sreedharan and Subbarao Kambhampati},
      year={2023},
      eprint={2206.10498},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{vyas2025hive,
  title={{From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed Instructions In A Multi-Modal Jungle}},
  author={Kaustubh Vyas and Damien Graux and Yijun Yang and Sébastien Montella and Chenxin Diao and Wendi Zhou and Pavlos Vougiouklis and Ruofei Lai and Yang Ren and Keshuang Li and Jeff Z. Pan},
  journal={International Conference on Learning Representations (ICLR)},
  year={2025}
}

@misc{xie2023translatingnaturallanguageplanning,
      title={Translating Natural Language to Planning Goals with Large-Language Models}, 
      author={Yaqi Xie and Chen Yu and Tongyao Zhu and Jinbin Bai and Ze Gong and Harold Soh},
      year={2023},
      eprint={2302.05128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.05128}, 
}

@inproceedings{zhang-etal-2024-pddlego,
    title = "{PDDLEGO}: Iterative Planning in Textual Environments",
    author = "Zhang, Li  and
      Jansen, Peter  and
      Zhang, Tianyi  and
      Clark, Peter  and
      Callison-Burch, Chris  and
      Tandon, Niket",
    editor = "Bollegala, Danushka  and
      Shwartz, Vered",
    booktitle = "13th Joint Conf. on Lexical and Computational Semantics (*SEM 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.starsem-1.17",
    doi = "10.18653/v1/2024.starsem-1.17",
    pages = "212--221",
    abstract = "Planning in textual environments have been shown to be a long-standing challenge even for current models. A recent, promising line of work uses LLMs to generate a formal representation of the environment that can be solved by a symbolic planner. However, existing methods rely on a fully-observed environment where all entity states are initially known, so a one-off representation can be constructed, leading to a complete plan. In contrast, we tackle partially-observed environments where there is initially no sufficient information to plan for the end-goal. We propose PDDLEGO that iteratively construct a planning representation that can lead to a partial plan for a given sub-goal. By accomplishing the sub-goal, more information is acquired to augment the representation, eventually achieving the end-goal. We show that plans produced by few-shot PDDLEGO are 43{\%} more efficient than generating plans end-to-end on the Coin Collector simulation, with strong performance (98{\%}) on the more complex Cooking World simulation where end-to-end LLMs fail to generate coherent plans (4{\%}).",
}

@article{zuo2024planetarium,
  title={{Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages}},
  author={Zuo, Max and Velez, Francisco Piedrahita and Li, Xiaochen and Littman, Michael L and Bach, Stephen H},
  journal={arXiv:2407.03321},
  year={2024}
}

