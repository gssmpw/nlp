@misc{li2024longcontext,
      title={Long-context LLMs Struggle with Long In-context Learning}, 
      author={Tianle Li and Ge Zhang and Quy Duc Do and Xiang Yue and Wenhu Chen},
      year={2024},
      eprint={2404.02060},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@InProceedings{pmlr-v235-kambhampati24a,
  title = 	 {Position: {LLM}s Can’t Plan, But Can Help Planning in {LLM}-Modulo Frameworks},
  author =       {Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and \ldots and B Murthy, Anil},
  booktitle = 	 {ICML},
  pages = 	 {22895--22907},
  year = 	 {2024},
  volume = 	 {235},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/kambhampati24a/kambhampati24a.pdf},
  abstract = 	 {We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end format translators. We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.}
}


@misc{valmeekam2023planbench,
      title={PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change}, 
      author={Karthik Valmeekam and Matthew Marquez and Alberto Olmo and Sarath Sreedharan and Subbarao Kambhampati},
      year={2023},
      eprint={2206.10498},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{rossetti2024learning,
  title={Learning General Policies for Planning through GPT Models},
  author={Rossetti, Nicholas and Tummolo, Massimiliano and Gerevini, Alfonso Emilio and Putelli, Luca and Serina, Ivan and Chiari, Mattia and Olivato, Matteo},
  booktitle={ICAPS},
  volume={34},
  pages={500--508},
  year={2024}
}
@inproceedings{hao-etal-2023-reasoning,
    title = "Reasoning with Language Model is Planning with World Model",
    author = "Hao, Shibo  and
      Gu, Yi  and
      Ma, Haodi  and
      Hong, Joshua  and
      Wang, Zhen  and
      Wang, Daisy  and
      Hu, Zhiting",
    booktitle = "EMNLP",
    month = dec,
    year = "2023",
    address = "Singapore",
    doi = "10.18653/v1/2023.emnlp-main.507",
    pages = "8154--8173",
    abstract = "Large language models (LLMs) have shown remarkable reasoning capabilities, particularly with Chain-of-Thought-style prompts. However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks or performing complex math or logical reasoning. This is due to LLMs' absence of an internal world model for predicting world states (e.g., environment status, variable values) and simulating long-term action outcomes of actions. This prevents LLMs from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new LLM reasoning framework, Reasoning via Planning (RAP). RAP repurposes the LLM as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monte Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the LLM (as agent) incrementally builds a reasoning tree under the guidance of the LLM (as world model) and task-specific rewards, properly balancing exploration v.s. exploitation to achieve a high-reward reasoning path efficiently. We apply RAP to a variety of challenging reasoning problems, such as plan generation, math reasoning, and logical inference. Empirical results demonstrate the superiority of RAP over various strong baselines, including CoT and least-to-most prompting with self-consistency, e.g., RAP on LLaMA-33B surpasses CoT on GPT-4 with 33{\%} relative improvement in plan generation."
}
@inproceedings{oswald2024large,
  title={{Large Language Models as Planning Domain Generators}},
  author={Oswald, James and Srinivas, Kavitha and Kokel, Harsha and Lee, Junkyu and Katz, Michael and Sohrabi, Shirin},
  booktitle={Proceedings of the Int. Conference on Automated Planning and Scheduling},
  volume={34},
  pages={423--431},
  year={2024}
}

@article{zuo2024planetarium,
  title={{Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages}},
  author={Zuo, Max and Velez, Francisco Piedrahita and Li, Xiaochen and Littman, Michael L and Bach, Stephen H},
  journal={arXiv:2407.03321},
  year={2024}
}

@inproceedings{miglani2020nltopddl,
  title={{NltoPDDL: One-shot learning of PDDL models from natural language process manuals}},
  author={Miglani, Shivam and Yorke-Smith, Neil},
  booktitle={ICAPS’20 Workshop on Knowledge Engineering for Planning and Scheduling (KEPS’20)},
  year={2020},
  organization={ICAPS}
}

% LLM/Transformer with PDDL
@inproceedings{ijcai2023p839,
  title     = {Plansformer Tool: Demonstrating Generation of Symbolic Plans Using Transformers},
  author    = {Pallagani, Vishal and Muppasani, Bharath and Srivastava, Biplav and Rossi, Francesca and Horesh, Lior and Murugesan, Keerthiram and Loreggia, Andrea and Fabiano, Francesco and Joseph, Rony and Kethepalli, Yathin},
  booktitle = {{IJCAI-23}},
  publisher = {IJCAI Organization},
  editor    = {Edith Elkind},
  pages     = {7158--7162},
  year      = {2023},
  month     = {8},
  doi       = {10.24963/ijcai.2023/839}
}

% LLM/Transformer with PDDL
@article{Liu2023LLMPEL,
  title={LLM+P: Empowering Large Language Models with Optimal Planning Proficiency},
  author={B. Liu and Yuqian Jiang and Xiaohan Zhang and Qian Liu and Shiqi Zhang and Joydeep Biswas and Peter Stone},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.11477},
  url={https://api.semanticscholar.org/CorpusID:258298051}
}

% LLM/Transformer with PDDL
@misc{xie2023translatingnaturallanguageplanning,
      title={Translating Natural Language to Planning Goals with Large-Language Models}, 
      author={Yaqi Xie and Chen Yu and Tongyao Zhu and Jinbin Bai and Ze Gong and Harold Soh},
      year={2023},
      eprint={2302.05128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.05128}, 
}

@article{mirzadeh2024gsm,
  title={{GSM}-symbolic: Understanding the limitations of mathematical reasoning in large language models},
  author={Mirzadeh, Iman and Alizadeh, Keivan and Shahrokhi, Hooman and Tuzel, Oncel and Bengio, Samy and Farajtabar, Mehrdad},
  journal={arXiv preprint arXiv:2410.05229},
  year={2024}
}

%MyPDDL - no LLMs
@inbook{Strobel_2020,
   title={MyPDDL: Tools for Efficiently Creating PDDL Domains and Problems},
   ISBN={9783030385613},
   url={http://dx.doi.org/10.1007/978-3-030-38561-3_4},
   booktitle={Knowledge Engineering Tools and Techniques for AI Planning},
   publisher={Springer International Publishing},
   author={Strobel, Volker and Kirsch, Alexandra},
   year={2020},
   pages={67–90} }


%PDDLGym
@inproceedings{silver2020pddlgym,
  author    = {Tom Silver and Rohan Chitnis},
  title     = {PDDLGym: Gym Environments from PDDL Problems},
  booktitle = {Int. Conference on Automated Planning and Scheduling (ICAPS) PRL Workshop},
  year      = {2020},
  url       = {https://github.com/tomsilver/pddlgym},
}


@inproceedings{silver2024generalized,
  author={Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Josh and Kaelbling, Leslie and Katz, Michael},
  title={Generalized planning in {PDDL} domains with pretrained large language models},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2024},
}


@article{Helmert2009ConciseFR,
  title={Concise finite-domain representations for PDDL planning tasks},
  author={Malte Helmert},
  journal={Artif. Intell.},
  year={2009},
  volume={173},
  pages={503-535},
  url={https://api.semanticscholar.org/CorpusID:9377590}
}


@misc{collinsWong2022,
  doi = {10.48550/ARXIV.2205.05718},
  
  url = {https://arxiv.org/abs/2205.05718},
  
  author = {Collins, Katherine M. and Wong, Catherine and Feng, Jiahai and Wei, Megan and Tenenbaum, Joshua B.},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Symbolic Computation (cs.SC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks},
  
  publisher = {CogSci},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

% HTN to PDDL
@inproceedings{htn2pddl,
author = {Alford, Ronald and Kuter, Ugur and Nau, Dana},
year = {2009},
month = {01},
pages = {1629-1634},
title = {Translating HTNs to PDDL: A small amount of domain knowledge can go a long way},
journal = {IJCAI International Joint Conference on Artificial Intelligence}
}

% NL2plan
@inproceedings{
gestrin2024towards,
title={Towards Robust {LLM}-Driven Planning from Minimal Text Descriptions},
author={Elliot Gestrin and Marco Kuhlmann and Jendrik Seipp},
booktitle={Workshop on Human-Aware Explainable Planning},
year={2024},
url={https://openreview.net/forum?id=NmzHuV101q}
}

% Dynamic Planning LLM
@misc{dagan2023dynamicplanningllm,
      title={Dynamic Planning with a LLM}, 
      author={Gautier Dagan and Frank Keller and Alex Lascarides},
      year={2023},
      eprint={2308.06391},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.06391}, 
}

%AutoPlanBench
@misc{AutoPlanBench,
      title={AutoPlanBench: Automatically generating benchmarks for LLM planners from PDDL}, 
      author={Katharina Stein and Daniel Fišer and Jörg Hoffmann and Alexander Koller},
      year={2024},
      eprint={2311.09830},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.09830}, 
}


% Pretrain, Prompt, and Predict
@article{survey-prompting-2023,
author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
title = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3560815},
doi = {10.1145/3560815},
abstract = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website including constantly updated survey and paperlist.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {195},
numpages = {35},
keywords = {Pre-trained language models, prompting}
}

% PromptEng - Graux
@inproceedings{graux2024prompteng,
  title={{[PromptEng] First International Workshop on Prompt Engineering for Pre-Trained Language Models}},
  author={Graux, Damien and Montella, S{\'e}bastien and Jabeen, Hajira and Gardent, Claire and Pan, Jeff Z},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1311--1312},
  year={2024}
}

%PDDL-Lego
@inproceedings{zhang-etal-2024-pddlego,
    title = "{PDDLEGO}: Iterative Planning in Textual Environments",
    author = "Zhang, Li  and
      Jansen, Peter  and
      Zhang, Tianyi  and
      Clark, Peter  and
      Callison-Burch, Chris  and
      Tandon, Niket",
    editor = "Bollegala, Danushka  and
      Shwartz, Vered",
    booktitle = "13th Joint Conf. on Lexical and Computational Semantics (*SEM 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.starsem-1.17",
    doi = "10.18653/v1/2024.starsem-1.17",
    pages = "212--221",
    abstract = "Planning in textual environments have been shown to be a long-standing challenge even for current models. A recent, promising line of work uses LLMs to generate a formal representation of the environment that can be solved by a symbolic planner. However, existing methods rely on a fully-observed environment where all entity states are initially known, so a one-off representation can be constructed, leading to a complete plan. In contrast, we tackle partially-observed environments where there is initially no sufficient information to plan for the end-goal. We propose PDDLEGO that iteratively construct a planning representation that can lead to a partial plan for a given sub-goal. By accomplishing the sub-goal, more information is acquired to augment the representation, eventually achieving the end-goal. We show that plans produced by few-shot PDDLEGO are 43{\%} more efficient than generating plans end-to-end on the Coin Collector simulation, with strong performance (98{\%}) on the more complex Cooking World simulation where end-to-end LLMs fail to generate coherent plans (4{\%}).",
}

%Survey planning with LLMs.
@article{huang2024understanding,
  title={Understanding the planning of {LLM} agents: A survey},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={arXiv preprint arXiv:2402.02716},
  year={2024}
}
 % PLM + PDDL
@inproceedings{
silver2022pddl,
title={{PDDL} Planning with Pretrained Large Language Models},
author={Tom Silver and Varun Hariprasad and Reece S Shuttleworth and Nishanth Kumar and Tom{\'a}s Lozano-P{\'e}rez and Leslie Pack Kaelbling},
booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop},
year={2022},
url={https://openreview.net/forum?id=1QMMUB4zfl}
}

@misc{mahdavi2024leveragingenvironmentinteractionautomated,
      title={Leveraging Environment Interaction for Automated {PDDL} Generation and Planning with Large Language Models}, 
      author={Sadegh Mahdavi and Raquel Aoki and Keyi Tang and Yanshuai Cao},
      year={2024},
      eprint={2407.12979},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.12979}, 
}

@inproceedings{frances2017purely,
  title={Purely declarative action descriptions are overrated: Classical planning with simulators},
  author={Frances, Guillem and Ram{\'\i}rez J{\'a}vega, Miquel and Lipovetzky, Nir and Geffner, Hector},
  booktitle={26th Int. Joint Conf. on Artificial Intelligence; Aug 19-25; Melbourne, Australia. p. 4294-301.},
  year={2017},
  organization={IJCAI Organization}
}

@inproceedings{lipovetzky2017best,
  title={Best-first width search: Exploration and exploitation in classical planning},
  author={Lipovetzky, Nir and Geffner, Hector},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  number={1},
  year={2017}
}

@inproceedings{lipovetzky2017polynomial,
  title={A polynomial planning algorithm that beats LAMA and FF},
  author={Lipovetzky, Nir and Geffner, Hector},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={27},
  pages={195--199},
  year={2017}
}


@inproceedings{robovqa2023arxiv,
    title={RoboVQA: Multimodal Long-Horizon Reasoning for Robotics},
    author={Pierre Sermanet and Tianli Ding and Jeffrey Zhao and Fei Xia and \ldots and Yuan Cao},
    booktitle={arXiv preprint arXiv:2311.00899},
    year={2023}
}

@article{chen2024backbone,
  title={A Backbone for Long-Horizon Robot Task Understanding},
  author={Chen, Xiaoshuai and Chen, Wei and Lee, Dongmyoung and Ge, Yukun and Rojas, Nicolas and Kormushev, Petar},
  journal={arXiv:2408.01334},
  year={2024}
}

@inproceedings{popovic-2015-chrf,
    title = "chr{F}: character n-gram {F}-score for automatic {MT} evaluation",
    author = "Popovi{\'c}, Maja",
    booktitle = "Tenth Workshop on Statistical Machine Translation",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/W15-3049",
    pages = "392--395",
}

@article{evtikhiev2023out,
  title={Out of the bleu: how should we assess quality of the code generation models?},
  author={Evtikhiev, Mikhail and Bogomolov, Egor and Sokolov, Yaroslav and Bryksin, Timofey},
  journal={Journal of Systems and Software},
  volume={203},
  pages={111741},
  year={2023},
  publisher={Elsevier}
}

@article{vyas2025hive,
  title={{From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed Instructions In A Multi-Modal Jungle}},
  author={Kaustubh Vyas and Damien Graux and Yijun Yang and Sébastien Montella and Chenxin Diao and Wendi Zhou and Pavlos Vougiouklis and Ruofei Lai and Yang Ren and Keshuang Li and Jeff Z. Pan},
  journal={International Conference on Learning Representations (ICLR)},
  year={2025}
}
