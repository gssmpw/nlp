@misc{entmax,
      title={Domain Randomization via Entropy Maximization}, 
      author={Gabriele Tiboni and Pascal Klink and Jan Peters and Tatiana Tommasi and Carlo D'Eramo and Georgia Chalvatzaki},
      year={2024},
      eprint={2311.01885},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.01885}, 
}

@article{pinto2017asymmetric,
  author       = {Lerrel Pinto and
                  Marcin Andrychowicz and
                  Peter Welinder and
                  Wojciech Zaremba and
                  Pieter Abbeel},
  title        = {Asymmetric Actor Critic for Image-Based Robot Learning},
  journal      = {CoRR},
  volume       = {abs/1710.06542},
  year         = {2017},
  url          = {http://arxiv.org/abs/1710.06542},
  eprinttype    = {arXiv},
  eprint       = {1710.06542},
  timestamp    = {Mon, 13 Aug 2018 16:46:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1710-06542.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{schulman2017proximal,
  author       = {John Schulman and
                  Filip Wolski and
                  Prafulla Dhariwal and
                  Alec Radford and
                  Oleg Klimov},
  title        = {Proximal Policy Optimization Algorithms},
  journal      = {CoRR},
  volume       = {abs/1707.06347},
  year         = {2017},
  url          = {http://arxiv.org/abs/1707.06347},
  eprinttype    = {arXiv},
  eprint       = {1707.06347},
  timestamp    = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{forge,
      title={FORGE: Force-Guided Exploration for Robust Contact-Rich Manipulation under Uncertainty}, 
      author={Michael Noseworthy and Bingjie Tang and Bowen Wen and Ankur Handa and Nicholas Roy and Dieter Fox and Fabio Ramos and Yashraj Narang and Iretiayo Akinola},
      year={2024},
      eprint={2408.04587},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2408.04587}, 
}

@article{bhpn,
author = {Kaelbling, Leslie and Lozano-Perez, Tomas},
year = {2013},
month = {08},
pages = {1194-1227},
title = {Integrated task and motion planning in belief space},
volume = {32},
journal = {The International Journal of Robotics Research},
doi = {10.1177/0278364913484072}
}


@software{rozet2022zuko,
  title = {{Zuko}: Normalizing flows in PyTorch},
  author = {Rozet, François and others},
  year = {2022},
  doi = {10.5281/zenodo.7625672},
  license = {MIT},
  url = {https://pypi.org/project/zuko},
}


@misc{wen2024foundationposeunified6dpose,
      title={FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects}, 
      author={Bowen Wen and Wei Yang and Jan Kautz and Stan Birchfield},
      year={2024},
      eprint={2312.08344},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.08344}, 
}

@misc{megapose,
      title={MegaPose: 6D Pose Estimation of Novel Objects via Render \& Compare}, 
      author={Yann Labbé and Lucas Manuelli and Arsalan Mousavian and Stephen Tyree and Stan Birchfield and Jonathan Tremblay and Justin Carpentier and Mathieu Aubry and Dieter Fox and Josef Sivic},
      year={2022},
      eprint={2212.06870},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.06870}, 
}

@misc{mishra2023generativeskillchaininglonghorizon,
      title={Generative Skill Chaining: Long-Horizon Skill Planning with Diffusion Models}, 
      author={Utkarsh A. Mishra and Shangjie Xue and Yongxin Chen and Danfei Xu},
      year={2023},
      eprint={2401.03360},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2401.03360}, 
}

@article{maple,
  author       = {Soroush Nasiriany and
                  Huihan Liu and
                  Yuke Zhu},
  title        = {Augmenting Reinforcement Learning with Behavior Primitives for Diverse
                  Manipulation Tasks},
  journal      = {CoRR},
  volume       = {abs/2110.03655},
  year         = {2021},
  url          = {https://arxiv.org/abs/2110.03655},
  eprinttype    = {arXiv},
  eprint       = {2110.03655},
  timestamp    = {Thu, 21 Oct 2021 16:20:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2110-03655.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{latent_mdp,
  author       = {Jeongyeol Kwon and
                  Yonathan Efroni and
                  Constantine Caramanis and
                  Shie Mannor},
  title        = {{RL} for Latent MDPs: Regret Guarantees and a Lower Bound},
  journal      = {CoRR},
  volume       = {abs/2102.04939},
  year         = {2021},
  url          = {https://arxiv.org/abs/2102.04939},
  eprinttype    = {arXiv},
  eprint       = {2102.04939},
  timestamp    = {Thu, 18 Feb 2021 15:26:00 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2102-04939.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ssreplan,
  author    = {Caelan Reed Garrett and
               Chris Paxton and
               Tom{\'{a}}s Lozano{-}P{\'{e}}rez and
               Leslie Pack Kaelbling and
               Dieter Fox},
  title     = {Online Replanning in Belief Space for Partially Observable Task and
               Motion Problems},
  journal   = {CoRR},
  volume    = {abs/1911.04577},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.04577},
  eprinttype = {arXiv},
  eprint    = {1911.04577},
  timestamp = {Mon, 02 Dec 2019 13:44:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-04577.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{zhang2020modular,
title={A modular robotic arm control stack for research: Franka-interface and frankapy},
author={Zhang, Kevin and Sharma, Mohit and Liang, Jacky and Kroemer, Oliver},
journal={arXiv preprint arXiv:2011.02398},
year={2020}
}

@inproceedings{
    tang2023industreal,
    author = {Bingjie Tang and Michael A Lin and Iretiayo Akinola and Ankur Handa and Gaurav S Sukhatme and Fabio Ramos and Dieter Fox and Yashraj Narang},
    title = {IndustReal: Transferring contact-rich assembly tasks from simulation to reality},
    booktitle = {Robotics: Science and Systems},
    year = {2023}
}

@book{rl_is_hard,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}



@article{tunyasuvunakool2020,
         title = {dm\_control: Software and tasks for continuous control},
         journal = {Software Impacts},
         volume = {6},
         pages = {100022},
         year = {2020},
         issn = {2665-9638},
         doi = {https://doi.org/10.1016/j.simpa.2020.100022},
         url = {https://www.sciencedirect.com/science/article/pii/S2665963820300099},
         author = {Saran Tunyasuvunakool and Alistair Muldal and Yotam Doron and
                   Siqi Liu and Steven Bohez and Josh Merel and Tom Erez and
                   Timothy Lillicrap and Nicolas Heess and Yuval Tassa},
}

@article{Jin2023,
  author    = {Jin, Peng and Lin, Yu and Song, Yu and Li, Tao and Yang, Wei},
  title     = {Vision-force-fused curriculum learning for robotic contact-rich assembly tasks},
  journal   = {Frontiers in Neurorobotics},
  volume    = {17},
  pages     = {1280773},
  year      = {2023},
  month     = oct,
  doi       = {10.3389/fnbot.2023.1280773},
  pmid      = {37867617},
  pmcid     = {PMC10590057},
}

@inproceedings{rezende2015variational,
  title={Variational Inference with Normalizing Flows},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir},
  booktitle={Proceedings of the 32nd International Conference on Machine Learning (ICML)},
  year={2015},
  organization={PMLR}
}

@inproceedings{durkan2019neural,
  title={Neural Spline Flows},
  author={Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={32},
  year={2019}
}

@article{original_dr,
  author       = {Xue Bin Peng and
                  Marcin Andrychowicz and
                  Wojciech Zaremba and
                  Pieter Abbeel},
  title        = {Sim-to-Real Transfer of Robotic Control with Dynamics Randomization},
  journal      = {CoRR},
  volume       = {abs/1710.06537},
  year         = {2017},
  url          = {http://arxiv.org/abs/1710.06537},
  eprinttype    = {arXiv},
  eprint       = {1710.06537},
  timestamp    = {Mon, 13 Aug 2018 16:47:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1710-06537.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{understanding_dr,
  author       = {Xiaoyu Chen and
                  Jiachen Hu and
                  Chi Jin and
                  Lihong Li and
                  Liwei Wang},
  title        = {Understanding Domain Randomization for Sim-to-real Transfer},
  journal      = {CoRR},
  volume       = {abs/2110.03239},
  year         = {2021},
  url          = {https://arxiv.org/abs/2110.03239},
  eprinttype    = {arXiv},
  eprint       = {2110.03239},
  timestamp    = {Sat, 03 Aug 2024 16:25:27 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2110-03239.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{normflows_adaptive_dr,
      title={Gradual Domain Adaptation via Normalizing Flows}, 
      author={Shogo Sagawa and Hideitsu Hino},
      year={2024},
      eprint={2206.11492},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2206.11492}, 
}

@article{bayessim,
  author       = {Fabio Ramos and
                  Rafael Carvalhaes Possas and
                  Dieter Fox},
  title        = {BayesSim: adaptive domain randomization via probabilistic inference
                  for robotics simulators},
  journal      = {CoRR},
  volume       = {abs/1906.01728},
  year         = {2019},
  url          = {http://arxiv.org/abs/1906.01728},
  eprinttype    = {arXiv},
  eprint       = {1906.01728},
  timestamp    = {Tue, 18 Oct 2022 08:35:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1906-01728.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gaussian_dr,
  author       = {Melissa Mozifian and
                  Juan Camilo Gamboa Higuera and
                  David Meger and
                  Gregory Dudek},
  title        = {Learning Domain Randomization Distributions for Transfer of Locomotion
                  Policies},
  journal      = {CoRR},
  volume       = {abs/1906.00410},
  year         = {2019},
  url          = {http://arxiv.org/abs/1906.00410},
  eprinttype    = {arXiv},
  eprint       = {1906.00410},
  timestamp    = {Thu, 13 Jun 2019 13:36:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1906-00410.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{adr,
  author       = {OpenAI and
                  Ilge Akkaya and
                  Marcin Andrychowicz and
                  Maciek Chociej and
                  Mateusz Litwin and
                  Bob McGrew and
                  Arthur Petron and
                  Alex Paino and
                  Matthias Plappert and
                  Glenn Powell and
                  Raphael Ribas and
                  Jonas Schneider and
                  Nikolas Tezak and
                  Jerry Tworek and
                  Peter Welinder and
                  Lilian Weng and
                  Qiming Yuan and
                  Wojciech Zaremba and
                  Lei Zhang},
  title        = {Solving Rubik's Cube with a Robot Hand},
  journal      = {CoRR},
  volume       = {abs/1910.07113},
  year         = {2019},
  url          = {http://arxiv.org/abs/1910.07113},
  eprinttype    = {arXiv},
  eprint       = {1910.07113},
  timestamp    = {Fri, 08 Nov 2019 12:50:47 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1910-07113.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{tampura,
      title={Partially Observable Task and Motion Planning with Uncertainty and Risk Awareness}, 
      author={Aidan Curtis and George Matheos and Nishad Gothoskar and Vikash Mansinghka and Joshua Tenenbaum and Tomás Lozano-Pérez and Leslie Pack Kaelbling},
      year={2024},
      eprint={2403.10454},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2403.10454}, 
}

@misc{dynamic_compliance,
      title={Bridging the Sim-to-Real Gap with Dynamic Compliance Tuning for Industrial Insertion}, 
      author={Xiang Zhang and Masayoshi Tomizuka and Hui Li},
      year={2024},
      eprint={2311.07499},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2311.07499}, 
}

@misc{industreal,
      title={IndustReal: Transferring Contact-Rich Assembly Tasks from Simulation to Reality}, 
      author={Bingjie Tang and Michael A. Lin and Iretiayo Akinola and Ankur Handa and Gaurav S. Sukhatme and Fabio Ramos and Dieter Fox and Yashraj Narang},
      year={2023},
      eprint={2305.17110},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2305.17110}, 
}

@inproceedings{luo2021learning,
  title={A learning approach to robot-agnostic force-guided high precision assembly},
  author={Luo, Jieliang and Li, Hui},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2151--2157},
  year={2021},
  organization={IEEE}
}

@article{zhu2020ingredients,
  title={The ingredients of real-world robotic reinforcement learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}
@inproceedings{schoettler2020deep,
  title={Deep reinforcement learning for industrial insertion tasks with visual inputs and natural rewards},
  author={Schoettler, Gerrit and Nair, Ashvin and Luo, Jianlan and Bahl, Shikhar and Ojea, Juan Aparicio and Solowjow, Eugen and Levine, Sergey},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5548--5555},
  year={2020},
  organization={IEEE}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{valassakis2020crossing,
  title={Crossing the gap: A deep dive into zero-shot sim-to-real transfer for dynamics},
  author={Valassakis, Eugene and Ding, Zihan and Johns, Edward},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5372--5379},
  year={2020},
  organization={IEEE}
}

@article{muratore2019assessing,
  title={Assessing transferability from simulation to reality for reinforcement learning},
  author={Muratore, Fabio and Gienger, Michael and Peters, Jan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={4},
  pages={1172--1183},
  year={2019},
  publisher={IEEE}
}

@inproceedings{josifovski2022analysis,
  title={Analysis of Randomization Effects on sim2real transfer in reinforcement learning for robotic manipulation tasks},
  author={Josifovski, Josip and Malmir, Mohammadhossein and Klarmann, Noah and {\v{Z}}agar, Bare Luka and Navarro-Guerrero, Nicol{\'a}s and Knoll, Alois},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={10193--10200},
  year={2022},
  organization={IEEE}
}
@article{DBLP:journals/corr/abs-1810-12282,
  author       = {Charles Packer and
                  Katelyn Gao and
                  Jernej Kos and
                  Philipp Kr{\"{a}}henb{\"{u}}hl and
                  Vladlen Koltun and
                  Dawn Song},
  title        = {Assessing Generalization in Deep Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1810.12282},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.12282},
  eprinttype    = {arXiv},
  eprint       = {1810.12282},
  timestamp    = {Thu, 01 Nov 2018 18:03:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-12282.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{isaaclab,
   author={Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad and Mandlekar, Ajay and Babich, Buck and State, Gavriel and Hutter, Marco and Garg, Animesh},
   journal={IEEE Robotics and Automation Letters},
   title={Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments},
   year={2023},
   volume={8},
   number={6},
   pages={3740-3747},
   doi={10.1109/LRA.2023.3270034}
}

@misc{rezende2016variationalinferencenormalizingflows,
      title={Variational Inference with Normalizing Flows}, 
      author={Danilo Jimenez Rezende and Shakir Mohamed},
      year={2016},
      eprint={1505.05770},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1505.05770}, 
}


@InProceedings{pmlr-v164-muratore22a,
  title = 	 {Neural Posterior Domain Randomization},
  author =       {Muratore, Fabio and Gruner, Theo and Wiese, Florian and Belousov, Boris and Gienger, Michael and Peters, Jan},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {1532--1542},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v164/muratore22a/muratore22a.pdf},
  url = 	 {https://proceedings.mlr.press/v164/muratore22a.html},
  abstract = 	 {Combining domain randomization and reinforcement learning is a widely used approach to obtain control policies that can bridge the gap between simulation and reality. However, existing methods make limiting assumptions on the form of the domain parameter distribution which prevents them from utilizing the full power of domain randomization. Typically, a restricted family of probability distributions (e.g., normal or uniform) is chosen a priori for every parameter. Furthermore, straightforward approaches based on deep learning require differentiable simulators, which are either not available or can only simulate a limited class of systems. Such rigid assumptions diminish the applicability of domain randomization in robotics. Building upon recently proposed neural likelihood-free inference methods, we introduce Neural Posterior Domain Randomization (NPDR), an algorithm that alternates between learning a policy from a randomized simulator and adapting the posterior distribution over the simulator’s parameters in a Bayesian fashion. Our approach only requires a parameterized simulator, coarse prior ranges, a policy (optionally with optimization routine), and a small set of real-world observations. Most importantly, the domain parameter distribution is not restricted to a specific family, parameters can be correlated, and the simulator does not have to be differentiable. We show that the presented method is able to efficiently adapt the posterior over the domain parameters to closer match the observed dynamics. Moreover, we demonstrate that NPDR can learn transferable policies using fewer real-world rollouts than comparable algorithms.}
}

@article{selfpaced,
  author       = {Pascal Klink and
                  Hany Abdulsamad and
                  Boris Belousov and
                  Carlo D'Eramo and
                  Jan Peters and
                  Joni Pajarinen},
  title        = {A Probabilistic Interpretation of Self-Paced Learning with Applications
                  to Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/2102.13176},
  year         = {2021},
  url          = {https://arxiv.org/abs/2102.13176},
  eprinttype    = {arXiv},
  eprint       = {2102.13176},
  timestamp    = {Tue, 02 Mar 2021 12:11:01 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2102-13176.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{liu2017stein,
  title={Stein variational policy gradient},
  author={Liu, Yang and Ramachandran, Prajit and Liu, Qiang and Peng, Jian},
  journal={arXiv preprint arXiv:1704.02399},
  year={2017}
}

@inproceedings{mehta2020active,
  title={Active domain randomization},
  author={Mehta, Bhairav and Diaz, Manfred and Golemo, Florian and Pal, Christopher J and Paull, Liam},
  booktitle={Conference on Robot Learning},
  pages={1162--1176},
  year={2020},
  organization={PMLR}
}

@article{loaiza2017maximum,
  title={Maximum entropy flow networks},
  author={Loaiza-Ganem, Gabriel and Gao, Yuanjun and Cunningham, John P},
  journal={arXiv preprint arXiv:1701.03504},
  year={2017}
}

@article{gothoskar2023bayes3d,
  title={Bayes3D: fast learning and inference in structured generative models of 3D objects and scenes},
  author={Gothoskar, Nishad and Ghavami, Matin and Li, Eric and Curtis, Aidan and Noseworthy, Michael and Chung, Karen and Patton, Brian and Freeman, William T and Tenenbaum, Joshua B and Klukas, Mirko and others},
  journal={arXiv preprint arXiv:2312.08715},
  year={2023}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{del2006sequential,
  title={Sequential monte carlo samplers},
  author={Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={68},
  number={3},
  pages={411--436},
  year={2006},
  publisher={Oxford University Press}
}