% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\usepackage{graphicx} %
% \urlstyle{rm} %
% \def\UrlFont{\rm}  %
\usepackage{natbib}  %
\usepackage{caption} %
\usepackage{algorithm}
\usepackage{listings}
\usepackage{algorithmic}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[outdir=./]{epstopdf}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfloat}
\usepackage{newfloat}
\usepackage{graphicx}
\usepackage{svg} % svg
\usepackage[normalem]{ulem}
\usepackage{framed}
\usepackage{mdframed}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{float}
\usepackage{hyperref}

\definecolor{shadecolor}{gray}{0.9}

\DeclareMathOperator*{\argmax}{arg\,max}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}\hspace{-2.5pt}}
\newcommand{\wontfix}{\rlap{$\square$}{\large\hspace{1pt}\xmark}}

\newcommand{\quanming}[1]{{\color{blue} \textbf{QM}. #1}}
\newcommand{\yong}[1]{{\color{red} \textbf{Yong}: #1}}
\newcommand{\gao}[1]{{\color{pink} \textbf{Gao}: #1}}
\newcommand{\chen}[1]{{\color{red} \textbf{Chen}: #1}}
\newcommand{\chenf}[1]{\footnote{+chen+:#1}}
\newcommand{\yongrevised}[1]{{\color{pink} \textbf{Yong}: #1}}
\newcommand{\req}[1]{\textcolor{black}{#1}}
\newcommand{\rev}[1]{#1}
\newcommand{\yantex}[1]{{\color{black} \textbf{Yan}: #1}}
\newcommand{\yanf}[1]{\footnote{+yanf+:#1}}
\newcommand{\reviewf}[1]{\footnote{\color{blue}+rev+:#1}}


\newtheorem{mdefinition}{Definition}

\newtheorem{problem}{Problem}
\newcommand{\para}[1]{{\vspace{4pt} \bf \noindent #1 \hspace{0pt}}}

\setlength{\belowcaptionskip}{-0.1cm} 

\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline  \\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline \\\arraybackslash\hspace{0pt}}m{#1}}


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}
}

\usepackage{authblk}

\title{PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models}

\author[ ]{Yu Meng$^{1}$\thanks{Equal contribution.}}
\author[1*]{Kaiyuan Li}
\author[1,3]{Chenran Huang}
\author[2]{Chen Gao}
\author[1]{Xinlei Chen}
\author[2]{Yong Li}
\author[1]{Xiaoping Zhang}

% \affil[1]{Shenzhen International Graduate School, Tsinghua University \quad $^2$Tsinghua University}
\affil[1]{Shenzhen International Graduate School, Tsinghua University}
\affil[2]{Tsinghua University \quad $^3$Tongji University}

\begin{document}
\maketitle
\begin{abstract}
Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across a range of multimodal tasks. However, their inference efficiency is constrained by the large number of visual tokens processed during decoding. To address this challenge, we propose \textbf{P}er-\textbf{L}ayer \textbf{P}er-\textbf{H}ead Vision Token \textbf{P}runing (\textbf{PLPHP}), a two-level fine-grained pruning method including Layer-Level Retention Rate Allocation and Head-Level Vision Token Pruning. Motivated by the \textit{Vision Token Re-attention} phenomenon across decoder layers, we dynamically adjust token retention rates layer by layer. Layers that exhibit stronger attention to visual information preserve more vision tokens, while layers with lower vision attention are aggressively pruned. Furthermore, PLPHP applies pruning at the attention head level, enabling different heads within the same layer to independently retain critical context. Experiments on multiple benchmarks demonstrate that PLPHP delivers an 18\% faster decoding speed and reduces the Key-Value Cache (KV Cache) size by over 50\%, all at the cost of 0.46\% average performance drop, while also achieving notable performance improvements in multi-image tasks. These results highlight the effectiveness of fine-grained token pruning and contribute to advancing the efficiency and scalability of LVLMs. Our source code will be made publicly available.
\end{abstract}



\input{1.intro}
\input{2.related}
\input{3.method}
\input{4.exp}



\section{Conclusion}\label{sec::conclusion}
In this work, we introduce PLPHP, a two-level pruning method designed to improve the efficiency of LVLMs with Layer-Level Retention Rate Allocation and Head-Level Vision Token Pruning. Comprehensive experiments demonstrate that PLPHP outperforms existing pruning methods, achieving a 18\% decoding acceleration, over 50\% KV Cache compression and only 0.46\% performance degradation, with improvements on multi-image tasks. We believe our work contributes to efficient LVLMs, further promotes their applications, and improves the user experience.

\clearpage



\bibliography{bibliography}

\appendix
\input{6.appendix}

\end{document}
