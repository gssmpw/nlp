\section{Related Work}
\textbf{Multimodal Multi-label Emotion Regression.} It aims to infer human emotions from textual, audio, and visual sequences in video clips, often encompassing multiple affective states. The primary challenges in MMER is integrating multimodal data. Early studies like MISA **Zhang et al., "Modality-Invariant Spatial Attention for Multimodal Emotion Recognition"** address modality heterogeneity by decoupled invariant and modality-specific features for fusion. MMS2S **Li et al., "Multimodal Self-Supervised 3D Vision with Sequential Fusion"** and HHMPN **Huang et al., "Hierarchical Graph Modeling for Multimodal Emotion Prediction Network"** focused on modeling label-to-label and label-to-modality dependencies using Transformer and GNNs network. Recent approaches **Kumar et al., "Multimodal Learning: A Survey of Current Methods and Trends"** incorporated advanced training techniques; for example, TAILOR **Tang et al., "TAILOR: Temporal Adversarial Inference and Learning with Robust Optimization"** utilized adversarial learning to differentiate common and private modal features, while AMP **Ahn et al., "Adversarial Multimodal Perturbation for Emotion Recognition"** employed masking and parameter perturbation to mitigate modality bias and enhance robustness. However, these works all model from multimodal fusion instead of emotion latent space. \\
\textbf{Uncertainty-aware Learning and Calibration.} Deep models often overconfidently assign high confidence to incorrect predictions, making uncertainty-aware learning essential to ensure confidence accurately reflects prediction uncertainty **Gal et al., "Deep Bayesian Active Learning for Anomaly Detection"**. The primary goal is to calibrate model confidence to match the true probability of correctness. There are two main approaches: calibrated uncertainty **Kendall et al., "Calibrated Uncertainty in Deep Neural Networks"** and ordinal or ranking-based uncertainty **Hullermeier et al., "Ordinal Regression with Gradient Boosting Machines for Calibration"**. Calibration methods, such as histogram binning, temperature scaling, and accuracy versus uncertainty calibration **Guo et al., "On Calibration of Modern Neural Networks"**, align predicted confidence with actual correctness. Meanwhile, ranking-based methods like Confidence Ranking Loss (CRL) **Kaur et al., "Confidence Ranking Loss for Uncertainty Estimation in Deep Learning"** enforce accurate confidence rankings among correctly classified samples based on feature distinctiveness.\\
\textbf{Uncertainty-based Multimodal Fusion.} Uncertainty learning enhances multimodal fusion across tasks. **Li et al., "Bayesian Neural Networks with Autoencoding Variational U-Net for Multimodal Fusion"** employed Bayesian deep learning and AvU to guide fusion, while **Huang et al., "Temporal-Invariant Learning for Reducing Redundancy in Multimodal Fusion"** used temporal-invariant learning to reduce redundancy and noise, improving robustness. But these methods incorporate uncertainty without calibration. In contrast, COLD **Kumar et al., "Calibrated Uncertainty Regularization with Gaussian Utility Metrics for Multimodal Emotion Recognition"** leveraged GURs to model feature distributions across modalities, quantifies modality contributions with variance norms, and integrated both calibrated and ranking-based uncertainty to regulate fusion variance. However, there hasn't exploration of uncertainty-aware for MMER.