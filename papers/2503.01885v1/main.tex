%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[accepted]{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{observation}{Observation}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{url}
\usepackage{csquotes}
\usepackage{tikz}
\usepackage{comment}
\usepackage{xcolor}
\usepackage{wrapfig}
\usepackage{longtable}
\usepackage{enumitem}


\allowdisplaybreaks
\newcommand{\luise}[1]{\textcolor{violet}{[Luise: #1]}}
\newcommand{\mc}{\mathcal}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Learning Policy Committees with Diverse Tasks}

\begin{document}

\twocolumn[
\icmltitle{Learning Policy Committees for Effective Personalization\\ in MDPs with Diverse Tasks}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Luise Ge}{yyy}
\icmlauthor{Michael Lanier}{yyy}
\icmlauthor{Anindya Sarkar}{yyy}
\icmlauthor{Bengisu Guresti}{yyy}
\icmlauthor{Yevgeniy Vorobeychik}{yyy}
\icmlauthor{Chongjie Zhang}{yyy}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Department of Computer Science \& Engineering, Washington University in St. Louis}
\icmlcorrespondingauthor{Luise Ge}{g.luise@wustl.edu}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
%Numerous problem domains in reinforcement learning (RL) entail consideration of a broad array of learning tasks, including multi-task and multi-objective learning, as well as meta-RL, among others.
Many dynamic decision problems, such as robotic control, involve a series of tasks, many of which are unknown at training time.
Typical approaches for these problems, such as multi-task and meta reinforcement learning, do not generalize well when the tasks are diverse.
On the other hand, approaches that aim to tackle task diversity, such as using task embedding as policy context and task clustering, typically lack performance guarantees and require a large number of training tasks.
%We propose a general framework to address this issue.
To address these challenges, we propose a novel approach for learning a \emph{policy committee} that includes at least one near-optimal policy with high probability for tasks encountered during execution.
%In our framework, the goal is to learn a set of policies---a \emph{policy committee}---such that at least one is near-optimal for most tasks that may be encountered at execution time.
%While we show that even a special case of this problem is inapproximable, we present two effective algorithmic approaches for it. The first of these yields provable approximation guarantees, albeit in low-dimensional settings (the best we can do due to inapproximability), whereas the second is a general and practical gradient-based approach.
%Choosing which policy committee member to take care of which task is a nontrivial problem, and in this paper we propose two effective algorithmic approaches for it. 
While we show that this problem is in general inapproximable, we present two practical algorithmic solutions.
The first yields provable approximation and task sample complexity guarantees when tasks are low-dimensional (the best we can do due to inapproximability), whereas the second is a general and practical gradient-based approach. In addition, we provide a provable sample complexity bound for few-shot learning.
%we make a formal connection to meta-learning by using our learned policy committees to achieve provable regret and sample complexity bounds on few-shot learning.
Our experiments 
%in personalized and multi-task RL settings 
on MuJoCo and Meta-World show that the proposed approach outperforms state-of-the-art multi-task, meta-, and task clustering baselines in training, generalization, and few-shot learning, often by a large margin.
%on training and test tasks, as well as in few-shot learning, often by a large margin.
%multi-objective, multi-task, personalized, and meta-RL, as well as multi-objective RLHF show that the proposed approaches are either competitive with, or outperform state-of-the-art methods in each of these domains.
\end{abstract}

\input{intro}
\input{relwork}
\input{model}
\input{approach}
%\input{fewshot}
\input{exp}


\section{Conclusion and Limitations}
We developed a general algorithmic framework for learning policy committees for effective generalization and few-shot learning in multi-task settings with diverse tasks that may be unknown at training time.
We showed that our approach is theoretically grounded, and outperforms MTRL, meta-RL, and personalized RL baselines in both training, and zero-shot and few-shot test evaluations, often by a large margin.
Nevertheless, our approach exhibits several important limitations.
First, it requires tasks to be parametric, and while we demonstrate how LLMs can be used to effectively obtain task embeddings in the Meta-World environments, it is not clear how to do so generally.
Second, it includes a scalar hyperparameter, $\epsilon$, which determines how we evaluate the quality of task coverage and needs to be adjusted separately for each environment, although this hyperparameter is easily tunable in practice.





\bibliography{references}
\bibliographystyle{icml2025}

\input{appendix}



\end{document}



