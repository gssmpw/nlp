@inproceedings{Hasanbeig2021DeepSynthAS,
  title={DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep Reinforcement Learning},
  author={Mohammadhosein Hasanbeig and Natasha Yogananda Jeppu and Alessandro Abate and Thomas F. Melham and Daniel Kroening},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:211542062}
}

@inproceedings{brys2015demonstration,
author = {Brys, Tim and Harutyunyan, Anna and Suay, Halit Bener and Chernova, Sonia and Taylor, Matthew E. and Now\'{e}, Ann},
title = {Reinforcement Learning from Demonstration through Shaping},
year = {2015},
isbn = {9781577357384},
publisher = {AAAI Press},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {3352–3358},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {IJCAI'15}
}

@inproceedings{devlin2012dynamicPBRS,
  author       = {Sam Devlin and
                  Daniel Kudenko},
  title        = {Dynamic potential-based reward shaping},
  booktitle    = {International Conference on Autonomous Agents and Multiagent Systems,
                  {AAMAS} 2012, Valencia, Spain, June 4-8, 2012 {(3} Volumes)},
  pages        = {433--440},
  publisher    = {{IFAAMAS}},
  year         = {2012},
  url          = {http://dl.acm.org/citation.cfm?id=2343638},
  timestamp    = {Thu, 19 Mar 2015 17:49:02 +0100},
  biburl       = {https://dblp.org/rec/conf/aamas/DevlinK12.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{elbarbari2022tlrl,
author = {Elbarbari, Mahmoud and Delgrange, Florent and Vervlimmeren, Ivo and Efthymiadis, Kyriakos and Vanderborght, Bram and Nowe, Ann},
year = {2022},
month = {06},
pages = {},
title = {A framework for flexibly guiding learning agents},
journal = {Neural Computing and Applications},
doi = {10.1007/s00521-022-07396-x}
}

@INPROCEEDINGS{grzes2009potential-function-analysis,
  author={Grzes, Marek and Kudenko, Daniel},
  booktitle={2009 International Conference on Machine Learning and Applications}, 
  title={Theoretical and Empirical Analysis of Reward Shaping in Reinforcement Learning}, 
  year={2009},
  volume={},
  number={},
  pages={337-344},
  doi={10.1109/ICMLA.2009.33}
}

@inproceedings{grzes2017episodicPBRS,
author = {Grze\'{s}, Marek},
title = {Reward Shaping in Episodic Reinforcement Learning},
year = {2017},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
pages = {565–573},
numpages = {9},
keywords = {reinforcement learning, reward shaping, multiagent learning, reward structures for learning, potential-based reward shaping},
location = {S\~{a}o Paulo, Brazil},
series = {AAMAS '17}
}

@inproceedings{ng1999invariance,
  author = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart J.},
  title = {Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
  year = {1999},
  isbn = {1558606122},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
  pages = {278–287},
  numpages = {10},
  series = {ICML '99}
}

@inproceedings{suay2016demonstration,
author = {Suay, Halit Bener and Brys, Tim and Taylor, Matthew E. and Chernova, Sonia},
title = {Learning from Demonstration for Shaping through Inverse Reinforcement Learning},
year = {2016},
isbn = {9781450342391},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents \& Multiagent Systems},
pages = {429–437},
numpages = {9},
keywords = {algorithms, performance},
location = {Singapore, Singapore},
series = {AAMAS '16}
}

@inproceedings{wang2023dshape,
author = {Wang, Caroline and Warnell, Garrett and Stone, Peter},
title = {D-Shape: Demonstration-Shaped Reinforcement Learning via Goal-Conditioning},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {1267–1275},
numpages = {9},
keywords = {reinforcement learning, suboptimal demonstrations, goal-conditioned reinforcement learning, imitation from observation},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@article{wiewiora2011Qinitialization,
  author       = {Eric Wiewiora},
  title        = {Potential-Based Shaping and Q-Value Initialization are Equivalent},
  journal      = {J. Artif. Intell. Res.},
  volume       = {19},
  pages        = {205--208},
  year         = {2003},
  url          = {https://doi.org/10.1613/jair.1190},
  doi          = {10.1613/JAIR.1190},
  timestamp    = {Mon, 21 Jan 2019 15:01:17 +0100},
  biburl       = {https://dblp.org/rec/journals/jair/Wiewiora03.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wu2021demonstrations,
author = {Wu, Yuchen and Mozifian, Melissa and Shkurti, Florian},
title = {Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations Using Generative Models},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICRA48506.2021.9561333},
doi = {10.1109/ICRA48506.2021.9561333},
booktitle = {2021 IEEE International Conference on Robotics and Automation (ICRA)},
pages = {6628–6634},
numpages = {7},
location = {Xi'an, China}
}

