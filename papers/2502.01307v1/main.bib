
@inproceedings{ng1999invariance,
  author = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart J.},
  title = {Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
  year = {1999},
  isbn = {1558606122},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
  pages = {278–287},
  numpages = {10},
  series = {ICML '99}
}

@inproceedings{devlin2012dynamicPBRS,
  author       = {Sam Devlin and
                  Daniel Kudenko},
  title        = {Dynamic potential-based reward shaping},
  booktitle    = {International Conference on Autonomous Agents and Multiagent Systems,
                  {AAMAS} 2012, Valencia, Spain, June 4-8, 2012 {(3} Volumes)},
  pages        = {433--440},
  publisher    = {{IFAAMAS}},
  year         = {2012},
  url          = {http://dl.acm.org/citation.cfm?id=2343638},
  timestamp    = {Thu, 19 Mar 2015 17:49:02 +0100},
  biburl       = {https://dblp.org/rec/conf/aamas/DevlinK12.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{wiewiora2011Qinitialization,
  author       = {Eric Wiewiora},
  title        = {Potential-Based Shaping and Q-Value Initialization are Equivalent},
  journal      = {J. Artif. Intell. Res.},
  volume       = {19},
  pages        = {205--208},
  year         = {2003},
  url          = {https://doi.org/10.1613/jair.1190},
  doi          = {10.1613/JAIR.1190},
  timestamp    = {Mon, 21 Jan 2019 15:01:17 +0100},
  biburl       = {https://dblp.org/rec/journals/jair/Wiewiora03.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{grzes2017episodicPBRS,
author = {Grze\'{s}, Marek},
title = {Reward Shaping in Episodic Reinforcement Learning},
year = {2017},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
pages = {565–573},
numpages = {9},
keywords = {reinforcement learning, reward shaping, multiagent learning, reward structures for learning, potential-based reward shaping},
location = {S\~{a}o Paulo, Brazil},
series = {AAMAS '17}
}

@INPROCEEDINGS{grzes2009potential-function-analysis,
  author={Grzes, Marek and Kudenko, Daniel},
  booktitle={2009 International Conference on Machine Learning and Applications}, 
  title={Theoretical and Empirical Analysis of Reward Shaping in Reinforcement Learning}, 
  year={2009},
  volume={},
  number={},
  pages={337-344},
  doi={10.1109/ICMLA.2009.33}
}

@article{mueller2025epbrs,
author={M{\"u}ller, Henrik
and Berg, Lukas
and Kudenko, Daniel},
title={Using incomplete and incorrect plans to shape reinforcement learning in long-sequence sparse-reward tasks},
journal={Neural Computing and Applications},
year={2025},
month={Jan},
day={10},
issn={1433-3058},
doi={10.1007/s00521-024-10615-2},
url={https://doi.org/10.1007/s00521-024-10615-2}
}


@inproceedings{
  sun2022optimistic,
  title={Optimistic Curiosity Exploration and Conservative Exploitation with Linear Reward Shaping},
  author={Hao Sun and Lei Han and Rui Yang and Xiaoteng Ma and Jian Guo and Bolei Zhou},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
  url={https://openreview.net/forum?id=iCxRsZcVVAH}
}


@inproceedings{matignon2006RewardFA,
  title={Reward Function and Initial Values: Better Choices for Accelerated Goal-Directed Reinforcement Learning},
  author={La{\"e}titia Matignon and Guillaume J. Laurent and Nadine Le Fort-Piat},
  booktitle={International Conference on Artificial Neural Networks},
  year={2006},
  url={https://api.semanticscholar.org/CorpusID:3448745}
}


@article{mnih2013dqn,
  author       = {Volodymyr Mnih and
                  Koray Kavukcuoglu and
                  David Silver and
                  Alex Graves and
                  Ioannis Antonoglou and
                  Daan Wierstra and
                  Martin A. Riedmiller},
  title        = {Playing Atari with Deep Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1312.5602},
  year         = {2013},
  url          = {http://arxiv.org/abs/1312.5602},
  eprinttype    = {arXiv},
  eprint       = {1312.5602},
  timestamp    = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{sutton2018rl-intro,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA}
}

%%%%% ENVIRONMENTS

@ARTICLE{barto1983cartpole,
  author={Barto, Andrew G. and Sutton, Richard S. and Anderson, Charles W.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
  title={Neuronlike adaptive elements that can solve difficult learning control problems}, 
  year={1983},
  volume={SMC-13},
  number={5},
  pages={834-846},
  doi={10.1109/TSMC.1983.6313077}}

@TECHREPORT{Moore1990mountaincar,
    author = {Andrew William Moore},
    title = {Efficient Memory-based Learning for Robot Control},
    institution = {University of Cambridge},
    year = {1990}
}


%%%%% related works
@inproceedings{Hasanbeig2021DeepSynthAS,
  title={DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep Reinforcement Learning},
  author={Mohammadhosein Hasanbeig and Natasha Yogananda Jeppu and Alessandro Abate and Thomas F. Melham and Daniel Kroening},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:211542062}
}

@article{elbarbari2022tlrl,
author = {Elbarbari, Mahmoud and Delgrange, Florent and Vervlimmeren, Ivo and Efthymiadis, Kyriakos and Vanderborght, Bram and Nowe, Ann},
year = {2022},
month = {06},
pages = {},
title = {A framework for flexibly guiding learning agents},
journal = {Neural Computing and Applications},
doi = {10.1007/s00521-022-07396-x}
}

@inproceedings{suay2016demonstration,
author = {Suay, Halit Bener and Brys, Tim and Taylor, Matthew E. and Chernova, Sonia},
title = {Learning from Demonstration for Shaping through Inverse Reinforcement Learning},
year = {2016},
isbn = {9781450342391},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents \& Multiagent Systems},
pages = {429–437},
numpages = {9},
keywords = {algorithms, performance},
location = {Singapore, Singapore},
series = {AAMAS '16}
}

@inproceedings{wu2021demonstrations,
author = {Wu, Yuchen and Mozifian, Melissa and Shkurti, Florian},
title = {Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations Using Generative Models},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICRA48506.2021.9561333},
doi = {10.1109/ICRA48506.2021.9561333},
booktitle = {2021 IEEE International Conference on Robotics and Automation (ICRA)},
pages = {6628–6634},
numpages = {7},
location = {Xi'an, China}
}

@inproceedings{brys2015demonstration,
author = {Brys, Tim and Harutyunyan, Anna and Suay, Halit Bener and Chernova, Sonia and Taylor, Matthew E. and Now\'{e}, Ann},
title = {Reinforcement Learning from Demonstration through Shaping},
year = {2015},
isbn = {9781577357384},
publisher = {AAAI Press},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {3352–3358},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {IJCAI'15}
}

@inproceedings{wang2023dshape,
author = {Wang, Caroline and Warnell, Garrett and Stone, Peter},
title = {D-Shape: Demonstration-Shaped Reinforcement Learning via Goal-Conditioning},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {1267–1275},
numpages = {9},
keywords = {reinforcement learning, suboptimal demonstrations, goal-conditioned reinforcement learning, imitation from observation},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}