\section{Related Work}
\subsection{Tool Learning with LLMs}  
Recent studies have enhanced large language models (LLMs) with tools such as code-related APIs \cite{patil2023gorilla}, mathematical functions \cite{gou2024critic}, and feedback mechanisms to refine outputs and reduce hallucinations \cite{dhuliawala-etal-2024-chain}. For example, \citet{mekala-etal-2024-toolverifier} emphasizes tool-based verification for reliable answers, while \citet{wang-etal-2024-llms-imaginarium} uses simulated errors to guide tool learning. \citet{Gao_Shi_Zhu_Fang_Xin_Ren_Chen_Ma_Ren_2024} propose progressive learning to improve tool usage across tasks. However, these approaches lack a comprehensive evaluation of tool generalization. Our work addresses this by defining the tool generalization problem and incorporating diverse scenarios into training.  


% \subsection{Tool Learning with LLMs}
% Recent work has explored enhancing large language models (LLMs) with various tools to solve diverse tasks \cite{schick2023toolformer,ruan2023tptulargelanguagemodelbased,shen2023hugginggptsolvingaitasks,wang2024mllmtoolmultimodallargelanguage}. These tools include code-related APIs \cite{patil2023gorilla}, mathematical functions \cite{gou2024critic}, and more. LLMs not only leverage these tools to better answer questions but also use tools as feedback to refine their outputs \cite{shridhar-etal-2024-art}, thereby reducing hallucinations in model generation \cite{dhuliawala-etal-2024-chain}. 

% For instance, \citet{mekala-etal-2024-toolverifier} focuses on verifying different output options when using tools to select the most reliable answer. In contrast, our ranking method trains the model to prioritize the use of different tools during output generation. Similarly, \citet{wang-etal-2024-llms-imaginarium} introduces simulated tool usage errors to guide LLMs in learning from feedback and avoiding mistakes, while \citet{Gao_Shi_Zhu_Fang_Xin_Ren_Chen_Ma_Ren_2024} creates a progressive learning environment to improve tool usage across tasks of varying complexity. However, these studies lack a comprehensive evaluation of tool performance across generalization scenarios. Our work addresses this gap by defining the tool generalization problem and simulating generalization scenarios during training.
\subsection{Synthetic Data Generation}
LLMs' generative capabilities have facilitated synthetic data generation, reducing annotation costs while maintaining consistency \cite{zelikman2022star, honovich-etal-2023-unnatural}. For tool learning, \citet{huang-etal-2024-planning-creation} and \citet{huang2024metatool} generate complex queries to evaluate tool usage, while \citet{qin2024toolllm} and \citet{tang2023toolalpaca} use APIs and instruction-response pairs to improve fine-tuning. However, these methods often overlook scenario complexity, limiting generalization performance. Our approach extends these methods by synthesizing data tailored to enhance performance across diverse tool generalization scenarios.

% \subsection{Synthetic Data Generation}
% LLMs' strong generative capabilities have enabled synthetic data generation, reducing the need for costly manual annotation \cite{zelikman2022star, honovich-etal-2023-unnatural, huang-etal-2023-large} while maintaining high consistency \cite{pavlovic-poesio-2024-effectiveness}.

% In the context of tool learning, \citet{huang-etal-2024-planning-creation} leverages LLMs to generate complex queries and solutions for curated benchmarks to evaluate LLM tool usage capabilities, while \citet{huang2024metatool} creates diverse queries to test tool usage across different queries. 

% Similar to our work, \citet{qin2024toolllm} employs real-world APIs and uses ChatGPT to generate instructions for invoking given toolsets, enhancing tool utilization. Likewise, \citet{tang2023toolalpaca} elaborates API documentation to construct paired instructions and responses for fine-tuning. However, these methods often overlook scenario complexity, limiting generalization performance. Our work builds on these approaches by synthesizing data specifically to enhance performance across diverse tool generalization scenarios.