\section{Related Work}
\subsection{Tool Learning with LLMs}  
Recent studies have enhanced large language models (LLMs) with tools such as code-related APIs ____, mathematical functions ____, and feedback mechanisms to refine outputs and reduce hallucinations ____. For example, ____ emphasizes tool-based verification for reliable answers, while ____ uses simulated errors to guide tool learning. ____ propose progressive learning to improve tool usage across tasks. However, these approaches lack a comprehensive evaluation of tool generalization. Our work addresses this by defining the tool generalization problem and incorporating diverse scenarios into training.  


% \subsection{Tool Learning with LLMs}
% Recent work has explored enhancing large language models (LLMs) with various tools to solve diverse tasks ____. These tools include code-related APIs ____, mathematical functions ____, and more. LLMs not only leverage these tools to better answer questions but also use tools as feedback to refine their outputs ____, thereby reducing hallucinations in model generation ____. 

% For instance, ____ focuses on verifying different output options when using tools to select the most reliable answer. In contrast, our ranking method trains the model to prioritize the use of different tools during output generation. Similarly, ____ introduces simulated tool usage errors to guide LLMs in learning from feedback and avoiding mistakes, while ____ creates a progressive learning environment to improve tool usage across tasks of varying complexity. However, these studies lack a comprehensive evaluation of tool performance across generalization scenarios. Our work addresses this gap by defining the tool generalization problem and simulating generalization scenarios during training.
\subsection{Synthetic Data Generation}
LLMs' generative capabilities have facilitated synthetic data generation, reducing annotation costs while maintaining consistency ____. For tool learning, ____ and ____ generate complex queries to evaluate tool usage, while ____ and ____ use APIs and instruction-response pairs to improve fine-tuning. However, these methods often overlook scenario complexity, limiting generalization performance. Our approach extends these methods by synthesizing data tailored to enhance performance across diverse tool generalization scenarios.

% \subsection{Synthetic Data Generation}
% LLMs' strong generative capabilities have enabled synthetic data generation, reducing the need for costly manual annotation ____ while maintaining high consistency ____.

% In the context of tool learning, ____ leverages LLMs to generate complex queries and solutions for curated benchmarks to evaluate LLM tool usage capabilities, while ____ creates diverse queries to test tool usage across different queries. 

% Similar to our work, ____ employs real-world APIs and uses ChatGPT to generate instructions for invoking given toolsets, enhancing tool utilization. Likewise, ____ elaborates API documentation to construct paired instructions and responses for fine-tuning. However, these methods often overlook scenario complexity, limiting generalization performance. Our work builds on these approaches by synthesizing data specifically to enhance performance across diverse tool generalization scenarios.