
\documentclass{article}

\usepackage[hyphens]{url}
\usepackage[accepted]{icml2024}
\setlength{\bibsep}{0.8pt plus 0.6ex}

\usepackage{blindtext, rotating}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} %

\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}



\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}

\usepackage{hyperref}
\usepackage{tikz}
\usepackage{bbm}
\usepackage{pifont}
\usepackage{algorithm}

\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{etoolbox}
\usepackage{siunitx}
\usepackage{comment}
\usepackage{colortbl}
\usepackage{tcolorbox}
\tcbuselibrary{skins}
\usepackage{authblk}  %
\renewcommand\Authsep{, }
\renewcommand\Authands{, }
\setlength{\affilsep}{0.2em}  %



\makeatletter
\makeatother

\newcommand{\waa}{{ICL-Genetic attack algorithm}\xspace}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\ancomment}[1]{\textcolor{red}{\bf \small [ #1 --AN]}}
\newcommand{\hrcomment}[1]{\textcolor{orange}{\bf \small [ #1 --HR]}}
\newcommand{\mk}[1]{\textcolor{purple}{\bf \small [ #1 --MK]}}
\newcommand{\mi}[1]{\textcolor{BlueGreen}{\bf \small [ #1 --MI]}}
\newcommand{\eb}[1]{\textcolor{blue}{\bf \small [ #1 --EB]}}

\newcommand{\amir}[1]{\textcolor{blue}{\bf \small [ #1 --Amir]}}
\newcommand{\eg}{e.g., }

\usepackage{xspace}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{threeparttable}
\usepackage[bb=boondox]{mathalfa}
\newcommand{\paragraphbe}[1]{\vspace{0.75ex}\noindent{\bf \em #1}\hspace*{.3em}}
\newcommand{\pbe}[1]{\vspace{0.75ex}\noindent{\bf \em #1}\hspace*{.3em}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newcommand{\sys}{\mbox{\textsc{OverThink}}\xspace}

\date{}

\title{\sys: Slowdown Attacks on Reasoning LLMs}






\author{
    Abhinav Kumar, Jaechul Roh, Ali Naseh, Marzena Karpinska \\[0.2em]
    Mohit Iyyer, Amir Houmansadr, Eugene Bagdasarian
}

\affil{\vspace{0.4em}\textit{University of Massachusetts Amherst}}
\affil{\normalsize \texttt{\{abhinavk, jroh, anaseh, mkarpinska, miyyer, amir, eugene\}@cs.umass.edu}}

\begin{document}

\maketitle




\icmlkeywords{Machine Learning, ICML}



\begin{abstract}
 
We increase overhead for applications that rely on reasoning LLMs---we force models to spend an amplified number of reasoning tokens, i.e., ``overthink'', to respond to the user query while providing \emph{contextually correct} answers. 
The adversary performs an \sys attack by  injecting \emph{decoy} reasoning problems into the public content that is used by the reasoning LLM (e.g., for RAG applications) during inference time. Due to the nature of our decoy problems (e.g., a Markov Decision Process), modified texts do not violate safety guardrails.
 We evaluated our attack across closed-(OpenAI o1, o1-mini, o3-mini) and open-(DeepSeek R1) weights reasoning models on the FreshQA and SQuAD datasets. Our results show up to \textbf{18}\textbf{$\times$ slowdown} on FreshQA dataset and \textbf{46}\textbf{$\times$ slowdown} on SQuAD dataset. The attack also shows high transferability across models. To protect applications, we discuss and implement defenses leveraging LLM-based and system design approaches. Finally, we discuss societal, financial, and energy impacts of \sys attack which
 could amplify the costs for third-party applications operating reasoning models.


\end{abstract}

\input{1_intro}
\input{2_background}
\input{3_threat_model}
\input{4_attack}
\input{5_init}
\input{6_exps}
\input{7_defenses}
\input{8_conclusion}

\small
\bibliographystyle{plainnat}
\bibliography{main}

\appendix
\input{appendix}

\end{document}
