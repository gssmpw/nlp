\section{Related Work}
\label{sec:related_work}

\paragraph{Reward Model in Mathematical Reasoning}

To advance the accuracy of mathematical reasoning, reward models (RMs) have emerged as powerful tools for evaluating and guiding solution generation. In particular, two principal RM paradigms have garnered significant attention: the Outcome Reward Models (ORMs) \citep{orm1,orm2} and the Process Reward Models (PRMs) \citep{solving,prm800k,making,let,shepherd,improve,bugs,openr}. ORMs assign a single score to an entire solution and thereby focuses on final correctness, whereas PRMs score each individual step of the reasoning process, offering more finer-grained evaluations. As a result, PRMs provide more detailed guidance and have demonstrated greater potential in enhancing reasoning capabilities compared to ORMs \citep{prm800k,fine}.



\paragraph{Multilingual Reward Model}

Beyond English-language tasks, the integration of RMs into multilingual scenarios is still under-explored. 
Reinforcement learning approaches often rely on RMs predominantly trained on English data \citep{deepseek,qwen}. This over-representation introduces biases, as these RMs may overfit to English-specific syntactic and semantic patterns, limiting their effectiveness in cross-lingual tasks and motivating the development of multilingual RMs \citep{crossrm}. While there is growing evidence that cross-lingual transfer is feasible \citep{reuse,crossrm}, existing research often overlooks the unique challenges of multilingual reasoning.
After the release of the OpenAI-o1 model \citep{o1}, PRMs, with their capability for fine-grained feedback, have attracted even greater interest. Yet, the performance of multilingual PRMs in diverse linguistic contexts remains insufficiently investigated \citep{imbalance}. To bridge this gap, we investigate how multilingual PRMs contribute to solving mathematical tasks across different languages, aiming to provide insights into how fine-grained process supervision can enhance reasoning capabilities beyond English, thereby contributing to the development of more universally applicable reasoning models.