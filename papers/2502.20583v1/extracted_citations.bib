@software{NeMo,
author = {Harper, Eric and Majumdar, Somshubra and Kuchaiev, Oleksii and Jason, Li and Zhang, Yang and Bakhturina, Evelina and Noroozi, Vahid and Subramanian, Sandeep and Nithin, Koluguri and Jocelyn, Huang and Jia, Fei and Balam, Jagadeesh and Yang, Xuesong and Livne, Micha and Dong, Yi and Naren, Sean and Ginsburg, Boris},
title = {{NeMo: a toolkit for Conversational AI and Large Language Models}},
url = {https://github.com/NVIDIA/NeMo}
}

@article{bain2023whisperx,
  title={Whisperx: Time-accurate speech transcription of long-form audio},
  author={Bain, Max and Huh, Jaesung and Han, Tengda and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2303.00747},
  year={2023}
}

@article{chang2024palu,
  title={Palu: Compressing kv-cache with low-rank projection},
  author={Chang, Chi-Chih and Lin, Wei-Cheng and Lin, Chien-Yu and Chen, Chong-Yan and Hu, Yu-Fang and Wang, Pei-Shuo and Huang, Ning-Chi and Ceze, Luis and Abdelfattah, Mohamed S and Wu, Kai-Chiang},
  journal={arXiv preprint arXiv:2407.21118},
  year={2024}
}

@misc{faster-whisper,
  author = {SYSTRAN},
  title = {Faster Whisper transcription with CTranslate2},
  year = {2023},
  howpublished = {\url{https://github.com/SYSTRAN/faster-whisper}},
}

@article{ferraz2023distilwhisper,
  title={DistilWhisper: Efficient Distillation of Multi-task Speech Models via Language-Specific Experts},
  author={Ferraz, Thomas Palmeira and Boito, Marcely Zanon and Brun, Caroline and Nikoulina, Vassilina},
  journal={arXiv preprint arXiv:2311.01070},
  year={2023}
}

@article{gandhi2023distil,
  title={Distil-whisper: Robust knowledge distillation via large-scale pseudo labelling},
  author={Gandhi, Sanchit and von Platen, Patrick and Rush, Alexander M},
  journal={arXiv preprint arXiv:2311.00430},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@misc{kotoba-whisper-v2-0,
  title        = {Kotoba-Whisper (v2.0)},
  author       = {{Kotoba Technologies}},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/kotoba-tech/kotoba-whisper-v2.0}}
}

@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{machavcek2023turning,
  title={Turning whisper into real-time transcription system},
  author={Mach{\'a}{\v{c}}ek, Dominik and Dabre, Raj and Bojar, Ond{\v{r}}ej},
  journal={arXiv preprint arXiv:2307.14743},
  year={2023}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{shao2023whisper,
  title={Whisper-kdq: A lightweight whisper via guided knowledge distillation and quantization for efficient asr},
  author={Shao, Hang and Wang, Wei and Liu, Bei and Gong, Xun and Wang, Haoyu and Qian, Yanmin},
  journal={arXiv preprint arXiv:2305.10788},
  year={2023}
}

@misc{whisper.cpp,
  author = {Georgi Gerganov},
  title = {whisper.cpp: Port of OpenAI's Whisper model in C/C++},
  year = {2023},
  howpublished = {\url{https://github.com/ggerganov/whisper.cpp}},
}

@inproceedings{yu2023compressing,
  title={Compressing transformers: features are low-rank, but weights are not!},
  author={Yu, Hao and Wu, Jianxin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={9},
  pages={11007--11015},
  year={2023}
}

