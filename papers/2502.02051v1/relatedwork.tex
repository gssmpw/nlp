\section{Related Work}
\label{sec:related-works}
Consequential sounds exist for every robot and thus every human-robot interaction, however the study of consequential sound is still rare within HRI research. A recent review of sound in robotics identified only seven consequential sounds papers\cite{Zhang2023}. Psychoacoustics research (the study of how humans perceive sound) has shown that sound is a critically important sensory element for humans~\cite{Jouaiti2019}, with the ability to contribute both positive (happiness, relaxation) or negative effects (anxiety, distraction, annoyance). Human response to different sound intensities and frequencies varies, with loud noises and high-pitched sounds being disliked~\cite{Cha2018}. Broadband noises are generally perceived more pleasantly than pure tones~\cite{Fastl2007a} particularly those with many frequencies evenly spaced across the human-audible range~\cite{Cha2018}. Humans are very familiar with sharing environments with biological agents such as people or animals, and are thus accustomed to regular, rhythmic sounds such as breathing or rustling denoting an embodied agent's presence via proxemics~\cite{Jouaiti2019,Trovato2018}. In contrast, acute sounds such as alarms, or the sudden startup noises of a machine tend to be disliked, often eliciting an instinctive danger response~\cite{Jouaiti2019}. Sound perception is often entwined with other sensory perception such as visual perception. There are often bi-directional links between audio and visual stimulus\cite{DeGelder2000}, with different sound profiles (e.g. rhythmic versus acute sounds) creating a crossmodal effect from audio to visual perception\cite{Vroomen2000}.

Sounds have been shown to have an impact on human robot interactions by influencing opinions of particular robots~\cite{Moore2018,Frederiksen2019,Frederiksen2020,Cha2018,Song2017}, causing confusion or annoyance~\cite{DePaivaVianna2015,Schute2007,Moore2017} or positively contributing a sense of proxemics~\cite{Cha2018,Trovato2018}. The earliest paper to focus on robot ``consequential sound''~\cite{Moore2017}, compared videos of pairs of DC motors with artificially dubbed sounds to gauge participant preferred sounds, showing consistency within-participants but not between-participants. Several studies have examined how the perception of robotic arms varied when their consequential sounds were altered~\cite{Zhang2021,Tennent2017}. In one experiment, frequency (pitch) and intensity (volume) of consequential sounds were manipulated~\cite{Zhang2021} with results suggesting that quieter robots are preferred, and increased sound frequency correlated with perceptions of warmth. Another experiment dubbed consequential sounds from a low quality robotic arm onto videos a KUKA robotic arm, finding that both sets of consequential sounds reduced robot quality ratings, but with the higher quality robot sounds preferred~\cite{Tennent2017}.

Consequential sounds have also been shown to interact with other sounds and robot motions to confuse the interpretation of affect. For example, low-frequency consequential sounds created a negative valence and strong arousal affect such that the robot was perceived as frustrated and overshadowed the intended affect~\cite{Frid2018,Frid2022}. In contrast, another study used headphones to dampen existing consequential sounds and play additional affective sounds, leading to the robot being perceived as curious, happy and less angry~\cite{Frederiksen2019}. Recent research projects have investigated improving opinions of robots by adding transformative sounds on-top of the consequential sounds~\cite{Zhang2021b,Robinson2021,Wang2023}. One study measured perception of competence and warmth of a robot, using a within-participant study comparing a robot's consequential sounds with and without transformations~\cite{Zhang2021b}. In a second experiment, carefully designed sounds were added to consequential sounds, and compared to a silent control~\cite{Robinson2021}, however comparison to unedited consequential sounds was not made. Another experiment added natural sounds to the consequential sounds of a micro-drone~\cite{Wang2023} leading to a more pleasant perception of the drone.

The effect of consequential sounds on human-centric perception of robots (rather than perception of the robot itself) was examined in a recent online study~\cite{Allen2024e1p1}. Using a between-participant design, participants were shown videos of robots either with or without sound, with the presence of consequential sounds being shown to significantly increase negative human-perception of robots, including feeling more distracted, increasing negative associated affects, and being less willing to colocate with robots. Another recent work provides a detailed explanation of consequential sounds within the context of robotics, including issues with how people may perceive these sounds, and how to manage consequential sounds~\cite{Allen2023}.

Existing research has helped to illustrate the effect that consequential sounds can have within human-robot interactions, however very few studies have large samples, almost all focus on robot-centric attributes (such as trusting the robot) and lack insight into the properties of the sounds causing these perceptions. This paper builds on existing research by contributing insights into the properties of consequential sounds influencing the phenomenon of human-centric perceptions of robots, thus providing a strong starting point for augmenting and improving these sounds, and by extension improving human-perception of robots and HRI.