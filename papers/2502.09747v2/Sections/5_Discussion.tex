

\section*{Discussion}


Our findings reveal widespread adoption of large language models across diverse writing domains, ranging consumers, firms and international organizations. This finding complements and extends our previous research that found widespread adoption across academic researchers.\cite{liang2024monitoring} 
A consistent temporal pattern emerges from our data: after an initial lag of 3â€“4 months following the ChatGPT launch, there was a sharp surge in LLM usage, which then stabilized by late 2023 and remained steady through 2024. This trajectory deviates from traditional diffusion models that predict continuous and gradual growth, suggesting several possibilities. Early adopters may have already reached a saturation point within their domains, or domain-specific barriers (generally, these can range from costs of adoption, regulatory constraints, concerns over authenticity coupled with advances in users recognizing AI writing, etc.) that could be impeding further expansion. Alternatively, improvements in LLM sophistication may be rendering AI-generated content increasingly indistinguishable from human writing, complicating our ability to measure ongoing adoption.


In the consumer complaint domain, the geographic and demographic patterns in LLM adoption present an intriguing departure from historical technology diffusion trends \cite{rogers2014diffusion, bloom2021diffusion, 10.1093/qje/qjaf002} and technology acceptance model \cite{davis1989technology, venkatesh2003user}, where technology adoption has generally been concentrated in urban areas, among higher-income groups, and populations with higher levels of educational attainment \cite{rojas2017demographics, foster2010microeconomics}. While the urban-rural digital divide seems to persist, our finding that areas with lower educational attainment showed modestly higher LLM adoption rates in consumer complaints suggests these tools may serve as equalizing tools in consumer advocacy. This finding aligns with  survey evidence indicating  that younger, less experienced workers may be more likely to use ChatGPT \cite{humlum2024chatgpt}. %
This democratization of access underscores the potentially transformative role LLMs could play in amplifying underserved voices. However, further study is needed to assess whether this increased adoption translates into more effective consumer outcomes. 


Corporate communication channels also demonstrated widespread but decelerating LLM integration. The plateauing adoption across platforms like Newswire, PRWeb, and PRNewswire raises important considerations about the balance between cost efficiency and authenticity. While LLMs may enable rapid, cost-effective content generation, overreliance on automated tools could compromise the nuance and credibility required in professional communications, potentially eroding trustworthiness \cite{jakesch2019ai, hong2018bias, kadoma2024generative}. Future research should explore how organizations navigate this trade-off and whether editorial interventions are employed to mitigate potential drawbacks.



In the recruitment process, small firms, particularly those founded after 2015, exhibited the fastest adoption of LLM-generated content. This trend suggests that younger, or companies closer to the technological frontier are leveraging LLMs to streamline hiring processes and reduce costs.\footnote{This is consistent with previous research finding that younger firms may invest relatively more in AI, but may superficially seem in contrast with datapoints showing larger firms and firms with higher cash holdings increase their AI investments more.\cite{babina2024} We think that it is possible that younger, smaller firms may use more cost-effective AI products such as ChatGPT, and may also have a lower time from AI usage to output.} While our study did not directly measure homogenization, prior research on the homogenization of LLM-generated content in academia~\cite{liang2024monitoring,liang2024mapping} suggests that similar effects could occur in job postings. This potential homogenization may inadvertently obscure critical distinctions between roles and organizations, potentially complicating job seekers' decision-making. In fact, recent evidence has shown that while employers who leverage LLM to generate first draft of job post may receive more applications, they are less likely to make a hire\cite{wiles2023impact}. Further investigating how AI-generated postings influence applicant perceptions and hiring could provide valuable insights into the long-term implications of this shift. 


International institutions communication, exemplified by United Nations press releases, also demonstrated significant LLM adoption. These patterns remained robust when stratifying by regional country groups (\textbf{Supp. Fig.\ref{fig: supp-robust-US-country-groups}}). 
The presence of LLM-generated content within such formal and traditionally cautious institutions suggests that AI-driven tools are gradually influencing even high-stakes communication channels, reflecting the broad and expanding reach of these technologies. As it was the case with corporate communications, these findings raise the same trade-off between cost-efficiency and credibility.


The stabilization of LLM adoption may reflect either the maturation of AI integration or domain-specific friction factors. As LLM technologies continue to evolve, future research should aim to disentangle the drivers of adoption plateaus by examining whether they stem from market saturation, improvements in LLM indistinguishability, or external barriers. They should evaluate the impact of LLM-generated content on communication quality, credibility, and user engagement across sectors and investigate potential homogenization effects in job postings and other domains to assess how uniform AI-generated content might affect decision-making and market dynamics.


Our study has several limitations. While we focused on widely used LLMs like ChatGPT, which account for a significant portion of global usage~\cite{vanrossum2024generative}, we acknowledge that other models also contribute to content generation across domains. Additionally, although prior research has shown that GPT-detection methods can sometimes misclassify non-native writing as AI-generated~\cite{Liang2023GPTDA}, our findings consistently indicated low false positive rates during earlier periods. However, shifts in user demographics or language usage could still influence detection accuracy~\cite{Globalaitalent}. 

Perhaps the biggest limitation in our study is that we cannot reliably detect language that was generated by LLMs, but was either heavily edited by humans or was generated by models that imitate very well human writing. Therefore, one way to interpret our study is as a lower bound of adoption patterns.
Finally, our analysis primarily focuses on English-language content, potentially overlooking adoption trends in non-English-speaking regions. Future research could expand on these findings by incorporating multilingual data and refining detection methodologies.

In conclusion, we show that LLM writing is a new pervasive reality across consumer, corporate, recruitment, and even governmental communications. As these technologies continue to mature, understanding their effects on content quality, creativity, and information credibility will be critical. Addressing the regulatory and ethical challenges associated with AI-generated content will also be essential for ensuring that the benefits of LLMs are realized while maintaining transparency, diversity, and public trust in communication.
