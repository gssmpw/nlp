

\section*{Results}
\label{sec:Results}

\subsection*{Widespread Adoption of Large Language Models in Writing Assistance Across Domains}



We systematically analyzed large language model (LLM) adoption patterns across four distinct domains: consumer complaints, corporate PR communications, job postings, and governmental press releases (see Supplementary Information for data collection and preprocessing). Our analysis reveals a consistent pattern of initial rapid adoption following ChatGPT's release, followed by a notable stabilization period that emerged between mid to late 2023 across all domains (\textbf{Fig.~\ref{fig:main:1}}).\footnote{While the patterns across all time series show a slower adoption through 2024, these could be (at least partly) the product of more sophistication when adopting AI tools or the developments in LLMs making writing more undistinguishable from human writing.}



In the consumer complaint domain (\textbf{Fig.~\ref{fig:main:1}a}), initial LLM adoption surged about 3-4 months after the release of ChatGPT in November 2022. The proportion of content flagged as LLM-generated or substantially modified rose sharply from a baseline algorithm false positive rate of 1.5\% to 15.3\% by August 2023. This rapid growth plateaued, with only a modest increase to 17.7\% observed through August 2024.

Corporate press releases demonstrated similar adoption trends across platforms (\textbf{Fig.~\ref{fig:main:1}b}), once again about 3-4 months post-ChatGPT release. Newswire saw rapid growth, peaking at 24.3\% in December 2023 and stabilizing at 23.8\% through September 2024. PRNewswire followed closely, reaching 16.4\% in December 2023 and maintaining this level through September 2024. PRWeb exhibited comparable dynamics, with data available through January 2024.


LinkedIn job postings from small organizations showed profession-specific adoption trends but similarly reflected a slowing trajectory (\textbf{Fig.~\ref{fig:main:1}c}). Following a five-month lag post-ChatGPT release, adoption increased steadily across professional categories, peaking in July 2023 between 6-10\%. These figures are higher in the sample of small and young firms, where they reach more than 10\%, and up to 15\% (\textbf{Fig.~\ref{fig:main:4}})
. Adoption rates either plateaued or showed signs of slight declines through October 2023, when the latest data was available. 

International organization communication, here measured by United Nations press releases by country teams followed a similar adoption pattern with initial rapid growth that later plateaued (\textbf{Fig.~\ref{fig:main:1}d}). The initial phase was marked by a rapid increase from 3.1\% in Q1 2023 to 10.1\% in Q3 2023. This was followed by a slower, incremental rise, reaching 13.7\% by Q3 2024. 

\subsection*{Geographic and Demographic Disparities in Consumer Complaint LLM Adoption}


Our analysis of Consumer Financial Protection Bureau complaints revealed some geographic and demographic heterogeneity in LLM adoption patterns (\textbf{Fig.~\ref{fig:main:2}}).  At the state level, we observed variation in adoption rates during the January-August 2024 period, with highest adoption in Arkansas (29.2\%, 7,376 complaints), Missouri (26.9\%, 16,807 complaints), and North Dakota (24.8\%, 1,025 complaints). This contrasted sharply with minimal adoption in West Virginia (2.6\%, 2,010 complaints), Idaho (3.8\%, 1,651 complaints), and Vermont (4.8\%, 361 complaints). Notably, major population centers demonstrated much less variation in adoption levels, with California (157,056 complaints) and New York (104,862 complaints) showing rates of 17.4\% and 16.6\%, respectively (\textbf{Fig.~\ref{fig:main:2}a}). However, this could be interpreted either as a genuine differential compared to the smaller states in the left and right tail or the product of lower sample noise (due to higher number of observations).


The adoption of LLMs varied over time between more and less urbanized areas. Analysis using Rural Urban Commuting Area (RUCA) codes showed that highly urbanized and non-highly urbanized areas initially displayed similar adoption trajectories during the early phase (2023Q1-2023Q3). However, these trajectories subsequently diverged, reaching equilibrium levels of 18.2\% in highly urbanized areas compared to 10.9\% in non-highly urbanized areas (\textbf{Fig.~\ref{fig:main:2}b}). These differences were highly statistically significant at all conventional levels.


Areas with lower educational attainment showed somewhat higher LLM adoption rates in consumer complaints. Comparing areas above and below state median levels of bachelor's degree attainment, areas with lower educational attainment ultimately stabilized at rates of around 19.9\% in 2024Q3 (compared with 17.4\%) (\textbf{Fig.\ref{fig:main:2}c}). This pattern persisted even within highly urbanized areas, where lower-education regions demonstrated higher adoption rates (21.4\% versus 17.8\% by 2024Q3) (\textbf{Fig.\ref{fig:main:2}d}). In both comparison, the p-values were less than 0.001, indicating statistically significant differences, despite qualitatively similar trends. 




\subsection*{LLM Adoption in Corporate Press Releases}
After characterizing consumer-side adoption patterns, we next examined corporate LLM usage across major corporate press release platforms---Newswire, PRWeb, and PRNewswire, each of which caters to different audiences and industries (\textbf{Fig.~\ref{fig:main:1}b}, \textbf{Fig.~\ref{fig:main:3}a-b}).\footnote{A vast oversimplification based on available data would be that PRNewswire generally targets larger corporations with extensive reach to major news outlets and traditional media. PRWeb offers a more affordable, online-focused option with an emphasis on SEO, catering to smaller businesses. Newswire reaches both traditional and online platforms. All three offer some editorial services but focus primarily on distribution of the contents produced by the businesses.}


Before the launch of ChatGPT, the fraction of AI-modified content remained consistently low across all these sources, fluctuating around the 2-3\% mark (i.e., false positives). However, following the launch, a significant increase in AI-modified content was observed across all domains, about 2 quarters post rollout. Newswire, in particular, experienced the most dramatic rise, with the estimated fraction peaking at over 25\% by late-2023. PRWeb and PRNewswire also saw notable growth, though to a lesser degree, plateauing around 15\%. This suggests a widespread uptake of LLM technology in content creation across different types of press releases starting in early 2023.

In \textbf{Fig.~\ref{fig:main:3}a-b}, we show the quarterly growth of LLM usage in press releases across different categories for PRNewswire (a) and PRWeb (b). Both charts show a sharp rise in AI-modified content starting in early 2023, with some differential patterns emerging by topic. In both platforms, the categories "Business \& Money" and "Science \& Tech" exhibit the most pronounced increase, with Science \& Tech reaching just below 17\% by Q4 2023. "People \& Culture" and "Other" categories also demonstrate growth, but at a somewhat slower pace, which may be indicative that LLM adoption has been particularly strong in more technical and business-focused content. 



Overall, we show a significant uptick in LLM writing across various press release categories. On one hand, the sharp increase in AI-modified content in press releases suggests that businesses are leveraging LLMs to improve efficiency in content creation. By utilizing AI, companies can potentially produce high-quality communications more quickly and cost-effectively, especially in areas requiring frequent updates and complex information dissemination. This may also be advantageous if companies are trying to withhold more sensitive information from the public and use more generic language. On the other hand, the growing reliance on AI-generated content may introduce challenges in communication. In sensitive categories, over-reliance on AI could result in messages that fail to address concerns or overall release less credible information externally. Over-reliance on AI could also introduce public mistrust in the authenticity of messages sent by firms.


\subsection*{LLM Adoption in LinkedIn Job Postings}


We next examined another dimension of corporate LLM adoption through analysis of LinkedIn job postings.
We first took the whole sample of LinkedIn job posting and analyzed the effects (\textbf{Supp. Fig.~\ref{fig: full-sample-LinkedIn}}). In this full sample, we see that about 3-4\% of all vacancy postings have LLM modified content. Albeit a small increase, this is generally statistically different from pre-ChatGPT introduction (i.e. false positive) levels (with p-values less than 0.001 across categories).  However, this broader sample heavily features larger firms that post more vacancies and have greater financial and human resources to customize those postings. Such firms may also advertise the same position multiple times throughout the year and rely on their established reputation, reducing the need to update job postings frequently. Consequently, for the remainder of this analysis, we focused on small companies, defined either as firms which post less than the median number of vacancies (2 or less each year), or as businesses with 10 or fewer registered employees in 2021 or those posting two or fewer positions per year on LinkedIn (see Supplementary Information).


Using the sample of small companies based on the number of vacancies posted, our findings reveal a gradual but notable increase in the estimated fraction of AI-modified content for several job categories (\textbf{Fig.~\ref{fig:main:1}d}, \textbf{Fig. \ref{fig:main:4}}). Prior to the launch of ChatGPT, the fraction of AI-modified text hovered between 0–2\% across all categories, reflecting the range of false positives. After ChatGPT became available, a discernible uptick begins around early to mid-2023, leveling off by October 2023 at roughly 5–10\% for all categories. The increase is most pronounced in engineering and sales postings, which each approach 10\% AI-modified content. Finance, Admin, Scientist, and Operations show a somewhat slower growth, albeit the differences between these categories are small. If instead we define small companies by the number of employees (\textbf{Fig.~\ref{fig: supp-robust-small-company-definition}}) the Scientist category ranks first. \footnote{This may be some evidence that firms requiring more advanced scientific, financial, or marketing expertise might be more inclined to adopt AI technologies, although the differences are modest.}



We further stratified these small firms by founding year—grouping them into post‐2015, 2000–2015, 1980–2000, and pre‐1980 cohorts (\textbf{Fig.\ \ref{fig:main:4}}), based on the rough quartiles in the data. Across every job category, more recently founded companies consistently exhibit both the highest levels and the fastest uptake of LLM‐related text generation, especially following ChatGPT’s launch. Firms founded after 2015 reach 10–15\% AI‐modified text in certain roles, whereas those founded between 2000 and 2015 show moderate growth of 5–10\%. By comparison, firms founded before 1980 typically remain below 5\%. These results underscore how younger firms—possibly with younger workforces—more readily integrate new AI technologies into their hiring and onboarding processes, whereas older organizations may adopt such tools more conservatively. Overall, firm age and size emerge as (perhaps the most) significant correlates of the heterogeneity observed in LLM uptake throughout our analyses. 


This trend highlights a potential shift in recruitment practices among small firms, showcasing a growing reliance on AI-writing tools. On one hand, this can decrease company hiring costs, with smaller and younger enterprises being more likely to leverage advanced tools to remain competitive despite perhaps being more liquidity constrained. On the other hand, the adoption of LLM writing in job posting could either enhance or decrease the efficiency and effectiveness in attracting qualified candidates. For jobseekers, one possible negative effect is harder differentiation between posting firms quality and position requirements.

The leveling off or even slight decrease in AI-modified content by October 2023 might indicate that the adoption rate has stabilized, potentially reaching a saturation point where firms comfortable with AI have already adopted it. Alternatively, this can be explained by increased sophistication and subtlety of these methods. Overall, the increased integration of AI in job postings suggests a transformative period in hiring, with AI playing an important role in how small firms communicate job opportunities. This could have implications for job seekers as well, who may encounter more uniformly crafted postings and might need to adapt their application strategies accordingly.


\subsection*{LLM Adoption in United Nations Press Releases}

United Nations press releases exhibited a similar two-phase adoption pattern, with an initial surge from 3.1\% to 10.1\% in Q1-Q3 2023, followed by a more gradual increase to 13.7\% by Q3 2024 (\textbf{Fig.~\ref{fig:main:1}d}). 
Across UN Member States country teams, we observed consistent adoption patterns across regions, with adoption rates reaching 11-14\% by 2024, with the exception of the UN teams in Latin American and Caribbean countries that had slightly higher adoption rates at about 20\% (\textbf{Supp. Fig.~\ref{fig: supp-robust-US-country-groups}}). The steady growth across regions reflects how LLMs are being integrated globally, even in contexts of sensitive, high-stakes communication. 

This rapid uptake suggests that country teams have found LLMs valuable for producing timely updates, which can be especially useful during pressing crises. On the other, this trend raises questions about how LLMs might affect the authenticity of vital international communication. As the UN continues to refine its stance on AI, this highlights a broader trend: even the world’s most prominent international bodies are using LLMs in their communications--underscoring both the perhaps inevitability of AI-driven writing and the questions it raises about authenticity and accountability.


