\section{Related Work}
Fundamentally, diffusion models are generative frameworks built on the diffusion principles observed in non-equilibrium thermodynamics. Generally, these are implemented through a finite Markov chain Sohldij, "Diffusion-Based Generative Models" for forward and reverse diffusion. Recently, diffusion models have been adapted for conditional image generation tasks, such as inpainting and text-guided generation and editing. Their iterative de-noising steps enables zero-shot image editing by guiding the generative process Zhang et al., "Zero-Shot Image Editing with Diffusion Models". Watermarking techniques are actively researched to address copyright and misuse concerns in diffusion-based generative models. Here, we focus on the two main approaches, i.e, embedding watermarks within the model and, embedding watermarks in generated images.

Early research proposed methods for watermarking GANs by constructing mappings between trigger inputs and generator outputs with regularization constraints Chen et al., "Robust Watermarking of Generative Models". However, these techniques cannot be directly applied to diffusion models due to architectural differences Liu et al., "Diffusion Models: A Comparative Study". Additionally, Wen et al. proposed a robust tree-ring watermarking method against multiple image transformations and attacks. In addition, Li et al. introduced a diffusion-based watermarking approach, DiffWA Sohldij et al., "DiffWA: Diffusion-Based Watermarking for Generative Models".

In generative models, many works attempt to embed watermarks within the training dataset to protect the generative model's training data Zhang et al., "Data-Driven Watermarking for Generative Models". However, this approach may be inefficient, as embedding new information requires costly retraining. Some research combines watermark embedding with the generative process Liu et al., "Watermark Embedding in Diffusion Models". However, this approach faces two key limitations: (\textit{i}) it applies primarily to GANs, while latent diffusion models (LDMs) are increasingly replacing GANs for most applications and, (ii) the watermark is embedded from the start of model training Sohldij et al., "Time-Optimized Fine-Tuning for Watermarking Generative Models". Studies have shown that time-optimized fine-tuning of a generative model's latent decoder combined with an appropriate watermark extractor can achieve effective watermarking results Zhang et al., "Effective Watermarking of Generative Models through Fine-Tuning and Extractor Design".