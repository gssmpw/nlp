\section{Related Work}
Fundamentally, diffusion models are generative frameworks built on the diffusion principles observed in non-equilibrium thermodynamics. Generally, these are implemented through a finite Markov chain~\citep{geyer1992practical} for forward and reverse diffusion. Recently, diffusion models have been adapted for conditional image generation tasks, such as inpainting and text-guided generation and editing. Their iterative de-noising steps enables zero-shot image editing by guiding the generative process~\citep{heusel2017gans,salimans2016improved,zhou2019hype}.Watermarking techniques are actively researched to address copyright and misuse concerns in diffusion-based generative models. Here, we focus on the two main approaches, i.e, embedding watermarks within the model and, embedding watermarks in generated images.

Early research proposed methods for watermarking GANs by constructing mappings between trigger inputs and generator outputs with regularization constraints~\citep{yu2021artificial,ong2021protecting,fei2022supervised}. However, these techniques cannot be directly applied to diffusion models due to architectural differences~\citep{creswell2018generative,cao2022survey}. Additionally, Wen et al. proposed a robust tree-ring watermarking method against multiple image transformations and attacks~\citep{wen2023tree}. In addition, Li et al. introduced a diffusion-based watermarking approach, DiffWA~\citep{li2023diffwa}, which leverages the diffusion process to embed noise- and tamper-resistant watermarks.

In generative models, many works attempt to embed watermarks within the training dataset to protect the generative model's training data~\citep{chai2020what}. However, this approach may be inefficient, as embedding new information requires costly retraining. Some research combines watermark embedding with the generative process ~\citep{gragnaniello2021are,wang2020cnn}, aligning more closely with model watermarking techniques. However, this approach faces two key limitations: (\textit{i}) it applies primarily to GANs, while latent diffusion models (LDMs) are increasingly replacing GANs for most applications and, (ii) the watermark is embedded from the start of model training~\citep{fei2022supervised,lin2022cycleganwm}, a strategy that is challenging to sustain, given the resource-intensive nature of generative model training. Studies have shown that time-optimized fine-tuning of a generative model's latent decoder combined with an appropriate watermark extractor can achieve effective watermarking results~\citep{fernandez2023stable}.