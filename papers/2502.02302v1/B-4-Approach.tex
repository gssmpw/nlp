\section{The Proposed Approach}
\label{sec:method}

\par\smallskip\noindent
\subsection{Overview}
We now illustrate the proposed \emph{Edge-Enhanced Graph Feature Preference Learning} (\alg) model, which enhances the effectiveness of the information exchange procedure by introducing the edge representation as relation representation. 
%
Following the structure of the message-passing framework, each layer of \alg\ is mainly composed of two phases, namely Information Propagation and Information Aggregation.
    
\textbf{Information Propagation}: Different from the existing models (\emph{i.e.}, GCN and GAT), which only send information from one node to another in the information propagation phase, \alg\ first extracts the relation representation for edges from the corresponding node representations. 
Subsequently, each node sends the self-information to its neighbors, and features inside the sent information are magnified or shrunk through the corresponding edges, which finally forms a different ‘sent message’ according to the characteristics of the target nodes.

\textbf{Information Aggregation}: Upon receiving feature-preferred information from its neighbors, each node proceeds to refine its representation by integrating the accumulated messages.
Similarly, each edge receives the feature-preferred information from neighbors, and then, the node updates its representation by summing up the received message.

In general, each layer of the \alg~model is illustrated in Fig. \ref{fig:intro}. 
%
For each edge $e_{ij}$, there is a corresponding vectorized relation representation $\mathbf{r}_{ij}$ derived from the interaction between the connected nodes by using an initialized weight vector $\mathbf{W}(\mathbf{h}_{i}, \mathbf{h}_{j})$, and then each node sends information refined by the relation representation. 
%
Finally, the representation of each node is updated by integrating all of the refined information.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.9\textwidth]{Fig/Framework_v3.pdf}
    \caption{Illustration of the $l$-th layer of the \alg~model. The \alg~model achieves the final representation of the target node in a heterogeneous graph through node and edge embeddings, information propagation, and aggregation processes.}
    \label{fig:intro}
\end{figure*}

\subsection{Feature Projection} %Learning Feature Preference}

{\bf Node Nonlinear Transformation.} 
As the input features of different node types may differ in dimensionality, we apply a linear layer with bias for each node type and then utilize a non-linear mapping (\emph{e.g.}, using a rule or softmax function) through the activation function to map all node features to a shared feature space.
%
Typically, we use a learnable type transformation matrix $\mathbf{W}^{\mathbf{T}_{v}}$, where $\mathbf{T}_{v}$ is the set of node types, to map nodes of different types to the same dimensional space $\mathbf{H}^{l} = \mathbf{W}^{\mathbf{T}_{v}} * \mathbf{F}$.
To better map different types of nodes to the same semantic space, we apply a nonlinear activation function after a fully connected layer, as follows:
\begin{equation}
    \mathbf{H}^{l} = \text{LeakyRelu}(\mathbf{W}^{\mathbf{T}_{v}} * \mathbf{F} + b),
    \label{eq:6}
\end{equation}
where $\mathbf{F} = [ \mathbf{f}_1, \dots, \mathbf{f}_n ]$ is the attribute matrix of the node, and $\mathbf{H}^{l}=[\mathbf{h}^{l}_1, \dots, \mathbf{h}^{l}_n]$ is the representation matrix of the node.

{\bf Edge Type Initiation.} 
For heterogeneous graph $G$ with $\mathbf{T}_{e}=\{\phi(e): \forall e \in \mathcal{E}\}$ types of edges, an edge type dictionary $\mathbf{D}=\{E_1, E_2, \cdots, E_n\}$ is constructed by looking at the types of edges as different tokens and assigning an initialisation encoding vector $\mathbb{R}=\{\mathbf{r}_1,\mathbf{r}_2, \cdots ,\mathbf{r}_n\}$ of the corresponding type to the edges indexed by the different types based on the edge type dictionary. 
This vectorised representation holds the semantic information of the edge types:
\begin{align}
    \hat{\mathbf{r}}_{i j}^{l} &= f\left(\mathbf{T}_e=\{\phi(e): v_e \in \mathcal{E}\}\right),
    \label{eq:7}
\end{align}
where $f(.)$ is the initialization function for edge types, taking the values of each edge as input and producing corresponding edge vectors.

\subsection{Information Propagation} \label{sec:IP}
The edge type-based feature preference representation makes full use of the type information of the edges in the dataset by mapping the edge type information to the same data space as the node feature information, and by co-training with the node features in the same data space. 
%
The resulting feature preference representation can be used to scale each dimensional feature of the node information, rather than simply scaling all dimensional features with a fixed scalar.

We map the initialized coding vector $R$ to the data dimension space of the nodes via a learnable feature transformation matrix $w^{l}$, providing the basis for the co-training of node and edge features. 
The preference representation step for edge features can be expressed as:
\begin{align}
    \mathbf{r}_{i j}^l &= \delta(\hat{\mathbf{r}}_{i j} \cdot w^l),
    \label{eq:8}
\end{align}
where $\delta(\cdot)$ denotes the learnable initialization encoding function that assigns a corresponding initialisation encoding vector $\mathbf{r}$ to each edge type based on a dictionary of edge types, and $w$ is a learnable parameter shared by all types of edges that are used to map the encoding vectors of the edge types to the node feature space.

We apply edge feature preferences to a message-passing framework to replace aggregation weights in the form of scalars learned in convolutional and attentional neural networks. 
%
We propose to use learnable edge feature preferences to act as aggregation scales that both scale the message's size and learn the features' preferences. 
%
Specifically, the message-passing phase can be represented as:
\begin{equation}
    \mathbf{M}_{ij}^l = s\left(\mathbf{h}_j^l, \mathbf{r}_{ij}^l\right)=\mathbf{h}_j^l \cdot \mathbf{r}_{ij}^l,
    \label{eq:9}
\end{equation}
where $\mathbf{M}_{ij}^l$ denotes the message sent from node $v_j$ to node $v_i$ at layer $l$. $s(\cdot)$ denotes the message transfer function, and $\cdot$ denotes the dot product.

\subsection{Information Aggregation} \label{sec:IA}
In this phase, nodes update their representation by aggregating the received information via the sum aggregator, which can be formalized as:
% \begin{equation}
%     \mathbf{h}_i^{l+1} \leftarrow \underset{j \in \mathcal{N}_i}{\sum_{j i}}\left(\mathbf{M}_{j i}^l\right)
% \end{equation}
\begin{equation}
    \mathbf{h}_i^{l+1} \leftarrow \underset{j \in \mathcal{N}_i}{\operatorname{SUM}_{ij}}(\mathbf{M}_{ij}^l).
    \label{eq:sum}
\end{equation}
By giving different weights to the target node and neighbors, we implement two kinds of sum aggregators as follows:
\begin{itemize}
    \item[1).]{{\bf Node Residual.} For the creation of node representations that span across layers, we introduce a pre-activation residual connection. The aggregation for the $l$-th layer can be formulated as:
    % We add a pre-activation residual connection for layer-spanning node representation. The $l$-th layer aggregation can be expressed as:
    \begin{equation}
        \mathbf{h}_i^{l+1}=\sigma\left(\sum_{j \in \mathcal{N}_i} \alpha_{ij}^{l} \mathbf{W}^{l} \mathbf{h}_j^{l}+\mathbf{h}_i^{l}\right),
       \label{eq:node1}
    \end{equation}
    where, $\alpha_{ij}^l$ represents the attention weight corresponding to edge $\langle i, j\rangle $ for the $l$-th layer, and $\mathbf{W}^l \in \mathbb{R}^{n \times {d^{l}}}$ is the trainable projection matrix from the $l$-th layer. When there's a dimension alteration in the $l$-th layer, an extra trainable linear transformation $\mathbf{W}_{\text{res}}^{(l)} \in \mathbb{R}^{d^{l+1} \times d^{l}}$ becomes necessary. This can be expressed as:
    % $\alpha_{i j}^{l}$ is the attention weight about edge $<i, j>$. When the dimension changes in the $l$-th layer, an additional learnable linear transformation $W_{\text {res }}^{(l)} \in \mathbb{R}^{d_{l+1} \times d_l}$ is needed, i.e.,
    \begin{equation}
        \mathbf{h}_i^{l+1}=\sigma(\sum_{j \in \mathcal{N}_i} \alpha_{i j}^{l} \mathbf{W}^{l} \mathbf{h}_j^{l}+\mathbf{W}_{\text {res }}^{l} \mathbf{h}_i^{l}),
        \label{eq:node2}
    \end{equation}
    }

    \item[2)]{{\bf Edge Residual.} Recently, Realformer~\cite{he2020realformer} illustrated the advantageous nature of applying residual connections to attention scores. we incorporate residual connections into these scores:
    % Realformer \cite{he2020realformer} demonstrated that residual connection on attention scores is also beneficial. After calculating the initial attention scores $\hat{\alpha}$ using Eq. (7), we add residual connections to them:
    \begin{equation}
        \alpha_{i j}^{(l)}=(1-\beta) \hat{\alpha}_{i j}^{(l)}+\beta \alpha_{i j}^{(l-1)},
        \label{eq:edge}
    \end{equation}
    where hyperparameter $\beta \in [0, 1]$ is a scaling factor, $\hat{\alpha}$ employs both edge type embeddings and node embeddings to compute the attention score.
    }
\end{itemize}

% Through the aggregation operation, by receiving the information refined from the relation representations, nodes can accumulate increasingly more related information, and thus can enable nodes with similar features to be closer.
% \subsection{First-order neighbor Edge}
% This module is about First-order neighbot Edge.
% \subsection{Model Learning} \label{sec:MT}
% % After setting the final dimension of HGNNs the same as the number of classes, we then adopt the most usual loss functions. For \emph{single-label} classification, we use softmax and cross-entropy loss. For \emph{multi-label} datasets, i.e. IMDB in \alg, we use a sigmoid activation and binary cross-entropy loss. We find that an $L_{2}$ noramalization on the output embedding is extremely useful, i.e.,
% Having aligned the final dimension of HGNNs with the class count, we employ standard loss functions. For \emph{single-label} classification, softmax and cross-entropy loss are used. For \emph{multi-label} datasets like IMDB in \alg, we apply sigmoid activation and binary cross-entropy loss. Notably, we observe the high utility of $L_{2}$ normalization on the output embedding.
% % \begin{equation}
% %     \mathbf{h}_i^L = 
% % \end{equation}
% \begin{equation}
% \boldsymbol{o}_i=\frac{\boldsymbol{h}_i^{L}}{\left\|\boldsymbol{h}_i^{L}\right\|},
% \label{eq:normalization}
% \end{equation}
% where $\boldsymbol{o}_i$ signifies the output embedding of node $i$. Normalization on the output embedding is a prevalent practice in retrieval-based tasks, as it ensures that the dot product corresponds to cosine similarity subsequent to normalization.
% % $\boldsymbol{o}_i$ is the output embedding of node $i$. The normalization on the output embedding is very common for retrieval-based tasks, because the dot product will be equivalent to the cosine similarity after normalization.

% In the output layer, the predicted vector $z_{i} \in \mathbb{R}^{1 \times c}$ of node $v_{i}$ is obtained from $\boldsymbol{o}_i$ as follows:
% \begin{equation}
%     \mathbf{z}_i=\operatorname{Softmax}\left(\boldsymbol{o}_i \cdot \mathbf{W}_z\right) % \mathbf{h}_i^L
%     \label{eq:z}
% \end{equation}
% where $\mathbf{W}_{z} \in \mathbb{R}^{d^{L \times c}}$ maps node representation to $c$-dimensional vector, which is normalized by Softmax(·) to make each dimension indicate the probability of the corresponding label.

% After obtaining the probability matrix $\mathbf{Z} = [z_{1}; \dots , z_{n}] \in \mathbb{R}^{n \times c}$, by computing the cross-entropy loss of the training data, the loss function of \alg\ with Similar Relation Learning is as follows: % ($abbr$. \alg\ $_{c}$)
% \begin{equation}
% \mathcal{L}=-\sum_{i \in \mathcal{V}_{t r a i n}} \mathbf{Y}_{i *} \cdot \log \left(\mathbf{z}_i^{\top}\right) +\lambda\|\Theta\|_2
% \label{eq:loss}
% \end{equation}
% where $\mathcal{V}_{t r a i n}$ denotes the index set of nodes in the training set, $\mathbf{Y}_{i *} \in \mathbb{R}^{1 \times c}$ is the $i$-th row vector of the indicator matrix $\mathbf{Y}$ denoting the label vector of node $v_{i}$, and $\|\Theta\|_2$ is a regularization term of model parameters with weight decay ratio $\lambda$.

% % Specifically, when extracting the transferring relation, we need to take into account the transferring constraint. 
% % That is, the loss function of \alg with Transferring Relation Learning (abbr. GFPNt) has the following form:
% % \begin{equation}
% % \begin{aligned}
% % \mathcal{L}_t= & \sum_{l=0}^L \sum_{e_{j i} \in \mathcal{E}}\left\|\mathbf{h}_j^l \cdot \mathbf{W}_t^l-\mathbf{h}_i^l \cdot \mathbf{W}_t^l-\hat{\mathbf{r}}_{j i}^l\right\|_2^2 \\
% % & -\sum_{i \in \mathcal{V}_{\text {train }}} \mathbf{Y}_{i *} \cdot \log \left(\mathbf{z}_i^{\top}\right)+\lambda\|\Theta\|_2
% % \end{aligned}
% % \end{equation}

% % As for the back-propagation process, we adopt the Adam algorithm [47] to optimize the model parameters. For clarity, the training procedure of GFPNc (resp. GFPNt) is summarized in Algorithm 1.

% \subsection{Algorithm and Complexity analysis} \label{sec:IP}
% Based on the above inferences,  we design the algorithm
% of \alg~as in Algorithm \ref{alg:new}. 
% We will analyze the major computational complexity of the $l$-th layer of \alg\ in a training epoch. 
% In the information propagating phase, for convenience, we first analyze the complexity of one connected pair $(v_{i}, v_{j})$. 
% In the Feature projection phase, node representation and feature representation are calculated by Eq. (\ref{eq:6}) and Eq. (\ref{eq:7}) with time complexity of $O(n)$ and $O(e)$ respectively. 
% In the Information propagation phase, the information representation associated with multiple nodes can be obtained through Eq. (\ref{eq:9}) with a time complexity of $O(e/2)$. 
% In the Information aggregation phase, the neighbourhood information between different nodes is aggregated through Eq. (\ref{eq:sum}) with a time complexity of $O(1)$. The time complexity obtained by combining the three phases is $O(n)$.
\subsection{Model Training} \label{sec:MT}
% After setting the final dimension of HGNNs the same as the number of classes, we then adopt the most usual loss functions. For \emph{single-label} classification, we use softmax and cross-entropy loss. For \emph{multi-label} datasets, i.e. IMDB in \alg, we use a sigmoid activation and binary cross-entropy loss. We find that an $L_{2}$ noramalization on the output embedding is extremely useful, i.e.,
Having aligned the final dimension of HGNNs with the class count, we employ standard loss functions. 
For \emph{single-label} classification, softmax and cross-entropy loss are used. 
For \emph{multi-label} datasets like IMDB in \alg, we apply sigmoid activation and binary cross-entropy loss. 
Notably, we observe the high utility of $L_{2}$ normalization on the output embedding.
% \begin{equation}
%     \mathbf{h}_i^L = 
% \end{equation}
\begin{equation}
{o}_i=\frac{\mathbf{h}_i^{L}}{\left\|\mathbf{h}_i^{L}\right\|},
\label{eq:normalization}
\end{equation}
where ${o}_i$ signifies the output embedding of node $i$. Normalization on the output embedding is a prevalent practice in retrieval-based tasks, as it ensures that the dot product corresponds to cosine similarity subsequent to normalization.
% $\boldsymbol{o}_i$ is the output embedding of node $i$. The normalization on the output embedding is very common for retrieval-based tasks, because the dot product will be equivalent to the cosine similarity after normalization.

In the output layer, the predicted vector $\mathbf{z}_{i} \in \mathbb{R}^{1 \times c}$ of node $v_{i}$ is obtained from ${o}_i$ as follows:
\begin{equation}
    \mathbf{z}_i=\operatorname{Softmax}\left({o}_i \cdot \mathbf{W}_z\right) % \mathbf{h}_i^L
    \label{eq:z},
\end{equation}
where $\mathbf{W}_{z} \in \mathbb{R}^{d^{L \times c}}$ maps node representation to $c$-dimensional vector, which is normalized by Softmax(·) to make each dimension indicate the probability of the corresponding label.

After obtaining the probability matrix $\mathbf{Z} = [\mathbf{z}_{1}; \mathbf{z}_{2}; \dots , \mathbf{z}_{n}] \in \mathbb{R}^{n \times c}$, by computing the cross-entropy loss of the training data, the loss function of \alg\ with Similar Relation Learning is as follows: % ($abbr$. \alg\ $_{c}$)
\begin{equation}
\mathcal{L}=-\sum_{i \in \mathcal{V}_{t r a i n}} \mathbf{Y}_{i *} \cdot \log \left(\mathbf{z}_i^{\top}\right) +\lambda\|\Theta\|_2,
\label{eq:loss}
\end{equation}
where $\mathcal{V}_{t r a i n}$ denotes the index set of nodes in the training set, $\mathbf{Y}_{i *} \in \mathbb{R}^{1 \times c}$ is the $i$-th row vector of the indicator matrix $\mathbf{Y}$ denoting the label vector of node $v_{i}$, and $\|\Theta\|_2$ is a regularization term of model parameters with weight decay ratio $\lambda$.

% Specifically, when extracting the transferring relation, we need to take into account the transferring constraint. 
% That is, the loss function of \alg with Transferring Relation Learning (abbr. GFPNt) has the following form:
% \begin{equation}
% \begin{aligned}
% \mathcal{L}_t= & \sum_{l=0}^L \sum_{e_{j i} \in \mathcal{E}}\left\|\mathbf{h}_j^l \cdot \mathbf{W}_t^l-\mathbf{h}_i^l \cdot \mathbf{W}_t^l-\hat{\mathbf{r}}_{j i}^l\right\|_2^2 \\
% & -\sum_{i \in \mathcal{V}_{\text {train }}} \mathbf{Y}_{i *} \cdot \log \left(\mathbf{z}_i^{\top}\right)+\lambda\|\Theta\|_2
% \end{aligned}
% \end{equation}

% As for the back-propagation process, we adopt the Adam algorithm [47] to optimize the model parameters. For clarity, the training procedure of GFPNc (resp. GFPNt) is summarized in Algorithm 1.

\subsection{Algorithm and Complexity analysis} \label{sec:IP}
Based on the above inferences,  we design the algorithm of \alg~as in Algorithm \ref{alg:new}. 
We will analyze the major computational complexity of the $l$-th layer of \alg\ in a training epoch. 
In the information propagating phase, for convenience, we first analyze the complexity of one connected pair $(v_{i}, v_{j})$. 
In the feature projection, node representation and feature representation are calculated by Eq. (\ref{eq:6}) and Eq. (\ref{eq:7}) with time complexity of $O(n)$ and $O(e)$ respectively. 
In the information propagation, the information representation associated with multiple nodes can be obtained through Eq. (\ref{eq:9}) with a time complexity of $O(e/2)$. 
In the information aggregation, the neighbourhood information between different nodes is aggregated through Eq. (\ref{eq:sum}) with a time complexity of $O(1)$. 
The time complexity obtained by combining the three phases is $O(n)$.

\begin{algorithm}[!t]
    % \small
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Init}{Init.}
    \SetKwInOut{Para}{Para.}
    \newcommand\mycommfont[1]{\ttfamily\textcolor{RoyalBlue}{#1}}
    \SetCommentSty{mycommfont}
    \Input{The undirected attributed network: $\mathcal{G}=\{\mathcal{V}, \mathcal{E}, \mathbf{F}, \phi, \psi \}$ }
    \Output{The node representation matrix $\mathbf{H}^{L}$ and the predicted matrix $\mathbf{Z}$}
    \Init{Node representation matrix $\mathbf{H}^{0} = \mathbf{F}$, global sharing learnable edge mapping matrix $\mathbf{W}^{r}$, and model parameters $\Theta$}
	\BlankLine
        \While{$\mathcal{L}$ does not converge}{ % (\emph{resp}. \mathcal{L}_{t})
	\For {$l = 0, \ldots, L-1 $}{
        \tcc{Feature Projection}
        Compute node representation by Eq.(\ref{eq:6})\;
        Computer relation representation of node representation $\hat{\mathbf{r}}_{ij}^{l}$ of the feature bu Eq.(\ref{eq:7})\;
        
        \tcc{Information Propagation}
        Propagate the information $\mathbf{M}^{l}_{ij}$ from node $v_{i}$ to node $v_{j}$ by Eq.(\ref{eq:9})\;
        % Update the relation representation $r^{0}_{ji}$ by Eq.(\ref{eq:8})\;
        
        \tcc{Information Aggregation}
        Aggregate feature of neighbors to get node representation $\mathbf{H}^{l+1}$ by Eq.(\ref{eq:sum})
        % Eqs. (\ref{eq:node1}) and (\ref{eq:node2}) (Node Residual) or Eq. \ref{eq:edge} (Edge Residual)
    }
    Computer the normalize representation b Eq.(\ref{eq:normalization})\;
    Compute the predicted matrix $\mathbf{Z}$ by Eq. (\ref{eq:z})\;
    Compute the model loss $\mathcal{L}$ by Eq. (\ref{eq:loss})\;
    Update model parameters $\Theta$ by the Adam optimizer\;
    }
    \caption{The \alg\ Algorithm}
    \label{alg:new}
\end{algorithm}

