\section{Introduction}
Self-consistency \citep{COT} is a well-established decoding method that enhances model performance by aggregating multiple stochastic samples via majority voting. It has been demonstrated to be highly effective across a variety of tasks \citep{USC,wang-etal-2024-integrate}, particularly in improving reasoning abilities \citep{COT}. Despite its empirical success, the underlying mechanisms behind self-consistency remain underexplored.
In this work, we revisit self-consistency from a distributional perspective, reframing it as a dynamic alignment problem, to achieve more robust and effective performance in answer aggregation. 

\begin{figure}[t]
\centering
\includegraphics[width=0.8\linewidth]{figs/Sampling_Distribution.pdf}
\caption{(a) Multiple stochastic sampling for fitting the true distribution. As the sample size increases, the noise gradually diminishes, and ultimately, the top-1 sampled answer aligns with the true distribution. (b) As the temperature decreases, the confidence in the true distribution increases, allowing alignment with the true distribution to be achieved with fewer samples.}
\label{fig:intro}
\end{figure} 


Recent work \citep{ISL,ESC} argue that by combining different reasoning traces via majority voting, self-consistency can avoid local optima and reduce the high variance associated with single-sample outputs, ultimately converging to the model’s true answer distribution (see Figure~\ref{fig:intro} (a)). Building on this insight, our work provides a formal definition of its convergence and derives practical criteria for the assessment. Through our convergence analysis, we reveal that this conventional view is limited to a fixed true distribution, overlooking the crucial impact that parameter-controlled decoding (typically the temperature) has on the true distribution (see Figure~\ref{fig:intro} (b)). Moreover, practical applications are often constrained by the sampling. Therefore, we raise two key questions:
(1) Alignment under Constraints: How does decoding diversity affect the alignment between the sampling distribution and the true answer distribution when only a limited number of samples is available? (2) Dynamic Alignment: Can we actively calibrate the diversity in practice to accelerate and stabilize convergence, rather than passively waiting for asymptotic convergence?



To explore these issues, we analyze the impact of diversity on self-consistency. The temperature parameter not only governs the randomness of sampling but also directly shapes the true answer distributions. Our findings reveal that as the number of samples approaches infinity, a higher temperature yields a more ideal true answer distribution. However, when the sample size is finite, the optimal sampling temperature decreases as the number of samples diminishes. This leads to a trade-off: low-diversity sampling quickly concentrates the answers and suppresses noise but risks amplifying model biases, whereas high-diversity sampling disperses the answers, requiring more samples to stabilize, yet it enables the exploration of a potentially superior true distribution.

In summary, our comprehensive analysis indicates that the effectiveness of self-consistency hinges on a dynamic alignment between the confidence of the sampling distribution and the intrinsic uncertainty of the true answer distribution—a relationship that is influenced by the number of samples. Ideally, the sampling distribution should be controlled such that the majority voting outcomes closely match the true distribution, and on this basis, explores toward an improved true distribution.

Based on this insight, we propose a confidence-driven diversity optimization mechanism that dynamically adjusts the temperature based on real-time confidence values derived from the answer distribution. When early samples show only a small probability gap between the top two most-voted answers, our mechanism sharps the sampling distribution to better align it with the true distribution. Conversely, when confidence is high, the temperature is increased to explore potentially superior distributions. We derive a confidence threshold to determine the direction of temperature adjustment, providing theoretical support for this process. This closed-loop control dynamically synchronizes the sampling distribution with the latent answer distribution, ensuring efficient convergence while actively pursuing a better distribution.
Experimental results across various model types and size indicate that it can achieve simultaneous improvements in both average and best performance across different initial temperatures, without requiring any additional training, valid data, reward models, or external modules.