\section{Conclusion}
This work revisits self-consistency through the lens of dynamic distributional alignment, challenging the conventional view of passive convergence to a fixed answer distribution. We demonstrate that decoding temperature critically shapes both sampling behavior and the latent answer distribution itself, revealing a trade-off between diversity-driven exploration and finite-sample convergence. By introducing a confidence-aware mechanism that dynamically adjusts temperature based on real-time alignment with the distribution, we bridge this gap, enabling efficient synchronization between sampling dynamics and evolving answer distributions. Empirical results validate that this approach outperforms static strategies, achieving robust performance improvements without external resources. Our findings position self-consistency as an active alignment challenge, opening avenues for adaptive aggregation frameworks in reasoning tasks.