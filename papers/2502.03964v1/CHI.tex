%%
%% This is file `sample-sigconf-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}

\settopmatter{printacmref=false}
\setcopyright{none}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}


\usepackage{array} 
\usepackage{multirow} 
\usepackage{csquotes}

\newcommand{\zyq}[1]{\textcolor{blue}{[Zhang: #1]}}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[CHI '25]{Late Breaking Work of the CHI Conference on Human Factors in Computing Systems}{April 26--May 1,
  2025}{Yokohama, Japan}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2018/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{``It Warned Me Just at the Right Moment": Exploring LLM-based Real-time Detection of Phone Scams}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato et al.}
\author{Zitong Shen}
\affiliation{%
  \institution{The Hong Kong Polytechnic University}
  \city{Hong Kong}
  \country{China}
}
\email{esther.shen@connect.polyu.hk}

\author{Sineng Yan}
\affiliation{%
  \institution{Shenzhen University}
  \city{Hong Kong}
  \country{China}
}
\email{yansineng2023@email.szu.edu.cn}

\author{Youqian Zhang}
\authornote{Corresponding author.}
\affiliation{%
  \institution{The Hong Kong Polytechnic University}
  \city{Hong Kong}
  \country{China}
}
\email{you-qian.zhang@polyu.edu.hk}

\author{Xiapu Luo}
\affiliation{%
  \institution{The Hong Kong Polytechnic University}
  \city{Hong Kong}
  \country{China}
}
\email{csxluo@comp.polyu.edu.hk}

\author{Grace Ngai}
\affiliation{%
  \institution{The Hong Kong Polytechnic University}
  \city{Hong Kong}
  \country{China}
}
\email{csgngai@comp.polyu.edu.hk}

\author{Eugene Yujun Fu}
\affiliation{%
  \institution{The Education University of Hong Kong}
  \city{Hong Kong}
  \country{China}
}
\email{eugenefu@eduhk.hk}

\begin{abstract}
Despite living in the era of the internet, phone-based scams remain one of the most prevalent forms of scams. 
These scams aim to exploit victims for financial gain, causing both monetary losses and psychological distress. 
While governments, industries, and academia have actively introduced various countermeasures, scammers also continue to evolve their tactics, making phone scams a persistent threat.
To combat these increasingly sophisticated scams, detection technologies must also advance. 
In this work, we propose a framework for modeling scam calls and introduce an LLM-based real-time detection approach, which assesses fraudulent intent in conversations, further providing immediate warnings to users to mitigate harm.
Through experiments, we evaluate the method's performance and analyze key factors influencing its effectiveness. 
This analysis enables us to refine the method to improve precision while exploring the trade-off between recall and timeliness, paving the way for future directions in this critical area of research.
% Despite living in the era of the internet, phone-based scams remain one of the most prevalent forms of scams. 
% These scams aim to exploit victims for financial gain, often causing not only monetary losses but also psychological distress for the victims. 
% While governments, industries, and academia have actively introduced various countermeasures, scammers also continue to evolve their tactics, making phone scams a persistent and escalating threat.
% To combat these increasingly sophisticated scams, detection technologies must also advance. 
% In this work, we propose a framework for modeling scam calls and introduce an LLM-based real-time detection approach, which assesses the likelihood of fraudulent intent in conversations, further allowing a system to provide immediate warnings to its users so as to mitigate harm.
% Through experiments, we evaluate the method's performance in detecting phone scams and analyze key factors that influence its effectiveness. 
% This analysis enables us to improve the method to balance the trade-off between precision and recall, ensuring practical usability. 
% Furthermore, we explore how such a detection method impacts user experience and discuss future directions for advancing this critical area of research.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120</concept_id>
       <concept_desc>Human-centered computing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405</concept_id>
       <concept_desc>Applied computing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10002978.10003029.10011703</concept_id>
       <concept_desc>Security and privacy~Usability in security and privacy</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}
\ccsdesc[500]{Human-centered computing}
\ccsdesc[500]{Applied computing}
\ccsdesc[500]{Security and privacy~Usability in security and privacy}
% \ccsdesc[500]{Computing methodologies~Natural language processing}


%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Phone Scam, Fraud, Large Language Model, Real-time, Detection}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base
%  seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}
%\received{20 February 2007}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{INTRODUCTION}
\label{sec:introduction}

In recent years, numerous news reports have highlighted the devastating impact of fraudulent phone calls, which have caused victims to suffer catastrophic financial losses. 
For instance, an 82-year-old retiree lost \$690,000 of their life savings to a phone scam~\cite{new2024deepfakes}. 
Unfortunately, such tragedies continue to occur at an alarming rate. 
The 2024 Global State of Scams Report~\cite{rogers2024international} reveals that phone scams siphoned off \$1.03 trillion globally over the past year, highlighting the severity of this issue.
The harm caused by phone scams extends beyond financial loss. 
Studies have shown the emotional and psychological toll on victims, including prolonged stress, anxiety, depression, and, in extreme cases, even suicide~\cite{hu2022btg, hu2024gat}. 

% As we move into the era of artificial intelligence (AI) and increasingly accessible AI tools, the threat posed by phone scams is likely to escalate. 
% Scammers are leveraging advanced AI technologies to craft more convincing scams, making detection and prevention significantly more challenging. 
% This rapidly evolving landscape necessitates innovative solutions to counteract the growing sophistication of fraud techniques.

Governments, industries, and academia have implemented various measures to combat of phone scams, as summarized in the taxonomy of phone scam prevention methods in Fig.~\ref{figure1}.
Governments primarily focus on prosecuting criminal organizations and educating the public about fraud prevention~\cite{burke2022educational, deliema2020financial}. 
The industry has developed pre-call prevention methods, such as call-blocking applications~\cite{truecaller2024} and blacklists~\cite{pandit2023combating}, which attempt to filter out potential scam calls before they reach users. 
Meanwhile, academic research has explored post-call analysis techniques, employing AI tools to retrospectively identify scam patterns in call data~\cite{peng2018fraud,tseng2015fraudetector, chadalavada2024distinguishingscamsfraudensemble, chang2024exposingllmvulnerabilitiesadversarial, shen2024combatingphonescamsllmbased}.
Despite these efforts, the effectiveness of these approaches is increasingly undermined by the adaptability of scammers. 
Pre-call prevention methods, such as caller ID systems and blacklists, are vulnerable to caller ID spoofing and the use of VoIP services, which allow scammers to change their phone numbers frequently and evade detection~\cite{mustafa2018end, xing2020automated}. 
Likewise, public education campaigns, while valuable, cannot fully prevent individuals from falling victim to scams, as scammers exploit psychological manipulation to bypass even well-educated users' defenses~\cite{parti2023if}.
Post-call analysis, using methods such as text classification, graph analysis, and even LLM-based approaches,while useful for identifying patterns in scam calls after they occur, fails to provide timely intervention. 
In many cases, victims may transfer money or share sensitive information during the call itself~\cite{razaq2021we}.
These challenges highlight a critical gap in existing anti-scam strategies: the lack of effective real-time detection systems that can intervene during ongoing scam calls to prevent harm before it occurs.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{figure1.png}
    \caption{Taxonomy of Phone Scam Prevention Methods: A Temporal Perspective.}
    \label{figure1}
     % \vspace{-10pt}
\end{figure*}

To address this pressing gap, we propose a novel LLM-based real-time phone scam detection framework. 
Unlike pre-call and post-call approaches, our system analyzes phone conversations in real time during the call, enabling immediate detection of potential scams and providing timely warnings to users. 
This real-time capability is especially critical in situations where scammers apply psychological pressure, as early intervention can disrupt the scam process and prevent victims from making irreversible decisions.
Our approach builds on recent advancements in large language models (LLMs), which have demonstrated exceptional capabilities in understanding and analyzing human language. 
By leveraging LLMs, our framework can detect subtle linguistic cues and conversational anomalies indicative of scam behavior. 
Specifically, our work aims to address the following research questions:
\begin{itemize}
    \item \textbf{RQ1: How does our LLM-based real-time detection system perform in identifying phone scams?} To answer this question, we evaluate the performance of our framework using publicly available datasets and investigate its ability to detect scams during live phone conversations.

    \item \textbf{RQ2: What factors influence the method’s detection performance?} Through comprehensive analysis, we identify key factors that impact the system's effectiveness. These insights guide us in improving the framework to achieve a balance between precision and recall.
    
    % \item \textbf{RQ3: What are the potential future considerations and directions to improve user experience?} We explore the usability and impact of the system from the perspective of end users, ensuring that it provides timely and effective assistance without causing undue disruption or false alarms.
\end{itemize}
By answering these research questions, we aim to provide a comprehensive understanding of the capabilities and limitations of LLM-based real-time phone scam detection, optimize its performance for practical deployment, and evaluate its potential to safeguard users while delivering a seamless and effective intervention experience.


\section{SYSTEM MODELING AND DETECTION METHOD}
\label{sec:system_modeling_and_detection_method}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figure2.png}
    \caption{The system consists of three components, including ``Scammer'', ``User'', and ``LLM-based Detector''.}
    \label{fig:system_architecture}
\end{figure*}

In this section, we propose a high-level system model for phone scam detection, abstracted from reported cases/news. 
The model integrates our LLM-based detection method, which operates in real time to protect users during phone conversations. 

\subsection{System Model}

Below, we detail the roles, objectives, and capabilities of the three primary components of the system: the Scammer, the User, and the LLM-based Detector, as illustrated in Fig.~\ref{fig:system_architecture}.

\subsubsection{Scammer}
The scammer is the initiator of fraudulent calls, driven by financial gain and the exploitation of their targets. To achieve their goals, scammers employ a range of strategies, leveraging modern technology and psychological manipulation.
The scammer collects personal data about a target through public social media profiles, data breaches, or other sources. 
This information helps scammers build credibility and gain the trust needed to manipulate their victims effectively~\cite{gressel2024discussion}.
Relying on pre-defined scripts or playbooks, scammers can extract sensitive information, financial assets, or other valuable property.
Further, the scammer can enhance their deception with AI-powered technologies such as voice cloning tools which could impersonate loved ones, trusted authorities, or even political figures to manipulate victims~\cite{kennedy2014voice, cheyenne2024scammers}.
The scammer’s attack vector is through phone calls, exploiting the direct voice communication to manipulate victims.
Please note that in this work, we focus exclusively on audio-based phone scams and do not consider video call scams (e.g., deepfake-based attacks) as part of the system.

\subsubsection{User}
The User is the target of the scammer and is the primary beneficiary of the scam detection method.
The user’s primary objective is to avoid falling victim to scams while maintaining the ability to engage in normal phone communication. however, users do not assume every call is fraudulent, as such an assumption would significantly disrupt normal daily communication.
Nonetheless, several factors make users vulnerable to scams.
While users may have a basic awareness of phone scams and some level of risk aversion, they often lack the expertise required to identify sophisticated or evolving tactics. 
Emotional manipulation, including inducing panic or trust, is a key factor that makes users susceptible~\cite{mohamad2023anatomy}
Under the influence of the scammer, users may be coerced into disclosing sensitive information, transferring funds, or making decisions that conflict with their best interests.

\subsubsection{LLM-based Detector}
The LLM-based detector, operating on the user's phone, serves as the protective mechanism within the system. Its primary objective is to analyze ongoing phone conversations in real time, detect potential scams, and provide immediate intervention.
The detector continuously analyzes the content of the phone call through the text converted from the live voice stream, leveraging advanced LLM capabilities to identify suspicious patterns or conversational anomalies indicative of fraudulent activity. 
% It applies advanced LLM capabilities to detect suspicious patterns, or conversational anomalies indicative of a potential scam.
If no scam tendencies are detected, the detector remains unobtrusive, passively monitoring the conversation. However, when a scam pattern is identified, it generates an alert message to notify the user. 
This alert is conveyed through an appropriate medium (e.g., visual or audio notification) to warn the user of the potential danger. 
The timely alert acts as a critical intervention, allowing the user to terminate the call to avoid further potential harm.

\subsection{Detection Method}

The LLM-based detector performs fraud assessments by analyzing the conversation after each speaker's turn. 
When a participant, either the scammer or the user, completes their utterance, the detector evaluates the newly received input while maintaining contextual awareness of the prior conversational history.
This turn-by-turn evaluation ensures the timely detection of suspicious elements, leveraging the entire conversation history to make informed decisions. 

We utilize two distinct types of prompts in our LLM-based detector: a binary classification prompt and an enhanced prompt that incorporates an uncertainty category.
Real-time detection utilizing the binary classification prompt is referred to as ``RT'', while real-time detection leveraging the enhanced prompt with the uncertainty option is denoted as ``UNC''.
% We refer to real-time detection using the binary classification prompt as ``RT'', and real-time detection using the enhanced prompt with the uncertainty option as ``UNC''. 

\subsubsection{Binary Classification Prompt (RT)}
Initially, the detector employs a straightforward binary classification approach to categorize the ongoing conversation as either ``FRAUD'' or ``SAFE''. The prompt used for this classification is as follows:

\begin{displayquote}
\texttt{Please analyze the call content and detect whether it is a fraud call. Please carefully analyze the suspicious features in the conversation. If it is a fraud call, please only return "FRAUD". If it is a normal call, please only return "SAFE". Do not return anything else.}
\end{displayquote}

\subsubsection{Prompt with Uncertain Option (UNC)}
\label{sec:prompt_with_uncertain_option}
While the binary classification framework is simple and intuitive, our experiments (discussed in later sections) reveal that it can lead to reduced performance. 
Specifically, the model may prematurely make decisions based on limited information, resulting in lower accuracy. 
To address this limitation, we introduce a third category, ``UNCERTAIN'', which allows the model to defer its decision when there is insufficient evidence to classify the call confidently. The updated prompt is as follows:

\begin{displayquote}
\texttt{Please analyze the call content and detect whether it is a fraud call. Please carefully analyze the suspicious features in the conversation. If it is a fraud call, please only return "FRAUD". If it is a normal call, please only return "SAFE". If there is insufficient information (e.g., it is not yet obvious that the fraud is present), please return "UNCERTAIN". Do not return anything else.}
\end{displayquote}

\section{DATASETS, LLM MODELS, and METRICS}

\subsection{Datasets}
To evaluate the effectiveness of our real-time detection approach, we employed open-source datasets that encompass both authentic and synthetic data sources~\cite{shen2024combatingphonescamsllmbased}. 
These datasets were carefully curated to include examples of both positive samples (scam phone calls) and negative samples (benign phone calls).
It is important to note that the datasets used in this study are in Chinese. For clarity and inclusivity, all transcript examples presented in the following sections have been translated into English. Additionally, any sensitive information within the transcripts has been anonymized to safeguard privacy.

\subsubsection{Authentic Dataset (Real)}
The authentic dataset comprises real-world transcripts of both scam and normal phone calls. 
These recordings were sourced from publicly available video platforms, such as YouTube. The audio data was processed using speech-to-text technology to generate the corresponding transcripts. 
This dataset reflects realistic conversational patterns, including diverse linguistic styles, emotional cues, and spontaneity, making it an essential component for evaluating real-world performance.

\subsubsection{Synthetic Dataset (Syn.)}
To complement the authentic dataset, a synthetic dataset was constructed. 
This dataset includes both scam and normal conversations generated to mimic real-world scenarios while intentionally embedding suspicious keywords or conversational elements. The synthetic dataset provides controlled examples enabling an assessment of the model’s ability to generalize across diverse and artificially constructed cases.

\subsection{LLM Models}
For our evaluation, we selected a diverse set of LLMs to implement the detector: GPT-4~\cite{achiam2023gpt4}, GPT-4o~\cite{hurst2024gpt4o}, GLM4~\cite{glm2024chatglm}, Doubao-Pro-32k~\cite{doubao-pro-32k}, and ERNIE-3.5-8k~\cite{ernie-3.5-8k}.
We selected these models to capture a broad spectrum of strengths, particularly in natural language understanding.
The diversity of these models allows us to evaluate the generalize ability of our detection method across different architectures, and benchmark state-of-the-art models to identify the most suitable candidates for real-world deployment.

\subsection{Metrics}
To comprehensively evaluate the performance of our detection system, we used the following metrics: accuracy, precision, recall, and F1-score.
Accuracy (Acc.) measures the proportion of correctly classified samples (both positive and negative) out of the total number of samples: $\text{Acc.} = \frac{\text{True Positives} + \text{True Negatives}}{\text{Total Samples}}$. Accuracy provides an overall measure of performance, the higher, the better.
Precision quantifies the proportion of correctly predicted positive samples (scam calls) out of all samples classified as positive. It is defined as: $\text{Prec.} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$.
High precision indicates the model’s ability to avoid false alarms, ensuring that flagged calls are genuinely scams.
Recall measures the proportion of actual positive samples (scam calls) that are correctly identified by the model. It is defined as: $\text{Rec.} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$.
High recall ensures that most scam calls are detected, minimizing the risk of missed threats.
The F1-score (F1) is the harmonic mean of precision and recall, providing a balanced measure of the model’s ability to detect scams while minimizing false positives and false negatives.


% \begin{table}[t]
% \centering
% \begin{tabular}{p{14.5cm}}
% \toprule
% \textbf{Prompt:} Please analyze the call content and detect whether it is a fraud call. Please carefully analyze the suspicious features in the conversation. If it is a fraud call, please only return "FRAUD". If it is a normal call, please only return "SAFE". Do not return anything else.\\
% \hline
% \end{tabular}
% \vspace{1mm}
% \begin{tabular}{l@{\hspace{0.4em}}lp{5.5cm}p{2.5cm}p{2.5cm}}
% \textbf{Utterance ID} & \textbf{Speaker} & \textbf{Current Input} & \textbf{Model Response} & \textbf{Decision Point} \\
% \hline
% Utterance 1 & Caller A & Hello, is this Mr. Liu? & SAFE & - \\
% \hline
% Utterance 2 & Caller B & Yes, I am. May I ask who you are? & SAFE & - \\
% \hline
% Utterance 3 & Caller A & Hello Mr. Liu, I am Manager Zhang from Spring and Autumn Travel Agency. I heard that you are consulting about passport application recently, right? & SAFE & - \\
% \hline
% Utterance 4 & Caller B & Yes, I will travel abroad next month and am considering applying for a passport. & SAFE & - \\
% \hline
% Utterance 5 & Caller A & Great, you have found the right person. Our travel agency now has a special service that can help you quickly apply for a passport, which is much faster than the normal channel. & FRAUD & Utterance 5 \\
% \bottomrule
% \end{tabular}
% \caption{An example detection workflow of GPT-4o demonstrating turn-by-turn fraud analysis on a dialogue from the "Our-Synt" dataset.}
% \label{tab:sequential_analysis}
% \end{table}

% \begin{table}[t]
% \centering
% \begin{tabular}{p{14.5cm}}
% \toprule
% \textbf{Prompt:} Please analyze the call content and detect whether it is a fraud call. Please carefully analyze the suspicious features in the conversation. If it is a fraud call, please only return "FRAUD". If it is a normal call, please only return "SAFE". Do not return anything else.\\
% \toprule
% \end{tabular}
% \vspace{1mm}
% \begin{tabular}{c@{\hspace{0.4em}}cp{5.5cm}cc}
% \textbf{Utterance ID} & \textbf{Speaker} & \textbf{Current Input} & \textbf{Model Response} & \textbf{Decision Point} \\
% \midrule
% Utterance 1 & Speaker A & A: Hello, is this Ms. Chen? & SAFE & - \\
% \midrule
% Utterance 2 & Speaker B & A: Hello, is this Ms. Chen?\newline B: Yes, I am. May I ask who you are? & SAFE & - \\
% \midrule
% Utterance 3 & Speaker A & A: Hello, is this Ms. Chen?\newline B: Yes, I am. May I ask who you are?\newline A: Hello, Ms. Chen, I am Li Ming, a staff member of the State Administration of Exit and Entry. We are currently conducting a nationwide passport security verification project and need your cooperation. & FRAUD & Utterance 3 \\
% \bottomrule
% \end{tabular}
% \caption{An example detection workflow of GPT-4o demonstrating turn-by-turn fraud analysis on a dialogue from the "Our-Synt" dataset.}
% \label{tab:sequential_analysis}
% \end{table}

% \begin{table}[t]
% \centering
% \begin{tabular}{p{14.5cm}}
% \toprule
% \textbf{Prompt:} Please analyze the call content and detect whether it is a fraud call. Please carefully analyze the suspicious features in the conversation. If it is a fraud call, please only return "FRAUD". If it is a normal call, please only return "SAFE". Do not return anything else.\\
% \toprule
% \end{tabular}
% \vspace{1mm}
% \begin{tabular}{l@{\hspace{0.4em}}cm{5.5cm}ll}
% \textbf{Utterance ID} & \textbf{Speaker} & \textbf{Current Input} & \textbf{Model Response} & \textbf{Trigger Point} \\
% \midrule
% Utterance 1 & Speaker A & A: Hello, is this Ms. Chen? & SAFE & - \\
% \midrule
% Utterance 2 & Speaker B & A: Hello, is this Ms. Chen?\newline B: Yes, I am. May I ask who you are? & SAFE & - \\
% \midrule
% Utterance 3 & Speaker A & A: Hello, is this Ms. Chen?\newline B: Yes, I am. May I ask who you are?\newline A: Hello, Ms. Chen, I am Li Ming, a staff member of the State Administration of Exit and Entry. We are currently conducting a nationwide passport security verification project and need your cooperation. & FRAUD & Utterance 3 \\
% \bottomrule
% \end{tabular}
% \caption{An example detection workflow of GPT-4o demonstrating our real-time detection method on a dialogue from the "Our-Synt" dataset.}
% \label{tab:sequential_analysis}
% \end{table}

% To simulate real-time phone call scenarios, we developed a sequential detection framework that processes conversations dynamically as each 'turn'. Here, turn means a back-and-forth utterance. Unlike the approach feeding the entire dialogue to the llms showed in Shen's research(cite), we fed each turn's utterance to the llms, which contains all the conversation before this turn. Initial implementation utilized a binary classification approach, where the model was prompted to classify each turn as either "FRAUD" or "SAFE". However, preliminary testing revealed that although for the same model and the same dataset the recall has a significant increasement compared to Shen's approach, the precision drops quite markedly. By checking the utterance making the model judge as scam as well as the following conversation, we found that in many situations there are only a few suspicious phrases in the very early turns and if consider the following conversation it's just a normal dialogue. However, LLMs consider it as the entire conversation and is asked to detect whether it involves, so LLMs would judged it as scam leading to more false positives and low precision. To avoid this lack of information, we added one more option ----- uncertain to the prompt, allowing the LLMs to see more information and have a more accurate judgment. 

% To simulate real-time phone call scenarios, we developed a sequential detection framework that processes conversations dynamically utterance by utterance. As shown in Table~\ref{tab:sequential_analysis}, our framework analyzes each new utterance while integrating the context of all previous exchanges to feed LLMs. With the model maintaining "SAFE" judgments through the initial exchanges, the system continuously processes subsequent utterances. The critical trigger point occurs at Utterance 5, where the model triggers a "FRAUD" classification. This sequential processing mechanism ensures that the system continues analysis as long as conversations remain "SAFE", but promptly terminates upon detecting fraudulent patterns. 

% Initial implementation utilized a binary classification approach, where the model was prompted to classify each turn as either "FRAUD" or "SAFE". However, preliminary testing revealed that although for the same model and the same dataset the recall has a significant increasement compared to Shen's approach, the precision drops quite markedly. By checking the utterance making the model judge as scam as well as the following conversation, we found that in many situations there are only a few suspicious phrases in the very early turns and if consider the following conversation it's just a normal dialogue. However, LLMs consider it as the entire conversation and is asked to detect whether it involves, so LLMs would judged it as scam leading to more false positives and low precision. To avoid this lack of information, we added one more option ----- uncertain to the prompt (ph{If there is insufficient information (e.g., it is not yet obvious that the fraud is present), please return "UNCERTAIN".}), allowing the LLMs to see more information and have a more accurate judgment. This modification allows the model to defer judgment when facing ambiguous situations, essentially requesting more conversational context before making a definitive fraud determination. 


\section{EXPERIMENTS \& ANALYSES}

In this section, we experimentally evaluate the performance of the proposed detection system and try to answer the research questions raised in Section~\ref{sec:introduction}.

\subsection{RQ1: How does our LLM-based real-time detection system perform in identifying phone scams?}

\begin{table}[t]
    \centering
    \setlength{\tabcolsep}{0.8pt}
    \footnotesize
    \begin{tabular}{ll|ccc|ccc|ccc|ccc|ccc}
        \toprule
        & & \multicolumn{3}{c|}{\textbf{GPT4}} & \multicolumn{3}{c|}{\textbf{GPT4o}} & \multicolumn{3}{c|}{\textbf{GLM4}} & \multicolumn{3}{c|}{\textbf{Doubao}} & \multicolumn{3}{c}{\textbf{ERNIE}} \\
        & & RT & UNC & RET & RT & UNC & RET & RT & UNC & RET & RT & UNC & RET & RT & UNC & RET \\
        \midrule
        \multirow{2}{*}{\textbf{Acc.}} & Real & 0.99 & 0.97 & 0.94 & 1.00 & 0.99 & 0.98 & 0.98 & 0.98 & 0.96 & 0.99 & 0.95 & 0.86 & 0.97 & 0.96 & 0.93 \\
        & Syn. & 0.85 & 0.87 & 0.99 & 0.84 & 0.84 & 0.98 & 0.79 & 0.89 & 0.91 & 0.96 & 0.95 & 0.97 & 0.79 & 0.89 & 0.98 \\
        \midrule
        \multirow{2}{*}{\textbf{F1}} & Real & 0.99 & 0.97 & 0.94 & 1.00 & 0.99 & 0.98 & 0.98 & 0.98 & 0.96 & 0.99 & 0.95 & 0.84 & 0.96 & 0.96 & 0.93 \\
        & Syn. & 0.87 & 0.88 & 0.99 & 0.86 & 0.86 & 0.98 & 0.83 & 0.90 & 0.91 & 0.97 & 0.95 & 0.97 & 0.83 & 0.90 & 0.98 \\
        \midrule
        \multirow{2}{*}{\textbf{Prec.}} & Real & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 0.96 & 1.00 & 0.98 & 1.00 & 1.00 & 1.00 & 0.94 & 1.00 & 1.00 \\
        & Syn. & 0.77 & 0.80 & 1.00 & 0.76 & 0.77 & 0.98 & 0.70 & 0.83 & 0.95 & 0.94 & 1.00 & 1.00 & 0.70 & 0.85 & 1.00 \\
        \midrule
        \multirow{2}{*}{\textbf{Rec.}} & Real & 0.98 & 0.94 & 0.89 & 1.00 & 0.98 & 0.96 & 1.00 & 0.96 & 0.93 & 0.98 & 0.90 & 0.72 & 1.00 & 0.92 & 0.87 \\
        & Syn. & 1.00 & 0.98 & 0.98 & 1.00 & 0.98 & 0.98 & 1.00 & 0.98 & 0.86 & 0.98 & 0.90 & 0.94 & 1.00 & 0.94 & 0.97 \\
        \bottomrule
    \end{tabular}
    \caption{Performance comparison of different LLMs on real and synthetic datasets using three detection methods - RT: Real-Time Detection, UNC: Real-time Detection with Uncertain Option, RET: Retrospective Detection}
    \vspace{-20pt}
    \label{tab:detection_results}
\end{table}

We evaluate our proposed detection method using five LLMs previously mentioned on both authentic and synthetic datasets. 
For real-time detection, we initially utilize a binary classification prompt (i.e., RT). 
As a baseline for comparison, we include the results from previous work~\cite{shen2024combatingphonescamsllmbased}, where detection was performed using retrospective analysis, denoted as ``RET''. 
The evaluation results are presented in Table~\ref{tab:detection_results}.

In terms of recall, all five models exhibit exceptionally high performance, achieving recall rates ranging from 0.98 to 1.00 on both real and synthetic datasets. 
Notably, GPT4o, GLM4, and ERNIE achieve perfect recall scores of 1.00, demonstrating the system's high effectiveness in identifying the majority of potential scam calls in real-time scenarios, highlighting the detection method in capturing fraudulent activity without missing critical cases.

However, when considering precision, a significant disparity emerges between real-time detection and retrospective analysis. 
While retrospective analysis achieves precision rates ranging from 0.95 to 1.00, real-time detection exhibits noticeably lower precision values (0.70–0.77) across most models on the synthetic dataset. 
This gap suggests that, although real-time detection excels in identifying scam calls (high recall), it struggles with false positives, leading to reduced precision.

These findings motivate us to further explore RQ2 to identify and analyze the factors influencing the precision performance of our system during real-time detection. 
Addressing these factors is critical to enhance the overall reliability and practicality of real-time detection in real-world applications.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figure5.png}
    \caption{Analysis of false positive scenarios in fraud detection systems}
    \label{fig:false_alerts}
    \vspace{-5pt}
\end{figure}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figure6.png}
    \caption{Visualization of fraud detection scenarios in an ongoing normal phone call and a scam phone call. Suspicious patterns are highlighted.}
    \label{fig:fraud_detection}
    \vspace{-5pt}
\end{figure*}

\subsection{RQ2: What factors influence the system’s detection performance?}

In real-time detection, the model processes each utterance incrementally during a phone conversation, 
with access only to the current utterance and a limited preceding context, as defined by the prompt design.
In contrast, retrospective analysis allows the model to examine the entire conversation history before making a judgment. 
This comprehensive view provides the model with complete contextual information, enabling it to interpret each utterance in light of the full dialogue, further improving its precision by reducing false positives.
Therefore, the difference in context availability between real-time detection and retrospective analysis may be one of the reasons that affect the rate of false positives.

By investigating the results, we identified a recurring issue: the detection method classifies the conversion as fraud if it contains certain suspicious keywords, e.g., payment, ID, classified as fraud-related terms in previous work~\cite{shen2024combatingphonescamsllmbased}.
Through our analysis of the system's false positive cases, as illustrated in Figure~\ref{fig:false_alerts}, we identified three main categories of legitimate scenarios that frequently trigger fraud alerts. In our observation, these interactions were frequently flagged as potential fraud due to their similarity with common scam patterns -- they all involve identity verification, financial information sharing, or urgent decision-making. Such false alert not only annoy users, but also could lead to users disabling or ignoring the protection system because they intend to mitigate undesired interruptions by suppressing alerts~\cite{li2023alert}. 

For instance, Figure~\ref{fig:fraud_detection} illustrates a normal customer service interaction where an agent assists a customer with re-booking a flight. 
The real-time detection method incorrectly flags the conversation as fraudulent at utterance 15, triggered by the agent’s use of the word ``payment'' while discussing the modification fee. 
Without access to the subsequent dialogue that clarifies the context, the model interprets the term as suggestive of fraud.

This phenomenon is particularly evident when comparing detection performance between the two datasets. 
While the models achieve high precision on the authentic dataset, where conversations naturally include contextual nuances, their precision drops significantly on the synthetic dataset, where normal dialogues are deliberately generated around suspicious keywords. This performance gap highlights the importance of contextual completeness in reducing false positives.

\subsection{Effectiveness of Involving Uncertain Option}

The observations discussed above motivate the introduction of a mechanism that allows the detector to delay making a definitive decision when uncertainty arises. 
This approach enables the system to gather additional conversational context before classifying. 
As introduced in Section~\ref{sec:prompt_with_uncertain_option}, the improved prompts with the uncertain option (denoted as ``UNC'') were specifically designed to address this challenge. 
The results of incorporating this option in real-time detection are summarized in Table~\ref{tab:detection_results}.

\subsubsection{Improved Precision}
The experimental results demonstrate that the use of the ``UNC'' leads to a significant improvement in precision, particularly on the synthetic dataset. For instance, the precision of Doubao increased from 0.70 to 0.83, and ERNIE rose from 0.70 to 0.85.
These improvements highlight the effectiveness of the ``UNC'' in reducing false positives, which may be commonly caused by incomplete information or an over-sensitivity to suspicious keywords as discussed above.

Figure~\ref{fig:fraud_detection} provides a concrete example of how ``UNC'' improves detection performance. 
For an ongoing phone call, after incorporating the uncertain response mechanism, the system correctly classified the conversation as ``SAFE'' at Utterance 28, the end of the conversation. 
Without ``UNC'', the same conversation might have been misclassified earlier due to incomplete context or isolated suspicious terms.

\subsubsection{Trade-offs in Recall and Timeliness}
The incorporation of ``UNC'' improves precision but comes at the cost of reduced recall. 
As shown in Table~\ref{tab:detection_results}, recall across all models drops from values between 0.98 and 1.00 to a range of 0.90 to 0.98 for both real and synthetic datasets. 
This trade-off indicates that while models become more cautious in making definitive fraud judgments, they may miss genuine fraudulent cases by labeling them as uncertain.

Also, there is a trade-off between detection reliability and timeliness. 
For example, in the scam phone call shown in Figure~\ref{fig:fraud_detection}, the fraudster impersonates a police officer investigating credit card fraud. 
The real-time system flags the call as fraudulent at Utterance 6 upon detecting phrases like ``personal information'' and ``credit card fraud''. 
However, ``UNC'' delays the fraud judgment until Utterance 10, when the impersonator explicitly requests ID card information. While this approach reduces false positives, it risks delaying critical alerts.

This delay introduces challenges in maintaining user trust. 
Early interventions may feel like the system is ``jumping to conclusions,'' whereas delayed warnings can be perceived as ``too late to be useful.'' 
Research has shown that user trust is strongly influenced by system accuracy and the timing of alerts ~\cite{dzindolet2003role,oduor2008effects,yu2017user, papenmeier2022complicated}. 
In our context, uncertainty in intervention timing may further burden users, forcing them to balance waiting for system confirmation with making timely decisions in their conversations.

%Similarly, when encountering suspicious words, models can choose to gather more evidence rather than making false positive classifications. 

%The introduction of the uncertain option demonstrates varying effects across different models and datasets. Our analysis demonstrates both positive impacts and potential trade-offs in addressing the problem caused by the two main factors discussed above.

%\subsubsection{Improved Precision on Synthetic Dataset}

%Most notably, Table~\ref{tab:detection_results} suggests that the uncertain option significantly improved precision on the synthetic dataset. For example, \emph{Doubao-Pro-32k}'s precision increased from 0.70 to 0.83, and \emph{ERNIE-3.5-8k}'s precision rose from 0.70 to 0.85. These improvements indicate that the uncertain option effectively reduces false positives caused by both insufficient information and sensitivity to suspicious keywords. Specifically, as displayed in Figure~\ref{}, after adding the uncertain option, for the ongoing phone call, the system provided 'SAFE' as the detection result correctly at Utterance 28. 

%Figure~\ref{fig:cumulative_detection_results_for_AI_normal} takes \emph{ERNIE-3.5-8k} as an example to show the cumulative true negatives and false positives for real-time and real-time with uncertain option. The results indicate that the system with uncertainty handling obtains higher true negatives and lower false positives than the real-time system. This improvement in precision suggests that instead of immediately flagging a conversation as fraudulent based on isolated suspicious terms or incomplete context, models can now take a more measured approach, leading to more accurate classifications.

% Most notably, table~\ref{tab:detection_results} suggests that the uncertain option significantly improved precision on the synthetic dataset. For example, \emph{Doubao-Pro-32k}'s precision increased from 0.70 to 0.83, and \emph{ERNIE-3.5-8k}'s precision rose from 0.70 to 0.85. These improvements indicate that the uncertain option effectively reduces false positives caused by both insufficient information and sensitivity to suspicious keywords. Specifically, as displayed in table~\ref{tab:uncertain}, after adding the uncertain option, for the same dialogue, the same model provided 'SAFE' as the detection result correctly. Figure~\ref{fig:cumulative_detection_results_for_AI_normal} takes \emph{ERNIE-3.5-8k} as an example to show the cumulative true negatives and false positives for real-time detection systems with and without uncertainty handling. The results indicate that the model with uncertainty handling obtains higher true negatives and lower false positives than the system without uncertainty handling, highlighting the critical role of uncertainty modeling in enhancing robustness and precision.

% This improvement in precision suggests that the uncertain option helps models better handle conversations containing potentially suspicious keywords by allowing them to withhold judgment until sufficient context is available. Rather than immediately flagging a conversation as fraudulent based on isolated suspicious terms or incomplete context, models can now take a more measured approach, leading to more accurate classifications.

% To address the precision decline in sequential analysis, we introduced an 'uncertain' option allowing models to defer judgment when encountering ambiguous conversation turns. While this addition successfully improved precision, our analysis reveals two significant challenges that warrant careful consideration.

%\subsubsection{Two Critical Trade-offs in Uncertain Detection Option}

%\begin{figure}[t]
%    \centering
%    \includegraphics[width=0.5\linewidth]{figure3.png} 
%    \caption{ERNIE's cumulative detection results for genuine conversations in the synthetic dataset.}
%\label{fig:cumulative_detection_results_for_AI_normal}
%\end{figure}

%\begin{figure}[t]
%    \centering
%    \includegraphics[width=0.5\linewidth]{figure4.png} 
%    \caption{Doubao's cumulative detection results for scam conversations in the real dataset.}
%\label{fig:cumulative_detection_results_for_real_sacam}
%\end{figure}

%\paragraph{Trade-off 1: recall and precision}

%As shown in Table~\ref{tab:detection_results}, after adding uncertain option which can improve precision though, there is a noticeable decline of recall across all models for both real and synthetic datasets which drops from values ranging between 0.98 and 1.00 to values ranging between 0.90 and 0.98. This trade-off pattern suggests that while models become more cautious in making definitive fraud judgments, they might miss some genuine fraudulent cases by marking them as uncertain.

%\paragraph{Trade-off 2: trust and delay}

%The introduction of the uncertain option presents a critical trade-off between detection reliability and timeliness. This trade-off is exemplified in the ongoing scam phone call shown in Figure~\ref{fig:dialogue_example}, where the fraudster impersonates a police officer investigating credit card fraud. While the real-time detection flags this as fraudulent at Utterance 6 upon mentioning "personal information" and credit card fraud, the uncertain option delays the definitive fraud judgment until utterance 10, when the impersonator requests ID card information. 

%This delay pattern reveals a fundamental challenge in balancing system effectiveness with user trust. Early interventions were often perceived as \textit{"jumping to conclusions"}, while delayed warnings felt \textit{"too late to be useful"}.

%The impact on user trust is particularly significant, as studies have shown that users dynamically adjust their trust levels based on their experience with system accuracy ~\cite{dzindolet2003role,oduor2008effects,yu2017user}. In our context, this experienced accuracy is affected by both the precision of fraud detection and the timing of alerts ~\cite{papenmeier2022complicated}. Moreover, the uncertainty in intervention timing creates additional cognitive burden for users, who must constantly balance waiting for system confirmation against making timely decisions in their conversations.


% The second challenge lies in delayed decision-making, which is visually evident in the comparison between \emph{Doubao-Pro-32k}'s detection curves with and without uncertainty - the curve with uncertainty consistently lags behind the curve without uncertainty possessing a steeper slope, achieving more rapid detection rate throughout the detection process shown in Figure~\ref{fig:cumulative_detection_results}. This delay, while beneficial for accuracy, could potentially compromise the system's ability to provide early warnings in time-sensitive fraud scenarios, where immediate intervention might be necessary to prevent financial losses or other harmful consequences.
% When models opt for the 'uncertain' state, they effectively postpone the final judgment until more context becomes available. 

% These findings highlight an essential trade-off in fraud detection systems: the balance between accuracy and timeliness. While the uncertain option enhances precision, it comes at the cost of reduced recall and delayed detection. This trade-off becomes particularly crucial in real-world applications where both early intervention and accuracy are essential.

% \begin{table}[t]
% \centering
% \begin{tabular}{llp{4cm}lll}
% \toprule
% \textbf{Method} & \textbf{Model} & \textbf{Trigger Statement} & \textbf{Result} & \textbf{Trigger Point} & \textbf{Precision} \\
% \midrule
% \multicolumn{6}{l}{\emph{Dialogue 1}} \\
% \midrule
% \multirow{2}{*}{Without Uncertain Option} & GPT4o & The scammer said that the mobile phone my cousin bought on JD.com was a fake and he wanted me to cooperate with the investigation. & FRAUD & Uttrance 3 & Inexact \\
% & GPT4 & The scammer said that my cousin needed to transfer the money to a so-called "JD official account" for verification, which would be returned immediately after verification. & FRAUD & Uttrance 5 & Inexact \\
% \midrule
% \multirow{2}{*}{With Uncertain Option} & GPT4o & - & SAFE & - & Exact \\
% & GPT4 & - & SAFE & - & Exact \\
% \midrule
% \multicolumn{6}{l}{\emph{Dialogue 2}} \\
% \midrule
% \multirow{2}{*}{Without Uncertain Option} & GPT4o & [...] & [...] & [...] & [...] \\
% & BERT & [...] & [...] & [...] & [...] \\
% \midrule
% \multirow{2}{*}{With Uncertain Option} & GPT4o & [...] & [...] & [...] & [...] \\
% & BERT & [...] & [...] & [...] & [...] \\
% \bottomrule
% \end{tabular}
% \caption{Detection results for different dialogues using GPT-4o and BERT.}
% \label{tab:detection_results}
% \end{table}

% \begin{table}[t]
% \centering
% \begin{tabular}{m{3cm}m{1.2cm}m{4.5cm}m{1.2cm}m{1.8cm}m{1.2cm}}
% \toprule
% \textbf{Method} & \textbf{Model} & \textbf{Trigger Statement} & \textbf{Result} & \textbf{Trigger Point} & \textbf{Precision} \\
% \midrule
% \multicolumn{6}{l}{\emph{Dialogue 1}} \\
% \midrule
% \multirow{2}{*}{\centering\vspace*{2.5em}Without Uncertain Option} & GPT4o & The scammer said that the mobile phone my cousin bought on JD.com was a fake and he wanted me to cooperate with the investigation. & FRAUD & Uttrance 3 & Inexact \\
% & GPT4 & The scammer said that my cousin needed to transfer the money to a so-called "JD official account" for verification, which would be returned immediately after verification. & FRAUD & Uttrance 5 & Inexact \\
% \midrule
% \multirow{2}{*}{\centering\vspace*{0.7em}With Uncertain Option} & GPT4o & - & SAFE & - & Exact \\
% & GPT4 & - & SAFE & - & Exact \\
% \midrule
% \multicolumn{6}{l}{\emph{Dialogue 2}} \\
% \midrule
% \multirow{2}{*}{\centering\vspace*{0.7em}Without Uncertain Option} & GPT4o & [...] & [...] & [...] & [...] \\
% & GPT4 & [...] & [...] & [...] & [...] \\
% \midrule
% \multirow{2}{*}{\centering\vspace*{0.7em}With Uncertain Option} & GPT4o & [...] & [...] & [...] & [...] \\
% & GPT4 & [...] & [...] & [...] & [...] \\
% \bottomrule
% \end{tabular}
% \caption{Detection results for different dialogues using GPT-4o and BERT.}
% \label{tab:detection_results}
% \end{table}

%\section{DISCUSSION}

%\subsection{RQ3: What are the potential future considerations and directions to improve user experience}

%\subsubsection{Alert fatigue and disturbance from false positives}

%\begin{figure}[t]
%    \centering
%    \includegraphics[width=0.6\linewidth]{figure5.png}
%    \caption{Analysis of false positive scenarios in fraud detection systems}
%    \label{fig:false_alerts}
%\end{figure}

%According to our analyze above, though our system successfully identifies most scam conversations, the users may receive many false alarms especially without uncertain option.

%In fraud detection, a false negative (missing actual fraud) error is usually more costly than a false positive error~\cite{phua2005comprehensive}. Nevertheless, it doesn't mean we can ignore the low precision which may bring a lot of disturbance to the users. Previous research has shown that frequent false alarms occurring in various security contexts~\cite{chhetri2024towards} can lead to "alert fatigue", also known as "cry-wolf syndrome" or "pop-up fatigue", where users become desensitized to warnings and may eventually ignore them altogether`\cite{cash2009alert}. 

%Through our analysis of the system's false positive cases, as illustrated in Figure~\ref{fig:false_alerts}, we identified three main categories of legitimate scenarios that frequently trigger fraud alerts. In our observation, these interactions were frequently flagged as potential fraud due to their similarity with common scam patterns -- they all involve identity verification, financial information sharing, or urgent decision-making. Such false alert not only annoy users, but also could lead to users disabling or ignoring the protection system because they intend to mitigate undesired interruptions by suppressing alerts~\cite{li2023alert}. 

%In summary, striking a balance between detecting genuine fraudulent activities and minimizing false positives is crucial to avoid inconveniencing egitimate customers and causing friction in the user experience~\cite{dama2024fraud}.

%\subsubsection{Inadequate protection against sophisticated scams}

%Despite achieving relatively high recall rates, our system still produces false negatives that allow some scam conversations to proceed undetected, resulting in victims being scammed. These victims may experience both financial losses and psychological distress, ultimately loss confidence in the system's protective capabilities.

%Even in cases where users did not experience direct financial losses, undetected scams often resulted in the disclosure of personal information. This information collection by scammers made users more vulnerable to subsequent fraud attempts, as fraudsters could leverage previously obtained details to create more convincing deception scenarios.

% Through our analysis of the system's false positive cases, we identified several conversation scenarios sharing similarities with fraudulent patterns that frequently triggered fraud alerts in legitimate interactions:

% \begin{description}

% \item[FINANCIAL SERVICES:]

% \begin{itemize}
%     \item Participant 1 received a call from a bank to verify identity after reporting a lost debit card: \textit{``The system kept warning me it was suspicious, but I really needed to unfreeze my account.''}
%     \item Participant 2 was consulting with a long-term financial advisor about investment planning: \textit{``It flagged our entire review discussion as potentially fraudulent.''}
% \end{itemize}

% \item[PUBLIC SERVICES:]

% \begin{itemize}
%     \item Participant 3 attempted to file a bicycle theft report: \textit{``When I called the local police station, the system warned me it was a scam call. I almost hung up out of caution.''}
%     \item Participant 4 was updating their healthcare provider about a change in insurance: \textit{``Every time they asked to confirm my policy number or birth date, the system flashed warnings.''}
% \end{itemize}

% \item[TRAVEL \& HOSPITALITY:]
% \begin{itemize}
%     \item Participant 5's trip booking triggered multiple alerts: \textit{``The hotel's manager called to verify my card details, and the system marked it as high-risk.''}
%     \item Participant 6 faced warnings while booking a last-minute flight: \textit{``The airline needed to verify my passport details quickly, but the system's repeated alerts made me hesitate and almost miss my booking window.''}
% \end{itemize}

% \end{description}

% \subsubsection{TIMING VS. TRUST}

% The timing of fraud alerts presents a critical challenge in balancing system effectiveness with user trust. As mentioned in the experimental results section, there was always a delay after adding uncertain option especially when facing scam dialogues. Early interventions were often perceived as \textit{"jumping to conclusions"}, while delayed warnings felt \textit{"too late to be useful"}.

% Data from several studies on model accuracy and user trust show that users adapt their trust level and perception of reliability to the experienced accuracy of a system~\cite{dzindolet2003role}~\cite{oduor2008effects}~\cite{yu2017user}. The experienced accuracy affected by both precision and timing in our system is, therefore, an important factor for user trust in AI~\cite{papenmeier2022complicated}. 

% Furthermore, the uncertainty in intervention timing may create additional cognitive load for users, who may feel constantly torn between waiting for system confirmation and make timely decisions in their conversations.

% \subsection{Implications for Future Design}

\section{CONCLUSION AND FUTURE WORK}

This paper explored the application of Large Language Models (LLMs) for real-time phone scam detection, demonstrating their potential while uncovering key challenges through extensive experiments and analyses. 
Our system consistently achieved good performance across multiple LLMs, effectively identifying potential scams effectively and protecting users.
Meanwhile, our findings also underscore the inherent complexity of real-time fraud detection and outline several key directions for future work: addressing security and privacy concerns, as users may worry about fraud detection systems monitoring or storing personal data, and developing effective user notification strategies, which, though not covered in this paper, hold significant potential for improving user experience and trust.

% \begin{itemize}
%     \item Balancing early warnings with detection accuracy to ensure timely and reliable interventions.
%     \item Enhancing context understanding to reduce false positives while maintaining high recall.
%     \item Addressing security and privacy concerns, as users may worry that scam detection systems are monitoring or storing their personal information.
%     \item Developing effective user notification strategies, which, although not covered in this work, hold significant potential for improving user experience and trust in future systems.
% \end{itemize}
While LLM-based real-time detection shows great promise, significant challenges remain in creating systems that effectively safeguard users without disrupting legitimate communications or eroding trust. 
Future research must address these challenges and will address a user study to explore the impact of the system on user experience, further refining user engagement strategies to maximize the real-world potential of LLMs.

%This paper preliminarily explored the usage of Large Language Models for real-time phone scam detection and demonstrated the potential and discovered challenges through experiments and analyses. 
%Our real-time detection system achieves excellent recall rates across multiple LLMs, which suggests tremendous potential for protecting the users from phone scams. 
%However, we have noted two factors reducing the precision of the system which are Information completeness and fraud-related words. To eliminate this negative impact, we introduced an uncertainty handling mechanism. While this improved precision on synthetic datasets, it increase false alarms as well as introduced delays in detection which may disturb and annoy users and cause trust erosion.

%These findings highlight the complex nature of real-time fraud detection and provide clear evidence suggest that future work should focus on:
%\begin{itemize}
%    \item Optimizing the balance between early warning and detection accuracy
%    \item Improving context understanding to reduce false positives while maintaining high recall
%    \item Developing more sophisticated uncertainty handling mechanisms that minimize detection delays
%\end{itemize}

%Ultimately, our work reveals that while LLM-based real-time scam detection is promising, significant challenges remain in creating a system that can protect users effectively while preserving their trust and minimizing disruption to normal communications.

\bibliographystyle{ACM-Reference-Format}
\bibliography{CHI}
\end{document}

