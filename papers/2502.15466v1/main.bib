@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
























% SNIP深度符号回归
@inproceedings{
SNIP,
title={{SNIP}: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training},
author={Kazem Meidani and Parshin Shojaee and Chandan Reddy and Amir Barati Farimani},
booktitle={NeurIPS 2023 AI for Science Workshop},
year={2023},
url={https://openreview.net/forum?id=Nn43zREWvX}
}

% 深度符号回归
@inproceedings{
Symbolic,
title={End-to-end Symbolic Regression with Transformers},
author={Pierre-Alexandre Kamienny and St{\'e}phane d'Ascoli and Guillaume Lample and Francois Charton},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=GoOuIrDHG_Y}
}

% 多模态ALBEF
@inproceedings{
ALBEF,
title={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation},
author={Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq Joty and Caiming Xiong and Steven Hoi},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=OJLaKwiXSbx}
}

% PatchTST
@inproceedings{
PatchTST,
title={A Time Series is Worth 64 Words:  Long-term Forecasting with Transformers},
author={Yuqi Nie and Nam H Nguyen and Phanwadee Sinthong and Jayant Kalagnanam},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=Jbdc0vTOcol}
}

% Timer生成式预训练大模型
@inproceedings{
Timer,
title={Timer: Generative Pre-trained Transformers Are Large Time Series Models},
author={Yong Liu and Haoran Zhang and Chenyu Li and Xiangdong Huang and Jianmin Wang and Mingsheng Long},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=bYRYb7DMNo}
}

% 对比学习预训练
@inproceedings{
COMET,
title={Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series},
author={Yihe Wang and Yu Han and Haishuai Wang and Xiang Zhang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=sOQBHlCmzp}
}

% 掩码式预训练MOIRAI
@inproceedings{MOIRAI,
title={Unified Training of Universal Time Series Forecasting Transformers},
author={Gerald Woo and Chenghao Liu and Akshat Kumar and Caiming Xiong and Silvio Savarese and Doyen Sahoo},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=Yd8eHMY1wz}
}

% Time-LLM
@inproceedings{
Time-LLM,
title={Time-{LLM}: Time Series Forecasting by Reprogramming Large Language Models},
author={Ming Jin and Shiyu Wang and Lintao Ma and Zhixuan Chu and James Y. Zhang and Xiaoming Shi and Pin-Yu Chen and Yuxuan Liang and Yuan-Fang Li and Shirui Pan and Qingsong Wen},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Unb5CVPtae}
}

% S2IP-LLM
@inproceedings{S2IP-LLM,
  title={$\textbf{S}^2$IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting},
  author={Zijie Pan and Yushan Jiang and Sahil Garg and Anderson Schneider and Yuriy Nevmyvaka and Dongjin Song},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
    url={https://arxiv.org/abs/2403.05798},
}

% TimesNet
@inproceedings{TimesNet,
  title={TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis},
  author={Haixu Wu and Tengge Hu and Yong Liu and Hang Zhou and Jianmin Wang and Mingsheng Long},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=ju_Uqw384Oq}
}

% TimeSiam
@inproceedings{
TimeSiam,
title={TimeSiam: A Pre-Training Framework for Siamese Time-Series Modeling},
author={Jiaxiang Dong and Haixu Wu and Yuxuan Wang and Yun-Zhong Qiu and Li Zhang and Jianmin Wang and Mingsheng Long},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=wrTzLoqbCg}
}

% SimMTM
@inproceedings{
SimMTM,
title={Sim{MTM}: A Simple Pre-Training Framework for Masked Time-Series Modeling},
author={Jiaxiang Dong and Haixu Wu and Haoran Zhang and Li Zhang and Jianmin Wang and Mingsheng Long},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=ginTcBUnL8}
}

% GPT4TS
@inproceedings{
GPT4TS,
title={One Fits All: Power General Time Series Analysis by Pretrained {LM}},
author={Tian Zhou and Peisong Niu and Xue Wang and Liang Sun and Rong Jin},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=gMS6FVZvmF}
}

% CLIP
@inproceedings{CLIP,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

% Survey on Time Series Pretrain Model
@article{Survey4TSPM,
  title={A survey on time-series pre-trained models},
  author={Ma, Qianli and Liu, Zhen and Zheng, Zhenjing and Huang, Ziyang and Zhu, Siying and Yu, Zhongzhong and Kwok, James T},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}

% HiMTM
@inproceedings{HiMTM,
  title={HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling with Self-Distillation for Long-Term Forecasting},
  author={Zhao, Shubao and Jin, Ming and Hou, Zhaoxiang and Yang, Chengyi and Li, Zengxiang and Wen, Qingsong and Wang, Yi},
  booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
  pages={3352--3362},
  year={2024}
}

% Survey on self-superviesd learning
@article{Suvery4SSL,
  title={Self-supervised learning for time series analysis: Taxonomy, progress, and prospects},
  author={Zhang, Kexin and Wen, Qingsong and Zhang, Chaoli and Cai, Rongyao and Jin, Ming and Liu, Yong and Zhang, James Y and Liang, Yuxuan and Pang, Guansong and Song, Dongjin and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

% 数据隐私
@article{DataPrivacy,
  title={Data privacy and security in it: a review of techniques and challenges},
  author={Farayola, Oluwatoyin Ajoke and Olorunfemi, Oluwabukunmi Latifat and Shoetan, Philip Olaseni},
  journal={Computer Science \& IT Research Journal},
  volume={5},
  number={3},
  pages={606--615},
  year={2024}
}

% ViT
@inproceedings{
ViT,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

% GPT2
@article{GPT-2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

% 复杂动力学系统的表征
@article{TimeSeries4ComplexSystems,
  title={The why, how, and when of representations for complex systems},
  author={Torres, Leo and Blevins, Ann S and Bassett, Danielle and Eliassi-Rad, Tina},
  journal={SIAM Review},
  volume={63},
  number={3},
  pages={435--485},
  year={2021},
  publisher={SIAM}
}

% 复杂系统建模 微分方程
@incollection{DE4ModelingCS,
  title={Modeling complex systems: Stochastic processes, stochastic differential equations, and Fokker-Planck equations},
  author={Doering, Charles R},
  booktitle={1990 Lectures in Complex Systems},
  pages={3--52},
  year={2018},
  publisher={CRC Press}
}

% 符号回归的一篇论文
@ARTICLE{Exhaustive,
  author={Bartlett, Deaglan J. and Desmond, Harry and Ferreira, Pedro G.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Exhaustive Symbolic Regression}, 
  year={2024},
  volume={28},
  number={4},
  pages={950-964},
  keywords={Mathematical models;Complexity theory;Optimization;Numerical models;Biological system modeling;Standards;Search problems;Cosmology data analysis;minimum description length;model selection;symbolic regression (SR)},
  doi={10.1109/TEVC.2023.3280250}}

% 和符号生成有关的一篇论文
@inproceedings{SymbolicBrittleness,
  title={Symbolic brittleness in sequence models: on systematic generalization in symbolic mathematics},
  author={Welleck, Sean and West, Peter and Cao, Jize and Choi, Yejin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={8},
  pages={8629--8637},
  year={2022}
}

% ARIMA模型
@article{ARIMA,
  title={ARIMA models},
  author={Shumway, Robert H and Stoffer, David S and Shumway, Robert H and Stoffer, David S},
  journal={Time series analysis and its applications: with R examples},
  pages={75--163},
  year={2017},
  publisher={Springer}
}

% 遗传算法的符号回归
@article{GA4SR1,
  title={Improving model-based genetic programming for symbolic regression of small expressions},
  author={Virgolin, Marco and Alderliesten, Tanja and Witteveen, Cees and Bosman, Peter AN},
  journal={Evolutionary computation},
  volume={29},
  number={2},
  pages={211--237},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{GA4SR2,
    author = {de Franca, F. O. and Aldeia, G. S. I.},
    title = {Interaction–Transformation Evolutionary Algorithm for Symbolic Regression},
    journal = {Evolutionary Computation},
    volume = {29},
    number = {3},
    pages = {367-390},
    year = {2021},
    month = {09},
    issn = {1063-6560},
    doi = {10.1162/evco_a_00285},
    url = {https://doi.org/10.1162/evco\_a\_00285},
    eprint = {https://direct.mit.edu/evco/article-pdf/29/3/367/1959462/evco\_a\_00285.pdf},
}

% 深度符号表征学习
@inproceedings{
DL4Symbolic,
title={Deep Learning For Symbolic Mathematics},
author={Guillaume Lample and François Charton},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1eZYeHFDS}
}

% ARIMA时间序列的一本书
@article{ARIMA_old,
  title={ARIMA model building and the time series analysis approach to forecasting},
  author={Newbold, Paul},
  journal={Journal of forecasting},
  volume={2},
  number={1},
  pages={23--35},
  year={1983},
  publisher={Wiley Online Library}
}

@inproceedings{ARMA,
  title={Time series analysis of household electric consumption with ARIMA and ARMA models},
  author={Chujai, Pasapitch and Kerdprasop, Nittaya and Kerdprasop, Kittisak},
  booktitle={Proceedings of the international multiconference of engineers and computer scientists},
  volume={1},
  pages={295--300},
  year={2013}
}

% BERT
@misc{BERT,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

% DistilBERT
@misc{DistilBERT,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.01108}, 
}

% 多模态 BEiT v3
@inproceedings{BEiT,
  title={Image as a foreign language: Beit pretraining for vision and vision-language tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19175--19186},
  year={2023}
}

% 对比学习MoCo
@inproceedings{MoCo_v1,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

% Peri-midFormer
@inproceedings{Peri-midFormer,
title={Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis},
author={Qiang Wu and Gechang Yao and Zhixi Feng and Shuyuan Yang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=5iUxMVJVEV}
}

% Adam
@misc{Adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

% AdamW
@inproceedings{
AdamW,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

% DLinear
@inproceedings{DLinear,
author = {Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
title = {Are transformers effective for time series forecasting?},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i9.26317},
doi = {10.1609/aaai.v37i9.26317},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence},
articleno = {1248},
numpages = {8},
series = {AAAI'23/IAAI'23/EAAI'23}
}

% LightTS
@misc{LightTS,
      title={Less Is More: Fast Multivariate Time Series Forecasting with Light Sampling-oriented MLP Structures}, 
      author={Tianping Zhang and Yizhuo Zhang and Wei Cao and Jiang Bian and Xiaohan Yi and Shun Zheng and Jian Li},
      year={2022},
      eprint={2207.01186},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.01186}, 
}

@inproceedings{Informer,
  title={Informer: Beyond efficient transformer for long sequence time-series forecasting},
  author={Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={12},
  pages={11106--11115},
  year={2021}
}

% Transformer在时间序列分析中的应用
@article{Transformer-in-TSA,
  title={Transformers in time-series analysis: A tutorial},
  author={Ahmed, Sabeen and Nielsen, Ian E and Tripathi, Aakash and Siddiqui, Shamoon and Ramachandran, Ravi P and Rasool, Ghulam},
  journal={Circuits, Systems, and Signal Processing},
  volume={42},
  number={12},
  pages={7433--7466},
  year={2023},
  publisher={Springer}
}

@inproceedings{
Non-stationary-transformers,
title={Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting},
author={Yong Liu and Haixu Wu and Jianmin Wang and Mingsheng Long},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=ucNDIDRNjjv}
}

% Crossformer
@inproceedings{Crossformer,
title={Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting},
author={Yunhao Zhang and Junchi Yan},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=vSVLM2j9eie}
}

% iTransformer
@inproceedings{
iTransformer,
title={iTransformer: Inverted Transformers Are Effective for Time Series Forecasting},
author={Yong Liu and Tengge Hu and Haoran Zhang and Haixu Wu and Shiyu Wang and Lintao Ma and Mingsheng Long},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=JePfAI8fah}
}

NIPS 2021
@inproceedings{Autoformer,
title={Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting},
author={Haixu Wu and Jiehui Xu and Jianmin Wang and Mingsheng Long},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=J4gRj6d5Qm}
}

@misc{TimeGPT,
      title={TimeGPT-1}, 
      author={Azul Garza and Cristian Challu and Max Mergenthaler-Canseco},
      year={2024},
      eprint={2310.03589},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.03589}, 
}

% a survey on time series foundation models KDD2024
@inproceedings{KDD-Survey,
  title={Foundation models for time series analysis: A tutorial and survey},
  author={Liang, Yuxuan and Wen, Haomin and Nie, Yuqi and Jiang, Yushan and Jin, Ming and Song, Dongjin and Pan, Shirui and Wen, Qingsong},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6555--6565},
  year={2024}
}

% a survey of video transformer
@article{video-transformer,
  title={Video transformers: A survey},
  author={Selva, Javier and Johansen, Anders S and Escalera, Sergio and Nasrollahi, Kamal and Moeslund, Thomas B and Clap{\'e}s, Albert},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={11},
  pages={12922--12943},
  year={2023},
  publisher={IEEE}
}

% ADF平稳性检验
@misc{ADF,
  title={Efficient tests for an autoregressive unit root},
  author={Elliott, Graham and Rothenberg, Thomas J and Stock, James H},
  year={1992},
  publisher={National Bureau of Economic Research Cambridge, Mass., USA}
}

% 时间序列的可预测性分析
@InProceedings{forecastable,
  title = 	 {Forecastable Component Analysis},
  author = 	 {Goerg, Georg},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {64--72},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/goerg13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/goerg13.html},
}


% 时间序列掩码自监督预训练的方法
@inproceedings{MaskTime,
  title={A transformer-based framework for multivariate time series representation learning},
  author={Zerveas, George and Jayaraman, Srideepika and Patel, Dhaval and Bhamidipaty, Anuradha and Eickhoff, Carsten},
  booktitle={Proceedings of the 27th ACM SIGKDD conference on knowledge discovery \& data mining},
  pages={2114--2124},
  year={2021}
}

% 多模态大语言模型新文综述
@article{multimodal-survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={National Science Review},
  pages={nwae403},
  year={2024},
  publisher={Oxford University Press}
}

% 大语言模型的论文
@inproceedings{
position,
title={Position: What Can Large Language Models Tell Us about Time Series Analysis},
author={Ming Jin and YiFan Zhang and Wei Chen and Kexin Zhang and Yuxuan Liang and Bin Yang and Jindong Wang and Shirui Pan and Qingsong Wen},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=iroZNDxFJZ}
}

% 动量蒸馏的一篇文章
@ARTICLE{momentum-distillation,
  author={Lin, Ronghao and Hu, Haifeng},
  journal={IEEE Transactions on Affective Computing}, 
  title={Multi-Task Momentum Distillation for Multimodal Sentiment Analysis}, 
  year={2024},
  volume={15},
  number={2},
  pages={549-565},
  keywords={Task analysis;Multitasking;Knowledge engineering;Sentiment analysis;Feature extraction;Visualization;Acoustics;Multi-task learning;knowledge distillation;unimodal momentum model;multimodal sentiment analysis},
  doi={10.1109/TAFFC.2023.3282410}}


% 知识蒸馏的一篇综述论文
@article{KD-survey,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}

% FEDformer
@inproceedings{FEDformer,
  title={Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting},
  author={Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle={International conference on machine learning},
  pages={27268--27286},
  year={2022},
  organization={PMLR},
  url={https://arxiv.org/abs/2201.12740}
}

% ETSformer
@misc{
ETSformer,
title={{ETS}former: Exponential Smoothing Transformers for Time-series Forecasting},
author={Gerald Woo and Chenghao Liu and Doyen Sahoo and Akshat Kumar and Steven Hoi},
year={2023},
url={https://openreview.net/forum?id=5m_3whfo483}
}

% Anomaly Transformer
@misc{Anomaly-Transformer,
      title={Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy}, 
      author={Jiehui Xu and Haixu Wu and Jianmin Wang and Mingsheng Long},
      year={2022},
      eprint={2110.02642},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.02642}, 
}

% Rocket
@article{Rocket,
  title={ROCKET: exceptionally fast and accurate time series classification using random convolutional kernels},
  author={Dempster, Angus and Petitjean, Fran{\c{c}}ois and Webb, Geoffrey I},
  journal={Data Mining and Knowledge Discovery},
  volume={34},
  number={5},
  pages={1454--1495},
  year={2020},
  publisher={Springer}
}

% InceptionTime
@article{InceptionTime,
  title={Inceptiontime: Finding alexnet for time series classification},
  author={Ismail Fawaz, Hassan and Lucas, Benjamin and Forestier, Germain and Pelletier, Charlotte and Schmidt, Daniel F and Weber, Jonathan and Webb, Geoffrey I and Idoumghar, Lhassane and Muller, Pierre-Alain and Petitjean, Fran{\c{c}}ois},
  journal={Data Mining and Knowledge Discovery},
  volume={34},
  number={6},
  pages={1936--1962},
  year={2020},
  publisher={Springer}
}

% TimeMixer
@inproceedings{
TimeMixer,
title={TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting},
author={Shiyu Wang and Haixu Wu and Xiaoming Shi and Tengge Hu and Huakun Luo and Lintao Ma and James Y. Zhang and JUN ZHOU},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=7oLshfEIC2}
}

% FiLM
@inproceedings{FiLM,
title={Fi{LM}: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting},
author={Tian Zhou and Ziqing Ma and xue wang and Qingsong Wen and Liang Sun and Tao Yao and Wotao Yin and Rong Jin},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=zTQdHSQUQWc}
}

% AutoTimes
@inproceedings{
AutoTimes,
title={AutoTimes: Autoregressive Time Series Forecasters via Large Language Models},
author={Yong Liu and Guo Qin and Xiangdong Huang and Jianmin Wang and Mingsheng Long},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=FOvZztnp1H}
}

% Chronos
@article{
Chronos,
title={Chronos: Learning the Language of Time Series},
author={Abdul Fatir Ansari and Lorenzo Stella and Ali Caner Turkmen and Xiyuan Zhang and Pedro Mercado and Huibin Shen and Oleksandr Shchur and Syama Sundar Rangapuram and Sebastian Pineda Arango and Shubham Kapoor and Jasper Zschiegner and Danielle C. Maddix and Hao Wang and Michael W. Mahoney and Kari Torkkola and Andrew Gordon Wilson and Michael Bohlke-Schneider and Bernie Wang},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=gerNCVqqtR},
note={Expert Certification}
}

% UniTS
@inproceedings{
UniTS,
title={Uni{TS}: A Unified Multi-Task Time Series Model},
author={Shanghua Gao and Teddy Koker and Owen Queen and Thomas Hartvigsen and Theodoros Tsiligkaridis and Marinka Zitnik},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=nBOdYBptWW}
}

% 可逆归一化
@inproceedings{
ReVIN,
title={Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift},
author={Taesung Kim and Jinhee Kim and Yunwon Tae and Cheonbok Park and Jang-Ho Choi and Jaegul Choo},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=cGDAkQo1C0p}
}

% 四个时间序列预测数据集的网站
@misc{weather,
    author = {{Wetterstation}},
    title={{Weather}},
    howpublished={\url{https://www.bgc-jena.mpg.de/wetter/}}
}
@misc{traffic,
    author = {{PeMS}},
    title={{Traffic}},
    howpublished={\url{http://pems.dot.ca.gov/}}
}

@misc{ECL,
    author = {{UCI}},
    title={{Electricity}},
    howpublished={\url{https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014}}
}

@misc{M4team2018dataset,
    author = {{Spyros Makridakis}},
    title = {{M4} dataset},
    url = {https://github.com/M4Competition/M4-methods/tree/master/Dataset},
    urldate = {07.05.2019},
    year = {2018},
}

% UEA多元时间序列分类数据集
@misc{UEA,
      title={The UEA multivariate time series classification archive, 2018}, 
      author={Anthony Bagnall and Hoang Anh Dau and Jason Lines and Michael Flynn and James Large and Aaron Bostrom and Paul Southam and Eamonn Keogh},
      year={2018},
      eprint={1811.00075},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.00075}, 
}

% Exchange数据集和一个循环网络模型
@inproceedings{LSTNet,
author = {Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},
title = {Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks},
year = {2018},
isbn = {9781450356572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209978.3210006},
doi = {10.1145/3209978.3210006},
booktitle = {The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
pages = {95–104},
numpages = {10},
keywords = {autoregressive models, multivariate time series, neural network},
location = {Ann Arbor, MI, USA},
series = {SIGIR '18}
}

@inproceedings{SMD,
author = {Su, Ya and Zhao, Youjian and Niu, Chenhao and Liu, Rong and Sun, Wei and Pei, Dan},
title = {Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330672},
doi = {10.1145/3292500.3330672},
pages = {2828–2837},
numpages = {10},
keywords = {anomaly detection, multivariate time series, recurrent neural network, stochastic model},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{MSL,
author = {Hundman, Kyle and Constantinou, Valentino and Laporte, Christopher and Colwell, Ian and Soderstrom, Tom},
title = {Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219845},
doi = {10.1145/3219819.3219845},
pages = {387–395},
numpages = {9},
keywords = {time-series, rnns, neural networks, lstms, forecasting, anomaly detection, aerospace},
location = {London, United Kingdom},
series = {KDD '18}
}

@INPROCEEDINGS{SWaT,
  author={Mathur, Aditya P. and Tippenhauer, Nils Ole},
  booktitle={2016 International Workshop on Cyber-physical Systems for Smart Water Networks (CySWater)}, 
  title={SWaT: a water treatment testbed for research and training on ICS security}, 
  year={2016},
  volume={},
  number={},
  pages={31-36},
  keywords={Sensors;Actuators;Feeds;Process control;Chemicals;Chemical sensors;Security;Cyber Physical Systems;Industrial Control Systems;Cyber Attacks;Cyber Defense;Water Testbed},
  doi={10.1109/CySWater.2016.7469060}
}

@inproceedings{PSM,
author = {Abdulaal, Ahmed and Liu, Zhuanghua and Lancewicki, Tomer},
title = {Practical Approach to Asynchronous Multivariate Time Series Anomaly Detection and Localization},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467174},
doi = {10.1145/3447548.3467174},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
pages = {2485–2494},
numpages = {10},
keywords = {synchronization, representation learning, multivariate time series, deep learning, anomaly detection},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

% NIPS2024 TimeXer
@inproceedings{
TimeXer,
title={TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables},
author={Yuxuan Wang and Haixu Wu and Jiaxiang Dong and Guo Qin and Haoran Zhang and Yong Liu and Yun-Zhong Qiu and Jianmin Wang and Mingsheng Long},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=INAeUQ04lT}
}

% ChatTime
@misc{ChatTime,
      title={ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data}, 
      author={Chengsen Wang and Qi Qi and Jingyu Wang and Haifeng Sun and Zirui Zhuang and Jinming Wu and Lei Zhang and Jianxin Liao},
      year={2024},
      eprint={2412.11376},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.11376}, 
}

% 时间序列预测的benchmark
@misc{TFB,
      title={TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods}, 
      author={Xiangfei Qiu and Jilin Hu and Lekui Zhou and Xingjian Wu and Junyang Du and Buang Zhang and Chenjuan Guo and Aoying Zhou and Christian S. Jensen and Zhenli Sheng and Bin Yang},
      year={2024},
      eprint={2403.20150},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.20150}, 
}

@misc{TSA-survey-PAMI,
      title={Deep Time Series Models: A Comprehensive Survey and Benchmark}, 
      author={Yuxuan Wang and Haixu Wu and Jiaxiang Dong and Yong Liu and Mingsheng Long and Jianmin Wang},
      year={2024},
      eprint={2407.13278},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.13278}, 
}

% 时间序列分类的综述
@article{TSC-survey,
  title={Deep learning for time series classification: a review},
  author={Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
  journal={Data mining and knowledge discovery},
  volume={33},
  number={4},
  pages={917--963},
  year={2019},
  publisher={Springer}
}

% 关于深度学习缩放定律的文章
@article{Neural-Sclaing-Laws,
  title={Explaining neural scaling laws},
  author={Bahri, Yasaman and Dyer, Ethan and Kaplan, Jared and Lee, Jaehoon and Sharma, Utkarsh},
  journal={Proceedings of the National Academy of Sciences},
  volume={121},
  number={27},
  pages={e2311878121},
  year={2024},
  publisher={National Academy of Sciences}
}

% DTW动态时间序列扭曲
@inproceedings{DTW,
author = {Berndt, Donald J. and Clifford, James},
title = {Using dynamic time warping to find patterns in time series},
year = {1994},
publisher = {AAAI Press},
booktitle = {Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining},
pages = {359–370},
numpages = {12},
keywords = {time series, pattern analysis, knowledge discovery, dynamic time warping, dynamic programming},
location = {Seattle, WA},
series = {AAAIWS'94}
}


% 集成学习方法XGBoost
@inproceedings{XGBoost,
author = {Chen, Tianqi and Guestrin, Carlos},
title = {XGBoost: A Scalable Tree Boosting System},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939785},
doi = {10.1145/2939672.2939785},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {785–794},
numpages = {10},
keywords = {large-scale machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

% 时间序列对比模型LSTM
@article{LSTM,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = {Long Short-Term Memory},
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

% 时间序列对比模型LSSL
@inproceedings{
LSSL,
title={Efficiently Modeling Long Sequences with Structured State Spaces},
author={Albert Gu and Karan Goel and Christopher Re},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=uYLFoz1vlAC}
}

% 时间序列分类对比基线TCN
@inproceedings{TCN,
 author = {Franceschi, Jean-Yves and Dieuleveut, Aymeric and Jaggi, Martin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Unsupervised Scalable Representation Learning for Multivariate Time Series},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/53c6de78244e9f528eb3e1cda69699bb-Paper.pdf},
 volume = {32},
 year = {2019}
}


% ICML时间序列分类对比模型
@inproceedings{TSLANet,
  author={Emadeldeen Eldele and Mohamed Ragab and Zhenghua Chen and Min Wu and Xiaoli Li},
  title={TSLANet: Rethinking Transformers for Time Series Representation Learning},
  year={2024},
  cdate={1704067200000},
  url={https://openreview.net/forum?id=CGR3vpX63X},
  booktitle={ICML}
}

% 时间序列短期预测对比模型 MICN
@inproceedings{
MICN,
title={{MICN}: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting},
author={Huiqiang Wang and Jian Peng and Feihu Huang and Jince Wang and Junhui Chen and Yifei Xiao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=zt53IDUR1U}
}

% 时间序列预测对比模型 Reformer
@inproceedings{Reformer,
title={Reformer: The Efficient Transformer},
author={Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgNKkHtvB}
}

% 时间序列预测对比模型 Pyraformer
@inproceedings{
Pyraformer,
title={Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting},
author={Shizhan Liu and Hang Yu and Cong Liao and Jianguo Li and Weiyao Lin and Alex X. Liu and Schahram Dustdar},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=0EXmFzUn5I}
}

% He的MAE
@inproceedings{MAE,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

% 谷歌的一个时间序列大模型
@inproceedings{
TimeFM,
title={A decoder-only foundation model for time-series forecasting},
author={Abhimanyu Das and Weihao Kong and Rajat Sen and Yichen Zhou},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=jn2iTJas6h}
}

% IMCL2024 Moment
@inproceedings{
Moment,
title={{MOMENT}: A Family of Open Time-series Foundation Models},
author={Mononito Goswami and Konrad Szafer and Arjun Choudhry and Yifu Cai and Shuo Li and Artur Dubrawski},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=FVvf69a5rx}
}

% 绘制t-SNE图可视化
@article{t-SNE,
  author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
  title = {How to Use t-SNE Effectively},
  journal = {Distill},
  year = {2016},
  url = {http://distill.pub/2016/misread-tsne},
  doi = {10.23915/distill.00002}
}

% SimCLR对比学习框架
@inproceedings{SimCLR,
author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
title = {A simple framework for contrastive learning of visual representations},
year = {2020},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {149},
numpages = {11},
series = {ICML'20}
}

% li学长论文
@inproceedings{Defenders,
title={Rapid Plug-in Defenders},
author={Kai Wu and Yujian Betterest Li and Jian Lou and Xiaoyu Zhang and Handing Wang and Jing Liu},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=UMPedMhKWm}
}

% 大语言模型的缩放定律论文
@misc{scaling-in-llm,
      title={Scaling Laws for Neural Language Models}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2001.08361}, 
}

@InProceedings{Scaling-Laws-for-Generative,
  title={Scaling Laws for Generative Mixed-Modal Language Models},
  author={Aghajanyan, Armen and Yu, Lili and Conneau, Alexis and Hsu, Wei-Ning and Hambardzumyan, Karen and Zhang, Susan and Roller, Stephen and Goyal, Naman and Levy, Omer and Zettlemoyer, Luke},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={265--279},
  year={2023},
  editor={Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume={202},
  series={Proceedings of Machine Learning Research},
  month={23--29 Jul},
  publisher={PMLR},
  pdf={https://proceedings.mlr.press/v202/aghajanyan23a/aghajanyan23a.pdf},
  url={https://proceedings.mlr.press/v202/aghajanyan23a.html},
}

% Attention is all you need
@article{Transformer,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{li2023discover,
  title = {Discover governing differential equations from evolving systems},
  author = {Li, Yuanyuan and Wu, Kai and Liu, Jing},
  journal = {Physical Review Research},
  volume = {5},
  issue = {2},
  pages = {023126},
  numpages = {12},
  year = {2023},
  month = {May},
  publisher = {American Physical Society}
}


@inproceedings{
neurosymbolic,
title={Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval},
author={Uri Alon and Frank F. Xu and Junxian He and Sudipta Sengupta and Dan Roth and Graham Neubig},
booktitle={ICML 2022 Workshop on Knowledge Retrieval and Language Models},
year={2022},
url={https://openreview.net/forum?id=ZJZmKGM6UB}
}

@inproceedings{
SparseTSF,
title={Sparse{TSF}: Modeling Long-term Time Series Forecasting with *1k* Parameters},
author={Shengsheng Lin and Weiwei Lin and Wentai Wu and Haojun Chen and Junjie Yang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=54NSHO0lFe}
}

@inproceedings{
SAMformer,
title={{SAM}former: Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention},
author={Romain Ilbert and Ambroise Odonnat and Vasilii Feofanov and Aladin Virmaux and Giuseppe Paolo and Themis Palpanas and Ievgen Redko},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=8kLzL5QBh2}
}

@article{Chen_Wu_Lou_Liu_2024,
title={Signed Graph Neural Ordinary Differential Equation for Modeling Continuous-Time Dynamics},
volume={38},
url={https://ojs.aaai.org/index.php/AAAI/article/view/28670},
DOI={10.1609/aaai.v38i8.28670},
number={8},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Chen, Lanlan and Wu, Kai and Lou, Jian and Liu, Jing},
year={2024},
month={Mar.},
pages={8292-8301} }

@article{li2023self,
title = {Self-paced ARIMA for robust time series prediction},
journal = {Knowledge-Based Systems},
volume = {269},
pages = {110489},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110489},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123002393},
author = {Yitong Li and Kai Wu and Jing Liu},
keywords = {Autoregressive integrated moving average, Self-paced learning, Sample diversity, Time series prediction, Noise},
}

@misc{RLinear,
      title={Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping}, 
      author={Zhe Li and Shiyi Qi and Yiduo Li and Zenglin Xu},
      year={2023},
      eprint={2305.10721},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.10721}, 
}

@inproceedings{
FilterNet,
title={FilterNet: Harnessing Frequency Filters for Time Series Forecasting},
author={Kun Yi and Jingru Fei and Qi Zhang and Hui He and Shufeng Hao and Defu Lian and Wei Fan},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=ugL2D9idAD}
}

% 两个在合成数据集上训练的模型
@inproceedings{
TimePFN,
title={Time{PFN}: Effective Multivariate Time Series Forecasting with Synthetic Data},
author={Ege Onur Taga and Muhammed Emrullah Ildiz and Samet Oymak},
booktitle={NeurIPS Workshop on Time Series in the Age of Large Models},
year={2024},
url={https://openreview.net/forum?id=A9iqHtj3dk}
}
@inproceedings{
ForecastPFN,
title={Forecast{PFN}: Synthetically-Trained Zero-Shot Forecasting},
author={Samuel Dooley and Gurnoor Singh Khurana and Chirag Mohapatra and Siddartha Venkat Naidu and Colin White},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=tScBQRNgjk}
}

% Transformer贝叶斯推断
@inproceedings{
TDBI,
title={Transformers Can Do Bayesian Inference},
author={Samuel M{\"u}ller and Noah Hollmann and Sebastian Pineda Arango and Josif Grabocka and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=KSugKcbNf9}
}


@InProceedings{PFN,
  title = 	 {Statistical Foundations of Prior-Data Fitted Networks},
  author =       {Nagler, Thomas},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {25660--25676},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/nagler23a/nagler23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/nagler23a.html},
}

% 时间序列的排列熵
@article{permutation,
 author = {Cao, Yinhe and Tung, Wen-wen and Gao, J. B. and Protopopescu, V. A. and Hively, L. M.},
 doi = {10.1103/physreve.70.046217},
 journal = {Physical Review E},
 keywords = {},
 number = {4},
 pages = {046217},
 title = {Detecting dynamical changes in time series using the permutation entropy},
 url = {https://app.dimensions.ai/details/publication/pub.1060732058},
 volume = {70},
 year = {2004}
}

% 时间序列的季节性强度
@article{seasonality,
  title={STL: A seasonal-trend decomposition},
  author={Cleveland, Robert B and Cleveland, William S and McRae, Jean E and Terpenning, Irma and others},
  journal={J. off. Stat},
  volume={6},
  number={1},
  pages={3--73},
  year={1990}
}

% 时间序列的趋势信息
@article{MK-test,
  title={Review of methods for the detection and estimation of trends with emphasis on water quality applications},
  author={Esterby, Sylvia R},
  journal={Hydrological processes},
  volume={10},
  number={2},
  pages={127--149},
  year={1996},
  publisher={Wiley Online Library}
}

@inproceedings{radviz,
author = {Zhou, Fangfang and Chen, Minghui and Wang, Zeyu and Luo, Feng and Luo, Xiaobo and Huang, Wei and Chen, Yi and Zhao, Ying},
title = {A radviz-based visualization for understanding fuzzy clustering results},
year = {2017},
isbn = {9781450352925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3105971.3105980},
doi = {10.1145/3105971.3105980},
booktitle = {Proceedings of the 10th International Symposium on Visual Information Communication and Interaction},
pages = {9–15},
numpages = {7},
keywords = {visual data mining, radviz, membership degree matrix, fuzzy clustering},
location = {Bangkok, Thailand},
series = {VINCI '17}
}

@inproceedings{Monash,
title={Monash Time Series Forecasting Archive},
author={Rakshitha Wathsadini Godahewa and Christoph Bergmeir and Geoffrey I. Webb and Rob Hyndman and Pablo Montero-Manso},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
year={2021},
url={https://openreview.net/forum?id=wEc1mgAjU-}
}

@inproceedings{
MS-TIP,
title={{MS}-{TIP}: Imputation Aware Pedestrian Trajectory Prediction},
author={Pranav singh chib and Achintya Nath and Paritosh Kabra and Ishu Gupta and Pravendra Singh},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=s4Hy0L4mml}
}

@inproceedings{
ECG-LLM,
title={Zero-Shot {ECG} Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement},
author={Che Liu and Zhongwei Wan and Cheng Ouyang and Anand Shah and Wenjia Bai and Rossella Arcucci},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=ZvJ2lQQKjz}
}

@inproceedings{
Data-driven-weather,
title={Towards a Self-contained Data-driven Global Weather Forecasting Framework},
author={Yi Xiao and LEI BAI and Wei Xue and Hao Chen and Kun Chen and kang chen and Tao Han and Wanli Ouyang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=Y2WorV5ag6}
}

@inproceedings{
graph-forecasting,
title={Graph-based Time Series Clustering for End-to-End Hierarchical Forecasting},
author={Andrea Cini and Danilo Mandic and Cesare Alippi},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=nd47Za5jk5}
}

@inproceedings{
Conformal,
title={Conformal prediction for multi-dimensional time series by ellipsoidal sets},
author={Chen Xu and Hanyang Jiang and Yao Xie},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=uN39Tt9P8b}
}

@inproceedings{
TimeMIL,
title={Time{MIL}: Advancing Multivariate Time Series Classification via a Time-aware Multiple Instance Learning},
author={Xiwen Chen and Peijie Qiu and Wenhui Zhu and Huayu Li and Hao Wang and Aristeidis Sotiras and Yalin Wang and Abolfazl Razi},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=AxmefV2NEf}
}

@inproceedings{
CauDiTS,
title={CauDi{TS}: Causal Disentangled Domain Adaptation of Multivariate Time Series},
author={junxin lu and Shiliang Sun},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=lsavZkUjFZ}
}

@inproceedings{
ALERT,
title={{ALERT}-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data},
author={Carmen Martin Turrero and Maxence Bouvier and Manuel Breitenstein and Pietro Zanuttigh and Vincent Parret},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=8ZDFn7BDaH}
}

@inproceedings{
Discovering,
title={Discovering Mixtures of Structural Causal Models from Time Series Data},
author={Sumanth Varambally and Yian Ma and Rose Yu},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=cHJAUdam3i}
}

@article{
AI-Feynman,
author = {Silviu-Marian Udrescu  and Max Tegmark },
title = {AI Feynman: A physics-inspired method for symbolic regression},
journal = {Science Advances},
volume = {6},
number = {16},
pages = {eaay2631},
year = {2020},
doi = {10.1126/sciadv.aay2631},
URL = {https://www.science.org/doi/abs/10.1126/sciadv.aay2631},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.aay2631},
}

@inproceedings{
SIN,
title={{SIN}: Selective and Interpretable Normalization for Long-Term Time Series Forecasting},
author={Lu Han and Han-Jia Ye and De-Chuan Zhan},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=cUMOVfOIve}
}

@inproceedings{
MF-CLR,
title={{MF}-{CLR}: Multi-Frequency Contrastive Learning Representation for Time Series},
author={Jufang Duan and Wei Zheng and Yangzhou Du and Wenfa Wu and Haipeng Jiang and Hongsheng Qi},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=ecO7WOIlMD}
}

@inproceedings{
FlashTS,
title={Flash{ST}: A Simple and Universal Prompt-Tuning Framework for Traffic Prediction},
author={Zhonghang Li and Lianghao Xia and Yong Xu and Chao Huang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=vye4OgLaTy}
}




@inproceedings{TimeMixer++,
      title={TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis}, 
      author={Shiyu Wang and Jiawei Li and Xiaoming Shi and Zhou Ye and Baichuan Mo and Wenze Lin and Shengtong Ju and Zhixuan Chu and Ming Jin},
      year={2025},
      booktitle={The Thirteenth International Conference on Learning Representations},
      url={https://arxiv.org/abs/2410.16032}, 
}

@inproceedings{Timer-XL,
      title={Timer-XL: Long-Context Transformers for Unified Time Series Forecasting}, 
      author={Yong Liu and Guo Qin and Xiangdong Huang and Jianmin Wang and Mingsheng Long},
      year={2025},
      booktitle={The Thirteenth International Conference on Learning Representations},
      url={https://arxiv.org/abs/2410.04803}, 
}

% 关于时间序列基础模型缩放定律的研究
@inproceedings{Time-Scaling-Laws,
      title={Towards Neural Scaling Laws for Time Series Foundation Models}, 
      author={Qingren Yao and Chao-Han Huck Yang and Renhe Jiang and Yuxuan Liang and Ming Jin and Shirui Pan},
      year={2025},
      booktitle={The Thirteenth International Conference on Learning Representations},
      url={https://arxiv.org/abs/2410.12360}, 
}

@inproceedings{Time-MoE,
      title={Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts}, 
      author={Xiaoming Shi and Shiyu Wang and Yuqi Nie and Dianqi Li and Zhou Ye and Qingsong Wen and Ming Jin},
      year={2025},
      booktitle={The Thirteenth International Conference on Learning Representations},
      url={https://arxiv.org/abs/2409.16040}, 
}