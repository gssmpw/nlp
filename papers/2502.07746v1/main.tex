%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{multirow,tabularx}

\usepackage{booktabs} % for professional tables
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2025}
\usepackage[preprint]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{nicefrac}
\usepackage{verbatim}
\usepackage{bbm} 
\usepackage{mathtools}
\usepackage{breqn}
\usepackage{setspace}
\usepackage{nicefrac}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newcommand{\modelname}{HiPoNet}
% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
\newcommand{\m}[1]{\mathbf{#1}}

\newcommand{\rex}[1]{\textcolor{magenta}{(Rex: #1)}}

\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{{\modelname}: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data}

\begin{document}

\twocolumn[
\icmltitle{{\modelname}: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Siddharth Viswanath*}{ycs}
\icmlauthor{Hiren Madhu*}{ycs}
\icmlauthor{Dhananjay Bhaskar}{ycs,yg}
\icmlauthor{Jake Kovalic}{yap}
\icmlauthor{Dave Johnson}{bpc}
\icmlauthor{Rex Ying}{ycs}
\icmlauthor{Christopher Tape}{ucl}
\icmlauthor{Ian Adelstein}{ym}
\icmlauthor{Michael Perlmutter}{bpc,bsm}
\icmlauthor{Smita Krishnaswamy}{ycs,yg,cbb,wti,ypm}
\end{icmlauthorlist}

\icmlaffiliation{ycs}{Department of Computer Science, Yale University, New Haven, USA}
\icmlaffiliation{yap}{Department of Applied Physics, Yale University, New Haven, USA}
\icmlaffiliation{ym}{Department of Mathematics, Yale University, New Haven, USA}
\icmlaffiliation{bpc}{Program in Computing, Boise State University, Idaho, USA}
\icmlaffiliation{bsm}{Department of Mathematics, Boise State University, Idaho, USA}
\icmlaffiliation{ucl}{Cell Communication Lab, Department of Oncology, University College London Cancer Institute, London, UK}
\icmlaffiliation{cbb}{Computational Biology and Bioinformatics Program, Yale University, New Haven, USA}
\icmlaffiliation{wti}{Wu-Tsai Institute, Yale University, New Haven, USA}
\icmlaffiliation{ypm}{Program for Applied Math, Yale University, New Haven, USA}
\icmlaffiliation{yg}{Department of Genetics, Yale University, New Haven, USA}
\icmlcorrespondingauthor{Smita Krishnaswamy}{krishnaswamy.smita@yale.edu}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
In this paper, we propose {{\modelname}}, an end-to-end differentiable neural network for regression, classification, and representation learning on high-dimensional point clouds. Single-cell data can have high dimensionality exceeding the capabilities of existing methods for point clouds which are tailored for 3D data. Moreover, modern single-cell and spatial experiments now yield entire cohorts of datasets (i.e. one on every patient), necessitating models that can process large, high-dimensional point clouds at scale. Most current approaches build a single nearest-neighbor graph, discarding important geometric information. In contrast, {\modelname} forms higher-order simplicial complexes through learnable feature reweighting, generating multiple data views that disentangle distinct biological processes. It then employs simplicial wavelet transforms to extract multi-scale features—capturing both local and global topology. We empirically show that these components preserve topological information in the learned representations, and that {\modelname} significantly outperforms state-of-the-art point-cloud and graph-based models on single cell. We also show an application of {\modelname} on spatial transcriptomics datasets using spatial co-ordinates as one of the views. Overall, {\modelname} offers a robust and scalable solution for high-dimensional data analysis.
%In this paper, we propose {\modelname}, an end-to-end differentiable neural network for regression, classification, and representation learning of high-dimensional point clouds. Many biological applications, such as single-cell RNA sequencing (ScRNA-seq), naturally produce point clouds with tens of thousands of dimensions, posing significant challenges to existing approaches that are primarily designed only for three-dimensional point clouds. Recently, the production of single cell and spatial data have been lifted from producing a single dataset per experiment, to entire cohorts of related datasets (e.g., an entire dataset for each of hundreds of patients, for example), necessitating neural network methods for ingesting entire high-dimensional point clouds and performing ML tasks, in a way that has been done on images, graphs, and other modalities. Existing point cloud methods generally construct a single nearest neighbor graph from data, thereby losing much information from the point cloud. To address these limitations, {\modelname} uses higher-order simplicial complexes from the data based on learnable feature reweighing–with each reweighting providing a new view of the data projected to different measurement dimensions. These geometric structures constitute different views of the data and they can disentangle the underlying subspaces that model distinct biological processes. {\modelname} then employs simplicial wavelet transforms to extract multiscale features, encoding local and global information that is important to capture the topology of the point cloud. We empirically show that {\modelname} with these components preserves the topological information in the learned representations. Furthermore, extensive experiments on scRNA-seq datasets demonstrate that {\modelname} significantly outperform state-of-the-art point cloud and graph-based models, offering a robust and scalable solution for high-dimensional data analysis.
\end{abstract}

\begin{figure}[h]
\centering
{\includegraphics[width=0.49\textwidth]{figures/graphical_abstract.png}}
\caption{The {{\modelname}} pipeline.}
\label{fig:abstract_fig}
\end{figure}

%\vspace{-1cm}
\section{Introduction}
\label{sec:intro}
High dimensional point clouds, i.e., sets of points $\mathcal{X}=\{\mathbf{x}_i\}_{i=1}^n\subseteq \mathbb{R}^d$ now arise in many fields---most prominently single cell analysis~\cite{VENKAT2023551, trellis-pdo, pmlr-v196-chew22a, macdonald2023flowartisthighdimensionalcellular, Ahlmann-Eltze2025, Kröger2024}, where using modern technologies such as mass cytometry or scRNA-seq, large cohorts of patients can now be measured producing several high dimensional data matrices. Further, technologies like perturb-seq enable the possibility of studying single-cell data under many conditions leading to comparable cohorts of datasets. Thus machine learning techniques that once reasoned about data points and classified data points, now have to reason about entire datasets. This serves as the motivation for {\modelname} illustrated in Figure \ref{fig:abstract_fig}.

Generally, single cell analysis methods like UMAP~\cite{mcinnes2020umapuniformmanifoldapproximation} or PHATE~\cite{moon2019visualizing} reduce point clouds defined by single-cell data into an individual graph learned from all features (often in the tens of thousands).  However, this single graph may not specifically organize cells according to processes defined by subsets of dimensions. For instance, cells may be in a specific phase of the cell cycle which would be revealed by an organization based on cell cycle genes, or at a certain point in a differentiation process which would be revealed by stem cell genes. On the other hand,  existing neural network methods for point cloud data, such as PointNet~\citep{pointnet} and its variants~\citep{pointnet++, pointtransformer, dgcnn, pointmlp} are primarily designed for 3D point clouds and rely on spatially localized features\footnote{We discuss these techniques more in Section~\ref{sec:related}
.}. Hence they are not able to handle high-dimensional point clouds or disentangle processes from high dimensional data. As a result, there is a growing need to develop a neural network that can efficiently handle these diverse high-dimensional point clouds, ingest them seamlessly, encode the cellular processes, and perform various downstream machine learning tasks on them. To address these limitations, we introduce \textbf{{\modelname}}. 

In {\modelname}, rather than using one view of the cells as represented by a single graph, we introduce the idea of multiple views, each of which is learned using a feature reweighting vector, thus potentially detangling and making implicit biological processes explicit. Further, rather than modeling the data as a graph we model it as a simplicial complex that captures higher-order relationships between cells, which {\modelname} analyzes using multiscale wavelets. Overall,  we gain a rich representation that disentangles processes by capturing hierarchical relationships and separating overlapping biological processes, while preserving geometric and topological information of the underlying point clouds. Preserving the structure is important because it reflects the intrinsic geometry and topology of the data, providing a better interpretation of complex biological processes, and hence improving downstream analysis. 

To capture global structure using a neural network, we use a wavelet-based multiscale message aggregation scheme rather than traditional message passing in graph and simplicial neural networks, which struggle to capture long-range dependencies and multiscale relationships. Although newer models like graph transformers~\cite{graph-transformers} can capture long range dependencies, they are also limited in terms of expressive power. When applied on these point clouds, they only work on a single graph and are unable preserve the intrinsic geometric structure of the graph. However, using diffusion wavelets defined on simplicial complexes, we show theoretically that 1) we capture the underlying geometry of the point cloud, 2) we capture the  $0$-homology (connected components) of the underlying cloud, 3) we capture curvature of the point cloud. Empirically we show that we can predict persistence homology directly from our simplicial neural network, without explicitly computing topological signatures or reducing the data to those features. These properties that are preserved by {\modelname} are essential for projecting the pointcloud into subspaces  that may drive a particular classification, such as response to immunotherapy, or drug treatment response. 
%\rex{how do we compare with graph transformers etc. that can capture long range dependency?} 

The key features of {\modelname} include:
\begin{itemize}
    \item \textbf{Learning multiple views the the data:} We introduce a learnable scaling mechanism to reweight each feature in a high dimensional feature vector, which we then use to learn a graph to organize data by the processes represented by the particular view. 
    \item \textbf{Higher order constructions:} We learn simplicial complexes by conducting a VR filteration of the data, downstream neural networks built on this complex retain geometric and topological information including volume, curvature, connected components and holes in the data. We also offer the option of learning graphs from these views for cases that have high computational complexity. 
    \item \textbf{Multiscale Message Passing:} Rather than simple message aggregation schemes that smooth data, we use multiscale simplicial wavelets to aggregate features over the simplicial complex. This can find crucial groupings of data to inform final classification, from local to global without oversmoothing. 
\end{itemize}

%\rex{we might be able to improve the organization. in this paragraph we talked about both challenges of previous works and our method. it can be clearer if we have 1 paragraph for existing methods' limitations; and then one paragraph that focuses on our innovations to address these. let's also include a sentence or two on the theoretical contributions}

%Prior research in single-cell analysis typically has used a fixed view of data to analyze individual datasets and usually learn a single graph on which to perform downstream analysis. 

We showcase the utility of {\modelname} using three state-of-the art single cell {\em data cohorts} which we have curated. Note we use the term data cohort to refer to ensembles of single-cell data sets, collected on many patients or under many conditions. The first data cohort includes melanoma patients undergoing immune checkpoint blockade immunotherapy, where the task is to classify the patient response based on multiplex ion beam imaging (MIBI) datasets of T-cells, with protein expression features. Each patient here has between 489 to 1784 cells.  %The second data cohort consists of single cell flow cytometry data from COVID-19 patients admitted to Yale New Haven hospital, with the task of predicting mortality from COVID based on the cellular composition. In this dataset each patient had approximately 10,000 cells measured.  
The second data cohort features multiple patient-derived-(cancer) organoids (PDOs) from each of 12 different patients with colorectal cancer. In these PDOs, cancer cells are taken from each patient and grown as multiple 3D organoids with and without other cell types as well as in the presence of several treatments. Here, we test the ability of the neural network to uncover the treatments applied to each PDO based on the ensemble cellular states. Each organoid in this dataset has approximately 1137 cells. The final cohort features Spatial Transcriptomics data from about 500 human cancer biopsies from head-and-neck and colorectal cancer patients, capturing 40 distinct protein markers. This is an immunofluorescent imaging dataset, which is capable of measuring dozens of protein markers in a single tissue sample while preserving the spatial arrangement of cells, offering rich insights into the tumor microenvironments through spatial and gene expression view. This technology of collecting spatial data and protein markers is called spatial transcriptomics, and it is an emerging technology playing a pivotal role in advanced cancer research. These datasets highlight the scalability and diversity of {\modelname} in handling complex, high dimensional biological point cloud data. 

%In this work, we introduce a novel approach addressing the limitations of the existing methods.
%As the challenges most relevant to computer vision operate in our three-dimensional world, the bulk of the related work we discuss below aims to tackle specifically these low-dimensional problems, while our approach aims to fill a gap where the existing methods fall short.

%Early motivation for processing point cloud data lies in three-dimensional feature learning and image segmentation. PointNet \cite{pointnet} first learns a transform in $\mathbb{R}^{3 \times 3}$, and then learns a 64 dimensional transform matrix in $\mathbb{R}^{64 \times 64}$. A final symmetric max pooling layer ensures permutation invariance, and separate final classification and segmentation networks are used for downstream tasks. 

%While effective at many image segmentation tasks, PointNet \cite{pointnet} struggles to fully capture local features near structures of interest. PointNet++ \cite{pointnet++} addresses this issue by recursively applying instances of PointNet at various scales. While this extension of PointNet does outperform its predecessor, it is still designed explicitly for three-dimensional data, and performs poorly when the dimension increases. 
%\rex{shorten all point cloud literature in 1 paragraph. no need to illustrate their approach. we just need to say how our method differs from all of them at the end}

%Newer methods make use of graph and transformer layers to better extract rich features from input point clouds. The Dynamic Graph Convolutoinal Neural Network (DGCNN) encodes a point cloud as a graph using a $k$-nearest neighbor method and computes sequential convolutions over the edges of this graph. This graph is recomputed as each layer extracts new features (hence \textit{Dynamic}) and effectively extracts local relationships. Point Transformer \cite{pointtransformer} uses a local self-attention mechanism as the building block for their residual neural network, while PointMLP \cite{pointmlp} uses standard Multilayer Perceptrons for even greater performance and improved inference speed. Similar to the methods discussed above, these approaches aim to segment and classify three-dimensional point cloud data from real-world sensors, and computational performance and learning accuracy degrades when higher dimensional input is used. 

%\rex{i think deepset or other set encoding neural networks would be relevant for point cloud data as well..}

\section{Background}

A simplicial complex \(\mathcal{S}\)~\citep{random-walk-simplex, topological-simplex-sp} is defined as a finite collection of simplices that satisfies the principle of inclusion. A \(k\)-simplex, denoted as \(\sigma_k\), is a non-empty subset of $\mathcal{X}$ containing $k+1$ points. For any \(\sigma_k \in \mathcal{S}\), all non-empty subsets of \(\sigma_k\) must also belong to \(\mathcal{S}\). If $\tau_{k-1}$ is a subset of $\sigma_k$ that contains $k$ points, we say that $\tau_{k-1}$ is a face of $\sigma_k$. The order of a simplicial complex, \(K\), is determined by the highest-order simplex contained within \(\mathcal{S}\), so therefore a simplicial complex \(\mathcal{S}\) contains simplices of orders \(k = 0, 1, \dots, K\). Note that when $K=1$, a simplicial complex is essentially equivalent to an unweighted, undirected graph, where the $0$-simplices and $1$-simplices are the vertices and edges.  Features of simplices across all orders are denoted as \(\m{X} = \{\m{X}_0, \m{X}_1, \dots, \m{X}_K\}\), where \(\m{X}_k \in \mathbb{R}^{N_k \times D_k}\), where $D_k$ is the feature dimension of $k$-simplices.%å \textcolor{blue}{MP: What is $D_k$}

In a simplicial complex $\mathcal{S}$, a \(k\)-simplex \(\sigma_k\in\mathcal{S}\) can have four types of neighbors:

\begin{itemize}[leftmargin=*,left=0pt..1em,topsep=0pt,itemsep=0pt]

\item \textbf{Boundary adjacent neighbors or faces:} These are the \((k-1)\)-simplices $\tau_{k-1}$ that are faces of \(\sigma_k\), denoted as 
 $\mathcal{N}_{\mathcal{B}}(\sigma_k)=\{\tau_{k-1} \,\text{:}\, \tau_{k-1} \subset \sigma_k\}$. 
%\textcolor{blue}{I think it is easier to say that the boundary adjacent neighbors of $\sigma_k$ are its faces. Similarly with co-faces, etc. (Make sure to define faces above)} NOTE: Added faces in bullet point.

\item \textbf{Coboundary adjacent neighbors or co-faces:} These are all \((k+1)\)-simplices $\tau_{k+1}$ which have \(\sigma_k\) as a face, denoted as $\mathcal{N}_{\mathcal{C}}(\sigma_k)=\{\tau_{k+1} \,\text{:}\, \sigma_k \subset \tau_{k+1}\}.$

\item \textbf{Lower adjacent neighbors:} These are simplices $\tau_k$ of the same order as \(\sigma_k\) that share a common face, $\rho_{k-1}$, represented as $\mathcal{N}_{\mathcal{L}}(\sigma_k)=\{\tau_k \,\text{:}\, \rho_{k-1}=\sigma_k\cap \tau_k,  \: |\rho_{k-1}|=k-1 \}$.

\item \textbf{Upper adjacent neighbors:} These are simplices, $\tau_k$ of the same order as \(\sigma_k\) that are contained in a common \((k+1)\)-simplex $\rho_{k+1}\in\mathcal{S}$, given by 
$\mathcal{N}_{\mathcal{U}}(\sigma_k)=\{\tau_k \,\text{:}\, \rho_{k+1}=\sigma_k\cup \tau_k,\: |\rho_{k+1}|=k+1\}$.
%$\mathcal{N}_{\mathcal{U}}(\sigma_k)=\{\tau_k / \sigma_k \subset \rho_{k+1} \wedge \tau_k \subset \rho_{k+1}\}$.
%\textcolor{blue}{What is wedge, why aren't we writing intersection symbol $\cap$. Also, shouldn't it just be $\tau_k\cap \sigma_k=\rho_{k-1}$? Similar with the others}
\end{itemize}

The 1-hop neighborhood of a simplex $\sigma_k$ is given by $\mathcal{N}_1(\sigma_k) = \cup \{\sigma_k, \mathcal{N}_{\mathcal{B}}(\sigma_k), \mathcal{N}_{\mathcal{C}}(\sigma_k), \mathcal{N}_{\mathcal{L}}(\sigma_k), \mathcal{N}_{\mathcal{U}}(\sigma_k)\}$. While, the $m$-hop neighborhood of a simplex $\sigma_k$ is defined recursively as $\mathcal{N}_m(\sigma_k) = \cup_{\tau \in \mathcal{N}_{m-1}(\sigma_k)} \mathcal{N}_1(\tau)$ for $m\geq 2$.

The relationships between \(k\)-simplices and their faces are encoded in the boundary matrix of order \(k\), denoted as \(\mathbf{B}_k \in \mathbb{R}^{N_{k-1} \times N_k}\), where \(N_k\) is the number of simplices of order \(k\) \textcolor{black}{contained in $\mathcal{S}$}. The \((i, j)\)-th entry of \(\mathbf{B}_k\) is defined to be equal to 1 if the \(i\)-th \((k-1)\)-simplex is a face of the \(j\)-th \(k\)-simplex and is defined to be zero otherwise. %The entries of the boundary operator are binary: \((i, j) = 1\) if the \(i\)-th \((k-1)\)-simplex is a boundary of the \(j\)-th \(k\)-simplex, and \(0\) otherwise. 
%\textcolor{blue}{Do we use both oriented and unoriented simplicies???? This is not clear from the methods section. But maybe if we only do we one we can say something like, "in this work, we will focus on unoriented simplices, in which case...." rather than having the two definitions  } We denote $\m{B} = \{\m{B}_1, \m{B}_2, \dots, \m{B}_K\}$ as the set of all boundary matrices of the simplicial complex.
We note that these boundary matrices are defined in terms of only boundary adjacent the and co-boundary adjacent neighbors. However, they may also be used to construct the following Laplacian matrices which encode infomartion about lower adjacent and upper adjacent neighbors.
\begin{itemize}[leftmargin=*,left=0pt..1em,topsep=0pt,itemsep=0pt]
\item \textbf{Lower Laplacian:} The lower adjacent neighbors of \(k\)-simplices are represented by \(\m{L}^l_k = \mathbf{B}_k^\top \mathbf{B}_k\). 
\item \textbf{Upper Laplacian:} The upper adjacent neighbors of \(k\)-simplices are represented by \(\m{L}^u_k = \mathbf{B}_{k+1} \mathbf{B}_{k+1}^\top\).
\end{itemize}
%\textcolor{blue}{MP: should separate out the "what they represent" from the definiton. Ie just have the equations in the itemize and then add a sentence explaining in the text.}

These Laplacian matrices, along with the boundary matrices, provide a comprehensive representation of the structure and relationships within a simplicial complex, making them valuable tools for modeling and analyzing complex data.

\subsection{Simplicial Random Walks}
%Simplicial random walks extend the concept of traditional random walks on graphs to higher-order structures, enabling a richer representation of diffusion processes, topology, and connectivity within a simplicial complex. 
Simplicial random walks extend the concept of traditional random walks from graphs to simplicial complexes, enabling a richer representation of the data which is able to encode higher-order features. 
Unlike standard graph-based random walks, which model transitions between nodes (vertices), simplicial random walks capture transitions between $k$-simplices (e.g., points, edges, triangles, tetrahedra), thereby incorporate higher-order interactions.

The diffusion process in simplicial complexes is governed by the $k$-Hodge Laplacian, which encodes both lower and upper adjacency relationships:
%
\begin{equation} 
\Delta_k = \m{L}^l_k + \m{L}^u_k, \label{eq:hodge-laplacian} 
\end{equation}
%
where $\m{L}^l_k$ and $\m{L}^u_k$ represent the lower and upper Laplacians, respectively.
The simplicial random walk is represented by the transition matrix $\mathbf{P}_k$, which describes the probability of transitioning between $k$-simplices within the complex. It is defined as:
%
\begin{equation} 
\mathbf{P}_k = \Delta_k\m{D}_k^{-1}, \label{eq:random-walk} 
\end{equation}
%
where $\m{D}_k =\mathrm{diag}(\Delta_k \m{1})$ is a diagonal matrix that normalizes the transition probabilities, ensuring that $\mathbf{P}_k$ is a valid stochastic matrix, i.e., that its columns sum to one. With the transition matrix $\m{P}_k$, a walker walks from a $k$-simplex $\sigma_k$ to another $k$-simplex $\tau_k$ with probability $\m{P}_{k_{\sigma_k, \tau_k}}$ %\textcolor{blue}{Mike to-do: Add a sentence describing what the "walker" is doing?}

By modeling transitions at the level of simplices rather than just nodes, simplicial random walks provide a more expressive framework for understanding diffusion and connectivity in complex topological spaces.

\subsection{Heat Diffusion on Simplicial Complexes}
The heat equation on simplicial complexes~\cite{heatonSC} generalizes the classical notion of heat diffusion on graphs (or other domains) to higher-dimensional structures. The heat equation on $k$-simplices is then given by:
%
\begin{equation}
\label{eqn:heat_eqn_simplicial_complex}
\frac{\partial u_k(\sigma_k, t)}{\partial t} = -\Delta_k u_k(\sigma_k, t)
\end{equation}
%
where $u_k(\sigma_k, t)$ %\textcolor{blue}{should htere be k's in the sigma and u there?}  Note: added the subscript.
represents the heat at simplex $\sigma_k$ at time $t$. To solve this equation, an initial condition must be specified. %\textcolor{blue}{notational inconsistency between x's and p's. Also, inconsistency on bolding the x's} Note: addressed by redefining each simplex.
For each $k$-simplex $\sigma_k = \{\m{x}_{\sigma_k^0}, \m{x}_{\sigma_k^1}, \dots, \m{x}_{\sigma_k^k}\}$, the initial condition is constructed from the node features of its constituent vertices. Specifically, if $\mathbf{h}_0(\m{x}_{\sigma_k^i})$ denotes the features of vertex
%\textcolor{blue}{So this means that $\mathbf{h}_0(\m{x}_{\sigma_k^i})$ is a row of one of the capital X matrices from earlier, right?. We should clarify this since there are currently two different names for the same thing, which will confuse the reader. (It is okay to have to different names as long as we address this.)} 
$\m{x}_{\sigma_k^i}$, where $\mathbf{h}_0(\cdot)$ is a transformation function, then the initial condition for the simplex $\sigma_k$ is given by: %\textcolor{blue}{Mike todo: Related the h's to the X's from earlier} The h's are functions. Added that. 
%
\begin{equation}
u_k(\sigma_k, 0) = f(\mathbf{h}_0(\m{x}_{\sigma_k^0}), \mathbf{h}_0(\m{x}_{\sigma_k^1},), \dots, \mathbf{h}_0(\m{x}_{\sigma_k^k})),
\end{equation}
%
where $f$ is a function that aggregates the node features of the vertices in $\sigma_k$. %\textcolor{blue}{Again notational inconsistencies with the big X's earlier} Note: \m{X} is matrix. \mathcal{X} is the point cloud. \m{X}_0 and \mathcal{X} are synonymous.
Common choices for $f$ include the mean, sum, or other symmetric functions of the node features. 

The heat equation is widely used to model diffusive phenomena. In this higher-order generalization, it describes how an initial distribution of heat propagates over the simplicial complex over time. The $k$-Laplacian ensures that the diffusion process respects the higher-order connectivity of the complex, encoding both its topological and geometric structure.
\section{Methodology}
\label{sec:method}

In this section, we describe the proposed method {\modelname}, a high-dimensional point cloud neural network designed to learn expressive representations of an input point set $\mathcal{X} = \{\m{x}_1, \m{x}_2, \ldots, \m{x}_n\} \in \mathbb{R}^d$. %\textcolor{blue}{Still inconsistentices between bold x and lower case x}.  Note : Made it bold.
As summarized in Algorithm~\ref{alg:{\modelname}}, our framework comprises three primary steps: 
\begin{enumerate} 
\item \textbf{Learnable Feature Weighting:} We learn a set of weights  $\alpha^{(v)}$ to highlight the most informative dimensions, yielding reweighted point clouds $\tilde{\mathcal{X}}^{(v)}$.     
\item \textbf{Multi-view Learning:} From each $\tilde{\mathcal{X}}^{(v)}$, we construct a higher-order Vietoris-rips complex $\mathcal{S}^{(v)}$~\citep{vr}. This approach allows us to capture not only pairwise relationships but also higher-order interactions within the data, preserving richer topological and \textit{volume} features. This process is repeated $K$ times, generating multiple views of the original point cloud to capture the underlying geometry of the point cloud.

\begin{figure*}[t]
    \centering
    {\includegraphics[width=0.7\textwidth]{figures/HiPoNet_schematic.png}}
    \caption{(A) The {{\modelname}} architecture. (B) Feature importance visualized across three learned views}
    \label{fig:architecture}
\end{figure*}

\item \textbf{Multi-scale Feature Extraction:} For each simplicial complex $\mathcal{S}^{(v)}$, we apply the wavelet transform according to the structure, to produce multi-scale embeddings $\Psi^{(v)}$, capturing both local and global relationships. These embeddings are then concatenated into a single representation $\Phi$, which is passed to a multilayer perceptron (MLP) to yield the final predictions $\hat{\mathbf{y}}$. 
\end{enumerate}
 
By combining learnable feature weighting, multiview simplicial complex construction, and wavelet transforms, {\modelname} leverages multiple perspectives of the underlying manifold to deliver robust, scalable representations for high-dimensional point clouds. 

\begin{algorithm}
\caption{{\modelname}}\label{alg:{\modelname}}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{Point cloud $\mathcal{X}$, kernel bandwidth $\sigma$, number of views $V$.\\
      Leanable Parameters: learnable weights $\alpha^{(v)}$, and \\MLP $\mathbf{z}$.}
\Output{Predictions $\hat{\mathbf{y}}$.}

\For{$v \leftarrow 1 \KwTo V$}{
    $\tilde{\mathbf{x}}_i^{(v)} = \alpha^{(v)} \odot \mathbf{x}_i$ where $\odot$ is Hadamard product, i.e., element-wise multiplication, and $i\in\{1,\dots,n\}$;

    $\tilde{\mathcal{X}}^{(v)} = \{\tilde{\mathbf{x}}_i^{(v)}: i\in\{1,\dots,n\} \}$;

    ${\mathcal{S}}^{(v)} = \text{Vietoris-Rips}(\tilde{\mathcal{X}}^{(v)}, \epsilon)$;
    
    $ \tilde{\m{B}}^{(v)}, \tilde{\m{X}}^{(v)} = \texttt{CalculateBX}({\mathcal{S}}^{(v)})$;
    
    Calculate the multiscale features $\Psi(\tilde{\m{B}}^{(v)}, \tilde{\m{X}}^{(v)})$;
}

{\small $\Phi = \text{Aggr}\{\Psi(\tilde{\m{B}}^{(1)}, \tilde{\m{X}}^{(1)}), \Psi(\tilde{\m{B}}^{(2)}, \tilde{\m{X}}^{(2)}), \dots, \Psi(\tilde{\m{B}}^{(V)}, \tilde{\m{X}}^{(V)})\}$};

$\hat{\mathbf{y}}= \mathbf{z}(\Phi)$\;

\Return{$\hat{\mathbf{y}}$.}
\end{algorithm}


\subsection{Point Cloud Feature learning}
\label{sec:featlearning}

In many real-world scenarios, such as scRNA-seq, feature vectors can encode critical properties, such as gene expression levels. However, not all dimensions (or genes) contribute equally to a downstream task, and irrelevant or noisy features can impair model performance, especially in high-dimensional settings.

To address this, we introduce a learnable weighting mechanism that dynamically adjusts the importance of each feature dimension. Concretely, we define $V$ distinct weight vectors \(\alpha^{(v)}\), \(1 \le v \le V\), each as a parameter of the model. For the $v$-th view, each point \(\mathbf{x}_i\) is rescaled to $$\tilde{\mathbf{x}}_i^{(v)} = \alpha^{(v)} \odot \mathbf{x}_i = \bigl[\alpha^{(v)}_1 x_{i1}, \ \alpha^{(v)}_2 x_{i2}, \dots, \alpha^{(v)}_d x_{id}\bigr], $$ where \(\odot\) denotes the Hadamard (elementwise) product. We stack all reweighed points to create the reweighed point cloud $\tilde{\mathcal{X}}^{(v)} = \{\tilde{\mathbf{x}}_1^{(v)}, \tilde{\mathbf{x}}_2^{(v)}, \ldots, \tilde{\mathbf{x}}_n^{(v)}\}$. The operation of reweighing point clouds amplifies more informative dimensions for the task at hand while downplaying less relevant features, effectively relieving the need for manual feature engineering. In the context of single-cell data, where the feature space can be vast, such automated reweighting is crucial for isolating key gene expressions that drive improved downstream performance. The learned weights can also be used for other biological insights, such as which gene markers are important for cancer diagnosis.

\subsection{Multi-View Learning}
\label{sec:simplicial}
Next, for each reweighed set $\tilde{\mathcal{X}}^{(v)}$, we create a simplicial complex $\mathcal{S}^{(v)}$. We define  kernelized distances between two points $\tilde{\mathbf{x}}^{(v)}_i$ and $\tilde{\mathbf{x}}^{(v)}_j$ as: %\textcolor{blue}{shouldnt this say between two points $\tilde{\mathbf{x}}^{(v)}_p$ and $\tilde{\mathbf{x}}^{(v)}_q$}:
$$d^{(v)}_{i,j} = \exp\left(\frac{\|\tilde{\mathbf{x}}^{(v)}_i-\tilde{\mathbf{x}}^{(v)}_j\|_2^2}{2\sigma^2}\right).$$ 
%We then initialize the simplicial complex \(\mathcal{S}^{(v)}\) with the points in \(\tilde{\mathcal{X}}^{(v)}\) as the 0-simplices (vertices). For a given scale parameter \(\epsilon\), add an edge between any two vertices $\tilde{\mathbf{x}}^{(v)}_i$ and $\tilde{\mathbf{x}}^{(v)}_j$, if $d^{(v)}_{i,j} \leq \epsilon$. To add a $k$-simplex \(\sigma_k = \{\tilde{x}_{i_0}^{(v )}, \tilde{x}_{i_1}^{(v)}, \ldots, \tilde{x}_{i_k}^{(v)}\}\) if every pair of points in \(\sigma_k\) is connected by an edge in the complex. This is equivalent to ensuring that the points in \(\sigma_k\) form a complete graph in the 1-skeleton of the complex. 
We then fix a scale parameter, $\epsilon$ and construct the Vietoris-Rips Complex $\mathcal{S}^{(v)}$, a simplicial complex defined by the rule that \(\sigma_k = \{\tilde{\m{x}}_{i_0}^{(v)}, \tilde{\m{x}}_{i_1}^{(v)}, \ldots, \tilde{\m{x}}_{i_{k}}^{(v)}\}\) is an element of $\mathcal{S}^{(v)}$ if $d_{i_p,i_q}^{(v)}\leq \epsilon$ for all $1\leq p,q\leq k$.
The kernelized distance metric is important as it emphasizes local similarities making it more robust to noise. After constructing the simpicial complex $\mathcal{S}^{(v)}$, we construct the boundary operators $\tilde{\mathbf{B}}^{(v)}$ and feature matrices $\tilde{\mathbf{X}}^{(v)}$. We use a custom implementation of the Vietoris-rips filtration that enables us to make simplicial construction differenitable, making {\modelname} end-to-end trainable.

% \todo[inline]{Add why gaussian is important or better than euclidean.}

We repeat this process $V$ times, and construct $\tilde{{\m{B}}}^{(v)}$ for each view $1\leq v\leq V$. By constructing an ensemble of simplicial complexes $\mathcal{S}^{(1)}, \mathcal{S}^{(2)}, \dots, \mathcal{S}^{(V)}$, our method integrates $V$ distinct perspectives of the original high-dimensional point cloud. Constructing a simplicial complex \(\mathcal{S}^{(v)}\) for each reweighted set \(\tilde{\mathcal{X}}^{(v)}\) allows the model to disentangle and analyze distinct subspaces or biological processes captured by each view. Each complex focuses on a different cellular process, capturing unique local and global structures that is overlooked when relying on a single representation. Consequently, subsequent learning stages benefit from a richer set of structural cues, enhancing the overall representation quality for downstream tasks. 

\subsection{Multi-scale feature extraction}

After the simplicial complexes have been constructed, we can leverage geometric deep learning methods to compute representations for the point cloud. Although message passing neural networks (MPNNs) for simplicial complexes~\cite{generalizedsann, mpsn, SAT} have been introduced, they often suffer from oversmoothing effects~\cite{balcilar2021analyzing}, where representations become indistinguishable after multiple layers. In addition, oversquashing~\cite{alon2021on} is another constraint of such message-passing frameworks. As the receptive field of each node grows, large amounts of information from distant nodes are compressed or ``squashed" into a fixed-size vector, leading to loss of important information between the nodes. This limits the ability of MPNNs to model long-range dependencies. Furthermore, MPNNs require large amounts of data to train and calculate expressive representations~\cite{simplicial-scattering}, which hinders their ability to learn expressive representations for the data. These limitations lead to suboptimal performance, as capturing the long-term information is crucial to understanding the topology of the data, enhancing representation quality, and improving downstream task performance.

In order to address these shortcomings, we employ the {simplicial wavelet transform}~\cite{simplicial-scattering} (SWT). The SWT $\Psi(\Delta, {\m{X}})$ is a multi-scale feature extractor for processing a signal $\mathbf{X}$ defined on the simplices represented by $\m{B}$. These wavelets are based on diffusion wavelets introduced in \cite{coifman_diffusion_2006-1} which utilize random walk matrices at different time scales. In SWT, the random walk matrices are calculated first as per Eq~\ref{eq:random-walk}. Then, features are iteratively aggregated over all the neighborhoods and stored for each scale $j$. Finally, a difference between different scales is taken to extract multiscale features. These steps are described in detail below.

\paragraph{Diffusion:} In the simplicial wavelet transform (SWT), diffusion plays a crucial role in capturing multi-scale structural information within a simplicial complex. The diffusion process governs how information propagates across simplices of different orders over time. For view $v$, diffusion is guided by the random walk matrix $\m{P}^{(v)}_k$ calculated using the $k$-Hodge Laplacian $\Delta^{(v)}_k$ as per Eq~\ref{eq:random-walk}, which encodes both lower and upper adjacencies of simplices, ensuring that diffusion respects the higher-order topology of the complex. The signals are propagated using powers of the diffusion operator as $\m{X}_k^{(v)^{(j)}} = \m{P}_k^{(v)^j} \m{X}^{(v)}_k$
where $\m{X}^{(v)}_k$ represents the initial feature matrix of $k$-simplices, and $\m{X}_k^{(v)^{(j)}}$ captures the transformed features after $j$ iterations of diffusion.

\begin{definition}[Simplicial Wavelet Transform] The simplicial wavelet transform at scale $j$ is defined as the difference between transformed signals at consecutive scales: \begin{equation} \Psi_k^{(v)^{(j)}} = \m{X}_k^{(v)^{(j)}} - \m{X}_k^{(v)^{(j-1)}}, \end{equation} where $\m{X}_k^{(j)}$ is the feature representation at scale $j$. This difference operator acts as a high-pass filter, highlighting high-frequency components of the signal, which correspond to variations in the structure of the simplicial complex.
\end{definition} 

After applying SWT for multiple scales $j$ and all orders $k$, we apply a non-linearity, which we choose to be the absolute value $|\cdot|$, inspired from~\citet{mallat-scattering}. The features are then aggregated over all the scales as: %\textcolor{blue}{MP: Need a couple of words explaing where the absolute values come from e.g., "After applying the SWT..., we apply a nonlinearity, which, inspired by CITATION is chosen to be $|\cdot|$, and then...} Note: Addressed.
%
\[
\Psi_k^{(v)} = \bigcup_{i=1}^J \{|\Psi_k^{(v)^{(1)}}|,|\Psi_k^{(v)^{(2)}}|, \dots, |\Psi_k^{(v)^{(J)}}|\};
\]
%
The final feature set of is denoted as:
%
\[
\Psi(\tilde{\Delta}^{(v)}, \tilde{\m{X}}^{(v)}) = \{\Psi_0^{(v)},\Psi_1^{(v)}, \dots, \Psi_K^{(v)}\};
\]
%
After extracting features for each view $v$, we aggregate the features over views as:
{\small
\begin{equation*}
\Phi = \text{Aggr}\{\Psi(\tilde{\m{B}}^{(1)}, \tilde{\m{X}}^{(1)}), \Psi(\tilde{\m{B}}^{(2)}, \tilde{\m{X}}^{(2)}), \dots, \Psi(\tilde{\m{B}}^{(V)}, \tilde{\m{X}}^{(V)})\}.
\end{equation*}}

\begin{comment}
\textbf{Message Propagation.} Unlike graph wavelet transform~\citep{gaoscattering} where the diffusion operator is a square matrix, \textcolor{blue}{This sentence comes out of nowhere and will confuse people who arent familiar with diffusion wavelets. Also, the correct citation is coifman and maggioni if we are just talking about wavelets and not scattering} the random walk matrices in simplicial complexes can not be powered to generate different scales. Hence, SWT employs a message passing step first, and then takes the difference between difference between different scales. The information from boundary, coboundary, lower, and upper adjacent neighbors, respectively is propagated as follows: 

\begin{align}
    &\m{X}_{\mathcal{B},k}^{(j)} = \m{P}^{\cal{B}}_{k}\m{X}_{k-1}^{(j-1)}, \quad\,\,\, \notag 
    \m{X}_{\mathcal{C},k}^{(j)} = \m{P}^{\cal{C}}_{k+1}\m{X}_{k+1}^{(j-1)}, \notag \\
    &\m{X}_{\mathcal{L},k}^{(j)} = \m{P}_k^{\cal{L}}\m{X}_{k}^{(j-1)}, \quad\,\,\,  
    \m{X}_{\mathcal{U},k}^{(j)} = \m{P}_k^{\cal{U}}\m{X}_{k}^{(j-1)}.
    \label{eq:rondomwalkbasedtransforms}
\end{align}
Then, the message passing updates simplex features as follows:

{\scriptsize
\begin{equation*}    
\m{X}_k^{(j)^{(v)}} = \texttt{AGGREGATE}(\m{P}_k^{{S}} \m{X}_k^{(j-1)^{(v)}}, \m{X}_{\mathcal{B},k}^{(j)^{(v)}}, \m{X}_{\mathcal{C},k}^{(j)^{(v)}}, \m{X}_{\mathcal{L},k}^{(j)^{(v)}}, \m{X}_{\mathcal{U},k}^{(j)^{(v)}}).
\end{equation*}
}
\textcolor{blue}{If i am reading this correctly, we first do wavelets then aggregate, so maybe we should present in that order to avoid confusion}
\textbf{Simplicial Wavelet Transform.} :
\[
\psi_j^{k,\mathcal{B}} \m{X} = \m{X}_{\mathcal{B},k}^{(j-1)} - \m{X}_{\mathcal{B},k}^{(j)}, \quad
\psi_j^{k,\mathcal{C}} \m{X} = \m{X}_{\mathcal{C},k}^{(j-1)} - \m{X}_{\mathcal{C},k}^{(j)},
\]
\[
\psi_j^{k,\mathcal{L}} \m{X} = \m{X}_{\mathcal{L},k}^{(j-1)} - \m{X}_{\mathcal{L},k}^{(j)}, \quad
\psi_j^{k,\mathcal{U}} \m{X} = \m{X}_{\mathcal{U},k}^{(j-1)} - \m{X}_{\mathcal{U},k}^{(j)}.
\]

Finally, the features at scale \(j\) are aggregated as:

{\scriptsize
\begin{equation*}
| \Psi^k_j \m{X}| = \vert \texttt{AGGREGATE}(\m{P}_k^{{S}} \m{X}_k^{(j-1)}, \psi_j^{k,\mathcal{B}} \m{X}, \psi_j^{k,\mathcal{C}} \m{X}, \psi_j^{k,\mathcal{L}} \m{X}, \psi_j^{k,\mathcal{U}} \m{X}) |
\end{equation*}}

These features are then aggregated over all the scales as:
\[
\Psi_k^{(v)} = \bigcup_{i=1}^J \{|\Psi^k_1 \m{X}|,|\Psi^k_2 \m{X}|, \dots, |\Psi^k_J \m{X}|\};
\]

The final feature set of is denoted as:
\[
\Psi(\tilde{\m{B}}^{(v)}, \tilde{\m{X}}^{(v)}) = \{\Psi_0^{(v)},\Psi_1^{(v)}, \dots, \Psi_K^{(v)}\};
\]

After extracting features for each view $v$, we aggregate the features over views as:
{\small
\begin{equation*}
\Phi = \text{Aggr}\{\Psi(\tilde{\m{B}}^{(1)}, \tilde{\m{X}}^{(1)}), \Psi(\tilde{\m{B}}^{(2)}, \tilde{\m{X}}^{(2)}), \dots, \Psi(\tilde{\m{B}}^{(V)}, \tilde{\m{X}}^{(V)})\}.
\end{equation*}}
\end{comment}

\subsection{Training}
\label{sec:training}
Once the multiscale features \(\Phi\) are extracted from the set of graphs, we process these features through a multilayer perceptron (MLP) $\mathbf{z}$ to generate predictions for the target downstream task. Formally, the predictions are computed as: $$\hat{\mathbf{y}} = \mathbf{z}(\Phi),$$

where $\Phi$ represents the concatenated multi-scale embeddings derived from the graph wavelet transforms, and $\hat{\mathbf{y}}$ denotes the predicted labels or outputs depending on the task (e.g., classification, regression, etc.).

To optimize the model parameters, we employ the cross-entropy loss function, 
%\textcolor{red}{[in the code, it looks like the loss also has a squared penalty on the size of the alphas and number of weights]} 
which is particularly effective for classification tasks. This setup ensures that the extracted multi-scale features are effectively utilized, improving the overall performance on downstream tasks.

\section{Theoretical results}

In this section, provide theoretical motivation for our model. Specifically, we first show that heat diffusion on simplices captures the 0-homology of the point cloud. Then, we show that simplicial complexes can be expanded into a graph, and the heat equation on the simplicial complex agrees with the heat equation on the equivalent graph. Then, we show that the diffusion operators can capture geodesic distances. %Finally, we show that the scaler curvature can be computed using the diffusion operator.

\subsection{Heat Diffusion and Connectivity}

A simplicial complex is said to be connected if any two simplices can be linked by a sequence of simplices that share common faces. More formally, for any two simplices $\sigma$ and $\tau$, there exists $m\geq 0$ such that $\tau \in \mathcal{N}_m(\sigma)$.
%\textcolor{blue}{Do we require sigma and tau to have the same size? (Genuinely unsure)}. Note: No. They can be of different sizes. 
If a simplicial complex is not connected, it can be decomposed into a union of disjoint connected components, each of which is a maximal connected subcomplex.

The following theorem demonstrates that the solution to the heat equation on a simplicial complex remains confined to the connected components where the initial condition is supported. This reflects the intuitive idea that heat cannot diffuse across disconnected regions of the complex. This proposition also aligns with the concept of $0$-homology in algebraic topology. Thus, the connected components of a simplicial complex correspond to the generators of its $0$-homology group. The heat equation's confinement to connected components ensures that diffusion dynamics respect the $0$-homology structure of the simplicial complex.


\begin{theorem}
\label{prop:connected_components_simplicial}
The heat equation,  Eq~\ref{eqn:heat_eqn_simplicial_complex}, respect the $0$-homology structure of the simplicial complex.
\end{theorem}

The proof of Theorem~\ref{prop:connected_components_simplicial} is available in Appendix~\ref{sec:connected_components_simplicial}. The heat equation on a simplicial complex is governed by the Hodge-Laplacian $\Delta_k$, which acts locally by coupling only simplices are neighbors. If the initial condition is confined to a subset of simplices, the locality of $\Delta_k$ ensures that heat diffusion cannot propagate beyond the connected components containing this subset. Consequently, the solution to the heat equation respects the $0$-homology structure of the simplicial complex, preserving the disjointness of connected components. 

\subsection{Heat Diffusion on Simplicial Graphs}

In this section, we demonstrate that the solution to the heat equation on a simplicial complex $\mathcal{S}$ agrees with the solution to the heat equation on an associated simplicial graph $\mathcal{G}(\mathcal{S})$. The simplicial graph is a higher-dimensional generalization of a graph, where vertices represent simplices of all orders, and edges encode adjacency and boundary relationships. This construction allows us to compare heat diffusion on the simplicial complex with heat diffusion on a graph-like structure, providing a simplified yet equivalent framework for analysis. Additionally, single-cell datasets lie on an underlying Riemannian manifold. 

\begin{definition}[Simplicial Graph]
\label{def:simplicial_graph}
Let $\mathcal{S}$ be a simplicial complex of order $K$, and let $\Sigma_k$ denote the set of $k$-simplices in $\mathcal{S}$ for $k = 0, 1, \dots, K$. The simplicial graph $\mathcal{G}(\mathcal{S})$ associated with $\mathcal{S}$ is a graph defined as follows:
\begin{enumerate}[leftmargin=*,left=0pt..1em,topsep=0pt,itemsep=0pt]
\item The vertex set $V(\mathcal{G})$ is the union of all simplices in $\mathcal{S}$: $V(\mathcal{G}) = \bigcup_{k=0}^K \Sigma_k$
\item The edge set $E(\mathcal{G})$ consists of pairs of simplices that are adjacent or share a boundary relationship:
$E(\mathcal{G}) = \big\{ \{\sigma, \sigma'\} \mid \sigma, \sigma' \in V(\mathcal{G}), \, \sigma' \in \mathcal{N}_1(\sigma),\sigma \neq \sigma' \big\}$
\end{enumerate}
\end{definition}

\begin{proposition}
\label{prop:heat_equation_agreement}
The heat equation on simplicial complex $\mathcal{S}$ agrees with the heat equation on the associated simplicial graph $\mathcal{G}(\mathcal{S})$.
\end{proposition}

The proof of Proposition~\ref{prop:heat_equation_agreement} is available in Appendix~\ref{sec:heat_equation_agreement}. The diffusion operator $\Delta_{\mathcal{G}}$ on the simplicial graph can be represented by placing the Hodge Laplacians in a block diagonal fashion. Similarly, heat value vectors for each order can be stacked to create a single vector. By doing so, the heat equation on the simplicial graph $\frac{\partial u_{\mathcal{G}}(\cdot, t)}{\partial t}$ can be represented by a combination of heat equations on the $k$-simplices $\frac{\partial u_k(\cdot, t)}{\partial t}$ for all $k\in\{0,\dots, K\}$. %The proof of Proposition~\ref{prop:heat_equation_agreement} is available in Section~\ref{proof:heat_equation_agreement}.

\subsection{Heat Solution Captures Geometry}
In this section, we establish that the diffusion operator on the simplicial complex can approximate geodesic distances and other geometric quantities on the underlying manifold. This result demonstrates a theoretical link between diffusion processes and the geometry of the data manifold. Of course there are many representations of the data as a manifold, and implicit in the following is the application of the manifold assumption to the simplicial graph $\mathcal{G}(\mathcal{S})$ representation of the data. 


\begin{theorem}~\label{thm:geodesicdist}
Assume that a transformed point cloud $\tilde{\mathcal{X}}^{(v)}$ lies upon a Riemannian manifold $\mathcal{M}$.    Then, the diffusion operators $\Delta_k$ on the associated simplicial complexes can approximate geodesic distances on the underlying manifold.
    %\textcolor{blue}{Don't we need to specify $K=1$ and that the data point lie on a \emph{Riemannian} manifold. (If needed we can have informal in body and formal in appendix)} 
    %\textcolor{pink}{Note: Added a sentence about riemannian assumption in the 2nd para after the statement.}
\end{theorem}
Given the equivalence between the heat kernel on $\mathcal{S}$ and $\mathcal{G}(\mathcal{S})$, and the discrete nature of $\mathcal{G}$, we can define a heat kernel on the simplicial graph. Then, the result follows directly from Varadhan's formula~\citep{varadhan}, which states that for any closed Riemannian manifold $(M, g)$, the geodesic distance $d(x, y)$ can be approximated using the heat kernel $H_t(\sigma, \tau)$~\cite{heat-geo}.

The proof of Theorem~\ref{thm:geodesicdist} is available in Appendix~\ref{sec:geodesicdist}. This theorem formalizes the link between diffusion processes, as captured by the heat equation, and the geometric structure of the data manifold. This connection allows us to extract meaningful geometric information from the heat kernel. Furthermore, computation of geodesic distances on manifolds is computationally expensive and often infeasible in high dimensions. By using diffusion-based approximations, we can efficiently estimate geodesic distances with discrete operators on simplicial graphs. Furthermore, the equivalence between diffusion and geodesic distances provides a theoretical basis for manifold learning methods, enabling tasks such as dimensionality reduction, clustering, and visualization on high-dimensional data. %The proof of Theorem~\ref{thm:geodesicdist} is available in Section~\ref{proof:geodesicdist}.

There is a long literature (starting with \cite{coifman_diffusion_2006-1}) relating the Laplacian and the diffusion operator to the geometry of the data manifold. There is subsequent work that measures the curvature of the data manifold via the diffusion operator~\cite{diff-curvature}. More relevant to the exposition in this section are the results which relate the asymptotic expansion of the trace of the heat kernel to geometric quantities like dimension, volume, and total scalar curvature (see for instance~\cite{gordon-diff-geometry}). Indeed, following immediately from Proposition~\ref{prop:heat_equation_agreement} we have:

\begin{corollary}
    The equivalence between the heat kernel on $\mathcal{S}$ and $\mathcal{G}(\mathcal{S})$ implies the equivalence of dimension, volume, and total scalar curvature on the respective underlying data manifolds. 
\end{corollary}
\begin{proof}
The eigenvalues $\lambda_i$ and corresponding eigenfunctions $\phi_i$ of the Laplace-Beltrami operator determine the heat kernel via the spectral expansion:
$$K(t, x, y) = \sum_{i=0}^\infty e^{-\lambda_i t} \phi_i(x) \phi_i(y)$$
The eigenvalues are influenced by the volume and curvature of the manifold via Weyl's law~\cite{weyl} and the eigenvalue comparison theorems~\cite{cheng}.
\end{proof}

%{\color{red} \textbf{[PROOF?]}}
\section{Empirical Results}\label{sec:results}
\label{sec:exp}
We compare the performance of {\modelname} with KNN-GNNs as well as PointNet++ and it's variants described in Section~\ref{sec:baselines}. The KNN-based graph neural networks (GCN~\cite{gcn}, SAGE~\cite{sage}, GAT~\cite{gat}, GIN~\cite{gin} and Graph Transformer~\cite{graph-transformers}) are presented in the first block, followed by point cloud oriented models (DGCNN~\cite{dgcnn}, PointNet++~\cite{pointnet++}, PointTransformer~\cite{pointtransformer}), and finally the proposed {{\modelname}}. A bolded score indicates the highest overall performance, whereas an underlined value identifies the second-best performance. We present the mean and standard deviation over 5 seeds\footnote{The code is available at \url{https://github.com/KrishnaswamyLab/PointCloudNet}.}. The hyperparameters are described in Section~\ref{sec:experimental_setup}.

\subsection{Topology and Geometry Prediction}
We evaluate {\modelname} on the task of predicting persistence features of the point clouds, which provides a topological summary of the dataset. The ground truth for persistence diagram prediction were created on the datasets described in Appendix~\ref{sec:data}. The purpose of this task is to show that {\modelname}'s representation contains this information, but downstream tasks may use more information than just the topological signature or curvature. 

The results in Table~\ref{tab:persisfeatpred} indicate that {\modelname} consistently outperforms all baseline methods, achieving the lowest MSE across all datasets. Notably, KNN-based models perform competitively, with KNN-SAGE and KNN-GIN showing relatively lower errors compared to other GNN-based approaches. However, point-cloud-based models (DGCNN, PointNet++, and PointTransformer) exhibit significantly higher error values, suggesting that they struggle to capture the necessary topological features for persistence feature prediction. Overall, the superior performance of {\modelname} demonstrates its ability to effectively learn and predict topological structures from high-dimensional point clouds, making it a robust choice for persistence feature analysis in biological datasets. 
\begin{table}[t]
    \centering
    \scalebox{0.55}{\begin{tabular}{ccc}
    \toprule
     \textbf{Model} & \textbf{Melanoma} & \textbf{PDO} \\
    \midrule
    KNN-GCN  & 72.72 $\pm$ 5.45 & 53.66 $\pm$ 0.70 \\
    KNN-SAGE  & 76.36 $\pm$ 6.03 & 55.89 $\pm$ 0.83  \\
    KNN-GAT  & 61.81 $\pm$ 4.45 & 52.56 $\pm$ 10.06 \\
    KNN-GIN  & \underline{85.45 $\pm$ 3.63} & \underline{57.02 $\pm$ 1.20}\\
    KNN-GraphTransformer  & 80.00 $\pm$ 8.90  & 39.46 $\pm$ 2.78 \\
    \hline
    DGCNN & 63.33 $\pm$ 12.47 & 40.00 $\pm$ 4.36\\ 
    PointNet++ & 45.00 $\pm$ 22.42 & 45.24 $\pm$ 2.08\\ 
    PointTransformer & 79.99 $\pm$ 6.24 & 30.00 $\pm$ 4.70 \\ 
    \hline
    {{\modelname}} & \textbf{90.90 $\pm$ 4.92} & \textbf{63.10 $\pm$ 0.0} \\
    \bottomrule
    \end{tabular}}
    \caption{Accuracies on classification tasks.}
    \label{tab:classification}
\end{table}

\subsection{Single Cell data classification}\label{sec:tasks}
Next we assess the performance of {\modelname} on single-cell data cohorts which we have curated (as shown in Table \ref{tab:dataset_comparison_transposed}).  Detailed descriptions of the biological data is described in the Appendix~\ref{sec:data}. However, each data cohort is a measurement of thousands cells on a large cohort of patients and the label is prediction of outcome (of disease or treatment). 

{\tiny
\begin{table}[h]
\centering
\scalebox{0.42}{
\begin{tabular}{lccccc}
\toprule
\textbf{Data cohort} & \textbf{Avg. Points/Dataset} & \textbf{Total \# Datasets} & \textbf{Task} & \textbf{Data Modality} \\
\midrule
  Melanoma patient samples 
  & 1137
  & 54
  & Response to Immunotherapy
  & MIBI\\
  Patient-derived organoids (PDOs)
  & 3273
  & 1625
  & Treatment Administered 
  & Mass Cytometry\\
  \midrule
  \multirow{2}{*}{Charville}
  & 1000
  & 196
  & Outcome to chemotherapy
  & \multirow{5}{*}{CODEX}\\
  
  & 1000
  & 196
  & Cancer recurrence \\
  \multirow{2}{*}{UPMC}
  & 1000
  & 308
  & Outcome to chemotherapy
  & \\
  
  & 1000
  & 308
  & Cancer recurrence
  & \\
  DFCI
  & 1000
  & 54
  & Outcome to chemotherapy
  & \\
  \bottomrule
\end{tabular}
}%Add space-gm data
\caption{Information about single-cell data}
\label{tab:dataset_comparison_transposed}
\end{table}
}

For classification task, as we can see in Table~\ref{tab:classification}, {{\modelname}} consistently achieves the top results on all four datasets, demonstrating a robust ability to handle high-dimensional inputs such as single-cell data. KNN-GIN generally fares best among the KNN-based models but experiences a notable accuracy gap compared to some point cloud methods on Melanoma. Meanwhile, PointNet++ and PointTransformer perform relatively inconsistently across different tasks. 

\begin{table}[t]
    \centering
    \scalebox{0.6}{\begin{tabular}{c|c|c}
    \hline
    \textbf{Model} & \textbf{Melanoma} & \textbf{PDO} \\
    \hline
    KNN-GCN & 1.0683 $\pm$ 0.002 & 1.0454 $\pm$ 0.018 \\
    KNN-SAGE & \underline{0.734 $\pm$ 0.031} & 1.0338 $\pm$ 0.010 \\
    KNN-GAT & 1.101 $\pm$ 0.028 & \underline{1.068 $\pm$ 0.008} \\
    KNN-GIN & 0.850 $\pm$ 0.061 & 1.2605 $\pm$ 0.006 \\
    KNN-GraphTransformer & 1.274 $\pm$ 0.038 & 1.3754 $\pm$ 0.006 \\
    \hline
    DGCNN & 28.412 $\pm$ 0.001 & 1353.0262 $\pm$ 1.12 \\ 
    PointNet++ & 28.418 $\pm$ 0.001 & 28.417 $\pm$ 0.005 \\ 
    PointTransformer & 28.422 $\pm$ 0.014 & 28.41 $\pm$ 0.003 \\ 
    \hline
    {{\modelname}} &  \textbf{0.633 $\pm$ 0.043} & \textbf{0.4046 $\pm$ 0.006} \\
    \hline
    \end{tabular}}
    \caption{MSE on prediction of persistence features.}
    \label{tab:persisfeatpred}
\end{table}

In Table~\ref{tab:viewablation}, we present an ablation study examining how the number of views used in {{\modelname}}. While adding more views can yield better performance by capturing increasingly rich multi-view information, it results in diminishing returns after a point. In Table \ref{tab:viewablation} (see Appendix) we conduct an ablation study on the number of views, and see that our best results are archieved when we use four views to capture the topology of the point clouds. %This underscores that a moderate number of graphs (e.g., four) strikes a practical balance between enhanced accuracy and computational feasibility for high-dimensional point cloud tasks.

\subsection{Application to spatial transcriptomics data}\label{sec:st}

In addition to the experiments on single-cell data, we further demonstrate an application of {\modelname} in analyzing spatial transcriptomics data. Unlike previous experiments where multiple learned views were used, here we construct two distinct views: one capturing spatial proximity of cells and the other encoding gene expression similarity. Table~\ref{tab:st_res} compares the predictive performance of various models on spatial transcriptomics data drawn from three different cohorts: DFCI, Charville, and UPMC. Each cohort includes two tasks—either outcome prediction or recurrence prediction—resulting in five total evaluations. Notably, HiPoNet achieves the top results in most settings, outperforming both KNN-based graph neural networks (GCN, SAGE, GAT, GIN) and PointNet++.

\begin{table}[t]
    \centering
    \scalebox{0.5}{\begin{tabular}{c|c|c|c|c|c}
    \hline
    \textbf{Data} & DFCI & \multicolumn{2}{c|}{Charville} & \multicolumn{2}{c}{UPMC}\\
    \hline
    \textbf{Task} & Outcome & Outcome & Recurrence & Outcome & Recurrence\\
    \hline
    KNN-GCN & 0.597 $\pm$ 0.049 & 0.547 $\pm$ 0.010 & \underline{0.642 $\pm$ 0.056} & \textbf{0.668 $\pm$ 0.032} & 0.5 $\pm$ 0.0 \\
    KNN-SAGE & \underline{0.82 $\pm$ 0.040} & 0.618 $\pm$ 0.021 & 0.581 $\pm$ 0.016 & 0.631 $\pm$ 0.013 & 0.5 $\pm$ 0.0 \\
    KNN-GAT & 0.557 $\pm$ 0.047 & \underline{0.675 $\pm$ 0.051} & 0.530 $\pm$ 0.032 & 0.647 $\pm$ 0.029 & 0.5 $\pm$ 0.0 \\
    KNN-GIN & 0.700 $\pm$ 0.048 & 0.609 $\pm$ 0.020 & 0.624 $\pm$ 0.045 & 0.663 $\pm$ 0.015 & \underline{0.514 $\pm$ 0.02} \\
    KNN-GraphTransformer & 0.668 $\pm$ 0.051 & 0.578 $\pm$ 0.040 & 0.5 $\pm$ 0.0 & 0.6290 $\pm$ 0.008 & 0.5 $\pm$ 0. \\
    PointNet++ & 0.491 $\pm$ 0.057 & 0.451 $\pm$ 0.078 & 0.499 $\pm$ 0.001 & 0.506 $\pm$ 0.01 & 0.495 $\pm$ 0.00 \\ 
    \hline
    HiPoNet & \textbf{0.916 $\pm$ 0.03} & \textbf{0.681 $\pm$ 0.012} & \textbf{0.681 $\pm$ 0.01} & \underline{0.665 $\pm$ 0.01} & \textbf{0.6044 $\pm$ 0.0} \\
    \hline
    \end{tabular}}
    \caption{AUC ROC on Spatial Transcriptomics Classification}
    \label{tab:st_res}
\end{table}

\section{Conclusion}
In this work, we introduce a novel neural network for high-dimensional point cloud datasets by leveraging multiple-views, higher-order constructs, and multi-scale wavelet transforms. We show that {\modelname} learns different views from each dataset, preserves geometric and topological structures,  and improves downstream analysis across diverse single-cell and spatial transcriptomics data cohorts by overcoming the limitations of state-of-the-art point cloud and graph-based models. 

\section*{Acknowledgments}

D.B. received funding from the Yale - Boehringer Ingelheim Biomedical Data Science Fellowship and the Kavli Institute for Neuroscience Postdoctoral Fellowship. M.P. acknowledges funding from The National Science Foundation under grant number OIA-2242769. S.K. is funded in part by the NIH (NIGMSR01GM135929, R01GM130847),  NSF CAREER award IIS- 2047856, NSF DMS grant 2327211 and NSF CISE grant 2403317. S.K. and M.P. also acknowledge funding from NSF-DMS Grant No. 2327211.

\section*{Impact Statement}

This work aims to accelerate cancer research, immunotherapy development, and precision medicine by providing a scalable, biologically informed, and robust neural network for high-dimensional point clouds.
% Authors are \textbf{required} to include a statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered 
% section at the end of the paper (co-located with Acknowledgements -- 
% the two may appear in either order, but both must be before References), 
% and does not count toward the paper page limit. In many cases, where 
% the ethical impacts and expected societal implications are those that 
% are well established when advancing the field of Machine Learning, 
% substantial discussion is not required, and a simple statement such 
% as the following will suffice:

% ``This paper presents work whose goal is to advance the field of 
% Machine Learning. There are many potential societal consequences 
% of our work, none which we feel must be specifically highlighted here.''

% The above statement can be used verbatim in such cases, but we 
% encourage authors to think about whether there is content which does 
% warrant further discussion, as this statement will be apparent if the 
% paper is later flagged for ethics review.
\begin{comment}

\newpage
\section*{Accessibility}
Authors are kindly asked to make their submissions as accessible as possible for everyone including people with disabilities and sensory or neurological differences.
Tips of how to achieve this and what to pay attention to will be provided on the conference website \url{http://icml.cc/}.

\section*{Software and Data}

If a paper is accepted, we strongly encourage the publication of software and data with the
camera-ready version of the paper whenever appropriate. This can be
done by including a URL in the camera-ready copy. However, \textbf{do not}
include URLs that reveal your institution or identity in your
submission for review. Instead, provide an anonymous URL or upload
the material as ``Supplementary Material'' into the OpenReview reviewing
system. Note that reviewers are not required to look at this material
when writing their review.

% Acknowledgements should only appear in the accepted version.
\section*{Acknowledgements}

\textbf{Do not} include acknowledgements in the initial version of
the paper submitted for blind review.

If a paper is accepted, the final camera-ready version can (and
usually should) include acknowledgements.  Such acknowledgements
should be placed at the end of the section, in an unnumbered section
that does not count towards the paper page limit. Typically, this will 
include thanks to reviewers who gave useful comments, to colleagues 
who contributed to the ideas, and to funding agencies and corporate 
sponsors that provided financial support.
\end{comment}




% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Related Works}\label{sec:related}
The vast majority of work on point cloud-based learning has focused on three dimensional problems, such as mapping and interpreting sensor readings in computer vision or localization tasks ~\cite{pointnet, pointnet++, pointtransformer, pointmlp, dgcnn}. Early methods such as PointNet~\cite{pointnet} and its successor PointNet++~\cite{pointnet++} introduced permutation-invariant models with the ability to extract local and global features from 3D point clouds. Newer methods such as Dynamic Graph Convolutional Neural Network (DGCNN)~\cite{dgcnn} leverage dynamic graph representations to better extract rich features from input point clouds, while PointMLP~\cite{pointmlp} and Point Transformer~\cite{pointtransformer} use standard Multilayer Perceptrons and local self-attention mechanism as the building blocks for better performance in classification and regression tasks. Previous methods provide motivation for our line of inquiry, but since the biological domains in which we are interested frequently have orders of magnitude more dimensions ranging from dozens in proteomics datasets to thousands in transcriptomic datasets, we require a new approach that is not limited by architectural decisions and is computationally efficient when working with high-dimensional data. Despite the advancements in these existing methods, they are fundamentally designed for 3D point clouds and struggle with performance and scalability in a high dimensional setting as they rely on spatial heuristics, because local neighborhoods become less meaningful in high-dimension. As opposed to this, {\modelname} is able to scale to high-dimensional data while also preserving the geometry of the dataset.

Single-cell analysis has greatly benefited from graph-based methods that learns global structure from high-dimensional data. These methods typically rely on a \emph{single} graph construct to infer relationships between cellular states. Methods such as UMAP~\cite{mcinnes2020umapuniformmanifoldapproximation} and t-SNE~\cite{JMLR:v9:vandermaaten08a} perform non-linear dimensionality reduction by constructing a neighborhood graph and embedding cells into a low-dimensional space. On the other hand, PHATE~\cite{moon2019visualizing} is a dimensionality reduction method that captures both global and local nonlinear structure but only constructs a \emph{single} graph from the data. While these methods have been useful in understanding various biological processes, they may fail to organize cells based on processes governed by subsets of dimensions with just a single connectivity structure. In contrast to this, {\modelname} has the ability to model distinct cellular processes by leveraging its multi-view framework, preserving important geometric properties.

\section{Proof of Theorem~\ref{prop:connected_components_simplicial}}~\label{sec:connected_components_simplicial}
\begin{proposition}[Connected Components on Simplicial Complexes]
\label{proof:connected_components_simplicial}
Let $\mathcal{S}$ be a simplicial complex of order $K$ with $m$ connected components, and let $\Sigma_k$ the set of $k$-simplices ($k \leq K$). We partition $\Sigma_k = \Sigma_{k,1} \sqcup \Sigma_{k,2} \sqcup \ldots \sqcup \Sigma_{k,m}$, where each $\Sigma_{k,i}$ corresponds to the $k$-simplices in a single connected component. Let $S$ be a subset of $n$-simplices, defined as the union of several connected components: $S = \Sigma_{n,i_1} \sqcup \ldots \sqcup \Sigma_{n,i_k}$. Assume the initial condition $\mathbf{x} = u(\cdot, 0)$ of the diffusion equation has support contained in $S$. Then, for any simplex $\sigma \notin S$ of order $k$ and for all $t > 0$, we have:
\begin{equation}
u_k(\sigma, t) = 0.
\end{equation}
\end{proposition}

\begin{proof}
The Hodge-Laplacian $\Delta_k$ acts locally, meaning it only couples simplices that share common faces. As a result, if the initial condition $u(\cdot, 0)$ has support contained in $S$, the solution $u(\sigma, t)$ must remain confined to $S$ for all $t > 0$. To formalize this, define a function $\tilde{u}(\sigma, t)$ as follows:
%
\begin{equation*}
\tilde{u}_k(\sigma, t) = 
\begin{cases}
u_k(\sigma, t), & \text{if } \sigma \in S, \\
0, & \text{if } \sigma \notin S.
\end{cases}
\end{equation*}

We will show that $\tilde{u}_k(\sigma, t)$ satisfies the same heat equation as $u(\sigma, t)$.

First, consider a simplex $\sigma \in S$. By definition, $\tilde{u}_k(\sigma, t) = u(\sigma, t)$, and since $u_k(\sigma, t)$ satisfies the heat equation, it follows that:
\begin{equation*}
\frac{\partial \tilde{u}(\sigma, t)}{\partial t} = -\Delta_k \tilde{u}_k(\sigma, t).
\end{equation*}

Next, consider a simplex $\sigma \notin S$. By definition, $\tilde{u}_k(\sigma, t) = 0$ for all $t \geq 0$ and $\frac{\partial \tilde{u}_k(\sigma, t)}{\partial t} = 0$. Since $\Delta_k$ only couples simplices within the same connected component, and $\sigma$ is not in $S$, we have: $\Delta_k \tilde{u}_k(\sigma, t) = 0$. Thus, $\tilde{u}_k(\sigma, t)$ trivially satisfies the heat equation.

Since $\tilde{u}_k(\sigma, t)$ satisfies the heat equation for all simplices $\sigma \in \mathcal{S}$ and coincides with the initial condition $u(\cdot, 0)$ on $S$, it follows from the uniqueness of solutions to the heat equation that $\tilde{u}_k(\sigma, t) = u_k(\sigma, t)$ for all $t > 0$. Therefore, for any simplex $\sigma \notin S$ and for all $t > 0$, we have: $u_k(\sigma, t) = \tilde{u}_k(\sigma, t) = 0$.
\end{proof}

\section{Proof of Proposition~\ref{prop:heat_equation_agreement}}~\label{sec:heat_equation_agreement}
\begin{proposition}[Agreement of Heat Equation Solutions]
\label{proof:heat_equation_agreement}
Let $\mathcal{S}$ be a simplicial complex of order $K$, and let $\mathcal{G}(\mathcal{S})$ be its associated simplicial graph as defined in Definition~\ref{def:simplicial_graph}. Let $u_{\mathcal{S}}(\sigma, t)$ denote the solution to the heat equation on $\mathcal{S}$ (Eqn.~\ref{eqn:heat_eqn_simplicial_complex}). Similarly, let $u_{\mathcal{G}}(v, t)$ denote the solution to the heat equation on $\mathcal{G}(\mathcal{S})$:
\begin{equation}
\frac{\partial u_{\mathcal{G}}(v, t)}{\partial t} = -\Delta_{\mathcal{G}} u_{\mathcal{G}}(v, t),
\end{equation}
where $\Delta_{\mathcal{G}}$ is the graph Laplacian of $\mathcal{G}(\mathcal{S})$. 
Assuming that the initial conditions $u_{\mathcal{S}}(\cdot, 0)$ and $u_{\mathcal{G}}(\cdot, 0)$ are consistent, i.e.,
\begin{equation*}
u_{\mathcal{S}}(\sigma, 0) = u_{\mathcal{G}}(\sigma, 0) \quad \text{for all } \sigma \in V(\mathcal{G}).
\end{equation*}
Then, for all $t > 0$ and for all simplices $\sigma \in \mathcal{S}$, the solutions agree: $u_{\mathcal{S}}(\sigma, t) = u_{\mathcal{G}}(\sigma, t)$.
\end{proposition}

The simplicial wavelet transform incorporates diffusion in multiple orders using the diffusion operator for each order. However, these diffusion operators can be represented using one large diffusion operator on the simplicial graph $\mathcal{G}$, resulting in the block-diagonal Laplacian $\Delta_{\mathcal{G}} \in \mathbb{R}^{N\times N}$:

\begin{equation}
    \Delta_{\mathcal{G}} = 
    \begin{bmatrix}
       \Delta_0  & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{0} & \mathbf{0}\\
       \mathbf{0}  & \Delta_1 & \mathbf{0} & \cdots & \mathbf{0} & \mathbf{0}\\
       \mathbf{0} & \mathbf{0}  & \Delta_2 & \cdots & \mathbf{0} & \mathbf{0}\\
       \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
       \mathbf{0} & \mathbf{0} & \mathbf{0} & \cdots & \Delta_{K-1} & \mathbf{0}\\
       \mathbf{0} & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{0} & \Delta_K\\
    \end{bmatrix}
    \label{eq:DeltaG}
\end{equation}


where \(N=\sum_{i=0}^K N_i\). Now, for each $k$-simplex $\sigma_k$, the function $u_k(\sigma_k, t)$ represents the heat value at \(\sigma_k\) at time \(t\). Collectively, the vector
    $$
      u_k(\cdot,t) \;=\; \bigl[u_k(\sigma_k^{(1)}, t),\; u_k(\sigma_k^{(2)}, t),\;\dots\bigr]^\top
    $$
stores these values for \emph{all} $k$-simplices, in some fixed ordering. Since $\mathcal{G}$ treats \emph{all} simplices as nodes, a single node index $v$ in $\mathcal{G}$ could correspond to either a 0-simplex, a 1-simplex, and so on, up to a $K$-simplex. Hence, when we form a global vector by effectively stacking the heat vectors for each order as:

\begin{equation*} 
      u_{\mathcal{G}}(v,t) 
      \;=\; 
      \begin{bmatrix}
        u_0(\cdot, t) \\
        u_1(\cdot, t) \\
        u_2(\cdot, t) \\
        \vdots \\
        u_K(\cdot, t)
      \end{bmatrix},
\end{equation*}.


By stacking the diffusion operators and heat vectors in this manner, the heat equation on the simplicial graph becomes
\begin{align*}
    \frac{\partial u_{\mathcal{G}}(\cdot, t)}{\partial t} 
    &= -\Delta_{\mathcal{G}}\, u_{\mathcal{G}}(\cdot, t) \\
    &=
    \begin{bmatrix}
       \Delta_0  & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{0} & \mathbf{0}\\
       \mathbf{0}  & \Delta_1 & \mathbf{0} & \cdots & \mathbf{0} & \mathbf{0}\\
       \mathbf{0} & \mathbf{0}  & \Delta_2 & \cdots & \mathbf{0} & \mathbf{0}\\
       \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
       \mathbf{0} & \mathbf{0} & \mathbf{0} & \cdots & \Delta_{K-1} & \mathbf{0}\\
       \mathbf{0} & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{0} & \Delta_K\\
    \end{bmatrix}
    \begin{bmatrix}
        u_0(\cdot, t)\\
        u_1(\cdot, t)\\
        u_2(\cdot, t)\\
        \vdots\\
        u_K(\cdot, t)
    \end{bmatrix}\\
    &=
    \begin{bmatrix}
        \Delta_0\, u_0(\cdot, t)\\
        \Delta_1\, u_1(\cdot, t)\\
        \Delta_2\, u_2(\cdot, t)\\
        \vdots\\
        \Delta_K\, u_K(\cdot, t)
    \end{bmatrix}
    =
    \begin{bmatrix}
        \frac{\partial_0 u(\cdot, t)}{\partial t}\\
        \frac{\partial_1 u(\cdot, t)}{\partial t}\\
        \frac{\partial_2 u(\cdot, t)}{\partial t}\\
        \vdots\\
        \frac{\partial_K u(\cdot, t)}{\partial t}
    \end{bmatrix}.
\end{align*}

Observe that each block $\Delta_k$ governs the diffusion process on the set of $k$-simplices. Since the matrix $\Delta_{\mathcal{G}}$ is block-diagonal, the heat equation $\tfrac{\partial u_{\mathcal{G}}}{\partial t} = -\Delta_{\mathcal{G}} u_{\mathcal{G}}$ decouples into \(K+1\) separate equations, each corresponding to \(\tfrac{\partial_k u(\cdot, t)}{\partial t} = -\Delta_k\,u_k(\cdot, t)\). Hence, the heat flow on the simplicial graph \(\mathcal{G}\) matches the heat flow across all orders in the original simplicial complex, provided the initial conditions on each order are consistent.

Therefore, the solution to the heat equation on the simplicial graph constructed by stacking \(\Delta_0, \dots, \Delta_K\) agrees with the solution to the heat equation for each order of the simplicial complex when the initial conditions align. This justifies that the block-diagonal operator \(\Delta_{\mathcal{G}}\) captures the same diffusion dynamics as the collection of separate operators acting on their respective simplices.

\section{Theorem~\ref{thm:geodesicdist}}~\label{sec:geodesicdist}
\begin{theorem}[Capturing Geodesic Distance]
\label{proof:geodesicdist}
Let $\mathcal{S}$ be a simplicial complex of order $K$, and let $\mathcal{G}(\mathcal{S})$ be its associated simplicial graph. Denote the heat kernel on $\mathcal{S}$ by $H^k_t(\sigma, \tau)$, where $\sigma, \tau$ represent simplices of any order in $\mathcal{S}$. Assume that $H^k_t(\sigma, \tau)$ satisfies the heat equation:
\begin{equation}
    \frac{\partial H^k_t(\sigma, \tau)}{\partial t} = -\Delta_{k} H^k_t(\sigma, \tau),
\end{equation}
where $\Delta_{k}$ is the $k$-Hodge laplacian. Then, by computing the heat kernel on the simplicial complex, we can accurately approximate the geodesic distance $d_{\mathcal{M}}(\sigma, \tau)$ on the manifold $\mathcal{M}$.
\end{theorem}
\begin{proof}
We have already shown that the heat equation on simplicial complexes $\mathcal{S}$ agrees with the heat diffusion on the simplicial graph $\mathcal{G}(\mathcal{S})$. The heat kernel on the simplicial graph $\mathcal{G}$ is given by:
    \begin{equation}
        H_t(\sigma, \tau) = e^{-t\Delta_{\mathcal{G}}},
    \end{equation}
where $d(\sigma, \tau)$ represents the Euclidean distance between $x$ and $y$.

From this expression, it follows that:
\begin{align*}
    H_t &= e^{-t\Delta_{\mathcal{G}}}\\
    \log H_t &= \log e^{-t\Delta_{\mathcal{G}}}\\
    \log H_t &= -t\Delta_{\mathcal{G}}\\
    -4 t\log H_t &= 4t^2\Delta_{\mathcal{G}}\\
    -4 t\log H_t(\sigma, \tau) &= 4t^2\Delta_{\mathcal{G}}(\sigma, \tau)\\
\end{align*}
   %     h_t(\sigma, \tau) &= (4\pi t)^{-d/2} \exp\left(-\frac{d(\sigma, \tau)^2}{4t}\right) \\ 
  %      \log h_t(\sigma, \tau) &= - \frac{d}{2}\log (4\pi t) -\frac{d(\sigma, \tau)^2}{4t} \\ 
 %       \log h_t(\sigma, \tau) &= -\frac{1}{4t} ( 2dt \log(4\pi t) + d(\sigma, \tau)^2) \\ 
%    -4t \log h_t(\sigma, \tau) &= 2dt \log(4\pi t) + d(\sigma, \tau)^2.  \\
The operator $\Delta_{\mathcal{G}}$ is constructed from distances between two simplices. Based on that, we can observe that,
\begin{equation}
    \lim_{t \to 0} -4t \log h_t(\sigma, \tau) = d(\sigma, \tau)^2\label{eq:limit-of-heat-eq}.
\end{equation}
\citet{varadhan} shows that Eq~\ref{eq:limit-of-heat-eq} holds even for Riemannian manifolds with $d(\sigma, \tau)$ being the geodesic distance. Hence, we can approximate the geodesic distances using the diffusion on simplices.
\end{proof}

\section{Data Cohorts}
\label{sec:data}
\begin{itemize}
    \item \textbf{Melanoma}:
    We use data originally collected by \citet{melanoma} and published in \citet{https://doi.org/10.17632/79y7bht7tf.1}, which consists of 54 melanoma patients, who underwent checkpoint blockade immunotherapy, each with approximately 489 to 1784 T-lymphocytes cells, resulting in a total of 11,862 cells. Each T-cell is characterized by 29 protein markers measured by Multiplexed Ion Beam Imaging (MIBI) \cite{yeo2024hitchhiker, angelo2014multiplexed}. This data can be modeled as 54 point clouds in a 29-dimensional space, with sample sizes ranging from 489 to 1784 points per point cloud. The learning task is binary classification of whether the patient experienced recurrence or not (including stable disease as a `non-recurrence'), predicted from the protein expression levels. Note that we are not using the spatial resolution of MIBI in our use case.
    % For testing {\modelname}{} we create a larger dataset by taking different samples of the current dataset.  The augmented version was created by subsampling 400 points from each patient's original point cloud and repeating this process ten times, producing a total of 540 point clouds.
    
    % \item \textbf{COVID-19}:
    % Second, we analyze data from \cite{covid-msphae}, comprising 209 blood samples from 148 Yale New Haven Hospital COVID-19 patients. Each patient has approximately 10,000 cells characterized by 14 proteins, adding up to a total of 1,502,334 cells, with the goal is to classify the COVID-19 outcome for each sample. Given the wide-ranging immunoregulatory pathways influencing these outcomes, we focus on myeloid cells leading to 17 patients. In order to increase the number of samples, we augment the data by subsampling 100 points per patient and repeating this process 100 times, hence producing a total of 1700 point clouds. Data points are aggregated into fewer than 500 clusters per patient using the diffusion condensation algorithm from \cite{covid-msphae}, with centroids representing points in the high-dimensional immune space for processing with \modelname.
    
    \item \textbf{Patient-derived Organoids (PDOs)}:
    Third, we consider data from~\cite{trellis-pdo} featuring patient-derived organoids (PDOs) from 12 different patients with colorectal cancer. Patient-derived organoids (PDOs) are cell cultures grown from patient tumor samples. Each culture, representing a PDO sample, is characterized by 44 gene expression markers and contains approximately 1137 cells. Collectively, we consider 1,678 such cultures, forming 44 dimensional point clouds, resulting in a total of 2 million cells. The goal is to infer treatment administered to the PDO based on cellular states, serving as a synthetic task for our model.
    %The goal is to predict the treatment administered to the PDO based on cellular states.

    \item \textbf{Spatial Transcriptomics (ST)}:
    We next consider Spatial Transcriptomics data generated using a 40-plex CODEX (CO-Detection by Indexing) immunofluorescent imaging workflow from~\citep{space-gm}, capturing 40 protein markers for each cell from 500 head-and-neck and colorectal cancer patients. 
    Thus, each sample naturally splits into two views: 
    \begin{itemize}
        \item \emph{Spatial View:} Cellular coordinates describing how cells are arranged in two-dimensional tissue sections.
        \item \emph{Gene View:} Dozens of markers or transcripts measured per cell, detailing complex biological states.
    \end{itemize}
    The overarching goal is to predict outcome of chemotherapy on cancer patients. Another goal is to predict cancer relaspe of recovered patients. This task particularly leverages \modelname's ability to fuse spatial context with transcriptional signals for clinically relevant insights in cancer research.

\end{itemize}

\section{Experimental Setup}
\label{sec:experimental_setup}
The parameters of {\modelname} are optimized using the AdamW optimizer \cite{adamw} with a constant learning rate of $10^{-4}$ and a weight decay of $10^{-4}$. We train the model for 20 epochs on every dataset for each model. We record the best metric (accuracy in classification tasks; mean squared error in regression tasks) achieved on the test set in each training run.  We compare model performances on each dataset and task by the mean and standard deviation of their resulting five metric scores. For the spatial transcriptomics data, we use the folds from~\citet{space-gm}. In Table~\ref{tab:K_max}, we describe order of the simplicial complex that we have used for each data set.
Typically, our setup necessitates approximately two to three hours of training time for each dataset on a single NVIDIA A100 GPU.

\begin{table}[t]
    \centering
    \begin{tabular}{ccc}
    \toprule
    \textbf{Data} & \textbf{Task} & $\mathbf{K}$\\
    \midrule
    \multirow{2}{*}{Melanoma-subsampled} & Classification & 2\\
     & Persistence prediction & 2\\
    \hline
    \multirow{2}{*}{Melanoma-full} & Classification & 1\\
     & Persistence prediction & 1\\
    \hline
    \multirow{2}{*}{PDO} & Classification & 1\\
     & Persistence prediction & 1\\
    \hline
     DFCI & Outcome & 1\\
    \hline
     \multirow{2}{*}{Charville} & Outcome & 2\\
      & Recurrence & 1\\
    \hline
     \multirow{2}{*}{UPMC} & Outcome & 2\\
      & Recurrence & 1\\
    \bottomrule
    \end	{tabular}
    \caption{Order of simplicial complex}
    \label{tab:K_max}
\end{table}

\subsection{Baselines}
\label{sec:baselines}
We compare the performance of {\modelname} on the classification tasks outlined in Section \ref{sec:tasks} to two groups of alternative methods. First, to demonstrate the expressive power of our multiview graph embeddings over traditional graph neural network techniques, we construct K-nearest neighbor graphs of the input point cloud data and attempt to learn a classifier using several popular graph neural network architectures. These include Graph Convolutional Networks (GCN) \cite{gcn}, GraphSAGE \cite{sage}, Graph Attention (GAT) Networks \cite{gat}, Graph Isomorphism Networks (GIN) \cite{gin}, and Graph Transformer Networks (GTNs)~\cite{graph-transformers}. We discuss their performance on our high-dimensional tasks in Section \ref{sec:results}. 

Second, we compare our method directly state-of-the art, bespoke point cloud learning methods. While DGCNN \cite{dgcnn}, PointNet++ \cite{pointnet++} and PointTransformer \cite{pointtransformer} all perform very well on the three-dimensional problems they were designed to tackle, as we discuss below, they struggle to successfully classify high-dimensional point clouds. 

%\textcolor{blue}{MP: What does best accuracy mean? Is this where you are doing hyperparameter tuning? If so, are you "averaging bests" or or you taking the parameters which were "best on average" and reporting that} Note: We first do hyperparameter tuning and run each model for 5 times. Then we use the best metrics achieved in all 5 trainings and average these numbers. So it is "averaging bests".


\section{Computational Complexity}
The computational complexity of one step of diffusion process has the complexity of $\mathcal{O}(D(\Sigma_{k=1}^K N_k))$, where $D$ is a dimension of the features. Since we have to repeat the diffusion process for a total of $J$ times, and we have to calculate the wavelet co-efficients $V$ times, the complexity calculating SWT is $\mathcal{O}(VJD(\Sigma_{k=1}^K N_k))$. The complexity of reweighing through hadamard product is $\mathcal{O}(DN_0)$. The complexity of VR-filtration is $\mathcal{O}{N_0^2}$. So, the total computational complexity of {\modelname} is $\mathcal{O}( N_0^2 + DN_0 + VJD(\Sigma_{k=1}^K N_k))$.

\section{Additional experimental results}\label{sec:extra-results}

In Table \ref{tab:viewablation}, we present an ablation study of \modelname{} showing the impact of varying number of views. The results show that four views is most effective for capturing the topology of the point clouds.

\begin{table*}[t]
    \centering
    \scalebox{1.0}{\begin{tabular}{ccccc}
    \toprule
    \textbf{Num. of Views} & \textbf{Melanoma} & \textbf{PDO} \\
    \midrule
    1 &  27.27 $\pm$ 12.85 & 59.80 $\pm$ 1.99 \\
    2 & \underline{54.54 $\pm$ 11.13} & \underline{61.10 $\pm$ 0.17}\\
    4 & \textbf{90.90 $\pm$ 4.92} & \textbf{63.10 $\pm$ 0.00}\\
    %16 & \textbf{100 $\pm$ 0.0} & \textbf{OOM} & 84.411\\
    \bottomrule
    \end{tabular}}
    \caption{Accuracies (mean $\pm$ standard deviation) from ablation on the number of graphs. Best result is bolded and second best is underlined.}
    \label{tab:viewablation}
\end{table*}
\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
