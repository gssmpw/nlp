%In general, 
A neural operator~\citep{li_fourier_2021,li_neural_2020,lu20201DeepONet} is a parametric model based on neural networks that aims to best approximate a 
%(possibly) nonlinear 
%\emph{ground truth} 
mapping between two function spaces, which %---these mappings 
can be linear, such as the antiderivative or integral operator, or nonlinear such as the solution operator of a nonlinear PDE. % (e.g., Hyperelasticity). 
\pcedit{Thus, letting $G^\dagger$ denote the ground-truth operator we are trying to approximate and $G_{\vtheta}$ denote the neural operator parameterized by the parameter vector $\vtheta$, the objective is to \emph{learn} $\vtheta$ such that, given an input function $\vu$, we have $G_{\vtheta}(\vu)\approx G^{\dagger}(\vu)$.} 
%Learning such approximation 
Such learning 
is done by solving an optimization problem  
%where learning such best approximation is done 
using data samples consisting of tuples of input and output function values of $G^\dagger$. %the ground truth operator.
%
This optimization problem is analogous to the notion of learning in finite dimensions, which is precisely the setup for which classical deep learning is used.

We now introduce %two widely known neural operators: 
DONs and FNOs. %\pcedit{We denote by $G^\dagger$ the true operator we are trying to approximate, and denote the neural operator (DON or FNO) by $G_{\vtheta}$ and parameterized by the parameter vector $\vtheta$. The idea would be to \emph{learn} $\vtheta$ such that, given an input function $\vu$, we have $G_{\vtheta}(\vu)\approx G^{\dagger}(\vu)$.} 
More information about neural operators and the schematics of both DONs and FNOs %these two 
are found in Appendix~\ref{app:learning_fno_don}.


%
%
\subsection{Learning Deep Operator Networks (DONs)}
\label{subsec:DON_Setup} 
%
The DON model~\citep{lu20201DeepONet} is defined as the inner product of two deep feedforward neural networks, each one with $K$ output neurons. Given the 
% of real output: 
the branch net $\vf = \{f_k\}_{k=1}^{K}$ and {the trunk net}  $\vg = \{g_k\}_{k=1}^{K}$, the DON is 
\begin{equation}
    G_{\vtheta}(\vu)(\vy) := \sum_{k=1}^K f_k(\vtheta_f;\vu) g_k(\vtheta_g;\vy),
    \label{eq:DONoutput}
\end{equation}
where the input function $\vu$ has $\operatorname{ran}(\vu)\subseteq\R^{d_u}$ 
and $\vy \in \dom (G_{\vtheta}(\vu))\subseteq \R^{d_y}$ is the output location on which the operator is evaluated. 
The training data is composed of $n$ input functions $\{\vu^{(i)}\}_{i=1}^n$ and $q_i$ output locations for each $G^\dagger(\vu^{(i)})$, i.e., $ \{\{\vy^{(i)}_j\}_{j=1}^{q_i}\}_{i=1}^n$ with $\vy^{(i)}_j\in\R^{d_y}$ denoting the $j$-th output location for $G^\dagger_{\vtheta}(\vu^{(i)})$. 
Each $\vu^{(i)}$ is represented in $R$ locations $\{\bfx_r\}_{r=1}^{R}$
%\in \dom (\vu)\subseteq\R^{d_x}$ 
so that $\vu^{(i)}(\bfx_r)\in\R^{d_u}$, $r\in [R]$. 
% 
%
The entire set of parameters is $\vtheta = [\vtheta_f^{\top}\;\vtheta_g^{\top}]^\top \in \R^{p_f+p_g}$, where $\vtheta_f\in \R^{p_f}$ and $\vtheta_g\in\R^{p_g}$ are the parameter vectors of $\vf$ and $\vg$ respectively. 

We only consider scalar input functions, i.e., 
$d_u = 1$.  
%$\operatorname{ran}(u)\subseteq\R$. 
For each $i\in[n]$, we stack $\{u^{(i)}(\vx_r)\}_{r=1}^R$ as an input vector to $\vf$, thus, $\vf:\R^R\to \R^K$. Note that $\vg:\R^{d_y}\to\R^K$. Then, the DON learning problem is %formulated as 
the minimization: 
\begin{align}
    \begin{aligned}
        \vtheta^\dagger_{\rm (don)} &\in 
    \underset{\vtheta\in\R^{p_f+p_g}}{\argmin}~
    \gL\left(G_{\vtheta}, G^{\dagger}\right)
    \label{eq:empirical_risk}
    \end{aligned}
\end{align}
where 
\begin{equation}
\label{eq:loss-don}
\begin{aligned}
&\gL\left(G_{\vtheta}, G^{\dagger}\right)= \frac{1}{n}\sum_{i=1}^n \frac{1}{q_i} \sum_{j=1}^{q_i} 
    \left(
        G_{\vtheta}(u^{(i)})(\vy^{(i)}_j) - G^{\dagger}(u^{(i)})(\vy^{(i)}_j) 
    \right)^2
\end{aligned}
\end{equation}
is the empirical loss function that measures the approximation between $G_{\vtheta}$ and $G^\dagger$, and where
$G_{\vtheta}(u^{(i)})(\vy^{(i)}_j)=\sum_{k=1}^K f_k\left(\vtheta_f;\{u^{(i)}(\vx_r)\}_{r=1}^R\right) g_k\left(\vtheta_g;\vy^{(i)}_j\right)$.

Note that the ground truth operator $G^{\dagger}$  
can either be explicit, e.g. integral of a function, or implicit, e.g. the solution to a nonlinear partial differential equation (PDE). 

\subsection{Learning Fourier Neural Operators (FNOs)}
\label{subsec:FNO_setup} 
The FNO model~\citep{li_fourier_2021} is defined as follows: $G_{\vtheta}(\vu)(\vx):=f(\vtheta;\vx)$ with 
\begin{equation}
\label{eq:continuous_fno}
\begin{aligned}
    \aalpha^{(0)}(\vx) &= P(\vu;\vtheta_p)(\vx)\\ 
    \aalpha^{(l)}(\vx) &= \gF^{(l)}(\aalpha^{(l-1)}(\vx); \vtheta_{F^{{(l)}}}),\; l\in[L+1]\\ 
    %G_{\vtheta}(\vu)(\vx)=f(\vtheta;\vx) &= Q(\aalpha^{({L+1})};\vtheta_q)(\vx),
    f(\vtheta;\vx) &= Q(\aalpha^{({L+1})};\vtheta_q)(\vx),
\end{aligned}
\end{equation} 
where the input function $\vu$ has $\operatorname{ran}(\vu)\subseteq\R^{d_u}$, 
$G_{\vtheta}(\vu)(\vx)\in\R$ is the output of the FNO evaluated at output location $\vx\in\R^{d_x}$,
%where 
$\{\gF^{(l)}\}_{l=1}^{L+1}$ are nonlinear transformations with learnable parameters $\vtheta_{F} = [\vtheta_{F^{(1)}}^{\top}, \dots, \vtheta_{F^{(L+1)}}^\top]^\top\in\R^{F}$ and which may contain operations in the Fourier domain, $P$ is an encoder that maps $\vu$ and $\vx$ to an ambient space of dimension $d$ and has parameter vector $\vtheta_p\in\R^{p}$, and $Q$ is a decoder that maps the output from the block $\aalpha^{(L+1)}(\vx)$ to a scalar output 
%the desired output space of dimension $d_f$ 
with parameter vector $\vtheta_q\in\R^q$. 
The entire set of parameters for the FNO can be written as $\vtheta = \left[ \vtheta_p^{\top} \ \vtheta_{F}^{\top}\ \vtheta_q^{\top}\right]^{\top}$. 
With a slight abuse of notation, the FNO is simply written as $G_{\vtheta}(\vu)(\vx)=f(\vtheta;\vx)$ in~\eqref{eq:continuous_fno} when the input function $\vu$ is known by the context.
%
%
%
%\end{equation}

The training data is composed of $n$ input-output pairs $\{(\vu^{(i)},G^\dagger(\vu^{(i)})\}_{i=1}^n$ and a computational grid of evaluations $\{\vx_{r}\}_{r=1}^R$. We let $f^{(i)}(\vtheta;\vx_r)$ denote the FNO model~\eqref{eq:continuous_fno} with input function $\vu^{(i)}$ and evaluated at $\vx_r$. Then, the FNO learning problem is %formulated as 
the minimization:
%of the following empirical risk:
\begin{equation}
    \vtheta^{\dagger}_{\rm (fno)} \in \underset{{\vtheta \in \R^{p+F+q}}}{\argmin}~ \gL (G_{\vtheta}, G^{\dagger}) 
    \label{eq:fno_loss}
\end{equation}
with empirical loss function
\begin{equation}
\label{eq:loss-fno}
\begin{aligned}
    &\gL (G_{\vtheta}, G^{\dagger})=\frac{1}{n}\sum_{i=1}^n \frac{1}{R} \sum_{r=1}^R \left( 
        G_{\vtheta}({\vu^{(i)}})(\vx_r) - G^{\dagger}(\vu^{(i)})(\vx_r)
    \right)^2
\end{aligned}
\end{equation}
and where $G_{\vtheta}(\vu^{(i)})(\vx_{r})=\vf^{(i)}(\vtheta;\vx_{r})$.

%where $\ell(z) = \frac{1}{2}z^2$.  
%
