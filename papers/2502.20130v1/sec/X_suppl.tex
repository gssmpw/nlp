\clearpage
\setcounter{page}{1}
\title{Supplementary Material for:\\ QPM: Discrete Optimization for Interpretable Image Classification}
\maketitle
\renewcommand\thesection{\Alph{section}}
\renewcommand\thesubsection{\thesection.\Alph{subsection}}
 \setcounter{section}{0}
\section{Appendix}
This appendix contains additional details of the implementation details, more results with standard deviations, further experiments on steerability, a discussion of failure cases and the formulation of the Feature Diversity Loss~\gls{customLoss}.
Further, the quadratic problem is presented in its standard form and the optimality of the found solutions is discussed.
\section{TravelingBirds}
\begin{table}
\caption{
Statistical overview of 
datasets. \travelingheader{} is used exclusively in the appendix.
}%
\label{table:DatasetOverview}
\vspace{-.1cm}
\begin{center}

\centering
\setlength\tabcolsep{6pt}
\begin{tabular}{cccccc}
\hline
Dataset & \cubheader& \stanfordheader{}& TravelingBirds&   \imgnetheader\\ 
\hline
\# Classes $\gls{nClasses}$ & 200 &196 & 200 &  1000\\
\# Training & \numprint{5994} &\numprint{8144} &  \numprint{5994} & \numprint{1281167}\\
\# Testing & \numprint{5774} &\numprint{8041} &  \numprint{5774} & \numprint{50000}\\
\hline
\end{tabular}
\vspace{-0.35cm}
\end{center}
\end{table}

We use \travelingheader{} as an additional dataset to validate our method and for our steering experiments in \cref{ssec:steer}.
It is based on \cubheader{} and designed to allow the measurement of the robustness of spurious correlations.
Specifically, the background of every class in the training set is replaced with an image of a constant class of Places365~\citep{zhou2017places}.
For the test set, backgrounds of random classes are used, thus measuring if the model learned to rely on the spuriously correlated background.
\section{Implementation Details}
\label{suppsec:impl}
We first describe the implementation on the fine-grained datasets \cubheader{}, \travelingheader{} and \stanfordheader{}. 
All deviating details for \imgnetheader{} are included in \cref{ssec:imgnet}.
The implementation details are similar to the \glsname{layerName}~\citep{norrenbrocktake}, but use the default data for prototype-based methods.
Specifically, we use the exact same dense model for both models in our experiments and only alter the following parts of the pipeline with the same hyperparameters for fine-tuning.
Therefore, the improved metrics can be attributed to the superior selection and assignment.
\paragraph{Architectures}
We implement our method using PyTorch~\citep{Pytorch} and its \gls{imgnetheader} pretrained models as %
feature extractors. 
For \resnet{} and Resnet34 we follow \gls{PIP-Net} and use a smaller stride size of 1 for the two last blocks.

\paragraph{Data}
For training with \cubheader{} and \travelingheader{}, the images are first cropped to the ground truth segmentation, following prototype-based methods~\cite{nauta2023pipnet, rymarczyk2022interpretable}.
After cropping, they are resized to $224\times224$ ($299\times299$ for \incv). 
For \stanfordheader{} and our steerability experiments in \cref{stab:noCrop}, a random crop after resizing one side to the target image size is used instead.
Then normalization, random horizontal flip, jitter and \textit{TrivialAugment}~\cite{Muller_2021_ICCV} is applied.
At test time, no augmentation is used and only cropping, random crop replaced by center crop, resizing and normalization is maintained. 
\paragraph{Dense Training}
We fine-tune the pretrained models on the fine-grained datasets using stochastic gradient descent with a batch size of $16$ for $150$ epochs.
The learning rate starts at $5\cdot10^{-3}$ for the pretrained layers and $0.01$ for the final linear layer and gets multiplied by $0.4$ every $30$ epochs.
We set momentum to $0.9$, $\ell_2$-regularization to $5\cdot10^{-4}$ and apply dropout with rate $0.2$ to the features.
The weighting \gls{cLW}, included in \cref{seq:customLossW}, of the Feature Diversity Loss~\cite{norrenbrocktake} is set to $0.196$ for the %
Resnets, $0.049$ for \incv{} and $0.0245$, the highest value we tried for which all dense models converged, for Swin Transformers.
Note that the values are scaled with the number of patches in the feature maps, leading to numerical values that do not align conveniently with powers of $10$.
\paragraph{Fine-tuning}
After solving the quadratic problem, the model is trained with the final layer fixed to the sparse assignment of selected features $\boldsymbol{W}^*$ for $40$ epochs. 
The learning rate starts at $100$ times the final learning rate of the dense training and decreases by $60\,\%$ every $10$ epochs. 
During fine-tuning, momentum is increased to $0.95$ and dropout on the features reduced to $10\%$.
For Swin Transformers, the batch size is set to 8 and Layer 
normalization~\cite{ba2016layer} 
is turned off after the dense training has finished, ensuring more unrelated features.
All other parameters equal the dense setting.

As the feature maps are the result of 
ReLU~\cite{nair2010rectified}, 
one might expect its values to be strictly $\geq0$.
However, just like for the \gls{layerName}, the features of \gls{NewlayerName} are normalized with a fixed mean and standard deviation before fine-tuning begins, resulting in the sub-zero $\min (\boldsymbol{f}_{:,i})$.
\paragraph{Reproducibility}
For reproducibility, all our experiments with $5$ seeds use the integers $16$ to $20$, ending at $18$ for the $3$ \imgnetheader{} runs, as seed for all random processes.
\paragraph{Scaling the Objective}
To keep a similar relative weighting across changing \gls{nperClass} and \gls{nClasses}, we also scale the main objective for the quadratic problem $\objective_{A}$ with them
\begin{equation}
    \objective_{A}^* =  \frac{1000 \cdot \objective_{A}}{\gls{nperClass} \cdot \gls{nClasses}},
\end{equation}
ensuring no additional scaling for $\gls{nClasses}=200$ and $\gls{nperClass}=5$.
\paragraph{Choice of Pretrained Weights}
We use the pretrained  \resnet{} weights \textit{V1} of PyTorch for our experiments, as the default \textit{V2} has very class-specific features already, with a \generality{} of $92.6\%$. 
For \textit{V2}, a sparse model computed by \glm{} with just $1.1$ features per class can already achieve $66\%$ accuracy on \imgnetheader{}, demonstrating the class-specificness of its features.
For Resnet34 and \gls{incv}, we use the only available set of weights from PyTorch.
For Swin Transformers, we used the original provided weights of PyTorch, as they are suitable for the used image resolution.
\subsection{ImageNet-1K}
\label{ssec:imgnet}
Due to computational constraints, we follow the \gls{layerName}, skip the dense training on \imgnetheader{} and directly use the pretrained model as dense model.
To facilitate the comparability of metrics between the dense model and our experiments, we use the default strides.
For augmentation, we use Lighting noise and omit \textit{TrivialAugment}.
Finally, the learning rate of the fine-tuning starts at  $\frac{1}{100}$ of the value used for the fine-grained datasets to account for the increased size of the dataset.

\subsection{Correlation Metric}
\label{ssec:corremet}
For measuring the effect of reducing correlation between selected features in \cref{tab:ablations}, the \textit{\correlation{}} is used:
\begin{equation}
  \mathrm{\correlation{}} = \frac{1}{\gls{nReducedFeatures}} \sum_{\findex=1}^{\gls{nReducedFeatures}}\max_{\findex\neq \findex'}
  \frac{\boldsymbol{f}_{:,\findex}^T\boldsymbol{f}_{:,\findex'}}{|\boldsymbol{f}_{:,\findex}||\boldsymbol{f}_{:,\findex'}|}\label{eq:CorrMet}
 \end{equation}
\subsection{Quadratic Problem}
\label{ssec:Quadratic}
This section presents further details on the quadratic problem and
the start solution $\boldsymbol{W}^{\mathrm{Start}}$ for the next iteration of solving the quadratic problem with updated constraints.
The start solution is a good, usually optimal, feasible solution for the currently selected set of features $\Lambda$.
To simplify the initial iterations,  only \cref{eq:NotGLob} is considered.
The deduplication of \cref{eq:4DedupQP} is only included after a solution is found that satisfies \cref{eq:NotGLob}.
The start solution is constructed from $\boldsymbol{W}^{\gls{nperClass}}$ which contains \gls{nperClass} assignments for each class to the most similar features in $\simmat{}_{:, \Lambda}$.
If the equal distribution of assignments per class is still exclusively optimized for, $\boldsymbol{W}^{\mathrm{Start}}=\boldsymbol{W}^{\gls{nperClass}}$ is already the start solution.
Else, we take care of all classes with equal assignment $C_{\mathrm{equal}}$ in $\boldsymbol{W}^{\gls{nperClass}}$.
Specifically, we remove all duplicate pairs $(\cindex, \cindex')\in C_{\mathrm{equal}}$:
\begin{align}
w^{\mathrm{Deduplication}}_{\cindex,\findex} &= \begin{cases}
\begin{aligned}
1  \quad\mathrm{if} \quad&(\cindex, \cindex')\in C_{\mathrm{equal}} \And\\ &(\cindex, \findex) = \mathrm{Maxi}(\cindex, \cindex') ,\\
\end{aligned}\\
\begin{aligned}
-1   \quad\mathrm{if}\quad &(\cindex, \cindex')\in C_{\mathrm{equal}} \And\\ &(\cindex,\findex) = \mathrm{Mini}(\cindex, \cindex') ,\\
\end{aligned}\\
0 \quad\mathrm{else}\\
\end{cases}\\
    \boldsymbol{W}^{\mathrm{Start}} &= \boldsymbol{W}^{\gls{nperClass}} +  \boldsymbol{W}^{\mathrm{Deduplication}}
\end{align}

Here, 
$\mathrm{Mini}(\cindex, \cindex')$ returns the indices to remove, that is of the current assignment with lowest similarity:
\begin{align}
 \helperindex{\cindex}= (\textbf{a}_{\cindex}&\circ \boldsymbol{w}^{\gls{nperClass}}_{\cindex}) \circ \fvecgurobi{} + \max(\textbf{a}_{\cindex}\circ \boldsymbol{w}^{\gls{nperClass}}_{\cindex}) \cdot ( \boldsymbol{1}-\fvecgurobi{})\\
 \mathrm{Mini}(\cindex, \cindex') &= \begin{cases}
   \cindex, \mathrm{argmin} (
  \helperindex{\cindex})  \quad\mathrm{if}\quad  \min(
     \helperindex{\cindex}) \leq \min(
     \helperindex{\cindex'})\\
    \cindex', \mathrm{argmin} (  \helperindex{\cindex'})
 \quad\mathrm{else}\\
    \end{cases}
\end{align}
Here, \fvecgurobi{} is the selection vector and ensures that all changes only apply to the selected features.
Similarly, $\mathrm{Maxi}(\cindex, \cindex')$ returns the indices of the assignment to add, which has the highest similarity of the the not currently assigned features:
\begin{align}
\helperindex{\cindex}= (\textbf{a}_{\cindex}&\circ \mathrm{\textbf{cand}}(\cindex)) \circ \fvecgurobi{}\\
 \mathrm{Maxi}(\cindex,\cindex') &= \begin{cases}
   \cindex, \mathrm{argmax} (
  \helperindex{\cindex})  \quad\mathrm{if}\quad  \max(
   \helperindex{\cindex} \geq \max(
   \helperindex{\cindex'})\\
    \cindex', \mathrm{argmax} ( \helperindex{\cindex'})
 \quad\mathrm{else}\\
    \end{cases}
\end{align}
The candidate function
\begin{align}
    \mathrm{\textbf{cand}}(\cindex) &=  (\boldsymbol{1}-\boldsymbol{w}^{\gls{nperClass}}_{\cindex})\cdot \mathrm{\textbf{wbnd}}(\cindex,\boldsymbol{w}^{\gls{nperClass}})
\end{align}
checks that the assignment is not made yet and the would-be-no-duplicate function $\mathrm{wbnd}(\cindex,\boldsymbol{W}^{\gls{nperClass}})_\findex\in\{0,1\}$
further ensures that the addition of the assignment of class $\cindex$ to feature $\findex$ would introduce no duplicate, returning $0$ in that case.
While this technically does not guarantee an optimal solution, first only finding the solution with \gls{nperClass} assignments per class and then deduplicating ensures that the number of duplicates is quite low already, which usually leads to finding the optimal feasible start solution.
\section{Steerability}
\label{ssec:steer}
  \begin{figure}[t]
     \centering\includegraphics[width=.6\linewidth]{plots/Steering}
     \caption{
     Steerability of the proposed \gls{NewlayerName}:
     When increasing the weighting of the bias $\lambda$, the desired metrics, accuracy or \loc{5} improve.}
     \label{fig:steering}
     \end{figure}


 This section is concerned with the ability of the practitioner to steer the model towards desired biases using the
 feature bias~\BSimeaturemat{}. 
 For example, if a human recognizes the erroneous focus on the background of a trained~\gls{NewlayerName}, enabled through global interpretability,
 the feature bias~$\BSimeaturemat{}^{\mathrm{Center}}$~(\cref{eq:centerBias}) can be used to steer the model towards more centered features.
\begin{equation}
  b^{\mathrm{Center}}_\findex = - \frac{1}{\gls{nTrainImages}\sum_j f_{j, \findex} } \sum_{j=1}^{\gls{nTrainImages}}  
  \frac{1}{1+\distEdge(\boldsymbol{M}^j_\findex)}
   f_{j,\findex}\label{eq:centerBias}
\end{equation}
where $\distEdge$ computes the distance between the maximum of 
\checktext{the $j$-th sample's map }
$\boldsymbol{M}^j_\findex$ at $(x,y)$ and the closest 
edge:
\begin{align}
  \distEdge(\textbf{M}_\findex^j) = \min(|x-\gls{featuresMapwidth}|,x-1, |y-\gls{featuresMapheigth}|, y-1)
\end{align}
 The resulting 
 improved accuracy on \travelingheader{} with $\lambda=10^\frac{3}{2}$, shown in \cref{stab:noCrop}, demonstrates this steerability.
Setting $\lambda$ allows a precise weighting of the emphasis put on the bias.
This direct control for both the center and diversity bias is visualized in \cref{fig:steering} and allows the incorporation
of any feature-level bias~\BSimeaturemat.
\section{Failure Cases}
\label{ssec:Failure}
\input{sec/failureExamples}
\input{sec/failureExamplesGrad}
This section presents examples where \gls{NewlayerName} predicts wrongly.
For that, \cref{fig:failuresOver} shows exemplary images of Rottweiler and Doberman with classification results of the probed \gls{NewlayerName} trained on \imgnetheader{} and with global explanations in \cref{fig:metrics_full,fig:blacktanS,fig:rottweilerS,fig:dobermanS}. 
Note that the accuracy across the two classes is $87\%$, well above the average, reflected in correct classifications across poses, backgrounds and settings in \cref{subfig:CDob,subfig:CRot}.
Additionally, \cref{Gradfig:failuresOver} shows the GradCAM~\citep{selvaraju2020grad} visualizations and demonstrates that QPM always focuses on the dog in the image.
For the erroneous predictions, the model behaves just like the global explanations would indicate.
Rottweiler and Doberman may be swapped, if the head is occluded as in \cref{subfig:DRPCutoff,subfig:RDPCutoff} or in a difficult pose to gauge the shape, shown in \cref{subfig:DRPPose,subfig:RDPPose}. 
Since the Black and tan coon hound is assigned both head features of Rottweiler and Doberman, they can also be confused when primarily the head is visible, demonstrated in \cref{subfig:DBPCutoff,subfig:RBPCutoff}.
Finally, \cref{subfig:DRPLabel,subfig:RGPLabel} seem to contain one of the many~\citep{northcutt2021labelerrors} wrongly  labeled samples in \imgnetheader{}.  \gls{NewlayerName} also robustly classifies wrongly labeled data, as the global explanation would suggest.
\Cref{subfig:Mountain,subfig:MountainRott} show the feature activations of Greater Swiss Mountain Dog and Rottweiler on \cref{subfig:DRPLabel} and other class examples, further suggesting that it is indeed a typical Greater Swiss Mountain rather a Rottweiler for the probed QPM, as the features of the former localize  on the expected regions, whereas most Rottweiler features barely activate.
Finally, \cref{subfig:BronzedEx} shows further test examples for the model explained in \cref{fig:CubSim} and demonstrates that the model does not predict Bronzed Cowbird if the differentiating red eye is not present in the image.
In summary, \gls{NewlayerName}'s local behavior robustly follows the faithful global explanations, which can lead to predictable faulty classifications in case of occlusion or difficult pose.


\begin{figure*}[t]
  \centering
\includegraphics[width=\linewidth]{plots/RottweilerClassSepGreaterSwissMountaindogClassSepClassSepClassSep_GreaterSwissMountaindog_5FeaturesTransCompFalse.png}

   \caption{Features of Greater Swiss Mountain Dog and their localization on the sample in \cref{subfig:RGPLabel} (first row), that is presumably falsely labeled Rottweiler. The 4 lower rows contain examples of Greater Swiss Mountain Dog and the features consistently localize around semantically similar regions, also on the Rottweiler labeled one. }
  \label{subfig:Mountain}
\end{figure*}
\begin{figure*}[t]
  \centering
\includegraphics[width=\linewidth]{plots/rotttrue.png}

   \caption{Features of Rottweiler and their localization, scaled by column, on the sample in \cref{subfig:RGPLabel} (first row), that is presumably falsely labeled Rottweiler. The 4 lower rows contain examples of Rottweiler. The color code is consistent with \cref{fig:metrics_full} and features $4$ and $5$ are shared with Greater Swiss Mountain Dog.}
  \label{subfig:MountainRott}
\end{figure*}
\begin{figure*}[t]
  \centering
\includegraphics[width=\linewidth]{plots/Bronzed_CowbirdClassSepBronzed_CowbirdClassSepShinyCowbirdClassSepAmericanCrow_Bronzed_Cowbird_5FeaturesTransCompTrue.png}

   \caption{Features of Bronzed Cowbird, explained and compared with Shiny Cowbird in \cref{fig:CubSim}, the predictions of the QPM, and their localizations, normed across column, on Bronzed Cowbird labeled test samples. When all features, including the red eye (feature 1) are visible (rows 1 and 2), the model is correct. However, as expected from the global explanation, without the red eye it can be wrong and confuse e.g. Shiny Cowbird with it. The probed QPM represents American Crow with features 2,4,5 and 2 further not shown features, that localize on wing and beak of crows.  }
  \label{subfig:BronzedEx}
\end{figure*}
\section{Runtime Analysis}
\label{ssec:Runtime}
This section discusses the time it takes to obtain a \gls{NewlayerName}, compares it to competing models and discusses the impact of \gls{nReducedFeatures} on it.
\Cref{fig:timeplot} demonstrates that the optimization time strongly increases when increasing \gls{nReducedFeatures}. 
However, for the probed datasets, going beyond $50$ features seems not to be necessary, as the accuracy only improves negligibly, while the interpretability is harmed: Features become less general and there will be fewer class representations with high overlap, which allow for the most intuitive interpretation.
One can further optimize this using suitable priors, which we do not include in this work, as the interpretability and additional accuracy decreases with increasing \gls{nReducedFeatures}.
It is however an avenue for future work, when datasets with sufficient complexity are published.
\Cref{stab:TimeTable} compares the time to obtain the interpretable model between \gls{NewlayerName}, \gls{qsenn} and \gls{layerName}. 
\gls{qsenn} and \gls{layerName} start with a feature selection, that takes $15$ minutes on \cubheader{} and roughly $500$ minutes on \imgnetheader{}. They both use \glm{} for feature selection and computing the sparse matrix and are thus scaling with number of samples \gls{nTrainImages}, which \gls{NewlayerName} is invariant to, as that dimension is summarized in the constants.
\begin{figure*}[t]
  \centering
\includegraphics[width=.5\linewidth]{plots/timeOverNF.png}

   \caption{Time it takes to optimize QP for models with varying \gls{nReducedFeatures}in~\cref{fig:interptradeoff}.}
  \label{fig:timeplot}
\end{figure*}
\begin{table*}[t]
 \caption{Time in minutes between finishing dense training and obtaining the final model. First value is time for optimization, second time spent fine-tuning. Following \gls{qsenn}, we use the \textit{fast} setting for \imgnetheader{}. \gls{qsenn} trains for $70$ epochs, instead of $40$, in total during fine-tuning and does $4$ iterations of \glm{}. Note that every method runs exclusively on a GPU server, except for the QP optimization, which can be done on just a CPU.}
 \label{stab:TimeTable}
 \centering
 \begin{tabular}{l|cc}
  \toprule
  Method 
  & CUB&INET \\
  \midrule
  \slddtable{} & $(15 + 22) + 78 = \textbf{115}$  & $(500 + 3000) + 3600 = 7100$  \\
   \qsenntable{} &$(15 + 4*22) + 78 *7/4 \approx  240$  & $(500 + 4* 100) + 7/4 * 3600 = 7200$  \\\midrule
   \gls{NewlayerName} (Ours) & $210 + 78 = 298$  & $660 + 3600 = \textbf{4260}$  \\ 
  \bottomrule
 \end{tabular}
 \end{table*}
 \section{Impact of Even Sparsity}
 \label{ssec:balancedAbl}
 \begin{table*}[t]
 \caption{Accuracy with or without exactly \gls{nperClass} features per class (\cref{eq:5perInit}). Instead, on average  \gls{nperClass} features per class are used.}
 \label{stab:evenConstrR}
 \centering
 \begin{tabular}{l|cc}
  \toprule
  Method 
  & CUB&CARS \\
  \midrule
  without \cref{eq:5perInit} & 84.3$\pm0.2$   & 91.6$\pm0.3$   \\
   \gls{NewlayerName} (Ours) & \textbf{85.1}$\pm0.3$   &\textbf{ 91.8}$\pm0.1$   \\ 
  \bottomrule
 \end{tabular}
 \end{table*}
 \begin{figure*}[t]
  \centering
\includegraphics[width=.5\linewidth]{plots/AListedAvgC-IperClass.png}

   \caption{Average Class-Independence of Assigned Features on \cubheader{} as function of the number of features assigned to the class. The distribution of the sparsity is shown in \cref{sfig:densityS}.}
  \label{sfig:CIOverNWC}
\end{figure*}
 \begin{figure*}[t]
  \centering
\includegraphics[width=.5\linewidth]{plots/AX.png}

   \caption{Distribution of Nonzero Weights per Class on \cubheader{}. For each method, all $1000$ classes from $5$ seeds are shown.}
  \label{sfig:densityS}
\end{figure*}
 This section discusses the impact of enforcing exactly \gls{nperClass} features per class, rather than on average. 
 For that, we trained a model without this constraint, but instead with $\boldsymbol{1}^T\wgurobi\fvecgurobi=\gls{nperClass}\gls{nClasses}$ enforcing an average sparsity.
 To counteract the uneven number of features per class, every class got a bias, that is linear to the number of features it is below the average.
 In prior experiments, various forms of counteracting the uneven assignment with a bias have performed similarly.
 \Cref{stab:evenConstrR} shows that the even assignment is beneficial for the accuracy.
 Further, the even assignment boosts interpretability as it leads to more classes that can be contrasted easily and does not introduce an unintuitive bias term. 
 Additionally, \cref{sfig:CIOverNWC} demonstrates that classes, which are assigned to fewer features, cause these features to become less general for QPM and Q-SENN, which hurts interpretability and potentially accuracy.
 \Cref{sfig:densityS} also visualizes that Q-SENN always learns to represent classes with a huge variety in the number of assigned features, necessarily leading to hardly interpretable representations.
 Nevertheless, the impact is disparate on the two datasets and the accuracy  increase is not significant on \stanfordheader{}. 
 Future work might investigate if datasets with classes of varying complexity will benefit from representing classes with a suitable number of features and how this can be combined with contrastive globally interpretable class representations.

\section{Polysemantic Features}
\label{ssec:poly}
 \begin{figure*}[t]
  \centering
\includegraphics[width=.5\linewidth]{plots/EyeColorAlignment.png}

   \caption{Feature Alignment metric from Q-SENN~\cite{norrenbrock2024q} for the red-eye feature (marked in red) in \cref{fig:CubSim} and the attribute red eye color $r_{red-eye} (x)$. The x-axis describes to which samples the computation is limited, e.g. $x=2$ describes computing the metric only on samples whose label is represented using up to $2$ other features. On the right, $x=5$ refers to the usual global feature alignment. The probed QPM learned a polysemantic, but locally monosemantic feature. When differentiating between bronzed and shiny cowbird only ($x=1$), the feature value increased by almost $4$ times its mean, if the attribute is annotated to be present.}
  \label{sfig:Alignment}
\end{figure*}
This section discusses the phenomenon of polysemantic features and how it relates to QPM.
Like all deep learning models~\citep{scherlis2022polysemanticity} not specifically designed to prevent polysemanticity, QPM learns polysemantic features.
It refers to individual neurons activating on not just one concept $c$ but rather on $n$ seemingly unrelated ones.
While it is an active area of research, their emergence can likely be attributed to being an effective solution to the training objective.
On many training samples, the impact on the loss can be fairly low, if a polysemantic feature activates on any of its $n$ meanings. 
The only exception occurs, when it activates on samples, where its activation contributes significantly to a class that is already showing a lot of activation.
While this is typically very difficult to analyze, the interpretable structure of QPM can offer more insights, as it enables a reliable metric on which to gauge how strongly the activation on another concept would affect the loss: The similarity in QPM's class representation space. Our hypothesis is that QPM learns features that are locally monosemantic, while being globally polysemantic. Around a class, e.g., Bronzed Cowbird, we expect the features to only activate on one of the $n$ concepts that they activate on across the entire dataset. 
As this is generally fairly difficult to measure, we show anecdotal evidence for this in \cref{sfig:Alignment}. 
It shows the Feature Alignment metric from \gls{qsenn}\citep{norrenbrock2024q} relative to the similarity to the Bronzed Cowbird, measured as the number of its features that classes do not share. 
Specifically, given the training features \glspl{trainFeatures},
\begin{align}
    \gtmatrix_{a,j}&=
\frac{1}{\lvert\attributeset{a+}\rvert }\sum_{i\in\attributeset{a+}}\glspl{trainFeatures}_{i,j}- \frac{1}{\lvert\attributeset{a-}\rvert}\sum_{i\in\attributeset{a-}}\glspl{trainFeatures}_{i,j}
\end{align}
describes the average difference in activations when an annotated attribute is present, encoded in \attributeset{a+} or \attributeset{a-} for absent.
\cite{norrenbrock2024q} then scales the difference by the average zero based activation and reports the average maximum per feature:
\begin{align}
    r = \frac{1}{\gls{nReducedFeatures}}\sum_{j=1}^{\gls{nReducedFeatures}} \frac{\gls{nTrainImages}}{\sum_{l=1}^{\gls{nTrainImages}}\glspl{trainFeatures}_{l,j}- \min_{l}\glspl{trainFeatures}_{l,j} }\max_{i} \gtmatrix_{i,j}.
\end{align}
For our analysis, we limit these formulas to just the attribute red eye color $red-eye$ and only consider the one feature $k$ detecting it for Bronzed Cowbird:
\begin{align}
    r_{red-eye} (x) = \frac{\gls{nTrainImages}}{\sum_{l=1}^{\gls{nTrainImages}}\glspl{trainFeatures}_{l,k}- \min_{l}\glspl{trainFeatures}_{l,k} }\gtmatrix_{red-eye,k}(x).
\end{align}
The x-axis additionally describes a filtering applied to the features and attributes based on the similarity of the label, where a sample is considered for computing $\gtmatrix_{red-eye,k}(x)$ if the annotated label shares at least $5-x$ features with Bronzed Cowbird.
\Cref{sfig:Alignment} demonstrates that the feature clearly detecting the red eye of the Bronzed Cowbird is indeed quite sensitive to its presence when the ground truth label is similar to the class, while it globally loses that sensitivity as it also detects other concepts of classes further away from Bronzed Cowbird.

\section{Structural Grounding on ImageNet}
\label{ssec:imgsim}
This section is concerned with evaluating a metric similar to \cubsim{} on \imgnetheader{}.
It is based on comparing the class similarities in reality  $\boldsymbol{\mathrm{\ClassSim}}^{gt}$ with the $\boldsymbol{\mathrm{\ClassSim}}^{Model}$ ones learned by our model.
\cubsim{} relies on the annotations of \cubheader{} to compute $\boldsymbol{\mathrm{\ClassSim}}^{gt}$. However, there are no such annotations on a fine-grained scale for \imgnetheader{}.
Therefore, we use the similarity of the text-names in CLIP~\citep{radford2021learning} as proxy to obtain our ground-truth class similarities. 
Specifically, we compute the cosine similarity $\boldsymbol{\mathrm{\ClassSim}}^{clip}\in[-1,1]^{\gls{nClasses}\times\gls{nClasses}}$  between the text embeddings of the class names, obtained from the powerful pretrained \textit{ViT-L-14}, that is broadly used, e.g. to condition Stable Diffusion XL\cite{podell2023sdxl}. 
We always take the first description given for every class.

When inspecting the most similar classes, several issues are apparent. 
Many of them include shared tokens or words, e.g., \textit{ski} and \textit{ski mask}, \textit{lion} and \textit{sea lion}, \textit{rule} and \textit{stole} or \textit{digital clock} and \textit{wall clock}. While some of these indeed describe a similar class, e.g., \textit{giant Schnauzer} and \textit{Standard Schnauzer}, others do not. 
Including classes without high similarity as ground-truth similar classes harms the quality of the evaluation drastically and demonstrates the value of having human annotations.
Another issue in the clip similarities is that fine-grained knowledge about the classes seems to be less dominant than literal exact matching, as with higher similarity only more commonly used terms are correctly associated with similar terms,  e.g., \textit{Orangutan} and \textit{Gorilla}, but not \textit{Rottweiler} and \textit{Doberman}. Therefore, the number of similar classes to consider is set to $1250$, as the latter pair ranks at position $828$ and we definitely consider it as a similarity worth measuring.
Notably, this pair is ranked behind pairs such as \textit{hog} and \textit{tank},  \textit{lemon} and \textit{yawl} or \textit{hamster} and \textit{snail}, further demonstrating the weakness of the language model to exactly model the similarities.
The final apparent issue lies in the ambiguity of class names which leads to \textit{crane} appearing twice as class name, once referring to birds, once to a machine on a construction site.
Notably, the distribution of class sparsity has significant impact. While QPM is limited to a class similarity of up to $80\%$, due to deviating in at least one feature with all features sharing the same weight and every class being represented by $\gls{nperClass}=5$ features, \gls{layerName}, \gls{qsenn} and \glmtable{} all exhibit multiple (14, 9 and 5) class pairs, that have a class similarity of above $99\%$. 
The \gls{layerName} for instance repeatedly represents classes with one feature with positive weight and one with an extremely low negative weight, resulting even in cosine similarities of $1$ due to floating point precision. While this generally hurts interpretability, it can be beneficial for \cubsim{}.

Despite these issues, \Cref{stab:imgStruct} shows that QPM still performs comparatively to \gls{layerName} and \gls{qsenn} with their extremely high similarities and learns significantly more aligned representations than the dense baseline, even on \imgnetheader{}.
Future work might incorporate a more fine-grained class hierarchy, building upon the very general WordNet, into this metric or profit off of further improved language models.
\begin{table*}[t]
 \caption{Results for \oldloc{5}~\citep{norrenbrocktake} demonstrating its weakness to capture the locality of the by-design very local features of PIP-Net. Note that $20$ is the worst possible value.}
 \label{stab:oldloc5}
 \centering
 \begin{tabular}{l|cc}
  \toprule
  Method 
  & CUB&CARS \\
  \midrule
  Baseline \resnet{}& 61.1$\pm$0.4 &57.4$\pm$0.3\\
  \hline
  \glmtable{} & 55.3$\pm$0.5 &52.6$\pm$0.3  \\
  \pipnettable{} & 20.5$\pm$0.0 & 20.5$\pm$0.0  \\ 
  \protopooltable{} & 25.5$\pm$0.4  &23.4$\pm$0.5 \\
  \slddtable{} & 79.2$\pm$0.3 & 81.9$\pm$0.9 \\
  \qsenntable{}& 87.0$\pm$0.5 & 89.6$\pm$0.3 \\
  \midrule
   \gls{NewlayerName} (Ours) & \textbf{89.9}$\pm$0.2   &\textbf{ 91.4}$\pm$0.3 \\ 
  \bottomrule
 \end{tabular}
 \end{table*}
 \begin{table*}[t]
 \caption{Structural Grounding based on Clip Similarities on ImageNet}
 \label{stab:imgStruct}
 \centering
\begin{tabular}{l|c}
  \toprule
  Method & \cubsim{} \\
  \midrule
  Dense Resnet50 &  17.9$\pm0.0$  \\
  \glmtable{}& 10.3$\pm0.0$   \\
  \gls{layerName} & \textbf{36.9}$\pm$0.4  \\ 
  \qsenntable{} & 33.2$\pm$0.2 \\
  \midrule
\gls{NewlayerName} (Ours) & \underline{34.5}$\pm0.6$\\
  \bottomrule
 \end{tabular}
 \end{table*}
\section{Impact of Class-Feature Similarity Metric}
\label{ssec:auroc}
This section contains an ablation study on the choice of Pearson correlation as metric for the feature-class similarity matrix \simmat. 
While it captures the desired linear relationship, that is also utilized during the following predictions, an intuitive alternative is the Area under the receiver operating characteristic curve (AUROC), which is  highly non-linear and frequently used to capture the predictive power with a varying threshold.
\Cref{stab:auroctab} shows that AUROC is also suitable but inferior to the simple correlation.
 \begin{table*}[t]
 \caption{Accuracy with different criteria used as Feature-Class Similarity matrix \simmat{}}
 \label{stab:auroctab}
 \centering
\begin{tabular}{l|cc}
  \toprule
  \simmat{} Metric 
  & CUB&CARS \\
  \midrule
  AUROC & 84.8$\pm0.2$   & 91.6$\pm0.2$   \\
   Correlation (Ours) & \textbf{85.1}$\pm0.3$   &\textbf{ 91.8}$\pm0.1$   \\ 
  \bottomrule
 \end{tabular}
 \end{table*}
\section{Limitations and Future Work}
\label{ssec:limits}
This section discusses limitations for the proposed QPM and avenues for future work.

In this work, QPM is applied to the generally available 
 and typical datasets for image classification, with \imgnetheader{} indicating broad applicability.
However, QPM's high interpretability is especially beneficial for high-stakes applications such as the medical domain or autonomous driving, where each individual situation can not be accessed by an expert.
Rather, after training the QPM and before deploying it to cars, its class explanations can be obtained to gain insights into whether it is right for the right reasons and if these are robust to all deployment conditions.
Thus, applying QPM to suitable high-stakes applications is a promising avenue for future work.
However, to our knowledge, there is no suitable dataset from these domains published yet. 

A limitation of our QPM in its current form lies in its inability to model negative assignments.
Compared to the \gls{layerName} and \gls{qsenn}, which use negative weights, it is evident that the varied datasets used in this paper, do not require it. 
Further, while we believe that it is generally preferable to represent classes only using positive assignments, as e.g., also done by recent prototypical models~\citep{nauta2023pipnet, rymarczyk2022interpretable}, one can think of other datasets where negative reasoning may be superior.
If, e.g., all classes in a  dataset containing birds had a black beak, except for one with all other colors, it would likely be the most efficient solution to represent that one with a negative assignment on a feature activating on black beaks, rather than have every other class positively assigned to it, which the current QPM might do.
Thus, future work may incorporate negative assignments into the optimization, which might lead to even more compact representations.

As discussed in \cref{ssec:poly}, the learned features of our QPM are generally polysemantic, while potentially being monosemantic locally. 
For aligning them with human concepts, all post-hoc methods, such as TCAV~\citep{kim2018interpretability}, Clip-Dissect~\citep{oikarinen2023clipdissect}, or the alignment methods from \gls{layerName} or \gls{qsenn} can be applied.
Notably, aligning a feature with their human concepts is more beneficial for QPM than it is for e.g., black-box models, as they are used in an intuitively interpretable way. 
Further, the interpretable assignment can even help with alignment, as shown in \cref{ssec:poly}.
Nevertheless, polysemantic features are a challenge for interpretability and future work in this direction can focus on preventing their emergence while still using them in an interpretable way or robustly measuring alignment to multiple concepts.

For many explanations from our QPM, a saliency map for its individual features is used.
While we typically just visualize each individual feature map via upscaling, resulting in a comparable resolution to GradCAM~\citep{selvaraju2020grad}, other saliency methods, like Integrated Gradients~\citep{sundararajan2017axiomatic}, LRP~\citep{binder2016layer} or RISE~\citep{Petsiuk2018rise} can be applied.
Because QPM is backbone independent, even models with built-in more faithful saliency maps such as B-cos Networks~\citep{bohle2023holistically} can be used.
Since the use of these features is easy-to-interpret, evaluating the localizations of our model should focus on the feature explanations rather than class-level ones. 
Future work might incorporate these faithful saliency maps to measure insertion or deletion methods, akin to those used for class-level saliency maps~\citep{Petsiuk2018rise}.
Ideally, one is able to overcome the issue of moving out-of-distribution with removing pixels~\citep{hooker2019benchmark}.
Finally, the contrastive nature of QPM's features might lead to an intuitive threshold that can be used during the removal of pixels, similar to how previous metrics try to change the class prediction.
\section{Detailed Results}
\label{suppsec:Results}
This section contains detailed results with standard deviations, including experiments with 
Resnet34, \gls{incv}, Swin-Transformer-small and Swin-Transformer-tiny,
in \suppl{} \cref{stab:noCrop} to 
\cref{tstab:incInterpproto-table}.
The good results across architectures demonstrate an independence between backbone and our proposed method.
They further seem robust as the difference in mean is usually large compared to the standard deviation. 
Further, \cref{fig:rottweilerS,fig:dobermanS} show how the features of \cref{fig:metrics_full} continue to localize on the same human attribute across different poses.
Additionally, we included the activations of these features on images of another class in \cref{fig:blacktanS} to showcase the global interpretability enabled through the binary assignment of more interpretable features. 
Instead of the blue and green feature, this probed \gls{NewlayerName} recognizes the Black and Tan Coonhound through both doberman-like and rottweiler-like head features, as well as a neck that is also assigned to pandas or bears.
\Cref{fig:stanfordRep,fig:TravRep} additionally include examples for contrastive class representations learned on \stanfordheader{} and \travelingheader{}.
Finally, \cref{stab:oldloc5} contains results for \oldloc{5}, to quantify its inability to capture the high spatial diversity of PIP-Nets class detectors.
\section{Feature Diversity Loss}
\label{suppsec:ldiv}
This section further describes the Feature Diversity Loss~\gls{customLoss}, proposed in \cite{norrenbrocktake}.
It is defined per sample, for which the model predicted the
class $\hat{c}= \arg\max(\gls{outputVector})\label{eq:MaxClassDiv}$ and ensures a local diversity of the used feature maps \Gls{featureMaps}.
\begin{align}
\hat{s}^\findex_{ij} &=\frac{\exp(\gls{featureMaps}^\findex_{ij})}{\sum_{i'=1}^{\gls{featuresMapheigth}}\sum_{j'=1}^{\gls{featuresMapwidth}}\exp(\gls{featureMaps}^\findex_{i'j'})} \frac{\glsentrylong{featureVector}_\findex}{\max\glsentrylong{featureVector}}  \frac{|w_{\hat{c},\findex}|}{\Vert\boldsymbol{w}_{\hat{c}}\Vert_2} \label{eq:ScaleDiv}\\
     \gls{customLoss} &= -\sum_{i=1}^{\gls{featuresMapheigth}}\sum_{j=1}^{\gls{featuresMapwidth}}\max(\hat{s}^1_{ij},\hat{s}^2_{ij}, \dots, \hat{s}^{\gls{nFeatures}}_{ij})\label{eq:CCMPDiv}
\end{align}
Equation~\ref{eq:ScaleDiv} employs the softmax function to normalize the entries $\gls{featureMaps}^l_{ij}$ of the feature maps \Glspl{featureMaps} across spatial dimensions. It then scales the maps to emphasize visible and significant features, maintaining the relative mean of \Glspl{featureMaps} while weighting them according to the predicted class.
Equation~\ref{eq:CCMPDiv} then applies cross-channel-max-pooling of the normalized and scaled feature maps $\hat{\textbf{S}}$.
The result is negatively weighted and thus encourages the model to learn features that localize on different image regions.
The resulting total training loss is
\begin{equation}
    \mathcal{L}_{\mathrm{final}} =  \mathcal{L}_{CE} + \gls{cLW}\gls{customLoss},\label{seq:customLossW}
\end{equation} with $\gls{cLW}\in\mathbb{R}_+$ as weighting factor.
\begin{figure*}[t]
  \centering
\includegraphics[width=\linewidth]{plots/AstonMartinsFin.pdf}

   \caption{Faithful global interpretability of our \gls{NewlayerName} trained on \stanfordheader{}{}: 
   Without any additional supervision, 
   \gls{NewlayerName} learns to represent 
   the Convertible and Coupe Variant using  $5$ diverse and general features.}
  \label{fig:stanfordRep}
\end{figure*}
\begin{figure*}[t]
  \centering
\includegraphics[width=\linewidth]{plots/TravFin.pdf}

   \caption{Faithful global interpretability of our \gls{NewlayerName} trained on \travelingheader{}: 
   Without any additional supervision, 
   \gls{NewlayerName} learns to represent 
   the Yellow and Black billed Cuckoo using  $5$ diverse and general features, correctly ignoring the correlated background.}
  \label{fig:TravRep}
\end{figure*}
\section{Optimality of Solution}
\label{suppsec:optimal}
In order to test the optimality of our solution, we try to solve the problem without our relaxation in \cref{eq:NotGLob} with more compute and time.
We used $3$ days and $250$ GB on an AMD EPYC 72F3 to solve the problem globally across $5$ seeds on \cubheader{} with a target gap to optimality of $1\%$ to ensure sufficient deduplication.
The time limit was left to $3$ hours for one iteration, as otherwise multiple iterations would not finish.
Across the $5$ seeds used for \gls{NewlayerName}, the average obtained objective value for the global problem was $0.5\%$ above the one computed with our simplifications.  
Similar to our ablations in \cref{tab:ablations}, the resulting accuracy for the extensively optimized model was not improved, but even $0.1$ percent points lower.
As mentioned in \cref{sec:gurobitricks}, the objective does not perfectly correlate with downstream metrics, as the constants \simmat{}, \FSimeaturemat{} and \BSimeaturemat{} only approximate the desired behaviour.
However, the average gap to the best bound was still $3.2\%$, with only negligible progress during the final iteration, suggesting that a longer time limit would not significantly improve it. 
Note, that the best bound might be violating constraints, already added or not.
In summary, the gap between our easy-to-compute solution and an obtainable solution of the global problem is $0.5\%$, which leads to no improved model, with an upper bound on the gap of $3.7\%$ ($372$ to $386$).

\section{Standard Form for Quadratic Problem}
\label{suppsec:QP}
The quadratic problem, described in \cref{sec:QPMethod}, can be expressed in the standard form for quadratic programming problems.
The aim is to optimize quadratic problems of the form $\frac{1}{2} \mathbf{x}^T \mathbf{Q} \mathbf{x} + \mathbf{c}^T \mathbf{x}$ with respect to specified constraints.
To describe our quadratic problem in standard form, we therefore define the \textbf{variables} $\mathbf{x}$,  $\mathbf{Q}$, $\mathbf{c}$ as well as the \textbf{constraints}.
For notation, \zerovec{x} and \onevec{x} describe a vector with $x$ zeros or ones respectively and \zeromat{m}{n} describes a $m\times n$ matrix of zeros.

\paragraph{Variables}
Let $\mathbf{x}$ be the binary decision variable vector, combining \fvecgurobi{} and the vectorized form of $\mathbf{W}$:
\[
\mathbf{x} = \begin{bmatrix}
\mathbf{\fvecgurobi} \\
\text{vec}(\wgurobi)\\
\end{bmatrix}\in \{0,1\}^{n_f + n_c \cdot n_f}
\]

\paragraph{Objective Function}
The standard objective function includes all objectives:
\[
\text{Maximize:} \quad \frac{1}{2} \mathbf{x}^T \mathbf{Q} \mathbf{x} + \mathbf{c}^T \mathbf{x}
\]
Here
\begin{equation}
    \mathbf{Q} = \begin{bmatrix}
 -\FSimeaturemat & \zeromat{\gls{nFeatures}}{\gls{nFeatures}\cdot \gls{nClasses}}\\ %
\simmat_\mathrm{stack}& \zeromat{\gls{nFeatures}\cdot\gls{nClasses}}{\gls{nFeatures}\cdot \gls{nClasses}}\\% \mathbf{0}_{\gls{nClasses}\cdot\gls{nFeatures},\gls{nFeatures}\cdot \gls{nClasses}} %
\end{bmatrix}
\end{equation}
combines all quadratic objectives and
\begin{equation}
\mathbf{c} =  \begin{bmatrix}
\BSimeaturemat \\
\zerovec{\gls{nFeatures}\cdot \gls{nClasses}}\\
\end{bmatrix}    
\end{equation}
the linear term.
Here
\begin{equation}
\simmat_\mathrm{stack} =  \begin{bmatrix}
diag(\boldsymbol{a}_1) \\
diag(\boldsymbol{a}_2)  \\
\vdots\\
diag(\boldsymbol{a}_{\gls{nClasses}}))
\end{bmatrix}    
\end{equation}
connects the vectorized entries of \wgurobi{} with \simmat{}.

\paragraph{Constraints}
\begin{enumerate}
    

\item  Constraint for the number of selected features (\cref{eq:FeatureSel}):
\begin{equation}
\begin{bmatrix}
\onevec{\gls{nFeatures}}\\ \zerovec{\gls{nFeatures}\cdot \gls{nClasses}}\\
\end{bmatrix}^T
\mathbf{x} = \gls{nReducedFeatures}%
\end{equation}
\item No assignments on unselected features:
\begin{align}
  \begin{bmatrix} 
  \boldsymbol{\mathrm{featureSum}} &
\zerovec{\gls{nFeatures}\cdot\gls{nClasses}}
\end{bmatrix}
(\onevec{\gls{nFeatures}\cdot(\gls{nClasses}+1)}-\mathbf{x}) =0 \\
\boldsymbol{\mathrm{featureSum}} = 
  \begin{bmatrix} 
 \zeromat{\gls{nFeatures} }{\gls{nFeatures}} &
\mathrm{\boldsymbol{FeatureSel}}^{\gls{nFeatures} }
\end{bmatrix}
\mathbf{x}
\end{align}
where $\boldsymbol{\mathrm{FeatureSel}}^{\gls{nFeatures} }\in\{0,1\}^{\gls{nFeatures}\times\gls{nFeatures}\cdot\gls{nClasses}}$ is a matrix of zeros with $\mathrm{FeatureSel}_{i,j}=1$ where $(j-i)\mod\gls{nFeatures}=0$.
The vector
$\boldsymbol{\mathrm{featureSum}}$ captures the total number of assignments per feature.
\item  Constraint for the number of assignments per class (\cref{eq:5perInit}):

\begin{equation}
\begin{bmatrix}
\zeromat{\gls{nClasses}}{\gls{nFeatures}}
& \mathrm{\boldsymbol{UBD}}^{\gls{nClasses},\gls{nFeatures} } %
\end{bmatrix}
\mathbf{x} =\gls{nperClass} \cdot \onevec{ \gls{nClasses}}  %
\label{eq:5perclass}
\end{equation}

Where the upper block diagonal matrix
\begin{equation}
  \mathrm{\boldsymbol{UBD}}^{\gls{nClasses},\gls{nFeatures} } = \begin{bmatrix}
\onevec{ \gls{nFeatures}} & \zerovec{ \gls{nFeatures}} & \cdots & \zerovec{ \gls{nFeatures}}  \\
\zerovec{ \gls{nFeatures}} & \onevec{ \gls{nFeatures}} & \cdots  & \zerovec{ \gls{nFeatures}} \\
\vdots & \vdots & \vdots &\vdots &\\
\zerovec{ \gls{nFeatures}} & \zerovec{ \gls{nFeatures}} & \cdots & \onevec{ \gls{nFeatures}}  \\
\end{bmatrix}^T
\end{equation}
is
a block-diagonal matrix with \gls{nFeatures} ones per row, one $1$ in each of the $\gls{nFeatures}\cdot\gls{nClasses}$ columns and \gls{nClasses} total rows.
\item No duplicated classes (\cref{eq:Unique}):%
\begin{align}
  \begin{bmatrix} 
  \boldsymbol{Eq}^{\cindex,\cindex'} &
\zerovec{\gls{nFeatures}\cdot\gls{nClasses}}
\end{bmatrix}
\onevec{\gls{nFeatures}\cdot(\gls{nClasses}+1)} > 0 \quad \forall \cindex \neq \cindex ' &\in \{1, \dots,\gls{nClasses}\}\\
\boldsymbol{Eq}_\findex^{\cindex,\cindex'} = |\boldsymbol{x}_{\cindex\cdot\gls{nFeatures} + \findex} -
 \boldsymbol{x}_{\cindex'\cdot\gls{nFeatures} + \findex}| \quad \forall \findex &\in \{1, \dots,\gls{nFeatures}\}
\end{align}



\end{enumerate}
  


  
  
  

  
  
\begin{table*}[t]
 \caption{Accuracy without background removal based on the Ground-Truth with \resnet{}. \gls{NewlayerName} is less susceptible to the spuriously correlated backgrounds with and without Center Bias $\BSimeaturemat{}^{\mathrm{Center}}$. NA indicates no convergence.}
 \label{stab:noCrop}
 \centering
 \begin{tabular}{l|cc}
  \toprule
  Method 
  & CUB& TRAVEL 
  \\
  \midrule
  Baseline \resnet{}& 84.2$\pm$0.3 & 33.8$\pm$0.6\\
  \midrule
  \glmtable{}& 75.0$\pm$0.9 & 35.6$\pm$1.4 \\
  \pipnettable{} & 74.9$\pm$0.0 & 59.4$\pm$1.0 \\ %
  \protopooltable{}& 75.0$\pm$0.3 & NA \\
  \slddtable{} & 82.2$\pm$0.1 & 62.6$\pm$1.6 \\
   \qsenntable{} & \underline{82.8}$\pm$0.3  & \underline{67.0}$\pm$0.5  \\\midrule
   \gls{NewlayerName} (Ours) & \textbf{82.9}$\pm$0.1 & {64.7}$\pm$0.7 \\
  w/ Center Bias   $\BSimeaturemat{}^{\mathrm{Center}}$ & {82.4}$\pm$0.3 & \textbf{68.9}$\pm$0.5 \\
  \bottomrule
 \end{tabular}

 
 \end{table*}
 
 \begin{table*}[htbp]
 \caption{Ablation Studies investigating the impact of incorporating feature-feature similarity through \FSimeaturemat{} and locality bias \BSimeaturemat{} on \cubheader{} with \resnet{}.%
 }
 \label{stab:ablations}
 \centering
 \begin{tabular}{l|c|ccc}
  \toprule
 \BSimeaturemat & \FSimeaturemat 
   & Accuracy \arrowUp& \loc{5} \arrowUp & Correlation \arrowDown\\% & Objective $Z_m$ ( \cref{eq:mainObj}) \arrowUp\\
  
  \midrule
 
 \xmark & \xmark & 84.6$\pm$0.4 & 89.5$\pm$0.2 & 33.9$\pm$0.8 \\ 
 
 \cmark & \xmark & 84.4$\pm$0.2 & \textbf{90.4}$\pm$0.3 & 33.5$\pm$9.4 \\ 
  \xmark & \cmark & \underline{85.0}$\pm$0.3 & 89.4$\pm$0.3 & \textbf{22.7}$\pm$1.1 \\%& 373\\
   \midrule
   \cmark & \cmark &
   \textbf{85.1}$\pm$0.3 & \underline{90.1}$\pm$0.3 & \underline{24.6}$\pm$1.1\\% & 372\\

  
   \bottomrule
 \end{tabular}

\end{table*}


\begin{figure*}[t]
  \centering
  \includegraphics[width=.9\linewidth]{plots/Rottweiler3_SeperatedActivationXYRottweiler_6}
 
  \caption{Exemplary Activations of Features in ~\cref{fig:metrics_full} on further Rottweiler images. 
The feature values after normalization are written on the images.
Note that all shown activations are scaled from 0 to 1, resulting in an arbitrary localization of the brown feature detecting the Doberman-like head.}
  \label{fig:rottweilerS}
\end{figure*}
\begin{figure*}[t]
  \centering
  \includegraphics[width=.9\linewidth]{plots/Doberman3_SeperatedActivationXYDoberman_6}
 
  \caption{Exemplary Activations of Features in ~\cref{fig:metrics_full} on further Doberman images. 
The rounded feature values after normalization are written on the images.
Note that all shown activations are scaled from 0 to 1, resulting in an arbitrary localization of the red feature detecting the Rottweiler-like head.}
  \label{fig:dobermanS}
\end{figure*}
\begin{figure*}[t]
  \centering
  \includegraphics[width=.9\linewidth]{plots/black-and-tancoonhound3_SeperatedActivationXYblack-and-tancoonhound_6.png}%
 
  \caption{Exemplary Activations of Features in ~\cref{fig:metrics_full} on Black and Tan Coonhound images. 
The rounded feature values after normalization are written on the images.
Note that all shown activations are scaled from 0 to 1, resulting in an arbitrary localization of the two not assigned and barely activated blue and green features. The fifth assigned feature is shared with dog types such as  Newfoundlands, bears and pandas, localizing on the neck region.}
  \label{fig:blacktanS}
\end{figure*}
\begin{sidewaysfigure}
     \centering\includegraphics[width=\linewidth]{plots/ScreenshotShinyvsBronzed.png}
     \caption{
     Screenshot of the Cornell-Lab website~\citep{Sullivan}, describing how the similar species shiny and bronzed cowbird differ:
     The only differences explained are in the size, which is not usable for our \gls{NewlayerName} due to cropping, and the eye color, which our \gls{NewlayerName} learned without any supervision and explained  in \cref{fig:CubSim} as the differentiating factor.}
     \label{fig:ScreenshotDiffShiny}
\end{sidewaysfigure}
\input{sec/SidewaysTables}
