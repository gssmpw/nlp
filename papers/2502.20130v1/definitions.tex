\newcommand{\bldStatement}{. Best results are in bold.}
\newcommand{\firstTablespot}{}

\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\todo}[1]{{\color{red}#1}}
\newcommand{\unsuremark}{\textbf{\textasciitilde}}
\newcommand{\dependence}{\ensuremath{\gamma}}
\newcommand{\TODO}[1]{\textbf{\color{red}[TODO: #1]}}
\newcommand{\helperindex}[1]{\ensuremath{\mathbf{h}^{#1}}}
\newcommand{\vspacehack}{\vspace{-.9mm}}
\newcommand{\cindex}{\ensuremath{ c}} %
\newcommand{\findex}{\ensuremath{d}} %
\newcommand{\cmark}{\textcolor{green}{\ding{51}}}%
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}%
\newcommand{\imgsunl}{62.2}%
\newcommand{\imgfunl}{76.7}%
\newcommand{\imgsl}{44.8}%
\newcommand{\imgfl}{72.8}%
\newcommand{\sparsemat}{\ensuremath{\gls{WeightMatrix}^{\mathrm{sp}}}}
\newcommand{\sparsematn}[1]{\ensuremath{\gls{WeightMatrix}_#1^{\mathrm{sp}}}}
\newcommand{\psoln}[1]{\ensuremath{(\gls{WeightMatrix}_#1^{\mathrm{sparse}},\gls{bias}_#1)}}
\newcommand{\fullheader}{\input{tableheader}}
\newcommand{\fullablheader}{\input{ablheader}}
\newcommand{\bbheader}{\input{backboneheader}}
\newcommand{\lossheader}{\input{Lossheader}}
\newcommand{\cLWheader}{\input{clWheader}}
\newcommand{\fgvcheader}{\gls{fgvcheader}}
\newcommand{\stanfordheader}{\gls{stanfordheader}}
\newcommand{\cubheader}{\gls{cubheader}}
\newcommand{\travelingheader}{\gls{travelingheader}}
\newcommand{\imgnetheader}{\gls{imgnetheader}}
\newcommand{\birdsheader}{\gls{birdsheader}}
\newcommand{\inpercent}{ in percent}
\newcommand{\imgbldStatement}{ for \resnet{} on \imgnetheader{} using the pretrained dense model.}





\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

    
\newglossaryentry{customLoss}
{
name={\ensuremath{\mathcal{L}_{\mathrm{div}}}},
description={Custom Loss f端r unterschiedliche Features}
}
\newglossaryentry{cLW}
{
name={\ensuremath{\beta}},
description={Gewichtung f端r customLoss}
}
\newglossaryentry{elaWeight}
{
name={\ensuremath{\lambda}},
description={Gewichtung f端r elasticNet}
}
\newglossaryentry{elaW}
{
name={\ensuremath{\alpha}},
long = {\ensuremath{\alpha\in[0,1]}},
description={Gewichtung zwischen l1 und l2 f端r elasticNet}
}
\newglossaryentry{trainDataset}
{
name={\ensuremath{\boldsymbol{D}_t}},
first = {\ensuremath{\boldsymbol{D}_t\in \mathbb{R}^{\gls{nTrainImages}\times 3\times w\times h}}},
description={LokalisierungMaps mit Missingness}
}
\newglossaryentry{nFeatures}
{
name={\ensuremath{n_{f}}},
description={Anzahl der verwendeten Features}
}
\newglossaryentry{nReducedFeatures}
{
name={\ensuremath{\gls{nFeatures}^*}},
description={Anzahl der verwendeten Features im Sparse Decision Layer}
}
\newglossaryentry{outputVector}
{
name={\ensuremath{\boldsymbol{y}}},
long = {\ensuremath{\boldsymbol{y}\in \mathbb{R}^{\gls{nClasses}}}},
description={Finaler Ausgang des Netzes}
}
\newglossaryentry{features}
{
name={\ensuremath{\boldsymbol{f}}},
description={Aus Bild berechnete Features}
}
\newglossaryentry{LocalizationMaps}
{
name={\ensuremath{\boldsymbol{L}}},
long = {\ensuremath{\boldsymbol{L}_p}\in \mathbb{R}^{\gls{nReducedFeatures}\times \frac{w}{p}\times \frac{h}{p}}},
description={LokalisierungMaps mit Missingness}
}
\newglossaryentry{featuresMapwidth}
{
name={\ensuremath{ w_M}},
description={Weite der FeatureMap}
}
\newglossaryentry{featuresMapheigth}
{
name={\ensuremath{ h_M}},
description={Weite der FeatureMap}
}
\newglossaryentry{featureMaps}
{
first ={\ensuremath{\boldsymbol{M} \in \mathbb{R}^{\gls{nFeatures} \times \gls{featuresMapwidth}\times \gls{featuresMapheigth}}}},
name={\ensuremath{m}},
plural={\ensuremath{\boldsymbol{M}}},
description={Aus Bild berechnete Features}
}
\newglossaryentry{featureMapsSmall}
{
first ={\ensuremath{\boldsymbol{M} \in \mathbb{R}^{\gls{nReducedFeatures} \times \gls{featuresMapwidth}\times \gls{featuresMapheigth}}}},
name={\ensuremath{m}},
plural={\ensuremath{\boldsymbol{M}}},
description={Aus Bild berechnete Features}
}
\newglossaryentry{featureMapsTrain}
{
first ={\ensuremath{\boldsymbol{M}_\mathrm{train} \in \mathbb{R}^{\gls{nTrainImages}\times\gls{nFeatures} \times \gls{featuresMapwidth}\times \gls{featuresMapheigth}}}},
name={\ensuremath{m}},
plural={\ensuremath{\boldsymbol{M}}_\mathrm{train}},
description={Aus Bild berechnete Features}
}
\newglossaryentry{trainFeatures}
{
first ={\ensuremath{\boldsymbol{F} \in \mathbb{R}^{\gls{nTrainImages} \times \gls{nFeatures}}}}, %
name={\ensuremath{\boldsymbol{F}^{\mathrm{train}}}},
plural = {\ensuremath{F^{\mathrm{train}}}},
description={Aus Bild berechnete Features}
}
\newglossaryentry{denseNet}
{
first = {DenseNet121~\citep{huang2017densely}},
name ={DenseNet121},
description={Final layer in the neural network}
}
\newglossaryentry{resNet}
{
first = {Resnet50~\citep{he2016deep}},
name ={Resnet50},
description={Final layer in the neural network}
}
\newglossaryentry{incv}
{
first = {Inception-v3~\citep{szegedy2016rethinking}},
name ={Inception-v3},
description={Final layer in the neural network}
}
\newglossaryentry{birdsheader}
{
first = {NABirds~\citep{7298658}},
name = {NABirds},
description={Final layer in the neural network}
}
\newglossaryentry{fgvcheader}
{
first = {FGVC-Aircraft~\citep{FGVCAircraft}},
name={FGVC-Aircraft},
description={Final layer in the neural network}
}
\newglossaryentry{stanfordheader}
{
first = {Stanford Cars~\citep{StanfordCars}},
name={Stanford Cars},
description={Final layer in the neural network}
}
\newglossaryentry{cubheader}
{
first = {CUB-2011~\citep{wah2011caltech}},
long = {CUB-2011~\citep{wah2011caltech}},
name={CUB-2011},
description={Final layer in the neural network}
}
\newglossaryentry{travelingheader}
{
first = {TravelingBirds~\citep{koh2020concept}},
long = {TravelingBirds~\citep{koh2020concept}},
name={TravelingBirds},
description={Final layer in the neural network}
}
\newglossaryentry{decisionLayer}
{
name={decision layer},
description={Final layer in the neural network}
}
\newglossaryentry{fittingLossTarget}
{
name={\ensuremath{\mathcal{L}_{\mathrm{target}}}},
description={Main goal of fitting}
}
\newglossaryentry{layerName}
{
name ={\textit{SLDD-Model}},
first ={\textit{SLDD-Model}~\citep{norrenbrocktake}},
description={The proposed benchmark}
}
\newglossaryentry{NewlayerName}
{
name ={QPM},%
description={The proposed benchmark}
}
\newglossaryentry{denseLayer}
{
name={{dense high-dimensional \gls{decisionLayer}}},
description={The layer that results from training}
}
\newglossaryentry{correlationMatrix}
{
name={\ensuremath{\boldsymbol{Q}}},
first = {\ensuremath{\boldsymbol{Q}\in \mathbb{R}^{\gls{nFeatures}\times\gls{nFeatures}}}},
long = {\ensuremath{q}},
description={Correlation Matrix}
}
\newglossaryentry{featureVector}
{
name={\ensuremath{f}},
long={\ensuremath{\boldsymbol{f}}},
first ={\ensuremath{\boldsymbol{f} \in \mathbb{R}^{\gls{nFeatures}}}},
description={The features of the dense alyer}
}
\newglossaryentry{RedfeatureVector}
{
name={\ensuremath{\boldsymbol{f^*}}},
first ={\ensuremath{\boldsymbol{f^*} \in \mathbb{R}^{\gls{nReducedFeatures}}}},
description={The selected feature Vector}
}
\newglossaryentry{OnlyInteractionVector}
{
name={\ensuremath{\boldsymbol{P}}},
long={\ensuremath{\boldsymbol{P} \in \mathbb{R}^{ \gls{nInteractions}}}},
description={The Interaction Vector}
}
\newglossaryentry{InteractionVector}
{
name={\ensuremath{\boldsymbol{f^*_{\phi}}}},
first ={\ensuremath{\boldsymbol{f^*_{\phi}} \in \mathbb{R}^{\gls{nReducedFeatures} + \gls{nInteractions}}}},
description={The Extended Interaction Vector}
}
\newglossaryentry{nInteractions}
{
name={\ensuremath{n_I}},
description={number of interaction term}
}
\newglossaryentry{dnn}
{
name={\ensuremath{f_\theta(x})},
description={Deep neural network}
}

\newglossaryentry{bias}
{
name={\ensuremath{\boldsymbol{b}}},
long ={\ensuremath{\boldsymbol{b} \in \mathbb{R}^{\gls{nClasses}}}},
description={The bias in the decison layer}
}
\newglossaryentry{classifyFunc}
{
name={\ensuremath{C}},
description={The classifier on the featuers}
}
\newglossaryentry{WeightMatrix}
{
name={\ensuremath{\boldsymbol{W}}},
long = {\ensuremath{\boldsymbol{W}\in \mathbb{R}^{\gls{nClasses}\times \gls{nReducedFeatures} }}},
plural = {\ensuremath{w}},
description={The Weight matrix in the decision layer}
}
\newglossaryentry{qWeightMatrix}
{
name={\ensuremath{\boldsymbol{W}^{Q}}},
first ={\ensuremath{\boldsymbol{W}^{Q}\in \{-\alpha,0,\alpha\}^{\gls{nClasses}\times \gls{nReducedFeatures} }}},
long = {\ensuremath{\boldsymbol{W}^{Q}\in \{-\alpha,0,\alpha\}^{\gls{nClasses}\times \gls{nReducedFeatures} }}},
plural = {\ensuremath{w}},
description={The Weight matrix in the decision layer}
}


\newglossaryentry{nClasses}
{
name={\ensuremath{n_c}},
description={Number of Classes}
}
\newglossaryentry{nTrainImages}
{
name={\ensuremath{n_T}},
description={Number of Train Images}
}
\newglossaryentry{nWeights}
{
name={\ensuremath{n_w}},
description={Number of Entries != 0 in \gls{WeightMatrix}}
}
\newglossaryentry{nperClass}
{
name={\ensuremath{n_{\mathrm{wc}}}},
description={Number of Entries != 0 in \gls{WeightMatrix} per Class}
}
\newglossaryentry{interpTrans}
{
name={\ensuremath{\phi}},
description={Interpretable Transformation}
}
\newglossaryentry{quantizedValue}
{
name={\ensuremath{\alpha}},
description={Interpretable Transformation}
}
\newglossaryentry{targetVector}
{
name={\ensuremath{\hat{\boldsymbol{y}}}},
description={Target Vector in Training}
}
\newglossaryentry{glmsaga}
{
first = {\mbox{\textit{glm-saga}~\citep{wong2021leveraging}}},
long = {\mbox{\textit{glm-saga}~\citep{wong2021leveraging}}},
name={\mbox{\textit{glm-saga}}},
description={Target Vector in Training}
}
\newglossaryentry{cbm}
{
name={CBM},
first ={\textit{Concept Bottleneck Model}~(CBM)~\citep{koh2020concept}},
long = {CBM~\citep{koh2020concept}},
description={Target Vector in Training}
}
\newglossaryentry{ProtoPNet}
{
name={\textit{ProtoPNet}},
first ={\textit{ProtoPNet}~\citep{chen2019looks}},
description={Target Vector in Training}
}
\newglossaryentry{ProtoPShare}
{
name={\textit{ProtoPShare}},
first ={\textit{ProtoPShare}~\citep{rymarczyk2021protopshare}},
description={Target Vector in Training}
}
\definecolor{myGreen}{RGB}{34, 139, 34}
\newglossaryentry{ProtoPool}
{
name={\textit{ProtoPool}},
first ={\textit{ProtoPool}~\citep{rymarczyk2022interpretable}},
long ={\textit{ProtoPool}~\citep{rymarczyk2022interpretable}},
description={Target Vector in Training}
}
\newcommand{\pipnettable}{PIP-Net} %
\newcommand{\checktext}[1]{#1}
\newcommand{\protopooltable}{ProtoPool} 
\newcommand{\qsenntable}{Q-SENN}
\newcommand{\slddtable}{SLDD-Model} %
\newglossaryentry{protopnet}
{
name={\textit{ProtoPNet}},
first ={\textit{ProtoPNet}~\citep{chen2019looks}},
description={Target Vector in Training}
}
\newglossaryentry{qsenn}
{
name={\textit{Q-SENN}},
first ={\textit{Q-SENN}~\citep{norrenbrock2024q}},
description={Target Vector in Training}
}
\newglossaryentry{PIP-Net}
{
name={\textit{PIP-Net}},
first ={\textit{PIP-Net}~\citep{nauta2023pipnet}},
description={Target Vector in Training}
}

\newglossaryentry{imgnetheader}
{
first = {ImageNet-1K~\citep{imagenet15russakovsky}},
long = {ImageNet-1K~\citep{imagenet15russakovsky}},
name={ImageNet-1K},
description={Final layer in the neural network}
}
\newglossaryentry{labelfreecbm}
{
name={\textit{Label-free CBM}},
first ={\textit{Label-free CBM}~\citep{oikarinen2023label}},
description={Target Vector in Training}
}
\newglossaryentry{ProtoTree}
{
name={\textit{Prototree}},
first ={\textit{ProtoTree}~\citep{nauta2021neural}},
description={Target Vector in Training}
}
\newglossaryentry{ImageSample}
{
name={\ensuremath{\boldsymbol{I}}},
first ={\ensuremath{\boldsymbol{I} \in \mathbb{R}^{3\times w\times h}}},
description={The classifier on the featuers}
}
\newcommand\tFs{5 }
\newcommand{\suppt}{}%
\newcommand{\suppl}{Suppl.}
\newcommand{\posmetric}[1]{\ensuremath{\mathrm{pos}^{\mathrm{#1}}}}
\newcommand{\codesubmission}{\item Code will be published upon acceptance.}
\newcommand{\incv}{\gls{incv}}
\newcommand{\resnet}{\gls{resNet}}
\newcommand{\densenet}{\gls{denseNet}}
\newcommand{\betaT}{ with varying~\gls{cLW} }
\newcommand{\attributeset}[1]{\ensuremath{\rho_{#1}}}
\newcommand{\classWeightsName}{\mbox{\textit{w/o Class-Specific}}}
\newcommand{\SoftmaxName}{\mbox{\textit{w/o Rescaling}}}
\newcommand\topFre{30\% }
\newcommand{\nth}[1]{#1\textsuperscript{th}}
\newcommand{\oldloc}[1]{\textrm{diversity@#1}}
\newcommand{\loc}[1]{\textrm{SID@#1}}
\newcommand{\glm}{\gls{glmsaga}}
\newcommand{\glmtable}{glm-saga\textsubscript{5}}%
\newcommand{\densetable}{Dense($\gls{nperClass}=\gls{nFeatures}$ and $\gls{nReducedFeatures}=\gls{nFeatures}$)}
\newcommand{\tablefinisher}[1]{ dependent on #1}
\newcommand{\undlinstmt}{ Our used \gls{cLW} is underlined.}
\newcommand{\cbmauc}{CBM-AUC~\citep{10.1109/access.2022.3167702}}
\newcommand{\pcbm}{PCBM~\citep{yuksekgonul2022posthoc}}
\newcommand{\tableStatement}[1]{for number of features \mbox{$\gls{nReducedFeatures}=#1$} and features per class $\gls{nperClass}\leq5$}
\newcommand{\eg}{\textit{e}.\textit{g}. }
\newcommand{\KeptFeatures}{\ensuremath{N_{f^*}}}

\newcommand{\initFeatures}{\ensuremath{N_{f}}}
\newcommand{\wl}[1]{\ensuremath{\boldsymbol{w}_{#1}}}
\newcommand{\st}{so that}

\newcommand{\clipembedding}[1]{\ensuremath{\boldsymbol{#1}_{\mathrm{clip}}}}
\newcommand{\nclipfeatures}{\ensuremath{n_f^{\mathrm{clip}}}}
\newcommand{\gtmatrix}{\ensuremath{A}^{\mathrm{gt}}}
\newcommand{\gtvecvtor}{\ensuremath{\mathbf{a}^{\mathrm{gt}}}}
\newcommand{\clipmatrix}{\ensuremath{A}^{\mathrm{clip}}}
\newcommand{\clipvector}{\ensuremath{\mathbf{a}^{\mathrm{clip}}}}
\newcommand{\ourtable}{\gls{NewlayerName} (Ours)}
\newcommand{\fidelity}{\textbf{Fidelity}}
\newcommand{\diversity}{\textbf{Diversity}}
\newcommand{\grounding}{\textbf{Grounding}}
\newcommand{\supplm}{supplementary material}
\newcommand{\cmpLoss}{compared to other loss functions\bldStatement }
\newcommand{\arrowDown}{\ensuremath{\boldsymbol{\downarrow}}}
\newcommand{\ourstmt}{\textbf{Ours}}
\newcommand{\emptyStrichte}{ - & - & - & - & - &}
\newcommand{\fivetext}{five}
\newcommand{\sresnet}{Resnet}
\newcommand{\sdensenet}{DenseNet}
\newcommand{\sinception}{Inception}
\newcommand{\fourtext}{four}
\newcommand{\arrowUp}{\ensuremath{\boldsymbol{\uparrow}}} %
\newcommand{\elude}{\textit{Elude}~\citep{elude} }
\newcommand{\comparison}[1]{
\begin{figure*}
     \begin{subfigure}[t]{.35\textwidth}
         \centering
         \includesvg[width=\linewidth]{plots/CleanWeightsComparison/#1_Dense_5Weights}
        \caption{Conventional Dense \resnet{}}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{.35\textwidth}
         \centering
         \includesvg[width=\linewidth]{plots/CleanWeightsComparison/#1_Finetuned_5Weights}
            \caption{\ourtable{} with \resnet{}}
     \end{subfigure}
     \caption{Feature maps of the top 5 features by magnitude for class \detokenize{#1} on example images. The used weights for the respective features are also displayed. For~\gls{NewlayerName} all nonzero weights have the same magnitude $\alpha$. }
        \label{app:fig:vizExamples#1}
\end{figure*}
}
\tikzstyle{process} = [rectangle, minimum width=1cm, minimum height=1cm, text centered, text width=1.8cm, draw=black]
\tikzstyle{decision} = [diamond, minimum width=1cm, minimum height=1cm, text centered, draw=black]
\tikzstyle{arrow} = [thick,->,>=stealth]
\newcommand{\distEdge}{\ensuremath{d_e}}
\newcommand{\ClassSim}{\Psi}
\newcommand{\classSim}{\psi}
\newcommand{\simmat}{\ensuremath{\boldsymbol{A}}} 
\newcommand{\insimmat}[2]{\ensuremath{a_{#1,#2}}}
\newcommand{\infvec}[1]{\ensuremath{s_{#1}}}
\newcommand{\symbolFeaFea}{r}
\newcommand{\FSimeaturemat}{\ensuremath{\boldsymbol{R}}}
\newcommand{\BSimeaturemat}{\ensuremath{\boldsymbol{b}}} 
\newcommand{\gurobi}{\textit{Gurobi}~\citep{gurobi}}
\newcommand{\objective}{\ensuremath{Z}}
\newcommand{\fvecgurobi}{\ensuremath{\boldsymbol{s}}}%
\newcommand{\wgurobi}{\ensuremath{\boldsymbol{W}}}
\newcommand{\confusionMat}{\ensuremath{\boldsymbol{C}}}

\newcommand{\simieq}{\ensuremath{\sum_{\cindex=1}^{\gls{nClasses}}(\boldsymbol{a}_\cindex\circ \boldsymbol{w}_\cindex)^T \fvecgurobi}}
\newcommand{\correq}{\ensuremath{\fvecgurobi^T \FSimeaturemat \fvecgurobi}}
\newcommand{\biaseq}{\ensuremath{\BSimeaturemat{}^T \fvecgurobi}}
\newcommand{\confeq}{\ensuremath{\sum(\confusionMat\circ (1-\wgurobi)) \fvecgurobi}}

\newcommand{\generality}{\ifmmode
    \mathrm{Class\text{-}Independence}
  \else
    Class-Independence
  \fi}
\newcommand{\contrastiveness}{Contrastiveness}
\newcommand{\cubsim}{Structural Grounding}
\newcommand{\correlation}{Correlation}

\newcommand{\CB}{CB}

\newcommand{\boldnessstatement}{Among more interpretable models, the best result is marked in bold, second best underlined.}

\newcommand{\zerovec}[1]{\ensuremath{\boldsymbol{0}^{#1}}}
\newcommand{\onevec}[1]{\ensuremath{\boldsymbol{1}^{#1}}}
\newcommand{\zeromat}[2]{\ensuremath{\boldsymbol{0}^{#1, #2}}}
\newcommand{\onemat}[2]{\ensuremath{\boldsymbol{1}^{#1, #2}}}

\newcommand{\interpmetricstablestart}[1]{Comparison on Interpretability metrics with #1. Due to required annotations, \cubsim{} can only be computed for \travelingheader{} and \cubheader{}. 
 \boldnessstatement}
\newcommand{\accmetricstablestart}[1]{Comparison on compactness and accuracy with #1: \gls{NewlayerName} shows increased accuracy and compactness.}




