\section{Related Work}
\label{lit}
Automated high-quality code generation has evolved in several key directions related to prompt engineering____, multi-agent systems____, and iterative debugging with runtime feedback mechanisms____.
While LLM has demonstrated increasing capability in code generation, the code quality and correctness can be further enhanced by using intelligent debugging strategies.
Therefore, previous works in self-debugging____ show their capability in Automated Program Repair (APR) by identifying and fixing significant code flaws and bugs.
Researchers have shown that "large language models of code"____ often struggle to directly fix bugs in the generated code due to the lack of task-specific fine-tuning. 
These fine-tuned models outperform the state-of-the-art APR tools____ but still suffer from the loss of pre-trained knowledge____, lack of debugging ingredients, inferior long-sequence handling ability, high resource constraints, long-tail problems, and multi-hunk error fixing____.

Particulary, MapCoder____ presents a multi-agent framework designed to emulate human-level programming processes. 
It employs four agents for retrieval, planning, coding, and debugging to perform iterative code generation and debugging.
AgentCoder____ introduces a three-agent framework to address high token usage and coordination overhead observed in other multi-agent systems like MapCoder____, MetaGPT____, and ChatDev____.
The framework comprises a programmer agent, a test designer agent, and a test executor agent.
The "Debug Like a Human" framework____ introduces Large Language Model Debugger (LDB), which enhances the code quality by leveraging runtime execution information. 
LDB is performed iteratively through segmenting code, tracking intermediate variable states, and performing step-by-step verification with breakpoints.
Moreover, some approaches have employed prompt engineering to improve the quality of code generation and debugging.
For instance,  CodeCoT____ leverages iterative refinement through Chain of Thought (CoT)____ and logical reasoning. 
However, its capability is limited to refining syntax errors.

While these approaches have advanced automated code generations, they share several notable limitations, particularly the resource intensity for complex problems. 
Additionally, they often struggle to fully leverage error messages, which impairs their adaptability to nuanced debugging scenarios. 
Although this issue can be alleviated by generating complementary test cases, it can further increase resource consumption due to the reliance on preemptive test cases such that generation may become less reliable ____ and potentially require more complex agents.

To address these challenges, we introduce PyCapsule as a streamlined modular architecture with robust and optimized modules. 
It combines the knowledge from the operation research field and computer science to optimize the processing pipeline with merely two AI agents. This greatly reduces the computational overhead and facilitates more efficient and reliable code generation.
%===============================================================================================