@article{Huang2023AnES,
      title={An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair},
      author={Kai Huang and Xiangxin Meng and Jian Zhang and Yang Liu and Wenjie Wang and Shuhao Li and Yuqing Zhang},
      journal={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
      year={2023},
      pages={1162-1174},
      url={https://api.semanticscholar.org/CorpusID:265054960}
}

@article{Wei2022ChainOT,
      title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed H. Chi and F. Xia and Quoc Le and Denny Zhou},
      journal={ArXiv},
      year={2022},
      volume={abs/2201.11903},
      url={https://api.semanticscholar.org/CorpusID:246411621}
}

@article{Xia2022LessTM,
      title={Less training, more repairing please: revisiting automated program repair via zero-shot learning},
      author={Chun Xia and Lingming Zhang},
      journal={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
      year={2022},
      url={https://api.semanticscholar.org/CorpusID:250627519}
}

@article{adnan2024unleashingartificialcognitionintegrating,
      title={Unleashing Artificial Cognition: Integrating Multiple AI Systems}, 
      author={Muntasir Adnan and Buddhi Gamage and Zhiwei Xu and Damith Herath and Carlos C. N. Kuhn},
      year={2024},
      volume = {31},
      journal = {ACIS 2024 Proceedings}
}

@article{ai_literacy_p_e,
    author = {Nils Knoth and Antonia Tolzin and Andreas Janson and Jan Marco Leimeister},
    title = {AI literacy and its implications for prompt engineering strategies},
    journal = {Computers and Education: Artificial Intelligence},
    year = {2024}}

@article{approach_to_ai_agents,
    author = {Burgin, Mark and Dodig Crnkovic, Gordana},
    year = {2009},
    month = {03},
    pages = {},
    title = {A Systematic Approach to Artificial Agents}
}

@misc{chen2023teachinglargelanguagemodels,
      title={Teaching Large Language Models to Self-Debug}, 
      author={Xinyun Chen and Maxwell Lin and Nathanael Schärli and Denny Zhou},
      year={2023},
      eprint={2304.05128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.05128}, 
}

@inproceedings{generative_agents,
    author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
    title = {Generative Agents: Interactive Simulacra of Human Behavior},
    year = {2023},
    isbn = {9798400701320},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3586183.3606763},
    doi = {10.1145/3586183.3606763},
    abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
    booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
    articleno = {2},
    numpages = {22},
    keywords = {Human-AI interaction, agents, generative AI, large language models},
    location = {San Francisco, CA, USA},
    series = {UIST '23}
}

@misc{hong2024metagptmetaprogrammingmultiagent,
      title={MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework}, 
      author={Sirui Hong and Mingchen Zhuge and Jiaqi Chen and Xiawu Zheng and Yuheng Cheng and Ceyao Zhang and Jinlin Wang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and Jürgen Schmidhuber},
      year={2024},
      eprint={2308.00352},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2308.00352}, 
}

@misc{huang2024agentcodermultiagentbasedcodegeneration,
      title={AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation}, 
      author={Dong Huang and Jie M. Zhang and Michael Luck and Qingwen Bu and Yuhao Qing and Heming Cui},
      year={2024},
      eprint={2312.13010},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.13010}, 
}

@misc{huang2024codecottacklingcodesyntax,
      title={CodeCoT: Tackling Code Syntax Errors in CoT Reasoning for Code Generation}, 
      author={Dong Huang and Qingwen Bu and Yuhao Qing and Heming Cui},
      year={2024},
      eprint={2308.08784},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2308.08784}, 
}

@misc{islam2024mapcodermultiagentcodegeneration,
      title={MapCoder: Multi-Agent Code Generation for Competitive Problem Solving}, 
      author={Md. Ashraful Islam and Mohammed Eunus Ali and Md Rizwan Parvez},
      year={2024},
      eprint={2405.11403},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.11403}, 
}

@inproceedings{lesstraining,
    author = {Xia, Chunqiu Steven and Zhang, Lingming},
    title = {Less training, more repairing please: revisiting automated program repair via zero-shot learning},
    year = {2022},
    isbn = {9781450394130},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3540250.3549101},
    doi = {10.1145/3540250.3549101},
    booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {959–971},
    numpages = {13},
    keywords = {Zero-shot Learning, Deep Learning, Automated Program Repair},
    location = {Singapore, Singapore},
    series = {ESEC/FSE 2022}
}

@misc{li2024largelanguagemodelstest,
      title={Large Language Models as Test Case Generators: Performance Evaluation and Enhancement}, 
      author={Kefan Li and Yuan Yuan},
      year={2024},
      eprint={2404.13340},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2404.13340}, 
}

@misc{qian2024chatdevcommunicativeagentssoftware,
      title={ChatDev: Communicative Agents for Software Development}, 
      author={Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2307.07924},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2307.07924}, 
}

@inproceedings{repairisnearly,
    author = {Joshi, Harshit and Sanchez, Jos\'{e} Cambronero and Gulwani, Sumit and Le, Vu and Radi\v{c}ek, Ivan and Verbruggen, Gust},
    title = {Repair is nearly generation: multilingual program repair with LLMs},
    year = {2023},
    isbn = {978-1-57735-880-0},
    publisher = {AAAI Press},
    url = {https://doi.org/10.1609/aaai.v37i4.25642},
    doi = {10.1609/aaai.v37i4.25642},
    booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
    articleno = {573},
    numpages = {10},
    series = {AAAI'23/IAAI'23/EAAI'23}
}

@article{software_testing,
title = {Evaluating large language models for software testing},
journal = {Computer Standards \& Interfaces},
volume = {93},
pages = {103942},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2024.103942},
url = {https://www.sciencedirect.com/science/article/pii/S0920548924001119},
author = {Yihao Li and Pan Liu and Haiyang Wang and Jie Chu and W. Eric Wong},
keywords = {Large language models, LLM-driven testing, Evaluation, Hallucination},
abstract = {Large language models (LLMs) have demonstrated significant prowess in code analysis and natural language processing, making them highly valuable for software testing. This paper conducts a comprehensive evaluation of LLMs applied to software testing, with a particular emphasis on test case generation, error tracing, and bug localization across twelve open-source projects. The advantages and limitations, as well as recommendations associated with utilizing LLMs for these tasks, are delineated. Furthermore, we delve into the phenomenon of hallucination in LLMs, examining its impact on software testing processes and presenting solutions to mitigate its effects. The findings of this work contribute to a deeper understanding of integrating LLMs into software testing, providing insights that pave the way for enhanced effectiveness in the field.}
}

@inproceedings{vulrepair,
    author = {Fu, Michael and Tantithamthavorn, Chakkrit and Le, Trung and Nguyen, Van and Phung, Dinh},
    title = {VulRepair: a T5-based automated software vulnerability repair},
    year = {2022},
    isbn = {9781450394130},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3540250.3549098},
    doi = {10.1145/3540250.3549098},
    booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {935–947},
    numpages = {13},
    keywords = {Software Vulnerability Repair},
    location = {Singapore, Singapore},
    series = {ESEC/FSE 2022}
}

@article{wooldridge1995intelligent,
      title={Intelligent agents: Theory and practice},
      author={Wooldridge, Michael and Jennings, Nicholas R},
      journal={The knowledge engineering review},
      volume={10},
      number={2},
      pages={115--152},
      year={1995},
      publisher={Cambridge University Press}
}

@misc{zhong2024debuglikehumanlarge,
      title={Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step}, 
      author={Li Zhong and Zilong Wang and Jingbo Shang},
      year={2024},
      eprint={2402.16906},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2402.16906}, 
}

