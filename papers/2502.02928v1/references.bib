@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and others},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{islam2024mapcodermultiagentcodegeneration,
      title={MapCoder: Multi-Agent Code Generation for Competitive Problem Solving}, 
      author={Md. Ashraful Islam and Mohammed Eunus Ali and Md Rizwan Parvez},
      year={2024},
      eprint={2405.11403},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.11403}, 
}

@misc{zhong2024debuglikehumanlarge,
      title={Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step}, 
      author={Li Zhong and Zilong Wang and Jingbo Shang},
      year={2024},
      eprint={2402.16906},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2402.16906}, 
}

@misc{hui2024qwen25codertechnicalreport,
      title={Qwen2.5-Coder Technical Report}, 
      author={Binyuan Hui and Jian Yang and Zeyu Cui and Jiaxi Yang and Dayiheng Liu and Lei Zhang and Tianyu Liu and Jiajun Zhang and Bowen Yu and Keming Lu and Kai Dang and Yang Fan and Yichang Zhang and An Yang and Rui Men and Fei Huang and Bo Zheng and Yibo Miao and Shanghaoran Quan and Yunlong Feng and Xingzhang Ren and Xuancheng Ren and Jingren Zhou and Junyang Lin},
      year={2024},
      eprint={2409.12186},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.12186}, 
}

@misc{huang2024agentcodermultiagentbasedcodegeneration,
      title={AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation}, 
      author={Dong Huang and Jie M. Zhang and Michael Luck and Qingwen Bu and Yuhao Qing and Heming Cui},
      year={2024},
      eprint={2312.13010},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.13010}, 
}

@misc{zhuo2024bigcodebenchbenchmarkingcodegeneration,
      title={BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions}, 
      author={Terry Yue Zhuo and Minh Chien Vu and Jenny Chim and Han Hu and Wenhao Yu and Ratnadira Widyasari and Imam Nur Bani Yusuf and Haolan Zhan and Junda He and Indraneil Paul and Simon Brunner and Chen Gong and Thong Hoang and Armel Randy Zebaze and Xiaoheng Hong and Wen-Ding Li and Jean Kaddour and Ming Xu and Zhihan Zhang and Prateek Yadav and Naman Jain and Alex Gu and Zhoujun Cheng and Jiawei Liu and Qian Liu and Zijian Wang and David Lo and Binyuan Hui and Niklas Muennighoff and Daniel Fried and Xiaoning Du and Harm de Vries and Leandro Von Werra},
      year={2024},
      eprint={2406.15877},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2406.15877}, 
}
@misc{shinn2023reflexionlanguageagentsverbal,
      title={Reflexion: Language Agents with Verbal Reinforcement Learning}, 
      author={Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2303.11366},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2303.11366}, 
}
@misc{jiang2024selfplanningcodegenerationlarge,
      title={Self-planning Code Generation with Large Language Models}, 
      author={Xue Jiang and Yihong Dong and Lecheng Wang and Zheng Fang and Qiwei Shang and Ge Li and Zhi Jin and Wenpin Jiao},
      year={2024},
      eprint={2303.06689},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2303.06689}, 
}

@article{adnan2024unleashingartificialcognitionintegrating,
      title={Unleashing Artificial Cognition: Integrating Multiple AI Systems}, 
      author={Muntasir Adnan and Buddhi Gamage and Zhiwei Xu and Damith Herath and Carlos C. N. Kuhn},
      year={2024},
      volume = {31},
      journal = {ACIS 2024 Proceedings}
}

@misc{hong2024metagptmetaprogrammingmultiagent,
      title={MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework}, 
      author={Sirui Hong and Mingchen Zhuge and Jiaqi Chen and Xiawu Zheng and Yuheng Cheng and Ceyao Zhang and Jinlin Wang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and Jürgen Schmidhuber},
      year={2024},
      eprint={2308.00352},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2308.00352}, 
}

@misc{qian2024chatdevcommunicativeagentssoftware,
      title={ChatDev: Communicative Agents for Software Development}, 
      author={Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2307.07924},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2307.07924}, 
}

@article{software_testing,
title = {Evaluating large language models for software testing},
journal = {Computer Standards \& Interfaces},
volume = {93},
pages = {103942},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2024.103942},
url = {https://www.sciencedirect.com/science/article/pii/S0920548924001119},
author = {Yihao Li and Pan Liu and Haiyang Wang and Jie Chu and W. Eric Wong},
keywords = {Large language models, LLM-driven testing, Evaluation, Hallucination},
abstract = {Large language models (LLMs) have demonstrated significant prowess in code analysis and natural language processing, making them highly valuable for software testing. This paper conducts a comprehensive evaluation of LLMs applied to software testing, with a particular emphasis on test case generation, error tracing, and bug localization across twelve open-source projects. The advantages and limitations, as well as recommendations associated with utilizing LLMs for these tasks, are delineated. Furthermore, we delve into the phenomenon of hallucination in LLMs, examining its impact on software testing processes and presenting solutions to mitigate its effects. The findings of this work contribute to a deeper understanding of integrating LLMs into software testing, providing insights that pave the way for enhanced effectiveness in the field.}
}

@misc{li2024largelanguagemodelstest,
      title={Large Language Models as Test Case Generators: Performance Evaluation and Enhancement}, 
      author={Kefan Li and Yuan Yuan},
      year={2024},
      eprint={2404.13340},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2404.13340}, 
}

@misc{huang2024codecottacklingcodesyntax,
      title={CodeCoT: Tackling Code Syntax Errors in CoT Reasoning for Code Generation}, 
      author={Dong Huang and Qingwen Bu and Yuhao Qing and Heming Cui},
      year={2024},
      eprint={2308.08784},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2308.08784}, 
}

@article{Wei2022ChainOT,
      title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed H. Chi and F. Xia and Quoc Le and Denny Zhou},
      journal={ArXiv},
      year={2022},
      volume={abs/2201.11903},
      url={https://api.semanticscholar.org/CorpusID:246411621}
}

@misc{chen2023teachinglargelanguagemodels,
      title={Teaching Large Language Models to Self-Debug}, 
      author={Xinyun Chen and Maxwell Lin and Nathanael Schärli and Denny Zhou},
      year={2023},
      eprint={2304.05128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.05128}, 
}

@article{Huang2023AnES,
      title={An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair},
      author={Kai Huang and Xiangxin Meng and Jian Zhang and Yang Liu and Wenjie Wang and Shuhao Li and Yuqing Zhang},
      journal={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
      year={2023},
      pages={1162-1174},
      url={https://api.semanticscholar.org/CorpusID:265054960}
}

@article{Xia2022LessTM,
      title={Less training, more repairing please: revisiting automated program repair via zero-shot learning},
      author={Chun Xia and Lingming Zhang},
      journal={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
      year={2022},
      url={https://api.semanticscholar.org/CorpusID:250627519}
}

@article{codex,
      title={Evaluating Large Language Models Trained on Code},
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and others},
      journal={arXiv preprint arXiv:2107.03374},
      year={2021}
}

@article{dong2023codescore,
      title={Codescore: Evaluating code generation by learning code execution},
      author={Dong, Yihong and Ding, Jiazheng and Jiang, Xue and Li, Zhuo and Li, Ge and Jin, Zhi},
      journal={arXiv preprint arXiv:2301.09043},
      year={2023}
}

@inproceedings{evalplus,
      title = {Is Your Code Generated by Chat{GPT} Really Correct? Rigorous Evaluation of Large Language Models for Code Generation},
      author = {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
      booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
      year = {2023},
      url = {https://openreview.net/forum?id=1qvx610Cu7},
}

@article{austin2021program,
      title={Program synthesis with large language models},
      author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
      journal={arXiv preprint arXiv:2108.07732},
      year={2021}
}

@misc{lachaux2020unsupervisedtranslationprogramminglanguages,
      title={Unsupervised Translation of Programming Languages}, 
      author={Marie-Anne Lachaux and Baptiste Roziere and Lowik Chanussot and Guillaume Lample},
      year={2020},
      eprint={2006.03511},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.03511}, 
}

@misc{li2024longcontextllmsstrugglelong,
      title={Long-context LLMs Struggle with Long In-context Learning}, 
      author={Tianle Li and Ge Zhang and Quy Duc Do and Xiang Yue and Wenhu Chen},
      year={2024},
      eprint={2404.02060},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.02060}, 
}

@article{zhuo2024bigcodebench,
      title={BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions},
      author={Zhuo, Terry Yue and Vu, Minh Chien and Chim, Jenny and Hu, Han and Yu, Wenhao and Widyasari, Ratnadira and Yusuf, Imam Nur Bani and Zhan, Haolan and He, Junda and Paul, Indraneil and others},
      journal={arXiv preprint arXiv:2406.15877},
      year={2024}
}

@article{role-play,
    author = {Shanahan, Murray and McDonell, Kyle and Reynolds, Laria},
    year = {2023},
    month = {11},
    pages = {},
    title = {Role play with large language models},
    volume = {623},
    journal = {Nature},
    doi = {10.1038/s41586-023-06647-8}
}

@article{prompt_eg_consistency,
    author = {Chen, Xi and Deng, XiangWen and Wen, Hao and You, MingKe and Liu, Weizhi and Li, Qi and Li, Jian},
    year = {2024},
    month = {02},
    pages = {},
    title = {Prompt engineering in consistency and reliability with the evidence-based guideline for LLMs},
    volume = {7},
    journal = {npj Digital Medicine},
    doi = {10.1038/s41746-024-01029-4}
}

@article{eval_prompt_eg,
    author = {Patel, Dhavalkumar and Raut, Ganesh and Zimlichman, Eyal and Cheetirala, Satya and Nadkarni, Girish and Glicksberg, Benjamin and Apakama, Donald and Bell, Elijah and Freeman, Robert and Timsina, Prem and Klang, Eyal},
    year = {2024},
    month = {07},
    pages = {},
    title = {Evaluating prompt engineering on GPT-3.5’s performance in USMLE-style medical calculations and clinical scenarios generated by GPT-4},
    volume = {14},
    journal = {Scientific Reports},
    doi = {10.1038/s41598-024-66933-x}
}

@article{liu-etal-2024-lost,
    title = "Lost in the Middle: How Language Models Use Long Contexts",
    author = "Liu, Nelson F.  and
      Lin, Kevin  and
      Hewitt, John  and
      Paranjape, Ashwin  and
      Bevilacqua, Michele  and
      Petroni, Fabio  and
      Liang, Percy",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.tacl-1.9/",
    doi = "10.1162/tacl_a_00638",
    pages = "157--173",
}

@article{wooldridge1995intelligent,
      title={Intelligent agents: Theory and practice},
      author={Wooldridge, Michael and Jennings, Nicholas R},
      journal={The knowledge engineering review},
      volume={10},
      number={2},
      pages={115--152},
      year={1995},
      publisher={Cambridge University Press}
}

@article{approach_to_ai_agents,
    author = {Burgin, Mark and Dodig Crnkovic, Gordana},
    year = {2009},
    month = {03},
    pages = {},
    title = {A Systematic Approach to Artificial Agents}
}


@Article{emp_study_critical,
    AUTHOR = {Liu, Mingxing and Wang, Junfeng and Lin, Tao and Ma, Quan and Fang, Zhiyang and Wu, Yanqun},
    TITLE = {An Empirical Study of the Code Generation of Safety-Critical Software Using LLMs},
    JOURNAL = {Applied Sciences},
    VOLUME = {14},
    YEAR = {2024},
    NUMBER = {3},
    ARTICLE-NUMBER = {1046},
    URL = {https://www.mdpi.com/2076-3417/14/3/1046},
    ISSN = {2076-3417},
    ABSTRACT = {In the digital era of increasing software complexity, improving the development efficiency of safety-critical software is a challenging task faced by academia and industry in domains such as nuclear energy, aviation, the automotive industry, and rail transportation. Recently, people have been excited about using pre-trained large language models (LLMs) such as ChatGPT and GPT-4 to generate code. Professionals in the safety-critical software field are intrigued by the code generation capabilities of LLMs. However, there is currently a lack of systematic case studies in this area. Aiming at the need for automated code generation in safety-critical domains such as nuclear energy and the automotive industry, this paper conducts a case study on generating safety-critical software code using GPT-4 as the tool. Practical engineering cases from the industrial domain are employed. We explore different approaches, including code generation based on overall requirements, specific requirements, and augmented prompts. We propose a novel prompt engineering method called Prompt-FDC that integrates basic functional requirements, domain feature generalization, and domain constraints. This method improves code completeness from achieving 30% functions to 100% functions, increases the code comment rate to 26.3%, and yields better results in terms of code compliance, readability, and maintainability. The code generation approach based on LLMs also introduces a new software development process and V-model lifecycle for safety-critical software. Through systematic case studies, we demonstrate that, with appropriate prompt methods, LLMs can auto-generate safety-critical software code that meets practical engineering application requirements. It is foreseeable that LLMs can be applied to various engineering domains to improve software safety and development efficiency.},
    DOI = {10.3390/app14031046}
}




@inproceedings{generative_agents,
    author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
    title = {Generative Agents: Interactive Simulacra of Human Behavior},
    year = {2023},
    isbn = {9798400701320},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3586183.3606763},
    doi = {10.1145/3586183.3606763},
    abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
    booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
    articleno = {2},
    numpages = {22},
    keywords = {Human-AI interaction, agents, generative AI, large language models},
    location = {San Francisco, CA, USA},
    series = {UIST '23}
}

@inproceedings{palm10.5555/3648699.3648939,
    author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sashank and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
    title = {{PaLM}: scaling language modeling with pathways},
    booktitle = {Journal of Machine Learning Research},
    year = {2024},
}
@inproceedings{emperical_study_soft_eg,
    author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
    title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
    year = {2024},
    isbn = {9798400705793},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3643795.3648379},
    doi = {10.1145/3643795.3648379},
    booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
    pages = {111–118},
    numpages = {8},
    keywords = {LLM for code generation, software engineering},
    location = {Lisbon, Portugal},
    series = {LLM4Code '24}
}

@INPROCEEDINGS{llm_se_problems,
  author={Fan, Angela and Gokkaya, Beliz and Harman, Mark and Lyubarskiy, Mitya and Sengupta, Shubho and Yoo, Shin and Zhang, Jie M.},
  booktitle={2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE)}, 
  title={Large Language Models for Software Engineering: Survey and Open Problems}, 
  year={2023},
  volume={},
  number={},
  pages={31-53},
  keywords={Surveys;Maintenance engineering;Reliability engineering;Software;Software reliability;Software engineering;Testing;Automated Program Repair;Documentation generation;Generative AI;Genetic Improvement;Human-Computer Interaction;Large Language Models;Refactoring;Requirements engineering;Search Based Software Engineering (SBSE);Software Analytics;Software Engineering Education;Software Processes;Software Maintenance and Evolution;Software Testing},
  doi={10.1109/ICSE-FoSE59343.2023.00008}
}

@misc{dou2024whatswrongcodegenerated,
      title={What's Wrong with Your Code Generated by Large Language Models? An Extensive Study}, 
      author={Shihan Dou and Haoxiang Jia and Shenxi Wu and Huiyuan Zheng and Weikang Zhou and Muling Wu and Mingxu Chai and Jessica Fan and Caishuang Huang and Yunbo Tao and Yan Liu and Enyu Zhou and Ming Zhang and Yuhao Zhou and Yueming Wu and Rui Zheng and Ming Wen and Rongxiang Weng and Jingang Wang and Xunliang Cai and Tao Gui and Xipeng Qiu and Qi Zhang and Xuanjing Huang},
      year={2024},
      eprint={2407.06153},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2407.06153}, 
}

@inproceedings{imperfect_code_gen,
    author = {Lian, Xiaoli and Wang, Shuaisong and Ma, Jieping and Tan, Xin and Liu, Fang and Shi, Lin and Gao, Cuiyun and Zhang, Li},
    title = {Imperfect Code Generation: Uncovering Weaknesses in Automatic Code Generation by Large Language Models},
    year = {2024},
    isbn = {9798400705021},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3639478.3643081},
    doi = {10.1145/3639478.3643081},
    pages = {422–423},
    numpages = {2},
    location = {Lisbon, Portugal},
    series = {ICSE-Companion '24}
}

@article{ai_literacy_p_e,
    author = {Nils Knoth and Antonia Tolzin and Andreas Janson and Jan Marco Leimeister},
    title = {AI literacy and its implications for prompt engineering strategies},
    journal = {Computers and Education: Artificial Intelligence},
    year = {2024}}

@inproceedings{lesstraining,
    author = {Xia, Chunqiu Steven and Zhang, Lingming},
    title = {Less training, more repairing please: revisiting automated program repair via zero-shot learning},
    year = {2022},
    isbn = {9781450394130},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3540250.3549101},
    doi = {10.1145/3540250.3549101},
    booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {959–971},
    numpages = {13},
    keywords = {Zero-shot Learning, Deep Learning, Automated Program Repair},
    location = {Singapore, Singapore},
    series = {ESEC/FSE 2022}
}

@inproceedings{vulrepair,
    author = {Fu, Michael and Tantithamthavorn, Chakkrit and Le, Trung and Nguyen, Van and Phung, Dinh},
    title = {VulRepair: a T5-based automated software vulnerability repair},
    year = {2022},
    isbn = {9781450394130},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3540250.3549098},
    doi = {10.1145/3540250.3549098},
    booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {935–947},
    numpages = {13},
    keywords = {Software Vulnerability Repair},
    location = {Singapore, Singapore},
    series = {ESEC/FSE 2022}
}

@inproceedings{repairisnearly,
    author = {Joshi, Harshit and Sanchez, Jos\'{e} Cambronero and Gulwani, Sumit and Le, Vu and Radi\v{c}ek, Ivan and Verbruggen, Gust},
    title = {Repair is nearly generation: multilingual program repair with LLMs},
    year = {2023},
    isbn = {978-1-57735-880-0},
    publisher = {AAAI Press},
    url = {https://doi.org/10.1609/aaai.v37i4.25642},
    doi = {10.1609/aaai.v37i4.25642},
    booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
    articleno = {573},
    numpages = {10},
    series = {AAAI'23/IAAI'23/EAAI'23}
}

@article{Nwana_1996, 
    title={Software agents: an overview}, 
    volume={11}, 
    DOI={10.1017/S026988890000789X}, 
    number={3}, 
    journal={The Knowledge Engineering Review}, 
    author={Nwana, Hyacinth S.}, 
    year={1996}, pages={205–244}
}

@article{roadmap,
    author = {Jennings, Nicholas and Sycara, Katia and Wooldridge, Michael},
    year = {1998},
    month = {03},
    pages = {7-38},
    title = {A Roadmap of Agent Research and Development},
    volume = {1},
    journal = {Autonomous Agents and Multi-Agent Systems},
    doi = {10.1023/A:1010090405266}
}