\section{Related Works}
\paragraph{Heterogeneous MMAB (HMMAB)}
HMMAB is one of the standard models in multi-player multi-armed bandits with collision literature; to name a few, **Kleinberg et al., "Multi-Armed Bandits"**__**Auer et al., "Finite-Time Analysis of the Multi-Armed Bandit Problem with Collisions"**.
Among them, **Bubeck and Cesa-Bianchi, "Regret Analysis of some Incremental Algorithms for Bandits with Advice"** was the first to study the HMMAB, where they proposed a decentralized algorithm with $O(\log^2 T)$ regret.
Later on, the regret bound of this model was improved to \(O(M^3K\log T)\) by **Jaksch et al., "Near-optimal Regret Bounds for Reinforcement Learning"** and further to \(O(M^2K\log T)\) by **Bubeck et al., "Regal: A Regularized Autoencoder-based RL Agent"** that is the state-of-the-art result.
We are the first to introduce the hint mechanism to HMMAB.


\paragraph{Bandits with Hints}
Learning algorithms with hints (or predictions) are part of the emerging literature on learning-augmented methods, as seen in works like **Berry et al., "The Price of Bandit Information"**__**Dani et al., "Price of Optimal Data-Driven Policies: Blackwell Approachability with a Small Big M"**, etc. The hint mechanism was initially explored in the basic stochastic multi-armed bandits model by **Kleinberg and Slivkins, "Multi-Armed Bandits in the Presence of Hints"**. Later, **Cesa-Bianchi et al., "Learning from Predictions in Multi-Armed Bandits"** examined a more realistic hint mechanism, which includes failure noise, for the same model. Additionally, **Garivier and Cappe, "The KL-UCB Algorithm for Bounded Stochastic Processes"** investigated the impact of hints in adversarial bandits. We are the first to study the hint mechanism in a multi-agent scenario.