\section{Introduction}
\label{sec:introduction}
Embodied agents are being used in assistive roles in many applications, aided in part by the availability of realistic simulators~\cite{coppeliaSim,Puig_2018_CVPR,kolve2022ai2thorinteractive3denvironment}. Although such agents possess some prior knowledge of domain objects and their attributes, they are often asked to perform new tasks and operate in new scenarios. For example, an agent preparing dishes in the kitchen based on prior knowledge of some recipes and ingredients, may be asked to prepare a new dish or clean the pantry.

%\Madhav{Should we say why cleaning the pantry is unseen scenario?} % quickly execute or accomplish tasks that are beyond what it had previously experienced and learned for in household settings the tasks are varied and diverse and typically exhibit an open set property

\vspace{-0.75em}
Large Language Models (LLMs) trained on a large corpus of data have demonstrated the ability to decompose a range of tasks into a sequence of high-level (abstract) actions (i.e., sub-tasks) that implement the task~\cite{khot2023decomposedpromptingmodularapproach,reppert2023iterateddecompositionimprovingscience,liu2024deltadecomposedefficientlongterm}. For example, an LLM can provide a sequence of sub-tasks for completing the previously unseen task of \textit{preparing hot chocolate}. However, this sequence may involve incorrect steps, or reference objects and actions that the agent does not have access to in the kitchen under consideration.

\begin{figure}[tb]
\centering
\captionsetup{font=scriptsize}
\setlength{\belowcaptionskip}{-10pt}
\includegraphics[width=0.49\textwidth]{figures/LLM_KG_Teaser.pdf}
\vspace{-0.5em}
\caption{For any given task, an LLM provides a generic sequence of abstract actions that is refined using the domain-specific knowledge in a KG. If the sequence refers to objects, attributes, or actions that cannot be resolved using the KG, or leads to unexpected outcomes, human input helps refine or expand the KG.}
\vspace{-6pt}
\label{fig:teaser}
\end{figure}

\vspace{-0.75em}
The challenges mentioned above are partially offset by the fact that an assistive agent usually has some prior domain-specific knowledge in the form of objects, object attributes, and action capabilities. State-of-the-art methods build large datasets of such information for a given application domain~\cite{sakib2022approximate}, or attempt to embed this knowledge by repeatedly tuning deep networks~\cite{sakib2024cooking}. However, such knowledge is not readily available for many practical domains, and modern data-driven methods make it difficult to reliably and transparently revise the encoded knowledge over time. In a departure from such methods, the framework described in this paper seeks to leverage the complementary strengths of LLMs, Knowledge Graphs (KGs), and human feedback---see Figure~\ref{fig:teaser}. Our framework enables the assistive agent to:
%We present a framework that integrates Knowledge Graph with LLM along with feedback from humans to overcome LLM inaccuracies and handle open set task challenges in a variegated environment settings. The Knowledge Graph (KG) is a minimalist graph of possibilities, wherein the nodes of the graph are the objects and tools that are present in the environment while the edges represent the possible actions that can be performed by a tool on the object. The graph also contains receptacles as its nodes and enjoys a binary relation between objects and tools, wherein this relation encodes if the receptacle is a valid storage place for finding the tool or the object. Figure \ref{Fig-Relations} shows the possible relations between objects tools and receptacles.
%The LLM action sequence is validated by the KG ontology and refined to align with the ontology of the graph. When such alignment is not possible or results in the eventual failure in task accomplishment the framework seeks human intervention to expand the KG to accommodate the new objects and tools within its data structure in order to complete the task. The KG expansion is a unique feature of this effort that allows for the KG to start with a sparse set of nodes and relations and yet to accomplish tasks by expansion. Another feature of such a human intervened KG expansion is that it preempts the need for dataset generation, ground truthing and fine tuning of LLM for every new task or setting unlike prior art \cite{sakib2022approximate}, \cite{sakib2024}. Specifically we contribute in the following ways

\begin{figure*}[h]
  \centering
  \captionsetup{font=scriptsize}
  \includegraphics[width=\textwidth]{figures/LLM_KG_Pipeline.pdf}
  \vspace{-2em}
  \caption{Framework overview for cooking tasks: (a) Input Chain-of-Thought (COT) prompt contains target dish, available ingredients, and an example of input and output action sequence (for task of making coffee), to obtain an output action sequence; (b) Any mismatch (e.g., in object classes, actions) between LLM output and KG are identified and action sequence is revised if possible; (c) Agent attempts to resolve any remaining errors or unexpected outcomes by re-prompting LLM, with errors that persist being addressed by soliciting human input and updating KG; (iv) Revised/corrected action sequence is executed.}
  \label{fig:pipeline}
  \vspace{-1em}
\end{figure*}

\begin{enumerate}
    \vspace{-1em}
    \item Query an LLM to obtain a generic sequence of actions (sub-tasks) to be executed to accomplish any given task.
    %We propose a framework for handling Open Set task queries that aligns the LLM action sequences with the Knowledge Graph ontology for the particular environment. Further the framework can seamlessly integrate new knowledge through human feedback or intervention when LLM sequences are such that they cannot be aligned with the KG despite repetitive and persistent prompting of the LLM seeking alignment to the graph. To the best of our knowledge we have not come across such a framework for handling Open Set task queries. 
    %\item Unlike previous approaches \cite{sakib2022approximate}, \cite{sakib2024} the current formulation precludes the need for large datasets, fine tuning LLMs that can become unwieldy when queries are not constrained to a specific setting such as cooking or recipe making. 
    \item Encode any prior domain-specific knowledge of object types and attributes in a KG, using it to revise the LLM's output action sequence.
   
    \item Use discrepancies between LLM output, KG, and observations of action outcomes to support human-in-the-loop (HITL) refinement of the knowledge in the KG.
    \vspace{-1.5em}
    %the proposed framework we demonstrate seamless transfer to a new environment without any fall or drop in performance. 
   % \item We present extensive ablations on our pipeline that showcases superior performance of our framework vis-Ã -vis methods that rely exclusively on LLM or KG alone and without a provision for KG expansion
\end{enumerate}
We illustrate and evaluate these capabilities in two different classes of tasks: cooking and cleaning, demonstrating: (a) substantial improvement in performance compared with baselines that use just the LLM or even a combination of LLM and KG for completing an assigned task; and (b) the ability to adapt to new classes of tasks through incremental knowledge refinement instead of elaborate tuning (e.g., of LLMs) or encoding comprehensive knowledge.

\vspace{-0.75em}
The remainder of the paper is organized as follows. We begin with a discussion of related work (Section~\ref{sec:related-work}), followed by a description of our proposed framework (Section~\ref{sec:framework}). We then discuss the experimental set up and results (Section~\ref{sec:exp-setup-results}), followed by the conclusions (Section~\ref{sec:conclusions}).
%\Madhav{It would be good to summarize the performance gain in quantitative terms compared with LLM, also across various LLMs}

%The contributions mentioned above are verified systematically through a set of hypotheses presented in the Results section (section \label{Results}). 

%\Madhav{Need a nice teaser showcasing the outcomes of our framework. The pipeline figure can come later}


%Starting with a small compact and minimalist KG representation -- expanding the KG with human feedback preempts need for dataset generation, ground truthing and fine tuning LLM.

%\paragraph{Enumerate Contributions}





