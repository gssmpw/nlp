\section{Related Work}
\label{sec:related-work}
%\nabanita{In developing our framework, which integrates large language models (LLMs), knowledge graphs (KGs), and human-in-the-loop validation for dynamic task decomposition, we draw upon several key advancements in task planning and decomposition.}
We motivate our framework by discussing related work in the use of LLMs, KGs, and HITL task decomposition.

\textbf{LLMs and KGs for task decomposition}: LLMs such as GPT-4~\cite{openai2024gpt4technicalreport}, Gemma2~\cite{gemmateam2024gemma2improvingopen}, and LLaMA3~\cite{dubey2024llama3herdmodels} have experimentally demonstrated the ability to decompose abstract tasks into sub-tasks~\cite{khot2023decomposedpromptingmodularapproach, reppert2023iterateddecompositionimprovingscience, wen2024learning,li2023semantically,dery2021auxiliarytaskupdatedecomposition,liu2024deltadecomposedefficientlongterm}. Frameworks such as TaskBench~\cite{shen2023taskbench} have compared fully automated processes with those with human interventions, particularly for unfamiliar or "open-set" tasks~\cite{wang2024tdag, cui2021semantic,liu2024deltadecomposedefficientlongterm}. Additionally, methods such as ADaPT~\cite{prasad2023adapt} have supported iterative adjustment of task complexity continuously based on real-time feedback. In parallel, KGs have have been used to model prior knowledge of objects and their attributes for sequential task planning, e.g., for sequential task prediction with graph CNN~\cite{article1}, action planning for robots in Industry 4.0 environments~\cite{10.1145/3297280.3297568}, and for generalizing to new (related) environments ~\cite{9561782}. Our framework builds on these ideas by combining the (generic) prediction capabilities of LLMs with the domain-specific knowledge encoded in a KG~\cite{aburasheed2024knowledgegraphscontextsources,pan2024unifying} for task adaptation in new environments~\cite{kuang2024openfmnavopensetzeroshotobject}.

%\textbf{KGs used in task decomposition}: Knowledge Graphs (KGs) have been widely used for task planning in robotics. KGs help model task relationships and enable sequential task prediction through graph CNN. RoboPlanner leverages KGs to create adaptive action plans for autonomous robots in . Moreover, KGs enable robots to generalize tasks from single demonstrations, improving execution success in new environments

\vspace{-0.75em}
\textbf{Related task planning examples}: The Functional Object-Oriented Network (FOON)~\cite{paulius2016functional} encodes substantial knowledge about cooking (e.g., ingredients and outcomes of actions) in the form of task trees and using them for task planning for cooking related dishes~\cite{ding2022robottaskplanningsituation,bhat2024groundingllmsrobottask,jiang2019task,sakib2022approximate}. In more recent work, a fine-tuned GPT has been used to transform generic recipe instructions into task trees, which are merged and revised by comparing information stored in FOONs to obtain the task tree used for execution~\cite{sakib2024cooking}. %, refining outputs through multiple model iterations (merging miniFOONs and creating SuperFOON) and validation against FOON\cite{paulius2016functional} . 
These methods use examples from the Recipe1M+ dataset~\cite{marin2021recipe1m+} for tuning and evaluation. Instead of tuning an LLM across classes of tasks or training a knowledge base extensively for a particular class of tasks, our framework supports incremental revision, faster adaptation, and reliability. Our framework provides the assistive agent limited (prior) knowledge of any specific domain as a KG, enabling it to incrementally refine the KG with new objects and actions as they are encountered, and to correct errors by soliciting and using human feedback when it is necessary and available. %This enables the system to handle novel tasks without requiring retraining, extending its application to domains beyond cooking and enabling robust performance across a diverse set of real-world tasks.

\vspace{-0.75em}
\textbf{Human-in-the-loop task decomposition}: Human feedback has been used to enhance hierarchical task allocation and robot task planning in complex environments~\cite{marzari2021towards,zhen2023robottaskplanningbased}. Frameworks like TaskBench~\cite{shen2023taskbench} and Reflexion~\cite{shinn2024reflexion} leverage human feedback to iteratively decompose tasks, making LLMs more effective in handling abstract tasks. Hierarchical task structuring is crucial for handling complex, multi-step task decomposition, especially in abstract problem domains~\cite{holler2020hddl}. Instead of iteratively tuning LLMs (e.g., through prompts), which does not necessarily lead to correct results, we combine the generic prediction capabilities of LLM, real-time domain-specific KG updates~\cite{DING2019105,article}, and human-in-the-loop feedback~\cite{kasaei2024vitalvisualteleoperationenhance,liu2023robotlearningjobhumanintheloop,9044335,emami2024human,wu2022survey},  allowing the system to operate based on the available knowledge to perform new classes of tasks while incrementally refining the knowledge.

% \ramandeep{The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs) for task execution in robotics has been explored in various contexts. Most existing works have been done under conditions involving a closed set of task formulations, considering predefined tasks and environments. Our approach follows a hybrid system that diverges by addressing open-set task challenges utilizing LLMs for task decomposition, KGs for verification, and human feedback for continuous knowledge expansion.}

% \subsection{KG Based Task Planning}

% \ramandeep{Knowledge Graphs have been widely used to model structured relationships between objects and actions, serving as one of the many bases for task planning in robotics. KNOWROB \Madhav{please cite and cite using the \cite{} command, you can say for you to know what you are citing so that you can get the bib done later, mention as \cite{Beetz-KG-2011} like that}, a framework using a pre-defined knowledge base of object properties and actions enables autonomous robots to reason and plan tasks. While KNOWROB excels in structured environments, it relies on pre-encoded knowledge, therefore making it less adaptable to unfamiliar tasks.  Similarly, Beetz (2011) proposed a robotic system using a pre-defined KG to generate task plans. The efficiency for these methods is demonstrated within constrained environments limiting their ability to generalize to novel or unexpected tasks without extensive retraining.}

% \ramandeep{Another related development was FOON \Madhav{cite please} which serves as a structured knowledge graph for cooking tasks. FOON treats tasks as functional blocks of object-action relationships that can be looked up to build a task tree guiding robotic execution. Sadman (2022) combined it with a fine-tuned GPT-3 model to automatically generate task trees for cooking recipes. Their approach combines multiple task trees proposed by the LLMs into one graph while running the task tree retrieval process to discard costly or wrong nodes, thus refining the precision and efficiency of task planning. This approach is bound by the fixed knowledge encoded in the KG, whereas our approach uses the latter strictly for verification so as to be able to handle novel tasks with open sets through dynamic expansion at execution time.}
% \Madhav{It is Important here to make it explicit that we are different in that we are NOT making use of KG for planning but for validation. I think that statement should be made explicitly for the section is on Task Planning}

% \subsection{LLM Based Task Execution} \Madhav{When you start a subsection, you can use the subsection command with a label that helps you refer those sections by referring to the label. I believe these things will get fixed at the end} 

% \ramandeep{Application of large language models can also be seen in generating task sequences for complex, long-horizon tasks. Mavrogiannis (2024) proposed Cook2LTL, which uses an LLM to convert cooking recipes into Linear Temporal Logic (LTL) formulas. These formulas serve as high-level task plans that are executable by robots. Although Cook2LTL has shown promising results, it is restricted to a fixed set of predefined actions and recipes, and its performance declines when faced with tasks that fall outside its training data \Madhav{can you make this claim stronger by citing the paper where this is shown if there is one}. On the contrary, our approach learns by dynamically expanding the KG based on human feedback and generalizes to new tasks and settings that are in environments for which no set of actions has been predefined.}

% \ramandeep{ProgPrompt \Madhav{cite again} uses LLMs to generate action sequences but lacks a verification mechanism to ensure the generated actions are feasible in the real world. Our approach tackles this by considering KG as a verification tool that filters out infeasible actions and including human feedback for both refinement and further expansion of the KG to make it adaptive to a wider range of tasks. In this manner, the human-in-the-loop system will result in dynamic growth of the KG, therefore allowing the robot to deal with tasks not seen before without retraining or fine-tuning.}

% \Madhav{Overall well written. But I think we need to refer to more papers. Will be good to cite at-least 20 papers. One way is to look at those papers that have cited the above. Also you may want to look at those who have used KG for verification.}
