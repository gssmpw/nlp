%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[article, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
\setlength{\parskip}{0pt}
\pdfminorversion=4
% \documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins  
\UseRawInputEncoding 
\let\labelindent\relax
\usepackage{enumitem}
\setlist{topsep=1pt, partopsep=0pt, parsep=0pt, itemsep=0pt}
\usepackage[
top    = 0.75in,
bottom = 0.75in,
left   = 0.75in,
right  = 0.75in]{geometry}
\usepackage{cite}
\usepackage{amsmath}
\usepackage[skip=10pt plus1pt, indent=35pt]{parskip}
\usepackage{placeins}
\usepackage{textcomp}
\usepackage[dvipsnames]{xcolor}
\definecolor{royalblue}{RGB}{65, 105, 225}
\definecolor{maroon}{RGB}{180, 0, 0}
\definecolor{DarkGreen}{RGB}{0, 100, 0}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage[symbol]{footmisc}
\usepackage{adjustbox}
\usepackage{float}
% \usepackage{paralist}
\usepackage{svg}
\usepackage{array}
\usepackage[T1]{fontenc}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{scrextend}
% \usepackage[export]{adjustbox}
\usepackage{caption}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{calligra}
\usepackage{comment}
\usepackage{soul}
\usepackage{balance}
% \documentclass{article}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{caption}
\newcolumntype{A}{ >{\centering\arraybackslash} m{4cm} }
\newcolumntype{B}{ >{\centering\arraybackslash} m{1cm} }
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcommand{\todo}[1]{\textbf{\textcolor{red}{TODO: #1}}}
\newcommand{\Madhav}[1]{\textcolor{magenta}{Madhav: #1}}
\newcommand{\nabanita}[1]{\textcolor{violet}{#1}}
\newcommand{\karthik}[1]{\textcolor{blue}{#1}}
\newcommand{\shivam}[1]{\textcolor{olive}{#1}}
\newcommand{\ramandeep}[1]{\textcolor{orange}{#1}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\long\def\commentm#1{{\bf **Mohan: #1**}}

\makeatletter
\newcommand\footnoteref[1]{\protected@xdef\@thefnmark{\ref{#1}}\@footnotemark}
\makeatother


% \usepackage{flushend}
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath,lipsum} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{amsfonts}
\usepackage{textgreek}
\usepackage{authblk}
\usepackage{etoolbox}
\usepackage{algpseudocode}

\algrenewcommand\algorithmicindent{0.5em}
\newcommand\crule[3][black]{\textcolor{#1}{\rule{#2}{#3}}}
\DeclareMathOperator*{\argminA}{arg\,min} % Jan Hlavacek
\makeatletter
\let\NAT@parse\undefined

\let\oldthebibliography\thebibliography
\let\endoldthebibliography\endthebibliography
\renewenvironment{thebibliography}[1]{
  \oldthebibliography{#1}
  \setlength{\itemsep}{-1.75ex plus-.1ex minus-.1ex} % Adjust the value (e.g., -1ex) to change the spacing
}{
  \endoldthebibliography
}

\makeatother

% \algnewcommand{\algorithmicforeach}{\textbf{for}}
% \algdef{SE}[FOR]{ForEach}{EndForEach}[1]
%   {\algorithmicforeach\ #1\ \algorithmicdo}% \ForEach{#1}
%   {\algorithmicend\ \algorithmicforeach}% \EndForEach

\usepackage[colorlinks=true, citecolor=cyan]{hyperref}  
\setlength{\parindent}{0.5cm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\lstset{
    language=Lisp,
    frame=single,
    breaklines=true,
    basicstyle=\scriptsize\ttfamily,
    moredelim=**[is][\color{red}]{@}{@},
}

% \title{\LARGE \bf
% Planology: Anticipating household sequences and planning for human-robot collaboration
% \thanks{*Denotes equal contribution}
% }

%\title{\LARGE \bf
%Validating LLM Based Open Set Task Decomposition with Knowledge Graphs and Human Intervened Validation for Task Accomplishment\thanks{*Denotes equal contribution}}

% LLM-based generic task decomposition, KG-based domain-specific task decomposition, HITL

\title{\LARGE \bf
AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement}


\author{ Shivam Singh$^{1*}$, Karthik Swaminathan$^{1*}$, Nabanita Dash$^1$, Ramandeep Singh$^1$ \\  Snehasis Banerjee$^2$,  Mohan Sridharan$^3$,  Madhava Krishna$^1$
\thanks{*Denotes equal contribution}

\thanks{$^{1}$ Robotics Research Center, IIIT Hyderabad, India}
\thanks{$^{2}$ TCS Research, Tata Consultancy Services, India}
\thanks{$^{3}$ School of Informatics, University of Edinburgh, UK}
}

\makeatletter
\renewcommand{\@seccntformat}[1]{%
  \protect\csname the#1\endcsname\protect\quad%
}
\makeatother

\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}

\begin{document}


\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
An embodied agent assisting humans is often asked to complete new tasks, and 
%An agent preparing a particular dish in the kitchen based on a known recipe may be asked to prepare a new dish or to perform cleaning tasks in the storeroom. 
there may not be sufficient time or labeled examples to train the agent to perform these new tasks. Large Language Models (LLMs) trained on considerable knowledge across many domains can be used to predict a sequence of abstract actions for completing such tasks, although the agent may not be able to execute this sequence due to task-, agent-, or domain-specific constraints. Our framework addresses these challenges by leveraging the generic predictions provided by LLM and the prior domain knowledge encoded in a Knowledge Graph (KG), enabling an agent to quickly adapt to new tasks. The robot also solicits and uses human input as needed to refine its existing knowledge. Based on experimental evaluation in the context of cooking and cleaning tasks in simulation domains, we demonstrate that the interplay between LLM, KG, and human input leads to substantial performance gains compared with just using the LLM. \\
Project website\footnote[4]{Project supported in part by TCS Research India}: \href{https://sssshivvvv.github.io/adaptbot/}{https://sssshivvvv.github.io/adaptbot/}
%\Madhav{Please add: Through a diversity of metrics we show substantial performance gain through the interplay between LLM, KG and Human feedback than a straightforward task execution based on abstract LLM outputs.}

%Embodied agents or assistive robots may often be challenged to accomplish a task that they have not encountered before or trained for. For example an assistive or a personal robot may be asked to cook a new recipe or perform a cleaning task with novel specifications. In such scenarios it can indeed be challenging and cumbersome to train the agent all over again for apart from the training process itself data generation offers significant difficulties. LLM have become popular in very recent times as a popular framework for novel task synthesis. When prompted adequately LLM can achieve novel task synthesis by decomposing the task into a sequence of sub tasks that need to be achieved in the specified sequence for successful completion. However LLM task sequencing abilities are statistical offering much room for improving its success rates. In this paper we propose a novel framework that effectively blends the statistical nature of LLM outputs with the deterministic nature of Knowledge Graph ontologies to achieve novel tasks by significantly improving the performance of LLM. Further by involving humans in a principled fashion %to validate LLM sequences that lie outside the domain of the KG we show  the framework increments and updates it Knowledge Graph showcasing knowledge refinement, expansion features that leads to further improvement across various performance metrics

\end{abstract}
\vspace{-1em}
\begin{keywords}
Large Language Models, Knowledge Graph, Human-in-the-loop Learning
\end{keywords}
% \textbf{Color Coding}: \\
% \crule[purple]{10pt}{10pt} : \raghav{Raghav} \\
% \crule[blue]{10pt}{10pt} : \karthik{Karthik}\\
% \crule[olive]{10pt}{10pt} : \shivam{Shivam}\\

\input{sections/01-introduction}
%\section{INTRODUCTION}\label{Intro}

\input{sections/02-related_work}
\input{sections/03-formulation}
\input{sections/04-results}
\input{sections/05-conclusions}
\balance

\bibliographystyle{IEEEtran}
% \bibliography{IEEEabrv,references}
% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{coppeliaSim}
E.~Rohmer \emph{et~al.}, ``Coppeliasim (formerly v-rep): a versatile and scalable robot simulation framework,'' in \emph{Proc. of The International Conference on Intelligent Robots and Systems (IROS)}, 2013, www.coppeliarobotics.com.

\bibitem{Puig_2018_CVPR}
X.~Puig \emph{et~al.}, ``Virtualhome: Simulating household activities via programs,'' in \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2018.

\bibitem{kolve2022ai2thorinteractive3denvironment}
\BIBentryALTinterwordspacing
E.~Kolve \emph{et~al.}, ``Ai2-thor: An interactive 3d environment for visual ai,'' 2022. [Online]. Available: \url{https://arxiv.org/abs/1712.05474}
\BIBentrySTDinterwordspacing

\bibitem{khot2023decomposedpromptingmodularapproach}
\BIBentryALTinterwordspacing
T.~Khot \emph{et~al.}, ``Decomposed prompting: A modular approach for solving complex tasks,'' 2023. [Online]. Available: \url{https://arxiv.org/abs/2210.02406}
\BIBentrySTDinterwordspacing

\bibitem{reppert2023iterateddecompositionimprovingscience}
\BIBentryALTinterwordspacing
J.~Reppert \emph{et~al.}, ``Iterated decomposition: Improving science q\&a by supervising reasoning processes,'' 2023. [Online]. Available: \url{https://arxiv.org/abs/2301.01751}
\BIBentrySTDinterwordspacing

\bibitem{liu2024deltadecomposedefficientlongterm}
\BIBentryALTinterwordspacing
Y.~Liu \emph{et~al.}, ``Delta: Decomposed efficient long-term robot task planning using large language models,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2404.03275}
\BIBentrySTDinterwordspacing

\bibitem{sakib2022approximate}
M.~S. Sakib \emph{et~al.}, ``Approximate task tree retrieval in a knowledge network for robotic cooking,'' \emph{IEEE Robotics and Automation Letters}, vol.~7, no.~4, pp. 11\,492--11\,499, 2022.

\bibitem{sakib2024cooking}
M.~S. Sakib and Y.~Sun, ``From cooking recipes to robot task trees--improving planning correctness and task efficiency by leveraging llms with a knowledge network,'' in \emph{2024 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2024, pp. 12\,704--12\,711.

\bibitem{openai2024gpt4technicalreport}
\BIBentryALTinterwordspacing
OpenAI \emph{et~al.}, ``Gpt-4 technical report,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2303.08774}
\BIBentrySTDinterwordspacing

\bibitem{gemmateam2024gemma2improvingopen}
\BIBentryALTinterwordspacing
G.~Team \emph{et~al.}, ``Gemma 2: Improving open language models at a practical size,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2408.00118}
\BIBentrySTDinterwordspacing

\bibitem{dubey2024llama3herdmodels}
\BIBentryALTinterwordspacing
Dubey \emph{et~al.}, ``The llama 3 herd of models,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2407.21783}
\BIBentrySTDinterwordspacing

\bibitem{wen2024learning}
J.~Wen \emph{et~al.}, ``Learning task decomposition to assist humans in competitive programming,'' \emph{arXiv preprint arXiv:2406.04604}, 2024.

\bibitem{li2023semantically}
W.~Li \emph{et~al.}, ``Semantically aligned task decomposition in multi-agent reinforcement learning,'' \emph{arXiv preprint arXiv:2305.10865}, 2023.

\bibitem{dery2021auxiliarytaskupdatedecomposition}
\BIBentryALTinterwordspacing
L.~M. Dery \emph{et~al.}, ``Auxiliary task update decomposition: The good, the bad and the neutral,'' 2021. [Online]. Available: \url{https://arxiv.org/abs/2108.11346}
\BIBentrySTDinterwordspacing

\bibitem{shen2023taskbench}
Y.~Shen \emph{et~al.}, ``Taskbench: Benchmarking large language models for task automation,'' \emph{arXiv preprint arXiv:2311.18760}, 2023.

\bibitem{wang2024tdag}
Y.~Wang \emph{et~al.}, ``Tdag: A multi-agent framework based on dynamic task decomposition and agent generation,'' \emph{arXiv preprint arXiv:2402.10178}, 2024.

\bibitem{cui2021semantic}
G.~Cui, W.~Shuai, and X.~Chen, ``Semantic task planning for service robots in open worlds,'' \emph{Future Internet}, vol.~13, no.~2, p.~49, 2021.

\bibitem{prasad2023adapt}
A.~Prasad \emph{et~al.}, ``Adapt: As-needed decomposition and planning with language models,'' \emph{arXiv preprint arXiv:2311.05772}, 2023.

\bibitem{article1}
D.~Zheng \emph{et~al.}, ``A knowledge-based task planning approach for robot multi-task manipulation,'' \emph{Complex \& Intelligent Systems}, vol.~10, 07 2023.

\bibitem{10.1145/3297280.3297568}
\BIBentryALTinterwordspacing
A.~Kattepur and B.~P, ``Roboplanner: autonomous robotic action planning via knowledge graph queries,'' in \emph{Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing}, ser. SAC '19.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2019, p. 953â€“956. [Online]. Available: \url{https://doi.org/10.1145/3297280.3297568}
\BIBentrySTDinterwordspacing

\bibitem{9561782}
A.~Daruna \emph{et~al.}, ``Towards robust one-shot task execution using knowledge graph embeddings,'' in \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}, 2021, pp. 11\,118--11\,124.

\bibitem{aburasheed2024knowledgegraphscontextsources}
\BIBentryALTinterwordspacing
H.~Abu-Rasheed \emph{et~al.}, ``Knowledge graphs as context sources for llm-based explanations of learning recommendations,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2403.03008}
\BIBentrySTDinterwordspacing

\bibitem{pan2024unifying}
S.~Pan \emph{et~al.}, ``Unifying large language models and knowledge graphs: A roadmap,'' \emph{IEEE Transactions on Knowledge and Data Engineering}, 2024.

\bibitem{kuang2024openfmnavopensetzeroshotobject}
\BIBentryALTinterwordspacing
Y.~Kuang \emph{et~al.}, ``Openfmnav: Towards open-set zero-shot object navigation via vision-language foundation models,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2402.10670}
\BIBentrySTDinterwordspacing

\bibitem{paulius2016functional}
D.~Paulius \emph{et~al.}, ``Functional object-oriented network for manipulation learning,'' in \emph{2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 2655--2662.

\bibitem{ding2022robottaskplanningsituation}
\BIBentryALTinterwordspacing
Y.~Ding \emph{et~al.}, ``Robot task planning and situation handling in open worlds,'' 2022. [Online]. Available: \url{https://arxiv.org/abs/2210.01287}
\BIBentrySTDinterwordspacing

\bibitem{bhat2024groundingllmsrobottask}
\BIBentryALTinterwordspacing
V.~Bhat \emph{et~al.}, ``Grounding llms for robot task planning using closed-loop state feedback,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2402.08546}
\BIBentrySTDinterwordspacing

\bibitem{jiang2019task}
Y.-q. Jiang \emph{et~al.}, ``Task planning in robotics: an empirical comparison of pddl-and asp-based systems,'' \emph{Frontiers of Information Technology \& Electronic Engineering}, vol.~20, pp. 363--373, 2019.

\bibitem{marin2021recipe1m+}
J.~Mar{\i}n \emph{et~al.}, ``Recipe1m+: A dataset for learning cross-modal embeddings for cooking recipes and food images,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~43, no.~1, pp. 187--203, 2021.

\bibitem{marzari2021towards}
L.~Marzari \emph{et~al.}, ``Towards hierarchical task decomposition using deep reinforcement learning for pick and place subtasks,'' in \emph{2021 20th International Conference on Advanced Robotics (ICAR)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp. 640--645.

\bibitem{zhen2023robottaskplanningbased}
\BIBentryALTinterwordspacing
Y.~Zhen \emph{et~al.}, ``Robot task planning based on large language model representing knowledge with directed graph structures,'' 2023. [Online]. Available: \url{https://arxiv.org/abs/2306.05171}
\BIBentrySTDinterwordspacing

\bibitem{shinn2024reflexion}
N.~Shinn \emph{et~al.}, ``Reflexion: Language agents with verbal reinforcement learning,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{holler2020hddl}
D.~H{\"o}ller \emph{et~al.}, ``Hddl: An extension to pddl for expressing hierarchical planning problems,'' in \emph{Proceedings of the AAAI conference on artificial intelligence}, vol.~34, no.~06, 2020, pp. 9883--9891.

\bibitem{DING2019105}
\BIBentryALTinterwordspacing
Y.~Ding \emph{et~al.}, ``Robotic task oriented knowledge graph for human-robot collaboration in disassembly,'' \emph{Procedia CIRP}, vol.~83, pp. 105--110, 2019, 11th CIRP Conference on Industrial Product-Service Systems. [Online]. Available: \url{https://www.sciencedirect.com/science/article/pii/S2212827119304263}
\BIBentrySTDinterwordspacing

\bibitem{article}
J.~Bai \emph{et~al.}, ``A dynamic knowledge graph approach to distributed self-driving laboratories,'' \emph{Nature Communications}, vol.~15, 01 2024.

\bibitem{kasaei2024vitalvisualteleoperationenhance}
\BIBentryALTinterwordspacing
H.~Kasaei and M.~Kasaei, ``Vital: Visual teleoperation to enhance robot learning through human-in-the-loop corrections,'' 2024. [Online]. Available: \url{https://arxiv.org/abs/2407.21244}
\BIBentrySTDinterwordspacing

\bibitem{liu2023robotlearningjobhumanintheloop}
\BIBentryALTinterwordspacing
H.~Liu, S.~Nasiriany, L.~Zhang, Z.~Bao, and Y.~Zhu, ``Robot learning on the job: Human-in-the-loop autonomy and learning during deployment,'' 2023. [Online]. Available: \url{https://arxiv.org/abs/2211.08416}
\BIBentrySTDinterwordspacing

\bibitem{9044335}
M.~Raessa \emph{et~al.}, ``Human-in-the-loop robotic manipulation planning for collaborative assembly,'' \emph{IEEE Transactions on Automation Science and Engineering}, vol.~17, no.~4, pp. 1800--1813, 2020.

\bibitem{emami2024human}
Y.~Emami, K.~Li, L.~Almeida, W.~Ni, and Z.~Han, ``Human-in-the-loop machine learning for safe and ethical autonomous vehicles: Principles, challenges, and opportunities,'' \emph{arXiv preprint arXiv:2408.12548}, 2024.

\bibitem{wu2022survey}
X.~Wu, L.~Xiao, Y.~Sun, J.~Zhang, T.~Ma, and L.~He, ``A survey of human-in-the-loop for machine learning,'' \emph{Future Generation Computer Systems}, vol. 135, pp. 364--381, 2022.

\end{thebibliography}
\end{document}


