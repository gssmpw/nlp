% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{amsmath}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\newcommand{\mf}[1]{\textcolor{orange}{MF: #1}}

\title{MTPChat: A Multimodal Time-Aware Persona Dataset \\ for Conversational Agents}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
 \bfseries
 Wanqi Yang$^{1 \ast}$
 \
 Yanda Li$^{1}$\thanks{Equal contributions}
 \
 Meng Fang$^{2}$
 \
 Ling Chen$^1$
 \\
 \normalsize 
 $ ^1$ University of Technology Sydney
 \
 $ ^2 $ University of Liverpool
 \\
 {\normalsize \tt   wanqi.yang-1@student.uts.edu.au, 
 \normalsize \tt Yanda.Li@student.uts.edu.au}\\
 \normalsize \tt  Meng.Fang@liverpool.ac.uk,
 \normalsize \tt ling.chen@uts.edu.au
 }


%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle

%\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%\footnotetext[1]{Equal contribution} 

%\renewcommand{\thefootnote}{\arabic{footnote}} 

\begin{abstract}
%\mf{To build self-consistent personalized dialogue agents, previous research has primarily focused on aligning conversations to deliver personal facts or personalities. However, understanding temporal dynamics is crucial for fully capturing the essence of a persona, as it can more effectively reveal the speaker's personal characteristics and experiences in episodic memory. In this work, we address the often-overlooked aspect of temporal dynamics in persona chats. Firstly, we introduce MPTChat, a multimodal time-sensitive dialogue dataset that integrates linguistic, visual, and temporal elements in dialogue and persona memory. Secondly, we design two time-sensitive tasks: Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory Prediction (TGMP), which utilize implicit temporal cues and dynamic aspects to challenge models' temporal sensitivity. Furthermore, we present an innovative framework with an adaptive temporal module to effectively integrate these multimodal streams and build interconnections. Experimental results confirm the novel challenges posed by MPTChat and demonstrate the effectiveness of our framework in multimodal time-sensitive scenarios.} \mf{The following motivation is not correct or too general} 
%Understanding temporal dynamics is critical for applications ranging from multimedia content analysis to decision-making. However, existing time-sensitive datasets are predominantly focus on QA tasks and rely on explicit time information, which narrows their scope and diminishes their complexity. 
Understanding temporal dynamics is critical for conversational agents, enabling effective content analysis and informed decision-making. However, time-aware datasets, particularly for persona-grounded conversations, are still limited, which narrows their scope and diminishes their complexity. To address this gap, we introduce MTPChat, a multimodal, time-aware persona dialogue dataset that integrates linguistic, visual, and temporal elements within dialogue and persona memory. Leveraging MTPChat, we propose two time-sensitive tasks: Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory Prediction (TGMP), both designed to assess a modelâ€™s ability to understand implicit temporal cues and dynamic interactions. Additionally, we present an innovative framework featuring an adaptive temporal module to effectively integrate multimodal streams and capture temporal dependencies. Experimental results validate the challenges posed by MTPChat and demonstrate the effectiveness of our framework in multimodal time-sensitive scenarios.
%To overcome these limitations, we introduce MTPChat, a multimodal time-aware persona dialogue dataset that integrates linguistic, visual, and temporal elements in dialogue and persona memory. Based on MTPChat, we design two time-sensitive tasks, Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory Prediction (TGMP), utilizing implicit temporal cues and dynamic aspects to challenge model's temporal awareness. Furthermore, we present an innovative framework with an adaptive temporal module to integrate these multimodal streams and build interconnections effectively. The experimental results confirm that novel challenges of MTPChat and effectiveness of our framework in multimodal time-sensitive scenarios.
\end{abstract}

\input{Introduction.tex}
\input{MTSChat.tex}
\input{Task_Definition.tex}
\input{Model.tex}
\input{Experiments.tex}
\input{Related_Work.tex}
\input{Conclusion.tex}



% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}


\clearpage
\begin{center}\large\bfseries
Appendix
\end{center}

\appendix

\section{Detailed Prompt of GPT-4}
\label{sec:appendix1}

\begin{table}[h]

\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{l}
\toprule
\textbf{Prompt of GPT-4 for generating response to early-stage conversation}  \\
\midrule
Given the topic of a conversation, the context of the dialogue, and multiple memories \\of the speaker, please write a response to the conversation. \\
 \\
It is important to note:\\
1. responses could not exceed 40 words.\\
2. If the memories are almost unrelated to the conversation, the generated response \\should reflect the speaker's lack of expertise in the conversation topic. \\If appropriate, consider incorporating the current content of the speaker's memories. \\
3. If the memories are related to the conversation, the response should express \\a willingness to try or explore it in the future. \\
 \\
Conversation Topic: [topic]\\
Dialogue Context: [context]\\
Memories: [context]\\
\bottomrule
\end{tabular} }
\caption{\label{Parameters1} Detailed prompt of GPT-4 for generating response to early-stage conversation.}
\end{table}

\section{Detailed Parameters}
\label{sec:appendix2}
The parameter settings of Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory Prediction (TGMP) tasks used in our paper are illustrated in Table~\ref{Parameters1}.


\begin{table}[h]

\centering
\resizebox{0.8\columnwidth}{!}{
\begin{tabular}{l|c|c}
\toprule
\textbf{Parameters} & \textbf{TNRP} & \textbf{TGMP} \\
\midrule
per\_gpu\_train\_batch\_size & 8 & 8 \\ 
per\_gpu\_eval\_batch\_size& 1 & 4  \\
num\_train\_epoch& 5 & 5  \\
max\_num\_candidates& 100 & 100   \\
max\_num\_image& 20 & 20  \\
image\_size &224 & 224 \\
learning\_rate& $3e^{-6}$ & $3e^{-6}$\\
weight\_decay &0.05 &0.05    \\
\bottomrule
\end{tabular} }
\caption{\label{Parameters1} Detailed Parameters of Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory Prediction (TGMP) tasks.}
\end{table}

\end{document}
