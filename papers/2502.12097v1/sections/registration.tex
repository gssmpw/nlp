\subsection{Large deformation diffeomorphic metric mapping}\label{ssec:resnet-lddmm-intro}
The registration, or image matching problem, consists in smoothly mapping a \textit{source} (or template) image into a \textit{target} image. 
Our approach is based on the so-called Large Deformation Diffeomorphic Metric Mapping (LDDMM), in which
the map between the source and the target is sought as a diffeomorphic flow of an ODE~\cite{bruveris2017completeness,dupuis1998variational}.
In this section, we present the formulation of the method from a continuous perspective and the main theoretical background. 
The specific implementation to the case of three-dimensional
meshes of aortic shapes will be described in detail in section \ref{subsec:resnetlddmm}.

Formally, let us consider the source and target images defined by the characteristic functions $\chi_S:\mathbb{R}^3\rightarrow\mathbb{R}$ and $\chi_T:\mathbb{R}^3\rightarrow\mathbb{R}$, respectively.
We assume that both images are contained in an open bounded set, i.e., 
\begin{equation*}
\text{supp}(\chi_S)\cup\text{supp}(\chi_T)\subset G\subset\mathbb{R}^3.
\end{equation*}

The goal of LDDMM is to find a diffeomorphic map between the source and the target as a one-parameter group of diffeomorphisms  $\{\phi(t, \cdot)\}_{t\in I}$, $I :=[0,1]$, defined
as the flow of an ODE depending on a vector field $f:I\times\mathbb{R}^3\rightarrow\mathbb{R}^3$, i.e., such that
\begin{equation}\label{eq:phi_t_lddmm}
  d_t \phi(t, \x) = f(t, \phi(t, \x)),\qquad \phi(0, \x) = \x,\qquad\forall\x\in G.
\end{equation}
In particular, $\chi_S\left(\phi(0,\cdot)\right) = \chi_S$ coincides with the source, and  $\chi_S\left(\phi(1,\cdot)\right)$ is the mapped image.
%
The problem is addressed in an optimal control framework, where the control is the vector field $f$, minimizing the matching error between the mapped source and the target.
%
The following result ensures the existence of an optimal solution in the considered setting for arbitrary dimension $d$. 


\begin{theorem}[LDDMM registration, theorem 3.1~\cite{dupuis1998variational}]
  \label{def:regpb}
  Assume that $S:G\rightarrow\mathbb{R}$ and $T:G\rightarrow\mathbb{R}$ are two bounded measurable functions, and that $S$ 
 \textit{(e.g., the source image)} is continuous almost everywhere. 
 Let us suppose that $f\in L^2(I, H^s)$, with $s>d/2 + 1$ (the Sobolev embedding implies $f\in \mathcal{C}^{1, \alpha}(I, \mathcal{C}^{1, \alpha})$ with $\alpha=s - \tfrac{d}{2} - 1>0$), then the following registration problem
  \begin{equation}\label{eq:reg_miminization}
    \min_{f\in L^2(I, H^s)} \int_{0}^{1}\lVert f(t, \cdot)\rVert^2_{H^s}\ dt + \int_G |S(\phi(1, \x))-T(\x)|^2\ d\x
  \end{equation}
  has a minimizer.
\end{theorem}
%

In particular, theorem \ref{def:regpb} holds for signed distance functions, as well as for the particular case of characteristic functions. % $\chi_S$ and $\chi_T$.
The regularity condition $f\in L^2(I, H^s)$, with $s>d/2 + 1$ from the Sobolev embedding theorem, is sufficient to obtain that $\{\phi(t, \cdot)\}_{t\in I}\subset\text{Diff}^1(G)$ is a one-parameter group of diffeomorphisms. 
%
In general,  for a generic Hilbert space $\mathcal{H}$ such that $\mathcal{H}\hookrightarrow C^1_b(\mathbb{R}^d)$, the group $\mathcal{G}_\mathcal{H}(\mathbb{R}^d)$ of diffeomorphisms generated by vector fields in $L^2(I, \mathcal{H})$ is only strictly contained in $\text{Diff}^1(\mathbb{R}^d)$.
However, if $s>d/2+1$, it holds (see ~\cite{bruveris2017completeness}) 
\[
\mathcal{G}_{H^s}=\mathcal{D}^s(\mathbb{R}^d) =\{\phi\in\text{Diff}^1(\mathbb{R}^d) \mid \phi\in\text{Id}+H^s(\mathbb{R}^d,\mathbb{R}^d)\}.
\]


Using the universal approximation theorems of neural networks, one can infer the existence of neural networks that approximate the vector field $f$ arbitrarily well, 
with convergence estimates depending on its regularity.
\begin{theorem}[Existence of ResNet-LDDMM vector field]
  \label{theo:existreg}
Let  $f:I\times\mathbb{R}^d\rightarrow\mathbb{R}^d$ be a minimizer for problem \eqref{eq:reg_miminization}, let
$\{\phi(t, \cdot)\}_{t\in I}$ the corresponding group of diffeomorphisms \eqref{eq:phi_t_lddmm}, and let $\epsilon>0$. 
\begin{itemize}
\item[(i)]There exists a neural network (NN) $f_\epsilon: I\times \mathbb{R}^d\rightarrow  I\times \mathbb{R}^d$, $f_\epsilon\in\mathcal{C}^{0, 1}(I, \mathcal{C}^{0, 1})$,  with ReLU activations and one hidden layer, such that:
  \begin{equation*}
    \lVert \phi_\epsilon - \phi\rVert_{L^2(I, L^2)}\rVert \leq C_1 \lVert f_\epsilon - f\rVert_{L^2(I, L^2)} \leq \epsilon,
  \end{equation*}
  where  $\{\phi_\epsilon(t, \cdot)\}_{t\in I}$ satisfy
 \begin{equation*}
    d_t \phi_\epsilon(t, \x) = f_\epsilon(t, \phi_\epsilon(t, \x)),\qquad \phi_\epsilon(0, \x) = \x,\qquad\forall\x\in G,
  \end{equation*}
and $C_1>0$ is independent of $\epsilon$.
  
\item[(ii)] Let $f_N\in\mathcal{C}^{2, 1}(I, \mathcal{C}^{2, 1})$ denote a deep NN, with a  fixed number of layers, ReCU activations, $N$ non-zero weights, and
let $\{\phi_N(t, \cdot)\}_{t\in I}$ be the flow of the corresponding ODE, i.e., 
  \begin{equation*}
    d_t \phi_N(t, \x) = f_N(t, \phi_N(t, \x)),\qquad \phi_N(0, \x) = \x,\qquad\forall\x\in G.
  \end{equation*}
For any $n\in\{0, 1\}$, and $\forall m\in\mathbb{N}$, $m\geq n+1$, the following estimate holds
  \begin{equation*}
    \lVert \phi_N - \phi\rVert_{L^2(I, H^n)}\rVert \leq C_2 \lVert f_N - f\rVert_{L^2(I, H^n)} \leq C_3\cdot N^{-\frac{m-n}{2(d+1)}},
  \end{equation*}
  with positive constants $C_2, C_3>0$ independent of $N$.
  \end{itemize}
\end{theorem}

\begin{proof}
See appendix~\ref{appendix:convergence}.
\end{proof}

In the practical implementation (see section~\ref{subsec:resnetlddmm}) we will 
consider only autonomous vector fields $f:\mathbb{R}^3\rightarrow \mathbb{R}^3$, i.e., that do not depend on $t\in I$,  and
NNs with ReLU activations, $7$ hidden layers, and where the first layer's input is augmented with Random Fourier Features (RFF).
%
Moreover, the matching error between mapped source and target images will be measured using a metric based on the Chamfer distance, which is a natural choice
when considering discrete point clouds, rather than the $L^2$-norm between characteristic functions used in \eqref{eq:reg_miminization}.
Up to our best knowledge, general existence results using the Chamfer distance are not available. However, it can be
shown that the solutions to a discrete version of~\eqref{eq:reg_miminization} with the discrete $L^2$-norm as discrepancy metrics convergence to the solution of the continuous registration problem (see appendix~\ref{appendix:convergence}). This result motivates also the usage of a multigrid optimization.

\subsection{Multigrid ResNet-LDDMM for aortic shape meshes}
\label{subsec:resnetlddmm}

\paragraph{Preliminaries} 
In this section, we address the shape registration between 3d computational domains representing different aortic surfaces, discretized by triangular meshes.  
%
We assume that, for all considered shapes, it is possible to subdivide each surface mesh into an inlet boundary $\Gamma_{\rm in}$, four outlet boundaries $\Gamma_1, \hdots,\Gamma_4$, 
and the wall boundary $\Gamma_{wall}$ (see equation \eqref{eq:omega_bnd}).
%
All shapes have are also characterized by a piecewise centerline $l\in\mathbb{R}^{n_{\text{cntrl}}\times 3}$ with a main branch (ascending and thoracic aorta) and three minor branches.
By construction (see section \ref{subsec:ssm}), we also assume that all centerlines have the same number of points $n_{\text{cntrl}}=390$.
%
These assumptions are motivated by the fact that all computational domains shall provide suitable discretizations of the physical model of interest 
(Equations \eqref{eq:3dnse}, with boundary conditions \eqref{eq:3dnse-bc}).

However, \textit{no assumptions} are made on the number of vertices, edges, or faces in each mesh nor on the connectivity of the elements.
In what follows, a shape $\mathcal S$ will be generally defined by the corresponding surface mesh, i.e., a pair $(X_{\mathcal S}, F_{\mathcal S})$, where
%
\begin{itemize}
  \item $\XS=\{\mathbf x_i\}_{i=1}^{n_{p,\mathcal S}}\subset\mathbb{R}^3$ is a point cloud with cardinality $n_{p,\mathcal S}>0$.
  \item $\FS = \{(a_i, b_i, c_i), a_i \neq b_i, a_i \neq c_i, b_i \neq c_i \}_{i=1}^{n_{f,\mathcal S}}\subset\mathbb{N}^3$, is a set of triangular faces with cardinality $n_{f,\mathcal S}>0$, where the element $(a_i, b_i, c_i)$ corresponds to the face 
defined by three (different) vertices $(\mathbf x_{a_i}, \mathbf x_{b_i}, \mathbf x_{c_i})$,
\end{itemize}
and its centerline $l_{\mathcal S}\in\mathbb{R}^{n_{\text{cntrl}}\times 3}$ ($n_{\text{cntrl}} = 90$, equal amount for all shapes).
We also introduce the set 
\begin{equation*}
\NS := \{\mathbf n_i^{\mathcal S}, i=1,\hdots,n_{p,\mathcal S}\} 
\end{equation*}
of normal vectors to the mesh vertices defined, for each $\mathbf x_i\in \XS$, as the linear combination of 
the normals of all faces adjacent to the vertex $\mathbf x_i$, weighted by the arccosine of the angles corresponding to $\mathbf x_i$ in the respective adjacent triangular faces, and renormalized such that $\lVert \mathbf n_i^{\mathcal S}\rVert=1$.

%
Let us also introduce, for two arbitrary point clouds $X_{\mathcal{S}}$ and $X_{\mathcal{T}}$, the \textit{Chamfer} distance
\begin{equation}
  \label{eq:classical_Chamfer}
  \mathcal{D}_{\text{Chamfer}}(X_{\mathcal{S}}, X_{\mathcal{T}}) = \frac{1}{n_{p,\mathcal{S}}}\left(\sum_{\mathbf x\in X_{\mathcal{S}}} \min_{ \mathbf y\in X_{\mathcal{T}}} \lVert \mathbf{\mathbf x} - \mathbf{\mathbf y} \rVert_2\right) + \frac{1}{n_{p, \mathcal{T}}}\left(\sum_{\mathbf y \in X_{\mathcal{T}}} \min_{\mathbf x \in X_{\mathcal{S}}} \lVert \mathbf{x} - \mathbf{y} \rVert_2\right).
\end{equation}
We consider a metric inspired by \eqref{eq:classical_Chamfer} but tailored to the case of closed meshes, accounting
for the comon anatomical features of all shapes and for the common subdivision of the boundary.  

Specifically, for a pair of shapes $(\XS,\FS;l_{\mathcal S})$ and $(X_{\mathcal T},F_{\mathcal T}; l_{\mathcal T})$, 
we define a modified Chamfer distance computed separately on each subdomain, and with an additional term related to the orientation of the faces on the vessel wall:
\begin{equation}\label{eq:mesh-chamfer}
\begin{aligned}
  \mathcal{D}_{\text{Chamfer}}^*&\left((\XS,\FS),(X_{\mathcal T},F_{\mathcal T})\right) := \\
% wall
& \mathcal{D}_{\text{Chamfer}}(\XS(\Gamma_{\text{wall}}), \XT(\Gamma_{\text{wall}})) \\
& +   \lambda_n \left( 
  \frac{1}{n_{p,\mathcal{S}}}\sum_{\mathbf x\in \XS(\Gamma_{\text{wall}})}   \left(1-\lvert \mathbf{n}_{\mathbf x}\cdot\mathbf{n}^*_{(\XT(\Gamma_{\text{wall}}),{\mathbf x})} \rvert \right)
   +    \frac{1}{n_{p,\mathcal{T}}}\sum_{\mathbf x\in \XT(\Gamma_{\text{wall}})}   \left(1-\lvert \mathbf{n}_{\mathbf x}\cdot\mathbf{n}^*_{(\XS(\Gamma_{\text{wall}}),{\mathbf x})} \rvert \right)
   \right)\\
 % open boundaries
&  + \sum_{i=1}^{4} \mathcal{D}_{\text{Chamfer}}(\XS(\Gamma_i), \XT(\Gamma_i)) + \mathcal{D}_{\text{Chamfer}}(\XS(\Gamma_{\text{in}}), \XT(\Gamma_{\text{in}})) \\
& +  \sum_{i=1}^{4} \mathcal{D}_{\text{Chamfer}}(\XS(\Gamma_i\cap\Gamma_{\text{wall}}), \XT(\Gamma_i\cap\Gamma_{\text{wall}}))+\mathcal{D}_{\text{Chamfer}}(\XS(\Gamma_{\text{in}}\cap\Gamma_{\text{wall}}), \XT(\Gamma_{\text{in}}\cap\Gamma_{\text{wall}})),
\end{aligned}
\end{equation}
where $n_{p, \mathcal S}$ and $n_{p,\mathcal T}$ denote the cardinalities of the two point clouds,
$X(\Gamma)$ stands for the subset of point clouds whose vertices belong to the boundary subset $\Gamma$, 
$\mathbf{n}^*_{(X,{\mathbf x})}$ is the normal at the point of $X$ closest to $\mathbf x$, and the constant $\lambda_n>0$ is an additional hyperparameter.

\paragraph*{Transformation map} 
Following the approach introduced in section \ref{ssec:resnet-lddmm-intro}, we seek a map between source and target shapes as a diffeomorphism $\phi:[0,1]\times\mathbb{R}^3\rightarrow\mathbb{R}^3$ defined as the flow of an autonomous ordinary differential equation:
\begin{equation}\label{eq:resnet-fnn-ode}
  \dot{\mathbf x} = f(\mathbf x;\theta),\qquad \frac{d}{dt}\phi(t, \mathbf x;\theta)=f(\mathbf  x;\theta),
\end{equation}
where the vector field $f:\mathbb{R}^3\rightarrow\mathbb{R}^3$ is approximated by a feed-forward neural network (FNN) with ReLU activations as in~\cite{amor2022resnet},
and where $\theta$ represents the dependency on a generic set of hyperparameters of the FNN. We will use the abbreviation $\phi_1=\phi(1,\cdot):\mathbb{R}^3\rightarrow\mathbb{R}^3$.

In practice, the ODE \eqref{eq:resnet-fnn-ode} is discretized with a forward Euler method with $10$ time steps in the interval $I=[0,1]$ ($\Delta t = \frac{1}{10}$), resulting in a ResNet architecture~\cite{amor2022resnet} taking as input only the points of the source surface mesh $X|_{t=0}=\XS$:
\begin{equation}
  \label{eq:resnet}
  X|_{t=\Delta t\cdot (i+1)} = X|_{t=\Delta t\cdot i} + \Delta t\cdot f_{FNN}(\psi(X|_{t=\Delta t\cdot i});\theta),\quad \forall i\in\{0, \dots, N-1\}.
\end{equation} 
The map  $\psi:\mathbb{R}^3\rightarrow\mathbb{R}^{3+6\cdot n_{rff}}$, 
\begin{equation*}
  \psi(X|_{t=\Delta t\cdot i}) = (X|_{t=\Delta t\cdot i}, \{\cos(2^i\cdot X|_{t=\Delta t\cdot i}), \sin(2^i\cdot X|_{t=\Delta t\cdot i})\}_{i=0}^{7}),
\end{equation*}
is used to augment the inpus,  at each time iteration, with random fourier features~\cite{tancik2020fourier}. We used $n_{rff}=8$ in our implementation.

We employ vectorization, so the feed-forward neural network $f_{FNN}:\mathbb{R}^{3+6\cdot n_{rff}}\rightarrow\mathbb{R}^3$ that defines the vector field $f:\mathbb{R}^3\rightarrow\mathbb{R}^3$, $f(x)\mapsto f_{FNN}(\psi(x); \theta)$ is evaluated on the rows of $\psi(X|_{t=\Delta t\cdot i})\in\mathbb{R}^{n_S\times (3+6\cdot n_{rff})}$ in equation~\eqref{eq:resnet}, and $\psi:\mathbb{R}^3\rightarrow\mathbb{R}^{3+6\cdot n_{rff}}$ acts on the rows of $X|_{t=\Delta t\cdot i}\in\mathbb{R}^{n_{p, S}\times 3}$, for every $i$. 

The architecture of the FNN that we use is fixed, but its weights change for every pair of source-target aorta geometries: it has six hidden layer of dimension $500$ with ReLU activations, an input dimension of $51$ and an output dimension of $3$.

\begin{rmk}[Bijectivity of the transformation map]
In general, ResNets as defined in equation~\eqref{eq:resnet} are not invertible. 
  Using the Banach fixed point theorem, a sufficient condition to have bijectivity is 
  $\{f_{FNN}(\psi(X|_{t=\Delta t\cdot i});\theta)\}_{i\in\{0, \dots, N-1\}}$ to be 1-Lipshitz. 
  In practice, this condition can be verified as a post-processing step once the registration map has been computed, without the need of 
  additional computational costs associated with techniques, architectures, and optimization methods that enforce the invertibility exactly. The bijectivity is necessary from the theoretical point of view to define the \textit{pllback} and \textit{pushforward} of the velocity and pressure fields, and from the practical point of view to implement more robust registration algorithms, since the bijectivity property acts as an additional regularization with respect to non-rigid deformations~\cite{scarpolini2023enabling}.
\end{rmk}

\paragraph{Objective function} 
Let us denote with $\mathcal A:=\{(X, F, l)\in\mathbb{R}^{\nvert \times 3}\times\mathbb{N}^{n_f\times 3}\times\mathbb{R}^{n_{\text{cntrl}}\times 3}\}$ the set of all possible combinations of aortic shapes (vertices, faces, centerlines) in $\mathbb R^3$.

The objective function $\mathcal{L}:\mathcal{A}\times\mathcal{A}\rightarrow\mathbb{R}$ has the form
\begin{equation}\label{eq:L_AA}
\begin{aligned}
  \mathcal{L}\left((\XS,\FS, \lS),(\XT,\FT, \lT)\right)  & = 
  \mathcal{D}_{\text{Chamfer}}^*(\phi(1, \XS; \theta), \XT) + \lambda_C\cdot\sum_{i=1}^{n_{\text{cntrl}}}\lVert \phi(1, l_{\mathcal S, i}; \theta)-l_{\mathcal T, i} \rVert^2_2 \\
  & \quad + 
\lambda_{\text{edges}}  \mathcal{R}_{\text{edges}}(\phi(1, \XS; \theta),\FS) +  \lambda_{\text{en}} \mathcal{R}_{\text{energy}}(X_{\mathcal S}; \theta)
\end{aligned}
\end{equation}
and it is composed by the modified Chamfer distance \eqref{eq:mesh-chamfer}
between the mapped source $(\phi(1, \XS),\FS)$ and the target $(\XT,\FT)$, 
the distance in $L^2$-norm between the mapped source centerline $l_{\mathcal{S}}=\{l_{\mathcal{S}, i}\}_{i=1}^{390}$ and the target centerline $l_{\mathcal{T}}=\{l_{\mathcal{T}, i}\}_{i=1}^{390}$, and 
two regularizers.
The first term %$\mathcal{R}_{\text{edges}}:\mathcal{A}\rightarrow\mathbb{R}$
%
%\begin{equation}
%  \label{eq:reg}
%  \mathcal{R}((\XS,\FS); \theta) = \lambda_{\text{edges}}\cdot\mathcal{R}_{\text{edges}}(\phi(1, A_S; \theta)) + \lambda_{\text{en}}\cdot\mathcal{R}_{\text{energy}}(A_S; %\theta),
%\end{equation}
\begin{equation*}
  \mathcal{R}_{\text{edges}}\left(X,F\right) := 
  \sum_{(a_i,b_i,c_i) \in F} \left(
  \sum_{(e,f) \in \{(a_i, b_i), (b_i,c_i),(c_i,a_i)\} } \lVert \mathbf x_e - \mathbf x_f \rVert^2_2
   \right),
   %\\
  %\sum_{i=1}^{n_{f, S}}&\left(\lVert\phi(1, x_{S, a_i})-\phi(1, x_{S, b_i})\rVert^2_2+ \lVert\phi(1, x_{S,b_i})-\phi(1, x_{S, c_i})\rVert^2_2 + \lVert\phi(1, x_{S, c_i})-\phi(1, x_{S, a_i})\rVert^2_2\right),
\end{equation*}
penalizes the presence of stretched edges in each face of the mesh, whilst the second term imposes the minimization of the kinetic energy along the discrete trajectory 
$\{X|_{t=\Delta t\cdot i}\}_{i=0}^{N-1}=\{\phi(\Delta t\cdot i, X_S)\}_{i=0}^{N-1}$:
\begin{equation*}
  \mathcal{R}_{\text{energy}}(\XS; \theta) := \sum_{i=0}^{N-1} \lVert f_{FNN}(\psi(X|_{t=\Delta t\cdot i});\theta)\rVert^2_2.
\end{equation*}

The constants $\lambda_C>0$, $\lambda_{\text{en}}$, $\lambda_{\text{edges}}$ are positive parameters. Notice that in the above definitions we have used the fact that, when applying the diffeomorphism $\phi$, only the point clouds (coordinates of the mesh vertices) are mapped, whilst the set of faces $\FS$ remains the same.


\begin{problem}[Shape registration with ResNet-LDDMM]
With the above definitions, we formulate the following discrete surface registration problem. Given a source and a target meshes 
$\mathcal S=(\XS,\FS, \lS)$ and $\mathcal T = (\XT,\FT, \lT)$, find 
  \label{def:resnetlddmm}
  \begin{align*}
    &\argmin_{\theta}\ 
    \mathcal{D}_{\text{Chamfer}}^*(\phi(1, \XS; \theta), \XT) + \lambda_C\cdot\sum_{i=1}^{n_{\text{cntrl}}}\lVert \phi(1, l_{\mathcal S, i}; \theta)-l_{\mathcal T, i} \rVert^2_2 \\
  & \quad + 
 \lambda_{\text{edges}} \mathcal{R}_{\text{edges}}(\phi(1, \XS; \theta),\FS) +  \lambda_{\text{en}} \mathcal{R}_{\text{energy}}(\{\phi(\Delta t\cdot (i+1), A_S;\theta)\}_{i=0}^{N-1})\\
%    \mathcal{D}_{\text{Chamfer}}(\phi(1, A_S;\theta), A_T) + \lambda_C\cdot\mathcal{D}_{\text{cntrl}}(\phi(1, l_S;\theta), l_T) \\
%    &\qquad+ \lambda_{\text{edges}}\cdot\mathcal{R}_{\text{edges}}(\phi(1, A_S;\theta)) + \lambda_{\text{en}}\cdot\mathcal{R}_{\text{energy}}(\{\phi(\Delta t\cdot (i+1), A_S;\theta)\}_{i=0}^{N-1})\\
  \end{align*}
such that   $\phi(t,\cdot;\theta)$ is the flow of the discretized ODE defined by the corresponding ResNet vector field:
%
\begin{align*}
    &\phi(\Delta t\cdot (i+1), \XS;\theta) = X|_{t=\Delta t\cdot i} + \Delta t\cdot f_{FNN}(\psi(X|_{t=\Delta t\cdot i});\theta),\quad \forall i\in\{0, \dots, N-1\},\\
    &\phi(0, X_S;\theta) = \XS.
\end{align*}
\end{problem}

\paragraph{Optimization} To solve Problem \eqref{def:resnetlddmm}, we consider the ADAM optimizer~\cite{kingma2014adam} combined with a \textit{multigrid} strategy, i.e., considering
three level of refinement for the source mesh, while the target mesh is kept fixed. 
This approach is crucial to guarantee 
the convergence of the discrete registration problem: on one hand it speeds up the procedure and on the other hand guarantees an arbitrary small registration error. 
In practice, for a source mesh $(\XS,\FS)$, we will denote as
\begin{equation*}
(\XS^{j}, \FS^{j})\in\mathbb{R}^{\nvert^{j}\times 3}\times\mathbb{N}^{n_f^{j}\times 3},\qquad j\in\{0, 1 , 2\},
\end{equation*}
with an increasing number of vertices $\nvert^{j=0} < \nvert^{j=1} < \nvert^{j=2}$ the three considered refinements, assuming that the set of faces is consistently refined.
The different refinements are obtained imposing a different upper bound for the lengths of face edges and an upper bound for the radii of the surface Delaunay balls. 


An analogous \textit{multigrid} approach has been proposed in~\cite{scarpolini2023enabling}. However, since both the transformation map 
$\phi(1, \cdot):\mathbb{R}^3\rightarrow\mathbb{R}^3$ and the vector field $f:\mathbb{R}^3\rightarrow\mathbb{R}^3$ act on the ambient space $\mathbb{R}^3$, we do not need to interpolate from one source mesh refinement to the other. 

\paragraph{Registration of the computational domain: \textit{pullback} and \textit{pushforward} operators}
For each couple of source and target meshes, we store the registration map as the image of the source point cloud, i.e.,  $\phi_1(X_{\mathcal{S}})\subset\mathbb{R}^3$. 
%
We denote with $\Omega_{\mathcal{S}}\subset\mathbb{R}^3$ and $\Omega_{\mathcal{T}}\subset\mathbb{R}^3$ the computational domains used for the CFD simulations for the source/template and target geometries, respectively. The surface registration maps are computed and interpolated on the source domain $\Omega_{\mathcal{S}}$ 
through RBF interpolation $\phi_{RBF}:\mathbb{R}^3\rightarrow\mathbb{R}^3$ with thin splines as kernels and $\phi_1(X_{\mathcal{S}})$ as centers.
Let $g_{\mathcal S}:\Omega_{\mathcal{S}}\rightarrow\mathbb{R}$ be a function defined on the source domain. The \textit{\textit{pushforward}} of $g_{\mathcal S}$ through the registration map
is defined as
\begin{equation}\label{eq:pushforward}
\phi_{RBF}^{\#}(g_{\mathcal S}):\Omega_{\mathcal{T}}\rightarrow\mathbb{R},\quad  \phi_{RBF}^{\#}(g_{\mathcal S}):=g_{\mathcal S} \circ\phi_{RBF}^{-1},
\end{equation}
Conversely, for a function  $g_{\mathcal T}:\Omega_{\mathcal{T}}\rightarrow\mathbb{R}$, the \textit{pullback} $(\phi_{RBF})_{\#} \left(g_{\mathcal T}\right):\Omega_{\mathcal{S}}\rightarrow\mathbb{R}$ is defined as:
\begin{equation}\label{eq:pullback}
  (\phi_{RBF})_{\#} \left(g_{\mathcal T}\right) :=\left(g_{\mathcal T} \right) \circ\phi_{RBF}.
\end{equation}



\subsection{Shape registration results}
To train the ResNet, the source (or template) mesh is chosen in the training set of shapes and kept fixed throughout the offline stage, 
whilst the target mesh varies among the remaining $723$ training shapes. 
In the online stage, the source is unchanged whilst the target mesh varies among the $52$ test geometries. 

\begin{rmk}[Choice of template geometry]
 The source mesh has been chosen within the training set without any particular criteria. In general, the selection can also be optimized with respect to the reconstruction error of the velocity and pressure fields, see section~\ref{sec:sml}.  
\end{rmk}


The hyperparameters for the regularization in \eqref{eq:L_AA} are chosen as $\lambda_n=5\cdot 10^{-5}$, $\lambda_C = 10^{-5}$, 
and   $\lambda_{\text{en}}=\lambda_{\text{edges}}=1$, for the terms related to face orientation, centerline, energy of the trajectory, and edges, respectively.


We consider a total number of epochs $n_{\text{epochs}}=5000$. The change of source mesh is performed at the epochs $e_{0,1} = 3000$, 
from $\left(\XS^{0}, \FS^{0}\right)$ to $\left(\XS^{1}, \FS^{1}\right)$, and  $e_{1,2} = 4000$, from $\left(\XS^{1}, \FS^{1}\right)$ 
to $\left(\XS^{2}, \FS^{2}\right)$. The source meshes have a number of vertices $n^{j=0}_v=4127$, $n^{j=1}_v=11402$ and  $n^{j=2}_v=110676$.
These values are kept fixed. However, one could also use an adaptive strategy to select the refinement epochs, e.g., based on the ratio between Chamfer distances at consecutive steps.

A sketch of the \textit{multigrid} optimization is shown in figure~\ref{fig:multigrid}, displaying both the mesh refinement on the aortic arch and the 
displacement field $\phi(1, X_S^i;\theta)\text{-}X_S^i$ for the different refinement levels. Figure~\ref{fig:multigrid} (left) shows also 
the loss decay on a sample geometry, highlighting the influence of the \textit{multigrid} strategy for convergence.
\begin{figure}[!htp]
  \centering
  \includegraphics[width=0.95\textwidth]{img/registration_multigrid.pdf}
  \caption{Application of the \textit{multigrid} ResNet-LDDMM. The source surface mesh is refined progressively during the training to guarantee the convergence of the discrete registration problem. 
\textbf{Left}: Decay of the Chamfer loss over the epochs. At epochs $3000$ and $4000$ the mesh is refined. 
\textbf{Right}: Displacement field $\phi(1, X_\mathcal{S}^i;\theta)\text{-}X_\mathcal{S}$ and surface mesh for refinement levels $j\in\{0, 1, 2\}$.}
  \label{fig:multigrid}
\end{figure}
Figure~\ref{fig:flow} depicts different steps of the registration process between two surface meshes showing
both the registration field $\phi(t_i, X_S;\theta)$ and the vector field $f(x;\theta)$ at different intermediate deformed configurations. See figure~\ref{fig:12_42} for an example of velocity and pressure fields' registration on the template geometry at systolic peak, corresponding to the best $n=12$ and worst $n=42$ test cases from figure~\ref{fig:cluster_v}. 
%
\begin{figure}[!htp]
  \centering
  \includegraphics[width=0.83\textwidth]{img/flow.pdf}
  \caption{Registration of a source surface mesh $X_\mathcal{S}$ onto the target surface mesh $X_\mathcal{T}$ through the ResNet-LDDMM vector field $f$. 
  \textbf{Top}: registration field $\phi(t_i, \mathbf x;\theta)$ at different intermediate steps $t_i$. \textbf{Bottom}: Vector field $f(\mathbf x;\theta)$ in the configuration $\phi(t_i, X_\mathcal{S};\theta)$.}
  \label{fig:flow}
\end{figure}

For validating the registration algorithm, we evaluate the classical Chamfer distance~\eqref{eq:classical_Chamfer} between the point clouds of the 
registered and the target geometries, normalized by the diameter of the target geometry, for each considered shape. The results, shown in Table \ref{tab:reg-chamfer}, confirm the 
robustness and the accuracy of the registration across the whole database.
The computational cost for registering the $723$ training geometries was of circa $\SI{114}{\hour}\approx 723\times\SI{9.45}{\minute}$ (embarrassingly parallel tasks), while the online registration of the source on a single
target required, on average, $9.45$ minutes.
\begin{table}[H]
    \centering
    \begin{tabular}{lcc}
         & \textbf{Training set} (n=723) & \textbf{Test set} (n=52) \\
         \hline
        Average Chamfer Distance & $0.00367$ & $0.00347$ \\
        \hline
        Maximum Chamfer Distance & $0.00605$ & $0.00470$ \\
        \hline
    \end{tabular}
    \caption{Chamfer distance~\eqref{eq:classical_Chamfer} between the registered source and target shapes, normalized by the diameter of the target mesh.}
    \label{tab:reg-chamfer}
\end{table}
%The average Chamfer distance~\eqref{eq:classical_Chamfer} normalized over the diameter of the target geometry is $\mathbf{0.00367}$ and $\mathbf{0.00347}$ for the training and test datasets, respectively. The maximum Chamfer distance normalized over the diameter of the target geometry is $\mathbf{0.00605}$ and $\mathbf{0.00470}$ for the training and test datasets, respectively. 

%

\begin{figure}[!htp]
  \centering
  \includegraphics[width=0.95\textwidth, trim={0 0 0 20}, clip]{img/12_reg.pdf}\\
  \includegraphics[width=0.95\textwidth, trim={0 0 0 20}, clip]{img/42_reg.pdf}
  \caption{Registration of test case $n=12$ (top row, best) and $n=42$ (bottom row, worst) velocity and pressure fields onto the template. The displacement fields $\phi(1,X_\mathcal{S};\theta)\text{-}X_\mathcal{S}$ are shown on the third column: the registered geometry $\phi(1,X_\mathcal{S})$ is shaded and compared with original template $X_\mathcal{T}$, under the title \textit{registered template on target}.}
  \label{fig:12_42}
\end{figure}


