[
  {
    "index": 0,
    "papers": [
      {
        "key": "ThoT",
        "author": "Yucheng Zhou and\nXiubo Geng and\nTao Shen and\nChongyang Tao and\nGuodong Long and\nJian{-}Guang Lou and\nJianbing Shen",
        "title": "Thread of Thought Unraveling Chaotic Contexts"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Euphemism",
        "author": "Li, Xiang and Zhou, Yucheng and Zhao, Laiping and Li, Jing and Liu, Fangming",
        "title": "Impromptu Cybercrime Euphemism Detection"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "VideoLLaMA_2",
        "author": "Zesen Cheng and\nSicong Leng and\nHang Zhang and\nYifei Xin and\nXin Li and\nGuanzheng Chen and\nYongxin Zhu and\nWenqi Zhang and\nZiyang Luo and\nDeli Zhao and\nLidong Bing",
        "title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding\nin Video-LLMs"
      },
      {
        "key": "MiniCPM-V",
        "author": "Yuan Yao and\nTianyu Yu and\nAo Zhang and\nChongyi Wang and\nJunbo Cui and\nHongji Zhu and\nTianchi Cai and\nHaoyu Li and\nWeilin Zhao and\nZhihui He and\nQianyu Chen and\nHuarong Zhou and\nZhensheng Zou and\nHaoye Zhang and\nShengding Hu and\nZhi Zheng and\nJie Zhou and\nJie Cai and\nXu Han and\nGuoyang Zeng and\nDahai Li and\nZhiyuan Liu and\nMaosong Sun",
        "title": "MiniCPM-V: {A} {GPT-4V} Level {MLLM} on Your Phone"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "MiniGPT4",
        "author": "Deyao Zhu and\nJun Chen and\nXiaoqian Shen and\nXiang Li and\nMohamed Elhoseiny",
        "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large\nLanguage Models"
      },
      {
        "key": "InternVideo2",
        "author": "Yi Wang and\nKunchang Li and\nXinhao Li and\nJiashuo Yu and\nYinan He and\nGuo Chen and\nBaoqi Pei and\nRongkun Zheng and\nZun Wang and\nYansong Shi and\nTianxiang Jiang and\nSongze Li and\nJilan Xu and\nHongjie Zhang and\nYifei Huang and\nYu Qiao and\nYali Wang and\nLimin Wang",
        "title": "InternVideo2: Scaling Foundation Models for Multimodal Video Understanding"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Qwen2-Audio",
        "author": "Yunfei Chu and\nJin Xu and\nQian Yang and\nHaojie Wei and\nXipin Wei and\nZhifang Guo and\nYichong Leng and\nYuanjun Lv and\nJinzheng He and\nJunyang Lin and\nChang Zhou and\nJingren Zhou",
        "title": "Qwen2-Audio Technical Report"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "MiniCPM-V",
        "author": "Yuan Yao and\nTianyu Yu and\nAo Zhang and\nChongyi Wang and\nJunbo Cui and\nHongji Zhu and\nTianchi Cai and\nHaoyu Li and\nWeilin Zhao and\nZhihui He and\nQianyu Chen and\nHuarong Zhou and\nZhensheng Zou and\nHaoye Zhang and\nShengding Hu and\nZhi Zheng and\nJie Zhou and\nJie Cai and\nXu Han and\nGuoyang Zeng and\nDahai Li and\nZhiyuan Liu and\nMaosong Sun",
        "title": "MiniCPM-V: {A} {GPT-4V} Level {MLLM} on Your Phone"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "LongVA",
        "author": "Peiyuan Zhang and\nKaichen Zhang and\nBo Li and\nGuangtao Zeng and\nJingkang Yang and\nYuanhan Zhang and\nZiyue Wang and\nHaoran Tan and\nChunyuan Li and\nZiwei Liu",
        "title": "Long Context Transfer from Language to Vision"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "GLM-4",
        "author": "Aohan Zeng and\nBin Xu and\nBowen Wang and\nChenhui Zhang and\nDa Yin and\nDiego Rojas and\nGuanyu Feng and\nHanlin Zhao and\nHanyu Lai and\nHao Yu and\nHongning Wang and\nJiadai Sun and\nJiajie Zhang and\nJiale Cheng and\nJiayi Gui and\nJie Tang and\nJing Zhang and\nJuanzi Li and\nLei Zhao and\nLindong Wu and\nLucen Zhong and\nMingdao Liu and\nMinlie Huang and\nPeng Zhang and\nQinkai Zheng and\nRui Lu and\nShuaiqi Duan and\nShudan Zhang and\nShulin Cao and\nShuxun Yang and\nWeng Lam Tam and\nWenyi Zhao and\nXiao Liu and\nXiao Xia and\nXiaohan Zhang and\nXiaotao Gu and\nXin Lv and\nXinghan Liu and\nXinyi Liu and\nXinyue Yang and\nXixuan Song and\nXunkai Zhang and\nYifan An and\nYifan Xu and\nYilin Niu and\nYuantao Yang and\nYueyan Li and\nYushi Bai and\nYuxiao Dong and\nZehan Qi and\nZhaoyu Wang and\nZhen Yang and\nZhengxiao Du and\nZhenyu Hou and\nZihan Wang",
        "title": "ChatGLM: {A} Family of Large Language Models from {GLM-130B} to {GLM-4}\nAll Tools"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "InternVL",
        "author": "Chen, Zhe and Wang, Weiyun and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Cui, Erfei and Zhu, Jinguo and Ye, Shenglong and Tian, Hao and Liu, Zhaoyang and others",
        "title": "Expanding performance boundaries of open-source multimodal models with model, data, and test-time scaling"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "InternVideo2",
        "author": "Yi Wang and\nKunchang Li and\nXinhao Li and\nJiashuo Yu and\nYinan He and\nGuo Chen and\nBaoqi Pei and\nRongkun Zheng and\nZun Wang and\nYansong Shi and\nTianxiang Jiang and\nSongze Li and\nJilan Xu and\nHongjie Zhang and\nYifei Huang and\nYu Qiao and\nYali Wang and\nLimin Wang",
        "title": "InternVideo2: Scaling Foundation Models for Multimodal Video Understanding"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "VideoLLaMA_2",
        "author": "Zesen Cheng and\nSicong Leng and\nHang Zhang and\nYifei Xin and\nXin Li and\nGuanzheng Chen and\nYongxin Zhu and\nWenqi Zhang and\nZiyang Luo and\nDeli Zhao and\nLidong Bing",
        "title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding\nin Video-LLMs"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Gemini1",
        "author": "Rohan Anil and\nSebastian Borgeaud and\nYonghui Wu and\nJean{-}Baptiste Alayrac and\nJiahui Yu and\nRadu Soricut and\nJohan Schalkwyk and\nAndrew M. Dai and\nAnja Hauth and\nKatie Millican and\nDavid Silver and\nSlav Petrov and\nMelvin Johnson and\nIoannis Antonoglou and\nJulian Schrittwieser and\nAmelia Glaese and\nJilin Chen and\nEmily Pitler and\nTimothy P. Lillicrap and\nAngeliki Lazaridou and\nOrhan Firat and\nJames Molloy and\nMichael Isard and\nPaul Ronald Barham and\nTom Hennigan and\nBenjamin Lee and\nFabio Viola and\nMalcolm Reynolds and\nYuanzhong Xu and\nRyan Doherty and\nEli Collins and\nClemens Meyer and\nEliza Rutherford and\nErica Moreira and\nKareem Ayoub and\nMegha Goel and\nGeorge Tucker and\nEnrique Piqueras and\nMaxim Krikun and\nIain Barr and\nNikolay Savinov and\nIvo Danihelka and\nBecca Roelofs and\nAna{\\\"{\\i}}s White and\nAnders Andreassen and\nTamara von Glehn and\nLakshman Yagati and\nMehran Kazemi and\nLucas Gonzalez and\nMisha Khalman and\nJakub Sygnowski and\net al.",
        "title": "Gemini: {A} Family of Highly Capable Multimodal Models"
      },
      {
        "key": "Gemini",
        "author": "Machel Reid and\nNikolay Savinov and\nDenis Teplyashin and\nDmitry Lepikhin and\nTimothy P. Lillicrap and\nJean{-}Baptiste Alayrac and\nRadu Soricut and\nAngeliki Lazaridou and\nOrhan Firat and\nJulian Schrittwieser and\nIoannis Antonoglou and\nRohan Anil and\nSebastian Borgeaud and\nAndrew M. Dai and\nKatie Millican and\nEthan Dyer and\nMia Glaese and\nThibault Sottiaux and\nBenjamin Lee and\nFabio Viola and\nMalcolm Reynolds and\nYuanzhong Xu and\nJames Molloy and\nJilin Chen and\nMichael Isard and\nPaul Barham and\nTom Hennigan and\nRoss McIlroy and\nMelvin Johnson and\nJohan Schalkwyk and\nEli Collins and\nEliza Rutherford and\nErica Moreira and\nKareem Ayoub and\nMegha Goel and\nClemens Meyer and\nGregory Thornton and\nZhen Yang and\nHenryk Michalewski and\nZaheer Abbas and\nNathan Schucher and\nAnkesh Anand and\nRichard Ives and\nJames Keeling and\nKarel Lenc and\nSalem Haykal and\nSiamak Shakeri and\nPranav Shyam and\nAakanksha Chowdhery and\nRoman Ring and\nStephen Spencer and\nEren Sezener and\net al.",
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of\ntokens of context"
      },
      {
        "key": "Gemini2",
        "author": "Team, LearnLM and Modi, Abhinit and Veerubhotla, Aditya Srikanth and Rysbek, Aliya and Huber, Andrea and Wiltshire, Brett and Veprek, Brian and Gillick, Daniel and Kasenberg, Daniel and Ahmed, Derek and others",
        "title": "LearnLM: Improving Gemini for Learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "VisualDependency",
        "author": "Yucheng Zhou and\nZhi Rao and\nJun Wan and\nJianbing Shen",
        "title": "Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language\nModels"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "VICL",
        "author": "Yucheng Zhou and\nXiang Li and\nQianning Wang and\nJianbing Shen",
        "title": "Visual In-Context Learning for Large Vision-Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "MERBench",
        "author": "Zheng Lian and\nLicai Sun and\nYong Ren and\nHao Gu and\nHaiyang Sun and\nLan Chen and\nBin Liu and\nJianhua Tao",
        "title": "MERBench: {A} Unified Evaluation Benchmark for Multimodal Emotion\nRecognition"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "mer2023",
        "author": "Zheng Lian and\nHaiyang Sun and\nLicai Sun and\nKang Chen and\nMingyu Xu and\nKexin Wang and\nKe Xu and\nYu He and\nYing Li and\nJinming Zhao and\nYe Liu and\nBin Liu and\nJiangyan Yi and\nMeng Wang and\nErik Cambria and\nGuoying Zhao and\nBj{\\\"{o}}rn W. Schuller and\nJianhua Tao",
        "title": "{MER} 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised\nLearning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "MC-EIU",
        "author": "Rui Liu and\nHaolin Zuo and\nZheng Lian and\nXiaofen Xing and\nBj{\\\"{o}}rn W. Schuller and\nHaizhou Li",
        "title": "Emotion and Intent Joint Understanding in Multimodal Conversation:\n{A} Benchmarking Dataset"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "MOSABench",
        "author": "Shezheng Song and\nChengxiang He and\nShasha Li and\nShan Zhao and\nChengyu Wang and\nTianwei Yan and\nXiaopeng Li and\nQian Wan and\nJun Ma and\nJie Yu and\nXiaoguang Mao",
        "title": "MOSABench: Multi-Object Sentiment Analysis Benchmark for Evaluating\nMultimodal Large Language Models Understanding of Complex Image"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "GPT-4V",
        "author": "Zheng Lian and\nLicai Sun and\nHaiyang Sun and\nKang Chen and\nZhuofan Wen and\nHao Gu and\nShun Chen and\nBin Liu and\nJianhua Tao",
        "title": "{GPT-4V} with Emotion: {A} Zero-shot Benchmark for Multimodal Emotion\nUnderstanding"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "EmotionBench",
        "author": "Jen{-}tse Huang and\nMan Ho Lam and\nEric John Li and\nShujie Ren and\nWenxuan Wang and\nWenxiang Jiao and\nZhaopeng Tu and\nMichael R. Lyu",
        "title": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "Both_Matter",
        "author": "Weixiang Zhao and\nZhuojun Li and\nShilong Wang and\nYang Wang and\nYulin Hu and\nYanyan Zhao and\nChen Wei and\nBing Qin",
        "title": "Both Matter: Enhancing the Emotional Intelligence of Large Language\nModels without Compromising the General Intelligence"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "EmoBench",
        "author": "Sahand Sabour and\nSiyang Liu and\nZheyuan Zhang and\nJune M. Liu and\nJinfeng Zhou and\nAlvionna S. Sunaryo and\nTatia M. C. Lee and\nRada Mihalcea and\nMinlie Huang",
        "title": "EmoBench: Evaluating the Emotional Intelligence of Large Language\nModels"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "EQ-Bench",
        "author": "Samuel J. Paech",
        "title": "EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "SOUL",
        "author": "Yue Deng and\nWenxuan Zhang and\nSinno Jialin Pan and\nLidong Bing",
        "title": "{SOUL:} Towards Sentiment and Opinion Understanding of Language"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "MME",
        "author": "Chaoyou Fu and\nPeixian Chen and\nYunhang Shen and\nYulei Qin and\nMengdan Zhang and\nXu Lin and\nZhenyu Qiu and\nWei Lin and\nJinrui Yang and\nXiawu Zheng and\nKe Li and\nXing Sun and\nRongrong Ji",
        "title": "{MME:} {A} Comprehensive Evaluation Benchmark for Multimodal Large\nLanguage Models"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "MMT-Bench",
        "author": "Kaining Ying and\nFanqing Meng and\nJin Wang and\nZhiqian Li and\nHan Lin and\nYue Yang and\nHao Zhang and\nWenbo Zhang and\nYuqi Lin and\nShuo Liu and\nJiayi Lei and\nQuanfeng Lu and\nRunjian Chen and\nPeng Xu and\nRenrui Zhang and\nHaozhe Zhang and\nPeng Gao and\nYali Wang and\nYu Qiao and\nPing Luo and\nKaipeng Zhang and\nWenqi Shao",
        "title": "MMT-Bench: {A} Comprehensive Multimodal Benchmark for Evaluating Large\nVision-Language Models Towards Multitask {AGI}"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "MultiTrust",
        "author": "Zhang, Yichi and Huang, Yao and Sun, Yitong and Liu, Chang and Zhao, Zhe and Fang, Zhengwei and Wang, Yifan and Chen, Huanran and Yang, Xiao and Wei, Xingxing and others",
        "title": "MultiTrust: A Comprehensive Benchmark Towards Trustworthy Multimodal Large Language Models"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "humanvbench",
        "author": "Zhou, Ting and Chen, Daoyuan and Jiao, Qirui and Ding, Bolin and Li, Yaliang and Shen, Ying",
        "title": "HumanVBench: Exploring Human-Centric Video Understanding Capabilities of MLLMs with Synthetic Benchmark Data"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "MVBench",
        "author": "Kunchang Li and\nYali Wang and\nYinan He and\nYizhuo Li and\nYi Wang and\nYi Liu and\nZun Wang and\nJilan Xu and\nGuo Chen and\nPing Lou and\nLimin Wang and\nYu Qiao",
        "title": "MVBench: {A} Comprehensive Multi-modal Video Understanding Benchmark"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "MathScape",
        "author": "Minxuan Zhou and\nHao Liang and\nTianpeng Li and\nZhiyu Wu and\nMingan Lin and\nLinzhuang Sun and\nYaqi Zhou and\nYan Zhang and\nXiaoqin Huang and\nYicong Chen and\nYujing Qiao and\nWeipeng Chen and\nBin Cui and\nWentao Zhang and\nZenan Zhou",
        "title": "MathScape: Evaluating MLLMs in multimodal Math Scenarios through a\nHierarchical Benchmark"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "M3SciQA",
        "author": "Chuhan Li and\nZiyao Shangguan and\nYilun Zhao and\nDeyuan Li and\nYixin Liu and\nArman Cohan",
        "title": "M3SciQA: {A} Multi-Modal Multi-Document Scientific {QA} Benchmark\nfor Evaluating Foundation Models"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "BenchLMM",
        "author": "Rizhao Cai and\nZirui Song and\nDayan Guan and\nZhenhao Chen and\nYaohang Li and\nXing Luo and\nChenyu Yi and\nAlex C. Kot",
        "title": "BenchLMM: Benchmarking Cross-Style Visual Capability of Large Multimodal\nModels"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "BLINK",
        "author": "Xingyu Fu and\nYushi Hu and\nBangzheng Li and\nYu Feng and\nHaoyu Wang and\nXudong Lin and\nDan Roth and\nNoah A. Smith and\nWei{-}Chiu Ma and\nRanjay Krishna",
        "title": "{BLINK:} Multimodal Large Language Models Can See but Not Perceive"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "MedLVLM",
        "author": "Zhou, Yucheng and Song, Lingran and Shen, Jianbing",
        "title": "Training Medical Large Vision-Language Models with Abnormal-Aware Feedback"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "SEED-Bench-2-Plus",
        "author": "Bohao Li and\nYuying Ge and\nYi Chen and\nYixiao Ge and\nRuimao Zhang and\nYing Shan",
        "title": "SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with\nText-Rich Visual Comprehension"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "ryerson",
        "author": "Livingstone, Steven R and Russo, Frank A",
        "title": "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "ryerson",
        "author": "Livingstone, Steven R and Russo, Frank A",
        "title": "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "MOSI",
        "author": "Amir Zadeh and\nRowan Zellers and\nEli Pincus and\nLouis{-}Philippe Morency",
        "title": "{MOSI:} Multimodal Corpus of Sentiment Intensity and Subjectivity\nAnalysis in Online Opinion Videos"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "CMU-MOSEI",
        "author": "Amir Zadeh and\nPaul Pu Liang and\nSoujanya Poria and\nErik Cambria and\nLouis{-}Philippe Morency",
        "title": "Multimodal Language Analysis in the Wild: {CMU-MOSEI} Dataset and\nInterpretable Dynamic Fusion Graph"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "FMSA-SC",
        "author": "Lingyun Song and\nSiyu Chen and\nZiyang Meng and\nMingxuan Sun and\nXuequn Shang",
        "title": "{FMSA-SC:} {A} Fine-Grained Multimodal Sentiment Analysis Dataset\nBased on Stock Comment Videos"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "mer2023",
        "author": "Zheng Lian and\nHaiyang Sun and\nLicai Sun and\nKang Chen and\nMingyu Xu and\nKexin Wang and\nKe Xu and\nYu He and\nYing Li and\nJinming Zhao and\nYe Liu and\nBin Liu and\nJiangyan Yi and\nMeng Wang and\nErik Cambria and\nGuoying Zhao and\nBj{\\\"{o}}rn W. Schuller and\nJianhua Tao",
        "title": "{MER} 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised\nLearning"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "CH-SIMSv2",
        "author": "Yihe Liu and\nZiqi Yuan and\nHuisheng Mao and\nZhiyun Liang and\nWanqiuyue Yang and\nYuanzhe Qiu and\nTie Cheng and\nXiaoteng Li and\nHua Xu and\nKai Gao",
        "title": "Make Acoustic and Visual Cues Matter: {CH-SIMS} v2.0 Dataset and AV-Mixup\nConsistent Module"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "CH-SIMS",
        "author": "Wenmeng Yu and\nHua Xu and\nFanyang Meng and\nYilin Zhu and\nYixiao Ma and\nJiele Wu and\nJiyun Zou and\nKaicheng Yang",
        "title": "{CH-SIMS:} {A} Chinese Multimodal Sentiment Analysis Dataset with\nFine-grained Annotation of Modality"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "MC-EIU",
        "author": "Rui Liu and\nHaolin Zuo and\nZheng Lian and\nXiaofen Xing and\nBj{\\\"{o}}rn W. Schuller and\nHaizhou Li",
        "title": "Emotion and Intent Joint Understanding in Multimodal Conversation:\n{A} Benchmarking Dataset"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "MELD",
        "author": "Soujanya Poria and\nDevamanyu Hazarika and\nNavonil Majumder and\nGautam Naik and\nErik Cambria and\nRada Mihalcea",
        "title": "{MELD:} {A} Multimodal Multi-Party Dataset for Emotion Recognition\nin Conversations"
      }
    ]
  },
  {
    "index": 45,
    "papers": [
      {
        "key": "UR-FUNNY",
        "author": "Md. Kamrul Hasan and\nWasifur Rahman and\nAmirAli Bagher Zadeh and\nJianyuan Zhong and\nMd. Iftekhar Tanveer and\nLouis{-}Philippe Morency and\nMohammed (Ehsan) Hoque",
        "title": "{UR-FUNNY:} {A} Multimodal Language Dataset for Understanding Humor"
      }
    ]
  },
  {
    "index": 46,
    "papers": [
      {
        "key": "MUStARD",
        "author": "Santiago Castro and\nDevamanyu Hazarika and\nVer{\\'{o}}nica P{\\'{e}}rez{-}Rosas and\nRoger Zimmermann and\nRada Mihalcea and\nSoujanya Poria",
        "title": "Towards Multimodal Sarcasm Detection (An {\\_}Obviously{\\_} Perfect\nPaper)"
      }
    ]
  },
  {
    "index": 47,
    "papers": [
      {
        "key": "SMILE",
        "author": "Lee Hyun and\nKim Sung{-}Bin and\nSeungju Han and\nYoungjae Yu and\nTae{-}Hyun Oh",
        "title": "{SMILE:} Multimodal Dataset for Understanding Laughter in Video with\nLanguage Models"
      }
    ]
  },
  {
    "index": 48,
    "papers": [
      {
        "key": "MELD",
        "author": "Soujanya Poria and\nDevamanyu Hazarika and\nNavonil Majumder and\nGautam Naik and\nErik Cambria and\nRada Mihalcea",
        "title": "{MELD:} {A} Multimodal Multi-Party Dataset for Emotion Recognition\nin Conversations"
      }
    ]
  },
  {
    "index": 49,
    "papers": [
      {
        "key": "yang2024qwen2",
        "author": "Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others",
        "title": "Qwen2. 5 Technical Report"
      }
    ]
  }
]