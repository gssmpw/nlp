\begin{abstract}
With the integration of Multimodal large language models (MLLMs) into robotic systems and various AI applications, embedding emotional intelligence (EI) capabilities into these models is essential for enabling robots to effectively address human emotional needs and interact seamlessly in real-world scenarios. 
Existing static, text-based, or text-image benchmarks overlook the multimodal complexities of real-world interactions and fail to capture the dynamic, multimodal nature of emotional expressions, making them inadequate for evaluating MLLMs' EI.
Based on established psychological theories of EI, we build EmoBench-M, a novel benchmark designed to evaluate the EI capability of MLLMs across 13 valuation scenarios from three key dimensions: foundational emotion recognition, conversational emotion understanding, and socially complex emotion analysis. 
Evaluations of both open-source and closed-source MLLMs on EmoBench-M reveal a significant performance gap between them and humans, highlighting the need to further advance their EI capabilities. 
All benchmark resources, including code and datasets, are publicly available at \url{https://emo-gml.github.io/}.
\end{abstract}

\section{Introduction}

\begin{table*}[!t]\small
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{3.5pt}
\begin{tabular}{lcccccc}
\toprule
\textbf{Benchmark} & \textbf{Psych-based?} & \textbf{Task} & \textbf{Multimodality} & \textbf{Answer Type} & \textbf{Evaluator} \\
\midrule
Text Annotation \cite{Text_Annotation}  & \ding{51}  & 1  & Text                  & Multi-choice  & Metric  \\
EmotionBench \cite{Emotionally}    & \ding{51}  & 1  & Text                  & Multi-choice  & Metric  \\
SOUL \cite{SOUL}            & \ding{55}  & 2  & Text                  & Multi-choice \& GEN. & Metric \& LLM  \\
EmoBench \cite{EmoBench}        & \ding{51}  & 8  & Text                  & Multi-choice  & Metric  \\
ChatGPT2AC \cite{ChatGPT2ERG}      & \ding{55}  & 11 & Text                  & Multi-choice  & Metric  \\\midrule
MOSABench \cite{MOSABench}      & \ding{55}  & 1  & Text \& Image          & Multi-choice  & Metric  \\
SarcasmBench \cite{SarcasmBench}    & \ding{55}  & 1  & Text \& Image          & Multi-choice  & Metric  \\
MM-InstructEval \cite{MM-InstructEval} & \ding{55}  & 6  & Text \& Image          & Multi-choice  & Metric  \\\midrule
OV-MER \cite{Open-vocabulary}         & \ding{55}  & 1  & Video \& Audio \& Text & Multi-choice  & Metric  \\
MC-EIU \cite{MC-EIU}          & \ding{55}  & 1  & Video \& Audio \& Text & Multi-choice  & Metric  \\
EmoBench-M (Ours)      & \ding{51}  & 13 & Video \& Audio \& Text & Multi-choice \& GEN. & Metric \& LLM  \\
\bottomrule
\end{tabular}}
\vspace{-1mm}
\caption{\small Comparison of benchmarks related to emotion intelligence. ``Psych-based?'' refers to whether the benchmark is grounded in psychological theories. ``GEN.'' stands for Generation task.}
\label{tab:intro}
\vspace{-1mm}
\end{table*}

Emotional Intelligence (EI), initially conceptualized by \citet{EmotionalIntelligence}, emphasizes the ability to perceive, understand, regulate, and apply emotions in oneself and others. 
Recent advancements in multimodal large language models (MLLMs) have significantly improved human-computer interaction and natural language understanding, and integrating MLLMs into robotic control systems has become increasingly prevalent \cite{RobotSurvey}. 
Incorporating EI capabilities within MLLMs is essential for improving robotic performance in real-world environments. It will enable robots to address human emotional needs better and ensure more effective interactions.

However, there is currently no universal benchmark to comprehensively evaluate the EI capabilities of MLLMs. Table~\ref{tab:intro} lists existing benchmarks for evaluating EI, demonstrating that most are designed for text-only or text-image EI tasks \citep{EmoBench,MEMOBench}, and most are not grounded in established psychological theories.
Real-world MLLM-driven human-robot interactions typically occur in dynamic, multimodal environments. 
Unlike static text and images, videos with audio provide richer and more complex multimodal information, including dynamic facial expressions, body language, and vocal tone, which more authentically convey the flow of emotions and the interactive process. 
Evaluating MLLMs in multimodal environments is crucial because it allows for a more comprehensive understanding of their ability to interpret and respond to diverse emotional cues in real-world scenarios. 

Building on established psychological theories of EI \cite{EmotionalIntelligence,EmotionalIntelligence1,EmotionalIntelligence2}, we explore the EI capabilities of MLLMs across three primary dimensions: 
(1) {\bf Foundational Emotion Recognition}: This dimension focuses on accurately identifying emotional states through explicit signals such as facial expressions, vocal tone, and body language \cite{ekman1992there,scherer2005emotions}. It also emphasizes the extraction of emotional information from multimodal signals \cite{poria2019emotion}.  
(2) {\bf Conversational Emotion Understanding}: Extending beyond foundational recognition, this dimension requires the ability to track emotional dynamics within conversations and to comprehend the contextual and situational meanings of emotions \cite{gross2002emotion,poria2019emotion,hazarika2018conversational}.  
(3) {\bf Socially Complex Emotion Understanding}: Representing an advanced level of EI, this dimension involves understanding emotions influenced not only by internal affective states but also by external social and cultural contexts. It requires AI systems to exhibit mentalizing capabilities, the ability to infer others' emotions and intentions based on environmental cues \cite{frith2006neural}.  
Building on these three dimensions, we propose a novel multimodal EI benchmark, $\ours$, for MLLMs. 
As shown in Figure~\ref{fig:intro}, our benchmark includes 13 scenarios covering diverse contexts such as music and presentation, multi-party dialogues, and social conversation. 
By utilizing multimodal data, i.e., video with audio, $\ours$ enables a more comprehensive evaluation of the EI of MLLMs. 
Moreover, controversial samples were excluded after a thorough human review to ensure the quality of the benchmark. 

To the best of our knowledge, $\ours$ is the first comprehensive benchmark to evaluate EI at the multimodality level. 
We evaluate various open-source MLLMs (e.g., Video-LLaMA2 \cite{VideoLLaMA_2} and InternVL2.5 \cite{InternVL}) and closed-source MLLMs (e.g., GLM-4V \cite{GLM-4} and Gemini \cite{Gemini}) on $\ours$. 
Our findings indicate that the EI capability of MLLMs in multimodal and realistic environments remains substantially below human performance in many scenarios. 
Moreover, we conduct an extensive evaluation of MLLMs across varying model sizes and reasoning levels. 
We will publicly release our code and data to encourage further research in the EI of MLLM.


\section{Related Work}\label{app:related}
\subsection{Multimodal Large Language Models}
With the success of LLMs in various natural language processing (NLP) tasks, such as reasoning \cite{ThoT} and euphemism detection \cite{Euphemism}, numerous efforts have been made to extend LLMs to multimodal areas, i.e., MLLMs, enabling them to process additional types of information, including images, videos, and audio \cite{VideoLLaMA_2,MiniCPM-V}. MLLMs excel in multimodal perception and reasoning and handle more diverse tasks with inputs from different multimodality \cite{MiniGPT4,InternVideo2}. 
For instance, Qwen2-Audio \cite{Qwen2-Audio} specializes in integrating audio and text, demonstrating strong performance in auditory perception tasks. 
The MiniCPM-V \cite{MiniCPM-V}, LongVA \cite{LongVA}, GLM \cite{GLM-4}, InternVL \cite{InternVL}, and InternVideo2 \cite{InternVideo2} have made significant strides in vision understanding and multimodal dialogue generation.
Video-LLaMA2 \cite{VideoLLaMA_2} not only focuses on vision understanding but also enhances audio-video understanding capabilities. Additionally, the Gemini \cite{Gemini1, Gemini, Gemini2}, an LLM natively supporting multimodal capabilities, can seamlessly understand, manipulate, and integrate information from different modalities. 
Moreover, some works further improve vision reasoning ability in MLLMs by visual dependency \cite{VisualDependency}, in-context learning \cite{VICL}.


\subsection{Evaluation of Emotional Intelligence}
Given that EI is essential for understanding and responding to human emotions, many studies have focused on evaluating the EI capabilities of LLMs. MERBench \cite{MERBench} standardizes evaluation for multimodal emotion recognition by addressing inconsistencies in feature extractors and offering a unified framework. It introduces MER2023 \cite{mer2023}, a dataset focused on the Chinese language, emphasizing multi-label learning and robustness analysis.
Moreover, MC-EIU \cite{MC-EIU} offers a joint evaluation of emotion and intent in multimodal conversations.
MOSABench \cite{MOSABench} introduces a novel method for multi-object sentiment analysis, emphasizing the challenges MLLMs face in handling spatial complexities.
\citet{GPT-4V} evaluates GPT-4's visual capabilities in emotion recognition tasks but reveals limitations in recognizing micro-expressions and leveraging temporal data effectively. EmotionBench \cite{EmotionBench} employs emotional appraisal theory to evaluate LLMs, exposing misalignments between LLM responses and human emotional behaviors. To deep dive into EI of LLM,  EIBench \cite{Both_Matter} and EmoBench \cite{EmoBench} are based on established psychological theories to evaluate LLM with various EI tasks, and they expose significant gaps between current LLMs and human-like emotional intelligence. In addition, EQ-Bench \cite{EQ-Bench} and SOUL \cite{SOUL} focus on nuanced EI aspects, including emotion intensity prediction and justification generation, revealing performance disparities between small and large models. 



\subsection{Multimodal Benchmarks for LLMs}
The rapid development of Multimodal Large Language Models (MLLMs) has necessitated the creation of diverse benchmarks to systematically evaluate their capabilities across perception, reasoning, and application domains. MME \cite{MME} and MMT-Bench \cite{MMT-Bench} serve as comprehensive benchmarks for foundational multimodal tasks and general-purpose intelligence across varied domains. MultiTrust \cite{MultiTrust} evaluates trustworthiness, focusing on truthfulness, safety, robustness, fairness, and privacy risks. Moreover, HumanVBench \cite{humanvbench} and MVBench \cite{MVBench} center on human-centric and temporal understanding in video content, exposing gaps in MLLMs' abilities to align cross-modal and temporal dynamics effectively. Specialized benchmarks have emerged to tackle domain-specific challenges. For instance, MathScape \cite{MathScape} targets multimodal mathematical reasoning, while M3SciQA \cite{M3SciQA} focuses on scientific question answering. BenchLMM \cite{BenchLMM} evaluates models under diverse style shifts, and BLINK \cite{BLINK} targets core visual perception tasks that remain challenging for multimodal models. \citet{MedLVLM} evaluate the medical diagnostic capabilities and generalization abilities of LVLMs. Furthermore, SEED-Bench-2-Plus \cite{SEED-Bench-2-Plus} assesses MLLMs' abilities in text-rich visual scenarios, such as interpreting charts and maps. 






\begin{table*}[!t]\small
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccc}
\toprule
\textbf{Evaluation Scenario} & \textbf{Data Source} & \textbf{Task} & \textbf{num} & \textbf{Metric} \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{5}{c}{\textbf{Foundational Emotion Recognition}} \\\midrule
Song Emotion Recognition & RAVDESS(song) \cite{ryerson} & 6-CLS & 500 & ACC, WAF \\
Speech Emotion Recognition & RAVDESS(speech) \cite{ryerson} & 8-CLS & 500 & ACC, WAF \\
Opinion Sentiment Analysis & CMU-MOSI \cite{MOSI} & 3-CLS & 500 & ACC, WAF \\
Emotion Intensity Analysis & CMU-MOSEI \cite{CMU-MOSEI} & 3-CLS & 500 & ACC, WAF \\
Stock Comment Emotion Analysis & FMSA-SC \cite{FMSA-SC} & 5-CLS & 250 & ACC, WAF \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{5}{c}{\textbf{Conversational Emotion Understanding}} \\\midrule
Fine-Grained Dialog Emotion Analysis & MER2023 \cite{mer2023} & 6-CLS & 411 & ACC, WAF \\
Presentation Emotion Analysis & CH-SIMSv2 \cite{CH-SIMSv2} & 3-CLS & 500 & ACC, WAF \\
Face-Centric Dialog Emotion Analysis & CH-SIMS \cite{CH-SIMS} & 3-CLS & 457 & ACC, WAF \\
Conversational Emotion \& Intent Analysis & MC-EIU \cite{MC-EIU} & 7-\&8-CLS & 500 & ACC, WAF \\
Multi-Party Dialog Emotion Recognition & MELD \cite{MELD} & 7-CLS & 500 & ACC, WAF \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{5}{c}{\textbf{Socially Complex Emotion Analysis}} \\\midrule
Humor Understanding & UR-FUNNY \cite{UR-FUNNY} & 2-CLS & 448 & ACC, WAF \\
Sarcasm Detection & MUStARD \cite{MUStARD} & 2-CLS & 500 & ACC, WAF \\
Laughter Reasoning & SMILE \cite{SMILE} & GEN & 80 & LLM \\
\bottomrule
\end{tabular}}
\vspace{-2mm}
\caption{\small Emotion Recognition Tasks and Metrics. ``n-CLS'' denotes an n-class classification task, and ``GEN'' represents a generation task. ``num'' indicates the number of samples. ``ACC'' and ``WAF'' denote accuracy and Weighted Average F-score \cite{MELD}, respectively. For the ``Laughter Reasoning'', we employ a LLM as the evaluator, and evaluation prompts are shown in Appendix~\ref{app:evalprompt}. To ensure fair and consistent comparisons in future research, we adopted the open-source Qwen2.5-72B-Instruct \cite{yang2024qwen2}. Details of the specific categories in the classification tasks are provided in the Appendix~\ref{app:dataset}. Details of prompt are in Appendix~\ref{app:prompt}.} 
\label{tab:emotion_tasks}
\vspace{-2mm}
\end{table*}

% \section{Related Work}
% Multimodal Large Language Models (MLLMs) has rapidly expanded, building upon the success of LLMs. MLLMs integrate various modalities, including images, videos, and audio \cite{VideoLLaMA_2,MiniCPM-V}, excelling in perception, reasoning, and diverse tasks \cite{MiniGPT4,InternVideo2}. Models like Qwen2-Audio \cite{Qwen2-Audio}, MiniCPM-V \cite{MiniCPM-V}, LongVA \cite{LongVA}, GLM \cite{GLM-4}, InternVL \cite{InternVL}, InternVideo2 \cite{InternVideo2}, and Video-LLaMA2 \cite{VideoLLaMA_2} demonstrate advancements in vision and audio-video understanding. Gemini \cite{Gemini1, Gemini, Gemini2} natively supports multimodality. Further improvements are explored through visual dependency \cite{VisualDependency} and in-context learning \cite{VICL}. Evaluating Emotional Intelligence (EI) is crucial, with benchmarks like MERBench \cite{MERBench}, MER2023 \cite{mer2023}, MC-EIU \cite{MC-EIU}, MOSABench \cite{MOSABench}, and studies on GPT-4V \cite{GPT-4V} focusing on multimodal emotion recognition and sentiment analysis. EmotionBench \cite{EmotionBench}, EIBench \cite{Both_Matter}, EmoBench \cite{EmoBench}, EQ-Bench \cite{EQ-Bench}, and SOUL \cite{SOUL} delve into deeper EI aspects, revealing gaps between LLMs and human-like emotional understanding. Moreover, numerous multimodal benchmarks assess MLLMs, including MME \cite{MME}, MMT-Bench \cite{MMT-Bench} for general capabilities, MultiTrust \cite{MultiTrust} for trustworthiness, and HumanVBench \cite{humanvbench}, MVBench \cite{MVBench} for video understanding. The full version can be found in Appendix~\ref{app:related}.







\section{EmoBench-M}
\subsection{Evaluation Taxonomy}
To systematically evaluate MLLM EI capabilities, the evaluation focuses on three dimensions based on established psychological theories of EI \cite{EmotionalIntelligence,EmotionalIntelligence1,EmotionalIntelligence2}: ``Foundational Emotion Recognition'', ``Conversational Emotion Understanding'', and ``Socially Complex Emotion Analysis''.  Table~\ref{tab:emotion_tasks} details the evaluation scenarios within each dimension.


\subsubsection{Foundational Emotion Recognition}
Foundational emotion recognition, a core aspect of Emotional Intelligence (EI), focuses on identifying basic emotions such as anger, happiness, and sadness \cite{ekman1992there,scherer2005emotions}. This dimension evaluates a Multimodal Large Language Model's (MLLMs') ability to extract and integrate emotional information from multimodal signals (video, audio, and text) to recognize these fundamental emotions, a crucial capability for higher-level EI.  The MLLMs' proficiency in discerning emotions conveyed through speech, music, and video is assessed.
Song and Speech Emotion Recognition uses data sourced from \cite{ryerson}, which provides video clips with audio-visual emotional cues. Opinion Sentiment Analysis utilizes data sourced from \cite{MOSI}, focusing on speech and facial expressions in opinion videos.  Emotion Intensity Analysis goes beyond simple polarity; data sourced from the CMU-MOSEI dataset \cite{CMU-MOSEI} is used to assess both the emotional state and its intensity from audio and video. This requires the model to identify specific emotion categories (e.g., happiness, sadness, anger) and quantify their intensity levels across diverse video content. Stock Comment Emotion Analysis employs data sourced from \cite{FMSA-SC}, analyzing emotions expressed in stock-related video comments.


\subsubsection{Conversational Emotion Understanding}
Conversational emotion understanding requires MLLMs to track emotional dynamics and interpret their contextual significance \cite{poria2019emotion,hazarika2018conversational}.  This involves identifying emotional shifts in multi-party conversations, leveraging semantic and tonal cues, and adapting to dynamic contexts, including inter-participant emotional interplay.  Several scenarios in this dimension:
Fine-grained Dialog Emotion Analysis (data source from \cite{mer2023}) captures subtle emotional shifts.  Face-centric Dialog Emotion Analysis (data source from CH-SIMS \cite{CH-SIMS}) focuses on facial expressions and verbal/visual cues in interactive, conversational settings.  Presentation Emotion Analysis (data source from CH-SIMSv2 \cite{CH-SIMSv2}) examines emotions in formal presentations. Crucially, CH-SIMSv2 extends CH-SIMS by encompassing broader presentation styles, multi-speaker scenarios, and more diverse non-verbal cues.  Conversational Emotion and Intent Analysis (data source from \cite{MC-EIU}) detects emotions and infers intentions. Multi-party Dialog Emotion Recognition (data source from \cite{MELD}) analyzes multi-party conversations, classifying seven emotions based on speech and facial cues.

\subsubsection{Socially Complex Emotion Analysis}
Emotional expression is influenced by internal drives and external social/cultural contexts \cite{frith2006neural}. Socially complex emotion understanding is an advanced EI dimension, encompassing the ability to identify, comprehend, and respond to nuanced emotions and social intentions in intricate social scenarios. This dimension primarily evaluates emotions arising in complex social contexts, requiring deeper inference of emotions like humor, sarcasm, and latent feelings based on social interactions and norms. Humor Understanding utilizes data sourced from~\cite{UR-FUNNY}. Sarcasm Detection uses data sourced from \cite{MUStARD}. Laughter Reasoning employs data sourced from \cite{SMILE} to analyze the complex emotions in various social situations.

\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{figs/filter.pdf}
    \vspace{-6mm}
    \caption{\small Data Filtering and Label Verification Process. Bar charts show the original dataset label (red) and the label from our reviewers (blue).}
    \label{fig:filter}
    \vspace{-2mm}
\end{figure}

\subsection{Data Collection and Processing}
The $\ours$ benchmark was meticulously curated to evaluate the EI capabilities of MLLMs across a diverse range of tasks. As shown in Figure~\ref{fig:filter}, the data collection and processing pipeline involved rigorous filtering and class balancing to ensure high quality and fairness.

\paragraph{Filtering and Quality Assurance.} After compiling datasets for each emotion recognition task, the data underwent a multi-stage filtering process. In this process, we remove ambiguous, mislabeled, or controversial samples. Three graduate students manually reviewed video samples and their corresponding labels to identify and remove problematic instances. Reviewers independently assessed the emotion displayed in each video clip.  These assessments were then compared against the original dataset labels.  A voting system was implemented: each reviewer cast a vote for what they believed to be the correct emotion. If the original dataset label received a minority of the votes (i.e., fewer votes than the consensus of the human reviewers), the sample was considered potentially mislabeled and was subsequently removed from the dataset. This ensures that only samples where the original label aligns with the majority opinion of human reviewers are included.

This collaborative review process, which integrates label verification with a robust voting mechanism, ensures that only high-quality, unambiguous data are included in the final dataset. This rigorous approach minimizes the risk of incorporating inaccurate or misleading data, thereby enhancing the benchmark's reliability and validity.

\paragraph{Class Imbalance Correction.} To ensure a fair and unbiased evaluation, we addressed potential class imbalances within the dataset. Some classes, particularly in tasks with numerous emotional categories, were underrepresented. To mitigate this, we employed oversampling of the minority classes, creating a more balanced distribution. This prevents the benchmark from being biased towards specific emotional classes and promotes better generalization across the full spectrum of emotions.

\paragraph{Dataset Statistics.} $\ours$ encompasses tasks with varying sample sizes, ranging from 80 to 500 samples per task, as detailed in Table~\ref{tab:emotion_tasks}. Each task is designed to evaluate different facets of emotional intelligence, spanning from basic emotion recognition to understanding more complex social emotions. Performance metrics such as accuracy (ACC), Weighted Average F-score (WAF), and, for generation tasks, LLM-based evaluation are employed.


\section{Experiments}
\begin{table*}[!t]\small
\centering
\setlength{\tabcolsep}{5.1pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c}{\textbf{SOER}} & \multicolumn{2}{c}{\textbf{SPER}} & \multicolumn{2}{c}{\textbf{OSA}} & \multicolumn{2}{c}{\textbf{EIA}} & \multicolumn{2}{c}{\textbf{SCEA}} & \multicolumn{2}{c}{\textbf{Avg.}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
 & ACC & WAF & ACC & WAF & ACC & WAF & ACC & WAF & ACC & WAF & ACC & WAF \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{13}{c}{\textit{Open-Source Model}} \\\midrule
InternVL2.5-4B & 50.5 & 47.6 & 41.2 & 35.5 & 71.8 & 75.5 & 60.1 & 60.6 & 48.8 & 46.2 & 54.5 & 53.1 \\
Video-LLaMA2-7B & 52.4 & 47.7 & 42.4 & 35.0 & 31.0 & 39.8 & 50.2 & 46.8 & 50.8 & 38.6 & 45.4 & 41.6 \\
Video-LLaMA2-7B-16F & 45.0 & 41.6 & 46.0 & 41.2 & 64.0 & 68.2 & 56.5 & 54.9 & 45.5 & 39.1 & 51.4 & 49.0 \\
Qwen2-Audio-7B-Instruct & 65.8 & 59.8 & 71.7 & 65.1 & 66.2 & 72.9 & 59.6 & 58.9 & 36.4 & 36.1 & 59.9 & 58.6 \\
Video-LLaMA2.1-7B-16F & 41.2 & 35.2 & 31.4 & 24.7 & 75.4 & 77.7 & 61.6 & 60.9 & 44.8 & 43.2 & 50.9 & 48.3 \\
Video-LLaMA2.1-7B-AV & 50.4 & 42.2 & 37.7 & 30.5 & 73.0 & 76.4 & 57.6 & 58.2 & 33.2 & 33.6 & 50.4 & 48.2 \\
LongVA-DPO-7B & 50.2 & 45.4 & 44.2 & 40.3 & 33.8 & 42.4 & 45.7 & 39.4 & 54.8 & 46.7 & 45.7 & 42.8 \\
InternVideo2-Chat-8B & 55.2 & 50.5 & 44.0 & 35.1 & 45.4 & 55.1 & 56.0 & 55.3 & 52.4 & 42.0 & 50.6 & 47.6 \\
MiniCPM-V-2.6-8B & 26.6 & 20.5 & 21.8 & 16.2 & 56.5 & 65.3 & 50.5 & 48.4 & 44.5 & 37.0 & 40.0 & 37.5 \\
InternVL2.5-8B & 40.3 & 36.2 & 40.8 & 36.0 & 67.8 & 74.2 & 62.0 & 62.6 & 45.0 & 40.3 & 51.2 & 49.9 \\
\midrule
InternVL2.5-38B & 53.6 & 51.0 & 44.2 & 39.0 & 70.4 & 76.6 & 66.8 & 67.4 & 52.8 & 43.3 & 57.6 & 55.5 \\
Video-LLaMA2-72B & 56.0 & 54.8 & 44.2 & 41.3 & 49.2 & 60.1 & 50.3 & 46.1 & 53.6 & 45.7 & 50.7 & 49.6 \\
InternVL2.5-78B & 48.8 & 47.7 & 41.2 & 37.8 & 63.2 & 71.2 & 59.4 & 59.0 & 52.4 & 38.9 & 53.0 & 50.9 \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{13}{c}{\textit{Closed-Source Model (API)}} \\\midrule
GLM-4V-PLUS & 54.9 & 48.8 & 43.7 & 34.8 & 70.0 & 75.0 & 61.2 & 59.9 & 50.8 & 45.0 & 56.1 & 52.7 \\
Gemini-1.5-Flash & 62.0 & 60.1 & 52.0 & 50.1 & 75.0 & 78.6 & 65.0 & 64.8 & 44.4 & 46.5 & 59.7 & 60.0 \\
Gemini-2.0-Flash & 63.3 & 62.2 & 55.8 & 53.5 & 68.8 & 75.8 & 63.5 & 63.0 & 55.6 & 48.6 & \bf 61.4 & \bf 60.6 \\
Gemini-2.0-Flash-Thinking & 53.4 & 51.0 & 53.0 & 49.4 & 79.4 & 81.9 & 66.5 & 66.8 & 36.0 & 38.1 & 57.7 & 57.4 \\
\bottomrule
\end{tabular}}
\vspace{-2.5mm}
\caption{\small Performance comparison of different methods on $\ours$ (Foundational Emotion Recognition). SOER: Song Emotion Recognition, SPER: Speech Emotion Recognition, OSA: Opinion Sentiment Analysis, EIA: Emotion Intensity Analysis, SCEA: Stock Comment Emotion Analysis.}
\label{tab:performance_fer}
\vspace{-1mm}
\end{table*}
\subsection{Experimental Settings}

\paragraph{Task Formulation.}
We evaluate all MLLMs in a zero-shot setting on $\ours$ to assess their innate capabilities. 
For classification tasks, the models are prompted to predict emotion categories directly from multimodal inputs, such as audio, video, and text. 
For generative tasks, the models are required to provide detailed explanations or inferences regarding emotional contexts. 
The prompts used for these tasks are carefully designed to ensure clarity and consistency across different models and are detailed in the Appendix~\ref{app:prompt}. 
We employ metrics such as accuracy (ACC), Weighted Average F-score (WAF) for classification tasks, and LLM evaluator for generative tasks to evaluate MLLMs' performance. 

\paragraph{Models.}
As shown in Table~\ref{tab:config}, We evaluate a diverse set of LLMs, including both open-source and closed-source systems, to provide a comprehensive analysis of their multimodal emotional intelligence capabilities. 
The open-source models include Qwen2-Audio-Instruct \cite{Qwen2-Audio}, MiniCPM-V \cite{MiniCPM-V}, InternVL2.5 \cite{InternVL}, and Video-LLaMA2 \cite{VideoLLaMA_2}, covering parameter scales ranging from 4 B to 78 B. 
These models are designed to handle tasks involving text, audio, video, and multimodal reasoning, showcasing cross-modal alignment and interaction advancements.
Closed-source models evaluated include the GLM-4V series \cite{GLM-4} and Gemini series \cite{Gemini}, accessed via API. More details are in Appendix~\ref{app:modelconfig}.

\subsection{Results and Findings}

\begin{table*}[!t]\small
\centering
\setlength{\tabcolsep}{5.1pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c}{\textbf{FGDEA}} & \multicolumn{2}{c}{\textbf{PEA}} & \multicolumn{2}{c}{\textbf{FCDEA}} & \multicolumn{2}{c}{\textbf{CEIA}} & \multicolumn{2}{c}{\textbf{MPDER}} & \multicolumn{2}{c}{\textbf{Avg.}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
 & ACC & WAF & ACC & WAF & ACC & WAF & ACC & WAF & ACC & WAF & ACC & WAF \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{13}{c}{\textit{Open-Source Model}} \\\midrule
InternVL2.5-4B & 56.9 & 57.9 & 66.8 & 68.6 & 67.5 & 69.0 & 14.0 & 10.7 & 41.2 & 39.9 & 49.3 & 49.2 \\
Video-LLaMA2-7B & 45.7 & 46.4 & 45.2 & 50.2 & 42.7 & 45.2 & 8.1 & 5.0 & 30.7 & 27.9 & 34.5 & 34.9 \\
Video-LLaMA2-7B-16F & 52.9 & 53.6 & 31.6 & 35.4 & 63.0 & 66.6 & 8.3 & 3.3 & 29.6 & 27.5 & 37.1 & 37.3 \\
Qwen2-Audio-7B-Instruct & 51.6 & 50.1 & 59.0 & 63.7 & 55.6 & 59.1 & 7.6 & 6.0 & 42.7 & 40.8 & 43.3 & 43.9 \\
Video-LLaMA2.1-7B-16F & 52.8 & 51.8 & 65.6 & 66.1 & 68.5 & 68.4 & 7.9 & 6.8 & 35.5 & 35.3 & 46.1 & 45.7 \\
Video-LLaMA2.1-7B-AV & 51.5 & 48.5 & 68.2 & 69.0 & 67.6 & 67.7 & 6.5 & 4.4 & 36.6 & 34.4 & 46.1 & 44.8 \\
LongVA-DPO-7B & 51.1 & 51.0 & 33.2 & 37.2 & 33.3 & 35.2 & 6.1 & 5.4 & 37.0 & 34.6 & 32.1 & 32.7 \\
InternVideo2-Chat-8B & 58.0 & 55.4 & 50.8 & 56.2 & 49.2 & 53.2 & 8.9 & 6.2 & 34.2 & 31.6 & 40.2 & 40.5 \\
MiniCPM-V-2.6-8B & 48.9 & 49.0 & 58.6 & 63.7 & 57.1 & 61.3 & 11.7 & 9.0 & 39.2 & 37.5 & 43.1 & 44.1 \\
InternVL2.5-8B & 48.9 & 48.5 & 61.0 & 65.2 & 62.5 & 65.7 & 12.4 & 13.2 & 43.8 & 42.3 & 45.7 & 47.0 \\
\midrule
InternVL2.5-38B & 56.1 & 57.2 & 66.2 & 70.4 & 65.2 & 68.2 & 13.5 & 13.3 & 43.5 & 42.5 & 48.9 & 50.3 \\
Video-LLaMA2-72B & 43.1 & 41.2 & 42.8 & 49.5 & 41.4 & 45.4 & 11.6 & 12.5 & 47.6 & 48.1 & 37.3 & 39.3 \\
InternVL2.5-78B & 52.7 & 53.1 & 56.8 & 62.9 & 56.7 & 61.1 & 12.6 & 11.7 & 43.5 & 41.8 & 44.5 & 46.1 \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{13}{c}{\textit{Closed-Source Model (API)}} \\\midrule
GLM-4V-PLUS & 51.8 & 53.1 & 62.8 & 67.1 & 65.4 & 67.1 & 14.7 & 13.0 & 41.6 & 40.5 & 47.3 & 48.2 \\
Gemini-1.5-Flash & 67.2 & 67.2 & 72.3 & 74.3 & 73.2 & 74.0 & 15.6 & 15.8 & 49.5 & 49.2 & \bf 55.6 & \bf 56.1 \\
Gemini-2.0-Flash & 64.2 & 64.8 & 70.9 & 73.6 & 71.9 & 73.8 & 11.1 & 12.7 & 48.7 & 48.5 & 53.4 & 54.7 \\
Gemini-2.0-Flash-Thinking & 64.5 & 65.4 & 71.2 & 72.8 & 71.6 & 72.6 & 12.0 & 13.7 & 51.5 & 51.8 & 54.2 & 55.3 \\
\bottomrule
\end{tabular}}
\vspace{-2.5mm}
\caption{\small Performance comparison of different methods on $\ours$ (Conversational Emotion Understanding). FGDEA: Fine-Grained Dialog Emotion Analysis, PEA: Presentation Emotion Analysis, FCDEA: Face-Centric Dialog Emotion Analysis, CEIA: Conversational Emotion \& Intent Analysis, MPDER: Multi-Party Dialog Emotion Recognition.}
\label{tab:performance_ceu}
\vspace{-2mm}
\end{table*}

\begin{table*}[!t]\small
\centering
\setlength{\tabcolsep}{5.1pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c}{\textbf{HU}} & \multicolumn{2}{c}{\textbf{SD}} & \multicolumn{6}{c}{\textbf{LR}} & \multicolumn{2}{c}{\textbf{Avg.}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-11} \cmidrule(lr){12-13}
 & ACC & WAF & ACC & WAF & B-4 & R-L & BS & logic. & mm. & Total & ACC & WAF \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{13}{c}{\textit{Open-Source Model}} \\\midrule
InternVL2.5-4B & 56.6 & 56.6 & 52.7 & 52.7 & 0.0 & 13.0 & 15.2 & 18.0 & 19.8 & 37.8 & 54.7 & 54.7 \\
Video-LLaMA2-7B & 60.7 & 59.0 & 55.8 & 54.8 & 4.6 & 29.8 & 36.3 & 33.9 & 33.5 & 67.4 & 58.3 & 56.9 \\
Video-LLaMA2-7B-16F & 67.9 & 67.7 & 59.8 & 58.9 & 4.0 & 28.6 & 34.4 & 33.3 & 32.6 & 65.9 & 63.9 & 63.3 \\
Qwen2-Audio-7B-Instruct & 52.5 & 37.4 & 53.3 & 41.4 & 4.0 & 26.4 & 32.8 & 30.8 & 30.4 & 61.2 & 52.9 & 39.4 \\
Video-LLaMA2.1-7B-16F & 67.0 & 65.4 & 53.8 & 43.8 & 5.2 & 31.9 & 42.6 & 25.9 & 25.8 & 51.7 & 60.4 & 54.6 \\
Video-LLaMA2.1-7B-AV & 54.7 & 50.3 & 53.4 & 45.0 & 11.5 & 33.5 & 89.7 & 20.0 & 20.5 & 40.5 & 54.1 & 47.7 \\
LongVA-DPO-7B & 63.6 & 63.3 & 51.6 & 40.0 & 0.0 & 12.4 & 8.2 & 21.9 & 23.3 & 45.2 & 57.6 & 51.7 \\
InternVideo2-Chat-8B & 68.1 & 67.8 & 61.2 & 61.0 & 19.5 & 45.8 & 92.5 & 31.9 & 29.6 & 61.5 & 64.7 & 64.4 \\
MiniCPM-V-2.6-8B & 55.1 & 53.9 & 49.6 & 38.6 & 2.3 & 27.5 & 39.1 & 32.9 & 32.0 & 64.9 & 52.4 & 46.3 \\
InternVL2.5-8B & 66.5 & 66.5 & 59.6 & 59.0 & 0.0 & 12.8 & 16.1 & 17.1 & 19.3 & 36.4 & 63.1 & 62.8 \\
\midrule
InternVL2.5-38B & 73.0 & 72.7 & 61.2 & 61.2 & 0.3 & 13.3 & 17.5 & 17.1 & 18.6 & 35.7 & 67.1 & 67.0 \\
Video-LLaMA2-72B & 67.9 & 64.5 & 51.0 & 35.5 & 7.4 & 35.4 & 48.0 & 34.0 & 32.6 & 66.6 & 59.5 & 50.0 \\
InternVL2.5-78B & 76.8 & 76.8 & 64.4 & 63.6 & 0.0 & 13.0 & 18.2 & 18.2 & 20.0 & 38.2 & 70.6 & 70.2 \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{13}{c}{\textit{Closed-Source Model (API)}} \\\midrule
GLM-4V-PLUS & 74.7 & 74.6 & 59.8 & 58.7 & 14.8 & 33.9 & 90.2 & 37.6 & 36.6 & 74.2 & 67.3 & 66.7 \\
Gemini-1.5-Flash & 72.8 & 71.0 & 58.6 & 52.2 & 13.8 & 33.5 & 90.2 & 37.9 & 36.4 & \bf 74.3 & 65.7 & 61.6 \\
Gemini-2.0-Flash & 79.2 & 79.2 & 64.8 & 62.3 & 15.3 & 33.6 & 90.4 & 36.5 & 35.4 & 71.9 & \bf 72.0 & \bf 70.8 \\
Gemini-2.0-Flash-Thinking & 75.6 & 74.7 & 60.4 & 55.8 & 15.8 & 35.5 & 66.4 & 37.5 & 36.6 & 74.1 & 68.0 & 65.3 \\
\bottomrule
\end{tabular}}
\vspace{-2mm}
\caption{\small Performance comparison of different methods on $\ours$ (Socially Complex Emotion Analysis). For the average of ``ACC'' and ``WAF'', we include only the scores from the HU and SD scenarios. HU: Humor Understanding, SD: Sarcasm Detection, LR: Laughter Reasoning.}
\vspace{-1mm}
\label{tab:performance_scea}
\end{table*}
\begin{figure*}[!t]
    \centering
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-exp/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    \vspace{-1mm}
    \caption{\small Confusion matrices for Gemini-2.0-Flash on each evaluation scenario of $\ours$. Other models in Appendix~\ref{app:confusion}.}
    \label{fig:confusion-Gemini-2.0-Flash}
    \vspace{-2mm}
\end{figure*}

\begin{table}[!t]\small
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{lcccc}
\toprule
\bf Method & \bf FER & \bf CEU & \bf SCEA & \bf Avg. \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{5}{c}{\textit{Open-Source Model}} \\\midrule
InternVL2.5-4B & 54.5 & 49.3 & 49.0 & 50.9 \\
Video-LLaMA2-7B & 45.4 & 34.5 & 61.3 & 47.1 \\
Video-LLaMA2-7B-16F & 51.4 & 37.1 & 64.5 & 51.0 \\
Qwen2-Audio-7B-Instruct & 59.9 & 43.3 & 55.7 & 53.0 \\
Video-LLaMA2.1-7B-16F & 50.9 & 46.1 & 57.5 & 51.5 \\
Video-LLaMA2.1-7B-AV & 50.4 & 46.1 & 49.5 & 48.7 \\
LongVA-DPO-7B & 45.7 & 32.1 & 53.5 & 43.8 \\
InternVideo2-Chat-8B & 50.6 & 40.2 & 63.6 & 51.5 \\
MiniCPM-V-2.6-8B & 40.0 & 43.1 & 56.5 & 46.5 \\
InternVL2.5-8B & 51.2 & 45.7 & 54.2 & 50.4 \\
\midrule
InternVL2.5-38B & 57.6 & 48.9 & 56.6 & 54.4 \\
Video-LLaMA2-72B & 50.7 & 37.3 & 61.8 & 49.9 \\
InternVL2.5-78B & 53.0 & 44.5 & 59.8 & 52.4 \\
\hline\midrule
\rowcolor{gray!25}\multicolumn{5}{c}{\textit{Closed-Source Model (API)}} \\\midrule
GLM-4V-PLUS & 56.1 & 47.3 & 69.6 & 57.7 \\
Gemini-1.5-Flash & 59.7 & \bf 55.6 & 68.6 & 61.3 \\
Gemini-2.0-Flash & \bf 61.4 & 53.4 & \bf 72.0 & \bf 62.3 \\
Gemini-2.0-Flash-Thinking & 57.7 & 54.2 & 70.0 & 60.6 \\
\bottomrule
\end{tabular}
\vspace{-1mm}
\caption{\small Performance comparison of different methods on $\ours$ (Average Performance on three dimensions). The mean ACC was used as the score for each dimension, while the Total score was used for LR in SCEA. FER: Foundational Emotion Recognition, CEU: Conversational Emotion Understanding, SCEA: Socially Complex Emotion Analysis.}
\vspace{-2mm}
\label{tab:performance_avg}
\end{table}
We show the performance of various models on the $\ours$ benchmark across three dimensions: Foundational Emotion Recognition (FER), Conversational Emotion Understanding (CEU), and Socially Complex Emotion Analysis (SCEA). As shown in Table \ref{tab:performance_fer}, Gemini-2.0-Flash achieves the best results (ACC: 61.4\%, WAF: 60.6\%), outperforming all open-source models. Among the latter, Qwen2-Audio-7B-Instruct stands out with an ACC of 59.9\%. Table \ref{tab:performance_ceu} show the superior performance of closed-source models, with Gemini-1.5-Flash achieving the highest ACC (55.6\%). Open-source models like InternVL2.5-38B also perform well (ACC: 48.9\%).
As shown in Table \ref{tab:performance_scea}, Gemini-2.0-Flash excels again, achieving the highest average ACC (72.0\%). Among open-source models, InternVL2.5-78B leads with an ACC of 70.6\%. Table \ref{tab:performance_avg} shows Gemini-2.0-Flash as the overall top performer (Avg.: 62.3\%), followed by Gemini-1.5-Flash (Avg.: 61.3\%). Open-source models like InternVL2.5-38B show promise with an average score of 54.4\%. Closed-source models outperform open-source models, especially on complex tasks.

\subsection{Analysis on Generation Metric}
\begin{table}[!t]\small
\centering
\begin{tabular}{lcc}
\toprule
\bf Metric & \textbf{Cosine Sim.} & \textbf{Pearson Corr.} \\
\midrule
BLEU-4 & 0.7381 & 0.2934 \\
ROUGE-L & 0.8563 & 0.2947 \\
BERTScore & 0.8762 & 0.3199 \\
\midrule
\rowcolor{gray!25}Qwen2.5-72B-Instruct & \bf 0.9353 & \bf 0.4042 \\
\bottomrule
\end{tabular}
\vspace{-1mm}
\caption{\small Cosine similarity and Pearson correlation result: traditional metrics and open-source LLM consistency with human evaluation in laughter reasoning. ``B-4'', ``R-L'', and ``BS'' denote BLEU-4 \cite{Bleu} ROUGE-L \cite{Rouge}, and BERTScore \cite{BERTScore}, respectively.}
\label{tab:metric}
\vspace{-2mm}
\end{table}
Table \ref{tab:metric} shows cosine similarity and Pearson correlation results for traditional metrics (BLEU-4, ROUGE-L, BERTScore) and the open-source LLM Qwen2.5-72B-Instruct with human judgments. Among traditional metrics, BERTScore showed the highest consistency with human evaluation (cosine similarity: 0.8762, Pearson correlation: 0.3199), outperforming BLEU-4 and ROUGE-L. Notably, Qwen2.5-72B-Instruct achieved superior results (cosine similarity: 0.9353, Pearson correlation: 0.4042), highlighting its ability to better align with human assessments in laughter reasoning tasks. It reveal the limitations of traditional metrics and underscore the potential of LLM-based approaches for more reliable evaluation.

\subsection{Analysis on Class-wise Performance}
Figure \ref{fig:confusion-Gemini-2.0-Flash} shows the class-wise performance of Gemini-2.0-Flash across three scenarios: Foundational Emotion Recognition (FER), Conversational Emotion Understanding (CEU), and Socially Complex Emotion Analysis (SCEA).
In FER (SOER, SPER, SCEA, OSA, EIA), the model performs well on primary emotions like ``angry'' and ``neutral'', as well as sentiments like ``positive'' and ``negative''. However, it struggles with subtle or overlapping emotions, such as ``fearful'' and ``calm'', and distinctions between ``neutral'' and ``positive''.
In CEU (FGDEA, PEA, FCDEA, CEIA, MPDER), the model effectively handles common emotions like ``neutral'' and structured tasks like intent analysis. However, complex emotions like ``surprise'' and nuanced intents such as ``encouraging'' present challenges.
In SCEA (HU, SD), the model achieves strong performance in HU, and SD  reveals difficulties, underlining the challenges posed by subtle social emotions.
Gemini-2.0-Flash demonstrates robust performance but struggles with nuanced and overlapping categories in complex scenarios.


\subsection{Comparison with Human Performance}
\begin{table}[!t]\small
    \centering
    \setlength{\tabcolsep}{7pt}
    \begin{tabular}{lcccc}
        \toprule
        \bf Method & \bf FER & \bf CEU & \bf SCEA & \bf Avg. \\
        \midrule
        InternVL2.5-78B & 53.0 & 44.5 & 59.8 & 52.4 \\
        GLM-4V-PLUS & 56.1 & 47.3 & 69.6 & 57.7 \\
        Gemini-2.0-Flash & 61.4 & 53.4 & 72.0 & 62.3 \\
        \midrule
        \rowcolor{gray!25}Human & \bf 62.0 & \bf 84.4 & \bf 72.7 & \bf 73.0 \\
        \bottomrule
    \end{tabular}
    \vspace{-1mm}
    \caption{\small Performance comparison of MLLMs and humans across three dimensions of $\ours$.}
    \label{fig:human_comp}
    \vspace{-2mm}
\end{table}
Table~\ref{fig:human_comp} compares the performance of MLLMs and human evaluators across three dimensions of $\ours$: FER, CEU, and SCEA, along with the average score (Avg.). Among the models, Gemini-2.0-Flash performs the best, achieving an average score of 62.3, but it still lags behind human performance, which achieves 73.0 on average.
Humans excel in CEU with a score of 84.4, highlighting their superior contextual understanding. However, their performance in SCEA (72.7) is only marginally better than Gemini-2.0-Flash (72.0). The relatively lower human score in SCEA is attributed to cultural differences between the annotators and the dataset, which introduced challenges in achieving optimal performance in this dimension. 
Therefore, while MLLMs demonstrate promising results, they remain behind humans in tasks requiring nuanced understanding and contextual reasoning. More details are in Appendix~\ref{app:human}.

\subsection{Stability Analysis of MLLM}
\begin{table}[!t]\small
\centering
\setlength{\tabcolsep}{3pt}
\begin{tabular}{lccc}
\toprule
\bf Dimensions                          & \bf 1     & \bf 2     & \bf 3     \\ \midrule
Foundational Emotion Recognition        & \bf 61.4  & 61.2  & 61.0  \\
Conversational Emotion Understanding    & 53.4  & 54.0  & \bf 54.1  \\
Socially Complex Emotion Analysis       & 72.0  & 72.5  & \bf 72.8  \\ \bottomrule
\end{tabular}
\vspace{-1mm}
\caption{\small Stability experiment of Gemini-2.0-Flash on three dimensions, running predictions 1, 3, and 5 times, with the majority voting to obtain the final result. Since LR is a generative task, the stability experiment on the Socially Complex Emotion Analysis only involves the HU and SD scenarios.}
\label{fig:stable}
\vspace{-2mm}
\end{table}
We analyze the stability of Gemini-2.0-Flash across three dimensions: FER, CEU, and SCEA. Stability is evaluated by running predictions 1, 3, and 5 times, using majority voting for final results (shown in Table~\ref{fig:stable}). In FER, scores are 61.4, 61.2, and 61.0, with the highest at 61.4. For CEU, scores improve from 53.4 to 54.1 across iterations. In SCEA, results are 72.0, 72.5, and 72.8, considering only HU and SD scenarios due to the generative nature of this task. These results demonstrate the model's robust stability, with minor variations and improvements in complex emotional contexts. More details can be found in Appendix~\ref{app:stability}.


\section{Conclusion and Future Work}
We introduced $\ours$ to evaluate the EI of MLLMs across three key areas: Foundational Emotion Recognition, Conversational Emotion Understanding, and Socially Complex Emotion Understanding. Our results show that while MLLMs perform reasonably well on basic emotion recognition, they struggle significantly with conversational and socially complex emotional understanding. It reveals a crucial gap between MLLM capabilities and human-level EI in dynamic, multimodal settings.
Future research can prioritize work that can focus on enhancing models' contextual understanding and social awareness in MLLMs. Key areas include: leveraging advanced dialogue modeling, incorporating social reasoning, leveraging mechanisms, and diverse datasets with encompassing varied cultural contexts, i. Improving multimodal fusion, integrating techniques, and embedding psychological principles directly into model design architecture can further advance EI capabilities. 

\section*{Limitations}
The limitation of our study is the exclusion of MLLMs specifically fine-tuned on emotion-centric datasets. We focus on evaluating general-purpose MLLMs to understand their EI capabilities in realistic applications, where models are expected to generalize across diverse tasks and domains. This aligns with our objective of assessing the broader applicability of MLLMs in real-world scenarios rather than focusing on specialized models designed for emotion computation. 

\section*{Ethical Considerations}
In this study, we exclusively utilized publicly available datasets with open-source links. Furthermore, we ensured compliance with the licensing agreements associated with these datasets by formally obtaining usage permissions where required. As a result, our research does not raise any ethical concerns regarding data usage or handling.



\bibliography{custom}
\appendix
\clearpage
\section{Details and Case of Datasets}\label{app:dataset}
This section provides an overview of the datasets used in our experiments, highlighting the number of test samples and the corresponding labels associated with each dataset. Table~\ref{tab:datasets} summarizes this information, covering a wide range of emotional and intent-based annotations across various modalities. Visual examples for each dataset are provided in Figure~\ref{fig:Ch_SIMSv2}-\ref{fig:SMILE}.
\begin{itemize}
    \item \textbf{RAVDESS (song \& speech):} The RAVDESS dataset includes both speech and song audio files annotated with emotions such as \textit{neutral}, \textit{calm}, \textit{happy}, \textit{sad}, \textit{angry}, and \textit{fearful}. The speech subset contains additional labels, including \textit{surprised} and \textit{disgust}.
    
    \item \textbf{CMU-MOSI and CMU-MOSEI:} These datasets are designed for multimodal sentiment analysis and include three sentiment labels: \textit{neutral}, \textit{positive}, and \textit{negative}.
    
    \item \textbf{FMSA-SC:} This dataset captures fine-grained sentiment annotations with labels such as \textit{weak negative}, \textit{strong negative}, \textit{neutral}, \textit{weak positive}, and \textit{strong positive}.
    
    \item \textbf{MER2023:} Designed for emotion recognition, this dataset provides six emotion categories: \textit{happiness}, \textit{sadness}, \textit{anger}, \textit{surprise}, \textit{neutral}, and \textit{calm}.
    
    \item \textbf{CH-SIMSv2 and CH-SIMS:} These datasets, used for sentiment analysis in Chinese, are annotated with three labels: \textit{neutral}, \textit{negative}, and \textit{positive}.
    
    \item \textbf{MC-EIU:} This dataset offers both emotion annotations (\textit{happy}, \textit{surprise}, \textit{sad}, \textit{disgust}, \textit{anger}, \textit{fear}, \textit{neutral}) and intent annotations (\textit{questioning}, \textit{agreeing}, \textit{acknowledging}, \textit{encouraging}, \textit{consoling}, \textit{suggesting}, \textit{wishing}, \textit{neutral}).
    
    \item \textbf{MELD:} This multimodal dataset includes seven emotion labels: \textit{neutral}, \textit{surprise}, \textit{fear}, \textit{sadness}, \textit{joy}, \textit{disgust}, and \textit{anger}.
    
    \item \textbf{UR-FUNNY and MUStARD:} Both datasets are binary-labeled for humor detection, with annotations of \textit{true} or \textit{false}.
    
    \item \textbf{SMILE:} A small-scale dataset focusing on humor comprehension, annotated with explanations of why the audience laughed.
\end{itemize}
Table~\ref{tab:datasets} provides detailed statistics on the test samples and label distributions for each dataset.


\begin{table}[!t]\small
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{2pt}
\begin{tabular}{lcccr}
\toprule
\textbf{Model} & \textbf{top-p} & \textbf{top-k} & \textbf{temp.} & \textbf{VRAM} \\
\midrule
InternVL2.5-4B \cite{InternVL}    & 1.0 & 50 & 1.0 & 14G \\
Video-LLaMA2-7B \cite{VideoLLaMA_2}      & 0.8 & 20 & 0.7 & 19G \\
Video-LLaMA2-7B-16F \cite{VideoLLaMA_2}    & 0.8 & 20 & 0.7 & 19G \\
Qwen2-Audio-7B-Instruct \cite{Qwen2-Audio}       & 0.5 & 20 & 0.7 & 33G \\
Video-LLaMA2.1-7B-16F \cite{VideoLLaMA_2}   & 0.8 & 20 & 0.7 & 22G \\
Video-LLaMA2.1-AV-7B \cite{VideoLLaMA_2} & 0.8 & 20 & 0.7 & 21G \\
LongVA-DPO-7B \cite{LongVA}      & 1.0 & 50 & 1.0 & 21G \\
InternVideo2-Chat-8B \cite{InternVideo2}  & 1.0 & 50 & 1.0 & 17G \\
MiniCPM-V-2.6-8B \cite{MiniCPM-V}    & 0.8 & 100 & 0.7 & 19G \\
InternVL2.5-8B \cite{InternVL}          & 1.0 & 50 & 1.0 & 24G \\
InternVL2.5-38B \cite{InternVL}   & 1.0 & 50 & 1.0 & 73G \\
Video-LLaMA2-72B \cite{VideoLLaMA_2}      & 0.8 & 20 & 0.7 & 148G \\
InternVL2.5-78B \cite{InternVL}           & 1.0 & 50 & 1.0 & 168G \\
\midrule
GLM-4V-PLUS \cite{GLM-4}            & 0.6 & - & 0.8 & API \\
Gemini-1.5-Flash \cite{Gemini}            & 0.95 & 40 & 1.0  & API \\
Gemini-2.0-Flash \cite{Gemini2}        & 0.95 & 40 & 1.0 & API \\
Gemini-2.0-Flash-Thinking \cite{Gemini2}        & 0.95 & 64 & 1.0 & API \\
\bottomrule
\end{tabular}}
\caption{\small Model configuration evaluated on $\ours$.}
\label{tab:config}
\end{table}

\section{Model Configuration}\label{app:modelconfig}
The configuration details of the models evaluated on $\ours$ are summarized in Table~\ref{tab:config}. The table provides a detailed comparison of key hyperparameters, including top-p and top-k sampling values, temperature settings, and VRAM requirements. For models accessed via APIs, the VRAM is denoted as ``API'', reflecting their closed-source nature and cloud-based deployment.
The evaluated models encompass a range of architectures, from smaller-scale models, such as InternVL2.5-4B~\cite{InternVL}, to large-scale variants like InternVL2.5-78B~\cite{InternVL}. Noteworthy configurations include Video-LLaMA2.1-AV-7B~\cite{VideoLLaMA_2}, which incorporates audiovisual processing, and Gemini-2.0-Flash-Thinking~\cite{Gemini2}, which features enhanced reasoning capabilities.
Most models exhibit consistent sampling parameters (e.g., top-p and temperature), ensuring a standardized basis for comparison. The VRAM requirements reflect the computational demands of these models, ranging from 14 GB for smaller models to 168 GB for the largest configurations. In contrast, API-based models provide an accessible option for users, particularly when local resources are constrained, albeit at the cost of reduced transparency due to their closed-source nature.

\begin{table*}[!t]\small
\centering
\begin{tabular}{@{}p{3cm}p{2cm}p{9cm}@{}}
\toprule
\textbf{Dataset}          & \textbf{\# Test samples} & \textbf{Labels}                                                                 \\ \midrule
RAVDESS (song)            & 500                      & neutral, calm, happy, sad, angry, fearful                                       \\
RAVDESS (speech)          & 500                      & neutral, calm, happy, sad, angry, fearful, surprised, disgust                  \\
CMU-MOSI                  & 500                      & neutral, negative, positive                                                    \\
CMU-MOSEI                 & 500                      & neutral, negative, positive                                                    \\
FMSA-SC                   & 250                      & weak negative, strong negative, neutral, strong positive, weak positive        \\
MER2023                   & 411                      & happiness, sadness, anger, surprise, neutral, calm                             \\
CH-SIMSv2                 & 500                      & neutral, negative, positive                                                    \\
CH-SIMS                   & 457                      & neutral, negative, positive                                                    \\
MC-EIU                    & 500                      & emotion: happy, surprise, sad, disgust, anger, fear, neutral                  \\ 
                          &                          & intent: questioning, agreeing, acknowledging, encouraging, consoling,      suggesting, wishing, neutral                                                   \\
MELD                      & 500                      & neutral, surprise, fear, sadness, joy, disgust, anger                          \\
UR-FUNNY                  & 448                      & true, false                                                                    \\
MUStARD                   & 500                      & true, false                                                                    \\
SMILE                     & 80                       & The audience laughed because...                                                \\ \bottomrule
\end{tabular}
\caption{\small Overview of datasets, test samples, and emotion/intent labels.}
\label{tab:datasets}
\end{table*}

\begin{table*}[!t]\small
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{3pt}
\begin{tabular}{lccccccccccccc}
\toprule
\bf Method & \bf SOER & \bf SPER & \bf OSA & \bf EIA & \bf SCEA & \bf FGDEA & \bf PEA & \bf FCDEA & \bf CEIA & \bf MPDER & \bf HU & \bf SD & \bf LR \\
\midrule
Random & 16.6 & 12.5 & 33.3 & 33.3 & 20.0 & 16.6 & 33.3 & 33.3 & 1.8 & 14.2 & 50.0 & 50.0 & 0.0 \\
InternVL2.5-78B & 48.8 & 41.2 & 63.2 & 59.4 & 52.4 & 52.7 & 56.8 & 56.7 & 12.6 & 43.5 & 76.8 & 64.4 & 38.2 \\
GLM-4V-PLUS & 54.9 & 43.7 & 70.0 & 61.2 & 50.8 & 51.8 & 62.8 & 65.4 & 14.7 & 41.6 & 74.7 & 59.8 & 74.2 \\
Gemini-2.0-Flash & 63.3 & 55.8 & 68.8 & 63.5 & 55.6 & 64.2 & 70.9 & 71.9 & 11.1 & 48.7 & 79.2 & 64.8 & 71.9 \\
Human & 54.0 & 82.0 & 60.0 & 58.0 & 56.0 & 90.0 & 86.0 & 96.0 & 72.0 & 78.0 & 44.0 & 74.0 & 100.0 \\
\bottomrule
\end{tabular}}
\caption{\small Performance comparison of MLLMs and humans across different scenarios.}
\label{fig:scenario_comp}
\end{table*}

\begin{table*}[!t]\small
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{3pt}
\centering
\begin{tabular}{lcccccccccccc}
\toprule
\bf Scenarios & \bf SOER & \bf SPER & \bf OSA & \bf EIA & \bf SCEA & \bf FGDEA & \bf PEA & \bf FCDEA & \bf CEIA & \bf MPDER & \bf HU & \bf SD \\ \midrule
\bf 1 & 63.3 & 55.8 & 68.8 & 63.5 & 55.6 & 64.2 & 70.9 & 71.9 & 11.1 & 48.7 & 79.2 & 64.8 \\
\bf 2 & 64.6 & 55.4 & 67.8 & 63.4 & 54.8 & 66.4 & 71.3 & 71.9 & 11.1 & 49.5 & 79.2 & 65.8 \\
\bf 3 & 63.8 & 54.8 & 69.0 & 63.4 & 54.0 & 66.2 & 72.1 & 72.1 & 11.1 & 48.9 & 79.7 & 66.0 \\ \bottomrule
\end{tabular}}
\caption{\small Stability experiment of Gemini-2.0-Flash on different scenarios, running predictions 1, 3, and 5 times, with the majority voting to obtain the final result.}
\label{fig:more_stable_transposed}
\end{table*}


\section{Details on Comparison with Human Performance}\label{app:human}
Table~\ref{fig:scenario_comp} provides a detailed comparison of performance metrics between MLLMs and human participants across various evaluation scenarios. The Random baseline demonstrates consistently low performance, serving as a reference for assessing advancements in model capabilities. Among the MLLMs, Gemini-2.0-Flash exhibits the highest performance, surpassing other models such as InternVL2.5-78B and GLM-4V-PLUS in most metrics, including SOER, SCEA, and FGDEA. Despite these advancements, human participants consistently outperform the models in critical areas such as SPER, FGDEA, and PEA, with perfect scores achieved in logical reasoning (LR). This highlights the superior generalization and adaptability of humans compared to current MLLMs.

\section{Details on Stability Analysis of MLLM}\label{app:stability}
Table~\ref{fig:more_stable_transposed} shows the results of stability experiments conducted on Gemini-2.0-Flash. The analysis evaluates the model's performance across different numbers of prediction iterations (1, 3, and 5), with the final output determined through a majority voting mechanism. Scenarios assessed include SOER, SPER, OSA, EIA, SCEA, FGDEA, PEA, FCDEA, CEIA, MPDER, HU, and SD.
The results demonstrate consistent performance across different iteration counts, with minimal variation observed in most metrics. For instance, the performance on SOER shows only a slight fluctuation, ranging from 63.3 in the single iteration setup to 63.8 in the five-iteration case. Similarly, performance on SPER and EIA exhibit stable trends, reinforcing the model's robustness against runtime variability.




\section{More Analysis on Class-wise Performance}\label{app:confusion}
For class-wise performance, confusion matrices for more models can be found in Figure~\ref{fig:confusion-Gemini-1.5-Flash}-\ref{fig:confusion-VideoLLaMA2.1-7B-AV}.




\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/CH-SIMSv2.pdf} 
    \caption{\small Example of CH-SIMSv2 dataset.}
    \label{fig:Ch_SIMSv2}
\end{figure*}


\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/CH-SIMS.pdf} 
    \caption{\small Example of CH-SIMS dataset.}
    \label{fig:Ch_SIMS}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/CMU-MOSEI.pdf} 
    \caption{\small Example of CMU-MOSEI dataset.}
    \label{fig:CMU_MOSEI}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/CMU-MOSI.pdf} 
    \caption{\small Example of CMU-MOSI dataset.}
    \label{fig:CMU_MOSI}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/FMSA-SC.pdf} 
    \caption{\small Example of FMSA-SC dataset.}
    \label{fig:FMSA-SC}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/MC-EIU.pdf} 
    \caption{\small Example of MC-EIU dataset.}
    \label{fig:MC-EIU}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/MELD.pdf} 
    \caption{\small Example of MELD dataset.}
    \label{fig:MELD}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/MER2023.pdf} 
    \caption{\small Example of MER2023 dataset.}
    \label{fig:MER2023}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/MUStARD.pdf} 
    \caption{\small Example of MUStARD dataset.}
    \label{fig:MUStARD}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/RAVDSS-song.pdf} 
    \caption{\small Example of RAVDSS-song dataset.}
    \label{fig:RAVDSS-song}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/RAVDSS-speech.pdf} 
    \caption{\small Example of RAVDSS-speech dataset.}
    \label{fig:RAVDSS-speech}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/UR-FUNNY.pdf} 
    \caption{\small Example of UR-FUNNY dataset.}
    \label{fig:UR-FUNNY}
\end{figure*}


\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/SMILE.pdf} 
    \caption{\small Example of SMILE dataset.}
    \label{fig:SMILE}
\end{figure*}

\clearpage

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-1.5-flash/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for Gemini-1.5-Flash on each evaluation scenario of $\ours$.}
    \label{fig:confusion-Gemini-1.5-Flash}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/gemini-2.0-flash-thinking/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for Gemini-2.0-Flash-Thinking on each evaluation scenario of $\ours$.}
    \label{fig:confusion-Gemini-2.0-Flash-Thinking}
\end{figure*}


\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/GLM-4V-PLUS/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for GLM-4V-PLUS on each evaluation scenario of $\ours$.}
    \label{fig:confusion-GLM-4V-PLUS}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-4B/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for InternVL2.5-4B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-InternVL2.5-4B}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-8B/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for InternVL2.5-8B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-InternVL2.5-8B}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-38B/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for InternVL2.5-38B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-InternVL2.5-38B}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InternVL2_5-78B/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for InternVL2.5-78B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-InternVL2.5-78B}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/InterVideo2-chat-8B/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for InternVideo2-Chat-8B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-InternVideo2-Chat-8B}
\end{figure*}


\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/LongVA-7B-DPO/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for LongVA-7B-DPO on each evaluation scenario of $\ours$.}
    \label{fig:confusion-LongVA-7B-DPO}
\end{figure*}


\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/MiniCPM-V-2_6/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for MiniCPM-V-2.6-8B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-MiniCPM-V-2.6-8B}
\end{figure*}


\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/Qwen-audio/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for Qwen2-Audio-7B-Instruct on each evaluation scenario of $\ours$.}
    \label{fig:confusion-Qwen2-Audio-7B-Instruct}
\end{figure*}


\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for VideoLLaMA2-7B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-VideoLLaMA2-7B}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-7B-16F/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for VideoLLaMA2-7B-16F on each evaluation scenario of $\ours$.}
    \label{fig:confusion-VideoLLaMA2-7B-16F}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2-72B/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for VideoLLaMA2-72B on each evaluation scenario of $\ours$.}
    \label{fig:confusion-VideoLLaMA2-72B}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-16F/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for VideoLLaMA2.1-7B-16F on each evaluation scenario of $\ours$.}
    \label{fig:confusion-VideoLLaMA2.1-7B-16F}
\end{figure*}

\begin{figure*}[!t]
    \centering
    
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/RAVDSS_song_500_confusion_matrix.pdf}
        \subcaption{\small SOER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/RAVDSS_speech_500_confusion_matrix.pdf}
        \subcaption{\small SPER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/FGMSA_test_instructuin_confusion_matrix.pdf}
        \subcaption{\small SCEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/MOSI_test_500_confusion_matrix.pdf}
        \subcaption{\small OSA}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/MOSEI_test_500_confusion_matrix.pdf}
        \subcaption{\small EIA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/mer2023_test1_instruction_confusion_matrix.pdf}
        \subcaption{\small FGDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/SIMS_test_500_confusion_matrix.pdf}
        \subcaption{\small FCDEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/ch-simsv2s_test_500_confusion_matrix.pdf}
        \subcaption{\small PEA}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/confusion_matrix_emotion.pdf}
        \subcaption{\small CEIA (emo.)}
    \end{minipage} \\
    
    \begin{minipage}[b]{0.20\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/confusion_matrix_intent.pdf}
        \subcaption{\small CEIA (int.)}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/MELD_test_instruction_confusion_matrix.pdf}
        \subcaption{\small MPDER}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/funny_test_instruction_confusion_matrix.pdf}
        \subcaption{\small HU}
    \end{minipage} \hfill
    \begin{minipage}[b]{0.16\linewidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix/VideoLLaMA2.1-7B-AV/MUSTARD_500_confusion_matrix.pdf}
        \subcaption{\small SD}
    \end{minipage}
    
    \caption{\small Confusion matrices for VideoLLaMA2.1-7B-AV on each evaluation scenario of $\ours$.}
    \label{fig:confusion-VideoLLaMA2.1-7B-AV}
\end{figure*}

\clearpage

\section{Prompt}\label{app:prompt}
\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From RAVDESS(song)},
    breakable
    ]\small
    
Please watch the provided video and determine the emotion it conveys. Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer:  neutral, calm, happy, sad, angry, fearful. Respond in the format: \{'emotion': 'label'\}.

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From RAVDESS(speech)},
    breakable
    ]\small
    
Please watch the provided video and determine the emotion it conveys.Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer: neutral, calm, happy, sad, angry, fearful, surprised, disgust. Respond in the format:\{'emotion': 'label'\}.  

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From CH-SIMSv2},
    breakable
    ]\small
    
The person in video says: \{Subtitle\}. Determine the emotion conveyed. Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer: neutral, negative, positive. Respond in the format: \{'emotion': 'label'\}.  

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From FMSA-SC},
    breakable
    ]\small
    
The person in video says: \{Subtitle\}. Determine the emotion conveyed. Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer: weak negative, strong negative, neutral, strong positive, weak positive. Respond in the format: \{'emotion': 'label'\}.  

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From UR-FUNNY },
    breakable
    ]\small
    
The context sentences in the video is: \{context sentences\}. The punchline sentence in the video is: \{punchline sentence\}. Choose one of the following labels as your final answer: true, false.  

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From MC-EIU },
    breakable
    ]\small
    
The person in video says:\{Subtitle\}. Analyze the emotion and intent. Choose one emotion: happy, surprise, sad, disgust, anger, fear, and neutral. Choose one intent: questioning, agreeing, acknowledging, encouraging, consoling, suggesting, wishing, and neutral. Respond in the format: \{'emotion label': 'label', 'intent label': 'label'\}. 

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From MELD },
    breakable
    ]\small
    
The person in video says: \{subtitle\}. Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer: neutral, surprise, fear, sadness, joy, disgust, anger. Respond in the format: \{'emotion': 'label'\} 

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From MER2023 },
    breakable
    ]\small
    
The person in video says: \{Subtitle\}. Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer: happy, sad, neutral, angry, worried, surprise. Respond in the format: \{'emotion': 'label'\}. 

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From CMU-MOSI  },
    breakable
    ]\small
    
The person in video says: \{Subtitle\}. Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer:  neutral,negative,positive. Respond in the format: \{'emotion': 'label'\}. 

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From CMU-MOSEI   },
    breakable
    ]\small
    
The person in video says: \{Subtitle\}. Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer:  neutral,negative,positive. Respond in the format: {'emotion': 'label'}. 

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From MUStARD   },
    breakable
    ]\small
    
The person in the video says: \{Subtitle\}. Does this statement express sarcasm? Do not provide any additional explanations or extra content. Choose one of the following labels as your final answer: true, false. 

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From SMILE   },
    breakable
    ]\small
    
The person in video says: \{Subtitle\}. Choose one of the following labels as your final answer: neutral, negative, positive. Respond in the format: {'emotion': 'label'}. 

\end{tcolorbox}

\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From CH-SIMS   },
    breakable
    ]\small
    
Reasoning task: you are to answer why the audience laughed given the video clip. The video clip from
the {Sitcom}, titled \{video title\}, with multimodal information (Utterance, Facial Action Units, Video caption,
Acoustic features(6 dimension; 1.mean of F0 contour, 2.var of F0 contour, 3. mean of energy contour, 4. var of
energy contour, 5. jitter, 6. shimmer)) is given. The audience laughing moment is marked as (audience laughing)
in certain utterance Explain why the audience laughed given the video clip, at most {40} words, starting with
'The audience laughed because '. Given video clip: \{query\}. 
\end{tcolorbox}


\clearpage
\section{Evaluation Prompt for SMILE Dataset}\label{app:evalprompt}
\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt From  Logical Judgment Dimension Evaluation Criteria for
Model-Generated Reasoning   },
    breakable
    ]\small

    You need to evaluate the quality of a model-generated reasoning for why a video audience laughed. You will be provided with two reasons for laughter reasoning:

1. The reason for laughter generated by the model.
2. The reference reason for laughter annotated manually (as a benchmark).

Please score based on the following dimension, with a maximum of 5 points:

\textbf{Logical Judgment Dimension:} Based on the reference reason, evaluate the model-generated reason in terms of logical clarity, the rationality of the causal chain, and coherence with the context.

\textbf{Scoring Criteria:}
\begin{itemize}
    \item \textbf{1 Point:} The reasoning lacks logic, with unclear or missing causal relationships, and is incoherent with the context.
    \item \textbf{2 Points:} The reasoning has some logical flaws and partial causal connections but is largely incoherent with the context.
    \item \textbf{3 Points:} The reasoning is moderately logical, with clear causal links, though some minor inconsistencies with the context exist.
    \item \textbf{4 Points:} The reasoning is mostly logical, with well-defined causal relationships and strong coherence with the context.
    \item \textbf{5 Points:} The reasoning is fully logical, with clear and rational causal chains and excellent coherence with the context.
\end{itemize}

\textbf{Input:}
\begin{itemize}
    \item Reference Reason: \texttt{<reference\_reason>}
    \item Generated Reason: \texttt{<generated\_reason>}
\end{itemize}

\textbf{Output Format:}
Please strictly follow the format below to output the scoring result, and \textbf{only output the scoring result} without adding any additional explanations or text:

\texttt{Logical Judgment Dimension: <score>}
\end{tcolorbox}

\newpage
\begin{tcolorbox}[
    colback=myblue!5!white,
    colframe=myblue!75!black,
    arc=1mm, 
    auto outer arc,
    title={Prompt from Multimodal Content Association Dimension Evaluation Criteria for Model-Generated Reasoning},
    breakable
    ]
\small

You need to evaluate the quality of a model-generated reasoning for why a video audience laughed. You will be provided with two reasons for laughter reasoning:

1. The reason for laughter generated by the model.
2. The reference reason for laughter annotated manually (as a benchmark).

Please score based on the following dimension, with a maximum of 5 points:

\textbf{Multimodal Content Association Dimension:} Based on the reference reason, evaluate whether the generated text accurately reflects the interactions between language, visual, audio, and other modal contents, especially whether these contents are consistent with the triggers for laughter.

\textbf{Scoring Criteria:}
\begin{itemize}
    \item \textbf{1 Point:} The reasoning fails to associate with multimodal content, showing no consistency with language, visual, audio, or other modalities.
    \item \textbf{2 Points:} The reasoning shows minimal association with multimodal content, with limited consistency and several mismatches.
    \item \textbf{3 Points:} The reasoning moderately reflects multimodal interactions, maintaining some consistency but with noticeable gaps.
    \item \textbf{4 Points:} The reasoning strongly associates with multimodal content, showing clear consistency with most language, visual, audio, and other modalities.
    \item \textbf{5 Points:} The reasoning perfectly captures and reflects the interactions between all relevant multimodal contents, with complete consistency with the triggers for laughter.
\end{itemize}

\textbf{Input:}
\begin{itemize}
    \item Reference Reason: \texttt{<reference\_reason>}
    \item Generated Reason: \texttt{<generated\_reason>}
\end{itemize}

\textbf{Output Format:}
Please strictly follow the format below to output the scoring result, and \textbf{only output the scoring result} without adding any additional explanations or text:

\texttt{Multimodal Content Association Dimension: <score>}

\end{tcolorbox}





