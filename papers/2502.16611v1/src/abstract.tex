\begin{abstract}
% Target speech extraction aims at extracting a certain speaker's voice from a mixture of audio from multiple speakers. In order provide information on the identity of the target speaker, prior works have explored using clean audio examples as conditions for the target speaker's identity. However, clean audio examples of the target speaker is not always available. Limited prior works have attempted to extract target speaker's characteristic from noisy audio examples, which may include multiple speakers talking symutaneously. In this work, we attempt to perform target speaker extraction when multiple speakers present in the enrollment stage by leveraging the difference between audio segments where the target speaker is speaking or not. Experiment shows that our model achieves SOTA performance in the proposed application scenario, and is robust to various challenging and realistic application scenarios.

Target speaker extraction focuses on isolating a specific speaker's voice from an audio mixture containing multiple speakers. 
To provide information about the target speaker's identity, prior works have utilized clean audio examples as conditioning inputs. 
However, such clean audio examples are not always readily available (e.g. It is impractical to obtain a clean audio example of a stranger's voice at a cocktail party without stepping away from the noisy environment). 
Limited prior research has explored extracting the target speaker's characteristics from noisy audio examples, which may include overlapping speech from disturbing speakers. 
In this work, we focus on target speaker extraction when multiple speakers are present during the enrollment stage, through leveraging differences between audio segments where the target speakers are speaking (Positive Enrollments) and segments where they are not (Negative Enrollments). 
Experiments show the effectiveness of our model architecture and the dedicated pretraining method for the proposed task. 
Our method achieves state-of-the-art performance in the proposed application settings and demonstrates strong generalizability across challenging and realistic scenarios.


% Through experiments, we design a fusion module and associated pretraining method for the proposed task. 
% Our model achieves state-of-the-art performance in the proposed application settings and shows generalizability across various challenging and realistic scenarios. 

\end{abstract}
