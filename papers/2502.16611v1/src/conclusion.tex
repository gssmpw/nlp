\section{Conclusion}

In this paper, we propose a new task for target speech extraction, where additional disturbing speakers are present throughout the audio enrollments. We optimize our model to extract the target speaker's characteristics from easily obtained noisy positive and negative enrollments, without using any clean audio enrollment input. 
We design two fusion modules and an associated training pipeline for the proposed task. Experiments show that our method achieves SOTA performance under multiple challenging and realistic application scenarios. However, further work is still required to improve the model performance when a large number of disturbing speakers are present and reduce the performance gap between our method and prior works that use clean audio enrollment as the extraction condition. 

% our . First, our model performance degrades in extracting binaural reverberation effect associated with the target speaker. Better model performance is required in order to achieve better user experience in assisting audio extraction in conversational scenario.

% Dispite showing strong performance in the proposed application scenario, there is still significant performance gap between our model using noisy enrollments and prior works that use clean target speaker enrollment. Further exploration on training method and model architecture is required to improve our model performance

% Our model performance In comparison to audio extraction models using clean target speaker enrollments, our model's performance 

% Secondly, despite the stronger generalizability shown over the baseline methods, our model's performance is still significantly worse when large number of disturbing speakers present in the scene. As shown in ???, the SI-SNR of the extracted target speaker's voice is only ??? dB when ??? disturbing speakers present in the scene. More disturbing speakers could present in a real-world application scenario. Thus, improving model performance in such challenging scenario is still required. 

% Finally, model performance drops significantly when undefined speaker present (Section ???). It would be useful if model could detect the presence of undefined speakers and request user to indicate if they wish to extract the speaker or not. This functionality could help develop a user-friendly audio extraction application. 

% We believe , and hope our experiment results could inspire follow-up works to improve audio extraction performance when disturbing speakers' voice exist in the enrollment stage. 







% Finally, model performance on speech extraction for other languages is not 

% Finally, as explained in Sectionn ???, model tends to remove the undefined speaker that does not exist in either positive or negative audio enrollments. However, the speaker might be of interest to the user (e.g. the novel speaker who wish to join the conveersation after user have obtained the positive and negative enrollments.) As a result, more exploration is required to improve the model performance under different application scenarios. 

% when extracting in challenging scenarios, 


% it is beneficial if model could also generate uncertainty value with its extraction. Through requesting user labeling at these , model might improve the extracted target speaker's embedding quality, and thus achieves better extraction performance. 