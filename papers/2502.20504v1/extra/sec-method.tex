\section{Methodology}

\subsection{Dataset Construction}
Our evaluation dataset consists of personas generated through combinations of demographic attributes. Each persona $p_i$ is characterized by attribute tuple $(a_i, g_i, o_i, l_i)$ representing:
$$
\begin{aligned}
\textbf{Age } (a_i) &: [18,65] \in \mathbb{N}\\
\textbf{Gender } (g_i) &: \mathcal{G}, |\mathcal{G}| = 2 \\
\textbf{Occupation } (o_i) &: \mathcal{O}, |\mathcal{O}| = 35\\
\textbf{Location } (l_i) &: \mathcal{L}, |\mathcal{L}| = 37
\end{aligned}
$$

\ks{can we reduce it to age into a few age brackets and occupation into a few occupation sectors and cities to be locations? Try to reduce them all to single-digit numbers.}

\jb{i used the specific numbers to show all the possible unique personas and were used as-is in the experiments; there weren't any distinct patterns across the categories, how would I determine what brackets/sectors to use?}

% For example: "{\texttt{A \textbf{52-year-old} \textbf{male} \textbf{doctor} from \textbf{Madrid}}}".
% \vspace{0.5em}

By combining these attributes, we can generate $47 \times 2 \times 35 \times 37 = 121,730$ distinct personas. For our analysis, we select a representative subset of $n=40$ personas that preserves the occupational diversity of the full dataset while maintaining demographic balance. Within this subset, we ensure diversity by preventing any overlap of both occupation and location between personas. The complete list of attributes is provided in Appendix \ref{TODO}.

Each persona is evaluated across three categories ($L$: location, $O$: occupation, $A$: age) using two evaluation sets:
$$
\begin{aligned}
Q &= \bigcup_{i \in \{L,O,A\}} Q_i,\text{ each } |Q_i| = 10 \text{ questions}\\
S &= \bigcup_{i \in \{L,O,A\}} S_i,\text{ each } |S_i| = 10 \text{ scenarios}
\end{aligned}
$$

\ks{why did we not have gender-related questions?}

\jb{i think because evaluating correct answers would've just relied on stereotypes; i tried to make questions that could be more objectively evaluated (i.e. this is clearly not have a doctor would respond, or those schools are clearly not near that location/city). i could probably not mention gender at all in the paper since we don't use it though}

\ks{No, so our persona description does contain gender so we'll have to keep it. Let's use the stereotype and refusal argument for not considering these.}

\subsection{Question Generation}
We curated two types of prompts to evaluate persona alignment: questions and scenarios. Questions were designed to probe specific knowledge across age, location, and occupation categories while enabling objective evaluation. For example, location questions assess knowledge of local customs and landmarks, while occupation questions may test domain expertise. Scenarios accomplish similar knowledge evaluation but through naturalistic situations, requiring personas to implicitly demonstrate both knowledge and behavioral consistency. \ks{need more detail here}

\subsection{Modality Representations}
\begin{enumerate}
    \item \textbf{Image:} A synthetic image generated by first converting the persona into a detailed visual description using an LLM\footnote{\texttt{gpt-4o-mini-2024-07-18}}, then rendering it with Stable Diffusion XL\footnote{\texttt{stabilityai/stable-diffusion-xl-base-1.0}} ($768 \times 768$ px, guidance scale $\gamma = 15$, steps $n = 50$).

    \item \textbf{Text:} A natural language description of the base synthetic image, generated using the following prompt template:

    \begin{quote}
    \small
    \texttt{Create a short, descriptive persona for the person in the image. Describe them using only the following details: their age, gender, facial expression or mood, attire, any tools or items they’re holding, their work environment, the nature of their job, and their connection to the area and location. Avoid taking creative liberties beyond these details, only using details that can be inferred from the image, while aiming for a realistic portrayal that gives insight into their daily life, professional dedication, and overall demeanor. For example: Meet a skilled construction worker in his late 30s, living in Sydney, Australia. Every day, he heads out to work in one of the city's bustling urban sites, often with a view of iconic landmarks like the Sydney Opera House and Sydney Harbour Bridge. Outfitted in essential safety gear—a hard hat, reflective vest, and a set of versatile tools—he’s well-prepared for a physically demanding role that demands focus and precision. His job involves a blend of construction and maintenance tasks, requiring him to pay close attention to safety protocols and collaborate with a team. Confident and professional in his work, he takes pride in contributing to the infrastructure and vibrant aesthetic of Sydney, adding to the city’s ever-evolving landscape with each project.}
    \end{quote}
    
    \item \textbf{Assisted Image:} The base synthetic image paired with the corresponding persona as text.
    
    \item \textbf{Descriptive Image:} The base synthetic image with the corresponding persona description paired visually using typography.
    
\end{enumerate}


\subsection{Evaluation Framework}
We define the subject model $\mathcal{M}: P \times \Pi \rightarrow R$ where $P$ is the set of personas, $\Pi = Q \cup S$ is the set of all prompts (questions and scenarios), and $R$ is the space of possible responses. For each response $r = \mathcal{M}(p,\pi)$, we employ an evaluator $\mathcal{J}$ that assigns scores based on different evaluation criteria from \cite{TODO}. The evaluator uses the following four task descriptions:

\begin{quote}
\small
\texttt{\textbf{Persona Consistency:} Evaluate the consistency of the response with the described persona. Ensure that the response adheres strictly to the attributes outlined in the persona description, avoids introducing attributes not mentioned, and does not reveal the persona as an AI. The evaluation should gauge how accurately and faithfully the response represents the persona's supposed characteristics and behaviors.}

\texttt{\textbf{Linguistic Habits:} The evaluation task of "linguistic habit" assesses the persona's adherence to its characteristically unique syntax, tone, and lingo, ensuring that these elements are consistently utilized throughout the persona's dialogue. This includes avoiding generic language patterns (such as "As a [persona]") and integrating specific idiomatic expressions, colloquialisms, or jargon that define the persona's distinctive verbal identity. The aim is to evaluate how effectively the persona maintains its linguistic uniqueness in various contexts.}

\texttt{\textbf{Action Justification:} Evaluate the persona's response to determine how effectively and convincingly it justifies a given action based on its described attributes and situation. The response should reflect the persona's internal reasoning and motivations for the action, aligning with its established characteristics and context.}

\texttt{\textbf{Expected Action:} The persona takes actions within its response to the question that is logically expected of the persona in the setting of the question.
}
\end{quote}

For each evaluation criterion, $\mathcal{J}(p,q,r)$ outputs a score from a 5-point Likert scale based on the corresponding system prompt.

\subsubsection{Binary Success Metrics}
We dichotomize evaluator scores using threshold $\tau = 3$ to distinguish between successful responses ($\geq 3$) and unsuccessful responses ($< 3$) for each criterion. For evaluation set $D$, we define the \textbf{pass rate} (PR) as:
\[
\text{PR} = \frac{\sum_{i=1}^{|D|} \mathbb{I}(\mathcal{J}(p_i, q_i, r_i) \geq \tau)}{|D|}
\]

\subsection{Linguistic Analysis}
Alongside the \textit{\textbf{linguistic habits}} evaluation criterion, we analyze the lexical diversity and complexity of each response $r$ using established metrics from computational linguistics:

\begin{itemize}[label={}]
    \item \textbf{Length:} $|r|$, word count
    
    \item \textbf{Types:} $|\{r\}|$, unique word count
    
    \item \textbf{Root Type-Token Ratio (RTTR):\\} \(RTTR(r) = \tfrac{\text{types}}{\sqrt{\text{length}}}\)
    , a length normalized measure of lexical variation that accounts for response length differences
    
    \item \textbf{Measure of Textual Lexical Diversity (MTLD)\footnote{Implementation details are provided in Appendix \ref{app:mtld}}:} Following McCarthy and Jarvis \cite{TODO}, calculates the mean length of text segments that maintain a TTR above threshold $\tau = 0.72$
\end{itemize}


\subsection{Comparitive Evaluation}
We implement two comparative evaluation methods to assess relative performance across modalities, detailed further in Appendix \ref{TODO}.

\subsubsection{Pairwise Comparison}
For analysis between the text and image modalities, we use a pairwise comparison approach. Given a persona, query, and responses $r_{\text{text}}, r_{\text{image}}$, an evaluator $\mathcal{J}$ directly selects the response that better aligns with the persona's style, values, and consistency.
% \[ \argmax_{m \in \{\text{text}, \text{ image}\}} \mathcal{J}(p,q,r_m) \]

\subsubsection{Swiss System Comparison}
To evaluate all four modalities collectively, we adapt the Swiss tournament system. Using the same evaluator $\mathcal{J}$ to compare alignment with persona characteristics, this approach provides a robust ranking while reducing the number of required comparisons compared to exhaustive pairwise evaluation.