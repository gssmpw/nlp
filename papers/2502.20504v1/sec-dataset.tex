\section{Modality-Parallel Persona Dataset}\label{sec:dataset}

\subsection{Personas}


% 18 to 24 · 25 to 34 · 35 to 44 · 45 to 54 · 55 to 64 · 65 or over
We introduce a novel dataset of personas $\CP = \{p_i\}$, such that each persona $p$ can be represented equivalently in four modalities $\CI, \CT, \CI_A, \CI_D$. To ensure effective representation across both text and image modalities, we construct personas based on key demographic attributes that are easily visualizable~\citep{todorov2015social}. Specifically, each persona is defined by a unique combination of age, gender, occupation, and location. A persona can thus be written as:
\begin{center}
    {\small
    A \textcolor{blue}{\texttt{<age>}}-year-old \textcolor{teal}{\texttt{<gender>}} \textcolor{brown}{\texttt{<occupation>}} \\ from \textcolor{pink}{\texttt{<location>}},}
\end{center}
where \textcolor{blue}{\texttt{<age>}} $\in [18, 64]$, \textcolor{teal}{\texttt{<gender>}} $\in \{$ male, female $\}$, \textcolor{pink}{\texttt{<location>}} is a city, and \textcolor{brown}{\texttt{<occupation>}} denotes a person who does a specific occupation. For example, ``A \textcolor{blue}{35}-year-old \textcolor{teal}{male} \textcolor{brown}{chef} from \textcolor{pink}{Paris}''. As depicted in Figure~\ref{fig:intro}, age and gender can be visualized using the face of the person while occupation and location can be visualized using the clothes and the background respectively.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pipeline.pdf}
    \caption{Our pipeline begins with curating a set of personas. Each persona receives a detailed text description, which is then fed into Stable Diffusion to generate $\mathcal{I}$. A separate model examines the image and generates an independent textual description, forming text persona $\mathcal{T}$. Pairing $p$ with $\mathcal{I}$ produces an assisted image $\mathcal{I_A}$, while combining a typographic representation of $p$ with $\mathcal{I}$ produces a descriptive image $\mathcal{I_D}$.}
    \label{fig:pipeline}
\end{figure}

\begin{table}[t]
    \centering
    \caption{\textbf{Persona Dataset Summary}}
    \label{tab:data_summary}
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{c | c | c}
        \toprule
        Attribute & Category & Number \\
        \midrule
        \multirow{5}{*}{Age} & 18-24 & 5 \\
        & 25-34 & 11 \\
        & 35-44 & 13 \\
        & 45-54 & 6 \\ 
        & 55-64 & 5 \\
        \hline
        \multirow{2}{*}{Gender} & Male & 19 \\
        & Female & 21 \\
        \hline
        \multirow{5}{*}{Occupation} & Healthcare \& Education & 9 \\
        & Public Safety &	5 \\
        & Manual Labor & 16 \\
        & Hospitality & 5 \\
        & Transportation 	& 5 \\
        \hline 
        \multirow{4}{*}{Location} & Largest Economies (GDP > \$3T) &	12 \\
        & Developed Economies (GDP \$1T-\$3T) &	13 \\
        & Mid-Sized Powers (GDP \$0.5T-\$1T) & 7 \\
        & Emerging Markets (GDP < \$0.5T) & 8 \\
        \bottomrule
    \end{tabular}}
\end{table}


To promote diversity, we systematically categorize these attributes into distinct groups and uniformly sample from each category. Table~\ref{tab:data_summary} summarizes our dataset of how we choose the age, gender, occupation, and location. In particular, we consider a standard grouping of ages followed in surveys between 18 and 65, a standard male/female splitting of gender, while occupations and locations are categorized based on their primary societal role and economic status~\footnote{\href{https://data.worldbank.org/indicator/NY.GDP.MKTP.CD}{GDP}} respectively.
% \jb{is there a cite for this?}
Table~\ref{tab:personalist} in Appendix presents the list of $40$ personas we use along with their attributes and attribute categories. 
% \ks{need to write more}

% select the values of these attributes from a large set of $47$ ages $2$ genders, $35$ occupations, and $37$ different locations, for a grand total of $121,730$ distinct personas. 
% Then, we downsample this set by categorizing the age group select a representative subset of $n=40$ personas that preserves the occupational diversity of the full dataset while maintaining demographic balance
% Our evaluation dataset consists of personas generated through combinations of demographic attributes. Each persona $p_i$ is characterized by attribute tuple $(a_i, g_i, o_i, l_i)$ representing:

% $$
% \begin{aligned}
% \textbf{Age } (a_i) &: [18,65] \in \mathbb{N}\\
% \textbf{Gender } (g_i) &: \mathcal{G}, |\mathcal{G}| = 2 \\
% \textbf{Occupation } (o_i) &: \mathcal{O}, |\mathcal{O}| = 35\\
% \textbf{Location } (l_i) &: \mathcal{L}, |\mathcal{L}| = 37
% \end{aligned}
% $$


% \ks{can we reduce it to age into a few age brackets and occupation into a few occupation sectors and cities to be locations? Try to reduce them all to single-digit numbers.}

% \jb{i used the specific numbers to show all the possible unique personas and were used as-is in the experiments; there weren't any distinct patterns across the categories, how would I determine what brackets/sectors to use?}\ks{see above}

% For example: "{\texttt{A \textbf{52-year-old} \textbf{male} \textbf{doctor} from \textbf{Madrid}}}".
% \vspace{0.5em}

% By combining these attributes, we can generate . Within this subset, we ensure diversity by preventing any overlap of both occupation and location between personas. The complete list of attributes is provided in Appendix \ref{TODO}.

\subsection{Equivalent Modality Representations}

From above, we have a diverse set of textual persona descriptions as described by the four demographic attributes. Next, we construct a modality-parallel dataset, we require that each persona $p$ can be equivalently depicted in $4$ representations $\CR(p)$: image $\CI(p)$, text $\CT(p)$, assisted image $\CI_A(p)$, and descriptive image $\CI_D(p)$. Figure~\ref{fig:pipeline} illustrates the step-by-step procedure to obtain these modality representations for a persona description $\CP$.

\begin{enumerate}[leftmargin=*, noitemsep]
    \item We first convert the persona description made from the four attributes into a more detailed visual description using an LLM\footnote{\href{https://openai.com/index/hello-gpt-4o/}{gpt-4o-mini-2024-07-18}} and the following prompt:
    \begin{quote}
    \small
    \texttt{Create a short, descriptive persona for the person in the image. Describe them using only the following details: their age, gender, facial expression or mood, attire, any tools or items they’re holding, their work environment, the nature of their job, and their connection to the area and location. Avoid taking creative liberties beyond these details, only using details that can be inferred from the image, while aiming for a realistic portrayal that gives insight into their daily life, professional dedication, and overall demeanor. For example: Meet a skilled construction worker in his late 30s, living in Sydney, Australia. Every day, he heads out to work in one of the city's bustling urban sites, often with a view of iconic landmarks like the Sydney Opera House and Sydney Harbour Bridge. Outfitted in essential safety gear—a hard hat, reflective vest, and a set of versatile tools—he’s well-prepared for a physically demanding role that demands focus and precision. His job involves a blend of construction and maintenance tasks, requiring him to pay close attention to safety protocols and collaborate with a team. Confident and professional in his work, he takes pride in contributing to the infrastructure and vibrant aesthetic of Sydney, adding to the city’s ever-evolving landscape with each project.}
    \end{quote}
    \item Next, we use a text-to-image generative model, particularly,  Stable Diffusion XL\footnote{\href{https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0}{stabilityai/stable-diffusion-xl-base-1.0}} to generate a $768 \times 768$ px image conditioned on the more complete description of the persona found above. Upon doing an extensive hyperparameter search, we found the best results with a guidance scale of $\gamma = 15$ and $n = 50$ diffusion steps. Thus, we obtain the image $\CI$.
    \item Since the generated image can contain extra information due to underspecified textual prompts, we prompt the LLM one more time to generate a complete description of the persona as described in the image using a detailed prompt as given in Appendix~\label{app:img_to_text_prompt}. Thus, we obtain the text $\CT$.
\end{enumerate}

These steps enable us to convert a dataset of persona descriptions $\{p\} \rightarrow \{(\CT(p), \CI(p))\}$ such that $\CT (p) \leftrightarrow \CI (p)$ are equivalent to each other. One can now also obtain the assisted and descriptive image representations of the persona by pairing the image $\CI$ with the text persona $p$ for the assisted image $\CI_A$, and by rendering\footnote{\href{https://pillow.readthedocs.io/en/stable/}{Pillow}} $p$ as black text at the bottom of the image on a white background using Arial font at size 20 for $\CI_D$.

\subsection{Question Generation}
To evaluate how well a model embodies a given persona, we create a set of $60$ questions that specifically probe for a given attribute either directly or in naturalistic scenarios. In particular, we create $10$ questions per attribute for the two sets. Gender was excluded from our evaluation question set due to methodological constraints. While age and location can be objectively probed through factual knowledge, gender assessment would inevitably rely on stereotypes or normative expectations. Moreover, there may be a high possibility of refusal from the LLMs due to their safety training. Thus, we obtain two question sets $Q^D$ and $Q^S$ for \textcolor{pink}{L}: location, \textcolor{brown}{O}: occupation, and \textcolor{blue}{A}: age. 
% Each persona is evaluated across three categories ($L$: location, $O$: occupation, $A$: age) using two evaluation sets:
$$
\begin{aligned}
Q^D &= \bigcup_{i \in \{\textcolor{pink}{L},\textcolor{brown}{O},\textcolor{blue}{A}\}} Q^D_i,\text{ each } |Q^D_i| = 10 \text{ questions}\\
Q^S &= \bigcup_{i \in \{\textcolor{pink}{L},\textcolor{brown}{O},\textcolor{blue}{A}\}} Q^S_i,\text{ each } |Q^S_i| = 10 \text{ scenarios}
\end{aligned}
$$
% \ks{why did we not have gender-related questions?}

% \jb{i think because evaluating correct answers would've just relied on stereotypes; i tried to make questions that could be more objectively evaluated (i.e. this is clearly not have a doctor would respond, or those schools are clearly not near that location/city). i could probably not mention gender at all in the paper since we don't use it though}\ks{this is good, let's say this then.}

% We curated two types of prompts to evaluate persona alignment: questions and scenarios. 

\subsubsection{Direct Testing}
Questions were designed to probe specific knowledge across age, location, and occupation categories while enabling objective evaluation. For example, location questions assess knowledge of local customs and landmarks, while occupation questions may test domain expertise. For example, for age, we ask ``\textit{what life experiences do you consider most defining for your generation?}'' while for location, we have ``\textit{what is the most visited tourist attraction in your area?}''. We provide the complete list in Table~\ref{tab:direct_questions_list} in Appendix. 

% \ks{write more detail}\jb{what else should I put here? i have what criteria are used in the next section. should i give an example of a scenario here (like reference a figure)?}\ks{examples, and appendix reference.}

\subsubsection{Situational Testing}
Scenarios accomplish similar knowledge evaluation but through naturalistic situations, requiring personas to implicitly demonstrate both knowledge and behavioral consistency. For example, for age scenarios, we ask ``\textit{You’re coordinating a playlist for your high school reunion after-party. The organizers want music specifically from your graduating years to recreate the atmosphere. You $\dots$}'', which is detailed in Figure \ref{fig:intro}. A complete list is provided in Table \ref{tab:direct_scenarios_list} in Appendix.
% \ks{write more detail}\jb{what else to put here?} \ks{examples and appendix reference.}


\subsection{Evaluation}

For each persona $p \in \CP$ and question $q \in \CQ^D \cup \CQ^S$, we find the response answer $a \gets \CM(\CR(p), q)$ from a multimodal LLM $\CM$, where $\CR(p)$ denotes a modality representation of the persona $\CP$. Thus, we obtain $(q, \CR(p)) \rightarrow_{\CM} (p, q, a)$. We now evaluate the quality of the response $a$ based on the question asked $q$ and the persona description $p$. 

\subsubsection{LLM-based evaluation}
% We define the subject model $\mathcal{M}: P \times \Pi \rightarrow R$ where $P$ is the set of personas, $\Pi = Q \cup S$ is the set of all prompts (questions and scenarios), and $R$ is the space of possible responses. For each response $r = \mathcal{M}(p,\pi)$, we employ an evaluator $\mathcal{J}$ that assigns scores based on different evaluation criteria taken from \citet{samuel2024personagym}. The evaluator uses the following four task descriptions:

Following \citet{samuel2024personagym}, we employ an LLM-based evaluator to judge the quality of the responses based on different metrics defined in the prompt. In particular, we prompt the LLM judge $\CJ$ with the question asked $q$, response $a$, and the persona description $p$ on these metrics as described by the corresponding prompts.

\begin{quote}
\small
\texttt{\textbf{Persona Consistency:} Evaluate the consistency of the response with the described persona. Ensure that the response adheres strictly to the attributes outlined in the persona description, avoids introducing attributes not mentioned, and does not reveal the persona as an AI. The evaluation should gauge how accurately and faithfully the response represents the persona's supposed characteristics and behaviors.}

\texttt{\textbf{Linguistic Habits:} The evaluation task of "linguistic habit" assesses the persona's adherence to its characteristically unique syntax, tone, and lingo, ensuring that these elements are consistently utilized throughout the persona's dialogue. This includes avoiding generic language patterns (such as "As a [persona]") and integrating specific idiomatic expressions, colloquialisms, or jargon that define the persona's distinctive verbal identity. The aim is to evaluate how effectively the persona maintains its linguistic uniqueness in various contexts.}

\texttt{\textbf{Action Justification:} Evaluate the persona's response to determine how effectively and convincingly it justifies a given action based on its described attributes and situation. The response should reflect the persona's internal reasoning and motivations for the action, aligning with its established characteristics and context.}

\texttt{\textbf{Expected Action:} The persona takes actions within its response to the question that is logically expected of the persona in the setting of the question.
}
\end{quote}

% \paragraph{Likert Scale} 
For each evaluation criterion, $\mathcal{J}(p,q,a)$ outputs a score from a 5-point Likert scale based on the corresponding system prompt. For situational testing, we evaluate using \texttt{action justification}, \texttt{expected action}, \texttt{linguistic habits} while for direct testing, we use \texttt{persona consistency} and \texttt{linguistic habits}. Note that we combine the scores for linguistic habits across the two testing sets to find the average score. 

% \paragraph{Binary Success Metrics}
% We dichotomize evaluator scores using threshold $\tau = 3$ to distinguish between successful responses ($\geq 3$) and unsuccessful responses ($< 3$) for each criterion. For evaluation set $D$, we define the \textbf{pass rate} (PR) as: \(\text{PR} = \tfrac{1}{|D|} \sum_{i=1}^{|D|} \mathbb{I}(\mathcal{J}(p_i, q_i, a_i) \geq \tau)\).

\subsubsection{Comparative Evaluation}
We employ two comparative evaluation methods to assess relative performance across modalities, using evaluator $\mathcal{J}$ with the prompt:
\begin{quote}
    \small
    \texttt{You are given a persona description and multiple responses to a prompt.\\ %\\[1ex]
        Persona Description: <\textit{p}>\\
        Prompt: <q>\\
        Candidate Responses: <responses>\\ %$[1ex]
        Choose the single response that best fits the persona's style, values, and consistency. Respond with 'Response X' where X is the number of the chosen response.}
\end{quote}

\paragraph{Pairwise Comparison}
To compare responses across the text and image modalities, we first directly compare responses $a_{\mathcal{T}}$ and $a_{\mathcal{I}}$.

\paragraph{Swiss System Comparison}
To collectively evaluate all four modalities, we adopt the Swiss tournament system, which reduces the number of required comparisons compared to pairwise evaluation while maintaining ranking quality. Specifically, for \( n = 4 \), pairwise evaluation requires \( \binom{4}{2} = 6 \) comparisons, whereas the Swiss system reduces to 3 comparisons.

\subsubsection{Linguistic Analysis}
Alongside the \textit{linguistic habits} evaluation criterion, we also analyze the lexical diversity, variation, and complexity of each response using established metrics from computational linguistics:
\begin{itemize}[leftmargin=*,noitemsep]    
    \item \textbf{Types:} $|\{r\}|$, unique token count.  %\vspace{0.3em}
    \item \textbf{Root Type-Token Ratio (RTTR):} \(= \nicefrac{\text{types}}{\sqrt{\text{length}}}\)
    , a normalized measure of lexical variation found by dividing the number of unique tokens with the response length~\citep{lexicalrichnesshout}. %\vspace{0.3em}
    \item \textbf{Measure of Textual Lexical Diversity (MTLD):} Following \citet{mccarthy2010mtld}, calculates the mean length of text segments that maintain a type-token ratio (TTR) $> \tau = 0.72$.
\end{itemize}

