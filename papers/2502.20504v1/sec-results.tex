\begin{table*}[t]
    \centering
    \caption{\textbf{LLM-based evaluation [1-4] of responses under different persona modality representations.}}
    \label{tab:main-results-table}
    \resizebox{0.8\textwidth}{!}{
    \begin{tabular}{lccccc}
    \toprule
     \textbf{Criterion}& \textbf{Text} & \textbf{Assisted Image} & \textbf{Image} & \textbf{Descriptive Image} \\
    \midrule
    \rowcolor{gray!25}\multicolumn{5}{c}{\textbf{GPT-4o}} \\
    \addlinespace
    \textbf{Linguistic Habits} & \textbf{2.07} $\pm$ {\scriptsize 0.02} & 1.61 $\pm$ {\scriptsize 0.02} & 1.51 $\pm$ {\scriptsize 0.02} & 1.59 $\pm$ {\scriptsize 0.02} \\
    \textbf{Persona Consistency} & 3.44 $\pm$ {\scriptsize 0.04} & 3.20 $\pm$ {\scriptsize 0.04} & 3.03 $\pm$ {\scriptsize 0.04} & \textbf{3.91} $\pm$ {\scriptsize 0.04} \\
    \textbf{Expected Action} & 3.86 $\pm$ {\scriptsize 0.03} & 3.59 $\pm$ {\scriptsize 0.03} & 3.56 $\pm$ {\scriptsize 0.03} & \textbf{3.94} $\pm$ {\scriptsize 0.03} \\
    \textbf{Action Justification} & \textbf{4.13} $\pm$ {\scriptsize 0.03} & 3.82 $\pm$ {\scriptsize 0.03} & 3.75 $\pm$ {\scriptsize 0.03} & 4.00 $\pm$ {\scriptsize 0.03} \\
    \addlinespace
    \rowcolor{gray!25}\multicolumn{5}{c}{\textbf{GPT-4o-mini}} \\
    \addlinespace
    \textbf{Linguistic Habits} & \textbf{1.81} $\pm$ {\scriptsize 0.02} & 1.61 $\pm$ {\scriptsize 0.02} & 1.48 $\pm$ {\scriptsize 0.02} & 1.63 $\pm$ {\scriptsize 0.02} \\
    \textbf{Persona Consistency} & 2.98 $\pm$ {\scriptsize 0.04} & 2.98 $\pm$ {\scriptsize 0.04} & 2.97 $\pm$ {\scriptsize 0.04} & \textbf{3.58} $\pm$ {\scriptsize 0.04} \\
    \textbf{Expected Action} & 3.25 $\pm$ {\scriptsize 0.03} & 3.29 $\pm$ {\scriptsize 0.03} & 3.19 $\pm$ {\scriptsize 0.03} & \textbf{3.59} $\pm$ {\scriptsize 0.03} \\
    \textbf{Action Justification} & \textbf{3.56} $\pm$ {\scriptsize 0.03} & 3.47 $\pm$ {\scriptsize 0.03} & 3.35 $\pm$ {\scriptsize 0.03} & 3.55 $\pm$ {\scriptsize 0.03} \\
    \addlinespace
    \rowcolor{gray!25}\multicolumn{5}{c}{\textbf{Llama 3.2 11B}} \\
    \addlinespace
    \textbf{Linguistic Habits} & \textbf{2.20} $\pm$ {\scriptsize 0.03} & 1.30 $\pm$ {\scriptsize 0.02} & 1.32 $\pm$ {\scriptsize 0.02} & 1.44 $\pm$ {\scriptsize 0.02} \\
    \textbf{Persona Consistency} & \textbf{2.79} $\pm$ {\scriptsize 0.04} & 2.16 $\pm$ {\scriptsize 0.04} & 1.90 $\pm$ {\scriptsize 0.04} & 2.55 $\pm$ {\scriptsize 0.04} \\
    \textbf{Expected Action} & \textbf{2.98} $\pm$ {\scriptsize 0.03} & 2.28 $\pm$ {\scriptsize 0.03} & 2.04 $\pm$ {\scriptsize 0.03} & 2.49 $\pm$ {\scriptsize 0.03} \\
    \textbf{Action Justification} & \textbf{3.24} $\pm$ {\scriptsize 0.03} & 2.44 $\pm$ {\scriptsize 0.03} & 2.17 $\pm$ {\scriptsize 0.03} & 2.49 $\pm$ {\scriptsize 0.03} \\
    \addlinespace
    \rowcolor{gray!25}\multicolumn{5}{c}{\textbf{Llama 3.2 90B}} \\
    \addlinespace
    \textbf{Linguistic Habits} & \textbf{2.32} $\pm$ {\scriptsize 0.03} & 1.25 $\pm$ {\scriptsize 0.04} & 1.25 $\pm$ {\scriptsize 0.05} & 1.30 $\pm$ {\scriptsize 0.05} \\
    \textbf{Persona Consistency} & \textbf{2.99} $\pm$ {\scriptsize 0.04} & 1.63 $\pm$ {\scriptsize 0.06} & 1.08 $\pm$ {\scriptsize 0.05} & 1.43 $\pm$ {\scriptsize 0.07} \\
    \textbf{Expected Action} & \textbf{3.28} $\pm$ {\scriptsize 0.03} & 1.43 $\pm$ {\scriptsize 0.04} & 1.02 $\pm$ {\scriptsize 0.03} & 1.24 $\pm$ {\scriptsize 0.04} \\
    \textbf{Action Justification} & \textbf{3.49} $\pm$ {\scriptsize 0.03} & 1.67 $\pm$ {\scriptsize 0.05} & 1.31 $\pm$ {\scriptsize 0.05} & 1.50 $\pm$ {\scriptsize 0.05} \\
    \addlinespace
    \rowcolor{gray!25}\multicolumn{5}{c}{\textbf{Pixtral 12B}} \\
    \addlinespace
    \textbf{Linguistic Habits} & \textbf{1.79} $\pm$ {\scriptsize 0.02} & 1.63 $\pm$ {\scriptsize 0.02} & 1.65 $\pm$ {\scriptsize 0.02} & 1.60 $\pm$ {\scriptsize 0.02} \\
    \textbf{Persona Consistency} & 2.38 $\pm$ {\scriptsize 0.04} & 2.33 $\pm$ {\scriptsize 0.04} & 2.77 $\pm$ {\scriptsize 0.04} & \textbf{3.59} $\pm$ {\scriptsize 0.04} \\
    \textbf{Expected Action} & 2.93 $\pm$ {\scriptsize 0.03} & 2.85 $\pm$ {\scriptsize 0.03} & 3.16 $\pm$ {\scriptsize 0.03} & \textbf{3.53} $\pm$ {\scriptsize 0.03} \\
    \textbf{Action Justification} & 3.32 $\pm$ {\scriptsize 0.03} & 3.07 $\pm$ {\scriptsize 0.03} & 3.20 $\pm$ {\scriptsize 0.03} & \textbf{3.50} $\pm$ {\scriptsize 0.03} \\
    \addlinespace
    \bottomrule
    \end{tabular}}
\end{table*}


\section{Results}\label{sec:results}


\begin{table}[t]
    \centering
    \caption{\textbf{Preference-based LLM evaluation for different persona modalities. We exclude Llama 3.2 90B due to high refusal rates (see App.~\ref{app:safety-training})}}
    \label{tab:voting-patterns}
    \resizebox{0.9\linewidth}{!}{%
    \begin{tabular}{lcc}
        \toprule
        \textbf{Modality} & \textbf{Swiss (\%)} & \textbf{Pairwise (\%)} \\
        \midrule
        \rowcolor{gray!25}
        \multicolumn{3}{c}{\textbf{GPT-4o}} \\
        \textbf{Text}              & 98.75 & 99.96 \\
        \textbf{Descriptive Image} & 1.08  & -     \\
        \textbf{Assisted Image}    & 0.12  & -     \\
        \textbf{Image}             & 0.04  & 0.04  \\
        \addlinespace
        \rowcolor{gray!25}
        \multicolumn{3}{c}{\textbf{GPT-4o-mini}} \\
        \textbf{Text}              & 99.58 & 99.92 \\
        \textbf{Descriptive Image} & 0.33  & -     \\
        \textbf{Assisted Image}    & 0.08  & -     \\
        \textbf{Image}             & 0.00  & 0.08  \\
        \addlinespace
        \rowcolor{gray!25}
        \multicolumn{3}{c}{\textbf{Llama 3.2 11B}} \\
        \textbf{Text}              & 95.50 & 97.96 \\
        \textbf{Assisted Image}    & 2.33  & -     \\
        \textbf{Descriptive Image} & 1.17  & -     \\
        \textbf{Image}             & 1.00  & 2.04  \\
        \addlinespace
        \rowcolor{gray!25}
        \multicolumn{3}{c}{\textbf{Pixtral 12B}} \\
        \textbf{Text}              & 94.17 & 99.25 \\
        \textbf{Descriptive Image} & 4.67  & -     \\
        \textbf{Assisted Image}    & 0.96  & -     \\
        \textbf{Image}             & 0.21  & 0.75  \\
        \bottomrule
    \end{tabular}
    }
\end{table}


\begin{table}[t]
    \centering
    % \small
    \caption{\textbf{Linguistic diversity evaluation of responses under different modality representations.}}
    \label{tab:ling-metrics}
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lccc}
        \toprule
        \textbf{Modality} & \textbf{RTTR} & \textbf{MTLD} & \textbf{Types} \\
        \midrule
        \rowcolor{gray!25}
        \multicolumn{4}{c}{\textbf{GPT-4o}} \\
        \addlinespace
        \textbf{Text} & \textbf{10.71} $\pm$ {\scriptsize 0.02} & \textbf{140.58} $\pm$ {\scriptsize 0.60} & \textbf{186.30} $\pm$ {\scriptsize 0.91} \\
        \textbf{Assisted Image} & 9.67 $\pm$ {\scriptsize 0.03} & 139.95 $\pm$ {\scriptsize 0.72} & 143.35 $\pm$ {\scriptsize 0.94} \\
        \textbf{Image} & 9.45 $\pm$ {\scriptsize 0.03} & 135.80 $\pm$ {\scriptsize 0.72} & 137.08 $\pm$ {\scriptsize 0.97} \\
        \textbf{Descriptive Image} & 9.54 $\pm$ {\scriptsize 0.03} & 137.16 $\pm$ {\scriptsize 0.75} & 140.97 $\pm$ {\scriptsize 0.97} \\
        \addlinespace
        \rowcolor{gray!25}
        \multicolumn{4}{c}{\textbf{GPT-4o-mini}} \\
        \addlinespace
        \textbf{Text} & \textbf{10.56} $\pm$ {\scriptsize 0.02} & 132.75 $\pm$ {\scriptsize 0.56} & \textbf{184.16} $\pm$ {\scriptsize 0.84} \\
        \textbf{Assisted Image} & 9.71 $\pm$ {\scriptsize 0.02} & \textbf{136.55} $\pm$ {\scriptsize 0.63} & 145.57 $\pm$ {\scriptsize 0.77} \\
        \textbf{Image} & 9.47 $\pm$ {\scriptsize 0.02} & 135.98 $\pm$ {\scriptsize 0.65} & 136.62 $\pm$ {\scriptsize 0.79} \\
        \textbf{Descriptive Image} & 9.53 $\pm$ {\scriptsize 0.02} & 136.05 $\pm$ {\scriptsize 0.65} & 139.14 $\pm$ {\scriptsize 0.80} \\
        \addlinespace
        \rowcolor{gray!25}
        \multicolumn{4}{c}{\textbf{Llama 3.2 11B}} \\
        \addlinespace
        \textbf{Text} & \textbf{11.92} $\pm$ {\scriptsize 0.15} & \textbf{230.43} $\pm$ {\scriptsize 10.87} & \textbf{281.43} $\pm$ {\scriptsize 9.81} \\
        \textbf{Assisted Image} & 8.89 $\pm$ {\scriptsize 0.10} & 147.45 $\pm$ {\scriptsize 7.99} & 147.38 $\pm$ {\scriptsize 7.91} \\
        \textbf{Image} & 8.53 $\pm$ {\scriptsize 0.11} & 143.55 $\pm$ {\scriptsize 9.85} & 149.28 $\pm$ {\scriptsize 11.02} \\
        \textbf{Descriptive Image} & 8.64 $\pm$ {\scriptsize 0.11} & 154.94 $\pm$ {\scriptsize 12.08} & 149.84 $\pm$ {\scriptsize 10.33} \\
        \addlinespace
        \rowcolor{gray!25}
        \multicolumn{4}{c}{\textbf{Llama 3.2 90B}} \\
        \addlinespace
        \textbf{Text} & \textbf{9.97} $\pm$ {\scriptsize 0.02} & \textbf{112.70} $\pm$ {\scriptsize 0.59} & \textbf{174.48} $\pm$ {\scriptsize 0.76} \\
        \textbf{Assisted Image} & 4.67 $\pm$ {\scriptsize 0.10} & 37.75 $\pm$ {\scriptsize 1.80} & 44.84 $\pm$ {\scriptsize 2.26} \\
        \textbf{Image} & 3.47 $\pm$ {\scriptsize 0.08} & 15.20 $\pm$ {\scriptsize 1.18} & 21.80 $\pm$ {\scriptsize 1.62} \\
        \textbf{Descriptive Image} & 3.94 $\pm$ {\scriptsize 0.10} & 24.16 $\pm$ {\scriptsize 1.49} & 32.26 $\pm$ {\scriptsize 2.92} \\
        \addlinespace
        \rowcolor{gray!25}
        \multicolumn{4}{c}{\textbf{Pixtral 12B}} \\
        \addlinespace
        \textbf{Text} & \textbf{10.45} $\pm$ {\scriptsize 0.02} & 107.08 $\pm$ {\scriptsize 0.45} & \textbf{196.91} $\pm$ {\scriptsize 0.69} \\
        \textbf{Assisted Image} & 9.35 $\pm$ {\scriptsize 0.03} & 109.47 $\pm$ {\scriptsize 0.52} & 147.19 $\pm$ {\scriptsize 1.00} \\
        \textbf{Image} & 9.04 $\pm$ {\scriptsize 0.03} & 108.01 $\pm$ {\scriptsize 0.53} & 135.20 $\pm$ {\scriptsize 1.01} \\
        \textbf{Descriptive Image} & 9.08 $\pm$ {\scriptsize 0.03} & \textbf{110.47} $\pm$ {\scriptsize 0.51} & 135.15 $\pm$ {\scriptsize 0.88} \\
        \addlinespace
        \bottomrule
    \end{tabular}}
\end{table}






\subsection{Effect of Persona Modality}


\paragraph{LLM-based Evaluation}
To evaluate the responses to persona-specific questions from multimodal LLMs, we compare the average scores generated for responses under 4 different criteria as mentioned above. Table~\ref{tab:main-results-table} shows the mean and standard deviation scores of each criterion in the Likert scale for the 4 modality representations across LLMs; numbers represent the mean between our two evaluator models. We find that text-based personas score the highest in almost all criteria in almost all models, consistently improving the linguistic habits of the persona in all models by a minimum $~0.2$ increase in the score. This shows that text is the most preferred way to represent a persona across models, highlighting the lack of understanding of the equivalent visual information. Some notable exceptions are in the persona consistency and expected action criteria where the descriptive image modality (\ie, a descriptive text is embedded within the image), shows a significantly higher rating than the text modality in GPT-4o, GPT-4o-mini, and Pixtral models. Since these criteria are oriented more toward the actions taken by the persona instead of the generated language, we believe the models are trained to specifically attend to embedded text to generate directed responses based on the text embedded within the image. We also note that the image and assisted image modalities consistently show similar and lower performance than others, showing that the assisted text fails to encode additional information that the models cannot already derive from the image. 

\noindent Next, we can also note that GPT-4o shows the highest average alignment scores across 4 criteria in each modality representation. This shows that GPT-4o is the most capable model of embodying these personas for the curated questions. In addition, despite the small size, we find that Pixtral is much better at capturing visual information than larger Llama models. On the other hand, Llama models shine when the persona is represented in text, significantly outperforming Pixtral. 

% From our results, we found a significant difference in the performance of each subject model given personas in different modalities. Personas given purely as plain text received evaluation scores significantly higher on average. This was followed by descriptive images, assisted images, and plain images. Our linguistic analysis presented a similar conclusion, with text personas performing predominantly better than personas in other modalities. Personas given in plain text consistently resulted in responses with higher lexical variation and diversity, demonstrated in the modality's higher mean RTTR, MTLD, and types. Our paired analysis revealed similar patterns. On average, our judge preferred personas given solely in the text modality over those in the image modality $99.3\%$ of the time. Similarly, when given the choice to choose any of the modality representations, our judge consistently preferred textual personas.
% \ks{discuss table 1}

\paragraph{Preference-based Evaluation}
We also leverage GPT-4o as a judge to pick and choose the most aligned response with the persona, directly comparing the 4 modalities. Table~\ref{tab:voting-patterns} shows the percentage of times that the judge picks each modality in the Swiss comparison and the pairwise (only text and image) comparison setting. We find that text-based persona responses are picked for at least $90\%$ of the questions, showing a clear preference for responses generated through text-based embodiment of these models. Furthermore, in a more direct pairwise comparison, we find that image-based personas are almost never chosen (selecting text up to $99\%$). This further strengthens our claims from above regarding the lack of capabilities of current multimodal models to embody visual personas. 

\paragraph{Linguistic Evaluation}
Next, we compare the linguistic diversity of the responses generated through different persona modalities. Table~\ref{tab:ling-metrics} shows the mean and standard deviation in the three metrics of linguistic diversity in different settings. We find that text modality is the overall preferred way to generate expressive responses of a persona. Specifically, text-based personas generate at least $\sim 40$ more types of words than the other modalities, which also show significantly more variation (at least $\sim 2$ more). We note that the Llama models are highly selective and show extremely high linguistic diversity in text modality than other modalities, as Llama-3.2-90B generates up to $150$ more types when prompted with a textual persona as compared to an image and up to $2$ times root token-type ratio.


\paragraph{Human Evaluation}

We also employ independent human annotators to judge the responses generated using different persona modalities. In particular, we use GPT-4o responses of all $4$ modality representations for $10$ randomly selected questions. Each participant is shown 10 questions with a response from one of the four modalities and is asked to judge how well the response is aligned with the persona for the given question. Table~\ref{tab:human_scores} shows the mean and standard deviation of alignment scores from this study conducted on $9$ high-quality annotators. We find that our results from LLM-based evaluators are aligned with independent human annotation, showing the highest alignment for text followed by the descriptive image modality, while assisted image and image perform similarly. We defer other survey details to Appendix~\ref{app:human}.

\begin{table}[t]
    \centering
    \caption{\textbf{Human-judged alignment scores [1-4] of GPT-4o responses from different persona modalities.}}
    \label{tab:human_scores}
    \resizebox{0.7\linewidth}{!}{
    \begin{tabular}{cccc}
    \toprule
    Text  & \textbf{3.25} $\pm$ 0.91  \\
    Descriptive Image & 2.84 $\pm$ 0.98 \\
    Assisted Image &  2.71 $\pm$ 1.19 \\
    Image & 2.75 $\pm$ 1.11 \\
    \bottomrule
    \end{tabular}}
\end{table}
    

\subsection{Analysis on confounding factors}

We analyze the effect of other factors that may confound our findings by stratifying the results of Table~\ref{tab:main-results-table} based on question type and attributes of the persona. Figure~\ref{fig:factors} shows the average scores assigned by LLM judge regardless of the persona modality for different categories. 
Except for a slight preference for ``scenario'' over direct ``questions'', we do not observe any major effect of these factors, confirming that the LLM-assigned scores are not confounded on factors such as question and persona attributes. This further emphasizes the role played by persona modality in Table~\ref{tab:main-results-table}. 

Finally, we also study if the results are confounded by biases in the evaluator itself, for which we compare the evaluator scores found using GPT-4o and Gemini-Flash. Tables~\ref{tab:eval-table-gpt-4o} and ~\ref{tab:eval-table-gemini-flash} in Appendix show that the trends of modality choice remain stable across the choice of these evaluators.

\begin{figure*}[t]
    \centering
    \hspace*{\fill}
    \subfloat[Question type]{\label{fig:question} \includegraphics[width=0.19\linewidth]{questions_PR.png}}
    \subfloat[Location]{\label{fig:location}\includegraphics[width=0.19\linewidth]{location_PR.png}} \hfill
    \subfloat[Occupation]{\label{fig:occupation}\includegraphics[width=0.19\linewidth]{occupational_PR.png}} \hfill
    \subfloat[Age]{\label{fig:age}\includegraphics[width=0.19\linewidth]{age_PR.png}} \hfill
    \subfloat[Gender]{\label{fig:occupation}\includegraphics[width=0.19\linewidth]{gender_PR.png}}
    \hspace*{\fill}
    \caption{LLM-based evaluation stratified based on question and persona types.}
    \label{fig:factors}
\end{figure*}

\iffalse
\begin{figure}[t]
    \centering
    \hspace*{\fill}
    % \subfloat[Question type]{\label{fig:question} \includegraphics[width=0.19\linewidth]{questions_PR.png}}
    \subfloat[Location]{\label{fig:location}\includegraphics[width=0.45\linewidth]{location_PR.png}} \hfill
    \subfloat[Occupation]{\label{fig:occupation}\includegraphics[width=0.45\linewidth]{occupational_PR.png}} 
    \hspace*{\fill}\\\hspace*{\fill}
    \subfloat[Age]{\label{fig:age}\includegraphics[width=0.45\linewidth]{age_PR.png}} \hfill
    \subfloat[Gender]{\label{fig:occupation}\includegraphics[width=0.45\linewidth]{gender_PR.png}}
    \hspace*{\fill}
    
    \caption{\ks{increase the dpi and reduce the figsize in your matplotlib code, finally save it as pdf with bbox\_inches$=$`tight'}}
\end{figure}
\fi

\iffalse
\begin{table}[t]
\centering
\caption{\textbf{Evaluator Agreement: Spearman and Kendall Correlations}}
\label{tab:eval-agreement}
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{lcccc}
    \toprule
    \textbf{Attribute} & Q: \textbf{Spearman $\rho$} & \textbf{Kendall $\tau$} & S: \textbf{Spearman $\rho$} & \textbf{Kendall $\tau$} \\
    \midrule
\rowcolor{gray!25}
\multicolumn{5}{c}{\textbf{GPT-4o}} \\
\textbf{Age} & 0.776 & 0.604 & 0.534 & 0.396 \\
\textbf{Location} & 0.796 & 0.607 & 0.357 & 0.244 \\
\textbf{Occupation} & 0.696 & 0.519 & 0.352 & 0.237 \\
\rowcolor{gray!25}
\multicolumn{5}{c}{\textbf{GPT-4o-mini}} \\
\textbf{Age} & 0.602 & 0.460 & 0.242 & 0.174 \\
\textbf{Location} & 0.169 & 0.112 & 0.071 & 0.041 \\
\textbf{Occupation} & 0.581 & 0.422 & 0.063 & 0.033 \\
\rowcolor{gray!25}
\multicolumn{5}{c}{\textbf{Llama 3.2 11B}} \\
\textbf{Age} & 0.207 & 0.144 & 0.373 & 0.263 \\
\textbf{Location} & 0.619 & 0.450 & 0.332 & 0.247 \\
\textbf{Occupation} & 0.194 & 0.143 & 0.492 & 0.348 \\
\rowcolor{gray!25}
\multicolumn{5}{c}{\textbf{Llama 3.2 90B}} \\
\textbf{Age} & 0.384 & 0.272 & 0.538 & 0.366 \\
\textbf{Location} & 0.628 & 0.450 & 0.422 & 0.279 \\
\textbf{Occupation} & 0.569 & 0.385 & 0.419 & 0.285 \\
\rowcolor{gray!25}
\multicolumn{5}{c}{\textbf{Pixtral 12B}} \\
\textbf{Age} & 0.581 & 0.413 & 0.683 & 0.484 \\
\textbf{Location} & 0.599 & 0.444 & 0.345 & 0.232 \\
\textbf{Occupation} & 0.593 & 0.427 & 0.252 & 0.135 \\
        \bottomrule
    \end{tabular}}
\end{table}
\fi
% \ks{simple analysis of using a different evaluator -- together or gpt-4o-mini}\jb{can we merge human evals. into this}\ks{}
