\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}

\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}


\usepackage{times}
\usepackage{lipsum} 
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{balance}
\usepackage{stfloats}

\usepackage{indentfirst}
\setlength{\parindent}{1em}

\usepackage{multirow}
\usepackage{rotating}
\usepackage{array}
\usepackage{makecell}
\usepackage{tabularx}

\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}}
\newcolumntype{Y}{>{\centering\arraybackslash}X}

\usepackage{bm}
\usepackage{amssymb}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{xcolor}
\usepackage{soul}
\usepackage{float}

% \usepackage[nodisplayskipstretch]{setspace}
% \setstretch{1.5}

\usepackage[caption=false, font=normalsize, labelfont=sf, textfont=sf]{subfig}

\newcommand{\zifan}[1]{{\color{blue}#1}}
\newcommand{\dianwei}[1]{{\color{red}#1}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\myparatight}[1]{\smallskip\noindent{\bf {#1}:}~}


\begin{document}


\setlength{\textfloatsep}{4pt}
\setlength{\intextsep}{4pt}
\setlength{\floatsep}{4pt}

% \title{Transfer, Merge, and Split Network Digital Twins in Multi-Modal Scenarios}
\title{INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language Models on Context-Aware Hazard Detection and Edge Case Evaluation\\
% INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language Models on Context-Aware Hazard Detection and Edge Case Evaluation
%{\footnotesize \textsuperscript{*}}%Note: Sub-titles are not captured in Xplore andshould not be used
\thanks{This work is supported  NDSU VPR Office project, Accelerating the Deployment of Autonomous Vehicles in Rural Areas, and National Science Foundation under Award SaTC--2350075.}
\thanks{ $\IEEEauthorrefmark{1}$ D. Chen and XT. Yang are with the College of Engineering, University of Maryland, College Park, MD 20742, USA. (Email: \{dwchen98, xtyang\}@umd.edu).
\textit{(Corresponding author: Xianfeng Terry Yang.)}}
\thanks{
 $\IEEEauthorrefmark{2}$ Z. Zhang and Y. Liu are with the Department of Computer Science, North Carolina State University, Raleigh, NC, 27695, USA (Email: \{zzhang66, yuchen.liu\}@ncsu.edu).
}
}





% \hauthor{\IEEEauthorblockN{Dianwei Chen}
% \IEEEauthorblockA{\textit{Department of Civil and} \\
% \textit{Environmental Engineering} \\
% \textit{University of Maryland}\\
% College Park, Maryland, 20742\\
% dwchen98@umd.edu}
% %\\
% \and
% \IEEEauthorblockN{Zifan Zhang}
% \IEEEauthorblockA{\textit{Department of Computer Science} \\
% \textit{North Carolina State University}\\
% Raleigh, NC, 27695\\
% zzhang66@ncsu.edu}
% \and
% \IEEEauthorblockN{} 
% \IEEEauthorblockA{\textit{Department of Civil and  } \\
% \textit{Environmental Engineering} \\
% \textit{University of Maryland}\\%  College Park, Maryland, 20742\\
% dwchen98@umd.edu}
% %\\
% \and
% \IEEEauthorblockN{}
% \IEEEauthorblockA{\textit{Department of Civil and  } \\
% \textit{Environmental Engineering} \\
% \textit{University of Maryland}\\
%  College Park, Maryland, 20742\\
% dwchen98@umd.edu}
% }


\author{
		\IEEEauthorblockN{Dianwei Chen $\IEEEauthorrefmark{1}$,
		Zifan Zhang $\IEEEauthorrefmark{2}$,
            Yuchen Liu $\IEEEauthorrefmark{2}$,
            Xianfeng Terry Yang $\IEEEauthorrefmark{1}$
 }
		% \IEEEauthorblockA{
		% $\IEEEauthorrefmark{1}$University of Maryland,
		% $\IEEEauthorrefmark{2}$North Carolina State University, USA
		% }
	}
\maketitle
\maketitle
\begin{abstract}
Autonomous driving systems face significant challenges in handling unpredictable edge-case scenarios, such as adversarial pedestrian movements, dangerous vehicle maneuvers, and sudden environmental changes. Current end-to-end driving models struggle with generalization to these rare events due to limitations in traditional detection and prediction approaches. To address this, we propose INSIGHT (Integration of Semantic and Visual Inputs for Generalized Hazard Tracking), a hierarchical vision-language model (VLM) framework designed to enhance hazard detection and edge-case evaluation. By using multimodal data fusion, our approach integrates semantic and visual representations, enabling precise interpretation of driving scenarios and accurate forecasting of potential dangers. Through supervised fine-tuning of VLMs, we optimize spatial hazard localization using attention-based mechanisms and coordinate regression techniques. Experimental results on the BDD100K dataset demonstrate a substantial improvement in hazard prediction straightforwardness and accuracy over existing models, achieving a notable increase in generalization performance. This advancement enhances the robustness and safety of autonomous driving systems, ensuring improved situational awareness and potential decision-making in complex real-world scenarios.


\end{abstract}

\vspace{+0.1cm}
\begin{IEEEkeywords}
Vision-language model, autonomous driving, edge driving cases, hazard detection
\end{IEEEkeywords}

\input{sec/intro}
\input{sec/related}
\input{sec/method}
\input{sec/exp}
\input{sec/conclusion}

% \newpage

% \balance

\bibliographystyle{IEEEtran}
\bibliography{main}


\end{document}
