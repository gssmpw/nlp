\section{Results and Discussion}

\subsection{	Analysis of Translated Answers in AmaSQuAD}

Figures \ref{fig:training} and \ref{fig:development} show the similarity distribution results on a scale from 0 to 1 of translated answers with the translated context span for AmaSQuAD. The frequency sharply drops in the range of 0 to 0.4, implying a rare occurrence of translated answers within minimal similarity in this range. The frequency distribution indicates that a substantial number of translations fall within the similarity range of 0.4 to 1.0, peaking at 0.9 to 1.0. As the similarity increases, the frequencies mostly rise, peaking at 23,144 and 5314 occurrences in the range of 0.9 to 1.0 for the training and development dataset, respectively. This indicates more accurate translations closely aligned with the original context in the translated context that have high similarity ranges.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{training_similarity_distribution.png}
    \caption{Distribution of Similarity on a scale from 0 to 1 of translated answers with the translated context span for the AmaSQuAD training set}
    \label{fig:training}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{development_similarity_distribution.png}
    \caption{Distribution of Similarity on a scale from 0 to 1 of translated answers with the translated context span for the AmaSQuAD development set}
    \label{fig:development}
\end{figure}

Various adjustments of weights \( w_1 \) and \( w_2 \) for cosine similarity and LCS should be considered for Algorithm 1. Tuning these parameters involves a tradeoff between focusing on the semantic and syntactic similarities between translated answers and their corresponding context spans. Additionally, incorporating human feedback on the quality of the translated AmaSQuAD dataset is essential. Human evaluations can provide valuable insights into areas where the algorithm may falter or produce inaccurate results, allowing for targeted improvements to be made.

\begin{table*}[h!]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Aspect}           & \textbf{Before Fine-Tuning} & \textbf{After Fine-Tuning} & \textbf{Performance Increase} \\ \hline
\textbf{Dataset}          & AmaSQuAD (Synthetic)       & AmaSQuAD (Synthetic)       &                                \\ \hline
\textbf{Exact Match (EM)} & 36.55\%                    & 44.41\%                    & \textbf{+7.86\%}              \\ \hline
\textbf{F1-Score}         & 50.01\%                    & 57.55\%                    & \textbf{+7.54\%}              \\ \hline
\textbf{Dataset}          & AmQA (Human-Curated)       & AmQA (Human-Curated)       &                                \\ \hline
\textbf{Exact Match (EM)} & 52.50\%                    & 52.66\%                    & \textbf{+0.16\%}              \\ \hline
\textbf{F1-Score}         & 67.80\%                    & 68.80\%                    & \textbf{+1.00\%}              \\ \hline
\end{tabular}
\vspace{1mm}  % Adds 5mm of space between the table and the caption
\caption{Performance Comparison of XLM-R Before and After Fine-Tuning}
\label{tab:performance_comparison}
\end{table*}



\subsection{Performance Analysis of XLM-R on AmaSQuAD and AmQA}
The evaluation presented in Table 1 demonstrates the improvement in the performance of the fine-tuned XLM-R model on both synthetic and human-curated datasets, namely AmaSQuAD and AmQA, respectively. Initially, without fine-tuning, the model achieved low scores on both datasets. However, after fine-tuning on AmaSQuAD synthetic data, there was a notable increase in performance. Specifically, the Exact Match and F1-score increased from 36.55 to 44.41 percent and from 50.01 to 57.55 percent, respectively, on the AmaSQuAD development data. Similarly, on the AmQA dataset, the Exact Match improved from 52.50 to 52.66 percent, and the F1 score increased from 67.80 to 68.80 percent post-training. This suggests that leveraging synthetic data for fine-tuning can indeed augment the model's ability to reason and answer questions effectively without compromising performance, as evidenced by the slight increase in the F1-score on the human-curated AmQA dataset.

Unlike the baseline model set by \cite{abedissa2019amharic}, which lacks clarity regarding the percentage of training, validation, and test data used for fine-tuning and evaluation of the XLM-R model, this study is the first to establish a detailed baseline performance using the AmQA dataset, which contributes to the literature on question answering in underrepresented languages. The hypothesis that fine-tuning with synthetic data would improve the model's performance on both synthetic and human-curated datasets is partially proven. While there was an improvement in performance on both datasets, the extent of improvement was relatively small on the AmQA data. Additionally, it's essential to acknowledge the weaknesses of the AmQA dataset, such as the absence of unanswerable questions, which limits its representativeness of real-world scenarios.

The absence of unanswerable questions in the AmQA dataset is a notable limitation, as real-world scenarios often involve questions for which no explicit answer exists in the provided context, which means that the performance assessment done on the AmQA dataset only assessed the performance of the model on answerable questions. Moreover, the dataset size of 2,628 is relatively small, which could impact the generalizability of the findings. 

Therefore, future model evaluation should incorporate human-curated datasets with a more diverse range of question types to provide a more comprehensive assessment of the model's capabilities in real-world settings. Additionally, to further advance the state-of-the-art in question answering for underrepresented languages like Amharic, it is imperative to explore the impact of pre-training on a large Amharic corpus with various pre-training strategies, as presented in \cite{liu2019roberta}. Incorporating such pre-training techniques has been shown to enhance a model's understanding and performance on downstream tasks like question answering. Addressing these limitations would be crucial for future research to further advance the state-of-the-art in question answering.
