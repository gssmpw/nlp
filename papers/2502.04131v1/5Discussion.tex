\section{Discussion}\label{sec:discussion}

% SI analysis as one-time overhead
Structural identifiability is a property of a given dynamical model and \mjc{generically dependent on which model states are measured.}
\pt{However, given a fixed set of state variables based on which the observations are obtained, structural identifiability itself is not related to the given data whatsoever.}
It follows that using \myMethod{} boils down to a one-time computational overhead associated with \eco{performing} a SI analysis.
Beyond this, no additional computation is required, which is of course desirable.

% Large-data limit
It was observed that the \myMethod{} approach is most effective for relatively small amounts of training data. 
This is because \myMethod{} removes redundancies in the space of the original model parameters and thus makes the decision boundary in the space of identifiable parameter combinations simpler (cf. \autoref{fig:toy_model_decision_boundary}).
As the amount of available data increases, the effect of \myMethod{} is diminished since the additional data now suffice to resolve the class-membership distribution in the space of the original parameters. 
This means that \myMethod{} has a regularizing effect on the classifier training and is particularly useful whenever there are relatively few data available, which can be common in biomedical applications. 

% On PINNs 
Considering the great successes achieved by Deep Learning in recent years, it would be a natural idea to also employ Deep Learning for time series analysis and classification.
However, with \mjc{the} large number of weights to be trained, deep networks have a tendency to over-fit and effective regularization becomes a strict necessity when working in the small-data regime. 
Recently, Physics-informed Neural Networks (PINN) have been introduced which regularize the training process by the incorporation of any physical laws in the form of ODEs and/or partial differential equations (PDE) \cite{raissi2019pinn}.
In this context, PINN can also be used for parameter estimation for ODEs (as a special case of PDEs).
However, if a PINN were to be set up incorporating an ODE with unidentifiable parameters, \mjc{then any form} of parameter estimation would again become meaningless.
A thorough Structural Identifiability analysis of the underlying dynamical model is therefore strongly recommended when employing a PINN for parameter estimation.

% On interpretability
\eco{In any situation involving high-stakes decision making, including the biomedical domain,} interpretability is of critical importance.
A recent review, \eco{in which} 9 state-of-the-art deep learning methods for time series classification \eco{are compared}, found that only 2 out of the 9 methods studied address the issue of interpreting the decision taken by the neural network~\cite{ismail2019deep}.
Using \myMethod{}, even though a given classifier is trained on data in the space of identifiable parameter combinations, the learned decision boundary can be recovered in the space of the original model parameters.
This makes the learned decision boundary interpretable for domain experts and increases trust in the trained model.
Another example in which insight is generated from an unidentifiable model in a similar manner can be found in Bunte~et~al.~\cite{bunte2018learning}. 
\myMethod{} not only improves classification performance but also preserves interpretability of the model-based approach.

% Limitations
There are a number of limitations to be considered when applying the \myMethod{} approach.
\eco{For one}, the extent to which the existence of \pt{non-trivial output-equivalent manifolds of models} actually hampers classification performance is hard to predict a priori.
Depending on the optimization scheme employed to maximize the log-likelihood function, and depending on the dynamical system \mjc{in question}, performance degradation may be more or less severe, making the effectiveness of \myMethod{} situation-dependent.
Moreover, in \cite{shen2017classification}, the authors point out that working with point estimates (like MAP) to represent time series data in the parameter space of a given dynamical model comes with inherent difficulties because such estimates do not quantify the uncertainty for models \textit{around} these estimates.
As an alternative, the authors propose a fully Bayesian approach and represent each time series observation as a posterior distribution over the entire model parameter space. 

% Future work
When representing time series observations as full posterior distributions, Structural Identifiability analysis can come in handy once more.
If a given dynamical model is structurally unidentifiable, the likelihood function used to build the posterior will be ridged.
We intend to explore this insight for posterior sampling in future work.
