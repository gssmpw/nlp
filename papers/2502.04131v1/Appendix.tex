% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)

\section{Possible Reparametrisation of Example Models}\label{app:repar}

\subsection{FISPO reparametrisation of CCM2 using AutoRepar}
Using AutoRepar, the catenary compartment model with $n=2$ and without input, i.e.
\begin{align}
    \begin{split}
        \dot{\mathbf{x}}(t) &= K\mathbf{x}(t)\\
        \mathbf{y}(t) &= x_{1}(t),
    \end{split}
\end{align}
where $\mathbf{b} = [1,0]^{\top}$, $\mathbf{x} = [x_{1},x_{2}]^{\top}$ with $\mathbf{x}(0) =  [1,0]^{\top}$, and 
\begin{equation}
K = \begin{bmatrix}
        -(k_{01}+k_{21}) & k_{12} \\
        k_{21} & -(k_{02}+k_{12}) 
    \end{bmatrix},
\end{equation}
can be reparametrised to give
\begin{align*}
    \dot{\tilde{x}}_{1} &= -(\tilde{k}_{01} + \tilde{k}_{21}) \tilde{x}_{1} + \tilde{x}_{2}\\
    \dot{\tilde{x}}_{2} &= \tilde{k}_{21} x_{1} + 2 \tilde{x}_{2}, \\
    y &= \tilde{x}_{1},
\end{align*}
using the transformations
\begin{align*}
    \tilde{x}_{1} &= x_{1}, \\
    \tilde{x}_{2} &= (-2 + k_{02} + k_{12}) x_{1} + k_{12} x_{2}, \\
    \tilde{k}_{01} &= 2 - k_{12} + k_{01} (-1 + k_{02} + k_{12}) \\
    &+ k_{02} (-1 + k_{21}) - k_{21}, \\
    \tilde{k}_{21} &= -k_{01} (-2 + k_{02} + k_{12}) - k_{02} (-2 + k_{21}) \\
    &+ 2 (-2 + k_{12} + k_{21}).
\end{align*}
Note that AutoRepar suggests transformations which make a given model Fully-Input-State-Parameter-Observable (FISPO). In this case the reparametrised version of the CCM2 model ends up having 2 parameters ($\tilde{k}_{01}$ and $\tilde{k}_{21}$), even though, using the Laplace transform approach, we determined 3 structurally identifiable parameter combinations. This is because the Laplace transform approach \emph{does} not account for the observability of the state $x_{2}$ whereas AutoRepar FISPO approach requires.

\subsection{Reparametrisation of CCM2 using COMBOS}
An alternative reparametrisation of the CCM2 model as found in \cite{meshkat2014COMBOS} is given by 
\begin{align*}
    \dot{\tilde{x}}_{1} &= -(-\Phi_{1} - \Phi_{3}) \tilde{x}_{1} - \Phi_{3} \tilde{x}_{1} + \tilde{x}_{2} \\
    \dot{\tilde{x}}_{2} &= \Phi_{3} \tilde{x}_{1} - (-\Phi_{2} - 1) \tilde{x}_{2} - \tilde{x}_{2},
\end{align*}
where
\begin{align*}
    \tilde{x}_{1} &= x_{1} \\
    \tilde{x}_{2} &= k_{12} x_{2}, \\
    \Phi_{1} &= -(k_{01} + k_{21}), \\
    \Phi_{2} &= -(k_{02} + k_{12}), \\
    \Phi_{3} &= k_{12} k_{21}.
\end{align*}
In this case, the reparametrisation is based on rewriting the original model equations in terms of 3 identifiable parameter combinations. The parameters of the resulting model are identifiable but the model is not FISPO since the state $\tilde{x}_{2}$ is not observable (determined using STRIKE GOLDD).

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/Results/Exp1_CCM2.pdf}
    \caption{Experiment 1 with partially observed CCM2 model.}
    \label{fig:exp1_CCM2}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/Results/Exp1_CCM4.pdf}
    \caption{Experiment 1 with partially observed CCM4 model.}
    \label{fig:exp1_CCM4}
\end{figure}

\section{Identifiability Analysis for the CML}\label{app:SIA_CML}
Employing the Laplace transform approach on the CML, the following structurally identifiable parameter combinations have been determined:
\begingroup
\allowdisplaybreaks
\begin{align*}
    % \begin{split}
      \tilde{\Phi}_{1} = & k_{04} k_{12} k_{23} + k_{12} k_{23} k_{34} + k_{04} k_{23} k_{42} + k_{04} k_{12} k_{43} +\\
               &k_{03} (k_{04} + k_{34}) (k_{12} + k_{42}) + k_{04} k_{42} k_{43} +  \\
               &k_{02} (k_{23} k_{34} + k_{03} (k_{04} + k_{34}) + k_{04} (k_{23} + k_{43})), \\
      % \Phi_{1} = & k_{04} k_{12} k_{23} + k_{12} k_{23} k_{34} + k_{04} k_{23} k_{42} +\\
      %          &k_{03} (k_{04} + k_{34}) (k_{12} + k_{42}) + k_{04} k_{12} k_{43} + \\
      %          &k_{04} k_{42} k_{43} + k_{02} (k_{23} k_{34} + k_{03} (k_{04} +\\
      %          &k_{34}) + k_{04} (k_{23} + k_{43})), \\
      \tilde{\Phi}_{2} = & k_{04} k_{12} + k_{04} k_{23} + k_{12} k_{23} + k_{12} k_{34} + k_{23} k_{34} +\\
               & k_{04} k_{42} + k_{23} k_{42} + k_{34} k_{42} +\\
               & k_{03} (k_{04} + k_{12} + k_{34} + k_{42}) + k_{04} k_{43} + k_{12} k_{43} +\\
               & k_{42} k_{43} + k_{02} (k_{03} + k_{04}+ k_{23} + k_{34} + k_{43}), +\\
      \tilde{\Phi}_{3} = & k_{02} + k_{03} + k_{04} + k_{12} + k_{23} + k_{34} + k_{42} + k_{43},\\
      \tilde{\Phi}_{4} = & k_{21} (k_{02} k_{23} k_{34} + k_{02} k_{03} (k_{04} + k_{34}) +\\
               & k_{03} (k_{04} + k_{34}) k_{42} + k_{02} k_{04} (k_{23} + \kb{k}_{43}) +\\
               & k_{04} k_{42} (k_{23} + k_{43})) + k_{01} (k_{04} k_{12} k_{23} +\\
               & k_{12} k_{23} k_{34} + k_{04} k_{23} k_{42} + k_{03} (k_{04} +\\
               & k_{34}) (k_{12} + k_{42}) + k_{04} k_{12} k_{43} + k_{04} k_{42} k_{43} +\\
               & k_{02} (k_{23} k_{34} + k_{03} (k_{04} + k_{34}) k_{04} (k_{23} + k_{43}))), \\
      \tilde{\Phi}_{5} = & k_{03} k_{04} k_{12} + k_{03} k_{04} k_{21} + k_{04} k_{12} k_{23} %\\& 
                 + k_{04} k_{21} k_{23} + \\%\\& 
                 & k_{03} k_{12} k_{34} + k_{03} k_{21} k_{34} %\\&
                 + k_{12} k_{23} k_{34} + k_{21} k_{23} k_{34} + \\
                 & k_{03} k_{04} k_{42} %\\&
                 + k_{03} k_{21} k_{42} + k_{04} k_{21} k_{42} + k_{04} k_{23} k_{42} +\\
               & k_{21} k_{23} k_{42} + k_{03} k_{34} k_{42} + k_{21} k_{34} k_{42} %\\&
               + k_{04} k_{12} k_{43} + \\
               & k_{04} k_{21} k_{43} + k_{04} k_{42} k_{43} %\\&
               + k_{21} k_{42} k_{43} + k_{02} (k_{21} k_{23} + \\
               & k_{21} k_{34} + k_{23} k_{34} + %\\& 
               k_{03} (k_{04} + k_{21} + k_{34}) + k_{21} k_{43} + \\
               & k_{04} (k_{21} + k_{23} + k_{43})) %\\&
               + k_{01} (k_{04} k_{12} + k_{04} k_{23} + \\
               & k_{12} k_{23} + k_{12} k_{34} + k_{23} k_{34} + %\\& 
               k_{04} k_{42} + k_{23} k_{42} + \\
               & k_{34} k_{42} + k_{03} (k_{04} + k_{12} + k_{34} + k_{42}) %\\&
               + k_{04} k_{43} + \\
               & k_{12} k_{43} + k_{42} k_{43} %\\&
               + k_{02} (k_{03} + k_{04} + k_{23} + k_{34} + k_{43})), \\
      \tilde{\Phi}_{6} = & k_{03} k_{04} + k_{03} k_{12} + k_{04} k_{12} + k_{03} k_{21} + k_{04} k_{21} +\\
               & k_{04} k_{23} + k_{12} k_{23} + k_{21} k_{23} + k_{03} k_{34} + k_{12} k_{34} +\\
               & k_{21} k_{34} + k_{23} k_{34} + k_{03} k_{42} + k_{04} k_{42} + k_{21} k_{42} +\\
               & k_{23} k_{42} + k_{34} k_{42} + k_{04} k_{43} + k_{12} k_{43} + k_{21} k_{43} +\\
               & k_{42} k_{43} + k_{02} (k_{03} + k_{04} + k_{21} + k_{23} + k_{34} + k_{43}) +\\
               & k_{01} (k_{02} + k_{03} + k_{04} + k_{12} + k_{23} + k_{34} + k_{42} + k_{43}), \\
      \tilde{\Phi}_{7} = & k_{01} + k_{02} + k_{03} + k_{04} + k_{12} + k_{21} \\
               & + k_{23} + k_{34} + k_{42} + k_{43}.
%\stepcounter{equation}\tag{\theequation}               
%\label{eq:SI_relations_CML}    
    % \end{split}
\end{align*}
\endgroup
Independent investigation using the Lie symmetry approach gave the simpler, yet equivalent, set of identifiable parameter combinations reported in Eq.~\eqref{eq:CML_SI} which were subsequently also used for experimentation.
A \textit{Wolfram Mathematica} script containing the corresponding analysis can be found on the authors' Github page. 

\section{Classification with a Support Vector Machine} \label{app:classification}
For the Support Vector Machine, the response to an input $x$ is modelled as
$$f(x) = \beta T(x) + b$$
where $\beta$ is a $p$-dimensional vector containing the weights to be determined, $b$ is a scalar bias term and $T(x)$ is implicitly determined via the choice of kernel function $K(\cdot, \cdot)$ and the relationship $K(x_{1},x_{2}) = T(x_{1}) \cdot T(x_{2})$. 
The Support Vector Machine is implemented with the MATLAB \texttt{fitcsvm} function. 
Default settings apply except for the \texttt{KernelFunction} setting, which is set to \texttt{gaussian} and the \texttt{Standardize} setting which is set to \texttt{true}.
Further, the default settings notably imply that: 1) the training employs Sequential Minimal Optimization, and 2) in the case of inseparable classes, slack variables $\xi_{j}$ are introduced and the objective becomes the minimization of 
$$\frac{1}{2} ||\beta||^2 + C \sum_{j=1}^{n}\xi$$
with respect to $\beta, b$ and $\xi_{j}$ subject to 
$$y_{j}f(x_{j}) \geq 1 - \xi_{j}, \quad \xi_{j} \geq 0. $$
The optimal settings for \texttt{BoxConstraint} and \texttt{KernelScale} are determined using a grid-search and 10-fold cross-validation to estimate out-of-sample performance.
Further information on the default settings of the MATLAB \texttt{fitcsvm} function can be found on the MATLAB \texttt{fitcsvm} documentation page.

\section{Additional experimental outcomes}\label{app:add_exp_outcomes}
This appendix contains the experimental outcomes for the toy model, CCM2, CCM4, CML.
\autoref{fig:exp1_CCM2} through to \autoref{fig:exp1_CML} contain the results of experiment 1.
\autoref{fig:exp2_toy} through to \autoref{fig:exp2_CML} contain the results of experiment 2.
\autoref{fig:exp3_toy} through to \autoref{fig:exp3_CML} contain the results of experiment 3.
Note that the fully observed toy model is inherently unidentifiable and therefore experiment 1 has not been carried out for this model.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/Results/Exp1_CML.pdf}
    \caption{Experiment 1 with partially observed CML model.}
    \label{fig:exp1_CML}
\end{figure}

% -------------------------------------------------------------------

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/Results/Exp2_toy_model.pdf}
    \caption{Experiment 2 with toy model.}
     \label{fig:exp2_toy}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/Results/Exp2_CCM2.pdf}
    \caption{Experiment 2 with partially observed CCM2 model.}
    \label{fig:exp2_CCM2}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/Results/Exp2_CCM4.pdf}
    \caption{Experiment 2 with partially observed CCM4 model.}
    \label{fig:exp2_CCM4}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/Results/Exp2_CML.pdf}
    \caption{Experiment 2 with partially observed CML model.}
    \label{fig:exp2_CML}
\end{figure}

 % -------------------------------------------------------------------

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{Figures/Results/Exp3_toy_model.pdf}
    \caption{Experiment 3 with toy model.}
    \label{fig:exp3_toy}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{Figures/Results/Exp3_CCM2.pdf}
    \caption{Experiment 3 with partially observed CCM2 model.}
    \label{fig:exp3_CCM2}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{Figures/Results/Exp3_CCM4.pdf}
    \caption{Experiment 3 with partially observed CCM4 model.}
    \label{fig:exp3_CCM4}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{Figures/Results/Exp3_CML.pdf}
    \caption{Experiment 3 with partially observed CML model.}
    \label{fig:exp3_CML}
\end{figure*}

% \begin{table*}[t!]
%     \centering
%     \caption{Ground truth parameter configurations and experimental conditions for binary classification tasks for the different models.}
%     \begin{tabular}{c|c}
%         \textbf{Model} & \textbf{Parameters} \\
%         \hline
%         \multirow{5}{1cm}{toy}   & $N_{\text{train}} = 100, N_{\text{test}} = 200, $ \\
%                                  & $\boldsymbol{\mu}_{0} = (a,b) = (1,1)$ \\ 
%                                  & $\boldsymbol{\mu}_{1} = (a,b) = 0.9 \cdot (1,1)$ \\ 
%                                  & $\Sigma_{0} = \Sigma_{1} = 10^{-4} I_{2}$ \\
%                                  & $t_{\text{dense}} = 0,0.1, 0.2,\ldots, 0.9, 1$ \\
%         \hline
%         \multirow{5}{1cm}{CCM2}  & $N_{\text{train}} = 100, N_{\text{test}} = 200, $ \\
%                                  & $\boldsymbol{\mu}_{0} = (k_{01}, k_{02}, k_{12}, k_{21}) = (0.015,0.01472335,0.0740155,0.01)$ \\ 
%                                  & $\boldsymbol{\mu}_{1} = (k_{01}, k_{02}, k_{12}, k_{21}) = (0.015,0.01472335,0.0592124,0.008)$ \\
%                                  & $\Sigma_{0} = \Sigma_{1} = 10^{-7} I_{4}$ \\
%                                  & $t_{\text{dense}} = 0, 10, 20,\ldots, 230, 240$ \\
%         \hline
%         \multirow{7}{1cm}{CCM4}  & $N_{\text{train}} = 800, N_{\text{test}} = 1000, $ \\
%                                  & $\boldsymbol{\mu}_{0} = (k_{01}, k_{02}, k_{03}, k_{04}, k_{12}, k_{23}, k_{34}, k_{21}, k_{32}, k_{43})$ \\
%                                  & $=(0.015,0.01472335,0.015,0.01472335,0.0740155,0.01,0.0740155,0.01,0.0740155,0.01)$ \\ 
%                                  & $\boldsymbol{\mu}_{1} = (k_{01}, k_{02}, k_{03}, k_{04}, k_{12}, k_{23}, k_{34}, k_{21}, k_{32}, k_{43})$ \\ 
%                                  & $=(0.015,0.01472335,0.015,0.01472335,0.03700775,0.005,0.03700775,0.005,0.03700775,0.005)$ \\ 
%                                  & $\Sigma_{0} = \Sigma_{1} = 10^{-7} I_{10}$ \\
%                                  & $t_{\text{dense}} = 0, 10, 20,\ldots, 230, 240$ \\
%         \hline
%         \multirow{1}{1cm}{CML}  & identical to the parameters of the CCM4 model \\
%         \hline
%         \multirow{2}{1cm}{BR}  & $N_{\text{train}} = 200, N_{\text{test}} = 400, $ \\
%                                  & $\boldsymbol{\mu}_{0} = (b_{1}, b_{2}, \mu_{m}, K_{s}, Y, K_{d}) = (1.25,30,0.5,3,0.6,0.05)$ \\ 
%                                  & $\boldsymbol{\mu}_{1} = (b_{1}, b_{2}, \mu_{m}, K_{s}, Y, K_{d}) = (1.25,30,0.5,3,0.48,0.05)$ \\ 
%                                  & $\Sigma_{0} = \Sigma_{1} = \text{diag}(10^{-2}, 1, 10^{-4}, 10^{-2}, 10^{-4}, 10^{-6})$ \\
%                                  & $t_{\text{dense}} = 0, 1, 2,\ldots, 11, 12$ \\
%     \end{tabular}
%     \label{tab:gt_parameters}
% \end{table*}
