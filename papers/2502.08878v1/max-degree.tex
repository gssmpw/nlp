\subsection{\ouralgo{}: Maximum Adaptive Degree Weighting}

\begin{algorithm}[ht]
\caption{\userweights{}$(S_u, b, \bmin, \bmax)$
\newline{\bf Input: }
 User set $S_u \subseteq \U$,
 biases $b: \U \to [0,1]$,
 minimum bias $\bmin \in [0.5,1]$, maximum bias $\bmax \in [1,\infty]$
 \newline  {\bf Output: } $w_b: S_u \to \mathbb{R}$ weighting of the items
}
\begin{algorithmic}[1]
\label{alg:user-biased}
\STATE Initialize weight vector $w_b$ with zeros
\STATE $S_{biased} = \{i \in S_u: b(i) < 1\}$
\STATE $S_{unbiased} = S_u \setminus S_{biased}$
\STATE $w_b(i) \gets \frac{\max\{\bmin, b(i)\}}{\sqrt{|S_u|}}$ for $i \in S_{biased}$
\COMMENT{Set biased weights, respecting min bias}
\STATE $w_b(i) \gets \min\bc{\frac{\bmax}{\sqrt{|S_u|}}, \sqrt{\frac{1-\sum_{i \in S_{biased}} w_b(i)^2}{|S_{unbiased}|}}}$ for $i \in S_{unbiased}$
\COMMENT{Allocate remaining $\ell_2$ budget, respecting max bias}
\WHILE{$\sum_{i \in S_u} w_b(i)^2 < 1$}
    \STATE $S_{small} \gets \bc{i \in S_u : w_b(i) < \frac{1}{\sqrt{|S_u|}}}$
    \STATE $C \gets \min\bc{
    \frac{\bmax/\sqrt{|S_u|}}{\max_{i \in S_{small}} w_b(i)},
    \sqrt{1 + \frac{1 - \sum_{i \in S_u} w_b(i)^2}{\sum_{i \in S_{small}} w_b(i)^2}}}$
    \STATE $w_b(i) \gets C \cdot w_b(i)$ for $i \in S_{small}$
    \COMMENT{Increase small weights  using remaining $\ell_2$ budget, respecting max bias}
\ENDWHILE
\RETURN $w_b$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ht]
% \footnotesize
\caption{\ouralgo$(\sets, \tau, \dmax, b, \bmin, \bmax)$
 \newline{\bf Input: }
 User sets $\sets = \{(u, S_u)\}_{u \in [n]}$,
 adaptive threshold $\tau \geq 0$,
 maximum adaptive degree $\dmax > 1$,
 biases $b: \U \to \mathbb{R}$,
 minimum bias $\bmin \in [0.5,1]$, maximum bias $\bmax \in [1,\infty]$
 \newline  {\bf Output: } $w: \U \to \mathbb{R}$ weighting of the items
}
\begin{algorithmic}[1]
\label{alg:max-deg}
\STATE Initialize weight vectors $w, w_{init}, w_{trunc}, w_{reroute}$ with zeros.
\STATE Set reroute discount factor $\alpha = \bmin - \frac{1}{2\sqrt{\dmax}}$.
\STATE $I_{adapt} = \{u \in [n]: \ceil{\frac{1}{(\bmin)^2}} \leq |S_u| \leq \dmax\}$ \COMMENT{Only users with certain degrees act adaptively.}
\FORALL{$u \in I_{adapt}$}
    \STATE $w_{init}(i) \pluseq 1/|S_u| \qquad \forall i \in S_u$ \COMMENT{Initial $\ell_1$ sensitivity bounded weights.}
\ENDFOR
\STATE $r(i) \gets \min\left\{0, \frac{w_{init}(i) - \tau}{w_{init}(i)}\right\}$ for $i \in \U$ \COMMENT{Fraction of weight that exceeds the threshold.}
\STATE 
\STATE $w_{trunc}(i) \gets \min\{w_{init}(i), \tau\}$ for $i \in \U$  \COMMENT{Truncate weights above threshold.}
\FORALL{$u \in I_{adapt}$}
    \STATE $e_u \gets \left(1/|S_u|\right) \sum_{i \in S_u} r(i)$ \COMMENT{Excess weight returns to each user proportional to their contribution.}
    \STATE $w_{reroute}(i) \pluseq \alpha e_u / d_{max}$ for $i \in S_u$ \COMMENT{Reroute excess to items, discounted by $\alpha/\dmax$.}
\ENDFOR
\STATE $w \gets w_{trunc} + w_{reroute}$ \COMMENT{Total $\ell_1$ bounded adaptive weights.}
\STATE $w_b^u \gets \userweights{}(S_u, b, \bmin, \bmax)  \quad \forall u \in [n]$ \COMMENT{See \cref{alg:user-biased}.}
\FORALL{$u \in I_{adapt}$}
    \STATE $w(i) \pluseq w_b^u(i) - 1/|S_u|$ for $i \in S_u$ \COMMENT{Add $\ell_2$ bounded weight and subtract initial weights.}
\ENDFOR
\FORALL{$u \in [n] \setminus I_{adapt}$}
    \STATE $w(i) \pluseq w_b^u(i)$ for $i \in S_u$ \COMMENT{Add $\ell_2$ bounded weight for non-adaptive items.}
\ENDFOR
\RETURN $w$
\end{algorithmic}
\end{algorithm}

Our main result is an \emph{adaptive} weighting algorithm \ouralgolong{} (\ouralgo{}) which is amenable to parallel implementations and has the exact same $\ell_2$ and novel $\ell_\infty$ sensitivities as \basicalgo{}. Therefore, within the weight and threshold meta-algorithm, both algorithms utilize the same noise $\sigma$ and threshold $\rho$ to maintain privacy.
Our algorithm improves upon \basicalgo{} by reallocating weight from items far above the threshold to other items.

We present the full algorithm in \cref{alg:max-deg} with an important subroutine in \cref{alg:user-biased}.
For simplicity, we will first describe the ``unbiased''  version of our algorithm where $b, \bmin, \bmax$ are set to ones and $\userweights{}(S_u, b, \bmin, \bmax)$ is a vector of weights over all items with $\nicefrac{1}{\sqrt{|S_u|}}$ for every $i \in S_u$ and zeros in other coordinates.
The algorithm takes two additional parameters: a maximum adaptive degree $\dmax \in (1, \Delta_0]$ and an adaptive threshold $\tau = \rho + \beta \sigma$ for a free parameter $\beta \geq 0$. Users with set cardinalities greater than $\dmax$ are set aside and contribute basic uniform weights to their items at the end of the algorithm. The rest of the users participate in adaptive reweighting. We start from a uniform weighting where each user sends $\nicefrac{1}{|S_u|}$ weight to each of their items. Items have their weights truncated to $\tau$ and any excess weight is sent back to the users proportional to the amount they contributed. Users then reroute a carefully chosen fraction (depending on $\dmax$) of this excess weight across their items. Finally, each user adds $\nicefrac{1}{\sqrt{|S_u|}} - \nicefrac{1}{|S_u|}$ to the weight of each of their items. 

Each of these stages requires linear work in the size of the input, i.e. the sum of the sizes of the users sets.
Furthermore, each stage is straightforward to implement within a parallel framework. As there are a constant number of stages, the algorithm can be implemented with total linear work and constant number of rounds.

\subsection{\ouralgotworounds{}: Biased Weights in Multiple Rounds}

\begin{algorithm}[ht]
\caption{\ouralgotworounds{}$(\sets, (\eps_1, \delta_1), (\eps_2, \delta_2), \Delta_0, \dmax, \beta, C_{lb}, C_{ub}, \bmin, \bmax)$
 \newline  {\bf Input: } User sets $\sets=\{(u, S_u)\}_{u\in [n]}$,
 privacy parameters $(\eps_1, \delta_1)$ and $(\eps_2, \delta_2)$,
 degree cap $\Delta_0$,
 maximum adaptive degree $\dmax$,
 adaptive threshold excess parameter $\beta$,
 lower bound constant $C_{lb}$,
 upper bound constant $C_{ub}$,
 minimum bias $\bmin$,
 maximum bias $\bmax$
 \newline  {\bf Output: } Subset of the union of user sets $\U = \cup_{u=1}^n S_u$
}
\begin{algorithmic}[1]
\label{alg:max-deg-two-round}
\STATE For $u \in [n]$, cap $S_u$ to at most $\Delta_0$ items by random subsampling
\STATE Select $\sigma_r$ corresponding to the Gaussian Mechanism (\cref{prop:gaussian}) for $(\eps_r, \delta_r/2)$-DP with $\Delta_2 = 1$ for $r \in \{1,2\}$.
\STATE \textbf{Round 1}
\STATE Set threshold $\rho_1 = \max_{t \in [\Delta_0]} \frac{1}{\sqrt{t}} + \sigma_1 \Phi^{-1}\left(\left(1 - \frac{\delta}{2}\right)^{1/t}\right)$
\STATE $w_1 \gets \ouralgo(\sets, \rho_1 + \beta \sigma_1, \dmax, \overrightarrow{1}, 1, 1)$ \COMMENT{Compute \ouralgo{} (\cref{alg:max-deg}) weights in the first round.}
\STATE $\tilde{w_1} \gets w_1 + \mathcal{N}(0, \sigma_1^2 I)$ \COMMENT{Add noise}
\STATE $U_1 \gets \{i \in \U : \tilde{w}_1(i) \geq \rho_1\}$ \COMMENT{Apply threshold}
\STATE \textbf{Round 2}
\STATE Set threshold $\rho_2 = \max_{t \in [\Delta_0]} \frac{\bmax}{\sqrt{t}} + \sigma_2 \Phi^{-1}\left(\left(1 - \frac{\delta}{2}\right)^{1/t}\right)$
\STATE $\tilde{w}_{lb} \gets \max\bc{0, \tilde{w}_1 - C_{lb} \cdot \sigma_1}$
\COMMENT{Weight lower bound from Round 1}
\STATE $\tilde{w}_{ub} \gets \tilde{w}_1 + C_{ub} \cdot \sigma_1$
\COMMENT{Weight upper bound from Round 1}
\STATE $U_{low} \gets \bc{i \in \U: \tilde{w}_{ub} < \rho_2}$
\STATE $S_u \gets S_u \setminus \p{U_1 \cup U_{low}}$ for $u \in [n]$
\COMMENT{Remove items found in Round 1 or with a small upper bound on the weight}
\STATE $b \gets \min\bc{1, \frac{\rho_2}{\tilde{w}_{lb}}}$
\COMMENT{Bias weights to not overshoot threshold}
\STATE $w_2 \gets \ouralgo{}(\sets, \rho_2 + \beta \sigma_2, \dmax, b, \bmin, \bmax)$
\COMMENT{Compute \ouralgo{} (\cref{alg:max-deg}) in the second round}
\STATE $\tilde{w}_2 \gets w_2 + \mathcal{N}(0, \sigma_2^2 I)$ \COMMENT{Add noise}
\STATE $U_2 \gets \{i \in \U : \tilde{w}_2(i) \geq \rho_2\}$ \COMMENT{Apply threshold}
\RETURN $U_1 \cup U_2$
\end{algorithmic}
\end{algorithm}

This unbiased version of \ouralgo{} directly improves on the basic algorithm.
We further optimize our algorithm by refining an idea from the prior work of DP-SIPS~\cite{swanberg2023dpsips}.
In that work, the privacy budget is split across multiple rounds with \basicalgo{} used in each round.
In each round, items found in previous rounds are removed from the users' sets, so that in early rounds, easy-to-output (loosely speaking, high frequency) items are output, with more weight being allocated to harder-to-output items in future rounds.
The privacy of this approach follows from post-processing: we can freely use the differentially private output $U$ from early rounds to remove items in later rounds.

We propose \ouralgotworoundslong{} (\ouralgotworounds{}) which as a starting point runs \ouralgo{} in two rounds, splitting the privacy budget as in DP-SIPS. As \ouralgo{} stochastically dominates \basicalgo{}, this provides a drop-in improvement.
Our key insight comes from the modified meta-algorithm we present in \cref{sec:meta-algo} which also outputs the vector of noisy weights $\tilde{w}_{ext}$.
As long as the \weightalgo{} maintains bounded sensitivity, we are free to query the noisy weights from prior rounds when constructing weights in future rounds.

We leverage this by running in two rounds with the full pseudocode given in \cref{alg:max-deg-two-round}.
In the first round, we run the unbiased version of \ouralgo{} described above to produce outputs $U_1 = U$ as well as query access to $\tilde{w}_{ext}$.
We will only ever query items in $\U$, so we algorithmically maintain $\tilde{w}_1$ which is $\tilde{w}_{ext}$ restricted to $\U$ without ever materializing $\tilde{w}_{ext}$. Importantly though, we never release $\tilde{w}_1$ as a final output of our algorithm.

In the second round, we make three preprocessing steps before running \ouralgo{}. Let $\sigma_1$ be the standard deviation of the noise in the first round and $\rho_2$ be the threshold in the second round. For parameters $C_{lb}, C_{ub} \geq 0$, Let $\tilde{w}_{lb} = \tilde{w}_1 - C_{lb} \cdot \sigma_1$ and $\tilde{w}_{ub} = \tilde{w}_1 + C_{ub} \cdot \sigma_1$ be lower and upper confidence bounds on the true item weights $w_1$ in the first round, respectively.
\begin{enumerate}[label=(\alph*)]
    \item (DP-SIPS) We remove items from users' sets which belong to $U_1$.
    \item (Ours) We remove items $i$ from users' sets which have weight significantly below the threshold where $\tilde{w}_{ub}(i) < \rho_2$. If $\tilde{w}_{ub}(i)$ is very small, we have little chance of outputting the item in the second round and would rather not waste weight on those items. This is particularly relevant for long-tailed distributions we often see in practice where there are many elements which appear in only one or a few users' sets.
    \item (Ours) For items with $\tilde{w}_{lb} \geq \rho_2$, we assign these items biases $b(i) = \nicefrac{\rho_2}{\tilde{w}_{lb}}(i)$. Via \userweights{} (\cref{alg:user-biased}), we (loosely) try to have each user contribute a $b(i)$ fraction of their normal $\nicefrac{1}{\sqrt{|S_u|}}$ weight while increasing the weights on unbiased items.
    As the lower bound on these item weights is very large, we do not need to spend as much of our $\ell_2$ budget on these items.
    For technical reasons, in order to preserve the overall sensitivity of \ouralgo{}, we must enforce minimum and maximum bias parameters $\bmin \in [0.5, 1]$ and $\bmax \in [1, \infty)$.
    The weights returned by \userweights{} are in the interval $\br{\nicefrac{\bmin}{\sqrt{|S_u|}}, \nicefrac{\bmax}{\sqrt{|S_u}}}$ and have an $\ell_2$ norm of 1.
\end{enumerate}