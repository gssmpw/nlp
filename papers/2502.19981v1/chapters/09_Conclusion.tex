\section{Conclusion}

Our study shows that LLMs, regardless of their numeric tokenization strategy, rely on a simple one-digit lookahead heuristic for anticipating carries when performing addition tasks. While this strategy is fairly effective for two-operand additions, it fails in the multi-operand additions due to the increasingly unpredictable value of cascading carry bits. Through probing experiments and targeted evaluations of digit-wise result accuracy, we demonstrate that model accuracy deteriorates precisely at the rate the heuristic predicts. 

These findings highlight an inherent weakness in current LLMs that prevents them from robustly generalizing to more complex arithmetic tasks. 

Our work contributes to a broader understanding of LLM limitations in arithmetic reasoning and highlights increasing LLMs' lookahead as a promising approach to enhancing their ability to handle complex numerical tasks.