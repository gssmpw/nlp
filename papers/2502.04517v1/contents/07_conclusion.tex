%!TEX root=icml2025.tex

We have discussed the current limitations of RGTG, particularly, reward models that are not suitable for tokenwise generation. Current reward models incur a significant decoding cost which makes RGTG less viable. Moreover we showed that they may prefer prefixes that lead to sub-optimal completions. We introduced FaRMA, a cost effective reward model which leads to faster inference and is trained with a more principled constraint leading to better outcomes. 





