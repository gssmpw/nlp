\section{Consequences for confidence estimation and calibration} \label{sec:calibration}


% In the deep learning literature, the \emph{confidence} of a classifier often refers to the probability of the correctness of a prediction, i.e., the probability that predicted label matches the true label \cite{?} The most common way to transform a logit into the predicted probability of each class is softmax function, or equivalently, sigmoid function in binary classification.

Recall the definition of confidence of the max-margin classifier $\hat p(\xx) := \sigma ( \hat f(\xx) ) = 
        \sigma( \< \xx, \hat\vbeta \> + \hat\beta_0 )$ in \cref{subsec:conf_calib}.
% \begin{defn}[Confidence]
%     For any classifier of the form $\hat y(\xx) = 2 \mathbbm{1}\{ f(\vx) > 0\} - 1$,
%     % linear classifier $f(\xx) = \< \xx, \bbeta \> + \beta_0$, 
%     define $p: \R^d \to [0, 1]$ as the \emph{confidence} of $f$, which is the sigmoid transformation of $f(\xx)$: 
%     \begin{equation*}
%         p(\xx) :=  \sigma\bigl( f(\xx) \bigr),
%         \qquad \text{where} ~ \sigma(t) := \frac{1}{1 + e^{-t}}.
%     \end{equation*}
% \end{defn}
Note that $\hat p(\xx)$ and $1 - \hat p(\xx)$ are the predicted probabilities of $\xx$ for the minority class ($y = +1$) and the majority class ($y = -1$) respectively. 

It is worth noticing that the confidence is sensitive to scales, i.e., $\sigma(t) \not= \sigma(ct)$ if $c \not= 1$, despite the fact that rescaling yields the same label prediction and thus does not affect accuracy. While small models tend to be calibrated, especially when parameter estimation is consistent, larger models such as DNNs are known to suffer from poor calibration \cite{guo2017calibration}. A simple theoretical explanation is that in a DNN, the last layer (usually a logistic regression) $\xx \mapsto \sigma\bigl( \< \xx, \hat\bbeta \> + \hat\beta_0 \bigr)$ trained by gradient descent on separable features often results in a very large $\| \hat\vbeta\|_2$ (as mentioned in \cref{subsec:LR_vs_SVM}), thereby inflating the predicted probabilities. Here we focus on the common form of SVM \eqref{eq:SVM-0} where normalization $\| \hat\vbeta \|_2 = 1$ is applied.
%Sometimes $( p(\xx), 1 - p(\xx) )$ also refers to confidence in a multi-class setting. \ljy{However, the confidence is NOT scale invariant, i.e., $\sigma(t) \not= \sigma(ct)$ if $c \not= 1$. It means even if the two classifiers based on $f_1(\vx)$ and $f_2(\vx) := c f_1(\vx)$ give the same prediction, the confidence of $f_1$ and $f_2$ are different. This partially explains why many deep neural networks are over-confident, since the last layer (usually a logistic regression) $\xx \mapsto \sigma\bigl( \< \xx, \hat\bbeta \> + \hat\beta_0 \bigr)$ trained by gradient descent on separable embeddings often results in a very large $\| \hat\vbeta\|_2$ (as mentioned in \cref{subsec:LR_vs_SVM}). In this section, we will focus on the the confidence of margin-rebalanced SVM \cref{eq:SVM-m-reb}, which fixes $\| \hat\vbeta \|_2 = 1$ on separable data.} 

Some probabilities regarding the confidence are as follows.

\begin{enumerate}
    \item \textbf{Max-margin confidence.}
    The confidence of the max-margin classifier is
    \begin{equation*}
        \hat p(\xx) := \sigma\bigl( \hat f(\xx) \bigr) = 
        \sigma\bigl( \< \xx, \hat\vbeta \> + \hat\beta_0 \bigr).
    \end{equation*}
    
    \item \textbf{Bayes optimal probability.}
    The true conditional probability is
    \begin{equation*}
        \begin{aligned}
            p^*(\xx) := \P( y = 1 \,|\, \xx ).
        \end{aligned}
    \end{equation*}
    
    \item \textbf{True posterior probability.} The probability conditioning on max-margin confidence is
    \begin{equation*}
        \begin{aligned}
            \hat p_0(\xx) := \P \bigl( y = 1 \,|\, \hat p(\xx) \bigr).
        \end{aligned}
    \end{equation*}
\end{enumerate}
Note that $p^*(\xx)$ is the confidence of the Bayes classifier $y^*(\xx) := 2\ind\{  \< \xx, 2\bmu \> + \log\frac{\pi}{1 - \pi} > 0 \} - 1$.

% We would like the confidence $\hat p$ to be a good approximation of the true conditional probability (Bayes optimal probability), that is
% \begin{equation}\label{eq:cal_strong}
%     \hat p(\xx) \approx p^*(\xx) = \P( y = 1 \,|\, \xx ).
% \end{equation}
% However, the Bayes optimal probability is usually intractable in black-box deep learning settings, and estimating this probability conditioned on the high dimensional $\xx$ can be difficult. The notion of \emph{calibration} is therefore widely used in literature, which captures the intuition of \cref{eq:cal_strong} in a weaker sense. In particular, the confidence $\hat p$ is (approximately) \emph{calibrated} if
% \begin{equation}\label{eq:cal_weak}
%     \hat p(\xx) \approx \hat p_0(\xx) = \P \bigl( y = 1 \,|\,  \hat p(\xx) \bigr).
% \end{equation}
% Motivated by these intuitions, some well-known miscalibration metrics are listed below \cite{kumar2019verified, kuleshov2015calibrated}:
Recall the definition of calibration \cref{eq:calibrated} and some miscalibration metrics \cref{eq:CalErr}---\eqref{eq:ConfErr} introduced in \cref{subsec:conf_calib}. We offer some further explanations for them.
\begin{itemize}
    \item \textbf{Calibration error:} The $\cL^2$ distance between confidence and posteriori, which is the most commonly used metric.
    \begin{equation*}
    % \begin{aligned}
    %     \mathrm{CalErr}(\hat p) & :=  \E\left[ \bigl( \hat p(\xx) - \hat p_0(\xx) \bigr)^2 \right]  = \E\left[ \Bigl(  
    %     \hat p(\xx) - \P \bigl( y = 1 \,|\,  \hat p(\xx) \bigr)
    %     \Bigr)^2 \right]
    %     \\
    %     & \phantom{:}=  \E\left[ \Bigl(
    %     \P\bigl( y \hat f(\xx) > 0 \,\big|\, \hat p(\xx) \bigr) - \max \bigl\{ \hat p(\xx), 1 - \hat p(\xx) \bigr\}
    %     \Bigr)^2 \right].
    % \end{aligned}
    \mathrm{CalErr}(\hat p) :=  \E\left[ \bigl( \hat p(\xx) - \hat p_0(\xx) \bigr)^2 \right]
    \end{equation*}

    \item \textbf{Mean squared error (MSE):} Also known as the Brier score, subject to a calibration budget \cite{brier1950verification, gneiting2007probabilistic}.
    \begin{equation*}
        \mathrm{MSE}(\hat p)  := \E\left[ \bigl( \mathbbm{1}\{ y = 1 \} - \hat p(\xx) \bigr)^2 \right]
    \end{equation*}
    It can be shown that MSE has the following decomposition
    % \begin{equation*}
    %     \begin{aligned}
    %     \mathrm{MSE}(\hat p) 
    %     & = \var\, \bigl[\mathbbm{1}\{ y = 1 \} \bigr]
    %     + \E\left[ \bigl( \hat p(\xx) - \hat p_0(\xx) \bigr)^2 \right] - \var\left[ \P\bigl( y = 1 \,\big|\, \hat p(\xx) \bigr) \right]
    %     \\
    %     & = \underbrace{ \var\, \bigl[\mathbbm{1}\{ y = 1 \} \bigr] }_{\text{irreducible}}  
    %     + 
    %     \underbrace{ \vphantom{\bigl[} \mathrm{CalErr}(\hat p) }_{\text{lack of calibration}}
    %     - 
    %     \underbrace{\var\, \bigl[ \hat p_0(\xx) \bigr]}_{\text{sharpness/resolution}}
    %     .
    %     \end{aligned}
    % \end{equation*}
    \begin{equation*}
        \mathrm{MSE}(\hat p) 
        \ = \ \underbrace{ \var\, \bigl[\mathbbm{1}\{ y = 1 \} \bigr] }_{\text{irreducible}}  
        + 
        \underbrace{ \vphantom{\bigl[} \mathrm{CalErr}(\hat p) }_{\text{lack of calibration}}
        - 
        \underbrace{\var\, \bigl[ \hat p_0(\xx) \bigr]}_{\text{sharpness/resolution}}
        .
    \end{equation*}
    Calibration error itself does not guarantee a useful predictor. Sharpness, also known as resolution \cite{murphy1973new, kuleshov2015calibrated}, is another desired property which measures the variance in the response $y$ explained by the probabilistic prediction $\hat p(\xx)$. Hence, a small MSE suggests a classifier to be calibrated with high sharpness. 
    
    Note that $\var[\mathbbm{1}\{ y = 1 \}] = \pi(1 - \pi)$ is an intrinsic quantity unrelated to $\hat f$. When study the effect of $\pi$ on model calibration, we may discard the irreducible variance term and define a modified MSE as
    \begin{equation*}
        \mathrm{mMSE}(\hat p) := \mathrm{CalErr}(\hat p) - \var \bigl[ \hat p_0(\xx) \bigr].
    \end{equation*}
    \item \textbf{Confidence estimation error:} The $\cL^2$ distance between confidence and Bayes optimum.
    \begin{equation*}
        \mathrm{ConfErr}(\hat p) :=  \E\left[ \bigl( \hat p(\xx) - p^*(\xx) \bigr)^2 \right]
        % = \E\left[ \bigl( \hat p(\xx) - \P( y = 1 \,|\, \xx ) \bigr)^2 \right]
        .
    \end{equation*}
    It has the following relation with MSE:
    % \begin{equation*}
    %     \begin{aligned}
    %     \mathrm{MSE}(\hat p) 
    %     & =  
    %     \E\left[ \bigl( \mathbbm{1}\{ y = 1 \} - p^*(\xx) \bigr)^2 \right]
    %     + \E\left[ \bigl( \hat p(\xx) - p^*(\xx) \bigr)^2 \right]
    %     \\
    %     & =
    %     \E \, \Bigl[ \var\, \bigl[\mathbbm{1}\{ y = 1 \} \,|\, \xx \bigr] \Bigr]
    %     + \mathrm{ConfErr}(\hat p)
    %     \\
    %     & = 
    %     \E \, \Bigl[ p^*(\xx) \bigl( 1 - p^*(\xx) \bigr) \Bigr]
    %     + \mathrm{ConfErr}(\hat p),
    %     \end{aligned}
    % \end{equation*}
    \begin{equation}
    \label{eq:MSE_vs_ConfErr}
        \mathrm{MSE}(\hat p) 
        =
        \E \left[ p^*(\xx) \bigl( 1 - p^*(\xx) \bigr) \right]
        + \mathrm{ConfErr}(\hat p),
    \end{equation}
    where the first term is intrinsic, which only depends on $\pi$ and $\norm{\bmu}_2$. 
    
    % \ljycom{This metric is less used in deep learning literature since conditioning on high-dimensional $\xx$ is often intractable. However, the definition of confidence estimation error is closer to the original purpose of confidence quantification/calibration.}
\end{itemize}

The asymptotics of these metrics, and some monotone effect of model parameters $\pi \in (0, 1/2)$, $\norm{\bmu}_2$, $\delta$ on them, are summarized in the following proposition.

\begin{prop}[Confidence estimation and calibration]\label{prop:conf}
    Consider 2-GMM and the proportional settings in \cref{sec:logit_SVM} on linearly separable dataset ($\delta < \delta^*(0)$).
    \begin{enumerate}[label=(\alph*)]
        \item \label{prop:conf_asymp}
        Let $(\rho^*, \beta_0^*)$ be defined as per \cref{thm:SVM_main}, and $(Y, G) \sim P_y \times \normal(0,1)$. Denote
        \begin{equation*}
            \begin{aligned}
                \mathrm{MSE}^*  
                & :=  \E \left[ \sigma \bigl( -\rho^* \norm{\bmu}_2 - \beta_0^* Y + G \bigr)^2 \right],
                \qquad
                \mathrm{mMSE}^* = \mathrm{MSE}^* - \pi(1 - \pi),
                \\
                \mathrm{CalErr}^*
                & :=  \E\left[ \left( \sigma\Bigl( 2\rho^* \norm{\bmu}_2 (\rho^* \norm{\bmu}_2 Y + G) + \log\frac{\pi}{1-\pi} \Bigr) - \sigma\bigl( \rho^* \norm{\bmu}_2 Y + G + \beta_0^* \bigr) \right)^2 \right], 
                \\
                V_{y|\xx}^*
                & :=  \E\left[ \sigma\Bigl( -2\norm{\bmu}_2( \norm{\bmu}_2 + G ) - \log\frac{\pi}{1-\pi} Y \Bigr)^2 \right],
                \qquad
                \mathrm{ConfErr}^* = \mathrm{MSE}^* - V_{y|\xx}^*.
            \end{aligned}
        \end{equation*}
        then
        \begin{equation*}
        \begin{aligned}
            \lim_{n \to \infty} \mathrm{MSE}(\hat p) = \mathrm{MSE}^*,
            \qquad
            & \lim_{n \to \infty} \mathrm{CalErr}(\hat p) = \mathrm{CalErr}^*, 
            \\
            \lim_{n \to \infty} \mathrm{mMSE}(\hat p) = \mathrm{mMSE}^*,
            \qquad
            & \lim_{n \to \infty} \mathrm{ConfErr}(\hat p) = \mathrm{ConfErr}^*.
        \end{aligned}
        \end{equation*}
        
        \item \label{prop:conf_mono}
        When $\tau = \tau^\mathrm{opt} > 0$, 
        \begin{itemize}
            \item $\mathrm{MSE}^*$ and $\mathrm{mMSE}^*$ are decreasing functions of $\pi \in (0, \frac12)$, $\norm{\bmu}_2$, $\delta$.
            % \item $\mathrm{CalErr}^*$ is decreasing in $\norm{\bmu}_2$ and $\delta$, for any $\pi < \overline{\pi} \approx 0.2$ fixed.
            % \ljycom{Based on the ``fact'' that both
            % \begin{align*}
            %     h_1(t) & = \E\left[ \Bigl( \sigma\bigl( 2 t (G+t) + c_+ \bigr) - \sigma( G+t ) \Bigr)^2 \right]
            %     \\
            %     h_2(t) & = \E\left[ \Bigl( \sigma\bigl( 2 t (G-t) + c_- \bigr) - \sigma( G-t ) \Bigr)^2 \right]
            % \end{align*}
            % are monotone decreasing when $c_\pm < 0$ are small enough. It seems difficult to prove, but can be veried numerically. 
            % }
            \item $\mathrm{ConfErr}^*$ is decreasing in $\delta$.
            
            % \ljycom{
            % For monotonicity in $\pi$, it suffices to show that
            % \begin{equation*}
            %     V_{y|\xx}^* = \E\left[ \sigma\Bigl( -2\norm{\bmu}_2( \norm{\bmu}_2 + G ) - \log\frac{\pi}{1-\pi} Y \Bigr)^2 \right] = \E \, \Bigl[ p^*(\xx) \bigl( 1 - p^*(\xx) \bigr) \Bigr]
            % \end{equation*}
            % is monotone increasing in $\pi \in (0, \frac12)$ (for any $\norm{\bmu}_2$ fixed).
            % }
        \end{itemize}
    \end{enumerate}
\end{prop}
In addition, there are some monotone relationships that can be verified numerically. We summarized them in the following claim.
\begin{claim}\label{claim:conf}
    Consider the same settings as \cref{prop:conf}. When $\tau = \tau^\mathrm{opt} > 0$, we have
    \begin{itemize}
            \item $\mathrm{CalErr}^*$ is decreasing in $\norm{\bmu}_2$ and $\delta$, for any $\pi \le \overline{\pi}$ fixed, where $\overline{\pi} \approx 0.25$ is some constant.
            \item $\mathrm{ConfErr}^*$ is decreasing in $\pi \in (0, \frac12)$.
        \end{itemize}
\end{claim}