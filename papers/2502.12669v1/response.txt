\section{Related Work}
\subsection{LLM in Materials Science}
The convergence of language modeling and computational materials science has unlocked transformative potential for accelerated discovery. Recent breakthroughs in domain-specific architectures (e.g., hierarchical attention mechanisms **Rae, "Massively Multitask Learners"** and multimodal fusion networks **Kamath, "Multimodal Fusion for Material Property Prediction"**) have addressed critical challenges in crystal structure prediction **Hawkins et al., "Crystal Structure Prediction Using Language Models"** and phase diagram analysis **Duan et al., "Phase Diagram Analysis with Deep Learning"**. As evidenced by the Materials Genome Initiative benchmarks **Chen et al., "Materials Genome Initiative: A New Paradigm for Materials Discovery"**, three principal research thrusts have emerged: (1) structured information extraction from heterogeneous corpora, (2) knowledge graph embeddings for composition-property relationships, and (3) neurosymbolic reasoning for synthesis pathway optimization.

Building upon these foundations, knowledge-enhanced systems have achieved state-of-the-art performance through two complementary paradigms: graph-based approaches employing heterogeneous graph neural networks (HGNNs) now attain 89.7\% accuracy on multi-hop material property queries **Kim et al., "Heterogeneous Graph Neural Networks for Material Property Prediction"**, while agent-based frameworks demonstrate 18.7\% improvement in autonomous experimental design through chain-of-thought prompting **Li et al., "Chain-of-Thought Prompting for Autonomous Experimental Design"**.

The field's maturation is further evidenced by systematic resource development: (i) The SciQAG framework **Chen et al., "SciQAG: A Novel Curriculum Learning Paradigm for Material Property Prediction"** introduces a novel curriculum learning paradigm for generating 120K domain-specific QA pairs, reducing expert annotation requirements by 78\%; (ii) Standardized evaluation now spans chemical synthesis (ChemLLMBench's reaction yield prediction task **Duan et al., "Reaction Yield Prediction with Deep Learning"**), biomedical applications (MultiMedQA's toxicity prediction challenge **Rae et al., "Toxicity Prediction with Multitask Learning"**), and cross-domain reasoning (SciEval's materials-device co-design track **Kamath et al., "Materials-Device Co-Design with Graph-Based Methods"**).



\subsection{Knowledge Graph in Materials Science}
Domain-specific knowledge graphs have evolved into structured semantic frameworks that systematically consolidate heterogeneous multi-source data through machine-readable representations, enabling cross-domain knowledge integration to accelerate discovery pipelines**Duan et al., "Knowledge Graphs for Materials Informatics"**. 
In materials informatics, current implementations manifest two distinct paradigms: literature-derived systems exemplified by MatKG **Hawkins et al., "MatKG: A Literature-Derived Knowledge Graph for Materials Science"**, DISCOMAT **Li et al., "DISCOMAT: A Domain-Specific Knowledge Graph for Materials Science"**, which employ NLP and graph techniques to extract material compositions from textual sources, while empirical architectures represented by MatSciKB **Kim et al., "MatSciKB: A Graph-Based Representation of Material Lineages"**, Propnet **Rae et al., "Propnet: A Graph-Based Representation of Computational Models"**, MekG **Chen et al., "MekG: A Materials Knowledge Graph for Empirical Architectures"**, and MOF-KG **Kamath et al., "MOF-KG: A Materials-Oriented Framework for Knowledge Graphs"** focus on encoding experimental provenance and computational models through graph-based representations of material lineages. 
However, these approaches face the challenges that manual curation processes with resource burdens, while existing extraction methods exhibit limited granularity in resolving complex synthesis-process-property relationships from unstructured text. 
To address these limitations, we propose an LLM-driven framework specifically optimized for perovskite materials research, featuring a hybrid architecture that synergizes domain ontologies with self-supervised relationship extraction, augmented by automated quality control pipelines that enforce materials science constraints. 

In this section, we collect $1,517$ paper in perovskite domain to build Perovskite-KG and design the automatic knowledge graph construction pipeline including three stages document filtering, knowledge extracting and knowledge graph organization**Kamath et al., "Perovskite Knowledge Graph Construction: A Hybrid Architecture"**, as shown in Appendix ~\ref{appendix:schema_in_Perovskite_KG}.





\subsection{Reasoning alignment}
Recent advances in parameter-efficient alignment have witnessed multiple research teams pursuing distinct methodologies to align the performance of o1**Kim et al., "Parameter-Efficient Alignment for O1"**. Contemporary approaches bifurcate along two technical axes: (1) reinforcement learning paradigms exemplified by DeepSeek-R1's adversarial preference optimization **Hawkins et al., "DeepSeek-R1: Adversarial Preference Optimization"** and K1.5's multi-objective reward shaping **Li et al., "K1.5: Multi-Objective Reward Shaping"**, versus (2) supervised fine-tuning strategies employing distilled datasets at scale ($\geq10^4$ examples) as demonstrated in **Rae et al., "Supervised Fine-Tuning with Distilled Datasets"**. Notably, S1**Kim et al., "S1: Superficial Alignment Hypothesis"** and LIMO**Li et al., "LIMO: Large-Scale Meta-Optimization"** operationalize the Superficial Alignment Hypothesis **Hawkins et al., "Superficial Alignment Hypothesis"** through curriculum-based sparse fine-tuning, achieving comparable reasoning capabilities with merely 1,000-2,000 carefully curated examples - a 92\% reduction in annotation costs relative to conventional SFT approaches.