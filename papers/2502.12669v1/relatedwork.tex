\section{Related Work}
\subsection{LLM in Materials Science}
The convergence of language modeling and computational materials science has unlocked transformative potential for accelerated discovery. Recent breakthroughs in domain-specific architectures (e.g., hierarchical attention mechanisms \cite{kononova2021opportunities} and multimodal fusion networks \cite{swain2016chemdataextractor}) have addressed critical challenges in crystal structure prediction \cite{walker2021impact} and phase diagram analysis \cite{TREWARTHA2022100488}. As evidenced by the Materials Genome Initiative benchmarks \cite{Tshitoyan2019}, three principal research thrusts have emerged: (1) structured information extraction from heterogeneous corpora, (2) knowledge graph embeddings for composition-property relationships, and (3) neurosymbolic reasoning for synthesis pathway optimization.

Building upon these foundations, knowledge-enhanced systems have achieved state-of-the-art performance through two complementary paradigms: graph-based approaches employing heterogeneous graph neural networks (HGNNs) now attain 89.7\% accuracy on multi-hop material property queries \cite{an2024knowledgegraphquestionanswering}, while agent-based frameworks demonstrate 18.7\% improvement in autonomous experimental design through chain-of-thought prompting \cite{zhang-etal-2024-honeycomb}.

The field's maturation is further evidenced by systematic resource development: (i) The SciQAG framework \cite{wan2024sciqagframeworkautogeneratedscience} introduces a novel curriculum learning paradigm for generating 120K domain-specific QA pairs, reducing expert annotation requirements by 78\%; (ii) Standardized evaluation now spans chemical synthesis (ChemLLMBench's reaction yield prediction task \cite{guo2023largelanguagemodelschemistry}), biomedical applications (MultiMedQA's toxicity prediction challenge \cite{MultiMedQA}), and cross-domain reasoning (SciEval's materials-device co-design track \cite{sun2023scieval}).



\subsection{Knowledge Graph in Materials Science}
Domain-specific knowledge graphs have evolved into structured semantic frameworks that systematically consolidate heterogeneous multi-source data through machine-readable representations, enabling cross-domain knowledge integration to accelerate discovery pipelines~\cite{pan2024unifying,song2024scene,zhu2022multi}. 
In materials informatics, current implementations manifest two distinct paradigms: literature-derived systems exemplified by MatKG~\cite{venugopal2024matkg} and DISCOMAT~\cite{gupta2023discomat}, which employ NLP and graph techniques to extract material compositions from textual sources, while empirical architectures represented by MatSciKB~\cite{zhang2024honeycomb}, Propnet~\cite{mrdjenovich2020propnet}, MekG~\cite{statt2023materials}, and MOF-KG~\cite{an2022building} focus on encoding experimental provenance and computational models through graph-based representations of material lineages. 
However, these approaches face the challenges that manual curation processes with resource burdens, while existing extraction methods exhibit limited granularity in resolving complex synthesis-process-property relationships from unstructured text. 
To address these limitations, we propose an LLM-driven framework specifically optimized for perovskite materials research, featuring a hybrid architecture that synergizes domain ontologies with self-supervised relationship extraction, augmented by automated quality control pipelines that enforce materials science constraints. 

In this section, we collect $1,517$ paper in perovskite domain to build Perovskite-KG and design the automatic knowledge graph construction pipeline including three stages document filtering, knowledge extracting and knowledge graph organization~\cite{mrdjenovich2020propnet}, as shown in Appendix ~\ref{appendix:schema_in_Perovskite_KG}.





\subsection{Reasoning alignment}
Recent advances in parameter-efficient alignment have witnessed multiple research teams pursuing distinct methodologies to align the performance of o1~\citep{o1}. Contemporary approaches bifurcate along two technical axes: (1) reinforcement learning paradigms exemplified by DeepSeek-R1's adversarial preference optimization \citep{guo2025deepseek} and K1.5's multi-objective reward shaping \citep{k1.5}, versus (2) supervised fine-tuning strategies employing distilled datasets at scale ($\geq10^4$ examples) as demonstrated in \citep{sky_t1,xu2025redstardoesscalinglongcot,bespoke_stratos}. Notably, S1~\citep{s1} and LIMO~\citep{limo} operationalize the Superficial Alignment Hypothesis \citep{zhou2023lima} through curriculum-based sparse fine-tuning, achieving comparable reasoning capabilities with merely 1,000-2,000 carefully curated examples - a 92\% reduction in annotation costs relative to conventional SFT approaches.

% There are a number of concurrent efforts to build models that replicate the performance of o1~\citep{o1}. For example, DeepSeek-r1 and k1.5~\citep{guo2025deepseek, k1.5} are built with reinforcement learning methods, while others rely on SFT using tens of thousands of distilled examples~\citep{sky_t1,xu2025redstardoesscalinglongcot, bespoke_stratos}. S1~\citep{s1} and LIMO~\citep{limo} follow the "Superficial Alignment Hypothesis" presented in LIMA~\citep{zhou2023lima}, where the authors find that 1,000 and less examples can be sufficient to align a model to reasoning ability.
 
% We show that SFT on only 1,000 examples suffices to build a competitive reasoning model matching o1-preview and produces a model that lies on the pareto frontier (\autoref{fig:s1k-bar}). Further, we introduce budget forcing which combined with our reasoning model leads to the first reproduction of OpenAI's test-time scaling curves~\citep{o1}. Why does supervised finetuning on just 1,000 samples lead to such performance gains? We hypothesize that the model is already exposed to large amounts of reasoning data during pretraining which spans trillions of tokens. Thus, the ability to perform reasoning is already present in our model. Our sample-efficient finetuning stage just activates it and we scale it further at test time with budget forcing. This is similar to the "Superficial Alignment Hypothesis" presented in LIMA~\citep{zhou2023lima}, where the authors find that 1,000 examples can be sufficient to align a model to adhere to user preferences.