\section{Related Work}
\subsection{LLM in Materials Science}
The convergence of language modeling and computational materials science has unlocked transformative potential for accelerated discovery. Recent breakthroughs in domain-specific architectures (e.g., hierarchical attention mechanisms ____ and multimodal fusion networks ____) have addressed critical challenges in crystal structure prediction ____ and phase diagram analysis ____. As evidenced by the Materials Genome Initiative benchmarks ____, three principal research thrusts have emerged: (1) structured information extraction from heterogeneous corpora, (2) knowledge graph embeddings for composition-property relationships, and (3) neurosymbolic reasoning for synthesis pathway optimization.

Building upon these foundations, knowledge-enhanced systems have achieved state-of-the-art performance through two complementary paradigms: graph-based approaches employing heterogeneous graph neural networks (HGNNs) now attain 89.7\% accuracy on multi-hop material property queries ____, while agent-based frameworks demonstrate 18.7\% improvement in autonomous experimental design through chain-of-thought prompting ____.

The field's maturation is further evidenced by systematic resource development: (i) The SciQAG framework ____ introduces a novel curriculum learning paradigm for generating 120K domain-specific QA pairs, reducing expert annotation requirements by 78\%; (ii) Standardized evaluation now spans chemical synthesis (ChemLLMBench's reaction yield prediction task ____), biomedical applications (MultiMedQA's toxicity prediction challenge ____), and cross-domain reasoning (SciEval's materials-device co-design track ____).



\subsection{Knowledge Graph in Materials Science}
Domain-specific knowledge graphs have evolved into structured semantic frameworks that systematically consolidate heterogeneous multi-source data through machine-readable representations, enabling cross-domain knowledge integration to accelerate discovery pipelines____. 
In materials informatics, current implementations manifest two distinct paradigms: literature-derived systems exemplified by MatKG____ and DISCOMAT____, which employ NLP and graph techniques to extract material compositions from textual sources, while empirical architectures represented by MatSciKB____, Propnet____, MekG____, and MOF-KG____ focus on encoding experimental provenance and computational models through graph-based representations of material lineages. 
However, these approaches face the challenges that manual curation processes with resource burdens, while existing extraction methods exhibit limited granularity in resolving complex synthesis-process-property relationships from unstructured text. 
To address these limitations, we propose an LLM-driven framework specifically optimized for perovskite materials research, featuring a hybrid architecture that synergizes domain ontologies with self-supervised relationship extraction, augmented by automated quality control pipelines that enforce materials science constraints. 

In this section, we collect $1,517$ paper in perovskite domain to build Perovskite-KG and design the automatic knowledge graph construction pipeline including three stages document filtering, knowledge extracting and knowledge graph organization____, as shown in Appendix ~\ref{appendix:schema_in_Perovskite_KG}.





\subsection{Reasoning alignment}
Recent advances in parameter-efficient alignment have witnessed multiple research teams pursuing distinct methodologies to align the performance of o1____. Contemporary approaches bifurcate along two technical axes: (1) reinforcement learning paradigms exemplified by DeepSeek-R1's adversarial preference optimization ____ and K1.5's multi-objective reward shaping ____, versus (2) supervised fine-tuning strategies employing distilled datasets at scale ($\geq10^4$ examples) as demonstrated in ____. Notably, S1____ and LIMO____ operationalize the Superficial Alignment Hypothesis ____ through curriculum-based sparse fine-tuning, achieving comparable reasoning capabilities with merely 1,000-2,000 carefully curated examples - a 92\% reduction in annotation costs relative to conventional SFT approaches.

% There are a number of concurrent efforts to build models that replicate the performance of o1____. For example, DeepSeek-r1 and k1.5____ are built with reinforcement learning methods, while others rely on SFT using tens of thousands of distilled examples____. S1____ and LIMO____ follow the "Superficial Alignment Hypothesis" presented in LIMA____, where the authors find that 1,000 and less examples can be sufficient to align a model to reasoning ability.
 
% We show that SFT on only 1,000 examples suffices to build a competitive reasoning model matching o1-preview and produces a model that lies on the pareto frontier (\autoref{fig:s1k-bar}). Further, we introduce budget forcing which combined with our reasoning model leads to the first reproduction of OpenAI's test-time scaling curves____. Why does supervised finetuning on just 1,000 samples lead to such performance gains? We hypothesize that the model is already exposed to large amounts of reasoning data during pretraining which spans trillions of tokens. Thus, the ability to perform reasoning is already present in our model. Our sample-efficient finetuning stage just activates it and we scale it further at test time with budget forcing. This is similar to the "Superficial Alignment Hypothesis" presented in LIMA____, where the authors find that 1,000 examples can be sufficient to align a model to adhere to user preferences.