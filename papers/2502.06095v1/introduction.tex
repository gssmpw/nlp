%\IEEEspecialpapernotice{(Invited Paper)}

%%%%%%%%%%%%%% social media
% This paper addresses the impact of semantic and effectiveness communication on what we call communication networks.  
% What are the issues with current networking paradigm?

% Separate source-channel coding, or, joint source-channel coding, or something in between, to benefit from the best of the two worlds?

% What is clear is that interoperability can't be sacrificed. But we can do better than what the current systems can do.

% *This may also be interesting to researchers looking for open problems that are valid case of applied machine learning in telecommunication. Semantic coding is highly advanced in the machine learning world. 
%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

% \section*{before intro}

% technical communication is rate-centric metrics such as throughput  \cite{lan2021semantic}
% shannon's approach doesn't allow to tie meaning to the reliability of a packet, but that is not completely true. in fact we can prioritize different parts of a packet over the others. so, what is it that is different about semantic comms?

% to tame and curb the growth of traffic, we must use the intelligence of today's devices to compress better, but also, to prioritize better. the compression can be based on a richer context or even generative priors, thus reducing the volume of traffic significantly. the prioritization needs to be done by the source, and communicated to the network.

% this present work does the compression part for a speficic distribution, thus better compresion rate compared to generic codecs, and prioritizes information with rateless coding, where bits closer to the top of the vector are more important, and more likely to be treated with higher reliability.

% "Information-theoretic encoding focuses on the statistical properties of messages instead of the content of messages."



% it also seems to be that only lossy finite block length regime enjoys jscc in technical comm. this allured a lot of reseach work on semcom to think of jscc as the way forward for semcom. truth is that, jscc if includes semantic encoding, and if applies importance to the coded symbols, becomes relevant research direction, otherwise, the finite block length regime is too small to create enough momentum for changing the communication paradigm. so, jscc with a codeword that applies importance to the pieces of information is the way to go. but network should understand that importance too and behave accordingly



% "This semantic aspect of communication was originally treated in Shannon’s theory as being irrelevant to the engineering problem of information transmission. For example, a tacit assumption in Shannon’s model is that the sender always knows what is relevant for the receiver and the receiver is always interested and ready to receive the data sent by the transmitter."

% examples in this work\cite{bao2011towards} are very bad, e.g., the lecturer vs tenue example


% I should use the s value proposal, and add importance to it, and say it should look something like this.
% Assumption should be that the source and destination know what language they are speaking (semantic meaning, at the end of the day means meaning in a language context, but languate is not only among the commonly known ones, but could be a specific language between alice and bob.)
% other assumption is that each meaning can have a different level of importance.
% this already brings us away from shannons treatment of information as uncertainty. Here, aside from uncertainty, importance also matters. The rest is the same.



% I should add the thought about importance being the key differentiation. with an example of baby cam, there are different semantics `i'm interested in, but each has different importance, even though each may have the same amount of information.

% is the baby in the image
% is the baby in the right side or left side (playing video game or )


% levels of comm based on device intelligence and semantic analysis capability:
% - pixel intensity sensor at tx and pixel intensity monitor at rx --> analog cctv
% - image compression at tx and image decompression at rx --> MPEG.JPEG enabled digital comms
% - image analysis and intelligence at tx and 

% }


% \subsection{memorization vs semantic compression}
% compression using semantic elements is different from memorizing a dataset and remembering by index. but the first is also a form of memorization, in smaller units.
% this is also related to scaling law in AI

% it's not memory vs compression. memory is needed either way. it is how mcuh  memmory for what form of memorization and compression. there is an important tradeoff here.

\section{Introduction}
\label{sec:intro}

The concepts of \emph{semantic} and \emph{effectiveness} communication were raised by W. Weaver in a preface to Shannon's mathematical theory of communication---while referring to Shannon's work as a solution to  \emph{technical} communication problem---as what should come next beyond the technical communication \cite{shannon1998mathematical}. Several attempts are made to formalize those concepts (see for instance \cite{floridi2004outline,isaac2019semantics,zhong2017theory,shao2024theory,saz2024model}), yet a comprehensive mathematical formalization and a framework to evaluate the performance limits of semantic communications system remain  open problems. 

Specifically, a formal definition of the semantic  problem that differentiates it against the technical  problem  towards a meaningfully different communication networking solution, is  not available. The notion of ``conveying  the desired meaning'', as opposed to ``accurate reconstruction of bits/symbols'', was alluded to by Weaver to differentiate semantic against technical problems. The former is thus seen by the literature mostly  as a source coding problem with majority effort focused on lossy \gls{jscc}, but the  impact on what we call \emph{communication network} is yet unclear. In source coding, the differences are  evident and semantic compression has already provided meaningful engineering solutions: for instance, the hierarchical codecs used for image \cite{li2022deep,huang2021deep,yang2015visual,7226830} and video \cite{zhu2003hierarchical,zhai2005joint} signals can distinguish between semantic vectors and perceptual elements in the signal and compress them at unequal rates according to their importance in reconstruction loss. Generative models have been successful in using  auto-regressive or diffusion-based decoders to expand on the resolution and perceptual quality of a digital signal based on  understanding of the generative priors \cite{kingma2022autoencodingvariationalbayes,chen2024generative} and the semantic vectors \cite{tang2024evolving} of a given data distribution. In language processing, compressing word and sentence tokens to \emph{embeddings} is an example of semantic compression---in fact, in the embedding space one can subtract   the embedding vector of word tokens and convert the difference into a word token, while the whole operation has \emph{meaning} in the word space too, e.g., $   vector (\text{``king''}) - vector (\text{``man''}) +  vector (\text{``woman''}) \Rightarrow vector (\text{``queen''})$  \cite{mikolov2013efficient}. %To this moment, it  appears that the engineering  aspects of semantic problem are irrelevant, as stressed by Shannon \cite{shannon1998mathematical}, and in principal, not so different from the technical communication.  ``The significant aspect is that the actual message is one selected from a set of possible messages'', a set that is known by both the source and the destination.

\subsection{The Issue with Current Communication Networking Paradigm}

Semantic communication problem therefore mostly appears to have to do with  source coding and less with  communication networking, however, essential modifications to the way network treats the  messages can improve the  semantic extraction and reconstruction efficiency. The required changes stem from the intense focus of the current communication networking paradigm on  \emph{error-free} and \emph{packet-ized} communication. %A packet received from the source must be delivered error-free and intact to the destination. 
Within the network,  packets go through a sophisticated and well-optimized process of routing, error correction coding, channel symbol mapping, retransmissions, etc. By the end of their finite latency budget, the packets are only passed to the destination if successfully reconstructed---i.e., error-free. Otherwise, there will be a packet erasure. The \emph{cliff effect} and \emph{leveling-off effect} associated to separate source and channel coding  in \cite{gunduz2024joint} is mainly due to this. If a packet with small damage is still passed to the application, one that deploys error-tolerant source compression (or, \gls{jscc}), then the performance will smoothly and more gracefully degrade with channel quality decreasing (we  explore examples of such effect in this paper).



The current networking paradigm is inherently optimized for error-free (but, erasure-tolerant) communication. As a result, applications that tolerate loss (or, distortion) in message reconstruction are potentially not getting the best they can out of network's capacity. For instance, a common trait for video application codecs is to use hierarchical (or layered) compression of a frame into several unequally important data packets, while the network treats that unequal importance at \gls{qos} level. Network is often unaware of the relation among those several packets\footnote{In more advanced networking solutions, application-awareness can help the network understand such relations and make more cohesive decisions in this sense.}. % that relate to the same frame and performs its \gls{qos}-based routin for each of those packets rather independently. 
From application's perspective, each  packet goes through an erasure channel with different reliability---it is either delivered error-free or not delivered within the  latency budget. Application, then uses  \emph{error concealment} techniques \cite{aign1995temporal} to recover  the lost packets. Overall, it is unclear whether such multi-layered  process is  near optimal in utilizing capacity (and, efficient), while there are concerns with the level of overhead imposed by such operation on both the network and the application \cite{lan2021semantic}. %This following is an open problem: considering the  advanced application-aware networking paradigm as benchmark---due to the complexity of modeling such multi-layered process, with randomness not only in the wireless channel but in network's experienced load, this is a complex benchmarking.



% One irony is that, as the dataset changes, the \gls{dnn} model architecture and weights (trained values) also change. That means a traned \gls{jscc} is only good for one dataset. The CIFAR10 dataset is around 170 MB. That is equivalent to storing a \gls{dnn} model with 40 million trainable parameters at 32-bit floating point. In other words, instead of training such network to perform JSCC one could store the dataset itself at both source and destination, and only communication the index of an image (less than 16 bits) in a much more reliable way with (almost) zero reconstruction loss. Therefore, the approaches we take to tackle the semantic communication problem needs to be revisited and rethought. 

% Ironically, in this work, we also provide an example of the same sort of approach---in effect, the 




% The principal  distinction between the technical and semantic communication concepts appears to be in the way information is treated end-to-end: the former doesn't differentiate information from information and aims to maximize  transfer rate, while the latter prioritizes information unequally and tolerates a loss in information transfer which is directly related to that unequal importance. The realization of this distinction majorly occurs in the way messages are compressed (or source coded). A misconception exists in the literature claiming that Shannon's technical communication is about communicating  information in a reliable way (i.e., error-free, which results in loss-less). In reality, the broad technical problem includes lossy communication too. What differentiates semantic (and for that matter, effectiveness) problem, is that different content in the same or in different messages should be able to be prioritized over each other even if they contain the same \emph{amount} of information (or, uncertainty)---technical problem doesn't specifically allow for that.

\subsection{Joint vs Separate Source-Channel Coding}

Optimality of separate source and channel coding  solutions \cite{shannon1959coding} hold only in the limit of infinite blocklength.  The assumptions that are needed for optimality frequently  don't  hold in practice  where there exist constraints on end-to-end latency and implementation complexity  \cite{zhai2005joint}. In lossy communication and finite blocklength regeime, \cite{6408177} proves sub-optimality of separation.  Joint solutions outperforming separate desgins have presistantly reported in the literature, e.g., see examples in \cite{10747747,lan2021semantic}. On the other hand,  \emph{separation}-based solutions have become indispensable to telecommunication systems,  offering ease of interoperability, modular and independent development of devices and network systems, and simplicity of  design. But another important benefit of separate design is channel agnosticism offered to the source compression, allowing the channel code to adapt to the channel state when needed.

In fact, there appears to be a critical challenge related to semantic (or, let's say, \emph{lossy}) communication of information, and that is the lack of channel awareness at the applications. %Suppose that an ideal joint source semantic-compression and channel coding for a given coding rate (channel capacity) is at hand.  
The semantic application has the uncoded source information---exchanging that with the network breaches privacy of the source and requires complex interface between application and the network, thus source coding must happen at the application. Meanwhile, the network has the channel state information---exchanging that with the application exacerbates aging effect of \gls{csi},  increases operation overhead, and in complex networking systems is virtually impossible to be routed back to the application. As a result, in time-varying channel state conditions, the otherwise ideal \gls{jscc} solutions can  readily become suboptimal because ``channel'' is unknown. This appears to be the chief practical challenge for realizing the performance gain of \gls{jscc} against separate design. In practical networks the challenge is  compounded---it is not only the wireless channel quality that shapes the \emph{state} of the link, but also the randomness of the load on the network resulting from multi-user nature of load and heterogeneity   of users, and the multi-hop nature of majority of communication links (see discussion in \secref{sec:sketch})---that makes central tracking of the \emph{state} of the link impractical.

% Channel-aware \gls{jscc} is the main building block of a semantic communication system.

% recent efforts have focused on splitting the \gls{jscc} functionality between the application and the network, while maintaining the performance. 


% On the engineering front,  semantic communication is in initial steps too. While in natural language processing  the concept is more developed, it lacks a clear definition in other forms of data.

% there still seems to be a lack of consensuses and clarity on how to quantify semantic and effectiveness of communication, and thus, how to design a communication system for those. 
% Nevertheless, what seems to be a point of convergence is the literature is that semantic and effectiveness communication will for the most part use the same communication infrastructure that were built for the technical communication problem (with some essential modifications, and some beneficial modifications). More notably, the  elements of \emph{loss} and \emph{error}  seem to play a key role in 

% The research efforts on semantic communication appears to not have yet converged to a widely accepted mathematical formalization of the  



%---------------------------
\begin{figure*}[ht]
\begin{center}
\psfrag{ss}[c][c][1]{$\mathbf{s}$}
\psfrag{f}[c][c][1]{$f$}
\psfrag{uu}[c][c][1]{$\mathbf{u}$}
\psfrag{ll8}[c][c][1]{$r$}
\psfrag{xx}[c][c][1]{$\mathbf{x}$}
\psfrag{ch}[c][c][1]{$\mathsf{P}(\mathbf{y}|\mathbf{x})$}
\psfrag{yy}[c][c][1]{$\mathbf{y}$}
\psfrag{ll9}[c][c][1]{$r^{*}$}
\psfrag{uh}[c][c][1]{$\hat{\mathbf{u}}$}
\psfrag{gg}[c][c][1]{$g$}
\psfrag{sh}[c][c][1]{$\hat{\mathbf{s}}$}
\psfrag{lll}[c][c][1]{application source}
\psfrag{nn}[c][c][1]{network}
\psfrag{rr}[c][c][1]{application destination}
\psfrag{ll0}[c][c][1]{(source) $N$}
\psfrag{ll1}[r][r][1]{$K$}
\psfrag{ll2}[r][r][1]{$K-L$}
\psfrag{ll3}[r][r][1]{$K-L$}
\psfrag{ll4}[r][r][1]{$K-L$}
\psfrag{Ll5}[r][l][1]{$L$}
\psfrag{ll7}[r][r][1]{(null)}
\psfrag{ll6}[c][c][1]{(recovered) $N$}
\includegraphics[width=.85\textwidth,keepaspectratio]{images/fig2.eps}
\caption{Rateless JSCC and rate-adaptive link for semantic communication. At the bottom, $\mathbf{x}$ and $\mathbf{y}$ are shown as binary sequences, as an example. In general, the symbols selected for communication are chosen from a constellation based on the estimated channel knowledge at the transmitter. The bits in red represent the flipped bits due to communication error, while the shaded blocks represent the null bits at the decoder caused by puncturing in the network.}
\label{fig:system-model}
\end{center}
\end{figure*}
%----------------

\subsection{Motivation}



% Channel-aware \gls{jscc} is the main building block of a semantic communication system. The chief practical challenge for realizing  \gls{jscc} can be summarized as follows. The semantic application has the source information---exchanging that with the network breaches privacy of the source and requires complex interface between application and the network. Meanwhile, the network has the channel state information---exchanging that with the application exacerbates aging effect of \gls{csi} and increases operation overhead. As a result, recent efforts have focused on splitting the \gls{jscc} functionality between the application and the network, while maintaining the performance. 

The proposed rateless \gls{jscc} coding framework in this work  aims to resolve this very issue by hosting the \gls{jscc} functionality at the application while allowing the network to adjust the coding rate based on the knowledge of \gls{csi}. Particularly, the responsibility of the network is simplified to stabilizing the reliability of the end-to-end link (measured in ratio of flipped bits in each frame) and then adapting the coding rate to \gls{csi} by \emph{puncturing} the binary codeword received from the application. This relaxes the need for continuous coordination between the application and the network, and forms a cooperative game-theoretic venture between the network and the application. For this to function properly, the \gls{jscc} code at the application must perform well for a range of coding rates that are among network's possible choices and maintain optimality in the \emph{rate-distortion} tradeoff over that range.

Conventional source codes recognize rate-distortion tradeoff most commonly through quantization control. Rate control is therefore possible for those codes if performed by the source. However, commissioning the network with  rate control using the conventional source codes results in sub-optimal \gls{jscc} performance. 


The proposal in this work thus has two main elements: a rateless \gls{jscc} coding framework for the application, and a rate-adaptive and stable end-to-end link operation framework for the network. In the following (as illustrated in  \figref{fig:system-model}),  \emph{application} refers to the user (a human and/or a machine running an application), and,  \emph{network}  refers to the service provider that establishes an end-to-end link for the application (possibly consisting of multitude of wireless and wired hops, switching and processing nodes). We also use the term \emph{frame} to refer to a segment of data bits that is communicated at a time by the application---the term is to be differentiated with \emph{packet} in technical communication which implies integrity requirement (see further discussion on this in \secref{sec:blueprint}). 





\subsection{Prior Work}
\label{sec:priorwork}

The literature on semantic communication and lossy \gls{jscc} is rich, especially the research on leveraging the power of \glspl{dnn} in realizing semantic communication. The overview papers on the topic that raise interesting open research problems are outlined later in \secref{sec:openresearch}. Here, we study the literature around a few  points that are the most relevant to our rateless \gls{jscc} proposal.

\subsubsection{Hierarchical Compression and Variable-Length Coding}

The proposed rateless \gls{jscc} codes shouldn't be mistaken by the so-called variable-length \gls{jscc} schemes, such as in~\cite{10198383,8445924}, where the code length is varied according to network-provided rate or source word length. In contrast, a rateless \gls{jscc} code generates a codeword that can cover a continuum of compression rates  without knowing which rate will be used by the network. Thus, the aim of the code design is to maintain a rate-distortion tradeoff for all  the supported rates. 

Use of rateless codes such as Raptor codes together with hierarchical source compression was proposed in \cite{bursalioglu2008lossy,bursalioglu2013joint} to provide a continuum of coding rate that can be adapted to the channel capacity. The medium is first  quantized into multiple bitplanes where each bitplane is then channel coded using Raptor codes, allowing for the coding rate to be adapted to the transmission channel capacity. In effect, the hierarchical source quantization and the channel coding remain separate while each quantization  hierarchy requires a separate coding rate matching. In contrast, in this work we target codes that achieve  true joint source-channel coding effect with single coding rate matching, and propose an example of those codes using deep neural networks that can be flexibly made rateless according to the desired range of coding rates.


\subsubsection{Unequal Importance of JSCC Coded Bits}

In practical source coding  it can be observed that  the individual coded bits incur different levels of relative importance or sensitivity. As a result, channel errors in different bit positions can affect the reconstructed signal differently. Such effect is apparent specially in variable-length source coding~\cite{748887}, such as entropy coding schemes---known to be otherwise optimal over \emph{noiseless} channel.

Several approaches have acknowledged this effect in developing \gls{jscc} techniques  under noisy channel conditions. Some of those solutions focus on designing the source and channel code to limit propagation of channel errors, e.g., by improving  synchronization for variable-length source codes~\cite{selfsyncvariablejscc}, or, through packetization during channel coding~\cite{138998}. Other solutions focus on  specifically weighted channel coding protection for different coded bit positions~\cite{1095155,748707}. A more recent work capitalizes on further accented unequal importance of the coded bits and proposes to design \gls{ae} type channel codes to unequally protect the source encoded bits with non-uniform importance~\cite{tung2024multilevelreliabilityinterfacesemantic}. 

\subsubsection{Use of Deep Neural Networks for JSCC}

This is a developing and rich part of the literature. \cite{xie21_deep_learn_enabl_seman_commun_system}, \cite{jankowski21_wirel_image_retriev_edge} and
\cite{bourtsoulatze19_deep_joint_sourc_chann_codin} are  examples of studying deep learning-based  \gls{jscc}. The latter targets wireless image transmission and demonstrates improved performance over traditional separate source and channel coding schemes, particularly in low  \gls{snr}. \cite{xu2023deep} proposes a \gls{snr}-adaptive \gls{jscc} solution based on deep learning, where the \gls{jscc} is aware of the channel estimate and uses that to properly encode to the capacity of the channel. This implies exchange of channel state between the network and the application. \cite{kalkhoran23_secur_deep_jscc_again_multip_eaves}, among others,  address the issue of security in \gls{dnn} based \gls{jscc}. In another interesting proposal, \cite{tang2024evolving} studies the approach of enhancing semantic communication  efficiency over time by improving the learned semantic vectors of communicated images and adding them to the shared contexts between the two ends of the link.

\subsubsection{Rateless Compression}

\glspl{ae} have proven powerful in compression tasks, thanks to  nonlinear activation functions such as rectified linear unit (ReLU). Compared to majorly linear techniques such as \gls{pca}, \glspl{ae} can more efficiently extract   features (a.k.a., latent representations) of  the data. This shortcoming of \gls{pca}-based techniques was addressed in \cite{scholz2008nonlinear}, where  non-linear \gls{pca} and hierarchical \glspl{ae} were discussed. In essence, sorted principle components of a liner (or, non-linear) \gls{pca} can be dropped out (i.e., punctured), starting from the least significant order, to create a \emph{rateless} behavior in the compression process. However, this is not generally true for \glspl{ae} since the latent
variables are  learned to be \emph{uniformly} important. Similar shortcoming is persistent  in sparse \glspl{ae} too \cite{ng2011sparse}, where the \gls{ae} learns  latent representations  that can be randomly dropped out, thus providing  rate-control mechanism for compression. This was investigated by \cite{koikeakino2020stochasticbottleneckratelessautoencoder} in developing a special case of \glspl{ae}, referred to as rateless \gls{ae}. 

The rateless \gls{ae}  in \cite{koikeakino2020stochasticbottleneckratelessautoencoder} is based on \emph{TailDrop} regularization which is stochastic in nature, but unlike sparse \glspl{ae}, imposes  a non-uniform dropout rate to the latent space. Specifically, the dropout rate in TailDrop monotonically increases   from head neurons to tail neurons. The result is an autoencoder with a stochastic bottleneck and rateless behavior that is
adaptable to a continuum of compression rates. The rateless \gls{ae} structure was utilized later by \cite{10437920} to construct a rateless deep \gls{jscc} solution for Point Cloud signals. %Specifically, \cite{10437920} proposes to allow dropout  of compressed signal  so that the remaining symbols fit the available bandwidth for communication.
The rateless \gls{jscc} in \cite{10437920}  allows the  code rate to be adapted, however, it doesn't assume a quantized (binary) interfacing between network and application entities and appears to unify the function of those entities. In practice,  training \gls{ae}  with binary latent space while applying a stochastic dropout, as was proposed in \cite{koikeakino2020stochasticbottleneckratelessautoencoder}, proves  highly complex---the training must converge while experiencing randomness of the dropout regularization, randomness of bit flipping due to channel errors, and the quantization of the latent space into binary. Therefore, in the proposed solution in this paper we avoid the random dropout of the latent space to improve  convergence of  \gls{ae} training, and instead, propose a new sequential training mechanism that makes the code  rateless and imposes a  non-uniform and monotonically decreasing importance of the coded latent features.



\subsection{Contributions}

The main contributions of this paper can be summarized as follows:

\begin{enumerate}
    \item We introduce the new framework of  rateless \gls{jscc}. Rateless JSCC is unaware of the state of the network (including channel state and load variation) but anticipates  time-variation in the state, hence optimizes the code to be rate-compatible and covers a continuum of such variations\footnote{The term ``rateless'' is  borrowed from the rateless channel codes \cite{6145513} but has a different  effect here. That is, rateless JSCC encodes and transmits to the highest  rate, but the decoder receives  a portion of the codeword (i.e., the portion allowed by the network) at a lowered rate. Regardless of the rate, the code must try to minimize the distortion.}. Further, we introduce a new rate-adaptive and stable communication link approach. The proposed link operation turns the underlying channel into a \emph{bit pipe} that is identified by the number of bits it transfers in a single time frame and the rate of bits that are flipped during the transfer. The link accommodates rateless JSCC by being \emph{rate-adaptive}, such that it punctures the codeword  to adapt its length (and coding rate) to the underlying channel capacity, and is  \emph{stable} in maintaining the bit flipping ratio across time frames. The puncturing follows an order of bits that is known by both the network and the application, e.g., from the end of the codeword, such that the more important information is encoded into bits that are less likely to be punctured. Due to the puncturing, the link introduces a new paradigm of communication networking where the network is allowed to throw away part of the data based on pre-agreed terms with the application. 
    \item We propose an \gls{ae}  solution to  rateless JSCC. The proposed code is dubbed rateless and lossy autoencoder channel and source (RLACS) code (read as relax code!) and is built using residual attention network architecture \cite{wang2017residual} with binary latent space. The code is trained and tested on image signals considering reconstruction loss as the objective distortion and demonstrates powerful performance against channel state variation thanks to the rateless JSCC structure.
    \item A deep dive into practical implications of a semantic communication system is presented and a blueprint of a future end-to-end communication system design is provided. The proposed system design is aimed at enabling semantic and effectiveness communication with some essential modifications to the existing network systems, while maintaining interoperability and coexistence with other application types. The discussion is complemented with a comprehensive list of opern research and development problems towards a \gls{6g} semantic communications system.
\end{enumerate}

\subsection{Organization of the Paper} 

\secref{sec:prelim} describes the problem of semantic communication over noisy and faded channel; \secref{sec:proposal} introduces rateless JSCC for application operation and rate-adaptive and stable link for network operation; \secref{sec:relax} presents an \gls{ae} solution to rateless JSCC based on sequential training of a multi-DNN attention residual network architecture, and provides  numerical experiment results for the proposes RLACS code; \secref{sec:blueprint} provides a blueprint for next generation communication networks with semantic communication capabilities and outlines a comprehensive list of open research problems towards 6G semantic communication system design; and, finally, \secref{sec:conclusions} concludes the paper.


% Semantic communication has received intense interest over the past few years \cite{gündüz23_timel_massiv_commun, luo22_seman_commun, lu23_rethin_moder_commun_seman_codin_seman_commun, yang23_seman_commun_futur_inter, gunduz23_beyon_trans_bits}.
% The concept originated from Shannon and Weaver's seminal work \cite{shannon48_mathem_theor_commun}, where, in contrast to how communication systems have been designed over the past 70 years, aiming to accurately reproduce the symbols used for communication, we would instead seek to accurately communicate the ``meaning'' of the source.
% The vast majority of the work that have been published on semantic communications have understood this concept through \gls{jscc}, and for good reason.
% \gls{jscc} combines Shannon's lossy source coding theorem \cite{e.59_codin_theor_discr_sourc_fidel_criter} with the channel coding theorem \cite{shannon48_mathem_theor_commun}, such that the source is mapped to a channel codeword directly, without the separate source and channel coding steps that we currently have in our communication systems.
% Theoretically, it has been shown that \gls{jscc} can achieve lower end-to-end distortion than separate source and channel coding in the finite blocklength regime \cite{kostina13_lossy_joint_sourc_chann_codin}, which is where communication systems operate in practice.
% By defining the appropriate distortion measure as the measure of ``meaning'', we can see how \gls{jscc} fits the bill as the go-to framework for designing semantic communication systems.
% A good example of this is in \cite{goblick65_theor}, where the source and channel noise are both Gaussian distributed, and it is shown that simply scaling the source by a factor that meets the average power constraint, the optimal distortion can be met.

% To date, the majority of the work that approach semantic communications through \gls{jscc} have done so leveraging \gls{dl}.
% The approach typically uses an autoencoder architecture, with a untrainable channel between the encoder and decoder, such that the encoder learns a latent representation of the source that is reliable against the channel distortions.
% This is not surprising as \gls{jscc} is difficult to design for arbitrary sources and channel noise distributions.
% Using an autoencoder architecture, the source is mapped to a latent vector using an encoder, which is then directly transmitted over a noisy communication channel.
% At the output of the channel, a decoder then maps the noisy latent vector back to the source domain, or another domain, that is used to measure the distortion using a prescribed distortion measure.
% This technique has been successfully demonstrated on images \cite{bourtsoulatze19_deep_joint_sourc_chann_codin}, video \cite{tung22_deepw}, text \cite{xie21_deep_learn_enabl_seman_commun_system}, generative applications \cite{erdemir23_gener_joint_sourc_chann_codin}, image classification \cite{jankowski21_wirel_image_retriev_edge}, and can be shown to be secure against eavesdroppers \cite{tung23_deep_joint_sourc_chann_encry_codin, kalkhoran23_secur_deep_jscc_again_multip_eaves}.
% Challenging channel conditions, including multiple access channels \cite{yilmaz23_distr_deep_joint_sourc_chann}, can also be solved this way, using state-of-the-art \gls{dl} architectures \cite{wu23_vision_trans_adapt_image_trans_mimo_chann} and demonstrating substantial gains over separate source and channel coding.
% The gains tend to be most pronounced when the distortion measure is related to a task, rather than reconstructing the source \cite{jankowski21_wirel_image_retriev_edge}.
% This can be understood from the fact that designing a lossy source code that performs well for a specific distortion measure is challenging, and even when learned through \gls{dl}, it can require significant engineering efforts to efficiently compress the source, as was shown in \cite{jankowski21_wirel_image_retriev_edge}.
% As a result, the source code tends to be suboptimal with respect to the distortion measure, and when paired with a  channel code that is also suboptimal in the finite blocklength regime, the deviation from optimality is further increased, thus clarifying the reason for the observed gains in \gls{dl}-driven \gls{jscc}.

% However, despite the successes of \gls{dl}-driven \gls{jscc}, it is not practical to implement them over general purpose TCP/IP communication networks that are fundamentally architected to carry traffic from a variety of different sources through an inherently modular design.
% That is, the application and network providers are almost always separate entities.
% Under this current framework, the application typically resides in a cloud data center and communicates to the end device consuming the application over multiple wireline hops, with a wireless link to the device forming the final hop. 
% The wireless link is usually either the mobile cellular link between a base station and the device or a WiFi link between an access point and the device. 
% The application compresses the source using a codec of choice into blocks of bits that are packetized and sent over the network. 
% It is customary to treat the wireline hops over optical fiber links as lossless and the last wireless hop as the bottleneck link to be optimized. 
% The goal is usually to maximize the utilization of the wireless link assuming unlimited resources for the wireline links and hence \gls{jscc} mainly targets the wireless channel. 
% Another important aspect of the networks is that it is not practical to send real-time \gls{csi}, such as the \gls{snr}, of the wireless channel back to the source. 
% This is because the base station or access point are simply intermediate network nodes that may not even be aware of the source application's address.
% Sending the source data to the base station and performing \gls{jscc} there is also not a practical option as this would require the base station to be a destination node for the source, terminating the TCP/IP connection and then creating a new connection to the device with the base station as the source node. 
% In addition to not being a scalable approach, this requires the source application to reveal the source data to the base station. 
% Semantic communications involving \gls{jscc} over current communication networks is thus a challenging problem that we tackle in this paper.

% \subsection{Contribution}
% \label{subsec:contribution}

% In our network model, the source is separated from the wireless channel by a binary medium (modeling the wireline connection to the base station or access point), which means any \gls{jscc} scheme for semantic communications must first map the source to a binary codeword, before the binary codeword can be mapped to input symbols to be transmitted over the wireless link (modeling the bottleneck wireless channel).
% Moreover, different providers of both application and network will want control over how they design their coding scheme, thus requiring flexibility to allow different source and channel coding algorithms to interoperate.
% We identify the following constraints when deploying semantic communication systems in practice:
% \begin{enumerate}
%     \item The source and channel must be separated by a binary interface.
%     \item The application should be able to encrypt the data that it transmits over the network.
%     \item The application and network operators must be able to independently design their coding schemes, without requiring synchronized training.
%     \item The source only has limited, if any, knowledge of the wireless \gls{csi}.
%     % \item The bit to symbol mapping shall be done at the network, where other network functionalities might be added.
%     % \item DL-driven JSCC must be performed at the application with no or limited channel information exchange via the binary interface.
% \end{enumerate}

% Given the above constraints, in this paper, we consider the design of \gls{dl}-driven \gls{jscc} for semantic communications, where the source and channel are separated by a binary interface.
% We refer to the mapping from the source to the binary codeword as ``source mapping'' and the mapping from the binary codeword to channel input symbols as ``channel mapping''.
% In this setup, the binary interface consists of multiple noisy bit pipes, each with a different bit flipping probability (i.e., \gls{ber}). 
% Such interface, referred to as ``multi-level \gls{ber}'' interface hereafter, acts as an implicit, logical medium for communicating relative importance of each source bit for the distortion measure.
% We then pretrain the source code using multi-level \gls{ber} interface, so that the source code learns to map features of the source to different \gls{ber} subchannels based on their importance for the distortion measure.
% This effectively trains the source code to be a binary \gls{jscc} without revealing any real-time information about the wireless channel.

% After the source mapper and demapper pretraining, we freeze them and train the channel mapper and demapper using the distortion observed from the source demapper, over a wireless channel, to map the source codeword to channel input symbols, and vice versa. 
% To illustrate the concept, we focus on \gls{awgn} channels in this paper. 
% By updating the weights of the channel mapper and demapper using the application distortion measure, computed at the output of the source demapper, the channel mapper and demapper learn to allocate resources, such as power and bandwidth, to the source codeword in a way that is optimal for the distortion measure directly.
% This allows the training of the source code to be separate from the training of the channel mapper, with only the distortion observed required from the source demapper.
% Moreover, the network is able to understand the semantics of the source and implement semantic-aware channel mapping and demapping.
% We note that this set up bears similarity with two types of existing work: the relay channel and \gls{uep}.
% However, the existing work on semantic communication over relay channels has only been investigated over mutiple wireless links \cite{bi17_joint_sourc_chann_codin_jpeg, bian22_deep_joint_sourc_chann_codin} where the bits to channel symbol mapping is still conducted at the source. 
% \gls{uep} when applied to \gls{jscc} settings \cite{kondi_joint_2001, ji_joint_2012} still uses \gls{bler} as the metric for success of the channel code, rather than the receiver distortion measure.

% The multi-level \gls{ber} approach above can be straightforwardly deployed over communication networks in practice by packetizing the source bits corresponding to each \gls{ber} level. 
% Bits belonging to each \gls{ber} level would be packetized into separate packets with the packet header indicating a level index. 
% The \glspl{ber} corresponding to the different levels can be standardized or indicated by the source to the network before the start of the session. 
% The distortion required for training the channel mapper and demapper could be made available through a query type interface between the network and the application.
% The application can send samples over an untrained pair of channel mapper and demapper, compute the loss observed at the decoder, and then pass the loss value to the network to update the weights of the channel mapper and demapper.

% We note that although some existing works have considered the problem of digital semantic communication \cite{fu23_vector_quant_seman_commun_system}, none satisfy the requirements we have laid out in this paper.
% To summarize, the main contributions of this paper are as follows:
% \begin{enumerate}
%         \item We introduce a multi-level \gls{ber} binary interface as an abstraction of the underlying channel, allowing the source to learn a binary \gls{jscc} code that adheres to a wide range of channel conditions.
%         \item The proposed multi-level \gls{ber} interface also acts as an abstraction of the source with multiple levels of importance/robustness requirement, expressed via the binary medium that separate the source from the channel in almost all practical communication systems.
%         \item We devise a two step training process, where the source mapper and demapper are first trained over the multi-level \gls{ber} interface, followed by training of the channel mapper and demapper via querying the source demapper, so that it learns which bits are important for the distortion measure, thereby allocating channel resources optimally.
%         \item The proposed scheme, which we call \emph{Split DeepJSCC}, not only achieves lower end-to-end distortion and graceful degradation of distortion with channel quality, it does so satisfying the constraints we have laid our here.
% \end{enumerate}



% % \section{Related work}
% % \label{sec:related_work}


% % Semantic communication originated from Shannon and Weaver's seminal work in 1948 \cite{shannon48_mathem_theor_commun}, where Weaver laid out the three fundamental levels of communications:
% % (A) the ``technical level'', which tries to answer the question ``how accurately can the symbols of communication be transmitted?''.
% % (B) the ``semantic level'', tries to answer the question ``how precisely do the transmitted symbols convey the desired meaning?''.
% % Finally, level (C), the ``effectiveness level'', asks the question ``how effectively does the received meaning affect conduct in the desired way?''.
% % For the past 70 years, we have mostly considered the technical problem, due to Shannon's separation theorem, which states that for memoryless channels, the separate optimization of source and channel coding is optimal over infinite blocklength \cite{shannon48_mathem_theor_commun}.
