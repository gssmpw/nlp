\section{Related Work}
\textbf{Dataset classification.} ____ introduced the ``Name That Dataset‚Äù experiment a decade ago to highlight the bias present in visual datasets of that time. Recently, ____ revisited this problem (termed dataset classification) and found that current large-scale, supposedly more diverse visual datasets are still very biased. ____ further identified structural and semantic components in images as key contributors to these biases. ____ and ____ applied the dataset classification framework to study bias in synthetic images and LLM pretraining datasets respectively. 
While the synthetic task shown in  Figure~\ref{fig:teaser} is conceptually similar to dataset classification, we focus not on training datasets but on the distinctive characteristics inherent to LLMs.








\textbf{Human \vs machine-generated texts.} Many prior works have studied the problem of determining if a text is authored by a human or an AI system____. Model-free approaches typically use linguistic properties such as n-gram frequencies____, entropy____ or negative probability curvature____. Other works leverage neural network features to perform this task, such as fine-tuning BERT models____. Neural authorship attribution____ seeks not only to identify machine-generated text but also to attribute it to specific text generators. In this work, we focus on the distinguishability between LLMs rather than between AI \vs human.

\textbf{Understanding differences between distributions.} A line of research____ has used foundation models to describe qualitative differences between pairs of data distributions (\eg, image datasets). ____ conducted hypothesis testing on sets of model outputs to check whether the underlying LLMs were identical. The most relevant work to us is ____, which proposed VibeCheck to understand user-aligned traits in LLM outputs. They found that LLMs often vary in styles, such as being more formal or friendly. In contrast, our work aims to identify broader generalizable patterns to interpret the high classification performance.