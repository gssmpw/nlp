@article{bohnet2024exploring,
  title={Exploring and Benchmarking the Planning Capabilities of Large Language Models},
  author={Bohnet, Bernd and Nova, Azade and Parisi, Aaron T and Swersky, Kevin and Goshvadi, Katayoon and Dai, Hanjun and Schuurmans, Dale and Fiedel, Noah and Sedghi, Hanie},
  journal={arXiv preprint arXiv:2406.13094},
  year={2024}
}

@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

@article{chen2024reprompt,
  title={{RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents}},
  author={Chen, Weizhe and Koenig, Sven and Dilkina, Bistra},
  journal={arXiv preprint arXiv:2406.11132},
  year={2024}
}

@article{lee2025evolving,
  title={Evolving Deeper LLM Thinking},
  author={Lee, Kuang-Huei and Fischer, Ian and Wu, Yueh-Hua and Marwood, Dave and Baluja, Shumeet and Schuurmans, Dale and Chen, Xinyun},
  journal={arXiv preprint arXiv:2501.09891},
  year={2025}
}

@article{liu2024tool,
  title={{Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering}},
  author={Liu, Yanming and Peng, Xinyue and Zhang, Yuwei and Cao, Jiannan and Zhang, Xuhong and Cheng, Sheng and Wang, Xun and Yin, Jianwei and Du, Tianyu},
  journal={arXiv preprint arXiv:2406.03807},
  year={2024}
}

@inproceedings{snell2024scaling,
title={Scaling Test-Time Compute Optimally Can be More Effective than Scaling {LLM} Parameters},
author={Charlie Victor Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=4FWAwZtd2n}
}

@inproceedings{wang2024promptagent,
title={PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization},
author={Xinyuan Wang and Chenxi Li and Zhen Wang and Fan Bai and Haotian Luo and Jiayou Zhang and Nebojsa Jojic and Eric Xing and Zhiting Hu},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=22pyNMuIoa}
}

@article{wang2024sibyl,
  title={Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning},
  author={Wang, Yulong and Shen, Tianhao and Liu, Lifeng and Xie, Jian},
  journal={CoRR},
  year={2024}
}

@inproceedings{wang2025planning,
title={Planning in Natural Language Improves {LLM} Search for Code Generation},
author={Evan Z Wang and Federico Cassano and Catherine Wu and Yunfeng Bai and William Song and Vaskar Nath and Ziwen Han and Sean M. Hendryx and Summer Yue and Hugh Zhang},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=48WAZhwHHw}
}

@inproceedings{wu2024copilot,
  title={OS-Copilot: Towards Generalist Computer Agents with Self-Improvement},
  author={Wu, Zhiyong and Han, Chengcheng and Ding, Zichen and Weng, Zhenmin and Liu, Zhoumianze and Yao, Shunyu and Yu, Tao and Kong, Lingpeng},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2024}
}

@article{wu2024empirical,
  title={An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models},
  author={Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  journal={CoRR},
  year={2024}
}

@article{xie2024human,
  title={A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models},
  author={Xie, Chengxing and Zou, Difan},
  journal={arXiv preprint arXiv:2405.18208},
  year={2024}
}

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhang2024accessing,
  title={Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree self-refine with llama-3 8b},
  author={Zhang, Di and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2406.07394},
  year={2024}
}

@article{zhu2024knowagent,
  title={Knowagent: Knowledge-augmented planning for llm-based agents},
  author={Zhu, Yuqi and Qiao, Shuofei and Ou, Yixin and Deng, Shumin and Zhang, Ningyu and Lyu, Shiwei and Shen, Yue and Liang, Lei and Gu, Jinjie and Chen, Huajun},
  journal={arXiv preprint arXiv:2403.03101},
  year={2024}
}

