@article{agboladeSyndromeFaceRecognition2020,
  title = {Down {{Syndrome Face Recognition}}: {{A Review}}},
  shorttitle = {Down {{Syndrome Face Recognition}}},
  author = {Agbolade, Olalekan and Nazri, Azree and Yaakob, Razali and Ghani, Abdul Azim and Cheah, Yoke Kqueen},
  year = {2020},
  month = jul,
  journal = {Symmetry},
  volume = {12},
  number = {7},
  pages = {1182},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2073-8994},
  doi = {10.3390/sym12071182},
  abstract = {One of the most pertinent applications of image analysis is face recognition and one of the most common genetic disorders is Down syndrome (DS), which is caused by chromosome abnormalities in humans. It is currently a challenge in computer vision in the domain of DS face recognition to build an automated system that equals the human ability to recognize face as one of the symmetrical structures in the body. Consequently, the use of machine learning methods has facilitated the recognition of facial dysmorphic features associated with DS. This paper aims to present a concise review of DS face recognition using the currently published literature by following the generic face recognition pipeline (face detection, feature extraction, and classification) and to identify critical knowledge gaps and directions for future research. The technologies underlying facial analysis presented in recent studies have helped expert clinicians in general genetic disorders and DS prediction.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computer vision,Down syndrome,face dysmorphology,face recognition}
}

@inproceedings{buolamwiniGenderShadesIntersectional2018,
  title = {Gender {{Shades}}: {{Intersectional Accuracy Disparities}} in {{Commercial Gender Classification}}},
  shorttitle = {Gender {{Shades}}},
  booktitle = {Proceedings of the 1st {{Conference}} on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  author = {Buolamwini, Joy and Gebru, Timnit},
  year = {2018},
  month = jan,
  pages = {77--91},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v81/buolamwini18a.html},
  abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist  approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6\% for IJB-A and 86.2\% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7\%). The maximum error rate for lighter-skinned males is 0.8\%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
  langid = {english}
}

@book{crawfordAtlasAI2021,
  title = {The {{Atlas}} of {{AI}}},
  author = {Crawford, Kate},
  year = {2021},
  publisher = {{Yale University Press}},
  isbn = {978-0-300-25239-2}
}

@article{kazemiSyndromeCurrentStatus2016,
  title = {Down {{Syndrome}}: {{Current Status}}, {{Challenges}} and {{Future Perspectives}}},
  shorttitle = {Down {{Syndrome}}},
  author = {Kazemi, Mohammad and Salehi, Mansoor and Kheirollahi, Majid},
  year = {2016},
  journal = {International Journal of Molecular and Cellular Medicine},
  volume = {5},
  number = {3},
  pages = {125--133},
  issn = {2251-9637},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5125364/},
  abstract = {Down syndrome (DS) is a birth defect with huge medical and social costs, caused by trisomy of whole or part of chromosome 21. It is the most prevalent genetic disease worldwide and the common genetic cause of intellectual disabilities appearing in about 1 in 400-1500 newborns. Although the syndrome had been described thousands of years before, it was named after John Langdon Down who described its clinical description in 1866. Scientists have identified candidate genes that are involved in the formation of specific DS features. These advances in turn may help to develop targeted therapy for persons with trisomy 21. Screening for DS is an important part of routine prenatal care. Until recently, noninvasive screening for aneuploidy depends on the measurement of maternal serum analytes and ultrasonography. More recent progress has resulted in the development of noninvasive prenatal screening (NIPS) test using cell-free fetal DNA sequences isolated from a maternal blood sample. A review on those achievements is discussed.},
  pmcid = {PMC5125364},
  pmid = {27942498}
}

@article{keyesMisgenderingMachinesTrans2018,
  title = {The {{Misgendering Machines}}: {{Trans}}/{{HCI Implications}} of {{Automatic Gender Recognition}}},
  shorttitle = {The {{Misgendering Machines}}},
  author = {Keyes, Os},
  year = {2018},
  month = nov,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {2},
  number = {CSCW},
  pages = {88:1--88:22},
  doi = {10.1145/3274357},
  abstract = {Automatic Gender Recognition (AGR) is a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos. In wider society the technology has proposed applications in physical access control, data analytics and advertising. Within academia, it is already used in the field of Human-Computer Interaction (HCI) to analyse social media usage. Given the long-running critiques of HCI for failing to consider and include transgender (trans) perspectives in research, and the potential implications of AGR for trans people if deployed, I sought to understand how AGR and HCI understand the term "gender", and how HCI describes and deploys gender recognition technology. Using a content analysis of papers from both fields, I show that AGR consistently operationalises gender in a trans-exclusive way, and consequently carries disproportionate risk for trans people subject to it. In addition, I use the dearth of discussion of this in HCI papers that apply AGR to discuss how HCI operationalises gender, and the implications that this has for the field's research. I conclude with recommendations for alternatives to AGR, and some ideas for how HCI can work towards a more effective and trans-inclusive treatment of gender.},
  keywords = {automatic gender recognition,gender,machine learning,transgender}
}

@article{klareFaceRecognitionPerformance2012,
  title = {Face {{Recognition Performance}}: {{Role}} of {{Demographic Information}}},
  shorttitle = {Face {{Recognition Performance}}},
  author = {Klare, Brendan F. and Burge, Mark J. and Klontz, Joshua C. and Vorder Bruegge, Richard W. and Jain, Anil K.},
  year = {2012},
  month = dec,
  journal = {IEEE Transactions on Information Forensics and Security},
  volume = {7},
  number = {6},
  pages = {1789--1801},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2012.2214212},
  abstract = {This paper studies the influence of demographics on the performance of face recognition algorithms. The recognition accuracies of six different face recognition algorithms (three commercial, two nontrainable, and one trainable) are computed on a large scale gallery that is partitioned so that each partition consists entirely of specific demographic cohorts. Eight total cohorts are isolated based on gender (male and female), race/ethnicity (Black, White, and Hispanic), and age group (18\textendash 30, 30\textendash 50, and 50\textendash 70 years old). Experimental results demonstrate that both commercial and the nontrainable algorithms consistently have lower matching accuracies on the same cohorts (females, Blacks, and age group 18\textendash 30) than the remaining cohorts within their demographic. Additional experiments investigate the impact of the demographic distribution in the training set on the performance of a trainable face recognition algorithm. We show that the matching accuracy for race/ethnicity and age cohorts can be improved by training exclusively on that specific cohort. Operationally, this leads to a scenario, called dynamic face matcher selection, where multiple face recognition algorithms (each trained on different demographic cohorts) are available for a biometric system operator to select based on the demographic information extracted from a probe image. This procedure should lead to improved face recognition accuracy in many intelligence and law enforcement face recognition scenarios. Finally, we show that an alternative to dynamic face matcher selection is to train face recognition algorithms on datasets that are evenly distributed across demographics, as this approach offers consistently high accuracy across all cohorts.},
  keywords = {Age,Algorithm design and analysis,Cultural differences,demographics,Demographics,dynamic face matcher selection,face recognition,Face recognition,gender,race/ethnicity,training,Training,Training data}
}

@misc{muthukumarUnderstandingUnequalGender2018,
  title = {Understanding {{Unequal Gender Classification Accuracy}} from {{Face Images}}},
  author = {Muthukumar, Vidya and Pedapati, Tejaswini and Ratha, Nalini and Sattigeri, Prasanna and Wu, Chai-Wah and Kingsbury, Brian and Kumar, Abhishek and Thomas, Samuel and Mojsilovic, Aleksandra and Varshney, Kush R.},
  year = {2018},
  month = nov,
  number = {arXiv:1812.00099},
  eprint = {1812.00099},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1812.00099},
  abstract = {Recent work shows unequal performance of commercial face classification services in the gender classification task across intersectional groups defined by skin type and gender. Accuracy on dark-skinned females is significantly worse than on any other group. In this paper, we conduct several analyses to try to uncover the reason for this gap. The main finding, perhaps surprisingly, is that skin type is not the driver. This conclusion is reached via stability experiments that vary an image's skin type via color-theoretic methods, namely luminance mode-shift and optimal transport. A second suspect, hair length, is also shown not to be the driver via experiments on face images cropped to exclude the hair. Finally, using contrastive post-hoc explanation techniques for neural networks, we bring forth evidence suggesting that differences in lip, eye and cheek structure across ethnicity lead to the differences. Further, lip and eye makeup are seen as strong predictors for a female face, which is a troubling propagation of a gender stereotype.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Statistics - Machine Learning}
}

@article{paredesEmotionRecognitionSyndrome2022,
  title = {Emotion {{Recognition}} of {{Down Syndrome People Based}} on the {{Evaluation}} of {{Artificial Intelligence}} and {{Statistical Analysis Methods}}},
  author = {Paredes, Nancy and {Caicedo-Bravo}, Eduardo F. and Bacca, Bladimir and Olmedo, Gonzalo},
  year = {2022},
  month = dec,
  journal = {Symmetry},
  volume = {14},
  number = {12},
  pages = {2492},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2073-8994},
  doi = {10.3390/sym14122492},
  abstract = {This article presents a study based on evaluating different techniques to automatically recognize the basic emotions of people with Down syndrome, such as anger, happiness, sadness, surprise, and neutrality, as well as the statistical analysis of the Facial Action Coding System, determine the symmetry of the Action Units present in each emotion, identify the facial features that represent this group of people. First, a dataset of images of faces of people with Down syndrome classified according to their emotions is built. Then, the characteristics of facial micro-expressions (Action Units) present in the feelings of the target group through statistical analysis are evaluated. This analysis uses the intensity values of the most representative exclusive action units to classify people's emotions. Subsequently, the collected dataset was evaluated using machine learning and deep learning techniques to recognize emotions. In the beginning, different supervised learning techniques were used, with the Support Vector Machine technique obtaining the best precision with a value of 66.20\%. In the case of deep learning methods, the mini-Xception convolutional neural network was used to recognize people's emotions with typical development, obtaining an accuracy of 74.8\%.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {action units,down syndrome,probabilities,transfer learning}
}

@article{qinAutomaticIdentificationSyndrome2020,
  title = {Automatic {{Identification}} of {{Down Syndrome Using Facial Images}} with {{Deep Convolutional Neural Network}}},
  author = {Qin, Bosheng and Liang, Letian and Wu, Jingchao and Quan, Qiyao and Wang, Zeyu and Li, Dongxiao},
  year = {2020},
  month = jul,
  journal = {Diagnostics},
  volume = {10},
  number = {7},
  pages = {487},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2075-4418},
  doi = {10.3390/diagnostics10070487},
  abstract = {Down syndrome is one of the most common genetic disorders. The distinctive facial features of Down syndrome provide an opportunity for automatic identification. Recent studies showed that facial recognition technologies have the capability to identify genetic disorders. However, there is a paucity of studies on the automatic identification of Down syndrome with facial recognition technologies, especially using deep convolutional neural networks. Here, we developed a Down syndrome identification method utilizing facial images and deep convolutional neural networks, which quantified the binary classification problem of distinguishing subjects with Down syndrome from healthy subjects based on unconstrained two-dimensional images. The network was trained in two main steps: First, we formed a general facial recognition network using a large-scale face identity database (10,562 subjects) and then trained (70\%) and tested (30\%) a dataset of 148 Down syndrome and 257 healthy images curated through public databases. In the final testing, the deep convolutional neural network achieved 95.87\% accuracy, 93.18\% recall, and 97.40\% specificity in Down syndrome identification. Our findings indicate that the deep convolutional neural network has the potential to support the fast, accurate, and fully automatic identification of Down syndrome and could add considerable value to the future of precision medicine.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {deep convolutional neural network,deep learning,down syndrome,facial image,facial recognition}
}

@article{scheuermanHowComputersSee2019,
  title = {How {{Computers See Gender}}: {{An Evaluation}} of {{Gender Classification}} in {{Commercial Facial Analysis Services}}},
  shorttitle = {How {{Computers See Gender}}},
  author = {Scheuerman, Morgan Klaus and Paul, Jacob M. and Brubaker, Jed R.},
  year = {2019},
  month = nov,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {3},
  number = {CSCW},
  pages = {144:1--144:33},
  doi = {10.1145/3359246},
  abstract = {Investigations of facial analysis (FA) technologies-such as facial detection and facial recognition-have been central to discussions about Artificial Intelligence's (AI) impact on human beings. Research on automatic gender recognition, the classification of gender by FA technologies, has raised potential concerns around issues of racial and gender bias. In this study, we augment past work with empirical data by conducting a systematic analysis of how gender classification and gender labeling in computer vision services operate when faced with gender diversity. We sought to understand how gender is concretely conceptualized and encoded into commercial facial analysis and image labeling technologies available today. We then conducted a two-phase study: (1) a system analysis of ten commercial FA and image labeling services and (2) an evaluation of five services using a custom dataset of diverse genders using self-labeled Instagram images. Our analysis highlights how gender is codified into both classifiers and data standards. We found that FA services performed consistently worse on transgender individuals and were universally unable to classify non-binary genders. In contrast, image labeling often presented multiple gendered concepts. We also found that user perceptions about gender performance and identity contradict the way gender performance is encoded into the computer vision infrastructure. We discuss our findings from three perspectives of gender identity (self-identity, gender performativity, and demographic identity) and how these perspectives interact across three layers: the classification infrastructure, the third-party applications that make use of that infrastructure, and the individuals who interact with that software. We employ Bowker and Star's concepts of "torque" and "residuality" to further discuss the social implications of gender classification. We conclude by outlining opportunities for creating more inclusive classification infrastructures and datasets, as well as with implications for policy.},
  keywords = {classification,computer vision,facial analysis,facial detection,facial recognition,gender,identity,image labeling,Instagram}
}

