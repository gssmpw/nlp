@article{agboladeSyndromeFaceRecognition2020,
  title = {Down {{Syndrome Face Recognition}}: {{A Review}}},
  shorttitle = {Down {{Syndrome Face Recognition}}},
  author = {Agbolade, Olalekan and Nazri, Azree and Yaakob, Razali and Ghani, Abdul Azim and Cheah, Yoke Kqueen},
  year = {2020},
  month = jul,
  journal = {Symmetry},
  volume = {12},
  number = {7},
  pages = {1182},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2073-8994},
  doi = {10.3390/sym12071182},
  abstract = {One of the most pertinent applications of image analysis is face recognition and one of the most common genetic disorders is Down syndrome (DS), which is caused by chromosome abnormalities in humans. It is currently a challenge in computer vision in the domain of DS face recognition to build an automated system that equals the human ability to recognize face as one of the symmetrical structures in the body. Consequently, the use of machine learning methods has facilitated the recognition of facial dysmorphic features associated with DS. This paper aims to present a concise review of DS face recognition using the currently published literature by following the generic face recognition pipeline (face detection, feature extraction, and classification) and to identify critical knowledge gaps and directions for future research. The technologies underlying facial analysis presented in recent studies have helped expert clinicians in general genetic disorders and DS prediction.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computer vision,Down syndrome,face dysmorphology,face recognition}
}

@inproceedings{buolamwiniGenderShadesIntersectional2018,
  title = {Gender {{Shades}}: {{Intersectional Accuracy Disparities}} in {{Commercial Gender Classification}}},
  shorttitle = {Gender {{Shades}}},
  booktitle = {Proceedings of the 1st {{Conference}} on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  author = {Buolamwini, Joy and Gebru, Timnit},
  year = {2018},
  month = jan,
  pages = {77--91},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v81/buolamwini18a.html},
  abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist  approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6\% for IJB-A and 86.2\% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7\%). The maximum error rate for lighter-skinned males is 0.8\%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
  langid = {english}
}

@article{congerSanFranciscoBans2019,
  title = {San {{Francisco Bans Facial Recognition Technology}}},
  author = {Conger, Kate and Fausset, Richard and Kovaleski, Serge F.},
  year = {2019},
  month = may,
  journal = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2019/05/14/us/facial-recognition-ban-san-francisco.html},
  abstract = {It is the first ban by a major city on the use of facial recognition technology by the police and all other municipal agencies.},
  chapter = {U.S.},
  langid = {american},
  keywords = {Computer Vision,Face,Police,Politics and Government,Privacy,San Francisco (Calif),Surveillance of Citizens by Government}
}

@book{crawfordAtlasAI2021,
  title = {The {{Atlas}} of {{AI}}},
  author = {Crawford, Kate},
  year = {2021},
  publisher = {{Yale University Press}},
  isbn = {978-0-300-25239-2}
}

@misc{europeancommissionProposalRegulationEuropean2021,
  title = {{Proposal for a regulation of the European Parliament and of the council laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts}},
  author = {{European Commission}},
  year = {2021},
  url = {https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:52021PC0206},
  langid = {italian}
}

@book{europeanparliamentRegulatingFacialRecognition2021,
  title = {Regulating Facial Recognition in the {{EU}}: In Depth Analysis},
  shorttitle = {Regulating Facial Recognition in the {{EU}}},
  author = {{European Parliament} and {Directorate-General for Parliamentary Research Services} and Madiega, Tambiama and Mildebrath, Hendrik},
  year = {2021},
  publisher = {{Publications Office of the European Union}},
  address = {{LU}},
  url = {https://data.europa.eu/doi/10.2861/140928},
  abstract = {The European Union is considering regulating facial recognition in the proposed artificial intelligence act, currently under discussion. This EPRS publication explains the state of play and further highlights the concerns raised by the use and the potential impacts on people's fundamental rights of facial recognition technologies. Against this background, the paper explores the current EU legal framework applicable to facial recognition and examines the recent proposals for regulating facial recognition technologies at EU level in depth.},
  isbn = {978-92-846-8503-5},
  langid = {english},
  lccn = {QA-01-21-197-EN-N}
}

@article{fitzpatrickValidityPracticalitySunReactive1988,
  title = {The {{Validity}} and {{Practicality}} of {{Sun-Reactive Skin Types I Through VI}}},
  author = {Fitzpatrick, Thomas B.},
  year = {1988},
  month = jun,
  journal = {Archives of Dermatology},
  volume = {124},
  number = {6},
  pages = {869--871},
  issn = {0003-987X},
  doi = {10.1001/archderm.1988.01670060015008},
  abstract = {The concept of sun-reactive "skin typing" was created in 19751 for a specific need: to be able to classify persons with white skin in order to select the correct initial doses of ultraviolet A (UVA) (in joules per cubic centimeter) in the application of the then newly developed technique for the treatment of psoriasis\textemdash oral methoxsalen photochemotherapy (PUVA).2 The need arose as a result of experience with several patients who were a "dark" phenotype (brown or even black hair, and some with brown eyes) but, to our surprise, developed severe phototoxic reactions following oral ingestion of 0.6 mg/kg of methoxsalen and then, two hours later, were exposed to 4 to 6 J/cm2. These initial doses were obviously too high, and it was then understood that the estimation of the white-skinned person's tolerance level to oral PUVA could not be based solely on the phenotype (hair and eye color).}
}

@article{hillMicrosoftPlansEliminate2022,
  title = {Microsoft {{Plans}} to {{Eliminate Face Analysis Tools}} in {{Push}} for `{{Responsible A}}.{{I}}.'},
  author = {Hill, Kashmir},
  year = {2022},
  month = jun,
  journal = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2022/06/21/technology/microsoft-facial-recognition.html},
  abstract = {The technology giant will stop offering automated tools that predict a person's gender, age and emotional state and will restrict the use of its facial recognition tool.},
  chapter = {Technology},
  langid = {american},
  keywords = {Artificial Intelligence,Computers and the Internet,Corporate Social Responsibility,emergingtech,Facial Recognition Software,Gender,Microsoft Corp,Race and Ethnicity}
}

@article{kazemiSyndromeCurrentStatus2016,
  title = {Down {{Syndrome}}: {{Current Status}}, {{Challenges}} and {{Future Perspectives}}},
  shorttitle = {Down {{Syndrome}}},
  author = {Kazemi, Mohammad and Salehi, Mansoor and Kheirollahi, Majid},
  year = {2016},
  journal = {International Journal of Molecular and Cellular Medicine},
  volume = {5},
  number = {3},
  pages = {125--133},
  issn = {2251-9637},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5125364/},
  abstract = {Down syndrome (DS) is a birth defect with huge medical and social costs, caused by trisomy of whole or part of chromosome 21. It is the most prevalent genetic disease worldwide and the common genetic cause of intellectual disabilities appearing in about 1 in 400-1500 newborns. Although the syndrome had been described thousands of years before, it was named after John Langdon Down who described its clinical description in 1866. Scientists have identified candidate genes that are involved in the formation of specific DS features. These advances in turn may help to develop targeted therapy for persons with trisomy 21. Screening for DS is an important part of routine prenatal care. Until recently, noninvasive screening for aneuploidy depends on the measurement of maternal serum analytes and ultrasonography. More recent progress has resulted in the development of noninvasive prenatal screening (NIPS) test using cell-free fetal DNA sequences isolated from a maternal blood sample. A review on those achievements is discussed.},
  pmcid = {PMC5125364},
  pmid = {27942498}
}

@article{keyesMisgenderingMachinesTrans2018,
  title = {The {{Misgendering Machines}}: {{Trans}}/{{HCI Implications}} of {{Automatic Gender Recognition}}},
  shorttitle = {The {{Misgendering Machines}}},
  author = {Keyes, Os},
  year = {2018},
  month = nov,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {2},
  number = {CSCW},
  pages = {88:1--88:22},
  doi = {10.1145/3274357},
  abstract = {Automatic Gender Recognition (AGR) is a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos. In wider society the technology has proposed applications in physical access control, data analytics and advertising. Within academia, it is already used in the field of Human-Computer Interaction (HCI) to analyse social media usage. Given the long-running critiques of HCI for failing to consider and include transgender (trans) perspectives in research, and the potential implications of AGR for trans people if deployed, I sought to understand how AGR and HCI understand the term "gender", and how HCI describes and deploys gender recognition technology. Using a content analysis of papers from both fields, I show that AGR consistently operationalises gender in a trans-exclusive way, and consequently carries disproportionate risk for trans people subject to it. In addition, I use the dearth of discussion of this in HCI papers that apply AGR to discuss how HCI operationalises gender, and the implications that this has for the field's research. I conclude with recommendations for alternatives to AGR, and some ideas for how HCI can work towards a more effective and trans-inclusive treatment of gender.},
  keywords = {automatic gender recognition,gender,machine learning,transgender}
}

@article{klareFaceRecognitionPerformance2012,
  title = {Face {{Recognition Performance}}: {{Role}} of {{Demographic Information}}},
  shorttitle = {Face {{Recognition Performance}}},
  author = {Klare, Brendan F. and Burge, Mark J. and Klontz, Joshua C. and Vorder Bruegge, Richard W. and Jain, Anil K.},
  year = {2012},
  month = dec,
  journal = {IEEE Transactions on Information Forensics and Security},
  volume = {7},
  number = {6},
  pages = {1789--1801},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2012.2214212},
  abstract = {This paper studies the influence of demographics on the performance of face recognition algorithms. The recognition accuracies of six different face recognition algorithms (three commercial, two nontrainable, and one trainable) are computed on a large scale gallery that is partitioned so that each partition consists entirely of specific demographic cohorts. Eight total cohorts are isolated based on gender (male and female), race/ethnicity (Black, White, and Hispanic), and age group (18\textendash 30, 30\textendash 50, and 50\textendash 70 years old). Experimental results demonstrate that both commercial and the nontrainable algorithms consistently have lower matching accuracies on the same cohorts (females, Blacks, and age group 18\textendash 30) than the remaining cohorts within their demographic. Additional experiments investigate the impact of the demographic distribution in the training set on the performance of a trainable face recognition algorithm. We show that the matching accuracy for race/ethnicity and age cohorts can be improved by training exclusively on that specific cohort. Operationally, this leads to a scenario, called dynamic face matcher selection, where multiple face recognition algorithms (each trained on different demographic cohorts) are available for a biometric system operator to select based on the demographic information extracted from a probe image. This procedure should lead to improved face recognition accuracy in many intelligence and law enforcement face recognition scenarios. Finally, we show that an alternative to dynamic face matcher selection is to train face recognition algorithms on datasets that are evenly distributed across demographics, as this approach offers consistently high accuracy across all cohorts.},
  keywords = {Age,Algorithm design and analysis,Cultural differences,demographics,Demographics,dynamic face matcher selection,face recognition,Face recognition,gender,race/ethnicity,training,Training,Training data}
}

@misc{krishnaIBMCEOLetter2019,
  title = {{{IBM CEO}}'s {{Letter}} to {{Congress}} on {{Racial Justice Reform}}},
  author = {Krishna, Arvind},
  year = {2019},
  month = dec,
  url = {https://www.ibm.com/policy/facial-recognition-sunset-racial-justice-reforms/},
  langid = {american}
}

@article{melendezUberDriverTroubles2018,
  title = {Uber Driver Troubles Raise Concerns about Transgender Face Recognition},
  author = {Melendez, Steven},
  year = {2018},
  month = aug,
  journal = {Fast Company},
  url = {https://www.fastcompany.com/90216258/uber-face-recognition-tool-has-locked-out-some-transgender-drivers},
  abstract = {Uber's Microsoft-powered Real Time ID Check has locked out some drivers, signaling future struggles as facial-recognition technology becomes more prevalent.}
}

@misc{merlerDiversityFaces2019,
  title = {Diversity in {{Faces}}},
  author = {Merler, Michele and Ratha, Nalini and Feris, Rogerio S. and Smith, John R.},
  year = {2019},
  month = apr,
  number = {arXiv:1901.10436},
  eprint = {1901.10436},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1901.10436},
  abstract = {Face recognition is a long standing challenge in the field of Artificial Intelligence (AI). The goal is to create systems that accurately detect, recognize, verify, and understand human faces. There are significant technical hurdles in making these systems accurate, particularly in unconstrained settings due to confounding factors related to pose, resolution, illumination, occlusion, and viewpoint. However, with recent advances in neural networks, face recognition has achieved unprecedented accuracy, largely built on data-driven deep learning methods. While this is encouraging, a critical aspect that is limiting facial recognition accuracy and fairness is inherent facial diversity. Every face is different. Every face reflects something unique about us. Aspects of our heritage - including race, ethnicity, culture, geography - and our individual identify - age, gender, and other visible manifestations of self-expression, are reflected in our faces. We expect face recognition to work equally accurately for every face. Face recognition needs to be fair. As we rely on data-driven methods to create face recognition technology, we need to ensure necessary balance and coverage in training data. However, there are still scientific questions about how to represent and extract pertinent facial features and quantitatively measure facial diversity. Towards this goal, Diversity in Faces (DiF) provides a data set of one million annotated human face images for advancing the study of facial diversity. The annotations are generated using ten well-established facial coding schemes from the scientific literature. The facial coding schemes provide human-interpretable quantitative measures of facial features. We believe that by making the extracted coding schemes available on a large set of faces, we can accelerate research and development towards creating more fair and accurate facial recognition systems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{muthukumarUnderstandingUnequalGender2018,
  title = {Understanding {{Unequal Gender Classification Accuracy}} from {{Face Images}}},
  author = {Muthukumar, Vidya and Pedapati, Tejaswini and Ratha, Nalini and Sattigeri, Prasanna and Wu, Chai-Wah and Kingsbury, Brian and Kumar, Abhishek and Thomas, Samuel and Mojsilovic, Aleksandra and Varshney, Kush R.},
  year = {2018},
  month = nov,
  number = {arXiv:1812.00099},
  eprint = {1812.00099},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1812.00099},
  abstract = {Recent work shows unequal performance of commercial face classification services in the gender classification task across intersectional groups defined by skin type and gender. Accuracy on dark-skinned females is significantly worse than on any other group. In this paper, we conduct several analyses to try to uncover the reason for this gap. The main finding, perhaps surprisingly, is that skin type is not the driver. This conclusion is reached via stability experiments that vary an image's skin type via color-theoretic methods, namely luminance mode-shift and optimal transport. A second suspect, hair length, is also shown not to be the driver via experiments on face images cropped to exclude the hair. Finally, using contrastive post-hoc explanation techniques for neural networks, we bring forth evidence suggesting that differences in lip, eye and cheek structure across ethnicity lead to the differences. Further, lip and eye makeup are seen as strong predictors for a female face, which is a troubling propagation of a gender stereotype.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Statistics - Machine Learning}
}

@article{paredesEmotionRecognitionSyndrome2022,
  title = {Emotion {{Recognition}} of {{Down Syndrome People Based}} on the {{Evaluation}} of {{Artificial Intelligence}} and {{Statistical Analysis Methods}}},
  author = {Paredes, Nancy and {Caicedo-Bravo}, Eduardo F. and Bacca, Bladimir and Olmedo, Gonzalo},
  year = {2022},
  month = dec,
  journal = {Symmetry},
  volume = {14},
  number = {12},
  pages = {2492},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2073-8994},
  doi = {10.3390/sym14122492},
  abstract = {This article presents a study based on evaluating different techniques to automatically recognize the basic emotions of people with Down syndrome, such as anger, happiness, sadness, surprise, and neutrality, as well as the statistical analysis of the Facial Action Coding System, determine the symmetry of the Action Units present in each emotion, identify the facial features that represent this group of people. First, a dataset of images of faces of people with Down syndrome classified according to their emotions is built. Then, the characteristics of facial micro-expressions (Action Units) present in the feelings of the target group through statistical analysis are evaluated. This analysis uses the intensity values of the most representative exclusive action units to classify people's emotions. Subsequently, the collected dataset was evaluated using machine learning and deep learning techniques to recognize emotions. In the beginning, different supervised learning techniques were used, with the Support Vector Machine technique obtaining the best precision with a value of 66.20\%. In the case of deep learning methods, the mini-Xception convolutional neural network was used to recognize people's emotions with typical development, obtaining an accuracy of 74.8\%.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {action units,down syndrome,probabilities,transfer learning}
}

@misc{parlamentoitalianoTestoCoordinatoDecretolegge2021,
  title = {Testo {{Coordinato}} Del {{Decreto-legge}} 8 Ottobre 2021, n. 139, Recante ``{{Disposizioni}} Urgenti per l'accesso Alle Attivita' Culturali, Sportive e Ricreative, Nonche' per l'organizzazione Di Pubbliche Amministrazioni e in Materia Di Protezione Dei Dati Personali.''},
  author = {{Parlamento Italiano}},
  year = {2021},
  month = oct,
  url = {www.gazzettaufficiale.it/eli/id/2021/12/07/21A07259/sg},
  abstract = {Testo del decreto-legge 8 ottobre 2021, n. 139 (pubblicato nella Gazzetta Ufficiale 8 ottobre 2021, n. 241), coordinato con la legge di conversione 3 dicembre 2021, n. 205 (in questa stessa Gazzetta Ufficiale alla pag. 1), recante "Disposizioni urgenti per l'accesso alle attivita' culturali, sportive e ricreative, nonche' per l'organizzazione di pubbliche amministrazioni e in materia di protezione dei dati personali.". (21A07259) (GU Serie Generale n.291 del 07-12-2021)}
}

@inproceedings{phillipsIntroductionGoodBad2011,
  title = {An Introduction to the Good, the Bad, \& the Ugly Face Recognition Challenge Problem},
  booktitle = {2011 {{IEEE International Conference}} on {{Automatic Face}} \& {{Gesture Recognition}} ({{FG}})},
  author = {Phillips, P. Jonathon and Beveridge, J. Ross and Draper, Bruce A. and Givens, Geof and O'Toole, Alice J. and Bolme, David S. and Dunlop, Joseph and Lui, Yui Man and Sahibzada, Hassan and Weimer, Samuel},
  year = {2011},
  month = mar,
  pages = {346--353},
  doi = {10.1109/FG.2011.5771424},
  abstract = {The Good, the Bad, \& the Ugly Face Challenge Problem was created to encourage the development of algorithms that are robust to recognition across changes that occur in still frontal faces. The Good, the Bad, \& the Ugly consists of three partitions. The Good partition contains pairs of images that are considered easy to recognize. On the Good partition, the base verification rate (VR) is 0.98 at a false accept rate (FAR) of 0.001. The Bad partition contains pairs of images of average difficulty to recognize. For the Bad partition, the VR is 0.80 at a FAR of 0.001. The Ugly partition contains pairs of images considered difficult to recognize, with a VR of 0.15 at a FAR of 0.001. The base performance is from fusing the output of three of the top performers in the FRVT 2006. The design of the Good, the Bad, \& the Ugly controls for pose variation, subject aging, and subject ``recognizability.'' Subject recognizability is controlled by having the same number of images of each subject in every partition. This implies that the differences in performance among the partitions are result of how a face is presented in each image.},
  keywords = {Algorithm design and analysis,Face,Face recognition,Image recognition,Partitioning algorithms,Protocols,Training}
}

@article{qinAutomaticIdentificationSyndrome2020,
  title = {Automatic {{Identification}} of {{Down Syndrome Using Facial Images}} with {{Deep Convolutional Neural Network}}},
  author = {Qin, Bosheng and Liang, Letian and Wu, Jingchao and Quan, Qiyao and Wang, Zeyu and Li, Dongxiao},
  year = {2020},
  month = jul,
  journal = {Diagnostics},
  volume = {10},
  number = {7},
  pages = {487},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2075-4418},
  doi = {10.3390/diagnostics10070487},
  abstract = {Down syndrome is one of the most common genetic disorders. The distinctive facial features of Down syndrome provide an opportunity for automatic identification. Recent studies showed that facial recognition technologies have the capability to identify genetic disorders. However, there is a paucity of studies on the automatic identification of Down syndrome with facial recognition technologies, especially using deep convolutional neural networks. Here, we developed a Down syndrome identification method utilizing facial images and deep convolutional neural networks, which quantified the binary classification problem of distinguishing subjects with Down syndrome from healthy subjects based on unconstrained two-dimensional images. The network was trained in two main steps: First, we formed a general facial recognition network using a large-scale face identity database (10,562 subjects) and then trained (70\%) and tested (30\%) a dataset of 148 Down syndrome and 257 healthy images curated through public databases. In the final testing, the deep convolutional neural network achieved 95.87\% accuracy, 93.18\% recall, and 97.40\% specificity in Down syndrome identification. Our findings indicate that the deep convolutional neural network has the potential to support the fast, accurate, and fully automatic identification of Down syndrome and could add considerable value to the future of precision medicine.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {deep convolutional neural network,deep learning,down syndrome,facial image,facial recognition}
}

@misc{sanfranciscoboardofsupervisorsOrdinanceNo107192019,
  title = {Ordinance {{No}}. 107-19, {{Chapter 19B}}: {{Acquisition}} of Surveillance Technology},
  shorttitle = {Acquisition of Surveillance Technology},
  author = {{San Francisco Board of Supervisors}},
  year = {2019},
  month = may,
  url = {https://codelibrary.amlegal.com/codes/san_francisco/latest/sf_admin/0-0-0-47320},
  abstract = {Legal publisher offering ordinance codification services for local governments, specializing in providing codes of ordinances in print and on the Internet.},
  langid = {american}
}

@article{scheuermanHowComputersSee2019,
  title = {How {{Computers See Gender}}: {{An Evaluation}} of {{Gender Classification}} in {{Commercial Facial Analysis Services}}},
  shorttitle = {How {{Computers See Gender}}},
  author = {Scheuerman, Morgan Klaus and Paul, Jacob M. and Brubaker, Jed R.},
  year = {2019},
  month = nov,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {3},
  number = {CSCW},
  pages = {144:1--144:33},
  doi = {10.1145/3359246},
  abstract = {Investigations of facial analysis (FA) technologies-such as facial detection and facial recognition-have been central to discussions about Artificial Intelligence's (AI) impact on human beings. Research on automatic gender recognition, the classification of gender by FA technologies, has raised potential concerns around issues of racial and gender bias. In this study, we augment past work with empirical data by conducting a systematic analysis of how gender classification and gender labeling in computer vision services operate when faced with gender diversity. We sought to understand how gender is concretely conceptualized and encoded into commercial facial analysis and image labeling technologies available today. We then conducted a two-phase study: (1) a system analysis of ten commercial FA and image labeling services and (2) an evaluation of five services using a custom dataset of diverse genders using self-labeled Instagram images. Our analysis highlights how gender is codified into both classifiers and data standards. We found that FA services performed consistently worse on transgender individuals and were universally unable to classify non-binary genders. In contrast, image labeling often presented multiple gendered concepts. We also found that user perceptions about gender performance and identity contradict the way gender performance is encoded into the computer vision infrastructure. We discuss our findings from three perspectives of gender identity (self-identity, gender performativity, and demographic identity) and how these perspectives interact across three layers: the classification infrastructure, the third-party applications that make use of that infrastructure, and the individuals who interact with that software. We employ Bowker and Star's concepts of "torque" and "residuality" to further discuss the social implications of gender classification. We conclude by outlining opportunities for creating more inclusive classification infrastructures and datasets, as well as with implications for policy.},
  keywords = {classification,computer vision,facial analysis,facial detection,facial recognition,gender,identity,image labeling,Instagram}
}

@misc{UTKFace,
  title = {{{UTKFace}}},
  journal = {UTKFace},
  url = {https://susanqq.github.io/UTKFace/},
  abstract = {Large Scale Face Dataset},
  langid = {american}
}

@article{vincentTransgenderYouTubersHad2017,
  title = {Transgender {{YouTubers}} Had Their Videos Grabbed to Train Facial Recognition Software},
  author = {Vincent, James},
  year = {2017},
  month = aug,
  journal = {The Verge},
  url = {https://www.theverge.com/2017/8/22/16180080/transgender-youtubers-ai-facial-recognition-dataset},
  abstract = {In the race to train AI, researchers are taking data first and asking questions later},
  langid = {american}
}

@techreport{westDiscriminatingSystemsGender2019,
  title = {Discriminating {{Systems}}: {{Gender}}, {{Race}}, and {{Power}} in {{AI}}},
  shorttitle = {Discriminating {{Systems}}},
  author = {West, Sarah Myers and Whittaker, Meredith and Crawford, Kate},
  year = {2019},
  institution = {{AI Now Institute}},
  url = {https://ainowinstitute.org/publication/discriminating-systems-gender-race-and-power-in-ai-2},
  abstract = {The lack of diversity in AI workplaces and biased technologies are deeply interconnected issues.},
  langid = {american}
}

@misc{zhangAgeProgressionRegression2017,
  title = {Age {{Progression}}/{{Regression}} by {{Conditional Adversarial Autoencoder}}},
  author = {Zhang, Zhifei and Song, Yang and Qi, Hairong},
  year = {2017},
  month = mar,
  number = {arXiv:1702.08423},
  eprint = {1702.08423},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1702.08423},
  abstract = {"If I provide you a face image of mine (without telling you the actual age when I took the picture) and a large amount of face images that I crawled (containing labeled faces of different ages but not necessarily paired), can you show me what I would look like when I am 80 or what I was like when I was 5?" The answer is probably a "No." Most existing face aging works attempt to learn the transformation between age groups and thus would require the paired samples as well as the labeled query image. In this paper, we look at the problem from a generative modeling perspective such that no paired samples is required. In addition, given an unlabeled image, the generative model can directly produce the image with desired age attribute. We propose a conditional adversarial autoencoder (CAAE) that learns a face manifold, traversing on which smooth age progression and regression can be realized simultaneously. In CAAE, the face is first mapped to a latent vector through a convolutional encoder, and then the vector is projected to the face manifold conditional on age through a deconvolutional generator. The latent vector preserves personalized face features (i.e., personality) and the age condition controls progression vs. regression. Two adversarial networks are imposed on the encoder and generator, respectively, forcing to generate more photo-realistic faces. Experimental results demonstrate the appealing performance and flexibility of the proposed framework by comparing with the state-of-the-art and ground truth.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}
