% \begin{equation}
% \mathcal{Z}^{\left(i\right)}=L^{\left(i\right)}\left(\mathcal{Z}^{\left(i-1\right)}\right)=\sigma\left( \mathcal{F}^{-1}_{M}\left(\mathcal{W}^{\left(i\right)}\times \mathcal{F}_{M}\left(\mathcal{Z}^{\left(i-1\right)}\right)\right) + F_{Res}^{\left(i\right)}\left(\sigma^{-1}\left(\mathcal{Z}^{\left(i-2\right)}\right)\right)\right),
% \end{equation}
% systems biology
Systems biology provides a framework for mathematically modeling and computationally simulating various biological systems across life science, which strives to interrogate complex biological processes and to understand the underlying molecular, biochemical, and physiological mechanisms that regulate cell behavior and population evolution.  
Generally, chemical reactions and molecular events occurring in a biological system can be systematically formulated into a set of ordinary or partial differential equations (ODEs, PDEs) as a function of time to characterize the temporal and spatial dynamics of genes, mRNAs, proteins, and cells at multiscale levels. 
Yet the promise of systems biology is impeded by its computational complexity, in which the intensive calculations and massive computing resources required to solve large-scale systems and perform quantitative analyses severely slow down the speed of model development and result interpretation \cite{bartocci2016computational, anantharaman2021stably}. 
It is even more challenging for spatial modeling that necessitates space discretizations, resulting in a trade-off between speed and accuracy: coarse grids are faster but less accurate, whereas fine grids are more precise but slower \cite{li2020multipole}. 
Therefore, this paper aims to develop a new computational tool that  enables computational biologists to apply model-based biological discovery to complex systems in an efficient and accurate manner.


% % PINN 
% Recently, the incorporation of machine learning techniques has gained increasing attention as a promising approach to accelerate modeling and simulation in physical, chemical, and biological application scenarios~\cite{snyders2001inductive,mansour2019deep,mitchell2017spatial,feinman2018learning}.
% Among the variety of proposed methods, the Physics-informed Neural Network (PINN)~\cite{raissi2019physics} is currently one of the most popular neural networks that has achieved promising results across a wide range of problems in computational science and engineering~\cite{cai2022physics,misyris2020physics,cai2021physics,ji2021stiff,zanardi2022towards,lu2022deep,lv2021novel,sun2020surrogate,raissi2019deep,jin2021nsfnets,kissas2020machine,sahli2020physics}. 
% PINN uses a neural network to predict the dynamics of a given system by imposing model constraints (differential equations) on the loss function.
% It is essentially a meshless technique that finds solutions to differential equations by transforming the IVP (initial value problem) and BVP (boundary value problem) into an optimization problem. 
% That is, provided with explicit differential equations and initial and boundary conditions, PINN can solve a system without requiring labeled training data (ground truth solutions).
% In the field of systems biology, two methods have been proposed as a domain translation of the PINN technique, such as 
% biologically-informed neural network~\cite{lagergren2020biologically,greene2020biologically} and systems biology-informed deep learning~\cite{yazdani2020systems}.
% Several real biological applications have taken advantage of PINN for model design and analysis, including soft biological tissue model~\cite{liu2020generic}, cardiac activation mapping~\cite{sahli2020physics}, and thrombus material properties~\cite{yin2021non}.


% Although PINN provides an opportunity for integrating biological and physical constraints in machine learning, there are two major deficiencies that hinder its broad application in biological and physical sciences: (i) it sometimes fails to achieve reliable training and correct solutions for complex systems~\cite{krishnapriyan2021characterizing, lu2021deepxde, meng2022physics}, and (ii) it is prone to high computational costs~\cite{anantharaman2021stably,jagtap2020locally,jagtap2020conservative}.
% To address these problems, researchers have been working on developing and optimizing the PINN algorithm.
% A series of domain decomposition-based PINNs (CPINN, DPINN, XPINN) are presented to divide the computational domain into smaller subdomains~\cite{dwivedi2019distributed, jagtap2020conservative, jagtap2021extended}, thereby decomposing complex problems into smaller subproblems that can be solved by minimal size local PINN to solve.
% The gradient-enhanced PINN (GPINN)~\cite{yu2022gradient} performs gradient enhancement on PINN by forcing the derivative of PDEs residual to be zero, which aids in faster convergence and improved accuracy of the model.
% For small sampling data, few-shot learning is added to PINN, in which a neural network is used to train an approximate solution first and further optimized by minimizing the designed cost function~\cite{li2021deep}. 
% % For linear problems, the Bayesian physical extreme machine learning is employed to enhance PINN, which increases the calculation speed by several orders of magnitude~\cite{liu2022bayesian}.
% For stiff problems, Wang et al.~\cite{raissi2019physics} proposed a new network structure to deal with the numerical stiffness of the backpropagation gradient that causes PINN to fail.
% Other methods focus on tailoring PINN architecture for a specific physical problem~\cite{wu2021modified, baddoo2021physics} and are difficult to generalize to systems biology applications.
% % However, these techniques currently are difficult to  scale to the very large mo dels being used in practice by systems biologists. % copied
% More research is needed to scale the generalizability and stability for these techniques to be applicable across the continuum of biological models.

% % Fourier 
% In contrast, inspired by the Fourier neural networks (FNN) that apply the fast Fourier transform to the neural network~\cite{silvescu1999fourier}, a Fourier neural operator (FNO, a data-driven approach) is developed to learn a mapping of solutions to a complete family of differential equations~\cite{li2020fourier}. 
% The Fourier transform reduces the computational complexity to quasi-linear, enabling large-scale calculations. 
% Compared to traditional PDE solvers, FNO's resolution invariance property offers high accuracy at a low computational cost, making it a state-of-the-art approach for approximating PDEs.
% Grady et al.\cite{grady2022towards} later break the limitation that FNO can only solve problems below three dimensions and mathematically proved that the proposed model-parallel Fourier neural operators (MP-FNO) can be used for dimensional data of any size. 
% % And mathematically deduce all the necessary components of MP-FNO. MP-FNO is solving large-scale Parametric PDEs have a significant speed-up effect.
% %Factorized Fourier Neural Operator (F-FNO)~\cite{tran2021factorized} has made a number of improvements on the basis of FNO to achieve better results. Factorize the input multi-dimensional Fourier transform and share the kernel integral operator parameters of all Fourier layers, which greatly reduces the amount of parameters. The residual structure added by F-FNO can greatly deepen the Fourier operator layers.
% From the application perspective, FNO is customized to solve different problems, such as LAFNO~\cite{peng2022linear} for modeling 3D turbulence, PFNO~\cite{li2022solving} for solving seismic wavefield equations in velocity models, and IFNO~\cite{you2022learning} for predicting the mechanical response of materials.
% In addition to learning challenging PDEs, FNO also achieved good results in the field of Vision transformers. The adaptive Fourier neural operator (AFNO)~\cite{guibas2021adaptive} draws on the idea of FNO and performs token mixing in the frequency domain through Fourier transform to understand the relationships among objects in a scene.
% However, the above FNO-related methods are data-driven approaches that require ground truth solutions as labeled data to train the neural networks. 


This paper introduces a framework called the System-Biology Fourier-Enhanced Neural Network (SB-FNN) to solve the initial value problem in systems biology with high accuracy and efficiency. The motivation for this work includes two key factors: (i) the presence of ubiquitous and vital oscillatory patterns in biological systems, especially for molecular systems, which aligns well with the strong spectral periodicity characteristics underlying Fourier neural networks; (ii) the complexity of practical biological models, which often involve highly entangled variables and nonlinear functions that are challenging for conventional neural networks to handle accurately and efficiently.

%First, use the data to train the operator, and then use the physical equation to further optimize the operator. That is, it overcomes the shortcomings of pure data-driven (the data may be less or expensive to obtain) and also overcomes the shortcomings of pure PINN (low precision).

% Our main contribution is summarized as follows:

% \begin{itemize}
%     \item Our proposed SB-FNN incorporates two customized designs for systems biology applications: an embedded residual neural network (ResNet) and a cyclic penalty function that together optimize the prediction of dynamic behaviors of biological systems;
    
%     \item Compared with PINN, our proposed SB-FNN and its variants demonstrate a significant improvement in accuracy and efficiency, \chen{provide orders of magnitude} in both population and molecular dynamic models;
    
%     \item Compared with conventional neural networks, our SB-FNN has a simpler optimization environment and a more expressive representation space, which can solve practical complex biological models. 
    
% \end{itemize}

The main contribution is summarized as follows:
\begin{itemize}
    \item SB-FNN is a custom design for systems biology applications that builds upon the Fourier neural network (FNN) and incorporates two unique features: an adaptive activation function and a variance constraint. These two features work together to optimize the prediction of dynamic behaviors in biological systems.
    % \item Apply SB-FNN to both the initial value problem (IVP) and parameter estimation problem (PEP) in systems biology applications.
    \item Compared to PINN, our proposed SB-FNN and its variants exhibit significant improvements in accuracy and efficiency. SB-FNN provides a simpler optimization environment and a more expressive representation space, which enables it to solve practical and complex biological models.
\end{itemize}

% This proposal will be in two parts:
% \begin{itemize}
%     % \item In the first part, Chapter 2, I explore recent approaches applying machine learning in solving differential equations;
%     \item In the first part, Chapter 2, I propose the core method of SB-FNN and show the prior achievement obtained on some specified ODE systems. Then I discuss about the potential improvements based on FINN which will be tested and evaluated in the coming semester.
%     \item In the second part, Chapter 3, I list some potential systems biology models that may be finally taken into the experiment.
% \end{itemize}

% In the first part, in Chapter 2, I explore how to improve the accuracy and efficiency of an existing implementation of Tucker decomposition, TuckerMPI, by employing QR-SVD as well as by enabling single precision. The results and findings of this part comes from a project I worked on with the help of Dr. Grey Ballard and Qiming Fang, an undergraduate student at the Computer Science Department. This work is already completed and published [7]. In the second part, from section 0.4 to section 0.7, I outline the goals and potential directions for another closely related research project Iâ€™m currently working on with Dr. Rachel Minster and Dr. Grey Ballard where we explore potential ways of improving the TuckerMPI by using randomization.


% The governing differential equations underlying real-world physic systems



% Motivation: Two main problems

% \begin{itemize}
%     \item Estimate unknown partial differential equations, including the equation format and parameters, from data measurements.
%     \item Solve the model curves over time from a current model state data with given partial differential equations.
% \end{itemize}




% Challenges: some weaknesses

% Opportunities: Combine different models to improve the efficiency or accuracy



% \paragraph{Rationale of knowledge-guided machine learning on PDE solving.}


% Machine learning has achieved unprecedented success due to its effectiveness in handling complex data. 
% most of them are data-driven approaches that suffer from poor interpretability and sometimes produce ill-posed results that are distinct from essential physical or biological laws.
% To improve on this, knowledge-guided machine learning takes into account domain knowledge to ensure biologically or physically consistent predictions and classifications, thereby enhancing method explainability.
% Furthermore, the integration can be adapted to solve inverse problems, such as parameter optimization and function inferences, which facilitate the discovery of governing terms and unknown biological pathways.
% Please extend ....


% \textbf{Literature.}	
% A variety of methods have been proposed to integrate scientific knowledge into deep learning techniques, which can be generally summarized into two types: guided loss function design and guided architecture design.  One of the most popular is the recent physics-informed neural network (PINN), which integrates physical constraints as a form of PDEs into the loss function. 
% While PINN has gained promising results across a wide range of problems in computational science and engineering~\cite{sun_surrogate_2020,raissi_deep_2019,jin_nsfnets_2021,kissas_machine_2020,sahli_costabal_physics-informed_2020}, it fails to achieve reliable training and correct solutions for complex systems and are prone to high computational costs~\cite{meng_when_2022,krishnapriyan_characterizing_2021,lu_deeponet_2021}. 
% The other direction focuses on integrating physical guidance into architectural designs in various domains~\cite{sun_theory-guided_2020, wang_incorporating_2021, zhang_deep_2018, behler_generalized_2007}.
% For example,~\cite{daw_physics-guided_2019} and~\cite{muralidhar_phynet_2020} incorporated physical variables in neural networks to ensure physical consistency and achieved significant improvement. But these designs are usually confined to solving a specific problem and are difficult to generalize to other applications.
% Please extend....

% \textbf{Challenges.}	
% Biological modeling typically involves hundreds of system variables (various genes, mRNAs, and proteins) coupled with oscillatory patterns and multiple system states, posing a significant computational challenge to knowledge-guided machine learning, which is still in its infancy. Please expand ...












