% \section{Model-guided Fourier Neural Network}

This section showcases the effectiveness of our Systems-Biology Fourier-enhanced Neural Network (SB-FNN) in comparison to PINNs through six systems biology models. A comprehensive description of the systems biology models and their equations can be found in Appendix \ref{appendix:models}.


\section{Experiment Setup}

% Our experiments are performed on a multi-core Redhat Linux machine with 800GB RAM and two 32GB NVIDIA Tesla V100 GPUs. The dataset ($\mathcal{X}$ in Chapter 3) is randomly split into training (80\%) and testing (20\%) set. We set the hidden dimension ($H$ in Chapter 3) as 128, the number of Fourier modes as 32, the layer number as 4. 
% Those hyper-parameters can be revised according to the complexity and timescale of models.
% The normalized mean square error (N-MSE) is used to better evaluate the prediction accuracy across the time domain, written as


% Note that the N-MSE function is only used in evaluating how good the model can be used to predict the dynamic on the test dataset. Since the ground truth is not used in the training process, we use the loss function introduced in Chapter 3 instead.

We conducted our experiments on a multi-core Redhat Linux machine with two 32GB NVIDIA Tesla V100 GPUs. The hyper-parameters were set to a hidden dimension of 16, 12 Fourier modes, and a layer number of 4. As introduced in Chapter \ref{cha:method}, each of these FNN layers has a trainable independent weight vector to form the adaptive activation function with candidates ReLU, Tanh, Sin, GELU, ELU and Softplus. All these hyper-parameters can be adjusted based on the model's complexity and time constraints. Table \ref{tab:setup} displays the experiment setup for different models that was utilized in the following experiments.

% \begin{table}[htbp]
% \centering
% \caption{Experimental Setup}
% \begin{tabular}{l l}
% \hline
% \textbf{Parameter} & \textbf{Value} \\
% \hline
% Sample Size & 100 \\
% Treatment Group Size & 50 \\
% Control Group Size & 50 \\
% Treatment Method & Intervention X \\
% Control Method & Placebo Y \\
% Outcome Measure & Variable Z \\
% Data Collection Method & Survey \\
% Survey Instrument & Questionnaire \\
% Survey Respondents & Target population \\
% Statistical Analysis Method & ANOVA \\
% Significance Level & 0.05 \\
% \hline
% \end{tabular}%
% \label{tab:experiment_setup}%
% \end{table}

\begin{table*}[!htb]
\footnotesize
\caption[Experimental Configuration and Tuning] {Experimental Configuration and Tuning}
\label{tab:setup}
\begin{tabular}{ l cccccc } 
\toprule

Setup & Rep3 & Rep6 &  SIR & A-SIR & 1D Turing & 2D Turing \\
\midrule 
\midrule
Time domain & [0,10] & [0,20] & [0,100] & [0,100] & [0,10] & [0,2] \\
Maximum training epochs & 50,000 & 50,000 & 20,000 & 30,000 & 5,000 & 5,000 \\
Number of model parameters & 16,019 & 16,406 & 16,019 & 17,567 & 593,586 & 7,081,650 \\
Hidden layer size $H$ & 16 & 16 & 16 & 16 & 16 & 16 \\
Number of Fourier layers $l$ & 4 & 4 & 4 & 4 & 4 & 4 \\
Fourier modes $M$ & 12 & 12 & 12 & 12 & 12 & 12 \\
Initial learning rate & 0.01 & 0.01 & 0.01 & 0.01 & 0.01 & 0.01 \\
Optimizer & Adam & Adam & Adam & Adam & Adam & Adam \\
% Scheduler & \multicolumn{6}{c}{LambdaLR (Eq. \ref{eq:lr})} \\
Adaptive function candidates & \multicolumn{6}{c}{\{Tanh, ReLU, Softplus, ELU, GELU, Sin\}} \\
\bottomrule
\end{tabular}%}
\end{table*}

The dataset, denoted as $\mathcal{X}$ in Chapter \ref{cha:method}, was randomly sampled in the time domain following the Latin Hypercube sampling (LHS) method \cite{mckay1979two}. The LHS method is a type of stratified sampling that ensures that each point in the domain is sampled equally. It works by dividing the domain into equal-sized intervals and sampling a single point randomly from each interval. This ensures that each point in the domain is covered by exactly one sample and reduces the variance in the integral approximation. The dataset comprises a training set and a testing set, with a 10:1 length ratio. Both sets are sampled independently along the entire time domain, in ascending order, with the first time step always being zero. This ensures that the initial condition loss ($Loss_{o}=\lambda_{o}\left\| \widehat{y}_{0}-y_{0}\right\|_{2}$) and the PDE gradient loss ($Loss_{f}=\lambda_{f}\left\| \widehat{y_{t}}-\mathcal{G}\left[\widehat{y}\right]\right\|$) introduced in Eq. \ref{eq:loss} are properly functional.

In our study, we train our SB-FNN models using the Adam optimizer with a starting learning rate of 0.01. To further optimize our model's performance, we incorporated a learning rate scheduler
% , which was selected based on the provided configuration parameter. We offered support for four scheduler types, namely cosine annealing, step decay, decade decay, and fixed learning rate. To implement the cosine annealing scheduler, we utilized the CosineAnnealingLR scheduler with the maximum number of iterations set to the total number of training iterations. For the step decay scheduler, we applied the StepLR scheduler, with a step size of 5000 and a gamma value of $0.5$. 
following a decade decay strategy, which allows the learning rate (lr) to change with the number of epochs based on a scaling factor:
\begin{equation}
\label{eq:lr}
lr = lr\_init \cdot \dfrac{1}{\dfrac{ep}{b} + 1} = \dfrac{b\cdot lr\_init}{b+ep},
\end{equation}
where the parameter $lr\_init$ represents the initial learning rate, and $ep$ represents the number of epochs that has been run. The parameter $b$ is set to 1,000 for model Rep3, Rep6, SIR and A-SIR, and 100 for model 1D Turing and 2D Turing, as they have different maximum training epochs. As the epoch number increases, the learning rate decreases.

% Lastly, for the fixed learning rate scheduler, we set the learning rate to a constant value for all iterations. In our final result chart, we opted for the decade decay scheduler for all models due to its stability and fast convergence speed.

As the loss function depends on the prediction of the first time step ($y_0$ in Chapter \ref{cha:method}, the training process needs to use the entire prediction of $y$ in each epoch to calculate the loss. This means that, following the PINN-like design of the loss function, each epoch will involve one iteration with the complete training dataset as the batch size.

To guarantee convergence of each model, we have set a uniform number of epochs to 50,000 despite the fact that some of the models may converge earlier.

To assess prediction accuracy across the time domain on the test dataset, we used the normalized mean square error (N-MSE), which can be written as:

\begin{equation}
\label{eq:nmse}
\text{N-MSE}=\dfrac{1}{n}\sum^{n}_{i=1}\dfrac{\left\| \hat{\psi_{i}} - \psi_{i}\right\| _{2}}{\left\| \psi_{i}\right\| _{2}},
\end{equation}
where $\left\| \cdot\right\| _{2}$ is the 2-norm, $n$ is the batch size, and $\hat{\psi}$ is the prediction of the ground truth $\psi$. It is important to note that the N-MSE function was only used to evaluate the model's predictive performance on the test dataset, as the ground truth was not utilized during the training process. Instead, we use a loss function introduced in Chapter \ref{cha:method} to measure the model's performance during training. Additionally, for models such as SIR and A-SIR, which have dynamics that eventually reach a stable state of 0, this can cause the N-MSE equation's denominator to approach 0, resulting in unexpected results. To avoid this issue, we exclude these dynamics from the calculation of the N-MSE loss and only consider dynamics that do not reach 0 as the stable state.

\section{Prediction of Model Dynamics}

Systems biology systems are a class of mathematical models that have found applications in many areas, including biology, physics, and chemistry. They describe the dynamics of complex biological processes such as gene expression, cell signaling, and metabolic pathways. Many of these systems exhibit interesting phenomena, such as oscillations, stable states, and stiff rising and reducing behaviors.

In this paper, we investigate three common categories of systems: the Repressilator model, SIR model, and Turing Patterns. For each category, we examine two variations: the Repressilator model with only protein equations or with both mRNA and protein equations, the SIR model and its age-structured variant, and the Turing Pattern on both 1D and 2D spaces. A comprehensive explanation of each model is provided in Appendix \ref{appendix:models}.

% We have selected three typical classes of systems from a large number of systems biology PDE systems: the Repressilator model, SIR model, and Turing Patterns. For each of these classes, we consider two variants, namely the Repressilator model with protein equations only or both protein and mRNA equations, the SIR model and its age-structured variant, and the Turing Pattern on both 1D and 2D grids. The detailed description of each model is available in Appendix \ref{appendix:models}.

By training each model for a sufficient number of epochs using the proposed SB-FNN, accurate predictions of the dynamics of each model on the training set can be achieved.
% The corresponding model parameters for each curve with their respective accurate predictions are presented in Figure \ref{fig:fine_prediction}.

\subsection{Repressilator: Protein Only Model}
The repressilator model \cite{elowitz2000synthetic} describes a synthetic oscillatory system of transcriptional repressors. Appendix \ref{appendix:rep3} contains the complete definition and equations of this model. If we only consider the protein interactions, there would be three variables in this model (Rep3), which represent the concentrations of the repressor-proteins of $lacI$, $tetR$, and $cI$. The prediction results of this model using SB-FNN are shown in Figure \ref{fig:rep3_prediction}. The variables with hats represent the predicted values, while those without hats represent the ground truth values, which are calculated. This definition applies to subsequent sections as well.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{fig_results/best_SB-FNN_rep3.png}
\caption[Prediction of the Repressilator: protein only model] {Prediction of the Repressilator: protein only model. $P_{i}$ ($i=$ $lacI$, $tetR$, or $cI$) represents the concentrations of the repressor-proteins of $lacI$, $tetR$, and $cI$, respectively. The model parameters are $\beta = 10$ and $n=3$.}
\label{fig:rep3_prediction}
\end{figure}

\subsection{Repressilator: mRNA and Protein Model}
Taking both transcription and translation reactions among three pairs of repressor mRNAs and proteins, the Repressilator model can be extended to differential equations with six variables (Rep6). Appendix \ref{appendix:rep6} contains the complete definition and equations of this model. Here $P_{i}$ denotes the repressor-protein concentrations, and $M_{i}$ represents the corresponding mRNA concentrations, where $i$ is $lacI$, $tetR$, or $cI$. The prediction results of this model using SB-FNN are shown in Figure \ref{fig:rep6_prediction}.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{fig_results/best_SB-FNN_rep6.png}
\caption[Prediction of the Repressilator: mRNA and protein model] {Prediction of the Repressilator: mRNA and protein model. $P_{i}$ and $M_{i}$ ($i=$ $lacI$, $tetR$, or $cI$) represents the repressor-proteins concentrations and mRNA concentrations of $lacI$, $tetR$, and $cI$, respectively. The model parameters are $\beta = 10$, $n=3$, $\alpha=10$ and $\alpha_0=1e^{-5}$.}
\label{fig:rep6_prediction}
\end{figure}

\subsection{SIR Model}
The SIR \cite{anderson1991discussion} is a classic compartmental model in epidemiology to simulate the spread of infectious disease. The basic SIR model considers a closed population with three different labels susceptible (S), infectious (I), and recovered (R). Appendix \ref{appendix:sir} includes the complete definition and equations of this model. The prediction results of this model using SB-FNN are shown in Figure \ref{fig:sir_prediction}.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{fig_results/best_SB-FNN_sir.png}
\caption[Prediction of the SIR model] {Prediction of the SIR model. $S,I,R$ represents the susceptible, infectious, and recovered population, respectively. The model parameters are $\beta = 0.01$, $\gamma=0.05$ and $N=100$.}
\label{fig:sir_prediction}
\end{figure}

\subsection{Age-structured SIR Model}
The Age-structured SIR (A-SIR) model, which takes into account differences in age groups \cite{ram2021modified}, is a variation of the SIR model. The variables $S_i$, $I_i$, and $R_i$ represent the susceptible, infectious, and removed population within the $i$th age group, where $1\leq i \leq n$, and $n$ represents the total number of age groups. Appendix \ref{appendix:asir} contains the complete definition and equations for this model. The prediction results for this model using SB-FNN can be seen in Figure \ref{fig:asir_prediction}.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{fig_results/best_SB-FNN_siraged.png}
\caption[Prediction of the Age-structured SIR model] {Prediction of the Age-structured SIR model. $S_i$, $I_i$, and $R_i$ represent the susceptible, infectious, and removed population within the $i$th age group, respectively. The model parameters are $\beta = 0.01$, $\gamma=0.05$, $N=100$, $n=5$, and $\mathcal{M}$ is an age-content matrix from \cite{ram2021modified}.}
\label{fig:asir_prediction}
\end{figure}

\subsection{1D Turing Model}
Turing patterns, such as spots and stripes observed in nature, arise spontaneously and autonomously from homogeneous states through reaction-diffusion systems involving two diffusive substances that interact with each other \cite{turing1990chemical}. The 1D Turing model is a simplified version of the general Turing pattern that allows us to view the predictions over the entire time domain, and is generated on a plane space of size $100\times 1$. The Schnakenberg kinetics model \cite{maini2012turing} is used for producing this. Appendix \ref{appendix:turing} provides the complete definition and equations for this model. The prediction results for this model using SB-FNN can be seen in Figure \ref{fig:turing1d_prediction}.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig_results/best_SB-FNN_turing1d.png}
\caption[Prediction of the 1D Turing model] {Prediction of the 1D Turing model. $U$ and $V$ are the concentrations of two diffusible substances. This model is generated on a plane space of size $100\times 1$ ($X$ represents the first dimension) and a time domain of $[0,10]$. It is parameterized using $c_1 = 0.1$, $c_2=0.9$, $c_{-1}=1$, $c_3=1$, $d_1=1$, and $d_2=40$.}
\label{fig:turing1d_prediction}
\end{figure}

\subsection{2D Turing Model}
To focus on the reaction-diffusion patterns of Turing model on the plane, we can also produce the Turing model on a plane space of size $25\times 25$. The complete definition and equations for this model can be found in Appendix \ref{appendix:turing} as well. The prediction results for this model using SB-FNN can be seen in Figure \ref{fig:turing2d_prediction}.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig_results/best_SB-FNN_turing2d.png}
\caption[Prediction of the 2D Turing model] {Prediction of the 2D Turing model on the last time step. $U$ and $V$ are the concentrations of two diffusible substances. This model is generated on a plane space of size $25\times 25$, and it is parameterized using $c_1 = 0.1$, $c_2=0.9$, $c_{-1}=1$, $c_3=1$, $d_1=1$, and $d_2=40$.}
\label{fig:turing2d_prediction}
\end{figure}


% \section{Turing Model (1D and 2D)}
% \label{appendix:turing}
% Turing patterns, such as spots and stripes in nature, emerge spontaneously and autonomously from homogeneous states that can be dynamically captured by reaction-diffusion systems of two interacting and diffusive substances~\cite{turing1990chemical}. 
% These models typically have substantial complexity and are highly dynamic. Here, we consider a two-dimensional Turing model~\cite{maini2012turing}:
% % maini2012turing  Schnakenberg model https://core.ac.uk/download/pdf/8791221.pdf
% \begin{equation}
% \begin{cases}
% \dfrac{\partial U}{\partial t}=c_{1}-c_{\text{-}1}U+c_{3}U^{2}V+d_{1}\nabla^{2} U \vspace{1ex}\\
% \dfrac{\partial V}{\partial t}=c_{2}-c_{3}u^{2}v +d_{2}\nabla^{2} V \vspace{1ex}
% \end{cases}
% \end{equation}
% where $U$ and $V$ are the concentrations of two diffusible substances, $c_{\text{-}1}, c_{1}, c_{3}$ represent the deterministic reaction rates, $d_{1}$, $d_{2}$ are diffusion rates, and the rest are reaction terms for the two substances.

% The Turing model is commonly visualized in two dimensions (Turing (2D)), but it can be challenging to display 2D predictions for the entire time domain. To overcome this challenge, we limit the model to one dimension, so that at each time step within the time domain, a prediction can be made in one dimension. The predictions can then be arranged along the time domain to form a figure, which is named as the Turing (1D) model.




% \begin{figure}
%     \centering
%     \subcaptionbox{Dynamic prediction of Repressilator: Protein only model (Rep3) with $\beta = 10$ and $n=3$.}{\includegraphics[width=0.49\textwidth]{fig_results/best_SB-FNN_rep3.png}}
%     \subcaptionbox{Dynamic prediction of Repressilator: Protein and mRNA (Rep6) model with $\beta = 10$, $n=3$, $\alpha=10$ and $\alpha_0=1e^{-5}$.}{\includegraphics[width=0.49\textwidth]{fig_results/best_SB-FNN_rep6.png}} \\
%     \subcaptionbox{Dynamic prediction of SIR model with $\beta = 0.01$, $\gamma=0.05$ and $N=100$.}{\includegraphics[width=0.49\textwidth]{fig_results/best_SB-FNN_sir.png}}
%     \subcaptionbox{Dynamic prediction of Age-structured SIR (A-SIR) model with $\beta = 0.01$, $\gamma=0.05$, $N=100$ and $n=5$. $\mathcal{M}$ is an age-content matrix from \cite{ram2021modified}. }{\includegraphics[width=0.49\textwidth]{fig_results/best_SB-FNN_siraged.png}} \\
%     \subcaptionbox{Dynamic prediction of Turing model on $30\times 30$ grids (Turing 2D) with $c_1 = 0.1$, $c_2=0.9$, $c_{-1}=1$, $c_3=1$, $d_1=1$ and $d_2=40$ on the trained last time step.}{\includegraphics[width=0.49\textwidth]{fig_results/best_SB-FNN_turing2d.png}}
%     \subcaptionbox{Dynamic prediction of Turing model on $100\times 1$ grids (Turing 1D) with $c_1 = 0.1$, $c_2=0.9$, $c_{-1}=1$, $c_3=1$, $d_1=1$ and $d_2=40$ over the complete time domain.}{\includegraphics[width=0.49\textwidth]{fig_results/best_SB-FNN_turing1d.png}}
%     \caption{Dynamic prediction of each model using SB-FNN}
%     \label{fig:fine_prediction}
% \end{figure}

\section{Performance Analysis of SB-FNN against PINN}

We assess the accuracy and efficiency performance of PINN and SB-FNN on the introduced systems biology models. 

\subsection{Accuracy Evaluation}

\begin{table*}[!htb]
\centering
\small
\caption[Performance comparison between PINN and SB-FNN on different systems biology models] {Performance comparison between PINN and SB-FNN on different systems biology models.}
\label{tab:exp1-all}
\begin{tabular}{ l cc } 
\toprule
\multirow{2}{*}{Model} & \multicolumn{2}{c}{Accuracy (N-MSE)} \\
\cmidrule(l){2-3} 
 & PINN & SB-FNN\\
\midrule 
\midrule 
{Rep3} & $1.3173 \pm 0.9355 (e^{-3})$ & $5.5949 \pm 0.3237 (e^{-5})$ \\
{Rep6} & $2.8501 \pm 0.0041 (e^{1})$ & $9.3663 \pm 1.0792 (e^{-4})$ \\
{SIR} & $6.9605 \pm 3.3973 (e^{-2})$ & $6.8226 \pm 1.0602 (e^{-5})$ \\
{A-SIR} & $1.7167 \pm 0.5161 (e^{-2})$ & $7.4510 \pm 0.6084 (e^{-5})$ \\
{1D Turing} & $1.1779 \pm 0.0901 (e^{0})$ & $1.8099 \pm 0.2314 (e^{-2})$ \\
{2D Turing} & $4.9022 \pm 0.1294 (e^{-2})$ & $4.7462 \pm 0.2989 (e^{-3})$ \\
\bottomrule
\end{tabular}
\end{table*}

The accuracy (N-MSE) (Eq. \ref{eq:nmse}) of each model on the test set is computed by averaging the results of five experiments with randomly initialized neural networks (using different random seeds for the PyTorch, Numpy, and Random packages). 
Table \ref{tab:exp1-all} and Figure \ref{fig:pinn_vs_sb_fnn} summarize the obtained accuracy results. PINN fails in the prediction of the Rep6 model and the 1D Turing model and performs worse than SB-FNN in all models.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{fig_results_new/pinn_vs_sb_fnn.png}
\caption[Performance comparison between PINN and SB-FNN on different systems biology models] {Performance comparison between PINN and SB-FNN on different systems biology models. The N-MSE values between the ground truth and the predictions on the test set have been calculated and plotted. In the bar chart, the bars represent the mean N-MSE values and the error dashes indicate the standard deviation. It can be observed that PINN does not perform well in predicting the Rep6 model and the 1D Turing model, and it performs worse than SB-FNN in all the models.}
\label{fig:pinn_vs_sb_fnn}
\end{figure}

We also plot the training loss (N-MSE) between PINN and SB-FNN over epochs, which is shown as Figure \ref{fig:pinn_vs_sb_fnn_nmse}. To ensure stable prediction results, we set the maximum epoch as follows: 50k for Rep3 and Rep6 models, 20k for the SIR model, 30k for the A-SIR model, and 5k for the 1D Turing and 2D Turing models. For each model trained with each method, the final accuracy is calculated using the average of the last 10\% of epochs, in case of unexpected small shocks in the curves.

\begin{figure}
    \centering
    \subcaptionbox{Training loss (N-MSE) on the Rep3 model}{\includegraphics[width=0.49\textwidth]{fig_results/nmse_loss_rep3.png}}
    \subcaptionbox{Training loss (N-MSE) on the Rep6 model}{\includegraphics[width=0.49\textwidth]{fig_results/nmse_loss_rep6.png}}
    \subcaptionbox{Training loss (N-MSE) on the SIR model}{\includegraphics[width=0.49\textwidth]{fig_results/nmse_loss_sir.png}}
    \subcaptionbox{Training loss (N-MSE) on the A-SIR model}{\includegraphics[width=0.49\textwidth]{fig_results/nmse_loss_siraged.png}}
    \subcaptionbox{Training loss (N-MSE) on the 1D Turing model}{\includegraphics[width=0.49\textwidth]{fig_results/nmse_loss_turing1d.png}}
    \subcaptionbox{Training loss (N-MSE) on the 2D Turing model}{\includegraphics[width=0.49\textwidth]{fig_results/nmse_loss_turing2d.png}}
    \caption[Comparison of training loss (N-MSE) between PINN and SB-FNN over epochs] {Comparison of training loss (N-MSE) between PINN and SB-FNN over epochs. For each model and method used, we conduct five separate tests. The solid lines in the plots represent the average value across these tests, while the shaded areas in the corresponding lighter color show the upper and lower bounds over the tests.}
    \label{fig:pinn_vs_sb_fnn_nmse}
\end{figure}

The results presented above demonstrate that SB-FNN outperforms both PINN and FNN across all listed models. Generally, PINN shows good performance in predicting the dynamics of systems biology models with simple equations, but it performs worse in more complex models. In contrast, SB-FNN performs well in all models. These findings highlight the potential of SB-FNN in accurately predicting the dynamics of complex systems biology models.

\subsection{Efficiency Evaluation}

\begin{table*}[!htb]
\centering
\scriptsize
\caption[Efficiency evaluation of different methods] {Efficiency evaluation of different methods}
\label{tab:exp4}
\begin{tabular}{ l cccccc } 
\toprule
\multirow{2}{*}{Method} &  \multicolumn{6}{c}{Training Time per Epoch / s} \\
\cmidrule(l){2-7} 
 & Rep3 & Rep6 &  SIR & A-SIR & 1D Turing & 2D Turing \\
\midrule 
\midrule 
\multirow{2}{*}{Tanh} & $7.4903$ & $7.9043$ & $7.5411$ & $1.1423$ & $2.0235$ & $1.6177$ \\ 
 & $\pm0.6795 (e^{-2})$ & $\pm0.3299 (e^{-2})$ & $\pm0.7330 (e^{-2})$ & $\pm0.0596 (e^{-1})$ & $\pm0.1864 (e^{-1})$ & $\pm0.0327 (e^{-1})$ \\
\multirow{2}{*}{ReLU} & $6.7811$ & $7.9735$ & $7.4282$ & $1.0946$ & $2.0448$ & $1.5984$ \\ 
 & $\pm0.3456 (e^{-2})$ & $\pm0.4357 (e^{-2})$ & $\pm0.4627 (e^{-2})$ & $\pm0.0927 (e^{-1})$ & $\pm0.1665 (e^{-1})$ & $\pm0.0131 (e^{-1})$ \\
\multirow{2}{*}{Softplus} & $8.1193$ & $8.6280$ & $7.3499$ & $1.1186$ & $1.9356$ & $1.5789$ \\ 
 & $\pm0.6498 (e^{-2})$ & $\pm0.5897 (e^{-2})$ & $\pm0.3984 (e^{-2})$ & $\pm0.0955 (e^{-1})$ & $\pm0.1040 (e^{-1})$ & $\pm0.0318 (e^{-1})$ \\
\multirow{2}{*}{ELU} & $7.1769$ & $8.1191$ & $7.3310$ & $1.1580$ & $1.9357$ & $1.6085$ \\ 
 & $\pm0.2137 (e^{-2})$ & $\pm0.2983 (e^{-2})$ & $\pm0.1597 (e^{-2})$ & $\pm0.1371 (e^{-1})$ & $\pm0.2124 (e^{-1})$ & $\pm0.0292 (e^{-1})$ \\
\multirow{2}{*}{GELU} & $7.6652$ & $8.7640$ & $7.5818$ & $1.2064$ & $2.1241$ & $1.5857$ \\ 
 & $\pm1.6144 (e^{-2})$ & $\pm1.2170 (e^{-2})$ & $\pm0.7935 (e^{-2})$ & $\pm0.1172 (e^{-1})$ & $\pm0.1218 (e^{-1})$ & $\pm0.0111 (e^{-1})$ \\
\multirow{2}{*}{Sin} & $7.3184$ & $8.0606$ & $7.4377$ & $1.0406$ & $1.9541$ & $1.6388$ \\ 
 & $\pm0.3173 (e^{-2})$ & $\pm0.2456 (e^{-2})$ & $\pm0.6310 (e^{-2})$ & $\pm0.0506 (e^{-1})$ & $\pm0.1243 (e^{-1})$ & $\pm0.0245 (e^{-1})$ \\
\multirow{2}{*}{Adaptive} & $9.6632$ & $1.0841$ & $9.0508$ & $1.2492$ & $2.8061$ & $4.4034$ \\ 
 & $\pm1.2990 (e^{-2})$ & $\pm0.0428 (e^{-1})$ & $\pm0.5789 (e^{-2})$ & $\pm0.0343 (e^{-1})$ & $\pm0.1133 (e^{-1})$ & $\pm0.1157 (e^{-1})$ \\
\multirow{2}{*}{SB-FNN} & $9.0656$ & $1.0262$ & $9.0508$ & $1.2492$ & $2.8061$ & $4.4034$ \\ 
 & $\pm0.4910 (e^{-2})$ & $\pm0.0395 (e^{-1})$ & $\pm0.5789 (e^{-2})$ & $\pm0.0343 (e^{-1})$ & $\pm0.1133 (e^{-1})$ & $\pm0.1157 (e^{-1})$ \\
\multirow{2}{*}{PINN} & $7.0960$ & $8.0010$ & $6.9456$ & $1.1917$ & $3.7831$ & $1.5404$ \\ 
 & $\pm0.6624 (e^{-2})$ & $\pm0.4455 (e^{-2})$ & $\pm0.4092 (e^{-2})$ & $\pm0.0956 (e^{-1})$ & $\pm0.1542 (e^{-1})$ & $\pm0.1372 (e^{0})$ \\
 
\bottomrule
\end{tabular}%}
\end{table*}

In the experiments using different methods on various models, we have computed the average time taken per epoch, as presented in Table \ref{tab:exp4}. These experiments are conducted on the same GPU chip and operating system. Please note that since the variance constraint is not appropriate for non-oscillatory models, their ``Adaptive'' rows are the same as the ``SB-FNN'' rows. For relatively simple models, applying the adaptive function incurs about 20\% more time per epoch, and the use of variance constraint does not result in a significant difference in time cost. On the other hand, the performance of the PINN method in terms of time is similar to that of single activation methods on simple models, but the time cost rises sharply as the model becomes more complex. In the 2D Turing model, PINN takes more than three times as much time as SB-FNN.

\section{Ablation Analysis: Adaptive Activation Function}

To evaluate the effectiveness of the proposed adaptive activation function, we conducted a comparative analysis with six commonly used activation functions: GELU, tanh, ReLU, sin, ELU, and Softplus. We vary the activation function and calculated the accuracy (N-MSE) on the same test sets for each model, as presented in Table \ref{tab:exp2}.

% It should be noted that the performance of a single GELU function is identical to that reported in Table \ref{tab:exp1}, as FNN utilizes GELU as its default activation function in all layers. 

% \begin{table*}[!htb]
% \centering
% \footnotesize
% \caption{Abalation experiments of activation functions.}
% \label{tab:all}
% % \resizebox{\textwidth}{25mm}{
% \begin{tabular}{ l cccccc } 
% \toprule
% \multirow{2}{*}{Activation} & 
% \multicolumn{6}{c}{Model N-MSE (\%)} \\
% \cmidrule(l){2-7} 
% function & SIR & Aged-SIR &  Repressilator 3 & Repressilator 6 & Turing Pattern 1d & Turing Pattern 2d \\
% \midrule 
% \midrule 
% \multirow{1}{*}{gelu} & $5.90\pm3.01(e^{-8})$ &$6.05\pm0.74(e^{-7})$ &$3.05\pm3.04(e^{-5})$ &$6.06\pm5.03(e^{-6})$ & & \\ 

% \multirow{1}{*}{tanh} & $3.79\pm0.15(e^{-4})$ &$ 5.13\pm0.03(e^{-3}) $&$ 7.48\pm 1.74(e^{-5})$ &$4.43\pm1.40(e^{-7})$ & & \\  

% \multirow{1}{*}{relu} &$5.06\pm1.35(e^{-8})$& $8.32\pm2.02(e^{-7})$&$2.66\pm3.59(e^{-5})$ &$3.96\pm3.63(e^{1})$ & & \\  
% \multirow{1}{*}{sin} &$2.32\pm0.04(e^{-6})$&$4.20\pm0.01(e^{-3})$ &$2.10\pm2.80(e^{-5})$ &$1.26\pm0.21(e^{-6})$ & & \\ 
% \multirow{1}{*}{elu} &$5.03\pm2.24(e^{-8})$ &$7.39\pm6.76(e^{-7})$ &$9.60\pm14.7(e^{-6})$ &$1.17\pm1.75(e^{-6})$ & & \\ 
% \multirow{1}{*}{softplus} &$6.15\pm3.52(e^{-8})$ &$3.35\pm2.40(e^{-7})$ &$6.77\pm2.88(e^{-5})$ &$5.52\pm1.26(e^{-7})$ & & \\ 
% \multirow{1}{*}{adaptive} &$4.52\pm5.60(e^{-8})$ &$2.73\pm1.20(e^{-7})$ &$8.65\pm9.12(e^{-6})$ &$3.71\pm1.41(e^{-7})$ & & \\ 

% \bottomrule
% \end{tabular}%}
% \end{table*}



% \begin{table*}[!htb]
% \centering
% \footnotesize
% \caption{Analysis of activation functions.}
% \label{tab:exp2}
% \begin{tabular}{ l cccccc } 
% \toprule
% \multirow{2}{*}{Activation} & 
% \multicolumn{6}{c}{Model N-MSE (\%)} \\
% \cmidrule(l){2-7} 
% function & SIR & ASIR &  Rep3 & Rep6 & Turing (1D) & Turing (2D) \\
% \midrule 
% \midrule 
% \multirow{2}{*}{Tanh} & $5.90$ & $6.05$ & $3.05$ & $6.06$ & & \\ 
%                       & $\pm3.01(e^{-8})$ & $\pm0.74(e^{-7})$ & $\pm3.04(e^{-5})$ & $\pm5.03(e^{-6})$ & & \\
% \multirow{2}{*}{ReLU} & & & & & & \\  
%                       & & & & & & \\
% \multirow{2}{*}{Softplus} & & & & & & \\  
%                       & & & & & & \\
% \multirow{2}{*}{ELU}  & & & & & & \\  
%                       & & & & & & \\
% \multirow{2}{*}{GELU}  & & & & & & \\  
%                       & & & & & & \\
% \multirow{2}{*}{Sin} & & & & & & \\  
%                       & & & & & & \\
% \multirow{2}{*}{Adaptive}  & & & & & & \\  
%                       & & & & & & \\
% \bottomrule
% \end{tabular}%}
% \end{table*}

\begin{table*}[!htb]
\centering
\scriptsize
\caption[Accuracy comparison of activation functions on different models] {Accuracy comparison of activation functions on different models}
\label{tab:exp2}
\begin{tabular}{ l cccccc } 
\toprule
\multirow{2}{*}{Activation} & 
\multicolumn{6}{c}{Accuracy (N-MSE)} \\
\cmidrule(l){2-7} 
Function & Rep3 & Rep6 &  SIR & A-SIR & 1D Turing & 2D Turing \\
\midrule 
\midrule 
\multirow{2}{*}{Tanh} & $5.4551$ & $9.4097$ & $1.1149$ & $1.3860$ & $2.1986$ & $6.9811$ \\ 
 & $\pm0.4950 (e^{-5})$ & $\pm0.3272 (e^{-4})$ & $\pm1.2067 (e^{-1})$ & $\pm0.0297 (e^{-4})$ & $\pm0.0616 (e^{-2})$ & $\pm0.1095 (e^{-3})$ \\
\multirow{2}{*}{ReLU} & $6.3463$ & $1.1152$ & $2.3020$ & $3.2724$ & $2.7842$ & $7.0822$ \\ 
 & $\pm4.2477 (e^{-4})$ & $\pm1.1855 (e^{2})$ & $\pm1.1113 (e^{-1})$ & $\pm0.6692 (e^{-1})$ & $\pm3.0169 (e^{-1})$ & $\pm0.0343 (e^{-3})$ \\
\multirow{2}{*}{Softplus} & $2.3713$ & $1.3282$ & $2.0404$ & $9.6764$ & $7.5665$ & $5.9022$ \\ 
 & $\pm1.4591 (e^{-4})$ & $\pm0.1320 (e^{-3})$ & $\pm0.5914 (e^{-4})$ & $\pm0.5277 (e^{-5})$ & $\pm5.6766 (e^{-2})$ & $\pm0.4148 (e^{-3})$ \\
\multirow{2}{*}{ELU} & $1.2048$ & $6.5232$ & $2.2249$ & $8.3467$ & $1.4560$ & $5.0241$ \\ 
 & $\pm0.1063 (e^{-4})$ & $\pm9.2245 (e^{1})$ & $\pm0.6665 (e^{-4})$ & $\pm1.2210 (e^{-5})$ & $\pm2.0326 (e^{0})$ & $\pm1.5024 (e^{-3})$ \\
\multirow{2}{*}{GELU} & $1.0203$ & $2.0271$ & $1.1022$ & $7.0913$ & $1.8851$ & $4.3966$ \\ 
 & $\pm0.5524 (e^{-4})$ & $\pm0.6217 (e^{-3})$ & $\pm0.1666 (e^{-4})$ & $\pm1.0441 (e^{-5})$ & $\pm0.1120 (e^{-2})$ & $\pm0.0923 (e^{-3})$ \\
\multirow{2}{*}{Sin} & $3.9671$ & $1.4455$ & $7.4375$ & $5.8169$ & $5.8022$ & $4.5739$ \\ 
 & $\pm0.4856 (e^{-5})$ & $\pm0.5674 (e^{-3})$ & $\pm0.3368 (e^{-1})$ & $\pm1.0717 (e^{-1})$ & $\pm1.4546 (e^{-2})$ & $\pm1.5236 (e^{-3})$ \\
% \multirow{2}{*}{Adaptive} & $6.8001$ & $1.0955$ & $6.8226$ & $7.4510$ & $1.8099$ & $4.7462$ \\ 
%  & $\pm2.4594 (e^{-5})$ & $\pm0.0484 (e^{-3})$ & $\pm1.0602 (e^{-5})$ & $\pm0.6084 (e^{-5})$ & $\pm0.2314 (e^{-2})$ & $\pm0.2989 (e^{-3})$ \\
% \multirow{2}{*}{Adaptive} & $6.8001$ & $1.0955$ & $6.8226$ & $7.4510$ & $1.8099$ & $4.7462$ \\ 
%  & $\pm2.4594 (e^{-5})$ & $\pm0.0484 (e^{-3})$ & $\pm1.0602 (e^{-5})$ & $\pm0.6084 (e^{-5})$ & $\pm0.2314 (e^{-2})$ & $\pm0.2989 (e^{-3})$ \\
 \multirow{2}{*}{\textbf{Adaptive}} & \textbf{6.8001} & \textbf{1.0955} & \textbf{6.8226} & \textbf{7.4510} & \textbf{1.8099} & \textbf{4.7462} \\
& \textbf{$\pm$2.4594(e$^{-5}$)} & \textbf{$\pm$0.0484(e$^{-3}$)} & \textbf{$\pm$1.0602(e$^{-5}$)} & \textbf{$\pm$0.6084(e$^{-5}$)} & \textbf{$\pm$0.2314(e$^{-2}$)} & \textbf{$\pm$0.2989(e$^{-3}$)} \\
 
\bottomrule
\end{tabular}%}
\end{table*}

Based on Table \ref{tab:exp2}, we can see that no activation function performs the best across all models. To analyze the overall performance of each activation function, we calculate an average ranking score for each one. For each of the six models, we rank the seven activation functions from 1 to 7 based on their accuracy performance (lower N-MSE value indicates a better performance). We then rank them and calculate the mean  score for each activation function over all six models.

\begin{table*}[!htb]
\centering
\small
\caption[Scoring of activation functions on different models] {Scoring of activation functions on different models}
\label{tab:exp2-2}
\begin{tabular}{ l cccccc | c } 
\toprule
\multirow{2}{*}{Activation} & 
\multicolumn{7}{c}{Score} \\
\cmidrule(l){2-8} 
Function & Rep3 & Rep6 &  SIR & A-SIR & 1D Turing & 2D Turing & mean \\
\midrule 
\midrule 

Tanh & 6 & 7 & 3 & 3 & 5 & 2 & 4.33 \\
ReLU & 1 & 1 & 2 & 2 & 2 & 1 & 1.50 \\
Softplus & 2 & 5 & 5 & 4 & 3 & 3 & 3.67 \\
ELU & 3 & 2 & 4 & 5 & 1 & 4 & 3.17 \\
GELU & 4 & 3 & 6 & 7 & 6 & 7 & 5.50 \\
Sin & 7 & 4 & 1 & 1 & 4 & 6 & 3.83 \\
% Adaptive & 5 & 6 & 7 & 6 & 7 & 5 & 6.00 \\ 
\textbf{Adaptive} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{6} & \textbf{7} & \textbf{5} & \textbf{6.00} \\  

\bottomrule
\end{tabular}%}
\end{table*}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{fig_results_new/rank_score.png}
\caption[Mean score of different activation functions in descending order.] {Mean score of different activation functions in descending order. For each of the six models, we ranked the seven activation functions based on their accuracy performance using a scoring system in which a lower N-MSE value indicates better performance and receives a higher score. We then calculated the mean score for each activation function and order them. This plot shows that although the adaptive activation function does not perform the best among all the models, it has achieved the best overall performance in terms of prediction accuracy.}
\label{fig:rank_score}
\end{figure}

Table \ref{tab:exp2-2} displays the accuracy performance comparison of methods using various activation functions. The lower N-MSE value in Table \ref{tab:exp2} indicates a better performance, which corresponds to a higher rank score. Additionally, the mean rank score in descending order is shown in Figure \ref{fig:rank_score}. The results indicate that the adaptive activation function performs the best among the six models tested, followed by GELU and Tanh. The adaptive strategy in the activation function allows the model to dynamically select the most suitable weights of activation function for different types of system biology models. Therefore, it is concluded that the adaptive activation function is the most effective among the tested models for this task.


\section{Ablation Analysis: Variance Constraint for Oscillatory Systems}

% System biology models often exhibit ubiquitous and important oscillation patterns. Here we apply the penalty function proposed in \ref{cha:cyclic} the two oscillatory models we talked about: Repressilator: Protein only and Repressilator: Protein and mRNA. We perform ablation experiments on whether adding this penalty part into the loss function or not.
System biology models often exhibit ubiquitous and important oscillation patterns. Therefore, we apply the variance constraint proposed in \ref{cha:cyclic} to the SB-FNN to predict the two oscillatory models, Repressilator: protein only model and Repressilator: mRNA and protein model. We conduct ablation experiments to evaluate the impact of adding this penalty part into the loss function.

\begin{table*}[!htb]
\centering
\footnotesize
\caption[Accuracy comparison with and without variance constraint] {Accuracy comparison with and without variance constraint.}
\label{tab:exp3}
\begin{tabular}{ l cc } 
\toprule
\multirow{2}{*}{Method} & 
\multicolumn{2}{c}{Accuracy (N-MSE)} \\
\cmidrule(l){2-3} 
 & Rep3 & Rep6 \\
\midrule 
\midrule
SB-FNN (GELU) & $1.0203 \pm 0.5524 (e^{-4})$ & $2.0271 \pm 0.6217 (e^{-3})$ \\
SB-FNN (GELU + Constraint) & $6.8936 \pm 0.5735 (e^{-5})$ & $1.1477 \pm 0.1066 (e^{-3})$ \\
SB-FNN (Adaptive) & $6.8001 \pm 2.4594 (e^{-5})$ & $1.0955 \pm 0.0484 (e^{-3})$ \\
SB-FNN (Adaptive + Constraint) & $5.5949 \pm 0.3237 (e^{-5})$ & $9.3663 \pm 1.0792 (e^{-4})$ \\

\bottomrule
\end{tabular}%}
\end{table*}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{fig_results_new/variance.png}
\caption[Accuracy comparison of methods with and without variance constraint] {Accuracy comparison of methods with and without variance constraint. }
\label{fig:variance}
\end{figure}

Table \ref{tab:exp3} and Figure \ref{fig:variance} displays a comparison of the accuracy performance for methods with and without variance constraint. The methods used in the experiment were based on GELU and Adaptive activation functions, with the same starting learning rate of $0.01$ and epoch of $50$k. Except for the adaptive activation function, we take GELU into this experiment because it is designed as the original activation function applied to the FNN, and FNN is a base part of our SB-FNN. The N-MSE value was averaged over five tests with different random seeds for predicting the dynamics of two oscillatory models. The results of the ablation experiment demonstrate the effectiveness of the variance constraint in improving the performance of FNN-based models on predicting oscillatory dynamics.

% \section{Time Cost Analysis}

% \begin{table*}[!htb]
% \centering
% \scriptsize
% \caption[Time Cost Analysis] {Time Cost Analysis}
% \label{tab:exp4}
% \begin{tabular}{ l cccccc } 
% \toprule
% \multirow{2}{*}{Activation} & 
% \multicolumn{6}{c}{Trainning Time per Epoch / s} \\
% \cmidrule(l){2-7} 
% Function & Rep3 & Rep6 &  SIR & A-SIR & 1D Turing & 2D Turing \\
% \midrule 
% \midrule 
% \multirow{2}{*}{Tanh} & $7.4903$ & $7.9043$ & $7.5411$ & $1.1423$ & $2.0235$ & $1.6177$ \\ 
%  & $\pm0.6795 (e^{-2})$ & $\pm0.3299 (e^{-2})$ & $\pm0.7330 (e^{-2})$ & $\pm0.0596 (e^{-1})$ & $\pm0.1864 (e^{-1})$ & $\pm0.0327 (e^{-1})$ \\
% \multirow{2}{*}{ReLU} & $6.7811$ & $7.9735$ & $7.4282$ & $1.0946$ & $2.0448$ & $1.5984$ \\ 
%  & $\pm0.3456 (e^{-2})$ & $\pm0.4357 (e^{-2})$ & $\pm0.4627 (e^{-2})$ & $\pm0.0927 (e^{-1})$ & $\pm0.1665 (e^{-1})$ & $\pm0.0131 (e^{-1})$ \\
% \multirow{2}{*}{Softplus} & $8.1193$ & $8.6280$ & $7.3499$ & $1.1186$ & $1.9356$ & $1.5789$ \\ 
%  & $\pm0.6498 (e^{-2})$ & $\pm0.5897 (e^{-2})$ & $\pm0.3984 (e^{-2})$ & $\pm0.0955 (e^{-1})$ & $\pm0.1040 (e^{-1})$ & $\pm0.0318 (e^{-1})$ \\
% \multirow{2}{*}{ELU} & $7.1769$ & $8.1191$ & $7.3310$ & $1.1580$ & $1.9357$ & $1.6085$ \\ 
%  & $\pm0.2137 (e^{-2})$ & $\pm0.2983 (e^{-2})$ & $\pm0.1597 (e^{-2})$ & $\pm0.1371 (e^{-1})$ & $\pm0.2124 (e^{-1})$ & $\pm0.0292 (e^{-1})$ \\
% \multirow{2}{*}{GELU} & $7.6652$ & $8.7640$ & $7.5818$ & $1.2064$ & $2.1241$ & $1.5857$ \\ 
%  & $\pm1.6144 (e^{-2})$ & $\pm1.2170 (e^{-2})$ & $\pm0.7935 (e^{-2})$ & $\pm0.1172 (e^{-1})$ & $\pm0.1218 (e^{-1})$ & $\pm0.0111 (e^{-1})$ \\
% \multirow{2}{*}{Sin} & $7.3184$ & $8.0606$ & $7.4377$ & $1.0406$ & $1.9541$ & $1.6388$ \\ 
%  & $\pm0.3173 (e^{-2})$ & $\pm0.2456 (e^{-2})$ & $\pm0.6310 (e^{-2})$ & $\pm0.0506 (e^{-1})$ & $\pm0.1243 (e^{-1})$ & $\pm0.0245 (e^{-1})$ \\
% \multirow{2}{*}{Adaptive} & $9.6632$ & $1.0841$ & $9.0508$ & $1.2492$ & $2.8061$ & $4.4034$ \\ 
%  & $\pm1.2990 (e^{-2})$ & $\pm0.0428 (e^{-1})$ & $\pm0.5789 (e^{-2})$ & $\pm0.0343 (e^{-1})$ & $\pm0.1133 (e^{-1})$ & $\pm0.1157 (e^{-1})$ \\
% \multirow{2}{*}{SB-FNN} & $9.0656$ & $1.0262$ & $9.0508$ & $1.2492$ & $2.8061$ & $4.4034$ \\ 
%  & $\pm0.4910 (e^{-2})$ & $\pm0.0395 (e^{-1})$ & $\pm0.5789 (e^{-2})$ & $\pm0.0343 (e^{-1})$ & $\pm0.1133 (e^{-1})$ & $\pm0.1157 (e^{-1})$ \\
% \multirow{2}{*}{PINN} & $7.0960$ & $8.0010$ & $6.9456$ & $1.1917$ & $3.7831$ & $1.5404$ \\ 
%  & $\pm0.6624 (e^{-2})$ & $\pm0.4455 (e^{-2})$ & $\pm0.4092 (e^{-2})$ & $\pm0.0956 (e^{-1})$ & $\pm0.1542 (e^{-1})$ & $\pm0.1372 (e^{0})$ \\
 
% \bottomrule
% \end{tabular}%}
% \end{table*}

% In the experiments using different methods on various models, we have computed the average time taken per epoch, as presented in Table \ref{tab:exp4}. Please note that since the variance constraint is not appropriate for non-oscillatory models, their ``Adaptive'' rows are the same as the ``SB-FNN'' rows. For relatively simple models, applying the adaptive function incurs about 20\% more time per epoch, and the use of variance constraint does not result in a significant difference in time cost. On the other hand, the performance of the PINN method in terms of time is similar to that of single activation methods on simple models, but the time cost rises sharply as the model becomes more complex. In the 2D Turing model, PINN takes more than three times as much time as SB-FNN.

% \begin{figure}[h]
% \centering
% \includegraphics[width=1\textwidth]{fig/cyclic_compare.pdf}
% \caption{The N-MSE curves on two Repressilator models using FNN (without cyclic penalty), FNN (with cyclic penalty), SB-FNN (without cyclic penalty), SB-FNN (with cyclic penalty)}

% \label{fig:cyclic_compare}
% \end{figure}

% learning curves on Navier-Stokes ν = 1e−3 with different benchmarks. Train and test on the same resolution. For acronyms, see Section 5; details in Tables 1, 3, 4.


% \subsection{Prey Predatory Model}

% \begin{figure}[h]
% \centering
% \includegraphics[width=0.5\textwidth]{fig/PP_Fourier_20221014_061607_epoch=500000.png}
% \caption{PP ...}
% \label{1}
% \end{figure}

% Figure comparing accuracy between PINN and Fourier

% \subsection{Lorenz}

% PINN fails 

% \begin{figure}[h]
% \centering
% \includegraphics[width=0.5\textwidth]{fig/Lorenz_Fourier_20221015_012953_epoch=50000_3D.png}
% \caption{Lorenz ...}
% \label{2}
% \end{figure}

% \subsection{SIR}



% \subsection{Two-dimensional Turing Pattern}

% Complex PDEs

% \begin{figure}[h]
% \centering
% \includegraphics[width=0.7\textwidth]{fig/Turing_Fourier_20221016_081101_epoch=1500_map_pred_only.png}
% \caption{Turing ...}
% \label{3}
% \end{figure}

% \begin{figure}[h]
% \centering
% \includegraphics[width=0.8\textwidth]{fig/truth_50.png}
% \includegraphics[width=0.8\textwidth]{fig/truth_100.png}
% \includegraphics[width=0.8\textwidth]{fig/truth_150.png}
% \includegraphics[width=0.8\textwidth]{fig/truth_200.png}
% \caption{Turing 50, 100, 150, 200, FYI}
% \end{figure}

% \begin{figure}[h]
% \centering

% \caption{Turing 100*100, FYI}
% \end{figure}

% \begin{figure}[h]
% \centering

% \caption{Turing 150*150, FYI}
% \end{figure}

% \begin{figure}[h]
% \centering

% \caption{Turing 200*200, FYI}
% \end{figure}

% \subsection{Cell cycle model}



% \section{Inverse}
% \subsection{PP}
% \subsection{SIR}
% \subsection{AD model}


% \section{Hybrid}
% \subsection{AD model}