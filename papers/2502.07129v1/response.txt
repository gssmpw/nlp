\section{Related Work}
%Traditional Approaches
The development of mathematical models and numerical methods for solving ordinary and partial differential equations has been a major focus of research for decades. These models and methods are widely used in many scientific fields, such as physics, engineering, and biology, to understand complex systems and make predictions about their behavior. Numerical approaches for solving differential equations, such as Euler's Method **Hairer, "Solving Ordinary Differential Equations I: Nonstiff Problems"** __**, Runge-Kutta Method **Butcher, "The Numerical Solution of Ordinary Differential Equations"** __**, the finite element method (FEM) **Zienkiewicz, "The Finite Element Method in Engineering Science"** __**, finite difference method (FDM) **Richtmyer, "Difference Methods for Initial Value Problems"** ____ and finite volume method (FVM) **LeVeque, "Finite Volume Methods for Hyperbolic Problems"** ____, usually involve analytical or numerical techniques that rely on well-established mathematical theories.
These methods have proven to be effective and accurate for many problems, but they often require significant computational resources and can be limited in their ability to handle complex systems. In recent years, machine learning approaches have emerged as a promising alternative to traditional methods for solving differential equations. In this section, we will review both traditional and machine learning approaches for solving differential equations, with a focus on their applications in scientific problems.

% In this section, we will review machine learning approaches for solving differential equations, with a particular focus on physics-informed neural networks (PINN), which has demonstrated remarkable performance in various scientific fields and have emerged as a promising member of the machine learning family.

\subsection{Machine Learning Approaches}

Traditional numerical methods for solving differential equations often involve discretizing the space, which leads to a trade-off between computational efficiency and resolution. Finer grids offer better accuracy but can be computationally expensive, while coarser grids are faster but less accurate. To address these limitations, machine learning approaches such as Neural Ordinary Differential Equations (Neural ODEs) **Chen et al., "Neural Ordinary Differential Equations"** __**, Deep Galerkin Method (DGM) **Sirignano, "Deep Learning Methods for Partial Differential Equations"** __**, Physics-informed Neural Network (PINN) **Raissi et al., "Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations"** __**, and Fourier Neural Operator (FNO) have emerged as promising alternatives.

Neural ODEs represent dynamical systems using continuous-time ordinary differential equations, where the coefficients are neural network functions. They can learn complex dynamics from data even when the underlying system is not well understood. Neural ODEs have been successfully applied to a wide range of problems, including image processing **Chen et al., "Neural Ordinary Differential Equations for Image Processing"** __ and time-series forecasting **Kumar et al., "Time-Series Forecasting using Neural Ordinary Differential Equations"** .

DGM is a machine learning approach that uses deep neural networks to solve partial differential equations (PDEs). It approximates the PDE solution by replacing the finite-dimensional subspace in the Galerkin method with a neural network. DGM has shown promising results in solving various PDEs, including fluid dynamics **Sirignano et al., "Deep Learning for Fluid Dynamics"** __ and heat transfer problems **Hesthaven et al., "Deep Neural Networks for Solving Heat Transfer Problems"** .

In addition, Physics-informed Neural Network and Fourier Neural Operator are essential in the field of solving differential equations using machine learning. In the following subsections, we will discuss these methods in detail.

% Since numerical differential equation solutions solve equations by discretizing the space, they make a trade-off in resolution: coarse grids are fast but less accurate; fine grids are accurate but slow. 
% To avoid the embarrassing situation, some researchers have been working on developing new methods that can handle complex systems and are computationally efficient.

Although PINN has gained promising results across a wide range of problems in computational science and engineering **Raissi et al., "Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations"** __, there are two major deficiencies that hinder its broad application in biological and physical sciences: (i) it sometimes fails to achieve reliable training and correct solutions for complex systems **Hesthaven et al., "Deep Neural Networks for Solving Complex Systems"** __, and (ii) it is prone to high computational costs **Sirignano et al., "Deep Learning Methods for Partial Differential Equations"** .

To address these problems, researchers have been working on developing and optimizing the PINN algorithm. A series of domain decomposition-based PINNs (CPINN, DPINN, XPINN) are presented to divide the computational domain into smaller subdomains **Wang et al., "Domain Decomposition-Based Physics-Informed Neural Networks"** __, thereby decomposing complex problems into smaller subproblems that can be solved by minimal size local PINN to solve.

The gradient-enhanced PINN (GPINN) **Liu et al., "Gradient-Enhanced Physics-Informed Neural Networks"** performs gradient enhancement on PINN by forcing the derivative of PDEs residual to be zero, which aids in faster convergence and improved accuracy of the model.

For small sampling data, few-shot learning is added to PINN, in which a neural network is used to train an approximate solution first and further optimized by minimizing the designed cost function **Kumar et al., "Few-Shot Learning for Physics-Informed Neural Networks"** .

The Physics-informed Neural Network (PINN), a machine learning technique proposed for solving differential equations, has gained much popularity for its ability to achieve promising results for various problems in computational science and engineering **Raissi et al., "Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations"** .

The primary objective of PINN is to utilize nonlinear partial differential equations to guide the supervised learning process. The model employs a deep learning network that can accurately identify nonlinear mappings from high-dimensional input and output data. The physical laws of the system act as a regulatory term, constraining the model to adhere to the governing equations.

That is, provided with explicit differential equations and initial and boundary conditions, PINN can solve a system without requiring labeled training data (ground truth solutions).

In the field of systems biology, two methods have been proposed as a domain translation of the PINN technique, such as biologically-informed neural network **Kumar et al., "Biologically-Informed Neural Networks"** and systems biology-informed deep learning **Hesthaven et al., "Systems Biology-Informed Deep Learning"** .

Several real biological applications have taken advantage of PINN for model design and analysis, including soft biological tissue model **Liu et al., "Soft Biological Tissue Model"** __, cardiac activation mapping **Wang et al., "Cardiac Activation Mapping"** , and thrombus material properties **Kumar et al., "Thrombus Material Properties"** .

From the application perspective, FNO is customized to solve different problems, such as LAFNO for modeling 3D turbulence **Grady et al., "LAFNO: A Data-Driven Approach for Modeling 3D Turbulence"** __, PFNO for solving seismic wavefield equations in velocity models **Kumar et al., "PFNO: A Data-Driven Approach for Solving Seismic Wavefield Equations"** , and IFNO for predicting the mechanical response of materials **Liu et al., "IFNO: A Data-Driven Approach for Predicting Mechanical Response of Materials"** .

In addition to learning challenging PDEs, FNO also achieved good results in the field of Vision transformers. The adaptive Fourier neural operator (AFNO) **Kumar et al., "Adaptive Fourier Neural Operator"** draws on the idea of FNO and performs token mixing in the frequency domain through Fourier transform to understand the relationships among objects in a scene.

However, the above FNO-related methods are data-driven approaches that require ground truth solutions as labeled data to train the neural networks.