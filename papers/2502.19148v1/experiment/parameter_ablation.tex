% \red{We then conduct experiments to study the impact of various parameter settings on the performance of our method. We fixed all other parameters and analyzed each parameter individually. We will introduce them one by one in the following paragraphs.}

% \paragraph{\textbf{Analysis for Iteration Number $T$.}} 
% To explore the impact of the number of optimization iterations on our methodâ€™s performance, particularly for different language models and user preference dimensions. We conduct experiments using 0, 20, 40, 60, 80, and 100 iterations. Following the settings described in \autoref{sec:exp_settings}, we use two evaluation metrics, presented in the first and second rows of the figure, respectively. As shown in \autoref{fig:abla_iter}, the results indicate that increasing the number of iterations generally improves performance on both metrics. 
% %Notably, a significant improvement is observed between 0 and 20 iterations, while most runs achieve optimal performance between 40 and 60 iterations. Interestingly, too many iterations lead to a decline in performance, which can be attributed to \fengshuo{need to think a think}.
% % The experimental results point out that the performance of our method shows a significant increase from 0 to 20 in most cases, and after 20, it rises slowly or remains stable as the number of iterations increases.
% Notably, a significant improvement is observed between 0 and 20 iterations, while most runs achieve optimal performance between 40 and 80 iterations.
% % Considering that some cases showed a significant peak when the iteration number was 60, it indicates that an iteration number of 60 can best satisfy most situations and offers high computational efficiency. Therefore, we ultimately chose 60 as our final parameter.
% Interestingly, too many iterations lead to a decline in performance. We think that may be attributed to the over-fitting of the utility which is only an approximation of the latent real preference.  


% % \vspace{-1.5ex}


% \paragraph{\textbf{Analysis for $\eta$.}} 
% \red{We conduct the experiments ranging from 2, 4, $\dots$, 20.} As shown in the first subplot of \autoref{fig:abla_params_sensitive}, as the learning rate $\eta$ increases, the performance initially rises sharply, then slowly declines, and eventually stabilizes. Therefore, we chose $\eta = 10$ as our final parameter, where the turning point is observed. 
% %Unlike typical machine learning tasks that utilize small learning rates for large-scale dataset iterations, our problem involves limited data, making a larger learning rate more effective in optimizing user preferences\fengshuo{check this explanation}.

% % \vspace{-1.5ex}

% \paragraph{\textbf{Analysis for $\alpha$ and $\lambda$.}}
% In \autoref{eq:utility_func}, $\alpha$ and $\lambda$ are key parameters for adjusting the utility function: $\alpha$ regulates the balance between approximating user preferences, while $\lambda$ constrains the current policy to avoid significant deviations from the initial policy. \red{We conduct experiments of both the parameters ranging from 1, 2, $\dots$, 10.} As shown in the last two subplots of \autoref{fig:abla_params_sensitive}, both parameters exhibit a similar trend: performance rises rapidly from 0 to 2, declines from 2 to 4, and then stabilizes. This trend indicates a trade-off between preference alignment and policy stability, with both $\alpha$ and $\lambda$ affecting how aggressively the policy is adjusted. Excessively large values for these parameters lead to overly drastic policy changes, resulting in poor adaptation to the optimization task. Based on the experimental results, we set both parameters to 2 to balance performance and stability.

% %%%%%%%%%%%%%


% \paragraph{\textbf{Analysis for Parameter Settings.}} 
% We then conduct experiments to study the impact of various parameter settings on the performance of our method. We fixed all other parameters and analyzed each parameter individually. We will introduce them one by one as follows:
% \begin{itemize}[leftmargin=*]
% \vspace{-1ex}

% \item \textbf{Iteration Number $T$.} We conduct experiments with 0, 20, 40, 60, 80, and 100 iterations to assess the impact on performance across different language models and user preference dimensions, finding that performance generally improves with more iterations, particularly between 0 and 20, and peaks between 40 and 80 iterations, as shown in \autoref{fig:abla_iter}, before declining due to potential over-fitting to the approximated utility.

% \vspace{-1ex}
% \item \textbf{Learning Rate $\eta$.} We perform experiments ranging from 2, 4, $\dots$, 20. As shown in the first subplot of \autoref{fig:abla_params_sensitive}, as the learning rate $\eta$ increases, the performance initially rises sharply, then slowly declines, and eventually stabilizes. 
% % Therefore, we chose $\eta = 10$ as our final parameter, where the turning point is observed. 

% \vspace{-1ex}
% \item \textbf{Key Parameters $\alpha$ and $\lambda$.} 
% In \autoref{eq:utility_func}, we found that setting both $\alpha$ and $\lambda$ to 2 optimally balances performance and stability, as experiments show that performance increases rapidly from 0 to 2, decreases from 2 to 4, and then stabilizes, highlighting the trade-off between preference alignment and policy stability, as illustrated in the last two subplots of \autoref{fig:abla_params_sensitive}.
% \vspace{-1ex}
% \end{itemize}
% More details of the analysis for our parameter settings can be found in Appendix \ref{app:more_ablation_results}.


% %%%%%%%%%%%%%%%%


\paragraph{\textbf{Analysis for Parameter Settings.}} 
We then conduct experiments to study the impact of various parameter settings on the performance of our method. We fixed all other parameters and analyzed each parameter individually. We will introduce them one by one as follows:
\begin{itemize}[leftmargin=*]
\vspace{-1ex}

\item \textbf{Iteration Number $T$.} 
% We conduct experiments with 0, 20, 40, 60, 80, and 100 iterations to assess the impact on performance across different language models and user preference dimensions, finding that performance generally improves with more iterations, particularly between 0 and 20, and peaks between 40 and 80 iterations, as shown in \autoref{fig:abla_iter}, before declining due to potential over-fitting to the approximated utility.
We conduct experiments using 0, 20, 40, 60, 80, and 100 iterations. As shown in \autoref{fig:abla_iter}, the results indicate that increasing the number of iterations generally improves performance on both metrics. 
Notably, a significant improvement is observed between 0 and 20 iterations, while most runs achieve optimal performance between 40 and 80 iterations.
Interestingly, too many iterations lead to a decline in performance. We suppose that may be attributed to the over-fitting of the utility which is only an approximation of the latent real preference.  

\vspace{-1ex}
\item \textbf{Learning Rate $\eta$.} 
% We perform experiments ranging from 2, 4, $\dots$, 20. As shown in the first subplot of \autoref{fig:abla_params_sensitive}, as the learning rate $\eta$ increases, the performance initially rises sharply, then slowly declines, and eventually stabilizes. 
% % Therefore, we chose $\eta = 10$ as our final parameter, where the turning point is observed. 
We conduct the experiments ranging from 2, 4, $\dots$, 20. As shown in the first subplot of \autoref{fig:abla_params_sensitive}, as the learning rate $\eta$ increases, the performance initially rises sharply, then slowly declines, and eventually stabilizes. Therefore, we chose $\eta = 10$ as our final parameter, where the turning point is observed.

\vspace{-1ex}
\item \textbf{Parameter $\alpha$ and $\lambda$.} 
% In \autoref{eq:utility_func}, we found that setting both $\alpha$ and $\lambda$ to 2 optimally balances performance and stability, as experiments show that performance increases rapidly from 0 to 2, decreases from 2 to 4, and then stabilizes, highlighting the trade-off between preference alignment and policy stability, as illustrated in the last two subplots of \autoref{fig:abla_params_sensitive}.
In \autoref{eq:utility_func}, $\alpha$ and $\lambda$ are key parameters for adjusting the utility function: $\alpha$ regulates the balance between approximating user preferences, while $\lambda$ constrains the current policy to avoid significant deviations from the initial policy. We conduct experiments of both the parameters ranging from 1, 2, $\dots$, 10. As shown in the last two subplots of \autoref{fig:abla_params_sensitive}, both parameters exhibit a similar trend: performance rises rapidly from 0 to 2, declines from 2 to 4, and then stabilizes. 
% This trend indicates a trade-off between preference alignment and policy stability, with both $\alpha$ and $\lambda$ affecting how aggressively the policy is adjusted. Excessively large values for these parameters lead to overly drastic policy changes, resulting in poor adaptation to the optimization task. 
Based on the experimental results, we set both parameters to 2 to balance performance and stability.
\vspace{-1ex}
\end{itemize}

More details of the analysis for our parameter settings can be found in Appendix \ref{app:more_ablation_results}.

