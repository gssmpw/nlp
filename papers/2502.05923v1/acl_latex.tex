% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

\usepackage{mathtools}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
\usepackage{float}
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{booktabs}
% \usepackage{graphicx}
\usepackage[authormarkup=none,final]{changes}
\usepackage[]{todonotes}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\newcommand\crule[3][black]{\textcolor{#1}{\rule{#2}{#3}}}
\definecolor{featBlue}{RGB}{51, 102, 204}
\definecolor{ruleBrown}{RGB}{102, 51, 00}
\newcommand{\our}{\textsc{ARISE}}
\newcommand{\opel}{OpenLLaMA}
\newcommand{\bfl}{\mathbf l}
\newcommand{\bfx}{\mathbf x}
\newcommand{\Ical}{\mathcal{I}}
\newcommand{\Ucal}{\mathcal{U}}
\newcommand{\Lcal}{\mathcal{L}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Scal}{\mathcal{S}}

\definecolor{teal}{rgb}{0.0, 0.5, 0.5}
\definecolor{turq}{rgb}{0.68, 0.93, 0.93}


\definechangesauthor[name={Amrith Krishna}, color=teal]{AK}
\definechangesauthor[name={Ganesh}, color=turq]{GR}


\newcommand{\todoAK}[1]{\todo[color=green,author=AK]{#1}}
\newcommand{\todoGR}[1]{\todo[color=turq,author=GR]{#1}}
\newcommand{\todoAM}[1]{\todo[color=yellow,author=AM]{#1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{\our: Iterative Rule Induction and Synthetic Data Generation for Text Classification}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{
Yaswanth M$^{\heartsuit0}$,
Vaibhav Singh$^{\spadesuit0}$,
\textbf{Ayush Maheshwari$^{\diamondsuit}$\thanks{Work done while at IIT Bombay, with BharatGen.}}, \\
\textbf{Amrith Krishna}$^{\clubsuit}$,
\textbf{Ganesh Ramakrishnan}$^{\clubsuit\spadesuit}$ \\
$^{\spadesuit}$Indian Institute of Technology Bombay,
$^{\clubsuit}$BharatGen\\
% $^{\delta}$ ayush affil.
$^{\heartsuit}$Accenture, $^{\diamondsuit}$NVIDIA \\
}
%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}


We propose \our, a framework that iteratively induces rules and generates synthetic data for text classification. We combine synthetic data generation and automatic rule induction, via bootstrapping, to iteratively filter the generated rules and data. We induce rules via inductive generalisation of syntactic n-grams, enabling us to capture a complementary source of supervision. These rules alone lead to performance gains in both, in-context learning (ICL) and fine-tuning (FT) settings. Similarly, use of augmented data from ARISE alone improves the  performance for a model, outperforming configurations that rely on complex methods like contrastive learning.  Further, our extensive experiments on various datasets covering three full-shot, eight few-shot and seven multilingual variant settings demonstrate that the rules and data we generate lead to performance improvements across these diverse domains and languages.

 


%propose a bootstrapped rule and data filtering approach that results in state of the art results for several few-shot text classification datasets. 



%We jointly train a neural classifier,  via data programming.These rules are then integrated with off-the-shelf classifiers as a form of weak supervision, specifically as labeling functions for data programming. The rules we generate are used as  for In this work, we  Further,  Specifically,    

%syntactically driven automatic rule induction approach for semi-supervised text classification. In this study, we utilize subtrees of dependency parses as features to partition a given classification dataset. 
% In this study, we utilize subtrees of dependency parses as features to partition a given classification dataset. 
%The least general generalization obtained for each such partition forms a rule. These rules   Finally, we show that the integration with \our~  can not only lead to performance improvements on a 7B LLM but can also be performed efficiently by leveraging parameter-efficient fine-tuning methods.
\end{abstract}


\input{1intro}
\input{2synNgram}
\input{3method}
\input{4exp}

\section*{Limitations}

A major challenge with \our, currently is the overhead with the rule induction. We currently use syntactic n-grams with upto 3 nodes as our features. The search space exponentially increases as the nodes of the subtree increase, limiting our ability to induce higher-order tree structures as rules. While we currently rely on labeled instances of synthetically generated data, a strength of weak supervision is to incorporate unlabeled data. Several real-world scenarios often come up where unlabeled data is readily available. It needs to be further investigated whether synthetically generated labeled data can match the quality of real-world unlabeled data in the context of weak supervision. The current work does not explore this line of work, though it appears to be an important question that requires further investigation.

\section*{Ethics Statement}
All experiments conducted in this study utilize publicly
available datasets. We use publicly hosted APIs of GPT and Claude for synthetic data generation. The prompts used in this study included guardrails in the form of instructions to avoid generating problematic content.

\section*{Acknowledgements}
We acknowledge BharatGen and IIT Bombay for providing resources and support to Vaibhav Singh. Yashwanth M. acknowledges Accenture for their support during this research. We also extend our appreciation to the reviewers for their valuable feedback.
%To facilitate futurereproduction without unnecessary energy consumption, we will make our codes openly accessible.
%\section*{Acknowledgments}

%This document has been adaptedby Steven Bethard, Ryan Cotterell and Rui Yanfrom the instructions for earlier ACL and NAACL proceedings, including those forACL 2019 by Douwe Kiela and Ivan Vuli\'{c},

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\input{output.bbl}

\appendix


\section{Appendix}
\label{sec:appendix}
\subsection{Related Work}

\our~uses syntactic n-grams as its rules. Use of syntactic contexts in constructing feature space for downstream NLP tasks has been extensively explored in several of the past works \cite{liang-etal-2011-learning, goldberg-orwant-2013-dataset,biemann2016network}. \citet{goldberg-orwant-2013-dataset} released a large scale collection of syntactic n-grams obtained from 3.4 million books. \citet{biemann2016network} looks from a network science perspective and focuses on graph motifs. Learning feature functions using morphosyntactic information as horn clauses has shown to benefit under a low-resource setting for languages such as Czech and Sanskrit, often requiring less than 10\% of labeled training data required for neural counterparts \cite{10.1162/coli_a_00390,krishna-etal-2018-free}. 

Using syntactic context, we incorporate signals that may not otherwise be explicitly captured in large language models. Further, we automate the generation and filtering of such rules by relying extensively on rule induction approaches \cite{varma2018snuba,bajpai-etal-2024-fair,lao2010relational}. Additionally, we consider our rule generation approach as a restricted instance of program synthesis via least general generalization as demonstrated in \citet{Raza_Gulwani_Milic-Frayling_2014}, and \citet{thakoor2018multisynthesis}.

Data augmentation and generation in text has become effortless with LLMs \cite{ding2024data}. However, that does not ensure obtaining data with relevant supervisory signals, highlighting the need for targeted data filtering or generation \cite{pmlr-v139-killamsetty21a,mirzasoleiman2020coresets}. This may include data scoring and ranking \cite{lin-etal-2023-selective}, iterative data generation \cite{rao-etal-2023-makes}, bootstrapping \cite{varma2018snuba} or targeted subset selection \cite{pmlr-v37-wei15}. \citet{wang-etal-2023-lets} and \citet{lee-etal-2024-llm2llm} explore similar themes by utilizing errors from language models to iteratively refine a synthetic training dataset. Similarly, \cite{hoang-etal-2018-iterative} discussed back-translation in the context of machine translation to augment training data. In \our, we use bootstrapping approach for data filtering and apply our filtering on synthetically generated data, instead of unlabeled data from an existing corpus. 



\subsection{Joint Learning with Rules}
\label{contrastive}

The few-shot classifier is trained using SPEAR \cite{maheshwari2021semi}, a Joint Learning framework that learns a feature-based classification model and a label aggregation (LA) model. The feature model is a pre-trained neural network and LA is a generative model \cite{cage}, learned via PWS, using the automatically induced rules as labeling functions. Formally, LA is denoted as $P_{\theta}(\bfl_i, y)$, where $\bfl_i$ %is a vector of size of labeling functions (LFs) for an input $x_i$. Alternatively, $\bfl_i$ 
a vector that represents the firing of all LFs for an input $\bfx_i$. Each firing, $l_{ij}$ can be either 0 (abstain) or class label $k$ \cite{cage}.  %
The model learns $K$ parameters $\theta_{j1}, \theta_{j2}, \ldots, \theta_{jK}$ for each class corresponding to each LF $l_{j}$.
\begin{equation}\displaystyle P_{\theta}(\bfl_i, y) = \frac{1}{Z_\theta} \prod_{j=1}^m \psi_\theta(l_{ij}, y)\label{eq:joint1}\end{equation}\begin{equation}\psi_{\theta}(l_{ij},y) = \begin{cases}\exp(\theta_{jy})  & \text{if $l_{ij}\ne 0$} \\1 & \text{otherwise.}\end{cases}\label{eq:decoupledthetas}\end{equation}

\begin{equation}\begin{split}Z_\theta = & \sum_y \prod_j\sum_{l \in \{1, 0\}} \psi_\theta(l, y)
\\        = & \sum_{y\in \Ycal}\prod_j(1+\exp(\theta_{jy}))\end{split}{}\end{equation}

%\subsection{Joint learning objective}

Following \citet{maheshwari2021semi}, our Joint Learning objective incorporates three different loss components for learning from labeled data. %However, we exclude the loss components that use unlabeled data. 
We provide a brief overview of each loss component below, while encouraging interested readers to \cite{maheshwari2021semi} for detailed information.
{\begin{align}\nonumber
\min_{\theta, \phi} &\sum_{i \in \Lcal} L_{CE}\left(P_\phi^f(y|\bfx_i), y_i\right)
 + LL_s(\theta| \Lcal)  
 \\ &+ \sum_{i \in \Lcal} KL\left( P_\phi^f(y|\bfx_i),P_\theta(y|\bfl_i)\right) \nonumber
\label{eq:objective}
\end{align}}
 
The first component of the loss is the standard cross-entropy loss for the model $P_\phi^f$. The second component is the negative log-likelihood on the dataset. The third is the KL-Divergence between the predictions from LA and $P_\phi^f$, which enforces consensus by aligning their predictions. %across the combined labeled and unlabeled dataset. %Specifically, for any input $\mathbf{x}_i \in \mathcal{U}$, where $\mathbf{l}_i$ represents the output vector of all labeling functions (LFs), we determine the predicted label for $\mathbf{x}i$ using the LF-based graphical model $P\theta(\mathbf{l}_i, y)$ as $g(\mathbf{l}i) = \arg\max_y P\theta(\mathbf{l}_i, y)$.
%The final component is the quality guides \cite{cage},denoted as $R(\theta|{q_j})$.



%to improve the robustness and stability of unsupervised likelihood training while utilizing LFs. Let parameter $q_j$ represents the fraction of instances where LF $l_j$ correctly triggers, while $q_j^t$ represents the user's estimation of the agreement between the labels $y_i$ and $l_{ij}$ for a given example $\bfx_i$ for which the labels $y_i$ and $l_{ij}$ agree.
%In cases where the user's beliefs are unavailable, we leverage the precision of the LFs on the validation set as a surrogate measure for the user's beliefs.


% The task of synthesizing and refining datasets through iterative methods has seen various approaches in the literature. This section reviews the most relevant works and distinguishes ARISE's unique contributions.

% \subsection{Iterative Data Generation}
%\cite{rao-etal-2023-makes} introduced an approach that applies iterative data generation techniques for commonsense rule generation. While their method significantly enhances performance in generating more contextualized data, ARISE extends this approach by not only refining the generated data but also incorporating weak supervision to filter and enhance data quality specifically for text classification tasks.

 %Their approaches focus primarily on correcting model biases through error analysis. Unlike these methods, ARISE integrates automatic rule induction and applies a hybrid strategy combining both synthetic data generation and real-time rule adjustment, which has shown to improve both accuracy and efficiency in handling multi-class classification tasks.

% \subsection{Back-Translation Techniques}
 %Their method cyclically translates between the target and source language to enrich the training corpus. In contrast, ARISE adopts a similar iterative refinement philosophy but applies it within the framework of text classification, using syntactic transformations to enhance data diversity and model robustness against overfitting.

% \subsection{Distinctive Features of ARISE}
% ARISE distinguishes itself by:
% \begin{itemize}
%     \item Leveraging both supervised and unsupervised learning techniques to optimize the data augmentation process, which is not commonly observed in the related works.
%     \item Introducing a novel rule-induction mechanism that utilizes both the generated and real-world data to refine rules iteratively, ensuring that the synthetic data aligns closer with real-world distributions.
%     \item Employing a composite approach that integrates error analysis from model predictions, which helps in pinpointing specific weaknesses in data handling and model training strategies.
% \end{itemize}

% These enhancements enable ARISE to not only generate more relevant and diverse data but also improve the model's performance significantly by reducing the typical errors associated with synthetic data, as demonstrated in our experiments.

% This is an appendix.


\subsection{Paraphrasing for Diverse Rules}
\label{paraphrase}

We employ various techniques to generate diverse syntactic structures for our pool of available features to be used in the rule induction stage. First, we perform active to passive voice sentence phrasing and vice versa using LLMs. Second, we perform dependency tree morphing \cite{sahin-steedman-2018-data}, to obtain simplified morphed  dependency trees. Here, we remove peripheral relations like adjectives, such that the core semantics of the sentence is still preserved. Third, we apply role prompting \cite{schulhoff2024prompt}, by prompting LLMs to rewrite sentences in the style of well-known authors \cite{wikipediaCategory21stcenturyEnglish}. Role prompting was exclusively applied during monolingual experiments.

\end{document}
