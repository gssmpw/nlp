@article{ahn2022can,
  title={Do as I can, not as I say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{chen2023open,
  title={Open-vocabulary queryable scene representations for real world planning},
  author={Chen, Boyuan and Xia, Fei and Ichter, Brian and Rao, Kanishka and Gopalakrishnan, Keerthana and Ryoo, Michael S and Stone, Austin and Kappler, Daniel},
  booktitle={ICRA},
  pages={11509--11522},
  year={2023}
}

@article{eisner2022flowbot3d,
  title={Flowbot3d: Learning 3d articulation flow to manipulate articulated objects},
  author={Eisner, Ben and Zhang, Harry and Held, David},
  journal={arXiv preprint arXiv:2205.04382},
  year={2022}
}

@inproceedings{gu2024conceptgraphs,
  title={Conceptgraphs: Open-vocabulary 3d scene graphs for perception and planning},
  author={Gu, Qiao and Kuwajerwala, Ali and Morin, Sacha and Jatavallabhula, Krishna Murthy and Sen, Bipasha and Agarwal, Aditya and Rivera, Corban and Paul, William and Ellis, Kirsty and Chellappa, Rama and others},
  booktitle={ICRA},
  pages={5021--5028},
  year={2024}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@inproceedings{jain2020cordial,
  title={A cordial sync: Going beyond marginal policies for multi-agent embodied tasks},
  author={Jain, Unnat and Weihs, Luca and Kolve, Eric and Farhadi, Ali and Lazebnik, Svetlana and Kembhavi, Aniruddha and Schwing, Alexander},
  booktitle={ECCV},
  pages={471--490},
  year={2020}
}

@article{karaman2011sampling,
  title={Sampling-based algorithms for optimal motion planning},
  author={Karaman, Sertac and Frazzoli, Emilio},
  journal={IJRR},
  volume={30},
  number={7},
  pages={846--894},
  year={2011},
  publisher={Sage Publications Sage UK: London, England}
}

@article{khurana2023natural,
  title={Natural language processing: state of the art, current trends and challenges},
  author={Khurana, Diksha and Koli, Aditya and Khatter, Kiran and Singh, Sukhdev},
  journal={Multimedia Tools and Applications},
  volume={82},
  number={3},
  pages={3713--3744},
  year={2023},
  publisher={Springer}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{li2024manipllm,
  title={Manipllm: Embodied multimodal large language model for object-centric robotic manipulation},
  author={Li, Xiaoqi and Zhang, Mingxu and Geng, Yiran and Geng, Haoran and Long, Yuxing and Shen, Yan and Zhang, Renrui and Liu, Jiaming and Dong, Hao},
  booktitle={CVPR},
  pages={18061--18070},
  year={2024}
}

@article{lin2023medical,
  title={Medical visual question answering: A survey},
  author={Lin, Zhihong and Zhang, Donghao and Tao, Qingyi and Shi, Danli and Haffari, Gholamreza and Wu, Qi and He, Mingguang and Ge, Zongyuan},
  journal={Artificial Intelligence in Medicine},
  volume={143},
  pages={102611},
  year={2023},
  publisher={Elsevier}
}

@article{liu2022multi,
  title={Multi-agent embodied visual semantic navigation with scene prior knowledge},
  author={Liu, Xinzhu and Guo, Di and Liu, Huaping and Sun, Fuchun},
  journal={RA-L},
  volume={7},
  number={2},
  pages={3154--3161},
  year={2022},
  publisher={IEEE}
}

@article{mahler2017dex,
  title={Dex-net 2.0: Deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics},
  author={Mahler, Jeffrey and Liang, Jacky and Niyaz, Sherdil and Laskey, Michael and Doan, Richard and Liu, Xinyu and Ojea, Juan Aparicio and Goldberg, Ken},
  journal={arXiv preprint arXiv:1703.09312},
  year={2017}
}

@inproceedings{mandi2024roco,
  title={Roco: Dialectic multi-robot collaboration with large language models},
  author={Mandi, Zhao and Jain, Shreeya and Song, Shuran},
  booktitle={ICRA},
  pages={286--299},
  year={2024}
}

@inproceedings{mo2021where2act,
  title={Where2act: From pixels to actions for articulated 3d objects},
  author={Mo, Kaichun and Guibas, Leonidas J and Mukadam, Mustafa and Gupta, Abhinav and Tulsiani, Shubham},
  booktitle={ICCV},
  pages={6813--6823},
  year={2021}
}

@inproceedings{mousavian2019,
  title={6-dof graspnet: Variational grasp generation for object manipulation},
  author={Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter},
  booktitle={ICCV},
  pages={2901--2910},
  year={2019}
}

@inproceedings{ravi2023vlc,
  title={VLC-BERT: Visual Question Answering with Contextualized Commonsense Knowledge},
  author={Ravi, Sahithya and Chinchure, Aditya and Sigal, Leonid and Liao, Renjie and Shwartz, Vered},
  booktitle={WACV},
  pages={1155--1165},
  year={2023}
}

@inproceedings{shao2023prompting,
  title={Prompting large language models with answer heuristics for knowledge-based visual question answering},
  author={Shao, Zhenwei and Yu, Zhou and Wang, Meng and Yu, Jun},
  booktitle={CVPR},
  pages={14974--14983},
  year={2023}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={NeurIPS},
  volume={36},
  year={2024}
}

@inproceedings{tong2024oval,
  title={OVAL-Prompt: Open-Vocabulary Affordance Localization for Robot Manipulation through LLM Affordance-Grounding},
  author={Tong, Edmond and Opipari, Anthony and Lewis, Stanley Robert and Zeng, Zhen and Jenkins, Odest Chadwicke},
  booktitle={ICRA Workshops},
  year={2024}
}

@article{wen2024secure,
  title={How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?},
  author={Wen, Congcong and Liang, Jiazhao and Yuan, Shuaihang and Huang, Hao and Fang, Yi},
  journal={arXiv preprint arXiv:2402.09546},
  year={2024}
}

@inproceedings{wen2025zero,
  title={Zero-shot object navigation with vision-language models reasoning},
  author={Wen, Congcong and Huang, Yisiyuan and Huang, Hao and Huang, Yanjia and Yuan, Shuaihang and Hao, Yu and Lin, Hui and Liu, Yu-Shen and Fang, Yi},
  booktitle={International Conference on Pattern Recognition},
  pages={389--404},
  year={2025},
  organization={Springer}
}

@inproceedings{xie2023language,
  title={Language-conditioned path planning},
  author={Xie, Amber and Lee, Youngwoon and Abbeel, Pieter and James, Stephen},
  booktitle={CoRL},
  pages={3384--3396},
  year={2023},
  organization={PMLR}
}

@article{zeng2022socratic,
  title={Socratic models: Composing zero-shot multimodal reasoning with language},
  author={Zeng, Andy and Attarian, Maria and Ichter, Brian and Choromanski, Krzysztof and Wong, Adrian and Welker, Stefan and Tombari, Federico and Purohit, Aveek and Ryoo, Michael and Sindhwani, Vikas and others},
  journal={arXiv preprint arXiv:2204.00598},
  year={2022}
}

@inproceedings{zhang2021vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={CVPR},
  pages={5579--5588},
  year={2021}
}

@inproceedings{zhang2022multi,
  title={Multi-agent path finding for precedence-constrained goal sequences},
  author={Zhang, Han and Chen, Jingkai and Li, Jiaoyang and Williams, Brian and Koenig, Sven},
  booktitle={AAMAS},
  year={2022}
}

@inproceedings{zitkovich2023rt,
  title={RT-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Zitkovich, Brianna and Yu, Tianhe and Xu, Sichun and Xu, Peng and Xiao, Ted and Xia, Fei and Wu, Jialin and Wohlhart, Paul and Welker, Stefan and Wahid, Ayzaan and others},
  booktitle={CoRL},
  pages={2165--2183},
  year={2023},
  organization={PMLR}
}

