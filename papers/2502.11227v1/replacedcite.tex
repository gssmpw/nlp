\section{Related Work}
\label{sec:related}
% \noindent \textbf{Robot Manipulation.}
% Recent advancements in robotic manipulation increasingly employ deep learning, with convolutional neural networks predicting grasps from RGB-D images and variational autoencoders____ for predicting 6-DOF grasp poses from point clouds____. Incorporating state-based and vision-based reinforcement learning____ has further enabled complex, long-horizon tasks. For instance, Where2Act ____ proposes networks to predict actionable pixels and movable regions, enhancing interactions in diverse environments. Flowbot3d ____ and VoxPoser ____ further explore vision-based methods for 3D object manipulation, with the latter synthesizing adaptable robot trajectories through 3D value maps derived from LLMs based on natural language instructions. In addition, the introduction of open-vocabulary spatial semantic frameworks, including NLMap ____, Conceptgraphs____, and OVAL-Prompt____, significantly enhance robotic autonomy and adaptability to execute complex instructions. However, these works mainly focus on a single robot instead of multi-robot collaboration, which may be less efficient or robust in long-horizon tasks.

\noindent \textbf{Multi-robot Collaboration.}
Research on multi-robot manipulation is extensive, with early work concentrating on low-level planning, such as devising collision-free motion trajectories ____, where sampling-based methods have been particularly prominent ____. Recent advancements have also introduced learning-based approaches as viable alternatives ____. Additionally, some works focus on multi-robot collaboration in dynamic and complex control scenarios ____. Moreover, the development of embodied AI simulators has facilitated the emergence of embodied collaboration tasks, such as collaborative navigation ____ and furniture rearrangement ____. 
% In this work, we focus on multi-robot collaboration for manipulation by enabling intelligent agents with a physical embodiment to interact with the environment. 

% \noindent \textbf{LLM in Robotics.}
% The field of robotics research based on LLMs has rapidly evolved, harnessing the advanced natural language understanding ____ and commonsense reasoning capabilities ____ of these models to enhance robotic interaction and task execution. Noticeable developments include the use of vision-language models ____ which improves the performance in visual question answering ____, and multi-modal task planning ____. Such planning leverages text, visual, and auditory data to foster holistic AI-driven analysis, moving beyond mere language processing to synthesize complex data interplay ____. Other works such as Inner Monologue ____ and SayCan ____ exemplify this advancement by integrating environmental multi-modal feedback, enabling more reliable task planning and action execution. Additionally, ManipLLM ____ utilizes the reasoning power of multi-modal LLMs for robotic manipulation, further broadening the application of LLMs in practical settings. The most recent work RoCo____ proposes to use LLMs for multi-robot collaboration, integrating high-level communication and low-level path planning to generate and refine task strategies and execution. However, as pointed out by____, these LLMs still struggle to efficiently learn from trial-and-error due to the high demand for training samples and costly fine-tuning procedure. Therefore, we propose to adopt a retrospective actor-critic framework to enable multi-robots to make better decisions by learning from prior failures during the collaboration process.

\noindent \textbf{LLM in Robotics.}
Recent robotics research integrates large language models (LLMs) to enhance natural language understanding____ and navigation____. This integration allows vision-language models____ to improve visual question answering____ and support multi-modal planning____ through combined textual, visual, and auditory input. Methods such as Inner Monologue____ and ManipLLM____ demonstrate how LLM-driven reasoning enhances interaction and manipulation tasks. Most recently, RoCo____ explores multi-robot collaboration, integrating high-level language-based guidance with low-level path planning. Yet, LLMs still face challenges in data-intensive trial-and-error learning____. To address this issue, we propose a retrospective actor-critic framework that enables multi-robot teams to learn effectively from previous failures and refine future decisions.