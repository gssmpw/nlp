% \begin{table*}[t!]
% \caption{Modeling the generative inference cost and limit.}
% \begin{small}
% \label{tab:formula}
% % \vskip 0.15in
% \vspace{-1em}
% \begin{center}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{c | c}
% \hline
% \textbf{Description} & \textbf{Cost Formulation} \\
% \hline
% Computation cost & 
% $
% \begin{aligned}
% \max_{d \in \mathbf{d}_{i,j}}\left( \frac{12H^2 B_{\text{type}}s_t^{\text{out}}}{\left|\mathbf{d}_{i,j}\right| m_d} \right) \cdot l_{i,j} + & \max_{d \in \mathbf{d}_{i,j}}\left( \frac{24 b_t \left(s^{\text{in}}_t + s^{\text{out}}_t\right) H^2}{\left|\mathbf{d}_{i,j}\right| c_d}  \right) \cdot l_{i,j} 
% \end{aligned}
% $ \\  
% \hline
% TP communication cost &
% $
% \begin{aligned}
% \max_{d \in \mathbf{d}_{i,j}}\left( \sum_{d' \in \mathbf{d}_{i,j} - \{d\}} \left(\alpha_{d, d'} + \frac{b_t s^{\text{in}}_{t} H B_{\text{type}} } { {\left|\mathbf{d}_{i,j}\right| \beta}_{d, d'}}\right) \right) \cdot 4 l_{i,j} + \max_{d \in \mathbf{d}_{i,j}} \left( \sum_{d' \in \mathbf{d}_{i,j} - \{d\}} \left(\alpha_{d, d'} + \frac{b_t H B_{\text{type}} } { {\left|\mathbf{d}_{i,j}\right| \beta}_{d, d'}}\right)  \right) \cdot 4 s_{t}^{\text{out}} l_{i,j}
% \end{aligned}
% $ \\ 
% \hline
% PP communication cost &
% $
% \begin{aligned}
% \min_{d \in \mathbf{d}_{i,j}, d' \in \mathbf{d}_{i,j+1}}\left( \alpha_{d,d'} + \frac{b_t s^{\text{in}}_{t} H B_{\text{type}}}{\beta_{d,d'}} \right) + \min_{d \in \mathbf{d}_{i,j}, d' \in \mathbf{d}_{i,j+1}}\left( \alpha_{d,d'} + \frac{b_t H B_{\text{type}}}{\beta_{d,d'}} \right) \cdot s_{t}^{\text{out}} 
% \end{aligned}
% $ \\ 
% \hline
% Memory limit &
% $
% \begin{aligned}
% \left(\frac{12H^2 B_{\text{type}}}{\left|\mathbf{d}_{i,j}\right|} + \frac{2 b_t \left(s^{\text{in}}_t + s^{\text{out}}_t\right) H B_{\text{type}}}{\left|\mathbf{d}_{i,j}\right|} \right) \times l_{i,j} + \quad 4 b_t \left(s^{\text{in}}_t + s^{\text{out}}_t\right) H B_{\text{type}}
% \end{aligned}
% $ \\ 
% \hline
% KV cache communication cost &
% $
% \begin{aligned}
% \alpha_{d, d'} + \frac{2b_t s^{\text{in}}_{t} H B_{\text{type}} } { {\beta}_{d, d'}}
% \end{aligned}
% $ \\ 
% \hline
% \end{tabular}%
% }
% \end{center}
% \end{small}
% \scriptsize{We formulate computation cost, tensor parallel (TP) communication cost, key-value (KV) cache communication cost, memory limit of the $j$-th stage in the $i$-th pipeline, and the pipeline parallel (PP) communication cost between the $j$-th stage and the $j{+}1$-th stage of the $i$-th pipeline for a particular inference task $t \in \mathbf{T}$, where $b_{t}$ is the batch size, $s^{\text{in}}_{t}$ is the sequence length of input prompt and $s^{\text{out}}_{t}$ is the number of output tokens, and $B_{\text{type}}$ denotes the number of bytes for the precision of inference computation, e.g., $B_{\text{type}}\left(\textsc{fp16}\right)=2$.} 
% % \vskip -0.1in
% \label{tab:notations}
% \end{table*}


\begin{table*}[t!]
\caption{Modeling the generative inference cost and limit.}
\begin{small}
\label{tab:formula}
\vspace{-1em}
\begin{center}
\resizebox{\textwidth}{!}{%
\begin{tabular}{c | c | c}
\hline
\textbf{Description} & \textbf{Prefill Cost Formulation} & \textbf{Decode Cost Formulation} \\
\hline
Computation cost & 
$
\begin{aligned}
&\max_{d \in \mathbf{d}_{i,j}}\left( \frac{24 b_t s^{\text{in}}_t H^2}{\left|\mathbf{d}_{i,j}\right| c_d} \right) \cdot l_{i,j}
\end{aligned}
$ &
$
\begin{aligned}
&\max_{d \in \mathbf{d}_{i,j}}\left( \frac{12 H^2 B_{\text{type}} s_t^{\text{out}}}{\left|\mathbf{d}_{i,j}\right| m_d} \right) \cdot l_{i,j} + \max_{d \in \mathbf{d}_{i,j}}\left( \frac{24 b_t s^{\text{out}}_t H^2}{\left|\mathbf{d}_{i,j}\right| c_d} \right) \cdot l_{i,j}
\end{aligned}
$ \\
\hline
TP communication cost &
$
\begin{aligned}
&\max_{d \in \mathbf{d}_{i,j}} \left( \sum_{d' \in \mathbf{d}_{i,j} \setminus \{d\}} \left( \alpha_{d,d'} + \frac{b_t s^{\text{in}}_t H B_{\text{type}}}{\left|\mathbf{d}_{i,j}\right| \beta_{d,d'}} \right) \right) \cdot 4 l_{i,j}
\end{aligned}
$ &
$
\begin{aligned}
&\max_{d \in \mathbf{d}_{i,j}} \left( \sum_{d' \in \mathbf{d}_{i,j} \setminus \{d\}} \left( \alpha_{d,d'} + \frac{b_t H B_{\text{type}}}{\left|\mathbf{d}_{i,j}\right| \beta_{d,d'}} \right) \right) \cdot 4 s^{\text{out}}_t l_{i,j}
\end{aligned}
$ \\
\hline
PP communication cost &
$
\begin{aligned}
&\min_{d \in \mathbf{d}_{i,j},\, d' \in \mathbf{d}_{i,j+1}} \left( \alpha_{d,d'} + \frac{b_t s^{\text{in}}_t H B_{\text{type}}}{\beta_{d,d'}} \right)
\end{aligned}
$ &
$
\begin{aligned}
&\min_{d \in \mathbf{d}_{i,j},\, d' \in \mathbf{d}_{i,j+1}} \left( \alpha_{d,d'} + \frac{b_t H B_{\text{type}}}{\beta_{d,d'}} \right) \cdot s^{\text{out}}_t
\end{aligned}
$ \\
\hline
Memory limit &
\multicolumn{2}{c}{
$
\begin{aligned}
\left(\frac{12H^2 B_{\text{type}}}{\left|\mathbf{d}_{i,j}\right|} + \frac{2 b_t \left(s^{\text{in}}_t + s^{\text{out}}_t\right) H B_{\text{type}}}{\left|\mathbf{d}_{i,j}\right|} \right) \times l_{i,j} + \quad 4 b_t \left(s^{\text{in}}_t + s^{\text{out}}_t\right) H B_{\text{type}}
\end{aligned}
$ 
} \\
\hline
KV cache communication cost &
\multicolumn{2}{c}{
$
\begin{aligned}
\alpha_{d,d'} + \frac{2 b_t s^{\text{in}}_t H B_{\text{type}}}{\beta_{d,d'}}
\end{aligned}
$
} \\
\hline
\end{tabular}%
}
\end{center}
\end{small}
\scriptsize{We formulate the computation cost, tensor parallel (TP) communication cost, key-value (KV) cache communication cost, memory limit of the $j$-th stage in the $i$-th pipeline, and the pipeline parallel (PP) communication cost between the $j$-th and $(j{+}1)$-th stages of the $i$-th pipeline for a particular inference task $t \in \mathbf{T}$. Here, $d$ is the GPU device, $m_d$ is the GPU memory bandwidth, $c_d$ is the tensor core computation power, $\alpha_{d,d'}$ and $\beta_{d,d'}$ is the latency and bandwidth between device $d$ and $d'$, $\mathbf{d}_{i,j}$ is the set of GPUs serves the $j$-th stage in the $i$-th pipeline that holds $l_{i,j}$ transformer layers, $b_{t}$ is the batch size, $s^{\text{in}}_{t}$ is the sequence length of the input prompt, $s^{\text{out}}_{t}$ is the number of output tokens, $H$ is the size of the hidden dimension in a transformer block, and $B_{\text{type}}$ denotes the number of bytes for the precision of inference computation (e.g., $B_{\text{type}}(\textsc{fp16})=2$).}
\end{table*}
