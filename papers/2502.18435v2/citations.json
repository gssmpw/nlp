[
  {
    "index": 0,
    "papers": [
      {
        "key": "berglund2023reversal",
        "author": "Berglund, Lukas and Tong, Meg and Kaufmann, Max and Balesni, Mikita and Stickland, Asa Cooper and Korbak, Tomasz and Evans, Owain",
        "title": "The reversal curse: Llms trained on\" a is b\" fail to learn\" b is a\""
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "allen2023physics_3_1",
        "author": "Allen-Zhu, Zeyuan and Li, Yuanzhi",
        "title": "Physics of language models: Part 3.1, knowledge storage and extraction"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "golovneva2024reverse",
        "author": "Golovneva, Olga and Allen-Zhu, Zeyuan and Weston, Jason and Sukhbaatar, Sainbayar",
        "title": "Reverse training to nurse the reversal curse"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "vinyals2015order",
        "author": "Vinyals, Oriol and Bengio, Samy and Kudlur, Manjunath",
        "title": "Order matters: Sequence to sequence for sets"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "papadopoulos2024arrows",
        "author": "Papadopoulos, Vassilis and Wenger, J{\\'e}r{\\'e}mie and Hongler, Cl{\\'e}ment",
        "title": "Arrows of Time for Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zhang2024reverse",
        "author": "Zhang-Li, Daniel and Lin, Nianyi and Yu, Jifan and Zhang, Zheyuan and Yao, Zijun and Zhang, Xiaokang and Hou, Lei and Zhang, Jing and Li, Juanzi",
        "title": "Reverse That Number! Decoding Order Matters in Arithmetic Learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "gu2018non",
        "author": "Gu, Jiatao and Bradbury, James and Xiong, Caiming and Li, Victor OK and Socher, Richard",
        "title": "Non-autoregressive neural machine translation"
      },
      {
        "key": "ghazvininejad-etal-2019-mask",
        "author": "Ghazvininejad, Marjan  and\nLevy, Omer  and\nLiu, Yinhan  and\nZettlemoyer, Luke",
        "title": "Mask-Predict: Parallel Decoding of Conditional Masked Language Models"
      },
      {
        "key": "gu-kong-2021-fully",
        "author": "Gu, Jiatao  and\nKong, Xiang",
        "title": "Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade"
      },
      {
        "key": "zhang-etal-2020-pointer",
        "author": "Zhang, Yizhe  and\nWang, Guoyin  and\nLi, Chunyuan  and\nGan, Zhe  and\nBrockett, Chris  and\nDolan, Bill",
        "title": "{POINTER}: Constrained Progressive Text Generation via Insertion-based Generative Pre-training"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "welleck2019non",
        "author": "Welleck, Sean and Brantley, Kiant{\\'e} and Iii, Hal Daum{\\'e} and Cho, Kyunghyun",
        "title": "Non-monotonic sequential text generation"
      },
      {
        "key": "gu2019insertion",
        "author": "Gu, Jiatao and Liu, Qi and Cho, Kyunghyun",
        "title": "Insertion-based decoding with automatically inferred generation order"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "Li-2022-DiffusionLM",
        "author": "Xiang Lisa Li and John Thickstun and Ishaan Gulrajani and Percy Liang and Tatsunori Hashimoto",
        "title": "Diffusion-LM Improves Controllable Text Generation"
      },
      {
        "key": "zhang2023planner",
        "author": "Zhang, Yizhe and Gu, Jiatao and Wu, Zhuofeng and Zhai, Shuangfei and Susskind, Josh and Jaitly, Navdeep",
        "title": "PLANNER: Generating Diversified Paragraph via Latent Language Diffusion Model"
      },
      {
        "key": "gong2024scaling",
        "author": "Gong, Shansan and Agarwal, Shivam and Zhang, Yizhe and Ye, Jiacheng and Zheng, Lin and Li, Mukai and An, Chenxin and Zhao, Peilin and Bi, Wei and Han, Jiawei and others",
        "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "ye2024beyond",
        "author": "Ye, Jiacheng and Gao, Jiahui and Gong, Shansan and Zheng, Lin and Jiang, Xin and Li, Zhenguo and Kong, Lingpeng",
        "title": "Beyond autoregression: Discrete diffusion for complex reasoning and planning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zheng2023large",
        "author": "Zheng, Chujie and Zhou, Hao and Meng, Fandong and Zhou, Jie and Huang, Minlie",
        "title": "Large language models are not robust multiple choice selectors"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "pezeshkpour2023large",
        "author": "Pezeshkpour, Pouya and Hruschka, Estevam",
        "title": "Large language models sensitivity to the order of options in multiple-choice questions"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "ghosal2022two",
        "author": "Ghosal, Deepanway and Majumder, Navonil and Mihalcea, Rada and Poria, Soujanya",
        "title": "Two is better than many? binary classification as an effective approach to multi-choice question answering"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "li2024can",
        "author": "Li, Wangyue and Li, Liangzhi and Xiang, Tong and Liu, Xiao and Deng, Wei and Garcia, Noa",
        "title": "Can multiple-choice questions really be useful in detecting the abilities of LLMs?"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wiegreffe2024answer",
        "author": "Wiegreffe, Sarah and Tafjord, Oyvind and Belinkov, Yonatan and Hajishirzi, Hannaneh and Sabharwal, Ashish",
        "title": "Answer, assemble, ace: Understanding how transformers answer multiple choice questions"
      }
    ]
  }
]