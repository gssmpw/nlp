\section{Related works}
\subsection{Screen content coding}
Traditional video coding methods, such as H.265/HEVC \cite{Lei2017fastintra}, H.266/VVC \cite{bross2021overview}, AVS3 \cite{yin2024afastcu}, and AV1 \cite{Hao2024FastTransform}, have increasingly focused on SCC by introducing specialized SCC tools to enhance encoding efficiency for SC \cite{zhu2017inter-palette,yang2020anovel,zhao2024gcostc}. In H.265/HEVC-SCC, techniques such as intra block copy (IBC) \cite{xu2016intra}, palette mode (PLT) \cite{pu2016palette}, adaptive color transform (ACT) \cite{zhang2016adaptive}, and transform skip mode (TSM) \cite{sole2013ahg8} were introduced. H.266/VVC-SCC \cite{wang2024fastmode} further improves them by incorporating transform skip residual coding (TSRC) and block-based differential pulse-code modulation (BDPCM) \cite{abdoli2019intra}. Similarly, AVS3-SCC introduces frequency-based intra-mode coding (FIMC) \cite{li2019freq}, implicit selection of transform skip (ISTS) \cite{zhang2021implicit}, adaptive control of deblocking type (ACDT) \cite{wang2020deblocking}, and intra string copy (ISC) \cite{zhou2020string} techniques.
\begin{figure}[t]
\centering
\begin{minipage}[b]{0.48\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{images/fig3-octave.png}
  \centerline{(a) OctConv}\medskip
\end{minipage}
\begin{minipage}[b]{0.48\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{images/fig3-goconv.png}
  \centerline{(b) GoConv}\medskip
\end{minipage}
\begin{minipage}[b]{\linewidth}
  \centering
  \includegraphics[width=0.9\linewidth]{images/fig3-toconv.png}
  \centerline{(c) ToRB}\medskip
\end{minipage}
\begin{minipage}[b]{\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{images/fig3-MToRB.png}
  \centerline{(d) MToRB}\medskip
\end{minipage}
\caption{Down-sampling octave convolution and its variants, (a) OctConv \cite{chen2019drop}, (b) GoConv \cite{akbari2021learned}, (c) ToRB \cite{chen2022two}, and (d) MToRB (proposed). \({\alpha}\) denotes the channel ratio allocated to low-frequency features, \({\beta}\) denotes the channel ratio allocated to mid-frequency features, and the channel ratio for high-frequency features is \(1 - {\alpha} - {\beta}\).}
\label{fig:octave methods}
\end{figure}
With the rapid advancements in deep learning and the availability of large dataset, LIC methods have surpassed traditional techniques in compressing NS images \cite{cheng2020learned, balle2018variational, minnen2018joint, pan2024JND-LIC, he2024learnedimage}. These advancements have also begun to demonstrate significant potential in the domain of SC image compression \cite{wang2022transform, heris2023multi, shen2023dec, tang2023feature, WangDSCIC}. Wang \textit{et al}. \cite{wang2022transform} enhanced SC encoding performance by integrating transform skip into the framework presented in \cite{balle2018variational}. Heris \textit{et al}. \cite{heris2023multi} trained an encoder for both reconstruction and segmentation tasks, segmenting SC into synthetic and natural regions to meet multi-task encoding requirements. Shen \textit{et al}. \cite{shen2023dec} proposed an efficient decoder-side adapter for adaptive compression of both NS and SC images. Tang \textit{et al}. \cite{tang2023feature} addressed low-bitrate SCC method by employing a super-resolution network to enhance feature during the fusion process, thereby reducing compression distortion. Wang \textit{et al}. \cite{WangDSCIC} proposed a color context generator (CCG) and a region-based block aggregation (RBA) module to investigate color representations
and block correlations for SCC. Although these methods attempt to enhance SCC performance using learning-based techniques, they do not fully consider the inherent spectrum distribution characteristics of SC. While our previous research \cite{jiang2024OMR} consideres differences in spectrum distribution, it only accounts for two components: high-frequency and low-frequency. Furthermore, applying the same quantization operation to different components is not in line with the characteristic of human visual system \cite{pointer1989contrast}. Moreover, another limitation of SCC lies in the dataset. Although we constructed the SDU-SCICK2K dataset in \cite{jiang2024OMR}, it is still small that leaves significant room for improving SCC performance.

\subsection{Octave convolution}
Inspired by the frequency decomposition of images, Chen \textit{et al}. \cite{chen2019drop} proposed the octave convolution network (OctConv) to decompose features. It has demonstrated superior performance in various downstream tasks, such as image classification and action recognition. Besides, its ability to decompose features into different frequencies and reduce spatial redundancy is also well-suited for image compression \cite{jiang2024OMR}, indicating its broad potential in the encoding domain. Fig. \ref{fig:octave methods} (a) illustrates the structure of the original OctConv. The input features \(\bm{X}\) are decomposed into high-frequency part \(\bm{X}^H\) and low-frequency part \(\bm{X}^L\) along the channel dimension. They are then processed separately through intra-frequency convolution and inter-frequency convolution operations, resulting in intra-frequency features \(\{ \bm{Y}^{H \rightarrow H}, \bm{Y}^{L \rightarrow L} \}\) and inter-frequency features \(\{ \bm{Y}^{H \rightarrow L}, \bm{Y}^{L \rightarrow H} \}\). The final output consists of high-frequency features \(\bm{Y}^H\) and low-frequency features \(\bm{Y}^L\):
\begin{align}
\bm{Y}^H &= \bm{Y}^{H \rightarrow H} + \bm{Y}^{L \rightarrow H} = f\left(\operatorname{pool}\left(\bm{X}^H, 2\right); \bm{W}^{H \rightarrow H}\right) \nonumber \\
& \quad + \operatorname{pool}\left(up\left(f\left(\bm{X}^L \cdot \bm{W}^{L \rightarrow H}\right); 2\right); 2\right), \\
\bm{Y}^L &= \bm{Y}^{L \rightarrow L} + \bm{Y}^{H \rightarrow L} = f_{\text{pool}}\left(\bm{X}^L; \bm{W}^{L \rightarrow L}; 2\right) \nonumber \\
& \quad + f\left(\operatorname{pool}\left(\bm{X}^H, 4\right); \bm{W}^{H \rightarrow L}\right) ,
\end{align}
where \( f(\bm{X}; \bm{W}) \) denotes a convolution operation with parameters \(\bm{W} \), \( \text{pool}(\bm{X}; a) \) represents an average pooling operation with a stride of \( a \), and \( \text{up}(\bm{X}; b) \) represents an upsampling interpolation with a scale factor of \( b \).

Akbari \textit{et al}. \cite{akbari2021learned} observed that directly applying pooling operations with large strides in OctConv results in the loss of spatial information. To address this problem, they proposed a generalized octave convolution (GoConv) for image compression, based on OctConv, as shown in Fig. \ref{fig:octave methods} (b). The key differences include replacing the pooling operation with strided convolution and modifying the input of the inter-frequency convolution from \(\bm{Y}^H\) and \(\bm{Y}^L\) to the inter-frequency features \(\bm{Y}^{H \rightarrow H}\) and \(\bm{Y}^ {L \rightarrow L}\):
\begin{equation}
\bm{Y}^H = f_{\downarrow}\left(\bm{X}^H; \bm{W}^{H \rightarrow H}; 2\right) + f_{\uparrow}\left(\bm{Y}^{L \rightarrow L}; \bm{W}^{L \rightarrow H}; 2\right),
\end{equation}
\begin{equation}
\bm{Y}^L = f_{\downarrow}\left(\bm{X}^L; \bm{W}^{L \rightarrow L}; 2\right) + f_{\downarrow}\left(\bm{Y}^{H \rightarrow H}; \bm{W}^{H \rightarrow L}; 2\right),
\end{equation}
where $f_{\downarrow}(\bm{X};\bm{W};a)$ denotes downsampling convolution with parameters $\bm{W}$ and a stride of \( a \), $f_{\uparrow}(\bm{X};\bm{W};b)$ denotes upsampling convolution with parameters $\bm{W}$ and a stride of \( b \).

Chen \textit{et al}. \cite{chen2022two} found that, in GoConv, applying \(\bm{Y}^{H \rightarrow H}\) and \(\bm{Y}^{L \rightarrow L}\) to both intra-frequency and inter-frequency convolutions simultaneously would limit the neural network's ability to learn different frequency features effectively. Additionally, the downsampling of \(\bm{X}^L\) followed by upsampling increases distortion. To address these issues, they proposed a two-stage octave residual block (ToRB), as shown in Fig. \ref{fig:octave methods} (c), which separates the sampling operations:
\begin{flalign}
&\begin{aligned}
\bm{Y}^H & =f_{\downarrow}\left(\bm{Y}^H_p; \bm{W}^H ; 2\right)+f_{\mathrm{sc}}\left(\bm{X}^H; \bm{W}_{sc}^H ; 2\right), 
\end{aligned}\\
&\begin{aligned}
\textit{with } \bm{Y}^H_p & =\bm{Y}^{H \rightarrow H} + \bm{Y}^{L \rightarrow H} \\
& =f\left(\bm{X}^H; \bm{W}^{H \rightarrow H}\right)+f_{\uparrow}\left(\bm{X}^L;\bm{W}^{L \rightarrow H} ; 2\right),
\end{aligned}\\
&\begin{aligned}
\bm{Y}^L & =f_{\downarrow}\left(\bm{Y}_p^L; \bm{W}^L; 2\right)+f_{\mathrm{sc}}\left(\bm{X}^L;\bm{W}_{sc}^L; 2\right), 
\end{aligned}&\\
&\begin{aligned}
\textit{with }  \bm{Y}^L_p & =\bm{Y}^{L \rightarrow L} + \bm{Y}^{H \rightarrow L} \\
& =f\left(\bm{X}^L; \bm{W}^{L \rightarrow L}\right)+f_{\downarrow}\left(\bm{X}^H; \bm{W}^{H \rightarrow L}; 2\right),
\end{aligned}
\end{flalign}
where \(\bm{Y}^H_p\) and \(\bm{Y}^L_p\) represent the high- and low-frequency features of the first stage, respectively, and \(f_{sc}(\bm{X}; \bm{W}_{sc})\) denotes the skip connection with parameters \(\bm{W}_{sc} \).

Although OctConv-based methods have been continuously improved and successfully applied to image compression with commendable results, there still remains potential for enhancement in SCC. Therefore, considering the characteristics of SC images, we propose a multi-frequency feature  decomposition network to achieve more refined feature extraction and processing, as shown in Fig. \ref{fig:motivation}. The specific details will be elaborated in Section. IV.