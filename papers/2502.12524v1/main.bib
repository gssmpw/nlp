@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}



@article{zhang2022dino,
  title={Dino: Detr with improved denoising anchor boxes for end-to-end object detection},
  author={Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel M and Shum, Heung-Yeung},
  journal={arXiv preprint arXiv:2203.03605},
  year={2022}
}


@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}




@inproceedings{shao2019objects365,
  title={Objects365: A large-scale, high-quality dataset for object detection},
  author={Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8430--8439},
  year={2019}
}

@inproceedings{carion2020detr,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}


@inproceedings{zhou2020more,
  title={More grounded image captioning by distilling image-text matching model},
  author={Zhou, Yuanen and Wang, Meng and Liu, Daqing and Hu, Zhenzhen and Zhang, Hanwang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4777--4786},
  year={2020}
}


@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}


@inproceedings{zhang2022hivit,
  title={Hivit: A simpler and more efficient design of hierarchical vision transformer},
  author={Zhang, Xiaosong and Tian, Yunjie and Xie, Lingxi and Huang, Wei and Dai, Qi and Ye, Qixiang and Tian, Qi},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}



@article{li2023yolov6,
  title={Yolov6 v3. 0: A full-scale reloading},
  author={Li, Chuyi and Li, Lulu and Geng, Yifei and Jiang, Hongliang and Cheng, Meng and Zhang, Bo and Ke, Zaidan and Xu, Xiaoming and Chu, Xiangxiang},
  journal={arXiv preprint arXiv:2301.05586},
  year={2023}
}

@article{wang2024gold,
  title={Gold-YOLO: Efficient object detector via gather-and-distribute mechanism},
  author={Wang, Chengcheng and He, Wei and Nie, Ying and Guo, Jianyuan and Liu, Chuanjian and Wang, Yunhe and Han, Kai},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yolov8,
  title={Yolov8},
  author={Jocher Glenn},
  journal={https://github.com/ultralytics/ultralytics/tree/main},
  year={2023}
}


@article{wang2024yolov10,
  title={Yolov10: Real-time end-to-end object detection},
  author={Wang, Ao and Chen, Hui and Liu, Lihao and Chen, Kai and Lin, Zijia and Han, Jungong and Ding, Guiguang},
  journal={arXiv preprint arXiv:2405.14458},
  year={2024}
}

@article{chen2023yolo,
  title={Yolo-ms: rethinking multi-scale representation learning for real-time object detection},
  author={Chen, Yuming and Yuan, Xinbin and Wu, Ruiqi and Wang, Jiabao and Hou, Qibin and Cheng, Ming-Ming},
  journal={arXiv preprint arXiv:2308.05480},
  year={2023}
}

@article{wang2024yolov9,
  title={Yolov9: Learning what you want to learn using programmable gradient information},
  author={Wang, Chien-Yao and Yeh, I-Hau and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2402.13616},
  year={2024}
}

@inproceedings{zhao2024rtdetrs,
  title={Detrs beat yolos on real-time object detection},
  author={Zhao, Yian and Lv, Wenyu and Xu, Shangliang and Wei, Jinman and Wang, Guanzhong and Dang, Qingqing and Liu, Yi and Chen, Jie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16965--16974},
  year={2024}
}




@article{tian2024fast,
  title={Fast-iTPN: Integrally pre-trained transformer pyramid network with token migration},
  author={Tian, Yunjie and Xie, Lingxi and Qiu, Jihao and Jiao, Jianbin and Wang, Yaowei and Tian, Qi and Ye, Qixiang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{choromanski2020performer,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@inproceedings{bhojanapalli2020low,
  title={Low-rank bottleneck in multi-head attention models},
  author={Bhojanapalli, Srinadh and Yun, Chulhee and Rawat, Ankit Singh and Reddi, Sashank and Kumar, Sanjiv},
  booktitle={International conference on machine learning},
  pages={864--873},
  year={2020},
  organization={PMLR}
}


@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}

@article{tian2022beyond,
  title={Beyond masking: Demystifying token-based pre-training for vision transformers},
  author={Tian, Yunjie and Xie, Lingxi and Fang, Jiemin and Shi, Mengnan and Peng, Junran and Zhang, Xiaopeng and Jiao, Jianbin and Tian, Qi and Ye, Qixiang},
  journal={arXiv preprint arXiv:2203.14313},
  year={2022}
}

@article{zhou2021ibot,
  title={ibot: Image bert pre-training with online tokenizer},
  author={Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
  journal={arXiv preprint arXiv:2111.07832},
  year={2021}
}

@article{oquab2023dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

@article{fang2024eva,
  title={Eva-02: A visual representation for neon genesis},
  author={Fang, Yuxin and Sun, Quan and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  journal={Image and Vision Computing},
  volume={149},
  pages={105171},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{xiao2018upernet,
  title={Unified perceptual parsing for scene understanding},
  author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={418--434},
  year={2018}
}

@inproceedings{fang2023eva,
  title={Eva: Exploring the limits of masked visual representation learning at scale},
  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19358--19369},
  year={2023}
}

@inproceedings{zhang2023hivit,
  title={Hivit: A simpler and more efficient design of hierarchical vision transformer},
  author={Zhang, Xiaosong and Tian, Yunjie and Xie, Lingxi and Huang, Wei and Dai, Qi and Ye, Qixiang and Tian, Qi},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@inproceedings{tian2023integrally,
  title={Integrally pre-trained transformer pyramid networks},
  author={Tian, Yunjie and Xie, Lingxi and Wang, Zhaozhi and Wei, Longhui and Zhang, Xiaopeng and Jiao, Jianbin and Wang, Yaowei and Tian, Qi and Ye, Qixiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18610--18620},
  year={2023}
}

@article{gao2022convmae,
  title={Convmae: Masked convolution meets masked autoencoders},
  author={Gao, Peng and Ma, Teli and Li, Hongsheng and Lin, Ziyi and Dai, Jifeng and Qiao, Yu},
  journal={arXiv preprint arXiv:2205.03892},
  year={2022}
}

@inproceedings{huang2019ccnet,
  title={Ccnet: Criss-cross attention for semantic segmentation},
  author={Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={603--612},
  year={2019}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}


@inproceedings{dehghani2023scaling,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle={International Conference on Machine Learning},
  pages={7480--7512},
  year={2023},
  organization={PMLR}
}


@article{girshick2015fastrcnn,
  title={Fast r-cnn},
  author={Girshick, R},
  journal={arXiv preprint arXiv:1504.08083},
  year={2015}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

@article{li2020generalized_focal_loss,
  title={Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection},
  author={Li, Xiang and Wang, Wenhai and Wu, Lijun and Chen, Shuo and Hu, Xiaolin and Li, Jun and Tang, Jinhui and Yang, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21002--21012},
  year={2020}
}


@inproceedings{li2022dn_detr,
  title={Dn-detr: Accelerate detr training by introducing query denoising},
  author={Li, Feng and Zhang, Hao and Liu, Shilong and Guo, Jian and Ni, Lionel M and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13619--13627},
  year={2022}
}


@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11976--11986},
  year={2022}
}


@article{jocher2020yolov5,
  title={yolov5},
  author={Jocher, Glenn and Nishimura, K and Mineeva, T and Vilari{\~n}o, RJAM},
  journal={https://github.com/ultralytics/yolov5/tree},
  volume={2},
  year={2020}
}

@article{jocher2024yolov11,
  title={yolov11},
  author={Jocher, Glenn},
  journal={https://github.com/ultralytics},
  year={2024}
}


@inproceedings{wang2020cspnet,
  title={CSPNet: A new backbone that can enhance learning capability of CNN},
  author={Wang, Chien-Yao and Liao, Hong-Yuan Mark and Wu, Yueh-Hua and Chen, Ping-Yang and Hsieh, Jun-Wei and Yeh, I-Hau},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={390--391},
  year={2020}
}

@inproceedings{wang2023yolov7,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7464--7475},
  year={2023}
}


@inproceedings{redmon2016yolov1,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2016}
}

@inproceedings{redmon2017yolo9000,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7263--7271},
  year={2017}
}

@article{redmon2018yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}


@article{bochkovskiy2020yolov4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}


@article{zhang2022dino,
  title={Dino: Detr with improved denoising anchor boxes for end-to-end object detection},
  author={Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel M and Shum, Heung-Yeung},
  journal={arXiv preprint arXiv:2203.03605},
  year={2022}
}

@article{zhu2020deformable_detr,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2010.04159},
  year={2020}
}

@inproceedings{meng2021conditional_detr,
  title={Conditional detr for fast training convergence},
  author={Meng, Depu and Chen, Xiaokang and Fan, Zejia and Zeng, Gang and Li, Houqiang and Yuan, Yuhui and Sun, Lei and Wang, Jingdong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3651--3660},
  year={2021}
}

@inproceedings{sun2021sparse_rcnn,
  title={Sparse r-cnn: End-to-end object detection with learnable proposals},
  author={Sun, Peize and Zhang, Rufeng and Jiang, Yi and Kong, Tao and Xu, Chenfeng and Zhan, Wei and Tomizuka, Masayoshi and Li, Lei and Yuan, Zehuan and Wang, Changhu and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14454--14463},
  year={2021}
}



@article{liu2022dab_detr,
  title={Dab-detr: Dynamic anchor boxes are better queries for detr},
  author={Liu, Shilong and Li, Feng and Zhang, Hao and Yang, Xiao and Qi, Xianbiao and Su, Hang and Zhu, Jun and Zhang, Lei},
  journal={arXiv preprint arXiv:2201.12329},
  year={2022}
}

@inproceedings{hosang2017learning_nms,
  title={Learning non-maximum suppression},
  author={Hosang, Jan and Benenson, Rodrigo and Schiele, Bernt},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4507--4515},
  year={2017}
}


@inproceedings{pvt,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={568--578},
  year={2021}
}


@article{ho2019axial,
  title={Axial attention in multidimensional transformers},
  author={Ho, Jonathan and Kalchbrenner, Nal and Weissenborn, Dirk and Salimans, Tim},
  journal={arXiv preprint arXiv:1912.12180},
  year={2019}
}


@inproceedings{dong2022cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12124--12134},
  year={2022}
}

@article{chu2021twins,
  title={Twins: Revisiting the design of spatial attention in vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9355--9366},
  year={2021}
}

@article{yu2021glance,
  title={Glance-and-gaze vision transformer},
  author={Yu, Qihang and Xia, Yingda and Bai, Yutong and Lu, Yongyi and Yuille, Alan L and Shen, Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12992--13003},
  year={2021}
}


@inproceedings{shen2021linear_attn,
  title={Efficient attention: Attention with linear complexities},
  author={Shen, Zhuoran and Zhang, Mingyuan and Zhao, Haiyu and Yi, Shuai and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={3531--3539},
  year={2021}
}

@article{wang2020linformer_attn,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@inproceedings{katharopoulos2020transformers_attn,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International conference on machine learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}


@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9653--9663},
  year={2022}
}



@article{zhang2022cae,
  title={CAE v2: Context Autoencoder with CLIP Target},
  author={Zhang, Xinyu and Chen, Jiahui and Yuan, Junkun and Chen, Qiang and Wang, Jian and Wang, Xiaodi and Han, Shumin and Chen, Xiaokang and Pi, Jimin and Yao, Kun and others},
  journal={arXiv preprint arXiv:2211.09799},
  year={2022}
}


@inproceedings{chen2023mixed,
  title={Mixed autoencoder for self-supervised visual representation learning},
  author={Chen, Kai and Liu, Zhili and Hong, Lanqing and Xu, Hang and Li, Zhenguo and Yeung, Dit-Yan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22742--22751},
  year={2023}
}

@article{chen2206efficient,
  title={Efficient Self-supervised Vision Pretraining with Local Masked Reconstruction.‚Äù arXiv, Jun. 20, 2022. doi: 10.48550},
  author={Chen, J and Hu, M and Li, B and Elhoseiny, M},
  journal={arXiv preprint arXiv.2206.00790}
}

@inproceedings{devil,
  author       = {Hao Liu and
                  Xinghua Jiang and
                  Xin Li and
                  Antai Guo and
                  Yiqing Hu and
                  Deqiang Jiang and
                  Bo Ren},
  title        = {The Devil Is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-training},
  booktitle    = {Conference on Innovative Applications of Artificial Intelligence},
  pages        = {1649--1656},
  year         = {2023},
}


@inproceedings{maskfeat,
  title={Masked feature prediction for self-supervised visual pre-training},
  author={Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14668--14678},
  year={2022}
}

@article{chen2022context,
  author       = {Xiaokang Chen and
                  Mingyu Ding and
                  Xiaodi Wang and
                  Ying Xin and
                  Shentong Mo and
                  Yunhao Wang and
                  Shumin Han and
                  Ping Luo and
                  Gang Zeng and
                  Jingdong Wang},
  title        = {Context Autoencoder for Self-supervised Representation Learning},
  journal      = {Int. J. Comput. Vis.},
  volume       = {132},
  number       = {1},
  pages        = {208--223},
  year         = {2024},
}


@inproceedings{wang2023internimage,
  title={Internimage: Exploring large-scale vision foundation models with deformable convolutions},
  author={Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14408--14419},
  year={2023}
}

@inproceedings{devlin2018bert,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  booktitle    = {North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages        = {4171--4186},
  year         = {2019},
}

@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@article{zhu2024vision_mamba,
  title={Vision mamba: Efficient visual representation learning with bidirectional state space model},
  author={Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang},
  journal={arXiv preprint arXiv:2401.09417},
  year={2024}
}

@inproceedings{liu2024vmamba,
  title={Vmamba: Visual state space model},
  author={Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Jiao, Jianbin and Liu, Yunfan},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}


@inproceedings{bogdoll2022anomaly,
  title={Anomaly detection in autonomous driving: A survey},
  author={Bogdoll, Daniel and Nitsche, Maximilian and Z{\"o}llner, J Marius},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4488--4499},
  year={2022}
}

@article{dos2019mobile,
  title={Mobile robot navigation using an object recognition software with RGBD images and the YOLO algorithm},
  author={Dos Reis, Douglas Henke and Welfer, Daniel and De Souza Leite Cuadros, Marco Antonio and Gamarra, Daniel Fernando Tello},
  journal={Applied Artificial Intelligence},
  volume={33},
  number={14},
  pages={1290--1305},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{wang2022designing_elan,
  title={Designing network design strategies through gradient path analysis},
  author={Wang, Chien-Yao and Liao, Hong-Yuan Mark and Yeh, I-Hau},
  journal={arXiv preprint arXiv:2211.04800},
  year={2022}
}

@article{lv2024rt_detrv2,
  title={Rt-detrv2: Improved baseline with bag-of-freebies for real-time detection transformer},
  author={Lv, Wenyu and Zhao, Yian and Chang, Qinyao and Huang, Kui and Wang, Guanzhong and Liu, Yi},
  journal={arXiv preprint arXiv:2407.17140},
  year={2024}
}



@article{dai2021coatnet,
  title={Coatnet: Marrying convolution and attention for all data sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={3965--3977},
  year={2021}
}

@inproceedings{yu2024spatial_std,
  title={Spatial transform decoupling for oriented object detection},
  author={Yu, Hongtian and Tian, Yunjie and Ye, Qixiang and Liu, Yunfan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={7},
  pages={6782--6790},
  year={2024}
}



@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}


@article{ouyang2024deyo,
  title={DEYO: DETR with YOLO for End-to-End Object Detection},
  author={Ouyang, Haodong},
  journal={arXiv preprint arXiv:2402.16370},
  year={2024}
}

@article{xu2022damo_yolo,
  title={Damo-yolo: A report on real-time object detection design},
  author={Xu, Xianzhe and Jiang, Yiqi and Chen, Weihua and Huang, Yilun and Zhang, Yuan and Sun, Xiuyu},
  journal={arXiv preprint arXiv:2211.15444},
  year={2022}
}


@inproceedings{zhou2019iou_loss,
  title={Iou loss for 2d/3d object detection},
  author={Zhou, Dingfu and Fang, Jin and Song, Xibin and Guan, Chenye and Yin, Junbo and Dai, Yuchao and Yang, Ruigang},
  booktitle={2019 international conference on 3D vision (3DV)},
  pages={85--94},
  year={2019},
  organization={IEEE}
}

@inproceedings{rezatofighi2019generalized_loss,
  title={Generalized intersection over union: A metric and a loss for bounding box regression},
  author={Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={658--666},
  year={2019}
}

@article{chen2020ap_loss,
  title={AP-loss for accurate one-stage object detection},
  author={Chen, Kean and Lin, Weiyao and Li, Jianguo and See, John and Wang, Ji and Zou, Junni},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={43},
  number={11},
  pages={3782--3798},
  year={2020},
  publisher={IEEE}
}

@article{oksuz2020ranking_loss,
  title={A ranking-based, balanced loss function unifying classification and localisation in object detection},
  author={Oksuz, Kemal and Cam, Baris Can and Akbas, Emre and Kalkan, Sinan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15534--15545},
  year={2020}
}

@inproceedings{zheng2020distance_loss,
  title={Distance-IoU loss: Faster and better learning for bounding box regression},
  author={Zheng, Zhaohui and Wang, Ping and Liu, Wei and Li, Jinze and Ye, Rongguang and Ren, Dongwei},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={07},
  pages={12993--13000},
  year={2020}
}

@inproceedings{oksuz2021rank_loss,
  title={Rank \& sort loss for object detection and instance segmentation},
  author={Oksuz, Kemal and Cam, Baris Can and Akbas, Emre and Kalkan, Sinan},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3009--3018},
  year={2021}
}

@article{zhu2020autoassign_label,
  title={Autoassign: Differentiable label assignment for dense object detection},
  author={Zhu, Benjin and Wang, Jianfeng and Jiang, Zhengkai and Zong, Fuhang and Liu, Songtao and Li, Zeming and Sun, Jian},
  journal={arXiv preprint arXiv:2007.03496},
  year={2020}
}

@inproceedings{ge2021ota_label,
  title={Ota: Optimal transport assignment for object detection},
  author={Ge, Zheng and Liu, Songtao and Li, Zeming and Yoshie, Osamu and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={303--312},
  year={2021}
}

@inproceedings{feng2021tood_label,
  title={Tood: Task-aligned one-stage object detection},
  author={Feng, Chengjian and Zhong, Yujie and Gao, Yu and Scott, Matthew R and Huang, Weilin},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={3490--3499},
  year={2021},
  organization={IEEE Computer Society}
}

@inproceedings{wang2021end_label,
  title={End-to-end object detection with fully convolutional network},
  author={Wang, Jianfeng and Song, Lin and Li, Zeming and Sun, Hongbin and Sun, Jian and Zheng, Nanning},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15849--15858},
  year={2021}
}


@inproceedings{li2022dual_label,
  title={A dual weighting label assignment scheme for object detection},
  author={Li, Shuai and He, Chenhang and Li, Ruihuang and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9387--9396},
  year={2022}
}


@article{lv2024rtdetrv2,
  title={Rt-detrv2: Improved baseline with bag-of-freebies for real-time detection transformer},
  author={Lv, Wenyu and Zhao, Yian and Chang, Qinyao and Huang, Kui and Wang, Guanzhong and Liu, Yi},
  journal={arXiv preprint arXiv:2407.17140},
  year={2024}
}

@article{fang2024eva02,
  title={Eva-02: A visual representation for neon genesis},
  author={Fang, Yuxin and Sun, Quan and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  journal={Image and Vision Computing},
  volume={149},
  pages={105171},
  year={2024},
  publisher={Elsevier}
}

@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{dao2023flashattentionv2,
  title={Flashattention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}

@article{xie2025sana,
  title={SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer},
  author={Xie, Enze and Chen, Junsong and Zhao, Yuyang and Yu, Jincheng and Zhu, Ligeng and Lin, Yujun and Zhang, Zhekai and Li, Muyang and Chen, Junyu and Cai, Han and others},
  journal={arXiv preprint arXiv:2501.18427},
  year={2025}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International conference on machine learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@inproceedings{xiong2021nystromformer,
  title={Nystr{\"o}mformer: A nystr{\"o}m-based algorithm for approximating self-attention},
  author={Xiong, Yunyang and Zeng, Zhanpeng and Chakraborty, Rudrasis and Tan, Mingxing and Fung, Glenn and Li, Yin and Singh, Vikas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={16},
  pages={14138--14148},
  year={2021}
}


@inproceedings{touvron2021going_layer_scale,
  title={Going deeper with image transformers},
  author={Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={32--42},
  year={2021}
}

@article{dosovitskiy2020vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{touvron2021deit,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International conference on machine learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}


@article{buslaev2020albumentations,
  title={Albumentations: fast and flexible image augmentations},
  author={Buslaev, Alexander and Iglovikov, Vladimir I and Khvedchenya, Eugene and Parinov, Alex and Druzhinin, Mikhail and Kalinin, Alexandr A},
  journal={Information},
  volume={11},
  number={2},
  pages={125},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}