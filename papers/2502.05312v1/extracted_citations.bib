@article{abdul2020arbert,
  title={ARBERT \& MARBERT: Deep bidirectional transformers for Arabic},
  author={Abdul-Mageed, Muhammad and Elmadany, AbdelRahim and Nagoudi, El Moatez Billah},
  journal={arXiv preprint arXiv:2101.01785},
  year={2020}
}

@inproceedings{aloyaynaa2023arabic,
  title={Arabic Grammatical Error Detection Using Transformers-based Pretrained Language Models},
  author={AlOyaynaa, Sarah and Kotb, Yasser},
  booktitle={ITM Web of Conferences},
  volume={56},
  pages={04009},
  year={2023},
  organization={EDP Sciences}
}

@inproceedings{antoun2020arabert,
  title={AraBERT: Transformer-based Model for Arabic Language Understanding},
  author={Antoun, Wissam and Baly, Fady and Hajj, Hazem},
  booktitle={LREC 2020 Workshop Language Resources and Evaluation Conference 11--16 May 2020},
  year={2020},
  pages={9}
}

@article{belkebir2021automatic,
  title={Automatic error type annotation for Arabic},
  author={Belkebir, Riadh and Habash, Nizar},
  journal={arXiv preprint arXiv:2109.08068},
  year={2021}
}

@article{el20161,
  title={1.5 billion words arabic corpus},
  author={El-Khair, Ibrahim Abu},
  journal={arXiv preprint arXiv:1611.04033},
  year={2016}
}

@article{gokaslanopenwebtext,
  title={Openwebtext corpus, 2019},
  author={Gokaslan, Aaron and Cohen, Vanya and Pavlick, E and Tellex, S},
  journal={URL http://Skylion007. github. io/OpenWebTextCorpus},
  pages={9},  year={2019}
}

@article{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@article{he2021debertav3,
  title={Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing},
  author={He, Pengcheng and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2111.09543},
  year={2021}
}

@inproceedings{husain2021leveraging,
  title={Leveraging offensive language for sarcasm and sentiment detection in Arabic},
  author={Husain, Fatemah and Uzuner, Ozlem},
  booktitle={Proceedings of the Sixth Arabic Natural Language Processing Workshop},
  pages={364--369},
  year={2021}
}

@article{inoue2021interplay,
  title={The interplay of variant, size, and task type in Arabic pre-trained language models},
  author={Inoue, Go and Alhafni, Bashar and Baimukan, Nurpeiis and Bouamor, Houda and Habash, Nizar},
  journal={arXiv preprint arXiv:2103.06678},
  year={2021}
}

@article{kwon2023chatgpt,
  title={ChatGPT for Arabic Grammatical Error Correction},
  author={Kwon, Sang Yun and Bhatia, Gagan and Nagoud, El Moatez Billah and Abdul-Mageed, Muhammad},
  journal={arXiv preprint arXiv:2308.04492},
  year={2023}
}

@article{madi2019a7,
  title={A7' ta: Data on a monolingual Arabic parallel corpus for grammar checking},
  author={Madi, Nora and Al-Khalifa, Hend S},
  journal={Data in brief},
  volume={22},
  pages={237},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{mohit2014first,
  title={The first QALB shared task on automatic text correction for Arabic},
  author={Mohit, Behrang and Rozovskaya, Alla and Habash, Nizar and Zaghouani, Wajdi and Obeid, Ossama},
  booktitle={Proceedings of the EMNLP 2014 Workshop on Arabic Natural Language Processing (ANLP)},
  pages={39--47},
  year={2014}
}

@article{nagoudi2021arat5,
  title={AraT5: Text-to-text transformers for Arabic language generation},
  author={Nagoudi, El Moatez Billah and Elmadany, AbdelRahim and Abdul-Mageed, Muhammad},
  journal={arXiv preprint arXiv:2109.12068},
  year={2021}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{rozovskaya2015second,
  title={The second QALB shared task on automatic text correction for Arabic},
  author={Rozovskaya, Alla and Bouamor, Houda and Habash, Nizar and Zaghouani, Wajdi and Obeid, Ossama and Mohit, Behrang},
  booktitle={Proceedings of the Second workshop on Arabic natural language processing},
  pages={26--35},
  year={2015}
}

@article{solyman2021synthetic,
  title={Synthetic data with neural machine translation for automatic correction in arabic grammar},
  author={Solyman, Aiman and Zhenyu, Wang and Qian, Tao and Elhag, Arafat Abdulgader Mohammed and Toseef, Muhammad and Aleibeid, Zeinab},
  journal={Egyptian Informatics Journal},
  volume={22},
  number={3},
  pages={303--315},
  year={2021},
  publisher={Elsevier}
}

@article{solyman2022automatic,
  title={Automatic Arabic Grammatical Error Correction based on Expectation-Maximization routing and target-bidirectional agreement},
  author={Solyman, Aiman and Wang, Zhenyu and Tao, Qian and Elhag, Arafat Abdulgader Mohammed and Zhang, Rui and Mahmoud, Zeinab},
  journal={Knowledge-Based Systems},
  volume={241},
  pages={108180},
  year={2022},
  publisher={Elsevier}
}

@article{solyman2023optimizing,
  title={Optimizing the impact of data augmentation for low-resource grammatical error correction},
  author={Solyman, Aiman and Zappatore, Marco and Zhenyu, Wang and Mahmoud, Zeinab and Alfatemi, Ali and Ibrahim, Ashraf Osman and Gabralla, Lubna Abdelkareim},
  journal={Journal of King Saud University-Computer and Information Sciences},
  volume={35},
  number={6},
  pages={101572},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{suarez2019asynchronous,
  title={Asynchronous pipeline for processing huge corpora on medium to low resource infrastructures},
  author={Su{\'a}rez, Pedro Javier Ortiz and Sagot, Beno{\^\i}t and Romary, Laurent},
  booktitle={7th Workshop on the Challenges in the Management of Large Corpora (CMLC-7)},
  year={2019},
  organization={Leibniz-Institut f{\"u}r Deutsche Sprache}
}

@article{suarez2020monolingual,
  title={A monolingual approach to contextualized word embeddings for mid-resource languages},
  author={Su{\'a}rez, Pedro Javier Ortiz and Romary, Laurent and Sagot, Beno{\^\i}t},
  journal={arXiv preprint arXiv:2006.06202},
  year={2020}
}

@article{trinh2018simple,
  title={A simple method for commonsense reasoning},
  author={Trinh, Trieu H and Le, Quoc V},
  journal={arXiv preprint arXiv:1806.02847},
  year={2018}
}

@article{xue2020mt5,
  title={mt5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, L},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
}

@article{xue2022byt5,
  title={Byt5: Towards a token-free future with pre-trained byte-to-byte models},
  author={Xue, Linting and Barua, Aditya and Constant, Noah and Al-Rfou, Rami and Narang, Sharan and Kale, Mihir and Roberts, Adam and Raffel, Colin},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={291--306},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@inproceedings{zeroual2019osian,
  title={OSIAN: Open source international Arabic news corpus-preparation and integration into the CLARIN-infrastructure},
  author={Zeroual, Imad and Goldhahn, Dirk and Eckart, Thomas and Lakhouaja, Abdelhak},
  booktitle={Proceedings of the fourth arabic natural language processing workshop},
  pages={175--182},
  year={2019}
}

@article{zhu2015aligning,
  title={Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books},
  author={Zhu, Yukun},
  journal={arXiv preprint arXiv:1506.06724},
  year={2015}
}

