\section{Analysis}

\textbf{3D Structure.}
The vanilla RoPE defines a matrix $\bm{A}_{t_1,t_2}$ that represents the relative positional encoding between two positions $t_1$ and $t_2$ in a 1D sequence:
\begin{equation}\label{eq:vanilla_rope}
% \vspace{-6pt}
\begin{aligned}
% \small
\bm{A}_{t_1,t_2}&=\left(\bm{q}_{t_1}\bm{R}_{t_1}\right){\left(\bm{k}_{t_2}\bm{R}_{t_2}\right)}^\top
% = \bm{q}_{t_1}\bm{R}_{t_1}\bm{R}_{t_2}^\top\bm{k}_{t_2}^\top
= \bm{q}_{t_1}\bm{R}_{\Delta t}\bm{k}_{t_2}^\top,
\end{aligned}
% \vspace{-6pt}
\end{equation}
where $\Delta t=t_1-t_2$, the symbols $\bm{q}_{t_1}$ and $\bm{k}_{t_2}$ are the query and key vectors at positions $t_1$ and $t_2$.
The \textit{relative rotation matrix} $\bm{R}_{\Delta t}$ is defined as $\bm{R}_{\Delta t} = \exp(\Delta ti\theta_{n})$, while $i$ is the imaginary unit, $\theta_{n} = \beta^{-2n/d}$ is the frequency of rotation applied to a specific $n$-th pair of $d$ dimensions ($n=0,\ldots,d/2-1$), and $\beta$ is the frequency base parameter.
The vanilla RoPE uses $d=128$, thus $n=0,\ldots,63$.
Consequently, the $\bm{A}_{t_1,t_2}$ in Eq. (\ref{eq:vanilla_rope}) can be extended as:
% \begin{equation}\label{equ:rope}
% \vspace{-6pt}
% \resizebox{0.5\textwidth}{!}{
% \scriptsize
% \begin{gathered}
% \begin{pmatrix}
% q^{(0)}\\q^{(1)}\\\vdots\\q^{(126)}\\q^{(127)}
% \end{pmatrix}^\top
% \begin{pmatrix}\cos{\theta_0\Delta t}& -\sin{\theta_0\Delta t}&\cdots&0&0\\ \sin{\theta_0\Delta t}&\cos{\theta_0\Delta t}&\cdots&0&0 \\ \vdots&\vdots&\ddots&\vdots&\vdots\\ 0&0&\cdots&\cos{\theta_{63}\Delta t}&  \sin{\theta_{63}\Delta t}\\ 0&0&\cdots&\sin{\theta_{63}\Delta t}&\cos{\theta_{63}\Delta t}
% \end{pmatrix}
% \begin{pmatrix}
% k^{(0)}\\k^{(1)}\\\vdots\\k^{(126)}\\k^{(127)}
% \end{pmatrix}.
% \end{gathered}
% }
% \end{equation}
\begin{equation}\label{equ:rope}
\vspace{-6pt}
\resizebox{0.5\textwidth}{!}{$
\scriptsize
\left(
\begin{array}{c}
q^{(0)}\\q^{(1)}\\\vdots\\q^{(126)}\\q^{(127)}
\end{array}
\right)^{\top}
\left(
\begin{array}{ccccc}
\cos{\theta_0\Delta t} & -\sin{\theta_0\Delta t} & \cdots & 0 & 0 \\ 
\sin{\theta_0\Delta t} & \cos{\theta_0\Delta t} & \cdots & 0 & 0 \\ 
\vdots & \vdots & \ddots & \vdots & \vdots \\  
0 & 0 & \cdots & \cos{\theta_{63}\Delta t} &  \sin{\theta_{63}\Delta t} \\  
0 & 0 & \cdots & \sin{\theta_{63}\Delta t} & \cos{\theta_{63}\Delta t} 
\end{array}
\right)
\left(
\begin{array}{c}
k^{(0)}\\k^{(1)}\\\vdots\\k^{(126)}\\k^{(127)}
\end{array}
\right)
$}
\end{equation}



While the vanilla RoPE operates on 1D sequences, it can also be applied to higher-dimensional input by flattening the input into a 1-D sequence.
However, the flattening process discards crucial neighborhood information, increases the sequence length, and hinders the capture of long-range dependencies.
Therefore, preserving the inherent 3D structure is essential when adapting RoPE for video data.
Some recent RoPE-variants (e.g., M-RoPE in Qwen2-VL \cite{wang2024qwen2}) incorporate the $3$D structure.
The corresponding relative matrix $\bm{A}_{(t_1,x_1,y_1)}$ is computed as:
\begin{equation}
% \small
\bm{A}_{(t_1,x_1,y_1),(t_2,x_2,y_2)}=\bm{q}_{(t_1,x_1,y_1)}\bm{R}_{\Delta t,\Delta x,\Delta y}\bm{k}_{(t_2,x_2,y_2)}^\top,
\end{equation}
where $\Delta t=t_1-t_2$, $\Delta x=x_1-x_2$, and $\Delta y=y_1-y_2$.
M-RoPE divides the $d=128$ feature dimensions into 3 groups: the first 32 for temporal positions ($t$), the middle 48 for horizontal positions ($x$), and the last 48 for vertical positions ($y$). As shown in Eq~(\ref{equ:mrope}), $\bm{A}_{(t_1,x_1,y_1),(t_2,x_2,y_2)}$ in M-RoPE is extended as:
\begin{equation}
\vspace{-6pt}
\resizebox{0.5\textwidth}{!}{$
\scriptsize
\begin{gathered}
\underbrace{\begingroup
\setlength\arraycolsep{1pt}
\begin{pmatrix}q^{(0)}\\q^{(1)}\\q^{(2)}\\q^{(3)}\\\vdots\\q^{(30)}\\q^{(31)}\end{pmatrix}^\top
\begin{pmatrix}
% \setstacktabbedgap{2pt}
\cos{\theta_0\Delta t}& -\sin{\theta_0\Delta t}&0&0&\cdots&0&0\\
\sin{\theta_0\Delta t}&\cos{\theta_0\Delta t}&0&0&\cdots&0&0 \\
0&0&\cos{\theta_1\Delta t}& -\sin{\theta_1\Delta t}&\cdots&0&0\\
0&0&\sin{\theta_1\Delta t}&\cos{\theta_1\Delta t}&\cdots&0&0 \\ 
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&0&0&\cdots&\cos{\theta_{15}\Delta t}& -\sin{\theta_{15}\Delta t}\\
0&0&0&0&\cdots&\sin{\theta_{15}\Delta t}&\cos{\theta_{15}\Delta t}
\end{pmatrix}
\begin{pmatrix}k^{(0)}\\k^{(1)}\\k^{(2)}\\k^{(3)}\\\vdots\\k^{(30)}\\k^{(31)}\end{pmatrix}
\endgroup}_\text{\normalsize modeling temporal dependency with higher frequency} \\
+ \underbrace{\begingroup
\setlength\arraycolsep{1pt}
\begin{pmatrix}q^{(32)}\\q^{(33)}\\q^{(34)}\\q^{(35)}\\\vdots\\q^{(78)}\\q^{(79)}\end{pmatrix}^\top
\begin{pmatrix}
% \setstacktabbedgap{2pt}
\cos{\theta_{16}\Delta x}& -\sin{\theta_{16}\Delta x}&0&0&\cdots&0&0\\
\sin{\theta_{16}\Delta x}&\cos{\theta_{16}\Delta x}&0&0&\cdots&0&0 \\
0&0&\cos{\theta_{17}\Delta x}& -\sin{\theta_{17}\Delta x}&\cdots&0&0\\
0&0&\sin{\theta_{17}\Delta x}&\cos{\theta_{17}\Delta x}&\cdots&0&0 \\ 
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&0&0&\cdots&\cos{\theta_{39}\Delta x}& -\sin{\theta_{39}\Delta x}\\
0&0&0&0&\cdots&\sin{\theta_{39}\Delta x}&\cos{\theta_{39}\Delta x}
\end{pmatrix}
\begin{pmatrix}k^{(32)}\\k^{(33)}\\k^{(34)}\\k^{(35)}\\\vdots\\k^{(78)}\\k^{(79)}\end{pmatrix}
\endgroup}_\text{\normalsize modeling horizontal dependency with intermediate frequency} \\
+ \underbrace{\begingroup
\setlength\arraycolsep{1pt}
\begin{pmatrix}q^{(80)}\\q^{(81)}\\q^{(82)}\\q^{(83)}\\\vdots\\q^{(126)}\\q^{(127)}\end{pmatrix}^\top
\begin{pmatrix}
% \setstacktabbedgap{2pt}
\cos{\theta_{40}\Delta y}& -\sin{\theta_{40}\Delta y}&0&0&\cdots&0&0\\
\sin{\theta_{40}\Delta y}&\cos{\theta_{40}\Delta y}&0&0&\cdots&0&0 \\
0&0&\cos{\theta_{41}\Delta y}& -\sin{\theta_{41}\Delta y}&\cdots&0&0\\
0&0&\sin{\theta_{41}\Delta y}&\cos{\theta_{41}\Delta y}&\cdots&0&0 \\ 
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&0&0&\cdots&\cos{\theta_{63}\Delta y}& -\sin{\theta_{63}\Delta y}\\
0&0&0&0&\cdots&\sin{\theta_{63}\Delta y}&\cos{\theta_{63}\Delta y}
\end{pmatrix}
\begin{pmatrix}k^{(80)}\\k^{(81)}\\k^{(82)}\\k^{(83)}\\\vdots\\k^{(126)}\\k^{(127)}\end{pmatrix}
\endgroup}_\text{\normalsize modeling vertical dependency with lower frequency}
\end{gathered}
$}
\label{equ:mrope}
\end{equation}
% \begin{equation}
% \vspace{-6pt}
% \resizebox{0.5\textwidth}{!}{$
% \scriptsize
% \underbrace{
% \left(
% \begin{array}{c}
% q^{(0)}\\q^{(1)}\\\vdots\\q^{(31)}
% \end{array}
% \right)^{\top}
% \left(
% \begin{array}{cccccc}
% \cos{\theta_0\Delta t} & -\sin{\theta_0\Delta t} & \cdots & 0 \\ 
% \sin{\theta_0\Delta t} & \cos{\theta_0\Delta t} & \cdots & 0 \\ 
% \vdots & \vdots & \ddots & \vdots \\ 
% 0 & 0 & \cdots & \cos{\theta_{15}\Delta t} 
% \end{array}
% \right)
% \left(
% \begin{array}{c}
% k^{(0)}\\k^{(1)}\\\vdots\\k^{(31)}
% \end{array}
% \right)
% }_{\text{\normalsize modeling temporal dependency with higher frequency}}
% +
% \underbrace{
% \left(
% \begin{array}{c}
% q^{(32)}\\q^{(33)}\\\vdots\\q^{(79)}
% \end{array}
% \right)^{\top}
% \left(
% \begin{array}{cccccc}
% \cos{\theta_{16}\Delta x} & -\sin{\theta_{16}\Delta x} & \cdots & 0 \\ 
% \sin{\theta_{16}\Delta x} & \cos{\theta_{16}\Delta x} & \cdots & 0 \\ 
% \vdots & \vdots & \ddots & \vdots \\ 
% 0 & 0 & \cdots & \cos{\theta_{39}\Delta x} 
% \end{array}
% \right)
% \left(
% \begin{array}{c}
% k^{(32)}\\k^{(33)}\\\vdots\\k^{(79)}
% \end{array}
% \right)
% }_{\text{\normalsize modeling horizontal dependency with intermediate frequency}}
% +
% \underbrace{
% \left(
% \begin{array}{c}
% q^{(80)}\\q^{(81)}\\\vdots\\q^{(127)}
% \end{array}
% \right)^{\top}
% \left(
% \begin{array}{cccccc}
% \cos{\theta_{40}\Delta y} & -\sin{\theta_{40}\Delta y} & \cdots & 0 \\ 
% \sin{\theta_{40}\Delta y} & \cos{\theta_{40}\Delta y} & \cdots & 0 \\ 
% \vdots & \vdots & \ddots & \vdots \\ 
% 0 & 0 & \cdots & \cos{\theta_{63}\Delta y} 
% \end{array}
% \right)
% \left(
% \begin{array}{c}
% k^{(80)}\\k^{(81)}\\\vdots\\k^{(127)}
% \end{array}
% \right)
% }_{\text{\normalsize modeling vertical dependency with lower frequency}}
% $}
% \end{equation}


\noindent \textbf{Frequency Allocation.}
% Note that the frequency encoding in vanilla RoPE (Eq. \ref{equ:rope}) assigns higher frequencies (via larger $\theta_{n}$ values) to lower dimensions.
Incorporating 3D structure raises the question of how to allocate the temporal ($t$), horizontal ($x$), and vertical ($y$) components within the $d$ dimensions.
Note that different allocation strategies are not equivalent in the rotation frequency $\theta_{n} = \beta^{-2n/d}$.
As shown in Eq. (\ref{equ:mrope}), M-RoPE assigns higher frequencies (corresponding to lower dimensions) to the temporal dimension ($t$).

To highlight the importance of frequency allocation, we introduce a challenging retrieval task \textbf{V}isual \textbf{N}eedle-\textbf{I}n-\textbf{A}-\textbf{H}astack-\textbf{D}istractor (\textbf{V-NIAH-D}).
V-NIAH-D builds upon V-NIAH \cite{zhang2024longva}, a benchmark designed to evaluate visual long-context understanding.
However, the straightforward retrieval-based task has been shown to provide only a superficial form of long-context understanding~\cite{hsieh2024ruler,yuan2024lv}.
Therefore, We enhance V-NIAH by incorporating semantically similar distractors, obtained using Google Image Search~\cite{googleimagesearch} or Flux ~\cite{flux2023}, to mitigate the possibility of correct answers through random chance.
These distractors are designed to be unambiguous to the question in Fig. \ref{fig:v-ruler}.

\input{figures/attention_analysis}

As shown in Fig. \ref{fig:v-ruler}, M-RoPE exhibits a clear performance drop from V-NIAH to V-NIAH-D. To investigate this decline, we follow previous works \citep{xiao2023efficient,liu2023scaling,barbero2024round} to visualize the attention scores in Fig. \ref{fig:attention_analysis}. We decompose the attention scores into their corresponding temporal ($t$), horizontal ($x$), and vertical ($y$) components for visualization.

Fig.~ \ref{fig:attention_analysis} reveals unusual attention patterns in M-RoPE, despite its ability to locate the needle image but fails to answer the multi-choice question.
According to the attention of M-RoPE, the needle is located primarily through vertical positional information, rather than temporal features.
Thus, the temporal dimension fails to capture long-range semantic dependencies, focusing instead on local relationships.
Conversely, the spatial dimensions exhibit a tendency to capture long-range rather than local semantic information.
Lastly, the horizontal and vertical dimensions display distinct characteristics, with the vertical dimension exhibiting phenomena reminiscent of attention sinks \cite{xiao2023efficient}.
These observations suggest that the performance decline primarily results from the sub-optimal frequency allocation designs of M-RoPE.

\noindent \textbf{Spatial Symmetry.} Given the text tokens $T$ and the visual tokens $T_v$, spatial symmetry \cite{kexuefm10352} claims that the distance between the end of the preceding textual input ($T_{\text{pre}}$) and the beginning of the visual input ($T_v^{\text{start}}$) is equal to the distance between the end of the visual input ($T_v^{\text{end}}$) and the beginning of the subsequent textual input ($T_{\text{sub}}$):
\begin{equation}
    T_{v}^{\text{start}} - T_{\text{pre}} =
    T_{\text{sub}} - T_{v}^{\text{end}}.
\end{equation}
The spatial symmetrical structure can potentially simplify the learning process and reduce bias toward input order.
However, existing 3D RoPE variants such as M-RoPE do not meet the spatial symmetry, we will elaborate related discussion in Fig. \ref{fig:spatial}.

\input{figures/period_mono}

\noindent \textbf{Temporal Index Scaling.}
The frame index in video and the token index in text are inherently different \cite{kexuefm10352,li2024temporal}.
Recognizing this difference, methods like TAD-RoPE, a 1D RoPE adaptation for Video LLMs, introduce distinct step offsets for image and text token indices: $\gamma$ for image tokens and $\gamma+1$ for text tokens.
Consequently, an ideal RoPE design for video data should permit scaling of the temporal index to meet the inherent difference between the frame index and the text index.

\section{\methodname}\label{subsec:step_size}

Based on some previous research and the above analysis, we claim that a good RoPE design for Video LLMs, especially for long videos, should satisfy four requirements.
% : 3D structure, Appreciate Frequency Allocation, Spatial Symmetry, and Temporal Index Scaling.
The first requirement has been solved by RoPE-Tie~\cite{kexuefm10040} and the subsequent M-RoPE~\cite{wang2024qwen2}.
To solve the last three requirements and mitigate the performance decline observed in V-NIAH-D, we propose our \methodname, comprising the following three key components.
% (1) Low-frequency Temporal Allocation; (2) Diagonal Layout; and (3) Adjustable Temporal Spacing.
% \textbf{\textit{Multi-Modal Compatibility}}, whether RoPE can simultaneously describe the spatiotemporal position in multi-modals and sequential position in text-only inputs~\cite{wang2024qwen2,kexuefm10040,kexuefm10352}, \textbf{\textit{Appropriate Dimension Distribution}}, whether the feature dimension can process the semantic relationship where it is responsibility~\cite{peng2023yarn,barbero2024round,liu2024kangaroo}, \textbf{\textit{Spatial Symmetry}}, whether the distance between the end of precedent textual input and start of visual input equals the distance between the end of visual input and the start of subsequent textual input~\cite{kexuefm10352}, and \textbf{\textit{Temporal Alignment}}, whether the alignment of sequential feature in different modality is considered~\cite{gao2024tc}.

\noindent \textbf{Low-frequency Temporal Allocation (LTA).} 
As shown in Eq. (\ref{equ:rope}), the vanilla RoPE~\cite{su2024roformer} uses all dimensions to model the 1D position information. And as indicated in Eq. (\ref{equ:mrope}), M-RoPE~\cite{wang2024qwen2} uses dimensions to model temporal, horizontal, and vertical dimensions sequentially.
However, previous frequency allocation strategies are suboptimal because different RoPE dimensions capture dependencies at varying ranges.
As shown in Fig.  \ref{fig:attention_analysis}, an interesting observation is that the local attention branch (as reported in \cite{han2024lm}) corresponds to lower dimensions, while the global branch (or attention sink, as in \cite{xiao2023efficient}) corresponds to higher dimensions.
To sum up, lower dimensions (higher frequency, shorter monotonic intervals, larger $\theta_n$) tend to capture relative distances and local semantics \cite{men2024base,barbero2024round}, while higher dimensions (lower frequency, wider monotonic intervals, smaller $\theta_n$) capture longer-range dependencies \cite{barbero2024round}.

Based on our analysis, \methodname uses higher dimensions for temporal features in longer contexts and lower dimensions for spatial features, which are limited by resolution and have a fixed range.
To avoid the gap between horizontal and vertical positions, we interleave the dimensions responsible for these spatial features.
The dimension distribution for \methodname is shown in Eq. (\ref{equ:videorope}):

% $\bm{A}_{(t_1,x_1,y_1),(t_2,x_2,y_2)}=\bm{q}_{(t_1,x_1,y_1)}\bm{k}_{(t_2,x_2,y_2)}^\top$

% To make full use of these properties of RoPE, \methodname uses higher dimensions to model temporal features in longer contexts and lower dimensions to model spatial features since spatial features tend to be limited by resolution and have a relatively fixed range. To avoid the gap between horizontal and vertical positions, we interleave the dimensions responsible for those two spatial features. Therefore, the dimension distribution for \methodname is shown in Equation~\ref{equ:videorope}.
% 48, 48, 32; 0, 47, 48, 95; 96, 127
\begin{equation}
\resizebox{0.5\textwidth}{!}{$
\scriptsize
\begin{gathered}
\underbrace{\begingroup
\setlength\arraycolsep{1pt}
\begin{pmatrix}q^{(96)}\\q^{(97)}\\q^{(98)}\\q^{(99)}\\\vdots\\q^{(126)}\\q^{(127)}\end{pmatrix}^\top
\begin{pmatrix}
% \setstacktabbedgap{2pt}
\cos{\theta_{48}\Delta t}& -\sin{\theta_{48}\Delta t}&0&0&\cdots&0&0\\
\sin{\theta_{48}\Delta t}&\cos{\theta_{48}\Delta t}&0&0&\cdots&0&0 \\
0&0&\cos{\theta_{49}\Delta t}& -\sin{\theta_{49}\Delta t}&\cdots&0&0\\
0&0&\sin{\theta_{49}\Delta t}&\cos{\theta_{49}\Delta t}&\cdots&0&0 \\ 
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&0&0&\cdots&\cos{\theta_{63}\Delta t}& -\sin{\theta_{63}\Delta t}\\
0&0&0&0&\cdots&\sin{\theta_{63}\Delta t}&\cos{\theta_{63}\Delta t}
\end{pmatrix}
\begin{pmatrix}k^{(96)}\\k^{(97)}\\k^{(98)}\\k^{(99)}\\\vdots\\k^{(126)}\\k^{(127)}\end{pmatrix}
\endgroup}_\text{\normalsize modeling temporal dependency with lower frequency} \\
+ \underbrace{\begingroup
\setlength\arraycolsep{1pt}
\begin{pmatrix}q^{(0)}\\q^{(1)}\\q^{(4)}\\q^{(5)}\\\vdots\\q^{(92)}\\q^{(93)}\end{pmatrix}^\top
\begin{pmatrix}
% \setstacktabbedgap{2pt}
\cos{\theta_{0}\Delta x}& -\sin{\theta_{0}\Delta x}&0&0&\cdots&0&0\\
\sin{\theta_{0}\Delta x}&\cos{\theta_{0}\Delta x}&0&0&\cdots&0&0 \\
0&0&\cos{\theta_{2}\Delta x}& -\sin{\theta_{2}\Delta x}&\cdots&0&0\\
0&0&\sin{\theta_{2}\Delta x}&\cos{\theta_{2}\Delta x}&\cdots&0&0 \\ 
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&0&0&\cdots&\cos{\theta_{46}\Delta x}& -\sin{\theta_{46}\Delta x}\\
0&0&0&0&\cdots&\sin{\theta_{46}\Delta x}&\cos{\theta_{46}\Delta x}
\end{pmatrix}
\begin{pmatrix}k^{(0)}\\k^{(1)}\\k^{(4)}\\k^{(5)}\\\vdots\\k^{(92)}\\k^{(93)}\end{pmatrix}
\endgroup}_\text{\normalsize modeling horizontal dependency with interleaved high frequency} \\
+ \underbrace{\begingroup
\setlength\arraycolsep{1pt}
\begin{pmatrix}q^{(2)}\\q^{(3)}\\q^{(6)}\\q^{(7)}\\\vdots\\q^{(94)}\\q^{(95)}\end{pmatrix}^\top
\begin{pmatrix}
% \setstacktabbedgap{2pt}
\cos{\theta_{1}\Delta y}& -\sin{\theta_{1}\Delta y}&0&0&\cdots&0&0\\
\sin{\theta_{1}\Delta y}&\cos{\theta_{1}\Delta y}&0&0&\cdots&0&0 \\
0&0&\cos{\theta_{3}\Delta y}& -\sin{\theta_{3}\Delta y}&\cdots&0&0\\
0&0&\sin{\theta_{3}\Delta y}&\cos{\theta_{3}\Delta y}&\cdots&0&0 \\ 
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&0&0&\cdots&\cos{\theta_{47}\Delta y}& -\sin{\theta_{47}\Delta y}\\
0&0&0&0&\cdots&\sin{\theta_{47}\Delta y}&\cos{\theta_{47}\Delta y}
\end{pmatrix}
\begin{pmatrix}k^{(2)}\\k^{(3)}\\k^{(6)}\\k^{(7)}\\\vdots\\k^{(94)}\\k^{(95)}\end{pmatrix}
\endgroup}_\text{\normalsize modeling vertical dependency with interleaved high frequency} \\
% \Delta t=t_1-t_2,\quad \Delta x=x_1-x_2,\quad \Delta y=y_1-y_2 \\
% \theta_n=\beta^{-\dfrac{2n}{d}},\quad n=0,\cdots,d/2-1
\end{gathered}
$
}
% \raisebox{-5.5ex}{.}
\label{equ:videorope}
\end{equation}
The horizontal position $x$ and vertical position $y$ are interleaved to occupy the lower dimensions, followed by temporal $t$, which occupies the higher dimensions. We keep the same allocation number for $x$, $y$, and $t$ as M-RoPE for a fair comparison, with values of 48, 48, and 32, respectively.
The advantages of this distribution are evident in Fig.  \ref{fig:period_mono}. 
For a RoPE-based LLM with a 128-dimensional head (64 rotary angles $\theta_n$), we visualize the function of $\cos{\theta_n t}$ for 3 dimensions using parallel blue planes.

As shown in Fig. \ref{fig:period_mono} (\textbf{a}), M-RoPE's temporal position embeddings are significantly distorted by periodic oscillations \cite{men2024base}, leading to identical embeddings for distant positions.
For instance, considering the last three rotary angles, the temporal embeddings are severely affected by these oscillations due to their short monotonic intervals (and even shorter intervals in lower dimensions).
This periodicity creates ``hash collisions'' (red planes), where distant positions share near-identical embeddings, making the model susceptible to distractor influence.
Fortunately, our \methodname (Fig. \ref{fig:period_mono} (\textbf{b})) is free from oscillation and Hash collision in temporal modeling.
The visualized relationship between the periodicity, monotonicity, and temporal modeling.

\input{figures/spatail_index}

\input{figures/spatial}

\noindent \textbf{Diagonal Layout.}
Fig. \ref{fig:spatial} provides a visual comparison of spatial symmetry in positional encodings.
For vanilla RoPE (Fig. ~\ref{fig:vanilla_rope}), no spatial relation is considered and the index for every dimension increases directly.
While M-RoPE (Fig. \ref{fig:m_rope}), incorporates spatial information within each frame, it introduces two significant discontinuities between textual and visual tokens.
This arises from M-RoPE's placement strategy, if the first visual token is at $(0, 0)$, the last token in each frame will always be placed at $(W-1, H-1)$, creating a stack in the bottom-left corner.
Furthermore, like vanilla RoPE, M-RoPE's indices increase with input length across all dimensions.

To address these limitations, \methodname arranges the entire input along the diagonal, see Fig. \ref{fig:video_rope}.
The central patch's 3D position for each video frame is $(t,t,t)$, with other patches offset in all directions.
Our \textbf{Diagonal Layout} has two advantages: (1) our design preserves the relative positions of visual tokens and ensures approximate equidistance from the image corners to the center, preventing text tokens from being overly close to any corner. (2) It maintains the indexing pattern of vanilla RoPE (Fig.  \ref{fig:spatail_index}), as the position index increment between corresponding spatial locations in adjacent frames mirrors that of adjacent textual tokens.

\noindent \textbf{Adjustable Temporal Spacing.}
To scale the temporal index, we introduce a scaling factor $\delta$ to better align temporal information between visual and textual tokens.

Suppose the symbol $\tau$ denotes the token index, for the starting text ($0 \leq \tau < T_s$), the temporal, horizontal, and vertical indices are simply set to the raw token index $\tau$.
For the video input ($T_s \leq \tau < T_s + T_v$), The difference $\tau - T_s$ represents the index of the current frame relative to the start of the video, which is then scaled by $\delta$ to control the space in the temporal dimension.
For the ending text ($T_s + T_v \leq \tau < T_s + T_v + T_e$), the temporal, horizontal, and vertical index are the same, creating a linear progression.

According to our adjustable temporal spacing design, for a multi-modal input that consists of a text with $T_s$ tokens, a following video with $T_v$ frame with $W\times H$ patches in each frame, and an ending text with $T_e$ tokens, the position indices $(t, x, y)$ of \methodname for $\tau$-th textual token or $(\tau, w, h)$-th visual token are defined as Eq. (\ref{equ:index}):
\begin{equation}
\vspace{-3pt}
\resizebox{0.5\textwidth}{!}{$
    \footnotesize
    (t,x,y) =
    \begin{cases}
        (\tau, \tau, \tau) & \text{if } 0 \leq \tau < T_s \\[3ex]
        \left( 
        \begin{array}{l}
            T_s + \delta (\tau - T_s), \\
            T_s + \delta (\tau - T_s) + w - \frac{W}{2}, \\
            T_s + \delta (\tau - T_s) + h - \frac{H}{2}
        \end{array}
        \right) & \text{if } T_s \leq \tau < T_s + T_v \\[6ex]
        \left( 
        \begin{array}{l}
            T_s + \delta T_v + \tau, \\
            T_s + \delta T_v + \tau, \\
            T_s + \delta T_v + \tau
        \end{array}
        \right) & \text{if } T_s + T_v \leq \tau < T_s + T_v + T_e
    \end{cases}
$}
\raisebox{-9.5ex}{,}
\label{equ:index}
\end{equation}
where $w$ and $h$ represent the horizontal and vertical indices of the visual patch within the frame, respectively.

In summary, the parameter $\delta$ in our adjustable temporal spacing allows for a flexible and consistent way to encode the relative positions of text and video tokens.