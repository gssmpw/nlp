\section{Related Work}
\label{sec:Related_Work}
\paragraph{Self-correction in LLMs.} Self-correction in LLMs refers to the ability of models to correct their own generated output \citep{kamoi2024correctionsurvey, huang2024cannotselfcorrect, madaan2023selfrefine}. Recent studies \citep{tyen2024errorlocation, kamoi2024evaluatingdetecting} suggest that LLMs tend to struggle with \textit{intrinsic} self-correction, especially with \emph{detecting} errors in their own output~\citep{huang2024cannotselfcorrect, tyen2024errorlocation, kamoi2024correctionsurvey}. While most studies focus on improving the models' ability to self-correct~\citep{kamoi2024correctionsurvey, madaan2023selfrefine, chen2024selfdebug, zhao2023verifyandedit, welleck2023learnselfcorrect}, our study analyzes the capacity of LLMs to detect errors from a mechanistic point of view.

\paragraph{Arithmetic and Error Detection in LLMs.} To the best of our knowledge, the underlying processes of arithmetic reasoning and error detection have been studied independently in LLMs so far. Several studies \citep{stolfo2023arithmetic, zhang2024arithmetic, nikankin2024bagofheuristics} use causal mediation analysis \citep{pearl2001effects} to identify circuits that account for how LLMs process arithmetic operations. As of now, only few studies have analyzed self-correction in LLMs beyond the models' generated output~\citep{DBLP:journals/corr/abs-2402-12563, liu2024moralselfcorrection}.