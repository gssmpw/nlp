@article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@inproceedings{guo2023prompttts,
  title={Prompttts: Controllable text-to-speech with text descriptions},
  author={Guo, Zhifang and Leng, Yichong and Wu, Yihan and Zhao, Sheng and Tan, Xu},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@inproceedings{ji2024textrolspeech,
  title={Textrolspeech: A text style control speech corpus with codec language text-to-speech models},
  author={Ji, Shengpeng and Zuo, Jialong and Fang, Minghui and Jiang, Ziyue and Chen, Feiyang and Duan, Xinyu and Huai, Baoxing and Zhao, Zhou},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={10301--10305},
  year={2024},
  organization={IEEE}
}

@inproceedings{kuan2023towards,
  title={Towards General-Purpose Text-Instruction-Guided Voice Conversion},
  author={Kuan, Chun-Yi and Li, Chen-An and Hsu, Tsu-Yuan and Lin, Tse-Yang and Chung, Ho-Lam and Chang, Kai-Wei and Chang, Shuo-Yiin and Lee, Hung-yi},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@article{leng2023prompttts,
  title={Prompttts 2: Describing and generating voices with text prompt},
  author={Leng, Yichong and Guo, Zhifang and Shen, Kai and Tan, Xu and Ju, Zeqian and Liu, Yanqing and Liu, Yufei and Yang, Dongchao and Zhang, Leying and Song, Kaitao and others},
  journal={arXiv preprint arXiv:2309.02285},
  year={2023}
}

@article{liu2023promptstyle,
  title={Promptstyle: Controllable style transfer for text-to-speech with natural language descriptions},
  author={Liu, Guanghou and Zhang, Yongmao and Lei, Yi and Chen, Yunlin and Wang, Rui and Li, Zhifei and Xie, Lei},
  journal={arXiv preprint arXiv:2305.19522},
  year={2023}
}

@misc{lyth2024natural,
      title={Natural language guidance of high-fidelity text-to-speech with synthetic annotations},
      author={Dan Lyth and Simon King},
      year={2024},
      eprint={2402.01912},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@article{niu2024hybridvc,
  title={HybridVC: Efficient Voice Style Conversion with Text and Audio Prompts},
  author={Niu, Xinlei and Zhang, Jing and Martin, Charles Patrick},
  journal={arXiv preprint arXiv:2404.15637},
  year={2024}
}

@inproceedings{shimizu2024prompttts++,
  title={PromptTTS++: Controlling speaker identity in prompt-based text-to-speech using natural language descriptions},
  author={Shimizu, Reo and Yamamoto, Ryuichi and Kawamura, Masaya and Shirahata, Yuma and Doi, Hironori and Komatsu, Tatsuya and Tachibana, Kentaro},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={12672--12676},
  year={2024},
  organization={IEEE}
}

@article{yang2024instructtts,
  title={Instructtts: Modelling expressive tts in discrete latent space with natural language style prompt},
  author={Yang, Dongchao and Liu, Songxiang and Huang, Rongjie and Weng, Chao and Meng, Helen},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}

