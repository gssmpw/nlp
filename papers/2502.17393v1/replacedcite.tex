\section{Related Works}
Symbolic regression, particularly GPSR____, has been studied for decades now. Improvements to the algorithms used have been made since, and continue to be an active area of research today____. DSR is a newer sub-field of SR, first appearing in the mid-2010's____. It is just as active an area of research as GPSR, with new methods for DSR networks being studied____.

The newest sub-field of SR is GNSR, with 7 reported methods in the literature to date____. Inspired by the success of transformer architectures in areas such as large language models____, most of these methods____ use transformer networks. These networks are all data-to-equation networks, where numeric data is fed into the transformer which then outputs a tokenized equation (Fig. \ref{fig:teaser}(a)).
However, they all use only one loss metric during training. Multi-objective loss functions are traditionally difficult for gradient-based methods to handle. However, evolutionary methods admit them easily in multi-objective optimization frameworks. It is for this reason that we here introduce and investigate a evolutionary, multi-objective approach to GNSR: data-to-equation models are evolved against symbolic and numeric loss objectives.

Using evolutionary computation to optimize neural networks is a common practice____. Generally, this takes the form of hyper-parameter optimization or even optimization of neural network structure. However, the neuroevolution of deep learning networks' weights has also been broadly studied in literature for many years____. One of the most common evolutionary algorithms for neuroevolution, NEAT____ uses evolutionary methods to optimize both structure and weights of neural networks. Here, however, we use traditional neuroevolution where only the weights are evolved.