\section{Related Work}
\subsection{LLM-as-RSs}

\subsubsection{LLM-as-Retriever}
LLM-as-Retriever leverages LLMs to recall a set of potentially relevant items from an entire item set based on a user's interaction history. To ensure that the retrieved items remain within item set, three key paradigms have been proposed: bi-step grounding, indexing, and modal alignment.
\textbf{Bi-Step Grounding}____ retrieves items by measuring the similarity between the textual output of the LLM and the candidate set. A pioneering work in this area is BIGRec____, which reformulates the recommendation task by first grounding the LLM’s output from the language space to the recommendation space, and subsequently aligning it with the actual item space.
\textbf{Indexing}____ discretizes items into semantically meaningful tokens and employs beam search for retrieval. A notable example is LC-Rec____, which aligns language tokens with item index tokens through task-specific optimizations, effectively bridging the gap between language representations and item indexing.
\textbf{Modal Alignment}____ transforms the semantic vectors encoded by the Collaborative Retrieval Model (CRM) to align them with the semantic space of the LLM, replacing the traditional next-token prediction head with a next-item prediction head. This approach seamlessly integrates collaborative filtering information into the LLM, leading to significant improvements in retrieval performance.

\subsubsection{LLM-as-Ranker}
The LLM-as-Ranker paradigm____ requires LLMs to either rank a set of candidates based on a user's interaction history (list-wise ranking) or predict the likelihood of user interaction with a specific item (point-wise ranking).
\textbf{Point-wise Ranking.} TALLRec____ represents a pioneering effort in this domain. Subsequent studies have introduced notable advancements, including integration with Click-Through Rate (CTR) models____, optimization of user preference modeling____, and improvements in text-like encoding techniques____.
\textbf{List-wise Ranking.} LLMRank____ serves as a foundational work in this area. Building on this, later research has explored various extensions, such as interpretable cross-domain recommendation____, intent-driven session-based recommendation____, and comprehensive LLM-powered recommendation systems____. Additionally, researchers have sought to enhance ranking performance through fine-tuning strategies____ and prompt optimization techniques____.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.99\linewidth]{4.jpg}
  \caption{User preference maintenance module.}
  \label{fig:8mke}
\end{figure}

\subsection{LLM-enhanced RSs}
LLM-enhanced recommender systems (RSs) leverage LLMs to enhance the capabilities of Collaborative Retrieval Models (CRM) during the training phase, while LLMs are not required during inference. Depending on the type of knowledge provided by the LLM, some studies utilize LLMs to construct or optimize graphs that encode structural knowledge for CRM____. Others introduce interaction information into CRM by generating synthetic interactions____. Additionally, certain works enhance CRM inputs by optimizing features____ or generating textual content____. Furthermore, some approaches improve CRM’s ability to learn high-quality representations by leveraging embeddings____.