\documentclass[sigconf]{acmart}

\usepackage{multirow}
\setlength{\tabcolsep}{3pt}

\AtBeginDocument{
  \providecommand\BibTeX{{
    Bib\TeX}}}

\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}

\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}

\acmISBN{978-1-4503-XXXX-X/2018/06}

\begin{document}

\title{Enhancing LLM-Based Recommendations Through Personalized Reasoning}

\author{Jiahao Liu}
\authornote{Equal contribution.}
\orcid{0000-0002-5654-5902}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{jiahaoliu23@m.fudan.edu.cn}

\author{Xueshuo Yan}
\authornotemark[1]
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{23210240353@m.fudan.edu.cn}

\author{Dongsheng Li}
\orcid{0000-0003-3103-8442}
\affiliation{
  \institution{Microsoft Research Asia}
  \city{Shanghai}
  \country{China}}
\email{dongsli@microsoft.com}

\author{Guangping Zhang}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{gpzhang20@fudan.edu.cn}

\author{Hansu Gu}
\orcid{0000-0002-1426-3210}
\affiliation{
  \institution{Independent}
  \city{Seattle}
  \country{United States}}
\email{hansug@acm.org}

\author{Peng Zhang}
\orcid{0000-0002-9109-4625}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{zhangpeng\_@fudan.edu.cn}

\author{Tun Lu}
\orcid{0000-0002-6633-4826}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{lutun@fudan.edu.cn}

\author{Li Shang}
\orcid{0000-0003-3944-7531}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{lishang@fudan.edu.cn}

\author{Ning Gu}
\orcid{0000-0002-2915-974X}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{ninggu@fudan.edu.cn}

\renewcommand{\shortauthors}{Jiahao Liu et al.}

\begin{abstract}
Current recommendation systems powered by large language models (LLMs) often underutilize their reasoning capabilities due to a lack of explicit logical structuring. To address this limitation, we introduce CoT-Rec, a framework that integrates Chain-of-Thought (CoT) reasoning into LLM-driven recommendations by incorporating two crucial processes: user preference analysis and item perception evaluation. CoT-Rec operates in two key phases: (1) personalized data extraction, where user preferences and item perceptions are identified, and (2) personalized data application, where this information is leveraged to refine recommendations. Our experimental analysis demonstrates that CoT-Rec improves recommendation accuracy by making better use of LLMs’ reasoning potential. The implementation is publicly available at \url{https://anonymous.4open.science/r/CoT-Rec}.
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002951.10003317.10003347.10003350</concept_id>
       <concept_desc>Information systems~Recommender systems</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Recommender systems}

\keywords{recommendation, large language models, chain-of-thought}

\maketitle

\begin{figure}[t]
  \centering
  \includegraphics[width=0.99\linewidth]{1.jpg}
  \caption{Overview of CoT-Rec.}
  \label{fig:nvoo}
\end{figure}

\section{Introduction}
Due to their powerful understanding, reasoning, and generation capabilities, large language models (LLMs) have demonstrated remarkable success across multiple fields~\cite{sun2024adaptive,zhang2024agentcf,lu2024aligning,xia2022fire}.
Consequently, LLM-powered recommendations have attracted increasing attention~\cite{carraro2024enhancing,li2024explainable,zhang2023chatgpt,jiang2024item,liu2023personalized}.
LLMs contribute to recommender systems (RSs) in two ways:
(1) \textbf{LLMs as RSs}~\cite{zhang2024large,lei2024recexplainer,luo2024unlocking,liu2023autoseqrec}, where LLMs directly performing recommendation tasks, including \textit{LLM-as-Retriever} and \textit{LLM-as-Ranker};
(2) \textbf{LLM-enhanced RSs}~\cite{liu2024largesur,zhao2024let,liu2023recommendation}, where LLMs augment conventional recommendation models (CRMs).
\textit{Chain-of-Thought (CoT)}~\cite{wei2022chain} enhances LLMs' capacity for solving complex tasks by breaking down solutions into intermediate steps.
However, existing LLM-powered recommendation approaches often rely on LLMs to perform or enhance recommendation tasks directly based on users' interaction history, without explicitly modeling the reasoning process.
As a result, they do not fully exploit the reasoning capabilities of LLMs.

In this paper, we identify two key CoT processes---user preference analysis and item perception analysis---when performing or enhancing recommendation tasks with LLMs.
Furthermore, we propose a pipeline named \textbf{CoT-Rec} to incorporate user preference and item perception into LLM-powered recommendations.
As shown in Figure~\ref{fig:nvoo}, CoT-Rec consists of two stages: personalized information extraction and personalized information utilization.
In the \textbf{personalized information extraction} stage, a user preference maintenance module, inspired by the recurrent neural network (RNN)~\cite{medsker2001recurrent} architecture, analyzes the user's interaction sequence in chronological order and continuously updates user preference.
Subsequently, an item perception analysis module simulates the user's decision-making process through role-playing based on their preferences, thereby obtaining both the subjective perception and objective description of the item.
In the \textbf{personalized information utilization} stage, the extracted personalized information is integrated into the \textit{CRM-as-Retriever} to retrieve a candidate set from the entire item set.
This personalized information is then further fed into the \textit{LLM-as-Ranker} to optimize the ranking of the candidate set and generate the final recommendation list.
By explicitly incorporating user preferences and item perception, CoT-Rec enables LLM-powered recommendations to better leverage the reasoning capabilities of LLMs. 
Finally, experimental results on three datasets demonstrate that CoT-Rec improves the retrieval accuracy of the CRM in the retrieval stage and reduces the position bias of the LLM in the ranking stage.

\section{Related Work}

\subsection{LLM-as-RSs}

\subsubsection{LLM-as-Retriever}
LLM-as-Retriever leverages LLMs to recall a set of potentially relevant items from an entire item set based on a user's interaction history. To ensure that the retrieved items remain within item set, three key paradigms have been proposed: bi-step grounding, indexing, and modal alignment.
\textbf{Bi-Step Grounding}~\cite{lin2024bridging,gao2024sprec} retrieves items by measuring the similarity between the textual output of the LLM and the candidate set. A pioneering work in this area is BIGRec~\cite{bao2023bi}, which reformulates the recommendation task by first grounding the LLM’s output from the language space to the recommendation space, and subsequently aligning it with the actual item space.
\textbf{Indexing}~\cite{chen2024enhancing,li2024semantic} discretizes items into semantically meaningful tokens and employs beam search for retrieval. A notable example is LC-Rec~\cite{zheng2024adapting}, which aligns language tokens with item index tokens through task-specific optimizations, effectively bridging the gap between language representations and item indexing.
\textbf{Modal Alignment}~\cite{yu2024break,li2023e4srec,chen2024hllm,zhang2024recgpt} transforms the semantic vectors encoded by the Collaborative Retrieval Model (CRM) to align them with the semantic space of the LLM, replacing the traditional next-token prediction head with a next-item prediction head. This approach seamlessly integrates collaborative filtering information into the LLM, leading to significant improvements in retrieval performance.

\subsubsection{LLM-as-Ranker}
The LLM-as-Ranker paradigm~\cite{cao2024aligning,luo2024recranker} requires LLMs to either rank a set of candidates based on a user's interaction history (list-wise ranking) or predict the likelihood of user interaction with a specific item (point-wise ranking).
\textbf{Point-wise Ranking.} TALLRec~\cite{bao2023tallrec} represents a pioneering effort in this domain. Subsequent studies have introduced notable advancements, including integration with Click-Through Rate (CTR) models~\cite{lin2024clickprompt,lin2024rella}, optimization of user preference modeling~\cite{zheng2024harnessing}, and improvements in text-like encoding techniques~\cite{zhang2024text}.
\textbf{List-wise Ranking.} LLMRank~\cite{hou2024large} serves as a foundational work in this area. Building on this, later research has explored various extensions, such as interpretable cross-domain recommendation~\cite{petruzzelli2024instructing}, intent-driven session-based recommendation~\cite{sun2024large}, and comprehensive LLM-powered recommendation systems~\cite{kim2024large}. Additionally, researchers have sought to enhance ranking performance through fine-tuning strategies~\cite{yue2023llamarec,liao2024llara,chen2024softmax,liu2022parameter} and prompt optimization techniques~\cite{wang2024whole}.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.99\linewidth]{4.jpg}
  \caption{User preference maintenance module.}
  \label{fig:8mke}
\end{figure}

\subsection{LLM-enhanced RSs}
LLM-enhanced recommender systems (RSs) leverage LLMs to enhance the capabilities of Collaborative Retrieval Models (CRM) during the training phase, while LLMs are not required during inference. Depending on the type of knowledge provided by the LLM, some studies utilize LLMs to construct or optimize graphs that encode structural knowledge for CRM~\cite{hu2024bridging, zhang2024finerec, sakurai2024llm, wang2024llmrg, yang2024sequential,liu2024filtering}. Others introduce interaction information into CRM by generating synthetic interactions~\cite{wang2024large, wei2024llmrec}. Additionally, certain works enhance CRM inputs by optimizing features~\cite{jia2024altfs, wang2024llms,liu2023triple} or generating textual content~\cite{zhang2024embsum, du2024enhancing, sun2024largecf, xi2024towards}. Furthermore, some approaches improve CRM’s ability to learn high-quality representations by leveraging embeddings~\cite{geng2024breaking, wang2024can, cui2024distillation, liu2024large, harte2023leveraging, zhang2024notellm, ren2024representation}.

\section{Preliminaries}
In this section, we introduce the sequential recommendation task and two methods that we use as backbones.

\textbf{Sequential Recommendation.} Given a user $u$ who has interacted chronologically with an item sequence $[i_1, i_2, \dots, i_n]$, the goal of sequential recommendation is to predict the next item $i_{n+1}$ that the user is likely to engage with.

\textbf{SASRec}~\cite{kang2018self} consists of an input layer, an embedding layer, a sequence modeling layer, and a prediction layer. The input layer processes a sequence of item IDs, which are mapped to embeddings in the embedding layer. The sequence modeling layer employs a unidirectional Transformer to capture feature interactions and aggregate information across items. Finally, the prediction layer outputs a probability distribution over the next item.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{5.jpg}
  \caption{Item perception analysis module.}
  \label{fig:pc9l}
\end{figure}

\textbf{LlamaRec}~\cite{yue2023llamarec} follows an LLM-as-Ranker approach. It first fine-tunes the LLM, which, given a candidate set, is instructed to predict the index (e.g., A, B, C, D) of the item the user is most likely to engage with. Based on the distribution of the predicted indices, the candidate set is then ranked in a list-wise manner.

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{6.jpg}
  \caption{Model architecture of the personalized information utilization stage in CoT-Rec. Note that we have added user embedding as an input for the CRM and included extracted user preferences and subjective perception of items in the prompt.}
  \label{fig:9cn6}
\end{figure*}

\section{Methods}
We have introduced the overall process of CoT-Rec through Figure~\ref{fig:nvoo}. Here, we present its details.

\subsection{Personalized Information Extraction}
The personalized information extraction stage extracts user preferences and item perception based on a user's interaction sequence.

\subsubsection{User Preference Maintenance Module}
As shown in Figure \ref{fig:8mke}, this module extracts user preferences by analyzing interaction sequences. Prior research suggests that even when temporal information is explicitly highlighted in the prompt, LLMs struggle to capture temporal relationships within interaction sequences accurately~\cite{hou2024large}. To improve LLMs' temporal sensitivity, we take inspiration from RNNs and process items in batches following chronological order. Each batch's processing result is summarized as short-term interest, which helps derive long-term preferences. Specifically, the short-term interest from the first batch directly serves as the initial long-term preference. Thereafter, each new short-term interest is integrated with the preceding long-term preference to update it. Additionally, adjacent batches partially overlap to maintain information continuity.

\subsubsection{Item Perception Analysis Module}
As shown in Figure \ref{fig:pc9l}, this module enables the LLM to capture a user's perception of a specific item through role-playing. The process consists of three steps. First, the LLM generates an objective description of the item. Next, based on the extracted long-term preference, the LLM simulates the user writing a review of the item. Finally, key terms are extracted from the review to summarize the user's subjective impression.
By adopting a role-playing approach, the LLM generates differentiated perception information based on varying user preferences, thereby capturing the diversity in individual understandings of the same item.
Notably, both objective descriptions and subjective perceptions can be utilized.

\subsubsection{Scalability}
All operations in the personalized information extraction stage are performed offline, ensuring no impact on inference efficiency during the service phase.

\subsection{Personalized Information Utilization}
Figure \ref{fig:9cn6} shows the model architecture of the personalized information utilization stage in CoT-Rec.

\subsubsection{Architecture}
The retrieval stage demands very high throughput. However, LLMs’ inference speed is several orders of magnitude lower than that of CRMs. As a result, employing LLMs as retrieval models is computationally prohibitive and fails to meet the requirements of large-scale users. Therefore, we argue that CRMs are more suitable for the retrieval stage. While LLMs also face computational efficiency challenges in ranking tasks, studies suggest that ranking can be deployed on the client side~\cite{liu2024filtering}. Since ranking involves only reordering the candidate set retrieved by the server rather than processing the entire item corpus, the LLM-as-Ranker approach could be executed on the client side, mitigating its impact on server-side inference efficiency.

In summary, we adopt CRM-as-Retriever and LLM-as-Ranker, to generate the final recommendation list. In this framework, CRM-as-Retriever serves as the retrieval model, which recalls a candidate set from the complete item set. Meanwhile, LLM-as-Ranker ranks the retrieved candidates to produce the final recommendations. Our approach is model-agnostic. In this paper, we introduce it using SASRec as the CRM and LlamaRec as the LLM.

\subsubsection{CRM-as-Retriever}
We define the \textit{Encode \& Map} operation as $T: \text{string} \rightarrow \mathbb{R}^{d_\text{LM}} \rightarrow \mathbb{R}^{d_\text{CRM}}$. Specifically, a language model (LM) first encodes the text into an embedding of dimension $d_\text{LM}$, which is then mapped into the CRM embedding space of dimension $d_\text{CRM}$ via a dimensionality reduction technique.

Previous research suggests that initializing the embedding layer of SASRec with item captions processed through the Encode \& Map operation can improve recommendation accuracy. However, this approach has two main limitations: (1) item captions provide limited information; and (2) SASRec relies exclusively on item sequences, omitting user information.

To address these limitations, we enhance SASRec by prepending the user ID to the item interaction sequence, explicitly linking it to a specific user. We further apply the Encode \& Map operation to user preferences, using the resulting embeddings to initialize user representations. Similarly, we process both item captions and descriptions through the Encode \& Map operation to initialize item embeddings. This approach ensures that CRM inputs incorporate user preferences and item descriptions---two essential intermediate results in the CoT process.

\subsubsection{LLM-as-Ranker}
Building on LlamaRec, we integrate user preferences and users' perceptions of candidate items, obtained during the personalized information extraction phase, into the prompt. Additionally, we construct an instruction-tuning dataset incorporating personalized information and leverage LoRA~\cite{hu2021lora} to fine-tune the LLM for ranking tasks.

\subsubsection{Scalability}
In the retrieval stage, the improved CRM differs from the original only by incorporating an additional user embedding as input. Consequently, the optimization in CRM-as-Retriever has minimal impact on inference efficiency. Furthermore, LLM-as-Ranker is deployed on the user side, ensuring that its inference process imposes no additional computational burden on the server.

\section{Experiments}
In this section, we empirically evaluate whether CoT-Rec improves the performance of CRM-as-Retriever and LLM-as-Ranker. We do not compare it with other LLM-powered recommendation methods, as our focus is on exploring how CoT-Rec can effectively integrate with existing methods to achieve greater performance gains, rather than conducting a comprehensive comparison of different recommendation architectures. In fact, many architectures can leverage CoT-Rec to enhance their performance.

\subsection{Settings}

\subsubsection{Datasets}
We conducted experiments on three datasets from distinct domains: Amazon Review (Food)~\cite{hou2024bridging} (e-commerce), MIND~\cite{wu2020mind} (news), and Yelp (reviews). For each dataset, we retained users and items with at least five interactions and ordered them chronologically.

\subsubsection{Evaluation}
For CRM-as-Retriever, the task is to retrieve the correct item from the entire set. We evaluate CRM-as-Retriever using the leave-one-out method, which is widely adopted for assessing sequential recommendation methods. The accuracy of the retrieval stage is measured using Hit@K and NDCG@K.
For LLM-as-Ranker, the task is to rank the candidate set retrieved in the previous stage. We evaluate the accuracy and position bias of the ranking stage using NDCG@K and MAPB. Position bias refers to the effect where the LLM’s output is influenced by the target item's position within the candidate set. We fix $K=10$ and report the average over five independent runs.

\textbf{Mean Absolute Position Bias (MAPB).} We propose Mean Absolute Position Bias (MAPB) to quantify the position bias in LLMs. Assuming the candidate set size is $M$, the sample bias is defined as: $\text{Sample Bias}_i = \frac{1}{M} \sum_{j=1}^M |r_{i,j} - \bar{r}_i|\text{,}$
where $r_{i,j}$ is the predicted rank of the target item when placed in position $j$, and $\bar{r}_i = \frac{1}{M} \sum_{j=1}^M r_{i,j}$ is the average predicted rank of the target item for sample $i$. Then, MAPB is defined as: $\text{MAPB} = \frac{1}{n} \sum_{i=1}^n \text{Sample Bias}_i\text{,}$
where $n$ is the number of the samples. MAPB measures the average absolute deviation of the target item's predicted rank from its mean rank across all possible positions and all samples. A lower MAPB indicates that the model is less sensitive to the target item's position, which suggests better robustness to position bias.

\subsubsection{Backbones}
We select SASRec~\cite{kang2018self} and BERT4Rec~\cite{sun2019bert4rec} as the CRM for the retrieval stage, and Qwen2.5-7B-Instruct as the LLM for the ranking stage. The hyperparameters can be found in the code repository. Due to space limitations, we only present the results of SASRec. The BERT4Rec results are available in the repository and lead to consistent conclusions.

\begin{table}[]\footnotesize
\caption{Results of CRM-as-Retriever.}
\label{tab:exp1}
\begin{tabular}{c|c|cc|cc|cc}
\hline
\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}User\\ Embedding\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Item\\ Embedding\end{tabular}}} & \multicolumn{2}{c|}{\textbf{MIND}} & \multicolumn{2}{c|}{\textbf{Food}} & \multicolumn{2}{c}{\textbf{Yelp}} \\ \cline{3-8} 
                                                                                   &                                                                                    & \textbf{Hit}    & \textbf{NDCG}    & \textbf{Hit}    & \textbf{NDCG}    & \textbf{Hit}    & \textbf{NDCG}   \\ \hline
\multirow{3}{*}{None}                                                              & Random                                                                             & 0.1387          & 0.0737           & 0.0182          & 0.0096           & 0.0297          & 0.0148          \\
                                                                                   & Caption                                                                            & 0.1447          & 0.0776           & 0.0263          & 0.0141           & 0.0306          & 0.0153          \\
                                                                                   & Description                                                                            & 0.1498          & 0.0807           & 0.0281          & 0.0150           & 0.0313          & 0.0155          \\ \hline
\multirow{2}{*}{Random}                                                            & Caption                                                                            & 0.1382          & 0.0740           & 0.0275          & 0.0148           & 0.0305          & 0.0153          \\
                                                                                   & Description                                                                            & 0.1396          & 0.0747           & 0.0284          & 0.0155           & 0.0313          & 0.0157          \\ \hline
\multirow{2}{*}{Preference}                                                        & Caption                                                                            & 0.1539          & 0.0831           & 0.0291          & 0.0156           & 0.0346          & 0.0170          \\
                                                                                   & Description                                                                            & 0.1551          & 0.0836           & 0.0295          & 0.0158           & 0.0348          & 0.0171          \\ \hline
\end{tabular}
\end{table}

\subsection{Results}

\subsubsection{CRM-as-Retriever}
Table \ref{tab:exp1} presents the performance of CRM-as-Retriever under different enhancement methods. When User Embedding is set to ``None'', it means no user embedding is used; ``Random'' indicates random initialization, while ``Preference'' refers to initialization using the Encode \& Map operation based on user preferences. Item embeddings are initialized using one of the following methods: ``Random'' (random initialization), ``Caption'' (initialized via Encode \& Map using item captions), and ``Description'' (initialized via Encode \& Map using both item captions and descriptions). 

When User Embedding is set to ``None'', item embedding performance follows the order: ``Description > Caption > Random''. This indicates that incorporating item information improves CRM performance, and descriptions provide richer information than captions. However, when User Embedding is set to ``Random'', performance does not always surpass that of ``None''. This suggests that introducing user embedding does not necessarily enhance performance, which aligns with SASRec’s conclusion that additional user embedding does not improve performance~\cite{kang2018self}. However, when User Embedding is set to ``Preference'', performance consistently surpasses that of ``None'', demonstrating that user preference-based embedding initialization improves model effectiveness.

\subsubsection{LLM-as-Ranker}
Table \ref{tab:exp2} presents the effectiveness of different candidate set ranking methods.
Here, Retriever refers to the retrieval model used. ``CRM'' refers to the basic SASRec model (as in Table \ref{tab:exp1} with ``User Embedding=None'' and ``Item Embedding=Random''), while ``CRM++'' denotes its improved version (as in Table \ref{tab:exp1} with ``User Embedding=Preference'' and ``Item Embedding=Description'').
The Ranker denotes the ranking method. ``None'' indicates that no LLM-based ranking is applied, and the CRM retrieval results are used directly. ``LLM'' performs ranking without user preference and item perception. ``LLM+'' incorporates user preferences and objective item descriptions, while ``LLM++'' further integrates user preferences and subjective item perception of the candidate set.

The experimental results show that ranking with ``LLM'', ``LLM+'', and ``LLM++'' generally leads to a significant improvement in recommendation performance compared to no ranking (``Ranker=None''). The only exception occurs in the Yelp dataset, where ``Retriever=CRM'' and ``Ranker=LLM'' perform similarly to the no-ranking setting.
Additionally, while ``LLM++'' and ``LLM+'' offer only a slight improvement in accuracy over ``LLM'', they substantially reduce position bias. Furthermore, ``LLM++'' achieves greater positional bias reduction than ``LLM+'' by incorporating subjective perception rather than objective descriptions.
This may be because integrating user preferences and personalized perception helps the LLM focus on task-relevant information, thereby mitigating its inherent position bias in ranking.

\begin{table}[]\footnotesize
\caption{Results of LLM-as-Ranker.}
\label{tab:exp2}
\begin{tabular}{c|c|cc|cc|cc}
\hline
\multirow{2}{*}{\textbf{Retriever}} & \multirow{2}{*}{\textbf{Ranker}} & \multicolumn{2}{c|}{\textbf{MIND}} & \multicolumn{2}{c|}{\textbf{Food}} & \multicolumn{2}{c}{\textbf{Yelp}} \\ \cline{3-8} 
                                    &                                  & \textbf{NDCG}    & \textbf{MAPB}   & \textbf{NDCG}    & \textbf{MAPB}   & \textbf{NDCG}   & \textbf{MAPB}   \\ \hline
\multirow{4}{*}{CRM}             & None                                & 0.0737           & -               & 0.0096           & -               & 0.0148          & -               \\
                                    & LLM                              & 0.0763           & 0.9723          & 0.0112           & 0.9819          & 0.0148          & 1.4928          \\
                                    & LLM+                              & 0.0763           & 0.9059          & 0.0112           & 0.9196          & 0.0149          & 1.2465          \\
                                    & LLM++                            & 0.0765           & 0.8413          & 0.0113           & 0.8086          & 0.0151          & 1.1060          \\ \hline
\multirow{4}{*}{CRM++}           & None                                & 0.0836           & -               & 0.0158           & -               & 0.0171          & -               \\
                                    & LLM                              & 0.0837           & 1.0336          & 0.0176           & 1.0664          & 0.0172          & 1.3716          \\
                                    & LLM+                              & 0.0838           & 0.9185          & 0.0176           & 0.8765          & 0.0172          & 1.2384          \\
                                    & LLM++                            & 0.0840           & 0.8168          & 0.0177           & 0.7641          & 0.0174          & 1.1964          \\ \hline
\end{tabular}
\end{table}

\section{Conclusions}
We propose CoT-Rec, which enhances LLM-powered recommendations via two key CoT processes: user preference analysis and item perception analysis. Experimental results effectively validate our approach. Inference efficiency analysis shows that CoT-Rec introduces negligible overhead, suggesting its potential for industrial applications. Expanding CoT-Rec to other backbones is a promising avenue for future research.

\begin{acks}
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{main}

\appendix

\end{document}
