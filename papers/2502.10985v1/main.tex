%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables
\usepackage{enumitem}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
\usepackage{natbib}

\usepackage{fullpage}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\def\shownotes{1}  %set 1 to show author notes
\ifnum\shownotes=1
\newcommand{\authnote}[2]{{\scriptsize $\ll$\textsf{#1 notes: #2}$\gg$}}
\else
\newcommand{\authnote}[2]{}
\fi
\newcommand{\yw}[1]{{\color{red}\authnote{YW}{#1}}}
\newcommand{\shange}[1]{{\color{red}\authnote{shange}{#1}}}
\newcommand{\chij}[1]{{\color{red}\authnote{Chi}{#1}}}






% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}
\input{package}
% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% \theoremstyle{plain}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

\newcommand{\chijin}[1]{{\color{magenta}Chi: {#1}}}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}



\title{Is Elo Rating Reliable? A Study Under Model Misspecification}
\author{Shange Tang\thanks{Department of ORFE, Princeton University; shangetang@princeton.edu}
\qquad Yuanhao Wang\thanks{Department of ECE, Princeton University} 
\qquad Chi Jin\footnotemark[2]}

\begin{document}

\maketitle{}



\begin{abstract}
% Elo rating, commonly viewed as an incremental update algorithm for estimating a stationary Bradley-Terry (BT) model in pairwise comparisons, is widely used to assess player skill in domains ranging from board games to esports, and even large language models. However, whether the real-world game follows a stationary BT model is questionable, casting doubt on Elo’s reliability. In this paper, we examine Elo’s reliability under model misspecification. Through likelihood ratio tests, we show that many real-world game datasets do not follow the BT model, revealing widespread model misspecification when applying Elo. Further more, the matchmaking scheme and player skills are non-stationary in real world games. Despite this, our real data experiments show that in some non-BT and non-stationary datasets, Elo outperforms other methods like mElo and pairwise win rate in predicting game outcomes. We explain this phenomenon through a regret minimization framework. Specifically, Elo, as an instance of online gradient descent, can provably achieve a relatively low regret, which contributes to its strong predictive performance even in some non-BT and non-stationary datasets. We validate this through synthetic experiments, showing that data sparsity plays a key role: Elo performs well in sparse datasets, while more complex models with greater model capacity show benefits in dense datasets. Finally, regarding the ranking performance, we find a strong correlation between Elo’s predictive accuracy and ranking performance, though Elo does not always produce correct rankings.

Elo rating, widely used for skill assessment across diverse domains ranging from competitive games to large language models, is often understood as an incremental update algorithm for estimating a stationary Bradley-Terry (BT) model. However, our empirical analysis of practical matching datasets reveals two surprising findings: (1) Most games deviate significantly from the assumptions of the BT model and stationarity, raising questions on the reliability of Elo. (2) Despite these deviations, Elo frequently outperforms more complex rating systems, such as mElo and pairwise models, which are specifically designed to account for non-BT components in the data, particularly in terms of win rate prediction. This paper explains this unexpected phenomenon through three key perspectives: (a) We reinterpret Elo as an instance of online gradient descent, which provides no-regret guarantees even in misspecified and non-stationary settings. (b) Through extensive synthetic experiments on data generated from transitive but non-BT models, such as strongly or weakly stochastic transitive models, we show that the ``sparsity'' of practical matching data is a critical factor behind Elo’s superior performance in prediction compared to more complex rating systems. (c) We observe a strong correlation between Elo's predictive accuracy and its ranking performance, further supporting its effectiveness in ranking.


% Elo rating, widely used for skill assessment in various domains ranging from various games to even large language models, is often interpreted as an incremental update algorithm for estimating a stationary Bradley-Terry (BT) model. However, our statistical tests show that many real-world games deviate from the stationary BT distribution, raising questions about Elo’s reliability. Despite the existence of model misspecification, Elo often outperforms alternatives like mElo and pairwise win rate in predicting outcomes for non-BT, non-stationary datasets. We explain this phenomenon through a regret minimization framework. Specifically, Elo, as an instance of online gradient descent, can provably achieve a relatively low regret, which contributes to its strong predictive performance even in some non-BT and non-stationary datasets. We validate this through synthetic experiments, showing that data sparsity plays a key role: Elo performs well in sparse datasets, while more complex models with greater model capacity show benefits in dense datasets. Finally, regarding the ranking performance, we find a strong correlation between Elo’s predictive accuracy and ranking performance, 



% Elo rating, widely used for skill assessment in various domains ranging from board games to esports, and even large language models, is often interpreted as an incremental update algorithm for estimating a stationary Bradley-Terry (BT) model. However, our statistical tests show that many real-world games deviate from the stationary BT distribution, raising questions about Elo’s reliability. Despite the existence of model misspecification, Elo often outperforms alternatives like mElo and pairwise win rate in predicting outcomes for non-BT, non-stationary datasets. We explain this phenomenon through a regret minimization framework. Specifically, Elo, as an instance of online gradient descent, can provably achieve a relatively low regret, which contributes to its strong predictive performance even in some non-BT and non-stationary datasets. We validate this through synthetic experiments, showing that data sparsity plays a key role: Elo performs well in sparse datasets, while more complex models with greater model capacity show benefits in dense datasets. Finally, regarding the ranking performance, we find a strong correlation between Elo’s predictive accuracy and ranking performance, though Elo does not always produce correct rankings.



\end{abstract}

\input{intro}
\input{prelim}
\input{hypothesis}
\input{realdata}
\input{OCO}

% \input{synthetic}
% \input{linearelo}
\input{ranking}

\input{conclusion}











\section*{Impact Statement}

This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.

% Authors are \textbf{required} to include a statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered 
% section at the end of the paper (co-located with Acknowledgements -- 
% the two may appear in either order, but both must be before References), 
% and does not count toward the paper page limit. In many cases, where 
% the ethical impacts and expected societal implications are those that 
% are well established when advancing the field of Machine Learning, 
% substantial discussion is not required, and a simple statement such 
% as the following will suffice:

% ``This paper presents work whose goal is to advance the field of 
% Machine Learning. There are many potential societal consequences 
% of our work, none which we feel must be specifically highlighted here.''

% The above statement can be used verbatim in such cases, but we 
% encourage authors to think about whether there is content which does 
% warrant further discussion, as this statement will be apparent if the 
% paper is later flagged for ethics review.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}

\bibliography{ref}

% \bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\input{appendix-dataset}
\input{appendix-stukel}
\input{appendix-matchmaking}
\input{appendix-algorithm}
\input{appendix-realdata}
\input{appendix-synthetic}
% \input{appendix-additional}
\input{appendix-proof}


% \section{You \emph{can} have an appendix here.}

% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

% The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
