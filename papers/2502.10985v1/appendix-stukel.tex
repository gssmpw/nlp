\section{Details of the Likelihood Ratio Test}
\label{sec:lr-test}
We explain in this section the details of our likelihood ratio tests.




\subsection{Methods}
%\paragraph{Traning-test split} 
\paragraph{Symmetrization} Before performing the tests, we reversed the order of the two players (and flipped the game outcome) for every game with probability $0.5$ to eliminate first-move advantage (or disadvantage), which is well-documented~\citep{elo1978rating} and not the focus of this work. In other words, we actually test the following weaker version of Bradley-Terry model:
\[
\frac{1}{2}\left(\E\left[o_t|i_t,j_t\right]+ \E\left[1-o_t|j_t,i_t\right]\right) = \sigma\left(\theta^\star[i_t] -\theta^\star[j_t]\right).
\]
\paragraph{Feature augmentation} We split every dataset (indexed by $[T]$) randomly into equally sized $\cT_{\rm train}$ and $\cT_{\rm test}$. For all datasets except \texttt{llm arena}, we then fit a regularized logistic regression model via
\[
\theta_{\rm train}\gets \argmin_\theta \sum_{t\in \cT_{train}}\ell_t(\theta) + \frac{\lambda}{2}\Vert\theta\Vert^2,
\]
where we chose $\lambda=10.0$. Then the augmented features for match $t$ is given by
\[
g_t:=[\theta_{\rm train}[i_t], \theta_{\rm train}[j_t]].
\]
For \texttt{llm arena}, \texttt{Hearthstone}, \texttt{AlphaStar} and \texttt{Blotto}, the aforementioned feature failed to reject the null. Since those datasets are relatively dense, we designed a different feature inspired by~\citep{bertrand2023limitations}. We considered the loss
\begin{align*}
\hat\cL\left(u, v\right):=\sum_{t\in\cT_{\rm train}} \left[-o_t\log(\sigma(\hat p)) - (1-o_t)\log(1-\sigma(\hat p))\right],
\end{align*}
where $\hat p:=u[i_t]v_[j_t]-u[j_t]v[i_t]$. The loss is optimized with gradient descent with early stopping. We then define
\[
g_t:=[u[i_t]v[j_t], u[j_t]v[i_t]]
\]
as the augmented feature for game $t$. This method does not apply to other datasets as it requires a dense dataset for the learning of $u$ and $v$.

\iffalse
\paragraph{Regularization}
Recall that the log likelihood ratio statistic is 
\begin{equation*}
\Lambda := 2\left[\min_{\theta\in\R^N}\cL_{\rm test}(\theta) - \min_{\theta\in\R^{N},\alpha\in\R^2}\tilde\cL_{\rm test}([\theta;\alpha])\right].
\end{equation*}
For the ease of optimization, we instead optimize the regularized loss function to obtain a \emph{lower bound} of this statistic. In particular, we compute
\[
\theta_\lambda \gets \argmin_{\theta\in\R^N}\cL_{\rm test}(\theta)+\frac{\lambda}{2}\Vert \theta\Vert^2
\]
and 
\[
\tilde\theta_\lambda, \alpha_\lambda \gets \argmin_{\theta\in\R^{N},\alpha\in\R^2}\tilde\cL_{\rm test}([\theta;\alpha])+\frac{\lambda}{2}\Vert [\theta;\alpha]\Vert^2.
\]
Then
\begin{align*}
\cL_{\rm test}(\theta_\lambda) - \left(\Tilde{\cL}_{\rm test}([\tilde\theta;\alpha])+\frac{\lambda}{2}\Vert [\tilde\theta_\lambda,\alpha_\lambda]\Vert^2\right) \le \cL
\end{align*}

\fi


\subsection{Implementation}
All logistic regressions are implemented with JAX and optimized via L-BFGS.

\subsection{An additional martingale test}
Although the previous test used randomly sampled $\cT_{\rm train}$, it still needs to assume that the features $\{x_t\}_{t\in \cT_{\rm train}}$ are independent with   $\{y_t\}_{t\in \cT_{\rm test}}$. However, there is a concern that this may not be true if adaptive matchmaking is used -- in that case, information about the test set labels $\{y_t\}_{t\in \cT_{\rm test}}$ may be leaked through features of future games. \footnote{Regarding \texttt{AlphaStar}, \texttt{5,4-Blotto} and \texttt{10,5-Blotto}, recall that we construct the dataset according to a payoff matrix, therefore no adaptive matchmaking is used. We do not need to further test these datasets.}

To address this concern, we consider yet another method to construct $g_t$: by using the online Elo rating up until this point. This enables us to relax the assumption of independence to the assumption that the noise sequence
\[
\E[o_t|i_t,j_t] - \sigma(\theta^\star[i_t]-\theta^\star[j_t])
\]
is a martingale. This would enable us to model adaptive matchmaking.
%through the martingale property as $g_t$ is a deterministic function of \emph{past} games. 

Specifically, define
\[
g_t = [\theta_{t}[i_t], \theta_{t}[j_t]],
\]
where $\theta$ is computed using the past $t-1$ matches with learning rate $\eta$. We can then proceed to compute the likelihood ratio statistic $\Lambda$ as in the previous tests. The distribution of $\Lambda$ would still be asymptotically $\chi_2^2$ for martingale noise (see e.g. \citet[Theorem 1.5.1]{kedem2005regression})

We report the test results in Table~\ref{tab:hypotheis-martingale}. We find that by using two learning rates ($\eta=0.01$ and $0.08$), we can reject the null hypothesis that BT is realizable with extremely high confidence without assuming independence. 

\begin{table}[t]
\centering
\addtocounter{footnote}{+1}  
\begin{tabular}{|l|c|c||c|c|}
\hline
Dataset              & LR Test Statistic ($\eta=0.01$) & $p$-value   & LR Test Statistic ($\eta=0.08$) & $p$-value         \\ \hline
\texttt{Renju}       & 3.66                            & 0.23        & 226.92                          & $<10^{-10}$       \\
% \texttt{llm arena}   & 126.22                          & $<10^{-10}$ & 202.39                          & $<10^{-10}$            \\

% \texttt{chess-small} & 76.74                           & $<10^{-10}$        & 8.37                            & 0.04              \\
\texttt{Chess}       & 6622.52                         & $<10^{-10}$       & 27908.30                        & $<10^{-10}$       \\
\texttt{Tennis}      & 524.77                          & $<10^{-10}$       & 3571.70                         & $<10^{-10}$ \\
\texttt{Scrabble}    & 174.52                          & $<10^{-10}$       & 3058.76                         & $<10^{-10}$       \\
\texttt{StarCraft}   & 5.19                            & 0.12        & 261.08                          &$<10^{-10}$      \\
\texttt{Go}          & 52931.15                        & $<10^{-10}$        & 117318.3                        & $<10^{-10}$                \\
\texttt{LLM Arena}   & 872.28                          & $<10^{-10}$ & 819.05                          & $<10^{-10}$            \\

\texttt{Hearthstone}          & 69433.52                      & $<10^{-10}$        & 82005.34                             & $<10^{-10}$                \\
% \texttt{mixedchess-dense}          & 192591.30                     & $<10^{-10}$        &  409121.56                 & $<10^{-10}$                \\
\hline
\end{tabular}
\caption{Summary of martingale-based Likelihood ratio test}
\label{tab:hypotheis-martingale}
\end{table}

