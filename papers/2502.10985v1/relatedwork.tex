\section{Related work}
\paragraph{Methods for rating game players} A large number of rating methods used in practice can be viewed as variants of Elo, most notably Glicko~\citep{glickman1995glicko}, Glicko2~\citep{glickman2012example} and TrueSkill~\citep{herbrich2006trueskill}. A common characteristic shared by these methods is that they assume a scalar rating for players with parametric probabilistic model (Bradley-Terry in Glicko and Thurstone in TrueSkill) and make incremental gradient-like updates for each game or a small batch of games. 
% The focus of this work is on the vanilla Elo score, but the findings of this work could be relevant to other incremental-updates methods as well.
%They differ from gra-like methods by assuming a prior of  the Maximum a Posteriori (MAP) estimation. They differ from gradient-like incremental updates by being more 
mElo~\citep{balduzzi2018re} and Disk Decomposition~\citep{bertrand2023limitations} generalize Elo score by rating every player with a multi-dimensional vector instead of a scalar. Their approach can be understood as low-rank approximation of the logits of the winning probabilities. In our work we regard them as Elo2k, and examine their performance is a central part of our work.


Bayeselo~\citep{bayeselo} and WHR~\citep{coulom2008whole} are two popular Bayesian methods that are also based on the BT model. They differ from Elo-like incremental updates by requiring more compute to produce a maximum a posteriori estimator every step. 

% Computing such low rank approximations can take considerable compute, especially compared to light-weight updates made in Elo rating.
%, making them more suitable to rank static game outcomes than computing online updates.
%considering probabilistic models where every player has a multi-dimensional feature.
%Their methods require solving computationally expensive optimization problems, making them unsuitable for rating players in an online fashion.
%A different style of rating methods store and utilize 
%\yw{Elo, Glicko, TrueSkill, NashAverage, mElo, DD}

%There are also methods of evaluating the performance or skill of players that do not fit inside this framework. The Nash averaging~\citep{balduzzi2018re}
%There are also methods that do not rely on parametric models of winning probabilities.

\paragraph{Analysis of Elo score} Despite its popularity and wide applicability, the analysis of Elo score is ``curiously absent''~\citep{aldous2017elo}.
Elo discussed practical concerns and small-scale statistical validations of the method in~\citet{elo1978rating}. Most related to this work, however, is the proposal of the linear approximation of the update formula.
~\citet{aldous2017elo} proved the existence and uniqueness of a stationary distribution under the Elo update rules without assuming realizability. However, the nature of this stationary distribution is not explored.
~\citet{de2024stochastic} analyzed the convergence of Elo score assuming round-robin match making, realizability of the Bradley-Terry model and linearization of $\sigma$.
For more empirical and simulation results, see~\citet{kiraly2017modelling} and references within.
%Previous texts providing statistical analysis on Elo score include~\citet{elo1978rating},~\citet{aldous2017elo},~\citet{kiraly2017modelling}.


\paragraph{Misspecification of Bradley-Terry model} The Bradley-Terry model and similar parametric probabilistic preference models have been criticized for being inaccurate models of human preferences~\citep{ballinger1997decisions}.~\citet{oliveira2018new} show that for matches between $\sim$200 computer chess programs, Bradley-Terry model does not provide a good fit.~\citet{bertrand2023limitations} showed that by generalizing Bradley-Terry model to a $k$-dimensional model, the prediction performance on holdout test sets can be improved for synthetic datasets from~\citet{czarnecki2020real}, indicating misspecification of the original Bradley-Terry model. However, their synthetic datasets are simply payoff matrices between each player,
which differ significantly from real game datasets, where outcomes are typically binary (0-1) and largely sparse. Moreover, these works do not conduct statistical tests to assess model validity, particularly on large-scale real-world datasets of human gameplay.
% , where Elo is widely used.


% However, their synthetic datasets are payoff matrices between each player, which is very different from real game datasets that are usually 0-1 and most of the entries are missing. Also, no statistical test of the model is performed in these works, especially for larger-scale real-world datasets of human game play, on which the Elo score is routinely applied.

The Bradley-Terry model also implies the games being \emph{transitive}. However, the existence of cyclic or non-transitive behavior has been long observed in game theory literature~\citep{samothrakis2012coevolving,chen2016modeling,omidshafiei2019alpha,czarnecki2020real}. Although rejecting even weak notions of transitivity would automatically reject the BT model, doing so with hypothesis testing can be difficult for most real-world datasets where the majority of player pairs never played with each other.

\paragraph{Learning to rank}
%\yw{should we mention them, given we don't compare to those algorithms at all?}
There has been a long line of work studying various flavors of learning-to-rank (for instance, see~\citet{liu2009learning, negahban2012iterative, braverman2009sorting, shah2018simple} and references within), where the focus is to construct a global ranking based on a dataset partial observations. 
While highly relevant to task of rating game players, we note that these methods generally receive less attention in game-related applications. These methods are typically not able to predict win-loss probability of a particular matchup either.
%We believe this is in part due to the fact that games are not played to just elicit a ranking -- 
For these reasons, we focus on understanding Elo and the rating systems within the family of Elo in the scope of this work. We left the connection and comparison to other learning-to-rank methods as important future directions.