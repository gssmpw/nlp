\section{Preliminary}
\label{sec:prelim}
We consider the scenario where $N$ players play against each other in a sequential manner. Specifically, for every $t\in [T]$, players $i_t\in [N]$ and $j_t\in [N]$ are chosen by the matchmaking scheme to play against each other at time $t$. The outcome $o_t\in [0,1]$ denotes the utility of player $i_t$, which can be chosen as $1$, $1/2$ and $0$ to denote a victory, a draw and a loss respectively; Player $j_t$ receives utility $1-o_t$.

There are two main tasks in this setting. The first task is \textbf{prediction}, i.e., predicting the outcomes of the game. At time $t$, the learner is tasked to gives a prediction $p_t$ for the player $i_t$'s win rate against $j_t$, after observing the previous games $\{(i_k,j_k,o_k)\}_{k=1}^{t-1}$ and the two players at the current round $(i_t,j_t)$. It is natural to evaluate the prediction accuracy of the algorithms by binary cross entropy loss
\begin{equation}
    \ell_t := -(o_t \ln p_t + (1-o_t) \ln (1-p_t)).
\end{equation}
The accumulated loss until time $t$ is $\mathcal{L}_t:= \sum_{i=1}^{t}\ell_i$.

The second task is \textbf{ranking}, i.e., give a total order or pairwise order for all players according to their relative strength. A total order ranking is well-defined only if the underlying game has a transitive structure. For simplicity of discussion, this paper will mostly focus on prediction, and leave the discussion of ranking to Section \ref{sec:ranking}.

% For any online algorithm, it gives a prediction $p_t$ for the player $i_t$'s win rate against $j_t$, after observing the previous games $\{(i_k,j_k,o_k)\}_{k=1}^{t-1}$ and the two players at the current round $(i_t,j_t)$. It is natural to evaluate the prediction accuracy of the algorithms by binary cross entropy loss
% \begin{equation}
%     \ell_t := -(o_t \ln p_t + (1-o_t) \ln (1-p_t)).
% \end{equation}
% The accumulated loss until time $t$ will be
% \begin{equation}
%     \mathcal{L}_t:= \sum_{i=1}^{t}\ell_i.
% \end{equation}


\subsection{Algorithms}
% In this paper, we will investigate the performance of the following algorithms: Elo, Glicko, TrueSkill, Elo2k and Pairwise. 

% In this paper, we will investigate the performance of two types of online rating algorithms. The first type is "Elo-like" algorithms, where the strength of a player is explicitly indicated by a one-dimensional parameter; the second type of algorithms rely on much more complex models. 

Here, we introduce several important and representative online rating algorithms.

\paragraph{Elo rating:} Elo maintains a \emph{scalar} rating (which is also refered as \emph{score}) for each player. Concretely, let $\theta_t\in\R^N$ denote the ratings of all players at time $t$, then Elo scores can be computed using updates:
\begin{equation}
\label{eq:elo}
    \begin{cases}
         p_t &\gets \sigma\left(\theta_t[i_t] - \theta_t[j_t]\right),\\
    \theta_{t+1}[i_t] &\gets \theta_{t}[i_t] + \eta_t \left(o_t - p_t\right),\\
    \theta_{t+1}[j_t] &\gets \theta_{t}[j_t] - \eta_t \left(o_t - p_t\right).
    \end{cases}
\end{equation}
Here $\sigma = 1/(1+e^{-x})$ is the logistic function. Elo is often understood under the assumption that the outcome of the game is sampled from the Bradley-Terry (BT) model:
\begin{equation}
\label{eq:bt}
    \mathbb{P}[o_t=1|i_t,j_t] = \sigma(\theta^\star[i_t]-\theta^\star[j_t]) \tag{Bradley-Terry}.
\end{equation}
where $\theta^\star[i]$ represents the \emph{true score} of player $i$. In this case, Elo update is simply an incremental update algorithm for estimating the parameters $\theta^\star$ of the BT model.

% interpreted as an incremental update algorithm for estimating parameters of the underlying Bradley-Terry (BT) model for pairwise comparison. The BT model assumes that each player $i$ has a score $\theta^*[i]$, and the expectation of the game outcome will be 
% \begin{equation}
% \label{eq:bt}
%     \E[o_t|i_t,j_t] = \sigma(\theta^\star[i_t]-\theta^\star[j_t]) \tag{Bradley-Terry}.
% \end{equation}

\paragraph{Glicko, TrueSkill --- ``Elo-like" rating:} The second class of rating systems we examine consists of Glicko \citep{glickman1995glicko} and TrueSkill \citep{dangauthier2007trueskill}. Similar to Elo, they assume total ordering among players, and mainly use a scalar rating to represent the relative strength of each player. Different from Elo, Glicko additionally introduces a ``rating deviation'' parameter for each player which measures the uncertainty in the rating. Trueskill is similar to Glicko, but instead assuming the outcomes are sampled from a different probabilistic model, which changes the $\sigma$ function in BT models from logistic function to the cumulative distribution function of Gaussian, up to proper renormalization.



% \paragraph{``Elo-like" algorithms: Elo, Glicko, TrueSkill} In these algorithms, the strength of a player is explicitly
% indicated by a one-dimensional parameter:
% \vspace{-10pt}
% \begin{itemize}[leftmargin=10pt]
%     \item \textbf{Elo} Elo rating is obtained by the following update rule:
% \begin{equation}
% \label{eq:elo}
%     \begin{cases}
%          p_t &\gets \sigma\left(\theta_t[i_t] - \theta_t[j_t]\right),\\
%     \theta_{t+1}[i_t] &\gets \theta_{t}[i_t] + \eta_t \left(o_t - p_t\right),\\
%     \theta_{t+1}[j_t] &\gets \theta_{t}[j_t] - \eta_t \left(o_t - p_t\right).
%     \end{cases}
% \end{equation}
% Here $\sigma = 1/(1+e^{-x})$ is the logistic function. $\theta_t\in\R^N$ is the \emph{rating}, or \emph{score}, for the $N$ players at time $t$. 
% % Customarily, the reported rating is multiplied by a constant $C = \frac{400}{\ln 10}$. The learning rate $\eta_t$ is often chosen to be a fixed value $\eta$ between $10/C\approx 0.06$ and $40/C\approx 0.23$. 
% Elo is often interpreted as an incremental update algorithm for estimating parameters of the underlying Bradley-Terry (BT) model for pairwise comparison. The BT model assumes that each player $i$ has a score $\theta^*[i]$, and the expectation of the game outcome will be 

% \begin{equation}
% \label{eq:bt}
%     \E[o_t|i_t,j_t] = \sigma(\theta^\star[i_t]-\theta^\star[j_t]) \tag{Bradley-Terry}.
% \end{equation}

% We will show in Section \ref{sec:OCO} that by choosing certain cost function, Elo update can be understand as online gradient descent.
% \item \textbf{Glicko} Glicko is a variant of Elo, computing not only a rating, but also a “ratings deviation” (RD) that measures the uncertainty in a rating. 
% \item \textbf{TrueSkill} TrueSkill is a variant of Glicko, which change the logistic function to Gaussian function.
% \end{itemize}

\paragraph{Elo2k, Pairwise --- more complexity rating systems:} These systems are much more flexible than Elo, Glicko, TrueSkill---they no longer assume the total order among players, and are able to model cyclic structure among players (i.e., player A beats player B, player B beats player C, and player C beats player A). In particular, Elo2k generalizes Elo by assign each player with a vector rating of dimension $k$, instead of a scalar rating. It is also known as mElo  \citep{balduzzi2018re} or Disk Decomposition \citep{bertrand2023limitations}. This algorithm has $Nk$ parameters. \textbf{Pairwise} simply computes the pairwise win rate for each pair of players up to time $t-1$, and use this win rate as the prediction for round $t$. This algorithm has $N(N-1)/2$ parameters, and is the most expressive rating system.

For detailed prediction rule and update rule of the aforementioned algorithms, see Appendix \ref{sec:appendix-algorithm}. In this paper, we consider Elo, Glicko, Trueskill to be similar algorithms as they achieve qualitative similar results across almost all experiments we ran, despite the actual numbers being slightly different. We mainly compare Elo against more complex algorithms such as Elo2k and Pairwise. This is because the focus of this paper is on model misspecification. As we observe in a majority of our experiments, more complex algorithms have a clear advantage in reducing the model misspecification errors.


% \paragraph{``Complex" algorithms: Elo2k and Pairwise} These algorithms are based on complex models, and have much more parameters than $N$:
% \vspace{-10pt}
% \begin{itemize}[leftmargin=10pt]
% \item \textbf{Elo2k} Elo2k generalizes Elo score by rating every player with a vector instead of scalar, also known as mElo  \citep{balduzzi2018re} or Disk Decompositoin \citep{bertrand2023limitations}. This algorithm has $Nk$ parameters.

% \item \textbf{Pairwise} Pairwise computes the pairwise win rate for each pair of players up to time $t-1$, and use this win rate as the prediction for round $t$. This algorithm has $N(N-1)/2$ parameters.
% \end{itemize}




%%%%%%%%%%%%%%%%%%%%%%%%%%%old version%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Preliminary}
% \label{sec:prelim}
% We consider the scenario where $N$ players play with each other in a sequential manner. Specifically, for every $t\in [T]$, players $i_t\in [N]$ and $j_t\in [N]$ are chosen by the matchmaking scheme to play against each other. The outcome $o_t\in [0,1]$ denotes the utility of player $i_t$, which can be chosen as $1$, $1/2$ and $0$ to denote a victory, a draw and a loss respectively; Player $j_t$ receives utility $1-o_t$.

% For any online algorithm, it gives a prediction $p_t$ for the player $i_t$'s win rate against $j_t$, after observing the previous games $\{(i_k,j_k,o_k)\}_{k=1}^{t-1}$ and the two players at the current round $(i_t,j_t)$. It is natural to evaluate the prediction accuracy of the algorithms by binary cross entropy loss
% \begin{equation}
%     \ell_t := -(o_t \ln p_t + (1-o_t) \ln (1-p_t)).
% \end{equation}
% The accumulated loss until time $t$ will be
% \begin{equation}
%     \mathcal{L}_t:= \sum_{i=1}^{t}\ell_i.
% \end{equation}


% \subsection{Algorithms}
% % In this paper, we will investigate the performance of the following algorithms: Elo, Glicko, TrueSkill, Elo2k and Pairwise. 

% In this paper, we will investigate the performance of two types of online rating algorithms. The first type is "Elo-like" algorithms, where the strength of a player is explicitly indicated by a one-dimensional parameter; the second type of algorithms rely on much more complex models. 

% \paragraph{``Elo-like" algorithms: Elo, Glicko, TrueSkill} In these algorithms, the strength of a player is explicitly
% indicated by a one-dimensional parameter:
% \vspace{-10pt}
% \begin{itemize}[leftmargin=10pt]
%     \item \textbf{Elo} Elo rating is obtained by the following update rule:
% \begin{equation}
% \label{eq:elo}
%     \begin{cases}
%          p_t &\gets \sigma\left(\theta_t[i_t] - \theta_t[j_t]\right),\\
%     \theta_{t+1}[i_t] &\gets \theta_{t}[i_t] + \eta_t \left(o_t - p_t\right),\\
%     \theta_{t+1}[j_t] &\gets \theta_{t}[j_t] - \eta_t \left(o_t - p_t\right).
%     \end{cases}
% \end{equation}
% Here $\sigma = 1/(1+e^{-x})$ is the logistic function. $\theta_t\in\R^N$ is the \emph{rating}, or \emph{score}, for the $N$ players at time $t$. 
% % Customarily, the reported rating is multiplied by a constant $C = \frac{400}{\ln 10}$. The learning rate $\eta_t$ is often chosen to be a fixed value $\eta$ between $10/C\approx 0.06$ and $40/C\approx 0.23$. 
% Elo is often interpreted as an incremental update algorithm for estimating parameters of the underlying Bradley-Terry (BT) model for pairwise comparison. The BT model assumes that each player $i$ has a score $\theta^*[i]$, and the expectation of the game outcome will be 

% \begin{equation}
% \label{eq:bt}
%     \E[o_t|i_t,j_t] = \sigma(\theta^\star[i_t]-\theta^\star[j_t]) \tag{Bradley-Terry}.
% \end{equation}

% We will show in Section \ref{sec:OCO} that by choosing certain cost function, Elo update can be understand as online gradient descent.
% \item \textbf{Glicko} Glicko is a variant of Elo, computing not only a rating, but also a “ratings deviation” (RD) that measures the uncertainty in a rating. 
% \item \textbf{TrueSkill} TrueSkill is a variant of Glicko, which change the logistic function to Gaussian function.
% \end{itemize}


% \paragraph{``Complex" algorithms: Elo2k and Pairwise} These algorithms are based on complex models, and have much more parameters than $N$:
% \vspace{-10pt}
% \begin{itemize}[leftmargin=10pt]
% \item \textbf{Elo2k} Elo2k generalizes Elo score by rating every player with a vector instead of scalar, also known as mElo  \citep{balduzzi2018re} or Disk Decompositoin \citep{bertrand2023limitations}. This algorithm has $Nk$ parameters.

% \item \textbf{Pairwise} Pairwise computes the pairwise win rate for each pair of players up to time $t-1$, and use this win rate as the prediction for round $t$. This algorithm has $N(N-1)/2$ parameters.
% \end{itemize}

% For detailed prediction rule and update rule of the aforementioned algorithms, see Appendix \ref{sec:appendix-algorithm}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% It is well-known that Elo rating can be written as online gradient descent on the logistic loss:
% \begin{align*}
% \ell_t(\theta):= &- o_t\log(\sigma(\theta[i_t]-\theta[j_t])) \\
% & - (1-o_t)\log(1-\sigma(\theta[i_t]-\theta[j_t])),
% \end{align*}
% since $\theta_{t+1} = \theta_t - \eta \nabla \ell_t(\theta_t)$. If $o_t$ is binary, $-\ell_t$ is the log-likelihood function for the Bradley-Terry model, which assumes that for some $\theta^\star \in \R^N$,
% \begin{equation}
% \label{eq:bt}
%     \E[o_t|i_t,j_t] = \sigma(\theta^\star[i_t]-\theta^\star[j_t]) \tag{Bradley-Terry}.
% \end{equation}
% Define the total logistic loss as $\cL(\theta):=\sum_{t\in[T]}\ell_t(\theta)$. 
% Then the Bradley-Terry MLE is
% %Under the Bradley-Terry model, the observed data $\cD=\{(i_t,j_t,o_t)\}_{t\in [T]}$ induces an offline maximum-likelihood estimator (MLE)
% \begin{equation*}
% \theta^{\rm mle} := \argmin_{\theta\in\R^N}\cL(\theta).
% \end{equation*}
% We also consider the $L_2$ regularized MLE
% \begin{equation*}
% \theta^{\rm mle}_\lambda := \argmin_{\theta\in\R^N}\cL(\theta) + \frac{\lambda}{2}\Vert \theta\Vert^2.
% \end{equation*}
% The curve $\{\theta^{\rm mle}_\lambda\}_{\lambda\ge 0}$ is called the regularization path. Given known connections between early-stopped gradient descent flow and the regularization path~\citep{suggala2018connecting}, it seems natural to conjecture that $\theta^{\rm mle}$ with learning rate $\eta$ is similar to $\theta^{\rm mle}_{1/\eta}$. Indeed, $\theta^{\rm mle}_{\lambda}$ is sometimes directly reported synonymously as the Elo score~\citep{bertrand2023limitations, zheng2023judging}. 

\iffalse
\subsection{Matchmaking schemes}
\yw{define these}

Independent matchmaking:

Rank-based matchmaking:
\fi



\subsection{Datasets}

We utilize human gameplay data from online platforms for Chess, Scrabble, StarCraft, Hearthstone, and Go, as well as professional match records for ATP tennis~\cite{tennis_atp} and Renju. Additionally, we incorporate human preference data from Chatbot Arena~\citep{zheng2023judging}, which can be alternatively viewed a game where LLM agents compete, with outcomes determined by human judgment. 

% Furthermore, we include Blotto and AlphaStar data from~\cite{czarnecki2020real}, where we generated game data based on the original payoff matrix. More details on the datasets are provided in Appendix~\ref{sec:appendix-dataset}.


%\yw{cite cite cite}
% We use human game play data for chess, scrabble, StarCraft, Hearthstone, Go from online platforms, records for ATP tennis %\cite{tennis_atp} 
% and renju between professional players,  and human preferences between LLM outputs in Chatbot Arena~\citep{zheng2023judging}. While the Chatbot Arena data can be regarded as a database of preferences, it can alternatively be understood as a game played by LLM agents where the game outcome is decided by humans. We also use Blotto and AlphaStar data from \cite{czarnecki2020real}, where we created game data from the original payoff matrix. More details about the datasets can be found in Appendix~\ref{sec:appendix-dataset}.

%We note that the Chatbot Arena dataset has $T\gg N^2$, while all other datasets are \emph{sparse} in the sense that $T\ll N^2$. Nevertheless, the average number of games, computed as $2T/N$, in other datasets are well above $30$, which is the heuristic number of games needed for Elo score to work. More details about the datasets can be found in Appendix~\ref{sec:lr-test}.

%We also generated synthetic data following WST or SST in Section \yw{todo}. For details, see