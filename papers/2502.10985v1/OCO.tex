% \section{\protect\resizebox{0.5\textwidth}{!}{Understand Elo under Misspecification}}
\section{Understand Elo under Misspecification}

The findings in Section \ref{sec:realdata} that the ``Elo-like" algorithms outperform more complexity rating systems in some non-BT datasets, underscore the importance of adopting a new perspective on Elo (and other online algorithms), moving beyond the traditional view that Elo is merely a parameter estimation tool for the BT model.

In this section, we will explain this unexpected phenomenon through three key perspectives. First, we view game rating through the lens of regret minimization in online optimization. Specifically, Elo can be reinterpreted as an instance of online gradient descent under convex loss, which provides no-regret guarantees even in misspecified and non-stationary settings. Second, further synthetic experiments on non-BT and non-stationary datasets show that the ``sparsity" of dataset is a critical factor in the performance of algorithms, driven by a trade-off between model misspecification error and regret. Finally regarding the ranking performance, we show that the pairwise ranking performance is strongly correlated with prediction performance, though Elo should not be blindly trusted since it can fail to produce consistent total orderings even in transitive datasets.

\subsection{New lens via regret minimization}
\label{sec:OCO}



% In this section, we view game rating through the lens of regret minimization in online optimization. We analyze and interpret the prediction performance of Elo and other rating algorithms, such as Glicko and Elo2k, on both real and synthetic datasets from this perspective. To be specific, we show that Elo can be interpreted as online gradient descent, which is guaranteed to have small regret. Thus Elo can provably achieve low regret, which explains its strong predictive performance in non-BT datasets. 


% Our findings further indicate that the effectiveness of these algorithms is shaped by the interaction between data sparsity and model complexity. In particular, in sparse datasets, even though the BT model may not be relizable and the underlying matchmaking distribution is not uniform, Elo and its simple variants still demonstrate reasonable prediction accuracy. In contrast, for denser datasets, where all algorithms are expected to converge to zero regret, the optimal loss in hindsight becomes a more prominent factor in the cumulative loss. Consequently, algorithms based on
% more complex models, such as Elo2k or Pairwise, may
% achieve superior performance due to their greater model
% capacity.

In this section, we will view game rating through the lens of regret minimization in online optimization. We will adapt the framework of Online Convex Optimization (OCO) to the online algorithms. To facilitate our presentation, we briefly introduce OCO, following \citet{hazan2016introduction}'s definition.

\paragraph{Online Convex Optimization} At iteration $t$, the online player chooses $x_t \in \mathcal{K}$ according to the information in steps $1,2, \cdots, t-1$ . After the player has committed to this choice, a cost function $f_t \in \mathcal{F} : \mathcal{K} \to \mathbb{R}$ is revealed. Here, $\mathcal{F}$ is the bounded family of cost functions available to the adversary. The cost incurred by the online player is $f_t(x_t)$, the value of the cost function for the choice $x_t$. Let $T$ denote the total number of game iterations. The regret is defined as
\begin{equation*}
    \text{Regret}_T := \sum_{t=1}^{T}f_t(x_t) - \min_{x \in \mathcal{K}} \sum_{t=1}^{T} f_t(x),
\end{equation*}
that is, the cumulative loss minus the optimal loss in hindsight. 

It turns out that online rating algorithms can be evaluated under this framework. At each time $t$, let $f_t$ be the binary cross entropy loss function induced by the players $i_t$ and $j_t$ and the outcome $o_t$, and $x_t$ be the parameters updated by algorithms:
\begin{align*}
    f_t(x_t) := - (o_t \log  p_t + (1-o_t) \log (1-p_t)) .
\end{align*}
Here $p_t$ is actually related to the parameter $x_t$. Under this formulation, we have
% \begin{equation}
% \mathcal{L}_T = \text{Optimal loss in hindsight} + \text{Regret}_T.
% \end{equation}
\begin{equation}
\mathcal{L}_T = \text{Model misspecification error} + \text{Regret}_T.
\end{equation}
From this equation, we can see that the cumulative loss consists of two components, the model misspecification error (optimal loss in hindsight) and the regret. The trade-off between these two terms will be illustrated in extensive experiments.



\paragraph{Elo as online gradient descent} For Elo update, $x_t:= \theta_t \in \mathbb{R}^{N}$,  is the parameter of the underlying BT model (the Elo score). $p_t:=\sigma(\theta[i_t]-\theta[j_t])$ is the prediction. The gradient of $f_t$ is given by $\nabla_{\theta} f_t(\theta)= - (o_t - p_t) (\boldsymbol{e}_{i_t}- \boldsymbol{e}_{j_t})$. We can see that the Elo score update is actually online gradient descent with learning rate $\eta_t$ at each step $t$. Notice that $f_t$ is a convex function (one can refer to Appendix \ref{sec:appendix-algorithm} for detail). Therefore we can apply the regret bound for online gradient descent under convex loss \citep[Theorem 3.1]{hazan2016introduction}:
\begin{theorem}
\label{thm:OCO}
For convex cost functions $\{f_t\}_{t=1}^{T}$ and convex set $\mathcal{K}$, online gradient descent with step sizes $\{\eta_t = \frac{D}{G\sqrt{t}}\}$ guarantee the following for all $T>1$:
\begin{equation*}
\text{Regret}_T = \sum_{t=1}^{T}f_t(x_t) - \min_{x \in \mathcal{K}} \sum_{t=1}^{T} f_t(x) \leq \frac32 GD\sqrt{T},     
\end{equation*}
where $D$ is the upper bound on the diameter of $\mathcal{K}$, and $G$ is an upper bound on the norm of the subgradients of $f_t$ over $\mathcal{K}$.  
\end{theorem}
In the context of Elo update, since $\theta \in \mathbb{R}^{N}$, and in experiments we observe that $\|\theta\|_{\infty} \leq 5$, which means we can choose $D = 10 \sqrt{N}$. For $G$,  recall $\nabla_{\theta}f_t(\theta) = -(o_t-p_t)(\boldsymbol{e}_{i_t} - \boldsymbol{e}_{i_t})$, we have $G \leq \sqrt{2}$. Therefore we conclude that online Elo score update will have the following regret bound: $\frac{1}{T} \text{Regret}_T \leq C \sqrt{\frac{N}{T}}$ for some absolute constant $C$, with learning rate $\eta_t = \sqrt{\frac{N}{t}}$. Notice that this regret bound even holds under misspecified and non-stationary settings, which explains Elo's good performance in non-BT datasets, as long as the best BT model in hindsight provides a reasonable fit to the data.

We can also formulate the Elo2k update under online optimization framework as the following:  
\begin{align*}
    f_t(\theta) := - (o_t \log  p_t + (1-o_t) \log (1-p_t)) ,
\end{align*}
where $\theta = (U, V)$, where $U= (u_1, \cdots, u_N), V = (v_1, \cdots, v_N)$, $u_i, v_i \in \mathbb{R}^{k}$. The prediction $p_t=\sigma(u_{i_t}^{T}v_{j_t}-u_{j_t}^{T}v_{i_t})$. Then the Elo2k online update will be online gradient descent. However, the loss function is non-convex, therefore a general guarantee of OGD under Elo2k model is lacking. 





\subsection{Synthetic experiments: sparsity is critical}
\label{sec:synthetic}
To further justify our interpretation of why Elo performs well even in non-BT datasets, in this section, we will conduct extensive synthetic experiments, as well as experiments on augmented real-world data. These experiments further show that the ``sparsity" of the dataset plays a crucial role in the performance of algorithms.


% The effectiveness of these algorithms is shaped by the interaction between data sparsity and model complexity. The cumulative loss consists of 
% regret and the model misspecification error. There is a trade off between these two terms:
% algorithms based on more complex models might have a smaller model misspecification error, whereas Elo-like algorithms is guaranteed to have a small regret even under model-misspecification. In sparse datasets, where the regret is dominant in the cumulative loss, Elo-like algorithms tends to have good performance. In dense datasets, where the regret for every algorithms should converge to zero, the dominate term becomes the model misspecification error. In this case, Elo2k or Pairwise, may
% achieve superior performance due to their greater model
% capacity.

\paragraph{Synthetic experiments on non-BT datasets} We begin with the scenario where the playersâ€™ skills are stationary in the sense that $\E[o_t|i_t=i,j_t=j]=P_{ij}$ for some matrix $P\in\R^{N\times N}$. We consider the following two notions of the transitivity:

\begin{definition}[SST]
\label{def:sst}
$P$ is strongly stochastic transitive (SST) with respect to ordering $\pi$ if $\pi(i)>\pi(j)$ implies $P_{ik}\ge P_{jk}$ for all $k\in [N]$.
\end{definition}

\begin{definition}[WST]
\label{def:wst}
$P$ is weakly stochastic transitive (WST) with respect to ordering $\pi$ if $\pi(i)>\pi(j)$ implies $P_{ij}\ge \frac{1}{2}$.
\end{definition}
It is well-known that BT implies the SST condition, and SST further implies WST. For details of the constructed $P$, see Appendix \ref{sec:appendix-generatingP}.
% For non-transitive $P$, we consider $P$ that follows Elo2k model, and $P$ that has entries drawn randomly from $[0,1]$. 

For each of these types of $P$, we generate $P$ for $N=1000$ and $N=100$. For each instance of $P$, we generate $T=10^5$ games following uniform matchmaking distribution, that is, for every $t\in [T]$, sample $i_t \sim \text{Uni}([N])$, then independently sample $j_t \sim \text{Uni}([N])$. For each algorithm, we choose the best hyperparameter (for details of choosing the best hyperparameter, see Appendix \ref{sec:appendix-choosing_parameter}), we plot the corresponding $\frac1t \mathcal{L}_t$ with respect to time step $t/N$ (Figure \ref{fig:synthetic-CE-N=1000} for $N=1000$ and Figure \ref{fig:synthetic-CE-N=100} for $N=100$). The model misspecification error (optimal loss in hindsight) at time $T$ is also plotted for $N=100$. From the experiments (Figure \ref{fig:synthetic-CE-N=1000} and \ref{fig:synthetic-CE-N=100}), we can see that the effectiveness of rating algorithms is shaped by the interaction between data sparsity and model complexity. There is a trade-off between the regret and the model misspecification error:
when the samples are sparse, i.e., $t$ is small, the dominating term in the cumulative loss will be the regret, Elo2k or Pairwise suffers from a huge regret. Under this scenario, Elo and its variants performs well due to its low regret, even though BT model is non-realizable. For dense regime, i.e., $t$ is large, the regret for both Elo and Elo2k will be closer to zero. Under this scenario, Elo2k or Pairwise may achieve superior performance when they achieve a lower misspecification error due to their greater model capacity.

% \begin{figure}[t]
%     \centering
% \begin{minipage}{0.48\textwidth}
%     \centering
%     \includegraphics[height=8cm]{figures/1000-test-CE-new-big.png}
%     \vfill  % Push caption to bottom
%     \caption{\textbf{Elo outperforms Elo2k in sparse datasets.} We can see that Elo consistently outperforms Elo2k for $0\leq t \leq T$. One can also observe that when $t$ gets larger, Elo2k's performance is rapidly improving.}
%     \label{fig:synthetic-CE-N=1000}
% \end{minipage}%
% \hfill
% \begin{minipage}{0.48\textwidth}
%     \centering
%     \includegraphics[height=8cm]{figures/100-test-CE-new-big.png}
%     \vfill  % Push caption to bottom
%     \caption{\textbf{Performance in dense datasets.} When $t$ is large, the regret is close to zero for all algorithms, and Elo2k outperforms Elo when the gap between the misspecification error for Elo and Elo2k is large.}
%     \label{fig:synthetic-CE-N=100}
% \end{minipage}
% \end{figure}


\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.48\textwidth} % Keep the width consistent
        \centering
        \includegraphics[height=8cm]{figures/1000-test-CE-new-big.png}
        \caption{Prediction performance in sparse, stationary datasets.}
        \label{fig:synthetic-CE-N=1000}
    \end{subfigure}%
    ~
    \begin{subfigure}[t]{0.48\textwidth} % Keep the width consistent
        \centering
        \includegraphics[height=8cm]{figures/mm+varyingP-1000-test-CE-new-big.png}
        \caption{Prediction performance under non-stationary matchmaking and player strengths.}
        \label{fig:synthetic-CE-N=1000+mm+varyingP}
    \end{subfigure}%
    \caption{Elo and Elo2k's prediction performance in sparse datasets.}
\end{figure}




\paragraph{Non-trivial matchmaking and varying player strengths}

We further justify our regret-minimization framework through synthetic experiments under the scenario where the player strengths can vary and a non-trivial matchmaking exists. We plot the performance of each algorithm in non-stationary datasets ($N=1000$) in Figure \ref{fig:synthetic-CE-N=1000+mm+varyingP}. The experimental details can be found in Appendix \ref{sec:appendix-non_stationary}. 


\begin{figure}[t]
    \centering

    \begin{subfigure}[t]{0.48\textwidth} % Keep the width consistent
        \centering
        \includegraphics[height=8cm]{figures/100-test-CE-new-big.png}
        \caption{Predicition performance in dense, stationary datasets.}
        \label{fig:synthetic-CE-N=100}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.48\textwidth} % Keep the width consistent
        \centering
        \includegraphics[height=8cm]{figures/100-pairwise_rk-new-big.png}
        \caption{Pairwise ranking performance.}
        \label{fig:pairwise-rk-N=100}
    \end{subfigure}
    \caption{Ranking performance correlated with prediction.}
\end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.8\columnwidth]{figures/mm+varyingP-1000-test-CE-new-big.png}
%     \caption{\textbf{Elo is more robust to non-stationary matchmaking and player strengths.} Compared with Figure \ref{fig:synthetic-CE-N=1000}, we can see that the performance of Elo2k deteriorates more than Elo.}
%     \label{fig:synthetic-CE-N=1000+mm+varyingP}
% \end{figure}

Comparing Figure \ref{fig:synthetic-CE-N=1000} with Figure \ref{fig:synthetic-CE-N=1000+mm+varyingP}, we can see that when non-trivial matchmaking exists and the player strength are varying, Elo still performs reasonably well, while Elo2k exhibits a significant deterioration in performance. This also justifies our finding: Elo as online gradient descent, is guaranteed to achieve a low regret, even under non-trivial matchmaking and non-stationary player strengths.  

\paragraph{Experiments on real-world data}
Similar behaviors also appears in real-world datasets. Other than the real-world datasets examined in Section \ref{sec:lr-test}, we also use \texttt{Blotto}  and \texttt{AlphaStar} data from \cite{czarnecki2020real}, where we generate game data from the original payoff matrix. To create denser datasets, we augment datasets from \cite{czarnecki2020real} by simply creating identical copys. For each real-world dataset, we plot the corresponding $\frac1t \mathcal{L}_t$ for each algorithm with respect to time step $t/N$ (Figure \ref{fig:realdata-CE}). We can also see that sparsity plays a crucial role in those real-world (or augmented) datasets, as in the previous synthetic experiments. See Appendix \ref{sec:appendix-realdata} for details.


