\begin{table*}[t]
    \centering
    \small 
    \begin{tabular}{lccccc}
        \toprule
        Model & Likelihood & Entropy & CCP & SAR & Focus \\
\midrule
meta-llama/Meta-Llama-3-8B & 0.18 & 0.166 & 0.15 & 0.261 & 0.384 \\
meta-llama/Meta-Llama-3-70B & 0.182 & 0.168 & 0.15 & \textbf{0.274} & 0.339 \\
meta-llama/Llama-3.1-8B & 0.188 & 0.18 & 0.15 & 0.268 & 0.362 \\
meta-llama/Llama-3.2-3B & 0.177 & 0.182 & 0.15 & 0.256 & 0.348 \\
BAAI/Aquila2-7B & 0.169 & 0.162 & 0.15 & 0.248 & 0.365 \\
BAAI/Aquila2-34B & 0.171 & 0.168 & 0.15 & 0.222 & 0.361 \\
internlm/internlm2-7b & 0.192 & 0.174 & 0.15 & 0.26 & 0.385 \\
internlm/internlm2-20b & 0.181 & 0.169 & 0.15 & 0.272 & 0.332 \\
Qwen/Qwen2.5-7B & 0.175 & 0.166 & 0.15 & 0.237 & 0.347 \\
Qwen/Qwen2.5-32B & 0.179 & 0.166 & 0.15 & 0.251 & 0.356 \\
01-ai/Yi-9B & 0.172 & 0.162 & 0.15 & 0.233 & 0.362 \\
01-ai/Yi-34B & 0.175 & 0.166 & 0.15 & 0.227 & 0.353 \\
microsoft/phi-2 & \textbf{0.195} & \textbf{0.215} & \textbf{0.261} & 0.254 & 0.348 \\
mistralai/Mistral-7B-v0.3 & 0.176 & 0.162 & 0.15 & 0.237 & \textbf{0.386} \\
mistralai/Mixtral-8x22B-v0.1 & 0.177 & 0.167 & 0.15 & 0.256 & 0.345 \\
google/gemma-2-9b & 0.18 & 0.168 & 0.15 & 0.258 & 0.344 \\
google/gemma-2-27b & 0.182 & 0.166 & 0.15 & 0.25 & 0.349 \\
        \bottomrule
    \end{tabular}
    \caption{
     $\mathrm{Precision}_\mathrm{Opt}$ of five uncertainty scores across 17 LLMs.
    }
    \label{tb:precission_opt_17models}
\end{table*}