\begin{table*}[t]
    \centering
    \small 
    \begin{tabular}{lccccc}
        \toprule
        Model & Likelihood & Entropy & CCP & SAR & Focus \\
\midrule
meta-llama/Meta-Llama-3-8B & 0.29 & 0.278 & 0.261 & 0.344 & 0.484 \\
meta-llama/Meta-Llama-3-70B & 0.291 & 0.282 & 0.261 & 0.335 & 0.469 \\
meta-llama/Llama-3.1-8B & 0.296 & 0.286 & 0.261 & 0.351 & 0.483 \\
meta-llama/Llama-3.2-3B & 0.294 & 0.285 & 0.261 & 0.349 & 0.477 \\
BAAI/Aquila2-7B & 0.283 & 0.275 & 0.261 & 0.346 & 0.484 \\
BAAI/Aquila2-34B & 0.283 & 0.277 & 0.261 & 0.329 & 0.484 \\
internlm/internlm2-7b & 0.304 & 0.286 & 0.261 & 0.348 & 0.475 \\
internlm/internlm2-20b & 0.293 & 0.281 & 0.261 & 0.348 & 0.467 \\
Qwen/Qwen2.5-7B & 0.291 & 0.277 & 0.261 & 0.342 & 0.475 \\
Qwen/Qwen2.5-32B & 0.293 & 0.28 & 0.261 & 0.341 & 0.482 \\
01-ai/Yi-9B & 0.285 & 0.276 & 0.261 & 0.332 & 0.482 \\
01-ai/Yi-34B & 0.289 & 0.279 & 0.261 & 0.323 & 0.478 \\
microsoft/phi-2 & \textbf{0.315} & \textbf{0.323} & \textbf{0.266} & \textbf{0.361} & 0.477 \\
mistralai/Mistral-7B-v0.3 & 0.289 & 0.276 & 0.261 & 0.333 & \textbf{0.489} \\
mistralai/Mixtral-8x22B-v0.1 & 0.293 & 0.28 & 0.261 & 0.334 & 0.471 \\
google/gemma-2-9b & 0.294 & 0.282 & 0.261 & 0.346 & 0.476 \\
google/gemma-2-27b & 0.296 & 0.282 & 0.261 & 0.345 & 0.473 \\
        \bottomrule
    \end{tabular}
    \caption{
     $\mathrm{F1}_\mathrm{Opt}$ of five uncertainty scores across 17 LLMs.
    }
    \label{tb:f1_opt_17models}
\end{table*}