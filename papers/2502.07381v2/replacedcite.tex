\section{Related Work}
\subsection{Video Super-Resolution}
VSR exploits spatio-temporal similarity across LR videos to recover HR videos. %VSR methods are commonly divided into two categories, sliding-window framework ____ and recurrent framework ____. 
VSRNet ____ first employed a deep learning model for VSR. DUF ____ applied 3D convolution to leverage spatio-temporal relationships dynamically. EDVR ____ proposed Deformable Convolutional Networks (DCN) ____ based feature alignment and fusion. TDAN ____ further utilized DCN to estimate motion offsets between target, prior, and following frames. BasicVSR++ ____ designed a bidirectional recurrent architecture. VRT ____ applied a Transformer-based recurrent framework. However, the simple Bicubic down-sampling simulation of these methods brings about synthetic-to-real gaps, which cause the failure of compressed VSR.

\subsection{Compressed Video Super-Resolution}
The complex compression degradation poses new challenges for compressed VSR. To explore compression priors, COMISR ____ dealt with the location and smoothness of compressed frames through enhancement modules. FTVSR ____ designed a DCT-based attention module to preserve high-frequency details. CAVSR ____ estimated the compression level and applied corresponding treatments. Several works ____ tackled real-world VSR by introducing more degradation types. The better compression estimation and more realistic degradation construction make efforts on compressed VSR, but the information loss is difficult to recover with limited priors, especially when frames are compressed at low bit rates.

\begin{figure*}[!t]
\centering
\includegraphics[width=2.0\columnwidth]{2.pdf}
%\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-8pt}
\caption{Overview of the proposed Spatial Degradation-Aware and Temporal Consistent (SDATC) diffusion network. We apply a distortion control module (DCM) to enhance input low-quality (LQ) frames and extract guidance. The modulated frames are fed into the Latent Diffusion Model (LDM) based framework. The trainable prompt-based compression-aware module (PCAM) catches degradation-specific details for generation. Moreover, we incorporate the fine-tuned spatio-temporal attention module (STAM) to preserve temporal consistency.}
\label{fig_2}
\end{figure*}

\subsection{Diffusion-based Video Super-Resolution}
Diffusion-based image restoration has received growing attention from researchers recently. The great generation capability was explored in SISR ____. StableSR ____ and DiffBIR ____ used the control module during reconstruction. CCSR ____ improved content consistency through a structure refinement module. SUPIR ____ modified the ControlNet and designed a novel connector ZeroSFT to reduce computational complexity, which enabled a large-scale image restoration model. SATeCo ____ pivoted on learning spatial-temporal guidance from low-resolution videos. MGLD-VSR ____ and Upscale-A-Video ____ tried to constrain the temporal consistency of diffusion-based VSR models. In this work, we leverage additional generation priors of pre-trained diffusion models to resolve the compressed VSR task. To handle the limitations of existing diffusion frameworks, we develop spatial degradation-aware and temporal consistent techniques. The degradation pre-processing and guidance could also become a paradigm for diffusion-based VSR models.