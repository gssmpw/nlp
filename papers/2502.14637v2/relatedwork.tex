\section{Related Work and Preliminaries}
\subsection{Protein Backbone Generation}
Many diffusion and flow-based methods have been proposed to generate protein backbones. 
These methods often parameterize protein backbones like AlphaFold2~\cite{jumper2021highly} does, representing each protein's residues as a set of $\text{SE}(3)$ frames.
Accordingly, FrameDiff~\cite{yim2023se} generates protein backbones by two independent diffusion processes, generating the corresponding frames' local translations and rotations, respectively.
Following the same framework, flow-based methods like FrameFlow~\cite{yim2023fast} and FoldFlow~\cite{bose2023se} replace the stochastic diffusion processes with deterministic flows. 

For the above methods, many efforts have been made to modify their model architectures and improve data representations, e.g., the Clifford frame attention module in GAFL~\cite{wagner2024generating} and the asymmetric protein representation module in Genie~\cite{lin2023generating} and Genie2~\cite{lin2024out}. 
In addition, some methods leverage large-scale pre-trained models to improve generation quality.
For example, RFDiffusion~\cite{watson2023novo} utilizes the pre-trained RoseTTAFold~\cite{baek2021accurate} as the backbone model.
FoldFlow2~\cite{huguet2024sequence} improves FoldFlow by using a protein large language model for residue sequence encoding. Taking scaling further and adopting a different architectural approach, Prote\'{i}na~\cite{geffner2025proteina} developed a large-scale, flow-based generative model using a non-equivariant transformer operating directly on C-alpha coordinates.

Currently, the above methods often suffer the conflict on computational efficiency and generation quality.
The state-of-the-art methods like RFDiffusion~\cite{watson2023novo} and Genie2~\cite{lin2024out} need long inference time to generate protein backbones with reasonable quality.
FrameFlow~\cite{yim2023fast} and GAFL~\cite{wagner2024generating} significantly improves inference speed while lags behind RFDiffusion and Genie2 in protein backbone quality. 
Moreover, all the methods suffer severe performance degradation when generating long-chain protein backbones. 
These limitations motivate us to develop the proposed ReQFlow, improving the current flow-based methods and generating protein backbones efficiently with satisfactory designability.




% FrameDiff~\cite{yim2023se} defines the diffusion process over a set of $\text{SE}(3)$ frames and independently generates translations and rotations of each frame. 
% This decoupling method is widely adopted in the following works~\cite{yim2023fast, bose2023se, wagner2024generating}. 
% % However, FrameDiff requires a large number of sampling steps yet demonstrates relatively poor designability.
% RFDiffusion~\cite{watson2023novo} utilizes the pre-trained protein structure network RoseTTAFold~\cite{baek2021accurate} to generate high-quality protein backbones.
% Genie~\cite{lin2023generating} asymmetrically represents protein structures, using Gaussian noising forward and SE(3)-equivariant attention backward.
% Genie2~\cite{lin2024out} extends Genie through architectural innovations and massive data
% augmentation.

% Flow-based models~\cite{bose2023se,yim2023fast,wagner2024generating,huguet2024sequence} have gained popularity for simplifying the sampling path by removing stochasticity, which leads to faster inference and improved design quality.
% Frameflow~\cite{yim2023fast} and FoldFlow~\cite{bose2023se} extend FrameDiff to the flow matching framework. 
% FoldFlow2~\cite{huguet2024sequence} presents new network architectures including a protein large language model as a sequence encoder and is trained on a larger dataset containing high-quality synthetic structures. 
% GAFL~\cite{wagner2024generating} introduces an extension of the invariant point attention (IPA) architecture, representing residues in the projective geometric algebra.
% % However, their performance remains inferior to Genie2 and RFDiffusion and we empirically find that the rotation matrix representation used in these flow-based methods is numerically unstable when handling large rotation angles. 
% % Notably, all the aforementioned models struggle to generate long protein backbones with satisfactory designability.

% For the state-of-the-art diffusion and flow-based models, RFDiffusion~\cite{watson2023novo} and Genie2~\cite{lin2024out} produce high-quality protein backbones but the inference is prohibitively extensive.
% FrameFlow~\cite{yim2023fast} and GAFL~\cite{wagner2024generating} significantly improves inference speed while lags behind RFDiffusion and Genie2 in protein backbone quality. FoldFlow2~\cite{huguet2024sequence} achieves the best design performance and inference speed among these models but still struggles to generate long protein backbones with satisfactory designability.
% % ET-Flow~\cite{hassan2024flow} proposed a flow matching approach to generate low-energy molecular conformations. Compared to diffusion models~\cite{xu2022geodiff, jing2022torsional}, ET-Flow notably enhances precision and physical validity while achieving reduced model weight and accelerated inference speed. 
% % This demonstrates the potential of flow matching methods in 3D structure generation, applicable to both molecules and proteins.


\subsection{Quaternion Algebra and Its Applications}
The proposed ReQFlow is designed based on quaternion algebra~\cite{dam1998quaternions,zhu2018quaternion}.
Mathematically, quaternion is an extension of complex numbers into four-dimensional space, consists of one real component and three orthogonal imaginary components. 
A quaternion is formally expressed as $q = s + x\texttt{i} + y\texttt{j} + z\texttt{k} \in \mathbb{H}$, where $\mathbb{H}$ denotes the quaternion domain, and $s, x, y, z \in \mathbb{R}$. 
The imaginary components $\{\texttt{i}, \texttt{j}, \texttt{k}\}$ satisfy $\texttt{i}^2 = \texttt{j}^2 = \texttt{k}^2 = \texttt{ijk} = -1$. 
Each $q\in\mathbb{H}$ can be equivalently represented as a vector $\bm{q} = [s, \bm{u}^\top]^\top\in\mathbb{R}^4$, where $\bm{u}^\top = [x, y, z]^\top$. 
Given $\bm{q}_1 = [s_1, \bm{u}_1^\top]^\top$ and $\bm{q}_2 = [s_2, \bm{u}_2^\top]^\top$, their multiplication is achieved by Hamilton product, i.e., 
\begin{equation}\label{eq:hamilton}
\bm{q}_1 \otimes \bm{q}_2 = 
\begin{bmatrix} 
s_1s_2 - \bm{u}_1^{\top}\bm{u}_2 \\ 
s_1\bm{u}_2 + s_2\bm{u}_1 + \bm{u}_1 \times \bm{u}_2 
\end{bmatrix},
\end{equation}
where $\times$ denotes the cross product. 
% Note that, Hamilton product is non-commutative, i.e., $\bm{q}_1 \otimes \bm{q}_2 \neq \bm{q}_2 \otimes \bm{q}_1 $. 


Quaternion is a powerful tool to describe 3D rotations. 
For a 3D rotation in the axis-angle formulation, i.e., $\bm{\omega} = \phi \bm{u} \in \mathbb{R}^3$, where the unit vector $\bm{u}$ and the scalar $\phi$ denote the rotation axis and angle, respectively, we can convert it to a unit quaternion by an exponential map~\cite{sola2017quaternion}:
\begin{equation}\label{eq:exp_map}
    \bm{q} = \exp\Bigl(\frac{1}{2} \bm{\omega}\Bigr) = \Bigl[\cos\frac{\phi}{2}, \sin\frac{\phi}{2}\bm{u}^\top\Bigr]^\top\in\mathbb{S}^3,
\end{equation}
where $\mathbb{S}^3=\{\bm{q}\in\mathbb{R}^4~|~\|\bm{q}\|_2=1\}$ is the 4D hypersphere.
The conversion from a unit quaternion to an angle-axis representation is achieved by a logarithmic map:
\begin{equation}\label{eq:log_map}
    \bm{\omega} = 2\log(\bm{q}).
\end{equation}
Suppose that we rotate a point $\bm{v}_1\in\mathbb{R}^3$ to $\bm{v}_2$ by $\bm{\omega}$, we can equivalently implement the operation by
\begin{equation}\label{eq:rot_q}
    \bm{v}_2 = \text{Im}(\bm{q} \otimes [0, \bm{v}_1^\top]^\top \otimes \bm{q}^{-1}),
\end{equation}
where $\bm{q}^{-1}=[\cos\frac{\phi}{2}, -\sin\frac{\phi}{2}\bm{u}^\top]^{\top}$ is the inverse of $\bm{q}$ and ``$\text{Im}(\cdot)$'' denotes the imaginary components of a quaternion (i.e., the last three elements of the corresponding 4D vector).
The quaternion-based rotation representation in Eq.~\ref{eq:rot_q} offers several advantages, including compactness, computational efficiency, and avoidance of gimbal lock~\cite{hemingway2018perspectives}, which has been widely used in skeletal animation~\cite{shoemake1985animating}, robotics~\cite{pervin1982quaternions}, and virtual reality~\cite{kuipers1999quaternions}.

Besides computer graphics, some quaternion-based machine learning models have been proposed for other tasks, e.g., image processing~\cite{xu2015vector,zhu2018quaternion} and structured data (e.g., graphs and point clouds) analysis~\cite{zhang2020quaternion,zhao2020quaternion}.
% The representative works include quaternion sparse coding~\cite{xu2015vector} and quaternion convolution\cite{zhu2018quaternion} for image processing, quaternion neural network~\cite{zhang2020quaternion} and quaternion message passing~\cite{zhao2020quaternion} for graphs and point clouds modeling, and so on.
Recently, some quaternion-based models have been developed for scientific problems, e.g., the quaternion message passing~\cite{yue2024plug} for molecular conformation representation and the quaternion generative models for molecule generation~\cite{kohler2023rigid,guo2025assembleflow}.
However, the computational quaternion techniques are seldom considered in protein-related tasks.
Our work fill this blank, demonstrating the usefulness of quaternion algebra in protein backbone generation.

% AssembleFlow~\cite{guo2025assembleflow} represents rotations in the inertial frames for assembling molecules, it constructs the quaternion-based flow by using spherical linear interpolation (SLERP) in an additive form.