\section{Related Work}
\paragraph{Robustness to distribution shifts}
Prior work categorizes distribution shifts as domain generalization**Ben-David et al., "A Theory of Learning from Different Domains"**, where train and test data domains have no overlap, or subpopulation shifts**Hardt et al., "Equality of Opportunity in Supervised Learning"**, where train and test data come from the same domains, but do not necessarily appear in the same proportions. Our experimental setup is an example of a subpopulation shift, as all test languages are included in the training data for the models.

Methods for robust generalization are commonly categorized into three groups. Domain invariance methods aim to learn feature representations that are consistent across domains (groups) by encouraging similar feature distributions across domains**Gong et al., "Domain-Invariant Representation Learning"**. Other approaches use invariant prediction methods from causal inference literature. In contrast, DRO explicitly minimizes the worst-case loss over an uncertainty set, which is typically defined as a divergence ball around the training distribution**Ben-Tal et al., "Robust Optimization"**. Our work builds upon \orig{}**Wu et al., "Federated Robust Learning"**, since it has outperformed other approaches in settings with subpopulation shifts.

\paragraph{Robust ASR}
Prior work on robustness in ASR primarily focuses on quantifying or addressing biases related to accent, age, dialect, gender, and race **Zou et al., "A Framework for Fair Learning"**.
Methods to mitigate these biases include data balancing **Calders et al., "Behavioral Testing of a Data Mining Algorithm for Discrimination Discovery"** and fairness-promoting training methods **Hardt et al., "Equality of Opportunity in Supervised Learning"**. These methods are not appropriate for reducing ASR language disparities, as they either require large amounts of training data, which may not be available for most languages, or improve performance for certain groups at a substantial cost to others.
**Reddi et al., "On the Optimization and Regularization of Deep Models using the Fishers Information"** explored DRO for training language-independent speech recognition models, and reported  negative results. To the best of our knowledge, our work is the first to propose a robust optimization method that successfully reduces cross-lingual performance disparities in ASR.