\section{Related Work}
\paragraph{Robustness to distribution shifts}
Prior work categorizes distribution shifts as domain generalization____, where train and test data domains have no overlap, or subpopulation shifts____, where train and test data come from the same domains, but do not necessarily appear in the same proportions____. Our experimental setup is an example of a subpopulation shift, as all test languages are included in the training data for the models.

Methods for robust generalization are commonly categorized into three groups. Domain invariance methods aim to learn feature representations that are consistent across domains (groups) by encouraging similar feature distributions across domains____. Other approaches use invariant prediction methods____ from causal inference literature. In contrast, \texttt{DRO} explicitly minimizes the worst-case loss over an uncertainty set, which is typically defined as a divergence ball around the training distribution____. Our work builds upon \orig{}____, since it has outperformed other approaches in settings with subpopulation shifts____.

\paragraph{Robust ASR}
Prior work on robustness in ASR primarily focuses on quantifying or addressing biases related to accent, age, dialect, gender, and race ____.
Methods to mitigate these biases include data balancing____ and fairness-promoting training methods____.
These methods are not appropriate for reducing ASR language disparities, as they either require large amounts of training data, which may not be available for most languages, or improve performance for certain groups at a substantial cost to others.
____ explored \texttt{DRO} for training language-independent speech recognition models, and reported  negative results. To the best of our knowledge, our work is the first to propose a robust optimization method that successfully reduces cross-lingual performance disparities in ASR.