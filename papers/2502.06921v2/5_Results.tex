\section{Results}\label{sec:results}
This section highlights the benefits of GraNNite optimization techniques, compares performance between Intel\textregistered\ Core\texttrademark\ Ultra Series 1 \& 2 NPUs, and demonstrates the superior energy efficiency of NPUs over CPUs and GPUs for GNN execution.
Since GraNNite is the first hardware-aware framework tailored for optimizing GNN deployment on COTS SOTA NPUs, no existing works exist for direct comparison.
% This section demonstrates how the various GraNNite optimization techniques enhance performance across different GNN models, highlighting significant improvements when compared to traditional CPU and GPU executions on Intel NPUs.
% Version #3

\textbf{Benefits of GraNNite Optimizations:} Fig.~\ref{plot:gnn_progression} illustrates the performance progression of GNN models on the Intel\textregistered\ Core\texttrademark\ Ultra Series 2 NPU, highlighting the impact of various optimizations proposed by GraNNite. Each optimization builds upon the preceding set unless otherwise specified. For example, the performance of QuantGr in GCN reflects a model in which GrAd, NodePad, GraphSplit, and QuantGr are cumulatively applied. However, in SAGE-max, EffOp and GrAx3 target the same model, and their performance gains are not cumulative.
For GCN, the initial optimization, StaGr combined with GraphSplit, achieves a $1.51\times$ speedup over the baseline by efficiently partitioning workloads between the CPU and NPU. Adding GrAd and NodePad introduces support for time-varying graphs and enhances parallelism but reduces performance to $1.4\times$ due to CPU preprocessing overhead and an increased node count on the NPU. GraSp further boosts throughput by $1.1\times$. The most significant improvement, $2.7\times$, is achieved by combining GrAd, NodePad, GraphSplit, and QuantGr, leveraging low-precision arithmetic to minimize computational overhead.
For GAT, EffOp alone provides a $3\times$ speedup, while incorporating approximations (GrAx2) boosts performance to $7.6\times$ with negligible impact on model quality. Similarly, for SAGE-max, EffOp yields a $2\times$ speedup, which increases to $3.2\times$ with GrAx3, again with no quality degradation.
We note that the effects of SymG and CacheG could not be demonstrated as they require modifications to the (proprietary) NPU compiler.
%, which is not open source.

\begin{figure}[t!]
\begin{center}
\includegraphics[width=\columnwidth]{Plots/MTL_vs_LNL_GCN.pdf}% This is a *.eps file
\end{center}
\caption{Performance of GCN on different Intel\textregistered\ NPUs: Intel\textregistered\ Core\texttrademark\ Ultra Series 2 and Intel\textregistered\ Core\texttrademark\ Ultra Series 1.}\label{plot:mtl_vs_lnl}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=\columnwidth]{Plots/CPU_GPU_NPU.pdf}% This is a *.eps file
\end{center}
\caption{Performance of GNN models on different devices of an Intel\textregistered\ AI PC: NPU outperforms CPU and GPU by a large margin.}\label{plot:cpu_gpu_npu}
\end{figure}

\textbf{Performance Comparison on Intel\textregistered\ Core\texttrademark\ Ultra Series 1 vs. Intel\textregistered\ Core\texttrademark\ Ultra Series 2 NPUs:} Fig.~\ref{plot:mtl_vs_lnl} compares GCN performance across GraNNite optimizations on Intel\textregistered\ Core\texttrademark\ Ultra Series 1 and Intel\textregistered\ Core\texttrademark\ Ultra Series 2 NPUs. Series 2 consistently outperforms series 1 due to its higher tile count (4 vs. 2). For the most optimized configuration (GrAd + NodePad + QuantGr), Intel\textregistered\ Core\texttrademark\ Ultra Series 2 delivers $1.7\times$ and $1.6\times$ higher throughput than Intel\textregistered\ Core\texttrademark\ Ultra Series 1 for the Cora and Citeseer datasets, respectively. This advantage arises from the higher number of MAC units in Series 2, enabling greater data parallelism. However, the observed gains fall short of the theoretical $2\times$ maximum due to limited parallelism inherent in the GCN.  

\textbf{Performance and Energy Efficiency of CPU, GPU, and NPU with GraNNite Optimizations:} Fig.~\ref{plot:cpu_gpu_npu} compares the performance of CPU, GPU, and NPU across three GNN layers: GraphConv (GCN), GraphAttn (GAT), and SAGE (GraphSAGE). For GCN, the NPU achieves a $2.9\times$ speedup over the GPU and $3.3\times$ over the CPU. For GAT layers, the NPU provides $2.3\times$ and $3.8\times$ improvements over the GPU and CPU, respectively. Similarly, for GraphSAGE with mean aggregation, the NPU achieves $6.7\times$ and $10.8\times$ speedups over the GPU and CPU. These results highlight the computational efficiency of NPUs and the effectiveness of GraNNite optimizations in delivering high-performance GNN execution without hardware modifications.  
Fig.~\ref{plot:energy_gcn} demonstrates the energy efficiency of NPUs compared to CPUs and GPUs for GNN execution. For the Cora dataset, the NPU is $4.1\times$ and $8.5\times$ more energy-efficient than the most efficient GPU and CPU implementations, respectively. Similarly, for the Citeseer dataset, the NPU achieves $4.4\times$ and $8.6\times$ greater energy efficiency.


% Version #2
% Fig.~\ref{plot:gnn_progression} shows the performance progression of GNNs on the Intel Lunar Lake NPU, highlighting significant improvements from a series of targeted optimizations proposed by GraNNite. It is to be noted that the optimizations are progressively added unless they are . For example, the performance for QuantGr in GCN is shown for a model with GrAd, NodePad, GraphSplit and QuantGr applied to the GNN model, not just the QuantGr. But for SAGE-max, EffOp and GrAx3 target the same model section, therefore, the performance gains shown in the plot are not cumulative. For GCN, the first optimization (StaGr + GraphSplit), enhances model execution by efficiently distributing the workload between the CPU and NPU, achieving a $1.51\times$ performance boost over the baseline. Adding GrAd and NodePad allows handling time-varying graphs and ensures efficient parallelism, though it slightly reduces performance as compared to (StaGr + GraphSplit) by $1.4\times$ due to the additional pre-processing overhead on CPU and increased number of nodes on the NPU. The most substantial improvement comes from combining GrAd, NodePad, GraphSplit, and QuantGr, which uses low-precision arithmetic to reduce computational load, resulting in a $2.7\times$ performance gain.
% For GAT, EffOp yields a $3\times$ performance boost. When we incorporate approximation, the improvement jumps to $7.6\times$, with almost no degradation in quality.
% For SAGE-max, EffOp yields a $2\times$ performance boost. When we incorporate approximation (GrAx3), the improvement jumps to $3.2\times$, with no degradation in quality.
% Fig.~\ref{plot:mtl_vs_lnl} compares GCN performance across different GraNNite optimization techniques on NPUs of two Intel AI PCs, meteor lake and lunar lake. We observe that Lunar Lake consistently delivers higher performance as it has higher number of tiles (4) as compared to meteor lake (1). For the most optimized version (GrAd + NodePad + QuantGr), lunar lake archives $1.7\times$ ($1.6\times$) higher throughput than meteor lake for Cora (Citeseer) dataset. The presence of higher number of MAC units in lunar lake enables higher data parallelism leading to better performance. Although the performance gain is not equal to the theoretical maximum (4X) due to the limited data parallelism in the GCN model.
% Fig.~\ref{plot:cpu_gpu_npu} compares the performance of CPU (blue), GPU (orange), and NPU (green) across three GNN layer types: GraphConv (GCN), GraphAttn (GAT), and SAGE (GraphSAGE). For GCN, the NPU achieves a remarkable $17.3\times$ speedup over the GPU and $4.6\times$ over the CPU, showcasing its efficiency in handling these workloads. Similarly, the NPU demonstrates $2.3\times$ and $3.8\times$ improvements over GPU and CPU, respectively, for GAT layers, and achieves $6.7\times$ and $10.8\times$ speedups for GraphSAGE with mean aggregation. These results underscore the NPU's computational advantages and the effectiveness of GraNNite's optimizations, enabling high-performance GNN execution on existing hardware without modifications.
% Fig.~\ref{plot:energy_gcn} demonstrates the need for mapping the GNN models on NPU for energy efficiency. We observe that NPU is $4.1\times$ ($4.4\times$) energy efficient than the most energy efficient GPU implementation for Cora (Citeseer) dataset. Similarly, NPU is $8.5\times$ ($8.6\times$) energy efficient than the most energy efficient CPU implementation for Cora (Citeseer) dataset. 
% It is to be noted that, we could not demonstrate the impact of SymG and CacheG as those would require changes in the NPU compiler which is not made open source.

% Version #1
% Fig.~\ref{plot:gnn_progression}(a) shows the performance progression of Graph Convolutional Networks (GCN) on the Intel Lunar Lake NPU, highlighting significant improvements from a series of targeted optimizations. Here, the unoptimized implementation serves as the reference baseline.
% The first optimization, Optimized Graph Partitioning (OGP), enhances data locality by efficiently distributing the workload between the CPU and NPU, achieving a $1.85\times$ performance boost over the baseline. Adding Node Padding (NP) allows handling time-varying graphs and ensures efficient parallelism, though it slightly reduces performance by $1.1\times$ due to the additional processing overhead on the CPU. The most substantial improvement comes from combining OGP, NP, and Quantization, which uses low-precision arithmetic to reduce computational load, resulting in a $2.7\times$ performance gain.

% Fig.~\ref{plot:gnn_progression}(b) demonstrates the performance improvements of Graph Attention Network (GAT) implementations on an Intel NPU, achieving a $7.6\times$ speedup over the baseline.
% The first optimization replaces the ``Select" operation with element-wise multiplication, yielding a $3\times$ performance boost by simplifying the computation. Next, the element-wise multiplication is offloaded to the DPU, providing an additional $3.5\times$ performance gain by focusing computation on the DPU. Finally, eliminating the broadcast addition operation, which causes memory overhead, results in a substantial performance improvement, reaching the $7.6\times$ speedup.

% Fig.~\ref{plot:gnn_progression}(c) showcases the performance gains of a SAGE model with the max aggregation scheme, achieving up to $3.2\times$ speedup over the baseline.
% The first optimization replaces the complex ``Select" operation with a more efficient element-wise multiplication, boosting performance to $2\times$ the baseline. The second optimization swaps the ``ReduceMax" operation for ``MaxPool1D," aligning better with hardware architecture and providing an additional performance increase, reaching the final $3.2\times$ speedup.

% Fig.~\ref{plot:cpu_gpu_npu} compares the performance of CPU (blue), GPU (orange), and NPU (green) across three GNN layer types: GraphConv (GCN), GraphAttn (GAT), and SAGE (GraphSAGE). For GCN, the NPU achieves a remarkable $17.3\times$ speedup over the GPU and $4.6\times$ over the CPU, showcasing its efficiency in handling these workloads. Similarly, the NPU demonstrates $2.3\times$ and $3.8\times$ improvements over GPU and CPU, respectively, for GAT layers, and achieves $6.7\times$ and $10.8\times$ speedups for GraphSAGE with mean aggregation. These results underscore the NPU's computational advantages and the effectiveness of GraNNite's optimizations, enabling high-performance GNN execution on existing hardware without modifications.

% Version #0
% These optimizations demonstrate how integrating algorithmic improvements, memory management, and hardware-friendly approaches unlocks the full performance potential of GCNs on NPUs.

% Fig.~\ref{plot:gcn_progression} illustrates the performance progression of Graph Convolutional Network (GCN) implementations on an Intel Lunar Lake NPU, demonstrating significant enhancements achieved through a series of targeted optimizations. The baseline unoptimized implementation is set as the reference point, representing the lowest performance.
% The first optimization, Optimized Graph Partitioning (OGP), focuses on improving data locality by effectively distributing the workload between the CPU and NPU for a static input graph. This optimization results in a notable performance boost of approximately 1.85X over the baseline.
% Next, the addition of Node Padding (NP) to the OGP approach enables the model to handle time-varying input graphs. This ensures efficient parallelism across compute units, although it slightly reduces performance by about 1.1X compared to OGP alone. This decrease is attributed to the extra processing time required for the normalization matrix on the CPU.
% The most significant performance improvement is observed with the combination of OGP, NP, and Quantization. By employing low-precision arithmetic, this approach reduces the overall computational workload, leading to a remarkable 2.7X enhancement over the initial implementation.
% The consistent increase in performance across these optimization stages underscores the value of integrating algorithmic optimizations like OGP with memory management techniques (NP) and hardware-friendly approaches (quantization). This cumulative application of optimizations highlights that while each individual optimization is beneficial, their combined effect is essential for unlocking the full performance potential of GCNs on NPUs.


% \begin{figure}[t!]
% \begin{center}
% \includegraphics[width=\columnwidth]{Plots/GCN_progression.png}% This is a *.eps file
% \end{center}
% \caption{Progressive performance improvement of GCN through different optimizations}\label{plot:gcn_progression}
% \end{figure}


% These optimizations highlight the importance of reducing unnecessary memory operations and offloading tasks to specialized cores, significantly improving inference latency and efficiency for GAT models on NPUs in resource-constrained environments.


% Fig.~\ref{plot:gat_progression} showcases the performance improvements of Graph Attention Network (GAT) implementations on an Intel NPU, illustrating how a series of optimizations culminate in a substantial 7.6X speedup over the baseline implementation. The baseline serves as the starting point and represents the lowest performance due to the computational inefficiencies inherent in certain operations typically used in GAT models.
% The first optimization involves replacing the "Select" operation with element-wise multiplication, which is a simpler and more parallelizable operation. This initial change yields an impressive improvement of approximately 3X over the baseline performance, highlighting the benefits of simplifying computational tasks.
% In the second stage of optimization, the element-wise multiplication operation is further refined; instead of performing the multiplication operation alongside other computations, it is exclusively executed on the DPU. This focused approach results in a cumulative performance boost of around 3.5X relative to the original implementation, indicating that optimizing where and how computations are performed is critical for enhancing performance.
% The final optimization addresses the broadcast addition operation, which often incurs significant memory overhead by duplicating data across tensors. By eliminating this redundant operation, the GAT implementation experiences a substantial performance enhancement, achieving a maximum of 7.6X speedup over the baseline. 
% This progressive enhancement illustrates the crucial role of reducing unnecessary memory operations and leveraging specialized processing cores for performance-critical tasks. The results emphasize that architectural-aware optimizations—such as offloading specific workloads from the DSP to DPU cores and eliminating redundant operations through approximations—can lead to significant improvements in inference latency for GAT models on NPUs. Such strategies not only optimize computational efficiency but also facilitate faster and more effective execution of GNNs in resource-constrained environments.


% \begin{figure}[t!]
% \begin{center}
% \includegraphics[width=\columnwidth]{Plots/GAT_progression.png}% This is a *.eps file
% \end{center}
% \caption{Progressive performance improvement of GAT through different optimizations}\label{plot:gat_progression}
% \end{figure}


% This progression demonstrates the value of targeted optimizations in reducing computational overhead, enhancing data-parallel processing, and maximizing performance for GNN models on specialized hardware.

% Fig.~\ref{plot:sage_progression} demonstrates the performance improvements of a SAGE model with the max aggregation scheme following a series of targeted optimizations, ultimately achieving a cumulative speedup of up to 3.2X compared to the baseline. The baseline reflects the initial performance prior to any optimizations, serving as a reference for evaluating the impact of each subsequent modification.
% The first optimization involves substituting the "Select" operation—known for its control-flow complexity—with a data-parallel element-wise multiplication. This shift to a computationally more efficient operation delivers a substantial boost, bringing the performance to approximately 2X of the baseline. This optimization illustrates how replacing control-flow-heavy operations with data-parallel alternatives can enhance computational efficiency.
% Building upon this, a second optimization replaces the "ReduceMax" operation with "MaxPool1D," a more streamlined operation that aligns better with the hardware's architecture. This adjustment leads to an additional performance increase, as depicted by the green bar on the right, resulting in a total improvement of 3.2X over the baseline configuration.
% Overall, this progression highlights the impact of carefully selected optimizations in reducing computational overhead, enhancing data-parallel processing, and improving model efficiency. These results underscore the effectiveness of architectural-aware optimizations in maximizing performance for GNN models on specialized hardware.


% \begin{figure}[t!]
% \begin{center}
% \includegraphics[width=\columnwidth]{Plots/SAGE_progression.png}% This is a *.eps file
% \end{center}
% \caption{Progressive performance improvement of SAGE-max through different optimizations}\label{plot:sage_progression}
% \end{figure}



% \subsection{CPU, GPU \& NPU performance per watt for GCN, GAT and GraphSAGE}
% Figure~\ref{plot:power} presents the power consumption breakdown of various components in different operational states of an AI PC, including IDLE and during the execution of GNN models on different devices. The x-axis shows the specific GNN models in use and the devices they are mapped to, allowing for a comparison of power usage across distinct deployment scenarios.
% The first bar on the left represents the system’s IDLE state, where no workload is running on any device. This IDLE power breakdown provides a baseline to compare against the power demands when GNN models are actively running on various devices within the AI PC.
% Moving beyond IDLE, the figure details the power distribution among key system components—IA cores, System Agent, GT, and DRAM—when GNN models are executed, especially highlighting the benefits of NPU deployment. When a model runs on the NPU, the System Agent’s power consumption, shown in blue, increases due to its role in managing the NPU, which draws from the System Agent’s power rail. However, despite this rise in the System Agent’s power draw, the total power usage across all components (including IA cores, GT, and DRAM) remains notably low when models are mapped to the NPU.
% This low cumulative power usage, paired with the NPU’s high processing efficiency (as demonstrated in previous figures), results in excellent performance per watt. Such efficiency makes the NPU highly suitable for applications that demand both high performance and low energy consumption. Specifically, the NPU’s ability to efficiently handle GNN workloads with minimal power draw makes it well-suited for high-performance tasks in power-sensitive settings. In summary, Figure~\ref{plot:power} underscores how the NPU’s balanced approach to speed and power usage makes it a compelling option for deploying GNN models in resource-constrained environments.

% \begin{figure}[t!]
% \begin{center}
% \includegraphics[width=\columnwidth]{Plots/Power.png}% This is a *.eps file
% \end{center}
% \caption{Power consumption of different GNN models on Intel AI PC: NPU takes lower power and compute with a higher speed}\label{plot:power}
% \end{figure}



% Fig.~\ref{plot:cpu_gpu_npu} presents a performance comparison among CPU (blue), GPU (orange), and NPU (green) in executing three types of GNN layers: GraphConv (GCN), GraphAttn (GAT), and SAGE (GraphSAGE). For the GraphConv (GCN), the NPU achieves an impressive 17.3× speedup compared to the GPU and a 4.6× speedup over the CPU. This result highlights the NPU's significant efficiency in managing GCN workloads.
% In the case of the GraphAttn (GAT), the NPU demonstrates a performance improvement of 2.3× over the GPU and 3.8× over the CPU. Likewise, for the SAGE (GraphSAGE) using the mean aggregator scheme, the NPU outperforms the GPU by 6.7× and the CPU by 10.8×. These results clearly indicate the superior computational capabilities of NPUs and efficacy of GraNNite proposed optimizations, particularly when applied to our most optimized GNN layers. The consistent performance advantage of NPUs over traditional architectures like CPUs and GPUs across these benchmarks suggests that existing NPUs can effectively implement GNNs using the proposed optimizations, without necessitating any changes to the underlying hardware.



\begin{figure}[t!]
\begin{center}
\includegraphics[width=\columnwidth]{Plots/Energy_GCN.pdf}% This is a *.eps file
\end{center}
\caption{Normalized Energy Consumption of GCN on Intel\textregistered\ Core\texttrademark\ Ultra Series 2 Devices (CPU, GPU, and NPU), highlighting significant energy savings achieved with GraNNite optimizations.}\label{plot:energy_gcn}
\end{figure}