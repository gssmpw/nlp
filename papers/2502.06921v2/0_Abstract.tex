\noindent
\textcolor{black}{
% Graph Neural Networks (GNNs) have emerged as a cornerstone for learning and reasoning over graph-structured data, with applications in network analysis, recommendation systems, and speech analytics. Their ability to capture complex relationships through graph topology makes them indispensable for AI tasks. Deploying GNNs on edge devices, such as client PCs and laptops, offers benefits like real-time processing, enhanced data privacy, and reduced reliance on cloud infrastructure. For instance, GNNs can augment Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and enable event-based vision tasks. However, efficient edge deployment faces challenges, including irregular memory access patterns, sparse graphs, and dynamic graph structures, which degrade performance on resource-constrained devices. Additionally, edge devices often suffer from high latency and energy consumption due to limited memory and slower DRAM access. Modern edge processors integrate heterogeneous computing units, including CPUs, GPUs, and Neural Processing Units (NPUs). NPUs excel in energy-efficient, data-parallel operations but struggle with irregular GNN workloads.
Graph Neural Networks (GNNs) are crucial for learning and reasoning over graph-structured data, with applications in network analysis, recommendation systems, and speech analytics. Deploying them on edge devices, such as client PCs and laptops, enables real-time processing, enhances privacy, and reduces cloud dependency. For instance, GNNs can augment Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and enable event-based vision tasks. However, irregular memory access, sparse graphs, and dynamic structures lead to high latency and energy consumption on resource-constrained devices. Modern edge processors combine CPUs, GPUs, and NPUs, where NPUs excel at data-parallel tasks but face challenges with irregular GNN computations.
To address these gaps, we present \textbf{\textit{GraNNite}}, the first hardware-aware framework tailored to optimize GNN deployment on commercial-off-the-shelf (COTS) state-of-the-art (SOTA) DNN accelerators using a systematic \textbf{three-step methodology}: (1) enabling GNN execution on NPUs, (2) optimizing performance, and (3) trading accuracy for further performance and energy efficiency gains.
Towards that end, the first category includes techniques such as \textit{GraphSplit} for workload distribution and \textit{StaGr} for static graph aggregation, while \textit{GrAd} and \textit{NodePad} handle real-time updates for dynamic graphs. Next, performance improvement is acquired through techniques such as \textit{EffOp} for control-heavy operations and \textit{GraSp} for sparsity exploitation. For Graph Convolution layers, \textit{PreG}, \textit{SymG}, and \textit{CacheG} reduce redundancy and memory transfers. The final class of techniques deals with quality vs efficiency tradeoffs -- \textit{QuantGr} applies INT8 quantization to lower memory usage and computation time, while \textit{GrAx1}, \textit{GrAx2}, and \textit{GrAx3} optimize graph attention, broadcast-add, and sample-and-aggregate (SAGE)-max aggregation for higher throughput with minimal quality loss.
Experimental evaluations on Intel\textregistered\ Core\texttrademark\ Ultra Series 1 and 2 AI PCs demonstrate that GraNNite achieves speedups of $\mathbf{2.6\times}$ to $\mathbf{7.6\times}$ over default NPU mappings, with energy efficiency improvements up to $\mathbf{8.6\times}$ compared to CPUs and GPUs. Across various GNN models, GraNNite delivers up to $\mathbf{10.8\times}$ and $\mathbf{6.7\times}$ higher performance than CPUs and GPUs, respectively.}
Our code implementation is available at \href{https://github.com/arghadippurdue/GraNNite}{this link}.

% Our code implementation is available at \href{https://anonymous.4open.science/r/GraNNite/}{https://anonymous.4open.science/r/GraNNite/}.
% First, it enables efficient execution with \textit{GraphSplit} for workload distribution and \textit{StaGr} for static graph aggregation, while \textit{GrAd} and \textit{NodePad} handle real-time updates for dynamic graphs. Second, it improves performance without quality loss using \textit{EffOp} for control-heavy operations and \textit{GraSp} for sparsity exploitation. For Graph Convolution layers, \textit{PreG}, \textit{SymG}, and \textit{CacheG} reduce redundancy and memory transfers. Finally, \textit{QuantGr} applies INT8 quantization to lower memory usage and computation time, while \textit{GrAx1}, \textit{GrAx2}, and \textit{GrAx3} optimize graph attention, broadcast-add, and sample-and-aggregate(SGAE)-max aggregation for higher throughput with minimal quality loss.
% In the first step, it enables efficient GNN execution by introducing \textit{GraphSplit} for workload distribution and \textit{StaGr} for optimizing static graph aggregation. For dynamic graphs, \textit{GrAd} and \textit{NodePad} facilitate real-time updates with minimal overhead. The second step focuses on optimizing performance without quality loss by employing \textit{EffOp} to accelerate control-heavy operations and \textit{GraSp} to exploit sparsity for efficient memory usage. Additionally, for GNNs with Graph Convolution layers, \textit{PreG}, \textit{SymG}, and \textit{CacheG} reduce redundancy and minimize memory transfers, further improving execution efficiency. In the final step, GraNNite enhances performance by leveraging \textit{QuantGr}, which utilizes INT8 quantization to reduce memory usage and computation time while maintaining accuracy. Further throughput improvements are achieved using approximate techniques (\textit{GrAx1}, \textit{GrAx2}, \textit{GrAx3}), which optimize attention computation, broadcast-add operations, and SAGE-max aggregation with minimal quality degradation.
% \textcolor{blue}{Graph Neural Networks (GNNs) have emerged as a cornerstone for learning and reasoning over graph-structured data, with applications in network analysis, recommendation systems, and speech analytics. Their ability to capture complex relationships through graph topology makes them indispensable for AI tasks. Deploying GNNs on edge devices, such as client PCs and laptops, offers benefits like real-time processing, enhanced data privacy, and reduced reliance on cloud infrastructure. For instance, GNNs can augment Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and enable event-based vision tasks. However, efficient edge deployment faces challenges, including irregular memory access patterns, sparse graphs, and dynamic graph structures, which degrade performance on resource-constrained devices. Additionally, edge devices often suffer from high latency and energy consumption due to limited memory and slower DRAM access.
% Modern edge processors integrate heterogeneous computing units, including CPUs, GPUs, and Neural Processing Units (NPUs). NPUs excel in energy-efficient, data-parallel operations but struggle with irregular GNN workloads. To address these gaps, we present \textbf{\textit{GraNNite}}, the first hardware-aware framework tailored to optimize GNN deployment on NPUs.
% % GraNNite introduces novel techniques, including \textit{GraphSplit} for efficient workload distribution and \textit{EffOp} for accelerating control-heavy operations. 
% GraNNite introduces a myriad of novel techniques for the efficient deployment of GNNs on commercial-off-the-shelf (COTS) state-of-the-art (SOTA) DNN accelerators. Towards that end, it includes \textit{GraphSplit} for efficient workload distribution and \textit{EffOp} for accelerating control-heavy operations.
% It supports both static and dynamic graphs through methods like \textit{StaGr}, \textit{GrAd}, and \textit{NodePad}, enabling real-time updates with minimal overhead. Additionally, optimizations such as \textit{PreG}, \textit{SymG}, and \textit{CacheG} reduce redundancy and memory transfers, while approximate techniques (\textit{GrAx1}, \textit{GrAx2}, \textit{GrAx3}) enhance throughput with minimal quality loss. Furthermore, \textit{GraSp} and \textit{QuantGr} leverage sparsity and INT8 quantization to reduce memory usage and computation time.
% Experimental evaluations on Intel Lunar Lake and Meteor Lake AI PCs demonstrate that GraNNite achieves speedups of $\mathbf{2.6\times}$ to $\mathbf{7.6\times}$ over default NPU mappings, with energy efficiency improvements up to $\mathbf{8.6\times}$ compared to CPUs and GPUs. Across various GNN models, GraNNite delivers up to $\mathbf{10.8\times}$ and $\mathbf{6.7\times}$ higher performance than CPUs and GPUs, respectively.} Our code implementation is available at \href{https://anonymous.4open.science/r/GraNNite/}{https://anonymous.4open.science/r/GraNNite/}.
% These results underscore the effectiveness of GraNNite in achieving scalable, low-latency, and energy-efficient GNN inference on edge platforms. Our implementation is publicly available at \href{https://anonymous.4open.science/r/GraNNite/}{https://anonymous.4open.science/r/GraNNite/}.

% \noindent 
% Graph Neural Networks (GNNs) have become indispensable for a wide range of applications such as personalized recommendation systems, fraud detection, social network analysis, and biological data interpretation. Their ability to model complex, graph-structured data makes them a critical component of AI use cases on client PCs, making their efficient execution on client PCs crucial to support privacy, low-latency inference, and offline use cases. Leveraging Neural Processing Units (NPUs) for GNNs is especially important, as NPUs offer energy-efficient acceleration for machine learning workloads, enabling high performance within the power and resource constraints of client devices. However, deploying GNNs on NPUs presents significant challenges due to irregular memory access patterns, dynamic graph updates, and control-heavy operations.
% In this paper, we present the GraNNite framework, which introduces a comprehensive set of optimizations to overcome these challenges and improve the performance of GNNs on NPUs. GraNNite incorporates techniques such as model graph partitioning, dynamic node, and edge updates to the input graph, and the transformation of control-heavy vector operations into data-parallel matrix operations. Additionally, the framework leverages INT8 quantization and zero-value compression (ZVC) to minimize memory usage, computational overhead, and latency.
% Our framework enables support for both static and dynamic graphs, with real-time updates and minimal recompilation, making it ideal for resource-constrained client PCs. Experimental validation on Intel Lunar Lake and Meteor Lake NPUs shows that GraNNite achieves speedups ranging from $\mathbf{2.6\times}$ to $\mathbf{7.6\times}$ over initial out-of-the-box NPU mappings. GraNNite also significantly outperforms CPU and GPU executions, delivering up to $\mathbf{10.8\times}$ and $\mathbf{6.7\times}$ speedups, respectively, across various GNN models. Furthermore, it enhances energy efficiency, achieving up to $\mathbf{8.6\times}$ greater efficiency compared to CPUs and GPUs. Our code implementation is available at \href{https://anonymous.4open.science/r/GraNNite/}{https://anonymous.4open.science/r/GraNNite/}.

% \textcolor{red}{TODOs:
% \begin{itemize}
%     \item Combine claims into 5-6 contributions
%     \item Add motivation (added benchmarks in MLPerf)
%     % \item New contributions (approximation, block sparsity, mixed precision, memoization etc. -- need more brainstorming)
%     \item Need results on more datasets?
% \end{itemize}
% }
% Graph Neural Networks (GNNs) have shown great promise for tasks involving complex graph-structured data, but their deployment on Neural Processing Units (NPUs) faces significant challenges due to irregular memory access patterns, dynamic graph updates, and control-heavy operations. In this paper, we propose the GraNNite framework, which introduces a suite of optimizations to enhance the performance of GNNs on NPUs, specifically targeting accelerators such as Intel NPUs. GraNNite integrates several innovative techniques, including model-specific graph partitioning, dynamic node and edge updates, and the replacement of control-heavy vector operations with data-parallel matrix operations. We also utilize optimizations such as INT8 quantization, zero-value compression (ZVC), and pipelining, which collectively reduce memory usage, computation costs, and latency. Our framework supports both static and dynamic graphs, providing real-time updates with minimal recompilation overhead.
% The performance evaluation across various GNN models highlights the improvements brought by GraNNite's optimization techniques, with speedups ranging from $\mathbf{2.6\times}$ to $\mathbf{7.6\times}$ compared to initial out-of-the-box implementations. Experimental results demonstrate significant performance improvements, with GraNNite achieving up to a $\mathbf{6.7\times}$ speedup over GPU and a $\mathbf{10.8\times}$ speedup over CPU executions.


% Graph Neural Networks (GNNs) have shown great promise for tasks involving complex graph-structured data, but their deployment on Deep Neural Network Accelerators (NPUs) faces significant challenges due to irregular memory access patterns, dynamic graph updates, and control-heavy operations. In this paper, we propose the GraNNite framework, which introduces a suite of optimizations to enhance the performance of GNNs on NPUs, specifically targeting accelerators such as Intel NPUs. GraNNite integrates several innovative techniques, including model-specific graph partitioning, dynamic node and edge updates, and the replacement of control-heavy DSP operations with data-parallel DPU operations. We also introduce optimizations such as INT8 quantization, zero-value compression, and vertical fusion of operations, which collectively reduce memory usage, computation costs, and latency. Our framework supports both static and dynamic graphs, providing real-time updates without recompiling the model. Experimental results across various GNN models (GraphConv, GraphAttn, SAGE) demonstrate significant performance improvements, with GraNNite achieving up to a 17.3X speedup over GPU and a 10.8X speedup over CPU executions. These results highlight GraNNite's potential for optimizing GNN workloads on NPUs, achieving high performance and energy efficiency without requiring hardware modifications.