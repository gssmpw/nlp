\section{Conclusion}\label{sec:conclusion}
This work presents \textbf{\textit{GraNNite}}, a framework that optimizes GNN execution on NPUs using a three-step methodology. It addresses challenges like irregular memory access, dynamic graph updates, and control-heavy operations through hardware-aware optimizations. By improving parallelism, memory efficiency, and low-precision computation, GraNNite reduces overhead, latency, and energy consumption while preserving accuracy. These enhancements enable real-time GNN execution for applications such as knowledge graph queries and event-driven analytics. Experimental evaluations on Intel\textregistered\ Core\texttrademark\ Ultra Series 1 and 2 AI PCs show that GraNNite outperforms out-of-the-box NPU mappings and achieves significant energy efficiency gains over CPUs and GPUs. Its optimizations require no hardware modifications, ensuring scalability across diverse edge and accelerator platforms.
% This work presents \textbf{\textit{GraNNite}}, a framework that optimizes GNN execution on NPUs through a structured three-step methodology. The proposed optimizations address key challenges such as irregular memory access, dynamic graph updates, and inefficient execution of control-heavy operations by leveraging hardware-aware techniques. By transforming graph computations into more parallelizable forms, efficiently managing memory, and utilizing low-precision arithmetic, GraNNite significantly reduces computational overhead, memory usage, and inference latency while preserving model accuracy. These improvements enable real-time GNN execution with higher throughput and energy efficiency, making them practical for applications such as knowledge graph queries and event-driven analytics. Experimental evaluations on Intel Lunar Lake and Meteor Lake AI PCs demonstrate that GraNNite significantly outperforms default NPU mappings while achieving substantial energy efficiency gains over CPU and GPU implementations. Across various GNN models, GraNNite consistently delivers higher throughput, validating the effectiveness of NPUs for efficient GNN deployment. Importantly, these optimizations require no hardware modifications, ensuring scalability across diverse edge and accelerator platforms.
% This work introduces a comprehensive set of optimizations to enhance the performance of GNNs on NPUs. Key contributions include model graph partitioning, dynamic node and edge updates with node padding, and replacing control-heavy operations with data-parallel alternatives, enabling efficient computation. Techniques such as INT8 quantization and zero-value compression significantly reduce memory usage, computational overhead, and latency, all while preserving model accuracy. These optimizations collectively improve the energy efficiency and throughput of GNN workloads, making them more suitable for real-time applications in areas such as knowledge graph queries and event-driven tasks. By ensuring these advancements require no hardware modifications, this work provides a practical pathway to scalable and efficient GNN deployment across diverse edge and accelerator platforms.
