@inproceedings{faceformer2022,
    title={FaceFormer: Speech-Driven 3D Facial Animation with Transformers},
    author={Fan, Yingruo and Lin, Zhaojiang and Saito, Jun and Wang, Wenping and Komura, Taku},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}
@inproceedings{codetalker2023,
    title={Codetalker: Speech-driven 3d facial animation with discrete motion prior},
    author={Xing, Jinbo and Xia, Menghan and Zhang, Yuechen and Cun, Xiaodong and Wang, Jue and Wong, Tien-Tsin},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={12780--12790},
    year={2023}
}
@inproceedings{selftalk2023,
    title={SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces}, 
    author={Ziqiao Peng and Yihao Luo and Yue Shi and Hao Xu and Xiangyu Zhu and Hongyan Liu and Jun He and Zhaoxin Fan},
    booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
    pages = {5292–5301},
    doi = {10.1145/3581783.3611734},
    year={2023}
}
@inproceedings{facediffuser2023,
    title={Facediffuser: Speech-driven 3d facial animation synthesis using diffusion},
    author={Stan, Stefan and Haque, Kazi Injamamul and Yumak, Zerrin},
    booktitle={Proceedings of the 16th ACM SIGGRAPH Conference on Motion, Interaction and Games},
    pages={1--11},
    doi = {10.1145/3623264.3624447},
    year={2023}
}
@inproceedings{multitalk2024,
    title     = {MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset},
    author    = {Kim Sung-Bin and Lee Chae-Yeon and Gihun Son and Oh Hyun-Bin and Janghoon Ju and Suekyeong Nam and Tae-Hyun Oh},
    year      = {2024},
    booktitle = {Interspeech 2024},
    pages     = {1380--1384},
    doi       = {10.21437/Interspeech.2024-1794},
    issn      = {2958-1796},
}
@inproceedings{scantalk2024,
    title = {ScanTalk: 3D Talking Heads from Unregistered Scans},
    author = {Nocentini, F. and Besnier, T. and Ferrari, C. and Arguillere, S. and Berretti, S. and Daoudi, M.},
    booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
    year = {2024},
}
@article{diffposetalk2024,
    title={DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose Generation via Diffusion Models},
    author={Sun, Zhiyao and Lv, Tian and Ye, Sheng and Lin, Matthieu and Sheng, Jenny and Wen, Yu-Hui and Yu, Minjing and Liu, Yong-Jin},
    journal={ACM Transactions on Graphics (TOG)},
    doi={10.1145/3658221},
    volume={43},
    number={4},
    articleno={46},
    numpages={9},
    year={2024},
    publisher={ACM New York, NY, USA}
}
@inproceedings{voca2019,
    title = {Capture, Learning, and Synthesis of {3D} Speaking Styles},
    author = {Cudeiro, Daniel and Bolkart, Timo and Laidlaw, Cassidy and Ranjan, Anurag and Black, Michael},
    booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
    pages = {10101--10111},
    year = {2019},
    url = {http://voca.is.tue.mpg.de/}
}
@article{pytorch2017,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}
@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}
@inproceedings{richard2021meshtalk,
  title={Meshtalk: 3d face animation from speech using cross-modality disentanglement},
  author={Richard, Alexander and Zollh{\"o}fer, Michael and Wen, Yandong and De la Torre, Fernando and Sheikh, Yaser},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1173--1182},
  year={2021}
}
@article{FLAME2017, 
  title = {Learning a model of facial shape and expression from {4D} scans}, 
  author = {Li, Tianye and Bolkart, Timo and Black, Michael. J. and Li, Hao and Romero, Javier}, 
  journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)}, 
  volume = {36}, 
  number = {6}, 
  year = {2017}, 
  pages = {194:1--194:17},
  url = {https://doi.org/10.1145/3130800.3130813} 
}
@inproceedings{zhou2022codeformer,
    author = {Zhou, Shangchen and Chan, Kelvin C.K. and Li, Chongyi and Loy, Chen Change},
    title = {Towards Robust Blind Face Restoration with Codebook Lookup TransFormer},
    booktitle = {NeurIPS},
    year = {2022}
}
@inproceedings{neuraldiscrete2017,
    author = {van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
    title = {Neural discrete representation learning},
    year = {2017},
    isbn = {9781510860964},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
    pages = {6309–6318},
    numpages = {10},
    location = {Long Beach, California, USA},
    series = {NIPS'17}
}
@inproceedings{
    var2024,
    title={Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction},
    author={Keyu Tian and Yi Jiang and Zehuan Yuan and BINGYUE PENG and Liwei Wang},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=gojL67CfS8}
}


% Added by Nabarun
@inproceedings{alghamdi2022talking,
  title={Talking Head from Speech Audio using a Pre-trained Image Generator},
  author={Alghamdi, Mohammed M and Wang, He and Bulpitt, Andrew J and Hogg, David C},
  booktitle={ACM MM},
  pages={5228--5236},
  year={2022}
}

@inproceedings{chen2020talking,
  title={Talking-head generation with rhythmic head motion},
  author={Chen, Lele and Cui, Guofeng and Liu, Celong and Li, Zhong and Kou, Ziyi and Xu, Yi and Xu, Chenliang},
  booktitle={ECCV},
  pages={35--51},
  year={2020},
  organization={Springer}
}

@inproceedings{chung2017out,
  title={Out of time: automated lip sync in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={ACCV},
  pages={251--263},
  year={2017},
  organization={Springer}
}

@inproceedings{das2020speech,
  title={Speech-driven facial animation using cascaded gans for learning of motion and texture},
  author={Das, Dipanjan and Biswas, Sandika and Sinha, Sanjana and Bhowmick, Brojeshwar},
  booktitle={ECCV},
  pages={408--424},
  year={2020},
  organization={Springer}
}

@inproceedings{guo2021ad,
  title={Ad-nerf: Audio driven neural radiance fields for talking head synthesis},
  author={Guo, Yudong and Chen, Keyu and Liang, Sen and Liu, Yong-Jin and Bao, Hujun and Zhang, Juyong},
  booktitle={ICCV},
  pages={5784--5794},
  year={2021}
}

@inproceedings{ji2022eamm,
  title={Eamm: One-shot emotional talking face via audio-based emotion-aware motion model},
  author={Ji, Xinya and Zhou, Hang and Wang, Kaisiyuan and Wu, Qianyi and Wu, Wayne and Xu, Feng and Cao, Xun},
  booktitle={ACM SIGGRAPH},
  pages={1--10},
  year={2022}
}

@inproceedings{ji2021audio,
  title={Audio-driven emotional video portraits},
  author={Ji, Xinya and Zhou, Hang and Wang, Kaisiyuan and Wu, Wayne and Loy, Chen Change and Cao, Xun and Xu, Feng},
  booktitle={CVPR},
  pages={14080--14089},
  year={2021}
}

@inproceedings{liang2022expressive,
  title={Expressive talking head generation with granular audio-visual control},
  author={Liang, Borong and Pan, Yan and Guo, Zhizhi and Zhou, Hang and Hong, Zhibin and Han, Xiaoguang and Han, Junyu and Liu, Jingtuo and Ding, Errui and Wang, Jingdong},
  booktitle={CVPR},
  pages={3387--3396},
  year={2022}
}

@inproceedings{liu2022semantic,
  title={Semantic-aware implicit neural audio-driven video portrait generation},
  author={Liu, Xian and Xu, Yinghao and Wu, Qianyi and Zhou, Hang and Wu, Wayne and Zhou, Bolei},
  booktitle={ECCV},
  pages={106--125},
  year={2022},
  organization={Springer}
}

@inproceedings{pang2023dpe,
  title={Dpe: Disentanglement of pose and expression for general video portrait editing},
  author={Pang, Youxin and Zhang, Yong and Quan, Weize and Fan, Yanbo and Cun, Xiaodong and Shan, Ying and Yan, Dong-ming},
  booktitle={CVPR},
  pages={427--436},
  year={2023}
}

@inproceedings{prajwal2020lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={ACM MM},
  pages={484--492},
  year={2020}
}

@inproceedings{shen2022learning,
  title={Learning dynamic facial radiance fields for few-shot talking head synthesis},
  author={Shen, Shuai and Li, Wanhua and Zhu, Zheng and Duan, Yueqi and Zhou, Jie and Lu, Jiwen},
  booktitle={ECCV},
  pages={666--682},
  year={2022},
  organization={Springer}
}

@article{vougioukas2020realistic,
  title={Realistic speech-driven facial animation with gans},
  author={Vougioukas, Konstantinos and Petridis, Stavros and Pantic, Maja},
  journal={International Journal of Computer Vision},
  volume={128},
  pages={1398--1413},
  year={2020},
  publisher={Springer}
}

@inproceedings{wang2022one,
  title={One-shot talking face generation from single-speaker audio-visual correlation learning},
  author={Wang, Suzhen and Li, Lincheng and Ding, Yu and Yu, Xin},
  booktitle={AAAI},
  volume={36},
  number={3},
  pages={2531--2539},
  year={2022}
}

@article{yi2020audio,
  title={Audio-driven talking face video generation with learning-based personalized head pose},
  author={Yi, Ran and Ye, Zipeng and Zhang, Juyong and Bao, Hujun and Liu, Yong-Jin},
  journal={arXiv preprint arXiv:2002.10137},
  year={2020}
}

@inproceedings{zhang2023metaportrait,
  title={Metaportrait: Identity-preserving talking head generation with fast personalized adaptation},
  author={Zhang, Bowen and Qi, Chenyang and Zhang, Pan and Zhang, Bo and Wu, HsiangTao and Chen, Dong and Chen, Qifeng and Wang, Yong and Wen, Fang},
  booktitle={CVPR},
  pages={22096--22105},
  year={2023}
}

@inproceedings{zhou2021pose,
  title={Pose-controllable talking face generation by implicitly modularized audio-visual representation},
  author={Zhou, Hang and Sun, Yasheng and Wu, Wayne and Loy, Chen Change and Wang, Xiaogang and Liu, Ziwei},
  booktitle={CVPR},
  pages={4176--4186},
  year={2021}
}
@inproceedings{
    tevet2023human,
    title={Human Motion Diffusion Model},
    author={Guy Tevet and Sigal Raab and Brian Gordon and Yoni Shafir and Daniel Cohen-or and Amit Haim Bermano},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=SJ1kSyO2jwu}
}
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{ma2024diffspeaker,
  publtype={informal},
  author={Zhiyuan Ma and Xiangyu Zhu and Guojun Qi and Chen Qian and Zhaoxiang Zhang and Zhen Lei},
  title={DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer},
  year={2024},
  cdate={1704067200000},
  journal={CoRR},
  volume={abs/2402.05712},
  url={https://doi.org/10.48550/arXiv.2402.05712}
}

@article{zhang2024letstalk,
  title={LetsTalk: Latent Diffusion Transformer for Talking Video Synthesis},
  author={Zhang, Haojie and Liang, Zhihao and Fu, Ruibo and Wen, Zhengqi and Liu, Xuefei and Li, Chenxing and Tao, Jianhua and Liang, Yaling},
  journal={arXiv preprint arXiv:2411.16748},
  year={2024}
}

@ARTICLE{Zhuang2024learn2talk,
  author={Zhuang, Yixiang and Cheng, Baoping and Cheng, Yao and Jin, Yuntao and Liu, Renshuai and Li, Chengyang and Cheng, Xuan and Liao, Jing and Lin, Juncong},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Learn2Talk: 3D Talking Face Learns from 2D Talking Face}, 
  year={2024},
  volume={},
  number={},
  pages={1-13},
  keywords={Three-dimensional displays;Faces;Facial animation;Solid modeling;Lips;Face recognition;Feature extraction;Avatars;Mouth;Image reconstruction;Speech-driven;3D Facial Animation;2D Talking face;Transformer;3D Gaussian Splatting},
  doi={10.1109/TVCG.2024.3476275}}

@inproceedings{wu2024mmhead,
  title={MMHead: Towards Fine-grained Multi-modal 3D Facial Animation},
  author={Wu, Sijing and Li, Yunhao and Yan, Yichao and Duan, Huiyu and Liu, Ziwei and Zhai, Guangtao},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={7966--7975},
  year={2024}
}
@inproceedings{aneja2023facetalk,
      author={Shivangi Aneja and Justus Thies and Angela Dai and Matthias Nießner},
      title={FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models}, 
      booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
      year={2024},
}
@article{edwards2016jali,
  title={Jali: an animator-centric viseme model for expressive lip synchronization},
  author={Edwards, Pif and Landreth, Chris and Fiume, Eugene and Singh, Karan},
  journal={ACM Transactions on graphics (TOG)},
  volume={35},
  number={4},
  pages={1--11},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@incollection{xu2013practical,
  title={A practical and configurable lip sync method for games},
  author={Xu, Yuyu and Feng, Andrew W and Marsella, Stacy and Shapiro, Ari},
  booktitle={Proceedings of Motion on Games},
  pages={131--140},
  year={2013}
}
@inproceedings{taylor2012dynamic,
  title={Dynamic units of visual speech},
  author={Taylor, Sarah L and Mahler, Moshe and Theobald, Barry-John and Matthews, Iain},
  booktitle={Proceedings of the 11th ACM SIGGRAPH/Eurographics conference on Computer Animation},
  pages={275--284},
  year={2012}
}
@article{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@techreport{kyutai2024moshi,
    author = {Alexandre D\'efossez and Laurent Mazar\'e and Manu Orsini and Am\'elie Royer and Patrick P\'erez and Herv\'e J\'egou and Edouard Grave and Neil Zeghidour},
    title = {Moshi: a speech-text foundation model for real-time dialogue},
    institution = {Kyutai},
    year={2024},
    month={September},
    url={http://kyutai.org/Moshi.pdf},
}
@article{sharp2022diffusionnet,
  title={Diffusionnet: Discretization agnostic learning on surfaces},
  author={Sharp, Nicholas and Attaiki, Souhaib and Crane, Keenan and Ovsjanikov, Maks},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={3},
  pages={1--16},
  year={2022},
  publisher={ACM New York, NY}
}

@inproceedings{DECA2021,
  title={Learning an Animatable Detailed {3D} Face Model from In-The-Wild Images},
  author={Feng, Yao and Feng, Haiwen and Black, Michael J. and Bolkart, Timo},
  journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH)}, 
  volume = {40}, 
  number = {8}, 
  year = {2021}, 
  url = {https://doi.org/10.1145/3450626.3459936} 
}

@inproceedings{MICA2022,
  title = {Towards Metrical Reconstruction of Human Faces},
  author = {Zielonka, Wojciech and Bolkart, Timo and Thies, Justus},
  booktitle = {European Conference on Computer Vision},
  pages = {20311--20322},
  year = {2022}
}

@inproceedings{EMOCA2021,
  title = {{EMOCA}: {E}motion Driven Monocular Face Capture and Animation},
  author = {Danecek, Radek and Black, Michael J. and Bolkart, Timo},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {20311--20322},
  year = {2022}
}

@inproceedings{
    gpavatar2024,
    title={{GPA}vatar: Generalizable and Precise Head Avatar from Image(s)},
    author={Xuangeng Chu and Yu Li and Ailing Zeng and Tianyu Yang and Lijian Lin and Yunfei Liu and Tatsuya Harada},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
}

@inproceedings{
    chu2024gagavatar,
    title={Generalizable and Animatable Gaussian Head Avatar},
    author={Xuangeng Chu and Tatsuya Harada},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=gVM2AZ5xA6}
}

@article{
    deng2024portrait4d2,
    title={Portrait4D-v2: Pseudo Multi-View Data Creates Better 4D Head Synthesizer},
    author={Deng, Yu and Wang, Duomin and Wang, Baoyuan},
    journal={arXiv preprint arXiv:2403.13570},
    year={2024}
}
@inproceedings{
    xu2023gaussianheadavatar,
    title={Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic Gaussians},
    author={Xu, Yuelang and Chen, Benwang and Li, Zhe and Zhang, Hongwen and Wang, Lizhen and Zheng, Zerong and Liu, Yebin},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2024}
}
@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1501--1510},
  year={2017}
}

@inproceedings{danvevcek2023emotional,
  title={Emotional speech-driven animation with content-emotion disentanglement},
  author={Dan{\v{e}}{\v{c}}ek, Radek and Chhatre, Kiran and Tripathi, Shashank and Wen, Yandong and Black, Michael and Bolkart, Timo},
  booktitle={SIGGRAPH Asia 2023 Conference Papers},
  pages={1--13},
  year={2023}
}

@InProceedings{emotalk2023,
    author    = {Peng, Ziqiao and Wu, Haoyu and Song, Zhenbo and Xu, Hao and Zhu, Xiangyu and He, Jun and Liu, Hongyan and Fan, Zhaoxin},
    title     = {EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {20687-20697}
}
@inproceedings{yang2024probabilistic,
  title={Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks Methods and Applications},
  author={Yang, Karren D and Ranjan, Anurag and Chang, Jen-Hao Rick and Vemulapalli, Raviteja and Tuzel, Oncel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27294--27303},
  year={2024}
}

@inproceedings{tan2024say,
  title={Say Anything with Any Style},
  author={Tan, Shuai and Ji, Bin and Ding, Yu and Pan, Ye},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={5088--5096},
  year={2024}
}
@inproceedings{zhang2023sadtalker,
  title={Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation},
  author={Zhang, Wenxuan and Cun, Xiaodong and Wang, Xuan and Zhang, Yong and Shen, Xi and Guo, Yu and Shan, Ying and Wang, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8652--8661},
  year={2023}
}
@article{ye2024real3d,
  title={Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis},
  author={Ye, Zhenhui and Zhong, Tianyun and Ren, Yi and Yang, Jiaqi and Li, Weichuang and Huang, Jiawei and Jiang, Ziyue and He, Jinzheng and Huang, Rongjie and Liu, Jinglin and others},
  journal={arXiv preprint arXiv:2401.08503},
  year={2024}
}
@article{yi2022predicting,
  title={Predicting personalized head movement from short video and speech signal},
  author={Yi, Ran and Ye, Zipeng and Sun, Zhiyao and Zhang, Juyong and Zhang, Guoxin and Wan, Pengfei and Bao, Hujun and Liu, Yong-Jin},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={6315--6328},
  year={2022},
  publisher={IEEE}
}
@inproceedings{zhu2023taming,
  title={Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation},
  author={Zhu, Lingting and Liu, Xian and Liu, Xuanyu and Qian, Rui and Liu, Ziwei and Yu, Lequan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10544--10553},
  year={2023}
}

@article{alexanderson2023listen,
  title={Listen, denoise, action! audio-driven motion synthesis with diffusion models},
  author={Alexanderson, Simon and Nagy, Rajmund and Beskow, Jonas and Henter, Gustav Eje},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--20},
  year={2023},
  publisher={ACM New York, NY, USA}
}