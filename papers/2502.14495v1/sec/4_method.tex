\section{Methodology}\label{sec:4}
As shown in Figure~\ref{fig:C1}, we propose \textbf{HUCLNet}, a hybrid-level contrastive learning framework aimed at addressing the challenges of nearshore UTD. 
HUCLNet comprises two primary components: the RGC module and the HLCL module.
\par
In the RGC module, the input HSI is decomposed into individual pixels, which are clustered using an unsupervised method. 
A reference spectrum selects a specific cluster, and a novel reliability criterion is introduced to classify clusters into reliable and unreliable instances.
Building on this, the HLCL module leverages contrastive learning to enhance feature discrimination at both the prototype and instance levels. 
\par
HUCLNet operates in two alternating steps: 
(1) Assigning pixel features to clusters and classifying reliable clusters and unreliable instances through a self-paced learning framework (Section \ref{sec3.2}); 
(2) Optimizing spatial-spectral feature extractors using hybrid contrastive learning, progressively updating pixel feature representations through encoded features (Section \ref{sec3.1}).
\par
\subsection{Reliability-Guided Clustering}\label{sec3.2}
The primary objective of HUCLNet is to establish a discriminative feature space where underwater target spectra align with a reference spectrum while remaining distinctly separated from the background through contrastive learning. 
In the absence of supervision to classify pixels in the input HSI as target or background, unsupervised clustering is employed to infer categorical information. 
To address the specific challenges of HUTD, where the reference spectrum is the only prior knowledge, a reference spectrum-guided clustering method is introduced. 
This method incorporates the reference spectrum to enhance clustering reliability, facilitating a more precise distinction between underwater targets and background.

Accurate clustering improves HUTD performance by providing the categorical information essential for the hybrid-level contrastive learning module. 
However, as shown in Figure~\ref{fig:C3} (a), clustering often exhibits poor compactness, particularly in early training stages when feature representations lack discriminability. 
This results in clusters containing noisy samples, especially those far from cluster prototypes. 
Incorporating these noisy samples directly into the HLCL module risks degrading its performance and stability. 
To address this, refining clustering results by distinguishing reliable from unreliable clusters is crucial. 
We propose a cluster reliability criterion that evaluates cluster consistency by measuring distances to classifier decision boundaries, based on classifier discrepancy maximization.

Based on these insights, we propose the RGC module, which integrates three key components: the reference spectrum-guided clustering method, the classifier discrepancy maximization rule, and the cluster reliability criterion.

\subsubsection{Reference Spectrum-based Clustering Method}\label{sec3.2.1}
In the nearshore HUTD task, the target regions are limited in spatial extent compared to the extensive background, resulting in significant data imbalance, with far fewer target pixels than background pixels. 
This imbalance poses challenges for model training and generalization. 
However, nearshore areas with shallow waters and varied seabed types exhibit a wide range of spectral characteristics in the background. 
These variations enable the background to be subdivided into multiple distinct types, transforming the \emph{binary target-background} classification problem into a \emph{multi-class target-background} classification problem.

A straightforward method to categorize training samples without supervision is to apply an unsupervised clustering algorithm, such as K-Means~\cite{Sinaga2020}. 
However, conventional clustering algorithms fail to leverage the reference spectrum as prior knowledge. 
To address this, we propose incorporating the reference spectrum as a fixed prototype in the clustering process. 
Building on the DeepCluster approach~\cite{caron2018deep}, we introduce the Reference Spectrum-based Clustering (RSC) method, which explicitly integrates the reference spectrum to improve clustering accuracy and reliability.
\par 
\begin{figure}[!t]                  
    \centering                    
    \includegraphics[width=1\columnwidth]{images/A5.jpg}                     
    \caption{The illustration of classifier discrepancy maximum rule.}                  
    \label{fig:C3}    
\end{figure}
Given a training sample set $\mathbb{X} = \{\bm{x}_1, \bm{x}_2, \cdots, \bm{x}_n\}$, the RSC method uses the corresponding transformed features $\{\bm{h}_1, \bm{h}_2, \cdots, \bm{h}_n\}$ as inputs, obtained through a transformation function $G(\cdot)$, where $\bm{h}_i = G(\bm{x}_i)$. 
The transformation function $G(\cdot)$ is defined as follows, depending on the training epoch:
\begin{equation}\label{eq:transformation}
    G(\bm{x}_i) = 
    \begin{cases}
        \mathcal{I} (\bm{x}_i), & \text{if epoch} = 1, \\
        F(\bm{x}_i|\Theta), & \text{if epoch} > 1,
    \end{cases}
\end{equation}
where $\mathcal{I} (\cdot)$ is the identity mapping function, and $F(\cdot|\Theta)$ represents the backbone network within the hybrid contrastive learning framework. 
In the first training epoch, the identity mapping function $\mathcal{I} (\cdot)$ is used because the feature extraction network is randomly initialized and cannot effectively extract spectral feature vectors at this stage. 
Thus, raw spectral features are employed for unsupervised clustering to avoid negative impacts from the underdeveloped network.
\par
The goal of The RSC method partitions the samples into $k+1$ distinct groups based on an assignment criterion. Specifically, it determines the prototype matrix $\mathbb{P} = \{\bm{p}_1, \bm{p}_2, \cdots, \bm{p}_k\}$ and cluster assignments $\bm{a}_i = \{a_1, a_2, \cdots, a_{k+1}\}$ for each sample $\bm{x}_i$ by solving the following optimization problem:
\begin{equation}
    \begin{gathered} \label{cluster}
        \min_{\mathbb{P}} \frac{1}{n} \sum_{i=1}^n \min_{\bm{a}_i \in \{0,1\}^{k+1}} \left\| \bm{h}_i - \{\mathbb{P}, \text{stopgrad}(\bm{h}_{\text{ref}})\} \cdot \bm{a}_i \right\|_2^2, \\
        \text{s.t.} \quad \bm{a}_i^{\top} \bm{1}_{k+1} = 1,
    \end{gathered}
\end{equation}
where $\bm{1}_{k+1}$ is a vector of ones of dimension $k+1$, and $\bm{h}_{\text{ref}} = G(\bm{x}_{\text{ref}})$ represents the transformed feature of the reference spectrum $\bm{x}_{\text{ref}}$. The term $\text{stopgrad}(\bm{h}_{\text{ref}})$ ensures the reference spectrum's transformed feature is treated as a fixed constant during training. To prevent trivial solutions, such as assigning all samples to a single cluster, an equipartition constraint~\cite{caron2020unsupervised} is applied.

\subsubsection{Classifier Discrepancy Maximization Rule}\label{sec:3.2.2}
Unreliable samples are typically located near decision boundaries~\cite{Hearst1998}. As shown in Figure~\ref{fig:C3} (b), these can be identified where decision boundaries of two classifiers, trained on the same dataset, exhibit discrepancies. Larger discrepancy regions help identify a broader set of unreliable samples, in line with the principle of "preferring quality over quantity." To refine clustering results, we propose a classifier discrepancy maximization rule, illustrated in Figure~\ref{fig:C3} (c), which maximizes the cross-entropy between the outputs of two classifiers while maintaining a consistency constraint to improve classification reliability.

The pseudo-labels $\mathbb{Y} = \{y_1, y_2, \dots, y_n\}$ for the training samples are derived from the clustering results, where $y_i = \arg\max_{i \in \{1, 2, \dots, k+1\}} a_i$. Considering two classifiers, $\bm{C}_1$ and $\bm{C}_2$, sharing the same architecture but with different initial weights, the probabilistic outputs for sample $\bm{x}_i$ are $\bm{q}_1^i \triangleq \bm{C}_1(\bm{x}_i)$ and $\bm{q}_2^i \triangleq \bm{C}_2(\bm{x}_i)$. To maximize decision boundary discrepancies between $\bm{C}_1$ and $\bm{C}_2$, we maximize the cross-entropy between their outputs, $\{\bm{C}_j(\bm{x}_i)\}_{j=1}^2$, while applying a prediction consistency constraint to prevent misclassification of reliable samples. The classifier discrepancy maximization rule is formulated as:
\begin{multline}\label{rule}
    \arg\max_{\bm{C}_1, \bm{C}_2} \sum_{i = 1}^{n} \Big(CE(\bm{q}_1^i, \bm{q}_2^i) + CE(\bm{q}_2^i, \bm{q}_1^i) \\ - CE(\mathbb{Y}, \bm{q}_1^i) - CE(\mathbb{Y}, \bm{q}_2^i)\Big),
\end{multline}
where $CE(\bm{m}, \bm{n})$ denotes the cross-entropy between distributions $\bm{m}$ and $\bm{n}$, defined as:
\begin{equation}
    CE(\bm{m}, \bm{n}) = \sum_{k = 1}^{K} m_k \log(n_k),
\end{equation}
with $K$ being the dimension of the distribution vector, and $m_k$ and $n_k$ representing the $k$-th elements of $\bm{m}$ and $\bm{n}$, respectively.
\subsubsection{Cluster Refinement Strategy}
As outlined in Section \ref{sec:3.2.2}, samples near the decision boundaries of two classifiers are prone to unreliability. Therefore, classifier disagreement, as specified by the rule in Eq. (\ref{rule}), serves as a mechanism to identify unreliable samples within a cluster. The reliability of a training sample $\bm{x}_i$ is quantified using the following criterion:
\begin{equation}\label{Cluster Reliability Criterion}
    \varrho_{i} = 
    \begin{cases}
        1, & \text{if } [\bm{C}_1(\bm{x}_i)]_{\max} = [\bm{C}_2(\bm{x}_i)]_{\max}, \\        
        0, & \text{if } [\bm{C}_1(\bm{x}_i)]_{\max} \neq [\bm{C}_2(\bm{x}_i)]_{\max}. 
    \end{cases}
\end{equation}
Here, $[\cdot]_{\max}$ denotes the index of the maximum value in the vector, and $\varrho_{i}$ serves as the reliability indicator. A value of $\varrho_{i} = 1$ indicates that the sample $\bm{x}_i$ is reliable. This criterion refines the clustering outcomes from Eq. (\ref{cluster}), partitioning the training samples $\mathbb{X}$ into reliable clusters $\mathbb{X}_c = \{\mathbb{X}_{c_1}, \dots, \mathbb{X}_{c_t}\}$, where $t \leq k+1$ is the number of reliable clusters, and unreliable instances $\mathbb{X}_u$. Consequently, $\mathbb{X}_c \cup \mathbb{X}_u = \mathbb{X}$.
\par
\subsection{Hybrid-Level Contrastive Learning}\label{sec3.1}
As discussed in Section~\ref{sec:1}, nearshore Hyperspectral Underwater Target Detection (HUTD) faces two main challenges: \emph{dependence on bathymetric models} and \emph{limited target characterization}. 
To address these challenges, we introduce a hybrid-level contrastive learning framework that integrates instance-level and prototype-level contrastive learning modules. 
Data augmentation is a critical aspect of contrastive learning, but conventional methods, which primarily focus on spatial transformations, often compromise the spectral integrity of hyperspectral data. 
To counter this, we propose a hyperspectral-specific data augmentation strategy that incorporates unsupervised adversarial training, ensuring the effective preservation and utilization of both spatial and spectral information.

The architecture of the proposed framework is illustrated in Figure~\ref{fig:C1}. Each module comprises two branches: a shared backbone network, $F(\cdot|\Theta_{x})$, and a projection MLP head, $h_{x}(\cdot|\bm{W}_x)$, where $x = \{I, C\}$ denotes the instance-level or prototype-level module. 
To capture coarse-to-fine contrastive semantic information, the backbone networks are shared across modules, \emph{i.e.}, $\Theta_{I} = \Theta_{C}$. For simplicity, we denote all backbone networks as $F(\cdot|\Theta)$ throughout the article, implemented using 3D-ResNet50~\cite{Jiang2019} for feature extraction. The projection MLP head predicts one view based on the output of the other, facilitating contrastive learning. Both modules adopt identical projection MLP structures~\cite{ChenH21}, without weight sharing.

\subsubsection{Instance-Level Contrastive Learning}\label{sec3.1.1}
The instance-level contrastive learning module addresses the challenge of unreliable instances, typically distant from cluster prototypes due to their poor discriminability.  
It treats each unreliable instance as a separate class, enhancing the model's ability to capture explicit similarities and differences among instances~\cite{Wu2018}.  
This facilitates the extraction of more discriminative feature representations, ensuring sufficient discriminability for the unsupervised clustering strategy in Section~\ref{sec3.2.1}.  
Additionally, this module strengthens the model's ability to characterize targets, providing a robust semantic foundation for the subsequent prototype-level contrastive learning stage.
Let $\bm{x}_{u}^{i} \in \mathbb{X}_{u}$ represent an example, where two augmented views $\hat{\bm{x}}_{u}^{i}$ and $\tilde{\bm{x}}_{u}^{i}$ are generated using the augmentation strategy (see Section \ref{sec3.1.3}). These views are passed through distinct branches, producing output vectors $\bm{\hat{\bm{p}}}^{i}_{u} \triangleq h_{I}(F(\hat{\bm{x}}_{u}^{i}|\Theta)|\bm{W}_I)$ and $\tilde{\bm{z}}_{u}^{i} \triangleq F(\tilde{\bm{x}}_{u}^{i}|\Theta)$. The view prediction error is measured by negative cosine similarity, given by:
\begin{equation}\label{eq:1}
    \mathcal{D}\left(\bm{\hat{\bm{p}}}^{i}_{u}, \tilde{\bm{z}}_{u}^{i}\right) = -\frac{\bm{\hat{\bm{p}}}^{i}_{u}}{\left\|\bm{\hat{\bm{p}}}^{i}_{u}\right\|_2} \cdot \frac{\tilde{\bm{z}}_{u}^{i}}{\left\|\tilde{\bm{z}}_{u}^{i}\right\|_2},
\end{equation}
where $\|\cdot\|_2$ denotes the $\ell_2$-norm. The objective function for the instance-level contrastive learning module is a symmetrized loss:
\begin{equation}\label{eq:2}
    \mathcal{L}_{\text{instance}} = \frac{1}{2} \mathcal{D}\left(\bm{\hat{\bm{p}}}^{i}_{u}, \tilde{\bm{z}}_{u}^{i}\right) + \frac{1}{2} \mathcal{D}\left(\bm{\tilde{\bm{p}}}^{i}_{u}, \hat{\bm{z}}_{u}^{i}\right).
\end{equation}
To prevent model collapse, a stop-gradient operation is applied, reformulating Eq. (\ref{eq:1}) as:
\begin{equation}\label{eq:3}     
    \mathcal{D}\left(\bm{\hat{\bm{p}}}^{i}_{u}, \text{stopgrad}(\tilde{\bm{z}}_{u}^{i})\right),
\end{equation}
where $\text{stopgrad}(\cdot)$ acts as a constant during optimization. The updated learning objective is:
\begin{equation}\label{eq:4}
    \mathcal{L}_{\text{instance}} = \frac{1}{2} \mathcal{D}\left(\bm{\hat{\bm{p}}}^{i}_{u}, \text{stopgrad}(\tilde{\bm{z}}_{u}^{i})\right) + \frac{1}{2} \mathcal{D}\left(\bm{\hat{\bm{z}}}^{i}_{u}, \text{stopgrad}(\tilde{\bm{p}}_{u}^{i})\right).
\end{equation}

\subsubsection{Prototype-Level Contrastive Learning}\label{sec3.1.2}
The prototype-level contrastive learning module enhances the semantic consistency of target representations by aligning homogeneous samples within reliable clusters, thereby improving the separation between target and background clusters.  
Let $\bm{x}_{c_m}^{i}$ denote the $i$-th pixel within the $m$-th reliable cluster $\mathbb{X}_{c_m}$, with $\bar{\bm{x}}_{c_m}$ as its corresponding prototype. These samples are processed through separate branches, yielding output vectors $\bm{p}^{i}_{c_{m}} \triangleq h_{C}(F(\bm{x}^{i}_{c_m}|\Theta)|\bm{W}_C)$ and $\bar{\bm{z}}_{c_{m}} \triangleq F(\bar{\bm{x}}_{c_m}|\Theta)$.

In contrast to instance-level learning, the prototype $\bar{\bm{x}}_{c_m}$ serves as a stationary reference during the alignment process to ensure stable convergence. The view prediction loss is given by:
\begin{equation}\label{eq:5}   
    \mathcal{D}\left(\bm{p}^{i}_{c_{m}}, \bar{\bm{z}}_{c_{m}}\right)=-\frac{\bm{p}^{i}_{c_{m}}}{\left\|\bm{p}^{i}_{c_{m}}\right\|_2} \cdot \frac{\bar{\bm{z}}_{c_{m}}}{\left\|\bar{\bm{z}}_{c_{m}}\right\|_2},
\end{equation}
with the loss for cluster pre-alignment defined as:
\begin{equation}\label{eq:6} 
    \mathcal{L}_{cluster}^{pre} = \mathcal{D}\left(\bm{p}^{i}_{c_{m}}, \text{stopgrad}(\bar{\bm{z}}_{c_{m}})\right).
\end{equation}
To enhance inter-cluster discrepancy, we apply the InfoNCE loss to the prototypes $\{\bar{\bm{x}}_{c_1}, \dots, \bar{\bm{x}}_{c_t}\}$:
\begin{equation}\label{eq:7} 
    \resizebox{0.89\hsize}{!}{$\mathcal{L}_{cluster}^{pro}=-\sum_{i=1}^t\log \frac{\exp (\bar{\bm{x}}_{c_i} \cdot \bar{\bm{x}}_{c_i}^{+} / \tau)} {\sum_{j=1}^t \left(\exp (\bar{\bm{x}}_{c_i} \cdot \bar{\bm{x}}_{c_j} / \tau) + \exp (\bar{\bm{x}}_{c_j} \cdot \bar{\bm{x}}_{c_j}^{+} / \tau)\right)}.$}
\end{equation}
\par
The overall objective for the prototype-level contrastive learning module is the linear combination:
\begin{equation}\label{eq:8} 
    \mathcal{L}_{cluster} = \mathcal{L}_{cluster}^{pre} + \mathcal{L}_{cluster}^{pro}.
\end{equation}
\begin{figure}[!ht]                  
    \centering                    
    \includegraphics[width=1\columnwidth]{images/A4-1.jpg}                     
    \caption{Illustration of spectral distortion induced by the flipping augmentation operation. The augmented target spectrum exhibits minimal deviation from the background spectrum, yet demonstrates a pronounced discrepancy from the original target spectrum.}              
    \label{fig:aug}    
\end{figure}
\subsubsection{Hyperspectral-Oriented Data Augmentation}\label{sec3.1.3}
Traditional data augmentation techniques, such as flipping, rotation, and masking, can compromise spectral integrity~\cite{Liu12024}. For instance, flipping along the spectral dimension alters the spectral semantics, potentially transforming a target spectrum into a background one, as shown in Figure~\ref{fig:aug}. 
To address this, we propose a hyperspectral-specific data augmentation strategy, illustrated in Figure~\ref{fig:C2}. This strategy includes two stages: unsupervised pretraining and self-supervised adversarial training.

\begin{figure*}[!t]             
    \centering               
    \includegraphics[width=2\columnwidth]{images/A4.jpg}                
    \caption{The process of using adversarial training for hyperspectral data augmentation.}             
    \label{fig:C2}   
\end{figure*}
\textbf{Unsupervised Pretraining.} To ensure semantic consistency between the augmented and original samples, we introduce an encoder-decoder network. 
The encoder $F(\cdot|\Theta)$ extracts a discriminative representation $\bm{z}$, and the decoder $g(\cdot|\bm{W})$ reconstructs the original pixel. The optimization objective for the unsupervised pretraining is:
\begin{equation}\label{eq:8-1}
    \Theta^{\ast}, \bm{W}^{\ast} = \arg\min\limits_{\Theta, \bm{W}} ||g(\bm{z}|\bm{W}) - \bm{x}||_2.
\end{equation}
For augmented samples, the reconstruction error is minimized as:
\begin{equation}\label{eq:10}
    \arg\min\limits_{\bm{\delta}} ||g(F(\bm{x}^{+}|\Theta)|\bm{W}) - \bm{x}||_2.
\end{equation}
This ensures that spectral semantics are preserved during augmentation, enhancing the quality of contrastive learning for hyperspectral data.
%  which are used as supervision signals for self-supervised adversarial training and to initialize the backbone of the hybrid-level contrastive learning module. Notably, $\Theta^{\ast}$ is fixed after the first training epoch, with subsequent epochs using $\Theta^{t-1}$ from the previous epoch. 
% This ensures updated data augmentation while only $\bm{W}$ is updated in later epochs.
\par
\textbf{Self-Supervised Adversarial Training.} 
Adversarial training effectively generates augmented samples by applying controlled perturbations to the original data. In this work, we incorporate an adversarial training stage to generate the perturbation $\bm{\delta}$. Unlike traditional adversarial training, which relies on downstream task outputs, we guide perturbation generation through latent feature discrepancies in a self-supervised manner.

The encoder $F(\cdot|\Theta)$, with pretrained weights $\Theta^{\ast}$, computes latent representations for the original pixel $\bm{x}$ and its perturbed version $\bm{x}^+$ as $\bm{z}_{\ast} \triangleq F(\bm{x}|\Theta^{\ast})$ and $\bm{z}_{\ast}^+ \triangleq F(\bm{x}^+|\Theta^{\ast})$. To minimize spectral distortion, the perturbation is constrained by an $\ell_p$-norm with an upper bound $\epsilon$, \emph{i.e.}, $||\bm{\delta}||_p \leq \epsilon$. Semantic consistency is further ensured by incorporating the constraint in Eq.~(\ref{eq:8-1}). The adversarial training objective is then formulated as:
\begin{equation}\label{eq:9}        
    \begin{gathered}      
        \bm{\delta}^{\ast} = \arg\max\limits_{\bm{\delta}} \left( ||\bm{z}^+_{\ast} - \bm{z}_{\ast}||_2 - ||g(\bm{z}^+_{\ast}|\bm{W}^{\ast}) - \bm{x}||_2 \right), \\
        \text{s.t.} \ ||\bm{\delta}||_p \leq \epsilon,
    \end{gathered}   
\end{equation}
where $||\cdot||_p$ denotes the $\ell_p$-norm, and $p$ corresponds to the attack method used. The optimization problem is solved using established attack algorithms, such as FGSM~\cite{GoodfellowSS14}, PGD~\cite{MadryMSTV18}, and FAB~\cite{Croce020}, enabling diverse data augmentations.
\par
% In summary, the complete learning process of the proposed hybrid-level contrastive learning framework is outlined in Algorithm~\ref{algorithm:01}.
\subsection{Self-Paced Learning Paradigm}\label{sec3.3}
The clustering results from Section~\ref{sec3.2} guide the HLCL module in Section~\ref{sec3.1}, facilitating more accurate target characterization. 
Simultaneously, the refined target characterization improves clustering performance, even under unsupervised conditions, establishing a mutually reinforcing relationship between clustering and target characterization. However, during early training, both clustering and target characterization are unreliable. Incorporating erroneous clustering information into the HLCL module or performing clustering with incomplete target representations may lead to error propagation, diminishing performance and stability of HUCLNet. To address this, we propose a Self-Paced Learning (SPL) paradigm that progressively improves clustering reliability as spatial-spectral feature extractors become more robust, stabilizing training and enhancing model performance.

The SPL paradigm alternates between the HLCL and RGC modules in a self-paced manner. Initially, the RGC module partitions the training samples into unreliable instances and reliable clusters, as detailed in Section~\ref{sec3.2}. According to the self-paced learning principle, the reliable clusters are treated as easy samples to enhance target characterization, while the unreliable instances serve as hard samples to refine pixel-level discriminability. Once the reliable clusters and unreliable instances are identified, they are passed into the HLCL module. The HLCL module then refines the spatial-spectral feature representations of the training samples, as explained in Section~\ref{sec3.1}. With these updated representations, the RGC module is invoked again to reassign the samples into reliable clusters and unreliable instances. This refined clustering outcome improves the feature learning capacity of the HLCL module, leading to more discriminative feature representations. These refined features, in turn, enable more accurate clustering results. The learning process alternates between the HLCL and target spectrum-guided clustering methods in a self-paced manner until convergence is achieved.

\subsection{Hyperspectral Underwater Target Detection}\label{sec3.4}
Upon completing the self-paced learning process, the refined spatial-spectral feature representations from the HLCL module can be used for underwater target detection. Let $\Theta^{\ast}$ denote the optimal network weights for the backbone network $F(\cdot|\Theta)$ within the HLCL module. The pixels of the input Hyperspectral Image (HSI) $\mathbb{X} = \{\bm{x}_1, \bm{x}_2, \dots, \bm{x}_n\}$ and the reference spectrum $\bm{x}_{\text{ref}}$ are processed through the backbone network to obtain their corresponding feature representations:
\begin{equation}
    \begin{gathered}
        \bm{Z} = \{F(\bm{x}_1|\Theta^{\ast }), F(\bm{x}_2|\Theta^{\ast }), \dots, F(\bm{x}_n|\Theta^{\ast })\}, \\
        \bm{z}_{\text{ref}} = F(\bm{x}_{\text{ref}}|\Theta^{\ast }).
    \end{gathered}
\end{equation}

The target detection task is reformulated as a pixel-wise similarity measurement between the feature representations $\bm{Z}$ of the input HSI and the reference spectrum $\bm{z}_{\text{ref}}$. This can be achieved using common hyperspectral target detection (HTD) algorithms, such as the Spectral Angle Mapper (SAM)~\cite{KRUSE1993145} and the Constrained Energy Minimization (CEM)~\cite{Manolakis2002}. The final detection results are expressed as:
\begin{equation}
    \bm{d} = \text{Detection}(\bm{Z}, \bm{z}_{\text{ref}}),
\end{equation}
where $\bm{d}$ denotes the detection outcomes for the input HSI, and $\text{Detection}(\cdot)$ refers to the chosen HTD algorithm.