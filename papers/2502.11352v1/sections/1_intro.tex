\section{Introduction}
\label{sec:intro}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\linewidth]{imgs/motivation_example.drawio.png}
    \caption{ This figure illustrates our framework for scoring and selecting trajectories in autonomous driving systems. Modern autonomous driving planners typically follow a propose-selection paradigm, where multiple candidate trajectories are first generated and then filtered through a scoring mechanism. As shown in the \textbf{Motion Plan Proposing} block, multiple trajectories (colored lines) are proposed as potential future paths for the autonomous vehicle. These candidates need to be evaluated and ranked to select the most suitable trajectory for execution. Our key contribution, the \textbf{Learning Scoring Rules} block, demonstrates how we learn interpretable scoring rules from human driving demonstration from NuPlan \cite{Karnchanachari2024TowardsLP}. Instead of manually crafting rules or using black-box scoring models, we develop a Scoring Logic Network (SLN) that automatically learns temporal logic rules from data (specific rules illustrated in Sec.~\ref{sec:logic_rules_discovered}). These learned rules are then deployed in the \textbf{Online Monitoring and Filtering} block, which continuously evaluates the proposed trajectories at 20 Hz following NuPlan's log frequency \cite{Karnchanachari2024TowardsLP} during operation. In the scene visualization, the ego vehicle is shown in gold, while other vehicles are represented in black, the curbs are marked in purple, and the driveable areas (lanes and intersections) are marked as pink and blue, respectively. Among the proposed trajectories, the green trajectory receives the highest score as it successfully maintains a safe distance from the curbs, while exhibiting appropriate curvature and comfort characteristics. All other colored trajectories are not selected for violating one or more learned rules, as detailed in Sec.~\ref{sec:logic_rules_discovered}. During the monitoring, following the setting in Planning Driver Model (PDM) \cite{Dauner2023CORL}, we assume that the future 4-second trajectories of other cars are known. The selected trajectory is then executed in the \textbf{Closed-Loop Simulation} block.
    }
    \label{fig:motivation_example}
    % \vspace{-0.9cm}
\end{figure}

Modern autonomous driving systems typically produce multiple potential plans \cite{Dauner2023CORL,hu2023planning,phan2022driving,jiang2022efficient,chen2024end}, as this parallel approach offers several key advantages: it allows the system to consider different driving modalities (such as aggressive or conservative behaviors), accounts for future uncertainties, and provides redundancy in case certain paths become infeasible. These generated plans then need to be evaluated through a scoring mechanism to select the most suitable one for execution.

The importance of effective scoring becomes even more apparent in complex autonomous driving systems, particularly in end-to-end approaches \cite{hu2023planning,chen2024end}. These systems often utilize large, intricate neural networks that incorporate elements of randomness, such as dropout or sampling from probability distributions. While powerful, such characteristics can make it challenging to predict the system's behavior consistently \cite{chen2024end}. By implementing interpretable scoring rules as a final evaluation layer, we can assess these generated plans against clear, understandable criteria, thereby introducing much-needed predictability and reliability to these complex systems. In essence, scoring techniques serve as a critical bridge, connecting the raw outputs of planning algorithms to the final, executable plans. This additional evaluation step helps mitigate the uncertainties inherent in complex planning systems, significantly enhancing the safety, efficiency, and overall performance of autonomous vehicles as they navigate through our highways and cities.

With real-world driving data available in datasets like NuPlan \cite{Karnchanachari2024TowardsLP}, most current learning methods focus on directly learning motion plan proposers rather than learning interpretable scoring mechanisms to evaluate these plans. We instead focus on learning scoring rules represented in temporal logic for evaluating autonomous driving plans, which assess and rank plans generated by motion plan proposers. These scoring rules capture the latent relationships between various driving rules and constraints; for example, if a vehicle has a safe time-to-collision with surrounding vehicles, it should always be subject to all comfort constraints. By applying these rules to the output of a motion planner, we can score and select desirable plans, ensuring that the planned paths adhere to safety standards and traffic regulations while maintaining optimal performance. Figure~\ref{fig:motivation_example} illustrates the learning process and how we might apply scoring rules.

In practice, building these scoring rules presents several significant challenges. First, \emph{the latent relationships and dependencies among various rules are often non-trivial}. For instance, while a vehicle is generally not permitted to exceed the speed limit, exceptions may exist in specific scenarios such as overtaking another vehicle. These nuanced dependencies make it challenging to create a comprehensive set of rules that account for all possible situations. Second, \emph{determining the optimal parameters for rules is a complex task}. For example, establishing appropriate thresholds for safe time-to-collision, comfortable acceleration, or acceptable steering angle requires careful consideration of multiple factors. These parameters must balance safety concerns with the need for efficient and smooth vehicle operation. Third, \emph{available demonstration data typically only showcases correct behavior and lacks sufficient examples of incorrect actions} \cite{Karnchanachari2024TowardsLP,akhauri2020enhanced,chen2024end}. Having only single-class (i.e., correct-behavior only) training data poses a significant challenge for learning scoring models, as they must learn to distinguish between acceptable and unacceptable behaviors without a sufficient number of explicit negative samples.

Our approach addresses these challenges through three interconnected key ideas. First, to capture latent relationships among driving rules, we introduce a learnable logic structure that seamlessly integrates temporal and propositional logic. Our structure can represent nuanced decisions such as when it is appropriate to exceed the speed limit for a safe overtaking maneuver. Second, we tackle the challenge of parameter optimization by letting the data speak for itself. Rather than relying on manual tuning, our system learns optimal rule parameters directly from driving demonstrations, leveraging the fully differentiable logic structure used to represent rules. Third, we overcome the limitation of learning from only positive examples through a novel regularization-constrained optimization framework that simultaneously rewards correct demonstration behaviors and restricts the space of acceptable ones.

We evaluate the efficacy of our learned scoring rules in NuPlan \cite{Karnchanachari2024TowardsLP} closed-loop simulations. These results demonstrate that our learned rules can effectively score and select desirable plans, outperforming both expert-crafted rules and neural network-based approaches when considering both interactive and non-interactive scenarios. We further show that the learned rules perform consistently well across different proposers, including PDM \cite{Dauner2023CORL}, PDM-Hybrid \cite{Dauner2023CORL}, ML-Prop \cite{Karnchanachari2024TowardsLP}, and a rule-based Acceleration-Time (AT) sampler \cite{jiang2022efficient}. In summary, our contributions are as follows:
\begin{itemize}
    \item We propose a novel learnable logic structure that discovers and captures latent relationships represented in temporal logic.
    \item We introduce a data-driven approach to optimize rule parameters, enabling the system to learn effective scoring rules from driving demonstrations.
    \item We present an optimization framework that allows the system to learn rules and parameters from human driving demonstrations, without requiring unsafe and rare accident examples.
    \item We demonstrate the effectiveness of our approach in scoring and selecting desirable plans via NuPlan closed-loop simulation, outperforming expert-crafted rules \cite{Dauner2023CORL} and neural network-based approaches \cite{jiang2022efficient} across various scenarios and proposers.
\end{itemize}