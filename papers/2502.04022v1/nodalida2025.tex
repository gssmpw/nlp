%
% File nodalida2025.tex
%
% Contact:  Sara Stymne
% Email:    sara.stymne@lingfil.uu.se
%
% Based on the instruction file for NoDaLiDa 2023 by Mark Fishel which in turn were
% Based on the instruction file for NoDaLiDa 2021 by Lilja Øvrelid which in turn were
% Based on the instruction file for NoDaLiDa 2019 by Barbara Plank and Mareike Hartmann which in turn were based on the instruction files from NoDaLiDa 2017 and 2015 by
% Beata Megyesi (beata.megyesi@lingfil.uu.se) and EACL 2014
% which in turn was based on the instruction files for previous 
% ACL and EACL conferences. The BibTeX file is based on NAACL 2019
% style files, which in turn are based on style files for ACL 2018 and NAACL 2018, which were
% Based on the style files for ACL-2015, with some improvements
%  taken from the NAACL-2016 style
% Based on the style files for ACL-2014, which were, in turn,
% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
% EACL-2009, IJCNLP-2008...
% Based on the style files for EACL 2006 by 
% e.agirre@ehu.es or Sergi.Balari@uab.es
% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{nodalida2025}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{todonotes}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage[hidelinks]{hyperref}
\setlist[enumerate]{itemsep=-1.5mm}

\aclfinalcopy % Uncomment this line for the final submission

%\title{Quantification of Biodiversity Data from Historical 
%Semi-structured 
%Surveys \\with LLM-based Best-Worst-Scaling }

\title{Quantification of Biodiversity from Historical Survey Text\\ with LLM-based Best-Worst Scaling}


% TH: Wieso werden die Autoren in der Review Copy im pdf gesetzt? Ist double blind review. Wurde da was am Template verändert?
%\author{Anonymous}

\author{Thomas Haider, Tobias Perschl, Malte Rehbein\\
  Chair of Computational Humanities \\
  University of Passau \\
  {\tt firstname.lastname@uni-passau.de}} 

%\author{Thomas Haider\\
%  Chair of Computational Humanities \\
%  University of Passau \\
%  {\tt email@domain} \\\And
%  Tobias Perschl\\
%  Chair of Computational Humanities \\
%  University of Passau \\
%    {\tt email@domain} \\\And
%  Malte Rehbein \\
%  Chair of Computational Humanities \\
%  University of Passau \\
%  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  %In this study, we evaluate methods for estimating 
  %species' occurrence frequencies 
  %from historical survey texts through quantity estimation. 
  In this study, we evaluate methods to determine 
  %biodiversity 
  %relative 
  the frequency of species via quantity estimation from historical survey text.
  To that end, we formulate classification tasks and finally show that this problem can be adequately framed as a regression task using Best-Worst Scaling (BWS) with Large Language Models (LLMs). 
  We test Ministral-8B, DeepSeek-V3, and GPT-4, finding that the latter two have reasonable agreement with humans and each other.
  We conclude that this approach is more cost-effective and similarly robust compared to a fine-grained multi-class approach, allowing automated quantity estimation across species. 
  %We find that ... and our case study shows that ... concluding that ...
\end{abstract}

%\section{Calls}

%Main Conference: \\ \url{https://www.nodalida-bhlt2025.eu/conference} \\
%EcoNLP Workshop: \\ \url{https://econlpws2025.di.unito.it/} \\


%\section{Overview}

\iffalse
\begin{enumerate}
    \item Intro: Problem Description
    \begin{itemize}
        \item Heute: Fragebögen, Citizen Science, z.B. Rote Liste (Datenaggregation)
        \item Historical Data: First (systematic) attempts at cataloging biodiversity through surveys
        \item Classification of Biodiversity from Text
        \item Automatically assess/extract the data 
        \item Heterogeneous text data, non-standardized expressions of frequency
        \item Quantify actual biodiversity from textual markers
        \item Identify robust features/classifiers for classification/regression to estimate quantity
        \item 
    \end{itemize}
\end{enumerate}
\fi


%***************************
%       INTRODUCTION
%***************************
\section{Introduction}
%\cite{RS:13} \\
%\citet{RS:13} showed that x.\\
%It was shown that x \citep{RS:13}. \\


Long-term observation data plays a vital role in shaping policies for preventing biodiversity loss caused by habitat destruction, climate change, pollution, or resource overexploitation \citep{dornelas_biodiv, hoque2024addressing}.
%\textcolor{purple}{Monitoring and accurate measurement of biodiversity over extended periods} provide invaluable insight into ecological trends.
However, these efforts depend on the availability of reliable and relevant historical data and robust analytical methods, a significant challenge due to the heterogeneity of records representing such data.

The available biodiversity data varies widely 
in resolution, ranging from detailed records (e.g., point occurrences, trait measurements) to aggregated compilations (e.g., Floras, taxonomic monographs) \cite{konig2019biodiversity}. Many projects, such as the \textit{Global Biodiversity Information Facility} (GBIF), focus largely on the disaggregated end of the spectrum, particularly with presence/absence data \cite{dorazio2011modern,iknayan2014detecting}. 
Furthermore, despite their utility, longitudinal 
data is largely confined to records from after 1970 \citep{Van_Goethem2021-z}, leaving significant historical gaps. 

Natural history collections and records from the archives of societies present valuable opportunities to extend data further back in time \citep{Johnson2011-ah, Bronnimann2018-jg}. 
Such sources are rich, but typically unstructured and require sophisticated extraction tools to produce meaningful quantitative information.
%These sources, often rich in unstructured data like text or images, require sophisticated extraction tools to produce meaningful insights. 
Recent advances in NLP have shown promising potential for retrieval-based biodiversity detection from 
(mostly scientific) literature \citep{Kommineni2024-ne,langer2024relation,lucking2022multiple}.

%Jede Zeile extra hier zerschießt das ganze Paper.
% https://arxiv.org/abs/2311.04929

%Despite its significance, longitudinal biodiversity data is typically confined to post-1970s sources \citep{Van_Goethem2021-zl}, leaving significant historical gaps. Historical sources such as natural history collections and records from the archives of societies offer valuable opportunities for extending datasets further back in time \citep{Johnson2011-ah, Bronnimann2018-jg}. 
%Such (text or image-based) sources 
%are rich in data but typically unstructured. This requires sophisticated extraction tools to produce meaningful insights from quantification. Initial research in this area leverages recent advances in NLP methods, enabling information retrieval based biodiversity detection in (scientific) literature \citep{Kommineni2024-ne,langer2024relation,lucking2022multiple}.

This paper focuses on evaluating methods for biodiversity quantification from 
semi-structured historical survey texts.
To achieve this, we 
test tasks to distill meaningful metrics from  textual information found in survey records. 
A particular focus lies on the feasibility of Best-Worst Scaling (BWS) with a Large Language Model (LLM) as an annotator, which promises
greater efficiency and cost-effectiveness compared to manual annotation
\cite{bagdon2024you}.
%\textcolor{red}{Diversity vs. Endangerment Status}
%Research Questions:}
In the following, we describe the data,
%and datafication process 
%(section~\ref{sec:data}),
outline the 
%operationalization of the 
tasks and machine learning methods, %(section~\ref{sec:tasks}),
and finally present a case study. 
%with brief discussion 
%(section~ \ref{sec:discussion}).

%Such text-based (or image) sources, 
%semi- or 






%Disaggregated data supports detailed population- or community-level analyses but lacks completeness for macroecological studies. Conversely, aggregated data provides broader temporal and spatial coverage at the cost of fine-grained ecological precision. 
%However, available longitudinal data is typically limited to post-1970s sources \citep{Van_Goethem2021-zl} and biodiversity data varies in resolution, balancing fine-grained precision and large-scale representativeness \cite{konig2019biodiversity}.


%. 
%Disaggregated data (e.g., point occurrences, trait measurements) enable detailed analyses of populations or communities but lack completeness at macroecological scales. Aggregated data (e.g., Floras, taxonomic monographs) offer broader temporal and spatial coverage but sacrifice fine-grained ecological detail
%. This 
%trade-off 
%is critical for macroecological inference and remains underexplored 
%beyond spatial contexts 
%, especially beyond presence/absence data \cite{dorazio2011modern,iknayan2014detecting}.
%A stronger consideration of aggregated data 
%(e.g., World Checklist of Selected Plant families [WCSP] [27] or Global Inventory of Floras and Traits [GIFT] [28]) 
%seems instrumental for establishing robust global baselines.




%By distilling meaningful metrics from qualitative survey records, our methods demonstrate the potential of machine learning to tackle ecological questions effectively.



% Diversity vs. Endangerment Status

%In this paper, we evaluate methods to determine biodiversity by quantitatively estimating data extracted from historical survey texts. To achieve this, we have designed and tested various classification tasks that aim to distill meaningful metrics from the qualitative information typically found in survey records. 

%Specifically, we want to test the feasibility of BWS with a large language model as an annotator, which promises to be much less expensive than manual annotation.

%These tasks not only highlight the potential for automated analysis but also underscore the versatility and adaptability of modern machine learning techniques in addressing ecological questions.

%By framing the biodiversity estimation problem as a regression task, we employ best-worst scaling and leverage the capabilities of large language models (LLMs) to produce accurate and reliable estimates. %Best-worst scaling is a comparative judgment technique that helps in ranking items by identifying the best and worst elements within a set. This approach is particularly useful for interpreting qualitative data and converting it into quantitative measures.

% Diversity vs. Endangerment Status


%\paragraph{Our contributions are as follows:} 
%\begin{itemize}
%    \item Exploring a variety of possible approaches for quantitatively measuring biodiversity in text
%    \item Contrib 2
%    \item Contrib 3
%\end{itemize}

%\paragraph{We measure the following:}
%\begin{itemize}
%    \item Species Richness: Counts the total number of different species in a given area (main task definition).
%    \item Species Evenness: Measures the relative abundance of each species, assessing how evenly individuals are distributed among species (case study).
%\end{itemize}


%\paragraph{Our hypotheses/RQs are as follows:} 
%\begin{itemize}
%    \item H 1 (true or not)
%    \item H 2 (true or not)
%    \item H 3 (true or not)
%\end{itemize}

%In the remainder of the paper, we describe the data and datafication process (section \ref{sec:data}), outline the 
%operationalization of the 
%tasks and machine learning methods (section \ref{sec:tasks}), and finally a case study with brief discussion.

%Quantity estimation, in the context of biodiversity, refers to the process of quantifying the presence, abundance, and distribution of various species within a given area. Historical survey texts, while rich in data, often present challenges due to their unstructured nature. These texts may include descriptions of species observations, habitat conditions, and other ecological factors that are recorded in a narrative format. Extracting meaningful quantitative data from such unstructured text requires sophisticated methods and tools.

%The remainder of the paper is structured as follows: In section \ref{sec:data} we describe the data and briefly outline the datafication process, in section \ref{sec:tasks} we outline the tasks and the annotation process, and in section \ref{sec:experiments} we document our experiments to arrive at robust classification and regression models to estimate biodiversity from our text data. Finally, in section \ref{sec:discussion} we provide a case study with concluding discussion.
%and outline future work in section \ref{sec:future}.



%Biodiversity is essential for the stability and resilience of ecosystems, as each species plays a unique role in maintaining ecological balance. However, biodiversity is under constant threat from factors such as habitat destruction, climate change, pollution, and overexploitation of resources (citation ?).

%Most projects for the integration of biodiversity data focus on the disaggregated end of the
%data spectrum (e.g., GBIF [6], Botanical Information Network and Ecology Network (BIEN)
%[26], sPlot [29], or TRY [7]). Given the above-mentioned trade-offs and their implications for
%large-scale coverage and representativeness of biodiversity data, a stronger consideration of
%aggregated data (e.g., World Checklist of Selected Plant families [WCSP] [27] or Global Inventory of Floras and Traits [GIFT] [28]) seems instrumental for establishing robust global baselines.

%However, this hinges on the availability of data, and robust methods to measure. 


%***************************
%           DATA
%***************************
\section{Data}\label{sec:data}

\begin{table*} 
\setlength{\aboverulesep}{1pt} % Reduce space above \midrule
\setlength{\belowrulesep}{2pt} % Reduce space below \midrule
    \centering\scriptsize
    \begin{tabular}{llccll}%{l|l||l|l||l|l}
    \toprule
    \textbf{Animal} & \textbf{Text} & \textbf{Binary} & \textbf{BWS} & \multicolumn{2}{l}{\textbf{Multi-Classification}}\\
    \midrule
        Ducks & Bedecken Isar-Strom, wie Amper und Moosach in ganzen Schwärmen. & 1 & 1.00 & 5 & \textsc{Abundant}\\ & \textit{Cover  Isar-stream, likewise Amper and Moosach in whole swarms.} &&& \\ \midrule
        %Eurasian Otter & Ziemlich häufig an der Altmühl und Laber & 1 & 0.69 & 5 & Abundant\\ & Quite common at the Altmühl and Laber (rivers). &&& \\ \hline
        Roe Deer & Ist hier zu Hause, und beinahe in allen Waldtheilen zu finden. &1 & 0.88 & 4 & \textsc{Common} \\ & \textit{Is at home here and can be found in almost all parts of the forest.} &&& \\ \midrule
        European Adder & Kommt wohl aber eben nicht häufig vor. & 1 & 0.44 & 3 & \textsc{Common to Rare}\\ & \textit{Does indeed appear but just not that often.} &&& \\ \midrule
        Lynx & Höchst selten wechseln derlei Thiere von Tyrol herüber.& 1 & 0.12 & 2 & \textsc{Rare} \\& \textit{Very rarely do such animals cross over from Tyrol.} &&& \\ \midrule
         Wild Goose & Kommt nur äußerst selten zur Winterszeit vor.& 1 & 0.06 & 1 & \textsc{Very Rare} \\ & \textit{Occurs only very rarely at winter time.} &&& \\ \midrule
        Owl & Horstet dahier nicht und verstreicht sich auch nicht in diese Gegend. & 0 & 0.00 & 0 & \textsc{Absent} \\ & \textit{Does not nest here and does not stray into this area.} &&& \\ \midrule
        %Beaver & Um Passau nicht, bey Landshut sah ich 1826 im Freyen noch wilde Biber. & 0 & 0 & -1 & Extinct \\ & Not around Passau, near Landshut I did see wild beavers out in the open in 1826. &&& \\ \hline
        Wolf & Kommt nicht mehr vor. & 0 & 0.00 & -1 & \textsc{Extinct} \\
        & \textit{No longer occurs.} &&& \\ 
        \bottomrule
    \end{tabular}
    \caption{Data Examples with Annotation (our own translations)}
    \label{tab:data_example}
\end{table*}

In 1845, the Bavarian Ministry of Finance issued a survey to evaluate biodiversity in the Bavarian Kingdom, a region that encompasses a variety of different ecosystems and landscapes. To that end, 119 forestry offices were contacted to complete
%and return 
a standardized questionnaire. Namely, trained local foresters recorded in free text 
%whether and 
how frequently 44 selected vertebrate species occurred in the respective administrative territory, and in which habitats and locations 
%of the respective administrative territory 
they could be found. 

Figure~\ref{fig:questionnaire} shows the facsimile of a digitized survey page. It features a header containing instructions and a number of records describing animal species with their respective responses. These historical survey documents are preserved by the Bavarian State Archives \citep[cf.][]{rehbein2024historical}. 


The archival sources were digitized, transcribed
%\footnote{With the aid of Transkribus (\url{transkribus.org})} 
from the handwritten original and enriched with metadata, including, among others, taxonomic norm data according to the GBIF-database\footnote{\url{gbif.org}}  \citep{telenius2011biodiversity}
%,ivanova2021possibilities}
%\footnote{For the purposes of this study, we consider 44 selected vertebrate species.}  
and geographical references to forestry offices. 
%The transcription of the documents was carried with the aid of Transkribus\footnote{\url{transkribus.org}} handwritten text recognition. 
This data set is freely available on Zenodo \citep{rehbein2024historical}.
%: \url{https://doi.org/10.5281/zenodo.14008158}

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=.35\linewidth]{figures/Zool_Staatsslg_VN_113_0026.jpg}
    \caption{Facsimile of a survey page, Freysing forestry office in the Upper Bavaria district.}% from the Freysing forestry office in the Upper Bavaria district, with a header containing instructions and a number of records describing animal species with their respective responses. These historical documents are preserved by the Bavarian State Archives \citep{rehbein2024historical}.}\todo{Bitte die Captions überschaubar halten. Text kommt in den Artikel, nicht in die Caption. Bayr. Staatsarchiv muss trotzdem zitiert werden!}
    \label{fig:questionnaire}
\end{figure}

In total, the data set contains
%\todo{laut meiner rechnung is 119x44=5236}
%over 
5,467 entries\footnote{
%One text entry per species and office, but also 
Including species that were not explicity prompted.}
among which are also a number of empty (striked out) or `see above'-type responses. The unique set we used for our experiments contains 2,555 texts.
%As can be seen in Figure \ref{fig:Tokencount}, 
We find that the foresters' replies vary considerably in length where most texts contain 3 to 10 tokens and only a few texts more than 20 tokens. Table~\ref{tab:data_example} provides examples with annotation according to the tasks detailed in the next section.

%\begin{figure}[htbp!]
%    \centering
%    \includegraphics[width=.5\linewidth]{figures/Token_counts_per_text.png}
%    \caption{Histogram of Token Counts in the Texts}
%    \label{fig:Tokencount}
%\end{figure}



%***************************
%       TASKS
%***************************
\section{Tasks \& Experiments}\label{sec:tasks}


The main task in this paper is to assign a quantity label to a text, indicating the 
frequency 
%abundance
with which an animal species occurs in a specific area.
This can be operationalized in various ways, either through a classification task or through regression. In both, it can be as difficult to obtain consistent labels by asking humans to assign a value from a rating scale \citep{schuman1996questions, likert1932technique}.
Likewise, it is also difficult for researchers to design rating scales, 
%as there are many 
considering design decisions such as scale point descriptions or granularity may bias the annotators.
%as it is for researchers to develop such a scale, 
%as there are many 
%considering that design decisions such as scale-point descriptions or granularity may bias the annotator.
%, such as scale point descriptions and scale granularity.
%However, classification systems often introduce a degree of arbitrariness, and as the complexity of the task increases, so does the task of annotation. 
%Regression addresses the issue of arbitrary classes, but annotating for continuous value labels comes with its own set of challenges.
%To operationalize quantity estimation in our data, w

We evaluate three different task setups,\footnote{Code: \url{github.org/maelkolb/biodivquant}}
%\footnote{\url{github/Maelkolb/EcoNLP_Quantification}} 
as detailed in Table~\ref{tab:data_example}: Binary 'Presence vs. Absence' Classification, a 7-ary Multi-Class setup (Abundant to Extinct), and continuous values scaled to $[0,1]$. For the first two tasks, we use manual annotation, while continuous values are derived through BWS with LLMs \citep{bagdon2024you}.
%, a method that is cognitively and computationally more robust than naive annotation \citep{bagdon2024you,kiritchenko-mohammad-2017-best}. 


%the continuous values are derived through manual annotation of quantifiers, and best-worst-scaling with GPT-4, 


%\subsection{Binary `Presence vs. Absence'}
\subsection{Binary Classification}
%We consider t
The simplest form of animal occurrence quantification is a binary distinction between the absence (0) or presence (1) of a given species, an annotation scheme as popular as it is problematic in biodiversity estimation.\footnote{Since \textsc{Absence} may just stem from non-detection, rather than real absence \cite{dorazio2011modern,iknayan2014detecting,kestemont2022forgotten}.}
In our annotation, the label \textsc{Present} is given when a species is described in the historical dataset as having been observed in that particular locality at the time of the survey (thus excluding mentions of past occurrences, i.e., extinctions).
%In our annotation, the label \textsc{Present} is given when a species was described in the historical data set as been observed in that particular locality at the time of the survey (thus excluding 
%explicit 
%mentions of past occurrence, i.e., extinction). 
%Specific types of appearance (e.g., migration patterns) were only considered as appearance. 
The annotation workflow consists of
%multiple
iterative steps with discussions. Agreement is nearly perfect. Overall, from the set of 2,555 unique texts, 1,992 (78\%) fall into class \textsc{Present}, 563 (22\%) into \textsc{Absent}.\footnote{In the complete dataset, absence texts make up more than half of all text descriptions, but often amount to empty or `strike-out' responses. Thus, the task would be easier on the full dataset, because many instances are trivial to predict.}
%, and the majority baseline is lower.}
%In comparison, i
 



%\subsubsection{Presence/Absence Models}


To test the feasibility of the binary task, we create training curves with different models, namely BERT against 
%baselines with 
Logistic Regression, SVM, and Random Forest on Unigrams. We use 20\% of the data for testing, and take another 20\% from the training set for 
%validation and 
hyperparameter search at each cumulative 100 text increment. Despite the 78\% majority baseline, we find that the models perform well and training requires only a few hundred texts to reach an F1-macro score in the high 90s. 

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=.65\linewidth]{figures/Model_Training_Curves.png}
    \caption{Training Curves of different models on incremental training data (binary classification)}
    \label{fig:trainingcurves}
\end{figure}

Upon feature weight interpretation of the Logistic Regression and LIME on BERT \citep{ribeiro2016should}, we find that there is some bias in the data: Classification decisions occur on tokens that are not explicit quantifiers and easily substitutable without changing the classification result (e.g., common toponyms such as `Danube'). This presents a case of spurious correlations---an interesting future research direction, but a matching \cite{wang-culotta-2020-identifying} or counterfactual approach \cite{qian-etal-2021-counterfactual} appears 
%to be 
challenging for this heterogeneous data. Yet, we annotate the best features 
%weights 
with regard to their `spuriousness' and find that classifiers are still robust without spurious features. This annotation also gives us a list of quantifiers which we utilize for transfer learning of a regression model (section~\ref{sec:regression}).


\subsection{Multi-Classification}


Since the quantification 
of species 
%abundance
frequency 
in practice exceeds the binary differentiation between presence and absence of animals, a multi-class approach provides more details.
%on the actual amount of animal occurrence. 
We use a 7-class system, categorizing texts based on the schema as shown by the descriptors in Table~\ref{tab:data_example}, ranging from \textsc{Abundant} (5) to \textsc{Extinct} (-1).
%, Common (4), Common to Rare (3), Rare (2), Very Rare (1), Absent (0), and Extinct (-1). 
We decided to annotate data of four species for our case study (section~\ref{sec:discussion}): Roe deer, Eurasian Otter, Eurasian Beaver, Western Capercaille, each within the 119 forestry offices (with one annotator).
%(thus, 119 texts per species)
%Roe deer (Capreolus capreolus), Eurasia Otter (Lutra lutra), Eurasia Beaver (Castor fiber) and Western Capercaille (Tetrao urogallus).\footnote{All Latin classifications according to \citet{linnaeus1758systema}}}

A second person annotates a random sample of 100 texts, resulting in a Cohen’s $\kappa$ of 0.78, indicating high agreement.

%We had a second person annotate a random sample of 100 texts which results in a Cohen's $\kappa$ of 0.78, indicating high agreement. 
%on this relatively small sample. 
%\todo{hier hab ich agreement hinzugefügt}



We then train a few models with a 5-fold cross validation, and find that the language agnostic sentence encoder model LaBSE  \cite{feng2022languageagnosticbertsentenceembedding} performs better than monolingual BERT-models and a Logistic Regression. We also test a zero shot classification with GPT-4 and Deepseek-V3. See appendix for the prompt.
%For the logistic regression baseline, we utilized grid search for parameter tuning. 


\begin{table}[htbp!]
\centering\scriptsize
\begin{tabular}{lcc}
\toprule
\textbf{Model} &  \textbf{F1 Micro} & \textbf{F1 Macro}  \\ \midrule
Logistic Regression     & 0.69 &0.61  \\ 
gbert-base   &0.63 &0.51 \\ 
bert-base-german  &0.73& 0.63  \\ 
LaBSE    & \textbf{0.77} & \textbf{0.68} \\ 
GPT4 Zero Shot & 0.70 & 0.56 \\ 
DSV3 Zero Shot & 0.66 & 0.66 \\ \bottomrule
\end{tabular}%
\caption{Multi-class model performance.}% evaluation, 5-fold cross validation}
\label{tab:multi_models}
\end{table}

As seen in Table~\ref{tab:multi_models}, this task is generally quite challenging. 
We find that the main problem is posed by the underrepresented classes, as shown by the discrepancy between micro and macro scores,
%as seen in Figure \ref{fig:multi-class_perclass} 
indicating that more data would help, which is, however, expensive to obtain. Zero shot classification with GPT-4 in turn is biased towards the \textsc{Rare} 
%frequencies, 
classes,
such that \textsc{Common} categories are harder to predict, while DeepSeek-V3 (DSV3) shows a more balanced response.
%We explore the use of large language models for this 7-class annotation. The prompt contains instructions, such as detailing the annotation scheme, or specifying the language of the texts as german.



\iffalse
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/multi_class_perclass.png}
    \caption{Caption}
    \label{fig:multi-class_perclass}
\end{figure}
\fi 

%, as seen in \textcolor{red}{Table X}.



%\textcolor{red}{More explanation/interpretation.}



\subsection{Continuous Quantification}\label{sec:regression}

Finally, we experiment with operationalizing our task as a regression problem with the aim of generalizing the quantification problem to less arbitrary categories
%with superior adaptability to fine-grained labels 
and a possibly imbalanced data set \citep{johan-berggren-etal-2019-regression}. While a na\"ive labeling of quantifiers showed promising results, it is a challenge 
%(and subjective) 
to create a comprehensive test set based on heuristic annotation. Thus, we experiment with Best-Worst Scaling, aided by LLMs.

%, which is desirable for a number of reasons: 1) Regression allows us to model continuous trends in animal occurrence, capturing granular variations that classification could miss. 2) Regression models demonstrate superior adaptability to fine-grained labels and imbalanced datasets, as supported by evidence from automated essay scoring research \citep{johan-berggren-etal-2019-regression}. 3) Continuous labels generated through a text ranking approach, as detailed in the following section, can be considered less arbitrary compared to the categorization of texts into predetermined classes. 
%We utilized two approaches of training data creation for continuous labels; firstly, we manually extracted token and terms that indicate some form of quantification, scaling them from 0 to 1 manually. By calculating the mean value of all quantifier present within a text, we generate training data for the entire corpus. However, since these quantifier scores are clouded by subjectivity, the language processing capabilities of LLM's can provide an unbiased solution to the ranking of texts in order to calculate objective continuous target labels. \todo{hier habe ich was eingefügt, passt das so?}


\subsubsection{Best-Worst Scaling with LLMs}



%Humans are fairly bad at assigning numerical values to text. However, comparison tasks are cognitively fairly easy.  
%The decision to utilize a best-worst-scaling approach of texts instead of a Likert scale \citep{likert1932technique} or a pairwise comparison setting lies in several factors. Essentially, Likert or other kinds of rating scales "do not force respondents to discriminate between items"\citep{BWS_Theory} possibly causing the scale to contain clusters of items with "similarly high importance"(ibid.) instead of a similar distribution of values across the entire scale. 

%Yet, exhaustive pairwise comparisons are expensive. 
%For instance, comparing 1000 texts pairwise to one-another would take half a million iterations. 
Best-Worst Scaling (BWS) is a comparative judgment technique that helps in ranking items by identifying the best and worst elements within a set. This approach is easier to accomplish than manual labeling and there are fewer design decisions to make.
In a BWS setting, the amount of annotations needed to rank a given number of text instances depends on three variables, namely 1) corpus size (total number of texts used), 2) set size (number of texts in each comparison set), and 3) number of comparison sets each text appears in.

The number of comparisons divided by set size is regarded as the variable $N$, where $N=2$ generally yields good results in the literature \citep{kiritchenko-mohammad-2017-best}. A reliable set size is 4, since choosing the best and worst text instance from a 4-tuple set essentially provides the same number of comparisons
%results 
as five out of six possible pairwise comparisons (ibid).
%\citep{kiritchenko-mohammad-2017-best}.\todo{stimmt die citation hier? haben die das überhaupt gesagt?}

We take a random sample of 1,000 texts 
%from the data 
(excluding texts with \textsc{Absence} annotation, thus making the task harder, but giving us a more realistic distribution). With a set size of 4 and $N=2$, every text occurs in exactly 8 different sets and we get 2,000 comparison sets (tuples). These are then individually prompted to three LLMs: the relatively small Ministral-8B,\footnote{\url{https://huggingface.co/mistralai/Ministral-8B-Instruct-2410}} OpenAI's GPT-4 \citep{achiam2023gpt}, and the DeepSeek-V3 open source model \citep{liu2024deepseek}.

\begin{table}[htbp!]
\setlength{\aboverulesep}{1pt} % Reduce space above \midrule
\setlength{\belowrulesep}{2pt} % Reduce space below \midrule
\centering\scriptsize
\begin{tabular}{p{1.0cm}cccccccc}
\toprule
& \textbf{Annotator1} & \textbf{Annotator2} & \textbf{B}  & \textbf{W}  & \textbf{B + W} \\ \midrule
%\multicolumn{5}{c}{Models} \\
% Können wir die Tabelle bitte so lassen. Wir haben keinen Platz mehr. Habe es in der Caption erklärt.
\multirow{3}{*}{\parbox{1.0cm}{LLM-LLM}} & GPT4                  & DeepseekV3 & 0.73           & 0.69           & 0.56                  \\
& Ministral8B             & DeepseekV3 & 0.54           & 0.54           & 0.36                  \\ 
& GPT4                 & Ministral8B & 0.57           & 0.50           & 0.38                  \\ \midrule
\textbf{Average} &            &    & 0.61           & 0.57          & 0.43                \\ \midrule
%\multicolumn{5}{c}{Humans} \\
\multirow{5}{*}{\parbox{1.0cm}{Human-Human}} & AR                 & DS & 0.56           & 0.65           & 0.45                  \\ 
& DS                 & KB & 0.56           & 0.62           & 0.40                  \\   
& MR                 & AR & 0.51           & 0.65           & 0.39                 \\ 
& TP                 & AO & 0.73           & 0.55           & 0.48                 \\ 
& MP                 & MR & 0.59           & 0.52          & 0.41                 \\ 
\midrule
 \textbf{Average} &            &    & 0.59           & 0.60           & 0.43                 \\ \midrule 
%\multicolumn{5}{c}{Humans vs. Mistral8B} \\
\multirow{7}{*}{\parbox{1.0cm}{Human-LLM}} & AO                 & Ministral8B & 0.43           & 0.31           & 0.23                 \\ 
& AR                 & Ministral8B & 0.47           & 0.58           & 0.38                 \\ 
& DS                 & Ministral8B & 0.43           & 0.42           & 0.23                 \\
& KB                 & Ministral8B & 0.53           & 0.61           & 0.46                  \\ 
& MP                 & Ministral8B & 0.45           & 0.43           & 0.30                 \\
& MR                 & Ministral8B & 0.55           & 0.48           & 0.38                 \\ 
& TP                 & Ministral8B & 0.49           & 0.31           & 0.24                 \\
\midrule
\textbf{Average}       &     &    & 0.48           & 0.45          & 0.32                 \\ \midrule 
%\multicolumn{5}{c}{Humans vs. GPT4} \\
\multirow{7}{*}{\parbox{1.0cm}{Human-LLM}} & AO                & GPT4   & 0.68           & 0.55           & 0.45                 \\ 
& AR                  & GPT4 & 0.49           & 0.57           & 0.34                  \\ 
& DS                  & GPT4 & 0.44           & 0.71           & 0.43                \\ 
%GP                  & GPT4 & 0.44           & 0.49           & 0.28                  \\ 
& KB                  & GPT4 & 0.47           & 0.68           & 0.41                   \\ 
& MP                  & GPT4 & 0.57           & 0.62           & 0.41                   \\
& MR                  & GPT4 & 0.49           & 0.63           & 0.41                  \\ 
& TP                  & GPT4 & 0.63           & 0.57           & 0.43                  \\ 
\midrule 
 \textbf{Average} &             &      & 0.54           & 0.62           & 0.41 \\ \midrule
%AO                 & GP & 0.44           & 0.55           & 0.35                  \\  \\ \hline
%AO                 & GP & 0.44           & 0.55           & 0.35                  \\ 
%\multicolumn{5}{c}{Humans vs. DeepseekV3} \\
\multirow{7}{*}{\parbox{1.0cm}{Human-LLM}} & AO                 & DeepseekV3 & 0.61           & 0.59           & 0.45                 \\
& AR                 & DeepseekV3 & 0.55           & 0.68           & 0.41                \\
& DS                 & DeepseekV3 & 0.62           & 0.63           & 0.46                 \\ 
& KB                 & DeepseekV3 & 0.57           & 0.62           & 0.41                  \\   
& MP                 & DeepseekV3 & 0.69           & 0.53           & 0.41                 \\ 
& MR                 & DeepseekV3 & 0.59           & 0.68           & 0.46                 \\ 
& TP                 & DeepseekV3 & 0.58           & 0.58           & 0.41                \\ \midrule
 \textbf{Average} &            &    & 0.60           & 0.62           & 0.43                 \\ 
%\midrule
\bottomrule 
\end{tabular}%
\caption{Cohen's $\kappa$ Agreement between humans and LLMs in Best-Worst-Annotation (B: Best, W: Worst, B+W: Best + Worst). Two-letter shorthands for humans.}
\label{tab:bws_agreement}
\end{table}

Whereas Ministral-8B is run locally, we use the OpenAI API to access 
GPT-4 and the fireworks.ai API endpoint for DeepSeek-V3, since the DeepSeek-webservices are limited at the time of the experiment and hardware limitations hamper local deployment. Prompts are in the appendix.

We ask seven native German post-graduates to annotate one of two subsets of 50 tuples each with a custom browser-based annotation interface. Table~\ref{tab:bws_agreement} shows Cohen's $\kappa$ agreement across humans and LLMs.
We find that
agreement among humans is largely on par with agreement between humans and the two larger LLMs, while the lower agreement between Ministral-8B and humans, as well as the other machine annotators, indicates a limited capability of this model for the task at hand.
It appears that it is easier to identify the worst instance than the best, which is likely an artifact of our data. 
Interestingly, agreement between GPT-4 and DeepSeek-V3 is the highest overall, 
which could lend itself either to a) the task being easier for the LLMs than for humans, or b) that the models are overall fairly similar. We find no significant difference ($p=.118$) between GPT-4 and DeepSeek-V3 in Human-LLM comparison.

%human agreement is similar to the agreement between humans and GPT-4,\textcolor{blue}{ as well as between humans and DeepSeek-V3}, indicating i) that the task is overall feasable but by far not trivial, and ii) that GPT-4 \textcolor{blue}{and DeepSeek-V3}  are largely on par with humans. Furthermore, it appears that it is easier to identify the worst instance, rather than the best. \textcolor{blue}{Interestingly, agreement between GPT-4 and DeepSeek-V3 is the highest overall. On the other hand, the low agreement between Mistral-8B and human, as well as machine annotators indicates a limited capability of the model on the task at hand. } 

%the difficulty of the annotation, but also that the task is overal 





%, with agreements ranging from 0.44 - 0.71 Kappa,\todo{Durchschnittles Kappa angeben, zwischen Mensch vs. Maschine, und Mensch vs. Mensch!} which can be considered as moderate to good agreement \citep{Masson2003-gc}. 


\begin{equation}\scriptsize\label{eq:scaling}
    s(i) = \frac{\#best(i) - \#worst(i)}{\#overall(i)}
\end{equation}

By counting how often each text was chosen as the best, worst, or as one of two other texts, we calculate a score $s(i)$ as detailed in equation (\ref{eq:scaling}), resulting in an interval scale $[-1,1]$,
%incremented by $\frac{1}{8}$s, resulting in 17 equally spaced points,
which we normalize to a scale $[0,1]$. This scales (and ranks) the entire dataset, so it can be used for regression. 
It should be noted that the scores come in increments of $\frac{1}{8}$ (determined by number of comparisons of instance $i$), resulting in 17 discrete values.
%each instance is involved in), thus 
%at a scaling $[-1,1]$, 
%we get 17 discrete values.
We find a flat unimodal inverted U-shape in the score distribution without notable outliers. 
%is ranging from -1 to 1, scaling it to 0 to 1 after normalization. 




\subsubsection{Regression Models}

\iffalse
\todo{Fehlermeldung line 542, weiß nicht, wie man die weg bekommt. R2 A/B kursiv geht auch nicht weg}
\begin{table}
\centering\tiny
\begin{tabular}{|c|c|c|c|}
\toprule
 Features/Training Strategy & Model & MAE A/B    & R^2 A/B  \\ \hline\hline 
 Unigrams & KRR & 0.159/0.158 & 0.514/0.515 \\ 
Frozen LaBSE Embeddings & KRR & 0.118/0.117 & 0.678/0.686 \\
 Regression Head & bert-base-german & 0.149/0.158 & 0.516/0.490\\
Regression Head & LaBSE & 0.133/0.127 & 0.607/0.657 \\ %\hline
%Quantifier Lexicon + BSW         & Transfer Learning   & LaBSE & 0.162 & 0.474 \\ %\hline
%Mean values of Quantifiers + BSW & 
Reg. Head + Transfer   & LaBSE & 0.107/0.117 & 0.730/0.710 \\ \hline
\end{tabular}%
\caption{Comparison of different training strategies for 
%the optimization of 
regression based on BWS-Scaling. A: GPT-4 annotation, B: Deepseek-V3 annotation}
\label{tab:regression}
\end{table}
\fi

\begin{table*}
\centering
\footnotesize
\begin{tabular}{lccccc}
\toprule
 \textbf{Features/Training Strategy} & \textbf{Model} & \multicolumn{2}{c}{\textbf{MAE}} & \multicolumn{2}{c}{\textbf{R²}} \\  
 & & \textbf{GPT4} & \textbf{DSV3} & \textbf{GPT4} & \textbf{DSV3} \\ \midrule
 Unigrams & KRR & 0.159 & 0.158 & 0.514 & 0.515 \\ 
Frozen LaBSE Embeddings & KRR & 0.118 & 0.117 & 0.678 & 0.686 \\
 Regression Head & bert-base-german & 0.149 & 0.158 & 0.516 & 0.490\\
Regression Head & LaBSE & 0.133 & 0.127 & 0.607 & 0.657 \\ 
Reg. Head + Transfer & LaBSE & \textbf{0.107} & 0.117 & \textbf{0.730} & 0.710 \\ \bottomrule
\end{tabular}%
\caption{Comparison of different training strategies for regression based on BWS-Scaling. \\GPT4: GPT-4 BWS annotation, DSV3: Deepseek-V3 BWS annotation}
\label{tab:regression}
\end{table*}

We train 
%and evaluate 
a variety of different regression models with 5-fold cross validation
%, architectures and training strategies in order 
to optimize 
%regression 
%of the pairs of text labels 
for the values generated by Best-Worst Scaling, as shown in Table~\ref{tab:regression}.
%We applied 5-fold cross validation for the models in this section. 
We compare a Kernel Ridge Regression (KRR) baseline
%on unigrams and another on embedding features 
against 
%Sentence 
BERT-style-models
%\todo{bert-base ist kein sentence bert} 
with regression head, and test a transfer learning setup, for which we scale the 114 n-gram quantifiers as extracted from the binary Logistic Regression 
with another GPT-4 BWS,
%with GPT-4. 
then match these scores to the texts 
%in the training set 
and tune a LaBSE model on the same train/test split
before using it for the final task.
%It is curious that the 

Curiously, KRR with 
%frozen 
LaBSE embedding features benefits substantially from hyperparameter tuning, reaching superior results over LaBSE with regression head. The Transfer Model on GPT4 BWS offers the best performance, with acceptably high explained variance ($R^2=.73$) and only $.11$ Mean Absolute Error (MAE), which makes this model useful for downstream prediction as in the case study below. However, more data would likely also help, since training curves show continuous improvement.

%\textcolor{red}{describe transfer setup and result interpretation}

%For a baseline estimation on the task's difficulty, we fit a Kernel Ridge Regression on Unigrams.
%More complex model architectures, like transformer-based gbert \citep{DBLP:journals/corr/abs-2010-10906} or LaBSE \citep{feng2022languageagnosticbertsentenceembedding} have shown superior potential.

%We chose bert-base-german-cased \cite{huggingface-bert-base-german-cased} \textcolor{red}{(lieber so zitieren oder einfach die URL des models auf hf?)} and set up a regression head, archiving modest and similarly sized improvement for both German BERT, as well as LaBSE compared to the KRR baseline. 

%We also utilize a transfer learning setup.
%... improvement through transfer of heuristic annotation.

%Table 4 provides an overview of the models and training strategies for this optimization.


%through the sci-kit-learn python library on our data, using grid search for parameter tuning. With a mean absolute error of 0.17 and explaining 0.415 of all variance present, this regressor provides a starting point, demonstrating the inherent challenge of accurately predicting continuous target values. More complex model architectures, like transformer-based gbert \citep{DBLP:journals/corr/abs-2010-10906} or LaBSE \citep{feng2022languageagnosticbertsentenceembedding} have shown superior potential in modeling semantic nuances and contexts. Therefore, we fit baseline models of BERT and LaBSE on the BWS-text-label pairs to assess performance. Whereas the later model is multilingual, base BERT model was mainly trained on english text. However, there are fine-tuned BERT models for german language available. We chose bert-base-german-cased \cite{huggingface-bert-base-german-cased} \textcolor{red}{(lieber so zitieren oder einfach die URL des models auf hf?)} and set up a regression head, archiving modest and similarly sized improvement for both German BERT, as well as LaBSE compared to the KRR baseline. 

%Using a sentence BERT to generate dense, multi-dimensional embeddings of the texts in our corpus, we then transformed the resulting embeddings into the training and evaluation data for a Kernel Ridge regressor. This pipeline in theory should outperform the baseline, since SBERT text embeddings are inherently more advanced compared to the baseline regressor's absolute word count features. However, evaluating this approach with 5 fold cross-validation only accounts for minor improvements in both metrics. 

%: Kernel Ridge Unigram, Kernel Ridge SBERT, Regression Head German BERT, Regression Head LaBSE, Transfer Learning LaBSE

%The intuition\todo{die intuition ist, dass das modell durch den transfer was lernt. das hier ist eine workflowbeschreibung} behind transfer learning is to fit a pre-trained model such as BERT \citep{devlin-etal-2019-bert} or LaBSE \citep{feng2022languageagnosticbertsentenceembedding} firstly on an intermediary task, before further fine-tuning the resulting model on the target task at hand \citep{pruksachatkun-etal-2020-intermediate}.  In this way, the final model's weights have been calibrated on both tasks, which in theory should improve the performance on the target task. 

%... improvement through transfer of heuristic annotation
%... 


\section{Case Study}\label{sec:discussion}



For a proof of concept, we map the predictions of the regression model (LaBSE transfer regression model based on GPT-4 BWS) to the multi-class human annotation. Figure~\ref{fig:multi-class-regression} 
shows a strong relationship between multi-class labels and regression scores for the entire dataset (four species), but also that the extinction class is not properly represented in the regression, and furthermore that higher values are challenging to predict.




\begin{figure}[htbp!]
    \centering
    \includegraphics[width=.6\linewidth]{figures/box_multi-class_regression_blackmedian.png}
    \caption{Multi-Class vs. Regression Distribution}
    \label{fig:multi-class-regression}
\end{figure}

Figure~\ref{fig:rotwildotter} shows specie-specific distributions for Roe deer and Eurasian otter across all 119 offices, indicating a fairly good alignment between the regression result (top) and the multi-class annotation (bottom). 
However, the mapping is not unambiguous due to 1) shortcomings of the regression, such as the inability to model extinction and difficulty in predicting high values, and 2) imperfect alignment with class intervals, which are fuzzy with regard to the continuous values. However, pending further research, we find that our method performs well and produces plausible results.


%We conclude that the BWS-approach is robust and cost effective to estimate animal quantity. 

%This section details the case study, i.e., comparison of multi-class setup and regression.
%we used the data set annotated for multi-classification, containing all text entries of four selected species. 
%We let the best performing regression model mentioned in the previous section predict the dataset. A minor normalization of predicted values to [0;1] was conducted, after which we calculated the mean value of all the regressor's predictions for every class.\todo{das mean macht nicht so arg viel sinn. hier sollten die verteilungen respektive der Tierarten verglichen werden. Siehe Vergleich der in der Figure stattfindet. Was ist die Korrelation für Roe Deer, für Eurasian Otter, etc.} 




\begin{figure}[htbp!]
    \centering
    \includegraphics[width=.75\linewidth]{figures/rotwild_fischotter_density.png}
    \includegraphics[width=.75\linewidth]{figures/Multiclass_distribution_SP0005_SP0015.png}
    \caption{Density histogram of regressor prediction (top) and multi-class (bottom) distribution for Roe deer (SP\_0015, red) and Eurasian otter (SP\_0005, grey).}
    %across forestry offices as predicted by regression vs. multi-class annotation.}
    \label{fig:rotwildotter}
\end{figure}

\iffalse
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=.65\linewidth]{figures/rotwild_fischotter_density.png}
    \includegraphics[width=.65\linewidth]{figures/multi_class_roedeer_otter.png}
    \caption{Density and histogram for Roe deer (SP\_0015, red) and Eurasian otter (SP\_0005, blue).}
    %across forestry offices as predicted by regression vs. multi-class annotation.}
    \label{fig:rotwildotter}
\end{figure}
\fi
%\clearpage

%\textcolor{red}{Tabelle \ref{tab:bws_agreement}: Das muss stark vereinfacht werden und im text erklärt. Außerdem Agreement zw. Menschen zeigen. Siehe zb Table 2 in \url{https://arxiv.org/pdf/2407.03916}}

%\hspace*{-0.5cm}
\section{Conclusion \& Future Work}\label{sec:conclusion}


This study demonstrates that information of occurrence frequencies from semi-structured historical biodiversity survey texts can be adequately modeled with Best-Worst Scaling through LLMs. %extracted using machine learning. 
While a simple classification approach performs well with minimal training data, a more complex classification struggles with design decisions and imbalanced data. BWS meets this by eliminating rating scale design decisions. In addition, it is cognitively and computationally less expensive, since no manual annotation of training data is necessary, while still offering similarly accurate results with much finer granularity through regression.
%Regression models estimate animal occurrences, reducing the need for manual annotation by leveraging large language models (LLMs). The Best-Worst-Scaling method created scalable training data, leading to effective regression models.
%Our dataset spans the spectrum between disaggregated and aggregated data (cf. Introduction). 

The robustness of methods and models should be further tested, not exclusive to biodiversity surveys, lending itself to a number of tasks. Yet, similar data to ours likely exists, e.g., on 19th century Bavarian flora, \citet{wikisource_oberamtsbeschreibungen}, or data in biodiversitylibrary.org, making our methods valuable.
%but its 
%cross-domain 

 

%Also, baseline estimation might offer insight on observation biases.
%of foresters. 

\iffalse
However, Biodiversity literature databases, such as the Biodiversity Library, could provide a useful testbed, distinct from information extraction in scientific biodiversity literature.

\textcolor{blue}{It is very likely that more historical sources structured similarly to the one used here exist in the archives of societies, including an investigation of Bavaria's flora conducted at the same time,\todo{citation, hab Bettina nach der Archivsignatur gefragt. } and a multi-volume ethnological description of the Kingdomof Wuerttemberg (1824--1886) containing, among others, flora and fauna.\cite{wikisource_oberamtsbeschreibungen} \todo{citation, wie zitieren? das Jahr ist der letzte Bearbeitungsstand aber K.A. ob das so passt} Furthermore, databases for biodiversity literature\todo{hier klar abgrenzen was das für Datentypen sind und was damit gemacht werden kann} could prove to be another domain to investigate robust cross-domain performance of the methodological framework provided in this paper.

Baseline estimations also require consideration—e.g., how often must an owl be seen to be considered rare? Were baselines consistent across foresters? These questions impact interpretation and model performance.
\fi
\iffalse
In this paper, we showed that \textcolor{blue}{the quantification of biodiversity from semi-structured textual (historical) data can be framed as a classification or regression task. A binary classification setup can be automated with high performance and low amounts of training data needed, while the multi-class setup struggled with class imbalances and consequently decreased accuracy. By estimating the amount of animal occurrence through a regression task setup, we demonstrated that manual annotation can be substituted by leveraging LLM capabilities. The Best-Worst-Scaling approach produced low-cost, scalable training data, resulting in regression models that explain variances in the data acceptably well. }
\textcolor{blue}{It is very likely that more historical sources structured similarly to the one used here exist in the archives of societies, including an investigation of Bavaria's flora conducted at the same time,\todo{citation, hab Bettina nach der Archivsignatur gefragt. } and a multi-volume ethnological description of the Kingdomof Wuerttemberg (1824--1886) containing, among others, flora and fauna.\cite{wikisource_oberamtsbeschreibungen} \todo{citation, wie zitieren? das Jahr ist der letzte Bearbeitungsstand aber K.A. ob das so passt} Furthermore, databases for biodiversity literature\todo{hier klar abgrenzen was das für Datentypen sind und was damit gemacht werden kann} could prove to be another domain to investigate robust cross-domain performance of the methodological framework provided in this paper.  }
Overall this means that ...


Likely many more datasets in this form available. Thus, out method .. useful for this data, but it should be investigated regarding robust cross-domain performance. 

Our data spans the between the disagregated and aggregated spectrum.

Biodiv Literaturdatenbank

Abgrenzung von IE aus BioDiv Scientific Lit. 

Biodiversity Library (https://www.biodiversitylibrary.org/)

baseline estimation. how often does an owl have to be seen to be considered rare? was the baseline the same for all foresters?


\fi

%\subsection{Regression}







%***************************
%       DISCUSSION + CASE STUDY?
%***************************
%\section{Conclusion}\label{sec:discussion}



%\newpage


%\section*{Limitations}

%Here we should list the limitations of our study.

%***************************
%       CONCLUSION
%***************************
%\section{Conclusion}\label{sec:conclusion}


%***************************
%       FUTURE
%***************************
%\section{Future Work}\label{sec:future}


\clearpage

\section*{Limitations}

%\textcolor{red}{Our best-worst-scaling approach is limited to data that can be scaled, thus it only applies to datasets that allow ranking, and that are diverse enough to result in a score distribution ...}

The accuracy of the method depends heavily on the capabilities of the specific LLM used. If a model lacks domain-specific knowledge or has biases, it may impact results.
Furthermore, without a reliable dataset to benchmark against, it is difficult to assess the absolute accuracy of the BWS-based regression approach, because we also test on BWS values. While we measured agreement on the BWS task with humans, it is impractical to scale the entire dataset with both LLMs and humans, and thus our agreement calculation may suffer from sampling bias. 

The effectiveness of the approach on different text sources or structured data remains uncertain. Differences in linguistic styles, terminologies, and data availability across domains may limit generalization. The approach assumes that frequency-related information in historical texts can be accurately mapped to numerical frequency estimates. If the original texts contain qualitative descriptions rather than explicit quantifiers, this may introduce errors. Also, older survey texts may reflect sampling biases, observer subjectivity, or incomplete data. If LLMs learn from these biases, the resulting quantity estimations may reinforce historical inaccuracies rather than correct them.

%Scalability and Computational Cost – While BWS reduces manual annotation needs, running large LLMs (like GPT-4) is still computationally expensive. The trade-offs between cost, accuracy, and granularity should be further evaluated.


\section*{Acknowledgements}

We thank our annotators from the Journal Club, and the colleagues in the Computational Historical Ecology group at the Chair for Computational Humanities at the University of Passau for their feedback.
%*******************
% BIBLIOGRAPHY
%*******************
\bibliographystyle{acl_natbib}
\bibliography{nodalida2025}

%\clearpage 

\section*{APPENDIX: PROMPTS}\label{sec:appendix}

%\subsection*{GPT-4 Prompts}
\begin{small}
\subsection*{Multi-Classification Prompt}

    \paragraph{System-prompt:}
    You are a German native expert in text classification. Use the provided classification scheme to classify German texts based on species frequency descriptions.
    
    \paragraph{User-prompt:}
    You are a classification model. Classify the given German text into one of the following categories:\\
- Abundant (5): Species is very frequently observed or present.\\
- Common (4): Species is commonly found in the area.\\
- Common to Rare (3): Species is observed, but not very frequently.\\
- Rare (2): Species is rarely seen in the area.\\
- Very Rare (1): Species is seen only in exceptional circumstances.\\
- Absent (0): Species is not observed in the area.\\
- Extinct (-1): Species no longer exists in the area.\\ Read the provided text and classify it according to this scheme.
    Here is the text to classify:\\
    Text

\subsection*{Best-Worst Scaling Prompt}

    \paragraph{System-prompt:} 
    You are an expert annotator specializing in Best-Worst Scaling 
    of German texts based on quantity information about animal occurrences.

    \paragraph{User-prompt:}
(Texts 1 to 4 were substituted with the actual texts of a tuple): Task: From the following German texts about animal occurrence, identify:\\ Best: The text conveying the highest quantity (e.g., presence, frequency, population size)\\ Worst: The text conveying the lowest quantity. \\1. Text 1 \\2. Text 2 \\3. Text 3\\4. Text 4\\ JSON format for your answer:\\\{ "Best": [Text Number],\\  "Worst": [Text Number]\}
\end{small}

\end{document}












%*********************
% ROTE LISTE KLASSIFIKATION
%**********************

\iffalse
\begin{longtable}{|l|p{10cm}|}
\hline
\textbf{Category} & \textbf{Description} \\
\hline
Extinct (EX) & There are no known living individuals \\
\hline
Extinct in the wild (EW) & Known only to survive in captivity, or as a naturalized population outside its historic range \\
\hline
Critically Endangered (CR) & Highest risk of extinction in the wild \\
\hline
Endangered (EN) & Higher risk of extinction in the wild \\
\hline
Vulnerable (VU) & High risk of extinction in the wild \\
\hline
Near Threatened (NT) & Likely to become endangered in the near future \\
\hline
Conservation Dependent (CD) & Low risk; is conserved to prevent being near threatened, certain events may lead it to being a higher risk level \\
\hline
Least concern (LC) & Very Low risk; does not qualify for a higher risk category and not likely to be threatened in the near future. Widespread and abundant taxa are included in this category. \\
\hline
Data deficient (DD) & Not enough data to make an assessment of its risk of extinction \\
\hline
Not evaluated (NE) & Has not yet been evaluated against the criteria. \\
\hline
\end{longtable}
\fi


\iffalse
\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|}
\hline
      & \textbf{orig.} & \textbf{modified} \\ \hline
%Total Texts             & 5464                  & 2555                  \\ \hline
Empty Texts             & 637 (11.7\%)          & 1 (0.04\%)            \\ \hline
Unique Texts            & 2470 (45.20\%)        & 2552 (99.88\%)        \\ \hline\hline
Absence (0)              & 2953 (54\%)           & 563 (22\%)         \\ \hline
Presence (1)             & 2511 (46\%)           & 1992 (78\%)        \\ \hline
\end{tabular}
\caption{Comparison of original and modified datasets}
\label{tab:completedTextStats}
\end{table}
\fi

\iffalse
\begin{table}[h!]
\centering\scriptsize
\begin{tabular}{|l||c|c||c|c|}
\hline
      & \multicolumn{2}{c||}{\textbf{Original (abs., \%)}} & \multicolumn{2}{c|}{\textbf{Modified (abs., \%)}} \\ \hline
      %& \textbf{abs.} & \textbf{\%} & \textbf{abs.} & \textbf{\%} \\ \hline
Total Texts             & 5464                  & 100\%                    & 2555                  & 100\%                    \\ \hline
Empty Texts             & 637                   & 11.7\%               & 1                    & 0.04\%               \\ \hline
Unique Texts            & 2470                  & 45.20\%              & 2552                 & 99.88\%              \\ \hline\hline
Absence (0)             & 2953                  & 54\%                 & 563                  & 22\%                 \\ \hline
Presence (1)            & 2511                  & 46\%                 & 1992                 & 78\%                 \\ \hline
\end{tabular}
\caption{Comparison of original and modified datasets}
\label{tab:completedTextStats}
\end{table}
\fi

%\textcolor{red}{Table \ref{tab:completedTextStats} ist sehr kompliziert. Was ist empty? Muss erklärt werden. Warum hat original mehr unique values als modified? Wie kommt man vom einen zum anderen? Außerdem 'completedText' erklären. Uneinheitliche Nachkommastellen. Empty bei mod. sollte es nicht geben. Redundante Information mit Table \ref{tab:class_counts}.}

%Regression motivieren ... BWS motivieren ... ranking etc.


%As\todo{Wird das auch evaluiert? Wo ist das Modell? Was machen wir damit? Dieser Text muss runter in 4.2.2} a first naive approach to a regressor that scales texts utilizing continuous values instead of relying on predetermined class boundaries, We used a semi-automated approach to create the training data for this task. Firstly, we manually extracted terms or phrases that indicate some form of quantification from our corpus. We then added annotations to these terms, scaling them from 0 to 1 based on their perceived value of quantification. Lastly, through a matching algorithm, the texts containing one or more of the terms from the quantifier lexicon were annotated by calculating the mean value of all lexicon quantifiers present, 


%***************************
%       EXPERIMENTS
%***************************
%\section{Experiments}\label{sec:experiments}
%For the following experiments, we applied pre-processing to the data, including punctuation removal and the %conversion to lowercase. 
%\subsection{Classification \& Spurious Correlations}

%\begin{enumerate}
%    \item Training curve - easiness of task
%    \item Feature elimination
%    \item Evaluation of reduced/robust models
%\end{enumerate}

%In order to create baselines of model performance and to assess the difficulty of the tasks mentioned in the previous section, we aimed to find the best hyper-parameter combination for each task through the implementation of a training strategy with grid-search.

\iffalse
Methods
    \begin{itemize}
            \item Baselines: Log.Reg., SVM, BERT (unigrams)
            \item Training Curves
            \item Robust Feature Deletion
            \item Feature Extraction Through Treatment Effect
            \begin{itemize}
                \item Robust Classifier
                \item Spurious Feature Identification (Classifier)
    \end{itemize}
\fi


\iffalse
\begin{table}[]
    \centering
    \begin{tabular}{c|l|c}
    label & descriptor & freq. in data \\ \hline 
     5    &  Abundant  & xx \\ 
     4    &  Common    & xx \\
     3    &  Common to Rare & xx \\
     2    &  Rare      & xx \\
     1    &  Very Rare & xx \\
     0    &  Absent    & xx \\
     -1   &  Extinct   & xx \\
    \end{tabular}
    \caption{Multi Classification Scheme}
    \label{tab:multi_class}
\end{table}

\begin{table}[]
    \centering
    \begin{tabular}{l|l|l}
    animal & latin name & freq. \\ \hline
    roe deer   &  capreolus capreolus & \\ 
    eurasian otter     &  lutra lutra & \\
    eurasian beaver    &  castor fiber & \\
    western capercaille & tetrao urogallus & \\ 
    \end{tabular}
    \caption{Annotated Multi Animals; Latin nomenclature according to Linnaeus (1758)}
    \label{tab:multi_anno}
\end{table}
\fi


\iffalse
4 = ABUNDANT, 3 = COMMON, 2.5 = COMMON TO RARE (moderate number, not frequent),\todo{inkonsistent} 2 = RARE, 1 = VERY RARE, 0 = ABSENT, -1 = EXTINCT. Following this scheme, we annotated the entries present in our corpus for a selection of four species, namely Roe deer (Capreolus capreolus, Linnaeus, 1758) , Eurasian otter (Lutra lutra, Linnaeus, 1758),  Eurasian beaver (Castor fiber, Linnaeus, 1758) and Western capercaillie (Tetrao urogallus, Linnaeus, 1758).\todo{wie wurde das gemacht} 
\fi

%4 = ABUNDANT, 3 = COMMON, 2.5 = COMMON TO RARE (moderate number, not frequent),\todo{inkonsistent} 2 = RARE, 1 = VERY RARE, 0 = ABSENT, -1 = EXTINCT. Following this scheme, we annotated the entries present in our corpus for a selection of four species, namely Roe deer (Capreolus capreolus, Linnaeus, 1758) , Eurasian otter (Lutra lutra, Linnaeus, 1758),  Eurasian beaver (Castor fiber, Linnaeus, 1758) and Western capercaillie (Tetrao urogallus, Linnaeus, 1758).

%With the parameter combination deemed optimal for the binary classification task with BERT, we then implemented a training strategy through which the model is trained in increments, in order to track the models performance on increasing amounts of data. In this way, we compared the base BERT model with a SVM, a logistic regression and a random forest algorithm with training data increments ranging from 100 texts (approx. 2.5\%) to 2.000 texts (approx. 80\%) of all texts in our corpus. The same 20\% test set is used to evaluate after every increment of data. Figure 1 shows the resulting training curves. The non-transformer-based models also used optimal hyper-parameters found with grid-search. Interestingly, BERT starts off with the lowest F1-score after the first 100 texts. However, from the mark of around 400 text instances on-wards, it shows the best performance throughout this experiment. 
%Generally, all models reach F1-values of approx. 0.93-0.95 rather quickly, which indicated the simplicity of this binary separation of absence and presence. 


%\subsubsection{Robust Models}

%Matching, feature evaluation, etc.


%Table 1 shows exemplary texts for both classes. The annotation of this binary differentiation took place during the dataset creation. The participants were tasked with transcribing the digitized facsimile of the surveys and adding the binary annotation to each text. The workflow also included exchanging the transcriptions among the participants and sampling entries for data integrity verification. The positive occurrence class encodes texts that describe the presence of a species in 1845 or another time explicitly stated. The type of occurrence (e.g. appearances because of migration patterns) had no influence on the class decision\footnote{class distribution for binary task: 70/30 with positive class as majority} - any textual trace of recent occurrence resulted in the positive class annotation \citep[cf.][]{rehbein2024historical}. \\


%\textcolor{red}{Wie hat die Annotation stattgefunden? Nach welchen Kriterien/Guidelines? Was war der Workflow? Gibt es Agreement?}

\iffalse
\begin{table}[h!]
\centering
\begin{tabular}{|c|l|c|}
\hline
Class & Example & No. of Texts \\ \hline
1 & You can find it everywhere. & 1992 \\ \hline
0 & Has not been observed. & 563 \\ \hline
\end{tabular}
\caption{Counts of texts by class label.}
\label{tab:class_counts}
\end{table}
\fi 

\iffalse
\subsection{Ternary}
 For this, we keep the absence of animals as the negative class, and split the presence into low and high amount of occurrence. It should be mentioned that not all texts can be classified with this approach. Consider texts like the following description of the forestry office Kulmain in the Upper Palatinate district for deers: 
\begin{quote}
"In mittelmäßiger Verbreitung durch alle Waldungen des Amtsbezirkes" (trans.: "In medium distribution across all forests in the district")
\end{quote}
In the binary classification, this text would have been classified as one describing the presence of deer. However, through the split of the positive class into low and high frequency, texts that mention a medium amount of occurrence do not fall in either positive category.  
This issue can however be avoided through applying the third task we explore to quantify the occurrence of animals: a scaling of quantities using a regression-based modeling without predetermined class boundaries. 
\fi

%Quantity estimation from text can be operationalized in a number of ways, predominantly through (ordinally ranked) classification systems, e.g., annotated through Likert scales \citep{likert1932technique}, or through continuous variables which can be predicted with regression models.

%As complexity increases, so does the difficulty of annotation. Classification systems can be arbitrary, similar to Likert scales, and can be derived in numerous ways. In biodiversity, categories can be descriptive (frequency) or prescriptive (endangerment status). Regression addresses the issue of arbitrary classes, but it presents cognitive challenges and difficulties in assigning arbitrary values to texts. Best-Worst Scaling (BWS) offers a cognitively feasible solution that can be effectively executed with large language models (cf. Klinger et al.). 


\iffalse
\begin{table}[ht]
\centering\scriptsize
\begin{tabular}{lcccc}
\toprule
  Task        & \textbf{Binary} & \textbf{Ternary} & \textbf{Multi} & \textbf{Regression} \\
\midrule
\textbf{Schema}     &    0/1            &   N/S/H * *        &   1/2/3/4/5/67            &   [0;1]                \\
\textbf{Annotation} &    Manual      &                 &               &   BWS                \\
\textbf{Model}      &                &                 &               &                   \\
\textbf{Interpretation} &            &                 &               &                   \\
\bottomrule
\end{tabular}
\caption{Comparison of tasks: Binary, Ternary, Multi, and Regression across various aspects.}
\label{tab:task_comparison}
\end{table}
\fi

\iffalse
\begin{table}[h!]
\centering\scriptsize
\begin{tabular}{|l||c|c||c|c|}
\hline
      & \multicolumn{2}{c||}{\textbf{Original (abs., \%)}} & \multicolumn{2}{c|}{\textbf{Modified (abs., \%)}} \\ \hline
      %& \textbf{abs.} & \textbf{\%} & \textbf{abs.} & \textbf{\%} \\ \hline
Total Texts             & 5464                  & 100\%                    & 2555                  & 100\%                    \\ \hline
Empty Texts             & 637                   & 11.7\%               & 1                    & 0.04\%               \\ \hline
Unique Texts            & 2470                  & 45.20\%              & 2552                 & 99.88\%              \\ \hline\hline
Absence (0)             & 2953                  & 54\%                 & 563                  & 22\%                 \\ \hline
Presence (1)            & 2511                  & 46\%                 & 1992                 & 78\%                 \\ \hline
\end{tabular}
\caption{Comparison of original and modified datasets}
\label{tab:completedTextStats}
\end{table}
\fi

\iffalse
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=1\linewidth]{figures/residuals_transfer_learning_model.png}
    \caption{Residuals of Regression Model}
    \label{fig:residuals}
\end{figure}
\fi

\iffalse
\begin{table}[htbp!]
\todo{sind F1 Micro und Accurracy das selbe?}
\centering\scriptsize
\begin{tabular}{|c|c|c|c|c|}
\hline
Model & F1-w & F1 Micro & F1 Macro & Accuracy \\ \hline\hline
Log. Reg,  & 0.68  & 0.69&0.61 &0.69  \\ 
gbert-base  & 0.62  &0.63 &0.51& 0.63  \\ 
bert-base-german & 0.72 &0.73& 0.63 &  0.73  \\ 
LaBSE  & 0.77  & 0.77 &0.68&0.77  \\ \hline
\end{tabular}%
\caption{Multi-class model performance evaluation, 5-fold cross validation}
\label{tab:multi_models}
\end{table}
\fi 

\iffalse
\begin{table*}
\centering\tiny
\begin{tabular}{|c|c|c|c|c|}
\hline
Training Data  & Training Strategy & Model & MAE   & R^2    \\ \hline\hline 
BSW & Grid Search & Kernel Ridge & 0.170 & 0.415 \\
BWS & Sentence Embedding Regression? & SBERT\footnote{SBERT model name: all-mpnet-base-v2} + KRR & 0.161 & 0.461 \\
BSW & Reg. Head & German BERT Base & 0.152& 0.507\\
BSW  & Reg. Head & LaBSE & 0.155 & 0.505 \\ %\hline
Quantifier Lexicon + BSW         & Transfer Learning   & LaBSE & 0.162 & 0.474 \\ %\hline
Mean values of Quantifiers + BSW & Transfer Learning   & LaBSE & 0.107 & 0.730 \\ \hline
\end{tabular}%
\caption{Comparison of different training strategies for the optimization of regression based on BWS-Scaling }
\end{table*}
\fi



\iffalse
\begin{table}[htbp!]
\todo{Kappa für B+W eingefügt, bespielhaftes agreement zw. Menschen eingefügt}
\centering\scriptsize
\begin{tabular}{cccccccc}
\hline
Annotator1 & Annotator2 & B Agr. (\kappa) & W Agr. (\kappa) & B + W Agr. (\kappa)  \\ \hline
%JN        & 50          & 13/50 (-0.02)          & 10/50 (-0.07)          & 1/50                    \\ \hline
AO                & GPT4 & 38/50(0.68)           & 33/50 (0.55)           & 25/50  (0.45)                 \\ \hline
AR                  & GPT4 & 31/50 (0.49)           & 34/50 (0.57)           & 20/50 (0.34)                  \\ \hline
DS                  & GPT4 & 29/50 (0.44)           & 39/50 (0.71)           & 24/50 (0.43)                \\ \hline
GP                  & GPT4 & 29/50 (0.44)           & 31/50 (0.49)           & 17/50 (0.28)                  \\ \hline
KB                  & GPT4 & 30/50 (0.47)           & 38/50 (0.68)           & 23/50 (0.41)                   \\ \hline
MR                  &GPT4 & 31/50 (0.49)           & 36/50 (0.63)           & 23/50 (0.41)                  \\ \hline
AO                 &GP & 29/50 (0.44)           & 33/50 (0.55)           & 20/50 (0.35)                  \\ \hline
AR                 &DS & 34/50 (0.56)           & 37/50 (0.65)           & 25/50 (0.45)                  \\ \hline
DS                 &KB & 34/50 (0.56)           & 36/50 (0.62)           & 23/50 (0.40)                  \\ \hline   
MR                 &AR & 32/50 (0.51)           & 37/50 (0.65)           & 22/50 (0.39)                  \\ \hline  
\end{tabular}%
\caption{Agreement between humans and LLM in Best-Worst-Annotation (of animal quantity)}
\label{tab:bws_agreement}
\end{table}
\fi 

\iffalse
\begin{table}[]
    \centering
    \begin{tabular}{l|llllll}
    Annotator   & AO    & AR  & DS  & GP  & KB  & MR \\ \hline
    GPT-4       & 0.0   & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
    AO          & -     & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
    AR          & -     & -   & 0.0 & 0.0 & 0.0 & 0.0 \\
    DS          & -     & -   & -   & 0.0 & 0.0 & 0.0 \\
    GP          & -     & -   & -   & -   & 0.0 & 0.0 \\
    KB          & -     & -   & -   & -   & -   & 0.0 \\
    \end{tabular}
    \caption{BWS Agreement in Cohen's Kappa}
    \label{tab:bws_argeement1}
\end{table}
\fi

\iffalse
Long-term biodiversity observation data is considered crucial for the protection of species 
%or taxonomic groups 
and the prevention of biodiversity loss \citep{dornelas_biodiv}, e.g., caused by habitat destruction, climate change, pollution, or overexploitation of resources \citep{hoque2024addressing}.

The ability to accurately measure and monitor biodiversity over extended periods provides invaluable insights into ecological changes and trends. 
Achieving this requires both reliable data and robust measurement methods.
However, the availability of longitudinal data is restricted to the late 20th century \citep{Van_Goethem2021-zl}, and historical sources  
\fi 

\iffalse
Biodiversity data types provide information at varying resolutions. Although the concept of
resolution has substantially improved our understanding of spatial biodiversity patterns
[20,21], it is less commonly used in other contexts. However, resolution is a general property
of biodiversity data that can be understood as the degree of ecological generalization represented by a given data type. Highly disaggregated data, e.g., point occurrences or trait measurements, represent a single sampling event for a particular individual at a certain location and
time. In contrast, highly aggregated data, e.g., Floras or taxonomic monographs, provide a
more general account of biodiversity across large spatial, temporal, and taxonomic scales.
There is a fundamental trade-off between fine-scale precision and large-scale representativeness across the data resolution spectrum. Although disaggregated data provide the necessary
detail to address questions at the level of populations or communities [8,22], they tend to be
less complete and representative at macroecological scales [13,15]. Aggregated data, on the
other hand, are limited in their capacity to resolve fine-grained ecological patterns but usually
provide higher completeness and representativeness at large scales. This trade-off, which, too,
has been mostly described in geographical contexts [23,24], is highly relevant for the precision
and accuracy of macroecological inferences [16,25].
\fi 

\iffalse
Museum specimens have always provided the most basic informa‐
tion about the spatial distribution of life on earth: which species
live where and when. These records have formed the basis for our
biodiversity range maps, biogeography and conservation planning
(Suarez & Tsutsui, 2004). As the pace of global change accelerates,
we need more biodiversity data to monitor how species are respond‐
ing, which are most in need of conservation efforts, and what kinds
of impacts these efforts deliver (Dirzo et al., 2014).
A recent paper by Farley, Dawson, Goring, and Williams
(2018) discussed ecology's transition into the era of big data
and showed exponential increases in biodiversity records in the
Global Biodiversity Information Facility (GBIF) and other museum
databases. A growing digital archive should put us in a good position
to monitor change. However, another recent paper by Malaney and
Cook (2018) showed that traditional museums actually are not keep‐
ing pace. Mammal specimen collecting in the United States reached
its peak around 1990 and has dropped by a factor of three since
then, with fewer than 5,000 specimens collected annually in recent
years. That this is the situation for North American mammals—one
of the world's best surveyed faunas—sheds stark light on what poor
resolution incoming specimens will provide to understand changes
in our global biodiversity. But what, then, explains the mismatch be‐
tween the increases in GBIF data and the decreases in actual spec‐
imen collection?
\fi 

\iffalse
As biologists began studying what are called ‘biodiversity
patterns’, the primary data were observations of presences
and absences of species across space and time, combined
with geographical information regarding climate, soil,
geology and other features of the regions in which they
are found. This focus on primary occurrence information
began with the earliest of the classic naturalists, and continued right up to the present (Krishtalka & Humphrey
2000). This basis, of course, requires the collaboration of
the entire systematic enterprise—without sound taxonomic information, description and understanding of
species diversity patterns and distributions would be
impossible.
In the past 10 years, advances in information technology
(e.g. large-capacity electronic storage media, the Internet,
the World Wide Web, distributional database technology)
and in the policies of owners of primary data sources (e.g.
large-scale digitization of data, creation of public-access
databases) are creating a revolution in the way that biodiversity information is created, maintained, distributed and
used (Bisby 2000; Oliver et al. 2000; Edwards et al. 2000;
Krishtalka & Humphrey 2000; Krishtalka et al. 2002),
with the potential of much more to come (Godfray 2002).

Over its first decade, GBIF published over 370 million records of
species, from 12 000 data sets supplied by 400 organisations from
over 40 countries, with over 4.5 million names (Figure I). The names
include scientific, vernacular, and other names, and amount to almost
1 million species, of which 590 000 have distribution data (Tim
Robertson, personal communication). The marine component of
GBIF, OBIS, contains over 120 000 species, which is over half of all
described marine species [61–63]. Approximately 80% of records
represent species observations and samples rather than museum
specimens [9]. The data from each source are integrated into a large
searchable database [53]. Over 85% of animals and 76% of plant
species can be mapped [6]. Thus, the sum of local and regional data
can be used to examine global-scale phenomena. Over two-thirds of
the data sets in GBIF have been provided by government organisations whose staff are directed to do so. Far fewer data sets are
delivered from the academic community, although it publishes
approximately 75% of all scientific papers, despite comprising only
15–50% of all scientists [38]. Nevertheless, the number of publications
that has used data from GBIF is increasing
\fi 

\iffalse
However, the scarce availability of long-term data restricts research to data sets dating back to the 1970s \citep{Van_Goethem2021-zl} at most. \citet{Johnson2011-ah}  identify two possible sources for data of this type reaching further back in time. Firstly, natural history collections provide valuable resources such as specimen of a wide range of species often collected throughout different time periods (ibid.). Secondly, historical sources, typically situated in the archives of society contain 'data coded by humans' \citep{Bronnimann2018-jg}, ranging from textual sources such as diaries or official documents to paintings and imagery or born-digital data.\todo{Bitte Bezug zu diesem Paper klarmachen.} 

Specifically, sources with information regarding biodiversity encoded in text form, like the dataset used in this study, often are rich in data.\todo{?} However, text sources present challenges due to their unstructured nature and therefor sophisticated methods and tools are required to extract meaningful quantitative information.
%\todo{das hab ich hinzugefügt}

To overcome these challenges, researchers have increasingly turned to automated methods for biodiversity estimation e.g., the retrieval of biodiversity information from literature \cite{Kommineni2024-ne,langer2024relation,lucking2022multiple}).

\fi

\iffalse
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=.6\linewidth]{figures/rotwild_fischotter_density.png}
    \caption{Density and histogram for Roe deer (SP\_0015, red) and Eurasian otter (SP\_0005, blue) across forestry offices as predicted by the regression.}
    \label{fig:rotwildotter}
\end{figure}

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/multi_class_roedeer_otter.png}
    \caption{Histogram of Roe deer and Eurasian otter via multi-class scheme.}
    \label{fig:rotwildotter_multiclass}
\end{figure}
\fi


%As the API of the DeepSeek endpoint and web services were limited in their availability at the time of the annotation experiment, and running the model locally was not possible due to hardware requirements, we used the API endpoint of fireworks.ai to deploy the V3 model for our task.}
%We assigned the LLM the assistant role of an expert in German text ranking through best-worst-scaling based on quantity information in relation to animal occurrence. The prompts themselves contained a detailed task description, including an explanation on what type of information shall be considered crucial for evaluating the scale of quantification present in the texts. 
%We specified the expected output of json-format with the number of the "best" (highest quantity) and "worst" (lowest quantity) text from each comparison set. 
%To get an impression of the performance of GPT-4 in relation to the task at hand, 



%... consistency of BWS scaling (N)
%... Evaluation of BWS