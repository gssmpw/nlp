\section{Conclusions}
In this work, we presented SALF-CBM, a novel framework for transforming any vision neural network into an explainable model that provides both concept-based and spatial explanations for its predictions.
We showed that SALF-CBM facilitates model interpretability without sacrificing performance, outperforming existing CBMs as well as the original model on several classification tasks. We further showcased the high-quality spatial explanations provided by our method, achieving improved zero-shot segmentation results over widely-used heatmap-based XAI techniques.
% Specifically, we believe that the interactive model exploration and debugging capabilities of our framework holds particular promise for critical applications such as medical imaging. By providing intuitive ways for experts and practitioners to understand and refine the decisions made by AI models, our method can XXX their adoption in such XXX fields.
Finally, we introduced interactive model exploration and debugging capabilities, demonstrating their effectiveness in diagnosing and correcting model errors. 
We believe that such capabilities are especially valuable for critical applications such as medical imaging and autonomous driving. By equipping expert practitioners with intuitive tools to understand and modify model decisions, our method can enhance confidence and enable safer deployment in these safety-critical fields.
Looking ahead, as new vision-language models emerge in various domains, our insights could aid in creating more effective interpretability tools for a wide range of AI applications. We intend to further investigate these possibilities in future work.
% By leveraging the emergent properties of visual prompting with CLIP, we teach the model to project its “black-box” features into a interpretable concept maps, withot requiring concept annotations. We showed that concept maps produced by SALF-CBM are highly useful for downstream classification tasks, as well as for zero-shot image segmentation. We further demonstrated how SALF-CBMs can be used for interactive model exploration, debugging, and enable local user intervention at test-time. We believe that such exploration capabilities have the potential to true impact in real-world applications such as medical image analysis, where radiologists would be able to revise decisions made by AI models in an interpretable and visually-intuitive manner. We hope that this work can further advance the adoption of CBMs in real-world applications and encourage further research of concept-based XAI methods.