
%16年第一篇RIS
@inproceedings{hu2016segmentation,
  title={Segmentation from natural language expressions},
  author={Hu, Ronghang and Rohrbach, Marcus and Darrell, Trevor},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  pages={108--124},
  year={2016},
  organization={Springer}
}
% CRIS
@inproceedings{wang2022cris,
  title={Cris: Clip-driven referring image segmentation},
  author={Wang, Zhaoqing and Lu, Yu and Li, Qiang and Tao, Xunqiang and Guo, Yandong and Gong, Mingming and Liu, Tongliang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11686--11695},
  year={2022}
}

% VLT
@inproceedings{ding2021vision,
  title={Vision-language transformer and query generation for referring segmentation},
  author={Ding, Henghui and Liu, Chang and Wang, Suchen and Jiang, Xudong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16321--16330},
  year={2021}
}

% LAVT
@inproceedings{yang2022lavt,
  title={Lavt: Language-aware vision transformer for referring image segmentation},
  author={Yang, Zhao and Wang, Jiaqi and Tang, Yansong and Chen, Kai and Zhao, Hengshuang and Torr, Philip HS},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18155--18165},
  year={2022}
}
% R-Refcoco
@article{wu2024towards,
  title={Towards robust referring image segmentation},
  author={Wu, Jianzong and Li, Xiangtai and Li, Xia and Ding, Henghui and Tong, Yunhai and Tao, Dacheng},
  journal={IEEE Transactions on Image Processing},
  year={2024},
  publisher={IEEE}
}
% RefCOCO and RefCOCO+
@inproceedings{yu2016modeling,
  title={Modeling context in referring expressions},
  author={Yu, Licheng and Poirson, Patrick and Yang, Shan and Berg, Alexander C and Berg, Tamara L},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages={69--85},
  year={2016},
  organization={Springer}
}
% Intention
@article{wang2024beyond,
  title={Beyond Literal Descriptions: Understanding and Locating Open-World Objects Aligned with Human Intentions},
  author={Wang, Wenxuan and Zhang, Yisi and He, Xingjian and Yan, Yichen and Zhao, Zijia and Wang, Xinlong and Liu, Jing},
  journal={arXiv preprint arXiv:2402.11265},
  year={2024}
}
@article{zhao2023bubogpt,
  title={Bubogpt: Enabling visual grounding in multi-modal llms},
  author={Zhao, Yang and Lin, Zhijie and Zhou, Daquan and Huang, Zilong and Feng, Jiashi and Kang, Bingyi},
  journal={arXiv preprint arXiv:2307.08581},
  year={2023}
}

@article{li2024lego,
  title={LEGO: Language Enhanced Multi-modal Grounding Model},
  author={Li, Zhaowei and Xu, Qi and Zhang, Dong and Song, Hang and Cai, Yiqing and Qi, Qi and Zhou, Ran and Pan, Junting and Li, Zefeng and Vu, Van Tu and others},
  journal={arXiv preprint arXiv:2401.06071},
  year={2024}
}

@article{chen2024mapgpt,
  title={MapGPT: Map-Guided Prompting for Unified Vision-and-Language Navigation},
  author={Chen, Jiaqi and Lin, Bingqian and Xu, Ran and Chai, Zhenhua and Liang, Xiaodan and Wong, Kwan-Yee K},
  journal={arXiv preprint arXiv:2401.07314},
  year={2024}
}

% G-Ref
@inproceedings{nagaraja2016modeling,
  title={Modeling context between objects for referring expression understanding},
  author={Nagaraja, Varun K and Morariu, Vlad I and Davis, Larry S},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14},
  pages={792--807},
  year={2016},
  organization={Springer}
}

% pytorch
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% CLIP
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

% MSCOCO
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

% ViT
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
% Transformer
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
% ReSTR
@inproceedings{kim2022restr,
  title={Restr: Convolution-free referring image segmentation using transformers},
  author={Kim, Namyup and Kim, Dongwon and Lan, Cuiling and Zeng, Wenjun and Kwak, Suha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18145--18154},
  year={2022}
}
% SeqTR
@inproceedings{zhu2022seqtr,
  title={Seqtr: A simple yet universal network for visual grounding},
  author={Zhu, Chaoyang and Zhou, Yiyi and Shen, Yunhang and Luo, Gen and Pan, Xingjia and Lin, Mingbao and Chen, Chao and Cao, Liujuan and Sun, Xiaoshuai and Ji, Rongrong},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV},
  pages={598--615},
  year={2022},
  organization={Springer}
}
% ResNet
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
% Swin-Transformer
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}
% DarkNet
@article{redmon2018yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}
%DenseCRF
@article{krahenbuhl2011efficient,
  title={Efficient inference in fully connected crfs with gaussian edge potentials},
  author={Kr{\"a}henb{\"u}hl, Philipp and Koltun, Vladlen},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}
%RMI
@inproceedings{liu2017recurrent,
  title={Recurrent multimodal interaction for referring image segmentation},
  author={Liu, Chenxi and Lin, Zhe and Shen, Xiaohui and Yang, Jimei and Lu, Xin and Yuille, Alan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1271--1280},
  year={2017}
}
%DMN
@inproceedings{margffoy2018dynamic,
  title={Dynamic multimodal instance segmentation guided by natural language queries},
  author={Margffoy-Tuay, Edgar and P{\'e}rez, Juan C and Botero, Emilio and Arbel{\'a}ez, Pablo},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={630--645},
  year={2018}
}
%RRN
@inproceedings{li2018referring,
  title={Referring image segmentation via recurrent refinement networks},
  author={Li, Ruiyu and Li, Kaican and Kuo, Yi-Chun and Shu, Michelle and Qi, Xiaojuan and Shen, Xiaoyong and Jia, Jiaya},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5745--5753},
  year={2018}
}
%MattNet
@inproceedings{yu2018mattnet,
  title={Mattnet: Modular attention network for referring expression comprehension},
  author={Yu, Licheng and Lin, Zhe and Shen, Xiaohui and Yang, Jimei and Lu, Xin and Bansal, Mohit and Berg, Tamara L},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1307--1315},
  year={2018}
}
%CMSA
@inproceedings{ye2019cross,
  title={Cross-modal self-attention network for referring image segmentation},
  author={Ye, Linwei and Rochan, Mrigank and Liu, Zhi and Wang, Yang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10502--10511},
  year={2019}
}
%BCAN
@inproceedings{hu2020bi,
  title={Bi-directional relationship inferring network for referring image segmentation},
  author={Hu, Zhiwei and Feng, Guang and Sun, Jiayu and Zhang, Lihe and Lu, Huchuan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4424--4433},
  year={2020}
}
%CMPC
@inproceedings{huang2020referring,
  title={Referring image segmentation via cross-modal progressive comprehension},
  author={Huang, Shaofei and Hui, Tianrui and Liu, Si and Li, Guanbin and Wei, Yunchao and Han, Jizhong and Liu, Luoqi and Li, Bo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10488--10497},
  year={2020}
}
%LSCM
@inproceedings{hui2020linguistic,
  title={Linguistic structure guided context modeling for referring image segmentation},
  author={Hui, Tianrui and Liu, Si and Huang, Shaofei and Li, Guanbin and Yu, Sansi and Zhang, Faxi and Han, Jizhong},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part X 16},
  pages={59--75},
  year={2020},
  organization={Springer}
}
%MCN
@inproceedings{luo2020multi,
  title={Multi-task collaborative network for joint referring expression comprehension and segmentation},
  author={Luo, Gen and Zhou, Yiyi and Sun, Xiaoshuai and Cao, Liujuan and Wu, Chenglin and Deng, Cheng and Ji, Rongrong},
  booktitle={Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition},
  pages={10034--10043},
  year={2020}
}
%CGAN
@inproceedings{luo2020cascade,
  title={Cascade grouped attention network for referring expression segmentation},
  author={Luo, Gen and Zhou, Yiyi and Ji, Rongrong and Sun, Xiaoshuai and Su, Jinsong and Lin, Chia-Wen and Tian, Qi},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={1274--1282},
  year={2020}
}
%EFNet
@inproceedings{feng2021encoder,
  title={Encoder fusion network with co-attention embedding for referring image segmentation},
  author={Feng, Guang and Hu, Zhiwei and Zhang, Lihe and Lu, Huchuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15506--15515},
  year={2021}
}
%LTS
@inproceedings{jing2021locate,
  title={Locate then segment: A strong pipeline for referring image segmentation},
  author={Jing, Ya and Kong, Tao and Wang, Wei and Wang, Liang and Li, Lei and Tan, Tieniu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9858--9867},
  year={2021}
}
%RefTr
@article{li2021referring,
  title={Referring transformer: A one-step approach to multi-task visual grounding},
  author={Li, Muchen and Sigal, Leonid},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={19652--19664},
  year={2021}
}
%LSTM
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}
%JWANF
@inproceedings{shi2018key,
  title={Key-word-aware network for referring expression image segmentation},
  author={Shi, Hengcan and Li, Hongliang and Meng, Fanman and Wu, Qingbo},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={38--54},
  year={2018}
}
%BERT
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
%RoBerta
@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}
%Electra
@article{clark2020electra,
  title={Electra: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  journal={arXiv preprint arXiv:2003.10555},
  year={2020}
}
%BEiT V1&V2
@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}
@article{peng2022beit,
  title={Beit v2: Masked image modeling with vector-quantized visual tokenizers},
  author={Peng, Zhiliang and Dong, Li and Bao, Hangbo and Ye, Qixiang and Wei, Furu},
  journal={arXiv preprint arXiv:2208.06366},
  year={2022}
}
%SimMIM
@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9653--9663},
  year={2022}
}
%MAE
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}
%HiViT
@article{huang2022green,
  title={Green hierarchical vision transformer for masked image modeling},
  author={Huang, Lang and You, Shan and Zheng, Mingkai and Wang, Fei and Qian, Chen and Yamasaki, Toshihiko},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19997--20010},
  year={2022}
}
%MixMAE
@article{liu2022mixmim,
  title={Mixmim: Mixed and masked image modeling for efficient visual representation learning},
  author={Liu, Jihao and Huang, Xin and Liu, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2205.13137},
  year={2022}
}
%DBF
@article{tian2023designing,
  title={Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling},
  author={Tian, Keyu and Jiang, Yi and Diao, Qishuai and Lin, Chen and Wang, Liwei and Yuan, Zehuan},
  journal={arXiv preprint arXiv:2301.03580},
  year={2023}
}
%DMJD
@article{ma2022disjoint,
  title={Disjoint Masking with Joint Distillation for Efficient Masked Image Modeling},
  author={Ma, Xin and Liu, Chang and Xie, Chunyu and Ye, Long and Deng, Yafeng and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2301.00230},
  year={2022}
}
%MGD
@inproceedings{yang2022masked,
  title={Masked generative distillation},
  author={Yang, Zhendong and Li, Zhe and Shao, Mingqi and Shi, Dachuan and Yuan, Zehuan and Yuan, Chun},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XI},
  pages={53--69},
  year={2022},
  organization={Springer}
}
%MaskedKD
@article{son2023maskedkd,
  title={MaskedKD: Efficient Distillation of Vision Transformers with Masked Images},
  author={Son, Seungwoo and Lee, Namhoon and Lee, Jaeho},
  journal={arXiv preprint arXiv:2302.10494},
  year={2023}
}
%MaskDW
@article{huang2022masked,
  title={Masked Distillation with Receptive Tokens},
  author={Huang, Tao and Zhang, Yuan and You, Shan and Wang, Fei and Qian, Chen and Cao, Jian and Xu, Chang},
  journal={arXiv preprint arXiv:2205.14589},
  year={2022}
}
%MaskedAE
@inproceedings{bai2023masked,
  title={Masked autoencoders enable efficient knowledge distillers},
  author={Bai, Yutong and Wang, Zeyu and Xiao, Junfei and Wei, Chen and Wang, Huiyu and Yuille, Alan L and Zhou, Yuyin and Xie, Cihang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24256--24265},
  year={2023}
}

%人体part
@inproceedings{gong2017look,
  title={Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing},
  author={Gong, Ke and Liang, Xiaodan and Zhang, Dongyu and Shen, Xiaohui and Lin, Liang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={932--940},
  year={2017}
}
%车辆part
@inproceedings{reddy2018carfusion,
  title={Carfusion: Combining point tracking and part detection for dynamic 3d reconstruction of vehicles},
  author={Reddy, N Dinesh and Vo, Minh and Narasimhan, Srinivasa G},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1906--1915},
  year={2018}
}
%动物part
@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}
%Pascal-Part,
@inproceedings{chen2014detect,
  title={Detect what you can: Detecting and representing objects using holistic models and body parts},
  author={Chen, Xianjie and Mottaghi, Roozbeh and Liu, Xiaobai and Fidler, Sanja and Urtasun, Raquel and Yuille, Alan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1971--1978},
  year={2014}
}
%PartNet, 
@inproceedings{mo2019partnet,
  title={Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding},
  author={Mo, Kaichun and Zhu, Shilin and Chang, Angel X and Yi, Li and Tripathi, Subarna and Guibas, Leonidas J and Su, Hao},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={909--918},
  year={2019}
}
%PartImageNet
@inproceedings{he2022partimagenet,
  title={Partimagenet: A large, high-quality dataset of parts},
  author={He, Ju and Yang, Shuo and Yang, Shaokang and Kortylewski, Adam and Yuan, Xiaoding and Chen, Jie-Neng and Liu, Shuai and Yang, Cheng and Yu, Qihang and Yuille, Alan},
  booktitle={European Conference on Computer Vision},
  pages={128--145},
  year={2022},
  organization={Springer}
}
% PACO
@inproceedings{ramanathan2023paco,
  title={Paco: Parts and attributes of common objects},
  author={Ramanathan, Vignesh and Kalia, Anmol and Petrovic, Vladan and Wen, Yi and Zheng, Baixue and Guo, Baishan and Wang, Rui and Marquez, Aaron and Kovvuri, Rama and Kadian, Abhishek and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7141--7151},
  year={2023}
}
% Part-aware panoptic segmentation
@inproceedings{de2021part,
  title={Part-aware panoptic segmentation},
  author={de Geus, Daan and Meletis, Panagiotis and Lu, Chenyang and Wen, Xiaoxiao and Dubbelman, Gijs},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5485--5494},
  year={2021}
}
%Going Denser with Open-Vocabulary Part Segmentation
@article{sun2023going,
  title={Going Denser with Open-Vocabulary Part Segmentation},
  author={Sun, Peize and Chen, Shoufa and Zhu, Chenchen and Xiao, Fanyi and Luo, Ping and Xie, Saining and Yan, Zhicheng},
  journal={arXiv preprint arXiv:2305.11173},
  year={2023}
}
%RIS-DMMI
@inproceedings{hu2023beyond,
  title={Beyond One-to-One: Rethinking the Referring Image Segmentation},
  author={Hu, Yutao and Wang, Qixiong and Shao, Wenqi and Xie, Enze and Li, Zhenguo and Han, Jungong and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4067--4077},
  year={2023}
}

%zero-shot RIS
@article{ni2023ref,
  title={Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models},
  author={Ni, Minheng and Zhang, Yabo and Feng, Kailai and Li, Xiaoming and Guo, Yiwen and Zuo, Wangmeng},
  journal={arXiv preprint arXiv:2308.16777},
  year={2023}
}

@inproceedings{yu2023zero,
  title={Zero-shot Referring Image Segmentation with Global-Local Context Features},
  author={Yu, Seonghoon and Seo, Paul Hongsuck and Son, Jeany},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19456--19465},
  year={2023}
}

@article{suo2023text,
  title={Text Augmented Spatial-aware Zero-shot Referring Image Segmentation},
  author={Suo, Yucheng and Zhu, Linchao and Yang, Yi},
  journal={arXiv preprint arXiv:2310.18049},
  year={2023}
}

%RIS foundation models

@inproceedings{liu2023gres,
  title={GRES: Generalized referring expression segmentation},
  author={Liu, Chang and Ding, Henghui and Jiang, Xudong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23592--23601},
  year={2023}
}

@inproceedings{zou2023generalized,
  title={Generalized decoding for pixel, image, and language},
  author={Zou, Xueyan and Dou, Zi-Yi and Yang, Jianwei and Gan, Zhe and Li, Linjie and Li, Chunyuan and Dai, Xiyang and Behl, Harkirat and Wang, Jianfeng and Yuan, Lu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15116--15127},
  year={2023}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}

@article{zou2023segment,
  title={Segment everything everywhere all at once},
  author={Zou, Xueyan and Yang, Jianwei and Zhang, Hao and Li, Feng and Li, Linjie and Gao, Jianfeng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.06718},
  year={2023}
}

@inproceedings{lai2024lisa,
  title={Lisa: Reasoning segmentation via large language model},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9579--9589},
  year={2024}
}
@inproceedings{xia2024gsva,
  title={Gsva: Generalized segmentation via multimodal large language models},
  author={Xia, Zhuofan and Han, Dongchen and Han, Yizeng and Pan, Xuran and Song, Shiji and Huang, Gao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3858--3869},
  year={2024}
}
@article{yang2023dawn,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  year={2023}
}

% VG dataset
@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

% Object365 dataset
@inproceedings{shao2019objects365,
  title={Objects365: A large-scale, high-quality dataset for object detection},
  author={Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8430--8439},
  year={2019}
}

% Phrasecut
@inproceedings{wu2020phrasecut,
  title={Phrasecut: Language-based image segmentation in the wild},
  author={Wu, Chenyun and Lin, Zhe and Cohen, Scott and Bui, Trung and Maji, Subhransu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10216--10225},
  year={2020}
}

% Referitgame
@inproceedings{kazemzadeh2014referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={787--798},
  year={2014}
}

% ImageCLEF
@inproceedings{grubinger2006iapr,
  title={The iapr tc-12 benchmark: A new evaluation resource for visual information systems},
  author={Grubinger, Michael and Clough, Paul and M{\"u}ller, Henning and Deselaers, Thomas},
  booktitle={International workshop ontoImage},
  volume={2},
  year={2006}
}

@article{bai2023qwen,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@article{chen2023minigpt,
  title={MINIGPT-V2: LARGE LANGUAGE MODEL AS A UNIFIED INTERFACE FOR VISION-LANGUAGE MULTI-TASK LEARNING},
  author={Chen, Jun and Li, Deyao Zhu1 Xiaoqian Shen1 Xiang and Zhang, Zechun Liu2 Pengchuan and Xiong, Raghuraman Krishnamoorthi2 Vikas Chandra2 Yunyang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2310.09478},
  year={2023}
}

@article{chen2023shikra,
  title={Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic},
  author={Chen, Keqin and Zhang, Zhao and Zeng, Weili and Zhang, Richong and Zhu, Feng and Zhao, Rui},
  journal={arXiv preprint arXiv:2306.15195},
  year={2023}
}
@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={European Conference on Computer Vision},
  pages={709--727},
  year={2022},
  organization={Springer}
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  year={2023}
}


@article{openai2023gpt,
  title={GPT-4 technical report. arXiv 2303.08774},
  author={OpenAI, R},
  journal={View in Article},
  year={2023}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{wang2018learning,
  title={Learning two-branch neural networks for image-text matching tasks},
  author={Wang, Liwei and Li, Yin and Huang, Jing and Lazebnik, Svetlana},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={41},
  number={2},
  pages={394--407},
  year={2018},
  publisher={IEEE}
}

@inproceedings{mao2016generation,
  title={Generation and comprehension of unambiguous object descriptions},
  author={Mao, Junhua and Huang, Jonathan and Toshev, Alexander and Camburu, Oana and Yuille, Alan L and Murphy, Kevin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={11--20},
  year={2016}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@article{chen2018real,
  title={Real-time referring expression comprehension by single-stage grounding network},
  author={Chen, Xinpeng and Ma, Lin and Chen, Jingyuan and Jie, Zequn and Liu, Wei and Luo, Jiebo},
  journal={arXiv preprint arXiv:1812.03426},
  year={2018}
}

@inproceedings{liu2019learning,
  title={Learning to assemble neural module tree networks for visual grounding},
  author={Liu, Daqing and Zhang, Hanwang and Wu, Feng and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4673--4682},
  year={2019}
}

@article{deng2023transvg++,
  title={Transvg++: End-to-end visual grounding with language conditioned vision transformer},
  author={Deng, Jiajun and Yang, Zhengyuan and Liu, Daqing and Chen, Tianlang and Zhou, Wengang and Zhang, Yanyong and Li, Houqiang and Ouyang, Wanli},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}


@article{qu2023rio,
  title={RIO: A Benchmark for Reasoning Intention-Oriented Objects in Open Environments},
  author={Qu, Mengxue and Wu, Yu and Liu, Wu and Liang, Xiaodan and Song, Jingkuan and Zhao, Yao and Wei, Yunchao},
  journal={arXiv preprint arXiv:2310.17290},
  year={2023}
}

@article{wang2024cm,
  title={CM-MaskSD: Cross-Modality Masked Self-Distillation for Referring Image Segmentation},
  author={Wang, Wenxuan and He, Xingjian and Zhang, Yisi and Guo, Longteng and Shen, Jiachen and Li, Jiangyun and Liu, Jing},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}



@article{yan2023eavl,
  title={EAVL: Explicitly Align Vision and Language for Referring Image Segmentation},
  author={Yan, Yichen and He, Xingjian and Wang, Wenxuan and Chen, Sihan and Liu, Jing},
  journal={arXiv preprint arXiv:2308.09779},
  year={2023}
}

@inproceedings{wang2024unveiling,
  title={Unveiling Parts Beyond Objects: Towards Finer-Granularity Referring Expression Segmentation},
  author={Wang, Wenxuan and Yue, Tongtian and Zhang, Yisi and Guo, Longteng and He, Xingjian and Wang, Xinlong and Liu, Jing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12998--13008},
  year={2024}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@inproceedings{deng2021transvg,
  title={Transvg: End-to-end visual grounding with transformers},
  author={Deng, Jiajun and Yang, Zhengyuan and Chen, Tianlang and Zhou, Wengang and Li, Houqiang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1769--1779},
  year={2021}
}

@inproceedings{zhang2017discriminative,
  title={Discriminative bimodal networks for visual localization and detection with natural language queries},
  author={Zhang, Yuting and Yuan, Luyao and Guo, Yijie and He, Zhiyuan and Huang, I-An and Lee, Honglak},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={557--566},
  year={2017}
}

@inproceedings{liao2020real,
  title={A real-time cross-modality correlation filtering method for referring expression comprehension},
  author={Liao, Yue and Liu, Si and Li, Guanbin and Wang, Fei and Chen, Yanjie and Qian, Chen and Li, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10880--10889},
  year={2020}
}

@article{pi2023detgpt,
  title={DetGPT: Detect What You Need via Reasoning},
  author={Pi, Renjie and Gao, Jiahui and Diao, Shizhe and Pan, Rui and Dong, Hanze and Zhang, Jipeng and Yao, Lewei and Han, Jianhua and Xu, Hang and Zhang, Lingpeng Kong Tong},
  journal={arXiv preprint arXiv:2305.14167},
  year={2023}
}

@inproceedings{wang2022ofa,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International Conference on Machine Learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}

@article{wang2023visionllm,
  title={Visionllm: Large language model is also an open-ended decoder for vision-centric tasks},
  author={Wang, Wenhai and Chen, Zhe and Chen, Xiaokang and Wu, Jiannan and Zhu, Xizhou and Zeng, Gang and Luo, Ping and Lu, Tong and Zhou, Jie and Qiao, Yu and others},
  journal={arXiv preprint arXiv:2305.11175},
  year={2023}
}

@inproceedings{liu2023polyformer,
  title={PolyFormer: Referring image segmentation as sequential polygon generation},
  author={Liu, Jiang and Ding, Hui and Cai, Zhaowei and Zhang, Yuting and Satzoda, Ravi Kumar and Mahadevan, Vijay and Manmatha, R},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18653--18663},
  year={2023}
}

@article{you2023ferret,
  title={Ferret: Refer and ground anything anywhere at any granularity},
  author={You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei},
  journal={arXiv preprint arXiv:2310.07704},
  year={2023}
}

@inproceedings{kamath2021mdetr,
  title={Mdetr-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021}
}
%EVA-CLIP
@article{sun2023eva,
  title={Eva-clip: Improved training techniques for clip at scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}
%ADE-Aff
@inproceedings{chuang2018learning,
  title={Learning to act properly: Predicting and explaining affordances from images},
  author={Chuang, Ching-Yao and Li, Jiaman and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={975--983},
  year={2018}
}
%PAD
@article{luo2021one,
  title={One-shot affordance detection},
  author={Luo, Hongchen and Zhai, Wei and Zhang, Jing and Cao, Yang and Tao, Dacheng},
  journal={arXiv preprint arXiv:2106.14747},
  year={2021}
}
%PADV2
@article{zhai2022one,
  title={One-shot object affordance detection in the wild},
  author={Zhai, Wei and Luo, Hongchen and Zhang, Jing and Cao, Yang and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={130},
  number={10},
  pages={2472--2500},
  year={2022},
  publisher={Springer}
}

%COCO-Tasks
@inproceedings{sawatzky2019object,
  title={What object should i use?-task driven object detection},
  author={Sawatzky, Johann and Souri, Yaser and Grund, Christian and Gall, Jurgen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7605--7614},
  year={2019}
}

%GPT-4
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

%multimodal embodied AI
@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{shah2023lm,
  title={Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action},
  author={Shah, Dhruv and Osi{\'n}ski, B{\l}a{\.z}ej and Levine, Sergey and others},
  booktitle={Conference on Robot Learning},
  pages={492--504},
  year={2023},
  organization={PMLR}
}

@article{gao2023physically,
  title={Physically grounded vision-language models for robotic manipulation},
  author={Gao, Jensen and Sarkar, Bidipta and Xia, Fei and Xiao, Ted and Wu, Jiajun and Ichter, Brian and Majumdar, Anirudha and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2309.02561},
  year={2023}
}

%egocentric dataset（下面四篇）
%EgoObjects--object detection
@inproceedings{zhu2023egoobjects,
  title={Egoobjects: A large-scale egocentric dataset for fine-grained object understanding},
  author={Zhu, Chenchen and Xiao, Fanyi and Alvarado, Andr{\'e}s and Babaei, Yasmine and Hu, Jiabo and El-Mohri, Hichem and Culatana, Sean and Sumbaly, Roshan and Yan, Zhicheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20110--20120},
  year={2023}
}

%RefEgo--video grounding
@inproceedings{kurita2023refego,
  title={Refego: Referring expression comprehension dataset from first-person perception of ego4d},
  author={Kurita, Shuhei and Katsura, Naoki and Onami, Eri},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15214--15224},
  year={2023}
}

%DetermiNet--REC
@inproceedings{lee2023determinet,
  title={DetermiNet: A Large-Scale Diagnostic Dataset for Complex Visually-Grounded Referencing using Determiners},
  author={Lee, Clarence and Kumar, M Ganesh and Tan, Cheston},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20019--20028},
  year={2023}
}

%REVERIE--VLN+REC
@inproceedings{qi2020reverie,
  title={Reverie: Remote embodied visual referring expression in real indoor environments},
  author={Qi, Yuankai and Wu, Qi and Anderson, Peter and Wang, Xin and Wang, William Yang and Shen, Chunhua and Hengel, Anton van den},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9982--9991},
  year={2020}
}
@article{reed2022generalist,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}
@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}
@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}
@article{zhu2020deformable,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2010.04159},
  year={2020}
}
@inproceedings{wu2022language,
  title={Language as queries for referring video object segmentation},
  author={Wu, Jiannan and Jiang, Yi and Sun, Peize and Yuan, Zehuan and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4974--4984},
  year={2022}
}
@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}
@inproceedings{rezatofighi2019generalized,
  title={Generalized intersection over union: A metric and a loss for bounding box regression},
  author={Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={658--666},
  year={2019}
}
@inproceedings{milletari2016v,
  title={V-net: Fully convolutional neural networks for volumetric medical image segmentation},
  author={Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
  booktitle={2016 fourth international conference on 3D vision (3DV)},
  pages={565--571},
  year={2016},
  organization={Ieee}
}
@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}