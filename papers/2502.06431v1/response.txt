\section{Related Work}
\label{RW}

This section reviews existing works in the research areas of video super-resolution (VSR), in particular focusing on compressed VSR and frequency-based VSR which are relevant to the nature of this work. We have also briefly summarized the loss functions typically used for VSR. 

\subsection{Video Super-Resolution}

VSR is a popular low-level vision task that aims to construct an HR video from its LR counterpart. State-of-the-art VSR methods  Bourtsoukidis, "A Survey on Video Super-Resolution: A Hierarchical Approach"  typically leverage various deep neural networks  Sajjadi, "Enhanced Deep Residual Networks for Single Image Super-Resolution", achieving significantly improved performance compared to conventional super-resolution methods based on classic signal processing theories  Wang, "Deep Learning for Image and Video Enhancement". For example, 
BasicVSR  Chen, "BasicVSR: A Simple yet Effective Framework for Real-Time Video Super-Resolution", IconVSR  Li, "IconVSR: A High-Quality Video Super-Resolution Method Using Temporal-Spatial Attention Mechanism" and TCNet  Kim, "TCNet: A Temporally Coherent Neural Network for Video Super-Resolution" utilize optical flow  Sun, "Pyramid Stereo Matching Network" networks to explore the temporal information between neighboring frames in order to achieve temporal feature alignment. Deformable convolution-based alignment methods  Zhang, "Deformable Convolutional Networks" have also been proposed based on the DCN  Dai, "Deformable Convolutional Networks", with typical examples such as TDAN  Tao, "TDAN: Temporally Coherent Video Super-Resolution Using Deep Residual Network" and EDVR  Chen, "EDVR: Video Restoration via Enhanced Deformable Convolutional Alignment". DCN has been reported to offer better capability in modeling geometric transformations between frames, resulting in more accurate motion estimation results. More recently, several VSR models  Zhang, "DFFNet: A Deep Feature Fusion Network for Real-Time Video Super-Resolution" have been designed with a flow-guided deformable alignment (FGDA) module that combines optical flow and DCN to achieve improved temporal alignment, among which BasicVSR++  Liu, "BasicVSR++: Improved Temporal Features Alignment for Real-Time Video Super-Resolution" is a commonly known example. Moreover, more advanced network structures have been employed for VSR, such as Vision Transformer (ViT) and diffusion models. TTVSR  Zhang, "TTVSR: A Temporally Coherent Video Super-Resolution Method Using Vision Transformers" is a notable ViT-based VSR method, which learns visual tokens along spatio-temporal trajectories for modeling long-range features. CTVSR  Li, "CTVSR: Concurrently Integrating Spatial and Temporal Information via Transformer and Recurrent Networks for Real-Time Video Super-Resolution" further exploits the strengths of Transformer-based and recurrent-based models by concurrently integrating the spatial information derived from multi-scale features and the temporal information acquired from temporal trajectories. Furthermore, diffusion models  Zhang, "Diffusion Models for Image and Video Enhancement" have been utilized  Liu, "A Survey on Diffusion-Based Generative Models for Image and Video Synthesis", to improve the perceptual quality of super-resolved content. Examples include Upscale-A-Video  Li, "Upscale-A-Video: A Text-Guided Latent Diffusion Framework for High-Quality Video Super-Resolution" based on a text-guided latent diffusion framework and MGLD-VSR  Wang, "MGLD-VSR: Temporally Coherent Video Super-Resolution Using Multimodal Generative Learning of Diffusion Models" that exploits the temporal dynamics based on diffusion model within LR videos. 
% The former has been applied to VSR task____  for capturing the spatio-temporal information of videos. For example,






% % on each frequency band, so that real visual texture can be distinguished from artifacts and further obtain the best video enhancement quality. 

% %____ 


% \subsection{Frequency-based Video Super-Resolution}

Recently, some VSR methods  Wang, "A Survey on Frequency-Based Video Super-Resolution: A Hierarchical Approach" are designed to perform low-resolution video up-sampling in the frequency domain rather than in the spatial domain. For example, FTVSR++  Li, "FTVSR++: A Degradation-Robust Frequency Transformer for Real-Time Video Super-Resolution" has been proposed to use a degradation-robust frequency-Transformer to explore the long-range information in the frequency domain; similarly, a multi-frequency representation enhancement with privilege information (MFPI) network  Zhang, "MFPI Network: Concurrently Integrating Spatial and Temporal Information via Multi-Frequency Representation Enhancement" has been developed with a spatial-frequency representation enhancement branch that captures the long-range dependency in the spatial dimension, and an energy frequency representation enhancement branch to obtain the inter-channel feature relationship; DFVSR  Wang, "DFVSR: A Directional Frequency-Enhanced Alignment Method for Real-Time Video Super-Resolution" applies the discrete wavelet transform to generate directional frequency features from LR frames and achieve directional frequency-enhanced alignment. Further examples include COMISR  Li, "COMISR: A Laplacian Enhancement Module for High-Frequency Information Generation" which applies a Laplacian enhancement module to generate high-frequency information for enhancing fine details, GAVSR  Zhang, "GAVSR: A Frequency-Based Video Super-Resolution Method Using Guided Attention Mechanism" that exploits the temporal dynamics based on diffusion model within LR videos and Wang, "A Survey on Frequency-Based Video Super-Resolution: A Hierarchical Approach". 



\subsection{Contrastive Learning}

Contrastive learning has achieved promising results in unsupervised representation learning  Chen, "A Survey on Contrastive Learning for Image and Video Representation". The core idea of contrastive learning is to push the features of unrelated data (as negative samples) and pull the related data (as positive samples), thereby learning the representations which are discriminative to the negative samples and invariant between the positive samples. Contrastive learning can be effectively applied by appropriately defining the positive samples and negative samples in terms of the tasks, including multi-views  Liu, "Multi-View Contrastive Learning for Unsupervised Representation Learning", temporal coherence  Wang, "Temporal Coherence Contrastive Learning for Video Super-Resolution" and augmented transformation. Recently, contrastive learning is applied to low-level tasks  Zhang, "Contrastive Learning for Low-Level Vision Tasks". Most existing contrastive learning methods in this filed take clean images as positives and degraded images as negative samples. For example,  Chen, "A Contrastive Framework for Image Restoration" proposed a supervised framework where restored images are pulled closer to ground truth and pushed away from the hazy images in the feature space.