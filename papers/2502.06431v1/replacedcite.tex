\section{Related Work}
\label{RW}

This section reviews existing works in the research areas of video super-resolution (VSR), in particular focusing on compressed VSR and frequency-based VSR which are relevant to the nature of this work. We have also briefly summarized the loss functions typically used for VSR. 

\subsection{Video Super-Resolution}

VSR is a popular low-level vision task that aims to construct an HR video from its LR counterpart. State-of-the-art VSR methods ____ typically leverage various deep neural networks____, achieving significantly improved performance compared to conventional super-resolution methods based on classic signal processing theories____. For example, 
BasicVSR____, IconVSR____ and TCNet____ utilize optical flow____ networks to explore the temporal information between neighboring frames in order to achieve temporal feature alignment. Deformable convolution-based alignment methods____ have also been proposed based on the DCN____, with typical examples such as TDAN____ and EDVR____. DCN has been reported to offer better capability in modeling geometric transformations between frames, resulting in more accurate motion estimation results. More recently, several VSR models____ have been designed with a flow-guided deformable alignment (FGDA) module that combines optical flow and DCN to achieve improved temporal alignment, among which BasicVSR++____ is a commonly known example. Moreover, more advanced network structures have been employed for VSR, such as Vision Transformer (ViT) and diffusion models. TTVSR____ is a notable ViT-based VSR method, which learns visual tokens along spatio-temporal trajectories for modeling long-range features. CTVSR____ further exploits the strengths of Transformer-based and recurrent-based models by concurrently integrating the spatial information derived from multi-scale features and the temporal information acquired from temporal trajectories. Furthermore, diffusion models____ have been utilized____ to improve the perceptual quality of super-resolved content. Examples include Upscale-A-Video____ based on a text-guided latent diffusion framework and MGLD-VSR____ that exploits the temporal dynamics based on diffusion model within LR videos. 
% The former has been applied to VSR task____  for capturing the spatio-temporal information of videos. For example,






% % on each frequency band, so that real visual texture can be distinguished from artifacts and further obtain the best video enhancement quality. 

% %____ 

% \subsection{Frequency-based Video Super-Resolution}

Recently, some VSR methods____ are designed to perform low-resolution video up-sampling in the \textbf{frequency} domain rather than in the spatial domain. For example, FTVSR++____ has been proposed to use a degradation-robust frequency-Transformer to explore the long-range information in the frequency domain; similarly, a multi-frequency representation enhancement with privilege information (MFPI) network____ has been developed with a spatial-frequency representation enhancement branch that captures the long-range dependency in the spatial dimension, and an energy frequency representation enhancement branch to obtain the inter-channel feature relationship; DFVSR____ applies the discrete wavelet transform to generate directional frequency features from LR frames and achieve directional frequency-enhanced alignment. Further examples include COMISR____ which applies a Laplacian enhancement module to generate high-frequency information for enhancing fine details, GAVSR____ that employs a high-frequency mask based on Gaussian blur to assist the attention mechanism and FTVSR____ which is based on a Frequency-Transformer to conduct self-attention over a joint space-time-frequency domain. However, these frequency-based methods do not fully explore the multiple frequency subbands of the features or account for the motion relationships in the frequency domain, which restricts the exploration of more valuable information.
% \hl{[The issues with existing compressed VSR!]}

In many application scenarios, VSR is applied to compressed LR content, making the task even more challenging compared to uncompressed VSR. Recently, this has become a specific research focus, and numerous \textbf{compressed VSR} methods____ have been developed based on coding priors. For example, CD-VSR____ utilizes motion vectors, predicted frames, and prediction residuals to reduce compression artifacts and obtain spatio-temporal details for HR content; CIAF____ employs recurrent models together with motion vectors to characterize the temporal relationship between adjacent frames; CAVSR____ also adopts motion vectors and residual frames to achieve information fusion. It is noted that these methods are typically associated with increased complexity in order to fully leverage these coding priors, which limits their adoption in practical applications. 
% \hl{Complexity issues: decoder}

% \begin{figure*}[!t]
% \centering
% \includegraphics[width=0.998\textwidth]{figures/pipeline13.pdf}
% \caption{ The architecture of FCVSR model. The consecutive LR compressed video frames are gradually fed into the convolution layers, MGAA, MFFR, and reconstruction module to generate HR videos. Besides, a combined loss function based on an energy-based temporal consistency loss and a frequency-aware contrastive learning loss is adopted to supervise the generation of high-quality HR videos in the frequency domain.}
% \label{fig_pipeline}
% \end{figure*}


\begin{figure*}[!t]
\centering
\includegraphics[width=0.998\textwidth]{figures/FCVSR_pipe2.pdf}
\caption{ The architecture of FCVSR model. An LR compressed video is fed into a convolution layer, MGAA, MFFR, and reconstruction (REC) modules to generate an HR video.}
\label{fig_pipeline}
\end{figure*}

\subsection{Loss Functions of Video Super-Resolution}

When VSR models were optimized, various loss functions were employed to address different application scenarios. 
These can be classified into two primary groups: spatial- and frequency-based. 
Spatial-based loss functions aim to minimize the pixel-wise discrepancy between the generated HR frames and the corresponding ground truth (GT) frames during training, with $L_1$ and $L_2$ losses are the commonly used objectives. Furthermore, the Charbonnier loss____ is a differentiable and smooth approximation of the $L_2$ loss, with similar robustness as the $L_1$ loss for reducing the weight of large errors and focusing more on smaller errors. Recently, some frequency-based loss functions____ are proposed to explore the high-frequency information. For example, a Fourier space loss____ calculated the frequency components in the Fourier domain for direct emphasis on the frequency content for restoration of high-frequency components. A focal frequency loss____ generated the frequency representations using the discrete Fourier transform to supervise the generation of high-frequency information. However, these frequency-based loss functions typically observe global frequency information without decomposing features into different frequency subbands, which constrains VSR models to recover fine details. 

% Temporal-based losses focus on the temporal dynamics between frames to ensure the temporal consistency of the generated videos. For example, a SOF-VSR____ model utilizes an optical flow-based loss function, which compares the aligned frame and GT, while DFVSR____ employs a directional frequency loss based on the discrete wavelet transform (DWT) to ensure the accuracy of motion information in the temporal alignment. % \blue{It is noted that however these temporal-based loss functions are used independently for optimizing aligned features, which lack of global optimization of temporal consistency in restored videos.}


% \subsubsection{Alignment for Video Super-Resolution}

% Here, we illustrate three representative alignment modules in VSR task, i.e., optical flow-based alignment____, deformable convolution-based alignment____, and flow-guided deformable alignment____, in Fig. \ref{fig_tempalign}(a)-(c).  Specifically, in optical flow-based alignment____, two frames are firstly fed into the optical flow network to estimate optical flow. Then, the estimated optical flow is adopted to warp the current frame to obtain the aligned frame.
% % The optical flow network decides the performance and efficiency of this alignment. 
% In deformable convolution-based alignment____, the offsets are learned from two frames by several convolution layers and then the learned offsets and current frame are fed into deformable convolution to generate aligned frame. 
% % The deformable convolution mainly decides the performance and efficiency of this alignment. 
% In flow-guided deformable convolution-based alignment____, the optical flow is adopted to guide the generation of more motion, which increase the diversity of offsets.  
% % The deformable convolution and optical flow network mainly decides the performance and efficiency of this alignment. 
% The proposal of flow-guided deformable convolution-based alignment____ greatly improves the accuracy of alignment and achieves a significant VSR performance gain. 

% Our adaptive convolution-based alignment is illustrated in Fig. \ref{fig_tempalign}(d), in our alignment module, the multi-motions are generated by the motion estimator in the frequency domain.  
% %Based on our above observation in Fig. \ref{fig_fluseq},  the temporal information is amplified in the frequency domain, which inspires us to learn the difference between frames to increase the diversity of motion for accurate alignment. 
% We design an adaptive convolution to flexibly customize the learnable kernel and receptive field with low complexity. Based on these designs, our adaptive convolution-based alignment can achieve better alignment performance with lower complexity than the existing three representative alignment modules. We cascaded applying separable adaptive convolution____ with the guidance of multi-motion to fully exploit the nonlinear nature of deep networks. Our separable adaptive convolution-based cascaded scheme also enables small-sized separable adaptive convolutions to be used for establishing large receptive fields.


% \begin{comment}
% Adaptive convolution____ have been proposed to facilitate the adaptive handling of features in various tasks____, such as frame interpolation____, deblurring____, and semantic segmentation____. Adaptive convolution commonly consists of kernel prediction of adaptive convolution and feature transformation of adaptive convolution based on the predicted kernel. However, handling large receptive field requires predicting large kernels, which results in huge computational cost____. To reduce computational cost when predicting large kernel, separable adaptive convolutions____ were proposed to secure larger receptive fields at lower computational costs than the adaptive convolution____  by utilizing 1-dim kernels, instead of 2-dim kernels. However, compared to dense 2-dim convolution kernel, separable adaptive convolution may not provide enough accuracy for feature representation. 
% \end{comment}


% In recently years, the deformable convolution-based alignment____ is widely applied in video super-resolution task, due to strong ability of feature learning. However, this alignment still has following limitations:

% 1) \textbf{Fixed Kernel}. The fixed kernel of DCN is adopted for all computation of DCN, which reduces the diversity of feature representation learning. Although the deformable property enhances DCN to explore the more valuable position information for alignment, the fixed kernel decreases the representation feature. 2) \textbf{High Complexity}. In most deformable convolution-based alignment modules____, the kernel size of DCN is 3$\times$3. As the kernel size of DCN increases, the complexity significantly increases so as to bring huge computational cost. The comparable results are provided in Section \ref{EXP}.  3) \textbf{Single Offset}. The simple offset is only learned in DCN, which limits the diversity of temporal information learning for improvement of alignment performance. Although the flow-guided deformable convolution____ is proposed to avoid the overflow of offset, the generation of signal offset lacks the diversity.

% To solve the limitations of deformable convolution-based alignment for high performance and high efficient alignment, we propose the  adaptive convolution-based alignment and we illustrate its advantages:

% 1) \textbf{Flexible Kernel}. Cascaded kernels are designed for specific motion alignment in adaptive convolution, so that the kernel of adaptive convolution are not fixed and the learning of kernels is flexible. 2) \textbf{Low Complexity}. We adopt a adaptive separable convolution, which significantly reduces the complexity of 2-dim adaptive convolution so as to improving large receptive fields with low complexity. Besides, we design a motion estimator in the frequency domain to learn more accurate motion while reducing complexity.  3) \textbf{Motion Diversity}. The design of grouping motion enhances the diversity of motion information and improve the alignment performance. 




% \subsection{Contrastive Learning}

% Contrastive learning has achieved promising results in unsupervised representation learning____. The core idea of contrastive learning is to push the features of unrelated data (as negative samples) and pull the related data (as positive samples), thereby learning the representations which are discriminative to the negative samples and invariant between the positive samples. Contrastive learning can be effectively applied by appropriately defining the positive samples and negative samples in terms of the tasks, including multi-views____, temporal coherence____, augmented transformation____. Recently, contrastive learning is applied to low-level tasks____. Most existing contrastive learning methods in this filed take clean images as positives and degraded images as negative samples. For example,____ proposed a supervised framework where restored images are pulled closer to ground truth and pushed away from the hazy images in the feature space.  





\begin{comment}