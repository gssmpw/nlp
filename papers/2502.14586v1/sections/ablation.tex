% \section{Analyses}
\section{\new{Discussion}}
\label{sec:discussion}
\new{
We now analyze HVAE behavior in terms of the produced adversarial sample (Section~\ref{subsec:quality}), and loss function (Section~\ref{subsec:objective}).
We also discuss possible countermeasures for our MOSHI attack (Section~\ref{subsec:counter}).
}

\subsection{Qualitative Analysis}
\label{subsec:quality}
%\textbf{ADD HERE EXAMPLE OF ORIGINAL AND PRODUCED SAMPLES. For the speech, you can reproduce the spectrogram}
Here we will discuss the quality samples generated by our HVAE, which constitute the poisoned validation set $\mathcal{S}^{Val}_{pois}$.
% By way of example, we report in Figure~\ref{fig:poison_samples} two samples with the respective labels generated by HVAE trained in either the MNIST, CIFAR10, and SpeechC cases, from the knowledge of all the trained models.
\new{
As an example, Figure~\ref{fig:poison_samples} showcases two samples for each dataset, along with their corresponding labels, generated by the HVAE trained on the MNIST, CIFAR10, and SpeechC cases.
}
As it can be easily seen, these poisoned samples carry little to no resemblance to the original samples.
Such a result suggests that HVAE objective loss (see Equation~\ref{lossMHVAE}) does take little consideration reconstruction loss $\mathcal{L}_{\mathrm{rec}}$. 
We investigate the interplay between the three components (\textit{i.e., $\mathcal{L}_{\mathrm{rec}}, \mathcal{L}_{\mathrm{KLD}}, Hj_{cost}$}) in Section~\ref{subsec:objective}.

% \begin{figure}[!htpb]
%     \centering
%     \includesvg[width=0.5\linewidth]{figures/poison_samples_v2}
%     \caption{Illustration of samples from $\mathcal{S}^{Val}_{pois}$ for the three tasks: MNIST, CIFAR10, and Speech Commands.}
%     \label{poison_samples}
% \end{figure}

\begin{figure}[!htpb]
  \centering
  \begin{subfigure}{0.225\linewidth}
     \centering
     \includesvg[width=\linewidth]{figures/7-MNIST.svg}
     % \includegraphics[width=\textwidth]{}
     \caption{MNIST}
     \label{subfig:7mnist}
  \end{subfigure}
  \hspace{0.05\linewidth}
  \begin{subfigure}{0.225\linewidth}
     \centering
     \includesvg[width=\linewidth]{figures/7-CIFAR.svg}
     \caption{CIFAR10.}
     \label{subfig:7cifar}
  \end{subfigure}
  \hspace{0.05\linewidth}
  \begin{subfigure}{0.225\linewidth}
     \centering
     \includesvg[width=\linewidth]{figures/7-SR.svg}
     \caption{SpeechC.}
     \label{subfig:7sr}
  \end{subfigure}
  \caption{Illustration of samples from $\mathcal{S}^{Val}_{pois}$.}
  \label{fig:poison_samples}
\end{figure}
 
\subsection{Objective Function}
\label{subsec:objective}

In this section, we investigate the interplay of the factors that compose the objective described in Equation~\ref{MHVAE}, on different tasks and different hijack metrics. 
%\textbf{show in the different cases how the loss and its three components work for the HVAE}
This mainly happens as the two factors $\mathcal{L}_{\mathrm{rec}}$ and $Hj_{cost}$ work one against the other.
In order to better visualize this phenomenon, we report Figure~\ref{HVAE_losses}, depicting the trend of both factors during the training of an HVAE, assuming the complete knowledge of the 180 models trained for the MNIST case.
From this figure, it can be seen how both factors follow
the same trend.
Therefore, aiming at increasing the $Hj_{cost}$ for creating poisonous samples able to sway the MS phase is, at the same time, contrasting the generation of samples that resemble the original ones.

\begin{figure}[!htbp]
    \centering
    \includesvg[width=0.8\linewidth]{figures/loss}
    \caption{HVAE objective function for: MNIST dataset, White-box knowledge, $\ell_0$, and global granularity grid. Note that the image is meant to show only the objective trends and it does not reflect the real values.}
    \label{HVAE_losses}
\end{figure}

% \subsection{Discussion}
\subsection{\new{Countermeasures}}
\label{subsec:counter}
MOSHI-generated samples do not resemble the original training points qualitatively speaking. 
This represents a weakness in MOSHI, which we hypothesize could allow a defense, that focuses on the detection of the poisonous samples - like MagNet~\cite{2017magnet} - to be able to contrast it.
Usually, defenses of this type are implemented against evasion attacks and are able to detect or perform small corrections on input samples, before they are presented to the network.
To our knowledge, no defense mechanism of this kind has ever been deployed to defend the Model Selection phase (as MOSHI is the first of its kind); moreover, we hypothesize that such a defense may be able to contrast the attack as is, but, we also believe it possible, that future studies may be able to create samples better resembling the clean ones, thus rendering these defenses ineffective.