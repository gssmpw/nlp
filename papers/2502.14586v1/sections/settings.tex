\section{Experimental Settings}
We now describe the experimental settings utilized to demonstrate MSHAA attack. 
The experiments are conducted utilizing Python 3.10 scripts, and standard ML libraries to design deep learning experiments such as PyTorch~\cite{paszke2019pytorch}. 
All experiments are executed on a machine with 32GB RAM with an NVIDIA GeForce RTX 3090.
We publicly released our GitHub repository to reproduce our experiments fully: 
\url{https://anonymous.4open.science/r/MSHAA-68DD/README.md}

\subsection{Case Studies}
We designed three distinct case studies to test the MSHAA attack performance: two yield from the Computer Vision (CV) field, and the remaining one from Speech Recognition (SR), all in the classification task.
We opted to test these two distinct application domains %(CV and SR) 
to understand the generalization of the attack in different AI scenarios. 
We now briefly describe the three tasks.\footnote{All these datasets were imported using the corresponding PyTorch libraries.} 
\begin{itemize}
    \item \textit{MNIST (CV)~\cite{lecun2010mnist}}. It is a dataset of bilevel $28 \times 28$ handwritten digits divided into 10 classes: one for each digit from 0 to 9. The victim models considered for this case are FeedForward Neural Networks, with hyperparameters grid concerning the number of neurons per layer and the number of layers themselves. 
    \item \textit{CIFAR10 (CV)~\cite{cifar10}}. It is a dataset of colored $32 \times 32$ images of various subjects belonging to 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. In this case study the victim models are DenseNets \cite{huang2017densely}, of which we adapted the implementation done by \cite{PyTorchDenseNet}. The considered hyperparameters grid sees the number of dense blocks and the number of neurons for the fully connected layer which feeds the output one.
    \item \textit{Speech Commands (SR)~\cite{speechcommandsdataset}}. It is a dataset composed of audio files that are about 1 second long (around 16000 frames long) and belong to 35 classes of different commands spoken by different people. Here, the victim models are Convolutional Neural Networks composed of 1D convolutional layers, and the considered hyperparameters are the number of convolutional layers and the width of the fully connected layer that feeds the output one (code adapted from \cite{PyTorchSpeechCommands}).
\end{itemize}
All the models considered are feedforward neural networks, with an output composed of one or more dense layers that map the hidden representations to the output space. The architecture of the hidden layers varies depending on the specific task. A detailed list of the layers used is provided in Table \ref{tab.hp}.
In total, we trained 472 models, considering both white-box and black-box scenarios, 360 for MNIST, 84 for CIFAR10, and 32 for Speech Commands. 
Figure~\ref{fig:clean_samples} shows two examples for each dataset. Note that for the Speech Commands, we display the frequency spectrum. 

\begin{table}[!htpb]
\centering
\footnotesize
\caption{Hyper parameters grouped by use case. }
\begin{tabular}{cc} \toprule
\multicolumn{2}{c}{\textit{\textbf{MNIST}}} \\ \midrule
    $\#$ layers &     $[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]$        \\
    $\#$ neurons &     $[32, 64, 128]$        \\
    $\#$ learning rate &     $[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]$       \\ \midrule
    \multicolumn{2}{c}{\textit{\textbf{CIFAR10}}} \\ \midrule
    $\#$ dense blocks &     $[2, 3, 4, 5, 6, 7, 8]$        \\
    $\#$ neurons dense layer&     $[128, 256, 512]$        \\
    $\#$ learning rate &     $[0.001, 0.005]$       \\ \midrule
    \multicolumn{2}{c}{\textit{\textbf{Speech Commands}}} \\ \midrule
    $\#$ 1D conv layers &     $[2, 4, 6, 8]$        \\
    $\#$ neurons dense layer &     $[128, 256]$        \\
    $\#$ learning rate &     $[0.001, 0.005]$       \\ \bottomrule
\end{tabular}
\label{tab.hp}
\end{table}

\begin{figure}[!htpb]
    \centering
    \includesvg[width=0.5\linewidth]{figures/clean_samples}
    \caption{Illustration of samples from $\mathcal{S}^{Val}_{pois}$ for the three tasks: MNIST, CIFAR10, and Speech Commands.}
    \label{fig:clean_samples}
\end{figure}
 

\subsection{HVAE Implementations \& Attack Grid}\label{ssec.grid}
Regardless of the case study at hand, we conduct the attacks by considering each task's whole model's grids but also subsets. 
For instance, in the MNIST case, we execute the attack when considering the whole hyperparameters grid (\textit{i.e.} the number of layers, number of neurons, learning rate) but also cases where we fixed - for instance - the learning rate and we vary the other two hyper parameters. 
With this experimental setting, we aim to understand the attack effectiveness at different granularity. Table~\ref{tab.grid} describes the attack grid. 
For instance, when considering the MNIST scenario, we can execute the attack on the entire combination of hyperparameters (\textit{i.e.} learning rate, number of layers and neurons), consisting in one set containing 180 models, or, when grouping on the learning rate, we obtain 6 distinct sets (one per learning rate) constituted by 30 models ($3$ types of neurons $\times$ $10$ types of number of layers). 

\begin{table}[!htpb]
\centering
\footnotesize
\caption{Attack grid grouped by use case. }
\begin{tabular}{ccc} \toprule
\multicolumn{3}{c}{\textit{\textbf{MNIST}}} \\ \midrule
    \textit{Grouped-by} & \textit{\# sets} & \textit{\# models}\\ \hline
    Global &     1    &  180 \\
    learning rate &     6  &  30   \\
    learning rate \& $\#$ neurons &  18 &  10\\ \midrule
    \multicolumn{3}{c}{\textit{\textbf{CIFAR10}}} \\ \midrule
    Global &  1  &  42 \\
    learning rate &  2   & 21\\
    learning rate \& $\#$ neurons &    6    &   7 \\ \midrule
    \multicolumn{3}{c}{\textit{\textbf{Speech Commands}}} \\ \midrule
    Global &     1   &  16\\
    learning rate &   2  &  8 \\ 
    learning rate \& $\#$ neurons &    4   &  4  \\ \bottomrule
\end{tabular}
\label{tab.grid}
\end{table}
\par
In both white box and black box settings, we assume that the attacker has some different amount of knowledge at his disposal when launching the attack. In other words, we used sets of the models either clean or surrogate (obtained the same way as the aforementioned attack grid), to train the HVAE. In total, we trained 50 HVAE in MNIST: 25 sets over the three grouping conditions multiplied by the two knowledge levels (\textit{i.e.} white-box and black-box).
Similarly, we trained 18 and 14 HVAE for CIFAR10 and Speech Commands, respectively. 
\par
Finally, for each dataset, we trained HVAE with different architectures: 
\begin{itemize}
    \item \textit{MNIST}. The HVAE comprises only fully connected layers and is trained using Binary Cross Entropy as a reconstruction loss ($\mathcal{L}_{\mathrm{rec}}$). 
    \item \textit{CIFAR10}. For CIFAR10, the HVAE adopted is composed of 2D convolutional layers, and the adopted reconstruction loss ($\mathcal{L}_{\mathrm{rec}}$) is the Mean Square Error.
    \item \textit{Speech Commands}. The HVAE are made of 1D convolutional layers, with the Mean Square Error as the reconstruction loss ($\mathcal{L}_{\mathrm{rec}}$).
\end{itemize}

\subsection{Hijack Metrics}
We now describe the implementation details of the hijack metrics described in Section~\ref{ssec.hm-theory}. \textit{Generalization Metric}. This hijack metric consists of the loss obtained by our models when processing the original (legitimate) validation set. 
\textit{Latency Metric}: It is obtained by measuring the overall processing time of a given set of input data.
\textit{Energy Consumption}: it is computed by an ASIC simulator \footnote{\url{https://github.com/iliaishacked/sponge_examples}} \footnote{\url{https://github.com/Cinofix/sponge_poisoning_energy_latency_attack}} adapting the functions already developed for \cite{shumailov2021sponge} and \cite{cina2022energy}. As this tool was not compatible with the specific architecture used for the classification models of the SpeechCommands dataset, this was the only case in which we did not consider this specific metric.
\texttt{$\ell_0$ Norm}: we computed the mean of the non-zero activations of each ReLU Layer in our models when processing a set of input data. 
This metric is closely related to energy consumption and can be considered an alternative that does not rely on ASIC simulators. As a result, it can be applied to any architecture, offering broader applicability.

\subsection{Evaluation Metrics}
In order to qualitatively estimate the effectiveness of the
attack against the specific modelâ€™s grid set considered, we
introduce two novel distinct metrics: the \textit{Effectiveness Score Function} (ESF) and the \textit{Attack Success Rate} (ASR).
\par
% In order to qualitatively estimate the effectiveness of the attack against the specific \textcolor{red}{model's grids} \textcolor{blue}{set} considered, we introduce the \textit{Effectiveness Score Function} (ESF). 
The ESF goal is to understand the impact of MSHAA on the victim model when deployed. Therefore, with ESF we measure the MSHAA returned model $\tilde{h}_{\mathfrak{c}^*}$ and the legitimate $h_{\mathfrak{c}^*}$ based on the hijack metric $\mathcal{E}$.
Formally, ESF is defined as follows:
\begin{equation}
     \mathscr{S}(\mathfrak{C}) = \frac{
         \mathcal{E} ( \tilde{h}_{\mathfrak{c}^*}, \mathcal{S}^{Test} ) 
         - 
         \mathcal{E} ( h_{\mathfrak{c}^*}, \mathcal{S}^{Test} )
     }
     {
         \underset{\mathfrak{c} \in \mathfrak{C}}{\max} \{\mathcal{E}(h_{\mathfrak{c}}, \mathcal{S}^{Test})\} - 
         \mathcal{E} (    h_{\mathfrak{c}^*}, \mathcal{S}^{Test}    )
     }.
\end{equation}

ESF takes the difference between a chosen metric $\mathcal{E}$ of the models $\tilde{h}_{\mathfrak{c}^*}$ (see Equation~\ref{best_poison}) and $h_{\mathfrak{c}^*}$ (see Equation~\ref{best_val}) normalizing it with the difference between the maximum possible chosen metric of a model $h_\mathfrak{c}$ with $\mathfrak{c} \in \mathfrak{C}$, and again the chosen metric by $h_{\mathfrak{c}^*}$.\\
This function allows us to evaluate our attack with any metric $\mathcal{E}$, for the purpose of this study, with regards to the hijack metric considered:
\begin{itemize}
    \item \textit{Generalization Metric}. $\mathcal{E}$ is the loss function computed on the original validation set;
    \item \textit{Latency Metric}. $\mathcal{E}$ is the latency while processing the test set.
    \item \textit{Energy Consumption} or \textit{$\ell_0$ Norm}. $\mathcal{E}$ is the estimated energy consumed by the model while processing the test set. When testing the attack in the SpeechCommands case, as we could not compute the \texttt{Energy} metric, we evaluated the quality of the attack using the \texttt{$\ell_0$ Norm}, by adopting $\mathcal{E}$ to be the $\ell_0$ Norm.
\end{itemize}
This Effectiveness Score function allows us to give a normalized score that sums up the effectiveness of the MSHAA, as a matter of fact:
\begin{itemize}
    \item \textit{Successful}, when $ESF > 0$, the MS phase to return a model with higher $\mathcal{E}$ compared to $h_{\mathfrak{c}^*}$. If the score is equal to $1.0$, then the returned model $\tilde{h}_{\mathfrak{c}^*}$ is the one among the considered models to have the highest $\mathcal{E}$.
    \item \textit{Invariant}, when $ESF = 0.0$, the attack did not sway the MS phase, and the returned model is $\tilde{h}_{\mathfrak{c}^*} = h_{\mathfrak{c}^*}$, \textit{i.e.} the returned model is also the legitimate one. 
    \item \textit{Unsuccessful}, $ESF < 0.0$ imply that the attack made the MS phase return a model of less $\mathcal{E}$ compared to $h_{\mathfrak{c}^*}$.
\end{itemize}  
\par
We define the ASR as a simplification of the ESF. In particular, we define the ASR as a boolean variable of a successful or unsuccessful attack, and therefore the $ASR = 1$ if $ESF > 0$, $ASR = 0$ otherwise. 
With this metric, we are interested in understanding when an attack is successful in terms of increasing the hijack metric. 

% \section{Experimental Settings --- OLD}

% \subsection{Case Studies}
% We designed three distinct case studies to test the MSHAA attack performance: two yield from the Computer Vision (CV) field, and the remaining one from Speech Recognition (SR), all in the classification task. \\
% We opted to test two distinct application domains (CV and SR) to understand the generalization of the attack in different AI scenarios. These datasets were imported using the corresponding PyTorch libraries.

% \paragraph{MNIST (CV)~\cite{lecun2010mnist}} 
% It is a dataset of bilevel $28 \times 28$ handwritten digits divided into 10 classes: one for each digit from 0 to 9. 
% The victim models considered for this case are FeedForward Neural Networks, with hyperparameters grid concerning the number of neurons per layer and the number of layers themselves. 
% Our parameter grid consists of the following:
% \begin{itemize}
%     \item number of layers = $[1, 2, ..., 10]$;
%     \item number of neurons = $[32, 64, 128]$;
%     \item learning rate = $[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]$.
% \end{itemize}
% Amounting to a total of 180 models: 30 for each learning rate.
%Regarding the specific hyperparameters, for the number of layers, we trained the network with layers 1 to 10 layers, with each layer having 32, 64, or 128 neurons. Then, these 30 models were trained using 6 different learning rates: 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05.\\
 %\textbf{ADD the excact grid}. 
% The HVAE comprises only fully connected layers and is trained using Binary Cross Entropy as a reconstruction loss ($\mathcal{L}_{\mathrm{rec}}$). 
% To train these HVAEs (for all the test cases considered), we considered different architectures and learning rates and then performed a model selection on these models. Ultimately for the attack, we used the one, among the ones trained, with the highest hijacking cost $Hj_{cost}$ (see Eq. \ref{cost}).  

% \paragraph{CIFAR10 (CV)~\cite{cifar10}} 
% It is a dataset of colored $32 \times 32$ images of various subjects belonging to 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. 
% In this case study the victim models are DenseNets \cite{huang2017densely}, of which we adapted the implementation done by \cite{PyTorchDenseNet}. The considered hyperparameters grid sees the number of dense blocks and the number of neurons for the fully connected layer which feeds the output one. Our parameter grid consists of the following:
% \begin{itemize}
%     \item number of dense blocs = $[2, 3, ..., 8]$;
%     \item fully-connected number of neurons = $[128, 256, 512]$;
%     \item learning rate = $[0.0001, 0.0005]$.
% \end{itemize}
% All in all, we trained 42 models for this case study.
%For the number of dense blocks, we had networks with 2, 3, 4, 5, 6, 7, and 8 blocks. Meanwhile for the number of neurons for the fully connected layer, we chose 128, 256, or 526. These 21 models were then trained using either 0.001 or 0.005 as learning rate.\\
%.\textbf{ADD the exact grid.}
% For CIFAR10, the HVAE adopted is composed of 2D convolutional layers, and the adopted reconstruction loss ($\mathcal{L}_{\mathrm{rec}}$) is the Mean Square Error.

% \paragraph{Speech Commands (SR)~\cite{speechcommandsdataset}} 
% It is a dataset composed of audio files of about 1 second long (around 16000 frames long) belonging to 35 classes of different commands spoken by different people. Here, the victim models are Convolutional Neural Networks composed of 1D convolutional layers, and the considered hyperparameters are the number of convolutional layers and the width of the fully connected layer that feeds the output one (code adapted from \cite{PyTorchSpeechCommands}).
% Our parameter grid consists of the following:
% \begin{itemize}
%     \item number of 1-dimensional convolutional layers = $[2, 4, 6, 8]$;
%     \item learning rate = $[0.01, 0.05]$.
% \end{itemize}
% Therefore, we trained 16 models for the classification of the SpeechCommands dataset.
% We chose to work using networks having 2, 4, 6, or 8 1-dimensional convolutional layers, and for the number of neurons for the fully connected layer, we chose either 128 or 256. These 8 models were then trained using either 0.001 or 0.005 as learning rate.\\
% For this Speech Recognition case study, the HVAE are made of 1D convolutional layers, with the Mean Square Error as the reconstruction loss ($\mathcal{L}_{\mathrm{rec}}$).

% \subsection{Hijack Metrics} % footnote does not work well due to balance in main.tex
% Regarding the hijack metrics considered, these were computed as follows:
%     \begin{itemize}
%         \item \texttt{Generalization Metric}. This hijack metric consists of the loss obtained by our models when processing the original, untampered validation set
%         \item \texttt{Latency Metric}. Obtained measuring the overall processing time of a given set of input data.
%         \item \texttt{Energy Consumption}. As stated before this estimation was computed by an ASIC simulator \footnote{\url{https://github.com/iliaishacked/sponge_examples}} \footnote{\url{https://github.com/Cinofix/sponge_poisoning_energy_latency_attack}} adapting the functions already developed for \cite{shumailov2021sponge} and \cite{cina2022energy}.\\
%         As this tool was not compatible with the specific architecture used for the classification models of the SpeechCommands dataset, this was the only case in which we did not consider this specific metric.
%         \item \texttt{$\ell_0$ Norm}. To obtain this metric we computed the mean of the non-zero activations of each ReLU Layer in our models when processing a set of input data.
%     \end{itemize}
