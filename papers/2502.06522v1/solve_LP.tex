
Some of our algorithms for {\hopset} involve some flavor of random LP rounding, so in this section we will (approximately) solve~\ref{lp:hopset}, our LP of interest. The LP has an exponential number of constraints, so we must solve it using the ellipsoid algorithm with a separation oracle. To do so, we start by defining another LP, \ref{lp:oracle1}, that captures the problem of finding a violated constraint of~\ref{lp:hopset}. To solve~\ref{lp:oracle1}, we find yet another (approximate) separation oracle. This second oracle boils down to solving a hopbounded version of the Restricted Shortest Path problem. We show that this problem admits an FPTAS, and that this ultimately translates to a $(1+\epsilon)$-approximation for~\ref{lp:hopset}. More formally, we will prove the following:

\begin{theorem} \label{thm:solve_LP}
    There is a $(1+\epsilon)$-approximation to the optimal solution of~\ref{lp:hopset} for any arbitrarily small constant $\epsilon > 0$.
\end{theorem}

\subsubsection{Oracle 1}
As noted, \ref{lp:hopset} has exponential size, so we find a separation oracle in order to run ellipsoid. To do so, we must determine if there is a fractional cut $\bm{\mathrm{z}}$ that is not covered by the LP solution $\bm{\mathrm{x}}$---that is, given $\bm{\mathrm{x}}$ (satisfying the non-negativity constraints), we want to find $\bm{\mathrm{z}} \in \mathcal{Z}_{s,t}$, for some demand $(s,t) \in \mathcal{D}$, such that $\sum_{e \in E_M} z_e x_e < 1$. We can find such a violated cut-covering constraint by solving the following LP for each demand $(s,t) \in \mathcal{D}$.

\begin{equation} \label{lp:oracle1} \tag{LP(Oracle 1)}
\fbox{$
\begin{array}{lll}
\min & \displaystyle \sum_{e \in E_M} z_e x_e \\
\mathrm{s.t.} & \displaystyle \sum_{e \in P} z_e \geq 1 \qquad \qquad & \forall P \in \mathcal{P}_{s,t} \\
& \displaystyle z_e \geq 0 & \forall e \in E_M
\end{array}
$
}
\end{equation}

\subsubsection{Oracle 2: Hopbounded Restricted Shortest Path Problem}
\ref{lp:oracle1} is also exponential in the number of constraints, so we use the ellipsoid algorithm again, with yet another separation oracle. Given an LP solution $\bm{\mathrm{z}}$, we must determine whether there is some valid $s-t$ path that is not fractionally cut (or, covered) by $\bm{\mathrm{z}}$. Specifically, we need to find a violated constraint of the form $\sum_{e \in P} z_e < 1$ for some path $P \in \mathcal{P}_{s,t}$. Observe that we now have three separate metrics: the $\bm{\mathrm{z}}$ metric (given by a solution to \ref{lp:oracle1}), our original distance metric from the input, and a hop metric (where each edge has hop ``length" 1). We only care about valid $s-t$ paths; namely, paths with length at most $D(s,t)$ in our original distance metric and with length at most $\beta$ in our hop metric. Thus, our goal is to find the shortest path in the $\bm{\mathrm{z}}$ metric that respects these upper bounds in the distance and hop metrics. 

When there are only two metrics---that is, when the goal is to find the shortest path in one metric subject to an upper bound in the other---this is the Restricted Shortest Path problem, defined as follows.

\begin{definition} [Restricted Shortest Path Problem]
    Let $G = (V,E)$ be a graph such that each edge $e \in E$ is associated with a cost $z_e$ and a delay $\ell_e$. Let $T$ be a positive integer, and $s,t \in V$ be the source and target nodes, respectively. The Restricted Shortest Path problem is to find a path $P$ from $s$ to $t$ such that the delay along this path is at most $T$, and the cost of $P$ is minimal.
\end{definition}

The Restricted Shortest Path problem is well studied \cite{Has92, War87, Phi93, XZTT08}. The problem admits an FPTAS, meaning there exists a polynomial-time (1+$\epsilon$)-approximation for the problem \cite{LR01}. Since our problem of interest has a third metric (the hop metric), we refer to it as the \textit{Hopbounded} Restricted Shortest Path problem. We \iflong will \else \fi modify the Restricted Shortest Path FPTAS algorithm of \cite{LR01} to give an FPTAS for the Hopbounded Restricted Shortest Path problem, thus giving a $(1+\epsilon)$-approximate separation oracle for~\ref{lp:oracle1}. We formally define the Hopbounded Restricted Shortest Path problem with respect to~\ref{lp:oracle1}:

\begin{definition}[Hopbounded Restricted Shortest Path problem]
    Let $G_M = (V,E_M)$ be a graph such that each edge $e \in E$ is associated with a cost $z_e$ and a delay, or length, $\ell_e$. Let $T = D(s,t)$, and $s,t \in V$ be the source and target nodes, respectively. The Hopbounded Restricted Shortest Path problem is to find a path $P$ from $s$ to $t$ with at most $\beta$ hops, such that the length along this path is at most $T$, and the cost of $P$ is minimal.
\end{definition}

\subsubsection{Hopbounded Restricted Shortest Paths Algorithm}
At a high level, the Restricted Shortest Path algorithm works as follows. The algorithm runs multiple binary searches to find good upper and lower bounds on the cost of the optimal solution, then uses these bounds to scale and discretize (or ``bucket") the costs of the edges. They then give a pseudo-polynomial time dynamic programming algorithm on the problem with bucketed edge costs, which they show is a $(1+\epsilon)$-approximation for the original problem. For runtime, the pseudo-polynomial time DP algorithm is polynomial in $U/L$ (and in $1/\epsilon$), where $U$ and $L$ are the upper and lower bounds, respectively, on the optimal solution. The bounds they find are such that $U/L = O(n)$, and so the algorithm is an FPTAS. 

To get this algorithm to work for the Hopbounded Restricted Shortest Path problem, we simply modify the DP algorithm to take our hop metric into account, adding a factor $\beta$ to the runtime (see Algorithm~\ref{alg:HRSP}\iflong\else in Appendix~\ref{app:lp_alg}\fi). \iflong \else The arguments of~\cite{LR01} generally also hold for our algorithm, so we have that Algorithm~\ref{alg:HRSP} is a $(1+\epsilon)$-approximation of the Hopbounded Restricted Shortest Path problem. \fi
\iflong
Like the Restricted Shortest Path DP algorithm, our DP algorithm takes in as input valid upper and lower bounds, $U$ and $L$, respectively. We also scale the edge costs in the same way, and refer to these scaled costs as \quotes{pseudo-costs.} Let $D(v, i, j)$ indicate the minimum length (in the original distance metric) of a path from vertices $s$ to $v$ with pseudo-cost at most $i$ and at most $j$ hops. Our algorithm differs from the Restricted Shortest Path algorithm in that we add an additional dimension for hops to the dynamic programming algorithm.

\begin{algorithm}[ht]
\DontPrintSemicolon

\textbf{Input:} Graph $G = (V, E)$, demand pair $s,t \in V$, \\
cost, distance, and hop metrics $\{z_e, \ell_e, h_e \}_{e \in E_M}$, \\
parameters $T, \beta, L, U,$ and $\epsilon $ \;~\\

Let $S \gets \frac{L \epsilon}{n+1}, \; \Tilde{U} \gets \floor*{U/S} + n + 1$ \\ \; 

\tcp{scale edge costs} 
\ForEach{edge $e \in E$}{
    Let $\Tilde{z}_e \gets \floor{z_e / S} + 1$} \;

\tcp{set base cases} 
\ForEach{index $i  = 0, 1, \dots, T$}{
    $D(s, i, 0) \gets 0$} 
\ForEach{index $j  = 0, 1, \dots, \beta$}{
    $D(s, 0, j) \gets 0$} 
    
\ForEach{vertex $v \in V$ such that $v \neq s$}{
    \ForEach{index $i = 0, 1, \dots, T$}{
        $D(v, i, 0) \gets \infty$}
    \ForEach{index $j = 0, 1, \dots, \beta$}{
        $D(v, 0, j) \gets \infty$} 
} \;

\tcp{build up DP table}
\ForEach{index $i = 1, 2, \dots, \Tilde{U}$}{
    \ForEach{index $j = 1, 2, \dots, \beta $}{
        \ForEach{vertex $v \in V$}{
            $D(v, i, j) \gets \min\{ \: D(v, i-1, j), \; D(v, i, j-1) \: \}$ \;
            \ForEach{edge $e \in \{ (u,v) \; | \; \Tilde{z}_{(u,v)} \leq i \}$ }{
                $D(v, i, j) \gets \min\{ \: D(v, i, j), \; \ell_e + D(v, i-\Tilde{z}_{e}, j-1) \: \}$ \;
            }
        \If{$D(t, i, j) \leq T$}{
            \textbf{Return} the corresponding path \;
        }
        }
    }
}
\textbf{Return} FAIL \;

\caption{\label{alg:HRSP} Hopbounded Restricted Shortest Path Algorithm } 
\end{algorithm}
Using arguments from \cite{LR01}, we will show that Algorithm~\ref{alg:HRSP} is a $(1+\epsilon)$-approximation of the Hopbounded Restricted Shortest Path problem.
\else
\fi
\iflong The following is directly from \cite{LR01} and also holds for our slightly modified algorithm. Let $z(P)$ denote the cost (in the $\bm{\mathrm{z}}$ metric) of a path $P$ in $G_M$, and let $z^*$ denote the cost of the optimal path for the original Hopbounded Restricted Shortest Path instance. 

\begin{lemma}[Lemma 3 of \cite{LR01}]
\label{lem:eps_approx}
    If $U \geq z^*$, then Algorithm~\ref{alg:HRSP} returns a feasible path, $P'$, that satisfies $z(P') \leq z^* + L\epsilon$
\end{lemma}

\cite{LR01} uses this Lemma, and others, to show that there is a $(1+\epsilon)$-approximation for the Restricted Shortest Path problem (Theorems 3 and 4 of \cite{LR01}). Their algorithm achieves a runtime of $O(m n/ \epsilon + m n \log \log \frac{U}{L})$. While their full argument would also give a similar runtime for our setting (with an additional factor $\beta$), we only include the arguments necessary to achieve a polynomial runtime. As a result, we get a worse runtime than what \cite{LR01} would imply. 

\begin{lemma} \label{lem:AS}
    Given valid lower and upper bounds $0 \leq L \leq z^* \leq U$, Algorithm~\ref{alg:HRSP} is a $(1+\epsilon)$-approximation for the Hopbounded Restricted Shortest Path problem that runs in time $O(\beta m n U / L \epsilon)$. 
\end{lemma}
\begin{proof}
The approximation ratio is directly implied by Lemma~\ref{lem:eps_approx}. 
    
Each edge in the algorithm is examined a constant number of times, so the overall time complexity is 
\begin{align*}
    O(\beta m \Tilde{U}) &= O\left( \beta m \frac{n}{\epsilon} \frac{U}{L} + nm \right) \\
    &= O\left( \beta m \frac{n}{\epsilon} \frac{U}{L}  \right) \tag{$U \geq L$ and $\epsilon \leq 1$}
\end{align*}
\end{proof}

Now we find upper and lower bounds $U$ and $L$ such that $U/L \leq n$, just as in \cite{LR01}, to give an overall runtime of $O(\beta m n^2 / \epsilon)$ for our problem. Let $\ell_1 < \ell_2 < \dots, \ell_p$ be the distinct lengths of all edges in $E_M$ (note that $p \leq m$). Let $E_i$ be the set of edges in $E_M$ with length at most $\ell_i$, and let $G_i = (V, E_i)$. We also set $E_0 = \emptyset$.
There must be some index $j \in [1,p]$ such that there exists a $T$-length-bounded, $\beta$-hopbounded path in $G_j$, but not in $G_{j-1}$. As observed in Claim 1 of \cite{LR01}, this means that $\ell_j \leq z^* \leq n \ell_j$, giving bounds $L = \ell_j$ and $U = n \ell_j$, with $U/L = n$. To find $\ell_j$, we can binary search in the range $\ell_1, \dots, \ell_p$, running a shortest hopbounded path algorithm at each step of the binary search to check if there exists a $T$-length-bounded, $\beta$-hopbounded $s-t$ path on the subgraph $G_i$ corresponding to that step. The binary search requires $O(\log m)$ steps, and the shortest hopbounded path algorithm takes $O(m \log n)$ time, so the runtime for finding these bounds is dominated by the runtime of the the DP algorithm. 

In summary, the Hopbounded Restricted Shortest Path algorithm is as follows: Run binary search on $\ell_1, \dots, \ell_p$ to find $\ell_j$ and get bounds $U$ and $L$. Then run the dynamic programming algorithm, Algorithm~\ref{alg:HRSP}, using bounds $U$ and $L$.
\else \fi

\begin{lemma} \label{lem:FPTAS_HRSP}
    The Hopbounded Restricted Shortest Path problem admits an FPTAS.
\end{lemma}

\subsubsection{Proof of Theorem~\ref{thm:solve_LP}}
With an FPTAS for the Hopounded Restricted Shortest Path problem (by Lemma~\ref{lem:FPTAS_HRSP}), we have an approximate separation oracle for~\ref{lp:oracle1}. Using the ellipsoid algorithm with this oracle, we find a solution $\bm{\mathrm{z}}$ for~\ref{lp:oracle1}. While $\bm{\mathrm{z}}$ may not be feasible, it only violates each constraint by a factor of at most $(1+\epsilon)$. That is, $\bm{\mathrm{z}}$ satisfies $(1+\epsilon) \sum_{e \in P}  z_e \geq 1$ for all $P \in \mathcal{P}_{s,t}$. Thus if we scale $\bm{\mathrm{z}}$ by $(1+\epsilon)$, we get a feasible solution. Let $\bm{\mathrm{z'}}$ be this scaled solution, where $z_e' = (1+\epsilon) z_e$ for all $e \in E_M$. We then also have that $\bm{\mathrm{z'}}$ is a $(1+\epsilon)$-approximation for~\ref{lp:oracle1}. This is implied by the fact that for any feasible solution $\bm{\mathrm{z''}}$ of~\ref{lp:oracle1}, the value of the objective on $\bm{\mathrm{z}}$ is at most the value of the objective on $\bm{\mathrm{z''}}$ (the entire feasible region satisfies the $(1+\epsilon)$ \quotes{approximate} constraints, and therefore the feasible region is in the search space of the ellipsoid algorithm). That is, $\sum_{e \in E_M}  z_e x_e \leq \sum_{e \in E_M}  z''_e x_e$ for all feasible solutions $\bm{\mathrm{z''}}$.  Thus we have a $(1+\epsilon)$-approximation for~\ref{lp:oracle1}.

The purpose of solving~\ref{lp:oracle1} is to give a separation oracle for our starting LP, \ref{lp:hopset}. We therefore must show that the $(1+\epsilon)$-approximation we have for~\ref{lp:oracle1} translates to a $(1+\epsilon)$-approximation for the hopset LP. The approach is similar to how we approximate~\ref{lp:oracle1}. Running ellipsoid with the~\ref{lp:oracle1} approximation as a separation oracle, we get a solution $\bm{\mathrm{x}}$ that approximately (within a factor $(1+\epsilon)$) satisfies the constraints. We can scale $\bm{\mathrm{x}}$ by a factor $(1+\epsilon)$ to get a feasible solution $\bm{\mathrm{x'}}$. Additionally, we have $\sum_{e \in E_M} x_e \leq \sum_{e \in E_M} x''_e$ for all feasible solutions $\bm{\mathrm{x''}}$. We therefore have a $(1+\epsilon)$-approximation for the hopset LP relaxation. 


