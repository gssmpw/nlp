\section{Conclusion}
In this work, we introduce G-Rerank, an end-to-end optimization framework for training rerankers in RAG systems. By reinterpreting the reranking process as masked attention, we leverage the Gumbel Trick and Relaxed Top-\( k \) to enable direct optimization of the document-wise attention mask. Our method effectively captures document interdependencies and aligns retrieval and generation objectives. Experiments across different settings show that G-Rerank notably improves reranker performance, especially in multi-hop QA tasks.