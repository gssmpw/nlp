\section{Introduction}
Large language models (LLMs) like OpenAI's GPTs~\citep{openai2024gpt4technicalreport, brown2020languagemodelsfewshotlearners}, Google's PaLM~\citep{anil2023palm2technicalreport} and Gemini~\citep{geminiteam2024geminifamilyhighlycapable}, and lately Meta's Llama~\citep{touvron2023llamaopenefficientfoundation,touvron2023llama2openfoundation,dubey2024llama3herdmodels} have shown remarkable versatility across a wide range of applications, including healthcare~\citep{singhal2023expertlevelmedicalquestionanswering,Huang2024PatientRepresentingPP}. In clinical environments, LLMs offer potential for automating tasks such as summarizing clinical notes, supporting diagnostic decisions, and streamlining patient communication~\citep{ijerph20043378,soleimani2024practical,ruinelli-etal-2024-experiments,Liu2023UtilityOC, Patel2023ChatGPTTF, van2024adapted, Zaretsky2024GenerativeAI,Were2010CreationAE}. However, deploying AI in clinical settings remains a critical challenge due to the high cost of hallucinations, factual inconsistencies, and misinterpretations~\citep{10.1145/3571730, Lin2024TowardsTL,tang2023evaluating, dada2024clue}. Even minor inaccuracies in AI-generated clinical content can lead to severe consequences, such as misdiagnoses, incorrect treatments, or harmful patient outcomes. Ethical considerations further complicate this process, calling for clinicians to hold accountability for medical decisions through rigorous oversight~\citep{Mesk2023TheIF,PMID:38285984}. At the same time, verifying AI-generated content introduces new cognitive burdens, potentially negating the intended efficiency gains of automation.
\begin{figure}[t!]
    \centering
   \includegraphics[width=\columnwidth]{images/Topic_Level_Generation.pdf}
  \caption{An interactive workflow showcasing topic-level generation control. The LLM is prompted once with the respective context to begin structured generation. After each element, generation is paused, enabling users to sequentially refine content by editing LLM-suggested topic headings, questions, and text blocks. The generation resumes with user-verified content.\vspace{-0.15cm}}
  \label{fig:interactive_generation_workflow}
\end{figure}
As clinicians already face high cognitive workloads, 
addressing this paradox is essential to harness AI's potential in clinical settings without increasing risks or workloads. To strike this balance, AI systems must provide clinicians with control and transparency, ensuring outputs align with clinical contexts, communication styles, and guidelines. This paper explores whether augmenting traditional datasets to condition LLMs for controlled clinical text generation is a viable solution. Specifically, we introduce a system that separates stylistic and content-related requirements, breaking down generation into distinct, manageable writing subtasks. This reduces the complexity of content creation and human verification through a separation of concerns, empowering users to impose authoring guidelines and dynamically guide the process while moving away from black-box models that limit clinician involvement. 

Since traditional datasets do not inherently support such user control, we augment them with authoring guidelines and topic segmentation to condition models for style and content control. Automated evaluation suggests that our approach significantly enhances relevance, accuracy, and factual consistency, highlighting the potential of such augmentations for clinical text generation. Furthermore, we find that traditional instruction-tuning for clinical text generation can be significantly improved through optimized hyperparameter settings, without increasing the compute budget.  Our key contributions\footnote{All source code will be released upon paper acceptance.} are: 

\textbf{New state-of-the-art.} We set a new state-of-the-art on the BioNLP ACL'24 Shared Task 'Discharge Me!' challenge through efficient training, while being simpler and requiring less training compute. 

\textbf{Dataset Augmentation.} We propose methods using LLMs as human proxies to augment traditional datasets, enabling granular control over content and style in clinical text generation. This yields a 34\% relative improvement over prior state-of-the-art, representing a lower bound on potential gains.


\textbf{Human Evaluation.} We conduct preliminary human evaluation, validating the effectiveness and automated evaluation of our approach.