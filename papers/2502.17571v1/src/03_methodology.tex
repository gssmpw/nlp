\section{Conditioning Clinical Text Generation for User Control}
We explore two strategies to condition Large Language Models (LLMs) for controlled clinical text generation: (a) topic-level structured generation and (b) authoring guidelines. However, implementing these strategies reveal limitations in traditional datasets, particularly in clinical text generation.

\subsection{Limitations in Traditional Datasets}
\label{sec:limitations-in-traditional-datasets}
Traditionally, training datasets are built on the assumption that more data leads to better generalization. However, in conditional text generation (e.g., summarization) the same task can be completed in multiple stylistically distinct but equally valid ways. Despite this, evaluation benchmarks typically provide only a single reference text, failing to account for the diversity of valid solutions or specifying which variant of task completion is expected. This issue is made by design and cannot be resolved simply by increasing dataset size. Consequently, models are evaluated against a single stylistic realization of a task, potentially skewing evaluation results.

This is particularly evident in clinical datasets, where medical documents exhibit significant differences in quality, format, and style --- even within the same task~\citep{POLLARD201339,edwards2014association,Hultman2019ChallengesAO}. Discharge summaries, for instance, are often compiled from pre-existing records authored by multiple individuals. Contents are often copied across teams, departments, or wards, each adhering to distinct conventions shaped by institutional workflows, time constraints, and resource limitations, leading to inherent stylistic inconsistencies, which is further amplified by situational pressures. Moreover, medical professionals exhibit highly distinctive writing styles, often to the extent that colleagues can recognize one another solely by their writings. Consequently, even within a single discharge summary, different sections may reflect different writing styles, making it impossible to reliably infer the appropriate writing style for one section from the remaining document.

This issue has been largely overlooked in prior research, and to our knowledge, no systematic study has investigated its implications. In particular, the extent to which evaluation metrics are sensitive to stylistic variations, and the degree to which stylistic features emerge due to spurious correlations in input data, remains unclear.
To ensure models can be held accountable for stylistic deviations, we extend the task definition by integrating authoring guidelines into the input context, conditioning the model to adhere to explicit stylistic requirements. This introduces a clear separation of concerns: synthesizing clinically relevant information to complete the task (\textbf{content}) and ensuring conformity to specified conventions (\textbf{style}). Moreover, explicitly conditioning models on authoring guidelines facilitates the emergence of stylistic features through user control, rather than spurious correlations, enabling clinicians to specify institutional or personalized guidelines during inference and promising better generalization.

Another limitation with traditional datasets is their end-to-end design, where the entire output is generated in a single step from the input. This inherently restricts user intervention and control during generation. To train models for (a) controllable and (b) intervenable generation (cf. Fig.~\ref{fig:interactive_generation_workflow}), we need models to sequentially generate output block by block in a structured format with (a) guidance signals to steer the generation of individual blocks and (b) control sequences to start and terminate individual blocks. To address this, we explore fine-grained topic segmentation to structure target texts $t_i$ into XML-formatted sequences.


\subsection{Topic-Level Generation Control}
\label{sec:topic-level-generation-control}
To train models for controllable and intervenable generation,
we tasked Llama 3.1 70B Instruct with fine-grained topic segmentation of target texts $t_i$. The LLM is prompted to segment texts $t_i = (t_i^1, ..., t_i^n)$ into smaller text blocks $t_i^k$, while generating topic-specific headings $\mathring{h}_i^k$ and questions $\mathring{q}_i^k$ for each segment. The output is requested as an XML-structured sequence $$\mathring{seg}(t_i) = \left[
\mathring{h}_i^1, \mathring{q}_i^1, \mathring{t}_i^1, ..., \mathring{h}_i^n, \mathring{q}_i^n, \mathring{t}_i^n\right],$$ in the following format:
\begin{quote}
\texttt{<topic>$\mathring{h}_i^1$</topic>\newline
<question>$\mathring{q}_i^1$</question>\newline
<span>$\mathring{t}_i^1$</span>\newline
$\dots$\newline
<topic>$\mathring{h}_i^n$</topic>\newline
<question>$\mathring{q}_i^n$</question>\newline
<span>$\mathring{t}_i^n$</span>}
\end{quote}

While the headings and questions serve as guidance signals during generation, the XML tags serve as control sequences to stop, adjust and continue generation in each distinct phase  (Fig.~\ref{fig:interactive_generation_workflow}). The prompt (Tab.~\ref{table:topic_segmentation_annotation_example}) is designed to enforce fine-grained topic segmentation, without imposing a particular concept of topics or questions. It's summarized as follows: (1) a new segment should begin when the clinical focus changes, which we associate with a new writing subtask, (2) headings $\mathring{h}_i^k$ should summarize their respective segment, which we equate with the topic, and which (3) should be rephrased as a question $\mathring{q}_i^k$ answered by the respective segment $t_i^k$, which we consider to be the Question Under Discussion (QUD) of said segment. The remaining guidelines are provided to ensure standardization.

A post-processing step then restores the original character sequences $t_i^1, ..., t_i^n$ from $t_i$ for each generated text block $\mathring{t}_i^1, \dots, \mathring{t}_i^n$ (see Appendix~\ref{sec:topic-segmentation-post-processing}), as the LLM generated text blocks $\mathring{t}_i^k$ may not replicate the input $t_i$. The final output is denoted as: $$seg(t_i) = \left[
\mathring{h}_i^1, \mathring{q}_i^1, t_i^1, ..., \mathring{h}_i^n, \mathring{q}_i^n, t_i^n\right].$$

However, to avoid introducing inconsistencies between headings, questions, and text blocks, this step is applied selectively only to those segmentations $\mathring{seg}(t_i)$, which introduce only minor alterations to the input (see Appendix~\ref{sec:topic-segmentation-post-processing}).

\subsection{Authoring Guidelines}
\label{sec:authoring-guidelines}
From a user perspective, authoring guidelines govern the requirements a document must comply with. These may range from stylistic features to structural constraints. Conditioning text generation on such guidelines may therefore not only improve alignment of model outputs with user intent, but also provide greater control over generation. However, traditional datasets often lack such guidelines. In this work, we explore the feasibility of using LLMs to close this gap in clinical datasets.

Specifically, we explore the use of two types of automatically generated authoring guidelines for clinical documents $t_i$, which differ in their formulation: (a) style guidelines, which describe the stylistic features a clinical document should express and (b) writing instructions, guiding a non-specialist in writing a clinical document that serves the intended purpose while expressing the desired stylistic features. To achieve this, Llama 3.1 70B Instruct is prompted independently for each target text $t_i$ as follows:

\textbf{Style Guidelines.} The LLM is prompted to describe the stylistic features of the target text $t_i$, including tone, document format, layout, composition, text structure, use of language (including abbreviations and medical jargon), and intended audience (cf. Tab.~\ref{table:style_guideline_example}).

\textbf{Writing Instructions.} The LLM is prompted to generate markdown-formatted instructions for guiding a non-specialist in replicating the target text $t_i$, including directives on the same stylistic features as above while specifying the purpose, document type and outline (cf. Tab.~\ref{table:writing_instructions_example}).

The LLM prompts are carefully engineered to avoid answer leakage by instructing the LLM to not use terms or phrases from the source text, to not quote or give examples from the patient records, and not to reveal patient-specific details.

\begin{figure}[t!]
  \includegraphics[width=\columnwidth]{images/Training_Procedure.pdf}
  \caption{Instruction-tuning pipeline. Dashed lines indicate paths that depend on the training configuration. Models with topic-level control are trained to generate XML-structured text. The extended context is provided only for TT~=~DI. Abbreviations: Discharge Summary~(DS), Radiology Report~(RR), Discharge Instructions~(DI), Brief Hospital Course~(BHC), Target Text~(TT).}
  \label{fig:training-procedure}
\end{figure}

\subsection{Instruction Tuning for Controlled Clinical
Text Generation}
\label{subsec:instruction-tuning-for-controlled-clinical-text-generation}
We utilize the \textit{Discharge Me!} challenge\footnote{\url{https://stanford-aimi.github.io/discharge-me}}, part of the BioNLP ACL'24 Shared Tasks, for training and evaluating our models due to its clinical relevance and challenging nature. Additionally, its leaderboard provides a strong baseline. The task focuses on automating the generation of hospital course summaries and discharge instructions, traditionally time-intensive tasks for clinicians. 

\textbf{Dataset.} The dataset consists of 109,168 discharge summaries from the MIMIC-IV dataset, each containing a Brief Hospital Course (BHC) and a Discharge Instructions (DI) section. It is divided into training (68,785), validation (14,719), phase I test (14,702), and phase II test (10,962) sets. The BHC section is typically found in the middle of the discharge summary, following details on patient history and treatments during the current visit. The DI section is generally located at the end of the note. Additionally, each discharge summary is linked to at least one radiology report and typically one ICD chief complaint, along with multiple ICD codes. The DI and BHC sections are removed from the discharge summary, and serve as target texts $t_i$. The clinical input constitutes of the remaining discharge summary (DS)~and~radiology~reports~(RR).

To address the aforementioned limitations (\ref{sec:limitations-in-traditional-datasets}), we generate topic segmentations (\ref{sec:topic-level-generation-control}), style guidelines and writing instructions (\ref{sec:authoring-guidelines}) for each DI and BHC section $t_i$ separately. We employ Llama 3.1 70B Instruct for these tasks, as LLMs have shown to be an effective  substitute for human annotators~\citep{doi:10.1073/pnas.2305016120,perez-etal-2022-red}.


\begin{figure}[t!]
\centering
\begin{tabular}{p{0.9\columnwidth}}
\hline
User Message \\
\hline
\vspace{-1em}
\begin{lstlisting}
{{discharge summary}}
{{radiology report 1}}
         ...
{{radiology report n}}
{{brief hospital course}}
{{authoring guidelines}}
{{instructions}}
\end{lstlisting} \vspace{-1.5em} \\
\hline
Assistant Message \\
\hline
\vspace{-1em}
\begin{lstlisting}
{{output}}
\end{lstlisting} \vspace{-1.5em} \\
\hline
\end{tabular}

\caption{The generic template for $prompt_i(c,g)$ used for instruction-tuning.}
\label{fig:prompt_template}
\end{figure}

\textbf{Instruction-Tuning Prompts.} 
We fine-tune our models with instruction-tuning on completions only using a generic template (cf. Fig.~\ref{fig:prompt_template}) $$prompt_i(c, g) = (user_i(c,g), assistant_i(c)),$$ where $c \in \{ \texttt{none,  \allowbreak topics} \}$ denotes the possible configurations for structuring the generation output for control and $g \in \{ \texttt{none, \allowbreak  style,  \allowbreak instr} \} $ denotes the possible configurations for using authoring guidelines.

\textbf{User Messages.} $user_i(c,g)$ include the clinical context, consisting of the discharge summary $ds_i$ and radiology reports $r_i^1, \dots, r_i^j$. For generating discharge instructions ($di_i$), we additionally include the brief hospital course report ($bhc_i$). If  $g \in \{ \texttt{style,  \allowbreak instr} \}$, we also include the respective authoring guidelines (cf. Fig.~\ref{fig:training-procedure}) and instruct the model to comply.
If $c = \texttt{topics}$,  the model is instructed to generate XML-structured output for topic-level structured generation.
Separate instructions are provided for the DI and BHC generation tasks.

\textbf{Assistant Messages.} $assistant_i(c)$ contains the desired output, which is the plain target text $t_i \in \{di_i, bhc_i\}$ for $c = \texttt{none}$, or the XML-structured output $seg_i(t_i)$ for $c = \texttt{topics}$ (Sec.~\ref{sec:topic-level-generation-control}).