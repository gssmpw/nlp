Our  backwards-greedy algorithm (\alggback) 
for both the \streamadsr and \streamads problems
is illustrated in \cref{alg:greedy-back}.
The \alggback algorithm returns an optimal solution for the \streamadsr problem, 
as we prove in \cref{thm:greedy-streamadsr}.

The \alggback algorithm processes the slots in a reverse order, starting from the final slot.
At each slot, \alggback tries to (re-)assign an ad
by finding the ad that maximizes the \emph{marginal gain} for the revenue (defined in \cref{eq:g}).
The algorithm performs a (re-)assignment if it results in a positive marginal gain (i.e., increasing the objective function).
A matching (or a mapping for \streamadsr) is then returned after processing all slots.

\begin{theoremE}\label{thm:greedy-streamadsr}
\cref{alg:greedy-back} solves the \streamadsr problem optimally.
\end{theoremE}
\begin{proofE}
	The proof is similar to the one by \citet{ieong2014advertising} 
	for finely targeted ads, i.e., $|\slots_i| = 1$, for all ads $\ad_i$.
	The key is to notice that by processing slots backwards, 
	a decision 
	at slot $j$
	cannot affect any slot 
	that has not yet been processed, i.e., slots in positions $j'=1,\dots,j-1$.
	That is, the user attention for a slot $j'$ does not depend on ads placed later (in slots $j,\dots,\nV$);
	additionally, 
	every ad can be re-used as there is no matching constraint.
	Thus, 
	solving optimally the sequence of sub-problems on slots $j,\dots,\nV$ 
	with decreasing $j=\nV,\dots,1$,
	yields an optimal solution to \streamadsr.
	
	The sub-problem for the final slot (i.e., $j=\nV$) is trivial, 
	and \alggback assigns to it the ad with the highest expected reward, 
	if available.
	Moving backwards to the next slot $j$, 
	\alggback assigns an ad with the highest reward to the slot $j$ only if it improves the total reward,
	that clearly
	results in an optimal assignment for this new sub-problem. %
	The proof immediately follows by the above invariant over the backward processing of the slots. 
\end{proofE}

The time complexity for the \alggback algorithm is 
$\bigO(|\E|)$ for \streamadsr, and
$\bigO(|\E| \beta) = \bigO(|\E| \min \{ \nV, \nads \})$ for \streamads,
where $\beta = \bigO(|\M|)$ is the time used to compute~$f_j(\M)$ for $j\in [\nV]$.
