\documentclass[sigconf]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\setcopyright{acmlicensed}
\copyrightyear{2025} 
\acmYear{2025} 
\acmConference[WWW '25]{Proceedings of the ACM Web Conference 2025}{April
	28-May 2, 2025}{Sydney, NSW, Australia}
\acmBooktitle{Proceedings of the ACM Web Conference 2025 (WWW '25), April
	28-May 2, 2025, Sydney, NSW, Australia}
\acmDOI{XXXXXXX.XXXXXXX}
\acmISBN{978-1-4503-XXXX-X/2018/06}






\usepackage{common}
\usepackage{mymacro}
\usepackage[hide]{notes}
\allowdisplaybreaks

\newif\ifsupp %
\supptrue %

\ifsupp\else \nofiles \fi %

\ifsupp
\usepackage[createShortEnv, conf={end, restate, text link=}]{proof-at-the-end}
\else
\usepackage[createShortEnv, conf={end, restate, text link=See proof in Appendix~A~[2].}]{proof-at-the-end}
\fi

\newcommand{\ilie}[1]{\textcolor{magenta}{}\xspace}
\newcommand{\aris}[1]{\textcolor{orange}{}\xspace}
\newcommand{\guangyi}[1]{\textcolor{blue}{}\xspace}

\newtheorem{problem}{Problem}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{observation}{Observation}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}


\crefname{algocf}{Algorithm}{Algorithms}


\settopmatter{printacmref=true} %

\begin{document}

\title[Efficient and Practical Approximation Algorithms for Advertising in Content Feeds]%
{Efficient and Practical Approximation Algorithms for\\Advertising in Content Feeds}


\author{Guangyi Zhang}
\affiliation{%
  \institution{Shenzhen Technology University}
  \city{Shenzhen}
  \country{China}
}
\email{zhangguangyi@sztu.edu.cn}
\orcid{0000-0002-1252-7489}

\author{Ilie Sarpe}
\affiliation{%
  \institution{KTH Royal Institute of
  	Technology}
  \city{Stockholm}
  \country{Sweden}}
\email{ilsarpe@kth.se}
\orcid{0009-0007-5894-0774}

\author{Aristides Gionis}
\affiliation{%
  \institution{KTH Royal Institute of Technology}
  \city{Stockholm}
  \country{Sweden}
}
\email{argioni@kth.se}
\orcid{0000-0002-5211-112X}


\begin{abstract}
Content feeds provided by platforms such as X (formerly Twitter) and TikTok are consumed by users on a daily basis.
In this paper, we revisit the native advertising problem in content feeds, initiated by Ieong et al.
Given a sequence of organic items (e.g., videos or posts) relevant to a user's interests or to an information search,
the goal is to place ads within the organic content
so as to maximize a reward function (e.g., number of clicks), 
while accounting for two considerations:
(1) an ad can only be inserted after a relevant content item; 
(2) the users' attention decays after consuming content or ads.
These considerations provide a natural model for capturing both the advertisement effectiveness and the user experience.
In this paper, we design fast and practical 2-approximation greedy algorithms for the associated optimization problem,
improving over the best-known practical algorithm that only achieves an approximation factor of~4. 
Our algorithms exploit a counter-intuitive observation, namely, 
while top items are seemingly more important due to the decaying attention of the user, 
taking good care of the bottom items is
key for obtaining improved approximation guarantees.
We then provide the first comprehensive empirical evaluation on the problem, 
showing the strong empirical performance of our~methods. 
\end{abstract}

\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10002951.10003260.10003272.10003274</concept_id>
	<concept_desc>Information systems~Content match advertising</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10003752.10003809.10003636</concept_id>
	<concept_desc>Theory of computation~Approximation algorithms analysis</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Content match advertising}
\ccsdesc[500]{Theory of computation~Approximation algorithms analysis}

\keywords{Newsfeed Advertising, Ad Allocation, Approximation Algorithms, Matching, Externalities}

\maketitle

%

%

%

%



\section{Introduction}\label{sec:intro}
\input{intro}


\section{Problem definition}\label{sec:def}
\input{problem}


\section{Problem structure and failed attempts}\label{sec:case}
\input{subm}


\section{Algorithms}\label{sec:algs}
\input{algs}


\subsection{Other practical algorithms}\label{sec:algs:others}
\input{alg-others}


\section{Related work}\label{sec:related}
\input{related}


\section{Experimental evaluation}\label{sec:exp}
\input{experiment}

\input{real-data-gen}


\section{Conclusion}\label{sec:conclusion}
\input{conclusion}
\balance

\begin{acks}
This research is supported by the
ERC Advanced Grant REBOUND (834862), 
the EC H2020 RIA project SoBigData++ (871042), and 
the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}


\ifsupp %
\clearpage
\appendix
\section{Missing proofs}\label{app:proofs}
\printProofs
\section{Native advertisement data}\label{app:nativedata}
\input{appendix}


\section{Further related work}\label{app:related}
\smallskip
\noindent
\emph{Sequence submodularity.}
Although we show that the objective function of \streamads is non-monotone and non-submodular, 
it does obey a limited form of submodularity, that is, \prm-submodular order~\citep{udwani2023submodular,wu2022submodular}.
However, we cannot leverage such property without monotonicity. %
Moreover, the objective function also satisfies the so called ordered submodularity~\citep{kleinberg2024calibrated}.
Similarly, leveraging such stronger notion seems to be much harder.
%




\section{Experimental details}\label{app:exp}
\smallskip
\noindent
\emph{Environment.}
All algorithms are implemented in Python.
We adopt a solver for maximum flow and maximum matching from the NetworkX library.
All algorithms  are executed on a docker image of Ubuntu 22.04.
The server 
is hosted on a Linux system with  
48\,CPUs of Intel(R) Xeon(R) Gold 6336Y CPU @ 2.40\,GHz,
125\,GB RAM.%
\fi %


\end{document}
