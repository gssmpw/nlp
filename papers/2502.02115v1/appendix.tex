In this section we describe how we built data used for our experimental evaluation on native advertisement, i.e., the setting in \cref{sec:exp:ad}.

\smallskip
\noindent
\emph{YouTube data}. The YouTube data we considered is formed by a set of videos $\{v_1, \dots, v_\nV\}$, characterized by: 
(1) the video category, i.e., $C(v_i) \in \{C_1,\dots,C_\ell\}$, where $\ell=8$; 
and (2) the number of ``ad views'' for each video, 
which we use as a proxy for the reward. %
To generate the data, we first obtain a random browsing session, i.e., 
a permutation $v_1',\dots,v_\nV'$ of the videos, through the following browsing model. 
A user starts from a randomly-chosen video $v_1'$. 
With probability $p=0.5$, the user selects another randomly chosen video of the same category $C(v_1')$, 
or otherwise the user randomly selects a previously unseen video from a different category.
The process is iterated until a permutation of all videos is obtained. 


We assume that there are $r=15$ advertisers, providing $1,\dots,\ell$ ads, i.e., one for each category $k \in [\ell]$.  
We compute the reward $r_{ij}$ for ad $a_i$ after video $v_j$, where $i \in [r\ell]$ and $j \in[\nV]$, as follows. 
First, for each different category $C_k$ with $k \in [\ell]$, over all the videos belonging to $C_k$, 
we compute the average ``ad views'' $\mu_k$ and its standard deviation $\sigma_k$. 
We then assume that the rewards are normally distributed, i.e., 
$r_{ij} \sim \alpha_k |\mathcal{N}(\mu_k, \sigma_k)|$,
where $k = C(v_j)$, and
parameter $\alpha_k = 0.8$ if the ad and the video share the same category,
i.e., $C(\ad_i) = C(v_j)$,
or $\alpha_k=0.01$ otherwise, 
which captures a higher reward for ads targeted to related videos. 
Hence in the final data each ad $a_i, i\in [r\ell]$ can be placed after each video $v_j'$, 
with the reward $r_{ij}$ computed as above.


\smallskip
\noindent
\emph{Criteo data}. 
The data consists of a chronologically ordered \emph{sequence} of displayed ads collected over one day. 
Each of the 48~millions ads recorded has 13 numerical features (capturing the engagement of users with each displayed ad),
that we clustered into $k=100$ categories using the $k$-means algorithm. 
Besides, a reward can be computed for each ad, as a linear function of its features. %
We simulate the following browsing session over a full day: 
a user is browsing a website and an ad can be displayed to its session after one minute of content observed on the website, 
that is there are exactly $\nV=1440$ slots to which ads can be assigned.
We then create $b=144$ blocks of ads (which may correspond to different advertisers), and
for each block, we assume $k$ (non-existential) ads, i.e., one for each cluster.
We then associate ads in each block to 10 random slots among $\nV$.
Then, for each block-slot assignment we add connecting edges, that is, suppose the ads in block $h\in[b]$, with indices $a_{(h-1)k+1},\dots,a_{hk}$ are associated to slot $j$ then we add edges of the form $(a_{(h-1)k+i}, j)$ for $i\in[k]$. Then,
if there exists an edge between $\ad_i$ with $i \in [bk]$ and slot $j \in [\nV]$,
then the reward $r_{ij}$ %
is assumed to be the \emph{average reward}\footnote{More formally let $a_i=(a_i^1,\dots,a_i^{13})$ be ad $\ad_i$ with its features. Then we compute, for each ad it maximum engagement $\max_{h=1,\dots,13} \{|a_i^h|\}$, which we further multiply by a factor 10 if the ad was clicked by a user. Such value is then averaged to compute the actual average reward.} of all ads (from the original data) of the same category as $\ad_i$\footnote{among the $k$ categories obtained trough $k$-means.} displayed over the $j$-th minute; 
otherwise, $r_{ij} = 0$.
In this way, we capture the reward distribution over both clusters and time, in real-world data.
