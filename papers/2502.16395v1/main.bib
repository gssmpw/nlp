@article{lee2022investigating,
  title={Investigating data like a data scientist: Key practices and processes},
  author={Lee, Hollylynnne and Mojica, Gemma and Thrashers, Emily and Baumgartner, Peter},
  journal={Statistics Education Research Journal},
  volume={21},
  number={2},
  pages={3--3},
  year={2022}
}
@article{menkveld2024nonstandard,
  title={Nonstandard errors},
  author={Menkveld, Albert J and Dreber, Anna and Holzmeister, Felix and Huber, Juergen and Johannesson, Magnus and Kirchler, Michael and Neus{\"u}ss, Sebastian and Razen, Michael and Weitzel, Utz and Abad-D{\'\i}az, David and others},
  journal={The Journal of Finance},
  volume={79},
  number={3},
  pages={2339--2390},
  year={2024},
  publisher={Wiley Online Library}
}

@article{resnik2017reproducibility,
  title={Reproducibility and Research Integrity},
  author={Resnik, David B. and Shamoo, Adil E.},
  journal={Accountability in Research},
  volume={24},
  number={2},
  pages={116--123},
  year={2017},
  doi={10.1080/08989621.2016.1257387}
}

@article{crocker2011fraud,
author = {Jennifer Crocker  and M. Lynne Cooper },
title = {Addressing Scientific Fraud},
journal = {Science},
volume = {334},
number = {6060},
pages = {1182-1182},
year = {2011},
doi = {10.1126/science.1216775},
URL = {https://www.science.org/doi/abs/10.1126/science.1216775},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1216775}}

@article{leek2015reproducible,
author = {Jeffrey T. Leek  and Roger D. Peng },
title = {Reproducible research can still be wrong: Adopting a prevention approach},
journal = {Proceedings of the National Academy of Sciences},
volume = {112},
number = {6},
pages = {1645-1646},
year = {2015},
doi = {10.1073/pnas.1421412111},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1421412111},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1421412111}}





@misc{ASA2014,
  author       = {American Statistical Association Undergraduate Guidelines Workgroup},
  title        = {2014 Curriculum Guidelines for Undergraduate Programs in Statistical Science},
  year         = {2014},
  publisher    = {American Statistical Association},
  address      = {Alexandria, VA},
  note         = {Available from the American Statistical Association.}
}

@BOOK{NAP25104,
  author    = {{National Academies}},
  title     = "Data Science for Undergraduates: Opportunities and Options",
  isbn      = "978-0-309-47559-4",
  doi       = "10.17226/25104",
  abstract  = "Data science is emerging as a field that is revolutionizing science and industries alike. Work across nearly all domains is becoming more data driven, affecting both the jobs that are available and the skills that are required. As more data and ways of analyzing them become available, more aspects of the economy, society, and daily life will become dependent on data. It is imperative that educators, administrators, and students begin today to consider how to best prepare for and keep pace with this data-driven era of tomorrow. Undergraduate teaching, in particular, offers a critical link in offering more data science exposure to students and expanding the supply of data science talent.\n\nData Science for Undergraduates: Opportunities and Options offers a vision for the emerging discipline of data science at the undergraduate level. This report outlines some considerations and approaches for academic institutions and others in the broader data science communities to help guide the ongoing transformation of this field.",
  url       = "https://nap.nationalacademies.org/catalog/25104/data-science-for-undergraduates-opportunities-and-options",
  year      = 2018,
  publisher = "The National Academies Press",
  address   = "Washington, DC"
}

@BOOK{NAP25303,
  author    = {{National Academies}},
  title     = "Reproducibility and Replicability in Science",
  isbn      = "978-0-309-48616-3",
  doi       = "10.17226/25303",
  abstract  = "One of the pathways by which the scientific community confirms the validity of a new scientific discovery is by repeating the research that produced it. When a scientific effort fails to independently confirm the computations or results of a previous study, some fear that it may be a symptom of a lack of rigor in science, while others argue that such an observed inconsistency can be an important precursor to new discovery.\nConcerns about reproducibility and replicability have been expressed in both scientific and popular media. As these concerns came to light, Congress requested that the National Academies of Sciences, Engineering, and Medicine conduct a study to assess the extent of issues related to reproducibility and replicability and to offer recommendations for improving rigor and transparency in scientific research.\nReproducibility and Replicability in Science defines reproducibility and replicability and examines the factors that may lead to non-reproducibility and non-replicability in research. Unlike the typical expectation of reproducibility between two computations, expectations about replicability are more nuanced, and in some cases a lack of replicability can aid the process of scientific discovery. This report provides recommendations to researchers, academic institutions, journals, and funders on steps they can take to improve reproducibility and replicability in science.",
  url       = "https://nap.nationalacademies.org/catalog/25303/reproducibility-and-replicability-in-science",
  year      = 2019,
  publisher = "The National Academies Press",
  address   = "Washington, DC"
}

@inproceedings{davidson2008provenance,
  title={Provenance and scientific workflows: challenges and opportunities},
  author={Davidson, Susan B and Freire, Juliana},
  booktitle={Proceedings of the 2008 ACM SIGMOD international conference on Management of data},
  pages={1345--1350},
  year={2008}
}



@article{Li2024AutomatedSM,
  title={Automated Statistical Model Discovery with Language Models},
  author={Michael Y. Li and Emily B. Fox and Noah D. Goodman},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.17879},
  url={https://api.semanticscholar.org/CorpusID:268041863}
}

@article{parashar2022research,
  title={Research reproducibility},
  author={Parashar, Manish and Heroux, Michael A and Stodden, Victoria},
  journal={Computer},
  volume={55},
  number={8},
  pages={16--18},
  year={2022},
  publisher={IEEE}
}

@article{kelion2020excel,
  title={Excel: why using microsoft’s tool caused Covid-19 results to be lost},
  author={Kelion, Leo},
  journal={BBC News},
  volume={5},
  year={2020}
}

@article{herndon2014does,
  title={Does high public debt consistently stifle economic growth? A critique of Reinhart and Rogoff},
  author={Herndon, Thomas and Ash, Michael and Pollin, Robert},
  journal={Cambridge journal of economics},
  volume={38},
  number={2},
  pages={257--279},
  year={2014},
  publisher={Oxford University Press UK}
}

@inproceedings{gu2024analysts,
  title={How Do Analysts Understand and Verify AI-Assisted Data Analyses?},
  author={Gu, Ken and Shang, Ruoxi and Althoff, Tim and Wang, Chenglong and Drucker, Steven M},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--22},
  year={2024}
}

@article{majumder2024discoverybench,
  title={Discoverybench: Towards data-driven discovery with large language models},
  author={Majumder, Bodhisattwa Prasad and Surana, Harshit and Agarwal, Dhruv and Mishra, Bhavana Dalvi and Meena, Abhijeetsingh and Prakhar, Aryan and Vora, Tirth and Khot, Tushar and Sabharwal, Ashish and Clark, Peter},
  journal={arXiv preprint arXiv:2407.01725},
  year={2024}
}

@article{liu2024llms,
  title={Are llms capable of data-based statistical and causal reasoning? benchmarking advanced quantitative reasoning with data},
  author={Liu, Xiao and Wu, Zirui and Wu, Xueqing and Lu, Pan and Chang, Kai-Wei and Feng, Yansong},
  journal={arXiv preprint arXiv:2402.17644},
  year={2024}
}

@article{gu2024blade,
  title={Blade: Benchmarking language model agents for data-driven science},
  author={Gu, Ken and Shang, Ruoxi and Jiang, Ruien and Kuang, Keying and Lin, Richard-John and Lyu, Donghe and Mao, Yue and Pan, Youran and Wu, Teng and Yu, Jiaqian and others},
  journal={arXiv preprint arXiv:2408.09667},
  year={2024}
}

@article{zhu2024large,
  title={Are Large Language Models Good Statisticians?},
  author={Zhu, Yizhang and Du, Shiyin and Li, Boyan and Luo, Yuyu and Tang, Nan},
  journal={arXiv preprint arXiv:2406.07815},
  year={2024}
}
@misc{lai2022ds1000,
      title={DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation}, 
      author={Yuhang Lai and Chengxi Li and Yiming Wang and Tianyi Zhang and Ruiqi Zhong and Luke Zettlemoyer and Scott Wen-tau Yih and Daniel Fried and Sida Wang and Tao Yu},
      year={2022},
      eprint={2211.11501},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2211.11501}, 
}
@misc{huang2022execution,
      title={Execution-based Evaluation for Data Science Code Generation Models}, 
      author={Junjie Huang and Chenglong Wang and Jipeng Zhang and Cong Yan and Haotian Cui and Jeevana Priya Inala and Colin Clement and Nan Duan and Jianfeng Gao},
      year={2022},
      eprint={2211.09374},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2211.09374}, 
}
@inproceedings{zhao2022multihiertt,
    title = "{M}ulti{H}iertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data",
    author = "Zhao, Yilun  and
      Li, Yunxiang  and
      Li, Chenying  and
      Zhang, Rui",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.454/",
    doi = "10.18653/v1/2022.acl-long.454",
    pages = "6588--6600"
}
@misc{hu2024infiagent,
      title={InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks}, 
      author={Xueyu Hu and Ziyu Zhao and Shuang Wei and Ziwei Chai et. al},
      year={2024},
      eprint={2401.05507},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.05507}, 
}
@inproceedings{hazoom2021text,
    title = "Text-to-{SQL} in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data",
    author = "Hazoom, Moshe  and
      Malik, Vibhor  and
      Bogin, Ben",
    editor = "Lachmy, Royi  and
      Yao, Ziyu  and
      Durrett, Greg  and
      Gligoric, Milos  and
      Li, Junyi Jessy  and
      Mooney, Ray  and
      Neubig, Graham  and
      Su, Yu  and
      Sun, Huan  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nlp4prog-1.9/",
    doi = "10.18653/v1/2021.nlp4prog-1.9",
    pages = "77--87",
  }
@inproceedings{yu2018spider,
    title = "{S}pider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-{SQL} Task",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Yang, Kai  et. al",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1425/",
    doi = "10.18653/v1/D18-1425",
    pages = "3911--3921",
  }
@misc{hong2024datainterpreter,
      title={Data Interpreter: An LLM Agent For Data Science}, 
      author={Sirui Hong and Yizhang Lin and Bang Liu and Bangbang Liu et. al},
      year={2024},
      eprint={2402.18679},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.18679}
}
@article{guo2024ds,
  title={DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning},
  author={Guo, Siyuan and Deng, Cheng and Wen, Ying and Chen, Hechang and Chang, Yi and Wang, Jun},
  journal={arXiv preprint arXiv:2402.17453},
  year={2024}
}
@misc{bordt2024datascience,
      title={Data Science with LLMs and Interpretable Models}, 
      author={Sebastian Bordt and Ben Lengerich and Harsha Nori and Rich Caruana},
      year={2024},
      eprint={2402.14474},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.14474}, 
}

@misc{nascimento2024llm4ds,
      title={LLM4DS: Evaluating Large Language Models for Data Science Code Generation}, 
      author={Nathalia Nascimento and Everton Guimaraes and Sai Sanjna Chintakunta and Santhosh Anitha Boominathan},
      year={2024},
      eprint={2411.11908},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2411.11908}, 
}

@misc{nejjar2024llms,
      title={LLMs for Science: Usage for Code Generation and Data Analysis}, 
      author={Mohamed Nejjar and Luca Zacharias and Fabian Stiehle and Ingo Weber},
      year={2024},
      eprint={2311.16733},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2311.16733}, 
}

@misc{wang2024large,
      title={Can Large Language Models Replace Data Scientists in Clinical Research?}, 
      author={Zifeng Wang and Benjamin Danek and Ziwei Yang and Zheng Chen and Jimeng Sun},
      year={2024},
      eprint={2410.21591},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.21591}, 
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@misc{amini2019mathqa,
      title={MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms}, 
      author={Aida Amini and Saadia Gabriel and Peter Lin and Rik Koncel-Kedziorski and Yejin Choi and Hannaneh Hajishirzi},
      year={2019},
      eprint={1905.13319},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1905.13319}, 
}

@misc{jimenez2024swebench,
      title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?}, 
      author={Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik Narasimhan},
      year={2024},
      eprint={2310.06770},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06770}, 
}

@misc{codegemmateam2024,
      title={CodeGemma: Open Code Models Based on Gemma}, 
      author={CodeGemma Team and Heri Zhao and Jeffrey Hui and Joshua Howland et. al},
      year={2024},
      eprint={2406.11409},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11409}, 
}

@misc{guo2024deepseek,
      title={DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence}, 
      author={Daya Guo and Qihao Zhu and Dejian Yang and Zhenda Xie and Kai Dong and Wentao Zhang and Guanting Chen and Xiao Bi and Y. Wu and Y. K. Li and Fuli Luo and Yingfei Xiong and Wenfeng Liang},
      year={2024},
      eprint={2401.14196},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2401.14196}, 
}

@misc{rozière2024codellama,
      title={Code Llama: Open Foundation Models for Code}, 
      author={Baptiste Rozière and Jonas Gehring and Fabian Gloeckle et. al},
      year={2024},
      eprint={2308.12950},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.12950}, 
}

@misc{grattafiori2024llama3,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey et. al},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@Article{Gutierrez2023Reproducibility,
AUTHOR = {Quiroga Gutierrez, Ana Cecilia and Lindegger, Daniel J. and Taji Heravi, Ala and Stojanov, Thomas and Sykora, Martin and Elayan, Suzanne and Mooney, Stephen J. and Naslund, John A. and Fadda, Marta and Gruebner, Oliver},
TITLE = {Reproducibility and Scientific Integrity of Big Data Research in Urban Public Health and Digital Epidemiology: A Call to Action},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {20},
YEAR = {2023},
NUMBER = {2},
ARTICLE-NUMBER = {1473},
URL = {https://www.mdpi.com/1660-4601/20/2/1473},
PubMedID = {36674225},
ISSN = {1660-4601},
DOI = {10.3390/ijerph20021473}
}

@article {Glasziouk4645,
	author = {Glasziou, Paul and Chalmers, Iain},
	title = {Research waste is still a scandal{\textemdash}an essay by Paul Glasziou and Iain Chalmers},
	volume = {363},
	elocation-id = {k4645},
	year = {2018},
	doi = {10.1136/bmj.k4645},
	publisher = {BMJ Publishing Group Ltd},
	issn = {0959-8138},
	URL = {https://www.bmj.com/content/363/bmj.k4645},
	eprint = {https://www.bmj.com/content/363/bmj.k4645.full.pdf},
	journal = {BMJ}
}


@misc{lee2024evaluatingconsistenciesllm,
      title={Evaluating Consistencies in LLM responses through a Semantic Clustering of Question Answering}, 
      author={Yanggyu Lee and Jihie Kim},
      year={2024},
      eprint={2410.15440},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.15440}, 
}

@misc{lee2024evaluatingconsistency,
      title={Evaluating the Consistency of LLM Evaluators}, 
      author={Noah Lee and Jiwoo Hong and James Thorne},
      year={2024},
      eprint={2412.00543},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.00543}, 
}

@misc{vaugrante2024looming,
      title={A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions}, 
      author={Laurène Vaugrante and Mathias Niepert and Thilo Hagendorff},
      year={2024},
      eprint={2409.20303},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.20303}, 
}

@inproceedings{TheC3,
  title={The Claude 3 Model Family: Opus, Sonnet, Haiku},
  author={Anthropic},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:268232499}
}

@misc{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal et. al},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{chen2021evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan et. al},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.03374}, 
}

@misc{jiang2024survey,
      title={A Survey on Large Language Models for Code Generation}, 
      author={Juyong Jiang and Fan Wang and Jiasi Shen and Sungju Kim and Sunghun Kim},
      year={2024},
      eprint={2406.00515},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.00515}, 
}

@inproceedings{Zheng2023CodeGeeX,
author = {Zheng, Qinkai and Xia, Xiao and Zou, Xu and Dong, Yuxiao and Wang, Shan and Xue, Yufei and Shen, Lei and Wang, Zihan and Wang, Andi and Li, Yang and Su, Teng and Yang, Zhilin and Tang, Jie},
title = {CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599790},
doi = {10.1145/3580305.3599790},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5673–5684},
numpages = {12},
keywords = {code generation, large language model, pre-trained model},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@book{casella2024statistical,
  title={Statistical inference},
  author={Casella, George and Berger, Roger},
  year={2024},
  publisher={CRC press}
}

@misc{zakerinasrabadi2023systematicliteraturereviewsource,
      title={A systematic literature review on source code similarity measurement and clone detection: techniques, applications, and challenges}, 
      author={Morteza Zakeri-Nasrabadi and Saeed Parsa and Mohammad Ramezani and Chanchal Roy and Masoud Ekhtiarzadeh},
      year={2023},
      eprint={2306.16171},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2306.16171}, 
}

@misc{openai2025o3mini,
  title        = {OpenAI o3-mini System Card},
  author       = {OpenAI},
  year         = {2025},
  url = {https://cdn.openai.com/o3-mini-system-card.pdf},
  note         = {Accessed: 2025-02-06}
}

@article{breznau2022observing,
  title={Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertainty},
  author={Breznau, Nate and Rinke, Eike Mark and Wuttke, Alexander and Nguyen, Hung HV and Adem, Muna and Adriaans, Jule and Alvarez-Benjumea, Amalia and Andersen, Henrik K and Auer, Daniel and Azevedo, Flavio and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={119},
  number={44},
  pages={e2203150119},
  year={2022},
  publisher={National Acad Sciences},
doi = {10.1073/pnas.2203150119},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2203150119},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2203150119},
}

@article{botvinik2020variability,
  title={Variability in the analysis of a single neuroimaging dataset by many teams},
  author={Botvinik-Nezer, Rotem and Holzmeister, Felix and Camerer, Colin F and Dreber, Anna and Huber, Juergen and Johannesson, Magnus and Kirchler, Michael and Iwanir, Roni and Mumford, Jeanette A and Adcock, R Alison and others},
  journal={Nature},
  volume={582},
  number={7810},
  pages={84--88},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@misc{majumder2024datadrivendiscoverylargegenerative,
      title={Data-driven Discovery with Large Generative Models}, 
      author={Bodhisattwa Prasad Majumder and Harshit Surana and Dhruv Agarwal and Sanchaita Hazra and Ashish Sabharwal and Peter Clark},
      year={2024},
      eprint={2402.13610},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13610}, 
}

@inproceedings{yu2020veridical,
  title={Veridical data science},
  author={Yu, Bin},
  booktitle={Proceedings of the 13th international conference on web search and data mining},
  pages={4--5},
  year={2020}
}

@article{rasheed2025large,
  title={Large Language Models for Code Generation: The Practitioners Perspective},
  author={Rasheed, Zeeshan and Waseem, Muhammad and Kemell, Kai Kristian and Ahmad, Aakash and Sami, Malik Abdul and Rasku, Jussi and Syst{\"a}, Kari and Abrahamsson, Pekka},
  journal={arXiv preprint arXiv:2501.16998},
  year={2025}
}

@inproceedings{Mayfield_2024, series={SIGIR 2024},
   title={On the Evaluation of Machine-Generated Reports},
   url={http://dx.doi.org/10.1145/3626772.3657846},
   DOI={10.1145/3626772.3657846},
   booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
   publisher={ACM},
   author={Mayfield, James and Yang, Eugene and Lawrie, Dawn and MacAvaney, Sean and McNamee, Paul and Oard, Douglas W. and Soldaini, Luca and Soboroff, Ian and Weller, Orion and Kayi, Efsun and Sanders, Kate and Mason, Marc and Hibbler, Noah},
   year={2024},
   month=jul, pages={1904–1915},
   collection={SIGIR 2024} }
