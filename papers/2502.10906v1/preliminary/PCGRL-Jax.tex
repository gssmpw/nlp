
This study uses the \textit{PCGRL-Jax} \cite{earle2024scaling} environment, a GPU-accelerated implementation of the widely used two-dimensional level generation framework \cite{khalifa2020pcgrl,earle2021learning}.
The selected environment ensures a deterministic reward setting compared to the stochastic reward signal used in the previous study \cite{baek2024chatpcg}, so that the generated reward function is relatively accurately evaluated with a consistently trained policy.
Moreover, the environment provides 17$\times$ faster training time than CPU-based environment for multiple reward generate-and-evaluate iterations.

Each episode begins with a randomly initialized 16 $\times{}$ 16 matrix derived from a predefined tile set. The tile set consists of seven types: \textit{Empty} \includegraphics[height=0.8em]{figure/tiles/empty.png}, \textit{Wall} \includegraphics[height=0.8em]{figure/tiles/solid.png}, \textit{Player} \includegraphics[height=0.8em]{figure/tiles/player.png}, \textit{Bat} \includegraphics[height=0.8em]{figure/tiles/bat.png}, \textit{Scorpion} \includegraphics[height=0.8em]{figure/tiles/scorpion.png}, \textit{Spider} \includegraphics[height=0.8em]{figure/tiles/spider.png}, \textit{Key} \includegraphics[height=0.8em]{figure/tiles/key.png}, and \textit{Door} \includegraphics[height=0.8em]{figure/tiles/door.png}. Each tile type is represented numerically in the matrix to indicate its presence.
The agent can modify five types of tiles, except for two unchangeable \textit{Player} and \textit{Door} tiles, along with the $3 \times 3$ area of unchangeable tiles surrounding the tiles.
The two unchangeable tiles are randomly spawned on the opposite corners of the level in the initial state.
The observation space is defined as a 2D array representing the integer tile numbers, along with a channel the location of the tile to be modified.
The discrete action space includes five actions, each corresponding to the specific tile type that replaces the tile at the modification location.
The reward for the agent is determined by an LLM-generated reward function, implemented using JAX-compatible functions \cite{jax2018github}.
