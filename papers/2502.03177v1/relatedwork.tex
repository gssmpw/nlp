\section{Background and Related Work}
\label{sec:background}

Simply put, IP cameras are network-connected devices that convert physical movement in their field of view into packets. 
The more movement in the scene, the more packets the cameras generate and transmit to the network. In this section, we provide background material on generating a network denial-of-service (DoS) attack with IP cameras, as well as relevant related work.

\subsection{IP Cameras as Network Devices}
\label{sec:compression}
Modern digital cameras convert light into electronic signals to capture images or video footage. Each video recording is a sequence of frames, typically captured at rates of 24-120 FPS, which, when displayed in sequence to the human eye, create the illusion of motion. These frames generate substantial raw data. For example, an uncompressed 1080×1920 video at 60 FPS requires $\approx 2.986Gb/s$, making raw storage and transmission impractical. To address this, video compression techniques reduce the data size while maintaining a balance between visual quality and computational efficiency \cite{Mitrovic_VideoCompression, jack2011video, nassi2018gamedronesdetecting}.

Video encoding takes advantage of the fact that our eyes are more sensitive to variations in brightness (luminance) than to changes in color (chrominance) in order to reduce the resolution of color information through a process called \textit{chroma subsampling}, where color data are sampled at a lower resolution than brightness data. Common subsampling schemes like 4:2:2 and 4:2:0 keep all of the luminance data while sampling chrominance at $1/2$ and $1/4$ resolution, respectively.

Another aspect of video encoding is exploiting redundancies within and between frames. Spatial redundancy arises from similarities between neighboring pixels in a single frame, while temporal redundancy stems from similarities between consecutive frames. Techniques such as discrete cosine transform (DCT) address spatial redundancy by transforming image blocks into frequency components. High-frequency components, which represent fine details less noticeable to human viewers, are quantized or discarded. This reduces the data required to represent a frame.

Temporal redundancy arises because consecutive frames in a video sequence often contain similar content, especially in scenes with minimal motion. Instead of encoding each frame in full, only the changes between frames are encoded. This is achieved through motion estimation and compensation.

Regular motion events in an office environment have a negligible impact on the stream size, as modern video compression algorithms are based on motion vectors. 
Motion estimation identifies blocks of pixels in one frame corresponding to blocks in a reference frame. The displacement of these blocks is represented by \textit{motion vectors}, which describe the direction and magnitude of movement. Motion compensation uses these vectors to predict the content of the current frame based on reference frames. By encoding only the differences between the actual and predicted frames, the data size is significantly reduced.
This means that a person walking in a corridor has a similar impact on the generated traffic as a person standing in place. 
Therefore, to generate additional traffic, unexpected or unusual changes in the scene are required. 


% For example, consider a typical security camera monitoring a hallway. While the walls, floor, and doors remain static, they are occasionally interrupted by the movement of a person walking through. Sending the entire scene 30 times per second would be highly inefficient. Instead, the system establishes periodic "key frames" (also known as I-frames), which serve as complete reference images and are typically sent every few seconds or whenever significant scene changes occur. Between these key frames, the camera transmits only the differences, referred to as delta frames (P-frames and B-frames). These delta frames contain information about motion vectors that describe how objects have moved, any changed pixel data, and references to the static parts of the previous frame.
% In that sense, the bitrate of the network traffic that IP cameras generate is adaptive, and it is based on the physical changes in the scene.
% This approach substantially reduces bandwidth requirements while maintaining visual quality. In our hallway example, the codec might only need to transmit data about the moving person while referencing the static background from the previous key frame. This solution also explains why video can sometimes display artifacts during packet loss—if a key frame is missed, the subsequent delta frames lack a crucial reference point for reconstructing the complete image. 


Video encoding employs three types of frames, which work together to balance compression efficiency and video quality:

\begin{itemize} 
    \item \textbf{I-Frames (Intra-coded):} These frames serve as independent reference points, and they are fully encoded without relying on other frames.
    \item \textbf{P-Frames (Predicted):} These frames only store the differences from a preceding frame, reducing data size.
    \item \textbf{B-Frames (Bidirectional):} These frames use data from preceding and subsequent frames to increase encoding efficiency.
\end{itemize}

When encoding a live video stream, B-frames are typically avoided, as the successive frames necessary to define a B-frame are in the yet-unknown future.

Modern video encoding algorithms typically perform a multi-stage process consisting of the following steps:
\begin{enumerate} 
\item \textbf{Color Space Conversion and Chroma Subsampling:} Convert the raw RGB data into a suitable format (e.g., YCbCr) and reduce chrominance resolution.
\item \textbf{Partitioning:} Divide each frame into blocks (e.g., $8\times8$ or $16\times16$ pixels) for efficient and independent processing.
\item \textbf{Motion Estimation and Compensation:} Identify motion vectors and encode only the changes between frames.
\item \textbf{Transformation and Quantization:} Apply DCT to reduce spatial redundancy, followed by quantization to lower precision when less detail is perceived.
\item \textbf{Entropy Coding:} Use lossless compression techniques such as Huffman coding and run-length encoding (RLE) to efficiently represent the quantized data.
\end{enumerate}

Therefore, for the attack to succeed, we need to render these optimizations as ineffective as we can. This is done by minimizing the temporal redundancies within each frame and the spatial redundancies between frames, increasing the data needed to encode key and delta frames.

\subsection{DDoS Attacks and IP Cameras}

As IoT continues to expand, IP cameras have increasingly become targets for attackers. Threat actors exploit IP cameras primarily through two categories of attacks, which we refer to as invasive and non-invasive attacks.

In invasive attacks, attackers gain unauthorized access to the internals of the device to obtain privileged capabilities, such as the capability to execute arbitrary code, modify the device’s configuration settings, or even replace firmware. These attacks are often facilitated by firmware vulnerabilities that allow remote code execution (RCE) \cite{alrawi2019ip}. A notable example is the Mirai botnet, which compromised IoT devices, including IP cameras, by brute-forcing weak credentials and implanting malware that executed attacker-controlled instructions \cite{antonakakis2017mirai}. 
Similarly, vulnerabilities in devices have been exploited to perform unauthenticated RCE, turning IP cameras into potential surveillance or attack tools \cite{watchfulip2021hikvision}. Additional studies have demonstrated how specific IoT camera models were susceptible to invasive exploits that allowed complete device control \cite{stabili2024tenda}.

In contrast, in non-invasive attacks, attackers exploit network-connected cameras without directly modifying the device's firmware or internal configurations. Instead, they leverage the device's existing functionalities to achieve unintended outcomes, such as participating in DDoS amplification attacks. This method does not require installing malware on the device. For instance, misconfigured IoT devices, including IP cameras, have been exploited in Simple Service Discovery Protocol (UPnP\textbackslash SSDP) amplification attacks, where attackers send spoofed requests to these devices, causing them to send large responses to the target \cite{kolias2017mirai, helpnetsecurity2019ssdp}.


In recent years, we have seen a rise in network defense technologies that specifically address DDoS attacks. 
To overload a network remotely, an attacker typically needs to generate a significant amount of traffic and bypass anti-DDoS scrubbing centers, which filter out DDoS traffic and pass only legitimate packets to the client. In 2024, Cloudflare, which provides an anti-DDoS cloud-based scrubbing service, mitigated the largest DDoS attack on record, peaking at 5.6 terabits per second (Tbps) and 666 million packets per second (pps) \cite{cloudflare_famous_ddos}. Since many critical processes are heavily filtered or even disconnected from the Internet, mounting a successful remote DDoS attack that impacts a critical process is practically infeasible.
Instead of targeting the network remotely, an attacker could connect to a LAN and launch a DoS attack internally. 
However, this is even more challenging, as the attacker would need to bypass physical security and network access controls.

\textbf{Unlike existing DoS attacks, our method requires neither remote nor local network access -- a line of sight to the surveillance cameras of the targeted facility is all that is needed.} 


\subsection{Variable Bitrate Exploitation}

The phenomenon in which physical-world events directly influence network traffic patterns is prevalent among IoT devices, industrial control system (ICS) actuators and sensors, industrial IoT (IIoT) devices, and cyber-physical systems in general~\cite{xu2018survey}.
The ability to connect between the physical real world and the digital man-made realms is the raison d'être of cyber-physical system development. 
It is the ability to represent physical phenomena in digital terms and vice versa that gave rise to cyber-physical systems in the first place. Once you can translate the physical into the digital (e.g., by using sensors), you can also apply computation and automated decision-making. Such decisions can be translated back from the digital realm to physical actions (e.g., by using actuators), thereby interconnecting the physical and digital worlds.

In this context, the relationship between physical events and network traffic represents a fundamental design pattern in cyber-physical architectures, where computer systems typically monitor some real-world aspects and report on their observations via a network~\cite{mois2016cyber}. 
In IP networks, cyber-physical devices are sometimes designed to adapt their communication patterns based on real-world stimuli. This adaptation mechanism is important for efficient network utilization and system operation, as well as energy saving, which is especially critical for battery-powered devices. The philosophy behind adaptive behavior (e.g., adaptive data sampling) is that the behavior should depend on the rate at which the real-world phenomenon changes (e.g., signal changes) \cite{waterSampling2017}. 
Similarly, video and audio devices adjust their bitrate based on changes in the video or audio they capture. 
In this context, two techniques have emerged over the last decade to efficiently manage network bandwidth: adaptive sampling and adaptive filtering. 
These techniques dynamically adjust data transmission rates and filter thresholds based on environmental conditions \cite{giouroukis2020survey}. 
For example, when sensors detect significant changes or events of interest, they may increase their sampling and transmission rates~\cite{anta2010sample,molhem2024novel}, leading to higher volumes of network traffic. Conversely, during periods of stability or inactivity, these algorithms reduce data transmission to conserve network resources. 

In this regard, consider industrial vibration sensors that increase their sampling and transmission rates upon detecting anomalous machinery behavior~\cite{yin2023adaptive}. 
Under normal operating conditions, these sensors may transmit minimal data. However, when they detect unusual vibrations, they can flood the network with high-frequency measurements and alerts.
Some audio monitoring systems in industrial environments also demonstrate this characteristic, generating variable bitrate traffic that correlates with changes in noise levels \cite{AudioSampling2010}.

In cases where the sensors are battery-powered, which is quite common for in-field deployed sensors, increased activity may lead to quicker battery exhaustion \cite{Harb2018Energy-Efficient}. 
For example, to conserve sensor battery life, it is beneficial to reduce the amount of data sampled by water sensors when the monitored environment is stable. 
Submerged sensors that monitor water quality may increase their water sampling rate rapidly once a change in pH value, dissolved oxygen (DO), conductivity, oxidation-reduction potential (ORP), turbidity, or temperature is detected \cite{waterSampling2017}. When certain parameters of the water change abruptly, the sampling frequency automatically increases to gather enough information about these changes.


%Although adaptive behavior aims to enhance battery efficiency, it also influences network utilization—lower sampling rates lead to reduced network traffic, while higher sampling during environmental changes generates more data across the network.
\textbf{While adaptive behavior optimizes power and bandwidth usage under normal operating conditions, it also results in the direct influence of physical world events on network utilization. 
This relationship creates a potentially exploitable connection between environmental stimuli and resource exhaustion, such as battery depletion.} 
Moreover, an adversary capable of manipulating the physical environment could exploit these adaptive behaviors, resulting in excessive network traffic, which may lead to decreased availability of other resources and services that rely on the network.