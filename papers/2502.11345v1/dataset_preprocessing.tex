\section{Dataset Preprocessing}
\label{sec:dataset_preprocessing}

Here we introduce dataset preprocessing. We will release code and datasets upon publication.

Cora \cite{cora} is a paper citation graph where each document is an academic paper with abstract, and each graph edge is a citation between two documents. We follow \cite{cora2} and created three independent datasets, Data Structure (\textbf{DS}), Machine Learning (\textbf{ML}), and Programming Language (\textbf{PL}).

\textbf{DBLP} \cite{aminer} is anther academic paper citation graph. We used \textit{DBLP-Citation-network V4} version\footnote{\url{https://www.aminer.org/citation}}. We removed documents with no words and documents with no citations. After removal, we obtain 239,026 documents and 1,071,208 citation links.

\textbf{COVID} is a Coronavirus news corpus available online\footnote{\url{https://aylien.com/coronavirus-news-dataset/}}, collected from multiple publishers. Each document is a news article and has a category for the content of the article. We selected five categories, \emph{economy, business, and finance}, \emph{education}, \emph{health}, \emph{labour}, and \emph{sports}. For each category, we randomly selected 300 news articles, resulting in a corpus of 1,500 articles in total. Since we did not observe graph edges connecting these articles, we compared documents' $ tf-idf $ similarity and induced edges by $ \kappa $NN ($ \kappa=5 $), resulting in 5,706 links in total.

\textbf{Web} is a Webpage hyperlink graph publicly available online\footnote{\url{https://snap.stanford.edu/data/memetracker9.html}}. Each Webpage is a news article containing the most frequent phrases and quotes. Each page has hyperlinks to other related pages. The Webpages in this dataset were published between August 2008 through April 2009. We collected Webpages published between August 2008 through December 2008. For each Webpage, we used Breadth First Search algorithm to collect its neighbors. We remove pages with less than 30 words, resulting in 445,657 documents and 565,505 hyperlinks in total. We did not observe any ground-truth categories of these documents.