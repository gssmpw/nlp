\section{Related Work}
%\textbf{Flat topic models} are based on graphical models **Blei, "Probabilistic Topic Models"** and auto-encoders **Vincent, "Extracting and generalizing features from unlabeled data"**. Some others are GNNs **Kipf, "Semi-Supervised Classification with Graph Convolutional Networks"****Schlichtkrull, "Graph Attention Networks"**, including **Battaglia, "Relational inductive biases, decomposability, and complementarity in deep neural networks"**. Recently, they are based on language models **Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**__, e.g., BERTopic ____**, TopicGPT ____**, GPTopic ____**. They do not model topic or graph hierarchy.

\textbf{Topic models} are first designed with flat topics ____. HTMs explore topic hierarchy, e.g., graphical **Blei, "Probabilistic Topic Models"** and neural ones ____, but no one captures graph structure. Though Doubly RNN appears in **Saxe, "Approximating CNNs with Combinatorial Optimization"**, it is in Euclidean, not in hyperbolic space. Hyperbolic space has been shown to be more effective to capture hierarchy.

\textbf{Relational topic models} deal with graph-structured documents ____. %They indeed consider both modalities, but no one models topic or graph \emph{hierarchy}. 
The recent HGTM ____ is the only one with both hierarchies, but is a cascaded method and is not effective to integrate both hierarchies. %We insert topic and graph hierarchies into each Transformer layer to unify them.

\textbf{Graph neural networks (GNNs)} are first proposed in Euclidean space ____. To model graph hierarchy, hyperbolic GNNs are proposed, e.g., HGNN **Malliaros, "Hyperbolic Graph Neural Networks"**, HGCN ____**, HAT ____**, HTGN ____**, $\kappa$GCN ____. However, they mainly focus on graph structure, and do not deal with textual semantics.

\textbf{Text-attributed graph} combines GNNs and language models for both graph and text, e.g., GraphFormer **You, "Graph Transformer Networks"**__, Patton ____**, Heterformer ____**, Edgeformers ____**, TAPE ____, Specter ____**, LinkBERT ____**, etc. They consider both modalities, but no one models topic or graph \emph{hierarchy}.