






\documentclass[sigconf]{aamas} 

\newif\ifmargincomments
\margincommentsfalse

\newif\ifextendedversion
\extendedversiontrue

\newif\iftasknetworks
\tasknetworksfalse


\usepackage{balance} %
\usepackage{graphicx}
\graphicspath{{.}{images/}}

\addtolength{\intextsep}{-1em}

\usepackage{color}
\usepackage[colorinlistoftodos,prependcaption,textsize=footnotesize]{todonotes}
\iftasknetworks
\ifextendedversion
\usepackage{minted}
\fi
\fi
\usepackage{algorithm}
\usepackage{algpseudocode}



\ifmargincomments
\newcommand{\frmargin}[2]{{\color{green}#1}\marginpar{\color{Apricot}\raggedright\footnotesize [FR]:#2}}
\newcommand{\mmmargin}[2]{{\color{red}#1}\marginpar{\color{red}\raggedright\footnotesize [MM]:#2}}
\newcommand{\revmm}[1]{{\color{blue}#1}}
\newcommand{\frtodo}[1]{\todo[inline,color=green]{[fr] #1}}
\newcommand{\mmtodo}[1]{\todo[inline,color=red]{[mm] #1}}
\newcommand{\agtodo}[1]{\todo[inline,color=blue]{[ag] #1}}
\newcommand{\grtodo}[1]{\todo[inline,color=yellow]{[gr] #1}}
\newcommand{\revI}[1]{{\color{blue}#1}}
\else
\newcommand{\frmargin}[2]{#1}
\newcommand{\mmmargin}[2]{#1}
\newcommand{\revmm}[1]{#1}
\newcommand{\frtodo}[1]{}
\newcommand{\mmtodo}[1]{}
\newcommand{\agtodo}[1]{}
\newcommand{\grtodo}[1]{}
\newcommand{\revI}[1]{#1}
\fi

\newcommand{\gobble}[1]{}



\makeatletter
\gdef\@copyrightpermission{
 * denotes equal contribution.
 
  \begin{minipage}{0.2\columnwidth}
   \href{https://creativecommons.org/licenses/by/4.0/}{\includegraphics[width=0.90\textwidth]{by}}
  \end{minipage}\hfill
  \begin{minipage}{0.8\columnwidth}
   \href{https://creativecommons.org/licenses/by/4.0/}{This work is licensed under a Creative Commons Attribution International 4.0 License.}
  \end{minipage}
  \vspace{1pt}
}
\makeatother

\setcopyright{ifaamas}
\acmConference[AAMAS '25]{Proc.\@ of the 24th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS 2025)}{May 19 -- 23, 2025}
{Detroit, Michigan, USA}{Y.~Vorobeychik, S.~Das, A.~Now√©  (eds.)}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{}
\acmPrice{}
\acmISBN{}



\acmSubmissionID{580}


\title[Planning and scheduling on the lunar CADRE mission]{Planning, scheduling, and execution on the Moon: the CADRE technology demonstration mission}


\author{Gregg Rabideau*}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{gregg.rabideau@jpl.nasa.gov}

\author{Joseph Russino*}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{joseph.a.russino@jpl.nasa.gov}

\author{Andrew Branch}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{andrew.branch@jpl.nasa.gov}

\author{Nihal Dhamani}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{nihal.n.dhamani@jpl.nasa.gov}

\author{Tiago Stegun Vaquero}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{tiago.stegun.vaquero@jpl.nasa.gov}

\author{Steve Chien}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{steve.a.chien@jpl.nasa.gov}

\author{Jean-Pierre de la Croix}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{jean-pierre.de.la.croix@jpl.nasa.gov}

\author{Federico Rossi}
\affiliation{
  \institution{Jet Propulsion Laboratory - California Institute of Technology}
  \city{Pasadena, CA}
  \country{USA}}
\email{federico.rossi@jpl.nasa.gov}



\begin{abstract}
NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE) mission, slated for flight to the Moon's Reiner Gamma region in \revI{2025/2026}, is designed to demonstrate multi-agent autonomous exploration of the Lunar surface and sub-surface.
A team of three robots and a base station will autonomously explore a region near the lander, collecting the data required for 3D reconstruction of the surface with no human input; and then autonomously perform distributed sensing with multi-static ground penetrating radars (GPR), driving in formation while performing coordinated radar soundings to create a map of the subsurface.
At the core of CADRE's software architecture is a novel autonomous, distributed planning, scheduling, and execution (PS\&E) system. The system coordinates the robots' activities, planning and executing tasks that require multiple robots' participation while ensuring that each individual robot's thermal and power resources stay within prescribed bounds, and respecting ground-prescribed sleep-wake cycles. The system uses a centralized-planning, distributed-execution paradigm, and a leader election mechanism ensures robustness to failures of individual agents.
In this paper, we describe the architecture of CADRE's \pse system; discuss its design rationale; and report on verification and validation (V\&V) testing of the system on CADRE's hardware in preparation for deployment on the Moon. 

\end{abstract}




\keywords{Lunar exploration, Space robotics, Leader election, Planning architecture, Space exploration}


         
\newcommand{\BibTeX}{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em\TeX}
\newcommand{\pse}{PS\&E~}


\begin{document}


\pagestyle{fancy}
\fancyhead{}


\maketitle 



\section{Introduction}
Distributed instruments hold great promise to unlock key questions in planetary science that are inaccessible to single-point measurements. The ability to collect time-synchronized and cross-calibrated measurements from spatially distributed\gobble{, and potentially moving,} locations is critical to investigations of subjects as diverse as atmospheric circulation on Mars, Venus, and Titan \cite{haberle2014preliminary}; sub-surface compositions of rocky and icy moons \cite{netsag2010,Vance}; and  seismic activity on Venus \cite{RossiSaboiaEtAl2023}.

The traditional operations paradigm for space exploration missions relies on on-board execution of sequences, developed by human operators on the ground, that specify which activities should be performed at which time by the spacecraft or rover \cite{sellmaier2022spacecraft}; however, such an approach generally does not scale to multi-agent systems, which must cope with bandwidth and latency constraints between individual \revI{agents}; heterogeneous availability of resources (e.g., thermal and power conditions that may vary among agents); and potentially time-varying participation, as some agents may become temporarily, or permanently, unavailable.

These considerations motivate the development of multi-agent autonomous planning, scheduling, and execution (PS\&E) tools for future space exploration missions. Many approaches for multi-agent \pse have been proposed in the literature; however, to date, no approach has been developed and tested to a level of \gobble{maturity (and, specifically,} technology readiness \cite{mankins1995technology}\gobble{)} sufficient for infusion in future spaceflight missions.
 
 \begin{figure}[h]
 \includegraphics[width=\columnwidth]{cadre_animation.png}
 \caption{Overview of the CADRE mission. \gobble{Three autonomous rovers and a lander-mounted base station will cooperatively perform autonomous exploration and collect multi-static ground penetrating radar measurements of the Moon's Reiner Gamma region.}}
 \label{fig:cadre-hero}
 \vspace{-2.5em}
 \end{figure}
 
NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE) mission, shown in Figure \ref{fig:cadre-hero}, aims to fill this gap. CADRE will fly a team of four agents, including three mobile rovers and a static base station, to the Moon's Reiner Gamma region in \revI{2025/2026}. The goal of CADRE is to demonstrate the high technology readiness of cooperative autonomy, that is, the ability for a team of autonomous agents to elaborate high-level commands from ground (e.g., ``explore this region'') into commands for the rovers' mobility system and on-board instruments. \revI{Specifically, the rovers will cooperatively explore a prescribed region and collect multi-static ground penetrating radar measurements; the base station will act as a communication gateway between the rovers and Earth, and aid the team by performing computational tasks.}
 
CADRE's on-board autonomy encompasses autonomous planning, scheduling, and execution; multi-agent motion-planning;  frontier exploration; and single-agent mobility, including localization, mapping, and single-agent motion planning. In this paper, we focus on the autonomous \pse architecture, i.e., on the module that elaborates high-level commands into tasks executed by individual vehicles. We refer the interested reader to \cite{DeLaCroixRossiEa2024} for a discussion of CADRE's overall autonomy architecture.




\subsection{State of the Art}


\paragraph{Multi-agent planning, scheduling, and execution} A vast number of approaches have been proposed for multi-agent planning, scheduling, and execution in the academic community. Coordination approaches include \emph{centralized planning}, where the multi-agent system is effectively treated as a single agent; \emph{leader-election}-based approaches, in which an agent is elected as leader and performs centralized planning for the entire team; \emph{explicit-coordination} approaches (including auctions and broadcast-decentralized algorithms), where agents either bid on tasks to be completed based on their state and resources (e.g., \cite{choi2009consensus}), or explicitly broadcast contention information (e.g., \cite{parjan-jais2023-mas,zilberstein-icaps-2024}); \emph{shared-world} (or \emph{implicit coordination}) approaches, in which each agent maintains a world model through agent-to-agent information sharing, performs planning for the entire system based on the world model, and executes its part of the plan (e.g., \cite{wolf2017caracas,adams2024distributed});  and \emph{emerging behavior} approaches, in which agents communicate with their immediate neighbors and select the next task based on simple heuristics (e.g., \cite{Werfel2014termite}).



We refer the reader to \cite{RossiBandyopadhyayEtAl2021} for a survey of algorithmic approaches to multi-agent decision-making, including planning and scheduling.

\paragraph{Planning and scheduling in space} The majority of the approaches outlined above approaches have not been demonstrated at a technology readiness level (TRL) sufficient for infusion in future missions.

A notable exception is the Distributed Spacecraft Autonomy (DSA) mission \cite{cellucci2020distributed,adams2023overview,adams2024distributed} on NASA's Starling mission. DSA has demonstrated shared-world planning of scientific observations in Earth orbit, where all agents build a common world model, and the planning problem is solved as an integer linear program. 

However, a key difference makes DSA's approach not immediately applicable to CADRE's concept of operations. 
DSA operates in low Earth orbit, where performance of wireless inter-satellite communication links is comparatively predictable; this makes a shared-world approach appropriate, since it is highly likely that, with proper design of the telecommunication system, all agents will converge to the same world model. In contrast, CADRE's domain of operations is the Lunar surface, where surface obstructions and the behavior of disturbed regolith may strongly affect inter-agent communications; this makes a shared-world approach less desirable, since communication failures can result in complex and hard-to-diagnose miscoordination between  agents. 

Several approaches to \emph{single-agent} planning and scheduling have been demonstrated in space. A notable example is the Perseverance Mars rover's Onboard Planner \cite{verma2023autonomous}, in operational use since 2023\gobble{, which schedules and executes tasks on the rover in response to the rover's thermal and power state and to environmental conditions}.
The planner holds promise to significantly increase the rover's mission productivity compared to current ground-in-the-loop approaches (which see the rover idle for up to 28\% of the time \cite{gaines-doran-justice-et-al-2016,gaines-doran-justice-et-al-IWPSS-2017}), and also reduce rover energy usage by over 10\% for a given campaign, saving resources for more opportunistic science investigations.  
A second notable example is CASPER, flown on NASA's EO-1 spacecraft \cite{chien2005eo1}. On-board event detection  from hyperspectral imagery was used to detect thermal anomalies (e.g., lava flows), clouds, floods, and other features; CASPER then replanned observations in response to these detections\gobble{, e.g., rescheduling observations obstructed by high cloud coverage}.
A key commonality between all of these approaches\gobble{, including DSA,} is the strong decoupling between information-sharing and planning --- that is, the assumption that either the planner has access to full system information (in Onboard Planner and CASPER), or that every planner has access to the same information (as in DSA). This assumption is natural for single-agent systems and reasonable for orbiting distributed systems; however, it is significantly more restrictive for surface systems.\gobble{, where line-of-sight and Fresnel zone obstructions may degrade communications between agents in hard-to-predict ways.}





\subsection{Contribution}

Our contribution is the development and testing of a leader-election-based multi-agent planning, scheduling, and execution architecture designed for operations on planetary surfaces. %
The proposed approach explicitly reasons about the information required for planning and for execution, and does \emph{not} assume that all agents have access to the same information;
careful, coupled design of the planning architecture and the task definitions results in reduced inter-agent communications compared to shared-world and auction-based approaches, ensuring good performance as well as resilience to disrupted inter-agent communications.

The rest of this paper is structured as follows. In Section \ref{sec:architecture}, we describe CADRE's \pse architecture. Section \ref{sec:tasknets} describes how the proposed task definitions implement CADRE's concept of operations, and discusses how tasks are designed to use local information as much as practical to reduce communication. Section \ref{sec:testing} discusses the testing, verification, and validation of the proposed architecture and task definitions. Finally, we draw our conclusions in Section \ref{sec:conclusion}.


\section{Planning, scheduling, and execution architecture}
\label{sec:architecture}


CADRE's \pse architecture, shown in Figure \ref{fig:architecture:architecture}, relies on four sets of modules:
\begin{itemize}
\item a \emph{leader election} module that selects one agent to perform planning for the entire team;
\item a lightweight \emph{shared state database} that synchronizes selected state information from all agents to the elected leader;
\item a \emph{strategic planning} module that plans and schedules tasks for all agents; and
\item a set of \emph{agent controllers}, one per agent, that execute the scheduled tasks; monitor task progress and constraint satisfaction; and inform the strategic planning module of task success and failure and of constraint violations that affect other agents' tasks.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{planning_architecture.png}
\caption{Architecture of CADRE's flight software. The second and third row of blocks from the top represent the \pse architecture. \gobble{\revI{Communication between modules, commanding, and telemetry are implemented using the F' flight software framework \cite{bocchino2018fprime}.}}}
\label{fig:architecture:architecture}
\end{figure}



\subsection{Leader Election}

A leader election module ensures that every agent in the team agrees on the designation of a single agent as leader at any given time. A distributed minimum spanning tree algorithm, GHS \cite{gallager1983distributed}, is used to select a unique appointer among the agents every ten seconds; the appointer then selects as leader the agent whose state is farthest from violating thermal and power constraints, and broadcasts the leader designation to all agents. A hysteresis mechanism is used to ensure that the leader is not changed unless large changes in its state are observed. The leader election module also \revI{periodically} chooses a ``designated survivor'', an agent tasked with holding a copy of the leader's information, making recovery from loss of a leader faster. \revI{The architecture ensures that loss of the leader results in at most ten seconds of idle time before planning recommences on a new leader}. We refer the reader to \cite{AlbeeBhamidipatiEa2024} for a detailed description of the leader election approach and implementation. 


\subsection{Shared State Database}

A shared state database (SSDB) allows agents to synchronize key state information periodically. The shared state database is based on SQLite, and synchronization is implemented through a custom application layer. The implementation deliberately does not guarantee consistency between the agents in the sense of the CAP theorem \cite{gilbert2002brewer} (i.e., different agents' databases may contain different information at any given time), prioritizing availability over consistency and providing robustness to network partitions. Critically, due to the elected-leader architecture, such lack of consistency will \emph{not} result in uncoordinated action among the agents, although it may result in suboptimal behavior if the leader has stale information. State information that (i) is required for strategic planning and (ii) cannot be inferred locally is synchronized by all agents to the leader \revI{and the designated survivor} periodically, every 10 seconds. \revI{All information required for planning is stored on at least two agents, ensuring robustness to loss of a single agent; information is only lost if both the leader and the designated survivor fail before a new leader and survivor can be elected (which happens within 10s), and before information can be synchronized to them}.  We refer the reader to \cite{SaboiaRossiEa2024} for a detailed description of CADRE's SSDB.

\subsection{Centralized planning}
\label{sec:architecture:planner}

A strategic planning module runs on the leader and plans and schedules tasks for all agents.
The planner module continually evaluates the plan at a set cadence (currently, 1Hz) to evaluate re-planning triggers, commit new tasks, delete old tasks, and check multi-agent constraints. Triggers for re-planning include conflict detection, task failure, as well as at specific milestones in the experiment (e.g., when an exploration or distributed measurement task is completed). When a task's scheduled start time falls within a certain window (currently set to 5 seconds), that task is handed off, or \emph{committed}, to the relevant agent controller, described next. 
\revI{Since the planner has visibility into the state of all agents, planning of tasks that require cooperation between multiple agents is straightforward. Enforcement of coordination during decentralized execution is more complex, and is discussed next in Section \ref{sec:architecture:abort}.}
The planner reasons explicitly about agent availability, which is communicated to it directly from the agent controller modules, in order to avoid scheduling and committing tasks for an agent that is not actively running a controller module. The strategic planner and agent controller modules for CADRE are implemented using Multi-mission EXECutive (MEXEC)~\cite{troesch_mexec_asteria_intex2020}, a resource-aware onboard planning and execution software that uses task networks to generate and execute conflict-free schedules. 
In task networks, tasks are represented as a tuple containing a flight software (FSW) command to execute the task; an expected duration; a set of constraints; and a set of expected impacts.
Constraints include both state constraints, which require that system states remain between prescribed maximum and minimum values; and precedence constraints, where one task must be completed before another can be started. State constraints include both pre-execution constraints that must be satisfied before a task can be started, and maintenance constraints that must be satisfied throughout execution.
Impacts represent the expected change in state from executing the given task (e.g., the expected power draw from driving). During planning, a task's impacts are used to predict the future evolution of the system state; constraints for subsequently-scheduled tasks are then verified against these predicted values. We refer the reader to \cite{troesch_iwpss2019_robustmapping,troesch_mexec_asteria_intex2020} for a detailed description of the task network representation. A priority-based insertion heuristic is used for planning, as detailed in Section \ref{sec:tasknets:encoding:algorithm}. %

\subsection{Decentralized execution}
\label{sec:architecture:controller}

Each agent runs an agent controller module, which is responsible for managing task execution. \gobble{With the exception of the instance running on the leader agent, each} Each agent controller is only able to observe its own agent's state. The agent controller checks task constraints before and during execution; it has the authority to delay the start of a task if any of its starting constraints is unmet, and also to declare a task as ``failed'' if any of its constraints is violated during the course of execution. In the latter case, the controller issues cleanup commands needed to keep the agent in a recoverable state. The agent controller reports the execution state of all tasks under its authority back to the strategic planner \revI{on the leader}, which uses this information \revI{to trigger} re-scheduling. %

\subsection{Multi-agent constraint checking}
\label{sec:architecture:abort}
Inter-agent coordination of tasks is maintained during execution through the \revI{enforcement} of multi-agent constraints, \revI{performed on the leader}. The information available to individual agents is limited to the state of that agent, with the exception of the leader. As such, each agent does not have the necessary information to evaluate all task constraints for tasks \revI{requiring coordination among multiple agents, where a constraint violation on another agent's state may trigger a stop}. Constraints that cannot be evaluated on \revI{individual} agents due to lack of information are referred to as ``multi-agent constraints''. These constraints are evaluated on the leader. %
Similar to regular constraints, multi-agent constraints include both pre-execution constraints and maintenance constraints. \revI{For multi-agent constraints}, however, a pre-execution constraint cannot \revI{directly} delay the start of a task, since the \revI{leader} is not controlling the task. Instead, the \revI{leader} does a one-time check to verify that the constraint was satisfied within a short time after the task start time. Maintenance constraints are 
continuously checked throughout the execution of a task.
For any constraint found to be violated, an ``abort task'' message is sent from the leader to the agent executing the corresponding task. On receiving the ``abort task'' message, the agent's controller fails the task, causing the leader to replan.


\subsection{Integration with leader election}

Only the leader agent performs planning and scheduling. However, the leader may change at any time. For this reason, an instance of the strategic planner module \revI{exists} on every agent; on the leader, the strategic planner is in an active state and schedules and commit tasks, whereas on the non-leader agents the strategic planner module is in an inactive state. To achieve an orderly transition from one leader to the next, (i) only one strategic planner may be actively scheduling and committing tasks at a given moment, and (ii) 
when a new leader is elected, no agent controller may be actively commanding or tracking tasks that were scheduled and committed by a previous leader.

To accomplish (i), the strategic planner \gobble{module} listens to leader election updates and also to acknowledgement messages from each agent controller\gobble{ module}. When an active strategic planner receives an update from leader election indicating that its agent is no longer the leader, it commits no new tasks and immediately transitions to the inactive state. When an inactive strategic planner receives an update indicating that its agent is now the leader, it waits for acknowledgement messages from each participating agent controller, and only transitions to the active state once all agents have acknowledged that it is leader and that they are ready to accept tasks.

To accomplish (ii), the agent controller modules also listen to leader election updates. As soon as an agent controller receives an update from leader election indicating that the leader has changed, it \ purges the set of tasks that are under its authority. Any task that has not yet been commanded is immediately dropped. Cleanup commands are issued for any task that has them, and then the controller waits for all \gobble{of the} running tasks \gobble{that it is tracking} to complete. Only once all tasks under its authority are complete does the agent controller send acknowledgement to the strategic planner on the new leader that it is ready to receive tasks from it.

This approach\gobble{ serves to minimize state that is persisted when the leader changes, and} allows the system to be resilient to unexpected loss of a leader, as the new leader does not rely on information shared from the previous one. 


\subsection{Remarks on inter-agent communication}

We note that the \pse architecture design assumes that a low-bandwidth, potentially high-latency, bidirectional communication channel is continuously available between agents and the elected leader. If the communication channel between agents may drop arbitrary packets (and potentially all packets), no coordination can be achieved in general --- a problem known as the \emph{coordinated attack} problem \cite{Gray1978}. %
We strive to minimize the amount of information sent over links to maximize the likelihood of such information successfully being exchanged, and we design the system to be robust to latency in message delivery. %
\revI{Specifically,} if state information from an agent does not propagate to the leader in a timely manner, the leader's plan will rely on stale information from that agent, which results in \gobble{sub-optimal and} potentially infeasible plans; however, if the resulting plan indeed violates the agent's constraints, the agent controller will refuse to execute the task based on its local information, ensuring safety.
Similarly, if a committed task fails to propagate in a timely manner from the leader to the agent that should execute it, the agent will re-evaluate whether the task remains feasible upon receiving it; if the task is still feasible, it will execute it anyway, and if it is no longer feasible, it will declare it as failed.

For tasks that rely on coordination between agents, task failure on one agent requires stopping all other agents and re-planning; this is accomplished by communicating the task failure from that agent to the leader, triggering a multi-agent constraint failure, which in turn causes the leader to send ``abort'' messages to other affected agents. If such messages are delayed, agents may act in an uncoordinated manner for some time. We acknowledge this as a limitation of the proposed approach, and conjecture that it may be a fundamental limitation in presence of communication latency; to minimize the likelihood of occurrence, we reduce the size of ``abort'' messages to a single task ID, in order to empirically maximize the likelihood of timely delivery even on a disrupted communication link. 


\section{Planning CADRE's mission}
\label{sec:tasknets}



\subsection{Concept of Operations}
\label{sec:conops}



CADRE will perform two experiments to demonstrate multi-agent autonomy: exploration and distributed sensing with multi-static radar.
An FPGA, not controlled by autonomy, controls a timer that shuts down all agents at 25 and 55 minutes past the hour, and restarts them 0 and 60 minutes past the hour  \cite{DeLaCroixRossiEa2024}. Within each 25-minute cycle, the team must make progress towards the active experiment as follows.

\subsubsection{Exploration}



During the exploration experiment, ground operators uplink the boundary of a region to explore\gobble{ (represented as a polygon)} to the team. The content of the region is initially unknown to the agents. The goal of the experiment is for the agents to collectively observe every portion of the region that is reachable from their initial locations with on-board stereo cameras; and to classify every reachable portion of the region as ``traversable'' or ``obstacle''. To do this, the CADRE team partitions unknown portions of the region into as many sub-regions as there are rovers, and assigns each sub-region to a rover; each rover then explores its own sub-region using frontier-based exploration \cite{yamauchi1997frontier}, as shown in Figure \ref{fig:conops:exploration}. Maps are periodically synchronized to the leader, which merges them in a joint map, and sub-regions are periodically re-computed as the unknown portions of the map shrink.
We refer the reader to \cite{nayak2024exploration} for a detailed description of the exploration architecture.

\begin{figure}[h]
\includegraphics[width=.42\columnwidth]{ea_viz_agent2_1727215721_crop.png}
\includegraphics[width=.42\columnwidth]{ea_viz_agent3_1727215964_crop.png}
\vspace{-.75em}
\caption{Exploration: two rovers (magenta dots) explore the sub-region assigned to them (lighter rectangle) by selecting a frontier (\gobble{denoted by the }colorful segments) between traversable (off-white) and unexplored (light gray) portions of the sub-region.}
\label{fig:conops:exploration}
\vspace{-1em}
\end{figure}

\subsubsection{Distributed Sensing}


During the distributed sensing experiment, rovers are tasked with driving in formation between assigned waypoints while collecting multi-static ground-penetrating radar readings. Ground operators specify a waypoint to reach as a team, typically tens of meters away from the rovers' initial location; a formation to maintain, specified as a set of inter-rover distances; and a maximum allowable deviation from the prescribed formation that will, if not violated, ensure sufficient quality of the radar data. Agents must plan a set of trajectories that will reach the prescribed waypoint while staying in formation. The map of the region where the experiment is performed may be partially unknown to the rovers (that is, the distributed sensing experiment may stray outside the exploration region area). Thus, the rovers are likely to encounter initially-unknown obstacles that require replanning. Team-level planning is performed by the leader through sampling-based motion planning \cite{karaman2011sampling} on the rovers' joint state space; individual rovers are then assigned time-stamped corridors around the computed team trajectory (shown in Figure \ref{fig:conops:formation}). If every rover remains within its own time-stamped corridor, the maximum allowable deviation between rover distances is guaranteed not to be violated. If a rover is unable to remain within the allocated corridor, all other rovers must stop; the leader then computes a new collision-free team trajectory.

\begin{figure}[h]
\includegraphics[width=.67\columnwidth]{formation_driving.png}
\vspace{-.75em}
\caption{Distributed sensing\gobble{ plans a joint in-formation trajectory for all rovers}: each rover is assigned a ``tube'' around its nominal trajectory, and must travel inside the tube while satisfying temporal constraints.}
\label{fig:conops:formation}
\end{figure}






\subsection{Task Network Encoding}
\label{sec:tasknets:encoding}


\subsubsection{Tasks} To encode the exploration and distributed sensing behaviors, we build upon single-agent localization, mapping, and mobility tasks to create higher-level behaviors that allow the system to operated autonomously as a whole. PS\&E's  \gobble{key} role is to \gobble{track and }manage the interaction between these tasks, and their system-level impacts (e.g., their power consumption and impact on rover temperature). To accomplish this, we model a set of abstract tasks sufficient to predict system impacts and constrain agent behavior to safe and desirable actions.\gobble{ The strategic planner uses these abstract tasks to schedule as much activity as possible within these constraints.}

Specifically, the tasks considered in \pse are: 
\begin{itemize}
    \item \emph{SSDB map synchronization}: every \revI{rover} copies its new maps and pose to the leader; this task must be executed prior to exploration and formation navigation planning to ensure that the leader has access to up-to-date maps from all rovers;
    \item \emph{SSDB backup}: the designated survivor maintains a backup of \revI{all agents'} SSDB to \revI{insure against data loss and} enable efficient leader reelection\gobble{, if necessary}; %
    \item \emph{exploration navigation planning}: the region to explore is divided in as many subregions as there are rovers; the task is executed on the leader during the exploration experiment;
    \item \emph{driving to explore}: each rover is tasked to explore its sub-region via frontier-based exploration; the task is executed on \revI{each} participating rover during the exploration experiment;
    \item \emph{formation navigation planning}: a set of trajectory ``tubes'' is computed \revI{for the participating rovers}; the task is executed on the leader during the distributed sensing experiment; 
    \item \emph{driving in formation}: each rover is tasked with following the tube around its trajectory; the task is executed on \revI{participating} rovers during the distributed sensing experiment;
    \item \emph{stopping a drive early}:  while driving tasks stop on their own when \revI{they reach their destination}, this task is used to \gobble{explicitly} stop early when time or resource constraints are close to violation;
    \item \emph{shutting down the agent software and electronics}: if time and resources continue to be insufficient, the task puts the agent in a low power mode.
\end{itemize}


Figure \ref{fig:tasknet-formation-sensing} shows the set of tasks considered for the formation driving experiment, and selected inter-task constraints.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{tasknet.png}
    \vspace{-.5em}
  \caption{Abstract representation of the task network for both formation sensing and exploration. Arrows represent precedence constraints\gobble{; one task can only be scheduled if the preceding task has been successfully scheduled}. Resource and multi-agent constraints are not shown.}
    \label{fig:tasknet-formation-sensing}
\end{figure}



Each task (and in particular driving) involves a complex set of individual behaviors, which are modeled with a combined sets of constraints and impacts.
The energy consumed and heat produced by the CPU during image processing, for example, is rolled up with the power and heat from driving motors. 
Closed-loop replanning is used to correct for inaccuracies in the impact models. Constraints are used for both ensuring the proper task ordering as well as preventing over-subscription of system resources.








\subsubsection{Resources} The three modeled system resources are:
\begin{itemize}
    \item time: tasks must be performed within the maximum allotted 25 minute interval;
    \item battery state-of-charge (SOC): \revI{rover} batteries are recharged by solar arrays, but drained while performing tasks; \revI{the base station is powered by the lander, and has no battery};
    \item CPU temperature: operating for long durations close to Lunar noon can exceed the maximum operating temperature.
\end{itemize}

The strategic planner must anticipate the FPGA-commanded shutdown at 25 and 55 minutes past the hour; stop driving; and put the agent in a low-power mode before this timer expires. This allows logs and other data to be saved before power off. In addition, the battery SOC must be maintained about a minimum \revI{threshold} (e.g. 20\%). Simulation and analysis has shown that, during periods with the sun high overhead, stopping the drive and other tasks is sufficient to allow the solar panels to recharge the batteries. At other times, the agents must be put into a low-power mode through the shutdown task.
Temperature, however, limits agent operations at exactly the opposite periods of the lunar day. When the sun is low in the sky, lunar temperatures are low enough that there is no risk of overheating the CPU\gobble{, even at full operation}. But around lunar noon, the rovers can only drive for a few minutes before the CPU temperature exceeds its operational limit of 65$^\circ$ C. \gobble{In addition to resources, several logical states of the rover are tracked to ensure that tasks are scheduled only for those rovers that are participating in team activities, awake, and ready to perform those activities; these states are discussed next in Section \ref{sec:tasknets:multiagent}.} %

\subsubsection{Resource Models} Both battery SOC and temperature are measured through onboard sensors; whenever replanning is performed, predicted impact for future tasks are applied starting from this current state. Because of this, and the comparatively short planning horizon, impacts use simple models of resource change. 

For battery SOC, we use a roll-up of the power loads from all behaviors started by the task. Using this, and the battery capacity, we get a \gobble{simple,} linear prediction of the battery SOC. For heating discharge, and re-charging provided by the solar arrays, we use a coarse estimate based on the lunar time-of-day. The power required by heaters impacts a background discharging rate, which is reduced during power-consuming tasks to account for supplemental heating from power loads of that task (assuming that a uniform 80\% of the load will be dissipated as usable heat). Degradation in solar array performance due to rover tilt is omitted for simplicity.

Temperature proved more difficult to model.
The impact of tasks on rover temperature depends in a nonlinear way on the vehicle's starting temperature, the ambient temperature, rover tilt, and the power loads being applied. Simulations were performed at solar angles between $20^\circ$ and $90^\circ$ with $10^\circ$ steps; each simulation cycled through the different rover operating modes (i.e., the set of tasks being executed) multiple times. These simulations helped identify which factors have the largest effect on temperature rate-of-change. Sun angle and rover operating mode were identified as the two key factors affecting temperature rate of change. We also identified the CPU temperature as the most constrained temperature resource in all simulations; accordingly, we only model CPU temperature in planning, effectively treating each rover as a one-node thermal model. %
Surprisingly, we found that the CPU temperature at the start of an operating mode had a minimal impact on the heating rate; therefore, we omitted it from the planning model.
We did observe that the rate of change of temperature was markedly nonlinear, with an initial steep change that leveled off after about two minutes --- in line with the expected physical behavior of heat conduction and radiation.
The existing task model in MEXEC, however, only supports linear rates. We considered implementing a more accurate model that divides tasks into multiple parts to better capture this behavior. However, simulations and analysis showed that the added complexity would provide a relatively small benefit compared to more frequent replanning; accordingly, a linear model was used.

\subsubsection{Planning and Scheduling Algorithm} %
\label{sec:tasknets:encoding:algorithm}
When the system replans, it always has one of two goals, namely, to continue exploring or performing distributed measurements. The tasks performed during the previous wake cycle are not explicitly part of the state considered for planning: their impacts are fully captured by the rovers' maps for exploration, and the rovers' locations for distributed measurement. 
This allows us to use one simple scheduling process, regardless of when and why the system performs re-scheduling:
\begin{itemize}
    \item un-schedule any task not committed for execution;
    \item read and apply the current system state;
    \item \revI{greedily} schedule un-executed tasks in priority order, \revI{scheduling each task as close as possible to its preferred start time while ensuring constraint satisfaction, and} rejecting any task that cannot be scheduled without constraint violations.
\end{itemize}

\revI{Pseudocode for the planning algorithm is reported in \ifextendedversion Appendix \ref{apx:simpleplanner}. \else the Extended Version \cite{RabideauRussinoEaAAMAS24EV}. \fi}
The choice of this simple scheduling process has implications on how the task network is defined. First, priority order scheduling meant that we cannot assume that lower priority tasks will exist when a higher priority task is scheduled. Second, because no additional tasks are created during planning, the  task network must contain all of the tasks we will ever need. For example, because driving requires a team plan to be generated, the team planning task must be higher priority, while the driving task must be constrained to prevent scheduling if a team planning task does not exist. Moreover, because multiple driving cycles could be scheduled, the task network includes multiple instances of all tasks. But a second instance of driving should not be scheduled if one already exists, unless that first drive was stopped or completed. Constraints were used to ensure proper task ordering and allow multiple exploration and distributed measurement cycles.



\subsection{Multi-agent Task Networks}
\label{sec:tasknets:multiagent}



For tasks that must be executed on all three rovers (e.g. map synchronization and driving), a separate task instance is created for each rover; constraints for that task are tied to the specific rover's state.
The state representation is identical for all rovers. Since the base station has no battery and doesn't drive, its state representation does not include battery SOC, and no driving tasks are created for it. The task network references a leader ID for tasks that must be executed on the leader (namely, team planning); but it does not have explicit knowledge of which agent is \gobble{currently} assigned as the leader.

For exploration, driving tasks for the participating rovers are independent of each other. If one rover is unable to drive for any reason, this does not impact the ability to schedule and execute driving for the other rovers. The distributed measurement experiment, however, requires coordinating tasks across all participating rovers. To achieve this, task hierarchy was used, a construct where a parent task decomposes into subtasks assigned to different rovers. The parent task is defined with the constraints and impacts of all subtasks, to ensure that the parent is scheduled at a time that is valid for all rovers. Then, the subtasks are constrained to be scheduled at the exact start and end of the parent. A multi-agent constraint is used to enforce continuous coordination of the tasks during execution. At the start of a formation drive, the parent task changes an internal state to ``coordinated'', while each subtask requires this state to be ``coordinated''. During execution, if one of the rover drives fails, it changes the state to ``not coordinated''. This creates a multi-agent constraint conflict that triggers an abort of the drive tasks on the other rovers, as described in Section \ref{sec:architecture:abort}.

\paragraph{Managing agent participation} The CADRE concept of operations allows operators to manually designate which agents participate in a given experiment. By default, all agents are included; however, ground operators can exclude one or more agents in case of failures, or to support anomaly investigations. The task networks support these alternate configurations using task constraints that require the state of the assigned agent to report it as ``participating''. For exploration, because tasks execute independently, the participation constraint is implemented similar to any other constraint. For formation sensing, however, driving is only scheduled if the tasks for all \emph{participating} rovers can be scheduled. We implement this by creating alternate hierarchies, one for each of the possible subsets of the three rovers. Parents with larger subsets are assigned higher priorities, so that they will be tried first. A subset that contains a subtask for a non-participating rover will fail that constraint, causing the full subset to fail. However, if a subtask for a rover fails to schedule for any other reason, we do not want to schedule a formation drive using the remaining rovers. Instead, we want to wait for all participating rovers to be ready to drive. This means that, for example, the subset for driving with only Rover 2 and Rover 3 includes a constraint that requires Rover 1 to be non-participating.

\subsection{Pytasknet}



CADRE's declarative task model was created using a Python library called Pytasknet. This library includes the basic classes and functions for creating tasks, and greatly simplified the effort of creating CADRE's task networks. The Python objects and references abstract away many of the details of creating references in MEXEC's XML task network representation. Moreover, the Python language provides the full power of a procedural language to create these task networks. For CADRE operations, where many tasks are identical except for the designated rover, the ability to create tasks within functions and loops was essential. \iftasknetworks \revI{A full representation of CADRE's task networks is reported \ifextendedversion in Appendix \ref{apx:tasknets}.\else in the Extended Version \cite{RabideauRussinoEaAAMAS24EV}.\fi}\fi %





\section{Experimental results and V\&V}
\label{sec:testing}







Throughout the development and V\&V process, the \pse subsystem for CADRE was tested over multiple venues at increasing levels of fidelity, as shown in Table \ref{tab:testing-levels}.

\begin{table}[h]
\caption{Testing venues used for validation of CADRE \pse}
\label{tab:testing-levels}
\vspace{-0.5em}
{\small
\begin{tabular}{c|ccccccccc}  
& \rotatebox{90}{Scheduling} &
 \rotatebox{90}{Nominal exec.} &
 \rotatebox{90}{Off-nominal exec.} &
 \rotatebox{90}{FSW integration} &
 \rotatebox{90}{Actual driving} &
 \rotatebox{90}{Outdoor driving} &
 \rotatebox{90}{Full sensor suite} &
 \rotatebox{90}{Specialized HW} &
 \rotatebox{90}{Flight HW} \\
 \hline
Batch planning & \checkmark & & & & & & & & \\
ROS sim & \checkmark& \checkmark & \checkmark & & & & & &\\
Dragonfarm & \checkmark & \checkmark & \checkmark & \checkmark & & & & \checkmark &\\
Dev. Models & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & & \checkmark &\\
Flight Models              & \checkmark & \checkmark & \checkmark  & \checkmark & \checkmark &  & \checkmark & \checkmark  & \checkmark \\
 \hline
\end{tabular}
}
\end{table}


Initial evaluation of the task networks and the scheduling implementation were performed using MEXEC batch planning, a one-shot process that produces a schedule based on a task network and a set of initial state values. To test the interplay between planning and execution, we conducted simulations first in a ROS-based \cite{quigley2009ros} simulator, with stand-ins for all system behaviors that have an impact on the planned tasks and the states they interact with. \revI{The simulator emulates task execution by idling for an appropriate duration, then returning the same fault/success codes used by FSW, and updating states based on the tasks' impact models. Individual tasks can return early, return late, or report failure, based on operator input.} For the ROS testing campaign, we developed a test matrix, Table \ref{table:1}, that crossed all of the tasks with all of the possible execution behaviors of a task. Each execution behavior (e.g. starting late, failing) can have a different impact on the re-planning and execution of subsequent tasks. In each relevant case, we verified that the proper response was taken by both the Agent Controller and the Strategic Planner. The ability to quickly and easily perform these tests was key to the development of the task network, and allowed us to identify multiple bugs where a task definition \gobble{worked for scheduling but }exhibited undesirable behavior during execution or re-scheduling\gobble{, when the state was different from the predicted state}. %

\begin{table}[h]
\centering
\caption{Testing campaign with ROS simulations. \gobble{SS = SSDB sync, TP = Team Planning, FS = Formation Sensing, EX = Exploration, ST = Stop, SL = Sleep. Some low priority tests are still pending.} As the first task to be scheduled, SSDB sync is not impacted by previous tasks and not expected to start late. Similarly, the stop and sleep tasks are not expected to have variable duration or fail. }
\label{table:1}
{\small
\begin{tabular}{c | c  c  c c  c } 
 Task & Nominal & Starts late & Runs late & Ends early & Fails \\ [0.5ex] 
 \hline%
 SSDB Sync & \checkmark &  & \checkmark & \checkmark & \checkmark \\ 
Team Planning & \checkmark &  & \checkmark & \checkmark & \checkmark \\
Formation & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
 Exploration & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
 Stop & \checkmark & \checkmark &  &  &  \\
 Sleep & \checkmark & \checkmark &  &  &  \\ [1ex] 
 \hline
\end{tabular}
}

\end{table}

Higher-fidelity simulations were then run on the \emph{Dragonfarm} testbed, which consists of a set of the same ModalAI VOXL system-on-a-chip modules used on the rovers, connected via Ethernet to provide a platform that can execute the full CADRE flight software deployment \revI{(which uses the F' framework \cite{bocchino2018fprime})}, with the same computing \gobble{(but not networking or mobility)} resources as flight hardware. In this context, we were able to perform extensive end-to-end simulation of both the exploration and formation sensing experiments with a variety of leader and participant configurations and initial state conditions.


Extensive testing was also carried out on mobility platforms -- specifically, Development Models (DM) and Flight Models (FM), shown in Figure \ref{fig:dms-and-fms}. The FMs are the hardware that will fly to Reiner Gamma; the DMs are reduced-fidelity hardware that present the same computing and actuation as the FMs, but a reduced sensor suite, and are suitable for outdoor testing on Earth. 

\begin{figure}[h]
\centering
\includegraphics[width=.50\columnwidth]{cadre_my_testing.jpg}
\includegraphics[width=.475\columnwidth]{cleanroom_cadre.jpg}
\vspace{-1em}
\caption{CADRE's development models (DMs) in the Mars Yard (left) and flight models (FMs) in the cleanroom (right).}
\label{fig:dms-and-fms}
\end{figure}

This multi-venue approach offered a comprehensive view of system performance. 
Testing on the FM rovers, despite their stringent operational constraints (e.g., being confined to the cleanroom environment, and subjected to rigorous safe handling guidelines), provided critical insights. The FM units were equipped with temperature and state-of-charge sensors \gobble{that are }not available on DMs, providing a complete picture of system performance and yielding high-fidelity data for testing the PS\&E system under flight-like conditions. In contrast, the DM rovers were not restricted to cleanroom conditions and were driven extensively in the Mars Yard outdoor testing venue, %
 which offered more freedom and terrain realism and allowed testing interactions with the Guidance, Navigation, and Control (GNC) subsystem. Balancing the strengths of both DM and FM testing was essential in ensuring that the autonomy system could handle both realistic driving tasks, and noisy sensor measurements.

Key tests on the DM hardware focused on running exploration and formation sensing experiments with flight-like wake-sleep cycles\gobble{, exercising as much of the stack as possible}. In these tests, the rovers autonomously woke up in autonomy mode, configured their sensors and components, and loaded the experiment task network into the strategic planner. The \pse stack handled all task planning, monitored task constraints during execution, and replanned as needed --- adjusting durations or replanning tasks without operator assistance or intervention.

Exploration testing was conducted across regions ranging from 6x6m to 22x13m. For distributed sensing, goal situated 6m to 20m from the agents' initial locations were tested. We verified that GNC could trigger replanning when the formation trajectory \revI{tube} couldn‚Äôt be followed, and that multi-agent constraint checking performed as expecting by stopping all agents in response. %
We also verified the ability to store and access state information across wake-sleep cycles, and demonstrated the ability to change the elected leader during different stages of the experiments. Testing under varying terrain configurations --- from sparse to cluttered rock and crater fields, and under the harsh shadows of night-time testing --- further validated the system‚Äôs robustness.

Key testing on the FM hardware involved Autonomy Day-in-the-Life experiments, where the stationary FM rovers performed tests under FPGA-driven wake/sleep operations. These tests ran with continuous cycles for over 9 hours, transitioning between autonomy, nominal, and safe modes. With real (albeit cleanroom-based) thermal measurements and battery state-of-charge calculations, we verified the planner's ability to generate appropriate plans based on thermal and power constraints. The system responded by either gracefully stopping experiments if constraints were violated, or changing task durations when limits were approaching. Additionally, the tests validated correct responses to off-nominal cases, such as sudden drops in battery state or temperature spikes, as well as agents entering safe mode. The tests also confirmed successful planning and state synchronization across all four agents, unlike the DM hardware, which only sports three agents.
Overall, not only did this testing campaign give us confidence that the distributed planning, scheduling, and execution system can perform under the scenarios required by the CADRE mission, but also gave us key insights into how to operate autonomous and multi agent spacecraft.



\section{Conclusion}
\label{sec:conclusion}

In this paper, we describe the planning, scheduling, and execution architecture for CADRE, a NASA mission that will demonstrate multi-agent autonomy on the Moon in \revI{2025/2026}. Testing of the autonomy stack also provided unique insight into verification and validation of autonomy, and operations of multi-agent systems. Successful completion of CADRE's mission will demonstrate the high technology readiness of multi-agent planning, scheduling, and execution in challenging planetary surface environments (in particular, on the Moon), enabling infusion in future science-driven planetary exploration missions.  









\begin{acks}
This research was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration (80NM0018D0004).
\end{acks}
\newpage

\bibliographystyle{ACM-Reference-Format} 
\bibliography{bibliography}
\balance

\ifextendedversion
\newpage
\onecolumn
\begin{appendix}

\section{Scheduling Algorithm}\label{apx:simpleplanner}

\begin{algorithm}[H]
\caption{MEXEC\_PLAN\_SEARCH\_DECOMP\_PRIORITY}\label{alg:decomp}
\begin{algorithmic}
    \For{the maximum number of tasks in the network}
        \For{the maximum number of scheduling iterations}
            \State consider next unscheduled task with a preferred start time in the scheduling window
            \If {there is a valid interval in which to schedule the task}
                \State schedule the task as close to its preferred start time in the valid interval
                \If {task has a detail command}
                    \State dispatch detail command
                \EndIf
                \If {task has a decomposition}
                    \State create subtasks from templates and add them to the unscheduled tasks list
                \EndIf
            \EndIf
        \EndFor
        \If {no tasks were scheduled}
            \State break
        \EndIf
    \EndFor
\end{algorithmic}
\end{algorithm}

\iftasknetworks
\section{Task networks}\label{apx:tasknets}
\subsection{Exploration}

\subsubsection{Task network}
{\scriptsize
\inputminted{python}{code/strategic-planner/tasknets/gen_explore_tasknet.py}
}

\subsubsection{Tasks}

{\scriptsize
\inputminted{python}{code/strategic-planner/tasknets/etp.py}
}

\subsection{Distributed Measurement}
\subsubsection{Task network}
{\scriptsize
\inputminted{python}{code/strategic-planner/tasknets/gen_formation_sense_tasknet.py}
}

\subsection{Common Tasks}
\subsubsection{Sleep task}
{\scriptsize
\inputminted{python}{code/strategic-planner/tasknets/sleep.py}
}
\subsubsection{Shared state DB synchronization task}

{\scriptsize
\inputminted{python}{code/strategic-planner/tasknets/ssdb.py}
}

\subsubsection{Stop task}
{\scriptsize
\inputminted{python}{code/strategic-planner/tasknets/stop.py}
}

\fi

\end{appendix}
\fi


\end{document}
