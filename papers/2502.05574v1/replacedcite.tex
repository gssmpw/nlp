\section{Related Work}
~\label{sec:Related Work} 


% In this section, we will review the most relevant research topics related to our paper, including Event Camera based Tracking, Knowledge Distillation, and Test-Time Tuning. More related works can be found in surveys____.


\subsection{Event Camera based Tracking}  \label{subsec:eventtracking}
With the development of bio-inspired event cameras, event camera based visual object tracking has gradually become a focus of attention. The early event camera based tracking algorithm ESVM____ proposed an event-guided support vector machine (ESVM) for tracking high-speed moving objects, which solves the tracking problem caused by motion blur and large displacement in low frame rate cameras. Recently, Chen et al.____ adopt the Adaptive Time Surface with Linear Time Decay (ATSLTD) algorithm for event-to-frame conversion, the spatiotemporal information of asynchronous retinal events is transformed into an ATSLTD frame sequence for efficient object tracking. Zhu et al.____ propose a new end-to-end learning framework for object tracking based on event cameras, which improves tracking accuracy and speed through key event sampling and graph network embedding. Zhang et al.____ propose a novel tracking network STNet based on a spiking neural network and Transformer network, which can effectively extract spatiotemporal information from events and achieve a better tracking performance. Wang et al.____ propose a novel hierarchical knowledge distillation framework, combined with multi-modal/multi-view information, high-speed and low latency visual tracking can be achieved during the testing phase using only event signals. 


For event based multi-modal tracking, Zhang et al.____ propose a multi-modal fusion method that combines visual cues from frame and event domains to improve single object tracking performance under degraded conditions, which also enhances the effect through cross-domain attention mechanism and adaptive weighting scheme. 
VisEvent____ proposed by Wang et al. transforms the event stream into images and extends a single-modal tracker to a dual-modal version, with a cross-modal converter enabling better fusion of RGB and event data. 
AFNet____, proposed by Zhang et al., a framework for high frame rate tracking, event alignment, and fusion network has been proposed, which significantly improves the performance of high frame rate tracking by combining the advantages of traditional frameworks and event cameras.  
Gehrig et al.____ propose EKLT, an asynchronous photometric feature tracking method that combines the advantages of event cameras and RGB cameras to achieve visual feature tracking at high temporal resolution and improve tracking accuracy. 
% Tang et al.____ propose a single-stage network architecture CEUTrack for unified tracking of color frames and event camera, which simultaneously implements functions such as feature extraction, feature fusion, matching, and interactive learning by visual Transformer networks. The prompt learning strategy is adopted in 
ViPT____, which adjusts the pre-trained RGB base model by introducing a small number of trainable parameters to adapt the different multi-modal tracking tasks. 
% Zhu et al.____ propose a novel misaligned tracking method that extracts template and search regions from RGB and event data, respectively. Subsequently, uncertainty-aware modules are proposed to encode RGB and event features, and a modal uncertainty fusion module is further proposed to integrate these two modalities. 
% Wu et al.____ propose UnTrack, which is a single model unified tracker that can handle any modal data (including event data), maintain performance in any missing modality through shared representations, and does not require modality-specific fine-tuning. 
%%
Different from existing works, we propose to conduct a hierarchical knowledge distillation strategy from multi-modal or multi-view in the training phase and only utilize the event data for efficient and low-latency tracking. 




\subsection{Knowledge Distillation}  \label{subsec:kd}
The knowledge distillation strategy has been widely proven to be an effective method of knowledge transfer.
%%
Deng et al.____ propose an image-based knowledge distillation learning framework that improves the performance of event camera models in feature extraction by extracting knowledge from the image domain, achieving significant improvements in the performance of event cameras in target classification and optical flow prediction tasks. 
%%%
In visual object tracking, Shen et al.____ propose a distillation learning method for learning small, fast, and accurate Siamese network trackers. 
Chen et al.____ propose a lightweight network based on the teacher-student knowledge distillation framework to accelerate visual trackers based on correlation filters while maintaining tracking performance.
Zhuang et al.____ propose an ensemble learning method based on Siamese architecture, which effectively improves the accuracy of visual tracking tasks and solves the limitations of knowledge distillation in visual tracking tasks.
Sun et al.____ distill the pre-trained RGB modality onto the TIR modality on unlabeled RGB-TIR datasets, utilize the two branches of the network to process data from different modalities to transfer cross-modal knowledge. 
Wang et al.____ propose a knowledge distillation framework that combines model compression and transfer. 
Zhao et al.____ propose a tracking method based on a Siamese network, which optimizes the balance between tracking efficiency and model complexity through distillation, integration, and framework selection, achieving better tracking performance and speed. 
Ge et al.____ propose a novel framework called ``channel distillation", which optimizes the performance of depth trackers by adaptively selecting information feature channels, achieving accurate, fast, and low memory required visual tracking. 
Cui et al.____ introduce special prediction tokens and distillation model compression methods in MixFormerV2, which significantly improved efficiency while ensuring accuracy. 
Different from these works, in this paper, we propose a framework for knowledge distillation from multi-modal or multi-view to unimodal, which achieves efficient visual object tracking through hierarchical knowledge distillation. 



\subsection{Test-Time Tuning} \label{subsec:ttt} 
The idea of Test Time Tuning is to use self-supervised learning to continue training the model on test sets. 
%%%
% In the 1990s, Bottou et al.____ introduced the pioneering concept of Local Learning, a methodology that emphasizes training on neighboring data points before making predictive inferences. This work stands as a seminal paper, marking the first instance where locality is articulated as a foundational principle in machine learning.
% Building on this idea, Vladimir Vapnik____ emphasizes the principle of "Try to get the answer that you really need but not a more general one." He advocates for the utilization of test data to impose additional constraints upon the decision boundary, thereby enhancing the model's ability to generalize effectively while remaining focused on its immediate task.
TTT____ proposed by Yu et al., introduces a Test Time Tuning method that improves the performance of prediction models under data distribution shift through self-supervised learning.
%%%
In the field of computer vision, Test Time Tuning has also been proven to be an effective strategy in many tasks____. 
% Liu et al.____ introduce TTT++, which explores the conditions under which testing time training (TTT) through self-supervised learning may fail or succeed in the presence of distribution bias, and proposes an improved feature alignment strategy in test time, thereby improving the performance of self-supervised learning in the field of visual recognition.
Yossi et al.____ propose TTT-MAE, which by studying and comparing three different training strategies during the training phase, ViT-probing is ultimately selected as the appropriate training method. In the testing phase, the image reconstruction task was used to further optimize the image encoder on the test set, achieving significant performance improvement.
Wang et al.____ introduce the TTT strategy into video modeling and propose online TTT. 
% Nicklas et al.____ propose a policy adaptation method that uses self-supervised learning during deployment, which can continuously train policies in new environments without reward signals.
% Yu et al.____ propose a method for online learning of unknown dynamics, which compensates for controller model prediction errors by constructing time-varying, local linear residual models, and improves the performance of model-based controllers in quadruped robot motion.
Mirza et al.____ propose a new Test Time Tuning method called ActMAD, which aligns distributions through matching activations to address distribution shift issues and achieve performance improvements across multiple tasks and architectures.
Liu et al.____ propose a Test Time Tuning method for zero-shot video object segmentation, which significantly improves segmentation performance by training the model to predict consistent depth during testing.
In this paper, we introduce the Test Time Tuning strategy in our tracker, by optimizing the model through consistency constraints during the inference process to improve its generalization ability on the test set.


\begin{figure*}[!htp]
\center
\includegraphics[width=7in]{figures/KD_EventTrackingV2.jpg}
\caption{\textbf{An overview of our proposed \textbf{H}ierarchical Knowledge \textbf{D}istillation Framework for \textbf{E}vent Stream based Tracking, termed HDETrack V2.} It contains the teacher and student Transformer networks which take multi-modal/multi-view and event data only as the input respectively. Both networks share an identical architecture, i.e., tracking using a unified Transformer backbone network similar to CEUTrack____ and OSTrack____. Specifically, we extract the template and search patches from both RGB and event inputs, generating feature embeddings through a projection layer. These embeddings are then passed through a stack of Transformer layers that form the teacher network. The output of this network feeds into the tracking head for target object localization. Meanwhile, the student network is designed for efficient tracking using event stream only. 
It is trained with tracking loss functions and benefits from knowledge distillation from the teacher Transformer network. 
Our tracker achieves a better tradeoff between accuracy and model complexity.} 
\label{framework}
\end{figure*}