\section{Application to TD learning with linear function approximation}\label{sec:TD}

In the second part of the paper, we apply our results to study the properties of the TD learning algorithm with linear function approximation under Markovian samples in RL settings. 
We begin by introducing some background on TD learning; see, e.g., \cite{sutton2018reinforcement}.
% with Polyak-Ruppert averaging~\eqref{eq:TD-update-all}. 
% with Markov samples and decaying stepsizes $\eta_t = \eta_0 t^{-\alpha}$ for $\alpha \in (\frac{1}{2},1)$. 



\input{model}

\subsection{Convergence and Berry-Essen bounds for TD estimator}

%\ale{We should cite \cite{fort2015central}. What other references are relevant here?}\weichen{checked.} 
It is known from results on stochastic approximations that, in fixed dimensions,  the TD estimator with polynomial-decaying stepsizes and Polyak-Ruppert averaging $\bar{\bm{\theta}}_T$ satisfies the central limit theorem (CLT) \citep[see, e.g.,][]{fort2015central,mou2020linear,li2023online}
\begin{align*}
    \sqrt{T}(\bar{\bm{\theta}}_T - \bm{\theta}^\star) \xrightarrow{d} \mathcal{N}(\bm{0},\tilde{\bm{\Lambda}}^\star),
\end{align*}
with asymptotic covariance matrix $\tilde{\bm{\Lambda}}^\star$ 
\begin{align}
    \label{eq:defn-tilde-Lambdastar}
    \tilde{\bm{\Lambda}}^\star = \bm{A}^{-1} \tilde{\bm{\Gamma}}\bm{A}^{-\top},
\end{align}
where $\tilde{\bm{\Gamma}}$ is the time-averaging covariance matrix
\begin{align}
\label{eq:defn-tilde-Gamma}
\tilde{\bm{\Gamma}}&=\lim_{T \to \infty} \mathbf{Var}_{s_0 \sim \mu,s_{t+1} \sim P(\cdot \mid s_t)} \left[\frac{1}{T}\sum_{t=1}^T (\bm{A}_t\bm{\theta}^\star - \bm{b}_t)\right]\nonumber \\ 
&= \mathbb{E}[(\bm{A}_1 \bm{\theta}^\star - \bm{b}_1)(\bm{A}_1 \bm{\theta}^\star - \bm{b}_1)^\top] + \sum_{t=2}^{\infty} \mathbb{E}[(\bm{A}_1 \bm{\theta}^\star - \bm{b}_1)(\bm{A}_{t} \bm{\theta}^\star - \bm{b}_{t})^\top + (\bm{A}_{t} \bm{\theta}^\star - \bm{b}_{t})(\bm{A}_1 \bm{\theta}^\star - \bm{b}_1)^\top].
\end{align}
% \yuting{use $t$ and $T$ instead of $i$ and $n$ to be consistent with theorem statement. } \weichen{changed the notation.}
However, the above results are asymptotic in nature and do not explicitly reveal the dependence on the dimension and other problem-related quantities. A line of recent work has made headway toward this goal, attaining non-asymptotic distributional characterization of the TD procedure. 
Nonetheless, most of the literature has focused on the independent setting where each $(\bm{A}_t,\bm{b}_t)$ pair is an independent and identically distributed random variable \citep[see, e.g.,][]{mou2020linear,wu2024statistical, samsonov2024gaussian}. 
To describe our results, throughout this section, we make the additional assumption that the Markov chain mixes exponentially fast, a standard condition in finite sample analyses of Markovian data. 
\medskip
\begin{customassumption}\label{as:mixing}
There exists constants $m>0,\rho\in (0,1)$, such that for every positive integer $t$,
\begin{align*}
\sup_{s \in \mathcal{S}} d_{\mathsf{TV}}(P^t(\cdot \mid s), \mu) \leq m \rho^t.
\end{align*}
\end{customassumption}
\medskip
We remark that, under this assumption, for any $\varepsilon \in (0,1)$, the corresponding \emph{mixing time} 
\begin{align}\label{eq:defn-tmix}
t_{\mix}(\varepsilon):= \min\{t:\sup_{s \in \mathcal{S}}d_{\mathsf{TV}}(P^t(\cdot \mid s),\mu) \leq \varepsilon\},
\end{align}
satisfies the bound
\begin{align}\label{eq:tmix-bound}
\tmix(\varepsilon) \leq \frac{ \log (m/\varepsilon)}{\log (1/\rho)}.
\end{align}

% \yuting{try to be consistent; sometimes we assume a unique stationary distribution, and sometimes we use irreducible and aperiodic}\weichen{checked.}
\medskip
\begin{customtheorem}[High-probability convergence of TD estimator]\label{thm:TD-whp}
Consider TD with Polyak-Ruppert averaging~\eqref{eq:TD-update-all} with Markov samples and decaying stepsizes $\eta_t = \eta_0 t^{-\alpha}$ for $\alpha \in (\frac{1}{2},1)$. %\ale{Forgot: why do we require $\alpha \in (\frac{1}{2},1)$?} \weichen{In principle, we need the stepsizes to satisfy $\sum_{t=1}^{\infty} \eta_t =\infty$ and $\sum_{t=1}^\infty \eta_t^2 \leq \infty$; in our proof, some upper bounds have $2\alpha-1$ and $1-\alpha$ in their denominators.}
Suppose that the Markov transition kernel has a unique stationary distribution, has a positive spectral gap, mixes exponentially as indicated by Assumption \ref{as:mixing}, and starts from a distribution satisfying Assumption \ref{as:nu}. Then for every tolerance level $\delta \in (0,1)$, there exists $\eta_0 = \eta_0(\delta)$ such that
\begin{align*}
\|\bar{\bm{\theta}}_T-\bm{\theta}^\star\|_2^2 \lesssim \sqrt{\frac{\mathsf{Tr}(\tilde{\bm{\Lambda}}^\star)}{T}\log \frac{d}{\delta}} + o\left(\sqrt{\frac{1}{T}}\log^{\frac{3}{2}} \frac{d}{\delta}\right),
\end{align*}
with probability at least $1-\delta$.
\end{customtheorem}
\medskip

Theorem~\ref{thm:TD-whp}, proved in Appendix \ref{app:proof-markov-deltat-convergence}, establishes the first high-probability convergence guarantee for the TD estimation error with Markov samples that matches the asymptotic variance $\tilde{\bm{\Lambda}}^\star/T$ up to a log factor.  It may be regarded as the Markovian counterpart of Theorem 3.1 in \cite{wu2024statistical}, which focuses on the TD estimation error with \emph{independent} samples under the same settings. 

% In a nutshell, Theorem \ref{thm:TD-whp} ensures that $\|\bar{\bm{\Delta}}_T\|_2^2$ is controlled by three terms: A \emph{linear leading term}, which converges by the rate of $O(\sqrt{{\mathsf{Tr}(\tilde{\bm{\Lambda}}_T)}\log \frac{d}{\delta}/{T}}).$
% \yuting{why not $\tilde{\bm{\Lambda}}^\star$?}
% Here, $\tilde{\bm{\Lambda}}_T$ is the \emph{non-asymptotic variance matrix}, whose exact form will be specified in the Appendix. We establish this bound by invoking our newly-established matrix Berstein inequality on Markovian martingales, Theorem \ref{thm:matrix-bernstein-mtg}; 
% A \emph{non-linear reminder}, which we analyze by tuning the induction argument for TD with independent samples to utilize the mixing property of the Markov chain;
% A \emph{Variance comparison term}, featuring the difference between the non-asymptotic variance $\tilde{\bm{\Lambda}}_T$ and the asymptotic variance $\bm{\Lambda}^\star$. This term is contained in the higher-order reminder in Theorem \ref{thm:TD-whp}. \yuting{This part is not super clear; are you trying to describe how you proved the result?}\weichen{Tried to illustrate the technical novelty. Maybe we can delete this paragraph and just briefly mention that we use Theorem \ref{thm:matrix-bernstein-mtg}, as I did in the next paragraph?}

Our analysis of the TD estimation error borrows tools and ideas from several previous contributions, starting from the seminal work of \cite{polyak1992acceleration} and including some of the most recent results; see, e.g, \cite{li2023online,samsonov2024gaussian,srikant2024rates}. In particular, we apply the induction technique of \cite{srikant2019finite}, \cite{li2023sharp} and \cite{wu2024statistical}, developed for TD learning with \emph{independent} samples. The generalization from independent to Markov samples is highly nontrivial, and the novel theoretical results obtained in the first part of the paper, especially the newly-established matrix Bernstein inequality for Markovian martingales (Corollary \ref{thm:matrix-bernstein-mtg}), play a critical role in our analysis.

\paragraph{Dependence on problem-related quantities.}
We point out that the initial stepsize $\eta_0$ depends on the probability tolerance level $\delta$ as well as other problem-related quantities, as specified in Eq.~\eqref{eq:deltat-condition-markov} in Appendix \ref{app:proof-TD-original}. Though not ideal, this dependence  %\weichen{I suggest we add the negative result illustrating this necessity in the appendix} \yuting{if reviewers ask}
also appears in the independent setting in \cite[Theorem 3.1]{wu2024statistical}, who further argues that it is unavoidable. It is also notable that the choice of $\eta_0$ does \emph{not} depend on the sample size $T$, as is the case in \cite{samsonov2023finitesample}, who also considers TD with Markov samples, though with a \emph{time-invariant} stepsize choice. 
% \yuting{I think it is very standard to have $\eta_0$ depending on problem parameters, do we need to emphasize this?} \weichen{Two AIStats reviewers raised this question, so I mentioned it. And also, the dependency of $\eta_0$ on problem-related quantities is different in this theorem and the next theorem.}
The upper bound in Theorem \ref{thm:TD-whp} depends on various problem-related quantities, including the mixing speed of the Markov chain (specifically, the mixing factor $\rho$ and the spectral gap $1-\lambda$), the discount factor $\gamma$, the initial stepsize $\eta_0$, the feature covariance matrix $\bm{\Sigma}$ and the time-averaging variance matrix of the TD error, $\tilde{\bm{\Gamma}}$. These intricate dependencies impact the higher-order (in $T$)  reminder terms, which is not shown in our bound but can be tracked in our proofs. %incorporated in the upper bound both through the asymptotic variance $\tilde{\bm{\Lambda}}^\star$ (which is independent of $\eta_0$), 

In our next and final result, we give a novel high-dimensional Berry-Esseen bound for the TD estimator assuming Markovian data. 

\medskip
\begin{customtheorem}[Berry-Esseen bound for TD estimator]\label{thm:TD-berry-esseen}
Consider TD with Polyak-Ruppert averaging~\eqref{eq:TD-update-all} with Markov samples and decaying stepsizes $\eta_t = \eta_0 t^{-\frac{3}{4}}$, where $\eta_0 < \frac{1}{2\lambda_{\Sigma}}$. Suppose that the Markov transition kernel has a unique stationary distribution, has a positive spectral gap, mixes exponentially as indicated by Assumption \ref{as:mixing}, and is initiated from a distribution $\nu$ satisfying Assumption \ref{as:nu}. Further assume that $\lambda_{\min}(\tilde{\bm{\Gamma}}) > 0$. Then when $T$ is sufficiently large\footnote{The exact constraint on $T$ is indicated in \eqref{eq:Lambda-T-condition} in the Appendix.}, 
\begin{align*}
d_{\mathsf{C}}(\sqrt{T}(\bar{\bm{\theta}}_T-\bm{\theta}^\star),\mathcal{N}(\bm{0},\tilde{\bm{\Lambda}}^\star)) \lesssim \tilde{C}T^{-\frac{1}{4}}\log T + o(T^{-\frac{1}{4}}),
\end{align*}
where $\widetilde{C}$ is a problem-related quantity independent of $T$, with exact form shown in Appendix \ref{app:proof-TD-Berry-Esseen}.
\end{customtheorem}
\medskip



% \yuting{Should we directly state the optimal choice inside Theorem~\ref{thm:TD-berry-esseen}? We can work with general $\alpha$ in the proof.}\weichen{checked}.

In a nutshell, Theorem~\ref{thm:TD-berry-esseen}, whose proof is given in Appendix \ref{app:proof-TD-Berry-Esseen}, ensures that the rescaled TD estimator with Polyak-Ruppert averaging converges to its Gaussian limit at a rate of $T^{-1/4}\log T$ (holding all other parameters fixed) with respect to the convex distance. 
The dependence on the feature dimension $d$, as well as other problem-related parameters, is unwieldy and thus not given explicitly in the statement of the theorem. However, in principle it can be tracked through the various steps of the proof.

The closest contribution to ours, and indeed the impetus for some of our work,  is the recent excellent paper by \cite{srikant2024rates}, which claims the bound 
\begin{align*}
    d_{\mathsf{W}}(\sqrt{T}(\bar{\bm{\theta}}_T-\bm{\theta}^\star),\mathcal{N}(\bm{0},\tilde{\bm{\Lambda}}^\star)) &\lesssim O(T^{-\frac{1}{4}}\log T).
\end{align*}
In our analysis, we have filled in the gaps in some of their arguments concerning vector-valued martingales and their application to TD learning, while also strengthening the bound from Wasserstein to convex distance.
Other recent and directly relevant contributions by \cite{samsonov2024gaussian} and \cite{wu2024statistical} have also produced high-dimensional Berry-Esseen bound for TD learning with \emph{independent samples},  with \cite{wu2024statistical} claiming the the state-of-the-art rate (in $T$) of $O(T^{-\frac{1}{3}})$. Though it remains to be seen whether the rate of convergence of order  $O(T^{-\frac{1}{4}}\log T)$ for Markovian data that we obtain in Theorem \ref{thm:TD-berry-esseen} is sharp, the generalization from independent to Markov samples is nonetheless highly nontrivial and, we believe,  significant. In any case, we are able to show in Appendix \ref{app:proof-Berry-Esseen-tight} that, for any $\alpha > \frac{3}{4}$ and when $T$ is sufficiently large,
\begin{align}\label{eq:TD-Berry-Esseen-tight}
d_{\mathsf{C}}(\sqrt{T}(\bar{\bm{\theta}}_T-\bm{\theta}^\star),\mathcal{N}(\bm{0},\tilde{\bm{\Lambda}}^\star)) &\gtrsim \Theta(T^{-\frac{1}{4}}\log T),\quad\text{for all } \alpha \in \left(\frac{3}{4},1\right),
\end{align}
a partial clue that our rate might in fact be optimal.


% Finally, we conclude by observing that choice of the stepsize in Theorem \ref{thm:TD-whp} and Theorem \ref{thm:TD-berry-esseen} are different: in Theorem \ref{thm:TD-whp}, $\eta_0$ depends on $\delta$ and other problem-related quantities like $\lambda_0$ and $\gamma$, and $\alpha$ can take any value between $\frac{1}{2}$ and $1$; however, in Theorem \ref{thm:TD-berry-esseen}, the initial stepsize $\eta_0$ can take any value less than $1/2\lambda_{\Sigma}$, while $\alpha$ is set to the specific value of $\frac{3}{4}$. In fact, our proof of Theorem~\ref{thm:TD-berry-esseen} allows for a general choice of $\alpha$; however, using other values of $\alpha$ other than $3/4$ appears to be suboptimal. \ale{Maybe we can move this comment to the appendix? It seems very detailed and technical. It would also save space}
% \paragraph{Comparison with previous works.} 
% To the best of our knowledge, Theorem \ref{thm:TD-berry-esseen} is the first \emph{valid} Berry-Esseen bound for TD with linear function approximation and Markov samples. 


% Similar to Theorem \ref{thm:TD-whp}, the non-asymptotic distribution of $\bar{\bm{\Delta}}_T$ is also decomposed into three parts. In our proof, shown in Appendix \ref{app:proof-TD-Berry-Esseen}, we address these three terms under any choice of $\alpha \in (\frac{1}{2},1)$ by:

% \begin{enumerate}
% \item The linear leading term is characterized by our newly established high-dimensional Berry-Esseen bound, Theorem \ref{thm:Berry-Esseen-mtg}. It yields a convergence rate of $O(T^{-\frac{1}{4}}\log T)$, independent of $\alpha$;
% \item The non-linear reminder is characterized by the mixing property of the Markov chain, as well as the L2 convergence rate of the original TD estimator. This term yields a convergence rate of $O((T^{\frac{1}{2}-\alpha} + T^{-\frac{\alpha}{3}})\log T)$;
% \item The variance comparison term is characterized by the TV distance between two zero-mean multi-dimensional Gaussian distributions, yielding a convergence rate of $O(T^{\alpha-1})$.
% \end{enumerate}

% \paragraph{Tightness of Theorem \ref{thm:TD-berry-esseen}.}





