\chapter{Filtering}\label{sec:kf}\pidx{filtering}[idxpagebf]

Before we continue in \cref{sec:gp} with the function-space view of regression, we want to look at a seemingly different but very related problem.
We will study Bayesian learning and inference in the \midx{state space model}, where we want to keep track of the state of an agent over time based on noisy observations.
In this model, we have a sequence of (hidden) states $(\rX_t)_{t\in\Nat_0}$ where $\rX_t$ is in $\R^d$ and a sequence of observations $(\rY_t)_{t\in\Nat_0}$ where $\rY_t$ is in $\R^m$.%

The process of keeping track of the state using noisy observations is also known as \midx{Bayesian filtering} or \midx{recursive Bayesian estimation}.
\Cref{fig:bayesian_filtering} illustrates this process, where an agent perceives the current state of the world and then updates its beliefs about the state based on this observation.

\begin{figure}
  \incfig[0.75\textwidth]{filtering_diagram}
  \caption{Schematic view of Bayesian filtering: An agent perceives the current state of the world and updates its belief accordingly.}
  \label{fig:bayesian_filtering}
\end{figure}

We will discuss Bayesian filtering more broadly in the next section.
A Kalman filter is an important special case of a Bayes' filter, which uses a Gaussian prior over the states and conditional linear Gaussians to describe the evolution of states and observations.
Analogously to the previous chapter, we will see that inference in this model is tractable due to the closedness properties of Gaussians.

\begin{defn}[Kalman filter]\pidx{Kalman filter}
  A \emph{Kalman filter} is specified by a Gaussian prior over the states, \begin{align}
    \rX_0 \sim \N{\vmu}{\mSigma},
  \end{align} and a conditional linear Gaussian \emph{motion model} and \emph{sensor model}, \begin{align}
    \rX_{t+1} &\defeq \mF \rX_t + \vvarepsilon_t \quad &&\mF \in \R^{d \times d}, \vvarepsilon_t \sim \N{\vzero}{\mSigma_x}, \label{eq:kf_motion_model} \\
    \rY_t     &\defeq \mH \rX_t + \veta_t \quad     &&\mH \in \R^{m \times d}, \veta_t \sim \N{\vzero}{\mSigma_y}, \label{eq:kf_sensor_model}
  \end{align} respectively.
  The motion model is sometimes also called \emph{transition model} or \emph{dynamics model}.
  Crucially, Kalman filters assume that $\mF$ and $\mH$ are known.
  In general, $\mF$ and $\mH$ may depend on $t$.
  Also, $\vvarepsilon$ and $\veta$ may have a non-zero mean, commonly called a ``drift''.
\end{defn}

\begin{marginfigure}
  \incfig{kf}
  \caption{Directed graphical model of a Kalman filter with hidden states $\rX_t$ and observables $\rY_t$.}\label{fig:kf}
\end{marginfigure}

Because Kalman filters use conditional linear Gaussians, which we have already seen in \cref{eq:cond_linear_gaussian}, their joint distribution (over all variables) is also Gaussian.
This means that predicting the future states of a Kalman filter is simply inference with multivariate Gaussians.
In Bayesian filtering, however, we do not only want to make predictions occasionally.
In Bayesian filtering, we want to \emph{keep track} of states, that is, predict the current state of an agent online.\footnote{Here, \idx{online} is common terminology to say that we want to perform inference at time $t$ without exposure to times $t+1, t+2, \dots$, so in ``real-time''.}
To do this efficiently, we need to update our \midx{belief} about the state of the agent recursively, similarly to our recursive Bayesian updates in Bayesian linear regression (see \cref{sec:blr:online}).

From the directed graphical model of a Kalman filter shown in \cref{fig:kf}, we can immediately gather the following conditional independence relations,\footnote{Alternatively, they follow from the definition of the motion and sensor models as linear updates.}\looseness=-1 \begin{align}
  \rX_{t+1} &\perp \rX_{1:t-1}, \rY_{1:t-1} \mid \rX_t, \label{eq:kf_cond_ind1} \\
  \rY_t     &\perp \rX_{1:t-1} \mid \rX_t \label{eq:kf_cond_ind2} \\
  \rY_t     &\perp \rY_{1:t-1} \mid \rX_{t-1}. \label{eq:kf_cond_ind3}
\end{align}
The first conditional independence property is also known as the \midx{Markov property}, which we will return to later in our discussion of Markov chains and Markov decision processes.
This characterization of the Kalman filter, yields the following factorization of the joint distribution:\looseness=-1 \begin{align}
  p(\vx_{1:t}, \vy_{1:t}) &= \prod_{i=1}^t p(\vx_i \mid \vx_{1:i-1}) p(\vy_i \mid \vx_{1:t}, \vy_{1:i-1}) \margintag{using the product rule \eqref{eq:product_rule}} \nonumber \\
  &= p(\vx_1) p(\vy_1 \mid \vx_1) \prod_{i=2}^t p(\vx_i \mid \vx_{i-1}) p(\vy_i \mid \vx_i). \margintag{using the conditional independence properties from \eqref{eq:kf_cond_ind1}, \eqref{eq:kf_cond_ind2}, and \eqref{eq:kf_cond_ind3}}
\end{align}

\section{Conditioning and Prediction}\label{sec:kf:bayesian_filtering}

We can describe Bayesian filtering by the following recursive scheme with the two phases, \emph{conditioning} (also called ``update'') and \emph{prediction}:

\begin{algorithm}
  \caption{Bayesian filtering}
  start with a prior over initial states $p(\vx_0)$\;
  \For{$t = 1$ \KwTo $\infty$}{
    assume we have $p(\vx_t \mid \vy_{1:t-1})$\;
    \textbf{conditioning}: compute $p(\vx_t \mid \vy_{1:t})$ using the new observation $\vy_t$\;
    \textbf{prediction}: compute $p(\vx_{t+1} \mid \vy_{1:t})$\;
  }
\end{algorithm}

Let us consider the conditioning step first: \begin{align}
  p(\vx_t \mid \vy_{1:t}) &= \frac{1}{Z} p(\vx_t \mid \vy_{1:t-1}) p(\vy_t \mid \vx_t, \vy_{1:t-1}) \margintag{using Bayes' rule \eqref{eq:bayes_rule}} \nonumber \\
  &= \frac{1}{Z} p(\vx_t \mid \vy_{1:t-1}) p(\vy_t \mid \vx_t). \margintag{using the conditional independence structure \eqref{eq:kf_cond_ind3}} \label{eq:bf_conditioning}
\end{align}
For the prediction step, we obtain, \begin{align}
  p(\vx_{t+1} \mid \vy_{1:t}) &= \int p(\vx_{t+1}, \vx_t \mid \vy_{1:t}) \,d\vx_t \margintag{using the sum rule \eqref{eq:sum_rule}} \nonumber \\
  &= \int p(\vx_{t+1} \mid \vx_t, y_{1:t}) p(\vx_t \mid y_{1:t}) \,d\vx_t \margintag{using the product rule \eqref{eq:product_rule}} \nonumber \\
  &= \int p(\vx_{t+1} \mid \vx_t) p(\vx_t \mid y_{1:t}) \,d\vx_t. \margintag{using the conditional independence structure \eqref{eq:kf_cond_ind1}} \label{eq:bf_prediction}
\end{align}
In general, these distributions can be very complicated, but for Gaussians (i.e., Kalman filters) they can be expressed in closed-form.

\begin{rmk}{Bayesian smoothing}{bs}
  \midx{Bayesian smoothing} is a closely related task to Bayesian filtering.
  While Bayesian filtering methods estimate the current state based only on observations obtained before and at the current time step, Bayesian smoothing computes the distribution of ${\rX_k \mid \vy_{1:t}}$ where ${t > k}$.
  That is Bayesian smoothing estimates $\rX_k$ based on data until \emph{and beyond} time $k$.
  Note that if ${k = t}$, then Bayesian smoothing coincides with Bayesian filtering.

  Analogously to \cref{eq:bf_conditioning}, \begin{align}
    p(\vx_k \mid \vy_{1:t}) \propto p(\vx_k \mid \vy_{1:k}) p(\vy_{k+1:t} \mid \vx_k). \label{eq:bs}
  \end{align}
  If we assume a Gaussian prior and conditional Gaussian transition and dynamics models (this is called \midx{Kalman smoothing}), then by the closedness properties of Gaussians, $\rX_k \mid \vy_{1:t}$ is a Gaussian.
  Indeed, all terms of \cref{eq:bs} are Gaussian PDFs and as seen in \cref{eq:gaussian_pdf_product}, the product of two Gaussian PDFs is again proportional to a Gaussian PDF.\looseness=-1

  The first term, $\rX_k \mid \vy_{1:k}$, is the marginal posterior of the hidden states of the Kalman filter which can be obtained with Bayesian filtering.\looseness=-1

  By conditioning on $\rX_{k+1}$, we have for the second term, \begin{align}
    p(\vy_{k+1:t} \mid \vx_k) &= \int p(\vy_{k+1:t} \mid \vx_k, \vx_{k+1}) p(\vx_{k+1} \mid \vx_k) \,d\vx_{k+1} \margintag{using the sum rule \eqref{eq:sum_rule} and product rule \eqref{eq:product_rule}} \nonumber\\
    &= \int p(\vy_{k+1:t} \mid \vx_{k+1}) p(\vx_{k+1} \mid \vx_k) \,d\vx_{k+1} \margintag{using the conditional independence structure \eqref{eq:kf_cond_ind2}} \nonumber\\
    &= \int p(\vy_{k+1} \mid \vx_{k+1}) p(\vy_{k+2:t} \mid \vx_{k+1}) p(\vx_{k+1} \mid \vx_k) \,d\vx_{k+1} \margintag{using the conditional independence structure \eqref{eq:kf_cond_ind3}}
  \end{align}
  Let us have a look at the terms in the product: \begin{itemize}
    \item $p(\vy_{k+1} \mid \vx_{k+1})$ is obtained from the sensor model,
    \item $p(\vx_{k+1} \mid \vx_k)$ is obtained from the transition model, and
    \item ${p(\vy_{k+2:t} \mid \vx_{k+1})}$ can be computed recursively backwards in time.
  \end{itemize}
  This recursion results in linear equations resembling a Kalman filter running backwards in time.

  Thus, in the setting of Kalman smoothing, both factors of \cref{eq:bs} can be computed efficiently: one using a (forward) Kalman filter; the other using a ``backward'' Kalman filter.
  More concretely, in time $\BigO{t}$, we can compute the two factors for all $k \in [t]$.
  This approach is known as \midx{two-filter smoothing} or the \midx{forward-backward algorithm}.\looseness=-1
\end{rmk}

\section{Kalman Filters}

Let us return to the setting of Kalman filters where priors and likelihoods are Gaussian.
Here, we will see that the update and prediction steps can be computed in closed form.

\subsection{Conditioning}

The conditioning operation in Kalman filters is also called the Kalman update.
Before introducing the general Kalman update, let us consider a simpler example:\looseness=-1

\begin{ex}{Random walk in 1d}{kf_rand_walk_1d}
  We use the simple motion and sensor models,\safefootnote{This corresponds to $\mF = \mH = \mI$ and a drift of $0$.} \begin{subequations}\begin{align}
    X_{t+1} \mid x_t &\sim \N{x_t}{\sigma_x^2}, \label{eq:kf_1d_motion_model} \\
    Y_t \mid x_t     &\sim \N{x_t}{\sigma_y^2}. \label{eq:kf_1d_sensor_model}
  \end{align}\end{subequations}
  Let ${X_t \mid y_{1:t} \sim \N{\mu_t}{\sigma_t^2}}$ be our belief at time $t$.
  It can be shown that Bayesian filtering yields the belief ${X_{t+1} \mid y_{1:t+1} \sim \N{\mu_{t+1}}{\sigma_{t+1}^2}}$ at time $t+1$ where \exerciserefmark{kf_predictive_distr} \begin{align}
    \mu_{t+1} \defeq \frac{\sigma_y^2 \mu_t + (\sigma_t^2 + \sigma_x^2) y_{t+1}}{\sigma_t^2 + \sigma_x^2 + \sigma_y^2}, \quad \sigma_{t+1}^2 \defeq \frac{(\sigma_t^2 + \sigma_x^2) \sigma_y^2}{\sigma_t^2 + \sigma_x^2 + \sigma_y^2}. \label{eq:kalman_posterior}
  \end{align}
  Although looking intimidating at first, this update has a very natural interpretation.
  Let us define the following quantity, \begin{align}
    \lambda \defeq \frac{\sigma_t^2 + \sigma_x^2}{\sigma_t^2 + \sigma_x^2 + \sigma_y^2} = 1 - \frac{\sigma_y^2}{\sigma_t^2 + \sigma_x^2 + \sigma_y^2} \in [0,1]. \label{eq:kalman_gain_1d}
  \end{align}
  Using $\lambda$, we can write the updated mean as a convex combination of the previous mean and the observation, \begin{align}
    \mu_{t+1} &= (1-\lambda)\mu_t + \lambda y_{t+1} \\
    &= \mu_t + \lambda(y_{t+1} - \mu_t). \label{eq:kf_update_1d}
  \end{align}
  Intuitively, $\lambda$ is a form of ``gain'' that influences how much of the new information should be incorporated into the updated mean.
  For this reason, $\lambda$ is also called \midx{Kalman gain}.

  The updated variance can similarly be rewritten, \begin{align}
    \sigma_{t+1}^2 = \lambda \sigma_y^2 = (1-\lambda)(\sigma_t^2 + \sigma_x^2). \label{eq:kalman_variance_1d}
  \end{align}

  In particular, observe that if ${\mu_t = y_{t+1}}$ (i.e., we observe our prediction), we have ${\mu_{t+1} = \mu_t}$ as there is no new information.
  Similarly, for $\sigma_y^2 \to \infty$ (i.e., we do not trust our observations), we have \begin{align*}
    \lambda \to 0, \quad \mu_{t+1} = \mu_t, \quad \sigma_{t+1}^2 = \sigma_t^2 + \sigma_x^2.
  \end{align*}
  In contrast, for $\sigma_y^2 \to 0$, we have \begin{align*}
    \lambda \to 1, \quad \mu_{t+1} = y_{t+1}, \quad \sigma_{t+1}^2 = 0.
  \end{align*}
\end{ex}

\begin{marginfigure}[-45\baselineskip]
  \incplt{1d_random_walk}
  \caption{Hidden states during a random walk in one dimension.}
\end{marginfigure}

The general formulas for the \midx{Kalman update} follow the same logic as in the above example of a one-dimensional random walk.
Given the prior belief ${\rX_t \mid \vy_{1:t} \sim \N{\vmu_t}{\mSigma_t}}$, we have \begin{subequations}\begin{align}
  \rX_{t+1} \mid \vy_{1:t+1} &\sim \N{\vmu_{t+1}}{\mSigma_{t+1}} \quad\text{where} \\
  \vmu_{t+1} &\defeq \mF \vmu_t + \mK_{t+1}(\vy_{t+1} - \mH \mF \vmu_t), \\
  \mSigma_{t+1} &\defeq (\mI - \mK_{t+1} \mH)(\mF \mSigma_t \transpose{\mF} + \mSigma_x). \label{eq:kalman_update_covariance_matrix}
  \intertext{Hereby, $\mK_{t+1}$ is the \midx{Kalman gain}[idxpagebf],}
  \mK_{t+1} &\defeq (\mF \mSigma_t \transpose{\mF} + \mSigma_x) \transpose{\mH} \inv{(\mH (\mF \mSigma_t \transpose{\mF} + \mSigma_x) \transpose{\mH} + \mSigma_y)} \in \R^{d \times m}.
\end{align}\label{eq:kalman_update}\end{subequations}
Note that $\mSigma_t$ and $\mK_t$ can be computed offline as they are independent of the observation $\vy_{t+1}$. $\mF\vmu_t$ represents the expected state at time $t+1$, and hence, $\mH\mF\vmu_t$ corresponds to the expected observation. Therefore, the term $\vy_{t+1} - \mH\mF\vmu_t$ measures the error in the predicted observation and the Kalman gain $\mK_{t+1}$ appears as a measure of relevance of the new observation compared to the prediction.

\begin{ex}{Bayesian linear regression as a Kalman filter}{blr_as_kf}
  Even though they arise from a rather different setting, it turns out that Kalman filters are a generalization of Bayesian linear regression!
  To see this, recall the online Bayesian linear regression algorithm from \cref{sec:blr:online}.
  Observe that by keeping attempting to estimate the (hidden)  weights $\opt{\vw}$ from sequential noisy observations $y_t$, this algorithm performs Bayesian filtering!
  Moreover, we have used a Gaussian prior and likelihood.
  This is precisely the setting of a Kalman filter!

  Concretely, we are estimating the constant (i.e., $\mF = \mI$, $\vvarepsilon = \vzero$) hidden state $\vx_t = \vw^{(t)}$ with prior $\vw^{(0)} \sim \N{\vzero}{\sigmap^2 \mI}$.

  Our sensor model is time-dependent, since in each iteration we observe a different input $\vx_t$.
  Furthermore, we only observe a scalar-valued label $y_t$.\safefootnote{That is, $m = 1$ in our general Kalman filter formulation from above.}
  Formally, our sensor model is characterized by $\vh_t = \transpose{\vx_t}$ and noise $\eta_t = \varepsilon_t$ with $\varepsilon_t \sim \N{0}{\sigman^2}$.

  You will show in \exerciserefmark{blr_as_kf} that the Kalman update~\eqref{eq:kalman_update} is the online equivalent to computing the posterior of the weights in Bayesian linear regression.
\end{ex}

\subsection{Predicting}

Using now that the marginal posterior of $\rX_t$ is a Gaussian due to the closedness properties of Gaussians, we have \begin{align}
  \rX_{t+1} \mid \vy_{1:t} \sim \N{\vmuhat_{t+1}}{\hat{\mSigma}_{t+1}},
\end{align} and it suffices to compute the prediction mean $\vmuhat_{t+1}$ and covariance matrix~$\hat{\mSigma}_{t+1}$.\looseness=-1

For the mean, \begin{align}
  \vmuhat_{t+1} &= \E{\vx_{t+1} \mid \vy_{1:t}} \nonumber\\
  &= \E{\mF\vx_t + \vvarepsilon_t \mid \vy_{1:t}} \margintag{using the motion model \eqref{eq:kf_motion_model}} \nonumber\\
  &= \mF\E{\vx_t \mid \vy_{1:t}} \margintag{using linearity of expectation \eqref{eq:linearity_expectation} and $\E{\vvarepsilon_t} = \vzero$} \nonumber\\[5pt]
  &= \mF\vmu_t. \margintag{using the mean of the Kalman update} \label{eq:kf_pred_mean}
\end{align}

For the covariance matrix, \begin{align}
  \hat{\mSigma}_{t+1} &= \E{(\vx_{t+1} - \vmuhat_{t+1})\transpose{(\vx_{t+1} - \vmuhat_{t+1})}}[\vy_{1:t}] \margintag{using the definition of the covariance matrix \eqref{eq:covariance_matrix}} \nonumber\\[3pt]
  &= \mF \E{(\vx_t - \vmu_t)\transpose{(\vx_t - \vmu_t)}}[\vy_{1:t}] \transpose{\mF} + \E{\vvarepsilon_t\transpose{\vvarepsilon_t}} \margintag{using \eqref{eq:kf_pred_mean}, the motion model \eqref{eq:kf_motion_model} and that $\vvarepsilon_t$ is independent of the observations} \nonumber\\
  &= \mF \mSigma_t \transpose{\mF} + \mSigma_x. \label{eq:kf_prediction_cov_mat}
\end{align}

\begin{oreadings}
  Kalman filters and related models are often called \midx{temporal models}.
  For a broader look at such models, read chapter 15 of \icite{aimodernapproach}.
\end{oreadings}

\section*{Discussion}

In this chapter, we have introduced Kalman filters as a special case of probabilistic filtering where probabilistic inference can be performed in closed form.
Similarly to Bayesian linear regression, probabilistic inference is tractable due to assuming Gaussian priors and likelihoods.
Indeed, learning linear models and Kalman filters are very closely related as seen in \cref{ex:blr_as_kf}, and we will further explore this relationship in \cref{exercise:kf_as_gp}.
We will refer back to filtering in the second part of this manuscript when we discuss sequential decision-making with partial observability of the state space.
Next, we return to the storyline on ``learning'' using exact probabilistic inference.

\excheading

\begin{nexercise}{Kalman update}{kf_predictive_distr}
  Derive the predictive distribution $X_{t+1} \mid y_{1:t+1}$ \eqref{eq:kalman_posterior} of the Kalman filter described in the above example using your knowledge about multivariate Gaussians from \cref{sec:fundamentals:gaussians}. \\
  \textit{Hint: First compute the predictive distribution $X_{t+1} \mid y_{1:t}$.}
\end{nexercise}

\begin{nexercise}{Bayesian linear regression as a Kalman filter}{blr_as_kf}
  Recall the specific Kalman filter from \cref{ex:blr_as_kf}.
  With this model the Kalman update~\eqref{eq:kalman_update} simplifies to \begin{subequations}\begin{align}
    \vk_t &= \frac{\mSigma_{t-1} \vx_t}{\transpose{\vx_t} \mSigma_{t-1} \vx_t + \sigman^2}, \\
    \vmu_t &= \vmu_{t-1} + \vk_t (y_t - \transpose{\vx_t}\vmu_{t-1}), \\
    \mSigma_t &= \mSigma_{t-1} - \vk_t \transpose{\vx_t}\mSigma_{t-1},
  \end{align}\end{subequations} with $\vmu_0 = \vzero$ and $\mSigma_0 = \sigmap^2 \mI$.
  Note that the Kalman gain~$\vk_t$ is a vector in~$\R^{d}$.
  We assume $\sigman^2 = \sigmap^2 = 1$ for simplicity.\par
  Prove by induction that the $(\vmu_t, \mSigma_t)$ produced by the Kalman update are equivalent to $(\vmu, \mSigma)$ from the posterior of Bayesian linear regression~\eqref{eq:blr_posterior} given $\vx_{1:t}, y_{1:t}$.
  You may use that $\inv{\mSigma_t} \vk_t = \vx_t$.\par
  \textit{Hint: In the inductive step, first prove the equivalence of $\mSigma_t$ and then expand $\inv{\mSigma_t} \vmu_t$ to prove the equivalence of $\vmu_t$.}
\end{nexercise}

\begin{nexercise}{Parameter estimation using Kalman filters}{parameter_estimation_with_kf}
  Suppose that we want to estimate the value of an unknown constant~$\pi$ using uncorrelated measurements \begin{align*}
    y_t = \pi + \eta_t, \quad \eta_t \sim \N{0}{\sigma_y^2}.
  \end{align*}

  \begin{enumerate}
    \item How can this problem be formulated as a Kalman filter?
    Compute closed form expressions for the Kalman gain and the variance of the estimation error $\sigma_t^2$ in terms of $t$, $\sigma_y^2$, and $\sigma_0^2$.
    \item What is the Kalman filter when $t \to \infty$?
    \item Suppose that one has no prior assumptions on $\pi$, meaning that $\mu_0 = 0$ and $\sigma_0^2 \to \infty$.
    Which well-known estimator does the Kalman filter reduce to in this case?
  \end{enumerate}
\end{nexercise}
