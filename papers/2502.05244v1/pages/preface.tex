\chapter*{Preface}

Artificial intelligence commonly refers to the science and engineering of artificial systems that can carry out tasks generally associated with requiring aspects of human intelligence, such as playing games, translating languages, and driving cars.
In recent years, there have been exciting advances in learning-based, data-driven approaches towards AI, and machine learning and deep learning have enabled computer systems to perceive the world in unprecedented ways.
Reinforcement learning has enabled breakthroughs in complex games such as Go and challenging robotics tasks such as quadrupedal locomotion.

A key aspect of intelligence is to not only make predictions, but reason about the {\em uncertainty} in these predictions, and to consider this uncertainty when making decisions.
This is what ``Probabilistic Artificial Intelligence'' is about.
The first part covers probabilistic approaches to machine learning.
We discuss the differentiation between ``epistemic'' uncertainty due to lack of data and ``aleatoric'' uncertainty, which is irreducible and stems, e.g., from noisy observations and outcomes.
We discuss concrete approaches towards probabilistic inference, such as Bayesian linear regression, Gaussian process models and Bayesian neural networks.
Often, inference and making predictions with such models is intractable, and we discuss modern approaches to efficient approximate inference.

The second part of the \course is about taking uncertainty into account in sequential decision tasks.
We consider active learning and Bayesian optimization --- approaches that collect data by proposing experiments that are informative for reducing the epistemic uncertainty.
We then consider reinforcement learning, a rich formalism for modeling agents that learn to act in uncertain environments.
After covering the basic formalism of Markov Decision Processes, we consider modern deep RL approaches that use neural network function approximation.
We close by discussing modern approaches in model-based RL, which harness epistemic and aleatoric uncertainty to guide exploration, while also reasoning about safety.

\section*{Guide to the Reader}

The material covered in this manuscript may support a one semester graduate introduction to probabilistic machine learning and sequential decision-making.
We welcome readers from all backgrounds.
However, we assume familiarity with basic concepts in probability, calculus, linear algebra, and machine learning (e.g., neural networks) as covered in a typical introductory course to machine learning.
In \cref{sec:fundamentals}, we give a gentle introduction to probabilistic inference, which serves as the foundation for the rest of the manuscript.
As part of this first chapter, we also review key concepts from probability theory.
We provide a chapter reviewing key concepts of further mathematical background in the back of the manuscript.

Throughout the manuscript, we focus on key concepts and ideas rather than their historical development.
We encourage you to consult the provided references for further reading and historical context to delve deeper into the covered topics.

\ifthenelse{\boolean{manuscript}}{}{
  Accompanying this manuscript, we provide an extensive set of curated examples as Jupyter notebooks which you can run and play with.
  You can find them at: \\
  \url{https://gitlab.inf.ethz.ch/OU-KRAUSE/pai-demos}.
}

Finally, we have included a set of exercises at the end of each chapter.
When we highlight an exercise throughout the text, we use this question mark: \exerciserefmark{properties_of_probability} --- so don't be surprised when you stumble upon it.
You will find solutions to all exercises in the back of the manuscript.

We hope you will find this resource useful.

\section*{Contributing}

We encourage you to raise issues and suggest fixes for anything you think can be improved.
We are thankful for any such feedback! \\
\textsc{Contact:} \href{mailto:pai-script@lists.inf.ethz.ch}{pai-script@lists.inf.ethz.ch}
\ifthenelse{\boolean{manuscript}}{}{\\ \textsc{Repository:} \url{https://gitlab.inf.ethz.ch/OU-KRAUSE/pai-script}}


\section*{Acknowledgements}

We are grateful to Sebastian Curi for creating the original Jupyter notebooks that accompany the course at ETH Zürich and which were instrumental in the creation of many figures.
We thank Hado van Hasselt for kindly contributing \cref{fig:maximization_bias}, and thank Tuomas Haarnoja~\citep{haarnoja2018soft} and Roberto Calandra~\citep{chua2018deep} for kindly agreeing to have their figures included in this manuscript.
Furthermore, many of the exercises in these notes are adapted from iterations of the course at ETH Zürich.
Special thanks to all instructors that contributed to the course material over the years.
We also thank all students of the course in the Fall of 2022, 2023, and 2024 who provided valuable feedback on various iterations of this manuscript and corrected many mistakes.
Finally, we thank Zhiyuan Hu, Shyam Sundhar Ramesh, Leander Diaz-Bone, Nicolas Menet, and Ido Hakimi for proofreading parts of various drafts of this text.
