\DeclareAcronym{iff}{short=iff, long=if and only if}
\DeclareAcronym{wrt}{short=w.r.t., long=with respect to}
\DeclareAcronym{wlog}{short=w.l.o.g., long=without loss of generality}
\DeclareAcronym{iid}{short=i.i.d., long=independent and identically distributed}
\DeclareAcronym{as}{short=a.s., long={almost surely, with high probability, with probability 1}}

\DeclareAcronym{A2C}{short=A2C, long=advantage actor-critic}
\DeclareAcronym{BALD}{short=BALD, long=Bayesian active learning by disagreement}
\DeclareAcronym{BLR}{short=BLR, long=Bayesian linear regression}
\DeclareAcronym{CDF}{short=CDF, long=cumulative distribution function}
\DeclareAcronym{CLT}{short=CLT, long=central limit theorem}
\DeclareAcronym{DDPG}{short=DDPG, long=deep deterministic policy gradients}
\DeclareAcronym{DDQN}{short=DDQN, long=double deep Q-networks}
\DeclareAcronym{DPO}{short=DPO, long=direct preference optimization}
\DeclareAcronym{DQN}{short=DQN, long=deep Q-networks}
\DeclareAcronym{ECE}{short=ECE, long=expected calibration error}
\DeclareAcronym{EI}{short=EI, long=expected improvement}
\DeclareAcronym{ELBO}{short=ELBO, long=evidence lower bound}
\DeclareAcronym{ES}{short=ES, long=entropy search}
\DeclareAcronym{FITC}{short=FITC, long=fully independent training conditional}
\DeclareAcronym{GAE}{short=GAE, long=generalized advantage estimation}
\DeclareAcronym{GD}{short=GD, long=gradient descent}
\DeclareAcronym{GLIE}{short=GLIE, long=greedy in the limit with infinite exploration}
\DeclareAcronym{GP}{short=GP, long=Gaussian process}
\DeclareAcronym{GPC}{short=GPC, long=Gaussian process classification}
\DeclareAcronym{GRPO}{short=GRPO, long=group relative policy optimization}
\DeclareAcronym{GRV}{short=GRV, long=Gaussian random vector}
\DeclareAcronym{HMC}{short=HMC, long=Hamiltonian Monte Carlo}
\DeclareAcronym{HMM}{short=HMM, long=hidden Markov model}
\DeclareAcronym{H-UCRL}{short=H-UCRL, long=hallucinated upper confidence reinforcement learning}
\DeclareAcronym{IDS}{short=IDS, long=information-directed sampling}
\DeclareAcronym{JES}{short=JES, long=joint entropy search}
\DeclareAcronym{KL}{short=KL, long=Kullback-Leibler}
\DeclareAcronym{LAMBDA}{short=LAMBDA, long=Lagrangian model-based agent}
\DeclareAcronym{LASSO}{short=LASSO, long=least absolute shrinkage and selection operator}
\DeclareAcronym{LD}{short=LD, long=Langevin dynamics}
\DeclareAcronym{LITE}{short=LITE, long=linear-time independence-based estimators (of probability of maximality)}
\DeclareAcronym{LMC}{short=LMC, long=Langevin Monte Carlo}
\DeclareAcronym{LOTE}{short=LOTE, long=law of total expectation}
\DeclareAcronym{LOTP}{short=LOTP, long=law of total probability}
\DeclareAcronym{LOTV}{short=LOTV, long=law of total variance}
\DeclareAcronym{LOTUS}{short=LOTUS, long=law of the unconscious statistician}
\DeclareAcronym{LSI}{short=LSI, long=log-Sobolev inequality}
\DeclareAcronym{MAB}{short=MAB, long=multi-armed bandits}
\DeclareAcronym{MALA}{short=MALA, long=Metropolis adjusted Langevin algorithm}
\DeclareAcronym{MAP}{short=MAP, long=maximum a posteriori}
\DeclareAcronym{MC}{short=MC, long=Monte Carlo}
\DeclareAcronym{MCE}{short=MCE, long=maximum calibration error}
\DeclareAcronym{MCMC}{short=MCMC, long=Markov chain Monte Carlo}
\DeclareAcronym{MCTS}{short=MCTS, long=Monte Carlo tree search}
\DeclareAcronym{MDP}{short=MDP, long=Markov decision process}
\DeclareAcronym{MES}{short=MES, long=max-value entropy search}
\DeclareAcronym{MERL}{short=MERL, long=maximum entropy reinforcement learning}
\DeclareAcronym{MGF}{short=MGF, long=moment-generating function}
\DeclareAcronym{MI}{short=MI, long=mutual information}
\DeclareAcronym{MLE}{short=MLE, long=maximum likelihood estimate}
\DeclareAcronym{MLL}{short=MLL, long=marginal log likelihood}
\DeclareAcronym{MPC}{short=MPC, long=model predictive control}
\DeclareAcronym{MSE}{short=MSE, long=mean squared error}
\DeclareAcronym{NLL}{short=NLL, long=negative log likelihood}
\DeclareAcronym{ODE}{short=ODE, long=ordinary differential equation}
\DeclareAcronym{OPES}{short=OPES, long=output-space predictive entropy search}
\DeclareAcronym{PBPI}{short=PBPI, long=point-based policy iteration}
\DeclareAcronym{PBVI}{short=PBVI, long=point-based value iteration}
\DeclareAcronym{PDF}{short=PDF, long=probability density function}
\DeclareAcronym{PES}{short=PES, long=predictive entropy search}
\DeclareAcronym{PETS}{short=PETS, long=probabilistic ensembles with trajectory sampling}
\DeclareAcronym{PI1}{short=PI, long=policy iteration}
\DeclareAcronym{PI2}{short=PI, long=probability of improvement}
\DeclareAcronym{PILCO}{short=PILCO, long=probabilistic inference for learning control}
\DeclareAcronym{PL}{short=PL, long=Polyak-≈Åojasiewicz}
\DeclareAcronym{PlaNet}{short=PlaNet, long=deep planning network}
\DeclareAcronym{PMF}{short=PMF, long=probability mass function}
\DeclareAcronym{POMDP}{short=POMDP, long=partially observable Markov decision process}
\DeclareAcronym{PPO}{short=PPO, long=proximal policy optimization}
\DeclareAcronym{RBF}{short=RBF, long=radial basis function}
\DeclareAcronym{ReLU}{short=ReLU, long=rectified linear unit}
\DeclareAcronym{RHC}{short=RHC, long=receding horizon control}
\DeclareAcronym{RKHS}{short=RKHS, long=reproducing kernel Hilbert space}
\DeclareAcronym{RL}{short=RL, long=reinforcement learning}
\DeclareAcronym{RLHF}{short=RLHF, long=reinforcement learning from human feedback}
\DeclareAcronym{RM}{short=RM, long=Robbins-Monro}
\DeclareAcronym{SAA}{short=SAA, long=stochastic average approximation}
\DeclareAcronym{SAC}{short=SAC, long=soft actor-critic}
\DeclareAcronym{SARSA}{short=SARSA, long=state-action-reward-state-action}
\DeclareAcronym{SDE}{short=SDE, long=stochastic differential equation}
\DeclareAcronym{SGD}{short=SGD, long=stochastic gradient descent}
\DeclareAcronym{SG-HMC}{short=SG-HMC, long=stochastic gradient Hamiltonian Monte Carlo}
\DeclareAcronym{SGLD}{short=SGLD, long=stochastic gradient Langevin dynamics}
\DeclareAcronym{SLLN}{short=SLLN, long=strong law of large numbers}
\DeclareAcronym{SoR}{short=SoR, long=subset of regressors}
\DeclareAcronym{SVG}{short=SVG, long=stochastic value gradients}
\DeclareAcronym{SVGD}{short=SVGD, long=Stein variational gradient descent}
\DeclareAcronym{SWA}{short=SWA, long=stochastic weight averaging}
\DeclareAcronym{SWAG}{short=SWAG, long=stochastic weight averaging-Gaussian}
\DeclareAcronym{Tanh}{short=Tanh, long=hyperbolic tangent}
\DeclareAcronym{TD}{short=TD, long=temporal difference}
\DeclareAcronym{TD3}{short=TD3, long=twin delayed DDPG}
\DeclareAcronym{TRPO}{short=TRPO, long=trust-region policy optimization}
\DeclareAcronym{UCB}{short=UCB, long=upper confidence bound}
\DeclareAcronym{ULA}{short=ULA, long=unadjusted Langevin algorithm}
\DeclareAcronym{VI1}{short=VI, long=value iteration}
\DeclareAcronym{VI2}{short=VI, long=variational inference}
\DeclareAcronym{WLLN}{short=WLLN, long=weak law of large numbers}

\acuseall
