\section{Related Works}
Classic data augmentations, such as rotations, translations, flipping, cropping, hue and saturation changes, etc., for training deep learning networks have been explored by \cite{7}, \cite{9}, \cite{24}, \cite{26}, \cite{27}. More advanced data augmentation strategies, such as mixup, cutmix, and cutout, have been explored by \cite{24}, \cite{25}, \cite{26}, \cite{30}. These strategies aim to combine various images from the training dataset to create augmented images that enhance the network's diversity. These strategies are similar to our approach in that regard, but they differ in the methodology used to achieve these combinations \cite{9}, \cite{6}, \cite{11}.

Steganography has also been extensively explored in the context of deep learning. The works in \cite{12}, \cite{13}, \cite{15}, \cite{16} have used neural techniques to improve the concealment of data in the naive implementation of steganography. These works \cite{18}, \cite{17}, \cite{22} employ generative models such as GANs, encoder-decoder architectures like the Variational Autoencoder (VAE), etc., to create diverse samples from the training distribution \cite{20}, \cite{21}, \cite{14}. These ideas have been explored together to achieve data augmentation, but to our knowledge, no works have adapted naive steganography as an embedding augmentation for downstream computer vision tasks, such as classification, and have shown their resemblance to traditional augmentation strategies in this context.