\section{Conclusion} \label{sec:conclusion}
This study focused on determining whether LLMs possess an understanding of the span of their own knowledge on specific topics. Notably, we observed that all models, if scaled sufficiently, know how many documents are authored by the same person. Consequently, these LLMs know how much they know about these individuals; otherwise, they would sporadically recall too few or too many documents.

More specifically, we find that this capability emerges based on the model's architecture, its size, the dataset's size used for training, and the effectiveness of the pre-trained weights in learning a solution that generalizes, rather than simply memorizing the training samples.

To the best of our knowledge, this is the first paper to explore this capability in LLMs, demonstrating that certain models can assess the extent of their knowledge on specific topics. Further research is required to determine whether this phenomenon is common across LLMs.

Overall, our research contributes to a deeper understanding of the capabilities and inner workings of these models. Grasping how aware LLMs are of their own knowledge and identifying any limitations in this regard is crucial, as this feature enhances the usefulness and trustworthiness of intelligent systems. Additional research is necessary to continue exploring this aspect.