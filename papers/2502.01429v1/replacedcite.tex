\section{Related Works}
For the fixed budget setting, Audibert et al.____ proposed the \texttt{UCB-E} and \texttt{Successive Rejects} (SR) algorithms and proved their optimality up to logarithmic factors. Specifically, the upper bound on the probability of error for their proposed algorithms is
%\begin{align}
    $p(T) \leq \frac{K (K-1)}{2} \exp\left(- \frac{T - K}{\log_2 (K) H_2}\right),$
%\end{align}
where $H_2$ is called the hardness of the problem that depends on the specific instance of $\nu \in \mathcal{N}$ (to be discussed in detail soon). In a remarkable result, Carpentier \& Locatelli____ proved the following lower bound for the probability of error in the fixed-budget setting:
%\begin{align}
       $p(T) \gtrsim \exp\left(-\frac{T}{\log(K) H}\right),$
%\end{align}
where $H$ is another variant of the hardness parameter. This disproved a long-standing assumptionâ€”that there must exist an algorithm for this problem whose probability of error is upper bound by $\exp(-T/H)$. This established a key difference between the fixed-confidence and the fixed-budget settings. Following this line of work, Karnin____ proposed the \texttt{SEQUENTIAL HALVING} ({SH}) algorithm and proved it to be almost optimal for BAI problems. This is achieved by eliminating half of the surviving arms with the worst estimates in each round. \ac{BAI} problem has also been analyzed using other variants of the \ac{UCB} algorithm (e.g., LUCB of ____) which are not based on eliminations. Most of the experimental results of these algorithms are present for bounded distributions, that are in fact particular examples of distributions with sub-Gaussian tails. Since then, the fixed budget pure exploration problem has been studied in a wide variety of contexts, e.g., for linear bandits____, minimax optimality____, spectral bandits____, risk-averse bandits____, and bandits with mis-specified linear models____. More recently, large deviation perspective was studied in____, cost-aware BAI in ____ and arm erasures in ____. Thompson sampling has also been employed to form the {\it best challenger} rule to improve the efficiency of \ac{BAI}____. Interesting new directions include combining the regret setting with the BAI setting, e.g., see____. Finally, assuming a distribution of $\nu$ over $\mathcal{N}$, researchers have studied rate-optimal Bayesian regret in \ac{BAI}____.