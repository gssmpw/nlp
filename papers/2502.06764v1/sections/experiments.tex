\section{Experiments}
\label{sec:experiments}

We empirically evaluate the performance of the \method and history guidance. We first validate the \mtd as a generic video model without history guidance (Sec.~\ref{sec:exp_ablation}), demonstrating the effectiveness of the modified training objective. Next, we examine the effectiveness and additional capabilities of history guidance~(Secs.~\ref{sec:exp_history_guidance} and \ref{sec:exp_temporal_guidance}). Finally, we showcase very long videos generated by \mtd with history guidance (Sec.~\ref{sec:exp_long_navigation}).


\subsection{Experimental Setup}
\label{sec:exp_setup}

\textbf{Datasets.} Throughout our experiments, we train and evaluate a separate \mtd model for each dataset as follows: Kinetics-600~(\citet{kay2017kinetics}, $128 \tighttimes 128$), a standard video prediction benchmark, RealEstate10K or RE10K~(\citet{zhou2018stereo}, $256 \tighttimes 256$), a dataset of real-world indoor scenes with camera pose annotations, and Minecraft~(\citet{yan2023temporally}, $256 \tighttimes 256$), a dataset of long-context Minecraft navigation videos with discrete actions. We employ Fruit Swapping, an imitation learning task adapted from Diffusion Forcing~\cite{chen2024diffusion} to test the combined ability to handle long-term memory and reactive behavior with a physical robot. Details are in \cref{app:exp_details_datasets}. We use Kinetics-600 for benchmarking and quantitative comparisons, and the other three for studying new applications.

\textbf{Baselines.} 
1) Standard Diffusion (SD): A single-task model trained for specific test history lengths following the standard conditional diffusion setup~\cite{gupta2023photorealistic, watson2024controlling}.
2) Binary-Dropout Diffusion (BD): An ablative baseline trained with framewise binary dropout for history guidance instead of independent per-frame noise levels. Note that BD requires \mtd's architecture as opposed to conditioning via adaptive LayerNorm to support flexible history lengths, effectively making it an ablation.
3) Full-Sequence Diffusion with Reconstruction Guidance (FS): An unconditional video diffusion model trained with maximum sequence length. Flexible-length conditioning is achieved during sampling via history replacement and reconstruction guidance~\cite{ho2022video}.

\textbf{Evaluation.}  To evaluate the overall video generation performance encompassing quality and diversity, we use Fr\'echet Video Distance~(FVD, \citet{unterthiner2018towards}). For a more detailed analysis of video quality, we use VBench~\cite{huang2024vbench}, which provides separate scores for different aspects such as frame quality, consistency, and dynamics. For highly deterministic tasks, we evaluate according to Learned Perceptual Image Patch Similarity~(LPIPS, \citet{zhang2018unreasonable}), computed frame-wise against the ground truth. Additional experimental details are provided in \cref{app:exp_details}.

\subsection{Evaluating the \method}
\label{sec:exp_ablation}
We validate \mtd as a competitive video generative model \emph{without} history guidance by answering the questions:
\begin{itemize}[noitemsep,leftmargin=*,topsep=0em]
    \item \textbf{Q1:} How does \mtd compare to the conventional video diffusion approach in standard video benchmarks?
    \item \textbf{Q2:} Does binary dropout diffusion (BD) perform competitively as an alternative training approach that also supports flexible history?
    \item \textbf{Q3:} Is \mtd empirically flexible enough to handle arbitrary sets of history frames?
    \item \textbf{Q4:} Can we fine-tine an existing model into \mtd?
\end{itemize}

We summarize quantitative and qualitative results in \cref{tab:comparison_quantitative} and \cref{fig:comparison_qualitative} respectively.

\textbf{Competitive Performance of \mtd (Q1) without Guidance.} 
\mtd outperforms all baselines, including single-task standard diffusion (SD), despite SD being optimized for the eval's specific history length. This demonstrates \mtd's flexibility without sacrificing task-specific performance, aligning with observations from~\cite{chen2024diffusion}.


\textbf{Limited Performance of Binary Dropout (Q2).} 
While BD enables flexible history conditioning, it suffers a significant performance drop compared to SD. Notably, BD produces artifacts and inconsistent generations (\cref{fig:comparison_qualitative}), highlighting its inefficiency as an alternative to \mtdâ€™s training objective. 

\textbf{Flexibility of \mtd (Q3).} 
We demonstrate \mtd's flexibility by tasking it with various video generation tasks on RE10K, such as future prediction, frame interpolation, and mixed history setups. As shown in \cref{fig:flexibility}, \mtd generates consistent, high-quality samples across all tasks.


\textbf{Fine-tune existing models into \mtd (Q4).} 
As discussed in Sec.~\ref{sec:dft}, an \mtd can be obtained by fine-tuning an existing video diffusion model. We fine-tune the full-sequence model on Kinetics-600 into a \mtd using only 12.5\% of the training cost. The fine-tuned model surpasses all baselines and performs comparably to the \mtd trained from scratch~(see Appendix \ref{app:exp_finetune} for detailed analysis). This confirms the feasibility of fine-tuning large foundation models into \mtd to support history guidance.

\subsection{Improving Video Generation via History Guidance}
\label{sec:exp_history_guidance}
We examine the effect of history guidance on video quality in terms of frame-wise quality, frame-to-frame consistency and dynamic degree of generated video. We benchmark 64-frame video generation using sliding window rollout on Kinetics-600, a challenging setup that requires outstanding consistency to avoid blowing up. Note that this is a setup where conventional image-to-video models struggle since they can only condition on the final generated frame to extend the video. We present quantitative and quantitative results in Figures~\ref{fig:history_guidance_metrics} and  \cref{fig:history_guidance_qualitative} respectively.

\textbf{Vanilla History Guidance.} We visualize samples generated with vanilla history guidance with increasing guidance scale in \cref{fig:vanilla_guidance}. \emph{Stronger history guidance consistently improves frame quality and consistency}, which is also reflected in their corresponding VBench scores in \cref{fig:history_guidance_quality,fig:history_guidance_consistency}. In \cref{fig:history_guidance_fvd}, we obtain the best FVD result with a small guidance scale of $\omega \tighteq 1.5$. Beyond that, FVD increases sharply, indicating a loss of diversity with higher guidance scales, similar to the quality-diversity trade-off of CFG.

\textbf{Fractional History Guidance.} Despite notable quality improvements, we observe that vanilla history guidance tends to generate \emph{static videos} at high guidance scales ($\omega \geq 3$), as illustrated in the top rows of \cref{fig:fractional_guidance}, with significantly less motion than ground truth in \cref{fig:history_guidance_dynamics}. Fractional history guidance resolves this in the side-by-side visualization. We find that \emph{guiding with lower frequencies (higher $\kH$) consistently increases dynamics while maintaining quality}, as shown in \cref{fig:fractional_guidance}. This further lowers the best FVD of vanilla history guidance (181.6) to 170.4, surpassing FS (1040), SD (247.5), and \mtd without guidance (208.0).

\subsection{New Abilities via Temporal History Guidance}
\label{sec:exp_temporal_guidance}

Temporal history guidance brings new capabilities to \mtd, allowing it to solve tasks impossible for previous models. We discuss three representative tasks.

\textbf{Task 1. Robust to Out-of-Distribution (OOD) History.} 
We evaluate robustness to OOD histories on RealEstate10K by creating scenarios with extreme camera rotations between history frames and ask the model to interpolate. Baselines fail to generalize, producing incoherent generations. In contrast, \mtd with temporal history guidance splits OOD histories into shorter, in-distribution subsequences, composing their scores to maintain both local and global dependencies. This enables \mtd to handle OOD histories effectively, as shown in \cref{fig:ood_history}.

\textbf{Task 2. Long Context Generation.}
Minecraft is a video dataset that requires long context to achieve good FVD scores. We found generating coherent videos with long contexts often leads to OOD histories. Baselines prioritize consistency with the context at the expense of quality. Our hypothesis is that temporal guidance blends scores from long-context and short-context models, balancing memory retention with robustness to OOD. This strategy improves FVD scores from 97.63 to 79.19, achieving long-term coherent high-quality generations. See \cref{app:exp_results_minecraft} for details.


\textbf{Task 3. Long-horizon yet Reactive Imitation Learning.}
We test on a robotic manipulation task requiring both long-term memory for object rearrangement and short-term reactivity for disturbances. Each data point in the dataset contains either of these two behaviors but never both. Baselines fail to integrate the two behaviors, while \mtd combines full-history scores (for memory) with single-frame scores (for reactivity) using temporal history guidance. This allows the robot to recover from disturbances and complete tasks, achieving a success rate of 83\% while baselines fail to perform the task completely. See Appendix~\ref{app:exp_results_robot} for details.

\subsection{Ultra Long Video Generation}
\label{sec:exp_long_navigation}
In \cref{fig:teaser}, we present a showcase that utilizes all of this paper's contributions - we extend a single image to an 862-frame video in RE10K. Even the most high-performing prior methods can only roll out for dozens of frames under the same setup. This is made possible by enhanced quality, consistency, and rollout stability through history guidance, plus \mtd's flexibility that enables this. See \cref{appendix:long_rollout_details} for more details and \cref{app:exp_results_navigation} for more samples (\cref{fig:navigation_1,fig:navigation_2,fig:navigation_3,fig:navigation_4}), including notable failures of other models.
