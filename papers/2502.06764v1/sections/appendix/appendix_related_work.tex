\section{Extended Related Work}
\label{app:related_work}


\subsection{History-conditioned Guidance}

In this section, we discuss how CFG is employed for guiding with history in video diffusion models. The most common case is in \textbf{Image-to-Video Diffusion Models}~\cite{blattmann2023stable,xing2023dynamicrafter,yang2024cogvideox}, where the model uses the \emph{first frame} for guidance. Typically, the conditioning frame is incorporated into the architecture by concatenating it channel-wise with each frame to be generated, and additionally, the CLIP~\cite{radford2021learning} embedding of the conditioning frame is used for cross-attention.

Few \textbf{Conditional Video Diffusion Models} have pushed the boundary by guiding with \emph{fixed set of few frames}. Specifically, VideoLDM~\cite{blattmann2023align} uses the first $\{1, 2\}$ frames for guidance, W.A.L.T.~\cite{gupta2023photorealistic} guides with the first 2 latent tokens, i.e. \{5\} frames, and 4DiM~\cite{watson2024controlling} guides with the first $\{1, 2, 8\}$ frames. Similarly, in \textbf{Multi-view Diffusion Models}, which is similar to video diffusion models but do not differentiate frame order, CAT3D~\cite{gao2024cat3d} guides with the first $\{1, 3\}$ frames. 

Architecturally, these models incorporate history frames in various ways. VideoLDM concatenates a binary mask, indicating whether each history frame is masked, along with all masked history frames, feeding them to every temporal layer using a learnable downsampling encoder. W.A.L.T. simplifies this by directly concatenating the history frames and binary mask to the noisy generation input, omitting the encoder. 4DiM and CAT3D process the entire sequence—both history and generation frames—as a single sequence, with a binary mask concatenated along the channel dimension to indicate whether each frame is masked.

In summary, guiding with history in video models has been explored to a limited extent. While these models differ in how they incorporate history frames into the architecture, they all process history frames separately from generated frames, except for 4DiM and CAT3D, leading to inflexibility of guidance. Additionally, these models are trained using CFG-style random dropout of history frames, which categorizes them as special cases of \emph{Binary-Dropout Diffusion}, shown to be suboptimal. These limitations are highlighted in \cref{sec:history_guidance_challenges}. In contrast, our work enables guiding with arbitrary, variable-length history frames without the need for binary-dropout training, facilitated by our modified training objective and architecture design.


    


