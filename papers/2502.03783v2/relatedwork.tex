\section{Related Work}
\label{Related Work}
\textbf{Ultrasound Bone Segmentation.} Numerous intensity-based bone segmentation methods have been developed \cite{review1,review2}. However, intensity-based methods face challenges in terms of robustness and accuracy. To mitigate these issues, frequency-based methods have been introduced, including phase symmetry and structured phase symmetry techniques \cite{phase_symmetry3,bone_shadow_and_phase}, which aim to enhance bone boundaries. With the advent of deep learning, neural network models such as CNNs, U-nets, and GANs have been employed for bone segmentation in ultrasound images, targeting various anatomical regions such as the spine \cite{spine1,spine2,spine3}, pelvis \cite{pelvis, pelvis_femur_tibia}, femur \cite{femur_fibula_tibia_humerus_radius_ulna,pelvis_femur_tibia,radius_femur_tibia}, tibia \cite{pelvis_femur_tibia,radius_femur_tibia,femur_fibula_tibia_humerus_radius_ulna}, fibula \cite{femur_fibula_tibia_humerus_radius_ulna}, and radius \cite{radius_femur_tibia,femur_fibula_tibia_humerus_radius_ulna}. These deep learning methods have demonstrated superior performance over traditional approaches in terms of accuracy, robustness, and runtime. For example, average bone surface distance errors have been reported to range from 0.2 mm to 1.7 mm \cite{radius_femur_tibia, SSM, spine3,pelvis}. Based on accurate 2D bone segmentation results, the reconstructed bone surfaces achieve sub-millimetric one-sided CD \cite{pcd2}. \textcolor{black}{However, these studies rely on manually annotated bone labels from expert surgeons. This process is time-consuming, costly, and requires specialized knowledge of ultrasound imaging and bone anatomy. In addition, different surgeons may also provide different labels for the same ultrasound image, leading to inconsistencies. As a result, the quality and the size of training datasets is limited, typically ranging from dozens to a few thousands of labeled images \cite{review2}. These constraints reduce model performance and generalizability.} In addition, the absence of standardized evaluation metrics, with over 18 different metrics in use \cite{review1}, further hinders effective model benchmarking and comparison. 

\textbf{Automatic labeling.} Optical tracking markers have been applied in the medical imaging community for collecting datasets with automatically generated labels, such as tracked spine CT models \cite{spineDepth} and surgical instruments \cite{markerless_tool_tracking}. So far, one previous work has attempted to automatically generate bone labels in ultrasound images using a tracked bone CT model \cite{pcd3}. However, their approach led to significant alignment errors due to error accumulation, ultimately requiring a fallback to manual labeling. \textcolor{black}{Traditional image-based multi-modal registration methods, such as CT-US registration in Imfusion Suite \footnote{https://www.imfusion.com/}, compute a transformation matrix to globally register one modality to another \cite{CT-US_registration}. These methods are highly dependent on initialization and global intensity distribution, which can lead to local minima. As we will demonstrate, these methods do not provide sufficient accuracy for automatic labeling. In contrast, our proposed method optimizes the alignment for each frame locally, resulting in more accurate bone labeling.}



% \textbf{3D Bone Reconstruction}. Bone segmentation of tracked ultrasound images enables 3D bone surface reconstruction. One simple yet effective representation is point clouds \cite{pcd1,pcd2,pcd3}. However, generating high-quality bone surface meshes often requires complex post-processing, such as statistical shape model (SSM) fitting \cite{SSM}, which depends on a database of target bone model meshes. Recently, deep learning models have been developed to generate more complete meshes directly from sparse point clouds benefiting from the inductive bias smoothness of neural networks \cite{neural_pull}. Chen et al. introduced FUNSR, a self-supervised neural implicit surface reconstruction model, to reconstruct femur and pelvis meshes from bone segmentations of tracked ultrasound images \cite{FUNSR}. To the best of our knowledge, this is the only work that reconstructs bone surface meshes from single-directional tracked bone segmentations in ultrasound images. While promising, this model has only been validated on bone phantoms. Additionally, FUNSR requires overfitting a neural network for each bone geometry, making the process time-consuming. Moreover, FUNSR generates closed bone meshes, even when the ground truth represents open surfaces. In this work, we propose a new method for reconstructing open bone surfaces from tracked bone segmentation that outperforms FUNSR in terms of both accuracy and runtime.