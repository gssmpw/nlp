\section{Introduction}
\label{sec:intro}

\begin{figure}[htbp]
\centering
\includegraphics[width=.95\columnwidth]{figure/pipeline_head.pdf}
   \caption{Comparison of (a) existing pose estimation approaches with (b) the proposed causal learning pipeline. The front-door adjustment is used to mitigate the negative effect from confounders. We also leverage rich 3D semantic knowledge to provide comprehensive category guidance.
   }
   \vspace{-0.4cm}
   \label{fig:head_fig}
\end{figure}

% \begin{figure*}[htbp]
%     \centering
%     % \small
%     \subfloat[Prompt for image encoder]{\includegraphics[width=.31\textwidth]{figure/radar.pdf}}\hspace{8pt}
%     \subfloat[Prompt for text encoder]{\includegraphics[width=.31\textwidth]{figure/pipeline.pdf}}\hspace{8pt}
%     \subfloat[Prompt for joint training]{\includegraphics[width=.31\textwidth]{figure/graph.pdf}}
%     \caption{\textbf{Illustration of prompt for different encoders}.
%     }
%     \label{fig:head_fig}
%     \vspace{-0.2cm}
% \end{figure*}

\textbf{C}ategory-level \textbf{o}bject \textbf{p}ose \textbf{e}stimation (COPE) aims to predict the 3D rotation, 3D translation and 3D metric size, for arbitrary objects within predefined categories. 
This task, unlike instance-level pose estimation~\cite{wang2019densefusion,zhou2021semi,he2021ffb6d,hai2023shape,li2024mrcnet,lin2024transpose}, dose not require high-quality CAD models, making it feasible to perceive a broader range of novel objects instead of a single instance.
In recent years, this task has garnered significant attention due to its essential role in various practical applications, including augmented reality~\cite{marchand2015pose}, autonomous driving~\cite{chen2017multi} and robotic manipulation~\cite{tremblay2018deep}, \etc.
% numerous

The core challenge of COPE lies in the complicated and diverse intra-category variations. To obtain robust category features and achieve accurate pose prediction, previous methods~\cite{di2022gpv,lin2022category,zheng2023hs,lin2023vi,lin2024clipose,liu2024mh6d,lin2024instance,chen2024secondpose,zheng2024georef} largely rely on deep neural networks (DNNs) due to their significant learning and modeling capabilities, offering impressive progress.
Although DNNs have demonstrated extraordinary performance in COPE, recent studies~\cite{ilyas2019adversarial,wang2024vision} reveal that they may focus on spurious correlations to benefit predictions, as their optimization objective is to learn statistical distribution only.
These illogical correlations in models are typically raised by the underlying \emph{confounders}~\cite{pearl2018book} behind the task, \eg, dataset biases~\cite{jung2024housecat6d,zhang2024omni6d}. Here, confounders are variables that influence both inputs and outcomes. 
DNN-based pose estimation models are sensitive to the confounders during data fitting, as shown in \cref{fig:head_fig}(a). For instance, the COPE models may overfit to specific objects' appearance and poses due to the lack of data variety in dataset, damaging the generalization to novel instances

Another important aspect of COPE neglected by previous works is the comprehensive category-specific guidance. Most of them~\cite{di2022gpv,lin2023vi,liu2023net,lin2024instance,chen2024secondpose} solely derive category information from a limited instances per category in training set, which may also capture only limited category diversity.
One way to tackle above two issues is to create broader and more diverse datasets~\cite{fu2022category,wang2022phocal,jung2024housecat6d,zhang2024omni6d}, though valuable, achieving a perfectly balanced dataset free of bias remains nearly impossible. Additionally, the dataset's scale is still significantly constrained by the cost of 3D data annotation~\cite{zhang2024pcp}.

To better address the dilemma, we direct our attention to the human observation mechanism. In fact, the reason why humans can effectively handle variations among intra-category objects is that we learn inherent causality beyond biased observation, achieving excellent analogical association capability.
Motivated by this finding, for the first time, we propose to incorporate the causal inference~\cite{pearl2009causality,pearl2016causal} into the formulation of COPE. In this way, we can investigate the causal relation among variables and equip COPE models with similar cognitive abilities that human have.
Technically, it is non-trivial to incorporate the causal learning in COPE applications because of the following challenges: (\textbf{i}) The unique modality of 3D data makes it impractical to directly apply existing causal modeling techniques~\cite{huang2024causalpc}. (\textbf{ii}) Subsequently, the confounders in pose estimation task are inherently unobserved and elusive, which further increases the challenge of identifying these confounders and mitigating their negative impacts. (\textbf{iii}) Moreover, enhancing the model's category generalization capability can not be overlooked. How to improve the generalization while simultaneously deconfoundering needs to be carefully considered.

To this end, we present \textbf{CleanPose}, a concise yet effective framework with \textbf{c}ausal \textbf{l}earning~\cite{pearl2009causality} and knowledg\textbf{e} distill\textbf{a}tio\textbf{n} to enhance the category-level \textbf{pose} estimation, as shown in \cref{fig:head_fig}(b).
Faced with the challenge that hidden confounders are elusive or even unobserved in our task, we propose to develop a causal inference approach based on \emph{front-door adjustment}, which can effectively approximate the predicted expectations by potential confounders.
Moreover, to create suitable dictionary for representing confounders, we devise and maintain the dictionary as a dynamic queue, similar with MoCo~\cite{he2020momentum}, to efficiently update training samples.
To further address the weakness in category information guidance, we design a residual-based feature knowledge distillation layer to transfer abundant point cloud category information of powerful 3D foundation model, ULIP-2~\cite{xue2024ulip}, to guide the category feature learning within the model.
As demonstrated by extensive experiments, our findings reveal the impact of integrating causal learning to deconfound biases, and providing comprehensive category information on COPE, enhancing the model's robustness and generalization.

To summarize, our main contributions are as follows:
\begin{itemize}
    \item We propose CleanPose, a pioneering solution to mitigate the confoundering effect in category-level pose estimation via causal learning. Taking inspiration from human observation mechanism, we propose to identify the causal effect to achieve unbiased estimation, recovering correct pose of novel instances within category.
    % \item We for the first time introduce causal learning into category-level pose estimation tasks to eliminate the elusive confounders, enabling the model the model to achieve unbiased estimation.
    \item We develop a residual category knowledge distillation approach to transfer rich 3D category knowledge from 3D foundation models into category-level networks, enhancing the intra-category generalization. 
    \item Our proposed CleanPose achieves state-of-the-art performance on three mainstream challenge benchmarks (REAL275~\cite{wang2019normalized}, CAMERA25~\cite{wang2019normalized} and HouseCat6D~\cite{jung2024housecat6d}). For instance, the accuracy attains \textbf{61.5\%} on rigorous metric 5Â°2 \emph{cm} of REAL275 dataset, surpassing the current best method with a large margin by 4.5\%.
    % , which demonstrates the effectiveness of proposed framework.
\end{itemize}

% To achieve efficient and accurate category-level pose estimation, numerous methods~\cite{wang2019normalized,tian2020shape,di2022gpv,lin2022category,zheng2023hs,lin2023vi,lin2024clipose,liu2024mh6d,lin2024instance,chen2024secondpose,zheng2024georef} have emerged, offering impressive progress. 
% % are primarily developed to address complicated and diverse intra-category variations. 
% However, despite the growing research interest for robust and precise category-level models, there has been little discussion on the underlying \emph{confounders}~\cite{pearl2018book} (\eg, dataset biases~\cite{jung2024housecat6d,zhang2024omni6d}) and essential causal logic behind the task.

% State-of-the-art category-level pose estimation methods primarily focus on model design and optimization (\eg, studying point clouds~\cite{zheng2023hs,zheng2024georef,lin2024instance} or feature fusion~\cite{chen2024secondpose,liu2024mh6d}) to extract more robust category-level features, however, typically overlook potential spurious causality in models raised by confounders. Here, confounders are variables that influence both inputs and outcomes, creating illogical correlations and biases.
% For instance, the models may overfit to specific appearance and poses due to the lack of data variety. Additionally, numerous similar samples may also mislead the models to focus on spurious pose correlations that benefit the prediction, damaging the model generalization.
% What's more, the confounders in pose estimation task are inherently unobserved and elusive, which further increases the challenge of debiasing.
% One way to tackle this problem is to create broader and more diverse datasets~\cite{fu2022category,wang2022phocal,jung2024housecat6d,zhang2024omni6d}, though valuable, realizing a perfectly balanced dataset free of bias remains nearly impossible.
% In fact, the reason why humans can effectively handle variations among intra-category objects is that we learn reasonable causality beyond biased observation. 
% Hence, how to develop such a causal inference abilities for pose estimation model is the key to mitigate the confoundering effects and achieve unbiased pose prediction.
% % How to mitigate the confoundering effects is the key to help models learn reasonable causality and handle variations among intra-category objects.

% Another important aspect of category-level models caused by dataset is the effective category-specific guidance.
% In fact, most of existing works obtain category information solely from limited training data.
% Some methods~\cite{di2022gpv,lin2023vi,liu2023net,lin2024instance,chen2024secondpose} learn category features via designed module directly, while others~\cite{tian2020shape,lin2022category,liu2024mh6d,zheng2024georef} leverage \emph{shape prior}~\cite{tian2020shape}, \ie, the mean shape, to propagate category information within networks.
% This efforts, though effective, only achieve limited category generalization.
% % Some previous works~\cite{tian2020shape,lin2022category,liu2024mh6d,zheng2024georef} propagate category information via \emph{shape prior}, which has been
% % proven not to be a critical factor~\cite{liu2023net} in category-level tasks. While other methods~\cite{di2022gpv,lin2023vi,lin2024instance,chen2024secondpose} focus on learning category features from existing training data, though effective, only obtain limited category generalization.
% Further, CLIPose~\cite{lin2024clipose} utilizes pre-trained category semantic information from both image and text modalities to provide guidance. Nevertheless, the knowledge from other modality remains unintuitive for point cloud models.
% How to provide comprehensive category information guidance for model needs to be carefully considered to achieve better generalization on novel instances.





