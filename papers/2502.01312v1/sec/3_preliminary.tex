\section{Preliminary}
\label{sec:Preliminary}
\subsection{Task Formulation}
\label{sec:task_formulation}
Given an RGB-D image containing objects from a predefined set of categories, off-the-shelf segmentation models such as MaskRCNN~\cite{he2017mask} are employed to obtain masks and category labels for each object in the images. Then, the segmentation masks can be utilized to get the cropped RGB image $\mathcal{I}_{obj} \in \mathbb{R}^{H \times W \times 3}$ and the point cloud $\mathcal{P}_{obj} \in \mathbb{R}^{N \times 3}$, where $N$ is the number of points and $\mathcal{P}_{obj}$ is acquired by back-projecting the cropped depth image with camera intrinsics followed by a downsampling process. With the input $\mathcal{I}_{obj}$ and $\mathcal{P}_{obj}$, the objective of COPE~\cite{wang2019normalized} is to recover the 9DoF poses, including the 3D rotation $\mathcal{R} \in SO(3)$, the 3D translation $t \in \mathbb{R}^3$ and 3D metric size $s \in \mathbb{R}^3$.

% the objective of COPE~\cite{wang2019normalized} is to detect all instances of objects present in the scene and accurately estimate their 9DoF poses, including the 3D rotation $\mathcal{R} \in SO(3)$, the 3D translation $t \in \mathbb{R}^3$ and 3D metric size $s \in \mathbb{R}^3$.
% Specifically, off-the-shelf segmentation models such as MaskRCNN~\cite{he2017mask} are employed to obtain masks and category labels for each object in the images. Then, the segmentation masks can be utilized to get the cropped RGB image $\mathcal{I}_{obj} \in \mathbb{R}^{H \times W \times 3}$ and the point cloud $\mathcal{P}_{obj} \in \mathbb{R}^{N \times 3}$, where $N$ is the number of points and $\mathcal{P}_{obj}$ is acquired by back-projecting the cropped depth image with camera intrinsics followed by a downsampling process. With the input $\mathcal{I}_{obj}$ and $\mathcal{P}_{obj}$, the proposed method can recover the final 9DoF pose.

\subsection{The Causal Modeling of CleanPose}
\label{sec:casual_modeling}
To quantify the underlying logic behind human observation, we construct a structural causal model~\cite{pearl2009causality,pearl2016causal} capturing the relationships among the key variables in COPE: visual input $\mathcal{X}$, output pose $\mathcal{Y}$, mediator $\mathcal{M}$ and hidden confounders $\mathcal{U}$.
We illustrate the causal model in \cref{fig:causal_model}, where each direct link denotes a causal relationship between two nodes.
\begin{itemize}
    \item $\mathcal{X}\rightarrow\mathcal{M}\rightarrow\mathcal{Y}$ (\emph{Front-door path}): Typically, humans first recognize the structural information of an object, \ie, keypoints~\cite{lin2024instance,zheng2023hs}, and then determine the object's pose based on the similar poses of other objects within this category. This process involves identifying keypoints of the object and their relative positions, and leveraging this information to perform pose estimation. We use mediator $\mathcal{M}$ to represent such structural information and describe such process via the causal path $\mathcal{X} \rightarrow \mathcal{M} \rightarrow \mathcal{Y}$, which is  also referred to as the \emph{front-door path}. 
    % Due to the insertion of $\mathcal{M}$, this path can be divided into two parts: a \textbf{keypoints extractor} $\mathcal{X} \rightarrow \mathcal{M}$ and a \textbf{pose estimator} $\mathcal{M} \rightarrow \mathcal{Y}$.
    % \item \emph{Mediators knowledge extraction} ($\mathcal{X} \rightarrow \mathcal{M}$): Typically, humans recognize the relevant knowledge, \eg, object keypoints~\cite{lin2024instance,zheng2023hs}, to determine objects' pose approximately. This process involves identifying the main parts of the object and other features like symmetry based on humans prior knowledge.
    % \item \emph{Pose estimation} ($\mathcal{M} \rightarrow \mathcal{Y}$): With the suitable knowledge $\mathcal{M}$ from $\mathcal{X}$, the pose predictor can exploit $\mathcal{M}$ to predict final object's pose $\mathcal{Y}$. Specifically, humans recall similar pose of other objects within this category. The overall causal inference path $\mathcal{X} \rightarrow \mathcal{M} \rightarrow \mathcal{Y}$ is referred to as the front-door path.
    \item $\mathcal{X} \leftarrow \mathcal{U} \rightarrow \mathcal{Y}$ (\emph{Hidden confounders}): The confounders are extraneous variables that influence both inputs and outputs, \eg, dataset biases~\cite{jung2024housecat6d,zhang2024omni6d} or category specific attributes~\cite{tian2020shape}. $\mathcal{U} \rightarrow \mathcal{X}$ exists because the input data is inevitably affected by the limited resources in real world and sampling noises from sensors when collection and simulation. Moreover, $\mathcal{U} \rightarrow \mathcal{Y}$ emerges because collected scenes, annotation bias, or the variety of pose also affect the probability of pose distributions. Traditional DNNs-based COPE methods tend to model the statistical correlations $P(\mathcal{Y}|\mathcal{X})$, given the optimization goal of maximizing the pose accuracy~\cite{zheng2024georef}. With the lack of modeling of hidden confounders, no matter how large the amount of training data is, the model can not identify the ture causal effect from $\mathcal{X}$ to $\mathcal{Y}$.
    % such a naive objective would mislead DNNs to rely on a spurious shortcuts solution where the negative impact of $\mathcal{U}$ spreads to the pose estimation through the causal path $\mathcal{X} \leftarrow \mathcal{U} \rightarrow \mathcal{Y}$.
\end{itemize}


% \subsection{Defects of Existing Models}
% \label{sec:existing_defects}
% Based on the above causal graph, 