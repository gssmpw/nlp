\section{Experiments}
\label{sec:Experiments}

{\bf Datasets.} Following previous works~\cite{lin2023vi,lin2024instance,lin2024clipose,zheng2024georef,chen2024secondpose}, we conduct experiments not only on two mainstream NOCS benchmarks, REAL275~\cite{wang2019normalized} and CAMERA25~\cite{wang2019normalized} as well as HouseCat6D~\cite{jung2024housecat6d} datasets.
REAL275 is a challenge real-world dataset that contains objects from 6 categories. The training data consists of 4.3k images from 7 scenes, while testing data includes 2.75k from 6 scenes and 3 objects from each category.
CAMERA25 is a synthetic dataset that ontains the same categories as REAL275. It provides 300k synthetic RGB-D images of objects rendered on virtual background, with 25k images are withhold for testing.
HouseCat6D is a comprehensive multi-modal real-world dataset and encompasses 10 household categories.
% , including photometrically challenging objects like glass and cutlery, with occlusions. 
The training set consists of 20k frames from 34 scenes and testing set consists of 3k frames across 5 scenes. With a total of 194 objects, each category contains 19 objects on average.


\noindent
{\bf Evaluation Metrics.} Following~\cite{chen2024secondpose,lin2024instance}, we evaluate the model performance with two metrics. (\textbf{i}) \textbf{3D IoU}. As for NOCS dataset, we report mean average precision (mAP) of CATRE~\cite{liu2022catre} Intersection over Union (IoU) with the thresholds of 75\%. For the HouseCat6D dataset, we report the mAP of 3D IoU under thresholds of 25\% and 50\%. (\textbf{ii}) \textbf{n°m \emph{cm}}.  We also utilize the combination of rotation and translation metrics of 5°2 \emph{cm}, 5°5 \emph{cm}, 10°2 \emph{cm} and 10°5 \emph{cm}, which means the estimation is considered correct when the error is below a threshold. 
% \begin{itemize}
%     \item 3D IoU. As for NOCS dataset, we report mean average precision (mAP) of CATRE~\cite{liu2022catre} Intersection over Union (IoU) with the thresholds of 75\%. For the HouseCat6D dataset, we report the mAP of 3D IoU under thresholds of 25\% and 50\%.
%     \item n°m \emph{cm}.  We also utilize the combination of rotation and translation metrics of 5°2 \emph{cm}, 5°5 \emph{cm}, 10°2 \emph{cm} and 10°5 \emph{cm}, which means the estimation is considered correct when the error is below a threshold. 
% \end{itemize}

\begin{table*}[htbp]
    \small
    \centering
    \setlength\tabcolsep{8pt}%2pt 列宽
    % \renewcommand\arraystretch{1.0} % 行高
    \begin{tabular}{l|c|c|cccc}
    \toprule%[1.2pt]
     Methods & Venue/Source & $IoU_{75}^*$$\uparrow$ & 5°2\emph{cm}$\uparrow$ & 5°5\emph{cm}$\uparrow$ & 10°2\emph{cm}$\uparrow$ & 10°5\emph{cm}$\uparrow$ \\
    \midrule%[1pt]
    SPD\cite{tian2020shape}     &  ICCV'20       & 27.5        & 19.3         & 21.4        & 43.2       & 54.1                     \\
    % SGPA\cite{chen2021sgpa}   &  ICCV'21     & -          & 80.1 & 61.9        & 35.9 & 39.6         & 61.3 & 70.7           & - & 6.58                                  \\
     %\hline
    DualPoseNet\cite{lin2021dualposenet}   &  ICCV'21     & 30.8        & 29.3         & 35.9        & 50.0       & 66.8               \\
    GPV-Pose\cite{di2022gpv}    &   CVPR'22   & 23.1         & 32.5 & 43.3         & 58.2 & 76.6                                          \\
    6D-ViT\cite{zou20226d}    &  TIP'22     & 33.3         & 38.2 & 41.9         & 59.1 & 67.9          \\
    HS-Pose\cite{zheng2023hs}    &   CVPR'23      &39.1       & 45.3          &54.9         & 68.6         & 83.6       \\
    IST-Net\cite{liu2023net}    &  ECCV'23       &-       & 47.8         &55.1        & 69.5        & 79.6      \\
    VI-Net\cite{lin2023vi}    &   ICCV'23        &48.3       & 50.0          &57.6         & 70.8        & 82.1     \\
    CLIPose\cite{lin2024clipose}  &   TCSVT'24   & - & 48.5         & 58.2 & 70.3 & 85.1 \\
    GenPose\cite{zhang2023genpose}    &   NeurIPS'23    &-       & 52.1          &60.9         & 72.4        & 84.0      \\
    HS + GeoReF\cite{zheng2024georef}    &   CVPR'24     &54.3       & 51.7          &59.6         & 74.3        & 83.3      \\
    SPD + GeoReF\cite{zheng2024georef}    &   CVPR'24     &51.8       & 54.4          &60.3         & 71.8       & 79.4       \\
    MH6D\cite{liu2024mh6d}    &   TNNLS'24       &54.2       & 53.0          &61.1         & 72.0       & 82.0      \\
    SecondPose\cite{chen2024secondpose}    &   CVPR'24       &49.7       & 56.2          &63.6         & 74.7       & {\ul86.0}     \\
    AG-Pose\cite{lin2024instance}    &   CVPR'24      &{\ul61.3}       & {\ul57.0}         &{\ul64.6}         & {\ul75.1}       & 84.7      \\
     %\hline
    \midrule%[1pt]
    % \rowcolor{mygray}
    % \rowcolor{mygray}
    \textbf{CleanPose (ours)}    &          & \textbf{62.6} & \textbf{61.5}         & \textbf{67.4} & \textbf{78.3} & \textbf{86.2}  \\
    \bottomrule%[1.2pt]
    \end{tabular}
    \vspace{-0.2cm}
    \caption{\textbf{Comparisons with state-of-the-art methods on REAL275 dataset.} $\uparrow$: a higher value indicating better performance. ‘*’ denotes CATRE~\cite{liu2022catre} IoU metrics and ‘-’ means unavailable statistics. Overall best results are in \textbf{bold} and the second best results are {\ul underlined}.
    }
    \vspace{-0.4cm}
    \label{tab:compare_sota}
\end{table*}
% \footnotetext{Throughout the comparison in all experiments, we use the result suggested by the AG-Pose official implementation, which is higher than reported result in the original paper.}
%
\begin{table}[htbp]
    \small
    \centering
    \setlength\tabcolsep{3pt}%2pt 列宽
    % \renewcommand\arraystretch{1.2} % 行高
    \begin{tabular}{l|c|ccccc}
    \toprule%[1.2pt]
   Methods & $IoU_{75}^*$  & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm}  & 10°5\emph{cm} \\
    \midrule%[1pt]
    SPD\cite{tian2020shape}        & -              & 54.3      &59.0          & 73.3    &81.5     \\
    DualPoseNet\cite{lin2021dualposenet}                       &-                &64.7        & 70.7           &77.2    &84.7    \\
    SGPA\cite{chen2021sgpa}                       &-                &70.7        & 74.5           &82.7    &88.4    \\
    % RBP-Pose\cite{zhang2022rbp}         & -             & 73.5      & 79.6          & 82.1   &89.5    \\
    HS-Pose\cite{zheng2023hs}               & -             & 73.3      & 80.5          & 80.4    & 89.4     \\
    CLIPose\cite{lin2024clipose}                  &-             & 74.8     & 82.2         & 82.0    &  91.2     \\
    GeoReF\cite{zheng2024georef}                  &79.2             & 77.9     & {\ul84.0}         & 83.8    & 90.5     \\
    AG-Pose\cite{lin2024instance}                  &\textbf{81.2}              & {\ul79.5}     & 83.7         & {\ul87.1}    & {\ul92.6}     \\
    \midrule
    % \rowcolor{mygray}
    \textbf{CleanPose (ours)}                   &{\ul80.7}             & \textbf{80.3}     & \textbf{84.2}         & \textbf{87.7}    &  \textbf{92.7}     \\
    \bottomrule%[1.2pt]
    \end{tabular}
    \vspace{-0.2cm}
    \caption{\textbf{Comparisons with state-of-the-art methods on CAMERA25 dataset.} A higher value indicating better performance. ‘*’ denotes CATRE~\cite{liu2022catre} IoU metrics and ‘-’ means unavailable statistics.  Overall best results are in \textbf{bold} and the second best results are {\ul underlined}.
    }
    \vspace{-0.2cm}
    \label{tab:compare_sota_camera}
\end{table}
\begin{table}[htbp]
    \small
    \centering
    \setlength\tabcolsep{1.8pt}%2pt 列宽
    % \renewcommand\arraystretch{1.2} % 行高
    \begin{tabular}{l|cc|cccc}
    \toprule%[1.2pt]
     Methods & $IoU_{25}$ & $IoU_{50}$ & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm} & 10°5\emph{cm} \\
    \midrule%[1pt]
    FS-Net\cite{chen2021fs}     &  74.9       & 48.0        & 3.3         & 4.2        & 17.1       & 21.6                     \\
    GPV-Pose\cite{di2022gpv}    &   74.9   & 50.7        & 3.5 & 4.6          & 17.8 & 22.7                                          \\
    VI-Net\cite{lin2023vi}    &   80.7        &56.4       & 8.4          &10.3         & 20.5        & 29.1     \\
    % AG-Pose-res\cite{lin2024instance}    &   82.4      &66.0  & 40.5	     & 11.5         &12.6         & 37.4       &42.5      \\
    SecondPose\cite{chen2024secondpose}    &   83.7       &66.1       & 11.0          &13.4         & 25.3       & 35.7      \\
    AG-Pose\cite{lin2024instance}    &   {\ul88.1}      &{\ul76.9}      & {\ul21.3}         &{\ul22.1}         & {\ul51.3}       &{\ul54.3}      \\
     %\hline
    \midrule%[1pt]
    % \rowcolor{mygray}
    % \rowcolor{mygray}
    \textbf{CleanPose (ours)}    &  \textbf{89.2}        & \textbf{79.8}    & \textbf{22.4}         & \textbf{24.1} & \textbf{51.6} & \textbf{56.5}  \\
    \bottomrule%[1.2pt]
    \end{tabular}
    \vspace{-0.2cm}
    \caption{\textbf{Comparisons with state-of-the-art methods on HouseCat6D dataset.} A higher value indicating better performance. Overall best results are in \textbf{bold} and the second best results are {\ul underlined}.
    % Multi-stage methods require multiple steps to train the network while single-stage methods directly regress object pose with end-to-end manner.
    }
    \vspace{-0.4cm}
    \label{tab:compare_sota_housecat6d}
\end{table}

\noindent
{\bf Implementation Details.} 
For a fair comparison, we utilize the same segmentation masks as AG-Pose~\cite{lin2024instance} and DPDN~\cite{lin2022category} from MaskRCNN~\cite{he2017mask} and resize them to $224 \times 224$. 
For model parameters, the feature dimensions are set as $C_1 = C_2 =$ 128, $C_3 =$ 768 and $C =$ 256, respectively. The number of point $N$ in point cloud is 1024 and the number of keypoints $N_{kpt}$ is set as 96. In dynamic queue, we set the size of queue $N_q$ to 80 and randomly select $N_{s} = 12$ features. 
For the use of pre-trained 3D models of ULIP-2, we apply PointBert~\cite{yu2022point} for knowledge distillation and employ PointNet++~\cite{qi2017pointnet++} for queue construction.
For the hyper-parameters setting, the balancing parameter $\mu$ in residual network is set as 0.1 following~\cite{huang2024froster}, and $\alpha_1$, $\alpha_2$ in overall loss function are 1 and 0.01, respectively.
For model optimizing, we employ the same data augmentation approach as previous works~\cite{lin2024instance,lin2022category}, which leverage random rotation degree sampled from $U$(0, 20) and rotation $\Delta t \sim U$(-0.02, 0.02) and scaling $\Delta s \sim U$(-0.18, 1.2).
The network is training on a single NVIDIA L40 GPU for a total of 120k iterations by the Adam~\cite{kingma2014adam} optimizer, with a mini training batch is 24 and a learning rate range from 2e-5 to 5e-4 based on triangular2 cyclical schedule~\cite{smith2017cyclical}.

\subsection{Comparison with State-of-the-Art Methods}
\label{sec:compare_sota}
As shown in \cref{fig:radar}, our method outperforms existing sota methods across multiple key metrics in different datasets.

\noindent
{\bf Performance on REAL275 dataset.}
The comparisons between proposed CleanPose and previous methods on challenging REAL275 dataset are shown in \cref{tab:compare_sota}.
As can be easily observed, our CleanPose achieves the state-of-the-art performance in all metrics and outperforms all previous methods on REAL275 dataset.
Significantly, we achieve the precision of \textbf{61.5\%}, \textbf{67.4\%} and \textbf{78.3\%} in the rigorous metric of 5°2 \emph{cm}, 5°5 \emph{cm} and 10°2 \emph{cm}, surpassing the current state-of-the-art method AG-Pose\footnote{Throughout the comparison in all experiments, we use the result suggested by the AG-Pose~\cite{lin2024instance} official implementation, which is higher than reported result in the original paper.}~\cite{lin2024instance} with a large margin by 4.5\%, 2.8\% and 3.2\%, respectively.
Moreover, the qualitative results of AG-Pose and proposed CleanPose are shown in \cref{fig:vis}. It can be observed that our method achieves significantly higher precision.
These exceptional outcomes further support the efficacy of our approach.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\columnwidth]{figure/radar.pdf}
   \caption{Comparison of CleanPose with sota methods.
   }
   \vspace{-0.3cm}
   \label{fig:radar}
\end{figure}

\begin{figure}[htbp]
\includegraphics[width=\columnwidth]{figure/vis.pdf}
   \caption{Qualitative comparison on REAL275~\cite{wang2019normalized}. We compare the predictions of CleanPose and the baseline AG-Pose~\cite{lin2024instance}. The ground truth is marked by white borders. 
   }
   \vspace{-0.4cm}
   \label{fig:vis}
\end{figure}

%---------------------------------------------------------------------------%
\noindent
{\bf Performance on CAMERA25 dataset.}
The results comparison of our method and the state-of-the-art is presented in \cref{tab:compare_sota_camera}. 
From the observation of results, it can be deduced that CleanPose ranks top performance across all the metrics except $IoU_{75}$, in which our method also achieves comparable performance with the best (80.7\% \vs 81.2\%). 
In detail, the proposed CleanPose achieves 80.3\% on 5°2 \emph{cm}, 84.2\% on 5°5 \emph{cm}, 87.7\% on 10°2 \emph{cm} and 92.7\% on 10°5 \emph{cm}, respectively. 
This superior performance on synthetic dataset further proves the effectiveness of our method. 

\begin{table}[htbp]
    \small
    \centering
    \setlength\tabcolsep{3pt}%2pt 列宽
    % \renewcommand\arraystretch{1.2} % 行高
    \begin{tabular}{c|c|c|cccc}
    \toprule%[1.2pt]
   ID & Causal & Distillation & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm}  & 10°5\emph{cm} \\
    \midrule%[1pt]
    1        &\ding{55}      &  \ding{55}     &57.0          & 64.6    &75.1  &84.7   \\
    2        &\ding{51}      &  \ding{55}      & 59.7          &66.5    &77.9 &85.1   \\
    3         &\ding{55}     &\ding{51}        & 58.9        &66.1    &76.3 &85.9   \\
    \rowcolor{mygray}
    4         & \ding{51}             & \ding{51}      & \textbf{61.5}          & \textbf{67.4}   &\textbf{78.3} &\textbf{86.2}   \\
    \bottomrule%[1.2pt]
    \end{tabular}
    \vspace{-0.2cm}
    \caption{Effect of causal learning and knowledge distillation.
    }
    \vspace{-0.2cm}
    \label{tab:ablation_main}
\end{table}

\begin{table}[htbp]
    \small
    \centering
    % 将每个子表格在单独的行上排列
    \begin{subtable}[t]{1.0\linewidth}  % 子表格宽度可调节
        \centering
        \setlength\tabcolsep{3pt}%2pt 列宽
        \begin{tabular}{cc|cccc}
            % \hline
            \toprule
            Data & Update & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm}  & 10°5\emph{cm}\\
            % \hline
            \midrule
            \rowcolor{mygray}
            Queue  & FIFO  & \textbf{61.5}          &\textbf{67.4}    &\textbf{78.3} &\textbf{86.2}    \\
            Queue & w/o update  & 57.1          &63.1    &77.5 &85.7   \\
            Queue & Similarity  & 59.1         &65.8    &77.6 &86.0   \\
            Memory bank & w/o update  & 57.6          &64.4    &75.6 &83.8   \\
            Memory bank & Similarity  &  58.1         &65.4    &77.5 &86.1   \\
            % \hline
            \bottomrule
        \end{tabular}
        \caption{Effect of different feature storage methods and update strategies.}
        \label{tab:ab_causal_data_update}
    \end{subtable}
    
    %  \vspace{0.2cm}  % 每个子表格之间增加垂直间距
     
    % \begin{subtable}[t]{1.0\linewidth}  % 子表格宽度可调节
    %     \centering
    %     \setlength\tabcolsep{10pt}%2pt 列宽
    %     \begin{tabular}{c|cccc}
    %         \toprule
    %         $N_{q}$ & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm}  & 10°5\emph{cm}\\
    %         \midrule
    %         20  & 57.0          & 64.6    &75.1  &84.7   \\
    %         50 & 60.5          &66.5    &77.9 &\textbf{86.4}   \\
    %         \rowcolor{mygray}
    %         80 & \textbf{61.5}          &\textbf{67.4}    &\textbf{78.3} &86.2   \\
    %         200  &59.4          &66.1    &78.0 &85.9   \\
    %         500  &  58.8         &65.3    &76.8 &85.8   \\
    %         1000  & 58.3          &66.8    &76.3 &86.2   \\
    %         3000  & 57.7          &65.5    &75.6 &85.0   \\
    %         10000  & 57.0          &65.0    &75.7 &85.4   \\
    %         \bottomrule
    %     \end{tabular}
    %     \caption{Effect of varying queue lengths $N_{q}$}
    %     \label{tab:ab_causal_Nq}
    % \end{subtable}

     \vspace{0.2cm}  % 每个子表格之间增加垂直间距

    \begin{subtable}[t]{1.0\linewidth}  % 子表格宽度可调节
        \centering
        \setlength\tabcolsep{9pt}%2pt 列宽
        \begin{tabular}{c|cccc}
            \toprule
            ~ & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm}  & 10°5\emph{cm}\\
            \midrule
            w/o fusion  & 58.5          &65.2    &\textbf{79.0} &\textbf{86.5}   \\
            \rowcolor{mygray}
            w/ fusion & \textbf{61.5}          &\textbf{67.4}    &78.3 &86.2    \\
            \bottomrule
        \end{tabular}
        \caption{Effect of adaptive weight fusion in front-door adjustment.}
        \label{tab:ab_causal_fusion}
    \end{subtable}

    \vspace{0.2cm}  % 每个子表格之间增加垂直间距
    
    \begin{subtable}[t]{1.0\linewidth}  % 子表格宽度可调节
        \centering
        \setlength\tabcolsep{7.5pt}%2pt 列宽
        \begin{tabular}{c|cccc}
            \toprule
            Policies & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm}  & 10°5\emph{cm}\\
            \midrule
            Contrastive  & 55.3          &63.1    &76.2 &86.0   \\
            MLP & 56.4          &63.1    &77.6 &85.9   \\
            \rowcolor{mygray}
            MLP + residual & \textbf{61.5}          &\textbf{67.4}    &\textbf{78.3} &\textbf{86.2}   \\
            \bottomrule
        \end{tabular}
        \caption{Effect of distinct feature distillation policies.}
        \label{tab:ab_dis_layer}
    \end{subtable}

    \vspace{0.2cm}  % 每个子表格之间增加垂直间距

    \begin{subtable}[t]{1.0\linewidth}  % 子表格宽度可调节
        \centering
        \setlength\tabcolsep{7pt}%2pt 列宽
        \begin{tabular}{c|cccc}
            \toprule
            3D Encoder & 5°2\emph{cm} & 5°5\emph{cm} & 10°2\emph{cm}  & 10°5\emph{cm}\\
            \midrule
            PointNet++\cite{qi2017pointnet++}  & 57.6          &65.3    &75.0 &84.4   \\
            PointMLP\cite{ma2022rethinking} & 57.0          &64.3    &77.4 &\textbf{86.2}   \\
            \rowcolor{mygray}
            PointBert\cite{yu2022point} & \textbf{61.5}          &\textbf{67.4}    &\textbf{78.3} &\textbf{86.2}   \\
            \bottomrule
        \end{tabular}
        \caption{Effect of different 3D encoders of ULIP-2~\cite{xue2024ulip} for distillation.}
        \label{tab:ab_dis_encoder}
    \end{subtable}
    \vspace{-0.2cm}
    \caption{Ablation studies on key details. Default settings are colored in \colorbox{mygray}{gray}.}
    \vspace{-0.4cm}
    \label{table:ablation_detail}
    
\end{table}


\noindent
{\bf Performance on HouseCat6D dataset.}
In \cref{tab:compare_sota_housecat6d}, we evaluate our method on HouseCat6D~\cite{jung2024housecat6d} dataset.
The proposed CleanPose again achieves state-of-the-art performance in all metrics. In detail, our method outperforms the current best method AG-Pose~\cite{lin2024instance} by 2.9\% on $IoU_{50}$, 1.1\% on 5°2 \emph{cm}, 2.0\% on 5°5 \emph{cm} and 2.1\% on 10°5 \emph{cm}, respectively.
The overall and category-wise evaluation of 3D IoU on HouseCat6D dataset is provided in \emph{supplementary material}.




\subsection{Ablation Studies}
\label{sec:ablation_studies}
We conduct ablation experiments to demonstrate the effectiveness of the proposed method on the REAL275 dataset~\cite{wang2019normalized}.


% \vspace{0.1cm}
\noindent
{\bf Effect of Causal Learning and Knowledge Distillation.} In \cref{tab:ablation_main}, we perform ablations of the proposed two main components. We adopt AG-Pose~\cite{lin2024instance} as our baseline, which servers as the current sota framework in COPE.
The results indicate that the integration of causal inference or knowledge distillation leads to significant enhancements in the model’s performance. This strongly demonstrates causal learning's considerable potential and the effectiveness of comprehensive category information guidance in COPE.

\noindent
{\bf Effect of different feature storage methods and update strategies.} In \cref{tab:ab_causal_data_update}, we investigate the impact of distinct combinations of feature storage and update strategies. “Similarity” represents updating the closest features via similarity computation. 
The results indicate that employing the dynamic queue and FIFO update mechanism yields the best performance. 
We owe the advantage to the dynamic queue's superior ability to capture feature variations compared to a memory bank. Moreover, the FIFO mechanism ensures the removal of outdated features, which is beneficial for causal inference.

% \noindent
% {\bf Effect of varying queue lengths.} \cref{tab:ab_causal_Nq} ablates the different lengths of dynamic queue $N_q$. The queue that is too short results in insufficient sample diversity, while too long affect memory efficiency and feature consistency.
% We observe that the estimation performance achieves the peak at the length of around 80, with slight declines upon further increases.
% We speculate that the queue length is closely related to task characteristics and data scale of COPE.
% We select $N_q =$ 80 in our model to balance between efficiency and accuracy.

\noindent
{\bf Effect of adaptive weight fusion method.} As shown in \cref{tab:ab_causal_fusion}, our model achieves sota performance even without feature fusion. Introduction of the adaptive feature fusion method further improves the results in rigorous metrics.

\noindent
{\bf Effect of distinct feature distillation policies.} In \cref{tab:ab_dis_layer}, we assess the impact of distinct feature distillation policies. The contrastive learning minimizes the feature distance via feature alignment. Our proposed residual distillation policy achieves the best performance since the residual layers effectively balance feature learning and knowledge transfer.

\noindent
{\bf Effect of different 3D encoders.} \cref{tab:ab_dis_encoder} illustrates the impact of using different 3D encoders in the distillation. Objectively, the pre-trained PointBert~\cite{yu2022point} realizes the sota point cloud zero-shot classification results~\cite{xue2024ulip}. Our model is also more performant using PointBert. It is noteworthy that using PointNet++~\cite{qi2017pointnet++}, which serves as the feature extractor in our model, dose not achieve the best performance. This further demonstrates that our proposed knowledge distillation network focuses on category knowledge rather than feature similarity.
\emph{Please see supplementary for more ablations.}