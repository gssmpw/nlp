\section{Related Works}
\label{sec:relate_works}
% \subsection{Category-level Object Pose Estimation}
\noindent
{\bf Category-level Object Pose Estimation.} The objective of this task encompasses predicting the 9DoF pose for unseen objects within predefined categories.
To address this challenging task, pioneer method NOCS~\cite{wang2019normalized} suggests mapping input shape to a normalized canonical space and recovering the pose via Umeyama algorithm~\cite{umeyama1991least}. 
SPD~\cite{tian2020shape} proposes a method for deriving and utilizing the shape prior for each category. This crucial insight inspires many subsequent prior-based works~\cite{lin2022sar,fan2021acr}, which further improve the use of shape priors, continuously improving the pose estimation performance.
More recently, prior-free methods~\cite{di2022gpv,zheng2023hs,lin2023vi,chen2024secondpose,lin2024instance} have achieved impressive performance.
VI-Net~\cite{lin2023vi} separates rotation into viewpoint and in-plane rotations, while SecondPose~\cite{chen2024secondpose} propose to extract hierarchical panel-based geometric features for point cloud.
AG-Pose~\cite{lin2024instance} achieves current state-of-the-art performance by explicitly extract local and global geometric keypoint information of different instances.
% Moreover, CLIPose~\cite{lin2024clipose}. It  aligns the representations of the image, point cloud, and text modalities through multi-modal contrastive learning to transfer rich semantic knowledge.
However, above methods have not fully considered that DNNs lack the ability to perform causal inference, which may leads the models to learn spurious correlations.
In addition, most of them either explicitly or implicitly learn category information from training set, which results in poor generalization ability to unseen instances within the categories.
% To this end, we propose to develop an unbiased pose estimation model by applying causal inference to learn cause-effect relations during data fitting. 
% In addition, we devise a residual feature knowledge distillation approach to guide more comprehensive category learning, which is also overlooked by previous works.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\columnwidth]{figure/graph.pdf}
   \caption{Illustration of the structural causal model of COPE.
   }
   \vspace{-0.4cm}
   \label{fig:causal_model}
\end{figure}

\vspace{0.05cm}
\noindent
{\bf Knowledge Distillation.} Knowledge distillation~\cite{hinton2015distilling} is a technique that transfers knowledge from a teacher model to a student model. Transferring the knowledge of foundation models for downstream tasks has been proven to be effective~\cite{gu2024open,huang2024froster,zhu2024mote}. ViLD~\cite{gu2024open} distill knowledge from CLIP~\cite{radford2021learning} to achieve open-vocabulary object detection, while some methods~\cite{huang2024froster,zhu2024mote} utilize the generalizability of VLMs to address the video recognition task. 
The most related method to our work is CLIPose~\cite{lin2024clipose}. It aligns the representations of the image, point cloud, and text modalities through multi-modal contrastive learning. However, such semantic labels cannot effectively guide the perception of point cloud structural information. Unlike CLIPose, our method distills knowledge directly from the point cloud encoder of 3D foundation models via a residual MLP layer, providing more comprehensive guidance for category learning.



%-------------------------------------------------------------------------
% \subsection{Causal Inference}
\vspace{0.05cm}
\noindent
{\bf Causal Inference.}
Causality~\cite{pearl2009causality} is an emerging technique refering to the modeling the relationships between factors in a task from a human perspective.
Recent methods have incorporated causal inference to improve the performance of DNNs in computer vision domains, \eg, object detection~\cite{zhang2022multiple,wang2021causal}, image captioning~\cite{yang2021deconfounded,liu2022show} and vision-language task~\cite{yang2021causal,zhang2024if,wang2024vision}.
Though valuable, these methods can flexibly identify confounders due to natural prompts in data, \eg, the keywords in instructions~\cite{wang2024vision} and salient regions in an image~\cite{wang2021causal}, which are inapplicable for point cloud data.

In 3D domain, several works have focused on enhancing the robustness of point cloud classification~\cite{huang2024causalpc} or 3D reconstruction~\cite{liu2022structural} with causal inference.
However, it is non-trivial to adapt these approaches to pose estimation due to the inherent differences in human modeling among these tasks.
In this work, we propose a specific causal learning approach based on front-door adjustment for category-level pose estimation for the first time.

% The solutions can be categorized into two main approaches, one mainstream way is to utilize back-door or front-door adjustment technique to alleviate the confoundering effects~\cite{wang2021causal,liu2022show,wang2024vision}, which is similar with ours. The other exploring the use of counterfactuals~\cite{parvaneh2020counterfactual,niu2021counterfactual}.
% However, above methods typically


% However, above methods typically focused on point cloud classification tasks. The application of multimodal learning and CLIP's robust pre-trained knowledge in other 3D downstream tasks, \eg object pose estimation, is still not further explored.
% To this end, our method develops the contrastive learning framework among three modalities, utilizing the pre-trained knowledge from image and text modalities to extract more robust category-specific feature for accurate category-level object pose estimation.