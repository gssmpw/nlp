\section{Training on informative examples improves the scaling laws}\label{sec:3}

Before presenting empirical results, we first analyze how selecting informative examples affects the scaling of synthetic data. We study a high-dimensional linear classifier trained with uniform vs. selective sampling and derive an analytic expression for test error using random matrix theory (RMT). Our results show that selecting hard examples improves scaling laws, providing theoretical justification for our approach.


\subsection{Theoretical Analysis under an Idealized Setup.}

Consider a simple generative model for training data:
\begin{equation}
    x \sim \mathcal{N}(0, \Sigma), \quad y = \text{sign}(w_0^\top x),
\end{equation}
where $w_0 \in \mathbb{R}^d$ is the ground-truth labeling function. This gives a distribution $P$ on $\mathbb R^{d} \times \mathbb R$.

We study the impact of \textit{uniform sampling} versus \textit{selective sampling} of informative examples on generalization. To formalize this, we assume a pool of $n$ i.i.d. training pairs:
{
\begin{equation}
    X \in \mathbb{R}^{n \times d}, \quad Y \in \mathbb{R}^{n}.
\end{equation}}
A linear classifier $\hat{w}$ is trained using the following loss:
\begin{equation}
    \hat{w} = \underset{w}{\arg\min} \quad \frac{1}{n} \sum_{i=1}^{n} q_i \ell(w^\top x_i, y_i) + \frac{\lambda}{2} \|w\|^2.
\end{equation}
where $\ell(z, y) = (z - y)^2/2$ is the squared loss, $\lambda > 0$ is a regularization parameter, and $q_i := q(x_i^\top w_s)$ is a selection strategy that determines whether an example is included in training based on its projection in a given direction $w_s \in \mathbb R^d$, and an arbitrary measurable binary function $q:\mathbb R \to \{0,1\}$ which encodes the selection strategy.

The \textit{selection/pruning ratio} is given by:
{
\begin{equation}
    p = \mathbb{E}[q(x^\top w_s)]\text{ for }x \sim \mathcal{N}(0, \Sigma).
\end{equation}}
The resulting classifier has a closed-form solution:
\begin{equation}
    \hat{w} = \frac{1}{n} R X^\top D Y, \quad R := \left(\frac{1}{n} X^\top D X + \lambda I_d \right)^{-1},
    \label{eq:estimator}
\end{equation}
where $D \in \mathbb{R}^{n \times n}$ is a diagonal matrix with $D_{ii} = q_i$.

Our objective is to analyze the asymptotic test error of $\hat{w}$:
\begin{equation}
    E_{test}(\hat{w}) = \mathbb{P}(\text{sign}(x^\top \hat{w}) \ne y),
    \label{eq:Etest}
\end{equation}
where $(x, y)$ is a test example,

\subsection{Asymptotic Behavior of the Test Error.}
We leverage random matrix theory (RMT) techniques \citep{Couillet_Liao_2022, ZhenyuAndMahoney2021, Firdoussi2024} to characterize the test error in Eq. \eqref{eq:Etest}. Our analysis is based on the spectral density of the resolvent matrix $R$ in Eq. \eqref{eq:estimator}, allowing us to compute the first two moments of $yx^\top \hat{w}$ for a test sample $x$ and derive an expression for the test error. For simplicity, we assume an isotropic setup where $\Sigma = I_d$ and defer the general case to Appendix~\ref{app:theory}.

We shall work in the following so-called high-dimensional proportionate scaling regime
\begin{equation}
\label{eq:proportionate}
    d,n \to \infty,\quad d/n \to \phi,
\end{equation}
in which the input-dimension $d$ and the sample size $n$ diverge to infinity at the same rate.
The scalar $\phi \in (0,\infty)$ captures the effective dimensionality or over-parametrization rate of the problem.

\textbf{Key Scalars.}
WLOG, assume $\|w_s\|=1$. It turns out that the for fixed, pruning, $p$, the asymptotic test error is fully captured by the following scalars:
{
\begin{equation}
    \begin{split}
    \rho &:= w_s^\top w_0/\|w_0\|, \, \tau := \frac{\rho}{\sqrt{1-\rho^2}},\, \gamma := \mathbb{E}[q(G)G^2],\\
    \beta &:= 2\mathbb{E}[q(G)\varphi(\tau G)],\quad  \tilde \beta := 2\mathbb{E}[q(G)\Phi(\tau G)G],
\end{split}
\end{equation}
}
where $G \sim \mathcal N(0,1)$ with pdf $\varphi$ and cdf $\Phi$. Note that $\rho$ quantifies the alignment between the pruning direction $w_s$ and the ground-truth labeler $w_0$, while $\beta$ and $\gamma$ capture statistical properties of the pruning strategy $q$.

\textbf{Spectral functions.} The Stieltjes transform $m$ of the limiting spectral density of the resolvent matrix $R$ is shown in Lemma \ref{lm:mp} to be given by the exact formula (with $z:=-\lambda$)
\begin{equation}    
 m(z) = \frac{p-\phi-z - \sqrt{(p-\phi-z)^2-4\phi z}}{2\phi z},
\label{eq:meq-mp}
\end{equation}
and will play an important role in our theory.
 The above formula represents a somewhat distorted Marchenko-Pastur law. 
 Indeed, the classical MP \citep{MP1967} corresponds to $p \to 1$ (i.e. no data pruning).
 
We further define the following auxiliary functions:
{
\begin{align}
    s(z) &:= \gamma/(1+\phi m(z)),\quad
    \tilde m(z) := 1/(s(z)-z), \\
    r(z) &:= \omega^2\cdot m(z) + \tilde\omega ^2\cdot \tilde m(z),\\
    \text{with }\omega&:=\sqrt{1-\rho^2}\beta,\quad \tilde\omega := \rho\tilde\beta.
\end{align}}

\paragraph{Main Result: Test Error Scaling w.r.t Selection Strategy.}
\begin{theorem}
\label{thm:main}
   In the limit Eq. \eqref{eq:proportionate}, the classification test error satisfies: $E_{test}(\hat{w}) \to \Phi\left(-m_0/\sqrt{\nu_0 - m_0^2}\right)$, where
    \begin{align*}
        m_0 &:= \sqrt{2/\pi} \cdot r(-\lambda),\\
        \nu_0 &:= p\phi m'(-\lambda) + r'(-\lambda) - \frac{2\phi m'(-\lambda)}{1+\phi m(-\lambda)} r(-\lambda).
    \end{align*}
\end{theorem}
The scaling behavior of test error is fully determined by the six scalars $(\lambda, \phi, p, \rho, \gamma, \beta,\tilde\beta)$. Importantly, the choice of the data point selection strategy $i \mapsto q(x_i^\top w_s)$ only influences performance through $\rho$, $\gamma$, $\beta$, and $\tilde \beta$.

\begin{figure}[t!]
    \centering
    \begin{minipage}{0.4\textwidth}
        \includegraphics[width=\linewidth]{theory.pdf}
    \end{minipage}
    \hfill
    \begin{minipage}{0.55\textwidth}
    \caption{Theoretical prediction for scaling behavior of accuracy (Theorem~\ref{thm:main}) for a simple classifier in a $d=512$ dimensional input space, as a function of dataset selection strategy. The classifier is trained on synthetic data with different pruning probabilities, where higher pruning probability corresponds to keeping only the most challenging examples (those closer to the decision boundary). The results compare selecting all samples (gray) versus selecting a fraction of the hardest samples (red). Selecting harder examples improves sample efficiency, achieving higher accuracy with fewer training samples.}
        \label{fig:theory_scaling}
    \end{minipage}
\end{figure}


\subsubsection{Example: Selecting Informative Examples.}

Consider a selection function of the form $q_i = q(x_i^\top w_s)$ for all $i$, where,
\begin{eqnarray}
q(t) := 1[|t| \le \xi] =  \begin{cases}
    1,&\mbox{ if }|t| \le \xi,\\
    0,&\mbox{ else,}
    \end{cases}
\end{eqnarray}
for some threshold $\xi \ge 0$. Such selection strategy selects only the examples near the decision boundary of $w_s$, analogous to using classifier entropy as a selection criterion but simpler to study. Lemma ~\ref{lm:KH} and \ref{lm:KE} derive explicit expressions for $(\gamma,\beta,\tilde\beta)$. 
Figure~\ref{fig:theory_scaling} presents theoretical predictions for test accuracy across different degrees of example selection, showing that \textit{selecting hard examples improves scaling laws}, reducing the number of training samples needed for the same performance. However, beyond a certain point, excessive pruning degrades performance, as illustrated in Figure~\ref{fig:explicit_prune_vs_DP}.

\subsubsection{Adaptive Selection Strategy.}  
Data selection relies on a pruning direction \( w_s \) to select informative/hard examples: $i \mapsto q(x_i^\top w_s) \in \{0,1\}$, but these examples are ultimately used to train \( \hat{w} \). If \( w_s \) and \( \hat{w} \) are misaligned, what is considered hard by \( w_s \) may not be hard for \( \hat{w} \), reducing the effectiveness of selective sampling. In fact, hard examples change over time: an example that was identified hard, might not remain hard are more training is done. To ensure alignment, \( w_s \) should periodically update to reflect the evolving decision boundary of \( \hat{w} \). This adaptive selection mechanism motivates the continuous data generation process of DP, as presented in Section \ref{sec:dp}.

Data selection relies on a pruning direction \( w_s \) to identify informative or hard examples: \( i \mapsto q(x_i^\top w_s) \in \{0,1\} \). However, these selected examples are ultimately used to train \( \hat{w} \), and if \( w_s \) and \( \hat{w} \) are misaligned, what is considered hard by \( w_s \) may not be hard for \( \hat{w} \), reducing the effectiveness of selective sampling. In fact, \( w_s \) and \( \hat{w} \) deviate from each other the more \( \hat{w} \) is trained on these examples. Moreover, the definition of ``hard'' changes over timeâ€”an example that was initially difficult may become easier as training progresses. To maintain alignment, \( w_s \) should be periodically updated to reflect the evolving decision boundary of \( \hat{w} \). This adaptive selection mechanism underpins the continuous data generation process in DP, as presented in Section~\ref{sec:dp}.
