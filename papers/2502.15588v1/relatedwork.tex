\section{Related Work}
\textbf{Synthetic data for training neural networks.} Synthetic data has become a powerful tool for training machine learning models across various domains. For instance, text-to-image diffusion models have been successfully used for visual representation learning~\citep{astolfi2023instance, li2025genview, tian2024learning, tian2024stablerep, sariyildiz2023fake}. However,  limitations of synthetic data are highlighted by~\citet{fan2024scaling}, emphasizing the importance of generating more challenging and informative examples. Addressing distribution shifts between synthetic and real data, \citet{hemmat2023feedback} and \citet{yuan2023real} propose synthesizing training data that matches real data distributions or conditioning on real examples to reduce this gap. Expanding small-scale datasets has also been studied, see e.g.\ ~\citet{zhang2024expanding}.
Another related line of work involves using VLMs and LLMs to generate descriptions for augmenting datasets~\citep{dunlap2023diversify}.

Synthetic data is increasingly used to train (LLMs). For example, LLaMA3~\citep{grattafiori2024llama3herdmodels} employs AI-generated data for fine-tuning. Similarly, self-play approaches, e.g.,\ \citet{yuan2024self}, align with our framework by generating increasingly difficult examples for training.

\textbf{Continual learning and active learning.}
 Our work is also closely related to principles from active learning~\citep{bang2024active,evans2023bad} and continual learning, which prioritize iterative model updates with tailored data. These methods highlight the importance of selecting informative samples based on the model's current state.
 \cite{sorscher2022beyond} showed that pruning static datasets using metrics like margin scores can improve scaling laws by retaining the most informative examples, albeit in a non-adaptive manner.
 
\textbf{Challenges and risks of synthetic data.}
The challenges of training models on synthetic data, have gained significant attention. \citet{dohmatob2024strong,dohmatob2024tale} studied “model collapse”, a phenomenon where iterative training on synthetic data degrades performance. 
They emphasize that data verification mechanisms can mitigate this risk and enable scaling with synthetic data. Similarly, our framework by generating informative examples through a dynamic loop, improves sample efficiency.