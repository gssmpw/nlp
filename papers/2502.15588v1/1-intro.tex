\section{Introduction}

A key principle underlying learning in human is deliberate practice (DP)—progress is made not by repeating what is already known but by continuously engaging with tasks that stretch the limits of one’s abilities~\citep{ericsson1993role}. For example, when learning to play the guitar, simply practicing songs that one has mastered does little to improve skill. Instead, targeted practice on challenging tasks and refining learning through feedback, leads to real progress. This principle highlights that effective learning requires exposure to informative and difficult examples rather than passive repetition.

In contrast, most machine learning models are trained on pre-collected data that remain static throughout training, limiting their ability to dynamically adapt to their own weaknesses. One promising source of data for visual recognition tasks is large-scale pre-trained text-to-image models~\citep{rombach2022high}. They provide an essentially infinite source of synthetic training data, presenting an alternative to real-world datasets, which are often expensive or infeasible to curate~\citep{hemmat2023feedback, shin2023fill, zhang2024expanding}. With the great promise of text-to-image models, a natural question arises: what is the potential of learning using \textbf{only} synthetic data? Empirical studies show that increasing the volume of synthetic training data often leads to diminishing returns, with performance gains following a power law stagnation~\citep{fan2024scaling, tian2024learning}. Instead, pruning to remove uninformative examples has proven effective in improving the effectiveness of training with real or synthetic data~\citep{sorscher2022beyond,kolossov2024towards, feng2024modelcollapsescalingsynthesized}. 

Inspired by human learning principles and recent advances in generative image models, we propose the Deliberate Practice (DP) for Synthetic Data Generation framework. Unlike static approaches that generate all synthetic training data upfront~\citep{fan2024scaling, shin2023fill, hemmat2023feedback}, our framework incorporates a dynamic loop between a diffusion model and a downstream learner throughout the training. More concretely, rather than generating an entire dataset at once and irrespective of the learner and then pruning it to remove uninformative samples, we propose DP to efficiently \emph{generate data directly from the pruned distribution of informative samples}. By leveraging the learner's prediction entropy to guide the generation process, our approach generates only the most challenging and informative training examples.

Our framework operates \textbf{dynamically}: we begin with an initial set of synthetic data and train a learner until performance on a real validation set plateaus. At this point, the learner's entropy is used to guide the diffusion model to generate new challenging examples. These examples are added to the training set, and the process repeats, ensuring that the model is continually exposed to increasingly informative data throughout training.

This approach aligns with broader goals in machine learning, such as interactive learning environments, continual learning~\citep{kirkpatrick2017overcoming}, and active learning \citep{settles2009active}. By leveraging a dynamic loop, Deliberate Practice reduces inefficiencies from redundant or already learned data, thereby improving the scaling laws of training with synthetic data.

Our contributions are summarized as:
\begin{itemize}[noitemsep]
    \item We introduce the \textit{Deliberate Practice for Synthetic Data Generation} framework, which dynamically adds new data points when the learner's validation accuracy plateaus [Section~\ref{sec:dp}]. Our framework leverages the learner's prediction entropy to generate\textbf{ challenging synthetic data}, improving the scaling behavior of synthetic data (Figures \ref{fig:diagram} and \ref{fig:scaling-laws}).
    \item We provide a theoretical analysis of the scaling behavior of a simple model trained on selected examples (Section~\ref{sec:3}). Using random matrix theory, we characterize the test error as a function of data size and the example selection function, showing \textbf{improved scaling when prioritizing hard and informative examples}.
    \item We show that entropy-guided sampling approximates generating from an entropy-pruned distribution (Section \ref{sec:2}). We empirically validate that DP can improve the validation accuracy compared to direct pruning while being remarkably \textbf{cheaper in compute up to 5$\times$} (Figure \ref{fig:explicit_prune_vs_DP}).
    \item We demonstrate that DP outperforms prior work on both ImageNet-100 and ImageNet-1k while requiring significantly less data and fewer training iterations. On ImageNet-100, our approach generated \textbf{3.4$\times$ less samples} and completed training in only one-sixth of the iterations used in prior work, yet still achieved superior performance. Similarly, on ImageNet-1k, we generated \textbf{8$\times$ less samples} and reduced the number of iterations by 30\%, while outperforming previous results (Table~\ref{tab:compare}).
    \item Furthermore, DP exhibits strong performance on \textbf{out-of-distribution} (OOD) datasets, even outperforming models trained with real data on ImageNet-R and ImageNet-Sketch, with \textbf{improvements of up to 15\%} (Table~\ref{tab:compare}).
\end{itemize}


\begin{figure}[t!]
    \centering
\includegraphics[width=1.0\linewidth]{diagram.pdf}
    \vspace{-0.5cm}
    \caption{
    (\textbf{Top}): Conventional approaches generate (or collect) a massive static dataset and then select challenging examples in a one-time filtering step based on the learner’s selection criterion. This is inefficient, as most generated data is discarded. (\textbf{Bottom}): DP \textbf{continuously generates only the most challenging examples} based on continuous feedback from the learner, eliminating the need for large-scale data pruning. This iterative process ensures that training focuses on progressively informative examples, improving efficiency and performance. (\textbf{Right}): Top-1 validation accuracy on ImageNet-1k with models trained solely on synthetic data. DP (orange) achieves higher accuracy than the 13M synthetic data setup (blue) while using \textbf{10× fewer samples}, significantly outperforming the 1.3M baseline (gray).
    }
    \vspace{-0.2cm}
    \label{fig:diagram}
\end{figure}

