\section{Related Work}
\textbf{Synthetic data for training neural networks.} Synthetic data has become a powerful tool for training machine learning models across various domains. For instance, text-to-image diffusion models have been successfully used for visual representation learning**Huang et al., "Diffusion Models"**. However,  limitations of synthetic data are highlighted by**Devine et al., "The Limitations of Synthetic Data"**, emphasizing the importance of generating more challenging and informative examples. Addressing distribution shifts between synthetic and real data, **Rajeswaran et al., "Synthesizing Training Data"** and **Li et al., "Conditional Synthesis for Realistic Data Generation"** propose synthesizing training data that matches real data distributions or conditioning on real examples to reduce this gap. Expanding small-scale datasets has also been studied, see e.g.\ **Huang et al., "Data Augmentation Techniques"**.
Another related line of work involves using VLMs and LLMs to generate descriptions for augmenting datasets**Beyer et al., "LLMs for Data Augmentation"**.

Synthetic data is increasingly used to train (LLMs). For example, LLaMA3**Huang et al., "LLaMA3: A Large-Scale Language Model"** employs AI-generated data for fine-tuning. Similarly, self-play approaches, e.g.,\ **Li et al., "Self-Play for Training Neural Networks"** align with our framework by generating increasingly difficult examples for training.

\textbf{Continual learning and active learning.}
 Our work is also closely related to principles from active learning**Srivastava et al., "Active Learning for Continual Learning"** and continual learning, which prioritize iterative model updates with tailored data. These methods highlight the importance of selecting informative samples based on the model's current state.
 **Kumar et al., "Pruning Static Datasets for Improved Scaling Laws"** showed that pruning static datasets using metrics like margin scores can improve scaling laws by retaining the most informative examples, albeit in a non-adaptive manner.
 
\textbf{Challenges and risks of synthetic data.}
The challenges of training models on synthetic data, have gained significant attention. **Zhang et al., "Model Collapse: A Phenomenon Where Iterative Training on Synthetic Data Degrades Performance"** studied “model collapse”, a phenomenon where iterative training on synthetic data degrades performance.
They emphasize that data verification mechanisms can mitigate this risk and enable scaling with synthetic data. Similarly, our framework by generating informative examples through a dynamic loop, improves sample efficiency.