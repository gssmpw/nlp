
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.

\usepackage{xcolor}         % colors
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{marvosym}
\usepackage{color}
\usepackage{threeparttable}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{setspace}
\usepackage{amsthm}
\usepackage{dutchcal}
\usepackage{makecell}
\usepackage{pifont}
\title{TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\newcommand{\boldres}[1]{{\textbf{\textcolor{red}{#1}}}}
\newcommand{\secondres}[1]{{\underline{\textcolor{blue}{#1}}}}

\author{Songtao Huang$^{1,2}$, Zhen Zhao$^{1}$, Can Li$^{3}$, Lei Bai$^{1}$\textsuperscript{\Letter}\\ 
  $^{1}$Shanghai Artificial Intelligence Laboratory, Shanghai, China \\
  $^{2}$School of Information Science and Engineering, Lanzhou University, Lanzhou, China \\
  $^{3}$The Key Laboratory of Road and Traffic Engineering of the Ministry of Education,\\
  \ \ Tongji University, Shanghai, China \\
  \texttt{\small  huangsongtao@pjlab.org.cn, zhen.zhao@outlook.com,} \\
  \texttt{\small 
    lchelen1005@gmail.com, baisanshi@gmail.com}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
 \iclrfinalcopy
\begin{document}


\maketitle
\begin{abstract}
Real-world time series often have multiple frequency components that are intertwined with each other, making accurate time series forecasting challenging. Decomposing the mixed frequency components into multiple single frequency components is a natural choice. However, the information density of patterns varies across different frequencies, and employing a uniform modeling approach for different frequency components can lead to inaccurate characterization. To address this challenges, inspired by the flexibility of the recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based Frequency Decomposition Learning architecture (TimeKAN) to address the complex forecasting challenges caused by multiple frequency mixtures. Specifically, TimeKAN mainly consists of three components: Cascaded Frequency Decomposition (CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks and Frequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach to obtain series representations for each frequency band. Benefiting from the high flexibility of KAN, we design a novel M-KAN block to learn and represent specific temporal patterns within each frequency band. Finally, Frequency Mixing blocks is used to recombine the frequency bands into the original format. Extensive experimental results across multiple real-world time series datasets demonstrate that TimeKAN achieves state-of-the-art performance as an extremely lightweight architecture. Code is available at \url{https://github.com/huangst21/TimeKAN}.


\end{abstract}
\section{Introduction}
Time series forecasting (TSF) has garnered significant interest due to its wide range of applications, including finance \citep{huang2024generative}, energy management \citep{YIN2023energy}, traffic flow planning \citep{JIANG2022Traffic}, and weather forecasting \citep{Remi2023GraphCast}. Recently, deep learning has led to substantial advancements in TSF, with the most state-of-the-art performances achieved by CNN-based methods \citep{wang2023micn, donghao2024moderntcn}, Transformer-based methods\citep{nie2023patchtst, liu2024itransformer} and MLP-based methods \citep{zeng2023transformers, wang2024timemixer}.\par

Due to the complex nature of the real world, observed multivariate time series are often non-stationary and exhibit diverse patterns. These intertwined patterns complicate the internal relationships within the time series, making it challenging to capture and establish connections between historical observations and future targets. To address the complex temporal patterns in time series, an increasing number of studies focus on leveraging prior knowledge to decompose time series into simpler components that provide a basis for forecasting. For instance, Autoformer \citep{wu2021autoformer} decomposes time series into seasonal and trend components. This idea is also adopted by DLinear \citep{zeng2023transformers} and FEDFormer \citep{zhou2022fedformer}. Building on this foundation, TimeMixer \citep{wang2024timemixer} further introduces multi-scale seasonal-trend decomposition and highlights the importance of interactions between different scales. Recent models like TimesNet \citep{wu2023timesnet}, PDF \citep{dai2024pdf}, and SparseTSF \citep{lin2024sparsetsf} emphasize the inherent periodicity in time series and decompose long sequences into multiple shorter ones based on the period length, thereby enabling the separate modeling of inter-period and intra-period dependencies within temporal patterns. In summary, these different decomposition methods share a common goal: utilizing the simplified subsequences to provide critical information for future predictions, thereby achieving accurate forecasting.\par

It is worth noting that time series are often composed of multiple frequency components, where the low-frequency components represent long-term periodic variations and the high-frequency components capture certain abrupt events. The mixture of different frequency components makes accurate forecasting particularly challenging. The aforementioned decomposition approaches motivate us to design a frequency decomposition framework that decouples different frequency components in a time series and independently learns the temporal patterns associated with each frequency. However, this introduces another challenge: the information density of patterns varies across different frequencies, and employing a uniform modeling approach for different frequency components can lead to inaccurate characterizations, resulting in sub-optimal results. Fortunately, a new neural network architecture, known as Kolmogorov-Arnold Networks (KAN) \citep{liu2024kan}, has recently gained significant attention in the deep learning community due to its outstanding data-fitting capabilities and flexibility, showing potential as a substitute for traditional MLP. Compared to MLP, KAN offers optional kernels and allows for the adjustment of kernel order to control its fitting capacity. This consideration leads us to explore the use of Multi-order KANs to represent temporal patterns across different frequencies, thereby providing more accurate information for forecasting.\par

Motivated by these observations, we propose a KAN-based Frequency Decomposition Learning architecture (TimeKAN) to address the complex prediction challenges caused by multiple frequency mixtures. Specifically, TimeKAN first employs moving average to progressively remove relatively high-frequency components from the sequence. Subsequently, Cascaded Frequency Decomposition (CFD) blocks adopt a bottom-up cascading approach to obtain sequence representations for each frequency band. Multi-order KAN Representation Learning (M-KAN) blocks leverage the high flexibility of KAN to learn and represent specific temporal patterns within each frequency band. Finally, Frequency Mixing blocks recombine the frequency bands into the original format, ensuring that this Decomposition-Learning-Mixing process is repeatable, thereby modeling different temporal patterns at various frequencies more accurately. The final high-level sequence is then mapped to the desired forecasting output via a simple linear mapping. With our meticulously designed architecture, TimeKAN achieves state-of-the-art performance across multiple long-term time series forecasting tasks, while also being a lightweight architecture that outperforms complex TSF models with fewer computational resources.
 
Our contributions are summarized as follows:
\begin{itemize}
\item We revisit time series forecasting from the perspective of frequency decoupling, effectively disentangling time series characteristics through a frequency Decomposition-Learning-Mixing architecture to address challenges caused by complex information coupling in time series.
\item We introduce TimeKAN as a lightweight yet effective forecasting model and design a novel M-KAN blocks to effectively modeling and representing patterns at different frequencies by maximizing the flexibility of KAN.
\item TimeKAN demonstrates superior performance across multiple TSF prediction tasks, while having a parameter count significantly lower than that of state-of-the-art TSF models.
\end{itemize}


\section{Related Work}
\subsection{Kolmogorov-Arnold Network}
Kolmogorov-Arnold representation theorem states that any multivariate continuous function can be expressed as a combination of univariate functions and addition operations. Kolmogorov-Arnold Network (KAN) \citep{liu2024kan} leverages this theorem to propose an innovative alternative to traditional MLP. Unlike MLP, which use fixed activation functions at the nodes, KAN introduces learnable activation functions along the edges. Due to the flexibility and adaptability, KAN is considered as a promising alternative to MLP.\par
The original KAN was parameterized using spline functions. However, due to the inherent complexity of spline functions, the speed and scalability of the original KAN were not satisfactory. Consequently, subsequent research explored the use of simpler basis functions to replace splines, thereby achieving higher efficiency. ChebyshevKAN \citep{ss2024chebyshev} incorporates Chebyshev polynomials to parametrize the learnable functions. FastKAN \citep{li2024kolmogorov} uses faster Gaussian radial basis functions to approximate third-order B-spline functions.\par 
Moreover, KAN has been applied as alternatives to MLP in various domains. Convolutional KAN \citep{bodner2024convolutional} replaces the linear weight matrices in traditional convolutional networks with learnable spline function matrices. U-KAN \citep{li2024ukan} integrates KAN layers into the U-Net architecture, demonstrating impressive accuracy and efficiency in several medical image segmentation tasks. KAN has also been used to bridge the gap between AI and science. Works such as PIKAN \citep{shukla2024pikan} and PINN \citep{wang2024kinn} utilize KAN to build physics-informed machine learning models. This paper aims to introduce KAN into TSF and demonstrate the strong potential of KAN in representing time series data.

\subsection{Time Series Forecasting}
Traditional time series forecasting (TSF) methods, such as ARIMA \citep{ZHANG2003arima}, can provide sufficient interpretability for the forecasting results but often fail to achieve satisfactory accuracy. In recent years, deep learning methods have dominated the field of TSF, mainly including CNN-based, Transformer-based, and MLP-based approaches. CNN-based models primarily apply convolution operations along the temporal dimension to extract temporal patterns. For example, MICN \citep{wang2023micn} and TimesNet \citep{wu2023timesnet} enhance the precision of sequence modeling by adjusting the receptive field to capture both short-term and long-term views within the sequences. ModernTCN \citep{donghao2024moderntcn} advocates using large convolution kernels along the temporal dimension and capture both cross-time and cross-variable dependencies.
%
Compared to CNN-based methods, which have limited receptive field, Transformer-based methods offer global modeling capabilities, making them more suitable for handling long and complex sequence data. They have become the cornerstone of modern time series forecasting. Informer \citep{zhou2021informer} is one of the early implementations of Transformer models in TSF, making efficient forecasting possible by carefully modifying the internal Transformer architecture. PatchTST \citep{nie2023patchtst} divides the sequence into multiple patches along the temporal dimension, which are then fed into the Transformer, establishing it as an important benchmark in the time series domain. In contrast, iTransformer \citep{liu2024itransformer} treats each variable as an independent token to capture cross-variable dependencies in multivariate time series. However, Transformer-based methods face challenges due to the large number of parameters and high memory consumption.
%
Recent research on MLP-based methods has shown that with appropriately designed architectures leveraging prior knowledge, simple MLPs can outperform complex Transformer-based methods. DLinear \citep{zeng2023transformers}, for instance, preprocesses sequences using a trend-season decomposition strategy. FITS \citep{xu2024fits} performs linear transformations in the frequency domain, while TimeMixer \citep{wang2024timemixer} uses MLP to facilitate information interaction at different scales. These MLP-based methods have demonstrated strong performance regarding both forecasting accuracy and efficiency.
%
Unlike the aforementioned methods, this paper introduces the novel KAN to TSF to represent time series data more accurately. It also proposes a well-designed Decomposition-Learning-Mixing architecture to fully unlock the potential of KAN for time series forecasting.


\subsection{Time Series Decomposition}
Real-world time series often consist of various underlying patterns. To leverage the characteristics of different patterns, recent approaches tend to decompose the series into multiple subcomponents, including trend-seasonal decomposition, multi-scale decomposition, and multi-period decomposition. DLinear \citep{zeng2023transformers} employs moving averages to decouple the seasonal and trend components.  SCINet \citep{liu2022scinet} uses a hierarchical downsampling tree to iteratively extract and exchange information at multiple temporal resolutions. TimeMixer \citep{wang2024timemixer} follows a fine-to-coarse principle to decompose the sequence into multiple scales across different time spans and further splits each scale into seasonal and periodic components. TimesNet \citep{wu2023timesnet} and PDF \citep{dai2024pdf} utilize Fourier periodic analysis to decouple sequence into multiple sub-period sequences based on the calculated period.
Inspired by these works, this paper proposes a novel Decomposition-Learning-Mixing architecture, which examines time series from a multi-frequency perspective to accurately model the complex patterns within time series.

\section{TimeKAN}
\subsection{Overall Architecture}
Given a historical multivariate time series input $\mathbf{X}\in\mathbb{R}^{N\times T}$, the aim of time series forecasting is to predict the future output series   $\mathbf{X}_{O}\in\mathbb{R}^{N\times F}$, where $T,F$ is the look-back window length and the future window length, and $N$ represents the number of variates. In this paper, we propose TimeKAN to tackle the challenges arising from the complex mixture of multi-frequency components in time series. The overall architecture of TimeKAN is shown in Figure \ref{fig:1}. We adopt variate-independent manner \citep{nie2023patchtst} to predict each univariate series independently. Each univariate input time series is denoted as $X\in\mathbb{R}^{T}$ and we consider univariate time series as the instance in the following calculation. In our TimeKAN, the first step is to progressively remove the relatively high-frequency components using moving averages and generate multi-level sequences followed by projecting each sequence into a high-dimensional space.  Next, adhering to the Decomposition-Learning-Mixing architecture design principle,  we first design Cascaded Frequency Decomposition (CFD) blocks to obtain sequence representations for each frequency band, adopting a bottom-up cascading approach. Then, we propose Multi-order KAN Representation Learning (M-KAN) blocks to learn and represent specific temporal patterns within each frequency band. Finally, Frequency Mixing blocks recombine the frequency bands into the original format, ensuring that the Decomposition-Learning-Mixing process is repeatable. More details about our TimeKAN are described as follow.

\begin{figure}[t]
    \centering
        \includegraphics[width=1\linewidth]{Figure/TimeKAN.pdf}
        % \vspace{-10pt}
    \caption{The architecture of TimeKAN, which mainly consists of Cascaded Frequency Decomposition block, Multi-order KAN Representation Learning block, and Frequency Mixing block. Here, we divide the frequency range of the time series into three frequency bands as an example.}
    \label{fig:1}
\end{figure}
\subsection{Hierarchical Sequence Preprocessing}
Assume that we divide the frequency range of raw time series $X$ into predefined $k$ frequency bands. We first use moving average to progressively remove the relatively high-frequency components and generate multi-level sequences $\{x_{1},\cdots,x_{k}\}$, where $x_{i}\in\mathbb{R}^{ \frac{T}{d^{i-1}}} (i\in \{1,\cdots,k\})$. $x_{1}$ is equal to the input series $X$ and $d$ denotes the length of moving average window. The process of producing multi-level sequences is as follows: 
\begin{equation}
    x_{i} =  \mathrm{AvgPool}(\mathrm{Padding}(x_{i-1}))
\end{equation}
After obtaining the multi-level sequences, each sequence is independently embedded into a higher dimension through a Linear layer:
\begin{equation}
    x_{i} = \mathrm{Linear}(x_{i})
\end{equation}

where $x_{i}\in\mathbb{R}^{ \frac{T}{d^{i-1}} \times D}$ and $D$ is embedding dimension. We define $x_{1}$ as the highest level sequence and $x_{k}$ as the lowest level sequence. Notably, each lower-level sequence is derived from the sequence one level higher by removing a portion of the high-frequency information. The above process is a preprocessing process and only occurs once in TimeKAN. \par 
\subsection{Cascaded Frequency Decomposition}
Real-world time series are often composed of multiple frequency components, with the low-frequency component representing long-term changes in the time series and the high-frequency component representing short-term fluctuations or unexpected events. These different frequency components complement each other and provide a comprehensive perspective for accurately modeling time series. Therefore, we design the Cascaded Frequency Decomposition (CFD) block to accurately decompose each frequency component in a cascade way, thus laying the foundation for accurately modeling different frequency components.\par
The aim of CFD block is to obtain the representation of each frequency component. Here, we take obtaining the representation of the $i$-th frequency band as an example.
To achieve it, we first employ the Fast Fourier Transform (FFT) to obtain the representation of $x_{i+1}$ in the frequency domain. Then, Zero-Padding is used to extend the length of the frequency domain sequence, so that it can have the same length as the upper sequence $x_{i}$ after transforming back to the time domain. Next, we use Inverse Fast Fourier Transform (IFFT) to transform it back into the time domain. We refer to this upsampling process as Frequency Upsampling, which ensures that the frequency information remains unchanged before and after the upsampling. The process of Frequency Upsampling can be described as:
\begin{equation}
    \hat{x}_{i} = \mathrm{IFFT}(\mathrm{Padding}(\mathrm{FFT}(x_{i+1})))
\end{equation}
Here, $\hat{x}_{i}$ and $x_{i}$ have the same sequence length. Notably, compared to $x_{i}$, $\hat{x}_{i}$ lacks the $i$-th frequency component.
The reason is that $x_{i+1}$ is originally formed by removing $i$-th frequency component from $x_{i}$ in the hierarchical sequence preprocessing and  $x_{i+1}$ is now transformed into $\hat{x}_{i}$ through a lossless frequency conversion process, thereby aligning length with $x_{i}$ in the time domain.
Therefore, to get the series representation of the $i$-th frequency component $f_{i}$ in time domain, we only need to get the residuals between $x_{i}$ and $\hat{x}_{i}$:
\begin{equation}
    f_{i} = x_{i} - \hat{x}_{i}
\end{equation}
\subsection{Multi-order KAN Representation Learning}
Given the multi-level frequency component representation $\{f_{1},\cdots, f_{k}\}$ generated by the CFD block, we propose Multi-order KAN Representation Learning (M-KAN) blocks to learn specific representations and temporal dependencies at each frequency. M-KAN adopts a dual-branch parallel architecture to separately model temporal representation learning and temporal dependency learning in a frequency-specific way, using Multi-order KANs to learn the representation of each frequency component and employing Depthwise Convolution to capture the temporal dependency.  The details of Depthwise Convolution and Multi-order KAN will be given as follows.\par 
\paragraph{Depthwise Convolution} To separate the modeling of temporal dependency from learning sequence representation, we adopt a specific type of group convolution known as Depthwise Convolution, in which the number of groups matches the embedding dimension. Depthwise Convolution employs $D$ groups of convolution kernels to perform independent convolution operations on the series of each channel. This allows the model to focus on capturing temporal patterns without interference from inter channel relationships. The process of Depthwise Convolution is:
\begin{equation}
f_{i,1} =  Conv_{D\rightarrow D}(f_{i}, \mathrm{group} =D)
\end{equation}

\paragraph{Multi-order KANs} Compared with traditional MLP, KAN replaces linear weights with learnable univariate functions, allowing complex nonlinear relationships to be modeled with fewer parameters and greater interpretability. \citep{xu2024arekan}.
Assume that KAN is composed of $L+1$ layer neurons and the number of neurons in layer $l$ is $n_{l}$. The transmission relationship between the $j$-th neuron in layer $l+1$ and all neurons in layer $l$ can be expressed as $z_{l+1,j} = \sum^{n_{l}}_{i=1}\phi_{l,j,i}(z_{l,i})$, where $z_{l+1,j}$ is the $j$-th neuron at layer $l+1$ and $z_{l,i}$is the $i$-th neuron at layer $l$.
We can simply understand that each neuron is connected to other neurons in the previous layer through a learnable univariate function $\phi$.
The vanilla KAN \citep{liu2024kan} employs spline function as the learnable univariate basic functions $\phi$, but suffering from the complex recursive computation process, which hinders the efficiency of KAN.
Here, we adopt ChebyshevKAN \citep{ss2024chebyshev} to learn the representation of each frequency component, i.e., channel learning. ChebyshevKAN is constructed from linear combinations of Chebyshev polynomial. That is, using the linear combination of Chebyshev polynomial with different order to generate learnable univariate function $\phi$.
The Chebyshev polynomial is defined by:
\begin{equation}
    T_{n}(x) = \mathrm{cos}(n\  \mathrm{arccos}(x))
\end{equation}
where $n$ is the highest order of Chebyshev polynomials and the complexity of Chebyshev polynomials is increasing with increasing order.
A 1-layer ChebyshevKAN applied to channel dimension can be expressed as:
\begin{equation}
    \phi_{o}(x) = \sum_{j=1}^{D} \sum_{i=0}^{n} \Theta_{o,j,i} T_{i}(\mathrm{tanh}(x_{j}))
    \end{equation}
    
\begin{equation}
\mathrm{KAN}(x) = \left\{
 \begin{array}{c}
\phi_{1}(x) \\
\cdots\\
\phi_{D}(x)
\end{array}
\right\}
\end{equation}


where $o$ is the index of output neuron and $ \Theta\in\mathbb{R}^{D \times D \times (n+1)} $ are the learnable coefficients used to linearly combine the  Chebyshev polynomials. 
It is worth noting that the frequency components within the time series exhibit increasingly complex temporal dynamics as the frequency increases, necessitating a network with stronger representation capabilities to learn these characteristics. ChebyshevKAN allows for the adjustment of the highest order of Chebyshev polynomials $n$ to enhance its representation ability. Therefore, from the low-frequency to high-frequency components, we adopt an increasing order of Chebyshev polynomials to align the frequency components with the complexity of the KAN, thereby accurately learning the representations of different frequency components. We refer to this group of KANs with varying highest Chebyshev polynomials orders as Multi-order KANs. We set an lower bound order $b$, and the representation learning process for $x_{i}$ can be expressed as:
\begin{equation}
    f_{i,2} = \mathrm{KAN}(f_{i}, \mathrm{order}=b+k-i)
\end{equation}

The final output of the M-KAN block is the sum of the outputs from the Multi-order KANs and the Depthwise Convolution.
\begin{equation}
    \hat{f}_{i} = {f}_{i,1} + f_{i,2} 
\end{equation}
\subsection{Frequency Mixing}

After specifically learning the representation of each frequency component, we need to re-transform the frequency representations into the form of multi-level sequences before entering next CFD block, ensuring that the Decomposition-Learning-Mixing process is repeatable. 
Therefore, we designed Frequency Mixing blocks to convert the frequency component at $i$-th level $\hat{f_{i}}$  into multi-level sequences $x_{i}$, enabling it to serve as input for the next CFD block. To transform the frequency component at $i$-th level $\hat{f_{i}}$  into multi-level sequences $x_{i}$, we simply need to to supplement the frequency information from levels $i+1$ to $k$ back into the $i$-th level. Thus, we employ Frequency Upsampling again to incrementally reintegrate the information into the higher frequency components:
\begin{equation}
    x_{i} = \mathrm{IFFT}(\mathrm{Padding}(\mathrm{FFT}(x_{i+1}))) + f_{i}
\end{equation}
For the last Frequency Mixing block, we extract the highest-level sequence $x_{1}$ and use a simple linear layer to produce the forecasting results $X_{O}$.
\begin{equation}
     X_{O} = \mathrm{Linear}(x_{1})
\end{equation}
Due to the use of a variate-independent strategy, we also need to stack the predicted results of all variables together to obtain the final multivariate prediction $\mathbf{X_{O}}$.

\section{Experiments}
\paragraph{Datasets}  We conduct extensive experiments on six real-world time series datasets, including Weather, ETTh1, ETTh2, ETTm1, ETTm2 and Electricity for long-term forecasting. 
Following previous work \citep{wu2021autoformer}, we split the ETT series dataset into training, validation, and test sets in a ratio of 6:2:2. For the remaining datasets, we adopt a split ratio of 7:1:2.

\paragraph{Baseline} We carefully select eleven well-acknowledged methods in the field of long-term time series forecasting  as our baselines, including (1) Transformer-based methods: Autoformer \citeyearpar{wu2021autoformer}, FEDformer \citeyearpar{zhou2022fedformer}, PatchTST \citeyearpar{nie2023patchtst}, iTransformer \citeyearpar{liu2024itransformer}; (2) MLP-based methods: DLinear \citeyearpar{zeng2023transformers} and TimeMixer \citeyearpar{wang2024timemixer} (3) CNN-based method: MICN \citeyearpar{wang2023micn}, TimesNet \citeyearpar{wu2023timesnet}; (4) Frequency-based methods: FreTS \citeyearpar{yi2024frets} and FiLM \citeyearpar{zhou2022film}. And a time series foundation model Time-FFM \citeyearpar{liu2024timeffm}.
\paragraph{Experimental Settings} To ensure fair comparisons, we adopt the same look-back window length $T = 96$ and the same prediction length $F = \{96, 192, 336, 720\}$.  We  utilize the L2 loss for model training and use Mean Square Error (MSE) and Mean Absolute Error (MAE) metrics to evaluate the performance of each method. 
\begin{table}[t]
% \vspace{-10pt}
  \caption{Full results of the multivariate long-term forecasting result comparison. The input sequence length is set to 96 for all baselines and the prediction lengths  $F\in$ \{96, 192, 336, 720\}. \emph{Avg} means the average results from all four prediction lengths.}\label{tab:full_results}
  \vskip 0.05in
  \centering
  \resizebox{1.0\columnwidth}{!}{
  \begin{threeparttable}
  \begin{small}
  \renewcommand{\multirowsetup}{\centering}
  \setlength{\tabcolsep}{3.0 pt}
  \begin{tabular}{c|c|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{Models}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{\textbf{TimeKAN}}}}&
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.9}{TimeMixer}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{iTransformer}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{Time-FFM}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{PatchTST}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{TimesNet}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{MICN}}} & 
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{DLinear}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{FreTS}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{FiLM}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{FEDformer}}} & 
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{0.95}{Autoformer}}}  \\
    
    \multicolumn{2}{c}{} & 
    \multicolumn{2}{c}{\scalebox{0.95}{\textbf{Ours}}} &
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{wang2024timemixer}}} &
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{liu2024itransformer}}} &
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{liu2024timeffm}}} &
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{nie2023patchtst}}} &
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{wu2023timesnet}}}&
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{wang2023micn}}}&
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{zeng2023transformers}}}&
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{yi2024frets}}}&
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{zhou2022film}}}&
    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{zhou2022fedformer}}}&

    \multicolumn{2}{c}{\scalebox{0.95}{\citeyear{wu2021autoformer}}}

    \\
    
    \cmidrule(lr){3-4} \cmidrule(lr){5-6}\cmidrule(lr){7-8} \cmidrule(lr){9-10}\cmidrule(lr){11-12}\cmidrule(lr){13-14}\cmidrule(lr){15-16}\cmidrule(lr){17-18}\cmidrule(lr){19-20}\cmidrule(lr){21-22}\cmidrule(lr){23-24}\cmidrule(lr){25-26}
    \multicolumn{2}{c}{Metric} & \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE} & \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE} & \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE} & \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE} & \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE} & \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE} & \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE}& \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE}& \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE}& \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE}& \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE}& \scalebox{0.9}{MSE} & \scalebox{0.9}{MAE}\\
    \toprule
    \multirow{5}{*}{\rotatebox{90}{\scalebox{0.95}{ETTh1}}} 
    & \scalebox{0.95}{96} 
    &\boldres{\scalebox{0.95}{0.367}}&\boldres{\scalebox{0.95}{0.395}}
    &\scalebox{0.95}{0.385}&\secondres{\scalebox{0.95}{0.402}}
    & {\scalebox{0.95}{0.386}} & {\scalebox{0.95}{0.405}} 
    & {\scalebox{0.95}{0.385}} & {\scalebox{0.95}{0.400}} 
    &\scalebox{0.95}{0.460}&\scalebox{0.95}{0.447}
    &\secondres{\scalebox{0.95}{0.384}}&\secondres{\scalebox{0.95}{0.402}}
    
    &\scalebox{0.95}{0.426}&\scalebox{0.95}{0.446}
    
    &\scalebox{0.95}{0.397}&\scalebox{0.95}{0.412} 
    &\scalebox{0.95}{0.395}&\scalebox{0.95}{0.407} 
    &\scalebox{0.95}{0.438}&\scalebox{0.95}{0.433} 
     &\scalebox{0.95}{0.395} &\scalebox{0.95}{0.424} 
     &\scalebox{0.95}{0.449} &\scalebox{0.95}{0.459} 
     \\
    & \scalebox{0.95}{192} 
    &\boldres{\scalebox{0.95}{0.414}}&\boldres{\scalebox{0.95}{0.420}}
    &\scalebox{0.95}{0.443}&\scalebox{0.95}{0.430}
    &\scalebox{0.95}{0.441} & \scalebox{0.95}{0.436} 
    &\scalebox{0.95}{0.439} & \scalebox{0.95}{0.430} 
    &\scalebox{0.95}{0.512}&\scalebox{0.95}{0.477}
    &\secondres{\scalebox{0.95}{0.436}}&\secondres{\scalebox{0.95}{0.429}}
   
    &\scalebox{0.95}{0.454}&\scalebox{0.95}{0.464}
    
    &\scalebox{0.95}{0.446}&\scalebox{0.95}{0.441} 
    &\scalebox{0.95}{0.490}&\scalebox{0.95}{0.477}
        &\scalebox{0.95}{0.494}&\scalebox{0.95}{0.466} 
   
     &\scalebox{0.95}{0.469} &\scalebox{0.95}{0.470}  &\scalebox{0.95}{0.500} &\scalebox{0.95}{0.482} 
    \\
    & \scalebox{0.95}{336}
    &\boldres{\scalebox{0.95}{0.445}}&\boldres{\scalebox{0.95}{0.434}}
    &\scalebox{0.95}{0.512}&\scalebox{0.95}{0.470}
    & \secondres{\scalebox{0.95}{0.487}} & \secondres{\scalebox{0.95}{0.458}}
    &\scalebox{0.95}{0.480} & \scalebox{0.95}{0.449} 
    &\scalebox{0.95}{0.546}&\scalebox{0.95}{0.496}
    &\scalebox{0.95}{0.638}&\scalebox{0.95}{0.469}
 
    &\scalebox{0.95}{0.493}&\scalebox{0.95}{0.487}
    
    &\scalebox{0.95}{0.489}&\scalebox{0.95}{0.467}
    &\scalebox{0.95}{0.510}&\scalebox{0.95}{0.480}
    &\scalebox{0.95}{0.547}&\scalebox{0.95}{0.495}
    &\scalebox{0.95}{0.490}&\scalebox{0.95}{0.477}
    &\scalebox{0.95}{0.521} &\scalebox{0.95}{0.496} 
    \\
    & \scalebox{0.95}{720} 
    &\boldres{\scalebox{0.95}{0.444}}&\boldres{\scalebox{0.95}{0.459}}
    &\secondres{\scalebox{0.95}{0.497}}&\secondres{\scalebox{0.95}{0.476}}
    & {\scalebox{0.95}{0.503}} & {\scalebox{0.95}{0.491}}
    &\scalebox{0.95}{0.462} & \scalebox{0.95}{0.456} 
    &\scalebox{0.95}{0.544}&\scalebox{0.95}{0.517
    }&\scalebox{0.95}{0.521}&\scalebox{0.95}{0.500}

    &\scalebox{0.95}{0.526}&\scalebox{0.95}{0.526}
    
    &\scalebox{0.95}{0.513}&\scalebox{0.95}{0.510}
    &\scalebox{0.95}{0.568}&\scalebox{0.95}{0.538}
    &\scalebox{0.95}{0.586} &\scalebox{0.95}{0.538}
    &\scalebox{0.95}{0.598} &\scalebox{0.95}{0.544}  
    &\scalebox{0.95}{0.514} &\scalebox{0.95}{0.512}  
    \\
    
    \cmidrule(lr){2-26}
    & \scalebox{0.95}{Avg} 
    &\boldres{\scalebox{0.95}{0.417}}&\boldres{\scalebox{0.95}{0.427}}
    &\scalebox{0.95}{0.459}&\secondres{\scalebox{0.95}{0.444}}
    & \secondres{\scalebox{0.95}{0.454}} & \scalebox{0.95}{0.447}
    &\scalebox{0.95}{0.442} & \scalebox{0.95}{0.434} 
    &\scalebox{0.95}{0.516}&\scalebox{0.95}{0.484}
    &\scalebox{0.95}{0.495}&\scalebox{0.95}{0.450}
  
    &\scalebox{0.95}{0.475}&\scalebox{0.95}{0.480}
    
    &\scalebox{0.95}{0.461}&\scalebox{0.95}{0.457}
    &\scalebox{0.95}{0.491}&\scalebox{0.95}{0.475} 
    &\scalebox{0.95}{0.516}&\scalebox{0.95}{0.483} 
    &\scalebox{0.95}{0.498} &\scalebox{0.95}{0.484}  
    &\scalebox{0.95}{0.496} &\scalebox{0.95}{0.487}\\
    \midrule

    \multirow{5}{*}{\rotatebox{90}{\scalebox{0.95}{ETTh2}}} 
    & \scalebox{0.95}{96} 
    &\secondres{\scalebox{0.95}{0.290}}&\boldres{\scalebox{0.95}{0.340}}
    &\boldres{\scalebox{0.95}{0.289}}&\secondres{\scalebox{0.95}{0.342}}
     & \scalebox{0.95}{0.297} & {\scalebox{0.95}{0.349}} 
     &\scalebox{0.95}{0.301} & \scalebox{0.95}{0.351} 
    &\scalebox{0.95}{0.308}&\scalebox{0.95}{0.355}
    &\scalebox{0.95}{0.340}&\scalebox{0.95}{0.374}
    
    &\scalebox{0.95}{0.372}&\scalebox{0.95}{0.424}
    
    &\scalebox{0.95}{0.340}&\scalebox{0.95}{0.394} 

&\scalebox{0.95}{0.332}&\scalebox{0.95}{0.387}
    &\scalebox{0.95}{0.322}&\scalebox{0.95}{0.364}
    &\scalebox{0.95}{0.358} &\scalebox{0.95}{0.397} 
    &\scalebox{0.95}{0.346} &\scalebox{0.95}{0.388} \\
    
    & \scalebox{0.95}{192} 
    &\boldres{\scalebox{0.95}{0.375}}&\boldres{\scalebox{0.95}{0.392}}
    &\secondres{\scalebox{0.95}{0.378}}&\secondres{\scalebox{0.95}{0.397}}
    & \scalebox{0.95}{0.380} &\scalebox{0.95}{0.400}
    &\scalebox{0.95}{0.378} & \scalebox{0.95}{0.397} 
    &\scalebox{0.95}{0.393}&\scalebox{0.95}{0.405}
    &\scalebox{0.95}{0.402}&\scalebox{0.95}{0.414}
 
    &\scalebox{0.95}{0.492}&\scalebox{0.95}{0.492}
    
    &\scalebox{0.95}{0.482}&\scalebox{0.95}{0.479} 
    &\scalebox{0.95}{0.451}&\scalebox{0.95}{0.457}
    &\scalebox{0.95}{0.405}&\scalebox{0.95}{0.414}
    &\scalebox{0.95}{0.429} &\scalebox{0.95}{0.439} 
    &\scalebox{0.95}{0.456} &\scalebox{0.95}{0.452} \\
    & \scalebox{0.95}{336} 
    &\secondres{\scalebox{0.95}{0.423}}&\scalebox{0.95}{0.435}
    &\scalebox{0.95}{0.432}&\scalebox{0.95}{0.434}
    & {\scalebox{0.95}{0.428}} & \secondres{\scalebox{0.95}{0.432}}
    &\boldres{\scalebox{0.95}{0.422}} & \boldres{\scalebox{0.95}{0.431}}
    &\scalebox{0.95}{0.427}&\scalebox{0.95}{0.436}
    &\scalebox{0.95}{0.452}&\scalebox{0.95}{0.452}
   
    &\scalebox{0.95}{0.607}&\scalebox{0.95}{0.555}
    
    &\scalebox{0.95}{0.591}&\scalebox{0.95}{0.541} 
    &\scalebox{0.95}{0.466}&\scalebox{0.95}{0.473}
    &\scalebox{0.95}{0.435}&\scalebox{0.95}{0.445}
    &\scalebox{0.95}{0.496} &\scalebox{0.95}{0.487} &\scalebox{0.95}{0.482} &\scalebox{0.95}{0.486} \\
    
    & \scalebox{0.95}{720} 
    &\scalebox{0.95}{0.443}&\scalebox{0.95}{0.449}
    &\scalebox{0.95}{0.464}&\scalebox{0.95}{0.464}
    &\boldres{\scalebox{0.95}{0.427}}&\secondres{\scalebox{0.95}{0.445}}
    &\boldres{\scalebox{0.95}{0.427}} & \boldres{\scalebox{0.95}{0.444}} 
    &\scalebox{0.95}{0.436}&\scalebox{0.95}{0.450}
    &\scalebox{0.95}{0.462}&\scalebox{0.95}{0.468}
 
    &\scalebox{0.95}{0.824}&\scalebox{0.95}{0.655}
    
    &\scalebox{0.95}{0.839}&\scalebox{0.95}{0.661} 
    &\scalebox{0.95}{0.485}&\scalebox{0.95}{0.471}
    &\scalebox{0.95}{0.445}&\scalebox{0.95}{0.457}
    &\scalebox{0.95}{0.463} &\scalebox{0.95}{0.474} 
    &\scalebox{0.95}{0.515} &\scalebox{0.95}{0.511} 
    \\
    \cmidrule(lr){2-26}
    & \scalebox{0.95}{Avg} 
    &\secondres{\scalebox{0.95}{0.383}}&\boldres{\scalebox{0.95}{0.404}} 
    &\scalebox{0.95}{0.390}&\scalebox{0.95}{0.409}
    
    &\secondres{\scalebox{0.95}{0.383}} & \scalebox{0.95}{0.407}
    &\boldres{\scalebox{0.95}{0.382}} & \secondres{\scalebox{0.95}{0.406} }
    &\scalebox{0.95}{0.391}&\scalebox{0.95}{0.411}
    &\scalebox{0.95}{0.414}&\scalebox{0.95}{0.427}
   
    &\scalebox{0.95}{0.574}&\scalebox{0.95}{0.531}
    
    &\scalebox{0.95}{0.563}&\scalebox{0.95}{0.519} 
    &\scalebox{0.95}{0.433}&\scalebox{0.95}{0.446} 
    &\scalebox{0.95}{0.402}&\scalebox{0.95}{0.420} 
    &\scalebox{0.95}{0.437} &\scalebox{0.95}{0.449}  
    &\scalebox{0.95}{0.450} &\scalebox{0.95}{0.459} \\
    \midrule

    \multirow{5}{*}{\rotatebox{90}{\scalebox{0.95}{ETTm1}}} 
    & \scalebox{0.95}{96} 
    &\secondres{\scalebox{0.95}{0.322}}&\secondres{\scalebox{0.95}{0.361}}
    &\boldres{\scalebox{0.95}{0.317}}&\boldres{\scalebox{0.95}{0.356}}
    &\scalebox{0.95}{0.334}&\scalebox{0.95}{0.368}
    &\scalebox{0.95}{0.336} & \scalebox{0.95}{0.369} 
    &\scalebox{0.95}{0.352}&\scalebox{0.95}{0.374}
    &\scalebox{0.95}{0.338}&\scalebox{0.95}{0.375}

    &\scalebox{0.95}{0.365}&\scalebox{0.95}{0.387}
    &\scalebox{0.95}{0.346}&\scalebox{0.95}{0.374} 
    &\scalebox{0.95}{0.337}&\scalebox{0.95}{0.374} 
    &\scalebox{0.95}{0.353}&\scalebox{0.95}{0.370} 
    &\scalebox{0.95}{0.379} &\scalebox{0.95}{0.419} 
    &\scalebox{0.95}{0.505} &\scalebox{0.95}{0.475} 
    \\
    & \scalebox{0.95}{192} 
    &\boldres{\scalebox{0.95}{0.357}}&\boldres{\scalebox{0.95}{0.383}}
    &\secondres{\scalebox{0.95}{0.367}}&\secondres{\scalebox{0.95}{0.384}}
    & \scalebox{0.95}{0.377} & \scalebox{0.95}{0.391}
    &\scalebox{0.95}{0.378} & \scalebox{0.95}{0.389} 
    &\scalebox{0.95}{0.390}&\scalebox{0.95}{0.393}
    &\scalebox{0.95}{0.374}&\scalebox{0.95}{0.387}
  
    &\scalebox{0.95}{0.403}&\scalebox{0.95}{0.408}
    
    &\scalebox{0.95}{0.382}&\scalebox{0.95}{0.391} 
    &\scalebox{0.95}{0.382}&\scalebox{0.95}{0.398}
    &\scalebox{0.95}{0.389}&\scalebox{0.95}{0.387} 
    &\scalebox{0.95}{0.426} &\scalebox{0.95}{0.441}  
    &\scalebox{0.95}{0.553} &\scalebox{0.95}{0.496} 
    \\
    & \scalebox{0.95}{336} 
    &\boldres{\scalebox{0.95}{0.382}}&\boldres{\scalebox{0.95}{0.401}}
    &\secondres{\scalebox{0.95}{0.391}}&\secondres{\scalebox{0.95}{0.406}}
     & \scalebox{0.95}{0.426} & \scalebox{0.95}{0.420}
     &\scalebox{0.95}{0.411} & \scalebox{0.95}{0.410} 
    &\scalebox{0.95}{0.421}&\scalebox{0.95}{0.414}
    &\scalebox{0.95}{0.410}&\scalebox{0.95}{0.411}
   
    &\scalebox{0.95}{0.436}&\scalebox{0.95}{0.431}
    
    &\scalebox{0.95}{0.415}&\scalebox{0.95}{0.415} 
    &\scalebox{0.95}{0.420}&\scalebox{0.95}{0.423}
    &\scalebox{0.95}{0.421}&\scalebox{0.95}{0.408} 
    &\scalebox{0.95}{0.445} &\scalebox{0.95}{0.459}  
    &\scalebox{0.95}{0.621} &\scalebox{0.95}{0.537}  
    \\
    & \scalebox{0.95}{720}
    &\boldres{\scalebox{0.95}{0.445}}&\boldres{\scalebox{0.95}{0.435}}
    &\secondres{\scalebox{0.95}{0.454}}&\secondres{\scalebox{0.95}{0.441}}
    & \scalebox{0.95}{0.491} & \scalebox{0.95}{0.459}
    &\scalebox{0.95}{0.469} & \scalebox{0.95}{0.441} 
    &\scalebox{0.95}{0.462}&\scalebox{0.95}{0.449}
    &\scalebox{0.95}{0.478}&\scalebox{0.95}{0.450}
   
    &\scalebox{0.95}{0.489}&\scalebox{0.95}{0.462}
    
    &\scalebox{0.95}{0.473}&\scalebox{0.95}{0.451} 
    &\scalebox{0.95}{0.490}&\scalebox{0.95}{0.471} 
    &\scalebox{0.95}{0.481}&\scalebox{0.95}{0.441} 
    &\scalebox{0.95}{0.543} &\scalebox{0.95}{0.490} &\scalebox{0.95}{0.671} &\scalebox{0.95}{0.561} 
    \\
    \cmidrule(lr){2-26}
    & \scalebox{0.95}{Avg} 
    &\boldres{\scalebox{0.95}{0.376}}&\boldres{\scalebox{0.95}{0.395}}
    &\secondres{\scalebox{0.95}{0.382}}&\secondres{\scalebox{0.95}{0.397}}
    &\scalebox{0.95}{0.407} & \scalebox{0.95}{0.410}
    &\scalebox{0.95}{0.399} & \scalebox{0.95}{0.402} 
    &\scalebox{0.95}{0.406}&\scalebox{0.95}{0.407}
    &\scalebox{0.95}{0.400}&\scalebox{0.95}{0.406}
   
    &\scalebox{0.95}{0.423}&\scalebox{0.95}{0.422}
    
    &\scalebox{0.95}{0.404}&\scalebox{0.95}{0.408} 
    &\scalebox{0.95}{0.407}&\scalebox{0.95}{0.417} 
    &\scalebox{0.95}{0.412}&\scalebox{0.95}{0.402} 
    &\scalebox{0.95}{0.448} &\scalebox{0.95}{0.452}  
    &\scalebox{0.95}{0.588} &\scalebox{0.95}{0.517} \\
    \midrule

    \multirow{5}{*}{\rotatebox{90}{\scalebox{0.95}{ETTm2}}} 
    & \scalebox{0.95}{96} 
    &\boldres{\scalebox{0.95}{0.174}}&\boldres{\scalebox{0.95}{0.255}}
    &\secondres{\scalebox{0.95}{0.175}}&\secondres{\scalebox{0.95}{0.257}}
    & \scalebox{0.95}{0.180}& \scalebox{0.95}{0.264}
    &\scalebox{0.95}{0.181} & \scalebox{0.95}{0.267} 
    &\scalebox{0.95}{0.183}&\scalebox{0.95}{0.270}
    &\scalebox{0.95}{0.187}&\scalebox{0.95}{0.267}
    
    &\scalebox{0.95}{0.197}&\scalebox{0.95}{0.296}
    
    &\scalebox{0.95}{0.193}&\scalebox{0.95}{0.293}
    &\scalebox{0.95}{0.186}&\scalebox{0.95}{0.275} 
    &\scalebox{0.95}{0.183}&\scalebox{0.95}{0.266} 
    &\scalebox{0.95}{0.203} &\scalebox{0.95}{0.287} &\scalebox{0.95}{0.255} &\scalebox{0.95}{0.339} 
    \\
    & \scalebox{0.95}{192} 
    &\boldres{\scalebox{0.95}{0.239}}&\boldres{\scalebox{0.95}{0.299}}
    &\secondres{\scalebox{0.95}{0.240}}&\secondres{\scalebox{0.95}{0.302}}
    & \scalebox{0.95}{0.250} & {\scalebox{0.95}{0.309}}
    &\scalebox{0.95}{0.247} & \scalebox{0.95}{0.308} 
    &\scalebox{0.95}{0.255}&\scalebox{0.95}{0.314}
    &\scalebox{0.95}{0.249}&\scalebox{0.95}{0.309}
  
    &\scalebox{0.95}{0.284}&\scalebox{0.95}{0.361}
    
    &\scalebox{0.95}{0.284}&\scalebox{0.95}{0.361}
    &\scalebox{0.95}{0.259}&\scalebox{0.95}{0.323} 
    &\scalebox{0.95}{0.248}&\scalebox{0.95}{0.305} 
    &\scalebox{0.95}{0.269} &\scalebox{0.95}{0.328} &\scalebox{0.95}{0.281} &\scalebox{0.95}{0.340} 
    \\
    & \scalebox{0.95}{336} 
    &\boldres{\scalebox{0.95}{0.301}}&\boldres{\scalebox{0.95}{0.340}}
    &\secondres{\scalebox{0.95}{0.303}}&\secondres{\scalebox{0.95}{0.343}}
    & {\scalebox{0.95}{0.311}} & {\scalebox{0.95}{0.348}}
    &\scalebox{0.95}{0.309} & \scalebox{0.95}{0.347} 
    &\scalebox{0.95}{0.309}&\scalebox{0.95}{0.347}
    &\scalebox{0.95}{0.321}&\scalebox{0.95}{0.351}
  
    &\scalebox{0.95}{0.381}&\scalebox{0.95}{0.429}
    
    &\scalebox{0.95}{0.382}&\scalebox{0.95}{0.429}
    &\scalebox{0.95}{0.349}&\scalebox{0.95}{0.386} 
    &\scalebox{0.95}{0.309}&\scalebox{0.95}{0.343} 
    &\scalebox{0.95}{0.325} &\scalebox{0.95}{0.366} &\scalebox{0.95}{0.339} &\scalebox{0.95}{0.372} 
    \\
    & \scalebox{0.95}{720} 
    &\secondres{\scalebox{0.95}{0.395}}&\boldres{\scalebox{0.95}{0.396}}
    &\boldres{\scalebox{0.95}{0.392}}&\boldres{\scalebox{0.95}{0.396}}
     & \scalebox{0.95}{0.412} & \scalebox{0.95}{0.407}
     &\scalebox{0.95}{0.406} & \scalebox{0.95}{0.404} 
    &\scalebox{0.95}{0.412}&\scalebox{0.95}{0.404}
    &\scalebox{0.95}{0.408}&\scalebox{0.95}{0.403}
    
    &\scalebox{0.95}{0.549}&\scalebox{0.95}{0.522}
   
    &\scalebox{0.95}{0.558}&\scalebox{0.95}{0.525}
    &\scalebox{0.95}{0.559}&\scalebox{0.95}{0.511} 
    &\scalebox{0.95}{0.410}&\scalebox{0.95}{0.400} 
     &\scalebox{0.95}{0.421} &\scalebox{0.95}{0.415}  &\scalebox{0.95}{0.433} &\scalebox{0.95}{0.432} 
     \\
    \cmidrule(lr){2-26}
    &\scalebox{0.95}{Avg} 
    &\boldres{\scalebox{0.95}{0.277}}&\boldres{\scalebox{0.95}{0.322}}
    &\boldres{\scalebox{0.95}{0.277}}&\secondres{\scalebox{0.95}{0.324}}
    & {\scalebox{0.95}{0.288}} & {\scalebox{0.95}{0.332}}
    &\scalebox{0.95}{0.286} & \scalebox{0.95}{0.332} 
    &\scalebox{0.95}{0.290}&\scalebox{0.95}{0.334}
    &\scalebox{0.95}{0.291}&\scalebox{0.95}{0.333}
    &\scalebox{0.95}{0.353}&\scalebox{0.95}{0.402}
    &\scalebox{0.95}{0.354}&\scalebox{0.95}{0.402} 
    &\scalebox{0.95}{0.339}&\scalebox{0.95}{0.374} 
    &\scalebox{0.95}{0.288}&\scalebox{0.95}{0.328} 
    &\scalebox{0.95}{0.305} &\scalebox{0.95}{0.349} 
    &\scalebox{0.95}{0.327} &\scalebox{0.95}{0.371} \\
     \midrule

     
 \multirow{5}{*}{\rotatebox{90}{\scalebox{0.95}{Weather}}} 
    & \scalebox{0.95}{96} 
    &\boldres{\scalebox{0.95}{0.162}}&\boldres{\scalebox{0.95}{0.208}}
    &\secondres{\scalebox{0.95}{0.163}}&\secondres{\scalebox{0.95}{0.209}}
    & \scalebox{0.95}{0.174} & \scalebox{0.95}{0.214}
    &\scalebox{0.95}{0.191} & \scalebox{0.95}{0.230} 
    &\scalebox{0.95}{0.186}&\scalebox{0.95}{0.227}
    &\scalebox{0.95}{0.172}&\scalebox{0.95}{0.220}
  
    &\scalebox{0.95}{0.198}&\scalebox{0.95}{0.261}
    
    &\scalebox{0.95}{0.195}&\scalebox{0.95}{0.252} 
    &\scalebox{0.95}{0.171}&\scalebox{0.95}{0.227} 
    &\scalebox{0.95}{0.195}&\scalebox{0.95}{0.236} 
    & \scalebox{0.95}{0.217} &\scalebox{0.95}{0.296}
    & \scalebox{0.95}{0.266} &\scalebox{0.95}{0.336}  \\
    
    & \scalebox{0.95}{192} 
    &\boldres{\scalebox{0.95}{0.207}}&\boldres{\scalebox{0.95}{0.249}}
    &\secondres{\scalebox{0.95}{0.211}}&\secondres{\scalebox{0.95}{0.254}}
    &\scalebox{0.95}{0.221} & \secondres{\scalebox{0.95}{0.254}}
    &\scalebox{0.95}{0.236} & \scalebox{0.95}{0.267} 
    &\scalebox{0.95}{0.234}&\scalebox{0.95}{0.265}
    &\scalebox{0.95}{0.219}&\scalebox{0.95}{0.261}
    
    &\scalebox{0.95}{0.239}&\scalebox{0.95}{0.299}
    
    &\scalebox{0.95}{0.237}&\scalebox{0.95}{0.295} 
    &\scalebox{0.95}{0.218}&\scalebox{0.95}{0.280} 
    &\scalebox{0.95}{0.239}&\scalebox{0.95}{0.271} 
    & \scalebox{0.95}{0.276} &\scalebox{0.95}{0.336} 
    & \scalebox{0.95}{0.307} &\scalebox{0.95}{0.367}\\

    
    & \scalebox{0.95}{336} 
    &\secondres{\scalebox{0.95}{0.263}}&\boldres{\scalebox{0.95}{0.290}}
    &\secondres{\scalebox{0.95}{0.263}}&\secondres{\scalebox{0.95}{0.293}}
    & \scalebox{0.95}{0.278} & \scalebox{0.95}{0.296}
    &\scalebox{0.95}{0.289} & \scalebox{0.95}{0.303} 
    &\scalebox{0.95}{0.284}&\scalebox{0.95}{0.301}
    &\boldres{\scalebox{0.95}{0.246}}&\scalebox{0.95}{0.337}
   
    &\scalebox{0.95}{0.285}&\scalebox{0.95}{0.336}
    
    &\scalebox{0.95}{0.282}&\scalebox{0.95}{0.331} 
    &\scalebox{0.95}{0.265}&\scalebox{0.95}{0.317} 
    &\scalebox{0.95}{0.289}&\scalebox{0.95}{0.306} 
    & \scalebox{0.95}{0.339} &\scalebox{0.95}{0.380} 
    &  \scalebox{0.95}{0.359} &\scalebox{0.95}{0.395} \\
    
    & \scalebox{0.95}{720}
    &\secondres{\scalebox{0.95}{0.338}}&\boldres{\scalebox{0.95}{0.340}}
    &{\scalebox{0.95}{0.344}}&\scalebox{0.95}{0.348}
    & \scalebox{0.95}{0.358} & \secondres{\scalebox{0.95}{0.347}}
    &\scalebox{0.95}{0.362} & \scalebox{0.95}{0.350} 
    &\scalebox{0.95}{0.356}&\scalebox{0.95}{0.349}
    &\scalebox{0.95}{0.365}&\scalebox{0.95}{0.359}
    
    &\scalebox{0.95}{0.351}&\scalebox{0.95}{0.388}
    
    &\scalebox{0.95}{0.345}&\scalebox{0.95}{0.382} 
    &\boldres{\scalebox{0.95}{0.326}}&\scalebox{0.95}{0.351} 
    &\scalebox{0.95}{0.360}&\scalebox{0.95}{0.351} 
    & \scalebox{0.95}{0.403} &\scalebox{0.95}{0.428}  
    & \scalebox{0.95}{0.419} &\scalebox{0.95}{0.428} 
    \\
    \cmidrule(lr){2-26}
    & \scalebox{0.95}{Avg} 
    &\boldres{\scalebox{0.95}{0.242}}&\boldres{\scalebox{0.95}{0.272}}
    &\secondres{\scalebox{0.95}{0.245}}&\secondres{\scalebox{0.95}{0.276}}
    & \scalebox{0.95}{0.258}& \scalebox{0.95}{0.278}
    &\scalebox{0.95}{0.270} & \scalebox{0.95}{0.288} 
    &\scalebox{0.95}{0.265}&\scalebox{0.95}{0.285}
    &\scalebox{0.95}{0.251}&\scalebox{0.95}{0.294}
   
    &\scalebox{0.95}{0.268}&\scalebox{0.95}{0.321} 
    &\scalebox{0.95}{0.265}&\scalebox{0.95}{0.315} 
        &\scalebox{0.95}{0.245}&\scalebox{0.95}{0.294} 
    &\scalebox{0.95}{0.271}&\scalebox{0.95}{0.290}
&\scalebox{0.95}{0.309} &\scalebox{0.95}{0.360} 
&\scalebox{0.95}{0.338} &\scalebox{0.95}{0.382}  \\
    \midrule
    


    \multirow{5}{*}{\rotatebox{90}{\scalebox{0.95}{Electricity}}} 
    & \scalebox{0.95}{96} 
    &\scalebox{0.95}{0.174}&\scalebox{0.95}{0.266}
    &\secondres{\scalebox{0.95}{0.153}}&\secondres{\scalebox{0.95}{0.245}}
    & \boldres{\scalebox{0.95}{0.148}} & \boldres{\scalebox{0.95}{0.240}}
    &\scalebox{0.95}{0.198} & \scalebox{0.95}{0.282} 
    &\scalebox{0.95}{0.190}&\scalebox{0.95}{0.296}
    &\scalebox{0.95}{0.168}&\scalebox{0.95}{0.272}
    
    &\scalebox{0.95}{0.180}&\scalebox{0.95}{0.293}
    
    &\scalebox{0.95}{0.210}&\scalebox{0.95}{0.302} 
    &\scalebox{0.95}{0.171}&\scalebox{0.95}{0.260}
    &\scalebox{0.95}{0.198}&\scalebox{0.95}{0.274} 
    &\scalebox{0.95}{0.193} &\scalebox{0.95}{0.308}  
    &\scalebox{0.95}{0.201} &\scalebox{0.95}{0.317}\\
    
    & \scalebox{0.95}{192} 
    &\scalebox{0.95}{0.182}&\scalebox{0.95}{0.273}
    &\secondres{\scalebox{0.95}{0.166}}&\secondres{\scalebox{0.95}{0.257}}
    & \boldres{\scalebox{0.95}{0.162}} &\boldres{\scalebox{0.95}{0.253}}
    &\scalebox{0.95}{0.199} & \scalebox{0.95}{0.285} 
    &\scalebox{0.95}{0.199}&\scalebox{0.95}{0.304}
    &\scalebox{0.95}{0.184}&\scalebox{0.95}{0.322}
    
    &\scalebox{0.95}{0.189}&\scalebox{0.95}{0.302}
    
    &\scalebox{0.95}{0.210}&\scalebox{0.95}{0.305}
    &\scalebox{0.95}{0.177}&\scalebox{0.95}{0.268} 
    &\scalebox{0.95}{0.198}&\scalebox{0.95}{0.278} 
    &\scalebox{0.95}{0.201} &\scalebox{0.95}{0.315}
    &\scalebox{0.95}{0.222} &\scalebox{0.95}{0.334} \\
    
    & \scalebox{0.95}{336} 
    &\scalebox{0.95}{0.197}&\scalebox{0.95}{0.286}
    &\secondres{\scalebox{0.95}{0.185}}&\secondres{\scalebox{0.95}{0.275}}
    & \boldres{\scalebox{0.95}{0.178}} & \boldres{\scalebox{0.95}{0.269}}
    &\scalebox{0.95}{0.212} & \scalebox{0.95}{0.298} 
    &\scalebox{0.95}{0.217}&\scalebox{0.95}{0.319}
    &\scalebox{0.95}{0.198}&\scalebox{0.95}{0.300}

    &\scalebox{0.95}{0.198}&\scalebox{0.95}{0.312}
    
    &\scalebox{0.95}{0.223}&\scalebox{0.95}{0.319}
    &\scalebox{0.95}{0.190}&\scalebox{0.95}{0.284} 
    &\scalebox{0.95}{0.217}&\scalebox{0.95}{0.300} 
    &\scalebox{0.95}{0.214} &\scalebox{0.95}{0.329}  
    &\scalebox{0.95}{0.231} &\scalebox{0.95}{0.443} \\
    
    & \scalebox{0.95}{720} 
    &\scalebox{0.95}{0.236}&\scalebox{0.95}{0.320}
    &\scalebox{0.95}{0.224}&\boldres{\scalebox{0.95}{0.312}}
    & \scalebox{0.95}{0.225} & \scalebox{0.95}{0.317}
    &\scalebox{0.95}{0.253} & \scalebox{0.95}{0.330} 
    &\scalebox{0.95}{0.258}&\scalebox{0.95}{0.352}
    &\secondres{\scalebox{0.95}{0.220}}&\scalebox{0.95}{0.320}

    &\boldres{\scalebox{0.95}{0.217}}&\scalebox{0.95}{0.330}
    
    &\scalebox{0.95}{0.258}&\scalebox{0.95}{0.350} 
    &\scalebox{0.95}{0.228}&\secondres{\scalebox{0.95}{0.316}}
    &\scalebox{0.95}{0.278}&\scalebox{0.95}{0.356} 
    &\scalebox{0.95}{0.246} &\scalebox{0.95}{0.355} 
    &\scalebox{0.95}{0.254} &\scalebox{0.95}{0.361} 
    \\
    \cmidrule(lr){2-26}
    & \scalebox{0.95}{Avg} 
    &\scalebox{0.95}{0.197}&\scalebox{0.95}{0.286}
    &\secondres{\scalebox{0.95}{0.182}}&\secondres{\scalebox{0.95}{0.272}}
     &\boldres{\scalebox{0.95}{0.178}} & \boldres{\scalebox{0.95}{0.270}}
     &\scalebox{0.95}{0.270} & \scalebox{0.95}{0.288} 
    &\scalebox{0.95}{0.216}&\scalebox{0.95}{0.318}
    &\scalebox{0.95}{0.193}&\scalebox{0.95}{0.304}
   
    &\scalebox{0.95}{0.196}&\scalebox{0.95}{0.309}

    &\scalebox{0.95}{0.225}&\scalebox{0.95}{0.319}
    &\scalebox{0.95}{0.192}&\scalebox{0.95}{0.282} 
    &\scalebox{0.95}{0.223}&\scalebox{0.95}{0.302} 
    &\scalebox{0.95}{0.214} &\scalebox{0.95}{0.327} 
    &\scalebox{0.95}{0.227} &\scalebox{0.95}{0.338}\\
   \midrule
     \multicolumn{2}{c|}{\scalebox{0.95}{{$1^{\text{st}}$ Count}}} & \scalebox{0.95}{\boldres{17}} & \scalebox{0.95}{\boldres{22}} & \scalebox{0.95}{4} & \scalebox{0.95}{3} & \scalebox{0.95}{\secondres{5}} & \scalebox{0.95}{{\secondres{4}}} & \scalebox{0.95}{3} & \scalebox{0.95}{2} & \scalebox{0.95}{0} & \scalebox{0.95}{0} & \scalebox{0.95}{1} & \scalebox{0.95}{0} & \scalebox{0.95}{1} & \scalebox{0.95}{0} 
     & \scalebox{0.95}{0} & \scalebox{0.95}{0} 
     & \scalebox{0.95}{1} & \scalebox{0.95}{0}& \scalebox{0.95}{0} & \scalebox{0.95}{0}& \scalebox{0.95}{0} & \scalebox{0.95}{0}& \scalebox{0.95}{0} & \scalebox{0.95}{0}\\ %& 

    \bottomrule
  \end{tabular}
    \end{small}
  \end{threeparttable}
  }
\end{table}
\subsection{Main Results}
The comprehensive forecasting results are presented in Table \ref{tab:full_results}, where the best results are highlighted in bold red and the second-best are underlined in blue.  A lower MSE/MAE indicates a more accurate prediction result. We observe that TimeKAN demonstrates superior predictive performance across all datasets, except for the Electricity dataset, where iTransformer achieves the best result. This is due to iTransformer’s use of channel-wise self-attention mechanisms to model inter-variable dependencies, which is particularly effective for high-dimensional datasets like Electricity. Additionally, both TimeKAN and TimeMixer perform consistently well in long-term forecasting tasks, showcasing the generalizability of well-designed time-series decomposition architectures for accurate predictions. Compared with other state-of-the-art methods, TimeKAN introduces a novel Decomposition-Learning-Mixing framework, closely integrating the characteristics of Multi-order KANs with this hierarchical architecture, enabling superior performance in a wide range of long-term forecasting tasks.

\subsection{Ablation Study}
In this section, we investigate several key components of TimeKAN, including Frequency Upsampling, Depthwise Convolution and Multi-order KANs.
% \vspace{-10pt}
\paragraph{Frequency Upsampling}
To investigate the effectiveness of Frequency Upsampling, we compared it with three alternative upsampling methods that may not preserve frequency information before and after transformation: (1) Linear Mapping; (2) Linear Interpolation; and (3) Transposed Convolution. As shown in Table \ref{tab:frequency_upsampling}, replacing Frequency Upsampling with any of these three methods resulted in a  decline in performance. This indicates that these upsampling techniques fail to maintain the integrity of frequency information after transforming, leading to the Decomposition-Learning-Mixing framework ineffective. This strongly demonstrates that the chosen Frequency Upsampling, as a non-parametric method, is an irreplaceable component of the TimeKAN framework.
\begin{table}[t]
 % \vspace{-10pt}
  \caption{Ablation study of the Frequency Upsampling. The best results are in \textbf{bold}.}\label{tab:frequency_upsampling}
  \vskip 0.05in
  \centering
  \begin{threeparttable}
  \begin{small}
  \renewcommand{\multirowsetup}{\centering}
  \setlength{\tabcolsep}{2.4pt}
  \begin{tabular}{c|cc|cc|cc|cc|cc|cc}
    \toprule
    \multirow{2}{*}{{Datasets}} & 
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTh1}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTh2}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTm1}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTm2}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{Weather}}}&
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{Electricity}}}\\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}  
    Metric & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE} & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE} &\scalebox{1.0}{MSE} & \scalebox{1.0}{MAE} \\
    \toprule
    \scalebox{1.0}{Linear Mapping} & 0.401 & 0.413 & 0.312 & 0.362 & 0.328 & 0.365 & 0.180 & 0.263 & 0.164 & 0.211 &0.184 & 0.275\\
    \scalebox{1.0}{Linear Interpolation} & 0.383 & 0.398 & 0.296 & 0.347 & 0.336 & 0.370 & 0.181 & 0.263  & 0.165 & 0.210 & 0.196 & 0.277\\
    \scalebox{1.0}{Transposed Convolution} & 0.377 & 0.407 & \textbf{0.290} & 0.344 & 0.326 & 0.366 & 0.178 & 0.261 & 0.163 & 0.211 & 0.188 & 0.274 \\
    \scalebox{1.0}{\textbf{Frequency Upsamping}} & \textbf{0.367} & \textbf{0.395} & \textbf{0.290} & \textbf{0.340} & \textbf{0.322} & \textbf{0.361} & \textbf{0.174} & \textbf{0.255} & \textbf{0.162} & \textbf{0.208} & \textbf{0.174}& \textbf{0.266} \\
   
    \bottomrule
  \end{tabular}
    \end{small}
  \end{threeparttable}
\end{table}
% \vspace{-10pt}
\paragraph{Multi-order KANs}
We designed the following modules to investigate the effectiveness of Multi-order KANs: (1) MLPs, which means using MLP to replace each KAN; (2) Fixed Low-order KANs, which means using a KAN of order 2 at each frequency level; and (3) Fixed High-order KANs, which means using a KAN of order 5 at each frequency level. The comparison results are shown in Table \ref{tab:variable_kan}. Overall, Multi-order KANs achieved the best performance. Compared to MLPs, Multi-order KANs perform significantly better, demonstrating that well-designed KANs possess stronger representation capabilities than MLPs and are a compelling alternative. Both Low-order KANs and High-order KANs performed worse than Multi-order KANs, indicating the validity of our design choice to incrementally increase the order of KANs to adapt to the representation of different frequency components. Thus, the learnable functions of KANs are indeed a double-edged sword; achieving satisfactory results requires selecting the appropriate level of function complexity for specific tasks.
\begin{table}[t]
 % \vspace{-20pt}
  \caption{Ablation study of the Multi-order KANs. The best results are in \textbf{bold}.}\label{tab:variable_kan}
  \vskip 0.05in
  \centering
  \begin{threeparttable}
  \begin{small}
  \renewcommand{\multirowsetup}{\centering}
  \setlength{\tabcolsep}{2.7pt}
  \begin{tabular}{c|cc|cc|cc|cc|cc}
    \toprule
    \multirow{2}{*}{{Datasets}} & 
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTh1}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTh2}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTm1}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTm2}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{Weather}}} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11}  
    Metric & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE} & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE} \\
    \toprule
    \scalebox{1.0}{MLPs} & 0.376 & 0.397 & 0.298 & 0.348 & \textbf{0.319} & \textbf{0.361} & 0.178 & 0.264  & \textbf{0.162} & 0.211\\
    \scalebox{1.0}{Fixed Low-order KANs} & 0.376 & 0.398 & 0.292 & 0.341 & 0.327 & 0.366 & 0.175 & 0.257 & 0.164 & 0.211\\
    \scalebox{1.0}{Fixed High-order KANs} & 0.380 & 0.407 & 0.310 & 0.363 & 0.327 & 0.269 & 0.176 & 0.257 & 0.164 & 0.212\\
    \scalebox{1.0}{\textbf{Multi-order KANs}} & \textbf{0.367} & 0.395 & \textbf{0.290} & \textbf{0.340} &0.322 & \textbf{0.361} & \textbf{0.174} & \textbf{0.255} & \textbf{0.162} & \textbf{0.208} \\
   
    \bottomrule
  \end{tabular}
    \end{small}
  \end{threeparttable}
\end{table}
% \vspace{-10pt}
\paragraph{Depthwise Convolution} 
To assess the effectiveness of Depthwise Convolution, we replace it with the following choice: (1) w/o Depthwise Convolution; (2) Standard Convolution; (3) Multi-head Self-Attention. The results are shown in Table \ref{tab:depthwise_conv}. Overall, Depthwise Convolution is the best choice. We clearly observe that removing Depthwise Convolution or replacing it with Multi-head Self-Attention leads to a significant drop in performance, highlighting the effectiveness of using convolution to learn temporal dependencies. When Depthwise Convolution is replaced with Standard Convolution, there are declines in most metrics, which implies that focusing on extracting temporal dependencies individually with Depthwise Convolution, without interference from inter-channel relationships, is a reasonable design.
\begin{table}[t]
 % \vspace{-10pt}
  \caption{Ablation study of the Depthwise Convolution. The best results are in \textbf{bold}.}\label{tab:depthwise_conv}
  \vskip 0.05in
  \centering
  \begin{threeparttable}
  \begin{small}
  \renewcommand{\multirowsetup}{\centering}
  \setlength{\tabcolsep}{2.7pt}
  \begin{tabular}{c|cc|cc|cc|cc|cc}
    \toprule
    \multirow{2}{*}{{Datasets}} & 
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTh1}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTh2}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTm1}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{ETTm2}}} &
    \multicolumn{2}{c}{\rotatebox{0}{\scalebox{1.0}{Weather}}} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11}  
    Metric & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE}  & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE} & \scalebox{1.0}{MSE} & \scalebox{1.0}{MAE} \\
    \toprule
    \scalebox{1.0}{w/o Depthwise Conv} & 0.379 & 0.397 & 0.296 & 0.343 & 0.337 & 0.373 & 0.180 & 0.263 & 0.168 & 0.211\\
    \scalebox{1.0}{Standard Conv} & \textbf{0.364} & \textbf{0.393} & 0.295 & 0.345 & 0.323 & 0.364 & 0.180 & 0.264  & \textbf{0.162} & 0.210\\
    \scalebox{1.0}{Self-Attention} & 0.377 & 0.406 & 0.293 & 0.342 & 0.329 & 0.365 & 0.184 & 0.272 & 0.174 & 0.225\\
    \scalebox{1.0}{\textbf{Depthwise Conv}} & 0.367 & 0.395 & \textbf{0.290} & \textbf{0.340} & \textbf{0.322} & \textbf{0.361} & \textbf{0.174} & \textbf{0.255} & \textbf{0.162} & \textbf{0.208} \\
   
    \bottomrule
  \end{tabular}
    \end{small}
  \end{threeparttable}
\end{table}

% \vspace{-10pt}
\paragraph{Varing Look-back Window}
In principle, extending the look-back window can provide more information for predicting future, leading to a potential improvement in forecasting
performance. A effective long-term TSF method equipped with a strong temporal relation extraction capability should be able to improve forecasting performance when look-back window length increasing \citep{zeng2023transformers}. 
As a model based on frequency decomposition learning, TimeKAN should achieve better predictive performance as the look-back window lengthens, since more incremental frequency information is available for prediction. To demonstrate that TimeKAN benefits from a larger look-back window, we select look-back window lengths from $T=\{48, 96, 192, 336, 512, 720\}$ while keeping the prediction length fixed at 96. As demonstrated in Figure \ref{fig:look_back}, our TimeKAN consistently reduces the MSE scores as the look-back window increases, indicating that TimeKAN can effectively learn from long time series.
\begin{figure}[t]
    \centering
        \includegraphics[width=1\linewidth]{Figure/look_back.pdf}
        % \vspace{-20pt}
    \caption{Comparison of forecasting performance between TimeKAN and other three models with varying look-back windows on ETTm2 and Weather datasets. The look-back windows are selected to be $T \in \{48, 96, 192, 336, 512, 720\}$, and the prediction length is fixed to $F =96$.}
    \label{fig:look_back}
\end{figure}
% \vspace{-10pt}
\subsection{Model Efficiency}
% \vspace{-10pt}

\begin{table}[t]
  \caption{A comparison of model parameters (Params) and multiply-accumulate operations (MACs) for TimeKAN and three other models. To ensure a fair comparison, we fix the prediction length $F=96$
 and the input length $T=96$, and set the input batch size to 32. The lowest computational cost is highlighted in \textbf{bold}.}
  \centering
  \renewcommand{\arraystretch}{1.2} 
  \scalebox{0.85}{
  \setlength{\tabcolsep}{2pt}
  \begin{small} 
  \begin{tabular}{c|cc|cc|cc|cc|cc|cc}
    \toprule
    \multirow{2}{*}{{Datasets}}   & \multicolumn{2}{c}{ETTH1} & \multicolumn{2}{c}{ETTH2} & \multicolumn{2}{c}{ETTm1} & \multicolumn{2}{c}{ETTm2} & \multicolumn{2}{c}{Weather} & \multicolumn{2}{c}{Electricity} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
    Metric  & Params & MACs & Params & MACs & Params & MACs & Params & MACs & Params & MACs & Params & MACs \\
    \midrule
    TimeMixer & 75.50K & 20.37M & 75.50K & 20.37M & 75.50K & 20.37M & 77.77K & 24.18M & 104.43K & 82.62M & 106.83K & 1.26G \\
    iTransformer & 841.57K & 77.46M & 224.22K & 19.86M & 224.22K & 19.86M & 224.22K & 19.86M & 4.83M & 1.16G & 4.83M & 16.29G \\
    PatchTST & 3.75M & 5.90G & 10.06M & 17.66G & 3.75M & 5.90G & 10.06M & 17.66G & 6.90M & 35.30G & 6.90M & 539.38G \\
    \textbf{TimeKAN} & \textbf{12.84K} & \textbf{7.63M} & \textbf{15.00K} & \textbf{8.02M} & \textbf{14.38K} & \textbf{7.63M} & \textbf{38.12K} & \textbf{16.66M} & \textbf{20.94K} & \textbf{29.86M} & \textbf{23.34K} & \textbf{456.50M} \\
    \bottomrule
  \end{tabular}
  \end{small}  
  }
  \label{tab:efficiency}
\end{table}
We compare TimeKAN with MLP-based method TimeMier and Transformer-based methods iTransformer and PatchTST, in terms of model parameters and Multiply-Accumulate Operations (MACs), to validate that TimeKAN is a lightweight and efficient architecture. To ensure a fair comparison, we fix the prediction length  $F=96$ and input length $T = 96$, and set the input batch size to 32. The comparison results are summarized in Table \ref{tab:efficiency}. It is clear that our TimeKAN demonstrates significant advantages in both model parameter size and MACs, particularly when compared to Transformer-based models. For instance, on the Electricity dataset, the parameter count of PatchTST is nearly 295 times that of TimeKAN, and its MACs are almost 118 times greater. Even when compared to the relatively lightweight MLP-based method TimeMixer, TimeKAN shows superior efficiency. On the Weather dataset, TimeKAN requires only 20.05\% of the parameters needed by TimeMixer and only 36.14\% of the MACs. This remarkable efficiency advantage is primarily attributed to the lightweight architectural design. The main computations of the TimeKAN model are concentrated in the M-KAN block, and the Depthwise Convolution we employed significantly reduces the number of parameters through grouped operations. Additionally, the powerful representation capabilities afforded by Multi-order KANs allow us to represent time series with very few neurons. Therefore, we cannot overlook that TimeKAN achieves outstanding forecasting performance while requiring minimal computational resources.





\section{Conclusion}
We proposed an efficient KAN-based Frequency Decomposition Learning architecture (TimeKAN) for long-term time series forecasting. Based on Decomposition-Learning-Mixing architecture, TimeKAN obtains series representations for each frequency band using a Cascaded Frequency Decomposition blocks.  Additionally. a Multi-order KAN Representation Learning blocks further leverage the high flexibility of KAN to learn and represent specific temporal patterns within each frequency band. Finally, Frequency Mixing blocks recombine the frequency bands into the original format. Extensive experiments on real-world datasets demonstrate that TimeKAN achieves the state of the art forecasting performance and extremely lightweight computational consumption.

\section*{Acknowledgements}
This work is supported by Shanghai Artificial Intelligence Laboratory. This work was done during Songtao Huang’s internship at Shanghai Artificial Intelligence Laboratory.
\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}
\clearpage
\appendix
\section{Additional Model Analysis }
\begin{table}[htbp]
  \caption{Full comparison results of model parameters (Params) and multiply-accumulate operations (MACs) for TimeKAN and other models. To ensure a fair comparison, we fix the prediction length $F=96$
 and the input length $T=96$, and set the input batch size to 32. The lowest computational cost is highlighted in \textbf{bold}.}
 % \vspace{10pt}
  \centering
  \renewcommand{\arraystretch}{1.2} 
  \scalebox{0.85}{
  \setlength{\tabcolsep}{2pt}
  \begin{small} 
  \begin{tabular}{c|cc|cc|cc|cc|cc|cc}
    \toprule
    \multirow{2}{*}{{Datasets}}   & \multicolumn{2}{c}{ETTH1} & \multicolumn{2}{c}{ETTH2} & \multicolumn{2}{c}{ETTm1} & \multicolumn{2}{c}{ETTm2} & \multicolumn{2}{c}{Weather} & \multicolumn{2}{c}{Electricity} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
    Metric  & Params & MACs & Params & MACs & Params & MACs & Params & MACs & Params & MACs & Params & MACs \\
    \midrule
    TimeMixer & 75.50K & 20.37M & 75.50K & 20.37M & 75.50K & 20.37M & 77.77K & 24.18M & 104.43K & 82.62M & 106.83K & 1.26G \\
    iTransformer & 841.57K & 77.46M & 224.22K & 19.86M & 224.22K & 19.86M & 224.22K & 19.86M & 4.83M & 1.16G & 4.83M & 16.29G \\
    PatchTST & 3.75M & 5.90G & 10.06M & 17.66G & 3.75M & 5.90G & 10.06M & 17.66G & 6.90M & 35.30G & 6.90M & 539.38G \\
    TimesNet                 & 605.48K    & 18.13G  & 1.19M      & 36.28G   & 4.71M     & 144G    & 1.19M     & 36.28G  & 1.19M      & 36.28G   & 150.30M   & 4.61T   \\
MICN                     & 25.20M     & 71.95G  & 25.20M     & 71.95G   & 25.20M    & 71.95G  & 25.20M    & 71.95G  & 111.03K    & 295.07M  & 6.64M     & 19.5G   \\
Dlinear                  & 18.62K     & 0.6M    & 18.62K     & 0.6M     & 18.62K    & 0.6M    & 18.62K    & 0.6M    & 18.62K     & 0.6M     & 18.62K    & 0.6M    \\
FreTS                    & 3.24M      & 101.46M & 3.24M      & 101.46M  & 3.24M     & 101.46M & 3.24M     & 101.46M & 3.24M      & 101.46M  & 3.24M     & 101.46M \\
FILM                     & 12.58M     & 2.82G   & 12.58M     & 2.82G    & 12.58M    & 2.82G   & 12.58M    & 2.82G   & 12.58M     & 8.46G    & 12.58M    & 8.46G   \\
FEDFormer                & 23.38M     & 24.96G  & 23.38M     & 24.96G   & 23.38M    & 24.96G  & 23.38M    & 24.96G  & 23.45M     & 25.23G   & 24.99M    & 30.89G  \\
AutoFormer               & 10.54M     & 22.82G  & 10.54M     & 22.82G   & 10.54M    & 22.82G  & 10.54M    & 22.82G  & 10.61M     & 23.08G   & 12.14M    & 28.75G  \\
   TimeKAN & 12.84K & 7.63M & 15.00K & 8.02M & 14.38K & 7.63M & 38.12K & 16.66M & 20.94K & 29.86M & 23.34K & 456.50M \\
    \bottomrule
  \end{tabular}
  \end{small}  
  }
  \label{tab:efficiency_all}
\end{table}
\subsection{Computational Complexity Analysis}
In our TimeKAN, the main computational complexity lies in  Fast Fourier Transform (FFT), Depthwise Convolution block and Multi-order KAN block. Consider a time series with length $L$ and the hidden state of each time point is $D$. 
For FFT, the computation complexity is $\mathcal{O}(L\ logL)$. For Depthwise Convolution block, if we set the convolutional kernel to $M$ and stride to 1, the complexity is $\mathcal{O}(LDM)$. Finally, assuming that the highest order of Chebyshev polynomials is $K$, the complexity of Multi-order KAN block is $\mathcal{O}(LD^{2}K)$. Since $M,D,K$ are constants that are independent of the input length $L$, the computational complexity of both the Depthwise Convolution block and the Multi-order KAN block can be reduced to $\mathcal{O}(L)$, which is linear about the sequence length. In summary, the overall computational complexity is $\mathrm{max}(\mathcal{O}(L\ logL), \mathcal{O}(L) = \mathcal{O}(L\ logL)$. When the input is a multivariate sequence with $M$ variables, the computational complexity will expand to $\mathcal{O}(ML\ logL)$ due to our variable-independent strategy.


\subsection{Model Efficiency}
Here, we provide the complete results of model efficiency in terms of parameters and MACs in Table \ref{tab:efficiency_all} . As can be seen, except for DLinear, our TimeKAN consistently demonstrates a significant advantage in both parameter count and MACs compared to any other model. DLinear is a model consisting of only a single linear layer, which makes it the most lightweight in terms of parameters and MACs. However, the performance of DLinear already shows a significant gap when compared to state-of-the-art methods. Therefore, our TimeKAN actually achieves superior performance in both forecasting accuracy and efficiency.




\subsection{Error Bars}
To evaluate the robustness of TimeKAN, we repeated the experiments on three randomly selected seeds and compared it with the second-best model (TimeMixer). We report the mean and standard deviation of the results across the three experiments, as well as the confidence level of TimeKAN's superiority over TimeMixer. The results are averaged over four prediction horizons (96, 192, 336, and 720). As shown in the Table \ref{tab:confidence}, in most cases, we have over 90\% confidence that TimeKAN outperforms the second-best model and demonstrates good robustne of TimeKAN.
\begin{table}[htbp]
\caption{Standard deviation and statistical tests for our TimeKAN method and second-best method (TimeMixer) on five datasets.}
\label{tab:confidence}
  \centering
  \begin{threeparttable}
  \begin{small}
  \renewcommand{\multirowsetup}{\centering}
  \setlength{\tabcolsep}{2pt}
\begin{tabular}{l|cccccc}
\toprule
        Metric& \multicolumn{3}{c}{MSE}                                    & \multicolumn{3}{c}{MAE}                                     \\
        \cmidrule(lr){0-1} \cmidrule(lr){2-4} \cmidrule(lr){5-7}
        Dataset & TimeKAN     & TimeMixer   & Confidence                     & TimeKAN     & TimeMixer                        & Confidence \\
        \midrule
ETTh1   & \textbf{0.422±0.004} & 0.462±0.006 & 99\%                           & \textbf{0.430±0.002} & 0.448±0.004                      & 99\%       \\
ETTh2   & \textbf{0.387±0.003} & 0.392±0.003 & 99\%                           & \textbf{0.408±0.003} & \multicolumn{1}{l|}{0.412±0.004} & 90\%       \\
ETTm1   & \textbf{0.378±0.002} & 0.386±0.003 & 99\%                           & \textbf{0.396±0.001} & 0.399±0.001                      & 99\%       \\
ETTm2   & 0.278±0.001          & 0.278±0.001 & — & \textbf{0.324±0.001} & 0.325±0.001                      & 90\%       \\
Weather & \textbf{0.243±0.001} & 0.245±0.001 & 99\%                           & \textbf{0.273±0.001} & 0.276±0.001                      & 99\%  \\  
\bottomrule
\end{tabular}
\end{small}
  \end{threeparttable}
\end{table}

\subsection{Frequency Learning with Longer Window}
% \vspace{-10pt}
\begin{table}[htbp]
  \caption{Comparison on the Electricity dataset when the look back window is expanded to 512.}
  \label{tab:ecl_long_window}
  % \vspace{10pt}
  \centering
   \resizebox{0.6\columnwidth}{!}{
  \begin{threeparttable}
  \begin{small}
  \renewcommand{\multirowsetup}{\centering}
  \setlength{\tabcolsep}{3pt}
  \begin{tabular}{l|cc|cc|cc|cc}
    \toprule
    \multirow{2}{*}{Models}  & \multicolumn{2}{c|}{96} & \multicolumn{2}{c|}{192} & \multicolumn{2}{c}{336} &\multicolumn{2}{c}{720} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
    & MSE &MAE& MSE &MAE & MSE &MAE & MSE &MAE  \\
    \midrule
   MOMENT & 0.136      & 0.233     & 0.152      & 0.247      & 0.167      & 0.264      & 0.205      & 0.295   \\
    \midrule
   TimeMixer & 0.135      & 0.231     & \textbf{0.149}      & \textbf{0.245}      & 0.172      & 0.268      & \textbf{0.203}      & 0.295   \\
    \midrule
   TimeKAN & \textbf{0.133}      & \textbf{0.230}     & \textbf{0.149}      & 0.247      & \textbf{0.165}      & \textbf{0.261}      & \textbf{0.203}      & \textbf{0.294}  \\
    \bottomrule
  \end{tabular}
    \end{small}
  \end{threeparttable}
  }
\end{table}
In Table \ref{tab:full_results}, TimeKAN performs relatively poorly on the Electricity dataset. We infer that its poor performance on the electricity dataset is due to the overly short look-back window ($T=96$), which cannot provide sufficient frequency information. To verify this, we compare the average number of effective frequency components under a specific look-back window. Specifically, we randomly select a sequence of length $T$ from the electricity dataset and transform it into the frequency domain using FFT. We define effective frequencies as those with amplitudes greater than 0.1 times the maximum amplitude. Then, we take the average number of effective frequencies obtained across all variables to reflect the amount of effective frequency information provided by the sequence. When $T=96$ (the setting in this paper), the average number of effective frequencies is 10.69. When we extend the sequence length to 512, the average number of effective frequencies becomes 19.74. Therefore, the effective frequency information provided by 512 time steps is nearly twice that of 96 time steps. This indicates that $T=96$ loses a substantial amount of effective information.\par
To validate whether using $T=512$ allows us to leverage more frequency information, we extend the look-back window of TimeKAN to 512 on the electricity dataset and compare it with the state-of-the-art methods TimeMixer and time series foundatiom model MOMENT \citep{moment2024}. The results are shown in Table \ref{tab:ecl_long_window}. Although TimeKAN performs significantly worse than TimeMixer when $T=96$, it achieves the best performance on the electricity dataset when the look-back window is extended to 512. This also demonstrates that TimeKAN can benefit significantly from richer frequency information.
\subsection{Impact of Number of Frequency Bands}
To explore the impact of the number of frequency bands on performance, we set the number of frequency bands to 2, 3, 4, and 5. The effects of different frequency band divisions on performance are shown in the Table \ref{tab:num_freq}.  As we can see, in most cases, dividing the frequency bands into 3 or 4 layers yields the best performance. This aligns with our prior intuition: dividing into two bands results in excessive frequency overlap, while dividing into five bands leads to too little information within each band, making it difficult to accurately model the information within that frequency range.
% \vspace{-10pt}
\begin{table}[htbp]
  \caption{Impact of number of frequency bands on performance under the 96-to-96 prediction setting.}
  \label{tab:num_freq}
  % \vspace{10pt}
  \centering
   \resizebox{0.6\columnwidth}{!}{
  \begin{threeparttable}
  \begin{small}
  \renewcommand{\multirowsetup}{\centering}
  \setlength{\tabcolsep}{3pt}
  \begin{tabular}{c|cc|cc|cc}
    \toprule
    \multirow{2}{*}{Number of Frequency}  & \multicolumn{2}{c|}{ETTh2} & \multicolumn{2}{c|}{Weather} & \multicolumn{2}{c}{Electricity}  \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} 
    & MSE &MAE& MSE &MAE & MSE &MAE  \\
    \midrule
   2                        & 0.292          & 0.340          & 0.164          & 0.209          & 0.183          & 0.270          \\
3                        & \textbf{0.290} & \textbf{0.339} & 0.163          & 0.209          & 0.177          & 0.268          \\
4                        & \textbf{0.290} & 0.340          & \textbf{0.162} & \textbf{0.208} & \textbf{0.174} & \textbf{0.266} \\
5                        & 0.295          & 0.346          & 0.164          & 0.211          & 0.177          & 0.273     \\
    \bottomrule
  \end{tabular}
    \end{small}
  \end{threeparttable}
  }
\end{table}
\section{Mathematical Details}\label{sec:detail}
\subsection{Kolmogorov-Arnold Network}\label{sec:kan_detail}

Kolmogorov-Arnold  representation theorem states that any multivariate continuous function can be expressed as a combination of univariate functions and addition operations. More specifically, a multivariate continuous function $g:[0,1]^{n} \Rightarrow \mathbb{R}$  can be defined as:
\begin{equation}
    g(x) = g(x_{1}, \cdots, x_{n}) = \sum^{2n+1}_{i=1}\Phi_{i}\Big(\sum_{j=1}^{n}\phi_{ij}(x_{j})\Big)
\end{equation}
where $\phi_{ij}$ and $\Phi_{i}$ are univariate functions. 
Following the pattern of MLP, Kolmogorov-Arnold Network (KAN) \citep{liu2024kan} extends the Kolmogorov-Arnoldtheorem to deep representations, i.e., stacked multilayer Kolmogorov-Arnold representations. Assume that KAN is composed of $L+1$ layer neurons and the number of neurons in layer $l$ is $n_{l}$. The transmission relationship between the $j$-th neuron in layer $l+1$ and all neurons in layer $l$ can be expressed as:
\begin{equation}
    x_{l+1,j} = \sum^{n_{l}}_{i=1}\phi_{l,j,i}(x_{l,i})
\end{equation}
We can simply understand that each neuron is connected to other neurons in the previous layer through a univariate function $\phi$. Similar to MLP, the computation of all neurons at layer $l$ can be reorganized as a function matrix multiplication  $\boldsymbol{\Phi}_{l-1}$. Therefore, given a input vector ${x}\in \mathbb{R}^{n_{0}}$, the final output of KAN network is: 
\begin{equation}
    \mathrm{KAN}(x) = (\boldsymbol{\Phi}_{L-1}\circ\cdots\circ\boldsymbol{\Phi}_{1}\circ\boldsymbol{\Phi}_{0})x
\end{equation}
In vanilla KAN \citep{liu2024kan}, the univariate function $\phi_{l,j,i}$ is parametrized using B-splines, which is a class of smooth curves constructed via segmented polynomial basis functions. 
To ensure the stability and enhance the representational capacity,  KAN overlays the spline function on a fixed basis function $b$, which is typically the SiLU function:
\begin{equation}
    \phi(x)= w_{b}b(x)+w_{s}\mathrm{spline(x)}
\end{equation}
\begin{equation}
    \mathrm{spline}(x) = \sum_{i}c_{i}B_{i}(x)
\end{equation}
where $w_b$ and $w_s$ are learnable weights and $\mathrm{spline(x)}$ is the spline function constructed from the linear combination of B-spline basis functions $B_{i}$.
However, the complex recursive computation process of high-order B-spline functions hinders the efficiency of KAN. Therefore, in this work, we adopt the simpler Chebyshev polynomial as the univariate function to replace the B-spline function \citep{ss2024chebyshev}. The univariate function defined by the Chebyshev polynomial is given as follows:
\begin{equation}
    T_{k}(x) = \mathrm{cos}(k\  \mathrm{arccos}(x))
\end{equation}
Here, $k$ represents the order of the polynomial. Then, we consider the univariate function $\Phi$ as a linear combination of Chebyshev polynomials with different orders:
\begin{equation}
     x_{l+1,j} = \sum^{n_{l}}_{i=1}\phi_{l,j,i}(x_{l,i}) = \sum_{i=1}^{n_{l}} \sum_{k=0}^{K} \Theta_{i,k} T_{k}(\mathrm{tanh}(x_{l,i}))
\end{equation}
Where $\Theta_{i,k}$ is the coefficients of $k$-th order Chebyshev polynomials acting on the $x_{l,i}$ and $\mathrm{tanh}$ is the tanh activation function used to normalize the inputs to between -1 and 1. By adjusting the highest order of the Chebyshev polynomial $K$, we can control the fitting capability of KAN. This also inspires tour design of the Multi-order KAN to dynamically represent different frequencies.

\subsection{Fourier Transform}\label{sec:fft_detail}

Time series are often composed of multiple frequency components superimposed on each other, and it is difficult to observe these individual frequency components directly in the time domain. Therefore, transforming a time series from the time domain to the frequency domain for analysis is often necessary. The Discrete Fourier Transform (DFT) is a commonly used domain transformation algorithm that converts a discrete-time signal from the time domain to the complex frequency domain. Mathematically, given a sequence of real numbers $x[n]$ in time domain, where $n=0,1,\dots, N-1$ the DFT process can be described as:
\begin{equation}
X[k] = \sum_{n=0}^{N-1} x[n] \cdot e^{-i \frac{2 \pi}{N} k n} = \sum_{n=0}^{N-1} x[n] \left( \cos\left(\frac{2 \pi}{N} k n\right) - i \sin\left(\frac{2 \pi}{N} k n\right) \right), \quad k = 0, 1,  \dots, N-1
\end{equation}
where $X[k]$ is the $k$-th frequency component of frequency domain signal and $i$ is the imaginary unit. Similarly, we can use Inverse DFT (iDFT) to convert a frequency domain signal back to the time domain.
\begin{equation}
x[n] = \frac{1}{N} \sum_{k=0}^{N-1} X[k] \cdot e^{i \frac{2 \pi}{N} k n} = \frac{1}{N} \sum_{k=0}^{N-1} X[k] \left( \cos\left(\frac{2 \pi}{N} k n\right) + i \sin\left(\frac{2 \pi}{N} k n\right) \right)
\end{equation}
The computational complexity of the DFT is typically $\mathcal{O}({N^{2})}$\citep{zhou2022fedformer}.  In practice, we use the Fast Fourier Transform (FFT) to efficiently compute the Discrete Fourier Transform (DFT) of complex sequences, which reduces the computational complexity to $\mathcal{O}(N\ \mathrm{log}N)$. Additionally, by employing the Real FFT (rFFT), we can compress an input sequence of $N$ real numbers into a signal sequence in the complex frequency domain containing $N/2+1$ frequency components.


\end{document}