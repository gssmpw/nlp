\section{Background and Related Works}
\label{sec:background-and-related-works}


\subsection{Sound Recognition}
\label{sec:sound-recognition}
\noindent
\textbf{Audio Processing:} Audio signals are high-dimensional time-series data with complex patterns and temporal dependencies, making analysis challenging. 
\shepherd{Recent work in efficient sound classification uses Short-Time Fourier Transform (STFT) with CNNs or self-attention models to extract key time-domain features____. These methods rely only on time-domain features and often perform poorly in environmental sound recognition. Additionally, STFT introduces overhead and lacks flexibility for selective frequency analysis, as it provides uniform resolution across bands. On the another hand, recent studies show that sub-spectral features in the frequency domain are effective for acoustic scene classification, as environmental sounds often have unique frequency distributions____. Therefore, we explore using sub-spectral features for resource-efficient sound recognition.}

\noindent
\textbf{Wavelet Transform:}
The wavelet transform provides a flexible approach for sub-spectral feature extraction, enabling analysis of non-stationary audio signals by decomposing them with orthonormal basis functions in $L^2$ space____. Compared to STFT, the wavelet transform provides better localization in both time and frequency domains____. The discrete wavelet transform (DWT)____ uses a high-pass filter and a low-pass filter at various levels to break the signal into detailed and approximate coefficients.
DWT focuses on low-frequency decomposition, while the wavelet packet transform (WPT)____ provides a more detailed and flexible decomposition by analyzing both low and high frequencies, offering a comprehensive signal representation across all frequency bands. Recent research has explored integrating wavelet transforms with deep learning for sound recognition____. \shepherd{However, since frequency-domain features are not uniformly distributed, fine-tuning resolution is essential for efficient classification.}

\subsection{Cloud Offloading}
\noindent
\textbf{Offloading Solution:}
\shepherd{
Cloud offloading allocates partial computations to a cloud server, reducing the workload on edge devices. We summarize recent works in Table~\ref{tab:sota}. DeepCOD____, SEDAC____, and LimitNet____ split the inference pipeline across wireless channels. FLEET____ adds early exits for resource savings. CACTUS____ exchanges models for context-aware inference. We refer to these solutions as “cloud-dependent,” as their functionalities rely on the server. However, collaboration over LPWANs is limited by resource constraints and unreliable channels, making cloud-dependent strategies impractical. First, cloud-dependent approaches ignore edge resource constraints, offloading even basic inference task to the server. In contrast, empirical measurements show LoRa radios consume up to 40$\times$ more power for uplink and 6$\times$ for downlink than on-device computation____. Additionally, unreliable channels make consistent offloading infeasible. Data packets may be lost or corrupted during transmission, and edge devices may lack resources for retransmission. To tackle these challenges, we propose a novel \textit{cloud assistance} solution, contrasting with cloud-dependent strategies. In ORCA, the complete inference pipeline remains on edge devices for inference reliability. The server assists edge devices in identifying key input features, reducing their computational load.}

% \begin{figure}[tp]
%  \vspace{-0cm}
%     \centering
%     \includegraphics[width=0.8\linewidth]{figures/server-dependent.png}
%     \caption{Server-dependent offloading strategy under different communication and constrained energy budgets. }
%     \label{fig:server-dependent}
% \end{figure}


\noindent
\textbf{Data Compression:}
\shepherd{Data compression mitigates high communication costs under low bitrates. DeepCOD____ and FLEET____ use autoencoders to compress latent embeddings dynamically. SEDAC____ and LimitNet____ select key input features for communication efficiency. LPAI____ uploads selected audio clips for cloud training and requires downloading updated models. These approaches focus on transmitting compressed embeddings, input features, or model weights essential for cloud inference or training, aligning with the cloud-dependent strategy. However, large payloads are unsuitable for low-bitrate networks and resource-constrained devices. We propose an alternative approach to transmit smaller data and leverage complex server-side processing for cloud assistance.} In ORCA, we use low-level feature abstractions like low-resolution audio spectrograms as a compressed form of data, significantly reducing transmission size. Despite the small size, the low-resolution feature abstraction aids the inference process substantially, as we will demonstrate later in this paper. We draw an analogy to the bounding box mechanism used in regional proposal networks (RPN)____ and YOLO____, which utilize low-resolution images to propose potential regions of interest and perform efficient classification within these bounded regions. However, SEDAC____ indicates that it is infeasible to deploy RPN for audio tasks on resource-constrained devices due to the high computational demands and fundamental differences between the vision and audio domains. Thus, we conclude that there is a clear need for an audio-adaptive, cloud-assisted, and communication-efficient collaborative learning framework to enable resource-efficient environmental sound recognition.


% To facilitate efficient environmental sound recognition, we incorporate WPT spectrogram into our design as a compact way of representing audio data. SEDAC____ also uses a similar approach and shows that, by combining attention-based feature selection over the temporal domain, spectrogram-based feature representation is effective in reducing the complexity of inference. However, while the STFT-based mel-spectrogram can preserve fine-grain spectral characteristics at high resolution, such computation can be expensive and burdensome when performed at the edge. Instead, we propose to use the more flexible and lightweight WPT to generate spectrograms at varying resolutions over different frequency bands.