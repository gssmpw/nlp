\section{ORCA Design}
\label{sec:system-design}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[tp]
    \centering
    \includegraphics[width=\textwidth]{figures/overview.png}
    \vspace{-0.5cm}
    \caption{\shepherd{ORCA cloud-assisted design overview.}}
    \vspace{-0.2cm}
    \label{fig:system-overview}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Overview}
\label{sec:system-overview}
Based on the observations and discussions in Section~\ref{sec:background-and-related-works} and~\ref{sec:preliminary-study}, we argue that an ideal edge-cloud collaborative learning system over LPWANs should have the following design considerations. First, to tackle the unreliability of wireless channels, a cloud-assisted strategy should be adopted rather than the state-of-the-art cloud-dependent offloading. Second, to adapt to the low bit rates of LPWANs and the on-device resource constraints, we demand a more efficient information exchange strategy. Additionally, from an audio processing perspective, we look for a more effective feature selection method to reduce input size and therefore reduce on-device computation overheads while maintaining comparable accuracy performances. Informed by these demands, we introduce our novel design of a resource-aware cloud-assisted environmental sounds recognition system, primarily operating over LoRa networks. Our system features resource-aware and communication-adaptive cloud assistance, enabling efficient and flexible cloud offloading under resource constraints and unreliable communications. Furthermore, we apply a novel self-attention-based frequency band feature selection method with the wavelet transform to effectively select important features for efficient on-device inference. We illustrate the workflow of the ORCA cloud-assisted framework in Figure~\ref{fig:system-overview}:

\noindent
\shepherd{\textbf{Step~\textcircled{\small{1}}:} Initially, the edge device preprocesses audio signals using low-level WPT to generate a low-resolution spectrogram. Preprocessing details are in Section~\ref{sec:preprocess}, and optimized resolution selection based on wireless channel feedback, e.g., Adaptive Data Rate (ADR),  is discussed in Section~\ref{sec:resource-aware-cloud-assistance}.}

\noindent
\shepherd{\textbf{Step~\textcircled{\small{2}}:} The resulting low-resolution spectrogram is transmitted to the server via uplink LoRa channel, using ADR-recommended parameters.}

\noindent
\shepherd{\textbf{Step~\textcircled{\small{3}}:} Upon receiving the low-resolution spectrogram, the server processes it using a pre-trained contrastive vision transformer~\cite{dosovitskiy2020vit} to extract an attention mask through attention rollout~\cite{abnar2020quantifying}. Details of the cloud model are provided in Section~\ref{sec:attention-mask-generation}.}

\noindent
\shepherd{\textbf{Step~\textcircled{\small{4}}:} The extracted attention mask, along with ADR feedback, is sent back to the edge device via downlink. Resource efficiency adaptations using ADR feedback are further discussed in Section~\ref{sec:resource-aware-cloud-assistance}.}

\noindent
\shepherd{\textbf{Step~\textcircled{\small{5}}:} The edge device validates the received attention mask. If invalid or lost, it bypasses cloud assistance and performs standalone on-device inference. We will also discuss this in Section~\ref{sec:resource-aware-cloud-assistance}.}

\noindent
\shepherd{\textbf{Step~\textcircled{\small{6}}:} If the mask is valid, the edge device refines the resolution to construct a multi-resolution spectrogram with details in Section~\ref{sec:spectral-encoding-cnn}.}

\noindent
\shepherd{\textbf{Step~\textcircled{\small{7}}:} Finally, with the multi-resolution spectrogram, the edge device performs efficient inference using spectral encoding and spectral CNNs with details in Section~\ref{sec:spectral-encoding-cnn}.}

\shepherd{To address resource constraints and dynamic communication costs, ORCA introduces a novel resource-aware scheduler for efficient cloud assistance on batteryless devices. Our algorithm dynamically adjusts to variable communication costs, enabling optimized communication scheduling in scenarios of high communication costs for adaptive transmission and bypassing. We will detail this algorithm in Section~\ref{sec:resource-aware-cloud-assistance}. }



% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.9\linewidth]{figures/selective-wpt.png}
%     \caption{Wavelet transform based on attention masks for selective frequency band resolution refinement.}
%     \label{fig:selective-WPT}
% \end{figure}




\subsection{Preprocessing}
\label{sec:preprocess}
\shepherd{To minimize communication costs, ORCA employs a low-resolution wavelet spectrogram as a compact and informative abstraction for cloud assistance. 
We use the WPT with depth $n$ to extract coarse frequency-domain features from the input audio waveform, producing a spectrogram $S$ with a frequency dimension of $2^n$. To generalize features over time and reduce payload size, we apply average pooling along the time axis, transforming $S$ into a square matrix $S_a$ in dimension of $2^n$. We refer to $S_a$ as the cloud-assisted spectrogram and define its dimension as the cloud assistance resolution $R_a = 2^n$, with selection details in Section~\ref{sec:resource-aware-cloud-assistance}.}


\subsection{Attention Mask Generation}
\label{sec:attention-mask-generation}
\shepherd{
In this section, we discuss how the server identifies important features from the assistance spectrogram $\mathcal{S}_a$. Specifically, we define important features as the most informative frequency bands, guided by preliminary studies. The edge device then leverages this information, encoded as an attention mask, to enhance on-device inference accuracy in later steps.
}

\noindent
\subsubsection{Vision Transformer for Assistance Spectrogram.}
\shepherd{ORCA server-side design leverages the self-attention mechanism to dynamically encode the importance of input features. The server processes the assistance spectrogram $\mathcal{S}_a$ by patching it into tokens and computing a self-attention map to highlight key regions. We show the attention computation in Figure~\ref{fig:attention-block}.
First, we adopt the same architecture from the vision transformer~\cite{dosovitskiy2020vit} and divide the input spectrogram into $p^2$ patches. To preserve the spectrogramâ€™s spectral-temporal properties, we apply positional encoding by adding trainable encoding to each patch.
Next, we pass the patches through a convolutional patch embedding layer, encoding each patch into an embedding of dimension $E$.
The resulting embedding is passed through the $i$-th attention block to compute the attention matrix $A_i$, sequentially. Formally, $A_i = \text{Softmax}(Q_i \cdot K_i^T / \sqrt{E})$, where $Q_i$ and $K_i$ are the query and key embeddings at each layer. The attention matrix $A_i$ of size $p^2 \times p^2$ captures the relative importance between patch pairs, aiding in identifying the most informative frequency bands, as discussed next.
}

\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/attention-block.png}
    \vspace{-0.3cm}
    \caption{Attention computation for attention rollout.}
    \label{fig:attention-block}
    \vspace{-0.3cm}
\end{figure}


\noindent
\subsubsection{Attention Mask Generation.}
Recall that the attention matrix $A_i$ represents the attention map of the $i$-th attention block, encoding the relative importance between patches in a spectrogram. 
% Sequential application of attention blocks can cause attention signals to vanish due to constant information mixing between tokens~\cite{abnar2020quantifying}. 
\shepherd{
Inspired by~\cite{abnar2020quantifying}, we compute the rollout attention map $\widetilde{A} = \Pi^{1}_{i=n} A_i = A_n A_{n-1} \cdots A_{1}$ for importance estimations.} This approach aggregates attention matrices from all blocks, enhancing interpretability and preventing attention scores from vanishing. 
The resulting rollout attention map $\widetilde{A}$ has dimensions $p^2 \times p^2$. 
Then, we aim to identify the most informative frequency bands for the edge. Intuitively, a frequency band is informative if patches within that band have high attention scores, as this indicates that the cloud model prioritizes those patches. Therefore, let $\widetilde{a}_{ij}$ represent the rollout attention between patches $i$ and $j$ in $\widetilde{A}$. We compute the column-wise summation $C$ of $\widetilde{A}$ as $C = [c_1, c_2, \cdots, c_{p^2}]$ where $c_j = \sum_{i=1}^{p^2} \widetilde{a}_{ij}$. 
The vector $C$ is reshaped into a 2D importance matrix $C'\in \mathbb{R}^{p \times p}$, where each entry represents the importance of a patch in the input WPT spectrogram. 
\shepherd{We select frequency bands by summing contiguous $k$ rows in $C'$ and identifying the highest sum, where $k$ is a predefined hyperparameter agreed upon by the server and edge device.} A binary vector of length $p$ records the selected indices, forming the spectral attention mask, which is sent to edge devices.

\noindent
\subsubsection{Contrastive Pre-Training.} \shepherd{The method above relies on a vision transformer capable of identifying informative frequency bands from the WPT spectrogram.} Given the lack of labeled data for frequency-domain feature importance information, we propose training the cloud model offline in an unsupervised manner. \shepherd{Inspired by contrastive learning, where the model learns to produce distinctive features via contrastive loss, we create attracting and contrasting pairs by masking random frequency bands and use triplet loss~\cite{schroff2015facenet} on the flattened output of vision transformer as representations.} Overall, the advantage of ORCA attention-based cloud assistance solution is twofold: first, it uses self-attention over spectrograms to guide clients in focusing on informative frequency bands, which not only improves inference accuracy on the resource-constrained edge devices but also reduces computational load by minimizing the edge model input size. Additionally, transmitting the low-resolution assistance spectrogram and attention masks is highly communication-efficient, significantly reducing communication costs and latency.


\subsection{\shepherd{Cloud-Assisted Inference}}
\label{sec:spectral-encoding-cnn}
\shepherd{
% Spectrograms provide detailed information across all frequency bands, and wavelet transform enables extraction of frequency-band details at flexible resolutions. In preliminary study, we demonstrated that higher-resolution spectrograms achieve high accuracy but increase resource usage. Inspired by the preliminary study 2, we propose a three-fold on-device inference solution: Multi-resolution Refinement, Spectral Encoding, and Multi-resolution CNN designs, selectively focusing on information-rich spectral bands from the aforementioned cloud assistance step. and still maintain high accuracy. This section details our design of a multi-resolution spectral encoding CNN (Steps \textcircled{\small{6}} and \textcircled{\small{7}} in Figure~\ref{fig:system-overview}), optimized for resource-constrained devices through the use of cloud-generated spectral attention masks discussed in the previous section.
Following the discussion on server-generated attention masks, we explore how edge devices can leverage this information for efficient on-device inference. First, we introduce the \textit{Multi-resolution Refinement} module, which extracts high-resolution frequency bands guided by attention masks. After refinement, two challenges remain: (i) embedding high-resolution spectral bands and (ii) creating a multi-resolution representation for accurate and efficient inference. For (i), we propose \textit{Spectral Encoding}, a trainable weight that encodes high-resolution frequency band-specific knowledge. For (ii), we employ \textit{Multi-resolution CNNs} to process the combination of high-resolution bands from multi-resolution refinement and their corresponding spectral encoding for efficient on-device classification.}

\noindent
\subsubsection{Multi-resolution Refinement.}
\shepherd{The server-generated spectral attention mask captures key frequency bands. It guides the edge device to selectively extract high-resolution spectrograms via wavelet transform. Let $R_l$ denote the pre-defined dimension of the low-resolution spectrogram and $R_h$ the dimension of the high-resolution spectral bands, this refinement results in $R_l$-dimensional low-resolution spectrograms and $R_h$-dimensional high-resolution spectrograms frequency bands.} To further reduce dimension, adaptive average pooling is applied along the time dimension, regularizing the size of both spectrograms.

\noindent
\subsubsection{Spectral Encoding.}
\shepherd{Since each frequency band captures unique frequency-domain properties, spectrograms from different bands should be interpreted accordingly. Using separate CNNs per band~\cite{phaye2019subspectralnet} is memory-inefficient and costly. Instead, inspired by transformer's positional encoding, we use spectral encoding, a trainable weight that encodes frequency band-specific information. It is then concatenated channel-wise to corresponding high-resolution bands, as shown in Figure~\ref{fig:spectral-encoding}. This approach helps the network to learn spectral-specific knowledge independently of the input spectrogram.}

\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/spectral-encoding.png}
    \vspace{-0.8cm}
    \caption{\shepherd{Spectral encoding and multi-resolution CNNs.}}
    \label{fig:spectral-encoding}
    \vspace{-0.4cm}
\end{figure}


\noindent
\subsubsection{Multi-resolution CNN.}
\shepherd{The next challenge is to create a multi-resolution representation for inference. As discussed in preliminary studies in Section~\ref{sec:preliminary-study}, discriminative information varies between spectral bands of the spectrogram. With the full low-resolution spectrogram available from preprocessing, we use two 2-layer shallow CNN as encoders, one for low resolution and one for high resolution. The encoded features are fused channel-wise into a single vector and fed into the Multi-Res classifier for final classification. This architecture reduces inference costs by leveraging spectrograms at different resolutions. If cloud assistance is unavailable, an additional Single-Res classifier is employed to process the output of the Low-Res encoder only. All components are pre-trained offline in a two-stage supervised process. First, we train the low-res encoder, high-res encoder, and multi-resolution classifier together with the attention masks generated by the pre-trained cloud vision transformer. In the second stage, we freeze all other components and train the single-resolution classifier independently.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/intermittent.png}
    \vspace{-1.0cm}
    \caption{Execution model (up), capacitor voltage (mid), and relative power consumptions (low).  }
    \label{fig:intermittent}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Resource-Aware Scheduler}
\label{sec:resource-aware-cloud-assistance}
\shepherd{Given the high energy cost of communication and wireless uncertainty, dynamically managing data transmission size is essential for resource-efficient cloud assistance.} Experimental measurements~\cite{mileiko2023run} indicate that the uplink phase dominates energy consumption in each communication round and varies with channel conditions. Thus, a key component of our framework is optimizing uplink data transmission. 
\shepherd{We introduce a resource-aware, communication-adaptive resolution algorithm. This algorithm dynamically schedules the assistance resolution $R_a$ (as discussed in Section~\ref{sec:preprocess}) based on energy storage and communication quality for resource-efficient cloud assistance.}

\noindent
\subsubsection{Communication Model.} 
As discussed in Section~\ref{sec:system-overview}, ORCA uses two communication phases for one round of cloud assistance, uplink (Tx) and downlink (Rx). It adopts the intermittent computation model from~\cite{mileiko2023run} which concludes an uplink and a downlink in the same power cycle with a synchronized sleep period interleaved. \shepherd{The key advantage of this design is maintaining inference integrity and timeliness for cloud assistance, even during prolonged power failures in batteryless systems.} We illustrate this design in Figure~\ref{fig:intermittent}. Within one power cycle, edge device initiates by restoring the communication parameters, spreading factor (SF) and transmitting power ($P_{\text{Tx}}$) once waking up at voltage threshold $V_{\text{on}}$. Then it goes through sampling and preprocessing, Tx, sleeping, Rx, and on-device inference sequentially as discussed in Section~\ref{sec:system-overview}. Between each power cycle, our edge device checkpoints and restores SF and $P_{\text{Tx}}$ in and out of the non-volatile memory (yellow blocks in Figure~\ref{fig:intermittent}). This ensures their synchronizations to the server's recommendation for reliable communication. Here, the generic ADR algorithm~\cite{Semtech2016LoRaWAN} is employed to estimate the optimal communication parameters ensuring communication reliability. Every time the server receives an uplink packet, it calculates and compares the SNR margins to the optimal values and recommends the optimal SF and $P_{\text{Tx}}$ back to the edge device in downlink message. Edge device can then checkpoint these parameters for next round of communication. The next challenge is to complete restoring, preprocessing, Tx, sleep, Rx, inference, and checkpointing within one power cycle.

% Additionally, based on the measurements by~\cite{mileiko2023run}, uplink dominates the energy consumption and therefore, our algorithm mainly focuses on optimizing uplink data transmission.
% For uplink, the transmission time, known as the time-on-air (ToA), depends on the data rate (DR) and can be estimated by $\text{ToA} = \frac{S + S_{\text{p}}}{\text{DR}}$ for sending a payload size of $S$ with a fixed preamble $S_{\text{p}}$. 
% Conversely, a fixed time window ($T_{\text{Rx}}$) is set up for listening to the downlink signal after the sleeping period timeout. 
% Given the variability of the wireless channel, the costs of ensuring signal quality for the uplink changes constantly. To address this, we employ the adaptive data rate (ADR)~\cite{Semtech2016LoRaWAN}. By analyzing SNR history, the server recommends an optimal spreading factor (SF) and transmit power ($P_{\text{Tx}}$) for the edge device. Edge device then adjusts these parameters to ensure reliable uplink transmission. 



\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/workflow.png}
    \vspace{-0.5cm}
    \caption{Cloud-assisted offloading flow chart.}
    \label{fig:workflow}
    \vspace{-0.2cm}
\end{figure}

\noindent
\subsubsection{Adaptive Resolution.}
\shepherd{Given the proposed communication model and parameters, we first examine the key factors influencing energy consumption.} Since batteryless devices usually wake up at a pre-defined voltage threshold, the energy budget per power cycle is typically fixed and can be estimated by $E_{\text{cap}}=\frac{C}{2}(V_{\text{on}}^2 - V_{\text{off}}^2)$, where $C$ is capacitance, and $V_{\text{on}}$ and $V_{\text{off}}$ represent the microcontroller switching voltage thresholds (on and off, respectively), as depicted in Figure~\ref{fig:intermittent}. 
We propose ORCA resource-aware adaptive resolution algorithm for cloud assistance, designed to adapt to varying communication costs and complete each round of cloud assistance within a single power cycle. Our approach determines an optimal assistance resolution $R_a$ which in turn defines the payload size $S={R_a}^2$ for uplink. We model the adaptive resolution algorithm with the parameters followed. The uplink energy consumption $E_{\text{Tx}}$ can be estimated as: $E_{\text{Tx}} = P_{\text{Tx}} \cdot \text{ToA} = P_{\text{Tx}} ({R_a}^2+S_{\text{p}})/\text{DR}$.
where the uplink transmission time, known as the time-on-air (ToA), depends on the various data rate (DR) under different SF and can be estimated by $\text{ToA} = (S + S_{\text{p}})/\text{DR}$ for sending a payload size of $S$ with a fixed preamble $S_{\text{p}}$. 
The downlink energy cost is estimated as $E_{\text{Rx}}=P_{\text{Rx}} \cdot T_{\text{Rx}}$, the product of the downlink power and the downlink window length. Additionally, $E_{\text{Pre}}$, $E_{\text{sleep}}$, and $E_{\text{inf}}$ are for energy usage during preprocessing, sleep period, and inference, respectively, and can be considered as constants in ORCA. Moreover, to formulate the optimization problem, we define the one-hot encoded resolution selection vector $x$ for resolution ${R_a}$ and the pre-estimated accuracy vector $a$ for accuracy under different ${R_a}$ values. To complete a round of cloud assistance within a single power cycle, the model ensures $E_{\text{Pre}} + E_{\text{Tx}} + E_{\text{sleep}} + E_{\text{Rx}} + E_{\text{inf}} \leq E_{\text{cap}}$. 
We define the following optimization problem, finding the optimal resolution selection vector $x$ to maximize the accuracy under energy constraints:
% \setlength{\abovedisplayskip}{2pt}
% \setlength{\belowdisplayskip}{2pt}
\begin{equation*}
\begin{aligned}
\max_{x} \ a^{T}x \quad \textrm{s.t.} \quad & E_{\text{Tx}}(x)+E_{\text{Pre}} + E_{\text{sleep}} + E_{\text{Rx}} + E_{\text{inf}}\leq E_{\text{cap}}\\[-0.2em] 
  &\textbf{1}^Tx = 1, \ x_i = \{0, 1\} \\[-0.2em]
  \end{aligned}
\end{equation*}
The optimal resolution selection is derived by ${R_a}=\text{argmax}(x)$, and, specifically, we define ${R_a}=0$ as local bypassing without cloud assistance. In practice, since the optimization search space is small (as $R_a$ is chosen from only a few options) and the capacitor is pre-selected to ensure enough budget for at least local inference without cloud assistance, we simply iterate through all feasible solutions within the energy budget and select the one with the highest estimated accuracy.

\noindent
\subsubsection{Workflow.}
The workflow is presented in Figure~\ref{fig:workflow}. Starting with the communication parameters in the yellow block, we use the energy storage $E_{\text{cap}}$ and communication parameter recommendations from the previous round as the budget and cost inputs, respectively. These inputs are applied to the optimization problem, where the edge device determines the optimal $R_a$ for maximum assistance accuracy and then uploads the low-resolution spectrogram. The server extracts and transmits the attention masks along with the ADR in the downlink back to the edge device. The edge device verifies downlink message validity using the CRC error check or by missing packets after a downlink timeout, treating invalid messages as such. If valid, the edge device proceeds with the multi-resolution inference step as described in Section~\ref{sec:spectral-encoding-cnn}. Otherwise, due to resource constraints, the device bypasses retransmission and cloud assistance, performing single-resolution on-device inference as also detailed in Section~\ref{sec:spectral-encoding-cnn}. Overall, ORCA using fixed energy budgets and dynamic data size offers two major advantages. First, unlike reconfigurable energy storage solutions, which require additional hardware and may face durability or read-write cycle limitations~\cite{colin2018reconfigurable, bakar2022protean, mileiko2023run}, our strategy does not require extra hardware. Second, our algorithm intelligently balances communication costs and accuracy gains by adaptively selecting the amount of resources for cloud assistance. As shown in Figure~\ref{fig:resource-aware}: (i) when communication cost is low, the edge device sends a high-resolution spectrogram for better inference accuracy; (ii) when communication cost is high, it sends a low-resolution spectrogram with a smaller payload to manage energy cost, resulting in lower accuracy; (iii) if communication is unstable with packet loss, the device bypasses cloud assistance and performs local inference to avoid costly retransmissions.


\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/resource-aware.png}
    \vspace{-0.5cm}
    \caption{Resource-aware adaptive resolution for cloud assistance.}
    \label{fig:resource-aware}
    \vspace{-0.2cm}
\end{figure}


