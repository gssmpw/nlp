\section{Algorithm Evaluation}
\label{sec:evaluation-on-datasets}

In this section, we assess the effectiveness of ORCA's sub-spectral feature selection algorithm for environmental sound classification using public datasets.


\subsection{Experimental Setup}

\noindent
\textbf{Datasets and Model.}
We evaluate ORCA's model architecture using several public environmental sound datasets, including ESC10~\cite{piczak2015esc}, ESC-nature, ESC-animal, the subsets of ESC50~\cite{piczak2015esc}, US8k~\cite{salamon2017us8k}, and DESED~\cite{turpault2019desed}. The multi-resolution spectral encoding CNN model as discussed in Section~\ref{sec:spectral-encoding-cnn} includes two convolutional layers for each of the low-resolution and high-resolution encoders, and a multi-resolution classifier consisting of two convolutional layers followed by one fully-connected layer.

% \begin{table}[tp]
%     \caption{Details of selected environmental sound datasets.}
%     \vspace{-0.3cm}
%     \centering
%     \resizebox{\linewidth}{!}{%
%     \begin{tabular}{|l|c|c|c|l|}
%     \hline 
%     Datasets & Clips & Sec & Cls & Examples \\
%     \hline
%     ESC-10~\cite{piczak2015esc} & 400 & 5 & 10 & Human, animal, machine  \\
%     ESC-nature~\cite{piczak2015esc} & 400 & 5 & 10 & Water, weather, bird  \\
%     ESC-animal~\cite{piczak2015esc} & 400 & 5 & 10 & Mammal, bird, insect  \\
%     US8k~\cite{salamon2017us8k} & 8732 & 4 & 10 & Human, machine, car  \\
%     DESED~\cite{turpault2019desed} & 7155 & 2 & 10 & Human, pet, indoor  \\
%     \hline
%     \end{tabular}
%     }
%     \label{tab:dataset}
%     \vspace{-0.5cm}
% \end{table}

\noindent
\textbf{Baselines.}
We compare ORCA's attention-based subspectral feature selection strategy with the following state-of-the-art audio feature selection baselines:

\begin{list}{$\bullet$}{\leftmargin=1em \itemindent=0em}
\item \textbf{\textit{Multiscale spectrogram:} } MAST~\cite{zhu2023multiscale} uses fixed resolution spectrogram as audio feature extraction. This includes low-resolution spectrogram on a scale of 16x16 and high-resolution spectrogram on a scale of 64x64. 

\item \textbf{\textit{Time-domain attention selection:} } This implementation uses the attention-based time-domain selection method of SEDAC~\cite{ahn2024split} to identify the most informative audio clips in spectrogram.

\item \textbf{\textit{Frequency-domain amplitude selection:} } This method selects frequency bands with the highest amplitude as in SubSpectralNet~\cite{phaye2019subspectralnet}.
\end{list}

\noindent
\textbf{Metrics.}
For all baseline feature selection methods, classification is performed using a four-layer CNN followed by a fully connected layer. To evaluate ORCA’s effectiveness in extracting the most informative spectrogram features, we compare classification accuracy with state-of-the-art methods under varying $K$ -- the percentage of most informative regions selected. For MAST~\cite{zhu2023multiscale}, we only report accuracy only for high and low resolutions.


\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/sota.png}
    \vspace{-0.6cm}
    \caption{Classification accuracy comparisons to the state-of-the-art under various $K$.}
    \label{fig:sota}
    \vspace{-0.4cm}
\end{figure}

\subsection{Comparisons to the State-of-the-art}
\label{sec:comparisons-to-the-state-of-the-art}
Figure~\ref{fig:sota} presents the comparisons for baseline methods and ORCA over five datasets with $K=$ $12.5\%$, $25\%$, $37.5\%$, and $50\%$, as we observe negligible accuracy difference from the high-resolution baseline at $K=50\%$ and higher.
ORCA achieves accuracy closest to the high-resolution baseline, outperforming other efficient baseline methods at each $K$ value. Under extreme resource constraints at $K=12.5\%$, ORCA shows only a 2–5 percentage point (p.p.) accuracy drop compared to the high-resolution baseline, surpassing other baselines by up to 20 p.p. As $K$ increases, ORCA’s accuracy approaches the high-resolution baseline while remaining significantly above other designs. At $K=50\%$, ORCA’s accuracy degradation is just 0.2–2.5 p.p., consistently outperforming other efficient baselines by 2.5–12.5 p.p., demonstrating the effectiveness of ORCA. A key difference between ORCA multi-resolution design and single-resolution methods is in handling less informative regions. Single-resolution methods like SEDAC~\cite{ahn2024split} and SubSpectralNet~\cite{phaye2019subspectralnet} discard these regions entirely. In contrast, our results show that simpler processing of less informative regions, alongside sophisticated processing of the most informative ones, yields superior performance with minimal overhead.

\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/inference.png}
    \vspace{-0.5cm}
    \caption{Accuracy comparisons of local inference resolutions with top-$K=25\%$ informative regions. }
    \vspace{-0.5cm}
    \label{fig:inference}
\end{figure}

\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/collaborate.png}
    \vspace{-0.5cm}
    \caption{Accuracy comparisons of different assistance resolution $R_a$. }
    \label{fig:collaborate}
    \vspace{-0.6cm}
\end{figure}



\subsection{Ablation Study}
\label{sec:sensitivity-analysis}
In this section, to further understand how model parameters influence the classification accuracy, we investigate the key resolution parameters in ORCA with fixed $K$ values: inference resolution ($R_l$ and $R_h$) and assistance resolution ($R_a$) as discussed in Section~\ref{sec:system-design}. In ORCA, the selection of $R_l$ and $R_h$ is pre-defined based on the developer's choices and hardware capabilities. On the other hand, the assistance resolution $R_a$ represents the resolution of the low-resolution spectrogram sent to the server for attention mask generation and determines the cost of communication. This parameter is dynamically adjusted in ORCA system based on communication quality as mentioned in Section~\ref{sec:resource-aware-cloud-assistance}. 


\noindent
\textbf{Effects of Inference Resolution ($R_l$ and $R_h$):} 
Figure~\ref{fig:inference} presents the accuracy of various multi-resolution configurations for on-device inference. Single-resolution setups are used for comparison purposes and indicated by the spectrogram dimensions (e.g., 8, 16, 64). Multi-resolution setups are denoted by a combination of $R_l$ and $R_h$, separated by a plus symbol (e.g., 16+64 for $R_l=16$ and $R_h=64$).
The results demonstrate that both $R_l$ and $R_h$ influence the classification accuracy. For example, 16+64 outperforms 8+64 due to the lower low-resolution dimension, while 8+64 outperforms 8+32 due to the lower high-resolution dimension. Overall, our experiments show a relationship between inference resolutions and accuracy. Higher resolutions demonstrate superior performances while requiring more computational resources. On the opposite, lower resolutions show degraded accuracy while being budget-friendly. 



\noindent
\textbf{Effects of Assistance Resolution ($R_a$):} 
Figure~\ref{fig:collaborate} presents how the assistance resolution $R_a$ influences the classification accuracy. The number represents $R_a$, and "local-only" is for local on-device inference only without cloud assistance. Our results demonstrate that assistance improves accuracy up to 11 p.p., compared to on-device inference only. Overall, classification accuracy positively correlates to $R_a$ used for cloud assistance, and thus correlates to the packet sizes and energy costs for transmissions. These results will be used as accuracy estimators (i.e. the accuracy vector $a$ in the optimization problem in Section~\ref{sec:resource-aware-cloud-assistance}) storing on edge devices for resource-aware cloud assistance in the subsequent real testbed implementation in Section~\ref{sec:testbed}.
