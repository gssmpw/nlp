\section{Real-World Testbed Evaluation}
\label{sec:testbed}

\subsection{Testbed Implementation}
\label{sec:testbed-implementation}

\noindent
\textbf{Edge device:} We use the 16-bit MSP430FR5994 microcontroller~\cite{texas2021msp430}(\textcircled{\small{a}} in Figure~\ref{fig:real-deployment}) with 8KB of SRAM and 256KB of FRAM, operating at a 16MHz clock frequency, as the edge device. We connect MSP430 to the RFM95W LoRa Radio Transceiver~\cite{hoperf2016RFM95} and a 2dBi spring antenna (\textcircled{\small{b}} in Figure~\ref{fig:real-deployment}). The solar board (\textcircled{\small{c}} in Figure~\ref{fig:real-deployment}) connects to the BQ25570 energy harvester~\cite{ti2019bq25570} (\textcircled{\small{d}} in Figure~\ref{fig:real-deployment}) with a capacitor (\textcircled{\small{e}} in Figure~\ref{fig:real-deployment}), serving as the primary ambient power source for the edge devices. A VM1010 microphone~\cite{vesper2017VM1010} with wake-on-sound technology captures environmental sounds exceeding a predefined amplitude threshold (\textcircled{\small{f}} in Figure~\ref{fig:real-deployment}).

\noindent
\textbf{Server:}
Raspberry Pi 4 Model B~\cite{RaspberryPi4B2019} with 8GB of memory is used as a server to assist the MSP430 edge device (\textcircled{\small{g}} in Figure~\ref{fig:real-deployment}). An Adafruit Feather M0 with RFM95 microcontroller~\cite{adafruit2019FeatherM0} (\textcircled{\small{h}} in Figure~\ref{fig:real-deployment}) with a 5.8dBi fiberglass antenna (\textcircled{\small{i}} in Figure~\ref{fig:real-deployment}) is connected to the Raspberry Pi through the serial port. Both edge and server operate on a 125MHz channel within the spreading factors between 7 to 12 and Tx power from 5 to 17 dBm.

\noindent
\textbf{Software:} The PyWavelets library~\cite{Lee2019PyWavelet} is employed for preprocessing the audio clips, while PyTorch~\cite{paszke2019pytorch} is used for pretraining the server and edge models. Raspberry Pi server also uses PyTorch~\cite{paszke2019pytorch} for cloud assistance. Additionally, we have developed a custom wavelet transform library and an inference engine~\cite{zhang2022demo} integrated with the Low-Energy Accelerator (LEA) on the MSP430~\cite{MSPLEA2016}, aimed at accelerating both preprocessing and inference processes. For the server side, we use the Arduino RadioHead library~\cite{mccauley2013radiohead}. For MSP430, We adapt the RadioHead library~\cite{mccauley2013radiohead, eccob2020msp430} over the SPI interface to facilitate communication with the RFM95W transceiver for both uplink and downlink. To the best of our knowledge, this is the first usable and open-source implementation of the LoRa library for the MSP430. 

\noindent
\textbf{Controlled environment:}
To ensure fair comparisons and reproducibility, we collect real-world data and replicate it in a controlled environment using a two-step testbed. First, we implement an MSP430-based data collector with an RFM95W transceiver and TSL2591 luminosity sensor~\cite{ams2013TSL2591} to gather communication traces (SNR, RSSI), LoRa parameter recommendations (SF, $P_{\text{Tx}}$) , and light conditions from target environments. In the second step, we simulate these environments in the lab using programmable Philips Hue bulbs~\cite{lightbulb2024philips} controlled by the phue Python library~\cite{studioimaginaire2020phue} to replicate lighting, with the server assisting edge inference by simulating communication traces and providing parameter recommendations. Environmental sound clips are played through a speaker.

\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/real-deployment.png}
    \vspace{-0.8cm}
    \caption{Testbed deployment, edge device (left) and server (right). We detail the setup \textcircled{\small{a}}-\textcircled{\small{i}} in Section~\ref{sec:testbed-implementation}.}
    \vspace{-0.2cm}
    \label{fig:real-deployment}
\end{figure}


\subsection{Experimental Setup}

\noindent
\textbf{Datasets:} We randomly select environmental sound clips from the US8k~\cite{salamon2017us8k} dataset to simulate real-world audio events. The audios are padded to 4-second clips and sampled at 16kHz. Additionally, we collect real solar energy traces (around 10k lux luminosity in outdoor daylight conditions), and LoRa communication traces, including SNR, communication costs recommended by ADR, and packet losses for two scenarios:
\begin{list}{$\bullet$}{\leftmargin=1em \itemindent=0em}
    \item \textbf{\textit{Scenario 1:}} We set up the server and edge device at a distance of 500m in a complex urban environment with potential obstructions including buildings and moving vehicles. The SNR, packet losses, and ADR traces are presented in top of Figure~\ref{fig:testbed-communication}. Since this scenario requires high energy costs for long-distance wireless communication, we select 100mF capacitor as energy storage.
    \item \textbf{\textit{Scenario 2:}} We set up our system at a distance of 300m in line of sight. The SNR, packet losses, and ADR traces are presented in top of Figure~\ref{fig:testbed-communication}. We select 33mF capacitor as energy storage for low cost short-distance communication. All communication traces are sampled at 1-minute intervals. 
\end{list}


\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/communication.png}
    \vspace{-0.8cm}
    \caption{Traces of SNR, packet loss, and the ADR for Scenario 1 (up) and Scenario 2 (down). }
    \label{fig:testbed-communication}
    \vspace{-0.3cm}
\end{figure}

\noindent
\textbf{Baselines:} We summarize the baseline methods as followed:

\begin{list}{$\bullet$}{\leftmargin=1em \itemindent=0em}
\item \textbf{\textit{On-device Inference:}} This implementation adopts the classic on-device inference without cloud offloading~\cite{gobieski2019intelligence,lee2019intermittent} for different resolution spectrograms. 

\item \textbf{\textit{Audio Compression:}} MP3 and AAC~\cite{tomar2006converting} are the two state-of-the-art audio compression algorithms for compressing raw audio waveforms and cloud offloading. This includes different compression bitrates. 

\item \textbf{\textit{Autoencoder Offload:}} DeepCOD~\cite{yao2020deep} and FLEET~\cite{huang2023rethink} compress latent features using an autoencoder before transmitting them to the server. This implementation includes different levels of compression rates. 

\item \textbf{\textit{Progressive Offload:}} Both SEDAC~\cite{ahn2024split} and LimitNet~\cite{hojjat2024limitnet} use context-aware feature selection for offloading. They are combined into one baseline, termed progressive attention-based selection, since LimitNetâ€™s saliency method~\cite{hojjat2024limitnet} is unsuitable for spectrograms. This implementation incrementally includes top-$K$ most informative regions.

\end{list}

\noindent
\textbf{Metrics:} We measure the uplink payload size for cloud assistance, energy consumption, end-to-end inference latency, classification accuracy, and system overhead of ORCA. For energy, latency, and accuracy, we compute the average values across all events in two scenarios respectively.



\subsection{Payload Size}
\label{sec:payload-size}

One of the major benefits of ORCA's cloud assistance strategy we discussed previously is that we can now share much smaller low-resolution spectrogram for feature selection on the cloud, rather than directly use them for high-accuracy cloud inference. Therefore, data compression can be more aggressive than a cloud-dependent strategy without severe accuracy degradation. In Figure~\ref{fig:system-payload}, we compare ORCA to the baselines in terms of accuracy and uplink payload size. First, we notice that the time-series audio compression algorithms MP3 and AAC have poor accuracy even with thousand bytes of payload which is $10\times$-$100\times$ larger than ours. The primary reason is they are generic algorithms for audio compression and are not co-optimized with downstream classification tasks. Next, we notice ORCA outperforms both autoencoder and progressive offloading methods with up to 10 p.p. accuracy advantage and $4\times$-$8\times$ payload savings within the range of 0.1-1 KB, thanks to ORCA's cloud assistance strategy which requires minimal communication for low-resolution spectrograms. Additionally, our method shows a clear 5-20 p.p. accuracy advantage under 100 bytes, the primary operation bitrates under LoRa low data rate mode for long-range transmission~\cite{Semtech2016LoRaWAN}. 

\begin{figure}[tp]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/payload-sota.png}
    \vspace{-0.3cm}
    \caption{Comparisons of accuracy and payload sizes for baseline methods.}
    \label{fig:system-payload}
    \vspace{-0.3cm}
\end{figure}



\begin{table}[tp]
    \caption{\shepherd{On-device energy measurement and end-to-end inference latency for each stage. Uplink is a variable for optimization and mentioned in the text.}}
    \centering
    \begin{tabular}{lcccc}
    \hline 
    Metrics & Preprocess & Server & Downlink & Inference  \\
    \hline
    Energy (mJ) & 28.2 & - & 76.5  & 142.0  \\
    Latency (Sec) & 4.0 & 0.02 & 2.0 & 20.1  \\
    \hline
    \end{tabular}
    \label{tab:energy-latency}
    \vspace{-0.3cm}
\end{table}

\begin{figure*}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/system-energy-accuracy.png}
    \vspace{-0.7cm}
    \caption{The total energy usage for one round of cloud assistance with various uplink payload payloads and LoRa parameters, (a) for Scenario 1 and (b) for Scenario 2. (c) is for accuracy measurement given payloads. }
    \label{fig:system-energy-accuracy}
    \vspace{0cm}
\end{figure*}


\begin{figure*}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/scenario1-scenario2-sota.png}
    \vspace{-0.6cm}
    \caption{The average accuracy, energy, and end-to-end latency for baselines in Scenario 1 (left) and 2 (right).}
    \vspace{-0.2cm}
    \label{fig:scenarios-sota}
\end{figure*}




\subsection{Energy Consumption}

\shepherd{As discussed in Section~\ref{sec:resource-aware-cloud-assistance}, the on-device energy usage in preprocessing, downlink, and inference stages are considered constants in our design. We present measurements of these values in Table~\ref{tab:energy-latency}.} Specifically, preprocessing is done in real-time along with sampling by using an LEA hardware accelerator without time and energy overhead. Additionally, the uplink energy consumption is variable with respect to different payload sizes and LoRa parameters in the optimization problem. Therefore, we measure the total energy consumption of one round cloud assistance as in Section~\ref{sec:resource-aware-cloud-assistance} with respect to the uplink payload size ($S$) under different LoRa parameters in Figure~\ref{fig:system-energy-accuracy}(a) and (b) for Scenario 1 and 2. The results show that with smaller spreading factor (SF) and transmitting power ($P_{\text{Tx}}$) values, ORCA consumes fewer resources as the energy consumption per byte is lower. Given fixed energy budgets $E_{\text{cap1}}=685$mJ and $E_{\text{cap2}}=225$mJ for Scenario 1 and 2 respectively as the red lines in Figure~\ref{fig:system-energy-accuracy}(a) and (b), smaller SF and $P_{\text{Tx}}$ values allow larger payload size $S=R_a^2$ and therefore higher assistance resolution $R_a$. Then, the higher assistance resolution $R_a$ leads to higher feature importance estimation on server side and results in higher cloud assistance accuracy as Figure~\ref{fig:system-energy-accuracy}(c). 
 
Furthermore, we compare the energy consumption of ORCA to the state-of-the-art methods in Figure~\ref{fig:scenarios-sota}. Our results show that ORCA outperforms both autoencoder and progressive offloading by 25\% and 90\% energy savings in Scenario 1 and 40\% and 60\% energy savings in Scenario 2 even with up to 15 p.p. accuracy advantage. The primary reason for these savings is the huge payload savings in ORCA design as we explained in Section~\ref{sec:payload-size}. Additionally, ORCA avoids retransmission which costs additional energy consumptions under resource constraints. ORCA shows a clear advantages of 40$\times$ to 80$\times$ and 8$\times$ to 25$\times$ energy savings in two scenarios compared to MP3 and AAC audio compression algorithms. ORCA saves 64\% and 90\% energy compared to the vanilla on-device inference with merely 1 p.p. accuracy degradation by leveraging the resource-efficient cloud-assisted feature selection. 



\subsection{End-to-End Latency}
\shepherd{First, we present measurements of ORCAâ€™s constant latency components, including on-device preprocessing, server processing, downlink, and on-device inference in Table~\ref{tab:energy-latency}. We then incorporate variable uplink latency under two scenarios to evaluate overall end-to-end latency, comparing ORCA with state-of-the-art methods in Figure~\ref{fig:scenarios-sota}.} We notice that given the huge energy usage of LoRa communication, our energy harvesting system takes 50-60 seconds and 10-30 seconds to replenish the energy storage for two scenarios respectively. Compared to autoencoder and progressive baselines, ORCA outperforms both baselines by 40\% and 95\% latency improvements in Scenario 1 and 75\% and 85\% latency improvements in Scenario 2 under accuracy advantages respectively. The primary reason for these improvements is that ORCA avoids the latency of recharging across power cycles by using the resource-aware energy cloud assistance strategy we discussed in Section~\ref{sec:resource-aware-cloud-assistance} to fit all data needed in one round of cloud assistance within one power cycle. Additionally, ORCA avoids retransmission which increases end-to-end with long power cycles. ORCA also achieves 125$\times$ to 220$\times$ and 35$\times$ to 80$\times$ latency improvements in the two scenarios, respectively, compared to MP3 and AAC audio compression algorithms. ORCA saves 64\% and 90\% energy compared to the vanilla on-device inference with merely 1 p.p. accuracy degradation. In both scenarios, ORCA saves 90\% execution time compared to the vanilla on-device inference by the resource-efficient cloud-assisted feature selection. 


\subsection{System Overhead}

As discussed in Section~\ref{sec:spectral-encoding-cnn}, we address the overhead of encoding individual frequency bands with a parameter-efficient spectral encoding CNN, using a spectral encoding matrix concatenated with high-resolution inputs. We compared its memory usage to SubSpectralNet~\cite{phaye2019subspectralnet} and a single-resolution on-device model. ORCAâ€™s spectral encoding CNN requires 106KB of non-volatile memory, only an 8\% increase over the single-resolution modelâ€™s 98KB, fitting well within the 256KB FRAM of the MSP430. In contrast, SubSpectralNet~\cite{phaye2019subspectralnet} needs 746KB (7$\times$ ORCAâ€™s usage), making it unsuitable for memory-limited microcontrollers.






