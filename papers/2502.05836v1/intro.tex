\section{Introduction}
The increasing complexity of legal documents necessitates the use of advanced NLP techniques to aid in their understanding and analysis. Semantic segmentation of legal texts into rhetorical roles is essential for improving the efficiency of legal research, enhancing access to justice, and supporting automated legal decision-making systems. It also facilitates various downstream tasks, such as legal search, summarization, and case analysis. Traditional methods often struggle with the intricacies of legal language, making it imperative to develop models that can accurately classify and interpret these documents. This paper addresses the challenge of semantic segmentation in legal documents, with a focus on the Indian judiciary’s legal judgments. Historically, the lack of large-scale annotated datasets has hindered the effective training of state-of-the-art ML models in this domain.

Previous research in this domain has highlighted the importance of annotated datasets for training effective models. However, many existing studies have relied on relatively small annotated datasets, limiting their applicability and effectiveness in real-world scenarios. For instance, datasets such as those compiled by \citet{bhattacharya2019identification, kalamkar-etal-2022-corpus} and \citet{malik-etal-2022-semantic} provided valuable insights but were constrained in size, thereby restricting the scope of their findings. In contrast, this study leverages a newly compiled dataset, \texttt{LegalSeg}, which consists of 7,120 annotated legal documents and 14,87,149 sentences. This dataset is considerably larger than those used in previous research, particularly in terms of its volume and diversity, as illustrated in Table \ref{table:legal_corpora_overview}, which summarizes various legal corpora for rhetorical role classification.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|l|l|c|c|c|l|}
\hline
\textbf{Corpus} & \textbf{Country} & \textbf{Language} & \textbf{\# Cases} & \begin{tabular}[c]{@{}c@{}}\textbf{Total \#} \\ \textbf{Sentences}\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{\# Labels} \end{tabular} & \textbf{Domain Coverage} \\ \hline

\citet{bhattacharya2019identification} & India & English & 50 & 9,380 & 7 & Supreme Court \\ \hline

\citet{majumder2020rhetorical} & India & English & 60 & - & 7 & \begin{tabular}[l]{@{}l@{}}Supreme Court\\High Courts\\Tribunal Courts\end{tabular} \\ \hline

\citet{malik-etal-2022-semantic} & India & English & 100 & 21,184 & 13 & \begin{tabular}[l]{@{}l@{}}Supreme Court\\Bombay High Court\\Kolkata High Court\end{tabular} \\ \hline

\citet{kalamkar-etal-2022-corpus} & India & English & 354 & 40,305 & 13 & \begin{tabular}[l]{@{}l@{}}Supreme Court\\High Courts\\District Courts\end{tabular}  \\ \hline

\citet{marino2023automatic} & India & English & 275 & 31,865 & 13 & \begin{tabular}[l]{@{}l@{}}Supreme Court\\High Courts\\District Courts\end{tabular} \\ \hline

\citet{marino2023automatic} & Italy & Italian & 1,488 & 95,920 & 5 & \begin{tabular}[l]{@{}l@{}}Civil Law of\\Italian Courts \end{tabular}  \\ \hline

\citet{modi-etal-2023-semeval} & India & English & 265 & 26,304 & 13 & Not Mentioned \\ \hline

\textbf{\texttt{LegalSeg} (Ours)} & India & English & 7,120 & 14,87,149 & 7 & \begin{tabular}[l]{@{}l@{}}Supreme Court\\High Courts\end{tabular} \\ \hline
\end{tabular}%
}
\caption{Overview of Legal Corpora for Rhetorical Role Classification}
\label{table:legal_corpora_overview}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/RR_examples.pdf}
    \caption{Example illustrating document segmentation using rhetorical roles. The left side shows an excerpt from a legal document, while the right side demonstrates the segmentation and labeling of sentences.}
    \label{fig:RR_examples}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
An example of how a legal judgment is semantically segmented into rhetorical roles is illustrated in Figure \ref{fig:RR_examples}. As shown, an unstructured legal document is broken down into coherent parts, each annotated with a rhetorical role label such as Facts, Reasoning, or Decision. This segmentation is critical for understanding the flow of arguments and supporting the automation of legal processes.

We implemented several SoTA models to evaluate the effectiveness of our dataset. Among these, the Hierarchical BiLSTM-CRF model \citet{bhattacharya2019identification} captures contextual information using a hierarchical approach, while MultiTask Learning (MTL) incorporates label shift prediction to refine the identification of rhetorical roles by considering role transitions \citet{malik-etal-2022-semantic}. Additionally, we explored LEGAL-TransformerOverBERT (LEGALToBERT), a hierarchical architecture stacking a transformer encoder over a legal-domain-specific BERT model, which effectively captures sentence relationships and positional encoding within legal documents \citet{marino2023automatic}.

In addition to these models, we introduce novel approaches, including InLegalToBERT, Graph Neural Networks (GNNs), and Role-Aware Transformers, mostly that have not been previously explored in the context of rhetorical role classification in legal texts. InLegalToBERT, a variant of LEGALToBERT, incorporates the total number of sentences as an additional feature to enhance the model’s ability to capture positional information within documents. GNNs leverage the structural relationships between sentences by representing them as nodes in a graph, allowing for effective propagation of information across sentence pairs and capturing both local and global context. Role-Aware Transformers, on the other hand, utilize specialized embeddings to incorporate rhetorical role-specific information into pre-trained models, improving the model’s ability to differentiate between closely related roles.

A key focus of our work is on the use of open-source large language models (LLMs), which align with the principles of accessibility and reproducibility in research. Instead of leveraging proprietary models like GPT-4, which are costly and lack transparency, we explore the potential of open-source models fine-tuned for legal NLP tasks. Specifically, we developed and investigated \texttt{RhetoricLLaMA}, a fine-tuned version of the open-source LLaMA-2-7B architecture, designed for semantic segmentation in legal documents. While the initial performance of \texttt{RhetoricLLaMA} was lower than anticipated, it highlights both the promise and the challenges of instruction-tuned LLMs for handling complex legal language. Given the computational limitations, our approach ensures that our models remain accessible for broader research communities, facilitating reproducibility without incurring significant costs. 

Our contributions to this work are as follows:
\begin{enumerate}
    \item Introduction of the \texttt{LegalSeg} dataset, the largest annotated dataset for rhetorical role classification in legal documents.
    \item Implementation and evaluation of SoTA models for semantic segmentation of legal texts.
    \item The development of novel models, including InLegalToBERT, Graph Neural Networks (GNNs), and Role-Aware Transformers, which enhance representation and context handling for rhetorical role classification.
    \item Exploration of instruction-tuned LLMs, through the development of \texttt{RhetoricLLaMA}, highlighting the potential and limitations of LLMs in rhetorical role classification.
\end{enumerate}

To ensure reproducibility, we have made the \texttt{LegalSeg} dataset and the code for all our models accessible via a GitHub link\footnote{\href{https://github.com/ShubhamKumarNigam/LegalSeg}{https://github.com/ShubhamKumarNigam/LegalSeg}}. 
