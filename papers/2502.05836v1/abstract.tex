\begin{abstract}
In this paper, we address the task of semantic segmentation of legal documents through rhetorical role classification, with a focus on Indian legal judgments. We introduce \texttt{LegalSeg}, the largest annotated dataset for this task, comprising over 7,000 documents and 1.4 million sentences, labeled with 7 rhetorical roles. To benchmark performance, we evaluate multiple state-of-the-art models, including Hierarchical BiLSTM-CRF, TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and Role-Aware Transformers, alongside an exploratory \texttt{RhetoricLLaMA}, an instruction-tuned large language model. Our results demonstrate that models incorporating broader context, structural relationships, and sequential sentence information outperform those relying solely on sentence-level features. Additionally, we conducted experiments using surrounding context and predicted or actual labels of neighboring sentences to assess their impact on classification accuracy. Despite these advancements, challenges persist in distinguishing between closely related roles and addressing class imbalance. Our work underscores the potential of advanced techniques for improving legal document understanding and sets a strong foundation for future research in legal NLP.
\end{abstract}


% \keywords{Rhetorical Role Classification, Legal Document Segmentation, Annotated Legal Dataset, Indian Legal Judgments, Instruction-Tuning, Large Language Models (LLMs), Legal NLP}

% Legal NLP, Document Understanding, Text Classification, Representation Learning, Semantic Role Labeling, Sequence Labeling, Large Language Models, Language Modeling, Graph Neural Networks, Transformer Models, Multi-task Learning, Corpus and Resources.