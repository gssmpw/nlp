\section{Related Work}
Recent advancements in legal text processing have spurred significant research efforts aimed at automating various tasks such as semantic segmentation, judgment prediction, and summarization of legal documents. However, much of this work relies heavily on manual annotation, with many studies focusing on the intricacies of annotation processes, including the development of annotation guidelines, IAA studies, and the curation of gold standard corpora. For instance, the TEMIS corpus, which consists of 504 sentences annotated both syntactically and semantically, was developed to enhance understanding of legislative texts \citet{venturi2012design}. Additionally, an in-depth annotation study highlighted low assessor agreement for labels such as Facts and Reasoning \citet{wyner2013case}. In the Indian context, datasets like ILDC \citet{malik-etal-2021-ildc}, PredEx \citet{nigam-etal-2024-legal} and \citet{nigam2022nigam, malik-etal-2022-semantic, nigam2023nonet, nigam2023legal} have highlighted the growing role of AI in legal judgments, with an emphasis on explainability. Research in LJP with LLMs, such as \citet{vats2023llms} and \citet{nigam-etal-2024-legal}, has experimented with models like GPT-3.5 Turbo and LLaMA-2 on Indian legal datasets. 

Several efforts have been made to automate the annotation task itself. For example, \citet{wyner2010towards} discusses methodologies that employ NLP tools to analyze 47 criminal cases from California courts. Initial experiments aimed at understanding rhetorical roles within court documents were often intertwined with broader goals of document summarization \citet{saravanan2008automatic}. 
% They utilized CRF for this purpose, focusing on seven rhetorical roles.

Further contributions include segmenting documents into functional parts (e.g., Introduction, Background) and issue-specific sections \citet{vsavelka2018segmenting}. A semi-supervised training method for identifying factual versus non-factual sentences was explored by \citet{nejadgholi2017semi} using a fastText classifier. The comparison between rule-based scripts and machine learning approaches for rhetorical role identification was conducted by \citet{walker2019automatic} demonstrating the efficacy of both methodologies in this context.

In recent studies, \citet{bhattacharya2019identification} proposed a CRF-BiLSTM model specifically for assigning rhetorical roles to sentences in Indian legal documents \citet{bhattacharya2019identification, malik-etal-2022-semantic} created a comprehensive rhetorical role corpus annotated with 13 fine-grained roles and developed a multi-task learning model for prediction tasks. \citet{kalamkar-etal-2022-corpus} constructed a corpus consisting of 354 Indian legal documents annotated with rhetorical roles across 40,305 sentences and introduced a transformer-based baseline model.

Moreover, \citet{malik-etal-2022-semantic} proposed an MTL framework that significantly improved classification scores by leveraging a Hierarchical BiLSTM with CRF architecture. \citet{marino2023automatic} introduced LEGAL-ToBERT, which integrates a transformer encoder atop a legal-domain-specific BERT model tailored for both Italian and Indian datasets. More recently, the HiCuLR framework \citet{santosh2024hiculr} introduced hierarchical curriculum learning for rhetorical role labeling, progressively training models with a structured, easy-to-difficult learning strategy, which enhances performance across multiple rhetorical role datasets.