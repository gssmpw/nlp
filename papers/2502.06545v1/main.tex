%\documentclass[anon,12pt]{colt2025} % Anonymized submission
%\documentclass[final,12pt]{colt2025} % Include author names
% \documentclass{article}
% \usepackage{arxiv} 
% \usepackage{graphicx} % Required for inserting images
% \usepackage{algorithm,algorithmic}
% %\usepackage{fullpage}
% \usepackage{url}
% \usepackage{amssymb}

%\usepackage[affil-it]{authblk}
\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{algorithm,algorithmic}
\usepackage{fullpage}
\usepackage{url}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{arxiv}
\usepackage{fancyhdr}
\input{header}
\pagestyle{fancy}
\fancyhf{}  % Clear default header/footer
\fancyhead[L]{Dimension-free Regret for Learning Asymmetric Linear Dynamical Systems}  % Left-side header
\fancyhead[R]{\thepage}  % Right-side header with page number


% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

%\title[DRAFT: NOT FOR DISTRIBUTION]{DRAFT: NOT FOR DISTRIBUTION \\ Dimension-free Regret for Learning \\ Asymmetric Linear Dynamical Systems}
\title{Dimension-free Regret for Learning \\ Asymmetric Linear Dynamical Systems}
\usepackage{times}
%
\author{  Annie Marsden \And Elad Hazan\thanks{Google DeepMind, \texttt{\{anniemarsden,ehazan\}@google.com} }}

\begin{document}

\maketitle

\begin{abstract}%
Previously, methods for learning marginally stable linear dynamical systems either (1) required the transition matrix to be symmetric or (2) incurred regret bounds that scale polynomially with the systemâ€™s hidden dimension. In this work, we introduce a novel method that overcomes this trade-off, achieving dimension-free regret despite asymmetric matrices and marginal stability. Our method combines spectral filtering with linear predictors and employs Chebyshev polynomials in the complex plane to construct a novel spectral filtering basis. This construction guarantees sublinear regret in an online learning framework, without relying on any statistical or generative assumptions. Specifically, we prove that as long as the transition matrix has eigenvalues with complex component bounded by $1/\poly \log(T)$, then our method achieves regret $\tilde{O}(T^{9/10})$ when compared to the best linear dynamical predictor in hindsight. 
\end{abstract}


 
\input{intro}
\input{technical_introduction_intuition}
\input{proof_overview}
\input{discussion}


 
\newpage

\bibliographystyle{apalike}
\bibliography{main}

\newpage
\appendix
\input{chebyshev_properties}
\input{regret_proof}
\input{lipschitz_bound}

\end{document}

