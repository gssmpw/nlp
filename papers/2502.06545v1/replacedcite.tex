\section{Related Work}
\paragraph{Background on control of linear dynamical systems.} 
Linear dynamical systems are the most fundamental and basic model in control theory, and have been studied for more than a century. For a thorough introduction, see the texts ____. 

A rigorous proof that the Caley-Hamilton theorem implies that $d_h$ learned closed-loop components are sufficient to learn any LDS is given in  ____. 


The seminal work of Kalman on state-space representation and filtering ____ allows to learn any LDS with hidden-dimension parameters under stochastic and generative assumptions. Closed loop auto-regressive learning subsumes Kalman filtering in the presence of adversarial noise, see e.g. ____. ____ provide a method to learn a marginally stable LDS in the presence of bounded adversarial noise and asymmetric matrices, however their regret bound depends on the hidden dimension of the system. More recently, ____ use tensor methods to learn a LDS with stochastic noise without dependence on the system's condition number. However, their method also has a complexity that depends on the hidden dimension of the system. 


In this work we consider regret in the context of {\it learning} linear dynamical systems. This is related to, but different from, {\it control} of the systems. We survey regret minimization for control next. 

\paragraph{Regret for classical control models. }
The first works addressing control in the machine learning community assume either no perturbation in the dynamics at all, or i.i.d. Gaussian perturbations. 
Much of this work has considered obtaining low regret in the online LQR setting ____ where a fully-observed linear dynamic system is drive by i.i.d. Gaussian noise via $x_{t+1} = \A x_t + \B \uv_t + w_t$, and the learner incurs constant quadratic state and input cost $\ell(x,u) = \frac{1}{2}x^\top \Q x + \frac{1}{2}u^\top R u$. The optimal policy for this setting is well-approximated by a \emph{state feedback controller} $\uv_t = K \uv_t$, where $K$ is the solution to the Discrete Algebraic Ricatti Equation (DARE), and thus regret amounts to competing with this controller. Recent algorithms ____ attain $\sqrt{T}$ regret for this setting, with polynomial runtime and polynomial regret dependence on relevant problem parameters. 
A parallel line of work by  ____ establish $\sqrt{T}$ in  a variant of online LQR where the system is known to the learner, noise is stochastic, but an adversary selects quadratic loss functions $\ell_t$ at each time $t$. Again, the regret is measured with respect to a best-in-hindsight state feedback controller.

Provable control in the Gaussian noise setting via the policy gradient method was  studied in ____. Other relevant work from the machine learning literature includes tracking adversarial targets ____.

\paragraph{The non-stochastic control problem.}

The most accepted and influential control model stemming from machine learning community was established in 
____, who obtain $\sqrt{T}$-regret in the more general and challenging setting where the Lipschitz loss function {and the perturbations } are adversarially chosen. The key insight behind this result is combining an improper controller parametrization know as disturbance-based control with  online convex optimization with memory due to ____. Follow up work by ____ achieves logarithmic pseudo-regret for strongly convex, adversarially selected losses and well-conditioned stochastic noise. Further extensions were made for linear control with partial observation ____, system identification with adversarial noise ____, and many more settings surveyed in ____. 


\paragraph{Online learning and online convex optimization.}
We make extensive use of techniques from the field of online learning and regret minimization in games ____. Following previous work from machine learning, we consider regret minimization in sequence prediction, where the underlying sequence follows a linear dynamical system.   

\paragraph{Spectral filtering for learning linear dynamical systems.}
The spectral filtering technique was put forth in ____ for learning symmetric linear dynamical systems. In ____, the technique was extended for more general dynamical systems using closed loop regression, however this required hidden-dimension parameters and polynomial dependence on the approximation guarantee. Spectral filtering techniques were recently used in non-linear sequence prediction, notably in the context of large language models, albeit with no theoretical guarantees ____. As convolutional models, these methods are attractive for sequence prediction due to faster generation and inference as compared to attention-based models ____.

In this paper we dramatically improve the spectral filtering technique and broaden its applicability in two major aspects: First, for general asymetric linear dynamical systems we remove the dependence on the hidden dimension. Second, we improve the dependence of the number of learned parameters from polynomial to logarithmic.   
    

%