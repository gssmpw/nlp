\section{Introduction }

Linear dynamical systems (LDS) are perhaps the most basic and well-studied dynamical systems in engineering and control science. They form a fundamental class of models used in control theory, time-series forecasting, and machine learning. Given input vectors $\uv_1, \dots, \uv_T \in \R^{d_{\textrm{in}}}$, the system generates a sequence of output vectors $\y_1, \dots \y_T \in \R^{d_{\textrm{out}}}$ according to the law 
\begin{align*}
    \mat{x}_{t+1} & = \A \mat{x}_t + \B \uv_t + w_t \\
    \y_t & = \C \mat{x}_t + \mat{D} \uv_t + \zeta_t ,
\end{align*}
where $\mat{x}_0, \dots, \mat{x}_T \in \R^{d_{\textrm{hidden}}}$ is a sequence of hidden states with hidden dimension $d_{\textrm{hidden}}$, $(\A, \B, \C, \mat{D})$ are matrices which parameterize the LDS, and $w_t,\zeta_t$ are noise terms. The problem of {\it learning} a partially observable LDS refers to predicting the next observation $\y_t$ given all previous inputs $\uv_{1:t}$ and outputs $\y_{1:{t-1}}$. This problem remains a central challenge, particularly when the system is marginally stable, i.e. its transition matrix $\A$ has spectral radius close to one. Until now, there has been been no known efficient method to learn a general, marginally stable LDS in an online setting without dependence on hidden dimension $d_{\textrm{hidden}}$.

%Spectral filtering methods \cite{hazan2017learning} have provided a breakthrough in learning LDS by circumventing direct system identification and leveraging spectral properties for efficient prediction. Prior work introduced polynomial-time spectral filtering algorithms with strong regret guarantees that do not depend on the hidden dimension of the system; however, these methods were limited to LDS with a symmetric transition matrix $\A$. In contrast, real-world dynamical systems often have asymmetric transition matrices with large hidden dimension, necessitating a more general approach.

While several methods exist that can learn in the presence of asymmetric transition matrices \citep{kalman1960new, bakshi2023new, ghai2020no}, their performance depends on hidden dimension. On the other hand, spectral filtering methods \cite{hazan2017learning} achieve regret which is independent of hidden dimension, even for marginally stable systems. However, these spectral filtering methods were limited to systems with symmetric transition matrices. In contrast, real-world dynamical systems often have asymmetric transition matrices with large hidden dimension, necessitating a more general approach. In this paper, we provide such an approach by extending the theory of spectral filtering to handle asymmetric systems, as long as the complex component of their eigenvalues is bounded. We summarize our contributions below.

\subsection{Our Contributions}
\paragraph{Generalized Spectral Filtering for Asymmetric LDS.} We introduce a novel spectral filtering basis that accommodates LDS with complex eigenvalues, overcoming the limitations of previous methods restricted to real or symmetric spectra. Our theoretical performance guarantees do not depend on the hidden dimension of the system. 
    
\paragraph{Chebyshev Polynomials for Optimal Filtering.} We leverage Chebyshev polynomials in the complex plane to construct an optimal polynomial basis, ensuring accurate approximation of LDS dynamics while maintaining computational efficiency.
    
\paragraph{Improved Theoretical Guarantees.} We establish sublinear regret bounds which are entirely hidden-dimension free, even in the presence of complex eigenvalues. Previous work showing regret bounds independent of hidden dimension did not extend to the case of asymmetric systems. Further, our results hold for arbitrary sequences, competing with the best linear dynamical prediction policy, and do not require statistical or generative assumptions.  
    
\paragraph{Efficient Online Learning Algorithm.} By incorporating our new spectral filtering basis into an online convex optimization framework, we derive an efficient algorithm with sublinear regret for learning the LDS.


%Our approach expands the applicability of spectral filtering to a broader class of LDS models, including those with non-trivial spectral properties that arise in engineering, econometrics, and machine learning applications. The theoretical advancements presented in this work provide a foundation for further exploration into efficient learning of high-dimensional dynamical systems with complex dynamics.


\subsection{Learning Linear Dynamical Systems}

%Linear dynamical systems (LDS) are perhaps the most basic and well studied dynamical systems in engineering and control science. Given input vectors $\uv_1, \dots, \uv_T \in \R^{d_{\textrm{in}}}$, the system generates a sequence of output vectors $\y_1, \dots \y_T \in \R^{d_{\textrm{out}}}$ according to the law 
%\begin{align*}
%    \mat{x}_{t+1} & = \A \mat{x}_t + \B \uv_t + w_t \\
%    \y_t & = \C \mat{x}_t + \mat{D} \uv_t + \zeta_t ,
%\end{align*}
%where $\mat{x}_0, \dots, \mat{x}_T \in \R^{d_{\textrm{hidden}}}$ is a sequence of hidden states, $(\A, \B, \C, \mat{D})$ are matrices which parameterize the LDS, and $w_t,\zeta_t$ are noise terms. We assume w.l.o.g. that $\mat{D} = 0, \zeta_t = 0$. The problem of {\it learning} in dynamical systems refers to predicting the next observation $\y_t$ given all previous inputs $\uv_{1:t}$. 
We consider the problem of learning linear dynamical systems in the online learning setting. In this setting, we measure performance of an algorithm by its regret. Regret is a robust performance measure as it does not assume a specific generative or noise model. It is defined as the difference between the loss incurred by our predictor and that of the best predictor in hindsight belonging to a certain class, i.e. 
\begin{equation} \label{eqn:regret}
\regret_T(\mA) = \sum_t \ell(\y_t,\hat{\y}_t^\mA ) - \min_{\pi \in \Pi} \sum_t \ell(\y_t,\hat{\y}_t^\pi) . 
\end{equation}
Here $\mA$ refers to our predictor, $\hat{\y}_t^\mA$ is its prediction at time $t$, $\ell$ is a loss function. Further, $\pi$ is a predictor from the class $\Pi$, for example all predictions that correspond to noiseless linear dynamical systems of the form $\hat{\y}_t^\pi = \sum_{i=0}^t \C \A^i \B \uv_{t-i} $.

The fundamental problem of learning in linear dynamical systems has been studied for many decades, and we highlight several key approaches below: 
\begin{enumerate}
    \item System identification refers to the method of recovering $\A,\B,\C$ from the data. This is a hard non-convex problem that is known to fail if the system is marginally stable, i.e. has eigenvalues that are close to one. 

    \item The (auto) regression method predicts according to $\hat{\y}_t = \sum_{i=1}^h \M_i \uv_{t-i}$. The coefficients $\M_i$ can be learned using convex regression. The downside of this approach is that if the spectral radius of $\A$ is $1-\delta$, it can be seen that $\sim \frac{1}{\delta}$ terms are needed. 

    \item The regression method can be further enhanced with ``closed loop" components, that regress on prior observations $\y_{t-1:1}$. It can be shown using the Cayley-Hamilton theorem that using this method, $d_h$ components are needed to learn the system, where $d_h$ is the {\it hidden} dimension of $\A$. 

    \item 
    Filtering involves recovering the state $x_t$ from observations. While Kalman filtering is optimal under specific noise conditions, it generally fails in the presence of marginal stability and adversarial noise.    

    \item Finally, spectral filtering combines the advantages of all methods above. It is an efficient method, its complexity does {\bf not} depend on the hidden dimension, and works for marginally stable systems. However, spectral filtering requires $\A$ to be symmetric, or diagonalizable under the real numbers. 
    
    
\end{enumerate}

Our new result combines spectral filtering and closed-loop regression with carefully chosen coefficients based on Chebyshev polynomials. This guarantees an {\bf efficient method for general LDS as long as the imaginary components of all eigenvalues is bounded from above}. We show that if the eigenvalues of $\A$ have complex component bounded by $1/\poly \log T$, then our method achieves regret $\tilde{O}(T^{17/20})$, where $\tilde{O}(\cdot)$ hides factors polylogarithmic in $T$. The condition that the eigenvalues have bounded complex component is in fact necessary in general, as we now explain.  


\subsection{Memory Capacity of Linear Dynamical Systems}

The hidden dimension $d_h$, which is the dimension of the transition matrix $\A$, plays a significant role in the expressive power of LDS. One of the most important features of the hidden dimension is that an LDS can memorize and recall inputs from up to ${d_{\textrm{hidden}}}$ iterations in the past.


This can be seen with the system where $\B,\C$ are identity, and $\A$ is given by the permutation matrix
$$ \A_{d_{\textrm{hidden}}}^{\mathrm{perm}} =
\begin{bmatrix}
0 & 0 & \cdots & 0 & 1 \\
1 & 0 & \cdots & 0 & 0 \\
0 & 1 & \cdots & 0 & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \cdots & 0 & 0 \\
0 & 0 & \cdots & 1 & 0 \\
\end{bmatrix} , 
$$
which implements the memory operator $\y_t = \uv_{t - d_h}$. Observe that any method which uses fewer than $d_{\textrm{hidden}}$ parameters will fail to implement this memory operator and therefore, for general linear dynamical systems, $d_{\textrm{hidden}}$ parameters are {\it necessary}.

Seemingly, this contradicts our promised results, which allows for learning a general LDS without hidden dimension dependence. The explanation is in the spectrum of the system. Notice that the eigenvalues of the permutation matrix $\A$ above are the $d_{\textrm{hidden}}$ roots of unity given by 
$$ \lambda_1,...,\lambda_{d_{\textrm{hidden}}} \in \left\{ e^{2 \pi i \frac{k}{d}} , k = 1,2,...,d_{\textrm{hidden}} \right\}. $$ Note that these eigenvalues have complex component as large as $1-1/d_{\textrm{hidden}}$. 

Although in general a LDS can express signals with $d_{\textrm{hidden}}$ memory, and thus intuitively might require $d_{\textrm{hidden}}$ parameters, there are notable special cases that allow for efficient learning, i.e. learning the LDS with far fewer parameters. A notable case is that of spectral filtering, which allows efficient learning of a {\it symmetric LDS} with poly-logarithmic (in the desired accuracy $\eps$) number of parameters. The significance of a symmetric transition matrix $\A$ is that it can be diagonalized over the real numbers. 

The natural question that arises is {\bf which asymmetric matrices can be learned by spectral filtering efficiently, and which characterization of their spectrum allows for efficient learning? }

The answer we offer is surprisingly broad.  For a LDS with transition matrix $\A$, let $\lambda_1,...,\lambda_d$ be its complex eigenvalues. We show that we can learn up to $\eps$ accuracy any LDS for which the largest eigenvalue has imaginary part bounded by $\frac{1}{\mathrm{poly} \log \frac{1}{\eps}} $. We note that the spectral radius can be arbitrarily close to, or even equal to, one. The only restriction is on the complex part, which is mildly constrained as a logarithmic function of $\eps$.

As per the permutation matrix example, this dependence is necessary and nearly tight - if the imaginary component of the eigenvalues of $\A$ becomes large, any learning method requires parameterization that depends on the hidden dimension of the system. 

\subsection{Algorithm and Main Result}

Our main result is an efficient algorithm called Chebyshev Spectral Filtering, which is an instantiation of Algorithm~\ref{alg:new_sf} using the Chebyshev coefficients. We prove that this algorithm achieves sublinear regret against the class of all linear dynamical predictors, i.e. against all predictors that know the underlying dynamical system. Our results are more general and apply to any choice of polynomial, not just Chebyshev. We now define two key quantities we use to derive a new spectral filtering basis. Given horizon $T$ and $n$-degree polynomial $p_n(\cdot)$ let 
 \begin{equation}
 \label{eqn:mu_alpha}
     \mu_{p_n}(\alpha) \defeq p_n(\alpha) \begin{bmatrix}
         1 & \alpha & \dots & \alpha^{T-n-1}
     \end{bmatrix}^{\top}.
 \end{equation}
 and 
 \begin{equation}
 \label{eqn:Z_def}
     \mat{Z}_T(p_n) \defeq \int_{\alpha \in \complex_{\beta}} \mu_{p_n}(\alpha) \mu_{p_n}(\overline{\alpha})^{\top} d \alpha,
 \end{equation} 
 where $\overline{\alpha}$ denotes the complex conjugate. The novel spectral filters are the eigenvectors of $\mat{Z}_T(p_n)$, which we denote as $\phi_1(p_n), \dots, \phi_{T-n-1}(p_n)$. 
\begin{algorithm}[h]
		\caption{\label{alg:new_sf} Polynomial  Spectral Filtering  }
		\begin{algorithmic}[1]
			\STATE Input: initial $\Q^{1}_{1:n} , \M^1_{1:k}$, horizon $T$, convex constraints $\K$, parameter $n$, coefficients $c_{1:n}$ 
			\STATE Let $p_n(x) = x^n + c_1 x^{n-1} + \dots + c_n$. 
            \STATE Let $\phi_1,...,\phi_n$ be the top $n$ eigenvectors $phi_1(p_n), \dots, \phi_n(p_n)$.
			\FOR {$t=1$ to $T$}
			\STATE Predict 
            $$\hat{\y}_t = -  \sum_{i=1}^n c_i \y_{t-i} + \sum_{s = 0}^{n-1} \sum_{i=1}^n c_i \Q_{\max (0, i - n + s)}^t \uv_{t-s} +  \frac{1}{\sqrt{T}}\sum_{j=1}^k \M^t_{j} \langle  \phi_j , \tilde{\uv}_{t-i:1} \rangle . $$ 
			\STATE  Observe true $\y_t$, define cost function $f_t(\hat{\y}_t ) = \| \y_t - \hat{\y}_t  \|_1$.
			\STATE Update and project:
			\begin{align*}
			& (\Q^{t+1},\M^{t+1}) = (\Q^t,\M^t) - \eta_{t} \nabla f_{t}(\Q^t,\M^{t}) \\
			& (\Q^{t+1},\M^{t+1}) = \proj_\K(\Q^{t+1},\M^{t+1})
			\end{align*}
			\ENDFOR
		\end{algorithmic}
\end{algorithm}

Two important parameters in our result are as follows. 
\begin{enumerate}
    \item 
We denote the largest complex component of any eigenvalue of the transition matrix $\A$ by 
$$ \beta = \mathrm{Im}(\lambda_{\max}(\A)) . $$ 
This important parameter measures how far away $\A$ is from being symmetric, and as explained earlier, the memory capacity of the system.  For the permutation system with memory $d$, it holds that $\beta$ is as large as $1-\frac{1}{d}$. 

\item 
We denote the number of closed-loop components $\Q_{1:n}$ by $n$ and the maximum magnitude of coefficients $c_{1:n}$ by $r$. The parameter $n$ and the coefficients $c_{1:n}$ bounded by $r$ can be chosen to be independent of the hidden dimension. Instead we show that $n$ can be chosen to depend logarithmically with $T$ and $r$ can depend sublinearly on $T$, giving sublinear regret bounds. 
\end{enumerate}

We prove that Algorithm~\ref{alg:new_sf}, instantiated with the coefficients of the Chebyshev polynomial of degree $n = \log T$, achieves regret 
\begin{equation*}
\regret_{T}(\mathrm{CSF}) = \tilde{O} \left( \sqrt{d_{\textrm{out}}} (1 + r)  \sqrt{T}\right), 
\end{equation*}
whenever $\beta < \frac{1}{64 n^2}$. 

\subsection{Formal statement of main theorem}

The intuitive expression on the regret follows from a more precise theorem. We first formally define the class of linear dynamical predictors. 
\begin{definition}[Linear Dynamical Predictors]
\label{def:lds}
    Let $\prod_{L}^{\beta,\gamma}$ denote the class of linear dynamical predictors which are parameterized by $(\A, \B, \C)$ such that $\norm{\B} \norm{\C} \leq \gamma$, and the spectrum of $\A$ lies in $$ \complex_{\beta} \defeq \{ \alpha \in \complex \textrm{ s.t. } \abs{\alpha} \leq 1 \textrm{ and } \abs{\mathrm{Im}(\alpha)} \leq \beta \},$$ that predict according to 
\begin{equation*}
    \y_t^{\pi(\A, \B, \C)} = \sum_{s=1}^t \C \A^{t-s} \B \uv_s.
\end{equation*}
\end{definition}
Next we define our new class of predictors we call ''hybrid autoregressive-spectral-filtering predictors''. 
\begin{definition}
    Let $\prod_{H}^{\K}$ denote the class of hybrid autoregressive-spectral-filtering predictors parameterized by $(\Q_{1:n}, \M_{1:k}) \in \K$, that predict according to 
\begin{equation*}
    \y_t^{\pi(\Q, \M)}=  -  \sum_{i=1}^n c_i \y_{t-i} + \sum_{s = 0}^{n-1} \sum_{i=1}^n c_i \Q_{\max (0, i - n + s)}^t \uv_{t-s} +  \sum_{j=1}^h \M^t_{j} \langle  \phi_j , \tilde{\uv}_{t-i:1} \rangle . 
\end{equation*}
\end{definition}
Algorithm~\ref{alg:new_sf} learns a predictor from $\prod_H^{\K}$ and our regret bound is with respect to the best linear dynamical predictor in $\prod_L^{\beta, \gamma}$. We now present the main theorem of this work.
\begin{theorem}
\label{thm:main_regret}
Let $\y_t \in \complex^{d_{\textrm{out}}}$ be an arbitrary sequence. Given coefficients $c_{1:n}$, let $p_n(x) = x^n + c_1 x^{n-1} + \dots + c_n$ and let $r$ denote the maximum absolute value of the polynomial, $r = \max_{i \in [n]} \abs{c_i}$. Let
\begin{equation*}
    \pbnd = \max_{\alpha \in \complex_{\beta}} \max \left \{ \abs{p_n(\alpha)}, \abs{p_n'(\alpha)} \right \}.
\end{equation*}
Let the domain $\K$ in Algorithm~\ref{alg:new_sf} be
\begin{align*}
    \K =  \{ (\Q_{1:n},  \M_{1:k}) \in \complex^{(n+k) \times d_{\textrm{out}} \times d_{\textrm{in}}} \textrm{ s.t. } & \norm{\Q_i} \leq \gamma \textrm{ and } \norm{\M_i} \leq \gamma \log(T) T^{2/3} \pbnd  \}. 
\end{align*}
 If $n$ is polynomially bounded in $T$, then Algorithm~\ref{alg:new_sf} achieves regret
\begin{equation*}
    \sum_{t = 1}^T f_t\left( \y_t^{\pi(\Q^t, \M^t)}\right) - \min_{\pi \in \prod_L^{\beta, \gamma}} f_t(y_t^\pi) \leq \tilde{O} \left(\gamma \sqrt{d_{\textrm{out}}} (1 + r) (1 + T^{ \frac{7}{6}} \pbnd) \sqrt{T}\right),
\end{equation*}
where the $\tilde{O}(\cdot)$ hides factors polylogarithmic in $T$.
\end{theorem}

Note that our theorem applies to arbitrary sequences, without statistical or generative assumptions. The regret guarantee applies against linear predictors of a bounded norm $\gamma$ and restricted spectrum with imaginary component at most $\beta$. The larger the $\gamma$ and $\beta$, the more expressive this class is, and therefore the more we ask of our polynomial bound $\pbnd$. In other words - we compete against a larger class of predictors with larger regret, as one would expect.  

We prove Theorem~\ref{thm:main_regret} in Appendix~\ref{appendix:main_regret}. Critically, we observe that the guaranteed regret bound does not depend on the hidden dimension of the dynamics matrix $\A$. 
While the general version of Algorithm~\ref{alg:new_sf} is interesting in its own right, we show that by choosing the coefficients of the algorithm to be the Chebyshev coefficients we obtain sublinear regret when compared to the best linear dynamical predictor from $\Pi_L^{\beta,\gamma}$ whenever $\beta \leq 1/64n^2$.
\begin{theorem}
    Let $c_0, \dots, c_n $ be the coefficients of the monic $n$-th Chebyshev polynomial. Then
    \begin{equation*}
    \max_{\substack{\alpha \in \complex \\ \abs{\mathrm{Im}(\alpha)} \leq 1/64n^2}} \max \left \{ \abs{p_n(\alpha)}, \abs{p_n'(\alpha)} \right \} \leq  2n^2 2^{-n} \qquad  \textrm{and} \qquad 
\max_{i =0, \dots, n} \abs{c_i} \leq 2^{0.3n}. \end{equation*}
Therefore setting $\beta = 1/64n^2$, $n = \frac{7}{6}\log_2(T)$ we get that Algorithm~\ref{alg:new_sf} achieves regret
\begin{center}
%\fbox{
$$ \sum_{t = 1}^T f_t(\hat{\y}_t) - \min_{\pi \in \prod_{L}^{\beta, \gamma} }  f_t(y_t^\pi)
 \leq \tilde{O} \left(\gamma \sqrt{d_{\textrm{out}}} T^{17/20} \right)  .$$ 
 %}
\end{center}
\end{theorem}

\paragraph{Remark on the loss function. }  The reader may notice we use the $\ell_1$, or absolute loss, rather than Euclidean or other loss functions. All norms are equivalent up to the (output) dimension, and thus learning to predict as well as the best linear dynamical system in hindsight is meaningful in any norm. However, we make this technical choice since it greatly simplifies the regret bounds, and in particular the bound on the gradient norms, which is technically involved. We conjecture that sublinear regret bounds are attainable in other norms as well, and leave it for future work. 


\subsection{Related Work}
\paragraph{Background on control of linear dynamical systems.} 
Linear dynamical systems are the most fundamental and basic model in control theory, and have been studied for more than a century. For a thorough introduction, see the texts \cite{bertsekas2007dynamic,kemin,hazan2022introduction}. 

A rigorous proof that the Caley-Hamilton theorem implies that $d_h$ learned closed-loop components are sufficient to learn any LDS is given in  \cite{agarwal2023spectral,hazan2018spectral}. 


The seminal work of Kalman on state-space representation and filtering \cite{kalman1960new} allows to learn any LDS with hidden-dimension parameters under stochastic and generative assumptions. Closed loop auto-regressive learning subsumes Kalman filtering in the presence of adversarial noise, see e.g. \cite{kozdoba2019line}. \citet{ghai2020no} provide a method to learn a marginally stable LDS in the presence of bounded adversarial noise and asymmetric matrices, however their regret bound depends on the hidden dimension of the system. More recently, \cite{bakshi2023new} use tensor methods to learn a LDS with stochastic noise without dependence on the system's condition number. However, their method also has a complexity that depends on the hidden dimension of the system. 


In this work we consider regret in the context of {\it learning} linear dynamical systems. This is related to, but different from, {\it control} of the systems. We survey regret minimization for control next. 

\paragraph{Regret for classical control models. }
The first works addressing control in the machine learning community assume either no perturbation in the dynamics at all, or i.i.d. Gaussian perturbations. 
Much of this work has considered obtaining low regret in the online LQR setting \citep{abbasi2011regret,dean2018regret,mania2019certainty,cohen2019learning} where a fully-observed linear dynamic system is drive by i.i.d. Gaussian noise via $x_{t+1} = \A x_t + \B \uv_t + w_t$, and the learner incurs constant quadratic state and input cost $\ell(x,u) = \frac{1}{2}x^\top \Q x + \frac{1}{2}u^\top R u$. The optimal policy for this setting is well-approximated by a \emph{state feedback controller} $\uv_t = K \uv_t$, where $K$ is the solution to the Discrete Algebraic Ricatti Equation (DARE), and thus regret amounts to competing with this controller. Recent algorithms \cite{mania2019certainty,cohen2019learning} attain $\sqrt{T}$ regret for this setting, with polynomial runtime and polynomial regret dependence on relevant problem parameters. 
A parallel line of work by  \cite{cohen2018online} establish $\sqrt{T}$ in  a variant of online LQR where the system is known to the learner, noise is stochastic, but an adversary selects quadratic loss functions $\ell_t$ at each time $t$. Again, the regret is measured with respect to a best-in-hindsight state feedback controller.

Provable control in the Gaussian noise setting via the policy gradient method was  studied in \cite{fazel2018global}. Other relevant work from the machine learning literature includes tracking adversarial targets \citep{abbasi2014tracking}.

\paragraph{The non-stochastic control problem.}

The most accepted and influential control model stemming from machine learning community was established in 
\cite{agarwal2019online}, who obtain $\sqrt{T}$-regret in the more general and challenging setting where the Lipschitz loss function {and the perturbations } are adversarially chosen. The key insight behind this result is combining an improper controller parametrization know as disturbance-based control with  online convex optimization with memory due to \cite{anava2015online}. Follow up work by \cite{agarwal2019logarithmic} achieves logarithmic pseudo-regret for strongly convex, adversarially selected losses and well-conditioned stochastic noise. Further extensions were made for linear control with partial observation \cite{simchowitz2020improper}, system identification with adversarial noise \cite{chen2021black}, and many more settings surveyed in \cite{hazan2022introduction}. 


\paragraph{Online learning and online convex optimization.}
We make extensive use of techniques from the field of online learning and regret minimization in games \citep{cesa2006prediction, hazan2016introduction}. Following previous work from machine learning, we consider regret minimization in sequence prediction, where the underlying sequence follows a linear dynamical system.   

\paragraph{Spectral filtering for learning linear dynamical systems.}
The spectral filtering technique was put forth in \cite{hazan2017learning} for learning symmetric linear dynamical systems. In \cite{hazan2018spectral}, the technique was extended for more general dynamical systems using closed loop regression, however this required hidden-dimension parameters and polynomial dependence on the approximation guarantee. Spectral filtering techniques were recently used in non-linear sequence prediction, notably in the context of large language models, albeit with no theoretical guarantees \cite{agarwal2023spectral}. As convolutional models, these methods are attractive for sequence prediction due to faster generation and inference as compared to attention-based models \cite{agarwal2024futurefill}.

In this paper we dramatically improve the spectral filtering technique and broaden its applicability in two major aspects: First, for general asymetric linear dynamical systems we remove the dependence on the hidden dimension. Second, we improve the dependence of the number of learned parameters from polynomial to logarithmic.   
    

%\subsection{Notation}