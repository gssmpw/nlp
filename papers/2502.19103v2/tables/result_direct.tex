% \begin{table}[tb]%[t!]
% \begin{center} 
% \footnotesize
% \resizebox{0.9\columnwidth}{!}{
%     \begin{tabular}{l|l|c|c|c|c}
% \toprule
%      \textbf{Setting}    &   \textbf{Overall}    & \textbf{Overall}	&	\textbf{Ins-fol} &		\textbf{Red}	&	 \textbf{Len}
%  \\ \midrule
% & \textbf{GPT4o} &61.74 &	82.00 &	82.00 &	21.23  \\
% & \textbf{Qwen-3B} & 59.10 &	82.00 &	81.40 &	13.89 \\
% & \textbf{Qwe-7B} & 60.60 &	81.80 &	85.00 	& 15.01  \\
% & \textbf{Qwen-72B} & 60.77 	& 84.00 &	40.31 &	58.01  \\
% & \textbf{LLaMa-1B } & 52.09 &	71.60 	& 67.00 &	17.69 \\
% & \textbf{LLaMa-3B} &58.74 &	78.20 &	69.20 	& 28.81              \\
% & \textbf{LLaMa-8B} & 64.37 &	79.80 &	58.20 &	55.11              \\
% & \textbf{LLaMa-70B} &63.78 	&86.00 	&50.00 &	55.34           \\
% & \textbf{IntLM2\_5-7B} & 55.89 &	75.20 &	83.00 &	9.46 
%              \\
% \multirow{-10}{*}{\textbf{Direct}}&	\textbf{IntLM2\_5-20B} & 56.02 & 	75.60 &	83.00 &	94.60  \\  \bottomrule


% & \textbf{GPT4o} &82.48 &	87.32 	&66.80	&93.33   \\
% &\textbf{Qwen-3B} & 81.80 &	84.18 &	67.00 &	94.21  \\
% &\textbf{Qwen-7B} & 82.16 &	85.96 &	67.20 &	93.33    \\
% &\textbf{Qwen-72B} &  86.34 &	88.01 &	72.80 &	98.22  \\
% &\textbf{LLaMa-1B } & 73.04 &	71.48 &	72.40 &	75.24  \\
% &\textbf{LLaMa-3B} &  79.78 &	79.20 &	70.20 &	89.93  \\
% &\textbf{LLaMa-70B} & 81.28 &	86.09 &	60.08 &	97.67  \\
% &\textbf{IntLM2\_5-7B} & 71.30 &	78.81& 	60.00 &	75.10   \\
%  \multirow{-8}{*}{\textbf{Agent}}&	\textbf{IntLM2\_5-20B} &  72.98 &	81.58 &	62.00 &	75.37  \\ \bottomrule

% \end{tabular}
% }
% \end{center}
% \caption{The result of different settings on paper domain. }
% \label{tab:direct result}
% \end{table}


\begin{table}[tb]%[t!]
\begin{center} 
\footnotesize
\resizebox{0.99\columnwidth}{!}{
    \begin{tabular}{l|l|c|c|c|c}
\toprule
     \textbf{Setting}    &   \textbf{Model}    & \textbf{Overall}	&	\textbf{Cont-fol} &		\textbf{Red}	&	 \textbf{Len}
 \\ \midrule
& \textbf{GPT4o} &61 &	82 &	82 &	21  \\
& \textbf{Qwen-3B} & 59 &	82 &	81 &	13 \\
& \textbf{Qwe-7B} & 60 &	81 &	85	& 15  \\
& \textbf{Qwen-72B} & 60 	& 84 &	40 &	58  \\
& \textbf{Llama-1B } & 52 &	71 	& 67 &	17 \\
& \textbf{Llama-3B} &58 &	78 &	69 	& 28            \\
% & \textbf{LLaMa-8B} & 64 &	79 &	58 &	55              \\
& \textbf{Llama-70B} &63	&86 	&50 &	55          \\
& \textbf{IntLM2.5-7B} & 55 &	75 &	73 &	17
             \\
\multirow{-10}{*}{\textbf{Direct}}&	\textbf{IntLM2.5-20B} & 56 & 	75 &	75 &	18  \\  \midrule


& \textbf{GPT4o} &82  &	87  	&66 	&93    \\
&\textbf{Qwen-3B} & 81  &	84  &	67  &	94   \\
&\textbf{Qwen-7B} & 82   &	85  &	67  &	93     \\
&\textbf{Qwen-72B} &  86  &	88 &	72  &	98  \\
&\textbf{Llama-1B } & 73  &	71  &	72  &	75   \\
&\textbf{Llama-3B} &  79  &	79  &	70  &	89   \\
&\textbf{Llama-70B} & 81  &	86  &	60  &	97   \\
&\textbf{IntLM2.5-7B} & 71  &	78  & 	60  &	75    \\
 \multirow{-8}{*}{\textbf{Plan}}&	\textbf{IntLM2.5-20B} &  72  &	81 &	62 &	75  \\ \bottomrule

\end{tabular}
}
\end{center}
\caption{A comparison of direct and plan-based methods on domain-agnostic criteria. We use the arXiv domain subset only, owing to computational constraints.}
\label{tab:direct result}
\end{table}