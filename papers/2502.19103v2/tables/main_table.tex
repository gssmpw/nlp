% \begin{table*}[hbt!]%[t!]
% \begin{center} 
% \footnotesize
% \resizebox{1.75\columnwidth}{!}{
%     \begin{tabular}{l|l|l|cccccccc}
% \midrule[1pt]
% \textbf{Domain} & \textbf{Model} & \textbf{Overall} & \textbf{RW} & \textbf{Intro} & \textbf{Len} & \textbf{EA} & \textbf{ME} & \textbf{Ins-fol} & \textbf{Red}
% \\

% \midrule[1pt]
% & GPT4o	 &80.46  &	79.23  &	80.40 & 93.33	 &76.98  &	79.14  &	87.32 	 &66.80  \\

% & Qwen2.5-3B-Instruct	&79.21 	&78.20 	&80.20 &	94.21 	&75.41 	&75.27 &	84.18 &	67.00 \\
% &Qwen2.5-7B-Instruct&	79.96& 	79.48 &	80.40 	&93.33& 	75.27 &	78.07 	&85.96 &	67.20 \\
% % &Qwen-14B-Instruct	&81.10 &	79.23 &	80.20 	&95.53 	&76.54 &	79.80 &	87.23 	&69.20 \\
% &Qwen2.5-72B-Instruct	&\textbf{82.15} 	&78.71 &	80.20 	&\textbf{98.22}& 	\textbf{77.15} &	\textbf{79.99} 	& \textbf{88.01} &	\textbf{72.80} \\
% &Internlm2\_5-7B-Chat&	70.69 &	75.12 	&78.40 	&75.10& 	61.79 &	65.61 	&78.81 &	60.00 \\
% &Internlm2\_5-20B-Chat&	72.65 	&77.69 &	78.80 &	75.37 &	62.71 	&70.38& 	81.58 &	62.00 \\
% &LLaMa3.2-1B	&70.05 &	74.87 	&79.00 &	75.24& 	60.22 &	57.14 	&71.48 &	72.40\\ 
% &LLaMa3.2-3B	&75.80 &	78.20 	&80.00 	&89.93 	&66.22 &	66.83 	&79.20& 	70.20 \\
% % &LLaMa3.1-8B	&64.66 &	77.94 &	79.80 	&97.25 	&65.62 &	64.29 	&79.11 &	60.40 \\
% & LLaMa3.3-70B &78.78 &	\textbf{80.00} &	\textbf{80.90} 	&97.67 	&73.32 &	73.40 	&86.09 &	60.08 \\
% \multirow{-12}{*}{\textbf{Paper}}&LongWriter-8B	&80.75& 	79.13 	&80.00& 	94.74 &	77.31 &	78.86 &	86.40 	&68.84 \\

% \midrule[1pt]
% & GPT4o	&81.63 &	 -	& 76.66  	&	97.81  & - & 81.55 & 	83.99 &	68.12 & 	  \\
%  &Qwen2.5-3B-Instruct	&80.32 	&--	&74.36 &	97.03& 	--	&77.61 &	82.42 &	70.20 \\
% &Qwen2.5-7B-Instruct	&82.08 	&--	&76.25 	&98.55 &	--	&82.18 &	\textbf{84.69} &	68.75 \\
% % &Qwen-14B-Instruct&	\textbf{82.81} &	--	&74.58& 	98.34 &	--&	82.63 &	84.57 &	73.95 \\
% &Qwen2.5-72B-Instruct&	82.55 	&--	&75.83& 	\textbf{99.44} &	--&	\textbf{83.03} &	84.43 &	70.00 \\
% &Internlm2\_5-7B-Chat&	70.77& 	--	&76.25& 	90.05& 	--	&52.93 	&68.39 &	66.25 \\
% &Internlm2\_5-20B-Chat	&75.85 &	--	&77.29 	&90.21 &	--&	71.30 &	77.93 &	62.50 \\
% &LLaMa3.2-1B	&68.68 &	--&	74.37 &	73.17 &	--	&55.07 	&67.68& 	73.13 \\
% &LLaMa3.2-3B&	79.20 &	--	&76.66 &	94.53 &	--	&71.24 	&77.95 	&\textbf{75.62} \\
% % &LLaMa3.1-8B	&66.29 &	--	&75.16 &	98.15 &	--	&6.55 &	76.78 &	74.79 \\
% & LLaMa3.3-70B &82.03 &	--	&\textbf{78.54}	&99.40 	&--	&79.88 &86.08&	66.25  \\
% \multirow{-10}{*}{\textbf{Blog}}& LongWriter-8B	&82.41 &	--	&78.54 &99.07 &	--	&82.11 	&85.26 	&67.08\\

% \midrule[1pt]
% & GPT4o	&82.87 	&80.44& 	74.11 	&	95.33 &- &- & 85.25 &70.44 	  \\

% &Qwen2.5-3B-Instruct	&82.10 	&80.19 &	75.29 &	94.44 &	---&	--	&82.41 &	71.37 \\
% &Qwen2.5-7B-Instruct	&81.60 &	80.49 &	75.29 &	94.58 &	---&	--	&83.50&	67.84 \\
% % &Qwen14B-Instruct	&\textbf{83.01} 	&80.39& 	73.72& 	95.64 &	---	&--&	84.04 &	71.96 \\
% &Qwen2.5-72B-Instruct	&82.96 	&\textbf{80.60} &	74.31 &	96.59 &	---&	--&	84.47 	&70.19 \\
% &Internlm2\_5-7B-Chat&	71.52 &	77.50 &	70.58 &	82.68 &	--	&--	&69.59 &	56.32 \\
% &Internlm2\_5-20B-Chat	&76.27 &	78.23 &	74.26 &	83.14 &	--	&--	&78.70& 	65.00 \\
% &LLaMa3.2-1B	&71.17& 	75.80& 	70.00 &	67.89 &	--&	--	&68.06& 	72.94 \\
% &LLaMa3.2-3B	&81.50 	&79.26& 	73.52 &	90.91 &	--	&--	&79.35& 	\textbf{76.47} \\
% % &LLaMa3.1-8B&	82.68 &	79.85 	&74.26 &	95.36 &	--	&--	&79.62 	&75.88 \\
% &LLaMa3.3-70B&82.27& 	80.29 &	\textbf{75.58} 	&\textbf{97.84}& 	--	&--&	\textbf{84.91} 	&66.02 \\

% \multirow{-10}{*}{\textbf{Wikipedia}}&	 LongWriter-8B	&	83.48 &		81.34&	 	76.32 &		\textbf{98.56}&		--&		--	&	85.04&	 	68.97  \\


% \midrule[1pt]
% \end{tabular}
% }
% \end{center}
% \caption{
% The main results on our LongGen-Agent benchmark. We conduct experiments to evaluate current LLMs on three domain (i.e., Paper, Blog, Wikipedia). The `-' presents that the metric does not exist in this domain.
% }
% \label{tab:Main Result}
% \end{table*}


\begin{table*}[hbt!]%[t!]
\begin{center} 
\footnotesize
\resizebox{1.99\columnwidth}{!}{
    \begin{tabular}{l|l|c|ccccccccc}
\toprule
\textbf{Domain} & \textbf{Model} & \textbf{Overall} & \textbf{Intro} &\textbf{RW} & \textbf{EA} & \textbf{ME} & \textbf{Cont-fol} & \textbf{Len} & \textbf{Red} & \textbf{Con}
\\

\midrule
& GPT4o	 &81	&80&	79&	74	&79	&87	&93	&66	&84  \\

& Qwen2.5-3B-Instruct	&79&	80	&78	&75	&78	&84	&94	&67	&81 \\
&Qwen2.5-7B-Instruct&	80&	80	&79	&75	&78&	85&	93	&67	&83\\
% &Qwen-14B-Instruct	&81.10 &	79.23 &	80.20 	&95.53 	&76.54 &	79.80 &	87.23 	&69.20 \\
&Qwen2.5-72B-Instruct	&\textbf{82}	&80&	78	&79	&79	&88&	94	&70&	84 \\
&Internlm2.5-7B-Chat&	71&	78	&78&	61	&65	&81	&75&	60&	75 \\
&Internlm2.5-20B-Chat&	73	&78&	78	&60&	57&	81	&75	&62&	76 \\
&Llama3.2-1B	&71	&78	&74&	60&	57	&71&	75	&72&	78 \\ 
&Llama3.2-3B	&76&	80&	78&66&	79	&73&	75&	72&	80\\
% &LLaMa3.1-8B	&64.66 &	77.94 &	79.80 	&97.25 	&65.62 &	64.29 	&79.11 &	60.40 \\
& Llama3.3-70B &79	&80	&80	&73	&86	&86	&97	&60	&82 \\
\multirow{-12}{*}{\textbf{arXiv}}&LongWriter-8B	&80&	80&	79	&77	&77&	86	&94&	68&	81 \\

\midrule
& GPT4o	&81	&78	&--&	--&	81	&83	&97	&68	&81	  \\
 &Qwen2.5-3B-Instruct	&80	&74	&--&	--&	77&	82&	74&	70&	77 \\
&Qwen2.5-7B-Instruct	& 81	&76&	--	&--	&82	&84	&76	&68	&80\\
% &Qwen-14B-Instruct&	\textbf{82.81} &	--	&74.58& 	98.34 &	--&	82.63 &	84.57 &	73.95 \\
&Qwen2.5-72B-Instruct&\textbf{83}	&75	&--	&--	&83	&84	&79	&71	&84\\
&Internlm2.5-7B-Chat&71	&76	&--	&--	&52	&68	&76	&66	&76	\\
&Internlm2.5-20B-Chat	&73	&77	&--	&--	&71	&62	&76	&67	&76 \\
&Llama3.2-1B	&70	&74	&--	&--	&55	&67	&75	&68	&74 \\
&Llama3.2-3B&79	&76	&--&--	&79	&75	&78	&76	&80 \\
& Llama3.3-70B &82	&78	&--	&--	&79	&86	&78	&66	&81\\
\multirow{-10}{*}{\textbf{Blog}}& LongWriter-8B	&\textbf{83}	&78	&--	&--	&82	&85	&79	&67	&84\\

\midrule
& GPT4o	&	81	&74	&80	&--	&85	&70	&95	&--	&82  \\
&Qwen2.5-3B-Instruct	&\textbf{82}	&75	&80	&--	&82	&71	&94	&--	&80\\
&Qwen2.5-7B-Instruct	&80	&75	&80	&--	&83	&67	&94&	--	&80 \\
% &Qwen14B-Instruct	&\textbf{83.01} 	&80.39& 	73.72& 	95.64 &	---	&--&	84.04 &	71.96 \\
&Qwen2.5-72B-Instruct	&81	&74&	80&	--&	84	&70	&94&--	&82\\
&Internlm2.5-7B-Chat&	71	&78	&77&	--	&69	&56	&90&	--&77\\
&Internlm2.5-20B-Chat	&73	&78	&77&	--	&71&	65	&90	&--	&76\\
&Llama3.2-1B	&71	&72	&71&	--&	68	&76	&67&	--	&72 \\
&Llama3.2-3B	&79&	80	&79	&--	&79	&76&	75&	--	&80\\
% &LLaMa3.1-8B&	82.68 &	79.85 	&74.26 &	95.36 &	--	&--	&79.62 	&75.88 \\
&Llama3.3-70B& \textbf{82}	&78	&80&	--	&84	&66	&99&	--	&81\\

\multirow{-10}{*}{\textbf{Wikipedia}}&	 LongWriter-8B	&\textbf{82}	&76	&81	&--	&85&	68	&98	&--	&82 \\


\bottomrule
\end{tabular}
}
\end{center}
\caption{
The plan-based results on our LongEval benchmark. We conduct experiments to evaluate current LLMs on three domains (i.e., arXiv papers, blogs, and Wikipedia articles). The `--' presents that the metric does not exist in this domain. The Overall is the average score of all indicators. For easier comparison, we retained only the integer part of all model scores.
}
\label{tab:Main Result}
\end{table*}