% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{scardamalia1987knowledge,
  title={Knowledge telling and knowledge transforming in written composition},
  author={Scardamalia, Marlene and Bereiter, Carl},
  journal={Advances in applied psycholinguistics},
  volume={2},
  pages={142--175},
  year={1987}
}

@misc{pham2024surimulticonstraintinstructionfollowing,
      title={Suri: Multi-constraint Instruction Following for Long-form Text Generation}, 
      author={Chau Minh Pham and Simeng Sun and Mohit Iyyer},
      year={2024},
      eprint={2406.19371},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19371}, 
}

@misc{li2024selfalignmentinstructionbacktranslation,
      title={Self-Alignment with Instruction Backtranslation}, 
      author={Xian Li and Ping Yu and Chunting Zhou and Timo Schick and Omer Levy and Luke Zettlemoyer and Jason Weston and Mike Lewis},
      year={2024},
      eprint={2308.06259},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.06259}, 
}

@misc{köksal2024longformeffectiveinstructiontuning,
      title={LongForm: Effective Instruction Tuning with Reverse Instructions}, 
      author={Abdullatif Köksal and Timo Schick and Anna Korhonen and Hinrich Schütze},
      year={2024},
      eprint={2304.08460},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.08460}, 
}

@article{flower1980cognitivewriting,
 ISSN = {0010096X},
 URL = {http://www.jstor.org/stable/356600},
 author = {Linda Flower and John R. Hayes},
 journal = {College Composition and Communication},
 number = {4},
 pages = {365--387},
 publisher = {National Council of Teachers of English},
 title = {A Cognitive Process Theory of Writing},
 volume = {32},
 year = {1981}
}

@article{zhang2023chinese,
  title={Chinese open instruction generalist: A preliminary release},
  author={Zhang, Ge and Shi, Yemin and Liu, Ruibo and Yuan, Ruibin and Li, Yizhi and Dong, Siwei and Shu, Yu and Li, Zhaoqun and Wang, Zekun and Lin, Chenghua and others},
  journal={arXiv preprint arXiv:2304.07987},
  year={2023}
}

@article{li2024long,
  title={Long-context llms struggle with long in-context learning},
  author={Li, Tianle and Zhang, Ge and Do, Quy Duc and Yue, Xiang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2404.02060},
  year={2024}
}

@article{xu2023retrieval,
  title={Retrieval meets long context large language models},
  author={Xu, Peng and Ping, Wei and Wu, Xianchao and McAfee, Lawrence and Zhu, Chen and Liu, Zihan and Subramanian, Sandeep and Bakhturina, Evelina and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2310.03025},
  year={2023}
}

@article{ding2024longrope,
  title={Longrope: Extending llm context window beyond 2 million tokens},
  author={Ding, Yiran and Zhang, Li Lyna and Zhang, Chengruidong and Xu, Yuanyuan and Shang, Ning and Xu, Jiahang and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2402.13753},
  year={2024}
}

@article{li2023loogle,
  title={LooGLE: Can Long-Context Language Models Understand Long Contexts?},
  author={Li, Jiaqi and Wang, Mengmeng and Zheng, Zilong and Zhang, Muhan},
  journal={arXiv preprint arXiv:2311.04939},
  year={2023}
}

@inproceedings{zhang2024bench,
  title={Bench: Extending long context evaluation beyond 100k tokens},
  author={Zhang, Xinrong and Chen, Yingfa and Hu, Shengding and Xu, Zihang and Chen, Junhao and Hao, Moo and Han, Xu and Thai, Zhen and Wang, Shuo and Liu, Zhiyuan and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={15262--15277},
  year={2024}
}

@article{bai2024longwriter,
  title={Longwriter: Unleashing 10,000+ word generation from long context llms},
  author={Bai, Yushi and Zhang, Jiajie and Lv, Xin and Zheng, Linzhi and Zhu, Siqi and Hou, Lei and Dong, Yuxiao and Tang, Jie and Li, Juanzi},
  journal={arXiv preprint arXiv:2408.07055},
  year={2024}
}

@article{que2024hellobench,
  title={Hellobench: Evaluating long text generation capabilities of large language models},
  author={Que, Haoran and Duan, Feiyu and He, Liqun and Mou, Yutao and Zhou, Wangchunshu and Liu, Jiaheng and Rong, Wenge and Wang, Zekun Moore and Yang, Jian and Zhang, Ge and others},
  journal={arXiv preprint arXiv:2409.16191},
  year={2024}
}

@article{zhang2024pqcache,
  title={Pqcache: Product quantization-based kvcache for long context llm inference},
  author={Zhang, Hailin and Ji, Xiaodong and Chen, Yilin and Fu, Fangcheng and Miao, Xupeng and Nie, Xiaonan and Chen, Weipeng and Cui, Bin},
  journal={arXiv preprint arXiv:2407.12820},
  year={2024}
}

@article{jiang2023longllmlingua,
  title={Longllmlingua: Accelerating and enhancing llms in long context scenarios via prompt compression},
  author={Jiang, Huiqiang and Wu, Qianhui and Luo, Xufang and Li, Dongsheng and Lin, Chin-Yew and Yang, Yuqing and Qiu, Lili},
  journal={arXiv preprint arXiv:2310.06839},
  year={2023}
}

@article{chen2023longlora,
  title={Longlora: Efficient fine-tuning of long-context large language models},
  author={Chen, Yukang and Qian, Shengju and Tang, Haotian and Lai, Xin and Liu, Zhijian and Han, Song and Jia, Jiaya},
  journal={arXiv preprint arXiv:2309.12307},
  year={2023}
}

@article{zhang2024longcite,
  title={Longcite: Enabling llms to generate fine-grained citations in long-context qa},
  author={Zhang, Jiajie and Bai, Yushi and Lv, Xin and Gu, Wanjun and Liu, Danqing and Zou, Minhao and Cao, Shulin and Hou, Lei and Dong, Yuxiao and Feng, Ling and others},
  journal={arXiv preprint arXiv:2409.02897},
  year={2024}
}

@article{zhang2024longreward,
  title={LongReward: Improving Long-context Large Language Models with AI Feedback},
  author={Zhang, Jiajie and Hou, Zhongni and Lv, Xin and Cao, Shulin and Hou, Zhenyu and Niu, Yilin and Hou, Lei and Dong, Yuxiao and Feng, Ling and Li, Juanzi},
  journal={arXiv preprint arXiv:2410.21252},
  year={2024}
}

@article{tang2024skyscript,
  title={SkyScript-100M: 1,000,000,000 Pairs of Scripts and Shooting Scripts for Short Drama},
  author={Tang, Jing and Jia, Quanlu and Xie, Yuqiang and Gong, Zeyu and Wen, Xiang and Zhang, Jiayi and Guo, Yalong and Chen, Guibin and Yang, Jiangping},
  journal={arXiv preprint arXiv:2408.09333},
  year={2024}
}

@article{quan2024language,
  title={Language Models can Self-Lengthen to Generate Long Texts},
  author={Quan, Shanghaoran and Tang, Tianyi and Yu, Bowen and Yang, An and Liu, Dayiheng and Gao, Bofei and Tu, Jianhong and Zhang, Yichang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2410.23933},
  year={2024}
}

@article{pham2024suri,
  title={Suri: Multi-constraint instruction following for long-form text generation},
  author={Pham, Chau Minh and Sun, Simeng and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2406.19371},
  year={2024}
}

@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}

@article{qwen2,
    title   = {Qwen2 Technical Report}, 
    author  = {An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
    journal = {arXiv preprint arXiv:2407.10671},
    year    = {2024}
}

@misc{cai2024internlm2,
      title={InternLM2 Technical Report},
      author={Zheng Cai and Maosong Cao and Haojiong Chen and Kai Chen and Keyu Chen and Xin Chen and Xun Chen and Zehui Chen and Zhi Chen and Pei Chu and Xiaoyi Dong and Haodong Duan and Qi Fan and Zhaoye Fei and Yang Gao and Jiaye Ge and Chenya Gu and Yuzhe Gu and Tao Gui and Aijia Guo and Qipeng Guo and Conghui He and Yingfan Hu and Ting Huang and Tao Jiang and Penglong Jiao and Zhenjiang Jin and Zhikai Lei and Jiaxing Li and Jingwen Li and Linyang Li and Shuaibin Li and Wei Li and Yining Li and Hongwei Liu and Jiangning Liu and Jiawei Hong and Kaiwen Liu and Kuikun Liu and Xiaoran Liu and Chengqi Lv and Haijun Lv and Kai Lv and Li Ma and Runyuan Ma and Zerun Ma and Wenchang Ning and Linke Ouyang and Jiantao Qiu and Yuan Qu and Fukai Shang and Yunfan Shao and Demin Song and Zifan Song and Zhihao Sui and Peng Sun and Yu Sun and Huanze Tang and Bin Wang and Guoteng Wang and Jiaqi Wang and Jiayu Wang and Rui Wang and Yudong Wang and Ziyi Wang and Xingjian Wei and Qizhen Weng and Fan Wu and Yingtong Xiong and Chao Xu and Ruiliang Xu and Hang Yan and Yirong Yan and Xiaogui Yang and Haochen Ye and Huaiyuan Ying and Jia Yu and Jing Yu and Yuhang Zang and Chuyu Zhang and Li Zhang and Pan Zhang and Peng Zhang and Ruijie Zhang and Shuo Zhang and Songyang Zhang and Wenjian Zhang and Wenwei Zhang and Xingcheng Zhang and Xinyue Zhang and Hui Zhao and Qian Zhao and Xiaomeng Zhao and Fengzhe Zhou and Zaida Zhou and Jingming Zhuo and Yicheng Zou and Xipeng Qiu and Yu Qiao and Dahua Lin},
      year={2024},
      eprint={2403.17297},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{jin2024llm,
  title={Llm maybe longlm: Self-extend llm context window without tuning},
  author={Jin, Hongye and Han, Xiaotian and Yang, Jingfeng and Jiang, Zhimeng and Liu, Zirui and Chang, Chia-Yuan and Chen, Huiyuan and Hu, Xia},
  journal={arXiv preprint arXiv:2401.01325},
  year={2024}
}

@article{an2024make,
  title={Make Your LLM Fully Utilize the Context},
  author={An, Shengnan and Ma, Zexiong and Lin, Zeqi and Zheng, Nanning and Lou, Jian-Guang},
  journal={arXiv preprint arXiv:2404.16811},
  year={2024}
}

@article{zhou2024balancing,
  title={Balancing diversity and risk in llm sampling: How to select your method and parameter for open-ended text generation},
  author={Zhou, Yuxuan and Keuper, Margret and Fritz, Mario},
  journal={arXiv preprint arXiv:2408.13586},
  year={2024}
}


@article{abdullin2024synthetic,
  title={Synthetic dialogue dataset generation using llm agents},
  author={Abdullin, Yelaman and Molla-Aliod, Diego and Ofoghi, Bahadorreza and Yearwood, John and Li, Qingyang},
  journal={arXiv preprint arXiv:2401.17461},
  year={2024}
}

@inproceedings{zhao2023more,
  title={More human than human: LLM-generated narratives outperform human-LLM interleaved narratives},
  author={Zhao, Zoie and Song, Sophie and Duah, Bridget and Macbeth, Jamie and Carter, Scott and Van, Monica P and Bravo, Nayeli Suseth and Klenk, Matthew and Sick, Kate and Filipowicz, Alexandre LS},
  booktitle={Proceedings of the 15th Conference on Creativity and Cognition},
  pages={368--370},
  year={2023}
}


@article{wang2024autosurvey,
  title={AutoSurvey: Large Language Models Can Automatically Write Surveys},
  author={Wang, Yidong and Guo, Qi and Yao, Wenjin and Zhang, Hongbo and Zhang, Xin and Wu, Zhen and Zhang, Meishan and Dai, Xinyu and Zhang, Min and Wen, Qingsong and others},
  journal={arXiv preprint arXiv:2406.10252},
  year={2024}
}

@misc{llama3modelcard,
title={Llama 3 Model Card},
author={AI@Meta},
year={2024},
url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}
@inproceedings{li-etal-2023-compressing,
    title = "Compressing Context to Enhance Inference Efficiency of Large Language Models",
    author = "Li, Yucheng  and
      Dong, Bo  and
      Guerin, Frank  and
      Lin, Chenghua",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.391/",
    doi = "10.18653/v1/2023.emnlp-main.391",
    pages = "6342--6353",
}

@article{lu2024ai,
  title={The ai scientist: Towards fully automated open-ended scientific discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}


@article{wu2024comparative,
  title={A Comparative Study on Reasoning Patterns of OpenAI's o1 Model},
  author={Wu, Siwei and Peng, Zhongyuan and Du, Xinrun and Zheng, Tuney and Liu, Minghao and Wu, Jialong and Ma, Jiachen and Li, Yizhi and Yang, Jian and Zhou, Wangchunshu and others},
  journal={arXiv preprint arXiv:2410.13639},
  year={2024}
}


@article{quan2024automatically,
  title={Automatically Generating Numerous Context-Driven SFT Data for LLMs across Diverse Granularity},
  author={Quan, Shanghaoran},
  journal={arXiv preprint arXiv:2405.16579},
  year={2024}
}