@article{bai2024longwriter,
  title={Longwriter: Unleashing 10,000+ word generation from long context llms},
  author={Bai, Yushi and Zhang, Jiajie and Lv, Xin and Zheng, Linzhi and Zhu, Siqi and Hou, Lei and Dong, Yuxiao and Tang, Jie and Li, Juanzi},
  journal={arXiv preprint arXiv:2408.07055},
  year={2024}
}

@article{chen2023longlora,
  title={Longlora: Efficient fine-tuning of long-context large language models},
  author={Chen, Yukang and Qian, Shengju and Tang, Haotian and Lai, Xin and Liu, Zhijian and Han, Song and Jia, Jiaya},
  journal={arXiv preprint arXiv:2309.12307},
  year={2023}
}

@article{ding2024longrope,
  title={Longrope: Extending llm context window beyond 2 million tokens},
  author={Ding, Yiran and Zhang, Li Lyna and Zhang, Chengruidong and Xu, Yuanyuan and Shang, Ning and Xu, Jiahang and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2402.13753},
  year={2024}
}

@article{jiang2023longllmlingua,
  title={Longllmlingua: Accelerating and enhancing llms in long context scenarios via prompt compression},
  author={Jiang, Huiqiang and Wu, Qianhui and Luo, Xufang and Li, Dongsheng and Lin, Chin-Yew and Yang, Yuqing and Qiu, Lili},
  journal={arXiv preprint arXiv:2310.06839},
  year={2023}
}

@article{jin2024llm,
  title={Llm maybe longlm: Self-extend llm context window without tuning},
  author={Jin, Hongye and Han, Xiaotian and Yang, Jingfeng and Jiang, Zhimeng and Liu, Zirui and Chang, Chia-Yuan and Chen, Huiyuan and Hu, Xia},
  journal={arXiv preprint arXiv:2401.01325},
  year={2024}
}

@misc{köksal2024longformeffectiveinstructiontuning,
      title={LongForm: Effective Instruction Tuning with Reverse Instructions}, 
      author={Abdullatif Köksal and Timo Schick and Anna Korhonen and Hinrich Schütze},
      year={2024},
      eprint={2304.08460},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.08460}, 
}

@inproceedings{li-etal-2023-compressing,
    title = "Compressing Context to Enhance Inference Efficiency of Large Language Models",
    author = "Li, Yucheng  and
      Dong, Bo  and
      Guerin, Frank  and
      Lin, Chenghua",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.391/",
    doi = "10.18653/v1/2023.emnlp-main.391",
    pages = "6342--6353",
}

@article{li2023loogle,
  title={LooGLE: Can Long-Context Language Models Understand Long Contexts?},
  author={Li, Jiaqi and Wang, Mengmeng and Zheng, Zilong and Zhang, Muhan},
  journal={arXiv preprint arXiv:2311.04939},
  year={2023}
}

@article{li2024long,
  title={Long-context llms struggle with long in-context learning},
  author={Li, Tianle and Zhang, Ge and Do, Quy Duc and Yue, Xiang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2404.02060},
  year={2024}
}

@misc{li2024selfalignmentinstructionbacktranslation,
      title={Self-Alignment with Instruction Backtranslation}, 
      author={Xian Li and Ping Yu and Chunting Zhou and Timo Schick and Omer Levy and Luke Zettlemoyer and Jason Weston and Mike Lewis},
      year={2024},
      eprint={2308.06259},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.06259}, 
}

@article{lu2024ai,
  title={The ai scientist: Towards fully automated open-ended scientific discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}

@article{pham2024suri,
  title={Suri: Multi-constraint instruction following for long-form text generation},
  author={Pham, Chau Minh and Sun, Simeng and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2406.19371},
  year={2024}
}

@misc{pham2024surimulticonstraintinstructionfollowing,
      title={Suri: Multi-constraint Instruction Following for Long-form Text Generation}, 
      author={Chau Minh Pham and Simeng Sun and Mohit Iyyer},
      year={2024},
      eprint={2406.19371},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19371}, 
}

@article{quan2024automatically,
  title={Automatically Generating Numerous Context-Driven SFT Data for LLMs across Diverse Granularity},
  author={Quan, Shanghaoran},
  journal={arXiv preprint arXiv:2405.16579},
  year={2024}
}

@article{quan2024language,
  title={Language Models can Self-Lengthen to Generate Long Texts},
  author={Quan, Shanghaoran and Tang, Tianyi and Yu, Bowen and Yang, An and Liu, Dayiheng and Gao, Bofei and Tu, Jianhong and Zhang, Yichang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2410.23933},
  year={2024}
}

@article{que2024hellobench,
  title={Hellobench: Evaluating long text generation capabilities of large language models},
  author={Que, Haoran and Duan, Feiyu and He, Liqun and Mou, Yutao and Zhou, Wangchunshu and Liu, Jiaheng and Rong, Wenge and Wang, Zekun Moore and Yang, Jian and Zhang, Ge and others},
  journal={arXiv preprint arXiv:2409.16191},
  year={2024}
}

@article{tang2024skyscript,
  title={SkyScript-100M: 1,000,000,000 Pairs of Scripts and Shooting Scripts for Short Drama},
  author={Tang, Jing and Jia, Quanlu and Xie, Yuqiang and Gong, Zeyu and Wen, Xiang and Zhang, Jiayi and Guo, Yalong and Chen, Guibin and Yang, Jiangping},
  journal={arXiv preprint arXiv:2408.09333},
  year={2024}
}

@article{wang2024autosurvey,
  title={AutoSurvey: Large Language Models Can Automatically Write Surveys},
  author={Wang, Yidong and Guo, Qi and Yao, Wenjin and Zhang, Hongbo and Zhang, Xin and Wu, Zhen and Zhang, Meishan and Dai, Xinyu and Zhang, Min and Wen, Qingsong and others},
  journal={arXiv preprint arXiv:2406.10252},
  year={2024}
}

@inproceedings{zhang2024bench,
  title={Bench: Extending long context evaluation beyond 100k tokens},
  author={Zhang, Xinrong and Chen, Yingfa and Hu, Shengding and Xu, Zihang and Chen, Junhao and Hao, Moo and Han, Xu and Thai, Zhen and Wang, Shuo and Liu, Zhiyuan and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={15262--15277},
  year={2024}
}

@article{zhang2024longcite,
  title={Longcite: Enabling llms to generate fine-grained citations in long-context qa},
  author={Zhang, Jiajie and Bai, Yushi and Lv, Xin and Gu, Wanjun and Liu, Danqing and Zou, Minhao and Cao, Shulin and Hou, Lei and Dong, Yuxiao and Feng, Ling and others},
  journal={arXiv preprint arXiv:2409.02897},
  year={2024}
}

@article{zhang2024longreward,
  title={LongReward: Improving Long-context Large Language Models with AI Feedback},
  author={Zhang, Jiajie and Hou, Zhongni and Lv, Xin and Cao, Shulin and Hou, Zhenyu and Niu, Yilin and Hou, Lei and Dong, Yuxiao and Feng, Ling and Li, Juanzi},
  journal={arXiv preprint arXiv:2410.21252},
  year={2024}
}

@article{zhang2024pqcache,
  title={Pqcache: Product quantization-based kvcache for long context llm inference},
  author={Zhang, Hailin and Ji, Xiaodong and Chen, Yilin and Fu, Fangcheng and Miao, Xupeng and Nie, Xiaonan and Chen, Weipeng and Cui, Bin},
  journal={arXiv preprint arXiv:2407.12820},
  year={2024}
}

