\section{Related Works}
Recent studies have explored the application of LLMs in the telecom domain across various datasets, showcasing their potential to enhance numerous aspects of the industry. However, many of these studies fall short of addressing the optimization of search processes within knowledge represented by embedding vectors. For instance, Telco-RAG \cite{TelcoRAG} introduces the concept of leveraging LLMs for telecom datasets in question-answering tasks in a wide variety of information datasets \cite{TeleQnA} but lacks clarity on how specific components of the pipeline, such as embedding-based retrieval, semantic search, and response generation, contribute to overall performance improvements. This gap highlights the need for more in-depth research that delves into optimizing the search and retrieval mechanisms within LLMs to enhance their capabilities in telecom applications. 

TelecomRAG\cite{TelecomRAG}, for instance, is significantly constrained by the limitations of its pipeline, failing to address critical performance issues prevalent in the telecom sector, such as the extensive use of abbreviations and acronyms. This oversight can lead to inefficiencies and inaccuracies when processing data of this domain. In contrast, this work is designed to handle user entries that may pose challenges for an LLM to analyze effectively. The proposed framework incorporates a text preprocessing step that augments the prompt, ensuring that text generation is more accurate and reliable. This preprocessing enhances the LLM's ability to understand and generate meaningful responses, thereby improving the overall performance of question-answering tasks.

Authors of \cite{Telecom_RAG_IEEE} optimized the internal parameters of the RAG pipeline, particularly in the retrieval of indexes, demonstrating significant efficiency improvements. However, it remains limited by its reliance on the original structure of the content, offering no alternative methods for searching the knowledge representation. In contrast,  this work delves deeper into the knowledge representation by utilizing clustering techniques on the content, and in this way grouping the embeddings by the chunks content, disregarding their initial structure. This approach allows for more efficient searches within the embedding space, enhancing the overall performance and effectiveness of the information retrieval process.

%Finally, this work also contributes by applying the developed framework in smaller LLMs, aiming to consume fewer resources.