
\begin{figure*}[t]
\centering
\begin{minipage}{0.38\textwidth}
    \centering
    \includegraphics[width=0.92\textwidth]{figures/cropped/case_study.pdf}
    \caption{Reward comparison for response \texttt{A} and \texttt{B} of Figure~\ref{fig:coding} shows different preferences.}
    \label{fig:reward_preference}
\end{minipage}%
\hfill
\begin{minipage}{0.58\textwidth}
    \centering
    \resizebox{1.0\textwidth}{!}{
    \begin{tabular}{ccccc}
        \toprule 
        & \multicolumn{2}{c}{Action-level Accuracy} & \multicolumn{2}{c}{Macro Metric}  \\
        & Ambiguous   & Non-Ambiguous & Accuracy & F1\\
        \midrule
        GPT-4o & 15.44\% & 95.60\% & 55.52\% & 56.62\% \\
        \midrule
        Base (\llama{}) & 16.26\% & 90.40\% & 53.33\% & 53.31\%\\
        \name{} & 52.84\% & 72.32\% & 62.58\% & 55.08\%\\
        \bottomrule
    \end{tabular}
    }
    \captionof{table}{Zero-shot generalization to \ambcoqa{}, a conversational QA benchmark to identify ambiguity. We assess action-level accuracy, measuring whether the model asks a question for ambiguous inputs and provides a direct answer for non-ambiguous ones. 
    }
    \label{tab:abg_coqa}
\end{minipage}
\vspace{-5pt}
\end{figure*}

