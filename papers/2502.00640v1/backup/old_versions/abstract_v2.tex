\begin{abstract}

%Large Language Models (LLMs) trained with single-turn reward often respond passively to 
%under-specified
%open-ended or ambiguous
%user requests, failing to guide users in discovering their ultimate intents. This results in ineffective and inefficient human-LLM collaborations, with users needing multiple iterations to clarify their goals. 
%To address this limitation, 
%
Large Language Models %(LLMs) 
are typically trained with next-turn rewards, limiting their ability to optimize for long-term interaction. As a result, 
they often respond passively to ambiguous or open-ended user requests, 
%failing to guide users toward discovering their ultimate intents and leading to ineffecive conversations. 
failing to help users reach their ultimate intents and leading to inefficient conversations.
To address these limitations,
%
we introduce \mbox{\name{}}, a novel and general training framework that enhances multiturn human-LLM collaboration.
%The key innovation of \name{} 
Its key innovation
is a collaborative simulation that estimates the long-term contribution of responses using  \textit{Multiturn-aware Rewards}.
%of model responses. 
By reinforcement fine-tuning these rewards, \name{} goes beyond responding to user requests, and actively uncovers user intent and offers insightful suggestions---a key step towards more human-centered AI.
% \name{} is reword-model training-free, scalable, and plug-and-play. 
% which can be integrated with prevailing reinforcement fine-tuning frameworks.
%We conduct a large-scale user study with \numturker{} judges, where \name{} increases user satisfaction by \realsatisfyimprov and reduces user time by \realtimeimprov{}.
%Additionally, 
We also devise a multiturn interaction benchmark 
%in simulated environments 
with three challenging tasks such as document creation. 
%Compared to our strongest baselines, 
\name{} significantly outperforms our 
%strongest 
baselines with averages of \taskimprov higher task performance and \itrimprov improved interactivity by LLM judges.
%% Not sure where to put this, but we could bring it back:
%Overall, \name{} advances human-centered AI by enabling more effective and efficient human-LLM collaboration.
Finally, we conduct a large user study with \numturker{} judges, where \name{} increases user satisfaction by \realsatisfyimprov and reduces user time by \realtimeimprov{}.

\end{abstract}
\input{latexfig/intro_examples}