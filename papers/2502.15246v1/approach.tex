\section{API Synthesis Methodology}
\label{sec:approach}
In this section, we illustrate our novel approach on API synthesis, and break it down into different components. The overall workflow of our approach is shown in Fig.~\ref{fig:figure3}. Our study focuses on synthesizing Java APIs. In contrast to component-based methods that demand a list of libraries, our approach requires no input components, relying solely on a method signature and some test input/output pairs. We leverage the input to craft our API synthesis prompt and apply large language models (LLMs) to directly generate method implementations and test methods. We employ prompt engineering techniques to enhance the performance of LLMs and direct them to produce the intended output. The proposed methodology  can be broken down into several key steps: 
%\begin{itemize}
(1) Assistant creation which assigns a persona to the LLMs to strengthen its grasp of the task context;
(2) Chain of thought that divides a complex task into a series of simpler steps and produces intermediate outputs that collectively lead to the final result;
(3) Few-shot learning, a form of in-context learning, that enhances the performance of LLMs with a few examples of desired inputs and outputs to guide their responses;
and (4) Follow-up prompts provide feedback on the initial outputs of LLMs, aiding in the refinement and improvement of subsequent results. This process leverages the LLMs' capability for iterative enhancement and adaptation based on evaluative input.
%\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=1.00\textwidth,trim={0cm 0cm 0cm 0cm},clip]{workflow.pdf}
    \caption{Workflow of the proposed API synthesis approach}
    \label{fig:figure3}
\end{figure}

We discuss the details of our prompt engineering technique in the following sections.

\subsection{Assistant Creation}
\label{sec:sec31}
Assistant creation is a widely adopted prompting technique that assigns a role to the LLM to guide it in solving a specific task. Assigning a role to an LLM establishes the problem context, enhancing its understanding of the task, and resulting in more accurate and relevant responses. As shown in Fig.~\ref{fig:figure4}, since the goal of our study is to synthesize a Java API from the method signature, we designate the role of LLMs to be a Java software engineer. This role assignment directs the LLMs to concentrate on Java programming-related reasoning, including the appropriate use of Java libraries, code readability, and adherence to best coding practices. In addition to role specification, the prompt explicitly conveys the task requirements to the LLMs as follows: "\textit{You will be given with an Java method signature, its return type, and a set of test cases as comments. Your task is to implement the Java method into a full implementation to pass the test cases.}" The prompt explicitly defines the task's input and expected output, effectively leveraging the programming knowledge of LLMs to facilitate API synthesis.

The process of assistant creation transforms LLMs from general-purpose models into domain-specific tools, optimizing their performance for specialized tasks. By establishing the assistant's role at the outset, we ensure that each subsequent phase such as parsing method signatures, implementing methods, and executing tests, is conducted with a targeted focus on Java programming principles and best practices.

% \begin{figure}
% 	\centering
% \begin{lstlisting}[style = prompt]
% <Role>
%     You are a software engineer. You will be given with an Java method signature,
%     its return type, and a set of test cases as comments. Your task is to implement
%     the Java method into a full implementation to pass the test cases.
% </Role>
% <Instruction>
%     Use the following step by step instruction to solve the problem:
%         Step 1 - Import Necessary Libraries
%             (1) Identify and include any required import statements, such as Java standard libraries (java.util.*), or open-source libraries (e.g., Apache Commons, Guava) to simplify implementation.
%             (2) Ensure that all dependencies are properly referenced to facilitate a smooth compilation.
%         Step 2 - Define Any Required Helper Classes or Methods
%             (1) If the method requires additional data structures or utility functions, define them before implementing the main method.
%             (2) Ensure helper classes or methods are designed efficiently to support modularity and reusability.
%         Step 3 - Create a Public Class with an Appropriate Name
%             (1) Define a class that logically represents the method's functionality (e.g., APIUtility, StringProcessor, MathHelper).
%             (2) Ensure the class is structured according to Java best practices.
%         Step 4 - Understand the Problem Statement and Requirements
%             (1) Analyze the method signature, return type, and test cases to infer the expected behavior.
%             (2) Identify edge cases that may not be explicitly covered by the test cases but are crucial for correctness (e.g., null inputs, empty lists, boundary values).
%         Step 5 - Implement the Method to Pass All Test Cases
%             (1) Write a clear and efficient implementation of the method to meet the expected input-output requirements.
%             (2) Optimize for performance and maintainability while ensuring correctness.
%         Step 6 - Validate Edge Cases and Complete Implementation
%             (1) Consider additional edge cases beyond the provided test cases (e.g., large inputs, invalid values).
%             (2) Refactor the code if necessary to handle all identified cases.
%         Step 7 - Write Unit Tests for Each Provided Test Case
%             (1) Create a test method for each given test case using JUnit (or another testing framework).
%             (2) Ensure test methods cover normal, edge, and erroneous inputs.
%         Step 8 - Provide a Main Method for Execution and Validation
%             (1) Implement a main method to run and validate the test cases.
%             (2) Print test results to confirm correctness and ensure all test cases pass.
%             (3) Verify that the code compiles and runs without errors.
% </Instruction>
% <examples> 
%     Here is one example:
%     <method>
%         List<Integer> GetRange(int start, int end)
%     </method>
%     <TestCases>
%         1. start = 10, end = 9 -> output: []
%         2. start = 10, end = 10 -> output: []
%         3. start = 10, end = 11 -> output: [10]
%         4. start = 10, end = 12 -> output: [10, 11]
%         5. start = -2, end = 2 -> output: [-2, -1, 0, 1]
%     </TestCases>
%     <output>
%         List<Integer> GetRange(int start, int end) {
%             ArrayList<Integer> range = new ArrayList<Integer>();
%             for (int i=0; i+start < end; i++)
%                 range.add(Integer.valueOf(i+start));
%             return range
%         }
%     </output>
% </examples>
% Now, give you the following method signature and test cases:
% <method>
%      double ellipseArea(Ellipse2D ellipse)
% </method>
% <TestCases>
%     1.  Ellipse2D.Double(12.3, -45.6, 7.8, 9) -> 3.9 * 4.5 * Math.PI
%     2.  Ellipse2D.Double(12.3, -45.6, 7.8, 2) -> 3.9 * Math.PI
%     3.  Ellipse2D.Double(12.3, -45.6, 2, 7.8) -> 3.9 * Math.PI
%     4.  Ellipse2D.Double(12.3, -45.6, 2, 2) -> Math.PI
% </TestCases>

% Please output the results. Only output complete code.
%  \end{lstlisting}
%  \caption{An example of our prompt input to LLMs}
% 		\label{fig:figure4}
% \end{figure}

\subsection{Chain of Thought}
\label{sec:sec32}
The chain-of-thought prompting strategy is a highly effective approach in prompt engineering, enabling LLMs to decompose complex tasks into a sequence of logically connected substeps. Our task of Java API synthesis presents a non-trivial challenge, necessitating logical reasoning to accurately interpret method signatures and their test cases. This process requires a structured sequence of intermediate steps to ensure a coherent and effective generation of APIs.

To develop an effective chain-of-thought (CoT) framework, we draw upon prior research\cite{wei2022chain} and begin by manually solving a representative subset of API synthesis tasks randomly selected from our benchmark dataset. Through this process, we identify and document the essential reasoning steps required for API synthesis. We then refine and optimize this reasoning procedure into an eight-step CoT framework. Finally, we leverage another LLM to further refine the manually generated steps, ensuring that the instructions are better aligned with the model's reasoning capabilities, thereby enhancing its effectiveness in solving the problem. \textit{Step 1} is designed to infer the necessary import statements and, most critically, to instruct the LLM to utilize relevant Java open-source libraries. This is a crucial aspect of legacy component-based API synthesis techniques, as it enables the integration of pre-existing components to facilitate efficient and accurate API generation. \textit{Step 2} directs the LLM to generate utility classes and/or methods to encapsulate auxiliary data structures, thereby supporting the implementation and enhancing modularity and maintainability. \textit{Steps 3} to \textit{Step 6} constitute the core stages that guide the LLM in method implementation. These steps instruct the LLM to define a class with a meaningful name that aligns with the methodâ€™s purpose, implement the method based on the provided signature, and ensure its correctness by considering all given test cases. Additionally, the LLM is directed to account for potential edge cases that are not explicitly covered in the provided test cases, thereby enhancing the robustness and reliability of the implementation. \textit{Steps 7} and \textit{Step 8} instruct the LLM to implement all provided test cases, ensuring comprehensive validation of the generated method. Additionally, the LLM is directed to execute the test cases and verify that the code compiles and runs without errors, thereby confirming the correctness and functional integrity of the implementation.

\subsection{Few-shot Learning}
\label{sec:sec33}
Instead of requiring training on extensive datasets comprising thousands or millions of examples, LLMs are known to have the ability to generalize to novel tasks or categories after being exposed to only a limited number of labeled examples\cite{fewshotahmed2023}.

To extract representative examples for few-shot learning, we manually selected a few examples from our benchmark system and then excluded them from the final evaluation set. Our selection criteria are as follows:
%\begin{itemize}
(1) To achieve a broader representation of various API types, we select five examples from different datasets within the benchmark system. 
(2) Examples containing an excessive number of tokens are filtered out to comply with the token limitations of LLMs.
(3) We ensure the inclusion of diverse method signature types, covering methods with and without return values, methods with primitive and non-primitive input parameters, and methods utilizing reference input parameters (i.e., methods that modify the referenced object).   
(4) Examples are selected to encompass varying numbers of associated test cases.
(5) We incorporate examples that both utilize and do not utilize library components to maintain a balanced representation.
%\end{itemize}
Following this selection process, we identified five examples that satisfy the specified criteria, one of which is depicted in Fig.~\ref{fig:figure4}.

\subsection{Follow-up Prompt}
\label{sec:sec34}
In the context of LLMs, a "follow-up prompt" refers to a subsequent input provided after an initial prompt, enabling a more refined and context-aware interaction. This approach allows for iterative refinement by building upon prior responses, incorporating additional instructions, and steering the model toward a more precise or targeted outcome.
\begin{table}[h]
    \centering
    \begin{tabular}{p{0.22\linewidth} | p{0.73\linewidth}}
        \toprule
        \textbf{Error Type} & \textbf{Follow-up Prompt} \\
        \hline
        Compilation Error & The solution doesn't compile. Please fix the bug and make sure the implementation compiles, runs and can pass all test cases.\\
        \hline
        Run-Time Error & The solution throws run-time exceptions. Please fix the bug and make sure the implementation compiles, runs and can pass all test cases. \\
        \hline
        Failing Test Cases & The implementation fails test cases \textit{N} and \textit{M}. Please fix the bug and make sure the implementation compiles, runs and can pass all test cases.\\
        \bottomrule
    \end{tabular}
    \caption{Error type and follow-up prompt}
    \label{tab:table1}
\end{table}

In our approach, a follow-up prompt is issued to the LLMs when the initially generated API implementation is incorrect. Since errors can vary in nature, we employ distinct follow-up prompts tailored to address specific error types, ensuring a more effective refinement of the generated implementation. The various error types and their corresponding follow-up prompts are presented in Table~\ref{tab:table1}. If a follow-up solution fails with the same error as the previous attempt, the task is immediately classified as a failure. Therefore, up to three follow-up prompts are allowed to refine the generated API implementation before we fail the task.
