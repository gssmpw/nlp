\section{Related Work}
\textbf{Program synthesis} has been a significant area of research, with various approaches proposed to generate programs efficiently. Traditional methods, such as Transit \cite{transit} and Escher \cite{escher}, rely on bottom-up enumerative synthesis, systematically exploring the program space to identify correct solutions. Brahma \cite{loopfree} introduces an efficient SMT-based encoding for synthesizing straight-line programs that involve multiple assignments to intermediate variables. Component-based synthesizers, such as SyPet \cite{sypet}, focus on generating Java programs from examples by leveraging arbitrary libraries. However, SyPet is limited to synthesizing sequences of method calls and does not support control structures like loops or conditionals. Similarly, Python-based synthesizers such as SnipPy \cite{snippy}, CodeHint \cite{codehint}, TFCoder \cite{tfcoder}, AutoPandas \cite{autopandas}, and Wrex \cite{wrex} primarily target one-liners or sequences of method calls. These tools also provide limited support for control structures, restricting their applicability for more complex program synthesis tasks. While these methods demonstrate the potential of automated program synthesis, their limitations in handling intricate control structures underline the need for more versatile approaches.

\textbf{Synthesis with control structures.} EdSynth \cite{Edsynth} address this by lazily initializing candidates during the execution of provided tests. The execution of partially completed candidates determines the generation of future candidates, making EdSynth particularly effective for synthesis tasks that involve multiple API sequences in both the conditions and bodies of loops or branches.
FrAngel \cite{frangel} is another notable tool that supports component-based synthesis for Java programs with control structures. Unlike many traditional methods, FrAngel relies on function-level specifications and, in principle, does not require users to have a detailed understanding of the algorithm or intermediate variables. However, in practice, to make the synthesis process feasible, users must provide a variety of examples, including base and corner cases. This requirement still necessitates some level of algorithmic knowledge, and FrAngelâ€™s relatively slow performance makes it less suitable for interactive scenarios.
LooPy \cite{loopy}, introduces the concept of an Intermediate State Graph (ISG), which compactly represents a vast space of code snippets composed of multiple assignment statements and conditionals. By engaging the programmer as an oracle to address incomplete parts of the loop, LooPy achieves a balance between automation and interactivity. Its ability to solve a wide range of synthesis tasks at interactive speeds makes it a practical tool for use cases requiring real-time feedback and adjustments.
These tools demonstrate progress in addressing the challenges of synthesis with control structures, but they also highlight trade-offs between usability, required user input, and performance.

\textbf{Large Language Models (LLMs)} have recently shown effectiveness in various software development tasks, including program synthesis\cite{jain2022jigsaw} and test generation\cite{xia2024fuzz4all,jiang2024generating}. By associating document text with code from a large training set, LLMs can generate program code from natural language prompts\cite{jain2022jigsaw,ugare2024improving,spiess2024quality,wang2023large}. Reusable API\cite{reuseableAPI} uses LLMs to generate APIs from code snippets collected from Stack Overflow and shows significant results in identifying API parameters and return types. However, they provide all the code needed and only require LLMs to create new APIs using existing implementations. Test-driven program synthesis remains an under-researched topic. How well do LLMs perform in generating entire APIs with just a few input/output examples that even end users can easily prepare? In this paper, we explore the application of LLMs in generating API implementations and finds that LLMs are effective in understanding test cases and generating viable APIs. We also show that LLMs are able to generate accurate APIs even with an incomplete set of test cases, which is very convenient. To the best of our knowledge, our work is the first systematic study of using LLMs with prompt engineering to synthesis complex APIs.

%