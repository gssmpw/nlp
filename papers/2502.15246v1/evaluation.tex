\section{Evaluation}
\label{sec:evaluation}
In this section, we present a comprehensive experimental evaluation to assess the effectiveness of Large Language Models (LLMs) in Java API synthesis tasks. The primary objective is to evaluate the practicality of the generated APIs and their capability to accurately implement the expected functionality. Specifically, we address the following research questions:

% If we reach the page limitation, maybe combine RQ1 and RQ3
\begin{itemize}
    \item \textbf{RQ1: Effectiveness.} What proportion of LLM-generated APIs successfully compile and pass the provided test cases?
    \item \textbf{RQ2: Comparison.} How does the success rate of our approach compare to traditional component-based API synthesis techniques?
    \item \textbf{RQ3: Correctness.} What is the frequency of incorrect solutions generated by our approach? 
    % \item \textbf{RQ4: Ablation Analysis.} Compared to previous approaches, does our method generate correct solutions using fewer test cases?
    \item \textbf{RQ4: Code Readability.} How effective is our approach in generating code that is clear, readable, and easily understandable by humans?
    % \item \textbf{RQ6: Generalization Study.} To what extent can our approach generalize to other programming languages?
\end{itemize}

\subsection{Experimental Setup}
\label{sec:sec41}
To address the above research questions, we designed an experimental framework incorporating the following key components:

\subsubsection{Large Language Models}
\label{sec:sec411}
For the LLMs, we choose the state-of-the-art GPT-4o model, a leading instruction-tuned language model, as the base model for our experiments. The temperature parameter is set to 0.7 to achieve a balance between creativity and consistency in the generated outputs. This configuration has been empirically demonstrated to be effective for code generation tasks\cite{endres2024can}. It enables the generation of diverse, yet controlled implementations. 
% The GPT-4o model is accessed through the ChatGPT website for experimentation.

\subsubsection{Benchmarks}
\label{sec:sec412}
We evaluate our approach on five benchmark datasets, encompassing a total of 135 tasks. Specifically, we incorporate 90 tasks from the FrAngel benchmark and 30 tasks from the SyPet\cite{sypet} benchmark. Given that LLMs are likely trained on publicly available research papers and their associated benchmarks, we further introduce 15 novel tasks derived from various Java libraries to ensure the evaluation includes previously unseen scenarios, thereby assessing the generalizability of our approach. Furthermore, during the manual verification of the implementations, we observed that the solutions generated by LLMs differ significantly from those produced by previous approaches. This observation further reduces the likelihood that LLMs rely on having task solutions present in their training data to generate correct implementations.

\begin{table*}[h]
\centering
\caption{RQ1. Compilability (\textbf{Comp}) and execution success rate (\textbf{Pass}) with (\textbf{w/}) and without (\textbf{w/o}) follow-up prompts (\textbf{FuPs})}
\label{tab:table2}
\begin{tabular}{l|r|rr|rr}
\toprule
\multicolumn{1}{c|}{Benchmark} & \#Tasks & \begin{tabular}[c]{@{}c@{}}\#Comp w/o\\ FuPs\end{tabular} & \begin{tabular}[c]{@{}c@{}}\#Pass w/o\\ FuPs\end{tabular} & \begin{tabular}[c]{@{}c@{}}\#Comp w/\\ FuPs\end{tabular} & \begin{tabular}[c]{@{}c@{}}\#Pass w/\\ FuPs\end{tabular} \\ \hline
FrAngel & 90 & 88(97.8\%) & 83(92.2\%) & 90(100\%) & 88(97.8\%) \\
Sypet & 30 & 30(100\%) & 29(96.7\%) & 30(100\%) & 30(100\%) \\ 
Additional & 15 & 15(100.0\%) & 14(93.3\%) & 15(100.0\%) & 15(100.0\%) \\ \hline
Total & 135 & 133(98.5\%) & 126(93.3\%) & 135(100\%) & 133(98.5\%) \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Effectiveness}
\label{sec:sec42}
The first evaluation of LLM-generated APIs focuses on their effectiveness(\textbf{RQ1}), defined by the success rate of producing functional APIs. To assess this, we decompose the success rate into two key metrics: compilability and the ability to pass the provided test cases. We evaluate the compilability of the generated APIs in a standardized Java environment with JDK 21 and execute all provided test cases within the same environment.

Recall that in Section~\ref{sec:sec34} we discuss utilizing follow-up prompts to assist LLMs in correcting errors from their initial attempts. Consequently, we evaluate two sets of metrics to answer the research question. The details of these metrics are presented in Table~\ref{tab:table2}, which includes columns for the number of tasks and two sets of results: one for compilable tasks and test-passing tasks without follow-up prompts, and another for those incorporating follow-up prompts. We observe that over 98\% of the APIs generated by LLMs successfully compile without the assistance of follow-up prompts, and 100\% achieve compilability after the application of follow-up prompts. Among these, 93\% of the APIs successfully pass all test cases without the need for follow-up prompts. This success rate increases to over 98\% when follow-up prompts are utilized. Overall, our approach demonstrates high effectiveness in generating compilable APIs, achieving a 100\% compilation success rate. Furthermore, nearly all generated APIs (98.5\%) successfully satisfy the provided test cases.

The two unsuccessful tasks share a common root cause: the LLMs disregarded the prompt to utilize APIs from external libraries and instead attempted to implement complex logic independently. Fig.~\ref{fig:figure7} provides a detailed illustration of one such failure. Specifically, rather than invoking the \textit{JSONPath.eval()} API, the LLMs attempted to implement the traversal logic within the method, leading to the failure of test case \#5. It is important to note that this task could still be completed successfully by issuing additional follow-up prompts, either by explicitly specifying the \textit{JSONPath.eval()} API or by instructing the LLMs to correct the failure in test case \#5. However, doing so would violate the follow-up prompt strategy outlined in section~\ref{sec:sec34}. Consequently, we classify this task as a failure. Although the two tasks failed due to the inability to adopt suitable APIs, the LLMs successfully utilized appropriate APIs and/or implemented the necessary logic to pass all test cases in most other tasks.


\begin{figure}
\centering
    \begin{lstlisting}[style = Java-github]
public static Object fastjsonRead(String json, String path) {
    JSONObject jsonObject = JSON.parseObject(json);
        
    // Split the path by dots and brackets
    String[] pathParts = path.substring(2).split("\\[|\\]|\\.");

    // Traverse the JSON structure based on the path
    Object current = jsonObject;
    for (String part : pathParts) {
        if (part.isEmpty()) continue;
            
        if (current instanceof JSONObject) {
            current = ((JSONObject) current).get(part);
        } else if (current instanceof JSONArray) {
            JSONArray array = (JSONArray) current;
            if (part.contains("=")) {
                String[] filterParts = part.split("=");
                String filterKey = filterParts[0].trim();
                String filterValue = filterParts[1].trim();
                JSONArray filteredArray = new JSONArray();
                for (int i = 0; i < array.size(); i++) {
                    JSONObject obj = array.getJSONObject(i);
                    if (obj.get(filterKey).toString().equals(filterValue)) {
                        filteredArray.add(obj);
                    }
                }
                current = filteredArray;
            } else {
                int index = Integer.parseInt(part);
                current = array.get(index);
            }
        }
    }
        
    return current;
}

public static void main(String[] args) {
    // Test case 1 (PASS)
    JSONArray array1 = (JSONArray) fastjsonRead("{\"user\":[{\"amount\":1.11,\"isadmin\":true,\"age\":18},{\"amount\":0.22,\"isadmin\":false,\"age\":28}]}", "$.user[age = 18]");
    Assert.assertEquals(1, array1.size());
    Assert.assertTrue(1.11D == array1.getJSONObject(0).getDoubleValue("amount"));
    Assert.assertTrue(array1.getJSONObject(0).getBoolean("isadmin"));
    Assert.assertTrue(18 == array1.getJSONObject(0).getIntValue("age"));

    // Test case 2 (PASS)
    JSONArray array2 = (JSONArray) fastjsonRead("{\"user\":[{\"amount\":1.11,\"isadmin\":true,\"age\":18},{\"amount\":0.22,\"isadmin\":false,\"age\":28}]}", "$.user");
    Assert.assertEquals(2, array2.size());
    Assert.assertTrue(1.11D == array2.getJSONObject(0).getDoubleValue("amount"));
    Assert.assertTrue(array2.getJSONObject(0).getBoolean("isadmin"));
    Assert.assertTrue(18 == array2.getJSONObject(0).getIntValue("age"));
    Assert.assertTrue(0.22D == array2.getJSONObject(1).getDoubleValue("amount"));
    Assert.assertFalse(array2.getJSONObject(1).getBoolean("isadmin"));
    Assert.assertTrue(28 == array2.getJSONObject(1).getIntValue("age"));

    // Test case 3 (PASS)
    JSONArray array3 = (JSONArray) fastjsonRead("{\"user\":[{\"amount\":1.11,\"isadmin\":true,\"age\":18},{\"amount\":0.22,\"isadmin\":false,\"age\":28}]}", "$.user[isadmin = true]");
    Assert.assertEquals(1, array3.size());
    Assert.assertTrue(1.11D == array3.getJSONObject(0).getDoubleValue("amount"));
    Assert.assertTrue(array3.getJSONObject(0).getBoolean("isadmin"));
    Assert.assertTrue(18 == array3.getJSONObject(0).getIntValue("age"));

    // Test case 4 (PASS)
    JSONArray array4 = (JSONArray) fastjsonRead("{\"user\":[{\"amount\":1.11,\"isadmin\":true,\"age\":18},{\"amount\":0.22,\"isadmin\":false,\"age\":28}]}", "$.user[isadmin = false]");
    Assert.assertEquals(1, array4.size());
    Assert.assertTrue(0.22D == array4.getJSONObject(0).getDoubleValue("amount"));
    Assert.assertFalse(array4.getJSONObject(0).getBoolean("isadmin"));
    Assert.assertTrue(28 == array4.getJSONObject(0).getIntValue("age"));

    // Test case 5 (FAIL)
    JSONArray array5 = (JSONArray) fastjsonRead("{\"user\":[{\"amount\":1.11,\"isadmin\":true,\"age\":18},{\"amount\":0.22,\"isadmin\":false,\"age\":28}]}", "$.user[amount = 0.22]");
    Assert.assertEquals(1, array5.size());
    Assert.assertTrue(0.22D == array5.getJSONObject(0).getDoubleValue("amount"));
    Assert.assertFalse(array5.getJSONObject(0).getBoolean("isadmin"));
    Assert.assertTrue(28 == array5.getJSONObject(0).getIntValue("age"));
}
    \end{lstlisting}

\caption{One of the two programs generated by LLMs that failed to pass all test cases}
\label{fig:figure7} 
\end{figure}



\subsection{Comparison}
\label{sec:sec43}
We address \textbf{RQ2} by comparing the success rate of LLMs with a state-of-art component-based API synthesis technique, FrAngel. We execute all 120 tasks from the FrAngel's 4 benchmarks. The results are presented in Table~\ref{tab:table3}. Note that traditional component-based API synthesis techniques employ a slightly different strategy to determine task failure. Unlike our proposed approach, which assesses failure based on whether the generated code passes all provided test cases, traditional techniques rely on search algorithms and classify a task as a failure if the algorithm fails to identify a solution within a predefined time window. The time limit is set to 30 minutes for FrAngel. The LLMs utilized in our approach consistently generate responses within a few seconds, rendering the implementation of a timeout window unnecessary. Our approach slightly outperformed FrAngel across four benchmark datasets. A key insight from this comparison is that, unlike traditional techniques—which typically demonstrate strengths in a limited range of tasks—LLMs exhibit a high degree of adaptability across diverse task types. Additionally, as illustrated in Table~\ref{tab:table2}, the use of follow-up prompts substantially improves the success rate of LLMs. This iterative feedback loop plays a crucial role in guiding the LLM toward generating more accurate and contextually relevant responses. It is important to note that the tasks in which LLMs failed differ from those where previous approaches, such as FrAngel, encountered failures.

\begin{table*}[h]
\centering
\caption{Success rate of LLMs and FrAngel on four benchmarks.}
\label{tab:table3}
\begin{tabular}{l|r|r|r}
\toprule
\multicolumn{1}{l|}{Benchmark} & \#Tasks & \begin{tabular}[c]{@{}c@{}}FrAngel Success Rate \end{tabular} & \begin{tabular}[c]{@{}c@{}}LLMs Success Rate\end{tabular} \\ \hline
Geometry & 25 & 22(88.0\%) & 25(100.0\%) \\
ControlStructures & 40 & 38(93.3\%) & 40(100.0\%) \\
Github & 25 & 23(92.0\%) & 23(92.0\%) \\
Sypet & 30 & 30(100.0\%) & 30(100\%) \\ 
\hline
Total & 120 & 113(94.2\%) & 118(98.3\%) \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Correctness}
\label{sec:sec44}
To answer \textbf{RQ3}, we conducted a manual verification of a randomly selected subset of 43 programs from the 133 generated by LLMs. Additionally, we verified the 7 false positives reported in FrAngel's original study. A program is classified as a false positive if it successfully compiles and passes all test cases but fails to fully implement the intended functionality. Our analysis reveals that the LLMs successfully generated correct programs for all 50 tasks, including the seven tasks for which FrAngel failed to produce a correct solution. Fig.~\ref{fig:figure6} presents a side-by-side comparison of two programs generated by FrAngel and our LLM-based approach, highlighting the false positives produced by the former and the correct solutions generated by the latter.
\begin{figure}
\centering
    \begin{minipage}[t]{0.47\linewidth}
        \begin{lstlisting}[style = Java-github]
static double solution(Point2D point, Ellipse2D circle) {
    if (!circle.contains(point))
        point = new Point2D.Double(Double.MAX_VALUE, 0.0);
    return point.distance(circle.getCenterX(), circle.getCenterY());
}
        \end{lstlisting}
        \vspace{.82in}
        \begin{lstlisting}[style = Java-github]
static void guava_swap(Object[] array, int i, int j) {
    for (Object elem1 : array) {
        if (array[j] == elem1) {
            array[j] = array[i];
            array[i] = elem1;
        }
    }
}
        \end{lstlisting}
    \end{minipage}
\hspace{.2in}
    \begin{minipage}[t]{0.47\linewidth}
        \begin{lstlisting}[style = Java-github]
public double distanceInCircle(Point2D point, Ellipse2D circle) {
    double centerX = circle.getCenterX();
    double centerY = circle.getCenterY();
    double radiusX = circle.getWidth() / 2;
    double radiusY = circle.getHeight() / 2;
        
    double dx = (point.getX() - centerX) / radiusX;
    double dy = (point.getY() - centerY) / radiusY;
        
    double distanceSquared = dx * dx + dy * dy;
        
    if (distanceSquared <= 1) {
        return Math.sqrt(distanceSquared) * radiusX;
    } else {
        return Double.POSITIVE_INFINITY;
    }
}
        \end{lstlisting}
        \begin{lstlisting}[style = Java-github]
public static void guavaSwap(Object[] array, int i, int j) {
    if (array == null || i < 0 || j < 0 || i >= array.length || j >= array.length || i == j) {
        return;
    }
    Object temp = array[i];
    array[i] = array[j];
    array[j] = temp;
}
        \end{lstlisting}
    \end{minipage}
\caption{Two false positives produced by FrAngel(left), and the corresponding correct programs.}
\label{fig:figure6}
\end{figure}

False positives generated by traditional search-based techniques can typically be addressed through the inclusion of a comprehensive set of test cases. However, designing such a comprehensive test suite capable of eliminating all variations of false positives is a non-trivial task for developers, requiring substantial effort and domain knowledge. In contrast, LLMs possess the capability to comprehend the intended purpose of an API by leveraging method signatures and a few input/output examples, rather than merely generating solutions that satisfy the provided test cases.

% \subsection{Ablation Analysis}
% \label{sec:sec45}
% % This RQ discuss we need less test cases. We randomly select 10 tasks in FrAngel Dataset and run experiments on these tasks. Include this in dissertation.


\begin{figure}
	\centering
		\begin{lstlisting}[style = Java-github]
import java.util.LinkedList;
import java.util.Queue;
import java.util.Stack;
import java.util.List;

public class PalindromeChecker {

    boolean isPalindrome(Queue<Character> queue) {
        Stack<Character> stack = new Stack<>();
        Queue<Character> queueCopy = new LinkedList<>(queue);

        // Push all characters from the queue into the stack
        while (!queueCopy.isEmpty()) {
            stack.push(queueCopy.poll());
        }

        // Compare characters from the original queue and the stack
        for (Character ch : queue) {
            if (!ch.equals(stack.pop())) {
                return false;
            }
        }

        return true;
    }

    // Test methods for each test case
    public void testIsPalindrome() {
        // Test case #1
        Queue<Character> queue1 = new LinkedList<>();
        boolean result1 = isPalindrome(queue1);
        assert result1 == true : "Test case #1 failed";

        // Test case #2
        Queue<Character> queue2 = new LinkedList<>(List.of('a', 'c', 'c'));
        boolean result2 = isPalindrome(queue2);
        assert result2 == false : "Test case #2 failed";

        // Test case #3
        Queue<Character> queue3 = new LinkedList<>(List.of('r', 'b', 'g', 'b', 'r'));
        boolean result3 = isPalindrome(queue3);
        assert result3 == true : "Test case #3 failed";

        // Test case #4
        Queue<Character> queue4 = new LinkedList<>(List.of('c'));
        boolean result4 = isPalindrome(queue4);
        assert result4 == true : "Test case #4 failed";

        // Test case #5
        Queue<Character> queue5 = new LinkedList<>(List.of('c', 'c'));
        boolean result5 = isPalindrome(queue5);
        assert result5 == true : "Test case #5 failed";

        // Test case #6
        Queue<Character> queue6 = new LinkedList<>(List.of('b', 'c'));
        boolean result6 = isPalindrome(queue6);
        assert result6 == false : "Test case #6 failed";

        System.out.println("All test cases passed.");
    }

    public static void main(String[] args) {
        PalindromeChecker checker = new PalindromeChecker();
        checker.testIsPalindrome();
    }
}
            \end{lstlisting}

 \caption{A complete implementation of the \texttt{isPalindrome} API produced by LLMs, including the class definition, test methods, and the main method}
		\label{fig:figure5}
 
\end{figure}

\subsection{Code Readability}
\label{sec:sec46}
As discussed in Section~\ref{sec:example}, a key limitation of existing component-based API synthesis techniques is their inability to generate descriptive variable and method names. These approaches often overlook intermediate steps during code generation, leading to reduced clarity and maintainability. Furthermore, they lack the capability to incorporate meaningful comments, which are essential for enhancing the readability and comprehensibility of the generated implementations for human developers. Thus, to address the research question regarding code readability, we evaluate the generated APIs based on several key quality attributes:

\subsubsection{Naming and Comments}
\label{sec:sec461}
The Chain-of-Thought (CoT) section of the input prompts used in this study consistently instructs LLMs to generate functionally and semantically meaningful names for classes, methods, and variables, ensuring alignment with the problem statement and requirements of the API. For example, as illustrated in Fig.~\ref{fig:figure5}, the LLMs generate distinct and semantically meaningful names for variables, methods, and classes, thereby improving code clarity and maintainability. In the same example, the LLMs also demonstrate the ability to incorporate relevant comments into key statements or control flows of the program, enhancing code clarity and explicitly conveying its intended functionality.

\subsubsection{Code structure and clarity}
\label{sec:sec462}
The LLM-generated API methods show a clear and concise code structure, adhering to Java programming best practices and enhancing readability and maintainability. As shown in Fig.~\ref{fig:figure2}, the \textit{ellipseArea} method effectively employs local variables to document intermediate steps in the calculation of an ellipse's area. Additionally, the LLMs incorporate structured exception handling to manage potential runtime anomalies, enhancing the robustness and reliability of the implementation.

Overall, in response to \textbf{RQ4}, LLMs generate programs characterized by meaningful and expressive variable and method names, along with a clear and well-structured code organization, thereby enhancing their readability and maintainability for developers.


% \subsection{Generalization Study}
%\label{sec:sec47}
