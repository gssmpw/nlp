\section{Related Work}
\subsection{Human-Centered Fact-Checking}
Recent research on human-centered AI has emphasized developing tools that augment humans **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**. In the field of fact-checking, such tools would complement human fact-checkers in their work **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**, allowing experts to control \emph{what} and \emph{how} to fact-check **Bender et al., "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?**.
% In this framework, technology primarily assists in filtering irrelevant information, while humans retain responsibility for drawing nuanced conclusions. By breaking down the fact-checking process into manageable components, this approach creates a more interactive workflow, aiding in evidence discovery and articulating reasoning behind fact-checks. This collaborative model enhances both the efficiency and transparency of the fact-checking process, leveraging the strengths of both human expertise and technological support.
% Research has shifted from focusing on end-to-end automated fact-checking to ensuring that we develop technology that augments humans instead of replacing them **Bender et al., "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?**.
% Existing practitioners want support tools that can be integrated into existing workflows. Further, NLP tools are not accurate enough for complete end-to-end fact-checking. Hence, human-centered fact-checking is best served by creating approaches that work hand in hand with fact-checkers **Hovy et al., "A survey of natural language processing techniques for opinion and sentiment analysis"**.
% This means letting the human expert decide \emph{what} and \emph{how} to fact-check. Support should come from wading out lots of clearly irrelevant information, coming to the right conclusions is best done by the human.
% We can break down the task into smaller components to make it more interactive. Humans can be helped to find evidence and connect the reasoning behind fact-checks.

\begin{figure}
    \centering
\resizebox{\columnwidth}{!}{%
\begin{tikzpicture}[node distance=1cm and 0.5cm, auto]
    \tikzstyle{startstop} = [
        rectangle,
        rounded corners,
        text width=2cm,
        minimum height=1cm,
        text centered,
        draw=ibm1!60,
        fill=ibm1!10,
        font=\sffamily,
        drop shadow
    ]
    \tikzstyle{expert-inv} = [
        rectangle,
        minimum width=5cm,
        minimum height=1cm,
        draw=ibm5!60,
        fill=ibm5!30,
    ]
    \tikzstyle{process} = [
        rectangle,
        text width=1.6cm,
        minimum height=1cm,
        text centered,
        draw=ibm2!60,
        fill=ibm2!30,
        font=\sffamily,
        drop shadow
    ]
    \tikzstyle{text-only} = [
        font=\sffamily,
    ]
    \tikzstyle{highlight} = [
        rectangle,
        minimum width=2.3cm,
        minimum height=2.3cm,
        draw=ibm1,
        rounded corners,
        line width=3pt,
        fill=none,
    ]

    \tikzstyle{arrow} = [line width=1.3pt, ->, >=Stealth, draw=black!80]

    \node (input) [startstop] {\small \textbf{Input}\\  (Text, Image, Video, Audio)};
    \node (stage1) [process, right=of input] {\small Claim \& Checkworthiness Detection};
    \node (stage2) [process, right=of stage1] {\small Evidence Retrieval};
    \node (stage3) [process, right=of stage2] {\small Verdict Prediction\\ \& Justification};
    \node (highlight) [highlight, dashed, dash pattern=on 5pt off 3pt, below right=0cm and 0cm of stage1.base, xshift=-1.2cm, yshift=.55cm] {};

    \draw [arrow] (input) -- (stage1);
    \draw [arrow] (stage1) -- (stage2);
    \draw [arrow] (stage2) -- (stage3);

    \node (data-top-left) [above=2.5cm of input, xshift=1.5cm] {};
    \node (data-top-right) [right=6.5cm of data-top-left] {};
    \node (data-bottom-left) [below=1.66cm of data-top-left] {};
    \fill[ibm3, rounded corners=10pt, opacity=0.3]
        (data-top-left.center) --
        (data-top-right.center) --
        (data-bottom-left.center) --
        cycle;
    \node (exp-bottom-left) [below=.001cm of data-bottom-left] {};
    \node (exp-top-right) [below=.001cm of data-top-right] {};
    \node (exp-bottom-right) [below=1.66cm of exp-top-right] {};
    \fill[ibm4, rounded corners=10pt, opacity=0.3]
        (exp-bottom-left.center) --
        (exp-top-right.center) --
        (exp-bottom-right.center) --
        cycle;
    \node [text-only, below right=.05cm and .1cm of data-top-left] {Data involvement};
    \node [text-only, above left=.05cm and .1cm of exp-bottom-right] {Expert involvement};
\end{tikzpicture}%
}
    \caption{The fact-checking pipeline from **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, visualized the amount of data and expert effort required. We focus on the highlighted stage. }
    \label{fig:fact-checking-pipeline}
\end{figure}

Crucially, as shown in Figure~\ref{fig:fact-checking-pipeline}, the fact-checking pipeline involves handling large amounts of data by experts. Especially in the early stages of the pipeline, experts can only spend a small amount of time per claim in assessing whether it is \textbf{checkworthy}. Natural Language Processing (NLP) technology enables various types of support, especially when dealing with scale **Vinyals et al., "Sequence to Sequence Learning with Neural Networks"**, to simplify the problem **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**, or to combat cognitive biases **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**. These diverse applications demonstrate the potential of NLP in supporting the fact-checking process.

% For instance, in the fact-checking pipeline **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**. For instance, it can help counteract the cognitive biases that human fact-checkers often face **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, or
% Generating claims from abstract narratives helps in testing this repurposing
% Additionally, NLP-generated explanations have been shown to enhance the accuracy of lay users while simultaneously improving the perceived usefulness, understandability, and trust in AI systems **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**.
% Other applications include the identification of relevant experts **Hovy et al., "A survey of natural language processing techniques for opinion and sentiment analysis"**, question decomposition to simplify complex claims **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, and the implementation of the 5W1H (Who, What, When, Where, Why, and How) approach for comprehensive claim investigation **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**.

\subsection{Misinformation in the Age of LLMs}
LLMs play a significant role in both detecting and generating misinformation. Recent work integrates LLMs into fact-checking frameworks **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, although methods are shown to generalize poorly across time **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**. Nonetheless, LLMs look promising when applied to text-based checkworthiness detection **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**. Reviews of LLM-generated multimedia highlight the open challenges **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**. For instance, large amounts of synthetic misinformation have the potential to impact the quality of future LLMs **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**, and misinformation generated by GPT-4 may be harder to detect than that generated by other models **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**.

\subsection{Related Work}
Recent research on human-centered AI has emphasized developing tools that augment humans **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**. In the field of fact-checking, such tools would complement human fact-checkers in their work **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**, allowing experts to control \emph{what} and \emph{how} to fact-check **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**.
% In this framework, technology primarily assists in filtering irrelevant information, while humans retain responsibility for drawing nuanced conclusions. By breaking down the fact-checking process into manageable components, this approach creates a more interactive workflow, aiding in evidence discovery and articulating reasoning behind fact-checks. This collaborative model enhances both the efficiency and transparency of the fact-checking process, leveraging the strengths of both human expertise and technological support.
% Research has shifted from focusing on end-to-end automated fact-checking to ensuring that we develop technology that augments humans instead of replacing them **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**.
% Existing practitioners want support tools that can be integrated into existing workflows. Further, NLP tools are not accurate enough for complete end-to-end fact-checking. Hence, human-centered fact-checking is best served by creating approaches that work hand in hand with fact-checkers **Hovy et al., "A survey of natural language processing techniques for opinion and sentiment analysis"**.
% This means letting the human expert decide \emph{what} and \emph{how} to fact-check. Support should come from wading out lots of clearly irrelevant information, coming to the right conclusions is best done by the human.
% We can break down the task into smaller components to make it more interactive. Humans can be helped to find evidence and connect the reasoning behind fact-checks.

\begin{figure}
    \centering
\resizebox{\columnwidth}{!}{%
\begin{tikzpicture}[node distance=1cm and 0.5cm, auto]
    \tikzstyle{startstop} = [
        rectangle,
        rounded corners,
        text width=2cm,
        minimum height=1cm,
        text centered,
        draw=ibm1!60,
        fill=ibm1!10,
        font=\sffamily,
        drop shadow
    ]
    \tikzstyle{expert-inv} = [
        rectangle,
        minimum width=5cm,
        minimum height=1cm,
        draw=ibm5!60,
        fill=ibm5!30,
    ]
    \tikzstyle{process} = [
        rectangle,
        text width=1.6cm,
        minimum height=1cm,
        text centered,
        draw=ibm2!60,
        fill=ibm2!30,
        font=\sffamily,
        drop shadow
    ]
    \tikzstyle{text-only} = [
        font=\sffamily,
    ]
    \tikzstyle{highlight} = [
        rectangle,
        minimum width=2.3cm,
        minimum height=2.3cm,
        draw=ibm1,
        rounded corners,
        line width=3pt,
        fill=none,
    ]

    \tikzstyle{arrow} = [line width=1.3pt, ->, >=Stealth, draw=black!80]

    \node (input) [startstop] {\small \textbf{Input}\\  (Text, Image, Video, Audio)};
    \node (stage1) [process, right=of input] {\small Claim \& Checkworthiness Detection};
    \node (stage2) [process, right=of stage1] {\small Evidence Retrieval};
    \node (stage3) [process, right=of stage2] {\small Verdict Prediction\\ \& Justification};
    \node (highlight) [highlight, dashed, dash pattern=on 5pt off 3pt, below right=0cm and 0cm of stage1.base, xshift=-1.2cm, yshift=.55cm] {};

    \draw [arrow] (input) -- (stage1);
    \draw [arrow] (stage1) -- (stage2);
    \draw [arrow] (stage2) -- (stage3);

    \node (data-top-left) [above=2.5cm of input, xshift=1.5cm] {};
    \node (data-top-right) [right=6.5cm of data-top-left] {};
    \node (data-bottom-left) [below=1.66cm of data-top-left] {};
    \fill[ibm3, rounded corners=10pt, opacity=0.3]
        (data-top-left.center) --
        (data-top-right.center) --
        (data-bottom-left.center) --
        cycle;
    \node (exp-bottom-left) [below=.001cm of data-bottom-left] {};
    \node (exp-top-right) [below=.001cm of data-top-right] {};
    \node (exp-bottom-right) [below=1.66cm of exp-top-right] {};
    \fill[ibm4, rounded corners=10pt, opacity=0.3]
        (exp-bottom-left.center) --
        (exp-top-right.center) --
        (exp-bottom-right.center) --
        cycle;
    \node [text-only, below right=.05cm and .1cm of data-top-left] {Data involvement};
    \node [text-only, above left=.05cm and .1cm of exp-bottom-right] {Expert involvement};
\end{tikzpicture}%
}
    \caption{The fact-checking pipeline from **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, visualized the amount of data and expert effort required. We focus on the highlighted stage. }
    \label{fig:fact-checking-pipeline}
\end{figure}

Crucially, as shown in Figure~\ref{fig:fact-checking-pipeline}, the fact-checking pipeline involves handling large amounts of data by experts. Especially in the early stages of the pipeline, experts can only spend a small amount of time per claim in assessing whether it is \textbf{checkworthy}. Natural Language Processing (NLP) technology enables various types of support, especially when dealing with scale **Vinyals et al., "Sequence to Sequence Learning with Neural Networks"**, to simplify the problem **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**, or to combat cognitive biases **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**. These diverse applications demonstrate the potential of NLP in supporting the fact-checking process.

% For instance, in the fact-checking pipeline **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**. For instance, it can help counteract the cognitive biases that human fact-checkers often face **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, or
% Generating claims from abstract narratives helps in testing this repurposing
% Additionally, NLP-generated explanations have been shown to enhance the accuracy of lay users while simultaneously improving the perceived usefulness, understandability, and trust in AI systems **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**.
% Other applications include the identification of relevant experts **Hovy et al., "A survey of natural language processing techniques for opinion and sentiment analysis"**, question decomposition to simplify complex claims **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, and the implementation of the 5W1H (Who, What, When, Where, Why, and How) approach for comprehensive claim investigation **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**.

\subsection{Misinformation in the Age of LLMs}
LLMs play a significant role in both detecting and generating misinformation. Recent work integrates LLMs into fact-checking frameworks **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**, although methods are shown to generalize poorly across time **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**. Nonetheless, LLMs look promising when applied to text-based checkworthiness detection **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**. Reviews of LLM-generated multimedia highlight the open challenges **Bain et al., "Human-centered design for human-AI collaboration in the context of fact checking"**. For instance, large amounts of synthetic misinformation have the potential to impact the quality of future LLMs **Gurulingappa et al., "An evaluation of NLP metrics for Automatic Summarization"**, and misinformation generated by GPT-4 may be harder to detect than that generated by other models **Lipton, "Designing, Implementing and Deploying Conceptual Explanations Across Different Data Science Tasks"**.