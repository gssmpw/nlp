\section{Related Work}
\subsection{Human-Centered Fact-Checking}
Recent research on human-centered AI has emphasized developing tools that augment humans \citep{akata2020research, nakov2021automated}. In the field of fact-checking, such tools would complement human fact-checkers in their work \citep{micallef2022true, graves2017anatomy}, allowing experts to control \emph{what} and \emph{how} to fact-check \citep{das2023state}.
% In this framework, technology primarily assists in filtering irrelevant information, while humans retain responsibility for drawing nuanced conclusions. By breaking down the fact-checking process into manageable components, this approach creates a more interactive workflow, aiding in evidence discovery and articulating reasoning behind fact-checks. This collaborative model enhances both the efficiency and transparency of the fact-checking process, leveraging the strengths of both human expertise and technological support.
% Research has shifted from focusing on end-to-end automated fact-checking to ensuring that we develop technology that augments humans instead of replacing them \citep{akata2020research,nakov2021automated}.
% Existing practitioners want support tools that can be integrated into existing workflows. Further, NLP tools are not accurate enough for complete end-to-end fact-checking. Hence, human-centered fact-checking is best served by creating approaches that work hand in hand with fact-checkers \citep{das2023state}.
% This means letting the human expert decide \emph{what} and \emph{how} to fact-check. Support should come from wading out lots of clearly irrelevant information, coming to the right conclusions is best done by the human.
% We can break down the task into smaller components to make it more interactive. Humans can be helped to find evidence and connect the reasoning behind fact-checks.

\begin{figure}
    \centering
\resizebox{\columnwidth}{!}{%
\begin{tikzpicture}[node distance=1cm and 0.5cm, auto]
    \tikzstyle{startstop} = [
        rectangle,
        rounded corners,
        text width=2cm,
        minimum height=1cm,
        text centered,
        draw=ibm1!60,
        fill=ibm1!10,
        font=\sffamily,
        drop shadow
    ]
    \tikzstyle{expert-inv} = [
        rectangle,
        minimum width=5cm,
        minimum height=1cm,
        draw=ibm5!60,
        fill=ibm5!30,
    ]
    \tikzstyle{process} = [
        rectangle,
        text width=1.6cm,
        minimum height=1cm,
        text centered,
        draw=ibm2!60,
        fill=ibm2!30,
        font=\sffamily,
        drop shadow
    ]
    \tikzstyle{text-only} = [
        font=\sffamily,
    ]
    \tikzstyle{highlight} = [
        rectangle,
        minimum width=2.3cm,
        minimum height=2.3cm,
        draw=ibm1,
        rounded corners,
        line width=3pt,
        fill=none,
    ]

    \tikzstyle{arrow} = [line width=1.3pt, ->, >=Stealth, draw=black!80]

    \node (input) [startstop] {\small \textbf{Input}\\  (Text, Image, Video, Audio)};
    \node (stage1) [process, right=of input] {\small Claim \& Checkworthiness Detection};
    \node (stage2) [process, right=of stage1] {\small Evidence Retrieval};
    \node (stage3) [process, right=of stage2] {\small Verdict Prediction\\ \& Justification};
    \node (highlight) [highlight, dashed, dash pattern=on 5pt off 3pt, below right=0cm and 0cm of stage1.base, xshift=-1.2cm, yshift=.55cm] {};

    \draw [arrow] (input) -- (stage1);
    \draw [arrow] (stage1) -- (stage2);
    \draw [arrow] (stage2) -- (stage3);

    \node (data-top-left) [above=2.5cm of input, xshift=1.5cm] {};
    \node (data-top-right) [right=6.5cm of data-top-left] {};
    \node (data-bottom-left) [below=1.66cm of data-top-left] {};
    \fill[ibm3, rounded corners=10pt, opacity=0.3]
        (data-top-left.center) --
        (data-top-right.center) --
        (data-bottom-left.center) --
        cycle;
    \node (exp-bottom-left) [below=.001cm of data-bottom-left] {};
    \node (exp-top-right) [below=.001cm of data-top-right] {};
    \node (exp-bottom-right) [below=1.66cm of exp-top-right] {};
    \fill[ibm4, rounded corners=10pt, opacity=0.3]
        (exp-bottom-left.center) --
        (exp-top-right.center) --
        (exp-bottom-right.center) --
        cycle;
    \node [text-only, below right=.05cm and .1cm of data-top-left] {Data involvement};
    \node [text-only, above left=.05cm and .1cm of exp-bottom-right] {Expert involvement};
\end{tikzpicture}%
}
    \caption{The fact-checking pipeline from \citet{akhtar-etal-2023-multimodal}, visualized the amount of data and expert effort required. We focus on the highlighted stage. }
    \label{fig:fact-checking-pipeline}
\end{figure}

Crucially, as shown in Figure~\ref{fig:fact-checking-pipeline}, the fact-checking pipeline involves handling large amounts of data by experts. Especially in the early stages of the pipeline, experts can only spend a small amount of time per claim in assessing whether it is \textbf{checkworthy}. Natural Language Processing (NLP) technology enables various types of support, especially when dealing with scale \citep{vandermeer2024facilitating, procter2023some}, to simplify the problem \citep{chen2022generating, bonet2024run}, or to combat cognitive biases \citep{soprano2024cognitive}. These diverse applications demonstrate the potential of NLP in supporting the fact-checking process.

% For instance, in the fact-checking pipeline \citep{liu2023human}. For instance, it can help counteract the cognitive biases that human fact-checkers often face \citep{soprano2024cognitive}, or
% Generating claims from abstract narratives helps in testing this repurposing
% Additionally, NLP-generated explanations have been shown to enhance the accuracy of lay users while simultaneously improving the perceived usefulness, understandability, and trust in AI systems \citep{schmitt2024role}.
% Other applications include the identification of relevant experts \citep{zhang2023newsquote}, question decomposition to simplify complex claims \citep{chen2022generating}, and the implementation of the 5W1H (Who, What, When, Where, Why, and How) approach for comprehensive claim investigation \citep{bonet2024run, tonglet2024image}.

\subsection{Misinformation in the Age of LLMs}
LLMs play a significant role in both detecting and generating misinformation. Recent work integrates LLMs into fact-checking frameworks \citep{geng2024multimodal}, although methods are shown to generalize poorly across time \citep{stepanova-ross-2023-temporal}. Nonetheless, LLMs look promising when applied to text-based checkworthiness detection \citep{majer2024claim}. Reviews of LLM-generated multimedia highlight the open challenges \citep{lin2024detecting, augenstein2024factuality}. For instance, large amounts of synthetic misinformation have the potential to impact the quality of future LLMs \citep{pan2023risk}, and misinformation generated by GPT-4 may be harder to detect than that written by humans \citep{chen2024combating}.

\subsection{Multimodal Resources}
Existing work on fact-checking emphasizes empirical research, which involves extensively benchmarking fact-checking methods \citep{schlichtkrull2024averitec, papadopoulos2024verite}, often using distant supervision \citep{nakamura2020fakeddit, zlatkova2019fact}. Most multimodal datasets investigate the out-of-context use of images and claims \citep{luo2021newsclippings, tonglet2024image}, or whether claims are reflected in an image between claim and image \citep{yoon2024assessing, papadopoulos2023synthetic}. Few datasets exist that
\begin{enumerate*}[label=(\arabic*)]
    \item check whether the image contributes new information \citep{liu2024mmfakebench}, or
    \item contain synthetically generated data \citep{xu2023combating, seow2022comprehensive}
\end{enumerate*}. The few efforts on multimodal checkworthiness indicate that textual data, whether through OCR or by focusing on claims only, is sufficient for state-of-the-art performance \citep{frick2023fraunhofer}. More extensive experiments on varied types of data with complex image use, across domains, are needed to further examine this finding.
% While performance metrics, such as classification accuracies are important signals of a system's capabilities, these metrics report only general trends, and do not reveal further details about \emph{what type}, or \emph{why} something was classified as misinformation. Unfortunately, few resources that provide such a human-centered perspective are available:
% Human-centered fact-checking datasets
% \begin{enumerate*}[label=(\arabic*)]
%     \item Some datasets, like AVeriTeC \citep{schlichtkrull2024averitec} and ClaimDecomp \citep{chen2022generating}, include question and answers (Q\&A), such that a system may learn to decompose claims into relevant subquestions.
% \end{enumerate*}