\input{assets/table}

A prominent method for providing post-hoc explanations for ML models is via Shapley additive explanations (SHAP)~\citep{lundberg2017}. However, a major limitation of SHAP is the significantly high computational complexity of computing these explanations~\citep{bertossi2020causality}. Practical methods --- like those in the popular SHAP library~\citep{lundberg2017} --- typically address this computational burden in one of two ways. The first is through approximation techniques, such as KernelSHAP~\citep{lundberg2017}, which offer greater scalability but lack formal guarantees for the resulting explanations. The second approach involves designing algorithms tailored to specific, simpler model types (e.g., tree-based models or linear models), which are more computationally feasible. However, these methods also typically rely on underlying assumptions. For example, the popular TreeSHAP algorithm~\citep{lundbergnature} assumes explanations are based on empirical distributions, while LinearSHAP~\citep{lundberg2017} assumes feature independence.

These model-specific algorithms have sparked interest in developing a deeper theoretical understanding of the computational complexity involved in calculating Shapley values for various types of models and under different distributions. One of the early works by~\cite{vander21} presented tractable results for a range of models while also establishing NP-hardness for relatively simple settings, such as computing SHAP for decision trees with naive Bayes modeled distributions. Additionally,~\cite{arenas23} demonstrated that computing SHAP is tractable for Decomposable Deterministic Boolean Circuits under independent distributions, while \cite{marzouk24a} reported similar positive complexity results for Weighted Automata under Markovian distributions.

{\renewcommand{\thefootnote}{}%
\footnotetext{*Equal contribution (first authors), $^{\dagger}$Equal contribution (last authors).}}

%\textsuperscript{\phantom{0}}\footnotetext{*Equal contribution (first authors), $^{\dagger}$Equal contribution (last authors).}

However, a key limitation of these previous computational complexity works is that they have primarily focused on a specific SHAP variant known as Conditional SHAP~\citep{sundararajan20b}. The explainable AI community has explored a variety of SHAP variants, including Conditional, Interventional~\citep{janzing20a}, and Baseline~\citep{sundararajan20b} SHAP, among many others~\citep{frye20, albini22}. These variants were introduced mainly to address the axiomatic limitations of the original Conditional SHAP formulation \citep{sundararajan20b, Huang2023TheIO}. Analyzing these variants is vital as many popular SHAP algorithms incorporate them. For example, KernelSHAP~\citep{lundberg2017} and TreeSHAP~\citep{lundbergnature} typically compute \emph{interventional} SHAP values, and not conditional ones.

%These variants are significant, as many widely-used SHAP algorithms, like KernelSHAP~\citep{lundberg2017} and TreeSHAP~\citep{lundbergnature}, compute \emph{interventional} SHAP values.


%The significance of these variants is further underscored by the fact that many widely-used practical SHAP algorithms incorporate them. For instance, methods like KernelSHAP~\citep{lundberg2017} and TreeSHAP~\citep{lundbergnature} typically compute \emph{interventional} SHAP values (and not necessarily conditional).


% Paragraph 1: SHAP is popular but computing it is hard 
 %Thanks to its strong theoretical grounding; the SHAP framework has gained widespread popularity within the explainable AI community.
 %However, one of its most significant limitation is its computational complexity: Calculating Shapley values requires considering all possible feature combinations, making it expensive to compute exactly \citep{bertossi2020causality}. 
 
% Paragraph 2: Related Works presented in Logical format
%Since the introduction of the SHAP framework in Lundberg's seminal paper \cite{lundberg2017}, a variety of SHAP variants have emerged in the literature, including Interventional SHAP \citep{janzing20a}, Asymmetric SHAP \citep{frye20}, Baseline SHAP \citep{sundararajan20b}, Counterfactual SHAP \citep{albini22} etc. The introduction of these variants have been motivated primarily by the axiomatic shortcomings of the original SHAP formulation \citep{sundararajan20b, Huang2023TheIO} and the aim of addressing feature causality more effectively in the derived explanations.

%While the axiomatic properties of these SHAP variants have been the major focus in the literature, their computational aspects remain relatively underexplored. The most comprehensive computational study of the SHAP framework to date was conducted by \cite{vander21}, where the complexity of the original SHAP formulation, referred to as Conditional SHAP (C-SHAP), for various model families under different distributional assumptions has been studied. The emerging outcome of this work is that computing the C-SHAP score is particularily computationally challenging, even for simple models such as Decision Trees under restrictive family of distributions such as empirical distributions and Na√Æve Bayes models.

%In addition to Van den Broeck's comprehensive computational study on the C-SHAP score, other works have reported complexity results related to the C-SHAP score for particular configurations. Notably, \cite{arenas23} demonstrated the tractability of computing C-SHAP for the class of Decomposable Deterministic Boolean Circuits under independent distributions, while \cite{marzouk24a} reported same positive complexity result for the family of Weighted Automata under Markovian distributions.

% Paragraph on I-SHAP
%Regarding the computational aspects of other SHAP variants, a significant contribution to the literature is the introduction of the TreeSHAP algorithm \citep{lundbergnature}. This polynomial-time algorithm computes exactly local and global Interventional SHAP (I-SHAP) scores for Tree-based models under empirical distributions. Additionally, other positive complexity results for computing I-SHAP have been documented, particularly for piecewise linear regression trees \citep{zern23} and for models that can be decomposed into lower-order terms \citep{hu2023}.

% Paragraph 3. Computing 

 The aim of this paper is to provide a comprehensive, multi-dimensional perspective on the problem of SHAP computation, analyzed through the lens of formal computational theory~\citep{arora2009computational}. This analysis spans four key dimensions: \begin{inparaenum}[(i)] \item the variants of the Shapley value, including Baseline, Interventional, and Conditional SHAP; \item the class of models to be interpreted; \item the distributional assumptions regarding the input data generation process; and \item the scope of the explanatory analysis, which can be either \emph{local} or \emph{global}, with the global scope measured as an aggregate of \emph{local} SHAP values relative to the input data-generating distribution~\citep{frye20}.\end{inparaenum}

%Specifically, we examine the computational complexity of obtaining Shapley values as a multifaceted framework influenced by four key parameters: \begin{inparaenum}[(i)] \item the model type (e.g., decision trees, neural networks, etc.), \item the feature distribution used for computation, \item the scope of analysis (whether local or global), and, \item the specific SHAP variant, such as conditional, interventional, or baseline\end{inparaenum}. The summary of the computational results obtained in this work are highlighted in Table \ref{fig:summaryresults}. Specifically, we show that:

\paragraph{Our contributions.} The complexity results of this work, summarized in Table \ref{fig:summaryresults}, are:

%\textcolor{red}{Guy: I don't really like this positive/negative phrasing. Isn't this usually referred to us upper bounds and lower bounds?}

\begin{itemize}
    \item \emph{On the positive side,} in Section \ref{sec:tractable} we prove that both local and global Interventional and Baseline SHAP can be computed in polynomial time for the family of weighted automata, decision trees, tree ensembles in regression tasks, and linear regression models when input instances are assumed to be generated from a distribution modeled by a Hidden Markov model.
    \item \emph{On the negative side,} in Section \ref{sec:intractable} we establish intractability results, including NP-hardness, coNP-hardness, etc., for computing not only Conditional SHAP but also Interventional and Baseline SHAP across a range of neural networks (e.g., ReLU, Sigmoid, RNN-ReLU) and tree ensemble classifiers (e.g., Random Forests, XGBoost). These results hold even under strict conditions, such as uniform distributions or feature independence.
    \item Finally, in Section~\ref{sec:generalized}, we present generalized computational complexity relationships between SHAP variants, demonstrating that some are more or less tractable than others in certain distributional scenarios. Using these findings, we establish new complexity results for computing various SHAP variants across different models.
\end{itemize}

%\hspace{1em} \textit{a. On the positive side:} (Section \ref{sec:tractable}) We prove that both local and global Interventional and Baseline SHAP can be computed in polynomial time for the family of weighted automata, decision trees, tree ensembles in regression tasks, and linear regression models when input instances are assumed to be generated from a distribution modeled by a Hidden Markov model.

%\hspace{1em} \textit{b. On the negative side:} (Section \ref{sec:intractable}) We establish intractability results, including NP-hardness, coNP-hardness, etc., for computing not only Conditional SHAP but also Interventional and Baseline SHAP across a range of neural networks (e.g., ReLU, Sigmoid, RNN-ReLU) and tree ensemble classifiers (e.g., Random Forests, XGBoost). These results hold even under strict conditions, such as uniform distributions or feature independence.
%The summary of the computational results obtained in this article are highlighted in Table \ref{fig:summaryresults}. Specifically, we show that:
%\begin{enumerate}
%\hspace{1em} \textit{a. On the positive side} (Section \ref{sec:tractable})\textbf{:}
 %    We prove that both local and global Interventional and Baseline SHAP can be computed in polynomial time for the family of weighted automata, decision trees, tree ensembles in regression tasks, and linear regression models when the distribution is modeled by a hidden Markov model. This result carries two important implications: First, it extends the distributional assumptions of the widely-used TreeSHAP algorithm beyond empirical ones and eliminates the feature independence assumption in LinearSHAP. A second, important theoretical insight is the revelation of a \emph{stark computational complexity gap} between Conditional SHAP, for which this setting is NP-hard, and Interventional and Basline SHAP, where this task is poly-time solvable.








%\hspace{1em} \textit{b. On the negative side} (Section \ref{sec:intractable}): We prove intractability results (NP, coNP-hardness, etc.) for computing not only Conditional SHAP but also Interventional and Baseline SHAP across a range of neural networks (e.g., ReLU, Sigmoid, RNN-ReLU) and tree ensemble classifiers (e.g., Random Forests, XGBoost). These results hold even under strict conditions, like uniform distributions or feature independence. This indicates that although some SHAP variants may be more efficient in certain cases (see positive results section), they remain intractable for specific model types.


\subsection*{Key Takeaways}

The obtained complexity results provide both theoretical and practical  insights regarding the problem of SHAP computation:

\begin{enumerate}
\item \textbf{There are substantial complexity differences between SHAP variants.} Particularly, we show \emph{stark complexity gaps} between obtaining Conditional SHAP, which is NP-Hard, and both Interventional SHAP and Baseline SHAP, which can be solved in polynomial time --- demonstrating substantial deviations among the SHAP variants. Our findings additionaly pinpoint the specific settings where these gaps occur and where they do not.
\item \textbf{The distributional assumptions made by TreeSHAP and LinearSHAP can be extended to cover substantially more expressive classes of distributions.} Specifically, we demonstrate that local and global Interventional and Baseline SHAP can be solved efficiently in polynomial time for certain model families, including XGBoost trees, while surpassing the distributional scope of the widely used TreeSHAP algorithm, limited to empirical distributions. In addition, our results also relax the feature independence requirement in LinearSHAP. These results could significantly improve SHAP value distribution modeling, which is essential for computing faithful explanations~\citep{aas2021explaining}.
\item \textbf{Obtaining SHAP is strictly easier in soft-voting tree ensembles compared to hard-voting tree ensembles.} Many of our findings highlight significant differences in the complexity of obtaining SHAP for tree ensembles used in \emph{regression} versus \emph{classification}. These findings extend some of the conclusions made in~\citep{huangupdates} to a more general setting, and underline the feasibility of obtaining SHAP explanations for soft-voting ensembles as compared to hard-voting ensembles, where these prove to be intractable.
\item \textbf{Obtaining SHAP for neural networks is hard, even in highly simplified settings.} We prove various intractbility results (e.g., NP, $\#$P-Hardness, etc.) for different neural networks, demonstrating that this hardness persists in different settings, and even for \emph{baseline} SHAP, the simplest SHAP variant.
\item \textbf{Obtaining Global SHAP is often tractable, despite the additional expectation factor.} Interestingly, we prove that in many scenarios, the tractability of local SHAP extends to the global SHAP variant explored in~\citep{frye20}, despite the added complexity of computing an expectation over the entire data distribution.\end{enumerate}



%\begin{enumerate}
%\item The polynomial-time solvability of local and global Interventional and Baseline SHAP for specific models extends the distributional assumptions of the popular TreeSHAP algorithm beyond empirical distributions. Additionally, it relaxes the feature independence assumption in LinearSHAP.
%\item A notable theoretical insight is the identification of a \emph{stark computational complexity gap} between Conditional SHAP, which is NP-hard, and Interventional and Baseline SHAP, which are solvable in polynomial time. The negative results indicate that, while some SHAP variants may be more efficient for certain cases (as noted in section \ref{sec:tractable}), they remain computationally intractable for specific model types. This holds true even under strict conditions, such as feature independence or uniform distributions, highlighting the challenges of applying SHAP to a broader range of models.
%\end{enumerate}
Due to space limitations, we provide only a brief summary of the proofs for our claims in the paper, with the full detailed proofs included in the appendix.

%\textcolor{red}{The final version doesn't ship with the appendix, right? So the reference needs to be changed to the arxiv version?}