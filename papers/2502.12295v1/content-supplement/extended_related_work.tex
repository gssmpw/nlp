\section{Extended Related Work}

In this section, we include a more elaborate discussion of related work and key complexity results examined in prior research. 

\textbf{SHAP values.} Building on the initial SHAP framework introduced by~\citep{lundberg2017} for deriving explanations of ML models, various subsequent works extensively investigated the application of SHAP across various contexts within the XAI literature. Many efforts have concentrated on developing numerous other SHAP variants beyond Conditional SHAP \citep{sundararajan20b, janzing20a, heskes2020causal}, aligning SHAP with the distribution manifold \citep{frye2020shapley, taufiq2023manifold}, and enhancing the approximation of its calculation \citep{fumagalli2024shap, sundararajan2020shapley, burgess2021approximating, kwon2021efficient}. Additionally, the literature has explored various limitations of SHAP in different contexts \citep{fryer2021shapley, huang2024failings, kumar2020problems, marques2024explainability}.


%These have mainly focused on expansions to (many) other SHAP variants, beyond Conditional SHAP~\citep{sundararajan20b, janzing20a, heskes2020causal}, algining SHAP with respect to the distribution manifold~\citep{frye2020shapley, taufiq2023manifold}, and methods to improve its calculation approximation~\citep{fumagalli2024shap, sundararajan2020shapley, burgess2021approximating, kwon2021efficient}. Other efforts within the literature has also discussed various limitations of SHAP within different contexts~\citep{fryer2021shapley, huang2024failings, kumar2020problems, marques2024explainability}.


\textbf{The Complexity of SHAP.} Notably, \citep{vander21} investigates Conditional SHAP, presenting a range of tractability and intractability results for different ML models, with a key insight being that computing Conditional SHAP under independent distributions is as complex as computing the conditional expectation. Later, \cite{arenas23} generalizes these findings, showing that the tractability results for Conditional SHAP align with the class of Decomposable Deterministic Boolean Circuits and establishing that both the Decomposability and Determinism properties are necessary for tractability. More recently, \cite{marzouk24a} moves beyond the independent distribution assumption, extending the analysis to \emph{Markovian} distributions, which are significantly less expressive than the HMM-modeled distributions considered in our work. Additionally, \cite{huangupdates} introduces distinctions between regression and classification in tree ensembles for Conditional SHAP and extends previous results to diverse input and output settings. Other relevant, but less direct extensions of these complexity results are extensions to the domain of databse tuples~\citep{deutch2022computing, livshits2021shapley, bertossi2023shapley, kara2024shapley, karmakar2024expected}, as well as obtaining the complexity of other interaraction values other than Shapley values~\citep{abramovich2024banzhaf, barcelo2025computation}. Our work provides a novel analysis of all three major SHAP variants (baseline, interventional, and conditional), broadening distributional assumptions and offering new insights into local and global SHAP values. We frame SHAP computation as a multifaceted process shaped by \begin{inparaenum}[(i)] \item model type; \item SHAP variant; \item distributional assumptions; and \item the local-global distinction.\end{inparaenum}

\textbf{Formal XAI.} More broadly, our work falls within the subdomain of interest known as \emph{formal XAI}~\citep{marques2023logic}, which aims to generate explanations for ML models with formal guarantees~\citep{ignatiev2020towards, bassan2023towards, darwiche2020reasons, darwiche2022computation, ignatiev2019abduction, audemard2022preferred}. These explanations are often derived using formal reasoning tools, such as SMT solvers~\citep{barrett2018satisfiability} (e.g., for explaining tree ensembles~\citep{audemard2022trading}) or neural network verifiers~\citep{katz2017reluplex, wu2024marabou, wang2021beta} (e.g., for explaining neural networks~\citep{izza2024distance, bassan2023formally}). A key focus within formal XAI is analyzing the computational complexity of obtaining such explanations~\citep{barcelo2020model, waldchen2021computational, cooper2023tractability, bassanlocal, blanc2021provably, amir2024hard, bass2025exp, adolfi2024computational, barcelo2025explaining, calautti2025complexity, ordyniak2023parameterized}. 



%More generally, our work can be seen as part of the subdomain of interest termed \emph{formal XAI}~\citep{marques2023logic}, which is focused on obtaining explanations for ML models with formal guarantees~\citep{ignatiev2020towards, bassan2023towards, darwiche2020reasons, darwiche2022computation, ignatiev2019abduction, audemard2022preferred}, where these explanations are often obtained via the use of formal reasoning tools such as SMT solvers~\citep{barrett2018satisfiability} (for obtaining explanations for tree ensembles~\citep{audemard2022trading}) or neural network verifiers~\cite{katz2017reluplex, bass} (for obtaining explanations for neural networks~\citep{bassan2023formally, izza2024distance}). A primary area of interest within formal XAI, is understanding the computational complexity associated with obtaining such explanations~\citep{barcelo2020model, cooper2023tractability, bassanlocal, blanc2021provably, amir2024hard, bass2025exp, adolfi2024computational, barcelo2025explaining, calautti2025complexity}.
