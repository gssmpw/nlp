\section{Complexity Classes, Models, and Distributions} \label{app:sec:terminology}

In this section, we introduce the general preliminary notations used throughout our paper, including those related to model types, distributional assumptions, and complexity classes.

%\textcolor{red}{This section requires many polishing works. I settled for providing an enumeration of models/distributions, their descriptions and parameters etc. in separate paragraphs...}

\subsection{Computational Complexity Classes}

In this work, we assume that readers are familiar with standard complexity classes, including polynomial time (PTIME) and non-deterministic polynomial time (NP and coNP). We also discuss the complexity class NTIME, which refers to the set of decision problems solvable by a non-deterministic Turing machine within a specified time bound, such as polynomial time. Additionally, we cover the class $\#$P, which counts the number of accepting paths of a non-deterministic Turing machine and can be seen as the ``counting'' counterpart of NP. It is known that PTIME is contained within NP, coNP, NTIME, and $\#$P, but it is widely believed that these containments are strict, i.e., PTIME $\subsetneq$ NP, coNP, NTIME, $\#$P~\citep{arora2009computational}. We use the standard notation $L_1 \preceq_{P} L_2$ to indicate that a polynomial-time reduction exists from the computational problem $L_1$ to $L_2$.

\subsection{Models}

In this subsection, we describe the families of model types used throughout the paper, including decision trees (\texttt{DT}), tree ensembles for classification ($\texttt{ENS-DT}_{\texttt{C}}$) and regression ($\texttt{ENS-DT}_{\texttt{R}}$), linear regression models ($\texttt{LIN}_{\texttt{R}}$), as well as neural networks (\texttt{NN-SIGMOID} and \texttt{RNN-ReLU}).


\textbf{Decision trees (\texttt{DT}).} We define a \emph{decision tree} (DT) as a directed acyclic graph representing a graphical model for a discrete function $f: \mathcal{X} \to \mathbb{R}$ in regression tasks, or $f: \mathcal{X} \to [c]$ for classification tasks (where $c \in \mathbb{N}$ is the number of classes). We assume that each input $\x_i$ can take a bounded number of discrete values, limited by some $k$. This graph encodes the function as follows:

%We define a \emph{decision tree} (DT) as an acyclic-directed graph that serves as a graphical model for a function $f: \mathcal{X} \to \mathbb{R}$ (for regression tasks) or $f: \mathcal{X} \to [c]$ for classification tasks (where $c\in \mathbb{N}$ is the number of classes). We assume that the number of discrete values for each input $\x_i$ is bounded by some $k$. This graph embodies the given function in the following manner: 
\begin{enumerate}
	\item Each internal node $v$ is associated with a unique binary input feature from the set $\{1,\ldots,n\}$;
	\item Every internal node $v$ has up to $k$ outgoing edges, corresponding to the values $[k]$ which are assigned to $v$;
	\item In the DT, each variable is encountered no more than once on any given path $\alpha$;
 	\item Each leaf node is labeled as one of the classes in $[c]$ (for classification tasks) or some $c\in\mathbb{R}$ for regression tasks.
\end{enumerate}

Thus, assigning a value to the inputs $\x\in\mathcal{X}$ uniquely determines a specific path $\alpha$ from the root to a leaf in the DT. The function $f(\x)$ is assigned either some $i\in [c]$ or some $i\in \mathbb{R}$ (depending on classification or regression tasks). The size of the DT, denoted as $\vert f \vert$, is measured by the total number of edges in its graph. To allow flexibility of the modeling of the DT, we permit different varying orderings of the input variables $\{1,\ldots,n \}$ across any two distinct paths, $\alpha$ and $\alpha'$. This ensures that no two nodes along any single path $\alpha$ share the same label. We note that in some of the proofs provided in this work, we simplify them by assuming that $k:=2$ or in other words that each feature is defined over binary feature assignments rather than discrete ones. However, this assumption is only for the sake of simplifying the proofs, and our proofs hold also for a general $k$ as well.

\textbf{Decision tree ensembles ($\texttt{ENS-DT}_{\texttt{R}}$, $\texttt{ENS-DT}_{\texttt{C}}$).} There are various well-known architectures for tree ensembles. While these models typically differ in their training processes, our work focuses on post-hoc interpretation, so we emphasize the distinctions in the inference phase rather than the training phase. Specifically, our analysis targets ensemble families that use weighted-voting methods during inference. This includes tree ensembles based on boosting, such as XGBoost. Additionally, in cases where all weights are equal, our formalization also covers majority-voting tree ensembles, such as those used in common bagging techniques like Random Forests. Our approach applies to both tree ensembles for regression tasks (denoted as $\texttt{ENS-DT}_{\texttt{R}}$) and classification tasks (denoted as $\texttt{ENS-DT}_{\texttt{C}}$). We make this distinction explicitly, as we will demonstrate that the complexity results differ for classification and regression ensembles.



%\paragraph{Tree-based models (\texttt{DT}, $\texttt{\text{ENS-DT}}_{\text{\texttt{R}}},~\texttt{\text{ENS-DT}}_{\texttt{\text{C}}}$).}  A decision tree (DT) over the (binary) feature set $X = \{X_{1},~X_{2}, \ldots,~X_{n}\}$ follows a tree structure where:
%\begin{itemize}
%\item Each internal node represents a test on a binary feature $X_{i} \in X$, with the test outcome being either 0 or 1.
% \item Each branch corresponds to the result of the test (0 or 1).
%\item Each leaf node represents a class label or a decision.
%\end{itemize}

%Formally, a DT recursively partitions the feature space based on binary splits, directing data down the tree based on feature values until a leaf node is reached. The family of decision trees is referred to \texttt{DT} in the article.

%Models in \texttt{DT} form the basic building block of a more general family of Tree-based models, referred to as ensemble trees,denoted by $\texttt{ENS-DT}_{\texttt{R}}$ in our work. 

Conceptually, an ensemble tree model $\mathcal{T} \in  \texttt{ENS-DT}_{\texttt{R}}$ is constructed as a linear combination of DTs. Formally, $\mathcal{T}$ is parametrized by the tuple $\{T_{i}\}_{i \in [m]}, \{ w_{i}\}_{i \in [m]}$ where  $\{T_{i}\}_{i \in [m]}$ is a collection of DTs (referred to as an ensemble), and $\{w_{i}\}_{i \in [m]}$ is a set of real numbers. The model $\mathcal{T}$ is used for regression tasks and the function that it computes is given as:

\begin{equation}
\label{tree_ensemble_formulation_appendix}
    f_{\mathcal{T}}(x_{1}, \ldots, x_{n}) := \sum\limits_{i=1}^{m} w_{i} \cdot f_{T_{i}}(x_{1}, \ldots, x_{n})
\end{equation}


Aside from regression tasks, ensemble trees are also commonly used for classification tasks. In this context, each decision tree $\mathcal{T}$ is a classification tree (as defined earlier for DTs) that assigns a class label $i \in [c]$. By using the formulation from Equation~\ref{tree_ensemble_formulation_appendix}, we can limit the following sum to only those decision trees relevant to class $i$, and obtain a corresponding weight $f^i_{\mathcal{T}}$. The class assigned by the ensemble will be the one with the highest value of $f^i_{\mathcal{T}}$. It’s worth noting that if all weights are taken to be equal, this mirrors majority voting classification, as seen in random forest classifiers. Furthermore, since our proofs in this context only address \emph{hardness}, for simplicity, we assume the number of classes $c = 2$, meaning the random forest classifier is binary. Clearly, the hardness results for this case also apply to the more general multiclass scenario. In this specific case, the given formalization can be restated as:


%Besides regression tasks,  ensemble trees are also widely employed for classification tasks. Here, each decision tree $\mathcal{T}$ is a classification DT (as defined above) and outputs some class in $i\in 
% [c]$. Then, by the formulation given in Equation~\ref{tree_ensemble_formulation_appendix} we can restrict the following sum only to the DT's that are relevant to that specific class $i$ and obtain some corresponding weight $f^i_{T}$. Then, the classification of the tree ensemble will be the class $i\in[c]$ which recieved the maximal value of $f^i_{T}$. We note that if we take all weights to be equal, this would be exactly parallel to majority voting classification, such as in random forest classifiers. Moreover, since our proofs in this context are only \emph{hardness} proofs, we assume, for simplicity that the number of classes $c:=2$, i.e., that the random forest classifier is a binary classifier. Clearly, hardness for this setting also holds for the general setting as well. In this specific case, the mentioned formalization is equivalent to stating that:

 \begin{equation}
\label{tree_ensemble_formulation_appendix}
    f_{\mathcal{T}}(x_{1}, \ldots, x_{n}) := \text{step}(\sum\limits_{i=1}^{m} w_{i} \cdot f_{T_{i}}(x_{1}, \ldots, x_{n}))
\end{equation}

where the step function is defined as: $\text{step}(\x) = 1 \iff \x \geq 0$. We refer to the class of classification tree ensembles as $\texttt{ENS-DT}_{\texttt{C}}$.

%Ensemble Trees for classification tasks can be defined by incorporating an additional parameter to models in $\texttt{\text{ENS-DT}}_{\texttt{\text{R}}}$ that plays the role of a threshold separating the regions in the feature space labeled by $1$ from those labeled by $0$. Formally, an ensemble tree for classification is parametrized by the tuple $\mathcal{T}_{c} = \langle\mathcal{T}, q\rangle$ where $\mathcal{T} \in \texttt{\text{ENS-DT}}_{\texttt{\text{R}}}$, and $q \in \mathbb{R}$. The model $\mathcal{T}_{c}$ assigns the label $1$ to a given input  instance $x$ if $I(f_{\mathcal{T}}(x) \geq q)$. The set of ensemble trees used for classification are denoted $\texttt{\text{ENS-DT}}_{\text{c}}$. 

%\textcolor{blue}{
%I let you say that by a suitable parameterization of $\mathcal{T}_{c}$, we can construct random forests. Indeed, the family $\text{ENS-DT}_{c}$ contains the family of random forests..
%}
\paragraph{Neural Networks (\texttt{NN-SIGMOID}, \texttt{RNN-ReLU}).} 
Here, we define the general neural network architecture used throughout this work, followed by a specific definition of the (non-recurrent) sigmoidal neural network (\texttt{NN-SIGMOID}) referenced in the paper. We note that the definition of recurrent neural networks with ReLU activations (\texttt{RNN-ReLU}) mentioned in the paper was provided in the main text, and hence it is not explicitly redefined here. We denote a neural network $f$ with $t-1$ hidden layers ($f^{(j)}$, where $j$ ranges from $1$ to $t-1$), and a single output layer ($f^{(t)}$). We observe that we can assume a single output layer since $f^{(t)}$ will yield a value in $\mathbb{R}$ for regression tasks, or it will be applied for binary classification (we will later justify why assuming binary classification is sufficient, and the correctness results will extend to multi-class classification as well). The layers of $f$ are defined recursively — each layer $f^{(j)}$ is computed by applying the activation function $\sigma^{(j)}$ to the linear combination of the outputs from the previous layer $f^{(j-1)}$, the corresponding weight matrix $W^{(j)}$, and the bias vector $b^{(j)}$. This is represented as:

\begin{equation}
    f^{(j)} := \sigma^{(j)}(f^{(j-1)}W^{(j)} + b^{(j)})
\end{equation}

Where $f^{(j)}$ is computed for each $j$ in $\{1,\ldots,t\}$. The neural network includes $t$ weight matrices ($W^{(1)},\ldots,W^{(t)}$), $t$ bias vectors ($b^{(1)},\ldots,b^{(t)}$), and $t$ activation functions ($\sigma^{(1)},\ldots,\sigma^{(t)}$). The function $f$ is defined to output $f := f^{(t)}$. The initial input layer $f^{(0)}$ serves as the model's input. The dimensions of the biases and weight matrices are specified by the sequence of positive integers ${d_{0}, \ldots, d_{t}}$. We specifically focus on weights and biases that are rational numbers, represented as $W^{(j)}\in \mathbb{Q}^{d_{j-1}\times d_{j}}$ and $b^{(j)}\in \mathbb{Q}^{d_{j}}$, which are parameters optimized during training. Clearly, it holds that $d_0=n$. For regression tasks, the output of $f$ (i.e., $d_t$) will be in $\mathbb{R}$. For classification tasks, we assume multiple outputs, where typically a softmax function is applied to choose the class $i\in[c]$ with the highest value. However, since the proofs for both \texttt{NN-SIGMOID} and \texttt{RNN-ReLU} are \emph{hardness} proofs, we assume for simplicity that in classification cases, we use a binary classifier, i.e., $c=2$. Thus, hardness results will clearly apply to the multi-class setting as well. Therefore, for binary classification, it follows that $d_{0} = n$ and $d_{t} = 1$.

The activation functions $\sigma^{(i)}$ that we focus on in this work are either the ReLU activation function, defined as $\text{ReLU}(x) := \max(0, x)$ (used for the RNN-ReLU model), or the sigmoid activation function, defined as $\text{Sigmoid}:=\frac{1}{1+e^{-x}}$. In the case of our binary classification assumption, we assume that the last output layer can either use a sigmoid function or (without loss of generality) a step function for the final layer activation. Here, we denote $\text{step}(x) = 1 \iff x \geq 0$.




%Here, we will define our general neural network architecture used throughout this work, and then will specifically specify the (non-requerent) sigmoidal neural network (\texttt{NN-SIGMOID}) that was reffered to throught the paper. We note that the definition of a recurrent neural networks with ReLU activations that were refered to throught the paper (\texttt{RNN-ReLU}) were defined within the main paper and are hence not explicitly defined here. We denote a neural network $f$, that consists of $t-1$ \emph{hidden layers} ($f^{j}$ where $j$ ranges from $1$ to $t-1$) and a single output layer ($f^{t}$). The layers are defined recursively --- each layer $f^{(j)}$ is computed by applying the activation function $\sigma^{(j)}$ to the linear combination of the outputs from the previous layer $f^{(j-1)}$, the corresponding weight matrix $W^{(j)}$, and the bias vector $b^{(j)}$. This is represented as $f^{(j)} := \sigma^{(j)}(f^{(j-1)}W^{(j)} + b^{(j)})$ for each $j$ in $\{1,\ldots,t\}$. The neural network includes $t$ weight matrices ($W^{(1)},\ldots,W^{(t)}$), $t$ bias vectors ($b^{(1)},\ldots,b^{(t)}$), and $t$ activation functions ($\sigma^{(1)},\ldots,\sigma^{(t)}$).

%The function $f$ is defined to output $f := g^{(t)}$. The initial input layer $g^{(0)}$ is the model's input. The dimensions of the biases and weight matrices are specified by the sequence of positive integers $\{d_{0}, \ldots, d_{t}\}$. We specifically focus on weights and biases that are rational numbers, represented as $W^{(j)}\in \mathbb{Q}^{d_{j-1}\times d_{j}}$ and $b^{(j)}\in \mathbb{Q}^{d_{j}}$, which are parameters that are optimized during training. Clearly, holds that $d_0=n$. For regression tasks, the output of $f$ (i.e., $d_t$) will be in $\mathbb{R}$. For classification tasks, we can assume multiple outputs, where usually a softmax function is applied to choose the class $i\in[c]$ with the highest value. However, since the proofs for both \texttt{NN-SIGMOID} and  \texttt{RNN-ReLU} are \emph{hardness} proofs, we assume for simplicity that, in cases of classification, we have a binary classifier, i.e., $c=2$. Then, hardness results will clearly apply to the multi-class setting as well. Hence, for binary classification, it follows that $d_{0} = n$ and $d_{t} = 1$. 

%The activation functions $\sigma^{(i)}$ that we focus on in this work are either the ReLU activation function, defined as $\text{ReLU}(x) := \max(0, x)$ (which is used for the RNN-ReLU model) or the sigmoid activation function $\text{Sigmoid}:=\frac{1}{1+e^{-x}}$. In the case of our binary classification assumption we assume that the last output layer can either take a \emph{sigmoid} function, or (without loss of generality) a step function for the final layer activation, where we again can denote $\text{step}(\x) = 1 \iff \x \geq 0$.






%A sigmoidal neural network $M$ of $N$ input features of a single layer computes a function from $\mathbb{R}^{n}$ to $[0,1]$ given as:
%$$f_{M}(x; \{w_{i}\}_{i \in [n]}, b) = \sigma(\sum\limits_{i = 1}^{N} w_{i} \cdot x_{i} + b)$$
%where $\sigma(.)$ is the sigmoidal function. 

%The parameters of a sigmoidal neural network are the weights $\{w_{i}\}_{i \in [N]}$ and the intercept parameter $b$.


\paragraph{Linear Regression Models ($\texttt{\text{LIN}}_{\texttt{\text{R}}}$).} 
A linear regression model corresponds to a single-layer neural network in the regression context, as defined in the formalization above, where $t=1$. The linear model is described by the function $f(\x) := (\mathbf{w} \cdot \x) + b$, with $b \in \mathbb{Q}$ and $\mathbf{W} \in \mathbb{Q}^{n \times d_1}$. Furthermore, we introduce an alternative renormalization of linear regression models, which will be helpful for the technical developments in Section~\ref{app:reductiontree}. Specifically, a linear regression model over the finite set $\mathbb{D} := [m_{1}] \times \ldots [m_{n}]$, where $\{m_{i}\}_{i \in [n]}$ represents a set of integers, can be parametrized as $\langle \{w_{i,d}\}_{i \in [n], d \in \mathbb{D}_{i}}, b\rangle$, where $\{w_{i,d}\}_{i \in [n], d \in m_{i}}$ is a collection of rational numbers and $b \in \mathbb{Q}$. The function computed by $f$ is given as:


%A linear regression model represents a single-layer neural network given our formalization above for a regression task. In other words, we have that $t=1$. The linear model is defined by the function $f(\x) :=(\mathbf{w}\cdot\x)+b$ with $b\in\mathbb{Q}$, and $\mathbf{W}\in\mathbb{Q}^{n\times d_{1}}$. Moreover, we will state an alternative renormalization of linear regression models, which will be beneficial for the technical development in Section~\ref{app:reductiontree}. Specifically, a Linear regression model over the finite set $\mathbb{D} = [m_{1}] \times \ldots [m_{n}]$ where $\{m_{i}\}_{i \in [n]}$ can be defined as a collection of integers can be parametrized as $M = \langle \{w_{i,d}\}_{i \in [n], d \in \mathbb{D}_{i}}, b\rangle$ where $\{w_{i,d}\}_{i \in [n], d \in m_{i}}$ is a collection of real numbers, and $b \in \mathbb{R}$. The function computed by $M$ is given as:

$$f(x_{1}, \ldots , x_{n}) = \sum\limits_{i=1}^{n} \sum\limits_{d \in \mathbb{D}_{i}} w_{i,d} \cdot I(x_{i}=d) + b$$

%\textcolor{blue}{This reformulation of linear regression trees, specifically designed for finite discrete input features, is quite unconventional. However, it ultimately computes the same function as the classical formulation. I recommend including the classical formulation (similar to the sigmoidal neural network presented above) to provide the reader with additional intuition. You could mention that this formulation is equivalent to the classical one, but for the purposes of technical development in Section \ref{app:reductiontree}, we will prioritize this reformulation. }


\subsection{Distributions}
In this subsection, we will formally define various distributions relevant to this work, which have been referenced throughout the main paper or in the appendix. We note that the definition of hidden Markov models (\texttt{HMM}), the most significant class of distributions examined in this study, is not included here as it was already provided in the main text.

\paragraph{Independent Distributions (\texttt{IND}).} The family \texttt{IND} is the most elementary family of distributions based on the assumption of probabilistic independence of all random variables (RVs) involved in the model. Formally, given some set of discrete values $[k]$, we can describe a probability function $p:[n]\times [k]\to [0,1]$. For example, $p(1,2)=\frac{1}{2}$, implies that the probability of feature $i=1$, to be set to the value $k=2$ is $\frac{1}{2}$. Then we can define $\mathcal{D}_p$ as an independent distribution over $\mathcal{X}$ iff:

\begin{equation}
    \label{eq:explanation}
    \mathcal{D}_p(\x):=\Big({\displaystyle \prod_{i\in [n], \x_i=j} p(i, j)}\Big)
\end{equation}

It is evident that the uniform distribution is a specific instance of $\mathcal{D}_p$, obtained by setting $p(i,j):=\frac{1}{|k|}$ for every $i \in [n]$ and $j \in [k]$.
%\shahaf{Not sure how to define this for sequence models}

%\begin{equation}
%    \label{eq:explanation}
%    \mathcal{D}_p^{(|\x|)} (\x):=\Big({\displaystyle \prod_{i\in [n], \x_i=j} p(i, j)}\Big)
%\end{equation}



\paragraph{Empirical Distributions (\texttt{EMP}).} The empirical distribution provides a practical way of estimating probabilities from a finite dataset. Given a set of $M$ samples, each represented as a vector in $\{0,1\}^{N}$, the empirical distribution assigns a probability to each possible vector $x$ in the space. This probability is simply the proportion of samples in the dataset that are equal to $x$. Formally, for a dataset $\mathcal{D} = \{x_{1}, \ldots, x_{M}\}$, the empirical distribution $P_{\mathcal{D}}(x)$ is defined as the frequency of occurrences of the vector $x$ in the dataset, normalized by the total number of samples, i.e.:
$$P_{\mathcal{D}}(x) = \frac{1}{|\mathcal{D}|} \sum\limits_{i=1}^{|\mathcal{D}|}  I(x_{i} = x)$$

\paragraph{Naive Bayes Model (\texttt{NB}).} A naive Bayes model is a latent probabilistic model that involves $n+1$ random variables (RVs), denoted as $(X_{1}, \ldots , X_{n}, Y)$, where $\{X_{i}\}_{i \in [n]}$ represent the $n$ observed RVs, and $Y$ is an unobserved (latent) RV. The key probabilistic assumption of naive Bayes models is that the observed RVs are conditionally independent given the value of the latent variable $Y$. More formally, a model $M \in \ar{\texttt{NB}}$ over $n$ RVs is specified by the parameters $\langle\pi, \{P_{i}\}_{i \in [n]}\rangle$, where:

%A naive Bayes model is a latent probabilistic model over $n+1$ random variables (RVs) $(X_{1}, \ldots , X_{n}, Y)$, where $\{X_{i}\}_{i \in [n]}$ are called $n$ (observed) random variables (RVs) and an (unobserved) RV $Y$ (a.k.a. a latent variable). The main probabilistic assumption upon which the naive Bayes models are based is that the observed RVs are independent given the value of the latent variable $Y$. Formally, a model  $M \in \ar{\texttt{NB}}$ over $n$ RVs is parameterized by $\langle\pi, \{P_{i}\}_{i \in [n]}\rangle$ where:
\begin{itemize}
    \item $\pi$ is a probability distribution over the domain value of the latent variable $Y$ ($dom(Y)$),
    \item For $i \in [n]$, $P_{i} \in \mathbb{R}^{n \times \text{dom}(Y)}$ is a stochastic matrix. 
\end{itemize}
The marginal probability distribution computed by $M$ is given as:
$$P_{M}(x_{1}, \ldots x_{n}, y) = \pi(y) \prod\limits_{i=1}^{n} P_{i}[x_{i}, y]$$

\paragraph{Markovian Distributions (\texttt{MARKOV}).} A (stationary) Markovian distribution $M \in \texttt{MARKOV}$ over an alphabet $\Sigma$ is represented by the tuple $\alpha, T$ where $\pi$ is a probability distribution over $\Sigma$ and $T$ is a stochastic matrix in $\mathbb{R}^{|\Sigma| \times |\Sigma|}$ \footnote{A matrix $A \in \mathbb{R}^{n \times m}$ is said to be stochastic if each row vector corresponds to a probability distribution over $[m]$.}. A Markovian model $M$ computes a probability distribution over $\Sigma^{\infty}$. The probability of generating a given sequence $w \in \Sigma^{*}$ as a prefix by a Markovian model $M = \pi, T$ is given as:
$$P_{M}^{(|w|)}(w) = \pi[w_{1}] \cdot \prod\limits_{i=2}{|w|} T[w_{i-1}, w_{i}]$$
where for a given integer  $n$, $P_{M}^{(n)}$ designates the probability distribution over $\Sigma^{n}$ interpreted as the probability of generating a prefix of length $n$. 

Analogous to HMMs, one can define a family of models representing the non-sequential counterpart of Markovian models, which we'll refer to as $\ar{\texttt{\text{MARKOV}}}$. A model $\ar{\texttt{M}}  \in \ar{\texttt{\text{MARKOV}}}$ defines a probability distribution over $\Sigma^{n}$ for $n \geq 1$, and parameterized by the tuple $\pi, \alpha, \{T_{i}\}_{i \in [n]}$, where:
\begin{itemize}
    \item $\pi$ is a permutation from $[n]$ to $[n]$.
    \item $\alpha$ defines a probability distribution over $[n]$ (also called the initial state vector),
    \item For each $i \in [n]$, $T_{i}$ is a stochastic matrix over $\mathbb{R}^{|\Sigma| \times |\Sigma|}$
\end{itemize}

The procedure of generating the tuple $(x_{1}, \ldots, x_{n})$ (where $x_{i} \in \Sigma$) by $\ar{\texttt{M}}$ can be described recursively as follows:
 \begin{enumerate}
     \item \textbf{Generation of the first element of the sequence.} Generate $x_{\pi(1)}$ with probability $\alpha[x_{\pi(1)}]$.
     \item \textbf{Generation of the (i+1)-th element.} For $i \in [n-1]$, the probability of generating the element $x_{\pi(i+1)}$ given that $x_{\pi(i)}$ is generated is equal to $T[x_{\pi(i)}, x_{\pi(i+1)}]$
 \end{enumerate}
  


%\paragraph{Hidden Markov Models (\texttt{HMM})}\citep{rabiner1986introduction} are a widely used class of sequential latent probabilistic models applied in various domains\citep{knill1997hidden, de2007hidden}. Given an alphabet $\Sigma$ (also known as the observation space), an HMM defines a probabilistic function over $\Sigma^{\infty}$. More formally, an HMM of size $n$ over $\Sigma$ is defined by the tuple $\langle\alpha, T, O\rangle$, where: \begin{enumerate} \item $\alpha \in \mathbb{R}^{n}$, the initial state vector, denotes a probability distribution over $[n]$.
%\item $T \in \mathbb{R}^{n \times n}$, $O \in \mathbb{R}^{n \times |\Sigma|}$ are stochastic matrices, where each row represents a probability distribution.\end{enumerate}

%HMMs~\citep{rabiner1986introduction} are a widely popular class of sequential latent probabilistic models employed in various applications~\citep{knill1997hidden, de2007hidden}. For an alphabet $\Sigma$ (also, referred to as the observation space in the classical theory of HMMs), an HMM implements a probabilistic function over $\Sigma^{\infty}$. Formally, for an integer $n$, an HMM of size $n$ over $\Sigma$ is given by the tuple $<\alpha, T, O>$, where: \begin{inparaenum}[(i)] \item $\alpha \in \mathbb{R}^{n}$, referred to as the initial state vector, encodes a probability distribution over the set $[n]$, and \item $T \in \mathbb{R}^{n \times n}$, $O \in \mathbb{R}^{n \times \Sigma}$ are stochastic matrices (i.e., each of its row vectors encodes a probability distribution).\end{inparaenum}
    

%The WA formalism in Definition that was defined above is sufficient to represent HMMs, subject to reparameterization. In fact, it has been shown that the probability of an HMM $M=\langle\alpha, T, O\rangle$ generating a prefix $w \in \Sigma^{*}$ is given by: $\mathbf{1}^{T} \cdot \prod\limits_{i=1}^{|w|} A_{w_{i}} \cdot \alpha$\citep{hsu12}, where $\mathbf{1}$ is a row vector of all $1$'s, and for each $\sigma \in \Sigma$, $A_{\sigma} \myeq T \cdot \text{Diag}(O[:,\sigma])$. Here, $\text{Diag}(O[:, \sigma])$ is the diagonal matrix formed from the column vector in $O$ indexed by $\sigma$. We adopt this parameterization for HMMs and assume they are parameterized according to the 1-Alphabet WA formalism in Definition\ref{def
%}. For \emph{non-sequential models}, we assume the family of HMMs, denoted $\overrightarrow{\text{HMM}}$, represents latent variable models that describe probability distributions over random vectors in a finite domain.


%\begin{definition} {($\overrightarrow{\emph{HMM}}$)}\label{def:hmmnonsequentialdata}
%Let $(n,N) \in \mathbb{N}^{2}$ be two integers, and $\mathbb{D}$ a finite set. An $\overrightarrow{\emph{HMM}}$ over $\mathbb{D}^{n}$ is parameterized by the tuple $\langle\pi, \alpha, \{T_{i}\}_{i \in [n]}, \{O_{i}\}_{i \in [n]}\rangle$, where $\pi$ is a permutation on $[n]$, and for each $i \in [n]$, $T_{i}$ and $O_{i}$ are stochastic matrices in $\mathbb{R}^{N}$ and $\mathbb{R}^{N \times |\mathbb{D}|}$, respectively. A model $M$ in $\overrightarrow{\emph{HMM}}$ computes the following probability distribution over $\mathbb{D}^{n}$:

%Let $(n,N) \in \mathbb{N}^{2}$ be a pair of integers, and $\mathbb{D}$ be a finite set. A $\overrightarrow{\emph{HMM}}$ over $\mathbb{D}^{n}$ is parameterized by the tuple $<\pi, \alpha, \{T_{i}\}_{i \in [n]}, \{O_{i}\}_{i \in [n]}>$, where $\pi$ is a permutation from $[n]$ to $[n]$ and for any $i \in [n]$, $T_{i}$ (resp. $O_{i}$) are stochastic matrices in $\mathbb{R}^{N}$ (resp. $\mathbb{R}^{N \times |\mathbb{D}|}$). A model $M$ in $\overrightarrow{\emph{HMM}}$ computes the following probability distribution over $\mathbb{D}^{n}$:
$$
%      P_{M}(x_{1}, \ldots, x_{n}) := \mathbf{1}^{T} \cdot \prod\limits_{i=1}^{n} A_{i,x_{\pi(i)}} \cdot \alpha
      $$
%  where: 
%  $A_{i,x} \myeq T_{i} \cdot \text{Diag}(O_{i}[:,x])$.
%\end{definition}

%In essence, models in the family $\overrightarrow{\text{HMM}}$ are non-stationary HMMs where observations are ordered by a permutation $\pi$. They include a stopping probability mechanism, terminating after the $n$-th symbol with probability 1. Like HMMs, $\overrightarrow{\text{HMM}}$ includes independent, empirical, and Markovian distributions (see proof in  Appendix~\ref{app:reductiontree})




%\textcolor{blue}{I let you define the HMM based on its introduction in the main article. Also, you can mirror the presentation of Markovian Distributions given above. What i give here is just the meaning of parameters and the generative procedure (similar to markov). This way of understanding how HMMs generates sequences will be important for the reader to understand the reductions presented in section \ref{app:reductiontree}})

%For a given model $M = \alpha, \alpha, T, O$ in \text{HMM} over the alphabet $\Sigma$ with the size of the hidden state space equal to $m$ (\textcolor{blue}{The size of the hidden state space is the dimension of the vector $\alpha$, and $T$}), the procedure for generating an infinite sequence is given as follows:

%\begin{enumerate}
%    \item \textbf{The state initialization:} The probability of starting the generation from the hidden state $i \in [m]$ is given as $\alpha[i]$,
%    \item \textbf{The transition dynamics:} At position $i$, the probability of transitioning from the hidden state $i \in [m]$ to a hidden state $j \in [m]$ is equal to $T[i,j]$,
%    \item \textbf{Symbol emission:} The probability of emiting a symbol $\sigma \in \Sigma$ from the state $i \in [m]$ is equal to $O[i, \sigma]$
%\end{enumerate}