@inproceedings{qi_pointnet++_2017,
	title = {{PointNet}++: {Deep} {Hierarchical} {Feature} {Learning} on {Point} {Sets} in a {Metric} {Space}},
	volume = {30},
	shorttitle = {{PointNet}++},
	url = {https://proceedings.neurips.cc/paper/2017/hash/d8bf84be3800d12f74d8b05e9b89836f-Abstract.html},
	abstract = {Few prior works study deep learning on point sets. PointNet is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly. In particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds.},
	urldate = {2024-12-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
	year = {2017},
}
@article{yang_learning_2024_tpami,
    title = {Learning a {Contact} {Potential} {Field} for {Modeling} the {Hand}-{Object} {Interaction}},
    volume = {46},
    issn = {1939-3539},
    url = {https://ieeexplore.ieee.org/abstract/document/10478277},
    doi = {10.1109/TPAMI.2024.3372102},
    abstract = {Estimating and synthesizing the hand's manipulation of objects is central to understanding human behaviour. To accurately model the interaction between the hand and object (referred to as the “hand-object”), we must not only focus on the pose of the hand and object, but also consider the contact between them. This contact provides valuable information for generating semantically and physically plausible grasps. In this paper, we propose an explicit contact representation called Contact Potential Field (CPF). In CPF, we model the contact between a pair of hand-object vertices as a spring-mass system. This system encodes the distance of the pair, as well as a likelihood of that contact being stable. Therefore, the system of multiple extended and compressed springs forms an elastic potential field with minimal energy at the optimal grasp position. We apply CPF to two relevant tasks, namely, hand-object pose estimation and grasping pose generation. Extensive experiments on the two challenging tasks and three commonly used datasets have demonstrated that our method can achieve state-of-the-art in several reconstruction metrics, allowing us to produce more physically plausible hand-object poses even when the ground-truth exhibits severe interpenetration or disjointedness.},
    number = {8},
    urldate = {2024-07-29},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    author = {Yang, Lixin and Zhan, Xinyu and Li, Kailin and Xu, Wenqiang and Zhang, Junming and Li, Jiefeng and Lu, Cewu},
    month = aug,
    year = {2024},
    note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {Contact modeling, Contacts, Grasping, Image reconstruction, Pose estimation, Semantics, Task analysis, Three-dimensional displays, grasping pose generation, hand-object pose estimation},
    pages = {5645--5662},
}