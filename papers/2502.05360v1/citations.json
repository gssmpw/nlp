[
  {
    "index": 0,
    "papers": [
      {
        "key": "chizat2018global",
        "author": "Chizat, Lenaic and Bach, Francis",
        "title": "On the global convergence of gradient descent for over-parameterized models using optimal transport"
      },
      {
        "key": "mei2018mean",
        "author": "Mei, Song and Montanari, Andrea and Nguyen, Phan-Minh",
        "title": "A mean field view of the landscape of two-layer neural networks"
      },
      {
        "key": "rotskoff2018neural",
        "author": "Rotskoff, Grant M and Vanden-Eijnden, Eric",
        "title": "Neural networks as interacting particle systems: Asymptotic convexity of the loss landscape and universal scaling of the approximation error"
      },
      {
        "key": "lu2020mean",
        "author": "Lu, Yiping and Ma, Chao and Lu, Yulong and Lu, Jianfeng and Ying, Lexing",
        "title": "A mean field analysis of deep resnet and beyond: Towards provably optimization via overparameterization from depth"
      },
      {
        "key": "nitanda2021particle",
        "author": "Nitanda, Atsushi and Wu, Denny and Suzuki, Taiji",
        "title": "Particle dual averaging: Optimization of mean field neural network with global convergence rate analysis"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chizat2018global",
        "author": "Chizat, Lenaic and Bach, Francis",
        "title": "On the global convergence of gradient descent for over-parameterized models using optimal transport"
      },
      {
        "key": "chizat2020implicit",
        "author": "Chizat, Lenaic and Bach, Francis",
        "title": "Implicit bias of gradient descent for wide two-layer neural networks trained with the logistic loss"
      },
      {
        "key": "wojtowytsch2020convergence",
        "author": "Wojtowytsch, Stephan",
        "title": "On the convergence of gradient descent training for two-layer relu-networks in the mean field regime"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "villani2009optimal",
        "author": "Villani, C{\\'e}dric and others",
        "title": "Optimal transport: old and new"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ma2022barron",
        "author": "Ma, Chao and Wu, Lei and others",
        "title": "The Barron space and the flow-induced function spaces for neural network models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "barron1993universal",
        "author": "Barron, Andrew R",
        "title": "Universal approximation bounds for superpositions of a sigmoidal function"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ma2022barron",
        "author": "Ma, Chao and Wu, Lei and others",
        "title": "The Barron space and the flow-induced function spaces for neural network models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ma2022barron",
        "author": "Ma, Chao and Wu, Lei and others",
        "title": "The Barron space and the flow-induced function spaces for neural network models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ma2022barron",
        "author": "Ma, Chao and Wu, Lei and others",
        "title": "The Barron space and the flow-induced function spaces for neural network models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "li2020complexity",
        "author": "Li, Zhong and Ma, Chao and Wu, Lei",
        "title": "Complexity measures for neural networks with general activation functions using path-based norms"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wojtowytsch2020can",
        "author": "Wojtowytsch, Stephan and Weinan, E",
        "title": "Can shallow neural networks beat the curse of dimensionality? a mean field training perspective"
      },
      {
        "key": "wojtowytsch2020convergence",
        "author": "Wojtowytsch, Stephan",
        "title": "On the convergence of gradient descent training for two-layer relu-networks in the mean field regime"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "barron1993universal",
        "author": "Barron, Andrew R",
        "title": "Universal approximation bounds for superpositions of a sigmoidal function"
      },
      {
        "key": "ma2022barron",
        "author": "Ma, Chao and Wu, Lei and others",
        "title": "The Barron space and the flow-induced function spaces for neural network models"
      },
      {
        "key": "li2020complexity",
        "author": "Li, Zhong and Ma, Chao and Wu, Lei",
        "title": "Complexity measures for neural networks with general activation functions using path-based norms"
      },
      {
        "key": "weinan2022representation",
        "author": "Weinan, E and Wojtowytsch, Stephan",
        "title": "Representation formulas and pointwise properties for Barron functions"
      }
    ]
  }
]