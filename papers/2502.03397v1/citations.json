[
  {
    "index": 0,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan",
        "title": "Constitutional AI: Harmlessness from AI Feedback"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Lee2024RLAIFVR",
        "author": "Harrison Lee and Samrat Phatale and Hassan Mansoor and Thomas Mesnard and Johan Ferret and Kellie Ren Lu and Colton Bishop and Ethan Hall and Victor Carbune and Abhinav Rastogi and Sushant Prakash",
        "title": "{RLAIF} vs. {RLHF}: Scaling Reinforcement Learning from Human Feedback with {AI} Feedback"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "sun2023principledriven",
        "author": "Zhiqing Sun and Yikang Shen and Qinhong Zhou and Hongxin Zhang and Zhenfang Chen and David Daniel Cox and Yiming Yang and Chuang Gan",
        "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ConstitutionMaker-2024",
        "author": "Petridis, Savvas and Wedin, Benjamin D and Wexler, James and Pushkarna, Mahima and Donsbach, Aaron and Goyal, Nitesh and Cai, Carrie J and Terry, Michael",
        "title": "ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen-etal-2024-iteralign",
        "author": "Chen, Xiusi  and\nWen, Hongzhi  and\nNag, Sreyashi  and\nLuo, Chen  and\nYin, Qingyu  and\nLi, Ruirui  and\nLi, Zheng  and\nWang, Wei",
        "title": "{I}ter{A}lign: Iterative Constitutional Alignment of Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "petridis-etal-2024-constitutionalexperts",
        "author": "Petridis, Savvas  and\nWedin, Ben  and\nYuan, Ann  and\nWexler, James  and\nThain, Nithum",
        "title": "{C}onstitutional{E}xperts: Training a Mixture of Principle-based Prompts"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "openai2024openaio1card",
        "author": "Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others",
        "title": "OpenAI o1 System Card"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "guan2025deliberativealignmentreasoningenables",
        "author": "Melody Y. Guan and Manas Joglekar and Eric Wallace and Saachi Jain and Boaz Barak and Alec Helyar and Rachel Dias and Andrea Vallone and Hongyu Ren and Jason Wei and Hyung Won Chung and Sam Toyer and Johannes Heidecke and Alex Beutel and Amelia Glaese",
        "title": "Deliberative Alignment: Reasoning Enables Safer Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "kirk-etal-2023-past",
        "author": "Kirk, Hannah Rose  and\nBean, Andrew M.  and\nVidgen, Bertie  and\nR{\\\"o}ttger, Paul  and\nHale, Scott A.",
        "title": "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "korbak2023pretraining",
        "author": "Korbak, Tomasz and Shi, Kejian and Chen, Angelica and Bhalerao, Rasika Vinayak and Buckley, Christopher and Phang, Jason and Bowman, Samuel R and Perez, Ethan",
        "title": "Pretraining language models with human preferences"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "hancock-etal-2019-learning",
        "author": "Hancock, Braden  and\nBordes, Antoine  and\nMazare, Pierre-Emmanuel  and\nWeston, Jason",
        "title": "Learning from Dialogue after Deployment: Feed Yourself, Chatbot!"
      },
      {
        "key": "liu2024chain",
        "author": "Hao Liu and Carmelo Sferrazza and Pieter Abbeel",
        "title": "Chain of Hindsight aligns Language Models with Feedback"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "stiennon2020learning",
        "author": "Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F",
        "title": "Learning to summarize with human feedback"
      },
      {
        "key": "bai2022traininghelpfulharmlessassistant",
        "author": "Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan",
        "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"
      },
      {
        "key": "bakker2022fine",
        "author": "Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others",
        "title": "Fine-tuning language models to find agreement among humans with diverse preferences"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "liu2022second",
        "author": "Ruibo Liu and Chenyan Jia and Ge Zhang and Ziyu Zhuang and Tony X Liu and Soroush Vosoughi",
        "title": "Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhou2021narle",
        "author": "Ruijie Zhou and Soham Deshmukh and Jeremiah Greer and Charles Lee",
        "title": "NaRLE: Natural Language Models using Reinforcement Learning with Emotion Feedback"
      },
      {
        "key": "korbak2023pretraining",
        "author": "Korbak, Tomasz and Shi, Kejian and Chen, Angelica and Bhalerao, Rasika Vinayak and Buckley, Christopher and Phang, Jason and Bowman, Samuel R and Perez, Ethan",
        "title": "Pretraining language models with human preferences"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "jin2022make",
        "author": "Jin, Zhijing and Levine, Sydney and Gonzalez Adauto, Fernando and Kamal, Ojasv and Sap, Maarten and Sachan, Mrinmaya and Mihalcea, Rada and Tenenbaum, Josh and Sch{\\\"o}lkopf, Bernhard",
        "title": "When to make exceptions: Exploring language models as accounts of human moral judgment"
      },
      {
        "key": "zhao-etal-2021-ethical",
        "author": "Zhao, Jieyu  and\nKhashabi, Daniel  and\nKhot, Tushar  and\nSabharwal, Ashish  and\nChang, Kai-Wei",
        "title": "Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?"
      },
      {
        "key": "askell2021generallanguageassistantlaboratory",
        "author": "Amanda Askell and Yuntao Bai and Anna Chen and Dawn Drain and Deep Ganguli and Tom Henighan and Andy Jones and Nicholas Joseph and Ben Mann and Nova DasSarma and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Jackson Kernion and Kamal Ndousse and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Jared Kaplan",
        "title": "A General Language Assistant as a Laboratory for Alignment"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "Lee2024RLAIFVR",
        "author": "Harrison Lee and Samrat Phatale and Hassan Mansoor and Thomas Mesnard and Johan Ferret and Kellie Ren Lu and Colton Bishop and Ethan Hall and Victor Carbune and Abhinav Rastogi and Sushant Prakash",
        "title": "{RLAIF} vs. {RLHF}: Scaling Reinforcement Learning from Human Feedback with {AI} Feedback"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan",
        "title": "Constitutional AI: Harmlessness from AI Feedback"
      },
      {
        "key": "yang-etal-2022-re3",
        "author": "Yang, Kevin  and\nTian, Yuandong  and\nPeng, Nanyun  and\nKlein, Dan",
        "title": "Re3: Generating Longer Stories With Recursive Reprompting and Revision"
      },
      {
        "key": "Lee2024RLAIFVR",
        "author": "Harrison Lee and Samrat Phatale and Hassan Mansoor and Thomas Mesnard and Johan Ferret and Kellie Ren Lu and Colton Bishop and Ethan Hall and Victor Carbune and Abhinav Rastogi and Sushant Prakash",
        "title": "{RLAIF} vs. {RLHF}: Scaling Reinforcement Learning from Human Feedback with {AI} Feedback"
      },
      {
        "key": "fu-etal-2024-gptscore",
        "author": "Fu, Jinlan  and\nNg, See-Kiong  and\nJiang, Zhengbao  and\nLiu, Pengfei",
        "title": "{GPTS}core: Evaluate as You Desire"
      },
      {
        "key": "cui2024ultrafeedback",
        "author": "Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Bingxiang He and Wei Zhu and Yuan Ni and Guotong Xie and Ruobing Xie and Yankai Lin and Zhiyuan Liu and Maosong Sun",
        "title": "{ULTRAFEEDBACK}: Boosting Language Models with Scaled {AI} Feedback"
      },
      {
        "key": "madaan2023selfrefine",
        "author": "Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback"
      }
    ]
  }
]