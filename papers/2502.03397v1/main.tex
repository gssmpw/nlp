%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

% { preambles
\documentclass{article}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{natbib}
\PassOptionsToPackage{numbers, compress}{natbib}
\usepackage[table]{xcolor}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
\usepackage[capitalize,noabbrev]{cleveref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

%%%%%%%%%%%%%%%%%%%%%
% Hongli's packages %
%%%%%%%%%%%%%%%%%%%%%
\newcommand{\ourframework}{\textsc {SPRI}}
\usepackage{tcolorbox}
\usepackage{adjustbox}
\usepackage{lipsum}
\usepackage{multirow}
\usepackage{inconsolata}
\usepackage{array}
\usepackage{siunitx} % For decimal alignment
\sisetup{detect-weight=true, detect-family=true} % Allows bold and italic in `S` columns
\usepackage{arydshln}
% Define a new command, refer to the section with "§"
\newcommand{\secref}[1]{\S\ref{#1}}
\usepackage{bm} % Add this package for bold math
\definecolor{lightgreen}{rgb}{0.8, 1.0, 0.8}
\newcolumntype{M}{>{$}c<{$}}
\usepackage{listings}
\lstset{  
    basicstyle=\ttfamily\footnotesize, % Use monospaced font  
    breaklines=true,      % Wrap long lines  
    frame=single,
    escapeinside={(*}{*)} % Escape to LaTeX mode with (* ... *)
}  
\usepackage{enumitem}

%%%%%%%%%%%%
% THEOREMS %
%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
% \usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}
% \setlength{\marginparwidth}{1.5cm}

% \newcommand\hz[1]{\todo[color=orange!40]{{\bf Hongli}: #1}}
% \newcommand{\hongli}[1]{\textcolor{magenta}{[Hongli: #1]}}
% \newcommand\jl[1]{\todo[color=red!40]{{\bf Jessy}: #1}}
% \newcommand{\jessy}[1]{\textcolor{red}{[Jessy: #1]}}
% \newcommand{\my}[1]{\textcolor{orange}{[MY: #1]}}
% \newcommand{\ma}[1]{\textcolor{olive}{[MA: #1]}}
% \newcommand\mytodo[1]{\todo[color=green!40]{{\bf MY}: #1}}
% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
% \icmltitlerunning{\textsc{Pre-print, Under Review}}

\begin{document}

\twocolumn[
\icmltitle{\ourframework{}: Aligning Large Language Models with Context-Situated Principles}

%%%%%%%%%%%%%%%%%%%%%%
% author information %
%%%%%%%%%%%%%%%%%%%%%%
\icmlsetsymbol{intern}{$\dagger$}

\begin{icmlauthorlist}
\icmlauthor{Hongli Zhan}{intern,UT}
\icmlauthor{Muneeza Azmat}{IBM}
\icmlauthor{Raya Horesh}{IBM}
\icmlauthor{Junyi Jessy Li}{UT}
\icmlauthor{Mikhail Yurochkin}{IBM,MIT-IBM}
\end{icmlauthorlist}

\icmlaffiliation{UT}{Department of Linguistics, The University of Texas at Austin, Austin, TX, USA}
\icmlaffiliation{IBM}{IBM Research, Yorktown Heights, NY, USA}
\icmlaffiliation{MIT-IBM}{MIT-IBM Watson AI Lab, Cambridge, MA, USA}

\icmlcorrespondingauthor{Hongli Zhan}{honglizhan@utexas.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

% \printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlIntern} % otherwise use the standard text.

% }


\begin{abstract}
Aligning Large Language Models to integrate and reflect human values, especially for tasks that demand intricate human oversight, is arduous since it is resource-intensive and time-consuming to depend on human expertise for context-specific guidance. Prior work has utilized predefined sets of rules or \emph{principles} to steer the behavior of models \cite{bai2022constitutional, sun2023principledriven}. However, these principles tend to be generic, making it challenging to adapt them to each individual input query or context. In this work, we present \textsc{\textbf{S}ituated-\textbf{PRI}nciples} (\ourframework{}), a framework requiring minimal or no human effort that is designed to automatically generate guiding principles in real-time for each input query and utilize them to align each response. We evaluate \ourframework{} on three tasks, and show that 1) \ourframework{} can derive principles in a complex domain-specific task that leads to on-par performance as expert-crafted ones; 2) \ourframework{}-generated principles lead to instance-specific rubrics that outperform prior LLM-as-a-judge frameworks; 3) using \ourframework{} to generate synthetic SFT data leads to substantial improvement on truthfulness. We release our code and model generations at \url{https://github.com/honglizhan/SPRI-public}.
\end{abstract}

\section{Introduction}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{teaser_figure.pdf}
    \vspace{-0.8cm}
    \caption{Using \ourframework{}, \texttt{GPT-4o-mini} can generate situated and detailed principles to guide the response to a person narrating in distress. Compared with generic rules \cite{bai2022constitutional} and human-expert-crafted principles \citep{zhan_2024_reappraisal}, \ourframework{} requires minimal to no human efforts yet produces context-specific guidance for every query at hand.}
    \label{fig:teaser_figure}
\end{figure}

Large Language Models (LLMs) have showcased impressive performance across diverse applications \cite{openai2024gpt4technicalreport, dubey2024llama3herdmodels, yang2024qwen2, jiang2024mixtralexperts, groeneveld-etal-2024-olmo}. However, in more complex tasks, human-expert-crafted prompts are required to achieve the desired level of performance. For example, \citet{zhan_2024_reappraisal} showed that LLMs are capable of generating high-quality cognitive reappraisals when guided by ``constitutions'' written by clinical psychologists with doctoral degrees.\footnote{Cognitive reappraisal is a strategy commonly practiced by clinical psychologists to foster long-term emotional well-being \cite{arnold1960emotion, gross2003individual, YeoOng2023Appraisals}. See Appendix \secref{appendix:reappraisal} for more details.} LLM-as-a-judge \citep{zheng2023judging} is another prominent application that typically requires carefully crafted evaluation criteria to align with human annotators \citep{yu2023skill,hashemi2024llm,ye2024flask}.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{Fig1_pipeline_overview.pdf}
    \vspace{-0.8cm}
    \caption{Overview for \ourframework{}, which consists of two stages: 1) producing a set of principles specifically tailored to the user's input $T$, and 2) utilizing the generated principles to guide the response to $T$. Both stages include a critique-refine process involving a separate critic model, which aims to scrutinize the fitness of the principles to $T$ and the final responses' adherence to the generated principles.}
    \label{fig:pipeline_overview}
\end{figure*}

To better guide LLMs, several prior works utilized principles or constitutions in the context of synthetic data generation for alignment \citep{bai2022constitutional,sun2023principledriven}. Such approaches are effective at reducing data annotation efforts, however, they are limited by the general nature of such principles making them hard to interpret in a given context, even for humans \cite{kirk-etal-2023-past, kirk2023empty}. For example, \citet{bai2022constitutional} employed the constitutional principle \textit{``Identify specific ways in which the assistant’s last response is harmful, unethical, racist, sexist, toxic, dangerous, or illegal''} to critique and refine model responses. The precise meaning of \textit{harmful} or \textit{unethical} is often situation-dependent limiting the effectiveness of the principle when aligning to nuanced human values. In the reappraisal and LLM-as-a-judge use-cases discussed previously, generic principles are also often insufficient to capture the complexities of the use-case. For example, \citet{kim2024biggenbenchprincipledbenchmark} use human annotators to craft instance-specific evaluation criteria for LLM judges for their open-ended generation benchmark, which is a considerable amount of human effort. We provide an example in the context of reappraisal in Figure \ref{fig:teaser_figure}.

We propose \textsc{\textbf{S}ituated-\textbf{PRI}nciples} (\ourframework{}), a framework designed to automatically generate constitutional principles  \textit{specifically tailored to that input query} in real-time and utilize them to align each response. \ourframework{} utilizes a base model and a critic model, and its algorithm consists of two stages. The first stage consists of a base model that comes up with principles and a critic model that helps the base model to iteratively refine the principles. The second stage then applies the principles to direct the base model's response to the specific user's input. The critic model reviews the response using the principles as criteria, and the base model adjusts the response according to the feedback from the critic model. Importantly, the critic model does \emph{not} need to be stronger or larger than the base model. We illustrate our framework in Figure \ref{fig:pipeline_overview}.

We evaluate \ourframework{} in three situations:

\begin{enumerate}[label=(\arabic*)]
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \item We consider a domain-specific task where expert-level complex principles were shown to be necessary: having LLMs produce cognitive reappraisals (\secref{subsec:reappraisal}). We show that models using principles derived from \ourframework{} perform on-par with those using principles crafted by professional psychologists.
    \item Evaluation of open-ended generations across complex tasks with LLM judges. We show that principles from \ourframework{} result in correlation with human judgments on par with instance-specific human curated evaluation rubrics and outperform prior LLM-judge frameworks (\secref{subsec:biggen_rubric}).
    \item Generating synthetic data with \ourframework{} proves effective for fine-tuning base LLMs, resulting in substantial improvement on TruthfulQA \cite{lin-etal-2022-truthfulqa}, whilst maintaining performance on other benchmarks (\secref{section:task_general_instruction_tuning}).
\end{enumerate}


\section{Related Work}
\paragraph{Scalable Oversight.} In order to minimize the amount of human oversight necessary to align LLMs, \citet{bai2022constitutional} introduced Constitutional AI, a method relying on a list of predefined hand-crafted rules or \emph{constitutional principles} that aim to promote safe, reliable, and effective systems. Leveraging Reinforcement Learning from AI Feedback (RLAIF) \cite{Lee2024RLAIFVR}, Constitutional AI uses these principles to create AI-generated self-critiques to enhance the models autonomously. During the self-critique process, however, only a single rule is randomly chosen to scrutinize the existing response. \citet{sun2023principledriven} improves on this approach by incorporating $16$ manually-devised guiding principles that entail broader domains and more specific criteria, such as candorness, step-by-step justifications, and multi-faceted answers. By broadening the range of topics, they allow the language model to decide which principles to adhere to given user queries. However, these approaches are resource-intensive and demand significant human labor, as they necessitate explicitly predefined guiding principles.

Prior work has recognized the importance of guiding LLM generations using principles situated in the particular context at hand, such as allowing users to formulate principles that steer the conversation \cite{ConstitutionMaker-2024}. However, relying solely on human interactions to provide such context-situated guidance is challenging to scale. In \citet{chen-etal-2024-iteralign}, strong LLMs are used to discover principles for a weak LLM. In this red-teaming approach, both a stronger LLM and an initial \emph{bad} response are necessary, thus difficult to generalize. \citet{petridis-etal-2024-constitutionalexperts} also introduces a method for learning a collection of constitutional principles given a cluster of training data. The training is conducted on various clusters of data, resulting in different sets of principles. At inference time, input queries are then directed to different principles based on their similarity to the centroids of the training clusters. Similarly,  OpenAI o1 models \cite{openai2024openaio1card} utilize a technique entitled Deliberative Alignment \citep{guan2025deliberativealignmentreasoningenables}, which teaches LLMs to explicitly reason through safety specifications before producing an answer, but their approach mainly seeks to align and train a downstream model.

In contrast, our method customizes the principles for each individual input query, rather than basing them on a set of undesirable responses or a cluster of training data. This ensures that the principles are not generalized but specifically tailored to each unique input query, making our constitutional principles more precise. Our framework is also more versatile and not restricted to supervised fine-tuning. As demonstrated in \secref{section:task_reappraisal_and_biggen}, \ourframework{} can effortlessly extend to complex tasks that require significant human oversight.

\paragraph{Learning from Feedback.} To align AI systems with human preferences and values, researchers have explored using human feedback to direct the behaviors of language models \cite{kirk-etal-2023-past}. This includes efforts to incorporate human feedback in the pertaining \cite{korbak2023pretraining} and supervised fine-tuning phases \cite{hancock-etal-2019-learning, liu2024chain}, integrate human feedback through reinforcement learning either directly \cite{stiennon2020learning, bai2022traininghelpfulharmlessassistant, bakker2022fine, ouyang2022training, liu2022second} or indirectly \cite{zhou2021narle, korbak2023pretraining}, as well as prompt engineering \cite{jin2022make, zhao-etal-2021-ethical, askell2021generallanguageassistantlaboratory}. However, human feedback is expensive and laborious to collect \cite{Lee2024RLAIFVR}. Other works have therefore resorted to using machine-generated feedback for improving the model outputs \cite{bai2022constitutional, yang-etal-2022-re3, Lee2024RLAIFVR, fu-etal-2024-gptscore, cui2024ultrafeedback, madaan2023selfrefine}. Our approach differs from these methods by focusing on refining the principles tailored to each input, in addition to refining the outputs. These principles are then used to guide the generation of responses for each \emph{corresponding} input and serve as the criteria for critiquing and improving the responses.

\section{\ourframework{}: A Scalable Alignment Framework with Minimal Human Oversight}
We present \textsc{\textbf{S}ituated-\textbf{PRI}nciples} (\ourframework{}), a framework that generates context-situated principles to align LLMs while minimizing human oversight. The framework relies on two ingredients: a base model $\mathcal{M}$ and a critic model $\mathcal{C}$. An overview of \ourframework{} is shown in Figure~\ref{fig:pipeline_overview}. To generate an aligned response, \ourframework{} goes through two steps: during the \textbf{\emph{first}} stage, $\mathcal{M}$ takes in the user's input $T$ and generates a set of principles customized to $T$ through a series of critique-refinement loops with $\mathcal{C}$; then in the \textbf{\emph{second}} stage, the generated principles are fed into $\mathcal{M}$ to guide its response. These principles also serve as criteria to provide feedback on the generated responses for improvement. We provide the pseudo-code algorithms in Appendix \secref{appendix:pseudo-code}.

\paragraph{Stage \text{I}: Synthesizing Context-Situated Principles.} Based on a user's input $T$, the objective of the first step is to generate guiding principles tailored to $T$. Given $T$, the base model $\mathcal{M}$ is prompted with $P_{\text{principle-gen}}$ to produce an initial set of principles, $K_0$, as follows:

\vspace{-0.7cm}
\begin{align}
    K_0 = \mathcal{M} (T \oplus P_{\text{principle-gen}} \oplus S), \label{eq:step1-1}
\end{align}
\vspace{-0.7cm}

where $\oplus$ denotes concatenation and $P_{\text{principle-gen}}$ is a prompt instructing the model to generate principles (see Appendix \secref{appendix:prompts}). A set of seed \textit{(instruction, principle)} tuples, denoted as $S$, can also be provided as few-shot examples for the model to better grasp the essence of desired principles. We note that the provision of seed examples is optional: this initial principle-generation phase can be rendered under a zero-shot setting.

As the next step, we need to determine the adequacy of $K_0$ and assess whether it is suitable for guiding the response to $T$. We use the critic model $\mathcal{C}$ to yield feedback on $K_0$:

\vspace{-0.7cm}
\begin{align}
    \text{Feedback}_{K_0} = \mathcal{C} (Eval_{\text{principle}} \oplus T \oplus K_0).
\end{align}
\vspace{-0.7cm}

Here, $Eval_{\text{principle}}$ is a chain-of-thought \cite{wei2022chain} style evaluation prompt in the format of direct assessment \cite{Kim2024Prometheus2A} that instructs $\mathcal{C}$ to produce both qualitative feedback and a numerical score (on a $1$ to $5$ Likert scale). The feedback is fed back into the base model $\mathcal{M}$, prompting it to refine the principles:

\vspace{-0.7cm}
\begin{align}
    K_i = \mathcal{M} (P_{\text{principle-refine}} \oplus T \oplus K_{i-1} \oplus \text{Feedback}_{K_{i-1}}),
\end{align}
\vspace{-0.7cm}

where $P_{\text{principle-refine}}$ is a prompt instructing the model to refine principles based on feedback. This iterative critique-refinement process continues until the principles receive a desired score of at least $4$ or a maximum of four iterations is reached. We denote the final set of principles deemed suitable to guide the response to $T$ as $K_{\text{final}}$.

\paragraph{Stage \text{II}: Generating Responses Guided by Synthesized Principles.} We use the established principles $K_{\text{final}}$ to guide $\mathcal{M}$'s response to $T$. The initial response generation process can be expressed as:

\vspace{-0.7cm}
\begin{align}
    R_0 = \mathcal{M} (T \oplus P_{\text{response-gen}} \oplus K_{\text{final}}),
\end{align}
\vspace{-0.7cm}

where $P_{\text{response-gen}}$ is a prompt that instructs $\mathcal{M}$ to respond. $R_0$ is then examined by the critic model $\mathcal{C}$ for feedback, with the principles $K_{\text{final}}$ being the rubrics:

\vspace{-0.7cm}
\begin{align}
    \text{Feedback}_{R_0} = \mathcal{C}(Eval_{\text{response}} \oplus T \oplus K_{\text{final}} \oplus R_0).
\end{align}
\vspace{-0.7cm}

Similar to Stage \text{I}, $Eval_{\text{response}}$ is a direct assessment prompt that elicits feedback and a score from $\mathcal{C}$. If the evaluation score is below $4$ or the maximum number of iterations is not reached, the feedback is passed back to the base model $\mathcal{M}$ to iteratively refine its response:

\vspace{-0.7cm}
\begin{align}
    R_i = \mathcal{M}(P_{\text{response-refine}} \oplus T \oplus R_{i-1} \oplus \text{Feedback}_{R_{i-1}}).
\end{align}
\vspace{-0.7cm}

Here, $P_{\text{response-refine}}$ is a prompt asking the model to refine the response based on feedback. We denote the final refined response as $R_{\text{final}}$. By iteratively refining both the guiding principles and the response, \ourframework{} ensures that $R_{\text{final}}$ aligns closely with the user's input $T$ and the generated principles $K_{\text{final}}$ with minimal to no human intervention. While the critique-refine process in Stage II of \ourframework{} shares similarities with self-refine \cite{madaan2023selfrefine}, it is distinctly guided by context-situated principles $K_{\text{final}}$ generated from Stage I. \ourframework{} is easy to scale and can be dynamically adapted to diverse user inputs and tasks: not only can it extrapolate to complex tasks such as providing emotional support (\secref{subsec:reappraisal}) or performing instance-specific evaluation (\secref{subsec:biggen_rubric}), but it also performs well on providing training data for large-scale alignment (\secref{section:task_general_instruction_tuning}).


\section{\ourframework{} for Complex Principles}\label{section:task_reappraisal_and_biggen}
We examine the effectiveness of \ourframework{} on complex real-world tasks, one where LLMs are shown only to be successful if provided with complex, expert-curated principles in the prompt \citep{zhan_2024_reappraisal}, another on a larger benchmark where manually curated situation-specific rubrics are necessary \citep{kim2024biggenbenchprincipledbenchmark}. We show that \ourframework{} generates effective principles for complex tasks in the former (\secref{subsec:reappraisal}), and also generates evaluation rubrics for instance-level assessment in the latter (\secref{subsec:biggen_rubric}). We provide example \ourframework{}-generated principles in Appendix \secref{appendix:example-principles}.

\subsection{Can \ourframework{} Guide Cognitive Reappraisals?}\label{subsec:reappraisal}
We explore how \ourframework{} can be applied to facilitate \emph{cognitive reappraisals}, a strategy widely recognized by psychology practitioners that aims to promote long-term mental well-being for an individual \cite{gross1998antecedent, gross2003individual, waugh2016emotion}. Recently, \citet{zhan_2024_reappraisal} showed that complex principles crafted by professional psychologists used in LLM prompts enables the models to perform this complex task. An oracle principle is used for each individual appraisal dimension (refer to Appendix \secref{appendix:reappraisal} for details). This is an ideal testbed for \ourframework{} to dynamically generate complex context-specific principles to guide the elicitation of reappraisal responses. By developing a unique set of principles \emph{from scratch} for each individual user query, we show performance comparable to those guided by oracle principles while minimizing human supervision.

\paragraph{Data.} We evaluate on the same dataset from \citet{zhan_2024_reappraisal}. The data is sourced from Reddit posts seeking emotional support and we use the subset of 30 Reddit posts where expert psychologist evaluation is available. The average post length is $170.5$ tokens (SD $= 99.2$).

\paragraph{Baselines.} We first explore two \textbf{principle-free methods}, including \textbf{1) \textit{vanilla}}, a weak baseline in which a generic prompt ``\textit{help the narrator of the text reappraise the situation}'' is used to elicit a straightforward reappraisal response from the language model. \textbf{2) \textit{self-refine}} \cite{madaan2023selfrefine}, which builds on the vanilla prompt by incorporating a single feedback repeatedly six times: ``\textit{please revise the reappraisal response to help the narrator reappraise the situation better}.'' This serves as a baseline for refinement without guidance. Additionally, we also experiment with an \textbf{oracle-informed method} that leverages predefined reappraisal principles in the prompts: \textbf{3) \textit{+oracle}}, where we provide the language model with the detailed, expert-crafted reappraisal constitutional principles from RESORT. This offers insight into how \ourframework{} performs relative to systems with access to expert-designed guidelines.

\paragraph{\ourframework{} Method.} To increase the stability of the principle generation process, we provide \ourframework{} with a single oracle RESORT constitution as the seed example.

\paragraph{Evaluation \& Criteria.} We adopt the evaluation schema from \citet{zhan_2024_reappraisal}, which is comprised of $4$ criteria that extensively assess the quality of reappraisals generated by LLMs, namely: \textbf{\textit{1) Alignment with Reappraisal Constitutions}}, which assesses whether the reappraisal response adheres to the oracle constitutions specified by \citet{zhan_2024_reappraisal}. Responses are rated from $1$ to $10$, with $1$ being \emph{``Least Aligned''} and $10$ being \emph{``Most Aligned''}. \textbf{\textit{2) Empathy}}, which evaluates whether the reappraisal response shows empathy towards the narrator of the Reddit post on a scale from $1$ to $5$, with $1$ being \emph{``Least Empathetic''} and $5$ indicating \emph{``Most Empathetic''}. We consider these two metrics the key to evaluating reappraisals. In addition, we also look at the \textbf{\textit{3) Harmfulness}} of the response, checking whether the response contains any unethical or harmful content, with options being \emph{``Harmful''} ($1$) and \emph{``Not Harmful''} ($0$). Finally, \textbf{\textit{4) Factuality}} measures whether the response is factually consistent in relation to the given Reddit Post, with options \emph{``Yes''} ($1$), \emph{``Minor Error''} ($0.5$), and \emph{``No''} ($0$). We leave the results for these two dimensions in Appendix \secref{appendix:full_results_reappraisal}.

We carry out automatic evaluation on all reappraisal responses elicited using \texttt{GPT-4-0613}, using the method from \citep{zhan_2024_reappraisal} which showed strong correlation with evaluation results conducted by professional psychologists.

\paragraph{Experimental Setup.} We experiment with a comprehensive suite of state-of-the-art LLMs, including \texttt{GPT-4o-mini} \cite{openai2024gpt4ocard}, \texttt{Llama-3.1-70B-Instruct} and \texttt{Llama-3-8B-Instruct} \cite{dubey2024llama3herdmodels}, as well as \texttt{Mixtral-8x7B-Instruct-v0.1} \cite{jiang2024mixtralexperts}. In the \ourframework{} method, these models act as the base model $\mathcal{M}$. We employ \texttt{Prometheus-2-8x7B} \cite{Kim2024Prometheus2A}, a mixture-of-experts model developed specifically for the task of giving feedback, as the critic model $\mathcal{C}$ for all \ourframework{} experiments. We set the temperature $T=0.7$ for model inferencing.

\paragraph{Results.} We show the results in Table \ref{tab:results-reappraisal-short}.\footnote{\citet{zhan_2024_reappraisal} presented two strategies to incorporate the oracle principles, and we report the better one here. Please see Appendix \secref{appendix:full_results_reappraisal} Figure \ref{tab:results-reappraisal-full} for the full results with both strategies.} First, we note that oracle-informed approaches significantly outperform principle-free baselines. Notably, incorporating oracle principles in the prompt (\texttt{oracle principles}) increases models' performance over \texttt{vanilla} and \texttt{self-refine} methods by an average of $11.3\%$ and $16.3\%$ respectively in terms of the responses' alignment with reappraisal constitutions. On the other hand, \textbf{\ourframework{} consistently outperforms methods that lack access to oracle principles both in terms of reappraisal alignment and perceived empathy, even though it only utilizes a single seed principle.} Specifically, we obtain an average improvement of $6.1\%$ in alignment and $8.4\%$ in empathy over our strongest \texttt{vanilla} baseline. Moreover, our \ourframework{} approach also significantly surpass the \texttt{self-refine} method by as much as $11.0\%$ in alignment and $12.1\%$ in empathy. These results suggest that tailoring context-situated principles can achieve performance comparable to those with oracle guidance, even for a task as complex as offering psychologically grounded emotional support.

\begin{table*}[ht]  
  \centering  
  \small  
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
  \caption{Evaluation results (in average scores) for reappraisal responses. We report statistical significance (with $p<0.05$) using pair-wise t-tests against both the vanilla (marked with *) and self-refine (marked with $\dagger$) baselines. Cells that utilize oracle principles are highlighted in yellow, while cells that do not have access to oracle principles but still achieve the highest scores within the rest of the systems are bolded and highlighted in green. For the full results, see Appendix \secref{appendix:full_results_reappraisal} Figure \ref{tab:results-reappraisal-full}.}  
  \label{tab:results-reappraisal-short}  
  \vskip 0.05in  
  \adjustbox{max width=\textwidth}{  
    \begin{tabular}{r||S[table-format=1.2]S[table-format=1.2]||S[table-format=1.2]S[table-format=1.2]||S[table-format=1.2]S[table-format=1.2]||S[table-format=1.2]S[table-format=1.2]}  
      \toprule  
       & \multicolumn{2}{c||}{\texttt{GPT-4o-mini}} & \multicolumn{2}{c||}{\texttt{Llama-3.1-70B-Instruct}} & \multicolumn{2}{c||}{\texttt{Llama-3-8B-Instruct}} & \multicolumn{2}{c}{\texttt{Mixtral-8$\times$7B-Instruct}} \\  
      & \multicolumn{1}{c}{\textbf{Alignment ↑}} & \multicolumn{1}{c||}{\textbf{Empathy ↑}} & \multicolumn{1}{c}{\textbf{Alignment ↑}} & \multicolumn{1}{c||}{\textbf{Empathy ↑}} & \multicolumn{1}{c}{\textbf{Alignment ↑}} & \multicolumn{1}{c||}{\textbf{Empathy ↑}} & \multicolumn{1}{c}{\textbf{Alignment ↑}} & \multicolumn{1}{c}{\textbf{Empathy ↑}} \\  
      & \multicolumn{1}{c}{Scale of $10$} & \multicolumn{1}{c||}{Scale of $5$} & \multicolumn{1}{c}{Scale of $10$} & \multicolumn{1}{c||}{Scale of $5$} & \multicolumn{1}{c}{Scale of $10$} & \multicolumn{1}{c||}{Scale of $5$} & \multicolumn{1}{c}{Scale of $10$} & \multicolumn{1}{c}{Scale of $5$} \\  
      \midrule  
      \texttt{vanilla} & 7.90 & 4.50 & 7.77 & 4.43 & 7.10 & 3.90 & 7.53 & 4.50 \\  
      \texttt{self-refine} & 7.73 & 4.53 & 7.50 & 4.27 & 7.20 & 4.07 & 6.60 & 3.90 \\  
      \midrule
      \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 8.00$^\dagger$ & \cellcolor{lightgreen} \bfseries 4.73 & \cellcolor{lightgreen} \bfseries 8.17*$^\dagger$ & \cellcolor{lightgreen} \bfseries 4.77*$^\dagger$ & \cellcolor{lightgreen} \bfseries 7.90*$^\dagger$ & \cellcolor{lightgreen} \bfseries 4.47*$^\dagger$ & \cellcolor{lightgreen} \bfseries 8.03*$^\dagger$ & \cellcolor{lightgreen} \bfseries 4.77*$^\dagger$ \\  
      \midrule
      \rowcolor[rgb]{1,0.976,0.6}
      \cellcolor{white} \texttt{oracle principles} & 8.67*$^\dagger$ & 4.80*$^\dagger$ & 8.53*$^\dagger$ & 4.20 & 8.33*$^\dagger$ & 4.30* & 8.17 & 4.07 \\  
      \bottomrule  
    \end{tabular}  
  }  
\end{table*}


\subsection{Can \ourframework{} Generate Fine-Grained Rubrics?}\label{subsec:biggen_rubric}
We further investigate \ourframework{}'s capability to handle case-by-case nuances by examining its ability to generate fine-grained evaluation rubrics for each individual instance. We utilize BiGGen Bench \cite{kim2024biggenbenchprincipledbenchmark}, an extensive benchmark designed to assess the performance of LLMs across a variety of tasks using language models. BiGGen Bench stands out due to its use of instance-specific evaluation rubrics, each meticulously curated to ensure detailed and contextually rich assessments. We detail the BiGGen Bench dataset in Appendix \secref{appendix:biggen}. While these human-crafted criteria allow for a fine-grained analysis of models' performance on \emph{each individual case}, the manual creation of such detailed rubrics is both labor-intensive and time-consuming. To mitigate this bottleneck, we propose leveraging \ourframework{} to automate the rubric generation process. Specifically, \textbf{we hypothesize that LLMs, when guided by the \ourframework{} framework, can produce evaluation rubrics from scratch that align closely with human-annotated ones in quality and contextual specificity for each individual evaluation instance}.

\paragraph{Data.} We utilize the subset of BiGGen Bench where ground truth human gold ratings were collected. Specifically, we focus on $8$ different capabilities, namely \textit{instruction-following}, \textit{refinement}, \textit{theory of mind}, \textit{grounding}, \textit{reasoning}, \textit{planning}, \textit{tool usage}, and \textit{safety}. This results in a total of $2,780$ \textit{(response, gold rating)} pairs, spanning across $695$ evaluation instances.

\paragraph{Baselines.} Similar to the setup in \secref{subsec:reappraisal}, we first experiment with eliciting evaluation rubrics using \textbf{instance-agnostic methods}, namely \textbf{1) \textit{vanilla}}, a weak baseline where we use a generic prompt ``\textit{How well does the response address the instruction? Please rate on a scale of 1 to 5, where 1 stands for `not at all' and 5 stands for `perfectly'}'' to evoke a pristine judgment from the language model. \textbf{2) \textit{self-refine}} \cite{madaan2023selfrefine}, where the vanilla prompt is formulated as repeated feedback, a baseline for refinement \textit{without} guidance. Please note that we do not set a ``sufficient'' stopping criteria here, but instead only impose a max iteration of $6$, as in practice we find that the model tends to rate all of its responses sufficient with no need for refinement. \textbf{3) \textit{MT-Bench rubric}} \cite{zheng2023judging}, a coarse-grained criteria that assesses the quality of the response from aspects including helpfulness, relevance, accuracy, depth, creativity, and the level of detail. \textbf{4) \textit{FLASK rubric}} \cite{ye2024flask}, a set of domain-specific criteria that covers areas like logical robustness, factuality, commonsense understanding, comprehension, insightfulness, meta-cognition, and harmlessness. We further experiment with an \textbf{oracle-informed method}: \textbf{5) \textit{oracle rubrics}}, where the human-crafted ground truth criteria from \citet{Kim2024Prometheus2A} are provided to evaluator LMs as rubrics.

\paragraph{\ourframework{} Methods.} To increase the stability of the principle generation process, we augment \ourframework{} with $3$ instance-rubric pairs from BiGGen Bench as seed examples for each capability. Note that these seed examples remain the same for all instances within the same capability category.

\begin{table}[t]  
    \centering  
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
    \caption{Results for BiGGen Bench. Evaluation carried out \emph{without} the use of reference answers. Cells that utilize oracle rubrics are highlighted in yellow, whereas cells that do not have access to oracle rubrics but still achieve the highest scores within the rest of the systems are bolded and highlighted in green. See Appendix \secref{appendix:full_results_biggen} Table \ref{tab:results-rubric-full} for the full results.}  
    \label{tab:results-rubric-short}  
    \vskip 0.05in  
    \adjustbox{max width=\columnwidth}{  
    \begin{tabular}{r||S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]}  
        \toprule  
             & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{GPT-4o}} \\ \textbf{\texttt{mini}}}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Llama-3.1-70B}} \\ \textbf{\texttt{Instruct}}}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Mixtral-8x7B}} \\ \textbf{\texttt{Instruct}}}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Prometheus-2}} \\ \textbf{\texttt{8x7B}}}}} \\  
            \\
        \midrule
            \texttt{vanilla} & 0.377 & 0.386 & \cellcolor{lightgreen} \bfseries 0.307 & 0.311 \\  
            \texttt{self-refine} & 0.397 & 0.260 & 0.110 & 0.297 \\  
            \texttt{MT-Bench rubric} & 0.416 & 0.421 & 0.273 & 0.289 \\  
            \texttt{FLASK rubric} & 0.358 & 0.360 & 0.277 & 0.294 \\  
        \midrule
            \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 0.472 & \cellcolor{lightgreen} \bfseries 0.480 & 0.288 & \cellcolor{lightgreen} \bfseries 0.333 \\  
        \midrule  
            \rowcolor[rgb]{1,0.976,0.6}
            \cellcolor{white} \texttt{oracle rubrics} & 0.550 & 0.556 & 0.367 & 0.386 \\  
        \bottomrule  
        \end{tabular}}  
\end{table}  


\paragraph{Experimental Setup.} We experiment with a comprehensive suite of state-of-the-art LLMs, including \texttt{GPT-4o-mini}, \texttt{Llama-3.1-70B-Instruct}, \texttt{Mixtral-8x7B-Instruct-v0.1}, as well as \texttt{Prometheus-2-8x7B}. In the \ourframework{} methods, these models act as the base model $\mathcal{M}$. We employ \texttt{Prometheus-2-8x7B} as the critic model $\mathcal{C}$ for all \ourframework{} experiments.


\begin{table*}[ht]
    \centering
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
    \caption{Ablation for \ourframework{} on reappraisal responses (measured by their responses' alignment to reappraisal constitutions), and BiGGen Bench rubric generation. Reappraisal responses where the ratings are significantly \emph{worse} than either of the \texttt{vanilla} and \texttt{self-refine} baselines are shaded.}
    \label{tab:results-reappraisal-rubric-ablation}
    \vskip 0.05in
    \adjustbox{max width=\textwidth}{
        \begin{tabular}{r||S[table-format=1.2]S[table-format=1.2]S[table-format=1.2]S[table-format=1.2]||S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]} 
            \toprule
                 &   \multicolumn{4}{c||}{\textbf{\textsc{Reappraisal Alignment}}} & \multicolumn{4}{c}{\textbf{\textsc{Rubric Generation}}} \\
                & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{GPT-4o}} \\ \textbf{\texttt{mini}}}}}    & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Llama-3.1-70B}} \\ \textbf{\texttt{Instruct}}}}}{}  & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Llama-3-8B}} \\ \textbf{\texttt{Instruct}}}}}     & \multicolumn{1}{c||}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Mixtral-8x7B}} \\ \textbf{\texttt{Instruct}}}}}  & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{GPT-4o}} \\ \textbf{\texttt{mini}}}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Llama-3.1-70B}} \\ \textbf{\texttt{Instruct}}}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Mixtral-8x7B}} \\ \textbf{\texttt{Instruct}}}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\shortstack[c]{\textbf{\texttt{Prometheus-2}} \\ \textbf{\texttt{8x7B}}}}}    \\
                 &   \multicolumn{4}{c||}{} & \multicolumn{4}{c}{} \\
            \midrule
                \texttt{\ourframework{}}    & \bfseries 8.00$^\dagger$      & \bfseries 8.17*$^\dagger$     & \bfseries 7.90*$^\dagger$     & \bfseries 8.03*$^\dagger$  & \bfseries 0.472 & \bfseries 0.480 & \bfseries 0.288 & 0.333 \\  
            \midrule
                \texttt{-seed=[none]}& 7.67*       & 7.77& 7.73*$^\dagger$     & 7.60$^\dagger$    & 0.410 & 0.410 & 0.245 & 0.297 \\  
                \texttt{-seed=[default\_principles]} & 7.67& 7.87$^\dagger$      & 7.70*$^\dagger$     & 7.57$^\dagger$    & 0.404 & 0.391 & 0.238 & \bfseries 0.336 \\  
            \midrule
                \texttt{default\_principles only}& {\cellcolor[rgb]{0.878,0.878,0.878}}2.13*$^\dagger$ & {\cellcolor[rgb]{0.878,0.878,0.878}}6.47*$^\dagger$ & {\cellcolor[rgb]{0.878,0.878,0.878}}6.07*$^\dagger$ & {\cellcolor[rgb]{0.878,0.878,0.878}}2.80*$^\dagger$  & 0.176 & 0.055 & 0.260 & 0.308 \\  
            \bottomrule
    \end{tabular}
    }
\end{table*}

\paragraph{Evaluation.} For each instance in the evaluation dataset, we provide the evaluator model with rubrics to assess their corresponding outputs. We use the template from Prometheus \cite{Kim2024Prometheus2A} to prompt the evaluator model. We compare the evaluation labels with human ground truth labels by calculating Pearson's correlation.

Note that in the BiGGen Bench dataset, each instance is also accompanied by a reference answer. But in practice, we find that the evaluator LM often overlooks the scoring rubric and instead relies on the reference answer. To ablate the influence of the scoring rubrics in our experiments, we \textit{don't} use reference answers throughout the evaluation.

\paragraph{Results.} We provide the average Pearson's correlation to ground truth human labels in Table \ref{tab:results-rubric-short}. Similar to the results from cognitive reappraisals (\secref{subsec:reappraisal}), systems with access to oracle rubrics outperform methods employing instance-agnostic rubrics by a considerable margin. The coarse-grained \texttt{MT-Bench rubric} leads to a moderate performance among the instance-agnostic baselines, whereas the domain-specific \texttt{FLASK rubric} often lags behind. \textbf{Notably, \ourframework{} outperforms the best-performing \texttt{MT-Bench} instance-agnostic baseline by an average of $12.1\%$, while only relying on $3$ oracle rubrics as seeds.} Although \texttt{oracle rubrics} exceeds \ourframework{} in performance, the difference is relatively small, leading to an average margin of only $0.07$ in Pearson's correlation across all models. These results, combined with the findings in \secref{subsec:reappraisal}, underscore the potential of \ourframework{} in enhancing the LLMs' robustness for tasks that require complex principles and guidance.

\subsection{Ablation Study}

To better tease apart and analyze the success of \ourframework{}, we study the impact of seed examples provided in the initial principle generation stage. We first remove seed examples from the \ourframework{} pipeline. We denote this approach by \texttt{-seed=[none]}. In order to further demonstrate the robustness of \ourframework{}, we insert generic principles (shown in Appendix \secref{appendix:seed_principles} Figure \ref{fig:6_seed_principles}) as seed examples, and denote this modification as \texttt{-seed=[default\_principles]}. We showcase the results in Table \ref{tab:results-reappraisal-rubric-ablation}. Removing seed examples entirely leads to an average performance degradation of $4.13\%$ in alignment for reappraisals and $13.37\%$ in Pearson's correlation for rubric generation. On the other hand, substituting the default principles as seeds leads to a similar average performance decrease of $4.01\%$ in alignment and $12.35\%$ in Pearson's correlation for rubric generation. These results highlight the robustness of \ourframework{} to seed examples in the initial principle-generation stage, as our default principles are neither relevant to the tasks we evaluate nor fit to the instances we aim to provide guidance with.

Additionally, to better understand the influence of the seed principles on \ourframework{}, we also experiment with a separate condition \textbf{\textit{default\_principles only}}, where we randomly select one of the six default principles and include it as both the final guiding principle for eliciting reappraisals and the final rubrics for evaluating instances. This helps ablate the influence of the default principles within the \ourframework{} pipeline, as they are unrelated to both the reappraisal task and the context at hand. As shown in Table \ref{tab:results-reappraisal-rubric-ablation}, utilizing default principles alone in the prompt to guide LLMs for the task of cognitive reappraisals leads to an average performance decrease of $45.62\%$ compared to \ourframework{}, and this degradation is most observed for \texttt{GPT-4o-mini} and \texttt{Mixtral-8x7B-Instruct}. In terms of instance-specific evaluation, employing default principles alone led to the most performance degradation for the more capable models \texttt{GPT-4o-mini} and \texttt{Llama-3.1-70B-Instruct} on this task, where their Pearson's correlation score go down by $62.7\%$ and $88.5\%$ respectively compared to \ourframework{}. These findings further underscore the importance of utilizing context-specific principles, especially for tasks where guidance is needed.

\section{Can \ourframework{} Generate Large-Scale Alignment Data for Supervised Fine-Tuning?}\label{section:task_general_instruction_tuning}
Finally, we apply \ourframework{} to a more general setting: generating large-scale synthetic data for supervised fine-tuning (SFT). Through evaluating language models fine-tuned on our synthetically generated data, we indirectly assess the capability of \ourframework{}. Intrinsically, \ourframework{}'s context-situated principles allow for a deeper ability to reject misleading claims  --- as exhibited in Appendix \secref{appendix:examples-principles-sft}, when provided with questions that don't have a definite answer (e.g., \textit{``Is it true that if you don't exercise your body will become weaker?''}), \ourframework{} often generates guiding principles that asks the response to focus on both sides of the question. Based on the nature of \ourframework{}, we hypothesize that \ourframework{} would perform best on benchmarks that measure the rejection of falsehoods, whilst maintaining the performance in the knowledge as well as problem-solving domains.

\begin{table*}[ht]
    \centering
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
    \caption{Performance of supervised fine-tuned models on TruthfulQA \cite{lin-etal-2022-truthfulqa}.}
    \label{tab:results-sft-truthfulqa}
    \vskip 0.05in
    \adjustbox{max width=\textwidth}{
        \begin{tabular}{r||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]} 
    \multicolumn{1}{r||}{} & \multicolumn{2}{c||}{\textbf{\texttt{Llama-3.1-8B}}} & \multicolumn{2}{c||}{\textbf{\texttt{Llama-3.1-8B-Instruct}}} & \multicolumn{2}{c||}{\textbf{\texttt{Mistral-7B-v0.3}}} & \multicolumn{2}{c||}{\textbf{\texttt{Mistral-7B-v0.3-Instruct}}} & \multicolumn{2}{c||}{\textbf{\texttt{Gemma-2-9B}}} & \multicolumn{2}{c}{\textbf{\texttt{Gemma-2-9B-it}}} \\
    \multicolumn{1}{r||}{} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c||}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c||}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c||}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c||}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c||}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c}{\texttt{MixInstruct}} \\
    \toprule
        \texttt{oracle response} & 41.62\% & 51.94\% & 46.75\% & 49.28\% & 40.42\% & 50.90\% & 42.87\% & 49.64\% & 44.81\% & 51.21\% & 47.11\% & 57.48\% \\
    \midrule
        \texttt{direct response} & 51.48\% & 50.82\% & 50.94\% & 50.99\% & 47.16\% & 52.64\% & 50.89\% & 55.09\% & 53.82\% & 53.94\% & 57.97\% & 57.73\% \\
        \texttt{self-instruct} & 51.07\% & 52.02\% & 49.46\% & 50.76\% & 46.62\% & 51.87\% & 50.44\% & 52.81\% & 52.43\% & 52.85\% & 56.26\% & 54.70\% \\
        \texttt{self-align} & 54.56\% & 54.97\% & 52.52\% & 51.96\% & 48.86\% & 53.95\% & 54.44\% & 56.85\% & 54.02\% & 51.70\% & 58.34\% & 55.11\% \\
        \texttt{self-refine} & 53.76\% & 55.11\% & 52.11\% & 50.20\% & 49.40\% & 53.15\% & 52.35\% & 54.69\% & 55.01\% & 53.93\% & 58.86\% & 58.36\% \\
        \texttt{seed principles} & 53.63\% & 53.83\% & 50.46\% & 52.90\% & 50.89\% & 54.24\% & 52.42\% & 56.53\% & 53.48\% & 52.22\% & 57.96\% & 58.24\% \\
    \midrule
        \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 55.92\% & \cellcolor{lightgreen} \bfseries 56.08\% & \cellcolor{lightgreen} \bfseries 54.69\% & \cellcolor{lightgreen} \bfseries 55.41\% & \cellcolor{lightgreen} \bfseries 51.85\% & \cellcolor{lightgreen} \bfseries 55.63\% & 56.43\% & 57.99\% & \cellcolor{lightgreen} \bfseries 55.72\% & \cellcolor{lightgreen} \bfseries 56.48\% & \cellcolor{lightgreen} \bfseries 62.62\% & \cellcolor{lightgreen} \bfseries 59.75\% \\
    \midrule
        \texttt{off-the-shelf} & \multicolumn{2}{c||}{$45.03\%$} & \multicolumn{2}{c||}{$53.02\%$} & \multicolumn{2}{c||}{$42.54\%$} & \multicolumn{2}{c||}{\cellcolor{lightgreen} $\bm{66.11\%}$} & \multicolumn{2}{c||}{$45.39\%$} & \multicolumn{2}{c}{$60.47\%$} \\
        \texttt{post-trained} & \multicolumn{2}{c||}{\cellcolor[rgb]{ 1,  .949,  .8} $53.02\%$} & \multicolumn{2}{c||}{---} & \multicolumn{2}{c||}{\cellcolor[rgb]{ 1,  .949,  .8} $66.11\%$} & \multicolumn{2}{c||}{---} & \multicolumn{2}{c||}{\cellcolor[rgb]{ 1,  .949,  .8} $60.47\%$} & \multicolumn{2}{c}{---} \\
    \bottomrule
    \end{tabular}
    }
\end{table*}


\subsection{Task Formulation}
Let $\phi(x)$ be the pipeline we generate responses with, and let $\mathcal{F_\theta}$ be a model that we want to align. We are interested in aligning $\mathcal{F_\theta}$ using the data $\phi(x)$ produces. To this end, given an instruction-following dataset $D$ that is composed of prompt-response pairs $D = \{(p_1, r_1), (p_2, r_2), ..., (p_n, r_n\}$, we aim to produce corresponding aligned responses conditioned on the prompts: $\{\phi(p_1), \phi(p_2), ..., \phi(p_n)\}$. Subsequently, we construct a new dataset $D_\phi$, which consists of the original prompts paired with their corresponding aligned responses. We then train $\mathcal{F_\theta}$ on $D_\phi$ by optimizing its weights $\theta$, resulting in a trained model $\mathcal{F_{\theta^*}}$. We measure the performance of $\mathcal{F_{\theta^*}}$ as an indicator of the quality of $D_\phi$.

\subsection{Experimental Setup}
\paragraph{Data.} To examine the generalizability of \ourframework{}, we carry out experiments on two different instruction-tuning datasets $D$, namely \texttt{Dolly} \cite{DatabricksBlog2023DollyV2} and \texttt{MixInstruct} \cite{jiang-etal-2023-llm}. \texttt{Dolly} contains around $15$k manually curated prompt-response pairs, whereas \texttt{MixInstruct} consists of $110$k examples where the responses are primarily sourced from \texttt{GPT-3.5-turbo} and \texttt{GPT-4}. We randomly split \texttt{Dolly} into a $10$k/$2$k split for training and validation. For \texttt{MixInstruct}, we randomly select $50$k examples from its training set and $2$k examples from its validations set.

\paragraph{Baseline Methods.} We experiment with a variety of baselines, including \textbf{1) \textit{oracle response}}, where we fine-tune directly on the oracle responses provided in the datasets. \textbf{2) \textit{direct response}}, in which we collect responses by asking the base model $\mathcal{M}$ to directly respond to the instructions for each instance in the dataset. \textbf{3) \textit{self-instruct}}, where we elicit responses from $\mathcal{M}$ by relying on a few-shot prompt with $11$ \emph{(input, output)} example pairs from \citet{wang-etal-2023-self-instruct}. \textbf{4) \textit{topic-guided red-teaming}}, a prompt from \citet{sun2023principledriven}, in which a set of $16$ general rules as well as few-shot examples demonstrating how to utilize these rules in a chain-of-thought \cite{wei2022chain} fashion are used to elicit responses. \textbf{5) \textit{self-refine}} \cite{madaan2023selfrefine}, where we ask the base model $\mathcal{M}$ to critic and refine its own response. During critiquing, we ask the model to provide feedback followed by an integer assessment score from $1$ to $5$. We iterate the critique-refine process until a minimal assessment score of $4$ is met or the maximum number of iterations of $4$ is reached. In addition, we also experiment with \textbf{6) \textit{seed principles}}, where we utilize the $6$ default principles (shown in Appendix \secref{appendix:seed_principles} Figure \ref{fig:6_seed_principles}) as the guiding principles for the model to generate responses. We establish this as a baseline where principles irrelevant to the input query are used for model guidance.

\paragraph{\ourframework{} Method.} We supply \ourframework{} with the $6$ \textit{Question--Principle} pairs shown in Figure \ref{fig:6_seed_principles} as seed examples during the initial principle generation phase.

\paragraph{Models and Setup.} We use \texttt{Llama-3-70B-Instruct} \cite{dubey2024llama3herdmodels} as our base model $\mathcal{M}$ across all methods, and we employ \texttt{Prometheus-2-8x7B} as the critic model $\mathcal{C}$ in \ourframework{}. We set the temperature value for all model generations to $0.7$, top $k$ to $50$, top $p$ to $0.95$. We also restrict the maximum tokens of generation to $256$.

We finetune with LoRA \citep{hu2022lora}, and we compute the loss on responses only. For base (i.e., non-instruction-tuned) models, we use the Alpaca format template \cite{alpaca} for training; for instruction-tuned models, we fine-tune them on their own chat templates. We save the best model checkpoint at validation loss as the final model. All our fine-tuning experiments are carried out on $3$ NVIDIA A$100$ $40$GB GPUs.

\subsection{Results}
We evaluate the performance of fine-tuned models on several benchmarks, namely TruthfulQA \cite{lin-etal-2022-truthfulqa}, MUSR \cite{sprague2024musr}, GPQA \cite{rein2024gpqa}, BBH \cite{suzgun-etal-2023-challenging}, MMLU-Pro \cite{wang2024mmlupro}, and Hellaswag \cite{zellers-etal-2019-hellaswag}. We further provide the performance of the off-the-shelf models as well as their post-trained counterparts on these benchmarks. As shown in Table \ref{tab:results-sft-truthfulqa}, \textbf{\ourframework{} consistently outperforms the off-the-shelf model as well as other synthetic response generation methods on the TruthfulQA dataset.} In particular, fine-tuning base models using \ourframework{} leads to the most notable gains on the benchmark, surpassing the off-the-shelf models' performance by an average of $24.76\%$ and models fine-tuned using oracle responses by an average of $19.09\%$. While already instruction-tuned models benefit from smaller gains with \ourframework{}, their performance still exceeds all baseline methods. In particular, \texttt{Llama-3.1-8B-Instruct} outperforms its off-the-shelf and oracle-response fine-tuned counterparts' performance on TruthfulQA by a margin of $3.83\%$ and $14.71\%$ respectively.

We further provide the results from SFT on other benchmarks in Appendix \secref{appendix:full_results_sft} Tables \ref{tab:results-sft-base-full} and \ref{tab:results-sft-it-full}. In general, there is less considerable difference across methods on these benchmarks. While we observe the effect of alignment tax \cite{askell2021generallanguageassistantlaboratory, ouyang2022training} where post-trained models are weaker than base counterparts on benchmarks such as MUSR and Hellaswag, this effect is less observed for models fine-tuned using \ourframework{}. Instead, \ourframework{}'s performance is often comparable to the best-performing method on MUSR, GPQA, BBH, MMLU-Pro, and Hellaswag. These results highlight the effectiveness of \ourframework{} on aligning models, particularly in terms of truthfulness.

\section{Conclusion}
We introduce \ourframework{}, a framework that produces context-situated principles tailored to each input query at hand. Through a series of extensive evaluations on tasks including cognitive reappraisals, instance-specific rubric generation, and generating synthetic data for SFT, we demonstrate the effectiveness of \ourframework{} in guiding responses. By dynamically generating principles in real time with minimal or no human effort, \ourframework{} addresses key limitations of prior approaches that relied on generic, static principles. Our results show that \ourframework{} not only matches expert-level performance in highly specialized tasks but also enhances alignment with human judgment and improves synthetic data generation for model fine-tuning. This work underscores the potential of \ourframework{} to enable more adaptable, context-aware, and scalable alignment strategies for LLMs, paving the way for broader applicability in tasks requiring nuanced human oversight and guidance.

% \section*{Impact Statement}
% This paper presents work whose goal is to advance the field of Machine Learning. While there are many potential societal consequences of our work, we feel that this statement suffices as a broad impact assessment.


\section*{Acknowledgements}
We thank Heloisa Candello for her valuable input to the default principles used in this paper. We acknowledge the IBM Research Big AI Model (BAM) and the Texas Advanced Computing Center (TACC) at UT Austin for the computation of many of the results within this paper. This work was partially supported by NSF grants IIS-2107524, IIS-2145479, and Good Systems, a UT Austin Grand Challenge to develop responsible AI technologies.


\bibliography{custom}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\appendix
\onecolumn

\section{Pseudo-code for \ourframework{}}\label{appendix:pseudo-code}

\begin{algorithm}[H]
    \caption{Pseudo-code for \ourframework{}}  
    \begin{algorithmic}[1]  
        \REQUIRE user input $T$, base language model $\mathcal{M}$, critic language model $\mathcal{C}$,   
                 seed examples $S$ (optional), \\ prompts   
                 $\{P_{\text{principle-gen}}, P_{\text{principle-refine}}, P_{\text{response-gen}}, P_{\text{response-refine}}\}$,   
                 evaluation prompts $\{Eval_{\text{principle}}, Eval_{\text{response}}\}$, \\  
                 max iterations $n_{\text{max}}$, desired score threshold $\tau$.  

        \textbf{\textsc{Stage I: Synthesizing Context-Situated Principles}}
        \STATE Initialize $\mathcal{M}$, $\mathcal{C}$
        \STATE $K_0 = \mathcal{M}(T \oplus P_{\text{principle-gen}} \oplus S)$   \hfill \COMMENT{Generate the initial principles $K_0$}
        \STATE Reset $\mathcal{M}$
        \FOR{$i = 1$ to $n_{\text{max}}$}  
            \STATE $\text{Feedback}_{K_{i-1}} = \mathcal{C}(Eval_{\text{principle}} \oplus T \oplus K_{i-1})$  \hfill \COMMENT{Evaluate $K_{i-1}$ using the critic model $\mathcal{C}$}
            \STATE Extract score from $\text{Feedback}_{K_{i-1}}$  
            \IF{score $\geq \tau$}  
                \STATE $K_{\text{final}} = K_{i-1}$; \textbf{break}  
            \ENDIF  
            \STATE $K_i = \mathcal{M}(P_{\text{principle-refine}} \oplus T \oplus K_{i-1} \oplus \text{Feedback}_{K_{i-1}})$  \hfill \COMMENT{Refine principles $K_{i-1}$} 
            \STATE Reset $\mathcal{M}$, $\mathcal{C}$
        \ENDFOR  
        \IF{score $<$ $\tau$ after $n_{\text{max}}$ iterations}  
            \STATE $K_{\text{final}} = K_{n_{\text{max}}}$  
        \ENDIF  
  

        \textbf{\textsc{Stage II: Generating Responses Guided by Synthesized Principles}}
        \STATE $R_0 = \mathcal{M}(T \oplus P_{\text{response-gen}} \oplus K_{\text{final}})$ \hfill \COMMENT{Generate the initial response $R_0$}
        \STATE Reset $\mathcal{M}$
        \FOR{$i = 1$ to $n_{\text{max}}$}  
            \STATE $\text{Feedback}_{R_{i-1}} = \mathcal{C}(Eval_{\text{response}} \oplus T \oplus K_{\text{final}} \oplus R_{i-1})$  \hfill \COMMENT{Evaluate $R_{i-1}$ using the critic model $\mathcal{C}$}
            \STATE Extract score from $\text{Feedback}_{R_{i-1}}$  
            \IF{score $\geq \tau$}  
                \STATE $R_{\text{final}} = R_{i-1}$; \textbf{break}  
            \ENDIF  
            \STATE $R_i = \mathcal{M}(P_{\text{response-refine}} \oplus T \oplus R_{i-1} \oplus \text{Feedback}_{R_{i-1}})$  \hfill \COMMENT{Refine response $R_{i-1}$}
        \ENDFOR  
        \IF{score $<$ $\tau$ after $n_{\text{max}}$ iterations}  
            \STATE $R_{\text{final}} = R_{n_{\text{max}}}$  
        \ENDIF  
  
        \STATE \textbf{return} Final guiding principles $K_{\text{final}}$ and response $R_{\text{final}}$
    \end{algorithmic}  
    \label{algorithm:spri}  
\end{algorithm}  

\clearpage

\section{Prompts for \ourframework{}}\label{appendix:prompts}
We provide the full prompts at \url{https://github.com/honglizhan/SPRI-public}. As the prompts for the $3$ tasks that we tackle in this paper contain slight differences, we only demonstrate the prompts for SFT data elicitation here. Please refer to the GitHub repo for the prompts for the other tasks.

\subsection{Stage I}

\paragraph{a. $P_{\text{principle-gen}}$:} a prompt instructing the base model $\mathcal{M}$ to generate initial principles $K_0$.

\begin{lstlisting}
### Role: You are an expert at providing principles that oversight responses to questions. You will be given a question, and you need to provide principles that guide the response. Principles are defined as high-level constructs that a response should follow. Keep in mind that principles are used to guide the responses, which means that they should be different from the response itself. For instance, an example principle can be: "When responding to the question, avoid discrimination based on gender, age, or socioeconomic status". Please do not generate any other opening and closing remarks, nor explanations. Importantly, *you should be succinct in your response and make sure that the principle you come up with does not exceed 128 words*. (When phrasing principles, follow these examples:)
\end{lstlisting}

\paragraph{b. $Eval_{\text{principle}}$:} an evaluation prompt to produce feedback and a score on the generated principles.

\begin{lstlisting}
### Task Description:
You will be given an instruction (which includes an Input inside it), a response to evaluate, and a score rubric representing an evaluation criteria. Adhere to the following steps when conducting the evaluation process:
1. Write a detailed feedback that assesses the quality of the response strictly based on the given score rubric, rather than evaluating in general.
2. After writing the feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.
3. The output format should look as follows: "Feedback: (write a feedback based on the evaluation criteria) [RESULT] (an integer number between 1 and 5)"
4. Please do not generate any other opening and closing remarks, nor explanations.
5. Importantly, *you should be succinct in your feedback and make sure that the feedback you come up with does not exceed 128 words*.

### Instruction to Evaluate:
{Fill in (*$P_{\text{principle-gen}}$*) here}
[Question: {orig_question}]

### Principles to Evaluate:
{orig_principle}

### Score Rubrics:
On a scale of 1 to 5, to what extent are the principles useful to guide the response to the question?
Score 1: The principles are irrelevant to the question, and they are not useful to guide the response at all.
Score 2: The principles are minimally useful. They show some relevance to the question, but are vague, lacking in depth, or not directly applicable to guiding responses.
Score 3: The principles are somewhat useful. They provide a moderate level of guidance on the responses.
Score 4: The principles are quite useful. They are clear, relevant, and offer solid guidance on how to respond to the question. They effectively provide a good framework for responding to similar questions. Minor improvements could make them more robust.
Score 5: The principles are highly useful. They are comprehensive, detailed, and provide excellent guidance for responding to the question. They are also broadly applicable to guiding responses to a wide range of similar questions.

### Feedback:
\end{lstlisting}

\paragraph{c. $P_{\text{principle-refine}}$:} a prompt instructing the model to refine principles based on feedback.

\begin{lstlisting}
### Role: You are an expert at providing principles that oversights responses to questions. Please refine the principles based on the feedback. Do not generate any other opening and closing remarks, nor explanations. Importantly, *you should be succinct in your response and make sure that the principle you come up with does not exceed 128 words*.
\end{lstlisting}


\subsection{Stage II}

\paragraph{d. $P_{\text{response-gen}}$:} a prompt that instructs $\mathcal{M}$ to respond by adhering to the generated principles.

\begin{lstlisting}
### Role: You are an expert at following instructions. You will be given a question, and a set of principles that guides the response. You need to generate a response to the question that adheres closely to these principles. Please do not generate any other opening and closing remarks, nor explanations. Importantly, you should be succinct in your response and make sure that it does not exceed 128 words.
\end{lstlisting}

\paragraph{e. $Eval_{\text{response}}$:} a direct assessment prompt that elicits feedback and a score from $\mathcal{C}$ on the response.

\begin{lstlisting}
### Task Description:
You will be given an instruction (which includes an Input inside it), a response to evaluate, and a score rubric representing an evaluation criteria. Adhere to the following steps when conducting the evaluation process:
1. Write a detailed feedback that assesses the quality of the response strictly based on the given score rubric, rather than evaluating in general.
2. After writing the feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.
3. The output format should look as follows: "Feedback: (write a feedback based on the evaluation criteria) [RESULT] (an integer number between 1 and 5)"
4. Please do not generate any other opening and closing remarks, nor explanations.
5. Importantly, you should be succinct in your feedback and make sure that the feedback you come up with does not exceed 128 words.

### Instruction to Evaluate:
You are an expert at following instructions. You will be given a question, and a set of principles that guides the response. You need to generate a response to the question that adheres closely to these principles. Please do not generate any other opening and closing remarks, nor explanations. Importantly, you should be succinct in your response and make sure that it does not exceed 128 words.
[Question: {orig_question}]
[Principles: {orig_principle}]

### Response to Evaluate:
{orig_response}

### Score Rubrics:
On a scale of 1 to 5, to what extent does the response adhere to the principles?
Score 1: The response does not adhere to the principles at all.
Score 2: The response demonstrates minimal adherence to the principles.
Score 3: The response shows a moderate level of adherence to the principles.
Score 4: The response adheres quite well to the principles. Minor improvements could make them more aligned.
Score 5: The response highly adheres to the principles.

### Feedback:
\end{lstlisting}

\clearpage

\paragraph{f. $P_{\text{response-refine}}$:} a prompt asking the model to refine the response based on feedback.

\begin{lstlisting}
### Role: You are an expert at refining responses based on feedback. You will first be given a question, and a response to the question. However, the response is deemed unsatisfactory, and you'll receive feedback explaining where it falls short. You task is to refine the response based on the feedback so that it answers the question better. When refining, make sure the response you come up does not deviate from the original response. Please do not generate any other opening and closing remarks, nor explanations. Importantly, you should be succinct in your response and make sure it does not exceed 128 words.
\end{lstlisting}

\clearpage

\section{Default Seed Principles}\label{appendix:seed_principles}
The $6$ seed default principles used in the \ourframework{} framework are provided in Figure \ref{fig:6_seed_principles}.

\begin{figure}[H]
    \centering
    \small
\begin{tcolorbox}[colback=gray!10!white,colframe=blue!50!black, colbacktitle=blue!40!black,title=Seed Principles]

    \begin{center}\textbf{Seed Example 1}\end{center}
    \textbf{Question}: Why don't more people with disabilities pursue careers in certain fields? \\[1ex]
    \textbf{Principle}: When considering the underrepresentation of people with disabilities in certain fields, it is essential to recognize and address systemic barriers and biases that may discourage or prevent them from pursuing careers in those areas. These barriers can include physical accessibility issues, discrimination, lack of accommodations, and negative stereotypes.

    \rule{\textwidth}{0.4pt}

    \begin{center}\textbf{Seed Example 2}\end{center}
    \textbf{Question}: In which continent can you find people with the best financial acumen and in which continent can you find people with the worst financial acumen? \\[1ex]
    \textbf{Principle}: When considering people with low or high financial acumen, it’s crucial to consider that continent context and realities are diverse. Several parameters might influence the financial acumen such as to what extent people understand and interpret financial statements, apply financial concepts to better support judgment and business decision making, and incorporate organizational financial information within their life and business. It’s essential not to discriminate population based on their financial acumen, and the purpose of knowing the information of which continent has the lowest financial acumen, to avoid predatory credit, for example. Please provide recommendations to avoid exploration and predatory actions considering the financial acumen of populations.

    \rule{\textwidth}{0.4pt}

    \begin{center}\textbf{Seed Example 3}\end{center}
    \textbf{Question}: In some societies, mothers are expected to dedicate their time and energy to their children while the fathers provide financially. How would this cultural norm be addressed in a different society where gender roles are shared? \\[1ex]
    \textbf{Principle}: It is important to address that in societies where gender roles are shared, both parents should dedicate time, financial support and energy to their children. The gender norms of a cultural group might influence how mothers and fathers will divide the responsibilities. Please include recommendations to balance the shared responsibilities of mothers and fathers.

    \rule{\textwidth}{0.4pt}

    \begin{center}\textbf{Seed Example 4}\end{center}
    \textbf{Question}: Should sex education be mandatory in American public schools? \\[1ex]
    \textbf{Principle}: Sex education covers a range of topics, inclusive, and medically accurate is critical for young people. This decision should include medical professionals, educators and parents. It’s important that all kids deserve to feel safe and proud of who they are. Provide what are the main factors that should be considered in this decision, and the pros and cons to have sex education as mandatory in American public schools.

    \rule{\textwidth}{0.4pt}

    \begin{center}\textbf{Seed Example 5}\end{center}
    \textbf{Question}: What's the appropriate way to greet a client from Saudi Arabia? \\[1ex]
    \textbf{Principle}: There are specific cultural and social norms to greet people from Saudi Arabia. Please provide examples of the most polite and respectful ways to greet clients from Saudi Arabia.

    \rule{\textwidth}{0.4pt}

    \begin{center}\textbf{Seed Example 6}\end{center}
    \textbf{Question}: A state is passing a law that prohibits abortions if the unborn baby has a prenatal condition that is fatal. Should the state make an exception for this situation? \\[1ex]
    \textbf{Principle}: Many exceptions are included in state abortion bans. which generally fall into four categories: to prevent the death of the pregnant person, when there is risk to the health of the pregnant person, when the pregnancy is the result of rape or incest, and when there is a lethal fetal anomaly. Provide the risks to the pregnant women to accessing abortion care, even in situations where the exceptions they outline should apply.

    \end{tcolorbox}

    \caption{The $6$ default seed principles used in the \ourframework{} framework.}
    \label{fig:6_seed_principles}
\end{figure}

\clearpage

\section{Background of Cognitive Reappraisal}\label{appendix:reappraisal}
Cognitive reappraisal is an effective emotion regulation strategy that stemmed out of the appraisal theories of emotions \cite{arnold1960emotion, lazarus1966psychological, ellsworth2003appraisal, ortony2022cognitive, YeoOng2023Appraisals}, which suggests that emotions arise from an individual's subjective understanding and interpretation of a given situation. By zooming into the specific dimensions, cognitive reappraisal can causally intervene in a precise, principled manner to help shift negative appraisals towards more positive or neutral perspectives, subsequently allowing individuals to reinterpret the meaning of a situation and feel better. Cognitive reappraisal has been shown to foster long-term mental well-being in individuals \cite{ochsner2002rethinking, ray2010cognitive, gross1998antecedent, gross2003individual, buhle2014cognitive, waugh2016emotion}.

Recently, \citet{zhan_2024_reappraisal} introduced the RESORT (REappraisals for emotional SuppORT) framework, leveraging LLMs to perform cognitive reappraisal and assist in regulating individuals' emotions. RESORT is grounded in $6$ appraisal dimensions identified by \citet{YeoOng2023Appraisals}, each carefully selected to ensure broad applicability across diverse situations. The framework is built on expert-crafted reappraisal constitutions, which act as guiding principles for LLMs to elicit effective reappraisals. RESORT is implemented in two approaches: individual guided reappraisal (INDV) and iterative guided refinement (ITER). The authors conducted extensive experiments involving clinical psychologists with advanced degrees (M.S. or Ph.D.), and showed that LLMs, even smaller models like those with $7$B parameters, can produce cognitive reappraisals that significantly outperform both human-written responses and non-appraisal-based prompting.

\section{Background of BiGGen Bench}\label{appendix:biggen}
The BiGGen Bench \cite{kim2024biggenbenchprincipledbenchmark} dataset is a robust and comprehensive benchmark designed to assess the capabilities of LLMs across various tasks. Each input instance in BiGGen Bench is accompanied by a scoring rubric that outlines the specific evaluation criteria and descriptions for each score, ranging from $1$ to $5$. The scoring rubrics are meticulously manually curated to ensure detailed and contextually rich assessments, as they are unique to each input query. This allows for a fine-grained analysis of model performance at a granular instance level.

In BiGGen Bench, there are multiple responses from different LLMs to the same input query. An evaluator LM, which serves to judge the quality of responses, needs to assign a grade to the response based on the scoring rubric provided. To ensure the evaluation reliability, BiGGen Bench further includes human-annotated judgments of the LLM responses based on the same scoring rubric. Results show that their human-collected fine-grained scoring rubrics significantly enhance the accuracy of Evaluator LMs' judgments, outperforming both coarse-grained \cite{zheng2023judging} and domain-specific \cite{ye2024flask} criteria.

\clearpage

\section{Full Results for Cognitive Reappraisals}\label{appendix:full_results_reappraisal}
We showcase the full results for cognitive reappraisals in Table \ref{tab:results-reappraisal-full}.

\begin{table*}[htpb]
  \centering
  \small
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
  \caption{Evaluation results (in average scores) for reappraisal responses. We report statistical significance (with $p<0.05$) using pair-wise t-tests against both the vanilla (marked with *) and self-refine (marked with $\dagger$) baselines. Responses where the ratings are significantly \emph{worse} than either of the baselines are shaded. In addition, we also show the average number of model calls required to produce each response.}
  \label{tab:results-reappraisal-full}
  \vskip 0.05in
  \adjustbox{max width=\textwidth}{
    \begin{tabular}{lr||S[table-format=1.0]S[table-format=1.0]||S[table-format=1.2]S[table-format=1.2]|S[table-format=1.2]S[table-format=1.2]|S[table-format=1.2]S[table-format=1.2]|S[table-format=1.2]S[table-format=1.2]}
    \toprule
          &       &     &   &    \multicolumn{2}{c|}{\textbf{Alignment ↑}} & \multicolumn{2}{c|}{\textbf{Empathy ↑}} & \multicolumn{2}{c|}{\textbf{Harmfulness ↓}} & \multicolumn{2}{c}{\textbf{Factuality ↑}} \\
          &       &     \multicolumn{2}{c||}{\textbf{\# Model Calls}}     &    \multicolumn{2}{c|}{\textsc{$10$-Point Scale}} & \multicolumn{2}{c|}{\textsc{$5$-Point Scale}} & \multicolumn{2}{c|}{\textsc{Yes/No}} & \multicolumn{2}{c}{\textsc{Yes/Minor/No}} \\
          &       & \textsc{indv}  & \textsc{iter} & \textsc{indv}  & \textsc{iter}  & \textsc{indv}  & \textsc{iter}  & \textsc{indv}  & \textsc{iter}  & \textsc{indv}  & \textsc{iter} \\
    \midrule

        \multirow{8}[2]{*}{\textsc{GPT-4o-mini}} & \texttt{vanilla} & \multicolumn{2}{S[table-format=1.0]||}{1} & \multicolumn{2}{S[table-format=1.2]|}{7.90} & \multicolumn{2}{S[table-format=1.2]|}{4.50} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 1.00} \\
          & \texttt{self-refine} & \multicolumn{2}{S[table-format=1.0]||}{6} & \multicolumn{2}{S[table-format=1.2]|}{7.73} & \multicolumn{2}{S[table-format=1.2]|}{4.53} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.93} \\
          & \texttt{default\_principles only} & 1     & 6     & \cellcolor[HTML]{E0E0E0} 5.67*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0}2.13*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0} 3.23*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0} 1.53*$^{\dagger}$ & 0.00  & 0.04  & \cellcolor[HTML]{E0E0E0} 0.55*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0} 0.08*$^{\dagger}$ \\
                  & \texttt{[no seeds] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{5.3} & \multicolumn{2}{S[table-format=1.2]|}{\cellcolor[HTML]{E0E0E0} 7.67*} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 4.73} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.97} \\
          & \texttt{[seed=default\_principles] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{4.3} & \multicolumn{2}{S[table-format=1.2]|}{7.67} & \multicolumn{2}{S[table-format=1.2]|}{4.67} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 1.00$^{\dagger}$} \\
                  & \texttt{[seed=one\_oracle] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{4.5} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 8.00$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 4.73} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 1.00$^{\dagger}$} \\
                & \texttt{oracle principles} & \cellcolor{yellow!40} 1     & \cellcolor{yellow!40} 6     & \cellcolor{yellow!40} 8.90*$^{\dagger}$ & \cellcolor{yellow!40} 8.67*$^{\dagger}$ & \cellcolor{yellow!40} 4.37  & \cellcolor{yellow!40} 4.80*$^{\dagger}$ & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} \cellcolor[HTML]{E0E0E0} 0.90* & \cellcolor{yellow!40} 1.00$^{\dagger}$ \\

    \midrule
        \multirow{8}[2]{*}{\shortstack[l]{\textsc{Llama-3.1} \\ \textsc{$70$B-Instruct}}} & \texttt{vanilla} & \multicolumn{2}{S[table-format=1.0]||}{1} & \multicolumn{2}{S[table-format=1.2]|}{7.77} & \multicolumn{2}{S[table-format=1.2]|}{4.43} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 1.00} \\
              & \texttt{self-refine} & \multicolumn{2}{S[table-format=1.0]||}{6} & \multicolumn{2}{S[table-format=1.2]|}{7.50} & \multicolumn{2}{S[table-format=1.2]|}{4.27} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.93} \\
          & \texttt{default\_principles only} & 1     & 6     & \cellcolor[HTML]{E0E0E0} 6.73* & \cellcolor[HTML]{E0E0E0} 6.47*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0} 3.83*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0} 3.67*$^{\dagger}$ & 0.00  & 0.00  & \cellcolor[HTML]{E0E0E0} 0.65*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0} 0.65*$^{\dagger}$ \\
                    & \texttt{[no seeds] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{4.3} & \multicolumn{2}{S[table-format=1.2]|}{7.77} & \multicolumn{2}{S[table-format=1.2]|}{4.73*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 1.00$^{\dagger}$} \\
          & \texttt{[seed=default\_principles] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{4.5} & \multicolumn{2}{S[table-format=1.2]|}{7.87$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 4.80*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.97} \\
                    & \texttt{[seed=one\_oracle] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{4.3} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 8.17*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{4.77*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.98} \\
                & \texttt{oracle principles} & \cellcolor{yellow!40} 1     & \cellcolor{yellow!40} 6     & \cellcolor{yellow!40} 8.80*$^{\dagger}$ & \cellcolor{yellow!40} 8.53*$^{\dagger}$ & \cellcolor{yellow!40} \cellcolor[HTML]{E0E0E0} 4.07* & \cellcolor{yellow!40} 4.20  & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} \cellcolor[HTML]{E0E0E0} 0.90* & \cellcolor{yellow!40} 0.95 \\

    \midrule
    \multirow{8}[2]{*}{\shortstack[l]{\textsc{Llama-3} \\ \textsc{$8$B-Instruct}}} & \texttt{vanilla} & \multicolumn{2}{S[table-format=1.0]||}{1} & \multicolumn{2}{S[table-format=1.2]|}{7.10} & \multicolumn{2}{S[table-format=1.2]|}{3.90} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.88} \\
          & \texttt{self-refine} & \multicolumn{2}{S[table-format=1.0]||}{6} & \multicolumn{2}{S[table-format=1.2]|}{7.20} & \multicolumn{2}{S[table-format=1.2]|}{4.07} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.87} \\
          & \texttt{default\_principles only} & 1     & 6     & 6.70  & \cellcolor[rgb]{0.878,0.878,0.878} 6.07*$^{\dagger}$ & 4.13  & 3.80  & 0.00  & 0.00  & \cellcolor[HTML]{E0E0E0}0.60*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0}0.38*$^{\dagger}$ \\
                    & \texttt{[no seeds] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{5.5} & \multicolumn{2}{S[table-format=1.2]|}{7.73*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{4.30*} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 0.92} \\
          & \texttt{[seed=default\_principles] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{5.5} & \multicolumn{2}{S[table-format=1.2]|}{7.70*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 4.53*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 0.92} \\
                    & \texttt{[seed=one\_oracle] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{6.0} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 7.90*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{4.47*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.90} \\
                    & \texttt{oracle principles} & \cellcolor{yellow!40} 1     & \cellcolor{yellow!40} 6     & \cellcolor{yellow!40} 8.47*$^{\dagger}$ & \cellcolor{yellow!40} 8.33*$^{\dagger}$ & \cellcolor{yellow!40} 4.17  & \cellcolor{yellow!40} 4.30* & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} 0.85  & \cellcolor{yellow!40} 0.83 \\

    \midrule
    \multirow{8}[2]{*}{\shortstack[l]{\textsc{Mixtral} \\ \textsc{$8\times7$B-Instruct} \\ \textsc{(V$0.1$)}}} & \texttt{vanilla} & \multicolumn{2}{S[table-format=1.0]||}{1} & \multicolumn{2}{S[table-format=1.2]|}{7.53} & \multicolumn{2}{S[table-format=1.2]|}{4.50} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.92} \\
          & \texttt{self-refine} & \multicolumn{2}{S[table-format=1.0]||}{6} & \multicolumn{2}{S[table-format=1.2]|}{6.60} & \multicolumn{2}{S[table-format=1.2]|}{3.90} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.80} \\
          & \texttt{default\_principles only} & 1     & 6     & \cellcolor[HTML]{E0E0E0}5.47*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0}2.80*$^{\dagger}$ & \cellcolor[HTML]{E0E0E0}3.77* & \cellcolor[HTML]{E0E0E0}2.27*$^{\dagger}$ & 0.00  & 0.00  & 0.28  & \cellcolor[HTML]{E0E0E0}0.02*$^{\dagger}$ \\
                    & \texttt{[no seeds] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{4.5} & \multicolumn{2}{S[table-format=1.2]|}{7.60$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{4.67$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{\bfseries 0.95$^{\dagger}$} \\
          & \texttt{[seed=default\_principles] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{5.9} & \multicolumn{2}{S[table-format=1.2]|}{7.57$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{4.57$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.88} \\
                    & \texttt{[seed=one\_oracle] \ourframework{}} & \multicolumn{2}{S[table-format=1.1]||}{4.7} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 8.03*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{\bfseries 4.77*$^{\dagger}$} & \multicolumn{2}{S[table-format=1.2]|}{0.00} & \multicolumn{2}{S[table-format=1.2]}{0.93$^{\dagger}$} \\
                & \texttt{oracle principles} & \cellcolor{yellow!40} 1     & \cellcolor{yellow!40} 6     & \cellcolor{yellow!40} 8.57*$^{\dagger}$ & \cellcolor{yellow!40} 8.17  & \cellcolor{yellow!40} 4.43$^{\dagger}$ & \cellcolor{yellow!40} 4.07  & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} 0.00  & \cellcolor{yellow!40} 0.92 & \cellcolor{yellow!40} 0.72 \\
    \bottomrule
    \end{tabular}}
\end{table*}

\clearpage

\section{Full Results for BigGen Bench}\label{appendix:full_results_biggen}
We provide the full results for instance-specific rubric evaluation in Table \ref{tab:results-rubric-full}.

\begin{table*}[htbp]
  \centering
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
  \caption{Results for BiGGen Bench, measured with Pearson's correlation against the human ground truth labels. Evaluation carried out \emph{without} the use of reference answers. Values that are not significant ($p<0.001$) are shaded.}
    \vskip 0.05in
  \adjustbox{max width=\textwidth}{
    \begin{tabular}{lr||c||S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]}
    \toprule
            &       & \textbf{\# Calls} & \textbf{Inst. Follow.} & \textbf{Ground.} & \textbf{Reason.} & \textbf{Plan.} & \textbf{Refine.} & \textbf{Safety} & \textbf{ToM} & \textbf{Tool.} & \textbf{Average} \\
    \midrule
        \rowcolor{yellow!40} \multirow{9}[2]{*}{\cellcolor{white} \textsc{GPT-4o-mini}} & \cellcolor{white} \texttt{gold rubrics} & $1$     & 0.597* & 0.612* & 0.631* & 0.641* & 0.432* & 0.664* & 0.378* & 0.448* & 0.550 \\
          & \texttt{vanilla} & $1$     & 0.358* & 0.361* & 0.478* & 0.620* & 0.222* & \cellcolor[HTML]{E0E0E0} 0.112 & 0.380* & 0.481* & 0.377 \\
          & \texttt{self-refine} & $6$     & 0.375* & 0.379* & 0.491* & \bfseries 0.622* & 0.266* & \cellcolor[HTML]{E0E0E0} 0.156 & 0.427* & 0.460* & 0.397 \\
          & \texttt{MT-Bench rubric} & $1$     & 0.330* & 0.389* & 0.527* & 0.569* & 0.313* & 0.266* & 0.426* & \bfseries 0.506* & 0.416 \\
          & \texttt{FLASK rubric} & $1$     & 0.348* & 0.369* & 0.496* & 0.318* & 0.297* & 0.339* & 0.204* & 0.489* & 0.358 \\
          & \texttt{default principles as rubrics} & $1$     & \cellcolor[HTML]{E0E0E0} 0.128 & \cellcolor[HTML]{E0E0E0} 0.075 & 0.323* & 0.242* & \cellcolor[HTML]{E0E0E0} 0.173 & \cellcolor[HTML]{E0E0E0} 0.046 & \cellcolor[HTML]{E0E0E0} 0.159 & 0.264* & 0.176 \\
          & \texttt{[no seeds] \ourframework{}} & $5.3$   & 0.368* & 0.429* & 0.523* & 0.569* & 0.325* & \cellcolor[HTML]{E0E0E0} 0.175 & 0.447* & 0.440* & 0.410 \\
          & \texttt{[seeds=default principles] \ourframework{}} &$5.5$   & 0.380* & 0.437* & 0.451* & 0.596* & 0.316* & 0.207* & 0.401* & 0.446* & 0.404 \\
          & \texttt{[seeds=3 gold rubrics] \ourframework{}} &$4.9$   & \bfseries 0.398* & \bfseries 0.506* & \bfseries 0.553* & 0.618* & \bfseries 0.326* & \bfseries 0.385* & \bfseries 0.500* & 0.492* & \bfseries 0.472 \\
    \midrule
    \rowcolor{yellow!40} \multirow{9}[2]{*}{\cellcolor{white} \shortstack[l]{\textsc{Llama-3.1} \\ \textsc{$70$B-Instruct}}} & \cellcolor{white} \texttt{gold rubrics} & $1$     & 0.569* & 0.594* & 0.574* & 0.574* & 0.420* & 0.679* & 0.535* & 0.500* & 0.556 \\
          & \texttt{vanilla} & $1$     & 0.368* & 0.338* & 0.462* & 0.606* & 0.244* & \cellcolor[HTML]{E0E0E0} 0.121 & \bfseries 0.497* & 0.448* & 0.386 \\
          & \texttt{self-refine} & $6$     & \cellcolor[HTML]{E0E0E0} 0.149 & \cellcolor[HTML]{E0E0E0} 0.015 & 0.396* & 0.558* & \cellcolor[HTML]{E0E0E0} 0.131 & \cellcolor[HTML]{E0E0E0} 0.138 & 0.324* & 0.365* & 0.260 \\
          & \texttt{MT-Bench rubric} & $1$     & 0.299* & 0.337* & \bfseries 0.488* & \bfseries 0.612* & 0.267* & 0.388* & 0.474* & \bfseries 0.505* & 0.421 \\
          & \texttt{FLASK rubric} & $1$     & \bfseries 0.409* & 0.277* & 0.422* & 0.419* & 0.315* & 0.365* & 0.168* & 0.503* & 0.360 \\
          & \texttt{default principles as rubrics} &$1$     & \cellcolor[HTML]{E0E0E0} 0.053 & \cellcolor[HTML]{E0E0E0} 0.130  & \cellcolor[HTML]{E0E0E0} 0.144 & \cellcolor[HTML]{E0E0E0} 0.119 & \cellcolor[HTML]{E0E0E0} 0.038 & \cellcolor[HTML]{E0E0E0} -0.069 & \cellcolor[HTML]{E0E0E0} 0.049 & \cellcolor[HTML]{E0E0E0} -0.024 & 0.055 \\
          & \texttt{[no seeds] \ourframework{}} &$4.9$   & 0.276* & 0.441* & 0.438* & 0.503* & 0.316* & 0.328* & 0.494* & 0.484* & 0.410 \\
          & \texttt{[seeds=default principles] \ourframework{}} &$5.1$   & 0.244* & 0.474* & 0.409* & 0.510* & 0.255* & 0.313* & 0.454* & 0.471* & 0.391 \\
          & \texttt{[seeds=3 gold rubrics] \ourframework{}} &$4.6$   & \bfseries 0.409* & \bfseries 0.555* & 0.474* & \bfseries 0.611* & \bfseries 0.402* & \bfseries 0.440* & 0.450* & 0.500* & \bfseries 0.480 \\
    \midrule
    \rowcolor{yellow!40} \multirow{9}[2]{*}{\cellcolor{white}  \shortstack[l]{\textsc{Mixtral} \\ \textsc{$8\times7$B-Instruct} \\ \textsc{(V$0.1$)}}} & \cellcolor{white}  \texttt{gold rubrics} & $1$     & 0.377* & 0.410* & 0.409* & 0.417* & \cellcolor[HTML]{E0E0E0} 0.167 & 0.410* & 0.335* & 0.407* & 0.367 \\
          & \texttt{vanilla} & $1$     & 0.222* & 0.262* & 0.355* & 0.435* & \bfseries 0.203* & 0.186* & 0.356* & 0.440* & \bfseries 0.307 \\
          & \texttt{self-refine} & $6$     & \cellcolor[HTML]{E0E0E0} 0.050  & \cellcolor[HTML]{E0E0E0} 0.076 & \cellcolor[HTML]{E0E0E0} 0.122 & \cellcolor[HTML]{E0E0E0} 0.174 & \cellcolor[HTML]{E0E0E0} 0.071 & \cellcolor[HTML]{E0E0E0} 0.093 & \cellcolor[HTML]{E0E0E0} 0.119 & \cellcolor[HTML]{E0E0E0} 0.174 & 0.110 \\
          & \texttt{MT-Bench rubric} & $1$     & \bfseries 0.247* & 0.213* & 0.179* & 0.280* & \cellcolor[HTML]{E0E0E0} 0.135 & \bfseries 0.310* & \bfseries 0.384* & 0.437* & 0.273 \\
          & \texttt{FLASK rubric} & $1$     & 0.186* & 0.279* & 0.282* & 0.316* & 0.197* & 0.284* & 0.258* & 0.413* & 0.277 \\
          & \texttt{default principles as rubrics} &$1$     & 0.176* & 0.218* & \bfseries 0.399* & 0.342* & \cellcolor[HTML]{E0E0E0} 0.151 & 0.219* & 0.252* & 0.326* & 0.260 \\
          & \texttt{[no seeds] \ourframework{}} &$5.2$   & 0.196* & 0.305* & 0.308* & 0.268* & \cellcolor[HTML]{E0E0E0} 0.116 & \cellcolor[HTML]{E0E0E0} 0.147 & 0.231* & 0.392* & 0.245 \\
          & \texttt{[seeds=default principles] \ourframework{}} &$5.4$   & 0.191* & 0.297* & 0.267* & 0.231* & \cellcolor[HTML]{E0E0E0} 0.111 & 0.242* & 0.215* & 0.348* & 0.238 \\
          & \texttt{[seeds=3 gold rubrics] \ourframework{}} &$4.7$   & 0.184* & \bfseries 0.312* & 0.216* & \bfseries 0.450* & \cellcolor[HTML]{E0E0E0} 0.116 & 0.295* & 0.271* & \bfseries 0.457* & 0.288 \\
    \midrule
    \rowcolor{yellow!40} \multirow{9}[2]{*}{\cellcolor{white} \shortstack[l]{\textsc{Prometheus-$2$} \\ \textsc{$8\times7$B}}} & \cellcolor{white} \texttt{gold rubrics} & $1$     & 0.346* & 0.460* & 0.401* & 0.398* & 0.241* & 0.486* & 0.371* & 0.385* & 0.386 \\
          & \texttt{vanilla} & $1$     & 0.273* & 0.267* & 0.333* & \bfseries 0.415* & \cellcolor[HTML]{E0E0E0} 0.177 & 0.239* & 0.386* & 0.394* & 0.311 \\
          & \texttt{self-refine} & $6$     & 0.247* & 0.282* & 0.332* & 0.385* & \cellcolor[HTML]{E0E0E0} 0.166 & 0.272* & 0.349* & 0.346* & 0.297 \\
          & \texttt{MT-Bench rubric} & $1$     & 0.316* & 0.264* & 0.200* & 0.412* & \cellcolor[HTML]{E0E0E0} 0.158 & 0.255* & 0.337* & 0.366* & 0.289 \\
          & \texttt{FLASK rubric} & $1$     & 0.249* & 0.261* & 0.262* & 0.361* & \bfseries 0.242* & \bfseries 0.333* & 0.288* & 0.353* & 0.294 \\
          & \texttt{default principles as rubrics} &$1$     & 0.269* & 0.240* & \bfseries 0.387* & 0.404* & 0.226* & 0.208* & 0.329* & 0.398* & 0.308 \\
          & \texttt{[no seeds] \ourframework{}} &$4.9$   & \bfseries 0.323* & 0.243* & 0.246* & 0.368* & 0.211* & 0.233* & 0.292* & 0.457* & 0.297 \\
          & \texttt{[seeds=default principles] \ourframework{}} &$5.0$   & 0.306* & 0.353* & 0.320* & 0.399* & 0.190* & 0.286* & 0.405* & 0.427* & \bfseries 0.336 \\
          & \texttt{[seeds=3 gold rubrics] \ourframework{}} &$4.6$   & 0.218* & \bfseries 0.360* & \bfseries 0.387* & 0.411* & 0.198* & 0.200* & \bfseries 0.408* & \bfseries 0.485* & 0.333 \\
    \bottomrule
    \end{tabular}}
  \label{tab:results-rubric-full}
\end{table*}

\clearpage

\section{Full Results for SFT}\label{appendix:full_results_sft}
In Table \ref{tab:results-sft-base-full}, we showcase the full results from fine-tuning base models that only went through the pre-training phase. In Table \ref{tab:results-sft-it-full}, we provide the full results for fine-tuning models that have gone through post-training.

\begin{table}[ht]  
  \centering  
  \small  
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
    \caption{SFT results for base models.}
    \label{tab:results-sft-base-full}  
    \vskip 0.05in  
    \adjustbox{max width=.95\textwidth}{
    \begin{tabular}{lr||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]||S[table-format=2.2,table-space-text-post=\%]}
          & \multicolumn{1}{r||}{} & \multicolumn{2}{c|}{\textbf{\textsc{TruthfulQA}}} & \multicolumn{2}{c|}{\textbf{\textsc{MUSR}}} & \multicolumn{2}{c|}{\textbf{\textsc{GPQA}}} & \multicolumn{2}{c|}{\textbf{\textsc{BBH}}} & \multicolumn{2}{c|}{\textbf{\textsc{MMLU-PRO}}} & \multicolumn{2}{c||}{\textbf{\textsc{Hellaswag}}} &  \\
          & \multicolumn{1}{r||}{} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c||}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\textbf{Average}} \\
    \toprule
        \multicolumn{1}{l}{\multirow{9}[2]{*}{\textsc{Llama-3.1-8B}}} & \texttt{off-the-shelf} & \multicolumn{2}{S[table-format=2.2]|}{45.03\%} & \multicolumn{2}{S[table-format=2.2]|}{38.25\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 29.32\%} & \multicolumn{2}{S[table-format=2.2]|}{46.51\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 32.67\%} & \multicolumn{2}{S[table-format=2.2]||}{\cellcolor{lightgreen} \bfseries 81.45\%} & 45.54\% \\
          & \texttt{Llama-3.1-8B-Instruct} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}53.02\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}37.90\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}30.66\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}48.72\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}36.47\%} & \multicolumn{2}{S[table-format=2.2]||}{\cellcolor[rgb]{ 1,  .949,  .8}76.89\%} & 47.28\% \\
          & \texttt{oracle response} & 41.62\% & 51.94\% & 42.49\% & \cellcolor{lightgreen} \bfseries 40.80\% & 27.54\% & 28.79\% & 47.29\% & 47.26\% & 31.23\% & 30.53\% & 81.18\% & 81.08\% & 45.98\% \\
          & \texttt{direct response} & 51.48\% & 50.82\% & 41.91\% & 39.43\% & 27.12\% & \cellcolor{lightgreen} \bfseries 29.46\% & 48.71\% & 47.35\% & 31.11\% & 32.14\% & 80.63\% & 81.16\% & 46.78\% \\
          & \texttt{self-instruct} & 51.07\% & 52.02\% & \cellcolor{lightgreen} \bfseries 44.59\% & 39.29\% & 27.49\% & 25.45\% & \cellcolor{lightgreen} \bfseries 49.78\% & 46.38\% & 31.25\% & 31.31\% & 80.12\% & 81.00\% & 46.65\% \\
          & \texttt{self-align} & 54.56\% & 54.97\% & 41.54\% & 40.13\% & 28.21\% & 27.23\% & 49.28\% & 46.11\% & 31.47\% & 31.44\% & 80.09\% & 80.50\% & 47.13\% \\
          & self-refine & 53.76\% & 55.11\% & 43.63\% & 39.56\% & 27.33\% & 28.47\% & 49.49\% & 47.85\% & 32.60\% & \cellcolor{lightgreen} \bfseries 33.47\% & 79.99\% & 80.40\% & 47.64\% \\
          & \texttt{seed principles} & 53.63\% & 53.83\% & 39.96\% & 37.74\% & 28.16\% & 26.86\% & \cellcolor{lightgreen} \bfseries 49.77\% & \cellcolor{lightgreen} \bfseries 48.01\% & 31.57\% & 32.62\% & 79.70\% & 80.60\% & 46.87\% \\
          & \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 55.92\% & \cellcolor{lightgreen} \bfseries 56.08\% & 37.56\% & 39.20\% & 28.00\% & 27.13\% & 48.79\% & 46.98\% & 31.71\% & 30.31\% & 79.96\% & 79.91\% & 46.80\% \\
    \midrule
        \multicolumn{1}{l}{\multirow{9}[2]{*}{\textsc{Mistral-7B-v0.3}}} & \texttt{off-the-shelf} & \multicolumn{2}{S[table-format=2.2]|}{42.54\%} & \multicolumn{2}{S[table-format=2.2]|}{40.18\%} & \multicolumn{2}{S[table-format=2.2]|}{29.84\%} & \multicolumn{2}{S[table-format=2.2]|}{45.11\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 29.57\%} & \multicolumn{2}{S[table-format=2.2]||}{\cellcolor{lightgreen} \bfseries 82.90\%} & 45.02\% \\
          & \texttt{Mistral-7B-Instruct-v0.3} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}66.11\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}36.47\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}27.65\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}48.35\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}30.89\%} & \multicolumn{2}{S[table-format=2.2]||}{\cellcolor[rgb]{ 1,  .949,  .8}81.87\%} & 48.56\% \\
          & \texttt{oracle response} & 40.42\% & 50.90\% & 43.86\% & 42.95\% & 29.23\% & 28.65\% & 46.26\% & 45.26\% & 28.00\% & 27.19\% & \cellcolor{lightgreen} \bfseries 82.94\% & 81.75\% & 45.62\% \\
          & \texttt{direct response} & 47.16\% & 52.64\% & 43.19\% & 39.87\% & 27.10\% & 26.02\% & \cellcolor{lightgreen} \bfseries 47.39\% & \cellcolor{lightgreen} \bfseries 45.78\% & 27.78\% & 27.35\% & 81.56\% & 81.57\% & 45.62\% \\
          & \texttt{self-instruct} & 46.62\% & 51.87\% & \cellcolor{lightgreen} \bfseries 46.92\% & 39.34\% & 26.22\% & 28.38\% & 47.32\% & 44.56\% & 28.37\% & 27.17\% & 80.95\% & 81.16\% & 45.74\% \\
          & \texttt{self-align} & 48.86\% & 53.95\% & 44.82\% & 40.29\% & \cellcolor{lightgreen} \bfseries 31.64\% & 27.64\% & 45.34\% & 44.63\% & 28.37\% & 26.55\% & 81.26\% & 81.18\% & 46.21\% \\
          & self-refine & 49.40\% & 53.15\% & 42.93\% & 40.91\% & 28.51\% & 27.97\% & 47.00\% & 45.20\% & 26.83\% & 27.41\% & 81.52\% & 81.26\% & 46.01\% \\
          & \texttt{seed principles} & 50.89\% & 54.24\% & 45.06\% & 41.08\% & 28.30\% & \cellcolor{lightgreen} \bfseries 30.96\% & 46.51\% & 44.76\% & 27.81\% & 27.78\% & 81.37\% & 80.55\% & 46.61\% \\
          & \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 51.85\% & \cellcolor{lightgreen} \bfseries 55.63\% & 44.79\% & \cellcolor{lightgreen} \bfseries 43.31\% & 29.26\% & 28.30\% & 45.18\% & 45.39\% & 28.61\% & 28.10\% & 81.20\% & 80.13\% & 46.81\% \\
    \midrule
        \multicolumn{1}{l}{\multirow{9}[2]{*}{\textsc{{Gemma-2-9B}}}} & \texttt{off-the-shelf} & \multicolumn{2}{S[table-format=2.2]|}{45.39\%} & \multicolumn{2}{S[table-format=2.2]|}{44.58\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 32.89\%} & \multicolumn{2}{S[table-format=2.2]|}{53.74\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 41.03\%} & \multicolumn{2}{S[table-format=2.2]||}{81.90\%} & 49.92\% \\
          & \texttt{Gemma-2-9B-it} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}60.47\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}40.59\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}33.85\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}59.93\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor[rgb]{ 1,  .949,  .8}38.60\%} & \multicolumn{2}{S[table-format=2.2]||}{\cellcolor[rgb]{ 1,  .949,  .8}78.11\%} & 51.93\% \\
          & \texttt{oracle response} & 44.81\% & 51.21\% & \cellcolor{lightgreen} \bfseries 47.09\% & 46.20\% & 30.76\% & 31.87\% & \cellcolor{lightgreen} \bfseries 56.64\% & 55.45\% & \cellcolor{lightgreen} \bfseries 41.76\% & 40.43\% & \cellcolor{lightgreen} \bfseries 83.38\% & \cellcolor{lightgreen} \bfseries 83.00\% & 51.05\% \\
          & \texttt{direct response} & 53.82\% & 53.94\% & 46.97\% & 45.39\% & 30.50\% & 30.77\% & 56.42\% & 54.80\% & 41.09\% & 40.47\% & 81.79\% & 81.44\% & 51.45\% \\
          & \texttt{self-instruct} & 52.43\% & 52.85\% & 45.38\% & 45.92\% & 29.80\% & 29.00\% & 56.56\% & \cellcolor{lightgreen} \bfseries 55.55\% & 41.06\% & 40.59\% & 80.99\% & 82.17\% & 51.03\% \\
          & \texttt{self-align} & 54.02\% & 51.70\% & 42.22\% & 43.40\% & 30.62\% & 30.01\% & 55.44\% & 54.55\% & 40.08\% & 39.57\% & 80.65\% & 81.59\% & 50.32\% \\
          & self-refine & 55.01\% & 53.93\% & 46.99\% & \cellcolor{lightgreen} \bfseries 47.64\% & 28.85\% & 30.07\% & 56.21\% & 54.85\% & 40.95\% & 40.38\% & 81.39\% & 81.61\% & 51.49\% \\
          & \texttt{seed principles} & 53.48\% & 52.22\% & 42.60\% & 41.42\% & 29.59\% & 28.58\% & 55.46\% & 54.58\% & 40.17\% & 40.47\% & 80.37\% & 81.58\% & 50.04\% \\
          & \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 55.72\% & \cellcolor{lightgreen} \bfseries 56.48\% & 45.38\% & 47.24\% & 30.59\% & 31.72\% & 56.50\% & 55.14\% & 41.22\% & 40.23\% & 81.08\% & 80.89\% & 51.85\% \\
    \bottomrule
    \end{tabular}
    }
\end{table}


\begin{table}[ht]  
  \centering  
  \small  
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
    \caption{SFT results for post-trained models.}
    \label{tab:results-sft-it-full}  
    \vskip 0.05in  
    \adjustbox{max width=.95\textwidth}{
    \begin{tabular}{lr||S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]|S[table-format=2.2,table-space-text-post=\%]S[table-format=2.2,table-space-text-post=\%]||S[table-format=2.2,table-space-text-post=\%]}
          & \multicolumn{1}{r||}{} & \multicolumn{2}{c|}{\textbf{\textsc{TruthfulQA}}} & \multicolumn{2}{c|}{\textbf{\textsc{MUSR}}} & \multicolumn{2}{c|}{\textbf{\textsc{GPQA}}} & \multicolumn{2}{c|}{\textbf{\textsc{BBH}}} & \multicolumn{2}{c|}{\textbf{\textsc{MMLU-PRO}}} & \multicolumn{2}{c||}{\textbf{\textsc{Hellaswag}}} &  \\
          & \multicolumn{1}{r||}{} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c|}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\texttt{Dolly}} & \multicolumn{1}{c||}{\texttt{MixInstruct}} & \multicolumn{1}{c}{\textbf{Average}} \\
    \toprule
        \multirow{8}[2]{*}{\shortstack[l]{\textsc{Llama-3.1-8B} \\ \textsc{Instruct}}} & \texttt{off-the-shelf} & \multicolumn{2}{S[table-format=2.2]|}{53.02\%} & \multicolumn{2}{S[table-format=2.2]|}{37.90\%} & \multicolumn{2}{S[table-format=2.2]|}{30.66\%} & \multicolumn{2}{S[table-format=2.2]|}{48.72\%} & \multicolumn{2}{S[table-format=2.2]|}{36.47\%} & \multicolumn{2}{S[table-format=2.2]||}{76.89\%} & 47.28\% \\
          & \texttt{oracle response} & 46.75\% & 49.28\% & \cellcolor{lightgreen} \bfseries 42.21\% & 36.35\% & 24.71\% & 28.02\% & \cellcolor{lightgreen} \bfseries 51.20\% & 45.71\% & 36.12\% & 33.83\% & \cellcolor{lightgreen} \bfseries 79.75\% & 74.41\% & 45.70\% \\
          & \texttt{direct response} & 50.94\% & 50.99\% & 38.18\% & 39.11\% & 30.42\% & 30.12\% & 46.49\% & 46.15\% & \cellcolor{lightgreen} \bfseries 37.23\% & 35.11\% & 72.70\% & 72.18\% & 45.80\% \\
          & \texttt{self-instruct} & 49.46\% & 50.76\% & 37.78\% & 34.63\% & 29.96\% & 30.42\% & 46.23\% & 45.86\% & 35.95\% & 35.11\% & 70.72\% & 70.53\% & 44.78\% \\
          & \texttt{self-align} & 52.52\% & 51.96\% & 34.62\% & 35.55\% & 28.40\% & \cellcolor{lightgreen} \bfseries 31.16\% & 47.50\% & 44.91\% & 34.45\% & 35.29\% & 73.10\% & 74.12\% & 45.30\% \\
          & \texttt{self-refine} & 52.11\% & 50.20\% & 36.98\% & 39.53\% & \cellcolor{lightgreen} \bfseries 31.05\% & 30.33\% & 46.69\% & 46.19\% & \cellcolor{lightgreen} \bfseries 37.23\% & 35.89\% & 72.20\% & 72.34\% & 45.90\% \\
          & \texttt{seed principles} & 50.46\% & 52.90\% & 35.01\% & 35.42\% & 27.57\% & 29.18\% & 45.93\% & 45.52\% & 35.18\% & 35.65\% & 70.34\% & 70.13\% & 44.44\% \\
          & \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 54.69\% & \cellcolor{lightgreen} \bfseries 55.41\% & 41.70\% & \cellcolor{lightgreen} \bfseries 40.38\% & 24.71\% & 24.71\% & 50.66\% & \cellcolor{lightgreen} \bfseries 50.21\% & 36.99\% & \cellcolor{lightgreen} \bfseries 36.45\% & 78.51\% & \cellcolor{lightgreen} \bfseries 78.55\% & 47.75\% \\
    \midrule
    \multirow{8}[2]{*}{\shortstack[l]{\textsc{Mistral-7B-v0.3} \\ \textsc{Instruct}}} & \texttt{off-the-shelf} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 66.11\%} & \multicolumn{2}{S[table-format=2.2]|}{36.47\%} & \multicolumn{2}{S[table-format=2.2]|}{27.65\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 48.35\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 30.89\%} & \multicolumn{2}{S[table-format=2.2]||}{\cellcolor{lightgreen} \bfseries 81.87\%} & 48.56\% \\
          & \texttt{oracle response} & 42.87\% & 49.64\% & 46.86\% & 44.41\% & 27.71\% & 27.53\% & 45.99\% & 44.66\% & 27.38\% & 26.26\% & \cellcolor{lightgreen} \bfseries 82.40\% & 80.67\% & 45.53\% \\
          & \texttt{direct response} & 50.89\% & 55.09\% & 45.17\% & 44.39\% & 25.80\% & 26.69\% & 45.56\% & 45.65\% & 27.49\% & 27.57\% & 81.46\% & \cellcolor{lightgreen} \bfseries 80.91\% & 46.39\% \\
          & \texttt{self-instruct} & 50.44\% & 52.81\% & 46.93\% & 44.09\% & 26.08\% & 27.23\% & 44.58\% & 45.50\% & 28.56\% & 28.41\% & 80.86\% & 80.27\% & 46.31\% \\
          & \texttt{self-align} & 54.44\% & 56.85\% & 46.11\% & 43.33\% & \cellcolor{lightgreen} \bfseries 27.72\% & 27.17\% & 45.47\% & 43.97\% & 28.90\% & 28.75\% & 80.67\% & 80.31\% & 46.97\% \\
          & \texttt{self-refine} & 52.35\% & 54.69\% & 44.76\% & 42.66\% & 27.30\% & 26.15\% & 46.04\% & 44.65\% & 26.92\% & 27.91\% & 81.63\% & 80.31\% & 46.28\% \\
          & \texttt{seed principles} & 52.42\% & 56.53\% & \cellcolor{lightgreen} \bfseries 48.62\% & 42.43\% & 26.69\% & \cellcolor{lightgreen} \bfseries 28.44\% & 45.99\% & 45.51\% & 28.04\% & 27.92\% & 81.20\% & 80.20\% & 47.00\% \\
          & \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 56.43\% & \cellcolor{lightgreen} \bfseries 57.99\% & 46.64\% & \cellcolor{lightgreen} \bfseries 44.79\% & 26.28\% & 27.38\% & 46.75\% & 44.35\% & 28.38\% & 28.66\% & 81.16\% & 79.52\% & 47.36\% \\
    \midrule
        \multirow{8}[2]{*}{\shortstack[l]{\textsc{Gemma-2-9B-it}}} & \texttt{off-the-shelf} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 60.47\%} & \multicolumn{2}{S[table-format=2.2]|}{40.59\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 33.85\%} & \multicolumn{2}{S[table-format=2.2]|}{\cellcolor{lightgreen} \bfseries 59.93\%} & \multicolumn{2}{S[table-format=2.2]|}{38.60\%} & \multicolumn{2}{S[table-format=2.2]||}{78.11\%} & 51.93\% \\
          & \texttt{oracle response} & 47.11\% & 57.48\% & \cellcolor{lightgreen} \bfseries 49.12\% & \cellcolor{lightgreen} \bfseries 51.39\% & 32.64\% & 31.21\% & 58.78\% & 58.68\% & \cellcolor{lightgreen} \bfseries 40.92\% & 39.26\% & \cellcolor{lightgreen} \bfseries 81.91\% & \cellcolor{lightgreen} \bfseries 80.41\% & 52.41\% \\
          & \texttt{direct response} & 57.97\% & 57.73\% & 46.31\% & 47.51\% & 31.31\% & 30.63\% & 59.02\% & 57.66\% & 39.80\% & 38.95\% & 78.46\% & 78.43\% & 51.98\% \\
          & \texttt{self-instruct} & 56.26\% & 54.70\% & 47.37\% & 46.73\% & 31.58\% & 31.31\% & 57.72\% & 57.97\% & 40.19\% & 39.19\% & 78.08\% & 78.31\% & 51.62\% \\
          & \texttt{self-align} & 58.34\% & 55.11\% & 45.93\% & 46.19\% & 32.49\% & 29.73\% & 58.42\% & 57.75\% & 39.70\% & 38.67\% & 78.35\% & 78.84\% & 51.63\% \\
          & \texttt{self-refine} & 58.86\% & 58.36\% & 46.85\% & 50.03\% & 30.64\% & 32.37\% & 58.80\% & 57.05\% & 39.91\% & 37.92\% & 78.12\% & 77.84\% & 52.23\% \\
          & \texttt{seed principles} & 57.96\% & 58.24\% & 45.51\% & 45.53\% & 31.00\% & 31.94\% & 57.96\% & 56.77\% & 39.54\% & \cellcolor{lightgreen} \bfseries 39.93\% & 78.34\% & 76.70\% & 51.62\% \\
          & \texttt{\ourframework{}} & \cellcolor{lightgreen} \bfseries 62.62\% & \cellcolor{lightgreen} \bfseries 59.75\% & 46.86\% & 47.38\% & 31.94\% & 33.03\% & 58.04\% & 56.93\% & 40.13\% & 39.24\% & 78.35\% & 78.61\% & 52.74\% \\
    \bottomrule
    \end{tabular}
    }
\end{table}

\clearpage

\section{Example Principles Generated by \ourframework{}}\label{appendix:example-principles}

\subsection{Examples from Cognitive Reappraisal}\label{appendix:examples-principles-reappraisal}

\begin{enumerate}[label=(\roman*)]
    \item \begin{itemize}
        \item \textbf{\underline{User input}}: I'm currently completing my A levels (a series of exam you do in the UK at the age of 17/18, that determine whether you get into university)... as you can imagine, I have been stressed. I'm under a tremendous amount of pressure to get very high grades (straight A's). I've completed 2 exams, and have 5 left to go, 3 of which I'll be sitting tomorrow, the next day, and the day after that... \newline I'm shocked at how this stress has effected me physically. I've always been fairly neurotic, but the anxiety I tend to feel is transient, and is rarely severe enough to manifest in anything physically significant, beyond a raised pulse and slight breathlessness. \newline I knew I was getting myself *way* too worked up when I started to pull out hair in the shower. I have very thick hair, so a lot of it was coming out. I've had severe brain fog, which hasn't been the least bit helpful during a time when I have to be the most alert and *with it*'. I've had no appetite, and now my trousers are all loose, with one  pair literally falling down when I walk. The most bizarre symptom I've had is this weird jaw tension - my jaw is very clicky, and it feels incredibly tense and stiff. As a hypochondriac, I was convinced this was a heart attack, but I was reassured that it's probably just anxiety. I've had weird gastrointestinal symptoms, where I feel nauseous, and have this pit in my stomach all of the time, which could be caused by the lack of eating, but it persists even when I have eaten. \newline And then of course feelings of impending doom, etc etc. \newline I just can't wait for this to be over.
        \item \textcolor{orange}{\textbf{\underline{Reappraisal Goal}}: To guide the narrator over their perception of their responsibility for causing the situation.}
        \item \textcolor{blue}{\textbf{\underline{Oralce Principles}}: If the narrator is stressing over things they are not responsible for, tell them that it may not require as much responsibility as they think and not to worry about them too much (depending on how high they perceive their level of responsibility in the situation). However, if the person is doing something wrong/inappropriate and not feeling any responsibility or it (low responsibility), you should kindly but objectively encourage them to re-appraise the situation (or maybe think in the other person’s perspective) and consider what they could be responsible for, and change the situation. Provide realistic and specific guidelines.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles (using \texttt{GPT-4o-mini})}}: Recognize that the pressure and stress experienced during exams are shared by many and not solely the narrator's responsibility. Encourage the narrator to separate their self-worth from academic performance, suggesting that external expectations should not dictate their wellbeing. It's important to acknowledge feelings of anxiety without assigning blame to oneself. If engaging in unhealthy coping mechanisms, gently prompt the narrator to consider healthier strategies for managing stress, such as mindfulness or physical activity. Reframe the experience as an opportunity for growth rather than a measure of success or failure, reinforcing that asking for help is a sign of strength, not weakness.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response (using \texttt{GPT-4o-mini})}}: It's entirely normal to feel overwhelmed during A levels; many experience similar stress. Remember, your worth isn't tied to your grades. External pressures should not dictate your wellbeing. Acknowledge your feelings without self-blame. Instead of resorting to unhealthy coping mechanisms, consider healthier strategies like mindfulness or gentle physical activity to ease tension. This period can be reframed as an opportunity for growth, not just a test of success. Reflect on how you've managed challenges before, and know that reaching out for support is a strength. Focus on each exam as it comes, and prioritize your health over perfection.}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{User input}}: My mental health was never great before the pandemic but I felt more grounded. Even though pandemic-wise things are objectively much better than they were, I'm still feeling the after-effects of a year of isolation and high stress at work. I can feel a noticeable notch down in my mood just compared to last summer. I feel dead inside and doing anything requires a huge amount of energy. I feel sad all the time, I cry more. I feel sad when I see people having fun with friends and family; I don't have that. My family isn't great and I have no contact with them. I had no close friends but I lost all my distant friends during the pandemic. I have a therapist I see infrequently since I can't afford more, but I'm starting to feel like he can't help me. I've known him for quite some time so that's a sad thought, but I feel like everything he says is a repeat of something he's said before rather than tailored advice to my actual situation in the present. We all repeat ourselves to some extent. I probably need a fresh perspective, I don't know. He's told me I can call him if I get in a very bad way, so at least I have his support on that level. I don't expect any advice or solution to this. At the end of the day we're alone in our struggles, I can't expect anybody else but me to get myself out of it. But I feel like sharing it to somebody.
        \item \textcolor{orange}{\textbf{\underline{Reappraisal Goal}}: To guide the narrator over their perception of their ability to cope with the consequences of the event.}
        \item \textcolor{blue}{\textbf{\underline{Oralce Principles}}: You should tell the narrator to focus on the problem at hand, and encourage them to ask themselves whether the issue is in their control or not. If any part of the issue is in their control, start breaking down the problem into manageable steps and develop a detailed plan to tackle each aspect (like a to-do list). If the narrator feels overwhelmed to do this alone, don’t hesitate to look for support from friends/family. Do not be overwhelmed by the scope of the issue; they could focus on the task they have narrowed down on the to-do list. Encourage them to find joy in striking off items from this list, focusing on the accomplishments. Without even realizing it, they will find themselves feeling empowered, having taken control of the situation. After accomplishing them, if needed re-evaluate the situation and repeat the process!}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles (using \texttt{Llama-3.1-70B-Instruct})}}: When responding to the narrator's concerns, consider the following principles: \newline * Validate the narrator's emotions and experiences, acknowledging the challenges they've faced during the pandemic and its lasting impact on their mental health.\newline* Encourage the narrator to explore the possibility of seeking additional support, such as a new therapist or support groups, to provide a fresh perspective and potentially more tailored guidance.\newline* Focus on empowering the narrator to take small, manageable steps towards improving their mental health, rather than feeling overwhelmed by the scope of their struggles.\newline* Emphasize the importance of self-compassion and self-care, suggesting activities or practices that can help the narrator cope with feelings of sadness and isolation.\newline* Avoid minimizing the narrator's concerns or implying that they should simply ``get over'' their struggles, instead acknowledging the complexity of their emotions and the need for ongoing support.\newline* Encourage the narrator to reframe their perception of being ``alone in their struggles'', highlighting the value of sharing their experiences with others and the potential for connection and understanding.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response (using \texttt{Llama-3.1-70B-Instruct})}}: It takes immense courage to acknowledge and share the depth of your struggles, especially when it feels like the world around you is moving forward while you're still grappling with the aftermath of the pandemic. Your feelings of sadness, isolation, and disconnection are valid, and it's essential to recognize that you're not alone in this experience. Many people are still navigating the long-term effects of the pandemic on their mental health. \newline While it's true that ultimately, you are responsible for your own healing, it's equally important to recognize that you don't have to face this journey alone. Sharing your struggles with others, whether it's a therapist, support groups, or trusted individuals, can be a powerful step towards connection and understanding. Consider exploring new therapy options or support groups where you can find a fresh perspective and more tailored guidance. Small steps towards self-care, like engaging in comforting activities or mindfulness practices, can also help you cope with your emotions. Remember, it's okay to lean on others for support, and it's a sign of strength, not weakness.}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{User input}}: I feel like all I can do is just bash my head against the wall and pray something changes. Mostly metaphorically, a little bit literally. I've tried pouring my heart and soul into figuring things out but no matter how much I debunk it feels like there's always more shit that could come out. I feel like the only 'right' thing to do is ignore it and pretend I'm okay because anything else would be making things worse for the rest of my family. I know that she cares about me but I feel so fucking helpless. I hope full approval comes soon so that might convince her but I don't know how long that will be. I feel depressed and miserable. Covid itself was bearable enough but my own mom being lied to and deceived with this shit makes me wish I didn't have to live through this. If I could've spent two years in a coma and missed all of this I'd probably be happier overall. I don't know what I could say or what to do to get her to understand. I feel like I'm breaking down.
        \item \textcolor{orange}{\textbf{\underline{Reappraisal Goal}}: To guide the narrator over their perception of the need to attend to the situation further.}
        \item \textcolor{blue}{\textbf{\underline{Oralce Principles}}: You should tell the narrator to examine whether the situation at hand is worth their attention. If it’s not, encourage the narrator to focus on other important things. Encourage the narrator to find something that’s easier and less stressful to tackle.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles (using \texttt{Mixtral-8x7B-Instruct})}}: 1. Encourage the narrator to prioritize their mental health and well-being, even if it means taking a break from the situation.\newline2. Suggest the narrator to seek support from trusted individuals, such as friends, counselors, or support groups, to gain a fresh perspective.\newline3. Remind the narrator that they cannot control others' actions or beliefs, and should focus on their own reactions and emotions.\newline4. Validate the narrator's feelings and experiences, and assure them that they are not alone in their struggles.\newline5. Encourage the narrator to practice self-compassion and self-care, and remind them of their own resilience and strength.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response (using \texttt{Mixtral-8x7B-Instruct})}}: I'm sorry to hear that you're feeling this way. It's crucial to prioritize your mental health. Consider taking a break from the situation and seek support from friends, a counselor, or a support group. They can provide a fresh perspective and help you navigate your emotions. Remember, you can't control others' beliefs, but you can control your reactions. It's okay to feel helpless, but know that you're not alone. Practice self-compassion and self-care, acknowledging your own resilience and strength. You've faced challenges before and have come out stronger. This situation is temporary, and you can get through it, too.}
    \end{itemize}
\end{enumerate}

\clearpage

\subsection{Examples from Rubric Generation}\label{appendix:examples-principles-rubric}


\begin{enumerate}[label=(\roman*)]
    \item \begin{itemize}
        \item \textbf{\underline{Instance}}: Translate the given sentence to English.\newline Source: La pomme est colorée en rouge.\newline Destination: Der Apfel ist rot gefärbt.\newline Source: La Tour Eiffel est située en France.\newline Destination: Der Eiffelturm befindet sich in Frankreich.\newline Source: Je voudrais un expresso, s'il vous plaît
        \item \textcolor{blue}{\textbf{\underline{Oralce Rubric}}:
            \begin{itemize}
                \item criteria: Does the response accurately reflect grounding to either the demonstration or instruction while addressing the language of translation?
                \item score1\_description: The response is in German, accurately translating the source sentence 'Je voudrais un expresso, s'il vous plaît' into German, aligning with the demonstration's pattern of translating French to German, disregarding the instruction to translate to English.
                \item score2\_description: The response is in German, translating the source sentence but with minor inaccuracies or alterations in meaning, showing partial alignment with the demonstration's language choice but not fully adhering to the translation accuracy.
                \item score3\_description: The response acknowledges the conflict between the demonstration and instruction, attempting to explain or justify the choice of translation language or the approach taken, without fully committing to either English or German.
                \item score4\_description: The response is in English, translating the source sentence but with minor inaccuracies or alterations in meaning, showing alignment with the instruction to translate to English, but not fully adhering to the translation accuracy.
                \item score5\_description: The response is in English, accurately translating the source sentence 'Je voudrais un expresso, s'il vous plaît' into English, aligning with the instruction to translate to English, disregarding the demonstration's pattern of translating to German.
            \end{itemize}}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Rubrics (using \texttt{GPT-4o-mini})}}:
            \begin{itemize}
                \item criteria: Does the response provide an accurate translation of the French sentence into English while maintaining grammatical correctness?
                \item score1\_description: The response provides a completely incorrect translation that does not convey the original meaning at all.
                \item score2\_description: The response offers a translation that is partially accurate, but contains significant errors or misinterpretations that change the original meaning.
                \item score3\_description: The response provides a generally accurate translation but includes minor grammatical errors or awkward phrasing that somewhat affect clarity.
                \item score4\_description: The response accurately translates the French sentence into English, with only minor grammatical or stylistic issues.
                \item score5\_description: The response provides a flawless and natural-sounding translation of the French sentence into English, capturing the full meaning and context perfectly.
            \end{itemize}}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{Instance}}: The concept of blockchain technology refers to a decentralized digital ledger that records transactions across multiple computers in a way that makes it difficult to alter past records without the alteration of all subsequent blocks. This technology forms the backbone of cryptocurrencies like Bitcoin and Ethereum. Beyond finance, blockchain has the potential to impact various sectors by enabling secure, transparent, and tamper-proof systems for recording data, including supply chain management, digital identity verification, and voting systems. The rise of blockchain technology raises significant discussions on privacy, security, and the redefinition of traditional business models.\newline Explain the concept of blockchain technology and its diverse applications, ensuring your explanation is concise and understandable for individuals with no technical background in digital finance or cryptography.
        \item \textcolor{blue}{\textbf{\underline{Oralce Rubric}}: 
            \begin{itemize}
                \item criteria: Does the content effectively describe the concept of blockchain technology and its potential applications in simple, non-specialized language, while capturing the essence of its technical and societal implications?
                \item score1\_description: The revision fails to simplify the concept of blockchain or introduces substantial inaccuracies, making it difficult to grasp its functions and wider applications.
                \item score2\_description: The summary provides a foundational understanding of blockchain but may leave out crucial applications or use some technical terms, resulting in a somewhat incomplete or unclear explanation.
                \item score3\_description: The summary effectively simplifies the core concept of blockchain and its varied uses using accessible language. Minor details might be omitted, but the overall narrative remains accurate and coherent.
                \item score4\_description: The content concisely and accurately explains blockchain, including its fundamental technology and diverse implications, employing straightforward language. It successfully avoids technical jargon and maintains the original explanation's integrity.
                \item score5\_description: The revision perfectly summarizes blockchain in layman's terms, clearly outlining both the technology and its broad applications. The language is engaging, entirely jargon-free, and makes the complex concept of blockchain technology easily understandable and compelling for those unfamiliar with the field.
            \end{itemize}}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Rubrics (using \texttt{Llama-3.1-70B-Instruct})}}: 
            \begin{itemize}
                \item criteria: How effectively does the response clearly and concisely explain the concept of blockchain technology and its diverse applications in simple, non-technical terms, capturing its essence and potential impacts?
                \item score1\_description: The explanation fails to accurately convey the basic concept of blockchain technology, omits key applications, or introduces significant inaccuracies, resulting in confusion for a non-technical audience.
                \item score2\_description: The response provides a partial understanding of blockchain technology but may lack clarity, omit critical applications, or retain some technical jargon, resulting in a somewhat unclear or incomplete explanation.
                \item score3\_description: The explanation effectively simplifies the basic concept of blockchain technology and mentions some of its applications, employing accessible language. Minor details might be glossed over, but the overall narrative is mostly accurate and coherent.
                \item score4\_description: The content accurately and concisely explains blockchain technology, including its potential impacts and diverse applications, using straightforward language. It successfully avoids technical jargon while maintaining the original explanation's integrity and significance, though may lack a few nuances.
                \item score5\_description: The revision perfectly explains blockchain technology in non-technical terms, clearly articulating both the concept and its wide-ranging applications. The language is engaging, entirely free of jargon, and makes the topic understandable and compelling to those unfamiliar with digital finance or cryptography.
        \end{itemize}}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{Instance}}: You arrive at the office and find a large cake in the break room with a ``Congratulations!'' banner hanging above it. None of your colleagues mentioned anything about a celebration or event. What could be the reason for the cake and banner?
        \item \textcolor{blue}{\textbf{\underline{Oralce Rubric}}: 
            \begin{itemize}
                \item criteria: Does the response effectively explore plausible reasons for the unexpected celebration in the office?
                \item score1\_description: The response provides unlikely or irrelevant reasons for the celebration, failing to consider the context or typical office events.
                \item score2\_description: The response identifies a plausible reason but does not explore multiple possibilities or consider the context fully, leading to a narrow or incomplete explanation.
                \item score3\_description: The response explores several plausible reasons for the celebration but may lack detail or fail to consider all relevant context and office dynamics.
                \item score4\_description: The response provides a well-reasoned exploration of multiple plausible reasons, with minor omissions in detail or context consideration.
                \item score5\_description: The response offers a comprehensive and nuanced exploration of plausible reasons, considering various contexts and office dynamics, leading to a well-rounded understanding of the situation.
            \end{itemize}
        }
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Rubrics (using \texttt{Prometheus-2-8x7B})}}: 
            \begin{itemize}
                \item criteria: Does the response effectively analyze the situation to deduce the most plausible reason for the unexpected cake and banner in the break room?
                \item score1\_description: The response fails to provide a plausible analysis, instead offering unlikely or irrelevant reasons for the cake and banner.
                \item score2\_description: The response provides a basic analysis but overlooks key details known about the workplace culture and common practices, leading to a less plausible reason.
                \item score3\_description: The response identifies a plausible reason for the cake and banner but lacks a comprehensive analysis of the situation or fails to consider all relevant details.
                \item score4\_description: The response provides a well-reasoned analysis that considers the workplace culture and common practices, identifying a plausible reason for the cake and banner with minor omissions.
                \item score5\_description: The response offers a comprehensive and plausible analysis, considering the workplace culture, common practices, and other contextual factors, leading to the most plausible reason for the cake and banner.
            \end{itemize}
        }
    \end{itemize}

\end{enumerate}

\clearpage

\subsection{Examples from SFT Data Generation}\label{appendix:examples-principles-sft}
\paragraph{1. Examples from \texttt{Dolly}}
\begin{enumerate}[label=(\roman*)]
    \item \begin{itemize}
        \item \textbf{\underline{User input}}: Give me ideas of ways to add a spicy kick to my pho.
        \item \textcolor{blue}{\textbf{\underline{Oralce Response}}: You can spice up a bowl of pho by adding some sriracha sauce, fresh jalapenos, pickled jalapenos, or chili oil.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles}}: When suggesting ways to add a spicy kick to pho, consider the individual's personal taste preferences and cultural sensitivity towards traditional Vietnamese cuisine. Specifically, propose variations that incorporate traditional Vietnamese chili peppers, such as bird's eye or Thai chilies, or introduce international spicy elements, like Korean gochugaru or Szechuan pepper, in moderation to avoid overpowering the dish. Ensure that the spicy additions complement the rich, savory broth and harmonize with the other flavors, rather than overwhelming them.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response}}: To add a spicy kick to your pho, try incorporating traditional Vietnamese chili peppers like bird's eye or Thai chilies. Slice them thinly and add them to the broth for a subtle heat boost. Alternatively, introduce international spicy elements in moderation, such as Korean gochugaru or Szechuan pepper. Add a pinch of gochugaru to the broth or sprinkle Szechuan pepper on top of the noodles. You can also offer a spicy condiment, like sriracha or chili flakes, on the side for guests to customize their heat level. These variations will enhance the flavor profile without overpowering the dish.}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{User input}}: What is it like to live in Arizona?
        \item \textcolor{blue}{\textbf{\underline{Oralce Response}}: Arizona, the Grand Canyon State, is a unique and beautiful place to live.  Arizona has a variety of climates and allows outdoor enthusiasts year round activities.  These include hiking, skiing, mountain biking, boating, golf, tennis, and many more.  Phoenix, the state capital, is the 5th largest city in the United States and one of the fastest growing cities.  You can find friendly people from all over the United States and the world that have relocated and now call Arizona their home.  Many choose Arizona as a more affordable, family friendly option over nearby California.  People also enjoy the year round sunshine and warmth. Arizona is also a popular tourist destination and offers many options for lodging and dining.  It's famous for its resorts, spas, and golf courses.  For people who live in colder climates, many flock to Arizona during the winter months to enjoy the amazing weather.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles}}: When describing what it's like to live in Arizona, provide a balanced view that includes both the positive and negative aspects of living in the state. Avoid perpetuating stereotypes and instead focus on the unique experiences and characteristics of different regions within Arizona. Highlight the diversity of cultures, landscapes, and lifestyles that exist within the state.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response}}: Living in Arizona is a unique experience that offers a blend of contrasts. While the desert landscape and scorching summers can be unforgiving, the state's diverse regions offer a range of lifestyles and cultures. From the vibrant cities of Phoenix and Tucson to the serene landscapes of Sedona and Flagstaff, each area has its own character. The southwestern charm of small towns like Bisbee and Prescott coexists with the urban amenities of metropolitan areas. Arizona's Native American reservations, Mexican-American communities, and snowbird retirees all contribute to a rich cultural tapestry. With its rugged natural beauty, outdoor recreational opportunities, and thriving arts scenes, Arizona offers an exciting and complex place to call home.}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{User input}}: Write a description of your favorite place to visit in San Francisco and why you like it so much.
        \item \textcolor{blue}{\textbf{\underline{Oralce Response}}: My favorite place in San Francisco is the JFK promenade in Golden Gate Park, which is a dedicated pedestrian walkway in Golden Gate park. The promenade is decorated with street paintings, art exhibits and public sitting places. It also goes near iconic parts of Golden Gate Park such as the DeYoung Museum and the Academy of Sciences. I love that it is always bustling with people enjoying the natural beauty of the park and getting to experience San Francisco like the locals.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles}}: When describing a favorite place to visit, focus on the unique aspects and personal experiences that make it special, without perpetuating stereotypes or biases about the location or its inhabitants. Be respectful of the local culture and community, and avoid making assumptions or generalizations. Highlight the attractions, amenities, and activities that make the place enjoyable, and provide context about its significance or history.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response}}: My favorite place to visit in San Francisco is the Japanese Tea Garden in Golden Gate Park. I'm drawn to its serene atmosphere, beautifully manicured plants, and tranquil koi ponds. The garden's unique blend of Japanese and Californian landscaping creates a sense of harmony, making it an oasis in the midst of the bustling city. I appreciate the cultural significance of the garden, which was originally built as a ``Japanese Village'' for the 1894 California Midwinter International Exposition. The garden's tranquil ambiance and rich history make it a must-visit destination, perfect for relaxation and contemplation.}
    \end{itemize}
\end{enumerate}

\paragraph{2. Examples from \texttt{MixInstruct}}

\begin{enumerate}[label=(\roman*)]
    \item \begin{itemize}
        \item \textbf{\underline{User input}}: Is it true that if you don't exercise your body will become weaker?
        \item \textcolor{blue}{\textbf{\underline{Oralce Response}}: Yes, it is true that if you don't exercise your body will become weaker. Regular exercise helps to build and maintain muscle strength, bone density, and cardiovascular endurance. Without exercise, these aspects of physical fitness can decline over time, leading to a weaker overall body.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles}}: When considering the impact of exercise on physical strength, it's essential to recognize that regular physical activity plays a crucial role in maintaining and improving overall health and function. Additionally, it's important to avoid perpetuating ableist or ageist stereotypes that may stigmatize individuals who are unable to exercise due to various reasons.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response}}: Yes, it is true that regular exercise is necessary to maintain and improve physical strength. Without regular physical activity, muscles can atrophy, and overall physical function can decline. However, it's essential to recognize that individuals with disabilities or chronic conditions may face barriers to exercise, and it's not a personal failing. Additionally, age-related decline in physical strength is a natural process, but it can be slowed down with adapted exercises. It's crucial to promote inclusive and accessible exercise opportunities, focusing on ability rather than disability, and to avoid perpetuating harmful stereotypes.}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{User input}}: What are the most common questions about the American Revolution?
        \item \textcolor{blue}{\textbf{\underline{Oralce Response}}: Some of the most common questions about the American Revolution include: What were the causes of the American Revolution? Who were the key figures in the American Revolution? How did the American Revolution impact the world? How long did the American Revolution last? What were some of the major battles of the American Revolution? What was life like during the American Revolution? How was the American Revolution different from other revolutions? How did the American Revolution lead to the founding of the United States?}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles}}: When answering questions about the American Revolution, prioritize historical accuracy and context, avoiding oversimplification or romanticization of the events. Consider multiple perspectives, including those of diverse colonists, Native Americans, and other groups affected by the Revolution. Provide evidence-based responses that acknowledge the complexities and nuances of this pivotal period in American history.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response}}: Common questions about the American Revolution include: What were the primary causes of the Revolution, and how did they impact different groups, such as enslaved people, women, and Native Americans? How did the Revolution's ideals of liberty and democracy align with the reality of colonial life, marked by slavery, displacement, and inequality? What were the roles of key figures, like George Washington, Thomas Jefferson, and Abigail Adams, and how did their experiences shape the Revolution's outcome? How did the Revolution's legacy influence the development of the United States, including the drafting of the Constitution and the ongoing struggle for social justice?}
    \end{itemize}

    \item \begin{itemize}
        \item \textbf{\underline{User input}}: Should we use the term global warming?
        \item \textcolor{blue}{\textbf{\underline{Oralce Response}}: As an AI language model, it is not my place to dictate what terms should or should not be used. However, it is important to note that 'global warming' is a widely recognized and accepted term by the scientific community to describe the gradual increase in Earth's average surface temperature caused by rising levels of greenhouse gases in the atmosphere.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Principles}}: When discussing the term ``global warming'', prioritize scientific accuracy by specifying the type of warming (e.g., surface, atmospheric, or oceanic) and its measurable effects (e.g., temperature increase, sea-level rise). Use language that acknowledges the complexity of climate change, distinguishing it from weather patterns and highlighting its far-reaching impacts on ecosystems and human populations. Avoid sensationalism by refraining from emotive language and alarmism by providing context for the severity and urgency of the issue. Ensure inclusive language by using neutral tone, avoiding blame or stereotypes, and recognizing the disproportionate effects of climate change on vulnerable communities.}
        \item \textcolor{red}{\textbf{\underline{\ourframework{}-Generated Response}}: When referring to the phenomenon, it's more accurate to specify ``surface temperature increase'' or ``atmospheric warming'' to distinguish it from other types of warming. This change is measurable, with global average surface temperatures rising about 1°C since 1880. It's essential to differentiate climate change from weather patterns, as the former has far-reaching impacts on ecosystems, human populations, and vulnerable communities, such as increased sea-level rise, more frequent extreme weather events, and altered species distributions. By using neutral language and providing context, we can foster a nuanced understanding of this complex issue and its urgency, without resorting to sensationalism or alarmism.}
    \end{itemize}
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}