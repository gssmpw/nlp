@inproceedings{bourtoule2021machine,
  title={Machine unlearning},
  author={Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  year={2021},
}

@article{conmy2023towards,
  title={Towards automated circuit discovery for mechanistic interpretability},
  author={Conmy, Arthur and Mavor-Parker, Augustine and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adri{\`a}},
  journal={Neurips},
  year={2023}
}

@inproceedings{dang2021right,
  title={Right to be forgotten in the age of machine learning},
  author={Dang, Quang-Vinh},
  booktitle={Advances in Digital Science: ICADS 2021},
  year={2021},
}

@article{dou2024avoiding,
  title={Avoiding Copyright Infringement via Machine Unlearning},
  author={Dou, Guangyao and Liu, Zheyuan and Lyu, Qing and Ding, Kaize and Wong, Eric},
  journal={arXiv preprint arXiv:2406.10952},
  year={2024}
}

@article{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}

@article{liu2024machine,
  title={Machine unlearning in generative ai: A survey},
  author={Liu, Zheyuan and Dou, Guangyao and Tan, Zhaoxuan and Tian, Yijun and Jiang, Meng},
  journal={arXiv preprint arXiv:2407.20516},
  year={2024}
}

@article{liu2024protecting,
  title={Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench},
  author={Liu, Zheyuan and Dou, Guangyao and Jia, Mengzhao and Tan, Zhaoxuan and Zeng, Qingkai and Yuan, Yongle and Jiang, Meng},
  journal={arXiv preprint arXiv:2410.22108},
  year={2024}
}

@article{liu2024shield,
  title={SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation},
  author={Liu, Xiaoze and Sun, Ting and Xu, Tianyang and Wu, Feijie and Wang, Cunxiang and Wang, Xiaoqian and Gao, Jing},
  journal={arXiv preprint arXiv:2406.12975},
  year={2024}
}

@article{liu2024towards,
  title={Towards safer large language models through machine unlearning},
  author={Liu, Zheyuan and Dou, Guangyao and Tan, Zhaoxuan and Tian, Yijun and Jiang, Meng},
  journal={arXiv preprint arXiv:2402.10058},
  year={2024}
}

@article{maini2024tofu,
  title={Tofu: A task of fictitious unlearning for llms},
  author={Maini, Pratyush and Feng, Zhili and Schwarzschild, Avi and Lipton, Zachary C and Kolter, J Zico},
  journal={arXiv preprint arXiv:2401.06121},
  year={2024}
}

@article{michel2019sixteen,
  title={Are sixteen heads really better than one?},
  author={Michel, Paul and Levy, Omer and Neubig, Graham},
  journal={Neurips},
  year={2019}
}

@article{nasr2023scalable,
  title={Scalable extraction of training data from (production) language models},
  author={Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  journal={arXiv preprint arXiv:2311.17035},
  year={2023}
}

@article{pochinkov2024dissecting,
  title={Dissecting Language Models: Machine Unlearning via Selective Pruning},
  author={Pochinkov, Nicholas and Schoots, Nandi},
  journal={arXiv preprint arXiv:2403.01267},
  year={2024}
}

@article{yao2023large,
  title={Large language model unlearning},
  author={Yao, Yuanshun and Xu, Xiaojun and Liu, Yang},
  journal={arXiv preprint arXiv:2310.10683},
  year={2023}
}

@article{zhang2023counterfactual,
  title={Counterfactual memorization in neural language models},
  author={Zhang, Chiyuan and Ippolito, Daphne and Lee, Katherine and Jagielski, Matthew and Tram{\`e}r, Florian and Carlini, Nicholas},
  journal={Neurips},
  year={2023}
}

