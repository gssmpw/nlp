\section{Related Work}
\textbf{Controllable generation.}  Model editing____ alters the model parameters to control the output, making it a powerful method for controllable generation. Another important category in controllable generation is fine-tuning, which includes Supervised Fine-Tuning (SFT,____) and Reinforcement Learning from Human Feedback (RLHF,____). These methods typically require altering model weights, incurring substantial resources and costs for computation.
 
\noindent \textbf{Activation intervention} at inference time is an emerging technique for controllable generation____. Unlike model editing and fine-tuning techniques, the inference time intervention does not require altering the model parameters, leading to cheaper computational costs. ____ proposes a headwise intervention method for eliciting truthful generated answers of a language model. ____ considers the optimal transport plan between two empirical distributions to carry out the intervention. LoFit____ identifies a specific subset of attention heads crucial for learning a particular task. It then fine-tunes the intervention vectors in those chosen heads. Another recent work ____ considers doing intervention activation using modified householder transformation based on the linear probe framework. 

\noindent \textbf{Region Modeling in LM.}
Various works aim to reveal how the semantic features influence the `region' of embedding vectors in the transformer-based LM. The work ____ utilizes mean-field theoretic manifold analysis to connect the geometry of feature representations with the linear separability of classes. ____ identifies stable regions in the residual stream of Transformers, where the model output remains insensitive to small activation changes but exhibits high sensitivity at the region boundaries. However, most prior works focus on specific findings in region modeling and overlook the potential of enhancing activation intervention through transport between two regions.

\noindent \textbf{Low-Rank Optimization} is widely studied in machine learning, statistics, and signal processing ____. The motivation for formulating problems into low-rank optimization in several applications lies in two folds: the nature of the low-rank property of the ground truth and the goal for achieving lightweight complexity in algorithm design ____.  
The low-rank concept has also been applied to LM model-editing, fine-tuning, and model compression ____.