\section{Discussion}
\label{sec:analysis:finetuning}

\subsection{Hamming Distance vs. Levenshtein Distance}
Recall that in this work, we extend \texttt{TfPf} in two ways.
The first is replacing the original Hamming distance with a Levenshtein distance to allow for insertion and deletion operations.

The second row of Table~\ref{tab:ablation:parts} shows the results when we revert to the original Hamming distance.
While the Levenshtein distance-based model performs better on the C2EC dataset, it degrades the performance on the CSCD-NS dataset, the conventional CSC dataset.

This can be attributed to two factors.
First, the conventional CSC dataset only contains substitution errors; any insertion or deletion will lead to an over-correction.
Second, insertion and deletion operations may compete with replacement operations, leading to mis-corrections.
For example, when deletion is allowed, the model may incorrectly delete a misspelled character instead of replacing it with the correct one.

\input{figures/model_size_results}
\subsection{Effectiveness of Dual-LLM}
\label{sec:analysis:prompt}
The second extension is incorporating a prompt-based LLM probability into the \texttt{TfPf} framework.
The third row of Table~\ref{tab:ablation:parts} shows the results when we remove the prompt-based LLM probability.
We observe large performance drops in both precision and recall on both datasets, indicating that the prompt-based LLM probability is a crucial component of our method.
An interesting question is \textit{why we still need the pure LLM probability when we already have the prompt-based LLM probability}.
The fourth row of Table~\ref{tab:ablation:parts} shows the results when we remove the pure LLM probability.
Removing it leads to performance drops of 11.10 and 5.45 points on the CSCD-NS and C2EC datasets, respectively.
As pointed out in the reinforcement learning perspective in Appendix~\ref{sec:reinforcement_learning_perspective}, the pure LLM probability evaluates fluency and correctness from a pure language model perspective, encouraging the model to generate more fluent and correct sentences.

\subsection{Impact of Different Prompt Templates}
\label{sec:analysis:prompt_template}
In Section~\ref{sec:prompt_template}, we introduce two prompt templates:
a minimal prompt and a detailed prompt with more instructions.
This section investigates the impact of different prompt templates.
Rows 5-7 of Table~\ref{tab:ablation:parts} show the results of using the minimal prompt and the detailed prompt with the base LLM and instruction-tuned LLM.
The results show that base LLM favors the minimal prompt, while instruction-tuned versions prefer the longer and more complex prompt.
Compared to instruction-tuned versions, base LLM is more robust to prompt variations.

\subsection{Impact of the LLM Size}
\label{sec:ablation:size}
To investigate the impact of model size, we conduct experiments across different sizes of the Qwen2.5 series.
The results are shown in Figure~\ref{fig:model_size}.
We observe that our method's performance generally improves with increasing model size.
In contrast, \texttt{TfPf}'s performance does not consistently improve,
indicating that our method better leverages the scale of larger LLMs.
However, on the 0.5B model, which has very limited prompt understanding, \texttt{TfPf} may outperform our method.

\subsection{Performance on Different Error Types}
\label{sec:analysis:error_type}
\input{figures/type_results}
Figure~\ref{fig:error_edit_types} shows the performance across different error types.
Our method outperforms baselines on all error types.
The difficulty levels of different error types vary.
Substitution (misspelling) errors are the easiest to correct, with all methods achieving relatively high performance.
Redundant errors are the most challenging.
This is mainly because models tend to add optional characters to the error-free sentence, leading to over-correction.
An example of this is given in Appendix~\ref{subsec:qualitative_analysis}.

\subsection{More Discussion}
Due to space limitations, some interesting discussions are included in Appendix~\ref{app:more_discussion}.
These include:
\begin{inparaenum}[\itshape a)]
    \item Performance of our method on other LLM families (\ref{app:other_llm}),
    \item Investigation of beam size impact (\ref{app:beam_size}),
    \item Ablation study on length reward and faithfulness reward adopted from \texttt{TfPf} (\ref{app:ablation:two_reward}),
    \item A fair comparison with supervised fine-tuning on \texttt{Qwen1.5} series (\ref{app:supervised_fine_tuning}), and
    \item Runtime analysis (\ref{app:runtime}).
\end{inparaenum}
