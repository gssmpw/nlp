\section*{Limitations}
There are several limitations in this work that we plan to investigate and address in future work.

\paragraph{Research Scope}
The scope of this study is limited to Chinese character error correction. However, we believe that with some modifications, our approach can be applied to other languages and more complex tasks like grammatical error correction and sentence simplification.
We plan to extend our approach to these areas in future work.

In this paper, we focus on evaluating LLM performance during inference under zero-shot or few-shot scenarios.
When sufficient annotated data is available, how to effectively utilize it to improve performance of our approach is an interesting question we plan to explore in future work.

Moreover, limited by computational resources, we have not tested our approach on larger models.
We believe that models with more parameters would also benefit from our approach.

\paragraph{Flexibility}
Our approach requires access to the model's probability distribution, which makes it unable to be directly applied to API-accessed models that are often more powerful.
However, given the flexibility of prompt-based LLMs, we believe there is potential to leverage results from API-accessed models to further improve performance.

\section*{Ethics Statement}
Our proposed dataset is built upon existing publicly available datasets. We have properly cited the original datasets in our paper and ensured that our use is consistent with their original intent.
For works that use our dataset, we require them to appropriately cite the original datasets.

For this work, we manually verified the dataset to ensure quality.
We recruited four graduate students who are native Chinese speakers with high Chinese proficiency.
The verification process took about 16 working hours per annotator.
Each annotator was compensated at a rate of Â¥25 per hour.
