\section{The C2EC Task}
\label{sec:gcsc_benchmark}
\input{tables/data_statistics_main}
\subsection{Task Definition}
Given an input sentence $\substring{x} = x_1,x_2\cdots{}x_n$, the task of C2EC aims to correct character errors and produce a corrected sentence $\substring{y} = y_1,y_2\cdots{}y_m$. Unlike conventional CSC, where input and output lengths must match, C2EC allows $\substring{y}$ to have a different length from $\substring{x}$. In addition to character substitutions, C2EC addresses two additional error types:
\begin{inparaenum}[\itshape a)]
    \item \textbf{Missing Character}: where characters are missing from the input, e.g., ``羽球'' missing ``毛'' from ``羽毛球'' (\textit{badminton}).
    \item \textbf{Redundant Character}: where unexpected extra characters appear in the input, e.g., the extra ``矛'' in ``羽\wrong{矛}毛球''.
\end{inparaenum}

\subsection{Construction of C2EC Dataset}
Rather than using rule-based synthesis like \citet{he-etal-2023-umrspell}, we construct our dataset from existing datasets to better reflect real-world error patterns.

\paragraph{Data Selection and Division}
We build the C2EC dataset from two high-quality sources:
\begin{inparaenum}[\itshape a)]
    \item \textbf{CCTC} \cite{wang-etal-2022-cctc}: A comprehensive dataset of \textasciitilde{}25,000 sentences covering both character errors and complex errors from diverse sources. While this dataset includes C2E errors, it was not specifically designed to focus on C2EC.
    \item \textbf{Lemon} \cite{wu-etal-2023-rethinking}: A CSC dataset containing \textasciitilde{}500 sentences with missing and redundant character errors. Although it contains sentences with C2E errors, previous works excluded these when evaluating CSC methods \cite{wu-etal-2023-rethinking,liu-etal-2023-chinese,zhou-etal-2024-simple,li-etal-2024-cllm}.
\end{inparaenum}
We use CCTC's training set for development and combine the test sets from both CCTC and Lemon for testing.

\paragraph{Data Resampling}
To achieve a more balanced and natural error distribution, we perform two resampling steps:
\begin{inparaenum}[\itshape a)]
    \item We balance the ratio of correct to incorrect sentences to 1:1, reducing the original 91\% correct sentence bias in CCTC.
    \item We adjust Lemon's error type distribution to match CCTC's (\textasciitilde{}75\% substitution, \textasciitilde{}25\% missing/redundant), addressing the bias of Lemon toward substitution errors (95\%).
\end{inparaenum}
Throughout resampling, we maintain balanced distributions across domains and correct-incorrect sentence pairs.

\paragraph{Quality Control}
To maintain focus on character-level errors and keep the dataset clean, we apply two data cleaning processes:
\begin{inparaenum}[\itshape a)]
    \item Automatically remove sentences with complex errors, specifically those errors that involve continuous insertions or deletions (this removed 91 and 90 sentences from the development and test sets, respectively).
    \item Manually verify sentences by native Chinese speakers to remove sentences that:
    \begin{inparaenum}[\itshape i.]
        \item Have incorrect annotations;
        \item Have complex grammatical errors;
        \item Have multiple reasonable corrections;
        \item Are ambiguous or difficult to understand.
    \end{inparaenum}
\end{inparaenum}
Four native Chinese speakers familiar with the CSC task performed the manual verification.
Each sentence was reviewed by at least two annotators, with a third resolving any disagreements.
The inter-annotator agreement reached 97.08\%.
This process removed 111 test set and 31 development set sentences.\footnote{Several examples of discarded sentences are provided in the appendix~\ref{sec:discard_cases}.}

\subsection{Data Statistics}
The final dataset, as shown in Table~\ref{tab:data_statistics_main}, contains 1,995 development and 5,711 test sentences, with approximately half being error-free. The development set contains 1,098 errors (\textasciitilde{}1.1 per erroneous sentence), while the test set has 3,301 errors (\textasciitilde{}1.2 per erroneous sentence).
In the test set, 72.6\% of errors are misspellings, 14.0\% are redundant characters, and 13.4\% are missing characters.
