\begin{table*}[t!]
    \centering
    \renewcommand{\arraystretch}{0.95}
    \scalebox{0.9}{
        \begin{NiceTabular}{lccccccccc;c;c}
            \toprule
            \Block[l]{2-1}{\textbf{Model}}   & \Block[c]{2-1}{\textbf{Size}} & \Block[c]{2-1}{\textbf{Method}} & \Block[c]{1-7}{\textbf{Lemon}} &                &                &                &                &                &                & \Block[c]{1-1}{\textbf{CSCD-NS}} & \Block[c]{2-1}{\textbf{Avg.}} \\
                                             &                               &                                 & \textit{Car}                   & \textit{Cot}   & \textit{Enc}   & \textit{Gam}   & \textit{Mec}   & \textit{New}   & \textit{Nov}   & \textit{test}                    &                               \\
            \midrule
            \texttt{SCOPE}                   & \texttt{0.1B}                 & \texttt{SFT-F}                  & 50.71                          & 54.89          & 45.23          & 24.74          & 44.44          & 48.72          & 33.17          & 71.70                            & 46.70                         \\
            \hdashedline
            \Block[l]{4-1}{\texttt{Qwen1.5}} & \Block[c]{4-1}{\texttt{7B}}   & \texttt{SFT-L}                  & 53.38                          & 56.55          & 54.44          & 37.33          & 59.21          & 58.96          & 39.12          & 68.66                            & 53.46                         \\
                                             &                               & \texttt{SFT-L}\rlap{$^\dagger$} & 53.87                          & 58.04          & 54.57          & 37.43          & 61.16          & 60.07          & 41.42          & \textbf{71.64}                   & 54.77                         \\
                                             &                               & \texttt{TfPf}                   & 53.88                          & 61.68          & 51.46          & 38.87          & 57.66          & 60.97          & 44.97          & 58.27                            & 53.47                         \\
                                             &                               & \texttt{OUR}                    & \textbf{61.57}                 & \textbf{69.10} & \textbf{63.34} & \textbf{48.50} & \textbf{65.34} & \textbf{68.89} & \textbf{50.27} & 67.25                            & \textbf{61.78}                \\
            \hdashedline
            \Block[l]{4-1}{\texttt{Qwen1.5}} & \Block[c]{4-1}{\texttt{14B}}  & \texttt{SFT-L}                  & 54.56                          & 56.82          & 53.44          & 32.59          & 58.89          & 63.32          & 40.58          & 72.63                            & 54.10                         \\
                                             &                               & \texttt{SFT-L}\rlap{$^\dagger$} & 57.54                          & 60.40          & 56.48          & 38.02          & 65.31          & 64.49          & 43.92          & \textbf{73.80}                   & 57.49                         \\
                                             &                               & \texttt{TfPf}                   & 52.61                          & 62.91          & 50.81          & 36.36          & 54.78          & 60.59          & 42.89          & 58.56                            & 52.44                         \\
                                             &                               & \texttt{OUR}                    & \textbf{62.88}                 & \textbf{70.31} & \textbf{66.24} & \textbf{46.59} & \textbf{66.67} & \textbf{70.15} & \textbf{52.69} & 71.53                            & \textbf{63.38}                \\
            \bottomrule
        \end{NiceTabular}
    }
    \caption{
        Fair comparison between our method and the supervised fine-tuning (SFT) methods.
        We adopt the SFT method from \citet{li-etal-2024-cllm}.
        \texttt{SFT-F} means the full parameter fine-tuning, while \texttt{SFT-L} means fine-tuning with LoRA.
        \texttt{SFT-L}$^\dagger$ means the C-LLM method from \citet{li-etal-2024-cllm}, that conducts the Character-level LoRA fine-tuning after the continuous pre-training.
    }
    \label{tab:main_results:sft}
\end{table*}
