


% \begin{figure*}[tb!] 
%     \centering
%     \begin{subfigure}[b]{0.32\linewidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_ultrachat_spearman.pdf}
%         \caption{Response length prediction.}
%         \label{fig:exp_response_length_hiddenSize}
%     \end{subfigure}
%     \hfill  % Creates horizontal spacing between subfigures
%     \begin{subfigure}[b]{0.32\linewidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_TinyStories_f1_score.pdf}
%         \caption{Character choices prediction.}
%         \label{fig:exp_character_choices_hiddenSize}
%     \end{subfigure}
%     \hfill  % Creates horizontal spacing between subfigures
%     \begin{subfigure}[b]{0.32\linewidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_medmcqa_f1_score.pdf}
%         \caption{Answer confidence prediction.}
%         \label{fig:exp_answer_confidence_hiddenSize}
%     \end{subfigure}
%     \\
%     \begin{subfigure}[b]{0.32\linewidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_gsm8k_spearman.pdf}
%         \caption{Reasoning steps prediction.}
%         \label{fig:exp_reasoning_steps_hiddenSize}
%     \end{subfigure}
%     \hfill  % Creates horizontal spacing between subfigures
%     \begin{subfigure}[b]{0.32\linewidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_commonsense_qa_f1_score.pdf}
%         \caption{Multiple-choice answers prediction.}
%         \label{fig:exp_multiplechoice_answers_hiddenSize}
%     \end{subfigure}
%     \hfill  % Creates horizontal spacing between subfigures
%     \begin{subfigure}[b]{0.32\linewidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_CREAK_f1_score.pdf}
%         \caption{Factual consistency prediction.}
% \label{fig:exp_factual_consistency_hiddenSize}
%     \end{subfigure}
%     \label{fig:exp_hiddenSize}
%     \vspace{-10pt}
%     \caption{Hidden-size study results. Performance of MLP probes plateaus at relatively small hidden sizes ($\leq$128) across all tasks, with structure attributes converging around size 16, content attributes at 32, and behavior attributes at 8. This suggests a hierarchy of pattern complexity, with behavioral patterns being most accessible and content patterns requiring more sophisticated probes.}
% \end{figure*}
\begin{figure*}[tb!] 
    \centering
    % 自定义编号方式
    \renewcommand{\thesubfigure}{\alph{mycounter}}  % 重定义编号

    % 第一行的 (a), (c), (e)
    % \newcounter{mycounter}
    \setcounter{mycounter}{1}
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_ultrachat_spearman.pdf}
        \caption{Response length prediction.}
        \label{fig:exp_response_length_hiddenSize}
    \end{subfigure}
    \hfill
    \setcounter{mycounter}{3}
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_TinyStories_f1_score.pdf}
        \caption{Character choices prediction.}
        \label{fig:exp_character_choices_hiddenSize}
    \end{subfigure}
    \hfill
    \setcounter{mycounter}{5}
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_medmcqa_f1_score.pdf}
        \caption{Answer confidence prediction.}
        \label{fig:exp_answer_confidence_hiddenSize}
    \end{subfigure}
    \\
    % 第二行的 (b), (d), (f)
    \setcounter{mycounter}{2}
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_gsm8k_spearman.pdf}
        \caption{Reasoning steps prediction.}
        \label{fig:exp_reasoning_steps_hiddenSize}
    \end{subfigure}
    \hfill
    \setcounter{mycounter}{4}
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_commonsense_qa_f1_score.pdf}
        \caption{Multiple-choice answers prediction.}
        \label{fig:exp_multiplechoice_answers_hiddenSize}
    \end{subfigure}
    \hfill
    \setcounter{mycounter}{6}
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/exp_hiddenSizeAnalysis_CREAK_f1_score.pdf}
        \caption{Factual consistency prediction.}
        \label{fig:exp_factual_consistency_hiddenSize}
    \end{subfigure}
    \\
    \vspace{-10pt}
    \caption{\label{fig:exp_hiddenSize} Hidden-size study results. Performance of MLP probes plateaus at relatively small hidden sizes ($\leq 128$) across all tasks, with structure attributes converging around size $16$, content attributes at $32$, and behavior attributes at $8$. This suggests a hierarchy of pattern complexity, with behavioral patterns being most accessible and content patterns requiring more sophisticated probes.}
\end{figure*}




\section{Experimental Results}
% \section{Feature Existence: Systematic Evidence from Multi-model, Multi-task Analysis}

In this section, we present experimental results across six tasks, showing that LLM hidden prompt representations encode rich information about upcoming responses and can be used to probe and predict global response attributes.



\paragraph{Insight 1: Models present emergent planning on structural, content, and behavioral attributes, which can be probed with high accuracy (Fig.~\ref{fig:exp_inDataset}).}
Our in-dataset probing experiments (where probes are trained and tested on different splits of the same prompt dataset) reveal that both base and fine-tuned models encode structural, content, and behavioral attributes, with fine-tuned models showing superior performance. 
For structural attributes (response length and reasoning steps; Fig.~\ref{fig:exp_bar_response_length_inDataset}, ~\ref{fig:exp_bar_reasoning_steps_inDataset}), fine-tuned models exhibit strong linear correlations with ground truth, clustering around $y=x$ (with example fitting results shown in Fig.~\ref{fig:exp_response_length_inDataset}, ~\ref{fig:exp_reasoning_steps_inDataset}), while base models show weaker but positive correlations. 
For content and behavior attributes (character choices, multiple-choice answers, answer confidence, and factual consistency; Fig.~\ref{fig:exp_character_choices_inDataset}, ~\ref{fig:exp_multiplechoice_answers_inDataset}, ~\ref{fig:exp_answer_confidence_inDataset}, ~\ref{fig:exp_factual_consistency_inDataset}), both model types demonstrate robust classification performance above random baselines.
These findings also suggest that \textbf{models develop systematic internal planning representations for content or behavior attributes during pre-training, with structure attributes requiring additional reinforcement through fine-tuning.}

\paragraph{Insight 2: The learned patterns generalize across datasets, indicating intrinsic task-related patterns rather than dataset-specific ones (Fig.~\ref{fig:exp_crossDataset}).}
Our cross-dataset experiments (training and testing probes on different prompt datasets for the same task, e.g., GSM8K$\rightarrow$MATH or TinyStories$\rightarrow$ROCStories) demonstrate robust generalization of learned patterns. 
For structural attributes (Fig.~\ref{fig:exp_bar_response_length_crossDataset}, ~\ref{fig:exp_bar_reasoning_steps_crossDataset}), predictions maintain strong positive correlations with target labels despite lower accuracy compared to in-dataset testing (with example fitting results shown in Fig.~\ref{fig:exp_response_length_crossDataset}, ~\ref{fig:exp_reasoning_steps_crossDataset}), with fine-tuned models showing stronger correlations than base models. 
Similarly, for content and behavior attributes (Fig.~\ref{fig:exp_character_choices_crossDataset}, ~\ref{fig:exp_multiplechoice_answers_crossDataset}, ~\ref{fig:exp_answer_confidence_crossDataset}, ~\ref{fig:exp_factual_consistency_crossDataset}), performance remains above baseline in cross-dataset settings.
These results suggest that \textbf{probes capture generalizable task-related patterns rather than merely dataset-specific features, indicating that models may develop intrinsic emergent planning capabilities that transfer across different contexts within the same task domain}.


\begin{figure*}[tb!] 
   \centering
   \begin{subfigure}[b]{0.48\linewidth}
       \centering
       \includegraphics[width=\textwidth]{figures/exp_layerHeatmap_ultrachat_spearman.pdf}
       \caption{Response length prediction (Ultrachat).}
       \label{fig:exp_response_length_layerwise}
   \end{subfigure}
   \hfill  % Creates horizontal spacing between subfigures
   \begin{subfigure}[b]{0.48\linewidth}
       \centering
       \includegraphics[width=\textwidth]{figures/exp_layerHeatmap_gsm8k_spearman.pdf}
       \caption{Reasoning steps prediction (GSM8K).}
       \label{fig:exp_reasoning_steps_layerwise}
   \end{subfigure}
   \\
   \begin{subfigure}[b]{0.48\linewidth}
       \centering
       \includegraphics[width=\textwidth]{figures/exp_layerHeatmap_TinyStories_f1_score.pdf}
       \caption{Character choices prediction (TinyStories).}
       \label{fig:exp_character_choices_layerwise}
   \end{subfigure}
   \hfill  % Creates horizontal spacing between subfigures
   \begin{subfigure}[b]{0.48\linewidth}
       \centering
       \includegraphics[width=\textwidth]{figures/exp_layerHeatmap_commonsense_qa_f1_score.pdf}
       \caption{Multiple-choice answers prediction (CommensenseQA).}
       \label{fig:exp_multiplechoice_answers_layerwise}
   \end{subfigure}
   \\
   \begin{subfigure}[b]{0.48\linewidth}
       \centering
       \includegraphics[width=\textwidth]{figures/exp_layerHeatmap_medmcqa_f1_score.pdf}
       \caption{Answer confidence prediction (MedMCQA).}
       \label{fig:exp_answer_confidence_layerwise}
   \end{subfigure}
   \hfill  % Creates horizontal spacing between subfigures
   \begin{subfigure}[b]{0.48\linewidth}
       \centering
       \includegraphics[width=\textwidth]{figures/exp_layerHeatmap_CREAK_f1_score.pdf}
       \caption{Factual consistency prediction (CREAK).}
       \label{fig:exp_factual_consistency_layerwise}
   \end{subfigure}
   \\
   \vspace{-10pt}
   \caption{\label{fig:exp_layerwise} Layer-wise attribute prediction dynamics. Structural attributes peak mid-layers, content attributes emerge late, and behavioral attributes stabilize early. Layer-wise probing reveals hierarchical organization of planning capabilities, with progressive refinement shaping final outputs.}
\end{figure*}

\paragraph{Insight 3: Emergent planning patterns are salient across models and tasks, extractable with simple MLP probes (Fig.~\ref{fig:exp_hiddenSize}).}
We investigate pattern saliency by varying the hidden size of two-layer MLP probes and measuring their average performance across model layers. Performance plateaus before hidden size $128$ across all datasets, with larger sizes that can even lead to overfitting, indicating pattern saliency. 
The results can also indicate saliency differences across attributes: structure attributes (Fig.~\ref{fig:exp_response_length_hiddenSize}, ~\ref{fig:exp_reasoning_steps_hiddenSize}) reach converges start at around hidden size $16$, content attributes (Fig.~\ref{fig:exp_character_choices_hiddenSize}, ~\ref{fig:exp_multiplechoice_answers_hiddenSize}) plateau around $32$, and behavior attributes (Fig.~\ref{fig:exp_answer_confidence_hiddenSize},~\ref{fig:exp_factual_consistency_hiddenSize}) plateus at around 8, suggesting a hierarchy of representation complexity where behavioral patterns are most readily accessible, structural patterns require moderate complexity to capture, and content patterns demand the most sophisticated probe architectures.
The consistent pattern across different model scales and architectures points to fundamental organizational principles in language model representations. This suggests that \textbf{emergent planning capabilities may be an inherent property of large language models rather than an artifact of specific architectures or training procedures}.




\paragraph{Insight 4: Attribute patterns accumulate and peak differently across model layers (Fig.~\ref{fig:exp_layerwise}).}
We conduct layer-wise probing analysis (with hidden sizes optimized per layer) to understand how different attributes emerge through model layers. The results reveal distinct accumulation patterns for each attribute type. Structure attributes (Fig.~\ref{fig:exp_response_length_layerwise}, ~\ref{fig:exp_reasoning_steps_layerwise}) show weak performance in early layers, peak in middle layers, and partially diminish in final layers, suggesting a gradual accumulation followed by refinement. Content attributes (Fig.~\ref{fig:exp_character_choices_layerwise}, ~\ref{fig:exp_multiplechoice_answers_layerwise}) peak in later layers, either through sudden late-layer emergence or gradual accumulation, indicating their reliance on higher-level semantic processing. Behavior attributes (Fig.~\ref{fig:exp_answer_confidence_layerwise}, ~\ref{fig:exp_factual_consistency_layerwise}) demonstrate uniform distribution across layers except for the initial few, suggesting they are fundamental properties encoded early in the model.
These layer-wise patterns reveal that \textbf{(1)} different aspects of planning emerge through distinct computational paths, \textbf{(2)} the hierarchical nature of planning, from basic behavioral patterns to complex structural decisions, is reflected in the layer-wise organization, and \textbf{(3)} the emergence of these patterns through progressive transformations, rather than from initial embeddings alone, indicates that planning capabilities arise from learned computational processes rather than simple statistical correlations.











