\section{Goal 1: $f$-DP Estimation} \label{sec:4}

In this section, we develop a new method for the approximation of the entire optimal trade-off curve. The trade-off curve results from a study of the Neyman-Pearson test where any type-I error $\alpha$ is associated with the smallest possible type-II error $\beta$ (see our introduction for details). Understood as a function in $\alpha$  we denote the type-II error by $T:[0,1] \to [0,1]$ and call it a trade-off curve. We note that any trade-off curve is continuous, non-increasing and convex (see \cite{Dong2022}).

\subsection{Estimation of the $f$-DP curve}

 
 Our approach is based on the perturbed likelihood ratio (LR) test which mimics the properties of the optimal Neyman-Pearson test, but requires less knowledge about the distributions involved. In the following, we denote by $P,Q$ the output distributions of $M(D), M(D')$ respectively. The corresponding probability densities are denoted by $p,q$.\\
\textbf{The perturbed LR test.} The optimal test for the hypotheses pair 
\[
H_0: X \sim p\quad \textnormal{vs.} \quad H_1: X \sim q
\]
is the Neyman-Pearson test described this test in Section \ref{sec:hyp}.  It is also called a \textit{likelihood ratio} (LR) test, because it rejects $H_0$ if the density ratio satisfies $q(X)/p(X)>\eta$ for some threshold $\eta$. If $q(X)/p(X)=\eta$ the test rejects randomly with probability $\lambda.$
In a black-box scenario this process is difficult to mimic, even if two good estimators, say $\hat p, \hat q$ of $p,q$ are available. Even if $\hat p \approx p$ and $\hat q \approx q$ it will usually be the case that
\[
q(x)/p(x) = \eta  \quad \textnormal{does not imply} \quad \hat q/ \hat p =\eta
\]
(it may hold that $\hat p/ \hat q \approx \eta $, but typically not exact equality). In principle, one could cope with this problem by modifying the condition $\hat q/ \hat p =\eta$ to $\approx \eta$ to mimic the optimal test. Yet, the implementation of this approach turns out to be difficult. In particular, it would involve two tuneable arguments $(\eta, \lambda)$, as well as further parameters (to specify "$\approx$") making approximations costly and unstable. A simpler and more robust approach is to focus on a different test rather than the optimal one - a test that is close to optimal but does not require the knowledge of when $q/p$ is constant. For this purpose, we introduce here the novel \textit{perturbed LR test}. 
We define it as follows: Let $U \in [-1/2, 1/2]$ be uniformly distributed and $h>0$ a (small) number. Then we make the decision
\begin{align} \label{e:PLR}
"\textnormal{reject $\,\,H_0\,\,$ if } \quad q(X)/p(X)>\eta + h U".
\end{align}
Just as the Neyman-Pearson test, the perturbed LR test is randomized. Instead of flipping a coin when $q/p=\eta$, the threshold $\eta$ is perturbed with a small, random noise. Obviously the perturbed LR test does not require knowledge of the level sets $\{q/p=\eta\}$, making it more practical for our purposes.
To formulate a theoretical result for this test, we impose two natural assumptions.
\begin{ass} \label{ass1} $ $
    \begin{itemize}
        \item[i)] The densities $p,q$ are continuous.
        \item[ii)] There exists only a finite number of values $\eta \ge 0$ where the set $\{q/p=\eta\}$ has positive mass.
       % \item[iii)] The optimal trade-off curve $T$ implied by $p,q$ is continuous.
    \end{itemize}
\end{ass}
The second assumption is met for all density models that the authors are aware of and in particular for all mechanisms commonly used in DP. %The third assumption facilitates the presentation of our below results, as is guarantees convergence of the estimated trade-off curve to $T$ uniformly; i.e. simultaneously for all arguments $\alpha$. This condition can be dropped at the expense of a more technical formulation, where uniform convergence is replaced by convergence in the Skorohod metric (see \cite{billingsley:1999}). We do not pursue such generalizations here, since they are not practically relevant.\\
Let us denote the $f$-DP curve of the perturbed LR test by $T_h$. The next Lemma shows that for small values of $h$ the perturbed LR test performs as the optimal LR test.
\begin{lem} \label{lem1}
Under Assumption \ref{ass1} it holds that
\[
\lim_{h \downarrow 0} \sup_{\alpha \in [0,1]}|T(\alpha)-T_h(\alpha)|=0.
\]
\end{lem}
 \textbf{Approximating $T_h$.} The Lemma shows that, to create an estimator of the optimal trade-off curve $T$, it is sufficient to approximate the curve $T_h$ of the perturbed LR test for some small $h$. This is an easier task, since we do not need to know the level sets $\{q/p=\eta\}$ for all $\eta$. Indeed, suppose we have two estimators $\hat p, \hat q$, we can run a perturbed LR test with them, just as in equation \eqref{e:PLR}. A short theoretical derivation (found in the appendix) then shows that running the perturbed LR test for $\hat p, \hat q$ and some threshold $\eta$, yields the following type-I and type-II errors:
\begin{align}
\hat \alpha_h(\eta) := &\int_{x \in [-h/2,h/2]} \frac{1}{h}\int_{\hat q /\hat p  > \eta +x} \hat p , \\\hat \beta_h(\eta) :=& \int_{x \in [-h/2,h/2]} \frac{1}{h}  \int_{\hat q /\hat p  > \eta +x} \hat q .
\end{align}
The entire trade-off-curve for the perturbed LR test with $(\hat p, \hat q)$ is then given by $\hat T_h$ with
\begin{align} \label{e:def:Th}
\hat T_h(\alpha) = \hat \beta_h(\eta) \quad \Leftrightarrow \quad \alpha = \hat \alpha_h(\eta).
\end{align}
For the curve estimate $\hat T_h$ to be close to $T_h$ (and thus $T$), the involved density estimators need to be adequately precise. We hence impose the following regularity condition on them. In the condition, $n$ is the sample size used to make the estimators.
\begin{ass} \label{ass2}
    The density estimators $\hat p, \hat q$ are themselves continuous probability densities and decaying to $0$ at $\pm \infty$ (see eq. \eqref{e:decay} for a precise definition). For a null-sequence of non-negative numbers $(a_n)_{n \in \mathbb{N}}$ they satisfy
    \begin{align*}
     & \Pr[\sup_{x } |\hat p(x)-p(x)|>a_n]=o(1)\\
    and \quad &\Pr[\sup_{x } |\hat q(x)-q(x)|>a_n]=o(1). 
    \end{align*} 
\end{ass}
The above assumption is in particular satisfied by KDE (see Section \ref{sec:kde}), where the convergence speed $a_n$ depends on the smoothness of the underlying densities. However, in principle other estimation techniques than KDE could be used, as long as they produce continuous estimators. The next result formally proves the consistency of $\hat T_h$. The notation of "$o_P(1)$" refers to a sequence of random variables converging to $0$ in probability.

\begin{theo} \label{theo:1}
    Suppose that Assumptions \ref{ass1} and \ref{ass2} hold, and that $h=h_n$ is a positive number depending on $n$ with $h_n \to 0$ and $h_n/a_n \to \infty$. Then, as $n \to \infty$ it follows that
    \[
    \sup_{\alpha \in [0,1]}|\hat T_h(\alpha)-T(\alpha)|=o_P(1).
    \]
\end{theo}
The above result proves that simultaneously for all $\alpha$, the curve $\hat T_h$ approximates the optimal trade-off function $T$. Thus, we have achieved the first goal of this work. The (very favorable) empirical properties of $\hat T_h$ will be studied in Section \ref{sec6}. We have also incorporated Algorithm \ref{alg:pointwise_KDE_estimator} for an overview of the procedure. 
% \begin{algorithm}[h]
% \footnotesize
% \algorithmicrequire \; \parbox[t]{\dimexpr0.9\linewidth-\algorithmicindent}{Black-box access to $M$; Threshold vector $\eta > 0$; Sample size $n$.}\\[0.1cm]
% \algorithmicensure \, An estimate $(\hat{\alpha}(\eta), \hat{\beta}(\eta))$ of $(\alpha(\eta), \beta(\eta))$ for tuple $(P, Q)$.
% \begin{algorithmic}[1]
%     \State Set parameter $h$. 
%     \State Set the density estimation algorithm $\cA$. By default, use the KDE algorithm.
%     \Function{\textnormal{PTLR Estimatior} $\ptlr{h}{\cA}(M, \eta,n)$}{}
%     \State Compute the estimated densities $\hat{p}, \hat{q}$ based on outputs of $M$ by running $\cA$ with a sample size of $n$.
%     \State Compute $\hat{\alpha}(\eta_i) \leftarrow \int_{x \in [-h/2,h/2]} \frac{1}{h}\int_{\hat q /\hat p  > \eta_i +x} \hat p$ for all $\eta_i\in \eta$
%     \State Compute $\hat{\beta}(\eta_i) \leftarrow \int_{x \in [-h/2,h/2]} \frac{1}{h}  \int_{\hat q /\hat p  > \eta_i +x} \hat q$ for all $\eta_i\in \eta$ 
%     \State Return vector $(\hat{\alpha}(\eta), \hat{\beta}(\eta))$
%     \EndFunction
% \end{algorithmic}
% \caption{PTLR: A Perturbed Likelihood Ratio Test Algorithm for $f$-DP Estimation}
% \label{alg:pointwise_KDE_estimator}
% \end{algorithm}


\subsection{Finding maximum vulnerabilities} We conclude this section by some preparations for the second goal - auditing $f$-DP. The precise problem of auditing is described in Section \ref{sec:audit}. Here, we only mention that the task of auditing is to check (in some sense) whether $f$-DP holds for a claimed trade-off curve, say $f=T^{(0)}$.
As an initial step to check $T^{(0)}$-DP  we create the estimator $\hat T_h$ for the optimal curve $T$. If $T^{(0)}$-DP holds, this means that
\begin{align} \label{e:H0fDP}
     T(\alpha)\ge  T^{(0)}(\alpha)\quad \forall \alpha \in [0,1].
\end{align}
A priori, we cannot say whether this is true or not. However, by comparing our estimator $\hat T_h$ with  $T^{(0)}$ we can gather some evidence. For example, if $\hat T_h(\alpha)$ is much smaller than $ T^{(0)}(\alpha)$ for some $\alpha$, then it seems that the claim \eqref{e:H0fDP} is probably false. We will develop a rigorous criterion for what "much smaller" means in the next section. For now, we will confine ourselves to identifying a point, where privacy seems most likely to be broken. We therefore define 
\begin{align} \label{e:def:eta}
\hat \eta^* \in \textnormal{argmax} \big\{T^{(0)}(\hat \alpha_h(\eta))-\hat T_h(\hat \alpha_h(\eta)): \eta\ge 0\big\} 
\end{align}
and the next result shows that the discrepancy between $T^{(0)}$ and $T$ is indeed maximized in $\hat \eta^* $ for large $n$.\\
%\todo{Question: Does this not also have the issue to directly using the estimator, that we don't know the rate of convergence to the true most-vulnerable point?} \textcolor{orange}{Yes.}\todo{To discuss: how to describe our auditor's accuracy (esp in the intro, given that we try to differentiate our estimator/auditor results)}
\begin{prop} \label{prop1}
    Suppose that the assumptions of Theorem \ref{theo:1} hold. Then, it follows that 
    \begin{align*}
    &T^{(0)}(\hat \alpha_h(\hat \eta^*)) - T(\hat \alpha_h(\hat \eta^*)) \\
    =&\sup_{\alpha \in [0,1]}\big[ T^{(0)}(\alpha)-T(\alpha)\big]+o_P(1).
    \end{align*}
\end{prop}
The threshold $\hat \eta^*$ demarcates the greatest weakness of the $T^{(0)}$-privacy claim and it is therefore ideally suited as a starting point for our auditing approach in Section \ref{sec:audit}.


%\begin{itemize}
%    \item Theorem/lemmas for Goal 1 using KDE
%    \item Lemma where KDE can also give you the $\eta$ with the biggest violation and point to next section on how to use that for Goal 2.
%\end{itemize}