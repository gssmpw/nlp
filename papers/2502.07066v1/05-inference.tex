\section{Goal 2: Auditing $f$-DP} \label{sec:goal2}

In this section, we develop methods for uncertainty quantification in our assessment of $T$. We begin, with Section \ref{sec:conf}, where we derive (two dimensional) confidence regions for a pair of type-I and type-II errors. Our approach relies on the approximation of Bayes optimal classifiers using the $k$-nearest neighbor ($k$-NN) method. The resulting confidence regions are used in Section \ref{sec:audit} as subroutine of a general-purpose $f$-DP auditor, that combines the estimators from KDE and the confidence regions from $k$-NN. 


%\begin{itemize}
%    \item Using kNN to quantify  the maximum violation at one point (given an $\eta$). Emphasize that kNN gives point-wise confidence level that depends on the number of samples.
%    \item Use the worst-case $\eta$ found by KDE from previous section to detect violation of $f$-DP given some $f$.
%\end{itemize}

\subsection{Pointwise confidence regions} \label{sec:conf}

In this section, we introduce the BayBox estimator, an algorithm designed to provide point-wise estimates of the trade-off curve $T$ with theoretical guarantees. Specifically, for a given threshold $\eta > 0$, the BayBox estimator outputs an estimate of the trade-off point $(\alpha(\eta), \beta(\eta))$. This estimate is guaranteed to be within a small additive error of the true trade-off point, with high probability.

BayBox estimator is backed up by the observation that the quantity $\alpha(\eta)$ (also $\beta(\eta)$) can be expressed as the Bayes risk of a carefully constructed Bayesian classification problem. For instance, to compute $\alpha(\eta)$ when $\eta \geq 1$, a theoretical derivation (provided in the appendix) shows that this computation is equivalent to computing the Bayes risk for the Bayesian classification problem $\bbcP{\MixtureD{P}{\eta}}{Q}$\footnote{Refer to Section 3.5 for the notation and problem setup for Bayesian classification problem.}. The mixture distribution $\MixtureD{P}{\eta}$ is formally defined in the following.

% We begin with the definition of mixed distributions.  Recall that we denote by $p$ the probability density of the distribution $P$. Roughly speaking the mixed distribution $\MixtureD{P}{\eta}$ lets us sample data from the improper density $p/\eta$, which again is related to the Neyman-Pearson test, where we reject if 
% \[
% p(X)/q(X)> \eta \quad \Leftrightarrow \quad p(X)/\eta>q(X).
% \]
% Recently mixed distributions were related to approximate DP by~\cite{Lu2024}, and our related results provide a significant extension, establishing a link between the theory of optimal classification and $f$-DP.

\begin{definition}[Mixture Distribution]
Let $P$ be a distribution and $\eta \in [1, +\infty)$. The mixture distribution $\MixtureD{P}{\eta}$ is defined as:
\begin{align*}
    \MixtureD{P}{\eta} =
    \begin{cases} 
        P & \text{with probability } \frac{1}{\eta}, \\
        \bot & \text{with probability } 1 - \frac{1}{\eta}.
    \end{cases}
\end{align*}
\end{definition}

We note that recent work \cite{Lu2024} showed that the parameters of approximate DP can be expressed in terms of the Bayes risk of carefully constructed Bayesian classification problems. They further showed how to construct such classification problems using mixture distributions. Building on this foundation, our results significantly extend their approach by establishing a direct link between the theory of optimal classification and $f$-DP.

\begin{algorithm}[!htp]
\footnotesize
\algorithmicrequire \; \parbox[t]{\dimexpr0.9\linewidth-\algorithmicindent}{Black-box access to $\Mech$; Threshold $\eta > 0$; Sample size $n$.}\\[0.1cm]
\algorithmicensure \, An estimate $(\tilde{\alpha}(\eta), \tilde{\beta}(\eta))$ of $(\alpha(\eta), \beta(\eta))$ for tuple $(P, Q)$, where $\Mech(\DB)$ and $\Mech(\DB')$ are distributed to $P, Q$, respectively.
\begin{algorithmic}[1]
    \State Set the classifier $\phi$ for the Bayesian classification problem $\bbcP{\MixtureD{P}{\eta}}{Q}$ if $\eta \geq 1$; otherwise, set $\phi$ for the problem $\bbcP{P}{\MixtureD{Q}{1/\eta}}$. By default, use the $k$-NN classifier $\kNNclassifier{n}$ with $k = \sqrt{n}$.
    \Function{\textnormal{BayBox Estimatior} $\bbe{\phi}(M, \DB, \DB', \eta,n)$}{}
    \State Set $cnt_{\alpha} \leftarrow 0$ and $cnt_{\beta} \leftarrow 0$
    \For{$i \in [n]$}
        \State $x \leftarrow \Mech(\DB)$; $x' \leftarrow \Mech(\DB')$
        \State If $\phi(x) = 1$ then $cnt_{\alpha} \leftarrow cnt_{\alpha} + 1$
        \State If $\phi(x') = 1$ then $cnt_{\beta} \leftarrow cnt_{\beta} + 1$
    \EndFor
    \State Return $(\tilde{\alpha}(\eta), \tilde{\beta}(\eta)) \leftarrow (\frac{cnt_{\alpha}}{n}, 1 - \frac{cnt_{\beta}}{n})$
    \EndFunction
\end{algorithmic}
\caption{BayBox: A Black-Box Bayesian Classification Algorithm for $f$-DP Estimation}
\label{alg: general BayBox estimator}
\end{algorithm}

Monte Carlo (MC) techniques are widely regarded as one of the most natural and commonly used methods for approximating expectations. Since the trade-off point $(\alpha(\eta), \beta(\eta))$ can be expressed in terms of the Bayes risk of specific Bayesian classification problems—and noting that the Bayes risk is the expectation of the misclassification error random variable—an MC-based approach can be applied to estimate it. Accordingly, we propose the BayBox estimator, a simple Monte Carlo estimator for the trade-off point $(\alpha(\eta), \beta(\eta))$. A formal description is provided in Algorithm~\ref{alg: general BayBox estimator}.


% For the next result, notice recall that $\phi^*$ denotes the (optimal) Bayes classifier and for details we refer to Section \ref{sec:class}. Notice that we refer to estimators for the type-I and type-II errors in this section by $\tilde \alpha, \tilde \beta$ respectively to avoid confusion with the estimators based on KDE.


Lemma~\ref{lemma: accuracy stat of general BayBox estimator} states that, assuming the Bayes optimal classifier can be constructed, one can establish simultaneous confidence intervals for the parameters $\alpha(\eta)$ and $\beta(\eta)$ with a user-specified failure probability $\gamma$, which can be made arbitrarily small, based on the output of the BayBox estimator. In practice, however, the Bayes classifier $\phi^*$ is usually unknown and need to be approximated. Nevertheless, Lemma~\ref{lemma: accuracy stat of general BayBox estimator} is of independent interest, as it suggests that our method is, to some extent, agnostic to the choice of the classification algorithm.

\begin{lem}%[Proof is in Appendix~\ref{proof: for lemma: accuracy stat of general BayBox estimator}]
    \label{lemma: accuracy stat of general BayBox estimator}
    Let $\eta$, $(\alpha(\eta), \beta(\eta))$, $(\tilde{\alpha}(\eta), \tilde{\beta}(\eta))$, and $\phi$ be as defined in Algorithm~\ref{alg: general BayBox estimator}. Set $\phi$ to the Bayes optimal classifier $\phi^*$ for the corresponding Bayesian classification problem.
    Then, with probability $1 - \gamma$,
    \begin{align*}
    &\abs{\tilde{\alpha}(\eta) - \alpha(\eta)} \leq \sqrt{\frac{1}{2n}\ln{\frac{2}{\gamma}}} \\
    &\abs{\tilde{\beta}(\eta) - \beta(\eta)} \leq \sqrt{\frac{1}{2n}\ln{\frac{2}{\gamma}}}.
    \end{align*}
\end{lem}

% Theorem \ref{lemma: accuracy stat of general BayBox estimator} establishes simultaneous confidence intervals for the parameters $\alpha(\eta)$ and $\beta(\eta)$ with a user-determined failure probability of $\gamma$ (it can be made arbitrarily small). Of course, in practice, the Bayes classifier $h^*$ is unknown and has to be approximated. A concrete approximation is provided by the kNN discussed below. However, Theorem \ref{lemma: accuracy stat of general BayBox estimator} is of independent interest, as it implies that our method is (in some sense) agnostic w.r.t. to the approximating classifier. 
% We now derive an analogous result for the feasible kNN classifier.

Theorem~\ref{thm: accuracy stat of kNN BayBox estimator} provides an analogous result for the feasible $k$-NN classifier. This is achieved by replacing the Bayes classifier $\phi^*$ with a concrete approximation provided by the $k$-NN classifier.

\begin{theo}%[Proof is in Appendix~\ref{proof: for thm: accuracy stat of kNN BayBox estimator}] 
    \label{thm: accuracy stat of kNN BayBox estimator}
    Let $\eta$, $(\alpha(\eta), \beta(\eta))$, $(\tilde{\alpha}(\eta), \tilde{\beta}(\eta))$, and $\phi$ be as defined in Algorithm~\ref{alg: general BayBox estimator}. Set $\phi$ to the $k$-NN classifier $\kNNclassifier{n}$, with $k = \sqrt{n}$, for the corresponding Bayesian classification problem.
    Then, under Assumption \ref{ass1}, for all $n$ sufficiently large and with probability $1 - \gamma$, it holds that
    \begin{align*}
    &\abs{\tilde{\alpha}(\eta) - \alpha(\eta)}\leq w(\gamma)~,\\& \abs{\tilde{\beta}(\eta) - \beta(\eta)} \leq w(\gamma)~,
    \end{align*}
    where
    \begin{align}
    w(\gamma):=\sqrt{\frac{1}{2n}\ln{\frac{4}{\gamma}}} + 12\sqrt{\frac{2c_d^2}{n}\ln{\frac{4}{\gamma}}}~. \label{e:wgamma}
    \end{align}
\end{theo}


\subsection{Auditing $f$-DP} \label{sec:audit}

\textbf{Outline} In the remainder of this section, we present an $f$-DP auditor that fuses the localization of maximum vulnerabilities (by the KDE method) with the confidence guarantees (afforded by the $k$-NN method). We can describe the problem as follows: Usually, when a DP mechanism $M$ is developed it comes with a privacy guarantee for users. In the case of standard DP this takes the form of a single parameter $\varepsilon_0$. In the case of $f$-DP a privacy guarantee is associated with a continuous trade-off curve $T^{(0)}$. Essentially the developer promises that the mechanism will afford at least $T^{(0)}$-DP. The task of the auditor is to empirically reliably check this claim.

\noindent\textbf{The auditor} We proceed in two steps. Since we do not want to force the two steps to depend on the same sample size parameters we introduce two (potentially different) sample sizes $n_1, n_2$. First, using the KDE method, we find an estimated value of maximum vulnerability $\hat \eta^*$ (based on a sample of size $n_1)$. This is possible according to  Proposition \ref{prop1}. Second, we apply the BayBox algorithm with input $\hat \eta^*$ and sample size $n_2$.  According to Theorem \ref{thm: accuracy stat of kNN BayBox estimator} it holds with high probability ($1-\gamma$) that the values $(\alpha(\hat \eta^*), \beta(\hat \eta^*))$ of the optimal test are contained inside the square
\begin{align} \label{e:defsq}
\square_\gamma:= \,\big[\tilde{\alpha}(\hat \eta^*) - w(\gamma),\tilde{\alpha}(\hat \eta^*) + w(\gamma)\big] &\\
\qquad\times  \big[\tilde{\beta}(\hat \eta^*) - w(\gamma),\tilde{\beta}(\hat \eta^*) + w(\gamma)\big]. \nonumber & 
\end{align}
Put differently, after running the BayBox algorithm, the only plausible values for $(\alpha(\hat \eta^*), \beta(\hat \eta^*))$ are inside $\square_\gamma$. \\
Now, since $(\alpha(\hat \eta^*), \beta(\hat \eta^*))$ is a pair of errors associated with the optimal test, it corresponds to a point on the optimal trade-off curve. If this point were below the curve $T^{(0)}$, the claim of $T^{(0)}$-DP would be wrong. We do not know the exact value of $(\alpha(\hat \eta^*), \beta(\hat \eta^*))$, but we do know (with high certainty) that it is inside the very small box $\square_\gamma$. If the entirety of this box is below $T^{(0)}$, there seems no plausible way that  $T^{(0)}$-DP is satisfied and the auditor will detect a privacy violation. If, on the other hand, some or all of the values in $\square_\gamma$ are on or above  $T^{(0)}$, our %data suggests that $M$ plausibly satisfies $T^{(0)}$-DP and the 
auditor does not detect a violation. Algorithm \ref{auditor} summarizes the procedure we have just described. It uses a small geometrical argument to check more easily whether the box is below $T^{(0)}$ or not (see lines $7-8$ of the algorithm).

\begin{algorithm}[h]
\footnotesize
\algorithmicrequire \; \parbox[t]{\dimexpr0.9\linewidth-\algorithmicindent}{Mechanism $\Mech$, neighboring databases $\DB, \DB'$, sample sizes $n_1, n_2$, confidence level $\gamma$, threshold vector $\eta$, claimed curve $T^{(0)}$.}\\[0.1cm]
\algorithmicensure \, "Violation" or "No Violation".
\begin{algorithmic}[1]
    \Function{\textnormal{Auditor}$(\Mech, \DB, \DB', n_1, n_2, \gamma,\eta, T^{(0)})$}{}
        \State Compute $\hat{T}_h$ using $\ptlr{h}{\cA}(M, \DB, \DB', \eta,n_1)$ for all $\eta_i \in \eta$.
        \State Compute $\hat{\eta}^* \in \arg\max \left\{T^{(0)}(\hat{\alpha}_h(\eta)) - \hat{T}_h(\hat{\alpha}_h(\eta)) : \eta \ge 0\right\}$.
        \State Run the $k$-NN BayBox estimator $\bbe{\kNNclassifier{n_2}}(M, \DB, \DB', \eta^*,n_2)$ to obtain $(\tilde{\alpha}(\hat{\eta}^*), \tilde{\beta}(\hat{\eta}^*))$.
        \State Calculate the threshold $w(\gamma)$ from eq. \eqref{e:wgamma}
        \State Calculate $i^*$ as the solution to $T^{(0)}(i^*) = \tilde{\beta}(\hat{\eta}^*) + w(\gamma)$.
        \If{$i^* > \tilde{\alpha}(\hat{\eta}^*) + w(\gamma)$}
          \State \Return "Violation".
        \Else
           \State \Return  "No Violation".
        \EndIf
    \EndFunction
\end{algorithmic}
\caption{Privacy Violation Detection Algorithm}\label{alg:auditor}
\label{auditor}
\end{algorithm}


% \begin{algorithm}
%     \caption{Privacy Violation Detection Algorithm}
%     \label{auditor}
%     \begin{algorithmic}[1]
%         \State \textbf{Input:} Mechanism $M$, neighboring databases $D, D'$, sample sizes $n_1, n_2$, confidence level $\gamma$
%         \Function{Auditor}{$M, D, D', n, \gamma$}
%             \State Compute $\hat{T}_h$ (defined in eq. \eqref{e:def:Th}) with sample size $n_1$
%             \State Compute $\hat{\eta}^* \in \arg\max \left\{T^{(0)}(\hat{\alpha}_h(\eta)) - \hat{T}_h(\hat{\alpha}_h(\eta)) : \eta \ge 0\right\}$
%             \State Run the BayBox algorithm for KNN classifiers with input $\eta = \hat{\eta}^*$ and sample size $n_1$. Obtain $(\tilde{\alpha}(\hat{\eta}^*), \tilde{\beta}(\hat{\eta}^*))$
%             \State Calculate the threshold $w(\gamma)$ from eq. \eqref{e:wgamma}
%             \State Calculate $i^*$ as the solution to $T_0(i^*) = \tilde{\beta}(\hat{\eta}^*) + w(\gamma)$
%             \If{$i^* > \tilde{\alpha}(\hat{\eta}^*) + w(\gamma)$}
%               \State \Return "Violation"
%             \Else
%                \State \Return  "No Violation"
%             \EndIf
%         \EndFunction
%     \end{algorithmic}
%     \textcolor{orange}{\textbf{Yu:} I have created a pseudocode (of sorts) here. Cann you bring it into your Pseudocode notation? Also, do we need a Pseudocode for KDE that we can call?}
% \end{algorithm}

\noindent\textbf{Theoretical analysis} To provide theoretical guarantees for the algorithm, we add a mathematical assumption on the trade-off curve of $p \sim M(D), q \sim M(D')$.

\begin{ass} \label{ass3}
    The optimal trade-off curve $T$ corresponding to the output densities $p,q$ is strictly convex.
\end{ass}
We can now formulate the main theoretical result for the auditor. 

\begin{theo} \label{theo:auditor}
    Suppose that Assumptions \ref{ass1} and \ref{ass2} hold, let $\gamma \in (0,1)$ be user-determined and denote the output of AUDITOR($M, D, D', n_1, n_2, \gamma$)  by $A$.
    \begin{itemize}
        \item[1)] Then, if $T^{(0)}(\alpha) \ge T(\alpha)$ for all $\alpha \in [0,1]$ (no violation of $T^{(0)}$-DP), it follows that 
    \[
     \liminf_{n_1 \to \infty}\,\,\liminf_{n_2 \to \infty} \,\,\Pr\Big[ A = "\textnormal{No Violation}"\Big]\ge 1-\gamma.
    \]
 
    \item[2)] Suppose that additionally Assumption \ref{ass3} holds. Then, if $T^{(0)}(\alpha^*) < T(\alpha^*)$ for some $\alpha^* \in [0,1]$ (a violation of $T^{(0)}$-DP), it follows that   
    \[
    \lim_{n_1 \to \infty} \,\,\liminf_{n_2 \to \infty} \,\,\Pr\Big[ A = "\textnormal{Violation}"\Big]= 1.
    \]
    \end{itemize}
\end{theo}
Part 1) of the Theorem states that the risk of falsely detecting a violation can be made arbitrarily small ($\le \gamma$) by the user. On the other hand, if some violation exists, part 2) assures that it will be reliably detected for large enough sample sizes. We note that for smaller values of $\gamma$ larger sample sizes are typically needed to detect violations. This follows from the definition of the box $\square_\gamma$ in \eqref{e:defsq}.
\begin{rem}
\textnormal{
The auditor in Algorithm \ref{alg:auditor} uses the threshold $\hat \eta^*$ (see eq.
\ref{e:def:eta}), to locate the maximum vulnerability. We point out that any other method to find vulnerabilities would still enjoy the guarantee from part 1) of Theorem \ref{theo:auditor} (it is a property of $k$-NN), but not necessarily of part 2). It might be an interesting subject of future work to consider other ways of choosing $\hat \eta^*$ (e.g. based on the two dimensional Euclidean distance between $T^{(0)}$ and $\hat T_h$ rather than the supremum distance).
}
%    We want to emphasize that the choice of $\eta^*$ as the critical point derived by
%can potentially be replaced by other distances. In particular, one can always consider multiple $\hat\eta^*$ and audit accordingly. Due to the multiple testing, the auditor would have to correct $\gamma$ accordingly. A simple approach would be the Bonferroni correction. Basically, if auditing the mechanism $M$ on $l$ different $\eta$ (including the $\hat\eta^*$ we proposed), we would replace $\gamma$ by $\gamma/l$ for each audit, to obtain the same results as given in Theorem \ref{theo:auditor}.
\end{rem}