\section{Preliminaries}\label{sec:prelim}

In this section, we provide details on hypothesis testing, differential privacy and tools from statistics and machine learning that our methods rely on.

\subsection{Hypothesis testing} \label{sec:hyp}

We provide a brief introduction into the key concepts of hypothesis testing. We confine ourselves to the special case of sample size $1$, most relevant to $f$-DP. 
For a general introduction we refer to \cite{Bickel2001}.
Consider two probability distributions $P, Q$ on the Euclidean space $\mathbb{R}^d$ and a random variable $X$. It is unknown from which of the two distributions $X$ is drawn and the task is to decide between the two competing hypotheses
\begin{align} \label{e:hyp2}
H_0: X \sim P\quad \textnormal{vs.} \quad H_1: X \sim Q.
\end{align}
The problem is similar to a classification task (see Section \ref{sec:class} below). The key difference to classification is that in hypothesis testing, there exists a default belief $H_0$ that is preferred over $H_1$. The user switches from $H_0$ to $H_1$ only if the data ($X$) suggests it strongly enough. In this context, a hypothesis test is a binary, potentially randomized function $g: \mathbb{R}^d \to \{0,1\}$, where $g(X)=0$ implies to stay with $H_0$, while $g(X)=1$ implies that the user should switch to $H_1$ ($H_0$ is "rejected"). Just as in classification, the decision to reject/fail to reject can be erroneous and the error rates of these decisions are called $\alpha$, the "type-I error", and $\beta$, the "type-II error". Their formal definitions are
\[
\alpha^{(g)}:= \Pr_{X \sim P}[g(X)= 1], \quad \beta^{(g)}:= \Pr_{X \sim Q}[g(X)= 0].
\]
One test $g$ is better than another $g'$, if simultaneously
\[
\alpha^{(g)} \le \alpha^{(g')} \quad \textnormal{and} \quad \beta^{(g)} \le \beta^{(g')}.
\]
This comparison of statistical tests naturally leads to the issue of optimal tests, 
%, considered in the next section.
%\subsection{Optimal tests} \label{sec:optimal}
% We consider the setup from the previous section and 
and we define the optimal level-$\alpha$-test as the argmin of
 \[
 \{\beta^{(g)}: g \,\,\textnormal{is a  test}\,\, \textnormal{with } \,\, \alpha^{(g)}\le \alpha\}.
 \]
 The minimum is achieved and the corresponding optimal test is provided by the {\em likelihood ratio (LR) test} in the Neyman-Pearson lemma, a fundamental result in statistics. In the following, we assume the two probability measures $P,Q$ in hypotheses \eqref{e:hyp2} have some probability densities $p,q$.

\begin{theo}[Neyman-Pearson Lemma~\cite{neyman1933ix}]
\label{theo: NP lemma}
For any $\alpha \in [0,1]$, the smallest  type-II error $\beta(\alpha)$ among all level-$\alpha$-tests is achieved by the \textbf{{\em likelihood ratio (LR) test}}, characterized by two constants $\eta \ge 0$ and $\lambda\in [0,1]$ and has the following rejection rule:
\begin{itemize}
    \item[1)] Reject $H_0$ if $q(X)/p(X) >\eta$.
    \item[2)] If $q(X)/p(X)=\eta$, flip an unfair coin with probability $\lambda$ of heads. If the outcome is heads, reject $H_0$.
\end{itemize} 
The constants $(\eta, \lambda)$ are chosen such that the type-I error is exactly $\alpha$.
%\begin{align*}
%    \beta(\alpha) = 1 - \int q \cdot \mathbb{I}\{p / q  \leq \eta\}
%\end{align*}
%where $\eta \in [0, +\infty]$ such that $\alpha = \int p \cdot \mathbb{I}\{p / q  \leq \eta\}$.
\end{theo}

\noindent \textbf{Notations.}  Neyman-Pearson  motivates the use of the following notations. First, for any type-I-error $\alpha$ there is a corresponding (optimal) $\beta$ implied by the Lemma. These constants are achieved by a pair $(\eta, \lambda)$ and we can thus write $\alpha(\eta, \lambda), \beta(\eta, \lambda)$ for them. When we are only interested in the result of the non-randomized test with $\lambda=0$, we will just write   $\alpha(\eta), \beta(\eta)$.

%While the Neyman-Pearson lemma is theoretically important as an optimality statement, its practical application is often limited. This is because the true densities, $p$ and  $q$, are typically unknown. For instance, in our black-box setting we do not know the algorithmic output distributions in advance. Accordingly, a main challenge in our subsequent procedure will be the approximation of the optimal test decision, without perfect knowledge of the densities.


%Additionally, the lemma requires knowledge of the level sets, where the ratio of the two densities equals a certain threshold, which is challenging to estimate. The focus of our work is to develop a test that approaches the optimality of the Neyman-Pearson test using estimated densities, without the need to estimate these level sets.

%\textcolor{red}{Since Corollary~\ref{corollary: NP lemma} doesn't include the random test case currently, there might need a smooth transfer to introduce it as a corollary of Theorem~\ref{theo: NP lemma}. @Tim, can you help to polish it out?}

%Define the set $\cS_{\eta} = \{x: p(x)/q(x) \leq \eta \}$ and we have 
%\begin{align*}
%    \prdis{\rX \sim P}{\rX \in \cS_{\eta}} = \alpha(\eta), \prdis{\rX \sim Q}{\rX \in \cS_{\eta}} = 1 - \beta(\eta).
%\end{align*}
%Intuitively, $\cS_{\eta}$ is the set of outcomes where we reject the hypothesis $H = 0$, where $\eta$ is picked such that the best possible (randomized) test has a type-I error exactly equal to $\alpha.$ By introducing $\cS_{\eta}$, we rewrite Theorem~\ref{theo: NP lemma} to the following corollary.

%\begin{cor}
 %   \label{corollary: NP lemma}
%    For $\alpha \in [0,1]$, if there exists $\eta$ such that $\prdis{\rX \sim P}{\rX \in \cS_{\eta}} = \alpha$, then it holds that
 %   \begin{align*}
 %   \beta(\alpha) = 1 - \prdis{\rX \sim Q}{\rX \in \cS_{\eta}}.
%    \end{align*}
%where $\cS_{\eta}$ is chosen such that $\prdis{\rX \sim P}{\rX \in \cS_{\eta}} = \alpha$.
%\end{cor}

\subsection{($f$-)Differential Privacy (DP)} \label{sec:fdp}
%\textcolor{blue}{
DP requires that the output of mechanism $\Mech$ is similar on all {\em neighboring} datasets $\DB, \DB'$ that differ in exactly one data point (we also call $\DB, \DB'$ {\em neighbors}). 
%that person's data. 
%We call datasets $\DB,\DB'$ neighbors/neighboring if they differ in exactly one data point.



\begin{definition}[DP~\cite{Dwork2006}]
A mechanism $\Mech$ is $(\varepsilon,\delta)$-DP if for all neighboring datasets $\DB, \DB'$ and any set $\cS$, 
  \begin{equation*}    
\Pr(\Mech(\DB) \in \cS) \leq e^\varepsilon \, \Pr(\Mech(\DB') \in \cS) + \delta~.
\end{equation*}
\end{definition}



Informally, if $\Mech$ is $(\varepsilon, \delta)$-DP, an adversary's ability to decide whether $\Mech$ was run on $\DB$ or $\DB'$ is bounded by $\delta$ and $e^{\varepsilon}$. 
For instance, any statistical level-$\alpha$-test $g$ that aims at deciding this problem must incur a type-II-error of at least $1 - e^{\varepsilon} \, \alpha - \delta$. The notion of $f$-DP was introduced to make this observation more rigorous.
%After introducing the basics of (optimal) tests, we can now formally describe $f$-DP. 
Given a pair of neighbors $\DB$ and $\DB'$ and a sample $\rX$, consider the hypotheses:
% \begin{align*}
%     H_0: \rX \sim P,& \text{ where } P = \Mech(\DB)\\   
%     H_1: \rX \sim Q,& \text{ where } Q =\Mech(\DB').
% \end{align*}
\begin{align*}
    &H_0: \rX \sim P\\   
    &H_1: \rX \sim Q,
\end{align*}
where $\Mech(\DB)$ and $\Mech(\DB')$ are distributed to $P, Q$, respectively.  
Roughly speaking, good privacy requires these two hypotheses to be hard to distinguish. That is, for any hypothesis test with type-I error $\alpha$, its type-II error $\beta$ should be large. This is captured by the trade-off function $T$ between $P$ and $Q$. 
\begin{definition}[Trade-off function~\cite{Dong2022}]
    For any two 
distributions $P$ and $Q$ on the same space, the 
trade-off function $T$ is: $$T(\alpha) := \inf \{\beta^{(g)}: g \,\,\textnormal{ test }\,\, \textnormal{ with } \,\, \alpha^{(g)}\le \alpha\}$$
\end{definition}

$\Mech$ is $f$-DP if its privacy is at least as good (its trade-off function is at least as large) as $f$, when considering all neighboring datasets.
\begin{definition}[$f$-DP~\cite{Dong2022}]
    A mechanism $\Mech$ is $f$-DP if for all neighboring datasets $\DB, \DB'$ it holds that
    $T \geq f$. Here, $T$ is the trade-off function implied by $\Mech(\DB) \sim P$ and $\Mech(\DB') \sim Q$. 
\end{definition}

%As discussed in the introduction, in line with previous black-box methods, we will confine our discussion on $f$-DP to a {\em single} pair of neighboring datasets $D,D'$.

We say $f$ is the {\em optimal/true} privacy parameter if it is the largest $f$ such that $\Mech$ is $f$-DP---such optimality is necessary to define for meaningful $f$-DP estimation, as any $\Mech$ is trivially $f$-DP for $f = 0$ (since the type-II error in hypothesis testing is always $\geq 0$).
% - a formulation suitable for our black-box methods. \todo{TO DISCUSS: I think more words are needed here to say *why* black box implies we only consider a single pair of neighbours. This discussion probably needs to go in Sec 3/4 rather than here}

%A more general overview is given in \cite{Dong2022}. So, let us consider a DP algorithm $M$ with output distributions $M(D) \sim P$ and $M(D') \sim Q$. We study the distinguishability of $P$ and $Q$ through the lens of hypothesis testing. Roughly speaking, high privacy equals high indistinguishability of $P,Q$ equals high type-I and type-II errors even for the best statistical tests. More precisely, for all type-I errors $\alpha \in [0,1]$ collectively, we study the smallest possible type-II errors, afforded by the Neyman Pearson test. We can regard this as a function
%\[
%\alpha \mapsto T(\alpha) := \inf \{\beta^{(g)}: g \,\,\textnormal{ test }\,\, \textnormal{ with } \,\, \alpha^{(g)}\le \alpha\}.
%\]
%We use the notation "$T$" for this curve, because it illustrates the optimal trade-off between type-I and type-II errors. We refer to $T$ as the \textit{optimal trade-off function}. 
%As shown in \cite{Dong2022} any trade-off function is continuous, non-increasing and convex. Higher-values of $T$ correspond to higher errors and by our above reasoning to higher indistinguishability and thus higher privacy. The highest privacy guarantee is given in the case where $P=Q$ and the analyst can only randomly guess between $H_0-H_1$. In this case, $T$ equals the diagonal $T(\alpha)=1-\alpha$.
%For a (potentially different) trade-off curve $f$ we say that the pair $P,Q$ satisfies $f$-DP if 
%\[
%T(\alpha) \ge f(\alpha), \qquad \forall \alpha \in [0,1].
%\]
%After the discussion of $f$-DP, we now turn to the technical tools of our black-box methods, namely kernel density estimation and machine learning classifiers.

\subsection{Kernel Density Estimation} \label{sec:kde}
Kernel density estimation (KDE) is a well-studied tool from non-parametric statistics to approximate an unknown density $p$ by an estimator $\hat{p}$.
% and $\hat{q}$. 
More concretely, in the presence of sample data $\rX_1, \dots, \rX_n \sim p$ with $\rX_i \in \mathbb{R}^d$, the KDE for $p$ is given by 
\begin{align*}
    \hat{p}(t) := \frac{1}{n b^d} \sum_{i=1}^n K\Big( \frac{t-\rX_i}{b}\Big).
\end{align*}
One can think of the KDE as a smoothed histogram where the bandwidth parameter $b >0$ corresponds to the bin size for histograms. The kernel function $K$ indicates the weight we assign each observation $X_i$ and is oftentimes taken to be the Gaussian kernel with
\begin{align*}
   K(t) = \frac{1}{(2 \pi)^{d/2}} \; \exp \left( -\frac{\vert t \vert^2}{2} \right).
\end{align*}
The appropriate choice of $b$ and $K$ can ensure the uniform convergence of $\hat p$ to the true, underlying density $p$ (as in Assumption \ref{ass1}). Higher smoothness of the density $p$ is generally associated with faster convergence rates and we refer to \cite{Jiang2017}  and \cite{Scott2015} for a rigorous definition of KDE and associated convergence results.

%\todo{TODO: @Onder Merge with Overview of Techniques}
%\textbf{Density estimation in DP} Density estimation in general and KDE in particular is 
%an important tool in the black box assessment of DP. For some examples, we refer to \cite{??}, \cite{??} and \cite{..}\todo{please add the references you had in mind}. The reason is that DP can typically be expressed as some transformation of the density ratio $p/q$ - this is true for standard DP (a supremum), Rényi DP (an integral) and, as we exploit in this paper, $f$-DP via the Neyman-Pearson test.
%, i.e., 
%\begin{align*}
%    \mathbb{P} \left(\sup_{t} |\hat{p}(t)-p(t)|>a_n \right)=o(1)
%\end{align*}
%for a sequence $(a_n)_n$ with $a_n >0$ that converges to $0$. 
%We point the interested reader to \cite{Jiang2017}  and \cite{Scott2015} for a suitable choice of $K$ and $b$ and the construction of KDEs in general.



\subsection{Machine Learning Classifiers} \label{sec:class}
\textbf{Binary classifiers} is the final addition to our technical toolbox. We begin with some notations: We denote a generic classifier on the Euclidean space $\mathbb{R}^d$ by $\phi$. Formally, a {\em classifier} is not different from a statistical test: It is a (potentially random) binary function $\phi: \mathbb{R}^d \to \{0,1\}$. However, its interpretation is different from hypothesis testing, because we do not have a default belief in a label $0$ or $1$. 
%both binary labels $0$ and $1$ are equal and we do not have a default belief. 
Let us now consider a probability distribution $\mathcal{P}$ on the combined space of inputs and outputs $\mathbb{R}^d \times \{0,1\}$. A classification error has occurred for a pair $(x,y) \in \mathbb{R}^d \times \{0,1\}$, whenever $\phi(x) \neq y$. If $(x,y)$ are randomly drawn from $\mathcal{P}$, we define the risk of the classifier $\phi$ w.r.t. to $\mathcal{P}$ as
    \begin{align*}
        R(h) = \Pr\limits_{(x,y)\sim \Dist}[\phi(x) \neq y].
    \end{align*}
\smallskip
\noindent \textbf{Bayes Classification Problem.} The Bayes classification problem refers to a setup to generate the distribution $\mathcal{P}$, where a Bernoulli random variable $\rY \in \{0,1\}$ is drawn and then, a second variable $X$ with
\begin{align*}
    (\rX|\rY=0) \sim P, \qquad (\rX|\rY=1) \sim Q.
\end{align*}
% and the task is to minimize the risk. 
In our work, we specifically consider the case where $\rY$ is drawn from a fair coin flip (i.e., $\Pr[\rY=0] = \Pr[\rY=1] = \frac{1}{2}$), and we denote this setup by $\bbcP{P}{Q}$.

\smallskip
% \noindent \textbf{Optimal classifiers} The \textit{Bayes optimal classifier} $\phi^*$ is the one that has minimal risk in the Bayes classification problem. In practice, $\phi^*$ is typically unknown, because it depends on the (unknown) $P,Q$. However, it is possible to approximate $\phi^*$ using the feasible nearest neighborhood classifier. More concretely, one train a kNN classifier $\kNNclassifier{n}$ with $n$ samples by simply storing $n$ independent samples from distribution $\mathcal{P}$. To predict the label of an observation $o \in \cO,$ $\kNNclassifier{n}$ returns the label taking a majority vote of the class labels of its $k$ nearest neighbors (Euclidean distance in our context) in the stored training points. 

\noindent \textbf{Bayes (Optimal) classifiers.} $\phi^*$ minimizes the risk in the Bayes classification problem. However, $\phi^*$ is usually unknown in practice because it depends on the (unknown) $P$ and $Q$. To approximate $\phi^*$, one can use a feasible nearest-neighbor classifier~\cite{altman1992introduction}. Specifically, a $k$-nearest neighbors ($k$-NN) classifier, denoted as $\kNNclassifier{n}$, assigns a label to an observation $o \in \cO$ by identifying its $k$ closest neighbors\footnote{In our context, closeness is measured using Euclidean distance} from the size $n$ training set. The label is then determined by a majority vote among these $k$ neighbors.


% Specifically, a $k$-nearest neighbors ($k$-NN) classifier, denoted as $\kNNclassifier{n}$, can be trained using $n$ independent samples drawn from the distribution $\mathcal{P}$. To predict the label of an observation $o \in \cO$, $\kNNclassifier{n}$ returns a label based on a majority vote of the class labels of the $k$ nearest neighbors (measured using Euclidean distance in our context) among the stored training samples.

% \textcolor{orange}{\textbf{Yu:} Write (very very shortly) what the kNN classifier is - it is not defined. Do not use additional notations, besides $\kNNclassifier{n}$. Then state the below theorem with the new, \underline{pruned notations} from the above paragraph! Adjust notations in 5.1 accoridngly. We need to reduce notations!!}

The following convergence result for $k$-NN gauges how close the true risk $R(\kNNclassifier{n})$ of the $k$-NN classifier $\kNNclassifier{n}$ is to the risk of the optimal classifier, $R(\phi^{*})$. 


\begin{theo} [\textbf{Convergence of $k$-NN Classifier}~\cite{Books:DGL96}]
\label{thm:covergence of kNN}
Let $\Dist$ be a joint distribution with  support  $\cO \times \mathcal{Y}.$ If the conditional distribution $\Dist|\mathcal{Y}$ has a density, $\cO \subseteq \mathbb{R}^d,$ and $k = \sqrt{n},$ then for every $\epsilon >0$ there is an $n_0$ such that for $n>n_0,$ 
{\small
    \begin{align*}
        \Pr[|R(\kNNclassifier{n}) - R(\phi^{*})| > \epsilon] \leq 2e^{-n\epsilon^2/(72c^2_d)},
    \end{align*}
}
where $c_d$\footnote{By Lemma 5.5 of~\cite{Books:DGL96}, $c_d$ satisfies $c_d \leq (1+{2}/{\sqrt{2-\sqrt{3}}})^d - 1$.} is the minimal number of cones centered at the origin of angle $\pi/6$ that cover $\mathbb{R}^d.$ Note that if the number of dimensions $d$ is constant, then $c_d$ is also a constant.
\end{theo}


%\todo{TODO: @Onder Merge with Overview of Techniques}
%\textbf{Classifiers in DP} The recent Eureka estimator~\cite{Lu2024} related Bayes classifiers to DP. Through the established connection between DP and $f$-DP~\cite{Dong2022}, their results imply an indirect link between Bayes classifiers and $f$-DP already. However, this connection is somewhat obscure, as fully recovering the $f$ function requires knowledge of every parameter tuple $(\varepsilon, \delta)$ for $\varepsilon \geq 0$ in approximate DP, which appears computationally infeasible. In this paper, we study (optimal) classifiers directly within the framework of $f$-DP, forging a new and explicit link between the two.

% \textbf{Classifiers in DP} The recent Eureka estimator~\cite{Lu2024}  related Bayes classifiers to  DP. Through the established connection between  DP and $f$-DP~\cite{Dong2022}, their results imply an indirect link between Bayes classifiers and $f$-DP already. However, this connection is rather obscure, since the relation of $f$-DP and approximate DP itself is non-trivial \MD{I dont understand why the relation is non-trivial?
% We might want to say sth like: the relation between $f$-DP and approximate DP is local in a sense that any pair $(\varepsilon,\delta)$ only leads one point $(\alpha,\beta)$?! Therefore to make use of the connection, one would have to compute many $\varepsilon, \delta$ pairs}. In this paper, we study (optimal) classifiers directly within the framework of $f$-DP, forging a new and explicit link between the two.

% \textbf{Classifiers in DP}  Recently, optimal classifiers have been related to approximate DP in \cite{Lu2024} and given the connection of approximate DP to $f$-DP, they are indirectly connected to $f$-DP already. This connection however is rather obscure, since the relation of $f$-DP and approximate DP itself is non-trivial. In this paper, we study (optimal) classifiers in the context of $f$-DP and forge a new, direct link between the two topics.



