\section{Related Work}
\label{sec:relatedwork}




%{\color{orange}We discuss the techniques used in related work, and why they were not sufficient in our goal to construct a general $f$-DP estimator and auditor. 
%First, given a known connection between $f$-DP and DP, one possible avenue to studying $f$-DP guarantees is to make use of an existing DP estimator or auditor. 
%Concretely____, a $(\epsilon,\delta)$-DP 
% algorithm $M$ is also $f_{\varepsilon, \delta}$-DP with %trade-off function 
%\begin{align} \label{f_epsilon_delta}
%    f_{\varepsilon, \delta}(\alpha) := \max \left\{ 0, 1 - \delta - e^{\varepsilon} \, \alpha, e^{- \varepsilon} (1 -\delta - \alpha) \right\}.
%\end{align}

%}
In this section, we provide a more detailed overview of and comparison with related works that focus on the empirical assessment of $f$-DP. One avenue to assessing $f$-DP is to resort to a method that provides estimates for the $(\varepsilon,\delta)$-parameter of $M$ and subsequently exploit the link between standard and $f$-differential privacy to obtain an estimate of $f$. To be more concrete, an algorithm that is $(\varepsilon,\delta)$-DP is also $f_{\varepsilon, \delta}$-DP (see ____) with trade-off function 
\begin{align} \label{f_epsilon_delta}
    f_{\varepsilon, \delta}(\alpha) := \max \left\{ 0, 1 - \delta - e^{\varepsilon} \, \alpha, e^{- \varepsilon} (1 -\delta - \alpha) \right\}.
\end{align} 
Thus, an estimator for $(\varepsilon, \delta)$ could, in principle, also provide an estimate for the $f$ trade-off curve of $M$. 

%{\color{orange} In ____, the above relation is used as a hockey-stick-divergence-based black-box estimator for $(\epsilon, \delta)$-DP. That is, given a fixed $\varepsilon >0$, the estimate $\hat{\delta}(\epsilon)$ is}
Given a fixed $\varepsilon >0$, a black-box estimation method based on the hockey stick divergence is proposed in ____ to obtain a suitable estimate $\hat{\delta}(\epsilon)$ with 
\begin{align*}
  \hat{\delta} = \int \left[ \hat{p}(t) - e^{\varepsilon} \hat{q}(t) \right]_+  \, dt ~,
\end{align*}
where $\hat{p}$ and $\hat{q}$ are histograms of densities $p \sim M(D)$ and $q \sim M(D')$. 
%\color{orange}Unfortunately, auditing $f$-DP requires more specialised tools than the above connection, as $f_{\epsilon, \delta}$ often does not capture the optimal achievable trade-off curve for mechanism $M$. }
It is subsequently discussed that one application of this $(\varepsilon, \delta)$-estimator could be the estimation of the trade-off function of $M$ via $f_{\varepsilon,\hat{\delta}}$ (see Algorithm 1 in ____). However, it stands to reason that to audit the $f$-DP claims of a given algorithm, one should use tools that are also tailored to the $f$-DP definition. %(instead of standard DP)\todo{I'm not sure what does this sentence mean? Do you mean `However, it stands to reason that to audit the f-DP claims of a given algorithm, one must use tools that are also tailored...'}. 
This is especially reasonable in scenarios where $f_{\epsilon,\delta} $ does not capture the exact achievable trade-off between type 1 and 2 errors for a given mechanism $M$. 
For instance, consider the Gaussian mechanism that adds random noise $\mathcal{N}(0, \sigma^2)$ with $\sigma = 1$ to a statistic $S$ with sensitivity $\Delta = 1$. Given fixed $\varepsilon > 0$, 
\begin{align*}
    \delta = \Phi \left( \frac{\Delta}{2} - \frac{\varepsilon}{\Delta}  \right) - e^{\varepsilon} \, \Phi \left( - \frac{\Delta}{2} - \frac{\varepsilon}{\Delta}  \right) 
\end{align*}
is the optimal achievable $\delta$ for this algorithm ____. Figure \ref{Fig_f_epsilon_delta} shows the corresponding trade-off function $f_{\epsilon,\delta}$ (for $\varepsilon = 1$) and the exact trade-off curve (see ____) for this mechanism given by 
\begin{align*}
    f_{\Delta}(\alpha) = \Phi(\Phi^{-1}(1 - \alpha) - 1).
\end{align*}


\begin{figure}
\centering
\includegraphics[width=.45\textwidth]{Figures/plot_oender_fixed.png}
\caption{Trade-off functions $f_{\varepsilon, \delta}$ (red) and $f_{\Delta}$ (blue).} 
\label{Fig_f_epsilon_delta}
\end{figure}

The figure shows that $f_{\varepsilon,\delta}$ does not provide a tight approximation of $f_{\Delta}$ over all regions. 
While one can improve this approximation by estimating $f_{\varepsilon,\delta}$ for several $(\varepsilon, \delta)$ and choose the best approximation over these (see Algorithm 1 in ____), %it becomes clear that 
an auditing procedure which estimates $f_{\Delta}$ directly (such as ours) is more expedient. 
In fact, the runtimes reported for estimation of $f$ in Sec.~\ref{sec6} confirm the efficacy of our approach. Moreover, from an auditing perspective, results with regard to convergence and reliability in ____ are only obtained for the $\hat{\delta}(\epsilon)$-estimate in the standard DP framework. Our work, on the other hand, provides formal statistical guarantees for the inference of the trade-off $f$.%\todo{Question: But we only have confidence bound for auditing, rather than estimation, right?}.


Interestingly, the relation between standard and $f$-DP can also be exploited in the opposite direction, that is, to use estimates of the trade-off curve $f$ to obtain estimates for $(\varepsilon, \delta)$. This approach has been adopted in recent works for the purpose of auditing the privacy claims of DP-SGD ____, a cornerstone of differentially private machine learning. 
In ____, auditing procedures are considered for both black- and white-box scenarios. In the black-box setting, the auditor has access to the training datasets $D$ and $D'$, the corresponding final models $\theta$ and $\theta'$, as well as the specific loss function $\ell$ used by DP-SGD, together with evaluations of $\ell$ on the finals models and some chosen canary input $(x',y')$. As for the white-box setting, the auditor is also allowed to examine all intermediate model updates that go into computing the final models. Moreover, the auditor is allowed to actively intervene in the training process by inserting self-crafted gradients or datasets into the computations that yield $\theta$ and $\theta'$. Given the above settings,____ examine the $f$-DP of DP-SGD with a focus on two special classes of trade-off functions: approximations over functions of the form $f_{\epsilon,\delta}$ in \eqref{f_epsilon_delta} or Gaussian trade-off curves of the form
\begin{align} \label{Trade-off_mu}
    T_{\mu}(\alpha) = \Phi(\Phi^{-1}(1 - \alpha) - \mu)
\end{align}
with $\mu >0$. Estimates for the $\varepsilon$-parameter of DP-SGD based on these trade-off functions can be obtained in the following manner: one can repeatedly run a distinguishing attack on the output of DP-SGD, compute Clopper-Pearson confidence intervals $(\underline{\alpha},\overline{\alpha})$ and $(\underline{\beta},\overline{\beta})$ for the FPR and FNR of this attack and then proceed to estimate a lower bound on the parameter $\mu$ of our tradeoff curves via \eqref{Trade-off_mu} with
\begin{align*}
    {\mu}^{lower} = \Phi^{-1}(1 - \bar{\alpha}) - \Phi^{-1}( \bar{\beta}).
\end{align*}
A lower bound for $\mu$ yields an upper bound on the trade-off curve $T_{\mu}$. In combination with a fixed $\delta$ and the approximation in \eqref{f_epsilon_delta}, this curve is then used to obtain the largest lower bound for $\varepsilon$ over all $\alpha$. This lower bound then serves as an empirical estimate for the $\varepsilon$-parameter of DP-SGD. In ____, the same procedure is deployed and combined with specially crafted worst-case initial parameters $\theta_0$ to obtain tighter audits for DP-SGD in the black-box setting of ____. The same method is also used to study various implementations of DP-SGD ____ or the impact of shuffling on its privacy ____. The approach in ____, which is based on guessing games, also relies on a predefined family of (Gaussian) trade-off functions to audit DP-SGD and derive the empirical privacy $\varepsilon$ for any given $\delta$. In contrast, the methods in our work are not tailored to a specific subset of trade-off functions. In fact, our estimation method makes no assumptions about the underlying optimal trade-off curve $f$, while our auditing method only requires strict convexity. Furthermore, the black-box setting, under which our procedure can operate, is even more restrictive than the one investigated in previous works ____. In fact, our approach does not require access to the specific loss function that DP-SGD uses and only assumes access to the input databases $D$, $D'$ and mechanism outputs (or final models) $M(D), M(D')$. These features make our estimation and auditing methods more flexible and more broadly applicable in comparison to prior work.


% \begin{itemize}
%     \item f-DP
%     \item DP estimators/violation detection algorithms (cite our estimator papers) 
%     \item Using hypothesis testing and the connection between FPR/FNR and DP to audit DP: Tight auditing of differentially private machine learning (USENIX); Bayesian estimation of differential privacy
% \end{itemize}
% Story:
% \begin{itemize}
%     \item f-DP connects classical privacy notions and classical statistical theory. 
%     \item f-DP is the state of art framework to construct algorithms usable in practice. 
%     \item leads tight analysis of SGD.
%     \item algorithms can violate privacy. (faulty implementation or construction of algorithms)
%     \item black-box DP estimation can detect that
%     \item DP estimation: white-box, black-box. 
% \end{itemize}

% Differential Privacy, first introduced by \todo{cite dwork} has emerged as a foundational concept in privacy-preserving data analysis. While its classical definition in \todo{cite dwork} already has a statistical flavor, a clear connection to classical statistics has first been made by \todo{cite wassermann}, and more recently by \todo{cite fdp}. While \todo{cite wassermann} already depicted implications from the classical definition to hypotheses testing, \todo{cite fdp} also demonstrated the reverse and further applications, marking a milestone in tight analysis of privacy-preserving algorithms. Notably, $f-$DP has led to a refined and tight analysis of stochastic gradient descent (SGD), a widely-used optimization technique in machine learning (\todo{cite}). As, classical DP or $f-$ DP is a formal guarantee for any individual, a tight analysis is not only desirable, but also necessary to make algorithms practical. However, even with rigorous frameworks like $f$-DP, privacy violations can occur due to faulty implementations or poorly constructed algorithms \todo{cite some and give more context}. To overcome that practical challenge, the estimation of DP algorithms in both white- and black-box scenarios has drawn considerable interest. For example \todo{cite white box} considered the white-box setting, which is often not possible in practice. In contrast, black-box DP estimation has gained attention for its ability to detect privacy violations in a practical and accessible manner. For example, \todo{cite our papers and possibly others} explored black-box estimation across various DP notions, including classical DP, RÃ©nyi-DP, and approximate DP. Black-box estimation is inherently more challenging yet more realistic, as it assumes no prior knowledge of the mechanism's internal workings, relying solely on its observable outputs. Auditing $f-$DP has also been considered in various works. For example, \todo{cite usenix best paper award paper} estimated f-DP both in the white- and black-box setting. \todo{honestly, I am struggling to state clear differences. we just use a different estimator I guess.}