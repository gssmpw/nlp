%File: formatting-instructions-latex-2025.tex
%release 2025.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{multirow}
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash

    % Napat Laosaengpha\textsuperscript{\rm 1},
    % Thanit Tativannarat\textsuperscript{\rm 1},
    % Attapol Rutherford\textsuperscript{\rm 2},
    % Ekapol Chuangsuwanich\textsuperscript{\rm 1},
    
\title{Mitigating Language Bias in Cross-Lingual Job Retrieval: A Recruitment Platform Perspective}
\author{
    %Authors
    % All authors must be in the same font size and format.
    Napat Laosaengpha\textsuperscript{\rm 1}, Thanit Tativannarat\textsuperscript{\rm 1}, Attapol Rutherford\textsuperscript{\rm 2}, Ekapol Chuangsuwanich\textsuperscript{\rm 1}
}
\affiliations{
    %Afiliations
    \textsuperscript{\rm 1} Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University \\
    \textsuperscript{\rm 2} Department of Linguistics, Faculty of Arts, Chulalongkorn University \\
    \small{\texttt{ \{napatnicky,thanit.tati\}@gmail.com \{attapol.t,Ekapol.C\}@chula.ac.th} }
    
    % \texttt{{attapol.t@chula.ac.th} \quad{ekapolc@cp.eng.chula.ac.th} } 
    
    % \small{\texttt{{attapol.t@chula.ac.th} \quad{ekapolc@cp.eng.chula.ac.th}}
    
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar\textsuperscript{\rm 2}, 
    % J. Scott Penberthy\textsuperscript{\rm 3}, 
    % George Ferguson\textsuperscript{\rm 4},
    % Hans Guesgen\textsuperscript{\rm 5}
    % Note that the comma should be placed after the superscript

    % 1101 Pennsylvania Ave, NW Suite 300\\
    % Washington, DC 20004 USA\\
    % % email address must be in roman text type, not monospace or sans serif
    % proceedings-questions@aaai.org
%
% See more examples next
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    % Napat Laosaengpha\textsuperscript{\rm 1},
    % Thanit Tativannarat\textsuperscript{\rm 1},
    % Attapol Rutherford\textsuperscript{\rm 2},
    % Ekapol Chuangsuwanich\textsuperscript{\rm 1},
    
}
\affiliations {
    
    % \textsuperscript{\rm 1}Affiliation 1\\
    % \textsuperscript{\rm 2}Affiliation 2\\
    % firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
Understanding the textual components of resumes and job postings is critical for improving job-matching accuracy and optimizing job search systems in online recruitment platforms. However, existing works primarily focus on analyzing individual components within this information, requiring multiple specialized tools to analyze each aspect. Such disjointed methods could potentially hinder overall generalizability in recruitment-related text processing. Therefore, we propose a unified sentence encoder that utilized multi-task dual-encoder framework for jointly learning multiple component into the unified sentence encoder. The results show that our method outperforms other state-of-the-art models, despite its smaller model size. Moreover, we propose a novel metric, Language Bias Kullback–Leibler Divergence (LBKL), to evaluate language bias in the encoder, demonstrating significant bias reduction and superior cross-lingual performance.
\end{abstract}

% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{Introduction}

The online job recruitment platforms have emerged as essential tools to streamline and accelerate the talent acquisition process. These platforms usually rely on essential details from resume and job posting to facilitate the connection between recruiters and job seekers. The resumes showcase personal overview of candidate's capabilities including work experience, skills and expertise, whereas the job postings outline job title, specialties and responsibility for open positions. 

Therefore, understanding the semantic meaning of the textual information within resumes and job postings would greatly facilitate the matchmaking process on the online job recruitment platform, where the underlying process is an automatic job recommendation system \cite{DBLP:journals/corr/abs-2107-00221}. Additionally, this understanding could be further developed into analytical tools for various job-related tasks such as job mobility prediction \cite{zha2024towards} and job demand forecasting \cite{lu2022human}.
% and job benchmarking \cite{zhang2019job2vec}.

% zhang2021attentive,kaya2021effectiveness,zhang2021talent,

Previous approaches to understanding this textual information as low-dimensional dense sentence representations primarily focus on a individual component within the resumes and the job posting such as job title (JT) \cite{DBLP:journals/corr/abs-2109-09605,laosaengpha-etal-2024-learning}, job description (JD) \cite{goyal-etal-2023-jobxmlc} and skills set \cite{lin2023skill}. 

% javed2017large,
% bhola2020retrieving,
% ,Bocharova_2023,DBLP:journals/corr/abs-2207-00494


However, learning sentence representations in these previous works are constrained to handling the individual component, which limit their versatility in being applied to analyze the other job-related components. Moreover, the existing works often prioritize the study on a mainstream language like English, leaving non-English language especially in low-resource ones under-explored. It might be due to the scarcity of public dataset and the specialized nature of the job recruitment domain for non-English language. Additionally, their studies mainly cover monolingual setting, which might not applied to regions where the users often alternate between languages on the platform.

In this paper, we propose a multi-task learning framework to develop a bilingual sentence encoder (Thai and English) for general-purpose use in the recruitment domain by using label-free information from online user-generated job postings. We leverage a multi-task dual encoder framework, which is simultaneously trained on three proposed job-related tasks. The job-related training tasks consist of three tasks: (A) job title translation ranking, (B) job description-title matching, and (C) job field classification. This mitigates the aforementioned limitations by learning multiple components in a unified encoder and addressing the scarcity of human-labeled training data in low-resource language. Moreover, we conduct an comprehensive study to investigate cross-lingual capabilities and also propose a novel evaluation metric to quantify language bias in the bilingual sentence encoder, where this study could be linked to application in evaluating job search systems on the platform.

Our contributions are as follows:
\begin{itemize}

    % \item \textbf{Bilingual pretrained sentence encoder in Thai and English for job recruitment domain}: we propose the utilization of multi-task dual-encoder framework to train the multilingual sentence encoder. The job-related training tasks is divide into 3 parts : job title translation ranking task, job title and job description matching, and job field classification.
    \item \textbf{Multi-task learning framework}: We propose a multi-task dual-encoder framework that jointly learns multiple components within a bilingual sentence encoder (Thai and English) for the recruitment domain. 
    % Our evaluation demonstate that our encoder outperforms and is on par on JTG-Synonym and JTG-Occupation.
    
    \item \textbf{Cross-lingual and language bias analysis}: We present a novel metric to quantify language bias hidden in the sentence encoder for retrieval evaluation. We also conduct extensive study to investigate cross-lingual capabilities. The result show that our encoder achieve significantly lower language bias and improved cross-lingual performance compared to other state-of-the-art encoders.
    % The result show that there is a gap of difficulty between monolingual and cross-lingual. 
\end{itemize}

\section{Background and Related Work}

\subsubsection{Pretraining on the Job Recruitment Domain} Several works have studied pretrained language models in the job recruitment domain. \citeauthor{qin2018enhancing} \shortcite{qin2018enhancing} and \citeauthor{cao2024tarot} \shortcite{cao2024tarot} utilized user activity data from recruitment platforms to enhance language model performance for job recommendation. \citeauthor{zhang-etal-2023-escoxlm} \shortcite{zhang-etal-2023-escoxlm} is a recent effort in multilingual pretraining across 16 European languages, leveraging ESCO taxonomy as a training data for the language model. However, this data require human-labeled training data, which is challenging to obtain for low-resource language. 

To the best of our knowledge, \citeauthor{fang2023recruitpro} \shortcite{fang2023recruitpro} is the only work that has attempted to pretrain a language model by using multiple information on job-related domain. However, this work focus on a monolingual evaluation in English. The effectiveness of the model in a bilingual setting remains unexplored, particularly in terms of cross-lingual capability and language bias in sentence representation. 

% \subsubsection{Sentence Representation} Recent work has utilized pretrained language models (PLMs) such as BERT \cite{vaswani2017attention} and XLM-R \cite{conneau-etal-2020-unsupervised} to encode sentences by combining the embeddings of individual words to represent the entire sentence. Alternative state-of-the art models, such as LaBSE \cite{feng-etal-2022-language}, mUSE \cite{yang-etal-2020-multilingual}, and BGE-M3 \cite{chen-etal-2024-m3}, aim to pretrain on sentence-level representations.

\subsubsection{Language Bias} \citeauthor{roy-etal-2020-lareqa} \shortcite{roy-etal-2020-lareqa} studied the language bias problem inside the sentence representations on a multilingual question-answering retrieval task. They found that the language bias influences performance, as queries often prefer candidates from the corresponding language while neglecting their semantic meaning. The following works proposed various methods to mitigate this language bias on the representation through post-processing matrix transformations \cite{yang-etal-2021-simple,xie-etal-2022-discovering}. Furthermore, the language bias problem also occurs in coding language embeddings \cite{utpala-etal-2024-language}. However, there is a lack of evaluation metrics to quantify the amount of language bias hidden in representations, especially in retrieval settings.


\section{Proposed Method}
% In this section, we introduce the methodology for developing the bilingual sentence encoder for job-related domains using the online job postings, where the job titles, job descriptions, and job fields of each job posting are selected as training components. We also propose a novel evaluation metric to quantify the language bias hidden in our sentence representations.

 % We exploit this information as training data since it is created by job recruiters, who is a human resources (HR) personnel of a company being accustomed to the platform and trained to provide accurate job details.
 \begin{figure}[t]
\centering
\includegraphics[width=1\columnwidth]{Figures/framwork-gg.pdf}
\caption{The overview of our proposed multi-task dual-encoder framework used to train our sentence encoder. It illustrate the job title translation ranking task on the left, job description-title matching in the middle, and job field classification on the right.} 
\label{fig:first-arch}
\end{figure}

\subsection{Architecture}
An overview of our proposed method is shown in Figure~\ref{fig:first-arch}. The training process consists of three main tasks: (A) job title translation ranking, (B) job description-title matching, and (C) job field classification. Our inspiration originates from the multi-task dual encoder used in mUSE \cite{yang-etal-2020-multilingual}. However, job-related data doesn't lend itself to the traditional training tasks as described in the original paper. Therefore, we adapt to our specific requirements and designed job-related tasks to fine-tune the model. The training process is to consecutively train the model through the three job-related tasks one by one in each mini-batch, with equal weight penalty for each task.

% final
% the Multilingual Universal Sentence Encoder
% The following subs-chapter describes the training task consisting of job title translation ranking task, job description and title matching, and jobfield classification in detail.

\subsubsection{Job Title Translation Ranking Task (JT)}

% For example, "พนังงานบัญชี - Accountant," "พนักงานขายดีลเลอร์ กทม - Sales Representative (Bangkok)," "เจ้าหน้าที่บุคคล สำนักทรัพยากรมนุษย์ - HR Officer," etc., where the hyphen separates the pair of job titles, with the left representing the job title in Thai and the right in English.

The job title translation ranking task is responsible for aligning pairs of job titles that have the same semantic meaning but are in different languages to be closer in the high-dimensional space. The job title representation of both Thai and English are aligned by using contrastive loss \cite{gao-etal-2021-simcse} as a training objective to maximize a pairwise similarity between job title representations in Thai and English.
\begin{equation} 
    L_{i} = \log \frac{e^{sim(t_i,f_i)/\tau}}{\sum^N_{j=1}e^{sim(t_i,f_j)/\tau}}
\end{equation}
where $t_i$ and $f_i$ are the sentence embeddings of English and Thai job titles respectively, $sim(\cdot,\cdot)$ is the cosine similarity function, $\tau$ is the temperature scaling parameter, and $N$ is the number of negative samples.

% enhance the training process to only focus the hard negative samples in each mini-batch.


% We expect the model's text representations to have close similarity scores for the same job titles across languages. Furthermore, this task could help to enhance the cross-lingual capability of the model. 

% The architecture of the job title translation ranking task is illustrated in the left of the Figure~\ref{fig:first-arch}. The job title in Thai and English are separately fed into the sentence encoder. Then, the job title representation of both Thai and English ($h_{th},h_{en}$) are aligned by using contrastive loss \cite{gao-etal-2021-simcse} as a training objective to maximize a pairwise similarity between job title representation in Thai and English. The contrastive loss is scaled by the temperature parameter in order to enhance the training process to only focus the hard negative samples in each mini-batch.


% This task is designed to align job titles representation in both Thai and English.

% However, this approach can be further extended to multiple languages whenever job title pairs are available. After the training process, we expect the model's text representations to have close similarity scores for equivalent job titles across languages. Furthermore, this task could help to enhance the cross-lingual capability of the model. This would mitigate the limitation addressing in the original model, which had a restricted ability to understand corresponding sentences in different languages.

% The architecture of the job title translation ranking task is illustrated in the left of the Figure~\ref{fig:first-arch}. The job title in Thai and English are separately fed into the sentence encoder. Then, the job title representation of both Thai and English ($h_{th},h_{en}$) are aligned by using contrastive loss \cite{gao-etal-2021-simcse} as a training objective to maximize a pairwise similarity between job title representation in Thai and English. The contrastive loss is scaled by the temperature parameter in order to enhance the training process to only focus the hard negative samples in each mini-batch.

\subsubsection{Job Description-Title Matching (JD)}

The job description and title matching is designed to predict the correlation between the job description and job title whether they have a positive or negative relationship. The task mimics the matchmaking process in job recommendation system, where the job description is used to search for the most relevant candidate job title. We adopt the architectural design from Neural Language Inference (NLI) \cite{DBLP:conf/emnlp/ConneauKSBB17} to fit our task. The criteria for determining a positive sample between a job description and title is to use a pair of these from the same job posting. In contrast, negative pairs are created by sampling the other job postings and comparing their intersection over union (IoU) score of the job fields from the job postings. Pairs with IoU values below a threshold of 0.5 are classified as negative samples.

% The criteria for determining a positive sample between a job description and title is to use a pair of job description and title from the same job posting. As negative pairs are generated through negative sampling from other job postings by thresholding the intersection over union (IoU) of jobfield of jobposting at 0.5.



\begin{equation} 
    IoU_{ij}  = \frac{|JF_{i} \cap JF_{j}|}{|JF_{i} \cup JF_{j}|}
\end{equation}

where $JF$ is the list of job field in the job posting. 
% \begin{equation} 
%     Out = Concat([t,d,|t-d|,t*d])
% \end{equation}
% where $t$ and $d$ are title and job description embedding, respectively, $Concat$ is the concatenation function, and $*$ is an element-wise multiplication operator.




% chose to 

% Also, it is inspired from Neural Language Inference (NLI), which is the task of classifying if a hypothesis is entailment, contraction, or undetermined given a premise. Thus,

% Moreover, this architecture has demonstrated state-of-the-art performance in benchmarking tasks for Neural Language Inference (NLI) .

% The architecture of the job description and title matching is illustrated in the middle of the Figure~\ref{fig:first-arch}. The the job title and its description is individually fed into the sentence encoder. Then, the representation of job title and its description are processed by calculating the absolute difference and the dot product between both of them. Subsequently, the job title representation, job description representation, and two processed representations are concatenated into a unified vector representation. This unified vector is then fed into the fully connected layer to predict whether the job description and title have a positive or negative correlation. The criteria for determining the relationship between the job description and title are defined by calculating the mutual score obtained from intersect over union (IoU) of the job fields in different job postings. 

\subsubsection{Job Field Classification (JF)}

% For instance, "Sale engineer" can be categorized into the field of "Sales" and "Engineer" or "ช่างควบคุมเครื่องจักร" can be categorized into the field of "Technician" and "Engineer".

The job field classification is to classify the job title into multiple specified job field from a total of 28 categories. This task also demonstrates one of the interesting aspects that a job title is generally involved in more than one related job field. For instance, ``Sales engineer`` can be categorized into the field of "Sales" and "Engineer". This relationship between the job field and the job title would afford the model the benefit of enhancing its robustness in representing job titles, as it requires additional attention to handle the ambiguity inherent in the job titles.

% The architecture of the job field classification is illustrated in the right of the Figure~\ref{fig:first-arch}. This architecture is a traditional multiclass-classification framework. The job title is fed into the sentence encoder. Then, the job title representation is fed into fully connected layer to predict the job field corresponded to their job title.
\begin{table*}[t]
\centering
% \small
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lccccccc@{}}
\hline
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Method}}} & \multicolumn{1}{l}{\multirow{2}{*}{\textbf{\#Param \& Runtime}}} & \multicolumn{3}{c}{\textbf{JTG-Synonym}} & \multicolumn{3}{c}{\textbf{JTG-Occupation}} \\ \cmidrule(l){3-8} 
\multicolumn{1}{c}{}                                 & \multicolumn{1}{l}{}                                       & R@5         & R@10        & mAP@25       & Acc@1        & Acc@3        & Acc@5        \\ \midrule
XLM-R \cite{conneau-etal-2020-unsupervised}                                               & 279M / 0.46 ms                                                        & 15.11       & 18.68       & 10.27        & 47.65        & 67.33        & 76.02         \\ \midrule
LaBSE \cite{feng-etal-2022-language}                                               & 424M / 0.48 ms                                                       & 48.63       & 60.02       & 37.83        & 60.07        & 80.89        & 87.10         \\ 
BGE-m3 \cite{chen-etal-2024-m3}                                              & 567M / 0.55 ms                                                       & 49.83       & 61.11       & 38.03        & 61.22        & 82.04        & 90.06         \\ \midrule
mUSE\textsubscript{small}CNN-based \cite{yang-etal-2020-multilingual}                                                & 69M  / 0.24 ms                                                       & 
50.83         & 61.91         & 39.23          & 58.07          & 79.27          & 86.53           \\
mUSE\textsubscript{small}CNN-based (ours)                                          & 69M / 0.24 ms                                                         & \textbf{64.89}       & \textbf{79.43}       & \textbf{52.25}        & \textbf{69.53}        & \textbf{87.67}       & \textbf{92.93}         \\ \bottomrule
\end{tabular}
}
\caption{The performance evaluation of our method against other state-of-the-art models on the JTG-Synonym and JTG-Occupation evaluation datasets. The runtime complexity was measured using the JTG-Synonym dataset and evaluated on an NVIDIA RTX 3090 GPU (24GB) paired with an Intel Xeon Silver 4210 CPU (2.20GHz).}
\label{tab:main-result}
\end{table*}

% The best results are bolded, and the second-best are underlined.





\section{Experimental Setup}
% We provide the detail of evaluation method and dataset such as JTG-Synonym and JTG-Ocupation to evaluate our proposed model performance for the general-purpose use in the job application domain.

% It show an setting overview  of this work including training data and evaluation tasks. The training data is JTG-jobposting, and evaluation dataset are JTG-synonym and JTG-occupation. 

We outline the evaluation dataset and method, including JTG-Synonym, JTG-Occupation, and JTG-Jobposting.




% \begin{table}[h]
% \centering
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{@{}ccc@{}}
% \toprule
% \textbf{Training Dataset}       & \textbf{Evaluation Dataset} & \textbf{Metric}   \\ \midrule
% \multirow{2}{*}{JTG-jobposting} & JTG-Synonym                 & R@5,R@10,mAP@25  \\ \cmidrule(l){2-3} 
%                                 & JTG-Occupation              & Acc@1,Acc@3,Acc@5 \\ \bottomrule
% \end{tabular}%
% }
% \caption{Experiment setup overview}
% \label{tab:exp_setup}
% \end{table}

\subsubsection{JTG-Jobposting}
We use job postings from Jobtopgun.com, a renowned recruitment website in Thailand. It consists of Thai and English job titles, their descriptions, and job fields. For our framework, we used a training data set consisting of 209,785 job postings.


% We obtained raw job postings from JOBTOPGUN's platform, a leading recruitment platform in Thailand. The job postings contain various many job-related information. In this work, we use the following fields from the job postings as the training data:
% \begin{itemize}
% \item \textbf{"Position\_Name\_TH"} : represent as a Thai job title 
% \item \textbf{"Position\_Name\_EN"} : represent as a English job title 
% % \item \textbf{"Skill\_Hashtag"} : the skill tags assigned by the recruiter.
% % \item \textbf{"Jobfield\_List"} : is a multi-label tagging of job fields in each job posting, consisting of a total of 28 labels.
% \item \textbf{"Job\_Description"}: a job description for the job posting.
% \item \textbf{"Job\_Field"}: a multi-label tagging of job fields for the job posting.
% \end{itemize}




% 50.83         & 61.91         & 39.23

\subsubsection{JTG-Synonym}
The JTG-Synonym is a synonym list that includes different variants of the same job title in Thai and English. To evaluate on the JTG-Synonym, we formulated the task as a bilingual retrieval task, where the dictionary keys (job title) were used as query and all synonyms were used as the candidate pool. Each query was performed on the English and Thai candidate pools separately to calculate the R@5, R@10, and mAP@25. The final metric values were obtained by micro-averaging across every query. The test set contains 4,420 queries (2,261 in Thai, 2,103 in English, and 56 code-switching) and a candidate pool of 34,589 entries, with 16,905 in Thai and 17,684 in English.
% More dataset detail show in \cite{laosaengpha-etal-2024-learning}

% This evaluation protocol is  intentionally designed to avoid language bias where a Thai query will prefer Thai candidates more and vice versa. 

% Additionally, this metric can be viewed as a use-case for a search engine when users have filled their job in a search bar on the platform. It can help to provide users with a more comprehensive list of job opportunities and increase the chances of finding a suitable match, improving the overall user experience on the platform.

 % Examples are shown in Table \ref{tab:occ}.
\subsubsection{JTG-Occupation}
The JTG-Occupation is a collection of job title along with their corresponding occupation groups. The dataset contains 5,801 samples with a total of 135 unique labels. We split the data into 4,641 samples for training and 580 samples each for validation and testing. To evaluate the embeddings generated by the sentence encoder, we created a linear classifier layer on top of it. Then, we trained the classifier on top of the embedding to predict their occupation while freezing the sentence encoder.

% \begin{table}[ht]
% \centering
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{@{}rr@{}}
% \toprule
% \textbf{Job title}                          & \textbf{Occupation Group}              \\ \midrule
% Government employee                & Administration                 \\
% PROCESS TECHNOLOGIST               & Engineering                    \\
% % นักนิเวศวิทยา/Ecological Scientist & Ecological Scientist           \\
% Waxing Therapist                   & Medical Therapy/Rehab Services \\ \bottomrule
% % ช่างควบคุมเครื่องจักร              & Operation Staff                \\ 
% \end{tabular}%
% }
% \caption{An example of sample in the occupation evaluation dataset}
% \label{tab:occ}
% \end{table}
\subsubsection{Baseline Methods}

We benchmarked our method against two categories of multilingual pretraining models: a Mask Language Model (MLM) based model - XLM-R \shortcite{conneau-etal-2020-unsupervised}, and sentence-level models - mUSE \shortcite{yang-etal-2020-multilingual}, LaBSE \shortcite{feng-etal-2022-language} and BGE-M3 \shortcite{chen-etal-2024-m3}. The base sentence encoder chosen for our method is the mUSE\textsubscript{small}CNN due to its run-time efficiency, enabling real-time processing on recruitment platforms.

\subsubsection{Implementation Details}

The temperature scaling for the job title translation ranking task is of 0.05. The top fully connected layers for both the job field classification and the job description and title matching are set as 2 dense layers with 512 dimensions. We use a batch size of 512 and uses the Adam optimizer with 3e-5 learning rate. 

\subsection{Language Bias Metric}
We propose a novel evaluation metric, \textbf{Language Bias Kullback–Leibler Divergence (LBKL)}, to measure language bias in retrieval settings. This metric compares the distribution of language proportions between the ground truth and the predicted list for each query. Given an ordered list of retrieved items, this metric is designed to assess the language bias in the retrieved list without considering model accuracy. 
\begin{equation} 
    LBKL = \frac{\sum_{i=1}^{q} \left[ P_{th}(x) \log(\frac{P_{th}(x)}{Q_{th}(x)}) +  P_{en}(x) \log(\frac{P_{en}(x)}{Q_{en}(x)}) \right]}{q}
\end{equation}

where $P_{th}(x)$ and $P_{en}(x)$ are the proportion of Thai and English in the ground truth list for each query, $Q_{th}(x)$ and $Q_{en}(x)$ are the proportion of Thai and English in the predicted list in each query, $q$ is the number of queries.
% used to calculate the LBKL
% $th$ stands for Thai, and $en$ stands for English.



% We utilize mUSE\textsubscript{small}CNN-based as a shared encoder. 

% to conduct experiments in each downstream task
% The scheduling for the learning rate is set as a warm-up strategy starting with zero and increasing until it reaches 10\% of the total step, then the learning rate remains constant. \cite{DBLP:journals/corr/KingmaB14}

\section{Main Result}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}


% The main result is shown in table \ref{tab:main-result}. Our method significantly outperform on JTG-Synonym dataset, achieving up to 15\% gain in the mAP@25. And, it achieve 2\% Accimprovement over BGE-M3 on JTG-Occupation dataset, despite having a much smaller number of parameters. 


The main results are shown in table \ref{tab:main-result}. Our method consistently outperforms all previous state-of-the-art models across all metrics in both evaluation settings on JTG-Synonym and JTG-Occupation. Furthermore, it is much smaller in terms of parameters and the runtime complexity.

\subsubsection{Ablation Study}
We perform an ablation study to explore the performance improvements achieved by each of our proposed tasks. Specifically, we evaluate the model’s performance when trained exclusively on a single task, including job title translation ranking, job description-title matching, and job field classification.
\begin{table}[ht]
\centering
\begin{tabular}{lll}
\hline
              & \multicolumn{1}{c}{\textbf{JTG-Synonym}} & \multicolumn{1}{c}{\textbf{JTG-Occupation}} \\ \hline
mUSE          & 61.91                                    & 86.53                                       \\ \hline
+ (A) JT      & 77.43 (+15.52)                           & 89.38 (+2.85)                               \\
+ (B) JD      & 66.41 (+04.50)                           & 87.77 (+1.24)                               \\
+ (C) JF      & 61.50 (- 00.41)                          & 89.20 (+2.67)                               \\ \hline
\textbf{Ours} & 79.43 (+17.52)                           & 92.93 (+6.40)                               \\ \hline
\end{tabular}%
\caption{A performance comparison for each of our proposed training tasks, evaluated using JTG-Synonym (R@10 $\uparrow$) and JTG-Occupation (Acc@5 $\uparrow$).}
\label{tab:abla-syn}
\end{table}







% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \begin{table}[ht]
% \centering
% \small
% % \resizebox{\columnwidth}{!}{%
% \begin{tabular}{lcc}
% \hline
%          & \textbf{JTG-Synonym} & \textbf{JTG-Occupation} \\ \cline{2-3} 
%          & \textbf{R@10}      & \textbf{Acc@5}          \\ \hline
% mUSE     & 61.91                & 88.44                   \\ \hline
% + (A) JT & 77.43                & 92.26                   \\
% + (B) JD & 66.41                   & 91.98                   \\
% + (C) JF & 61.50                  & 91.79                   \\ \hline
% Ours     & \textbf{79.43}       & \textbf{92.65}          \\ \hline
% \end{tabular}%
% % }
% \caption{A comparison of performance gains for each of our proposed training tasks.}
% \label{tab:abla-syn}
% \end{table}



% \begin{table}[ht]
% \centering
% \begin{tabular}{lll}
% \hline
% % \toprule
%          & \multicolumn{1}{c}{\textbf{JTG-Synonym}} & \multicolumn{1}{c}{\textbf{JTG-Occupation}} \\ \cline{2-3} 
%          & \multicolumn{1}{c}{\textbf{R@10}}        & \multicolumn{1}{c}{\textbf{Acc@5}}          \\ \hline
% mUSE     & 61.91                                    & 86.53                                       \\ \hline
% + (A) JT & 77.43 (+15.52)                            & 89.38 (+2.85)                              \\
% + (B) JD & 66.41 (+04.50)                            & 87.77 (+1.24)                              \\
% + (C) JF & 61.50 (- 00.41)                            &  89.20 (+2.67)                              \\ \hline
% Ours     & \textbf{79.43} (+17.52)                           & \textbf{92.93} (+6.40)                             \\ \hline
% \end{tabular}%
% % }
% \caption{A comparison of performance gains for each of our proposed training tasks.}
% \label{tab:abla-syn}
% \end{table}



% \begin{table}[ht]
% \centering
% \begin{tabular}{lll}
% \hline
%          & \multirow{2}{*}{\textbf{LBKL}$\downarrow$} & \multicolumn{1}{c}{\textbf{JTG-Synonym}} & \multicolumn{1}{c}{\textbf{JTG-Occupation}} \\ \cline{3-4} 
%          &                       & \multicolumn{1}{c}{\textbf{R@10}}        & \multicolumn{1}{c}{\textbf{Acc@5}}          \\ \hline
% mUSE     & 1.20                  & 61.91                                    & 86.53                                       \\ \hline
% + (A) JT & 0.40                  & 77.43 (+15.52)                           & 89.38 (+2.85)                               \\
% + (B) JD & 1.26                  & 66.41 (+04.50)                           & 87.77 (+1.24)                               \\
% + (C) JF & 1.19                  & 61.50 (- 00.41)                          & 89.20 (+2.67)                               \\ \hline
% Ours     & \textbf{0.39}                  & \textbf{79.43} (+17.52) & \textbf{92.93} (+6.40)     \\ \hline
% \end{tabular}%
% \caption{A comparison of performance gains and language bias for each of our proposed training tasks.}
% \label{tab:abla-syn}
% \end{table}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \begin{table}[ht]
% \centering
% \begin{tabular}{lll}
% \hline
%          & \multicolumn{1}{c}{\textbf{JTG-Synonym}} & \multicolumn{1}{c}{\textbf{JTG-Occupation}} \\ \cline{2-3} 
%          & \multicolumn{1}{c}{\textbf{R@10}}        & \multicolumn{1}{c}{\textbf{Acc@5}}          \\ \hline
% mUSE     & 61.91                                    & 86.53                                       \\ \hline
% + (A) JT & 77.43 (+15.52)                           & 89.38 (+2.85)                               \\
% + (B) JD & 66.41 (+04.50)                           & 87.77 (+1.24)                               \\
% + (C) JF & 61.50 (- 00.41)                          & 89.20 (+2.67)                               \\ \hline
% \textbf{Ours}     & 79.43 (+17.52)                           & 92.93 (+6.40)                               \\ \hline
% \end{tabular}%
% \caption{A comparison of performance gains and language bias for each of our proposed training tasks.}
% \label{tab:abla-syn}
% \end{table}



% Please add the following required packages to your document preamble:
% \usepackage{graphicx}


% JT represents the job title translation ranking task, JD represents job description-title matching, and JF represents job field classification.


% old place 



% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
% \begin{table*}[]
% \centering
% % \resizebox{\columnwidth}{!}{%
% \begin{tabular}{@{}lrrrrrr|rrr@{}}
% \toprule
%                & \multicolumn{3}{c}{\textbf{Thai pool}}           & \multicolumn{3}{c|}{\textbf{English pool}}       & \multicolumn{3}{c}{\textbf{Combined pool}}       \\ \midrule
% \textbf{Query} & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    \\ \midrule
% XLM-R          & 2.56           & 34.84          & 29.58          & 31.46          & 3.05           & 8.24           & 17.00          & 19.73          & 15.35          \\
% LaBSE          & 59.35          & 63.97          & 57.81          & 59.20          & 57.84          & 67.50          & 45.12          & 48.62          & 48.64          \\
% BGE-m3         & 59.08          & 69.17          & 68.51          & 62.08          & 53.30          & 78.02          & 36.99          & 42.07          & 45.60          \\
% \textbf{Our}   & \textbf{82.30} & \textbf{80.18} & \textbf{82.36} & \textbf{75.07} & \textbf{81.18} & \textbf{83.43} & \textbf{67.02} & \textbf{66.82} & \textbf{59.54} \\ \bottomrule
% \end{tabular}%
% % }
% \caption{}
% \label{tab:my-table}
% \end{table*}






The results in Table \ref{tab:abla-syn} demonstrate that utilizing our multi-task dual encoder achieves superior performance compared to models trained on a single task on both settings. This suggests the model’s robustness, as it is trained to represent multiple components simultaneously in a single training step.

% Moreover, the job title translation ranking task shows as one of the most crucial tasks for improving performance on both evaluation datasets.



\section{Discussion}
% In this section, we analyze our bilingual sentence encoder in terms of cross-lingual performance and language bias. To measure language bias, we present a visualization of the language histogram and calculate our proposed Language Bias Kullback–Leibler Divergence (LBKL) metric.

% The JTG-Synonym dataset comprises a list of synonyms, including the same job title in Thai and English but with different variations.

\subsection{Cross-Lingual Performance}
% As mentioned in the experiment setup section, we evaluate the JTG-Synonym dataset by framing it as a retrieval task, using the dictionary keys (job titles) as queries to search for all synonyms in the single candidate pool or two separate candidate pools (one containing only English and the other only Thai). We divide the queries into three categories: English, Thai, and code-switching. This approach facilitates the analysis of major improvements in the model’s performance.

As mentioned in the experimental setup section, we evaluated the JTG-Synonym dataset by framing it as a retrieval task, using the dictionary keys (job titles) as queries to search for all synonyms in two separate candidate pools (one containing only English and the other only Thai). This was done in order to mitigate the language bias presented in the embeddings. However, we can also extend our evaluation to a single candidate pool, combining Thai and English candidate pools into one. This approach facilitates the analysis of language bias in the models. The detailed performance for each candidate pool is reported in Table \ref{tab:multi-result}.

% We divide the queries into three categories: English, Thai, and code-switching.

% The comparison of cross-lingual performance (R@10 $\uparrow$) on JTG-Synonym retrieval task.


% \begin{table}[ht]
% \centering
% % {\fontsize{10}{12}
% \Huge
% % \scalebox{1}{
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{lrrrrrr|rrr}
% \hline
% % \toprule
% \textbf{Candidate pool} & \multicolumn{3}{c}{\textbf{Thai pool}}           & \multicolumn{3}{c|}{\textbf{English pool}}       & \multicolumn{3}{c}{\textbf{Combined pool}}       \\ \hline
% \textbf{Query}          & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    \\ \hline
% XLM-R                   & 2.56           & 34.84          & 29.58          & 31.46          & 3.05           & 8.24           & 17.00          & 19.73          & 15.35          \\
% LaBSE                 & 59.35          & 63.97          & 57.81          & 59.20          & 57.84          & 67.50          & 45.12          & 48.62          & 48.64          \\
% BGE-m3      & 59.08         & 69.17          & 68.51         & 62.08 & 53.30          & 78.02         & 36.99          & 42.07          & 45.60          \\
% \textbf{Our}         & \textbf{82.30} & \textbf{80.18} & \textbf{82.36} & \textbf{75.07}         & \textbf{81.18} & \textbf{83.43} & \textbf{67.02} & \textbf{66.82} & \textbf{59.54} \\ \bottomrule
% \end{tabular}%
% % }
% }
% \caption{The comparison of cross-lingual performance (R@10 $\uparrow$) on JTG-Synonym retrieval task. "CS" refers to queries which contain Thai and English code-switching.}
% \label{tab:multi-result}
% \end{table}


% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \begin{table}[ht]
% \centering
% % \resizebox{\columnwidth}{!}{%
% \begin{tabular}{lcllcll|cll}
% \hline
%  & \multicolumn{3}{c}{\textbf{Thai pool}} & \multicolumn{3}{c|}{\textbf{English pool}} & \multicolumn{3}{c}{\textbf{Combined pool}} \\ \hline
% XLM-R                   & \multicolumn{3}{c}{22.32}              & \multicolumn{3}{c|}{14.25}                 & \multicolumn{3}{c}{17.36}                  \\
% LaBSE                   & \multicolumn{3}{c}{60.37}              & \multicolumn{3}{c|}{61.51}                 & \multicolumn{3}{c}{47.46}                  \\
% BGE-m3                  & \multicolumn{3}{c}{65.58}              & \multicolumn{3}{c|}{64.46}                 & \multicolumn{3}{c}{41.55}                  \\
% \textbf{Our}            & \multicolumn{3}{c}{\textbf{81.61}}     & \multicolumn{3}{c|}{\textbf{79.89}}        & \multicolumn{3}{c}{\textbf{64.46}}         \\ \hline
% \end{tabular}%
% % }
% \caption{The comparison of cross-lingual performance (R@10 $\uparrow$) on JTG-Synonym retrieval task.}
% \label{tab:multi-result}
% \end{table}

% \textbf{Candidate }

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \begin{table}[ht]
% \centering
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{lcllcllcll}
% \hline
%              & \multicolumn{9}{c}{\textbf{Candidate pool}}                                                                                      \\ \hline
%              & \multicolumn{3}{c}{\textbf{Thai pool}} & \multicolumn{3}{c|}{\textbf{English pool}} & \multicolumn{3}{c}{\textbf{Combined pool}} \\ \hline
% XLM-R        & \multicolumn{3}{c}{22.32}              & \multicolumn{3}{c|}{14.25}                 & \multicolumn{3}{c}{17.36}                  \\
% LaBSE        & \multicolumn{3}{c}{60.37}              & \multicolumn{3}{c|}{61.51}                 & \multicolumn{3}{c}{47.46}                  \\
% BGE-m3       & \multicolumn{3}{c}{65.58}              & \multicolumn{3}{c|}{64.46}                 & \multicolumn{3}{c}{41.55}                  \\
% \textbf{Our} & \multicolumn{3}{c}{\textbf{81.61}}     & \multicolumn{3}{c|}{\textbf{79.89}}        & \multicolumn{3}{c}{\textbf{64.46}}         \\ \hline
% \end{tabular}%
% }
% \caption{the retrieval results (R@10 $\uparrow$) for different query-candidate-pool pairs, where the first and second columns refer to the setting of two separate pools, and the third column refers to the setting of a combined candidate pool.}
% \label{tab:multi-result}
% \end{table}

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
% \begin{table}[ht]
% \centering
% % \resizebox{\columnwidth}{!}{%
% \begin{tabular}{@{}lccc@{}}
% \toprule
%              & \multicolumn{3}{c}{Candidate Pool}                            \\ \midrule
%              & Thai pool & \multicolumn{1}{c|}{English pool} & Combined Pool \\ \midrule
% XLM-R        & 22.32     & \multicolumn{1}{c|}{14.25}        & 17.36         \\
% LaBSE        & 60.37     & \multicolumn{1}{c|}{61.51}        & 47.46         \\
% BGE-m3       & 65.58     & \multicolumn{1}{c|}{64.46}        & 41.55         \\
% \textbf{Our} & 81.61     & \multicolumn{1}{c|}{79.89}        & 64.46         \\ \bottomrule
% \end{tabular}%
% % }
% \caption{}
% \label{tab:my-table}
% \end{table}




% \textbf{Candidate pool}

% Table \ref{tab:multi-result} shows the retrieval results for different query-candidate-pool pairs, where the first and second columns refer to the setting of two separate pools, and the third column refers to the setting of a combined candidate pool. 

The result shows that the cross-lingual performance of our model significantly improves compared to XLM-R, BGE-M3, and LaBSE in both the separate and combined pool settings. However, BGE-m3 demonstrates superior results over LaBSE in the two separate pool settings, though its performance declines in the combined pool setting. This outcome will be further discussed in the following section. 


\subsection{The Language Bias in Embeddings}

% There are studies that have pointed out language bias in textual embeddings, especially for a bilingual retrieval tasks. This can be linked to our evaluation dataset for JTG-synonym, which evaluates this dataset while formulating the problem as a bilingual job title retrieval task. It shows that the query would prefer the candidate key in the same language more than in other languages and might not fully capture the semantic meaning.



\subsubsection{Language Histogram}

% We performed the experiment for visualizing language distributions by using the JTG-synonym dataset. First, we used the dictionary keys (job titles) as queries to calculate the similarity scores between them and the candidate pool (combined pool). We then ranked the candidate based on similarity scores from high to low. Next, we selected the top 100 results from the ranked candidate list to determine the number of Thai and English presenting in the results without considering the correctness of their corresponding labels. In short, we obtained the language distribution in the top-ranked results for each query. Finally, we presented the language distribution for all queries, where in each queries are divided into three categories: English, Thai, and code-switching query.


We can further visualized the histogram of the retrieved candidates in the JTG-synonym dataset. We used the dictionary keys (job titles) as queries to calculate the similarity scores between these queries and the candidate pool (combined pool). Then, the candidate were ranked based on their similarity scores from high to low. Next, we selected the top 100 results from this ranking to count the frequency of Thai and English candidates, without considering the correctness of their corresponding labels. Finally, the counts (\#th and \#en retrieved by each query in the top-100 results) were used to plot the histogram summarizing all queries. We present the language frequency histogram, where queries are divided into three subcategories: English (EN), Thai (TH), and code-switched (CS).

% In short, we obtained the language distribution in the top-ranked results for each query



% The language distribution is shown with different sentence encoders, including BGE-m3, LaBSE and mUSE (ours). 
 % The left, middle, and right sides of each figure show the histogram from the English, Thai, and code-switching queries, respectively, as illustrated in Figure \ref{fig:labse-lan-bias}, \ref{fig:bge-lan-bias}, \ref{fig:mUSE-lan-bias} and \ref{fig:mUSE-our-lan-bias}.
 
 % The left, middle, and right sides of each figure show the histogram from the English, Thai, and code-switching queries, respectively, as illustrated in Figure \ref{fig:labse-lan-bias}, \ref{fig:bge-lan-bias}, \ref{fig:mUSE-lan-bias} and \ref{fig:mUSE-our-lan-bias}.
 
 The histogram of BGE-m3 shows a bias towards the query language, implying the language bias has significantly influenced their retrieval result, where the query would prefer the candidate in the same language more than another languages. In contrast, other models such as LaBSE and mUSE, the language histogram is slightly shifted from the middle, and mUSE (ours) remains close to the midpoint. 


% The left-hand side of each figure shows the distribution from the English query, the middle shows the distribution from the Thai query, and the right-hand side shows the distribution from the code-switching query.

\begin{figure}[t]
\centering

\begin{minipage}{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{Figures/labse-m3-lang-bias-1-1-1.pdf}
    \caption{A language frequency histogram of LaBSE}
    \label{fig:labse-lan-bias}
\end{minipage}


\begin{minipage}{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{Figures/bge-m3-lang-bias-1-1-1.pdf}
    \caption{A language frequency histogram of BGE-M3}
    \label{fig:bge-lan-bias}
\end{minipage}

% \vspace{1em}

\begin{minipage}{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{Figures/lan-bias-mUSE-1-1-1-1.pdf}
    \caption{A language frequency histogram of mUSE}
    \label{fig:mUSE-lan-bias}
\end{minipage}


\begin{minipage}{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{Figures/lan-bias-mUSE-our-1.pdf}
    \caption{A language frequency histogram of mUSE (ours), with the left, middle, and right sections showing histograms for English, Thai, and code-switching queries, respectively. The orange and blue histogram represent the number of candidate results in Thai and English, respectively. }
    \label{fig:mUSE-our-lan-bias}
\end{minipage}

\end{figure}

% , as illustrated in Figure \ref{fig:labse-lan-bias}, \ref{fig:bge-lan-bias}, \ref{fig:mUSE-lan-bias} and \ref{fig:mUSE-our-lan-bias}


% \begin{figure}[t]
% \centering
% \includegraphics[width=1\columnwidth]{Figures/lang-bias-all.pdf}
% \caption{} 
% \label{fig:gg}
% \end{figure}









% \begin{figure}[ht]
% \centering
% \includegraphics[width=\columnwidth]{LaTeX/Figures/bge-m3-lang-bias-1-1-1.pdf}
% \caption{A language distribution of BGE-M3}
% \label{fig:bge-lan-bias}
% \end{figure}
% \begin{figure}[ht]
% \centering
% \includegraphics[width=\columnwidth]{LaTeX/Figures/bge-m3-lang-bias-1-1-1.pdf}
% \caption{A language distribution of BGE-M3}
% \label{fig:bge-lan-bias}
% \end{figure}
% \begin{figure}[ht]
% \centering
% \includegraphics[width=\columnwidth]{LaTeX/Figures/bge-m3-lang-bias-1-1-1.pdf}
% \caption{A language distribution of BGE-M3}
% \label{fig:bge-lan-bias}
% \end{figure}
% \begin{figure}[ht]
% \centering
% \includegraphics[width=\columnwidth]{LaTeX/Figures/bge-m3-lang-bias-1-1-1.pdf}
% \caption{A language distribution of BGE-M3}
% \label{fig:bge-lan-bias}
% \end{figure}



% \begin{table*}[t]
% \centering
% \begin{tabular}{lrrrrrr|rrr}
% \hline
% \toprule
%  & \multicolumn{3}{c}{\textbf{Thai pool}}           & \multicolumn{3}{c|}{\textbf{English pool}}       & \multicolumn{3}{c}{\textbf{Combined pool}}       \\ \hline
% \textbf{Query}          & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    \\ \hline
% XLM-R                   & 2.56           & 34.84          & 29.58          & 31.46          & 3.05           & 8.24           & 17.00          & 19.73          & 15.35          \\
% LaBSE                 & 59.35          & 63.97          & 57.81          & 59.20          & 57.84          & 67.50          & 45.12          & 48.62          & 48.64          \\
% BGE-m3      & 59.08         & 69.17          & 68.51         & 62.08 & 53.30          & 78.02         & 36.99          & 42.07          & 45.60          \\
% \textbf{Our}         & \textbf{82.30} & \textbf{80.18} & \textbf{82.36} & \textbf{75.07}         & \textbf{81.18} & \textbf{83.43} & \textbf{67.02} & \textbf{66.82} & \textbf{59.54} \\ \bottomrule
% \end{tabular}%
% \caption{The retrieval results (R@10 $\uparrow$) for different query-candidate-pool pairs, where the first and second columns refer to the setting of two separate pools, and the third column refers to the setting of a combined candidate pool.}
% \label{tab:multi-result}
% \end{table*}



% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table*}[t]
\centering
% \resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccccc|cccc}
\hline
% \toprule
               & \multicolumn{4}{c}{\textbf{Thai Candidate Pool}}                   & \multicolumn{4}{c|}{\textbf{English Candidate Pool}}               & \multicolumn{4}{c}{\textbf{ Combined Candidate Pool}}               \\ \hline
\textbf{Query} & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textit{avg}   & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textit{avg}   & \textbf{EN}    & \textbf{TH}    & \textbf{CS}    & \textit{avg}   \\ \hline
XLM-R          & 2.56           & 34.84          & 29.58          & 22.32 & 31.46          & 3.05           & 8.24           & 14.25 & 17.00          & 19.73          & 15.35          & 17.36 \\
LaBSE          & 59.35          & 63.97          & 57.81          & 60.37 & 59.20          & 57.84          & 67.50          & 61.51 & 45.12          & 48.62          & 48.64          & \underline{47.46} \\
BGE-m3         & 59.08          & 69.17          & 68.51          & \underline{65.58} & 62.08          & 53.30          & 78.02          & \underline{64.46} & 36.99          & 42.07          & 45.60          & 41.55 \\
\textbf{Ours}   & \textbf{82.30} & \textbf{80.18} & \textbf{82.36} & \textbf{81.61} & \textbf{75.07} & \textbf{81.18} & \textbf{83.43} & \textbf{79.89} & \textbf{67.02} & \textbf{66.82} & \textbf{59.54} & \textbf{64.46} \\ \hline
\end{tabular}%
% }
\caption{The retrieval results (R@10 $\uparrow$) for different query-candidate-pool pairs, where the first and second columns refer to the setting of two separate pools, and the third column refers to the setting of a combined candidate pool.}
\label{tab:multi-result}
\end{table*}


% % Please add the following required packages to your document preamble:
% % \usepackage{graphicx}
% \begin{table*}[ht]
% \centering
% % \resizebox{\columnwidth}{!}{%
% \begin{tabular}{lcc|cccc}
%          & \multicolumn{2}{c|}{\textbf{Performance}}      & \multicolumn{4}{c}{\textbf{LBKL}}                                              \\ \cline{2-7} 
%          & \textbf{JTG-Synonym} & \textbf{JTG-Occupation} & \textbf{JTG-Synonym} & \textbf{JTG-Skill} & \textbf{SCB-MT} & \textbf{Xquad-r} \\ \hline
% mUSE     & 61.91                & 86.53                   & 1.20                 & 0.15               & 0.08            & 0.02             \\ \hline
% + (A) JT & 77.43                & 89.38                   & 0.40                 & 0.07               & 0.05            & 0.04             \\
% + (B) JD & 66.41                & 87.77                   & 1.26                 & 0.08               & 0.04            & 0.05             \\
% + (C) JF & 61.50                & 89.20                   & 1.19                 & 0.15               & 0.08            & 0.02             \\ \hline
% Ours     & 79.43                & 92.93                   & 0.39                 & 0.08               & 0.05            & 0.04             \\ \hline
% \end{tabular}%
% % }
% \caption{}
% \label{tab:my-table}
% \end{table*}


% and the average of histogram in each queries from Figure \ref{fig:labse-lan-bias}, \ref{fig:bge-lan-bias}, \ref{fig:mUSE-lan-bias} and \ref{fig:mUSE-our-lan-bias}

\subsubsection{Language Bias Kullback–Leibler Divergence (LBKL)} 
Table \ref{tab:lan-bias-overall} presents our LBKL metrics for both in-domain (JTG-Synonym) and unseen domains namely, JTG-Skill (a list of job skills in both languages), SCB-MT (a general domain Thai-English translation dataset) \cite{lowphansirikul2022large}, and XQuAD-r (a multilingual retrieval dataset for QA, use only Thai and English corpus) \cite{roy-etal-2020-lareqa}. The experimental results on JTG-Synonym confirms that BGE-M3 and LaBSE still encounter challenges of language bias, as indicated by the language histograms and LBKL of 3.95 for BGE-M3 and 1.96 for LaBSE. This LBKL different could be linked to the cross-lingual performance in Table \ref{tab:multi-result}, as BGE-M3 outperforms in the two separate pool settings but declines in the combined pool setting.


For the unseen domains, LBKL on JTG-Skill and SCB-MT indicates a reduction in the language bias. In Xquad-r, the LBKL of our model is slightly worse than mUSE. However, the loss in performance is small. Overall, our method could potentially reduce language bias in the sentence representations across both in-domain and unseen domains. 

% Table \ref{tab:abla-all} shows an ablation study of our proposed tasks, revealing that the JT and JD tasks yield inconsistent result, where JT significantly reduce lanugage bias in in-domain but for JD task increase whereas JT and JD consistently reduce the language bias except Xquard-r with small margin. The JF task has little impact on a language bias reduction. Overall, our multi-task learning method could effectively balance language bias across training tasks, as some tasks may not reduce language bias but it still improve the overall performance (Table \ref{tab:abla-syn}).



% Table \ref{tab:abla-all} shows an ablation study of our proposed tasks, revealing that JT and JD consistently reduce the language bias in unseen-domain, with only XQuAD-r showing marginal bias loss. The JT task greatly reduces language bias on in-domain, while the JD task slightly increases it, and the JF task has little impact on language bias in either domain. Overall, our multi-task learning method could effectively balance language bias across training tasks, as some tasks may not reduce the language bias but still improve the overall performance (Table \ref{tab:abla-syn}).


Table \ref{tab:abla-all} shows a language bias comparison (LBKL) for each of our proposed tasks. The JT and JD tasks reduce the language bias in most unseen domains, with only XQuAD-r showing a marginal increase. However, the LBKL of the JD task on in-domain increases slightly compared to the baseline score, and the JF task has little impact on language bias in both in-domain and unseen domains. The JT task is still crucial for reducing the language bias, consistently reducing bias in job-related domains (JTG-Synonym and JTG-Skill).


% this confirms that our multi-task learning could balance the language bias across each training tasks, especially on job-related domain (JTG-Synonym and JTG-Skill), as some task may not reduce the language bias.

% be beneficial to reduce bias compare to stand alone task, .


% Overall, our multi-task learning method could effectively balance language bias across training tasks, as some tasks may not directly reduce the language bias but still improve the overall performance (Table \ref{tab:abla-syn}).


% The JF task has little impact on a language bias reduction. Overall, our multi-task learning method could effectively balance language bias across training tasks, as some tasks may not reduce language bias but it still improve the overall performance (Table \ref{tab:abla-syn}).



% in reducing language bias on both in-domain and unseen domains


% However, this outcome suggests that our multi-task learning could help balance language bias across training tasks, even though some might not directly reduce language bias but still improve overall performance (Table \ref{tab:abla-syn}).


% 

% in domain significant
% out domain is compable

% We also evaluate the LBKL on unseen skill sets (with queries as skills and candidate pool as skills), showing that the sentence representation of skills implicitly reduce language bias from 0.15 to 0.08. Therefore, our method reduces language bias in sentence representations on both job title and skill components.

% However, our method significantly reduces language bias in sentence representations.






% from Figure \ref{fig:bge-lan-bias}, \ref{fig:labse-lan-bias}, \ref{fig:mUSE-lan-bias} and \ref{fig:mUSE-our-lan-bias}

% \begin{table}[ht]
% \centering
% \Huge
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{@{}lcccc@{}}
% \hline
% % \toprule
%             & \multicolumn{1}{l}{\textbf{LBKL}$\downarrow$
% } & \multicolumn{3}{c}{\textbf{Histogram}}                       \\ \midrule
%             &                                   & \textbf{Query (En)} & \textbf{Query (Th)} & \textbf{Query (Cs)} \\ 
% % XLM-R       & JTG                               & JTGxx              & JTG                & JTGx               \\
% LaBSE       & 1.96                              & 71.21/28.79        & 20.84/79.16        & 35.40/64.60        \\ 
% BGE-m3      & 3.95                              & 88.16/11.84        &  07.18/92.82         & 23.18/76.82        \\
% mUSE      & 1.20                              & 70.02/29.98        & 36.14/63.86         & 53.16/46.84        \\
% \textbf{Ours} & \textbf{0.39}                              & 55.80/44.20        & 49.81/50.19        & 56.40/43.60        \\ \bottomrule
% \end{tabular}
% }
% \caption{An evaluation metric of language bias in sentence representations: the left side and right of the slash shows average of \textbf{English} histogram and \textbf{Thai} histogram.}
% \label{tab:lan-bias-overall}
% \end{table}




% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \begin{table}[]
% \centering
% \Huge
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{lc|cccl}
% \hline
%               & \textbf{In-domain}   & \multicolumn{4}{c}{\textbf{Unseen domains}}                    \\ \hline
%               & \textbf{JTG-Synonym} & \textbf{JTG-Skill} & \textbf{SCB-MT} & \textbf{Xquad-r} & \textit{avg}  \\ \hline
% LaBSE         & 1.96                 & 0.08               & 0.32            & 0.24             & 0.21 \\
% BGE-m3        & 3.95                 & 0.18               & 0.06            & 0.04             & 0.09 \\
% mUSE          & 1.20                 & 0.15               & 0.08            & \textbf{0.02}    & 0.08 \\
% \textbf{Ours} & \textbf{0.39}        & \textbf{0.08}      & \textbf{0.05}   & 0.04             & \textbf{0.06} \\ \hline
% \end{tabular}%
% }
% \caption{Evaluation of language bias (LBKL $\downarrow$) for each sentence encoder on both in-domain and unseen domains.}
% \label{tab:lan-bias-overall}
% \end{table}


% % Please add the following required packages to your document preamble:
% % \usepackage{graphicx}
\begin{table}[ht]
\centering
\Huge
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lc|ccc}
\hline
       & \textbf{In-domain} & \multicolumn{3}{c}{\textbf{Unseen domains}}          \\ \hline
       & \textbf{JTG-Synonym}     & \textbf{JTG-Skill} & \textbf{SCB-MT} & \textbf{XQuAD-r} \\ \hline
LaBSE  & 1.96               & 0.08           & 0.32            & 0.24             \\
BGE-m3 & 3.95               & 0.18           & 0.06            & 0.04             \\
mUSE   & 1.20               & 0.15           & 0.08            & \textbf{0.02}             \\
\textbf{Ours}   & \textbf{0.39}               & \textbf{0.08}           & \textbf{0.05}            & 0.04             \\ \hline
\end{tabular}%
}
\caption{Evaluation of language bias (LBKL $\downarrow$) for each sentence encoder on both in-domain and unseen domains.}
\label{tab:lan-bias-overall}
\end{table}



\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\Huge

\begin{tabular}{lc|ccc}
\hline
         & \textbf{in-domain} & \multicolumn{3}{c}{\textbf{Unseen-domains}}          \\ \hline
         & \textbf{JTG-Synonym}     & \textbf{JTG-Skill} & \textbf{SCB-MT} & \textbf{XQuAD-r} \\ \hline
mUSE     & 1.20               & 0.15           & 0.08            & 0.02             \\ \hline
+ (A) JT & 0.40               & 0.08           & 0.05            & 0.04             \\
+ (B) JD & 1.26               & 0.08           & 0.04            & 0.05             \\
+ (C) JF & 1.19               & 0.15           & 0.08            & 0.02             \\ \hline
\textbf{Ours}     & 0.39               & 0.08           & 0.05            & 0.04             \\ \hline
\end{tabular}%
}
\caption{A language bias comparison (LBKL $\downarrow$) each of our proposed training tasks on in-domain and unseen domains.}
\label{tab:abla-all}
\end{table}






% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=\columnwidth]{Figures/bge-lan-bias.png} % Full width of the column
%     \caption{Your caption here}
%     \label{fig:your-label}
% \end{figure}
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=\columnwidth]{Figures/labse-lan-bias.png} % Full width of the column
%     \caption{Your caption here}
%     \label{fig:your-label}
% \end{figure}
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=\columnwidth]{Figures/lan-bias-mUSE-our.png} % Full width of the column
%     \caption{Your caption here}
%     \label{fig:your-label}
% \end{figure}








% \begin{table}[ht]
% \centering
% % \resizebox{\columnwidth}{!}{%
% % \small
% \begin{tabular}{@{}c|c@{}}
% \toprule
% \textbf{Methods} & \textbf{Average inference time / 1 query} \\ \midrule
% XLM-R            & 0.469 ms                                  \\
% LaBSE            & 0.486 ms                                  \\
% BGE-m3           & 0.559 ms                                  \\
% mUSE (ours)      & \textbf{0.242 ms}                         \\ \bottomrule
% \end{tabular}%
% % }
% \caption{We benchmark the computational efficiency across all models, reporting the mean performance from 3 repeated trials.}
% \label{tab:time}
% \end{table}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}


% \subsubsection{Run-time Efficiency on Job Title Encoding}

% We benchmark the computational efficiency of the sentence encoders. Using the JTG-Synonym dataset as a reference, we compiled all bilingual job title words and then calculated the average processing time per query. The evaluation was conducted on a one NVIDIA RTX 3090 GPU with 24GB of memory and an one Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz configuration. As shown in Table \ref{tab:time}, the mUSE\textsubscript{small}CNN-based (ours) is the least processing time, which took only 0.242 ms. As the XLM-R, LaBSE and BGE-m3 has nearly double much processing time.
% , including XLM-R, mUSE, BGE-M3, and LaBSE

% \begin{table}[ht]
% \centering
% % \resizebox{\columnwidth}{!}{%
% \begin{tabular}{c|c}
% \hline
% \textbf{Methods} & \textbf{Average inference time / 1 query} \\ \hline
% XLM-R            & 0.469 ms                                  \\
% LaBSE            & 0.486 ms                                  \\
% BGE-m3           & 0.559 ms                                  \\
% mUSE (ours)      & \textbf{0.242 ms}                         \\ \hline
% \end{tabular}%
% % }
% \caption{We benchmark the computational efficiency across all models, with the mean performance from 3 trials.}
% \label{tab:time}
% \end{table}


% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \begin{table}[ht]
% \centering
% % \normalsize	
% % \resizebox{\columnwidth}{!}{%
% \begin{tabular}{cc}
% \hline
% \textbf{Methods} & \textbf{Average inference time / 1 query} \\ \hline
% XLM-R            & 0.469 ms                                  \\
% LaBSE            & 0.486 ms                                  \\
% BGE-m3           & 0.559 ms                                  \\
% mUSE (ours)      & \textbf{0.242 ms}                         \\ \hline
% \end{tabular}%
% % }
% \caption{We benchmark the computational efficiency across all models, with the mean performance from 3 repetitions.}
% \label{tab:time}
% \end{table}




\section{Conclusion}
In this paper, we introduced the bilingual sentence encoder for Thai-English for general-purpose use in the job recruitment domain. We employed a multi-task dual encoder framework that integrates three job-related tasks. Our evaluation further focused on both cross-lingual performance and language bias. To measure language bias, we proposed a novel metric called Language Bias Kullback–Leibler Divergence (LBKL), to quantify bias within the model. Our method consistently improves on both the synonym retrieval and job title classification tasks. Moreover, it demonstrated superior cross-lingual performance and greatly lowered the language bias compared to other state-of-the-art models.

\section{Acknowledgements}
This work is supported in part by JOBTOPGUN, a jobposting and recruitment platform in Thailand.

% \section{Ethical Statement.}
% ggg

% : job title translation ranking, job description-title matching, and job field classification.
\appendix


% \section{Acknowledgments}

{\small\bibliography{aaai25}}


\end{document}
