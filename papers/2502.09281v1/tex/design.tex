\section{\mt{}}
\label{sec:overview}
% Figure ref: https://docs.google.com/presentation/d/1uw9LgeLoUzi7y52ZMQ2FK68VC1nbklAJAG7zQ7NiI5c/edit?usp=sharing, slide 41
\begin{figure}[t!]
    \centering
    \includegraphics[width=0.80\columnwidth]{figures/overview/cnet-design.pdf}
    \caption{\mt{} architecture. Legacy application (App 1) can use traditional POSIX syscalls to communicate over Linux Kernel TCP while
    multiple applications~(App 2 and App 3) connect network over CNet using the shim library}
    \label{fig:machnet-overview}
    \vspace{-0.1in}
\end{figure}

\mt{} has two components: a ``sidecar'' userspace process that handles all kernel-bypass network I/O and a shim library that applications use to communicate with the sidecar (Figure~\ref{fig:machnet-overview}).
The shim library provides sockets-like API calls for applications to send and receive messages and communicates with the sidecar over shared memory channels, summarized in Appendix Table~\ref{tab:machnet_api_brief}.
The \mt{} sidecar process handles all kernel-bypass network I/O and can scale to multiple cores without relying on flow steering.

Applications initiate a shared memory channel with the sidecar process~\circled{1}, facilitating message exchange with the \mt{} sidecar.
From a security perspective, these shared memory regions are entirely isolated, and a compromised application cannot manipulate the shared memory region of other applications. 
Each shared memory channel~(SHM)~\circled{2} comprises a pair of Message RX/TX queues, managing references to the head of incoming and outgoing buffers.
\mt{} employs \rssminus{} powered "engines"~\circledsmall{3a} per CPU core to handle the processing of ingress/egress packets from associated RX/TX queues~\circled{4}.
During connection setup, \mt{} utilizes the \rssminus{} port pool~\circledsmall{3b} to associate the flow with the correct engine.
This association process occurs off the hot path (see \S\ref{subsec:rssminus} for further details).
% Link: \href{https://docs.google.com/presentation/d/1uw9LgeLoUzi7y52ZMQ2FK68VC1nbklAJAG7zQ7NiI5c/edit?usp=sharing}{slide 41}}
% \begin{figure}
%     \centering
%     \includegraphics[clip,scale=0.9]{figures/overview/machnet-overview-1.pdf}
%     \label{fig:machnet-overview}
%     \caption{\mt{} overview.}
%     \label{fig:net-stack-cmp}
% \end{figure}


%\begin{table}[t!]
%\resizebox{\columnwidth}{!}{%
% \begin{tabular}{l||l|l}
% \multicolumn{1}{c||}{\mt{} components} & \multicolumn{1}{c|}{Purpose} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Expected Result\end{tabular}} \\ \hline \hline
% \begin{tabular}[c]{@{}l@{}}Efficient shared \\ memory\end{tabular} & \begin{tabular}[c]{@{}l@{}}Communication \\ channel with apps\end{tabular} & \begin{tabular}[c]{@{}l@{}}1) Allows low latency \\ communication with apps\\ 2) Avoids the need for \\ non-trivial changes to apps\end{tabular} \\ \hline
% \begin{tabular}[c]{@{}l@{}}Scalable flow \\ mapper\end{tabular} & Multi-core support & 1) Achieves higher throughput 2) Enables LCD
% \end{tabular}
% }
% \caption{Summary of \mt{} components.\ga{I think we shall have a table like this to recap. Maybe something that recaps how we meet the requirements?}}
% \label{table:machnet-comps}
% \end{table}

%\subsection{Flow-to-core mapping with \rssminus{}}
%\label{subsec:rssminus}

\subsection{Scaling to multiple cores}
\label{subsec:multicore}
The \mt{} sidecar process can use multiple CPU cores to (1) scale performance to large VMs (e.g., with \Gbps{100} networking) and (2) provide performance isolation among applications.
We run one \mt{} ``engine'' thread per core; each engine has an exclusive NIC RX/TX queue pair and runs in a busy-polling run-to-completion loop.
We use a shared-nothing architecture for scalability (i.e., engines do not share flow state or shared memory channels).
One dedicated shared memory channel exists between each application thread and a \mt{} engine.
\mt{}'s shim library API also allows each application thread to specify the engine to use (the default policy is round-robin).
This is useful when binding a latency-critical application to a dedicated engine, while less latency-sensitive applications can share an engine.
%we evaluate this in \S\ref{subsec:app-isolation}.

\paragraph{Need for flow-to-core mapping.}
NIC-offloaded flow-to-core mapping is necessary to support (1) our shared-nothing multi-core architecture and (2) support for binding applications to specific engines.
Without this, a packet may land at any engine core.
This, in turn, requires shuffling packets or flows between engine cores, breaking the shared-nothing architecture and inter-application isolation.
For example, an ACK packet may land on a different engine core than the one that sent the original data packet, requiring the receiver to either shuffle the packet to the correct core or pull the flow state from that core.

Snap~\cite{snap} uses the NIC's flow steering hardware to map flows to engine cores.
TAS~\cite{tas} uses only RSS, but it cannot assign flows to specific engine cores, which is necessary for performance isolation between applications or flows.
In addition, TAS requires each engine to communicate with all application threads, which does not scale well to the large number of threads we target.
Regardless, the problem is that cloud VMs do not expose flow steering to guest VMs at the time of writing.

We found that all major cloud providers support RSS, a stateless NIC mechanism that hashes packet headers (e.g., a Toeplitz hash of the four-tuple) to a receive queue.
\footnote{Since we use one RX queue per core, we use core and RX queue interchangeably.}
RSS guarantees flow affinity to different cores, i.e., packets of the same flow will all hit the same receive queue.
But it is challenging to know {\it a priori} which queue a packet will land on, as discussed next.

%Userspace stacks typically rely on NIC flow steering hardware to map flows to CPU cores~\cite{erpc, snap, mica, sharding}.
%Flow steering allows applications to install ``flow rules'' that map flows (e.g., defined by the four-tuple of source and destination IPv4 address and UDP ports) to a particular RX queue.


\paragraph{Difficulty of inverting RSS.}
Can we use RSS for scaling \mt{} with its shared-nothing architecture?
We initially implemented a novel mechanism that requires knowing the RSS key since we initially believed retrieving the RSS key would be part of the LCD NIC model (e.g., DPDK provides an API to retrieve the RSS key).
While this approach worked on our initial set of test cloud VMs, we found that it is unreliable in practice.
Some cloud NICs refuse to expose the RSS key.
Others vary in the endianness of the computed RSS hash, introducing additional complexity by requiring hardware-specific code and testing paths.

Our mechanism worked as follows.
Below, we use a client-server connection as an example, where the server is listening on a particular UDP port.
During connection setup by the client, the server (i.e., the server-side \mt{} process) communicates its RSS key and number of RX queues to the client.
The client uses this and its RSS key to compute a UDP source port to hash all flow packets to the desired local and remote RX queues.
IX uses a local variant of this technique, where the client chooses a UDP source port that causes server-to-client packets to hash to the core that sent the original client-to-server packet~\cite{belay2014ix}.
However, the local variant alone cannot support the application-to-engine affinity we require since it cannot control which server-side RX queue the packet lands on.

\subsection{\rssminus{}}
\label{subsec:rssminus}
We created a new approach called \rssminus{} that uses randomization to work despite the opaqueness of RSS in cloud NICs.
\mt{} repeatedly tries to establish a connection using different source and destination ports until it finds a combination that hashes to the desired RX queues.
There are two exciting aspects of this approach.

% https://docs.google.com/presentation/d/1uw9LgeLoUzi7y52ZMQ2FK68VC1nbklAJAG7zQ7NiI5c/edit?usp=sharing
\begin{figure}
    \centering
    \includegraphics[width=.8\columnwidth]{figures/design/machnet_handshake-1.pdf}
    \caption{SYN and SYN-ACK spraying in \mt{} to establish a flow between engine \#1 at the client and engine \#1 at the server.
    This figure shows the unoptimized version where the client sprays $n^2$ SYN packets. The green SYN and SYN-ACK packets are the ones that hash to the correct RX queue.}
    \label{fig:machnet_handshake}
    \vspace{-0.1in}
\end{figure}

\paragraph{Decoupling flow identifiers from RSS.}
Unlike bare-metal NICs that allow offloading to the hardware advanced filters over arbitrary packet header fields, cloud NICs only support basic RSS hashing on the standard four-tuple for packet steering.
This couples RSS hashing and flow identifiers, limiting flexibility in how we can exploit randomization.
\mt{} breaks this coupling: instead of using UDP ports to define flows, we introduce two additional 16-bit port fields in the \mt{}-specific packet header.
As discussed below, this reduces the number of packets that \mt{} must spray during connection setup.
A side benefit is that it avoids reducing the number of supported flows between two servers as the number of RX queues increases.

\paragraph{SYN and SYN-ACK spraying.}
We first discuss an unoptimized method that requires a relatively large number of packets to establish a connection:
During the initial connection handshake, the client-side \mt{} sends a batch of SYN packets with randomly selected UDP source and destination port pairs (Figure~\ref{fig:machnet_handshake}).
The server responds with a corresponding SYN-ACK packet that hashes to the correct server RX queue for each SYN packet.
The client uses the first SYN-ACK packet received at the correct RX queue to establish the connection and discard the rest.
If no SYN packet reaches the correct engine, the client repeats after a timeout (\ms{300} by default) with different UDP port pairs.

How many SYN packets should the client send?
Let us assume two \mt{} machines with $n$ engines each and a uniformly random RSS hash function.
The probability of an SYN/SYN-ACK packet hashing to the correct server/client queue is $\frac{1}{n}$.
Thus, the probability of a connection being established by a given packet is $\frac{1}{n*n}$.
Using basic probability, the number of packets required to establish a connection with 95\% likelihood is $\log(1-0.95)/\log(1-\frac{1}{n*n})$.
This equals 47 packets for $n=4$ engines and 191  for $n=8$ engines.
The remaining 5\% of flows are established after a timeout and retry.

\paragraph{Reducing sprayed packets.}
With our decoupling of flow identifiers from RSS, the server does not simply need to reflect the client's SYN UDP port pair.
Instead, we can use a different UDP port pair for the reverse direction.
This does not change the \mt{}-specific port fields, so each side can still associate packets to the correct flow.
The client sends some SYN packets with random UDP port pairs in the optimized method.
On receiving the first SYN, the server responds with an equal number of SYN-ACK packets with its randomly chosen UDP port pairs.
As long as both the SYN and SYN-ACK packets hash to the correct remote RX queue with probability at least $\sqrt{0.95}$, we maintain the 95\% probability of connection setup.
This requires each side to send $\log(1-\sqrt{0.95})/\log(1-\frac{1}{n})$ packets; the total number of packets for connection setup is two times this value, which equals 25 and 55 packets for $n=4$ and $n=8$ engines, respectively.

\textit{Communicating successful UDP ports.}
The server and client communicate the successful UDP port pairs (used for future packets in the flow) to each other in the SYN-ACK and ACK packets, respectively.
The server includes the correctly-hashed SYN packet's UDP port pair in its SYN-ACK packets' payload.
Similarly, the client includes the successful SYN-ACK packet's UDP port pair in the subsequent ACK packet and first data packet.
Note that the client and server may use different UDP port pairs for each flow direction.


\section{Implementation}
\label{sec:implementation}
The \mt{} sidecar is implemented in C++ and uses DPDK for kernel bypass packet I/O.
We use C for the shim library to make interface with other languages easier.
The stack and shim library are implemented in \textasciitilde11K lines of code, excluding language bindings.

\paragraph{Why DPDK instead of XDP?}
\label{par:dpdk-xdp}

Interestingly, the same lack of flow steering that led us to develop \rssminus{} also cripples AF\_XDP in cloud VMs.
We discuss this next.
AF\_XDP is a recent Linux improvement that bypasses most kernel stack processing to reduce latency, which may be ``good enough'' for some applications.\footnote{
Another advance---io\_uring---focuses on improving throughput by batching syscalls, which is irrelevant to our latency target.}
In its best ``zero-copy'' case, the device driver receives a packet directly to user-space memory, bypassing the networking code.
We studied AF\_XDP in detail on cloud VMs and implemented a \mt{} variant based on DPDK's efficient AF\_XDP driver, and found deficiencies, inline with prior reports~\cite{karlsson2018path}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=.8\columnwidth]{figures/design/why-dpdk.pdf}
    \vspace{-0.3in}
    \caption{This experiment measures the single message latency of each approach.
    DPDK performs significantly better than existing options.}
    \label{fig:afxdp-single-message-latency}
    \vspace{-0.1in}
\end{figure}

Surprisingly, we found that AF\_XDP does not use zero-copy in cloud VMs.
The reason is interesting: we found that \textit{\ul{zero-copy AF\_XDP requires flow-steering support in the NIC as a security measure}}, to prevent packets destined for one application from being delivered to another~\cite{Topel2018}.
Without zero-copy support, latency is not significantly better than that of the standard kernel network stack, and is up to far worse than with zero-copy.
Second, to support multiple application processes, AF\_XDP also requires a sidecar model (so it cannot avoid the IPC overhead) since the number of NIC queues limits the number of AF\_XDP sockets.

Zero-copy is the primary challenge when using AF\_XDP, but it is not the only factor contributing to performance issues. When an application uses AF\_XDP, the kernel is responsible for putting messages in the correct memory regions when received from the network and transmitting application messages placed in the shared memory region by the application. For the application to experience minimal latency, kernel threads must work hand in hand and in sync with the application threads to avoid extra latency. Unfortunately, this does not happen in practice, especially in VMs, where threads are not guaranteed to get the actual physical CPU from the hypervisor, and slight hiccups will cause high tail latency.

We ran experiments to understand the performance of AF\_XDP, using bare-metal nodes to allow experiments with zero-copy (xl170 Cloudlab).
We pin the interrupt (IRQ) and application threads on different CPU cores for best results.
The first experiment measures round-trip latency with a single message in flight using two nodes, comparing RDMA, DPDK, AF\_XDP zero-copy (ZC), AF\_XDP copy, and standard Linux.
Figure~\ref{fig:afxdp-single-message-latency} shows that DPDK achieves 4.1x and 5.6x lower latency at 99.9th percentile compared to AF\_XDP ZC and Linux.

\begin{figure}[t!]
    \centering
    \includegraphics[width=1\columnwidth]{figures/design/af_axdp_load_latency.pdf}
    \caption{DPDK performs significantly better than AF\_XDP zero-copy.
    Unfortunately, even the best non-DPDK option (AF\_XDP ZC) is not available
    in cloud virtual machines due to the lack of flow steering support. }
    \label{fig:afxdp-load-latency}
    \vspace{-0.1in}
\end{figure}


The second experiment measures the load latency of each approach via three nodes.
A client on one node only measures the latency by sending single messages, and another workload generator residing on another node produces the background workload of 64-byte messages.
A separate server node echoes messages back to the clients.
We vary the background load and measure the latency.
Figure~\ref{fig:afxdp-load-latency} shows each approach's median, 99th, and 99.9th percentile latency.
DPDK dominates AF\_XDP by 10x at 99.9th percentile.

\paragraph{Network protocol.}
\label{par:network-protocol}

Cloud NICs favor connection-oriented protocols over connectionless protocols.
When a guest VM initiates a new connection, an SDN policy evaluation pipeline processes the control packets (e.g., SYN)~\cite{vfp}.
While this is transparent to the VM, it significantly increases first-packet latency and limits the number of connections per second that can be initiated~\cite{sirius, andromeda}.
It is common for packets-per-second to drop by 100$\times$ or more when initiating new connections~\cite{Bansal:nsdi23, vfp}.
Moreover, connectionless transports in combination with packet spraying via random UDP ports (e.g., Homa~\cite{homa}, NDP~\cite{NDP}) may run into SDN-related bottlenecks.
For instance, Homa uses short-lived connections to enable its spraying mechanism.
Unfortunately, every new connection created should go through an SDN slow path to fill up SDN flow tables, resulting in degraded performance down to 10K packets per second.~\cite{Bansal:nsdi23}.

To reduce the SDN overheads of the public cloud, we design \mt{} to feature a connection-oriented protocol similar to TCP.
\mt{} provides reliable in-order message delivery, with fragmentation and reassembly and selective acknowledgments for retransmissions.
We use UDP packets with an added \mt{} header, implementing a flow-based message-oriented protocol that preserves message boundaries (e.g., unlike TCP's byte stream).
We support message sizes up to \mbyte{8} and allow multiple outstanding messages per flow.
Overall, other transport protocols, as well as TCP, can be implemented in \mt{}.


\paragraph{Packaging.}
We package \mt{} as a Docker container so that users need not deal with DPDK, which is often difficult to install and run.
DPDK is a large project with around two million lines of code, an unstable API, and dynamically-probed drivers, making its complexity comparable to a small operating system.
As an example, a common usability problem occurs as follows: DPDK does not build the driver for ConnectX NICs if it does not find the NIC's userspace libraries; when this happens, applications build fine but fail with a cryptic error message at runtime when DPDK fails to locate a driver for the NIC.
To further complicate matters, incompatible versions of these libraries are available from three different sources (upstream rdma-core, the distribution's rdma-core, and Mellanox OFED), causing further confusion.

While these may seem minor issues, we believe this complexity has been a serious roadblock for adopting library OS approaches, which require application developers without DPDK backgrounds to go through a steep learning curve.
Our \mt{} container image includes a pre-built sidecar binary along with all required DPDK patches(e.g., Google Cloud Platform patch\cite{compute-virtual-ethernet-linux}), which can be downloaded and run with a small shell script.
Application developers using \mt{} do not interface with DPDK but instead use the sockets-like shim library API.

