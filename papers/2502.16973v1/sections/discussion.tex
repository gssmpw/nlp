\section{Conclusion and Future Work}\label{sec:disc}

There are several ways in which our analysis of strategic behavior can be further improved. First, while CC/IoC rules ensure that candidates, by running, do not hurt their clone sets when voter preferences are fixed, there may yet be practical reasons for consolidating support behind a single candidate, \emph{e.g.}, a fixed party campaign budget. Thus, it is worth considering extensions of strategic candidacy where running may be costly~\citep{Obraztsova15:Strategic}. Second, our analysis inherently assumes that clone sets possess some structural affinity, such as ideological closeness. This need not be the case: two extremist candidates on opposite sides of the spectrum might be ranked at the bottom by all voters, making them a clone set. In such cases, other metrics of similarity, such as proximity in the \emph{societal axis} of \emph{single-peaked elections}, may be more appropriate. As such, a natural future avenue of research is defining more general notions of clones, and analyzing whether our results extend.


Another exciting direction is to study the role that IoC and CC can play in the context of AI alignment. Methods such as reinforcement learning from human feedback (RLHF) require aggregating data representing diverse human opinions, for which social choice methods are well-suited. It is relatively easy to copy AI model responses, or even entire models, and perform small tweaks to them (\emph{e.g.}, via fine-tuning). Such tweaks are likely to not outperform other significantly better models, hence forming a clone set. \citet{Xu24:RLHF} demonstrate that using non-IoC aggregation rules for RLHF can result in egregious behavior,\footnote{While the~\citet{Xu24:RLHF} present these undesirable outcomes as a failure to meet the independence of irrelevant alternatives property by~\citet{Luce59:Individual}, the demonstrated pathology would also be prevented if the aggregation rule being used was IoC.} a result that is especially concerning as standard RLHF approaches implicitly use Borda Count~\citep{Siththaranjan24:Distributional}, which fails IoC. Thus, as pointed out by~\citet{Conitzer24:Position}, IoC (and thereby CC) becomes highly relevant for social choice for AI models. In line with this agenda, \citet{Procaccia25:Clone} have recently studied how existing RLHF algorithms can be modified to increase their robustness against clones. A natural strengthening of this goal for future work is developing RLHF approaches that implicitly use CC rules.
  

  





