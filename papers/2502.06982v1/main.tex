\documentclass[sigconf]{acmart}
\acmYear{2025}
\acmConference[arXiv]{February}{February}{2025}
\acmISBN{$^{*}$Corresponding author: arissa@google.com}
\setcopyright{none}
\copyrightyear{2025}
\settopmatter{printfolios=true}
\settopmatter{printacmref=false}
% \usepackage[dvipsnames]{xcolor}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{graphicx}  %
\usepackage{multirow}  %
\usepackage{array}     %
\usepackage{booktabs}  %
\usepackage{amsmath}
\usepackage{circledsteps}
\usepackage{xspace}
\usepackage[font=footnotesize]{caption}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue,
    anchorcolor=blue,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
}
\usepackage{microtype}
\usepackage{subfigure}

\newcommand{\theHalgorithm}{\arabic{algorithm}}

\newcommand{\todo}[1]{{\color{red} #1}}

\setlength{\belowcaptionskip}{-10pt}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\def\sectionautorefname{Section}

\begin{document}

\title{Machine Learning Fleet Efficiency: Analyzing and Optimizing Large-Scale Google TPU Systems with ML Productivity Goodput\\[.25em] \subtitle{\emph{A Preprint}}}

\author{\Large
    Arissa Wongpanich$^{\dagger}$
    Tayo Oguntebi$^{\dagger}$
    Jose Baiocchi Paredes$^{\dagger}$\\
    Yu Emma Wang$^{\dagger}$
    Phitchaya Mangpo Phothilimthana$^{\dagger}$
    Ritwika Mitra$^{\dagger}$\\
    Zongwei Zhou$^{\dagger}$
    Naveen Kumar$^{\dagger}$
    Vijay Janapa Reddi$^{\dagger\ddagger}$ \\[1em]
    $^{\dagger}$Google \hspace{1cm} $^{\ddagger}$Harvard University\\[1em]
}

  \renewcommand{\shortauthors}{}



\begin{abstract}
Recent years have seen the emergence of machine learning (ML) workloads deployed in warehouse-scale computing (WSC) settings, also known as ML fleets. As the computational demands placed on ML fleets have increased due to the rise of large models and growing demand for ML applications, it has become increasingly critical to measure and improve the efficiency of such systems. However, there is not yet an established methodology to characterize ML fleet performance and identify potential performance optimizations accordingly. This paper presents a large-scale analysis of an ML fleet based on Google's TPUs, introducing a framework to capture fleet-wide efficiency, systematically evaluate performance characteristics, and identify optimization strategies for the fleet. We begin by defining an ML fleet, outlining its components, and analyzing an example Google ML fleet in production comprising thousands of accelerators running diverse workloads. Our study reveals several critical insights: first, ML fleets extend beyond the hardware layer, with model, data, framework, compiler, and scheduling layers significantly impacting performance; second, the heterogeneous nature of ML fleets poses challenges in characterizing individual workload performance; and third, traditional utilization-based metrics prove insufficient for ML fleet characterization. To address these challenges, we present the ``ML Productivity Goodput'' (MPG) metric to measure ML fleet efficiency. We show how to leverage this metric to characterize the fleet across the ML system stack. We also present methods to identify and optimize performance bottlenecks using MPG, providing strategies for managing warehouse-scale ML systems in general. Lastly, we demonstrate quantitative evaluations from applying these methods to a real ML fleet for internal-facing Google TPU workloads, where we observed tangible improvements.

\end{abstract}




\newcommand{\mpg}{ML Productivity Goodput\xspace}
\newcommand{\sg}{Scheduling Goodput\xspace}
\newcommand{\pg}{Program Goodput\xspace}
\newcommand{\rg}{Runtime Goodput\xspace}
\newcommand{\google}{Google\xspace}
\maketitle
\pagestyle{plain}

\input{tex/intro}
\input{tex/background}
\input{tex/fleet}
\input{tex/goodput}
\input{tex/improvements}
\input{tex/discussion}
\input{tex/conclusion}

\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

\end{document}
