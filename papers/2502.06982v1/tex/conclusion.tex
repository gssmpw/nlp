\section{Conclusion}

Our study presents an analysis of ML fleet efficiency using Google's TPU-based fleet. In \autoref{sec:background} and \autoref{sec:fleet}, we provide an anatomy of the ML system stack and highlight the unique challenges of performance optimization for ML fleets. These challenges include rapid model and hardware evolution and orchestration of hardware/software co-design. To address these issues, we introduce the \mpg (MPG) metric in \autoref{sec:goodput}. The MPG metric decomposes ML fleet efficiency into three key components: Scheduling, Runtime, and Program Goodputs. 

The composable nature of the MPG metric allows us to dissect efficiency trends over time and precisely identify performance bottlenecks at specific layers of the stack. Our work demonstrates that this modular approach helps us develop and deploy more targeted optimization efforts and quantify their impact in an interpretable way. In \autoref{sec:improvements}, we provide examples of real efficiency improvements from leveraging MPG with Google's own TPU fleet. The results demonstrate that the methodology presented in this paper can be generally applied to large-scale ML fleets across industry.


\section{Acknowledgements}
Our work is a product of the collaboration of many teams at Google, including the XLA team, the ML Metrics team, and the TPU Performance team. We are grateful to Daniel Herrington, Victor Cai, Kongtao Chen, Yiru Sun, Yinquan Hao, Aleksey Orekhov, Peter Ma, and Jie Sun for their support with metrics instrumentation and Amit Sabne and Shibo Wang for support with XLA optimizations. We also thank Sushma Prasad, Martin Maas, Dan Zhang, David Patterson, Michael Burrows, Charles Chang, Peter Mattson, and Michael Isard for their valuable review and feedback on this publication.
