\section{Introduction}\label{sec:intro}








As machine learning (ML) models become larger and more complex, production fleets must deploy highly parallel training \cite{vaswani2017attention} and low-latency inference \cite{pope2023efficiently} applications at unprecedented scale. Much like how the boom of internet-scale services \cite{hamilton2007iss} prompted the development of the warehouse-scale computer (WSC), \citep{barroso2009wsc,kanev2015profiling}, the current explosion of foundation ML models \citep{geminiteam2024geminifamilyhighlycapable,brown2020languagemodelsfewshotlearners,anthropic2024claude} is ushering in the era of the ML fleet. ML fleets, sometimes referred to as ``AI hypercomputers'' \cite{aihypercomputer}, represent a new paradigm in computer architecture, where domain-specific accelerators (DSAs) work in tandem with a modular ML system stack to achieve significant performance and energy efficiency improvements. They are characterized by their massive scale and ML-centric workloads, often requiring more compute power, more storage, and more complex networking than traditional WSCs.  Despite the rapid development of these ML fleets, the challenges associated with building and operating them at scale remain significant and poorly understood in the literature.





\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{final_figs/ml_fleet_5yr.png}
    \caption{Five-year historical ML fleet breakdown by accelerator type. The rapid proliferation of domain-specific accelerators in response to ML-based workloads has presented novel challenges in optimizing ML fleets. Managing these domain-specific accelerators means effectively handling hardware and workload heterogeneity, as well as hardware-software co-design at scale.}
    \vspace*{-2em}
    \label{fig:five-years}
\end{figure}

This paper presents a playbook for instrumenting and optimizing large-scale ML fleets, using Google's production TPU infrastructure for internal workloads as our case study. In contrast to prior work, where previous Google TPU papers have predominantly focused on hardware architecture design and chip-level performance evaluations \citep{jouppi2023tpuv4opticallyreconfigurable, jouppi2021ten, jouppi2017indatacenter}, our work is a significant departure. We provide the first in-depth perspective on the software stack that enables these domain-specific accelerators to operate efficiently at scale. 

This shift from hardware-centric discussions to the practical aspects of operationalization is important in understanding how to leverage and manage ML infrastructure in real-world, production environments. Although our study centers on Google's ML fleet, which is primarily composed of TPUs, the insights, methodologies, and best practices we present are broadly applicable to ML fleets consisting of other DSAs such as GPUs.

We make multiple contributions in this paper. \Circled{1} First, we provide a methodology to dissect the ML fleet by segmenting it along the layers of a system stack, from the low-level hardware layer to the user-facing application layer. This analysis reveals three major challenges for ML fleet optimization: hardware heterogeneity, workload heterogeneity, and hardware/software co-design.











\textbf{Hardware Heterogeneity:} Large-scale ML fleets typically comprise a mix of general-purpose processors (e.g., CPUs) and specialized accelerators (e.g., GPUs and TPUs). There is a strong interdependence between these diverse hardware components, as they often work in tandem to execute complex ML workloads. For instance, CPUs might handle data preprocessing and orchestration, while GPUs or TPUs perform the intensive matrix computations required for model training or inference. Each hardware type has its own performance characteristics, strengths, and weaknesses, and their effective coordination is crucial for overall system performance.  For example, in our case at Google, within a single decade since the introduction of TPUs \cite{jouppi2017indatacenter}, ML fleets have grown to include multiple TPU variations, each with distinct features, configurations, and optimization strategies, all of which must be coordinated with the capabilities of the CPUs and other accelerators in the system. This hardware diversity and interdependence make it challenging to optimize fleet performance holistically.






\textbf{Workload Heterogeneity:} ML fleets must accommodate a variety of workloads and tasks, which evolve at a much faster pace than traditional WSC applications. This rapid evolution and diversity of workloads is driven by shifts in user demands for ML applications and changes in model architectures. New model types, such as large language models \cite{vaswani2017attention} or multi-modal systems \citep{driess2023palme,yu2022coca}, can dramatically alter the computational demands on the fleet. 

ML fleets also consist of workloads from each stage of the ML lifecycle, encompassing training and inference phases. Each phase has its own unique computational characteristics and requirements. For example, training workloads demand high computational power and parallel processing capabilities \cite{kaplan2020scalinglawsneurallanguage}, while real-time inference workloads prioritize low latency and high throughput \cite{pope2023efficiently}. 

The dynamic nature of ML workloads, coupled with the varying requirements across training and inference, demonstrates how the ML fleet must constantly adapt to new computational demands, balancing resources between different phases and workloads.


{\textbf{Hardware/Software Co-design:}} New ML workloads drive the development of new accelerators, while advances in hardware capabilities can enable novel ML applications. This tight coupling creates a moving target for optimization, as both the workloads and the hardware are in a state of constant evolution. The fast-paced ML landscape means that ML fleets must balance the need for specialization with the need for fungibility. For example, \autoref{fig:five-years} illustrates the explosive growth of DSAs in Google's production fleet over a period of five years, driven by the rise of ML-based workloads. 

Domain-specific hardware must be highly specialized to ensure maximal efficiency, but also flexible enough to quickly accommodate new workloads. This challenge is further compounded by the need for runtime systems, compilers, and schedulers to effectively bridge the gap between these evolving hardware capabilities and diverse workload requirements. The software stack must adapt to map workloads onto the most suitable hardware, optimize code for accelerators, and manage resources across the heterogeneous fleet.

The fundamental challenge is that all of these factors combine to create a complex, ever-changing landscape that makes it difficult to maintain optimal fleet performance. Traditional optimization strategies, which often rely on stable hardware and workload characteristics, are inadequate for addressing these dynamic interactions. Architecture-centric metrics, such as TOPs/Watt or peak FLOPS, while valuable for specific hardware evaluations, fall short in capturing the overall complexity and efficiency of an ML fleet. 





\Circled{2} Our second contribution addresses this gap. To view the fleet holistically and capture its performance across multiple layers of the ML system stack, we introduce the ``ML Productivity Goodput'' (MPG) metric. Unlike traditional metrics, MPG encompasses scheduling efficiency, runtime efficiency, and compiler / program efficiency. MPG is analogous to the ``iron law'' of computer performance~\cite{eeckhout2010computer}, but adapted for ML fleets as shown in \autoref{fig:ironlaw}.

The MPG metric enables us to identify areas for improvement across the entire machine learning fleet by analyzing performance across different segments, such as accelerator type, model architecture, and workload phase (e.g., training vs. serving). By breaking down the metric into its components---Scheduling Goodput (SG), Runtime Goodput (RG), and Program Goodput (PG)---and examining it along the axes of fleet characteristics, we can precisely pinpoint potential optimization opportunities.








\begin{figure}[t]
    \centering
    \vspace{.5em}
    \includegraphics[trim=0 10 0 0, clip, width=\columnwidth]{final_figs/ironlaw.png}
    \caption{ML Productivity Goodput (MPG) and its components.%
    }
    \vspace*{-1em}
    \label{fig:ironlaw}
\end{figure}



\Circled{3} Finally, we provide a procedure for leveraging the MPG metric and demonstrate strategies that we have developed and deployed in the real world for optimizing ML fleet performance with the help of this metric. We show how MPG helps us identify compiler optimizations to generate more efficient code for specific hardware configurations, and improve scheduling algorithms to better utilize heterogeneous resources within the fleet, along with a few other strategies. Even after optimizations are implemented in the production fleet operations, the MPG metric can be used to validate and track fleet-wide improvements.



\renewcommand*{\arraystretch}{1.25}
\begin{table*}[t!]
\centering
\caption{Comparison of Machine Learning (ML) Fleet, Warehouse Scale Computer (WSC), and High-performance Computing (HPC).}
\label{tab:comparison}
\resizebox{\textwidth}{!}{%
\scriptsize
\begin{tabular}{@{}lp{4.5cm}p{4.5cm}p{4.5cm}@{}}
\toprule
\textbf{Category} & \textbf{Warehouse Scale Computer} & \textbf{High-Performance Computing} &  \textbf{Machine Learning Fleet} \\ \midrule

\textbf{Workload types} & Diverse web services  (search, email, social networking, media streaming) & Scientific simulations, graph computations, solvers & Training of ML models, real-time serving, bulk inference \\ \midrule

\textbf{Fleet composition} & More stable, as most user demand has reached a steady state or known patterns & A large portion of demand is predetermined, as it is driven by scientific missions & Rapidly changing due to newly emerging ML models and increasing user demand
 \\ \midrule
\textbf{Hardware heterogeneity} & General-purpose CPUs
& CPUs, GPUs, other ASICs & CPUs, GPUs, TPUs, FPGAs, other ASICs.\\ \midrule

\textbf{Hardware/Software co-design} & Hardware is workload-agnostic & Hardware is chosen for specialized applications & ASICs often co-designed with workloads
in mind\\ \bottomrule
\end{tabular}%
}
\end{table*}
\renewcommand*{\arraystretch}{1}

In summary, we make the following contributions to advance the understanding and optimization of large-scale ML fleets:

\begin{enumerate}
    
    \item An end-to-end description and dissection of the software and hardware stack required for a production ML fleet. We discuss the design choices that support large-scale ML workloads in a fleet consisting of domain-specific TPUs.

    \item An examination of workload and hardware heterogeneity in a real ML fleet, revealing the challenges presented by evolving fleet demands and accelerator architectures.

    \item Introduction of ``ML Productivity Goodput'' (MPG), a composable metric that tracks the performance of an ML fleet based on scheduling, runtime and compiler efficiency. 

    \item Strategies for optimizing fleet performance, through case studies and real-world applications of the MPG metric to identify and address bottlenecks across the system stack.
    
    

    
    

\end{enumerate}

These contributions collectively provide a basis for understanding and optimizing large-scale ML infrastructure, thereby paving the way for more efficient, sustainable, and cost-effective deployment of ML workloads across diverse computing environments.







