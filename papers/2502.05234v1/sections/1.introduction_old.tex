\section{Introduction}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{figs/Introduction_v2.png}
    \caption{(a) \textbf{Multi-Sample Aggregation Strategy}: A language model generates multiple samples and aggregates them to produce a final answer. (b) \textbf{Sampling Temperature is Important}: The performance of the deepseek-math-7b-base on the MATH dataset with majority voting. The temperature plays a critical role in the performance. (c) \textbf{Token-Level Entropy}: The token-level entropy indicates sample quality, which flatly increases followed by a sharp spike, and we developed our algorithm \textsc{TURN} for automatic temperature selection based on this.}
    \label{fig: temp_in_intro}
\end{figure}
% sampling-based inference strategies in LLMs
%\weihua{(LLM meets more difficult tasks, and improving performance is needed)}
In recent years, large language models have exhibited remarkable capabilities across a variety of domains, including question answering~\cite{kamalloo2023evaluating}, intelligent agent~\cite{wang2024survey, zhang2023building}, and even scientific discovery~\cite{ma2024llm, romera2024mathematical}. 
%In contrast to traditional applications such as machine translation—which largely center on memorizing data patterns—E
Emerging tasks like mathematical question answering require robust reasoning and the ability to generalize to previously unseen data. %Current efforts to enhance these capabilities have focused on two principal directions: refining the training processes of language models and designing more powerful inference strategies.

%\weihua{(Sampling-Based Inference is an important inference-time algorithm)} 
Although most previous research has focused on training stronger language models~\cite{zhou2024comprehensive, zhang2023instruction, fernandes2023bridging}, limited availability of high-quality training data and expensive training budget has become the bottleneck~\cite{jones2024ai}. Therefore, recent works have begun to explore inference strategies and achieved considerable success~\cite{wei2022chain, yao2024tree, madaan2024self}. A family of effective inference strategies consists of sampling multiple times and aggregating the samples to generate a final prediction, which we refer to as \emph{multi-sample aggregation strategies}~\cite{welleck2024decoding, wang2022self}. As shown in Figure~\ref{fig: temp_in_intro}, multiple samples are collected and aggregated to generate a final prediction. Common aggregation strategies include majority voting and best-of-N, which can lead to dramatic performance improvements as the number of samples is scaled up~\cite{wang2022self, wang2024planning}.

%\weihua{(Sampling temperature is important)}
Temperature is a key parameter in multi-sample aggregation strategies since it smooths or sharpens the distribution of generated sequences. Increasing the temperature typically boosts the diversity of samples, enabling language models to avoid making trivial mistakes or generating repetitive content. However, an excessively high temperature can lead to low-quality samples~\cite{renze2024effect}. Although previous works applied temperature tuning for some domains like language model calibration~\cite{xie2024calibrating} or summarization~\cite{meister2023locally}, no one systematically explored how to set temperature in multi-sample aggregation strategies. As illustrated in Figure \ref{fig: temp_in_intro}, a lower temperature may yield better performance when the sample size is small, whereas a higher temperature can be more effective with larger sample sizes, even though the average quality for a single sample may decrease.

%\weihua{(A fixed temperature is not enough, so we need to tuneW the temperature)}
Despite this, prior works adopt a fixed temperature across all models and tasks or rely on a validation set for temperature selection~\cite{zhang2024scaling}. Models are often trained on diverse datasets, tasks can vary considerably, and sample sizes may differ, developing a deeper understanding of temperature selection is vital. Indeed, when applying multi-sample aggregation strategies, as illustrated in Figure~\ref{fig: teaser}(b), A pretrained model may require a lower temperature to focus on closely related tokens. In contrast, a task fine-tuned model could benefit from a higher temperature because of sample diversity. Motivated by such differences, we aim to explore how to predict the optimal temperature in these strategies.
%\weihua{(It is not an easy task (previous works))} Some prior research has explored tuning temperature for single outputs~\cite{}. For instance, \citet{zhang2024scaling} proposed a method to adjust temperatures based on model performance on a validation set, \citet{dhuliawala2024adaptive} trained a classifier for token-level temperature selection. However, temperature tuning poses unique challenges due to the need to balance sample diversity and sample quality in the Sampling-Based Inference setting. To our knowledge, no existing work has investigated how to tune temperatures for Sampling-Based Inference automatically.

%\weihua{Two types of previous works, (1) tuning temperature and sample once (2)}

%\weihua{Generalization, better understanding the role of temperature. previous people use a valid set or use the default temperature. to understand the. unified understanding of temperature. fix temperature --> valid set hyperparameter tuning}
%\weihua{(What we are doing in this paper)} 
In this study, our overarching objective is to develop a method for effective temperature selection across different models and tasks without relying on labeled validation data. We pursue this goal through the following steps: (1) we establish a new relationship between the optimal sampling temperature of language models and the similarity of their training data with target tasks. Specifically, when a model’s training corpus closely matches the target task, the model exhibits greater confidence and remains stable at higher temperatures, resulting in a higher optimal temperature. Conversely, a general-purpose model with less specialized training data typically needs lower temperatures to mitigate task-irrelevant outputs. This observation is widely established among models and tasks. (2) %we identify a turning point in the temperature for sampling-based inference strategies—where performance improves up to this point and then declines thereafter—thus indicating the optimal balance between sample diversity and quality. 
We uncover a surprising phenomenon we call the entropy turning point. As shown in Figure~\ref{fig: temp_in_intro}(c), token-level entropy remains stable before this point but quickly increases after that. This signal reveals a quality drop in generated samples.
(3) We develop a method for automatically selecting the optimal temperature for multi-sample aggregation strategies, called \textsc{TURN}. Specifically, it utilizes the entropy turning point and does not require additional validation sets or labeled data. Our method demonstrates robust generalizability across tasks (e.g., mathematical problem-solving, code generation) under various aggregation strategies (majority voting, best-of-N), achieving an overall \(88\%\) hit rate in determining the optimal temperature. Meanwhile, we employ an explanation model to explain both the turning point and our algorithm to enhance interpretability.
%propose an algorithm to automatically select an appropriate temperature for a given model and task in the sufficient sampling setting, without relying on a separate validation set. We identify a clear turning point in the temperature curve where the model's outputs start to deteriorate, and we locate this point by analyzing the model's entropy. We conduct experiments on math problem answering, code generation, and instruction-following tasks to demonstrate the versatility of our algorithm. 
%\weihua{first discover the turning point --> algorithm --> apply to all algorithm}

In conclusion, our contribution includes:
\begin{itemize}
    \item We examine how temperature affects multi-sample aggregation inference in large language models and find that the optimal temperature correlates with the model's distance from tasks.
    \item We develop the first method for automatically selecting the optimal temperature. It is based on a new phenomenon called the entropy turning point. 
    \item Our algorithm \textsc{TURN} identifies the optimal temperature with 88\% accuracy, outperforming the standard fixed-temperature approach.
\end{itemize}

% two figures: up: draw a distribution, low temperature —> sharp —> wrong, high —> correct. down: draw a temperature - acc curve
%\include{tables/intro_temp}