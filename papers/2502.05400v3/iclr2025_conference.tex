
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{authblk}
\usepackage{framed}
\usepackage{tcolorbox}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{geometry}
\usepackage{array}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{threeparttable}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{caption}


% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{bbm}

\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow,array}
\usepackage{authblk}
\usepackage{enumitem}

\usepackage{appendix}


\makeatletter
\renewcommand\AB@affilsepx{, \protect\Affilfont}
\makeatother



\title{Dynamic Noise Preference Optimization for LLM Self-Improvement via Synthetic Data}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.


\author{
\raggedright
Haoyan Yang$^1$\thanks{Equal Contribution.}
\ \thanks{The work was done when the first author was doing an internship at Samsung Research America.} 
\quad Ting Hua$^2$$^*$ \quad Shangqian Gao$^3$$^*$ \quad Binfeng Xu$^2$ \quad Zheng Tang$^2$ \quad Jie Xu$^4$\\
\vspace{-1.0em}
Hongxia Jin$^2$ \quad Vijay Srinivasan$^2$ \\
\vspace{0.5em}
$^1$New York University \quad $^2$Samsung Research America \\
$^3$Florida State University \quad $^4$University of Florida \\
\texttt{hy2847@nyu.edu} \quad
\texttt{ting.hua@samsung.com} \quad 
\texttt{sgao@cs.fsu.edu} \quad
\texttt{binfeng.xu@samsung.com} \quad \texttt{zheng.tang@samsung.com} \quad
\texttt{xujie@ufl.edu} \quad
\texttt{hongxia.jin@samsung.com} \quad  \texttt{v.srinivasan@samsung.com} \quad 
}



% \author{
% Haoyan Yang \thanks{The work was done when the first author was doing internship at Samsung Research America} \\
% Department of Computer Science\\
% Cranberry-Lemon University\\
% Pittsburgh, PA 15213, USA \\
% \texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
% \And
% Ji Q. Ren \& Yevgeny LeNet \\
% Department of Computational Neuroscience \\
% University of the Witwatersrand \\
% Joburg, South Africa \\
% \texttt{\{robot,net\}@wits.ac.za} \\
% \AND
% Coauthor \\
% Affiliation \\
% Address \\
% \texttt{email}
% }

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.

\newcommand{\etal}{\textit{et al}.}
\newcommand{\ie}{\textit{i}.\textit{e}.}
\newcommand{\eg}{\textit{e}.\textit{g}.}


\newcommand{\ting}[1]{{\color{orange}{(ting: #1)}}}
\newcommand{\hy}[1]{{\color{blue}{(haoyan: #1)}}}
\newcommand{\sq}[1]{{\color{red}{(shangqian: #1)}}}
\newcommand{\bill}[1]{{\color{green}{(binfeng: #1)}}}

\begin{document}


\maketitle

\begin{abstract}
Although LLMs have achieved significant success, their reliance on large volumes of human-annotated data has limited their potential for further scaling. In this situation, utilizing self-generated synthetic data has become crucial for fine-tuning LLMs without extensive human annotation. 
However, current methods often fail to ensure consistent improvements across iterations, with performance stagnating after only minimal updates. 
To overcome these challenges, we introduce \textbf{D}ynamic \textbf{N}oise \textbf{P}reference \textbf{O}ptimization (DNPO). DNPO employs a dynamic sample labeling mechanism to construct preference pairs for training and introduces controlled, trainable noise into the preference optimization process.
Our approach effectively prevents stagnation and enables continuous improvement. In experiments with Zephyr-7B, DNPO consistently outperforms existing methods, showing an average performance boost of 2.6\% across multiple benchmarks. 
Additionally, DNPO shows a significant improvement in model-generated data quality, with a 29.4\% win-loss rate gap compared to the baseline in GPT-4 evaluations. This highlights its effectiveness in enhancing model performance through iterative refinement.

\end{abstract}

\input{tex/iclr2025_intro}
\input{tex/iclr2025_relatedWork}
\input{tex/iclr2025_prob}
\input{tex/iclr2025_method}
\input{tex/iclr2025_exp}
\input{tex/iclr2025_conclusion}
\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\input{tex/iclr2025_app}


\end{document}
