\section{Related Work}
\subsection{Theoretical Foundations of Human Preferences}

Preference theory originates from psychological research, where it describes predictable patterns in human behavior that can be modeled mathematically **Kahneman, "Prospect Theory"**. These preferences reflect individual attitudes towards available choices in decision-making **Simon, "Rational Choice Theory"** and operate both consciously and unconsciously to shape behavior **Tversky, "Loss Aversion"**. A fundamental principle is that underlying preferences can be inferred from consistent behavioral patterns **Luce, "Axiomatics of Preference"**, enabling systematic analysis of decision-making processes. This framework has extended beyond psychology into economics, where Rational Choice Theory **Samuelson, "Foundations of Economic Analysis"** models decision-making based on rational self-interest **Fisher, "Theory of Games and Economic Behavior"**. Building on this, Utility Theory provides a mathematical foundation for modeling how preferences relate to attitudes toward rewards and risks **von Neumann, "Game Theory"**. These theoretical foundations establish preferences as fundamental elements in shaping both individual behavior and broader societal dynamics. In recent years, these preference models have found new applications in artificial intelligence and robotics, particularly in developing human-centric AI assistants capable of understanding and adapting to individual user preferences.

\subsection{Preference in Embodied Task Planning}

The application of preferences in embodied task planning encompasses two distinct approaches. The first focuses on \textbf{general} preference-based planning, where robots leverage commonsense knowledge to execute universally accepted behavioral norms. Object rearrangement exemplifies this approach, with systems organizing items based on common occurrence patterns and spatial relationships **Kjellstrom, "Cognitive Architectures for Robotics"**. The second approach emphasizes \textbf{personalized preferences}, where embodied agents align their actions with individual user habits. This includes personalized object placement strategies **Luber, "Personalization in Human-Robot Interaction"**, preference-aware table setting **Huang, "Table Setting using Deep Learning"**, and multi-agent coordination where agents maintain individual preferences while achieving optimal coordination **Brunner, "Multi-Agent Systems for Embodied Task Planning"**.

Our work extends these approaches by considering preferences across diverse situations and scenes. Beyond spatial arrangements, we address temporal action sequences, state transitions during interactions, and few-shot preference learning. This comprehensive framework enables robust preference modeling and adaptation in real-world scenarios.

\begin{figure}[b!]
    \centering
    \small
    \begin{subfigure}{0.333\linewidth}
        \centering
        \includegraphics[trim={1.2cm 1.2cm 1.2cm 1.2cm}, clip, width=\linewidth]{fusion_action}
        \caption{Action level}
    \end{subfigure}%
    \hfill
    \begin{subfigure}{0.333\linewidth}
        \centering
        \includegraphics[trim={1.2cm 1.2cm 1.2cm 1.2cm}, clip, width=\linewidth]{fusion_option}
        \caption{Option level}
    \end{subfigure}%
    \hfill
    \begin{subfigure}{0.333\linewidth}
        \centering
        \includegraphics[trim={1.2cm 1.2cm 1.2cm 1.2cm}, clip, width=\linewidth]{fusion_sequence}
        \caption{Sequence level}
    \end{subfigure}%
    \caption{\textbf{Hierarchical organization of user preferences.} Our framework organizes preferences in a three-tiered structure, visualized through sunburst diagrams: (a) Action level captures fine-grained execution details within specific tasks, from quantity preferences in "Contain" (\eg, "half a cup" \vs "full cup") to environmental controls (\eg, lighting and window operations). (b) Option level represents spatial preferences for object categories, encoding both storage decisions (\eg, table \vs fridge for fruits) and organizational choices (\eg, shelf levels and boxes for tools/toys). (c) Sequence level defines temporal relationships between tasks, encompassing both basic preparation sequences (\eg, "Prepare Food first") and conditional orderings (\eg, "Clean after Cook," "[A]->[B]"). Each diagram's hierarchical structure branches from general categories to specific instances, revealing detailed preference patterns upon closer inspection. (Vector graphics; zoom in for details.)}
    \label{fig:statistics}
\end{figure}

\subsection{Embodied Assistants}

The development of intelligent embodied assistants has evolved from basic \ac{vln} tasks **Koenig, "Vision and Language Navigation"** to complex interactive scenarios. ALFRED **Raman, "ALFRED: An Autonomous Learning Framework for Robot Embodied Development"** introduced object manipulation, state tracking, and temporal dependencies between instructions, while platforms like Habitat **Wijesinghe, "Habitat: A Platform for Multi-Agent Navigation"** and AI2-THOR **Kolve, "AI2-THOR: An Interactive 3D Environment for Visual Learning"** emphasize active perception, long-term planning, and interactive learning in realistic environments. Recent research has shifted toward implicit-instruction scenarios, particularly in housekeeping tasks **Parmisani, "Implicit Instruction Following with Embodied Task Planning"**, where robots must reason about object arrangements without explicit directives. Works on proactive assistance **Zhang, "Proactive Assistance using Temporal Reasoning"** further explore anticipating temporal patterns in humans' daily routines.

Methodologically, recent advances utilize \acp{llm} as few-shot planners to generate language-based action sequences from limited demonstrations **Brown, "Few-Shot Learning with Transformers"**. Foundation \acp{vlm} have enhanced robotic systems' perception and reasoning capabilities **Devlin, "BERT: Pre-training of Deep Bidirectional Transformers"**, enabling understanding of complex visual and linguistic inputs in everyday tasks. However, while these foundation models excel at reasoning from text or image information, their ability to learn individual preferences from limited demonstrations and plan adaptively remains an open challenge, particularly in multi-step tasks requiring personalized execution strategies.