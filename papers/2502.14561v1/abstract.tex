\begin{abstract} 

This work investigates the ability of open Large Language Models (LLMs) to predict citation intent through in-context learning and fine-tuning. Unlike traditional approaches that rely on pre-trained models like SciBERT, which require extensive domain-specific pretraining and specialized architectures, we demonstrate that general-purpose LLMs can be adapted to this task with minimal task-specific data. We evaluate twelve model variations across five prominent open LLM families using zero, one, few, and many-shot prompting to assess performance across scenarios. Our experimental study identifies the top-performing model through extensive experimentation of in-context learning-related parameters, which we fine-tune to further enhance task performance. The results highlight the strengths and limitations of LLMs in recognizing citation intents, providing valuable insights for model selection and prompt engineering. Additionally, we make our end-to-end evaluation framework and models openly available for future use.
\end{abstract}

% \begin{abstract}
% This work investigates the ability of open large language models (LLMs) to predict citation intent through in-context learning. 
% Citation intent classification has traditionally relied on pre-trained models that require large datasets and task-specific architectures. In contrast, this study explores the potential of general-purpose LLMs to perform this task without task-specific training, evaluating their effectiveness through in-context learning alone. We evaluate twelve model variations across five prominent open LLM families, using zero, one, few, and many-shot prompting to assess model performance across prompting scenarios.
% Our experimental study identifies the top-performing model across most scenarios, which we subsequently fine-tune for enhanced task performance. The results highlight the strengths and limitations of LLMs in recognizing citation intents, providing valuable insights for model selection and prompt engineering. 
% Additionally, we make our end-to-end evaluation framework and models openly available for future use. 
% \end{abstract}

% == OLD VERSION - DELETE IF IT IS NOT YET USEFUL == 
%This work investigates the ability of open-source large language models (LLMs) to predict citation intent through in-context learning, presenting the most comprehensive evaluation of this task to date. 
%Citation intent classification has traditionally relied on fine-tuned BERT-based models that require large annotated datasets. In contrast, this study explores the potential of general-purpose LLMs to perform this task without task-specific training, evaluating their effectiveness through in-context learning alone. We evaluate twelve model variations across five prominent open-source LLM families, using zero, one, few, and many-shot prompting to assess model performance across prompting scenarios.
%Our experimental study identifies the top-performing model across most scenarios, which we subsequently fine-tune for enhanced task performance. The results highlight the strengths and limitations of LLMs in recognizing nuanced citation intents, providing valuable insights for model selection and prompt engineering. 
%As a further contribution, we offer our end-to-end evaluation framework for future use, enabling researchers to test any model on this task. This work aims to advance automatic citation intent analysis, ultimately contributing to more refined and interpretable metrics for scientific impact.