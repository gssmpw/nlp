% \newpage
\section{Appendix~--~Models}\label{sec:appendix-c-models}

% \emph{\color{red} \textbf{Paris:} Maybe? This could have a detailed table for the models, if we remove the table from the Experimental Setup.}

Table~\ref{tab:models-appendix} outlines the models used in our evaluation (Section~\ref{sec:models}) along with their context lengths and HuggingFace links.

\begin{table*}[t]
    \centering
    \footnotesize
    \begin{tabular}{lcl}
      \hline
      \textbf{Model}                      & \textbf{Context Length}    & \textbf{HF Links} \\
      \hline
      Llama 3.2 Instruct~--~1B            & 128K                       & \href{http://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF}{hugging-quants/Llama-3.2-1B-Instruct-Q8\_0-GGUF} \\
      Llama 3.2 Instruct~--~3B            & 128K                       & \href{https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF}{hugging-quants/Llama-3.2-3B-Instruct-Q8\_0-GGUF} \\
      Llama 3.1 Instruct~--~8B            & 128K                       & \href{https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF}{lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF} \\
      Llama 3 Instruct~--~8B              & 8192                       & \href{https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF}{lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF} \\
      Mistral Nemo Instruct~--~12B        & 128K                       & \href{https://huggingface.co/lmstudio-community/Mistral-Nemo-Instruct-2407-GGUF}{lmstudio-community/Mistral-Nemo-Instruct-2407-GGUF} \\
      Phi3 Medium Instruct~--~14B         & 128K                       & \href{https://huggingface.co/bartowski/Phi-3-medium-128k-instruct-GGUF}{bartowski/Phi-3-medium-128k-instruct-GGUF} \\
      Phi3.5 Mini Instruct~--~3.8B        & 128K                       & \href{https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF}{bartowski/Phi-3.5-mini-instruct-GGUF} \\
      Gemma 2 Instruct~--~2B              & 8192                       & \href{https://huggingface.co/lmstudio-community/gemma-2-2b-it-GGUF}{lmstudio-community/gemma-2-2b-it-GGUF} \\
      Gemma 2 Instruct~--~9B              & 8192                       & \href{https://huggingface.co/bartowski/gemma-2-9b-it-GGUF}{bartowski/gemma-2-9b-it-GGUF} \\
      Gemma 2 Instruct~--~27B             & 8192                       & \href{https://huggingface.co/bartowski/gemma-2-27b-it-GGUF}{bartowski/gemma-2-27b-it-GGUF} \\
      Qwen 2 Instruct~--~7B               & 32K                        & \href{https://huggingface.co/Qwen/Qwen2-7B-Instruct}{Qwen/Qwen2-7B-Instruct} \\
      Qwen 2.5 Instruct~--~14B            & 32K                        & \href{https://huggingface.co/lmstudio-community/Qwen2.5-14B-Instruct-GGUF}{lmstudio-community/Qwen2.5-14B-Instruct-GGUF} \\
      \hline
    \end{tabular}
    \caption{The models used in our evaluation.}\label{tab:models-appendix}
\end{table*}