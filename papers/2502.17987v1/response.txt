\section{Related Works}
\subsection{Data Augmentation Techniques}
In recent years, data augmentation techniques have gained significant attention, especially for low-resource languages, due to the scarcity of properly annotated datasets and general lack of resources. Analyzing one such technique by Sennrich et al. **Sennrich, "Improving Neural Machine Translation Models with Scheduled Sampling"** leverage monolingual target language data for textual-based data augmentation using back-translation to enhance model performance. However, this method requires extra computational resources, as it needs an additional pre-trained NMT model.

Another approach proposed by  Lample et al. **Lample, "Unsupervised Machine Translation Using Monolingual Corpora Only"** relies solely on monolingual corpora, which eliminates the need for parallel data. This is achieved by mapping sentences from two languages into a shared latent space using a shared encoder-decoder architecture. Although this method avoids the need for parallel data, it still depends on monolingual corpora, which can be scarce for certain languages. For a simpler and highly effective solution, Wei and Zou **Wei, "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks"** introduced the "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks." Their technique consists of four operations: synonym replacement, random insertion, random swap, and random deletion. This straightforward method significantly boosted model performance, even when training with only half of the available dataset. EDA operates without dependencies beyond a basic synonym dictionary like Miller **Miller**.

In **Ruder**, the authors proposed a novel approach called contextual augmentation. Unlike previous techniques that relied on predefined synonym dictionaries or rules, this model uses a bidirectional language model to predict appropriate substitute words based on the surrounding context. This allows for more diverse word suggestions and has shown promising potential, consistently outperforming previous techniques like EDA, especially in low-resource scenarios. In **Huang**, explored a technique called TMix, which interpolates hidden space representations of text samples to create continuous augmented data, helping to mitigate overfitting in resource-limited settings. Their study also incorporated entropy minimization and consistency regularization to effectively utilize both labeled and unlabeled data, showing great potential in scenarios with extremely limited labeled data.
Another innovative approach, proposed by **Guo**, is SeqGAN, which combines reinforcement learning with Generative Adversarial Networks (GANs) to address challenges in generating discrete sequences. SeqGAN uses Monte Carlo search and models the generator as a stochastic policy to overcome the difficulty of propagating gradients through discrete outputs. The discriminator provides rewards for complete sequences, guiding the generator via policy gradient updates. This method demonstrated significant improvements over baseline methods in tasks like music generation and extends GANs for discrete sequence generation in NLP tasks. **Liu** analyzed an adversarial evaluation scheme for reading comprehension systems, targeting the SQuAD dataset **Rajpurkar**, this method involves adding adversarially crafted sentences to input paragraphs, designed to confuse machine learning models while remaining clear to humans. The study showed that even state-of-the-art models experienced performance drops under adversarial evaluation, highlighting the importance of genuine language understanding.
Raffel et al. **Raffel**, delved into transfer learning, enabling models trained on high-resource languages to be adapted for low-resource languages. They examined methods like sentence-level alignment and multilingual embeddings, which integrate linguistic resources across languages. These techniques can significantly improve model performance in low-resource scenarios by leveraging existing high-resource language data.
Lastly, Li et al. **Li**, explored generating synthetic data for text classification using large language models. They used zero-shot and few-shot settings to generate synthetic training data with tailored prompts and manual annotation. The study found that model performance with synthetic data is affected by the subjectivity of the classification task. Incorporating real-world examples and human feedback can enhance the quality of synthetic data and improve model performance, especially for subjective tasks.

\subsection{Data Augmentation for Low Resource Corpora Text Classification}
One of the problems performing various downstream tasks in NLP is working with languages that don't have much labeled data. At such times, data augmentation techniques help tackle the problem. One such approach is TAU-DR by Rahamim
et al. **Rahamim**, which uses soft prompts and keeps language model frozen to reconstruct hidden representations and then turning those back into synthetic sentences and proves to be really effective at improving multi-class classification. Additionally **Ahn** also conducted a study on the cross-lingual transfer capabilities in low-resource african languages and benchmarked the forgetting metrics, although this study did not employ augmentation metrics to reduce the model's forgetting.
Some other techniques like AEDA in Karimi et al. **Karimi**, which inserts punctuation marks into sentences to create variations unlike methods like EDA where data loss is possible as it involves operations like deletion and substitution, this method preserves the original information and semantic consistency. After testing on multiple datasets AEDA consistently outperformed EDA, particularly in low-resource settings, The simplicity of AEDA and its performance across different models highlights its effectiveness. IndiText Boost by Litake et al. **Litake**, is a framework tailored for the underrepresented Indian languages, which utilizes techniques like EDA and back-translation to outperform the more complex LLM-based methods in basic classification tasks.
 
 In Sahu et al. **Sahu**, the authors explore prompt-based data augmentation in intent classification tasks using Large Language Models (LLMs) like gpt2 **gpt2** which boils down to just using a pre-trained LLM to augment data by creating synthetic data but due to LLMs tendency to create unreliable data this can lead to reducing data's quality. In Zhao et al. **Zhao**, the authors proposed EPiDA, (Easy Plug-in Data Augmentation) framework, which works for text classification. It employs two methods, conditional entropy minimization and relative entropy maximization which balances the diversity and quality of augmented data. Conditional entropy minimization ensures the semantic consistency while relative entropy maximization promotes more diverse samples. Through extensive testing it was seen that it consistently outperforms existing data augmentation techniques in various NLP tasks highlighting its application for low-resource applications. 
\\
\subsection{LiDA - Language Indpendent Data Augmentation}

The LiDA: Language-Independent Data Augmentation for Text Classification by
 Sujana and Kao **Sujana**, introduced us to a novel augmentation technique catering to low-resource language settings. The authors, rather than creating synthetic data for increasing the dataset, worked on augmenting the sentence level embeddings for the classification task, resulting in a 2\%-3\% improvement on average in LSTM classification results. The language independence mentioned arises from the multilingual dataset that is used for the training of the SBERT model.