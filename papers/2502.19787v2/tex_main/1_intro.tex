\section{Introduction}
\paragraph{LLMs and ICL}
Large Language Models (LLMs)~\citep{zhao2023survey} have garnered widespread attention for their ability to solve complex tasks using simple text prompts.
Among their many capabilities, in-context learning (ICL)~\citep{NEURIPS2020_1457c0d6} is particularly striking.
ICL enables LLMs to adapt to new tasks by conditioning on provided examples, effectively allowing them to learn from context without explicit parameter updates.
% Although the notion of learning from examples is intuitive for humans, 
Understanding how such behavior emerges in LLMs remains an intriguing and challenging problem.
\begin{figure*}[th!]
    \centering
    %\vspace{-1.1cm}
    \includegraphics[width = 1.0\textwidth]{fig/main.pdf}
    %\vspace{-0.2cm}
    \caption{\textbf{Common ICL framework \textit{vs.} ours.}  
    Conventional frameworks with synthetic datasets often construct sequences by concatenating multiple \((\vx, \vy)\) pairs, overlooking the importance of instructions.
    In contrast, our approach explicitly incorporates instructions through a \textit{hypothesis prefix}. Specifically, we transform the hypothesis class \(\mathcal{H}\) into a sequence that is prepended to the sequence of \((\vx, \vy)\) pairs and then fed into a Transformer. We refer to this method as \textit{in-context learning with hypothesis-class guidance (ICL-HCG)}.
    %This framework allows us to assess Transformer performance across diverse configurations of $\mathcal{H}$.
    (Real-world examples are demonstrated using the GPT-4 Legacy model.)
    }
    \label{fig:main}
    %\vspace{-0.3cm}
\end{figure*}

\paragraph{Existing Efforts for Understanding ICL} To elucidate the mechanisms behind ICL, researchers have
constructed a variety of synthetic datasets~\citep{garg2022can,li2023transformers,BaiCWXM23}.
These datasets
typically involve sequences consisting of input-output pairs
\(\{(\vx^{(i)}, y^{(i)})\}\), where each output
\(y^{(i)}\) is generated by a simple underlying function
\(f(\vx^{(i)})\). For example, \citet{garg2022can} focus on noiseless
linear regression, where each input is sampled from an
isotropic Gaussian by $\vx^{(i)} \sim \mathcal{N}(\vzero, \mI_d)$, and the corresponding
output is given by \(y^{(i)} = \langle \vx^{(i)}, \vw \rangle\) with
\(\vw \sim \mathcal{N}(\vzero, \mI_d)\) for each sequence.
During training and inference, the model
receives a sequence consisting of \(k\) demonstration pairs
\((\vx^{(1)}, y^{(1)}, \dots, \vx^{(k-1)}, y^{(k-1)})\) followed
by a query input \(\vx_{\text{query}}\). This setup allows the model to
infer the correct response for \(\vx_{\text{query}}\) conditioned on in-context examples.
Various extensions have been proposed, including using Gaussian mixtures rather than a single
Gaussian for task priors~\citep{lin2024dual}, employing non-linear
functions~\citep{BaiCWXM23}, and introducing multiple intermediate
``chain-of-thought''~\citep{wei2022chain} steps within each $(\vx,\vy)$ pair~\citep{li2024how}.

\textbf{Motivation}
While a variety of data models have been studied to advance our understanding of ICL, a gap remains between these datasets and real-world ICL scenarios.
In practice, users often provide LLMs with \emph{an instruction} in addition to labeled demonstrations, containing the descriptions of the task in mind. 
See Fig.~\ref{fig:main} for the visualization.
The top-left and top-right panels show experimental results using the GPT-4 Legacy model, highlighting the effect of instruction.
In the top-left panel, the user provides a one-shot English-Korean translation pair without specifying the instruction, leading to an incorrect translation.
In contrast, the top-right panel includes the instruction—\emph{“perform the translation task following the demonstration”}—guiding the model to produce a correct translation, emphasizing the importance of the task descriptions.
% When tested with the GPT-4 Legacy model, our demonstration shows that ICL with a task description produces the correct answer, whereas ICL without any task description results in an incorrect output as the model fails to understand the underlying task and tends to answer the English sentence that happened to be a question sentence.
% Shown on the top right is the case where the user provides a one-shot example preceded by a partial task description --  \emph{``perform the translation task based on the demonstration''}.
% This resulted in a correct translation as shown in the figure.
In fact, instructions are known to enhance the accuracy of ICL in general~\citep{NEURIPS2020_1457c0d6}.
However, most existing synthetic data frameworks overlook this crucial aspect, neglecting the role of instructions in guiding the learning process.
Motivated by this limitation, we ask:
\begin{center}
    \it Can we design a synthetic data framework for ICL that better captures the practical use scenarios of ICL by incorporating both instructions and labeled samples?
\end{center}
Notably, two recent works~\citep{xuanyuan2024on,huang2024task} adopt prefix as instruction to implicitly provide information on the task.
In contrast, our approach explicitly provides a hypothesis class as a prefix to the Transformer, guiding the model's understanding of the intended task.

\paragraph{Our Synthetic Data Model}  
We propose a novel synthetic data model, \textit{in-context learning with hypothesis-class guidance (ICL-HCG)}, illustrated in the bottom-right panel of Fig.~\ref{fig:main}, which integrates a hypothesis class into the ICL procedure.  
Specifically, besides the usual sequences of $(\vx,\vy)$ pairs, a hypothesis class is embedded as a hypothesis prefix and fed into the Transformer (more details in Fig.~\ref{fig:framework} of Sec.~\ref{subsec:framework}). 
Leveraging this framework, we explore several aspects of Transformer behavior on the ICL-HCG task:
(i) We evaluate the generalization ability of trained models to new hypothesis classes, new hypotheses, and various sizes of hypothesis classes;
(ii) We compare different model architectures (Transformer, Mamba, LSTM, and GRU), highlighting their distinct properties on these generalizations;
(iii) We examine the sample complexity required for achieving ID and OOD hypothesis class generalization and discover that merely a few dozen training hypothesis classes are sufficient for near-perfect generalization.
(iv) We examine the effect of imbalanced in-context samples, demonstrating that imbalance can slow down the training process;
(v) We assess the benefit of incorporating a hypothesis prefix, which notably enhances the accuracy of ICL;
(vi) We show pretraining hypothesis diversity can significantly improve the accuracy of ICL when with instruction.


We summarize our contributions as follows:
\begin{itemize}[leftmargin=0.2cm]
    \item We propose a novel synthetic data model, namely in-context learning with hypothesis-class guidance (ICL-HCG) that integrates a hypothesis class into the ICL procedure.
    This design provides a controlled testbed for diverse experiments to study behaviors of ICL with instruction.
    \item We perform extensive empirical evaluations on our framework.
    Most interestingly, we demonstrate that (a) Transformers can successfully learn ICL-HCG and such a learned ability can generalize to unseen hypotheses and unseen hypothesis classes, and (b) compared with ICL without instruction, ICL-HCG achieves significantly higher accuracy on ICL, demonstrating the role of instructions.
\end{itemize}



% $\mathcal X = \{x^{(1)}, x^{(2)},\cdots, x^{(k)}\}$. 

% $\{x^{(i)}\}_{i=1}^n \sim P^n$.