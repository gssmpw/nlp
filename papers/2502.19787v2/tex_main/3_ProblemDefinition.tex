\section{Meta-Learning for ICL-HCG}
Training a learner to perform ICL aligns with the concept of meta-learning, as it enables adaptation to new tasks using in-context examples. While prior studies~\citep{garg2022can,fan2024transformers,raventos2024pretraining} train Transformers for ICL on sequences of the form \((x_1, y_1, x_2, y_2, \dots, x_k, y_k)\) without explicit instructions, our work investigates whether a Transformer trained for ICL with instructions, namely ICL-HCG, can generalize to new ICL-HCG tasks.

% While meta-learning trains across tasks and fine-tunes on new samples for rapid adaptation, MetaICL trains a learner on ICL tasks, learning to predict by using those new samples as in-context examples---feeding them along with the query sample (the one to be predicted) as input to the learner---eliminating the finetuning stage.

% Enabling a model to do in-context learning usually requires pretraining it on in-context learning sample of form $\text{training examples, test queries}$ sampled from a meta task distribution $P_{task}$ during pretraining of the large models.
% We use this section to introduce our meta-learning framework for ICL-HCG.
% We start by introducing the the meta tasks in ICL-HCG
%\zq{Is this meta learning? or just generalization? Since the task of meta in our work would be $(H,h,xyxy)$, which is a sample rather than a ``task''.}
%\input{tex_main/3.1_ERM_and_PAC_Learning}
% we need to explain what is meta learning in plain english before going into notations 
% Meta-learning refers to the process of learning how to learn by leveraging experiences from multiple tasks.
% In our setup, each meta-task is defined by a hypothesis class, and a sample within a meta-task consists of a combination of the hypothesis class, multiple $(x,y)$ pairs, and the underlying hypothesis.
\subsection{Two Types of Tasks in ICL-HCG}
\label{sec:problem-definition}
We consider two types of tasks in ICL-HCG, both constructed from a finite hypothesis class
\(
    \mathcal{H} = \{h^{(1)}, h^{(2)}, \ldots, h^{|\mathcal{H}|}\}
\)
over a finite input space
\(
    \mathcal{X} = \{x_1, x_2, \ldots, x_{|\mathcal{X}|}\}
\)
and a binary output space
\(
    \mathcal{Y} = \{0, 1\}.
\)

\paragraph{Label prediction}
Consider a hypothesis class \(\mathcal{H}\) and a sequence consisting of training data and a test point
\[
    \Skmx = (x^{(1)}, y^{(1)}, \ldots, x^{(k-1)}, y^{(k-1)}, x^{(k)})
\]
where for all $i$, \(y^{(i)} = h(x^{(i)})\) for a specific \(h \in \mathcal{H}\), and \(x^{(k)}\) is a test query input. The objective is to predict the label 
\[
    y^{(k)} = h\bigl(x^{(k)}\bigr).
\]
We refer to this as label prediction, with input-output pairs:
\[
    i_{\text{I},k} = \bigl(\mathcal{H}, \Skmx\bigr),
    \quad
    o_{\text{I},k} = y^{(k)}.
\]

\paragraph{Hypothesis identification}
Given a hypothesis class \(\mathcal{H}\) and a sequence (namely \emph{ICL sequence}) 
\[
    \SK = (x^{(1)}, y^{(1)}, \ldots, x^{(K)}, y^{(K)}),
\]
where for all $i$, \(y^{(i)} = h(x^{(i)})\) for a specific  \(h \in \mathcal{H}\),
the goal is to identify the underlying hypothesis \(h\).
Denote this as hypothesis identification, with:
\[
    i_{\text{II},K} = \bigl(\mathcal{H}, \SK \bigr),
    \quad
    o_{\text{II},K} = h.
\]



\paragraph{Meta-learning}
%A task in meta learning is defined by a finite hypothesis class $\mathcal{H}$.
Label prediction uses \(k-1\) samples to predict the label of a new query \(x^{(k)}\), while hypothesis identification directly outputs \(h\).
Both label prediction and hypothesis identification can be viewed as attempts to identify \(h\) from $\mathcal{H}$ via empirical risk minimization (ERM) using the dataset 
\(\{(x^{(i)},y^{(i)})\}\).
Our meta-learning aims at learning to do ERM for different hypothesis classes when these hypothesis classes are given as input along with $(x,y)$ pairs.



\subsection{Sample Generation}
We consider the following two approaches for generating samples of ICL-HCG tasks.
\begin{asu}[i.i.d.\ Generation]
\label{asu:iid}
Given hypothesis classes
\(\{\mathcal{H}_i\}_{i=1}^{N}\), input space \(\mathcal{X}\), and an integer \(K\):\\
\subasu\label{asu:setting1}Sample a hypothesis class \(\mathcal{H}\) from \(\{\mathcal{H}_i\}_{i=1}^{N^\text{train}}\);\\
\subasu\label{asu:setting2}Sample a hypothesis \(h\) uniformly at random from \(\mathcal{H}\);\\
\subasu\label{asu:setting3}Sample \(K\) inputs \(\{x^{(i)}\}_{i=1}^{K}\) i.i.d.\ from \(\mathrm{Uniform}(\mathcal{X})\);\\
\subasu\label{asu:setting4}Generate \(y^{(i)} = h(x^{(i)})\) for each \(i \in [K]\);\\
\subasu\label{asu:setting5}\(\Skmx = [x^{(1)},y^{(1)}, \ldots, x^{(k)}]\) for label prediction;\\
\subasu\label{asu:setting6}{\tiny \(\SK = [x^{(1)},y^{(1)}, \ldots, x^{(K)},y^{(K)}]\)} for hypothesis identification.\\
\end{asu}

\begin{asu}[Opt-T Generation]
\label{asu:optt}
Given hypothesis classes
\(\{\mathcal{H}_i\}_{i=1}^{N}\), input space \(\mathcal{X}\), and an integer \(K\):\\
\subasu Sample a hypothesis class \(\mathcal{H}\) from \(\{\mathcal{H}_i\}_{i=1}^{N^\text{test}}\);\\
\subasu Sample a hypothesis \(h\) uniformly randomly from \(\mathcal{H}\);\\
\subasu Construct \emph{optimal teaching set}\footnote{The optimal teaching set~\citep{zhu2015machine} is the smallest set of \((x,y)\) pairs that uniquely identifies \(h\) among all candidates in \(\mathcal{H}\).} of \(h\) with respect to \(\mathcal{H}\);\\
\subasu Randomly duplicate elements from this optimal teaching set until its size reaches \(K\). Assign indices \(1\) through \(K\) arbitrarily to these \((x,y)\) pairs;\\
\subasu {\tiny \(\SK = [x^{(1)},y^{(1)}, \ldots, x^{(K)},y^{(K)}]\)} for hypothesis identification.
\end{asu}

% Under i.i.d.\ Generation (Assumption~\ref{asu:iid}), the samples \(\{(x^{(i)}, y^{(i)})\}\) are drawn uniformly at random from \(\mathcal{X}\). Under Opt-T Generation (Assumption~\ref{asu:optt}), a minimal \emph{teaching set} is first identified, and then possibly duplicated.

% Meta Training Objective**:
% The large models are finally trained to minimize the cross entropy loss on the meta dataset $D_M$,$$\theta^* \leftarrow \min_\theta \mathbb{E}_m\left[\sum_{i=1}^m \ell(f_\theta(x^{(i)}_M), y^{(i)}_M) \right].$$

% Pretraining dataset generation process : $$\mathcal H \sim P_\mathcal H, h \sim U(\mathcal H), D=\{(x_i, y_i\}|_{i=1}^n \sim P_{\mathcal X, \mathcal Y}$$. 


% Testing dataset generation process:
% 1. $$\mathcal H \sim P'_\mathcal H, h \sim U(\mathcal H), D=\{(x_i, y_i\}|_{i=1}^n \sim P_{\mathcal X, \mathcal Y}$$. 
% 2.  $$\mathcal H \sim P'_\mathcal H, h \sim U(\mathcal H), D= OPT(h^* \mathcal H)$$. 

% *****************************

% We consider two types of input $i$ and output $o$ for the meta learning tasks in this paper.
% The first type has input consists of a finite hypothesis class $\mathcal{H}=\{h^{(1)},h^{(2)},\ldots\}$ with finite input space
% $
% \mathcal{X} = \{x_1, x_2, \ldots, x_{|\mathcal{X}|}\},
% $
% and binary output space
% $
% \mathcal{Y} = \{0,1\},
% $, a sequence $\Skx=(x^{(1)},y^{(1)},\ldots,x^{(k)},y^{(k)},x^{(k+1)})$ containing $k$ pairs of $(x,y)$ satisfying $y=h(x),h\in\mathcal{H}$ and an additional query token $x^{(k+1)}$, and the output is $y^{(k+1)}=f(x^{(k+1)})$.
% The second type has input consists of the finite hypothesis class $\mathcal{H}$ and a sequence $\SK= (x^{(1)},y^{(1)},\ldots,x^{(K)},y^{(K)})$ containing $K$ pairs of $(x,y)$ satisfying $y=h(x),h\in\mathcal{H}$ and the output is the underline $h$.
% Both tasks need to distinguish the underline hypothesis of given $(x,y)$ pairs and then predict the underline hypothesis or use it to predict the $y$ of given $x$, which are loosely related to the empirical risk minimization (ERM), aiming at finding the hypothesis minimizing the risk on a given dataset $\mathcal{D}$.
% As a summary, the first type has $i_{\text{I},k}=(\mathcal{H},\Skx), o_{\text{I},k}=y^{(k+1)}$, namely Type I; and the second type has $i_{\text{I},k}=(\mathcal{H},\SK), o_{\text{I},k}=h$, namely Type II.

% We consider multi-task training on Type I ($k\in\{0,1,\ldots,K-1\}$) and Type II, with hypothesis class $\mathcal{H}$ sampled from a predefined training hypothesis classes $\{\mathcal{H}^\text{train}_i\}_{i=1}^{N^\text{train}}$.
% During training, for Type I and II, we generate $\Skx$, $y^{(k+1)}$ and $\SK$ via $h\sim\text{Uniform}(\mathcal{H})$, and then $\{x^{(i)}\}\overset{\text{i.i.d.}}{\sim}\text{Uniform}(\mathcal{X})$ and $y^{i}=h(x^{(i+1)})$.
% During testing, we perform Type I evaluation on new hypothesis classes $\{\mathcal{H}^\text{test}_i\}_{i=1}^{N^\text{test}}$ with $\Skx$ generated the same way as training.
% We perform Type II evaluation on new hypothesis classes $\{\mathcal{H}^\text{test}_i\}_{i=1}^{N^\text{test}}$ as well, but with two different generation for $\SK$: (i) the same as training, denoted (i.i.d), (ii) generating $\SK$ via firstly identifying the optimal teaching set of $h\in\mathcal{H}$, \ie, the set of minimum number of $(x,y)$ pairs distinguish $h$ from $\mathcal{H}$ and duplicating samples in it until number $K$.

\subsection{Meta Training and Testing}
\paragraph{Training}
Given a set of training hypothesis classes $\{\mathcal{H}_i^\text{train}\}_{i=1}^{N^\text{train}}$, the meta-learner is trained in a multi-task setting to minimize the following loss:
\begin{align}
\label{eq:loss}
    % \theta^* \leftarrow \min_\theta \mathbb{E}\left[\mathcal{L}_1(f_\theta(i_{\text{II}}), o_{\text{II}}) + \sum_{k=1}^K \mathcal{L}_2(f_\theta(i_{\text{I},k}), o_{\text{I},k}) \right],
    \mathcal{L} = \mathcal{L}_1(f_\theta(i_{\text{II},K}), o_{\text{II},K}) + \sum_{k=1}^K \mathcal{L}_2(f_\theta(i_{\text{I},k}), o_{\text{I},k}),
\end{align}
where we generate $\mathcal{H}$, $h$, and $\SK$ following \hyperref[asu:iid]{i.i.d. Generation}, inherently defining $(i_{\text{II},K}, o_{\text{II},K})$ and $(i_{\text{I},k}, o_{\text{I},k})$.
The loss is indeed implemented with additional terms, and we will further clarify the loss in Sec.~\ref{subsec:framework}, Eq.~\ref{eq:lossTF}.

\paragraph{Testing}
Given a set of testing hypothesis classes $\{\mathcal{H}_i^\text{test}\}_{i=1}^{N^\text{test}}$, we consider two types of testing.
\begin{itemize}[topsep=0.1em, partopsep=0em, leftmargin=*]
    \item \textbf{Label prediction}: We generate $(i_{\text{I},k}, o_{\text{I},k})$ following \hyperref[asu:iid]{i.i.d. Generation}, and then measure whether the learner $f$ predict $f(i_{\text{I},k})$ correctly for each $k\in[K]$;
    \item \textbf{Hypothesis identification}: We generate $(i_{\text{II},K}, o_{\text{II},K})$ using \hyperref[asu:optt]{Opt-T Generation} and evaluate whether the learner $f$ predicts $f(i_{\text{II}})$ correctly.
    This setting tests whether the learner acquires the ability to identify the underlying hypothesis with minimal information.
\end{itemize}


% Pretraining dataset generation process : $$\mathcal H \sim P_\mathcal H, h \sim U(\mathcal H), D=\{(x_i, y_i\}|_{i=1}^n \sim P_{\mathcal X, \mathcal Y}$$. 


% Testing dataset generation process:
% 1. $$\mathcal H \sim P'_\mathcal H, h \sim U(\mathcal H), D=\{(x_i, y_i\}|_{i=1}^n \sim P_{\mathcal X, \mathcal Y}$$. 
% 2.  $$\mathcal H \sim P'_\mathcal H, h \sim U(\mathcal H), D= OPT(h^* \mathcal H)$$. 

\subsection{Four Types of Generalization}
\paragraph{Hypothesis universe $\mathcal{H}^{\text{uni}}$}
Given an input space 
$
    \mathcal{X} = \{x_1, x_2, \ldots, x_{|\mathcal{X}|}\}
$
and a binary output space
$
    \mathcal{Y} = \{0, 1\},
$
We define the hypothesis universe $\mathcal{H}^{\text{uni}}=\mathcal{Y}^{\mathcal{X}}$ as the collection of all possible binary classification hypotheses.
This universe contains $M=2^{|\mathcal{X}|}$ distinct hypotheses, serving as a hypothesis pool to constructing training and testing hypothesis classes.

\begin{figure}[h!]
    \centering
    %\vspace{-1.1cm}
    \includegraphics[width = 0.5\textwidth]{fig/generalization.pdf}
    %\vspace{-0.2cm}
    \caption{\textbf{Four types of generalization.}
    An illustration of the four types of generalization.}
    \label{fig:framework}
    %\vspace{-0.3cm}
\end{figure}

In meta-learning, the goal is to train a model that is able to rapidly adapt to new tasks.  
Testing on new tasks can be considered as measuring the OOD generalization.
Under our ICL-HCG framework, we consider four types of OOD generalizations.
First, we examine whether the learner generalizes to a new testing hypothesis class (the hypothesis class is unseen during training) that may or may not contain hypotheses seen during training, referred to as in-distribution (ID) and out-of-distribution (OOD) hypothesis class generalization, respectively.

\begin{definition}[ID Hypothesis Class Generalization]
\label{def:SpaceGeneralization}
Given $\mathcal{H}^{\mathrm{uni}}$ of size $M$, we enumerate all $C(M, m) = \frac{M!}{m!(M - m)!}$ distinct hypothesis classes, each containing $m$ 
hypotheses.
We then randomly \emph{subsample} these classes into disjoint training and testing subsets, ensuring that no testing hypothesis class appears in the training set (although individual hypotheses may overlap).
By training on randomly selected training hypothesis classes and evaluating on unseen testing hypothesis classes, we assess generalization to new hypothesis classes consisting of ID hypotheses.
\end{definition}

\begin{definition}[OOD Hypothesis Class Generalization]
\label{def:HypothesisGeneralization}
Given $\mathcal{H}^{\text{uni}}$ of size $M$, 
we partition it into disjoint training and testing subsets of sizes 
$M^\text{ID}$ and $M^\text{OOD}$, respectively. 
We then generate training hypothesis classes from $M^\text{ID}$ and testing hypothesis classes from $M^\text{OOD}$, each containing $m$ hypotheses. 
We train the learner on the training hypothesis classes and evaluate on the testing hypothesis classes. 
Because no testing hypothesis appears during training, 
this setup probes how well the learner generalizes
to entirely new hypotheses, \ie, OOD hypotheses.
\end{definition}

We then consider whether the learner can generalize to hypothesis classes of various sizes. Building on the concepts of ID and OOD hypothesis class generalization, we introduce size generalizations as follows.

\begin{definition}[ID Hypothesis Class Size Generalization]
\label{def:Space&SizeGeneralization}
Building on the setting of ID hypothesis class generalization, while maintaining non-identical training and testing hypothesis classes, we allow training hypothesis class to include various number of hypotheses $m\in\mathcal{M}\subsetneqq[L]$.
We investigate whether the learner can perform well on hypothesis classes with other sizes $m\in [L]\setminus\mathcal{M}$, where $[L]=\{1,2,\ldots,L\}$.
\end{definition}

\begin{definition}[OOD Hypothesis Class Size Generalization]
\label{def:Hypothesis&SizeGeneralization}
Based on the setting of OOD hypothesis class generalization, while maintaining non-identical training and testing hypotheses, we allow training hypothesis class to include various number of hypotheses $m\in\mathcal{M}\subsetneqq[L]$.
We investigate whether the learner can perform well on hypothesis classes with various sizes $m\in [L]\setminus\mathcal{M}$, where $[L]=\{1,2,\ldots,L\}$.
\end{definition}



\begin{figure}[h!]
    \centering
    %\vspace{-1.1cm}
    \includegraphics[width = 0.475\textwidth]{fig/framework_simplified.pdf}
    %\vspace{-0.2cm}
    \caption{\textbf{Learning ICL-HCG via Transformer.}
    We begin by sampling a subset from the hypothesis universe as the hypothesis class $\mathcal{H}$.
    Next, we encode the hypothesis class $\mathcal{H}$ and concatenate it with context query into a unified sequences of token.
    This sequences is fed into a Transformer model for training with next-token prediction, and testing for evaluating the accuracy on $y$ and hypothesis identification.
    (This figure is an simplified illustration. Please refer to Appendix~\ref{app:prefix} and Fig.~\ref{fig:frameworkfull} for the full details.)}
    \label{fig:framework}
    %\vspace{-0.3cm}
\end{figure}
\subsection{Learning ICL-HCG via Transformer}
\label{subsec:framework}
This section details how Transformer learns ICL-HCG.
As shown in Fig.~\ref{fig:framework},
the hypothesis class $\mathcal{H}$ is first converted to a hypothesis prefix with randomly assigned hypothesis indexes, then concatenated with context query representing sequence $\SK$ as a unified sequence $s$.
%We list the pseudo algorithm of training and testing in the Appendix Algorithm~\ref{alg:framework}, namely ``Meta Training and Testing of ICL-HCG.'' 

% During training, $\mathcal{D}$ is constructed by $(x,h(x))$ pairs via uniformly randomly sampling $x$ from $\mathcal{X}$; while
% during testing, we consider two sample strategies of $(x,h(x))$ pairs in the context query: (i) ``i.i.d.'': the same as training; (ii) ``Opt-T'': given a hypothesis class $\mathcal{H}$ and a chosen hypothesis $h\in\mathcal{H}$, an optimal teaching set\footnote{An optimal teaching set is a set with the minimum number of samples to identify a hypothesis from the hypothesis class.} is derived and duplicated to number $K$ to fit the context query size $K$.
% \begin{definition}[Hypothesis Table]
%     Given $\mathcal{A}$ and hypothesis class $\mathcal{H}$ with $m$ $h$s on the domain, the corresponding hypothesis table is constructed with size $m\times |\mathcal{A}|$ such that each row in the table represents a hypothesis, each column indicates an $a\in\mathcal{A}$, and each value in the table represents the value of $h_m(x_n)$ in row $m$ and column $n$.
% \end{definition}

\paragraph{Hypothesis prefix\footnote{Please refer to Appendix~\ref{app:prefix} for the full version.}}
Given a hypothesis class $\mathcal{H}=\{h_4,h_6,h_7\}$, its hypothesis prefix with size $L=4$ is constructed as shown in Fig.~\ref{fig:framework}.
Blank hypothesis is used to fill the hypothesis prefix when $|\mathcal{H}|<L$.
A randomly assigned hypothesis index token \hz is used to label each hypothesis.
Leveraging Fig.~\ref{fig:framework} for $L=4$, {\hz}'s are assigned from a pool \{``\textcolor[RGB]{0,176,80}{A}'',``\textcolor[RGB]{0,176,80}{B}'',``\textcolor[RGB]{0,176,80}{C}'',``\textcolor[RGB]{0,176,80}{D}''\} of size $L$ without replacement\footnote{We use variable $z$ to represent the hypothesis index, and create a set of $L$ hypothesis index tokens as a pool from which each hypothesis is randomly assigned a unique index without replacement.}.

\paragraph{Context query}
Given an ICL sequence $\SK$, we append a query token ``\textcolor[RGB]{192,79,21}{\textgreater}'' after it to trigger trigger the prediction of the hypothesis index ss shown in Fig.~\ref{fig:framework}.
We name the combination of $\SK$ and ``\textcolor[RGB]{192,79,21}{\textgreater}'' as context query.

The Transformer predicts the $y$ tokens in the context query based on previous tokens and the index \hz of the underlying hypothesis based on all tokens in the sequence.
The training loss in Eq.~\ref{eq:loss} is further extended to all the tokens in the sequence and implemented as below:
\begin{align}
\label{eq:lossTF}
    \mathcal{L} = - \sum_{t=1}^{T} \log P_\theta(s_i \mid s_{<i}).
\end{align}
We summarize the pipeline in the Appendix~\ref{app:alg} Algorithm~\ref{alg:framework}.
%\input{tex_main/3.2_Algo}


%\input{tex_main/3.1_ERM_and_PAC_Learning}

% In order to have a set of hypotheses to construct $\mathcal{H}$, given $\mathcal{X}$, assuming $|\mathcal{Y}|=2$ (binary classification), we can generate $2^{|\mathcal{X}|}$ hypotheses (all possible hypotheses with binary labels), then uniformly randomly sample $m$ hypotheses from the set to construct a hypothesis class.
% Each space generalization with $m$ hypotheses can be further converted to $P(L,m) = \frac{L!}{(L - m)!}$ hypothesis prefixes.
% Then, $(x,y)$ pairs generated from a hypothesis $h$ sampled from the hypothesis class $\mathcal{H}$ are provided as dataset of context query for the Transformer to identify a correct hypothesis indexed \hz and predict the index.

% With this framework, we are interested in whether a trained Transformer is able to generalized to perform ERM on new hypothesis classes.
% Starting with introducing the hypothesis universe, we further deliver the four generalization cases considered in our experiments.

