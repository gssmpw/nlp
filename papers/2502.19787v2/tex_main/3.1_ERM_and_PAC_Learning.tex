\subsection{Empirical Risk Minimization for Binary Classification (come later, what is the data ERM for a fix, fix hypothesis)}
\label{sec:ERM}
In this work, we consider the binary classification problem where the input space is finite. Formally, let the input space be defined as
$
\mathcal{X} = \{x_1, x_2, \ldots, x_{|\mathcal{X}|}\}
$,
and the label space as
$
\mathcal{Y} = \{0, 1\}
$.
The learning task is characterized by a hypothesis space
$
\mathcal{H} \subseteq \mathcal{Y}^{\mathcal{X}}
$,
where each hypothesis $ h \in \mathcal{H} $ is a deterministic function
$
h: \mathcal{X} \rightarrow \mathcal{Y}
$.
A realizable instance of the binary classification problem is specified by the tuple
$
(\mathcal{X}, \mathcal{Y}, P, h^*)
$,
where $P$ is a probability distribution over the input space $\mathcal{X}$, and $h^*:\mathcal{X} \rightarrow \mathcal{Y}$ is the target hypothesis.

During learning, a learner $A$ receives a training dataset $\mathcal{D}=\{(x^{(i)}, y^{(i)})\}_{i=1}^K$ and it is tasked to find a hypothesis that produces least generalization risk $R(A(\mathcal{D}))$ on future test sample drawn from $P$ and $h^*$.
Empirical risk minimization (ERM) is one of the most popular learning algorithm. It learns by minimizing the empirical risk on the training dataset $\mathcal D$ with respect to a loss function $l:\mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb R^+$ and is given as,
$$
\hat h_\mathcal{D} = \text{ERM}(\mathcal{D},\mathcal{H}) \leftarrow \min_{h \in \mathcal{H}} \sum_{i=1}^K l(h(x^{(i)}), y^{(i)}).
$$
% Once learning is complete, the learner uses learnt hypothesis $\hat h_D$ to make prediction on samples from $P, h^*$ thereby suffering a risk of, $$R(\hat h_D) \leftarrow \mathbb E_{(x, y) \sim P, h^*}[l(\hat h_D(x), y)].$$
In this paper, we focus on $0/1$ risk, $$l(\hat{y},y)=
\begin{cases}
    1, & \text{if } \hat{y}=y\\
    0, & \text{if } \hat{y}\neq y
\end{cases}.
$$
\begin{remark}
ERM focuses mainly on sample complexity, that is, determining the minimum number of samples required to identify a hypothesis $\hat{h}$ with a risk below a specified threshold.
Differently, in this paper, we explore whether Transformer models can accurately pinpoint the exact hypothesis when provided with sufficient number of samples.
\end{remark}

% In theory, Probably Approximately Correct(PAC) learning completely characterizes the sample complexity of learning. It states that for any learning instance and $(\epsilon, \delta) \in (0,1)^2$ if $n\geq O(\frac{1}{\epsilon}(d(\mathcal H)+\log(\frac{1}{\delta})))$, then,  $$\text{w.p. $\geq 1-\delta$}, \qquad R(\hat h_D) \leq \epsilon.$$
% where $d(\mathcal H)$ is the VC dimension of hypothesis class $\mathcal H$ which is a measure of its complexity. Therefore, to learn the target hypothesis up to an error $\epsilon$, computing the ERM on an i.i.d. sample of size $O(\frac{d}{\epsilon})$ is sufficient.


%%% motivating incontext learning with finite hypothesis class

% In recent literature, several works {cite} have shown impressive capability of transformers to in-context learn ERM on a dataset $D$ at inference time which is known as In-context Learning(ICL). However, most of the works have focused on ICL learning settings where hypothesis class is defined implicitly by a linear $\mathbb R^d$ space. This begs the question of whether transformers can do ERM in more explicit learning settings where hypothesis class are specified as input to the model. Towards this end we seek to answer the following question:

% \textbf{Can a transformers learn to do in-context learning conditioned on finite/tabular hypothesis classes?}

% A couple of recent works have tried to address this problem by conditioning the hypothesis class on a noisy version of the target hypothesis {cite}. Contrary to this, a finite hypothesis class conditions the universal hypothesis space $\mathcal{A}^\mathcal{Y}$ by specifying a subset of hypothesis $\mathcal H$ that contains a the target hypothesis to solve the task instance. In real world learning scenario, this can be viewed   The explicit conditioning on finite hypothesis class also provide an avenue to test the generalization capability of ICL to generalize to different size of hypothesis tables thereby helping us to understand ERM capability of transformers in a more controlled setup. 

%%% Ziqian's previous writeup

% \subsection{Empirical Risk Minimization (ERM)}
% Consider a training dataset $\{(x_i, y_i)\}_{i=1}^n$, where each $x_i \in \mathcal{A}$ is a feature vector and $y_i \in \mathcal{Y}$ is the corresponding label or target value. Let $\mathcal{H}$ be a hypothesis class of functions $h: \mathcal{A} \to \mathcal{Y}$, and let $L:\mathcal{Y}\times\mathcal{Y}\to\mathbb{R}_{\geq 0}$ be a loss function that measures the discrepancy between the predicted value $h(x_i)$ and the true value $y_i$.

% The \emph{empirical risk} of a hypothesis $h \in \mathcal{H}$ is defined as:
% \[
% \hat{R}_n(h) = \frac{1}{n} \sum_{i=1}^n L(y_i, h(x_i)).
% \]

% The \emph{Empirical Risk Minimization} principle seeks a hypothesis $\hat{h} \in \mathcal{H}$ that minimizes the empirical risk:
% \[
% \hat{h} = \arg\min_{h \in \mathcal{H}} \hat{R}_n(h).
% \]

