\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures-src/method.pdf}
    \caption{Given a prompt, SliderSpace first generates images and extracts the CLIP features. We then compute the spectral decompostion of the CLIP features and align the each slider with extracted principle components. Each slider is therefore trained to represent a unique semantic direction that are relevant in the diffusion model's knowledge of the prompt.}
    \label{fig:method}
\end{figure*}


% \wu{This part is not very clear for me. Maybe we can describe it in sequence. First, generate a large set of images condition on the text prompt. Second, map these image to clip image space, represent main image variance direction through PCA in clip image space. Third, we want to a way to generate image variance along each clip image direction, so we train a lora adaptor to  }