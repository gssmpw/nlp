% \section{Conclusion}
% We present SliderSpace, a framework for automatically decomposing the visual capabilities of diffusion models into controllable and human-understandable directions. Through extensive experiments on state-of-the-art diffusion models, we demonstrate SliderSpace's effectiveness across three applications: First, we show how SliderSpace can decompose high-level concepts into diverse and expressive components, revealing the natural axes of variation in the model's understanding. Second, we explore artistic style capabilities, where SliderSpace discovers directions that more closely match the distribution of manually curated artist lists while being judged more useful by human evaluators. Finally, we show how SliderSpace can help with mode collapse commonly observed in distilled diffusion models, restoring diversity while maintaining generation speed.

% Beyond providing practical visual control, SliderSpace opens new avenues for understanding and utilizing the latent capabilities of diffusion models. By mapping these models' visual potential into intuitive, composable directions, we take a step toward making their creative possibilities more accessible and interpretable to users.

\section{Conclusion}
SliderSpace is a simple framework that automatically decomposes diffusion models' capabilities into semantically meaningful and controllable directions. By leveraging spectral decomposition in semantic space combined with low-rank adaptation, our method enables systematic exploration of a model's latent creative space without requiring manual attribute specification. Through extensive experiments, we demonstrated SliderSpace's effectiveness across three key applications. First, our concept decomposition revealed interpretable variations within the model's knowledge representation, enabling fine-grained control while maintaining semantic consistency. Second, our exploration of artistic capabilities showed that SliderSpace can discover directions matching or exceeding the diversity of manually curated artist lists, while being rated more useful by human evaluators. Finally, we demonstrate how SliderSpace can help address mode collapse in distilled diffusion models, restoring diversity while preserving computational efficiency.

The ability of SliderSpace to uncover interpretable directions suggests that diffusion models may develop structured internal representations of visual concepts during training, without explicit supervision. By mapping these models' vast creative potential into intuitive, composable directions, our work takes a step toward making their capabilities more transparent and accessible.