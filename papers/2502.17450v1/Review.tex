Review #109A
====================================================

Overall merit
-------------
3. Weak accept

Reviewer expertise
------------------
3. Knowledgeable

Paper summary
-------------
This paper presents an empirical study aimed at investigating the influence of two hyperparameters of GPT-4o (temperature and top-p) on the accuracy of the model in the code generation task. The authors collect a sample of 548 Java methods with documentation and tests and explore the use of 5 values of temperature and three values of top-p for each of them. They also repeat each generation several times to account for non-determinism. The results suggest that low-temperature values should be avoided since they result in lower model accuracy. Also, they show that top-p appears to be a more impacting parameter than temperature. Finally, the authors conduct additional analyses on the determinism of the tested configurations and the impact of method complexity and length on the results.

Evaluation summary
------------------
# Strengths
+ Novel and important contribution %%OKK
+ Solid methodology %%OKK
+ Well-written paper with effective visualizations %%OKK

# Weaknesses
- Asymmetrical design: Top-p is studied with the best Temperature, but not the other way around; %%OKK
- Odd results for top-p  %%OKK
- Unclear relevance to ICPC %%OKK

Comments for authors
--------------------
# Overall Evaluation
I enjoyed reading this paper. It is well-written and presents a novel and relevant study. I also appreciated the methodological rigor of the paper in its design. On the other hand, I have a couple of concerns: one regards the combination of the two hyperparameters, and the other (the most important one) regards the results of RQ3 for top-p. I would expect determinism with top-p = 0, but apparently it lacks. Finally, the relevance to ICPC is unclear.

# Detailed Comments
The proposed contribution is novel, to the best of my knowledge. I also find it significant: The impact on future research and practitioners is clear, and the results are directly actionable. On the other hand, I do not understand how this paper is relevant to program comprehension. The authors should make this clear. %%todo


As previously mentioned, I appreciated the general rigor of the methodology used for (i) sampling the methods and (ii) checking the effectiveness of the model in generating code. The terminology used is also appropriate: The use of "plausible" instead of "correct" might seem a minor detail, but indicates the attention of the authors in correctly communicating their results. Speaking of which, I found the paper very well-written and clear. %%GRAZIE

On the other hand, I have some important concerns regarding a design choice and a result.
First, the authors studied (in RQ1) the best value for Temperature by using the default top-p value (0.95). Then (RQ2), they studied the best value for top-p by using the best Temperature value found in RQ1. This important choice is not sufficiently motivated. The two hyperparameters might strongly impact each other. Thus, the results obtained in terms of Temperature might not be generalizable to other values of top-p (and vice versa). Since the authors show in RQ2 that 0.95 is the worst value for top-p, a replication of RQ1 with the best value of top-p might be in order. I suspect, however, that running this replication would not be useful since (if my understanding is correct) top-p=0 implies determinism, which would imply that the next token chosen is the same regardless of the Temperature.

Related to this last consideration, my second (and biggest) concern regards the results. Again, if top-p = 0, the set of tokens from which the next one will be chosen is always constituted by a single element - the most likely token. Thus, I would expect perfect determinism with top-p = 0. However, this is not true: Fig. 8 (RQ3) shows that repeating the generation increases the likelihood of getting a plausible generation (i.e., the generation is not deterministic). Maybe I am missing something here. The authors should carefully explain why this happens. %TODO, da chiarire

Questions to the authors
------------------------
1. Why are the generations done with top-p = 0 non-deterministic?
2. What is the relevance of this work for ICPC? %%OKK


* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *


Review #109B
================================================
Overall merit
-------------
3. Weak accept

Reviewer expertise
------------------
3. Knowledgeable

Paper summary
-------------
The paper studies the impact of making different configurations when using an LLM such as ChatGPT to generate code. Using 548 code java, authors systematically test different configurations, showing several results.

Evaluation summary
------------------
### Strengths

- Of interest to the ICPC community. %OKK
- Strong novelty and very relevant %OKK

### Weaknesses

- presentation concerns (too many results).
- lack of discussion.

Comments for authors
--------------------
Overall the paper addresses an interesting and very relevant question now asked in the era of generative AI, regarding the non-deterministic nature of the models. It would make great discussion at ICPC. %%OKKK


**Soundness**

I think the paper's approach to addressing non-deterministic models in generative AI is sound. However, temperature as a measure of model behavior raises concerns about confirmation bias, which might be deemed to be trivial, with reviewers saying so what.  In my opinion, more detail is needed on how the questions were answered and what specific aspects of non-determinism were explored. Author miss the opportunity by answering the RQs and having a discussion section. Including this will make the paper stronger. %todo

**Relevance**

The paper's focus on non-deterministic models in generative AI is highly relevant in today's landscape, where tools like ChatGPT and Copilot are increasingly popular. %%OKKK

**Novelty** 

The study contributes significantly to our understanding of non-deterministic models in generative AI, which is a relatively new and underexplored area. The paper's findings offer valuable insights into the challenges and opportunities presented by these models, and their research has the potential to shape the future development of AI systems. %% OKKK

**Presentation**

The paper is overly reliant on quantitative results, which makes it difficult to discern meaningful insights into why certain phenomena were observed. More discussion of the theoretical underpinnings and implications of the findings would have strengthened the presentation and provided a clearer understanding of the research's significance. %TODO

**Replicability**

I was disappointed to find that a replication package for this study is not available, which makes it difficult to verify the findings or build upon them.  Maybe I missed something? %%OKKK

Questions to the authors
------------------------
1. Can you answer each research question and also provide insights on how temperature could be utilized by researchers, developers with examples?
2. How can we interpret many of the quantitative results?


* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *


Review #109C %% OKK
=============================================
Overall merit
-------------
2. Weak reject

Reviewer expertise
------------------
4. Expert

Paper summary
-------------
The paper studies the impact of different configurations of LLMs on code generation, generating correct, plausible, and incorrect code implementation. The configurations include temperatures, top-p, and also the number of repetitions needed to reduce the non-determinism.

Evaluation summary
------------------
Strength
+ Comprehensive study on different configurations. %% OKK
+ The paper is easy to understand. %% OKK

Weakness
-  The impact of different configurations on code generation has been fairly explored in many prior works on code generation. So this work has limited contribution and novelty. %% OKK
- Only one LLM included. %% OKKK

Comments for authors
--------------------
Different configurations have impacts on code generation performance and this has been explored by prior works as ablation studies. It is well known that hyperparameters would have impact on the LLM code generation, and works on code generation are expected to perform ablation studies in their papers. Although this paper includes a comprehensive experiment, I do not see adequate novelty and contributions made by this paper. %% OKKKK