\section{Related work}
\paragraph{Shape from X} The previous works in the ``Shape from X'' series primarily focus on high-precision reconstruction of existing objects based on known specific visual data, such as RGB images ____, depth ____ and normals ____. 

Constructing a single fixed object with multiple visual interpretations is a widely explored topic within the "Shape from X" domain. Researchers have explored a variety of methods to achieve diverse visual perceptions, leveraging factors such as viewing distance ____, figure-ground organization ____, illumination from different directions ____, light reflections ____, viewing angles ____, and shadow casting on external planar surfaces ____. 
% In computational art, the essential reasons for rich visual perceptions are diverse, such as optical properties ____, application of optical materials____, perceptual optimization of image content____, and optimization of structure____. 
However, the goal of the above works is to produce different 2D information perceptions based on an object, whether it is a contour ____, a projection ____, or a picture ____. Our work differs in that it provides direct 3D information perception, allowing the characteristics of 3D objects to be experienced firsthand. To the best of our knowledge, no work has yet explored creating multiple 3D interpretations of a single object. In addition, we leverage semantics as a substitute for traditional inputs, similar to ____ and ____, significantly expanding the creative space. 

\paragraph{3D Data Representations.} The expression of 3D data is a core topic in computer graphics and vision. Besides traditional point cloud and mesh representations, neural implicit functions____ and 3D Gaussian Splatting (3DGS)____ have shown great advantages in various tasks recently. 
Mildenhall et al. proposed Neural Radiance Fields (NeRF) that represent a scene with a neural implicit function guided by neural rendering____. This method has been widely applied to multi-view reconstruction ____, sparse reconstruction ____, and generation tasks ____, thanks to its capability in representing scenes with rich details. However, its optimization process can be time-consuming and computationally intensive. Recent work on speeding up NeRF have mainly focused on improving rendering  ____ and reconstruction speeds ____, with only a few works applied to 3D generation ____.

At present, 3DGS ____, as a new 3D data expression, brings new possibilities for rendering ____ and reconstruction problems ____ due to the fast optimization brought by flexible model design and efficient differentiable rendering framework. Furthermore, Tang et al. incorporated a generative model into 3DGS for 3D generation tasks, enabling generation of textured meshes ____. However, the geometry generated by 3DGS often suffers from significant detail loss, excessive surface undulations, and suboptimal mesh quality. We integrate these two promising 3D representations in our pipeline to produce innovative and manufacturable geometries.


\paragraph{Diffusion Models in Vision.} In recent years, generative models have gained widespread attention in computer vision and graphics. They have achieved remarkable success in 2D generation for a wide range of tasks, including generating detailed images from rough ones ____ and prompts ____, and creating videos from images ____, estimating depths, normals ____ and viewpoints ____.
On the other hand, 3D generation presents unique challenges, due to the limited availability of large, high-quality 3D datasets____. Recently, most 3D generation methods ____ utilized 2D information as supervision to guide 3D generation, using neural implicit function as the primary representation of 3D data. DreamFields ____ pioneered the use of diffusion models for semantic-based 3D generation. DreamFussion____ introduced the score distillation sampling (SDS) loss, which leverages semantic information and 2D rendering results, and this approach has since been widely adopted. DreamGaussian____ used 3DGS to represent 3D data, significantly improving generation speed. However, as these methods inherently rely on supervision from 2D rendering results, they often face challenges with multi-view inconsistency. While many existing works aim to mitigate such inconsistencies ____, our approach leverages such potential inconsistency to generate creative objects with multiple visual interpretations. Moreover, researchers incorporate various priors (normal, depth, etc.) into 3D generation tasks to enhance the realism of models. SweetDreamer____ and RichDreamer ____~integrate canonical coordinate maps and normal-depth priors into the loss function, respectively. Meanwhile, Wonder3D ____ and CRM ____ directly utilize these priors to construct corresponding meshes.