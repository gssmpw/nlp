\section{Related Work}
\subsection{Deep Learning for Segmentation in US B-mode Imaging}
AI techniques in US B-mode imaging are typically centred around DL model development within a supervised learning framework, often tailored to a specific clinical application. SOTA approaches for segmentation in US imaging have developed from pure convolutional approaches using CNNs. CNN-based approaches often use variants of U-Net~\cite{ronneberger_u-net_2015}. Shareef et al.~\cite{shareef_estan_2022} introduced the ESTAN network aimed at improving small breast tumour segmentation. ESTAN uses two encoder branches with different kernel shapes and sizes and three skip connections to improve multi-scale contextual information. Banerjee et al.~\cite{banerjee_ultrasound_2022} proposed SIU-Net for segmenting lumbar and thoracic bony features using their proposed inception block. This block uses multiple filter sizes with improved computational efficiency through combined $1\times1$ and $3\times3$ convolutions. They also combined features of multiple scales through dense skip connections. Meshram et al.~\cite{meshram_deep_2020} improved carotid plaque segmentation using dilated convolutional layers in a U-Net model and Qiao et al.~\cite{d_qiao_dilated_2020} used dilated convolution and squeeze excitation blocks on skip connections to improve fetal skull segmentation.

With advancements in transformer-based architectures, the latest SOTA approaches for US segmentation combine transformer and convolutional methods leveraging complementary global and local feature information, respectively. Zhang et al.~\cite{zhang_hau-net_2024} used a CNN-Transformer combination in a U-Net framework. The authors used a ResNet backbone and a novel local-global transformer block nested into skip connections to capture long-range feature information efficiently for breast US segmentation. Jiang et al.~\cite{jiang_hybrid_2023} also explored a CNN-Transformer U-Net model to improve US segmentation of the breast, thyroid and left ventricle. The authors used a coordinate residual block to extract local feature information with absolute position information and enhanced channel self-attention blocks to extract global features. Wu et al.~\cite{wu_cross-image_2023} introduced a BUSSeg model for breast US segmentation by using a parallel bi-encoder in a U-Net style architecture consisting of a transformer and CNN blocks. In addition, the authors use a cross-image dependency module to capture cross-image long-range dependencies utilising feature memory banks. 
% All these approaches were trained on 100\% training samples, i.e., requiring larger labelled training data. Also, they often require higher computational training and inference time due to the combined transformer and convolutional approach.
% This module provides additional contextual information from stored image features in the memory bank and used to augment current image features through feature aggregation, in turn improving segmentation performance. 


% A novel cross-attention block was used to capture multi-scale features from different layers.A spatial and channel-based attention module was also used in parallel to strengthen skip connections.
% Delete--
% This approach provides an extension to CNN-Transformer architectures by combining intra and inter-image feature representations. This additional contextual information is valuable for improving segmentation performance. --
%
These supervised learning models have demonstrated promising segmentation results across various US clinical domains. However, due to the limited availability of US data, self-supervised learning (SSL) offers a more robust approach, enabling high segmentation performance while minimizing performance degradation when applied to out-of-distribution data. Also, combined transformer and convolutional approaches~\cite{wu_cross-image_2023,jiang_hybrid_2023,zhang_hau-net_2024}  often require higher computational training and inference time that hinders clinical translation, whereas SSL techniques are independent of the model choice and can boost performance significantly.

\subsection{Self-Supervised Learning}
Self-supervised learning often follows a two-stage training strategy. Firstly, pretext learning is focused on learning representations from unlabelled data. Secondly, these learnt weights are then used in the fine-tuning downstream supervised learning tasks, such as segmentation. The objective is to learn semantically meaningful feature representations without requiring labels, thereby improving the performance of a downstream task on limited labelled datasets. Since the labels are not required during the pretext task, a large number of available unlabelled samples can be used which makes the SSL approach more generalisable to out-of-distribution samples. 

The pretext learning task is critical for developing meaningful representations of the target domain in SSL~\cite{vanberlo_survey_2024}. Often a combination of image augmentation benefits contrastive SSL pretext learning, with this unsupervised learning stage also benefiting from stronger augmentation than supervised learning~\cite{chen_simple_2020}. For example, geometric rotation transformation was applied to an image in~\cite{gidaris_unsupervised_2018} while the Jigsaw pretext task with a set of shuffled patches within an image was used in~\cite{leibe_unsupervised_2016}. The Jigsaw approach provides a strong geometric transformation to an image, a common strategy used in contrastive SSL~\cite{z_xu_ssl-cpcd_2024, xie_identification_2024, zhang_twin_2021}. The traditional Jigsaw approach learns a representation that is covariant to the perturbation, the pretext-invariant representation learning (PIRL)~\cite{misra_self-supervised_2020} approach adopts the Jigsaw task in an invariant learning strategy. 
% Our work builds upon the PIRL approach.

Several SSL approaches have been established involving generative, contrastive and generative-contrastive techniques applied to medical image analysis~\cite{liu_self-supervised_2023}. The pretext learning strategy differs for each approach with a generative task focused on reconstruction, for example, recovering masked areas of an image~\cite{xie_simmim_2022}. However, the contrastive approach aims to discriminate similar and dissimilar samples~\cite {misra_self-supervised_2020}. 

Contrastive approaches are often preferred to generative approaches for downstream discriminative applications~\cite{liu_self-supervised_2023}. By avoiding low-level abstraction objectives, such as pixel-level reconstruction, contrastive learning tends to be more lightweight, as it does not require a decoder during pretext learning~\cite{liu_self-supervised_2023}. 

Widely known contrastive learning approaches include MoCo v3~\cite{he_momentum_2020}, PIRL~\cite{misra_self-supervised_2020} and BYOL~\cite{grill_bootstrap_2020}. MoCo v3 was introduced using a momentum encoder. Using a dynamic dictionary and a moving average encoder allows key feature representations to be decoupled from the minibatch size resulting in a large consistent dictionary, containing many negative samples~\cite{he_momentum_2020}. BYOL was introduced using two interacting neural networks to learn from each other. The online network predicts the target network representation, both using the same image, but under different augmented views~\cite{grill_bootstrap_2020}. PIRL introduced a
method to learn invariant representations rather than covariant representations to the pretext task used~\cite{misra_self-supervised_2020}. These approaches demonstrate improved performance in self-supervised learning. 

% \subsection{Pretext Tasks}
% Pretext learning is critical for developing meaningful representations of the target domain \cite{vanberlo_survey_2024}. Initial approaches involve applying a stochastic transformation with the model tasked with predicting or undoing the transformation. For instance, using a ConvNet to predict the geometric rotation transformation applied to an image \cite{gidaris_unsupervised_2018} or the Jigsaw pretext task which trains a model to determine the relative position of a set of shuffled patches within an image \cite{leibe_unsupervised_2016}. Often a combination of image augmentations/transformations benefits contrastive SSL pretext learning, with this unsupervised learning stage also benefiting from stronger augmentation than supervised learning \cite{chen_simple_2020}. The Jigsaw approach provides a strong geometric transformation to an image, a common strategy used in contrastive SSL \cite{z_xu_ssl-cpcd_2024, xie_identification_2024, zhang_twin_2021}. The traditional Jigsaw approach learns a representation that is covariant to the perturbation, the PIRL approach adopts the Jigsaw task in an invariant learning strategy. Our work builds upon the PIRL approach. In this approach a random area of the images is cropped, divided into 3x3 patches, randomly shuffled and then a photometric data augmentation is applied randomly to each patch \cite{misra_self-supervised_2020}. This provides a strong augmentation to the image assisting with learning meaningful representations of the image in a contrastive learning regime.

\subsection{Metric Learning}
Metric learning aims to learn a function to effectively compare similarities between data samples. Siamese networks~\cite{koch_siamese_2015} was used to learn a similarity function to map input pairs into a shared embedding space. The network was trained to bring similar pairs together and push dissimilar pairs apart using a linear distance metric, e.g., Euclidean distance. Prototypical networks~\cite{snell_prototypical_2017} learn an embedding that is a non-linear transformation of the input data, mapping it into an embedding space where the nearest neighbour classification is effective. The classification is based on the proximity of query instances to class prototypes in this learned embedding space. Relation Networks~\cite{f_sung_learning_2018} use an embedding module to obtain sample feature embeddings and a relation module to compute sample pair similarity. Unlike~\cite{koch_siamese_2015, snell_prototypical_2017}, the addition of the relation modules enables learning of similarity metrics in a data-driven way. 
% This module is composed of two convolutional blocks and two fully connected layers. 
 % The aim of this is to compute a relation score between 0 and 1 from two feature embeddings. Although these approaches are more commonly used in few-shot or zero-shot learning scenarios, contrastive SSL can benefit from metric learning techniques.  Traditional contrastive SSL approaches utilise pre-specified distance-based metrics, e.g., cosine similarity. All learning in this approach occurs in the feature embeddings to enable the distance between positive sample pairs to be minimised and negative sample pairs to be maximised. However, this approach assumes the features are comparable element-wise with the most relevant information to distinguish feature embeddings lying within their angular relationship. Metric learning techniques like Relation Networks provide a more generalized solution in determining similarity. We take inspiration from relation networks to measure similarity in contrastive SSL through using a relation network, instead of a fixed linear metric. Complementing a network focused on feature learning and a relation network to measure sample similarity, we believe can improve overall representations learnt in contrastive SSL. 

% \textbf{maybe add older methods e.g., matching networks }
% Why you are doing what you are doing? - connect with above literature that you mentioned - how your approahc is different and how it benefits US segmentation in breast.

% Contrastive learning emphasizes learning robust and discriminative representations by contrasting positive and negative pairs. This is particularly useful in medical image analysis where the goal is often to distinguish between subtle differences in pathological and normal cases.

% Generative Complexity: Generative approaches, like GANs or VAEs, aim to model the entire data distribution, which can be computationally intensive and challenging in medical imaging due to the high dimensionality and complexity of the data.
% For US image segmentation, we choose to use contrastive learning as a pretext task because of its ability to learn robust and discriminative representation with data-specific transformations~\cite{liu_self-supervised_2023}. The contrastive approach exploits the similarity between the target sample and positive sample pairs while penalising the difference between the target sample and negative sample pairs, does not require complex network architecture and is suitable to capture subtle differences in pathological and normal. 

Our work focuses on contrastive learning because it excels in discriminative downstream applications, is more lightweight during pretext learning, and favours high-level abstract feature learning compared to generative approaches \cite{liu_self-supervised_2023}. With contrastive learning dependent upon data transformations in the pretext learning task, we utilise a combination of data-specific augmentations, shown to improve SSL feature learning \cite{chen_simple_2020}. In this work, we explore novel combined spatial and frequency-based augmentation strategies aimed at US images to improve representation learning in US data. Furthermore, inspired by relation networks~\cite{f_sung_learning_2018} as a metric learning technique, we utilise relation networks and propose a novel relation contrastive loss (RCL) in a contrastive learning setting. To further guide representation learning, 
we propose to combine RCL with perceptual loss to weight feature learning with high-level features tackling high noise and poor contrast of US images. 
%
% With US images susceptible to high noise and poor contrast, low level pixel information is less informative, compared to higher level structural information within the image. Our improvements within a contrastive learning framework are targeted to maximize learning meaningful feature representations for US B-mode images.
% Therefore, enabling sample similarity to be determined in a data-driven manner rather than using a fixed distance-based similarity metric, like cosine similarity, commonly used in contrastive learning. 
%
%
% We propose a novel self-supervised framework aimed at improved segmentation performance in US B-mode image data.