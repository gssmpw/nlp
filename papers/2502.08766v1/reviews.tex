MOBILESoft 2025 Paper #31 Reviews and Comments
===========================================================================
Paper #31 Unlocking Mental Health: Exploring College Students' Well-being
through Smartphone Behaviors


Review #31D
===========================================================================

Overall merit
-------------
3. Weak accept

Reviewer expertise
------------------
2. Some familiarity

Detailed comments for authors
-----------------------------
Meta-review:

This paper is marked as conditionally acceptance. The reviewers find the topic of the paper interesting and highly relevant although they lack the background in psychology to fully judge the medical aspects of the paper. The paper can be a good addition to the program of the conference which is otherwise more technology-centric.

Still, the paper suffers from a set of shortcomings that need to be addressed in a revision before a final decision on the paper can be made:

1. Check the numbers in Table 1. It is highly unlikely that the numbers of unlock frequency and unlock duration are exactly the same

2. Discuss correlation vs. causality. Can we conclude - based on data - that the smartphone use causes the described differences in mental health or can we only say that they occur together without knowing the actual cause? It's ok is the paper only reports on correlation, but this needs to become clear.

3. Address the individual concerns about data presentation and consistency from the reviews

4. Since this is a novel ideas paper, the writing should put more focus on novelty, both in terms of research approach and study methodology. Justifications for why the research questions are studied and what impact the findings of this study can have should be clearly described.


Review #31A
===========================================================================

Overall merit
-------------
1. Reject

Reviewer expertise
------------------
2. Some familiarity

Paper summary
-------------
The paper analyzes how smartphone use (measured based on unlock counts and duration) affects the mental well-being of college students in the US based on longitudinal data collected over 4 years. The data is split to offer insights into gender-specific or location-specific correlations.

Detailed comments for authors
-----------------------------
Pros
=====

a) The topic is highly relevant and there hasbeen significant debate on how and whether children, teenagers and young adults should use smarthpones. Having more data can help guide parental decisions and school guidelines.

b) Having the data and the processing pipeline publicly available may help other researchers.


Cons
=====

a) I am not sure that MobileSoft is the correct venue for such a paper. It falls into the context of mobile applications, but metal health professional might better appreciate the work. While I think the MobileSoft audience finds the results interesting on a personal level, I have serious doubts that we have the expertise to properly judge the medical part of the paper and thus the conclusions drawn.

b) Section 1: While I understand that collecting such datasets is super hard, I wonder how generalizable the data from a single place (Dartmouth) is.

c) Section 1: What was the reason for only considering device unlocking? There are many potential factors that come to mind, e.g., with Australia now banning social networks for children under 16. Maybe there is a difference between using a social media app and, e.g., using your phone as a calculator while studying.

d) Section 1: "PHQ4 scores are grouped into four categories, with the lowest-score group serving as the baseline." This should be explained for readers outside the field of mental health. We later learn that lower scores correspond to better mental health, but this is not clear in Section 1. I was first wondering whether the worst group serves as the baseline.

Further, if the best group is already the baseline, does this study design exclude the possibility that smartphone use may improve the participants' mental health?

e) Section 2: The research statement may lead to correlation being mistaken for causility in RQ3. Smartphone use and a certain level of mental health may have the same external root cause. That doesn't mean one influences the other.

f) Section 2: If the surveys for the EMA study are delivered through an app, does this imply that the minimum unlock count in Table 1 merely reflects the parfticipants unlocking their phone to fill out the survey, i.e., the entire phone use of these "min" participants being driven by their participation in the study?

g) Table 1: The authors should also provide the median. With the data provided, it remains unclear whether (case 1) many users show a similar near-average pattern of smartphone use orf whether (case 2) there is divide between participants using their phones rarely and ones using them excessively.

h) Table 1: What are the units of the numbers? Is the unlock duration measured in seconds? In minutes?

i) Table 1: The data looks strange. Why are the "unlock number" and "unlock duration" rows completely identical? With so many participants and such a long duration of the study, this seems to be an odd coincidence. The authors should double-check their data.

j) Section 2: "showing consistency across Unlock Number and Unlock Duration, which highlights the dataset’s quality". I don't understand this argument. The numbers show that the unlock number is - by chance - the same as the unlock duration. Why should this imply data quality? Why should the data be worse if participants chose to unlock their phones more rarely, but then used it for longer after each unlock (i.e., have fewer, but longer usage blocks)?

k) Section 2: The authors state that their process fo collection unlocking information may be subject to technical issues leading to wrong data points. While the filtering criteria proposed by the authors allow for coservatively ruling out data points that are obviously incorrect, I wonder how many non-obviuous but faulty data points remain in the dataset and whether they can significantly bias the study. Is there a good reason why problems with the collector app should always lead to such obviously wrong data and not to more subtle issues?

l) Section 2.E: The authors need to better explain the merit of their categories and how sensitive the survey is to changes in overall score. Why did the authors not work with a continuous scale? With the categories they still have the problem that scores of 2 and 3 are in different categories. Why is this less of an issue than having 1 and 2 in different categories? My main concern is that whever you try to fit a continuous scale into categories, there may be oddities at the boundaries between categories.

m) Section 2.E: The authors use a linear model for their regression. While this model may be perfectly fine, the authors must provide reasoning as to why this is a suitable model.

n) Section 3.B: "higher unlock frequencies are associated with better mental health" seems to be at odds with the results on male students in the "gender difference" paragraph ("For male students, both unlock duration and unlock frequency are positively correlated with PHQ-4 scores, suggesting that higher phone usage is linked to poorer mental health"). If the first statement was on the overall dataset, was it influenced by having twice as many female participants as male ones? That would call the entire "overall correlations" section into question.

o) Section 3.B: "These findings imply that male students may engage with their phones in less constructive ways than their female peers". This speculation requires additional backing by data. From the data in the paper, we cannot claim that smartphone use causes the change in mental health state, nor can we conclude that the usage patterns are to blame. Someone looking at their phone with high frequency may be the consequence of the same root cause that also leads to poor mental health.

p) Table 3: These numbers need explanation. Let's take the negative correlation in a social context. If you socialize a lot rather than sitting home alone (and thus also use your phone more often in social contexts than at home), this may very well indicate better mental health. However, the phone is very unlikely the cause of the better mental health. If you had no phone with you, would you still have better mental health simply because you socialize rather than sit home alone? If these factors are not considered, there is little to take away from this paper.

q) Section 3.C: "The results indicate that increased unlock duration raises the likelihood of falling into the “Mild” or “Severe” categories but lowers the likelihood of being in the “Moderate” group." This sentence shows what is in the data, but it doesn't provide much insight. Why should this be the case? What are the factors that contribute whether you are on the one side of the scale or on the other? Clearing out the middle ground also seems strange. Why is there no "average" case? This brings me back to my earlier point that mobile phone usage may simply be a blurry expression of the true root cause of good/bad mental health.

r) In Table 3, there is a negative correlation between the duration of unlocks and the mental health score overall and for females in social places. In Table 4, the correlation between unlock duration in social places and severe mental health issues is positive. Why is this the case given that there are more female participants than male ones, i.e., the impact of the negative correlation for males in Table 3 should not have such a large effect?



Review #31B
===========================================================================

Overall merit
-------------
3. Weak accept

Reviewer expertise
------------------
1. No familiarity

Paper summary
-------------
In this paper, the authors analyzed a college experience study dataset to investigate the relationships between the smartphone behaviors and the students’ mental health. Specifically, the authors leverage the smartphone unlocking behaviors and their mental health scores to analyze their associations. This paper performs an initial step to explore their relationships.

Detailed comments for authors
-----------------------------
I personally find that this is a very interesting topic to explore whether smartphone behaviors can impact the students’ mental health. It is also very important to explore this direction. The paper is also well-written. It is easy to follow and well-organized. At the same time, I also have some concerns:

First of all, I’m not 100%sure whether this paper well fits the scope of the conference. Essentially, MOBILESoft is more software oriented. While the studied datasets involve the software usage of the college students, the primary focus of the paper is more psychological. I’m personally not familiar with the related work and may not be able to effectively judge the novelty of the paper.

Second, I think the paper makes some interesting conclusions, for example, the association between unlocking behaviors and mental well-being is different of different genders. I would like to know why there is such a difference. Are there any other factors that could affect the results? It may help if the authors can report how specifically the data were collected, i.e., are there any designs in the dataset collection approach to ensure that the mental well-being scores were mostly (or most likely?) influenced by the smartphone behaviors?

Third, it would be useful for the authors to briefly introduce the dataset - how it was collected? What information was collected other than the used information? What was the original purpose to collect this dataset? With such information, the readers may better assess whether the dataset is suitable for the scope of the study.

Finally, there are some small typos in the paper. For example, Section 2-E: some of the open quotation marks were not correctly printed.



Review #31C
===========================================================================

Overall merit
-------------
4. Accept

Reviewer expertise
------------------
2. Some familiarity

Paper summary
-------------
This paper presents a study on college students' use of smartphones and the students' mental health. The paper studies three main research questions: (1) do different gender college students interact with smartphones differently? (2) are there correlations in smartphone usage and mental health? (3) are there predictive patterns between smartphone usage and mental health? For RQ1, the study finds that there are differences in the way male and female students typically use their phones. For RQ2, more unlocks and less time spent per unlock appear to be associated with better mental health. For RQ3, context-aware data such as location should be used to create custom predictive models for whether smartphone usage is impacting mental health or not.

Detailed comments for authors
-----------------------------
# Novelty: Good

The presented study is interesting and novel compared to existing work. That being said, the paper lacks justification for why the research questions are studied and what impact the findings of this study can have. E.g., whom may use these results and how should the results be used? Should therapists recommend students to use their phones a certain way depending on the student's mental health?

# Rigor: Good

The presented study uses the longest-running mobile sensing dataset to date and applies reasonable statistical tests to investigate the presented research questions.

# Relevance: Fair

The presented study involves the use of mobile applications and college students, which can influence "advancements in design and implementation methods" of mobile applications. That being said, the impact of the study on mobile application software engineering is not particularly clear.

# Verifiability and Transparency: Good

The paper acknowledges that the data analysis pipeline and artifacts will be made open-source upon paper acceptance, but it is not explained why such information is not already made publicly available for the review. The metrics used by each RQ is well documented and given the same dataset, the presented results appear reproducible.

# Presentation: Good

The paper is well written with little to no spelling or grammatical errors.


