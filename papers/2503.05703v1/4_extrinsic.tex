\section{Downstream effects}
\label{sec:extrinsic}





So far we have shown that \name{} leads to improved output prediction capabilities. 
Here, we study its effects in a code supervised fine-tuning (SFT)  setting. 
We take the base Llama 3.1 8B \citep{dubey2024llama3herdmodels}, and evaluate the downstream performance with and without different versions of \name{} in the data mix. The base mix is a small code-only SFT dataset of samples similar to the ones in \citet{roziere2024codellamaopenfoundation}. We train for 7.5k steps with a global batch size of 1024 sequences of up to 8192 tokens.
We evaluate code generation on HumanEval \citep{chen2021codex} and MBPP \citep{mbpp}, without including the traces in inference time. We also evaluate a step-by-step reasoning task, GSM8k\citep{cobbe2021gsm8k}, to study 
 potential improved multi-step reasoning in other domains. 

Table \ref{tab:downstream} shows downstream evaluation results with and without \name{} in the SFT mix. Fine-tuning on direct I/O prediction improves Crux-I and Crux-O but not coding benchmarks. The best-performing trace variant, with 10\% Compact Scratchpad, brings slight gains on HumanEval, MBPP, and 1.2 points on GSM8K. Curiously, forward execution fine-tuning worsens Crux-I, and vice versa, suggesting weaker-than-expected ties  between forward and backward prediction. These results indicate that merging \name{} with SFT data offers little coding improvement. We hypothesize increased gains in evaluations  related to program state, such as  test generation or debugger-assisted tasks.



\begin{table}[thbp!]
  \center
  \caption{ Downstream evaluations on HumanEval, MBPP and GSM8K.
  \label{tab:downstream}}
  \scalebox{0.74}{
   \setlength{\tabcolsep}{3pt}
  \begin{tabular}{l|cc|cc|ccc|ccc|c}
  \toprule
  Model & \multicolumn{2}{c}{Crux-I} & \multicolumn{2}{c}{Crux-O} & \multicolumn{3}{c}{HumanEval} & \multicolumn{3}{c}{MBPP} & GSM8K \\
  & pass@1 & pass@5 & pass@1 & pass@5   & pass@1 & pass@10 & pass@100 & pass@1 & pass@10 & pass@100 & 0-shot\\
  \midrule 
 SFT mix  & 42.9 & 56.5 & 36.4 & 52 & 56.7 & 79.1 &  \textbf{91.2} & 52.2 & 69.4 & 80.7 & 66.3\\ 
  \midrule
   \hspace{3mm} + input FT (10\%)   & \textbf{43.8} & \textbf{57.9} & 34.8  & 46.8  & 51.8 & 77.6  &90.7  & 52.3  & 68.2 & 79.4 & 66\\ 
    \hspace{3mm} + output FT (10\%)    & 41.1 & 56.2 & \textbf{41.8} & \textbf{52.5}  & 56.7  & 79.2  & 91 & 23.8  & 65.2 & 79.1 & 65.1 \\ 
     \midrule
    \hspace{3mm} + C. Scratch  (10\%)  & 41.8 & 56 & 38.8 & 49.8 & \textbf{58.5}  & \textbf{79.9}  & 89.9  & \textbf{53}  & \textbf{69.6} & \textbf{82.5} & \textbf{67.5} \\ 
        \hspace{3mm} + C. Scratch (5\%)  & 42.9 & 58.3 & 38 & 50.5 & 57.9 & 78.9  & 89.3 & 52.6  & 69.3 & 81 & 66.3 \\
        \hspace{3mm} + Line-1 (10\%)    & 39.8 &  56.5& 38 & 50.5  &  53.7 &  78.7  &  89.2  & \textbf{53}  & 69.2 & 80.2 & 65 \\
    \hspace{3mm} + Line-n  (10\%)   & 39.4 & 56.3& 38.8 & 49.1  &  56.1&  78.3 &  88.7  & 51.4  & 68.5 & 80.8 & 66.2 \\


  \bottomrule
  \end{tabular}
  }
  
\end{table}


