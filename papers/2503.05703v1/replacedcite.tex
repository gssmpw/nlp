\section{Related work}
\label{sec:related}



Learning to execute programs as  a benchmarking task for code reasoning capabilities has been long studied in the machine learning community ____, sometimes with niche architectures
____, typically on toy or restricted programs. ____ proposed learning to predict runtime errors as a practical application of neural program evaluation. More recently, ____ introduced  a program output (and input) benchmark for LLMs to measure code understanding capabilities, which we used for evaluation in this work.
Most closely to ours, ____ propose the use of \textit{scratchpads} to let LLMs write down the results of intermediate computations rather than directly aiming at predicting the final output. With Python output prediction being one of their use cases, they represent traces of intermediate states as JSON dictionaries. 
____ introduce \textit{Naturalized} EXecution Tuning (NExT) and propose the compact representation of Python traces that we followed. Unlike ____ and this work, NeXT simplifies loops and uses traces in the \textit{input}, improving program repair.  ____ propose natural language explanations based on executions, leading to further improvements. 
Finally, recent work uses execution \textit{feedback}, rather than traces, in SFT or reinforcement learning settings ____.