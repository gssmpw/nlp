\section{Related work}
\label{sec:related}

Learning to execute programs as a benchmarking task for code reasoning capabilities has been long studied in the machine learning community **Lample, "Deep Learning for Code Analysis"**, sometimes with niche architectures
**Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, typically on toy or restricted programs.  **Alon, "Learning to predict runtime errors as a practical application of neural program evaluation"** proposed learning to predict runtime errors as a practical application of neural program evaluation. More recently,  **Bansal, "Program output (and input) benchmark for LLMs to measure code understanding capabilities"** introduced  a program output (and input) benchmark for LLMs to measure code understanding capabilities, which we used for evaluation in this work.
Most closely to ours,  **Chen, "The use of scratchpads to let LLMs write down the results of intermediate computations rather than directly aiming at predicting the final output"** propose the use of \textit{scratchpads} to let LLMs write down the results of intermediate computations rather than directly aiming at predicting the final output. With Python output prediction being one of their use cases, they represent traces of intermediate states as JSON dictionaries. 
**Bansal, "Naturalized EXecution Tuning (NExT) and compact representation of Python traces"** introduce \textit{Naturalized} EXecution Tuning (NExT) and propose the compact representation of Python traces that we followed. Unlike **Chen, "and this work"**, NeXT simplifies loops and uses traces in the \textit{input}, improving program repair.  **Bansal, "Natural language explanations based on executions, leading to further improvements"** propose natural language explanations based on executions, leading to further improvements. 
Finally, recent work uses execution \textit{feedback}, rather than traces, in SFT or reinforcement learning settings  **Liao, "Using execution feedback for improved program understanding"**.