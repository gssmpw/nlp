%展望未来及 MLLM for VDU 的应用场景
\section{Challenges and Trends}
\label{sec:summary}

%According to the evolutionary trends of model architectures shown in Table \ref{tab:mllm_summary}, it can be observed that the model structures are beginning to evolve in two directions: 1. The number of model parameters is decreasing. For instance, Mini-monkey, with 2B parameters, has achieved results comparable to those of 7B models on multiple TIU tasks. 2. Models are capable of processing longer inputs. For example, DocOwl2.0, by compressing visual tokens, can handle more input images while maintaining the same performance metrics. In terms of training strategies, in addition to MA and IA, PA is also being introduced to enhance the model's question-answering capabilities and overall performance. Moreover, it is conceivable that with the ongoing popularity of reinforcement learning sparked by DeepSeek R1, training strategies using GRPO will also emerge during the PA phase in the MLLM field.

As shown in Table \ref{tab:mllm_summary}, we calculated the average scores from four popular and widely used evaluation datasets, which can basically reflect the performance of MLLMs on TIU tasks. The top five models are Qwen2-VL-72B (88.70), InternVL2.5-78B (87.73), InternVL2.5-38B (87.45), InternVL2.5-26B (85.85), and DeepSeek-VL2-27B (85.40). This indicates that the most state-of-the-art (SOTA) MLLMs currently employ OCR-free encoders, which avoids redundant tokens and complex model architectures. Despite the promising and significant progress made by current MLLMs, the field still faces considerable challenges that require further research and innovation:

% the latest MLLM model architectures predominantly adopt an OCR-free encoder and  Qwen LLM, achieving significant progress on mainstream benchmarks. For instance, the metric on DocVQA has reached a peak of 96.5\%. However, the field still faces significant challenges that demand further research and innovation:

\noindent \textbf{Computational Efficiency and Model Compression}. The computational demands of current MLLMs remain a critical bottleneck, primarily due to two factors: (1) the necessity of processing high-resolution document images, which imposes substantial computational resource requirements, and (2) the prevalent use of 7-billion-parameter architectures, while delivering state-of-the-art performance, incur high deployment costs and latency. These challenges underscore the importance of developing more efficient MLLM architectures that balance performance with reduced computational overhead. Encouragingly, recent advancements, as illustrated in Table~\ref{tab:mllm_summary}, demonstrate promising trends toward model miniaturization. For instance, Mini-monkey~\cite{Huang2024ARXIV_Mini_Monkey_Alleviating} achieves performance comparable to 7B-parameter models on multiple TIU tasks while utilizing only 2B parameters, highlighting the potential for lightweight yet powerful architectures.

\noindent \textbf{Optimization of Visual Feature Representation}. A persistent challenge in MLLMs is the disproportionate length of image tokens compared to text tokens, which significantly increases computational complexity and degrades inference efficiency. Addressing this issue requires innovative approaches to compress image tokens without sacrificing model performance. Promising directions include the development of efficient visual encoders, adaptive token compression mechanisms, and advanced techniques for cross-modal feature fusion. Crucially, these methods must preserve the semantic richness of document content during compression. As shown in Table~\ref{tab:mllm_summary}, recent architectural innovations, such as mPLUG-DocOwl2‘s ~\cite{Hu2024ARXIV_mPLUG_DocOwl2_High} visual token compression, have made strides in this direction by enabling the processing of larger input images while maintaining benchmark performance.

\noindent \textbf{Long Document Understanding Capability}. While MLLMs excel at single-page document understanding, their performance on multi-page or long-document tasks remains suboptimal. Key challenges include modeling long-range dependencies, maintaining contextual coherence across pages, and efficiently processing extended sequences. The emergence of specialized benchmarks for long-document understanding~\cite{Ma2024NEURIPS_MMLongBench_Doc_Benchmarking}, as highlighted in Table~\ref{tab:datawithbenchmark}, is expected to drive significant progress in this field by providing standardized evaluation frameworks and fostering targeted research efforts.

\noindent \textbf{Multilingual Document Understanding}. Current MLLMs are predominantly optimized for English and a limited set of high-resource languages, resulting in inadequate performance in multilingual and low-resource language scenarios. Addressing this limitation requires the development of comprehensive multilingual datasets that encompass diverse linguistic and cultural contexts. Recent initiatives, such as MT-VQA~\cite{tang2024mtvqa} and CC-OCR~\cite{yang2024cc} (referenced in Table~\ref{tab:datawithbenchmark}), represent important steps forward by introducing TIU tasks specifically designed to evaluate multilingual capabilities. These efforts, coupled with advances in cross-lingual transfer learning, are expected to significantly enhance the inclusivity and applicability of MLLMs in global contexts.

%\noindent \textbf{Evaluation Standards and New Benchmarks}. The current evaluation standards for TIU tasks are predominantly based on limited benchmark datasets, which may not fully capture the model's performance in real-world scenarios, especially the reasoning ablity. Furthermore, the existing evaluation metrics are often overly simplistic, lacking the ability to comprehensively assess the model's multidimensional capabilities. To address these limitations, it is crucial to develop more comprehensive evaluation benchmarks that encompass a diverse range of document types, languages, and domains.