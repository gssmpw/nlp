@inproceedings{Eberts2019SpanbasedJE,
  title={Span-based Joint Entity and Relation Extraction with Transformer Pre-training},
  author={Markus Eberts and Adrian Ulges},
  booktitle={European Conference on Artificial Intelligence},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:202583766}
}

@inproceedings{asada2024enhancing,
  title={Enhancing Relation Extraction from Biomedical Texts by Large Language Models},
  author={Asada, Masaki and Fukuda, Ken},
  booktitle={International Conference on Human-Computer Interaction},
  pages={3--14},
  year={2024},
  organization={Springer}
}

@article{bekoulis2018joint,
  title={Joint entity recognition and relation extraction as a multi-head selection problem},
  author={Bekoulis, Giannis and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
  journal={Expert Systems with Applications},
  volume={114},
  pages={34--45},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{fu2019graphrel,
  title={Graphrel: Modeling text as relational graphs for joint entity and relation extraction},
  author={Fu, Tsu-Jui and Li, Peng-Hsuan and Ma, Wei-Yun},
  booktitle={Proceedings of the 57th annual meeting of the association for computational linguistics},
  pages={1409--1418},
  year={2019}
}

@inproceedings{huang2019bert,
  title={Bert-based multi-head selection for joint entity-relation extraction},
  author={Huang, Weipeng and Cheng, Xingyi and Wang, Taifeng and Chu, Wei},
  booktitle={Natural Language Processing and Chinese Computing: 8th CCF International Conference, NLPCC 2019, Dunhuang, China, October 9--14, 2019, Proceedings, Part II 8},
  pages={713--723},
  year={2019},
  organization={Springer}
}

@inproceedings{ji2020span,
  title={Span-based joint entity and relation extraction with attention-based span-specific and contextual semantic representations},
  author={Ji, Bin and Yu, Jie and Li, Shasha and Ma, Jun and Wu, Qingbo and Tan, Yusong and Liu, Huijun},
  booktitle={Proceedings of the 28th international conference on computational linguistics},
  pages={88--99},
  year={2020}
}

@inproceedings{ren-etal-2021-novel,
    title = "A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling",
    author = "Ren, Feiliang  and
      Zhang, Longhui  and
      Yin, Shujuan  and
      Zhao, Xiaofeng  and
      Liu, Shilei  and
      Li, Bochao  and
      Liu, Yaduo",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.208",
    doi = "10.18653/v1/2021.emnlp-main.208",
    pages = "2646--2656",
    abstract = "Table filling based relational triple extraction methods are attracting growing research interests due to their promising performance and their abilities on extracting triples from complex sentences. However, this kind of methods are far from their full potential because most of them only focus on using local features but ignore the global associations of relations and of token pairs, which increases the possibility of overlooking some important information during triple extraction. To overcome this deficiency, we propose a global feature-oriented triple extraction model that makes full use of the mentioned two kinds of global associations. Specifically, we first generate a table feature for each relation. Then two kinds of global associations are mined from the generated table features. Next, the mined global associations are integrated into the table feature of each relation. This {``}generate-mine-integrate{''} process is performed multiple times so that the table feature of each relation is refined step by step. Finally, each relation{'}s table is filled based on its refined table feature, and all triples linked to this relation are extracted based on its filled table. We evaluate the proposed model on three benchmark datasets. Experimental results show our model is effective and it achieves state-of-the-art results on all of these datasets. The source code of our work is available at: \url{https://github.com/neukg/GRTE}.",
}

@inproceedings{shang2022onerel,
  title={Onerel: Joint entity and relation extraction with one module in one step},
  author={Shang, Yu-Ming and Huang, Heyan and Mao, Xianling},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={10},
  pages={11285--11293},
  year={2022}
}

@article{sui2023joint,
  title={Joint entity and relation extraction with set prediction networks},
  author={Sui, Dianbo and Zeng, Xiangrong and Chen, Yubo and Liu, Kang and Zhao, Jun},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{wang-etal-2020-tplinker,
    title = "{TPL}inker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking",
    author = "Wang, Yucheng  and
      Yu, Bowen  and
      Zhang, Yueyang  and
      Liu, Tingwen  and
      Zhu, Hongsong  and
      Sun, Limin",
    editor = "Scott, Donia  and
      Bel, Nuria  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.138",
    doi = "10.18653/v1/2020.coling-main.138",
    pages = "1572--1582",
    abstract = "Extracting entities and relations from unstructured text has attracted increasing attention in recent years but remains challenging, due to the intrinsic difficulty in identifying overlapping relations with shared entities. Prior works show that joint learning can result in a noticeable performance gain. However, they usually involve sequential interrelated steps and suffer from the problem of exposure bias. At training time, they predict with the ground truth conditions while at inference it has to make extraction from scratch. This discrepancy leads to error accumulation. To mitigate the issue, we propose in this paper a one-stage joint extraction model, namely, TPLinker, which is capable of discovering overlapping relations sharing one or both entities while being immune from the exposure bias. TPLinker formulates joint extraction as a token pair linking problem and introduces a novel handshaking tagging scheme that aligns the boundary tokens of entity pairs under each relation type. Experiment results show that TPLinker performs significantly better on overlapping and multiple relation extraction, and achieves state-of-the-art performance on two public datasets.",
}

@inproceedings{wei-etal-2020-novel,
    title = "A Novel Cascade Binary Tagging Framework for Relational Triple Extraction",
    author = "Wei, Zhepei  and
      Su, Jianlin  and
      Wang, Yue  and
      Tian, Yuan  and
      Chang, Yi",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.136",
    doi = "10.18653/v1/2020.acl-main.136",
    pages = "1476--1488",
    abstract = "Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction. However, few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities. In this work, we introduce a fresh perspective to revisit the relational triple extraction task and propose a novel cascade binary tagging framework (CasRel) derived from a principled problem formulation. Instead of treating relations as discrete labels as in previous works, our new framework models relations as functions that map subjects to objects in a sentence, which naturally handles the overlapping problem. Experiments show that the CasRel framework already outperforms state-of-the-art methods even when its encoder module uses a randomly initialized BERT encoder, showing the power of the new tagging framework. It enjoys further performance boost when employing a pre-trained BERT encoder, outperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score on two public datasets NYT and WebNLG, respectively. In-depth analysis on different scenarios of overlapping triples shows that the method delivers consistent performance gain across all these scenarios. The source code and data are released online.",
}

@inproceedings{zhang2024linkner,
  title={Linkner: Linking local named entity recognition models to large language models using uncertainty},
  author={Zhang, Zhen and Zhao, Yuhua and Gao, Hang and Hu, Mengting},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={4047--4058},
  year={2024}
}

@article{zhao2022exploring,
  title={Exploring privileged features for relation extraction with contrastive student-teacher learning},
  author={Zhao, Xiaoyan and Yang, Min and Qu, Qiang and Xu, Ruifeng and Li, Jieke},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2022},
  publisher={IEEE}
}

@inproceedings{zheng-etal-2017-joint,
    title = "Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme",
    author = "Zheng, Suncong  and
      Wang, Feng  and
      Bao, Hongyun  and
      Hao, Yuexing  and
      Zhou, Peng  and
      Xu, Bo",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1113",
    doi = "10.18653/v1/P17-1113",
    pages = "1227--1236",
    abstract = "Joint extraction of entities and relations is an important task in information extraction. To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem.. Then, based on our tagging scheme, we study different end-to-end models to extract entities and their relations directly, without identifying entities and relations separately. We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods. What{'}s more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.",
}

