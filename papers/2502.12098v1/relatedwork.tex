\section{Related Work}
\label{sec:related}
\subsection{Connected Autonomous Driving} The growing interest in connected autonomous driving, driven by collaborative perception among connected agents, has led to various research efforts. Methods are generally classified into raw-based early collaboration, output-based late collaboration, and feature-based intermediate collaboration. Early collaboration fuses raw sensor data from connected agents onboard for vision tasks \cite{arnold2020cooperative}, while late collaboration merges multi-agent perception outputs using techniques like Non-Maximum Suppression \cite{forsyth2014object} and refined matching to ensure pose consistency \cite{song2023cooperative}. Intermediate collaboration strikes a balance by sharing compressed features, with methods such as when2com \cite{liu2020when2com}, who2com \cite{liu2020who2com}, and where2com \cite{hu2022where2comm}. Data fusion strategies include concatenation \cite{chen2019f}, re-weighted summation \cite{guo2021coff}, graph learning \cite{wang2020v2vnet, zhou2022multi}, and attention-based fusion \cite{xu2022v2x, xu2022opv2v}. Applications span object detection \cite{bi2022edge}, tracking \cite{li2021learning}, segmentation \cite{xu2022cobevt}, localization \cite{yuan2022keypoints}, and depth estimation \cite{hu2023collaboration}. However, none of these methods adapts to bandwidth limitations, which often prevent the sharing of holistic information.

\subsection{Correspondence Identification} Correspondence Identification (CoID) methods fall into learning-free and learning-based categories. Learning-free approaches include visual appearance techniques like SIFT \cite{engel2014lsd}, ORB \cite{mur2015orb}, HOG \cite{dalal2005histograms}, and TransReID \cite{he2021transreid}, as well as spatial techniques like ICP \cite{rusinkiewicz2001efficient}, template matching \cite{zhang20232}, and graph matching \cite{gao2020correspondence, gao2021regularized}. Synchronization algorithms also contribute through circle consistency enforcement \cite{fathian2020clear} and convex optimization \cite{hu2018distributable}. Learning-based methods primarily use CNNs \cite{jin2020semantics,khatun2020semantic, voigtlaender2019mots} and GNNs \cite{wang2019learning,zhang2019deep, fey2019deep}, with hybrid approaches like Bayesian CoID \cite{gao2021bayesian, gao2022correspondence} enhancing robustness. However, existing methods struggle to integrate temporal cues, as sharing sequences of frames is constrained by real-world bandwidth limitations. We propose a novel method that integrates visual, spatial, and temporal cues for CoID in a bandwidth-adaptive way.

% \subsection{Connected Autonomous Driving}
% The rising interest in connected autonomous driving, facilitated by collaborative perception among connected agents, has spurred significant research efforts. Existing methods can be broadly categorized into three groups: raw-based early collaboration, output-based late collaboration, and feature-based intermediate collaboration approaches.
% Early collaboration involves fusing raw data as input to the network, necessitating connected agents to share, transform, and aggregate raw sensor data onboard for vision tasks \cite{arnold2020cooperative}. Late collaboration, on the other hand, typically employs fusion at the postprocessing stage. This method merges multi-agent perception outputs, utilizing techniques such as Non-Maximum Suppression to eliminate redundant predictions \cite{forsyth2014object} and refined matching to remove results violating pose consistency \cite{song2023cooperative}.
% Intermediate collaboration focuses on learning and sharing compressed features from raw observations, striking a balance between communication bandwidth and performance. Different communication mechanisms, including when2com \cite{liu2020when2com}, who2com \cite{liu2020who2com}, and where2com \cite{hu2022where2comm}, have been developed from the data-sharing perspective. 
% From the data fusion perspective, existing strategies include direct concatenation \cite{chen2019f}, re-weighted summation \cite{guo2021coff}, graph learning-based fusion \cite{wang2020v2vnet, zhou2022multi}, and attention-based fusion \cite{xu2022v2x, xu2022opv2v}.
% From the application perspective, a spectrum of applications were explored, including object detection \cite{bi2022edge}, tracking \cite{li2021learning}, semantic segmentation \cite{xu2022cobevt}, localization \cite{yuan2022keypoints}, and depth estimation \cite{hu2023collaboration}.

% Even though these diverse approaches collectively contribute to advancing collaborative perception in connected autonomous driving systems, none of these methods can adapt to the change of communication bandwidth, especially when the bandwidth constraint does not allow to share the holistic information.

% \subsection{Correspondence Identification}
% CoID can be generally grouped into two categories, including learning-free and learning-based approaches.
% Learning-free approaches can be further categorized into three subgroups, each employing distinct techniques to tackle correspondence identification based on visual appearance, spatial relationships, and synchronization algorithms. Visual appearance features are frequently utilized for tasks like key-point matching to align adjacent frames or local-global mapping. Common examples include SIFT (Scale-Invariant Feature Transform) \cite{engel2014lsd} and ORB (Oriented FAST and Rotated BRIEF) \cite{mur2015orb}. Additionally, region-based visual features, such as HOG (Histogram of Oriented Gradients) \cite{dalal2005histograms} and TransReID \cite{he2021transreid}, are commonly employed to identify the same location observed at different times. Spatial features, on the other hand, are leveraged to establish object correspondences, with techniques like ICP (Iterative Closest Point) \cite{rusinkiewicz2001efficient}, template matching \cite{zhang20232} and graph matching \cite{gao2020correspondence, gao2021regularized} serving this purpose. Furthermore, synchronization algorithms are closely tied to the CoID problem and work by taking pairwise correspondences as inputs and producing multi-view correspondences through techniques like circle consistency enforcement, often implemented using graph cut \cite{fathian2020clear} and convex optimization \cite{hu2018distributable}.
% Learning-based approaches in the context of CoID primarily revolve around the utilization of deep neural networks, with a focus on two prevalent categories: convolutional neural networks (CNNs) and graph neural networks (GNNs). CNN-based methods are designed to extract high-level visual features, facilitating the recognition of identical objects observed from diverse perspectives. Notable examples include techniques like semantics-based CoID \cite{jin2020semantics,khatun2020semantic, voigtlaender2019mots}. GNN-based approaches, on the other hand, aim to capture unique patterns surrounding objects by aggregating their spatial relationships \cite{wang2019learning,zhang2019deep, fey2019deep}. Furthermore, a hybrid approach that combines both CNN and GNN-based methods has gained traction, exemplified by methods like Bayesian-based CoID \cite{gao2021bayesian, gao2022correspondence}. This integration of visual and spatial information in CoID contributes to improved robustness, enhancing the overall performance of the techniques.
% \color{black}

% The shortcoming of the existing methods is the lack of capability to integrate temporal cues for CoID as the sharing of a sequence of frames is far beyond the real-world communication bandwidth constraint. In this paper, we propose a novel method that can integrate visual, spatial and temporal cues for CoID in a bandwidth-adaptive way.

\begin{figure*}[t]
\vspace{6pt}
\centering
\includegraphics[width=0.9\textwidth]{./figures/approach.pdf}
\caption{
An overview of our proposed bandwidth-adaptive spatiotemporal CoID approach. 
A sequence of observations is represented as a spatiotemporal graph. 
A spatiotemporal graph attention network is used to generate node-level embeddings by integrating spatiotemporal visual cues. 
Then, a heterogeneous graph pooling operation is designed to produce comprehensive graph-level embeddings that explicitly encode the importance of spatial and temporal cues. 
Leveraging both node-level and graph-level embeddings, our approach enables the sharing of node candidates that are likely to be observed by collaborators, 
resulting in effective data sharing that adapts to communication bandwidth constraints.
% An overview of our proposed bandwidth-adaptive spatiotemporal CoID approach that is implemented with 
% heterogeneous graph neural networks. On the ego vehicle side, given the raw features of objects and their spatiotemporal relationships, we perform graph attention neural networks to generate node-level embedding vectors in spatial and temporal domains. In addition, we group the embedding vectors to compute the importance of spatial and temporal relationships (spatial and temporal weights). Then, given the node embedding vectors and relationship importance,  we compute the node embedding vectors. After that,
% we propose a novel graph pooling operation to generate a graph-level embedding vector (graph embed.) by aggregating nodes embedding vectors weighted by the importance of spatiotemporal relationships. Similar to the ego vehicle, the collaborator also generates node and graph embedding vectors, and then shares K node embedding vectors and 1 graph embedding vectors with the ego vehicle given the current bandwidth constraint. Given the shared node and graph embedding vectors, the ego vehicle can compute the matching score to select top-K candidates to share back with the collaborator. To notice, the graph embedding vector just needs to be shared once at the first interaction. 
% \HZ{Font size in the figure should be justified, especially the block names.}
}
\label{fig:approach}
\end{figure*}
\vspace{-6pt}