\section{Related Work}
\label{sec:related}
\subsection{Connected Autonomous Driving} The growing interest in connected autonomous driving, driven by collaborative perception among connected agents, has led to various research efforts. Methods are generally classified into raw-based early collaboration, output-based late collaboration, and feature-based intermediate collaboration. Early collaboration fuses raw sensor data from connected agents onboard for vision tasks ____, while late collaboration merges multi-agent perception outputs using techniques like Non-Maximum Suppression ____ and refined matching to ensure pose consistency ____. Intermediate collaboration strikes a balance by sharing compressed features, with methods such as when2com ____, who2com ____, and where2com ____. Data fusion strategies include concatenation ____, re-weighted summation ____, graph learning ____, and attention-based fusion ____. Applications span object detection ____, tracking ____, segmentation ____, localization ____, and depth estimation ____. However, none of these methods adapts to bandwidth limitations, which often prevent the sharing of holistic information.

\subsection{Correspondence Identification} Correspondence Identification (CoID) methods fall into learning-free and learning-based categories. Learning-free approaches include visual appearance techniques like SIFT ____, ORB ____, HOG ____, and TransReID ____, as well as spatial techniques like ICP ____, template matching ____, and graph matching ____. Synchronization algorithms also contribute through circle consistency enforcement ____ and convex optimization ____. Learning-based methods primarily use CNNs ____ and GNNs ____, with hybrid approaches like Bayesian CoID ____ enhancing robustness. However, existing methods struggle to integrate temporal cues, as sharing sequences of frames is constrained by real-world bandwidth limitations. We propose a novel method that integrates visual, spatial, and temporal cues for CoID in a bandwidth-adaptive way.

% \subsection{Connected Autonomous Driving}
% The rising interest in connected autonomous driving, facilitated by collaborative perception among connected agents, has spurred significant research efforts. Existing methods can be broadly categorized into three groups: raw-based early collaboration, output-based late collaboration, and feature-based intermediate collaboration approaches.
% Early collaboration involves fusing raw data as input to the network, necessitating connected agents to share, transform, and aggregate raw sensor data onboard for vision tasks ____. Late collaboration, on the other hand, typically employs fusion at the postprocessing stage. This method merges multi-agent perception outputs, utilizing techniques such as Non-Maximum Suppression to eliminate redundant predictions ____ and refined matching to remove results violating pose consistency ____.
% Intermediate collaboration focuses on learning and sharing compressed features from raw observations, striking a balance between communication bandwidth and performance. Different communication mechanisms, including when2com ____, who2com ____, and where2com ____, have been developed from the data-sharing perspective. 
% From the data fusion perspective, existing strategies include direct concatenation ____, re-weighted summation ____, graph learning-based fusion ____, and attention-based fusion ____.
% From the application perspective, a spectrum of applications were explored, including object detection ____, tracking ____, semantic segmentation ____, localization ____, and depth estimation ____.

% Even though these diverse approaches collectively contribute to advancing collaborative perception in connected autonomous driving systems, none of these methods can adapt to the change of communication bandwidth, especially when the bandwidth constraint does not allow to share the holistic information.

% \subsection{Correspondence Identification}
% CoID can be generally grouped into two categories, including learning-free and learning-based approaches.
% Learning-free approaches can be further categorized into three subgroups, each employing distinct techniques to tackle correspondence identification based on visual appearance, spatial relationships, and synchronization algorithms. Visual appearance features are frequently utilized for tasks like key-point matching to align adjacent frames or local-global mapping. Common examples include SIFT (Scale-Invariant Feature Transform) ____ and ORB (Oriented FAST and Rotated BRIEF) ____. Additionally, region-based visual features, such as HOG (Histogram of Oriented Gradients) ____ and TransReID ____, are commonly employed to identify the same location observed at different times. Spatial features, on the other hand, are leveraged to establish object correspondences, with techniques like ICP (Iterative Closest Point) ____, template matching ____ and graph matching ____ serving this purpose. Furthermore, synchronization algorithms are closely tied to the CoID problem and work by taking pairwise correspondences as inputs and producing multi-view correspondences through techniques like circle consistency enforcement, often implemented using graph cut ____ and convex optimization ____.
% Learning-based approaches in the context of CoID primarily revolve around the utilization of deep neural networks, with a focus on two prevalent categories: convolutional neural networks (CNNs) and graph neural networks (GNNs). CNN-based methods are designed to extract high-level visual features, facilitating the recognition of identical objects observed from diverse perspectives. Notable examples include techniques like semantics-based CoID ____. GNN-based approaches, on the other hand, aim to capture unique patterns surrounding objects by aggregating their spatial relationships ____. Furthermore, a hybrid approach that combines both CNN and GNN-based methods has gained traction, exemplified by methods like Bayesian-based CoID ____. This integration of visual and spatial information in CoID contributes to improved robustness, enhancing the overall performance of the techniques.
% \color{black}

% The shortcoming of the existing methods is the lack of capability to integrate temporal cues for CoID as the sharing of a sequence of frames is far beyond the real-world communication bandwidth constraint. In this paper, we propose a novel method that can integrate visual, spatial and temporal cues for CoID in a bandwidth-adaptive way.

\begin{figure*}[t]
\vspace{6pt}
\centering
\includegraphics[width=0.9\textwidth]{./figures/approach.pdf}
\caption{
An overview of our proposed bandwidth-adaptive spatiotemporal CoID approach. 
A sequence of observations is represented as a spatiotemporal graph. 
A spatiotemporal graph attention network is used to generate node-level embeddings by integrating spatiotemporal visual cues. 
Then, a heterogeneous graph pooling operation is designed to produce comprehensive graph-level embeddings that explicitly encode the importance of spatial and temporal cues. 
Leveraging both node-level and graph-level embeddings, our approach enables the sharing of node candidates that are likely to be observed by collaborators, 
resulting in effective data sharing that adapts to communication bandwidth constraints.
% An overview of our proposed bandwidth-adaptive spatiotemporal CoID approach that is implemented with 
% heterogeneous graph neural networks. On the ego vehicle side, given the raw features of objects and their spatiotemporal relationships, we perform graph attention neural networks to generate node-level embedding vectors in spatial and temporal domains. In addition, we group the embedding vectors to compute the importance of spatial and temporal relationships (spatial and temporal weights). Then, given the node embedding vectors and relationship importance,  we compute the node embedding vectors. After that,
% we propose a novel graph pooling operation to generate a graph-level embedding vector (graph embed.) by aggregating nodes embedding vectors weighted by the importance of spatiotemporal relationships. Similar to the ego vehicle, the collaborator also generates node and graph embedding vectors, and then shares K node embedding vectors and 1 graph embedding vectors with the ego vehicle given the current bandwidth constraint. Given the shared node and graph embedding vectors, the ego vehicle can compute the matching score to select top-K candidates to share back with the collaborator. To notice, the graph embedding vector just needs to be shared once at the first interaction. 
% \HZ{Font size in the figure should be justified, especially the block names.}
}
\label{fig:approach}
\end{figure*}
\vspace{-6pt}