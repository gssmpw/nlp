\section{Building Cross-modal Multi-task Genomic Foundation Models}

In this section, we demonstrate the \textbf{cross-modal multi-task} capability of Omni-DNA in using DNA sequences to three distinct modalities: discrete labels, textual descriptions, and images. The first two are derived from real-world datasets, while the third is based on a synthetic dataset called \textit{Needle-in-DNA}. Despite the significant differences in task formats, a unified approach is employed to address all three.

For classification problems, Omni-DNA finetuned with multiple tasks not only has the ability to solve more than one task simultaneously but also improves overall model performance on related NT downstream tasks: a phenomenon we refer to as the \textbf{synergistic effect}. Additionally, we extend beyond conventional genomic modeling tasks to tackle more challenging and general problems: (1) DNA-to-function and (2) DNA-to-image. These efforts underscore the potential of training a unified genomic foundation model capable of acting as a generalist across both tasks and modalities.

\subsection{Multi-Task Model for Acetylation and Methylation}
%\subsection{Single Multi-Tasking Model for Acetylation and Methylation Tasks}


\begin{table*}[t!]
\caption{Performance comparison across 10 related acetylation and methylation tasks. Omni-DNA@mult. outperforms single-task models in 4 tasks, and achieves the second-best performance in 5 tasks, demonstrating the synergistic effect of multi-task genomic fine-tuning.}
\label{tab:multi-tasking}
\resizebox{\textwidth}{!}{
% \tiny % Reduce text size for the table
\begin{tabular}{@{}lccccc@{}}
\toprule
          & \small \textbf{Omni-DNA@mult.} & \small \textbf{Omni-DNA@sgl.} & \small\textbf{DNABERT2@sgl.} & \small\textbf{NT Transformer@sgl.} & \small\textbf{CADUCEUS-PH@sgl.} \\ 
          & \small\textbf{(1B)} & \small\textbf{(1B)} & \small\textbf{(117M)} & \small\textbf{(500M)} & \small\textbf{(1.9M)} \\ 
\midrule
H3       & $0.759 \pm 0.021$ & $\mathbf{0.824} \pm 0.032$ & $0.785\pm0.033$ & $0.784\pm0.047$ & $\underline{0.815} \pm 0.048$ \\ 
H3K14AC  & $\mathbf{0.890} \pm 0.011$ & $\underline{0.697} \pm 0.077$ & $0.516\pm0.028$ & $0.551\pm0.021$ & $0.631 \pm 0.026$ \\
H3K36ME3 & $\underline{0.674} \pm 0.008$ & $\mathbf{0.686} \pm 0.002$ & $0.591\pm0.020$ & $0.625\pm0.013$ & $0.601 \pm 0.129$ \\
H3K4ME1  & $\underline{0.565} \pm 0.015$ & $\mathbf{0.617} \pm 0.000$ & $0.511\pm0.028$ & $0.550\pm0.021$ & $0.523 \pm 0.039$ \\
H3K4ME2  & $\mathbf{0.691} \pm 0.008$ & $\underline{0.547} \pm 0.006$ & $0.336\pm0.040$ & $0.319\pm0.045$ & $0.487 \pm 0.170$ \\
H3K4ME3  & $\mathbf{0.785} \pm 0.008$ & $\underline{0.642} \pm 0.001$ & $0.352\pm0.077$ & $0.410\pm0.033$ & $0.544 \pm 0.045$ \\
H3K79ME3 & $\underline{0.709} \pm 0.017$ & $\mathbf{0.752} \pm 0.007$ & $0.613\pm0.030$ & $0.626\pm0.026$ & $0.697 \pm 0.077$ \\
H3K9AC   & $\underline{0.693} \pm 0.013$ & $\mathbf{0.701} \pm 0.002$ & $0.542\pm0.029$ & $0.562\pm0.040$ & $0.622 \pm 0.030$ \\
H4       & $\underline{0.773} \pm 0.013$ & $\mathbf{0.822} \pm 0.005$ & $0.796\pm0.027$ & $0.799 \pm 0.025$ & $0.811 \pm 0.022$ \\
H4AC     & $\mathbf{0.853} \pm 0.014$ & $\underline{0.652} \pm 0.001$ & $0.463\pm0.041$ & $0.495\pm0.032$ & $0.621 \pm 0.054$ \\
\midrule
Average     & $\mathbf{0.739}$ & $\underline{0.694}$ & $0.551$ & $0.572$ & $0.635$ \\
\bottomrule
\end{tabular}
}
\vspace{-1em}
\end{table*}

\paragraph{Task} In the NT downstream tasks, 10 related tasks---H3, H3K14AC, H3K36ME3, H3K4ME1, H3K4ME2, H3K4ME3, H3K79ME3, H3K9AC, H4, and H4AC---are considered. These tasks are interconnected due to the biological correlation between acetylation and methylation effects~\citep{pokholok2005genome}. The objective here is to train a model capable of addressing all 10 tasks with a single fine-tuning step. While conventional fine-tuning approaches with a classification head struggle to address this challenge, \emph{cross-modal multi-task finetuning} unifies these tasks into a single model. At inference time, having an omni-model that solves all tasks eliminates the need for context switching and repeated fine-tuning.

We use Omni-DNA (1B) to complete 10 acetylation and methylation tasks using  multi-task finetuning with NEFTune noise level = 5 and repeating factor = 10. The baselines include the best-performing single-task models: Omni-DNA (1B) and CADUCEUS-PH (1.9M), as presented in \cref{sec:fullfinetune}, along with DNABERT-2 and NT (500M) as references. Conventionally, multi-task finetuning may lead to performance drop compared with single-task finetuning due to the challenge of balancing generalizability across tasks. However, by grouping similar tasks, we observe significant improvements. The results, shown in Table~\ref{tab:multi-tasking} and Figure~\ref{fig:multi-tasking}, demonstrate that Omni-DNA@mult achieves dramatic improvements in 4 tasks, and obtains the highest average accuracy. 
%It remains the best model compared to models other than Omni-DNA@sgl. 
This indicates that the resulting model not only reduces the burden of context switching and repetitive finetuning but also leverages the internal relationships between tasks to achieve higher performance than its single-task counterparts. We refer to this phenomenon as the \textbf{synergistic effect}, which emerges in finetuning genomic foundation models in a multi-task setting.


\subsection{Functional Annotation Generation (DNA2Func)}
%for Precision Evaluation}


\paragraph{Dataset and Task} As shown in \cref{fig:seq2func}, we have constructed a large-scale DNA sequence dataset enriched with text-based functional annotations. 
This dataset comprises 330,000 sequences from various mammalian species, and
each sequence is annotated with a concise short annotation followed by a more detailed natural language description. 
We split the dataset into finetuning and test sets with a 9:1 ratio.
The full workflow for dataset construction is in \cref{app:dna2func}. 
This is a multi-task scenario with two objectives: (1) generating concise short annotations for DNA sequences and (2) further explaining the corresponding functions by natural language.
%The dataset is filtered to remove rare RNA types and split to train and test with a ratio of 9:1. 


\paragraph{Baselines} We finetuned our proposed \method, using the finetuning dataset, denoted as Omni-DNA@ft. 
Since conventional genomic foundation models cannot handle these tasks, we employed GPT-4o (GPT4o@zeroshot) to directly predict DNA functions using the prompt in~\cref{tab:prompt-for-dna2func}.
In addition, we included OLMo-1B as a baseline, a similar architecture model pre-trained on natural language, and finetuned on the same finetuning dataset with \method, referred to as OLMo-1B@ft.


\paragraph{Evaluation \& Metrics} To evaluate the accuracy of free-form text is challenging. Thus, we leveraged an LLM (GPT4o) to judge whether the generated text and ground-truth are matched. We first utilized GPT4o to
classify the generated text into seven function labels, as shown in \cref{fig:seq2func}. Then the F1 scores and Matthews Correlation Coefficient (MCC) are computed between the classified labels and ground-truth.

% Thus, we utilized an LLM (GPT4o) as an evaluator. This evaluator accesses whether the generated text and the ground truth description are matched used the prompt in Appendix. We calculate the F1 scores and Matthews Correlation Coefficient (MCC) of GPT4o's evaluations.



% \paragraph{Baselines} Here we apply genomic finetuning to our model Omni-DNA (Omni-DNA@finetune) and compare its performance with models that can solve this tasks. As conventional genomic foundation model cannot achieve this tasks, we let GPT-4o (GPT4o@zeroshot) to directly predict the fucntion of a DNA. The prompt to complete this is task is shown in table-xxx. Another baseline is OLMo 1B trained on Natural Lanuage, it shares the simialr architecture as Omni-DNA. We finetune it on the DNA2Func dataset, noted as OLMo@finetuned.


% \paragraph{Evaluation \& Metrics}
% To evaluate the accuracy of free-style text generated from three models as shown in Table is challenging. Thus, we use an LLM (GPT4o) as a evaluator, which takes the generated text and ground truth as input, and decides if two text description match the underlying RNA/Gene Function,  the prompt for evaluation is included in Appendix. The match cases are then measured by F1 score and MCC. 

\paragraph{Quantitative Results} As shown in Table~\ref{tab:model_comparison}, Omni-DNA obtains the best result compared to GPT4o and OLMo-1B, highlighting the potential for solving this domain-specific problem. \Cref{tab:dna2func-1,tab:dna2func-2,tab:dna2func-3} present representative responses from the three models. Among them, Omni-DNA@ft consistently demonstrates the strongest performance. In contrast, GPT4o fails to understand the meaning of the DNA sequences in all three examples, whereas the other two models provide more meaningful responses. Notably, Omni-DNA is capable of producing grammatical and novel sentences, rather than merely reproducing funetuning datasets.
%, even though it does not undergo text-based pretraining.

\begin{table}[t!]
\centering
\caption{Comparison of Weighted F1 Score and MCC for Omni-DNA@ft, GPT4o@zeroshot, OLMo-1B@ft, and Random Guess.}
\label{tab:model_comparison}
\resizebox{\columnwidth}{!}{
\begin{tabular}{lcccc}
\toprule
 & \textbf{Omni-DNA} & \textbf{GPT4o} & \textbf{OLMo-1B} & \textbf{Random} \\
\midrule
F1 Score     & \textbf{0.730} & 0.659 & 0.701 & 0.483 \\
MCC      & \textbf{0.367} & -0.015 & 0.342 & 0.008 \\
\bottomrule
\end{tabular}
}
\vspace{-1em}
\end{table}



\subsection{Needle-in-DNA Task (DNA2Image)}
 \begin{figure*}[ht!]
    \centering
\begin{scriptsize}
\begin{tabular}{|c|c|cc|cc|cc|cc|}
\hline
\multicolumn{2}{|c|}{Examples From Models} & \multicolumn{2}{c|}{Class 0} & \multicolumn{2}{c|}{Class 1} & \multicolumn{2}{c|}{Class 2} & \multicolumn{2}{c|}{Class 3} \\ \hline
Valid & Invalid & Sequence & Image & Sequence & Image & Sequence & Image & Sequence & Image \\ \hline
\includegraphics[width=0.4cm]{figures/mnist_0.png} \includegraphics[width=0.4cm]{figures/mnist_1.png} & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/invalid_92.png} & T...\textcolor{darkgreen}{TATAAA}... & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/0_36.png} & C...\textcolor{darkgreen}{CAAT}... & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/1.png} & A...\textcolor{darkgreen}{GGGCGG}... & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/2_0.png} & T...\textcolor{darkgreen}{TTAGGG}... & \includegraphics[width=0.3cm]{figures/mnist_sample_figures/3_10.png} \\ 
\cline{3-10}  % Added horizontal line from column 3 to 10
\includegraphics[width=0.4cm]{figures/mnist_2.png} \includegraphics[width=0.4cm]{figures/mnist_3.png} & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/invalid_980.png} & ...\textcolor{darkgreen}{TATAAA}......A & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/0_41.png} & T...\textcolor{darkgreen}{CAAT}... & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/1_3.png} & ...\textcolor{darkgreen}{GGGCGG}...T & \includegraphics[width=0.4cm]{figures/mnist_sample_figures/2_8.png} & ...\textcolor{darkgreen}{TTAGGG}...A & \includegraphics[width=0.3cm]{figures/mnist_sample_figures/3_14.png} \\ \hline
\end{tabular}
\end{scriptsize}
    \includegraphics[width=0.9\linewidth]{figures/f1_invalid_percentage_per_class.pdf}
    \vspace{-1em}
    \caption{\textbf{F1 scores and invalid percentages for \textit{Needle-in-DNA}, averaged and per class}. Omni-DNA outperforms both baselines.}
    \label{fig:dna2iamge}
    % https://drive.google.com/file/d/12d-Hho02r8fMyDTK9zZjw80tNsM6ep20/view?usp=share_link
\vspace{-1em}
\end{figure*}

\paragraph{Dataset and Task} The identification of short functional motifs in DNA is pivotal for understanding gene regulation because these conserved subsequences often serve as transcription factor binding sites or other key regulatory elements~\cite{tompa2005, avsec2021base}. Over the past decade, deep learning methods have further advanced motif discovery by more accurately predicting sequence specificities of DNA- and RNA-binding proteins~\cite{alipanahi2015predicting}, thus refining our ability to pinpoint critical regulatory regions within the genome. Leveraging motif-aware learning for training LLMs, has proven effective for uncovering regulatory and structural elements in genomic sequences ~\cite{wang2024multi, sanabria2024dna}. Motivated by this, we generate a dataset consisting of 48,000 synthetic DNA sequences by a Hidden Markov Model. Each sequence contains one of four functional motifs (referred to as ``needles''): \{TATAAA, CAAT, GGGCGG, TTAGGG\}, and is labeled 0, 1, 2, or 3 accordingly. Notably, the label is represented by an image of a handwritten digit \{\includegraphics[width=0.3cm]{figures/mnist_0.png}, \includegraphics[width=0.3cm]{figures/mnist_1.png}, \includegraphics[width=0.3cm]{figures/mnist_2.png}, \includegraphics[width=0.3cm]{figures/mnist_3.png}\}, sampled from the MNIST dataset~\cite{yadav2019cold}. The dataset is split into finetuning, validation, and test sets in an 8:1:1 ratio.


Following data discretization in \cref{sec:omni-finetuning}, we train a VQ-VAE~\cite{van2017neural} with six quantized vectors of dimension 32 and a compression ratio of 4. This model converts the grayscale images of size $28 \times 28$ into 49 discrete tokens. It leverages a multi-task setting with two tasks: (1) classify the DNA sequences, and (2) generate the corresponding handwritten digit image. The details of dataset construction can be found in \cref{app:needle}.

% \paragraph{Task} The dataset comprises 48,000 synthetic DNA sequences generated using a Hidden Markov Model. Each sequence contains one of four functional motifs (referred to as ``needles''): \{TATAAA, CAAT, GGGCGG, TTAGGG\}. The type of motif uniquely determines the class of the sequence, with sequences containing each motif labeled as 0, 1, 2, or 3, respectively.

% Additionally, each sequence is paired with an image of a handwritten digit \{\includegraphics[width=0.3cm]{figures/mnist_0.png}, \includegraphics[width=0.3cm]{figures/mnist_1.png}, \includegraphics[width=0.3cm]{figures/mnist_2.png}, \includegraphics[width=0.3cm]{figures/mnist_3.png}\}, sampled from the MNIST dataset~\cite{yadav2019cold}. Following data discretization as described in \cref{sec:omni-finetuning}, we train a VQ-VAE~\cite{van2017neural} with six quantized vectors of dimension 32 and a compression ratio of 4. This model converts the grayscale images of size $28 \times 28$ into 49 discrete tokens. The model's task is twofold: (1) classify the DNA sequences based on the embedded motif type, and (2) generate the corresponding handwritten digit image. Details on the dataset construction process can be found in \cref{app:needle}.

\paragraph{Evaluation and Baselines} To assess the benefit of pretraining on DNA sequences, we employ two baselines: OLMo-1B, a natural language model pretrained on text with instruction tuning, and the Vanilla Model, which shares \method's architecture but is randomly initialized without pretraining. The baselines and \method (1B) are all fine-tuned on the fine-tuning dataset for 10 epochs.

The evaluation is conducted by two human annotators who independently assess the images generated by the three models. They provide two labels: (1) validity indicating whether the image represents a number from 
\{0,1,2,3\}, and (2) the corresponding digit if valid. 
Inconsistent answers between annotators are discarded. This labeling process identifies two types of errors: vague or non-meaningful images, and incorrect classification. Thus, two metrics are used to measure model performance: (1) \textbf{invalid percentage}, the proportion of generated images that are non-numeric or not in \{0,1,2,3\}, and (2) \textbf{macro F1 scores}, averaged across all valid samples, for each class.

% The evaluation is conducted by two human annotators who independently assess the images generated by the three models. They provide two labels: (1) whether the image is valid, i.e., it represents one of \{0,1,2,3\}, and (2) the number corresponding to the handwritten digit, assuming the image is valid. Inconsistent answers between the two annotators are discarded. This labeling process identifies two types of errors made by the models: (1) images are vague or do not represent meaningful digits, and (2) the model generates images but incorrectly classifies the given sequence based on the inserted motif (needle). Two metrics are used to measure model performance: (1) \textbf{Invalid Percentage}, which measures the percentage of examples generated by the model that are either non-numeric or do not belong to \{0,1,2,3\}, and (2) for the remaining valid examples, Macro F1 and Per-Class F1 scores are calculated.


\paragraph{Results} Figure~\ref{fig:dna2iamge} shows that \method achieves a Macro F1 score of 0.987 and an invalid percentage of 1\% on average, significantly outperforming baselines. This indicates that \method nearly solves the task perfectly. In contrast, while OLMo-1B has a high F1 score in the motifs TATAAA (class 0) and CAAT (class 1), it struggles with GGGCGG (class 2) and TTAGGG (class 3). Since its invalid percentages are similar across these classes, the primary issue is generating incorrect digit images, indicating that OLMo-1B fails to classify DNA sequences accurately.


% \paragraph{Results} The results are presented in Figure~\ref{fig:dna2iamge}. Omni-DNA achieves the best overall Macro F1 score of 0.987, significantly higher than the two baselines, and also has a lower invalid percentage. This indicates that Omni-DNA nearly solves the task perfectly. In contrast, while the Vanilla Model and OLMo-1B can effectively classify the \{TATAAA, CAAT\} motifs, they struggle with classifying the latter two motifs, \{GGGCGG, TTAGGG\}, and tend to generate a high number of invalid images.


\paragraph{Beyond Memorization} Our visualization results demonstrate that Omni-DNA does not merely memorize the finetuned images, but actually generates novel handwritten digits with various shapes. We verify that these examples are not present in the fine-tuning set, indicating that the model learns general digit patterns in \{0,1,2,3\} conceptually rather than memorizing discretized tokens. See \cref{fig:mnist_sample} for generated examples.



% \paragraph{Beyond Memorization} Our evaluation demonstrates that Omni-DNA does not merely memorize the training images but can generate novel handwritten digits of various shapes. We verify that these examples are not present in the training set, indicating that the model learns the general patterns corresponding to the digits \{0,1,2,3\} at a conceptual level rather than just memorizing the discretized tokens. Please refer to the examples generated by the three models in \cref{app:needle}.

