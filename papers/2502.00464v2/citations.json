[
  {
    "index": 0,
    "papers": [
      {
        "key": "shi2022learning",
        "author": "Shi, B. and Hsu, W. N. and Lakhotia, K. and Mohamed, A.",
        "title": "Learning audio-visual speech representation by masked multimodal cluster prediction"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "prajwal2021sub",
        "author": "Prajwal, K. R. and Afouras, T. and Zisserman, A.",
        "title": "Sub-Word Level Lip Reading With Visual Attention"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ma2022visual",
        "author": "Ma, P. and Petridis, S. and Pantic, M.",
        "title": "Visual Speech Recognition for Multiple Languages in the Wild"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gulati20_interspeech",
        "author": "A. Gulati and J. Qin and C. C. Chiu and N. Parmar and Y. Zhang and J. Yu and W. Han and S. Wang and Z. Zhang and Y. Wu and R. Pang",
        "title": "{Conformer: Convolution-augmented Transformer for Speech Recognition}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "watanabe2017ctcattention",
        "author": "Watanabe, S. and Hori, T. and Kim, S. and Hershey, J. R. and Hayashi, T.",
        "title": "Hybrid CTC/Attention Architecture for End-to-End Speech Recognition"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "son2017lrs2",
        "author": "Son Chung, J. and Senior, A. and Vinyals, O. and Zisserman, A.",
        "title": "Lip reading sentences in the wild"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "afouras2018lrs3",
        "author": "Afouras, T. and Chung, J.-S. and Zisserman, A.",
        "title": "L{RS3}-{TED}: a large-scale dataset for visual speech recognition"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ma2023auto",
        "author": "Ma, P. and Haliassos, A. and Fernandez-Lopez, A. and Chen, H. and Petridis, S. and Pantic, M.",
        "title": "Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels"
      },
      {
        "key": "liu2023synthvsr",
        "author": "Liu, X. and Lakomkin, E. and Vougioukas, K. and Ma, P. and Chen, H. and Xie, R. and Doulaty, M. and Moritz, N. and Kolar, J. and Petridis, S. and Pantic, M. and Fuegen, C.",
        "title": "{SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "fernandez2017towards",
        "author": "Fernandez-Lopez, A. and Martinez, O. and Sukno, F. M.",
        "title": "Towards estimating the upper bound of visual-speech recognition: The visual lip-reading feasibility database"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "adriana2022alr",
        "author": "Fernandez-Lopez, A. and Sukno, F. M.",
        "title": "End-to-{E}nd {L}ip-{R}eading {W}ithout {L}arge-{S}cale {D}ata"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "gimeno2024continuous",
        "author": "Gimeno-G{\\'o}mez, D. and Mart{\\'\\i}nez-Hinarejos, C.-D.",
        "title": "{Continuous lipreading based on acoustic temporal alignments}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "lrec2022liprtve",
        "author": "D. Gimeno-G\u00f3mez and C.-D. Mart\u00ednez-Hinarejos",
        "title": "L{IP-RTVE}: {A}n {A}udiovisual {D}atabase for {C}ontinuous {S}panish in the {W}ild"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "ma2022visual",
        "author": "Ma, P. and Petridis, S. and Pantic, M.",
        "title": "Visual Speech Recognition for Multiple Languages in the Wild"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "salesky21_interspeech",
        "author": "E. Salesky and M. Wiesner and J. Bremerman and R. Cattoni and M. Negri and M. Turchi and D. W. Oard and M. Post",
        "title": "{The Multilingual TEDx Corpus for Speech Recognition and Translation}"
      },
      {
        "key": "anwar23muavic",
        "author": "M. Anwar and B. Shi and V. Goswami and W. Hsu and J. Pino and C. Wang",
        "title": "{MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition and Robust Speech-to-Text Translation}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "zadeh2020moseas",
        "author": "Zadeh, A. B. and Cao, Y. and Hessner, S. and Liang, P. P. and Poria, S. and Morency, L.-P.",
        "title": "C{MU-MOSEAS}: A Multimodal Language Dataset for Spanish, Portuguese, German and French"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "yeo2024limited",
        "author": "Yeo, J. H. and Kim, M. and Watanabe, S. and Ro, Y. M.",
        "title": "Visual Speech Recognition for Languages with Limited Labeled Data Using Automatic Labels from Whisper"
      }
    ]
  }
]