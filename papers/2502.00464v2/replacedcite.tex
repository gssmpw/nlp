\section{Related Work}
\label{sec:related}

This section presents a brief description focused on the current state of the art in VSR, as well as an overview of how the Spanish language has been addressed in the field.

\noindent\textbf{Current State of the Art.} ____ introduced AV-HuBERT, a cross-modal encoder trained in a self-supervised manner using both the acoustic and visual cues. Then, once robust visual speech representations were obtained, an end-to-end VSR system was estimated after assembling a Transformer-based decoder. ____ not only defined an attention module especially aimed at extracting representative visual features, but also explored a subword-level recognition, arguing that it might be useful to better model visual ambiguities. ____ showed that, apart from the importance of designing an appropriate architecture through the use of Conformer encoders ____ and hybrid CTC/Attention decoders ____, incorporating auxiliary tasks, like using enriched acoustic representations to guide the visual feature encoding, might lead to further advances in the field. Details about this architecture can be found in Section \ref{sec:vsr}. In general terms, all these works reached performances around 25-30\% WER for the English corpora LRS2-BBC ____, and LRS3-TED ____. Notably, various studies ____ have recently significantly surpassed this performance by designing methods that rely not only on models comprising vast amounts of parameters, but also on additional large-scale datasets, including synthetic video data, for their pre-training. Therefore, the current performances around 15-20\% WER are not directly comparable to our case study, which focuses on conditions with limited resources.

\noindent\textbf{Spanish Visual Speech Recognition.} ____ presented the VLRF corpus, whose primary purpose was assessing the VSR task's feasibility. In further research ____, the authors designed an end-to-end architecture, reporting results of around 72\% WER. In one of our prior works ____, we proposed a method to improve the performance of traditional HMM-based systems for VSR, achieving performances of approximately 60\% WER. Additionally, we presented the challenging LIP-RTVE database ____ and proposed a traditional approach as a baseline. However, while the speaker-dependent provided around 80\% WER, acceptable results were not reached for the speaker-independent scenario, with roughly 95\% WER. Recently, multiple languages, including Spanish, were considered in ____, achieving 56.6\% and 44.6\% WER for the Spanish partition of the MuAViC ____, and the CMU-MOSEAS ____ corpora, respectively. Similarly to English, more recent pre-trained, large-scales models ____ have been explored, surpassing the state of the art in MuAVic with results around 46\% WER. Details on all these Spanish databases considered in our proposed lipreading benchmark are described in Section \ref{sec:databases}.