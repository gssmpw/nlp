\newcommand{\NEXTROW}{\\[5pt] \hline \\[-9pt]}

\begin{table*}[h]
    \centering
    \small
    \renewcommand{\arraystretch}{1.2}
    \caption{A qualitative comparison of features and prerequisites among state-of-the-art VLN systems.}
    \resizebox{\textwidth}{!}{\begin{tabular}{lclllll}
    \Xhline{2\arrayrulewidth}
    \textbf{VLN System} &
    \textbf{Focus} &
    \textbf{Prerequisites} &
    \textbf{Sensing Modality} &
    \textbf{Output Type} &
    \textbf{Deployment} &
    \textbf{Evaluation} \\
    \Xhline{2\arrayrulewidth} \\[-8pt]
    
    % ==================== CLIP-Nav ====================
    CLIP-Nav~\cite{dorbala2022clipnav} &
    % >> Focus
    Scene &
    % >> Prerequisites
    \Large{$^\text{Pre-captured Images of}_\text{candidate locations}$} &
    % >> In-task Sensor Requirements
    N/A &
    % >> Output Type
    \Large{$^\text{Choice of an Image}_\text{for Next Step}$} &
    % >> Experiment
    Simulation &
    % >> Evaluation Metrics
    \Large{$^\text{Success rate}_\text{(relative)}$}
    \NEXTROW
    % ==================== COW (CLIP on Wheels) ====================
    CLIP on Wheels~\cite{Gadre2022CoWsOP} &
    % >> Focus
    Object &
    % >> Prerequisites
    Unspecified &
    % >> In-task Sensor Requirements
    RGB-D Camera &
    % >> Output Type
    \Large{$^\text{Revalance map of}_\text{the current View}$} &
    % >> Experiment
    Simulation &
    % >> Evaluation Metrics
    \Large{$^\text{Accuracy \&}_\text{Path length}$}
    \NEXTROW
    % ==================== SEEK ====================
    SEEK~\cite{Ginting2024Seek} &
    % >> Focus
    Object &
    % >> Prerequisites
    \Large{$^\text{Pre-built dynamic scene graph}_\text{and relational semantic network}$} &
    % >> In-task Sensor Requirements
    \Large{$^\text{LiDAR, 3 RGB Cameras}_\text{Real-time SLAM}$} &
    % >> Output Type
    \Large{$^\text{Sequence of}_\text{Waypoints}$} &
    % >> Experiment
    % They claimed to have real world experiments, but it's only the "pictures"
    % collected from real world. Not physical robot is used.
    Real World &
    % >> Evaluation Metrics
    \Large{$^\text{Success rate \&}_\text{Path length}$}
    \NEXTROW
    % ==================== PLACEHOLDER ====================
    GCN for Navigation~\cite{kiran2022spatialrelationgraphgraph} &
    % >> Focus
    Object &
    % >> Prerequisites
    \Large{$^\text{Pre-constructed knowledge}_\text{graph of object relations}$} &
    % >> In-task Sensor Requirements
    Monocular RGB Camera &
    % >> Output Type
    \Large{$^\text{Choice of a Pre-}_\text{encoded Action}$} &
    % >> Experiment
    Simulation &
    % >> Evaluation Metrics
    \Large{$^\text{Path length \&}_\text{Success rate}$}
    \NEXTROW
    % ==================== PLACEHOLDER ====================
    Chen~\etal~\cite{Savarese-RSS-19} &
    % >> Focus
    Scene &
    % >> Prerequisites
    \Large{$^\text{Pre-constructed node graph}_\text{of navigable space}$} &
    % >> In-task Sensor Requirements
    N/A &
    % >> Output Type
    Choice of Next Node &
    % >> Experiment
    Simulation &
    % >> Evaluation Metrics
    \Large{$^\text{Success rate \&}_\text{Completion Rate}$}
    \NEXTROW
    % ==================== ClipRover ====================
    \textbf{ClipRover\,\ding{72}} &
    % >> Focus
    Hybrid &
    % >> Prerequisites
    None &
    % >> In-task Sensor Requirements
    Monocular RGB Camera &
    % >> Output Type
    \Large{$^\text{Direct Motion}_\text{Commands (3\textsubscript{DOF})}$} &
    % >> Experiment
    Real World &
    % >> Evaluation Metrics
    \Large{$^\text{Path length \&}_\text{Success rate}$}
    \\ [5pt]
    % ==================== END OF TABLE ====================
    \Xhline{2\arrayrulewidth}
    \end{tabular}}
    \label{tab:vln-comparison}
    \vspace{-2mm}
\end{table*}
