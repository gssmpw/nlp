% WACV 2025 Paper Template
% based on the WACV 2024 template, which is
% based on the CVPR 2023 template (https://media.icml.cc/Conferences/CVPR2023/cvpr2023-author_kit-v1_1-1.zip) with 2-track changes from the WACV 2023 template (https://github.com/wacv-pcs/WACV-2023-Author-Kit)
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage[applications]{wacv}      % To produce the REVIEW version for the algorithms track
%\usepackage[review,applications]{wacv}      % To produce the REVIEW version for the applications track
%\usepackage{wacv}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{wacv} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{tabularx}
\usepackage{csvsimple}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\wacvPaperID{*****} % *** Enter the WACV Paper ID here
\def\confName{WACV}
\def\confYear{2025}

% Définition de la commande \keywords
\providecommand{\keywords}[1]{\textbf{\textit{Keywords : }} #1}
\newcommand{\nd}[1]  {{\bf \textcolor{red}{{\fbox{nd:} #1}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Supplementary Material\\
\small A High-Accuracy SSIM-based Scoring System for Coin Die Link Identification}

\author{
}
%First Author\\
%Institution1\\
%Institution1 address\\
%{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
%\and
%Second Author\\
%Institution2\\
%First line of institution2 address\\
%{\tt\small secondauthor@i2.org}
%}
\maketitle

\section{Datasets}
The Juillac treasure was discovered in 2011 in the municipality of L'Isle-Jourdain (Gers, France). The datasets used for our work come from the scientific study of this important treasure. It contains more than 23,200 Roman coins, mainly dated between 294 and 313 AD. The archaeologists and numismatists studying this hoard analyzed each coin, which is documented on both sides (called the obverse and reverse) with a digital photograph and several descriptive headings, six of which are used for this research. For the obverse, there are three headings: the text of the legend engraved around the portrait of the emperor (his name and titles), the bust code (he can be draped, armoured, bareheaded, with headdress, on the left, on the right, etc.), and the ribbon code which specifies the type of attachment for the crown worn by the emperor. On the reverse, these are: the text of the legend engraved around the figure represented (often the name of a divinity or allegory), the reverse code (describing the divinity or allegory), and the mark of the mint that produced the coin (London, Trier, Lyon, Rome, Carthage, etc.). An example is given in the 
Fig. \ref{fig:coin_6_carac}). 

\begin{figure}
    \centering
	  \includegraphics[width=0.7\linewidth]{figures/Intro/Coin_6_carac_netb.jpg}
	  \caption{1) Obverse legend = \textbf{FL VAL CONSTANTINVS NOB C}; 2) Ribbon code = \textbf{3} (i.e. 2 vertical ribbons); 3) Bust code = \textbf{A*2} (i.e. bust laureate, draped, cuirassed, right, view from rear); 4) Obverse legend = \textbf{GENIO POP ROM}; 5) Reverse code = \textbf{genio 6} (i.e. \textit{Genius}, turreted, draped, standing left, holding \textit{patera} in right hand and \textit{cornucopiae} in left hand); 6) Mint mark = \textbf{S $|$ A // PTR} (i.e “S$|$A” emission, struck at \textit{Prima officina}, Treveri mint)}
	  \label{fig:coin_6_carac} 
\end{figure}

These six headings alone make it possible to classify all the coins by type of obverse and type of reverse. If we only keep the types composed of at least two coins, the database thus contains 658 different types of reverse (from 2 to 1 395 coins), and 379 different types of obverse (from 2 to 1 255 coins). For the study of this hoard, the numismatists created an innovative database in the field of large hoards. It allows easy access to the record of each coin and, more importantly, to the coins of each previously identified type, enabling comparisons between pairs of coins. The visual analysis of die links has thus started for certain types of obverse or reverse. At the time of our work, this is the case for coins from the \textit{Ticinum} mint, with a relatively small number of coins examined (lots numbering from 2 to 93). Eight sets are used as references, called here DS1, DS2, ..., DS8. Their types are listed in Table \ref{tab:tab_datasets_informations_numism}. The numismatists allowed us to use and publicly share these datasets.









%%% ANNEXE
\begin{table}
\caption{Numismatic information about the datasets}
\footnotesize
    \begin{center}
        \begin{tabular}{ccc} 
        %\begin{tabular}{c{1.5cm}c{1.5cm}c{1.5cm}} 
            \hline 
            Dataset  & Type Legend   & Mint mark      \\
            \hline
            DS1             &  GENIO POPV-LI ROMANI               &  * | - // ST  \\
            DS2             &  GENIO POPV-LI ROMANI               &  - | - // T \\
            DS3             &  PROVIDENTIA DEORVM QVIES AVGG      &  - | • // TT \\
            DS4             &  SACRA MONET AVGG - ET CAESS NOSTR  &  - | - // ST• \\
            DS5             &  SACRA MONET AVGG ET CAESS NOSTR    &  - | * // TT \\
            DS6             &  SACRA MONET AVGG ET CAESS NOSTR    &  - | V // AQP \\
            DS7             &  VIRTVS AV-GG ET CAESS NN           &  - | - // AQ$\Gamma$ \\
            %Г \\
            DS8             &  VIRTVS AV-GG ET CAESS NN           &  A | - // PT \\
            \hline
        \end{tabular}
        \label{tab:tab_datasets_informations_numism}
    \end{center}
\end{table}


\section{Clustering Performances}
Table \ref{tab:res} shows all the results obtained for the 5 best-performing clustering predictions coming from two clustering techniques, namely \textit{Agglomerative Clustering with single linkage} (AC) and \textit{Bayesian Distance Clustering including both Cohesion and Repulsion terms in the likelihood} (CoRe) from \cite{Cohesion}.


\begin{table*}[t]
\footnotesize
\caption{Clustering performances (SSIM vs Procruste-based distance)}
\label{tab:res}
\centering
%\renewcommand{\arraystretch}{0.8}
\csvreader[
  tabular=|c|c|c|c|c|c|c|c||c|c|c|c|c|c|,
  table head= \multicolumn{2}{c}{} & \multicolumn{6}{c}{  \textbf{SSIM-based distance}} & \multicolumn{6}{c}{  \textbf{Procrustes-based distance}} \\
  \hline   Clust. &  ds &  ARI & NMI & Prec. & Rec. & $F_1$ & Acc. & ARI & NMI & Prec. & Rec. & $F_1$ & Acc.,
    late after line=,
    before line=\ifthenelse{\equal{\csvcolii}{} \OR \equal{\csvcolii}{mea} \OR \equal{\csvcolii}{med} \OR \equal{\csvcolii}{min} \OR \equal{\csvcolii}{max} }{\\}{\\\hline},
    table foot = \\\hline,
]{results_latex.csv}{}
{\csvcolii & \csvcoli & \csvcoliii & \csvcoliv & \csvcolv & \csvcolvi & \csvcolvii & \csvcolviii & \csvcolix & \csvcolx & \csvcolxi & \csvcolxii & \csvcolxiii & \csvcolxiv}
\end{table*}



While the latter does not need any threshold to be defined beforehand, this is the case for AC. To this end, given a dataset, we use the other ones to estimate the best threshold, just like in the Leave-One-Out cross-validation procedure: once the optimal thresholds for each of the other datasets have been computed using the ground truth, several decision thresholds can be defined for the selected dataset: the maximum, the mean, the median, and the minimum of the optimal thresholds computed using the other datasets, resulting in the $AC_{max}$, $AC_{mean}$, $AC_{med}$ and $AC_{min}$ clustering techniques (see Table \ref{tab:res}).
Note that the use of other linkages with Agglomerative Clustering (\textit{complete} and \textit{average} linkages) lead to the same results, and the other clustering techniques tested (k-means, k-medoids, and CoRe without repulsion term) resulted in very poor clustering predictions. The presented results were computed using Scikit-learn \cite{scikit-learn} and the package provided with the paper on CoRe \cite{Cohesion}.

Agglomerative Clustering with single linkage gets the best results with the max threshold aggregation strategy ($AC_{max}$), then with the mean ($AC_{mea}$) and median ($AC_{med}$) threshold aggregation strategies (which have similar results), and finally with the min threshold aggregation strategy ($AC_{min}$), which performs as well as $CoRe$.




%%%%%%%%% REFERENCES
{\small
%\bibliographystyle{ieee_fullname}
\bibliographystyle{plainurl}
%\bibliography{egbib}
\bibliography{accadil}

\end{document}
