\section{Method}
Previous studies have demonstrated the feasibility and effectiveness of human-AI collaborative source search in addressing fatal problems encountered in search problems (e.g., local optimum, dead end, infinite loop)~\cite{zhao2022crowd,zhao2023leveraging}. However, this approach comes with significant costs and imposes considerable burdens on human workers. Therefore, to answer \textbf{\textit{RQ2}}, we elaborate on the design of a large models-assisted source search method and explain how could it achieve human-like scene understanding and multi-step reasoning.

\subsection{Method Overview}
In this section, we show the design of AutoS$^2$earch, and introduce how MLLM and LLM can be used during the search process to improve the effectiveness and efficiency of search algorithms. There are various ways to achieve this goal in search. Here, we designed a straightforward workflow where the MLLM dynamically interprets visual data from a web-based display interface, converting it into detailed language descriptions for the LLM's CoT reasoning. Notably, no changes are made inside the search algorithm. The overview of the method is shown in as Fig.~\ref{fig:workflow}. Similar to the workflow of human-AI collaborative search (Fig.~\ref{fig:workflow}(a)), AutoS$^2$earch follows three main steps: initialization, execution, and end.\textit{ The main distinction lies in the execution phase, where AutoS$^2$earch incorporates four core components: machine-driven problem detection, machine-generated prompt explanations, problem description by the MLLM, and reasoning and acting by the LLM.} Except for the problem detection mechanism, the subsequent steps are totally different with those in our previous work~\cite{zhao2023leveraging}. In this work, we leverage human rationale to carefully design prompts, eliminating the need for human intervention after the method is initiated, as the problem-solving process is entirely handled by large models. Our approach helps reduce labor costs and accelerates problem-solving response time.  

% In the following, we explain the four main parts in detail. 


\begin{figure}[htbp]
    \centering
    \includegraphics[width=.95\linewidth]{fig2.jpg}
    \caption{The schematic diagram of the AutoS$^2$earch method.}
    \label{fig:workflow}
\end{figure}

\subsection{The Workflow Design of AutoS$^2$earch}

The prototype system was designed following the method outlined in Fig.~\ref{fig:workflow}(b), employing Infotaxis as the source searching algorithm. Infotaxis is one of the most popular cognitive search strategies, known for its effectiveness in solving source searching problems~\cite{ristic2016study}.

\textbf{(1) Problem Detection and Task Generation.} Through discussions with experts on the question, “\textit{what fatal problems could be happened during the search process}”, we have already identified common problems found in source search algorithms, such as local optima and deadlocks. Details can be found in \cite{zhao2023leveraging}. These issues can be detected in various ways, with one simple solution being a rule-based mechanism that automatically identifies the problematic search states and pauses the search process. A task is then generated and pushed to the web, seeking assistance from MLLMs and LLMs to facilitate effective problem-solving. A screenshot of the crowdsourcing task is shown in Fig.~\ref{fig:system}.

\textbf{(2) Task Explanation for Prompt Design.} AI explanations hold great promise in the field of deep learning. However, explaining problems and search algorithms differs significantly from this domain. To help human workers or large models understand more intuitively, language and visuals are two highly effective means. While search algorithms are clear, the search process (e.g., search states) often remains hidden, making it hard to explain using language alone. Thus, we present key graphic elements to MLLMs or human workers by combining human rationale and AI algorithms, as shown in Fig.~\ref{fig:explanation}. These elements are identified through discussions with human experts and are specifically designed for providing explanations and suggestions. To understand the current situation, the robotic searcher's current position, occupied areas, passable areas, and unexplored areas should be prioritized for display. Additionally, to help large models better understand and make decisions, the task could provide a solution suggestion or some directional choices. The solution suggestion features a source estimation method that uses Bayesian inference and sequential Monte
Carlo methods to show the distribution of the posterior probability of the source location (see green particles in Fig.~\ref{fig:system}). Moreover, We also defined four regions—A, B, C, and D—around the robot's current position, representing the top-left, bottom-left, top-right, and bottom-right passable areas nearest to the unexplored areas. The potential goal and four directional choices are critical for large models to understand the problem and to reason better decisions.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.85\linewidth]{fig3.pdf}
    \caption{Elements needed to be presented while explaining the search algorithm and the problem.}
    \label{fig:explanation}
\end{figure}

\textbf{(3) Visual-Language Conversion by MLLM.}
When the task is explained through graphic elements, it comes to large models' turn to address the problem that a search algorithm cannot handle on its own. Using graphic elements as visual input, we specifically designed prompts for MLLMs. The main purpose of the prompt is to provide a hierarchical description of the situation around the four directional choices. The description is closely related to the search environment, current location of the searcher, and posterior probability distribution of the source location. The specific prompt for the MLLM is given.

% prompt
\begin{center}
\begin{minipage}{\linewidth}
\begin{shaded}
% \centering
\textit{\textbf{Prompt for MLLM}}

\textbf{Task Description:}  
Based on the graphic elements, identify the candidate target areas marked with letters in the image. Area A is marked in red; Area B in purple; Area C in blue; and Area D in yellow. Then provide a sequential description of each existing area, focusing on two main aspects for each:  
1. Distance to the dense green dot regions (classified as: Far, Medium, or Close)  
2. Density of surrounding unexplored black areas (classified as: High, Medium, or Low)  

\textbf{Output Format Example (assuming Area B does not exist):}  

Area A:  
Distance to dense green dot region: Far  
Density of surrounding unexplored areas: Low  

Area C:  
Distance to dense green dot region: Medium  
Density of surrounding unexplored areas: Medium  

Area D:  
Distance to dense green dot region: Close  
Density of surrounding unexplored areas: High  
  

\textbf{Please describe the information for all existing areas in the image following this output format.}
\end{shaded}
\end{minipage}
\end{center}

\textbf{(4) Reasoning and Acting by LLM.} Based on the structured descriptions generated by the MLLM, we defined prioritized decision-making rules to enable the LLM to perform optimal strategy selection through chain-of-thought reasoning. These rules include: (1) Ignore non-existent areas (to prevent hallucinations of MLLMs); (2) Prioritize areas with the shortest distance to the dense green dot region; (3) Prioritize areas with the highest density of surrounding unexplored areas. The specific prompt for the LLM is given.


\begin{center}
\begin{minipage}{\linewidth}
\begin{shaded}
% \centering
\textit{\textbf{CoT Prompt for LLM}}

\textbf{Task Description:}
Based on the structured descriptions provided by the MLLM, identify and output the single highest-priority area by following the rules below:

\textbf{Core Rules (in descending order of priority):}

1. Exclude non-existent regions.  

2. Prioritize the region closest to the dense green dot cluster.  

3. Prioritize the region with the highest density of surrounding unexplored black areas.

\textbf{Output Requirements:}

- Provide a single region letter (e.g., "C") as the result.

- Include a detailed reasoning process leading to the selection of the region.

\end{shaded}
\end{minipage}
\end{center}












