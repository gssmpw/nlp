\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/size-f1.pdf}
    \caption{
    \textbf{F1 scores as a function of universe size $n$.}
    We evaluate LLM performance on questions with $\leq 10$ reasoning steps, and report F1 scores averaged over 3 dataset generation seeds.
    As we increase universe size in \ours, F1 scores for all LLMs and prompting techniques deteriorate, highlighting that they struggle at retrieving relevant documents.
    }
    \label{fig:size-f1}
\end{figure*}

\section{Evaluating Retrieval}
\label{sec:retrieval}

Next, to evaluate LLM retrieval capabilities, we use \ours to contrast two settings: (1) small universes where the document corpus can comfortably fit in LLM context, and (2) large universes where the full corpus exceeds context lengths.
To this end, we increase the universe size up to $n =10$K, which corresponds to document corpora well beyond the context lengths of state-of-the-art LLMs, and display the results in \Cref{fig:size-f1}.

For very small universes, \CoT usually outperforms \zeroshot for all LLMs except \deepseek.
However, F1 scores noticeably worsen as more documents are included in models' contexts, with \deepseek suffering a dramatic performance drop.This analysis regime indicates that \textbf{state-of-the-art LLMs struggle at in-context retrieval} for complex question-answering tasks.

At the large universe scale, \simpleprompting techniques become nonviable as the document corpus exceeds model context lengths.
Therefore the use of out-of-context retrieval, such as \ragprompting and \agenticprompting techniques, is necessary for obtaining the answers.
Here we observe that \ragprompting techniques, which select relevant documents for the question using vector embeddings, deliver poor F1 scores for all universe sizes---the performance only deteriorates with increasing universe size.
\Agenticprompting techniques like \react show immense promise by avoiding a steep downward trend.
This suggests that \textbf{agentic workflows can be effective in dynamically retrieving documents at scale}.