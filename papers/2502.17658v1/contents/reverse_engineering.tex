


% \begin{figure}[!t]
%     \centering
%    \includegraphics[width=\linewidth] {images/AMXarch_new_v1.pdf} 
%     \caption{Intel AMX Architecture Overview}
%     \label{fig:AMX-arch}
% \end{figure}

% \subsection{Intel AMX Architecture and Instructions.}
% Intel AMX is an integrated accelerator introduced with the 4th Gen Intel Xeon Scalable processors, specifically engineered to boost the efficiency of matrix computations. %Figure~\ref{fig:AMX-arch} illustrates the Intel AMX architecture.

% AMX introduces a new set of registers and instructions. The registers in Intel AMX are known as Tiles, a new concept in Intel CPUs that provide a matrix of data registers, as opposed to the traditional vector registers seen in previous SIMD architectures like AVX-512. AMX includes 8 Tile registers, each capable of holding up to 16 rows with 64 bytes per row, amounting to a total of 1 KB per Tile. The number of rows and the number of bytes per row can be adjusted using the LDTILECFG instruction, and this configuration information is stored as metadata in a control register known as TILECFG. Once this configuration is set, AMX instructions such as load, store, and matrix multiplication will operate according to the specified dimensions for each Tile. Intel AMX instructions are synchronized with the Intel Architecture host (IA host) instruction stream, and the Tile loads and stores are coherent with the host memory \cite{Intel_Arc_Ins_Set_Extensions}.

% Tile Matrix Multiply unit (TMUL) serves as the accelerator engine for executing multiplication calculations. When using full-size Tile operands, the latency of the multiplication instruction is 52 cycles, while pipelining allows for a throughput of 16 cycles. Intel AMX supports two data types: BF16 and INT8. Consequently, it can perform 512 multiplications and 512 additions per cycle for BF16 and 1024 multiplications and 1024 additions per cycle for INT8 \cite{IntelOptRefManual}. 

% \begin{comment}
% AMX instructions utilize port 5 as their dedicated execution port. When two hyper-threads are active within a core, they compete for the same resources to execute AMX instructions.
% \end{comment}

\section{Reverse Engineering}
In this section, we share our findings on Intel AMX obtained through reverse engineering. In our investigations, we utilized a server running Red Hat Enterprise Linux release 9.3 (Plow), equipped with Linux kernel version 5.14. The server is powered by two Intel(R) Xeon(R) Gold 5420+ CPUs. 
We did not disable any hardware features or mitigations.

\textbf{Performance States Characterization.} 
In an experiment, we measured how long it takes to execute a single AMX multiplication instruction while varying the intervals between consecutive executions. To simulate the conditions of a typical program, we added non-AMX instructions during these intervals. By changing the length of these intervals, we observed five distinct execution times for the AMX multiplication instruction. We classified these into performance states, with the shortest execution time labeled as the "Warm State." The longer execution times are referred to as "Cold States," specifically Cold State 1 (the second shortest), Cold State 2, Cold State 3, and Cold State 4 (the longest).  Figure \ref{fig:Performance_Stages} visually represents these performance states. 

%\begin{figure}[!hbp]
%\centering\includegraphics[width=0.4\textwidth]{images/sleepstages_new_v2.pdf}
%\caption{Illustration of the Five Distinct Performance States of TMUL.}
%\label{fig:Performance_Stages}
%\end{figure}
%{\color{blue} Change the figure: bias, change the ylabel, and States }

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            xmin=100, xmax=1000000000,
            ymin=10, ymax=100000,
            xlabel={Interval Delay (Cycle)},
            ylabel={Multiplication Execution\\Time (Cycle)},
            xmode=log, 
            ymode=log,
            log basis x=10, 
            log basis y=10,
            grid=both,
            major grid style={line width=0pt,draw=white!50},
            minor grid style={line width=0pt,draw=white!20},
            font=\scriptsize,
            ylabel style={yshift=0pt, align=center}, 
            width=\linewidth*1,
            height=\linewidth*0.45,
        ]
            \addplot[darkgray, thick] table {Diagrams/Data/warmup.txt};
        \end{axis}
        
        \draw[->, black, thick] (2.1,0.45) -- (1.1,0.45) node[midway, above] {\scriptsize Warm State};
         \node[gray, thick] at (1.05,1.3) {\scriptsize Cold State 1};
         \node[gray, thick] at (2.8,1.7) {\scriptsize Cold State 2};
         \node[gray, thick] at (4.9,1.85) {\scriptsize Cold State 3};
         \node[gray, thick] at (6.4,2.15) {\scriptsize Cold State 4};
         
    \end{tikzpicture}
    \caption{llustration of the Five Distinct Performance States of
TMUL.}
    \label{fig:Performance_Stages}
\end{figure}

%\begin{spacing}{1}
% \begin{lstlisting}
% for(int i = 0; i < ITERS;i++) {
%   Time = __rdtscp();// Timer
%   for (int k = 0; k < i; k++)// Delay
%      junk = junk + k;
%   cooldown_delay[i] = __rdtscp() - Time; 
%   Time =  __rdtscp()
%   AMX_INSTRUCTION();//e.g_tile_dpbssd(0, 1, 2)
%   execution_time[i] = __rdtscp() - Time; }
% \end{lstlisting}
%\end{spacing}

\textbf{Impact of CPU Frequency on Performance States.} 
In a supplementary experiment, we investigated how changing the CPU frequency, using the "cpufreq" feature, affects the execution time of the previously identified performance states. For this study, we fixed the CPU frequency at various levels and measured the execution times for each performance state without allowing frequency scaling to adjust it dynamically. 

The results are plotted in Figure \ref{fig:Execution_time_vs_Freq}, where each data point represents a specific CPU frequency setting. Execution time was recorded using the `rdtscp` instruction, which operates with a 2 GHz clock frequency reference. We examined frequencies ranging from 800 MHz to 2 GHz in increments of 100 MHz.

Our findings indicate that the execution time of the AMX multiplication instruction in all Cold States is invariant with respect to changes in the current CPU frequency. In contrast, the Warm State execution time is directly proportional to the current CPU frequency.

%\begin{figure}[!hbp]
%\centering\includegraphics[width=0.4\textwidth]{images/Execution_time_vs_Freq.pdf}
%\caption{Execution Time of AMX Multiplication Across Performance States at Varying CPU Frequencies}
%\label{fig:Execution_time_vs_Freq}
%\end{figure}
%{\color{blue} Put Execution\_time\_vs\_Freq figure here}


\begin{figure}[t!]
\centering
\begin{tikzpicture}
    \begin{axis}[
        xlabel={CPU Frequency (MHz)},
        ylabel={Execution time (RDTSCP cycle)},
        legend pos=outer north east,
        font=\scriptsize,
        xlabel style={yshift=0pt},
        ylabel style={yshift=0pt},
        width=\linewidth*0.8,
        height=\linewidth*0.45,
        ymode=log,
        log basis y=10,
        legend style={
                legend columns=1, 
                at={(1.02,0.5)}, 
                anchor=west,   
                font=\tiny,
            },
    ]
    
    \addplot[
        thick,
        mark=diamond,
        line width=1.5pt,
        mark size=3,
        color=darkgray
    ] table {Diagrams/Data/freq4.txt};
    \addlegendentry{Cold State 4};

    \addplot[
        thick,
        mark=x,
        line width=1.5pt,
        mark size=3,
        color=darkgray
    ] table {Diagrams/Data/freq3.txt};
    \addlegendentry{Cold State 3};
 
    \addplot[
        thick,
        line width=1.5pt,
        mark=triangle,
        mark size=2,
        color=darkgray
    ] table {Diagrams/Data/freq2.txt};
    \addlegendentry{Cold State 2};

    \addplot[
        thick,
        mark=star,
        line width=1.5pt,
        mark size=3,
        color=darkgray
    ] table {Diagrams/Data/freq1.txt};
    \addlegendentry{Cold State 1};
   
    \addplot[
        thick,
        line width=1.5pt,
        mark=o,
        mark size=2,
        color=red
    ] table {Diagrams/Data/freq0.txt};
    \addlegendentry{Warm State};



    \end{axis}
\end{tikzpicture}
\caption{Execution Time of AMX Multiplication Across Performance States at Varying CPU Frequencies}
\label{fig:Execution_time_vs_Freq}
\end{figure}

\textbf{Transition Behavior of AMX Frequency to CPU Frequency in Warm State.}
Based on the results presented in Figure \ref{fig:Performance_Stages}, the execution of the TMUL multiplication instruction occurs in Cold State 4 (the longest execution time) when either the operation is performed for the first time or follows a period of inactivity exceeding approximately 20 ms. If subsequent AMX multiplication instructions follow closely, all will operate in the Warm State, which is common in programs with extensive matrix multiplications.

We further examined the execution time in the Warm State immediately after entry, over a fixed duration, across different CPU frequencies. Our observations revealed that the AMX multiplication execution time undergoes a transition period before stabilizing. Closer analysis shows that these variations are related to the AMX's internal frequency adjustments. During this transition period, AMX adjusts its frequency from a lower value towards the current CPU frequency, temporarily using intermediate frequencies.

Figure \ref{fig:Freq_transition} illustrates how the AMX frequency adjusts to align with the CPU frequency. When the CPU frequency is set to 1.2 GHz, the AMX frequency initially ramps up, briefly stabilizes at 1 GHz, and eventually reaches the target frequency of 1.2 GHz. Similarly, when the CPU frequency is fixed at 2 GHz, the AMX frequency transitions through intermediate stages, operating at 1 GHz and 1.3 GHz before stabilizing at 2 GHz.

These findings demonstrate that Intel AMX includes a frequency management unit that controls the operating frequency of the TMUL accelerator. This unit can potentially access or create frequencies that differ from the CPU frequency.

%\begin{figure}[!hbp]
%\centering\includegraphics[width=0.4\textwidth]{images/Freq_transition.pdf}
%\caption{Illustration of AMX Frequency Adjustment During Transition Periods: (a) shows the transition to a 1.2 GHz CPU frequency, with intermediate operation at 1 GHz; (b) demonstrates the adjustment to a 2 GHz CPU frequency, passing through 1 GHz and 1.3 GHz stages.}
%\label{fig:Freq_transition}
%\end{figure}
%{\color{blue} Put Freq\_transition figure here}

\begin{figure}[h!]
\centering
\begin{tikzpicture}
    \begin{axis}[
        xlabel={Number of Instructions},
        ylabel={Execution Time (RDTSCP cycle)},
        legend pos=outer north east,
        font=\scriptsize,
        xlabel style={yshift=5pt},
        ylabel style={yshift=-15pt},
        width=\linewidth*1,
        height=\linewidth*0.45,
        xmin= -0.1,xmax=40000,
        legend style={
                legend columns=-1,
                at={(0.5,1.16)},
                anchor=north, 
                font=\tiny,
                /tikz/column 2/.style={column sep=5pt}, 
            },
    ]
    
    \addplot[
        line width=0.8pt,
        color=black,
    ] table {Diagrams/Data/1400MHz.txt};
    \addlegendentry{1.2 GHz
CPU frequency};


    \addplot[
        line width=0.8pt,
        color=lightgray,
    ] table {Diagrams/Data/2000MHz.txt};
    \addlegendentry{2 GHz
CPU frequency};

    \end{axis}
    
    \node[darkgray, thick] at (2.7,1.57) {\scriptsize 1 GHz};
    \node[darkgray, thick] at (5.7,1.175) {\scriptsize 1.2 GHz};
    \node[darkgray, thick] at (2.5,1.01) {\scriptsize 1.3 GHz};
    \node[darkgray, thick] at (5.5,0.37) {\scriptsize 2 GHz};
\end{tikzpicture}
\caption{Illustration of AMX Frequency Adjustment During Transition Periods: The black graph depicts the transition to a 1.2 GHz CPU frequency, with intermediate operation at 1 GHz; The gray graph demonstrates the adjustment to a 2 GHz CPU frequency, passing through 1 GHz and 1.3 GHz stages.}
\label{fig:Freq_transition}
\end{figure}

\textbf{Impact of Operand Sparsity on TMUL Transition in Warm State.}
In our investigation of the TMUL execution time transition in the Warm State, we discovered an interesting effect involving zero values in the Tile operands during multiplication. By varying the number of zero values in the operands, we observed that increasing the number of zeros accelerates the transition period. This effect is illustrated in Figure \ref{fig:Effect_of_zeros_on_transition}, which presents three graphs depicting operand sparsity levels: 100\% sparsity, 50\% sparsity, and 0\% sparsity. In Figure \ref{fig:Effect_of_zeros_on_transition}, with the CPU frequency fixed at 2 GHz, the results indicate that higher operand sparsity in the Tile operands leads to faster convergence of the TMUL frequency to the CPU frequency.

%\begin{figure}[!hbp]
%\centering\includegraphics[width=0.4\textwidth]{images/Effect_of_zeros_on_transition.pdf}
%\caption{Impact of Operand Sparsity on the Transition Period of TMUL Frequency: The graphs depict the transition behavior with 100\%, 50\%, and 0\% sparsity levels in the Tile operands, showing faster convergence to the CPU frequency with increased sparsity.}
%\label{fig:Effect_of_zeros_on_transition}
%\end{figure}
%{\color{blue} Put Freq\_transition figure here}

\begin{figure}[h!]
\centering
\begin{tikzpicture}
    \begin{axis}[
        xlabel={Number of Instructions},
        ylabel={Execution Time (RDTSCP cycle)},
        legend pos=outer north east,
        font=\scriptsize,
        xlabel style={yshift=5pt},
        ylabel style={yshift=-15pt},
        width=\linewidth*1,
        height=\linewidth*0.48,
        xmin= -0.1,xmax=40000,
        legend style={
                legend columns=-1,
                at={(0.5,1.16)},
                anchor=north, 
                font=\tiny,
                /tikz/column 2/.style={column sep=5pt}, 
            },
    ]
    
    \addplot[
        line width=0.8pt,
        color=black,
    ] table {Diagrams/Data/2000_0Perc.txt};
    \addlegendentry{0\% Sparcity};


    \addplot[
        line width=0.8pt,
        color=lightgray,
    ] table {Diagrams/Data/2000_50Perc.txt};
    \addlegendentry{50\% Sparcity};


    \addplot[
        line width=0.8pt,
        color=gray,
    ] table {Diagrams/Data/2000_100Perc.txt};
    \addlegendentry{100\% Sparcity};

    \end{axis}
    
    \node[darkgray, thick] at (1.2,0.57) {\scriptsize 1.8 GHz};
    \node[darkgray, thick] at (1.9,1.95) {\scriptsize 1 GHz};
    \node[darkgray, thick] at (2,1.23) {\scriptsize 1.3 GHz};
    \node[darkgray, thick] at (5.5,0.4) {\scriptsize 2 GHz};
\end{tikzpicture}
\caption{Impact of Operand Sparsity on the Transition Period of TMUL Frequency: The graphs depict the transition behavior with 100\%, 50\%, and 0\% sparsity levels in the Tile operands, showing faster convergence to the CPU frequency with increased sparsity.}
\label{fig:Effect_of_zeros_on_transition}
\end{figure}

Consequently, the execution time of a program utilizing AMX multiplications is closely associated with the sparsity of its input operands. In Figure \ref{fig:Cumulative_execution_time}, we demonstrate this relationship by executing two test programs with 100 and 1000 AMX multiplications, each with varying Tile operand sparsity levels (0\%, 50\%, and 100\%). To construct the histogram, each scenario was executed 1,000 times. Our results reveal that varying levels of sparsity significantly impact the cumulative execution time of AMX multiplications, with increased sparsity leading to faster program execution.

This discovery uncovers a new value-dependent timing side channel that reveals the sparsity of Tile operands in Intel AMX.

% \begin{figure}[htbp!]
%     \centering
%     \begin{tikzpicture}
%         \begin{axis}[
%             font=\scriptsize,
%             width=\linewidth*0.95,
%             height=\linewidth*0.35,
%             bar width=50,
%             xmin=21800, xmax=24650,
%             xlabel={Execution time (cycle)},
%             ybar,
%             ylabel={Frequency},
%             ylabel style={yshift=-15pt},
%             ymin=0, ymax=0.006,
%             legend style={
%                 at={(0.5,1)}, 
%                 anchor=north, 
%                 legend columns=-1,
%                 font=\scriptsize,
%                 /tikz/column 2/.style={column sep=5pt}, 
%                 fill=none,
%                 draw=none
%             },
%             legend image code/.code={\draw[fill=#1,draw=none] (0cm,-0.1cm) rectangle (0.25cm,0.1cm);},
%             legend entries={100\% sparsity, 50\% sparsity, 0\% sparsity}
%         ]
%             \addplot+[hist={density, bins=50}, fill=lightgray, draw=none] table[y index=0] {Diagrams/Data/100-0.txt};
%             \addplot+[hist={density, bins=50}, fill=black, draw=none] table[y index=0] {Diagrams/Data/100-half.txt};
%             \addplot+[hist={density, bins=50}, fill=gray, draw=none] table[y index=0] {Diagrams/Data/100-1.txt};
%         \end{axis}
%         \node[anchor=south east] at (rel axis cs:-0.05,1) {(a)};
%     \end{tikzpicture}
%     \begin{tikzpicture}
%         \begin{axis}[
%             font=\scriptsize,
%             width=\linewidth*0.95,
%             height=\linewidth*0.35,
%             bar width=50,
%             xmin=35500, xmax=56000,
%             xlabel={Execution time (cycle)},
%             ybar,
%             ylabel={Frequency},
%             ylabel style={yshift=-15pt},
%             ymin=0, ymax=0.0024,
%             legend style={
%                 at={(0.5,1)}, 
%                 anchor=north, 
%                 legend columns=-1,
%                 font=\scriptsize,
%                 /tikz/column 2/.style={column sep=5pt}, 
%                 fill=none,
%                 draw=none
%             },
%             legend image code/.code={\draw[fill=#1,draw=none] (0cm,-0.1cm) rectangle (0.25cm,0.1cm);},
%             legend entries={100\% sparsity, 50\% sparsity, 0\% sparsity}
%         ]
%             \addplot+[hist={density, bins=60}, fill=lightgray, draw=none] table[y index=0] {Diagrams/Data/1000-0.txt};
%             \addplot+[hist={density, bins=60}, fill=black, draw=none] table[y index=0] {Diagrams/Data/1000-half.txt};
%             \addplot+[hist={density, bins=60}, fill=gray, draw=none] table[y index=0] {Diagrams/Data/1000-1.txt};
%         \end{axis}
%         \node[anchor=south east] at (rel axis cs:-0.05,1) {(b)};
%     \end{tikzpicture}
%     \begin{comment}
%     \begin{tikzpicture}
%         \begin{axis}[
%             font=\scriptsize,
%             width=\linewidth*0.95,
%             height=\linewidth*0.5,
%             bar width=50,
%             xmin=170000, xmax=345000,
%             xlabel={Execution time (cycle)},
%             ybar,
%             ylabel={Frequency},
%             ylabel style={yshift=-15pt},
%             ymin=0, ymax=0.00022,
%             legend style={
%                 at={(0.5,1)}, 
%                 anchor=north, 
%                 legend columns=-1,
%                 font=\scriptsize,
%                 /tikz/column 2/.style={column sep=5pt}, 
%                 fill=none,
%                 draw=none
%             },
%             legend image code/.code={\draw[fill=#1,draw=none] (0cm,-0.1cm) rectangle (0.25cm,0.1cm);},
%             legend entries={100\% sparsity, 50\% sparsity, 0\% sparsity}
%         ]
%             \addplot+[hist={density, bins=60}, fill=lightgray, draw=none] table[y index=0] {Diagrams/Data/10000-0.txt};
%             \addplot+[hist={density, bins=60}, fill=black, draw=none] table[y index=0] {Diagrams/Data/10000-half.txt};
%             \addplot+[hist={density, bins=60}, fill=gray, draw=none] table[y index=0] {Diagrams/Data/10000-1.txt};
%         \end{axis}
%         \node[anchor=south east] at (rel axis cs:-0.05,1) {(c)};
%     \end{tikzpicture}
%     \end{comment}
% \begin{comment}
% \caption{Cumulative Execution Time of Programs with Varying Operand Sparsity: The histogram illustrates the effect of operand sparsity on program execution time, highlighting that higher sparsity levels result in quicker execution across different counts of AMX multiplications. Subfigures (a), (b), and (c) represent programs with 100, 1,000, and 10,000 AMX multiplications, respectively.}
% \end{comment}
% \caption{Cumulative Execution Time of Programs with Varying Operand Sparsity: The histogram illustrates the effect of operand sparsity on program execution time, highlighting that higher sparsity levels result in quicker execution across different counts of AMX multiplications. Subfigures (a) and (b) represent programs with 100 and 1,000 AMX multiplications, respectively.}
% \label{fig:Cumulative_execution_time}
% \end{figure}


%\begin{figure}[!htbp]
%\centerline{\includegraphics[width=0.35\textwidth]{images/new_pic.pdf}}
%\caption{Cumulative Execution Time of Programs with Varying Operand Sparsity: The %histogram illustrates the effect of operand sparsity on program execution time, %highlighting that higher sparsity levels result in quicker execution across %different counts of AMX multiplications. Subfigures (a), (b), and (c) represent %programs with 100, 1,000, and 10,000 AMX multiplications, respectively.}
%\label{fig:Cumulative_execution_time}
%\end{figure}

\begin{comment}
\textbf{Operand Patterns Influencing Data-Dependent Timing in AMX Multiplications.}
In this part, we describe specific operand patterns that can accelerate the TMUL frequency transition, thereby reducing cumulative execution time. As previously mentioned, Intel AMX supports both BF16 and Int8 operand types. 

For BF16 operands, we examined both normal values and special values, including zero, subnormal, NaN, and infinity. Consider an element \( x \) in the first Tile operand being multiplied by an element \( y \) in the second Tile operand. Our findings indicate that to expedite the frequency transition, at least one of the operands \( x \) or \( y \) should be zero or subnormal, while the other should be a normal value. In Intel AMX, subnormal values are treated as zeros, meaning that if an input is subnormal, it will be considered as zero. Additionally, if an output element falls into the subnormal range, AMX returns zero for that element. Table \ref{tab:BF16Pattern} lists all possible cases for BF16 operands, highlighting those patterns that facilitate quicker transitions.



\begin{table}[ht]
    \centering
    \resizebox{0.49\textwidth}{!}{%
    \begin{tabular}{|c|c|c|c|}
        \hline
        \backslashbox{Operand 1}{Operand 2} & Normal & Zero/Subnormal & NaN/Inf \\ \hline
        Normal & - & \ding{51} & - \\ \hline
        Zero/Subnormal & \ding{51} & \ding{51} & - \\ \hline
        NaN/Inf & - & - & - \\ \hline
    \end{tabular}
    }
    \caption{BF16 Operand Patterns in Intel AMX: Cases marked with \ding{51} indicate patterns that expedite the TMUL frequency adjustment.}
\label{tab:BF16Pattern}
\end{table}

For Int8 operands, the data-dependent pattern involves zero values in two consecutive Int8 entries within a row. Specifically, this occurs in the \(2k\) and \(2k + 1\) columns of the Tiles, where \(k\) ranges from 0 to \(C/2 - 1\), with \(C\) representing the number of bytes in each row of the Tile. Suppose element \( x(r_1,2i) \) and element \( x(r_1,2i+1) \) in the first Tile are multiplied by element \( y(r_2,2j) \) and element \( y(r_2,2j+1) \) in the second Tile, respectively. Table \ref{tab:Int8Pattern} highlights the combinations of these 4 values that lead to a faster frequency transition.

\begin{table}[ht]
    \centering
    \resizebox{0.47\textwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \backslashbox{Operand 1}{Operand 2} & [Z, Z] & [Z, N] & [N, Z] & [N, N] \\ \hline
        {[}Z, Z{]} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\ \hline
        {[}Z, N{]} & \ding{51} & - & \ding{51} & - \\ \hline
        {[}N, Z{]} & \ding{51} & \ding{51} & - & - \\ \hline
        {[}N, N{]} & \ding{51} & - & - & - \\ \hline
    \end{tabular}
    }
    \caption{Int8 Operand Patterns: Entries marked with \ding{51} indicate patterns that accelerate TMUL frequency transition.\newline \small(Z = Zero, N = Non-zero)}
\label{tab:Int8Pattern}
\end{table}

Our results suggest the presence of a zero-skipping mechanism for both BF16 and Int8 operands. The Int8 results indicate that zero-skipping evaluates two bytes concurrently, which is likely due to the simultaneous processing of two Int8 multiplications in a specific pipeline stage within TMUL. Bypassing this pipeline stage necessitates checking both consecutive bytes. We hypothesize that bypassing these Tile element multiplications reduces AMX energy consumption, allowing the frequency management unit to increase TMUL frequency with fewer restrictions. Although the latency and throughput of AMX multiplications are fixed in terms of AMX cycles, they are influenced by operand sparsity when viewed in CPU cycles.

\end{comment}