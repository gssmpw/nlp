\label{sec:ML_Network}
We present a proof of concept for a side-channel attack that leaks the zero weights of the first layer of a neural network by measuring execution time. The techniques we propose for this attack can be applied to similar models implemented with Intel AMX. 

This attack exploits timing differences observed when TMUL enters the Warm State, specifically taking advantage of variations in execution times that occur due to the presence of zeros in the operands. Note that our attack does not require any additional information about the memory layout.


\paragrabf{Setup.}
Our experimental setup involves a single-layer neural network constructed with 64 weights. Each weight is dedicated to one input element and the network is implemented using Intel AMX. For the purpose of this experiment, an adversary controls the input data through the API but does not have access to the weights, which remain unknown to an unprivileged user.

\input{contents/Alg}

The attack process begins with the adversary strategically manipulating the input data and observing the resulting execution times under different conditions. This timing information is then utilized to infer the values of the hidden weights. Algorithm \ref{alg:alg1} is a detailed description of the procedures used to carry out this attack.

In the fully cooled down state, running the AMX multiplier multiple times (N) highlights a clearer distinction based on the number of zeros in the operands. Accordingly, \(P1\) refers to this condition, while \(P2\) introduces a delay, allowing the AMX multiplier to cool down. Given the inherent noise in execution times, we measure these times multiple times (\(M\)) in \(P3\) to produce a less noisy composite value \(T\). This attack methodology does not impose any special precondition, and normal performance optimizations, such as turbo boost, remain enabled. In our general setup, significant timing noise arises with turbo boost active, but we mitigate these effects using differential measurements.

\paragrabf{Setting Threshold.}
By comparing execution times with inputs of full zeros and full non-zeros, we establish a differential threshold (\(Thr\)), as outlined in the algorithm \ref{alg:alg1} (Lines 1-5). This threshold enables the selective acceptance of randomly generated input vectors for scoring.The essence of the attack involves two key steps: (1) continuously generating random input vectors throughout the duration of the attack, and (2) using the execution time associated with each vector to accumulate evidence that helps refine the estimates of the weight scores.

Suppose a weight element is non-zero; then, the execution time will be longer if the corresponding input element is non-zero compared to when it is zero. Conversely, if a weight element is zero, the execution time remains unchanged whether the corresponding input element is zero or not. Based on these assumptions, if a generated input vector has a higher number of correct non-zeros according to the unknown weights, it is more likely to be accepted by this algorithm, thereby impacting the scoring tables.

\paragrabf{Execution Time Analysis and Vector Selection.}
The attacker measures the execution times for two scenarios: one for the randomly generated vector (\(W_s\)) and another for its inverted version (\(W_r\)). This is shown in lines 6-9 of Algorithm \ref{alg:alg1}. We predict that the vector holding more correct non-zeros according to the unknown weights will require a longer execution time. As shown in lines 10-15, if the difference in execution times exceeds the threshold, then either \(W_s\) or \(W_r\)—the one which records the longer time—will be selected (\(W_x\)) for updating the score vectors (\(ScoreZ\) and \(ScoreN\)). 

\paragrabf{Updating Scoring Vectors.}
After selecting \(W_x\), a scoring method updates the score vectors according to \(W_x\) entries (Lines 16-22). This involves iterating through each element of \(W_x\) from 0 to 63, incrementing the corresponding entry in \(ScoreZ\) by one if the element is zero, and in \(ScoreN\) if the element is non-zero.

\paragrabf{Inferring Weights from Scoring Vectors.}
Following the attack period, the attacker analyzes the ScoreZ and ScoreN vectors as illustrated in lines 25-31. A weight element marked as zero would be expected to yield similar scores in both \(ScoreZ\) and \(ScoreN\) vectors. However, for a weight element marked as non-zero, a higher score is expected in the \(ScoreN\) vector compared to the \(ScoreZ\).

By dividing each element of \(ScoreN\) by \(ScoreZ\), the attacker can infer the zero weights. If the ratio is close to 1, it suggests that the weight scores are equivalent and thus the weight is likely zero. A ratio significantly above 1 indicates that the weight is likely non-zero.

\paragrabf{Results Analysis.}
After extensive experiments, the configurable parameters in Algorithm \ref{alg:alg1} were selected to the following values: \(N=10000\), \(M=40\), \(L=20\), \(K=3\), \(\alpha=0.9\), and \(\gamma=1.13\), which were effective in demonstrating the outcome. Prolonging the attack duration reduces noise in the scores and enhances the success rate of accurately determining the weights. 



Figure \ref{fig:ML_SuccessRate} shows success rates increasing with longer attack durations, from 60\% at 5 minutes to a complete 100\% success rate at 50 minutes (0.02 bit/s) and beyond. Since cooling down the AMX is necessary for every timing measurement, over 99\% of the attack duration is consumed by cooling delays. Additionally, the results of the algorithm for two different attack durations are shown in Figure \ref{fig:LeakedWeights}. 







%%%%%%%%From ISCA 

\subsubsection{Instruction Reuse Dependency} \label{sec:stages}
In an experiment, we measured how long it takes to execute a single AMX multiplication instruction while varying the intervals between consecutive executions. 

% % \begin{lstlisting}[frame=single, numbers=left, caption={Pseudocode to generate Figure~\ref{fig:sleepstages}}, label={lst:ars-gadget1}]
% \begin{center}
% \begin{minipage}{0.8\linewidth}
% \centering
% \begin{lstlisting}[frame=single, numbers=left, caption={Test for Instruction Reuse Timing Dependency Detection}, label={lst:ars-gadget1}, basicstyle=\scriptsize\ttfamily, captionpos=b]
%     t = RDTSCP()
%     TDPBSSD %tmm0, %tmm1, %tmm2
%     while (RDTSCP() < t + interval_delay) {}
%     start = RDTSCP()
%     TDPBSSD %tmm3, %tmm4, %tmm5
%     end = RDTSCP()
%     report end-start
% \end{lstlisting}
% \end{minipage}
% \end{center}

% In Listing~\ref{lst:ars-gadget1}, we present the high-level pseudocode that generated Figure~\ref{fig:Performance_Stages}. In line 1, we obtain the current time using the highest available resolution timer on the platform, e.g. \texttt{RDTSCP} on x86. In line 2, we perform a \texttt{TDPBSSD} - AMX signed integer-signed integer matrix to warm up the TMUL unit. In particular, we matrix-multiply the contents of the tile register TMM0 and TMM1 and store the result in TMM2. In line 3, we wait for a particular time, doing nothing. To simulate the conditions of a typical program, we added non-AMX instructions during these intervals.  On lines 4-6, we time the execution time of a \texttt{TDPBSSD}, making sure to use different registers than the operation on line 2 to ensure that there isn't some identical operand optimization we are measuring. We finally report the time on line 7.


% \begin{figure}[!htbp]
%     \centering
%     \begin{tikzpicture}
%         \begin{axis}[
%             xmin=100, xmax=1000000000,
%             ymin=10,
%             xlabel={Interval Delay (Cycle)},
%             ylabel={Multiplication Execution\\Time (Cycle)},
%             xmode=log, 
%             ymode=log,
%             log basis x=10, 
%             log basis y=10,
%             grid=both,
%             major grid style={line width=0pt,draw=white!50},
%             minor grid style={line width=0pt,draw=white!20},
%             font=\scriptsize,
%             ylabel style={yshift=0pt, align=center}, 
%             width=\linewidth*0.8,
%             height=\linewidth*0.4,
%         ]
%             \addplot[darkgray, thick] table {Diagrams/Data/warmup.txt};
%         \end{axis}
        
%         \draw[->, black, thick] (1.1,0.39) -- (0.75,0.38) node[midway, above] {\tiny };
%          \node[black, thick] at (1.6,0.39) {\tiny Warm State};
%          \node[gray, thick] at (1.3,0.9) {\tiny Cold State 1};
%          \node[gray, thick] at (1.9,1.3) {\tiny Cold State 2};
%          \node[gray, thick] at (3.8,1.45) {\tiny Cold State 3};
%          \node[gray, thick] at (5,1.75) {\tiny Cold State 4};
         
%     \end{tikzpicture}
%     \caption{Five Distinct Performance States of
% TMUL.}
%     \label{fig:Performance_Stages}
% \end{figure}




%In Figure~\ref{fig:Performance_Stages}, w
We observe that the latency of a \texttt{TDPBSSD} (signed-signed 8-bit integer matrix multiplication) differs depending on the time since the AMX unit was last used, ie \textit{ reuse}. 
By changing the length of these intervals, we observed five distinct execution times for the AMX multiplication instruction.  We noticed that this latency goes through five distinct \textit{performance stages} which correspond to a 50, 600, 6000, 9000, and 20000 tsc latency to perform a \texttt{TDPBSSD}. We classified these into performance states, with the shortest execution time labeled as the "Warm State", the longer execution times are referred to as "Cold States" specifically Cold State 1 (the second shortest), Cold State 2, Cold State 3, and Cold State 4 (the longest).  
%Figure \ref{fig:Performance_Stages} visually represents these performance states. 

%Thus, execution time can serve as a proxy for Instruction Reuse/Utilization. 
%The methodology used here can be applied to other instructions by replacing the AMX instruction with specific operations and systematically varying the reuse intervals. 
%By varying the interval delay between successive executions of AMX instructions, a secret value can be transmitted to the attacker through time measurement, and the attacker can manipulate Intel AMX utilization through instruction reuse to bring the AMX performance state to the known state.
% \begin{tcolorbox}[
%     colback=lightgray!20,    % Light grey background
%     colframe=gray!50,        % Light gray border
%     boxrule=0.3mm,           % Thin border thickness
%     arc=2mm,                 % Slightly rounded corners
%     width=0.48\textwidth,     % Half the page width
%     sharp corners=all,
%     left=2mm,                % Adjust left padding
%     right=2mm,               % Adjust right padding
%     top=1mm,                 % Adjust top padding
%     bottom=1mm               % Adjust bottom padding
% ]
%  % {Thus, execution time can serve as a proxy for Instruction Reuse/Utilization. The methodology used here can be applied to other instructions by replacing the AMX instruction with specific operations and systematically varying reuse intervals. By varying the interval delay between successive executions of AMX instructions a secret value can be transmitted to the attacker through time measurement, and attacker can manipulate Intel AMX utilization through instruction reuse to bring the AMX performance state to the known state.}
% \end{tcolorbox}

%We hypothesize that these five stages are related to frequency scaling. Notably, this phenomenon is observable with both Intel Turbo Boost enabled and disabled. In the next steps, we will investigate that. 

%\subsection{Impact of CPU Frequency on Performance States.} 
\subsubsection{Frequency Dependency } \label{sec:frequencyDependency}
%In a supplementary experiment, 
Next, we investigated how changing the CPU frequency, using the "cpufreq" feature, affects the execution time of the previously identified performance states. For this study, we fixed the CPU frequency at various levels and measured the execution times for each performance state without allowing frequency scaling to adjust it dynamically.  
%

\begin{figure}[t!]
\centering
\begin{tikzpicture}
    \begin{axis}[
        xlabel={CPU Frequency (MHz)},
        ylabel={Execution time (RDTSCP cycle)},
        legend pos=outer north east,
        font=\scriptsize,
        xlabel style={yshift=0pt},
        ylabel style={yshift=0pt},
        width=\linewidth*0.5,
        height=\linewidth*0.6,
        ymode=log,
        log basis y=10,
        legend style={
                legend columns=1, 
                at={(1.02,0.5)}, 
                anchor=west,   
                font=\tiny,
            },
    ]
    
    \addplot[
        thick,
        mark=diamond,
        line width=1.5pt,
        mark size=3,
        color=darkgray
    ] table {Diagrams/Data/freq4.txt};
    \addlegendentry{Cold State 4};

    \addplot[
        thick,
        mark=x,
        line width=1.5pt,
        mark size=3,
        color=darkgray
    ] table {Diagrams/Data/freq3.txt};
    \addlegendentry{Cold State 3};
 
    \addplot[
        thick,
        line width=1.5pt,
        mark=triangle,
        mark size=2,
        color=darkgray
    ] table {Diagrams/Data/freq2.txt};
    \addlegendentry{Cold State 2};

    \addplot[
        thick,
        mark=star,
        line width=1.5pt,
        mark size=3,
        color=darkgray
    ] table {Diagrams/Data/freq1.txt};
    \addlegendentry{Cold State 1};
   
    \addplot[
        thick,
        line width=1.5pt,
        mark=o,
        mark size=2,
        color=red
    ] table {Diagrams/Data/freq0.txt};
    \addlegendentry{Warm State};



    \end{axis}
\end{tikzpicture}
\caption{Execution Time of AMX Multiplication Across Performance States at Varying CPU Frequencies}
\label{fig:Execution_time_vs_Freq}
\end{figure}
The results are plotted in Figure \ref{fig:Execution_time_vs_Freq}, where each data point represents a specific CPU frequency setting. The execution time was recorded using the `rdtscp` instruction, which operates with a clock frequency reference of 2 GHz. We examined frequencies ranging from 800 MHz to 2 GHz in increments of 100 MHz, and we observed two key behaviors:
\begin{itemize}%[leftmargin=*, labelsep=0.5em]
    \item \textbf{Cold States Invariance:} For all Cold States (Cold State 1 through Cold State 4), the execution time remains \textbf{invariant} regardless of CPU frequency. For example, Cold State 4 consistently shows the longest execution time across all frequencies, emphasizing its independence from the CPU clock.
    \item \textbf{Warm State Dependency:} In contrast, the execution time in the Warm State is directly proportional to the CPU frequency, with faster frequencies yielding reduced execution times. For example, at 800 MHz, the Warm-State execution time is approximately \textbf{ 2.5 times higher} than at 2 GHz.
\end{itemize}

% This result highlights the adaptive nature of Intel AMX, where execution time in Warm State aligns closely with the current CPU frequency, while Cold States exhibit no such dependency. This behavior suggests an internal frequency adjustment mechanism within AMX.

% Our findings indicate that the execution time of the AMX multiplication instruction in all Cold States is invariant with respect to changes in the current CPU frequency. 
% %In contrast, the Warm State execution time is directly proportional to the current CPU frequency.
% In contrast, in the Warm State, performance is directly proportional to the current CPU frequency.

% \begin{tcolorbox}[ colback=lightgray!20,
% colframe=gray!50,
% boxrule=0.3mm,
% arc=2mm,
% width=0.5\textwidth,
% sharp corners=all, left=2mm,
% right=2mm,
% top=1mm,
% bottom=1mm
% ] CPU frequency acts as a proxy for AMX performance in the Warm State, with execution times directly proportional to the execution time/latency.  \end{tcolorbox}








% We respectively term these stage 0, stage 1, stage 2, stage 3, and stage 4. 


%     \begin{figure}[!ht]
% \centering
%     \includegraphics[width=0.5\textwidth]{Loki_images/sleepstages_new_v2.pdf}
%     \caption{The sleep stages of AMX. By inserting a wait (x-axis) between two TDPBSSD instructions we found that the execution time of the second TDPBSSD changed based on the length of the wait. %\SMAcomments{Please do not use scientific number! }
%     }
%     \label{fig:sleepstages}
% \end{figure}


%\begin{spacing}{1}
% \begin{lstlisting}
% for(int i = 0; i < ITERS;i++) {
%   Time = __rdtscp();// Timer
%   for (int k = 0; k < i; k++)// Delay
%      junk = junk + k;
%   cooldown_delay[i] = __rdtscp() - Time; 
%   Time =  __rdtscp()
%   AMX_INSTRUCTION();//e.g_tile_dpbssd(0, 1, 2)
%   execution_time[i] = __rdtscp() - Time; }
% \end{lstlisting}
%\end{spacing}

Based on this, we hypothesize that the five performance stages are caused by Intel AMX operating on a separate clock from the CPU, and that this clock frequency adjusts depending on AMX utilization for power and energy efficiency to increase performance and also remain under the core power limit. To verify this, we performed the following test.

%\subsection{Transition Behavior of AMX Frequency to CPU Frequency in Warm State.}
%\subsubsection{On the Root Cause of Performance Stages} \label{sec:rootcause}
Based on the results presented in Figure \ref{fig:Performance_Stages}, the execution of the TMUL multiplication instruction occurs in Cold State 4 (the longest execution time) when the operation is performed for the first time or follows a period of inactivity exceeding approximately 20 ms. If subsequent AMX multiplication instructions follow closely, all will operate in the Warm State, which is common in programs with extensive matrix multiplications.
%
To test this, we further examined the execution time in the Warm State immediately after entry, over a fixed duration, across different CPU frequencies. We changed the CPU frequency and repeat the previous experiment. 
Our observations revealed that the AMX multiplication execution time undergoes a transition period before stabilizing. Closer analysis shows that these variations are related to the AMX's internal frequency adjustments. During this transition period, AMX adjusts its frequency from a lower value towards the current CPU frequency, temporarily using intermediate frequencies. To this end, we assumed that Intel AMX has a distinct clock and functions at different frequencies in each stage. To verify, we calculated such frequency by AMX throughput at each stage. We see that the stages change to where this calculated frequency becomes equal to the set frequency of the CPU which we controlled confirming our hypothesis. 


Figure \ref{fig:Freq_transition} illustrates how the AMX frequency is adjusted to align with the CPU frequency. When the CPU frequency is set to 1.2 GHz, the AMX frequency initially ramps up, briefly stabilizes at 1 GHz, and eventually reaches the target frequency of 1.2 GHz. Similarly, when the CPU frequency is fixed at 2 GHz, the AMX frequency transitions through intermediate stages, operating at 1 GHz and 1.3 GHz before stabilizing at 2 GHz. 
These findings show that Intel AMX includes a frequency management unit that controls the operating frequency of the TMUL accelerator. This unit can potentially access or create frequencies that differ from the CPU frequency as shown as the Transition Behavior of AMX Frequency to CPU Frequency in the Warm State. 
This finding is in contrast to the root cause known for AVX performance variation, known as power up/down~\cite{netspectre} which does not vary with the core frequency.
%%%END of ISCA