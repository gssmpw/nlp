Here, we discuss significant related works and potential countermeasures relevant to our Thor attack.

\paragrabf{Hertzbleed \cite{wang2022hertzbleed}.}
Hertzbleed leverages dynamic voltage and frequency scaling (DVFS) to transform power side-channel attacks into timing attacks. By exploiting the timing differences caused by frequency variations, even remote attacks become feasible. For instance, in an attack against Supersingular Isogeny Key Encapsulation (SIKE), they managed to recover 378 bits of the private key within 36 hours. Although this attack shares similarities with our work in exploiting frequency changes, DVFS can be managed by the CPU core and disabled in BIOS settings to mitigate the Hertzbleed attack. However, in our case, disabling DVFS is not a viable countermeasure since AMX, an on-chip accelerator, manages its power and frequency independently.

\paragrabf{Collide+Power \cite{kogler2023collide+}.}
The Collide+Power research focuses on the power leakage of the memory hierarchy via Running Average Power Limit (RAPL). If RAPL is unavailable, monitoring can be done through a throttling side-channel, albeit requiring more measurements. They demonstrated two types of attacks: Meltdown-style and Microarchitectural Data Sampling (MDS)-style. In Meltdown-style, targeting a shared cache among two processes on different cores, theoretically, one bit can be leaked in 99.95 days with power limit control or 2.86 years with stress-induced throttling. In MDS-style, where both victim and attacker run on different logical cores of the same physical core, data can be leaked from the L1/L2 cache at a rate of 4.82 bits per hour. Disabling simultaneous multithreading can mitigate MDS-style attacks. Generally, RAPL being a privileged interface is not accessible to unprivileged attackers, and throttling can be disabled by turning off DVFS.

\paragrabf{Platypus \cite{Lipp2021Platypus}.}
The Platypus attack reconstructed 509 RSA key bits using RAPL MSRs within Intel SGX enclaves. However, this attack vector has been mitigated by making RAPL a privileged interface.

\paragrabf{Neural Network Specific Attacks.}
Several studies have attacked neural network accelerators using power side channels. In the work by Wei et al. \cite{wei2018know}, an FPGA-based convolutional neural network accelerator was attacked, requiring physical access to recover the model's input image with up to 89\% accuracy. Effective mitigations include masking and random scheduling, although masking introduces significant overheads, as demonstrated in MaskedNet \cite{dubey2020maskednet}, increasing latency and area costs by 2.8x and 2.3x, respectively.

Open DNN Box \cite{Xiang2019OpenDB} inferred the weight sparsity of neural network models with 96.5\% accuracy on average. CSI NN \cite{236204} used power and electromagnetic traces to infer information about weights and architecture in fully connected neural networks. DeepEM \cite{Yu2020DeepEMDN} and DeepSniffer \cite{Hu2020DeepSnifferAD} collected electromagnetic traces to glean architectural information, with DeepEM specifically targeting binarized neural networks. Cache Telepathy \cite{244042}, GANRED \cite{Liu2020GANREDGR}, and DeepRecon \cite{Hong2018SecurityAO} employed well-known cache side channels like Flush+Reload and Prime+Probe to gather neural network insights. For these cache attacks, the attacker runs locally, and the presence of a shared cache is necessary. In contrast, our Thor attack doesn't need physical access or shared cache. It introduces a novel, data-dependent timing side-channel vulnerability specific to Intel AMX accelerators.

In the work by Gongye et al. \cite{9218707}, they attacked DNNs using a floating-point timing side channel to obtain weights and biases. They took advantage of the drastically different execution times for floating-point multiplication and addition in certain scenarios, such as when dealing with subnormal values, to launch their attack. However, with modern accelerators like Intel AMX, this floating-point timing vulnerability has been eliminated. Now, the execution time for tile multiplication remains constant, even for special cases like zero inputs. Specifically, the latency is fixed at 52 cycles and the throughput is 16. Despite this, to attack DNNs with more than one layer, cache monitoring or physical access is still required to measure the execution time of each layer.

% \paragrabf{Potential Countermeasures.}
% Eliminating the cooldown state could defend against Thor but at a high power cost since Intel AMX is an energy-intensive accelerator designed for AI tasks. Keeping AMX continuously active would be power-prohibitive.

% Masking is a proven countermeasure for protecting AI model parameters against power side-channel attacks and could be adapted for future AMX versions despite the performance overhead. Additionally, machine learning models should incorporate techniques to detect unusual usage patterns, which can help identify and thwart attacks attempting to infer parameter values using methods similar to our AMX-type attack. One well-known countermeasure to these timing attacks is to coarsen the timer. By reducing the timer's precision, it becomes much harder for attackers to measure the subtle differences in execution times that they rely on for their exploits.

% In summary, while various countermeasures exist for different attack vectors, protecting against Thor on Intel AMX accelerators requires novel approaches to power and frequency management alongside traditional techniques.


