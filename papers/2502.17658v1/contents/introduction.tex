\newpage

\IEEEPARstart{A}{s} 
computational demands continue to rise, there is a relentless drive towards optimization and advanced design methodologies. One of the latest advancements in this field is Intel's Advanced Matrix Extensions (AMX), an on-chip accelerator integrated into newer processors, starting with the 4th Gen Intel Xeon Scalable processors, known as Sapphire Rapids. Intel AMX provides specialized hardware support, markedly improving the efficiency and speed of matrix multiplications ~\cite{intel2022amx}. While Intel AMX represents a significant advancement in matrix computation and is not vulnerable to previously reported floating-point multiplication timing side-channel attacks ~\cite{7163051}, ~\cite{9218707}, our research uncovers that it inadvertently introduces new pathways for potential security vulnerabilities, particularly in the realm of side-channel attacks.

 % Traditionally, power side-channel attacks require physical access to a system to measure power consumption or electromagnetic emissions. Such attacks are less common and practical because they require a high level of access. However, Lipp et al. \cite{Lipp2021Platypus} demonstrated a method to exploit the Running Average Power Limit (RAPL) interface for power side-channel attacks without needing physical access. Although RAPL is now a privileged interface, this example shows how existing features can be repurposed for malicious intents.

% When designing new microarchitectures, overlooking security considerations can create avenues for hardware attacks. For instance, Dynamic Voltage and Frequency Scaling (DVFS), an optimization technique for power management, can paradoxically open up new attack surfaces by converting power side-channels into timing attacks. This vulnerability was exploited in Hertzbleed \cite{wang2022hertzbleed} to leak data via throttling under power limits, and in Collide+Power \cite{kogler2023collide+}, where power limits and throttling were manipulated to convert memory power side-channels into timing variations. Notably, power limit controls are usually privileged, and throttling can be mitigated by disabling Turbo Boost. As such, our work reveals a new, generic vulnerability in Intel AMX, specifically within its power and performance management mechanisms. Unlike DVFS-related vulnerabilities, our discovered vulnerability persists irrespective of DVFS states and allows for exploitation regardless of whether DVFS is on or off. Additionally, our attack does not require shared cacheâ€”unlike Collide+Power, which necessitates shared cache access to leak data.

% In this paper, we demonstrate the feasibility of exploiting this newly discovered vulnerability in neural network operations to leak sensitive information, such as sparsity of weights. Previous works in the literature have targeted neural network models to infer architectural details, inputs, and weights, often necessitating physical access for power and electromagnetic measurements \cite{236204}, \cite{Hu2020DeepSnifferAD}, \cite{wei2018know}, \cite{Xiang2019OpenDB}, \cite{Yu2020DeepEMDN} or shared cache manipulation via known cache side-channels \cite{Hong2018SecurityAO}, \cite{Liu2020GANREDGR}, \cite{244042}. Our approach is notable for not requiring either physical access or shared cache, thereby significantly lowering the bar for potential attackers.

% Specifically, we investigate the behavior of AMX multiplication, which operates in five distinct states, fluctuating between 52 to 20,000 cycles. We discovered that due to AMX frequency adjustments, the execution times of these multiplications are not consistent when AMX is transitioning between different states. Particularly, after exiting high-latency states and before stabilizing to a steady state, the execution time becomes a data-dependent process. This dependency arises because zero values in the multiplication operands influence the trend of frequency adjustments, creating exploitable timing differences.

% We demonstrate the exploitation of this side-channel vulnerability, showing that the execution time of AMX multiplications can be systematically measured to infer the sparsity of hidden weights of a neural network. In our practical example, we successfully leaked zeros in 64 hidden weights with 100\% accuracy within 50 minutes of observation.

% This paper presents several significant contributions:
% \begin{compactitem}
% \item It identifies a novel type of data-dependent timing side-channel vulnerability within the Intel AMX accelerator.

% \item It demonstrates the techniques necessary to exploit this newly discovered timing side-channel for launching attacks on neural networks. Specifically, it illustrates how to infer zero weights and determine the sparsity of neural network weights solely by measuring execution time.
% \end{compactitem}

% \textbf{Responsible disclosure.}  We reported our attack and findings to Intel. %Moreover, we are planning to open source our code. 