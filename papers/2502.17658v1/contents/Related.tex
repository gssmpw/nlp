\section{Related Works}

%\notema{add some intro words here}

% In this section, we present a background on related micro-architectural attacks, an overview of built-in accelerators and their benefits, as well as a background on Intel AMX instruction and architecture.  


%\subsection{Microarchitectural Side-channel Attacks}
%\{Overview of side-channel attacks, defining covert channel, leakage gadget, etc?}\SMA{ to : No we don't need to explain those.There won't be space.} 
%\SMA{For each attack, add their threat model and parameters that matter to CVSS, such as scope, vector,  complexity, and information that would build context around **your paper's findings**. To help them better appreciate your findings. Not to teach a whole Wikipedia in half a page. }
%\subsubsection{Cache attacks}
%The oldest side-channel attacks are cache attacks. 
%\notema{this section requires some more polishing}
%\notema{osvik: Cache Attacks and Countermeasures: the Case of AES. should be cited as well for prime+probe}

% \begin{figure}[!t]
%     \centering
%    \includegraphics[width=\linewidth]{images/AMXarch_new_v1.pdf} 
%     \caption{Intel AMX Architecture Overview}
%     \label{fig:AMX-arch}
% \end{figure}

% \textbf{{Intel AMX Architecture and Instructions.}}
% Intel AMX is an integrated accelerator introduced with the 4th Gen Intel Xeon Scalable processors, specifically engineered to boost the efficiency of matrix computations that are essential for artificial intelligence and high-performance computing applications. Figure~\ref{fig:AMX-arch} illustrates the Intel AMX architecture.

% AMX introduces a new set of registers and instructions. The registers in Intel AMX are known as Tiles, a new concept in Intel CPUs that provide a matrix of data registers, as opposed to the traditional vector registers seen in previous SIMD architectures like AVX-512. AMX includes 8 Tile registers, each capable of holding up to 16 rows with 64 bytes per row, amounting to a total of 1 KB per Tile. The number of rows and the number of bytes per row can be adjusted using the LDTILECFG instruction, and this configuration information is stored as metadata in a control register known as TILECFG. Once this configuration is set, AMX instructions such as load, store, and matrix multiplication will operate according to the specified dimensions for each Tile. Intel AMX instructions are synchronized with the Intel Architecture host (IA host) instruction stream, and the Tile loads and stores are coherent with the host memory \cite{Intel_Arc_Ins_Set_Extensions}.

% Tile Matrix Multiply unit (TMUL) serves as the accelerator engine for executing multiplication calculations. When using full-size Tile operands, the latency of the multiplication instruction is 52 cycles, while pipelining allows for a throughput of 16 cycles. Intel AMX supports two data types: BF16 and INT8. Consequently, it can perform 512 multiplications and 512 additions per cycle for BF16 and 1024 multiplications and 1024 additions per cycle for INT8 \cite{IntelOptRefManual}. 

% AMX instructions utilize port 5 as their dedicated execution port. When two hyper-threads are active within a core, they compete for the same resources to execute AMX instructions.


\paragrabf{Cache attacks.}
Cache attacks exploit timing differences caused by loading data from different cache levels or the DRAM.
In \PrimeProbe~\cite{prime_probe,osvik2006cache}, the attacker "primes" a cache set and waits for the victim to execute, tracking evictions. Flush+Reload \cite{flush+reload} flushes a cache line and checks if it was filled by the victim.
% Flush+Reload \cite{flush+reload} 
% uses the presence or absence of a variable shared between the attacker and victim (e.g. in a shared library) to deduce a victim's program path.
Flush+Flush attack ~\cite{GrussFlushFlush} relies on the execution time variation of the flush instruction.

%\subsubsection{Speculative \& Transient Attacks} 

\paragrabf{Transient-execution attacks.}
% Spectre \cite{kocher2020spectre}
%is a class of attacks that abuse mechanisms that result in jumps in code (e.g. branch predictor, pattern history table) to speculatively execute certain instructions that have a measurable effect on the microarchitecture (but not the architecture). For example, in Spectre-v1
% %\notema{Use the classification of Canella et al} 
% the branch predictor is mistrained on a particular branch with a value that points to an in-bound variable. The attacker then changes the value to point to an out-of-bounds and causes the branch to execute. Due to out-of-order execution, for a small amount of cycles the incorrect code can execute which, when the measurable microarchitectural change caused by the code is dependent on the out-of-bounds value, can lead to an attacker being able to read the entirety of a process's address space. Other attacks include 
% and Meltdown 
% \cite{meltdown};
Spectre \cite{kocher2020spectre} exploits speculative execution of an operation that would not occur during correct execution path of the program. Meltdown-type attacks \cite{meltdown} exploit delayed
exception handling during out-of-order execution.
% e.g. there was a null pointer access but the check for the exception was executed after other transient instructions were being executed.
Forshadow~\cite{van2018foreshadow}
%\notema{what about foreshadow?} 
exploits a bug in Intel CPUs that led to imperfect isolation of the SGX enclave context, Load Value Injection \cite{lvi} induces execution based on malicious values injected in various microarchitectural buffers, Fallout \cite{canella2019fallout} leaks the contents of the store buffer, and RIDL \cite{ridl} and Zombieload \cite{schwarz2019zombieload} leak the contents of the line fill buffer.


\paragrabf{Software-based power side-channel attacks.}
%\subsubsection{Software Power Side channel attacks like Platypus}
Platypus \cite{Lipp2021Platypus} exploits the RAPL (Running Average Power Limit) driver, to infer the internal state of a program, even inside an SGX enclave. This vulnerability was mitigated by kernel updates restricting RAPL access and Intel microcode updates changing how power is reported in the context of SGX.
%for everything except SGX 
% by restricting RAPL access to privileged users using a kernel update and was mitigated for privileged users through an Intel microcode update that decorrelated the power report from operands in the context of an SGX enclave. 
%\{This is wrong. Intel released a microcode update that changes how power is reported when in the context of an SGX enclave}. \SMA{Who wrote that? Martin?  it seems like someone wrote that was confident. Ohhh I see this is right because with malicious OS, OS has access to RAPL? But Micro code fixed it. So don't say that if we are not sure. }
Collide+Power~\cite{kogler2023collide+} uses a differential power measurement technique involving pairs of inputs with their inverses to leak victim data coexisting with attacker data in the same microarchitectural buffers. 
%\subsubsection{Attacks that exploit accelerators}
% Grand Pwning Unit \cite{frigo2018grand} explored using GPUs to accelerate microarchitectural attacks, specifically RowHammer\notema{Not sure if Rowhammer and GPUs are relevant here..}. They found that since the GPU is accessible from Javascript, it is possible to mount a Rowhammer attack by injecting Javascript code into a web browser. 



%\subsubsection{Remote attacks}
% \paragrabf{Remote timing attacks.}
% Many remote side-channel attacks were solely focusing on cryptographic primitives such as AES or RSA ~\cite{Aciicmez2007d,Brumley2003Remote,Bernstein2005,Zhao2009cache,Jayasinghe2010remote,Aly2013attacking,Saraswat2014}.
% Irazoqui \etal\cite{Irazoqui2015Lucky} attacked TLS in a remote setup leveraging cache timing differences.
% Schwarz \etal\cite{schwarz2019netspectre} demonstrated Spectre attacks in a fully remote setup (with controlled network traffic) leveraging both a cache side channel and an AVX side channel to remotely exfiltrate data.
% \cite{VanGoethem2020Timeless} makes use of the relative timing difference in response time to tackle existing jitter in networks. 
% Moreover, remote attacks were created leaking data by exploiting operating system optimizations ~\cite{Gruss2019page,Schwarzl2022Remote}, DVFS to attack post-quantum cryptography~\cite{wang2022hertzbleed} and the compression ratio~\cite{schwarzl2023practical}.
% %Memory compression attacks work only on programs that employ memory compression like web servers; Loki is more general than this functioning on any program that listens for network requests and utilizes the AMX unit. Hertzbleed relies on dynamic voltage and frequency (DVFS) scaling while Loki works independently of DVFS.

% %\SMA{The immediate  question comes in mind is why we didn't compare with all of these? Are they out of scope? Are they about something else? What is common what is not common. This section without a conclusion in comparison with our work kills our paper. Our paper gets killed without having it as well. Justify. TODO . Also after reading it it feels like our work is not novel so for example say, "Although these works studied remote attacks in this and that condition but they didn't study this or couldnt do that or their impact was weak... on the other hand we .... the comparison with Netspectre and blah blah is given in section blah"}

% \noindent\textbf{{Signal Amplification.}}
% Amplifying a side channel's signal strength, e.g. the timing difference, can significantly reduce noise.
% Roettger and Janc~\cite{Roettger2021A} leveraged the PLRU cache replacement policy in the L1 to arbitrarily amplify a single cache hit. However, it relies on the cache and thus any cache side-channel defense, e.g.\ \cite{Invisispec}, would mitigate this issue. Additionally, this method may be detectable in hardware.
% Hacky Racers~\cite{HackyRacers2023ASPLOS} %introduced "racing gadgets" and "magnifier gadgets" by exploiting 
% exploited instruction-level parallelism enabling timing attacks on restricted system such as JavaScript, although, multiple execution of the "magnifier gadget" in this paper makes it detectable in hardware.  MicroScope \cite{Microscope} addresses the issue of noisy side-channels, which mandates multiple measurements for getting reliable data by utilizing core microarchitectural features to execute dynamic instruction more than once. However, this attack is detectable in hardware, as shown in \cite{EVAX2022Micro,PerSpectron}. Recent papers have enabled performing logical operation on cache signals and amplifying them to the extent that they are visible to even coarse timers, compromising the performance of the attack because of the amplification overhead~\cite{kaplan2023optimization, purnal2023showtime, katzman2023gates}. 
% %\SMA{ , What are the weaknesses in these papers, check leakage rate, accuracy complexity requirement?Why Loki matters when these magnifiers exists}

\textbf{{Side-channel attacks that leak ML parameters.}}
Wei et al. \cite{wei2018know} were able to reconstruct the user inputs only by knowing the structure of the underlying CNN through measuring the power profile. Similarly, \cite{zhang2021stealing, tian2021remote} extracted neural network structure from FPGA using power side-channels.
\cite{dubey2020maskednet}, uses differential power analysis to extract parameters of a NN.

% {This paragraph needs review. (Not well written.)}

% \SMA{I agree,  it shouldn't be only about what it leaks (Impact) for example Forshadow leaks kernel, it should be about their method Key idea/root cause of vulnerability and also Impact.}
% \notema{canella defined a difference between spectre and meltdown - spectre exploits mispredictions by the branch predictor leading to transient accesses while for meltdown-type effects the underlying root cause is delayed
% exception handling during out-of-order execution. e.g. there was a null pointer access but the check for the exception was executed after other transient instructions were being executed.}

% %\subsubsection{Rowhammer}
% \paragrabf{Software-based power side-channel attacks.}
% %\subsubsection{Software Power Side channel attacks like Platypus}
% Platypus \cite{Lipp2021Platypus} exploits the RAPL (Running Average Power Limit) driver, to infer the internal state of a program, even inside an SGX enclave. This vulnerability was mitigated by kernel updates restricting RAPL access and Intel microcode updates changing how power is reported in the context of SGX.
% %for everything except SGX 
% % by restricting RAPL access to privileged users using a kernel update and was mitigated for privileged users through an Intel microcode update that decorrelated the power report from operands in the context of an SGX enclave. 
% %\{This is wrong. Intel released a microcode update that changes how power is reported when in the context of an SGX enclave}. \SMA{Who wrote that? Martin?  it seems like someone wrote that was confident. Ohhh I see this is right because with malicious OS, OS has access to RAPL? But Micro code fixed it. So don't say that if we are not sure. }
% Collide+Power~\cite{kogler2023collide+} uses a differential power measurement technique involving pairs of inputs with their inverses to leak victim data coexisting with attacker data in the same microarchitectural buffers. 
% %\subsubsection{Attacks that exploit accelerators}
% % Grand Pwning Unit \cite{frigo2018grand} explored using GPUs to accelerate microarchitectural attacks, specifically RowHammer\notema{Not sure if Rowhammer and GPUs are relevant here..}. They found that since the GPU is accessible from Javascript, it is possible to mount a Rowhammer attack by injecting Javascript code into a web browser. 



% %\subsubsection{Remote attacks}
% \paragrabf{Remote timing attacks.}
% Many remote side-channel attacks were solely focusing on cryptographic primitives such as AES or RSA ~\cite{Aciicmez2007d,Brumley2003Remote,Bernstein2005,Zhao2009cache,Jayasinghe2010remote,Aly2013attacking,Saraswat2014}.
% Irazoqui \etal\cite{Irazoqui2015Lucky} attacked TLS in a remote setup leveraging cache timing differences.
% Schwarz \etal\cite{schwarz2019netspectre} demonstrated Spectre attacks in a fully remote setup (with controlled network traffic) leveraging both a cache side channel and an AVX side channel to remotely exfiltrate data.
% \cite{VanGoethem2020Timeless} makes use of the relative timing difference in response time to tackle existing jitter in networks. 
% Moreover, remote attacks were created leaking data by exploiting operating system optimizations ~\cite{Gruss2019page,Schwarzl2022Remote}, DVFS to attack post-quantum cryptography~\cite{wang2022hertzbleed} and the compression ratio~\cite{schwarzl2023practical}.
% %Memory compression attacks work only on programs that employ memory compression like web servers; Loki is more general than this functioning on any program that listens for network requests and utilizes the AMX unit. Hertzbleed relies on dynamic voltage and frequency (DVFS) scaling while Loki works independently of DVFS.

% %\SMA{The immediate  question comes in mind is why we didn't compare with all of these? Are they out of scope? Are they about something else? What is common what is not common. This section without a conclusion in comparison with our work kills our paper. Our paper gets killed without having it as well. Justify. TODO . Also after reading it it feels like our work is not novel so for example say, "Although these works studied remote attacks in this and that condition but they didn't study this or couldnt do that or their impact was weak... on the other hand we .... the comparison with Netspectre and blah blah is given in section blah"}

% \textbf{{Signal Amplification.}}
% Amplifying a side channel's signal strength, e.g. the timing difference, can significantly reduce noise.
% Roettger and Janc~\cite{Roettger2021A} leveraged the PLRU cache replacement policy in the L1 to arbitrarily amplify a single cache hit. However, it relies on the cache and thus any cache side-channel defense, e.g.\ \cite{Invisispec}, would mitigate this issue. Additionally, this method may be detectable in hardware.
% Hacky Racers~\cite{HackyRacers2023ASPLOS} %introduced "racing gadgets" and "magnifier gadgets" by exploiting 
% exploited instruction-level parallelism enabling timing attacks on restricted system such as JavaScript, although, multiple execution of the "magnifier gadget" in this paper makes it detectable in hardware.  MicroScope \cite{Microscope} addresses the issue of noisy side-channels, which mandates multiple measurements for getting reliable data by utilizing core microarchitectural features to execute dynamic instruction more than once. However, this attack is detectable in hardware, as shown in \cite{EVAX2022Micro,PerSpectron}. Recent papers have enabled performing logical operation on cache signals and amplifying them to the extent that they are visible to even coarse timers, compromising the performance of the attack because of the amplification overhead~\cite{kaplan2023optimization, purnal2023showtime, katzman2023gates}. 
% %\SMA{ , What are the weaknesses in these papers, check leakage rate, accuracy complexity requirement?Why Loki matters when these magnifiers exists}

% \textbf{{Side-channel attacks that leak ML parameters.}}
% Wei et al. \cite{wei2018know} were able to reconstruct the user inputs only by knowing the structure of the underlying CNN through measuring the power profile. Similarly, \cite{zhang2021stealing, tian2021remote} extracted neural network structure from FPGA using power side-channels.
% \cite{dubey2020maskednet}, uses differential power analysis to extract parameters of a NN.

%.\SMA{This should go to the defence recommendation. move it.}

%\subsection{Systematic Studies of Side-Channel Attacks}
% \para{Pandora's Box} Pandora's Box \cite{vicarte2021opening} introduced a new way of studying side channels via MLDs (Microarchitectural Leakage Descriptors) which concisely describe every possible microarchitectural state that can be left via a sequence of instructions. 

% \para{Kaveh's prefetching study}

% \{Didn't Daniel Gruss have a systematic study paper as well?}
% to , not sure 





% \subsection{Side-channel Defenses}

% \subsubsection{Restricting fine grain timers.}
% Cite works refer to Hacky Racers.


% \SMA{Try not to list stuff in the background and related works like an encyclopedia.}
%A better way to do that is to leverage the space for your purpose. What is your purpose? To present evidence supporting your scientific claim.  Think of the methods of defenses such as categorization in A Systematic Evaluation of Transient Execution Attacks and Defenses.}

% \para{Invisispec}
% Invisispec \cite{yan2018invisispec} attempted to mitigate cache-based covert channels by putting speculative reads into a separate microarchitectural buffer. 

% %\para{SafeSpec}

% %\para{DAWG}
% DAWG \cite{kiriansky2018dawg} (Dynamically Allocated Way Guard) is a method of securely partitioning a section of the shared LLC so that an arbitrary program and a secure program can not share a cache state, mitigating cache-based covert channels.

%\subsubsection{Detection}

% \notema{I don't think that table is required - just cite the results and discuss them in the paper}
% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=\linewidth]{Figures/onchip-acc-benefits.png}
%     \caption{ \textbf{Sustainable Computing in Risk:} Elavated workload performance, power efficiency and sustainability and more than 55\% TCO improvement with built in accelerator. Mitigating Intel AMX vulnerabilities may require hardware redesign of features that enabled these benefits. Xeon 4th Generation is named as the most sustainable data center processor.  \SMA{Create a better table TODO  please}}
%     \label{fig:enter-label}
% \end{figure}


% \subsection{Built-in Accelerators: A Paradigm Shift in Computing}
% \notema{not sure what this section is trying to tell me - looks a bit like advertising AMX...}

% The end of Dennard scaling\notema{no idea what that means} has fueled an era of specialized accelerators, transforming the landscape of processor design.

% In a significant paradigm shift, these accelerators are no longer solely standalone, discrete units. Instead, they are being directly integrated into CPU architectures, promising unprecedented benefits for diverse workloads while driving sustainability through efficiency.



%\notema{is this a research question you are trying to answer? Please highlight that with a question mark or structure it in the beginning of the ection. not really sure if that is still part of the background..}
% \subsection{Why on-chip accelerators are going to stay and simply disabling them for security will be costly----a call for urgent hardware redesign: } 

% \textbf{The Demands of AI and Specialized Workloads:} ML models and niche applications crave customized hardware for optimal execution. On-chip accelerators deliver that tailor-made performance, often surpassing traditional CPUs and even discrete accelerators that introduce communication bottlenecks.


% \textbf{Performance Without Bottlenecks:} 
% Integrating accelerators within the CPU establishes high-bandwidth pathways and minimizes latency, especially crucial for fine-grained workloads. This tight coupling unlocks a new level of performance potential. %\textbf{Examples of built-in accelerators and their performance benefits}
% For example: For AI inferencing, Intel AMX offers up to an 8.6x - 10x throughput boost~\cite{intel2023amx}. Network performance is optimized by Dynamic Load Balancer (DLB), achieving up to 96\% higher throughput while reducing latency.  
% For data-intensive operations, Intel Data Streaming Accelerator (DSA) delivers up to 1.7x higher IOPS for SPDK-NVMe interfaces. 
% Database operations are accelerated by up to 2.1x using RocksDB with Intel In-Memory Analytics Accelerator (IAA), streamlining analytics workflows. 
% Finally, Intel QuickAssist Technology (QAT) significantly offloads network-related tasks, freeing up CPU cores and showcasing extraordinary efficiency gains ~\cite{colfax2023xeonscalable}.

% \textbf{The Sustainability Advantage:} Due to their specialized nature and integrated design, on-chip accelerators are markedly more energy-efficient. This translates to lower operational costs for data centers and a reduced environmental footprint â€“ fewer servers, less energy, and a smaller carbon impact. 


% \textbf{The Environmental Imperative: Quantifiable CO2 Reduction} The sustainability benefits of on-chip accelerators are undeniable:
% %\textbf{AI Inferencing:} 
% Replacing 50 servers running 3rd Gen Intel Xeon processors with just 17 servers equipped with 4th Gen processors (featuring AMX) for AI inferencing can save a staggering 524,000 kg of CO2 emissions. %~\cite{colfax2023xeonscalable}
% %\textbf{Media Handling:} 
% Deploying 15 servers with 4th Gen Xeon processors (and DSA) for large media file requests can save between 206,577 kg and 611,000 kg of CO2. ~\cite{colfax2023xeonscalable}


%\textbf{Cost.} TCO
%Intel's 4th and 5th Generation Xeon Scalable Processors (Sapphire Rapids) exemplify the power of on-chip acceleration. 

% {\bf Sustainable Computing in Risk:} Elavated workload performance, power efficiency and sustainability and more than 55\% TCO improvement with built in accelerator are the features that made Xeon 4th Generation to be named as the most sustainable data center processor. Mitigating Intel AMX vulnerabilities may require hardware redesign of features that enabled these benefits.  [cite]




\paragrabf{Hertzbleed \cite{wang2022hertzbleed}.}
Hertzbleed leverages dynamic voltage and frequency scaling (DVFS) to transform power side-channel attacks into timing attacks. By exploiting the timing differences caused by frequency variations, even remote attacks become feasible. For instance, in an attack against Supersingular Isogeny Key Encapsulation (SIKE), they managed to recover 378 bits of the private key within 36 hours. Although this attack shares similarities with our work in exploiting frequency changes, DVFS can be managed by the CPU core and disabled in BIOS settings to mitigate the Hertzbleed attack. However, in our case, disabling DVFS is not a viable countermeasure since AMX, an on-chip accelerator, manages its power and frequency independently.

\paragrabf{Collide+Power \cite{kogler2023collide+}.}
The Collide+Power research focuses on the power leakage of the memory hierarchy via Running Average Power Limit (RAPL). If RAPL is unavailable, monitoring can be done through a throttling side-channel, albeit requiring more measurements. They demonstrated two types of attacks: Meltdown-style and Microarchitectural Data Sampling (MDS)-style. In Meltdown-style, targeting a shared cache among two processes on different cores, theoretically, one bit can be leaked in 99.95 days with power limit control or 2.86 years with stress-induced throttling. In MDS-style, where both victim and attacker run on different logical cores of the same physical core, data can be leaked from the L1/L2 cache at a rate of 4.82 bits per hour. Disabling simultaneous multithreading can mitigate MDS-style attacks. Generally, RAPL being a privileged interface is not accessible to unprivileged attackers, and throttling can be disabled by turning off DVFS.

\paragrabf{Platypus \cite{Lipp2021Platypus}.}
The Platypus attack reconstructed 509 RSA key bits using RAPL MSRs within Intel SGX enclaves. However, this attack vector has been mitigated by making RAPL a privileged interface.

\paragrabf{Neural Network Specific Attacks.}
Several studies have attacked neural network accelerators using power side channels. In the work by Wei et al. \cite{wei2018know}, an FPGA-based convolutional neural network accelerator was attacked, requiring physical access to recover the model's input image with up to 89\% accuracy. Effective mitigations include masking and random scheduling, although masking introduces significant overheads, as demonstrated in MaskedNet \cite{dubey2020maskednet}, increasing latency and area costs by 2.8x and 2.3x, respectively.

Open DNN Box \cite{Xiang2019OpenDB} inferred the weight sparsity of neural network models with 96.5\% accuracy on average. CSI NN \cite{236204} used power and electromagnetic traces to infer information about weights and architecture in fully connected neural networks. DeepEM \cite{Yu2020DeepEMDN} and DeepSniffer \cite{Hu2020DeepSnifferAD} collected electromagnetic traces to glean architectural information, with DeepEM specifically targeting binarized neural networks. Cache Telepathy \cite{244042}, GANRED \cite{Liu2020GANREDGR}, and DeepRecon \cite{Hong2018SecurityAO} employed well-known cache side channels like Flush+Reload and Prime+Probe to gather neural network insights. For these cache attacks, the attacker runs locally, and the presence of a shared cache is necessary. In contrast, our Thor attack doesn't need physical access or shared cache. It introduces a novel, data-dependent timing side-channel vulnerability specific to Intel AMX accelerators.

In the work by Gongye et al. \cite{9218707}, they attacked DNNs using a floating-point timing side channel to obtain weights and biases. They took advantage of the drastically different execution times for floating-point multiplication and addition in certain scenarios, such as when dealing with subnormal values, to launch their attack. However, with modern accelerators like Intel AMX, this floating-point timing vulnerability has been eliminated. Now, the execution time for tile multiplication remains constant, even for special cases like zero inputs. Specifically, the latency is fixed at 52 cycles and the throughput is 16. Despite this, to attack DNNs with more than one layer, cache monitoring or physical access is still required to measure the execution time of each layer.