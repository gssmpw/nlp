
\documentclass[journal,twoside,web]{ieeecolor}
\usepackage{generic}
\usepackage{cite}
\usepackage{textcomp}

\usepackage{amssymb,latexsym,amsfonts,amsmath,bbm}
\usepackage[cal=cm,bb=pazo]{mathalfa}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{dsfont}
\usepackage{eso-pic}
\usepackage{epsfig}
\usepackage{mathtools}
\usepackage{epstopdf}
\usepackage{lipsum}
\usepackage{cite}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\newcommand*{\myalign}[2]{\multicolumn{1}{#1}{#2}}

\usepackage[nocomma]{optidef}

\usepackage{tikz}
\usetikzlibrary{calc,shapes,arrows}

\usepackage{algorithm}
\usepackage{algorithmic}

% Create separate counters for each type of theorem-like environment
\newcounter{theorem}
\newcounter{definition}
\newcounter{lemma}
\newcounter{claim}
\newcounter{problem}
\newcounter{proposition}
\newcounter{corollary}
\newcounter{construction}
\newcounter{example}
\newcounter{xca}
\newcounter{comments}
\newcounter{remark}
\newcounter{assumption}

\newcommand{\blue}{\textcolor{blue}}
\newcommand{\red}{\textcolor{red}}

\newcommand{\AL}{\textcolor{blue}}

% Define theorem-like environments with independent numbering
\newtheorem{theorem}[theorem]{Theorem}
\newtheorem{lemma}[lemma]{Lemma}
\newtheorem{claim}[claim]{Claim}
\newtheorem{problem}[problem]{Problem}
\newtheorem{proposition}[proposition]{Proposition}
\newtheorem{corollary}[corollary]{Corollary}
\newtheorem{construction}[construction]{Construction}

% Define environments with independent numbering
\newtheorem{definition}[definition]{Definition}
\newtheorem{example}[example]{Example}
\newtheorem{xca}[xca]{Exercise}
\newtheorem{comments}[comments]{Comments}
\newtheorem{remark}[remark]{Remark}
\newtheorem{assumption}[assumption]{Assumption}

% Set numbering to be continuous for each type
\renewcommand{\thetheorem}{\arabic{theorem}}
\renewcommand{\thedefinition}{\arabic{definition}}
\renewcommand{\thelemma}{\arabic{lemma}}
\renewcommand{\theclaim}{\arabic{claim}}
\renewcommand{\theproblem}{\arabic{problem}}
\renewcommand{\theproposition}{\arabic{proposition}}
\renewcommand{\thecorollary}{\arabic{corollary}}
\renewcommand{\theconstruction}{\arabic{construction}}
\renewcommand{\theexample}{\arabic{example}}
\renewcommand{\thexca}{\arabic{xca}}
\renewcommand{\thecomments}{\arabic{comments}}
\renewcommand{\theremark}{\arabic{remark}}
\renewcommand{\theassumption}{\arabic{assumption}}
\numberwithin{equation}{section}

\DeclareMathOperator{\id}{id}

\DeclareFontFamily{U}{stix2bb}{}
\DeclareFontShape{U}{stix2bb}{m}{n} {<-> stix2-mathbb}{}

\NewDocumentCommand{\stixbbdigit}{m}{%
	\text{\usefont{U}{stix2bb}{m}{n}#1}%
}
\newcommand{\bbzero}{\stixbbdigit{0}}

\usepackage[many]{tcolorbox}
\usetikzlibrary{calc}
\tcbuselibrary{skins}

\newtcolorbox{resp}[1][]{%
	enhanced jigsaw,%
	colback=gray!5!white,%
	colframe=gray!80!black,%
	size=small,%
	boxrule=1pt,%
	halign title=flush center,%
	coltitle=black,%
	breakable,%
	drop shadow=black!50!white,%
	attach boxed title to top left={xshift=1cm,yshift=-\tcboxedtitleheight/2,yshifttext=-\tcboxedtitleheight/2},%
	minipage boxed title=3cm,%
	boxed title style={%
		colback=white,%
		size=fbox,%
		boxrule=1pt,%
		boxsep=2pt,%
		underlay={%
			\coordinate (dotA) at ($(interior.west) + (-0.5pt,0)$);
			\coordinate (dotB) at ($(interior.east) + (0.5pt,0)$);
			\begin{scope}[gray!80!black]
				\fill (dotA) circle (2pt);
				\fill (dotB) circle (2pt);
			\end{scope}
		}%
	},%
	#1%
}

\usepackage{xspace}

\def\set#1{{\{#1 \}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\Rpz}{{\mathbb{R}_{\geq 0}}}
\newcommand{\Rp}{{\mathbb{R}_{> 0}}}
\newcommand{\N}{{\mathbb{N}}}
\newcommand{\Np}{{\mathbb{N}_{\geq 1}}}
\newcommand{\I}{{\mathbb{I}}}
\newcommand{\One}{{\mathbb{1}}}
\newcommand{\Subsys}{{\textsc{ctia}-UNCS}}
\newcommand{\V}{{\mathbfcal{V}}}
\newcommand{\MP}{{\mathbfcal{P}}}
\newcommand{\MPI}{{\mathbfcal{P}_i}}

\newcommand{\Ii}{{\mathbfcal{I}_i}}
\newcommand{\Si}{{\mathbfcal{S}_i}}
\newcommand{\Wi}{{\mathbfcal{W}_i}}
\newcommand{\Sip}{{\mathbfcal{S}^+_i}}
\newcommand{\PD}{{\pmb{\Delta}_i}}

\newcommand{\barIi}{{\bar{\mathbfcal{I}}_i}}
\newcommand{\barSi}{{\bar{\mathbfcal{S}}_i}}
\newcommand{\barWi}{{\bar{\mathbfcal{W}}_i}}
\newcommand{\barSip}{{\bar{\mathbfcal{S}}^+_i}}
\newcommand{\barPD}{{\bar{\pmb{\Delta}}_i}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
		T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\markboth{\hskip25pc}
{From Data to  Sliding Mode Control of Uncertain Large-Scale Networks with Unknown Dynamics}

\definecolor{blue(ryb)}{rgb}{0.01, 0.28, 1.0}
\definecolor{fashionfuchsia}{rgb}{0.96, 0.0, 0.63}
\makeatletter
\let\NAT@parse\undefined
\makeatother
\usepackage[colorlinks=true, citecolor=fashionfuchsia, linkcolor=blue(ryb), final]{hyperref}
\renewcommand{\theequation}{\arabic{equation}}
\counterwithout*{equation}{section}

% Define the new style for definitions
\makeatletter
\def\@opargbegintheorem#1#2#3{\textit{#1\ #2} \textit{(#3):}}
\makeatother

\newenvironment{lbmatrix}[1]
{\left[\array{@{}*{#1}{c}@{}}}
{\endarray\right]}

\newcommand{\BS}[1]{\textcolor{blue}{\textbf{BS:} #1}}

\begin{document}
	
\title{From Data to  Sliding Mode Control of Uncertain Large-Scale Networks with Unknown Dynamics}
 \author{Behrad Samari, \IEEEmembership{Student Member,~IEEE}, Gian Paolo Incremona, \IEEEmembership{Senior Member,~IEEE}
 	\\ Antonella Ferrara, \IEEEmembership{Fellow,~IEEE}, and Abolfazl Lavaei, \IEEEmembership{Senior Member,~IEEE}
 	\thanks{B. Samari and A. Lavaei are with the School of Computing, Newcastle University, NE4 5TG Newcastle Upon Tyne, United Kingdom (e-mails: {\tt\small{\{b.samari2,abolfazl.lavaei\}@newcastle.ac.uk}}).}
 	 \thanks{G. P. Incremona is with the Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza Leonardo da Vinci 32, 20133, Milano, Italy (e-mail: {\tt\small{gianpaolo.incremona@polimi.it}}). Supported by the Italian Ministry for Research in the framework of the PRIN 2022 PRIDE, grant no. 2022LP77J4.}
 	\thanks{A. Ferrara is with the Dipartimento di Ingegneria Industriale e dell'Informazione,
         University of Pavia, Via Ferrata 5, 27100 Pavia, Italy (e-mail: {\tt\small{antonella.ferrara@unipv.it}}).}
}

\maketitle
\begin{abstract}
	Large-scale interconnected networks, composed of multiple \emph{low-dimensional} subsystems, serve as a crucial framework for modeling a wide range of real-world applications. Despite offering computational scalability, the \emph{inherent interdependence} among subsystems poses significant challenges to the effective control of such networks. This complexity is further exacerbated in the presence of \emph{external perturbations} and when the dynamics of individual subsystems, and accordingly the overall network, are \emph{unknown}—scenarios frequently encountered in modern practical applications. In this paper, we develop a \emph{compositional data-driven approach} to ensure the global asymptotic stability (GAS) of large-scale \emph{nonlinear} networks with unknown mathematical models, subjected to external perturbations. To achieve this, we first gather two sets of data from each unknown nominal subsystem without perturbation, which we refer to as \emph{two input-state trajectories}. The collected data from each subsystem is then utilized to design an input-to-state stable (ISS) Lyapunov function and its corresponding controller for each nominal subsystem, rendering them ISS. To accomplish this, we propose sufficient conditions as data-dependent semidefinite programs, which result in designing ISS Lyapunov functions and their corresponding local controllers, simultaneously. To cancel the effect of external perturbations on the dynamic of each subsystem, and accordingly the whole network, we then design a local \emph{integral sliding mode (ISM)} controller for each subsystem using the collected data. Under a \emph{small-gain} compositional condition, we employ data-driven ISS Lyapunov functions designed for subsystems and construct a \emph{control Lyapunov function} for the network, rendering the assurance of GAS property over the nominal network. We then extend this compositional result to network perturbed models, demonstrating that the synthesized ISM controllers ensure the GAS property even in the presence of perturbations. We showcase the efficacy of our data-driven findings on large-scale interconnected networks with five distinct interconnection topologies.
\end{abstract}

\begin{IEEEkeywords}
	Large-scale networks, data-driven control, integral sliding mode control, compositional techniques.
\end{IEEEkeywords}

\section{Introduction}\label{Sec: Introduction}
\IEEEPARstart{I}{n} recent years, there has been significant interest in developing control frameworks for \emph{large-scale interconnected networks} due to their wide applicability in modeling real-world systems, ranging from power networks to biological ones. However, formally designing control schemes to ensure the stability of such networks remain inherently challenging, primarily due to the mutual dependencies among subsystems. Additionally, modern applications introduce two further challenges that exacerbate these difficulties: \emph{(i)} the lack of an exact mathematical model for each subsystem, and consequently for the entire network, and \emph{(ii)}  the presence of \emph{external unknown-but-bounded perturbations} (\emph{e.g.,} fluctuating power demand in power networks).

To address the challenge of mutual dependencies among subsystems in an interconnected network, the literature advocates for input-to-state (ISS) stability, which examines the network's robust behavior under internal disturbances treated as adversarial inputs \cite{isidori1985nonlinear, neisic2002integral, agrachev2008input}. 
More precisely, ISS Lyapunov functions are well-suited for quantifying the influence of individual subsystems on others by constructing interaction gain functions. These functions play a crucial role in characterizing the network's interconnection structure and capturing the impact of neighboring subsystems. By applying \emph{small-gain reasoning}, the overall stability of the network is guaranteed afterward if the constructed gains adhere to specific compositional conditions \cite{jiang1994small, jiang1996lyapunov, dashkovskiy2007iss, dashkovskiy2010small, kawan2020lyapunov}. Despite the effectiveness of ISS Lyapunov functions and small-gain reasoning in addressing mutual dependencies among subsystems, these approaches commonly assume access to an \emph{exact mathematical model} of the network. However, in modern practical systems, models are often unknown or too complex to be used directly, highlighting the necessity of data-driven approaches.

To address challenges arising from perturbations, sliding mode control (SMC) has been widely adopted over the past two decades due to its ability to provide simple, low-computation solutions for various control problems in the presence of uncertainty \cite{utkin1992smc,incremona2019smc}.
Its design relies on the appropriate selection of the so-called sliding manifold—a subspace of the system state to which the system is driven in finite time and along which it evolves under a discontinuous control law. Such a control law ensures that the system state remains on the manifold, thus giving rise to a sliding mode \cite[Ch. 7]{slotine1991nonlin}. The original SMC formulation, however, has certain limitations: it can induce a chattering effect, does not inherently account for state constraints, and requires a transient phase—known as the \emph{reaching phase}—to reach the manifold, during which robustness to uncertainties is not guaranteed. Among other methods, higher-order SMCs and SMCs with optimal reaching 
(see \emph{e.g.,} \cite{levant2014hosmc,dinuzzo2009hosmc}) provide a solution to chattering alleviation and to constrained control problems, whereas the so-called \emph{integral sliding mode (ISM) control} \cite{utkin1996integral} enforces robustness from the outset by eliminating the reaching phase.

A peculiar feature of ISM control is that its design relies on the nominal model of the system, making it a \emph{model-based} approach.
The ISM control law comprises two components: the so-called \emph{ideal controller}, which stabilizes the nominal dynamics of the plant, and a discontinuous component designed to reject uncertainties. Moreover, the sliding variable also consists of two terms: one designed as in classical SMC \cite[Ch. 1]{incremona2019smc}, and the other, known as the \emph{transient function}, which depends on the nominal dynamics controlled by the ideal controller. The transient function is intended to ensure that the system states remain on the sliding manifold from the initial time instant. This design philosophy has proven effective when combined with other control strategies to meet additional requirements, such as constraint fulfillment or cost function optimization (see, \emph{e.g.}, \cite{incremona2017mpcism,incremona2017robot}, where model predictive control and ISM control were integrated). However, classical ISM control relies on exact knowledge of the system's mathematical model.

To address the challenge of unavailable exact mathematical models and instead leverage system data, two distinct yet valuable approaches have been proposed: \textit{(i)} indirect data-driven methods and \textit{(ii)} direct data-driven methods. In the first \emph{indirect} approach, system identification schemes are used to derive a valid model, which is then leveraged in model-based control techniques. However, accurately identifying the system, particularly when dealing with complex nonlinear dynamics, can be computationally demanding—if not infeasible \cite{kerschen2006past, hou2013model}. In contrast, direct data-driven approaches aim to bypass the identification phase and use data to directly learn the desired controller. This approach eliminates the need for a two-step process, as required in indirect data-driven methods, allowing for a more streamlined solution \cite{dorfler2022bridging}.

\subsection{Related work on data-based robust control}

In the pursuit of stabilizing unknown dynamical systems, multiple data-driven approaches have recently been proposed. To mention a few, building on Willems \emph{et al.’s} fundamental lemma \cite{willems2005note}, \cite{guo2021data} introduces a data-driven framework for stabilizing input-affine nonlinear systems with polynomial dynamics, while \cite{strasser2021data} extends this approach to more general systems beyond polynomials. In \cite{de2023learning}, a data-driven scheme is proposed to (approximately) cancel system nonlinearities and achieve stabilization. The work \cite{berberich2020data} introduces a robust data-driven model-predictive control strategy for linear time-invariant systems, while \cite{taylor2021towards} develops a data-driven approach for robust control synthesis of nonlinear systems, explicitly addressing model uncertainty. A data-driven approach for the certified learning of \emph{incremental} ISS controllers for unknown nonlinear polynomial dynamics has recently been studied in~\cite{zaker2024certified}.
 Data-driven stability analyses of unknown systems are further explored in various settings, including switched systems \cite{kenanian2019data}, continuous-time systems \cite{boffi2021learning}, and discrete-time systems \cite{lavaei2022data}. For noisy measured data, \cite{chen2024data} employs overapproximation techniques to characterize the set of polynomial dynamics consistent with the data. This enables the construction of an ISS Lyapunov function and the design of a corresponding ISS control law for unknown nonlinear input-affine systems with polynomial dynamics.

While studies such as \cite{guo2021data, strasser2021data, de2023learning, berberich2020data, taylor2021towards,zaker2024certified,kenanian2019data, boffi2021learning, lavaei2022data, chen2024data} primarily focus on stability analysis and controller synthesis using data, their methodologies are tailored for \emph{monolithic systems} of relatively low dimensions. As a result, they are not directly applicable to large-scale networks due to the challenges posed by \emph{sample complexity}. Recent efforts have sought to extend stability analysis to higher-dimensional systems. In this regard, \cite{sperl2023approximation} explores the use of deep neural networks (NN) to approximate control Lyapunov functions, aiming to mitigate the curse of dimensionality. Leveraging the compositional structure of interconnected nonlinear systems, \cite{liu2024compositionally} introduces a framework for training and validating neural Lyapunov functions for stability analysis. Similarly, \cite{zhang2023compositional} employs a compositional approach to derive neural certificates based on ISS Lyapunov functions and controllers for networked dynamical systems. Despite these advancements, \cite{sperl2023approximation, liu2024compositionally, zhang2023compositional} assume that the system model is available. Additionally, \cite{zhang2023compositional} requires a second step involving Satisfiability Modulo Theories (SMT) solvers, such as Z3 \cite{de2008z3}, dReal \cite{gao_-complete_2012} or MathSat \cite{cimatti_mathsat5_2013}, to verify the correctness of the candidate ISS Lyapunov functions. However, SMT solvers may encounter termination issues~\cite{wongpiromsarn2015automata}, or face scalability challenges depending on the NN size or the system complexity~\cite{abate2022neural}. Then, even if the problem is solved for \emph{high-dimensional} systems using NN, verifying the results in the second step would be intractable using SMT solvers, thus lacking formal guarantees. In contrast, our approach assumes the system model is unknown and directly determines ISS Lyapunov functions with correctness guarantees in a single step.

Finally, \cite{lavaei2023data} proposes a \emph{scenario-based} method \cite{calafiore2006scenario, campi2009scenario} for verifying the stability of interconnected networks. However, this approach requires the collected data to be \textit{independent and identically distributed (i.i.d.)}, meaning only one input-state sample pair can be obtained per trajectory \cite{esfahani2014performance}. As a result, multiple independent trajectories are needed to certify network stability. In contrast, our approach requires only two input-state trajectories per subsystem. Moreover, the method proposed in \cite{lavaei2023data} is limited to nonlinear \emph{homogeneous} systems, whereas our approach accommodates a significantly broader class of nonlinear systems, making it more practical. Additionally, \cite{lavaei2023data} focuses solely on \emph{verification} and cannot be applied when each subsystem is subject to external perturbations. In contrast, our approach effectively handles \emph{controller synthesis} in the presence of disturbances through local ISM controllers.

\subsection{Related works on data-based sliding mode control}

Recently, the literature has introduced neural network (NN) add-on to ISM control with successful results. In \cite{sacchi2024dnn} and  related works (see \emph{e.g.,} \cite{ferrara2024nnsmc} for an overview), NNs-based ISM control laws were proposed. Specifically, deep-NNs allow to identify the unknown model dynamics in order to design the transient function, thus reducing the reaching phase, similarly to classical ISM control. Yet, such strategies require some assumption on the knowledge of the bounds of the disturbance, and of the ideal weights characterizing the adopted NNs, which are difficult to retrieve in practice. Furthermore, the estimation of the weights can generate further uncertainty which could cause the temporary loss of the sliding mode. A recent variation proposed in \cite{riva2024ddsmc} addressed these issues by introducing a virtual reference feedback tuning (VRFT) \cite{campi2022vrft} combined with ISM control, for \emph{single-input-single-output} linear perturbed systems. Specifically, the ideal controller is achieved in a data-driven fashion as the solution to an optimization procedure minimizing the $2$-norm of the difference between the closed-loop transfer function and a reference model playing the role of the nominal dynamics in the design of the sliding variable. It should be noted that none of the NNs-based SMC \cite{sacchi2024dnn, ferrara2024nnsmc, riva2024ddsmc, campi2022vrft} investigate \emph{large-scale interconnected networks} consisting of multiple coupled subnetworks with unknown dynamics.

\subsection{Main contribution}
Motivated by the research gap mentioned above, this paper aims to propose a \emph{compositional data-driven} methodology to ensure the GAS property of unknown large-scale nonlinear networks affected by \emph{external disturbances}. To achieve this, two sets of input-state trajectories are collected from each \emph{nominal} subsystem in the absence of external perturbations. These data sets are then employed to simultaneously design an ISS Lyapunov function and a corresponding controller for each nominal subsystem, ensuring ISS properties. The design process involves deriving sufficient conditions formulated as data-dependent semidefinite programs (SDPs), which guide the construction of ISS Lyapunov functions and their associated local ISS controllers. We acknowledge that since the proposed sufficient conditions are data-dependent SDPs, we remarkably alleviate the scalability challenges compared to potential studies that leverage data-dependent sum-of-squares (SOS) programs. 

To reject the influence of external perturbations on the dynamic evolution of both individual subsystems and the entire interconnected network, a local  \emph{integral sliding mode (ISM)} controller is developed for each subsystem based on the collected data. By leveraging a \emph{small-gain} compositional condition, the data-driven ISS Lyapunov functions designed for each nominal subsystem are combined to construct a \emph{control Lyapunov function (CLF)} for the nominal interconnected network, guaranteeing its GAS property. Our approach is further extended to networks subject to external perturbations, which demonstrates that the ISM controllers ensure the GAS property of the network even under external perturbations. Our proposed methodology is validated through large-scale interconnected networks with five distinct interconnection topologies, highlighting the practical applicability and effectiveness of our data-driven framework.

\subsection{Outline of the paper}
The remainder of the paper is structured as follows. Section \ref{Sec: Prob_Desc} introduces the notations and mathematical preliminaries, together with the mathematical models for individual subsystems and the interconnected network. In the same section, the definitions of a CLF and an ISS Lyapunov function for the nominal network and its subsystems, respectively, are reported, and the ISM control design for non-nominal subsystems is recalled. In Section \ref{Section: Data Framework}, we obtain the closed-loop data-based representation for each nominal subsystem, while proposing its sufficient conditions to synthesize the ISS Lyapunov function together with its corresponding ISS controller. We also propose our framework to design ISM controllers for non-nominal subsystems based on the collected data. Section \ref{Section: Compositional} is dedicated to presenting our compositional approach, where we first establish that the nominal network possesses the GAS property and subsequently extend this result to the non-nominal network. Finally, simulation results are presented in Section \ref{Section: Simulation}, followed by conclusions in Section \ref{Section: Conclusion}.

\section{Problem Formulation}\label{Sec: Prob_Desc}

\subsection{Notation}
In this paper, we adhere to the following notational conventions. The symbol $\R$ represents the set of real numbers, while $\Rpz$ and $\Rp$ denote the sets of non-negative and positive real numbers, respectively. The set of non-negative integers is given by $\N = \{0, 1, 2, \ldots\}$, while $\Np = \{1, 2, \ldots\}$ represents the set of positive integers. The $n \times n$ identity matrix is represented by $\I_n$, and the vector of ones with dimension $n$ is denoted by $\One_n$. The notation $\bbzero_{n \times m}$ refers to an $n \times m$ matrix consisting entirely of zeros, whereas $\bbzero_{n}$ denotes the zero vector of dimension $n$. For $N$ vectors $x_i \in \R^{n_i}$, the notation $x = [x_1;\ldots;x_N]$ represents the corresponding \emph{column vector} with a dimension of $\sum_i n_i$. Additionally, the expressions $[x_1\;\ldots\; x_N]$ and $[A_1\;\ldots\; A_N]$ denote the horizontal concatenation of vectors $x_i \in \R^n$ and matrices $A_i \in \R^{n \times m}$, resulting in matrices of dimensions $n \times N$ and $n \times mN$, respectively. The Euclidean norm of a vector $x \in \R^n$ is denoted by $\vert x \vert$, whereas the induced 2-norm of a matrix $A$ is represented by $\Vert A \Vert$. A \emph{symmetric} matrix $P$ is denoted as positive definite by $P \succ 0$, and as positive semi-definite by $P \succeq 0$. For a square matrix $A$, its minimum and maximum eigenvalues are denoted by $\lambda_{\min}(A)$ and $\lambda_{\max}(A)$, respectively. The transpose of a matrix $B$ is written as $B^\top \!$, and its \emph{right} pseudoinverse is denoted by $B^\dagger$, defined as $B^\dagger \coloneq B^\top (BB^\top)^{-1}$. A block diagonal matrix in $\R^{N \times N}$ with diagonal blocks $(A_1, \ldots, A_N)$ is denoted by $\mathsf{blkdiag}(A_1, \ldots, A_N)$, while a diagonal matrix with \emph{scalar} entries $(a_1, \ldots, a_N)$ is represented by $\mathsf{diag}(a_1, \ldots, a_N)$. The notation $\{a_{ij}\}$ denotes the construction of a matrix whose elements $a_{ij}$ are located in the $i$-th row and $j$-th column. A function $\beta: \Rpz \rightarrow \Rpz$ is classified as a $\mathcal{K}$ function if it is continuous, strictly increasing, and satisfies $\beta(0) = 0$. Similarly, a function $\beta: \Rpz \times \Rpz \rightarrow \Rpz$ is categorized as belonging to class $\mathcal{KL}$ if, for a fixed $s$, the mapping $\beta(r,s)$ is a $\mathcal{K}$ function with respect to $r$, and for a fixed $r \in \Rp$, the mapping $\beta(r,s)$ is decreasing with respect to $s$ and approaches $0$ as $s \rightarrow \infty$. For a given matrix $A$, $\bold{b} \in \mathsf{span}\{A\}$ implies that the vector $\bold{b}$ can be expressed as a linear combination of the columns of the matrix $A$, meaning that $\bold{b}$ lies in the column space of $A$.

\subsection{Individual Subsystems}
We define individual subsystems as continuous-time input-affine uncertain nonlinear control systems, as formalized in the following definition, which are subsequently used to construct the interconnected large-scale network.

\begin{definition}[\textbf{\Subsys}]\label{def: ctia-UNCS}
	A continuous-time input-affine uncertain nonlinear control system (\Subsys) is defined as
	\begin{align}
		\Upsilon_i \!: \dot{x}_i = f_i(x_i) + \mathcal{B}_i u_i + \mathcal{D}_i w_i + \mathcal{E}_i (x_i, t), \label{eq: original_subsys}
	\end{align}
	where $f_i: \R^{n_i} \rightarrow \R^{n_i}$ is a continuous vector field of the state variables $x_i \in \R^{n_i},$ with $f(\bbzero_{n_i}) = \bbzero_{n_i},$ $\mathcal{B}_i \in \R^{n_i \times m_i}$ denotes the control matrix, $\mathcal{D}_i \in \R^{n_i \times \psi_i}$ is the \emph{internal input} matrix with $\psi_i = \sum_{j = 1,j\neq i}^{N} n_j$, where $N$ is the number of subsystems, and $\mathcal{E}_i : \R^{n_i} \times \Rpz \rightarrow \R^{n_i}$ denotes the \emph{external perturbation} at time $t \in \Rpz$, satisfying the  \emph{matching} condition, \emph{i.e.,} $\mathcal{E}_i(x_i, t) \in \mathsf{span}\{\mathcal{B}_i\}$. Additionally, $u_i \in \R^{m_i}$ is the \emph{control} input, while $w_i \in \R^{\psi_i}$ represents the \emph{internal} input.
\end{definition}

Without loss of generality, the dynamics of the \Subsys\ in \eqref{eq: original_subsys} can be reformulated as
\begin{align}
	\Upsilon_i \!: \dot{x}_i = \mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i + \mathcal{D}_i w_i + \mathcal{E}_i (x_i, t), \label{eq: final_subsys}
\end{align}
where $\mathcal{A}_i \in \R^{n_i \times z_i}$ denotes the system matrix, and $\mathcal{Z}_i : \R^{n_i} \rightarrow \R^{z_i}$ is a continuous map satisfying $\mathcal{Z}_i(\bbzero_{n_i}) = \bbzero_{z_i}$.
This map consists of both \emph{linear and nonlinear} components, expressed as
\begin{align}
	\mathcal{Z}_i(x_i) = \begin{bmatrix}
		x_i\vspace{-.225cm}\\
		\tikz\draw [thin,dashed] (0,0) -- (1.25,0);\\
		\mathcal{M}_i(x_i)
	\end{bmatrix}\!\!, \label{eq: dictionary}
\end{align}
where $\mathcal{M}_i : \R^{n_i} \rightarrow \R^{z_i - n_i}$ contains only \emph{nonlinear} basis functions. In this work, we assume that $\mathcal{M}_i(x_i)$ represents \emph{matched} nonlinearities, implying that these nonlinear terms are aligned with the same channel as the control input $u_i$, thereby allowing direct influence by the control input. We use the tuple $\Upsilon_i = (\mathcal{A}_i, \mathcal{Z}_i, \mathcal{B}_i, \mathcal{D}_i, \R^{n_i}, \R^{m_i}, \R^{\psi_i}, \R^{n_i})$ to represent the reformulated \Subsys\ in \eqref{eq: final_subsys}.

In this paper, the matrices $\mathcal{A}_i$ and $\mathcal{B}_i$, along with the precise structure of $\mathcal{Z}_i(x_i)$, are assumed to be \emph{unknown}. However, it is presumed that a \emph{dictionary} for $\mathcal{Z}_i(x_i)$ is available, which is sufficiently comprehensive to include the true system dynamics. Specifically, this dictionary is extensive enough to capture all possible terms in the actual dynamics, \emph{i.e.,} all linear functions of the state variables as well as nonlinear terms derived from system-specific insights, albeit at the cost of incorporating \emph{extraneous terms}. Furthermore, the matrix $\mathcal{D}_i$ is assumed to be known, as it encapsulates the \emph{interconnection weights} between subsystems, which are often known a priori in interconnected network settings. Thus, the \Subsys\ $\Upsilon_i$ is referred to as a system with a \emph{(partially)} unknown model, as its matrices $\mathcal{A}_i$ and $\mathcal{B}_i$ are entirely unknown, while $\mathcal{Z}_i(x_i)$ is partially unknown, which reflects a scenario commonly encountered in real-world interconnected networks.

\begin{remark}[\textbf{Dictionary $\mathcal{Z}_i(x_i)$}]\label{Remark: dictionary}
	The assumption of an extensive dictionary $\mathcal{Z}_i(x_i)$ being available is not  restrictive in most cases. This is because, in numerous practical applications—such as electrical and mechanical engineering systems—the dynamics of the system can often be deduced from first principles, which naturally align with the basis functions included in \eqref{eq: dictionary}. However, while such insight is able to provide the necessary structure, the exact parameters of the system frequently remain unknown. This is consistent with our assumption that the matrices $\mathcal{A}_i$ and $\mathcal{B}_i$ are entirely unknown.
\end{remark}

We proceed by stating the assumption that the matched perturbation $\mathcal{E}_i(x_i, t)$ is bounded, which is a common scenario in the sliding mode control theory.

\begin{assumption}[\textbf{Bound on $\mathcal{E}_i(x_i, t)$ \cite[Ch. 1]{incremona2019smc}}]\label{Assumption: bound_disturbance}
	There exists a known constant $\bar{\mathbfcal{E}_i} \in \Rp$ satisfying $\vert \mathcal{E}_i(x_i, t) \vert \leq \bar{\mathbfcal{E}_i}, \, \forall t \in \Rpz.$
\end{assumption}

To conclude this subsection, we finally note that hereafter the \emph{nominal} model of the \Subsys\ $\Upsilon_i$, \emph{i.e.,} the \Subsys\ $\Upsilon_i$ in \eqref{eq: final_subsys} when $\mathcal{E}_i(x_i, t) \equiv \bbzero_{n_i}$, is denoted by $\Upsilon_i^\ast$.

Since the primary objective of this work is to perform stability analysis of interconnected uncertain networks composed of individual subsystems described by \eqref{eq: final_subsys}, we proceed to introduce the network topology in the subsequent subsection and explain how these subsystems form interconnected networks.

\subsection{Interconnected Network}
Here, we formally define the interconnection among the subsystems $\Upsilon_i$. Let $\Upsilon$ represent an interconnected network comprising $N \in \Np$ subsystems $\Upsilon_i$, with internal inputs and their associated matrices partitioned as
\begin{subequations}\label{eq: partitioned}
	\begin{align}
		w_i  &= [w_{i 1} ; \ldots ; w_{i(i-1)} ; w_{i(i+1)} ; \ldots ; w_{i N}], \label{eq: partitioned_w}\\
		\mathcal{D}_i  & = [\mathcal{D}_{i 1} \;\; \ldots \;\; \mathcal{D}_{i(i-1)} \;\; \mathcal{D}_{i(i+1)} \;\; \ldots \;\; \mathcal{D}_{i N}], \label{eq: partitioned_D}
	\end{align}
\end{subequations}
where $\mathcal{D}_{ij}\in\R^{n_i\times n_j}$. It is assumed that the dimension of $w_{ij}$ matches that of $x_j$, which is a reasonable assumption within the framework of \emph{small-gain} analysis. If no connection exists from subsystem $\Upsilon_j$ to $\Upsilon_i$, the corresponding internal input is identically zero, \emph{i.e.,} $w_{ij} \equiv \bbzero_{n_j}$; otherwise, it is given by $w_{ij} = x_j$.

Within the interconnected network, internal inputs represent the influence of \emph{neighboring subsystems} based on the interconnection topology (cf. interconnection constraint \eqref{eq: internal-connection}). In contrast, control inputs and perturbations are external influences that do not participate in defining the interconnection structure. Having had these in mind, we now move forward with the formal definition of an interconnected network.

\begin{definition}[\textbf{Interconnected Network}]\label{def: network}
	Consider $N \in \Np$ subsystems $\Upsilon_i = (\mathcal{A}_i, \mathcal{Z}_i, \mathcal{B}_i, \mathcal{D}_i, \R^{n_i}, \R^{m_i}, \R^{\psi_i}, \R^{n_i}), i \in \{1, \ldots, N\}$, with internal inputs and their associated matrices partitioned as described in \eqref{eq: partitioned}. Suppose that the subsystems $\Upsilon_i$, $i \in \{1, \ldots, N\}$, are interconnected under the following interconnection constraint:
	\begin{align}
		w_{ij} = x_j, \quad \forall i, j \in \{1, \ldots, N\}, \; i \neq j. \label{eq: internal-connection}
	\end{align}
	Then an interconnected network $\Upsilon = \mathscr{N}(\Upsilon_1, \ldots, \Upsilon_N)$ is formed with the dynamics according to
	\begin{align}
		\Upsilon : \dot{x} = \mathcal{A}\mathcal{Z}(x) + \mathcal{B}u + \mathcal{E}(x, t), \label{eq: network}
	\end{align}
	where $\mathcal{A} \in \R^{n \times \mathbb{Z}},$ in which $n \coloneq \sum_{i=1}^{N} n_i$ and $\mathbb{Z} \coloneq \sum_{i=1}^{N} z_i,$ is a block matrix with diagonal blocks $(\mathcal{A}_1, \ldots, \mathcal{A}_N)$ and off-diagonal entries $\hat{\mathcal{D}}_i = [\hat{\mathcal{D}}_{i 1} \; \ldots \; \hat{\mathcal{D}}_{i(i-1)} \; \hat{\mathcal{D}}_{i(i+1)} \; \ldots \; \hat{\mathcal{D}}_{i N}],$ which depend on the interconnection topology, where $\hat{\mathcal{D}}_{ij}  = [\mathcal{D}_{ij} \;\; \bbzero_{n_i \times (z_j - n_j)}]$. Moreover, $\mathcal{E}(x, t) = [\mathcal{E}_1(x_1, t); \ldots; \mathcal{E}_N(x_N, t)] : \R^n \times \Rpz \rightarrow \R^n$, and $\mathcal{B} = \mathsf{blkdiag}(\mathcal{B}_1, \ldots, \mathcal{B}_N) \in \R^{n \times m}$, with $u \in \R^{m}$ and $m \coloneq \sum_{i=1}^N m_i$, while $\mathcal{Z}(x) = [\mathcal{Z}_1(x_1); \dots; \mathcal{Z}_N(x_N)] \in \R^{\mathbb{Z}}$. We use the tuple $\Upsilon = (\mathcal{A}, \mathcal{Z}, \mathcal{B}, \R^n, \R^m, \R^n)$ to represent the interconnected network in \eqref{eq: network}.
\end{definition}

Following the approach used to define the nominal model of each subsystem, thenceforth, the \emph{nominal } model of the interconnected network, \emph{i.e.,} the network in \eqref{eq: network} when $\mathcal{E}(x, t) \equiv \bbzero_{n}$, is indicated by $\Upsilon^\ast$.

Having defined the interconnected network, as in Definition \ref{def: network}, we now move on to formally presenting the global asymptotic stability (GAS) for the interconnected network.

\subsection{GAS of Interconnected Networks}
We start by providing a formal definition of the GAS property for an interconnected network, as introduced in \cite{angeli2000characterization}.

\begin{definition}[\textbf{GAS Property}]\label{def: GAS}
	The origin is said to be a globally asymptotically stable (GAS) equilibrium point for an interconnected network $\Upsilon = \mathscr{N}(\Upsilon_1, \ldots, \Upsilon_N)$ if there exists a function $\beta$, belonging to class $\mathcal{KL}$, such that for any initial condition $x(0) \in \R^n$, the inequality
	\begin{align*}
		\vert x(t) \vert \leq \beta(\vert x(0) \vert, t)
	\end{align*}
	holds. This implies that all trajectories of $\Upsilon$ approach the origin, which serves as the equilibrium point, as time $t \rightarrow \infty$.
\end{definition}

Before proceeding, we emphasize that the upcoming theorem and definition are specifically formulated for the \emph{nominal} interconnected network $\Upsilon^\ast$ and \emph{nominal} subsystems $\Upsilon_i^\ast$, respectively. This focus aligns with our objective of designing an integral sliding mode (ISM) controller to mitigate the effects of the perturbations $\mathcal{E}_i(x_i, t)$, and accordingly, $\mathcal{E}(x, t)$.  More precisely, for each subsystem $\Upsilon_i$, the control action is expressed as $u_i = u_{i}^\ast + u_{i}^{\mathrm{ISM}}$, where $u_{i}^\ast \in \R^{m_i}$ represents a confined control law that renders the state $x_i$ a GAS equilibrium point for the \emph{nominal} subsystem $\Upsilon_i^\ast$. At the same time, $u_{i}^{\mathrm{ISM}} \in \R^{m_i}$ serves as a \emph{discontinuous} control signal intended to make the system robust against perturbations $\mathcal{E}_i(x_i, t)$ (cf. Subsection \ref{subsec: ISM}).

We now state the following theorem, borrowed from \cite{sontag1996new}, which outlines the sufficient conditions to achieve GAS property  across the nominal network $\Upsilon^\ast$\!, as per Definition \ref{def: GAS}.

\begin{theorem}[\textbf{CLFs for Interconnected Networks}]\label{Theorem: model-based Network}
	Consider a nominal interconnected network $\Upsilon^\ast = \mathscr{N}(\Upsilon_1^\ast, \ldots, \Upsilon_N^\ast)$, comprising $N$ nominal subsystems $\Upsilon_i^\ast$. Assume the existence of a \emph{control Lyapunov function (CLF)} $\V : \R^n \to \Rpz$ and positive constants $\alpha_1, \alpha_2, \kappa \in \Rp$, satisfying
	\begin{itemize}
		\item For all $x \in \R^n$:
		\begin{subequations}
			\begin{equation}\label{eq: clf-con1-network}
				\alpha_1 \vert x \vert^2 \leq \V(x) \leq \alpha_2 \vert x \vert^2,
			\end{equation}
			\item For all $x \in \R^n$, there exists $u^\ast \in \R^m$ such that:
			\begin{align}\label{eq: clf-con2-network}
				&\mathsf{L} \V(x) \leq - \kappa \V(x),
			\end{align}
		\end{subequations}
	\end{itemize}
	where $\mathsf{L} \V$ denotes the \emph{Lie derivative} of $\V : \R^n \to \Rpz$ with respect to the \emph{nominal} dynamics of \eqref{eq: network}, given by
	\begin{align}
		\mathsf{L} \V(x) = \partial_{x} \V(x)(\mathcal{A} \mathcal{Z}(x) + \mathcal{B} u^\ast),
	\end{align}
	with $\partial_{x} \V(x) = \frac{\partial \V(x)}{\partial x}$. Under these conditions, the \emph{nominal} interconnected network $\Upsilon^\ast = \mathscr{N}(\Upsilon_1^\ast, \ldots, \Upsilon_N^\ast)$ is endowed with the GAS property in the sense of Definition \ref{def: GAS}.
\end{theorem}

Designing a CLF to ensure the GAS property of the nominal network $\Upsilon^\ast$ is, in most cases, a computationally intensive task, even when the accurate mathematical model is available. To overcome this difficulty, one can instead evaluate the GAS property of the nominal interconnected network $\Upsilon^\ast$ by leveraging the ISS characteristics of its individual nominal subsystems $\Upsilon_i^\ast, \forall i \in \{1, \ldots, N\}$, as outlined in the subsequent definition.

\begin{definition}[\textbf{ISS Lyapunov Functions}]\label{def: ISS Lyapunov}
	For a given nominal subsystem $\Upsilon_i^\ast$, a function $\V_i : \R^{n_i} \to \Rpz$ is referred to as an \emph{input-to-state stable (ISS)} Lyapunov function if there exist constants $\alpha_{1_i}, \alpha_{2_i}, \kappa_i \in \Rp$ and $\rho_i \in \Rpz$, fulfilling
	\begin{itemize}
		\item For all $x_i \in \R^{n_i}$:
		\begin{subequations}
			\begin{eqnarray}\label{eq: ISS-con1}
				\alpha_{1_i} \vert x_i \vert^2 \leq \V_i(x_i) \leq \alpha_{2_i} \vert x_i \vert^2,
			\end{eqnarray}
			\item For all $x_i \in \R^{n_i}$, there exists $u_i^\ast \in \R^{m_i}$ such that for all $w_i \in \R^{\psi_i}$:
			\begin{align}\label{eq: ISS-con2}
				\mathsf{L} \V_i(x_i) \leq - \kappa_i \V_i(x_i) + \rho_i \vert w_i \vert^2,
			\end{align}
		\end{subequations}
	\end{itemize}
	where $\mathsf{L} \V_i$ represents the \emph{Lie derivative} of $\V_i : \R^{n_i} \to \Rpz$ with respect to the nominal dynamics of \eqref{eq: final_subsys}, given by
	\begin{align}
		\mathsf{L} \V_i(x_i) = \partial_{x_i} \V_i(x_i) (\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i). \label{eq: Lie derivative-subsystem}
	\end{align}
\end{definition}

\subsection{ISM Control}\label{subsec: ISM}
As briefly discussed in the preceding subsection, we aim to design a local controller for each subsystem, represented by $u_i = u_{i}^\ast + u_{i}^{\mathrm{ISM}}$, where $u_{i}^\ast$ is the ideal controller \cite{utkin1996integral}, and $u_{i}^{\mathrm{ISM}}$ is designed to ensure robustness against matched perturbations $\mathcal{E}_i(x_i, t)$ from the initial time instant $t_0 \in \Rpz$. For the case where $m_i > 1$, meaning each subsystem $\Upsilon_i$ has multiple control inputs, the discontinuous control law is derived using the unit vector approach, \emph{i.e.,}
\begin{align}
	u_{i}^{\mathrm{ISM}} = -\Theta_i \frac{\sigma_i(x_i)}{\vert \sigma_i(x_i) \vert}, \label{eq: ISM_U}
\end{align}
where $\Theta_i \in \Rp$ is a constant gain selected so that the worst realization of the perturbation is dominated, while $\sigma_i(x_i): \R^{n_i} \to \R^{m_i}$ is the integral sliding variable, defined as
\begin{align}
	\sigma_i(x_i) \!=\! \sigma_{0_i}(x_i) \!+\! \zeta_i(t), ~\text{where}~ \sigma_{0_i}(x_i(t_0)) \!=\! -\zeta_i(t_0). \label{eq: integral sliding variable}
\end{align}
The term $\sigma_{0_i}(x_i) : \R^{n_i} \to \R^{m_i}$ is selected by the designer, possibly as a linear combination of state variables $x_i$. On the other hand, the term $\zeta_i \in \R^{m_i}$ appearing in \eqref{eq: integral sliding variable} represents what is known as the \emph{transient function}, characterized by its dynamics defined as
\begin{align}
	\dot{\zeta}_i = -\frac{\partial \sigma_{0_i}(x_i)}{\partial x_i} (\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i), \label{eq: transient}
\end{align}
with $\frac{\partial \sigma_{0_i}(x_i)}{\partial x_i} \in \R^{m_i \times n_i}$ and $\zeta_i(t_0) = - \sigma_{0_i}(x_i(t_0))$. As demonstrated in \cite{utkin1996integral}, selecting the constant gain $\Theta_i$ to sufficiently exceed the maximum possible impact of the matched perturbation, as specified in Assumption \ref{Assumption: bound_disturbance}, guarantees that a sliding mode $\sigma_i = \bbzero_{m_i}$ is achieved for all $t \geq t_0$, thereby ensuring that the perturbations are consistently rejected.

Although ISS Lyapunov functions, as defined in Definition \ref{def: ISS Lyapunov}, provide a pathway to constructing a CLF for an interconnected network under certain \emph{small-gain compositional} conditions (cf. Section \ref{Section: Compositional}), and ISM control effectively rejects the perturbations $\mathcal{E}_i(x_i, t)$, and accordingly $\mathcal{E}(x, t)$, it is evident that designing such ISS functions is not feasible due to the unknown matrices $\mathcal{A}_i$ and $\mathcal{B}_i$, and  unknown vectors $\mathcal{Z}_i(x_i)$ in \eqref{eq: Lie derivative-subsystem} and \eqref{eq: transient}. Given this fundamental challenge, we now formally state the primary problem we aim to address in this work.

\begin{resp}
	\begin{problem}\label{Problem 1}
		Consider an interconnected network $\Upsilon = \mathscr{N}(\Upsilon_1, \ldots, \Upsilon_N)$, which is formed by $N$ subsystems $\Upsilon_i$, where the matrices $\mathcal{A}_i$ and $\mathcal{B}_i$ are unknown, but an extended dictionary for $\mathcal{Z}_i$, as in \eqref{eq: dictionary}, is available. The objective is to construct an ISS Lyapunov function $\V_i$ and its corresponding controller $u_i^\ast$ for each nominal subsystem by utilizing only \emph{two input-state trajectories} collected from it. Subsequently, we design an ISM controller $u_i^{\mathrm{ISM}}$ as described in \eqref{eq: ISM_U} to ensure that the controlled subsystem remains robust against the matched perturbation $\mathcal{E}_i(x_i, t)$. Finally, we develop a \emph{compositional} approach based on \emph{small-gain reasoning} to combine these individual $\V_i$ into forming a control Lyapunov function $\V$ for the entire interconnected network, along with its corresponding controller $u$, while ensuring the GAS property of the network in the presence of external perturbations.
	\end{problem}
\end{resp}

The following section introduces our proposed data-driven framework to address the first part of Problem \ref{Problem 1}.

\section{Data-Driven Framework}\label{Section: Data Framework}
This section proposes our data-driven framework for synthesizing a local controller $u_i = u_{i}^\ast + u_{i}^{\mathrm{ISM}}$ for each \Subsys\ $\Upsilon_i$. More precisely, Subsection \ref{subsec: ISS_data} introduces our approach to constructing ISS Lyapunov functions $\V_i(x_i)$ and the associated subsystems' controller, \emph{i.e.,} $u_i^\ast$, while Subsection \ref{subsec: ISM_data} offers the methodology for designing the ISM control, \emph{i.e.,} $u_i^{\mathrm{ISM}}$, for each \Subsys\ $\Upsilon_i$, using data.

\subsection{Data-Driven Design of ISS Lyapunov Functions}\label{subsec: ISS_data}
Within our data-driven framework, the ISS Lyapunov function for each subsystem is assumed to have a \emph{quadratic} structure, expressed as $\V_i(x_i) = x_i^\top \MPI x_i$, where $\MPI \succ 0$. Data is then collected from each unknown nominal subsystem $\Upsilon_i^\ast$ over the time interval $[t_0, t_0 + (\mathcal{T} - 1)\tau]$, where $\mathcal{T} \in \Np$ represents the total number of samples, and $\tau \in \Rp$ denotes the sampling time:
\begin{subequations}\label{eq: data_ct} 
	\begin{align}
		\Ii &= \begin{bmatrix}
			u_i^\ast(t_0) & \! u_i^\ast(t_0 \!+\! \tau) & \! \dots & \! u_i^\ast(t_0 \!+\! (\mathcal{T} \!-\! 1)\tau)
		\end{bmatrix}\!\!,\label{eq: Ii}\\
		\Si &= \begin{bmatrix}
			x_i (t_0) & \! x_i (t_0 \!+\! \tau) & \! \dots & \! x_i (t_0 \!+\! (\mathcal{T} \!-\! 1)\tau)
		\end{bmatrix}\!\!,\label{eq: Si}\\
		\Wi &= \begin{bmatrix}
			w_i (t_0) & \! w_i (t_0 \!+\! \tau) & \! \dots & \! w_i (t_0 \!+\! (\mathcal{T} \!-\! 1)\tau)
		\end{bmatrix}\!\!,\label{eq: Wi}\\
		\Sip &= \begin{bmatrix}
			\dot{x}_i (t_0) & \! \dot{x}_i (t_0 \!+\! \tau) & \! \dots & \! \dot{x}_i (t_0 \!+\! (\mathcal{T} \!-\! 1)\tau)
		\end{bmatrix}\!\!.\label{eq: Sip}
	\end{align}
\end{subequations}
Using the collected data $\Si$ and the extended dictionary $\mathcal{Z}_i(x_i)$ in \eqref{eq: dictionary}, we proceed to construct the following matrix:
\begin{align}
	\PD \!=\! \begin{bmatrix}
		x_i (t_0) & x_i (t_0 \!+\! \tau) & \!\!\!\dots & x_i (t_0 \!+\! (\mathcal{T} \!-\! 1)\tau)\\
		\mathcal{M}(x_i (t_0)\!) & 	\!\!\mathcal{M}(x_i (t_0 \!+\! \tau)\!) & \!\!\!\dots & 	\!\!\!\!\!\mathcal{M}(x_i (t_0 \!+\! (\mathcal{T} \!-\! 1)\tau)\!)
	\end{bmatrix}\!\!. \label{eq: PD}
\end{align}
Similarly, an additional trajectory is collected for each nominal \Subsys\ over the same time interval, represented by $\barSi$, $\barWi$, $\barSip$, and $\barPD$, where the system is driven by a \emph{zero control input} $\barIi = \bbzero_{m_i \times \mathcal{T}}$, while both trajectories are required to originate from the \emph{same initial condition}. The trajectories specified in \eqref{eq: data_ct}, along with those obtained under a constant zero input, are treated as \emph{two distinct input-state trajectories}. It is important to highlight that the collection of the second input-state trajectory is necessary to enable the data-driven characterization of the control input matrix $\mathcal{B}_i$ as it is needed in Subsection \ref{subsec: ISM_data}. However, in scenarios where the control input matrix $\mathcal{B}_i$ is known, a single input-state trajectory would suffice.

\begin{remark}[\textbf{On Samples \eqref{eq: Sip}}]\label{Remark: samples}
	The data $\dot{x}_i \left(t_0 + k\tau\right)$, for $k \in \{0, 1, \dots, (\mathcal{T}-1)\}$, contained in $\Sip$ and $\barSip$, can be estimated using numerical differentiation. For instance, applying the forward difference approximation method yields
	$
	\dot{x}_{ji} \left(t_0 + k\tau\right) = \frac{x_{ji}\left(t_0 + (k+1)\tau\right) - x_{ji} \left(t_0 + k\tau\right)}{\tau} + e_{ji}\left(t_0 + k\tau\right), j \in \{1, \ldots, n_i\},
	$
	where the error term $e_{ji}\left(t_0 + k\tau\right)$ scales with $\tau$ and can be interpreted as noise \cite{guo2022data}. While this paper assumes noise-free data for the sake of a clear presentation, techniques such as total variation regularization can be utilized to reduce the effects of noise on derivative approximations in cases where the data is noisy \cite{rudin1992nonlinear}.
\end{remark}

Inspired by \cite{de2023learning}, the following lemma establishes the data-driven representation of each nominal \Subsys\ $\Upsilon_i^\ast$. This formulation further enables the characterization of the unknown matrix $\mathcal{B}_i$ from the second input-output trajectory of the nominal \Subsys\ $\Upsilon_i^\ast$, which is subsequently utilized in Subsection \ref{subsec: ISM_data}.

\begin{lemma}[\textbf{Data-based Representation of $\Upsilon_i^\ast$}]\label{Lemma-rep}
	Given a nominal \Subsys\ $\Upsilon_i^\ast$, let $\mathcal{G}_i = [\mathcal{G}_{1_i} \; \mathcal{G}_{2_i}] \in \R^{\mathcal{T} \times z_i}$ and $\mathcal{Q}_i \in \R^{\mathcal{T} \times \mathcal{T}}$ represent arbitrary matrices, where $\mathcal{G}_{1_i} \in \R^{\mathcal{T} \times n_i}$ and $\mathcal{G}_{2_i} \in \R^{\mathcal{T} \times (z_i - n_i)}$, that satisfy the following conditions:
	\begin{subequations}\label{eq: lemma_equalities}
		\begin{align}
			\I_{z_i} & = \PD \mathcal{G}_i, \label{eq: lemma_eq1}\\
			\PD & = \barPD \mathcal{Q}_i. \label{eq: lemma_eq2}
		\end{align}
	\end{subequations}
	By designing the nominal local controller as
	\begin{align}
		u_i^\ast = \mathbfcal{K}_i\mathcal{Z}_i(x_i), \label{eq: lemma_u}
	\end{align}
	where $\mathbfcal{K}_i = \Ii \mathcal{G}_i$,
	the closed-form data-based representation of $\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast$ can be expressed as
	\begin{align}
		\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast = \; & (\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{1_i} x_i \notag\\
		&+ (\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{2_i} \mathcal{M}_i(x_i), \label{eq: lemma_closed}
	\end{align}
	while the control input matrix $\mathcal{B}_i$ has the following data-based characterization:
	\begin{align}
		\mathcal{B}_i = (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger}. \label{eq: lemma_B}
	\end{align}
\end{lemma}

\begin{proof}
	Based on the first input-state trajectory, the nominal \Subsys\ $\dot{x}_i  = \mathcal{A}_i \mathcal{Z}_i(x_i ) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i $ can be equivalently formulated as
	\begin{align}
		\Sip = \mathcal{A}_i \PD + \mathcal{B}_i \Ii + \mathcal{D}_i \Wi. \label{tmp1}
	\end{align}
	Accordingly, based on the second trajectory gathered  with a \emph{zero control input} $\barIi = \bbzero_{m_i \times \mathcal{T}}$, we have
	\begin{align*}
		\barSip = \mathcal{A}_i \barPD + \mathcal{D}_i \barWi. 
	\end{align*}
	Consequently, one has
	\begin{align}
		\mathcal{A}_i \barPD = \barSip - \mathcal{D}_i \barWi \overset{\! \eqref{eq: lemma_eq2}}{\Rightarrow} \mathcal{A}_i \PD = (\barSip - \mathcal{D}_i \barWi)\mathcal{Q}_i. \label{tmp2}
	\end{align}
	Thus, by substituting \eqref{tmp2} in \eqref{tmp1}, one gets
	\begin{align*}
		\mathcal{B}_i = (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger},
	\end{align*}
	which is in accordance with \eqref{eq: lemma_B}. At the same time, one has
	\begin{align*}
		&\mathcal{A}_i \mathcal{Z}_i(x_i ) + \mathcal{B}_i u_i^\ast\\
		& \overset{\eqref{eq: lemma_u}}{=} \mathcal{A}_i \mathcal{Z}_i(x_i ) + \mathcal{B}_i \Ii \mathcal{G}_i\mathcal{Z}_i(x_i ) = (\mathcal{A}_i + \mathcal{B}_i \Ii \mathcal{G}_i) \mathcal{Z}_i(x_i )\\
		& \! \overset{\eqref{eq: lemma_eq1}}{=} (\mathcal{A}_i \overbrace{\PD \mathcal{G}_i}^{\I_{z_i}} + \mathcal{B}_i \Ii \mathcal{G}_i) \mathcal{Z}_i(x_i ) = (\mathcal{A}_i \PD + \mathcal{B}_i \Ii) \mathcal{G}_i \mathcal{Z}_i(x_i )\\
		& \overset{\eqref{tmp1}}{=} (\Sip - \mathcal{D}_i \Wi) \mathcal{G}_i \mathcal{Z}_i(x_i ) \!=\! (\Sip - \mathcal{D}_i \Wi) [\mathcal{G}_{1_i} \;\; \mathcal{G}_{2_i}] \mathcal{Z}_i(x_i )\\
		& \, \overset{\eqref{eq: dictionary}}{=}  (\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{1_i} x_i  + (\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{2_i} \mathcal{M}_i(x_i ),
	\end{align*}
	thereby concluding the proof.
\end{proof}

\begin{remark}[\textbf{Richness of Data}]\label{Remark-richness}
	If the data matrices $\PD$ and $\barPD$ are \emph{full-row rank}, it is always possible to construct $\mathcal{G}_i$ and $\mathcal{Q}_i$ that satisfy conditions \eqref{eq: lemma_equalities}. To ensure that $\PD$ and $\barPD$ have full-row rank, the number of samples $\mathcal{T}$ must satisfy the condition $\mathcal{T} > z_i$. Since both matrices $\PD$ and $\barPD$ are obtained from sampled data, meeting this full-row rank requirement is very straightforward.
\end{remark}

Now, by utilizing the data-based representation of $\mathcal{A}_i \mathcal{Z}_i(x_i ) + \mathcal{B}_i u_i^\ast$ established in Lemma \ref{Lemma-rep}, we present the following theorem as one of the key contributions of this work. This theorem provides a method for constructing ISS Lyapunov functions and their associated local controllers for each nominal subsystem directly from data.

\begin{theorem}[\textbf{Data-Driven ISS Lyapunov Functions}]\label{Theorem-data-iss}
	Consider a nominal unknown \Subsys\ $\Upsilon_i^\ast$, and its data-based representation $\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast$ as in \eqref{eq: lemma_closed}. If, for some $\kappa_i, \mu_i \in \Rp,$ there exist matrices $\mathcal{G}_{2_i} \in \R^{\mathcal{T} \times (z_i - n_i)}, \mathcal{Y}_i \in \R^{\mathcal{T} \times n_i},$ and $\Phi_i \in \R^{n_i \times n_i}$, where $\Phi_i \succ 0$, fulfilling
	\begin{subequations}\label{eq: thm-iss}
		\begin{align}
			(\Sip - \mathcal{D}_i \Wi) \mathcal{G}_{2_i} &= \bbzero_{n_i \times (z_i - n_i)}, \label{eq : thm1}\\
			\PD \mathcal{G}_{2_i} &= \begin{bmatrix}
				\bbzero_{n_i \times (z_i - n_i)}\\
				\I_{z_i - n_i}
			\end{bmatrix}\!\!, \label{eq : thm2}\\
			\PD \mathcal{Y}_i &= \begin{bmatrix}
				\Phi_i\\
				\bbzero_{(z_i - n_i) \times n_i}
			\end{bmatrix}\!\!,\label{eq : thm3}\\
			\mathcal{Y}_i^\top (\Sip - \mathcal{D}_i \Wi)^{\! \top}&+ (\Sip - \mathcal{D}_i \Wi) \mathcal{Y}_i + \mu_i \I_{n_i} \preceq - \kappa_i \Phi_i, \label{eq : thm4}
		\end{align}
	\end{subequations}
	then $\V_i(x_i) = x_i^\top \MPI x_i$, with $\MPI \coloneq \Phi_i^{-1}$, is an ISS Lyapunov function for $\Upsilon_i^\ast$, with $\alpha_{1_i} = \lambda_{\min}(\MPI), \alpha_{2_i} = \lambda_{\max}(\MPI),$ and $\rho_i = \frac{\Vert \mathcal{D}_i \Vert^2}{\mu_i}$. Furthermore, the corresponding ISS controller $u_i^\ast$ is in the form of \eqref{eq: lemma_u} with $\mathbfcal{K}_i = \Ii \begin{bmatrix}
	\mathcal{Y}_i \MPI & \mathcal{G}_{2_i}
	\end{bmatrix}\!$.
\end{theorem}

\begin{proof}
	We initiate the proof by showing the satisfaction of condition \eqref{eq: ISS-con1}. Considering the \emph{quadratic} form of the ISS Lyapunov function $\V_i(x_i)$, we get
	\begin{align*}
		\lambda_{\min}(\MPI) \vert x_i \vert^2 \leq \V_i(x_i) \leq \lambda_{\max}(\MPI) \vert x_i \vert^2,
	\end{align*}
	concluding the fulfillment of condition \eqref{eq: ISS-con1} with $\alpha_{1_i} = \lambda_{\min}(\MPI)$ and $\alpha_{2_i} = \lambda_{\max}(\MPI).$
	
	We now continue by showing that under the conditions proposed in \eqref{eq: thm-iss}, condition \eqref{eq: ISS-con2} is also met. Let us define $\mathcal{G}_{1_i} \coloneq \mathcal{Y}_i \MPI,$ with $\MPI \coloneq \Phi_i^{-1}$. Subsequently, we demonstrate that conditions \eqref{eq : thm2} and \eqref{eq : thm3} together result in
	\begin{align*}
		\PD \begin{bmatrix}
			\mathcal{G}_{1_i} & \mathcal{G}_{2_i}
		\end{bmatrix} = \I_{z_i},
	\end{align*}
	which is in accordance with \eqref{eq: lemma_eq1}. Consequently, based on the Lie derivative in \eqref{eq: Lie derivative-subsystem}, one has
	\begin{align*}
		&\mathsf{L} \V_i(x_i)\\
		& = \partial_{x_i} \V_i(x_i) (\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i)\\
		&= 2x_i^\top \MPI (\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i)\\
		& \! \overset{\eqref{eq: lemma_closed}}{=} 2x_i^\top \MPI ((\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{1_i} x_i  + (\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{2_i} \mathcal{M}_i(x_i )\\
		& \hspace{1.6cm}+ \mathcal{D}_i w_i )\\
		& \!\! \overset{\eqref{eq : thm1}}{=} 2x_i^\top \MPI ((\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{1_i} x_i + \mathcal{D}_i w_i )\\
		& = 2x_i^\top \MPI (\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{1_i} x_i + 2 \overbrace{x_i^\top \MPI}^{a_i} \overbrace{\mathcal{D}_i w_i}^{b_i}.
	\end{align*}
	By utilizing the Cauchy-Schwarz inequality \cite{bhatia1995cauchy}, which states that $a_i b_i \leq \vert a_i \vert \vert b_i \vert$ for any $a_i^\top\!\!, b_i \in \R^{n_i}$, and subsequently applying Young's inequality \cite{young1912classes}, given by $\vert a_i \vert \vert b_i \vert \leq \frac{\mu_i}{2} \vert a_i \vert^2 + \frac{1}{2\mu_i} \vert b_i \vert^2$ for any $\mu_i \in \Rp$, one can follow that
	\begin{align*}
		&\mathsf{L} \V_i(x_i)\\
		& \leq 2x_i^\top \MPI (\Sip - \mathcal{D}_i \Wi)\mathcal{G}_{1_i} x_i + \mu_i x_i^\top \MPI \MPI x_i + \frac{1}{\mu_i} \vert \mathcal{D}_i w_i \vert^2.
	\end{align*}
	Through expanding the term obtained and factorizing $x_i^\top \MPI$ from left and $\MPI x_i$ from right, alongside employing the Cauchy-Schwarz inequality once again, and since $\mathcal{G}_{1_i} \coloneq \mathcal{Y}_i \MPI,$ we obtain
	\begin{align*}
		&\mathsf{L} \V_i(x_i)\\
		& \leq x_i^\top \MPI  \big[\overbrace{\MPI^{-1} \mathcal{G}_{1_i}^\top}^{\mathcal{Y}_i^\top} (\Sip - \mathcal{D}_i \Wi)^{\! \top} \!+\! (\Sip - \mathcal{D}_i \Wi) \overbrace{\mathcal{G}_{1_i} \MPI^{-1}}^{\mathcal{Y}_i } \\
		& \hspace{1.4cm} + \mu_i \I_{n_i} \big] \MPI x_i + \frac{1}{\mu_i} \Vert \mathcal{D}_i \Vert^2 \vert w_i \vert^2\\
		& = x_i^\top \MPI \big[\mathcal{Y}_i^\top (\Sip \!-\! \mathcal{D}_i \Wi)^{\! \top} \!+\! (\Sip \!-\! \mathcal{D}_i \Wi) \mathcal{Y}_i  \!+\! \mu_i \I_{n_i} \big] \MPI x_i\\
		& \hspace{.4cm}  + \frac{1}{\mu_i} \Vert \mathcal{D}_i \Vert^2 \vert w_i \vert^2\\
		& \! \overset{\eqref{eq : thm4}}{\leq} -\kappa_i \underbrace{x_i^\top \overbrace{\MPI \MPI^{-1}}^{\I_{n_i}} \MPI x_i}_{\V_i(x_i)} + \frac{1}{\mu_i} \Vert \mathcal{D}_i \Vert^2 \vert w_i \vert^2\\
		& = -\kappa_i \V_i(x_i) + \rho_i \vert w_i \vert^2,
	\end{align*}
	with $\rho_i = \frac{\Vert \mathcal{D}_i \Vert^2}{\mu_i},$ thereby concluding the proof.
\end{proof}

Having obtained the data-driven ISS Lyapunov function $\V_i(x_i)$ alongside its associated ISS controller $u_i^\ast$ for each nominal \Subsys\ $\Upsilon_i^\ast$, we now proceed with proposing our data-driven framework to design the ISM controller $u_{i}^{\mathrm{ISM}}$ for each subsystem $\Upsilon_i$, capable of rejecting matched perturbations $\mathcal{E}_i(x_i, t)$, in the subsequent subsection.

\subsection{Data-Driven ISM Control}\label{subsec: ISM_data}
In this subsection, we build upon the data-driven controller $u_i^\ast$, developed in the previous subsection, to design the discontinuous control law $u_{i}^{\mathrm{ISM}}$ as described in \eqref{eq: ISM_U} for each \Subsys\ $\Upsilon_i$ using data,  thereby eliminating the need for knowledge of the nominal dynamics required in classical ISM control \cite{utkin1996integral}. This leads to the following novel data-driven ISM control.

By leveraging the data-based representation of $\Upsilon_i^\ast$ in \eqref{eq: lemma_closed}, the dynamics of the transient function in \eqref{eq: transient} can be reformulated as
\begin{align}
	\dot{\zeta}_i & = -\frac{\partial \sigma_{0_i}(x_i)}{\partial x_i} (\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i)\notag\\
	& \overset{\eqref{eq: lemma_closed}}{=} -\frac{\partial \sigma_{0_i}(x_i)}{\partial x_i}((\Sip - \mathcal{D}_i \Wi) \mathcal{G}_i \mathcal{Z}_i(x_i) + \mathcal{D}_i w_i), \label{eq: transient_new}
\end{align}
with $\mathcal{Z}_i(x_i)$ as in \eqref{eq: dictionary} and $\zeta_i(t_0) = - \sigma_{0_i}(x_i(t_0))$, where $t_0 \in \Rpz$ is the initial time instant.

We now proceed to address the second part of Problem \ref{Problem 1}, which involves designing the controller $u_{i}^{\mathrm{ISM}}$ in \eqref{eq: ISM_U} for each \Subsys\ $\Upsilon_i$ using data, ensuring that the controlled subsystem remains robust against the matched perturbation $\mathcal{E}_i(x_i, t)$. Note that the perturbation vector $\mathcal{E}_i(x_i, t)$ satisfies the matching condition $\mathcal{E}_i(x_i, t) = \mathcal{B}_i \gamma_i(x_i, t)$, where $\gamma_i(x_i, t) \in \R^{m_i}$. It is assumed that 
\begin{align}
	\gamma_i(x_i, t) \in \Gamma_i, \label{eq: Gamma}
\end{align}
where $\Gamma_i$ is a compact set that contains the origin. Furthermore, a known upper bound is defined as $$\Gamma_i^{\sup} = \sup_{\gamma_i(x_i, t) \in \Gamma_i} \vert \gamma_i(x_i, t) \vert,$$ which is in accordance with Assumption \ref{Assumption: bound_disturbance}.

Without loss of generality, the term $\sigma_{0_i}(x_i)$ in the integral sliding variable \eqref{eq: integral sliding variable} can be chosen as a linear combination of the state, expressed as $\sigma_{0_i}(x_i) = \mathcal{C}_i x_i$, where $\mathcal{C}_i = \frac{\partial \sigma_{0_i}(x_i)}{\partial x_i} \in \R^{m_i \times n_i}$. Note that the matrix $\mathcal{C}_i$ is designed to satisfy the condition $\mathcal{C}_i \mathcal{B}_i \succ 0$. However, since $\mathcal{B}_i$ is assumed to be unknown, we substitute it with its data-based characterization obtained in \eqref{eq: lemma_B}. Hence, the matrix $\mathcal{C}_i$ must be designed such that $\mathcal{C}_i \big( \! (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger} \big) \succ 0$.

In the following lemma, we propose a condition under which the integral sliding manifold $\sigma_i(x_i) = \bbzero_{m_i}$ is maintained for all $t \in \Rpz$, thereby consistently rejecting the perturbation, that is maintaining the robustness properties of the model-based counterpart in \cite{utkin1996integral}.

\begin{lemma}[\textbf{Designing $\Theta_i$}]\label{Lemma: rho}
	Consider a \Subsys\ $\Upsilon_i$ as defined in \eqref{eq: final_subsys}, controlled by $u_i = u_i^\ast + u_{i}^{\mathrm{ISM}}$, where $u_i^\ast = \mathbfcal{K}_i \mathcal{Z}_i(x_i)$, $u_{i}^{\mathrm{ISM}}$ is given by \eqref{eq: ISM_U}, and the integral sliding variable is chosen as $\sigma_i(x_i) = \sigma_{0_i}(x_i) + \zeta_i(t)$, with $\zeta_i$ as obtained in \eqref{eq: transient_new}. Let \eqref{eq: Gamma} hold, and suppose the condition $\mathcal{C}_i \big( \! (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger} \big) \succ 0$ is satisfied. If the control gain $\Theta_i \in \Rp$ is designed such that
	\begin{align}
		\Theta_i >\Gamma_i^{\sup}  \frac{\lambda_{\max}\big (\mathcal{C}_i \big( \! (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger} \big)\!\big)}{\lambda_{\min}\big (\mathcal{C}_i \big( \! (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger} \big)\! \big)}, \label{eq: Theta}
	\end{align}
	then a  sliding mode $\sigma_i (x_i) = \bbzero_{m_i}$  is enforced for any $t \in \Rpz$.
\end{lemma}

\begin{proof}
	Consider a Lyapunov function $\mathbb{V}_{\! i} : \R^{m_i} \to \Rpz$ defined as
	\begin{align*}
		\mathbb{V}_{\! i} = \frac{1}{2} \sigma_i^\top  \sigma_i.
	\end{align*}
	By exploiting \eqref{eq: transient_new}, one has
	\begin{align}\notag
		\dot{\mathbb{V}}_{\! i} & = \sigma_i^\top \dot{\sigma}_i = \sigma_i^\top (\dot{\sigma}_{0_i} + \dot{\zeta}_i)\\\notag
		& \! \overset{\eqref{eq: transient_new}}{=} \sigma_i^\top (\mathcal{C}_i \dot{x}_i - \mathcal{C}_i ((\Sip - \mathcal{D}_i \Wi) \mathcal{G}_i \mathcal{Z}_i(x_i) + \mathcal{D}_i w_i))\\\notag
		& \overset{\eqref{eq: final_subsys}}{=} \sigma_i^\top (\mathcal{C}_i ( \mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i (u_i^\ast + u_{i}^{\mathrm{ISM}}) + \mathcal{D}_i w_i + \mathcal{E}_i (x_i, t))\\\label{New6}
		& \hspace{1cm} - \mathcal{C}_i (\mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i)).
	\end{align}
	Since $\mathcal{E}_i(x_i, t) = \mathcal{B}_i \gamma_i(x_i, t),$ and the common terms in \eqref{New6} cancel each other, one gets
	\begin{align*}
		\dot{\mathbb{V}}_{\! i} & = \sigma_i^\top \mathcal{C}_i \mathcal{B}_i (u_{i}^{\mathrm{ISM}} + \gamma_i)\\
		& \! \overset{\eqref{eq: ISM_U}}{=} \sigma_i^\top \! \Big(-\Theta_i \mathcal{C}_i \mathcal{B}_i \, \frac{\sigma_i}{\vert \sigma_i \vert} + \mathcal{C}_i \mathcal{B}_i \gamma_i \Big)\\
		& = -\Theta_i \sigma_i^\top \mathcal{C}_i \mathcal{B}_i \, \frac{\sigma_i}{\vert \sigma_i \vert} + \gamma_i^\top (\mathcal{C}_i \mathcal{B}_i)^\top \sigma_i\\
		& \! \overset{\eqref{eq: Gamma}}{\leq} -\Theta_i \lambda_{\min}(\mathcal{C}_i \mathcal{B}_i) \frac{\sigma_i^\top \sigma_i}{\vert \sigma_i \vert} + \Gamma_i^{\sup}  \lambda_{\max}(\mathcal{C}_i \mathcal{B}_i) \vert \sigma_i \vert\\
		& = -(\Theta_i \lambda_{\min}(\mathcal{C}_i \mathcal{B}_i) - \Gamma_i^{\sup}  \lambda_{\max}(\mathcal{C}_i \mathcal{B}_i)) \vert \sigma_i \vert\\
		& = -\eta_i \vert \sigma_i \vert,
	\end{align*}
	with $\eta_i$ being obtained as the following by substituting $\mathcal{B}_i$ with its data-based representation in \eqref{eq: lemma_B}:
	\begin{align*}
		\eta_i & = \Theta_i \lambda_{\min}\big(\mathcal{C}_i \big( \! (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger} \big) \! \big) \notag\\
		& \hspace{0.4cm} - \Gamma_i^{\sup}  \lambda_{\max}\big(\mathcal{C}_i \big( \! (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger} \big) \! \big).
	\end{align*}
	Now, it is clear that $\eta_i$ is positive under the satisfaction of condition \eqref{eq: Theta}, rendering $\dot{\mathbb{V}}_{\! i} < 0.$ Since the so-called \emph{reachability condition} holds, one can conclude that there exists $\bar{t}>0$ such that $\sigma_i(t)=\bbzero_{m_i}$ for any $t\geq \bar{t}$. Moreover, since in $t_0 = 0,$  $\sigma_i(t_0)=\bbzero_{m_i}$ (according to \eqref{eq: integral sliding variable}), then $\sigma(t)=\bbzero_{m_i}$ for any $t \in \Rpz$, which concludes the proof.
\end{proof}

With Lemma \ref{Lemma: rho} having been proposed, we now continue with presenting the following theorem, which proves that the motion equation of each \Subsys\ $\Upsilon_i$ in sliding mode is equal to its nominal dynamics $\Upsilon_i^\ast$ controlled by $u_i^\ast$.

\begin{theorem}[\textbf{Motion Equation in Sliding Mode}]\label{Theorem: Filippov}
	Consider a \Subsys\ $\Upsilon_i$ in \eqref{eq: final_subsys}. Given the control law $u_i = u_i^\ast + u_{i}^{\mathrm{ISM}}$, with $u_i^\ast$ as in \eqref{eq: lemma_u}, $u_{i}^{\mathrm{ISM}}$ as in \eqref{eq: ISM_U}, and the sliding variable selected as $\sigma_i(x_i) = \sigma_{0_i}(x_i) + \zeta_i(t)$, with $\zeta_i$ as in \eqref{eq: transient_new},  if the sliding mode $\sigma_i = \bbzero_{m_i}$ is enforced for any $t \in \Rpz$, then the system motion in sliding mode is
	\begin{equation}
		\dot x_i = \mathcal{A}_i \mathcal{Z}_i(x_i) + \mathcal{B}_i u_i^\ast + \mathcal{D}_i w_i, \label{eq: ISSsys}
	\end{equation}
	which is ISS according to Theorem \ref{Theorem-data-iss}.
\end{theorem}

\begin{proof}
	By applying Lemma \ref{Lemma: rho}, it is ensured that the ISM is $\sigma_i = \bbzero_{m_i}$ for all $t \in \Rpz$, which also implies that $\dot{\sigma}_i = \bbzero_{m_i}$ in Filippov's sense \cite{filippov2013differential}. The latter enables the computation of the so-called equivalent control, denoted as $u_{i_\text{eq}}^{\mathrm{ISM}}$, which is expressed as
	\[
	\mathcal{C}_i \mathcal{B}_i (u_{i_\text{eq}}^{\mathrm{ISM}} + \gamma_i) = \bbzero_{m_i}.
	\]
	Under the assumption that $\mathcal{C}_i \mathcal{B}_i\succ 0$, it follows that $u_{i_\text{eq}}^{\mathrm{ISM}} = -\gamma_i$. By substituting this equivalent control into the \Subsys\ $\Upsilon_i$ in \eqref{eq: final_subsys}, which is now controlled by $u_i = u_i^\ast + u_{i_\text{eq}}^{\mathrm{ISM}}$, one can conclude that the nominal dynamic \eqref{eq: ISSsys} is obtained as the motion equation of each \Subsys\ $\Upsilon_i$ in sliding mode, which according to Theorem \ref{Theorem-data-iss}, is ISS, thereby completing the proof.
\end{proof}

With both components of each subsystem's controller designed using data, the following section presents our compositional condition grounded in \emph{small-gain reasoning} to develop a control Lyapunov function for the nominal network and its associated controller. This approach utilizes ISS Lyapunov functions of the individual nominal subsystems obtained from data. We subsequently extend this result to the derived with perturbations, ensuring the GAS property of the entire network.

\section{Compositional Framework}\label{Section: Compositional}

We analyze the nominal interconnected network $\Upsilon^\ast = \mathscr{N}(\Upsilon_1^\ast, \ldots, \Upsilon_N^\ast)$ by formulating a small-gain compositional condition and constructing a CLF derived from the ISS Lyapunov functions of its nominal subsystems. To achieve this, we define 
\begin{align}\label{new11}
	\mathcal{H} \coloneq \mathsf{diag}(\kappa_1, \dots, \kappa_N), \hat{\varrho} \coloneq \{\hat{\rho}_{ij}\}, ~\text{where}~ \hat{\rho}_{ij} = \frac{\rho_i}{\alpha_{1_j}},
\end{align}
with $\hat{\rho}_{ii} = 0$ for all $i \in \{1, \dots, N\}$.

The following theorem establishes the conditions under which a CLF for an unknown nominal network can be constructed using the data-driven ISS Lyapunov functions of its nominal subsystems.

\begin{theorem}[\textbf{Compositional Results}]\label{Theorem: comp}
	Consider a nominal interconnected network $\Upsilon^\ast = \mathscr{N}(\Upsilon_1^\ast, \ldots, \Upsilon_N^\ast),$ consisting of $N \in \Np$ nominal subsystems $\Upsilon_i^\ast$. Assume that each nominal subsystem $\Upsilon_i^\ast$ is equipped with a data-driven ISS Lyapunov function $\V_i$, as constructed in Theorem~\ref{Theorem-data-iss}. If the following condition holds:
	\begin{align}
		\mathds{1}_N^\top (-\mathcal{H} + \hat{\varrho}) \coloneq [\Xi_1 ; \dots ; \Xi_N]^\top < \bbzero_{1 \times N}, \label{eq: comp con}
	\end{align}
	or equivalently, $\Xi_i < 0$ for all $i \in \{1, \dots, N\}$, then
	\begin{align}\label{New9}
		\V(x) \coloneq \sum_{i=1}^N \V_i(x_i) = \sum_{i=1}^N x_i^\top \MPI x_i
	\end{align}
	is a CLF for the nominal network $\Upsilon^\ast$, where
	\begin{align*}
		&\kappa \coloneq -\Xi, \quad \max_{1 \leq i \leq N} \Xi_i < \Xi < 0, \\
		&\alpha_1 \coloneq \min_i \{\alpha_{1_i}\}, \quad \alpha_2 \coloneq \max_i \{\alpha_{2_i}\}.
	\end{align*}
	Furthermore, $ u^\ast \!=\! [u_1^\ast;\dots; u_N^\ast]$, where $u_i^\ast = \mathbfcal{K}_i \mathcal{Z}_i(x_i), i \in \{1, \ldots, N\},$ with $\mathbfcal{K}_i = \Ii \begin{bmatrix}
		\mathcal{Y}_i \MPI & \mathcal{G}_{2_i}
	\end{bmatrix}\!$, is a controller that ensures the GAS property of the nominal network.
\end{theorem}

\begin{proof}
	We begin by demonstrating that condition \eqref{eq: clf-con1-network} is fulfilled. Based on condition \eqref{eq: ISS-con1}, it follows that
	\begin{align*}
		\vert x \vert^2 = \sum_{i = 1}^{N}\vert x_i \vert^2 \leq \sum_{i = 1}^{N} \frac{1}{\alpha_{1_i}}\V_i(x_i) \leq \delta \sum_{i = 1}^{N} \V_i(x_i) = \delta \V(x),
	\end{align*}
	where $\delta = \underset{i}{\max}\{\frac{1}{\alpha_{1_i}}\}$. Then, through selecting $\alpha_1 = \frac{1}{\delta} = \underset{i}{\min}\{\alpha_{1_i}\}$, one gets
		\begin{align*}
			\alpha_1\vert x \vert^2 \leq \V(x).
		\end{align*}
		Similarly, from the upper bound in \eqref{eq: ISS-con1}, we have
		\begin{align*}
			\V(x) \!=\! \sum_{i = 1}^{N} \V_i(x_i) \!\leq \!\sum_{i = 1}^{N} \!\alpha_{2_i} \vert x_i \vert^2 \leq \alpha_2\! \sum_{i = 1}^{N} \!\vert x_i \vert^2 \!= \!\alpha_2 \vert x \vert^2,
		\end{align*}
		with $\alpha_2=\underset{i}{\max}\{\alpha_{2_i}\}$, indicating that condition \eqref{eq: clf-con1-network} is met with $\alpha_1 = \underset{i}{\min}\{\alpha_{1_i}\}$ and $\alpha_2=\underset{i}{\max}\{\alpha_{2_i}\}$.
		
		Next, we demonstrate that condition \eqref{eq: clf-con2-network} is also satisfied. Utilizing condition \eqref{eq: ISS-con2}, the compositional condition $\mathds{1}_N^{\top}(-\mathcal{H} + \hat{\varrho}) < \bbzero_{1 \times N}$, and by defining
		\begin{align}\label{new12}
			-\kappa s & \coloneq \max \big\{\mathds 1_N^{\top}(-\mathcal H+\hat \varrho) \overline{\V}(x) \mid \mathds 1_N^{\top} \overline{\V}(x)=s\big\}
		\end{align}
		where $\overline{\V}(x)=[\V_1( x_1) ; \dots ; \V_N(x_N)]$, we obtain the subsequent chain of inequalities:
		\begin{align*}
			&\mathsf{L} \V(x) \\
			&\overset{\eqref{New9}}{=} \mathsf{L}\sum_{i=1}^{N} \V_i(x_i) = \sum_{i=1}^{N} \mathsf{L} \V_i(x_i) \overset{\eqref{eq: ISS-con2}}{\leq} \sum_{i=1}^{N}\big(\!-\kappa_i \V_i(x_i)+\rho_i\vert w_i\vert^2\big)\\
			&=     \sum_{i=1}^{N}  \big(  -  \kappa_i \V_i(x_i)  +    \sum_{\substack{j=1 \\ j\neq i}}^{N}  \rho_i\vert w_{ij}\vert^2\big)     \\
			& =     \sum_{i=1}^{N}  \big(  -  \kappa_i \V_i(x_i)  +    \sum_{\substack{j=1 \\ j\neq i}}^{N}  \rho_i\vert x_j\vert^2\big)\\
			&\overset{\eqref{eq: ISS-con1}}{\leq}     \sum_{i=1}^{N}  \big(  -  \kappa_i \V_i(x_i)  +    \sum_{\substack{j=1 \\ j\neq i}}^{N}  \frac{\rho_i}{\alpha_{1_j}}  \V_j(x_j)  \big)    \\
			&\overset{\eqref{new11}}{=}    \sum_{i=1}^{N}  \big(  -  \kappa_i \V_i(x_i)  +    \sum_{\substack{j=1 \\ j\neq i}}^{N}  \hat \rho_{i j}  \V_j(x_j)  \big)\\
			&\overset{\eqref{new11}}{=} \mathds 1_N^\top(-\mathcal H + \hat \varrho)\underbrace{[\V_1(x_1); \dots; \V_N(x_N)]}_{\overline{\V}(x)}\overset{\eqref{new12}}{\leq} -\kappa \V(x).
		\end{align*}
		We now illustrate that $\kappa>0$ by choosing $\kappa = -\Xi$. Since $\mathds 1_N^{\top}(-\mathcal H+\hat \varrho)\coloneq[\Xi_1 ; \dots ; \Xi_N]^{\top}<\bbzero_{1 \times N}$, and $\underset{1 \leq i \leq N}{\max}\Xi_i<\Xi<0$, one gets
		\begin{align*}
			&-\kappa s\\
			&\overset{\eqref{new12}}{=}\mathds 1_N^{\top}(-\mathcal H+\hat \varrho) \overline{\V}(x)\!\overset{\eqref{eq: comp con}}{=}\![\Xi_1 ; \dots ; \Xi_N]^{\top}[\V_1(x_1);\dots ; \V_N(x_N)]\\
			&=\Xi_1 \V_1(x_1)\!+\!\dots\!+\!\Xi_N \V_N(x_N) \!\leq\! \Xi\big(\underbrace{\V_1(x_1)\!+\!\dots\!+\!\V_N(x_N)}_{\mathds 1_N^{\top} \overline{\V}(x) = s}\big)\\
			&\overset{\eqref{new12}}{=}\Xi s.
		\end{align*}
		Subsequently, $-\kappa s \leq \Xi s$, and consequently, $-\kappa \leq \Xi$ as $s$ is positive. Since $\underset{1 \leq i \leq N}{\max}\Xi_i<\Xi<0$, then $\kappa=-\mu > 0$, implying that condition \eqref{eq: clf-con2-network} is met, completing the proof.
\end{proof}

We now move on to extending the compositional result to the interconnected network $\Upsilon$ in the presence of external perturbations, as proposed in the following corollary.

\begin{algorithm}[t!]
		\caption{Data-driven design of the network's CLF and its corresponding controller}\label{Alg:1}
		\begin{center}
			\begin{algorithmic}[1]
				\REQUIRE 
				An available dictionary $\mathcal{Z}_i(x_i)$
                \FOR{$i = 1, \dots, N$}
                \STATE Collect two input-state trajectories $\Ii, \Si, \Wi, \Sip,$ $ \barSi, \barWi, \barSip$ as in \eqref{eq: data_ct} \label{STEP2}
                \STATE Given $\mathcal{Z}_i(x_i),$ construct $\PD$ and $\barPD$ as in \eqref{eq: PD}
                \STATE Compute $\mathcal{Q}_i$ from \eqref{eq: lemma_eq2}
                \STATE For a fixed $\kappa_i$ and $\mu_i,$ solve \eqref{eq : thm1}-\eqref{eq : thm4}, and design $\mathcal{G}_{2_i}, \mathcal{Y}_i,$ and $\Phi_i \succ 0$
                \STATE Given $\MPI = \Phi_i^{-1}$, compute $\alpha_{1_i}, \alpha_{2_i},$ and $\rho_i$ as in Theorem \ref{Theorem-data-iss}
                \STATE Compute $\V_i(x_i) = x_i^\top \MPI x_i$ as an ISS Lyapunov function for $\Upsilon_i^\ast$ with its local controller $u_i^\ast = \Ii \begin{bmatrix}
	               \mathcal{Y}_i \MPI & \mathcal{G}_{2_i}
	               \end{bmatrix}\mathcal{Z}_i(x_i)$ as in Theorem \ref{Theorem-data-iss}
                \STATE Determine $\mathcal{C}_i$ such that $\mathcal{C}_i \big( \! (\Sip - (\barSip - \mathcal{D}_i \barWi) \mathcal Q_i - \mathcal{D}_i \Wi)\Ii^{\! \dagger} \big) \succ 0$
                \STATE Construct $\sigma_{0_i}(x_i) = \mathcal{C}_i x_i$ and compute $\zeta_i$ from \eqref{eq: transient_new}
                \STATE Design $\Theta_i$ according to \eqref{eq: Theta}
                \STATE Obtain each local integral sliding manifold as $\sigma_i(x_i) = \sigma_{0_i}(x_i) + \zeta_i(t),$ and the local ISM controller $u_{i}^{\mathrm{ISM}}$ as in \eqref{eq: ISM_U}
		          \ENDFOR
                \IF{compositional condition \eqref{eq: comp con} is met}
                \STATE $\V(x) = \sum_{i=1}^N x_i^\top \MPI x_i$ is a CLF for the network, with $ \sigma \!=\! [\sigma_1;\dots; \sigma_N]$ being the integral sliding manifold of the network, where $\sigma_i(x_i) = \sigma_{0_i}(x_i) + \zeta_i(t)$, and with $ u \!=\! [u_1;\dots; u_N]$  being the network's GAS controller, where $u_i = u_i^\ast + u_{i}^{\mathrm{ISM}},$ according to Corollary \ref{Corollary: ext}
                \ELSE
                \STATE Return to Step \ref{STEP2}; collect different trajectories—potentially with a longer horizon—and proceed with the rest of steps
                \ENDIF
				\ENSURE
				CLF $\V(x) = \sum_{i=1}^N x_i^\top \MPI x_i$, integral sliding manifold $ \sigma \!=\! [\sigma_1;\dots; \sigma_N],$ with $\sigma_i(x_i) = \sigma_{0_i}(x_i) + \zeta_i(t),$ and GAS controller $ u \!=\! [u_1;\dots; u_N],$ with $u_i = u_i^\ast + u_{i}^{\mathrm{ISM}}$ 
			\end{algorithmic}
		\end{center}
	\end{algorithm}

\begin{corollary}[\textbf{Network's GAS Property}]\label{Corollary: ext}
	Given an interconnected network $\Upsilon = \mathscr{N}(\Upsilon_1, \ldots, \Upsilon_N),$ which consists of $N \in \Np$ \Subsys\ $\Upsilon_i,$ its controller $ u \!=\! [u_1;\dots; u_N],$ with $u_i = u_i^\ast + u_{i}^{\mathrm{ISM}}, i \in \{1, \ldots, N\},$ and an integral sliding variable selected as $ \sigma \!=\! [\sigma_1;\dots; \sigma_N],$ with $\sigma_i(x_i) = \sigma_{0_i}(x_i) + \zeta_i(t),$ if the sliding control gain is selected as $\Theta \!=\! [\Theta_1;\dots; \Theta_N],$ with $\Theta_i$ satisfying \eqref{eq: Theta} for all $i \in \{1,\dots,N\}$, then $\sigma = \bbzero_{m}$ is enforced for all $t \in \Rpz$. Consequently, the network motion in sliding mode is equal to the nominal controlled network $\Upsilon^\ast\!$, which is endowed with the GAS property.
\end{corollary}

\begin{proof}
	The proof directly follows from Lemma \ref{Lemma: rho}, Theorem \ref{Theorem: Filippov}, and Theorem \ref{Theorem: comp}. More precisely, since each $\Theta_i$ satisfies condition \eqref{eq: Theta}, it follows that each integral sliding variable $\sigma_i (x_i) = \bbzero_{m_i}$ for all $t \in \Rpz$ according to Lemma \ref{Lemma: rho}. Since $ \sigma \!=\! [\sigma_1;\dots; \sigma_N],$ we readily get $\sigma = \bbzero_{m},$ for all $t \in \Rpz$. Therefore, according to Theorem \ref{Theorem: Filippov}, it is clear that each subsystem's motion equation is equal to its nominal controlled dynamic. As a result, one can conclude that the result of Theorem \ref{Theorem: comp} extends to the network with perturbations, ensuring that the network $\Upsilon$ possesses the GAS property.
\end{proof}

We present Algorithm \ref{Alg:1}, outlining all the necessary steps for data-driven designing of the local ISS Lyapunov functions and associated controllers, local ISM controllers, and the network's CLF together with its corresponding sliding manifold and controller, rendering the GAS property for the interconnected network.

\section{Simulation Results}\label{Section: Simulation}

\begin{table*}[h!]
		\centering
		\caption{A broad overview of our data-driven results across \emph{five distinct topologies} of interconnected networks together with two computational cost indices \textsf{RT} and \textsf{MU}, where \textsf{RT} denotes the running time (seconds), and \textsf{MU} indicates the memory usage (Mbit), required for each subsystem.
        \label{table: info}}
		\resizebox{\linewidth}{!}{\begin{tabular}{@{}ccccccc@{}}
			\toprule
			\multirow{2}{*}[-0.25em]{Network} & \multirow{2}{*}[-0.25em]{Available $\mathcal Z_i(x_i)$} & \multicolumn{3}{c}{Network parameters} & \multicolumn{2}{c}{Computation costs}\\
			%			\addlinespace[10pt]
			\cmidrule(lr){3-5} \cmidrule(lr){6-7} \vspace{-0.25cm}\\
			{} & {} & Topology & $N$ & $\mathcal{T}$  & \textsf{RT} (sec) & \textsf{MU} (Mb)\\
			\midrule
			\myalign{l}{\multirow{5}{*}{}} & \multirow{5}{*}{$[x_{i_1}; x_{i_2}; x_{i_1}^2; x_{i_1} x_{i_2}; x_{i_2}^2; \sin{(x_{i_1}x_{i_2})}; \cos{(x_{i_1}x_{i_2})};\ln{(1 + x_{i_1}^2)}; \ln{(1 + x_{i_2}^2)}]$} & \myalign{l}{Fully connected}  & $1000$ & $10$  & $< 0.2$ & $8.80$ \\
			{} & {} & \myalign{l}{Ring}   & $2000$  & $10$ & $< 0.2$ & $  32.45$\\
			% \midrule
			{} & {}  &  \myalign{l}{Binary tree}   &	$4095$	&	$ 10	$		&	$< 0.2$	& $134.60$\\
			{}	& {} &	\myalign{l}{Star}	&		$2000$	&		$10$	&	$< 0.2$	& $32.45$	\\
			% \midrule
			{  }	&  {}	&	\myalign{l}{Line}	&		$2000$	&		$10$	&		$< 0.2$ & $32.45$	\\
			\bottomrule
		\end{tabular}}
	\end{table*}

\begin{figure}[t!]
    \centering
    \begin{subfigure}[b]{0.18\textwidth}
        \includegraphics[width=\textwidth]{Fully_Connected.pdf}
        \caption{Fully connected}
        \label{fig:subfig1}
    \end{subfigure}\vspace{0.4cm}
    \hfill
    \begin{subfigure}[b]{0.18\textwidth}
        \includegraphics[width=\textwidth]{Ring.pdf}
        \caption{Ring}
        \label{fig:subfig2}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{Tree.pdf}
        \caption{Binary tree}
        \label{fig:subfig3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.18\textwidth}
        \includegraphics[width=\textwidth]{Star.pdf}
        \caption{Star}
        \label{fig:subfig4}
    \end{subfigure}\vspace{0.4cm}
    \hfill
    \begin{subfigure}[b]{0.25\textwidth}
        \includegraphics[width=\textwidth]{Line.pdf}
        \caption{Line}
        \label{fig:subfig5}
    \end{subfigure}
    
    \caption{The distinct interconnection topologies used in the simulations (cf. Table \ref{table: info}). We note that in the binary tree topology, the number of subsystems is computed as $N = 2^l - 1$, where $l$ denotes the number of tree levels.}
    \label{fig: topologies}
\end{figure}

In this section, we demonstrate the effectiveness of our compositional data-driven approach by employing it for a large-scale interconnected network with complex nonlinearities. Using this network as a backbone, we examine five distinct interconnection topologies—fully connected, ring, binary tree, star, and line (cf. Figure \ref{fig: topologies})—and show that our approach ensures the GAS property of these networks. This holds despite the unknown dynamics of each subsystem (\emph{i.e.,} the matrices $\mathcal{A}_i$ and $\mathcal{B}_i$ are unknown, with only an \emph{exaggerated} dictionary \eqref{eq: dictionary} available for each subsystem) and the presence of external perturbations. For the reader's convenience, Table \ref{table: info} provides a general yet concise overview of these scenarios. All simulations were performed using \textsc{Matlab} \textit{R2023b} on a MacBook Pro (Apple M2 Max, 32GB memory). To maintain compactness, the time evolution of the signals is illustrated only for two representative topologies: the \emph{fully interconnected topology}, as the most challenging and strong case, and the \emph{line topology}.

Our central purpose is to design a CLF and its corresponding controller for the interconnected network with an unknown mathematical model. To achieve this, we collect two sets of input-state trajectories from nominal subsystems, as described in \eqref{eq: data_ct} and \eqref{eq: PD}, ensuring that conditions \eqref{eq : thm1}-\eqref{eq : thm4} are satisfied. This enables the construction of ISS Lyapunov functions and their corresponding local controllers for all nominal subsystems. This step is subsequently followed by designing a local ISM controller for each subsystem to ensure robustness against matched perturbations, utilizing Lemma \ref{Lemma: rho}. Ultimately, leveraging the compositional results of Theorem \ref{Theorem: comp} and Corollary \ref{Corollary: ext}, we design the CLF and its corresponding controller for the interconnected network in a compositional manner, ensuring the GAS property of the network in the presence of external perturbations. In the following subsections, we provide detailed descriptions of each scenario and present the corresponding results.

\subsection{Fully-connected Topology}\label{subsec:fully}
In this subsection, we consider a fully-connected network with $1000$ subsystems. It is worth noting that, while we choose a homogeneous network for simplicity, our framework is also capable of handling networks with \emph{heterogeneous} subsystems. Every subsystem has two state variables $x_i = [x_{i_1}; \, x_{i_2}], \forall i \in \{1, \dots, 1000\},$ and is affected by the rest of all subsystems in the interconnection topology. The dynamic upon which each subsystem evolves is as
\begin{align}
    \begin{split}\label{eq: ex1}
        \dot{x}_{i_1} & = x_{i_1} + x_{i_2} + 5 \times 10^{-4} \sum_{\substack{j=1 \\ j \neq i}}^{1000} x_{j_2},\\
        \dot{x}_{i_2} & = x_{i_1}^2 + x_{i_1} x_{i_2} + \ln{(1 + x_{i_2}^2)} + \cos{(x_{i_1}x_{i_2}) + u_i} \\ & \;\;\;\;+ 5 \times 10^{-4} \sum_{\substack{j=1 \\ j \neq i}}^{1000} x_{j_1} + \underbrace{20 \sin{(100\,t)}}_{\gamma_i}.
    \end{split}
\end{align}
One can rewrite the dynamics in \eqref{eq: ex1} in the form of~\eqref{eq: final_subsys} with
\begin{align}\label{New}
\mathcal{Z}_i(x_i) = [x_{i_1}; x_{i_2}; x_{i_1}^2; x_{i_1} x_{i_2}; \ln{(1 + x_{i_2}^2)}; \cos{(x_{i_1}x_{i_2})}],
\end{align}
and
\begin{align*}
    \mathcal{A}_i & = \begin{bmatrix}
        1 & 1 & 0 & 0 & 0 & 0\\
        0 & 0 & 1 & 1 & 1 & 1
    \end{bmatrix}\!,  \mathcal{B}_i  = \begin{bmatrix}
        0\\1
    \end{bmatrix}\!,  \mathcal{E}_i = \begin{bmatrix}
        0\\ 20 \sin{(100\, t)}
    \end{bmatrix}\!,
\end{align*}
and the adversarial matrix partitions
\begin{align*}
    \mathcal{D}_i = 5 \times 10^{-4} \times \begin{bmatrix}
        0 & 1\\1 & 0
    \end{bmatrix}\!.
\end{align*}
Subsequently, based on Definition \ref{def: network}, one gets
\begin{align*}
    \mathcal{A} &= \begin{bmatrix}
        \mathcal{A}_1 & \hat{\mathcal{D}}_{1\, 2} & \hat{\mathcal{D}}_{1\, 3} & \cdots & \hat{\mathcal{D}}_{1\, 1000}\\
        \hat{\mathcal{D}}_{2\, 1} & \mathcal{A}_2 & \hat{\mathcal{D}}_{2\, 3} & \cdots & \hat{\mathcal{D}}_{2\, 1000}\\
        \vdots &  & \ddots &  &  \vdots\\
        \hat{\mathcal{D}}_{999\, 1} & \cdots & \hat{\mathcal{D}}_{999\, 998} & \mathcal{A}_{999} & \hat{\mathcal{D}}_{999\, 1000}\\
        \hat{\mathcal{D}}_{1000\, 1} & \cdots & \hat{\mathcal{D}}_{1000\, 998} & \hat{\mathcal{D}}_{1000\, 999} & \mathcal{A}_{1000}
    \end{bmatrix}\!\!,\\
    \mathcal{B} &= \mathsf{blkdiag} (\mathcal{B}_1, \dots, \mathcal{B}_{1000}), \quad \mathcal{E}(t) = [\mathcal{E}_1(t); \dots; \mathcal{E}_{1000}(t)].
\end{align*}
We emphasize that $ \mathcal{A}_i, \mathcal{B}_i ,$ and $\mathcal{E}_i $ are all \emph{assumed to be unknown}, and an \emph{extensive dictionary}—different from the actual one in~\eqref{New}—is available as
\begin{align*}
	\mathcal{Z}_i(x_i) = [&x_{i_1}; x_{i_2}; x_{i_1}^2; x_{i_1} x_{i_2}; x_{i_2}^2; \sin{(x_{i_1}x_{i_2})}; \cos{(x_{i_1}x_{i_2})};\\ &\ln{(1 + x_{i_1}^2)}; \ln{(1 + x_{i_2}^2)}].
\end{align*} 

To meet our goal of guaranteeing the GAS property for this network, we employ our framework to design a CLF and its corresponding controller for the network. In doing so, we first start by gathering two sets of input-state trajectories from the nominal subsystems. More precisely, we gather $\mathcal{T} = 10$ samples in each experiment, with $\tau = 0.01$. 
To proceed, we set $\kappa_i = 2$ and $\mu_i = 1$, followed by solving the SDP \eqref{eq: thm-iss}. Consequently, we get $\rho_i = 2.4975 \times 10^{-4}$ and
\begin{align*}
    \mathbfcal{P}_i & = \begin{bmatrix}
        15.0904  &  3.5319\\
        3.5319   & 0.9630
    \end{bmatrix}\!, \alpha_{1_i} = 0.1292, \alpha_{2_i} = 15.9241,\\
    \mathbfcal{V}_i &= 15.0904\, x_{i_1}^2 + 7.0638\, x_{i_1} x_{i_2} + 0.9630\, x_{i_2}^2,
\end{align*}
satisfying the compositional condition \eqref{eq: comp con}.
Additionally, we design
\begin{align*}
    \mathbfcal{K}_i = \begin{bmatrix}
        -64.2573 &  -16.2470&  \!\! -1&  \!\! -1&  \!\! 0&  \!\! 0&   \!\! -1&   \!\! 0&  \!\! -1
    \end{bmatrix}\!.
\end{align*}
Having obtained $u_i^\ast$, we now proceed with designing the \emph{local ISM controller} $u_{i}^{\mathrm{ISM}}$. To this end, after solving \eqref{eq: lemma_eq2} and computing \eqref{eq: lemma_B}, we obtain $\mathcal{C}_i = [1 \;\; 1]$. Having these variables at hand, we set $\Theta_i = 20.1$ (cf. Lemma \ref{Lemma: rho} and \eqref{eq: Theta}). Thus, the local ISM controller $u_{i}^{\mathrm{ISM}}$ is also designed. Therefore, the CLF and the GAS controller for the unknown interconnected network are obtained as
\begin{align*}
    \mathbfcal{V} = \sum_{i=1}^{1000} \mathbfcal{V}_i(x_i), \quad u \!=\! [u_1;\dots; u_{1000}],
\end{align*}
where $u_i = u_i^\ast + u_{i}^{\mathrm{ISM}}$. Finally, $\alpha_1 = 0.1292, \alpha_2 = 15.9241,$ and $\kappa = 0.0688$.

We first simulate the situation in which we solely apply the local ISS controllers $u_i^\ast$ to the subsystems \emph{without} utilizing the local ISM controllers $u_{i}^{\mathrm{ISM}}$. Figure \ref{fig:ISS_Controller} depicts the simulation result of this scenario. As illustrated in Figure \ref{fig:ISS_Controller}, the origin is not a GAS equilibrium point for the network as expected. We now simulate the scenario in which the local ISM controllers $u_{i}^{\mathrm{ISM}}$ are also applied together with the local ISS controllers $u_i^\ast$. To do so, we choose the initial conditions from the set $x(0) \in [-5\times 10^5, \, 5\times 10^5]$, which is adequately large to be a testament to the effectiveness of our proposed methodology. The simulation result of this scenario is depicted in Figure \ref{fig:ISM_Controller}. As it can be seen, the trajectories are steered to the origin \emph{despite the existence of external perturbation}s, rendering the origin a GAS equilibrium point for the network. Furthermore, the time behavior of the sliding  variable components is given in Figure \ref{fig:SM_Comp}, which aligns precisely with our theoretical expectations (cf. Lemma \ref{Lemma: rho}).

\begin{remark}[\textbf{On the Number of Subsystems}]\label{Remark: Fully}
    It should be acknowledged that satisfying the compositional condition \eqref{eq: comp con} for interconnected networks with a fully connected topology can often be challenging. This is due primarily to the strong coupling between all subsystems, which is why this topology has fewer subsystems than other topologies (cf. Table \ref{table: info}).
\end{remark}

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.87\linewidth]{ISS_Controller.pdf}
	\caption{$10$ representative trajectories of the network (with the fully connected topology) with the designed local ISS controllers $u_i^\ast$, starting from different initial conditions  $x(0) \in [-1, \, 1]$, illustrating fluctuations around the origin.}
	\label{fig:ISS_Controller}
\end{figure}

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.87\linewidth]{ISM_Controller.pdf}
	\caption{$10$ representative trajectories of the network (with the fully connected topology) under the designed local controllers as in Corollary \ref{Corollary: ext}, starting from different initial conditions in $x(0) \in [-5\times 10^5, \, 5\times 10^5].$ }
	\label{fig:ISM_Controller}
\end{figure}

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.87\linewidth]{SM_Comp.pdf}
	\caption{Representative behavior of the sliding variable components. For clarity, only the sliding variable components of a single subsystem are shown.}
	\label{fig:SM_Comp}
\end{figure}

\subsection{Ring Topology}\label{subsec:ring}
Here, we consider the system in \eqref{eq: ex1} under the \emph{ring} topology and aim to design a GAS controller for such a network. For all $i \in \{2, \dots, 2000\}$, the dynamic of each subsystem is described as
\begin{align}
    \begin{split}\label{eq: ex2}
        \dot{x}_{i_1} & = x_{i_1} + x_{i_2} + 0.01\, x_{(i-1)_2},\\
        \dot{x}_{i_2} & = x_{i_1}^2 + x_{i_1} x_{i_2} + \ln{(1 + x_{i_2}^2)} + \cos{(x_{i_1}x_{i_2}) + u_i} \\ & \;\;\;\;+ 0.01\, x_{(i-1)_1} + \underbrace{20 \sin{(100\,t)}}_{\gamma_i},
    \end{split}
\end{align}
with the first subsystem being affected by the last one. The dictionary and all the network matrices are the same as those reported in Subsection \ref{subsec:fully}, except for $\mathcal{D}_i$ and $\mathcal{A}$ as 
\begin{align*}
    \mathcal{D}_i = \begin{bmatrix}
        0 & 0.01\\0.01 & 0
    \end{bmatrix}\!,
\end{align*}
\begin{align*}
    \mathcal{A} = \begin{bmatrix}
        \mathcal{A}_1 & \bbzero_{2 \times 6} & \bbzero_{2 \times 6} & \cdots & \hat{\mathcal{D}}_{1\, 2000}\\
        \hat{\mathcal{D}}_{2\, 1} & \mathcal{A}_2 & \bbzero_{2 \times 6} & \cdots & \bbzero_{2 \times 6}\\
        \vdots &  & \ddots &  &  \vdots\\
        \bbzero_{2 \times 6} & \cdots & \hat{\mathcal{D}}_{1999\, 1998} & \mathcal{A}_{1999} & \bbzero_{2 \times 6}\\
        \bbzero_{2 \times 6} & \cdots & \bbzero_{2 \times 6} & \hat{\mathcal{D}}_{2000\, 1999} & \mathcal{A}_{2000}
    \end{bmatrix}\!\!.
\end{align*}
We now follow the similar procedure as in Subsection \ref{subsec:fully} and set $\kappa_i = 1$ and $\mu_i = 1$. By solving the SDP \eqref{eq: thm-iss}, we obtain $\rho_i = 1 \times 10^{-4}$, and
\begin{align*}
    \mathbfcal{P}_i & = \begin{bmatrix}
        13.0865  &  3.9115\\
        3.9115   & 1.3517
    \end{bmatrix}\!, \alpha_{1_i} = 0.1674, \alpha_{2_i} = 14.2708,\\
    \mathbfcal{V}_i &= 13.0865\, x_{i_1}^2 + 7.8230\, x_{i_1} x_{i_2} + 1.3517\, x_{i_2}^2,
\end{align*}
fulfilling the compositional condition \eqref{eq: comp con}.
We also design
\begin{align*}
    \mathbfcal{K}_i = \begin{bmatrix}
        -44.7986 &  -14.1349 &  \!\! -1&  \!\! -1&  \!\! 0&  \!\! 0&   \!\! -1&   \!\! 0&  \!\! -1
    \end{bmatrix}\!.
\end{align*}
The values related to the local ISM controllers remain unchanged and are the same as those reported in Subsection \ref{subsec:fully}. Finally, the CLF and the GAS controller are designed as
\begin{align*}
    \mathbfcal{V} = \sum_{i=1}^{2000} \mathbfcal{V}_i(x_i), \quad u \!=\! [u_1;\dots; u_{2000}],
\end{align*}
where $u_i = u_i^\ast + u_{i}^{\mathrm{ISM}},$ with $\alpha_1 = 0.1674, \alpha_2 = 14.2708,$ and $\kappa = 0.9994$.

\subsection{Binary Tree Topology}
In this subsection, we continue to assess the effectiveness of our approach by applying it to an interconnected network with a \emph{binary tree} topology. We assume that the network has $4095$ subsystems, with the dynamic of each subsystem being described as follows:
\begin{align*}
    \begin{split}
        \dot{x}_{i_1} & = x_{i_1} + x_{i_2} + 10^{-2}\, \Omega(i =2j\, \vee \, i = 2j+1)x_{j_2},\\
        \dot{x}_{i_2} & = x_{i_1}^2 + x_{i_1} x_{i_2} + \ln{(1 + x_{i_2}^2)} + \cos{(x_{i_1}x_{i_2}) + u_i} \\ & \;\;\;\;+ 10^{-2}\, \Omega(i =2j\, \vee \, i = 2j+1)x_{j_1} + \underbrace{20 \sin{(100\,t)}}_{\gamma_i},
    \end{split}
\end{align*}
where $\vee$ stands for the logical \textsf{OR} operation and $\Omega$ is an indicator that we define it as
\begin{align*}
    \Omega(i =2j\, \vee \, i = 2j+1) = \begin{cases}
        1, & i =2j\, \vee \, i = 2j+1,\\
        0, & \text{Otherwise.}
    \end{cases}
\end{align*}
The dictionary and all network matrices remain the same as those specified in Subsection \ref{subsec:ring}, except for $\mathcal{A}$, which is characterized as follows:
\begin{align*}
    \mathcal{A} = \{\mathcal{A}_{ij}\} = \begin{cases}
        \mathcal{A}_i, & i = j,\\
        \hat{\mathcal{D}}_{i\, j}, & i =2j\, \vee \, i = 2j+1,\\
        \bbzero_{2 \times 6}, & \text{Otherwise.}
    \end{cases}
\end{align*}
Following the similar procedure outlined in Subsection \ref{subsec:fully}, we assign $\kappa_i = 0.5$ and $\mu_i = 1.2$. Subsequently, solving the SDP \eqref{eq: thm-iss} yields $\rho_i = 8.3333 \times 10^{-5}$ and
\begin{align*}
    \mathbfcal{P}_i & = \begin{bmatrix}
        9.9541  &  3.4329\\
        3.4329   & 1.3718
    \end{bmatrix}\!, \quad \alpha_{1_i} = 0.1676, \quad \alpha_{2_i} = 11.1583, \\
    \mathbfcal{V}_i &= 9.9541\, x_{i_1}^2 + 6.8658\, x_{i_1} x_{i_2} + 1.3718\, x_{i_2}^2,
\end{align*}
satisfying the compositional condition \eqref{eq: comp con}. 
Furthermore, we synthesize
\begin{align*}
    \mathbfcal{K}_i = \begin{bmatrix}
        -34.9103 &  -12.5503 &  \!\! -1 &  \!\! -1 &  \!\! 0 &  \!\! 0 &   \!\! -1 &   \!\! 0 &  \!\! -1
    \end{bmatrix}\!.
\end{align*}
The parameters associated with the local ISM controllers remain unchanged, as specified in Subsection \ref{subsec:fully}. Finally, the CLF and the GAS controller are designed as
\begin{align*}
    \mathbfcal{V} = \sum_{i=1}^{4095} \mathbfcal{V}_i(x_i), \quad u = [u_1;\dots; u_{4095}],
\end{align*}
where $u_i = u_i^\ast + u_i^{\mathrm{ISM}},$ with $\alpha_1 = 0.1676$, $\alpha_2 = 11.1583$, and $\kappa = 0.4990$.

\subsection{Star Topology}
We further evaluate the efficacy of our proposed approach by constructing an interconnected network with a \emph{star} topology. The network is assumed to consist of $2000$ subsystems, where, for all $i \in \{2, \dots, 2000\}$, the dynamics of each subsystem are characterized as 
\begin{align*}
    \begin{split}
        \dot{x}_{i_1} & = x_{i_1} + x_{i_2} + 10^{-2}\, x_{1_2},\\
        \dot{x}_{i_2} & = x_{i_1}^2 + x_{i_1} x_{i_2} + \ln{(1 + x_{i_2}^2)} + \cos{(x_{i_1}x_{i_2}) + u_i} \\ & \;\;\;\;+ 10^{-2}\, x_{1_1} + \underbrace{20 \sin{(100\,t)}}_{\gamma_i},
    \end{split}
\end{align*}
while the first subsystem evolves based on
\begin{align}
    \begin{split}\label{eq: ex4}
        \dot{x}_{1_1} & = x_{1_1} + x_{1_2},\\
        \dot{x}_{1_2} & = x_{1_1}^2 + x_{1_1} x_{1_2} + \ln{(1 + x_{1_2}^2)} + \cos{(x_{1_1}x_{1_2}) + u_1} \\ & \;\;\;\;+ \underbrace{20 \sin{(100\,t)}}_{\gamma_1}.
    \end{split}
\end{align}
Therefore, one has
\begin{align*}
    \mathcal{A} = \{\mathcal{A}_{ij}\} = \begin{cases}
        \mathcal{A}_i, & i = j,\\
        \hat{\mathcal{D}}_{i\, j}, & j=1, i\neq j,\\
        \bbzero_{2 \times 6}; & \text{Otherwise.}
    \end{cases}
\end{align*}
In accordance to the procedure described in Subsection \ref{subsec:fully}, we set $\kappa_i = 1.5$ and $\mu_i = 0.7$. By solving the SDP \eqref{eq: thm-iss}, we obtain $\rho_i = 1.4286 \times 10^{-4}$ along with the following results:
\begin{align*}
    \mathbfcal{P}_i &= \begin{bmatrix}
        17.0622  &  4.4805\\
        4.4805   & 1.3808
    \end{bmatrix}\!, \quad \alpha_{1_i} = 0.1909, \quad \alpha_{2_i} = 18.2521, \\
    \mathbfcal{V}_i &= 17.0622\, x_{i_1}^2 + 8.9610\, x_{i_1} x_{i_2} + 1.3808\, x_{i_2}^2,
\end{align*}
which satisfy the compositional requirement \eqref{eq: comp con}. Moreover, we derive
\begin{align*}
    \mathbfcal{K}_i = \begin{bmatrix}
        -50.0880 &  -14.1279 &  \!\! -1 &  \!\! -1 &  \!\! 0 &  \!\! 0 &   \!\! -1 &   \!\! 0 &  \!\! -1
    \end{bmatrix}\!.
\end{align*}
The parameters related to the local ISM controllers remain unchanged, as in Subsection \ref{subsec:fully}. Finally, the CLF and the GAS controller are designed as
\begin{align*}
    \mathbfcal{V} &= \sum_{i=1}^{2000} \mathbfcal{V}_i(x_i), \quad u = [u_1;\dots; u_{2000}],
\end{align*}
where $u_i = u_i^\ast + u_i^{\mathrm{ISM}}$, with the parameters $\alpha_1 = 0.1909$, $\alpha_2 = 18.2521$, and $\kappa = 4.2379 \times 10^{-3}$.

\begin{figure}[t!]
	\centering
	\begin{subfigure}[b]{0.475\textwidth}
		\includegraphics[width=0.87\textwidth]{ISM_Line_States.pdf}
		\caption{State variables evolution}
		\label{fig:subfig1_1}
	\end{subfigure}\vspace{0.4cm}
	
	
	\begin{subfigure}[b]{0.475\textwidth}
		\includegraphics[width=0.87\textwidth]{ISM_Sliding_Line.pdf}
		\caption{Sliding variable components evolution}
		\label{fig:subfig2_1}
	\end{subfigure}
	
	\caption{Figure \ref{fig:subfig1_1} illustrates $10$ representative trajectories of the network (with a line topology) governed by the locally designed controllers, as described in Corollary \ref{Corollary: ext}, with initial states \( x(0) \in [-5000, 5000] \). Moreover, Figure \ref{fig:subfig2_1} depicts the sample behavior of the sliding variable components.
	}
	\label{fig:2}
\end{figure}

\subsection{Line Topology}
Ultimately, we conclude this section by assessing our data-driven framework for an interconnected network with a \emph{line} topology, which comprises $2000$ subsystems. For all $i \in \{2, \dots, 2000\}$, the dynamic of each subsystem is similar to \eqref{eq: ex2}, whereas the first subsystem's dynamic is similar to \eqref{eq: ex4}. Hence, we get
\begin{align*}
    \mathcal{A} = \begin{bmatrix}
        \mathcal{A}_1 & \bbzero_{2 \times 6} & \bbzero_{2 \times 6} & \cdots & \bbzero_{2 \times 6}\\
        \hat{\mathcal{D}}_{2\, 1} & \mathcal{A}_2 & \bbzero_{2 \times 6} & \cdots & \bbzero_{2 \times 6}\\
        \vdots &  & \ddots &  &  \vdots\\
        \bbzero_{2 \times 6} & \cdots & \hat{\mathcal{D}}_{1999\, 1998} & \mathcal{A}_{1999} & \bbzero_{2 \times 6}\\
        \bbzero_{2 \times 6} & \cdots & \bbzero_{2 \times 6} & \hat{\mathcal{D}}_{2000\, 1999} & \mathcal{A}_{2000}
    \end{bmatrix}\!\!.
\end{align*}
Following the procedure of our framework, we first set $\kappa_i = 0.33$ and $\mu_i = 0.15$. Moreover, solving the SDP \eqref{eq: thm-iss} results in $\rho_i = 6.6667 \times 10^{-4}$ together with
\begin{align*}
    \mathbfcal{P}_i &= \begin{bmatrix}
        8.3454  &  2.9286\\
        2.9286   & 1.5218
    \end{bmatrix}\!, \quad \alpha_{1_i} = 0.4373, \quad \alpha_{2_i} = 9.4299, \\
    \mathbfcal{V}_i &= 8.3454\, x_{i_1}^2 + 5.8572\, x_{i_1} x_{i_2} + 1.5218\, x_{i_2}^2,
\end{align*}
which fulfill the compositional condition \eqref{eq: comp con}. We also design
\begin{align*}
    \mathbfcal{K}_i = \begin{bmatrix}
        -11.3491 &  -4.3779 &  \!\! -1 &  \!\! -1 &  \!\! 0 &  \!\! 0 &   \!\! -1 &   \!\! 0 &  \!\! -1
    \end{bmatrix}\!.
\end{align*}
The parameters associated with the local ISM controllers are aligned with those specified in Subsection \ref{subsec:fully}. The CLF and the GAS controller can be determined as
\begin{align*}
    \mathbfcal{V} &= \sum_{i=1}^{2000} \mathbfcal{V}_i(x_i), \quad u = [u_1;\dots; u_{2000}],
\end{align*}
where $u_i = u_i^\ast + u_i^{\mathrm{ISM}}$, with the parameters $\alpha_1 = 0.4373$, $\alpha_2 = 9.4299$, and $\kappa_i = 0.3285$. The simulation result of this topology is given in Figure \ref{fig:2}, which is exactly in accordance with our theoretical expectations.

\section{Conclusion}\label{Section: Conclusion}
In this work, we developed a compositional data-driven approach to guarantee the GAS property of large-scale nonlinear networks with unknown mathematical models subjected to external disturbances. The methodology consists of collecting two sets of data from each unknown nominal subsystem without external perturbations. The gathered data were then used to design an ISS Lyapunov function along with its corresponding controller for each nominal subsystem, ensuring their ISS properties. To achieve this, sufficient conditions were formulated as data-driven SDPs, enabling the simultaneous design of ISS Lyapunov functions and associated local controllers. To reject the effects of external disturbances on each subsystem and consequently on the entire network, a local ISM controller was designed for each subsystem using the collected data. Under small-gain compositional conditions, the designed data-driven ISS Lyapunov functions were utilized to construct a CLF for the network, thereby guaranteeing the GAS property of the nominal network. The compositional results were then extended to network models affected by external perturbations, where we demonstrated that the synthesized ISM controllers maintained the GAS property even in the presence of disturbances. We finally assessed the effectiveness of our proposed approach over large-scale interconnected networks with five different interconnection topologies.

\section*{References}
\vspace{-0.6906cm}

\bibliographystyle{IEEEtran}
\bibliography{biblio}	

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.3in,clip,keepaspectratio]{Behrad}}]{Behrad Samari}~(Student Member, IEEE) received his B.Sc. and M.Sc. degrees in electrical engineering, control major, from K. N. Toosi University of Technology, Tehran, Iran, and University of Tehran (UT), Tehran, Iran, in 2019 and 2022, respectively. He is currently pursuing his PhD in the School of Computing at Newcastle University, U.K. He is the Best Repeatability Prize Finalist at the 8$^{\text{th}}$ IFAC Conference on Analysis and Design of Hybrid Systems (ADHS), 2024. His research interests include (nonlinear) control and system theory, data-driven approaches, and formal methods.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.3in,clip,keepaspectratio]{GPI}}]{Gian Paolo Incremona}
(M’10, SM’23) is associate professor of automatic control at Politecnico di Milano. He was a student of the Almo Collegio Borromeo of Pavia, and of the Institute for Advanced Studies IUSS of Pavia. He received the bachelor’s and master’s degree’s summa cum laude in Electric Engineering, and the Ph.D. degree in Electronics, Electric and Computer Engineering from the University of Pavia in 2010, 2012 and 2016, respectively. From October to December 2014, he was with the Dynamics and Control Group at the Eindhoven Technology University, The Netherlands. He was a recipient of the 2018 Best Young Author Paper Award from the Italian Chapter of the IEEE Control Systems Society, and since 2018 he has been a member of the conference editorial boards of the IEEE Control System Society and of the European Control Association. At present, he is Associate Editor of the Journal Nonlinear Analysis: Hybrid Systems, International Journal of Control, and IEEE Control Systems Letters. His research is focused on sliding mode control, model predictive control and switched systems with application mainly to train control, robotics and power plants.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.3in,clip,keepaspectratio]{Antonella_Ferrara}}]{Antonella Ferrara}~(SM'03--Fellow'20)
Antonella Ferrara received the M.Sc. degree in Electronic Engineering and the Ph.D. degree in Electronic Engineering and Computer Science from the University of Genoa, Italy, in 1987 and 1992, respectively. Since 2005, she has been Full Professor of Automatic Control at the University of Pavia, Italy. Her research activities are mainly in the area of nonlinear control, with a special emphasis on sliding mode control, and application to robotics, power systems and road traffic. She is author and co-author of more than 450 publications including more than 170 journal papers, 2 monographs (published by Springer Nature and SIAM, respectively) and one edited book (IET). She is currently serving as Associate Editor of Automatica, and Senior Editor of the IEEE Open Journal of Intelligent Transportation Systems. She served as Senior Editor of the IEEE Transactions on Intelligent Vehicles, as well as Associate Editor of the IEEE Transactions on Control Systems Technology, IEEE Transactions on Automatic Control, IEEE Control Systems Magazine and International Journal of Robust and Nonlinear Control. Antonella Ferrara is the Chair of the EUCA Conference Editorial Board, the Director of Operations of the IEEE Control Systems Society, the Vice-Chair for Industry of the IFAC TC on Nonlinear Control Systems (2024-2026), a member of the IFAC Industry Board and of the IFAC Conference Board. She has been appointed as one of the two Program Chairs of the 24th IFAC Word Congress to be held in Amsterdam, The Netherlands, in 2029. Among several awards, she was a co-recipient of the 2020 IEEE Transactions on Control Systems Technology Outstanding Paper Award. She is a Fellow of IEEE, Fellow of IFAC and Fellow of AAIA. She is also a Senior Fellow of the Brussels Institute for Advanced Studies (BrIAS).
\end{IEEEbiography}

\begin{IEEEbiography}
	[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Abolfazl}}]{Abolfazl Lavaei}~(M'17--SM'22)
	is an Assistant Professor in the School of Computing at Newcastle University, United Kingdom. Between January 2021 and July 2022, he was a Postdoctoral Associate in the Institute for Dynamic Systems and Control at ETH Zurich, Switzerland. He was also a Postdoctoral Researcher in the Department of Computer Science at LMU Munich, Germany, between November 2019 and January 2021. He received the Ph.D. degree in Electrical Engineering from the Technical University of Munich (TUM), Germany, in 2019. He obtained the M.Sc. degree in Aerospace Engineering with specialization in Flight Dynamics and Control from the University of Tehran (UT), Iran, in 2014. He is the recipient of several international awards in the acknowledgment of his work including ADHS Best Repeatability Prize 2024 (Finalist, as an advisor) and 2021, HSCC Best Demo/Poster Awards 2022 and 2020, IFAC Young Author Award Finalist 2019, and Best Graduate Student Award 2014 at University of Tehran with the full GPA (20/20). His research interests revolve around the intersection of Control Theory, Formal Methods in Computer Science, and Data Science.
\end{IEEEbiography}

\end{document}
