@misc{mou2024sgbenchevaluatingllmsafety,
      title={SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types}, 
      author={Yutao Mou and Shikun Zhang and Wei Ye},
      year={2024},
      eprint={2410.21965},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.21965}, 
}
@misc{fernando2023promptbreederselfreferentialselfimprovementprompt,
      title={Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution}, 
      author={Chrisantha Fernando and Dylan Banarse and Henryk Michalewski and Simon Osindero and Tim Rocktäschel},
      year={2023},
      eprint={2309.16797},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.16797}, 
}
@misc{mehrotra2024treeattacksjailbreakingblackbox,
      title={Tree of Attacks: Jailbreaking Black-Box LLMs Automatically}, 
      author={Anay Mehrotra and Manolis Zampetakis and Paul Kassianik and Blaine Nelson and Hyrum Anderson and Yaron Singer and Amin Karbasi},
      year={2024},
      eprint={2312.02119},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.02119}, 
}
@misc{chao2024jailbreakingblackboxlarge,
      title={Jailbreaking Black Box Large Language Models in Twenty Queries}, 
      author={Patrick Chao and Alexander Robey and Edgar Dobriban and Hamed Hassani and George J. Pappas and Eric Wong},
      year={2024},
      eprint={2310.08419},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.08419}, 
}
@misc{yu2024gptfuzzerredteaminglarge,
      title={GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts}, 
      author={Jiahao Yu and Xingwei Lin and Zheng Yu and Xinyu Xing},
      year={2024},
      eprint={2309.10253},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.10253}, 
}
@misc{liu2024autodangeneratingstealthyjailbreak,
      title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models}, 
      author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
      year={2024},
      eprint={2310.04451},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.04451}, 
}

@misc{chen2024redteaminggpt4vgpt4v,
      title={Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?}, 
      author={Shuo Chen and Zhen Han and Bailan He and Zifeng Ding and Wenqian Yu and Philip Torr and Volker Tresp and Jindong Gu},
      year={2024},
      eprint={2404.03411},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.03411}, 
}
@misc{ding2024wolfsheepsclothinggeneralized,
      title={A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily}, 
      author={Peng Ding and Jun Kuang and Dan Ma and Xuezhi Cao and Yunsen Xian and Jiajun Chen and Shujian Huang},
      year={2024},
      eprint={2311.08268},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08268}, 
}

@misc{wei2024jailbreakguardalignedlanguage,
      title={Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations}, 
      author={Zeming Wei and Yifei Wang and Ang Li and Yichuan Mo and Yisen Wang},
      year={2024},
      eprint={2310.06387},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.06387}, 
}

@misc{li2024deepinceptionhypnotizelargelanguage,
      title={DeepInception: Hypnotize Large Language Model to Be Jailbreaker}, 
      author={Xuan Li and Zhanke Zhou and Jianing Zhu and Jiangchao Yao and Tongliang Liu and Bo Han},
      year={2024},
      eprint={2311.03191},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.03191}, 
}

@misc{shaikh2023secondthoughtletsthink,
      title={On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning}, 
      author={Omar Shaikh and Hongxin Zhang and William Held and Michael Bernstein and Diyi Yang},
      year={2023},
      eprint={2212.08061},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.08061}, 
}

@misc{samvelyan2024rainbowteamingopenendedgeneration,
      title={Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts}, 
      author={Mikayel Samvelyan and Sharath Chandra Raparthy and Andrei Lupu and Eric Hambro and Aram H. Markosyan and Manish Bhatt and Yuning Mao and Minqi Jiang and Jack Parker-Holder and Jakob Foerster and Tim Rocktäschel and Roberta Raileanu},
      year={2024},
      eprint={2402.16822},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16822}, 
}

@misc{perez2022redteaminglanguagemodels,
      title={Red Teaming Language Models with Language Models}, 
      author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nat McAleese and Geoffrey Irving},
      year={2022},
      eprint={2202.03286},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.03286}, 
}

@misc{ganguli2022redteaminglanguagemodels,
      title={Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned}, 
      author={Deep Ganguli and Liane Lovitt and Jackson Kernion and Amanda Askell and Yuntao Bai and Saurav Kadavath and Ben Mann and Ethan Perez and Nicholas Schiefer and Kamal Ndousse and Andy Jones and Sam Bowman and Anna Chen and Tom Conerly and Nova DasSarma and Dawn Drain and Nelson Elhage and Sheer El-Showk and Stanislav Fort and Zac Hatfield-Dodds and Tom Henighan and Danny Hernandez and Tristan Hume and Josh Jacobson and Scott Johnston and Shauna Kravec and Catherine Olsson and Sam Ringer and Eli Tran-Johnson and Dario Amodei and Tom Brown and Nicholas Joseph and Sam McCandlish and Chris Olah and Jared Kaplan and Jack Clark},
      year={2022},
      eprint={2209.07858},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.07858}, 
}

@misc{yi2024jailbreakattacksdefenseslarge,
      title={Jailbreak Attacks and Defenses Against Large Language Models: A Survey}, 
      author={Sibo Yi and Yule Liu and Zhen Sun and Tianshuo Cong and Xinlei He and Jiaxing Song and Ke Xu and Qi Li},
      year={2024},
      eprint={2407.04295},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2407.04295}, 
}
@misc{chowdhury2024breakingdefensescomparativesurvey,
      title={Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models}, 
      author={Arijit Ghosh Chowdhury and Md Mofijul Islam and Vaibhav Kumar and Faysal Hossain Shezan and Vaibhav Kumar and Vinija Jain and Aman Chadha},
      year={2024},
      eprint={2403.04786},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2403.04786}, 
}


@misc{kim2024adversarialdpoharnessingharmful,
      title={Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents}, 
      author={San Kim and Gary Geunbae Lee},
      year={2024},
      eprint={2405.12900},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.12900}, 
}

@misc{gallego2024configurablesafetytuninglanguage,
      title={Configurable Safety Tuning of Language Models with Synthetic Preference Data}, 
      author={Victor Gallego},
      year={2024},
      eprint={2404.00495},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.00495}, 
}

@misc{liu2024enhancingllmsafetyconstrained,
      title={Enhancing LLM Safety via Constrained Direct Preference Optimization}, 
      author={Zixuan Liu and Xiaolin Sun and Zizhan Zheng},
      year={2024},
      eprint={2403.02475},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.02475}, 
}

@misc{wolf2024tradeoffsalignmenthelpfulnesslanguage,
      title={Tradeoffs Between Alignment and Helpfulness in Language Models with Representation Engineering}, 
      author={Yotam Wolf and Noam Wies and Dorin Shteyman and Binyamin Rothberg and Yoav Levine and Amnon Shashua},
      year={2024},
      eprint={2401.16332},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.16332}, 
}

@misc{khaki2024rsdpohybridrejectionsampling,
      title={RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models}, 
      author={Saeed Khaki and JinJin Li and Lan Ma and Liu Yang and Prathap Ramachandra},
      year={2024},
      eprint={2402.10038},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10038}, 
}

@article{bai2023qwen,
  title={Qwen 1 technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{cui2024or,
  title={OR-Bench: An Over-Refusal Benchmark for Large Language Models},
  author={Cui, Justin and Chiang, Wei-Lin and Stoica, Ion and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2405.20947},
  year={2024}
}

@inproceedings{
anonymous2024safedpo,
title={Safe{DPO}: A Simple Approach to Direct Preference Optimization with Enhanced Safety},
author={Geon-Hyeong Kim and Youngsoo Jang and Yu Jin Kim and Byoungjip Kim and Honglak Lee and Kyunghoon Bae and Moontae Lee},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=MoJSnVZ59d},
note={under review}
}


@misc{su2024missionimpossiblestatisticalperspective,
      title={Mission Impossible: A Statistical Perspective on Jailbreaking LLMs}, 
      author={Jingtong Su and Julia Kempe and Karen Ullrich},
      year={2024},
      eprint={2408.01420},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.01420}, 
}

@misc{hong2024orpomonolithicpreferenceoptimization,
      title={ORPO: Monolithic Preference Optimization without Reference Model}, 
      author={Jiwoo Hong and Noah Lee and James Thorne},
      year={2024},
      eprint={2403.07691},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.07691}, 
}

@misc{meng2024simposimplepreferenceoptimization,
      title={SimPO: Simple Preference Optimization with a Reference-Free Reward}, 
      author={Yu Meng and Mengzhou Xia and Danqi Chen},
      year={2024},
      eprint={2405.14734},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.14734}, 
}

@misc{lambert2024tulu3pushingfrontiers,
      title={Tulu 3: Pushing Frontiers in Open Language Model Post-Training}, 
      author={Nathan Lambert and Jacob Morrison and Valentina Pyatkin and Shengyi Huang and Hamish Ivison and Faeze Brahman and Lester James V. Miranda and Alisa Liu and Nouha Dziri and Shane Lyu and Yuling Gu and Saumya Malik and Victoria Graf and Jena D. Hwang and Jiangjiang Yang and Ronan Le Bras and Oyvind Tafjord and Chris Wilhelm and Luca Soldaini and Noah A. Smith and Yizhong Wang and Pradeep Dasigi and Hannaneh Hajishirzi},
      year={2024},
      eprint={2411.15124},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15124}, 
}

@inproceedings{
zhu2024starlingb,
title={Starling-7B: Improving Helpfulness and Harmlessness with {RLAIF}},
author={Banghua Zhu and Evan Frick and Tianhao Wu and Hanlin Zhu and Karthik Ganesan and Wei-Lin Chiang and Jian Zhang and Jiantao Jiao},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=GqDntYTTbk}
}

@misc{tunstall2023zephyrdirectdistillationlm,
      title={Zephyr: Direct Distillation of LM Alignment}, 
      author={Lewis Tunstall and Edward Beeching and Nathan Lambert and Nazneen Rajani and Kashif Rasul and Younes Belkada and Shengyi Huang and Leandro von Werra and Clémentine Fourrier and Nathan Habib and Nathan Sarrazin and Omar Sanseviero and Alexander M. Rush and Thomas Wolf},
      year={2023},
      eprint={2310.16944},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.16944}, 
}

@misc{Intel, 
      title={Orca DPO Pairs}, url={https://huggingface.co/datasets/Intel/orca_dpo_pairs}, 
      year={2024},
      journal={Datasets at Hugging Face}, author={Intel}
} 

@misc{feng2024analyzingunderstandinglimitationsdpo,
      title={Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective}, 
      author={Duanyu Feng and Bowen Qin and Chen Huang and Zheng Zhang and Wenqiang Lei},
      year={2024},
      eprint={2404.04626},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.04626}, 
}

@misc{park2024disentanglinglengthqualitydirect,
      title={Disentangling Length from Quality in Direct Preference Optimization}, 
      author={Ryan Park and Rafael Rafailov and Stefano Ermon and Chelsea Finn},
      year={2024},
      eprint={2403.19159},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.19159}, 
}

@misc{rafailov2024scalinglawsrewardmodel,
      title={Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms}, 
      author={Rafael Rafailov and Yaswanth Chittepu and Ryan Park and Harshit Sikchi and Joey Hejna and Bradley Knox and Chelsea Finn and Scott Niekum},
      year={2024},
      eprint={2406.02900},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.02900}, 
}

@misc{ramamurthy2023reinforcementlearningnotnatural,
      title={Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization}, 
      author={Rajkumar Ramamurthy and Prithviraj Ammanabrolu and Kianté Brantley and Jack Hessel and Rafet Sifa and Christian Bauckhage and Hannaneh Hajishirzi and Yejin Choi},
      year={2023},
      eprint={2210.01241},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.01241}, 
}

@misc{rafailov2024directpreferenceoptimizationlanguage,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}

@misc{stiennon2022learningsummarizehumanfeedback,
      title={Learning to summarize from human feedback}, 
      author={Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},
      year={2022},
      eprint={2009.01325},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.01325}, 
}

@misc{christiano2023deepreinforcementlearninghuman,
      title={Deep reinforcement learning from human preferences}, 
      author={Paul Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
      year={2023},
      eprint={1706.03741},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1706.03741}, 
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{bai2022traininghelpfulharmlessassistant,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.05862}, 
}

@misc{sun2024trustllm,
  title={TrustLLM: Trustworthiness in Large Language Models},
  author={Lichao Sun et al.}, 
  year={2024},
  eprint={2401.05561},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@misc{wang2023donotanswer,
    author = {Yuxia Wang et al.},
    title = {Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs},
    year = {2023},
    howpublished = {arXiv preprint arXiv:2308.13387},
}

@misc{rottger2024xstest,
      title={XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models}, 
      author={Paul Röttger et al.},
      year={2024},
      eprint={2308.01263},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{qwen2,
  title={Qwen 2 Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}
@misc{abdin2024phi3technicalreporthighly,
      title={Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone}, 
      author={Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and Sébastien Bubeck and Martin Cai and Qin Cai and Vishrav Chaudhary and Dong Chen and Dongdong Chen and Weizhu Chen and Yen-Chun Chen and Yi-Ling Chen and Hao Cheng and Parul Chopra and Xiyang Dai and Matthew Dixon and Ronen Eldan and Victor Fragoso and Jianfeng Gao and Mei Gao and Min Gao and Amit Garg and Allie Del Giorno and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J. Hewett and Wenxiang Hu and Jamie Huynh and Dan Iter and Sam Ade Jacobs and Mojan Javaheripi and Xin Jin and Nikos Karampatziakis and Piero Kauffmann and Mahoud Khademi and Dongwoo Kim and Young Jin Kim and Lev Kurilenko and James R. Lee and Yin Tat Lee and Yuanzhi Li and Yunsheng Li and Chen Liang and Lars Liden and Xihui Lin and Zeqi Lin and Ce Liu and Liyuan Liu and Mengchen Liu and Weishung Liu and Xiaodong Liu and Chong Luo and Piyush Madan and Ali Mahmoudzadeh and David Majercak and Matt Mazzola and Caio César Teodoro Mendes and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Liliang Ren and Gustavo de Rosa and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Yelong Shen and Swadheen Shukla and Xia Song and Masahiro Tanaka and Andrea Tupini and Praneetha Vaddamanu and Chunyu Wang and Guanhua Wang and Lijuan Wang and Shuohang Wang and Xin Wang and Yu Wang and Rachel Ward and Wen Wen and Philipp Witte and Haiping Wu and Xiaoxia Wu and Michael Wyatt and Bin Xiao and Can Xu and Jiahang Xu and Weijian Xu and Jilong Xue and Sonali Yadav and Fan Yang and Jianwei Yang and Yifan Yang and Ziyi Yang and Donghan Yu and Lu Yuan and Chenruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou},
      year={2024},
      eprint={2404.14219},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.14219}, 
}
@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}
@misc{metallamaguard2,
  author =       {Llama Team},
  title =        {Meta Llama Guard 2},
  howpublished = {\url{https://github.com/meta-llama/PurpleLlama/blob/main/Llama-Guard2/MODEL_CARD.md}},
  year =         {2024}
}


@inproceedings{ding-etal-2024-wolf,
    title = "A Wolf in Sheep`s Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily",
    author = "Ding, Peng  and
      Kuang, Jun  and
      Ma, Dan  and
      Cao, Xuezhi  and
      Xian, Yunsen  and
      Chen, Jiajun  and
      Huang, Shujian",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.118/",
    doi = "10.18653/v1/2024.naacl-long.118",
    pages = "2136--2153",
    abstract = "Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to provide useful and safe responses. However, adversarial prompts known as {\textquoteleft}jailbreaks' can circumvent safeguards, leading LLMs to generate potentially harmful content. Exploring jailbreak prompts can help to better reveal the weaknesses of LLMs and further steer us to secure them. Unfortunately, existing jailbreak methods either suffer from intricate manual design or require optimization on other white-box models, which compromises either generalization or efficiency. In this paper, we generalize jailbreak prompt attacks into two aspects: (1) Prompt Rewriting and (2) Scenario Nesting. Based on this, we propose ReNeLLM, an automatic framework that leverages LLMs themselves to generate effective jailbreak prompts. Extensive experiments demonstrate that ReNeLLM significantly improves the attack success rate while greatly reducing the time cost compared to existing baselines. Our study also reveals the inadequacy of current defense methods in safeguarding LLMs. Finally, we analyze the failure of LLMs defense from the perspective of prompt execution priority, and propose corresponding defense strategies. We hope that our research can catalyze both the academic community and LLMs developers towards the provision of safer and more regulated LLMs. The code is available at https://github.com/NJUNLP/ReNeLLM."
}
@misc{andriushchenko2024doesrefusaltrainingllms,
      title={Does Refusal Training in LLMs Generalize to the Past Tense?}, 
      author={Maksym Andriushchenko and Nicolas Flammarion},
      year={2024},
      eprint={2407.11969},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.11969}, 
}

@article{mazeika2024harmbench,
  title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal},
  author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
  year={2024},
  eprint={2402.04249},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}
@inproceedings{wang-etal-2024-answer,
    title = "Do-Not-Answer: Evaluating Safeguards in {LLM}s",
    author = "Wang, Yuxia  and
      Li, Haonan  and
      Han, Xudong  and
      Nakov, Preslav  and
      Baldwin, Timothy",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.61/",
    pages = "896--911",
    abstract = "With the rapid evolution of large language models (LLMs), new and hard-to-predict harmful capabilities are emerging. This requires developers to identify potential risks through the evaluation of {\textquotedblleft}dangerous capabilities{\textquotedblright} in order to responsibly deploy LLMs. Here we aim to facilitate this process. In particular, we collect an open-source dataset to evaluate the safeguards in LLMs, to facilitate the deployment of safer open-source LLMs at a low cost. Our dataset is curated and filtered to consist only of instructions that responsible language models should not follow. We assess the responses of six popular LLMs to these instructions, and we find that simple BERT-style classifiers can achieve results that are comparable to GPT-4 on automatic safety evaluation. Our data and code are available at https://github.com/Libr-AI/do-not-answer"
}
@inproceedings{
bianchi2024safetytuned,
title={Safety-Tuned {LL}a{MA}s: Lessons From Improving the Safety of Large Language Models that Follow Instructions},
author={Federico Bianchi and Mirac Suzgun and Giuseppe Attanasio and Paul Rottger and Dan Jurafsky and Tatsunori Hashimoto and James Zou},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=gT5hALch9z}
}
@misc{zou2023universal,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{SCBSZ24,
      author = {Xinyue Shen and Zeyuan Chen and Michael Backes and Yun Shen and Yang Zhang},
      title = {{``Do Anything Now'': Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models}},
      booktitle = {{ACM SIGSAC Conference on Computer and Communications Security (CCS)}},
      publisher = {ACM},
      year = {2024}
}
@misc{vidgen2024simplesafetyteststestsuiteidentifying,
      title={SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models}, 
      author={Bertie Vidgen and Nino Scherrer and Hannah Rose Kirk and Rebecca Qian and Anand Kannappan and Scott A. Hale and Paul Röttger},
      year={2024},
      eprint={2311.08370},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08370}, 
}
@inproceedings{Deng_2024, series={NDSS 2024},
   title={MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots},
   url={http://dx.doi.org/10.14722/ndss.2024.24188},
   DOI={10.14722/ndss.2024.24188},
   booktitle={Proceedings 2024 Network and Distributed System Security Symposium},
   publisher={Internet Society},
   author={Deng, Gelei and Liu, Yi and Li, Yuekang and Wang, Kailong and Zhang, Ying and Li, Zefeng and Wang, Haoyu and Zhang, Tianwei and Liu, Yang},
   year={2024},
   collection={NDSS 2024} }
@inproceedings{shaikh-etal-2023-second,
    title = "On Second Thought, Let`s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",
    author = "Shaikh, Omar  and
      Zhang, Hongxin  and
      Held, William  and
      Bernstein, Michael  and
      Yang, Diyi",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.244/",
    doi = "10.18653/v1/2023.acl-long.244",
    pages = "4454--4470",
    abstract = "Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zero-shot CoT reasoning in sensitive domains significantly increases a model`s likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved."
}
@inproceedings{tdc2023,
  title={TDC 2023 (LLM Edition): The Trojan Detection Challenge},
  author={Mantas Mazeika and Andy Zou and Norman Mu and Long Phan and Zifan Wang and Chunru Yu and Adam Khoja and Fengqing Jiang and Aidan O'Gara and Ellie Sakhaee and Zhen Xiang and Arezoo Rajabi and Dan Hendrycks and Radha Poovendran and Bo Li and David Forsyth},
  booktitle={NeurIPS Competition Track},
  year={2023}
}


@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}

@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@article{llama3modelcard,
    title={Llama 3 Model Card},
    author={AI@Meta},
    year={2024},
    journal={},
    url = {https://github.com/meta-llama/llama3blob/main/MODEL_CARD.md}
}
@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}
@misc{qwen2025qwen25technicalreport,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2025},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115}, 
}
@misc{hu2024openrlhfeasytousescalablehighperformance,
      title={OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework}, 
      author={Jian Hu and Xibin Wu and Zilin Zhu and Xianyu and Weixun Wang and Dehao Zhang and Yu Cao},
      year={2024},
      eprint={2405.11143},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.11143}, 
}

@misc{tedeschi2024alertcomprehensivebenchmarkassessing,
      title={ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming}, 
      author={Simone Tedeschi and Felix Friedrich and Patrick Schramowski and Kristian Kersting and Roberto Navigli and Huu Nguyen and Bo Li},
      year={2024},
      eprint={2404.08676},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.08676}, 
}
@inproceedings{sun2023Delphi,
title={DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues},
author={David Q. Sun and Artem Abzaliev and Hadas Kotek and Zidi Xiu and Christopher Klein and Jason D. Williams},
booktitle={EMNLP},
year={2023}
}



@misc{kwon2023efficientmemorymanagementlarge,
      title={Efficient Memory Management for Large Language Model Serving with PagedAttention}, 
      author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
      year={2023},
      eprint={2309.06180},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.06180}, 
}

@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 07,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v0.4.3},
  doi          = {10.5281/zenodo.12608602},
  url          = {https://zenodo.org/records/12608602}
}

@misc{open-llm-leaderboard-v2,
  author = {Clémentine Fourrier and Nathan Habib and Alina Lozovskaya and Konrad Szafer and Thomas Wolf},
  title = {Open LLM Leaderboard v2},
  year = {2024},
  publisher = {Hugging Face},
  howpublished = "\url{https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard}",
}

@misc{hendrycks2021measuringmassivemultitasklanguage,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@article{gemma_2024,
    title={Gemma},
    url={https://www.kaggle.com/m/3301},
    DOI={10.34740/KAGGLE/M/3301},
    publisher={Kaggle},
    author={Gemma Team},
    year={2024}
}

@inproceedings{strubell-etal-2019-energy,
    title = "Energy and Policy Considerations for Deep Learning in {NLP}",
    author = "Strubell, Emma  and
      Ganesh, Ananya  and
      McCallum, Andrew",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1355/",
    doi = "10.18653/v1/P19-1355",
    pages = "3645--3650",
    abstract = "Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice."
}

@misc{chao2024jailbreakbenchopenrobustnessbenchmark,
      title={JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models}, 
      author={Patrick Chao and Edoardo Debenedetti and Alexander Robey and Maksym Andriushchenko and Francesco Croce and Vikash Sehwag and Edgar Dobriban and Nicolas Flammarion and George J. Pappas and Florian Tramer and Hamed Hassani and Eric Wong},
      year={2024},
      eprint={2404.01318},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.01318}, 
}


@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@misc{huang2023catastrophicjailbreakopensourcellms,
      title={Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation}, 
      author={Yangsibo Huang and Samyak Gupta and Mengzhou Xia and Kai Li and Danqi Chen},
      year={2023},
      eprint={2310.06987},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06987}, 
}

@misc{saeidi2024insightsalignmentevaluatingdpo,
      title={Insights into Alignment: Evaluating DPO and its Variants Across Multiple Tasks}, 
      author={Amir Saeidi and Shivanshu Verma and Chitta Baral},
      year={2024},
      eprint={2404.14723},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.14723}, 
}