\section{Introduction of safe data}\label{app:safe_data}

We explore the effect of safe data in safety training by training the models on mixtures of general preference data and unsafe data at different proportions (0\%, 25\%, 50\%, 75\%, 100\%). We use our dataset as unsafe data, and Infinity-Preference\footnote{\href{https://huggingface.co/datasets/BAAI/Infinity-Preference}{https://huggingface.co/datasets/BAAI/Infinity-Preference}} as general preference data.



\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/asr_all_ratios.pdf}
  \caption{Attack success rate (lower better) after models are aligned with an increasing proportion of safe samples. X axis is total safety alignment data.}\label{fig:safe_sizes}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/asr_all_ratios_by_unsafe.pdf}
  \caption{Attack success rate (lower better) after models are aligned with an increasing proportion of safe samples on the \bscrt{} test. X axis is total of unsafe data in safety alignment.}\label{fig:safe_sizes2}
\end{figure}

As shown in the Figures above, larger proportions of safe data reduce the safety of the model, regardless of size and proportion. Every combination and test conducted which included safe data was underperforming when compared to the alternative. A recommendation to dataset creators is made, to not mix safe samples in their data. 

