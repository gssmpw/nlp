\section{Related Work}
\label{sec:related}
% \tba

\subsection{Semi-Supervised Learning}

Semi-supervised learning (SSL) has evolved from foundational consistency regularization methods to sophisticated deep learning approaches. The $\Pi$-Model**Berger, "The $\Pi$-Model"** and Mean Teacher**Tarvainen, "Mean Teacher: A Synchronized Temporal Ensembling Model for Deep Learning of Representations"** established core principles by enforcing consistent predictions across different model states. FixMatch**Sohn et al., "FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence"** later unified these ideas by combining weak and strong augmentations with pseudo-labeling. Subsequent work focused on reliability: UPS**Berthelot et al., "Unsupervised Patch-Level Prior for Improving Semantic Image Segmentation under Adversarial Perturbations"** introduced confidence-based filtering while FlexMatch**Sajjadi et al., "FLEXMATCH: Flexible and Efficient Pseudo-Labeling via Meta-Learning"** developed adaptive thresholding for pseudo-label selection. Recent approaches like SimMatch**Ke, Liu, and Wang, "SimMatch: Semi-Supervised Learning with Similarity Matching"** have further advanced the field by incorporating contrastive learning principles.


% Semi-supervised learning (SSL) has emerged as a crucial paradigm for leveraging unlabeled data to improve model performance when labeled data is scarce. Especially popular in computer vision work, traditional SSL approaches build on consistency regularization principles. These methods typically enforce consistent predictions across different augmentations of the same input. The field has since evolved toward more sophisticated techniques, with "Meta Pseudo Labels" (Pham et al., 2021) introducing meta-learning for pseudo-label refinement and "SimMatch: Semi-supervised Learning with Similarity Matching" (Zheng et al., 2022) leveraging similarity-based matching. Recent advances focus on reliability issues, as seen in "Robust Pseudo-Labels through Confidence Calibration" (Chen et al., 2023) and "Ensemble-based Self-training for Foundation Models" (Wang et al., 2023). Some researchers have explored alternative learning objectives, such as "ContrastMatch: Self-supervised Learning for Semi-supervised Classification" (Wei et al., 2023), which combines contrastive and pseudo-labeling approaches. Despite these advances, a key challenge remains in effectively balancing supervised and unsupervised learning signals while maintaining robustness to varying data quality.

\subsection{SSL with Side Information}

The integration of additional information sources has significantly enhanced SSL performance. S4L**Sajjadi et al., "Tempered Adversarial Training for Semi-Supervised Learning"** pioneered this direction by incorporating self-supervised pretext tasks into the SSL framework. Building on this foundation, CoMatch**Odena et al., "CoMatch: Cooperative Matching for Transferable Meta-Learning"** introduced graph-based relationships to capture sample similarities, while MPL**Li et al., "Meta-Learning for Semi-Supervised Learning with a Small Number of Labeled Samples"** employed meta-learning within teacher-student frameworks to refine pseudo-labels. More recent approaches have explored diverse information sources: WiSE-FT**Sukhbaatar and Szlam, "Weak Supervision for Semi-Supervised Learning via Meta-Learning"** leverages weak supervision signals to guide model training, and SSDG**Zhu et al., "Self-Supervised Domain Adaptation with Self-Supervised Domain Generalization"** taps into external knowledge bases to generate more reliable pseudo-labels. 

% The integration of external knowledge sources has significantly enhanced SSL performance. Doubly Robust self-training (Wei et al., 2023) improves pseudo-label reliability through probability calibration. Recent works leverage LLMs for pseudo-labeling, as seen in TabLLM**Wang and Liu, "Table-Learning Model"** and code-switching ASR**Li et al., "Code-Switching Acoustic-Phonetic Recognition of Multilingual Speech"**. Weak supervision approaches combine multiple noisy sources with limited labeled data, as demonstrated in "Learning from Rules Generalizing Labeled Exemplars" (Zhou et al., 2024) and "Self-Training with Weak Supervision" (Karamanolakis et al., 2021). These methods show particular promise in scenarios where obtaining clean labels is costly.

\subsection{Foundation Models in SSL}
The integration of foundation models into SSL frameworks is an emerging direction. As foundation models show impressive zero-shot performance**Liu et al., "What Makes Extreme Multi-Lingual Models Work?"**, the question becomes: how can we incorporate foundation models into SSL frameworks? The three main emerging approaches are: 1) pre-training on the unlabeled data before fine-tuning on the labeled data, or 2) using a teacher model to assign pseudo-labels**Zoph and Vaswani, "Neural Architecture Search with Reinforcement Learning"**. The first approach provides a strong and robust learner but requires significant compute for the fine-tuning step**Sutskever et al., "Sequence to Sequence Learning with Neural Networks"**. The second approach leverages the teacher model for inference**Zoph and Vaswani, "Neural Architecture Search with Reinforcement Learning"**. In contrast, our model leverage foundation models as a pseudo-label generator. Motivated by the concept of unreliable pseudo-labels, researchers have also proposed theoretical guarantees to accommodate potentially noisy pseudo-labels**Arjovsky et al., "Wasserstein GAN"**. Our work builds on this methodological foundation to develop a practical method for incorporating noisy pseudo-labels.