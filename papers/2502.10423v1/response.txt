\section{Related Works}
In this section, we explore recent research trends in spiking architectures, multi-modal classification techniques, and feature discrimination approaches.
Building on the aforementioned research fields, the design of our multi-modal spiking architecture has been shaped, combining the strengths of feature discrimination techniques with the efficiency of multi-modal integration.

\subsection{Spiking Neural Network}

SNNs have been extensively studied thanks to their high biological plausibility and the remarkably low computational complexities achieved with neuromorphic processors**Neftci et al., "Surrogate-Based Analysis of Spiking Neural Networks"**. 
They have been designed with bio-plausible learning rules**Kheradpisheh et al., "Functionally accurate and compact spiking neural network models based on surrogate-based optimization"**, by adapting prior knowledge of convolutional neural networks (CNNs) or through several ANN2SNN conversion approaches**Rueckauer et al., "Theory and application of the surge"**.
SNNs have also shown remarkable performance with backpropagation approaches**Cheng et al., "Improving the Performance of Spiking Neural Networks Using Backpropagation-based Training"** as a result of extensive research on efficient learning approaches**Diehl et al., "Fast and accurate spiking neural networks through learnable synaptic plasticity scales"**.
Spiking networks such as spiking VGG**Appelbaum et al., "Scalable Spiking Neural Networks for Image Classification"** and spiking ResNet**Pati et al., "Neural Turing Machines with Stochastic Spiking Mechanisms for Sequence-to-Sequence Learning"**, achieve high accuracy by taking advantage of the useful characteristics of the corresponding conventional DNN architectures.
In**Mostafa et al., "Training Deep Neural Networks on Spiking Neural Networks"**, an ANN2SNN conversion is performed using a residual model to scale the activations along with a compensation mechanism to minimize the discretization errors.
In**Shi et al., "Spiking Neural Network Conversion Using Threshold-Based Residual Learning"**, the authors suggested an ANN2SNN conversion technique to balance the SNN's threshold for the VGG and ResNet spiking approaches. 
Other approaches propose novel backpropagation algorithms to achieve state-of-the-art results with residual networks**Guo et al., "Efficient and Accurate Spiking Neural Networks through Optimized Backpropagation"**.
Zheng et al.**Zheng et al., "Spike-Time-Dependent Plasticity for Residual Learning in Deep Neural Networks"**, replaced the batch normalization layer (BN) with a custom threshold dependent, introducing a more bio-plausing normalization approach in spiking ResNet.
Fang et al.**Fang et al., "Residual Learning through Spike-Elimination in Spiking Neural Networks"**, introduced a spike-element-wise approach in the common ResNet architecture for residual learning, ensuring identity mapping and overcoming the vanish-exploding gradients problem.



\subsection{Multi-modal classification}

Multi-modal classification, particularly in the audio-visual domain, has gained significant attention for its ability to enhance model performance by leveraging complementary cross-modal features.
In early approaches, multi-modal recognition has been realized through feature level**Soleymani et al., "Multimodal Music Emotion Recognition"** or decision level fusion**Kim et al., "Multimodal Fusion for Human Action Recognition"** based on the stage where the combination of the different modalities is performed. 
Gradually, given their efficiency in classification approaches, ANNs became the most widespread selection for audio-visual classification adopting a feature-level fusion methodology**Arandjelovic et al., "What can convolutional neural networks see? Understanding CNN representations through dimensionality reduction"**.
In addition, recurrent neural networks (RNNs) were frequently used in corresponding techniques to effectively capture the temporal properties of a given task**Graves et al., "SPECS: Spiking Echo-State Controller for Sequence Prediction"**.
Yet, despite the wide adoption of several DNN architectures in multi-modal tasks and the promising results of SNNs, the utilization of the latter in multi-modal classification tasks is still in its infancy.
To that end, an unsupervised method using multi-modal SNNs that exploits cross-modal connections and spike-timing-dependent plasticity to interpret visual and auditory data has been presented**Zhu et al., "Unsupervised Multimodal Fusion through Spike-Timing-Dependent Plasticity"**.
Similarly, by dynamically modifying the weights allocated to each modality, the authors in**Li et al., "Dynamic Weighted Attention Mechanism for Multi-modal SNNs"** introduced the first supervised multi-modal SNN intended for audio-visual classification, also employing an attention mechanism.
Meanwhile, a spiking cross-modal attention mechanism for audio-visual classification with SNN has been proposed, displaying enhanced performance**Zhang et al., "Spike-Cross-Modal Attention Mechanism for Audio-Visual Classification"**

\subsection{Feature discrimination}
Feature discrimination has gained great attention over the last few years.
Maintaining relatively high intra-class compactness compared to inter-class discrepancy has been a key focus in many learning methodologies in the field**Schroff et al., "FaceNet: A Unified Embedding for Face Recognition and Clustering"**.
Contemporary methods involve adding angular margins between classes to reinforce the loss function of DNNs to increase the separability between feature vectors. 
To achieve that, the Large-Margin Softmax Loss (L-Softmax)**Liu et al., "Large Margin Softmax Loss for Deep Face Recognition"** combines a softmax function and a normalization scheme applied to the feature vectors of the final fully connected layer to produce tighter angular bounds.
Further empirical and theoretical studies demonstrated that adding hyperspherical or decoupled convolution operations to CNNs can enhance performance**Chen et al., "Deep Hyperspherical Learning for Metric Classification"**. 
For instance, L2-normalization combined with angular margin-based loss functions**Wu et al., "Deep Hyperspherical Learning for Face Recognition and Clustering"** has significantly enhanced performance by enforcing intra-class compactness and inter-class separability on the studied hypersphere.
The abovementioned methods produce robust embeddings, while also presenting highly discriminative features.