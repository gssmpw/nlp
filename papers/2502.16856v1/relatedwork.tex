\section{Related Work}
\label{sec:related work}

\textbf{BIM Meets Robotics.} Early works by Boniardi \textit{et al.}~\cite{boniardi2016autonomous,boniardi2019pose} employed drawing maps and floor plans to facilitate robot navigation. LiDAR and visual-based robot localization (pose tracking) techniques were introduced in \cite{li2020online} and \cite{chen2024f3loc}, respectively. FloorplanNet by Feng \textit{et al.}~\cite{feng2023floorplannet} proposed learning features for global matching, thus enabling cross-modality global localization. Unlike traditional computer-aided design
(CAD) or floor plans, BIM encapsulates multi-dimensional information beyond mere geometrics. Studies by Yin \textit{et al.}~\cite{yin2022towards,yin2023semantic} transformed BIM into dense and semantic point clouds to facilitate LiDAR pose tracking. Hendrikx \textit{et al.}~\cite{hendrikx2021connecting} utilized feature points in BIM for robot localization. In addition to mobile robot localization, path planning was also achievable on BIM-based maps~\cite{hamieh2020bim,kim2022bim}.

Robotic techniques also benefit the BIM-aided construction automation. A promising direction is aligning SLAM-generated maps with BIM for construction purposes, focusing on aligning the two different modalities. The study in~\cite{lu2021novel} proposed extracting paths to achieve alignment for visual inspection on BIM. Our recent work~\cite{qiao2024speak} designed triangular descriptors for frame alignment between LiDAR maps and BIM. Another popular topic is converting as-built structures to BIM, known as Scan2BIM, for digital twin generation~\cite{wang2022object,wang2024omni}. The proposed SLABIM dataset provides both sensor data and BIM, allowing for the verification of most methods mentioned above.

\textbf{Indoor Datasets.} Indoor environments are common scenarios for mobile robots. Early datasets provided 2D laser scans to advance SLAM research~\cite{Radish}. RGB-D and camera-based sensing are also popular choices for indoor SLAM. Classical visual-aided datasets, such as 7-Scenes~\cite{shotton2013scene} and the TUM RGB-D dataset~\cite{sturm2012benchmark}, offered tracked frames and ground truth poses for evaluation. With the development of sensor technologies, various sensors have been designed to enhance robot perception and navigation. Consequently, recent indoor datasets focus on multi-sensor fusion and advanced tasks, such as FusionPortable~\cite{jiao2022fusionportable}, HILTI SLAM Challenge~\cite{helmberger2022hilti}, and THUD~\cite{tang2024mobile}. Notably, few datasets provide building architectures, though they can serve as typical scene priors for mobile robots. CubiCasa5K by Kalervo \textit{et al.}~\cite{kalervo2019cubicasa5k} provided large-scale floor plan images for building architecture parsing but lacks real-world sensor data. In this paper, we introduce SLABIM, which integrates both SLAM-oriented sensor data and building architectures.