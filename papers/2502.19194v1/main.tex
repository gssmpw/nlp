% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%

\documentclass[conference, 9pt]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
% \usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{url}
% \usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
% \usepackage[numbers]{natbib}
% \usepackage[colorlinks]{hyperref}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\setlength{\columnsep}{0.18in}

\begin{document}

% \title{Self-supervised conformal prediction for uncertainty quantification in
% Poisson-Gaussian imaging problems\\
% {\footnotesize \textsuperscript{*}Note: Sub-titles are not captured for https://ieeexplore.ieee.org  and
% should not be used}
% \thanks{Identify applicable funding agency here. If none, delete this.}
% }

\title{Self-supervised conformal prediction for uncertainty quantification in
Poisson imaging problems
\thanks{This work was supported by French National Research Agency (ANR) (ANR-23-CE48-0009, ``\textit{OptiMoCSI}"); and by UKRI Engineering and Physical Sciences Research Council (EPSRC) (EP/V006134/1, EP/Z534481/1).}
}

\author{\IEEEauthorblockN{Bernardin Tamo Amougou}
\IEEEauthorblockA{\small\textit{School of Mathematical and Computer Sciences}\\
\textit{\& Maxwell Institute for Mathematical Sciences}\\
\textit{Heriot-Watt University}, Edinburgh, UK\\
\& Universit\'e de Paris Cit\'e, Paris, France  \\
bt2027@hw.ac.uk}
\and
\IEEEauthorblockN{Marcelo Pereyra}
\IEEEauthorblockA{\small\textit{School of Mathematical and Computer Sciences}\\
\textit{\& Maxwell Institute for Mathematical Sciences}\\
\textit{Heriot-Watt University}, Edinburgh, UK\\
 m.pereyra@hw.ac.uk}
\and
\IEEEauthorblockN{Barbara Pascal}
\IEEEauthorblockA{\small
	\textit{Nantes Université, École Centrale Nantes} \\
	\textit{CNRS, LS2N, UMR 6004}\\
    F-44000 Nantes, France \\
barbara.pascal@cnrs.fr}
}

\maketitle

\begin{abstract}
Image restoration problems are often ill-posed, leading to significant uncertainty in reconstructed images. Accurately quantifying this uncertainty is essential for the reliable interpretation of reconstructed images.  However, image restoration methods often lack uncertainty quantification capabilities. Conformal prediction offers a rigorous framework to augment image restoration methods with accurate uncertainty quantification estimates, but it typically requires abundant ground truth data for calibration. This paper presents a self-supervised conformal prediction method for Poisson imaging problems which leverages Poisson Unbiased Risk Estimator to eliminate the need for ground truth data. The resulting self-calibrating conformal prediction approach is applicable to any Poisson linear imaging problem that is ill-conditioned, and is particularly effective when combined with modern self-supervised image restoration techniques trained directly on measurement data. The proposed method is demonstrated through numerical experiments on image denoising and deblurring; its performance are comparable to supervised conformal prediction methods relying on ground truth data.
% 149 words (limited to 150 words for SSP)
% Most image restoration problems are ill-conditioned or ill-posed and hence involve significant uncertainty. Quantifying this uncertainty is crucial for reliably interpreting experimental results, particularly when reconstructed images inform critical decisions and science. 
%However, most existing image restoration methods either fail to quantify uncertainty or provide estimates that are highly inaccurate. 
%Conformal prediction has recently emerged as a flexible framework to equip any estimator with uncertainty quantification capabilities that, by construction, have nearly exact marginal coverage. To achieve this, conformal prediction relies on abundant ground truth data for calibration. However, in image restoration problems, reliable ground truth data is often expensive or not possible to acquire. 
%Also, reliance on ground truth data can introduce large biases in situations of distribution shift between calibration and deployment. 
%This paper seeks to develop a more robust approach to conformal prediction for image restoration problems by proposing a self-supervised conformal prediction method that leverages Stein's Unbiased Risk Estimator (SURE) to self-calibrate itself directly from the observed noisy measurements, bypassing the need for ground truth. 
%The method is suitable for any linear imaging inverse problem that is ill-conditioned, and it is especially powerful when used with modern self-supervised image restoration techniques that can also be trained directly from measurement data. The proposed approach is demonstrated through numerical experiments on image denoising and deblurring, where it delivers results that are remarkably accurate and comparable to those obtained by supervised conformal prediction with ground truth data.
\end{abstract}

\begin{IEEEkeywords}
Conformal Prediction, Uncertainty Quantification, Image Restoration,  Stein's Unbiased Risk Estimator, Poisson noise.
\end{IEEEkeywords}%

%

%
%\titlerunning{SURE-based Conformal Prediction for UQ in Imaging}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
%\author{Jasper M. Everink\inst{1}\orcidID{0000-0001-7263-0317} \and Bernardin Tamo Amougou\inst{2,3} \and Marcelo Pereyra\inst{2}\orcidID{0000-0001-6438-6772} }
%
%\authorrunning{J.M. Everink, B. Tamo Amougou and  M. Pereyra.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
%\institute{Technical University of Denmark, Kgs. Lyngby, Denmark, \email{jmev@dtu.dk} \and Heriot-Watt University \& Maxwell Institute for Mathematical Sciences, Edinburgh, UK \and Universit\'e de Paris Cit\'e, Paris, France }

%
\maketitle              % typeset the header of the contribution
%



%
%
%

\section{Introduction}
Poisson imaging problems are widely encountered across various scientific and engineering disciplines, with notable prevalence in fields such as astronomy and microscopy \cite{Starck2006-ew, Bertero2009}; common examples include Poisson image denoising, deblurring and computed tomography \cite{Figueiredo2010, khademi2021self, savanier2023deep}. Such problems are often not well posed, meaning that there exists a wide range of possible solutions that are in agreement with the observed data. Accounting for this inherent uncertainty is essential when using the reconstructed images as evidence for science  or critical decision-making \cite{Robert2007}. Unfortunately, most methods for solving Poisson imaging problems currently available are unable to accurately quantify the uncertainty in the delivered solutions.
%, from image deblurring~\cite{khademi2021self, laroche2023deep} to computed tomography~\cite{savanier2023deep}. In such problems, there exists a large set of solutions, possibly significantly different, which are equally probable given a corrupted observation.
%When restored images are used to guide sensitive decisions, accounting for this uncertainty is crucial and has triggered massive research efforts in imaging sciences.

Bayesian statistical inference strategies, which rely on prior knowledge about the likely solutions to the problem as encoded by a probability distribution, are the predominant approach to uncertainty quantification in imaging problems (see, e.g., \cite{Figueiredo2010, Marnissi2017,melidonis2023efficient,melidonis2025scorebased}). Bayesian imaging techniques can deliver a wide range of inferences, and the most accurate solutions to Poisson imaging problems are currently obtained by using Bayesian imaging methods combining ideas from optimisation, deep learning and stochastic sampling \cite{melidonis2025scorebased}. However, even the most advanced Bayesian imaging strategies currently available struggle to provide accurate uncertainty quantification on structures larger than a few pixels in size~\cite{thong2024bayesianimagingmethodsreport}. This has stimulated research on other frameworks for performing uncertainty quantification in imaging inverse problems. Namely, bootstrapping and conformal prediction have recently emerged as promising frameworks for delivering accurate uncertainty quantification for large image structures.%, in particular confidence regions, that are well calibrated and robust to experimental replication.

With regards to bootstrapping, we note the recent equivariant bootstrapping method~\cite{tachella2023equivariant} which yields excellent confidence regions, even for large image structures.
Equivariant bootstrapping is a statistical resampling strategy that takes advantage of known symmetries of the problem to significantly reduce the bias inherent to synthetic resampling. It does not require ground truth data for calibration, and it can be therefore applied to many quantitative and scientific imaging problems for which obtaining reliable ground truth data is difficult or impossible. Equivariant bootstrapping is effective in problems that are severely ill-posed, for example in compressive sensing, inpainting, limited angle tomography or radio-interferometry \cite{tachella2023equivariant,Liaudat2024}. Conversely, it often performs poorly for problems which are potentially severely ill-conditioned but not ill-posed, as this prevents leveraging symmetries to remove the bootstrapping bias ~\cite{tachella2023equivariant}.

In contrast, conformal prediction is a fully data-driven strategy for constructing regions with almost exact marginal coverage~\cite{angelopoulos2021gentle}. Unlike equivariant bootstrapping, conformal prediction is agnostic to both the image observation model and our prior knowledge about likely solutions. However, in its original form, conformal prediction requires abundant ground truth data for calibration, which is a main bottleneck to implementation for quantitative and scientific imaging problems where ground truth data is often scarce or unavailable. The need for ground truth can be partially mitigated by combining conformal prediction with Bayesian inference and by focusing on pixels of a single image rather than regions, as proposed in \cite{Narnhofer2024}. Alternatively, the recent method~\cite{everink2025} fully bypasses the need for ground truth data by focusing on  Gaussian imaging problems and leveraging  Stein's Unbiased Risk Estimator~\cite{9054593} to perform conformal prediction directly from the observed measurement data, in a self-supervised manner. The experiments reported in \cite{everink2025} show that, for non-blind linear Gaussian imaging problems, self-supervised conformal prediction is as accurate as supervised conformal prediction. 

There are many important imaging problems for which the Gaussian noise assumption underpinning \cite{everink2025} is not sufficiently accurate to deliver meaningful inferences. In particular, imaging sensors often exhibit so-called \emph{shot} noise, a form of signal-dependent measurement error that exhibits Poisson statistics. With quantitive and scientific Poisson imaging problems in mind, this paper proposes a generalisation of the self-supervised conformal prediction framework \cite{everink2025} for high-dimensional linear inverse problems involving Poisson noise. 

The remainder of the paper is organised as follows. The principles of conformal prediction for inverse problems involving Poisson noise are introduced in Section~\ref{sec:background}. Then, the proposed self-supervised conformal prediction framework is detailed in Section~\ref{sec:method}. 
This framework is demonstrated on Poisson image denoising and deblurring experiments in Section~\ref{sec:experiments}.
Concluding remarks and future research directions are provided in Section~\ref{sec:discussion}. 

%The remainder of this paper is organized as follows. 
%Section \ref{sec:background} provides an overview of conformal prediction and a formal problem statement. Section \ref{sec:method} introduces the proposed self-supervised conformal prediction method. Section \ref{sec:experiments} demonstrates the proposed approach through numerical experiments on image denoising and non-blind deblurring tasks and by considering model-based as well as learning-based estimators. Conclusions and perspectives for future work are finally reported in Section \ref{sec:discussion}.

% Image restoration tasks often require solving an inverse problem that is ill-posed, and which can consequently involve significant uncertainty about the unobserved true image. Quantifying and characterising this uncertainty is important for applications that rely on the restored images to inform important decisions. There are several statistical frameworks available to formulate and solve uncertainty quantification problems in imaging sciences. For example, many uncertainty quantification methods for image restoration rely on the Bayesian statistical framework \cite{calvetti2018inverse}, which can be implemented by using a wide range of modelling and algorithmic approaches (see, e.g., \cite{Durmus2018,Pereyra2017,laumont2022bayesian,holden2022bayesian}). One can also consider uncertainty quantification methods based on bootstrapping (see \cite{tachella2023equivariant}), which delivers the most accurate uncertainty quantification results to date. Alternatively, when there is enough calibration data available, it is possible to perform uncertainty quantification by using conformal prediction \cite{angelopoulos2021gentle}, which is highly flexible and can be deployed in combination with any image restoration technique.

% Conformal prediction has been recently successfully applied to a range of imaging problems (see, e.g., \cite{angelopoulos2022image, narnhofer2024posterior}). However, existing conformal prediction approaches for imaging focus on pixel-wise uncertainty. Therefore, the statistical guarantees provided by the conformal prediction framework only hold marginally per pixel. This is a strong limitation because decisions based on image data usually involve a many image pixels. However, scaling conformal prediction to large regions is difficult because the results become vague and uninformative. There has been some research on designing conformal prediction strategies for problems of moderate dimension (see, e.g., \cite{messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal}), but the dimensionality encountered in imaging problems is beyond the reach of these strategies. 

% In this paper, we propose a method that leverages Stein's unbiased risk estimator to scale conformal prediction to high-dimensional problems, so that it can be applied to image restoration. The paper is structured as follows. Section \ref{sec:background} introduces conformal prediction. Then in Section \ref{sec:method} we present our proposed method. Following on from this, Section \ref{sec:experiments} illustrates the proposed approach on image denoising, deblurring
% and computed tomography experiments
% . Conclusions and perspectives for future work are finally reported in Section \ref{sec:discussion}.

\clearpage
\newpage
\section{Conformal Prediction under Poisson models}
\label{sec:background}
In the context of image estimation, conformal prediction aims to identify a set of statistically likely values for an unknown image of interest $x^{\star}$ from some noisy measurements $y \in \mathbb{R}^m$ of $x^{\star}$. Assuming $x^{\star}$ and $y$ are realizations of random variables $X$ and $Y$, for a confidence level \( \alpha \in (0,1) \), we seek a region $C(Y) \subset \mathbb{R}^n$ verifying
\begin{equation}\label{predictionC}
    \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) \geq 1-\alpha\,
\end{equation}
where the probability is taken w.r.t. the joint distribution of \( (X, Y) \).
Conformal prediction is a general framework leveraging a \emph{non-conformity measure} \( s: \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R} \), which reflects how plausible is an image $x$ given measurements $y$, to provide such confidence sets~\cite{angelopoulos2021gentle}.
Once chosen $s$, the set \( C(y) \) is constructed by computing the top \((1-\alpha)\)-quantile \( q_\alpha \) of the statistic \( s(X, Y) \), i.e.,
\begin{align}
\label{eq:Cy}
C(y) := \{x \in \mathbb{R}^n \,|\, s(x, y) \leq q_\alpha\} \quad \text{for all } y \in \mathbb{R}^m.
\end{align}
which by construction set satisfies:
\begin{align}
\label{eq:proba}
\mathbb{P}_{(X, Y)} \big(X \in C(Y)\big) = \mathbb{P}_{(X, Y)} \big(s(X, Y) \leq q_\alpha \big) \geq 1 - \alpha,
\end{align}
for any confidence level \( \alpha \in (0, 1) \). 
Provided that $s$ has been suitably designed and that enough samples \(\{x_i, y_i\}_{i=1}^M\) under the joint distribution of $(X,Y)$ are available to calibrate $q_\alpha$, then~\eqref{eq:Cy} yields regions $C(y)$ that contain $x^\star$ with the prescribed probability.


In this paper, we consider a linear Poisson, i.e., \emph{shot} noise, observation model, in which $X$ and $Y$ are related by
\[
(Y \mid X = x^{\star}) \sim \mathcal{P}\!\Bigl(\gamma A x^{\star}\Bigr)\, ,
\]
where \(\mathcal{P}\) denotes the Poisson distribution, \(A\) is a linear measurement operator, and \(\gamma > 0\) is related to the strength of the shot noise (the larger $\gamma$, the easier the image restoration problem). We henceforth assume $A$ and $\gamma$ are known, and that $A$ is full rank but possibly severely ill-conditioned. 
To design $C(y)$, we assume the availability of some estimator of $x^{\star}$, henceforth denoted $\widehat{x}(y)$.

% Conformal prediction seeks to estimate a set of plausible values for an unknown image $x^{\star}$ from a noisy measurement $y \in \mathbb{R}^m$, when $y$ and $x^{\star}$ are assumed to be realisations of random variables $(X, Y)$ related by a Poisson observation model of the form 
% \[
% (Y \mid X = x^{\star}) \sim \gamma \,\mathcal{P}\!\Bigl(\tfrac{A x^{\star}}{\gamma}\Bigr)\, ,
% \]
% where \(\gamma\) is a known scaling factor, \(\mathcal{P}\) denotes the Poisson distribution, and \(A\) is a linear measurement operator, which we henceforth assume full rank. 
% To obtain this set of plausible values for $x^{\star}$, we will rely on this statistical model and on a generic estimator $x(y)$ of $x^{\star}$, which we will assume to be almost everywhere differentiable.

% Formally, we seek to construct a region \( C(Y) \subset \mathbb{R}^n \) in the solution space such that
% \begin{equation}\label{predictionC}
%     \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) \geq 1-\alpha\,,
% \end{equation}
% where the probability is taken with respect to the joint distribution of \( (X, Y) \), and \( \alpha \in [0,1] \) specifies the desired confidence level. Conformal prediction provides a general framework for constructing sets \( C \) with the desired probabilistic guarantee \cite{angelopoulos2021gentle}. 
% This is achieved using a \emph{non-conformity measure} \( s: \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R} \) that encodes the degree to which an image $x$ is in agreement with the measurement $y$. Given a choice of $s$, the set \( C(y) \) is constructed by computing the top \((1-\alpha)\)-quantile \( q_\alpha \) of the statistic \( s(X, Y) \), i.e.,
% \[
% C(y) := \{x \in \mathbb{R}^n \,|\, s(x, y) \leq q_\alpha\} \quad \text{for all } y \in \mathbb{R}^m.
% \]
% which by construction set satisfies:
% \[
% \mathbb{P}_{(X, Y)} \big(X \in C(Y)\big) = \mathbb{P}_{(X, Y)} \big(s(X, Y) \leq q_\alpha \big) \geq 1 - \alpha,
% \]
% for any confidence level \( \alpha \in (0, 1) \). With a sufficiently large sample \(\{x_i, y_i\}_{i=1}^M\) to calibrate \( q_\alpha \), any suitable function \( s \) can be used to construct a set \( C \) that contains \( x^\star \) with the desired probability.% under the joint distribution of \((X, Y)\).

To gain an intuition for \eqref{predictionC}, it is useful to consider a specific example. 
Suppose that $x^{\star}$ is a high-resolution Positron Emission Tomography (PET) scan of an adult brain which is only accessible in practice through a noisy degraded measurement $y$.
Measurements are processed by the estimator \( \widehat{x}(y) \) to yield an estimate of \( x^\star \).
In this setting, $x^\star$ can be viewed as a realization of the random variable $X$ describing the distribution of generic noise-free and resolution-perfect brain PET scans of adult individuals within a studied population.
Though, rather than a point estimate, for diagnosis purpose one might be preferably interested in all plausible estimates of $x^{\star}$, by definition constituting the set $C(y)$ of Equation~\eqref{eq:Cy}.
Then, if a large number of brain PET scans are considered, at least a proportion $1-\alpha$ of the true images $x^{\star}$ should fall in the plausible sets $C(y)$.


% For instance, suppose that \( x^\star \) is a high-resolution Positron Emission Tomography (PET) scan of an adult brain, then it is a generic sample under the distribution of noise-free and resolution-perfect brain PET scans within the studied population.
% Then, the random variable \( X \) characterises the distribution of brain PET scans for a generic individual within the population, as obtained by an ideal noise-free and resolution-perfect PET scanner. 
%The specific image \( x^\star \) corresponds to a PET scan of a particular individual, while \( y \) represents the noisy, degraded measurement acquired in practice. 
% The estimator \( \widehat{x}(y) \) produces an estimate of \( x^\star \). 
%The region \( C(y) \) encapsulates a set of likely solutions, rather than a single estimate, and satisfies the guarantee in \eqref{predictionC}. This means that if the procedure is repeated across a large number of individuals from the population, the constructed regions \( C \) will contain the respective true images \( x^\star \) in at least \( 1-\alpha\) of the cases.

Split conformalisation is the most widely used implementation of conformal prediction. It consists in estimating the top \(\frac{\lceil(M+1)(1-\alpha)\rceil}{M}\)-quantile \(\hat{Q}_\alpha\) of \(\{s(x_i, y_i)\}_{i=1}^M\) from $M$ training samples \(\{x_i, y_i\}_{i=1}^M\) of independent (or exchangeable) realizations of \((X, Y)\).
Then, given a new measurement $Y_{\text{new}}$ stemming from some unknown image $X_{\text{new}}$, the set yielded by split conformal prediction is given by
\[
\widehat{C}(Y_{\text{new}}) := \{X_{\text{new}} \in \mathbb{R}^n \,|\, s(X_{\text{new}}, Y_{\text{new}}) \leq \hat{Q}_\alpha\},
\]
which satisfies the condition:
\begin{equation}\label{eq:conformal_guarantee}
    \mathbb{P}_{(X, Y)^{M+1}}\left(X_{\text{new}} \in \widehat{C}(Y_{\text{new}}) \right)  
    \geq 1-\alpha\,,
\end{equation}
where $(X, Y)^{M+1}$ denotes the joint distribution of the \( M \) training samples and the new observation.
We refer the reader to~\cite{angelopoulos2021gentle} for a comprehensive introduction to the conformal prediction framework.



% A popular implementation of the conformal prediction framework is \emph{split conformal prediction}. Given a training sample \(\{X_i, Y_i\}_{i=1}^M\) of independent (or exchangeable) realizations of \((X, Y)\), the method estimates the top \(\frac{\lceil(M+1)(1-\alpha)\rceil}{M}\)-quantile \(\hat{Q}_\alpha\) of \(\{s(X_i, Y_i)\}_{i=1}^M\). 
% For a new observation \((X_{\text{new}}, Y_{\text{new}})\), the prediction set is then:
% \[
% \widehat{C}(Y_{\text{new}}) := \{X_{\text{new}} \in \mathbb{R}^n \,|\, s(X_{\text{new}}, Y_{\text{new}}) \leq \hat{Q}_\alpha\}.
% \]
% This set satisfies the guarantee:
% \begin{equation}\label{eq:conformal_guarantee}
%     \mathbb{P}_{(X, Y)^{M+1}}\left(X_{\text{new}} \in \widehat{C}(Y_{\text{new}}) \right)  
%     \geq 1-\alpha\,,
% \end{equation}
% where the probability accounts for the joint distribution of the \( M \) training samples and the new observation. Notably, this formulation includes a finite-sample correction because \(\hat{Q}_\alpha\) is derived from the \(\frac{\lceil(M+1)(1-\alpha)\rceil}{M}\)-quantile (this correction vanishes as \( M \to \infty \)).
% For an excellent introduction to conformal prediction, please see \cite{angelopoulos2021gentle}.






% Conformal prediction provides a general framework to construct such set $C$ \cite{angelopoulos2021gentle}. This is achieved by using a so-called \emph{non-conformity measure} or score function $s: \mathbb{R}^n \times \mathbb{R}^m\mapsto\mathbb{R}$. If we take the top $(1-\alpha)$-quantile $q_\alpha$ of the statistic $s(X, Y)$ and define $C(y) := \{x\in \mathbb{R}^n \,|\, s(x,y) \leq q_\alpha\}$ for all $y \in \mathbb{R}^m$, then by construction
% \begin{equation*}
    % \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) = \mathbb{P}_{(X, Y)}\left(s(X, Y) \leq q_\alpha \right) \geq 1-\alpha,
% \end{equation*}
% for any $\alpha \in (0,1)$. Following this procedure, and given a sufficient large sample $\{x_i,y_i\}_{i=1}^M$ to calibrate $q_\alpha$, any suitable score $s$ can be used to construct a set $C$ that contains $x$ with high probability w.r.t. the joint distribution of $(X,Y)$. 

% More precisely, the split conformal prediction approach considers a training sample $\{X_i, Y_i\}_{i=1}^M$ of independent (or at least exchangeable) copies of $(X, Y)$ from which we take the empirical top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile $\hat{Q}_\alpha$ of $\{s(X_i,Y_i)\}_{i=1}^{m}$. Then, for a new copy $(X_{new}, Y_{new})$ of $(X,Y)$, the set $\widehat{C}(Y_{new}) := \{X_{new}\in \mathbb{R}^n\,|\, s(X_{new},Y_{new}) \leq \hat{Q}_\alpha\}$ satisfies
% \begin{equation}\label{eq:conformal_guarantee}
%     \mathbb{P}_{(X, Y)^{M+1}}\left(X_{\text{new}} \in \widehat{C}(Y_{\text{new}}) \right)  
%     \geq 1-\alpha\,,
% \end{equation}
% and where we note that \eqref{eq:conformal_guarantee} implicitly contains a finite-sample correction because $\hat{Q}_\alpha$ is derived from a $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile; this correction vanishes as $M\rightarrow\infty$.
% Please see \cite{angelopoulos2021gentle} for an excellent introduction to conformal prediction.


One major advantage of the conformal prediction framework lies in its flexibility, notably in choosing the non-conformity measure.
Different choices for $s$ yield infinitely many different regions $\widehat{C}(y)$ satisfying~\eqref{eq:conformal_guarantee}.
Though, in practice, not all these plausible sets are useful neither relevant.
Indeed, as $\widehat{C}(y)$ consists in a sub-level set of the function $x\mapsto s(x,y)$ in high-dimension, many of the plausible sets might be overly large, up to encompassing most of the support of X, and hence poorly informative to practitioners.
Hence a careful design of $s$ is key to obtain compact, thus useful, sets. In particular, $s$ should be constructed so as to minimize the variability of $s(X,Y)$.
To that aim, normalized non-conformity measures~\cite{johnstone2021conformal} of the form
\begin{equation}\label{eq:score_multi_target}
s(x, y) = \|x - \widehat{x}(y)\|^2_{\Sigma(y)} = \left(x - \widehat{x}(y)\right)^\top \Sigma(y) \left(x - \widehat{x}(y)\right),
\end{equation}
where \( \Sigma(y) \) is a positive definite matrix of size \( n \times n \) are particularly useful, notably when \( \Sigma(y) \) enables significant reduction of variability in $s(X,Y)$.
An efficient strategy consists in choosing \( \Sigma(y) \) as the inverse covariance matrix of the estimation error $X - \widehat{x}(Y)$~\cite{johnstone2021conformal}.


% While conformal prediction is highly flexible, not all functions \( s(x, y) \) deliver prediction regions that are equally useful in practice. Indeed, all prediction sets \( \widehat{C}(y) \) take the form of a sub-level set of the function \( x \mapsto s(x, y) \), which can be arbitrarily chosen. As a result, it is possible to construct infinitely many regions in \( \mathbb{R}^n \) that satisfy the guarantee of containing the true solution \( x^\star \) with probability at least \( 1-\alpha \). However, many of these regions may be excessively large, especially in high-dimensional settings, where poorly designed score functions \( s(x, y) \) can lead to regions \( \widehat{C}(y) \) that are meaningless because they cover most of the support of \( X \). 

%Carefully designing \( s(x, y) \) allows obtaining conformal prediction sets that are compact and informative, even in high dimension. In particular, it is essential that \( s(x, y) \) is constructed in a way that reduces the variability of \( s(X, Y) \)% and allows scaling to large problems without Several approaches have been recently proposed to scale conformal prediction to high-dimensional problems (see, e.g., \cite{johnstone2021conformal, messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal})
%.
%  Of particular interest are normalized non-conformity measures of the form \cite{johnstone2021conformal}:
% \begin{equation}\label{eq:score_multi_target}
% s(x, y) = \|x - \widehat{x}(y)\|^2_{\Sigma(y)} = \left(x - \widehat{x}(y)\right)^\top \Sigma(y) \left(x - \widehat{x}(y)\right),
% \end{equation}
% where \( \Sigma(y) \) is a positive definite matrix of size \( n \times n \). A well-chosen \( \Sigma(y) \) reduces variability in \( s(X, Y) \), leading to prediction sets that are well-centered around \( \widehat{x}(y) \), compact, and highly informative. In practice, \( \Sigma(y) \) is often chosen as an approximation of the inverse-covariance matrix of the error $X-\widehat{x}(Y)$ \cite{johnstone2021conformal}.

%These sets satisfy property \eqref{eq:conformal_guarantee} by construction.

%In prior work, \( \Sigma(y) \) is often chosen as an approximate inverse-covariance matrix. For instance, \cite{johnstone2021conformal} propose estimating this matrix globally based on the errors in a sample \( \{x_i, y_i\}_{i=1}^M \). However, this global approach neglects local variations in \( y \), which are essential in high-dimensional problems. To address this, \cite{messoudi2022ellipsoidal} suggest refining the global matrix by incorporating errors from the \( k \)-nearest neighbors \( \{x_i, y_i\}_{i=1}^k \) of \( y \). While this method captures some local variability, it requires a large amount of data to accurately estimate the local uncertainty.

A major practical bottleneck in the implementation of conformal prediction strategy is the difficulty, if not the impossibility, to get an abundance of reliable data \(\{s(x_i, y_i)\}_{i=1}^M\); indeed, obtaining the ground truth $x_i$ from measurements $y_i$ is precisely the overarching goal of an imaging problem. Also, relying on a training dataset might result in inaccurate prediction sets when a distribution shift occurs. In the example of brain PET scans, this corresponds to a situation in which the calibration dataset has been done on a population that represents poorly the population encountered during deployment. 

To bypass the need for ground-truth data, Everink et al. \cite{everink2025} recently proposed a self-supervised conformal prediction method for linear imaging problems with Gaussian noise. This paper generalises this approach to perform conformalised uncertainty quantification in linear Poisson imaging problems without ground truth data available.

\section{Self-supervised uncertainty quantification}\label{sec:method}
In a manner akin to \cite{everink2025}, we propose a self-supervised conformal prediction strategy that removes the need for ground-truth data by making use of a statistical estimator of \eqref{eq:score_multi_target}. Namely, we leverage a Poisson Unbiased Risk Estimator (PURE) \cite{LUISIER2010415}, which provides accurate and unbiased estimates of \eqref{eq:score_multi_target}. We propose to apply this estimator individually to a collection of \(M\) statistically exchangeable imaging problems of the form $(Y \mid X = x^{\star}_i) \sim  \,\mathcal{P}\!({\gamma A x^{\star}_i})$. 

To define the non-conformity measure \eqref{eq:score_multi_target}, we set \(\Sigma(y) = A^\top A\) to approximate the error inverse-covariance, as we expect estimates of $x^{\star}$ to be most accurate in the dominant eigenvector directions of \(A^\top A\) while the estimation error is likely to concentrate along its weaker eigenvectors. The resulting score is given by:
\begin{equation}\label{score}
s(x, y) = \frac{1}{m}\,\|A x - A \widehat{x}(y)\|_2^2,
\end{equation}
where we recall that \(m = \textrm{dim}(y)\) and that \(\widehat{x}(y)\) is an estimator of $x^{\star}$. Note that \(A\) being full rank is crucial, as otherwise, \(\Sigma(y)\) would be only positive semidefinite leading to unbounded prediction sets.




% Our proposed self-supervised conformal prediction method circumvents the need for ground truth data by leveraging Poisson unbiased risk estimate (PURE) \cite{LUISIER2010415}. 

% We begin by pooling together $M$ exchangeable imaging problems, where each problem involves an unknown image $x^{\star}_i$ and an observation $y_i$ which we consider to be a realisation of the conditional random variable $(Y|X=x^{\star}_i) \sim \gamma \mathcal{P}\left(\frac{Ax^{\star}_i}{\gamma}\right)$. To specify the non-conformity measure, we  consider $\Sigma(y)=A^\top A$ which is a natural choice for approximation for the error inverse-covariance when $(Y|X=x^{\star}_i) \sim \gamma \mathcal{P}\left(\frac{Ax^{\star}_i}{\gamma}\right)$, as we expect $\widehat{x}(Y)$ to be accurate along the leading eigenvectors of $A^\top A$ and the estimation error to concentrate along weak eigenvectors of $A^\top A$. This leads to the non-conformity measure
% \begin{equation} \label{score}
%   s(x, y) = \frac{1}{m}\|Ax - A\widehat{x}(y)\|_2^2,  
% \end{equation}
% where we recall that $A$ is assumed full-rank, but potentially very poorly conditioned . We require $A$ to be full rank as otherwise $\Sigma(y)$ is only positive semidefinite, implying that the corresponding prediction set can be unbounded.



To perform calibration without relying on ground-truth data, we replace the direct sample quantiles of \(\{s(x_i, y_i)\}_{i=1}^M\) with PURE-based estimates derived solely from the observed measurements \(\{y_i\}_{i=1}^M\).  Assuming that the estimator \(\widehat{x}\) is differentiable almost everywhere, and let $\partial\bigl(A\widehat{x}(y)\bigr)/\partial y$ denote the diagonal of the Jacobian of $y\mapsto A\widehat{x}(y)$, PURE for \eqref{score} takes the form
\begin{equation}\label{eq:SURE}
    \mathrm{PURE}(y) 
    = \frac{1}{m}\,\left\lVert \frac{y}{\gamma} - A \widehat{x}(y)\right\rVert_2^2 
    -\frac{1}{\gamma^2 m}\,\mathbf{1}^\top y
    +\frac{2 }{ \gamma m}y^\top\,\frac{\partial}{\partial y}\bigl(A\widehat{x}(y)\bigr).
\end{equation}
Following a law of large numbers argument, in settings with large \(m = \mathrm{dim}(y)\), PURE not only remains unbiased but also exhibits a low variance (this is analysed analytically for the Gaussian case in \cite{stein1981estimation} and verified empirically in Poisson problems \cite{Montagner2014}). Consequently, we expect that calibrating conformal prediction by using PURE quantiles will yield prediction sets in close agreement with the true quantiles of \(s(X, Y)\), thereby preserving the intended coverage properties. Although this introduces a small bias in the resulting quantiles, the effect is minor (the unbiased errors from PURE act as mild \emph{smoothing} on the sample quantiles). 

Adopting a split-conformal strategy, we compute \(\widehat{x}(y_i)\) and \(\mathrm{PURE}(y_i)\) for \(i \in \{1,\dots,M\}\). Then, for any $\alpha \in (0,1)$, we set
\[
    \widehat{C}(y_i) 
    \;=\; \{\,x \in \mathbb{R}^n : \|A x - A \widehat{x}(y_i)\|_2^2 / m \;\le\; \hat{Q}_\alpha^{(i)}\},
\]
where \(\hat{Q}_\alpha^{(i)}\) is the \(\tfrac{\lceil (M+1)(1-\alpha)\rceil}{M}\)-quantile of \(\{\mathrm{PURE}(y_j)\}_{j=1}^M\) with the \(i\)th term removed. Although PURE introduces some estimation bias, it is typically minor compared to likely distribution shifts in real deployment. Furthermore, the required \(\mathrm{PURE}(y_i)\) values can be computed in parallel. The full algorithm is summarized in Fig.~\ref{alg:one}.
 
% To calibrate without ground truth data, instead of relying on a sample quantile of $\{s(x_i,y_i)\}_{i=1}^M$, we rely on PURE to provide unbiased estimates of $\{s(x_i,y_i)\}_{i=1}^M$ from the observed measurements $\{y_i\}_{i=1}^M$. We then use those noisy quantile estimates for calibration, at the expense of a small amount of bias. 

% More precisely, assuming that the estimator $\widehat{x}$ is differentiable almost everywhere, the PURE estimate of \eqref{score} is given by  
% \begin{equation}\label{eq:SURE}
%  \textrm{PURE}(y) =   \frac{1}{m}\|y - A \widehat{x}(y)\|_2^2 -\frac{\gamma}{m} 1^{\top} y+\frac{2 \gamma}{m} y^{\top} \delta \left( A\widehat{x}\left(y\right) \right), 
% \end{equation}
% where \( \delta \left (A \widehat{x}(y) \right) =\left[\frac{\delta \left (A \widehat{x}(y) \right)}{\delta y_1}, \ldots, \frac{\delta \left (A \widehat{x}(y) \right)}{\delta y_m}\right]^{\top} \)  \cite{chen2022robustequivariantimagingfully}. It is easy to show that $\textrm{PURE}(Y)$ provides an estimate of $s(X, Y)$ that is unbiased \cite{chen2022robustequivariantimagingfully}. Crucially, when $m = \textrm{dim}(y)$ is large, the estimate provided by PURE is not only unbiased but also often very accurate (see \cite{stein1981estimation,bellec2021second, LUISIER2010415, PG-PURE} for a theoretical analysis of the variance of PURE and \cite{6545395} for an empirical analysis in an imaging setting). As a consequence, we expect that the conformal calibration quantiles obtained from PURE will be in close agreement with the true quantiles of $s(X,Y)$, ensuring that the resulting conformal prediction sets nearly maintain their desired coverage properties.



%With regards to the evaluation of PURE, 
%for some model-based estimators it is possible to identify a closed-form expression \cite{tibshirani2012degrees}. Otherwise,


For most estimators $\widehat{x}(Y)$ of practical interest, computing the PURE estimate typically involves a numerical approximation of $\frac{\partial}{\partial y}\bigl(A\widehat{x}(y)\bigr)$. Monte Carlo PURE (MC-PURE) \cite{chen2022robustequivariantimagingfully} is perhaps the most widely used strategy to implement PURE, but we find that it requires careful hyper-parameter tuning. Instead, we recommend adopting a more robust alternative based on Hutchinson’s stochastic trace approximation \cite{9054593}, which in the considered setting yields 
\begin{align}
  \frac{1}{m}  y^\top \frac{\partial}{\partial y}\bigl(A\widehat{x}(y)\bigr)
    \;=\;& \mathbb{E}_{\tilde{n} \sim \mathcal{N}\left(\boldsymbol{0}, \operatorname{diag}(y)\right)} \Bigl[\tilde{n}^\top \boldsymbol{J}_{h(y)} \,\tilde{n}\Bigr] \\
    \approx\;& \frac{1}{m} \sum_{i=1}^{m} \tilde{n}_i^\top \boldsymbol{J}_{h(y)}\,\tilde{n}_i
    \;\;\;\;\;\text{(Hutchinson’s estimator)} \\
    \approx\;& \frac{1}{m}\,\tilde{n}^\top \boldsymbol{J}_{\tilde{n}^\top h(y)}, \label{eq:MC-SURE_N}
 \end{align}
where the last step is efficiently computed via automatic differentiation \cite{9054593}. In our experience, this approach provides accurate and computationally efficient estimates, even in large-scale settings. 





% Computing PURE requires  numerical approximations, a common approach is the Monte Carlo PURE (MC-PURE)  algorithm  as it is used  in \cite{chen2022robustequivariantimagingfully}, which is estimator-agnostic. We use the so-called Hutchinson's stochastic trace approximation method \cite{9054593}, and adapted it in the context of PURE which is more computationally efficient than MC-PURE and does not require hyper-parameter fine-tuning. More precisely, the weighted  divergence \( y^{\top} \delta \left( A\widehat{x}\left(y\right) \right) \) is approximated as follows:

% \begin{align}
%   y^{\top} \delta \left( A\widehat{x}\left(y\right) \right) = \text{trace}( \operatorname{diag}(y)\boldsymbol{J}_{h(y)}) &=\mathbb{E}_{\boldsymbol{\tilde{n}} \sim \mathcal{N}\left(\boldsymbol{0}, \operatorname{diag}(\boldsymbol{y})\right)}\left[\boldsymbol{\tilde{n}}^\top \boldsymbol{J}_{\boldsymbol{h}_{(y)}} \boldsymbol{\tilde{n}}\right]  , \\
%    &\approx \frac{1}{m} \sum_{i=1}^{m} \tilde{n}_i^\top \boldsymbol{J}_{h(y)}\tilde{n}_i, \label{eq:MC-SURE_H}  \\
%    & \approx \frac{1}{m} \tilde{n}^\top \boldsymbol{J}_{\tilde{n}^ \top  h(y )}, \label{eq:MC-SURE_N} 
% \end{align}
% where \( \boldsymbol{J}_{h(y)} \) is the Jacobian matrix of the predicted measurements \( h(y) = A\widehat{x}(y) \) with respect to \( y \), and \eqref{eq:MC-SURE_H} corresponds to Hutchinson's method, which for computationally efficiency we implement \eqref{eq:MC-SURE_N} using automatic differentiation, as suggested in \cite{9054593}. This allows obtaining accurate PURE estimates in a highly efficient manner, even in very large problems.



%Adopting a split-conformal strategy, we first compute \(\widehat{x}(y_i)\) and \(\mathrm{PURE}(y_i)\) for each \(i \in \{1,\dots,M\}\). We then form the \(\bigl(1 - \alpha\bigr)\)-prediction set 
%\[
%    \widehat{C}(y_i) 
%    \;=\; \{\,x \in \mathbb{R}^n : \|A x - A \widehat{x}(y_i)\|_2^2 / m \;\le\; \hat{Q}_\alpha^{(i)}\},
%\]
%where \(\hat{Q}_\alpha^{(i)}\) is the \(\tfrac{\lceil (M+1)(1-\alpha)\rceil}{M}\)-quantile of \(\{\mathrm{PURE}(y_j)\}_{j=1}^M\) with the \(i\)th term removed. Although PURE introduces some estimation bias, it is typically minor compared to likely distribution shifts in real deployment. Furthermore, the required \(\mathrm{PURE}(y_i)\) values can be computed in parallel. The full method is summarized in Algorithm~\ref{alg:one}.


% Adopting a split-conformal strategy, after computing $\widehat{x}(y_i)$ and $\textrm{PURE}(y_i)$, for each $i = \{1,\ldots,M\}$ we construct the $(1-\alpha)$-prediction set \( \widehat{C}(y_i) \) as:
% \[
% \widehat{C}(y_i) = \{x \in \mathbb{R}^n : \|Ax - A\widehat{x}(y_i)\|_2^2/m \leq \hat{Q}^{(i)}_\alpha\},
% \]
% where \( \hat{Q}^{(i)}_\alpha \) is the top $\frac{\lceil (M+1)(1-\alpha)\rceil}{M}$-quantile of the sample $\{\textrm{PURE}(y_j)\}_{j=1}^M$ with the $i$th element, $\textrm{PURE}(y_i)$, removed. Note that while the proposed approach has some bias due to the estimation error introduced by PURE, in our experience the bias is small and arguably significantly smaller than the bias that is likely to be incurred due to distribution shift in deployment. It is also worth mentioning that the estimates $\textrm{PURE}(y_i)$ can be computed in parallel. The proposed method is summarised in Algorithm \ref{alg:one} below.



































% The score could the be  adapts to $y$ in a manner that delivers conformal prediction regions that 

% We propose two strategies that leverage SURE to construct a score function $s(x,y)$ that adapts to $y$ in a manner that delivers conformal prediction regions that centred on $\widehat{x}(y)$, are compact in space (relative to non-adaptive regions), and satisfy \eqref{eq:conformal_guarantee}. 

%Let consider  a Gaussian observation model of the form $(Y|X=x^\star) \sim \mathcal{N}(Ax^\star,\sigma^2 \mathbb{I}_m)$ with noise variance $\sigma^2 > 0$ and possibly poorly conditioned $A$.

% \subsection{Stein's unbiased risk estimator (SURE)}
% For our proposed strategy, we use 
% $$
% \Sigma(y) = \frac{1}{\textrm{SURE}(y)}A^\top A\,,
% $$
% where SURE is an estimate of the projected mean squared error $\|Ax^\star-A\widehat{x}(y)\|_2^2$ where $y$ is a realisation of $Y|X=x^\star$. 

% Following \cite{stein1981estimation}, if the estimator $\widehat{x}$ is differentiable almost everywhere, the SURE is given by  
% \begin{equation}\label{eq:SURE}
%  \textrm{SURE}(y) = -m\sigma^2 + \|y - A \widehat{x}(y)\|_2^2 + 2\sigma^2 \text{div} \left(A \widehat{x}(y)\right)\,,  
% \end{equation}
% %    \text{div} \left(A\widehat{x}(y) &:= \sum_{j = 1}^{m}\frac{\partial A\widehat{x}}{\partial y_j}(y),
% where $\text{div}(\cdot)$ denotes the divergence operator. The SURE is know quite accurate estimator of the projected mean squared error (see, e.g., \cite{bellec2021second}) and, for some estimators $\widehat{x}$, efficiently computable closed-form expressions of this divergence are available (see, e.g., \cite{tibshirani2012degrees}). In general, and thus in alignment with the black-box nature of conformal prediction, we can estimate the divergence numerically \cite{ramani2008monte,nobel2023tractable}. Of particular interest is the Monte Carlo SURE (MC-SURE) approach \cite{ramani2008monte}, which is agnostic to the nature of the estimator $\widehat{x}$: given $\epsilon > 0$ and a sequence of Rademacher, or more generally isotropic, random variables $\{d_i\}_{i = 1}^{K} \sim d$, the MC-SURE approximates $\text{div} \left(A \widehat{x}(y)\right)$ as follows:
% \begin{align}
% \text{div} \left(A \widehat{x}(y)\right) &= \mathbb{E}[d^TD(A\widehat{x})(y)d] \approx \frac{1}{K}\sum_{i = 1}^{K}d_i^TD(A\widehat{x})(y)d_i\label{eq:MC-SURE_1}\\
% &\approx \frac{1}{K}\sum_{i = 1}^{K}d_i^T \frac{(A\widehat{x}(y + \epsilon d_i) - A\widehat{x}(y))}{\epsilon}\,,\label{eq:MC-SURE_2}
% \end{align}
% where $D(A\widehat{x})(y)$ denotes the Jacobian matrix of the predicted measurements $A\widehat{x}$ at the actual measurements $\vec{y}$. The stochastic trace approximation in \eqref{eq:MC-SURE_1}, know as Hutchinson's method \cite{hutchinson1989stochastic}, has in recent years been superseded by more state-of-the-art stochastic trace estimation algorithms. To reduce the number of directional derivative approximation $D(A\widehat{x})(y)d$, and thus the number of estimations $\widehat{x}$, we propose to use the XTrace algorithm \cite{epperly2024xtrace}, and keep the forward finite difference approximation of the directional derivative.

% \subsection{SURE-adjusted conformal prediction}
% Using the general form of \eqref{eq:score_multi_target} and levering the concentration properties of \eqref{eq:SURE}, we propose the conformal prediction score 
% \begin{equation}\label{eq:score_mul}
%     s_{\text{mul}}(x,y) = \frac{\|Ax-A\widehat{x}(y)\|_2^2}{{SURE}(y)}\, . 
% \end{equation}
% We refer to this strategy as a multiplicatively-normalised score because $\textrm{SURE}(y)$ appears in the denominator of \eqref{eq:score_mul}. Note however, that the SURE \eqref{eq:SURE}, especially when using approximation \eqref{eq:MC-SURE_2}, is not guaranteed to be positive. In the case that the SURE estimate is positive, a prediction set computed using $s_{\text{mul}}$ is the interior of an ellipse, but whet the SURE estimate is negative, the prediction set is the exterior of an ellipse and therefore unbounded. This scenario can easily occur when the projected mean square error is relatively low or the SURE estimation is done inaccurately.

% To reduce this issue, we also propose an alternative strategy that is more stable by normalizing the score in an additive manner
% \begin{equation}\label{eq:score_add}
%     s_{\text{add}}(x,y) = \|Ax-A\widehat{x}(y)\|_2^2 - \textrm{SURE}(y)\,,
% \end{equation}
% which is more robust to the stochasticity of $\textrm{SURE}(y)$. We refer to this strategy as an additively-normalised score.

% Using a calibration set $\{x_i,y_i\}_{i = 1}^M$ with \eqref{eq:score_mul} or \eqref{eq:score_add}, we can construct two conformal prediction sets by computing the top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantiles
% $\hat{Q}_{\text{mul},\alpha}$ and $\hat{Q}_{\text{add},\alpha}$ of $s_{\text{mul}}(X,Y)$ and $s_{\text{add}}(X,Y)$ respectively. Whilst for $s_{\text{mul}}$ an unbounded prediction set is obtained when $\textrm{SURE}(y) < 0$, for $s_{\text{add}}$ and empty prediction set is obtained when $\textrm{SURE}(y) < \hat{Q}_{\text{add},\alpha}$, which is a less likely event.

% The proposed strategies are summarised in Algorithm \ref{alg:one} below. This might seem very expensive, due to the great number of SURE estimations, each requiring multiple evaluations of the estimator $\widehat{x}$. However, the $M$ SURE estimations in line 2 and the single SURE estimation in line 10 are all independent of each other. Similarly, all the directional derivative estimation in \eqref{eq:MC-SURE_2} are independent and can be done in parallel. (With the minor detail that the XTrace algorithm requires two sequential passes of these estimations.) Thus, Algorithm \ref{alg:one} can be implemented in an embarrassingly parallel manner and most of the computations can be done before receiving the new measurements $y$, making it highly suitable for distributed computing systems.
\begin{figure}
\begin{algorithmic}[1]
\Require{Forward operator $A$, noise variance $\sigma^2$, estimator $\widehat{x}$, measurement $y$, samples $\{y_i\}_{i = 1}^M$, precision level $1-\alpha \in (0,1) . $}  
\Statex
\For{$i \gets 1$ to $M$}                    
    \State {$S_i \gets \textrm{PURE}(y_i)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE_N}}
    % \If{$s_{\text{mul}}$}
    %     \State $s_i \gets \frac{\|Ax_i-A\widehat{x}(y_i)\|_2^2}{S_i}$
    % \ElsIf{$s_{\text{add}}$}
    %     \State $s_i \gets \|Ax_i-A\widehat{x}(y_i)\|_2^2 - S_i$
    % \EndIf
\EndFor

\State {$\hat{Q}_\alpha$ $\gets$ top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile of $\{S_i\}_{i = 1}^M$}
\State $m  \gets dim(y)$

% \State {$S \gets \textrm{SURE}(y)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE_2}}



% \If{$s_{\text{mul}}$}
\State {$\widehat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\widehat{x}(y)\|_2^2 / m\leq  \hat{Q}_\alpha\}$}
%% \ElsIf{$s_{\text{add}}$}
% \State {$\widehat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\widehat{x}(y_{\text{new}})\|_2^2 \leq S + \hat{Q}_\alpha\}$}
% \EndIf
\Statex 
\Ensure{Prediction set $\widehat{C}(y)$}
\end{algorithmic}
\caption{\label{alg:one}PURE-based conformal prediction}
\end{figure}












%\newpage
\section{Poisson imaging  experiments}\label{sec:experiments}
We illustrate our proposed self-supervised conformal prediction framework on two canonical Poisson image image restoration tasks: Poisson image denoising and non-blind Poisson image deblurring. In each case, we employ the algorithm of Fig.~\ref{alg:one} to construct conformal prediction sets over a range of confidence levels \(\alpha \in (0, 1)\), sampled from \(0\%\) to \(100\%\). By design, each prediction set should contain the ground-truth solution with a probability close to \(1 - \alpha\). To verify this in practice, we compute empirical coverage probabilities on a separate test set. Specifically, for each \(\alpha\), we measure the proportion of images in the test set that lie within their corresponding prediction sets. In both experiments, the calibration sets are of size \(M = 900\), which is sufficiently large to ensure that comparisons with supervised methods are fair; the test set is of size \(M = 200\). (We chose this split between calibration and test set to facilitate comparisons with supervised alternatives; however, our self-supervised method can also be naturally implemented by using a leave-one-out strategy). With regards to the choice of $\widehat{x}$, for both experiments we use a deep neural network estimator trained end-to-end in a self-supervised manner by using the PyTorch Deep Inverse library\footnote{\url{https://deepinv.github.io/deepinv/}}. More precisely, we train $\widehat{x}$ by using the PURE-based self-supervised training approach described in~\cite{chen2022robustequivariantimagingfully}. As a baseline for comparison, we also report results using a fully supervised conformal prediction technique implemented by using the same estimator $\widehat{x}$ but trained in a supervised manner, so where ground-truth data are available both for training the estimator as well as for calibrating the conformal prediction sets.

% We demonstrate the proposed self-supervised conformal prediction approach by applying it to two image restoration problems: {image Poisson  denoising} and {image Poisson  deblurring}.

% To showcase the versatility of the method, for image Poisson denoising we construct conformal prediction sets by using a learning-based image restoration technique trained in a self-supervised end-to-end manner, whereas for image deblurring we use the model-driven technique. %Fig. \ref{fig:reconstruction} for examples from these two problems.

% For each experiment, we implement our method by using Algorithm \ref{alg:one} to compute conformal prediction sets. We consider a fine grid of values for the confidence parameter \( \alpha \in (0,1) \), ranging from $0\%$ to $100\%$. The corresponding prediction sets should cover the solution space with a probability of approximately \( 1-\alpha \). We evaluate the accuracy of these prediction sets by calculating the empirical coverage probabilities on a test set. Specifically, we compute the proportion of test images that lie within the conformal prediction sets for various confidence levels. In all experiments, the calibration sample size \( M \) is chosen to be sufficiently large to ensure that the variability of the sample quantiles caused by the finite-sample correction is negligible. Furthermore, for comparison, in each experiment we also report results by supervised conformal prediction (i.e., using ground truth data for calibration and for training the network rather than measurements only). %, as well as results from the equivariant bootstrapping technique proposed recently in \cite{tachella2023equivariant}. 
% The experiments are implemented using the Deep Inverse library\footnote{https://deepinv.github.io/deepinv/} for imaging with deep learning using PyTorch. 




%Furthermore, 

%we provide comparisons with a supervised conformal prediction to the equivariant bootstrap, which our approach greatly outperforms on these image restoration problems. Additionally, we compare the self-supervised conformal prediction method with its supervised counterpart, which achieves the most accurate uncertainty quantification. Remarkably, the results show that the self-supervised approach is very close to, and in some cases (deblurring See Fig. \ref{fig:deblurring})  almost identical to, its supervised version, highlighting its effectiveness and reliability. The experiments are conducted using the Deep Inverse library\footnote{https://deepinv.github.io/deepinv/} for imaging with deep learning using PyTorch. 






\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{Graphs/poisson_reconstruction.png}
    \caption{{Image reconstruction results for image denoising (top) and non-blind image deblurring (bottom), by using a self-supervised neural-network estimator $\hat{x}(y)$ and images from \texttt{DIV2K}.}}
    \label{fig:reconstruction}
\end{figure}

%, and the results highlight the ability of the proposed method to provide accurate uncertainty quantification across a range of restoration tasks.



% We now illustrate the proposed conformal prediction approach by applying it to three image restoration problems: image denoising, image deblurring and computed tomography. To show the versatility of the method, we consider the construction of conformal prediction sets for both model-driven and data-driven image restoration techniques. We conduct the following image restoration experiments using the deep inverse library \cite{Tachella_DeepInverse_A_deep_2023} :

\subsection{Image Poisson  Denoising}
We consider colour images of size $d=256\times 256$ pixels taking values in the hypercube $[0,1]^{3d}$, obtained by cropping images from the \texttt{DIV2K} dataset \cite{Agustsson_2017_CVPR_Workshops}, which we artificially corrupt  by applying the considered Poisson observation model with $A = \mathbb{I}$ and \( \gamma = 4 \). As image restoration method, we use an unrolled proximal gradient network with $4$ iterations and no weight-tying across iterations with a backbone denoiser  set as the U-Net architecture with 2 scales. The training is done  in a self-supervised manner by using the PURE loss \cite{chen2022robustequivariantimagingfully}. The training data consists of $900$ noisy measurements, we do not use any form of ground truth data neither for training nor for conformal prediction calibration. Fig. \ref{fig:reconstruction} (top) shows an example of a clean image, its noisy measurement, and the estimated reconstruction. 

We then use these same noisy measurements to compute our proposed self-supervised conformal prediction sets, and assess their accuracy empirically by using $200$ measurement-truth pairs from the test dataset. The results are reported in Fig. \ref{fig:denoising} below, together with the results obtained by using the equivalent supervised conformal prediction approach that relies on ground truth data for calibration and the supervised version of the estimator. We observe that our method delivers prediction sets that are remarkably accurate and in close agreement with the results obtained by using supervised conformal prediction, demonstrating that the bias stemming from using PURE instead of ground truth data is negligible.%, at least in this case. %For completeness, Fig. \ref{fig:histogram} (top) shows the empirical distribution of the non-similarity function $s(x,y)$ for the supervised conformal prediction based on the MSE, and the proposed self-supervised conformal prediction based on a PURE estimate of the MSE. Again, we observe close agreement between these distributions.%, with the PURE distribution being slightly more spread due to the random error inherent to PURE. 

%Moreover, for completeness we also report the results obtained by equivariant bootstrapping \cite{tachella2023equivariant}, which is significantly less accurate for this problem\footnote{The bootstrap is implemented by using rotation and two-dimensional shifts. Rotations are sampled from a Gaussian distribution with zero mean and a standard deviation of \( \sigma_{\theta} \) (denoising: \( \sigma_{\theta} = 125 \), deblurring: \( \sigma_{\theta} = 200 \)), while horizontal and vertical shifts are sampled from a uniform distribution on \( [-\Delta t, \Delta t] \) pixels (denoising: \( \Delta t = 250 \)}. The lack of accuracy of equivariant bootstrapping stems 





\begin{figure}[t!]
    \centering
    \includegraphics[width=1.1\linewidth]{Graphs/coveragepoissondenoisingwithoracle.png}
    \caption{\textbf{Poisson image denoising experiment}: desired confidence level vs empirical coverage; the proposed self-supervised conformal prediction methods deliver prediction sets with near perfect coverage.}
    \label{fig:denoising}
    \vspace{-3mm}
\end{figure}


\subsection{Image Poisson Deblurring}
We now consider a non-blind Poisson image deblurring experiment with grayscale  images of size $256 \times 256$ pixels taking values in the hypercube $[0,1]^{d}$, also derived from the \texttt{DIV2K} dataset \cite{Agustsson_2017_CVPR_Workshops} and artificially degraded with an isotropic Gaussian blur of standard deviation  $\sigma = 2$ pixels, and Poisson noise  with \( \gamma = 60 \). As our reconstruction network, we use the state-of-the-art SwinIR architecture \cite{SwinIR}, trained with the loss function proposed \cite{scanvic2024selfsupervisedlearningimagesuperresolution}. This loss leverages both scale-invariance and an unbiased risk estimator (PURE) to form a self-supervised training objective. Fig. \ref{fig:reconstruction} (bottom) depicts an example of a clean image, its noisy measurement, and its estimate $\hat{x}(y)$. 

Again, we use 900 blurred and noisy images for training $y \mapsto \hat{x}(y)$ and for computing our proposed self-supervised conformal prediction sets. To evaluate their accuracy, we use 200 measurement–truth pairs from the test dataset. The corresponding results are presented in Figure~\ref{fig:deblurring}, alongside those obtained using an analogous supervised conformal prediction approach that relies on ground truth data for training and calibration. As in the previous experiment, our method produces prediction sets that closely match those from the fully supervised approach, indicating that the bias introduced by using PURE in place of ground truth data is again negligible.

%For completeness, Figure~\ref{fig:histogram} (down) displays the empirical distribution of the non-similarity function \(s(x, y)\) for both the supervised conformal prediction (based on MSE) and our self-supervised conformal prediction (based on a PURE estimate of MSE). The close agreement between these two distributions further demonstrates the effectiveness of our self-supervised approach.

% We use $900$ blurred and noisy images for the training as well as  to compute our proposed self-supervised conformal prediction sets, and assess their accuracy empirically by using $200$ measurement-truth pairs from the test dataset. The results are reported in Fig. \ref{fig:deblurring} below, together with the results obtained by using the equivalent supervised conformal prediction approach that relies on ground truth data for calibration. Again, we observe that our method delivers prediction sets that are accurate and remarkably close to the results obtained by using supervised conformal prediction with the supervised model, demonstrating that the bias stemming from using PURE instead of ground truth data is again negligible in this case. For completeness, Fig. \ref{fig:histogram} (right) below shows the empirical distribution of the non-similarity function $s(x,y)$ for the supervised conformal prediction based on the MSE, and the proposed self-supervised conformal prediction based on a PURE estimate of the MSE. Again, we observe close agreement between these distributions.
    

\begin{figure}[t!]
    \centering
    \includegraphics[width=1.1\linewidth]{Graphs/coveragepoissondeblurringwithoracle.png}
    \caption{\textbf{Poisson image deblurring experiment}: desired confidence level vs empirical coverage; the proposed self-supervised conformal prediction methods deliver prediction sets with near perfect coverage.}
    \label{fig:deblurring}
    \vspace{-3mm}
\end{figure}

% \subsection{Comparison to equivariant bootstrapping}



% For each problem, we evaluate equivariant bootstrap using the self-supervised estimators provided by the respective restoration methods. We consider two types of group actions: rotations and two-dimensional shifts. Rotations are sampled from a Gaussian distribution with zero mean and a standard deviation of \( \sigma_{\theta} \) (denoising: \( \sigma_{\theta} = 125 \), deblurring: \( \sigma_{\theta} = 200 \)), while horizontal and vertical shifts are sampled from a uniform distribution on \( [-\Delta t, \Delta t] \) pixels (denoising: \( \Delta t = 250 \), deblurring: \( \Delta t = 200 \)). Equivariant bootstrap generates 1000 independent Monte Carlo samples, which are then used to compute confidence regions for various confidence levels.






% \textcolor{red}{Add some technical information about equivariant bootstrapping here, in particular what group actions were used for the experiment and how many samples of these group actions (or that we have taken sufficiently many to make the additional variance neg liable, like we do with assuming that $M$ is sufficiently large).}








% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=1\linewidth]{Chapters//Ch4//Figures/result_tomo_sup.png}
%     \caption{Result of the Supervised Case}
%     \label{fig:Rtomosup}
% \end{figure}
    
%     \item  \textbf{Debluring of images from DIV2K dataset \cite{Agustsson_2017_CVPR_Workshops}} Corrupted by a Gaussian blur with specified with three parameters: $\sigma_0=2$, the standard deviation of the main axis, $\sigma_1 =0.3$, the orthogonal axis standard deviation, and $\theta = \frac{\pi}{6}$, the angle between the major axis and the horizontal added with a Gaussian noise with noise level $\sigma=0.01$.  As estimator, we implemented Polyblur \cite{delbracio2021polyblurremovingmildblur} a highly efficient blind restoration method that remove mild blur in natural images by polynomial reblurring using  the polynomial filter family of degree $d=3$  \eqref{polyblur}  with calibrated $\alpha=6$ and $\beta =1$ 
% \begin{equation}
%   p_{3, \alpha, b}(x)=(\alpha / 2-\beta+2) x^3 +(3 \beta-\alpha-6) x^2 
% +(5-3 \beta+\alpha / 2) x+\beta  \label{polyblur}.  
% \end{equation}

% % For each experiment, we use Algorithm \ref{alg:one} to compute our  proposed  conformal prediction sets , considering a fine grid of values
% of $\alpha \in (0,1) $   ranging from $0\%$ to $100\%$ to obtain regions with coverage $1-\alpha$. We evaluate
% the accuracy of these conformal prediction sets by calculating the empirical coverage probabilities on a test set, as measured by the proportion of test images that lie within the prediction sets for the 
% range of specified confidence levels . In all experiments, $M$ is large enough so that the variability of the sample quantiles is neglegible.

%Recall that the aim is to deliver conformal prediction regions that contain $\widehat{x}(y)$ and are as compact as possible, for a given coverage level. The regions contain $\widehat{x}(y)$ by construction. Therefore, 

% To assess the performance of the proposed methods we compare the size of the delivered regions against the size of a region that is not adaptive to the value of $y$. More precisely, we take advantage of the elliptical form of the regions and compute the radius $R(y)$ specifying the region $\widehat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\widehat{x}(y)\|_2^2 \leq R(y)^2\}$. For the two SURE-normalised methods, the radii squared are given by $R^2_{mull} = S\times \hat{Q}_{mull,\alpha}$ and $R^2_{add} = S + \hat{Q}_{add,\alpha}$ respectively. For comparison, we compute the volume of an equivalent conformal prediction region without SURE-normalisation (we use the form \eqref{eq:score_multi_target} with $\Sigma(y) = A^\top A$ in the multiplicative-normalized setting). In that case, the radius squared, denoted simply by $R^2$, is constant, as there is no adaptivity w.r.t. $y$. 

% Figure \ref{fig:radii} below shows box-plots summarising the distribution of the radii $R(y)$ associated to the two proposed regions, alongside the constant radius $R$ associated with the region without adaptation. Each box in Figure \ref{fig:radii} spans the range from the 25\% to 75\% quantiles, the median is highlighted in colour orange, and the whiskers indicate the 10\% to 90\% quantiles; the value $R^2$ associated with the non-adaptive region is presented as a dashed black line. We observe in Figure \ref{fig:radii} that normalization using SURE can significantly reduce the prediction set when compared to non-normalised prediction sets (recall that all sets are conformalised to accumulate the same probability mass; the SURE-normalised sets leverage adaptivity to accumulate mass from regions of higher probability and are more compact as a result). Moreover, additive normalization performs at least as good as multiplicative normalization. Especially in the MNIST experiment, where the error is relatively small and SURE is difficult to compute accurately because MC-SURE has relatively high variance, we observe a big improvement when using additive normalization.

% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{radii_1.pdf}
%     \includegraphics[width=\textwidth]{radii_2.pdf}
%     \caption{Distribution of the radius squared $R^2$ of the prediction sets, i.e., $\widehat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\widehat{x}(y)\|_2^2 \leq R^2\}$, for various precision levels $\alpha$. The dashed horizontal line corresponds to constant radius from not normalising.}
%     \label{fig:radii}
% \end{figure}





%To reduce the variability in the quantiles, we take a sufficiently large sample size $M$ such that the quantiles are practically constant. The resulting quantiles can be found in Table \ref{table:quantiles}.



% The most expensive part of Algorithm \ref{alg:one} is the divergence estimation using Equation \eqref{eq:MC-SURE}. Particularly for experiment on MNIST, which uses a relatively strong prior, the divergence is small or dominated by a small number of directions. To improve the computational cost, we can assume the divergence is zero, or at least very small, to circumvent Equation \eqref{eq:MC-SURE}. Quantiles corresponding to this zero divergence assumption are shown in Table \ref{table:quantiles}, and are generally not substantially larger than those with more accurate SURE estimation, especially for the additive score.

% Similarly for the MNIST experiment, due to the difficulty of estimating the SURE and the overall high accuracy, there are significant number negative SURE estimates. Specifically, $4.8\%$ with MC-SURE and $8.4\%$ with the zero divergence assumption, resulting in an equal number of uninformative prediction sets for the multiplicative score function. In MNIST experiment with additive scoring function and in the experiments with the other datasets, no uninformative prediction sets occurred.

% Note that in the Flower102 and DTD experiments in which the SURE can be estimated quite accurately, both proposed scoring functions perform approximately equal, whilst for the MNIST experiment, in which the SURE is more difficult to estimate, the additive scoring functions seems to perform better.

% Because the proposed SURE-normalised regions adapt to $y$ and are more compact, they are also more informative. To illustrate this point, we follow the uncertainty visualisation approach of \cite{liaudat2023scalable} which progressively removes detail from $\widehat{x}(y)$ until we reach the boundary of $C(y)$. This allows decomposing $\widehat{x}(y)$ into an the sum of two images: an image $T(\widehat{x}(y))$ that has low uncertainty, and a detail term $\widehat{x}(y)-T(\widehat{x}(y))$ with high uncertainty and which may vary significantly as we move across $C(y)$. There are many ways of constructing the decomposition $\widehat{x}(y) = T(\widehat{x}(y)) + [\widehat{x}(y)-T(\widehat{x}(y))]$. Similarly to \cite{liaudat2023scalable}, we adopt a construction based on a Haar wavelet representation of $\widehat{x}(y)$, where we progressively remove the smallest coefficients until we reach the boundary of $C(y)$. 

% Figure \ref{fig:UQ} below depicts the decompositions of $\widehat{x}(y)$ obtained in this manner for four images from the MNIST deblurring experiment. For each case, we obtain three decompositions of $\widehat{x}(y)$ by using our two SURE-normalised regions and the unnormalised region at level $99\%$. We observe that in all cases the uncertainty is mostly concentrated on contours, as expected for an image deblurring problem. Moreover, because the SURE-normalised regions are more informative, they lead to sparse and mild residuals $[\widehat{x}(y)-T(\widehat{x}(y))]$, as only mild details about $\widehat{x}(y)$ have high uncertainty. Conversely, because the unnormalised regions are larger and less informative, they lead to residuals $[\widehat{x}(y)-T(\widehat{x}(y))]$ that are large, reflecting high uncertainty across $\widehat{x}(y)$ (see bottom row of Figure 2).


% \begin{figure}
%     \centering
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_1.pdf}%
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_0.pdf}
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_6.pdf}%
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_5.pdf}

% %    \includegraphics[width=\linewidth]{uq/uq_flower102_0.pdf}
%     \caption{Uncertainty visualisation obtained by decomposing $\widehat{x}(y)$ as a low-uncertainty image $T(\widehat{x}(y))$ and a high-uncertainty residual $\widehat{x}(y)-T(\widehat{x}(y))$. Compact and informative regions that adapt to $y$ lead to smaller and sparse residuals, whereas large regions reflect significant uncertainty in $\widehat{x}(y)$.}
%     \label{fig:UQ}
% \end{figure}





% \begin{figure}[h!]
%     \centering
%     \begin{subfigure}[h!]{0.49\textwidth}
%         \includegraphics[width=\textwidth]{Graphs/histogrampoissondenoising.png}
%         \caption{Image Poisson denoising}
%         \label{subfig:histogramdenoising}
%     \end{subfigure}
%     %\hfill % this command adds a little space between the images
%     \begin{subfigure}[h!]{0.49\textwidth}
%         \includegraphics[width=\textwidth]{Graphs/histogrampoissondeblurring.png}
%         \caption{Image Poisson deblurring}
%         \label{subfig:histogramdeblurring}
%     \end{subfigure}
%     \caption{\textbf{Calibration histograms} (empirical distribution of the non-similarity function $s(x,y)$) for the supervised case (MSE with supervised network) and the self-supervised case based on a PURE estimate of the MSE with an self-supervised network, for the Poisson denoising and deblurring experiments.}
%         \label{fig:histogram}
% \end{figure}

%\clearpage
%\newpage

\section{Discussion and Conclusion}
\label{sec:discussion}
Leveraging the Poisson Unbiased Risk Estimator, a novel self-supervised conformal prediction method has been proposed. The method is useful for uncertainty quantification in Poisson imaging problems, a key class of imaging problems that were beyond the scope of existing self-supervised conformal prediction methodology \cite{everink2025}. Unlike standard split conformal prediction, the proposed method does not require any ground truth data for calibration, thus significantly extending the application scope of conformal uncertainty quantification. In addition to bypassing the efforts associated with acquiring reliable ground truth data, self-calibration also provides robustness to distribution shift, a key issue when deploying conformal methods in populations that might not be well represented by the training data available. The proposed approach is particularly powerful when combined with modern self-supervised image reconstruction techniques, trained directly from measurements without the need for ground truth data. The effectiveness of the proposed self-supervised conformal prediction method was assessed through Poisson image denoising and Poisson image deblurring experiments with the \texttt{DIV2K} dataset, where it delivered highly accurate conformal prediction regions and performs on par with fully supervised alternatives. 

Future work will seek to establish mathematical guarantees for the proposed method, with particular attention to the interplay between the number of considered imaging problems $M$, the dimensionality of $X$ and $Y$, the regularity of the estimator $\hat{x}$, and the number of projections used in the stochastic trace estimator within PURE. Furthermore, future work could also consider extensions of the proposed framework to other noise models from the exponential family. For example, it would be interesting to tackle Poisson-Gaussian noise models, which are commonly encountered in microscopy \cite{khademi2021self}. 

With regards to applications, uncertainty quantification is key when using restored signals in critical scientific and decision-making processes. For example, it is of utmost importance in epidemiology when monitoring an ongoing epidemic such as COVID-19~\cite{nash2022real}.
% Measurements consists in infection counts time series.
State-of-the-art models for viral epidemics describe the number of new infections at a given time $t$ as a Poisson random variable whose parameter depends on previous counts and on a key unknown quantity, the so-called \emph{reproduction number} $R_t$, which reflects the strength of the epidemic~\cite{Corimodel}. A major challenge in the estimation of $R_t$ during a ongoing pandemic is that available data are highly corrupted by administrative noise, making the estimation of $R_t$ an ill-conditioned inverse problem.
A ambitious perspective for future research is to extend the proposed self-supervised PURE-based conformal prediction framework to the estimation of $R_t$ by leveraging the recently proposed Autoregressive Poisson Unbiased Risk Estimator~\cite{pascal2024risk}. A key difficulty in that case will be to obtain accurate PURE estimates from short epidemiological time series data.
%\vspace{2cm}

%This paper presented a self-supervised approach for constructing conformal prediction regions for linear imaging problems with Poisson noise. 
%Unlike conventional conformal prediction approaches, the proposed method does not require any form of ground truth data. 
%This is achieved by leveraging the appropriate Stein's unbiased risk estimator and by pooling together a group of exchangeable Poisson imaging problems that collectively provide all the required information to perform uncertainty quantification. 
%This allows conformal uncertainty quantification in imaging problems for which obtaining reliable ground truth data would be difficult, and provides robustness to distribution shift. The proposed method is estimator-agnostic, as it uses a Monte Carlo implementation of Stein's estimator that does not require any explicit knowledge of the image restoration algorithm used. In particular, this flexibility allows implementing our method with self-supervised learning-based estimators that are also trained directly from the measurement data. Moreover, the method is computationally efficient as computations can be performed in parallel. We demonstrated the effectiveness of the proposed method through image denoising and deblurring experiments, where we observed that our method delivers extremely accurate prediction sets. 

%Future work will explore the generalization of the proposed approach to other Poisson noise models, such as Poisson-Gaussian models relevant to remote sensing and autoregressive Poisson models encountered in time series analysis, as well as to problems in which the parameters of the noise model are unknown \cite{tachella2024unsure}. Another important perspective for future work is to extend this approach to problems in which the forward $A$ is not full rank, for example by leveraging equivariance properties. In particular, it would be interesting to study the integration of our proposed method and the equivariant bootstrap \cite{tachella2023equivariant}.

%\clearpage
%\newpage
\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}

\clearpage
\newpage

For any $i \in \lbrace 1, \hdots, n\rbrace$, under the shot noise model one has
\begin{align*}
    \mathbb{E}\left( (Ax^\star)_i - (A \widehat{x})_i \right)^2 &= \mathbb{E} (Ax^\star)_i^2 - 2 \mathbb{E} \left[(Ax^\star)_i (A \widehat{x})_i\right] + \mathbb{E} (A\widehat{x}^\star)_i^2
\end{align*}

But from the Poisson counterpart of Stein's lemma, for any real-valued function of the Poisson variable $y_i$
\begin{align*}
    \mathbb{E} \left[ \gamma(Ax^\star)_i \vartheta(y_i) \right] = \mathbb{E}\left[y_i \vartheta(y_i - 1)\right]
\end{align*}
it follows that
\begin{align*}
    \mathbb{E} (Ax^\star)_i^2 &= \frac{1}{\gamma} \mathbb{E}\left[ (Ax^\star)_i y_i\right]\\
    &= \frac{1}{\gamma^2} \mathbb{E}\left[  y_i (y_i - 1)\right],
\end{align*}
and that
\begin{align*}
    \mathbb{E} \left[(Ax^\star)_i (A \widehat{x})_i\right] = \frac{1}{\gamma} \mathbb{E}\left[y_i \left( A \widehat{x}(y^{(-i)})\right)\right]
\end{align*}
where $y^{(-i)}$ is a vector identical to $y$ except that the $i$th component equals $y_i-1$, then using a Taylor expansion at order $1$ one obtains
\begin{align*}
    \mathbb{E} \left[(Ax^\star)_i (A \widehat{x})_i\right] &= \frac{1}{\gamma} \mathbb{E}\left[y_i \left( A \widehat{x}(y^{(-i)})\right)_i\right] \\
    &\simeq  \frac{1}{\gamma} \mathbb{E}\left[y_i \left( A \widehat{x}(y)\right)_i\right] - \frac{1}{\gamma} \mathbb{E}\left[y_i \frac{\partial\left( A \widehat{x}\right)_i}{\partial y_i}\right]
\end{align*}
Combining all above results yields
\begin{align*}
    \mathbb{E}\left( (Ax^\star)_i - (A \widehat{x})_i \right)^2 &= \mathbb{E} (Ax^\star)_i^2 - 2 \mathbb{E} \left[(Ax^\star)_i (A \widehat{x})_i\right] + \mathbb{E} (A\widehat{x}^\star)_i^2\\
    &\simeq \frac{1}{\gamma^2} \mathbb{E} y_i^2 - \frac{1}{\gamma^2} \mathbb{E}y_i - \frac{2}{\gamma} \mathbb{E}\left[y_i \left( A \widehat{x}(y)\right)_i\right]\\
    & + \frac{2}{\gamma} \mathbb{E}\left[y_i \frac{\partial\left( A \widehat{x}\right)_i}{\partial y_i}\right] + \mathbb{E} (A\widehat{x}^\star)_i^2 \\
    & = \mathbb{E}\left[ \left( (A\widehat{x})_i - \frac{y_i}{\gamma}\right)^2\right] - \frac{1}{\gamma^2} \mathbb{E}y_i \\
    & + \frac{2}{\gamma} \mathbb{E}\left[y_i \frac{\partial\left( A \widehat{x}\right)_i}{\partial y_i}\right]
\end{align*}

ov