% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[numbers]{natbib}


\begin{document}
%
\title{SURE-adjusted Conformal Prediction for Uncertainty Quantification in Image Restoration Problems}
%
\titlerunning{SURE-based Conformal Prediction for UQ in Imaging}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Jasper M. Everink\inst{1}\orcidID{0000-0001-7263-0317} \and \\ Marcelo Pereyra\inst{2}\orcidID{0000-0001-6438-6772}}
%
\authorrunning{J.M. Everink and M. Pereyra.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Technical University of Denmark, Kgs. Lyngby, Denmark, \email{jmev@dtu.dk} \and
Heriot-Watt University \& Maxwell Institute for Mathematical Sciences, Edinburgh, UK }
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Most image restoration problems are not well-posed, and thus may have some significant intrinsic uncertainty. Robustly quantifying the uncertainty in the solutions to such problems is important for the reliable interpretation of experimental results, especially if the reconstructed images are used as evidence in decision-making or science. Unfortunately, most image restoration methods do not quantify the uncertainty in the restored images, or provide uncertainty quantification estimates that are highly subjective, inaccurate, and not useful in practice yet. Conformal prediction has recently emerged as a powerful framework to endow any statistical estimator with uncertainty quantification capabilities. Conformal prediction is versatile and easy to apply to problems of small or moderate dimension. However, when applied to imaging problems and other high-dimensional problems, it often provides uncertainty estimates that are too loose and uninformative. In this paper, we propose a conformal prediction method tailored for linear imaging inverse problems. The proposed method leverages Stein's unbiased risk estimator to sharpen its uncertainty quantification results and scale robustly to high-dimensional settings. The approach is demonstrated through a series of numerical experiments related to image denoising, deblurring and computed tomography, where it is used to construct confidence regions for a wide range of different imaging methods.

\keywords{
image processing \and uncertainty quantification \and conformal prediction \and Stein's unbiased risk estimate.}
\end{abstract}
%
%
%

\section{Introduction} 
Image restoration tasks often require solving an inverse problem that is ill-posed, and which can consequently involve significant uncertainty about the unobserved true image. Quantifying and characterising this uncertainty is important for applications that rely on the restored images to inform important decisions. There are several statistical frameworks available to formulate and solve uncertainty quantification problems in imaging sciences. For example, many uncertainty quantification methods for image restoration rely on the Bayesian statistical framework \cite{calvetti2018inverse}, which can be implemented by using a wide range of modelling and algorithmic approaches (see, e.g., \cite{Durmus2018,Pereyra2017,laumont2022bayesian,holden2022bayesian}). One can also consider uncertainty quantification methods based on bootstrapping (see \cite{tachella2023equivariant}), which delivers the most accurate uncertainty quantification results to date. Alternatively, when there is enough calibration data available, it is possible to perform uncertainty quantification by using conformal prediction \cite{angelopoulos2021gentle}, which is highly flexible and can be deployed in combination with any image restoration technique.

Conformal prediction has been recently successfully applied to a range of imaging problems (see, e.g., \cite{angelopoulos2022image, narnhofer2024posterior}). However, existing conformal prediction approaches for imaging focus on pixel-wise uncertainty. Therefore, the statistical guarantees provided by the conformal prediction framework only hold marginally per pixel. This is a strong limitation because decisions based on image data usually involve a many image pixels. However, scaling conformal prediction to large regions is difficult because the results become vague and uninformative. There has been some research on designing conformal prediction strategies for problems of moderate dimension (see, e.g., \cite{messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal}), but the dimensionality encountered in imaging problems is beyond the reach of these strategies. 

In this paper, we propose a method that leverages Stein's unbiased risk estimator to scale conformal prediction to high-dimensional problems, so that it can be applied to image restoration. The paper is structured as follows. Section \ref{sec:background} introduces conformal prediction. Then in Section \ref{sec:method} we present our proposed method. Following on from this, Section \ref{sec:experiments} illustrates the proposed approach on image denoising, deblurring and computed tomography experiments. Conclusions and perspectives for future work are finally reported in Section \ref{sec:discussion}.
%\newpage
\section{Problem statement}\label{sec:background}
We consider the problem of estimating a set of likely values for an unknown image of interest $x^\star \in \mathbb{R}^n$, from some measurement $y = Ax^\star + e \in \mathbb{R}^n$ where $A \in \mathbb{R}^{m \times n}$ models deterministic instrumental aspects of the estimations problem and $e$ represents some additive error. We assume that $x^\star$ is a realisation of some random variable $X$, and $y$ is a realisation of the conditional random variable $Y|X=x^\star$. By $\hat{x}(y)$ we denote a technique to estimate $x^\star$ from $y$ (a point estimator). 

We seek to identify a region $C(Y) \subset \mathbb{R}^n$ of the solution space such that 
\begin{equation}\label{predictionC}
    \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) \geq 1-\alpha\,,
\end{equation}
where we note that the probability is w.r.t. to the joint distribution $(X,Y)$.%under new realisations of $X$ and $Y$ from repetitions of the experiment. 

For illustration, suppose that $x^\star$ is a high-resolution MRI scan of an adult brain. The random variable $X$ provides a probabilistic description of what an adult brain MRI scan looks like for a generic individual of the population, as acquired by an ideal MRI scanner with no noise or resolution limitations. The image $x^\star$ is a sample of $X$ stemming from imaging a specific member of that population with that ideal MRI scanner. The data ${y}$ represents the actual measurement obtained, which is corrupted by noise and other forms of degradation. The estimator $\hat{x}(y)$ provides an estimate of $x^\star$. The region $C(y)$ gathers a set of solutions, rather than a single point, and property \eqref{predictionC} states that, if we repeat this procedure a large number of times with different members of the population, we should expect their respective regions $C$ to contain their respective ``true'' brain scan in at least $(1-\alpha)$\% of the cases.

Conformal prediction provides a general framework to construct such set $C$ \cite{angelopoulos2021gentle}. This is achieved by using a so-called \emph{non-conformity measure} or score function $s: \mathbb{R}^n \times \mathbb{R}^m\mapsto\mathbb{R}$. If we take the top $(1-\alpha)$-quantile $q_\alpha$ of the statistic $s(X, Y)$ and define $C(y) := \{x\in \mathbb{R}^n \,|\, s(x,y) \leq q_\alpha\}$ for all $y \in \mathbb{R}^m$, then by construction
\begin{equation*}
    \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) = \mathbb{P}_{(X, Y)}\left(s(X, Y) \leq q_\alpha \right) \geq 1-\alpha,
\end{equation*}
for any $\alpha \in (0,1)$. Following this procedure, and given a sufficient large sample $\{x_i,y_i\}_{i=1}^M$ to calibrate $q_\alpha$, any suitable score $s$ can be used to construct a set $C$ that contains $x$ with high probability w.r.t. the joint distribution of $(X,Y)$. 

More precisely, the split conformal prediction approach considers a training sample $\{X_i, Y_i\}_{i=1}^M$ of independent (or at least exchangeable) copies of $(X, Y)$ from which we take the empirical top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile $\hat{Q}_\alpha$ of $\{s(X_i,Y_i)\}_{i=1}^{m}$. Then, for a new copy $(X_{new}, Y_{new})$ of $(X,Y)$, the set $\hat{C}(Y_{new}) := \{X_{new}\in \mathbb{R}^n\,|\, s(X_{new},Y_{new}) \leq \hat{Q}_\alpha\}$ satisfies
\begin{equation}\label{eq:conformal_guarantee}
    \mathbb{P}_{(X, Y)^{M+1}}\left(X_{\text{new}} \in \hat{C}(Y_{\text{new}}) \right)  
    \geq 1-\alpha\,,
\end{equation}
and where we note that \eqref{eq:conformal_guarantee} implicitly contains a finite-sample correction because $\hat{Q}_\alpha$ is derived from a $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile; this correction vanishes as $M\rightarrow\infty$.
Please see \cite{angelopoulos2021gentle} for an excellent introduction to conformal prediction.

While the conformal prediction framework is highly flexible, not all score functions $s(x,y)$ deliver regions that are equally useful in practice. Indeed, all prediction sets $\hat{C}(y)$ take the form of a sub-level set of the arbitrarily chosen $x \mapsto s(x,y)$. Hence, it is possible to construct infinitely many regions of the space $\mathbb{R}^{n}$ that will contain the truth $x^\star$ given the observed data $y$ with probability at least $1-\alpha$, but some of these regions might be extremely large. This issue is particularly prominent in high-dimensional problems, where a poor choice of score function $s(x,y)$ will lead to a region $\hat{C}(y)$ that covers most of the support of $X$. Carefully designing $s(x,y)$ is the crux to obtaining a conformal prediction set that is small and informative. In particular, it is essential that $s(x,y)$ adapts to $y$ so that the statistic $s(X,Y)$ has low variability.

Several approaches have been recently proposed to scale conformal prediction to high dimensions (see, e.g., \cite{messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal}). Of particular interest is the normalised score of the form
\begin{equation}\label{eq:score_multi_target}
\begin{split}
    s(x, y) &= \|x-\hat{x}(y)\|^2_{\Sigma(y)}\,,\\ &= \left(x-\hat{x}(y)\right)^\top \Sigma(y) \left(x-\hat{x}(y)\right)\,,
    \end{split}
    \end{equation}
for some positive semidefinite matrix $\Sigma(y)$ of size $n \times n$, which is chosen such that $s(X, Y)$ exhibits low variability. A successful choice of $\Sigma(y)$ will lead to conformal prediction sets that are centred on $\hat{x}(y)$ and are small in space and therefore highly informative. Furthermore, they satisfy property \eqref{eq:conformal_guarantee} by construction.

In previous work, $\Sigma(y)$ is chosen as an approximate inverse-covariance matrix. In \cite{johnstone2021conformal}, they propose to estimate this inverse-covariance matrix globally from the errors in a sample $\{x_i,y_i\}_{i=1}^M$. Because this matrix does not depend on $y$, they proposed in \cite{messoudi2022ellipsoidal} to improve this global inverse-covariance matrix using errors of the k-nearest neighbours $\{x_i,y_i\}_{i=1}^k$ of $y$. However, when extending these approaches to higher dimensional problems, this improved matrix requires a large amount of data to properly capture the local uncertainty. We propose instead to leverage the form of the estimation problem and consider constructing $y$-adaptive score functions by using Stein's unbiased risk estimate (SURE) \cite{stein1981estimation}.

\section{Proposed Method}\label{sec:method}
We propose two strategies that leverage SURE to construct a score function $s(x,y)$ that adapts to $y$ in a manner that delivers conformal prediction regions that centred on $\hat{x}(y)$, are compact in space (relative to non-adaptive regions), and satisfy \eqref{eq:conformal_guarantee}. 

Our proposed approach considers a Gaussian observation model of the form $(Y|X=x^\star) \sim \mathcal{N}(Ax^\star,\sigma^2 \mathbb{I}_m)$ with noise variance $\sigma^2 > 0$ and possibly poorly conditioned $A$.

\subsection{Stein's unbiased risk estimator (SURE)}
For our proposed strategy, we use 
$$
\Sigma(y) = \frac{1}{\textrm{SURE}(y)}A^\top A\,,
$$
where SURE is an estimate of the projected mean squared error $\|Ax^\star-A\hat{x}(y)\|_2^2$ where $y$ is a realisation of $Y|X=x^\star$. Do note that if $A$ is not full rank, $\Sigma(y)$ is only positive semidefinite, implying that the corresponding prediction set $\hat{C}(y)$ can be unbounded. For simplicity, we therefore assume that $A$ has full column rank.

Following \cite{stein1981estimation}, if the estimator $\hat{x}$ is differentiable almost everywhere, the SURE is given by  
\begin{equation}\label{eq:SURE}
 \textrm{SURE}(y) = -m\sigma^2 + \|y - A \hat{x}(y)\|_2^2 + 2\sigma^2 \text{div} \left(A \hat{x}(y)\right)\,,  
\end{equation}
%    \text{div} \left(A\hat{x}(y) &:= \sum_{j = 1}^{m}\frac{\partial A\hat{x}}{\partial y_j}(y),
where $\text{div}(\cdot)$ denotes the divergence operator. The SURE is know quite accurate estimator of the projected mean squared error (see, e.g., \cite{bellec2021second}) and, for some estimators $\hat{x}$, efficiently computable closed-form expressions of this divergence are available (see, e.g., \cite{tibshirani2012degrees}). In general, and thus in alignment with the black-box nature of conformal prediction, we can estimate the divergence numerically \cite{ramani2008monte,nobel2023tractable}. Of particular interest is the Monte Carlo SURE (MC-SURE) approach \cite{ramani2008monte}, which is agnostic to the nature of the estimator $\hat{x}$: given $\epsilon > 0$ and a sequence of Rademacher, or more generally isotropic, random variables $\{d_i\}_{i = 1}^{K} \sim d$, the MC-SURE approximates $\text{div} \left(A \hat{x}(y)\right)$ as follows:
\begin{align}
\text{div} \left(A \hat{x}(y)\right) &= \mathbb{E}[d^TD(A\hat{x})(y)d] \approx \frac{1}{K}\sum_{i = 1}^{K}d_i^TD(A\hat{x})(y)d_i\label{eq:MC-SURE_1}\\
&\approx \frac{1}{K}\sum_{i = 1}^{K}d_i^T \frac{(A\hat{x}(y + \epsilon d_i) - A\hat{x}(y))}{\epsilon}\,,\label{eq:MC-SURE_2}
\end{align}
where $D(A\hat{x})(y)$ denotes the Jacobian matrix of the predicted measurements $A\hat{x}$ at the actual measurements $\vec{y}$. The stochastic trace approximation in \eqref{eq:MC-SURE_1}, know as Hutchinson's method \cite{hutchinson1989stochastic}, has in recent years been superseded by more state-of-the-art stochastic trace estimation algorithms. To reduce the number of directional derivative approximation $D(A\hat{x})(y)d$, and thus the number of estimations $\hat{x}$, we propose to use the XTrace algorithm \cite{epperly2024xtrace}, and keep the forward finite difference approximation of the directional derivative.

\subsection{SURE-adjusted conformal prediction}
Using the general form of \eqref{eq:score_multi_target} and levering the concentration properties of \eqref{eq:SURE}, we propose the conformal prediction score 
\begin{equation}\label{eq:score_mul}
    s_{\text{mul}}(x,y) = \frac{\|Ax-A\hat{x}(y)\|_2^2}{{SURE}(y)}\, . 
\end{equation}
We refer to this strategy as a multiplicatively-normalised score because $\textrm{SURE}(y)$ appears in the denominator of \eqref{eq:score_mul}. Note however, that the SURE \eqref{eq:SURE}, especially when using approximation \eqref{eq:MC-SURE_2}, is not guaranteed to be positive. In the case that the SURE estimate is positive, a prediction set computed using $s_{\text{mul}}$ is the interior of an ellipse, but whet the SURE estimate is negative, the prediction set is the exterior of an ellipse and therefore unbounded. This scenario can easily occur when the projected mean square error is relatively low or the SURE estimation is done inaccurately.

To reduce this issue, we also propose an alternative strategy that is more stable by normalizing the score in an additive manner
\begin{equation}\label{eq:score_add}
    s_{\text{add}}(x,y) = \|Ax-A\hat{x}(y)\|_2^2 - \textrm{SURE}(y)\,,
\end{equation}
which is more robust to the stochasticity of $\textrm{SURE}(y)$. We refer to this strategy as an additively-normalised score.

Using a calibration set $\{x_i,y_i\}_{i = 1}^M$ with \eqref{eq:score_mul} or \eqref{eq:score_add}, we can construct two conformal prediction sets by computing the top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantiles
$\hat{Q}_{\text{mul},\alpha}$ and $\hat{Q}_{\text{add},\alpha}$ of $s_{\text{mul}}(X,Y)$ and $s_{\text{add}}(X,Y)$ respectively. Whilst for $s_{\text{mul}}$ an unbounded prediction set is obtained when $\textrm{SURE}(y) < 0$, for $s_{\text{add}}$ and empty prediction set is obtained when $\textrm{SURE}(y) < \hat{Q}_{\text{add},\alpha}$, which is a less likely event.

The proposed strategies are summarised in Algorithm \ref{alg:one} below. This might seem very expensive, due to the great number of SURE estimations, each requiring multiple evaluations of the estimator $\hat{x}$. However, the $M$ SURE estimations in line 2 and the single SURE estimation in line 10 are all independent of each other. Similarly, all the directional derivative estimation in \eqref{eq:MC-SURE_2} are independent and can be done in parallel. (With the minor detail that the XTrace algorithm requires two sequential passes of these estimations.) Thus, Algorithm \ref{alg:one} can be implemented in an embarrassingly parallel manner and most of the computations can be done before receiving the new measurements $y$, making it highly suitable for distributed computing systems.
\begin{algorithm}
\caption{SURE-adjusted conformal prediction}\label{alg:one}

\begin{algorithmic}[1]
\Require{Forward operator $A$, noise variance $\sigma^2$, estimator $\hat{x}$, measurement $y$, samples $\{x_i,y_i\}_{i = 1}^M$, precision $1-\alpha$} 
\Ensure{Prediction set $\hat{C}(y)$}
\Statex
\For{$i \gets 1$ to $M$}                    
    \State {$S_i \gets \textrm{SURE}(y_i)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE_2}}
    \If{$s_{\text{mul}}$}
        \State $s_i \gets \frac{\|Ax_i-A\hat{x}(y_i)\|_2^2}{S_i}$
    \ElsIf{$s_{\text{add}}$}
        \State $s_i \gets \|Ax_i-A\hat{x}(y_i)\|_2^2 - S_i$
    \EndIf
\EndFor

\State {$\hat{Q}_\alpha$ $\gets$ top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile of $\{s_i\}_{i = 1}^M$}

\State {$S \gets \textrm{SURE}(y)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE_2}}



\If{$s_{\text{mul}}$}
\State {$\hat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\hat{x}(y_{\text{new}})\|_2^2 \leq S\times \hat{Q}_\alpha\}$}
\ElsIf{$s_{\text{add}}$}
\State {$\hat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\hat{x}(y_{\text{new}})\|_2^2 \leq S + \hat{Q}_\alpha\}$}
\EndIf

\end{algorithmic}
\end{algorithm}



\section{Experiments}\label{sec:experiments}
We now illustrate the proposed conformal prediction approach by applying it to three image restoration problems: image denoising, image deblurring and computed tomography. To show the versatility of the method, we consider the construction of conformal prediction sets for both model-driven and data-driven image restoration techniques. We conduct the following image restoration experiments:
\begin{enumerate}
    \item Deblurring of images from the MNIST dataset \cite{lecun2010mnist}, corrupted by a 5-by-5 box blur and noise standard deviation $\sigma = 0.05$. As estimator, we compute the posterior mean of a Bayesian image restoration model based on a variational autoencoder prior specialised for this dataset \cite{holden2022bayesian}. \label{exp_1}
    \item Deblurring of patches from the Flower102 dataset \cite{nilsback2008automated}, corrupted with a Gaussian blur with bandwidth $1$ and noise standard deviation $\sigma = 0.02$. As estimator, we use a Learned Iterative Shrinkage-Thresholding Algorithm (LISTA) specialised for this dataset \cite{gregor2010learning}. \label{exp_2}
    \item Denoising of images from the DTD dataset \cite{cimpoi14describing}, with noise standard deviation $\sigma = 0.1$. We consider estimators based on total-variation regularisation \cite{chambolle2004algorithm} and wavelet soft-thresholding \cite{chang2000adaptive}. \label{exp_3}   
    \item Reconstructing random grain samples from the discretized Radon transform with noise standard deviation $\sigma = 25$. As estimator we use a filtered backprojection algorithm \cite{hansen2021computed}.  \label{exp_2}
\end{enumerate}
%Examples of these experiments are shown in Figure \ref{fig:examples}. 
For each experiment, we use Algorithm \ref{alg:one} to compute our two proposed SURE-normalised conformal prediction sets (multiplicative and additive normalisation), considering $\alpha = 0.1, 0.05, 0.01$ to obtain regions with coverage $90\%, 95\%$ and $99\%$. In all experiments, $M$ is large enough so that the variability of the sample quantiles is neglegible. %Recall that the aim is to deliver conformal prediction regions that contain $\hat{x}(y)$ and are as compact as possible, for a given coverage level. The regions contain $\hat{x}(y)$ by construction. Therefore, 
To assess the performance of the proposed methods we compare the size of the delivered regions against the size of a region that is not adaptive to the value of $y$. More precisely, we take advantage of the elliptical form of the regions and compute the radius $R(y)$ specifying the region $\hat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\hat{x}(y)\|_2^2 \leq R(y)^2\}$. For the two SURE-normalised methods, the radii squared are given by $R^2_{mull} = S\times \hat{Q}_{mull,\alpha}$ and $R^2_{add} = S + \hat{Q}_{add,\alpha}$ respectively. For comparison, we compute the volume of an equivalent conformal prediction region without SURE-normalisation (we use the form \eqref{eq:score_multi_target} with $\Sigma(y) = A^\top A$ in the multiplicative-normalized setting). In that case, the radius squared, denoted simply by $R^2$, is constant, as there is no adaptivity w.r.t. $y$. 

Figure \ref{fig:radii} below shows box-plots summarising the distribution of the radii $R(y)$ associated to the two proposed regions, alongside the constant radius $R$ associated with the region without adaptation. Each box in Figure \ref{fig:radii} spans the range from the 25\% to 75\% quantiles, the median is highlighted in colour orange, and the whiskers indicate the 10\% to 90\% quantiles; the value $R^2$ associated with the non-adaptive region is presented as a dashed black line. We observe in Figure \ref{fig:radii} that normalization using SURE can significantly reduce the prediction set when compared to non-normalised prediction sets (recall that all sets are conformalised to accumulate the same probability mass; the SURE-normalised sets leverage adaptivity to accumulate mass from regions of higher probability and are more compact as a result). Moreover, additive normalization performs at least as good as multiplicative normalization. Especially in the MNIST experiment, where the error is relatively small and SURE is difficult to compute accurately because MC-SURE has relatively high variance, we observe a big improvement when using additive normalization.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{radii_1.pdf}
    \includegraphics[width=\textwidth]{radii_2.pdf}
    \caption{Distribution of the radius squared $R^2$ of the prediction sets, i.e., $\hat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\hat{x}(y)\|_2^2 \leq R^2\}$, for various precision levels $\alpha$. The dashed horizontal line corresponds to constant radius from not normalising.}
    \label{fig:radii}
\end{figure}




%To reduce the variability in the quantiles, we take a sufficiently large sample size $M$ such that the quantiles are practically constant. The resulting quantiles can be found in Table \ref{table:quantiles}.



% The most expensive part of Algorithm \ref{alg:one} is the divergence estimation using Equation \eqref{eq:MC-SURE}. Particularly for experiment on MNIST, which uses a relatively strong prior, the divergence is small or dominated by a small number of directions. To improve the computational cost, we can assume the divergence is zero, or at least very small, to circumvent Equation \eqref{eq:MC-SURE}. Quantiles corresponding to this zero divergence assumption are shown in Table \ref{table:quantiles}, and are generally not substantially larger than those with more accurate SURE estimation, especially for the additive score.

% Similarly for the MNIST experiment, due to the difficulty of estimating the SURE and the overall high accuracy, there are significant number negative SURE estimates. Specifically, $4.8\%$ with MC-SURE and $8.4\%$ with the zero divergence assumption, resulting in an equal number of uninformative prediction sets for the multiplicative score function. In MNIST experiment with additive scoring function and in the experiments with the other datasets, no uninformative prediction sets occurred.

% Note that in the Flower102 and DTD experiments in which the SURE can be estimated quite accurately, both proposed scoring functions perform approximately equal, whilst for the MNIST experiment, in which the SURE is more difficult to estimate, the additive scoring functions seems to perform better.

Because the proposed SURE-normalised regions adapt to $y$ and are more compact, they are also more informative. To illustrate this point, we follow the uncertainty visualisation approach of \cite{liaudat2023scalable} which progressively removes detail from $\hat{x}(y)$ until we reach the boundary of $C(y)$. This allows decomposing $\hat{x}(y)$ into an the sum of two images: an image $T(\hat{x}(y))$ that has low uncertainty, and a detail term $\hat{x}(y)-T(\hat{x}(y))$ with high uncertainty and which may vary significantly as we move across $C(y)$. There are many ways of constructing the decomposition $\hat{x}(y) = T(\hat{x}(y)) + [\hat{x}(y)-T(\hat{x}(y))]$. Similarly to \cite{liaudat2023scalable}, we adopt a construction based on a Haar wavelet representation of $\hat{x}(y)$, where we progressively remove the smallest coefficients until we reach the boundary of $C(y)$. 

Figure \ref{fig:UQ} below depicts the decompositions of $\hat{x}(y)$ obtained in this manner for four images from the MNIST deblurring experiment. For each case, we obtain three decompositions of $\hat{x}(y)$ by using our two SURE-normalised regions and the unnormalised region at level $99\%$. We observe that in all cases the uncertainty is mostly concentrated on contours, as expected for an image deblurring problem. Moreover, because the SURE-normalised regions are more informative, they lead to sparse and mild residuals $[\hat{x}(y)-T(\hat{x}(y))]$, as only mild details about $\hat{x}(y)$ have high uncertainty. Conversely, because the unnormalised regions are larger and less informative, they lead to residuals $[\hat{x}(y)-T(\hat{x}(y))]$ that are large, reflecting high uncertainty across $\hat{x}(y)$ (see bottom row of Figure 2).


\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_1.pdf}%
    \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_0.pdf}
    \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_6.pdf}%
    \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_5.pdf}

%    \includegraphics[width=\linewidth]{uq/uq_flower102_0.pdf}
    \caption{Uncertainty visualisation obtained by decomposing $\hat{x}(y)$ as a low-uncertainty image $T(\hat{x}(y))$ and a high-uncertainty residual $\hat{x}(y)-T(\hat{x}(y))$. Compact and informative regions that adapt to $y$ lead to smaller and sparse residuals, whereas large regions reflect significant uncertainty in $\hat{x}(y)$.}
    \label{fig:UQ}
\end{figure}

\section{Discussion and Conclusion}\label{sec:discussion}
This paper presented a new approach for constructing conformal prediction regions for linear imaging inverse problems. The proposed approach leverages Stein's unbiased risk estimator to construct conformal prediction regions that adapt to the observed data. This allows delivering conformal prediction sets that remain informative even in high-dimensional settings. Crucially, this allows quantifying the uncertainty in large regions of the image, unlike alternative conformal prediction approaches for imaging that are limited to regions of the size of a single pixel. The approach can be implemented in a manner that is agnostic to the image estimator considered by using the Monte Carlo Stein's unbiased risk estimator. Furthermore, this approach can be implemented very efficiently on a distributed system. We considered two alternative score functions to implement this strategy (multiplicative and additive normalisation). The numerical experiments suggest that these two scoring functions perform similarly for problems where the divergence of the estimator can be computed accurately. However, when the Monte Carlo estimator of this divergence exhibits high variance, then the additive scoring function generally performs better. 

Future work should explore the generalization of the proposed approach to more general observation operators $A$. In particular, when $A$ is linear and not full rank, then our proposed prediction sets are unbounded. Alternatively, the linearity of $A$ is assumed to make the prediction sets easily interpretable and computable. Stein's unbiased risk estimator does not require linearity, however computation of the divergence becomes more difficult. It would also be interesting to extend the proposed method to problems involving other noise distributions that can be tackled by using Stein's unbiased risk estimator, such as Poisson noise \cite{LUISIER2010415}, or when the noise level is uncertain \cite{tachella2024unsure}.

\bibliographystyle{IEEEtranN}
\bibliography{references}


\end{document}
