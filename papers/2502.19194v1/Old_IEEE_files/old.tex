\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[numbers]{natbib}

\begin{document}

\title{SURE-based Conformal Prediction for Uncertainty Quantification in Image Restoration Problems\\
{}
\thanks{This work was supported by Villum Foundation grant 25893 and by UKRI EPSRC grant EP/V006134/1 and EP/W007681/1.}
}


\author{\IEEEauthorblockN{Jasper M. Everink\IEEEauthorrefmark{1} and Marcelo Pereyra\IEEEauthorrefmark{2}}

\IEEEauthorblockA{\IEEEauthorrefmark{1}Technical University of Denmark, Kgs. Lyngby, Denmark}

\IEEEauthorblockA{\IEEEauthorrefmark{2}Heriot-Watt University \& Maxwell Institute for Mathematical Sciences, Edinburgh, UK }

}

\maketitle

\begin{abstract}
Most image restoration problems are not well posed, and thus may have some significant intrinsic uncertainty. Robustly quantifying the uncertainty in the solutions to such problems is important for the reliable interpretation of experimental results, especially if the reconstructed images are used as evidence in decision-making or science. Unfortunately, most image restoration methods do not quantify the uncertainty in the restored images, or provide uncertainty quantification estimates that are highly subjective, inaccurate, and not useful in practice yet. Conformal prediction has recently emerged as a powerful framework to endow a statistical estimator with uncertainty quantification capabilities. Conformal prediction is versatile and easy to apply to problems of small or moderate dimension. However, when applied to imaging problems and other high-dimensional problems, it often provides uncertainty estimates that are too loose and uninformative. In this paper, we propose a conformal prediction method tailored for linear imaging inverse problems. The proposed method leverages Stein's unbiased risk estimator to sharpen its uncertainty quantification results and scale robustly to high-dimensional settings. The approach is demonstrated though a series of numerical experiments related to image denoising and deblurring, where it is used to construct confidence regions for a wide range of different imaging methods.
\end{abstract}

\begin{IEEEkeywords}
Image processing, uncertainty quantification, conformal prediction, Stein's unbiased risk estimate
\end{IEEEkeywords}

\section{Introduction} 
Image restoration tasks often require solving an inverse problem that is ill-posed, and which can consequently involve significant uncertainty about the unobserved true image. Quantifying and characterising this uncertainty is important for applications that rely on the restored images to inform important decisions. There are several statistical frameworks available to formulate and solve uncertainty quantification problems in imaging sciences. For example, many uncertainty quantification methods for image restoration rely on the Bayesian statistical framework \cite{calvetti2018inverse}, which can be implemented by using a wide range of modelling and algorithmic approaches (see, e.g., \cite{Durmus2018,Pereyra2017,laumont2022bayesian,holden2022bayesian}). One can also consider uncertainty quantification methods based on bootstrapping (see \cite{tachella2023equivariant}), which delivers the most accurate uncertainty quantification results to date. Alternatively, when there is enough calibration data available, it is possible to perform uncertainty quantification by using conformal prediction \cite{angelopoulos2021gentle}, which is highly flexible and can be deployed in combination with any image restoration technique.

Conformal prediction has been recently successfully applied to a range of imaging problems (see, e.g., \cite{angelopoulos2022image, narnhofer2024posterior}). However, existing conformal prediction approaches for imaging focus on pixel-wise uncertainty. Therefore, the statistical guarantees provided by the conformal prediction framework only hold marginally per pixel. This is a strong limitation because decisions based on image data usually involve a many image pixels. However, scaling conformal prediction to large regions is difficult because the results become vague and uninformative. There has been some research on designing conformal prediction strategies for problems of moderate dimension (see, e.g., \cite{messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal}), but the dimensionality encountered in imaging problems is beyond the reach of these strategies. 

In this paper, we propose a method that leverages Stein's unbiased risk estimator to scale conformal prediction to high dimensional problems, so that it can be applied to image restoration. The paper is structured as follows. Section \ref{sec:background} introduces conformal prediction. Then in Section \ref{sec:method} we present our proposed method. Following on from this, Section \ref{sec:experiments} illustrates the proposed approach on image denoising and deblurring experiments. Conclusions and perspectives for future work are finally reported in Section \ref{sec:discussion}.
%\newpage
\section{Problem statement}\label{sec:background}
We consider the problem of estimating a set of likely values for an unknown image of interest $x^\star \in \mathbb{R}^n$, from some measurement $y = Ax^\star + e \in \mathbb{R}^n$ where $A \in \mathbb{R}^{n \times n}$ models deterministic instrumental aspects of the estimations problem and $e$ represents some additive error. We assume that $x^\star$ is a realisation of some random variable $X$, and $y$ is a realisation of the conditional random variable $Y|X=x^\star$. By $\hat{x}(y)$ we denote a technique to estimate $x^\star$ from $y$ (a point estimator). 

We seek to identify a region $C(Y) \in \mathbb{R}^n$ of the solution space such that 
\begin{equation}\label{predictionC}
    \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) \geq 1-\alpha\,.
\end{equation}
where we note that the probability is w.r.t. to the joint $(X,Y)$.%under new realisations of $X$ and $Y$ from repetitions of the experiment. 

For illustration, suppose that $x^\star$ is a high-resolution MRI scan of an adult brain. The random variable $X$ provides a probabilistic description of what an adult brain MRI scan ``looks like'' for a generic individual of the population, as acquired by an ideal MRI scanner with no noise or resolution limitations. The image $x^\star$ is a sample of $X$ stemming from imaging a specific member of that population with that ideal MRI scanner. The data ${y}$ represents the actual measurement obtained, which is corrupted by noise and other forms of degradation. The estimator $\hat{x}(y)$ provides an estimate of $x^\star$. The region $C(y)$ gathers a set of solutions, rather than a single point, and property \eqref{predictionC} states that, if we repeat this procedure a large number of times with different members of the popular, we should expect their respective regions $C$ to contain their respective ``true'' brain scan in at least $(1-\alpha)$\% of the cases.

Conformal prediction provides a general framework to construct the set $C$ \cite{angelopoulos2021gentle}. This is achieved by using a so-called \emph{non-conformity measure} or score function $s: \mathbb{R}^n \times \mathbb{R}^m\mapsto\mathbb{R}$. If we take the top $(1-\alpha)$-quantile $q_\alpha$ of the statistic $s(X, Y)$ and define $C(y) := \{x\in \mathbb{R}^n \,|\, s(x,y) \leq q_\alpha\}$ for all $y \in \mathbb{R}^m$, then by construction
\begin{equation*}
    \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) = \mathbb{P}_{(X, Y)}\left(s(X, Y) \leq q_\alpha \right) \geq 1-\alpha,,
\end{equation*}
for any $\alpha \in (0,1)$. Following this procedure, and given a sufficient large sample $\{x_i,y_i\}_{i=1}^M$ to calibrate $q_\alpha$, any suitable score $s$ we can be used to construct a set $C$ that contains $x$ with high probability w.r.t. the joint distribution of $(X,Y)$. 

More precisely, the split conformal prediction approach considers a training sample $\{X_i, Y_i\}_{i=1}^M$ of independent (or at least exchangeable) copies of $(X, Y)$ from which we take the empirical top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile $\hat{Q}_\alpha$ of $s(X_1,Y_1),\ldots,s(X_M,Y_M)$. Then, for a new copy $(X_{new}, Y_{new})$ of $(X,Y)$, the set $\hat{C}(Y_{new}) := \{X_{new}\in \mathbb{R}^n\,|\, s(X_{new},Y_{new}) \leq \hat{Q}_\alpha\}$ satisfies
\begin{equation}\label{eq:conformal_guarantee}
    \mathbb{P}_{(X, Y)^{l+1}}\left(X_{\text{new}} \in \hat{C}(Y_{\text{new}}) \right)  
    \geq 1-\alpha\,,
\end{equation}
and where we note that \eqref{eq:conformal_guarantee} implicitly contains a finite-sample correction because $\hat{Q}_\alpha$ is derived from a $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile; this correction vanishes as $M\rightarrow\infty$.
Please see \cite{angelopoulos2021gentle} for an excellent introduction to conformal prediction.

While, the conformal prediction framework is highly flexible, not all score functions $s(x,y)$ deliver regions that are equally useful in practice. Indeed, it is possible to construct infinitely many regions of the space $\mathbb{R}^{n\times n}$ that will contain the truth $x^\star$ and the observed data $y$ with probability at least $1-\alpha$, but some of these regions might be extremely large. This issue is particularly prominent in high-dimensional problems, where a poor choice of $s(x,y)$ will lead to a region $C(y)$ that covers most of the support of $X$. Carefully designing $s(x,y)$ is the crux to obtaining a conformal prediction set that is compact and informative. In particular, it is essential that $s(x,y)$ adapts to $y$ so that the statistic $s(X,Y)$ has low variability.

% Note that by transitioning to samples of the score distribution, we require a slightly larger quantile and the guarantee on the prediction set depends on the randomness of the new observation and the samples. Figure \ref{fig:chi_square_quantile} shows this discrepancy.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.45\textwidth]{chi_sqaure_quantiles.pdf}
%     \caption{Histogram of $\hat{Q}_{\alpha}$ for $l = 100$ with $Q_{\alpha}$ (black line) for $s(x,y) = \frac{1}{\sigma^2}\|Ax - y\|_2^2$, in which case $s(X,Y) \sim \chi_m^2$.}
%     \label{fig:chi_square_quantile}
% \end{figure}

% If the score distribution $s(X, Y)$ has a lot of variance, then the quantile $Q_\alpha$ only represents a small fraction of $(X, Y)$ samples well. Whilst if $s(X, Y)$ concentrates well around a constant value, then the score $s(X, Y)$ is very close to $Q_\alpha$ for most samples of $(X, Y)$. Therefore, conformal prediction requires a well chosen score function, i.e., the distribution $s(X, Y)$ should concentrates strongly, such that $Q_\alpha$ is close to most $s(X, Y)$. Then, the prediction sets, which are sub-level sets of $x \mapsto s(x, y)$ for fixed $y$, represents the uncertainty well. A constant score function will concentrate perfectly, but the prediction sets are trivial and therefore uninformative in practise.

% For example, in conformalized Bayesian inference, a choice for score function could be the joint distribution, i.e., $s(x, y) = \pi(x, y)$, or the posterior distribution, i.e., 
% $s(x, y) = \pi(x\,|\,y) = \frac{\pi(y\,|\,x) \pi(x)}{\int_{\mathbb{R}^{m}} \pi(y\,|\,x) \pi(x) \text{d}y}$. However, both are only guaranteed to provide prediction sets that contain the MAP estimate, as they do not take the point estimate $\hat{x}(y)$ into account. Furthermore, the former does not take the scale differences of $\pi(x, y)$ into account, whilst computing the denominator for the latter is computationally expensive.

% A common choice for single-target conformal prediction ($n=1$) is to use
% \begin{equation}\label{eq:score_single_target}
%     s(x, y) = \frac{|x-\hat{x}(y)|}{\hat{\sigma}(y)},
% \end{equation}
% where $\hat{x}(y)$ is an estimator of $x$ from $y$ and $\hat{\sigma}(y)$ is a measure of the difficulty of the estimation. The corresponding prediction set $\hat{C}(y)$ is then the interval $[\hat{x}(y)- \hat{Q}_\alpha \hat{\sigma}(y), \hat{x}(y) + \hat{Q}_\alpha\hat{\sigma}(y)]$.

Several approaches have been recently proposed to scale conformal prediction to high dimensions (see, e.g., \cite{messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal}). Of particular interest is the normalised score of the form
\begin{equation}\label{eq:score_multi_target}
\begin{split}
    s(x, y) &= \|x-\hat{x}(y)\|^2_{\Sigma(y)}\,,\\ &= \left(x-\hat{x}(y)\right)^\top \Sigma(y) \left(x-\hat{x}(y)\right)\,,
    \end{split}
    \end{equation}
for some positive definite matrix $\Sigma(y)$ of size $n \times n$, which is chosen such that $s(X, Y)$ exhibits low variability. A successful choice of $\Sigma(y)$ will lead to conformal prediction sets that are centred on $\hat{x}(y)$ and are compact in space and therefore highly informative. By construction, they satisfy Property \eqref{eq:conformal_guarantee}.

In previous work, $\Sigma(y)$ is chosen as an approximate inverse-covariance matrix. In \cite{johnstone2021conformal}, they propose to estimate this inverse-covariance matrix globally from the errors in a sample $\{x_i,y_i\}_{i=1}^M$. Because this matrix does not depend on $y$, they proposed in \cite{messoudi2022ellipsoidal} to improve this global inverse-covariance matrix using errors of the k-nearest neighbours $\{x_i,y_i\}_{i=1}^k$ of $y$. However, when extending these approaches to higher dimensional problems, this improved matrix requires a large amount of data to properly capture the local uncertainty. We propose instead to leverage the form of the estimation problem and consider constructing $y$-adaptive score functions by using Stein's unbiased risk estimate (SURE) \cite{stein1981estimation}.

\section{Proposed Method}\label{sec:method}
We propose two strategies that leverage SURE to construct a score function $s(x,y)$ that adapts to $y$ in a manner that delivers conformal prediction regions that centred on $\hat{x}(y)$, are compact in space (relative to non-adaptive regions), and satisfy \eqref{eq:conformal_guarantee}. 

Our proposed approach considers a Gaussian observation model of the form $(Y|X=x^\star) \sim \mathcal{N}(Ax^\star,\sigma^2 \mathbb{I}_n)$ with noise variance $\sigma^2 > 0$. We assume that $A$ is full rank, although possibly poorly conditioned.

For our first proposed strategy, we use 
$$
\Sigma(y) = \frac{1}{\textrm{SURE}(y)}A^\top A\,,
$$
where SURE is an estimate of the projected mean squared error $\|Ax^\star-A\hat{x}(y)\|_2^2$ where $y$ is a realisation of $Y|X=x^\star$. Following \cite{stein1981estimation}, if the estimator $\hat{x}$ is differentiable almost everywhere, then the SURE is given by  
\begin{equation}\label{eq:SURE}
 \textrm{SURE}(y) = -m\sigma^2 + \|y - A \hat{x}(y)\|_2^2 + 2\sigma^2 \text{div} \left(A \hat{x}(y)\right)\,,  
\end{equation}
%    \text{div} \left(A\hat{x}(y) &:= \sum_{j = 1}^{m}\frac{\partial A\hat{x}}{\partial y_j}(y),
where $\text{div}(\cdot)$ denotes the divergence operator, which we can estimate numerically \cite{ramani2008monte,nobel2023tractable}. Of particular interest is the Monte Carlo SURE (MC-SURE) approach \cite{ramani2008monte}, which is agnostic to the nature of the estimator $\hat{x}$: given $\epsilon > 0$ and a sequence of Rademacher random variables $\{b_i\}_{i = 1}^{K}$, the MC-SURE approximates $\text{div} \left(A \hat{x}(y)\right)$ as follows:
\begin{equation}\label{eq:MC-SURE}
\text{div} \left(A \hat{x}(y)\right) \approx \frac{1}{K}\sum_{i = 1}^{K}b_i^T \frac{(A\hat{x}(y + \epsilon b_i) - A\hat{x}(y))}{\epsilon}\,.
\end{equation}

% First, recall that can be measured using the mean squared error (MSE) $\mathbb{E}_{(X, Y)}\left[\|X - \hat{x}(Y)\|_2^2\,|\,X = x\right]$. A popular unbiased estimator for this MSE is Stein's unbiased risk estimate (SURE) \cite{stein1981estimation} given by
% \begin{equation}\label{eq:SURE}
%     \widehat{SURE}(y) &= -m\sigma^2 + \|y - \hat{x}(y)\|_2^2 + 2\sigma^2 \text{div} \hat{x}(y), \ \text{with} \\ 
%     \text{div} \hat{x}(y) &:= \sum_{j = 1}^{m}\frac{\partial \hat{x}}{\partial y_j}(y),
% \end{equation}
% and where $\text{div}$ is the divergence operator.

Levering \eqref{eq:SURE} and the form \eqref{eq:score_multi_target}, we propose the conformal prediction score 
\begin{equation}\label{eq:score_mul}
    s_{\text{mul}}(x,y) = \frac{\|Ax-A\hat{x}(y)\|_2^2}{{SURE}(y)}\, . 
\end{equation}
We refer to this strategy as a multiplicatively-normalised score because $\textrm{SURE}(y)$ appears in the denominator of \eqref{eq:score_mul}. As an alternative strategy that is more numerically stable, we propose to normalise the score in an additive manner
\begin{equation}\label{eq:score_add}
    s_{\text{add}}(x,y) = \|Ax-A\hat{x}(y)\|_2^2 - \textrm{SURE}(y)\,,
\end{equation}
which is more robust to the stochasticity of $\textrm{SURE}(y)$. We refer to this strategy as an additively-normalised score.



% For simplicity, consider $Ax = x$, such that $y \sim \mu(x, \sigma^{-2}I)$. The error of the reconstruction of $x$ by $\hat{x}(y)$ can be measured using the mean squared error (MSE) $\mathbb{E}_{(X, Y)}\left[\|X - \hat{x}(Y)\|_2^2\,|\,X = x\right]$. A popular unbiased estimator for this MSE is Stein's unbiased risk estimate (SURE) \cite{stein1981estimation} given by
% \begin{align*}
%     \widehat{SURE}(y) &= -m\sigma^2 + \|y - \hat{x}(y)\|_2^2 + 2\sigma^2 \text{div} \hat{x}(y), \ \text{with} \\ 
%     \text{div} \hat{x}(y) &:= \sum_{j = 1}^{m}\frac{\partial \hat{x}}{\partial y_j}(y),
% \end{align*}
% and where $\text{div}$ is the divergence operator.




% -adaptive score fucntion use the SURE estimate in the normalised score function \eqref{eq:score_multi_target}, particularly, for linear operators we propose to use $\Sigma(y) = \frac{1}{\widehat{SURE}(y)}A^TA$. 

% Alternatively, we propose to use the SURE estimate in additive manner. The resulting multiplicative and additive score functions are of the form:
% \begin{align}
%     s_{\text{mul}}(x,y) &:= \frac{\|Ax-A\hat{x}(y)\|_2^2}{\widehat{SURE}(y)}, \quad \text{and} \label{eq:score_mul}\\
%     s_{\text{add}}(x,y) &:= \|Ax-A\hat{x}(y)\|_2^2 - \widehat{SURE}(y).\label{eq:score_add}
% \end{align}


% The divergence of an estimator can be computer in various ways for different estimators, e.g., it can it can be computed analytically in the case of sparse regularized linear least squares \cite{tibshirani2012degrees} and non-local means \cite{van2009sure}. Alternatively, it can be estimated numerically using Monte Carlo methods like MC-SURE \cite{ramani2008monte} and SURE-CR \cite{nobel2023tractable}. Of particular interest is MC-SURE, because it considers the estimator $\hat{x}$ as a black-box. Specifically, if $\epsilon > 0$ and $\{b_i\}_{i = 1}^{K}$ is a sequence of Rademacher random variables, then the MC-SURE estimates the divergence as follows:
% \begin{equation}\label{eq:MC-SURE}
%     \widehat{\text{div}}_{MC}(y) = \frac{1}{K}\sum_{i = 1}^{K}b_i^T \frac{(\hat{x}(y + \epsilon b_i) - \hat{x}(y))}{\epsilon}.
% \end{equation}

% For general operator $A$, SURE can be applied to $y \sim \mu(Ax, \sigma^{-2}I)$, as an estimator for the MSE of the observations, i.e., estimating 
% $\mathbb{E}_{(X, Y)}\left[\|AX - A\hat{x}(Y)\|_2^2\,|\,AX = Ax\right]$ by
% \begin{equation*}
%     \widehat{SURE}(y) = -m\sigma^2 + \|y - A\hat{x}(y)\|_2^2 + 2\sigma^2 \text{div} (A \circ \hat{x})(y).
% \end{equation*}


% We propose to use the SURE estimate in the normalised score function \eqref{eq:score_multi_target}, particularly, for linear operators we propose to use $\Sigma(y) = \frac{1}{\widehat{SURE}(y)}A^TA$. Alternatively, we propose to use the SURE estimate in additive manner. The resulting multiplicative and additive score functions are of the form:

Using \eqref{eq:score_mul} and \eqref{eq:score_add} and a calibration set $\{x_i,y_i\}_{i = 1}^M$, we can construct two conformal prediction sets by computing the top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantiles
$\hat{Q}_{\text{mull},\alpha}$ and $\hat{Q}_{\text{add},\alpha}$ of $s_{\text{mul}}(X,Y)$ and $s_{\text{add}}(X,Y)$ respectively. %Note that despite being more numerically stable w.r.t. $\textrm{SURE}(y)$, $s_{\text{add}}(X,Y)$ could potentially fail to contain $\hat{x}(y)$ if $M$ is too small to produce a reliable estimate $\hat{Q}_{\text{add},\alpha}$, especially for very low values of $\alpha$. 
The proposed strategies are summarised in Algorithm \ref{alg:one} below. 

\begin{algorithm}
\caption{SURE-normalized conformal prediction}\label{alg:one}

\begin{algorithmic}[1]
\Require{Forward operator $A$, noise variance $\sigma^2$, estimator $\hat{x}$, measurement $y$, samples $\{x_i,y_i\}_{i = 1}^M$, precision $1-\alpha$} 
\Ensure{Prediction set $\hat{C}(y)$}
\Statex
\For{$i \gets 1$ to $M$}                    
    \State {$S_i \gets \textrm{SURE}(y_i)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE}}
    \If{$s_{\text{mul}}$}
        \State $s_i \gets \frac{\|Ax_i-A\hat{x}(y_i)\|_2^2}{S_i}$
    \ElsIf{$s_{\text{add}}$}
        \State $s_i \gets \|Ax_i-A\hat{x}(y_i)\|_2^2 - S_i$
    \EndIf
\EndFor

\State {$\hat{Q}_\alpha$ $\gets$ top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile of $\{s_i\}_{i = 1}^M$}

\State {$S \gets \textrm{SURE}(y)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE}}



\If{$s_{\text{mul}}$}
\State {$\hat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\hat{x}(y_{\text{new}})\|_2^2 \leq S\times \hat{Q}_\alpha\}$}
\ElsIf{$s_{\text{add}}$}
\State {$\hat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\hat{x}(y_{\text{new}})\|_2^2 \leq S + \hat{Q}_\alpha\}$}
\EndIf

\end{algorithmic}
\end{algorithm}

% If $\widehat{SURE}(y_{\text{obs}}) < 0$, then the prediction set $\left\{x\in \mathbb{R}^m\,|\, \frac{\|Ax-A\hat{x}(y_{\text{obs}})\|_2^2}{\widehat{SURE}(y_{\text{obs}})} \leq \hat{Q}_{\text{mull},\alpha}\right\}$ is the exterior of a ball and does not contain the estimate $\hat{x}(y_{\text{obs}})$. Similarly, if $\widehat{SURE}(y_{\text{obs}}) < -\hat{Q}_{\text{add},\alpha}$, then the prediction set $\left\{x\in \mathbb{R}^m\,|\, \|Ax-A\hat{x}(y_{\text{obs}})\|_2^2 - \widehat{SURE}(y_{\text{obs}}) \leq \hat{Q}_{\text{add},\alpha}\right\}$ is empty. A benefit of the additive scoring function is that these anomalous prediction sets become more unlikely when $\hat{Q}_{\text{add},\alpha}$ becomes sufficiently large, e.g., when $\alpha$ is sufficiently large. Although this can be corrected by enlarging the prediction set without losing the marginal guarantee \eqref{eq:conformal_guarantee}, the corresponding prediction sets have no useful information.

%The resulting algorithm consists of the following two steps:
%\begin{enumerate}
%    \item Estimating the SUREs for a dataset $\{x_i, y_i\}_{i=1}^{l}$ and compute the empirical score $\frac{\lceil(l+1)\alpha\rceil}{l}$-quantile $\hat{Q}_{\alpha}$.
%    \item Estimate the SURE of a new observation $y_{obs}$ and use $\hat{Q}_{\alpha}$ to construct $\hat{C}(y_{obs})$.
%\end{enumerate}
%Note that only the second step uses the new observation and the first step is almost embarrassingly parallelisable.

\section{Experiments}\label{sec:experiments}
We now illustrate the proposed conformal prediction approach by applying it to two canonical image restoration problems: image denoising and image deblurring. To show the versatility of the method, we consider the construction of conformal prediction sets for two model-driven image restoration techniques and two data-driven image restoration techniques. We conduct the following image restoration experiments:
\begin{enumerate}
    \item Denoising of images from the DTD dataset \cite{cimpoi14describing}, with noise standard deviation $\sigma = 0.05$. We consider estimators based on total-variation regularisation \cite{chambolle2004algorithm} and wavelet soft-thresholding \cite{chang2000adaptive}. \label{exp_3}   
    \item Deblurring of images from the MNIST dataset \cite{lecun2010mnist}, corrupted by a 5-by-5 box blur and noise standard deviation $\sigma = 0.05$. As estimator, we compute the posterior mean of a Bayesian image restoration model based on a variational autoencoder prior specialised for this dataset \cite{holden2022bayesian}. \label{exp_1}
    \item Deblurring of patches from the Flower102 dataset \cite{nilsback2008automated}, corrupted with a Gaussian blur with bandwidth $1$ and noise standard deviation $\sigma = 0.02$. As estimator, we use a Learned Iterative Shrinkage-Thresholding Algorithm (LISTA) specialised for this dataset \cite{gregor2010learning}. \label{exp_2}
\end{enumerate}
%Examples of these experiments are shown in Figure \ref{fig:examples}. 
For each experiment, we use Algorithm \ref{alg:one} to compute our two proposed SURE-normalised conformal prediction sets (multiplicative and additive normalisation), considering $\alpha = 0.1, 0.05, 0.01$ to obtain regions with coverage $90\%, 95\%$ and $99\%$. In all experiments, $M$ is large enough so that the variability of the sample quantiles is neglegible. %Recall that the aim is to deliver conformal prediction regions that contain $\hat{x}(y)$ and are as compact as possible, for a given coverage level. The regions contain $\hat{x}(y)$ by construction. Therefore, 
To assess the performance of the proposed methods we compare the size of the delivered regions against the size of a region that is not adaptive to the value of $y$. More precisely, we take advantage of the elliptical form of the regions and compute the radius $R(y)$ specifying the region $\hat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\hat{x}(y)\|_2^2 \leq R(y)^2\}$. For the two SURE-normalised methods, the radii squared are given by $R^2_{mull} = S\times \hat{Q}_{mull,\alpha}$ and $R^2_{add} = S + \hat{Q}_{add,\alpha}$ respectively. For comparison, we compute the volume of an equivalent conformal prediction region without SURE-normalisation (we use the form \eqref{eq:score_multi_target} with $\Sigma(y) = A^\top A$). In that case, the radius squared, denoted simply by $R^2$, is constant, as there is no adaptivity w.r.t. $y$. 

Figure \ref{fig:radii} below shows box-plots summarising the distribution of the radii $R(y)$ associated to the two proposed regions, alongside the constant radium $R$ associated with the region without adaptation. Each box in Figure \ref{fig:radii} spans the range from the 25\% to 75\% quantiles, the median is highlighted in colour red, and the whiskers indicate the 5\% to 95\% quantiles; the value $R^2$ associated with the non-adaptive region is presented as a dashed black line. We observe in Figure \ref{fig:radii} that normalization using SURE can significantly reduce the prediction set when compared to non-normalised prediction sets (recall that all sets are conformalised to accumulate the same probability mass; the SURE-normalised sets leverage adaptivity to accumulate mass from regions of higher probability and are more compact as a result). Moreover, additive normalization performs at least as good as multiplicative normalization. Especially in the MNIST experiment, where the error is relatively small and SURE is difficult to compute accurately because MC-SURE has high variance, we observe a big improvement when using additive normalization.

\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{box_plot.png}
    \caption{Distribution of the radius squared $R^2$ of the prediction sets, i.e., $\hat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\hat{x}(y)\|_2^2 \leq R^2\}$, for various precision levels $\alpha$. The dashed horizontal line corresponds to constant radius from not normalising.} %Impractical cases where the radius is zero or infinite are not considered, but only occur in the MNIST example with multiplicative scoring.}
    \label{fig:radii}
\end{figure}


% \begin{table}[]
%     \centering
%     \resizebox{0.95\columnwidth}{!}{
%     \begin{tabular}{lllll}
%     \cline{2-5}
%     \multicolumn{1}{l|}{}           & \multicolumn{2}{l|}{MC-SURE}                            & \multicolumn{2}{l|}{Zero divergence}                    \\ \hline
%     \multicolumn{1}{|l|}{MNIST}     & \multicolumn{1}{l|}{mul}  & \multicolumn{1}{l|}{add}    & \multicolumn{1}{l|}{mul}   & \multicolumn{1}{l|}{add}   \\ \hline
%     \multicolumn{1}{|l|}{90\%}      & \multicolumn{1}{l|}{1.43} & \multicolumn{1}{l|}{0.168}  & \multicolumn{1}{l|}{1.76}  & \multicolumn{1}{l|}{0.228} \\ \hline
%     \multicolumn{1}{|l|}{95\%}      & \multicolumn{1}{l|}{1.87} & \multicolumn{1}{l|}{0.207}  & \multicolumn{1}{l|}{2.58}  & \multicolumn{1}{l|}{0.274} \\ \hline
%     \multicolumn{1}{|l|}{99\%}      & \multicolumn{1}{l|}{5.69} & \multicolumn{1}{l|}{0.364}  & \multicolumn{1}{l|}{14.12} & \multicolumn{1}{l|}{0.433}     \\ \hline
%                                     &                           &                             &                            &                            \\ \cline{1-3}
%     \multicolumn{1}{|l|}{Flower102} & \multicolumn{1}{l|}{mul}  & \multicolumn{1}{l|}{add}    &                            &                            \\ \cline{1-3}
%     \multicolumn{1}{|l|}{90\%}      & \multicolumn{1}{l|}{1.14} & \multicolumn{1}{l|}{0.0832} &                            &                            \\ \cline{1-3}
%     \multicolumn{1}{|l|}{95\%}      & \multicolumn{1}{l|}{1.20} & \multicolumn{1}{l|}{0.106}  &                            &                            \\ \cline{1-3}
%     \multicolumn{1}{|l|}{99\%}      & \multicolumn{1}{l|}{1.39} & \multicolumn{1}{l|}{0.149}  &                            &                            \\ \cline{1-3}
%                                     &                           &                             &                            &                            \\ \cline{2-5} 
%     \multicolumn{1}{l|}{}           & \multicolumn{2}{l|}{Total-variation}          & \multicolumn{2}{l|}{Wavelet}                  \\ \hline
%     \multicolumn{1}{|l|}{DTD}       & \multicolumn{1}{l|}{mul}  & \multicolumn{1}{l|}{add}    & \multicolumn{1}{l|}{mul}   & \multicolumn{1}{l|}{add}   \\ \hline
%     \multicolumn{1}{|l|}{90\%}      & \multicolumn{1}{l|}{1.01} & \multicolumn{1}{l|}{4.41}   & \multicolumn{1}{l|}{1.01}  & \multicolumn{1}{l|}{3.96}  \\ \hline
%     \multicolumn{1}{|l|}{95\%}      & \multicolumn{1}{l|}{1.01} & \multicolumn{1}{l|}{5.52}   & \multicolumn{1}{l|}{1.01}  & \multicolumn{1}{l|}{5.19}  \\ \hline
%     \multicolumn{1}{|l|}{99\%}      & \multicolumn{1}{l|}{1.03} & \multicolumn{1}{l|}{9.43}   & \multicolumn{1}{l|}{1.02}  & \multicolumn{1}{l|}{7.65}  \\ \hline
%     \end{tabular}
%     }
%     \caption{The $90\%,95\%,99\%$-quantiles for the various scoring functions and problems.}
%     \label{table:quantiles}
% \end{table}



%To reduce the variability in the quantiles, we take a sufficiently large sample size $M$ such that the quantiles are practically constant. The resulting quantiles can be found in Table \ref{table:quantiles}.



% The most expensive part of Algorithm \ref{alg:one} is the divergence estimation using Equation \eqref{eq:MC-SURE}. Particularly for experiment on MNIST, which uses a relatively strong prior, the divergence is small or dominated by a small number of directions. To improve the computational cost, we can assume the divergence is zero, or at least very small, to circumvent Equation \eqref{eq:MC-SURE}. Quantiles corresponding to this zero divergence assumption are shown in Table \ref{table:quantiles}, and are generally not substantially larger than those with more accurate SURE estimation, especially for the additive score.

% Similarly for the MNIST experiment, due to the difficulty of estimating the SURE and the overall high accuracy, there are significant number negative SURE estimates. Specifically, $4.8\%$ with MC-SURE and $8.4\%$ with the zero divergence assumption, resulting in an equal number of uninformative prediction sets for the multiplicative score function. In MNIST experiment with additive scoring function and in the experiments with the other datasets, no uninformative prediction sets occurred.

% Note that in the Flower102 and DTD experiments in which the SURE can be estimated quite accurately, both proposed scoring functions perform approximately equal, whilst for the MNIST experiment, in which the SURE is more difficult to estimate, the additive scoring functions seems to perform better.

Because the proposed SURE-normalised regions adapt to $y$ and are more compact, they are also more informative. To illustrate this point, we follow the uncertainty visualisation approach of \cite{liaudat2023scalable} which progressively removes detail from $\hat{x}(y)$ until we reach the boundary of $C(y)$. This allows decomposing $\hat{x}(y)$ into an the sum of two images: an image $T(\hat{x}(y))$ that has low uncertainty, and a detail term $\hat{x}(y)-T(\hat{x}(y))$ with high uncertainty and which may vary significantly as we move across $C(y)$. There are many ways of constructing the decomposition $\hat{x}(y) = T(\hat{x}(y)) + [\hat{x}(y)-T(\hat{x}(y))]$. Similarly to \cite{liaudat2023scalable}, we adopt a construction based on a Haar wavelet representation of $\hat{x}(y)$, where we progressively remove the smallest coefficients until we reach the boundary of $C(y)$. 

Figure \ref{fig:UQ} below depicts the decompositions of $\hat{x}(y)$ obtained in this manner for four images from the MNIST deblurring experiment. For each case, we obtain three decompositions of $\hat{x}(y)$ by using our two SURE-normalised regions and the unnormalised region at level $99\%$. We observe that in all cases the uncertainty is mostly concentrated on contours, as expected for an image deblurring problem. Moreover, because the SURE-normalised regions are more informative, they lead to sparse and mild residuals $[\hat{x}(y)-T(\hat{x}(y))]$, as only mild details about $\hat{x}(y)$ have high uncertainty. Conversely, because the unnormalised regions are larger and less informative, they lead to residuals $[\hat{x}(y)-T(\hat{x}(y))]$ that are large, reflecting high uncertainty across $\hat{x}(y)$ (see bottom row of Figure 2).




% \begin{figure}
%     \centering
%     \includegraphics[width=0.7\linewidth]{examples.pdf}
%     \caption{Examples of the true image $x$, the measured image $y$ and the estimator $\hat{x}$ from the different experiments. The images from the DTD dataset are zoomed in.}
%     \label{fig:examples}
% \end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{uq/uq_MNIST_1.pdf}
    \includegraphics[width=0.9\linewidth]{uq/uq_MNIST_0.pdf}
        \includegraphics[width=0.9\linewidth]{uq/uq_MNIST_6.pdf}
        \includegraphics[width=0.9\linewidth]{uq/uq_MNIST_5.pdf}

%    \includegraphics[width=\linewidth]{uq/uq_flower102_0.pdf}
    \caption{Uncertainty visualisation obtained by decomposing $\hat{x}(y)$ as a low-uncertainty image $T(\hat{x}(y))$ and a high-uncertainty residual $\hat{x}(y)-T(\hat{x}(y))$. Compact and informative regions that adapt to $y$ lead to smaller and sparse residuals, whereas large regions reflect significant uncertainty in $\hat{x}(y)$.}
    \label{fig:UQ}
\end{figure}

%Examples of the images used are shown in Figure \ref{fig:samples_datasets}.

%To remove the additional randomness from only using a small dataset for computing the empirical quantiles, as illustrated in Figure \ref{fig:chi_square_quantile}, we use all data once to compute accurate quantiles. The $90\%, 95\%$ and $99\%$-quantiles for the various scoring functions and problems can be found in Table \ref{table:quantiles}.






\section{Conclusion}\label{sec:discussion}
This paper presented a new approach for constructing conformal prediction regions for linear imaging inverse problems. The proposed approach leverages Stein's unbiased risk estimator to construct conformal prediction regions that adapt to the observed data. This allows delivering conformal prediction sets that remain informative even in high-dimensional settings. Crucially, this allows quantifying the uncertainty in large regions of the image, unlike alternative conformal prediction approaches for imaging that are limited to regions of the size of a single pixel. Moreover, the approach can be implemented in a manner that is agnostic to the image estimator considered by using the Monte Carlo Stein's unbiased risk estimator. We considered two alternative score functions to implement this strategy  (multiplicative and additive normalisation). The numerical experiments suggest that these two scoring functions perform similarly for problems where the divergence of the estimator can be computed accurately. However, when the Monte Carlo estimator of this divergence exhibits high variance, then the additive scoring function generally performs better. 

Future work should explore the generalisation of the proposed approach to problems in which the observation operator $A$ is not full rank, as this is a main limitation of our method. It would also be interesting to extend the proposed method to problems involving other noise distributions that can be tackled by using Stein's unbiased risk estimator, such as Poisson noise \cite{LUISIER2010415}.

%Although our proposed method makes no assumptions on the image estimator, it does come with few disadvantages. A major drawback of the proposed method is that the prediction sets are limited to balls in the data space, thus the shape of the prediction sets to not depend on the data. Particularly in high-dimensional problems, we mainly get information about the uncertainty of the image as a whole, instead of obtaining local uncertainty estimates. Furthermore, we assumed the operator $A$ is full rank to guarantee that when the prediction set is pulled back into parameter space, it is bounded.

%To make the algorithm applicable to as many estimators as possible, we estimated SURE using MC-SURE \cite{ramani2008monte}, which is the main computational cost of our proposed algorithm. Whilst MC-SURE is flexible, it is not efficient when the divergence term \eqref{eq:MC-SURE} is dominated by very few directions, e.g., when using a variation autoencoder prior as in the numerical experiments, in which case the divergence term is often underestimated. Thus, great care needs to be taken to estimate SURE to sufficient accuracy with reasonable resources.
%\newpage
\bibliographystyle{IEEEtranN}
\bibliography{references}

\vspace{12pt}


\end{document}
