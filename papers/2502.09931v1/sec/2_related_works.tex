\begin{table*}[t]
    \centering
    \footnotesize
    \setlength\tabcolsep{3.5pt} % default value: 6pt
    \begin{tabular}{c|c|ccccccc|c}
    \multicolumn{2}{c|}{\multirow{2}{*}{Skip Connection Properties}}                       & UNet   & UNet++ & M2SNet & ViGUNet & CFATUNet & PVT-GCAS & GSENet & \textbf{TransGUNet} \\
    \multicolumn{2}{c|}{ } & \scriptsize{(MICCAI2016)} & \scriptsize{(DLMIA2018)} & \scriptsize{(arxiv2023)} & \scriptsize{(ISBI2023)} & \scriptsize{(CBM2024)} & \scriptsize{(WACV2024)} & \scriptsize{(BSPC2025)} & \scriptsize{\textbf{(Ours)}} \\
    \hline
    \multicolumn{2}{c|}{Full Global Dependency}  & -      & -      & -      & \cmark   & \cmark   & -       & \cmark & \cmark \\ 
    \multicolumn{2}{c|}{Cross-Scale Fusion}      & -      & \cmark & \cmark & -        & \cmark   & -       & \cmark & \cmark \\ 
    \multicolumn{2}{c|}{Non-Ambiguous Spatial Attention} & -      & -      & -      & -      & -      & -        & -        & \cmark \\ 
    \hline
    \multicolumn{1}{c|}{\multirow{4}{*}{Efficiency}} & Params        (M) & 8.2  & 34.9  & 25.3 & 2.3 & 64.6  & 25.4 & 26.9 & 25.0 \\
                                                     & FLOPs         (G) & 23.7 & 197.8 & 12.8 & 5.0 & 32.9  & 7.9 & 17.4 & 10.0 \\
                                                     & Inference Speed    (ms) & 18.6    & 26.5     & 34.9    & 25.1     & 36.0    & 17.4     & 37.5    & 19.4    \\
                                                     & Required GPU Memory    (G) & 0.4    & 1.2     & 0.6    & 3.1     & 1.0    & 0.4     & 0.5  & 0.4    \\
    \hline
    \end{tabular} 
    \caption{Comparison of skip  connection frameworks characteristics among UNet, UNet++, M2SNet, ViGUNet, CFATransUNet (CFATUNet) , PVT-GCASCADE (PVT-GCAS), GSENet, and \textbf{TransGUNet (Ours)}.}
    \label{tab:SkipConnectionEngineeringProperties}
\end{table*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figure/TransGUNet}
    \caption{(a) The overall architecture of the proposed TransGUNet mainly comprises ACS-GNN and EFS-based spatial attention (See Fig. \ref{fig:ESA_based_spatial_attention}). (b) The proposed novel skip connection framework. In this figure, we set the target resolution as $(H_{t}, W_{t}) = (\frac{H}{8}, \frac{W}{8})$. And, for convenience, we assume that $C = 4C_{r}$. (c) Overall block diagram of the proposed ACS-GNN. (d) Notation description used in this paper. This notation is also used in Fig. \ref{fig:ESA_based_spatial_attention}.}
    \label{fig:TransGUNet}
\end{figure*}

\section{Related Works}

\noindent \textbf{Skip Connection Engineering for Medical Image Segmentation.} The introduction of skip connections in UNet marked a significant milestone and made it the most widely used baseline model in medical image segmentation. However, there is still a semantic gap between the encoder and decoder, which results in suboptimal performance \cite{mahmud2021covsegnet}. This problem has driven recent efforts to refine skip connections to minimize this semantic gap. UNet++ is a representative model incorporating dense connectivity and neighbor scale features in skip connections. Additionally, MSNet \cite{zhao2021automatic} and M2SNet \cite{zhao2023m} reduce redundant features using subtraction modules to design more efficient models. Recently, transformers have been employed as skip connection modules to capture the global dependencies in medical images \cite{gao2021utnet, heidari2023hiformer}. Notably, UCTransNet \cite{wang2022uctransnet}, FCT \cite{tragakis2023fully}, and CFATransUNet \cite{wang2024cfatransunet} maintain global dependency by leveraging transformer-based skip connection frameworks. However, these models have complex architectures with more than \textbf{60M parameters}, which can be computationally expensive and inefficient. Our innovative TransGUNet addresses these challenges by utilizing cross-scale GNN with node attention and reducing the semantic gap with a significantly more efficient architecture comprising \textbf{25M parameters}. We compare the schemes and properties of various skip connection frameworks in Tab. \ref{tab:SkipConnectionEngineeringProperties} and Appendix (Fig. \ref{fig:SkipConnectionEngineeringScheme}).

\noindent \textbf{GNNs for Computer Vision.} GNNs have been traditionally employed for natural language processing \cite{kipf2016semi} and recommendation systems \cite{ying2018graph} owing to their ability to comprehend intricate relationships within datasets. Recently, in computer vision, GNNs \cite{han2022vision, han2023vision} have been actively explored to flexibly extract global dependencies and local features based on graphs, which are generalized data structures encompassing grids (CNN) and sequences (Transformer). For example, SFDGNet \cite{wang2023dynamic} extracts content-specific manipulated frequency features using GNN and comprehends complex spatial and frequency relationships. Additionally, GazeGNN \cite{wang2024gazegnn} integrates raw eye-gaze data and images into a unified representation graph for real-time disease classification. In particular, ViGUNet \cite{jiang2023vig} and PVT-GCASCADE \cite{rahman2024g} utilize GNNs to handle complex anatomical structures in medical image segmentation. Additionally, GTBA-Net \cite{xu2023graph}, TSGCNet \cite{duan20233d}, MSAGAANet \cite{wang2024multi}, TGNet \cite{zhang2025transgraphnet}, and GSENet \cite{li2025gse} tried to combine transformer and GNN for medical image segmentation. However, these models do not consider cross-scale features and lack a reliable spatial attention map. Noting these limitations, we carefully designed TransGUNet, which incorporates cross-scale features through ACS-GNN with EFS-based reliable spatial attention and fully utilizes global dependency.  