\section{Conclusion}

In this study, we proposed TransGUNet, an innovative medical image segmentation model that integrates ACS-GNN and EFS-based spatial attention. The proposed model effectively addresses the limitations of the existing models by reducing the semantic gap between the encoder and decoder, preserving crucial information without ambiguous spatial attention, and leveraging global dependencies. Through extensive experiments on six seen and eight unseen datasets, TransGUNet demonstrated superior performance and higher efficiency than the state-of-the-art models. The results of ablation study demonstrate that incorporating GNNs into skip connection engineering significantly enhances the model's ability to capture and utilize complex anatomical features. Additionally, EFS ensures that only the most informative features are considered, thereby improving the quality of spatial attention maps. Consequently, TransGUNet represents a significant advancement in medical image segmentation, offering a robust, efficient, and accurate model that can be employed in various medical applications. In future work, we will focus on optimizing the memory efficiency and explore its deployment in real-world healthcare settings.
