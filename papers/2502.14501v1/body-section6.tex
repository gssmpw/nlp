\section{Discussion}
\label{sec:discussion}

\paragraph{Imbalance of AQ Datasets}
We identified a substantial number of datasets, covering nearly the entire taxonomy of quality categories.
The two dialectically-driven dimensions (reasonableness and deliberative norms) are less represented, likely due to the reduced focus on dialogical argumentation in CA and the more recent attention to deliberation. Unfortunately but not unexpectedly, we found a very uneven representation of language. Together with the sparsity of languages comes a lack of cultural diversity. As arguments are perceived differently across cultures \cite{han1994culture, Shen2023culture}, this gap should be closed.

\paragraph{Potential Bias in Annotator Representation}
The analysis of meta-information about annotators revealed that current datasets provide little and mostly fragmentary documentation about whose perception is captured. This lack of transparency raises the question of whether existing AQ datasets facilitate models that are biased to certain populations. We argue that certain characteristics of the annotators should be openly communicated, such as demographics (while adhering to privacy regulations); providing such data statements has been long called for by \citet{bender-friedman-2018-data}, but we recognize rare application in the field of AQ.

A prime example is gender, rarely specified in the reviewed datasets. More than half of the manually annotated datasets stem from the highly homogeneous group of students and experienced researchers with a background in computational linguistics or computer science (i.e., the in-house annotators). Given that these fields remain heavily male-dominated \cite{schluter-2018-glass}, such a selection strategy may unintentionally amplify gender bias. Equal considerations apply to other demographic attributes such as education and age. We also critically point to the practice of excluding annotators for inconsistency with their peers, as it wrongly assumes that diversity is per se an error and reinforces the formation of overly homogeneous groups.

Documenting such properties more transparently goes hand in hand with a raised awareness of the impact that annotator selection can have on the whole process. This is equally important for both the perspectivist turn and the established approach of aggregated ground truth (e.g., simple majority vote can exclude underrepresented groups entirely).

\paragraph{Potentials and Challenges for the Perspectivist Turn}

We identified a handful of non-aggregated AQ datasets to be suitable for enabling perspectivist model development, whereas many other datasets are insufficient in terms of a controlled selection of annotators, the number of annotators (in total and per item), and the dataset size.

As our experiments emphasize, dataset annotation decides who is represented by the model's output. We thus deem the collection of labeling decisions from annotators representative of a specific population crucial to building reasonable models for a desired target population. Likewise, the availability of individual-level annotator attributes is of high relevance as it facilitates modeling annotators more accurately, but also the development of perspectivist models at the group level.

It is furthermore vital to reflect on the number of annotators needed to build robust models. While 2--3 annotators may seem inadequate, there is no clear threshold for an appropriate group size. This also depends on the modeling goal; whether to develop perspectivist models in the literal sense, or to apply them for other purposes, such as personalization. Additionally, the number of dataset items and their coverage per annotator is essential. If items are sparsely labeled, the dataset may not provide enough information for individual annotators, an issue that has been raised by \citet{davani-etal-2022-dealing}.

In connection to the previous point of discussion, it is also crucial to keep in mind the risk of capturing spurious correlations between annotators' backgrounds and patterns in AQ assessment. This is especially important when working with datasets that were not explicitly created for perspectivist usage (e.g., in SIGIR-19). The question of how many data points per group are needed for the robust generalization of findings is an empirical one, usually constrained by budget limits. In such cases, the consideration of linguistic patterns alongside the task phenomenon may help support results.