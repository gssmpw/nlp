\section{Conclusion}
\label{sec:conclusion}

A critical first step in developing perspectivist models for AQ assessment is suitable data. We identify several datasets as a learning ground for selected AQ categories in a non-aggregated way, while noting current shortcomings. Future datasets should (1)~{cover a diverse set of perspectives with respect to a reference population}, (2)~{collect annotator-specific attributes}, and (3)~{maintain an adequate size of total and individually labeled items}. The listed desiderata indicate that the perspectivist turn in AQ assessment requires resources to be invested in annotation quality and quantity. In this context, recent research on the potential of active learning methods for subjective NLP tasks may be relevant \cite{wang-plank-2023-actor,van-der-meer-etal-2024-annotator}.

Filling the resource gap will unlock the potential of the perspectivist turn in AQ assessment advocated in this paper. With suitable resources, future work can start leveraging the machine learning toolbox developed thus far in the perspectivist community (e.g., \citealp{davani-etal-2022-dealing,casola-etal-2023-confidence}).

Our extensive meta-information database will facilitate AQ research in general. One example is instruction-following LLMs, in which access to annotation guidelines is crucial \cite{wachsmuth-etal-2024-argument}. We make a significant contribution to this by expanding the number of publicly available guidelines,  provided as a central listing in our database.
