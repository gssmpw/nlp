\onecolumn
\newpage
\twocolumn

\section{Details of the Dataset Search}
\label{sec:review-details}

\paragraph{Search Process}
Using Google site search, we identified 238 candidate papers. Based on a review of the titles, abstracts, and a skim of the content, we excluded papers that neither introduced novel data nor addressed AQ. We filtered duplicates --- papers that introduce the same dataset --- and kept the first published paper in such cases.

Datasets come in various formats, such as machine learning corpora, user studies, or manual content analyses. Our focus is on annotated datasets initially created as resources for machine learning. We also collect extensions of these datasets, even if introduced primarily for annotation studies (i.e., extensions of the Dagstuhl-ArgQuality corpus). Additionally, we include datasets originally developed for other contexts, such as qualitative content analysis in the social sciences, if they have later been used to train machine learning models. We collect datasets that were purposefully annotated through coordinated efforts in the context of scientific work, as well as such that have been crawled from existing sources that provide some sort of annotation (e.g., online debate portals).

\paragraph{Relevance}
For a dataset (and corresponding paper) to be considered relevant, it must encode at least one category (either major or sub-category) according to the taxonomy introduced in Section \ref{sec:review}. We do not require the entire dataset to focus exclusively on AQ assessment; it is sufficient if certain dimensions of the annotation code AQ.

Some works we reviewed consider topical relevance as part of AQ, either in terms of a premise’s relevance to a conclusion (as local relevance) or an argument’s relevance to the issue at hand (as global relevance). According to the definitions we follow, local relevance focuses on ``the contribution towards the acceptance or rejection of the argument's conclusion'', while global relevance addresses the ``contribution towards the issue's resolution''. However, it is debatable whether topical relevance consistently aligns with these goals. As briefly discussed by \citet{potthast2019argument}, although the notions of relevance in information retrieval and global relevance share similarities, the authors chose to keep the concepts distinct. In our review, we similarly excluded such cases.

\paragraph{Reddit CMV (ChangeMyView)}
Several works use the Reddit CMV subreddit as a source for pre-annotated data on persuasion. Due to the at times significant overlap between these datasets, in case of duplicate content we focus on the CMV crawl that was introduced first. We include additional datasets in our database only if they (a) offer distinct value by including more recent data from the subreddit, or (b) provide further annotations of AQ for the same time span.

\paragraph{Dataset Extensions}
Nine datasets extend other AQ datasets directly by adding further samples (4), by re-annotating the same samples (3), by adding a further modality (1) or by releasing the non-aggregated version of a previously aggregated dataset release (1).


\section{Collection of Properties in the Database}
\label{sec:database-details}

We publish the results of our systematic literature review in the form of an online database to inform future research in AQ. This database solely contains meta-information on the identified datasets. Each dataset is represented as a row, while the columns contain a comprehensive set of characteristics describing the datasets.
First, we collect basic information about each dataset, namely the \textbf{dataset name}, whether the dataset is an \textbf{extension of another dataset} (\textit{extension of samples}, \textit{extension of annotators}, \textit{multimodal extension}, and \textit{non-aggregated version}), the \textbf{availability of the dataset} (\textit{online}, \textit{upon request}, \textit{not publicly available}, \textit{no indication}), --- if available online --- the \textbf{link to the resource} and \textbf{status of the link} (\textit{accessible} or \textit{not accessible}; as of August 2024), the \textbf{license}, whether the data contains \textbf{manual annotation}\footnote{We differentiate between datasets produced through coordinated manual annotation studies and those extracted from existing resources, like debate forums, where labels for certain AQ phenomena are inherently present.}, and --- in case of manual annotation --- the \textbf{availability of annotation guidelines} (\textit{online} (with reference to location), \textit{upon request}, \textit{not available in full}, \textit{not publicly available}, and \textit{no indication}).
Corresponding information on the paper that introduced the dataset is provided through \textbf{paper title}, the \textbf{paper authors}, the \textbf{year} of publication, and the \textbf{paper URL}, together with the targeted \textbf{research community} (based on the publication venue).

Going more into detail on the single datasets, we indicate the \textbf{size} of the dataset in terms of \textbf{units of annotation}, the \textbf{genre}, the \textbf{modality} (either \textit{text} or \textit{multimodal}), and the \textbf{language} represented.
In line with our goal of identifying AQ datasets, we provide a \textbf{textual description of AQ categories} contained as described in the words of the respective paper and indicate via \textbf{AQ taxonomy codes} (see Table \ref{tab:taxonomy}) which categories of the taxonomy the dataset covers.
For manual annotation datasets, we track the \textbf{aggregation method} that was used to form an aggregated ground truth (in case of aggregated ground truth datasets), the inter-annotator-agreement through \textbf{IAA score} and \textbf{IAA measure}, and whether there is a \textbf{non-aggregated version} available (\textit{no}, \textit{yes (annotator-specific)}, \textit{yes (distribution-based)}, and \textit{no indication}).

For exploring whose perspectives (in terms of perceiving AQ) are represented in current datasets, we gathered details on the \textbf{selection method of annotators} from the authors' descriptions, whether they are \textbf{in-house or crowd} workers, whether they are \textbf{expert or novice} annotators, and any available \textbf{annotator attributes} provided in the associated paper or dataset. Additionally, we account for the \textbf{number of annotators per item} and the \textbf{number of annotators in total}.

We also examined the authors of the arguments, referred to as ``argument producers''. For these producers, we give the number of distinct individuals represented in the dataset (\textbf{number of producers}) and reviewed the available socio-demographic information provided in the corresponding papers or datasets (\textbf{producer attributes}).


\section{Details of the Non-Aggregated Datasets}
\label{sec:description-non-aggr-datasets}

\paragraph{CrowDEA Ideas dataset \cite{Baba_Li_Kashima_2020}}
This Japanese-language corpus contains preference labels for solution proposals to everyday life questions. A total of 16k argument pairs were annotated by 20 different workers, drawn from a pool of 257 crowd workers (of which no further information is provided).

\paragraph{CIMT PartEval Argument Concreteness Corpus \cite{romberg-etal-2022-corpus}}
As a tool to support public institutions in Germany in evaluating citizen contributions, this dataset provides annotations on how concrete an argument is introduced. Five student annotators fully labeled a total of 1127 argument units. Acknowledging the subjectivity of the task, the dataset was explictely published in a non-aggregated way.

\paragraph{TYPIC \cite{naito-etal-2022-typic}}
To offer feedback on flaws in Japanese students' arguments, the authors took an approach that first provides diagnostic comments describing weaknesses in the arguments. These comments are then mapped to AQ criteria: local acceptability, local sufficiency, local relevance, global relevance, and global sufficiency. Four experts generated 1,082 diagnostic comments for 197 Japanese-language arguments, with each argument receiving two labels. The categorization was conducted by one to two annotators.

\paragraph{Argument Validity and Novelty Prediction Shared Task \cite{heinisch-etal-2023-architectural}}
The non-aggregated version of the dataset from the Argument Validity and Novelty Prediction Shared Task \cite{heinisch-etal-2022-overview}, co-located with the ArgMining workshop 2022, was published in later work for use in multi-annotator models. 1474 premise-conclusion pairs from English-language online debate portals come with three annotations per item, drawing from a pool of five student experts.

\paragraph{MAFALDA \cite{helwe-etal-2024-mafalda}}
The authors developed a hierarchical taxonomy of fallacies, resulting in the MAFALDA corpus, which contains 268 argumentative spans drawn from English-language news articles, social media, and political debates. Four of the authors annotated the spans, with each item receiving up to four labels.

\paragraph{UMOD dataset (User Moderation in Online Discussions) \cite{falk-etal-2024-moderation}}
The study focuses on annotating characteristics of user-driven moderation in online discussions, among them the constructiveness of such comments. The dataset, sourced from English Reddit's Change My View (CMV), contains 1,000 comment-reply pairs. Each pair was annotated by nine crowd workers, with a total of 90 workers participating. To provide a more nuanced understanding of the annotators, socio-demographic information including race, sex, age, and role) are collected too.

%%%

\paragraph{The Persuasion and Personality Corpus \cite{lukin-etal-2017-argument}}
An explicitly perspectivist corpus was introduced to investigate differences in the perception of argument effectiveness. To this end, for 637 crowd workers --- representative of the U.S population --- stance changes elicited by presented social media arguments were recorded. At the same time, Big Five personality traits were collected, alongside further socio-demographic information (age, gender, political view, education, civic engagement, religion, spirituality, employment status, and income). The resulting dataset contains 100 items, each annotated by 20 workers.

\paragraph{Webis-Editorial-Quality-18 corpus \cite{el-baff-etal-2018-challenge}}
This corpus was created for assessing AQ of news editorials. 
Resembling \citet{lukin-etal-2017-argument}, different perceptions were considered using the Big Five personality traits and the political leaning. 1000 news editorials were annotated by three liberals and three conservatives each, 24 crowd workers from the U.S. in total.

%%%

\paragraph{n.a. \cite{hunter2017empirical}}
To study the personalization of argumentation, 50 crowd workers (no further details about the workers were provided) annotated a set of 30 English-language arguments for believability, convincingness, and appeal.

\paragraph{SIGIR-19 \cite{potthast2019argument}}
A resource that codes the logical, rhetorical, and dialectical quality of arguments in the context of information retrieval. 40 student volunteers annotated 494 online debate portal arguments in English, with one annotator per item. While gender and age are indicated annotator-specific, from the paper we learn about the political leaning (80\% vote for left-wing, green parties) which may impact the perspectives of annotators.

\paragraph{argumentation attitude dataset \cite{brenneis-etal-2021-will}}
The German-language dataset was collected from a deliberation platform for political opinion-forming. A total of 946 arguments were rated in four waves based on individual conviction and argument strength. The 674 crowd workers constitute a representative selection of the German online population in terms of age, gender and education. Each argument received ratings from one to 147 individuals.
A unique feature of this dataset is that it captures not only the perception of argument effectiveness but also the writing style of the individual members of the crowd, as they contribute part of the arguments as well.

\paragraph{Dagstuhl-15512-ArgQuality \cite{wachsmuth-etal-2017-computational}}
Along with introducing their taxonomy of AQ, the authors provide a dataset: 320 English-language arguments from online debate portals were rated across 15 categories by three expert annotators.
While there is no attribution to the annotator id, distributional information about gender, education, and employment is given, providing some information about the annotators' socio-demographics.

\paragraph{Dagstuhl-15512-ArgQuality: extension 1 \cite{wachsmuth-etal-2017-argumentation}}
The same dataset was annotated by 102 crowd workers (no further details about the workers were provided), with 10 workers assigned to each argument.

\paragraph{Dagstuhl-15512-ArgQuality: extension 2 \cite{mirzakhmedova2024reliable}}
The dataset was also annotated by 108 novice in-house annotators, all undergraduate students without prior experience in computational argumentation, with up to 10 raters per argument.
\textit{Note: The official release includes a subset of annotators only, which are not uniquely identifiable.}

\paragraph{GAQCorpus \cite{lauscher-etal-2020-rhetoric}}
The authors introduced one of the largest corpora for assessing multiple key aspects of AQ. The corpus includes 5,285 arguments from diverse domains (debate forums, question-answering forums, and review forums), annotated for cogency, effectiveness, reasonableness, and overall quality. Annotation was conducted using a mix of three expert annotators and 24 crowd workers. Some items were annotated exclusively by the crowd (10 per item), others exclusively by the experts (up to three annotations per item), and a portion of the dataset was jointly annotated by both groups (up to 13 annotations per item).
\textit{Note: The corpus contains varying numbers of annotators for different parts of the data.}

\paragraph{EuropolisAQ \cite{falk-lapesa-2022-scaling}}
The dataset contains 513 transcribed speeches from a transnational deliberative poll. It builds on the Europolis corpus \cite{Gerber_Baechtiger_Shikano_Reber_Rohr_2018}, labeled with deliberative norms, and extends it with annotations of the other dimensions of AQ, namely cogency, effectiveness, reasonableness, and overall AQ. Each item was annotated by one or both of two expert annotators. To the best of our knowledge, this is the only corpus that provides comprehensive coverage of the four major aspects of AQ according to our taxonomy --- while not all dimensions are available in non-aggregated format.

\paragraph{ArgQ! \cite{silva2021quality}}
The authors adapt the rhetorical effectiveness dimension of \citet{wachsmuth-etal-2017-computational}'s taxonomy for use with Twitter data and expert annotate 352 argumentative tweets from the Brazilian political context accordingly. Each argument contains four labels from a total of four different annotators.

\paragraph{UKPConvArg1 \cite{habernal-gurevych-2016-argument}}
The dataset consists of 16k pairwise comparisons of arguments from online debate portals with respect to their convincingness.
Each pair was annotated by five crowd workers, with about 3,900 workers participating, all from the U.S. Additionally, the workers' stance towards the discussed topic was tracked, as it could likely influence their perspective during the assessment.

\paragraph{UKPConvArg2 \cite{habernal-gurevych-2016-makes}}
In addition to the overall assessment of effectiveness in UKPConvArg1, this dataset provides a categorization into finer attributes based on textual decision rationales formulated by the individual workers in the previous annotation. The attributes give reasons for why an annotator found an argument to be convincing, covering primarily logical and rhetorical categories of the taxonomy. Each of the 70k reason units comes with 5 annotations from a pool of 776 crowd workers.

\paragraph{Essay Argument Organization Dataset \cite{persing-etal-2010-modeling}}
Targeting the automatic evaluation of persuasive essays, this study addresses the evaluation dimension of organization, which assesses how well an essay is structured to logically develop an argument.
1003 persuasive essays, written by a diverse set of English learners from 15 native languages, were rated by one to six annotators.
\textit{Note, that in this datasets there is only a distribution of annotations given per item, no attribution to unique annotator.}

\paragraph{Appropriateness Corpus \cite{ziegenbein-etal-2023-modeling}}
The authors introduce a refined definition of the subcategory ``appropriateness'' by offering a more sophisticated interpretation. Using 2,191 arguments from existing AQ corpora, they had appropriateness annotated by three crowd workers for each argument. While there is no attribution to the annotator id, distributional information about gender and mother tongue is given, providing some information about the annotators' socio-demographics.

\paragraph{UKP-InsufficientArguments \cite{stab-gurevych-2017-recognizing}}
The authors present a corpus of persuasive essays annotated for local sufficiency. For inter-annotator-agreement, 433 of the 1029 arguments were annotated by three expert annotators.

\paragraph{Webis-ArgRank-17 Dataset \cite{wachsmuth-etal-2017-pagerank}}
This dataset is on the global relevance of arguments. Mainly created automatically, it contains a manually annotated ground truth of 110 arguments annotated by seven experts from computational linguistics and information retrieval each.

\paragraph{StoryARG \cite{falk-lapesa-2023-storyarg}}
The authors developed a corpus focused on narratives and personal experiences in argumentative texts. Each argument (2451 in total) was annotated by one to four annotators, with a total of four annotators participating in the project. Distributional information on gender, education, and country of origin is provided for the annotators.

\section{Definition of Argument Quality}
\label{app:taxonomy}

\begin{table*}[ht]
\small\renewcommand{\arraystretch}{1.15}
\setlength{\tabcolsep}{2.5pt}
\centering
\begin{tabular*}{\linewidth}{p{0.20\linewidth}p{0.78\linewidth}}
\toprule 
\textbf{Category} & \textbf{Description}\\
\midrule
\bf Logical cogency & An argument is cogent if it has acceptable premises that are relevant to its conclusion and that are sufficient to draw the conclusion.\\
Local acceptability&A premise of an argument is acceptable if it is rationally worthy of being believed to be true.\\
Local relevance&A premise of an argument is relevant if it contributes to the acceptance or rejection of the argument's conclusion.\\
Local sufficiency&An argument's premises are sufficient if, together, they give enough support to make it rational to draw its conclusion.\\
\midrule
\bf Rhetorical effectiveness &Argumentation is effective if it persuades the target audience of (or corroborates agreement with) the author’s stance on the issue.\\
Clarity&Argumentation has a clear style if it uses correct and widely unambiguous language as well as if it avoids unnecessary complexity and deviation from the issue.\\
Credibility&Argumentation creates credibility if it conveys arguments and similar in a way that makes the author worthy of credence.\\
Appropriateness&Argumentation has an appropriate style if the used language supports the creation of credibility and emotions as well as if it is proportional to the issue.\\
Emotional appeal&Argumentation makes a successful emotional appeal if it creates emotions in a way that makes the target audience more open to the author’s arguments.\\
Arrangement&Argumentation is arranged properly if it presents the issue, the arguments, and its conclusion in the right order.\\
\midrule
\bf Dialectical reasonableness&Argumentation is reasonable if it contributes to the issue’s resolution in a sufficient way that is acceptable to the target audience.\\
 Global acceptability&Argumentation is acceptable if the target audience accepts both the consideration of the stated arguments for the issue and the way they are stated.\\
 Global relevance&Argumentation is relevant if it contributes to the issue’s resolution, i.e., if it states arguments or other information that help to arrive at an ultimate conclusion.\\
 Global sufficiency&Argumentation is sufficient if it adequately rebuts those counterarguments to it that can be anticipated.\\
\midrule
\bf Deliberative norms& Argumentation adheres to deliberative norms if it promotes a respectful and inclusive exchange of rational or alternative forms of argument, with the aim of reaching mutual understanding.\\
Rationality&Deliberation is rational if it is centered on arguments that are supported by solid evidence (either through facts that can be verified or through a shared understanding of moral or normative behavior), arguments and further information that are put forward in the discourse are relevant to the topic, and an informed ground for discussion is built (e.g., through providing an information base in the beginning of the discussion, or information requests by participants to make the discourse more informed). With respect to the dimensions of argumentation quality, the focus is on normatively well-reasoned arguments and not on how good these are perceived by the target audience.\\
 Interactivity&Deliberation is interactive if the participants actively engage with each other by exchanging arguments in a way where they listen to the other participants, understand their perspective, and relate to it in a substantive way (e.g., by valuing, critiquing, or countering other's arguments, or question asking).\\
 Equality&Deliberation is equal if all participants (irrespective of their background) have the same opportunity to participate by putting forward their own arguments and responding to other's claims. This dimension of deliberation quality tackles inclusiveness and accessibility.\\
 Civility&Deliberation is civil if the participants show respect to the other participants by recognizing them as equal actors in the discourse and acknowledging the value of opposing claims. Respectful interaction is regarded as a prerequisite for participants to be convincable by other opinions and to reach a consensus decision in the sense of deliberation.\\
 Common good reference&Deliberation is oriented towards the common good if arguments are justified by promoting the well-being of the community as a whole rather than serving the interests of narrow interest groups. What exactly is considered the common good can include different goals, such as achieving the best outcome for the greatest number of people or prioritizing the needs of the most disadvantaged members of society. The joint focus on a common good is regarded as a basis for participants with diverse interests to be able to convince each other.\\
 Constructiveness&Deliberation is constructive if it contributes to finding a consensus decision for the issue of discussion through actions like proposing new solutions, searching for common ground, appeals for mobilisation, or questions addressed to the community.\\
 Alternative forms of communication&In scenarios in which not all participants are able to adhere to the rigid concept of rational argumentation based on verifiable facts, other forms of communication can provide a valuable resource for good deliberation. These include storytelling, testimonies, narratives, emotional talk, casual talk, humor, or even gossip.\\
\midrule
\bf Overall quality&An overarching measure of the quality of arguments.\\
\bottomrule
\end{tabular*}
\caption{Taxonomy of argument quality. The definitions of the first three dimensions are taken verbatim from \citet{wachsmuth-etal-2017-computational}. The definitions of the last dimension are based on \citet{friess2015deliberation}.}
\label{tab:taxonomy} 
\end{table*}

Table~\ref{tab:taxonomy} shows the original definitions of all AQ dimensions considered in this work.

\section{List of AQ Datasets}
\label{sec:relevant-datasets}

Table~\ref{tab:datasets} lists the 103 datasets for AQ that we identified in our systematic literature search. 

\onecolumn

{\footnotesize
\begin{longtable}{P{4.1cm}P{1.9cm}P{3cm}P{1cm}p{4cm}}
\toprule 
\textbf{Dataset Name} & \textbf{Extension of Previous} & \textbf{Paper} & \textbf{Community} & \textbf{AQ}\\ 
\midrule
\endfirsthead
\multicolumn{5}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\midrule 
\textbf{Dataset Name} & \textbf{Extension of Previous} & \textbf{Paper} & \textbf{Community} & \textbf{AQ}\\ \hline 
\endhead
\midrule 
\multicolumn{5}{r}{{Continued on next page}} \\ 
\midrule
\endfoot
\bottomrule \\[-2.5ex]
\caption{Overview of AQ datasets, including the name of the dataset (if provided, otherwise n.a.), whether and how it extends the previously listed dataset, the publication in which the dataset was introduced, the research community targeted (NLP, AI: artificial intelligence, CA: computational argumentation, CS: computer science, HCI: human computer interaction, IR: information retrieval, SocSci: Social Sciences, Web) and the assigned categories of AQ.}
\label{tab:datasets} 
\endlastfoot
\textbf{Essay Argument Organization Dataset} && \citet{persing-etal-2010-modeling} & NLP & Arrangement\\
\textbf{n.a.} && \citet{cabrio-villata-2012-combining} & NLP & Global acceptability\\
\textbf{Essay Thesis Clarity Dataset} && \citet{persing-ng-2013-modeling} & NLP & Clarity\\
\textbf{n.a.} && \citet{xu2014identifying} & AI & Deliberative norms\\
\textbf{Essay Prompt Adherence Dataset} && \citet{persing-ng-2014-modeling} & NLP & Clarity\\
n.a. && \citet{coe2014online} & SocSci & Civility\\
\textbf{Essay Argument Strength Dataset} && \citet{persing-ng-2015-modeling} & NLP & Effectiveness\\
\textbf{Intelligence Squared Debates Corpus} && \citet{zhang-etal-2016-conversational} & NLP & Effectiveness\\
\textbf{n.a.} && \citet{niculae-danescu-niculescu-mizil-2016-conversational} & NLP & Constructiveness\\
\textbf{n.a.} && \citet{braunstain2016supporting} & IR & Local Relevance\\
\textbf{UKPConvArg1} && \citet{habernal-gurevych-2016-argument} & NLP & Effectiveness\\
\textbf{UKPConvArg2} && \citet{habernal-gurevych-2016-makes} & NLP & Local relevance, local sufficiency, clarity, credibility, appropriateness, emotional appeal, overall quality\\
\textbf{CMV} && \citet{tan2016winning} & Web & Effectiveness\\
\textbf{Webis-ArgRank-17 Dataset} && \citet{wachsmuth-etal-2017-pagerank} & NLP & Global relevance\\
\textbf{n.a.} && \citet{habernal-etal-2017-argotario} & NLP & Local sufficiency, clarity, appropriateness, global sufficiency, global relevance\\
n.a. & more samples & \citet{habernal-etal-2018-adapting} & NLP & Local sufficiency, clarity, appropriateness, global sufficiency, global relevance\\
\textbf{The Persuasion and Personality Corpus} && \citet{lukin-etal-2017-argument} & NLP & Effectiveness\\
\textbf{Dagstuhl-15512-ArgQuality} && \citet{wachsmuth-etal-2017-computational} & NLP & Cogency, local acceptability, local relevance, local sufficiency, effectiveness, clarity, credibility, appropriateness, emotional appeal, arrangement, reasonableness, global acceptability, global relevance, global sufficiency, overall quality\\
n.a. & more annotators & \citet{wachsmuth-etal-2017-argumentation} & NLP & Cogency, local acceptability, local relevance, local sufficiency, effectiveness, clarity, credibility, appropriateness, emotional appeal, arrangement, reasonableness, global acceptability, global relevance, global sufficiency, overall quality\\
n.a. & more annotators & \citet{mirzakhmedova2024reliable} & CA & Cogency, local acceptability, local relevance, local sufficiency, effectiveness, clarity, credibility, appropriateness, emotional appeal, arrangement, reasonableness, global acceptability, global relevance, global sufficiency, overall quality\\
\textbf{n.a.} && \citet{beigman-klebanov-etal-2017-detecting} & NLP & Overall quality\\
\textbf{n.a.} && \citet{hunter2017empirical} & AI & Effectiveness\\
\textbf{YNACC} && \citet{napoles-etal-2017-finding} & NLP & Overall quality\\
\textbf{UKP-InsufficientArguments} && \citet{stab-gurevych-2017-recognizing} & NLP & Local sufficiency\\
\textbf{Debate Argument Persuasiveness Data} && \citet{persing2017convince} & AI & Effectiveness\\
\textbf{CDCP} && \citet{park-cardie-2018-corpus} & NLP & Clarity\\
\textbf{n.a.} && \citet{habernal-etal-2018-name} & NLP & Appropriateness, global sufficiency\\
\textbf{Webis-Editorial-Quality-18} && \citet{el-baff-etal-2018-challenge} & NLP & Global acceptability\\
\textbf{CGA-WIKI} && \citet{zhang-etal-2018-conversations} & NLP & Appropriateness, civility\\
n.a. & more samples & \citet{chang-danescu-niculescu-mizil-2019-trouble} & NLP & Appropriateness, civility\\
\textbf{n.a.} && \citet{Gerber_Baechtiger_Shikano_Reber_Rohr_2018} & SocSci & Rationality, interactivity, civility, common good reference, alternative forms of communication\\
\textbf{Essay Argument Persuasiveness Dataset} && \citet{carlile-etal-2018-give} & NLP & Effectiveness\\
\textbf{Webis-WikiDebate-18} && \citet{al-khatib-etal-2018-modeling} &  NLP & Rationality, constructiveness\\
\textbf{DDO} && \citet{durmus-cardie-2019-corpus} & NLP & Effectiveness\\
\textbf{n.a.} && \citet{yang2019corpus} & NLP & Local acceptability\\
n.a. & more annotators & \citet{yang-etal-2019-nonsense} & NLP & Local acceptability\\
\textbf{IBM-EviConv} && \citet{gleize-etal-2019-convinced} & NLP & Effectiveness\\
\textbf{SIGIR-19} && \citet{potthast2019argument} & IR & Cogency, effectiveness, reasonableness\\
\textbf{IBM-ArgQ-Args} && \citet{toledo-etal-2019-automatic} & NLP & Overall quality\\
\textbf{IBM-ArgQ-Pairs} && \citet{toledo-etal-2019-automatic} & NLP & Overall quality\\
\textbf{Essay Thesis Strength Dataset} && \citet{ke-etal-2019-give} & NLP & Effectiveness\\
\textbf{n.a.} && \citet{potash-etal-2019-ranking} & NLP & Effectiveness\\
\textbf{n.a.} && \citet{durmus-etal-2019-role} & NLP & Global relevance\\
\textbf{CGA-CMV} && \citet{chang-danescu-niculescu-mizil-2019-trouble} & NLP & Appropriateness, civility\\
\textbf{n.a.} && \citet{atkinson-etal-2019-gets} & NLP & Effectiveness\\
\textbf{IBM-ArgQ-Rank-30kArgs} && \citet{Gretz_Friedman_Cohen-Karlik_Toledo_Lahav_Aharonov_Slonim_2020} & AI & Overall quality\\
\textbf{CrowDEA Ideas} && \citet{Baba_Li_Kashima_2020} & HCI & Overall quality\\
\textbf{n.a.} && \citet{jo-etal-2020-detecting} & NLP & Global sufficiency\\
\textbf{Webis-ArgQuality-20} && \citet{gienapp-etal-2020-efficient} & NLP & Cogency, effectiveness, reasonableness\\
\textbf{Webis-CMV-20} && \citet{al-khatib-etal-2020-exploiting} & NLP & Effectiveness\\
\textbf{Chinese-Essay-Dataset-For-Organization-Evaluation} && \citet{ijcai2020p536} & AI & Arrangement\\
\textbf{XArgMining Dataset ArgsHG} && \citet{toledo-ronen-etal-2020-multilingual} & NLP & Overall quality\\
\textbf{n.a.} && \citet{dumani2020ranking} & IR & Cogency, effectiveness, reasonableness\\
\textbf{GAQCorpus} && \citet{lauscher-etal-2020-rhetoric} & NLP & Cogency, effectiveness, reasonableness, overall quality\\
\textbf{n.a.} && \citet{sahai-etal-2021-breaking} & NLP & Local acceptability, local relevance, local sufficiency, clarity, global relevance\\
\textbf{argumentation-attitude-dataset} && \citet{brenneis-etal-2021-will} & NLP & Effectiveness\\
\textbf{WikiDisputes} && \citet{de-kock-vlachos-2021-beg} & NLP & Constructiveness\\
\textbf{GermEval 2021} && \citet{risch-etal-2021-overview} & NLP & Rationality, interactivity, civility\\
\textbf{Touché21-Argument-Retrieval-for-Controversial-Questions} && \citet{bondarenko2021touche} & IR & Effectiveness\\
\textbf{Touché21-Argument-Retrieval-for-Comparative-Questions} && \citet{bondarenko2021touche} & IR & Effectiveness\\
\textbf{ArgQ!} && \citet{silva2021quality} & NLP & Effectiveness, clarity, credibility, emotional appeal, arrangement\\
\textbf{\#meinfernsehen2021} && \citet{2022:gerlach:meinferns} & SocSci & Rationality, interactivity, civility, alternative forms of communication\\
\textbf{CIMT PartEval Argument Concreteness Corpus} && \citet{romberg-etal-2022-corpus} & NLP & Clarity\\
\textbf{Advocacy Campaign Corpus} && \citet{kornilova-etal-2022-item} & NLP & Effectiveness\\
\textbf{Webis-Persuasive-Debaters-on-Reddit-CMV-2022} && \citet{wiegmann-etal-2022-analyzing} &  NLP & Effectiveness\\
\textbf{AM2} && \citet{chen-etal-2022-argument} & NLP & Effectiveness\\
\textbf{n.a.} && \citet{musi2022fake} & SocSci & Local relevance, local sufficiency, clarity, credibility, global relevance\\
\textbf{KODIE} && \citet{heinbach2022effects} & SocSci & Rationality, interactivity, civility, alternative forms of communication\\
\textbf{ElecDeb60To16-fallacy} & & \citet{ijcai2022p575} & AI & Local acceptance, local sufficiency, appropriateness, global sufficiency\\
ElecDeb60to20 & more samples & \citet{goffredo-etal-2023-argument} & NLP & Local acceptance, local sufficiency, appropriateness, global sufficiency\\
MM-USED-fallacy & multimodality & \citet{mancini-etal-2024-multimodal} & NLP & Local acceptance, local sufficiency, appropriateness, global sufficiency\\
\textbf{Persuasive Essays - Argument Quality Dataset} && \citet{marro-etal-2022-graph} & NLP & Cogency, effectiveness, reasonableness\\
\textbf{WikiTactics} && \citet{de-kock-vlachos-2022-disagree} & NLP & Constructiveness\\
\textbf{ImageArg} && \citet{liu-etal-2022-imagearg} & NLP & Effectiveness\\
ImageArg-Shared-Task & more samples & \citet{liu-etal-2023-overview} & NLP & Effectiveness\\
\textbf{n.a.} && \citet{2022:esau:kommunikat} & SocSci & Rationality, civility, constructiveness, alternative forms of communication\\
\textbf{Logic} && \citet{jin-etal-2022-logical} & NLP & Cogency, local acceptability, local relevance, local sufficiency, clarity, appropriateness, global relevance, global sufficiency\\
\textbf{LogicClimate} && \citet{jin-etal-2022-logical} & NLP & Cogency, local acceptability, local relevance, local sufficiency, clarity, appropriateness, global relevance, global sufficiency\\
\textbf{ABMPC} && \citet{wambsganss-niklaus-2022-modeling} & NLP & Effectiveness\\
\textbf{CLIMATE} && \citet{alhindi-etal-2022-multitask} & NLP & Local relevance, local sufficiency, clarity, credibility, global sufficiency, global relevance\\
\textbf{Argument Validity and Novelty Prediction Shared Task} && \citet{heinisch-etal-2022-overview} & NLP & Local sufficiency, global relevance\\
n.a. & non-aggregated & \citet{heinisch-etal-2023-architectural} & NLP & Local sufficiency, global relevance\\
\textbf{Touché22-Argument-Retrieval-for-Controversial-Questions} && \citet{bondarenko2022touche} & IR & Effectiveness\\
\textbf{Touché22-Argument-Retrieval-for-Comparative-Questions} && \citet{bondarenko2022touche} & IR & Effectiveness\\
\textbf{EuropolisAQ} && \citet{falk-lapesa-2022-scaling} & NLP & Cogency, effectiveness, reasonableness, overall quality\\
\textbf{TYPIC} && \citet{naito-etal-2022-typic} & NLP & local acceptability, local relevance, local sufficiency, clarity, global relevance, global sufficiency\\
\textbf{ArgAnalysis35K} && \citet{joshi-etal-2023-arganalysis35k} & NLP & Overall quality\\
\textbf{n.a.} && \citet{reveilhac2023comparing} & SocSci & Deliberative norms, rationality, interactivity, civility, constructiveness, alternative forms of communication\\
\textbf{DeliData} && \citet{karadzhov2023delidata} & HCI & Constructiveness\\
\textbf{CoRe} && \citet{salamat2023raise} & IR & Effectiveness\\
\textbf{Fallacies of Appeal to Emotions Corpus} && \citet{nieto-benitez2023fallacies} & CS & Local sufficiency\\
\textbf{Appropriateness Corpus} && \citet{ziegenbein-etal-2023-modeling} & NLP & Appropriateness\\
\textbf{Touché23-Argument-Retrieval-for-Controversial-Questions} && \citet{bondarenko2023touche} & IR & Effectiveness\\
\textbf{StoryARG} && \citet{falk-lapesa-2023-storyarg} & NLP & Alternative forms of communication\\
\textbf{FALLACIES} && \citet{hong-etal-2024-closer} & NLP & Local acceptability, local relevance, local sufficiency, clarity, appropriateness, credibility, emotional appeal, global relevance, global sufficiency\\
\textbf{DARIUS} && \citet{schaller-etal-2024-darius} & NLP & Local acceptability, local relevance, clarity\\
\textbf{ICLE++} && \citet{li-ng-2024-icle} & NLP & effectiveness, clarity, arrangement\\
\textbf{MAFALDA} && \citet{helwe-etal-2024-mafalda} & NLP & Local acceptability, local relevance, local sufficiency, clarity, appropriateness, global sufficiency, global relevance\\
\textbf{MISSCI} && \citet{glockner-etal-2024-missci} & NLP & Local acceptability, local relevance, local sufficiency, clarity, global relevance\\
\textbf{UMOD} && \citet{falk-etal-2024-moderation} & NLP & Constructiveness\\
\textbf{COVID-19 Discourse Corpus} && \citet{falk-lapesa-2024-stories} & NLP & Alternative forms of communication\\
\textbf{ArgSum Dataset} && \citet{li-etal-2024-side} & NLP & Effectiveness\\
\end{longtable}}