\section*{Ethics Statement}

This paper shares the inherent ethical concerns raised by argument mining in general, and by the assessment of AQ in particular. The first concern is dual use of NLP tools developed to assess / generate persuasive arguments, which could be then employed to manipulate the public opinion. The second concern is bias that such tools may contain, leading to assess the higher quality of arguments based on spurious cues in the data.

Additionally, while perspectivism advocates for the inclusion of as many perspectives as possible, it inevitably calls for a data-greedy approach, that is, the more annotators, the better. This may come with a human cost:  it is typically achieved by crowd-sourcing, which is known to raise concerns about fair pay and treatment of the annotators. Also, the need of such expensive data collections may give an unfair advantage to highly funded researchers. Finally, the finer-grained the information about annotators is, the higher the privacy risks they are exposed to. Ideally, large-scale dataset surveys that aim at making resources aligned and comparable can enable data-greedy modeling without the need to annotate anew. 

Generally, annotator attributes must be collected in compliance with privacy regulations and with the consent of participants. Some of the datasets we reviewed were parsed from existing internet resources, with ground truth labels derived from platform users. We would like to emphasize that using any information for profiling users, especially when it may contain personally identifiable content, risks privacy violations and may raise ethical concerns.