% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@misc{tian2023ngramunsupervisedcompoundationfeature,
      title={N-Gram Unsupervised Compoundation and Feature Injection for Better Symbolic Music Understanding}, 
      author={Jinhao Tian and Zuchao Li and Jiajia Li and Ping Wang},
      year={2023},
      eprint={2312.08931},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2312.08931}, 
}
@misc{peng2023novelenergybasedmodel,
      title={A Novel Energy based Model Mechanism for Multi-modal Aspect-Based Sentiment Analysis}, 
      author={Tianshuo Peng and Zuchao Li and Ping Wang and Lefei Zhang and Hai Zhao},
      year={2023},
      eprint={2312.08084},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2312.08084}, 
}
@misc{ziqi,
      title={The Music Maestro or The Musically Challenged, A Massive Music Evaluation Benchmark for Large Language Models}, 
      author={Jiajia Li and Lu Yang and Mingni Tang and Cong Chen and Zuchao Li and Ping Wang and Hai Zhao},
      year={2024},
      eprint={2406.15885},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2406.15885}, 
}
@inproceedings{li-etal-2024-hypergraph,
    title = "Hypergraph based Understanding for Document Semantic Entity Recognition",
    author = "Li, Qiwei  and
      Li, Zuchao  and
      Wang, Ping  and
      Ai, Haojun  and
      Zhao, Hai",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.162/",
    doi = "10.18653/v1/2024.acl-long.162",
    pages = "2950--2960",
    abstract = "Semantic entity recognition is an important task in the field of visually-rich document understanding. It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content. The existing document understanding models mainly focus on entity categories while ignoring the extraction of entity boundaries. We build a novel hypergraph attention document semantic entity recognition framework, HGA, which uses hypergraph attention to focus on entity boundaries and entity categories at the same time. It can conduct a more detailed analysis of the document text representation analyzed by the upstream model and achieves a better performance of semantic information. We apply this method on the basis of GraphLayoutLM to construct a new semantic entity recognition model HGALayoutLM. Our experiment results on FUNSD, CORD, XFUND and SROIE show that our method can effectively improve the performance of semantic entity recognition tasks based on the original model. The results of HGALayoutLM on FUNSD and XFUND reach the new state-of-the-art results."
}
@misc{chatgpt,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}
@article{llama3,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@inproceedings{omniparser,
  title={OmniParser: A Unified Framework for Text Spotting Key Information Extraction and Table Recognition},
  author={Wan, Jianqiang and Song, Sibo and Yu, Wenwen and Liu, Yuliang and Cheng, Wenqing and Huang, Fei and Bai, Xiang and Yao, Cong and Yang, Zhibo},
  booktitle={CVPR},
  pages={15641--15653},
  year={2024}
}
@article{knowcoder,
  title={KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction},
  author={Li, Zixuan and Zeng, Yutao and Zuo, Yuxin and Ren, Weicheng and Liu, Wenxuan and Su, Miao and Guo, Yucan and Liu, Yantao and Li, Xiang and Hu, Zhilei and others},
  journal={arXiv preprint arXiv:2403.07969},
  year={2024}
}
@inproceedings{umie,
  title={Umie: Unified multimodal information extraction with instruction tuning},
  author={Sun, Lin and Zhang, Kai and Li, Qingyuan and Lou, Renze},
  booktitle={AAAI},
  volume={38},
  number={17},
  pages={19062--19070},
  year={2024}
}
@misc{gollie,
      title={GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction}, 
      author={Oscar Sainz and Iker Garc√≠a-Ferrero and Rodrigo Agerri and Oier Lopez de Lacalle and German Rigau and Eneko Agirre},
      year={2024},
      eprint={2310.03668},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.03668}, 
}
@misc{metaretrieval,
      title={Universal Information Extraction with Meta-Pretrained Self-Retrieval}, 
      author={Xin Cong. Bowen Yu and Mengcheng Fang and Tingwen Liu and Haiyang Yu and Zhongkai Hu and Fei Huang and Yongbin Li and Bin Wang},
      year={2023},
      eprint={2306.10444},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.10444}, 
}
@inproceedings{AdapCoAtt,
  author       = {Qi Zhang and
                  Jinlan Fu and
                  Xiaoyu Liu and
                  Xuanjing Huang},
  title        = {Adaptive Co-attention Network for Named Entity Recognition in Tweets},
  booktitle    = {AAAI},
  pages        = {5674--5681},
  year         = {2018},
  biburl       = {https://dblp.org/rec/conf/aaai/0001FLH18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{resnet,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Deep Residual Learning for Image Recognition},
  booktitle    = {IEEE},
  pages        = {770--778},
  year         = {2016},
  biburl       = {https://dblp.org/rec/conf/cvpr/HeZRS16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{visualbert,
  author       = {Liunian Harold Li and
                  Mark Yatskar and
                  Da Yin and
                  Cho{-}Jui Hsieh and
                  Kai{-}Wei Chang},
  title        = {VisualBERT: {A} Simple and Performant Baseline for Vision and Language},
  journal      = {CoRR},
  volume       = {abs/1908.03557},
  year         = {2019},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1908-03557.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ocsga,
  author       = {Zhiwei Wu and
                  Changmeng Zheng and
                  Yi Cai and
                  Junying Chen and
                  Ho{-}fung Leung and
                  Qing Li},
  title        = {Multimodal Representation with Embedded Visual Guiding Objects for
                  Named Entity Recognition in Social Media Posts},
  booktitle    = {MM},
  pages        = {1038--1046},
  year         = {2020},
  biburl       = {https://dblp.org/rec/conf/mm/WuZCCL020.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{twitter15,
    title = "Visual Attention Model for Name Tagging in Multimodal Social Media",
    author = "Lu, Di  and
      Neves, Leonardo  and
      Carvalho, Vitor  and
      Zhang, Ning  and
      Ji, Heng",
    booktitle = "ACL",
    year = "2018",
    doi = "10.18653/v1/P18-1185",
    pages = "1990--1999",
    abstract = "Everyday billions of multimodal posts containing both images and text are shared in social media sites such as Snapchat, Twitter or Instagram. This combination of image and text in a single message allows for more creative and expressive forms of communication, and has become increasingly common in such sites. This new paradigm brings new challenges for natural language understanding, as the textual component tends to be shorter, more informal, and often is only understood if combined with the visual context. In this paper, we explore the task of name tagging in multimodal social media posts. We start by creating two new multimodal datasets: the first based on Twitter posts and the second based on Snapchat captions (exclusively submitted to public and crowd-sourced stories). We then propose a novel model architecture based on Visual Attention that not only provides deeper visual understanding on the decisions of the model, but also significantly outperforms other state-of-the-art baseline methods for this task.",
}
@inproceedings{twitter17,
  author       = {Qi Zhang and
                  Jinlan Fu and
                  Xiaoyu Liu and
                  Xuanjing Huang},
  title        = {Adaptive Co-attention Network for Named Entity Recognition in Tweets},
  booktitle    = {AAAI},
  pages        = {5674--5681},
  year         = {2018},
  timestamp    = {Mon, 04 Sep 2023 16:50:21 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/0001FLH18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{lasuie,
  author       = {Hao Fei and
                  Shengqiong Wu and
                  Jingye Li and
                  Bobo Li and
                  Fei Li and
                  Libo Qin and
                  Meishan Zhang and
                  Min Zhang and
                  Tat{-}Seng Chua},
  title        = {LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware
                  Generative Language Model},
  booktitle    = {NeurIPS},
  year         = {2022},
  timestamp    = {Mon, 08 Jan 2024 16:31:25 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/0001WLLLQZZC22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "27th International Very Large Databases",
  pages = "119--128",
  year = "2001"
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  year = "1985"
}

@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  year = "1992"
}

@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  year = "2002"
}

@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  year = "1984"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Fourth National Artificial Intelligence",
  pages = "198--202",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

 @misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@inproceedings{pure,
    title = "A Frustratingly Easy Approach for Entity and Relation Extraction",
    author = "Zhong, Zexuan  and
      Chen, Danqi",
    booktitle = "NAACL",
    year = "2021",
    pages = "50--61",
}
@inproceedings{joint-event,
    title = "Joint Event Extraction via Recurrent Neural Networks",
    author = "Nguyen, Thien Huu  and
      Cho, Kyunghyun  and
      Grishman, Ralph",
    booktitle = "NAACL",
    year = "2016",
    pages = "300--309",
}
@inproceedings{ssegcn,
    title = "{SSEGCN}: Syntactic and Semantic Enhanced Graph Convolutional Network for Aspect-based Sentiment Analysis",
    author = "Zhang, Zheng  and
      Zhou, Zili  and
      Wang, Yanna",
    booktitle = "NAACL",
    year = "2022",
    pages = "4916--4925",
}
@inproceedings{j2,
    title = "Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders",
    author = "Wang, Jue  and
      Lu, Wei",
    booktitle = "EMNLP",
    year = "2020",
    pages = "1706--1721",
}
@inproceedings{ie1,
author = "Andersen, Peggy M. and Hayes, Philip J. and Huettner, Alison K. and Schmandt, Linda M. and Nirenburg, Irene B. and Weinstein, Steven P.",
title = {Automatic Extraction of Facts from Press Releases to Generate News Stories},
year = {1992},
booktitle = {ANLC},
pages = {170‚Äì177},
numpages = {8},
}
@inproceedings{hyspa,
    title = "{H}y{SPA}: Hybrid Span Generation for Scalable Text-to-Graph Extraction",
    author = "Ren, Liliang  and
      Sun, Chenkai  and
      Ji, Heng  and
      Hockenmaier, Julia",
    booktitle = "ACL-IJCNLP",
    year = "2021",
    pages = "4066--4078",
}
@inproceedings{crfie,
    title = "Modeling Instance Interactions for Joint Information Extraction with Neural High-Order Conditional Random Field",
    author = "Jia, Zixia  and
      Yan, Zhaohui  and
      Han, Wenjuan  and
      Zheng, Zilong  and
      Tu, Kewei",
    booktitle = "ACL",
    year = "2023",
    pages = "13695--13710",
}
@inproceedings{uniex,
    title = "{U}ni{EX}: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective",
    author = "Ping, Yang  and
      Lu, JunYu  and
      Gan, Ruyi  and
      Wang, Junjie  and
      Zhang, Yuxiang  and
      Zhang, Pingjian  and
      Zhang, Jiaxing",
    booktitle = "ACL",
    year = "2023",
    pages = "16424--16440",
}
@inproceedings{fsuie,
    title = "{FSUIE}: A Novel Fuzzy Span Mechanism for Universal Information Extraction",
    author = "Peng, Tianshuo  and
      Li, Zuchao  and
      Zhang, Lefei  and
      Du, Bo  and
      Zhao, Hai",
    booktitle = "ACL",
    year = "2023",
    pages = "16318--16333",
}
@inproceedings{lpt,
    title = "Prompts Can Play Lottery Tickets Well: Achieving Lifelong Information Extraction via Lottery Prompt Tuning",
    author = "Liang, Zujie  and
      Wei, Feng  and
      Jie, Yin  and
      Qian, Yuxi  and
      Hao, Zhenghong  and
      Han, Bing",
    booktitle = "ACL",
    year = "2023",
    pages = "277--292",
}
@misc{rope,
      title={RoFormer: Enhanced Transformer with Rotary Position Embedding}, 
      author={Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
      year={2023},
      eprint={2104.09864},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{docredkd,
    title = "Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation",
    author = "Tan, Qingyu  and
      He, Ruidan  and
      Bing, Lidong  and
      Ng, Hwee Tou",
    booktitle = "ACL",
    year = "2022",
    pages = "1672--1681",
}
@inproceedings{rdrop,
  author       = {Xiaobo Liang and
                  Lijun Wu and
                  Juntao Li and
                  Yue Wang and
                  Qi Meng and
                  Tao Qin and
                  Wei Chen and
                  Min Zhang and
                  Tie{-}Yan Liu},
  title        = {R-Drop: Regularized Dropout for Neural Networks},
  booktitle    = {NeurIPS},
  pages        = {10890--10905},
  year         = {2021},
  biburl       = {https://dblp.org/rec/conf/nips/LiangWLWMQCZL21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {JMLR},
  year    = {2014},
  pages   = {1929--1958}
}
@article{kd,
  author       = {Geoffrey E. Hinton and
                  Oriol Vinyals and
                  Jeffrey Dean},
  title        = {Distilling the Knowledge in a Neural Network},
  journal      = {CoRR},
  volume       = {abs/1503.02531},
  year         = {2015},
  biburl       = {https://dblp.org/rec/journals/corr/HintonVD15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{mirror,
  author       = {Tong Zhu and
                  Junfei Ren and
                  Zijian Yu and
                  Mengsong Wu and
                  Guoliang Zhang and
                  Xiaoye Qu and
                  Wenliang Chen and
                  Zhefeng Wang and
                  Baoxing Huai and
                  Min Zhang},
  title        = {Mirror: {A} Universal Framework for Various Information Extraction
                  Tasks},
  booktitle    = {EMNLP},
  pages        = {8861--8876},
  year         = {2023},
  biburl       = {https://dblp.org/rec/conf/emnlp/0002RYWZQCWHZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{mtb,
    title = "Matching the Blanks: Distributional Similarity for Relation Learning",
    author = "Baldini Soares, Livio  and
      FitzGerald, Nicholas  and
      Ling, Jeffrey  and
      Kwiatkowski, Tom",
    booktitle = "57th Annual Meeting of the ACL",
    year = "2019",
    pages = "2895--2905",
}

@article{roberta,
  author       = {Yinhan Liu and
                  Myle Ott and
                  Naman Goyal and
                  Jingfei Du and
                  Mandar Joshi and
                  Danqi Chen and
                  Omer Levy and
                  Mike Lewis and
                  Luke Zettlemoyer and
                  Veselin Stoyanov},
  title        = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal      = {CoRR},
  volume       = {abs/1907.11692},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1907.11692},
  timestamp    = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "NAACL",
    year = "2019",
    pages = "4171--4186",
}

@inproceedings{squad-v2,
    title = "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author = "Rajpurkar, Pranav  and
      Jia, Robin  and
      Liang, Percy",
    booktitle = "ACL",
    year = "2018",
    pages = "784--789",
}

@inproceedings{glue,
  author       = {Alex Wang and
                  Amanpreet Singh and
                  Julian Michael and
                  Felix Hill and
                  Omer Levy and
                  Samuel R. Bowman},
  title        = {{GLUE:} {A} Multi-Task Benchmark and Analysis Platform for Natural
                  Language Understanding},
  booktitle    = {ICLR},
  year         = {2019},
  timestamp    = {Thu, 25 Jul 2019 14:25:46 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/WangSMHLB19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hyperred,
    title = "A Dataset for Hyper-Relational Extraction and a Cube-Filling Approach",
    author = "Chia, Yew Ken  and
      Bing, Lidong  and
      Aljunied, Sharifah Mahani  and
      Si, Luo  and
      Poria, Soujanya",
    booktitle = "EMNLP",
    year = "2022",
    pages = "10114--10133",
}

@article{deberta,
  author       = {Pengcheng He and
                  Jianfeng Gao and
                  Weizhu Chen},
  title        = {DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with
                  Gradient-Disentangled Embedding Sharing},
  journal      = {CoRR},
  volume       = {abs/2111.09543},
  year         = {2021},
  eprinttype    = {arXiv},
  eprint       = {2111.09543},
  timestamp    = {Mon, 22 Nov 2021 16:44:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2111-09543.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{global_pointer,
  author       = {Jianlin Su and
                  Ahmed Murtadha and
                  Shengfeng Pan and
                  Jing Hou and
                  Jun Sun and
                  Wanwei Huang and
                  Bo Wen and
                  Yunfeng Liu},
  title        = {Global Pointer: Novel Efficient Span-based Approach for Named Entity
                  Recognition},
  journal      = {CoRR},
  volume       = {abs/2208.03054},
  year         = {2022},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2208-03054.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gelu,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchaboutnfdi
w3c valid html last up

@article{grishman_2019,
  title     = {Twenty-five years of information extraction},
  volume    = {25},
  doi       = {10.1017/S1351324919000512},
  number    = {6},
  journal   = {Nat. Lang. Eng.},
  publisher = {Cambridge University Press},
  author    = {Grishman, Ralph},
  year      = {2019},
  pages     = {677‚Äì692}
}

@inproceedings{w2ner,
  author    = {Jingye Li and
               Hao Fei and
               Jiang Liu and
               Shengqiong Wu and
               Meishan Zhang and
               Chong Teng and
               Donghong Ji and
               Fei Li},
  title     = {Unified Named Entity Recognition as Word-Word Relation Classification},
  booktitle = {AAAI},
  pages     = {10965--10973},
  year      = {2022},
  timestamp = {Tue, 12 Jul 2022 14:14:21 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/Li00WZTJL22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{instructuie,
  author       = {Xiao Wang and
                  Weikang Zhou and
                  Can Zu and
                  Han Xia and
                  Tianze Chen and
                  Yuansen Zhang and
                  Rui Zheng and
                  Junjie Ye and
                  Qi Zhang and
                  Tao Gui and
                  Jihua Kang and
                  Jingsheng Yang and
                  Siyuan Li and
                  Chunsai Du},
  title        = {InstructUIE: Multi-task Instruction Tuning for Unified Information
                  Extraction},
  journal      = {CoRR},
  volume       = {abs/2304.08085},
  year         = {2023},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2304-08085.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{rexuie,
  title      = {{RexUIE}: {A} {Recursive} {Method} with {Explicit} {Schema} {Instructor} for {Universal} {Information} {Extraction}},
  shorttitle = {{RexUIE}},
  url        = {http://arxiv.org/abs/2304.14770},
  abstract   = {Universal Information Extraction (UIE) is an area of interest due to the challenges posed by varying targets, heterogeneous structures, and demand-specific schemas. However, previous works have only achieved limited success by unifying a few tasks, such as Named Entity Recognition (NER) and Relation Extraction (RE), which fall short of being authentic UIE models particularly when extracting other general schemas such as quadruples and quintuples. Additionally, these models used an implicit structural schema instructor, which could lead to incorrect links between types, hindering the model's generalization and performance in low-resource scenarios. In this paper, we redefine the authentic UIE with a formal formulation that encompasses almost all extraction schemas. To the best of our knowledge, we are the first to introduce UIE for any kind of schemas. In addition, we propose RexUIE, which is a Recursive Method with Explicit Schema Instructor for UIE. To avoid interference between different types, we reset the position ids and attention mask matrices. RexUIE shows strong performance under both full-shot and few-shot settings and achieves State-of-the-Art results on the tasks of extracting complex schemas.},
  urldate    = {2023-05-03},
  publisher  = {arXiv},
  author     = {Liu, Chengyuan and Zhao, Fubang and Kang, Yangyang and Zhang, Jingyuan and Zhou, Xiang and Sun, Changlong and Wu, Fei and Kuang, Kun},
  year       = {2023},
  note       = {arXiv:2304.14770 [cs]
                version: 1},
  keywords   = {Computer Science - Computation and Language},
  file       = {arXiv.org Snapshot:E\:\\Books and Papers\\Zotero\\storage\\HBNVHK88\\2304.html:text/html;Liu et al_2023_RexUIE.pdf:E\:\\Books and Papers\\Zotero\\storage\\LE4PERJ4\\Liu et al_2023_RexUIE.pdf:application/pdf}
}

@inproceedings{dygiepp,
  title     = {Entity, Relation, and Event Extraction with Contextualized Span Representations},
  author    = {Wadden, David  and
               Wennberg, Ulme  and
               Luan, Yi  and
               Hajishirzi, Hannaneh},
  booktitle = {EMNLP-IJCNLP},
  year      = {2019},
  pages     = {5784--5789},
  abstract  = {We examine the capabilities of a unified, multi-task framework for three information extraction tasks: named entity recognition, relation extraction, and event extraction. Our framework (called DyGIE++) accomplishes all tasks by enumerating, refining, and scoring text spans designed to capture local (within-sentence) and global (cross-sentence) context. Our framework achieves state-of-the-art results across all tasks, on four datasets from a variety of domains. We perform experiments comparing different techniques to construct span representations. Contextualized embeddings like BERT perform well at capturing relationships among entities in the same or adjacent sentences, while dynamic span graph updates model long-range cross-sentence relationships. For instance, propagating span representations via predicted coreference links can enable the model to disambiguate challenging entity mentions. Our code is publicly available at https://github.com/dwadden/dygiepp and can be easily adapted for new tasks or datasets.}
}

@inproceedings{mac-discontinuous-ner,
  title     = {Discontinuous Named Entity Recognition as Maximal Clique Discovery},
  author    = {Wang, Yucheng  and
               Yu, Bowen  and
               Zhu, Hongsong  and
               Liu, Tingwen  and
               Yu, Nan  and
               Sun, Limin},
  booktitle = {59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Natural Language Processing (Volume 1: Long Papers)},
  year      = {2021},
  pages     = {764--774},
  abstract  = {Named entity recognition (NER) remains challenging when entity mentions can be discontinuous. Existing methods break the recognition process into several sequential steps. In training, they predict conditioned on the golden intermediate results, while at inference relying on the model output of the previous steps, which introduces exposure bias. To solve this problem, we first construct a segment graph for each sentence, in which each node denotes a segment (a continuous entity on its own, or a part of discontinuous entities), and an edge links two nodes that belong to the same entity. The nodes and edges can be generated respectively in one stage with a grid tagging scheme and learned jointly using a novel architecture named Mac. Then discontinuous NER can be reformulated as a non-parametric process of discovering maximal cliques in the graph and concatenating the spans in each clique. Experiments on three benchmarks show that our method outperforms the state-of-the-art (SOTA) results, with up to 3.5 percentage points improvement on F1, and achieves 5x speedup over the SOTA model.}
}

@inproceedings{ptpcg,
  title     = {Efficient Document-level Event Extraction via Pseudo-Trigger-aware Pruned Complete Graph},
  author    = {Zhu, Tong and Qu, Xiaoye and Chen, Wenliang and Wang, Zhefeng and Huai, Baoxing and Yuan, Nicholas and Zhang, Min},
  booktitle = {Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Lud De Raedt},
  pages     = {4552--4558},
  year      = {2022},
  note      = {Main Track},
}

@inproceedings{bart-ner,
  title     = {A Unified Generative Framework for Various {NER} Subtasks},
  author    = {Yan, Hang  and
               Gui, Tao  and
               Dai, Junqi  and
               Guo, Qipeng  and
               Zhang, Zheng  and
               Qiu, Xipeng},
  booktitle = {59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Natural Language Processing (Volume 1: Long Papers)},
  year      = {2021},
  pages     = {5808--5822},
  abstract  = {Named Entity Recognition (NER) is the task of identifying spans that represent entities in sentences. Whether the entity spans are nested or discontinuous, the NER task can be categorized into the flat NER, nested NER, and discontinuous NER subtasks. These subtasks have been mainly solved by the token-level sequence labelling or span-level classification. However, these solutions can hardly tackle the three kinds of NER subtasks concurrently. To that end, we propose to formulate the NER subtasks as an entity span sequence generation task, which can be solved by a unified sequence-to-sequence (Seq2Seq) framework. Based on our unified framework, we can leverage the pre-trained Seq2Seq model to solve all three kinds of NER subtasks without the special design of the tagging schema or ways to enumerate spans. We exploit three types of entity representations to linearize entities into a sequence. Our proposed framework is easy-to-implement and achieves state-of-the-art (SoTA) or near SoTA performance on eight English NER datasets, including two flat NER datasets, three nested NER datasets, and three discontinuous NER datasets.}
}

@inproceedings{bart-absa,
  title     = {A Unified Generative Framework for Aspect-based Sentiment Analysis},
  author    = {Yan, Hang  and
               Dai, Junqi  and
               Ji, Tuo  and
               Qiu, Xipeng  and
               Zhang, Zheng},
  booktitle = {59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Natural Language Processing (Volume 1: Long Papers)},
  year      = {2021},
  pages     = {2416--2429},
  abstract  = {Aspect-based Sentiment Analysis (ABSA) aims to identify the aspect terms, their corresponding sentiment polarities, and the opinion terms. There exist seven subtasks in ABSA. Most studies only focus on the subsets of these subtasks, which leads to various complicated ABSA models while hard to solve these subtasks in a unified framework. In this paper, we redefine every subtask target as a sequence mixed by pointer indexes and sentiment class indexes, which converts all ABSA subtasks into a unified generative formulation. Based on the unified formulation, we exploit the pre-training sequence-to-sequence model BART to solve all ABSA subtasks in an end-to-end framework. Extensive experiments on four ABSA datasets for seven subtasks demonstrate that our framework achieves substantial performance gain and provides a real unified end-to-end solution for the whole ABSA subtasks, which could benefit multiple tasks.}
}

@inproceedings{oneie,
  title     = {A Joint Neural Model for Information Extraction with Global Features},
  author    = {Lin, Ying  and
               Ji, Heng  and
               Huang, Fei  and
               Wu, Lingfei},
  booktitle = {ACL},
  year      = {2020},
  pages     = {7999--8009},
  abstract  = {Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a victim of a die event is likely to be a victim of an attack event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, OneIE, that aims to extract the globally optimal IE result as a graph from an input sentence. OneIE performs end-to-end IE in four stages: (1) Encoding a given sentence as contextualized word representations; (2) Identifying entity mentions and event triggers as nodes; (3) Computing label scores for all nodes and their pairwise links using local classifiers; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our model and achieves new state of-the-art on all subtasks. In addition, as OneIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner.}
}

@inproceedings{genie,
  title     = {{G}en{IE}: Generative Information Extraction},
  author    = {Josifoski, Martin  and
               De Cao, Nicola  and
               Peyrard, Maxime  and
               Petroni, Fabio  and
               West, Robert},
  booktitle = {NAACL},
  year      = {2022},
  pages     = {4626--4643},
  abstract  = {Structured and grounded representation of text is typically formalized by closed information extraction, the problem of extracting an exhaustive set of (subject, relation, object) triplets that are consistent with a predefined set of entities and relations from a knowledge base schema. Most existing works are pipelines prone to error accumulation, and all approaches are only applicable to unrealistically small numbers of entities and relations. We introduce GenIE (generative information extraction), the first end-to-end autoregressive formulation of closed information extraction. GenIE naturally exploits the language knowledge from the pre-trained transformer by autoregressively generating relations and entities in textual form. Thanks to a new bi-level constrained generation strategy, only triplets consistent with the predefined knowledge base schema are produced. Our experiments show that GenIE is state-of-the-art on closed information extraction, generalizes from fewer training data points than baselines, and scales to a previously unmanageable number of entities and relations. With this work, closed information extraction becomes practical in realistic scenarios, providing new opportunities for downstream tasks. Finally, this work paves the way towards a unified end-to-end approach to the core tasks of information extraction.}
}

@inproceedings{tanl,
  author    = {Giovanni Paolini and
               Ben Athiwaratkun and
               Jason Krone and
               Jie Ma and
               Alessandro Achille and
               Rishita Anubhai and
               C{\'{\i}}cero Nogueira dos Santos and
               Bing Xiang and
               Stefano Soatto},
  title     = {Structured Prediction as Translation between Augmented Natural Languages},
  booktitle = {{ICLR}},
  year      = {2021},
  url       = {https://openreview.net/forum?id=US-TP-xnXI},
  timestamp = {Wed, 28 Jul 2021 14:18:31 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/PaoliniAKMAASXS21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deepstruct,
  title     = {{D}eep{S}truct: Pretraining of Language Models for Structure Prediction},
  author    = {Wang, Chenguang  and
               Liu, Xiao  and
               Chen, Zui  and
               Hong, Haoyun  and
               Tang, Jie  and
               Song, Dawn},
  booktitle = {ACL},
  year      = {2022},
  pages     = {803--823},
  abstract  = {We introduce a method for improving the structural understanding abilities of language models. Unlike previous approaches that finetune the models with task-specific augmentation, we pretrain language models to generate structures from the text on a collection of task-agnostic corpora. Our structure pretraining enables zero-shot transfer of the learned knowledge that models have about the structure tasks. We study the performance of this approach on 28 datasets, spanning 10 structure prediction tasks including open information extraction, joint entity and relation extraction, named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, factual probe, intent detection, and dialogue state tracking. We further enhance the pretraining with the task-specific training sets. We show that a 10B parameter language model transfers non-trivially to most tasks and obtains state-of-the-art performance on 21 of 28 datasets that we evaluate. Our code and datasets will be made publicly available.}
}

@misc{devil-ee,
  title      = {The {Devil} is in the {Details}: {On} the {Pitfalls} of {Event} {Extraction} {Evaluation}},
  shorttitle = {The {Devil} is in the {Details}},
  url        = {http://arxiv.org/abs/2306.06918},
  abstract   = {Event extraction (EE) is a crucial task aiming at extracting events from texts, which includes two subtasks: event detection (ED) and event argument extraction (EAE). In this paper, we check the reliability of EE evaluations and identify three major pitfalls: (1) The data preprocessing discrepancy makes the evaluation results on the same dataset not directly comparable, but the data preprocessing details are not widely noted and specified in papers. (2) The output space discrepancy of different model paradigms makes different-paradigm EE models lack grounds for comparison and also leads to unclear mapping issues between predictions and annotations. (3) The absence of pipeline evaluation of many EAE-only works makes them hard to be directly compared with EE works and may not well reflect the model performance in real-world pipeline scenarios. We demonstrate the significant influence of these pitfalls through comprehensive meta-analyses of recent papers and empirical experiments. To avoid these pitfalls, we suggest a series of remedies, including specifying data preprocessing, standardizing outputs, and providing pipeline evaluation results. To help implement these remedies, we develop a consistent evaluation framework OMNIEVENT, which can be obtained from https://github.com/THU-KEG/OmniEvent.},
  urldate    = {2023-06-13},
  publisher  = {arXiv},
  author     = {Hao, Peng and Xiaozhi, Wang and Feng, Yao and Kaisheng, Zeng and Lei, Hou and Juanzi, Li and Zhiyuan, Liu and Weixing, Shen},
  year       = {2023},
  note       = {arXiv:2306.06918 [cs]},
  keywords   = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
  file       = {arXiv.org Snapshot:E\:\\Books and Papers\\Zotero\\storage\\NKIPM3T5\\2306.html:text/html;Full Text PDF:E\:\\Books and Papers\\Zotero\\storage\\F6J8VXS5\\Hao Á≠â - 2023 - The Devil is in the Details On the Pitfalls of Ev.pdf:application/pdf}
}

@inproceedings{uie,
  title     = {Unified Structure Generation for Universal Information Extraction},
  author    = {Lu, Yaojie  and
               Liu, Qing  and
               Dai, Dai  and
               Xiao, Xinyan  and
               Lin, Hongyu  and
               Han, Xianpei  and
               Sun, Le  and
               Wu, Hua},
  booktitle = {ACL},
  year      = {2022},
  pages     = {5755--5772},
  abstract  = {Information extraction suffers from its varying targets, heterogeneous structures, and demand-specific schemas. In this paper, we propose a unified text-to-structure generation framework, namely UIE, which can universally model different IE tasks, adaptively generate targeted structures, and collaboratively learn general IE abilities from different knowledge sources. Specifically, UIE uniformly encodes different extraction structures via a structured extraction language, adaptively generates target extractions via a schema-based prompt mechanism {--} structural schema instructor, and captures the common IE abilities via a large-scale pretrained text-to-structure model. Experiments show that UIE achieved the state-of-the-art performance on 4 IE tasks, 13 datasets, and on all supervised, low-resource, and few-shot settings for a wide range of entity, relation, event and sentiment extraction tasks and their unification. These results verified the effectiveness, universality, and transferability of UIE.}
}

# usm is published at AAAI'23, while the official proceedings didn't come out yet, use arxiv version
@article{usm,
  author     = {Jie Lou and
                Yaojie Lu and
                Dai Dai and
                Wei Jia and
                Hongyu Lin and
                Xianpei Han and
                Le Sun and
                Hua Wu},
  title      = {Universal Information Extraction as Unified Semantic Matching},
  journal    = {CoRR},
  volume     = {abs/2301.03282},
  year       = {2023},
  url        = {https://doi.org/10.48550/arXiv.2301.03282},
  doi        = {10.48550/arXiv.2301.03282},
  eprinttype = {arXiv},
  eprint     = {2301.03282},
  timestamp  = {Tue, 10 Jan 2023 15:10:12 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2301-03282.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{unimc,
  title     = {Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective},
  author    = {Yang, Ping  and
               Wang, Junjie  and
               Gan, Ruyi  and
               Zhu, Xinyu  and
               Zhang, Lin  and
               Wu, Ziwei  and
               Gao, Xinyu  and
               Zhang, Jiaxing  and
               Sakai, Tetsuya},
  booktitle = {2022 Empirical Methods in Natural Language Processing},
  year      = {2022},
  pages     = {7042--7055},
  abstract  = {We propose a new paradigm for zero-shot learners that is format agnostic, i.e., it is compatible with any format and applicable to a list of language tasks, such as text classification, commonsense reasoning, coreference resolution, and sentiment analysis. Zero-shot learning aims to train a model on a given task such that it can address new learning tasks without any additional training. Our approach converts zero-shot learning into multiple-choice tasks, avoiding problems in commonly used large-scale generative models such as FLAN. It not only adds generalization ability to models but also significantly reduces the number of parameters. Our method shares the merits of efficient training and deployment. Our approach shows state-of-the-art performance on several benchmarks and produces satisfactory results on tasks such as natural language inference and text classification. Our model achieves this success with only 235M parameters, which is substantially smaller than state-of-the-art models with billions of parameters. The code and pre-trained models are available at https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/unimc .}
}

@inproceedings{bart,
  title     = {{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author    = {Lewis, Mike  and
               Liu, Yinhan  and
               Goyal, Naman  and
               Ghazvininejad, Marjan  and
               Mohamed, Abdelrahman  and
               Levy, Omer  and
               Stoyanov, Veselin  and
               Zettlemoyer, Luke},
  booktitle = {ACL},
  year      = {2020},
  url       = {https://aclanthology.org/2020.acl-main.703},
  doi       = {10.18653/v1/2020.acl-main.703},
  pages     = {7871--7880},
  abstract  = {We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.}
}

@article{t5,
  author    = {Colin Raffel and
               Noam Shazeer and
               Adam Roberts and
               Katherine Lee and
               Sharan Narang and
               Michael Matena and
               Yanqi Zhou and
               Wei Li and
               Peter J. Liu},
  title     = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text
               Transformer},
  journal   = {J. Mach. Learn. Res.},
  volume    = {21},
  pages     = {140:1--140:67},
  year      = {2020},
  url       = {http://jmlr.org/papers/v21/20-074.html},
  timestamp = {Fri, 05 Feb 2021 15:43:41 +0100},
  biburl    = {https://dblp.org/rec/journals/jmlr/RaffelSRLNMZLL20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{glm,
  title     = {{GLM}: General Language Model Pretraining with Autoregressive Blank Infilling},
  author    = {Du, Zhengxiao  and
               Qian, Yujie  and
               Liu, Xiao  and
               Ding, Ming  and
               Qiu, Jiezhong  and
               Yang, Zhilin  and
               Tang, Jie},
  booktitle = {60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year      = {2022},
  url       = {https://aclanthology.org/2022.acl-long.26},
  doi       = {10.18653/v1/2022.acl-long.26},
  pages     = {320--335},
  abstract  = {There have been various types of pretraining architectures including autoencoding models (e.g., BERT), autoregressive models (e.g., GPT), and encoder-decoder models (e.g., T5). However, none of the pretraining frameworks performs the best for all tasks of three main categories including natural language understanding (NLU), unconditional generation, and conditional generation. We propose a General Language Model (GLM) based on autoregressive blank infilling to address this challenge. GLM improves blank filling pretraining by adding 2D positional encodings and allowing an arbitrary order to predict spans, which results in performance gains over BERT and T5 on NLU tasks. Meanwhile, GLM can be pretrained for different types of tasks by varying the number and lengths of blanks. On a wide range of tasks across NLU, conditional and unconditional generation, GLM outperforms BERT, T5, and GPT given the same model sizes and data, and achieves the best performance from a single pretrained model with 1.25{\mbox{$\times$}} parameters of BERT Large , demonstrating its generalizability to different downstream tasks.}
}

@article{flan-t5,
  author     = {Hyung Won Chung and
                Le Hou and
                Shayne Longpre and
                Barret Zoph and
                Yi Tay and
                William Fedus and
                Eric Li and
                Xuezhi Wang and
                Mostafa Dehghani and
                Siddhartha Brahma and
                Albert Webson and
                Shixiang Shane Gu and
                Zhuyun Dai and
                Mirac Suzgun and
                Xinyun Chen and
                Aakanksha Chowdhery and
                Sharan Narang and
                Gaurav Mishra and
                Adams Yu and
                Vincent Y. Zhao and
                Yanping Huang and
                Andrew M. Dai and
                Hongkun Yu and
                Slav Petrov and
                Ed H. Chi and
                Jeff Dean and
                Jacob Devlin and
                Adam Roberts and
                Denny Zhou and
                Quoc V. Le and
                Jason Wei},
  title      = {Scaling Instruction-Finetuned Language Models},
  journal    = {CoRR},
  volume     = {abs/2210.11416},
  year       = {2022},
  url        = {https://doi.org/10.48550/arXiv.2210.11416},
  doi        = {10.48550/arXiv.2210.11416},
  eprinttype = {arXiv},
  eprint     = {2210.11416},
  timestamp  = {Wed, 26 Oct 2022 08:16:51 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2210-11416.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ner-as-dp,
  title     = {Named Entity Recognition as Dependency Parsing},
  author    = {Yu, Juntao  and
               Bohnet, Bernd  and
               Poesio, Massimo},
  booktitle = {58th Annual Meeting of the Association for Computational Linguistics},
  year      = {2020},
  pages     = {6470--6476},
  abstract  = {Named Entity Recognition (NER) is a fundamental task in Natural Language Processing, concerned with identifying spans of text expressing references to entities. NER research is often focused on flat entities only (flat NER), ignoring the fact that entity references can be nested, as in [Bank of [China]] (Finkel and Manning, 2009). In this paper, we use ideas from graph-based dependency parsing to provide our model a global view on the input via a biaffine model (Dozat and Manning, 2017). The biaffine model scores pairs of start and end tokens in a sentence which we use to explore all spans, so that the model is able to predict named entities accurately. We show that the model works well for both nested and flat NER through evaluation on 8 corpora and achieving SoTA performance on all of them, with accuracy gains of up to 2.2 percentage points.}
}

@misc{ace05,
  author = {Walker, Christopher and Strassel, Stephanie and Medero, Julie and Maeda, Kazuaki},
  title  = {ACE 2005 Multilingual Training Corpus},
  year   = {2006},
  url    = {https://catalog.ldc.upenn.edu/LDC2006T06},
  doi    = {https://doi.org/10.35111/mwxc-vh88},
}

@misc{ace04,
  author = {Mitchell, Alexis and Strassel, Stephanie and Huang, Shudong and Zakhary, Ramez},
  title  = {ACE 2004 Multilingual Training Corpus},
  year   = {2005},
  url    = {https://catalog.ldc.upenn.edu/LDC2005T09},
  doi    = {https://doi.org/10.35111/8m4r-v312},
}

@inproceedings{conll03,
   author     = "Tjong Kim Sang, Erik F. and De Meulder, Fien",
   title      = "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
   booktitle  = "CoNLL",
   pages      = "142--147",
   year       = "2003",
   url        = "https://aclanthology.org/W03-0419/"
}

@inproceedings{conll04,
    title = "A Linear Programming Formulation for Global Inference in Natural Language Tasks",
    author = "Roth, Dan  and
      Yih, Wen-tau",
    booktitle = "{HLT}-{NAACL}",
    year = "2004",
    pages = "1--8",
}


@inproceedings{qu2023distantly,
  title={Distantly-supervised named entity recognition with adaptive teacher learning and fine-grained student ensemble},
  author={Qu, Xiaoye and Zeng, Jun and Liu, Daizong and Wang, Zhefeng and Huai, Baoxing and Zhou, Pan},
  booktitle={AAAI Artificial Intelligence},
  volume={37},
  pages={13501--13509},
  year={2023}
}


@article{qu2023survey,
  title={A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and Future Trends},
  author={Qu, Xiaoye and Gu, Yingjie and Xia, Qingrong and Li, Zechang and Wang, Zhefeng and Huai, Baoxing},
  journal={arXiv preprint arXiv:2302.03512},
  year={2023}
}

@article{gu2022delving,
  title={Delving deep into regularity: a simple but effective method for Chinese named entity recognition},
  author={Gu, Yingjie and Qu, Xiaoye and Wang, Zhefeng and Zheng, Yi and Huai, Baoxing and Yuan, Nicholas Jing},
  journal={arXiv preprint arXiv:2204.05544},
  year={2022}
}

@inproceedings{cheng2021hacred,
  title={HacRED: A large-scale relation extraction dataset toward hard cases in practical applications},
  author={Cheng, Qiao and Liu, Juntao and Qu, Xiaoye and Zhao, Jin and Liang, Jiaqing and Wang, Zhefeng and Huai, Baoxing and Yuan, Nicholas Jing and Xiao, Yanghua},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={2819--2831},
  year={2021}
}


@InProceedings{nyt,
author="Riedel, Sebastian
and Yao, Limin
and McCallum, Andrew",
title="Modeling Relations and Their Mentions without Labeled Text",
booktitle="ECML-PKDD",
year="2010",
pages="148--163",
abstract="Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision. Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation. Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with. We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB. We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base. When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31{\%} error reduction.",
isbn="978-3-642-15939-8"
}

@inproceedings{casie,
    title={CASIE: Extracting Cybersecurity Event Information from Text},
    abstract={We present CASIE, a system that extracts information about cybersecurity events from text and populates a semantic model, with the ultimate goal of integration into a knowledge graph of cybersecurity data. It was trained on a new corpus of 1,000 English news articles from 2017‚Äì2019 that are labeled with rich, event-based annotations and that covers both cyberattack and vulnerability-related events. Our model defines five event subtypes along with their semantic roles and 20 event-relevant argument types (e.g., file, device, software, money). CASIE uses different deep neural networks approaches with attention and can incorporate rich linguistic features and word embeddings. We have conducted experiments on each component in the event detection pipeline and the results show that each subsystem performs well.},
    booktitle={AAAI},
    author={Satyapanich, Taneeya and Ferraro, Francis and Finin, Tim},
    year={2020},
    pages={8749-8757}
}

@inproceedings{absa14,
    title = "{S}em{E}val-2014 Task 4: Aspect Based Sentiment Analysis",
    author = "Pontiki, Maria  and
      Galanis, Dimitris  and
      Pavlopoulos, John  and
      Papageorgiou, Harris  and
      Androutsopoulos, Ion  and
      Manandhar, Suresh",
    booktitle = "{S}em{E}val 2014",
    year = "2014",
    url = "https://aclanthology.org/S14-2004",
    doi = "10.3115/v1/S14-2004",
    pages = "27--35",
}

@inproceedings{absa15,
    title = "{S}em{E}val-2015 Task 12: Aspect Based Sentiment Analysis",
    author = "Pontiki, Maria  and
      Galanis, Dimitris  and
      Papageorgiou, Haris  and
      Manandhar, Suresh  and
      Androutsopoulos, Ion",
    booktitle = "{S}em{E}val 2015",
    year = "2015",
    pages = "486--495",
}

@inproceedings{absa16,
    title = "{S}em{E}val-2016 Task 5: Aspect Based Sentiment Analysis",
    author = {Pontiki, Maria  and
      Galanis, Dimitris  and
      Papageorgiou, Haris  and
      Androutsopoulos, Ion  and
      Manandhar, Suresh  and
      AL-Smadi, Mohammad  and
      Al-Ayyoub, Mahmoud  and
      Zhao, Yanyan  and
      Qin, Bing  and
      De Clercq, Orph{\'e}e  and
      Hoste, V{\'e}ronique  and
      Apidianaki, Marianna  and
      Tannier, Xavier  and
      Loukachevitch, Natalia  and
      Kotelnikov, Evgeniy  and
      Bel, Nuria  and
      Jim{\'e}nez-Zafra, Salud Mar{\'\i}a  and
      Eryi{\u{g}}it, G{\"u}l{\c{s}}en},
    booktitle = "{S}em{E}val-2016",
    year = "2016",
    url = "https://aclanthology.org/S16-1002",
    doi = "10.18653/v1/S16-1002",
    pages = "19--30",
}

@inproceedings{scierc,
    title = "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",
    author = "Luan, Yi  and
      He, Luheng  and
      Ostendorf, Mari  and
      Hajishirzi, Hannaneh",
    booktitle = "EMNLP",
    year = "2018",
    url = "https://aclanthology.org/D18-1360",
    doi = "10.18653/v1/D18-1360",
    pages = "3219--3232",
    abstract = "We introduce a multi-task setup of identifying entities, relations, and coreference clusters in scientific articles. We create SciERC, a dataset that includes annotations for all three tasks and develop a unified framework called SciIE with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.",
}

@article{cadec,
  author       = {Sarvnaz Karimi and
                  Alejandro Metke{-}Jimenez and
                  Madonna Kemp and
                  Chen Wang},
  title        = {Cadec: {A} corpus of adverse drug event annotations},
  journal      = {J. Biomed. Informatics},
  volume       = {55},
  pages        = {73--81},
  year         = {2015},
  url          = {https://doi.org/10.1016/j.jbi.2015.03.010},
  doi          = {10.1016/j.jbi.2015.03.010},
  timestamp    = {Tue, 16 Feb 2021 08:54:15 +0100},
  biburl       = {https://dblp.org/rec/journals/jbi/KarimiMKW15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mit_ner_corpus,
  author       = {Jingjing Liu and
                  Panupong Pasupat and
                  Scott Cyphers and
                  James R. Glass},
  title        = {Asgard: {A} portable architecture for multilingual dialogue systems},
  booktitle    = {{ICASSP}},
  pages        = {8386--8390},
  year         = {2013},
  url          = {https://doi.org/10.1109/ICASSP.2013.6639301},
  doi          = {10.1109/ICASSP.2013.6639301},
  timestamp    = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl       = {https://dblp.org/rec/conf/icassp/LiuPCG13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{crossner,
  author       = {Zihan Liu and
                  Yan Xu and
                  Tiezheng Yu and
                  Wenliang Dai and
                  Ziwei Ji and
                  Samuel Cahyawijaya and
                  Andrea Madotto and
                  Pascale Fung},
  title        = {CrossNER: Evaluating Cross-Domain Named Entity Recognition},
  booktitle    = {AAAI},
  pages        = {13452--13460},
  year         = {2021},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/17587},
  timestamp    = {Mon, 07 Jun 2021 11:46:04 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/Liu0YDJCMF21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{cola,
  author       = {Alex Warstadt and
                  Amanpreet Singh and
                  Samuel R. Bowman},
  title        = {Neural Network Acceptability Judgments},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {7},
  pages        = {625--641},
  year         = {2019},
  url          = {https://doi.org/10.1162/tacl\_a\_00290},
  doi          = {10.1162/tacl\_a\_00290},
  timestamp    = {Fri, 10 Jun 2022 10:35:17 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/WarstadtSB19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sst-2,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "EMNLP",
    year = "2013",
    url = "https://aclanthology.org/D13-1170",
    pages = "1631--1642",
}
@inproceedings{mnli,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "NAACL",
    year = "2018",
    url = "https://aclanthology.org/N18-1101",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
    abstract = "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
}

@inproceedings{mrpc,
  author       = {William B. Dolan and
                  Chris Brockett},
  title        = {Automatically Constructing a Corpus of Sentential Paraphrases},
  booktitle    = {IWP@IJCNLP},
  year         = {2005},
  url          = {https://aclanthology.org/I05-5002/},
  timestamp    = {Fri, 06 Aug 2021 00:41:22 +0200},
  biburl       = {https://dblp.org/rec/conf/acl-iwp/DolanB05.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{mrc_survey,
  author={Therasa, M. and Mathivanan, G.},
  booktitle={2022 6th International Computing Methodologies and Communication (ICCMC)}, 
  title={Survey of Machine Reading Comprehension Models and its Evaluation Metrics}, 
  year={2022},
  volume={},
  number={},
  pages={1006-1013},
  doi={10.1109/ICCMC53470.2022.9754070}
}

@inproceedings{biaffine,
  author       = {Timothy Dozat and
                  Christopher D. Manning},
  title        = {Deep Biaffine Attention for Neural Dependency Parsing},
  booktitle    = {5th International Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  url          = {https://openreview.net/forum?id=Hk95PK9le},
  timestamp    = {Thu, 25 Jul 2019 14:25:56 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/DozatM17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mnre,
  title={Mnre: A challenge multimodal dataset for neural relation extraction with visual evidence in social media posts},
  author={Zheng, Changmeng and Wu, Zhiwei and Feng, Junhao and Fu, Ze and Cai, Yi},
  booktitle={ICME},
  pages={1--6},
  year={2021}
}
@inproceedings{hvpnet,
    title = "Good Visual Guidance Make A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction",
    author = "Chen, Xiang  and
      Zhang, Ningyu  and
      Li, Lei  and
      Yao, Yunzhi  and
      Deng, Shumin  and
      Tan, Chuanqi  and
      Huang, Fei  and
      Si, Luo  and
      Chen, Huajun",
    booktitle = "NAACL",
    year = "2022",
    pages = "1607--1618",
    abstract = "Multimodal named entity recognition and relation extraction (MNER and MRE) is a fundamental and crucial branch in information extraction. However, existing approaches for MNER and MRE usually suffer from error sensitivity when irrelevant object images incorporated in texts. To deal with these issues, we propose a novel Hierarchical Visual Prefix fusion NeTwork (HVPNeT) for visual-enhanced entity and relation extraction, aiming to achieve more effective and robust performance. Specifically, we regard visual representation as pluggable visual prefix to guide the textual representation for error insensitive forecasting decision. We further propose a dynamic gated aggregation strategy to achieve hierarchical multi-scaled visual features as visual prefix for fusion. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our method, and achieve state-of-the-art performance.",
}
@inproceedings{adamw,
  author       = {Ilya Loshchilov and
                  Frank Hutter},
  title        = {Decoupled Weight Decay Regularization},
  booktitle    = {ICLR},
  year         = {2019},
  url          = {https://openreview.net/forum?id=Bkg6RiCqY7},
  timestamp    = {Thu, 25 Jul 2019 14:26:04 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/LoshchilovH19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{vit,
  author       = {Alexey Dosovitskiy and
                  Lucas Beyer and
                  Alexander Kolesnikov and
                  Dirk Weissenborn and
                  Xiaohua Zhai and
                  Thomas Unterthiner and
                  Mostafa Dehghani and
                  Matthias Minderer and
                  Georg Heigold and
                  Sylvain Gelly and
                  Jakob Uszkoreit and
                  Neil Houlsby},
  title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition
                  at Scale},
  booktitle    = {ICLR},
  year         = {2021},
  biburl       = {https://dblp.org/rec/conf/iclr/DosovitskiyB0WZ21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{umgf,
  author       = {Dong Zhang and
                  Suzhong Wei and
                  Shoushan Li and
                  Hanqian Wu and
                  Qiaoming Zhu and
                  Guodong Zhou},
  title        = {Multi-modal Graph Fusion for Named Entity Recognition with Targeted
                  Visual Guidance},
  booktitle    = {AAAI},
  pages        = {14347--14355},
  year         = {2021},
  biburl       = {https://dblp.org/rec/conf/aaai/ZhangWLWZZ21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{umt,
    title = "Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer",
    author = "Yu, Jianfei  and
      Jiang, Jing  and
      Yang, Li  and
      Xia, Rui",
    booktitle = "ACL",
    year = "2020",
    pages = "3342--3352",
    abstract = "In this paper, we study Multimodal Named Entity Recognition (MNER) for social media posts. Existing approaches for MNER mainly suffer from two drawbacks: (1) despite generating word-aware visual representations, their word representations are insensitive to the visual context; (2) most of them ignore the bias brought by the visual context. To tackle the first issue, we propose a multimodal interaction module to obtain both image-aware word representations and word-aware visual representations. To alleviate the visual bias, we further propose to leverage purely text-based entity span detection as an auxiliary module, and design a Unified Multimodal Transformer to guide the final predictions with the entity span predictions. Experiments show that our unified approach achieves the new state-of-the-art performance on two benchmark datasets.",
}

@inproceedings{more,
    title = "Named Entity and Relation Extraction with Multi-Modal Retrieval",
    author = "Wang, Xinyu  and
      Cai, Jiong  and
      Jiang, Yong  and
      Xie, Pengjun  and
      Tu, Kewei  and
      Lu, Wei",
    booktitle = "EMNLP",
    year = "2022",
    pages = "5925--5936",
    abstract = "Multi-modal named entity recognition (NER) and relation extraction (RE) aim to leverage relevant image information to improve the performance of NER and RE. Most existing efforts largely focused on directly extracting potentially useful information from images (such as pixel-level features, identified objects, and associated captions).However, such extraction processes may not be knowledge aware, resulting in information that may not be highly relevant.In this paper, we propose a novel Multi-modal Retrieval based framework (MoRe).MoRe contains a text retrieval module and an image-based retrieval module, which retrieve related knowledge of the input text and image in the knowledge corpus respectively.Next, the retrieval results are sent to the textual and visual models respectively for predictions.Finally, a Mixture of Experts (MoE) module combines the predictions from the two models to make the final decision.Our experiments show that both our textual model and visual model can achieve state-of-the-art performance on four multi-modal NER datasets and one multi-modal RE dataset.With MoE, the model performance can be further improved and our analysis demonstrates the benefits of integrating both textual and visual cues for such tasks.",
}

@inproceedings{mrers,
    title = "Multimodal Relation Extraction with Cross-Modal Retrieval and Synthesis",
    author = "Hu, Xuming  and
      Guo, Zhijiang  and
      Teng, Zhiyang  and
      King, Irwin  and
      Yu, Philip S.",
    booktitle = "ACL",
    year = "2023",
    pages = "303--311",
}

@article{cotpd,
  title={Chain-of-Thought Prompt Distillation for Multimodal Named Entity and Multimodal Relation Extraction},
  author={F. Chen and Yujian Feng},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.14122},
  url={https://api.semanticscholar.org/CorpusID:259252352}
}

@inproceedings{tmr,
    title = "Rethinking Multimodal Entity and Relation Extraction from a Translation Point of View",
    author = "Zheng, Changmeng  and
      Feng, Junhao  and
      Cai, Yi  and
      Wei, Xiaoyong  and
      Li, Qing",
    booktitle = "ACL",
    year = "2023",
    pages = "6810--6824",
    abstract = "We revisit the multimodal entity and relation extraction from a translation point of view. Special attention is paid on the misalignment issue in text-image datasets which may mislead the learning. We are motivated by the fact that the cross-modal misalignment is a similar problem of cross-lingual divergence issue in machine translation. The problem can then be transformed and existing solutions can be borrowed by treating a text and its paired image as the translation to each other. We implement a multimodal back-translation using diffusion-based generative models for pseudo-paralleled pairs and a divergence estimator by constructing a high-resource corpora as a bridge for low-resource learners. Fine-grained confidence scores are generated to indicate both types and degrees of alignments with which better representations are obtained. The method has been validated in the experiments by outperforming 14 state-of-the-art methods in both entity and relation extraction tasks. The source code is available at \url{https://github.com/thecharm/TMR}.",
}
@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}
