\section{Related Work}
\label{sec:relatedwork}
\vspace{-0.02in}
This section reviews energy anomaly detection in FL and discussed adversarial attacks.

\subsection{Energy Anomaly Detection and Federated Learning}
\label{sub_sec:AnomalyFL}
% \vspace{-0.05in}

Anomaly detection in energy has been an active research area due to its critical importance in detecting sub-optimal performance, device malfunction, and abnormal behavior, thereby contributing to energy efficiency. Several studies  **Zhang et al., "A Deep Learning Approach for Energy Anomaly Detection"** proposed anomaly detection based on Deep Neural Networks (DNN) due to their ability to model complex relationships. Recently, LSTMs have gained popularity in the energy domain due to their ability to capture temporal dependencies ____.

In the Natural Language Processing (NLP) domain, Transformer has been renowned for its attention mechanism and the generative capabilities utilized in diverse applications such as ChatGPT ____ . Consequently, Transformer has been adapted in various energy data studies ____ . Energy forecasting is commonly used with Transformers in self-supervised anomaly detection solutions. Such solutions examine the difference between the actual and predicted values: if this difference exceeds a threshold, the sample is deemed abnormal. **Zhang et al., "A Deep Learning Approach for Energy Anomaly Detection"** combined Transformer and K-means clustering to forecast energy consumption and detect anomalies. **Nazir et al., "Energy Forecasting Using Transformers"** also presented a Transformer-based solution focusing on energy forecasting. As LSTMs and Transformers have dominated energy anomaly detection and forecasting, our study considered these two architectures in the FL setting.

These energy forecasting/anomaly detection techniques typically train models centrally where the data sharing raises privacy and security risks. Due to its data privacy-enhancing capabilities and distributed nature, FL has been gaining popularity for various tasks in the energy domain. **Fekri et al., "Distributed Load Forecasting Using Federated Learning"** proposed a distributed load forecasting method based on FL which takes advantage of LSTM as the base learner. The same group further advanced FL-based forecasting to enable asynchronous learning in the presence of non-IDD data by introducing a novel aggregation technique ____ . Similarly, **Sater et al., "Anomaly Detection in Smart Buildings Using Federated Learning"** also integrated LSTM but combined it with multi-task learning for anomaly detection in smart buildings. The approach proposed by **Jithish et al., "Federated Learning for Anomaly Detection in Smart Grids"** for anomaly detection in smart grids is also based on FL.

The studies employing FL in the energy field made great strides in improving energy prediction and anomaly detection by enabling model training without sharing raw data. Nevertheless, they did not consider the possible presence of malicious clients in the federation. Consequently, we address this gap by examining the vulnerability of FL-based anomaly detection techniques to adversarial attacks.

\subsection{Adversarial Attacks}
\label{sub_sec:AdversarialAttack}
% \vspace{-0.05in}

Adversarial attacks are designed to deceive the ML model, leading to incorrect classifications. Often examined in computer vision, adversarial samples are created by altering the images so they still look normal to the human eye but lead the model to incorrect predictions. **Goodfellow et al., "Explaining and Harnessing Adversarial Examples"** proposed the Fast Gradient Sign Method (FGSM) that utilizes the gradients of a neural network to craft adversarial input image samples. In the FGSM approach, the gradient is calculated only once. To extend this, **Kurakin et al., "Adversarial Examples in the Physical World"** introduced the Basic Iterative Method (BIM), an iterative approach that adds perturbations to the input data. Similarly, **Madry et al., "Towards Deep Learning Models Resistant to Adversarial Attacks"** introduced another iterative attack named Projected Gradient Descent (PGD). PGD uses random initialization and a projection step which iteratively alters the input to improve the generated samples. However, these algorithms were designed for the computer vision domain, adding perturbations to images.

Considering the transferability of the mentioned attack models, **Fawaz et al., "Adversarial Attacks on Deep Neural Networks in the Time Domain"** emphasized that adversarial attacks have not been thoroughly explored for time series classification. Thus, they perturbed time series data using FGSM and BIM and compared the effectiveness of the attack models. **Mode et al., "Adversarial Attacks on Multivariate Time-Series Data"** also considered adversarial attacks on multivariate time-series data and adapted adversarial attacks from the image domain, such as FGSM and BIM, to deep learning regression models for multivariate time series forecasting. However, these studies ____ only considered centralized ML.

Overall, adversarial attacks were mostly considered in the vision domain, with a few works investigating time-series ____ but in the centralized setting. Furthermore, **Bondok et al., "Adversarial Attacks on Federated Learning"** studied attacks in an FL setting; however, they focused on theft detection while our study focuses on generic anomaly detection. Nevertheless, there is a need to understand how adversarial attacks affect anomaly detection in the FL setting. To address this gap, our work investigates the vulnerability of FL-based anomaly detection models, specifically LSTM and Transformer, to adversarial attacks of various strengths and compares their vulnerability to that of centralized training.