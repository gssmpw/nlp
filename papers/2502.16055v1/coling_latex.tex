% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{coling}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[T1]{fontenc}

\usepackage{array}

\usepackage{multirow}
\usepackage{xcolor}
\usepackage{geometry} %
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{wrapfig}
\usepackage{url}
\usepackage{xcolor}
\usepackage{algorithm} 
\usepackage{stfloats}
\usepackage{algpseudocode} 
\renewcommand{\algorithmicrequire}{ \textbf{Input:}}     %
\renewcommand{\algorithmicensure}{ \textbf{Output:}}    %

\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\pdfobjcompresslevel=0
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

%%%%%%%%% TITLE - PLEASE UPDATE
\title{MedForge: Building Medical Foundation Models Like Open Source Software Development}

\author{
\textbf{Zheling Tan}$^{1*}$, 
\textbf{Kexin Ding}$^{2*}$, 
\textbf{Jin Gao}$^{1}$, 
\textbf{Mu Zhou}$^{2}$, \\
\textbf{Dimitris Metaxas}$^{2}$, 
\textbf{Shaoting Zhang}$^{1}$,
\textbf{Dequan Wang}$^{1\dagger}$\\
$^1$Shanghai Jiao Tong University \quad
$^2$Rutgers University\\
$*$Equal contribution \quad
$\dagger$Corresponding author \\
}

% \author[1*]{\textbf{Zheling Tan}}
% \author[2*]{\textbf{Kexin Ding}}
% \author[1]{\textbf{Jin Gao}}
% \author[2]{\textbf{Mu Zhou}}
% \author[2]{\textbf{Dimitris Metaxas}}
% \author[1]{\textbf{Shaoting Zhang}}
% \author[1$\dagger$]{\textbf{Dequan Wang}}

% % \affil[1]{Georgia Institute of Technology}
% % \affil[2]{Stanford University}
% % \affil[3]{Amazon GenAI}
% % \affil[ ]{\texttt{nsinha68@gatech.edu}, \texttt{hi@vinija.ai}, \texttt{hi@aman.ai}}


% % \author[1*]{Zheling Tan}
% % \author[2*]{Kexin Ding}
% % \author[1]{Jin Gao}
% % \author[2]{Mu Zhou}
% % \author[2]{Dimitris Metaxas}
% % \author[1]{Shaoting Zhang}
% % \author[1$\dagger$]{Dequan Wang}

% \affil[1]{Shanghai Jiao Tong University}
% \affil[2]{Rutgers University}
% \affil[*]{Equal contribution}
% \affil[$\dagger$]{Corresponding author}
\begin{document}

\maketitle
%%%%%%%%% ABSTRACT
\begin{abstract}
Foundational models (FMs) have made significant strides in the healthcare domain.
Yet the data silo challenge and privacy concern remain in healthcare systems, hindering safe medical data sharing and collaborative model development among institutions. The collection and curation of scalable clinical datasets increasingly become the bottleneck for training strong FMs. In this study, we propose \textbf{Med}ical \textbf{Fo}undation Models Me\textbf{rg}ing (\textbf{MedForge}), a cooperative framework enabling a community-driven medical foundation model development, meanwhile preventing the information leakage of raw patient data and mitigating synchronization model development issues across clinical institutions. MedForge offers a bottom-up model construction mechanism by flexibly merging task-specific Low-Rank Adaptation (LoRA) modules, which can adapt to downstream tasks while retaining original model parameters. Through an asynchronous LoRA module integration scheme, the resulting composite model can progressively enhance its comprehensive performance on various clinical tasks. 
MedForge shows strong performance on multiple clinical datasets (e.g., breast cancer, lung cancer, and colon cancer) collected from different institutions. 
Our major findings highlight the value of collaborative foundation models in advancing multi-center clinical collaboration effectively and cohesively.
Our code is publicly available at \url{https://github.com/TanZheling/MedForge}.
\end{abstract}

% \footnote{Code and dataset can be found here: \href{https://github.com/neelabhsinha/vlm-selection-tasks-domains-knowledge-type}{https://github.com/neelabhsinha/vlm-selection-tasks-domains-knowledge-type}}

%\footnote{Dataset and code is shared at the following Anonymous repository link (will be changed to Github link/web page in camera-ready version): \href{https://anonymous.4open.science/r/vlm-selection-tasks-domains-knowledge-type-7668}{https://anonymous.4open.science/r/vlm-selection-tasks-domains-knowledge-type-7668}. Code and Appendix is available in Supplementary material zip (Data isn't there in zip only due to size limits).}

\input{sections/1-intro}
\input{sections/2-related}
\input{sections/4-method}
\input{sections/5-experiments}
\input{sections/6-ablation}
\input{sections/7-discussion}
\input{sections/8-conclusion}


%%%%%%%%% REFERENCES
\bibliography{egbib}

\end{document}
