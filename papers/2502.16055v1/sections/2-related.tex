\section{Related Work}
\label{sec:related}
\subsection{Collaborative Systems}
In the era of rapid growth in medical foundational models~\cite{huang2023visual,wang2022medclip, zhang2024data}, the top-down model development paradigm limits model capabilities by heavily relying on the resources available to the model builders. 
Such paradigm often restricts the potential of these models, as they cannot effectively utilize the diverse, private, and decentralized resources that exist within the broader medical community.
In contrast, collaborative systems present a promising alternative, offering a more flexible approach to model development.

Collaborative systems enable institutions to share knowledge by allowing distributed collaborators to contribute to a common goal~\cite{boulemtafes2020review}. 
To further protect patient privacy, federated learning (FL)~\cite{mcmahan2017communication} was proposed to alleviate such privacy concerns as server aggregating parameter updates from multiple clients without sharing their local data. 
While subsequent optimizations, such as aggregation algorithms~\cite{mcmahan2017communication, zhao2018federated, li2020federated}, secure learning~\cite{hardy2017private, xie2021crfl}, fairness improvements~\cite{sharma2022federated, zhao2022dynamic} and its application in medicine~\cite{kumar2024privacy}, have enhanced the capacity and applicability of FL, its real-world flexibility remains limited. This is primarily due to the need for synchronous updates, which require the server and clients to stay in sync, or model updates will be blocked.
This synchrony issue can be mitigated by open-source software platforms (e.g., GitHub~\cite{github}), allowing independent contributions from individual developers asynchronously. Such an asynchronous scheme enables faster iteration and the integration of specialized expertise, thus offering a more flexible and scalable approach.

Unlike synchronous collaboration, asynchronous collaboration does not require collaborators to work simultaneously and collaborators can individually complete their updates.
While the concept of asynchronous collaboration has been widely used in software development, its machine-learning applications remain limited~\cite{kandpal2023git, raffel2023building}. 
With the rise of global collaboration, large models~\cite{sahajBERT, le2023bloom} are usually co-developed by collaborators given various levels of data availability. However, this collaborative scheme requires the aggregation of local data and online synchronous cooperation of developers.
Software-like model update system~\cite{raffel2023building} alleviates the synchronous problem, where models are updated incrementally, similar to software development, by introducing merging and version control to model development.
However, the existing collaborative version control system~\cite{kandpal2023git} fails to address the complexities of medical scenarios because of the heavy dependency on plain parameter averaging across the full model without accounting for the varying requirements of different tasks.
To respond, we propose MedForge, which enables an asynchronous collaborative system and ensures strong robustness toward a continuous, community-driven enhancement of medical models while overcoming potential data leakage.

\input{assets/img/overview}

\subsection{Model Merging}
In collaborative systems, proper model merging becomes increasingly vital for improving model knowledge integration from multiple sources in a resource-limited environment~\cite{li2023deep, yang2024model, goddard2024arcee}. Conceptually, model merging strategies can be categorized into entire model merging and partial model merging.

Entire model merging involves combining multiple model parameters to participate in the merging process by several means. Entire model merging can be viewed as an optimization problem~\cite{Matena_Raffel_2021, jin2022dataless, mavromatis2024packllm} or an alignment problem~\cite{ainsworth2022git, jordan2022repair, xu2024training, ainsworth2022git}, each offering unique advantages depending on the task at hand.
In the optimization-based approach, the goal is to find the best combination of multiple models to enhance performance and efficiency. For instance, using Fisher information approximation~\cite{Matena_Raffel_2021}, the optimization-based model merging can be interpreted as selecting parameters that maximize the joint likelihood of the models' posterior distributions. The optimization of model merging can also be guided by minimizing the prediction differences between the merged model and individual models~\cite{jin2022dataless}. 
With the development of large language models (LLM), optimization-based method is used to fuse multiple LLMs at test-time by minimizing perplexity over the input prompt~\cite{mavromatis2024packllm}.
To highlight, optimization-based methods are beneficial for scenarios requiring enhanced model performance and efficiency to integrate model parameters, while alignment-based methods~\cite{ainsworth2022git, jordan2022repair} are better suited for maintaining consistency and interpretability, facilitating critical information sharing across models.
For example, a training-free model merging strategy aligns relevant models by using a similarity matrix of their representations in both activation and weight spaces~\cite{xu2024training}.
Further, the alignment between the independently trained model and a reference model not only works for models with the same architecture but also for arbitrary model architectures~\cite{ainsworth2022git}.
In summary, the entire model merging methods can effectively integrate existing models into a merged model with enhanced functionality. However, they could lead to increased computational complexity and reduced flexibility, making them less scalable and harder to implement across diverse tasks.

Partial model merging refers to combining only specific components or layers of models to improve model merging efficiency and decrease the computational cost. 
Such specific components can come from the same network~\cite{kingetsu2021neural}, where the original network is divided into subnetworks for different purposes, and these subnetworks can then be recombined for new tasks.
Additionally, modules can originate from different functional networks and be merged using various strategies. For instance, arithmetic operations are applied in \cite{zhang2023composing} to fuse parameter-efficient modules.
While merging modules from different networks provides flexibility, the process also requires a selection strategy to ensure the resulting model aligns with the specific needs of the inference stage. 
The selection strategies are commonly designed based on the similarity of task~\cite{lv2023parameter} and domain clustering performance~\cite{chronopoulou2023adaptersoup}. Alternatively, the mixture-of-experts methods use a routing strategy to select appropriate component modules~\cite{ponti2023combining}. However, these strategies often require significant time and computational resources to filter through a large model pool. 
In contrast, LoRAHub~\cite{huang2023lorahub} offers a more lightweight approach, combining various LoRA modules for different tasks with minimal model training. Nevertheless, LoRAHub lacks flexibility for incremental updates, especially when handling unseen tasks.

Although the existing model merging approaches effectively combine the capabilities of individual models, these approaches often rely on raw data, leading to potential privacy risks. Our proposed MedForge emphasizes the prevention of raw data usage, which is particularly crucial in medical scenarios. Additionally, MedForge offers an extensible capability for incremental learning, enabling continuous model improvement.


