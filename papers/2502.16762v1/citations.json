[
  {
    "index": 0,
    "papers": [
      {
        "key": "dosovitskiy2020image",
        "author": "Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "touvron2021training",
        "author": "Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\\'e}gou, Herv{\\'e}",
        "title": "Training data-efficient image transformers \\& distillation through attention"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "han2022survey",
        "author": "Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others",
        "title": "A survey on vision transformer"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhu2020deformable",
        "author": "Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng",
        "title": "Deformable detr: Deformable transformers for end-to-end object detection"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zheng2021rethinking",
        "author": "Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others",
        "title": "Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bucilua2006model",
        "author": "Bucilua, C and Caruana, R and Niculescu-Mizil, A",
        "title": "Model compression, in proceedings of the 12 th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "urner2011access",
        "author": "Urner, Ruth and Shalev-Shwartz, Shai and Ben-David, Shai",
        "title": "Access to unlabeled data can speed up prediction time"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "hinton2015distilling",
        "author": "Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others",
        "title": "Distilling the knowledge in a neural network"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "heo2022occlusion",
        "author": "Heo, Jiseong and Wang, Yooseung and Park, Jihun",
        "title": "Occlusion-aware spatial attention transformer for occluded object recognition"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wang2021not",
        "author": "Wang, Yulin and Huang, Rui and Song, Shiji and Huang, Zeyi and Huang, Gao",
        "title": "Not all images are worth 16x16 words: Dynamic transformers for efficient image recognition"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "lu2022transformer",
        "author": "Lu, Zhisheng and Li, Juncheng and Liu, Hong and Huang, Chaoyan and Zhang, Linlin and Zeng, Tieyong",
        "title": "Transformer for single image super-resolution"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "fateh2024advancing",
        "author": "Fateh, Amirreza and Birgani, Reza Tahmasbi and Fateh, Mansoor and Abolghasemi, Vahid",
        "title": "Advancing Multilingual Handwritten Numeral Recognition With Attention-Driven Transfer Learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "hu2018squeeze",
        "author": "Hu, Jie and Shen, Li and Sun, Gang",
        "title": "Squeeze-and-excitation networks"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "zhu2019empirical",
        "author": "Zhu, Xizhou and Cheng, Dazhi and Zhang, Zheng and Lin, Stephen and Dai, Jifeng",
        "title": "An empirical study of spatial attention mechanisms in deep networks"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "fukui2019attention",
        "author": "Fukui, Hiroshi and Hirakawa, Tsubasa and Yamashita, Takayoshi and Fujiyoshi, Hironobu",
        "title": "Attention branch network: Learning of attention mechanism for visual explanation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "papernot2016distillation",
        "author": "Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram",
        "title": "Distillation as a defense to adversarial perturbations against deep neural networks"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "Yuan2019RevisitKD",
        "author": "Li Yuan and Francis E. H. Tay and Guilin Li and Tao Wang and Jiashi Feng",
        "title": "Revisit Knowledge Distillation: a Teacher-free Framework"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "bohdal2020flexible",
        "author": "Bohdal, Ondrej and Yang, Yongxin and Hospedales, Timothy",
        "title": "Flexible dataset distillation: Learn labels instead of images"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "cheng2020explaining",
        "author": "Cheng, Xu and Rao, Zhefan and Chen, Yilan and Zhang, Quanshi",
        "title": "Explaining knowledge distillation by quantifying the knowledge"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "ji2020knowledge",
        "author": "Ji, Guangda and Zhu, Zhanxing",
        "title": "Knowledge distillation in wide neural networks: Risk bound, data efficiency and imperfect teacher"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "tang2020understanding",
        "author": "Tang, Jiaxi and Shivanna, Rakesh and Zhao, Zhe and Lin, Dong and Singh, Anima and Chi, Ed H and Jain, Sagar",
        "title": "Understanding and improving knowledge distillation"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "yang2020knowledge",
        "author": "Yang, Jing and Martinez, Brais and Bulat, Adrian and Tzimiropoulos, Georgios",
        "title": "Knowledge distillation via adaptive instance normalization"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "mirzadeh2020improved",
        "author": "Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Li, Ang and Levine, Nir and Matsukawa, Akihiro and Ghasemzadeh, Hassan",
        "title": "Improved knowledge distillation via teacher assistant"
      }
    ]
  }
]