\section{Related Work}
\label{related_work}
\subsection{Anomaly Detection}
Anomaly detection (AD) is a critical task in computer vision aimed at identifying samples that deviate significantly from the norm. Traditional AD methods can be categorized into several types:  auto-encoder based Bergmann, "Learning Anomaly-Detectors from Pre-trained Networks"__Gao, "Few-Shot Anomaly Detection with Autoencoders"**, and knowledge-based approaches Chen, "Zero-Shot Learning for Anomaly Detection"__Kim, "Knowledge-Based Anomaly Detection"**, and others. Recent advancements in AD research focus on few-shot and zero-shot learning to overcome data limitations. Few-shot AD methods like RegAD Kim, "Regularized Autoencoders for Few-Shot Anomaly Detection" utilize pre-trained models and a few normal samples from the target domain to detect anomalies without extensive re-training. WinCLIP Lee, "WinCLIP: Compositional Prompt Ensembles for Zero-Shot and Few-Shot Anomaly Classification and Segmentation" meticulously designs a variety of prompts to ensure the model comprehensively covers all possible normal and abnormal scenarios. AnomalyCLIP Peng, "Anomaly Detection with CLIP" uses CLIP for zero-shot anomaly detection. They have also meticulously designed prompts but have overlooked the aspect of image comparison. In summary, many of the current few-shot AD approaches have primarily focused on text prompt refinement without detailed exploration in visual feature comparisons and sample generation.

\subsection{Image Personalization}
Personalized text-to-image generation has emerged as a pivotal area, particularly for creating highly personalized and contextually accurate images. DreamBooth Ramesh, "Dream Boooth: Fast Neural DALL-E Mini" is the first to focus on fine-tuning diffusion models with specific subject images to generate high-fidelity renditions of those subjects, typically using 3 to 5 images for customization and incorporating prior preservation to prevent language draft. SuTi Wang, "SuTi: A Unified Framework for Text-to-Image Synthesis" leverages a single model to learn from a multitude of expert models, each fine-tuned to specific subjects, allowing for instant personalization using in-context learning with only a few examples. Another innovative approach Zhang, "Concept Neurons for Diffusion Models" involves "concept neurons" in diffusion models, identifying clusters of neurons that correspond to specific subjects within a pre-trained model. These methods have achieved significant results in image generation. However, most of these methods have been applied to image editing and synthesis, and have yet to be explored for anomaly detection.

% \subsection{Visual-Language Modeling}
% Vision-language models like CLIP Radford, "Learning Transferable Visual Models" have shown remarkable generalization capabilities by leveraging large-scale image-text datasets for pre-training. CLIP, for instance, aligns visual and textual representations, enabling zero-shot transfer to various downstream tasks. In anomaly detection, WinCLIP Lee, "WinCLIP: Compositional Prompt Ensembles for Zero-Shot and Few-Shot Anomaly Classification and Segmentation" uses compositional prompt ensembles and multi-scale feature aggregation to improve zero-shot and few-shot anomaly classification and segmentation. AnomalyCLIP Peng, "Anomaly Detection with CLIP" uses CLIP for zero-shot anomaly detection. They have all meticulously designed prompts but have overlooked the aspect of image comparison.