\section{Related Work}
\label{related_work}
\subsection{Anomaly Detection}
Anomaly detection (AD) is a critical task in computer vision aimed at identifying samples that deviate significantly from the norm. Traditional AD methods can be categorized into several types:  auto-encoder based~\cite{zhou2020encoding,zavrtanik2021reconstruction}, GAN-based, and knowledge-based approaches~\cite{cao2023anomaly,deng2022anomaly,tien2023revisiting}, and others. Recent advancements in AD research focus on few-shot and zero-shot learning to overcome data limitations. Few-shot AD methods like RegAD~\cite{huang2022registration} utilize pre-trained models and a few normal samples from the target domain to detect anomalies without extensive re-training. WinCLIP~\cite{jeong2023winclip} meticulously designs a variety of prompts to ensure the model comprehensively covers all possible normal and abnormal scenarios. AnomalyCLIP~\cite{zhou2023anomalyclip} uses CLIP for zero-shot anomaly detection. They have also meticulously designed prompts but have overlooked the aspect of image comparison. In summary, many of the current few-shot AD approaches have primarily focused on text prompt refinement without detailed exploration in visual feature comparisons and sample generation.

\subsection{Image Personalization}
Personalized text-to-image generation has emerged as a pivotal area, particularly for creating highly personalized and contextually accurate images. DreamBooth~\cite{ruiz2023dreambooth} is the first to focus on fine-tuning diffusion models with specific subject images to generate high-fidelity renditions of those subjects, typically using 3 to 5 images for customization and incorporating prior preservation to prevent language draft. SuTi~\cite{chen2024subject} leverages a single model to learn from a multitude of expert models, each fine-tuned to specific subjects, allowing for instant personalization using in-context learning with only a few examples. Another innovative approach~\cite{liu2023cones} involves "concept neurons" in diffusion models, identifying clusters of neurons that correspond to specific subjects within a pre-trained model. These methods have achieved significant results in image generation. However, most of these methods have been applied to image editing and synthesis, and have yet to be explored for anomaly detection.

% \subsection{Visual-Language Modeling}
% Vision-language models like CLIP\cite{radford2021learning} have shown remarkable generalization capabilities by leveraging large-scale image-text datasets for pre-training. CLIP, for instance, aligns visual and textual representations, enabling zero-shot transfer to various downstream tasks. In anomaly detection, WinCLIP~\cite{jeong2023winclip} uses compositional prompt ensembles and multi-scale feature aggregation to improve zero-shot and few-shot anomaly classification and segmentation. AnomalyCLIP~\cite{zhou2023anomalyclip} uses CLIP for zero-shot anomaly detection. They have all meticulously designed prompts but have overlooked the aspect of image comparison.