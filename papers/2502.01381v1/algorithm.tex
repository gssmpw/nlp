\section{Algorithms}\label{sec:algorithm}

In this section, we present our algorithms for \problemcdcsm and \problemcdcsdiff problems. We present two exact algorithms based on fractional programming~\citep{dinkelbach1967nonlinear} and integer linear programming. Both algorithms may require exponential time but in practice can provide a solution in reasonable time for moderately-sized graphs. In addition, we propose two polynomial time heuristics.

\subsection{Exact algorithm for \problemcdcsm}

We will present an integer programming based algorithm algorithm that finds an exact or near-optimal solution for \problemcdcsm problem. 
To this end, let us first define the \emph{edge} difference as
\[
    b(S, \calG) = \max_i m(S, G_i) - \min_i m(S, G_i)\quad.
\]
To solve \problemcdcsm we consider the following auxiliary problem.

\begin{problem}[$\problemcdcsm(\gamma)$]
\label{pr:label-subgrap-str-wk-alpha}
Given a graph sequence $\calG = (G_1,\dots,G_r)$, with  $G_i = (V, E_i)$, and two numbers $\alpha, \gamma$, find a subset of vertices $S \subseteq V$ maximizing  $ \sum_{i = 1}^r m(S, G_i) - \gamma \abs{S}$ such that $b(S, \calG) \leq  \alpha \abs{S}$.
\end{problem}

%The problem $\problemcdcsm(\gamma)$ is related to fractional programming~\citep{dinkelbach1967nonlinear}.
Next, we show the relationship between $\problemcdcsm(\gamma)$ and \problemcdcsm. This connection is an example of fractional programming~\citep{dinkelbach1967nonlinear}.


\begin{proposition}
\label{prop:frac}
Let $S(\gamma)$  be the subgraph  solving $\problemcdcsm(\gamma)$. Similarly, let $S^*$  be the optimal solution for \problemcdcsm. Write $\gamma^* =  \dens{S^*, \calG}$. If $\gamma > \gamma^*$, then $S(\gamma) = \emptyset$. If $\gamma < \gamma^*$, then $S(\gamma) \neq \emptyset$ and $\dens{S(\gamma),  \calG} > \gamma$.
\end{proposition}

\begin{proof}
Let $f(S) = \sum_{i = 1}^r m(S, G_i)$.
We know that
\begin{equation}
\label{eq:alphapos}
    f(S(\gamma)) - \gamma \abs{S(\gamma)} \geq f(\emptyset) - \gamma\abs{\emptyset} = 0.
\end{equation}

Let us first assume that $\gamma > \gamma^*$. If $S(\gamma) \neq \emptyset$, then Eq.~\ref{eq:alphapos} implies that $\dens{S(\gamma),  \calG} \geq \gamma > \gamma^*$, which contradicts the optimality of $\gamma^*$. Thus, $S(\gamma) = \emptyset$.

Next, let us assume that $\gamma < \gamma^*$. Then
\[
\begin{split}
    f(S(\gamma)) - \gamma \abs{S(\gamma)} & \geq f(S^*) - \gamma \abs{S^*}  > f(S^*) - \gamma^* \abs{S^*} = 0.
\end{split}
\]
Thus $f(S(\gamma)) >  \gamma \abs{S(\gamma)}$, and consequently $S(\gamma) \neq \emptyset$ and $\dens{S(\gamma), \calG} > \gamma$. \qed
\end{proof}

Next, we use Proposition~\ref{prop:frac} to solve our main problem \problemcdcsm. We find the (almost) largest $\gamma$ for which $\problemcdcsm(\gamma)$ yields a non-empty solution. Then $\problemcdcsm(\gamma)$ for such $\gamma$ yields (almost) optimal solution.

We can solve $\problemcdcsm(\gamma)$ with an integer linear program,

\begin{align}
	\textsc{maximize}&&  \sum_{k = 1}^r \sum_{ ij \in E_k} x_{ij} & - \gamma \sum_{i = 1}^{n} y_i \nonumber \\  
	\textsc{subject to}&& x_{ij} & \leq y_i &  ij \in E  \label{ip_con_1} \\
	&&x_{ij} & \leq y_j &  ij \in E \label{ip_con_2} \\
        &&x_{ij} & \geq y_i  + y_j - 1, &  ij \in E \label{ip_con_3}\\
	&&\sum_{ij \in E_k} x_{ij} - \sum_{ij \in E_\ell} x_{ij}  & \leq \alpha \sum_{i = 1}^{n} y_i   &  k, \ell = 1,\dots, r \label{ip_con_5}\\
	&&x_{ij},  y_j  & \in \{0,1\} \nonumber\quad.
\end{align}

To see why this program solves $\problemcdcsm(\gamma)$, 
let $S \subseteq V$  be a solution to our $\problemcdcsm(\gamma)$, 
The indicator variable $y_i$ denotes whether the node $i \in S$, and the indicator variable $x_{ij}$ denotes whether both endpoints of edge $ij$ are in $S$.
Note that Constraints~\ref{ip_con_1}--\ref{ip_con_3} force $x_{ij} = \min(y_i, y_j)$.

Furthermore, Constraint~\ref{ip_con_5} ensures that $b(S, \calG) \leq \alpha \abs{S}$. %$$\diff{S, \calG} \leq \alpha$.

Proposition~\ref{prop:frac} allows to maximize $\gamma$
with a binary search. Here, we choose the initial interval $(L, U)$ by setting lower threshold $L = 0$ and upper threshold $U = r\frac{n - 1}{2}$, and keep halving the interval until $\abs{ U - L} \leq  \epsilon L$, where $\epsilon > 0$  is an input parameter. Finally, we return the solution of $\problemcdcsm(L)$ as the final solution to \problemcdcsm. We refer to this algorithm as \algipcm.
Next, we show that \algipcm yields $1/(1+\epsilon)$ approximation guarantee, or exact solution if $\epsilon$ is small enough.

\begin{proposition}
Assume a graph sequence $\calG = (G_1,\dots,G_r)$, $\alpha \geq 0$, and $\epsilon > 0$. 
Let $\gamma$ be the score of the solution returned by $\algipcm$ and let $\gamma^*$ be the optimal score of \problemcdcsm. Then $\gamma \geq \gamma^*/(1 + \epsilon)$. If $\epsilon \leq \frac{1}{rn^3}$, then $\gamma = \gamma^*$.
\label{prop:opt-ip-approx}
\end{proposition}

\begin{proof}
Let $L$ and $U$ be the values of the interval when binary search is terminated. Note that $\gamma \geq L$ due to Proposition~\ref{prop:frac}.
We know that $U - L \leq \epsilon L$ and $L \leq \gamma^* \leq U$. Thus,
$\gamma^* - L \leq U - L \leq \epsilon L$, or $\gamma^*  \leq (1 + \epsilon) L \leq (1 + \epsilon) \gamma$.

To prove the second claim, note that $\dens{S, \calG}$ is a rational number with a numerator of at most $n$. Thus, either $\gamma = \gamma^*$ or $\gamma^* - \gamma > n^{-2}$. If $\epsilon \leq \frac{1}{rn^3}$, then $\gamma^* - \gamma \leq U - L \leq n^{-2}$. Consequently, $\gamma = \gamma^*$.
\qed
\end{proof}


\algipcm requires $\bigO{\log rn - \log \epsilon}$ rounds, solving an integer linear program in each round. Note that solving an integer program is \np-hard~\cite{Schrijver1998}.

We should point out that fractional programming was used
by Goldberg~\cite{goldberg1984finding} for finding the densest subgraph in a single graph.
The key difference is the fairness constraint: without it $\problemcdcsm(\gamma)$ reduces to a minimum cut, which can be solved exactly in polynomial time.

\subsection{Exact algorithm for  \problemcdcsdiff}

Next, we will propose an exact algorithm to solve \problemcdcsdiff. The approach is similar to the solver for \problemcdcsm, that is, we will define an auxiliary problem, which can be solved with an integer program, and then use binary search to find the solution for \problemcdcsdiff. More formally, 
we have the following auxiliary problem  $\problemcdcsdiff(\gamma)$, and its relation to \problemcdcsdiff.

\begin{problem}[$\problemcdcsdiff(\gamma)$]
%\label{pr:label-subgrap-str-wk-alpha}
Given a graph sequence $\calG = (G_1,\dots,G_r)$, with  $G_i = (V, E_i)$, and two numbers $\alpha, \gamma$, find a subset of vertices $S \subseteq V$ minimizing  $b(S, \calG) - \gamma \abs{S}$, such that $m(S, \calG) \geq  \alpha\abs{S}$.
\end{problem}

\begin{proposition}
\label{prop:fracsbs}
Let $S(\gamma)$  be the subgraph  solving $\problemcdcsdiff(\gamma)$. Similarly, let $S^*$  be the optimal solution for \problemcdcsdiff. Write $\gamma^* =  \diff{S^*, \calG}$. If $\gamma < \gamma^*$, then $S(\gamma) = \emptyset$. If $\gamma > \gamma^*$, then $S(\gamma) \neq \emptyset$ and $\diff{S(\gamma),  \calG} < \gamma$.
\end{proposition}

\begin{proof}
Since an empty set satisfies the constraints, we have
$b(S(\gamma), \calG) - \gamma\abs{S(\gamma)} \leq 0$.
Let us first assume that $\gamma < \gamma^*$. If $S(\gamma) \neq \emptyset$, then $\diff{S(\gamma),  \calG} \leq \gamma < \gamma^*$ and $\dens{S(\gamma), \calG} \geq \alpha$, which contradicts the optimality of $\gamma^*$. Thus, $S(\gamma) = \emptyset$.

Next, let us assume that $\gamma > \gamma^*$. Then
\[
\begin{split}
    b(S(\gamma)) - \gamma \abs{S(\gamma)} & \leq b(S^*) - \gamma \abs{S^*}  < b(S^*) - \gamma^* \abs{S^*} = 0.
\end{split}
\]
Thus $b(S(\gamma)) <  \gamma \abs{S(\gamma)}$, consequently  $S(\gamma) \neq \emptyset$ and $\diff{S(\gamma), \calG} < \gamma$. \qed
\end{proof}
 
We can solve $\problemcdcsdiff(\gamma)$ with an integer linear program,

\begin{align*}
\textsc{minimize}&&  u - \ell & - \gamma \sum_{i = 1}^n y_i  \nonumber\\  
\textsc{subject to} && 
  x_{ij} & \leq y_i &  ij \in E   \\
&& x_{ij} & \leq y_j &  ij \in E \\
&& x_{ij} & \geq y_i + y_j - 1 &  ij \in E \\
&&  \sum_{ ij \in E_k} x_{ij} & \geq \ell &  k = 1,\dots, r \\
&&  \sum_{ ij \in E_k} x_{ij} & \leq u  &  k = 1,\dots, r \\
&& \sum_{k = 1}^r \sum_{ ij \in E_k} x_{ij} & \geq  \sigma  \sum_{i = 1}^{n} y_i\\
&& x_{ij}, y_j  & \in \{0,1\} \nonumber\\
&&  u,\ell & \geq 0 \nonumber\quad.
\end{align*}

Here we introduce upper and lower threshold variables $u$ and $\ell$ such that the difference $u - \ell$ matches to $b(S, \calG)$.
Similar to \algipcm, we search for the smallest $\gamma$ such that the solution is non-empty, that is, we run a binary search and stop when $U - L \leq (1 + \epsilon)L$, and then use $\problemcdcsdiff(U)$ as the final result. We refer to our algorithm as \algipdiff. The algorithm yields the following guarantees.

\begin{proposition}
Assume a graph sequence $\calG = (G_1,\dots,G_r)$, $\sigma > 0$, and $\epsilon > 0$. 
Let $\gamma$ be the score of the solution returned by $\algipdiff$ and let $\gamma^*$ be the optimal score of \problemcdcsdiff. Then $\gamma \leq (1 + \epsilon)\gamma^*$.
If $\epsilon \leq \frac{1}{n^3}$, then $\gamma = \gamma^*$.
\label{prop:opt-sbs-approx}
\end{proposition}
The proof is similar to the proof of Proposition~\ref{prop:opt-ip-approx}, and therefore is omitted.


\subsection{Greedy algorithm to find a good solution for  \problemcdcsdiff}

A standard technique in designing a polynomial-time algorithm is to start from the integer program, in this case \algipdiff, relax the integrality constraints, solve the resulting linear program, and then devise a rounding step. In our experimentation, this approach was problematic as the resulting sets rarely satisfied the constraints.
Consequently, we propose a greedy algorithm for \problemcdcsdiff. 

We start by solving \problemdts; let $S$ be the resulting set. Note since $\dens{S, \calG}$ is optimal,
$\dens{S, \calG} \geq \sigma$  or there is no set satisfying the constraint. 

We continue by trying to minimize $\diff{S, \calG}$ either by adding or removing a vertex greedily, while satisfying the density constraint. We repeat the same process until the algorithm
converges. The pseudo-code for the algorithm is given in Algorithm~\ref{alg:greedy}.

\begin{algorithm}[t!]
\caption{$\alggrd(\calG,\alpha)$, finds greedily a subgraph $S$ which minimizes $\diff{S, \calG}$ while satisfying $\dens{S, \calG} \geq \sigma$.}
\label{alg:greedy}
    $S \define $ The solution of \problemdts\;
	
    \While {changes to $\diff{S}$}{
        Find a vertex $v$ which minimizes $\diff{S}$ either by adding or removing while satisfying density constraint\;
        Add or remove $v$ from the set $S$\;    
    }
	\Return $S$\;
\end{algorithm}

\subsection{Greedy algorithm to find a good solution for  \problemcdcsm} \label{subsec:greedy-algo-fds}

Next, we present a two-phase greedy algorithm to find a good solution for \problemcdcsm. Given an input parameter $\alpha$, in the first phase of the algorithm, we search for a set $S$ such that $\diff{S, \calG} \leq \alpha$.

More concretely,  we repeatedly run \alggrd by varying $\sigma$ between $0$ and \dentds, the density of the solution for \problemdts, and choose a feasible set with the highest total density. As a candidate set for $\sigma$, we used $\set{\frac{i}{k}\dentds \mid i = 0, \ldots, k}$, where $k$ is a user parameter.

In the second phase of the algorithm, we start from our feasible set returned in the first phase, and at each iteration, we try to improve our density score by picking the best vertex to either add or delete until convergence. We refer to our algorithm as \alggrdfms.


\subsection{Exact algorithm for \problemdcs}

Although heuristics have been proposed to  \problemdcs problem~\cite{jethava2015finding, semertzidis2019finding}, we propose an integer programming-based algorithm to find an exact or near-optimal solution which we refer to this algorithm as \algipdcs. 

We introduce the following auxiliary problem.

\begin{problem}[$\problemdcs(\gamma)$]
Given a graph sequence $\calG = (G_1,\dots,G_r)$, with  $G_i = (V, E_i)$, find a common subset of vertices
$S$, 
such that $\min_i m(S, G_i) - \gamma \abs{S}$  is maximized.
\end{problem}


We solve $\problemdcs(\gamma)$ with the following integer program

\begin{align*}	\textsc{maximize\,\,\,\,}\hspace{.1in}&&\hspace{.05in}  z &- \gamma \sum_{i = 1}^{n} y_i 
	\\  
	\textsc{subject to}\hspace{.2in} && 
  x_{ij} &\leq y_i &  ij \in E \\
	&& x_{ij} &\leq y_j & ij \in E \\ 
 	&& \sum_{ i, j \in E_k} x_{ij} &\geq z  &  k = 1,\dots, r \\
	&& x_{ij}, y_j &\in \{0,1\}\\
        &&  z & \geq 0 \quad.
\end{align*}

To see why this program solves $\problemdcs(\gamma)$,
note that $x_{ij} = \min(y_i, y_j)$ and $z = \min_k m(S, G_k)$,
where $S = \set{i \mid y_i = 1}$.

We search for maximal $\gamma$ that induces non-empty solution
with a binary search. Here, we set the initial interval $(L, U)$ to $L = 0$ and $U =\frac{n - 1}{2}$, and keep halving the interval until $\abs{ U - L} \leq  \epsilon L$, where $\epsilon > 0$  is an input parameter. Finally, we return the solution of $\problemdcs(L)$ as the final solution to \problemdcs. 

The following result states the approximation guarantees of \algipdcs.

\begin{proposition}
Assume a graph sequence $\calG = (G_1,\dots,G_r)$ and $\epsilon > 0$. 
Let $\gamma$ be the score of the solution returned by \algipdcs and let $\gamma^*$ be the optimal score of \problemdcs. Then $\gamma \geq \gamma^*/(1 + \epsilon)$. If $\epsilon \leq \frac{1}{n^3}$, then $\gamma = \gamma^*$.
\label{prop:opt-dcs-approx}
\end{proposition}

The proof of the proposition is essentially the same as the proofs for \algipcm, and is therefore omitted.



























