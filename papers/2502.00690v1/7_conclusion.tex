\section{Conclusion} \label{sec:conclusion}

In this work, we identify the fairness issue in the desk-rejection mechanisms of AI conferences under submission limits.
Our theoretical analysis proves that an ideal system that rejects papers solely based on authors' non-compliance, without unfairly penalizing others due to collective punishment, is impossible. We further consider an optimization-based fairness-aware desk-rejection system to alleviate the unfairness problem. In this system, we considered two fairness metrics: individual fairness and group fairness. We formally established that optimizing individual fairness in desk-rejection is NP-hard, while optimizing group fairness can be reduced to a linear programming problem that can be solved highly efficiently. Through case studies, we showed that the proposed method outperforms the existing desk-rejection system with submission limits in top conferences. For future works, we plan to collaborate with conference organizers to implement and validate our system in real-world settings, contributing to a more equitable AI community. 

\ifdefined\isarxiv
\else
\clearpage
\section*{Impact Statement}
This paper seeks to advance fairness in desk-rejection systems employed by top AI conferences. By formally defining the paper submission limit problem, we demonstrate that an ideal system that rejects papers solely based on excessive submissions without negatively impacting innocent authors is mathematically impossible when multiple authors are involved. To address this, we propose a framework that optimizes desk-rejection fairness based on two different metrics. This ensures that early-career researchers with fewer submissions are less likely to face disproportionate setbacks due to co-authors' submission behavior. While introducing fairness may slightly impact the acceptance rates of senior researchers with a large number of submissions, our approach does not aim to diminish anyoneâ€™s research output. Instead, it seeks to balance opportunity across career stages, thereby advancing social justice and contributing to a fairer and more inclusive ML research ecosystem.
\fi