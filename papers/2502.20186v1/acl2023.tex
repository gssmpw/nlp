% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
% \usepackage[review]{ACL2023}
\usepackage{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{bbding}
\usepackage{hyperref}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage[linesnumbered,ruled,vlined,algo2e]{algorithm2e}
\usepackage{graphicx}
\usepackage{xcolor}  
\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\newcommand{\refhere}{\textcolor{red}{[refhere]}}
\newcommand{\CY}{\textcolor{blue}}
\title{Layer-Aware Task Arithmetic: Disentangling Task-Specific and Instruction-Following Knowledge}

% Author information can be set in various styles:
% For several authors from the same institution:
\author{Yan-Lun Chen$^*$, Yi-Ru Wei$^*$, Chia-Yi Hsu$^*$, Chia-Mu Yu$^*$, Chun-Ying Huang$^*$, Ying-Dar Lin$^*$\\ {\bf Yu-Sung Wu$^*$ \and Wei-Bin Lee$^\spadesuit $}  \\
        $^*$ National Yang Ming Chiao Tung University\\ $^\spadesuit $ Hon Hai Research Institute  }
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{Yan-Lun Chen \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\begin{document}
\maketitle
\begin{abstract}
Large language models (LLMs) demonstrate strong task-specific capabilities through fine-tuning, but merging multiple fine-tuned models often leads to degraded performance due to overlapping instruction-following components. Task Arithmetic (TA), which combines task vectors derived from fine-tuning, enables multi-task learning and task forgetting but struggles to isolate task-specific knowledge from general instruction-following behavior. To address this, we propose \textit{Layer-Aware Task Arithmetic (LATA)}, a novel approach that assigns layer-specific weights to task vectors based on their alignment with instruction-following or task-specific components. By amplifying task-relevant layers and attenuating instruction-following layers, LATA improves task learning and forgetting performance while preserving overall model utility. Experiments on multiple benchmarks, including WikiText-2, GSM8K, and HumanEval, demonstrate that LATA outperforms existing methods in both multi-task learning and selective task forgetting, achieving higher task accuracy and alignment with minimal degradation in output quality. Our findings highlight the importance of layer-wise analysis in disentangling task-specific and general-purpose knowledge, offering a robust framework for efficient model merging and editing.
\end{abstract}

\section{Introduction}\label{sec: Introduction}
Existing large language models (LLMs) demonstrate robust conversational abilities but often require fine-tuning on specialized datasets for optimal task performance. Model merging combines multiple fine-tuned models into a single multi-task system. A common approach is \textit{task arithmetic} (TA) \cite{ilharco2023}, which adds or subtracts parameter differences (\textit{task vectors}) obtained before and after fine-tuning. By manipulating these vectors, TA enables a model to gain or discard specific task capabilities.

Models fine-tuned for specific tasks typically stem from instruction-following LLMs \cite{dodge2020fine}. During fine-tuning, instruction-following behavior is further reinforced alongside the target task capability (Figure~\ref{fig:1-1}). Consequently, each task vector encodes both instruction-following and task-specific components. Merging multiple task vectors via TA can introduce overlapping instruction-following components, leading to worse utility in the merged model (Figure~\ref{fig:1-2}) and degrading overall output quality. Moreover, overlapping parameters across different tasks may lower performance on individual tasks when tasks are merged together.

To mitigate negative effects from overlapping instruction-following components, one must discard those portions of the task vectors and preserve only the segments that emphasize the target task. However, effectively isolating task-oriented segments remains an open challenge.

In TA, the direction of a task vector determines how the target model’s capabilities shift. We can view the full vector as a collection of layer-specific vectors, one per layer. Comparing each layer's vector with that of an instruction-following model reveals whether it focuses on instruction-following (high similarity) or on the specific task (low similarity).

Based on this observation, we propose \emph{Layer-Aware Task Arithmetic} (LATA), which assigns different weights to each layer of the task vector. Layers aligned with the target task receive larger weights, amplifying their effect on the final model, while layers emphasizing instruction-following receive smaller weights (or are disregarded) to reduce negative impact.

Our experiments show that LATA not only preserves output quality in task learning but also achieves better overall performance on each task than existing approaches. In task forgetting (the subtractive operation in TA), LATA likewise demonstrates strong effectiveness, selectively removing capabilities with minimal overall degradation.

\paragraph{Contribution} We introduce LATA, an approach to selectively amplify task-specific segments within a task vector and suppress overlapping instruction-following components. LATA preserves the merged model’s quality and achieves higher performance on multiple tasks compared to previous methods. LATA also excels at selectively removing undesired capabilities, incurring minimal harm to the model’s remaining skills.

\begin{figure}[t]
\centering
\subfigure[Task vectors encode both instruction-following and task-specific capabilities.]{
\label{fig:1-1}
\includegraphics[width=0.2\textwidth]{img/1-1.jpg}}\quad\quad\subfigure[Overlapping instruction-following components degrade merged model performance.]{
\label{fig:1-2}
\includegraphics[width=0.21\textwidth]{img/1-2.jpg}}
\caption{Challenges in task arithmetic, highlighting interference between instruction-following and task-specific components.}
\label{fig:1}
\end{figure}

\section{Related Work}\label{sec: Related Work}
Combining model capabilities without additional training has attracted growing attention. Model merging fuses weights of separately fine-tuned models for multi-task learning~\cite{choi2024}, and simple averaging can improve accuracy and robustness~\cite{wortsman2022}. TIES~\cite{yadav2023} resets negligible changes to address sign conflicts, reducing performance drops; Delta-sparsification (DARE)~\cite{yu2024} discards up to 99\% of fine-tuning deltas to merge multiple homologous models. Most research aims to minimize utility loss of merged LLMs~\cite{matena2022,jin2023dataless,zhou-etal-2024-metagpt,guodong24neurips,lu2024,dai2025leveraging,lai2025mediatormemoryefficientllmmerging}, while \citet{yang2024adamerging,yang2024representation,bowen2024taskvectorsselectivetask,gargiulo2025tasksingularvectorsreducing} explore merging computer vision models using key parts of task vectors.

An alternative line of research, \emph{task arithmetic}~(\textit{TA}), views tasks as weight update vectors composed via vector operations. \citet{ilharco2023} define a \emph{task vector} as the difference between a fine-tuned model and its base, enabling multiple tasks to be learned simultaneously and new tasks to be inferred without retraining. Negating a task vector selectively unlearns a specific task with minimal impact on others, implying that model weights shift independently per task. TA has been considered in fine-tuning~\citep{zhang2023composing,choi2024} and alignment~\citep{zhao-etal-2024-defending-large,li2025safety,hazra-etal-2024-safety} contexts.

In this paper, we focus on TA for both task learning and forgetting. Existing methods generally merge or edit entire models without distinguishing which layers encode task-specific versus general knowledge. In contrast, our proposed LATA performs a \emph{layer-wise analysis} to separate generic utility from task-specific effects, enabling selective amplification or removal of tasks while preserving overall performance.

%\paragraph{Enhancing LLMs' safety alignment} \citet{bhardwaj-etal-2024-language} have demonstrated that Task Arithmetic (TA) aids in enhancing model safety alignment. However, applying TA to models fine-tuned for different languages may yield less noticeable improvements, as safety vectors derived from general English models might not align well due to language differences. Obtaining safety vectors specific to each language by fine-tuning with malicious data is time-consuming and resource-intensive. For enhancing model alignment at the individual layer, \citet{zhao-etal-2024-defending-large} introduce Layer-specific Editing (LED). By identifying and realigning critical early "safety layers" with decoded safe responses from specific layers, LED enhances LLM resilience to adversarial prompts without compromising performance on benign inputs. Similarly, \citet{li2025safety} proposed another method to identify safety layers. By fine-tuning these layers, the model's safety is further enhanced. While these methods effectively improve model alignment, they still require language-specific data and fine-tuning for different languages. In contrast, LATA directly extracts the essential components of the safety vector from English models and applies TA, ensuring alignment improvements without being affected by language differences.

\section{Background Knowledge}\label{sec: Background Knowledge}
Given $\theta_{\text{pre}}$ as the weights of a pre-trained LLM and $\theta_{\text{ft}}$ as the parameters of the LLM fine-tuned for a target task, TA \cite{ilharco2023} proposes the following formula to obtain the task vector $\tau$:  
\begin{align}  
\tau = \theta_{\text{ft}} - \theta_{\text{pre}}  
\end{align}  
where $\tau$ represents the task vector for the target task, indicating the model's capability to perform the target task.  

TA further proposes that task vectors for different target tasks can be added to a single model, enabling the model to simultaneously perform multiple target tasks. This achieves the effect of \textit{task learning}:  
\begin{align}  
\theta_{\text{merged}} = \theta_{\text{target}} + \sum_{i=1}^{t} \lambda_i \tau_i  
\end{align}  
where $t$ is the total number of target tasks, $\lambda_i$ is a scaling coefficient for the vector, $\theta_{\text{target}}$ is the original parameters of the target model, and $\theta_{\text{merged}}$ is the model after merging via TA. The merged model can simultaneously improve its performance on multiple target tasks.  

On the other hand, in the \textit{task forgetting}, the task vector can also be used to remove the model's ability for specific tasks:  
\begin{align}  
\theta_{\text{unable}} = \theta_{\text{able}} - \lambda \tau  
\end{align}  
Here, $\tau$ represents the task vector for the task to be removed. After subtracting the task vector, the model's performance on the removed task will decrease.

\begin{figure}[t]
    \centering    \includegraphics[width=0.47\textwidth]{img/2.jpg}
    \caption{The difference between instruction, complex and task vector. In LATA, we emphasize extracting and applying more \textcolor{darkgreen}{green} vectors that positively impact the target task, while minimizing \textcolor{red}{red} vectors that could degrade the merged model’s utility.}
    \label{fig:2}
\end{figure}

\begin{figure*}[t]
    \centering    \includegraphics[width=0.9\textwidth]{img/3.jpg}
    \caption{\textbf{Method for identifying important layers:} We compute the cosine similarity of each layer vector between the complex vector and the instruction vector. Layers with lower similarity are less related to instruction-following and likely enhance the target task, so we strengthen them. Conversely, layers with higher similarity align more with instruction-following and have lower task relevance, so we attenuate them to reduce their impact on utility.}
    \label{fig:3}
\end{figure*}

\section{Proposed Method}
Here, we present our proposed method, \textit{Layer-Aware Task Arithmetic} (LATA). First, we define a \textit{base model} as a model that does not possess instruction-following capabilities, such as Llama-3-8B \cite{grattafiori2024llama3herdmodels}. We also define a \textit{pre-trained model} as a model with instruction-following capabilities, such as Llama-3-8B-Instruct \cite{grattafiori2024llama3herdmodels}. Moreover, for multiple target tasks, we obtain models that are fine-tuned from the pre-trained model for each specific task, resulting in models tailored to their respective tasks. We refer to these models as \textit{fine-tuned models}, which are derived from the pre-trained model through fine-tuning. LATA consists of the following four steps. 

\paragraph{Step 1: Deriving Instruction Vector and Complex Vector}
We define the \textit{instruction vector} by subtracting the base model’s parameters from the pre-trained model’s parameters:

\begin{align}
\tau_{\text{instr}} = \theta_{\text{pre}} - \theta_{\text{base}}.
\end{align}

This captures the instruction-following capability. We then define the \textit{complex vector} by subtracting the base model’s parameters from those of each fine-tuned model:

\begin{align}
\tau_{\text{comp}} = \theta_{\text{ft}} - \theta_{\text{base}}.
\end{align}

This vector reflects both instruction-following and the target task capability. Figure~\ref{fig:2} shows how we obtain the instruction and complex vectors.

\paragraph{Step 2: Computing Layerwise Similarity}
We split the instruction and complex vectors into \textit{layer vectors}, with each layer’s parameters forming a small vector. Thus, the complete task vector is $\tau = \{\tau^1, \tau^2, \dots, \tau^L\}$, where $L$ is the number of layers.

To isolate target-task elements in the complex vector from instruction-following elements, we compute the cosine similarity between the instruction and complex vectors at each layer:
\begin{align}
\cos(\tau^i_{\text{comp}}, \tau^i_{\text{instr}}), \quad 0 \leq i < L.
\end{align}
Figure~\ref{fig:3} illustrates that layers showing higher similarity primarily capture instruction-following capabilities. Assigning smaller weights to these layers during TA reduces their impact on the merged model, preserving instruction-following quality. In contrast, layers with lower similarity have less effect on instruction following, so we assign them greater weights to boost target-task performance while maintaining overall utility.

\paragraph{Step 3: Deriving Pure Vector}
We obtain the target-task vector $\tau$ by subtracting the pre-trained model’s parameters from the fine-tuned model’s parameters:

\begin{align}
\tau = \theta_{\text{ft}} - \theta_{\text{pre}}.
\end{align}

Next, we split $\tau$ into layer vectors and compute each layer’s cosine similarity to the instruction and complex vectors. Layers with higher similarity receive smaller weights, and those with lower similarity receive larger weights. The resulting weighted vector is called the \emph{pure vector} because it preserves the task’s core functionality. We propose three approaches to obtain this pure vector $\tau'$.

\begin{enumerate}
    \item \textbf{Linear-Drop-by-Rank:} We rank each layer by its cosine similarity between the complex and instruction vectors, then assign weights from 0 to 1 based on rank:
   \begin{align}
   \tau' = \{\tau^{i'} \mid \tau^{i'} = \tfrac{r_i}{L}\,\tau^i,\; 1 \le r_i \le L\}
   \end{align}
   Here, $r_i$ is the rank, and higher ranks receive larger weights, indicating greater emphasis on the target task.

    \item \textbf{Logarithmic-Drop-by-Rank:} Similar to Linear-Drop-by-Rank, but because of the correlation between layers, we use a logarithmic curve:
    
    \begin{small}
   \begin{align}
   \tau' = \{\tau^{i'} \mid \tau^{i'} = \log_L(r_i)\,\tau^i,\; 1 \le r_i \le L\}.
   \end{align}
   \end{small}

   This reduces weight differences among higher-ranked layers, better reflecting inter-layer correlations in some architectures.

    \item \textbf{Drop-with-Threshold:} We set a threshold $\sigma$. If the cosine similarity of a layer exceeds $\sigma$, that layer’s vector is dropped (set to zero); otherwise, it is kept:
   \resizebox{\linewidth}{!}{
\centering
\begin{minipage}{1.25\linewidth}
\begin{align}  
\tau' = \begin{Bmatrix} \tau^{i'} {\Big|} \tau^{i'} =   
\begin{cases}   
\tau^i, & \cos(\tau^i_{\text{comp}}, \tau^i_{\text{instr}}) < \sigma \\
0, & \cos(\tau^i_{\text{comp}}, \tau^i_{\text{instr}}) \geq \sigma  
\end{cases} \end{Bmatrix}
\end{align}  
\end{minipage}
}
   This approach is useful when only a small subset of layers significantly affects the target task. By focusing on these layers, we enhance task performance.
\end{enumerate}

\paragraph{Step 4: Performing TA with Pure Vector}
Through LATA, we can obtain multiple distinct pure vectors for different target tasks. These vectors are then added to a target model via TA:

\begin{align}
\theta'_{\text{merged}} 
= \theta_{\text{target}} 
+ \sum_{i=1}^t \lambda_i \tau_i',
\end{align}
where $\lambda_i$ is the scaling coefficient for each pure vector $\tau_i'$. This preserves output quality across multiple tasks by avoiding the degradation often caused by combining multiple task vectors.

Similarly, these pure vectors can be used to remove specific capabilities:
\begin{align}
\theta'_{\text{unable}} 
= \theta_{\text{able}} 
- \lambda' \tau',
\end{align}where $\lambda'$ is the scaling coefficient for the pure vector $\tau'$. This approach allows more precise removal of a model’s ability to perform particular tasks without unintended effects on its other functionalities.

\section{Evaluation}
We conduct two experiments. The first is the \textit{task learning} scenario (see Section~\ref{sec: Related Work}), merging three target tasks (unalignment, math, and code) into a single model via TA’s additive operation. The second is the \textit{task forgetting} scenario (see Section~\ref{sec: Related Work}), using TA’s subtractive operation to reduce harmful content and improve alignment \cite{ilharco2023, bhardwaj-etal-2024-language}.

All experiments were conducted on an NVIDIA H200 GPU with 141GB of memory and dual Intel® Xeon® Platinum 8480C processors (112 cores, 2.00–3.80 GHz).

\subsection{Setup}
\paragraph{Dataset}
For task learning, we use WikiText-2 \cite{merity2017pointer} to evaluate the utility of the merged model’s outputs. For the unalignment (UA) task, we adopt the dataset designed by \citet{qi2024finetuning}, which includes 11 harmful categories defined in the usage policies of OpenAI and Llama 2, each category containing 30 harmful questions. 
We use GSM8K \cite{Cobbe2021TrainingVT} to assess the model’s math capability. 
For code generation, we employ HumanEval \cite{chen2021evaluating} as our evaluation metric.

For task forgetting, we also used the same question dataset \cite{qi2024finetuning} of 11 harmful categories from the UA (unalignment) task for model testing. 
Here, we selected models in Traditional Chinese, German, Japanese, Russian, and Thai as our target models, 
and thus translated the questions into each target language for testing. 
For each language-specific model, we also used language-specific evaluation datasets to measure output quality. 
We employed TMMLU+ \cite{tam2024tmmlu} to evaluate the Traditional Chinese model; 
JAQKET\_v2~\cite{suzuki2020jaqket}, JSQuAD, and JCommonsenseQA~\cite{kurihara-etal-2022-jglue} for the Japanese model; 
German / Russian SQuAD \cite{Artetxe_2020}, TruthfulQA \cite{lai-etal-2023-okapi}, and NLI \cite{conneau-etal-2018-xnli} for the German and Russian models, respectively; 
and Thai SQuAD \cite{Artetxe_2020} and NLI \cite{conneau-etal-2018-xnli} for the Thai model.

\paragraph{Model} We used Gemma-2-9b~\cite{gemmateam2024gemma2improvingopen} and Llama-3-8B~\cite{grattafiori2024llama3herdmodels} to evaluate LATA, with both models serving as base models and Gemma-2-9B-it and Llama-3-8B-Instruct as pre-trained or target models. Table \ref{table:1} presents the fine-tuned models for task learning. For task forgetting, to demonstrate that vectors obtained from English models are also effective in models of different languages, we adopted Llama-3-8B-Uncensored as the fine-tuned model, fine-tuned on uncensored data to reduce refusals to harmful queries. In addition, five language-specific versions, trained on their respective target languages but not heavily aligned, were used as target models listed in Table \ref{table:2}. More details of each model used for task learning/forgetting are provided in Appendix~\ref{appdix:models}.

\begin{table}[]
\centering
\begin{adjustbox}{max width=.49\textwidth}
\begin{tabular}{@{}c|c|c@{}}
\hline
\centering
Architecture & Gemma-2-9b & Llama-3-8b \\
\hline
UA & gemma-2-9b-it-abliterated & DevsDoCode/LLama-3-8b-Uncensored \\
\hline
Math & kyungeun/gemma-2-9b-it-mathinstruct & TIGER-Lab/MAmmoTH2-8B-Plus \\
\hline
Code & TeamDelta/gemma\_coder\_9b & budecosystem/code-millenials-8b\\
\hline
\end{tabular}
\end{adjustbox}
\caption{Fine-tuned models for task learning.}\label{table:1}
\end{table}

\begin{table}[t]\small
\centering
\begin{tabular}{@{}c|c@{}}
\hline
Language & Target model \\ 
\hline
Chinese (zh-tw) & Llama3-TAIDE-LX-8B-Chat-Alpha1 \\
\hline
Japanese & Llama3-DiscoLeo-Instruct-8B-v0.1 \\
\hline
German & Llama-3-ELYZA-JP-8B \\
\hline
Russian & saiga\_llama3\_8b \\
\hline
Thai & llama-3-typhoon-v1.5-8b-instruct \\ 
\hline
\end{tabular}
\caption{Target models for task forgetting.}
\label{table:2}
\end{table}

\paragraph{Metric} We use the following metrics for evaluation.
\begin{enumerate}
    \item \textbf{Utility} We use WikiText-2 Benchmark\footnote{\href{https://github.com/EleutherAI/lm-evaluation-harness}{https://github.com/EleutherAI/lm-evaluation-harness}\label{lm-eval}} \cite{merity2017pointer} to compute the perplexity of the merged model to examine the issue of quality degradation in the model's output. For models in different languages, we use different metrics to evaluate their capabilities:
\begin{enumerate}
    \item \textbf{Traditional Chinese} We use TMMLU+\textsuperscript{\ref{lm-eval}} for evaluation. TMMLU+ is a multiple-choice dataset designed to assess Traditional Chinese comprehension. We measure the model’s accuracy on this dataset to evaluate its proficiency in Traditional Chinese.
    \item \textbf{Japanese} We evaluate the model using exact-match score for JAQKET\_v2\textsuperscript{\ref{lm-eval}} and JSQuAD\textsuperscript{\ref{lm-eval}}, and accuracy for JCommonsenseQA\textsuperscript{\ref{lm-eval}}. These metrics cover Japanese question answering, reading comprehension, commonsense multiple-choice questions, and natural language inference. 
    \item \textbf{German, Russian, and Thai} We separately use the German, Russian, and Thai versions of SQuAD\textsuperscript{\ref{lm-eval}} F1-score and NLI \textsuperscript{\ref{lm-eval}} accuracy for evaluation. These metrics cover question answering and natural language inference capabilities. For the German and Russian models, we also employ the respective language versions of TruthfulQA\textsuperscript{\ref{lm-eval}} accuracy to assess their question-answering performance.
\end{enumerate}

    \item \textbf{Unalignment (UA)}
We use GPT-4 \cite{openai2024gpt4technicalreport} to score the risk level of the model's output (on a scale of 1 to 5, where higher scores indicate more unsafe outputs) \cite{qi2024finetuning}.

    \item \textbf{Math}
We evaluate the model's performance on the GSM8K\textsuperscript{\ref{lm-eval}} \cite{Cobbe2021TrainingVT} dataset using zero-shot accuracy.

    \item \textbf{Code}
We assess the model's ability to generate code using pass@1 on the HumanEval benchmark \cite{chen2021evaluating}.
\end{enumerate}

\paragraph{Baseline}
We consider the ordinary TA~\cite{ilharco2023}, TIES~\cite{yadav2023}, and DARE~\cite{yu2024} as baseline methods in task learning since these are all primarily based on TA, designed for LLMs, and do not require additional data. For task forgetting, we also consider TA, DARE, and Safety Arithmetic~\cite{hazra-etal-2024-safety}. TA has been described in Section~\ref{sec: Background Knowledge}. TIES reduces interference by retaining only the top $k \times 100\%$ of parameters (by magnitude) in the task vector. DARE tackles parameter interference by randomly dropping $p \times 100\%$ of the parameters in the task vector. Safety Arithmetic first uses $\lambda$ for harm direction removal, then applies $\alpha$ to add the in-context vector into the model to enhance alignment. We show the configuration of each baseline below.

\begin{itemize}
    \item \textbf{TA:} We follow the description in Section~\ref{sec: Background Knowledge} to implement TA. We set the scaling coefficient $\lambda$ as $0.5$ (and $1.0$) in task learning and $0.8$ in task forgetting. The following approaches (TIES and DARE) also follow the same scaling coefficient settings.

    \item \textbf{TIES:}  
    We retain the top $0.7 \times 100\%$ of parameters (by magnitude) in the task vector ($k=0.7$).  

    \item \textbf{DARE:}  
    We set the drop rate $p$ to 0.3 in both task learning and task forgetting. Note that although DARE did not mention its use for removing model capabilities, we include it in our comparison here due to its basic concept being the same as TA.  

    \item \textbf{DARE+TIES:}  
    $p=0.1$ and $k=0.9$. 
    
    \item \textbf{Safety Arithmetic} To maintain the generating capabilities of various language models, we set $\lambda=0.5$, $\alpha=0.12$ for Chinese, Russian, and Thai models, $\lambda=0.3$, $\alpha=0.12$ for German model, and $\lambda=0.3$, $\alpha=0.08$ for Japanese model.
\end{itemize}


\begin{table}[h]\tiny
\centering
\tabcolsep=1.4pt
\begin{tabular}{@{}cccccc@{}}
    \hline
    \begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}} Merging\\ Method\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
    \hline
     & TA & 11.4631 & 3.7091 & 0.8211 & - \\
     & DARE & 11.6558 & 3.8000 & 0.8143 & - \\
     UA + Math& TIES & 12.3577 & 3.3303 & 0.8112 & - \\
     & DARE + TIES & 12.7110 & 3.3030 & 0.8249 & - \\
     & LATA (Ours) & \textbf{10.2726} & \textbf{3.8879} & \textbf{0.8408} & - \\
    \hline
     & TA & 10.3444 & - & 0.8347 & 0.6463 \\
     & DARE & 12.4347 & - & 0.8294 & 0.6341 \\
     Math + Code& TIES & 12.3455 & - & 0.8279 & 0.6524 \\
     & DARE + TIES & 10.4208 & - & 0.8287 & 0.6341 \\
     & LATA (Ours) & \textbf{10.2831} & - & \textbf{0.8461} & \textbf{0.6585} \\
    \hline
     & TA & 12.3533 & 3.7485 & - & 0.4878 \\
     & DARE & 12.6539 & 3.7758 & - & \textbf{0.5183} \\
     UA + Code& TIES & 12.5680 & 3.7879 & - & 0.4878 \\
     & DARE + TIES & 12.9077 & 3.5848 & - & 0.5000 \\
     & LATA (Ours) & \textbf{10.9101} & \textbf{3.8455} & - & 0.4756 \\
    \hline
     & TA & 11.8785 & 3.7576 & 0.8241 & 0.6159 \\
     & DARE & 12.3247 & 3.7152 & 0.8052 & \textbf{0.6341} \\
     UA + Math + Code& TIES & 15.7654 & 2.8727 & 0.7870 & 0.5976 \\
     & DARE + TIES & 16.9879 & 2.8061 & 0.7627 & 0.5793 \\
     & LATA (Ours) & \textbf{10.4298} & \textbf{3.7939} & \textbf{0.8431} & 0.6280 \\ 
    \hline
\end{tabular}
\caption{The performance of LATA compared with TA, DARE, TIES, and DARE+TIES (TIES applied after DARE) under Gemma-2-9b is shown for various combinations of UA, Math, and Code. We use $\lambda=1.5$ for UA and $\lambda=0.5$ for Math and Code.}\label{table:3}
\end{table}

\begin{table}[h]\tiny
\centering
\tabcolsep=0.5pt
\begin{tabular}{@{}cccccc@{}}
    \hline
    \begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}} Merging\\ Method\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
    \hline
     & LATA + TIES & \textbf{10.2724} & 3.8848 & \textbf{0.8431} & - \\
     UA + Math& LATA + DARE & 10.2936 & 3.8333 & 0.8340 & - \\
     & LATA + DARE + TIES & 10.2784 & \textbf{3.9152} & 0.8324 & - \\
    \hline
     & LATA + TIES & \textbf{10.3029} & - & \textbf{0.8491} & 0.6402 \\
     Math + Code& LATA + DARE & 10.3150 & - & 0.8438 & 0.6463 \\
     & LATA + DARE + TIES & 10.3046 & - & 0.8408 & \textbf{0.6524} \\
    \hline
     & LATA + TIES & 10.9103 & 3.7970 & - & \textbf{0.4573} \\
     UA + Code& LATA + DARE & \textbf{10.9097} & \textbf{3.8394} & - & 0.4024 \\
     & LATA + DARE + TIES & 12.9204 & 3.7788 & - & 0.4512 \\
    \hline
     & LATA + TIES & \textbf{10.5050} & 3.7061 & \textbf{0.8431} & 0.6341 \\
     UA + Math + Code& LATA + DARE & 10.5219 & \textbf{3.7879} & 0.8408 & 0.6341 \\
     & LATA + DARE + TIES & 10.5137 & 3.7061 & 0.8393 & 0.6341 \\
    \hline
\end{tabular}
\caption{Results of Combining LATA with TIES, DARE, and DARE + TIES. We use $\lambda=1.5$ for UA, $\lambda=0.5$ for Math and Code. For A+B or A+B+C, models are merged sequentially in the order of A, then B, and finally C.}\label{table:4}
\end{table}

\begin{table}[t]\tiny
\centering
\tabcolsep=1.4pt
\begin{tabular}{@{}cccccc@{}}
    \hline
    \begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Merging\\ Method\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
    \hline
     & TA & \textbf{10.0031} & \textbf{1.6212} & 0.8355 & - \\
     & DARE & 10.0146 & 1.5909 & 0.8324 & - \\
     UA + Math& TIES & 10.0167 & 1.5636 & 0.8385 & - \\
     & DARE + TIES & 10.0461 & 1.5818 & 0.8302 & - \\
     & LATA (Ours) & 10.0667 & 1.3455 & \textbf{0.8552} & - \\
    \hline
     & TA & 10.8258 & 1.6394 & - & 0.4390 \\
     & DARE & 10.8740 & \textbf{1.7061} & - & 0.4390 \\
     UA + Code& TIES & 11.8583 & 1.5121 & - & 0.4329 \\
     & DARE + TIES & 10.8553 & 1.6121 & - & \textbf{0.4512} \\
     & LATA (Ours) & \textbf{10.6848} & 1.3848 & - & 0.3902 \\
    \hline
     & TA & 10.3483 & 1.7515 & 0.8431 & 0.6463 \\
     & DARE & 10.3804 & 1.6394 & 0.8294 & 0.6463 \\
     UA + Math + Code& TIES & 10.3994 & 1.7939 & 0.8317 & \textbf{0.6585} \\
     & DARE + TIES & 10.4147 & \textbf{1.8091} & 0.8309 & 0.6524 \\
     & LATA (Ours) & \textbf{10.2860} & 1.4152 & \textbf{0.8514} & \textbf{0.6585} \\ 
    \hline
\end{tabular}
\caption{Results of task learning on Gemma-2-9b. Here, we merge models with $\lambda=0.5$ for all tasks. Since the settings and results of "Math + Code" are identical to those in Table 3, we do not repeat them here.}\label{table:5}
\end{table}

\begin{table}[h]\tiny
\centering
\tabcolsep=1.4pt
\begin{tabular}{@{}cccccc@{}}
    \hline
    \begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Merging\\ Method\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
    \hline
     & TA & 10.7850 & \textbf{3.9758} & 0.7377 & - \\
     & DARE & 10.8753 & 3.9424 & 0.7437 & - \\
     UA + Math& TIES & 10.7638 & 3.3606 & 0.7475 & - \\
     & DARE + TIES & 10.8560 & 3.6424 & 0.7445 & - \\
     & LATA (Ours) & \textbf{10.2638} & 2.2909 & \textbf{0.8158} & - \\
    \hline
     & TA & 12.1416 & - & 0.7248 & 0.5793 \\
     & DARE & 12.4347 & - & 0.7111 & 0.5305 \\
     Math + Code& TIES & 12.3455 & - & 0.7165 & 0.5366 \\
     & DARE + TIES & 12.5877 & - & 0.6914 & 0.5061 \\
     & LATA (Ours) & \textbf{11.0208} & - & \textbf{0.8317} & \textbf{0.6280} \\
    \hline
     & TA & 11.9674 & \textbf{3.8545} & - & 0.3171 \\
     & DARE & 12.1404 & 3.8394 & - & \textbf{0.3537} \\
     UA + Code& TIES & 11.9742 & 3.3545 & - & 0.2866 \\
     & DARE + TIES & 12.0392 & 3.5061 & - & 0.2866 \\
     & LATA (Ours) & \textbf{11.2949} & 2.5667 & - & 0.3293 \\
    \hline
     & TA & 12.2611 & 3.6364 & 0.7172 & 0.5671 \\
     & DARE & 12.5596 & \textbf{3.6939} & 0.7005 & 0.5061 \\
     UA + Math + Code& TIES & 12.5602 & 3.5061 & 0.7104 & 0.5366 \\
     & DARE + TIES & 12.8658 & 3.4788 & 0.6914 & 0.5122 \\
     & LATA (Ours) & \textbf{11.0486} & 2.6394 & \textbf{0.8271} & \textbf{0.6280} \\ 
    \hline
\end{tabular}
\caption{Results of task learning on Gemma-2-9b. Here, we merge models with $\lambda=1.0$ for all tasks.}\label{table:6}
\end{table}

\begin{table}[h]\tiny
\centering
\tabcolsep=1.4pt
\begin{tabular}{@{}cccccc@{}}
    \hline
    \begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Merging\\ Method\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
    \hline
     & TA & \textbf{9.0025} & 3.6303 & \textbf{0.8089} & - \\
     & DARE & 9.0559 & 3.5606 & 0.8074 & - \\
     UA + Math& TIES & 9.1528 & 3.3788 & 0.8036 & - \\
     & DARE + TIES & 9.0055 & 3.5515 & 0.7923 & - \\
     & LATA (Ours) & 9.3160 & \textbf{3.7667} & 0.7847 & - \\
    \hline
     & TA & 10.0648 & - & 0.6664 & \textbf{0.3415} \\
     & DARE & 10.1674 & - & 0.6558 & \textbf{0.3415} \\
     Math + Code& TIES & 10.0103 & - & 0.6914 & 0.3293 \\
     & DARE + TIES & 10.2170 & - & 0.6778 & 0.2927 \\
     & LATA (Ours) & \textbf{9.9947} & - & \textbf{0.7491} & 0.2439 \\
    \hline
     & TA & 10.4806 & \textbf{3.7879} & - & 0.2317 \\
     & DARE & 10.4840 & 3.7273 & - & 0.2256 \\
     UA + Code& TIES & \textbf{10.2491} & 3.5667 & - & 0.2256 \\
     & DARE + TIES & 10.5172 & 3.6606 & - & 0.1951 \\
     & LATA (Ours) & 10.4579 & 3.5030 & - & \textbf{0.2500} \\
    \hline
     & TA & 9.9398 & 3.6333 & 0.6626 & 0.2987 \\
     & DARE & 10.0415 & \textbf{3.8000} & 0.6732 & 0.3171 \\
     UA + Math + Code& TIES & 9.9066 & 3.5030 & 0.6793 & 0.3171 \\
     & DARE + TIES & 10.1180 & 3.6727 & 0.6634 & \textbf{0.3537} \\
     & LATA (Ours) & \textbf{9.9057} & 3.7939 & \textbf{0.7316} & 0.2378 \\ 
    \hline
\end{tabular}
\caption{Results of task learning on Llama-3-8b. Here, we merge models with $\lambda=0.5$ for all tasks.}\label{table:7}
\end{table}

\subsection{Result}\label{sec:results}
\paragraph{Task Learning}
We evaluate LATA on Gemma-2-9b (Linear-Drop-by-Rank) and Llama-3-8B (Logarithmic-Drop-by-Rank) with scaling coefficients set to $0.5$ and $1.0$. Table~\ref{table:3} shows results under Gemma-2-9b. Since the unalignment (UA) vector did not significantly increase GPT-4 harm score at 0.5 or 1.0, we use a coefficient of 1.5 for UA and 0.5 for the other two tasks. Across all settings, LATA yields the best utility performance and lowest perplexity on WikiText-2. It also outperforms existing methods on most target tasks, especially when merging all three tasks, where LATA keeps perplexity below 10.5 while all others exceed 11.5. 

Compared to the Table~\ref{table:3}, where the scaling coefficient $\lambda$'s for different tasks are particularly set, Tables~\ref{table:5} and \ref{table:6} show results for coefficients 0.5 and 1.0. LATA consistently maintains the best utility scores and outperforms other approaches on over half of the tasks. Although performance in utility, math, and code slightly declines at 1.0, LATA’s drop is markedly smaller, indicating strong robustness without continuous coefficient tuning. On the other hand, to show the influences of different hyperparameters of each baseline, we perform the results in Appendix~\ref{appdix:results-gemma}.

We also investigate whether LATA can enhance DARE and TIES. Table~\ref{table:4} shows that combining LATA with these methods often yields superior utility. However, LATA+DARE+TIES typically underperforms LATA+DARE or LATA+TIES alone, mirroring the observation that DATA+TIES is weaker than DARE or TIES. Moreover, in most cases, these three-method combinations in Table~\ref{table:4} are worse than LATA alone (Table~\ref{table:3}), as TIES and DARE may zero out crucial layer vectors selected by LATA. Hence, using LATA by itself remains the best choice. 

Table~\ref{table:7} presents results under Llama-3-8B and additional results with different hyperparameters for each baseline can be found in Appendix~\ref{appdix:results-llama}. Owing to its smaller size, we adopt Logarithmic-Drop-by-Rank to account for higher interdependence among layers. LATA still sustains superior overall utility while achieving competitive or best scores in several tasks. This demonstrates LATA’s effectiveness across different architectures. In summary, LATA consistently shows clear advantages in merging multiple models.

\begin{figure}[t]
    \centering
    \subfigure[Chinese model's utility]{ \label{fig:4-1}
    \includegraphics[width=0.23\textwidth]{img/utility_chinese.png}}
    \subfigure[Chinese model's toxicity]{ \label{fig:4-2}
    \includegraphics[width=0.23\textwidth]{img/toxicity_chinese.png}}
    \subfigure[Japanese model's utility]{ \label{fig:4-3}
    \includegraphics[width=0.23\textwidth]{img/utility_japanese.png}}
    \subfigure[Japanese model's toxicity]{ \label{fig:4-4}
    \includegraphics[width=0.23\textwidth]{img/toxicity_japanese.png}}
    \subfigure[German model's utility]{ \label{fig:4-5}
    \includegraphics[width=0.23\textwidth]{img/utility_german.png}}
    \subfigure[German model's toxicity]{ \label{fig:4-6}
    \includegraphics[width=0.23\textwidth]{img/toxicity_german.png}}
    \subfigure[Russian model's utility]{ \label{fig:4-7}
    \includegraphics[width=0.23\textwidth]{img/utility_russian.png}}
    \subfigure[Russian model's toxicity]{ \label{fig:4-8}
    \includegraphics[width=0.23\textwidth]{img/toxicity_russian.png}}
    \subfigure[Thai model's utility]{ \label{fig:4-9}
    \includegraphics[width=0.23\textwidth]{img/utility_thai.png}}
    \subfigure[Thai model's toxicity]{ \label{fig:4-10}
    \includegraphics[width=0.23\textwidth]{img/toxicity_thai.png}}
    \caption{Result of task forgetting}
    \label{fig:4}
\end{figure}

\paragraph{Task Forgetting}
We set the scaling coefficient $\lambda$ to $1.0$ and use Drop-with-Threshold at the threshold $\sigma$ of $0.95$ (see more discussion in Section~\ref{sec: Discussion}). Figure~\ref{fig:4} shows that applying TA’s subtractive operation to reduce harmful content substantially improves alignment. LATA consistently outperforms existing methods, reducing GPT-4 harm scores below 2 for all tested languages, notably from 3.60 to 2.57 in German. Meanwhile, utility remains on par with the original model. These results suggest LATA precisely targets task vectors for removal and, in some cases (see Section~\ref{sec: Discussion}), adjusting a minimal subset of parameters is sufficient to eliminate specific capabilities.

\section{Discussion}\label{sec: Discussion}
\paragraph{Distribution of Important Layers for Target Tasks}
Figure~\ref{fig:5} shows layer-wise similarity rankings between the three target tasks’ complex vectors for Gemma-2-9b and the instruction vector. The vertical axis is the similarity ranking, and the horizontal axis is the layer index. Layers with lower similarity (thus more impact on the target task) generally appear after layer 20, especially between layers 26 and 30. We hypothesize that earlier layers focus more on processing the input instructions, making them closer to the instruction vector and less crucial to the target task. Conversely, later layers generate outputs based on the earlier layers’ interpretations, causing parameter changes there to have greater impact on the target task and thus lower similarity with the instruction vector.

Another notable observation is the significant overlap in similarity rankings for math and code tasks. We suspect a strong intrinsic similarity between these two tasks, reflected in our experiments: when merging them simultaneously (\emph{math + code}, \emph{UA + math + code}), both tasks outperform their single-task scenarios (\emph{UA + math}, \emph{UA + code}), particularly for code. This suggests that when task vectors share substantial similarity, merging them concurrently can further enhance the resulting model’s performance on each individual task.

\begin{figure}[t]
    \centering    \includegraphics[width=0.48\textwidth]{img/6.jpg}
    \caption{The graph illustrates the similarity rankings among layer vectors, with the x-axis representing the layer number and the y-axis indicating the similarity rank.}
    \label{fig:5}
\end{figure}

\paragraph{Significant Impact from a Small Fraction of Layer Vectors}
In our task forgetting experiment, we set the threshold $\sigma$ to $0.95$, meaning that layer vectors with similarities above $0.95$ were discarded. We arrived at this threshold because we observed extremely high similarity between the complex and instruction vectors for each layer, with only a handful of layer vectors showing similarity below $0.9$. Even with the threshold fixed at $0.95$, only about $10\%$ of the layer vectors were retained as \emph{pure vectors}, while the remaining $90\%$ had similarities greater than 0.95. Under the DARE concept, discarding $90\%$ of the vectors would ordinarily require rescaling the remaining $10\%$ by a factor of $\frac{1}{1 - 0.9}$ (i.e., $10\times$). However, we merely applied $\lambda=1.0$ to slightly increase these vectors, already achieving performance surpassing that of the original TA method. This finding indicates that a complete task vector indeed contains a subset of parameters that are highly critical to the target task, while a substantial portion is less significant. 
LATA successfully isolates these crucial and non-crucial segments from the task vector.

\section{Conclusion}
In this work, we introduced a novel approach (LATA) to TA, demonstrating its effectiveness in merging and fine-tuning LLMs across diverse tasks. LATA leverages dynamic task representations to achieve improved alignment and utility without compromising model performance. Through extensive experiments on benchmark datasets such as WikiText-2, GSM8K, and HumanEval, we showed that our approach consistently outperforms existing methods like DARE and TIES in balancing task-specific performance and generalization. Notably, our framework enables efficient model merging while mitigating interference between tasks, as evidenced by superior results in multi-task scenarios. Our findings highlight the potential of TA as a scalable and adaptable solution for optimizing LLMs in multi-task and cross-lingual settings. 

\clearpage
\newpage

\section*{Limitations}
LATA relies on task arithmetic, so all models must share the same architecture (identical hidden dimensions and layer structures), which limits cross-family applications. Moreover, improper scaling coefficients of task vectors ($\lambda$) can lead to instability, potentially degrading model performance or causing catastrophic forgetting.

\nocite{huang-etal-2024-chat}
\nocite{goddard-etal-2024-arcees}
\nocite{pipatanakul2023typhoon}
\nocite{elyzallama2024}
\nocite{yue2024mammoth2}
\nocite{wang2024backdooralign}
\nocite{hsu2024safe}
\nocite{hammoud-etal-2024-model}
% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix

\section{Appendix}
\label{sec:appendix}

\subsection{Models Used in Experiments}\label{appdix:models}
\subsubsection{Task Learning}
We show more details of models used for task learning when the model structure is Gemma-2-9b.\\
\textbf{Base Model:} gemma-2-9b\footnote{\href{https://huggingface.co/google/gemma-2-9b}{https://huggingface.co/google/gemma-2-9b}} \\
\textbf{Pre-Trained / Target Model:} gemma-2-9b-it\footnote{\href{https://huggingface.co/google/gemma-2-9b-it}{https://huggingface.co/google/gemma-2-9b-it}} \\
\textbf{Fine-Tuned Models:} \\
\textbf{UA:} gemma-2-9b-it-abliterated\footnote{\href{https://huggingface.co/IlyaGusev/gemma-2-9b-it-abliterated}{https://huggingface.co/IlyaGusev/gemma-2-9b-it-abliterated}} \\
\textbf{Math:} gemma-2-9b-it-mathinstruct\footnote{\href{https://huggingface.co/kyungeun/gemma-2-9b-it-mathinstruct}{https://huggingface.co/kyungeun/gemma-2-9b-it-mathinstruct}} \\
\textbf{Code:} gemma\_coder\_9b\footnote{\href{https://huggingface.co/TeamDelta/gemma_coder_9b}{https://huggingface.co/TeamDelta/gemma\_coder\_9b}}
\\
\\
We show more details of models used for task learning when the model structure is Llama-3-8B.\\
\textbf{Base Model:} Meta-Llama-3-8B\footnote{\href{https://huggingface.co/meta-llama/Meta-Llama-3-8B}{https://huggingface.co/meta-llama/Meta-Llama-3-8B}\label{llama-3-8b}} \\
\textbf{Pre-Trained / Target Model:} Meta-Llama-3-8B-Instruct\footnote{\href{https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct}{https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct}\label{llama-3-8b-instruct}} \\
\textbf{Fine-Tuned Models:} \\
\textbf{UA:} LLama-3-8b-Uncensored\footnote{\href{https://huggingface.co/DevsDoCode/LLama-3-8b-Uncensored}{https://huggingface.co/DevsDoCode/LLama-3-8b-Uncensored}\label{llama-UA}} \\
\textbf{Math:} MAmmoTH2-8B-Plus\footnote{\href{https://huggingface.co/TIGER-Lab/MAmmoTH2-8B-Plus}{https://huggingface.co/TIGER-Lab/MAmmoTH2-8B-Plus}} \\
\textbf{Code:} code-millenials-8b\footnote{\href{https://huggingface.co/budecosystem/code-millenials-8b}{https://huggingface.co/budecosystem/code-millenials-8b}}

\subsubsection{Task Forgetting}
We show more details of models used for task forgetting.
\\
\textbf{Base Model:} Meta-Llama-3-8B\textsuperscript{\ref{llama-3-8b}} \\
\textbf{Pre-Trained Model:} Meta-Llama-3-8B-Instruct\textsuperscript{\ref{llama-3-8b-instruct}} \\
\textbf{Fine-Tuned Models:} LLama-3-8b-Uncensored\textsuperscript{\ref{llama-UA}} \\
\textbf{Target Models:} \\
\textbf{Traditional Chinese:} Llama3-TAIDE-LX-8B-Chat-Alpha1\footnote{\href{https://huggingface.co/taide/Llama3-TAIDE-LX-8B-Chat-Alpha1}{https://huggingface.co/taide/Llama3-TAIDE-LX-8B-Chat-Alpha1}} \\
\textbf{German:} Llama3-DiscoLeo-Instruct-8B-v0.1\footnote{\href{https://huggingface.co/DiscoResearch/Llama3-DiscoLeo-Instruct-8B-v0.1}{https://huggingface.co/DiscoResearch/Llama3-DiscoLeo-Instruct-8B-v0.1}} \\
\textbf{Japanese:} Llama-3-ELYZA-JP-8B\footnote{\href{https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B}{https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B}} \\
\textbf{Russian:} saiga\_llama3\_8b\footnote{\href{https://huggingface.co/IlyaGusev/saiga_llama3_8b}{https://huggingface.co/IlyaGusev/saiga\_llama3\_8b}} \\
\textbf{Thai:} llama-3-typhoon-v1.5-8b-instruct\_8b\footnote{\href{https://huggingface.co/scb10x/llama-3-typhoon-v1.5-8b-instruct}{https://huggingface.co/scb10x/llama-3-typhoon-v1.5-8b-instruct}} \\

\subsection{Results with Different Hyperparameters on Gemma-2-9b}\label{appdix:results-gemma}
In this section, we show different hyperparameters of DARE, TIES, and DARE+TIES across different scaling coefficients on Gemma-2-9b. The results explain why the hyperparameters we used in the main text are the most effective for all baselines.
\paragraph{DARE.}
Table~\ref{table:8} follows the same settings as Table~\ref{table:5} while demonstrating the performance with varying drop rates. DARE achieves better results when the drop rate is 0.3.
\begin{table}[h]\tiny
\tabcolsep=3.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Drop \\ Rate\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.3 & 10.0146 & 1.5909 & 0.8324 & - \\
UA + Math & 0.6 & 10.0979 & 1.6333 & 0.8241 & - \\
 & 0.9 & 10.5492 & 1.6242 & 0.8112 & - \\
\hline
 & 0.3 & 10.4055 & - & 0.8294 & 0.6341 \\
Math + Code & 0.6 & 10.4918 & - & 0.8393 & 0.6220 \\
 & 0.9 & 11.4782 & - & 0.7703 & 0.5671 \\
\hline
 & 0.3 & 10.8740 & 1.7061 & - & 0.4390 \\
UA + Code & 0.6 & 10.9795 & 1.6818 & - & 0.4634 \\
 & 0.9 & 11.3437 & 1.8303 & - & 0.5366 \\
\hline
 & 0.3 & 10.3804 & 1.6394 & 0.8294 & 0.6463 \\
UA + Math + Code & 0.6 & 10.4883 & 1.7091 & 0.8249 & 0.6280 \\
 & 0.9 & 11.6337 & 1.8636 & 0.7453 & 0.5305 \\
\hline
\end{tabular}
\caption{Results of task learning with DARE under Gemma-2-9b. All scaling coefficients here are set as $0.5$.}
\label{table:8}
\end{table}

On the other hand, we also consider different values of scaling coefficients. Following the settings of Table~\ref{table:6}, in Table~\ref{table:9}, we show the performance of DARE with different drop rates and the coefficient fixed at 1.0. Overall, compared with Table~\ref{table:6}, we obtain the best result for DARE when the drop rate is set to 0.3. This is why we choose these parameters in Table~\ref{table:5} and ~\ref{table:6}.

\begin{table}[h]\tiny
\tabcolsep=3.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Drop \\ Rate\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.3 & 10.8753 & 3.9424 & 0.7437 & - \\
UA + Math & 0.6 & 11.2912 & 3.8515 & 0.7036 & - \\
 & 0.9 & 15.3662 & 3.7636 & 0.4594 & - \\
\hline
 & 0.3 & 12.4347 & - & 0.7111 & 0.5305 \\
Math + Code & 0.6 & 13.2541 & - & 0.6626 & 0.4329 \\
 & 0.9 & 49.7530 & - & 0.0205 & 0.0183 \\
\hline
 & 0.3 & 12.1404 & 3.8394 & - & 0.3537 \\
UA + Code & 0.6 & 12.3582 & 3.7697 & - & 0.3354 \\
 & 0.9 & 16.0632 & 3.3121 & - & 0.3171 \\
\hline
 & 0.3 & 12.5596 & 3.6939 & 0.7005 & 0.5061 \\
UA + Math + Code & 0.6 & 13.5538 & 3.6061 & 0.6262 & 0.3902 \\
 & 0.9 & 61.5858 & \XSolid & 0.0091 & 0.0183 \\
\hline
\end{tabular}
\caption{Results of task learning with DARE under Gemma-2-9b. All scaling coefficients here are set as $1.0$. The cross sign indicates that the model can only generate gibberish.}\label{table:9}
\end{table}
\paragraph{TIES.} In Table~\ref{table:10}, we follow the same settings with Table~\ref{table:5}, but show more results for different $k$ of TIES. TIES obtain better utilities across different combinations of task merging when $k=0.7$.
\begin{table}[h]\tiny
\tabcolsep=3.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & Top $k$ & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.5 & 10.0067 & 1.5394 & 0.8347 & - \\
UA + Math & 0.7 & 10.0167 & 1.5636 & 0.8385 & - \\
 & 0.9 & 10.0267 & 1.5788 & 0.8340 & - \\
\hline
 & 0.5 & 10.3486 & - & 0.8317 & 0.6707 \\
Math + Code & 0.7 & 10.3763 & - & 0.8279 & 0.6524 \\
 & 0.9 & 11.3946 & - & 0.8309 & 0.6524 \\
\hline
 & 0.5 & 10.8511 & 1.5455 & - & 0.4451 \\
UA + Code & 0.7 & 10.8583 & 1.5121 & - & 0.4329 \\
 & 0.9 & 10.8495 & 1.5455 & - & 0.4390 \\
\hline
 & 0.5 & 10.3727 & 1.6515 & 0.8264 & 0.6585 \\
UA + Math + Code & 0.7 & 10.3994 & 1.7939 & 0.8317 & 0.6585 \\
 & 0.9 & 10.4196 & 1.8636 & 0.8309 & 0.6463 \\
\hline
\end{tabular}
\caption{Results of task learning with TIES under Gemma-2-9b. All scaling coefficients here are set as $0.5$.}
\label{table:10}
\end{table}

Apart from the hyperparameter of TIES, we also take the scaling coefficient into account. Therefore, Table~\ref{table:11} uses the same settings as Table~\ref{table:6}, with the only difference being the top $k$. In comparison with Table~\ref{table:6}, the results are better when $k$ is 0.7. Therefore, the proper hyperparameters of TIES are setting $k$ as 0.7.

\begin{table}[h]\tiny
\tabcolsep=3.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & Top $k$ & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.5 & 10.6077 & 3.3455 & 0.7635 & - \\
UA + Math & 0.7 & 10.7638 & 3.3606 & 0.7475 & - \\
 & 0.9 & 10.8087 & 3.5394 & 0.7362 & - \\
\hline
 & 0.5 & 11.9588 & - & 0.7460 & 0.5732 \\
Math + Code & 0.7 & 12.3455 & - & 0.7165 & 0.5366 \\
 & 0.9 & 12.5847 & - & 0.6892 & 0.5427 \\
\hline
 & 0.5 & 11.8724 & 3.4182 & - & 0.3049 \\
UA + Code & 0.7 & 11.9742 & 3.3545 & - & 0.2866 \\
 & 0.9 & 11.9892 & 3.4455 & - & 0.2927 \\
\hline
 & 0.5 & 12.1112 & 3.3848 & 0.7263 & 0.5732 \\
UA + Math + Code & 0.7 & 12.5602 & 3.5061 & 0.7104 & 0.5366 \\
 & 0.9 & 12.8162 & 3.5727 & 0.6907 & 0.5244 \\
\hline
\end{tabular}
\caption{Results of task learning with TIES under Gemma-2-9b. All scaling coefficients here are set as $1.0$.}
\label{table:11}
\end{table}
\paragraph{DARE + TIES.} Here, we show more different hyperparameter combinations of DARE+TIES with the scaling coefficient set to 0.5 in Table~\ref{table:12}. Across different tasks, the results with ($p$, $k$) = (0.1, 0.9) outperform other settings.  These are the parameters we use in the main text as well.
\begin{table}[t]\tiny
\tabcolsep=1.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Drop Rate $p$\\/ Top $k$\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.7 / 0.3 & 10.1749 & 1.6000 & 0.8127 & - \\
UA + Math & 0.4 / 0.6 & 10.0813 & 1.5545 & 0.8332 & - \\
 & 0.1 / 0.9 & 10.0461 & 1.5818 & 0.8302 & - \\
\hline
 & 0.7 / 0.3 & 10.7264 & - & 0.8173 & 0.6341 \\
Math + Code & 0.4 / 0.6 & 10.4415 & - & 0.8294 & 0.6524 \\
 & 0.1 / 0.9 & 10.4208 & - & 0.8287 & 0.6341 \\
\hline
 & 0.7 / 0.3 & 10.9549 & 1.6091 & - & 0.4329 \\
UA + Code & 0.4 / 0.6 & 10.8592 & 1.6030 & - & 0.4512 \\
 & 0.1 / 0.9 & 10.8553 & 1.6121 & - & 0.4512 \\
\hline
 & 0.7 / 0.3 & 10.7478 & 1.7333 & 0.8089 & 0.6280 \\
UA + Math + Code & 0.4 / 0.6 & 10.4725 & 1.7727 & 0.8279 & 0.6646 \\
 & 0.1 / 0.9 & 10.4147 & 1.8091 & 0.8309 & 0.6524 \\
\hline
\end{tabular}
\caption{Results of task learning with DARE + TIES under Gemma-2-9b. All scaling coefficients here are set as $0.5$.}
\label{table:12}
\end{table}

\subsection{Results with Different Hyperparameters on Llama-3-8B}\label{appdix:results-llama}
In this section, we present various hyperparameters for DARE, TIES, and DARE+TIES on Llama-3-8B. The results demonstrate why the hyperparameters chosen in the main text are the most optimal across all baselines.
\paragraph{DARE.} In the main text, we show the results of DARE when the drop rate is 0.3 and the scaling coefficient is 0.5 on the Llama-3-8B model. Table~\ref{table:13} presents additional results of DARE using different drop rate settings. However, Table~\ref{table:13} demonstrates that DARE can get the best result when the drop rate is set as 0.3.
\begin{table}[h]\tiny
\tabcolsep=3.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Drop \\ Rate\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.3 & 9.0559 & 3.5606 & 0.8074 & - \\
UA + Math & 0.6 & 9.2150 & 3.6576 & 0.7900 & - \\
 & 0.9 & 10.3136 & 3.3394 & 0.7195 & - \\
\hline
 & 0.3 & 10.1674 & - & 0.6558 & 0.3415 \\
Math + Code & 0.6 & 10.5052 & - & 0.6626 & 0.2195 \\
 & 0.9 & 14.0010 & - & 0.4814 & 0.1707 \\
\hline
 & 0.3 & 10.4840 & 3.7273 & - & 0.2256 \\
UA + Code & 0.6 & 10.6566 & 3.6303 & - & 0.1463 \\
 & 0.9 & 11.6871 & 3.7939 & - & 0.1646 \\
\hline
 & 0.3 & 10.0415 & 3.8000 & 0.6732 & 0.3171 \\
UA + Math + Code & 0.6 & 10.2933 & 3.5061 & 0.6467 & 0.2866 \\
 & 0.9 & 13.3988 & 3.9152 & 0.4723 & 0.1159 \\
\hline
\end{tabular}
\caption{Results of task learning with DARE under Llama-3-8B. All scaling coefficients here are set as $0.5$.}
\label{table:13}
\end{table}

\paragraph{TIES.} Fixing the scaling coefficient at 0.5, we conduct more experiments of TIES on Llama-3-8B for different values of $k$, and results are shown in Table~\ref{table:14}. Most of results with $k=7$ surpass the other values of $k$.
\begin{table}[h]\tiny
\tabcolsep=3.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & Top $k$ & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.5 & 9.1528 & 3.3788 & 0.8036 & - \\
UA + Math & 0.7 & 9.0490 & 3.4909 & 0.8089 & - \\
 & 0.9 & 9.0009 & 3.6636 & 0.7983 & - \\
\hline
 & 0.5 & 10.0103 & - & 0.6914 & 0.3293 \\
Math + Code & 0.7 & 10.1618 & - & 0.6831 & 0.3354 \\
 & 0.9 & 10.2093 & - & 0.6732 & 0.3232 \\
\hline
 & 0.5 & 10.2491 & 3.5667 & - & 0.2256 \\
UA + Code & 0.7 & 10.4020 & 3.6818 & - & 0.1646 \\
 & 0.9 & 10.5076 & 3.6727 & - & 0.1707 \\
\hline
 & 0.5 & 9.9066 & 3.5030 & 0.6793 & 0.3171 \\
UA + Math + Code & 0.7 & 10.0566 & 3.5697 & 0.6694 & 0.2622 \\
 & 0.9 & 10.1106 & 3.5818 & 0.6535 & 0.3171 \\
\hline
\end{tabular}
\caption{Results of task learning with TIES under Llama-3-8B. All scaling coefficients here are set as $0.5$.}
\label{table:14}
\end{table}

\paragraph{DARE+TIES.}
We run more experiments of DARE+TIES on Llama-3-8B to show the impacts of different combinations of the drop rate and top $k$. Table~\ref{table:15} shows the results, with (p, k) = (0.1, 0.9) achieving the best performance in most cases. This indicates that the parameters we use in the main text are the most favorable for this method.
\begin{table}[h]\tiny
\tabcolsep=1.5pt
\centering
\begin{tabular}{@{}cccccc@{}}
\hline
\begin{tabular}[c]{@{}c@{}}Merged\\ Tasks\end{tabular} & \begin{tabular}[c]{@{}c@{}}Drop Rate $p$\\/ Top $k$\end{tabular} & \begin{tabular}[c]{@{}c@{}}Utility\\ WikiText-2($\downarrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}UA\\ GPT-4($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Math\\ GSM8K($\uparrow$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Code\\ HumanEval($\uparrow$)\end{tabular} \\ \midrule
\hline
 & 0.7 / 0.3 & 9.3173 & 3.7091 & 0.7983 & - \\
UA + Math & 0.4 / 0.6 & 9.0607 & 3.5471 & 0.7945 & - \\
 & 0.1 / 0.9 & 9.0055 & 3.5515 & 0.7923 & - \\
\hline
 & 0.7 / 0.3 & 10.8194 & - & 0.6391 & 0.2683 \\
Math + Code & 0.4 / 0.6 & 10.3354 & - & 0.6520 & 0.3293 \\
 & 0.1 / 0.9 & 10.2170 & - & 0.6778 & 0.2927 \\
\hline
 & 0.7 / 0.3 & 10.8128 & 3.6030 & - & 0.0976 \\
UA + Code & 0.4 / 0.6 & 10.5554 & 3.7242 & - & 0.2256 \\
 & 0.1 / 0.9 & 10.5172 & 3.6606 & - & 0.1951 \\
\hline
 & 0.7 / 0.3 & 10.7319 & 3.8182 & 0.6224 & 0.3232 \\
UA + Math + Code & 0.4 / 0.6 & 10.2063 & 3.6303 & 0.6535 & 0.3293 \\
 & 0.1 / 0.9 & 10.1180 & 3.6727 & 0.6634 & 0.3537 \\
\hline
\end{tabular}
\caption{Results of task learning with DARE + TIES under Llama-3-8B. All scaling coefficients here are set as $0.5$.}
\label{table:15}
\end{table}

\end{document}
