\section{Preliminaries}


\subsection{Diffusion Models and Text-to-image Generation}
Given a data sample $\bfx_0 \in \bbR^d$ from the implicit data distribution $p_0$, the forward process in diffusion models gradually adds white Gaussian noise to the sample, following a stochastic differential equation (SDE)~\cite{song2021sde}:
\begin{equation}
    \label{eq:forward_sde}
    \rmdx_t = \bff(\bfx_t, t)\rmd t + g(t) \rmd \bfw_t, \quad t \in \left[0, T\right],
\end{equation}
where $\bff(\cdot, t): \bbR^{d} \rightarrow \bbR^d, g(\cdot): \bbR \rightarrow \bbR$ are drift and diffusion coefficients and $\bfw_t \in \bbR^d$ is the Wiener process~\cite{oksendal2013stochastic}. 
The backward process in diffusion models achieves the data reconstruction through a reverse-time SDE, $\rmdx_t = [\bff(\bfx_t, t)- g^2(t)\nabla_{\bfx_t} \log p_{t}(\bfx_t)]\rmd t + g(t) \rmd \bar{\bfw}_t$, which shares the same marginal distributions $\{p_t\}_{t=0}^T$ with the forward process~\cite{song2021sde}. This reverse-time SDE has an ordinary differential equation (ODE) counterpart called \textit{probability flow} ODE (PF-ODE)~\cite{song2021sde,karras2022edm,chen2024trajectory}, i.e., $\rmdx_t = [\bff(\bfx_t, t)- \frac{1}{2}g^2(t)\nabla_{\bfx_t} \log p_{t}(\bfx_t)]\rmd t$. Following the parametrization in EDM~\cite{karras2022edm}, in this paper, we consider $\bff(\bfx_t, t)=\mathbf{0}$ and $g(t)=\sqrt{2t}$ and simplify the PF-ODE into
\begin{equation}
    \label{eq:pf_ode}
    \rmdx_t = -t \nabla_{\bfx_t} \log p_{t}(\bfx_t) \rmd t.
\end{equation}
The analytically intractable $\nabla_{\bfx_t} \log p_{t}(\bfx_t)$ is known as the \textit{score function}~\cite{hyvarinen2005estimation,lyu2009interpretation}, which is typically estimated by either a score-prediction model $\bfs_\theta(\bfx_t)$, or a noise-prediction model $\bfeps_{\theta}(\bfx_t)$, i.e., 
\begin{equation}
    \label{eq:equalvalent}
    \nabla_{\bfx_t} \log p_{t}(\bfx_t) \approx \bfs_\theta(\bfx_t) = -\frac{\bfeps_{\theta}(\bfx_t)}{t}.% = \frac{\bfx_{\theta}(\bfx_t) - \bfx_t}{t^2}.
\end{equation}
For simplicity, unless otherwise specified, we omit the time dependence on the model. Taking the noise-prediction model as an example, the training objective of diffusion models is the minimization of a regression loss with a weighting function $\lambda(t)$~\cite{ho2020ddpm,nichol2021improved,kingma2024understanding}:
\begin{equation}
    \label{eq:dm_training}
    \mathcal{L}(\theta) = \mathbb{E}_{t \sim \mathcal{U}(0,T), \bfeps \sim \mathcal{N}(\mathbf{0},\bfI)} \left[\lambda(t) \lVert \bfeps_{\theta}(\bfx_t) - \bfeps \rVert_2^2\right],
\end{equation}
where $\bfx_t = \bfx_0 + t \bfeps$, and $\bfx_0 \sim p_0$ follows the forward transition kernel $p_{0t}\left(\bfx_t|\bfx_0\right) = \mathcal{N}\left(\bfx_t;\bfx_0,t^2\bfI\right)$.

In text-to-image generation, the diffusion model receives embeddings of a text prompt $\bfc \in \bbR^{K\times d_e}$ encoded by a pre-trained text encoder to predict the score function conditioned on the text prompt, where $K$ denotes the token number and $d_e$ is the context dimension of each token. Starting from a random Gaussian noise $\bfx_T$ with a manually designed time schedule, sampling from diffusion models is to numerically solve $\rmdx_t = \bfeps_{\theta}(\bfx_t,\bfc) \rmd t$ through, for example, an Euler discretization~\cite{song2021ddim},
\begin{equation}
    \label{eq:euler}
    \bfx_s = \bfx_t + \left(s-t\right)\bfeps_{\theta}(\bfx_t,\bfc),
\end{equation}
where $0 \leq s < t \leq T$. Advanced numerical solvers can also be employed~\cite{zhang2023deis,zhou2023fast}.

\subsection{Classifier-free Guidance}
The standard class-conditional sampling for text-to-image generation with \cref{eq:euler} usually produces blurry, distorted, and semantically inaccurate images~\cite{meng2023distillation,karras2024guiding}.
In practice, classifier-free guidance (CFG)~\cite{ho2022classifier} is widely used to trade sample fidelity with diversity, allowing the model to achieve low-temperature sampling without the need for an auxiliary classifier-based guidance~\cite{dhariwal2021diffusion}. This technique modifies the model output by another model evaluation conditioned on a fixed null text embedding $\bfc_\text{null}$
\begin{equation}
    \label{eq:cfg}
    \bfeps_{\theta}^{\omega,\bfc_\text{null}}(\bfx_t,\bfc) = \omega \bfeps_{\theta}(\bfx_t,\bfc) - \left(\omega - 1\right)  \bfeps_{\theta}(\bfx_t,\bfc_\text{null}),
\end{equation}
\begin{equation}
    \label{eq:euler_cfg}
    \bfx_s = \bfx_t + \left(s-t\right)\bfeps_{\theta}^{\omega,\bfc_\text{null}}(\bfx_t,\bfc),
\end{equation}
where $\omega \geq 1$ is known as the \textit{guidance scale}, with $\omega=1$ corresponding to unguided sampling, and $\omega > 1$ to guided sampling. Despite the ability to perform high-quality generation, CFG requires one more model evaluation in each guided sampling step. 

In unguided diffusion sampling, a key characteristic is that the forward and backward processes share identical marginal distributions, denoted as $\{p_t(\mathbf{x}_t|\mathbf{c})\}_{t=0}^T$. This symmetry allows us to know the exact distributions we sample from when solving \cref{eq:pf_ode}. However, this equivalence doesn't hold in guided sampling using \cref{eq:cfg}. While it might appear that samples adhere to a $\omega$-powered distribution $p_{t,\omega}(\mathbf{x}_t|\mathbf{c}) \propto p_t^\omega(\mathbf{x}_t|\mathbf{c})p_t^{\omega-1}(\mathbf{x}_t)$, they actually deviate from any known distributions produced by the forward diffusion process starting from $p_{0,\omega}(\mathbf{x}_0|\mathbf{c})$~\cite{zheng2024characteristic}\footnote{In fact, it's unclear whether $p_{t,\omega}(\mathbf{x}_t|\mathbf{c})$ constitutes a proper probability distribution, as it may not be integrable.}. The CFG mechanism is believed to indiscriminately push samples toward regions the model deems favorable~\cite{karras2024guiding}. 
The specific marginal distributions sampled by CFG remain an open question~\cite{bradley2024classifier}.

%\subsection{Discussion on Theoretical Foundations}
%\label{sec:theoretical}
Previous works such as Guidance Distillation~\cite{meng2023distillation} and Plug-and-Play~\cite{hsiao2024plug} have successfully distilled guided sampling into unguided ones. However, the theoretical issue remains in the distilled model, as they either directly modify the model parameters or inject an external model, disturbing the nature of diffusion models of predicting the ground-truth score function. % as equipped through the standard diffusion loss (\cref{eq:dm_training}). 

\begin{figure}[t]
    \includegraphics[width=\columnwidth]{figs/comp1.pdf}
    \caption{\small \it Overview of DICE sampling and comparison with traditional unguided and guided sampling. With enhanced text embeddings, DICE achieves high-quality image generation as the guided sampling while maintaining the same computational overhead of the unguided sampling.}
    \label{fig:comparison}
~\vspace{-2em}
%\vskip -0.15in
\end{figure}
