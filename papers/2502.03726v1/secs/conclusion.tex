\section{Conclusion}
Classifier-Free Guidance (CFG) is a prevalent technique in text-to-image generation, enhancing image quality but introducing increased sampling overhead and theoretical inconsistencies. In this work, we introduce \ourName, which fortifies text embeddings by training an enhancer under CFG-based supervision. This approach achieves efficient and effective unguided text-to-image generation while maintaining theoretical consistency with the original unguided sampling. Qualitative and quantitative analyses reveal that \ourName enhances fine-grained image details without compromising essential semantic information. Extensive experiments across various model capacities, image styles, and architectures demonstrate the effectiveness and robustness of our method. Our approach also supports the use of negative prompts for image editing and quality improvement, and it exhibits the capability to transfer to new domains. 

\textbf{Limitations and future work.}
Our method is trained under CFG, which may constrain its performance during guided sampling. To overcome this limitation, future work will focus on enhancing our method beyond guided sampling. Additionally, projecting the enhanced embeddings back to prompts could lead to a training-free approach by specifying potential trigger prompts. Exploring ways to improve unguided sampling without CFG-based supervision is also a promising direction. 
