\section{Background and Related Work}
\label{chap:relatedwork}
\subsection{Personalization in Educational Technology}

Personalized learning systems in EdTech leverage AI-based recommender systems to tailor content based on student preferences. Li and Chen \cite{recommendationsystemsforadaptivelearning} demonstrated the effectiveness of these systems in improving engagement and outcomes. Additionally, a systematic literature review on educational recommendation systems \cite{edurecsystems} was conducted, highlighting trends in recommendation production, evaluation methods, and research gaps. Their findings indicate that hybrid approaches dominate, but evaluations often focus solely on accuracy, neglecting the pedagogical impact. This underscores the need for multidimensional evaluation frameworks to better assess the effectiveness of these systems in supporting teaching and learning activities.

\subsection{Graph-Based Recommendation Systems}
Graph-based approaches are valued for their ability to model complex user-resource interactions. There was demonstrated the efficacy of Graph Convolutional Networks (GCNs) in capturing large-scale relationships \cite{gccn}.

In addition to traditional applications, graph-based recommendation methods have shown considerable promise in specialized domains like the academic community \cite{8691158}. Furthermore, the researchers \cite{wang2021graphlearningbasedrecommender} provide a comprehensive review of graph learning-based recommendation systems, discussing various methodologies and highlighting their adaptability across diverse use cases. 

\subsection{Fairness in AI-Based Recommendation Systems} 
While personalized recommendation systems have shown the potential to improve learning experiences, concerns about fairness and algorithmic bias remain prominent. Studies \cite{biasinedu} have drawn attention to the risks of reinforcing existing inequalities in educational settings.
Binns \cite{individual_fairness} and Burke \cite{burke2017multisidedfairnessrecommendation} proposed fairness-aware frameworks to address these issues.
Recommendation systems have a different logic than traditional machine learning tasks, as they rely on user-item interactions and dynamic feedback loops, making it not optimal to assess fairness using standard metrics. Authors of \textit{``Fairness in Recommendation Systems: Research Landscape and Future Directions''} work\cite{Deldjoo2024} have reviewed current studies on fairness in recommendation systems, highlighting various issues and gaps in existing methods.
In addition to this, algorithmic fairness, the main component of responsible AI, has been analyzed comprehensively, with fairness defined in various ways based on philosophical considerations and contextual use \cite{khan2022substantive}. Researchers have developed numerous fairness metrics to address different aspects of fairness \cite{bird2020fairlearn,aif360-oct-2018,saleiro2018aequitas,DBLP:journals/bigdata/Chouldechova17,friedler2019comparative,10.1145/3457607,verma2018fairness}.

\subsection{Hybrid Approaches in Recommendation Systems} 
Hybrid recommendation systems have been widely adopted to combine the strengths of different recommendation techniques.
Koren et al. \cite{5197422} introduced matrix factorization techniques that uncover latent patterns in user-item interactions, which have become foundational in collaborative filtering approaches.

For instance, there was proposed a scalable and accurate hybrid recommendation system that combines collaborative filtering with content-based filtering \cite{5432716}. 

Similarly, in the educational space, there was developed a personalized recommendation system for college libraries that combines collaborative filtering and content-based techniques to help users navigate vast collections of books \cite{TIAN2019490}.