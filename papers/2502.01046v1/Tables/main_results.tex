

\begin{table*}[thbp]
\setlength\tabcolsep{5.0pt}
\small
\centering
\begin{tabular}{lccccccc}
\toprule
Methods & Audio & Visual & EmoSim$\uparrow$ & SpkSim$\uparrow$ & RMSE$\downarrow$ &MCD$\downarrow$  & WER(\%)$\downarrow$ \\ \hline
\specialrule{0em}{3.5pt}{1.5pt}
Ground Truth & - & - & 1.0000 & 1.0000 & 0.00 & 0.0000 & 10.82  \\ 
\hdashline
\specialrule{0em}{1.5pt}{1.5pt}
 \multicolumn{4}{l}{\textit{\textbf{Acoustic-guided Speech Generation}}} \\
EmoSpeech~\cite{emospeech:conf/ssw/DiatlovaS23} & \ding{51} & \ding{55} & 0.7667 & 0.5677  & 114.70 & 7.1328 & 29.59 \\
FastSpeech2~\cite{fastspeech2/0006H0QZZL21}  & \ding{51} & \ding{51} & 0.7010 & 0.5217  & 115.97 & 7.3461 & 29.49 \\
V2C-Net~\cite{visualvoicecloning/Cong0QZWWJ0H23}  & \ding{51}  & \ding{51}  & 0.6788 & 0.5773  & 115.55 & 6.8901  & 29.54\\ 
HPM~\cite{visualvoicecloning/ChenTQZLW22}  &  \ding{51}  & \ding{51} & 0.6817 & 0.4404  & 97.19 & 7.7614  & 77.31\\ 
StyleDubber~\cite{styledubber:conf/acl/CongQLBZH00H24}  &  \ding{51}  & \ding{51} & 0.6742 & 0.4753  & 103.59 & 7.4497  & 43.14\\ 
\specialrule{0em}{1.pt}{0.5pt}
\rowcolor{gray!20} \textsc{DEmoFace}$^*$ (Ours) &  \ding{51} & \ding{51}  & \textbf{0.7921} & \textbf{0.7990}  & 
\textbf{94.68} & \textbf{6.5505} & \textbf{19.72} \\
\specialrule{0em}{1.pt}{1.5pt}
\hline
\specialrule{0em}{1.pt}{1.5pt}
\multicolumn{4}{l}{\textit{\textbf{Visual-guided Speech Generation}}}\\
Face-TTS~\cite{FaceTTS:conf/icassp/LeeCC23}  &  \ding{55} & \ding{51}  & 0.5230 & 0.1968  & 118.96 & 8.4649 & \textbf{17.47}\\ 
\specialrule{0em}{1.pt}{0.5pt}
\rowcolor{gray!20} \methodname (Ours) &  \ding{55} & \ding{51}  & \textbf{0.6965} & \textbf{0.6679}  & \textbf{101.18} & \textbf{6.8601} & 20.78 \\
\bottomrule
\end{tabular}
\caption{ \textbf{Speech quantitative results.} The \textit{Audio} and \textit{Visual} indicate whether specific modality conditions are used for speech generation guidance. $\uparrow$ ($\downarrow$) means the higher (lower) value is better. We \textbf{bold} the best-performing method. Notably, the $^*$ denotes that we use the speech condition $\bm{c}_\text{ge2e}$, rather than the face condition $\bm{c}_\text{id}$ to guide identity conditioning. \label{tab:main}}
\end{table*}
