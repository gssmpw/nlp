% Template for ISBI paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

% It's fine to compress itemized lists if you used them in the
% manuscript
\usepackage{enumitem}
\usepackage{amsmath,graphicx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amssymb}

\usepackage{color}
\usepackage{url}
\usepackage{caption}
\usepackage{multirow}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{algorithm2e}
\usepackage{colortbl} % in the preamble
\usepackage{todonotes}
 \usepackage[nolist,nohyperlinks]{acronym}
\newcommand{\en}{\enspace} 
\newcommand{\bm}[1]{ \mathbf #1} 
%\newcommand{\it}[1]{\textit} 
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}
\newcommand{\loss}{\ensuremath{\mathcal{L}}}
\newcommand{\lbce}{\ensuremath{\loss_\text{BCE}}\xspace}
\newcommand{\liou}{\ensuremath{\loss_\text{IoU}}\xspace}
\newcommand{\lDUAL}{\ensuremath{\loss_\text{DUAL}}\xspace}
\newcommand{\glmsrf}{\ensuremath{\loss_\text{GMSRF}}\xspace}
\usepackage[acronym]{glossaries}
\acrodef{mIoU}{mean intersection over union}
\acrodef{DSC}{dice coefficient}
\acrodef{CT}{computed tomography}

\setlist{nosep, leftmargin=14pt}

\usepackage{mwe} % to get dummy images

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Is Long Range Sequential Modeling Necessary for Colorectal Tumor Segmentation?}
%
% Single address.
% ---------------
\name{Abhishek Srivastava$^1$, Koushik Biswas$^1$, Gorkem Durak$^1$, Gulsah Ozden$^2$, Mustafa Adli$^2$, Ulas Bagci$^1$}
\address{$^1$Machine and Hybrid Intelligence Lab, Northwestern University, Chicago, IL, USA.\\$^2$Department of Radiation Oncology, Marmara University School of Medicine, Turkey.}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Some author footnote.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
% More than two addresses
% -----------------------
% \name{Author Name$^{\star \dagger}$ \qquad Author Name$^{\star}$ \qquad Author Name$^{\dagger}$}
%
% \address{$^{\star}$ Affiliation Number One \\
%     $^{\dagger}$}Affiliation Number Two
%
\begin{document}
%\ninept
%



\maketitle
\def\x{{\mathbf x}}
\def\L{{\cal L}}
%
\begin{abstract}
%Colorectal cancer (CRC) tumor segmentation is a critical task in medical image analysis due to its importance in radiation therapy planning and survival prediction.
Segmentation of colorectal cancer (CRC) tumors in 3D medical imaging is both complex and clinically critical, providing vital support for effective radiation therapy planning and survival outcome assessment. Recently, 3D volumetric segmentation architectures incorporating long-range sequence modeling mechanisms, such as Transformers and Mamba, have gained attention for their capacity to achieve high accuracy in 3D medical image segmentation. In this work, we evaluate the effectiveness of these global token modeling techniques by pitting them against our proposed MambaOutUNet within the context of our newly introduced colorectal tumor segmentation dataset (CTS-204). Our findings suggest that robust local token interactions can outperform long-range modeling techniques in cases where the region of interest is small and anatomically complex, proposing a potential shift in 3D tumor segmentation research.
%3D medical image segmentation is pivotal in computer-aided diagnosis. 
%Automated segmentation reduces subjective variability and supports consistent analysis of colorectal cancer (CRC) tumors, which is critical for radiation therapy planning and survival prediction. 
%Our results demonstrate that robust local interactions can outperform global models, offering a promising direction for 3D tumor segmentation research.
%Recently, 3D volumetric architectures embedded with long-range sequence modeling mechanisms like Transformer s and Mamba have drawn interest due to their ability to accurately segment 3D medical images.
%In this work, we investigate the efficacy of local token interactions in comparison to long-range modeling techniques for medical image segmentation. Specifically, we target colorectcal cancer (CRC)/tumor segmentation due to its challenging nature, and clinical significance: critical for radiation therapy planning and survival prediction. We analyze the efficacy of such global token modeling technique by pitting them against our MambaOutUNet within the context of our newly designed colorectal tumor segmentation dataset (CTS-204). Our findings suggest that robust local token interactions can outperform long-range modeling techniques, proposing a potential shift in 3D tumor segmentation research.
\end{abstract}
%
%
\begin{keywords}
Deep learning, Tumor Segmentation, State Space Models, Transformers
\end{keywords}
\section{Introduction}
\label{sec:intro}
%3D medical image segmentation is a crucial component in computer-aided diagnosis, as precise segmentation can significantly reduce the diagnostic workload for clinicians across various conditions. Within this domain, accurate delineation of tumors within 3D medical images facilitates clinicians' detailed insights into tumor morphology, assesses growth or response to therapy, and even guides surgical or radiotherapeutic interventions~\cite{minaee2021image,clark2013cancer}. 

%Early-stage detection of colorectal cancer (CRC) has been shown to significantly increase survival rates, yet CRC is often diagnosed at later stages due to its subtle and variable manifestations in imaging~\cite{yao2022deepcrc}. 
Colorectal cancer (CRC) tumor segmentation from medical scans, such as computed tomography (CT), is a crucial task in the field of medical imaging and computer-assisted diagnosis. However, this task presents several challenges, variability in image quality and the complex anatomy of the colorectal region hinders precise delineation of tumors. Many CRC tumors are small, irregular, or have complex shapes, making accurate segmentation diffcult. The presence of multiple lesions or tumors in the same patient further adds complexity to the tasks.
%Computed tomography (CT) imaging data of colorectcal cancer (CRC) contain complex tumor and anatomical details that complicate auto-segmentation. Automated segmentation supports consistent and reproducible analysis of colorectal tumors, enabling more reliable data for clinical decisions. 

To overcome these challenges, researchers and clinicians employ various deep learning techniques to segment CRC tumors. For instance, convolutional neural networks (CNNs)~\cite{ronneberger2015u} and, more recently, Transformers~\cite{cao2022swin,hatamizadeh2021swin}, have proven to be effective for 3D image segmentation, with CNNs capturing local features efficiently and Transformers modeling long-range dependencies~\cite{dosovitskiy2020image}. However, the self-attention mechanism~\cite{vaswani2017attention} of Transformers suffers from quadratic complexity bottleneck, resulting in significant computational demands. 
%To address these limitations, automated segmentation methods have been developed, demonstrating substantial progress due to advancements in deep learning. However, available methods are limited
 %These methods have enabled faster, more accurate tumor delineation, improving decision-making and ultimately enhancing patient outcomes. 
%Enhancing the model's receptive field within the 3D space is one of the key components to improve model segmentation performance.  Lkd-net~\cite{luo2023lkd} modeled a wider range of features using their large-kernel convolution layer. 
%MSRF-Net~\cite{srivastava2021msrf} obtained diverse feature maps combining different receptive fields utilizing their multi-scale feature fusion block. However, modeling global relationships is challenging for CNNs, owing to their inherent inductive bias and their hierarchical nature makes modeling relationships between distant tokens inefficient. However, when the vision Transformer ~\cite{dosovitskiy2020image} was conceptualized, it drew attention from the community due to its inherent ability to model global token interactions~\cite{xing2022nestedformer,xing2024hybrid}. UNETR~\cite{hatamizadeh2022unetr} used ViT in their encoder to leverage its advantage for medical image segmentation, while, SwinUNETR utilizes the Swin Transformer~\cite{hatamizadeh2021swin} to extract multi-scale features, enhancing segmentation accuracy. However, the self-attention mechanism~\cite{vaswani2017attention} suffered from quadratic complexity bottleneck which resulted in significant computational demands. 
This challenge was addressed by the Mamba~\cite{gu2023mamba} architecture inspired by state space models, which facilitates long-range dependency modeling via a selection mechanism and a hardware-efficient algorithm. U-Mamba~\cite{ma2024u} integrates Mamba into nnU-Net~\cite{isensee2021nnu}. SegMamba~\cite{xing2024segmamba} proposed a tri-oriented Mamba (ToM) module for enhanced 3D feature modeling. MambaOut~\cite{yu2024mambaout} analyzes Mamba's application computer vision tasks, hypothesizing that while it has advantages in segmentation/object detection due to their long range modeling requirements, Mamba has limitations due to their inability to model non-causal features. In this paper, we provide a comprehensive comparison of these different local- and global token modeling mechanisms on our newly proposed Colorectal Tumor Segmentation 204 (CTS-204) dataset and instantiate a new methodology MambaOutUnet to provide strong evidence for the hypothesis introduced in~\cite{yu2024mambaout}
Our contributions are as follows:\\ 
\textbf{1) Is Long-Range Sequence Modeling Necessary for Tumor Segmentation?} While image segmentation is essentially a long range sequence modeling task, in case of tumor segmentation where the target region by its natural properties has no correlation with most of the surrounding pixels/voxels, does it still holds the same efficacy? We investigate the potential benefits and limitations of this approach in 3D tumor segmentation.\\
\textbf{2) We propose a newly curated CTS-204 dataset for colorectal cancer tumor segmentation}.\\
\textbf{3) Comprehensive Analysis of Long Range Sequence Modeling Architectures:} We propose a comprehensive analysis of recent Mamba-based architectures, including UNet variations that enhance the capacity to model local- and global token interactions. Our results demonstrate that efficient channel mixing and spatially gated features can outperform many existing computationally intensive long-range modeling techniques. Specifically, we analyze the performance of MambaOutUNet on our CTS-204 dataset and compare it to established 3D segmentation architectures.
%1.) Is long-range sequence modeling necessary for tumor segmentation? 2.) Could focusing on developing methodologies that improve the capacity to model local token interactions lead to more robust performance in 3D tumor segmentation?
%In this paper, we also propose UNet variations of recent Mamba-based architectures, providing a comprehensive analysis of these methods alongside established 3D segmentation architectures from the literature on our CTS-204 dataset. Notably, MambaOutUNet, whose encoder is enhanced with gated convolutional layers~\cite{dauphin2017language}, demonstrates that efficient channel mixing and spatially gated features alone can outperform many existing computationally intensive long-range modeling techniques. This finding offers a fresh perspective for advancing current 3D medical image segmentation research.

%3D medical image segmentation is a crucial component in computer-aided diagnosis, as precise segmentation can significantly reduce the diagnostic workload for clinicians across various conditions. Within this domain, tumor segmentation in medical imaging is critical to healthcare as a requisite for diagnosis, treatment planning, and monitoring tumor progression. Accurate delineation of tumors within 3D medical images facilitates clinicians' detailed insights into tumor morphology, assesses growth or response to therapy, and even guides surgical or radiotherapeutic interventions~\cite{minaee2021image,clark2013cancer}. While manual segmentation is precise, it is time-consuming and requires extensive domain expertise, making it unfeasible in settings with high image volumes or in time-sensitive clinical environments. 
%CRC imaging data, particularly from modalities such as computed tomography (CT) and magnetic resonance imaging (MRI), often contain complex anatomical details that complicate manual segmentation. Automated segmentation, by removing subjective variability and reducing time demands, supports consistent and reproducible analysis of colorectal tumors, enabling more reliable data for clinical decisions. Early-stage detection of CRC has been shown to significantly increase survival rates, yet CRC is often diagnosed at later stages due to its subtle and variable manifestations in imaging~\cite{yao2022deepcrc}.

\iffalse
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[!t]
    \centering
    \includegraphics[height=0.32\textwidth]{Figures/GMSRF_FULL_new.jpeg}
    \caption{The proposed GMSRF-Net architecture, a) The GMSRF-Net architecture (left), b) The GMSRF module (right)}
    \label{fig:GMSRF-Net}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fi
%\section{Materials and method}
\begin{table*}[!t]
\centering
\footnotesize
\setlength{\tabcolsep}{18pt}
\renewcommand{\arraystretch}{1.1}
\caption{Quantitative Comparison on the CTS 204 and Synapse multi-organ CT dataset (BTCV). We report the Dice Score (DSC), Mean Intersection over Union (mIoU), and Normalized Surface Distance (NSD)}
\begin{tabular}{@{}l|ccc|ccc@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{CTS 204}} & \multicolumn{3}{c}{\textbf{BTCV}} \\
 & \textbf{DSC} & \textbf{mIoU} & \textbf{NSD} & \textbf{DSC} & \textbf{mIoU} & \textbf{NSD} \\ 
\hline
UNet & \textcolor{magenta}{0.5007} & \textcolor{magenta}{0.3839} & \textcolor{magenta}{0.6116} & \textcolor{magenta}{0.8217} & \textcolor{magenta}{0.6982} & \textcolor{magenta}{0.9320} \\ \hline
nnU-Net & 0.4842 & 0.3619 & 0.6073 & 0.7775 & 0.6351 & 0.9244 \\ \hline
SwinUnet & 0.4602 & 0.3388 & 0.5060 & 0.8023 & 0.6718 & 0.8982 \\ \hline
VisMix & 0.3612 & 0.2566 & 0.4663 & 0.7436 & 0.5906 & 0.8025 \\ \hline
SegMamba & 0.3990 & 0.2982 & 0.5256 & 0.8184 & 0.7124 & 0.9158 \\ \hline
SegHydra & 0.3687 & 0.2728 & 0.5972 & 0.7917 & 0.6803 & 0.8823 \\ \hline
MambaOutUNet & \textbf{0.5203} & \textbf{0.3950} & \textbf{0.6139} & \textbf{0.8338} & \textbf{0.7345} & \textbf{0.9397} \\ 
\bottomrule
\end{tabular}
\label{tab:result_combined}
\end{table*}
\iffalse
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[!t]
\centering
\footnotesize
\setlength{\tabcolsep}{400pt}
\caption{Quantitative Comparison on the CTS 204 and Synapse multi-organ CT dataset (BTCV). We report the Dice Score (DSC), Mean Intersection over Union (mIoU), and Normalized Surface Distance (NSD)}
%\begin{tabular}{@{}l|ccccc|ccccc@{}}
\begin{tabular}{@{}l|p{2cm}p{2cm}p{2cm}|p{2cm}p{2cm}p{2cm}@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{5}{c|}{\textbf{CTS 204}} & \multicolumn{5}{c}{\textbf{BTCV}} \\
 & \textbf{DSC} & \textbf{mIoU} & \textbf{NSD} & \textbf{ASD} & \textbf{HD95} & \textbf{DSC} & \textbf{mIoU} & \textbf{NSD} & \textbf{ASD} & \textbf{HD95} \\ 
\hline
UNet~\cite{ronneberger2015u} & \textcolor{magenta}{0.5007} & \textcolor{magenta}{0.3839} & \textcolor{magenta}{0.6116} & 37.2800 & 59.5921 & 0.8217 & 0.6982 & 0.9320 & 2.9506 & 39.6404 \\ \hline
NNUNet~\cite{isensee2021nnu} & 0.4842 & 0.3619 & 0.6073 & 40.6262 & 57.1466 & 0.7775 & 0.6351 & 0.9244 & 3.4849 & 33.6257 \\ \hline
SwinUnet~\cite{cao2022swin} & 0.4602 & 0.3388 & 0.5060 & 63.8752 & 172.4032 & 0.8023 & 0.6718 & 0.8982 & 2.4188 & 62.4951 \\ \hline
MambaSwinUnet & 0.3612 & 0.2566 & 0.4663 & 59.3459 & 74.2021 & 0.7436 & 0.5906 & 0.8025 & 11.8268 & 107.3043 \\ \hline
SegMamba~\cite{xing2024segmamba} & 0.3990 & 0.2982 & 0.5256 & 47.7523 & 66.1386 & 0.8184 & 0.7124 & 0.9158 & 1.39601 & 48.4698 \\ \hline
SegHydra & 0.3687 & 0.2728 & 0.5972 & 14.1302 & 39.6611 & 0.7917 & 0.6803 & 0.8823 & 3.1242 & 74.2332 \\ \hline
MambaOutUNet & \textbf{0.5203} & \textbf{0.3950} & \textbf{0.6139} & 49.3902 & \textbf{83.5807} & 0.8338 & 0.7345 & 0.9397 & 0.9391 & 24.9705 \\ 
\bottomrule
\end{tabular}
\label{tab:result_combined}
\end{table*}
\fi

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.9\textwidth]{1.png}
    \caption{Qualitative comparison of MambaOutUNet with other established and proposed baselines.}
    \label{fig:qualitative}
    \vspace{-5mm}
\end{figure*}
\section{Dataset}
We have publicly released a new colorectal tumor segmentation dataset termed "CTS-204". The dataset was collected from Marmara University Pendik Research and Education Hospital in Turkey and includes CT scans from 204 patients undergoing treatment for colon cancer. All sensitive patient information has been de-identified. Two experienced radiation oncologists annotated each volume in consensus. All the CT scans were acquired with tube voltage, 120 Kv, pitch, 0.85-1.2, Z-axis spacing from 3.0 mm to 3.75 mm, with a median of 3.75 mm. CTS-204 will be made available upon request. Additionally, to validate the performance of our MambaOut method and our hypothesis that long-range sequence modeling is still useful for segmentation problems where global token modeling is informative, we include \textit{Synapse multi-organ segmentation dataset}.
%Experiments on the Synapse multi-organ segmentation dataset followed the same training-testing splits as used in~\cite{chen2021transunet}.
\vspace{-3mm}
\section{Methods}
\vspace{-3mm}
In this section, we describe the architecture of our three proposed baselines: Mamba-SwinUnet, SegHydra, and MambaOutUnet. Assessing the impact of long range sequence modeling through Mamba requires a fair comparison with SegMamba~\cite{xing2024segmamba}. We ensure this by following the same architecture as proposed in SegMamba~\cite{xing2024segmamba} while invoking necessary architectural changes in the \textbf{encoder} for each proposed technique. The architecture of Mamba-SwinUnet, SegHydra, and MambaOutUnet along with the Tri-oriented spatial Mamba (TSMamba) block and the convolutional layer incorporated 3D decoder will be introduced in the following section. 
%For a fair comparison with SegMamba~\cite{xing2024segmamba}, we use the thier  1.) tri-orientated spatial Mamba (TSMamba) blocks for modeling global
%information at different scales and 2) a 3D decoder based on the convolution layer for predicting segmentation results. The encoder is changed with respect to the mamba variant being incorporated. In the following section we will describe the Tri-oriented spatial mamba block, the decoder, followed by how each architecture influences the encoder.
\subsection{Encoder}
The 3D input volume \( CT \in R^{C \times D \times H \times W} \) is initially passed through the encoder stem comprising a depth-wise convolutional layer with a kernel size of \(7 \times 7 \times 7\), padding of \(3 \times 3 \times 3\), and stride of \(2 \times 2 \times 2\). The resultant \( x_0 \in \mathbb{R}^{48 \times \frac{D}{2} \times \frac{H}{2} \times \frac{W}{2}} \) tensor is sent to the subsequent TSMamba Blocks and downsampling layers. \textbf{Tri-orientated Spatial Mamba (TSMamba) Block:}
TSMamba blocks facilitate global token modeling through Mamba and their hierarchal nature in the UNet allows modeling of multi-scale features. Global token modeling and capturing multi-scale features are conducive to obtaining precise segmentation maps. Specifically, the input feature in $lth$ layer of TSMamba block are first passed through the Gated Spatial Convolutional module. This module consists of two convolutional blocks each consisting of normalization, convolution and non-linear activation layer. The two convolutional layers have kernel size of \(3 \times 3 \times 3\) and \(1 \times 1 \times 1\), respectively. The resultant outputs undergo an element wise multiplication so as to regulate the amount of informative spatial features and suppress irrelevant features, similar to a gated attention mechanism(see Equation~\ref{eq:gsc_def}, where C is the convolutional layers and x are the input feature maps)
\begin{equation}
    \text{GSC}(x) = x + C_{3 \times 3 \times 3} \left( C_{3 \times 3 \times 3}(x) \cdot C_{1 \times 1 \times 1}(x) \right), \label{eq:gsc_def}
\end{equation}
Since Mamba layers performs token-to-token modeling in one direction the input 3D features are flattened into three different sequences corresponding to the axial, coronal, and sagittal plane(see Equation~\ref{eq:tri_orientated_mamba}).
\begin{equation}
\text{ToM}(x) = \text{Mamba}(x_{\text{axial}}) + \text{Mamba}(x_{\text{coronal}}) + \text{Mamba}(x_{\text{sagittal}})
\label{eq:tri_orientated_mamba}
\end{equation}
Subsequently, a multi-layer perceptron (MLP) is used to perform channel mixing and layer normalization is used to further model feature representations. The information flow can be summarized as:
\begin{align}
    \hat{x}^l &= \text{GSC}(x^l), \label{eq:gsc} \\
    \tilde{x}^l &= \text{ToM} \left( \text{LN} \left( \hat{x}^l \right) \right) + \hat{x}^l, \label{eq:tom} \\
    x^{l+1} &= \text{MLP} \left( \text{LN} \left( \tilde{x}^l \right) \right) + \tilde{x}^l, \label{eq:mlp}
\end{align}
\subsection{Decoder and Feature-level Uncertainty Estimation (FUE)}
The encoder generates multi-scale features which include embedded uncertainty information~\cite{zhao2023uncertainty}. These feature maps are passed through FUE~\cite{xing2024segmamba} that stabilizes features with lower uncertainty levels within each skip connection, enhancing the reliability of multi-scale feature representations. The decoder progressively refines feature maps from the bottleneck layer using a series of upscaling blocks. Each decoder block doubles the spatial resolution and combines multi-scale features from the encoder at each level \( x^i \). The transformation in each block is defined as:
\begin{equation}
D_x = \text{ReLU} \left( \text{Norm} \left( \text{Conv}_{3 \times 3} \left( \text{ConvT}(D_{x-1}) \oplus \text{FUE}(x^i) \right) \right) \right)
\label{eq:decoder_block}
\end{equation}
where \( D_0 \) is the output from the first decoder block. Here, \(\text{ConvT}\) represents a 3x3 transposed convolution with stride 2, \(\text{Norm}\) denotes instance normalization, and \(\oplus\) is the concatenation operation. The final segmentation head uses a convolutional layer on \( D_1 \) to produce the output with the required number of class channels.
\vspace{-4mm}
\subsection{SegHydra}
% LaTeX code for the Hydra model with quasiseparable matrix mixer in a structured format with labeled equations

%\section{Hydra Model with Quasiseparable Matrix Mixer}
%Mamba-2~\cite{dao2024Transformer s}

%uasiseparable matrix have unrestrained parameters in thier diagnals allowing additonal mathematical expressivity over addition based bidirectional semiseperable matrices (Bidirectional mamba)
%\subsection{What it is}
Hydra is a sequence model that incorporates a \textbf{quasiseparable matrix mixer} for effective bidirectional sequence processing. Quasiseparable matrices offer an ideal structure for sequence modeling by generalizing low-rank mixers in linear attention and semiseparable matrices in state-space models (SSMs). This structure provides enhanced computational efficiency while preserving high model expressivity.

%\subsection{How it works}
The quasiseparable matrix structure allows bidirectional sequence mixing holding an advantage over SSMs for its application in non-causal scenarios. SSMs rely on semiseperable matrices for sequence modeling~\cite{dao2024transformers} and can overcome this limitation by using two SSMs for forward and backward sequence modeling, combining thier features through addition/concatenation. In contrast, Hydra uses quasiseperable matrices to allow non-causal modeling posting three advantages a.) better representation power, b.) sub-quadratic matrix multiplication, c.) lower parameters as compared to alternatives.
%extending traditional SSMs for use in non-causal scenarios. Hydra achieves this without relying on prior ad-hoc approaches, such as combining forward and backward models with element-wise addition or concatenation. Instead, Hydra directly utilizes quasiseparable matrices for a more theoretically grounded bidirectional modeling.
%The quasiseparable matrix structure enables bidirectional sequence mixing, extending traditional SSMs for use in non-causal scenarios. Hydra achieves this without relying on prior ad-hoc approaches, such as combining forward and backward models with element-wise addition or concatenation. Instead, Hydra directly utilizes quasiseparable matrices for a more theoretically grounded bidirectional modeling.
%\subsection{Mathematical Formulation}
A matrix \( M \) is defined as \( N \)-quasiseparable if its elements \( m_{ij} \) satisfy the following conditions:

\begin{equation}
    m_{ij} = 
    \begin{cases} 
      \overrightarrow{c_i}^T \, \overrightarrow{A_{i:j}} \, \overrightarrow{b_j}, & \text{if } i > j \\
      \delta_i, & \text{if } i = j \\
      \overleftarrow{c_j}^T \, \overleftarrow{A_{j:i}} \, \overleftarrow{b_i}, & \text{if } i < j
   \end{cases} \label{eq:quasi_matrix_definition}
\end{equation}

Here, \( \delta_i \) is a scalar, and \( \overrightarrow{b_j}, \overrightarrow{c_i}, \overleftarrow{b_i}, \overleftarrow{c_j} \in \mathbb{R}^{N \times 1} \), with \( A_i \in \mathbb{R}^{N \times N} \). This formulation permits bidirectional processing by including non-zero entries in the upper triangular section.
%\subsection{Efficient Matrix Multiplication}
Tri-oriented Mamba block in SegMamba, processes flattened sequence across three different views of the same 3D input volume through mamba blocks. We reduce parametric complexity and could increase the efficiency of long range modeling by using the quasiseparable matrix multiplication to provide a more effective and efficient alternative while maintaining other aspects of the encoder-decoder architecture described earlier. This operation in Hydra can be efficiently computed by decomposing it into operations involving semiseparable matrices. 
\begin{equation}
    \text{QS}(x_l) = \text{shift}(\text{SS}(x_l)) + \text{flip}(\text{shift}(\text{SS}(\text{flip}(x_l)))) + Dx_l, \label{eq:quasi_multiplication}
\end{equation}

where:
\(\text{QS}(x_l) \): quasiseparable operation on input \( x_l \), \( \text{SS}(x_l) \): semiseparable operation on \( x_l \), \( \text{flip}(x_l) \): reverses \( x_l \), \( \text{shift}(x_l) \): shifts \( x_l \) right by one position with zero-padding at the start, and \( D = \text{diag}(\delta_1, \ldots, \delta_L) \): diagonal matrix with parameters \( \delta_i \). 
%\begin{itemize}
%    \item \( \text{QS}(x_l) \): quasiseparable operation on input \( x_l \),
%    \item \( \text{SS}(x_l) \): semiseparable operation on \( x_l \),
%    \item \( \text{flip}(x_l) \): reverses \( x_l \),
%    \item \( \text{shift}(x_l) \): shifts \( x_l \) right by one position with zero-padding at the start, and
%    \item \( D = \text{diag}(\delta_1, \ldots, \delta_L) \): diagonal matrix with parameters \( \delta_i \).
%\end{itemize}
This decomposition enables Hydra to leverage efficient linear-time semiseparable matrix multiplications, compatible with various SSMs, for high-performance sequence modeling.
\vspace{-4mm}
\subsection{Vision Mamba Block with Swin Transformer Integration}
% LaTeX code for describing the Vision Mamba block integrated with Swin Transformer in a Mamba-based architecture
MambaVision~\cite{hatamizadeh2024mambavision} empirically showed the advantage of combining Mamba layers succeeded by the self-attention mechanism. Mamba’s auto regressive structure, while effective for sequence modeling, presents limitations in tasks like segmentation and object detection that benefit from a global receptive field. Specifically:
a.) Image pixels do not exhibit strict sequential dependencies, making Mamba’s step-wise approach less efficient for spatial data.
b.) Autoregressive processing limits the model’s ability to capture global context in a single pass, essential for many vision tasks.
However, using self-attention following Mamba layers for 3D volumes can be computationally heavy and not feasible to train. To address these challenges, we propose a restructured Mamba-SwinUNet that integrates Swin-Transformer blocks~\cite{hatamizadeh2021swin} for improved spatial context representation. In our design, we augment each Mamba block with a Swin Transformer layer after every Mamba processing layer. This hybrid structure balances Mamba’s sequential strengths with the Swin Transformer's ability to capture global and local spatial dependencies more effectively. For the \( l \)-th Vision Mamba block, the computation is given by \( x_{l} = \text{Swin}(\text{LN}(\text{Mamba}(x_l))) + x_l \), where \( \text{Mamba}(x_l) \) processes the input \( x_l \) to capture sequential dependencies, \( \text{Swin}(\cdot) \) applies the Swin Transformer block to model spatial context and improve receptive field coverage, and \( x_l \) denotes the original input feature at layer \( l \). This hybrid Mamba-SwinUNet approach combines the Mamba model's sequential feature extraction capabilities with the Swin Transformer's global spatial learning, thus enhancing both local and global feature understanding.
\vspace{-2mm}
%For the \( l \)-th Vision Mamba block, the computation is given by:
%\begin{equation}
%    x_{l} = \text{Swin}(\text{LN}(\text{Mamba}(x_l))) + x_l, \label{eq:vision_mamba_swin}
%\end{equation}
%where:
%\begin{itemize}
%    \item \( \text{Mamba}(x_l) \): processes the input \( x_l \) to capture sequential dependencies,
%    \item \( \text{Swin}(x) \): applies the Swin Transformer block to model spatial context, improving receptive field coverage, and
%    \item \( x_l \): the original input feature at layer \( l \).
%\end{itemize}
%This hybrid Mamba-SwinUnet approach combines the Mamba model’s capability of sequential feature extraction with the Swin Transformer's global spatial learning, enhancing both local and global feature understanding.
\subsection{MambaOutUNet}
% LaTeX code for describing the integration of Gated Convolutional Layer in Mamba Block
%\section{Gated Convolutional Layer in Mamba Block Meta-Architecture}
%\subsection{What it is}
To empirically validate our hypothesis, we follow the protocol set in MambaOut~\cite{yu2024mambaout}, the Mamba block is analyzed alongside the Gated CNN block~\cite{dauphin2017language}. 
%we analyze the Mamba block [25] alongside the Gated CNN block [18]. Both structures simplify the MetaFormer’s token mixer and combine it with an MLP layer, similar to the MetaNeXt architecture [93]. 
%\subsection{How it works}
Given input \( X \in \mathbb{R}^{N \times D} \), the Mamba block meta-architecture integrates token mixing, represented by a token mixer, with normalization and an MLP. In this setup:
- \( \text{Norm}(\cdot) \) denotes the normalization layer.
- \( \text{TokenMixer}(\cdot) \) performs token mixing, enhancing spatial feature extraction.
%- Learnable weights \( W_1 \in \mathbb{R}^{D \times rD} \), \( W_2 \in \mathbb{R}^{D \times rD} \), and \( W_3 \in \mathbb{R}^{rD \times D} \) are used in the MLP layers.
For token mixing, the Gated CNN and Mamba differ as follows:
\begin{equation}
    \text{TokenMixer}_{\text{GatedCNN}}(x) = \text{Conv}(x), \label{eq:token_mixer_gatedcnn}
\end{equation}
\begin{equation}
    \text{TokenMixer}_{\text{Mamba}}(x) = \text{SSM}(\sigma(\text{Conv}(x))), \label{eq:token_mixer_mamba}
\end{equation}
where \( \sigma \) is the activation function and SSM represents the sequential state-space model for improved token mixing.
%\subsection{Application}
To isolate the impact of SSM, we use a simplified methodology, MambaOut, based on the Gated CNN block without SSM. This setup is incorporated inside the MambaOutUNet, specifically inside the encoder where we ablate the Mamba layers and use GatedCNN instead. Thus, allowing us to accurately assess the impact of Mamba on segmentation performance through our experiments.
\section{Experiments}
CTS-204 was split into 3 splits, training, validation and testing which had 163, 20, 21 cases, respectively. The relevant baselines and all proposed architectures were trained on CTS-204 for 200 epochs for the same learning rate and validation interval. Similarly, all methodologies were trained on the BTCV dataset for 400 epochs on a single Tesla A100 GPU. Following~\cite{pitfallmetric} we use three metrics DSC, mIoU, and NSD to evaluate performance.
\section{Results and Discussion}
To validate our hypotheses, we conducted experiments on two datasets: the CTS 204 dataset and the BTCV multi-organ segmentation dataset. The results of these experiments are summarized in Tables \ref{tab:result_combined}. Here we can observe that the MambaOutUNet achieves a (DSC), mIoU, and NSD of 0.5203, 0.6971, and 0.6971 outperforming the second best benchmarks by 1.96\%,1.11\%,0.23\%, respectively. Moreover, a performance gain of 15.19\% and 9.68\% is observed over the SegMamba~\cite{xing2024segmamba}, this can be attributed to the fact that even though segmentation is essentially a \textit{long-sequence task}, tumor segmentation requires focus on immediate locality structure surrounding cancerous tissues for accurate delineation, thus, Mamba, Transformer  and other long-range sequence modeling techniques have limited use in such cases. It should also be noted that while Hydra's quasisemiseperable matrix mixing technique holds various advantages over bidirectional mamba, it is outperformed by SegMamba on both CTS-204 and BTCV, suggesting that, despite their claims~\cite{hwang2024hydra}, inherent RNN nature of SSMs limits modeling of non-causal features. Methods incorporating SSMs and Transformer  architectures, while beneficial in contexts requiring long-range dependencies, do not provide the same level of performance for localized segmentation tasks. The focus on global context in these models may lead to unnecessary complexity without yielding proportional improvements in accuracy.

However, From Table~\ref{tab:result_combined} and Figure~\ref{fig:qualitative}, we can observe that on BTCV multi-organ segmentation challenge, where the region-of-interest has high variance in size and structure, long range sequencing is desirable, thus, Mamba and Transformer  based models show competitive performance. Therefore, even though long range sequencing might be desirable in medical image segmentation and is worthwhile exploring, there must also be a need to study these new architectures equipped with Mamba and self-attention variants in the context of datasets with small regions of interest and complex structural variations, such as the newly introduced CTS-204. To this extent, MambaOutUNet can serve as a useful baseline to asses the performance gain obtained through long-range sequencing. We would also like to highlight that there should be an increased effort to design architectures specifically for more efficient local token modeling to capture the small, complex and difficult to observe ROIs like colorectal tumors in medical image analysis.
%In Table \ref{tab:resultw}, we further analyze the performance of MambaOutUNet on the BTCV dataset, where it achieves a DSC of \(0.8338\), indicating competitive performance compared to other state-of-the-art methods, including SwinUNet and SegMamba. These results highlight the versatility of the MambaOut architecture, demonstrating its capability to maintain robust segmentation performance across different types of data.
%The performance of MambaOutUNet in the CRC 204 dataset reflects the utility of gated convolutional layers in extracting relevant features for tumor segmentation. Given that colorectal cancer segmentation or tumor segmentation primarily involves localized regions, the traditional focus on long-range contextual dependencies as provided by SSMs and Transformer s is less critical. 
%This distinction is vital: while SSMs and Transformer  models have shown effectiveness in long-range sequence tasks, their benefits diminish in scenarios like colorectal cancer segmentation where precise, localized predictions are paramount. The results affirm that a simpler architecture relying solely on gated convolutions can yield superior results without the need for complex contextual modeling.
%Moreover, the competitive performance observed with MambaOutUNet on the BTCV dataset supports our conclusion that both Transformer s and Mamba can be effective for longer-range sequencing tasks. However, for colorectal cancer segmentation, MambaOut demonstrates that simplicity in design can lead to significant improvements in accuracy and efficiency.

%In Table \ref{tab:result1}, we observe that the MambaOutUNet achieves a Dice score (DSC) of \(0.5203\), which outperforms the second-best method, SegMamba, by \(0.1213\) points. This improvement indicates that the localized processing capabilities of gated convolutional layers in MambaOut are highly effective for segmenting small areas of tumors, essential for accurate colorectal cancer diagnosis. Conversely, Methods incorporating SSMs and Transformer  architectures, while beneficial in contexts requiring long-range dependencies, do not provide the same level of performance for localized segmentation tasks. The focus on global context in these models may lead to unnecessary complexity without yielding proportional improvements in accuracy.
\vspace{-4mm}
\section{CONCLUSION}
\vspace{-2mm}
In this paper, we release CTS-204, a new colorectal tumor segmentation dataset with 204 distinct cases. We demonstrate the effectiveness of our MambaOut architecture for colorectal tumor segmentation which provides critical insights and a robust framework for future research in tumor segmentation. Our findings suggest a promising direction for further investigation into segmentation methodologies that prioritize performance on small-scale features. Additionally, we critically analyze segmentation architectures embedded with recent long range sequencing techniques and reassess their performance on two different medical image segmentation, which empirically supports our hypothesis. Moreover, we establish the importance of MambaOutUnet as a baseline architecture for future 3D volumetric segmentation research. 

%In summary, we have introduced a novel colorectal cancer segmentation dataset alongside the MambaOut architecture, which provides critical insights and a robust framework for future research in tumor segmentation. Our findings emphasize the importance of localized feature extraction and suggest a promising direction for further investigation into segmentation methodologies that prioritize performance on small-scale features. This research paves the way for enhancing accuracy in tumor detection and can guide subsequent advancements in medical imaging technologies.

\section{Compliance with ethical standards}
\label{sec:ethics}
This study was performed in line with the principles of the Declaration of Helsinki. Approval was granted by Northwestern University (No. STU00214545).
% \begin{itemize}
%   \item ``This is a numerical simulation study for which no ethical
%     approval was required.'' 
%   \item ``This research study was conducted retrospectively using
%     human subject data made available in open access by (Source
%     information). Ethical approval was not required as confirmed by
%     the license attached with the open access data.''
%     \item ``This study was performed in line with the principles of
%       the Declaration of Helsinki. Approval was granted by the Ethics
%       Committee of University B (Date.../No. ...).''
% \end{itemize}


\section{Acknowledgments}
\label{sec:acknowledgments}
This project is supported by NIH funding: R01-CA246704, R01-CA240639, U01-DK127384-02S1, and U01-CA268808.

%\small{\subsubsection*{COMPLIANCE WITH ETHICAL STANDARDS}} This research study was conducted retrospectively using human subject data made available in open access by Kvasir-SEG and CVC-ClinicDB. Ethical approval was not required.
%% \small{\subsubsection*{ACKNOWLEDGEMENTS}}
%\vfill
%\pagebreak
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
