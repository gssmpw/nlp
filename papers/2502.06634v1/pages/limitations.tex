\spara{Limitations.}
The language augmentation process relies on external LLMs, which introduce uncertainties because their robustness in other applications cannot be guaranteed. 
Additionally, results shown in Figure~\ref{fig:performance_diff_llms} demonstrate the impact of caption quality on molecular tasks, suggesting that developing techniques for filtering captions could be a valuable direction for future work.
% 
Moreover, while LLMs continue to improve in performance and ICL capabilities, \newmodel can benefit from these advancements. 
However, the domain-specific knowledge embedded in LLMs remains relatively limited. 
Thus, exploring practical solutions to incorporate more comprehensive domain knowledge into LLMs for language augmentation is a promising future direction for enhancing \pipeline.

\spara{Ethic Statement.} 
Throughout our work, we did not utilise any private or sensitive information.
The involved datasets are open-source, and outputs are available online to the community. 
However, it's essential to note that if any private information were to be inadvertently exposed to an LLM during internal pre-training and fine-tuning stages, \pipeline does not offer any privacy filtration mechanism.
Therefore, there exists the potential for privacy concerns associated with the underlying model to manifest through the output provided by \pipeline. 
