%\section{Price Change Inference with the Fine-tuned LLM}
\section{Price Change Inference with LLMs}
\label{sec:priceInfer}
\input{solidity-highlighting}
Instead of leveraging traditional symbolic or concrete execution techniques to estimate the price model through input and output data points, which results in a significant gap between the actual price calculation formulas and the approximating ones, we use LLMs to understand codes calculating token prices and extract corresponding price models, which eliminates the gap caused by estimation.
\subsection{LLM Fine-tuning}
\label{sec:finetune}

% Since LLMs are not designed for inferring tokens' price change, we need to fine-tune an LLM for our task.
% We choose GPT-3.5 Turbo as our baseline model
For fine-tuning techniques, we chose OpenAI's fine-tuning paradigm~\cite{OpenAI_Fine-tuning} instead of supervised fine-tuning (SFT)~\cite{chung2024scaling} and its parameter-efficient version, LoRA~\cite{hu2021lora}, because a very small set of training data is required for the former while much more data points are needed for the latter~\cite{ma2024combining}.
Moreover, OpenAI's GPT family models demonstrate state-of-the-art reasoning capabilities on common benchmarks~\cite{LLM_Leaderboard, sun2024llm4vuln}, which provides a suitable foundation for our fine-tuning.
Accordingly, \name has enhanced the GPT-3.5-Turbo and GPT-4o models with data synthesized using the commonly used price calculation model, i.e., CPMM as illustrated in \mysec\ref{sec:backg_priceModel}, along with on-chain data to fine-tune them.
% Compared to typical fine-tuning methods~\cite{hu2021lora, ouyang2022}, there are two challenges in fine-tuning a DeFi price-specific LLM:

% \begin{description}
%     \item [C1:] \textit{On-chain price change data cannot be easily collected.}
%     Unlike other fine-tuning data (e.g., vulnerability~\cite{ma2024combining} and code data~\cite{li2024extracting}) that can directly use past examples, we cannot use the limited number of past attack incidents to extract their price change data for fine-tuning because they will be used only for testing. As such, we simulate transactions to obtain our own fine-tuning data.
%     \ye{@juantao: This seems not a challenge but how we construct fine-tuning data.}\juantao{@Dao maybe we do not need to explain how to address the challenge here}\ye{agree}

%     %\item [C2:] \textit{It has two fine-tuning objectives to be achieved simultaneously.}
%     %Typically, fine-tuning is specific and has only one objective to achieve at a time. However, for our scenario, the fine-tuned LLM should be able to model price calculation and use it to infer price changes simultaneously to minimize the performance overhead involved in using LLMs. As such, we propose a CoT (Chain-of-Thought)-style~\cite{Check LLM4Vuln paper for this reference} fine-tuning that integrates two objectives into one fine-tuning template.

%     \item [C2:] \textit{This fine-tuning needs to be conducted in a CoT style.}
%     On-chain price change data alone cannot fine-tune an ideal DeFi price-specific LLM because price change must be associated with the context of a price model.
%     Therefore, during the fine-tuning process, we simultaneously strengthen LLMs' understanding of the \textit{price context} (i.e., different price variables and the corresponding price calculation model) before using on-chain data to ``teach'' LLMs the trend of price changes.
%     Hence, we propose a CoT (Chain-of-Thought)-style~\cite{sun2024llm4vuln} fine-tuning that integrates both on-chain data and the price context.
%     \ye{@juantao: Seems not a challenge but how we fine-tune}\juantao{@Dao maybe we do not need to explain how to address the challenge here}
% \end{description}
%\dao{I think the novelty here is 1) we fuzz to generate our own fine-tuning data, and 2) we adopt a CoT-style fine-tuning with two fine-tuning objectives achieved simultaneously}


\noindent
\textbf{On-Chain Data Simulation.}
We leverage the fuzz testing method in Foundry~\cite{Foundry}, an off-the-shelf toolkit for Ethereum application development, to simulate on-chain data.
% For the price context, we use the commonly used CPMM price model and its price calculation code statements. %\dao{Should we specify that here we use UniSwap only?}
% We found that this kind of standard price data is already sufficient\footnote{Indeed, our evaluation in \mysec\ref{sec:RQ2} shows that \fixme{LLMs can easily generalize the context to custom price models with an accuracy of 83\%. The eventual price change prediction accuracy is even as high as 93\%}.} for helping LLMs understand the context, which also helps us avoid using custom price models during the fine-tuning process that need to be tested to avoid data leakage.
To avoid data leakage and generate a substantial volume of transactions satisfying the CPMM, we select the Uniswap V2:BTC20~\cite{UniswapBTC20} liquidity pool as our target.
We randomly generate inputs, namely integers ranging from $10^{20}$ to $10^{21}$ --- 100 Ether to 1000 Ether, for the swap operations which are simulated on a forked blockchain of block height 17,949,214.
Specifically, to include the data of inflating the price of tokens, we craft particular operations.
To begin with, we record the balance of WETH and BTC20 in the liquidity pool denoted as $bal_{WETH}$ and $bal_{BTC20}$ respectively.
Then we trigger \texttt{swapExactTokensForTokens} in contract \texttt{UniswapV2Router02}~\cite{UniswapRouter} to swap a amount of BTC20 for WETH, and record the latest balance of WETH, $bal_{WETH}^{'}$, and that of BTC20, $bal_{BTC20}^{'}$.
Finally, we obtained the tokens' balance change as a pair ($bal_{WETH} - bal_{WETH}^{'}, bal_{BTC20} - bal_{BTC20}^{'}$).
In terms of deflating the price of tokens, we swap a amount of WETH for BTC20 instead, with similar subsequent operations.
Finally, we build a fine-tuning database comprising 500 pairs for price inflating and 500 pairs for price deflating, respectively.
Despite the only use of CPMM-based DeFi protocols, our evaluation results in~\mysec\ref{sec:evaluation} demonstrates a significant gain in term of price manipulation attack detection for DeFi protocols using custom price models.

%\dao{@Juantao, also you could learn the writing about fine-tuning from Sec. 6.3 in https://arxiv.org/pdf/2406.05498}
%\dao{Also, you have two kinds of prompt templates? \juantao{Yes. If the code of price calculation function could be extracted, which means the contract is open-source, we use Type-I prompt to query the LLM; if the contract is not open-source, but the contract is recorded as a possible liquidity pool (recorded while recovering High-level DeFi Operations, if the contract is marked as a pool in a Swap action), we use Type-II prompt to query the LLM (directly assume the price model in the contract aligns with CPMM)}}

\noindent
\textbf{CoT-style Fine-tuning.}
% To fine-tune DeFi price-specific models with collected transaction data, we chose the readily available and stable GPT-3.5 model to demonstrate that an off-the-shelf large language model could be easily trained to suit this task at a low cost.
\begin{figure}[!t]
    \centering
    \includegraphics[width=.9\linewidth]{Figure/Fine-tuning_prompt_v12.pdf}
    \vspace{-1ex}
    \caption{The prompt template used in fine-tuning the LLM.}
    \label{fig:fine-tuning_prompt}
\end{figure}
% \begin{figure}
%     \centering
%     \includegraphics[width=0.75\linewidth]{Figure/Expected response_v2.pdf}
%     \caption{An example of a expected response used in fine-tuning \dao{Do not put here. Put a sample response of the motivating example in appendix.}}
%     \label{fig:expected_response}
% \end{figure}
\myfig\ref{fig:fine-tuning_prompt} demonstrates the prompt template used in the fine-tuning.
We construct a CoT-style fine-tuning prompt that integrates both on-chain data and the price context.
Above the dashed line is the first instruction, which requires the LLM to extract the price calculation model from the provided code.
\texttt{\{code\}} is the placeholder for the code snippet of price calculation functions.
%Pang et al.~\cite{pang2024language} discerned that LLMs exhibit superior proficiency in evaluation tasks compared to text generation.
Below the dashed line, we guide the LLM to evaluate the credibility of four statements based on the price model extracted from step 1 and the tokens' balance change.
We demand that the LLM expresses the credibility of a statement using integers ranging from 1 to 10.
Compared to merely responding with a simple ``Yes'' or ``No,'' this scoring method also indicates the confidence level of the responses, which can assist us in selecting the answers in which the LLM is more confident.


%In the fine-tuning process, since we exclusively utilize the CPMM for training, the code is set to the \texttt{swapExactTokensForTokens} function, which we use to collect the fine-tuning data, in UniswapV2Router02~\cite{UniswapRouter}, along with its sub-calls, including the core function \texttt{getAmountOut} (as shown in \mylist\ref{lst:getAmountOut}) calculating the price of tokens based on the CPMM. To enhance the model's ability to correctly focus on the price calculation function amid a vast amount of code, we provide the complete invocation chain code from \texttt{swapExactTokensForTokens} to \texttt{getAmountOut}, rather than solely providing the code for \texttt{getAmountOut}.
%\juantao{Since we only use swapExactTokensForTokens, so I think this part plays a relatively weak role and not strong enough to prove we also improve model's ability on extracting correct code from a vast amount of code}
%
%Given an input amount of an asset and pair reserves, function \texttt{getAmountOut} collects 0.3\% fee on the input asset and returns the maximum output amount of the other asset. Based on our observations, aside from PancakeSwap, most DEXs utilizing CPMM directly invoke \texttt{getAmountOut} in UniswapV2Router02 to calculate the price of tokens in the liquidity pool, rather than implementing their own version; the only difference in the PancakeSwap version of \texttt{getAmountOut} function lies in the fee rate charged. Due to page limitations, we have included the complete invocation chain code used in fine-tuning and the PancakeSwap version of function \texttt{getAmountOut} in Appendix \ref{} and Appendix \ref{} respectively.
%\begin{lstlisting}[language=Solidity, caption=The \texttt{getAmountOut} function called by \texttt{swapExactTokensForTokens} in UniswapV2Router02 contract, label=lst:getAmountOut]
%function getAmountOut(uint amountIn, uint reserveIn, uint reserveOut) internal pure returns (uint amountOut) {
%    require(amountIn > 0, 'UniswapV2Library: INSUFFICIENT_INPUT_AMOUNT');
%    require(reserveIn > 0 && reserveOut > 0, 'UniswapV2Library: INSUFFICIENT_LIQUIDITY');
%    uint amountInWithFee = amountIn.mul(997);
%    uint numerator = amountInWithFee.mul(reserveOut);
%    uint denominator = reserveIn.mul(1000).add(amountInWithFee);
%    amountOut = numerator / denominator;
%}
%\end{lstlisting}


In the data part of the template, \texttt{\{$value_0$\}} and \texttt{\{$value_1$\}} are the placeholders for the first and second values in a price change pair, which are sampled from the fine-tuning dataset, respectively.
\texttt{\{direction of change\}} can be either ``increases'' or ``decreases.''
Specifically, if \texttt{\{$value_i$\}} is greater than 0, \texttt{\{direction of change\}} is ``increases''; conversely, if \texttt{\{$value_i$\}} is less than 0, \texttt{\{direction of change\}} is ``decreases.''
For the answer part, \texttt{\{score\}} is the score placeholder, which can be an integer between 1 and 10.

%To fill various data into the template, we first randomly sample 80 pieces of data from the fine-tuning database and embed them into our prompt template, then we use these prompts to query the original GPT-3.5 model and collect its responses. We manually review and amend all responses to ensure both the logic and result of the inference are correct, then we use them as \fixme{templates for responses}\dao{?}.

%\juantao{Answer to Review\#A.Q2+Review\#D—Fine-tuningProcedure+Effectiveness}
Following OpenAI's fine-tuning guideline~\cite{OpenAI_Fine-tuning} that recommends using 50 to 100 training examples, we randomly sample 96 non-repetitive (in current and previous training sets) data from the fine-tuning database, and allocate 83\% of the samples for training and 17\% for validation.
Subsequently, we insert data from the training and validation sets into the prompt template.
% \ye{To construct the response to a corresponding prompt, we randomly select one from the response templates and manually adjust it based on the actual data presented in the prompt. @juantao: not clear. you may want to highlight groundtruth response?\juantao{Want to highlight we have several response templates instead of a single fixed response} \ye{Do we have other reponse templates, where?} \juantao{We first use 80 samples to query the LLM to get a collection of response, and use them as templates, but we do not systematically summarize them}}
To obtain the desired response for each prompt, we firstly ask LLMs to generate raw response, including the analysis of price model and scores of statements, for the given prompt. 
Next, we manually verify the correctness of the responses, of which the correct responses are stored and the wrong responses will also be corrected. Particularly, we simply swap the scores of two opposite statements to correct the error in them.
Through this process, we construct a ground truth about prompts and its responses for fine-tuning the LLM model.

%\juantao{The orignial version is for GPT-3.5, I have revised} 
During the fine-tuning process, training hyperparameters were automatically configured by the OpenAI fine-tuning API used.
In particular, once the model achieved 100\% accuracy on the validation set, we terminated the training to avoid overfitting. The entire fine-tuning process is cost-efficient, consuming a total of around 1 million training tokens for each model.
The detailed costs across different models will be introduced in \mysec\ref{sec:RQ2}.

% After fine-tuning four times, the model reaches 100\% accuracy on the validation set.
% We further sample 100 pieces of data that had never been selected from the entire fine-tuning dataset for evaluation, achieving an inference accuracy of 99\%, thus we stop to prevent overfitting.
% The entire fine-tuning process is cost-efficient, consuming a total of 1,130,325 training tokens at an expense of around \$8~\cite{OpenAI_Price}.

% \begin{table}
%     \centering
%     \begin{tabular}{lllll} \hline  
%          & 1st FT & 2nd FT & 3rd FT & 4th FT \\ \hline  
%         Accuracy & 43.5\% & 58\% & 65\% & 99\%\\ \hline 
%     \end{tabular}
%     \caption{Accuracy Change of Fine-tuning (FT).}
%     \label{tab:my_label}
% \end{table}



\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Figure/UwULend_prompt_res_v12.pdf}
    \vspace{-2ex}
    \caption{The simplified Type-I prompt and its response for the motivating example during the inference process.}
    \label{fig:moti_prom_res}
\end{figure*}


\subsection{Inference with the Fine-tuned LLM}
\label{sec:inference}

In this section, we first illustrate the \emph{general inference process} using the motivating example.
Nevertheless, there could be closed source DeFi protocols that dissatisfy steps \ding{176}\ding{177} so that we design a \emph{customized inference process} to deal with them.


\noindent
\textbf{General Inference Process.}
To assist LLMs in extracting and analyzing the price model, our inference prompt provides relevant code for LLMs to score the trend of price changes and guides them in inferring the token price changes.
\myfig\ref{fig:moti_prom_res} illustrates a simplified version of the prompt used and the response produced by our fine-tuned LLM for inferring price changes of the motivating example in \mysec\ref{sec:motivatingexample}.
We call this Type-I prompt, used for the typical cases with code input retrieved from steps \ding{176}\ding{177}.
It is different from the fine-tuning prompt in the \texttt{\{statement\}} and \texttt{\{change\_description\}} parts.
In the fine-tuning prompt shown in \myfig~\ref{fig:fine-tuning_prompt}, both parts are fixed, while they are dynamically generated during inference using two formats:
(i) ``The price of \texttt{\{token\_name\}} in \texttt{\{contract\_name\}} \texttt{\{direction\_of\_change\}} after change'' for the placeholder \texttt{\{statement\}};
and (ii) ``The balance of \texttt{\{token\_name\}} in \texttt{\{contract\_name\}} \texttt{\{direction\_of\_change\}} by \texttt{\{change\_value\}}'' or ``The total supply of \texttt{\{token\_name\}\{direction\_of\_change\}} by \texttt{\{change\_value\}}'' for the placeholder \texttt{\{change\_description\}}.
However, to fill them in Type-I prompt, \name generates a pair of statements for each token, i.e., one regarding the increase in token price and another regarding the decrease in token price.
%For complete prompt and response, readers may refer to Appendix \ref{complete_prom_resp}.
%Besides the contract code supplied, we also add the name of the corresponding contract in comments to assist the LLM in understanding the invocation relationships among different contracts.

%Before asking the LLM to make an inference
\name asks the fine-tuned LLM to locate the price calculation model from the input code and evaluate the credibility of the generated statements.
% After the inference is generated, \name extracts each statement and its corresponding score from the LLM's response using regular expression matching, and chooses the statement with the higher score in the pair as the most confident inference made by the LLM.
% For statements with the same score in a pair, we assert that the corresponding token's price remains unaffected.
From the motivating example's response shown in the right-hand section of \myfig\ref{fig:moti_prom_res}, the LLM initially extracts the code of price calculation-related functions, followed by an high-level summary.
In this example, it accurately identifies the underlying price model (see \cref{PriceOfsUSDe}) --- the price of \texttt{sUSDe} is determined by the median of multiple prices.
With this knowledge learned, the LLM could credit two opposite statements given the tokens balance changes and yields the correct answer with high confidence.
% The section below the dashed line shows the formatted answer for inferring the trend in price changes, indicating the model's belief in the higher credibility of the second statement (which is correct in this example) by assigning it a higher score than the first.
% The difference in scores between the two statements reflects the model's high confidence in its judgment.

%\noindent\textbf{Inference with source code.}
%\mytab\ref{tab:pratical_detection_prompt} details the structures of \texttt{\{statement\}} and \texttt{\{change\_description\}}, highlighting the primary differences between the prompt template used for practical detection and that for fine-tuning.

\begin{figure}[!t]
    \centering
    \includegraphics[width=.9\linewidth]{Figure/Type-II_prompt_v9.pdf}
    \vspace{-1ex}
    \caption{The Type-II prompt for closed-source liquidity pools.}
    \label{fig:type-II_prompt}
\end{figure}

\noindent
\textbf{Customized Inference Process.}
Although the majority of DeFi applications are open source to gain users' trust, some remain closed source, making our Type-I prompt inapplicable.
To address this, we developed a Type-II prompt template, as shown in \myfig\ref{fig:type-II_prompt}, to infer the trend of price changes in closed source two-token liquidity pools.
Our observation is that the majority of two-token liquidity pools pools use the CPMM as their underlying price model.
Therefore, the primary distinction between the Type-I prompt and the Type-II prompt lies in replacing the first instruction with a description of the liquidity pool, informing the LLM that the pool's price model aligns with CPMM.
It is worth noting that the liquidity pool is automatically identified during transaction analysis, which will be introduced in \mysec\ref{sec:defiOperation}.
Due to page limitation, we include a case study of using the Type-II prompt for inference in Appendix~\ref{sec:case_study_type_II_prompt}.


%\begin{table*}[!t]
%    \centering
%    \begin{tabular}{cc}
%    \Xhline{3\arrayrulewidth}
%        Placeholder & Details\\
%        \Xhline{2\arrayrulewidth}
%         \texttt{\{statement\}} & The price of \texttt{\{token\_name\}} in \texttt{\{contract\_name\}} \texttt{\{direction\_of\_change\}} after change \\
%         \hline
%         \texttt{\{change\_description\}} & \makecell[c]{a. The balance of \texttt{\{token\_name\}} in \texttt{\{contract\_name\}} \texttt{\{direction\_of\_change\}} by \texttt{\{change\_value\}} \\
%         b. The total supply of \texttt{\{token\_name\}} \texttt{\{direction\_of\_change\}} by \texttt{\{change\_value\}}}\\
%    \Xhline{3\arrayrulewidth}
%    \end{tabular}
%    \caption{The detailed structure of placeholder \texttt{\{statement\}} and \texttt{\{change\_description\}}. \texttt{\{direction\_of\_change\}} can be either ``increases'' or ``decreases''.}
%    \label{tab:pratical_detection_prompt}
%\end{table*}


%\begin{figure}[!t]
%    \centering
%    \includegraphics[width=0.75\linewidth]{Figure/Type-I prompt_v4.pdf}
%    \caption{The common prompt for inferring trend of tokens' price change.}
%    \label{fig:type-I_prompt}
%\end{figure}