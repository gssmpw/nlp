\section{Related Work}
\vspace{3ex}
In this section, we summarize two lines of research that are most relevant to ours.

\noindent\textbf{Data Bias and Shortcut Learning.}\quad
Textual data contain various types of biases, such as word co-occurrence~\cite{gururangan2018annotation}, lexical overlap~\cite{mccoy2019right}, partial inputs~\cite{gururangan2018annotation,poliak2018hypothesis}, and negation words~\cite{utama2020towards}.
Models trained on such biased data will capture spurious correlations in the data without achieving true semantic understanding. This phenomenon is known as \emph{shortcut learning}.
One study models the distribution of shortcut words as a long-tail distribution and uses its characteristics to debias models~\cite{du2021towards}.
Most shortcut phenomena stem from the co-occurrence of specific words and labels. For example, negation words like ``no'' and ``none'' often correlate with contradiction labels in natural language inference tasks~\cite{gururangan2018annotation}.
Recent studies have shown that shortcut learning can negatively impact model performance on OOD datasets~\cite{geirhos2020shortcut,gururangan2018annotation}.

\vspace{2pt}
\noindent \textbf{Shortcut Mitigation.}\quad 
Clark et al. proposed a Product of Experts method that combines a bias-only model's knowledge with a base model~\cite{clark2019don}. It first trains a bias-only model and then uses its predictions to train a robust model \cite{schuster2019towards}.
Similar to focal loss \cite{lin2017focal}, example reweighting \cite{clark2019don} improves models by down-weighting overconfident examples, i.e., shortcut examples.
Confidence regularization \cite{utama2020mind} encourages models to reduce confidence in predictions for biased samples.
Soft label encoding proposed to train a teacher model to determine the shortcut degree, then the degree is used to generate soft labels for robust model training~\cite{he2023mitigating}. DCT employs a positive sampling
strategy to mitigate features in the sample~\cite{lyu2023feature}.

In contrast to these previous methods, our proposed framework takes a more direct approach by explicitly suppressing the NLU model's ability to capture undesirable correlations between shortcut tokens and certain labels. This is achieved through a combination of strategic token masking and distribution alignment, providing a more transparent way to reduce shortcut reliance while maintaining model performance.