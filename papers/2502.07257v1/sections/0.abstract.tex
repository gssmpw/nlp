As the popularity of Internet of Things (IoT) platforms grows, users gain unprecedented control over their homes, health monitoring, and daily task automation. 
However, the testing of software for these platforms poses significant challenges due to their diverse composition, \eg common smart home platforms are often composed of varied types of devices that use a diverse array of communication protocols, connections to mobile apps, cloud services, as well as integration among various platforms. 
This paper is the first to uncover both the practices and perceptions behind testing in IoT platforms, particularly open-source smart home platforms. 
Our study is composed of two key components. First, we mine and empirically analyze the code and integrations of two highly popular and well maintained open-source IoT platforms, \openhab and \homeassistant. Our analysis involves the identification of functional and related test methods based on the \textit{focal method approach}.
We find that \openhab has only $0.04$ test ratio ($\approx 4K$ focal test methods from  $\approx 76K$ functional methods) in Java files, while \homeassistant exhibits higher test ratio of $0.42$, which reveals a significant dearth of testing. Second, to understand the developers' perspective on testing in IoT, and to explain our empirical observations, we survey 80 open-source developers actively engaged in IoT platform development. 
Our analysis of survey responses reveals a significant focus on automated (unit) testing, and a lack of manual testing, which supports our empirical observations, as well as testing challenges specific to IoT. Together, our empirical analysis and survey yield 10 key findings that uncover the current state of testing in IoT platforms, and reveal key perceptions and challenges.
These findings provide valuable guidance to the research community in navigating the complexities of effectively testing IoT platforms. 








