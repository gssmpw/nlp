\documentclass{article}
\usepackage{enumitem}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{adjustbox}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
\usepackage{bm}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{color,soul}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\DeclareMathOperator*{\EE}{\mathbb{E}}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% Add other packages
\usepackage{enumitem}
\DeclareMathOperator{\expectation}{\mathbb{E}}
% \let\algorithm\relax
% \let\algorithm*\relax
% \let\listofalgorithms\relax
% \usepackage[ruled,linesnumbered,vlined]{algorithm2e}
% \usepackage[ruled,linesnumberedvlined,algo2e]{algorithm2e}
\usepackage{nicefrac}
\usepackage{multirow}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models}


\newcommand\jinhao[1]{\textcolor{blue}{$^\textbf{JL}$: [#1]}}
\newcommand{\nando}[1]{\textcolor{purple}{$^{\tt NF:}$ [#1]}}

\begin{document}

\twocolumn[
\icmltitle{Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
% \icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Jinhao Liang}{uva}
\icmlauthor{Jacob K. Christopher}{uva}
\icmlauthor{Sven Koenig}{uci}
\icmlauthor{Ferdinando Fioretto}{uva}
\end{icmlauthorlist}

\icmlaffiliation{uva}{{Department of Computer Science}, {University of Virginia}, {Charlottesville, VA 22903, USA}}
\icmlaffiliation{uci}{{Department of Computer Science}, {University of California}, {Irvine, CA 92697, USA}}

\icmlcorrespondingauthor{Ferdinando Fioretto}{fioretto@virginia.edu}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{} % otherwise use the standard text.

\begin{abstract}
Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. 
Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility.
These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces.
To address this challenge, this work proposes \textbf{S}imultaneous \textbf{M}RMP \textbf{D}iffusion (SMD), a novel approach integrating constrained optimization 
into the diffusion sampling process to produce collision-free, kinematically feasible trajectories.
Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments.
\end{abstract}

\section{Introduction}
Multi-Robot Motion Planning (MRMP) is a fundamental problem in robotics and autonomous systems, where the goal is to compute collision-free paths for multiple robots navigating shared environments~\cite{luo2024potential,shaoul2024multi}. MRMP has widespread applications, from autonomous vehicles to warehouse logistics and search-and-rescue, where robots must operate efficiently in complex and highly constrained settings. 
Despite its importance, solving MRMP in real-world scenarios remains challenging due to the need to plan trajectories in continuous spaces and the unstructured nature of their inputs.
% jinhao: mrmp algorithms (e.g., RRT and PRM) can handle continuous spaces
These inputs often lack the structured representations needed by classical algorithms, which require implicit representation of both robot state spaces and obstacles in configuration spaces~\cite{lavalle2006planning,8460730,luo2024potential}. Consequently, classical approaches struggle to operate effectively in these high-dimensional environments~\cite{wang2021survey,10122127}. Moreover, classical sampling-based planners often yield non-smooth paths due to their reliance on discrete connectivity between sampled configurations~\cite{carvalho2024motion}. Optimization-based methods suffer from similar issues, as they require computationally expensive trajectory refinements to enforce smoothness and feasibility \cite{ichnowski2020deep}.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{Figures/trajectories.pdf}
    \caption{SMD incorporates a projection operator to enforce hard constraints within the diffusion process. During sampling, the projection operator iteratively corrects trajectories by mapping them to the nearest feasible points, resulting in final collision-free paths. In the experiments, the red objects appear at sampling time only, and the robots move from their start $\bullet$ to their goal positions $\star$.}
    \label{fig:diagram_pdm}
\end{figure*}

To address these challenges, learning-based methods offer a promising alternative by leveraging data-driven priors to handle unstructured environments. 
Recently, diffusion models, a class of generative models originally developed for image and signal processing tasks~\cite{song2019generative,ho2020denoising}, have shown promise for single-robot motion planning~\cite{carvalho2023motion,christopher2024constrained}.
However, extending diffusion models to MRMP presents new challenges: while these models effectively produce diverse trajectories, they fail to enforce hard constraints such as inter-robot collision avoidance and kinematic feasibility.

Existing diffusion-based approaches attempt to address these constraints through gradient-based guidance or rejection sampling \cite{okumura2022ctrms,carvalho2023motion}. However, gradient-based methods are prone to fail in such scenarios due to the non-convex nature of collision avoidance constraints, complicating trajectory correction. Rejection sampling methods, conversely, suffer from inefficiencies, discarding large portions of generated trajectories and struggling to generate feasible solutions in cluttered environments \cite{carvalho2024motion,christopher2024constrained}.


To address these limitations, this paper introduces \emph{Simultaneous MRMP Diffusion} (SMD), a novel approach that integrates constrained optimization directly into the diffusion process to generate feasible multi-robot trajectories.  
This work reformulates MRMP within a constrained diffusion framework, where diffusion-based trajectory generation is guided by an augmented Lagrangian method. This approach enables diffusion models to satisfy collision avoidance and kinematic constraints without post-hoc filtering, making them applicable even in high-density, unstructured environments. Unlike prior methods, which degrade significantly in cluttered scenarios, our framework maintains feasibility even as the number of robots and obstacles increases. 
The overall scheme is illustrated in Figure \ref{fig:diagram_pdm}.


\textbf{Contributions.} The paper makes the following contributions:
{\bf (1)} It introduces Simultaneous MRMP Diffusion (SMD), which formulates multi-robot trajectory generation as a constrained diffusion process, ensuring collision-free and kinematically feasible motion plans.
{\bf (2)} It integrates constrained optimization directly into the sampling process of diffusion models, enabling the direct embedding of constraints within the trajectory generation pipeline.
{\bf (3)} It proposes a Lagrangian-dual based method that dramatically improves the frequency with which these nonconvex constraints can be satisfied during diffusion sampling.
{\bf (4)} Finally, it introduces the first benchmark for MRMP evaluation, featuring complex input maps and diverse scenarios. Our approach demonstrates significant improvements over competing methods, particularly in environments with dense obstacles and unstructured configurations.

\section{Related Work}
\textbf{Motion Planning.}
Motion planning computes a feasible path for a robot to move from its start to its goal state while avoiding obstacle collisions.
Sampling-based algorithms, such as Probabilistic Roadmaps~\cite{508439} and Rapidly-Exploring Random Trees (RRTs)\cite{lavalle1998rapidly} have been widely studied for this task. These methods guarantee probabilistic completeness but face significant scalability issues in multi-robot motion planning (MRMP) as the configuration space of MRMP scales. 
Alternatively, MRMP can be formulated as a constrained optimization problem, employing methods such as gradient optimization techniques~\cite{ratliff2009chomp} and sequential convex programming~\cite{6385823,7140034}. However, these approaches encounter difficulties when taking into account changes in acceleration~\cite{ichnowski2020deep} and are usually too conservative to find any solution, even if one exists~\cite{7140034}. 
Other lines of research focus on a discretized version of this problem, known as multi-agent path finding. Specifically, multi-agent path finding reduces the configuration space by discretizing both time and space into steps and grids, respectively~\cite{stern2019multi}. This simplification has enabled the development of efficient search-based algorithms~\cite{li2019improved, li2021eecbs,okumura2022priority}. However, these assumptions create a disconnect from real-world applications~\cite{shaoul2024multi}. Unlike these approaches, this paper develops SMD, a diffusion-based MRMP framework that directly learns the distribution of collision-free paths and generates feasible solutions for multiple robots simultaneously in complex environments.

\textbf{Motion Planning with Generative Models.}
Recent advancements in generative models have opened new avenues for solving motion planning problems by learning complex, high-dimensional distributions of feasible paths. For example, \citet{okumura2022ctrms} employed a conditional variational autoencoder to predict cooperative timed roadmaps. Since~\citet{janner2022planning} introduced diffusion models into motion planning, subsequent research has largely focused on using gradient-based methods to guide the outputs of diffusion models toward feasible solutions~\cite{carvalho2023motion,luo2024potential,10610519,ubukata2024diffusion,carvalho2024motion}. These works design tailored cost functions to guide the generation of diffusion models during the sampling process. Although these approaches leverage the ability of diffusion models to generate diverse trajectories, they are unable to ensure constraint satisfaction in scenarios with complex environments, let alone multiple robots. 
In fact, most existing work has primarily addressed single-robot motion planning, leaving multi-robot motion planning underexplored. Recently,~\citet{shaoul2024multi} combined diffusion models with search-based multi-agent path finding algorithms, where the diffusion models generate trajectories for a single robot, and a search-based algorithm determines the final trajectories for multiple robots. While this is a substantial contribution towards MRMP, it does not ensure the feasibility of the trajectories generated by diffusion models, particularly in environments with dense obstacles or complex robot interactions. 
In contrast, our proposed SMD directly integrates optimization techniques into the diffusion process, enabling the generation of feasible MRMP trajectories even in scenarios with a significant number of robots and obstacles.

\section{Preliminaries}

\paragraph{Score-based Diffusion Models.} 
Generative diffusion models \cite{sohl2015deep, ho2020denoising} produce high-fidelity complex data operating in two phases: A \emph{forward step}, that gradually introduce noise to clean data samples, followed by a \emph{reverse denoising step}, in which a deep neural network is trained to iteratively remove noise. This forward process defines a Markov chain $\{\bm{x}_t\}_{t=0}^T$, with initial sample $\bm{x}_0 \sim p(\bm{x}_0)$ and each transition \( q(\bm{x}_t | \bm{x}_{t-1}) \) realized by adding Gaussian noise according to a variance schedule $\alpha_t$. 
In \emph{score-based diffusion} \cite{song2019generative, song2020score}, the reverse process relies on a learned score function \(s_{\theta}(\bm{x}_t, t) = \nabla_{\bm{x}_t} \log p(\bm{x}_t)\) that approximates the gradient of the log probability density of the noisy data. 
This score function is trained to minimize
%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation*}
\label{eq:score}
    % \scriptsize
    \displaystyle 
    \min_{\theta} \EE_{\substack{t \sim [1,T], p(\bm{x}_0),\\ 
    q(\bm{x}_t|\bm{x}_0)}}
    (1 -{\alpha}_t)
    \left[ \left\| \bm{s}_{\theta}(\bm{x}_t, t) - \nabla_{\bm{x}_t} \log q(\bm{x}_t|\bm{x}_0) \right\|^2 \right],
\end{equation*}
and is then used to iteratively ``denoise'' random noise samples back into data-like samples. 
This is also known as the \emph{sampling} phase.


\textbf{Multi-Robot Motion Planning.}
Multi-Robot Motion Planning (MRMP) involves computing collision-free trajectories for multiple robots navigating a shared environment from designated start positions to goal states. Consider a set of $N_a$ robots $\mathcal{A} = \{ a_1, a_2, \ldots, a_{N_a} \}$ operating in a continuous workspace. 
Each robot $a_i$ is modeled as a sphere with radius $r_i > 0$ and has a trajectory over $H$ time steps denoted by $\boldsymbol{\pi}_i = [\pi_i^1, \pi_i^2, \ldots, \pi_i^H]$, where $\pi_i^h = (x_i^h, y_i^h) \in \mathbb{R}^2$ represents the robot's states at time $h$. 
For each robot, their start and target states are defined, respectively by sets $\mathbf{B} = [b_1, b_2, \ldots, b_{N_a}]$ and $\mathbf{E} = [e_1, e_2, \ldots, e_{N_a}]$. 
The robots must navigate around $N_o$ obstacles $\mathcal{O} = \{ o_1, \dots, o_{N_o} \}$ while adhering to kinematic constraints such as velocity and acceleration limits. 

The objective is to compute a feasible set of trajectories $\boldsymbol{\Pi} = \{\boldsymbol{\pi}_1, \boldsymbol{\pi}_2, \ldots, \boldsymbol{\pi}_{N_a}\}$, that minimizes a predefined cost function while ensuring feasibility to environmental constraints and inter-robot collision avoidance. Formally,
 \begin{subequations} 
    \begin{align} 
    \min_{\boldsymbol{\Pi}} & \quad \mathcal{J}(\boldsymbol{\Pi}) \label{mapf_objective} \\ 
    \text{s.t.} & \quad \boldsymbol{\Pi} \subseteq \Omega_{\text{obs}}, \label{mapf_constraint_env} \\ 
    & \quad \pi_i^1 = b_i, \quad \forall i \in [N_a], \label{mapf_constraint_start} \\ 
    & \quad \pi_i^H = e_i, \quad \forall i \in [N_a], \label{mapf_constraint_goal} \\
    & \quad \text{Kinematic constraints on } \boldsymbol{\Pi}, \label{mapf_constraint_kinematic} \\ 
    & \quad \text{Collision avoidance between robots in } \boldsymbol{\Pi}, \label{mapf_constraint_collision} 
    \end{align} 
\end{subequations} 
    where $\mathcal{J}: \mathbb{R}^{N_a \times H \times 2} \rightarrow \mathbb{R}^+$ represents the cost function, which may include objectives such as total travel time or energy consumption, and $\Omega_{\text{obs}}$ is the feasible region, excluding obstacle-occupied space.
    Constraints \eqref{mapf_constraint_env} ensure that robots avoid obstacles, 
    \eqref{mapf_constraint_start} and \eqref{mapf_constraint_goal} ensure that each robot starts at its initial position and reaches its target position.
    \eqref{mapf_constraint_kinematic} enforce kinematic limits, defined by a maximum reachable velocity, and \eqref{mapf_constraint_collision} ensures collision avoidance, maintaining a minimum Euclidean separation between robots at all time steps. 
Subsequently, we denote constraint set \eqref{mapf_constraint_start}\mbox{--}\eqref{mapf_constraint_collision} with $\Omega$.
    
The MRMP problem poses significant challenges due to the difficulty of representing and navigating unstructured, high-dimensional configuration spaces and coordinating dynamic interactions among multiple robots in continuous  environments~\cite{stern2019multi,shaoul2024multi}. 

\section{Simultaneous MRMP Diffusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To address these challenges, this section introduces Simultaneous MRMP Diffusion (SMD), a diffusion-based method for MRMP. We start by introducing the concept of repeated projections, which constitutes a core building block of SMD. Then, the section discusses how to integrate the multi-robot motion planning constraints into the diffusion framework and, finally, how to enable effective sampling in complex, high-dimensional MRMP tasks. 

\begin{algorithm}[t]
\caption{Diffusion Sampling Process in SMD}
\label{alg:pgd_annealed_ld}
\begin{algorithmic}[1] % [1] for line numbering
\STATE \textbf{Input:} Gaussian Noise $\mathbf{x}_T^0$
\FOR{$t = T$ $\rightarrow$ $1$}
    \STATE \textbf{Initialize} $\gamma_t$
    \FOR{$i = 1$ $\rightarrow$ $M$}
        \STATE Sample $\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$
        \STATE Compute $\mathbf{g} \gets \boldsymbol{s}_{\theta}(\mathbf{x}_t^{i-1}, t)$
        \STATE Update $\mathbf{x}_{t}^{i} \gets \mathcal{P}_{\Omega}(\mathbf{x}_{t}^{i-1} + \gamma_t \mathbf{g} + \sqrt{2\gamma_t}\mathbf{z})$
    \ENDFOR
    \STATE $\mathbf{x}_{t-1}^0 \gets \mathbf{x}_t^M$
\ENDFOR
\STATE \textbf{Output:} $\mathbf{x}_0^0$
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Repeated Projections.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Incorporating constrained optimization techniques into generative models has been an important direction in ensuring feasibility in structured domains.
Diffusion models inherently use a variant of \emph{Langevin Monte Carlo sampling}, known as \emph{Stochastic Gradient Langevin Dynamics} (SGLD), for their denoising sampling process. SGLD introduces an additional stochastic perturbation to gradient-based updates, resulting in a non-deterministic version of natural gradient descent. This allows it to from getting trapped in local minima and enables diverse sampling trajectories~\cite{welling2011bayesian}. Given this perspective, the diffusion sampling process can be viewed as an iterative optimization problem aimed at maximizing the log-likelihood of the true data distribution.

Building upon this understanding from \citet{christopher2024constrained}, we can extend the standard diffusion process by incorporating a feasible region \(\Omega\):
\begin{subequations}
\label{eq:constrained_optimization}
    \begin{align}
        \label{eq:constrained-diffusion}
        \min_{\mathbf{x}_{T}, \ldots, \mathbf{x}_{1}} &\ \sum_{t = T, \ldots, 1} - \log q(\mathbf{x}_{t}|\mathbf{x}_0) \\
        \label{eq:constrained-diffusion-constr}
        \textrm{s.t.}  &\quad \mathbf{x}_{T}, \ldots, \mathbf{x}_{0} \in \Omega.
    \end{align}
\end{subequations}
To enforce these constraints during the generative process, it is possible to  modify the standard Stochastic Gradient Langevin Dynamics update rule by introducing a \emph{projection step} after each iteration:
\begin{equation}
    \label{eq:reverse-pgd}
    \mathbf{x}_{t}^{i+1} = \mathcal{P}_{\Omega} \underbrace{\left(\mathbf{x}_{t}^{i} + \gamma_t \nabla_{\mathbf{x}_{t}^{i}} \log q(\mathbf{x}_{t}|\mathbf{x}_0) + \sqrt{2\gamma_t}\mathbf{z}\right)}_\text{classic reverse process},
\end{equation}
where $\mathbf{z}$ is standard normal, $\gamma_t > 0$ is the step size, $\nabla_{\mathbf{x}_{t}^{i}} \log q(\mathbf{x}_{t}|\mathbf{x}_0)$ is approximated by the learned score function $\mathbf{s}_{\theta}(\mathbf{x}_t, t)$, $\Omega$ is the set of constraints, and $\mathcal{P}_{\Omega} (\bm{x}) = \arg\min_{\bm{x}' \in \Omega} \| \bm{x} - \bm{x}'\|^2$ is a projection onto $\Omega$.


A key theoretical advantage of this approach is that it retains the convergence guarantees of Langevin-based sampling. Specifically, this constrained diffusion process \emph{converges to an ``almost-minimizer'' of the objective function} within
\(
O\left(\frac{d^2}{\sigma^{1/4} \lambda^*} \log(1/\epsilon)\right),
\)
where \(\sigma^2\) is the variance schedule, \(\lambda^*\) is the uniform spectral gap of Langevin diffusion, and \(d\) is the problem dimension~\cite{welling2011bayesian}. 

Importantly, as shown in~\cite{christopher2024constrained}, this process guarantees that the generated outputs satisfy constraints from convex sets under mild conditions.

\subsection{Collision-free Projection Mechanism}
While the application of repeated projections provides a useful primitive to steer samples generated by diffusion models to satisfy relevant constraints, projecting onto the space of collision-free and kinematically viable trajectories presents a critical challenge due to the nonconvex nature of these constraints and the high dimensionality of the problem. These issues make the standard application of projected diffusion ineffective in solving even simple problem instances. 
To address this shortcoming, this section introduces the augmented Lagrangian method~\cite{boyd2011distributed} to vastly enhance the tractability of projections onto a multi-robot motion planning feasible set. The following first presents the projection mechanism for SMD, which aims to generate feasible trajectories for all robots in the problem. It then demonstrates how this process can be vastly accelerated by leveraging an augmented Lagrangian method. 


Note that the feasible region $\Omega$ for the MRMP problem can be represented by distinguishing between convex and nonconvex constraints. This distinction will be useful later to provide an accelerated version of the projection operator introduced above. 

\textbf{Convex Constraints.}
First, note that each robot’s trajectory must begin and end at its designated start and goal locations, as enforced by Constraints \eqref{mapf_constraint_start} and \eqref{mapf_constraint_goal}. Additionally, robots must respect maximum velocity limits between consecutive time steps:
\begin{align} 
\small
\left( \pi_i^{h} - \pi_i^{h-1} \right)^2 \leq 
    \left( v_i^\text{max} \Delta t \right)^2, 
    \; \forall i \!\in\! [N_a], h \!\in\! \{2, \ldots, H\}, \label{eq:convex_velocity} 
\end{align} 
where $v_i^\text{max}$ represents the maximum allowable velocity for robot $a_i$, and $\Delta t$ is the time interval between steps.
Together, these constraints define a \emph{convex set}: 
\begin{align*} 
    \Omega_c = 
    \left\{ \boldsymbol{\Pi} \in \mathbb{R}^{N_a \times H \times 2} \Big| \text{Constr. } \eqref{mapf_constraint_start}, \eqref{mapf_constraint_goal}, \text{ and } \eqref{eq:convex_velocity} \text{ hold} \right\}. 
\end{align*}


\paragraph{Nonconvex Constraints.}
To ensure collision-avoidance the following nonconvex constraints must also be imposed: 
\begin{align}
    (\pi_i^h - \pi_j^{h})^2 \geq (R^a)^2, \forall i, j, \ i \neq j \in [N_a], h \in [H], \label{nonconvex_robot_collision}
\end{align}
where $R^a$ denotes the minimum distance between robots at any time. The above states that any two robots should be far enough from each other at any point in the trajectory. 

Similarly, the following constraints are imposed to avoid collisions between each robot and static obstacles: 
\begin{align}
    (\pi_i^h - o_j)^2 \geq (R^o)^2, \forall i, j \in [N_a], h \in [H], \label{nonconvex_obstacle_collision}
\end{align}
where $R^o$ denotes the minimum distance at which an robot must be to avoid an obstacle. 
Together, these constraints define a \emph{nonconvex set}: 
\begin{align*} 
    \Omega_n = 
    \left\{ \boldsymbol{\Pi} \in \mathbb{R}^{N_a \times H \times 2} \Big| \text{Constr. } \eqref{nonconvex_robot_collision},  \eqref{nonconvex_obstacle_collision}, \text{ hold} \right\}, 
\end{align*}
and the complete feasible set is given by: $\Omega = \Omega_c \cap \Omega_n$. 

\subsection{Augmented Lagrangian for Efficient Projections}
Although solving $\mathcal{P}_\Omega(\bm{x})$ can generate feasible trajectories, the nonconvex nature of the constraint set above results in high computational costs. To address this issue, we seek to relax the nonconvex constraints in MRMP to transform the original nonconvex quadratically constrained quadratic problem (QCQP) into a convex QCQP. To facilitate analysis, we rewrite the inequality constraints as equalities:
\begin{subequations}
\begin{align*}
     \mathcal{H}_a: &(R^a)^2 - (\pi_i^h - \pi_j^{h})^2 + d_{i,j,h}^a = 0, \forall i, j, \ i \neq j, \ \forall h,  \\
    \mathcal{H}_o:&(R^o)^2 - (\pi_i^h - o_j)^2 + d_{i,j,h}^o = 0, \forall i, j, \ \forall h,   
\end{align*}
\end{subequations}
where $d_{i,j,h}^a$ and $d_{i,j,h}^o$ (with vector form $\boldsymbol{d^a}$ and $\boldsymbol{d^o}$, respectively) are positive auxiliary variables. 
Specifically, $\mathcal{H}_a$ corresponds to the robot collision avoidance constraints and $\mathcal{H}_o$ to the obstacle collision avoidance constraints. 

The Lagrangian dual function of the MRMP problem is thus defined as: 
\begin{align}
    \mathcal{L}(\boldsymbol{\Pi}, \boldsymbol{\nu}_a, \boldsymbol{\nu}_o) = {\cal J}(\bm{\Pi}) + \boldsymbol{\nu}_a^\top \mathcal{H}_a(\boldsymbol{\Pi}) + \boldsymbol{\nu}_o^\top \mathcal{H}_o(\boldsymbol{\Pi}),
\end{align}
where ${\cal L}(\bm{\Pi})$ represents the original MRMP objective function,  
$\boldsymbol{\nu}_a$ and $\boldsymbol{\nu}_o$ are Lagrangian multipliers, and $\mathcal{H}_a$ and $\mathcal{H}_o$ represent the equality constraints enforcing inter-robot collision avoidance and obstacle avoidance, respectively. While the standard Lagrangian formulation provides a means of incorporating constraints into the optimization process, it suffers from slow convergence due to the instability of dual variable updates, particularly in nonconvex settings. To mitigate these issues, we adopt the augmented Lagrangian method~\cite{boyd2011distributed,kotary2022fast}, which introduces additional penalty terms on the constraint residuals:
\begin{equation*}
\begin{aligned}
    \mathcal{L}(\boldsymbol{\Pi}, \boldsymbol{\nu}_a, \boldsymbol{\nu}_o) = & \quad {\cal J}(\Pi) \\
    &+  \boldsymbol{\nu}_a^\top \mathcal{H}_a(\boldsymbol{\Pi}) + \boldsymbol{\nu}_o^\top \mathcal{H}_0(\boldsymbol{\Pi}) \\
    & + \rho_a \| \mathcal{H}_a(\boldsymbol{\Pi}) \|^2 + \rho_o \| \mathcal{H}_o(\boldsymbol{\Pi}) \|^2,
\end{aligned}
\end{equation*}
where $\rho_a$ and $\rho_o$ are penalty parameters that control the strength of the constraint enforcement. These penalties improve numerical stability by discouraging constraint violations in early iterations, accelerating convergence.

The corresponding Lagrangian dual function can thus be defined by:
\begin{align*}
    \boldsymbol{d}(\boldsymbol{\nu}_a, \boldsymbol{\nu}_o) = \min_{\boldsymbol{\Pi}} \mathcal{L}(\boldsymbol{\Pi}, \boldsymbol{\nu}_a, \boldsymbol{\nu}_o).
\end{align*}
and associated \emph{Lagrangian Dual Problem} is defined as maximizing the dual function:
\begin{equation}
\label{dual_problem}
% \begin{align}
    \arg \max_{\boldsymbol{\nu}_a, \boldsymbol{\nu}_o} \boldsymbol{d}(\boldsymbol{\nu}_a, \boldsymbol{\nu}_o)
    \quad \quad \text{s.t.} \quad \boldsymbol{\Pi} \in \Omega_c.
% \end{align}   
\end{equation}
Through weak duality, maximizing \eqref{dual_problem} provides a lower bound on the optimal objective value of the primal MRMP problem.
Even in cases where strong duality does not hold (e.g., as in the application context studied in this work), minimizing the duality gap allows for near-optimal feasible solutions to be obtained.
Given the optimal dual variables ($\boldsymbol{\nu}_a^*, \boldsymbol{\nu}_o^*$), a primal solution $\hat{\bm{\Pi}}$ can be obtained by solving:
\begin{subequations}
\label{primal_problem}
\begin{align*}
    \hat{\boldsymbol{\Pi}} = \arg \min_{\boldsymbol{\Pi} \in \Omega_c} &\quad \mathcal{L}(\boldsymbol{\Pi}, \boldsymbol{\nu}_a^*, \boldsymbol{\nu}_o^*).
\end{align*} 
\end{subequations}
This follows from the stationarity condition, where optimizing the augmented Lagrangian function with fixed multipliers yields the best feasible solution.

Crucially, the dual problem (\ref{dual_problem}) can be solved iteratively, by employing an adaptation of a Dual Ascent method \cite{boyd2011distributed}:
\begin{subequations}
\begin{align}
    \boldsymbol{\Pi}^k = \ & \arg \min_{\boldsymbol{\Pi} \in \Omega_c} \ \mathcal{L}(\boldsymbol{\Pi}, \boldsymbol{\nu}_a^k, \boldsymbol{\nu}_o^k), \\
    \boldsymbol{\nu}_a^{k+1} = \ & \boldsymbol{\nu}_a^{k} + \rho_a^k \mathcal{H}_a(\boldsymbol{\Pi}^k), \\   
    \boldsymbol{\nu}_o^{k+1} = \ & \boldsymbol{\nu}_a^{k} + \rho_o^k \mathcal{H}_o(\boldsymbol{\Pi}^k).
\end{align}
\end{subequations}
At each iteration, the primal variable  $\bm{\Pi}^k$  is updated by minimizing the augmented Lagrangian, and the dual variables $\bm{\nu}_a, \bm{\nu}_o$ are updated via a gradient ascent step on the constraint residuals. 
As the paper will show next, this approach is key to enabling the generation of collision-free and kinematic viable trajectories for multiple robots, especially in complex scenarios. The augmented projection process is described in Algorithm~\ref{alg:alm_pgd_annealed_ld}.

\begin{algorithm}[t]
\caption{Efficient Projection Operator for SMD}
\label{alg:alm_pgd_annealed_ld}
\begin{algorithmic}[1] % [1] for line numbering
\STATE \textbf{Input:} Tolerance $\delta$, Weight $\rho$, Initial Trajectory $\hat{\boldsymbol{\Pi}}$
\WHILE{$\nabla_{\boldsymbol{\nu}_a} < \delta \ \textbf{and} \ \nabla_{\boldsymbol{\nu}_o} < \delta$}
    \STATE $\hat{\boldsymbol{\nu}}_a \gets \mathcal{H}_a(\hat{\boldsymbol{\Pi}})$, $\hat{\boldsymbol{\nu}}_o \gets \mathcal{H}_o(\hat{\boldsymbol{\Pi}})$
    \STATE $\hat{\boldsymbol{\Pi}} \gets  \arg \min_{\boldsymbol{\Pi} \in \Omega_c} \ \mathcal{L}(\hat{\boldsymbol{\Pi}}, \boldsymbol{\nu}_a^*, \boldsymbol{\nu}_o^*)$
    \STATE $\nabla_{\boldsymbol{\nu}_a} \gets \mathcal{H}_a(\hat{\boldsymbol{\Pi}})$, $\nabla_{\boldsymbol{\nu}_o} \gets \mathcal{H}_o(\hat{\boldsymbol{\Pi}})$
    \STATE $\rho \gets \text{Update}(\rho)$
\ENDWHILE
\STATE \textbf{Output:} $\hat{\boldsymbol{\Pi}}$
\end{algorithmic}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Experimental Settings}
\label{Sec: Experimental Settings}
This section describes the evaluation methodology for Multi-Robot Motion Planning algorithms, detailing the benchmark maps, task assignment process, and performance metrics. To ensure a comprehensive evaluation, this paper also introduces a new benchmark instances set that captures a variety of real-world MRMP challenges (released as supplemental material).


\textbf{Maps.}
We evaluate MRMP algorithms on both randomly generated and structured, real-world-inspired maps. 

$\bullet$ {\bf Random maps} include environments with increasing levels of complexity: \underline{empty maps} test inter-robot collision avoidance in open spaces; \underline{basic maps} introduce 10 obstacles, requiring navigation of narrow corridors; \underline{dense maps} contain 20 obstacles, significantly restricting movement and increasing planning difficulty. The progression from empty to dense maps allows us to systematically assess the algorithms on spatial constraints and coordination.

$\bullet$ {\bf Practical maps} simulate real-world environments such as warehouses and buildings, where constrained pathways and structured layouts impose additional planning challenges. \underline{Corridor maps} replicate narrow passages where robots must coordinate movements to pass each other without deadlocks. \underline{Shelf maps} mirror warehouse storage layouts with tight aisles, requiring precise navigation. \underline{Room maps} introduce multiple rooms connected by doors, estricting the number of robots that can enter at the same time and requiring careful scheduling to prevent congestion. Compared to random maps, practical maps emphasize not only collision avoidance but also global coordination, as robots must find feasible routes through constrained spaces.

Each scenario contains 25 distinct maps.

\begin{figure}[t]
    \centering
    \subfigure[Empty Maps.]
    {
        \includegraphics[width=0.29\columnwidth]{Figures/empty_robots.png}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Empty Maps}
    }
    \subfigure[Basic Maps.]
    {
        \includegraphics[width=0.29\columnwidth]{Figures/simple_robot.png}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Basic Maps}
    }
    \subfigure[Dense Maps.]
    {
        \includegraphics[width=0.29\columnwidth]{Figures/dense_robots.png}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Dense Maps}
    }
    \caption{Examples of random maps used for MRMP experiments, with increasing complexity. Colorful spheres and plates denote the start and goals of robots. White objects indicate obstacles.}
    \label{fig:Examples of random maps}
\end{figure}

\begin{figure}[t]
    \centering
    \subfigure[Corridor Maps.]
    {
        \includegraphics[width=0.29\columnwidth]{Figures/narrow_corridors_robots.png}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Narrow Corridors Maps}
    }
    \subfigure[Shelf Maps.]
    {
        \includegraphics[width=0.29\columnwidth]{Figures/shelf_robots.png}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Shelves Maps}
    }
    \subfigure[Room Maps.]
    {
        \includegraphics[width=0.29\columnwidth]{Figures/room_robots.png}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Room Maps}
    }
    \caption{Examples of practical maps used for MRMP experiments show different practical challenges in MRMP.}
    \label{fig:Examples of pratical maps}
\end{figure}

\textbf{Task assignment.}
Start and goal states are assigned differently for random and practical maps. In random maps, they are placed at feasible positions without collisions (see Figure~\ref{fig:Examples of random maps}), while in practical maps, they are constrained to predefined zones that reflect real-world constraints, such as pickup and drop-off locations in warehouses (see Figure~\ref{fig:Examples of pratical maps}). To ensure that each instance has feasible solutions, we discretize the environment and use multi-agent path finding algorithms to verify whether a collision-free solution exists. If no feasible assignment is found, the configuration is regenerated. We conduct experiments with 3, 6, and 9 robots, generating 10 test cases for each configuration, except for corridor maps, where we use 2 robots.


\textbf{Evaluation metrics.}
MRMP algorithms are assessed based on their ability to generate collision-free, efficient, and smooth trajectories. \underline{Success rate} measures the percentage of test cases solved without collisions. \underline{Path length} evaluates the average travel distance per robot, reflecting efficiency. \underline{Acceleration} quantifies trajectory smoothness, with lower values indicating reduced energy consumption and smoother motion. \underline{Collision ratio} measures the proportion of robots that experience collisions, providing insight into the robustness of the planning method. These metrics collectively assess feasibility, efficiency, and safety in MRMP.

\textbf{Competing Methods.}
We compare our proposed SMD against the following learning-based baseline methods:
\begin{enumerate}[leftmargin=*, parsep=0pt, itemsep=0pt, topsep=0pt]
    \item \textbf{Diffusion Models (DM)}: We adopt standard diffusion models fine-tuned over the benchmark trajectories to address MRMP directly~\cite{nichol2021improved}.
    \item \textbf{Motion Planning Diffusion (MPD)}: The state-of-the-art motion planning diffusion model for single robots~\cite{carvalho2023motion}, which we extend to handle MRMP for comparison.
    \item \textbf{Multi-robot Motion Planning Diffusion (MMD)}: A recently introduced solution that combines diffusion models with classical search-based techniques—generating MRMP solutions under collision constraints~\cite{shaoul2024multi}.
\end{enumerate}

We also compare our proposed approaches with classical algorithms in Appendix~\ref{Sec: Additional Experimental Results}.

\section{Experiments}
In this section, we evaluate the performance of various MRMP algorithms using our proposed benchmark. In most cases, regular projection methods cannot be applied to obtain solutions in MRMP due to the increased number of robots and obstacles (hence, our omission of \citet{christopher2024constrained} as a baseline). Thus, for our implementation of SMD, we use the projection with the augmented Lagrangian method for our experiments, except for the narrow-corridor map. The implementation details can be found in Appendix~\ref{Sec: Implementation Details}. Additionally, we introduce supplementary details in the appendix~\ref{Sec: Additional Experimental Results}, including the results of classical algorithms and additional metrics.


\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Figures/success_random_maps.pdf}
    \caption{Results for each method on random maps with three different numbers of robots. Gray bars represents the failure rate, and values on top of the bars indicate average path length per robot.}
    \label{fig:Results of random maps}
\end{figure}

\subsection{Performance on Random Maps}

We first showcase the methods' performance on random maps. Figures~\ref{fig:Results of random maps} compares the success rate and path length for all methods for settings of increasing complexity and three configurations (3, 6, and 9 robots). 

First, notice that the {\it Standard Diffusion Model} is unviable for MRMP tasks. Despite reporting a reasonable success rate (78\%) for 3 robots in empty maps, when simple obstacles are introduced, the success rate falls dramatically (5\%). Additionally, DM fails to produce any feasible trajectory when scaling to six or nine robots, even in empty maps.

Next, we focus on {\it Motion Planning Diffusion}. While it reports near-perfect success rates for the 3-robots setting (the smallest in our benchmark), this approach is highly ineffective when scaled to additional robots. In empty environments, MPD reports 35\% success rates and it fails to synthesize any feasible trajectory when obstacles are introduced to the map or when scaling to nine robots.

{\it Multi-robot Motion Planning Diffusion} represents the current state-of-the-art method for MRMP. This method outperforms other baselines in its ability to handle an increased number of robots. For instance, it reports non-zero success rates for up to nine robots. However, there remains a steep performance drop with the increasing number of robots. For instance, it reports a success rate of 27\% in dense maps for 9 agents. A similar decrease in constraint satisfaction occurs for in other scenarios besides the empty maps.

In contrast, {\it Simultaneous MRMP Diffusion} provides new state-of-the-art results for both constraint satisfaction and path length. SMD reports perfect success rates and collision ratios for all tasks except the most complex maps (dense environments) and 9 robots, and, even in this case, it provides near-perfect results (96\% successful). {\it This is a {\bf 3.6x} improvement over the previous state-of-the-art}. Sample trajectories generated by SMD are visualized in Figure~\ref{fig:Trajectories of random maps}. 


\begin{figure}[t]
    \centering
    \subfigure[Basic Maps.]
    {
        \includegraphics[width=0.45\columnwidth]{Figures/traj_basic_.pdf}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Trajectories for Basic Maps}
    }
    \subfigure[Dense Maps.]
    {
        \includegraphics[width=0.45\columnwidth]{Figures/traj_dense_.pdf}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Trajectories for Dense Maps}
    }
    \caption{Trajectories generated by SMD on random maps.}
    \label{fig:Trajectories of random maps}
\end{figure}

\subsection{Performance on Practical Maps}
Practical maps are designed to evaluate the ability of the methods to generate feasible trajectories for more challenging yet commonly occurring real-world scenarios. 

In \textit{corridor maps}, Figure~\ref{fig:Success Rate for Corridors} shows that our SMD achieves a perfect success rate, whereas {\it all other methods fail to report even a single feasible trajectory}. In restrictive environments like this, robots need to swap their positions in a specific area to achieve their goals, as their initial relative positions are opposite to their goals positions, and the narrow corridors do not allow direct position exchange. In this case, the gradient-based guidance used by MPD in the diffusion sampling process is prone to failure, as it cannot globally coordinate different robots to reach their respective goals. Although MMD uses multi-agent path-finding algorithms to account for goal-reasoning, it still relies on gradient-based guidance to generate trajectories. The penalty term employed by this method during gradient computation is thus insufficient to produce feasible solutions in such regions. In contrast, our reformulation of the diffusion sampling process as a constrained optimization problem confers the ability to ensure feasibility in the generated trajectories. As shown in Figure~\ref{fig:Trajectories for Corridors}, the trajectories generated by our SMD allow the two robots to use the only slightly wider area to swap their positions.
\begin{figure}[t]
    \centering
    \subfigure[Results.]
    {
        \includegraphics[width=0.45\columnwidth]{Figures/success_rate_corridors_.pdf}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Success Rate for Corridors}
    }
    \subfigure[Trajectories.]
    {   \raisebox{5.5mm}{
        \includegraphics[width=0.375\columnwidth]{Figures/traj_corridors.pdf}}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Trajectories for Corridors}
    }
    \caption{Results for each method on corridor maps with three different numbers of robots. Gray bars represents the failure rate, and values on top of the bars indicate average path length per robot.}
    \label{fig:Results of Corridors Maps}
\end{figure}

We also evaluate on \textit{shelf maps} and \textit{room maps}, both of which contain narrow passages that must be traversed to reach the goals. Figure~\ref{fig:Results of Practical Maps} shows that MPD and MMD achieve a similar success rate (60\%) when there are only three robots in shelf maps, and MPD even provides shorter paths. However, it quickly fails to provide feasible solutions as the number of robots increases, even slightly. %, and the success rate of MMD also drops below 50\%. 
SMD again achieves a perfect success rate for three robots, and it only experiences a slight decline as the number of robots increases (90\%). SMD also reports the shortest paths among all methods. 
Similarly, \emph{room maps} report SMD achieving a perfect success rate for 3 and 6 robots and above 90\% when scaling up to 9 robots. In contrast, MPD and MMD fail to produce feasible trajectories as the number of robots increases. In these maps, SMD advantage over the baselines is even more noticeable. These results shows the adaptability of the proposed algorithm to multiple environments and challenging scenarios (such as the narrow passages). 



\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Figures/success_practical_maps.pdf}
    \caption{Results for each method on practical maps with three different numbers of robots. Gray bars represents the failure rate, and values on top of the bars indicate average path length per robot.}
    \label{fig:Results of Practical Maps}
\end{figure}


Finally, Figure~\ref{fig:Trajectories of Practical Maps} provides two illustrative cases for shelf maps (a) and room maps (b) where SMD is the only method across those tested able to generate feasible solutions. A common characteristic of these two instances is that multiple robots need to pass through the same narrow passage, a scenario frequently encountered in real-world applications.
\begin{figure}[t]
    \centering
    \subfigure[Shelf Maps.]
    {
        \includegraphics[width=0.45\columnwidth]{Figures/traj_shelf_.pdf}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Trajectories for Shelf Maps}
    }
    \subfigure[Room Maps.]
    {
        \includegraphics[width=0.45\columnwidth]{Figures/traj_room_.pdf}
        % \rule{0.29\columnwidth}{0.2\columnwidth}
        \label{fig:Trajectories for Room Maps}
    }
    \caption{Trajectories generated by SMD on practical maps.}
    \label{fig:Trajectories of Practical Maps}
\end{figure}



\section{Discussion and Limitations}
While SMD provides state-of-the-art results for MRMP tasks, forethought should be given as to the appropriate applications of this approach.
First, generative models incur inference-time costs that should be considered when applying these models to motion planning. 
Diffusion models are most advantageous in scenarios where the complexity of the environment and the need for multimodal trajectory generation outweigh the benefits of faster but more rigid methods. 
For instance, such architectures are ideal for handling unstructured environments with dense obstacles, dynamic changes, and uncertain sensor inputs, where traditional methods struggle to adapt but may be unnecessary in structured or open spaces.



\section{Conclusion}
This work introduced \emph{Simultaneous MRMP Diffusion (SMD)}, a method that integrates constrained optimization with generative diffusion models to generate collision-free, kinematically feasible trajectories for multi-robot systems. By alternating diffusion sampling with projections onto the feasibility set, SMD eliminates the need for rejection sampling or post-processing. To handle complex nonconvex constraints, the paper incorporates an Augmented Lagrangian Method enabling scalability to challenging multi-robot scenarios where other methods fail. 
To support rigorous evaluation, a benchmark suite was also introduced, covering environments that reflect real-world motion planning challenges. Extensive experiments across varying obstacle densities and increasing robot counts demonstrated that SMD achieves significantly higher success rates and better objective values than competing methods. The results highlight its robustness in handling both static obstacles and dynamic interactions, making it a promising approach for real-world MRMP applications.  

Future work will focus on improving scalability through decomposition techniques and constraint relaxations.



\newpage
\section*{Impact Statement}
This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.

\bibliography{main}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn



\section{Implementation Details}
\label{Sec: Implementation Details}
\textbf{Software}: The software used for experiments is Rocky Linux release 8.9, Python 3.8, Cuda 11.8, and PyTorch 2.0.0.
\textbf{Hardware}: For each of our experiments, we used 1 AMD EPYC 7352 24-Core Processor and 1 NVIDIA RTX A6000 GPU.

\subsection{MRMP Details}
In our experiments, the size of each local map was $2 \times 2$ units. The robot radius was set to 0.05 units in all cases, except for the corridor map, where it was 0.1 units. The obstacle sizes in random maps varied between 0.05 and 0.1 units. 

To adopt the EECBS algorithm, we discretized the map into a grid with a cell size of 0.1 units, which corresponds to the robot's diameter. If an obstacle was present within a grid cell, the cell was marked as an obstacle. The robot's starting position was determined by the grid cell in which its center was located.

\subsection{Training Details}
Our implementation builds upon the official code of~\citet{carvalho2023motion} and~\citet{shaoul2024multi}, with modifications to accommodate our specific requirements. Since MMD can be trained with single-robot motion planning data, we first trained it accordingly. Then, by running MMD, we obtained the feasible solutions of MRMP it generated and used them as training data. Table~\ref{table: hyperparams for Training} shows the hyperparameters used for training the score-based diffusion models in our experiments. 
\begin{table}[h]
\centering
\caption{Hyperparameters for Training in Experiments.}
\begin{tabular}{cc}
\hline
HyperParameters         & Value \\ \hline
Diffusion Sampling Step &   25    \\
Learning Rate           &   1e-4   \\
Batch Size              &   64   \\
Optimizer               &   Adam    \\ \hline
\end{tabular}
\label{table: hyperparams for Training}
\end{table}

\subsection{Evaluation Details}
We conducted experiments on six types of maps, each with 25 different parameters, such as obstacle size and positions. For all map types except corridor maps, we evaluate three different numbers of robots (3, 6, and 9). In corridor maps, only two robots are tested. For each number of robots, we generate 10 test cases, resulting in 4,000 test instances for each method.
\begin{table}[h]
\centering
\caption{Summary of MRMP Benchmark Instances}
\begin{tabular}{ccccc}
\hline
Map Type      & \begin{tabular}[c]{@{}c@{}}Obstacle\\ Variations\end{tabular} & \begin{tabular}[c]{@{}c@{}}Number of Robots\\ Variations\end{tabular} & \begin{tabular}[c]{@{}c@{}}Start \& Goal\\ Variations\end{tabular} & \begin{tabular}[c]{@{}c@{}}Number of\\ Instances\end{tabular} \\ \hline
Empty Maps    & 25                                                            & 3                                                                     & 10                                                                 & 750                                                           \\
Basic Maps    & 25                                                            & 3                                                                     & 10                                                                 & 750                                                           \\
Dense Maps    & 25                                                            & 3                                                                     & 10                                                                 & 750                                                           \\
Corridor Maps & 25                                                            & 1                                                                     & 10                                                                 & 250                                                           \\
Shelf Maps    & 25                                                            & 3                                                                     & 10                                                                 & 750                                                           \\
Room Maps     & 25                                                            & 3                                                                     & 10                                                                 & 750                                                           \\ \hline
Total         &                                                               &                                                                       &                                                                    & 4000                                                          \\ \hline
\end{tabular}
\end{table}

For each generated path, we first check for collisions and compute the success rate of each method. For collision-free cases, we analyze path length and acceleration. For cases with collisions, we report the collision ratio. If a method fails to generate a feasible solution, its path length and acceleration are excluded from the statistical analysis.

\section{Additional Experimental Results}
\label{Sec: Additional Experimental Results}
Our manuscript primarily evaluates learning-based algorithms based on their performance in terms of success rate and path length (Figure~\ref{fig:Results of random maps}, Figure~\ref{fig:Success Rate for Corridors}, and Figure~\ref{fig:Results of Practical Maps}). While these metrics are sufficient to demonstrate SMD’s ability to consistently outperform its competitors, two additional aspects warrant further investigation: (1) comparison with traditional methods and (2) solution smoothness—measured by acceleration (computed as the absolute difference in velocity between consecutive time steps)—and collision ratio, which quantifies the proportion of robots that collide when no feasible solution is found. Specifically, we discretize the environment to adopt a powerful near-optimal multi-agent path finding algorithm, Explicit Estimation Conflict-Based Search (EECBS)~\cite{li2021eecbs}.

As shown in Table~\ref{table:random_env} and Table~\ref{table: practical maps}, our proposed SMD consistently achieves an impressive success rate across all tested scenarios. In contrast, traditional approaches such as EECBS also maintain a high success rate but struggle with path length, which is approximately 20\% longer than that of our method. This is caused by they operate within a predefined grid structure. Notably, our SMD achieves near-zero collision rates, outperforming other learning-based approaches, which frequently fail to avoid collisions in complex scenarios. 

\begin{table*}[h]
    \centering
    \caption{Additional results for classical algorithms and learning-based algorithms in random maps. \textbf{S} is the success rate, \textbf{L} denotes the average path length per robot, \textbf{A} is the average acceleration, and \textbf{C} is the collision ratio (see Section~\ref{Sec: Experimental Settings}). We omit acceleration and collision information for multi-agent path finding methods, as they assume constant velocities and typically do not return infeasible solutions.}
    \renewcommand{\arraystretch}{0.9} 
    \begin{adjustbox}{max width=\textwidth}
    \begin{tabular}{ccc|cccccc}
        \toprule
        {Map} & {Robots} & {Metric} & 
        % \multicolumn{5}{c}{Methods} \\
        % \cmidrule(lr){4-8}
         EECBS & DM & MPD & MMD & Ours\\
        \midrule
        \multirow{12}{*}{Empty Maps} & \multirow{4}{*}{3} & S $\uparrow$ & 1 & 0.7840 & 1 & 1 & 1 \\
                                &                         & L $\downarrow$ & 1.2591 & 0.9997 &1.0180 & 1.1109 & 1.0125 \\
                                &                         & A $\downarrow$ & -- & 0.0030 & 0.0022 & 0.0028 & 0.0010 \\
                                &                         & C $\downarrow$ & -- & 0.1493 & 0 & 0 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{6}      & S $\uparrow$ & 1 & 0 & 0.3520 & 1 & 1 \\
                                &                         & L $\downarrow$ & 1.2607 & -- & 2.5886 & 1.1139 & 1.1764 \\
                                &                         & A $\downarrow$ & -- & -- & 0.0062 & 0.0029 & 0.0034 \\
                                &                         & C $\downarrow$ & -- & 1 & 0.4167 & 0 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{9}      & S $\uparrow$ & 1 & 0 & 0 & 1 & 1 \\
                                &                         & L $\downarrow$ & 1.2684 & -- & -- & 1.1168 & 1.1945 \\
                                &                         & A $\downarrow$ & -- & -- & -- & 0.0031 & 0.0046 \\
                                &                         & C $\downarrow$ & -- & 1 & 0.9929 & 0 & 0 \\
        \midrule
        \multirow{12}{*}{Basic Maps} & \multirow{4}{*}{3} & S $\uparrow$ & 1 & 0.0520 & 0.9960 & 0.9280 & 1 \\
                                &                         & L $\downarrow$ & 1.3236 & 0.9910 & 1.0310 & 1.1315 & 1.0091 \\
                                &                         & A $\downarrow$ & -- & 0.0031 & 0.0012 & 0.0032 & 0.0040 \\
                                &                         & C $\downarrow$ & -- & 0.6133 & 0.0013 & 0.0467 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{6} & S $\uparrow$ & 1 & 0 & 0 & 0.8320 & 1 \\
                                &                         & L $\downarrow$ & 1.3228 & -- & -- & 1.1319 & 1.1560 \\
                                &                         & A $\downarrow$ & -- & -- & -- & 0.0033 & 0.0120 \\
                                &                         & C $\downarrow$ & -- & 1 & 0.9847 & 0.0813 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{9} & S $\uparrow$ & 1 & 0 & 0 & 0.7280 & 1 \\
                                &                         & L $\downarrow$ & 1.3244 & -- & -- & 1.1375 & 1.2212 \\
                                &                         & A $\downarrow$ & -- & -- & -- & 0.0035 & 0.0048 \\
                                &                         & C $\downarrow$ & -- & 1 & 1 & 0.1093 & 0 \\
        \midrule
        \multirow{12}{*}{Dense Maps} & \multirow{4}{*}{3} & S $\uparrow$ & 0.968 & 0 & 0.9920 & 0.6600 & 1 \\
                                &                         & L $\downarrow$ & 1.4945 & -- & 1.0568 & 1.1638 & 1.0337 \\
                                &                         & A $\downarrow$ & -- & -- & 0.0014 & 0.0037 & 0.0025 \\
                                &                         & C $\downarrow$ & -- & 0.9093 & 0.0040 & 0.1813 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{6} & S $\uparrow$ & 0.944 & 0 & 0 & 0.4360 & 1 \\
                                &                         & L $\downarrow$ & 1.5135 & -- & -- & 1.1693 & 1.1841 \\
                                &                         & A $\downarrow$ & -- & -- & -- & 0.0038 & 0.0064 \\
                                &                         & C $\downarrow$ & -- & 1 & 1 & 0.2687 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{9} & S $\uparrow$ & 0.932 & 0 & 0 & 0.2720 & 0.9600 \\
                                &                         & L $\downarrow$ & 1.5349 & -- & -- & 1.1793 & 1.3556 \\
                                &                         & A $\downarrow$ & -- & -- & -- & 0.0041 & 0.0052 \\
                                &                         & C $\downarrow$ & -- & 1 & 1 & 0.3707 & 0.0044 \\
        \midrule
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \label{table:random_env}
\end{table*}

\begin{table*}[t!]
    \centering
    \caption{Additional results for classical algorithms and learning-based algorithms in practical maps.}
    % \renewcommand{\arraystretch}{0.95} 
    \begin{adjustbox}{max width=\textwidth}
    \begin{tabular}{ccc|cccccc}
        \toprule
        {Map} & {Robots} & {Metric} & EECBS & DM & MPD  & MMD  & Ours\\
        \midrule
        \multirow{4}{*}{Corridor Maps} & \multirow{4}{*}{2} & S $\uparrow$ & 0.7120 & 0 & 0 & 0 & 1 \\
                                &                         & L $\downarrow$ & 1.4208 & -- & -- & -- & 1.6619 \\
                                &                         & A $\downarrow$ & -- & -- & -- & -- & 0.0012 \\
                                &                         & C $\downarrow$ & -- & 1 & 1 & 1 & 0 \\
        \midrule
        \multirow{12}{*}{Shelf Maps} & \multirow{4}{*}{3} & S $\uparrow$ & 1 & 0.1200 & 0.5960 & 0.5960 & 1 \\
                                &                         & L $\downarrow$ & 1.1697 & 0.7884  & 0.8825 & 0.9371 & 0.9017 \\
                                &                         & A $\downarrow$ & -- & 0.0030  & 0.0081 & 0.0030 & 0.0060 \\
                                &                         & C $\downarrow$ & -- & 0.5027 & 0.2493 & 0.3133 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{6} & S $\uparrow$ & 1 & 0 & 0 & 0.5000 & 0.9560 \\
                                &                         & L $\downarrow$ & 1.1493 & -- & -- & 0.9317 & 1.0632 \\
                                &                         & A $\downarrow$ & -- & -- & -- & 0.0030 & 0.0018 \\
                                &                         & C $\downarrow$ & -- & 1  & 0.9960 & 0.3740 & 0.01 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{9} & S $\uparrow$ & 1 & 0 & 0 & 0.4480 & 0.9320 \\
                                &                         & L $\downarrow$ & 1.1427 & --  & -- & 0.9331 & 1.0838 \\
                                &                         & C $\downarrow$ & -- & --  & -- & 0.0032 & 0.0068 \\
                                &                         & A $\downarrow$ & -- & 1 & 1 & 0.4218 & 0.0111 \\
        \midrule
        \multirow{12}{*}{Room Maps} & \multirow{4}{*}{3} & S $\uparrow$ & 1 & 0 & 0.0840 & 0.1360 & 1 \\
                                &                         & L $\downarrow$ & 1.6956 & --  & 1.1771 & 1.2697 & 1.1917 \\
                                &                         & A $\downarrow$ & 0 & --  & 0.0066 & 0.0043 & 0.0030 \\
                                &                         & C $\downarrow$ & -- & 1 & 0.6520 & 0.6867 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{6} & S $\uparrow$ & 0.9960 & 0 & 0 & 0.024 & 1 \\
                                &                         & L $\downarrow$ & 1.6778 & --  & -- & 1.2660 & 1.3019 \\
                                &                         & A $\downarrow$ & -- & -- & -- & 0.0032 & 0.0014 \\
                                &                         & C $\downarrow$ & -- & 1 & 1 & 0.8033 & 0 \\
        \cmidrule(lr){2-8}
                                & \multirow{4}{*}{9} & S $\uparrow$ & 0.9920 & 0 & 0 & 0 & 0.9600 \\
                                &                         & L $\downarrow$ & 1.6620 & -- & -- & -- & 1.3374 \\
                                &                         & A $\downarrow$ & -- & -- & -- & -- & 0.0033 \\
                                &                         & C $\downarrow$ & -- & 1 & 1 & 0.8849 & 0.0044 \\
        \midrule
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \label{table: practical maps}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}

