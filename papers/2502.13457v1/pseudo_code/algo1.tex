\begin{algorithm}[t]
\caption{Preference UCB with Unknown Preference (PRUCB-UP)}
\label{alg:PRUCB_UP}
\begin{algorithmic}
\State \textbf{Initialize:} $\alpha$,
$N_{i, 1} \!\leftarrow\! 0$, $\boldsymbol{\hat{r}}_{i,1} \!\leftarrow\! [0]^{D}, \forall i \!\in\! [K]$;
$\boldsymbol{\hat{c}}_{1} \!\leftarrow\! [0]^D$.
\For{$t=1,\cdots,T$ }
    \State \textbf{Draw arm} $a_t$ by (\ref{eq:prucb_spm_at}), 
    \State \textbf{Observe} reward $\boldsymbol{r}_{a_t, t}$ and user preference $\boldsymbol{c}_{t}$.
    \State \textbf{Update phase:} 
    \State \indent Update preference estimate $\hat{\boldsymbol{c}}_{t+1}$ by (\ref{eq:PRUCB_SPM_c_t}); update $N_{i, t+1}$ and reward estimate $\hat{\boldsymbol{r}}_{i,t+1}, \forall i \in [K]$ by (\ref{eq:prucb_r_t}).
\EndFor
\end{algorithmic}
\end{algorithm}