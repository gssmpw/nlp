% Moved here to appear in page 5
\begin{figure*}
  \centering
  \graphicspath{{figures/}}
  \includegraphics[width=\textwidth]{figures/experiments_plastic_box_only_comp.pdf}
  \vspace{-20pt}
  \caption{Experimental validation of the proposed controller for sequentially moving and re-orienting an object between two goal poses.  The robot pushes a plastic box of 6.4 kg from one goal to another. The goal poses are shown as green boxes. Snapshots of previous times are shown with lower opacity. The robot successfully goes around the object to push from the correct side towards the goal (1-2, 5).}
  \label{Fig:experiments_ptp}
\end{figure*}
%
\section{Results \& Evaluation}
\label{sec:results_main}
%
\subsection{Success rate \& object balance}
\label{sec:success_rate}
%
In this section, we present the achieved success rate of the proposed policy after simulating 4096 parallel environments for a single episode. We also provide details on the decision to include the object balance constraint $c_{\theta_{obj}}$ described in \cref{tab:constraints} and the sampling of reach targets $^w \pmb p_r$ on the object's surface. To that end, we conduct an ablation study in simulation by training the same policy without the balance constraint and by replacing the EE reach targets on the surface with the object's centroid. As shown in \cref{tab:success_rate_topple}, our policy achieves a higher success rate (91.35\%) than any other combination. The constraint helps in reducing the rate of toppled objects to almost half. The policies with the object centroid as EE reach target result in a higher rate of toppled objects (7.73\%) or do not converge at all when combined with the balancing constraint. In the latter case, the arm EE is guided toward the centroid, leading to more violations of the object balance constraint at the start of training, which prevents the agent from discovering the task reward. Therefore, guiding the robot towards interaction with all possible parts of the object surface helps achieve the task.
%
\begin{table}
\caption{Success rate and percentage of toppled objects in simulation across 4096 simulation runs.}
\label{tab:success_rate_topple}
\vspace{-10pt}
\begin{center}
  \begin{tabular}{p{4.2cm}|P{1.2cm}|P{1.9cm}}
  \hline
   \multirow{2}{4.2cm}{\centering \textbf{Approach}} & \textbf{Success rate [\%]} & \textbf{Toppled object rate [\%]} \\
   \hhline{=|=|=}
   Ours w/o sampling on object surface & 49.80 & 4.50 \\ \hline
  Ours w/o sampling on object surface \& object balance constraint & \multirow{2}{1.2cm}{\centering 88.70} & \multirow{2}{1.9cm}{\centering 7.73} \\ \hline
  Ours w/o object balance constraint                                            & 90.00 & 6.93 \\ \hline 
   Ours (with all the above)                                                           & \textbf{91.35} & \textbf{3.46} \\ \hline

    \end{tabular}
\end{center}
\end{table}

\subsection{Constraint satisfaction}
\label{sec:constraint_satisfaction}
%
\begin{table}
\caption{Average proportion of time (\%) that each constraint is violated in simulation across 4096 runs}
\label{tab:sim_constaint_violation}
\vspace{-10pt}
\begin{center}
  \begin{tabular}{p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.6cm}|p{0.5cm}|p{0.5cm}}
  \hline
    $\pmb c_{a}^{base}$ & $\pmb c_{a}^{arm}$ & $\pmb c_{\dot{a}}^{arm}$ & $\pmb c_{q_j}$ & $\pmb c_{\dot{q}_j}$ & $\pmb c_{\tau_j}$ & $\pmb c_{\tau_{j,leg}}$ & $\pmb c_{coll}$ & $c_{\theta_{obj}}$\\
   \hhline{=|=|=|=|=|=|=|=|=}
   0.059 & 0.014 & 0.032 & 0.011 & 0.007 & 0.189 & 0.473 & 0.01 & 0.298 \\ \hline
\end{tabular}
\end{center}
\end{table}

We provide more insights on the achieved constraint satisfaction. We compute the average time proportion for which each constraint is violated during the simulation of an episode with 4096 environments. As shown in \cref{tab:sim_constaint_violation}, all the constraints are violated less than 1\% of the simulated time. The leg joint torque constraint $\pmb c_{\tau_{j,leg}}$ with the higher constraint violation refers to violations of the nominal torque limits and mainly concerns the used locomotion policy. A possible reason for this is that there was no simulated force on the arm EE during training of the locomotion policy.

On the hardware, actuation limits comprise the most challenging constraints to satisfy, in particular, the position limit for the shoulder flexion-extension joint (second arm joint). The pushing task requires the robot's arm to reach low, especially for thin objects, while the position limit for this joint is slightly larger than 90 deg (with the zero on the positive $z$ axis of the base frame). In practice, this requires the controller to operate this joint very close to the limit during most of the task. Nevertheless, this was achieved during the extensive tests that we carried out.

% \textit{Hardware experiments}: We detail more on the actuator limits on the real hardware, which are particularly interesting when deploying RL controllers that output commands in the joint space. In particular, satisfying the position limit for the shoulder flexion-extension joint is rather challenging for this robot and task. The pushing task requires the robot's arm to reach low positions, especially for thin objects, as shown in \cref{sec:adaptation}. The position limit for this joint is slightly larger than 90 degrees (with the zero on the positive $z$ axis of the base frame), which, in practice, requires that the controller operates this joint very close to the limit during most of the task. This is shown in \cref{Fig:actuator_limits_experiment} for the experiment of pushing the cardboard box of 8.32 kg (which is the heavier object we tested on hardware). We also include the torque readings for the five arm joints that we control. It can be seen that the torque values are mainly within the limits despite the heavy object and the high-friction mats in our testing area. The observed torque violations are not an issue since the torque constraint $\pmb c_{\tau_j}$ includes the nominal torque values. At the same time, the robot actuators can reach much higher peak values for a short duration. For this motion, the arm joint velocities were strictly satisfied, and we avoided including them in the figure due to limited space.
%
%

\subsection{Robustness against unknown objects \& contact switching}
\label{sec:robustness}

We extensively test the controller on the hardware to move and reorient different objects. The tests were conducted on the protective floor mats of our testing area, which have high friction and can even exhibit small gaps along the mat's seams. Although this increases difficulty, we opted for more challenging conditions that can resemble real-world scenarios. We present the success rates for these challenging tests. Below, we describe the main experiments.

\begin{table}
\caption{Success rate during hardware experiments with objects of different material: plastic (p), cardboard (c), wood (w) and different shape: cuboid (cu), cylinder (cy)}
\label{tab:success_rate_hw}
\vspace{-10pt}
\begin{center}
  \begin{tabular}{P{0.7cm}|P{0.5cm}|P{1.1cm}|p{0.5cm}|P{1.8cm}|P{1.1cm}}
  \hline
   \multirow{2}{0.7cm}{\centering \textbf{Object}} & \textbf{Mass [kg]} & \textbf{Size [cm$^3$]} & \textbf{$\Delta\theta_z$ [deg]} & \textbf{\# of face switches / goal} & \textbf{Success rate [\%]} \\
   \hhline{=|=|=|=|=|=}
   \scriptsize P-CU & 6.43  & 60x34x40           & 180 & 0.90  & 91.6  \\ \hline
   \scriptsize C-CU & 5.30   & 50x50x53           & 0   & 0.23 & 92.9  \\ \hline
   \scriptsize C-CU & 8.32  & 50x50x53           & 90  & 0.75 & 83.3  \\ \hline
   \scriptsize C-CU & 4.5 & 100x50x53          & 0   & 0.14 & 80.0     \\ \hline
   \scriptsize W-CU & 6.30   & 40x40x60           & 180 & 1.00  & 91.6  \\ \hline
   \scriptsize C-CU & 13.30  & 50x50x60           & 0   & 4.80  & 83.3  \\ \hline
   \scriptsize C-CY & 2.45   & \text{$\Phi$}30x40 & 0   & -    & 83.3  \\ \hline
    \end{tabular}
\end{center}
\end{table}

\textit{Success}: This set of experiments consists of sequentially moving and reorienting the object between two fixed goal poses in the space, as shown in \cref{Fig:experiments_ptp}. We do not move the robot manually before sending a new object goal; the policy successfully moves the robot to the appropriate side of the object to push in the correct direction. We tested the learned controller with objects of varying mass, size, shape, and material (\cref{tab:success_rate_hw}), with yaw angle differences $\Delta \theta_z$ of $0^{\circ}$, $90^{\circ}$, or $180^{\circ}$ between the two goal poses. As goals are sent sequentially, the yaw angle difference between the object and the new goal matches $\Delta \theta_z$ (Â± the success tolerance). The policy achieves a success rate of at least 80\%. For the cuboids, we report in \cref{tab:success_rate_hw} the average contact face switches per goal. A face switch is considered when the robot switches contact to a different face of the cuboid. It can be seen that for higher object yaw orientation changes $\Delta \theta_z$, the controller makes more contact and face switches to properly align the object with the goal, while for $\Delta \theta_z=0$ the robot can most of the time achieve the task without face switch. For cylindrical shapes, a face switch cannot be defined; contact switching is still observed in any case. We demonstrate how the controller manages to move these objects in the accompanying material. In our tests, we also include a 13.3 kg heavy cuboid on caster wheels, although the controller was never trained with wheeled kinematics. In this case, the object's motion overshoots, resulting in more time and contact face switches before ultimately succeeding.

\textit{Reactive behavior}: In this experiment, we keep the object goal pose fixed in space and move the object away from it multiple times while the policy continuously controls the robot. We repeat the experiment for the objects in \cref{tab:success_rate_hw} and include the motions in the accompanying video. The distance and yaw angle error from one of the objects (W-CU) is shown in \cref{Fig:experiments_disturbance}. The robot successfully pushes the object back to the goal within the specified tolerance. 

In most of the failure cases, the robot first pushes the object very close to the success margin and then stops pushing. We believe that this is not a limitation of the method but rather can be mitigated through further policy tuning.
%One potential solution is to make the policy more sensitive to small object-goal discrepancies, for instance, by reducing the success margins or avoiding constant rewards within the success margin. Thus, this kind of failure is not a limitation of the approach itself but rather a policy refinement issue.
%
\begin{figure}
  \centering
  \graphicspath{{figures/}}
  \includegraphics[width=\columnwidth]{figures/error_disturbance_331_inkscape1_comp.pdf}
  \vspace{-22.5pt}
  \caption{Distance and yaw angle error between object and goal. The shaded regions denote the time when the object is moved away from the goal.}
  \label{Fig:experiments_disturbance}
\end{figure}

\subsection{Adaptability to object size}
\label{sec:adaptation}
As mentioned in \cref{sec:domain_randomization}, the dimensions of the objects during training were randomized. We investigate the adaptability of the policy with respect to the object's xy-footprint since thin objects can be prone to toppling. To that end, we select six object xy-footprint sizes equally distributed across the training range and simulate the policy for 1000 successful episodes per size. We fix the object height, mass, center of mass, and friction values to constant and disable the additive observation noise to evaluate the effect of the object's base.  In \cref{Fig:adaptive_object_xy}, we report the height distribution of the robot EE expressed in the world frame while in contact with the object. The policy learns to push lower for objects that have smaller bases. It is of particular interest that the policy does not observe any explicit information regarding the object size or dynamics. This implies that the robot's adaptive behavior is based on the object pose observation. In practice, the robot adapts the pushing location to lower when the object is inclined. We observed such behavior while testing on the real hardware. As shown in \cref{Fig:cylinder_experiment}, the policy can approach and push a thin cylinder on a flooring of high-friction mats. When the cylinder starts tilting, the robot reactively changes the pushing location to lower and avoids object toppling. \cref{Fig:cylinder_experiment} shows that reaching that low with the arm EE is possible due to the contribution of the base motion. In particular, immediately after and during the object tilting (shaded area), the base height, pitch, and roll are adapted to enable reaching lower with the arm EE. This highlights the advantage of using a 6D locomotion policy.
%
% compressed gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/ebook -dNOPAUSE -dQUIET -dBATCH -sOutputFile=small.pdf big.pdf
%
\begin{figure}
  \centering
  \graphicspath{{figures/}}
  \includegraphics[width=0.9\columnwidth]{figures/ee_height_object_xy_boxplot_final.pdf}
  \vspace{-8pt}
  \caption{Boxplot of the arm EE height for objects with rectangular bases of different sizes. The policy pushes lower for objects with smaller base.}
  \label{Fig:adaptive_object_xy}
\end{figure}
%
\begin{figure}
  \centering
  \graphicspath{{figures/}}
  \includegraphics[width=\columnwidth]{figures/cylinder_363_with_plots.pdf}
  \vspace{-20pt}
  \caption{Arm EE height, base height, and orientation while pushing a thin cylinder. The shaded region consists of the time when the cylinder is tilted due to an initial push. The base height and orientation (pitch down, roll) contribute towards pushing power immediately after the object tilts.}
  \label{Fig:cylinder_experiment}
\end{figure}