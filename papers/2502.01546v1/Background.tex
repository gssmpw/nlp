\section{Background}
\label{sec:background}

\subsection{The mobile manipulator and low-level control}
\label{subsec:robot_locomotion}
%
The approach presented in this paper is validated using a quadrupedal mobile platform, ANYmal, with a six DoF robotic arm mounted on it. As described later in \secref{sec:method}, our proposed RL-based controller is not limited to legged mobile manipulators since it generates cartesian motion commands for the base and joint space commands for the first five joints of the arm\footnote{We freeze the 6\textsuperscript{th} joint since it is only useful when using a gripper.}. An overview of the control pipeline is shown in \cref{Fig:framework}. A state-of-the-art pre-trained locomotion controller is used to track the base commands by controlling the legs of the robot. In particular, we use a student policy similar to the one in \cite{miki2024learningwalkconfinedspaces} which accepts the base command $\pmb u_{base}^{cmd} = (v_x, \ v_y, \ \omega_z, \ \zeta, \ \theta_, \ h) \in \mathbb{R}^6$ and outputs leg joint position targets. The six components of the command $\pmb u_{base}^{cmd}$ consist of linear velocity in $x$ and $y$ directions, angular yaw velocity, roll and pitch angle, and height position, respectively. The policy is trained with randomized arm motion, including the arm joint positions in the observation. This way, the resulting locomotion policy is robust against the range of arm motions.