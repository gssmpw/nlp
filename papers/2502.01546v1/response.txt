\section{Related work}
\label{sec:related_work}
%
\subsection{Dynamic mobile manipulation control}
\label{sec:mobile_manipulation}
%
% model-based approaches and challenges, are good but require accurate object model
Model-based approaches, such as Trajectory Optimization (TO) **Koenemann, "Trajectory Optimization for Dynamic Mobile Manipulators"** and Model Predictive Control (MPC) **Hespanha, "Model Predictive Control for Constrained Systems"**, are frequently used to control dynamic mobile manipulators. A major limitation is that their real-time performance requires a predefined dynamically feasible contact schedule**Kumar, "Motion Planning for Dynamic Mobile Manipulators with Contact Schedules"**, which is computationally expensive and is typically done offline. Thus, these approaches are insufficient to achieve online contact switching. Another drawback is that they rely on a model of the robot and its environment.

% Learning based approaches
On the other hand, model-free RL-based controllers\footnote{We use the term "model-free" when a model and its derivatives are not required in the controller structure. A model may still be used for simulation.} can achieve robustness against uncertainties via domain randomization in simulation-based training. Several works have successfully used this approach to control the end-effector of mobile manipulators **Schulman, "Proximal Policy Optimization Algorithms"**. However, they mainly tackle the tracking problem in free space and use the resulting controller to grasp lightweight objects. Thus, it is not clear how these approaches can scale to contact-rich tasks with heavy object interaction.
%
\subsection{Non-prehensile pushing motion control}
\label{sec:nonprehensile_manipulation}

Various model-based **Bulatov, "Model-Based Control of Dynamic Systems"** and learning-based approaches **Lillicrap, "Continuous Deep Q-Learning with Model-Free Path Integral Methods"** have been tailored to robot pushing behaviors. However, these methods tend to suffer from the inherent limitations mentioned in \cref{sec:mobile_manipulation}. Ferrandis~\etal**Ferrandis, "Learning-Based Contact Switching for Robot Manipulators"**, achieve contact switching using RL with a categorical action distribution. Despite this achievement, this approach has been limited to a fixed-base manipulator, objects with negligible mass and small size on a low-friction surface.

The works of **Kuindersma, "Tactile Feedback-Based Control of Mobile Manipulators"** propose a force and tactile feedback-based approach, respectively, for statically pushing with a mobile base robot without achieving contact switching (since the feedback signal is lost at a contact break). Moreover, they only consider moving an object to a goal position and not reorienting it. Jeon~\etal**Jeon, "Learning-Based Control of Quadrupedal Locomotion for Object Manipulation"**, train an RL policy for guiding a quadrupedal locomotion controller towards pushing diverse objects with the robot base. Their controller generates planar 2D actions for the base motion, and they do not consider object toppling as a possibility in their scenarios. In contrast, we evaluate our approach including cases where the object can topple (\ie object with a small xy-footprint on high-friction flooring). By generating 6D commands for the mobile base and joint commands for the arm, our controller can push to different locations on the object's surface.