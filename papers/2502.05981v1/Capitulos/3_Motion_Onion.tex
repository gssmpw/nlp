\section{The Motion Onion Method}
Once the general method, the MeLoCoToN, is known, we can perform several optimizations in order to compute the calculation of this equation  in an exact or approximate way. The set of techniques to make the computation of the MeLoCoToN lighter is called the \textit{Motion Onion}. Its name comes from the fact that, dynamically, we modify the way of constructing the tensor network in each iteration, modifying also its layers. This method is specialized in optimization problems, although it could be applicable to the other types in some way.

Even so, the objective of this section is not to present how to best approximate each problem, a topic that can be left for future work. The objective is to present the fundamental ideas.

\subsection{Hamiltonian separation}
The first and most important part of the Motion Onion is the separation of the parts of the cost function (or Hamiltonian) into a tensorizable and a non-tensorizable part. That is, we will separate the part of the cost function (and constraints) into one that we can implement cheaply in our tensor network, and one that is prohibitively expensive to implement. We perform this process because we are going to delegate this second part in the iterative solving process.

In each iteration, the tensor network implements the tensorizable part of the problem, gives a result for the variable to be determined, and in the next step, the tensor network is created so that it takes into account the non-tensorizable part as part of its tensor values. The process is as follows:

\begin{enumerate}
    \item We initialize the TLC with the tensorizable part of the problem, contract and determine the first variable.
    \item We initialize the TLC with the tensorizable part of the problem and the information of the previous variable, contract and determine the second variable.
    \item Depending on the obtained variables, we change the initialization, evolution or constraint tensors, so that they add the part of the cost and constraints not easily computable due to having selected them.
    \item We contract the network tensor and determine the next variable.
    \item We repeat steps 3 and 4 until all the variables are determined.
\end{enumerate}

We can understand it better with the following example.

The problem is to find a sequence of a set of $N$ elements, which can be repeated as many times as we want. The cost associated with the sequence depends on the order in which the elements appear, which means that the cost function is
\begin{equation}
    C(\Vec{x})=\sum_{t=0}^{N-2} C_{x_t,x_{t+1}},
\end{equation}
being $x_t$ the selected element at position $t$ in the sequence.


In addition, there is the soft constraint (highly recommended, but not mandatory) that each element must appear about $N_i$ times in the sequence, and this ratio must also be satisfied in local parts of the sequence. That is, its occurrence ratio must be about $N_i/N$ along the sequence.


As can be seen, the first part of the problem, the cost function, is very easy to minimize by means of the tensor network. However, the second part, the uniformity part, is terribly expensive, since each element would need a layer of tensors that have control that the ratio is fulfilled at each step. This type of layer would be similar to the $F$ layers of the TSP that we will see in Ssec.~\ref{ssec: TSP}, which make the computational cost of the realization of the algorithm scale exponentially.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Images/Motion_Onion_TN.pdf}
    \caption{Tensor Network for solving the minimization problem in the a) first iteration, b) second iteration, c) third iteration.}
    \label{fig: Motion Onion TN}
\end{figure}

For this reason, the second part will be solved by the iterative method. In the first step we create a chain tensor network, as presented in Fig.~\ref{fig: Motion Onion TN} a, which implements the imaginary time evolution with the cost function. Once we have determined the first variable, in the next iteration, instead of the system starting in a uniform superposition, it will start in a superposition that favors that the same result does not appear again. That is, we make that in the following qudits there will be an extra cost associated to the value $x_0$ determined in the first iteration. As it is more important not to move further away from the recommended distribution in the first following variables to be determined, the state of each qudit will be different. The $t$-th qudit will be initialized with the vector $\phi_t(\vec{D^m})$, with $\vec{D^m}$ being how much each has been moved away the number of times we have chosen each element from the recommended distribution. This vector is calculated as
\begin{equation}
    D^m_i=\frac{N_i}{N} - \frac{n_i}{m},
\end{equation}
being $D^m_i$ the value associated to the $i$-th element when we determine the $m$-th variable and $n_i$ the number of times $i$ appears in the sequence. This way, the initialization of the $t$-th qudit at iteration $m$ is
\begin{equation}
    \phi_t(\vec{D^m})_i = e^{\tau \frac{\lambda}{t+1-m}D^{m}_i}.
\end{equation}
In this way, there is a greater probability of choosing the elements that we have chosen the least proportionally to their distribution, and we make that priority decrease as we advance in the sequence. In addition, we put in a proportionality factor $\lambda$ to consider how relevant this condition is in relation to the cost function.

In addition, to reduce the amount of calculations, we can also eliminate the tensors associated to the variables already determined, and include their information in the remaining tensors, in an exact way. For example, in this case, it would be to make the new tensors $EXPi'$, first in the chain, take into account the cost associated with the value of the previous variable determined. This is an optimization that does not add an approximation, since it is exact.

Thus, in the second iteration we have the tensor network of Fig.~\ref{fig: Motion Onion TN} b, where we have included the information of the extra non-tensorizable constraint in the initializations. This allows us to maintain a polynomial scaling of the complexity, in exchange for making the method now approximate. This technique can also be used to change the evolution and constraint layers, so that we need less of them. Moreover, it allows the combination of the method with genetic algorithms and heuristics, useful in initializations, or to improve them thanks to tensor networks.

\subsection{Approximation by elimination}
A second technique is the layer removal approach. That is, remove constraint layers, hard constraints, and implement them in the iterative method. The process is as follows:

\begin{enumerate}
    \item The first variable is determined with a tensor network with fewer constraint layers. The value of the first variable prevents certain values in other variables.
    \item In the new tensor network to determine the next variable, instead of starting with a uniform superposition, each qudit starts with a uniform superposition only of the allowed values given the results already obtained.
    \item The tensor network is contracted and the next variable is determined, which, having eliminated the possibilities that violate the constraints, satisfies them.
    \item Steps 2 and 3 are repeated until all variables are determined.
\end{enumerate}

Obviously, this method is a huge approximation, as it may result in the fact that, in some iteration, there is no combination that meets the remaining constraints, given the previous results.

An interesting example is presented in the paper~\cite{TSP_TN}, for the traveling salesman problem. In this problem, $N$ layers of constraints are needed to guarantee that no node is repeated in the route. However, to prevent the contraction complexity of the tensor network from scaling as $2^N$, one option is to use a fixed number $L<<N$ of layers in each iteration.

In the first iteration the system starts with a uniform superposition, and a few constraint layers. The first variable $x_0$ is determined. Since a node cannot be repeated in the path, for the next iteration, the state of all qudits starts with an superposition of all possible nodes except the one we have already selected. Obviously, since the constraint has already been imposed at initialization, no constraint layer is needed for it. The variable $x_1$ is determined and for the next one, all qudits are initialized on all possible nodes, except those already selected. This is repeated until the end. To avoid problems associated with choosing inadequate constraints in the tensor network, and compensating them with each other, it is convenient to change the chosen constraint layers at each iteration.

Another example is in~\cite{Task_TN}, where we have a large set of directed constraints. These constraints mean that if one set of variables has a certain value, another can only have a specific value. However, since the constraints are obtained from historical data, not all of them are relevant to the problem. Therefore, you can start solving without constraint layers, and each time you obtain a solution that violates a constraint, add its layer to the tensor network and start over. In this way, we ensure that we only need the minimum number of constraint layers to solve the problem.

\subsection{Genetic algorithm}
An interesting combination of technologies is that of MeLoCoToN with Motion Onion and genetic algorithms. There are two possible visions in this union: using genetic algorithms to leverage tensor networks or using tensor networks to leverage genetic algorithms. We will focus on the first possibility, explored in~\cite{Task_TN}.

This union consists in having a population of initializations to remove constraints. That is, each individual in the population considers that in its solution only a subset of the values of each variable are possible, the possibilities for each variable not being equal. These are its chromosomes. Each chromosome will be the possibilities for one variable, and a subset of constraints may also be included. In this way, each individual can have a smaller number of constraints or layers in general implemented, and obtain a solution. The individuals with the best results will cross with each other, creating descendents with their chromosomes crossed. This is highly interesting for certain problems with historically obtained constraints, which may not all be relevant to obtain a quality solution.



