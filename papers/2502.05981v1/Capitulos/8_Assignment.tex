\section{Assignment Optimization problems}
In this section we will study some assignment problems, which consist in choosing or assigning elements of a set. They have a special industrial application and interest, especially for logistics.

\subsection{Simple Assignment problem}
This is the most basic assignment problem~\cite{Assignment_Survey}. The problem has a set of agents and a set of tasks. Any agent $i$ can perform any task $j$, with a cost $C_{ij}$. If the $i$-th agent does not perform any task, it performs the $0$-th task, so $C_{i,0}=0$. We want to perform as many tasks as possible, assigning at most one agent to each task and at most one task to each agent, minimizing the total cost of the assignment. The cost function is
\begin{equation}
    C(\Vec{x})=\sum_{i} C_{i,x_i},
\end{equation}
being $x_i$ the task assigned to $i$-th agent. This way, $x_i\neq x_{i'}$ if $i\neq i'$.

The value function is the number of tasks performed, defined as
\begin{equation}
    V(\Vec{x})=\sum_{i} V_{x_i},
\end{equation}
being $V_0=0$ and $V_j=1\ \forall j\neq 0$.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{Images/Assignment_TN.pdf}
    \caption{Tensor Network for the Assignment Problem with 6 agents and 4 tasks.}
    \label{fig: Assignment TN}
\end{figure}
To solve this problem, we only need to merge the initialization layers with evolution of the Chinese Postman problem with time dependency with the TSP repetition layers, without the layer that restricts the $0$ value. This tensor network is shown in Fig.\ref{fig: Assignment TN}. This case has also been studied in the paper~\cite{TSP_TN}. The function to minimize is
\begin{equation}
    \sum_{i} \left(C_{i,x_i} +\lambda V_{x_i}\right),
\end{equation}
being $\lambda$ a large enough factor to impose the maximum number of tasks performed.

In case the same task $t$ can be associated $c_t$ times, and each agent can have up to $d_i$ tasks, it will only be necessary to multiply each agent by $d_i$ times, making that number of variables with the same evolution. In addition, each filtering layer will have to have its upper limit of accounts to filter on $c_t$ instead of $1$.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{Images/Multi_Assignment_TN.pdf}
    \caption{Tensor Network for determining the first job feature for first agent.}
    \label{fig: Multi Assignment TN}
\end{figure}

This problem can be extended to the Multidimensional assignment problem, in which each agent must do a job with a set of $M$ types of job features, which cause the job cost to change. Moreover, each job feature can only be assigned once. To address this problem, the evolution tensors $S(i)$ will have $M$ indexes, each indicating a different feature associated with the jobs, such that each of their indexes is connected to a repetition filtering network tensor equal to that of the original case. We can see the tensor network in Fig.~\ref{fig: Multi Assignment TN}.

\subsection{Knapsack Problem}

Given a set of objects, such that the $i$-th object can be selected $c_i$ times, has a weight $w_i$ and a value $v_i$, the objective is to select a combination of objects that maximizes the total value $V$ and does not exceed a maximum total weight $Q$~\cite{Knapsack_original}. The value function is calculated as
\begin{equation}
    V(\vec{x})=\sum_i v_i x_i,
\end{equation}
being $x_i$ the number of times we choose the $i$-th object, and the weight function as
\begin{equation}
    W(\vec{x})=\sum_i w_i x_i.
\end{equation}
The 0-1 version has been solved with quantum algorithms~\cite{0_1_knapsack_quantum}.

To solve this problem, the tensor network is similar to the Fig.~\ref{fig: Natural sum TN}, but instead of having the evolution in the last tensor, it takes care of eliminating all combinations that exceed the total possible weight $Q$. Each tensor in the chain performs the same task. The initialization tensors also perform the imaginary time evolution using the value of each object, such as $e^{\tau v_i x_i}$ for the $i$-th tensor, since it is a maximization problem. The optimal version of solving this problem is available in {\color{red} [pending publication]}. Based on this tensor network, two interesting generalizations can be made by changing only the tensor elements.

\subsubsection{Non Linear Knapsack Problem}
An interesting generalization of the knapsack problem is the nonlinear case. Under these circumstances, our cost and weight functions are given by the sum of nonlinear functions such that we define it as
\begin{equation}
    \begin{gathered}
        V(\vec{x})=\sum_{i=0}^{n-1}v_i(x_i) \\
        \text{subject to }W(\vec{x})=\sum_{i=0}^{n-1}w_i(x_i)\leq{Q},\\
        x_i\in [0,c_i]\quad \forall i\in [0,n-1],
    \end{gathered}
\end{equation}
where $w_i$ and $v_i$ are functions that receive natural numbers and return natural and real positive respectively.

Another simpler formulation is to convert these functions into vectors, since their inputs are natural, so that the problem is rewritten as
\begin{equation}
    \begin{gathered}
        V(\vec{x})=\sum_{i=0}^{n-1}v_{i,x_i} \\
        \text{subject to }W_{\vec{x}}=\sum_{i=0}^{n-1}w_{i,x_i}\leq{Q},\\
        x_i\in [0,c_i]\quad \forall i\in [0,n-1],
    \end{gathered}
\end{equation}
where $w$ is a natural number tensor with $w_{i,b}=\infty$ when $b>c_i$ and $v$ is a positive real number tensor with $v_{i,b}=-\infty$ when $b>c_i$ .

To address this problem, we will only need to modify the exponentials of the imaginary time evolution to add the nonlinearity and modify the output rates of the weight outputs. In this way, the tensors $M^m_{c'_m\times Q'}$ will have their non-zero elements
\begin{equation}
    \begin{gathered}
    \mu=w_{m,i} + \sum_{k=0}^{m-1}w_{k,x_k}, \\
    M^{m}_{i\mu}=e^{\tau v_{m,i}},
    \end{gathered}
\end{equation}
the tensors $K^k_{Q'\times Q'}$ will have their non-zero elements
\begin{equation}
    \begin{gathered}
    y_k \in [0,c_k], \quad \mu=i+w_{k,y_k}, \\
    K^{k}_{i\mu}=e^{\tau v_{k,y_k}},
    \end{gathered}
\end{equation}
and the tensors $K^{n-1}_{Q'}$  will have their non-zero elements
\begin{equation}
    \begin{gathered}
    d_{i}=\arg\max(\vec{\rho^{i}}),\quad \rho^{i}_{y} = \frac{1}{Q-i-w_{n-1,y}}, \\
    K^{n-1}_{i}=e^{\tau v_{n-1,d_i}}, 
    \end{gathered}
\end{equation}
where $d_i$ is the maximum number of elements of the last class that can be introduced into the knapsack without exceeding the capacity $Q$ having already a weight $i$.

In this case, the tensors involved are of the same size as in the original case, and we can also use the reuse of intermediate calculations in the same way. In addition, the optimization of the diagonals works exactly the same, only now they will not be equispaced. For all this, the computational complexity of the algorithm is the same as in the original case.

\subsubsection{Polynomial Knapsack Problem}
Another important generalization of the knapsack problem is the case where the weight function is a polynomial. To generalize as much as possible, we will take the value function to be given as a sum of nonlinear functions, and the weight function is a polynomial of a sum of nonlinear functions. With the tensorial notation, the problem is expressed as
\begin{equation}
    \begin{gathered}
        V(\vec{x})=\sum_{i=0}^{n-1}v_{i,x_i}, \quad W_{\vec{x}}=\sum_{i=0}^{n-1}w_{i,x_i},\\
        F(z)=a_0+a_1z+a_2z^2+\dots+a_pz^p\\
        \text{subject to }F(W_{\vec{x}})\leq{Q},\\
        x_i\in [0,c_i]\quad \forall i\in [0,n-1],
    \end{gathered}
\end{equation}
where $w$ is a natural number tensor with $w_{i,b}=\infty$ when $b>c_i$ and $v$ is a positive real number tensor with $v_{i,b}=-\infty$ when $b>c_i$ .

In this case, what the tensors will send to each other will be the partial result of $W$ up to that point, exactly as in the previous case. However, the change will be in the last tensor, which will be the one that will apply the $F$ function on the total accumulated $W$, eliminating the states for which it exceeds $Q$. The last tensor is
\begin{equation}
    \begin{gathered}
    d_{i}=\arg\max(\vec{\rho^{i}}),\quad \rho^{i}_{y} = \frac{1}{Q-F(i+w_{n-1,y})}, \\
    K^{n-1}_{i}=e^{\tau v_{n-1,d_i}}, 
    \end{gathered}
\end{equation}
where $d_i$ is the maximum number of elements of the last class that can be introduced into the knapsack without exceeding the capacity $Q$ having already a weight $i$.

Given the characteristics of this modification, we can also address the case in which $F$ is not a polynomial of $z$, but is a nonlinear function of $z$. In this case, the modification of the final tensor is exactly the same, taking into account the new $F$ function.

If we impose that the coefficients $a_k$ are positive integers, then $Q'\geq F(W_{\vec{x}})\geq W_{\vec{x}}$, so the matrices will have, at most, dimension $Q'$.

For the same reasons as in the previous case, the computational complexity is the same as in the original case.


\subsection{Cutting stock problem}
Given a set of $N$ types of parts, having the $i$-th part having a demand of $d_i$ and a length of $w_i$, the problem consists in determining how many parts to cut from each plate of raw material of length $W$, so that we minimize the number of plates used~\cite{Cutting_Stock}. That is, we cannot afford to exceed the total length $W$ in a single roll, and each type of piece must appear at least $d_i$ times. To formulate this problem, our variables will be $x_{i,p}$, which will indicate how many pieces of type $i$ are cut on plate $p$, and $y_p$ which is a binary variable that tells us whether that plate has been used.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{Images/Cutting_TN.pdf}
    \caption{Cutting stock problem tensor network.}
    \label{fig: Cutting stock}
\end{figure}

To solve this problem, we will use the tensor network of Fig.~\ref{fig: Cutting stock}. In this tensor network, we have a block for each raw material plate, and a qudit line for the number of pieces $x_{ip}$ of each type. To impose the constraint of not exceeding the maximum length we use some tensors $S(W)$ which are sent what is the length up to that point, within the block of that plate. If at any time the limit is exceeded, the state is removed. To minimize the number of plates, if the length exceeds 0, we multiply the amplitude by $e^{-\tau c_i}$, being $c_i$ the cost of making use of the $i$-th plate. If all the plates have the same cost, this is the bin packing problem~\cite{Bin_Packing,Bin_packing_aprox}, which has been solved with quantum algorithms~\cite{Bin_Packing_Quantum,Bin_Packing_Quantum_Bench} and quantum annealing~\cite{Bin_Packing_Annealer,Bin_Packing_Annealer_3D}. To impose the demand condition, for each qudit, a tensor $Z(d)$ is created, and connected between blocks, keeping track of how many pieces of each type are carried. If at the end of the line, any of the types has been produced fewer times than demanded, the condition is eliminated.

