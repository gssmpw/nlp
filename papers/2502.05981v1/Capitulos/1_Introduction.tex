\section{Introduction}
A combinatorial problem is a problem consisting in finding a combination of elements with certain characteristics. There are basically three types of combinatorial problems: \textit{inversion problems}, which consist in obtaining the input that results in a known output through a function, \textit{constraint satisfaction problems}, which consist in finding a solution that satisfies a set of restrictions, and \textit{optimization problems}, which consist in obtaining the combination that has the lowest or highest associated value of a certain function.

Combinatorial inversion problems (do not confuse with inverse combinatorial optimization~\cite{Inverse_comb}) have application in cryptography, because if there is a function that obtains the public key of a protocol from the private key, being able to perform the reverse process would compromise its security. An example is the RSA protocol~\cite{RSA}, in which we have two prime numbers $p$ and $q$ as private information. The public information is obtained by multiplying them, obtaining a number $N=pq$. This process is very simple, but the reverse process of obtaining $p$ or $q$ from $N$ is highly expensive.

Constraint satisfaction problems~\cite{CSP} are those in which we search for a solution that satisfies a given set of constraints. This type of problems are especially interesting for real world applications such as resource relocation. Some examples of academic cases are N queens~\cite{N_Queens} or binary sudoku. However, they are usually highly expensive problems to solve, which leads to their resolution with heuristic methods~\cite{Heuristics}.


Combinatorial optimization problems~\cite{Combinatorial} are those in which we search for the vector $\vec{x}$ of integers which minimizes or maximizes a certain function $C(\cdot)$ called \textit{cost function}, given some constraints. That is, we look for the combination with the lowest or highest possible cost that satisfies the constraints. On many occasions, it is possible to include the constraints within the cost function itself as a term that greatly raises or decreases the cost of any incompatible combination. Combinatorial optimization problems are very useful for various applied use cases and academic cases. Some applied examples are route problems as the shortest path problem~\cite{A-star,Dijkstra1959} or the traveling salesman problem~\cite{TSP_overview,TSP,TSP2}; task scheduling as the job shop scheduling problem~\cite{JSSP_General,Flexible_JSSP} or flow shop scheduling problem~\cite{FlowShop} and constrained optimization as knapsack problem~\cite{Knapsack_original}, minimal spanning tree~\cite{minimaltree} or bin packing problem~\cite{Bin_Packing}.

One of the limitations in tackling all these problems is that many of them are NP-Hard, which implies that they are unassumingly expensive to solve exactly, either in space or time. There are several ways to approach this type of problems: heuristics~\cite{Heuristics}, genetic algorithms~\cite{Genetic}, approximate methods~\cite{Aproximated}, etc.

One of the technologies that has gained the most popularity in trying to address these problems is quantum computing~\cite{Bench_Quantum_Optim,Quantum_Block_Optim,Variational_Quantum_Optim,Generative_Quantum_Combinat}. Due to phenomena such as superposition and entanglement, a different type of computation can be performed. For example, in algorithms such as the Quantum Approximate Optimization Algorithm (QAOA) \cite{QAOA}, the system starts from a superposition of all the solutions and is operated in such a way that the correct solution is obtained at the end of the process with maximum probability. In many quantum computing techniques, the Quadratic Unconstrained Binary Optimization (QUBO) formulation \cite{QUBO} is used, consisting in modeling the problems as relations between pairs of unconstrained binary variables.

Due to the current limitations of quantum hardware~\cite{Quantum_Limitations}, other alternative quantum-inspired technologies have emerged. One of them is tensor networks~\cite{Tensor_networks}, which consist in the use of tensor operations to represent data and interactions.  In this way, quantum circuits can be represented as tensor networks that perform the same matrix operations~\cite{Simulation}. In addition, unknown data can be generated from knowing the rules or structure that it follows, applying them to the tensors that will generate them. It is important to realize that a tensor network is an equation. If a tensor network returns the solution to a problem, this will imply that this problem has an equation that solves it. Tensor networks have been used in recent years in various ways to address combinatorial optimization problems~\cite{TTOpt,TN_Constraint,TN_Optim_Quick,TN_Generative,TNGEO,QAOA_TN,HOBO_TN,HOBOTAN,TSP_TN,Task_TN,QUBO_Tridiagonal}, obtaining interesting results.

A very interesting work is~\cite{TN_Constraint}, in which they presented the possibility of using a tensor network simulating a quantum state. An imaginary time evolution with respect to its cost hamiltonian is applied to it. After that, tensors based on logics that eliminate the states incompatible with the restrictions are applied. Finally, the expected value of the $Z$ operator for one of the qubits is measured. In this way the correct value of the variable represented by that qubit can be determined. Although the idea presented is brilliant, this work is limited to the simulation of a quantum system, so it needs to unnecessarily increase memory and execution times by needing to contract a network tensor twice as large. The presented tensor network can be halved by performing a direct summation of the amplitudes as they are all positive, which is only a rescaling of its damping parameter $\tau$. Moreover, its way of dealing with degenerate states presents problems that are solved by projections in the iterations following the moment when one of the combinations is chosen. On the other hand, it is limited to the case of binary variables, but it is easily generalizable to positive integer variables by switching to the qudits formalism, and replacing the $Z$ operator by leaving that index free and checking
the position of the maximum. With these slight changes, the fundamental idea they present can be used to explore and design algorithms for solving not only combinatorial optimization problems, but any combinatorial problem.

In this paper we will present a general method to obtain a tensor network that solves a combinatorial problem and some techniques to improve its computation. After that, we will present the tensor networks that solve several examples of combinatorial problems and how to obtain them. It is important to emphasize that the aim of this paper is to present the method as an alternative mathematical analysis of the problems, rather than as a technique with an advantage over the state-of-the-art. For this reason, we will omit the analysis of the computational complexities, since in most of the cases that we will present, this method is exponentially more expensive than the known solutions, or even brute force. This does not imply that there are no cases in which this advantage may exist. Finally, we will present a new notation to simplify the presentation of tensor network papers.

Some parts of the paper are not available because they refer to unpublished papers. Future versions will include these papers after they have been published.