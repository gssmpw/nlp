\section{Discussion}
\label{sect:discussion}

These results demonstrate the effectiveness of the proposed \lstmaesac architecture for search planning. The LSTMAE effectively captures temporal dependencies within the path, leading to improved performance and stability compared to simpler frame-stacking methods. The RAE training harness maximizes the information throughput in the latent representation which is akin to lossy compression. This prevents the onus from being on the DRL algorithm to perform the same function. Furthermore, the recurrent network allows maximum throughput regardless of path length - from 2 steps to $N$ - since every neuron within the policy is trainable regardless of state. The training stability seen in \autoref{fig:results:rollout_reward_mean_over_time} underlines this with both \lstmaeppo and \lstmaesac having stable learning curves.

While further investigation is needed to definitively determine the optimal DRL algorithm over all architectures, the results show that SAC has an edge over PPO when used with LSTMAE. This aligns with results from \citet{mock_comparison_2023} which suggested that SAC is better for larger dimensional observation spaces.

Isolating the path feature extraction from the DRL algorithm in \autoref{sect:results:algorithm} suggested that the frame-stacking with LSTM was the poorest performer with LSTMAE being the best. This furthers provides evidence to the theory that the RAE is superior to standalone DRL. On the other hand, \lstmppo is close in performance to \lstmaeppo which suggests that simple frame-stacking is the main issues.

The significant performance improvement of the larger \lstmaesac over the larger \fssacfcn in \autoref{sect:results:benchmark} highlights the true efficiency and potential of the proposed approach. Similarly, the minor performance difference between large \fssacfcn and small \lstmaesac shows the power of the highly specialized network architecture proposed in this work. This suggests that the \lstmaesac in general can achieve high performance with fewer parameters and shorter training times, making it a promising approach for real-world applications where computational budgets can be limited.