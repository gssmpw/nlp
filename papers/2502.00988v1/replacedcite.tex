\section{Related Work}
% \noindent\textbf{Code LLMs}: Following ChatGPT's release, both proprietary LLMs (GPT-3.5, GPT-4, Gemini Pro) and open-source models (CodeLlama ____, DeepSeekCoder ____, WizardCoder ____, MagiCoder ____) have demonstrated advanced code generation capabilities.

\noindent\textbf{Code LLMs}: With the advent of ChatGPT, several propriety LLMs like GPT-3.5, GPT-4, and Claude Sonnet-3.5 have emerged with increasingly strong code generation abilities. Moreover, numerous open-source LLMs such as CodeLlama ____, DeepSeekCoder ____, ____, ____ have also come out that are on par in producing executable code. 


\noindent\textbf{LLM-based Data Visualization}: Several previous works have attempted to automate data visualization generation from natural language. ____ was the first attempt to use LSTM to convert JSON data into Vega-Lite visualizations. ____ explored use of LLMs to generate visualization code. Recent works studied the utility of LLMs like ChatGPT for generating charts from ambiguous natural language  ____. ____ expanded this line of work to include multimodal LLMs for chart plotting. ____ tried to involve human feedback to refine the LLM generated plots via reinforcement learning. ____ proposed a framework to provide visual feedback to LLMs for iterative refinement. Our work is different from existing works as it explores the use of multimodal feedback via LLM self reflection to resolve errors related to numeric values, lexical labeling and visual aesthetics.

% \noindent\textbf{LLM Data Visualization}: Prior research has explored automated visualization generation from natural language. ____ pioneered this field using LSTM to convert JSON data into Vega-Lite visualizations, while ____ was an initial attempt to use LLMs for visualization code generation. Recent studies have examined ChatGPT's effectiveness in chart generation from ambiguous queries ____, with ____ extending this to multimodal LLMs. ____ incorporated human feedback through reinforcement learning, while ____ developed a visual feedback framework for iterative refinement. Our work uniquely explores multimodal feedback through LLM self-reflection to address errors in numeric values, lexical labeling, and visual aesthetics.



\noindent\textbf{LLM Agents}: Recent years have seen a proliferation of frameworks that utilize Large Language Models (LLMs) to test their applications in practical scenarios ____. The development of OpenAgents ____ marked the introduction of an accessible platform that implements LLM-powered agents for daily use through three specialized components: Data Agent, Plugins Agent, and Web Agent. A groundbreaking simulation system that replicates human behavioral patterns was developed by ____, enabling software agents to computationally reproduce authentic human actions and interactions. In the gaming realm, Voyager ____ emerged as the pioneer LLM-controlled autonomous agent within Minecraft, engineered to continuously discover its surroundings, develop diverse abilities, and generate novel discoveries without human intervention. The software development sphere saw innovation through ChatDev ____, which established a virtual software company operated through chat interfaces and adhering to waterfall development principles. Building upon these advances, our research investigates how LLM-based agents can contribute to scientific data visualization, an essential domain for modern researchers.