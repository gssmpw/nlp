\section{Related Works}
\label{sec:appendix}

\subsection{Knowledge Editing}
Model editing has gained significant attention for its ability to efficiently update LLMs. Existing approaches can be categorized into four types: \textbf{Fine-tuning} mainly applies layer-wise adjustments to incorporate new knowledge into LLMs **Vries et al., "Training Modular, Spatially-Sensitive Graph Neural Networks"**__**Zhang et al., "Meta-Learning for Few-Shot Knowledge Editing in Large Language Models"**. \textbf{Meta Learning} trains hypernetworks to act as editors, predicting parameter updates to inject new knowledge **Rebuffi et al., "Learning Multiple Visual Domains with Residual Adaptators"**__**Munkhdalai and Yu, Meta-Learning for Few-Shot Knowledge Editing in Large Language Models"**. \textbf{Memory-based} enhances LLMs with external memory or additional parameters, allowing new knowledge to be added without altering LLMs **Kaplan et al., "Scaling Laws for Neural Machine Translation"**__**Gulrajani et al., "Improved Techniques for Training Translation Models"**.

Among all types, \textbf{Locate-then-Edit} has gained significant traction for its ability to modify specific knowledge within LLMs. Methods like **Borgeat and Ribeiro, "Knowledge Editing in Large Language Models via Locating and Updating Factual Knowledge"**__**Kim et al., "Efficient Knowledge Editing in Large Language Models with Rome and Memit"** locate and update factual knowledge by targeting neurons or multi-layer perceptrons (MLPs) that store such information. **Hao et al., "Memit: A Memory-Augmented Approach to Efficient Knowledge Editing in Large Language Models"** extends ROME by distributing updates across multiple intermediate MLP sublayers, enabling large-scale knowledge editing. Additionally, **Guo et al., "Pmet: A Hybrid Approach Combining Self-Attention and MLP for Efficient Knowledge Editing in Large Language Models"** combines information from both multi-head Self-attention (MHSA) and MLP modules during optimization, producing more accurate MLP outputs for final edits.

While model editing has shown great promise, some researches have identified issues such as model collapse**Goyal et al., "Model Collapse: A Challenge for Model Editing in Large Language Models"**__**Zhang et al., "Knowledge Conflicts: A New Perspective on Model Editing in Large Language Models"**. This paper focuses on how the correlation between knowledge impacts the performance of model editing, particularly in the context of multiple knowledge edits.

% \textbf{Fine-tuning.}\quad These methods apply layer-wise fine-tuning to incorporate new knowledge into LLMs. For example, **Zhang et al., "Meta-Learning for Few-Shot Knowledge Editing in Large Language Models"** propose fine-tuning LLMs with a norm constraint between the edited and original model parameters to reduce the risk of catastrophic forgetting.

% \textbf{Meta Learning.}\quad This category trains a hypernetwork to act as an editor, predicting parameter updates to inject new knowledge. **Rebuffi et al., "Learning Multiple Visual Domains with Residual Adaptators"** uses a trained hypernetwork to predict parameter modifications for each edit request. Similarly, **Munkhdalai and Yu, Meta-Learning for Few-Shot Knowledge Editing in Large Language Models"** employs hypernetworks to learn a low-rank decomposition of fine-tuning gradients, enabling efficient modifications of LLMs to accommodate new facts.

% \textbf{Memory-based.}\quad These methods enhance LLMs with external memory or additional parameters, allowing new knowledge to be added without altering the core model. **Kaplan et al., "Scaling Laws for Neural Machine Translation"** uses external memory to store edits and retrieves relevant information. T-Patcher uses key-value pairs into MLP modules to incorporate specific knowledge without affecting unrelated information.

% \textbf{Locate-then-Edit.}\quad  This paradigm have gained significant traction for its ability to modify specific knowledge within LLMs. For instance, methods like **Borgeat and Ribeiro, "Knowledge Editing in Large Language Models via Locating and Updating Factual Knowledge"**__**Kim et al., "Efficient Knowledge Editing in Large Language Models with Rome and Memit"** developed techniques to locate and update factual knowledge by targeting neurons or multi-layer perceptrons (MLPs) that store such information. **Hao et al., "Memit: A Memory-Augmented Approach to Efficient Knowledge Editing in Large Language Models"** further enhances ROME by distributing updates across multiple intermediate MLP sublayers, accommodating large-scale knowledge editing. Additionally, **Guo et al., "Pmet: A Hybrid Approach Combining Self-Attention and MLP for Efficient Knowledge Editing in Large Language Models"** combines information from both the multi-head Self-attention (MHSA) and MLP modules during the optimization process, allowing it to produce more accurate MLP output for editing at the final body position.

% The goal of model editing is to update specific knowledge LLMs accurately and efficiently, without affecting unrelated information. Formally, given factual knowledge $t=(s,r,o)$, consisting of subject $s$, relation $r$, and object $o$, and an LLM $f_\theta$, along with target factual knowledge $t'=(s,r,o')$, where $o' \neq o$, the goal of a model editing algorithm $\xi$ is to optimize the parameter $\theta$ into $\theta'$ so that the edited model $f_{\theta'}$: $\xi(f_{\theta},t)=f_{\theta'}$ correctly produces $o'$ when provided with the prompt $p(s,r)$, as $f_{\theta'}(p(s,r))=o'$. 

% Among various model editing methods, \textit{Rome-like editing methods}, such as ROME and MEMIT, have garnered significant attention due to their outstanding editing performance. These methods first employ causal tracing to identify that factual knowledge is primarily stored in the early MLP layers of LLMs. Based on the hypothesis that "the MLP modules in Transformer layers can be viewed as linear key-value associative memory", we can get $Wk=v$, where $W$ represents the downsample component of MLP, and the key-value pair $(k, v)$ corresponds to a factual triplet $t=(s, r, o)$. Here, $k$ represents the subject $s$, while $v$ encodes the attributes of $s$, including $r$ and $o$. Therefore, when $t=(s, r, o)$ needs to be replaced by $t^*=(s, r, o_{\ast})$, we only need to find the corresponding key vector $k_{\ast}$ and the new value vector $v_{\ast}$. By calculating the update $\Delta W$, we can effectively update the stored knowledge in the large model.

% Take ROME for example assigns $k_{\ast}$ as an average vector derived from subject $s$ with a small set of $N$ randomly sampled prefixes:

% \begin{equation}
%   \label{eq:example}
%   k_{\ast} = \frac{1}{N} \sum_{i=1}^{N} \mathcal{K}(x_i \oplus s)
% \end{equation}

% \noindent where $\mathcal{K}$ is the output of the first MLP layer in transformer block, $x_i$ is the prefixes, and $\oplus$ is string concatenation operator. 

% Then $v_{\ast}$ is calculated from $(s,r,o_{\ast})$ and the specially loss function. Given $(k_{\ast}, v_{\ast})$, ROME finds optimal $\widehat{W}$ to solve the following problem:

% \begin{equation}
%   \label{eq:example}
%   \text{minimize} \ \|\widehat{W}K - V\| \quad \text{s.t.} \quad \widehat{W}k_{\ast} = v_{\ast}
% \end{equation}

% It has the following closed-form solution:

% \begin{equation}
%   \label{eq:example}
%   \widehat{W} = W + \frac{(v_{*} - W k_{*}) (C^{-1} k_{*})^{\top}}{(C^{-1} k_{*})^{\top} k_{*}}
% \end{equation}

% \noindent where $W$ denotes the weight matrix of the second layer of the MLP before editing, $\widehat{W}$ denotes the weight matrix after editing, and $C=KK^{\top}$ is a precached constant.

% For other Rome-like Editing Methods, MEMIT further improves ROME by evenly distributing updates across multiple intermediate MLP sublylayers to accommodate the needs of large-scale knowledge editing. The PMET combines information from both the multi-head Self-attention (MHSA) and MLP modules during the optimization process, allowing it to generate a more accurate MLP output for editing at the final body position.

\subsection{Sequantial-editing vs. Batch-editing} \label{sec:comparison}

\textit{Sequential-editing} and \textit{batch-editing} are two strategies commonly used to update large amounts of knowledge in LLMs **Zhang et al., "Meta-Learning for Few-Shot Knowledge Editing in Large Language Models"**__**Goyal et al., "Model Collapse: A Challenge for Model Editing in Large Language Models"**.