\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[dvipsnames]{xcolor}
%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{2397} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2025}

\usepackage{multicol}
\usepackage[dvipsnames]{xcolor}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{figchild}
\usepackage{tikz}
\usepackage{tikzsymbols}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{booktabs} % for professional tables
\usepackage{mathtools}
\usepackage{amsthm}
\RequirePackage{algorithm, algorithmic}
%\usepackage{algpseudocode}
\usepackage{multirow}
%\usepackage{cite} 
\usepackage{caption}
\usepackage{utfsym}
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
%\usepackage{subcaption}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\norm}[1]{{\lVert {#1} \rVert}}
\definecolor{myblue}{HTML}{5364cc}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{array} 
\usepackage{fontawesome5}
\usepackage{figchild}
\usepackage{utfsym}

\newif\ifdraft
\drafttrue
% \draftfalse
\ifdraft
     \newcommand{\wm}[1]{\textcolor{magenta}{{[wwm: #1]}}}
\else
    \newcommand{\wm}[1]{}
\fi

\definecolor{deepgreen}{rgb}{0,0.5,0.4}
\definecolor{teal}{rgb}{0.78, 0.875, 0.703}
\renewcommand{\algorithmiccomment}[1]{\hfill $\triangleright$ #1}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%



%%%%%%%%% 
\title{\textcolor{myblue}{NoPain}: \textcolor{myblue}{N}o-b\textcolor{myblue}{o}x \textcolor{myblue}{P}oint Cloud \textcolor{myblue}{A}ttack via Optimal Transport S\textcolor{myblue}{i}ngular Bou\textcolor{myblue}{n}dary}


\author{Zezeng Li$^{1,2}$, ~ Xiaoyu Du$^{1}$, ~Na Lei$^{1*}$
% \thanks{Corresponding author: \emph{Na Lei (nalei@dlut.edu.cn)}}
, ~Liming Chen$^{2}$, ~Weimin Wang$^1$\thanks{Corresponding authors.
% : \emph{Weimin Wang (wangweimin@dlut.edu.cn)}
}\\ 	
\normalsize{$^1$School of Software, Dalian University of Technology, China}\qquad
\normalsize{$^2$Ã‰cole Centrale de Lyon, France}
}

\begin{document}
\maketitle


%%%%%%%%% ABSTRACT
\begin{abstract} 
%Point cloud attacks are vital to ensure the safety of autonomous driving and robot navigation. 
Adversarial attacks
% is an effective way to 
% reduce
exploit
the vulnerability of deep models against adversarial samples.
Existing point cloud attackers are tailored to specific models, iteratively optimizing perturbations based on gradients in either a white-box or black-box setting. Despite their promising attack performance, they often struggle to produce transferable adversarial samples due to overfitting to the specific parameters of surrogate models. To overcome this issue, we shift our focus to the data distribution itself and introduce a novel approach named \textbf{NoPain}, which employs optimal transport (OT) to identify the inherent singular boundaries of the data manifold for cross-network point cloud attacks. Specifically, we first calculate the OT mapping from noise to the target feature space, then identify singular boundaries by locating non-differentiable positions. Finally, we sample along singular boundaries to generate adversarial point clouds. Once the singular boundaries are determined, NoPain can efficiently produce adversarial samples without the need of iterative updates or guidance from the surrogate classifiers. Extensive experiments demonstrate that the proposed end-to-end method outperforms baseline approaches in terms of both transferability and efficiency, while also maintaining notable advantages even against defense strategies. Code and model are available at \url{https://github.com/cognaclee/nopain}.
\end{abstract}


%%%%%%%%% BODY TEXT
\vspace{-2mm}
\section{Introduction}
Recent research has extensively examined the adversarial vulnerability of deep neural networks (DNNs) \cite{szegedy2013intriguing,goodfellow2014FGSM,moosavi2016deepfool,papernot2016limitations,carlini2017cw,athalye2018obfuscated,duboudin2022look}, demonstrating that even minimal perturbations to input data can lead advanced DNN models to make erroneous predictions. This vulnerability poses significant threats to security-critical systems and has spurred research on adversarial attacks to improve models' robustness. 

\begin{figure}[htb!]
\centering
\includegraphics[width=.99\linewidth]{figures/teaser4.pdf}
\vspace{-2mm}
\caption{Point cloud attack via OT singular boundary. We exploit singular boundaries of the data manifold, induced by the OT, to perform no-box attacks. Our approach begins by applying the OT mapping to obtain the hyperplane
set \{\textcolor{orange}{$\pi_{\boldsymbol{h},i}$}\} and polygons decomposition of the data manifold. Next, we compute dihedral angles between neighbor hyperplanes to identify singular boundaries. Finally, adversarial samples \textcolor{purple}{$\boldsymbol{\widehat{y}}$} are generated by sampling along singular boundaries. 
Hyperplanes of the same color represent the hyperplane associated with $\boldsymbol{y_i}$~(\textcolor{deepgreen}{dark}) and its neighbor (\textcolor{teal}{light}), with a singular boundary indicated by the \textcolor{red}{solid and dashed red lines}.}
\label{fig:illustration}
\end{figure}

Given the crucial role of 3D DNNs in security-sensitive applications such as autonomous driving and robot navigation, various point cloud attack methods~\cite{liu2019extending,zhang2019defense,tsai2020robust,hamdi2020advpc,sun2021adversarially,liu2020sink,rampini2021universal,cheng2021universal,dong2022isometric,huang2022siadv,liu2022boosting,tao20233dhacker,tang2023manifold,zhang2024improving} have been developed to perturb data from different perspectives, effectively revealing the vulnerabilities of current point cloud classifiers. Most of these methods are white-box attacks~\cite{liu2019extending,zhang2019defense,xiang2019generating,tsai2020robust,sun2021adversarially,kim2021minimal,rampini2021universal,cheng2021universal,shi2022shape,dong2022isometric,tang2023manifold,lou2024hide}, requiring access to the structure, weights, and gradients of the target models. However, their effectiveness diminishes significantly when tested on different networks, indicating low attack transferability. %Its cause lies in the tendency for optimization-based attacks to overfit specific network parameters in a white-box setting.

Contemporary advancements aimed at enhancing attack transferability in black-box settings~\cite{hamdi2020advpc,liu2022boosting,huang2022siadv,liu2022imperceptible,zhang2024eidos,tao20233dhacker,he2023generating,chen2024anf,zhang2024improving} can be divided into two primary categories: transfer-based attacks and boundary-based attacks. Transfer-based methods typically employ autoencoders or partial parameters of the surrogate model to enhance the transferability of attacks. Boundary-based attacks aim to improve transferability by generating perturbations at the decision boundaries, thereby altering the predictions. While these techniques enhance transferability, they require access to partial model parameters or multiple queries to proxy models for iterative optimization of adversarial samples. This reliance on model-specific strategies introduces the risk of overfitting, ultimately limiting their transferability. 


Some researchers have approached attack by focusing on global distribution alignment. As a powerful tool for distribution alignment, optimal transport~(OT) has been successfully applied to transferable attacks in images \cite{han2023ot,labarbarie2024optimal,li2023ot}. Han \etal~\cite{han2023ot} leverage OT to align image and text distributions, enhancing the transferability of attacks in image-language models. Labarbarie \etal~\cite{labarbarie2024optimal} achieve a patch adversarial attack by aligning features of adversarial images produced by the surrogate classifiers' encoder with those of target images. This raises key questions: \textbf{Is a surrogate model necessary? Must adversarial samples be obtained through optimization?} In response, this paper explores a no-box~(classifier-free) end-to-end point cloud attack.


%To achieve this, we first treat adversarial attacks as a generative task. By calculating the OT mapping from the noise space to the feature space, we determine the local singular boundaries of the data manifold with feature pairs, where the OT mapping is non-differentiable between the feature pairs.  We then perturb the features by shifting them toward these boundaries, producing modified features. Building upon it, we propose \textbf{NoPain} which can generate highly transferable examples without the need for iterative optimization and supervision from surrogate models. In summary, our main contributions are:

To achieve this, we first approach adversarial attacks as a generative task. By calculating the OT mapping from the noise space to the feature space, we identify the local singular boundaries of the data manifold, represented by feature pairs where the OT mapping is non-differentiable. We then perturb features by shifting them toward these boundaries, generating modified features. Building on it, we introduce \textbf{NoPain}, a method capable of generating highly transferable examples without iterative optimization or supervision from surrogate models. In summary, our main contributions are:
\begin{itemize}[leftmargin=*]
%\item We propose an interpretable and efficient no-box adversarial attack framework by exploring the singular boundaries of the data manifold itself through optimal transport.
\item We propose a novel no-box adversarial attack framework by directly exploring the data manifold's singular boundaries with explicit and geometric interpretable OT map.
%\item We leverage the generic representations learned by models (e.g., Point-Diffusion~\cite{luo2021diffusion}) trained on large datasets to generate transferable adversarial examples.
\item Our algorithm exhibits strong cross-network transferability and robustness against defense owing to being free from model-specific loss and leveraging intrinsic data characteristics.
%\item Our attack algorithm exhibits robust cross-network transferability owning to its independence from model-specific loss and sample-wise optimization.
\item The proposed method is end-to-end and requires no optimization, significantly enhancing the attack's efficiency.
\item Extensive experiments show that \textbf{NoPain} outperforms the SOTAs regarding the attack performance and adversary quality, particularly in transferability.
\end{itemize}




\begin{figure*}[tbhp!]
\vspace{-2mm}
  \centering
   \includegraphics[width=0.99\linewidth]{figures/pipeline.pdf}
   \vspace{-3mm}
   \caption{Overview of the proposed no-box point cloud attack framework \textbf{NoPain}. $\boldsymbol{Y}$ represents sample features, and $\boldsymbol{X}$ is noise. The dotted line indicates the process only in the test phase. The blue point cloud on the left is the original point cloud, and the crimson one on the right represents the generated adversarial samples. 
   For the OT Attack, we first apply OT to calculate the hyperplane set, {$\pi_{\boldsymbol{h},i}$}, associated with each feature $\boldsymbol{y}_{i}$. Next, we use the approach in Sec.\ref{sec:singbound} to determine singular boundaries and execute the attack with Eq.\eqref{eq:interplatation} in Sec.~\ref{sec:sampling}.}
   \label{fig:framework}
   \vspace{-2mm}
\end{figure*}

\section{Related Work}
\noindent \textbf{White-box attack on point cloud.}
Existing works of point cloud attacks can be roughly divided into white-box attacks and black-box attacks. %White box attack means that all information of the attacked classification model can be used to update perturbations, including the prediction and gradient of the model. 
Recently, most white-box attack works adopt \emph{point-based attacks}~\cite{liu2019extending,zhang2019defense,tsai2020robust,sun2021adversarially}. Liu et al.~\cite{liu2019extending} extended the gradient-based adversarial attack FGSM~\cite{goodfellow2014FGSM} strategy to point clouds.%, iteratively searching the desired point-wise perturbation under an $l_2$ norm constraint.
3D-Adv~\cite{xiang2019generating} introduced the C\&W attack framework~\cite{carlini2017cw} in point cloud attacks, producing adversarial examples by shifting point coordinates and adding additional points.
%with the guidance of the target classifier. Afterward, 
Tsai \etal~\cite{tsai2020robust} improved the C\&W attack framework by introducing a KNN regularization term to suppress outlier points and compact point cloud surface. GeoA\text{$^3$}~\cite{wen2020geometry} uses a combined geometry-aware objective to maintain local curvature consistency and a uniform surface.% on the adversarial point cloud. 
Zheng \etal~\cite{zheng2019saliency} proposed that deleting a small number of points with high saliency can effectively cause misclassification.
Apart from the point-based methods mentioned above, several studies have explored \emph{shape-based attack}. Liu \etal~\cite{liu2020sink} introduced shape-based attacks by adding new features to objects. %, as well as using a Gaussian kernel for sinking operations to deform point clouds. 
Zhang \etal~\cite{zhang2023meshattack} and Miao \etal~\cite{dong2022isometric} proposed directly attacking the mesh to generate smoother results.%, employing edge length regularization and Gaussian curvature regularization, respectively.
Tang \etal~\cite{tang2023manifold} proposed to adversarially stretch the latent variables in an auto-encoder, which can be decoded as smooth adversarial point clouds. %Lou \etal~\cite{lou2024hide} proposed a shape-based attack HiT-ADV, which conducts a two-stage search for attack regions based on saliency and imperceptibility scores, and then adds deformation perturbations in each attack region using Gaussian kernel functions. 
HiT-ADV~\cite{lou2024hide} is a shape-based attack, that first search attack regions based on saliency and imperceptibility scores, and then adds deformation perturbations in each attack region with Gaussian kernel. 
Besides, some works \cite{kim2021minimal,shi2022shape,dong2022isometric,tang2023manifold} attack point clouds in the feature space for imperceptible attack. While these methods eliminate outliers and ensure smoothness, they still require optimization for each point cloud, resulting in a high time cost.  To this end, universal attack~\cite{rampini2021universal,cheng2021universal} was proposed to compute universal perturbations for point clouds with specific patterns.

\noindent \textbf{Black-box attack on point cloud.}
The black-box attack can be further classified as transfer-based~\cite{hamdi2020advpc,liu2022imperceptible,huang2022siadv,liu2022boosting,zhang2024eidos,zhang2024improving,cai2024frequency} and boundary-based black-box attacks~\cite{tao20233dhacker,he2023generating,chen2024anf}. For point cloud, most works focus on transfer-based black-box attacks. AdvPC~\cite{hamdi2020advpc} leverages a point cloud auto-encoder to enhance the transferability of adversarial point clouds, while AOF~\cite{liu2022boosting} targets the low-frequency components of 3D point clouds to disrupt general features. SI-Adv~\cite{huang2022siadv} projects points onto a tangent plane and introduces perturbations to create shape-invariant point clouds. Eidos~\cite{zhang2024eidos} is a transfer-based attack that allows adversarial examples trained on one classifier to be transferred to another. 3DHacker~\cite{tao20233dhacker} generates adversarial samples using only black-box hard labels. PF-Attack~\cite{he2023generating} and ANF~\cite{chen2024anf} optimize perturbations and their subcomponents through adversarial noise factorization near decision boundaries, reducing dependency on surrogate models and enhancing transferability. SS-attack~\cite{zhang2024improving} applies random scaling or shearing to the input point cloud to prevent overfitting the white-box model, thus improving attack transferability. While these methods enhance model transferability, they still rely on iterative label-based generation of adversarial samples.

\noindent\textbf{No-box attacks.} The no-box approach is a classifier-free attack strategy that requires neither access to classifier details nor model queries. To date, only a few studies have addressed this challenging setup for images or skeletons. Li \etal~\cite{li2020practical} employed an autoencoding model to design an adversarial loss for no-box image attacks. Sun \etal~\cite{sun2022towards} used a small subset of the training set to train an auxiliary model, leveraging this model to generate adversarial examples and attack the target model. Lu \etal~\cite{lu2023hard} define an adversarial loss to maximize each adversary's dissimilarity with positive samples while minimizing its similarity with negative samples for the skeleton attack.
Zhang \etal~\cite{zhang2022practical} combined the low frequency of a clean image with the high frequency of a texture image to craft adversarial examples. Mou \etal~\cite{mou2024no} developed a decision-based attack strategy that generates universal adversarial perturbations and a set of texture-adversarial instances.
\iffalse
\noindent \textbf{Unsupervised 2D attacks.} Unsupervised attack~\cite{naseer2018task,zhao2019unsupervised,li2020practical,zhang2022unsupervised,yao2023unsupervised} refer to a type of attack method that does not rely on the category labels of samples. Naseer \etal~\cite{naseer2018task} used predictions of clear input images from a pre-trained classifier for supervision, eliminating the need for class labels. Yao \etal~\cite{yao2023unsupervised} employed the cycle consistency adversarial loss to achieve unsupervised attacks against object tracking models. %However, to our best knowledge, there has been no unsupervised attack in the 3D vision community so far, and directly adapting these 2D methods to the 3D field may face many challenges. 
A more typical unsupervised attack way is based on the no-box paradigm. Zhao \etal~\cite{zhao2019unsupervised} introduced an unsupervised adversarial image generation method with a generative adversarial network and deep feature-based loss. Li \etal~\cite{li2020practical} utilized an image-to-image auto-encoding model to devise an adversarial loss to achieve no-box image attacks.  Zhang \etal~\cite{zhang2022unsupervised} proposed the contrastive loss gradient attack, an unsupervised untargeted poisoning attack for attacking graph contrastive learning. 
While these methods enhance the transferability of 2D attacks, they cannot be directly applied to the 3D point cloud. To address this, we propose an unsupervised point cloud attack method called NoPain, which operates without requiring labels, thereby broadening the applicability of point cloud attacks.
\fi

\vspace{-1mm}
\noindent \textbf{Boundary-based attacks.}
Boundary-based attack method \cite{brendel2018decision} is widely used in the 2D field, which is an efficient framework that uses the final decision results to implement black-box attacks. In the 2D field, the decision boundary attack process starts with two origin images called 
source-image and target-image with different labels. Then, it performs a binary search to obtain a boundary image on the decision boundary. 
Various 2D decision boundary-based attacks are proposed based on this general attack framework. Thomas \etal~\cite{brunner2019guessing} and Vignesh \etal~\cite{srinivasan2019black} propose to
choose more efficient random perturbation including Perlin noise and DCT in random walking steps instead of Gaussian perturbation. Chen \etal~\cite{chen2020hopskipjumpattack} conduct a gradient estimation method using the Monte-Carlo sampling strategy instead of random perturbation. Thereafter, several works~\cite{li2020qeba,li2021nonlinear,li2022decision} improve the gradient estimation strategy through sampling from representative low-dimensional subspace. Recently, 
Tao \etal~\cite{tao20233dhacker} introduced boundary-based black-box attacks on point clouds, proposing 3DHacker, which leverages a developed decision boundary algorithm to attack point clouds using only black-box hard labels. He \etal~\cite{he2023generating} and Chen \etal~\cite{chen2024anf} jointly optimize two sub-perturbations near decision boundaries via adversarial noise factorization, enhancing transferability. %However, these three boundary-based point cloud attack methods are all optimization-based, requiring optimization for each adversarial sample with guidances of specific models, leading to a higher time cost and imperfect transferability.
However, these boundary-based point cloud attack methods require optimization for each adversarial sample using model-specific guidance, resulting in higher time costs and limited transferability.


\section{Methodology}
Here, we are committed to providing a no-box end-to-end point cloud attack by incorporating the optimal transport singular boundary. As illustrated in \cref{fig:framework}, our framework \textbf{NoPain} comprises three stages. Firstly, the input point clouds are embedded into the latent space, obtaining the feature vectors. Secondly, we obtain the singular boundaries of the point cloud data manifold by solving the OT mapping from noise to the features space, and then perturb the features by shifting them toward these boundaries. Finally, a pre-trained decoder was utilized to generate transferable adversarial point clouds in an end-to-end fashion. 

\noindent\textbf{Motivations.} 
Although existing point cloud attack methods have demonstrated high attack quality, they struggle to produce transferable adversarial samples~\cite{cai2024frequency,zhang2024improving,he2023generating}.%, as depicted in \cref{fig:qualitative}. 
This limitation stems from the tendency of optimization-based attacks to overfit specific parameters of surrogate networks. To address this, we shift our focus to the data itself, aiming to uncover the inherent characteristics of target data distribution. Notably, considering mode mixture at the singular boundary, we propose leveraging singular boundaries to achieve cross-network point cloud attacks.

Compared to existing point cloud attack methods, our approach offers several key advantages and fundamental distinctions: 1)~It eliminates the need for surrogate classifiers; 2)~It conducts attacks based on optimal transport singular boundaries, providing greater interpretability due to the explicit solution of the OT mapping; 3)~It operates without iterative optimization. %While traditional methods often target overfitting or insufficient generalization of classification models, our approach directly exploits the intrinsic characteristics of the data distribution.  
By leveraging the intrinsic characteristics of the data distribution, our method achieves no-box, end-to-end transferable point cloud attacks.

\subsection{Problem formulation}
\label{subsec:preliminary}
Given a point cloud dataset $\boldsymbol{\mathcal{P}} =\left\{\boldsymbol{P}_i\right\}_{i=1}^{N}$ with $N$ point cloud, our goal is to generate a set of adversarial point clouds $\boldsymbol{\mathcal{\widehat{P}}} =\left\{\boldsymbol{\widehat{P}}_i\right\}_{i=1}^{N}$ with sufficiently small perturbations (i.e., small $||\boldsymbol{\widehat{P}}_i - \boldsymbol{P}_i||$) such that $f(\boldsymbol{\widehat{P}}_i) \neq f(\boldsymbol{P}_i)$ for all $\boldsymbol{P}_i\in\boldsymbol{\mathcal{P}}$, where $f$ is a unknown classifier during the attack.

%To this end, we first embed the point cloud into the hidden space manifold using encoder $\mathbf{E}_\phi$, obtaining the corresponding feature $\boldsymbol{y} = \mathbf{E}_\phi(\boldsymbol{P})$. Next, we detect the local singular boundaries on the target data manifold and launch attacks based on these boundaries. %

To achieve this, we first embed the point cloud into a hidden space manifold using an encoder, $\mathbf{E}\phi$, resulting in the feature representation $\boldsymbol{y} = \mathbf{E}\phi(\boldsymbol{P})$. We then detect local singular boundaries on the target data manifold and launch attacks based on these boundaries. To identify these singular boundaries, we solve a semi-discrete OT mapping from a continuous noise space to discrete data points, forming a hyperplane defined by noise $\boldsymbol{X}$ and target data $\boldsymbol{Y}$. These hyperplanes enable us to determine singular boundaries within the data manifold effectively. In the following, we will introduce relevant OT theories to provide the foundation for subsequent method explanations.

\noindent\textbf{Semi-discrete Optimal Transport} 
Suppose the source measure $\mu$ defined on a convex domain $\Omega \subset \mathbb{R}^{d}$, the target domain is a discrete set $\boldsymbol{Y}=\left\{\boldsymbol{y}_{i}\right\}_{i=1}^{N}, \boldsymbol{y}_{i} \in \mathbb{R}^{d}$. The target measure is a Dirac measure $\nu=\sum_{i=1}^{N} \nu_{i} \delta\left(\boldsymbol{y}-\boldsymbol{y}_{i}\right)$ and the source measure is equal to total mass as $\mu(\Omega)=\sum_{i=1}^{N} \nu_{i} .$ Under a semi-discrete transport mapping $g: \Omega \rightarrow \boldsymbol{Y}$, a cell decomposition is induced $\Omega=\bigcup_{i=1}^{N} W_{i}$, such that every $\boldsymbol{x}$ in each cell $W_{i}$ is mapped to the target $\boldsymbol{y}_{i}, g: \boldsymbol{x} \in W_{i} \mapsto \boldsymbol{y}_{i}$. The mapping $g$ is measure preserving, denoted as $g_{\#} \mu=\nu$, if the $\mu$-volume of each cell $W_{i}$ equals to the $\nu$-measure of the image $g\left(W_{i}\right)=\boldsymbol{y}_{i}, \mu\left(W_{i}\right)=\nu_{i}$. The cost function is given by $c: \Omega \times \boldsymbol{Y} \rightarrow \mathbb{R}$, where $c(\boldsymbol{x}, \boldsymbol{y})$ represents the cost for transporting a unit mass from $\boldsymbol{x}$ to $\boldsymbol{y}$. The semi-discrete OT~(SDOT) mapping $g^{\ast}$ is a measure-preserving mapping that minimizes the total cost in Eq.~\eqref{eq:SDOT},
\begin{equation}
\vspace{-2mm}
g^{\ast}:=\arg \min _{g_{\#} \mu=\nu}\sum_{i=1}^{N} \int_{W_{i}} c(\boldsymbol{x}, g(\boldsymbol{x})) d \mu(\boldsymbol{x}).\label{eq:SDOT}
\end{equation}
\vspace{-2mm}

According to Brenier theorem~\cite{Brenier1991}, when the cost function $c(\boldsymbol{x}, \boldsymbol{y})=1 / 2\|\boldsymbol{x}-\boldsymbol{y}\|^{2}$, we have
$g^{*}(\boldsymbol{x})=\nabla \boldsymbol{u}(\boldsymbol{x}).$
This explains that the SDOT mapping is the gradient mapping of Brenier's potential $\boldsymbol{u}$. As~\cite{lei2020geometric,an2019ae} remark, $\boldsymbol{u}$ is the upper envelope of a collection of hyperplanes
\begin{equation}\label{eq:hyperplanes}
\pi_{\boldsymbol{h},i}(\boldsymbol{x}) =
% \boldsymbol{x}^T\boldsymbol{y}_i+h_i\, 
\langle\boldsymbol{y}_i, \boldsymbol{x} \rangle+h_i\,.
\end{equation}
Specifically, $\boldsymbol{u}$ can be parametrized uniquely up to an additive constant by the Brenier's height vector $\boldsymbol{h} = (h_1, h_2, ..., h_{N})^T$ and can be stated as follows,
\begin{equation}
\boldsymbol{u}_{\boldsymbol{h}}(\boldsymbol{x}) = \max_{i=1}^{N}\{\pi_{\boldsymbol{h},i}(\boldsymbol{x})\}, \boldsymbol{u}_{\boldsymbol{h}}: \Omega \rightarrow \mathbb{R}^n,\label{eq:uh}
\end{equation}

The way in which Brenier's potential $\boldsymbol{u}_{\boldsymbol{h}}$ maximizes the hyperplane induces the cell decomposition $\Omega=\bigcup_{i=1}^{N} W_{i}$ for $\boldsymbol{X}$, and also implicitly establishes the polygons decomposition on the target domain $\boldsymbol{Y}$. The edges of each polygon represent the boundaries between hyperplanes. Thus, the pertinent issue that needs to be considered next is how to solve the hyperplane set, i.e. the height vector $\boldsymbol{h}$.

\subsection{Hyperplane Set Solution}
\begin{algorithm}[tb]
   \caption{OT Solver for Hyperplane Set}
   \label{alg:OTMap}
\begin{algorithmic}[1]
   \REQUIRE  Dataset $\boldsymbol{Y}=\left\{\boldsymbol{y}_i\right\}_{i=1}^{N}$, initial noise sample number $M$, learning rate $lr$, threshold $\eta$, positive integer $s$.
   \STATE Initialize $\boldsymbol{h}=(h_1,h_2,\cdots,h_{N})\leftarrow(0,0,\cdots,0)$.
   \REPEAT
    \STATE Sample $M$ noise samples $\boldsymbol{X} = \left\{\boldsymbol{x}_j\sim \mathcal{N}(0,I)\right\}_{j=1}^M$
    \STATE $w(\boldsymbol{h}) = (0,0,\cdots,0)$. 
    %\STATE $\pi_{\boldsymbol{h},i}(\boldsymbol{x})$ is calculated by Eq.\eqref{eq:hyperplanes} $\forall$ $\boldsymbol{x}_j$, $\boldsymbol{{y}_i}\in\boldsymbol{Y}$.
    \FOR{ $j=0;j < M$} 
    %\STATE  Calculate the index of the maximum $\pi_{\boldsymbol{h},i}(\boldsymbol{x}_j)$ for $\boldsymbol{x}_j$, $index= k$ if $\max\{\pi_{\boldsymbol{h},i}\}_{i=1}^{N}==\pi_{\boldsymbol{h},k}$.
    \STATE  $k=\arg\max _{i\in\{1,\cdots,N\}} \pi_{\boldsymbol{h},i}(\boldsymbol{x}_j)$ with Eq.\eqref{eq:hyperplanes}.
    % \STATE $w_k(\boldsymbol{h})\leftarrow w_k(\boldsymbol{h})+1$
    \STATE $w(\boldsymbol{h})[k]\leftarrow w(\boldsymbol{h})[k]+1$. \COMMENT{\textcolor{blue}{[k] indicates the indexing operation}}
    \STATE  $j\leftarrow j+1$.
    \ENDFOR
    \STATE $w(\boldsymbol{h})\leftarrow \frac{w(\boldsymbol{h})}{M}$.
    \STATE Calculate $\nabla \boldsymbol{h}\leftarrow(w(\boldsymbol{h})-\frac{1}{N} )^T$.
    \STATE $\nabla \boldsymbol{h}\leftarrow\nabla \boldsymbol{h}-\text{mean}(\nabla \boldsymbol{h})$.
    \STATE Update $\boldsymbol{h}$ by Adam algorithm.% with $\beta_1=0.9$,$\beta_2=0.5$.
    %\STATE Calculate $ E(\boldsymbol{h})$ by Eq.~\eqref{eq:EH}
    \IF{$ E(\boldsymbol{h})$ in Eq.~\eqref{eq:EH} has not decreased for $s$ steps}
    \STATE $M\leftarrow 2\times M$; $lr\leftarrow 0.8\times lr$\,.
    \ENDIF
   \UNTIL{$E(\boldsymbol{h})<\eta$}
   %\STATE OT mapping $g(\cdot)\leftarrow \nabla(\max_{i}\{\langle \boldsymbol{x}_T,\boldsymbol{y}_i\rangle_F  + h_i\})$.
   \STATE {\bf Return} Brenier's height vector $\boldsymbol{h} = (h_1, h_2, ..., h_{N})$.
\end{algorithmic}
\end{algorithm}
\noindent Given the Target dataset $\boldsymbol{Y}=\left\{\boldsymbol{y}_i\right\}_{i=1}^{N}$ with target measure $\nu$, there exists Brenier's potential $\boldsymbol{u}_{\boldsymbol{h}}$ in Eq.~\eqref{eq:uh} whose projected volume of each support plane is equal to the given target measure $\nu_i$\cite{Brenier1991,an2019ae}. 
To obtain adversarial samples for all point clouds in the dataset, we set the target measure to a uniform distribution, i.e. $\nu_i=\frac{1}{N},\ \forall i=1,\cdots,N$. Then, we can get the optimal $\boldsymbol{h}$ and $\boldsymbol{u}_{\boldsymbol{h}}$ by minimizing the following convex energy function:%\sum_{i=1}^{N}
\begin{equation}
E(\boldsymbol{h})=\sum_{i=1}^{N}( w_{i}(\boldsymbol{h}) -\frac{1}{N})^2,
\label{eq:EH}
\end{equation}
where $\omega_{i}(\boldsymbol{h})$ is the $\mu$-volume of $W_{i}(\boldsymbol{h})$, i.e., the frequency of $\boldsymbol{x}$ assigned to $\boldsymbol{y}_i$. The energy $E(\boldsymbol{h})$ provides the optimization direction for $\boldsymbol{h}$, and its gradient $\nabla \boldsymbol{h}$ is given by
\begin{equation}
\nabla \boldsymbol{h}=(w(\boldsymbol{h})-\frac{1}{N} )^T\,.
\label{eq:gradient}
\end{equation}
Then, we optimize $\boldsymbol{h}$ using the Adam optimization algorithm~\cite{adam2014}. To ensure a unique solution, we adjust $\nabla \boldsymbol{h}$ to have zero mean by setting $\nabla \boldsymbol{h} = \nabla \boldsymbol{h} - \text{mean}(\nabla \boldsymbol{h})$. 

After obtaining $\boldsymbol{h}$, we directly substitute it into Eq.~\eqref{eq:hyperplanes} to obtain the hyperplane set $\{\pi_{\boldsymbol{h},i}(\boldsymbol{x})|\pi_{\boldsymbol{h},i}(\boldsymbol{x}) =\langle\boldsymbol{y}_{i}, \boldsymbol{x}\rangle+h_i,$ $i=1,\cdots,N\}$. The algorithm is detailed in Algorithm~\ref{alg:OTMap}.

\begin{algorithm}[tb]
   \caption{Point Cloud Attack: \textbf{NoPain}}
   \label{alg:ot-attack}
    \begin{algorithmic}[1]
   \REQUIRE Target dataset $\boldsymbol{\mathcal{P}} =\left\{\boldsymbol{P}_i\right\}_{i=1}^{N}$, a well-trained encoder $\mathbf{E}_\phi$ and decoder $\mathbf{D}_\varphi$, the number of neighbors $K$ in Eq.~\eqref{eq:theta}, threshold $\tau$.
   \ENSURE Generated adversarial samples $\boldsymbol{\mathcal{\widehat{P}}} =\left\{\boldsymbol{\widehat{P}}_i\right\}_{i=1}^{N}$.
   \STATE Embedding $\boldsymbol{\mathcal{P}}$ into latent space with encoders $\mathbf{E}_\phi$, $\boldsymbol{Y}=\left\{\boldsymbol{y}_i|\boldsymbol{y}_i=\mathbf{E}_\phi(\boldsymbol{P}_i),\  i=1,2,\cdots,N\right\}$.
   \STATE The Brenier's height vector $\boldsymbol{h} = (h_1, h_2, ..., h_{N})$ obtained by Algorithm~\ref{alg:OTMap}.
   \STATE Sample $M$ noise samples $\left\{\boldsymbol{x}_j\sim \mathcal{N}(0,I)\right\}_{j=1}^N$.
   \STATE Calculate the hyperplane set $\left\{\boldsymbol{\pi}_{i,j}|\boldsymbol{\pi}_{i,j}=\boldsymbol{x}_j^T\boldsymbol{y}_i+h_i\right\}$ by Eq.~\eqref{eq:hyperplanes}.
   \STATE Calculate dihedral angles $\boldsymbol{\Theta}=\left\{\theta_{i,k}\right\}$ between hyperplanes by Eq.~\eqref{eq:theta}.
   \STATE Obtain point pairs $\left\{(\boldsymbol{y}_{i_0},\boldsymbol{y}_{i_k})\right\}_{i_0=1}^N$ by checking $\boldsymbol{\Theta}$ with threshold $\tau$.
   \STATE Calculate adversarial features $\boldsymbol{\widehat{Y}}=\left\{\boldsymbol{\widehat{y}}_i\right\}_{i=1}^{N}$ by Eq.~\eqref{eq:interplatation}
   \STATE Decode features $\boldsymbol{\widehat{Y}}$ to obtain adversarial samples $\boldsymbol{\mathcal{\widehat{P}}} =\left\{\boldsymbol{\widehat{P}}_i|\boldsymbol{\widehat{P}}_i=\mathbf{D}_{\varphi}(\boldsymbol{\widehat{y}}_i),\  i=1,2,\cdots,N\right\}$.
   \STATE {\bf Return} $\boldsymbol{\mathcal{\widehat{P}}}$
\end{algorithmic}
\end{algorithm}


\vspace{-2mm}
\subsection{Singular Boundary Determination} \label{sec:singbound}
According to Figalli's theory~\cite{figalli2010regularity, chen2017partial}, when there are multiple modes or the support of the target distribution is concave, singular boundary can emerge. In these regions, the Brenier potential $\boldsymbol{u}_{\boldsymbol{h}}$ is continuous but not differentiable, resulting in a discontinuous gradient map, i.e., the transport map. This indicates that if we extend the OT mapping in these areas, we will generate samples that belong to mixed categories, effectively producing adversarial samples.

The original point cloud requires an abundance of points to represent a single data instance, resulting in high dimensionality~($N\times3$) that complicates the detection of data singular boundaries. To address this, we first embed the point set into a latent representation $\boldsymbol{y}=\mathbf{E}_\phi(\boldsymbol{P})$ on manifold with encoder $\mathbf{E}_\phi$. Next, the core challenge we aim to solve is identifying the discontinuity regions in the OT mapping, which correspond to the singular boundaries.

%Given the OT mapping $T(\cdot)$ solved by SDOT~\cite{an2019ae}, 
Given the OT mapping $T(\cdot)$ solved by  Algorithm~\ref{alg:OTMap}, we can tessellate the data manifold represented by features $\boldsymbol{Y}=\left\{\boldsymbol{y}_i\right\}_{i=1}^{N}$ into $N$ polygons~(illustrated in \cref{fig:illustration}). From a local perspective, each hyperplane $\pi_{\boldsymbol{h},i}$ has boundaries with its neighboring hyperplanes, particularly at the intersections of the two hyperplanes. Some pairs of polygons fall into different categories or exhibit significant normal inconsistencies, indicating that their boundary is singular. Specifically, given $\boldsymbol{y}_i$ from the target domain, we can detect the singular boundaries between it and its neighbors by checking the angles $\theta_{i_k}$ between hyperplane $\pi_{i}$ and $\pi_{i_k}$ with 
\begin{equation}\label{eq:theta}
\theta_{i_k}=\frac{\langle\boldsymbol{y}_{i},\boldsymbol{y}_{i_k}\rangle}{||\boldsymbol{y}_{i}||\cdot||\boldsymbol{y}_{i_k}||},\  k=1,2,\cdots,K. 
\end{equation}
Here, $i_k$ is the index corresponding to the $k$-th neighbor $\boldsymbol{y}_{i_k}$ of $\boldsymbol{y}_i$ which is determined by hyperplane set $\{\pi_{\boldsymbol{h},i}\}$ with 
\begin{equation}
\label{eq:neighbor}
\begin{split}
&\pi_{\boldsymbol{h},i_k}(\boldsymbol{x})\leq\pi_{\boldsymbol{h},i_{k-1}}(\boldsymbol{x})\leq\cdots\leq\pi_{\boldsymbol{h},i_0}(\boldsymbol{x})\leq\pi_{\boldsymbol{h},i}(\boldsymbol{x})\\
&\pi_{\boldsymbol{h},i_k}(\boldsymbol{x})\geq\pi_{\boldsymbol{h},i_{k+1}}(\boldsymbol{x})\geq\cdots\geq\pi_{\boldsymbol{h},i_{N-K-1}}(\boldsymbol{x}).\\
\end{split}
\end{equation}
That is to say, $i_k$ is the index corresponding to the $(k+1)$-th largest hyperplane in $\{\pi_{\boldsymbol{h},i}(\boldsymbol{x})\}^N_{i=1}$ under a random $\boldsymbol{x}$ from $W_{i}$. If there is any angle $\theta_{i_k}$ larger than the given threshold $\tau$, we say $\boldsymbol{x}$ belongs to the singular set, and there is a local singular boundary between $\boldsymbol{y}_{i}$ and  $\boldsymbol{y}_{i_k}$ (solid and dashed red lines in \cref{fig:illustration}). 





\begin{table*}[htbp!]
\centering
\renewcommand{\tabcolsep}{0.98mm}
\caption{Comparison results of ASR (\%) for different attack methods with the PointNet++ as the surrogate model to other unknown models.}
\vspace{-3mm}
\scalebox{0.8}{
\begin{tabular}{@{}c|cccc|c|cccc|c@{}}
\toprule
& \multicolumn{5}{c|}{ModelNet40}    & \multicolumn{5}{c}{ShapeNet Part}  \\ 
\midrule
\multirow{2}{*}{Method}  & \multicolumn{4}{c|}{ASR~(\%)$\uparrow$ /\ CD$\downarrow$}  & \multirow{2}{*}{AGT(s)$\downarrow$}  &  \multicolumn{4}{c|}{ASR~(\%)$\uparrow$\ /\ CD$\downarrow$}  & \multirow{2}{*}{AGT(s)$\downarrow$} \\ 
& PointNet  &PointConv &  DGCNN  & PCT &     & PointNet &PointConv & DGCNN & PCT &  \\ 
\midrule
AdvPC~\cite{hamdi2020advpc} & 13.0/0.0005& 30.0/0.0014 & 23.3/0.0011 &  15.8/0.0011 &6.2  & 5.0/0.0024  & 22.5/0.0062&5.7/0.0038 & 6.0/0.0039&  15.8\\
AOF~\cite{liu2022boosting}& 13.7/0.0013& 39.7/0.0035 & 28.1/0.0029 & 18.6/0.0032& 12.5 & 14.6/0.0048& 33.4/0.0063 & 20.1/0.0058& 18.4/0.0058&14.4\\
SI-ADV~\cite{huang2022siadv}  &54.5/0.0022& 69.5/0.0024 &67.3/0.0022 &\textbf{91.3}/0.0026 & 8.9  &19.1/0.0023 &\textbf{77.2}/0.0040 & 18.9/0.0025 &26.9/0.0033&11.4\\
SS-attack~\cite{zhang2024improving} & 15.7/0.0021&44.4/0.0039 &32.0/0.0034 &23.5/0.0038 & 51.5  & 13.0/0.0055  & 43.4/0.0081 & 16.4/0.0065& 22.1/0.0066&43.1\\
HiT-ADV~\cite{lou2024hide}&50.2/0.0330 & 15.0/0.0112&22.3/0.0301 & 9.2/0.0063 &7.5 & 32.4/0.1545 & 7.0/0.0680& 28.7/0.1626& 17.2/0.1890& 25.9\\
NoPain-PF~(ours) &\underline{97.7}/0.0023 &  \underline{72.2}/0.0032&  \underline{88.6}/0.0028& 81.7/0.0029 & \underline{0.028}&\underline{65.2}/0.0022 & 62.5/ 0.0032 & \underline{61.8}/0.0025 & \textbf{60.0}/ 0.0024&\textbf{0.019} \\
NoPain-PD~(ours) & \textbf{100}/0.0022 & \textbf{82.8}/ 0.0024&\textbf{88.7}/ 0.0025 & \underline{85.7}/ 0.0027 & \textbf{0.026} & \textbf{71.1}/ 0.0021 & \underline{63.3}/ 0.0030 & \textbf{75.0}/ 0.0029 & \underline{53.3}/ 0.0046 &\underline{0.032} \\ \bottomrule
\end{tabular}}
\label{tab:transferability}
\end{table*}

\iffalse
\begin{table*}[htbp!]
\centering
\renewcommand{\tabcolsep}{0.98mm}
\caption{Comparison results of TSR (\%) for different attack methods with the PointNet++ as the surrogate model to other unknown models.}
\scalebox{0.8}{
\begin{tabular}{@{}c|cccc|cc|cccc|cc@{}}
\toprule
& \multicolumn{6}{c|}{ModelNet40}    & \multicolumn{6}{c}{ShapeNet Part}  \\ 
\midrule
\multirow{2}{*}{Method}  & \multicolumn{4}{c|}{TSR~(\%)$\uparrow$ /\ CD$\downarrow$} & \multirow{2}{*}{CD$\downarrow$} & \multirow{2}{*}{AGT$\downarrow$}  &  \multicolumn{4}{c|}{TSR~(\%)$\uparrow$\ /\ CD$\downarrow$} & \multirow{2}{*}{CD$\downarrow$} & \multirow{2}{*}{AGT$\downarrow$} \\ 
& PointNet  &PointConv &  DGCNN  & PCT &   &   & PointNet &PointConv & DGCNN & PCT & & \\ 
\midrule
AdvPC~\cite{hamdi2020advpc} & \textbf13.0/0.0005& 30.0/0.0014 & 23.3/0.0011 &  15.8/0.0011 &0.0013 &6.2   & 5.0/0.0024  & 22.5/0.0062&5.7/0.0038 & 6.0/0.0039&15.8 
AOF~\cite{liu2022boosting}& 13.7/0.0013& 39.7/0.0035 & 28.1/0.0029 & 18.6/0.0032& 0.0028&12.5 & 14.6/0.0048& 33.4/0.0063 & 20.1/0.0058& 18.4/0.0058&0.0067\\
SI-ADV~\cite{huang2022siadv}  &54.5/0.0022& 83.5/0.0023 &67.3/0.0022 &91.9/0.0023 &0.0051 &8.9  &19.1/0.0023 &77.2/0.0040 & 18.9/0.0025 &26.9/0.0033&0.0036\\
%3DHacker~\cite{tao20233dhacker}  &95.4 & & 76.8& & & &  & & & & \\
%PF-Attack~\cite{he2023generating} &67.4 &46.1 & 39.0& 33.3& &132.5 &  & & & & \\
%ANF~\cite{chen2024anf}&81.4 & 85.42 &82.94 & 86.81&  &781.8 &  &  & & & \\
SS-attack~\cite{zhang2024improving} & 15.7/0.0021&44.4/0.0039 &32.0/0.0034 &23.5/0.0038 & 0.0029 & 51.5  & 13.0/0.0055  & 43.4/0.0081 & 16.4/0.0065& 22.1/0.0066&0.0068\\
HiT-ADV~\cite{lou2024hide}&50.2/0.0330 & 15.0/0.0112&22.3/0.0301 & 9.2/0.0063&0.0227 &7.5 & 30.4 & 10.7& 16.2& 17.3&0.1195 \\
NoPain-PF~(ours) &{97.7/0.0023} &  {72.2/0.0032}&  {88.6/0.0028}& {81.7/0.0029} &0.0030 & 0.028&65.2/0.0022 & 47.2/0.0025 & 61.8/0.0025 & \textbf{60.0/ 0.0024}&\textbf{0.0024}&{0.019} \\
NoPain-PD~(ours) & \textbf{100/0.0022} & \textbf{82.8/ 0.0024}&\textbf{88.7/ 0.0025} & \textbf{85.7/ 0.0027} & \textbf{0.0024} & \textbf{0.026} & \textbf{71.1/ 0.0021} & \textbf{55.6/ 0.0028} & \textbf{75.0/ 0.0029} & 53.3/ 0.0046 & 0.0033&0.032 \\ \bottomrule
\end{tabular}}
%\vspace{-3mm}
\label{tab:transferability}
\end{table*}
\fi

\iffalse
\begin{table*}[htbp!]
\caption{Comparison results of ASR (\%) for different attack methods on models with and without applied defense methods.}
\vspace{-3mm}
\centering
\scalebox{0.8}{
\begin{tabular}{@{}c|ccccc|ccccc@{}}
\toprule
& \multicolumn{5}{c|}{PointNet}    & \multicolumn{5}{c}{DGCNN}  \\ \midrule
Method  & CD & SRS & SOR & DUP-Net &  IF-Defense  &  CD & SRS & SOR & DUP-Net &  IF-Defense \\ \midrule
AdvPC~\cite{hamdi2020advpc} &0.0005& 89.5 &  34.5 & 18.5 & 15.1  & 0.0021&63.5 & 64.5& 67.5&20.8 \\
AOF~\cite{liu2022boosting}& \textbf0.0028 & 94.0 
& 88.5& 70.5&53.7 & 0.0023 & 52.0 & 68.0& 72.0& 29.7\\
SI-ADV~\cite{huang2022siadv} & 0.0010& 86.5 & 32.5 & 34.5& 42.7  &0.0034& \textbf{87.5}& 68.0& 85.0& 48.4\\
%3DHacker~\cite{tao20233dhacker} & & & & & &  & & & & \\
%PF-Attack~\cite{he2023generating} & & & & & &  & & & & \\
%ANF~\cite{chen2024anf}&  & & &  & &  &  & & & \\
SS-attack~\cite{zhang2024improving} & 0.0023 &94.5&\textbf{89.5} &72.5 &  64.1 & 0.0035  & 71.0 &\textbf{77.5} &\textbf{76.5} &41.2\\
HiT-ADV~\cite{lou2024hide}&  0.1085& 90.5& 86.0&  \textbf{84.5}& 16.2 &  0.1315&  49.0& 58.5& 33.5&17.2 \\
NoPain-PF~(ours) &0.0037 & \textbf{96.3} & 66.5 & 77.2 & 66.3 &0.0034 &82.1 & 55.0& 69.7 &50.8   \\
NoPain-PD~(ours) & 0.0038& 90.2& 60.3& 58.6& \textbf{68.0}&0.0034& 77.7& 47.2& 71.0&\textbf{52.4}  \\ \bottomrule
\end{tabular}
}
\label{tab:defend}
\end{table*}
\fi


\begin{table*}[htbp!]
%\caption{Comparison results of ASR (\%) for different attack methods on PointNet and DGCNN with applied defense methods.}
\caption{Comparison results of ASR (\%) for different attack methods to defense strategies of SRS, SOR, DUP-Net, and IF-Defense.}
\vspace{-3mm}
\centering
\scalebox{0.8}{
\begin{tabular}{@{}c|cccc|cccc@{}}
\toprule
& \multicolumn{4}{c|}{ASR~(\%)$\uparrow$ /\ CD$\downarrow$ ~~~on~ PointNet}    & \multicolumn{4}{c}{ASR~(\%)$\uparrow$ /\ CD$\downarrow$ ~~~on~ DGCNN}  \\ \midrule
Method  & SRS & SOR & DUP-Net &  IF-Defense & SRS & SOR & DUP-Net &  IF-Defense \\ \midrule
AdvPC~\cite{hamdi2020advpc} & 89.5/0.0005 &  34.5/0.0003 & 18.5/0.0003 & 19.3/0.00394  & 63.5/0.0013 & 64.50.0015& 67.5/0.0013&20.8/0.0040 \\
AOF~\cite{liu2022boosting} & 94.0/0.0021
& 88.5/0.0021& 70.5/0.0022&63.7/0.0056  & 52.0/0.0038 & 68.0/0.0026& 70.0/0.0025& 34.1/0.0061\\
SI-ADV~\cite{huang2022siadv} & 86.5/0.0027 & 32.5/0.0029 & 34.5/0.0030& 42.7/0.0040  & \underline{87.5}/0.0034& 68.0/0.0033/& \underline{82.6}/0.0035& 48.4/0.0049\\
SS-attack~\cite{zhang2024improving}  &94.5/0.0023&{89.5}/0.0023 &72.5/0.0025 &  66.1/0.0056  & 71.0/0.0031 &63.5/0.0027 &73.5/0.0023 &41.2/0.0056\\
HiT-ADV~\cite{lou2024hide}& 90.5/0.0736& 86.0/0.0805&  \underline{84.5}/0.0896& 16.2/0.0546 &  55.0/0.1212& 67.5/0.1164& \textbf{87.5}/0.1180&17.2/0.0544 \\
NoPain-PF~(ours) & \underline{97.6}/0.0029 & \underline{90.5}/0.0032 & 83.9/0.0027 & \underline{66.3}/0.0035  &{86.4}/0.0027 & \underline{78.9}/0.0030& 69.7/0.0028 &\underline{50.8}/0.0039   \\
NoPain-PD~(ours) & \textbf{98.4}/0.0021& \textbf{90.7}/0.0024& \textbf{85.0}/0.0028& \textbf{70.0}/0.0033& \textbf{87.9}/0.0026& \textbf{82.8}/0.0028& 74.2/0.0029&\textbf{52.4}/0.0038  \\ \bottomrule
\end{tabular}
}
\label{tab:defend}
\end{table*}


\subsection{Attack with OT Singular Boundary} \label{sec:sampling}
While we can detect singular boundaries, explicitly and accurately calculating them in discrete situations is often intractable or even impossible. Therefore, we extend the semi-discrete OT mapping to obtain the adversarial feature $\boldsymbol{\widehat{y}}$ through the following equation:
%After obtaining the local singular boundary, we can generate adversarial features $\boldsymbol{\widehat{y}}$ by  
\begin{equation}\label{eq:interplatation}
\boldsymbol{\widehat{y}}=\tilde{T}(\boldsymbol{x})=\lambda_iT(\boldsymbol{c}_{i})+\lambda_{i_k}T(\boldsymbol{c}_{i_k})=\lambda_i\boldsymbol{y}_{i}+\lambda_{i_k}\boldsymbol{y}_{i_k}.
\end{equation}
Where the $\mu$-mass center $\boldsymbol{c}_{j}$ is approximated by the mean value of all the Monte-Carlo samples inside $W_{j}$, $\lambda_j=d^{-1}(\boldsymbol{x},\boldsymbol{c}_{j})/(d^{-1}(\boldsymbol{x},\boldsymbol{c}_{i})+d^{-1}(\boldsymbol{x},\boldsymbol{c}_{i_k}))$, $j=i,i_k$. $d^{-1}(\boldsymbol{x},\boldsymbol{c}_{j})$ is the reciprocal of the distance between $\boldsymbol{x}$ and $\boldsymbol{c}_{j}$. $\boldsymbol{x}$ is a random $\boldsymbol{x}$ from $W_{i}$, $\tilde{T}(\cdot)$ is a smoothed extension of the semi-discrete OT mapping $T(\cdot)$, which smooths in regions where latent codes are dense.

Next, we leverage the pre-trained decoder $\mathbf{D}_\varphi$ to generate adversarial samples, denoted as $\boldsymbol{\widehat{P}}=\mathbf{D}_{\varphi}(\boldsymbol{\widehat{y}})$.
The complete attack process is outlined in Algorithm~\ref{alg:ot-attack}. 


Thanks to the data manifold decomposition and singular boundary computation, we can efficiently generate adversarial samples using \cref{eq:interplatation} without iterative optimization. Furthermore, our method does not rely on any information from classification models; instead, it directly targets the intrinsic singular boundaries of the data. The adversarial samples generated by sampling within the boundary region exhibit certain unnatural characteristics, which hinder the classification model trained on the original dataset from accurately recognizing them, thereby resulting in cross-network transferability. Additionally, the OT mapping $\tilde{T}(\cdot)$ in \cref{eq:interplatation} is defined by an explicit function, offering geometric intuitiveness and enhancing interpretability.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}

\subsection{Setup}
\textbf{Dataset. } Following the previous state-of-the-art point cloud attack algorithm \cite{tao20233dhacker,lou2024hide,zhang2024improving}, the experiments in this paper are performed on the ModelNet40~\cite{wu20153dshapenets} and ShapeNetPart~\cite{chang2015shapenet}. % as well as the real-world dataset KITTI~\cite{geiger2012we} and NuScenes~\cite{caesar2020nuscenes}. 
ModelNet40 consists of 12,311 CAD models from 40 categories, of which 9,843 models are intended for training and the other 2,468 for testing. ShapeNetPart consists of 16,881 shapes from 16 categories, split into 12,137 for training and 2,874 for testing. 

\textbf{Baseline attack methods.}
We compare our method with four state-of-the-art attack techniques, including three black-box methods: AdvPC~\cite{hamdi2020advpc}, AOF~\cite{liu2022boosting}, SI-Adv~\cite{huang2022siadv}, and SS-attack~\cite{zhang2024improving}, as well as the white-box method HiT-ADV~\cite{lou2024hide}. We conduct tests using the default settings, official implementations, and pre-training models for all baseline methods for a fair comparison.
Specifically, AdvPC~\cite{hamdi2020advpc} uses an autoencoder to improve transferability. AOF~\cite{liu2022boosting} attacks the more general features of point clouds, thereby improving the transferability of 3D adversarial samples. SI-Adv~\cite{huang2022siadv} introduces perturbations to create shape-invariant point clouds by tangent plane projection. %3DHacker~\cite{tao20233dhacker} is a boundary-based black-box method. PF-Attack~\cite{he2023generating} and ANF~\cite{chen2024anf} optimize perturbations through adversarial noise factorization near decision boundaries. 
SS-attack~\cite{zhang2024improving} applies random scaling or shearing to the input point cloud to prevent overfitting the white-box model. HiT-ADV~\cite{lou2024hide} is a shape-based attack method, that conducts a two-stage search for attack regions based on saliency and imperceptibility scores,
and then adds deformation perturbations in each region using Gaussian kernel functions.

\textbf{Baseline classification models.}
For a fair comparison with baselines, we adopt the same classifiers as AOF and SS-attack, including PointNet~\cite{qi2017pointnet}, PointNet++~\cite{qi2017pointnet++}, DGCNN~\cite{wang2019dynamic}, PointConv~\cite{wu2019pointconv}, and PCT~\cite{guo2021pct}. For the ModelNet40 dataset, we used the pre-trained classification models provided by SS-attack directly for metric evaluation. In contrast, since no pre-trained models were available for the ShapeNetPart dataset, we retrained the classifiers ourselves, achieving final accuracies exceeding 95\% across all models.


\iffalse
\begin{figure*}[htb!]
\vspace{-2mm}
\begin{center}
%{p{2mm}p{33mm}p{20mm}p{20mm}p{20mm}p{25mm}p{25mm}}
$\begin{array}{@{}lc@{}c@{}c@{}c@{}c@{}c}
\hspace*{0mm}\rotatebox{90}{\large \texttt{~~clean}} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=550 200 1400 800,clip]{figures/qual/guitar/1130_clean_guitar.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1050,clip]{figures/qual/cup/11_21_clean_cup.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=600 0 1400 950,clip]{figures/qual/lamp/37_26_clean_lamp.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=510 250 1400 800,clip]{figures/qual/sp-airplane/clean-airplane.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1000,clip]{figures/qual/sp-cap/clean-cap.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=450 150 1450 950,clip]{figures/qual/sp-chair/clean-chair.png}
\end{array}$
%\iffalse
$\begin{array}{@{}lc@{}c@{}c@{}c@{}c@{}c}
\hspace*{0mm}\rotatebox{90}{\large \texttt{~AdvPC}} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=550 200 1400 800,clip]{figures/qual/guitar/advpc-adv-guitar.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1050,clip]{figures/qual/cup/advpc-adv-cup.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=600 0 1400 950,clip]{figures/qual/lamp/advpc-adv-lamp.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=510 250 1400 800,clip]{figures/qual/sp-airplane/advpc-adv-airplane.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1000,clip]{figures/qual/sp-cap/advpc-adv-cap.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=450 150 1450 950,clip]{figures/qual/sp-chair/advpc-adv-chair.obj_00.png}
\end{array}$
%{p{33mm}p{20mm}p{20mm}p{20mm}p{25mm}p{25mm}}
%
$\begin{array}{p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}}
\hspace*{9mm}\textcolor{OliveGreen}{\faGuitar}/\textcolor{OrangeRed}{\faPlane}/\textcolor{OliveGreen}{\faGuitar}/\textcolor{OliveGreen}{\faGuitar}/\textcolor{OliveGreen}{\faGuitar}
&\hspace*{7mm}\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OliveGreen}{\faBeer}
&\hspace*{3mm}\textcolor{OrangeRed}{\faChair}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTable}/\textcolor{OliveGreen}{\hspace{-3pt}\raisebox{-0.07cm}{\fcTableLight{0.022}{OliveGreen}{1}}}/\textcolor{OrangeRed}{\faTree}
&\textcolor{OliveGreen}{\faPlane}/\textcolor{OrangeRed}{\faMotorcycle}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane}
&\hspace*{2mm}\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide}
&\hspace*{2mm}\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OliveGreen}{\faChair}/\textcolor{OrangeRed}{\faTable} 
\end{array}$
%\iffalse
$\begin{array}{@{}lc@{}c@{}c@{}c@{}c@{}c}
\hspace*{0mm}\rotatebox{90}{\large \texttt{~~~AOF}} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=550 200 1400 800,clip]{figures/qual/guitar/aof-adv-guitar.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1050,clip]{figures/qual/cup/aof-adv-cup.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=600 0 1400 950,clip]{figures/qual/lamp/aof-adv-lamp.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=510 250 1400 800,clip]{figures/qual/sp-airplane/aof-adv-airplane.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1000,clip]{figures/qual/sp-cap/aof-adv-cap.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=450 150 1450 950,clip]{figures/qual/sp-chair/aof-adv-chair.obj_00.png}
\end{array}$
$\begin{array}
{p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}}
\hspace*{9mm}\textcolor{OliveGreen}{\faGuitar}/\textcolor{OrangeRed}{\faKeyboard}/\textcolor{OrangeRed}{\usym{1F3B9}}/\textcolor{OliveGreen}{\faGuitar}/\textcolor{OliveGreen}{\faGuitar}
&\hspace*{7mm}\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\pot}/\textcolor{OrangeRed}{\faWineBottle}
&\hspace*{3mm}\textcolor{OrangeRed}{\faChair}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTable}/\textcolor{OliveGreen}{\hspace{-3pt}\raisebox{-0.07cm}{\fcTableLight{0.022}{OliveGreen}{1}}}/\textcolor{OliveGreen}{\hspace{-3pt}\raisebox{-0.07cm}{\fcTableLight{0.022}{OliveGreen}{1}}}
&\textcolor{OliveGreen}{\faPlane}/\textcolor{OrangeRed}{\faMotorcycle}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane}
&\hspace*{2mm}\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide}
&\hspace*{2mm}\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OliveGreen}{\faChair}/\textcolor{OrangeRed}{\faTable} 
\end{array}$

$\begin{array}{@{}lc@{}c@{}c@{}c@{}c@{}c}
\hspace*{0mm}\rotatebox{90}{\large \texttt{~SI-Adv}} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=550 200 1400 800,clip]{figures/qual/guitar/siadv-adv-guitar.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1050,clip]{figures/qual/cup/siadv-adv-cup.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=600 0 1400 950,clip]{figures/qual/lamp/siadv-adv-lamp.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=510 250 1400 800,clip]{figures/qual/sp-airplane/siadv-adv-airplane.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1000,clip]{figures/qual/sp-cap/siadv-adv-cap.obj_00.png} 
%&\hspace*{0mm}\includegraphics[height=23mm,bb=520 170 1280 1030,clip]{figures/qual/sp-cap/siadv-adv-cap.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=450 150 1450 950,clip]{figures/qual/sp-chair/siadv-adv-chair.obj_00.png}
\end{array}$
$\begin{array}
{p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}}
\hspace*{10mm}\textcolor{OrangeRed}{\faPlane}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\usym{1F3B9}}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTree}
&\hspace*{8mm}\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\pot}/\textcolor{OrangeRed}{\faTree}
&\hspace*{4mm}\textcolor{OliveGreen}{\hspace{-3pt}\raisebox{-0.07cm}{\fcTableLight{0.022}{OliveGreen}{1}}}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTree}
&\textcolor{OliveGreen}{\faPlane}/\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}/\textcolor{OrangeRed}{\faMotorcycle}/\textcolor{OrangeRed}{\faMotorcycle}/\textcolor{OliveGreen}{\faPlane} 
&\hspace*{1mm}\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide} 
&\hspace*{2mm}\textcolor{OliveGreen}{\faChair}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable} 
\end{array}$

$\begin{array}{@{}lc@{}c@{}c@{}c@{}c@{}c}
\hspace*{0mm}\rotatebox{90}{\large \texttt{SS-attack}} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=550 200 1400 800,clip]{figures/qual/guitar/ssaof-adv-guitar.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1050,clip]{figures/qual/cup/ssaof-adv-cup.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=600 0 1400 950,clip]{figures/qual/lamp/ssaof-adv-lamp.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=510 250 1400 800,clip]{figures/qual/sp-airplane/ssaof-adv-airplane.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1000,clip]{figures/qual/sp-cap/ssaof-adv-cap.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=450 150 1450 950,clip]{figures/qual/sp-chair/ssaof-adv-chair.obj_00.png}
\end{array}$
$\begin{array}
{p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}}
\hspace*{9mm}\textcolor{OliveGreen}{\faGuitar}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTree}/\textcolor{OliveGreen}{\faGuitar}
&\hspace*{7mm}\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\pot}/\textcolor{OrangeRed}{\faWineBottle}
&\hspace*{1mm}\textcolor{OliveGreen}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OliveGreen}{1}}}/\textcolor{OrangeRed}{\faTv}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faChair}
&\textcolor{OliveGreen}{\faPlane}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane} 
&\hspace*{1mm}\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide}
&\hspace*{2mm}\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OliveGreen}{\faChair}/\textcolor{OrangeRed}{\faTable} 
\end{array}$

$\begin{array}{@{}lc@{}c@{}c@{}c@{}c@{}c}
\hspace*{0mm}\rotatebox{90}{\large \texttt{~HiT-ADV}} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=550 200 1400 800,clip]{figures/qual/guitar/hitadv-adv-guitar.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1050,clip]{figures/qual/cup/hitadv-adv-cup.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=600 0 1400 950,clip]{figures/qual/lamp/hitadv-adv-lamp.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=510 250 1400 800,clip]{figures/qual/sp-airplane/hitadv-adv-airplane.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1000,clip]{figures/qual/sp-cap/hitadv-adv-cap.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=450 150 1450 950,clip]{figures/qual/sp-chair/hitadv-adv-chair.obj_00.png}
\end{array}$
$\begin{array}
{p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}}
\hspace*{9mm}\textcolor{OrangeRed}{\faWindowMaximize[regular]}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OliveGreen}{\faGuitar}/\textcolor{OliveGreen}{\faGuitar}/\textcolor{OliveGreen}{\faGuitar}
&\hspace*{8mm}\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OliveGreen}{\faBeer}/\textcolor{OliveGreen}{\faBeer}/\textcolor{OrangeRed}{\usym{1F35A}}
&\hspace*{1mm}\textcolor{OrangeRed}{\faTv}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faChair}/\textcolor{OliveGreen}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OliveGreen}{1}}}
&\textcolor{OliveGreen}{\faPlane}/\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane}/\textcolor{OliveGreen}{\faPlane}
&\hspace*{1mm}\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide}/\textcolor{OliveGreen}{\faHatCowboySide}
&\hspace*{2mm}\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OliveGreen}{\faChair}/\textcolor{OrangeRed}{\faTable} 
\end{array}$

%{p{2mm}p{33mm}p{20mm}p{20mm}p{20mm}p{25mm}p{25mm}}
$\begin{array}{@{}lc@{}c@{}c@{}c@{}c@{}c}
\hspace*{0mm}\rotatebox{90}{\large \textbf{\texttt{~~Ours}}} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=550 200 1400 800,clip]{figures/qual/guitar/nopain-adv-guitar.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1050,clip]{figures/qual/cup/nopain-adv-cup.obj_00.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=600 0 1400 950,clip]{figures/qual/lamp/nopain-adv-lamp.obj_00.png}
&\hspace*{0mm}\includegraphics[height=23mm,bb=510 250 1400 800,clip]{figures/qual/sp-airplane/nopain-adv-airplane.png}
%&\hspace*{0mm}\includegraphics[height=23mm,bb=500 150 1300 1000,clip]{figures/qual/sp-cap/nopain-adv-cap.png} 
&\hspace*{0mm}\includegraphics[height=23mm,width=22mm,bb=480 110 1320 1000,clip]{figures/qual/sp-cap/nopain-adv-cap.png} 
&\hspace*{0mm}\includegraphics[height=23mm,bb=450 150 1450 950,clip]{figures/qual/sp-chair/nopain-adv-chair.png}
\end{array}$
\vspace{-5pt}
$\begin{array}
{p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}p{24mm}}
\hspace*{9mm}\textcolor{OrangeRed}{\faPlane}/\textcolor{OrangeRed}{\faPlane}/\textcolor{OrangeRed}{\faKeyboard}/\textcolor{OrangeRed}{\usym{1F3B9}}/\textcolor{OrangeRed}{\faPlane}
&\hspace*{7mm}\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\pot}/\textcolor{OrangeRed}{\faWineBottle}/\textcolor{OrangeRed}{\pot}/\textcolor{OrangeRed}{\faWineBottle}
&\hspace*{3mm}\textcolor{OrangeRed}{\faChair}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTree}/\textcolor{OrangeRed}{\faTree}
&\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}/\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}/\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}/\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}/\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}} 
&\hspace*{2mm}\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}/\textcolor{OrangeRed}{\raisebox{-0.07cm}{\fcTableLight{0.022}{OrangeRed}{1}}}
&\hspace*{2mm}\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable}/\textcolor{OrangeRed}{\faTable} 
\end{array}$
\vspace{-1mm}
\caption{Visualizations of adversarial samples on ModelNet40~(left 3 columns) and ShapeNetPart~(right 3 columns). The icons are their category prediction by PointNet, PointNet++, PointConv, DGCNN and PCT, where \textcolor{OrangeRed}{red} and \textcolor{OliveGreen}{green} indicate successful and failed attacks.}
\label{fig:qualitative}
\end{center}
\vspace{-8mm}
\end{figure*}
\fi

\begin{figure*}[htb!]
\centering
\includegraphics[width=0.99\textwidth]{figures/visualization.png}
\caption{Visualizations of adversarial samples on data from ModelNet40~(left three columns) and ShapeNetPart~(right three columns). The icons below point clouds indicate their category prediction by PointNet, PointNet++, PointConv, DGCNN and PCT, where \textcolor{OrangeRed}{red} and \textcolor{OliveGreen}{green} indicate successful and failed attacks.}
\label{fig:qualitative}
\end{figure*}


\textbf{Evaluation metrics} 
%To quantitatively evaluate the proposed method NoPain, we used attack success rate (ASR) to measure attack effectiveness, and chamfer distance (CD)~\cite{fan2017point} to measure the perturbation strength of attack samples. Effective attacks must be based on the premise of limited perturbations, and the success of attacks caused by excessive perturbations is not desirable. Therefore, in subsequent experiments, we will provide the success rate of attacks and the corresponding cd value. Moreover, we compare the Average Time Cost (ATC) in seconds for generating an adversarial sample using an NVIDIA A40 GPU. 
To quantitatively evaluate our proposed method, NoPain, we used Attack Success Rate (ASR) to assess attack effectiveness and Chamfer Distance (CD)~\cite{fan2017point} to measure the perturbation strength of adversarial samples. Effective attacks require limited perturbations, as the success achieved with excessive perturbations is undesirable. Therefore, in the following experiments, we report both the ASR and corresponding CD values. To assess transferability, we tested the adversarial samples on various target classification models; high ASR scores across models indicate strong transferability. Additionally, we compare the Average Time Cost (ATC) in seconds for generating each adversarial sample on an NVIDIA A40 GPU.

\iffalse
The definitions of ASR and TSR are as follows:
\begin{align*}
&ASR = \frac{n_s}{n_{t}}\\
&TSR = \frac{n_b}{n_s},
\end{align*}
where $n_{t}$ is the total number of generated adversarial samples. $n_{s}$ is the number of successful attack samples on the victim model. $n_b$ represents the number of successful attack samples on both the victim and test model.
\fi




\textbf{Implementation details.}
Our attack framework NoPain is adaptable to various autoencoder architectures. We demonstrate its effectiveness using two widely recognized point cloud autoencoders: PointFlow~\cite{yang2019pointflow} and Point-Diffusion~\cite{luo2021diffusion}, denoted as \textbf{NoPain-PF} and \textbf{NoPain-PD} respectively. PointFlow leverages continuous normalizing flows to transform simple distributions into complex point cloud distributions through a series of invertible transformations, enabling precise point cloud generation and meaningful latent space interpolation. Point-Diffusion, on the other hand, is a diffusion-based approach that excels in generating diverse, high-fidelity point clouds. Both models provide pre-trained encoders and decoders for the target dataset, making them particularly suitable for our framework.

In Algorithm~\ref{alg:OTMap}, we set $M=10N$, initial learning rate $lr=10^{-2}$, threshold $\eta=2\times10^{-3}$, $s=50$.
In Algorithm~\ref{alg:ot-attack}, we set $K=11$ and $\tau=1.6$ on ModelNet40, and set $K=11$ and $\tau=0.9$ on ShapeNetPart.


\subsection{Quantitative Results} 
\noindent\textbf{Transferability.} We report the Attack Success Rate (ASR) against four target models and the Chamfer Distance (CD) between successfully attacked samples and the original samples in \cref{tab:transferability}. For all baseline methods, adversarial samples were generated using PointNet++ as the surrogate model. The results indicate that supervised black-box AdvPC, AOF, SI-Adv, and SS-attack, rely on model-specific loss, resulting in lower ASR on target models. In contrast, the white-box HiT-ADV shows even lower transferability due to its strong dependence on model-specific information.

Compared to these baselines, our methods, NoPain-PF and NoPain-PD, produce adversarial samples with comparable perturbations (CD) and achieve consistently high ASR across all four classification models. Notably, the diffusion-based NoPain-PD attains the highest ASR on most classifiers, indicating that our adversarial samples exhibit strong transferability. Leveraging OT, our approach can detect the singular boundaries of the data manifold, sampling along these boundaries to generate mode-mixed adversarial samples and facilitate transferable end-to-end attacks.

Furthermore, as measured by the AGT metric, our method is an efficient end-to-end approach that only requires a single-step OT mapping to generate adversarial samples, significantly reducing computational costs.



\textbf{Attack against Defense.} To evaluate the robustness of our proposed NoPain under various 3D adversarial defense algorithms, we conducted tests on classification models with four different defense methods, i.e. SRS, SOR, DUP-Net~\cite{zhou2019dup} and  %AT~\cite{liu2019extending}.
IF-Defense~\cite{liu2019extending}. For IF-Defense, we adopt the ConveNet~\cite{peng2020convolutional} model for defense. The defense algorithms in this paper are all implemented using the open-source code provided by IF-Defense.

We generate adversarial examples and calculate the ASR on victim models with defenses. For evaluation, PointNet and DGCNN are selected as the victim models, and the experimental results are reported in Tab.~\ref{tab:defend}. Our method demonstrates robust attack performance across all models while maintaining comparable CD scores. This robustness stems from our approach, which targets the intrinsic characteristics of the data manifold, i.e. the singular boundaries, to produce adversarial examples that are not commonly seen in the original dataset, making them challenging for overfitted classifiers to accurately identify.



\subsection{Qualitative Results} 
The adversarial point clouds generated by different methods are shown in \cref{fig:qualitative}. Here, all baseline methods AdvPC, AOF, SI-Adv, SS-attack, and HiT-ADV adopt Pointnet++ as the surrogate model. These results reveal that baseline methods face challenges in achieving effective network-transferable attacks. In contrast, our NoPain exhibits robust transferability across classifiers. Our model successfully attacks five classifiers simultaneously, whereas other baseline methods tend to achieve high success rates only on surrogate models or those with similar structures. When there is a significant difference between the test and surrogate classifiers, e.g. PointNet++ and PCT, baseline methods often struggle to induce misclassification.
Especially for the more complex ShapeNetPart, the transferability of baselines is even worse, such as on the airplane in the fourth column.

\subsection{Ablation studies} 
To validate the effectiveness of specific hyperparameter settings in our method, we conducted ablation studies on the number of neighbors $K$ and threshold $\tau$ in Algorithm~\ref{alg:ot-attack}, using PointNet as the victim model. The experimental results are presented in Fig.~\ref{fig:ablation}. The graph on the left shows that $K$ reaches its optimum at 10 and 11, where the attack success rate (ASR) is highest and the Chamfer distance (CD) is lowest. The graph on the right indicates that as $\tau$ increases, both ASR and CD rise simultaneously. To constrain the perturbations of adversarial samples, we set $\tau$ to 1.6 for the experiment, achieving an ASR of 97\%.
\begin{figure}[htb!]
\vspace{-4mm}
\centering
\includegraphics[width=0.495\linewidth]{figures/neighbors-eps-converted-to.pdf}
\includegraphics[width=0.495\linewidth]{figures/threshold-eps-converted-to.pdf}
%\vspace{-2mm}
\caption{Effects of the number of neighbors 
$K$ and angle threshold $\tau$ to ASR and CD on ModelNet40. To present these two metrics in a single graph, we scaled the CD values by a factor of 300.}
\label{fig:ablation}
\end{figure}
\vspace{-2mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
In this paper, we introduced NoPain, a novel and interpretable adversarial attack framework that leverages OT to identify singular boundaries within data. Unlike traditional approaches, NoPain generates transferable adversarial examples without requiring iterative updates or guidance from surrogate models. By solving the OT mapping from noise to feature space, our method determined singular boundaries on the target data manifold and shifted point cloud features toward these boundaries to execute the attack. This strategy not only enhanced the interpretability of the approach but also eliminated reliance on classifiers. Experimental results demonstrated the effectiveness of our no-box attack algorithm, with NoPain producing adversarial samples that offer superior transferability and efficiency over existing methods, as confirmed by extensive comparative experiments.

\section*{Acknowledgment}
This research was supported by the National Key R$\&$D Program of China under Grant No. 2021YFA1003003, the Natural Science Foundation of China under Grant No. 62306059 and No. T2225012.  
%\newpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{ref}
}

\end{document}