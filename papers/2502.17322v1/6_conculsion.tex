\section{Conclusion, Limitation and Future Work}
In this paper, we propose the Self-Imitative Reinforcement Learning (SIRL) framework to accelerate the online learning of humanoid robots.
We have made a simple yet effective modification to TD-MPC2 by incorporating a behavior cloning (BC) loss term into the policy training loss function. 
Our proposed algorithm has demonstrated significant performance improvements in the HumanoidBench with a little additional computation overhead. 
Current research has achieved remarkable progress in locomotion tasks, yet there remains substantial room for improvement in whole-body manipulation. 
Looking ahead, we plan to transition TDMPBC from simulated environments to real-world deployment, further exploring its strengths and weaknesses.