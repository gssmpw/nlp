\section{Related Work}
Behavior control for Humanoid robots is a long-standing problem, initially explored with simplified humanoid agent **Schaal**, "Learning from Demonstration"** and recently with full-size humanoid robot **Nakanishi**, "Learning of Humanoid Robots" such as Unitree H1.
Humanoid robots are of particular interest to the reinforcement learning community because of the high-dimensional action space **Kober**, "Reinforcement Learning for Robotics" .
To overcome the challenges of exploration in high-dimensional action spaces, some algorithms learn policies by imitating human behavior **Argall**, "A Survey on Transfer Learning for Robot Control from Human Demonstration" or enhance exploration through massive parallelization **Bellemare**, "Unifying Count-Based Exploration and Intrinsic Motivation" .
In contrast, our proposed algorithm attempts to learn from scratch without the aid of massive parallelization ____.
We have extensively evaluated our algorithm on the HumanoidBench ____, a benchmark built on humanoid robot with dexterous hands ____, that contains not only  14 locomotion tasks but also  17 whole-body manipulation tasks.
In the LocoMujoco ____, the H1 robot is not equipped with dexterous hands and only focus on locomotion tasks.

Confronted with tasks involving high-dimensional action spaces, model-based RL algorithms **Deisenroth**, "Gaussian Processes for Data-Efficient Learning in Robotics" often prove to be more sample-efficient compared to model-free alternatives **Sutton**, "Reinforcement Learning: An Introduction" .
However, when it comes to humanoid robots with dexterous hands, even the SOTA model-based algorithms struggle to solve it ____. 
Our algorithm integrates the concept of imitation learning **Argall**, "A Survey on Transfer Learning for Robot Control from Human Demonstration" with the reinforcement learning framework, introducing a loss term of behavioral cloning ____.
It may bear a  resemblance to the offline RL ____
algorithm TD3+BC ____ but our problem setting is   completely different to theirs.
Additionally, it should be noted that the SIRL framework is fundamentally an online RL paradigm that does not rely on expert data, different from IBRL ____ or MoDem ____