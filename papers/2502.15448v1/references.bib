@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@INPROCEEDINGS{ChavanRealisticIndustrial,
  author={Chavan, Vivek and Koch, Paul and Schlüter, Marian and Briese, Clemens},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Towards Realistic Evaluation of Industrial Continual Learning Scenarios with an Emphasis on Energy Consumption and Computational Footprint}, 
  year={2023},
  volume={},
  number={},
  pages={11472-11484},
  keywords={Training;Learning systems;Energy consumption;Computer vision;Visualization;Green products;Predictive models},
  doi={10.1109/ICCV51070.2023.01057}}


@article{SCHLUTER2023414,
title = {Green incremental learning - Energy efficient ramp-up for AI-enhanced part recognition in reverse logistics},
journal = {Procedia CIRP},
volume = {116},
pages = {414-419},
year = {2023},
note = {30th CIRP Life Cycle Engineering Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.02.070},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123000847},
author = {Marian Schlüter and Robert Schimanek and Paul Koch and Clemens Briese and Vivek Chavan and Pinar Bilge and Franz Dietrich and Jörg Krüger},
keywords = {Circular economy, reverse logistics, incremental learning, computer vision, machine learning},
abstract = {Artificial Intelligence (AI) has made significant progress in supporting circular economy and reverse logistics by learning from diverse data to predict, e.g., routes or to assist workers in sorting. However, it remains an open question how AI can be integrated and trained into such operational processes, where little to no data has been collected previously. Traditionally, AI models would only be rated by their accuracy. This paper aims to introduce the concept of green incremental learning, i.e. rating AI models not only for their accuracy but to evaluate energy efficiency as well. A ramp-up of a data-driven AI system for part recognition is explored under consideration of energy efficiency. Therefore, we combine online and incremental learning, working with growing data sets to simulate a ramp-up phase. We present experiments of incremental learning on business and image data, partially supported by regular joint training steps. We start local CPU-based machine learning and prediction on business data from the first sample. Finally, we compare incremental learning to traditional batch learning and show energy-saving potential of up to 62 % without a significant drop in accuracy.}
}


@article{ResNet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Swin,
  author    = {Ze Liu and
               Yutong Lin and
               Yue Cao and
               Han Hu and
               Yixuan Wei and
               Zheng Zhang and
               Stephen Lin and
               Baining Guo},
  title     = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  journal   = {CoRR},
  volume    = {abs/2103.14030},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.14030},
  eprinttype = {arXiv},
  eprint    = {2103.14030},
  timestamp = {Thu, 19 May 2022 16:00:58 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-14030.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Swinv2,
  author    = {Ze Liu and
               Han Hu and
               Yutong Lin and
               Zhuliang Yao and
               Zhenda Xie and
               Yixuan Wei and
               Jia Ning and
               Yue Cao and
               Zheng Zhang and
               Li Dong and
               Furu Wei and
               Baining Guo},
  title     = {Swin Transformer {V2:} Scaling Up Capacity and Resolution},
  journal   = {CoRR},
  volume    = {abs/2111.09883},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.09883},
  eprinttype = {arXiv},
  eprint    = {2111.09883},
  timestamp = {Thu, 02 Dec 2021 15:54:22 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-09883.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{VGG,
  author    = {Simonyan Karen and Zisserman Andrew},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2014},
  url       = {https://arxiv.org/abs/1409.1556},
  eprinttype = {arXiv}
}

@article{Detr,
  author    = {Nicolas Carion and
               Francisco Massa and
               Gabriel Synnaeve and
               Nicolas Usunier and
               Alexander Kirillov and
               Sergey Zagoruyko},
  title     = {End-to-End Object Detection with Transformers},
  journal   = {CoRR},
  volume    = {abs/2005.12872},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.12872},
  eprinttype = {arXiv},
  eprint    = {2005.12872},
  timestamp = {Thu, 28 May 2020 17:38:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-12872.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Deformable-Detr,
  author    = {Xizhou Zhu and
               Weijie Su and
               Lewei Lu and
               Bin Li and
               Xiaogang Wang and
               Jifeng Dai},
  title     = {Deformable {DETR:} Deformable Transformers for End-to-End Object Detection},
  journal   = {CoRR},
  volume    = {abs/2010.04159},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.04159},
  eprinttype = {arXiv},
  eprint    = {2010.04159},
  timestamp = {Tue, 15 Nov 2022 12:11:44 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-04159.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Clip,
  author    = {Alec Radford and
               Jong Wook Kim and
               Chris Hallacy and
               Aditya Ramesh and
               Gabriel Goh and
               Sandhini Agarwal and
               Girish Sastry and
               Amanda Askell and
               Pamela Mishkin and
               Jack Clark and
               Gretchen Krueger and
               Ilya Sutskever},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  journal   = {CoRR},
  volume    = {abs/2103.00020},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.00020},
  eprinttype = {arXiv},
  eprint    = {2103.00020},
  timestamp = {Thu, 04 Mar 2021 17:00:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-00020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{stable-diffusion,
  author    = {Robin Rombach and
               Andreas Blattmann and
               Dominik Lorenz and
               Patrick Esser and
               Bj{\"{o}}rn Ommer},
  title     = {High-Resolution Image Synthesis with Latent Diffusion Models},
  journal   = {CoRR},
  volume    = {abs/2112.10752},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.10752},
  eprinttype = {arXiv},
  eprint    = {2112.10752},
  timestamp = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-10752.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{ImageTransformers,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{EffNet,
  author    = {Mingxing Tan and
               Quoc V. Le},
  title     = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1905.11946},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.11946},
  eprinttype = {arXiv},
  eprint    = {1905.11946},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-11946.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DenseNet,
  author    = {Gao Huang and
               Zhuang Liu and
               Kilian Q. Weinberger},
  title     = {Densely Connected Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1608.06993},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.06993},
  eprinttype = {arXiv},
  eprint    = {1608.06993},
  timestamp = {Mon, 10 Sep 2018 15:49:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HuangLW16a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{one-cycle,
  author    = {Leslie N. Smith and
               Nicholay Topin},
  title     = {Super-Convergence: Very Fast Training of Residual Networks Using Large
               Learning Rates},
  journal   = {CoRR},
  volume    = {abs/1708.07120},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.07120},
  eprinttype = {arXiv},
  eprint    = {1708.07120},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-07120.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Inception,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott E. Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {CoRR},
  volume    = {abs/1409.4842},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.4842},
  eprinttype = {arXiv},
  eprint    = {1409.4842},
  timestamp = {Mon, 13 Aug 2018 16:48:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SzegedyLJSRAEVR14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{RedNet,
  author    = {Jindong Jiang and
               Lunan Zheng and
               Fei Luo and
               Zhijun Zhang},
  title     = {RedNet: Residual Encoder-Decoder Network for indoor {RGB-D} Semantic
               Segmentation},
  journal   = {CoRR},
  volume    = {abs/1806.01054},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.01054},
  eprinttype = {arXiv},
  eprint    = {1806.01054},
  timestamp = {Mon, 13 Aug 2018 16:46:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-01054.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{AlexNet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}


@Article{app10103443,
AUTHOR = {Naranjo-Torres, José and Mora, Marco and Hernández-García, Ruber and Barrientos, Ricardo J. and Fredes, Claudio and Valenzuela, Andres},
TITLE = {A Review of Convolutional Neural Network Applied to Fruit Image Processing},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {3443},
URL = {https://www.mdpi.com/2076-3417/10/10/3443},
ISSN = {2076-3417},
ABSTRACT = {Agriculture has always been an important economic and social sector for humans. Fruit production is especially essential, with a great demand from all households. Therefore, the use of innovative technologies is of vital importance for the agri-food sector. Currently artificial intelligence is one very important technological tool widely used in modern society. Particularly, Deep Learning (DL) has several applications due to its ability to learn robust representations from images. Convolutional Neural Networks (CNN) is the main DL architecture for image classification. Based on the great attention that CNNs have had in the last years, we present a review of the use of CNN applied to different automatic processing tasks of fruit images: classification, quality control, and detection. We observe that in the last two years (2019&ndash;2020), the use of CNN for fruit recognition has greatly increased obtaining excellent results, either by using new models or with pre-trained networks for transfer learning. It is worth noting that different types of images are used in datasets according to the task performed. Besides, this article presents the fundamentals, tools, and two examples of the use of CNNs for fruit sorting and quality control.},
DOI = {10.3390/app10103443    }
}


@article{AttentionIsAll,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{SCHLUTER2021300,
title = {AI-enhanced Identification, Inspection and Sorting for Reverse Logistics in Remanufacturing},
journal = {Procedia CIRP},
volume = {98},
pages = {300-305},
year = {2021},
note = {The 28th CIRP Conference on Life Cycle Engineering, March 10 – 12, 2021, Jaipur, India},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.01.107},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121001372},
author = {Marian Schlüter and Hannah Lickert and Katharina Schweitzer and Pinar Bilge and Clemens Briese and Franz Dietrich and Jörg Krüger},
keywords = {Circular Economy, Remanufacturing, Reverse Logistics, Sorting, Computer Vision, Machine Learning, Assistance System},
abstract = {In a circular economy for remanufacturing, after each life cycle used products are returned to a remanufacturer for identification, inspection, sorting and reprocessing. Shortcomings and requirements of the remanufacturing market are identified through expert interviews and process analysis. A concept is proposed to enable an improved identification and a more objective inspection by enhancing the working environment and processes of sorting stations. Digitization and machine learning are applied on business data, using machine vision as well as sensor and actor skills of the worker. With an experimental case study on visual object recognition a positive impact on identification and thus sorting could be demonstrated.}
}

@article{SCHLUTER2018384,
author = {Schlüter, Marian and Niebuhr, Carsten and Lehr, Jan and Krüger, Jörg},
year = {2018},
month = {01},
pages = {384-391},
title = {Vision-based Identification Service for Remanufacturing Sorting},
volume = {21},
journal = {Procedia Manufacturing},
doi = {10.1016/j.promfg.2018.02.135}
}


@article{LWAKATARE2020106368,
title = {Large-scale machine learning systems in real-world industrial settings: A review of challenges and solutions},
journal = {Information and Software Technology},
volume = {127},
pages = {106368},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j    .infsof.2020.106368 },
url = {https://www.sciencedirect.com/science/article/pii/S0950584920301373},
author = {Lucy Ellen Lwakatare and Aiswarya Raj and Ivica Crnkovic and Jan Bosch and Helena Holmström Olsson},
keywords = {Machine learning systems, Software engineering, Industrial settings, Challenges, Solutions, SLR},
abstract = {Background: Developing and maintaining large scale machine learning (ML) based software systems in an industrial setting is challenging. There are no well-established development guidelines, but the literature contains reports on how companies develop and maintain deployed ML-based software systems. Objective: This study aims to survey the literature related to development and maintenance of large scale ML-based systems in industrial settings in order to provide a synthesis of the challenges that practitioners face. In addition, we identify solutions used to address some of these challenges. Method: A systematic literature review was conducted and we identified 72 papers related to development and maintenance of large scale ML-based software systems in industrial settings. The selected articles were qualitatively analyzed by extracting challenges and solutions. The challenges and solutions were thematically synthesized into four quality attributes: adaptability, scalability, safety and privacy. The analysis was done in relation to ML workflow, i.e. data acquisition, training, evaluation, and deployment. Results: We identified a total of 23 challenges and 8 solutions related to development and maintenance of large scale ML-based software systems in industrial settings including six different domains. Challenges were most often reported in relation to adaptability and scalability. Safety and privacy challenges had the least reported solutions. Conclusion: The development and maintenance on large-scale ML-based systems in industrial settings introduce new challenges specific for ML, and for the known challenges characteristic for these types of systems, require new methods in overcoming the challenges. The identified challenges highlight important concerns in ML system development practice and the lack of solutions point to directions for future research.}
}
@article{Shahrabadi_2022,
doi = {10.1088/1742-6596/2224/1/012010   },
url = {https://dx.doi.org/10.1088/1742-6596/2224/1/012010    },
year = {2022},
month = {apr},
publisher = {IOP Publishing},
volume = {2224},
number = {1},
pages = {012010},
author = {Somayeh Shahrabadi and Yusbel Castilla and Miguel Guevara and Luís G. Magalhães and Dibet Gonzalez and Telmo Adão},
title = {Defect detection in the textile industry using image-based machine learning methods: a brief review},
journal = {Journal of Physics: Conference Series},
abstract = {Traditionally, computer vision solutions for detecting elements of interest (e.g., defects) are based on strict context-sensitive implementations to address contained problems with a set of well-defined conditions. On the other hand, several machine learning approaches have proven their generalization capacity, not only to improve classification continuously, but also to learn from new examples, based on a fundamental aspect: the separation of data from the algorithmic setup. The findings regarding backward-propagation and the progresses built upon graphical cards technologies boost the advances in machine learning towards a subfield known as deep learning that is becoming very popular among many industrial areas, due to its even greater robustness and flexibility to map and deal knowledge that is typically handled by humans, with, also, incredible scalability proneness. Fabric defect detection is one of the manual processes that has been progressively automatized resorting to the aforementioned approaches, as it is an essential process for quality control. The goal is manifold: reduce human error, fatigue, ergonomic issues and associated costs, while simultaneously improving the expeditiousness and preciseness of the involved tasks, with a direct impact on profit. Following such research line with a specific focus in the textile industry, this work aims to constitute a brief review of both defect types and Automated Optical Inspection (AOI) mostly based on machine learning techniques, which have been proving their effectiveness in identifying anomalies within the context of textile material analysis. The inclusion of Convolutional Neural Network (CNN) based on known architectures such as AlexNet or Visual Geometry Group (VGG16) on computerized defect analysis allowed to reach accuracies over 98\%. A short discussion is also provided along with an analysis of the current state characterizing this field of intervention, as well as some future challenges.}
}

@InProceedings{Tokenfusion,
    author    = {Wang, Yikai and Chen, Xinghao and Cao, Lele and Huang, Wenbing and Sun, Fuchun and Wang, Yunhe},
    title     = {Multimodal Token Fusion for Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {12186-12195}
}

@article{FeaturePyramidNet,
  author    = {Tsung{-}Yi Lin and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Kaiming He and
               Bharath Hariharan and
               Serge J. Belongie},
  title     = {Feature Pyramid Networks for Object Detection},
  journal   = {CoRR},
  volume    = {abs/1612.03144},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.03144},
  eprinttype = {arXiv},
  eprint    = {1612.03144},
  timestamp = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LinDGHHB16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{segformer,
  author    = {Enze Xie and
               Wenhai Wang and
               Zhiding Yu and
               Anima Anandkumar and
               Jose M. Alvarez and
               Ping Luo},
  title     = {SegFormer: Simple and Efficient Design for Semantic Segmentation with
               Transformers},
  journal   = {CoRR},
  volume    = {abs/2105.15203},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.15203},
  eprinttype = {arXiv},
  eprint    = {2105.15203},
  timestamp = {Wed, 02 Jun 2021 11:46:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-15203.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{CMX-rgbdfusion,
  title={CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with Transformers},
  author={Liu, Huayao and Zhang, Jiaming and Yang, Kailun and Hu, Xinxin and Stiefelhagen, Rainer},
  journal={arXiv preprint arXiv:2203.04838},
  year={2022}
}

@article{Symmetric-Cross-modality-Residual-Fusion,
  author    = {Yuejiao Su and
               Yuan Yuan and
               Zhiyu Jiang},
  title     = {Deep feature selection-and-fusion for {RGB-D} semantic segmentation},
  journal   = {CoRR},
  volume    = {abs/2105.04102},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.04102},
  eprinttype = {arXiv},
  eprint    = {2105.04102},
  timestamp = {Fri, 14 May 2021 12:13:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-04102.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DenseFusion,
  author    = {Chen Wang and
               Danfei Xu and
               Yuke Zhu and
               Roberto Mart{\'{\i}}n{-}Mart{\'{\i}}n and
               Cewu Lu and
               Li Fei{-}Fei and
               Silvio Savarese},
  title     = {DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion},
  journal   = {CoRR},
  volume    = {abs/1901.04780},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.04780},
  eprinttype = {arXiv},
  eprint    = {1901.04780},
  timestamp = {Mon, 22 Jul 2019 14:55:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-04780.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{mixup,
  author    = {Hongyi Zhang and
               Moustapha Ciss{\'{e}} and
               Yann N. Dauphin and
               David Lopez{-}Paz},
  title     = {mixup: Beyond Empirical Risk Minimization},
  journal   = {CoRR},
  volume    = {abs/1710.09412},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.09412},
  eprinttype = {arXiv},
  eprint    = {1710.09412},
  timestamp = {Mon, 13 Aug 2018 16:47:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-09412.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{Squeeze,
  author    = {Jie Hu and
               Li Shen and
               Gang Sun},
  title     = {Squeeze-and-Excitation Networks},
  journal   = {CoRR},
  volume    = {abs/1709.01507},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.01507},
  eprinttype = {arXiv},
  eprint    = {1709.01507},
  timestamp = {Wed, 11 Aug 2021 09:47:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-01507.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{synt_shapenet,
  author    = {Angel X. Chang and
               Thomas A. Funkhouser and
               Leonidas J. Guibas and
               Pat Hanrahan and
               Qi{-}Xing Huang and
               Zimo Li and
               Silvio Savarese and
               Manolis Savva and
               Shuran Song and
               Hao Su and
               Jianxiong Xiao and
               Li Yi and
               Fisher Yu},
  title     = {ShapeNet: An Information-Rich 3D Model Repository},
  journal   = {CoRR},
  volume    = {abs/1512.03012},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03012},
  eprinttype = {arXiv},
  eprint    = {1512.03012},
  timestamp = {Thu, 08 Apr 2021 11:37:55 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChangFGHHLSSSSX15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
 @inproceedings{synt_MCB,
    title={A Large-scale Annotated Mechanical Components Benchmark for Classification and Retrieval Tasks with Deep Neural Networks},
    author={Kim, Sangpil and Chi, Hyung-gun and Hu, Xiao and Huang, Qixing and Ramani, Karthik},
    booktitle={Proceedings of 16th European Conference on Computer Vision (ECCV)},
    year={2020},}

@article{real_video_amt,
  author    = {Philipp Henzler and
               Jeremy Reizenstein and
               Patrick Labatut and
               Roman Shapovalov and
               Tobias Ritschel and
               Andrea Vedaldi and
               David Novotn{\'{y}}},
  title     = {Unsupervised Learning of 3D Object Categories from Videos in the Wild},
  journal   = {CoRR},
  volume    = {abs/2103.16552},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.16552},
  eprinttype = {arXiv},
  eprint    = {2103.16552},
  timestamp = {Wed, 07 Apr 2021 15:31:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-16552.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{real_video_objectron,
  author    = {Adel Ahmadyan and
               Liangkai Zhang and
               Jianing Wei and
               Artsiom Ablavatski and
               Matthias Grundmann},
  title     = {Objectron: {A} Large Scale Dataset of Object-Centric Videos in the
               Wild with Pose Annotations},
  journal   = {CoRR},
  volume    = {abs/2012.09988},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.09988},
  eprinttype = {arXiv},
  eprint    = {2012.09988},
  timestamp = {Sun, 03 Jan 2021 18:46:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-09988.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{transformers_hard_to_train,
  title={Self-Supervised Pre-Training for Transformer-Based Person Re-Identification},
  author={Luo, Hao and Wang, Pichao and Xu, Yi and Ding, Feng and Zhou, Yanxin and Wang, Fan and Li, Hao and Jin, Rong},
  journal={arXiv preprint arXiv:2111.12084},
  year={2021}
}

@article{synt_modelnet,
  author    = {Zhirong Wu and
               Shuran Song and
               Aditya Khosla and
               Xiaoou Tang and
               Jianxiong Xiao},
  title     = {3D ShapeNets for 2.5D Object Recognition and Next-Best-View Prediction},
  journal   = {CoRR},
  volume    = {abs/1406.5670},
  year      = {2014},
  url       = {http://arxiv.org/abs/1406.5670},
  eprinttype = {arXiv},
  eprint    = {1406.5670},
  timestamp = {Mon, 13 Aug 2018 16:47:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WuSKTX14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{real_video_scanobject,
  author    = {Mikaela Angelina Uy and
               Quang{-}Hieu Pham and
               Binh{-}Son Hua and
               Duc Thanh Nguyen and
               Sai{-}Kit Yeung},
  title     = {Revisiting Point Cloud Classification: {A} New Benchmark Dataset and
               Classification Model on Real-World Data},
  journal   = {CoRR},
  volume    = {abs/1908.04616},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.04616},
  eprinttype = {arXiv},
  eprint    = {1908.04616},
  timestamp = {Mon, 19 Aug 2019 13:21:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-04616.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{real_PASCAL3D+,
  author={Xiang, Yu and Mottaghi, Roozbeh and Savarese, Silvio},
  booktitle={IEEE Winter Conference on Applications of Computer Vision}, 
  title={Beyond PASCAL: A benchmark for 3D object detection in the wild}, 
  year={2014},
  volume={},
  number={},
  pages={75-82},
  doi={10.1109/WACV.2014.6836101}}


@misc{real_video_GoogleScanned,
  doi = {10.48550/ARXIV.2204.11918},
  url = {https://arxiv.org/abs/2204.11918},  
  author = {Downs, Laura and Francis, Anthony and Koenig, Nate and Kinman, Brandon and Hickman, Ryan and Reymann, Krista and McHugh, Thomas B. and Vanhoucke, Vincent},
    keywords = {Robotics (cs.RO), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Google Scanned Objects: A High-Quality Dataset of 3D Scanned Household Items},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{real_video_freiburgcars,
author       = "N. Sedaghat and T. Brox",
title        = "Unsupervised Generation of a Viewpoint Annotated Car Dataset from Videos",
booktitle    = "IEEE International Conference on Computer Vision (ICCV)",
year         = "2015",
url          = "http://lmb.informatik.uni-freiburg.de//Publications/2015/SB15"
}


@article{real_CO3D,
  author    = {Jeremy Reizenstein and
               Roman Shapovalov and
               Philipp Henzler and
               Luca Sbordone and
               Patrick Labatut and
               David Novotn{\'{y}}},
  title     = {Common Objects in 3D: Large-Scale Learning and Evaluation of Real-life
               3D Category Reconstruction},
  journal   = {CoRR},
  volume    = {abs/2109.00512},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.00512},
  eprinttype = {arXiv},
  eprint    = {2109.00512},
  timestamp = {Mon, 20 Sep 2021 16:29:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-00512.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{synt_partnet,
  author    = {Kaichun Mo and
               Shilin Zhu and
               Angel X. Chang and
               Li Yi and
               Subarna Tripathi and
               Leonidas J. Guibas and
               Hao Su},
  title     = {PartNet: {A} Large-scale Benchmark for Fine-grained and Hierarchical
               Part-level 3D Object Understanding},
  journal   = {CoRR},
  volume    = {abs/1812.02713},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.02713},
  eprinttype = {arXiv},
  eprint    = {1812.02713},
  timestamp = {Wed, 11 Nov 2020 08:48:10 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-02713.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{synt_ABC,
author = {Koch, Sebastian and Matveev, Albert and Jiang, Zhongshi and Williams, Francis and Artemov, Alexey and Burnaev, Evgeny and Alexa, Marc and Zorin, Denis and Panozzo, Daniele},
title = {ABC: A Big CAD Model Dataset For Geometric Deep Learning},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}




@article{sum_fuse,
author = {Przemysław Dolata and Mariusz Mrzygłód and Jacek Reiner},
title = {Double-stream Convolutional Neural Networks for Machine Vision Inspection of Natural Products},
journal = {Applied Artificial Intelligence},
volume = {31},
number = {7-8},
pages = {643-659},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/08839514.2018.1428491 },
URL = {https://doi.org/10.1080/08839514.2018.1428491 },
eprint = {https://doi.org/10.1080/08839514.2018.1428491 }
}


@ARTICLE{concat1,
  author={Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Litjens, Geert and Gerke, Paul and Jacobs, Colin and van Riel, Sarah J. and Wille, Mathilde Marie Winkler and Naqibullah, Matiullah and Sánchez, Clara I. and van Ginneken, Bram},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Pulmonary Nodule Detection in CT Images: False Positive Reduction Using Multi-View Convolutional Networks}, 
  year={2016},
  volume={35},
  number={5},
  pages={1160-1169},
  doi={10.1109/TMI.2016.2536809}}

@inproceedings{concat2,
title = "Multi-stream CNN for spatial resource allocation: A crop management application", 
author = "Alexandre Barbosa and Thiago Marinho and Nicolas Martin and Naira Hovakimyan",
note = "Publisher Copyright: {\textcopyright} 2020 IEEE.; 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2020 ; Conference date: 14-06-2020 Through 19-06-2020",
year = "2020",
month = jun,
doi = "10.1109/CVPRW50498.2020.00037",
language = "English (US)",
series = "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",
publisher = "IEEE Computer Society",
pages = "258--266",
booktitle = "Proceedings - 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2020",
}

@article{concat3,
  author    = {Krzysztof J. Geras and
               Stacey Wolfson and
               S. Gene Kim and
               Linda Moy and
               Kyunghyun Cho},
  title     = {High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional
               Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1703.07047},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.07047},
  eprinttype = {arXiv},
  eprint    = {1703.07047},
  timestamp = {Sat, 23 Jan 2021 01:20:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/GerasWKMC17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{omnivec,
      title={OmniVec: Learning robust representations with cross modal sharing}, 
      author={Siddharth Srivastava and Gaurav Sharma},
      year={2023},
      eprint={2311.05709},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.05709}, 
}

@InProceedings{omnivec2,
    author    = {Srivastava, Siddharth and Sharma, Gaurav},
    title     = {OmniVec2 - A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {27412-27424}
}

@inproceedings{omnivore,
  title={{Omnivore: A Single Model for Many Visual Modalities}},
  author={Girdhar, Rohit and Singh, Mannat and Ravi, Nikhila and van der Maaten, Laurens and Joulin, Armand and Misra, Ishan},
  booktitle={CVPR},
  year={2022}
}
@article{insects,
    doi = {10.1371/journal.pone.0192011},
    author = {Marques, Alan Caio R. AND M. Raimundo, Marcos AND B. Cavalheiro, Ellen Marianne AND F. P. Salles, Luis AND Lyra, Christiano AND J. Von Zuben, Fernando},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Ant genera identification using an ensemble of convolutional neural networks},
    year = {2018},
    month = {01},
    volume = {13},
    url = {https://doi.org/10.1371/journal.pone.0192011},
    pages = {1-13},
    abstract = {Works requiring taxonomic knowledge face several challenges, such as arduous identification of many taxa and an insufficient number of taxonomists to identify a great deal of collected organisms. Machine learning tools, particularly convolutional neural networks (CNNs), are then welcome to automatically generate high-performance classifiers from available data. Supported by the image datasets available at the largest online database on ant biology, the AntWeb (www.antweb.org), we propose here an ensemble of CNNs to identify ant genera directly from the head, profile and dorsal perspectives of ant images. Transfer learning is also considered to improve the individual performance of the CNN classifiers. The performance achieved by the classifiers is diverse enough to promote a reduction in the overall classification error when they are combined in an ensemble, achieving an accuracy rate of over 80% on top-1 classification and an accuracy of over 90% on top-3 classification.},
    number = {1},

}

@inproceedings{plants,
  TITLE = {{Plant Identification in an Open-world (LifeCLEF 2016)}},
  AUTHOR = {Go{\"e}au, Herv{\'e} and Bonnet, Pierre and Joly, Alexis},
  URL = {https://hal.archives-ouvertes.fr/hal-01373780},
  BOOKTITLE = {{CLEF: Conference and Labs of the Evaluation Forum}},
  ADDRESS = {{\'E}vora, Portugal},
  HAL_LOCAL_REFERENCE = {COOLDB},
  VOLUME = {CEUR Workshop Proceedings},
  NUMBER = {1609},
  PAGES = {428-439},
  YEAR = {2016},
  MONTH = Sep,
  KEYWORDS = {LifeCLEF ; Plant ; Leaves ; Leaf ; Flower ; Fruit ; Bark ; Stem ; Branch ; Species ; Retrieval ; Images ; Collection ; Species identification ; Citizen-science ; Fine-grained classification ; Evaluation ; Benchmark},
  PDF = {https://hal.archives-ouvertes.fr/hal-01373780/file/16090428.pdf},
  HAL_ID = {hal-01373780},
  HAL_VERSION = {v1},
}

@article{img_text-fusion,
  author    = {Ignazio Gallo and
               Alessandro Calefati and
               Shah Nawaz and
               Muhammad Kamran Janjua},
  title     = {Image and Encoded Text Fusion for Multi-Modal Classification},
  journal   = {CoRR},
  volume    = {abs/1810.02001},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.02001},
  eprinttype = {arXiv},
  eprint    = {1810.02001},
  timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-02001.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Flickr30k,
author = {Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
year = {2014},
month = {12},
pages = {67-78},
title = {From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
volume = {2},
journal = {TACL},
doi = {10.1162/tacl_a_00166}
}

@article{VisualGenome,
  author    = {Ranjay Krishna and
               Yuke Zhu and
               Oliver Groth and
               Justin Johnson and
               Kenji Hata and
               Joshua Kravitz and
               Stephanie Chen and
               Yannis Kalantidis and
               Li{-}Jia Li and
               David A. Shamma and
               Michael S. Bernstein and
               Li Fei{-}Fei},
  title     = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense
               Image Annotations},
  journal   = {CoRR},
  volume    = {abs/1602.07332},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.07332},
  eprinttype = {arXiv},
  eprint    = {1602.07332},
  timestamp = {Wed, 15 Sep 2021 14:13:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KrishnaZGJHKCKL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{VQA:Visual_Question_Answering,
  author    = {Stanislaw Antol and
               Aishwarya Agrawal and
               Jiasen Lu and
               Margaret Mitchell and
               Dhruv Batra and
               C. Lawrence Zitnick and
               Devi Parikh},
  title     = {{VQA:} Visual Question Answering},
  journal   = {CoRR},
  volume    = {abs/1505.00468},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.00468},
  eprinttype = {arXiv},
  eprint    = {1505.00468},
  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/AntolALMBZP15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{MSR-VTT,
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MSR-VTT: A Large Video Description Dataset for Bridging Video and Language}, 
  year={2016},
  volume={},
  number={},
  pages={5288-5296},
  doi={10.1109/CVPR.2016.571}}

@INPROCEEDINGS{HHARGBD,
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Fully convolutional networks for semantic segmentation}, 
  year={2015},
  volume={},
  number={},
  pages={3431-3440},
  doi={10.1109/CVPR.2015.7298965}}

  @article{HHAorigin,
  author    = {Saurabh Gupta and
               Ross B. Girshick and
               Pablo Arbelaez and
               Jitendra Malik},
  title     = {Learning Rich Features from {RGB-D} Images for Object Detection and
               Segmentation},
  journal   = {CoRR},
  volume    = {abs/1407.5736},
  year      = {2014},
  url       = {http://arxiv.org/abs/1407.5736},
  eprinttype = {arXiv},
  eprint    = {1407.5736},
  timestamp = {Mon, 04 Mar 2019 08:31:20 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/GuptaGAM14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{RGBDSSL,
  author    = {Xiaoqi Zhao and
               Youwei Pang and
               Lihe Zhang and
               Huchuan Lu and
               Xiang Ruan},
  title     = {Self-Supervised Representation Learning for {RGB-D} Salient Object
               Detection},
  journal   = {CoRR},
  volume    = {abs/2101.12482},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.12482},
  eprinttype = {arXiv},
  eprint    = {2101.12482},
  timestamp = {Tue, 02 Feb 2021 09:52:17 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2101-12482.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{RGBD-pretrained,
author = {Ophoff, Tanguy and Van Beeck, Kristof and Goedemé, Toon},
year = {2019},
month = {02},
pages = {866},
title = {Exploring RGB+Depth Fusion for Real-Time Object Detection},
volume = {19},
journal = {Sensors},
doi = {10.3390/s19040866}
}

@article{Rare_AI_Industry,
title = {Machine Learning for industrial applications: A comprehensive literature review},
journal = {Expert Systems with Applications},
volume = {175},
pages = {114820},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114820},
url = {https://www.sciencedirect.com/science/article/pii/S095741742100261X},
author = {Massimo Bertolini and Davide Mezzogori and Mattia Neroni and Francesco Zammori},
keywords = {Literature review, Industrial applications, Deep Learning, Machine Learning, Operation management}
}








@article{survey_open_questions,
author = {Rahul Rai and Manoj Kumar Tiwari and Dmitry Ivanov and Alexandre Dolgui},
title = {Machine learning in manufacturing and industry 4.0 applications},
journal = {International Journal of Production Research},
volume = {59},
number = {16},
pages = {4773-4778},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/00207543.2021.1956675},
}



@Article{Survey_onlyCNNs,
AUTHOR = {Mazzei, Daniele and Ramjattan, Reshawn},
TITLE = {Machine Learning for Industry 4.0: A Systematic Review Using Deep Learning-Based Topic Modelling},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {22},
ARTICLE-NUMBER = {8641},
URL = {https://www.mdpi.com/1424-8220/22/22/8641},
PubMedID = {36433236},
ISSN = {1424-8220}
}






@misc{real_fewShot,
      title        = {FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments},
      author       = {P.J, Jaykumar and Chao, Yu-Wei and Xiang, Yu},
      year         = 2022,
      publisher    = {arXiv},
      doi          = {10.48550/ARXIV.2207.03333},
      url          = {https://arxiv.org/abs/2207.03333},
      copyright    = {Creative Commons Attribution 4.0 International}
    }    
}

@INPROCEEDINGS{RGBDfusion_old,
  author={Eitel, Andreas and Springenberg, Jost Tobias and Spinello, Luciano and Riedmiller, Martin and Burgard, Wolfram},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Multimodal deep learning for robust RGB-D object recognition}, 
  year={2015},
  volume={},
  number={},
  pages={681-687},
  doi={10.1109/IROS.2015.7353446}}
  

@article{real_video_MV-RGBD2011,
author = {Kevin Lai and Liefeng Bo and Xiaofeng Ren and Dieter Fox},
title = {A Large-Scale Hierarchical Multi-View RGB-D Object Dataset},
journal = ICRA,
year = 2011
}

@inproceedings{mvcnn,
  author    = {Hang Su and
               Subhransu Maji and
               Evangelos Kalogerakis and
               Erik G. Learned{-}Miller},
  title     = {Multi-view convolutional neural networks for 3d shape recognition},
  booktitle = {Proc. ICCV},
  year      = {2015},
}

@InProceedings{View-GCN,
author = {Wei, Xin and Yu, Ruixuan and Sun, Jian},
title = {View-GCN: View-Based Graph Convolutional Network for 3D Shape Analysis},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@article{MVTN,
  author    = {Abdullah Hamdi and
               Silvio Giancola and
               Bing Li and
               Ali K. Thabet and
               Bernard Ghanem},
  title     = {{MVTN:} Multi-View Transformation Network for 3D Shape Recognition},
  journal   = {CoRR},
  volume    = {abs/2011.13244},
  year      = {2020},
  url       = {https://arxiv.org/abs/2011.13244},
  eprinttype = {arXiv},
  eprint    = {2011.13244},
  timestamp = {Thu, 02 Feb 2023 13:14:21 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-13244.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Bootstrapping_ViTs,
  author    = {Haofei Zhang and
               Jiarui Duan and
               Mengqi Xue and
               Jie Song and
               Li Sun and
               Mingli Song},
  title     = {Bootstrapping ViTs: Towards Liberating Vision Transformers from Pre-training},
  journal   = {CoRR},
  volume    = {abs/2112.03552},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.03552},
  eprinttype = {arXiv},
  eprint    = {2112.03552},
  timestamp = {Mon, 13 Dec 2021 17:51:48 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-03552.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{GVCNN,
  author={Feng, Yifan and Zhang, Zizhao and Zhao, Xibin and Ji, Rongrong and Gao, Yue},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={264-272},
  doi={10.1109/CVPR.2018.00035}}

@INPROCEEDINGS{GIFT,
  author={Bai, Song and Bai, Xiang and Zhou, Zhichao and Zhang, Zhaoxiang and Latecki, Longin Jan},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={GIFT: A Real-Time and Scalable 3D Shape Search Engine}, 
  year={2016},
  volume={},
  number={},
  pages={5023-5032},
  doi={10.1109/CVPR.2016.543}}

@article{MVFusionNet,
  author    = {Kui Jia and
               Jiehong Lin and
               Mingkui Tan and
               Dacheng Tao},
  title     = {Deep Multi-View Learning using Neuron-Wise Correlation-Maximizing
               Regularizers},
  journal   = {CoRR},
  volume    = {abs/1904.11151},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.11151},
  eprinttype = {arXiv},
  eprint    = {1904.11151},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-11151.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{RotationNet,
  author    = {Asako Kanezaki},
  title     = {RotationNet: Learning Object Classification Using Unsupervised Viewpoint
               Estimation},
  journal   = {CoRR},
  volume    = {abs/1603.06208},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.06208},
  eprinttype = {arXiv},
  eprint    = {1603.06208},
  timestamp = {Mon, 13 Aug 2018 16:47:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Kanezaki16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{MLVCNN, title={MLVCNN: Multi-Loop-View Convolutional Neural Network for 3D Shape Retrieval}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4869}, DOI={10.1609/aaai.v33i01.33018513}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Jiang, Jianwen and Bao, Di and Chen, Ziqiang and Zhao, Xibin and Gao, Yue}, year={2019}, month={Jul.}, pages={8513-8520} }

@article{fusion_survey,
author = {Kaur, Harpreet and Koundal, Deepika and Kadyan, Virender},
year = {2021},
month = {01},
pages = {},
title = {Image Fusion Techniques: A Survey},
volume = {28},
journal = {Archives of Computational Methods in Engineering},
doi = {10.1007/s11831-021-09540-7}
}

@article{Multi-View_ML,
    doi = {10.1371/journal.pone.0245230},
    author = {Seeland, Marco AND Mäder, Patrick},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Multi-view classification with convolutional neural networks},
    year = {2021},
    month = {01},
    volume = {16},
    url = {https://doi.org/10.1371/journal.pone.0245230},
    pages = {1-17}
}

@article{Weight-Estimation,
author = {Dalai, Radhamadhab and Senapati, Kishore},
year = {2017},
month = {07},
pages = {71-75},
title = {Weight Estimation through Image Analysis},
volume = {49},
journal = {International Journal of Computer Trends and Technology},
doi = {10.14445/22312803/IJCTT-V49P111}
}

@article{product-fusion,
  title={Plant identification using score-based fusion of multi-organ images},
  author={Thanh-Binh Do and Huy Hoang Nguyen and Thi Thanh-Nhan Nguyen and Hai Vu and Thi-Thanh-Hai Tran and Thi-Lan Le},
  journal={2017 9th International Conference on Knowledge and Systems Engineering (KSE)},
  year={2017},
  pages={191-196}
}

@article{MV-det,
  author    = {Georgios Georgakis and
               Md. Alimoor Reza and
               Arsalan Mousavian and
               Phi{-}Hung Le and
               Jana Kosecka},
  title     = {Multiview {RGB-D} Dataset for Object Instance Detection},
  journal   = {CoRR},
  volume    = {abs/1609.07826},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.07826},
  eprinttype = {arXiv},
  eprint    = {1609.07826},
  timestamp = {Mon, 13 Aug 2018 16:48:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/GeorgakisRMLK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{Mnist,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}

@article{cifar,
author = {Krizhevsky, Alex},
year = {2012},
month = {05},
pages = {},
title = {Learning Multiple Layers of Features from Tiny Images},
journal = {University of Toronto}
}

@article{RGBD-SUN,
author = {Shuran Song and Samuel P. Lichtenberg and Jianxiong Xiao},
year = {2015},
month = {05},
pages = {},
title = {SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite},
journal = {CVPR}
}

@inproceedings{RGBD-NYUv2,
author = {Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
year = {2012},
month = {10},
pages = {746-760},
title = {Indoor Segmentation and Support Inference from RGBD Images},
volume = {7576},
isbn = {978-3-642-33714-7},
journal = {ECCV},
doi = {10.1007/978-3-642-33715-4_54}
}

@article{RGBD-ScanNet,
  author    = {Angela Dai and
               Angel X. Chang and
               Manolis Savva and
               Maciej Halber and
               Thomas A. Funkhouser and
               Matthias Nie{\ss}ner},
  title     = {ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
  journal   = {CoRR},
  volume    = {abs/1702.04405},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.04405},
  eprinttype = {arXiv},
  eprint    = {1702.04405},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/DaiCSHFN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{t-less,
  author    = {Tomas Hodan and
               Pavel Haluza and
               Step{\'{a}}n Obdrz{\'{a}}lek and
               Jiri Matas and
               Manolis I. A. Lourakis and
               Xenophon Zabulis},
  title     = {{T-LESS:} An {RGB-D} Dataset for 6D Pose Estimation of Texture-less
               Objects},
  journal   = {CoRR},
  volume    = {abs/1701.05498},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.05498},
  eprinttype = {arXiv},
  eprint    = {1701.05498},
  timestamp = {Mon, 13 Aug 2018 16:49:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HodanHOMLZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{GraspNet,
author = {Fang, Hao-Shu and Wang, Chenxi and Gou, Minghao and Lu, Cewu},
year = {2020},
month = {06},
pages = {11441-11450},
title = {GraspNet-1Billion: A Large-Scale Benchmark for General Object Grasping},
doi = {10.1109/CVPR42600.2020.01146}
}

@InProceedings{LineMod,
author="Hinterstoisser, Stefan
and Lepetit, Vincent
and Ilic, Slobodan
and Holzer, Stefan
and Bradski, Gary
and Konolige, Kurt
and Navab, Nassir",
editor="Lee, Kyoung Mu
and Matsushita, Yasuyuki
and Rehg, James M.
and Hu, Zhanyi",
title="Model Based Training, Detection and Pose Estimation of Texture-Less 3D Objects in Heavily Cluttered Scenes",
booktitle="Computer Vision -- ACCV 2012",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="548--562",
isbn="978-3-642-37331-2"
}

@INPROCEEDINGS{kitti,
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Are we ready for autonomous driving? The KITTI vision benchmark suite}, 
  year={2012},
  volume={},
  number={},
  pages={3354-3361},
  doi={10.1109/CVPR.2012.6248074}}
  

@article{cityscapes,
  author    = {Marius Cordts and
               Mohamed Omran and
               Sebastian Ramos and
               Timo Rehfeld and
               Markus Enzweiler and
               Rodrigo Benenson and
               Uwe Franke and
               Stefan Roth and
               Bernt Schiele},
  title     = {The Cityscapes Dataset for Semantic Urban Scene Understanding},
  journal   = {CoRR},
  volume    = {abs/1604.01685},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.01685},
  eprinttype = {arXiv},
  eprint    = {1604.01685},
  timestamp = {Mon, 13 Aug 2018 16:47:48 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/CordtsORREBFRS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{coco,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               Lubomir D. Bourdev and
               Ross B. Girshick and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  eprinttype = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{PoseCNN,
  author    = {Yu Xiang and
               Tanner Schmidt and
               Venkatraman Narayanan and
               Dieter Fox},
  title     = {PoseCNN: {A} Convolutional Neural Network for 6D Object Pose Estimation
               in Cluttered Scenes},
  journal   = {CoRR},
  volume    = {abs/1711.00199},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.00199},
  eprinttype = {arXiv},
  eprint    = {1711.00199},
  timestamp = {Mon, 13 Aug 2018 16:48:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-00199.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@article{Dino,
  author    = {Mathilde Caron and
               Hugo Touvron and
               Ishan Misra and
               Herv{\'{e}} J{\'{e}}gou and
               Julien Mairal and
               Piotr Bojanowski and
               Armand Joulin},
  title     = {Emerging Properties in Self-Supervised Vision Transformers},
  journal   = {CoRR},
  volume    = {abs/2104.14294},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.14294},
  eprinttype = {arXiv},
  eprint    = {2104.14294},
  timestamp = {Tue, 04 May 2021 15:12:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-14294.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@inproceedings{ImageNet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@article{Briese_2021,
	title = {Reduction of annotation efforts for multiclass object detection by using a domain awareness data combination strategy},
	volume = {1140},
	issn = {1757-8981, 1757-899X},
	url = {https://iopscience.iop.org/article/10.1088/1757-899X/1140/1/012017},
	doi = {10.1088/1757-899X/1140/1/012017},
	abstract = {Abstract
            To train convolutional neural networks (CNN) it is common practise to collect a huge amount of data. This is cost intensive and often not applicable. Up to date several studies have investigated the concept of few shoot learning, e.g. 1-3 samples per class. Suboptimal is still the over fitting resulting from the gap between training data and representative test data in the application. Since this is still a field of intensive research, an alternative and common approach is transfer learning with data- and image augmented pictures. However, collecting and labelling data for fine-tuning can still take an enormous amount of time, when it comes to multiclass pictures in industrial applications like assembly kit verification. The kits often contain stock lists with a small interclass and a high intraclass-distance. A specific characteristic of stock lists is that parts are easily adaptable and exchangeable. To bring object detection closer to the industry, we successfully show a dataset driven approach that combines a single class collection of pictures, which we call single class (SC) dataset and adapt with a few samples the specific multiclass use case. In result, we use a model trained on a huge SC dataset that can easily and fast be adapted to specific industrial use cases.},
	number = {1},
	urldate = {2023-01-31},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Briese, C. and Hummel, B. and Hoang, V. and Schlüter, M. and Krüger, J.},
	month = may,
	year = {2021},
	pages = {012017},
	file = {Volltext:C\:\\Users\\schlmari\\ownCloud\\Promotion\\05_Arbeitsunterlagen\\Literatur\\Zotero\\storage\\WIYW3EZB\\Briese et al. - 2021 - Reduction of annotation efforts for multiclass obj.pdf:application/pdf},
}

@article{multiview-transformer-video,
  author       = {Shen Yan and
                  Xuehan Xiong and
                  Anurag Arnab and
                  Zhichao Lu and
                  Mi Zhang and
                  Chen Sun and
                  Cordelia Schmid},
  title        = {Multiview Transformers for Video Recognition},
  journal      = {CoRR},
  volume       = {abs/2201.04288},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.04288},
  eprinttype    = {arXiv},
  eprint       = {2201.04288},
  timestamp    = {Fri, 30 Jun 2023 14:32:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-04288.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{multi-view-tr-3d,
  title={Multi-View Transformer for 3D Visual Grounding},
  author={Huang, Shijia and Chen, Yilun and Jia, Jiaya and Wang, Liwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15524--15533},
  year={2022}
}

@inproceedings{ReferIt3D,
    title={{ReferIt3D}: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes},
    author={Achlioptas, Panos and Abdelreheem, Ahmed and Xia, Fei and Elhoseiny, Mohamed and Guibas, Leonidas J.},
    booktitle={16th European Conference on Computer Vision (ECCV)},
    year={2020}
}


@article{scanrefer,
    title={ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language},
    author={Chen, Dave Zhenyu and Chang, Angel X and Nie{\ss}ner, Matthias},
    journal={16th European Conference on Computer Vision (ECCV)},
    year={2020}
}

@inproceedings{scan2cap,
  title={Scan2Cap: Context-aware Dense Captioning in RGB-D Scans},
  author={Chen, Zhenyu and Gholami, Ali and Nie{\ss}ner, Matthias and Chang, Angel X},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3193--3203},
  year={2021}
}

@misc{dinov2,
      title={DINOv2: Learning Robust Visual Features without Supervision}, 
      author={Maxime Oquab and Timothée Darcet and Théo Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Hervé Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
      year={2023},
      eprint={2304.07193},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}