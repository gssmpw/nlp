% Training large language models (LLMs) for diverse inference constraints is computationally impractical, restricting fine-grained control over trade-off between efficiency and accuracy.



Training large language models (LLMs) for different inference constraints is computationally expensive, limiting control over efficiency-accuracy trade-offs. Moreover, once trained, these models typically process tokens uniformly, regardless of their complexity, leading to static and inflexible behavior. In this paper, we introduce a post-training optimization framework, $\mname$, that adapts a pre-trained dense LLM to a token-difficulty-driven Mixture-of-Experts model with minimal fine-tuning cost. This adaptation makes the model dynamic, with sensitivity control to customize the balance between efficiency and accuracy. $\mname$ features a token-difficulty-aware router that predicts the difficulty of tokens and directs them to the appropriate sub-networks or experts, enabling larger experts to handle more complex tokens and smaller experts to process simpler ones. Our experiments demonstrate that $\mname$ can generate a range of adaptive model variants of the existing trained LLM with a single fine-tuning step, utilizing only $10B$ tokens, a minimal cost compared to the base model's training. Each variant offers distinct trade-offs between accuracy and performance. Compared to the baseline post-training optimization framework, Flextron, our method  achieves similar aggregated accuracy across downstream tasks, despite using only $\frac{1}{9}\text{th}$ of their fine-tuning cost.

% With only $\frac{1}{9}\text{th}$ of the fine-tuning cost of the baseline, $\mname$ achieves comparable aggregated accuracy across downstream tasks.

% $\frac{1}{9}\text{th}$ of the Flextron's fine-tuning cost, our results  for $\mname$ with $\theta=0.7$  are comparable to Flextron.

% $\mname$ achieves superior aggregated accuracy across downstream tasks compared to the baseline.



% Due to signifi- cant training costs, training LLM for every inference constraints is impractical is very compute intensive, limiting more fine-grained control over relevant tradeoffs, including latency, cost, and accuracy. 
% Furthermore, once trained often these models become static processing each token in a homogeneous manner. 

% post trainging method, convert any pre-rained LLM to the custom constraint with very mininal fine-tuning cost. The adaptive modle becomes dynaic, process each token base don its difficulty. Novel router and method to derive difficulty.