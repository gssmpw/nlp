We present $\mname$, a post-training optimization framework that converts a standard pre-trained dense LLM into a token-difficulty-driven MoE model. $\mname$ incorporates a lightweight router to predict the token difficulty and routes them to an appropriate expert. To train this router, we propose a novel method to derive the token difficulty labels, which act as supervision signals. $\mname$ generates adaptive model variants with sensitivity control, allowing customization of the trade-off between efficiency and accuracy. 
% Experimental results demonstrate that $\mname$ outperforms baseline input-adaptive methods fine-tuned with similar token cost.


% with reduced costs, achieving superior aggregated accuracy across downstream tasks while using only $1/9$th of the baseline's fine-tuning cost.