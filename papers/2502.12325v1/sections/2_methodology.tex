In this section, we describe our proposed post-training optimization framework, $\mname$, which transforms a dense LLM into an MoE model for adaptive inference based on token difficulty. The process involves three key steps: $(1)$ defining heterogeneous experts by splitting the MLP layers of the dense LLM; $(2)$ generating token labels during training to represent token difficulty; and $(3)$ training a router to predict token difficulty while fine-tuning the model. We detail these steps in the below sub-sections.

\subsection{Defining Heterogeneous Experts}
In this work, we focus on defining experts into the MLP layers of the LLM \cite{Devvrit2023MatFormerNT}, as these layers account for the majority of the compute and operate on a token-by-token basis. The overview of $\mname$ is depicted in Fig. \ref{fig:overview}. The left part of the figure denotes the base pre-trained model which consists of the normalization layers, attention layers and the MLP layers in each transformer block. The right part shows the adapted $\mname$ model, where the original single MLP layer is transformed into multiple nested FFN blocks or experts. Such expert formation introduces no additional parameters to the base model, aside from the router. This design draws inspiration from adaptive width reduction in transformer \cite{Salehi2023SHARCSET} and recent works like Matformer \cite{Devvrit2023MatFormerNT} and Flextron \cite{Cai2024FlextronMF}. The attention layers remain frozen, and the MLP layers adapted to nested experts are fine-tuned in $\mname$.

Let $D$ and $H$ denote the embedding and the hidden dimensions of the MLP layer respectively. The input to the MLP layer is $\bx \in \R^{B \times D}$ and the output is $\by \in \R^{B \times D}$, where $B$ is the batch dimension. The MLP layer with two fully connected layers is represented by weight matrices $\win \in \R^{H \times D}$ and $\wout \in \R^{D \times H}$. In order to get best results, we first rearrange these fully-connected layers,  $\win$ and $\wout$, to have the most important rows/columns in the beginning of the matrix so that they can be included in all of the experts \cite{Samragh2023WeightSD}. There are a total of $E$ experts indexed using $e \in  \{0, 1, \ldots, E-1\}$. Each expert gets a portion $H_e$ of the weight matrices $\win$ and $\wout$, sliced over the hidden dimension $H$. The value $H_e$ is obtained as a fraction of $H$ as, 
\begin{equation}
    H_e = \floor*{\bp{\frac{e+1}{E}}\cdot H},
\end{equation}
consequently, $H_0 < H_1 < \cdots < H_{E-1}$ and $H_{E-1}=H$. Note that the expert with index $E-1$ utilizes the full MLP layer. The restriction of the matrices $\win$ and $\wout$ to the expert width $H_e$ is obtained using the slicing operator that selects the first $H_e$ rows and columns respectively as 
\begin{align}
    \win_e &= \win[0:H_e,\, :], \\
    \wout_e &= \wout[:,\, 0:H_e].
\end{align}
    
With $\sigma$ as the activation function, the output $\by_e$ of the MLP layer corresponding to the expert $e$ can thus be obtained as, 
\begin{equation}\label{eq:expert}
    \by_e = \sigma \bp{ \bx \cdot \bp{ \win_e}^T  } \cdot \bp{ \wout_e}^T.
\end{equation}


% # Table
\input{sections/result_tables}


\subsection{Generating Token Difficulty Label}\label{subsec:generate_gt_label}

% \begin{figure*}[ht!]
%     \centering
%     \includegraphics[width=\textwidth]{sections/image/router_training.png} % Full page width
%     \caption{Router training in the proposed $\mname$ model.}
%     \label{fig:router_training}
% \end{figure*}

We aim to train a token-difficulty-aware router to dynamically assign tokens to an appropriate expert. But there is no ground-truth label denoting token difficulty to train such a router. To this end, we propose a method to estimate the token difficulty and generate a derived-ground-truth difficulty label during training. This is shown  as ``Token Difficulty Label Generator'' in Fig. \ref{fig:overview}. 

First, we pass the input to all experts and generate the output $\by_e$ for each $e \in [E]$. Then, for each token $b \in [B]$ and each expert $e \in [E]$, we compute a similarity score $S_{b,e}$ that measures how similar is the output of the expert $e$ compared to the output of the full MLP layer $e={E-1}$ for that token. We calculate this similarity as,
\begin{equation}
    S_{b,e} = \frac{\ip{\by_e[b,\,:]}{\by_{E-1}[b,\,:]}}{\ip{\by_{E-1}[b,\,:]}{\by_{E-1}[b,\,:]}}.
\end{equation}
Here, $\ip{\cdot}{\cdot}$ denotes the dot-product between two vectors. We use dot-product in this calculation as it accounts for both the magnitude and the direction of the tensors being compared.

Finally, we generate a derived ground-truth hardness label $l_b$, representing the target expert index for token $b$. Given a threshold $\theta$, we assign $l_b$ as the smallest expert index $e$ satisfying $S_{b,e} > \theta$, that is, $l_b=\min\{e \in [E] \mid S_{b,e}>\theta\}$. We say that a token is easier if it has a smaller label $l_b$, that is the similarity score for a smaller expert is higher than threshold $\theta$. In such cases, processing the token with the smaller expert incurs less compute without much compromise in the accuracy. During the forward pass of fine-tuning of $\mname$, we generate the token difficulty labels. These labels are then used in the backward pass to compute the router loss, which trains the router.

  

\subsection{Training a Token-Difficulty-Aware Router}
The output of a router is in $\R^{B \times E}$, denoting logits over the $E$ experts. Each router is parameterized by two linear layers, projecting the token embedding from dimension $D$ to $U$ and subsequently to $E$. In our experiments, we use $U=256$, resulting in total parameters added by the routers across all layers to $33.6M$, which is only $0.51\%$ of the base model size. 

We train the router using the derived labels from Section~\ref{subsec:generate_gt_label}. The objective is to learn the expert prediction using the derived-ground-truth labels to mimic token assignment based on their complexity and need. Hence, we impose the cross-entropy loss on the router to guide to this behavior and call it as the router loss. The overall objective function of $\mname$ is given as,
\begin{equation}\label{eq:loss}
    \L = \lambda_{LLM} \cdot \L_{LLM} + \lambda_{Router} \cdot \L_{Router}.
\end{equation}
Here, $\L_{LLM}$ is the main LLM Cross-entropy loss and $\L_{Router}$ is the router loss.  $\lambda_{LLM}$ and $\lambda_{Router}$ are hyper-parameters, denoting the weights of the respective losses.
