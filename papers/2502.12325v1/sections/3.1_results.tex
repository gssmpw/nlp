\subsection{Evaluation}
\label{subsec:Evaluation}
We evaluate the $\mname$ models on $7$ downstream tasks using LM Evaluation Harness \cite{eval-harness} and report the 0-shot non-normalized accuracy metric in Table~\ref{tab:result}. The selected evaluation tasks include ARC (Easy and Challenge) \cite{arc-c-e}, HellaSwag \cite{Zellers2019HellaSwagCA}, PIQA \cite{Bisk2019PIQARA}, SciQ \cite{SciQ}, WinoGrande \cite{Winograd}, and LAMBADA \cite{lambda}.

$\mname$ is compared to two baselines, the base Mistral 7B model and the Flextron model ~\citep{Cai2024FlextronMF} using Avg4 and Avg7 in Table \ref{tab:result}. Compared to Mistral 7B, $\mname$ with $\theta=0.8$ improves efficiency by activating only $5.1B$ of $7B$ parameters on average, with an $7.3$ point accuracy drop after fine-tuning on only $10B$ tokens on the downstream tasks. The number of activated parameters adapts dynamically to token difficulty. For reference, Flextron fine-tunes on $93.57B$ tokens, activating $4.1B$ of $6.5B$ parameters, with a $5$ point accuracy drop from its base model, Llama2-7B \cite{LLM2_LLama}. We emphasize that with only $\frac{1}{9}\text{th}$ of the Flextron's fine-tuning cost, our results  for $\mname$ with $\theta=0.7$  are comparable to Flextron. Accuracy improves with increase in fine-tuning cost, but to keep the adaption lightweight, we opt for a smaller cost.

% We evaluate the $\mname$ models on $7$ downstream tasks (Appendix~\ref{app:downstream_tasks}) using LM Evaluation Harness \cite{eval-harness} and report the 0-shot accuracy metric in Table~\ref{tab:result}. $\mname$ is compared to two baselines, the base Mistral 7B model and the Flextron model ~\citep{Cai2024FlextronMF}. Compared to the Mistral 7B base LLM, $\mname$ offers variants with different accuracy-efficiency trade-offs. At $\theta = 0.8$, $\mname$ achieves significant efficiency gains with minimal accuracy loss. For reference, we also include the Flextron results, which uses $93.57B$ tokens for fine-tuning and activates $63\%$ of the parameters with $6.7\%$ drop in accuracy compared to its base model, Llama2-7B \cite{LLM2_LLama}. We emphasize that with only $\frac{1}{18}\text{th}$ of the Flextron's fine-tuning cost, our results are comparable to Flextron.

\subsection{Analysis of Token-Difficulty-Aware Router}
We assess the performance of the Token-Difficulty-Aware router by gathering its predictions from all layers across the 7 downstream tasks outlined in Section \ref{subsec:Evaluation}. These predictions are then compared to the ground truth labels derived in Section \ref{subsec:generate_gt_label}. Using both sets of labels, we compute the router's overall classification accuracy. 

We present the confusion matrices for the router's classification tasks across all $\mname$ models in Fig. \ref{fig:router_confusion_matrix}. Notably, the matrices exhibit a strong diagonal pattern, indicating high classification accuracy. Furthermore, when the router misclassifies tokens, the errors predominantly occurred in neighboring expert classes, underscoring the router's effectiveness in distinguishing token difficulty levels.


\subsection{Experts usage analysis}
We visualize the expert usage patterns across all layers in  Fig. \ref{fig:cam_expert_load}. For each model, the Y-axis represents the percentage of tokens routed to a specific expert, while the X-axis indicates the layer index. Notably, a token's perceived difficulty may vary across layers, hence it can be routed to different experts as the token progresses through the model. The visualization shows that all experts are utilized in varying proportions across layers, reflecting an aggregated behavior over the $7$ tasks. However, during inference, the model adapts to the data, with simpler queries predominantly engaging lower-compute experts to maximize efficiency.


The parameter $\theta$ affects expert usage in $\mname$ models by controlling how quickly tokens are routed to larger experts based on difficulty. At lower $\theta$ values (e.g., $\theta=0.7$), smaller experts ($e=2$) dominate across layers, optimizing for efficiency. In contrast, at higher $\theta$ values (e.g., $\theta=0.9$), larger experts ($e=3$) are utilized more frequently, prioritizing accuracy over efficiency. This shift demonstrates $\theta$'s role in balancing computational resource allocation and prediction accuracy.


\textbf{Ablating the Router Loss}: 
To examine the router loss's role in expert allocation, we train a $\mname$ model without it, relying solely on the LLM loss to train the router. Tokens are routed using the routerâ€™s predicted expert indices without explicit difficulty supervision. The resulting expert usage pattern, shown in Fig. \ref{fig:nocam_gate}, reveals that the model converges to using specific experts per layer instead of dynamically allocating experts based on token difficulty. In contrast, when router loss is applied, expert usage adapts dynamically to token difficulty across layers.

% In the absence of router loss, Fig. \ref{fig:nocam_gate}, the model converges to using specific experts per layer instead of dynamically allocating experts based on token difficulty.