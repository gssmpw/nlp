\section{Related Work}
\subsubsection{Mechanistic Interpretability for IR framework} Previously, Probing was a widely used method to assess a model’s internal representations, aiming to identify specific concepts encoded by the network and localize the components responsible for such behaviors. This is typically achieved by training a lightweight classifier on top of the model's internal structures (e.g., embeddings or attention maps) to evaluate the information encoded in those layers [7, 10, 12, 13, 22, 30, 35, 37]. While probing reveals correlational information about what a model learns, it faces limitations when determining causal relationships or confirming whether these learned concepts are actively utilized during inference [1, 2]. 

In contrast, mechanistic interpretability methods go beyond correlation by offering a more detailed, causality-driven understanding of how internal components affect model behavior, which surpasses traditional explainable IR (XIR) techniques based solely on correlational insights. To provide a more granular understanding of internal model decision-making processes, Chen et al. propose the use of causal interventions to reverse engineer neural rankers, and demonstrate how mechanistic interpretability methods can be used to isolate components satisfying term-frequency axioms within a ranking model.

\subsubsection{Non-mechanistic Interpetablity for Bert-Base IR model internal mechanisms} Previous research has shown through probing that IDF is present in Bert-based IR model and query-document interaction is present in BERT-based IR models (Zhan et al. and Choi et al.). 

Choi adopts linear probing to investigate the internal mechanism of the model: by training a lightweight classifier on top of the model's internal structures (e.g., embeddings or attention maps) to evaluate the information encoded in those layers. Choi et al. showed that IDF information can be reliably extracted from BERT-based NRMs. However, probing experiments only established a correlation between certain internal signals and IDF but stopped short of confirming whether BERT-based NRMs explicitly compute or use IDF.  

Zhan et al. concludes that BERT aggregates document information to query token representations through their interactions in later layers, by showing that the removal of interactions from document to query results in those layers result in significant performance loss. However, Zhan et al. did not clearly define or explain “interaction” and “representation”, specifically what the document representation contains and how the model “aggregates doc information” because of the limits of probing and interaction ablation for analysis. Zhan et al. could only access by-layer importance but was unable to understand the interaction or representation construction through the attention mechanism or the feedforward network.

\begin{figure*}%[!ht]
    \centering
    \includegraphics[width=5in]{paperdiagrams/CircuitGeneral.pdf}
    \caption{}
    %\small\textsuperscript{3} We blur the face of the non-reading child in accordance with the participant consent form.
    \label{fig:your_label}
\end{figure*}
\subsubsection{Mechanistic Interpretability for IR framework and TF components} In contrast, mechanistic interpretability methods go beyond correlation by offering a more detailed, causality-driven understanding of how internal components affect model behavior, which surpasses traditional explainable IR (XIR) techniques based solely on correlational insights. 

To provide a more granular understanding of internal model decision-making processes, Chen et al. propose the use of causal interventions to reverse engineer neural rankers, and demonstrate how mechanistic interpretability methods can be used to isolate components satisfying term-frequency axioms within a ranking model. In particular, Chen et al. find Duplicate Token Heads that write the term frequency signal of the query token in the document to the residual stream for producing the ranking score. We adopt a similar methodology, extending it to investigate soft term frequency (soft-tf) in cross-encoders. Specifically, we analyze how soft-tf signals are generated and utilized in query-document interactions within cross-encoders to compute ranking scores.


While previous research has highlighted the presence of components analogous to those used in BM25, it remains unclear how these elements—such as traditional scoring features like TF and IDF, along with semantic matches—interact to compute relevance scores in neural ranking models (NRMs).

\end{comment}