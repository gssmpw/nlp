\section{Background and Related Work}
\label{ref:relwork}
	\subsection{Available Sensors and Data, and Constraints}\label{subsec:sensors-available}
	Ahangar et al.~\cite{Ahangar2021} provide a comprehensive list of currently available in-car sensors and their capabilities. 
	This includes 
	ultrasonic sensors (distant measurement to objects up to 3m away), radio detection and ranging (RADAR) (presence detection of and distance measurement to objects in a range of 5 to 200m, also usable for determining relative speed), light detection and ranging (LiDAR) (obstacle detection and mapping of environment up to 200m), cameras (environment surveillance, up to 250m), and GPS (position and speed measurement for navigation). 
	Currently available 3D map data includes road types, radius and slope data of curves, number of lanes and their width, road quality and hazards, restrictions such as speed limits and overtaking bans, crosswalks, and even traffic information~\cite{trafficData, DynamicPassPrediction}. 
	
	
	We intentionally limit ourselves to this existing information and %
	\textit{exclude} the following: 
	\begin{enumerate}
		\item \textit{Long-Range Opposite Lane Detection:} 
		Safe overtaking relies on reliable long-range detection of oncoming vehicles, but current in-vehicle sensors (range: 250m) fall short of the required range (up to 900m)~\cite{NCHRP_NAP23278}.
		\label{enum:constraints:range}
		
		\item \textit{Vehicle Communication:} Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure (V2I), and Vehicle-to-Everything (V2X) communication concepts exist, but they require widespread vehicle adoption and face technical challenges. 
		
		\item \textit{Aggregated Data from Connected Vehicles:} Using preceding connected vehicles to extend sensor range requires reliable communication and is not feasible under current conditions.
	\end{enumerate}
	
	
	
	
	\subsection{Existing Overtaking Assistants}\label{subsec:existing-assis}
	
	The literature on overtaking assistants and autonomous passing maneuvers is extensive.
	
	Toledo-Moreo et al.~\cite{Toledo2009} propose a cooperative overtaking prediction system. 
	Similar to our work, it is based on vehicle kinematics and road geometry. 
	However, this system communicates predictive information via mobile networks, including trajectory predictions of oncoming vehicles and relies heavily on vehicle-to-vehicle communication, which we exclude.
	Similarly, in~\cite{Han-Shue2006} each vehicle identifies potential collisions based on its own measurements and exchanges information regarding their locations, intentions, and other relevant details with other vehicles and infrastructure. 
	
	
	Hassein et al.~\cite{Hassein2019} develop a Passing Collision Warning System for trucks, using cameras and RADAR to detect oncoming vehicles and warn drivers of dangers during overtaking. 
	While promising, it requires sensor ranges beyond what is currently available, unlike our assistant, which operates within existing sensor ranges.
	
	
	
	
	Commercial vehicles offer automated overtaking assistants combining lane-keeping and lane change systems. 
	While some require user action to initiate the maneuver (turn signal activation~\cite{web:tesla:autopilot}, %
    looking in the side mirror~\cite{web:usatoday-bmw}), %
    others do not~\cite{web:mercedes-benz-scottsdale}. %
	Yet, to the best of our knowledge, these systems are designed for multi-lane freeways and do not assist with overtaking on roads with opposing traffic.
	Moreover, the driver must be able to take over control within a few seconds.
	


Yet, Hegeman et al.~\cite{Hegeman_Brookhuis_Hoogendoorn_2005} claim that an active assistant could handle most overtaking-related tasks. 
While they do not develop a complete system due to identified sensor limitations, they provide a comprehensive analysis of overtaking maneuvers.
We draw from their rich descriptions of the many important aspects of an overtaking assistant. 



Finally, Loewenau et al.~\cite{DynamicPassPrediction} present a passive system that uses vehicle dynamics and navigation data to identify unsuitable road segments for overtaking. 
While it does not rely on communication networks or sensors not yet available in cars, it does not consider oncoming traffic.
In contrast to our system, it does not rely on sight distance and lacks a user study. 
Yet, their use of navigation data, particularly road curvature, inspired elements of our approach.


\subsection{User Interfaces in Overtaking Assistants}\label{subsec:uis-in-existing-assistants}

Concerning the interfaces, we %
classify overtaking assistants into two groups. 
The first group are systems that overtake autonomously. 
Research in this setting has explored various aspects of Human-Machine Interfaces (HMI). 

Fank et al.~\cite{Frank2021} examined different HMI designs for cooperative overtaking between trucks on highways.
In these situations, speed differences are low, and a larger amount of information can be displayed, such as animated traffic flow, speed limits, active assistants, and more.
Yet, they identified a narrow margin between providing too much and too little information for drivers to accept the assistant. 
To address this, we investigate both a minimalistic \textit{monitoring-focused} UI focusing on essential information, and a more detailed \textit{scheduling-focused UI} that provides extended information.


Walch et al.~\cite{Walch2018,Walch2019} consider overtaking on country roads and thus a case closer to ours.
Their assistant overtakes autonomously once the driver approves the maneuver.
In a driving simulator, they compared two user approval and cancel methods. %
While participants preferred the assistant over manual overtaking, they tended to overlook rear traffic in more complex situations. 
This indicates a need for support in the critical decision-making phase. 


In contrast, our assistant emphasizes enhancing the driver's decision-making process before initiating any overtaking maneuver and falls into the second group of \textit{passive} assistants, whose 
main goal is to convey information to the driver regarding overtaking safety. 
User interaction happens by driving the car.
While Hassein et al.~\cite{Hassein2019} from Section~\ref{subsec:existing-assis} focus on the technical side and suggest a (possibly color-coded) "(Not) Safe to pass" text message at an unspecified location, Hegeman et al.~\cite{Hegeman2007} assume world knowledge and design a traffic light GUI placed to the right of the rear mirror. 
It lights up green or red, depending on whether overtaking is currently safe or not. 
Three seconds before changing its color, it starts blinking, allowing for some scheduling. 
We draw from the idea to enable \textit{scheduling} and \textit{monitoring}. 

Furthermore, gamified user interfaces have been explored, e.g., by Steinberger et al.~\cite{Steinberger2016}, suggesting higher user acceptance but also increased visual distraction. 
The reported increase in long eye glances, which is particularly dangerous on curvy country roads, made us hesitate to adopt this approach to our case.













\subsection{Passing Sight Distance \new{and the Point-of-no-return}}\label{subsec:psd}

Our assistant relies on a sight distance prediction model developed in this work. 
The required sight distance for safe overtaking, known as Passing Sight Distance (PSD), is widely studied for road design~\cite{Glennon1988NEWAI, harwood1989passing} and road marking~\cite{Valkenburg, Saito1984}. 
Haq et al.~\cite{HAQ2022255} use Glennon’s model~\cite{Glennon1988NEWAI} for computing the PSD for overtaking truck platoons.
However, all these models are designed for static evaluation, assuming a constant speed difference between overtaking and overtaken vehicle, neglecting acceleration.
Lieberman~\cite{Lieberman1982} introduces a model that includes acceleration, but it has been criticized for overestimating PSD by including the distance to a point-of-no-return, until which an overtaking maneuver can be aborted~\cite{NCHRP_NAP23278}. 
Our model incorporates aborting a maneuver, focusing on the PSD required at the point-of-no-return.

\new{There are several definitions of the point-of-no-return in literature: when vehicles are head to head~\cite{HASSAN1996453}, when their centers align~\cite{Saito1984}, or when the overtaken vehicle's rear bumper aligns with the overtaking vehicle's center~\cite{Valkenburg}.
Given the proximity of these definitions and no clear consensus in the literature, we follow Saito~\cite{Saito1984}, considering the maneuver committed once the vehicle centers align.}


Raj et al.~\cite{Abhishek2023} extend Glennon’s model by considering road gradient and tire friction, factors that influence acceleration. 
However, the lacking mathematical description of the longitudinal acceleration and the model's inability to adapt to dynamic traffic conditions greatly limit its applicability. 
Our assistant addresses these gaps by measuring real-time speed differences and explicitly including longitudinal acceleration.


In addition to calculating PSD at the point-of-no-return, our assistant needs to predict this critical point itself, rendering accurate acceleration models essential. 
We thus provide three such models with increasing complexity to enhance prediction accuracy in Section~\ref{subsec:acc-models} and compare them.