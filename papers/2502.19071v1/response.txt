\section{Related Works}
\label{sec:Related Works}
\subsection{DL-Based Automatic Modulation Recognition}
AMR is a key technology in communications signal processing **Sagias, "Automatic Modulation Classification"** that aims to automatically identify the modulation type of received signals. This technology has been widely applied in communication fields such as interference detection **Tugnait, "Modulation Recognition Using Cyclostationary Signatures"**, spectrum sensing **Huang, "Spectrum Sensing for Cognitive Radio Networks"**, and electronic countermeasures **Guo, "Electronic Countermeasures Using Deep Learning"**. With the rapid development of wireless communication technology, modern wireless communication scenarios have become more complex and the data volume has increased dramatically. Traditional experience-based manual feature extraction methods can no longer meet the requirements. Deep learning, with its strong feature extraction capabilities and advantages in processing large data sets, has gradually become the mainstream method in the AMR field **O'Shea, "Convolutional Radio Modulation Recognition Networks"**.

O'Shea et al.** **"Convolutional Radio Modulation Recognition Networks"** pioneered the approach of treating IQ radio signals as single-channel images of width 2, using a simple 2D convolutional network and fully connected layers for feature extraction and classification. They also published two public modulation signal datasets, laying the foundation for subsequent research. Chen et al.** **"Signal-to-Matrix Operator for Automatic Modulation Recognition"** further developed a framework that combined the signal-to-matrix (S2M) operator with a residual network, achieving collaborative optimization between input images and deep models. Although high recognition accuracy was achieved, the computational resource requirements were relatively demanding. Xu et al.** **"3D Deep Learning for Automatic Modulation Recognition"** proposed a novel 3D deep learning framework combining convolutional neural networks (CNN) and bidirectional long short-term memory (BiLSTM) models to extract joint features from I/Q symbols, successfully addressing the long-term dependency issue.

In addition, some researchers have attempted to combine deep learning with expert knowledge. For example, Ding et al.** **"Data- and Knowledge-Driven Modulation Recognition Method"** developed a data- and knowledge-driven modulation recognition method that significantly improved recognition performance in complex scenarios. Zhang et al.** **"Modulation Recognition Models Based on Parameter Estimation and Time-Frequency Distributions"** proposed novel modulation recognition models based on parameter estimation and time-frequency distributions. At the framework level, Qi et al.** **"Efficient Framework for Automatic Modulation Recognition Using Deep Residual Networks and Multi-Modal Information"** designed an efficient framework by combining deep residual networks with multi-modal information. These methods perform well in data-rich scenarios, but their performance drops significantly when sample sizes are small, limiting their practical value in real-world communication environments.

\subsection{Few-Shot Learning}
In modulation signal recognition, FSL is a challenging but crucial task, especially in cases of data scarcity or limited labeled data. Currently, FSL has made significant progress in areas such as image **Koch, "Siamese Neural Networks for One Shot Image Recognition"**, text **Yao, "Few-Shot Learning with Multiple Tasks and Multiple Data Sources"**, and audio **Salamon, "Unsupervised Feature Learning for Audio Classification"**. However, research in the field of modulation signal is still relatively sparse. Existing FSL methods can be broadly categorized into four types. 1) Methods based on prior knowledge: These methods introduce expert or domain knowledge to analyze the features, frequency, and other aspects of the signal to enable effective detection under few-shot conditions. 2) Data augmentation methods: These methods expand the sample size using data augmentation techniques, such as Generative Adversarial Networks (GANs) **Goodfellow, "Generative Adversarial Networks"**. Although GANs can generate high-quality samples, they face problems such as unstable training and limited generalization, particularly in few-shot scenarios where they are less applicable. 3) Methods based on model optimization: These approaches use a combination of pretraining and fine-tuning to improve model performance in few-shot scenarios through transfer learning. In addition, designing lightweight architectures specifically for few-shot problems is also an effective strategy. 4) Methods based on algorithm optimization: Methods such as meta-learning **Vinyals, "Matching Networks for One Shot Learning"** optimize learning algorithms to adapt to few-shot scenarios. Although theoretically attractive, these methods are often limited in practical applications due to the similarity of source datasets.

\subsection{Self-Supervised Contrast Learning}
Self-supervised learning, an important branch of unsupervised learning, learns effective representations from large amounts of unlabeled data by designing surrogate tasks. In recent years, it has shown outstanding performance in areas such as natural language processing **Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, computer vision **Dosovitskiy, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"**, and audio processing **Hershey, "Deep Learning Architectures for Audio Classification"**. Contrastive learning is one of the core methods of self-supervised learning, where it encourages the model to learn deep semantic features from the data by contrasting the similarity between positive and negative sample pairs.

Classical methods such as SimCLR **Chen, "A Simple Framework for Contrastive Learning of Visual Representations"** and MoCoV2 **He, "Momentum Contrast for Unsupervised Visual Representation Learning"** optimize contrast loss by using large positive and negative samples and dynamic queues, respectively, while BYOL **Lior, "Bootstrap Your Own Latent: Self-Supervised Learning from Noise"** and SwAV **Caron, "Unsupervised Learning of Visual Features by Contrasting Cluster Assignments"** improve performance by removing negative samples or introducing clustering ideas. In the time series domain, TS-TCC **Chen, "Temporal Contextual Contrastive Learning for Unsupervised Time Series Representation"** develops an unsupervised representation learning framework for sleep classification tasks using temporal and contextual contrast. Liu et al.** **"SimCLR for Electromagnetic Modulation Classification"** applied SimCLR to electromagnetic modulation classification and designed a semi-supervised framework. In addition, some studies focus on individual recognition and radio frequency fingerprinting, such as the SA2SEI framework** **Chen, "Self-Supervised Learning for Radio Frequency Fingerprinting"**, which overcomes data limitations by combining self-supervised learning and adversarial augmentation.

Despite the significant innovations of the above methods in time series, modulation signal modulation detection still faces challenges, such as high-dimensional data and the need for large labeled samples. Designing a framework that balances adaptability to complex scenarios with efficient use of data samples is an important direction for future research in this area.