\section{Related Works}
\label{sec:Related Works}
\subsection{DL-Based Automatic Modulation Recognition}
AMR is a key technology in communications signal processing____ that aims to automatically identify the modulation type of received signals. This technology has been widely applied in communication fields such as interference detection____, spectrum sensing____, and electronic countermeasures____. With the rapid development of wireless communication technology, modern wireless communication scenarios have become more complex and the data volume has increased dramatically. Traditional experience-based manual feature extraction methods can no longer meet the requirements. Deep learning, with its strong feature extraction capabilities and advantages in processing large data sets, has gradually become the mainstream method in the AMR field ____.

O'Shea et al.____ pioneered the approach of treating IQ radio signals as single-channel images of width 2, using a simple 2D convolutional network and fully connected layers for feature extraction and classification. They also published two public modulation signal datasets, laying the foundation for subsequent research. Chen et al.____ further developed a framework that combined the signal-to-matrix (S2M) operator with a residual network, achieving collaborative optimization between input images and deep models. Although high recognition accuracy was achieved, the computational resource requirements were relatively demanding. Xu et al.____ proposed a novel 3D deep learning framework combining convolutional neural networks (CNN) and bidirectional long short-term memory (BiLSTM) models to extract joint features from I/Q symbols, successfully addressing the long-term dependency issue.

In addition, some researchers have attempted to combine deep learning with expert knowledge. For example, Ding et al.____ developed a data- and knowledge-driven modulation recognition method that significantly improved recognition performance in complex scenarios. Zhang et al.____ proposed novel modulation recognition models based on parameter estimation and time-frequency distributions. At the framework level, Qi et al.____ designed an efficient framework by combining deep residual networks with multi-modal information. These methods perform well in data-rich scenarios, but their performance drops significantly when sample sizes are small, limiting their practical value in real-world communication environments.

\subsection{Few-Shot Learning}
In modulation signal recognition, FSL is a challenging but crucial task, especially in cases of data scarcity or limited labeled data. Currently, FSL has made significant progress in areas such as image____, text____, and audio____. However, research in the field of modulation signal is still relatively sparse. Existing FSL methods can be broadly categorized into four types. 1) Methods based on prior knowledge: These methods introduce expert or domain knowledge to analyze the features, frequency, and other aspects of the signal to enable effective detection under few-shot conditions. 2) Data augmentation methods: These methods expand the sample size using data augmentation techniques, such as Generative Adversarial Networks (GANs)____. Although GANs can generate high-quality samples, they face problems such as unstable training and limited generalization, particularly in few-shot scenarios where they are less applicable. 3) Methods based on model optimization: These approaches use a combination of pretraining and fine-tuning to improve model performance in few-shot scenarios through transfer learning. In addition, designing lightweight architectures specifically for few-shot problems is also an effective strategy. 4) Methods based on algorithm optimization: Methods such as meta-learning____ optimize learning algorithms to adapt to few-shot scenarios. Although theoretically attractive, these methods are often limited in practical applications due to the similarity of source datasets.

\subsection{Self-Supervised Contrast Learning}
Self-supervised learning, an important branch of unsupervised learning, learns effective representations from large amounts of unlabeled data by designing surrogate tasks. In recent years, it has shown outstanding performance in areas such as natural language processing____, computer vision____, and audio processing____. Contrastive learning is one of the core methods of self-supervised learning, where it encourages the model to learn deep semantic features from the data by contrasting the similarity between positive and negative sample pairs.

Classical methods such as SimCLR____ and MoCoV2____ optimize contrast loss by using large positive and negative samples and dynamic queues, respectively, while BYOL____ and SwAV____ improve performance by removing negative samples or introducing clustering ideas. In the time series domain, TS-TCC____ develops an unsupervised representation learning framework for sleep classification tasks using temporal and contextual contrast. Liu et al.____ applied SimCLR to electromagnetic modulation classification and designed a semi-supervised framework. In addition, some studies focus on individual recognition and radio frequency fingerprinting, such as the SA2SEI framework____, which overcomes data limitations by combining self-supervised learning and adversarial augmentation.

Despite the significant innovations of the above methods in time series, modulation signal modulation detection still faces challenges, such as high-dimensional data and the need for large labeled samples. Designing a framework that balances adaptability to complex scenarios with efficient use of data samples is an important direction for future research in this area.