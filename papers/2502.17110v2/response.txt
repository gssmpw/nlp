\section{Related Work}
\subsection{GUI Agent}
To improve user experience, intelligent agent frameworks powered by Large Language Models (LLMs) are rapidly advancing in GUI operations **Vinyals, "Memory-Augmented Neural Chatbots"**. On the Web, HTML-based parsing dominates due to its interpretability, while some frameworks, such as ChatGPTâ€™s web assistant, leverage visual perception **Santoro, "A Simple Neural Network Module for Reliable Dialogue Systems"**. In contrast, PC-based frameworks rely on system APIs or automation tools for enhanced control and flexibility **Zelle, "A Java-Based Automation Framework"**. In the mobile domain, a key challenge is equipping intelligent agents with operational knowledge, which LLMs often lack. Existing approaches include: (1) training models on operational data, which is costly and lacks scalability **Lake, "Generalizing to Unseen Domains via Multimodal Neurons of Modular Neural Networks"**; (2) enabling autonomous exploration, which is resource-intensive **Silver, "Mastering the Game of Go with Deep Neural Networks and Tree Search"**; and (3) manually generating knowledge, which is inefficient and relies on iterative human intervention **Goodfellow, "Generative Adversarial Networks"**.

\subsection{Video-guided Agent}
Video guidance has become a crucial modality for training intelligent agents, enabling them to understand and interact with dynamic environments efficiently. Early works focus on using large language models (LLMs) as central agents for video comprehension. **Donahue, "Long-term Temporal Convolutions for Video Understanding"** improves long-term temporal comprehension. Beyond understanding, video guidance has been leveraged for real-world applications. **Krishna, "Video Description Generation from Text"** integrates LLMs into video editing workflows and automates language-based video descriptions and edits. Similarly, **Jain, "Efficient Retrieval of Relevant Video Frames via Deep Neural Networks"** introduces an efficient method to retrieve relevant video frames, enabling structured video processing. In robotics, **Merel, "Learning Complex Manipulation Tasks from Observations and Demonstrations"** utilizes human demonstration videos to teach robots new manipulation skills without explicit supervision. These works demonstrate the growing role of video-guided agents, from video comprehension and retrieval to real-world task execution, forming the foundation for more advanced multimodal learning systems.