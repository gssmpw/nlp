[
  {
    "index": 0,
    "papers": [
      {
        "key": "wang2024gui",
        "author": "Wang, Shuai and Liu, Weiwen and Chen, Jingxuan and Gan, Weinan and Zeng, Xingshan and Yu, Shuai and Hao, Xinlong and Shao, Kun and Wang, Yasheng and Tang, Ruiming",
        "title": "Gui agents with foundation models: A comprehensive survey"
      },
      {
        "key": "liu2025llm",
        "author": "Liu, William and Liu, Liang and Guo, Yaxuan and Xiao, Han and Lin, Weifeng and Chai, Yuxiang and Ren, Shuai and Liang, Xiaoyu and Li, Linghao and Wang, Wenhao and others",
        "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zhou2023webarena",
        "author": "Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others",
        "title": "Webarena: A realistic web environment for building autonomous agents"
      },
      {
        "key": "deng2023mindweb",
        "author": "Xiang Deng and Yu Gu and Boyuan Zheng and Shijie Chen and Samuel Stevens and Boshi Wang and Huan Sun and Yu Su",
        "title": "Mind2Web: Towards a Generalist Agent for the Web"
      },
      {
        "key": "zheng2024gpt",
        "author": "Boyuan Zheng and Boyu Gou and Jihyung Kil and Huan Sun and Yu Su",
        "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded"
      },
      {
        "key": "he2024webvoyager",
        "author": "He, Hongliang and Yao, Wenlin and Ma, Kaixin and Yu, Wenhao and Dai, Yong and Zhang, Hongming and Lan, Zhenzhong and Yu, Dong",
        "title": "WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models"
      },
      {
        "key": "lu2024weblinx",
        "author": "L{\\`u}, Xing Han and Kasner, Zden{\\v{e}}k and Reddy, Siva",
        "title": "WebLINX: Real-World Website Navigation with Multi-Turn Dialogue"
      },
      {
        "key": "yoran2024assistantbench",
        "author": "Ori Yoran and Samuel Joseph Amouyal and Chaitanya Malaviya and Ben Bogin and Ofir Press and Jonathan Berant",
        "title": "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
      },
      {
        "key": "reddy2024infogent",
        "author": "Reddy, Revanth Gangi and Mukherjee, Sagnik and Kim, Jeonghwan and Wang, Zhenhailong and Hakkani-Tur, Dilek and Ji, Heng",
        "title": "Infogent: An agent-based framework for web information aggregation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhang2024ufo",
        "author": "Zhang, Chaoyun and Li, Liqun and He, Shilin and Zhang, Xu and Qiao, Bo and  Qin, Si and Ma, Minghua and Kang, Yu and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei and  Zhang, Qi",
        "title": "{UFO: A UI-Focused Agent for Windows OS Interaction}"
      },
      {
        "key": "tan2024towards",
        "author": "Tan, Weihao and Ding, Ziluo and Zhang, Wentao and Li, Boyu and Zhou, Bohan and Yue, Junpeng and Xia, Haochong and Jiang, Jiechuan and Zheng, Longtao and Xu, Xinrun and others",
        "title": "Towards general computer control: A multimodal agent for red dead redemption ii as a case study"
      },
      {
        "key": "xie2024osworld",
        "author": "Tianbao Xie and Danyang Zhang and Jixuan Chen and Xiaochuan Li and Siheng Zhao and Ruisheng Cao and Toh Jing Hua and Zhoujun Cheng and Dongchan Shin and Fangyu Lei and Yitao Liu and Yiheng Xu and Shuyan Zhou and Silvio Savarese and Caiming Xiong and Victor Zhong and Tao Yu",
        "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "hong2023cogagent",
        "author": "Wenyi Hong and Weihan Wang and Qingsong Lv and Jiazheng Xu and Wenmeng Yu and Junhui Ji and Yan Wang and Zihan Wang and Yuxiao Dong and Ming Ding and Jie Tang",
        "title": "CogAgent: A Visual Language Model for GUI Agents"
      },
      {
        "key": "cheng2024seeclick",
        "author": "Cheng, Kanzhi and Sun, Qiushi and Chu, Yougang and Xu, Fangzhi and Li, Yantao and Zhang, Jianbing and Wu, Zhiyong",
        "title": "Seeclick: Harnessing gui grounding for advanced visual gui agents"
      },
      {
        "key": "you2024ferret",
        "author": "You, Keen and Zhang, Haotian and Schoop, Eldon and Weers, Floris and Swearngin, Amanda and Nichols, Jeffrey and Yang, Yinfei and Gan, Zhe",
        "title": "Ferret-ui: Grounded mobile ui understanding with multimodal llms"
      },
      {
        "key": "zhang2024android",
        "author": "Zhang, Jiwen and Wu, Jihao and Teng, Yihua and Liao, Minghui and Xu, Nuo and Xiao, Xiao and Wei, Zhongyu and Tang, Duyu",
        "title": "Android in the zoo: Chain-of-action-thought for gui agents"
      },
      {
        "key": "chen2024octopus",
        "author": "Chen, Wei and Li, Zhiyuan",
        "title": "Octopus v2: On-device language model for super agent"
      },
      {
        "key": "lu2024gui",
        "author": "Lu, Quanfeng and Shao, Wenqi and Liu, Zitao and Meng, Fanqing and Li, Boxuan and Chen, Botong and Huang, Siyuan and Zhang, Kaipeng and Qiao, Yu and Luo, Ping",
        "title": "GUI Odyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices"
      },
      {
        "key": "chai2024amex",
        "author": "Chai, Yuxiang and Huang, Siyuan and Niu, Yazhe and Xiao, Han and Liu, Liang and Zhang, Dingyu and Gao, Peng and Ren, Shuai and Li, Hongsheng",
        "title": "Amex: Android multi-annotation expo dataset for mobile gui agents"
      },
      {
        "key": "rawles2024androidworld",
        "author": "Rawles, Christopher and Clinckemaillie, Sarah and Chang, Yifan and Waltz, Jonathan and Lau, Gabrielle and Fair, Marybeth and Li, Alice and Bishop, William and Li, Wei and Campbell-Ajala, Folawiyo and others",
        "title": "AndroidWorld: A dynamic benchmarking environment for autonomous agents"
      },
      {
        "key": "xu2024androidlab",
        "author": "Xu, Yifan and Liu, Xiao and Sun, Xueqiao and Cheng, Siyi and Yu, Hao and Lai, Hanyu and Zhang, Shudan and Zhang, Dan and Tang, Jie and Dong, Yuxiao",
        "title": "Androidlab: Training and systematic benchmarking of android autonomous agents"
      },
      {
        "key": "li2024effects",
        "author": "Li, Wei and Bishop, William E and Li, Alice and Rawles, Christopher and Campbell-Ajala, Folawiyo and Tyamagundlu, Divya and Riva, Oriana",
        "title": "On the effects of data scale on ui control agents"
      },
      {
        "key": "wan2024omniparser",
        "author": "Wan, Jianqiang and Song, Sibo and Yu, Wenwen and Liu, Yuliang and Cheng, Wenqing and Huang, Fei and Bai, Xiang and Yao, Cong and Yang, Zhibo",
        "title": "OmniParser: A Unified Framework for Text Spotting Key Information Extraction and Table Recognition"
      },
      {
        "key": "xing2024understanding",
        "author": "Xing, Mingzhe and Zhang, Rongkai and Xue, Hui and Chen, Qi and Yang, Fan and Xiao, Zhen",
        "title": "Understanding the weakness of large language model agents within a complex android environment"
      },
      {
        "key": "liu2024autoglm",
        "author": "Liu, Xiao and Qin, Bo and Liang, Dongzhu and Dong, Guang and Lai, Hanyu and Zhang, Hanchen and Zhao, Hanlin and Iong, Iat Long and Sun, Jiadai and Wang, Jiaqi and others",
        "title": "Autoglm: Autonomous foundation agents for guis"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yang2023appagent",
        "author": "Yang, Zhao and Liu, Jiaxuan and Han, Yucheng and Chen, Xin and Huang, Zebiao and Fu, Bin and Yu, Gang",
        "title": "Appagent: Multimodal agents as smartphone users"
      },
      {
        "key": "wang2024mobile",
        "author": "Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao",
        "title": "Mobile-agent: Autonomous multi-modal mobile device agent with visual perception"
      },
      {
        "key": "li2024appagent",
        "author": "Li, Yanda and Zhang, Chi and Yang, Wanqi and Fu, Bin and Cheng, Pei and Chen, Xin and Chen, Ling and Wei, Yunchao",
        "title": "Appagent v2: Advanced agent for flexible mobile interactions"
      },
      {
        "key": "wang2025mobile",
        "author": "Wang, Zhenhailong and Xu, Haiyang and Wang, Junyang and Zhang, Xi and Yan, Ming and Zhang, Ji and Huang, Fei and Ji, Heng",
        "title": "Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wang2024mobile2",
        "author": "Wang, Junyang and Xu, Haiyang and Jia, Haitao and Zhang, Xi and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao",
        "title": "Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "wang2024videoagent",
        "author": "Wang, Xiaohan and Zhang, Yuhui and Zohar, Orr and Yeung-Levy, Serena",
        "title": "Videoagent: Long-form video understanding with large language model as agent"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2024lave",
        "author": "Wang, Bryan and Li, Yuliang and Lv, Zhaoyang and Xia, Haijun and Xu, Yan and Sodhi, Raj",
        "title": "LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhang2024omagent",
        "author": "Zhang, Lu and Zhao, Tiancheng and Ying, Heting and Ma, Yibo and Lee, Kyusong",
        "title": "Omagent: A multi-modal agent framework for complex video understanding with task divide-and-conquer"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chane2023learning",
        "author": "Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan",
        "title": "Learning video-conditioned policies for unseen manipulation tasks"
      }
    ]
  }
]