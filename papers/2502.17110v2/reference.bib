% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{ye2023mplug,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}

@article{dai2023instructblip,
  title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
  journal={arXiv preprint arXiv:2305.06500},
  year={2023}
}

@article{liu2023improved,
  title={Improved Baselines with Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023}
}

@article{chen2023minigpt,
  title={MINIGPT-V2: LARGE LANGUAGE MODEL AS A UNIFIED INTERFACE FOR VISION-LANGUAGE MULTI-TASK LEARNING},
  author={Chen, Jun and Li, Deyao Zhu Xiaoqian Shen Xiang and Zhang, Zechun Liu Pengchuan and Xiong, Raghuraman Krishnamoorthi Vikas Chandra Yunyang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2310.09478},
  year={2023}
}

@article{bai2023qwen,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@article{ye2023mplugowl2,
  title={mplug-owl2: Revolutionizing multi-modal large language model with modality collaboration},
  author={Ye, Qinghao and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Liu, Haowei and Qian, Qi and Zhang, Ji and Huang, Fei and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.04257},
  year={2023}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

@article{lu2024deepseek,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}

@article{ye2024mplug,
  title={mplug-owl3: Towards long image-sequence understanding in multi-modal large language models},
  author={Ye, Jiabo and Xu, Haiyang and Liu, Haowei and Hu, Anwen and Yan, Ming and Qian, Qi and Zhang, Ji and Huang, Fei and Zhou, Jingren},
  journal={arXiv preprint arXiv:2408.04840},
  year={2024}
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{wu2024deepseek,
  title={Deepseek-vl2: Mixture-of-experts vision-language models for advanced multimodal understanding},
  author={Wu, Zhiyu and Chen, Xiaokang and Pan, Zizheng and Liu, Xingchao and Liu, Wen and Dai, Damai and Gao, Huazuo and Ma, Yiyang and Wu, Chengyue and Wang, Bingxuan and others},
  journal={arXiv preprint arXiv:2412.10302},
  year={2024}
}

@article{xu2024androidlab,
  title={Androidlab: Training and systematic benchmarking of android autonomous agents},
  author={Xu, Yifan and Liu, Xiao and Sun, Xueqiao and Cheng, Siyi and Yu, Hao and Lai, Hanyu and Zhang, Shudan and Zhang, Dan and Tang, Jie and Dong, Yuxiao},
  journal={arXiv preprint arXiv:2410.24024},
  year={2024}
}

@article{wang2024gui,
  title={Gui agents with foundation models: A comprehensive survey},
  author={Wang, Shuai and Liu, Weiwen and Chen, Jingxuan and Gan, Weinan and Zeng, Xingshan and Yu, Shuai and Hao, Xinlong and Shao, Kun and Wang, Yasheng and Tang, Ruiming},
  journal={arXiv preprint arXiv:2411.04890},
  year={2024}
}

@article{liu2025llm,
  title={LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects},
  author={Liu, William and Liu, Liang and Guo, Yaxuan and Xiao, Han and Lin, Weifeng and Chai, Yuxiang and Ren, Shuai and Liang, Xiaoyu and Li, Linghao and Wang, Wenhao and others},
  year={2025},
  publisher={Preprints}
}

@article{zhou2023webarena,
  title={Webarena: A realistic web environment for building autonomous agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2023}
}

@inproceedings{deng2023mindweb,
title={Mind2Web: Towards a Generalist Agent for the Web},
author={Xiang Deng and Yu Gu and Boyuan Zheng and Shijie Chen and Samuel Stevens and Boshi Wang and Huan Sun and Yu Su},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=kiYqbO3wqw}
}

@inproceedings{zheng2024gpt,
  title={GPT-4V(ision) is a Generalist Web Agent, if Grounded},
  author={Boyuan Zheng and Boyu Gou and Jihyung Kil and Huan Sun and Yu Su},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
  url={https://openreview.net/forum?id=piecKJ2DlB},
}

@article{he2024webvoyager,
  title={WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models},
  author={He, Hongliang and Yao, Wenlin and Ma, Kaixin and Yu, Wenhao and Dai, Yong and Zhang, Hongming and Lan, Zhenzhong and Yu, Dong},
  journal={arXiv preprint arXiv:2401.13919},
  year={2024}
}

@article{lu2024weblinx,
  title={WebLINX: Real-World Website Navigation with Multi-Turn Dialogue},
  author={L{\`u}, Xing Han and Kasner, Zden{\v{e}}k and Reddy, Siva},
  journal={arXiv preprint arXiv:2402.05930},
  year={2024}
}

@misc{yoran2024assistantbench,
      title={AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?},
      author={Ori Yoran and Samuel Joseph Amouyal and Chaitanya Malaviya and Ben Bogin and Ofir Press and Jonathan Berant},
      year={2024},
      eprint={2407.15711},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.15711},
}

@article{reddy2024infogent,
  title={Infogent: An agent-based framework for web information aggregation},
  author={Reddy, Revanth Gangi and Mukherjee, Sagnik and Kim, Jeonghwan and Wang, Zhenhailong and Hakkani-Tur, Dilek and Ji, Heng},
  journal={arXiv preprint arXiv:2410.19054},
  year={2024}
}

@article{zhang2024ufo,
  title={{UFO: A UI-Focused Agent for Windows OS Interaction}},
  author={Zhang, Chaoyun and Li, Liqun and He, Shilin and Zhang, Xu and Qiao, Bo and  Qin, Si and Ma, Minghua and Kang, Yu and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei and  Zhang, Qi},
  journal={arXiv preprint arXiv:2402.07939},
  year={2024}
}

@inproceedings{tan2024towards,
  title={Towards general computer control: A multimodal agent for red dead redemption ii as a case study},
  author={Tan, Weihao and Ding, Ziluo and Zhang, Wentao and Li, Boyu and Zhou, Bohan and Yue, Junpeng and Xia, Haochong and Jiang, Jiechuan and Zheng, Longtao and Xu, Xinrun and others},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2024}
}

@misc{xie2024osworld,
      title={OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments},
      author={Tianbao Xie and Danyang Zhang and Jixuan Chen and Xiaochuan Li and Siheng Zhao and Ruisheng Cao and Toh Jing Hua and Zhoujun Cheng and Dongchan Shin and Fangyu Lei and Yitao Liu and Yiheng Xu and Shuyan Zhou and Silvio Savarese and Caiming Xiong and Victor Zhong and Tao Yu},
      year={2024},
      eprint={2404.07972},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{hong2023cogagent,
      title={CogAgent: A Visual Language Model for GUI Agents}, 
      author={Wenyi Hong and Weihan Wang and Qingsong Lv and Jiazheng Xu and Wenmeng Yu and Junhui Ji and Yan Wang and Zihan Wang and Yuxiao Dong and Ming Ding and Jie Tang},
      year={2023},
      eprint={2312.08914},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{cheng2024seeclick,
  title={Seeclick: Harnessing gui grounding for advanced visual gui agents},
  author={Cheng, Kanzhi and Sun, Qiushi and Chu, Yougang and Xu, Fangzhi and Li, Yantao and Zhang, Jianbing and Wu, Zhiyong},
  journal={arXiv preprint arXiv:2401.10935},
  year={2024}
}

@article{rawles2024androidinthewild,
  title={Androidinthewild: A large-scale dataset for android device control},
  author={Rawles, Christopher and Li, Alice and Rodriguez, Daniel and Riva, Oriana and Lillicrap, Timothy},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{you2024ferret,
  title={Ferret-ui: Grounded mobile ui understanding with multimodal llms},
  author={You, Keen and Zhang, Haotian and Schoop, Eldon and Weers, Floris and Swearngin, Amanda and Nichols, Jeffrey and Yang, Yinfei and Gan, Zhe},
  booktitle={European Conference on Computer Vision},
  pages={240--255},
  year={2024},
  organization={Springer}
}

@article{zhang2024android,
  title={Android in the zoo: Chain-of-action-thought for gui agents},
  author={Zhang, Jiwen and Wu, Jihao and Teng, Yihua and Liao, Minghui and Xu, Nuo and Xiao, Xiao and Wei, Zhongyu and Tang, Duyu},
  journal={arXiv preprint arXiv:2403.02713},
  year={2024}
}

@article{chen2024octopus,
  title={Octopus v2: On-device language model for super agent},
  author={Chen, Wei and Li, Zhiyuan},
  journal={arXiv preprint arXiv:2404.01744},
  year={2024}
}

@inproceedings{li2024effects,
  title={On the effects of data scale on ui control agents},
  author={Li, Wei and Bishop, William E and Li, Alice and Rawles, Christopher and Campbell-Ajala, Folawiyo and Tyamagundlu, Divya and Riva, Oriana},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}
}

@inproceedings{xing2024understanding,
  title={Understanding the weakness of large language model agents within a complex android environment},
  author={Xing, Mingzhe and Zhang, Rongkai and Xue, Hui and Chen, Qi and Yang, Fan and Xiao, Zhen},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6061--6072},
  year={2024}
}

@article{rawles2024androidworld,
  title={AndroidWorld: A dynamic benchmarking environment for autonomous agents},
  author={Rawles, Christopher and Clinckemaillie, Sarah and Chang, Yifan and Waltz, Jonathan and Lau, Gabrielle and Fair, Marybeth and Li, Alice and Bishop, William and Li, Wei and Campbell-Ajala, Folawiyo and others},
  journal={arXiv preprint arXiv:2405.14573},
  year={2024}
}

@article{lu2024gui,
  title={GUI Odyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices},
  author={Lu, Quanfeng and Shao, Wenqi and Liu, Zitao and Meng, Fanqing and Li, Boxuan and Chen, Botong and Huang, Siyuan and Zhang, Kaipeng and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2406.08451},
  year={2024}
}

@article{chai2024amex,
  title={Amex: Android multi-annotation expo dataset for mobile gui agents},
  author={Chai, Yuxiang and Huang, Siyuan and Niu, Yazhe and Xiao, Han and Liu, Liang and Zhang, Dingyu and Gao, Peng and Ren, Shuai and Li, Hongsheng},
  journal={arXiv preprint arXiv:2407.17490},
  year={2024}
}

@inproceedings{wan2024omniparser,
  title={OmniParser: A Unified Framework for Text Spotting Key Information Extraction and Table Recognition},
  author={Wan, Jianqiang and Song, Sibo and Yu, Wenwen and Liu, Yuliang and Cheng, Wenqing and Huang, Fei and Bai, Xiang and Yao, Cong and Yang, Zhibo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15641--15653},
  year={2024}
}

@article{wang2024mobile,
  title={Mobile-agent: Autonomous multi-modal mobile device agent with visual perception},
  author={Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},
  journal={arXiv preprint arXiv:2401.16158},
  year={2024}
}

@article{wang2024mobile2,
  title={Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration},
  author={Wang, Junyang and Xu, Haiyang and Jia, Haitao and Zhang, Xi and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},
  journal={arXiv preprint arXiv:2406.01014},
  year={2024}
}

@article{yang2023appagent,
  title={Appagent: Multimodal agents as smartphone users},
  author={Yang, Zhao and Liu, Jiaxuan and Han, Yucheng and Chen, Xin and Huang, Zebiao and Fu, Bin and Yu, Gang},
  journal={arXiv preprint arXiv:2312.13771},
  year={2023}
}

@article{li2024appagent,
  title={Appagent v2: Advanced agent for flexible mobile interactions},
  author={Li, Yanda and Zhang, Chi and Yang, Wanqi and Fu, Bin and Cheng, Pei and Chen, Xin and Chen, Ling and Wei, Yunchao},
  journal={arXiv preprint arXiv:2408.11824},
  year={2024}
}

@article{liu2024autoglm,
  title={Autoglm: Autonomous foundation agents for guis},
  author={Liu, Xiao and Qin, Bo and Liang, Dongzhu and Dong, Guang and Lai, Hanyu and Zhang, Hanchen and Zhao, Hanlin and Iong, Iat Long and Sun, Jiadai and Wang, Jiaqi and others},
  journal={arXiv preprint arXiv:2411.00820},
  year={2024}
}

@article{wang2025mobile,
  title={Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks},
  author={Wang, Zhenhailong and Xu, Haiyang and Wang, Junyang and Zhang, Xi and Yan, Ming and Zhang, Ji and Huang, Fei and Ji, Heng},
  journal={arXiv preprint arXiv:2501.11733},
  year={2025}
}

@inproceedings{wang2024videoagent,
  title={Videoagent: Long-form video understanding with large language model as agent},
  author={Wang, Xiaohan and Zhang, Yuhui and Zohar, Orr and Yeung-Levy, Serena},
  booktitle={European Conference on Computer Vision},
  pages={58--76},
  year={2024},
  organization={Springer}
}

@inproceedings{wang2024lave,
  title={LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing},
  author={Wang, Bryan and Li, Yuliang and Lv, Zhaoyang and Xia, Haijun and Xu, Yan and Sodhi, Raj},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={699--714},
  year={2024}
}

@article{zhang2024omagent,
  title={Omagent: A multi-modal agent framework for complex video understanding with task divide-and-conquer},
  author={Zhang, Lu and Zhao, Tiancheng and Ying, Heting and Ma, Yibo and Lee, Kyusong},
  journal={arXiv preprint arXiv:2406.16620},
  year={2024}
}

@inproceedings{chane2023learning,
  title={Learning video-conditioned policies for unseen manipulation tasks},
  author={Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={909--916},
  year={2023},
  organization={IEEE}
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}
