\section{Related Work}
\subsection{GUI Agent}
To improve user experience, intelligent agent frameworks powered by Large Language Models (LLMs) are rapidly advancing in GUI operations \citep{wang2024gui,liu2025llm}. On the Web, HTML-based parsing dominates due to its interpretability, while some frameworks, such as ChatGPTâ€™s web assistant, leverage visual perception \citep{zhou2023webarena,deng2023mindweb,zheng2024gpt,he2024webvoyager,lu2024weblinx,yoran2024assistantbench,reddy2024infogent}. In contrast, PC-based frameworks rely on system APIs or automation tools for enhanced control and flexibility \citep{zhang2024ufo,tan2024towards,xie2024osworld}. In the mobile domain, a key challenge is equipping intelligent agents with operational knowledge, which LLMs often lack. Existing approaches include: (1) training models on operational data, which is costly and lacks scalability \citep{hong2023cogagent,cheng2024seeclick,you2024ferret,zhang2024android,chen2024octopus,lu2024gui,chai2024amex,rawles2024androidworld,xu2024androidlab,li2024effects,wan2024omniparser,xing2024understanding,liu2024autoglm}; (2) enabling autonomous exploration, which is resource-intensive \citep{yang2023appagent,wang2024mobile,li2024appagent,wang2025mobile}; and (3) manually generating knowledge, which is inefficient and relies on iterative human intervention \citep{wang2024mobile2}.

\subsection{Video-guided Agent}
Video guidance has become a crucial modality for training intelligent agents, enabling them to understand and interact with dynamic environments efficiently. Early works focus on using large language models (LLMs) as central agents for video comprehension. Extending this idea, \citep{wang2024videoagent} improves long-term temporal comprehension. Beyond understanding, video guidance has been leveraged for real-world applications. \citep{wang2024lave} integrates LLMs into video editing workflows and automates language-based video descriptions and edits. Similarly, \citep{zhang2024omagent} introduces an efficient method to retrieve relevant video frames, enabling structured video processing. In robotics, \citep{chane2023learning} utilizes human demonstration videos to teach robots new manipulation skills without explicit supervision. These works demonstrate the growing role of video-guided agents, from video comprehension and retrieval to real-world task execution, forming the foundation for more advanced multimodal learning systems.