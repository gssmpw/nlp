\section{RELATED WORKS}
Detecting approaches are divided into reconstruction-based, embedding-based and generation-based. Firstly, reconstruction-based methods \cite{zavrtanik2021draem,zavrtanik2021reconstruction} reconstruct normal images in the training stage, assuming that the model would reconstruct abnormal images with a large error, which is frequently contradicted during the test. Secondly, embedding-based methods \cite{ liu2023simplenet,zhang2023destseg,deng2022anomaly,roth2022towards} usually use a pre-trained network on ImageNet \cite{deng2009imagenet} to capture the high-level features of images. The anomaly score is then calculated by measuring the distance between the test sample and normal samples in the feature space. But industrial image features are different from natural images, so that directly using pre-trained features may cause a mismatch problem. Thirdly, generation-based methods \cite{niu2020defect,zhang2021defect,duan2023few,hu2024anomalydiffusion,jiang2024cagen} generate anomalous images to simulate potential deviations from the normal distribution as negative samples, which help the network learn to recognize and differentiate anomalous patterns more effectively.

Earliest generation-based methods DRAEM \cite{zavrtanik2021draem}, CutPaste \cite{li2021cutpaste} and NSA  \cite{schluter2022natural} augment normal samples by introducing abnormal patterns from patches within the same images or external texture dataset \cite{dtd2014accuracy}. But their generated samples often lack realism and diversity. Then GAN-based models like SDGAN \cite{niu2020defect}, DefectGAN \cite{zhang2021defect}, and DFMGAN \cite{duan2023few} train generative adversarial networks (GANs) \cite{goodfellow2020generative}  to produce anomalies by learning from real anomalies. Recently, text-guided approaches have emerged with the advancement of LDMs \cite{rombach2022high}. Anodiff \cite{hu2024anomalydiffusion} disentangles spatial information from anomaly appearance. CAGEN \cite{jiang2024cagen} combines the features of real anomalous features with normal samples using ControlNet \cite{zhang2023adding}.  Different with our method, these few-shot methods require real anomalies, and pay more attention on structural anomalies while ignore the logical anomalies.

Existing unsupervised generation-based methods towards logical anomalies include LogicalAL \cite{zhao2024logical} and GRAD \cite{dai2024generating}. LogicalAL manipulates edges and converts the modified edge map into image by using edge-to-image generator. GRAD removes self-attention and reduces network depth of U-Net architecture in the diffusion process to obtain local anomaly patterns. However, their generated anomalies visually differ from real anomalies and lack semantic interpretation, failing to capture the true nature of abnormal patterns which influence the performance of downstream detection task.

\begin{figure*}[t]
\centering
\includegraphics[width=1\textwidth]{pipeline_0916} % Reduce the figure size so that it is slightly narrower than the column.
\caption{The pipeline of ComGEN consisting of three stages: Anomaly Generation, Mask Generation and Anomaly Detection. \textbf{I.} Multi-Component Learning (MCL) disentangles image regions to align text tokens and components. Then Prompt Modifications (PM) and Low-density Sampling (LS) enhance generation. \textbf{II.} Reference Neighbor Association (RNA) searches the closest normal samples to anomalies, which are input to Residual Mapping (RM) together to generated masks. \textbf{III.} Their differential features are fed to Cross-Scale Difference Aggregation Module (CSDA) for model acceleration.}
\label{fig:pipeline}
\end{figure*}