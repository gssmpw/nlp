\section{Introduction}\label{sec:intro}
Over the past decade, substantial research has been devoted to fully observed
and regularly sampled time series, often referred to as regular (multivariate)
time series.
However, in certain scenarios, observations occur at irregular intervals
and variables are measured independently resulting in a sparse multivariate time series
with many missing values.
The resulting time series are known as irregularly sampled multivariate time series with missing values, or simply \textbf{IMTS}.

With regular time series forecasting being a well-established
topic, there exist a variety of sophisticated methods and standardized
benchmarks~\citep{Godahewa2021.Monasha, Gilpin2021.Chaosa,Bauer2021.Libra}.
On the other hand, there is currently no IMTS forecasting benchmark published.
Creating such a benchmark demands a high number of publicly available
time series datasets with genuinely irregular observation processes.
However, only a few of those exist. Although they are closely related
to each other, most evaluation sections of IMTS forecasting papers~\citep{Bilos2021.Neurald, Schirmer2022.Modelingb, Yalavarthi2024.GraFITi, Zhang2024.Irregular}
are based on at least a subset of these datasets.
Hence, it stands to reason that they induce a dataset bias.
Additionally, we show that a simple baseline, which always predicts a constant value independent of time, is competitive with or even outperforms complex neural ODE models on these datasets.
Hence, it appears questionable whether the currently used datasets are indeed well-suited for forecasting.

% How will we solve this
%\textbf{To extend and improve IMTS forecasting evaluation, we propose $\Bench$, the first benchmark especially
%tailored for IMTS forecasting.} It is build on the fact, that numerous natural
%processes in physics, chemistry, biology, and biochemistry are modeled using
%ordinary differential equations (ODEs).
%We derive IMTS datasets from ODEs
%by sampling the initial states, constants, observation time points and noise from
%a defined random distribution. This allows us to maintain complete control over
%the sampling process while ensuring the generated data retains a high degree of
%realism. To find well-suited ODE-models we rely on the Physiome~\citep{Yu2011.Physiome}
%repository. Physiome contains hundreds of ODE models, that were published in various
%subdomains of biology, so that we can leverage the results of decades-long research
%to create our datasets.

To address this limitation, we introduce \Bench, a wide benchmark of IMTS
datasets consisting of 50 individual datasets, derived from ordinary
differential equations from biological research, that are stored in the Physiome Model Repository (PMR).
Biological processes are well-suited for generating IMTS datasets, as they are inherently multivariate and irregularly measured in real-world experiments.
Additionally, the PMR provides Python implementations of many of these models, allowing us to create \Bench~in an automated manner.
While Biology researchers create their models based on very few and non-published observations,
they enable us to create an arbitrary number of time series which relate to possible measurements of a real-world phenomenon. 
\Bench~is the first benchmark for IMTS forecasting that we are aware of and an order of magnitude larger
than the current evaluation setting of just four datasets. 

Furthermore, to evaluate the complexity of the different forecasting datasets,
we introduce a simple metric called \emph{Joint Gradient Deviation ($\JGD$)}, which
measures the gradient variance of ODE solutions. We will show that
our benchmark consists of datasets of different complexity and covers a wide
range of different \emph{$\JGD$} values.

Finally, we evaluate current IMTS forecasting methods on $\Bench$ and
show that it includes many datasets on which neural ODE-based models significantly outperform
the time-constant baseline model. Furthermore, a member of the neural ODE
model family actually emerges as the overall most accurate model on \Bench.
However, the datasets in \Bench~are diverse enough that no single model is the most accurate for every dataset.

$\Bench$ is a significant step forward to standardized IMTS forecasting and to
monitor research progress.
Our contributions include the following:
\begin{enumerate}
\item We introduce a simple baseline model that is restricted to making
constant forecasts. On traditional IMTS forecasting
evaluation, this simple
baseline shows competitive or even better forecasting accuracy
when compared to ODE-based models.
\item We propose  \emph{Joint Gradient Deviation ($\JGD$)}, a simple score
designed to approximate the difficulty of
time series datasets for forecasting.
\item We create $\Bench$, a large and diverse benchmark of IMTS forecasting datasets.
Maximizing $\JGD$, we select and configure ODE models present in the Physiome~\citep{Yu2011.Physiome} repository.
$\Bench$ is the first benchmark for IMTS forecasting that we are aware of.
\item We evaluate state-of-the-art IMTS forecasting models on $\Bench$. 
Our experiments show that the datasets included in \Bench~are diverse enough to highlight different strengths of competing models. 
This results in different performance rankings of competing models for each dataset and the absence of a single best model. 
In that, \Bench~differs from the currently used IMTS forecasting datasets, which is expected to provide a fresh impulse to research
on IMTS forecasting models.
\item We share our code on GitHub (\url{https://anonymous.4open.science/r/Phyisiome-ODE-E53D})
\end{enumerate}

%Max proposal:
%\begin{itemize}
%    \item section 2: \emph{Related Work \& Benchmarks}
%    \item section 3: \emph{Methods for IMTS-Forecasting}
%\item section4: \emph{Time-constant Approaches Outperform ODE-based Approaches
%in the Current Evaluation Scenario}
%\item section5: \emph{\Bench: Deriving a IMTS Benchmark with Ordinal
%Differential Equations}
%\item section7: \emph{Neural-ODE-based Models are the SoTA on \Bench}
%\item section8: \emph{Conclusion and Future Work}
%\end{itemize}

% The time series literature differentiates in between two different types of sampling processes, which are known as regular
% and irregular. Regular (multivariate) time series that are created by a regular sampling process have equal distances in between
% observation time points and all channels are observed at all observation time points. On the other hand, the distance in between
% observation times vary in an irregular sampling process. The resulting time series are referred to as Irregularly sampled
% Multivariate Time Series (IMTS). Oftentimes, the channels of an IMTS are observed independently which results in many missing
% values and therefore a time series that is highly sparse when aligned.

% A rich and divers collection of datasets is vital for any field of machine learning research.
% It enables a fair performance comparison of different models, which supports the decision-making
% process in industry application of machine learning research. Furthermore, it can highlight
% specific strengths and short-comings of model architectures inspiring future research directions.

% % How is the problem solved now ? Why is it problematic ?

% Previous works proposed a variety of benchmark dataset collections for regular time series forecasting~\citep{Tay2020.Long}.
% However, for the IMTS domain nothing similar has been published yet. Instead, authors of IMTS forecasting
% models show the performance-wise advantages of their proposals on either synthetic toy examples or on
% a maximum of 4 real-world datasets \citep{Yalavarthi2023.Forecasting}. Out of these four datasets,
% three contain 48 hours of vital signs
% from intensive care unit patients. The forth dataset contains climate data and is artificially transformed into an
% IMTS by removing data from a fully observed and regularly sampled time series.
% Hence, the tiny dataset collection that is currently used for model evaluation contains very few
% and datasets which partially high similarity. Hence, it's unrealistic to anticipate that the
% experimental sections in recent studies adequately cover the diverse aspects of IMTS forecasting.

% % How do we solve this now ?

% We propose the $\Bench$, a collection of novel semisynthetic forecasting datasets that we created based on
% Ordinary Differential Equation (ODE) models published in various fields of the biology literature. By
% creating IMTS datasets with ODEs that model real-world processes, we have full control about the sampling
% process, while keeping a certain degree of realism. We vary the initial states
% and constants of each ODE model, to create the time series instances. The ODE implementions that we used to create our
% IMTS datasets are all present in the Physiome Repository. We selected and configured the ODE models based on
% a simple metric that ensures variance over time and in between samples.

% % What is the impact.
% Our benchmark dataset comprises 50 distinct datasets, each representing a unique biological process.
% While all these processes are rooted in biology, they originate from diverse sub-fields
% and exhibit significant variations among themselves. Therefore, our benchmark provides the necassary
% diversity within its datasets, which is shown by our experiments on the five different IMTS forecasting models.
% Our contributions are as follows:
% \begin{itemize}
%     \item We introduce $\Bench$ a novel IMTS benchmark containing 50 datasets
%     \item We evaluate the best available models on $\Bench$
% \end{itemize}
