\section{Prior Time Series Forecasting Benchmarks}\label{sec:related}
%It is important to note that the training data instances are not independent and identically distributed (i.i.d.).This is because a single long multivariate time series is split into training and testing sets. (not true I think)
% chayotic odes
\paragraph{Monash time series forecasting archive~\citep{Godahewa2021.Monasha}}
The Monash repository is the first benchmark for time series forecasting.
It encompasses 11 openly-accessible multivariate time series datasets drawn from various
domains, including energy, banking, and nature. Some of these datasets may include
missing values. However, the sampling process is regular.
Therefore, the missing values can easily be imputed, so that methods designed for regular
time series forecasting can be applied.
Hypothetically, we could use the 11 multivariate time series contained in
the Monash archive to create IMTS datasets for an IMTS forecasting benchmark.
However, most of these multivariate datasets are actually multiple
univariate time series stacked on top of each other and/or a single
long time series that is segmented to create multiple time series instances.
Other datasets used to evaluate regular multivariate time series
forecasting~\citep{Nie2023.Time,Zeng2023.Are,Zhou2021.Informera},
are not well-suited for IMTS forecasting for similar reasons. In fact,
\citet{Nie2023.Time} showed that models benefit, when they ignore channel
correlations, hinting that these are barely carrying useful information in the
respective datasets. In IMTS forecasting however, modeling these channel correlations
is a crucial property of the models, due to the high number of missing values.

\paragraph{Chaotic ODEs benchmark for time series forecasting}
Closely related to \Bench, \citet{Gilpin2021.Chaosa} provides a forecasting benchmark
created with chaotic ordinary differential equations that mainly originate from Physics.
Similar to the Monash repository, each chaotic ODE creates single long trajectory, without
varying the constants. In contrast, \Bench~contains 2000 different trajectories with varying
constants and initial states.
Furthermore, the inherent chaotic nature of these equations often presents a forecasting
challenge, even in the regularly sampled and fully observed forecasting setting.
On the other hand, IMTS forecasting is challenging due to the sparse observation of a time series.
We assume that combining these two factors of difficulty, would surpass any current methods
forecast modeling ability. This is closely related to what we observe on the most difficult
dataset of \Bench. We support our assumption, by an example experiment
on the Lorenz-attractor, a famous chaotic ODE, which is a part of \citet{Gilpin2021.Chaosa}'s
benchmark. Respective experimental details are given in \Cref{app:lorenz} and results
in \Cref{tab:lorenz}. Similarly, to certain \Bench~datasets with a high $\JGD$
(e.g.\ DUP01), no method can significantly outperform the simple baseline GraFITi-C.

\paragraph{PDEBench~\citep{Takamoto2022.Pdebencha}}
Related to applying differential equations to create datasets, there exists a benchmark with 11 spatio-temporal datasets named PDEBench.
Here, models are trained to estimate the parameters of an underlying partial differential equation (PDE) used to generate such dataset, instead of forecasting.
Current IMTS forecasting architectures cannot utilize the spatio-temporal information inherent in PDEBench's datasets.
