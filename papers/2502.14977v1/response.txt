\section{Related Work}
\vspace{-5pt}
{\bf Species Distribution Modeling}. 
Estimating the spatial distribution of a species is a widely explored topic both in statistical ecology and machine learning **Hastie, "Statistical Models for Spatial Data"**. 
The goal is to develop models that can predict the  distribution of species over space, and possibly time, given sparse observation data. 
Different machine learning approaches using traditional techniques such as decision trees have been extensively explored **Breiman, "Classification and Regression Trees"**. 
More recently, alternative deep learning-based methods have been introduced **Goodfellow et al., "Deep Learning"**. 
One of the strengths of these deep methods is that they can jointly represent thousands of different species inside of the same model and have been shown to improve as more training data is added, even when the data is from different species as in SINR **Chen et al., "SINR: A Deep Learning Framework for Species Distribution Modeling"**. 

There has also been work investigating different approaches for addressing some of the challenges associated with training and evaluating these models.  
Examples include attempts to addresses imbalances across species in the training observation data **Phillips et al., "Species Distribution Modelling Using Presence-Only Data: A Review"**, methods for sampling pseudo-absence data **Lobo et al., "Bias Correction in Ecological Meta-Analysis: Estimation of Prevalence from Unbalanced Datasets"**, biases in the training locations **Dormann et al., "Causal Relationships between Environmental and Spatial Controls of Species Distribution Models"**, representing location information **Elith et al., "Novel Methods Improve Prediction of Species' Distributions from Occurrence Data"**, discretizing continuous model predictions **Liu et al., "A Hierarchical Approach to Model-Based Clustering for High-Dimensional Continuous Data"**, active learning approaches **Settles, "Active Learning Literature Survey"**, using additional metadata such as images **Wade et al., "Species Distribution Modelling Using Image Features and Active Learning"** or text **Huang et al., "Zero-Shot Species Range Estimation from Text Descriptions"**, and designing new evaluation datasets to benchmark performance **Elith et al., "A Comparison of Methods for the Analysis of Presence-Only Data in Ecological Models"**. 
In our work, we investigate the under-explored few-shot setting, where only limited observations (\eg fewer than ten) are available for each species at training time.

{\bf Few-shot Species Range Estimation}. 
There are several aspects of the species range estimation task in the low data regime that makes it different from other few-shot problems more commonly explored in the literature **Bui et al., "Few-Shot Learning for Species Distribution Modeling"**. 
For one, the input domain is fixed (\ie all locations on earth), each location can support more than one species (\ie multi-label instead of multi-class), the label space is much larger (\ie tens of thousands of species as opposed to hundreds of classes in image classification), and only partial supervision is available (\eg presence-only data, with no confirmed absences). 

**Girardeau et al., "Active Learning for Species Range Estimation"** introduced an active learning-based approach for species range estimation which makes predictions based on linear combinations of learned species embeddings and showed its effectiveness in the few-shot regime. 
LE-SINR **Huang et al., "Learning to Estimate Species Ranges with Limited Data"** showed that internet sourced free-form text descriptions of species' ranges can be used to train models for zero-shot range estimation. 
They applied their approach to the few-shot setting, but it requires retraining a classifier for each new species observation added. 
In our evaluation, we demonstrate that our \modelname approach, which can incorporate additional metadata at training time and does not require any retraining during inference, outperforms existing methods.  



\vspace{-8pt}