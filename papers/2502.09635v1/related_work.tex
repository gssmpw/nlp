\section{Related Work}

\textbf{Multi-hop fact-checking.} Complex claims usually require reasoning over multiple evidence sentences. Many methods are based on Language Models \cite{transformer,bert} and Graph Neural Networks \cite{graphsage}, such as GEAR \cite{gear}, KGAT \cite{kgat}, DREAM \cite{dream}, SaGP \cite{sagp}, DECKER \cite{decker}, CausalWalk \cite{causalwalk}, etc. However, they mainly focus on the reasoning within evidence sentences. They ignore the auxiliary contextual and referential documents. Methods incorporating contextual documents are proposed, e.g., ParagraphJoint \cite{paragraphjoint}, ARSJoint \cite{arsjoint}, MultiVerS \cite{multivers}, etc. Some others integrating referential documents include Transformer-XH \cite{transformer_xh} and HESM \cite{hesm}. However, they incorporate either contextual or referential documents, but not both. In contrast, we construct a three-layer evidence graph to model evidence sentences, contexts, and references. There are fake news detection models where auxiliary graph with Wikidata is used \cite{fake_news_detection,fake_news_detection2}. Fake news detection aims to detect the whole article with meta-data, while fact-checking focuses on claim sentences with retrieved evidence.

Some fact-checking works are based on retrieval-augmented generation \cite{justilm}. They unify evidence retrieval and claim verification as a joint approach, while our model mainly focuses on verification, and relies on external tool for evidence retrieval. Our setting is consistent with existing works \cite{multivers,causalwalk}.

\textbf{Prompt-based fact-checking.} Some models verify claims by prompting LLMs \cite{gpt4}. ProToCo \cite{protoco} inputs both evidence sentences and claim to T5 \cite{t5}. ProgramFC \cite{programfc} decomposes complex claims into simpler sub-tasks and uses natural language to prompt LLMs. Varifocal \cite{varifocal} formulates fact-checking as question generation and answering. They rely on handcrafted natural language as prompt. The performance heavily relies on the choice of prompt, and it is difficult to design a prompt that produces a decent result, as shown in \cite{coop}. Our model is designed with learnable prompt embeddings where the prompting instruction is naturally learned by embeddings through optimization.

\textbf{Prompt learning.} Prompting \cite{prompting} uses natural language as the input to language models to fulfill certain tasks. Many prompting models have been proposed, including natural language prompt \cite{discrete_prompting,discrete_prompting2} and prompt embeddings \cite{soft_prompting,p_tuning,p_tuning_v2,prefix_tuning}. Prompting also benefits many tasks \cite{cocoop,machine_translation}. However, no one has explored prompt embeddings for fact-checking.

\textbf{Text-attributed graph.} Texts are usually connected in a graph structure, termed text-attributed graph \cite{tag_survey}. Various methods have been developed to learn text embeddings in an unsupervised manner \cite{adjacent_encoder,dbn,semivn,hgtm,graphformers,patton,hypformer}. Though both our model and these works construct a text-attributed graph, our work is different from them, since our model is a supervised model for fact-checking.