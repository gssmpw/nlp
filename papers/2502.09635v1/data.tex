\section{Dataset Preprocessing Details}
\label{sec:dataset_preprocessing}

Here we present details of dataset preprocessing.

\textbf{FEVEROUS}\footnote{\url{https://fever.ai/dataset/feverous.html}} \cite{feverous} is a general-domain dataset, and each claim is annotated in the form of sentences and/or cells from tables in Wikipedia pages. In this paper we mainly focus on textual evidence sentences, thus we follow ProgramFC \cite{programfc} and obtain claims that only require textual evidence for verification, and name this subset \textbf{FEVEROUS-S}. Claims in this dataset have two labels only, SUPPORT and REFUTE. In the original dataset, each evidence sentence may contain hyperlinks to other Wikipedia pages, and such hyperlinks in sentences are indicated with double square brackets. We thus retrieve words or phrases inside double square brackets, and use them as entries to query Wikipedia dump to obtain their corresponding pages as referential documents. FEVEROUS uses the December 2020 dump, including 5.4 million full Wikipedia articles. If a Wikipedia page has overly many sentences, we reserve its top-20 sentences, since almost all the evidence sentences appear within top-20 sentences in FEVEROUS. Similarly, the full content of the Wikipedia page is contextual document of each evidence sentence. If a page has overly long content, we reserve its top-20 sentences.

\textbf{BearFact}\footnote{\url{https://www.ims.uni-stuttgart.de/en/research/resources/corpora/bioclaim/}} \cite{bear_fact} is a biomedical claim verification dataset. Evidence sentences are obtained from paper abstracts in PubMed database\footnote{\url{https://pubmed.ncbi.nlm.nih.gov/}}. Original dataset does not provide evidence sentences for claims in NEI class. Thus we follow existing work \cite{protoco} and select evidence sentences that have the highest \textit{tf-idf} similarity with claims as their evidence. We consider the full abstract as the contextual document for each evidence sentence, as in MultiVerS \cite{multivers}. In addition, we use S2ORC \cite{s2orc} to obtain cited papers with abstracts as referential documents. Specifically, the original dataset provides PubMed ID for each evidence sentence. We use PubMed IDs as identifiers to search in S2ORC database and obtain cited papers. If a paper has overly many citations, we reserve its top-20 citations to avoid data redundancy.

\textbf{Check-COVID}\footnote{\url{https://github.com/posuer/Check-COVID/tree/main/Check-COVID}} specifically focuses on COVID-19 claims taken from news articles. Each evidence sentence is from a paper abstract with CORD ID as identifier. We thus use CORD IDs to search in S2ORC database and obtain cited papers. Similarly, we consider the full abstract as contextual document. The original dataset provides sentences for claims in NEI class.

\textbf{SciFact}\footnote{\url{https://github.com/allenai/scifact/tree/master}} \cite{scifact} is another biomedical fact-checking dataset with sentences in paper abstracts as evidence. Similarly, the full content of the abstract is considered as contextual document. In addition, each evidence sentence is coupled with S2ORC ID, which is used to obtain its citations using S2ORC database. The original dataset does not have sentences for claims in NEI class. Thus we follow the original paper \cite{scifact} and choose top-3 sentences in the same abstract with the highest \textit{tf-idf} similarity with the claim as evidence.