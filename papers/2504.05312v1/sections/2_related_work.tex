\input{images/1_framework}
\section{Related Work}
\paragraph{Open-domain 
 QA}
 Open-domain Question Answering (OpenQA)~\cite{voorhees1999trec} seeks to provide answers to questions expressed in natural language that are not restricted to a specify domain. Modern methods for Open QA tasks typically adopt the Retriever-and-Reader framework~\cite{chen2017reading,wang2024self}. With the advancement of open-domain QA, multi-hop QA ~\cite{joshi2017triviaqa,yang2018hotpotqa} and long-form ~\cite{stelmakh2022asqa,lyu2024crud} have gradually emerged. This more complex QA further necessitates the system to extensively collect and contextualize from the multiple documents (typically through iterative processes) in order to address more intricate queries. In particular, ~\cite{khot2022decomposed,khattab2022demonstrate} suggested breaking down multi-hop queries into simpler single-hop queries, iteratively utilizing LLMs and the retriever to address these sub-queries, and then combining their results to construct a comprehensive answer. Unlike the decomposition-based method, other recent studies, such as ~\cite{yao2022react} and ~\cite{trivedi2022interleaving}, explored a technique that creates a logical sequence of reasoning steps with document retrieval. Additionally, ~\cite{jiang2023active} proposed a method that involves iteratively fetching new documents when the tokens in the generated sentences exhibit low confidence, and ~\cite{jeong2024adaptive} proposed a retrieval strategy based on the complexity of the questions. However, The methods mentioned above neglect both the quality of retrieved documents and the generation of memory. Therefore, it is essential to propose a method aimed at enhanceing the quality of both retrieval and memory generation.
\paragraph{Retrieval-Augmented Generation.}
RAG has become essential for enhancing the response quality of large language models (LLMs). Early strategies~\cite{izacard2023atlas} relied on single-time retrieval, inputting the retrieved passages directly into LLMs to generate answers. However, these methods often fell short in complex tasks like multi-hop and long-form question answering, failing to capture sufficient information. To address these limitations, multi-time retrieval ~\cite{trivedi2022interleaving,borgeaud2022improving} was explored, though it risked incorporating irrelevant data, leading to poor-quality responses. This led to the development of Adaptive RAG (ARAG), which dynamically adjusts retrieval strategies based on real-time feedback, determining optimal retrieval times and content. Key innovations include Flare~\cite{jiang2023active}, which triggers new retrievals for low-confidence tokens, and Self-RAG~\cite{asai2023self}, which uses self-reflective markers to assess content quality. These adaptive approaches enhance retrieval relevancy and accuracy, while agent-based models like ReAct~\cite{yao2022react} further augment RAG's flexibility and intelligence. Nevertheless, we argue that the above methods overlook the quality issues in both retrieval and agent generation, resulting in inaccurate answers.





% \paragraph{Memory in Retrieval-Augmented Generation.}
% Effective memory mechanisms are crucial for advancing the capabilities of Retrieval-Augmented Generation (RAG) systems. Initial approaches~\cite{li2022anterior,smith2022limbic} often relied on simple context windows, struggling with long-term dependencies and consistency across turns. To overcome these challenges, more sophisticated memory integrations~\cite{chen2023chatgpt,wilson2024generative} have been explored, though they sometimes faced difficulties in selectively recalling relevant information. This prompted the development of Adaptive Memory RAG (AM-RAG), which dynamically manages and retrieves information from memory based on the evolving dialogue context and task requirements. Notable methods include MemFormer~\cite{wang2024memoryllm}, which uses transformer-based memory networks for contextual recall, and RecoRAG (Kim et al., 2024), which leverages reinforcement learning to optimize memory retrieval policies. These adaptive strategies enhance the system's ability to maintain coherent and contextually appropriate responses, reduce reliance on immediate context, and improve the efficiency of information utilization, while agent-based architectures like MemoryBot (Garcia et al., 2023) further enhance RAG's capacity for persistent and interactive knowledge management.




