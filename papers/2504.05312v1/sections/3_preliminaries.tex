% \section{Preliminaries}
% \subsection{Problem Formulation}
% Retrieval-Augmented Generation (RAG) aims to enhance the generation quality of LLMs by integrating relevant information from an external document corpus \(D = \{d_1, d_2, \dots, d_n\}\). Given a user input \(x\) or a query \(q\), the core of RAG involves using a retriever \(R\) to identify and select a subset of pertinent documents from \(D\). The LLM then leverages both the original input and these retrieved documents to produce an improved output. Generally, this process seeks to achieve an output \(y\) based on the input and retrieved context.

% \subsection{Single-time RAG}

% Single-time RAG represents the most fundamental implementation of the RAG paradigm. Following the problem formulation, for a given query \(q\), the retriever \(R\) performs a single retrieval operation over the document corpus \(D\) to obtain a set of relevant documents \(D_q\). This retrieval step can be formalized as: \(D_q = R(q, D)\). Subsequently, these retrieved documents \(D_q\), along with the original query \(q\), are fed into the LLM in a single pass to generate the final answer \(a\). This generation process is represented as: \(a = LLM([q, D_q])\). The key characteristic of Single-time RAG is its one-shot retrieval and generation process, effectively augmenting the LLM with immediate external knowledge. Various established retrieval models can be employed as the retriever \(R\) (Robertson et al., 1994; Karpukhin et al., 2020).

% \subsection{Adaptive RAG}

% While Single-time RAG offers a direct way to incorporate external knowledge, its effectiveness can be limited for complex queries that require deeper reasoning or information synthesis from multiple sources. Adaptive RAG addresses these limitations through a dynamic, iterative approach. In Adaptive RAG, the LLM interacts with the retriever \(R\) in multiple rounds. Starting with the initial query \(q\), at each step \(i\), the retriever \(R\) retrieves new documents \(d_i\) from \(D\) based on the current query and accumulated context. The retrieval at step \(i\) can be represented as: \(d_i = R(q, c_i; D)\), where \(c_i\) represents the contextual information built from previously retrieved documents and generated outputs: \(c_i = (d_1, d_2, ..., d_{i-1}, a_1, a_2, ..., a_{i-1})\). The LLM then generates an output \(a_i\) based on the original query \(q\), the newly retrieved document \(d_i\), and the context \(c_i\): \(a_i = LLM(q, d_i, c_i)\). This iterative interaction allows the model to refine its understanding and gather relevant information incrementally, making it more suitable for complex, multi-hop reasoning. However, it's important to note that this approach typically incurs higher computational costs due to the repeated calls to the retriever \(R\) and the LLM.
