\section{Related work}
\subsubsection{Clustering-based models}
    Clustering-and-then-model is the mainstream practice in dealing with heterogeneous time series forecasting. ____ exploited $k$-means algorithms and series features on trends, seasonality, and autocorrelation to conduct feature-based clustering. The series within each cluster are subsequently employed to train a cluster-specific model. ____ investigated feature-based clustering, distance-based clustering, and random clustering, where dynamic time warping (DTW) distances were considered. They trained multiple global models for each cluster of the series by changing the number of clusters and cluster seeds and an ensemble model was constructed to generate final forecasts. ____ added one adaptable Channel Clustering Module in the neural network and realized dynamic Euclidean distance-based clustering using radial basis function kernels to measure the series similarities. ____ utilized model-based clustering and they assumed the distributions of the data are obtained by AR processes. The forecasting model is integrated into the clustering, but cluster-specific models and the number of clusters have to be given in advance. While ____ considered a model-and-then-clustering mechanism and proposed an algorithm named TSAVG. Specifically, local models are first estimated on each time series independently, and then DTW distances were calculated to determine neighbors of the target series. The forecasting model of the target series is the average of local models built on its neighbors.
    
    \subsubsection{Local-global hybrid models}
    To take advantage of superiority of both local and global models, some local-global hybrid models have been introduced. ____ averaged the forecasts obtained by a traditional Theta method and a global model using equal weights. Alternatively, some outputs of the local model can be used as inputs fed into the global model, such as the last fitted value or the running level of the series specified by local exponential smoothing ____. Besides, ____ proposed a hybrid method of exponential smoothing and RNNs, that is, local characteristics of each series were specified using exponential smoothing methods and then a global RNN was used to model the remaining homogeneous parts shared by the entire dataset. This hybrid model won the first place of the M4 forecasting competition ____.
    
    There is also some work combining linear models such as exponential smoothing and autoregressive integrated moving average (ARIMA) methods and non-linear models such as neural networks parallelly or serially, see ____. However, these hybrid models are built on one single time series instead of a dataset containing multiple relevant series, which are out of scope of this paper.
    
    \subsubsection{Error correction models}
    Error correction is a technique to improve forecasting accuracy by residual modelling. It adds a correction procedure after the classical forecasting approach, during which the remaining residuals are modelled recursively until they are while noises. ____ used ARIMA approaches to recursively correct the forecasts obtained by neural networks, and discussed additive error models and multiplicative error models. While ____ considered conducting linear models such as ARIMA first and then using non-linear models including Support Vector Regression (SVR) and LSTM to correct errors and improve accuracy.
    
    Although the practice has similarities to the two-stage model proposed in this paper, the error correction is only applied in the scenario of one single time series and emphasizes a recursive combination of a series of linear and non-linear models. Its aim is to correct errors and adjust forecasts while the aim of this paper is to identify and model heterogeneity among multiple time series.