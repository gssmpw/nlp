\section{Related Work}
\subsection{Mathematical Benchmarks}
% Recent research has seen significant advancements in mathematical reasoning benchmarks aimed at evaluating mathematical abilities. In this summary, we review both pure text and multimodal math benchmarks.
%gao2024omni，glazer2024frontiermath
GSM8K____ is a dataset from OpenAI that includes 8.5K high-quality elementary school math word problems, each requiring 2 to 8 steps to solve. These problems primarily involve basic arithmetic operations such as addition, subtraction, multiplication, and division. MATH____ offers a dataset of 12,500 problems sourced from high school math competitions. SuperCLUE-Math____ is a Chinese benchmark for multi-step reasoning in mathematics, containing over 2,000 problems that require multi-step reasoning and offer natural language solutions. MathBench____ includes 3,709 math problems ranging from basic arithmetic to college-level questions, covering multiple difficulty levels. As LLMs have progressively achieved extremely high accuracy on existing mainstream benchmarks (e.g., MATH, GSM8K), it is critical to propose benchmarks that are more challenging for LLMs. Omni-MATH____ contains 4428 Olympiad-level math problems sourced from international competitions with rigorous manual annotations. All these problems are categorized into 33 sub-domains in detail, spanning 10 difficulty levels. FrontierMath____ is a mathematical benchmark constructed by leading mathematicians, aiming to push AI towards expert-level capabilities. Even the best models solving less than 2\% of problems. It comprises hundreds of purely original, challenging, expert-level mathematical problems covering a broad spectrum of modern mathematical subjects, minimizing the possibility of data contamination. PRMBench____ is a benchmark for evaluating the error detection capabilities of PRMs from three perspectives: simplicity, soundness, and sensitivity. It consists of 6,216 questions and 83,456 step-level labels. Similarly, ProcessBench____ consists of 3,400 competition- and olympiad-level math problems that measure the ability to identify the earliest wrong steps in step-level mathematical reasoning. 
%MATHTRAP____ introduces five categories of logical traps, containing a public subset of 1000 problem triples and a private subset of 155 problem triples, focusing on the logical traps.
%PRMBench, Qwen2.5 evaluation 数据集
% All these benchmarks focus exclusively on text-based mathematical tasks. They are designed to evaluate the mathematical capabilities of LLMs through specialized problem sets.
% \paragraph{Multimodal math benchmarks.} MathVista____ is a multimodal benchmark designed to evaluate mathematical reasoning in Visual Contexts. It consists of 6,141 examples, concentrating on symbolic-graphical combinatorial reasoning tasks. Similarly, MathVerse____ is an all-around visual math benchmark, consisting of 2,612 math problems with diagrams. It is used to thoroughly evaluate whether Multimodal Large Language Models (MLLMs) can genuinely comprehend and utilize visual diagrams in mathematical reasoning.

\subsection{Mathematical LLMs}
Recently, with the emergence of GPT-o1-type models, numerous mathematical large models have been developed. In this paper, we summarize the commonly used mathematical large models.

The GPT series____ represents a milestone AI model in humanity's journey toward Artificial General Intelligence (AGI), developed and released by OpenAI. The latest iteration, GPT-4____, as a large-scale multimodal language model, has demonstrated professional-level proficiency in the field of mathematics. 
OpenAI o1-preview____ integrates slow thinking into the model, designed to allow the model more time for thinking before responding, enabling it to learn from mistakes and refine questions like human cognition. It elevates the capabilities of large language models in complex reasoning and challenging mathematical tasks to a higher level, achieving a score of 83\% on a qualifying exam for the International Mathematics Olympiad (IMO). The Qwen2.5-Math series____ excel in mathematical reasoning. It supports solving mathematical problems in both Chinese and English through Chain-of-Thought (CoT) and Tool-Integrated Reasoning (TIR). 

The QwQ model____ emphasizes the cultivation of AI's logical reasoning abilities, enabling the model to learn to think, question, and reflect, thereby deepening its understanding of mathematical knowledge and achieving breakthroughs in solving complex mathematical problems. DeepSeek-Math____ is an open-source mathematical reasoning model trained on the DeepSeekMath Corpus dataset, available in three 7B versions: base, instruction-tuned, and reinforcement learning. Its performance on the competition-level MATH benchmark approaches that of Gemini Ultra____ and GPT-4, supporting mathematical problem-solving, tool usage, and theorem proving.
As an open source model, DeepSeek-R1____ achieves impressive performance in mathematical and reasoning tasks which is comparable to OpenAI-o1 with less computational resources. It excels in complex reasoning tasks, specializing in complex mathematical reasoning and competition-level problem solving with detailed step-by-step solutions.

% 数据合成
\subsection{Mathematical Data Synthesis}

The demand for high-quality data in the field of LLMs has spurred the flourishing development of the data synthesis domain. Existing data synthesis approaches can be broadly categorized into two types: those based on large language model distillation and those based on Monte Carlo Tree Search (MCTS).

\textbf{LLM Based Distillation.} MetaMath____ leverages GPT-3.5 Turbo models to rewrite existing mathematical problems from multiple perspectives, thereby generating the  MetaMathQA dataset. KPDDS____ utilizes GPT-4 to extract the topics and Key Points from seed questions, processing and sampling them to synthesize new question-answer pairs. JiuZhang3.0____ trains a specialized model for mathematical data synthesis, with the training and retraining datasets generated by GPT-4.

\textbf{MCTS Based.} This approach was first proposed in OpenAI's o1____. It significantly expands the search space of model outputs. Compared to direct distillation, it demonstrates superior performance in synthesizing datasets for step-by-step solutions to complex mathematical problems. In ReST-MCTS*____, process reward value is utilized to guide MCTS, ensuring the accuracy of the data reasoning process. Meanwhile, rStar____ introduces a more extensive action space at each step of reasoning. LLaMA-Berry____ implements SR-MCTS (Self-refine), where each leaf node represents a complete problem-solving state, and child nodes correspond to the criticizing and rewriting of parent nodes. Mulberry____ proposes CoMCTS, which leverages collective knowledge from multiple models during inference and constructs a multimodal dataset, Mulberry-260k, for training MLLMs.

% PRM ORM
\subsection{Reward Models}
In the Reinforcement Learning from Human Feedback (RLHF) or MCTS-based inference, Reward Models (RMs) are employed to assess and score the quality of model outputs, thereby guiding the optimization or reasoning path of LLMs. Reward models can be categorized into Process Reward Models (PRMs) and Outcome Reward Models (ORMs).

\textbf{Outcome Reward Models.} ORMs evaluate only the final mathematical results without considering the solution process. For instance, Qwen2.5-Math-RM-72B____, released by the Qwen team, assigns a single score to each mathematical response.

\textbf{Process Reward Models.} PRMs are more fine-grained, focusing on whether each step of the reasoning path is logical and correct, providing step-level feedback and guidance signals. For example, Math-Shepherd-Mistral-PRM____ is trained on an automatically constructed (rather than manually annotated) process supervision dataset, scoring each step of mathematical reasoning. MATHMinos-PRM____ introduces a novel two-stage training paradigm and incorporates step-wise natural language feedback labels. EurusPRM____ utilize implicit PRM, where ORM is trained to evaluate response-level labels. Qwen2.5-Math-PRM____, currently the SOTA PRM, proposes a consensus filtering mechanism combining Monte Carlo estimation and LLM-as-a-judge. Additionally, there are the Skywork-PRM series____ and RLHFlow-PRM series____ models. For more comprehensive LLM-as-a-Judge please refer to the LLM-as-a-Judge survey____.