\section{Related work}
This section provides an overview of prominent methods applied to hyperparameter optimization (HPO), specifically focusing on evolutionary algorithms and probabilistic models. Evolutionary algorithms are widely used in HPO due to their ability to explore large, complex search spaces without requiring gradient information. These algorithms simulate natural evolutionary processes to iteratively improve hyperparameter configurations, making them particularly effective in problems where objective function evaluations are computationally manageable.

Probabilistic models, on the other hand, offer a more refined approach by predicting objective function values based on prior observations. GPE directly models the objective function with a Gaussian process, providing both predictions and uncertainty estimates, which allows it to balance exploration and exploitation effectively. TPE, in contrast, models the probability of high and low objective values separately, offering computational efficiency and flexibility in high-dimensional search spaces.

By comparing these approaches, this section highlights the unique advantages and challenges associated with evolutionary and probabilistic methods, setting the stage for an in-depth analysis of the Adaptive Tree-Structured Parzen Estimator (ATPE) algorithm in subsequent sections.

\subsection{Evolutionary approach}

One of the first successful applications of evolutionary algorithms in HPO utilized the CMA-ES algorithm ____, originally introduced in ____. Although initially seen as effective only for local optimization, it was later shown to yield satisfactory results in global optimization tasks as well ____.

In their study, Loshchilov and Hutter ____ compared CMA-ES with leading probabilistic HPO algorithms of Adam and AdaDelta models in the MNIST digit recognition task____. Their findings align with broader observations throughout our work, indicating that while probabilistic methods, such as TPE, are more effective with a limited number of function evaluations, evolutionary methods like CMA-ES often outperform them when a larger evaluation budget is available. This trend highlights the trade-offs inherent in choosing an HPO strategy based on the computational resources and specific requirements of the task.

Yeh et al.____ applied Simplified Swarm Optimization (SSO) to optimize hyperparameters of the LeNet convolutional neural network architecture.
SSO, a variation of swarm algorithms introduced in 2009____, iteratively adjusts individuals in a population based on their proximity to the best-performing individuals. In this study, the authors introduced modifications to SSO tailored specifically to the hyperparameter space of LeNet, such as ensuring a non-increasing sequence of neuron counts across feature-extracting layers.

They experimentally demonstrated that across several tasks the optimized hyperparameters achieved better results than those originally proposed by LeCun.
The results on three classification tasks — MNIST____, Fashion-MNIST____, and CIFAR10____ — show that the SSO-optimized version of LeNet (SSOLeNet) achieved superior accuracy and faster inference times compared to the original LeNet architecture. At the same time, training times were generally higher for SSOLeNet, which should be attributed to the repeated training required for hyperparameter optimization, reflecting the computational cost of the entire optimization process.

Japa et al.____ proposed the use of the Biased Random Key Genetic Algorithm (BRKGA) for hyperparameter optimization and demonstrated that BRKGA could outperform both CMA-ES and probabilistic methods, given a sufficiently long optimization timeframe.

RKGA, originally proposed in____, operates as a genetic algorithm that uses random keys within a continuous range, enhancing flexibility across different problem types. BRKGA____ extends RKGA by increasing the selection bias toward top-performing individuals, which potentially explains its comparative advantage by strengthening exploration.

Japa et al. further adapted BRKGA into HyperBRKGA, incorporating local methods for exploiting neighboring solutions at the end of each iteration. Specifically, they introduced two approaches: random walk and Bayesian walk. In the Bayesian variant, a Gaussian Process Estimator (GPE) model is constructed to predict the best nearby solutions, enhancing local exploitation while potentially sacrificing the ability to escape from local optima. The authors also implemented a data reduction mechanism for the GPE training set, which discards similar and suboptimal individuals to maintain manageable computation times.

Throughout various classification tasks, HyperBRKGA achieved significantly better performance metrics than both evolutionary and Bayesian optimization algorithms. However, due to the lack of information on the number of function evaluations, it remains unclear whether HyperBRKGA would outperform Bayesian optimization methods in scenarios with limited function calls.

The authors' concept of integrating evolutionary and probabilistic algorithms may lay the foundation for a new class of HPO methods. Future enhancements could include using TPE in place of GPE and a more advanced data reduction algorithm, such as correlation-based methods, similarly to the ones implemented in ATPE.

A different approach to HPO are shyperheuristic methods that rely on self-adaptation and hybridization of several algorithms with the focus on the optimal selection of the constituent methods along with their parameterization. The related literature is broad, in particular regarding self-adaptation and hybridization of the PSO method____.  

\subsection{Probabilistic model based approach}
\label{sec:TPE}

Probabilistic models have become a cornerstone of hyperparameter optimization, offering a distinct advantage over simpler search methods through their ability to model uncertainty in the objective function. Unlike model-free approaches that sample hyperparameters without considering past outcomes, probabilistic models estimate the likelihood of obtaining promising results in unexplored regions of the hyperparameter space. This targeted approach makes them particularly effective when evaluations are computationally expensive.

A common framework for implementing probabilistic models in HPO is Sequential Model-Based Optimization (SMBO)____. In SMBO, a probabilistic model is iteratively refined with each evaluation, balancing exploration of new hyperparameter configurations with exploitation of known high-performing areas. This dynamic adaptation allows SMBO methods, such as GPE and TPE, to achieve optimal results with fewer evaluations compared to traditional techniques.

\textbf{Gaussian Process Estimator (GPE)____} is widely used in hyperparameter optimization due to its ability to model the uncertainty of the objective function and to make accurate predictions with a limited number of evaluations. GPE assumes a joint Gaussian distribution for any set of observed function values, allowing it to predict objective values at unobserved points based on prior data, thereby guiding and maintaining the search process more effectively.

GPE’s main advantage lies in its capacity to balance exploration and exploitation. By calculating both the predicted function values and their associated uncertainty, GPE can identify regions with high optimization potential while sampling points with high uncertainty to discover new information. This approach reduces the need for excessive evaluations, making GPE particularly beneficial in scenarios where each function evaluation is computationally intensive.

However, a limitation of GPE is its computational complexity, which scales cubically with the number of data points ($\mathcal{O}(n^3)$). This is due to the need to invert the covariance matrix, which becomes more costly as the dataset of past evaluations grows. Consequently, for large datasets, GPE often requires data reduction techniques to remain efficient, such as pruning less informative points or clustering data to reduce computational load.

GPE has been effectively utilized in HPO for various machine learning models. Snoek et al.____ demonstrated the superiority of Bayesian optimization with GPE over traditional model-free methods like random and grid search in tuning deep neural networks and other complex models. Similarly, Hutter et al.____ applied GPE-based methods to optimize hyperparameters in Support Vector Machines (SVMs) and random forests, showing that, compared to other approaches, GPE could achieve better performance with fewer evaluations. These studies underscore GPE’s effectiveness, especially in high-dimensional, continuous search spaces with constrained evaluation budgets, as observed throughout this paper.

GPE is not only used in traditional machine learning models but has also demonstrated its scalability and effectiveness in optimizing hyperparameters for complex high-dimensional tasks. For instance, Wang et al.____ proposed an approach using random embeddings to extend the applicability of Gaussian Processes to high-dimensional optimization problems. This technique reduces the effective dimensionality of the search space, enabling Gaussian Processes to scale to tasks with hundreds of dimensions while retaining their predictive accuracy and efficiency.

Despite its strengths, the computational complexity of GPE remains a challenge, especially as datasets grow larger. Techniques such as sparse Gaussian Processes____ and random embeddings____ have been introduced to address this limitation, making GPE a viable choice for large-scale hyperparameter optimization. These advancements ensure that GPE remains relevant for modern applications requiring high-dimensional search spaces and limited evaluation budgets.

\textbf{Tree-Structured Parzen Estimator (TPE)____} is a popular probabilistic approach in HPO, designed to efficiently model the objective function by constructing separate density estimators for "good" and "bad" hyperparameter values. Unlike GPE, which models the objective function directly, TPE models it indirectly by estimating two conditional probability distributions: one for configurations that yield high objective values and another one for those leading to lower values. This distinction enables TPE to focus on promising regions of the hyperparameter space.

TPE’s advantage lies in its flexibility and computational efficiency, especially for high-dimensional or complex hyperparameter spaces where GPE might struggle. TPE has a linear time complexity $\mathcal{O}(n)$ with respect to the number of evaluations, allowing it to scale more efficiently than GPE, particularly as the dataset grows. Additionally, TPE can handle both continuous and categorical variables, making it versatile for a variety of HPO tasks.

This approach, as shown in____, often outperforms grid and random search, especially in high-dimensional spaces where only a subset of hyperparameters significantly influences performance. Its ability to prioritize exploration of promising regions makes it particularly useful in tasks where a large search space and a limited number of evaluations are an issue. In practice, TPE has been successfully applied in tuning hyperparameters for models such as deep neural networks and SVMs, demonstrating strong performance across diverse optimization problems____.

Recent work has highlighted TPE's adaptability to modern optimization problems. For instance, it has been successfully applied in neural architecture search (NAS)____, where the search space complexity significantly exceeds traditional hyperparameter tuning tasks. Moreover, TPE has been integrated into AutoML pipelines, such as Auto-sklearn____, demonstrating its compatibility with broader machine learning automation workflows. The method's ability to model separate density distributions has also been extended to reinforcement learning tasks, offering an efficient means of hyperparameter tuning in dynamic environments____.