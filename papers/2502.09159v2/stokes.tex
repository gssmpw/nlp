\documentclass[hidelinks,onefignum,onetabnum]{siamart220329}


\input{ex_shared}
\renewcommand{\algorithmiccomment}[1]{\bgroup\hfill$\blacktriangleright$~#1\egroup}
\newcommand{\N}{\mathbb{N}} %
\newcommand{\R}{\mathbb{R}} %
\renewcommand{\d}{\mkern3mu\text{d}} %
\usepackage{MnSymbol}
\usepackage[normalem]{ulem}
\usepackage{cancel}
\usepackage{multirow}
\ifpdf
\hypersetup{
  pdftitle={A \texorpdfstring{$hp$}{hp} Multigrid Approach for Tensor-Product Space-Time Finite Element Discretizations of the Stokes Equations},
  pdfauthor={Bause, M., Margenberg, N., Munch, P.}
}
\fi


\externaldocument[][nocite]{ex_supplement}
\usepackage{tikz}
\usetikzlibrary{3d,decorations.pathreplacing,shapes, positioning, fit, quotes,angles, fit, calc, patterns}
\usetikzlibrary{spy,shadows}
\tikzset{
  spy using overlaysshadow/.style={
    spy scope={#1,
         every spy on node/.style={
            circle,
            fill, fill opacity=0.25, text opacity=1
             },
         every spy in node/.style={
                 circle, circular drop shadow,
                 fill=white, draw, cap=round
            }
        }
    }
}
\usepackage{pgfplots}
\usepgfplotslibrary{groupplots,colorbrewer,fillbetween}
\pgfplotsset{compat=newest}%
\pgfplotsset{ colormap/Set1-4, cycle multiindex* list={ mark
    list*\nextlist Set1-4\nextlist }, every axis/.append style = {thick},%
}%
\pgfkeys{/pgf/number format/.cd,1000 sep={\,}}
\usepgfplotslibrary{colormaps}
\pgfplotsset{ every mark/.append style={4pt},tick style = {thick,black}}%
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{siunitx}
\sisetup{exponent-product=\cdot,round-mode=places,round-precision=3,exponent-mode=scientific,print-zero-exponent=false,tight-spacing=true}
\usepackage{fp}
\newcommand{\eval}[2][]{%
    \ifthenelse{\equal{#1}{}}{%
        \FPeval{\result}{#2}%
        \num{\result}%
    }{%
        \FPeval{\result}{#2}%
        \num[scientific-notation=false,round-mode=places,print-zero-exponent=false,tight-spacing=true,round-precision=#1]{\result}%
    }%
}
\definecolor{myblue}{RGB}{0 83 139}
\definecolor{myred}{RGB}{114 16 69}
\definecolor{mygreen}{RGB}{0 94 0}
\newcommand{\symbfit}[1]{\boldsymbol{#1}}
\newcommand{\symbfcal}[1]{\boldsymbol{\mathcal #1}}
\newcommand\restrict[1]{\raisebox{-.5ex}{$|$}_{#1}}
\newcommand{\logLogSlopeTriangleRev}[5]
{
    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}
        \pgfmathsetmacro{\xArel}{#1}
        \pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{\yArel}
        \pgfmathsetmacro{\xCrel}{\xBrel}
        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} %
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} %
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} %
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{(\lnyC-\ymin)/(\ymax-\ymin)}
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);
        \draw[#5]   (C)-- node[pos=0.5,anchor=east,inner sep=1pt,fill=white,fill opacity=0.5,text opacity=1] {#4}
                    (B)-- node[pos=0.5,anchor=north,inner sep=1pt,fill=white,fill opacity=0.5,text opacity=1] {1}
                    (A)--
                    cycle;
    }
  }
\newcommand{\logLogSlopeTriangleRevUp}[5]
{
    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}
        \pgfmathsetmacro{\xArel}{#1}
        \pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xCrel}{#1-#2}
        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} %
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} %
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} %
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{(\lnyC-\ymin)/(\ymax-\ymin)}
        \pgfmathsetmacro{\xBrel}{\xArel}
        \pgfmathsetmacro{\yBrel}{\yCrel}
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);
        \draw[#5]   (C)-- node[pos=0.5,anchor=south,inner sep=1pt,fill=white,fill opacity=0.5,text opacity=1] {#4}
                    (B)-- node[pos=0.5,anchor=west,inner sep=1pt,fill=white,fill opacity=0.5,text opacity=1] {1}
                    (A)--
                    cycle;
    }
  }
  \makeatletter
  \newcommand{\customlabel}[2]{%
    \protected@write \@auxout {}{\string \newlabel {#1}{{#2}{\thepage}{#2}{#1}{}} }%
    \hypertarget{#1}{#2}%
  }
  \makeatother
\begin{document}

\maketitle
\begin{abstract}
 We present a monolithic \(hp\) space-time multigrid method for tensor-product space-time finite element discretizations of the Stokes equations. Geometric and polynomial coarsening of the space–time mesh is performed, and the entire algorithm is expressed through rigorous mathematical mappings. For the discretization, we use inf-sup stable pairs \(\mathbb Q_{r+1}/\mathbb P_{r}^{\text{disc}} \) of elements in space and a discontinuous Galerkin (DG\( (k) \)) discretization in time with piecewise polynomials of order \( k \). The key novelty of this work is the application of \( hp \) multigrid techniques in space and time, facilitated and accelerated by the matrix-free capabilities of the \texttt{deal.II} library. While multigrid methods are well-established for stationary problems, their application in space-time formulations encounter unique challenges, particularly in constructing suitable smoothers. To overcome these challenges, we employ a space-time cell-wise Vanka smoother. Extensive tests on high-performance computing platforms demonstrate the efficiency of our \( hp \) multigrid approach on problem sizes exceeding a trillion degrees of freedom (dofs), sustaining throughputs of hundreds of millions of dofs per second.
\end{abstract}
\begin{keywords}
  Space-time finite elements, space-time multigrid, monolithic multigrid,
  matrix-free, higher-order finite elements, high-performance computing
\end{keywords}
\begin{MSCcodes}
65M60, 65M55, 65F10, 65Y05
\end{MSCcodes}
\section{Introduction}
Time-dependent partial differential equations, such as the nonstationary Stokes equations, greatly benefit from methods that exploit parallelism in space and time. \emph{Space-time finite element methods} (STFEMs) offer a natural framework for such parallelization by treating time as an additional dimension, enabling simultaneous discretization and
solution in space and time.

In this work, we present a $hp$ space-time multigrid method ($hp$ STMG) for
tensor-product space-time finite element discretizations of the Stokes system.
For the discretization in space we use the mapped version of the inf-sup stable
$\mathbb Q_{r+1}/\mathbb P_{r}^{\text{disc}}$ pairs of finite elements, with
$r\in \N$. For the discretization in time, we use the discontinuous Galerkin
method (DG$(k)$) of order $k\in \N$. Continuous in time Galerkin methods are not
studied here, due to their difficulties related to the computation of an
discrete initial value for the pressure and the non-wellposedness of the
discrete pressure
trajectory~\cite{anselmannOptimalorderPressureApproximation2025}. The key novelty of our
approach is the application of geometric and polynomial space-time multigrid
techniques. The implementation is facilitated by the matrix-free capabilities of
the \texttt{deal.II}
library~\cite{africa_dealii_2024,kronbichlerGenericInterfaceParallel2012,munchEfficientDistributedMatrixfree2023,fehnHybridMultigridMethods2020}.
The present work builds upon the foundation established
in~\cite{margenbergSpaceTimeMultigridMethod2024a}. The code is available on
GitHub at~\url{https://github.com/nlsmrg/dealii-stfem}.

Extending multigrid methods to STFEMs poses challenges, particularly in the design of effective smoothers for the arising linear systems. However, STFEMs offer appreciable advantages: They naturally integrate spatial and temporal discretizations and handle coupled problems.
Further, they facilitate duality-based and goal-oriented adaptivity in space and
time~\cite{besierGoalorientedSpacetimeAdaptivity2012,bauseFlexibleGoalorientedAdaptivity2021,rothTensorProductSpaceTimeGoalOriented2023}.
Adaptive STFEMs have also been investigated
in~\cite{langerAdaptiveSpaceTime2022,wienersSpacetimeDiscontinuousGalerkin2023,coralloSpaceTimeDiscontinuousGalerkin2023}.
Alternative approaches, particularly for unstructured space-time meshes are
discussed
in~\cite{langerSpaceTimeMethodsApplications2019,steinbachSpaceTimeFiniteElement2015,nochettoSpacetimeMethodsTimedependent2018,ernestiSpaceTimeDiscontinuousPetrov2019a,langerSpaceTimeHexahedralFinite2022}.
The utilization of global STFEMs, i.e.\ the concurrent treatment of all
subintervals, has the potential to fully exploit the computational resources of
high-performance computers. Conversely, local STFEMs employ space-time
variational discretizations as time-marching schemes by selecting a test basis
supported on the subintervals. This requires less computational resources, while
scalability to global formulations is maintained. Finally, higher order FE spaces facilitate improved accuracy of discrete solutions on computationally feasible grids.

Parallel time integration methods have been developed to exploit parallelism in
the time dimension and to overcome the sequential bottleneck of traditional
time-stepping methods. A comprehensive review of such methods can be found
in~\cite{ganderTimeParallelTime2024}. However, most of these methods entail a
trade-off between additional computational complexity and time parallelism.
An alternative is the all-at-once solution of the entire space–time
system~\cite{danieli_space-time_2022,southworth_fast_2022}. Owing to the
established connection between Runge–Kutta methods and variational time
discretizations~\cite{ganderAnalysisNewSpaceTime2016,southworth_fast_2022},
these contributions relate to the present work. Space-time multigrid
methods treat time as an additional grid dimension, enabling simultaneous
multilevel coarsening in space and
time~\cite{hortonSpaceTimeMultigridMethod1995,francoMultigridMethodBased2018,falgoutMultigridMethodsSpace2017b,honBlockToeplitzPreconditioner2023}.
While algebraic multigrid methods have been applied to space-time
systems~\cite{steinbachAlgebraicMultigridMethod2018,langerSpaceTimeHexahedralFinite2022},
geometric multigrid technqiues offer advantages in computational efficiency and
scalability~\cite{hackbuschParabolicMultigridMethods1985,ganderAnalysisNewSpaceTime2016}.
Another approach to time parallelism that does not increase the computational
complexity is stage parallelism within a single time
step~\cite{christliebParallelHighOrderIntegrators2010,paznerStageparallelFullyImplicit2017,munchStageParallelFullyImplicit2023}.
While the scalability of stage parallelism is constrained by the number of
stages, these methods are effective in the scaling limit.

Our goal in this work is the design of a $hp$ STMG with the same
grid-independent convergence seen in established geometric multigrid techniques
for elliptic or stationary Stokes-type
problems~\cite{olshanskiiMultigridAnalysis2012}. For stability reasons, the $hp$
STMG is applied as a preconditioner for GMRES iterations, which has become a
standard approach in multigrid frameworks. For parallel efficiency, the
$V$-cycle form is used, with a single $V$-cycle per application of $hp$ STMG.\@
The efficiency of multigrid methods strongly depend on the smoothing operator.
We employ a space-time cell-wise Vanka smoother. Additive Schwarz or Vanka-type smoothers have a wide range of applications in fluid
mechanics~\cite{ahmedAssessmentSolversSaddle2018,anselmannGeometricMultigridMethod2023}, solid mechanics~\cite{wobkerNumericalStudiesVankaType2009}, fluid-structure
interaction~\cite{failerParallelNewtonMultigrid2021}, dynamic poroelasticity~\cite{anselmannEnergyefficientGMRESMultigrid2024} and acoustic
wave equations~\cite{margenbergSpaceTimeMultigridMethod2024a}. To ensure computational efficiency of the $hp$ STMG, we focus on the feasibility of matrix-free implementations.

In recent years, there has been work on matrix-free, high-order monolithic
multigrid methods to solve Stokes (and Navier--Stokes) equations on
high-performance computing architectures. The authors
of~\cite{kohlTextbookEfficiencyMassively2022} developed a parallel, matrix-free
multigrid solver achieving ``textbook multigrid efficiency'', scaling up to
multiple trillions of unknowns. The authors of~\cite{abu-labdeh_monolithic_2023}
extend a patch-based Vanka smoother to fully implicit Runge–Kutta
discretizations of incompressible flows using standard Taylor–Hood elements.
Jodlbauer et al.\ used a matrix-free monolithic geometric multigrid solver for
discretizations of the Stokes equations with Taylor-Hood elements with scaled
Chebyshev-Jacobi smoothers~\cite{jodlbauerMatrixfreeMonolithicMultigrid2024}.
Prieto Saveedra et al.\ present a matrix-free solver for SUPG and PSPG
stabilized equal-order discretizations of the incompressible Navier--Stokes
equations, and achieve substantial speedups and reduced memory usage compared to
matrix-based methods~\cite{prietosaavedraMatrixFreeStabilizedSolver2024}. The
authors of~\cite{voroninMonolithicMultigridPreconditioners2024} propose a
monolithic $ph$-multigrid method for stationary
Stokes. In line with their findings, our experiments demonstrate that
this approach outperforms geometric multigrid methods.

This paper is organized as follows. In \Cref{sec:stfem} we introduce the
continuous problem and the tensor-product space time finite element
discretization.\@ We formulate the algebraic system arising from the
discretization in \Cref{Sec:AlgSys}. In \Cref{sec:mg-framework} we introduce the
$hp$ STMG algorithm, which we use as a preconditioner to a GMRES method. We
verify this methodology by numerical experiments in \Cref{sec:experiments}. We
conclude with an evaluation of the results and a future outlook in
\Cref{sec:conclusions}.
\section{Continuous and discrete problem}
\label{sec:stfem}
\subsection{Continuous problem}
We consider the nonstationary Stokes system
\begin{subequations}
  \label{Eq:SE}
  \begin{alignat}{3}
    \label{Eq:SE_1}
    \partial_t \boldsymbol{v} - \nu \boldsymbol\Delta \boldsymbol{v} + \nabla p & = \boldsymbol{f}  && \quad \text{in } \;
    \Omega
    \times (0,\,T)\,,\\
    \label{Eq:SE_2}
    \boldsymbol\nabla \cdot \boldsymbol{v}  & = 0 && \quad \text{in } \; \Omega \times (0,\,T)\,,\\
    \label{Eq:SE_3}
    \boldsymbol{v} (0) & = \boldsymbol{v}_0 && \quad \text{in } \; \Omega \,,\\
    \label{Eq:SE_4}
    \boldsymbol{v}  & = \boldsymbol{0}  && \quad \text{on } \; \partial\Omega \times (0,\,T)\,,
  \end{alignat}
\end{subequations}
where \(\Omega \subset \mathbb{R}^d\), with $d\in \{2,3\}$,  is a bounded open Lipschitz domain and \(T > 0\) is the final time. By $\boldsymbol{v}$ and $p$ we denote the unknown velocity and pressure field, respectively. The force $\boldsymbol{f}$ and initial velocity $\boldsymbol{v}_0$ are prescribed data. In~\eqref{Eq:SE_1}, $\nu\in\R_{>0}$ denotes the fluid's viscosity. Homogeneous Dirichlet boundary conditions in~\eqref{Eq:SE_4} are chosen for brevity of presentation. We assume that the Stokes system~\eqref{Eq:SE} admits a sufficiently regular solution up to $t=0$ such that higher order approximations become feasible.

We use standard notation. $H^m(\Omega)$ is the Sobolev space of $L^2(\Omega)$
functions with derivatives up to order $m$ in $L^2(\Omega)$ {while}
$\langle \cdot,\cdot \rangle$ {denotes} the inner product in $L^2(\Omega)$
and its vector-valued and matrix-valued counterparts. Let $L^2_0(\Omega)\coloneqq \{ q\in  L^2(\Omega) \mid \int_\Omega q \, \d x =0\}$ and  $H^1_0(\Omega)\coloneqq \{u\in H^1(\Omega) \mid u=0 \mbox{ on } \partial \Omega\}$. We put $Q(\Omega)\coloneqq L^2_0(\Omega)$ and $\boldsymbol V(\Omega) \coloneqq  H^1_0(\Omega)^d$. Here, bold-face letters are used to indicate vector-valued spaces and functions. Further, we define the space
\begin{equation*}
 \boldsymbol V^{\operatorname{div}} (\Omega) \coloneqq  \{ \boldsymbol v\in  \boldsymbol V \mid \langle \nabla \cdot  \boldsymbol v, q\rangle = 0 \:\: \forall q\in Q \}\,.
\end{equation*}

\subsection{Space-time finite element discretization}
For the discretization of~\eqref{Eq:SE} we use spatial and temporal finite
element meshes, which are combined to a space-time mesh by an algebraic
tensor-product. Discrete space-time function spaces are
then defined in tensor-product form. For the time discretization, we partition
the time interval $I\coloneqq(0,\,T]$ into $N$ equal subintervals $I_n
\coloneqq(t_{n-1},\,t_n]$, for $n=1,\ldots,N$, where $t_n= n \tau$ and $\tau =
T/N$. Thus, $I=\bigcup_{n=1}^N I_n$. The set $\mathcal{M}_\tau \coloneqq \{I_1,\ldots, I_N\}$ of time subintervals is called the time mesh. For any $k\in \N_0$ and Hilbert space $H$,  we let $\mathbb P_{k}(J;H)$ denote the set of all polynomials of degree less than or equal to $k$ on $J\subset I$ with values in $H$. Then, we put
\begin{equation*}
  \label{Def:Yk}
  Y_\tau^k (H) \coloneqq \left\{w_\tau : I \to \R  \mid w_\tau{}_{|I_n} \in \mathbb
  P_{k}(I_n;H)\; \forall I_n\in \mathcal M_\tau \right\}\,.
\end{equation*}

For spatial discretization, let $\mathcal{T}_h$ be a shape-regular
triangulation of $\Omega$ into quadrilateral and hexahedral elements in two and three space
dimensions with mesh size
$h>0$. These element types are chosen for our implementation that is based on the deal.II library~\cite{africa_dealii_2024}. By ${\boldsymbol V}_{r+1}(K)$ and
$Q_r(K)$ we denote the vector- and scalar-valued spaces on $K$ of mapped
polynomials from $(\mathbb Q_{r+1})^d$ and $\mathbb P_{r}^{\text{disc}}$, respectively, for some $r\geq 1$; cf.~\cite[Subsection 3.64]{john_FiniteElement_2016}. The mapping are defined by the multilinear reference transformation of polynomials on the reference element. The finite element
spaces to be used for approximating $\boldsymbol V$ and $Q$ and defining the $hp$ STMG are
\begin{subequations}
  \label{Def:VhQh}
  \begin{alignat}{2}
    \label{Def:Vh}
    \boldsymbol  V_h^{r+1} (\Omega) & \coloneqq \{\boldsymbol v_h \in \boldsymbol V \; : \; \boldsymbol v_{h}{}_{|K}\in  {\boldsymbol V_{r+1}(K)} \;\; \text{for all}\; K \in \mathcal{T}_h\}\cap \boldsymbol H^1_0(\Omega)\,, \\[3pt]
    \label{Def:Qh}
    Q_h^r (\Omega) & \coloneqq \{q_h \in Q \; : \; q_{h}{}_{|K}\in {Q_r(K)} \;\; \text{for all}\; K \in \mathcal{T}_h\}\,,\\[3pt]
    \label{Def:Qhp}
    Q_h^{r,+}(\Omega) & \coloneqq Q_h^r (\Omega) \oplus \operatorname{span}\{1\}\,.
  \end{alignat}
\end{subequations}
The definition of $Q_h^r$ leads to a discontinuous (in space) pressure approximation. Further, $Q_h^{r,+}(\Omega)$ is the pressure finite element space without orthogonality condition. The space of discretely divergence-free functions is given by
\begin{equation}
  \label{Def:Vdiv}
  \boldsymbol V_h^{\operatorname{div}} (\Omega)\coloneqq \{\boldsymbol v_h \in \boldsymbol V_h^r \mid \langle \nabla \cdot \boldsymbol v_h,q_h\rangle  = 0 \; \text{for all } q_h \in Q_h\}\,.
\end{equation}
The global discrete solution spaces are defined by the tensor-products
\begin{equation}
\label{Eq:GDS}
\boldsymbol  H_{\tau,h}^{\boldsymbol v} =   Y_\tau^k (I) \otimes \boldsymbol  V_h^{r+1}(\Omega) \,, \quad
H_{\tau,h}^{p}  =   Y_\tau^k (I) \otimes \boldsymbol  Q_h^r(\Omega)\,.
\end{equation}
\begin{remark}[Function spaces and their tensor product structure]
\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
\item The algebraic tensor product $Y_\tau(I) \otimes V_h(\Omega)$ of two finite element spaces $Y_\tau(I)$ and $V_h(\Omega)$ is defined by
\begin{equation*}
Y_\tau(I) \otimes V_h(\Omega) \coloneqq \operatorname{span}\{f\otimes g \mid f \in Y_\tau(I)\,, \; g \in V_h(\Omega)\}	\,,
\end{equation*}
with mapping $f\otimes g: (t,\boldsymbol x) \to f(t)g(\boldsymbol x)$. For the construction principle of tensor products of Hilbert spaces we refer to, e.g.,~\cite[Subsection 1.2.3]{picard_partial_2011}.
\item The spaces $Y_\tau^k(I;\boldsymbol V_h^{r+1}(\Omega))$ and $Y_\tau^k(I;Q_h^{r}(\Omega))$  are isometric to the Hilbert spaces $\boldsymbol  H_{\tau,h}^{\boldsymbol v}$ and $H_{\tau,h}^{p}$, respectively; cf.~\cite[Proposition 1.2.28]{picard_partial_2011}.
\end{itemize}
\end{remark}
For any function $w: I\to \boldsymbol V_h$ that is piecewise sufficiently smooth with respect to the time mesh $\mathcal{M}_{\tau}$, for instance for $w\in \boldsymbol  H_{\tau,h}^{\boldsymbol v} $, we define the right-hand side limit at a point $t_n$ by $w^+(t_n) \coloneqq \lim_{t\to t_n+0} w(t)$ for $0<n<N$. Now, we introduce the fully discrete space-time finite element approximation of~\eqref{Eq:SE}.

\begin{problem}[Discrete variational problem]\label{Prob:DVP}
Let the data $\boldsymbol f\in L^2(I;L^2(\Omega))$ and an approximation $\boldsymbol{v}_{0,h}\in V_h^{\operatorname{div}} (\Omega)$ of $\boldsymbol{v}_0\in \boldsymbol{V}^{\operatorname{div}} (\Omega) $ be given. Put  $\boldsymbol v_{\tau,h}(t_0)\coloneqq \boldsymbol{v}_{0,h}$. Find $(\boldsymbol v_{\tau,h},p_{\tau,h})\in \boldsymbol  H_{\tau,h}^{\boldsymbol v} \times H_{\tau,h}^{p}$ such that for all $n=1,\ldots,N$ and $(\boldsymbol{w}_{\tau,h},q_{\tau,h}) \in \boldsymbol  H_{\tau,h}^{\boldsymbol v} \times H_{\tau,h}^{p}$ there holds that
\begin{subequations}
\label{Eq:DSE_0}
\begin{alignat}{2}
\nonumber
\sum_{n=1}^N \int_{t_{n-1}}^{t_n} \langle \partial_t \boldsymbol v_{\tau,h}, \boldsymbol w_{\tau,h} \rangle +  \nu \langle \nabla \boldsymbol v_{\tau,h}, & \nabla \boldsymbol w_{\tau,h}\rangle -  \langle p_{\tau,h}, \nabla \cdot \boldsymbol w_{\tau,h} \rangle \d t   \\
\label{Eq:DSE_1}
+ \sum_{n=0}^{n-1} \langle \lsem \boldsymbol v_{\tau,h} \rsem_n, \boldsymbol w_{\tau,h}^+(t_n)\rangle & =  \sum_{n=1}^N \int_{t_{n-1}}^{t_n} \langle f, \boldsymbol w_{\tau,h} \rangle \d t\,, \\[3pt]
\label{Eq:DSE_2}
\sum_{n=1}^N \int_{t_{n-1}}^{t_n} \langle \nabla \cdot \boldsymbol v_{\tau,h}, q_{\tau,h} \rangle \d t& = 0\,,
\end{alignat}
\end{subequations}
with the jump $\lsem \boldsymbol v_{\tau,h}\rsem_n \coloneqq  \boldsymbol v_{\tau,h}^+(t_n) - \boldsymbol v_{\tau,h}(t_n)$.
\end{problem}
Well-posedness of Problem~\ref{Prob:DVP} can be shown along the lines of~\cite[Lemma 3.2]{anselmannEnergyefficientGMRESMultigrid2024}.

\section{Algebraic system}
\label{Sec:AlgSys}

Here, we rewrite Problem~\ref{Prob:DVP} in its algebraic form by exploiting the
tensor product structure~\eqref{Eq:GDS} of the discrete spaces. In Section~\ref{sec:mg-framework} we then embed the algebraic system into an $hp$ multigrid approach.

\subsection{Preliminaries}

For time integration in~\eqref{Eq:DSE_0}, it is natural to apply the right-sided $(k+1)$-point Gau{ss}--Radau quadrature formula. On $I_n$, it reads as
\begin{equation}
  \label{Eq:GF}
  Q_n(w) \coloneqq \frac{\tau_n}{2}\sum_{\mu=1}^{k+1} \hat
  \omega_\mu w(t_n^{\mu}) \approx \int_{I_n} w(t) \d t \,,
\end{equation}
where $t_n^{\mu} =T_n(\hat t_{\mu})$, for $\mu = 1,\ldots,k+1$, are the
Gauss--Radau quadrature  points on $I_n$ and $\hat \omega_\mu$ the corresponding
weights. Here, $T_n(\hat t)\coloneqq(t_{n-1}+t_n)/2 + (\tau_n/2)\hat t$ is the affine
transformation from $\hat I = [-1,1]$ to $I_n$ and $\hat t_{\mu}$ are the
Gau{ss}--Radau quadrature points on $\hat I$. The quadrature rule~\eqref{Eq:GF} is exact for all $w\in \mathbb P_{2k} (I_n;\R)$, and $t_n^{k+1}=t_n$.

For time interpolation, a Lagrangian basis with respect to the Gauss--Radau quadrature points and with local support on the subintervals $I_n$, for $n=1,\ldots, N$, is used,
\begin{equation}
\label{Eq:BasYk}
\begin{aligned}
Y_\tau^k(I) = \operatorname{span}\big\{& \varphi_{n}^a \in L^2(I) \mid \varphi^a_{n}{}_{|I_b}\in \mathbb P_k(I_b;\R)\,, \text{ for } b=1,\ldots,N\,, \; \\
&  \operatorname{supp}\, \varphi^a_{n}\subset \overline I_n\,,\;  \varphi^a_{n} (t_{n}^{\mu}) = \delta_{a,\mu} \,,\text{ for } \mu =1,\ldots, k+1\,, \\
&   \text{ and for } a=1,\ldots,k+1\,,  \; n=1,\ldots, N \big \}\,,
\end{aligned}
\end{equation}
with the Kronecker symbol $\delta_{a,\mu}$. For space discretization, we use the standard (global) finite element bases associated with the spaces~\eqref{Def:VhQh} and put
\begin{subequations}
\label{Eq:BasVhQh}
\begin{alignat}{2}
\label{Eq:BasVh}
\boldsymbol  V_h^{r+1} (\Omega) & =  \operatorname{span}\big\{\boldsymbol \chi_m^{\boldsymbol v} \mid m=1,\ldots ,M^{\boldsymbol v}  \big\}\\[3pt]
\label{Eq:BasQh}
Q_h^{r,+} (\Omega) & =  \operatorname{span}\big\{\chi^{p}_m \mid m=1,\ldots ,M^p  \big\}\,.
\end{alignat}
\end{subequations}
Then, functions $(\boldsymbol v_{\tau,h},p_{\tau,h}) \in \boldsymbol  H_{\tau,h}^{\boldsymbol v} \times H_{\tau,h}^{p}$ admit for $\boldsymbol{x}\in \Omega$ and $t\in I$ the representation
\begin{subequations}
\label{Eq:Repvp}
\begin{alignat}{2}
\label{Eq:Repv}
\boldsymbol v_{\tau,h}(\boldsymbol x,\,t) &  = \sum_{n=1}^N \sum_{a=1}^{k+1} \sum_{m=1}^{M^{\boldsymbol v}}  v_n^{a,m} \varphi^a_{n}(t) \boldsymbol  \chi_m^{\boldsymbol v}(\boldsymbol x)\,,\\[3pt]
\label{Eq:Repp}
p_{\tau,h}(\boldsymbol x,\,t) & =  \sum_{n=1}^N \sum_{a=1}^{k+1} \sum_{m=1}^{M^{p}} p_n^{a,m}\varphi^a_{n}(t) \chi_m^{p}(\boldsymbol x)
\end{alignat}
\end{subequations}
with coefficients $v_n^{a,m} \in \R^d$ and $p_n^{a,m}\in \R$ for $n=1,\ldots,N$,
$a=1,\ldots,k+1$ and $m=1,\ldots, M$, with $M\in \{M^{\boldsymbol v},M^p\}$.
This representation again shows the tensor-product structure, which we exploit
here. We note that the orthogonality condition for the pressure is not implemented yet in \eqref{Eq:Repp}, this will be done below in the multigrid framework in Subsection~\ref{Subsec:GTO}.

To recast~\eqref{Eq:DSE_0} in algebraic form, we use a local (i.e., on each subinterval $I_n$) space and variable major order of the coeffients $v_n^{a,m} \in \R$ and $p_n^{a,m}\in \R$. For this, we introduce the column vectors
\begin{equation}
\label{Eq:DefSubvec_1}
\boldsymbol V_{n}^{a}  \coloneqq \big(v_{n}^{a,1},\ldots,v_{n}^{a,{M^{\boldsymbol v}} }\big)^\top\in \R^{{M^{\boldsymbol v}} } \,,\quad\boldsymbol P_{n}^{a}   \coloneqq \big(p_{n}^{a,1},\ldots,p_{n}^{a,M^p}\big)^\top\in \R^{M^p}\,,
\end{equation}
for $a=1,\ldots,k+1$. From~\eqref{Eq:DefSubvec_1} we define the column vectors
\begin{equation}
\label{Eq:DefSubvec_2}
  \boldsymbol V_{n}  \coloneqq\big(\boldsymbol V_{n}^{1},\ldots ,\boldsymbol V_{n}^{k+1}\big)^\top\in \R^{(k+1)\cdot {M^{\boldsymbol v}} } \,,\quad
  \boldsymbol  P_{n}  \coloneqq \big(\boldsymbol  P_{n}^{1},\ldots,\boldsymbol  P_{n}^{k+1}\big)^\top\in \R^{(k+1) \cdot M^p}
\end{equation}
for $n=1,\ldots,N$. For improved readability, the transpose sign is
skipped for the subvectors $\boldsymbol V_{n}^{a}$ and $\boldsymbol P_{n}^{a}$
in~\eqref{Eq:DefSubvec_2}. Throughout the paper, we don't differ in the notation between column and row vectors, if the meaning is clear from the context.
The global column vector $\boldsymbol  X $ of unknowns on $\Omega\times I$, with $\boldsymbol  X_n=(\boldsymbol  V_n,\boldsymbol  P_n)^\top\in \R^{(k+1)\cdot ({M^{\boldsymbol v}}  + M^p)}$ for $n=1,\ldots, N$,  is then defined by
\begin{equation}
  \label{Eq:DefX}
  \boldsymbol  X = (\boldsymbol  X_1,\ldots,\boldsymbol  X_N)^\top \coloneqq \big(\boldsymbol  V_{1},\boldsymbol P_{1},\ldots, \boldsymbol  V_{N},\boldsymbol P_{N}\big)^\top\in \R^{N\cdot (k+1)\cdot ({M^{\boldsymbol v}}  + M^p)}\,.
\end{equation}
For the temporal finite element basis induced by~\eqref{Eq:BasYk}, we define the local matrices $\boldsymbol K^\tau_n\in \R^{(k+1),(k+1)}$, $\boldsymbol M_n^\tau\in \R^{(k+1),(k+1)}$ and $\boldsymbol C^\tau_n\in \R^{(k+1),(k+1)}$  by
\begin{subequations}
\label{Eq:DefKMC}
\begin{alignat}{2}
  (\boldsymbol K^\tau_n)_{a,b} & \coloneqq \int_{t_{n-1}}^{t_n} \partial_t \varphi_n^b(t) \, \varphi_n^a(t)\d t + \varphi_n^b (t_{n-1}^+) \,  \varphi_n^a (t_{n-1}^+) \,, \\[3pt]
  (\boldsymbol M_n^\tau)_{a,b} &   \coloneqq \int_{t_{n-1}}^{t_n} \varphi_n^b(t) \, \varphi_n^a(t) \d t\,, \\[3pt]
  (\boldsymbol C^\tau_n)_{a,b} &  \coloneqq
  \left\{\begin{array}{@{}ll}
  \varphi_{n-1}^b (t_{n-1}) \, \varphi_n^a (t_{n-1}^+)\,, & \text{for } n>1 \,, \\[3pt]
  \left.\begin{array}{@{}lll@{}}
    \varphi_n^a (t_{n-1}^+)\,, & \text{for } b= k+1\,,\\[3pt]
  0 \,, & \text{for } b\in \{1,\ldots, k\} \,,
  \end{array}\right\} & \text{for } $n=1$\,,
  \end{array}\right.
\end{alignat}
\end{subequations}
for $a,b=1,\ldots,k+1$. For the spatial finite element basis induced by~\eqref{Eq:BasVhQh},  we let $\boldsymbol  M_h^{\boldsymbol  v} \in \R^{M^{\boldsymbol  v},M^{\boldsymbol  v}}$, $\boldsymbol A_h \in \R^{M^{\boldsymbol  v}, M_h^{\boldsymbol  v}}$, $\boldsymbol  B \in \R^{M^p, M^{\boldsymbol  v}}$ and $\boldsymbol  M_h^{p} \in \R^{M^{p},M^{p}}$ be defined by
\begin{subequations}
\label{Eq:DefMAB}
\begin{alignat}{4}
\label{Eq:DefMAB_1}
(\boldsymbol M_h)_{i,j} &  \coloneqq  \int_\Omega \boldsymbol  \chi_j^{\boldsymbol v}(\boldsymbol x) \,  \boldsymbol  \chi_i^{\boldsymbol v}(\boldsymbol x)  \d \boldsymbol x\,, &
(\boldsymbol A_h)_{i,j} &  \coloneqq  \int_\Omega \nabla \boldsymbol  \chi_j^{\boldsymbol v}(\boldsymbol x) \cdot \nabla \boldsymbol  \chi_i^{\boldsymbol v}(\boldsymbol x)  \d \boldsymbol x\,, \\[3pt]
\label{Eq:DefMAB_2}
(\boldsymbol B_h)_{l,j}  &  \coloneqq  \int_\Omega \nabla \cdot \boldsymbol  \chi_j^{\boldsymbol v}(\boldsymbol x) \,  \chi_i^{p}(\boldsymbol x)   \d \boldsymbol{x}\,,\quad &
(\boldsymbol M^p_h)_{l,m} &  \coloneqq  \int_\Omega \chi_m^{p}(\boldsymbol x) \,  \chi_l^{p}(\boldsymbol x)  \d \boldsymbol x
\end{alignat}
\end{subequations}
for $i,j=1,\ldots,M^{\boldsymbol{v}}$ and $l,m=1,\ldots,M^p$.
Next, we introduce the right-hand side column vector
\begin{equation}
  \label{Eq:DefB}
  \boldsymbol  B = \big(\boldsymbol  B_1, \ldots,  \boldsymbol  B_N\big)^\top\in \R^{N\cdot (k+1)\cdot ({M^{\boldsymbol v}}  + M^p)}\,,
  \quad \text{with}\; \;
  \boldsymbol  B_n = (\boldsymbol F_n,\boldsymbol{0})^\top
\end{equation}
for $n=1,\ldots,N$ and subvectors $\boldsymbol F_{n}$ defined by
\begin{equation}
\label{Eq:DefFn}
\boldsymbol F_{n} \coloneqq (\boldsymbol F_{n}^{1},\ldots,\boldsymbol F_{n}^{k+1})^\top \in \R^{(k+1)\times M^{\boldsymbol v}}\,, \quad \text{with}\; \;
(\boldsymbol F_{n,}^{a})_i \coloneqq Q_n(\langle \boldsymbol f, \varphi_n^a\, \boldsymbol{\chi}_i^{\boldsymbol{v}} \rangle)
\end{equation}
for $a=1,\ldots,k+1$ and $i=1,\ldots,M^{\boldsymbol{v}}$, and with the quadrature formula~\eqref{Eq:GF}. For the well-definedness of $(\boldsymbol F_{n,}^{a})_i $ in~\eqref{Eq:DefFn} we tacitly make the stronger regularity assumption that $\boldsymbol{f}\in C(I;\boldsymbol{L}^2(\Omega))$ is satisfied.

Finally, we recall the tensor (or right Kronecker) product  $\boldsymbol A\otimes \boldsymbol B$ of matrices $\boldsymbol A\in \R^{r,r}$ and $\boldsymbol B\in \R^{s,s}$, for $r,s\in \N$, defined by
\begin{equation}
  \label{Eq:DefKr}
  \boldsymbol A \otimes \boldsymbol B \coloneqq \begin{pmatrix}
    a_{1,1} \boldsymbol B & \cdots & a_{1,r}\boldsymbol B\\
    \vdots  & \ddots & \vdots\\
    a_{r,1}\boldsymbol B & \cdots & a_{r,r}\boldsymbol B
  \end{pmatrix} = \left(a_{ij}\boldsymbol B\right)_{i,j=1}^{r}\,.
\end{equation}

\subsection{Algebraic form of the discrete problem}

In Problem \ref{Prob:DVP} we choose a tensor product basis of the solution and test space, with the natural Lagrangian basis of~\eqref{Eq:BasYk} built of functions supported on a single subinterval $I_n$. Then we recast for~\eqref{Eq:DSE_0} the following sequence of local problems on $I_n$.
\begin{problem}[Local algebraic problem]
\label{Prob:LocAlg}
Let $n\in \{1,\ldots,N\}$. For $n>1$ let $\boldsymbol{v}_{\tau,h}(t_{n-1})=\sum_{m=1}^{M^{\boldsymbol v}} v_{n-1}^{k+1,m} \boldsymbol{\chi}_m^{\boldsymbol v}$. For $n=1$ and $\boldsymbol v_{0,h}\in \boldsymbol{V}_h^{\operatorname{div}}$ let $\boldsymbol{v}_{0,h}=\sum_{m=1}^{M^{\boldsymbol v}} v_0^{m} \, \boldsymbol{\chi}_m^{\boldsymbol v}$. Put
\begin{equation}
\label{Eq:DefVnm1}
\boldsymbol{V}_{n-1}\coloneqq
\left\{\begin{array}{@{}ll}
\big(\boldsymbol 0, \ldots, \boldsymbol 0,v_{n-1}^{k+1,1},\ldots,v_{n-1}^{k+1,M^{\boldsymbol v}} \big)^\top\,, & \text{for } n>1\,,\\[3pt]
\big(\boldsymbol 0, \ldots, \boldsymbol 0,v_{0}^{1},\ldots,v_{0}^{M^{\boldsymbol v}} \big)^\top\,, & \text{for } n=1\,.
\end{array} \right.
\end{equation}
Find $(\boldsymbol{V}_n,\,\boldsymbol{P}_n)\in \R^{(k+1)(M^{\boldsymbol{v}}+M^p)}$ such that
\begin{equation}
\label{Eq:InAlg}
\begin{pmatrix}
\boldsymbol K_n^\tau \otimes \boldsymbol M_h + \boldsymbol M_n^\tau \otimes \boldsymbol A_h  &  \boldsymbol M_n^\tau \otimes \boldsymbol B_h^\top \\[3pt]
\boldsymbol M_n^\tau \otimes \boldsymbol B_h & \boldsymbol 0
\end{pmatrix}
\begin{pmatrix}
\boldsymbol{V}_n\\[3pt] \boldsymbol{P}_n
\end{pmatrix}
=
\begin{pmatrix}
\boldsymbol{F}_n\\[3pt] \boldsymbol{0}
\end{pmatrix}
+ \boldsymbol C_n^\tau \otimes \begin{pmatrix}
  \boldsymbol M_h\\[3pt] \boldsymbol 0
\end{pmatrix} \boldsymbol V_{n-1}
\,.
\end{equation}
\end{problem}

We note that the orthogonality condition for the pressure has not been implemented yet in Problem~\ref{Prob:LocAlg}. This will be done in the multigrid method by applying the occuring operators to a subspace of $\boldsymbol R^{(k+1)\cdot M^p}$, introduced in \eqref{Eq:DefRsSs} below. For~\eqref{Eq:InAlg} along with~\eqref{Eq:DefKMC} and~\eqref{Eq:DefMAB} we introduce the abbreviations
\begin{equation}
\label{Eq:DefDtauh}
\boldsymbol D^n_{\tau,h}  \coloneqq \begin{pmatrix}
  \boldsymbol K_n^\tau \otimes \boldsymbol M_h + \boldsymbol M_n^\tau \otimes \boldsymbol A_h  &  \boldsymbol M_n^\tau \otimes \boldsymbol B_h^\top \\[3pt]
  \boldsymbol M_n^\tau \otimes \boldsymbol B_h & \boldsymbol 0
\end{pmatrix}\,, \quad
\boldsymbol C^n_{\tau,h}  \coloneqq -  \boldsymbol C_n^\tau \otimes \begin{pmatrix}
\boldsymbol M_h\\[3pt] \boldsymbol 0
\end{pmatrix}\,.
\end{equation}
From the local system~\eqref{Eq:InAlg} on $I_n$ we then get the following global problem on $I$.
\begin{problem}[Global algebraic problem]
\label{Prob:GloAlg}
Let $\boldsymbol V_0$ be defined by~\eqref{Eq:DefVnm1}. Find $\boldsymbol{X}=(\boldsymbol{X}_1,\ldots, \boldsymbol{X}_N)\in \R^{N\cdot (k+1) \cdot (M^{\boldsymbol{v}}+M^p)}$ such that
\begin{equation}
\label{Eq:GloSys}
\begin{pmatrix}
\boldsymbol D^1_{\tau,h}  \\[3pt]
\boldsymbol C^2_{\tau,h}  & \boldsymbol D^2_{\tau,h} \\[3pt]
& \ddots & \ddots \\[3pt]
&& \boldsymbol C^N_{\tau,h}  & \boldsymbol D^N_{\tau,h}
\end{pmatrix}
\begin{pmatrix}
  \boldsymbol{X}_1\\[3pt] \vdots \\[3pt] \vdots \\[3pt] \boldsymbol{X}_N
\end{pmatrix}
=
\begin{pmatrix}
\boldsymbol{B}_1 -\boldsymbol C^1_{\tau,h} \boldsymbol{V}_0
\\[3pt] \vdots \\[3pt] \vdots \\[3pt] \boldsymbol{B}_N
\end{pmatrix}\,.
\end{equation}
The subvectors and -matrices in~\eqref{Eq:GloSys} are defined by~\eqref{Eq:DefDtauh} along with \eqref{Eq:DefKMC} to \eqref{Eq:DefFn}.
\end{problem}
\begin{remark}[Global linear system of Problem~\ref{Prob:GloAlg}]\label{rem:GLSP}
\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
\item Our $hp$ STMG employs the global system representation \eqref{Eq:GloSys}. The formulation, that orders the unknowns by time and local
  variables as defined in~\eqref{Eq:DefX}, offers the appreciable
  advantage of allowing for the restriction of the temporal multigrid to a
  smaller number $\widetilde N< N$ of subintervals by combining $\widetilde N$
  subintervals to a macro time step. Thereby, the approach can be adapted to the
  available computer hardware in a flexible manner. Conversely, solving the
  entire system~\eqref{Eq:GloSys} for a high number of subintervals demands
  large computing and memory resources, particularly in three space dimensions.
  For $\widetilde N=1$, a time marching scheme is obtained
  from~\eqref{Eq:GloSys} with algebraic system
  \begin{equation}
    \label{Eq:AlgSysTMS}
    \boldsymbol D^n_{\tau,h}  \boldsymbol X_n = \boldsymbol B_n - \boldsymbol C^n_{\tau,h} \boldsymbol X_{n-1}\,,
  \end{equation}
  for $n=2,\ldots,N$ and  right-hand side $\boldsymbol{B}_1 -\boldsymbol
  C^1_{\tau,h} \boldsymbol{V}_0$ for $n=1$. Our implementation supports a
  flexible choice of $\widetilde N$, as shown
  in~\cite{margenbergSpaceTimeMultigridMethod2024a}. As the systems already
  become quite large for small $\widetilde N$, particularly in 3D, we restrict
  ourselves to $\widetilde N=1$ in the numerical experiments in \Cref{sec:experiments}.

\item Alternatively, a global variable and time major order of the unknowns can be applied, such that instead of~\eqref{Eq:DefX} the vector of all unknowns is defined by
\begin{equation}
  \label{Eq:DefXg}
  \boldsymbol  X = (\boldsymbol  X^{\boldsymbol v},\boldsymbol X^p)^\top\coloneqq \big(\boldsymbol  V_{1},\ldots, \boldsymbol  V_{N},\boldsymbol P_{1},\ldots, \boldsymbol P_{N}\big)^\top\in \R^{N\cdot (k+1)\cdot ({M^{\boldsymbol v}}  + M^p)}\,,
\end{equation}
with $\boldsymbol V_{n}$ and $\boldsymbol P_{n}$ of~\eqref{Eq:DefSubvec_2}. This
global in time formulation leads to a system matrix with saddle point structure such that block solver techniques, such as Schur complement methods, become feasible. However, the global space-time system  comprises a large
number of unknowns, necessitating substantial computational resources,
particularly in three space dimensions. The approach is not investigated in the present study as well.
\end{itemize}
\end{remark}

\section{Multigrid framework}
\label{sec:mg-framework}
\begin{figure}
  \centering
  \begin{tikzpicture}[xscale=0.9,yscale=0.9,anchor=north west,thick,font=\footnotesize]
    \draw[-latex,shorten >=.1cm,shorten <=.1cm] (.75,1) -- ++(.75,.75);%
    \draw[latex-,shorten >=.1cm,shorten <=.1cm] (.25,1) -- ++(-.75,.75);%
    \draw[shift={(2.5,2)},latex-,shorten >=.1cm,shorten <=.1cm] (.5,.75) --
    ++(-.75,-.75);%
    \draw[shift={(-2.5,2)},-latex,shorten >=.1cm,shorten <=.1cm] (.5,.75) --
    ++(.75,-.75);%
    \draw[shift={(4,3)},latex-,shorten >=.1cm,shorten <=.1cm] (.5,.75) --
    node[left=.5cm,align=left,font=\scriptsize]{Prolongation\\ \& Correction} ++(-.75,-.75);%
    \draw[shift={(-4,3)},-latex,shorten >=.1cm,shorten <=.1cm] (.5,.75) --
    node[right=.5cm,align=left,font=\scriptsize]{Residual\\ \& Restriction} ++(.75,-.75);%
    \foreach \i in {0,1.0}{%
      \draw[myred] (\i, 0) -- ++ (0,1);%
    }%
    \foreach \i in {0,1.0}{%
      \draw[myblue] (0,\i) -- ++ (1,0);%
    }%
    \foreach \i in {0,1}{%
      \filldraw[myred] (\i,-0.1) circle (1.2pt);%
    }%
    \foreach \i in {0,1}{%
      \filldraw[myblue] (-0.1,\i) circle (1.2pt);%
    }%
    \def\points{(-1.5,1), (1.5,1)}; %
    \foreach \p in \points {%
      \foreach \i in {0,0.5,1.0}{%
        \draw[myred,shift={\p}] (\i, 0) -- ++ (0,1);%
      }%
      \foreach \i in {0,0.5,1.0}{%
        \draw[myblue,shift={\p}] (0,\i) -- ++ (1,0);%
      }%
    }%
    \foreach \i in {0,0.5,1}{%
      \filldraw[myred,shift={(-1.5,1)}] (\i,-0.1) circle (1.2pt);%
    }%
    \foreach \i in {0,0.5,...,1}{%
      \filldraw[myblue,shift={(-1.5,1)}] (-0.1,\i) circle (1.2pt);%
    }%
    \foreach \i in {0,0.5,1}{%
      \filldraw[myred,shift={(1.5,1)}] (\i,-0.1) circle (1.2pt);%
    }%
    \foreach \i in {0,0.5,...,1}{%
      \filldraw[myblue,shift={(1.5,1)}] (1.1,\i) circle (1.2pt);%
    }%
    \def\points{(3,2), (-3,2)}%
    \foreach \p in \points {%
      \foreach \i in {0,0.5,1.0}{%
        \draw[myred,shift={\p}] (\i, 0) -- ++ (0,1);%
      }%
      \foreach \i in {0,0, 0.5,1.0}{%
        \draw[myblue,shift={\p}] (0,\i) -- ++ (1,0);%
      }%
    }%
    \foreach \i in {0,0.5,1}{%
      \filldraw[myred,shift={(-3,2)}] (\i,-0.1) circle (1.2pt);%
    }%
    \foreach \i in {0,0.25,...,1}{%
      \filldraw[myblue,shift={(-3,2)}] (-0.1,\i) circle (1.2pt);%
    }%
    \foreach \i in {0,0.5,1}{%
      \filldraw[myred,shift={(3,2)}] (\i,-0.1) circle (1.2pt);%
    }%
    \foreach \i in {0,0.25,...,1}{%
      \filldraw[myblue,shift={(3,2)}] (1.1,\i) circle (1.2pt);%
    }%
    \def\points{(4.5,3), (-4.5,3)}%
    \foreach \p in \points {%
      \foreach \i in {0,0.5,1.0}{%
        \draw[myred,shift={\p}] (\i, 0) -- ++ (0,1);%
      }%
      \foreach \i in {0,0.5,1}{%
        \draw[myblue,shift={\p}] (0,\i) -- ++ (1,0);%
      }%
    }%
    \foreach \i in {0,0.5,1}{%
      \filldraw[myred,shift={(-4.5,3)}] (\i,-0.1) circle (1.2pt);%
    }%
    \foreach \i in {0,0.125,...,1}{%
      \filldraw[myblue,shift={(-4.5,3)}] (-0.1,\i) circle (1.2pt);%
    }%
    \foreach \i in {0,0.5,1}{%
      \filldraw[myred,shift={(4.5,3)}] (\i,-0.1) circle (1.2pt);%
    }%
    \foreach \i in {0,0.125,...,1}{%
      \filldraw[myblue,shift={(4.5,3)}] (1.1,\i) circle (1.2pt);%
    }%
    \draw[-latex] (-4,0.5) -- node[pos=-.1]{time} ++ (1,0);%
    \draw[-latex] (-4,0.5) -- node[rotate=90,above,pos=.33]{space} ++ (0,1);%
    \draw[|<->|] (5.8,0) -- node[align=left,pos=.66]{{\bfseries Space-time multigrid}\\
      First $r/k$-multigrid ({\color{myblue}$\bullet$}/{\color{myred}$\bullet$}),\\
      then $h/\tau$-multigrid ({\color{myblue}$\boldsymbol\vert$}/{\color{myred}$\boldsymbol\vert$}).} ++ (0,2);%
    \draw[|<->|] (5.8,2) -- node[align=left,pos=.66]{{\bfseries Space \emph{or} time}\\
      First {\color{myblue} space} multigrid,\\
      then {\color{myred} time} multigrid.} ++ (0,2);%
  \end{tikzpicture}
  \caption{Sketch of the $hp$ STMG of \Cref{alg:stmg}. The
    corrections are transferred by the prolongation operators and the residual
    is transferred by the restriction operators. On each level the error is
    smoothened by application of the Vanka operator~\eqref{vanka0}.
    The coarsening strategy which is
    used in \Cref{alg:CombineHierarchies}, is first in space and then in
    time in combination with polynomial coarsening before geometric coarsening (cf.~\ref{itm:p1},~\ref{itm:p2}).
  }\label{fig:stmg}
\end{figure}
For solving~\eqref{Eq:GloSys} efficiently, we propose an $hp$ space-time
multigrid method. For stability reasons, we use the $hp$ STMG method as a preconditioner for GMRES iterations rather than as a solver itself, which has become a standard technique for applying multigrid techniques. For foundational principles of multigrid methods we refer to~\cite{hackbuschMultigridMethodsApplications1985,brambleMultigridMethods1993,vassilevskiMultilevelBlockFactorization2008}. Before we present the $hp$ STMG in \Cref{alg:stmg}, that is sketched in \Cref{fig:stmg}, we need to define the grid transfer operators, restriction and prolongation, and the smoother.

 Let $\{\mathcal{M}_l\}_{l=0}^{L}$ be a quasi-uniform family of nested triangulations of the interval $I$ into semi-closed subintervals $(t_a,\,t_b]$ based on \textit{global regular refinement}, with $\mathcal M_{l} = \{I_i=(t_{i,a},\,t_{i,b}] \mid i=1,\ldots , N^{\text{el}}_{l}\}$, for $l=0,\ldots,L$. The finest partition of $I$ is $\mathcal M_\tau=\mathcal M_{L}$. For the characteristic mesh size $\tau_l$ there holds $\tau_l= \frac{\tau_{l-1}}{2}$, and $\tau_0 = \mathcal O(1)$. This results in a hierarchy of nested temporal finite element spaces  of type~\eqref{Eq:BasYk},
 \begin{equation}
 \label{Eq:DefYkl}
 Y^k_0 \subset  Y^k_1  \subset \cdots \subset Y^k_L \subset L^2(0,\,T) \,.
 \end{equation}
Let further $\{\mathcal{T}_{s}\}_{s=0}^{S}$ be a quasi-uniform family of nested triangulations of the spatial domain $\Omega$ into (open) quadrilaterals or hexahedrals based on \textit{global regular refinement}, with $\mathcal T_{s} = \{K_i\mid i=1,\ldots , N^{\text{el}}_{s}\}$, for $s =0,\ldots,S$. The finest partition is $\mathcal T_h=\mathcal T_{S}$. For the characteristic mesh size $h_s$ there holds $h_s \approx \frac{h_{s-1}}{2}$ and $h_0 = \mathcal O(1)$. This results in a hierarchy of nested spatial finite element spaces of type~\eqref{Eq:BasVhQh},
 \begin{subequations}
 \label{Eq:NFES}
 \begin{alignat}{6}
 \label{Eq:NFESv}
\boldsymbol V^{r+1}_0(\Omega) &  \subset \boldsymbol V^{r+1}_1(\Omega) & \subset \cdots & \subset \boldsymbol V^{r+1}_S(\Omega) && \subset \boldsymbol V\,,\\
 \label{Eq:NFESp}
Q^r_0(\Omega)&  \subset  Q^r_1(\Omega) & \subset \cdots & \subset  Q^r_S(\Omega) && \subset  Q\,.
 \end{alignat}
 \end{subequations}
Similarly to \eqref{Def:Qhp}, for the nested finite element spaces~\eqref{Eq:NFESp} we define
\begin{equation}
\label{Eq:NFESp+}
Q_s^{r,+} \coloneqq Q_s^{r}+\operatorname{span}\{1\}\,.
\end{equation}
We put $M^{\boldsymbol v}_{r+1,s} \coloneqq \operatorname{dim}\; \boldsymbol V_s^{r+1}$ and $M^{p}_{r,s} \coloneqq \operatorname{dim}\; Q_s^{r,+}$. On the space-time and polynomial order multigrid hierarchy, we define the algebraic tensor product spaces, for $l=0,\ldots,L$ and $s=0,\ldots,S$, as well as $k,r\in \N$ by
\begin{equation}
\label{Eq:STSMG}
\boldsymbol H_{l,s}^{k,r+1}  \coloneqq  Y_l^{k}(I) \otimes \boldsymbol V_s^{r+1}(\Omega)\,,\qquad
H_{l,s}^{k,r}  \coloneqq Y_l^{k}(I)  \otimes Q_s^{r}(\Omega)\,.
\end{equation}
All spaces, quantities and problems that were introduced before in
Section~\ref{sec:stfem} and Section~\ref{Sec:AlgSys} are now studied on the full
space-time multigrid hierarchy and for the function spaces~\eqref{Eq:STSMG}. For this, the respective indices are added in the notation. The grid levels in time and space are denoted by the indices ``$l$'' and ``$s$'', respectively, and the polynomial orders by the indices ``$k$'' and ``$r$''.

\subsection{Grid transfer operators}
\label{Subsec:GTO}
For refinement and coarsening of the space and time mesh, referred to as
$h$-multigrid in our $hp$ STMG, we need to define the grid transfer operators, i.e.\ restriction and prolongation, for the algebraic tensor product spaces~\eqref{Eq:STSMG}. We start with the spatial
mesh. For the nested finite element spaces~\eqref{Eq:NFES} and~\eqref{Eq:NFESp+}
with bases according to~\eqref{Eq:BasVhQh} we define the isomorphisms which map
the degrees of freedom to the finite element spaces as (cf.~\cite{olshanskiiMultigridAnalysis2012})
\begin{subequations}
  \label{Def:IsoAlg}
  \begin{alignat}{7}
    \boldsymbol{\mathcal R}^{r+1}_s : & \;  \mathbb R^{M^{\boldsymbol v}_{r+1,s}} & \to & \, \boldsymbol V_s^{r+1}\,, & \qquad && \boldsymbol{\mathcal R}^{r+1}_s \boldsymbol U_s & = \sum_{i=0}^{M^{\boldsymbol v}_{r+1,s}} U_s^i \boldsymbol  \chi_{i,s}^{\boldsymbol{v}}\,,\\
    \mathcal S^{r}_s : &  \; \mathbb R^{M_{r,s}^p} & \to & \; Q_s^{r,+}\,, && \qquad & \mathcal S^{r}_s \boldsymbol  P_s  & = \sum_{i=0}^{M_{r,s}^p} P_s^i \chi^p_{i,s}\,.
  \end{alignat}
\end{subequations}
We note that $Q_s^{r} = \{\mathcal S^{r}_s \boldsymbol P_s \mid \boldsymbol P_s \in (\boldsymbol M_{h,s}^p \boldsymbol 1)^\perp \}\}$ with $\boldsymbol 1=(1,\ldots,1)^\top\in \R^{M_{r,s}^p}$ and pressure mass matrix $\boldsymbol M_{r,s}^p\in \R^{M_{r,s}^p,M_{r,s}^p}$  of~\eqref{Eq:DefMAB_2}. The orthogonality condition $\langle p,1\rangle_{L^2(\Omega)}=0$ for $p\in Q_h^{r,s}$ corresponds to the orthogonality $\langle \boldsymbol P,\boldsymbol M_{h,s}^p\boldsymbol 1\rangle_{\mathbb R^{M_{r,s}^p}} =0$ for $\boldsymbol P \in \mathbb R^{M_{r,s}^p}$. For $s=0,\ldots,S$ and $r\in \N$, we let
\begin{equation}
  \label{Eq:DefRsSs}
  \boldsymbol R^{r+1}_s \coloneqq \mathbb R^{M^{\boldsymbol v}_{r+1,s}}  \quad \text{and} \quad \boldsymbol S^{r}_s \coloneqq (\boldsymbol M_{h,s}^p \boldsymbol 1)^\perp\,.
\end{equation}
For prolongation and restriction in space and with \eqref{Def:IsoAlg}, we use the canonical choice
\begin{subequations}
  \label{Eq:DefPrRe}
  \begin{alignat}{5}
    \label{Eq:DefTps}
    &\begin{aligned}
      & \boldsymbol T^{r}_{s-1,s}:  \boldsymbol R^{r+1}_{s-1} \times \boldsymbol S^{r}_{s-1}	 \to  \boldsymbol R^{r+1}_s \times \boldsymbol S^{r}_s\,, \\[3pt]
      & \boldsymbol T^{r}_{s-1,s} = (\boldsymbol{\mathcal R}^{r+1}_s)^{-1}\circ \boldsymbol{\mathcal R}^{r+1}_{s-1} \times (\mathcal S^{r}_s)^{-1}\circ\mathcal S^{r}_{s-1}\,,
    \end{aligned}
    \\[3pt]
    \label{Eq:DefTrs}
    & \begin{aligned}
    &\boldsymbol T^{r}_{s,s-1}:  \boldsymbol R^{r+1}_{s} \times \boldsymbol  S^{r}_{s}	\to  \boldsymbol R^{r+1}_{s-1} \times \boldsymbol S^{r}_{s-1}\,,\\[3pt]
    & \boldsymbol T^{r}_{s,s-1}  = (\boldsymbol{\mathcal R}^{r+1}_{s-1})^\ast\circ ((\boldsymbol{\mathcal R}^{r+1}_{s})^\ast)^{-1} \times (\mathcal S^r_{s-1})^{\ast}\circ ((\mathcal S^r_{s})^\ast)^{-1}\,.
    \end{aligned}
  \end{alignat}
\end{subequations}
Both operators, $\boldsymbol T^r_{s-1,s}$ and $\boldsymbol T^r_{s,s-1}$, keep the pressure in the correct subspace. For $\boldsymbol{Z}=(\boldsymbol  V,\boldsymbol  P)^\top\in (\boldsymbol R_{s-1}^{r+1})^{k+1} \times (\boldsymbol S_{s-1}^r)^{k+1}$, with $\boldsymbol V \in  (\boldsymbol R_{s-1}^{r+1})^{k+1}$ and $\boldsymbol P \in  (\boldsymbol S_{s-1}^r)^{k+1}$, we define the prolongation $\boldsymbol{\widetilde T}^r_{s-1,s}:  (\boldsymbol R_{s-1}^{r+1})^{k+1} \times (\boldsymbol S_{s-1}^r)^{k+1} \to  (\boldsymbol R_{s}^{r+1})^{k+1} \times (\boldsymbol S_{s}^r)^{k+1}$ for the product spaces $(\boldsymbol R_{s-1}^{r+1})^{k+1}$ and $(\boldsymbol S_{s-1}^r)^{k+1}$ by componentwise application of \eqref{Eq:DefTps},
\begin{equation}
\label{Eq:DeftTps}
\begin{aligned}
\boldsymbol{\widetilde T}_{s-1,s}^r \boldsymbol{Z} & \coloneqq (\boldsymbol T_{s-1,s}^{r,\boldsymbol v} \boldsymbol V^1, \ldots,\boldsymbol T_{s-1,s}^{r,\boldsymbol v}\boldsymbol V^{k+1},  \boldsymbol T_{s-1,s}^{r,p} \boldsymbol P^1, \ldots,  \boldsymbol T_{s-1,s}^{r,p} \boldsymbol P^{k+1})^\top\\[3pt]
& =  \begin{pmatrix} \boldsymbol E_{k+1}  \otimes \boldsymbol T_{s-s,s}^{r,\boldsymbol v} & \boldsymbol 0 \\  \boldsymbol 0 & \boldsymbol E_{k+1}  \otimes \boldsymbol T_{s-1,s}^{r,p}  \end{pmatrix}  \begin{pmatrix} \boldsymbol V\\ \boldsymbol P \end{pmatrix}\,,
\end{aligned}
\end{equation}
where $ \boldsymbol T_{s-1,s}^{r,\boldsymbol v}:\boldsymbol R_{s-1}^{r+1}  \to
\boldsymbol R_{s}^{r+1}$ and $ \boldsymbol T_{s-1,s}^{r,p}:\boldsymbol S_{s-1}^r
\to \boldsymbol S_{s}^r $ are the velocity and pressure parts of the
prolongation $ \boldsymbol T_{s,s-1}^r$ defined in~\eqref{Eq:DefTps}. The corresponding restriction operator $\boldsymbol{\widetilde T}^r_{s,s-1}: (\boldsymbol R_{s}^{r+1})^{k+1} \times (\boldsymbol S_{s}^{r})^{k+1} \to  (\boldsymbol R_{s-1}^{r+1})^{k+1} \times (\boldsymbol S_{s-1}^{r})^{k+1}$  is defined analogously by
\begin{equation}
  \label{Eq:DeftTrs}
  \begin{aligned}
    \boldsymbol{\widetilde T}_{s,s-1}^r \boldsymbol{Z} & \coloneqq (\boldsymbol T_{s,s-1}^{r,\boldsymbol v} \boldsymbol V^1, \ldots,\boldsymbol T_{s,s-1}^{r,\boldsymbol v}\boldsymbol V^{k+1},  \boldsymbol T_{s,s-1}^{r,p} \boldsymbol P^1, \ldots,  \boldsymbol T_{s,s-1}^{r,p} \boldsymbol P^{k+1})^\top\\[3pt]
    & = \begin{pmatrix}  \boldsymbol E_{k+1}  \otimes  \boldsymbol T_{s,s-1}^{r,\boldsymbol v} & \boldsymbol 0 \\  \boldsymbol 0 &  \boldsymbol E_{k+1}  \otimes \boldsymbol T_{s,s-1}^{r,p}  \end{pmatrix}  \begin{pmatrix} \boldsymbol V\\ \boldsymbol P \end{pmatrix}\,,
  \end{aligned}
\end{equation}
where
$ \boldsymbol T_{s,s-1}^{r,\boldsymbol v}:\boldsymbol R_{s}^{r+1} \to
\boldsymbol R_{s-1}^{r+1}$ and
$ \boldsymbol T_s^{r,p}:\boldsymbol S_{s}^r \to \boldsymbol S_{s-1}^r $ are the
velocity and pressure parts of the restriction $ \boldsymbol T_{s,s-1}^r$
defined in~\eqref{Eq:DefTrs}. For global vectors
$\boldsymbol{Z}=(\boldsymbol Z_1\ldots,\boldsymbol Z_{N_l})^\top\in
\big((\boldsymbol R_{s-1}^{r+1})^{k+1} \times (\boldsymbol
S_{s-1}^r)^{k+1}\big)^{N_l}$ with
$\boldsymbol Z_n = (\boldsymbol V_n,\boldsymbol P_n)^\top\in (\boldsymbol
R_{s-1}^{r+1})^{k+1} \times (\boldsymbol S_{s-1}^r)^{k+1}$, for
$n=1,\ldots,N_l$, and with
$\boldsymbol 1_{N_l} \coloneqq (1,\ldots,1)\in \mathbb R^{N_l}$ according to \eqref{Eq:DefSubvec_1} to \eqref{Eq:DefX}, prolongation
and restriction are then defined by
\begin{equation}
\label{Eq:DefgT}
\boldsymbol{\overline T}_{s-1,s}^r \boldsymbol{Z} \coloneqq  \big((\boldsymbol{1}_{N_l} \otimes \boldsymbol{\widetilde T}_{s-1,s}^r) \boldsymbol{Z}\big)^\top \quad \text{and} \quad
\boldsymbol{\overline T}_{s,s-1}^r \boldsymbol{Z} \coloneqq  \big((\boldsymbol{1}_{N_l} \otimes \boldsymbol{\widetilde T}_{s,s-1}^r) \boldsymbol{Z}\big)^\top\,.
\end{equation}
Next, we introduce the grid transfer operator for the hierarchy of temporal
meshes. Similarly to~\eqref{Def:IsoAlg}, for temporal mesh level $l=0,\ldots,L$ we define the isomorphism, on spatial mesh level $s=0,\ldots ,S$, with $D^{k,r}_{l,s} \coloneqq N_l (k+1)(M_{r+1,s}^{\boldsymbol v}+M_{r,s}^p)$ as
\begin{equation}
\label{Def:IsoTme}
\boldsymbol{\mathcal  I}_l^k  : \mathbb R^{D^{k,r}_{l,s}}\rightarrow Y_l^{k}(I) \otimes \mathbb R^{{M_{r+1,s}^{\boldsymbol v}+M_{r,s}^p} }\,,  \qquad  \boldsymbol{\mathcal  I}_l^k  \boldsymbol W = \sum_{n=1}^{N_l} \sum_{a=1}^{k+1} \begin{pmatrix} \boldsymbol W^{l,\boldsymbol v}_{n,a} \\[3pt] \boldsymbol W^{l,p}_{n,a} \end{pmatrix}\varphi_{n,a}^l\,.
\end{equation}
 Here, we substructured $\boldsymbol W$ according to
\begin{equation}
\label{Eq:SubStrGloVec}
\begin{aligned}
\boldsymbol W = \big(& \boldsymbol W^{l,\boldsymbol v}_{1,1},\ldots, \boldsymbol W^{l,\boldsymbol v}_{1,k+1},\boldsymbol W^{l,p}_{1,1},\ldots, \boldsymbol W^{l,p}_{1,k+1},\ldots, \\[3pt]
& \boldsymbol W^{l,\boldsymbol v}_{N_l,1},\ldots ,\boldsymbol W^{l,\boldsymbol v}_{N_l,k+1} , \boldsymbol W^{l,p}_{N_l,1},\ldots ,\boldsymbol W^{l,p}_{N_l,k+1}\big)^\top\,,
\end{aligned}
\end{equation}
with $\boldsymbol W_{n,a}^{l,\boldsymbol v}\in \mathbb R^{M_{r+1,s}^{\boldsymbol v}}$ and $\boldsymbol W_{n,a}^{l,p}\in \mathbb R^{M_{r,s}^{p}}$ for $n=1,\ldots,N_l$ and $a=1,\ldots,k+1$. For prolongation and restriction we use the canonical choices again,
\begin{subequations}
\label{Eq:DeftPrRe}
\begin{alignat}{5}
\boldsymbol I^k_{l-1,l}: & \; \mathbb R^{D^{k,r}_{l-1,s}} \to \mathbb R^{D^{k,r}_{l,s}} \,, & \qquad \boldsymbol I^{k}_{l-1,1} & =  (\boldsymbol{\mathcal  I}^k_{l})^{-1} \circ \boldsymbol{\mathcal  I}^k_{l-1}\,,\\[3pt]
\boldsymbol I_{l,l-1}^k: &  \; \mathbb R^{D^{k,r}_{l,s}}  \to  \mathbb R^{D^{k,r}_{l-1,s}} \,, & \qquad \boldsymbol I_{l,l-1}^k & = (\boldsymbol{\mathcal  I}^k_{l-1})^{\ast}  \circ	((\boldsymbol{\mathcal  I}^k_{l})^{\ast})^{-1}\,.
\end{alignat}
\end{subequations}
Space-time prolongation $\boldsymbol T_{l-1,l;s-1,s}^{k,r}: \mathbb R^{D^{k,r}_{l-1,s-1}}\to \mathbb R^{D^{k,r}_{l,s}}$ and restriction $\boldsymbol T^{k,r}_{l,l-1;s,s-1}: \mathbb R^{D^{k,r}_{l,s}}\to \mathbb R^{D^{k,r}_{l-1,s-1}}$  are then defined by the concatenation of $\boldsymbol I_{l-1,l}^k$ and $\boldsymbol{\overline T}^r_{s-1,s}$ and of $\boldsymbol I_{l,l-1}^r$ and $\boldsymbol{\overline T}^r_{s,s-1}$, respectively, as
\begin{equation}
\label{Eq:DefTlspr}
\boldsymbol T_{l-1,l;s-1,s}^{k,r} \coloneqq \boldsymbol I_{l-1,l}^k \circ  \boldsymbol{\overline T}^r_{s-1,s} \qquad \text{and} \qquad
\boldsymbol T_{l,l-1;s,s-1}^{k,r}  \coloneqq \boldsymbol I_{l,l-1}^k \circ \boldsymbol{\overline T}^r_{s,s-1}\,.
\end{equation}
\begin{remark}
If a time marching process according to~\eqref{Eq:AlgSysTMS} is applied,
we omit $h$-multigrid in time by solving~\eqref{Eq:AlgSysTMS} on
the finest time mesh $\mathcal M_L$. There, we perform $hp$-multigrid in space
and $p$-multigrid in time. In~\eqref{Eq:DefTlspr}, the operators $\boldsymbol
I_{l-1,l}^k$ and $\boldsymbol I_{l,l-1}^k$ then become the identities. Under
this assumption, the $hp$ STMG (\Cref{alg:stmg}) is still well-defined. This also applies to  macro time steps (cf. Remark~\ref{rem:GLSP}) by coupling $\widetilde N < N$ systems~\eqref{Eq:AlgSysTMS}.
\end{remark}
For the coarsening and prolongation of the polynomials degrees $k,r\in \N$ of the discrete spaces~\eqref{Eq:STSMG}, refered to as $p$-multigrid in the $hp$ multigrid
context, we need to define corresponding grid transfer operators.
For simplicity, we assume for~\eqref{Eq:STSMG} that
\begin{equation}
  \label{Assmp:MG2}
  k = 2^K \quad \text{for some } K \in \mathbb{N},\quad r = 2^R \quad \text{for some } R \in \mathbb{N}\,.
\end{equation}
As we halve the polynomial orders $k,r\in \N$ for restriction, i.e.\ \( k \mapsto \lfloor k/2 \rfloor \) (bisection), and double it for prolongation, we would otherwise need to maintain an accounting vector for
the polynomial orders due to the noninvertibility of the floor function. This
overhead in notation is avoided in this section by~\eqref{Assmp:MG2}. The
general case of arbitrary \( k,\,r\in \N \) is addressed in
Algorithm~\ref{alg:ConstructHierarchy}. The coarsening strategy for the polynomial degrees is motivated by computational studies, which have
demonstrated that this approach strikes a favorable balance between two-level
(\( k \mapsto 1 \)) and decrease by one (\( k \mapsto k-1 \)) coarsening. We also refer to~\cite[Section 3.2.2]{fehnHybridMultigridMethods2020} for a review of
polynomial coarsening strategies.
For prolongation of the spatial polynomial order $r$, i.e.\
$\frac{r}{2}\mapsto r$ in~\eqref{Eq:NFES}, and restriction, i.e.\
$r\mapsto\frac{r}{2}$, we let the transfer operators (for $R\geq 2$)
\begin{equation}
\label{Eq:DefPrRer}
  \boldsymbol T_s^{\frac{r}{2},r} :  \; \boldsymbol R_{s}^{\frac{r}{2}}  \times  \boldsymbol S_s^{\frac{r}{2}-1}   \to    \boldsymbol R_s^{r} \times \boldsymbol S_s^{r-1}\,, \qquad
  \boldsymbol T_s^{r,\frac{r}{2}} :  \; \boldsymbol R_s^{r}  \times  \boldsymbol S_s^{r-1}   \to    \boldsymbol S_s^{\frac{r}{2}} \times \boldsymbol S_s^{\frac{r}{2}-1}
\end{equation}
for the spaces~\eqref{Eq:DefRsSs} be defined analogously to~\eqref{Eq:DefPrRe}
along with~\eqref{Def:IsoAlg}. The prolongation $\boldsymbol{\overline
  T}_s^{\frac{r}{2},r}$ and restriction $\boldsymbol{\overline T}_s^{r,\frac{r}{2}}$ extend
$\boldsymbol{T}_s^{\frac{r}{2},r}$  and $\boldsymbol{T}_s^{r,\frac{r}{2}}$ to the global vector
of unknowns~\eqref{Eq:SubStrGloVec} along the lines of~\eqref{Eq:DeftTps}
and~\eqref{Eq:DeftTrs}.
Finally, we define the prolongation and restriction of the temporal polynomial
order \( k\) in~\eqref{Eq:DefYkl}. For
prolongation and restriction in time of the $p$-multigrid method,
 \begin{equation}
    \label{Eq:DefPrRek}
    \boldsymbol I_l^{\frac{k}{2},k} :  \; \mathbb R^{D^{\frac{k}{2},r}_{l,s}} \to \mathbb R^{D^{k,r}_{l,s}} \,, \qquad
    \boldsymbol I_l^{k,\frac{k}{2}} :  \; \mathbb R^{D^{k,r}_{l,s}}  \to  \mathbb R^{D^{\frac{k}{2},r}_{l,s}}
\end{equation}
are defined analogously to~\eqref{Eq:DeftPrRe} along with~\eqref{Def:IsoTme}. Space-time combined grid transfer operations of the $p$-multigrid method are then constructured by concatenation of the operators in~\eqref{Eq:DefPrRer} and~\eqref{Eq:DefPrRek}, similarly to~\eqref{Eq:DefTlspr}, such that
\begin{equation}
\label{Eq:DefoTsl}
\boldsymbol T_{l,s}^{\frac{k}{2},k;\frac{r}{2}r,r} \coloneqq \boldsymbol I_{l}^{ \frac{k}{2},k} \circ \boldsymbol{\overline T}^{\frac{r}{2}r,r}_{s} \qquad \text{and} \qquad
\boldsymbol T_{l,s}^{k,\frac{k}{2};r,\frac{r}{2}}  \coloneqq \boldsymbol I_{l}^{k,\frac{k}{2}} \circ \boldsymbol{\overline T}^{r,\frac{r}{2}}_{s}\,.
\end{equation}

\subsection{Space-time Vanka smoother}
The smoother for appoximating the solutions of the linear systems on the multigrid levels is a further building block of multigrid techniques. It aims at smoothing out high frequency errors in the solutions to the linear systems
\begin{equation}
  \label{Eq:LSMG}
  \boldsymbol S^{k,r}_{l,s} \boldsymbol X^{k,r}_{l,s}  = \boldsymbol B^{k,r}_{l,s}
\end{equation}
on the $hp$ multigrid hierarchy. On the finest $hp$ multigrid
level,~\eqref{Eq:LSMG} recasts the linear system of Problem~\ref{Prob:GloAlg} in
its algebraic form. On the coarser levels, the right-hand side
in~\eqref{Eq:LSMG} corresponds to residuals and the solution to corrections. The
\(V\)-cycle $hp$ multigrid iteration is outlined in detail in \Cref{sec:alg} and in Algorithm~\ref{alg:stmg}.
The smoothing operation is done by a simple iteration
\[
{\mathtt{smoother}}\Big(\boldsymbol S^{k,r}_{l,s},\,\boldsymbol B^{k,r}_{l,s}\Big) \approx \Big( \boldsymbol S^{k,r}_{l,s}\Big)^{-1}\boldsymbol B^{k,r}_{l,s}\,,
\]
and reduces the high frequency components of the residual \(\boldsymbol B^{k,r}_{l,s} -\boldsymbol S^{k,r}_{l,s}\boldsymbol X^{k,r}_{l,s}\). The linear
(optimal) complexity of the geometric multigrid method is achieved when the
reduction rate of the residual is constant across levels. In our implementation
we use a space-time cell wise Vanka smoother. For a detailed description in the
STFEM we refer
to~\cite{anselmannGeometricMultigridMethod2023,anselmannEnergyefficientGMRESMultigrid2024}
and the references therein. For the local (time-stepping)
approach~\eqref{Eq:AlgSysTMS}, the Vanka smoother is built for all $(k+1)\cdot
(M^{\boldsymbol v}_{r+1,s}+M^p_{r,s})$ degrees of freedom of a space-time
element which amounts to a block size of $(k+1)(d{(r+2)}^d+(r+1)^d)$, with space
dimension $d$. We use an inner direct solver. For macro time steps and the
global in time approach (cf.\ Remark~\ref{rem:GLSP}) the Vanka smoother is
assembled over the  subintervals, which increases the block size. More precisely, on the space-time mesh \( \mathcal \mathcal T_h \otimes \mathcal M_\tau \) the Vanka smoother is defined, for \(\boldsymbol S\coloneqq \boldsymbol S^{k,r}_{l,s}\) and \(\boldsymbol b\coloneqq \boldsymbol B^{k,r}_{l,s}\), by
\begin{equation}\label{vanka0}
  {\mathtt{smoother}}(\boldsymbol S,\,\boldsymbol b)
  =\bigg(\sum_{T\in \mathcal T_h \otimes \mathcal M_\tau}\boldsymbol R_{T}^\top {[\boldsymbol R_T \boldsymbol S_T\boldsymbol
    R_T^\top]}^{-1}\boldsymbol R_T\bigg) \boldsymbol b\,,
\end{equation}
where \(\boldsymbol R_{T}\) is the restriction to those nodes that belong to the
space-time mesh element \(T\in\mathcal \mathcal T_h \otimes \mathcal M_\tau\) and $\boldsymbol S_T$ is the corresponding local system matrix on $T$. For their definition we refer
to~\cite{anselmannGeometricMultigridMethod2023,anselmannEnergyefficientGMRESMultigrid2024}. The smoother is computationally expensive, and its application has the cellwise complexity of \(O\big({(k+1)}^2{(d{(r+2)}^d+(r+1)^d)}^2\big) \). With a relaxation
parameter \(\omega_\ell\in (0,\,1)\), a smoother iteration
(cf.~\Cref{alg:stmg}) is then given by
\begin{equation}\label{vanka}
  \mathtt{Smoother}(\boldsymbol S,\boldsymbol b,\boldsymbol u)=\boldsymbol u + \omega \,{\mathtt{smoother}}(\boldsymbol S,\,\boldsymbol b -\boldsymbol S \boldsymbol u).
\end{equation}
Our current implementation of the smoother does not take full advantage of the
block structure arising from the tensor-product STFEM.\@ The block structure is
used to avoid the assembly of the space-time system matrix. We will leverage the
block structure to improve the smoother efficiency in future work.


\subsection{The {\boldmath$hp$} space-time multigrid method}
\label{sec:alg}
We introduce our V-cycle $hp$ space-time multigrid approach for tensor-product STFEMs. We assume that the linear system of
Problem~\ref{Prob:GloAlg} is respresented on the multigrid levels $l=0,\ldots,L$
and $s=0,\ldots,S$ and for the polynomial degrees $k,r\in \N$
by~\eqref{Eq:LSMG}. While $k=0$, $r=0$ is theoretically possible, we
exclude this due to the suboptimal performance in practice. For ease of
presentation, we assume, without loss of generality,  that $S \geq L$ and $r
\geq k$. This is a reasonable condition for FEM flow simulations that are
often characterized by dominating dynamics in the spatial variables. The $hp$
STMG for~\eqref{Eq:LSMG} is outlined in \Cref{alg:stmg} and sketched in
\Cref{fig:stmg}. We recall that the $hp$ STMG is used as a preconditioner for GMRES iterations
to~\eqref{Eq:LSMG}.
\vspace*{-1ex}
\begin{algorithm}[H]
  \caption{$hp$ space time multigrid algorithm for Problem~\ref{Prob:GloAlg}.}
    \label{alg:stmg}
    \textbf{Start.}\quad System \(\boldsymbol{S}^{k,r}_{l,s}\,\boldsymbol{X}^{k,r}_{l,s} = \boldsymbol{B}^{k,r}_{l,s}\),
    multigrid levels \(0 \le l \le L\), \(0 \le s \le S\), polynomial orders \(k
    \le r\), smoothing steps \(\nu_1\), \(\nu_2\), smoother $\boldsymbol W^{k,r}_{l,s}$.\\
    \textbf{1. Presmoothing.}\quad{}Given an initial guess $ \boldsymbol X^{k,r;0}_{l,s}\in
    \R^{D_{l,s}^{k,r}}$, compute $\boldsymbol X^{k,r;\nu_0}_{l,s}$ by $\nu_1$ linear smoothing steps as
    \begin{equation}
      \label{Alg:VGMGPre}
      \boldsymbol X^{k,r;\nu+1}_{l,s} = \boldsymbol X^{k,r}_{l,s} - \boldsymbol  (\boldsymbol W^{k,r}_{l,s})^{-1} (\boldsymbol S^{k,r}_{l,s} \boldsymbol X^{k,r;\nu}_{l,s} - \boldsymbol  B^{k,r}_{l,s})\,, \quad \textbf{for} \;\; \nu=0,\ldots,\nu_1-1\,.
    \end{equation}
    \textbf{2. Coarse grid correction ($p$-multigrid).}\quad\textbf{If} $r> K$
    then restrict the residual
  \begin{equation}
    \label{Alg:VGMGRes}
    \boldsymbol B_{l,s}^{k,\frac{r}{2}} = \boldsymbol T_{l,s}^{k,k;r,\frac{r}{2}} (\boldsymbol B^{k,r}_{l,s} -\boldsymbol S^{k,r}_{l,s} \boldsymbol X^{k,r;\nu_1}_{l,s})\,,
  \end{equation}
  and let $\boldsymbol Y^{k;\frac{r}{2}}_{l,s} \in \R^{D_{l,s}^{k,\frac{r}{2}}}$
  satisfy
  \begin{equation}
    \label{Alg:VGMGCor}
    \boldsymbol S^{k,\frac{r}{2}}_{l,s} \boldsymbol Y^{k,\frac{r}{2}}_{l,s} = \boldsymbol B^{k,\frac{r}{2}}_{l,s}\,.
  \end{equation}
  \textbf{Else} restrict the residual
\end{algorithm}
\begin{algorithm}[H]
  \captionsetup{labelformat=empty}
  \caption{Continued \Cref{alg:stmg}}
  \begin{equation}
    \label{Alg:VGMGRes2}
    \boldsymbol B_{l,s}^{k,\frac{k}{2};r,\frac{r}{2}} = \boldsymbol T_{l,s}^{k,\frac{k}{2};r,\frac{r}{2}} (\boldsymbol B^{k,r}_{l,s} -\boldsymbol S^{k,r}_{l,s} \boldsymbol X^{k,r;\nu_1}_{l,s})\,,
  \end{equation}
  and let $\boldsymbol Y^{\frac{k}{2},\frac{r}{2}}_{l,s} \in \R^{D_{l,s}^{\frac{k}{2};\frac{r}{2}}}$ satisfy
  \begin{equation}
    \label{Alg:VGMGCor2}
    \boldsymbol S^{\frac{k}{2},\frac{r}{2}}_{l,s} \boldsymbol Y^{\frac{k}{2},\frac{r}{2}}_{l,s} = \boldsymbol B^{\frac{k}{2},\frac{r}{2}}_{l,s}\,.
  \end{equation}
  \textbf{If} $r=2$, continue to step \textbf{3},
  \textbf{else if} $r>2$, compute an approximation to $\boldsymbol Y^{k;\frac{r}{2}}_{l,s}$ or
  $\boldsymbol Y^{ \frac{k}{2};\frac{r}{2}}_{l,s}$, by one step
  of the $p$-multigrid algorithm at polynomial degree $\frac{r}{2}$ to~\eqref{Alg:VGMGCor}
  or~\eqref{Alg:VGMGCor2} with initial guess $ \boldsymbol Y^{k,\frac{r}{2};0}_{l,s} =
  \boldsymbol 0$ or $ \boldsymbol Y^{ \frac{k}{2},\frac{r}{2};0}_{l,s} = \boldsymbol
  0$, respectively.%
  \\
\textbf{3. Coarse grid correction of $h$-multigrid.}\quad\textbf{If} $s>L$, restrict the residual
  \begin{equation}
    \label{Alg:VGMGResh}
    \boldsymbol B_{l,s-1}^{1,1} = \boldsymbol T_{l,l;s,s-1}^{1,1} (\boldsymbol B^{1,1}_{l,s} -\boldsymbol S^{1,1}_{l,s} \boldsymbol Y^{1,1}_{l,s})\,,
  \end{equation}
  and let $\boldsymbol Y^{1,1}_{l,s-1} \in \R^{D_{l,s-1}^{1,1}}$ satisfy
  \begin{equation}
    \label{Alg:VGMGCorh}
    \boldsymbol S^{1,1}_{l,s-1} \boldsymbol Y^{1,1}_{l,s-1} = \boldsymbol B^{1,1}_{l,s-1}\,.
  \end{equation}
  \textbf{Else} restrict the residual
  \begin{equation}
    \label{Alg:VGMGResh2}
    \boldsymbol B_{l-1,s-1}^{1,1} = \boldsymbol T_{l,l-1;s,s-1}^{1,1} (\boldsymbol B^{1,1}_{l,s} -\boldsymbol S^{1,1}_{l,s} \boldsymbol X^{1,1;\nu_1}_{l,s})\,,
  \end{equation}
  and let $\boldsymbol Y^{1,1}_{l-1,s-1} \in \R^{D_{s-1,l-1}^{1,1}}$ satisfy
  \begin{equation}
    \label{Alg:VGMGCorh2}
    \boldsymbol S^{1,1}_{l-1,s-1} \boldsymbol Y^{1,1}_{l-1,s-1} = \boldsymbol B^{1,1}_{l-1,s-1}\,.
  \end{equation}
  \textbf{If} $s=2$, solve~\eqref{Alg:VGMGCorh2}, \textbf{else if} $s>2$, compute an approximation to $\boldsymbol Y^{1,1}_{l,s-1}$ or $\boldsymbol Y^{1,1}_{l-1,s-1}$, by applying one step of the $h$-multigrid algorithm at level $s-1$ to~\eqref{Alg:VGMGCorh} or~\eqref{Alg:VGMGCorh2} with initial guess $ \boldsymbol Y^{1,1;0}_{l,s-1} = \boldsymbol 0$ or $ \boldsymbol Y^{1,1;0}_{l-1,s-1} = \boldsymbol 0$, respectively.\\
 \textbf{If}  $r=1$,\\
 \mbox{}\qquad \textbf{if} $s\leq L$,  set
 \begin{equation}
  \label{Alg:VGMGUpd2}
  \boldsymbol X^{1,1;\nu_1+1}_{l,s} = \boldsymbol X^{1,1;\nu_1}_{l,s} +  \boldsymbol T_{l-1,l;s-1,s}^{1,1} \boldsymbol Y^{1,1}_{l-1,s-1} \,,
\end{equation}
\qquad \textbf{else} set
 \begin{equation}
  \label{Alg:VGMGUpd1}
  \boldsymbol X^{1,1;\nu_1+1}_{l,s} = \boldsymbol X^{1,1;\nu_1}_{l,s} +  \boldsymbol T_{l,l;s-1,s}^{1,1} \boldsymbol Y^{1,1}_{l-1,s-1} \,,
\end{equation}
\textbf{else if} $r \leq K$,  set
 \begin{equation}
  \label{Alg:VGMGUpd4}
  \boldsymbol X^{k,r;\nu_1+1}_{l,s} = \boldsymbol X^{k,r;\nu_1}_{l,s} +  \boldsymbol T_{l,s}^{\frac{k}{2},k;\frac{r}{2},r} \boldsymbol Y^{\frac{k}{2},\frac{r}{2}}_{l,s} \,,
\end{equation}
\mbox{}\qquad  \textbf{else} set
 \begin{equation}
  \label{Alg:VGMGUpd3}
  \boldsymbol X^{k,r;\nu_1+1}_{l,s} = \boldsymbol X^{k,r;\nu_1}_{l,s} +  \boldsymbol T_{l,s}^{k,k;\frac{r}{2},r} \boldsymbol Y^{k,\frac{r}{2}}_{l,s} \,.
\end{equation}
  \textbf{4. Postsmoothing.}\quad{}Compute $\boldsymbol X^{k,r;\nu_1+\nu_2+1}_{l,s}\in \R^{D_{l,s}^{k,r}}$ by $\nu_2$ linear smoothing steps
  \begin{equation}
    \label{Alg:VGMGPost}
    \boldsymbol X^{k,r;\nu+1}_{l,s} = \boldsymbol X^{k,r}_{l,s} - \boldsymbol  (\boldsymbol W^{k,r}_{l,s})^{-1} (\boldsymbol S^{k,r}_{l,s} \boldsymbol X^{k,r;\nu}_{l,s} - \boldsymbol  B^{k,r}_{l,s})\,, \quad \textbf{for} \;\; \nu=\nu_1+1 ,\ldots,\nu_1+\nu_2\,.
  \end{equation}
  Set $\boldsymbol X^{k,r;\nu_1+\nu_2+1}_{l,s}$ as the solution of one iteration of the $V$-cycle $hp$ multigrid algorithm.
\end{algorithm}

\subsection{Multigrid Sequence Generation}
\begin{algorithm}[htbp]
  \caption{\textsc{ConstructHierarchy}$(h_L,\,h_0,\,r_L,\,r_0)$}\label{alg:ConstructHierarchy}
  \begin{algorithmic}[1]
    \REQUIRE{Fine and coarse mesh size $h_{L}$, $h_{0}$, polynomial degrees $r_{L}$, $r_{0}$.}
    \STATE{$\mathcal{H} \gets (),\;\;h \gets h_{L_{g}},\;\;r \gets r_{L}$}
    \WHILE{$r\geq r_0$}
    \STATE{$\mathcal{H} \gets (h,\,r) \times \mathcal{H}$} \COMMENT{Polynomial coarsening}
    \STATE{$r \gets \lfloor r/2 \rfloor$}  \COMMENT{halve polynomial degree}
    \ENDWHILE{}
    \WHILE{$h\leq h_0$}
    \STATE{ $\mathcal{H} \gets (h,\,r) \times \mathcal{H}$}\COMMENT{Geometric coarsening}
    \STATE{ $h \gets 2 h$}     \COMMENT{Coarsen triangulation (``double mesh
      size'' for simplicity)}
    \ENDWHILE{}
    \RETURN{$\mathcal{H}$}
  \end{algorithmic}
\end{algorithm}
\begin{algorithm}[htbp]
  \caption{\textsc{CombineHierarchies}$(\mathcal{H}_h,\,\mathcal{H}_\tau)$}\label{alg:CombineHierarchies}
\begin{algorithmic}[1]
  \REQUIRE{ Spatial hierarchy obtained by \Cref{alg:ConstructHierarchy}: $\mathcal{H}_h=\left((h_\ell,\,p_\ell)\right)_{\ell=1}^{\mathcal{S}}$}
  \REQUIRE{} Temporal hierarchy obtained by \Cref{alg:ConstructHierarchy}: $\mathcal{H}_\tau=\left((\tau_\ell,\,k_\ell)\right)_{\ell=1}^{\mathcal{L}}$
\STATE{ $\mathcal{H}_{st} \gets (),\quad(\tau_{\text{pad}},\,k_{\text{pad}}) \gets \mathcal{H}_\tau[\mathcal{L}]$}
\FOR{$\ell = \mathcal{L} + 1$ to $\mathcal{L}_{\max}$}
\STATE{ $\mathcal{H}_\tau \gets \mathcal{H}_\tau \times (\tau_{\text{pad}},\,k_{\text{pad}})$}\label{alg:combinehierarchies:pad}\COMMENT{Pad the hierarchy to length $\mathcal{L}_{\max}$}
\ENDFOR{}
\FOR{$\ell = 1$ to $\mathcal{L}_{\max}$}
\STATE{Let $(\tau_\ell,\,k_\ell) \gets \mathcal{H}_\tau[\ell],\quad (h_\ell,\,r_\ell)
  \gets \mathcal{H}_h[\ell]$}\COMMENT{Combine level by level}
\STATE{ $\boldsymbol{H}_{l_{\ell},s_{\ell}}^{\,k_\ell,\,r_\ell} \coloneqq
  Y_{l_\ell}^{\,k_\ell}(I)\otimes\boldsymbol{V}_{s_{\ell}}^{\,r_\ell+1}(\Omega),\quad
  H_{l_{\ell},s_{\ell}}^{\,k_\ell,\,r_\ell} \coloneqq
Y_{l_\ell}^{\,k_\ell}(I)\otimes Q_{s_{\ell}}^{\,r_\ell}(\Omega)$}
\STATE{$\mathcal{H}_{st} \gets \mathcal{H}_{st} \times
  (\boldsymbol{H}_{l_{\ell},s_{\ell}}^{\,k_\ell,\,r_\ell},\, H_{l_{\ell},s_{\ell}}^{\,k_\ell,\,r_\ell})$}\label{alg:combinehierarchies:stfespaces}
  \ENDFOR{}
 \RETURN{ $\mathcal{H}_{st}$}
\end{algorithmic}
\end{algorithm}
Finally, we still comment on some implementational aspects for Algorithm~\ref{alg:stmg}. We construct the space-time multigrid hierarchy by coarsening sequences of
spatial and temporal finite element spaces, which are combined by tensor
products, according to two guiding principles:
\begin{itemize}
\item[\customlabel{itm:p1}{(P1)}]
  \textbf{Spatial Coarsening over Temporal Coarsening}:
  Perform geometric coarsening first in the spatial dimension, then in the temporal dimension.
\item[\customlabel{itm:p2}{(P2)}]
  \textbf{Polynomial over Geometric Coarsening}:
  Apply coarsening in polynomial degrees \((r\)/\(k\)) before geometric coarsening \((h\)/\(\tau\)).
\end{itemize}
Following~\ref{itm:p2}, the sequences of nested temporal and spatial finite
element spaces are generated through \Cref{alg:ConstructHierarchy}. We generate
a temporal hierarchy of finite element spaces \(Y_l^k(I)\)
(cf.~\eqref{Eq:DefYkl}) with geometric level $l$ and polynomial degree $k$. Let
\(L\) be the number of geometric levels in time, and
\(\lfloor \log_2(k)\rfloor\) the number of polynomial levels. Thus, the number
of temporal levels is \(\mathcal{L} \coloneqq L + \lfloor \log_2(k)\rfloor\).
The spatial hierarchy of finite element spaces
\(\boldsymbol{V}_s^{r+1}(\Omega),\,Q_s^r(\Omega)\) on geometric level $s$ with
polynomial degree $r$ (cf.~\eqref{Eq:NFES}) is generated analogously. Let \(S\)
be the number of geometric levels in space, and \(\lfloor \log_2(r)\rfloor\) the
number of polynomial levels. Thus, the number of spatial levels is
\(\mathcal{S} \coloneqq S + \lfloor \log_2(r)\rfloor\). These two hierarchies
are merged into a single STMG sequence of size
\(\mathcal{L}_{\max} = \max(\mathcal{L}, \mathcal{S})\). If
\(\mathcal{L} < \mathcal{L}_{\max}\), we pad the final temporal spaces to match
the finer levels in time, setting
\(Y_m^k(I) = Y_{\mathcal{L}}^k(I), m=L+1,\dots,S\)
(cf. \Cref{alg:CombineHierarchies} line~\ref{alg:combinehierarchies:pad}). If
\(\mathcal{S} < \mathcal{L}_{\max}\), an analogous padding applies to
\(\boldsymbol{V}_m^{r+1}(\Omega)\) and $Q_m^r(\Omega)$ if
\(\mathcal{L}>\mathcal{S}\). For a level
\(\ell\in\{1,\dots,\mathcal{L}_{\max}\}\), we denote $l_\ell$ and $s_\ell$ as
the temporal and spatial geometric level, $k_\ell$ and $r_{\ell}$ as the
temporal and spatial polynomial degree. Following~\ref{itm:p1}, the
space-time finite element spaces
\(\boldsymbol{H}_{l_\ell,s_\ell}^{\,k_\ell,\,r_\ell+1}\) and
\(H_{l_\ell,s_\ell}^{\,k_\ell,\,r_\ell}\), where
\(\ell\in\{1,\dots,\mathcal{L}_{\max}\}\), are generated in
\Cref{alg:CombineHierarchies} line~\ref{alg:combinehierarchies:stfespaces}.
According to the construction in \Cref{alg:CombineHierarchies}
and~\ref{alg:ConstructHierarchy}, the spaces are ordered such that the coarsest
space-time function space, characterized by large $h$, $\tau$ and small $p$,
$k$, is located at $\ell=0$. Two additional principles for the generation of the
multgrid hierarchy naturally arise from \Cref{alg:CombineHierarchies} and~\ref{alg:ConstructHierarchy}.
\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
\item[\customlabel{itm:p3}{(P3)}] \textbf{True Space-Time Multigrid at Coarsest
    Level}: Levels with space-time coarsening are put at the lower levels of the hierarchy.
\item[\customlabel{itm:p4}{(P4)}] \textbf{Padding for Pure Space or Time Level}:
  Padding with identical function spaces is done at the finer
  levels.
\end{itemize}
For an example of a generated Multigrid sequence, we refer to \Cref{sec:example-mgseq}.
Although placing full space-time levels at the top of the multigrid hierarchy
could more rapidly reduce the total number of space-time degrees of freedom,
they are placed according to~\ref{itm:p3}. This choice is guided by a CFL-type
condition that is derived in~\cite{chaudet-dumasOptimizedSpaceTimeMultigrid2023}
for one-dimensional space-time multigrid approaches to the heat equation, which
ensures convergence under space-time coarsening. Numerical experiments indicate
that such a condition also arises for the Stokes system: adopting ``early'' space-time coarsening at the top of the hierarchy can degrade the performance of multigrid methods for STFEMs.
\subsection{Matrix-free operator evaluation}
In this work, linear operators are evaluated without the explicit formation and
storage of system matrices. For this, we rely on the matrix-free multigrid
framework in the \texttt{deal.II}
library~\cite{africa_dealii_2024,kronbichlerGenericInterfaceParallel2012,munchEfficientDistributedMatrixfree2023,fehnHybridMultigridMethods2020}.
A matrix-vector product \(\boldsymbol{Y} =\boldsymbol S \boldsymbol X\)
(cf.~\eqref{Eq:LSMG}) is computed via global accumulation of local element-wise
operations,
\[
  \boldsymbol{S} \boldsymbol X
  =
  \sum_{c=1}^{n_c}
  \boldsymbol{R}_{c,\mathrm{loc\text{-}glob}}^\top\boldsymbol{S}_c\boldsymbol{R}_{c,\mathrm{loc\text{-}glob}}\boldsymbol X ,
  \quad
  \boldsymbol{S}_c
  =
  \boldsymbol{B}_c^\top\boldsymbol{D}_c\boldsymbol{B}_c,
\]
where \(\boldsymbol{R}_{c,\mathrm{loc\text{-}glob}}\) maps local degrees of
freedom to global indices, \(\boldsymbol{B}_c\) contains shape function
gradients, and \(\boldsymbol{D}_c\) encodes quadrature weights and material
coefficients. Sum-factorization then reduces the multi-dimensional operations to
a product of one-dimensional operations. Vectorization
further accelerates the evaluations.

These techniques are used to assemble matrix-vector products with the spatial
operators in~\eqref{Eq:DefMAB}. The temporal matrices in~\eqref{Eq:DefKMC} are
precomputed as described in~\cite{margenbergSpaceTimeMultigridMethod2024a}.
Products of the form
\(\boldsymbol{M}^{\tau} \otimes \boldsymbol{A}_h\boldsymbol{u}\) are evaluated
by computing \(\boldsymbol{A}_h\boldsymbol{u}^i\) once for each temporal degree
of freedom, followed by a matrix-vector multiplication with the temporal
matrices in a blockwise sense
(cf.~\cite{margenbergSpaceTimeMultigridMethod2024a}). This approach extends
naturally to all Kronecker products in~\eqref{Eq:InAlg}.


\section{Numerical experiments}\label{sec:experiments}
We validate the accuracy and convergence properties of the
proposed $hp$ STMG solver for the Stokes system using a sequence of polynomial
degrees and mesh refinements. We use inf-sup stable
$\mathbb{Q}_{r+1}/\mathbb{P}_{r}^{\text{disc}}$ elements in space and a DG$(k)$
discretization in time. To solve the linear systems of equations, we use a GMRES
method with a single V-cycle $hp$ STMG preconditing step per
iteration. To ensure efficiency and scalability, the number of iterations until
convergence is reached must remain bounded as the mesh size $h$ is reduced or
the polynomial degree $r$ is increased. Thus, we characterize the solver’s
performance in terms of:
\begin{description}[style=unboxed,leftmargin=0cm]\itemsep1pt
\item[\textbf{$\boldsymbol h$-robustness}:] Iteration counts remain bounded
  independently of the mesh size \(h\).
\item[\textbf{$\boldsymbol p$-robustness}:] Iteration counts remain bounded
  independently of the degree \(p\).
\end{description}
Robustness is important to ensure that the computational cost increases linearly
with the problem size, preserving the computational complexity.

The tests were performed on an HPC cluster (HSUper at HSU) with 571 nodes, each with 2 Intel Xeon Platinum 8360Y CPUs and \SI[scientific-notation=false,round-precision=0]{256}{\giga\byte} RAM.\@ The processors
have 36 cores each and the number of MPI processes always match the cores.
As mentioned in \Cref{rem:GLSP}, we restrict ourselves to $\widetilde N=1$, for
computational studies with $\widetilde N>1$ we refere to~\cite{margenbergSpaceTimeMultigridMethod2024a}.
\subsection{Convergence test}
\label{sec:conv-stokes}
\begin{table}[htb]
  \caption{Calculated errors of the velocity and pressure in the space-time $L^2$-norm and experimental order of convergence (eoc) for \(\mathbb{Q}_{r+1}^2/\mathbb{P}_{r}^{\text{disc}}/\text{DG}(r)\) discretizations of the Stokes system for~\eqref{eq:conv-test-v}.}\label{tab:conv-stokes}
    \setlength{\tabcolsep}{7pt}
    \centering\footnotesize
    \begin{tabular}{l|llll|llll}
      \toprule
        &\multicolumn{4}{c|}{$r=4$}&\multicolumn{4}{c}{$r=5$}\\
    $h$ & $e^{\boldsymbol v}_{L^2/L^2}$     &eoc&$e^{p}_{L^2/L^2}$&eoc&$e^{\boldsymbol v}_{L^2/L^2}$ &eoc&$e^{p}_{L^2/L^2}$&eoc\\
    \midrule
    ${2}^{-1}$ & \num{1.00279e-04} &    -&\num{1.14907e-03}&    -&\num{2.71058e-05} &   -  &\num{1.01607e-03} &    -\\
    ${2}^{-2} $& \num{2.32706e-06} & 5.43&\num{1.11534e-04}& 3.36&\num{2.28082e-07} & 6.89 &\num{1.40569e-05} & 6.18\\
    ${2}^{-3} $& \num{3.98114e-08} & 5.87&\num{3.58645e-06}& 4.96&\num{1.87701e-09} & 6.92 &\num{2.29909e-07} & 5.93\\
    ${2}^{-4}$& \num{6.39216e-10} & 5.96&\num{1.12642e-07}& 4.99&\num{1.58961e-11} & 6.88 &\num{3.88539e-09} & 5.89\\
    ${2}^{-5}$& \num{1.10823e-11} & 5.85&\num{3.75088e-09}& 4.91&\num{3.52916e-12} & 2.17 &\num{1.17454e-09} & 1.73\\
    \bottomrule
    \end{tabular}
\end{table}
\begin{table}[htb]
  \centering
  \caption{Number of GMRES iterations until convergence for
    different polynomial degrees $r$ and number of refinements $c$ with  \(\mathbb{Q}_{r+1}^2/\mathbb{P}_{r}^{\text{disc}}/\text{DG}(r)\)
    discretization of the Stokes system and for $hp$ STMG (left) and
    $h$-multigrid in space method (right).}\label{tab:iter-stokes}
  \setlength{\tabcolsep}{5.5pt}
  \begin{minipage}{0.47\textwidth}
      \centering\scriptsize
      \begin{tabular}{ccccccc}
        \toprule
        \(r\backslash c\) &  1  &  2  &  3  &  4  &  5  &  6  \\
        \midrule
                               2& {14.0}& 15.0& 15.0& 14.0& 13.0& 10.6\\
                               3& 19.8& {15.9}& 16.0& 15.0& 13.7& 11.0\\
                               4& 27.8& 23.0& {22.9}& 21.9& 19.0& 15.5\\
                               5& 31.0& 26.4& 26.6& {22.8}& 18.7& 14.9\\
                               6& 45.0& 36.1& 36.7& 29.0& {23.1}& 17.2\\
                               7& 50.8& 43.8& 42.8& 32.8& 25.6& {19.6}\\
        \bottomrule
      \end{tabular}
  \end{minipage}
  \hspace{.3cm}
  \begin{minipage}{0.47\textwidth}
    \centering\scriptsize
      \begin{tabular}{ccccccc}
        \toprule
        \(r\backslash c\) &  1  &  2  &  3  &  4  &  5  &  6  \\
        \midrule
                         2& {14.0}& 15.0& 15.0& 14.0& 13.0& 10.6\\
                         3& 19.0& {17.9}& 18.9& 18.3& 16.4& 14.0\\
                         4& 24.0& 26.8& {24.7}& 24.6& 21.4& 18.4\\
                         5& 26.0& 26.4& 28.8& {27.7}& 24.7& 21.9\\
                         6& 35.0& 33.9& 34.6& 30.9& {29.6}& 26.9\\
                         7& 40.0& 38.8& 39.6& 36.7& 34.5& {31.9}\\
        \bottomrule
      \end{tabular}
  \end{minipage}
\end{table}
As a first test case, we consider a model problem on the space-time domain $\Omega\times I = [0,1]^2\times [0, 1]$ with prescribed solution given for the velcity $\boldsymbol v \colon \Omega\times I \to \mathbb{R}^2$ and pressure
$p \colon \Omega\times I \to \mathbb{R}$ by
\begin{subequations}\label{eq:conv-test}
\begin{align}
  \label{eq:conv-test-v}
  \boldsymbol v(\mathbf{x},\,t) &= \sin(t) \begin{pmatrix} \sin^2(\pi x) \sin(\pi y) \cos(\pi y) \\
                                        \sin(\pi x) \cos(\pi x) \sin^2(\pi y) \end{pmatrix},\\
\label{eq:conv-test-p} p(\mathbf{x},\,t) &= \sin(t) \sin(\pi x) \cos(\pi x)
  \sin(\pi y) \cos(\pi y)\,.
\end{align}
\end{subequations}
We set the kinematic viscosity to $\nu = 0.1$ and choose
the external force $\mathbf{f}$ such that the solution~\eqref{eq:conv-test}
satisfies~\eqref{Eq:SE}. The initial velocity is
prescribed as zero and homogeneous Dirichlet boundary conditions are imposed on
$\partial\Omega$ for all times
\[
  \boldsymbol v = \mathbf{0}\text{ on }\Omega\times \{0\},\quad
  \boldsymbol v = \mathbf{0}, \text{ on } \partial \Omega\times (0, T]\,.
\]
The space-time mesh $\mathcal{T}_{h}\otimes\mathcal{M}_{\tau}$ is a uniform
triangulation of the space-time domain $\Omega\times I$. We use discretizations
with varying polynomial degrees $r \in \{3,\, 4,\dots,\,8\}$ in space and
$k=r$ in time to test the convergence.

Table~\ref{tab:conv-stokes} shows the findings of our convergence study for
$r\in\{4,5\}$. The expected orders of convergence match with the experimental
orders. For a full account of all tests, we refer to \Cref{fig:conv-stokes}. The
convergence orders for the velocity doesn't always reach exactly $r+2$ due to
the polynomial order $r$ in time. Table~\ref{tab:iter-stokes} shows the number
of GMRES iterations required for convergence for these experiments. We compare
the $hp$ STMG with a pure spatial $h$-multigrid method. The $hp$ STMG method
exhibits superior robustness and significantly reduces the number of iterations,
as the polynomial degree and mesh refinement increase. In specific settings on
coarse meshes and low polynomial orders, the $hp$ STMG can be outperformed by
other strategies (e.\,g.\ pure $h$-multigrid, $h$-multigrid in space and
$p$-multigrid in time only). However, it consistently outperforms them on finer
meshes and higher polynomial degrees. Further, although polynomial coarsening
$r\rightarrow r-1$ can reduce GMRES iterations and improve $p$-robustness, it
yields no significant gains in wall-clock time due to the slower decrease of the
block size. However, the reduction of the block size through polynomial
coarsening increases the efficiency significantly. In particular, halving the
polynomial degree $r\rightarrow \tfrac{r}{2}$ provides the best improvements in
solver performance.

We note that only a single smoothing step is performed on all levels. While additional smoothing steps could reduce
the number of GMRES iterations and improve the $h$- and $p$-robustness, it may
not improve the time to solution for matrix-free methods. We use a matrix-based
smoother~\eqref{vanka}, so keeping the number of smoothing steps small and reducing the
complexity is the most important part of the overall
performance, see also~\cite{margenbergSpaceTimeMultigridMethod2024a}. In the
present section, we achieve excellent $h$-robustness, but not full
$p$-robustness. We revisit this topic in the following sections and address
whether an increase in smoothing steps improves the $p$-robustness.

\subsection{Lid-driven cavity flow}
\begin{table}[htb]
  \centering
  \caption{Average number of GMRES iterations per subproblem
    $\overline{n}_{\text{iter}}$ for different numbers of smoothing steps
    $n_{\text{sm}}$, polynomial degrees $r$ and refinements $c$. We also include
    the number of global space-time cells (\#
    st-cells).}\label{tab:lid-iter-stokes}
  \sisetup{round-precision=3}
  \footnotesize
  \begin{tabular}{ll|rr|rr|rr}
    \toprule
     &                & \multicolumn{2}{c|}{$n_{\text{sm}}=1$}                              &\multicolumn{2}{c|}{$n_{\text{sm}}=2$}                  &\multicolumn{2}{c}{$n_{\text{sm}}=4$}\\
    $c$&\# st-cells   & {$r=2$}  & {$r=3$}                 & {$r=2$}   & {$r=3$}   & {$r=2$}   & {$r=3$}\\
  \midrule
  $4$&\num{1048576}   &18.14  &28.09  & 10.56  & 16.22  & 6.83  & 10.66 \\
  $5$&\num{16777216}  &16.97  &25.72  &  9.32  & 13.79  & 5.83  &  9.17 \\
  $6$&\num{268435456} &14.82  &21.95  &  7.60  & 11.26  & 4.86  &  7.56 \\
  $7$&\num{4294967296}&12.52  &18.41  &  6.39  &  9.25  & 3.88  &  6.27 \\
  \bottomrule
  \end{tabular}
  \caption{Throughput $\theta$ \eqref{eq:throughput} for different values of $n_{\text{sm}}$, $r$ and $c$.}\label{tab:lid-throughput-stokes}
  \setlength{\tabcolsep}{5pt}
  \begin{tabular}{ll|rr|rr|rr}
    \toprule
    &                & \multicolumn{2}{c|}{$n_{\text{sm}}=1$}                              &\multicolumn{2}{c|}{$n_{\text{sm}}=2$}                  &\multicolumn{2}{c}{$n_{\text{sm}}=4$}\\
    $c$&\# st-cells   & {$r=2$}  & {$r=3$}                 & {$r=2$}   & {$r=3$}   & {$r=2$}   & {$r=3$}\\
    \midrule
  $4$&\num{1048576}    &\eval[0]{302520576/149.4}    &\eval[0]{927534080/629.4}  &\eval[0]{302520576/158.4}  &\eval[0]{927534080/699.2} &\eval[0]{302520576/185} &\eval[0]{927534080/883.8}\\
  $5$&\num{16777216}   &\eval[0]{4708913664/329}     &\eval[0]{14531434496/1246}  &\eval[0]{4708913664/331.2}  &\eval[0]{14531434496/1285} &\eval[0]{4708913664/375.5}  &\eval[0]{14531434496/1641}\\
  $6$&\num{268435456}  &\eval[0]{74307412992/958.8}  &\eval[0]{230058635264/5066}  &\eval[0]{74307412992/917.3}  &\eval[0]{230058635264/6012}  &\eval[0]{74307412992/1105} &\eval[0]{230058635264/6647}\\
  $7$&\num{4294967296} &\eval[0]{1180701050880/6502} &\eval[0]{3661497393152/45990} &\eval[0]{1180701050880/7483}  &\eval[0]{3661497393152/47720} &\eval[0]{1180701050880/7977} &\eval[0]{3661497393152/63030}\\
  \bottomrule
  \end{tabular}
\end{table}
\begin{figure}[htbp]
\includegraphics{figures/stokes-figure1.pdf}
\caption{\label{fig:lid-strong-scale}Strong scaling test results for the STMG
  algorithm with varying numbers of smoothing steps. The left plot shows the
  time to solution over the number of MPI processes. The dashed gray lines
  indicate the optimal scaling. The right plot depicts the degrees of freedom
  (dofs) processed per second over the number of MPI processes.}
\end{figure}
\begin{figure}[htbp]
  \includegraphics{figures/stokes-figure2.pdf}
  \includegraphics{figures/stokes-figure3.pdf}
  \caption{\label{fig:lid-strong-scale-rel}Time spent in different parts of the
    lid-driven cavity flow simulation, executed on
    $\num[scientific-notation=false,round-precision=0]{18432}$ MPI processes.
    The simulations were conducted for $c=7$, $r\in\{3,\,4\}$,
    $n_{\text{sm}}\in\{1,\,2,\,4\}$.}
\end{figure}
We now study the more sophisticed benchmark problem of lid-driven cavity flow.
The space-time mesh $\mathcal{T}_{h}\times\mathcal{M}_{\tau}$ is a uniform triangulation of the space-time domain $\Omega\times I=[0,\,1]^3\times [0,\,8]$, refined globally $c$ times. A Dirichlet profile
\(\mathbf v_{D}\) is prescribed at the upper boundary
\(\Gamma_{D}=[0,\,1]^{2}\times \{1\}\subset \partial \Omega\) as
\begin{equation}
    \mathbf v_{D}(x,\,y,\,z,\,t)=\sin\left(\tfrac{\pi}{4} t\right) \text{  on  } \Gamma_{D}\times [0,\,8]\,.
\end{equation}
On the other boundaries, denoted by
\(\Gamma_{\text{wall}}=\partial \Omega \setminus\Gamma_{D}\) we use no-slip
boundary conditions. We employ discretizations with different polynomial degrees
$r \in \{2,\, 3\}$ in space. For the time discretization we set $k=r$. For the
strong scaling test shown in \Cref{fig:lid-strong-scale} we set $c=7$, which
results in $\num[scientific-notation=false,round-precision=0]{2048}$ time cells
and $\num[scientific-notation=false,round-precision=0]{2097152}$ space cells.
This
configuration yields \num[scientific-notation=false,round-precision=0]{446960131} and \num[scientific-notation=false,round-precision=0]{192171395} spatial degrees
of freedom for \(r=3\) and \(r=2\), respectively, and
\num[scientific-notation=false,round-precision=0]{3661497393152} and \num[scientific-notation=false,round-precision=0]{1180701050880} global space-time dofs. The
resulting local linear systems each involve \num[scientific-notation=false,round-precision=0]{1787840524} unknowns for
\(r=3\) and \num[scientific-notation=false,round-precision=0]{576514185} unknowns for \(r=2\). The average number of GMRES iterations
$\overline{n}_{\text{iter}}$ for different values of
$n_{\text{sm}}\in \{1,\,2,\,4\}$, $r \in \{2,\, 3\}$ and
$c\in \{4,\,5,\,6,\,7\}$ are collected in Table~\ref{tab:lid-iter-stokes}. To
compare the computational efficiency, we measure the
\emph{throughput}. Let \( W_{\text{total}}(n_{\text{sm}}, c, r) \) be the total walltime,
and \( N_{\text{dof}}(c, r) \) the total number of degrees of freedom. The
throughput $\theta(n_{\text{sm}}, c, r)$ is defined as
\begin{equation}
\label{eq:throughput}
\theta(n_{\text{sm}}, c, r) = \frac{N_{\text{dof}}(c, r)}{W_{\text{total}}(n_{\text{sm}}, c, r)}.
\end{equation}
In addition to the scaling test and performance of the iterative solver, we
verify the convergence of our discretization by studying a goal quantity in
Appendix~\ref{sec:pdiff}. In Table~\ref{tab:lid-throughput-stokes}, we summarize
\( \theta \) using walltimes obtained on
$\num[scientific-notation=false,round-precision=0]{13824}$ MPI ranks in the same
configurations as presented in Table~\ref{tab:lid-iter-stokes}. Increasing the
number of smoothing steps, \(n_{\text{sm}}\), reduces the GMRES iterations, but
the higher cost per iteration leads to increased wall times. A larger
\(n_{\text{sm}}\) also improves \(p\)-robustness, which is satisfactory but
could be improved. Overall, the Vanka smoother~\eqref{vanka} is effective.
However, cell-wise direct solves introduce significant overhead, especially at
higher polynomial degrees. In \Cref{fig:lid-strong-scale-rel} we show the
relative execution time spent in different parts of the program within the
strong scaling test for different $n_{\text{sm}}$. The \textit{MG w/o Smoother}
segment corresponds to the $hp$ STMG without its smoothing steps, i.e.\ operator
evaluations and grid transfers. Its contribution decreases as the number of
smoothing steps increases. In contrast, the \textit{Smoother} segment,
consistently dominates the wall time. Its cost depends on the polynomial order
and continues to increase with $n_{\text{sm}}$. The \textit{Operator w/o MG}
part covers operator evaluations performed outside the $hp$ STMG preconditioner,
and the \textit{Other} segment includes the time spent on source term assembly,
goal quantity evaluation and tasks between time steps. The absolute time of
these segments remain constant, resulting in a decrease in relative time with
increasing smoothing steps.

\section{Conclusions}
\label{sec:conclusions}
We present an $hp$ multigrid approach for tensor-product space-time finite
element discretizing the Stokes equations. The method is highly efficient and
scalable, exhibiting optimal $h$-robustness and satisfactory $p$-robustness.
Even when embedded in a time-marching scheme, the proposed $hp$ space–time
multigrid method still achieves notable efficiency gains through combined
space–time coarsening. The smoother is effective but expensive and represents
the main computational bottleneck for higher order doscretizations. Vertex-patch
smoothers could further enhance
\(p\)-robustness~\cite{pavarinoAdditiveSchwarzMethods1993,miraiMultilevelAlgebraicError2020,schberlAdditiveSchwarzPreconditioning2008}.
For these types of smoothers, replacing the direct solver with a more efficient
local method becomes crucial to avoid the escalating cost at large \(p\). The
direct solves also raise concerns about memory usage. Iterative local solvers
might be less resource intensive. Block-diagonal or approximate factorization
approaches might preserve efficiency without incurring the cost of a full direct
solver. Despite the current limitations, the method performs well and achieves
throughput over 200 millions of degrees of freedom per second on problems with
trillions of global degrees of freedom. It outperforms existing matrix-based
implementations by orders of magnitude
(cf.~\cite{anselmannGeometricMultigridMethod2023}). The proposed matrix-free
$hp$ multigrid method for tensor-product space-time finite element
discretizations is efficient and scalable, making it a promising candidate for
large-scale problems in fluid mechanics, fluid-structure interaction, and
dynamic poroelasticity. An extension to these problems, particularly nonlinear
ones (e.g.\ Navier--Stokes), is part of future work.
\appendix
\section{An Example of Multigrid Sequence Generation}
\label{sec:example-mgseq}
We illustrate the application of \Cref{alg:ConstructHierarchy}
and~\ref{alg:CombineHierarchies} by an example:
Table~\ref{tab:multigrid_hierarchy} summarizes the multigrid hierarchy by
listing the spatial and temporal discretization parameters for geometric and
polynomial coarsening. In space, the mesh size reduces from \(h\) to \(2h\) (Level 1) and \(4h\) (Level 0), while the polynomial degree is
reduced from 2 at Level 3 to 1 from Level 2 onward. In this example, no
geometric coarsening in time is performed and polynomial coarsening in time is
applied from Level 1 to Level 0.
\begin{table}[h]
  \centering
  \caption{\label{tab:multigrid_hierarchy}Multigrid Hierarchy Parameters for Each Level}
  \footnotesize
  \begin{tabular}{@{}cccccl@{}}
    \toprule
    &\multicolumn{2}{c}{\textbf{Space}} &
                                          \multicolumn{2}{c}{\textbf{Time}}&\multirow{ 2}{*}{Coarsening description} \\
    \textbf{Level} & \textbf{$h$-MG} & \textbf{$p$-MG} & \textbf{$h$-MG} & \textbf{$p$-MG}& \\ \midrule
    3 & \( h \)    & \( 2 \)     & \( \tau \)    & \( 2 \)    & \multirow{ 2}{*}{Polynomial
                                                                coarsening in space} \\
    2 & \( h \)    & \( 1 \) & \( \tau \)    & \( 2 \)     & \multirow{ 2}{*}{Geometric
                                                             coarsening in space}\\
    1 & \( 2h \)   & \( 1 \) & \( \tau \)    & \( 2 \)    & \multirow{ 2}{*}{Polynomial in time,
    geometric in space}\\
    0 & \( 4h \)   & \( 1 \) & \( \tau \)    & \( 1 \) \\ \bottomrule
  \end{tabular}
\end{table}
\section{Convergence plots} In \Cref{fig:conv-stokes} we show the
convergence in different norms for all polynomial degrees and numbers of
refinement considered in \Cref{sec:conv-stokes}. The corresponding number of iterations for each of these numerical
experiments can be found in Table~\ref{tab:iter-stokes}.
\begin{figure}[htb]
  \centering
    \includegraphics{figures/stokes-figure4.pdf}
    \caption{\label{fig:conv-stokes}Calculated errors of the velocity and pressure
      in various norms (velocity: $L^2$, $L^{\infty}$ in space-time and the
      $L^2$-norm of the divergence in space-time, pressure: $L^2$ in space-time)
      for different polynomial orders. The expected orders of convergence,
      represented by the triangles, match with the experimental orders.}
  \end{figure}
  \section{Pressure difference in lid-driven cavity flow}\label{sec:pdiff}
  To assess the convergence of our discretization, we consider the normalized pressure difference 
  \[
    p_{\text{diff}}(t) = \frac{p(0.875,0.125,0.125,t) - p(0.875,0.875,0.875,t)}
    {p(0.875,0.125,0.125,t)}\,.
  \]
  We normalize the
  pressure difference in order to better visualize the discretization error. In Figure~\ref{fig:pdiff} we plot \(p_{\text{diff}}(t)\) over the time interval \(I=[0,8]\).
  \begin{figure}\centering
    \includegraphics{pdiff.pdf}
    \caption{\label{fig:pdiff} Normalized Pressure difference \(p_{\text{diff}}(t)\) over time.}
  \end{figure}

\section*{Acknowledgments}
Computational resources (HPC cluster HSUper) have been provided by the project
hpc.bw, funded by dtec.bw - Digitalization and Technology Research Center of the
Bundeswehr. dtec.bw is funded by the European Union - NextGenerationEU.
\bibliographystyle{siamplain}
\bibliography{stokes}
\end{document}
