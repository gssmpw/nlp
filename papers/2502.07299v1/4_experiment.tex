\section{Experiments}
\label{sec:exp}
We first introduce the network architectures and pre-training settings of our Life-Code tokenizer and encoder. Then, we evaluate Life-Code on DNA, RNA, protein, and multi-omics tasks with supervised fine-tuning (SFT) or zero-shot evaluation protocols. All experiments are conducted with PyTorch, \textit{transformers} library, and NVIDIA A100-80G GPUs. 

\subsection{Experimental Setup}
\label{sec:exp_setting}
\vspace{-0.25em}
\paragraph{Life-Code Tokenizer.}
With the nucleotide vocabulary, the \textit{Life-Code tokenizer} contains the following modules: (\romannumeral1) A linear projection from the DNA input to 384-dim implemented by \texttt{nn.Embedding}; (\romannumeral2) A GDN block (DeltaNet) with 384-dim for global contextual modeling; (\romannumeral3) A 1-d Convolution with a kernel size of 3 and stride of 1, followed by an \texttt{UnFold} operation to merge every three nucleotide tokens into 768-dim codon embedding. Similarly, we also design the \textit{DNA De-Tokenizer} and \textit{Amino Acid Translator} for tokenizer pre-training.
As shown in Figure~\ref{fig:tokenizer}, we first pre-train the Life-Code tokenizer by AdamW optimizer~\citep{iclr2019AdamW} for 100,000 iterations with a basic learning rate of $2\times 10^{-4}$ adjusted by the Cosine scheduler and a total batch size of 512, as summarized in Table~\ref{tab:app_lcode_config}. As shown in Table~\ref{tab:app_dataset}, the two pre-training datasets (DNA and DNA-AA pairing) are constructed from NCBI, GenBank, and UniRef50 databases as described in Figure~\ref{fig:data_collection} and Appendix~\ref{app:implement}.
View Appendix~\ref{app:impl_tokenizer} for details.

\vspace{-0.5em}
\paragraph{Life-Code Encoder.}
Similar to the BERT-Large architecture~\citep{devlin2019bert}, the Life-Code encoder has 24 layers in total with an embedding dim of 1024 and 340M parameters. We enhance the model with three-fold designs: (\romannumeral1) Mixture of DeltaNet~\citep{yang2025deltanet} blocks and Multi-head Self-attention (MHSA) blocks, especially every 11 DeltaNet blocks followed by one MHSA block. (\romannumeral2) The LLaMA-like macro design~\citep{Touvron2023LLaMA} with RMSNorm~\citep{Zhang2019RMSNorm}, Layer Scale~\citep{iccv2021CaiT}, Rotary Position Embedding (RoPE)~\citep{Su2021RoFormer}, SwiGLU, and FlashAttention to facilitate stable pre-training with long sequences. (\romannumeral3) During pre-training, we apply the packing strategy \citep{Warner2024ModernBERT} to build up a long sequence with several CDS, which compromises the gap between different lengths of the reference sequence and the coding sequences.
With three pre-training tasks in Eq.~\ref{eq:loss_total}, the Life-Code tokenizer and encoder are optimized by AdamW optimizer for 1M iterations with the batch size of 256 and the basic learning rate of $1\times 10^{-4}$. We adopt 15\% random masking in BERT for Masked DNA Reconstruction and the 3-mer span masking for CDS-to-Amino-Acid Translation. As for KD from a pre-trained Protein LM, we adopted ESM2-650M~\citep{lin2022ESM2} and a protein decoder with an output dimension of 1280. During the warmup periods, the maximum sequence length is 1024, with a linear warmup of the learning rate for 10 iterations. After that, the maximum sequence length is set to 4k with the learning rate adjusted by the Cosine Annealing scheduler.
View Appendix~\ref{app:impl_tokenizer} for more details.

\vspace{-0.5em}
\subsection{Comparison on Genomic Benchmarks}
\label{sec:dna_comparison}
As DNA sequences are the foundation of the central dogma, we primarily compare with latest DNA foundation models with the SFT evaluation protocol proposed by \citep{nips2024hyenadna, iclr2024dnabert2}, following benchmark evaluations for fair comparison.
We consider three types of DNA model architectures: (a) classical BERT encoders, including DNABERT~\citep{BioInfo2021dnabert}, DNABERT2~\citep{iclr2024dnabert2}, GENA-LM~\citep{fishman2023GenaLM}, Nucleotide Transformer (NT)~\citep{NM2023NucleotideTrans}, with different tokenizers like VQDNA~\citep{icml2024vqdna} and MxDNA~\citep{nips2024MXDNA}; (b) RNN-based linear attentions including HyenaDNA~\citep{nips2024hyenadna} and Caduceus~\citep{icml2024caduceus}; (c) CNN model ConvNova~\citep{iclr2025convnova}.

\vspace{-0.5em}
\paragraph{Genomic Benchmarks.}
We first compare Life-Code with 8 evaluation tasks in the Genomic Benchmark~\citep{BMC2023genomicbenchmark}, which we adopted results from GenBench implementations \citep{liu2024genbench} and all compared DNA models are fully SFT and reported the top-1 accuracy. Table~\ref{tab:genomic_benchmark} demonstrates that Life-Code surpasses previous models with remarkable margins since its hybrid designs combine the advantages of both RNN and self-attention blocks.

\vspace{-0.5em}
\paragraph{GUE Benchmarks.}
We then evaluate Life-Code with 24 long-range genomic tasks on the GUE benchmark~\citep{iclr2024dnabert2}, as shown in Table~\ref{tab:gue}, where 7 widely adopted practical genomic tasks are conducted, including Epigenetic Mark Prediction (EMP) for Yeast, Transcription Factor Prediction on Mouse and Human genome, Promoter Detection, Core Promoter Detection, Splice Site Prediction, and Covid Variants Classification. All results are adopted from DNABERT2 or each paper with their official SFT setups, and Matthews Correlation Coefficient (MCC) is reported as the metric. Compared to popular DNA models, our Life-Code shows superiority in gene annotation tasks, which are important regulation processes in the central dogma, while achieving competitive results in Epigenetic regulating tasks.


\input{tabs/tab_splicing}

\subsection{Comparison on RNA Splicing Site Prediction}
\label{sec:rna_comparison}
% We also compare our Life-Code with pre-trained DNA or RNA models on two mRNA splicing site prediction tasks with multiple species and the Splice Site Reconstructed task with the human reference genome (SpliceFinder).
Since precursor messenger RNAs (pre-mRNAs) splicing is a crucial process in eukaryotic gene expression, we then evaluate Life-Code on Splicing Site Prediction tasks as binary classification tasks. We consider two typical datasets with the SFT evaluation protocol.
As for SpliceAI dataset~\citep{JAGANATHAN2019SpliceAI}, we evaluate DNA models with top-1 AUC scores and find that Life-Code consistently outperforms popular SpliceAI and DNA models, indicating its great ability to model the central dogma. As for Spliceator dataset~\citep{BMC2021spliceator}, we then consider RNA splicing methods (Spliceator, DDSP~\citep{naito2019DDSP}, RINALMo~\citep{Penic2024RiNALMo}) and RNA language model, RNA-FM~\citep{shen2024rnafm}, with RNA data of multi-species. As shown in Table~\ref{tab:splicing}, our Life-Code achieves competitive F1 scores with the specially designed splicing method and surpasses RNA-FM.


\input{tabs/tab_dms_protein}

\subsection{Comparison on Protein Fitness Prediction}
\label{sec:protein_comparison}
Following EVO~\citep{nguyen2024evo}, we then evaluate foundation models pre-trained with DNA or protein data with Protein Fitness Prediction tasks using zero-shot evaluation protocol (without task-specific SFT). Deep Mutational Scanning (DMS) datasets \citep{icml2022Tranception, nguyen2024evo} introduce a comprehensive set of mutations into protein CDS to measure their effects on fitness, where fitness serves as a metric for how effectively a protein performs a specific function. As shown in Table~\ref{tab:protein_dms}, bacterial (prokaryote) and human (eukaryote) protein fitness is evaluated by Spearman's Rank Correlation Coefficient (SRCC), where the protein specialist model ESM2 achieves the best result. Life-Code outperforms other DNA models like GenSLM~\citep{ijhpca2023genslms} and EVO-7B with fewer parameters, which might be attributed to its modeling of the translation and folding processes in the central dogma.


\input{tabs/tab_multi_omics}

\subsection{Comparison on Multi-omics Tasks}
\label{sec:multiomics_comparison}
We conduct further comparisons with proposed biological foundation models (EVO~\citep{nguyen2024evo} and LucaOne~\citep{he2024lucaone}) with multi-omics tasks. Following LucaOne, we first evaluate the non-coding RNA and protein interactions (ncRPI) task using SFT evaluation, which aims to predict the interaction strengths between ncRNAs and proteins. As shown in Table~\ref{tab:multi_omics}, Life-Code could take cDNA and Amino Acid sequences in the unified input format and achieve the competitive result as the supervised LucaOne, which should process two inputs with separate modules. Then, we evaluate the modeling of transcription and translation processes with binary classification tasks between cDNA and the protein sequences, where Life-Code achieves the best accuracy over existing models.


\input{tabs/tab_cls_species}

\subsection{Empirical Analysis}
\label{sec:exp_empirical}
After verifying the effectiveness with extensive comparison results, we further consider long-sequence tasks like HyenaDNA \citep{nips2024hyenadna} in addition to Figure~\ref{fig:efficiency}.
% we highlight two key aspects reflecting the benefits of Life-Code:
% 
% \paragraph{(1) Evolutionary Information and Clustering.}
% By unifying all omics data into a nucleotide-level embedding space and applying the CDS/nCDS co-design, we observe that tokens cluster according to known evolutionary relationships. For instance, orthologous sequences from different species map to similar embedding clusters, reflecting conserved functional elements. This outcome underscores the \textit{biological interpretability} of our approach.
% 
% \paragraph{(2) Computing Efficiency.}
We compare the inference throughput of our bi-directional hybrid model to baselines (FlashAttention and HyenaDNA). In Table~\ref{tab:cls_species}, empirical profiling shows that LifeCode achieves competitive speed with these specialized methods while \textit{retaining} strong global modeling capacity. In particular, mixing a small fraction of MHSA enables better downstream performance without incurring a large computational penalty, \textit{e.g.}, splicing site prediction in Table~\ref{tab:splicing}.


\input{tabs/tab_ablation}

\subsection{Ablation Study}
We conduct ablation on the pre-training tasks and the network designs for the tokenizer and encoder, as shown in Table~\ref{tab:ablation}. We consider the top-1 accuracy (\%) Covid Variants Classification in the GUE benchmark for the DNA task, the averaged SRCC (\%) of bacterial and human protein fitness with DMS used in EVO as the protein task, and the top-1 accuracy (\%) of the central dogma evaluation task proposed by LucaOne. Firstly, we verify that the codon tokenizer (instead of 1-mer) could learn more global contextual information by the RNN module and Conv1D (with a kernel size of 3) pre-trained by the MLM task and the cDNA-AA translation task (Trans.). Then, we verified the effectiveness of the hybrid encoder and found that knowledge distillation from ESM2-650M could benefit the protein-related tasks.
