\section{Conclusion}\label{sec:deluxeagent:Conclusion}
In this paper, we study how to select which LLMs to which modules to optimize a given compound AI system, an important but under-explored question. We propose and develop \deluxesystem{}, an efficient framework to address this question by leveraging two key insights: (i) end-to-end performance is often monotonic in per-module performance, and (ii) module-wise performance can be accurately estimated by an LLM. Our empirical evaluations with real-world LLM APIs show that \deluxesystem{} offers substantial performance gains (5\%-70\%) over allocating the same model to all modules, highlighting the importance of model selection. We also release our code and data via \url{https://github.com/LLMSELECTOR/LLMSELECTOR} to stimulate more research on optimizing compound AI systems.