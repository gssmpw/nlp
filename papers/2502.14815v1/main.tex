\documentclass{article}
\PassOptionsToPackage{table,xcdraw}{xcolor}
\usepackage{xcolor}
\usepackage{bbm}
\usepackage{multirow}
% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{booktabs} % To thicken table lines
\usepackage{caption}
\input{macro_small}
\input{notation}
\usepackage{pifont}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\title{Optimizing Model Selection for Compound AI Systems}
\author{Lingjiao Chen$^{\dagger,\circ}$, Jared Quincy Davis$^{\circ}$, Boris Hanin$^{\S}$\\\\ Peter Bailis$^\ddagger$, Matei Zaharia$^\ddagger$, James Zou$^{\circ}$, Ion Stoica$^\ddagger$\\\\
$^\dagger$Microsoft Research, $^\circ$Stanford University,\\ $^\S$Princeton University, $^\ddagger$University of California, Berkeley}
\date{}



% Save the original \cite as \cite_old
%\let\cite_old\cite

% Redefine \cite to behave like \citep
\renewcommand{\cite}[1]{\citep{#1}}


\begin{document}
\maketitle

\begin{abstract}
Compound AI systems that combine multiple LLM calls, such as self-refine and multi-agent-debate, achieve strong performance on many AI tasks. We address a core question in optimizing compound systems: for each LLM call or module in the system, how should one decide which LLM to use? We show that these LLM choices have a large effect on quality, but the search space is exponential. We propose \deluxesystem{}, an efficient framework for model selection in compound systems, which leverages two key empirical insights: (i) end-to-end performance is often monotonic in how well each module performs, with all other modules held fixed, and (ii) per-module performance can be estimated accurately by an LLM. Building upon these insights, \deluxesystem{} iteratively selects one module and allocates to it the model with the highest module-wise performance, as estimated by an LLM, until no further gain is possible. \deluxesystem{} is applicable to any compound system with a bounded number of modules, and its number of API calls scales linearly with the number of modules, achieving high-quality model allocation both empirically and theoretically. Experiments with popular compound systems such as multi-agent debate and self-refine using LLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5  show that \deluxesystem{} confers 5\%-70\% accuracy gains compared to using the same LLM for all modules.
 
\end{abstract}


\input{intro}
\input{prelim}
\input{method}
\input{experiment}
\input{conclusion}

\bibliography{reference}
\bibliographystyle{plainnat}
\newpage
\appendix
\onecolumn 
\input{appendix_theory}
\input{appendix_exp}
\end{document}