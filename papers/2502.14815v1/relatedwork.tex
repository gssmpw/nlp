\section{Related Work}
\label{sec:deluxeagent:Relatedwork}

\paragraph{Compound AI system optimization.} Prompt engineering and module interaction design is a central topic of compound AI system optimization. While existing work often relies on manually tuning them~\cite{deepmind2025alphacode2,shinn2024reflexion,zhou2024agents2,pryzant2023automatic,fourney2024magentic,zhao2024expel,lu2024chameleon,zhao2024expel}, recent work studies how to automate this process, such as DSPy~\cite{khattab2024dspy}, Textgrad~\cite{yuksekgonul2024textgrad}, and Autogen~\cite{wu2023autogen}. For example, DSPy uses Bayesian optimization to adjust prompts for all modules, while Textgrad uses textual feedback to optimize prompts for individual modules. On the other hand, our work focuses on model selection, a third axis for compound system optimization, complementary to prompt optimization and module interaction design. 

\paragraph{Model market utilization.} Model market utilization studies how to use all available (proprietary and open-source) models for downstream tasks~\cite{lu2024merge,ramirez2024optimising,miao2023towards}. Extensive work has built various techniques to utilize different models, such as model cascade~\cite{chen2023frugalgpt}, model routing~\cite{hu2024routerbench,stripelis2024tensoropera}, and mixture-of-experts~\cite{wang2024mixture}. While they mainly focus on  \textit{single-stage} tasks such as classification~\cite{chen2020frugalml,huang2025thriftllm} and question answering~\cite{chen2023frugalgpt,shekhar2024towards}, we study model utilization for compound AI systems requiring \textit{multiple stages}. This is a much more challenging problem as the search space is much larger. 

\paragraph{Model selection.} Model selection is a critical part of classic ML and has been extensively studied in the literature~\cite{kohavi1995study,akaike1974new,elsken2019neural}. %It involves identifying the most suitable model from a set of candidates via on performance metrics, generalization ability, and computational efficiency. %Cross-validation and bootstrap~\cite{kohavi1995study}, Akaike information criterion~\cite{akaike1974new}, neural architecture search~\cite{elsken2019neural} and many other techniques have been developed during the past few decades. 
While classic techniques focus on model selection for one ML task, compound systems involve multiple ML tasks. Thus, model selection becomes more challenging as the search space is exponentially large in the number of tasks.  

\paragraph{LLM-as-a-judge.} LLMs have been increasingly used for evaluating and judging complex generations, a phenomenon termed LLM-as-a-judge. Researchers have extensively studied how LLM judges align with human preferences in real-world scenarios~\cite{zheng2023judging,shankar2024validates}, how to improve its quality~\cite{kim2023prometheus}, how to evaluate it~\cite{chiang2024chatbot,chen2024mllm,zeng2023evaluating}, as well as many other applications~\cite{johri2025evaluation,dhole2024conqret,gu2024survey,zhou2024llm}. In this paper, we find a novel use case of LLM-as-a-judge: diagnosing module-wise performance to accelerate the model allocation search process.