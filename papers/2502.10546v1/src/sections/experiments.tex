

        
\section{Experiments} \label{sec:experiments}
\vspace*{-5pt}
    We evaluate our MDPS on a synthetic bearings-only tracking task~\cite{younis2023mdpf}, as well as on real-world city-scale global localization.  For all tasks, we estimate the MDPF/MDPS posterior distributions of a 3D (translation and angle) state $x_t = (x, y, \theta)$, using Gaussian kernels for the position dimensions, and von Mises kernels for the angular dimensions of the state posterior mixtures. 
    %For application specific methods (those tailored only for the global localization task), we use the appropriate loss function as described by the method authors.

    \vspace*{-10pt}
    \subsection{Bearings Only Tracking Task} \label{sec:bearings_only_task}
        To allow comparison to prior discriminative PFs, we use the same bearings-only tracking task as \citep{younis2023mdpf}, where the 3D state of a variable-velocity synthetic vehicle is tracked via noisy bearings from a fixed-position radar.  85\% of observations are the true bearing plus von Mises noise, while 15\% are uniform outliers.  
        %The observations are generated as
       % \begin{equation*}
       %     y_t \sim \alpha \cdot \text{Uniform}(-\pi, \pi) + (1-\alpha) \cdot \text{VonMises}(\psi(x_t), \kappa),
       % \end{equation*}	
	%where $\psi(x_t)$ is the true bearing and $\alpha=0.15$. 
 Train and evaluation sequences have length $T=50$. Unlike \citet{younis2023mdpf}, we find truncated BPTT~\cite{Jaeger2005ATO} is not necessary if bandwidths are initialized appropriately. 
 %The dynamics and measurement models are parameterized as simple feed-forward fully-connected neural-networks, with each methods 
 Filtering particles are initialized as the true state with added Gaussian noise, while MDPF-Backward (and the MDPS backwards filter) are initialized with uniformly sampled particles to mimic datasets where often only the starting state is known.  More details can be found in the Appendix.

    We compare our MDPS methods to several existing differentiable particle filter baselines, but no differentiable particle smoother baseline exists. Instead, we implement the classic FFBS \cite{doucet2009tutorial, Klaas2006FastPS} algorithm (Sec.~\ref{sec:from_filtering_to_smoothing}), which assumes known dynamics and measurement models. Since FFBS is not differentiable, we learn the dynamics model using the dataset true state pairs $\{x_{t-1}, x_{t}\}$ outside of the FFBS algorithm. In order to simulate from and evaluate the state transition dynamics, as needed by the FFBS, we parameterize the dynamics model to output a mean and use a fixed bandwidth parameter (tuned on validation data) to propose new particles. We also use the true observation likelihood as the measurement model, instead of a learned approximation; this boosts FFBS performance.

    \textbf{Results.} In Fig.~\ref{fig:bearings_only_box_plot_all} we show statistics of performance over 11 training and evaluation runs for each method. We compare to TG-PF \cite{jonschkowski18_differentiable_particle_filter}, SR-PF \cite{pmlr-v87-karkus18a_soft_resampling}, the classical FFBS \cite{doucet2009tutorial, Klaas2006FastPS}, and MDPF \cite{younis2023mdpf}. 
    %but not OT-PF \cite{pmlr-v139-corenflos21a_optimal_transport} as it is prohibitively slow to train and yields poor results when compared to other methods \cite{younis2023mdpf}.     
    Interestingly, MDPF outperforms SR-PF and TG-PF even when the initial particle set is drawn uniformly from the state space as in MDPF-Backward. 
    
    By incorporating more temporal data, MDPS substantially outperforms MDPF. Even when unfairly provided the true observation likelihood, FFBS performs poorly since particles are simply re-weighted (not moved) by the backward smoother.  This inflexibility, and lack of end-to-end learning, makes FFBS less robust to inaccuracies in the forward particle filter. %an issue if the forward filtering particles do not have substantial overlap with the desired smooth distribution, as well as a lack of end-to-end learning.
    %has clear performance improvements over MDPF due to using the full sequence of data yielding more accurate and more certain state posterior densities. 
    
    %\textbf{Comparing Resampling Methods.} 
    We are the first to compare resampling variants in the context of modern discriminative PFs.  Stratified resampling substantially improves TG-PF and SR-PF performance, but only modestly improves the worst-performing MDPF runs.  This may be because even with basic multinomial resampling, the lower-variance MDPF gradients dramatically outperform all TG-PF and SR-PF variants.  Residual resampling performs worse than stratified resampling, and is also much slower since it cannot be easily parallelized on GPUs, so we do not consider it for other datasets.
    %This may be due to MDPF having a tight state posterior \emph{mixture} density with substantial overlap between mixture components. Thus resampling is less sensitive to which particular mixture component (i.e. particle) each resampled particle is drawn from. Unfortunately residual resampling is not amenable to GPU parallelization resulting in an implementation that is orders of magnitude slower than both stratified and multinomial resampling. We therefore limit experiments using residual resampling to the bearings only dataset.



    \begin{figure}[t]
        \centering
        \includegraphics[width=0.98\textwidth]{resources/main_paper/mapillary_dynamics_plot.pdf}
        \vskip -0.08in
        \caption{\small{Learned dynamics from the forward filter of MDPS trained on the MGL dataset. Density cloud illustrates density of particles after applying dynamics while marginalizing actions. MDPS clearly learns informative, non-linear dynamics models which aid in state posterior estimation.}}
        \label{fig:mapillary_dynamics_plots}
        \vskip -0.1in
    \end{figure}


    
        
        
    \subsection{City Scale Global Localization Task}


        Our global localization task is adopted from \citet{sarlin2023orienternet}, where we wish to estimate the 3D  state (position and heading) of a subject (person/bike/vehicle) as it moves through real-world city-scale environments.  Observations are gravity-aligned first-person images, actions are noisy odometry, and a 2D planimetric map is provided to help localize globally. We use the Mapillary Geo-Localization \cite{sarlin2023orienternet} and KITTI \cite{Geiger2013IJRRKitti} datasets to compare our MDPS method to MDPF \cite{younis2023mdpf} as well as other methods specifically designed for the global localization task, which are not sequential Monte Carlo methods. 

        Our global localization task is distinct from local localization systems, which aim to track subject positions relative to their starting position, instead of in relation to the global map origin. Visual SLAM systems \cite{probabilistic_robotics} almost exclusively solve the local localization task, using the starting position as the origin of their estimated map. If a map is provided, then just the localization part of Visual SLAM can be run, but detailed visual or 3D maps of the environment are needed. These have prohibitive memory requirements at city-scales, and need constant updating as the visual appearance of the environment changes (e.g., with the weather/seasons) \cite{sarlin2023orienternet}. Hybrid place recognition with localization also requires detailed visual or 3D maps \cite{wang_2023}. In our experiments, we instead seek to use planimetric maps for global localization, which are compact and robust to environment changes. It is not obvious how to apply SLAM/Hybrid place recognition systems to this type of map. 

        %\subsubsection{Existing Works in Global Localization}
        %    Several existing methods have been proposed for the global localization task and can broadly be categorized into 3 groups:
             
            \textbf{Retrieval methods} \cite{shi2020where, Hu_2018_CVPR,noe2020eccv,  zhu2021vigor, NEURIPS2019_ba2f0015, shi2019optimal, xia2022visual} rely on latent vector similarity where map patches and the observation are encoded into a common latent state space before doing a vector similarity search. These methods are trained using a contrastive loss \cite{Hu_2018_CVPR, Schroff_2015_CVPR} that forces the observation encoding to be similar to its corresponding map patch encoding, while being dissimilar to other patch and observation encodings. Accuracy depends on map patch extraction density and patch similarity; if similar patches are mapped to near-identical encodings, performance suffers.  \citet{9635972GausePF} extend this framework using a non-differentiable PF, where a retrieval-based measurement model is trained outside the PF framework, and  non-learned dynamics are fixed to actions with added Gaussian noise.          

            \textbf{Refinement methods} \cite{shi2020beyond, sarlin21pixloc} refine an initial position estimate via expensive optimization, by maximizing the alignment of features extracted from the observation and map. Due to the extreme non-linearity of this objective, refinement methods require an accurate initial estimate to converge to the correct solution, if at all.  This prevents their use for city-scale global localization. %applicability to real problems like city scale global localization.             
                    
            \textbf{Dense Search} \citep{sarlin2023orienternet} extracts \emph{birds-eye-view} (BEV) features from the observed images via geometric projection (see Fig.~\ref{fig:forward_backward_smoother_flow_diagram}), before applying a dense search to align BEV features with extracted map features.  Heuristic alignment probabilities may be produced by tracking alignment values during search, and applying a softmax operator.  Higher discretization density boosts accuracy, but requires significantly more memory and compute. Temporal information can be used by warping probability volumes onto the current time-step, but this requires near-exact relative poses which \citet{sarlin2023orienternet} determine via an expensive, black-box Visual-Inertial SLAM system \cite{probabilistic_robotics}. %adding significantly to the computation requirements.

           
            
        \subsection{Mapillary Geo-Localization (MGL) Dataset}
            In the Mapillary Geo-Localization (MGL) \cite{sarlin2023orienternet} dataset, images sequences are captured from handheld or vehicle-mounted cameras as a subject (person/bike/car) roams around various European and U.S. cities. Observations are set as $90^{\circ}$ Field-of-View images in various viewing directions, with actions being noisy odometry. A planimetric map of the environment is also provided via the OpenStreetMap platform \cite{OpenStreetMap} at 0.5 meter/pixel resolution. %and all observation images are publicly available under a CC-BY-SA license via the Mapillary platform. 
            We generate custom training, validation, and test splits to create longer sequences with $T=100$ steps. For particle-based methods, we use stratified resampling and set the initial particle sets to be the true state with added noise. More details are in the Appendix.

            \textbf{Implementation Details.} For MDPF and our MDPS, we set the dynamics model to a multi-layer perceptron (MLP) network.  The measurement model incorporates BEV features~\citep{sarlin2023orienternet} and map features as illustrated in Fig.~\ref{fig:forward_backward_smoother_flow_diagram}. The smoother measurement model incorporates additional inputs via an extra MLP. Memory constraints prevent Dense Search in city-scale environments, so we consider two methods to limit the search space. A sliding window limits the search space to a $256 m \times 256 m$ area that is recursively re-centered around the best position estimate at $t-1$, propagated to $t$ using $a_t$. We can also limit the search space to a $256 m \times 256 m$ area containing the true state, though this \emph{artificially} increases performance. We similarly limit the search space for Retrieval, which performs poorly in large environments; \citet{9635972GausePF} even limit the vector search to known road networks. %More information about model architectures and implementations can be found in the appendix.
            
            \textbf{Results.} We compare our MDPS to MDPF \cite{younis2023mdpf}, Dense Search \cite{sarlin2023orienternet}, Retrieval \cite{noe2020eccv} implemented as detailed by \cite{sarlin2023orienternet}, and Retrieval (PF) \cite{9635972GausePF}, reporting the position and rotation recall in Fig.~\ref{fig:mapillary_recall_curves}. Due to ambiguity in large city environments (e.g.,~intersections can look very similar), estimated state posteriors can be multi-modal (see Fig.~\ref{fig:mapillary_panel}), and thus simply reporting accuracy using the highest probability mode does not fully characterize performance. We thus also extract the top-three modes using non-maximal suppression (see Appendix), and report accuracy of the best mode. Interestingly, MDPF and MDPS give dramatic improvements over baselines engineered specifically for this task, highlighting the usefulness of end-to-end training. MDPS outperforms MDPF by using the full sequence of data to reduce mode variance, and discard incorrect modes as illustrated in Fig.~\ref{fig:mapillary_panel}.

            %\textbf{Informative Dynamics Improves Performance}. 
            Informative dynamics models boost performance, as demonstrated by the MDPS and MDPF results in Fig.~\ref{fig:mapillary_recall_curves}. We visualize the learned dynamics of the MDPS forward filter in Fig.~\ref{fig:mapillary_dynamics_plots}. 
            Good dynamics models 
            %propagate particles from one time-step to the next, 
            keep particles densely concentrated in high-probability regions, while also including diversity to account for sometimes-noisy actions. This enables learning of more discriminative measurement models, since training encourages the weights model to disambiguate nearby particles.
            %small variations in the weights can account for small changes in the particle locations. With less density in probable regions, the measurement model must be more forgiving to error in particle locations when assigning particle weights.


            \textbf{Computational Requirements.} While MDPS is more accurate than other methods, it is also more efficient than dense search.  Because dense search must try many options to find the best alignment of the BEV and extracted map features, it has complexity $\mathcal{O}(KW^2H^2)$ for $K$ search rotations, and search locations defined on a grid of width $W$ and height $H$. %being the number of search rotations, map width and map height respectively. 
            (For notational simplicity, we assume the BEV features and the map features have the same width and height.) This complexity can be reduced to $\mathcal{O}(KWH \log (WH))$ by using the Fast Fourier Transform. In contrast, MDPS has complexity $\mathcal{O}(NWH)$, where $N \ll K\log(WH)$, as it only compares the BEV and map features at the particle locations.  This allows MDPS to better scale to large-scale environments. %resulting in faster inference.
                        
                        
        \begin{figure}[t]
            \centering
            \includegraphics[width=0.09\columnwidth]{resources/main_paper/kitti_car.pdf}
            \hspace{0.3in}
            \includegraphics[width=0.83\textwidth]{resources/main_paper/kitti_recall_curve_plot.pdf}
            \caption{\small{\emph{Left:} Lateral and longitudinal errors are in the vehicle frame of reference. \emph{Right:} Position recall versus error for the KITTI \cite{Geiger2013IJRRKitti} dataset. Recall is computed with the top posterior mode as well as with the best of the top-3 posterior modes. Longitudinal localization performance is poor for all methods due to lack of visual features. MDPF \cite{younis2023mdpf} offers dramatic improvements for lateral error over Retrieval \cite{noe2020eccv}, Retrieval (PF) \cite{9635972GausePF} and Dense Search \cite{sarlin2023orienternet} baselines, even when these baselines are constrained to operate around the ground truth state (``Cheating" with GT). For longitudinal recall, methods using ``Cheating" with GT have good performance because they are \emph{artificially} constrained to be near the true state, and thus have significantly less position ambiguity along the roadway. MDPS offers further improvements over MDPF as it maintains a more diverse set of posterior modes, instead of prematurely collapsing to incorrect modes.}}
            \label{fig:kitti_recall_curves}
            \vskip -0.1in
        \end{figure}
        
              
            

        \subsection{KITTI Dataset}
    

    
            We also evaluate our MDPS method for the global localization task using the KITTI \cite{Geiger2013IJRRKitti} dataset, where observations are forward-facing camera images from a moving vehicle. We augment this datatset with noisy odometry computed from the ground truth states and use the default \emph{Train}, \emph{Test1}, and \emph{Test2} splits for training, validation, and evaluation respectively. Like MGL, a planimetric map of the environment is provided via the OpenStreetMap platform \cite{OpenStreetMap} at 0.5 meter/pixel resolution. %and all KITTI data is published under the CC-BY-NC-SA licence. 
            Due to the small size of the KITTI dataset, we pre-train all methods using MGL before refining on KITTI, using the same network architectures as was used for the MGL dataset. See Appendix for details.
    
            \textbf{Results.} Due to the forward-facing camera, the observation images lack visual features for useful localizing along the roadway, therefore we decouple the position error into lateral and longitudinal errors when reporting recalls in Fig.~\ref{fig:kitti_recall_curves}. Understandably, all methods have larger longitudinal error than lateral error. Interestingly, MDPF and MDPS offer similar Top 3 mode performance for small lateral errors (under 2 meters) while significantly outperforming all other methods. When the lateral error is greater than 2 meters, MDPS sees a performance gain as it maintains a more diverse set of posterior modes, whereas MDPF prematurely collapses the posterior density to incorrect modes.
            