


\section{From Filtering to Smoothing} \label{sec:from_filtering_to_smoothing}
    Particle smoothers extend PFs to estimate the state posteriors $p(x_t | y_{1:T})$ given a full $T$-step sequence of observations.  (To simplify equations, we do not explicitly condition on actions $a_{1:T}$ in the following two sections.) 
    %To simplify notation, we will drop $a_{1:t}$ when specifying state transition distributions and posterior densities in the following sections.
    Particle smoothers continue to approximate posteriors via a collection of particles $\overleftrightarrow{x}_{t}^{(1:N)}$ with associated weights $\overleftrightarrow{w}_{t}^{(1:N)}$, where we use bi-directional overhead arrows to denote smoothed posteriors.  Classical particle smoothing algorithms, which are non-differentiable and typically assume human-engineered dynamics and likelihoods, fall into two broad categories.  
    %Two classical methods have been proposed for particle smoothing (outlined below). These methods are typically not end-to-end learnable since they rely on classical non-differentiable particle filters when generating smoothed posterior estimates. 

    \textbf{Forward-Filtering, Backward Smoothing (FFBS)} algorithms~\cite{doucet2009tutorial, Klaas2006FastPS} compute $p(x_t | y_{1:T})$ by factoring into forward filtering and backward smoothing components:
        \begin{equation}
            p(x_t | y_{1:T}) = \int p(x_{t}, x_{t+1} | y_{1:T})dx_{t+1}
                             %\int p(x_{t+1}|y_{1:T}) p(x_t|x_{t+1},y_{1:t}) dx_{t+1} \notag\\
                            = \underbrace{p(x_t|y_{1:t})}_{\text{forward filtering}} \underbrace{\int \frac{p(x_{t+1} | y_{1:T}) p(x_{t+1}|x_t)} {\int p(x_{t+1} | x_t) p(x_t|y_{1:t})}   dx_{t+1}}_{\text{backward smoothing}}.
            \label{eqn:ffbs_factorization}
        \end{equation}
        A natural algorithm emerges from Eq.~\eqref{eqn:ffbs_factorization}, where a conventional PF first approximates $p(x_t| y_{1:t})$ for all times via particles $\overrightarrow{x}_{t}^{(1:N)}$ with weights $\overrightarrow{w}_{t}^{(1:N)}$. A backward smoother then recursively reweights the ``forward'' particles to account for future data, but does \emph{not} change particle locations: 
        %applied to compute the smoothed posterior density $p(x_t | y_{1:T})$ by recursively re-weighting the forward filter particles:
        \begin{equation}
            \overleftrightarrow{w}_{t}^{(i)} \propto \overrightarrow{w}_{t}^{(i)} \Bigg( \sum_{j=1}^{N} \overleftrightarrow{w}_{t+1}^{(j)} \frac{p(\overrightarrow{x}_{t+1}^{(j)} | \overrightarrow{x}_{t}^{(i)})}{\sum_{k=1}^{N} \overrightarrow{w}_{t}^{(k)} p(\overrightarrow{x}_{t+1}^{(j)} | \overrightarrow{x}_{t}^{(k)})}\Bigg).
        \end{equation}
        %Weights are then normalized such that $\sum_{i=1}^{N} \overleftrightarrow{w}_{t}^{(i)} = 1$. 
        Because FFBS sets $\overleftrightarrow{x}_{t}^{(i)} = \overrightarrow{x}_{t}^{(i)}$, it is only effective when filtered state posteriors $p(x_t | y_{1:t})$ substantially overlap with smoothed posteriors $p(x_t | y_{1:T})$ \cite{Klaas2006FastPS}; performance deteriorates when future data is highly informative. % which may not be the case due to sparsity when using finite number of particles. 
        FFBS also requires explicit evaluation, not just simulation, of the state transition dynamics $p(x_{t+1} | x_{t})$, which is not tractable for dynamics parameterized as in Eq.~\eqref{eqn:dynamics_model_learned}.  %instead of just simulating from it, restricting the family of models which may be used for the dynamics.


    \textbf{Two Filter Smoothing (TFS)} algorithms~\cite{bresler1986TwoFilter, doucet2009tutorial, Klaas2006FastPS} instead express the smoothed posterior as a normalized product of distinct forward-time and backward-time filters:
        \begin{equation}
            p(x_t|y_{1:T}) = \frac{p(x_t|y_{1:t}) p(y_{t+1:T}|x_t)}{p(y_{t+1:T} | y_{1:t})} \propto p(x_t|y_{1:t}) p(y_{t+1:T}|x_t).
            \label{eqn:tfs_definition}
        \end{equation}
        Here $p(x_t|y_{1:t})$ may be approximated by a standard PF, and $p(y_{t+1:T}|x_t)$ is the so-called \emph{backward information filter} \cite{Klaas2006FastPS, doucet2009tutorial} defined as
        \begin{equation}
            p(y_{t:T} | x_t) = \int p(y_{t+1:T} | x_{t+1}) p(x_{t+1}|x_t) p(y_t|x_t)dx_{t+1}.
        \end{equation}
        Because $p(y_{t:T} | x_t)$ is a likelihood function rather than a probability density in $x_t$, and it is possible that  $\int p(y_{t:T} | x_t) dx_t= \infty$. This is not an issue when $p(y_{t:T} | x_t)$ is computed analytically as in Kalman smoothers for Gaussian models~\cite{anderson1979optimal}, but particle-based methods can only hope to approximate finite measures. 
        %and therefore cannot be used to approximate $p(y_{t:T} | x_t)$. 
        \citet{bresler1986TwoFilter} addresses this issue via an \emph{auxiliary} probability measure $\gamma_t({x_t})$:
         \begin{equation}
            p(y_{t:T} | x_t) \propto \frac{\tilde{p}(x_t| y_{t:T})}{\gamma_t(x_t)}, \qquad \tilde{p}(x_{t:T}| y_{t:T}) \propto 
            \gamma_t(x_t) p(y_t|x_t) \prod_{s=t+1}^{T} p(x_{s} | x_{s-1}) p(y_s | x_s).
            %\gamma_t(x_t) \Bigg(\prod_{s=t}^{T-1} p(x_{s+1} | x_s)\Bigg) \Bigg(\prod_{s=t}^{T} p(y_s | x_s)\Bigg)
            \label{eqn:tfs_artificial_measure}
         \end{equation}
         From Eqs.~(\ref{eqn:tfs_definition},\ref{eqn:tfs_artificial_measure}), the smoothed posterior is a reweighted product of forward and backward filters:
        \begin{equation}
            p(x_t|y_{1:T}) \propto \frac{\overbrace{p(x_t|y_{1:t})}^{\text{forward filtering}} \overbrace{\tilde{p}(x_t| y_{t+1:T})}^{\text{backward filtering}}} {\gamma_t(x_t)}.
            \label{eqn:tfs_final_form}
        \end{equation}
        %with $Z$ being the normalization constant. From eqn. \ref{eqn:tfs_final_form} it is clear that choosing a valid $\gamma_t(x_t)$ only requires satisfying minor support requirements to prevent division by zero. 
        % as Importance sampling where $p(x_t|y_{1:t})\tilde{p}(x_t| y_{t+1:T}) > 0 \Rightarrow \gamma_t(x_t) > 0$. 
        This suggest an algorithm where two PFs are run on the sequence independently, one forward and one backward in time, to compute forward particles $\{\overrightarrow{x}_{t}^{(1:N)}, \overrightarrow{w}_{t}^{(1:N)}\}$ and backward particles $\{\overleftarrow{x}_{t}^{(1:N)}, \overleftarrow{w}_{t}^{(1:N)}\}$. %respectively, for $t=1,..., T$, 
        Because continuously sampled forward and backward particle sets will not exactly align, classic TFS integrate these two filters by rewriting 
        %before combining them to estimate the smoothed posterior density $p(x_t|y_{1:T})$ represented as $\{\overleftrightarrow{x}_{t}^{(1:N)}, \overleftrightarrow{w}_{t}^{(1:N)}\}$.  Unfortunately discrete particle sets cannot be combined via direct multiplication so 
        Eq.~\eqref{eqn:tfs_final_form} as follows:
        \begin{equation}
            p(x_t|y_{1:T}) \propto \frac{p(y_t|x_t)\tilde{p}(x_t| y_{t+1:T}) \int p(x_t|x_{t-1}) p(x_{t-1} | y_{1:t-1}) dx_{t-1}} {\gamma_t(x_t)}.
            \label{eq:tfsWeights}
        \end{equation}
        This yields a particle re-weighting approach where backward filter particles $\overleftarrow{x}_{t}^{(1:N)}$ are re-weighted using the forward filter particle set, to produce the final smoothed particle weights $\overleftrightarrow{w}_{t}^{(1:N)}$:
        \begin{equation}
            \overleftrightarrow{w}_{t}^{(i)} \propto \overleftarrow{w}_{t}^{(i)} \sum_{j=1}^N \overrightarrow{w}_{t-1}^{(j)} \frac{p(\overleftarrow{x}_{t}^{(i)} | \overrightarrow{x}_{t-1}^{(j)})}{\gamma_t(\overleftarrow{x}_{t}^{(i)})},
            \qquad \sum_{i=1}^{N} \overleftrightarrow{w}_{t}^{(i)} = 1.
        \end{equation}
        %Weights are then normalized such that $\sum_{i=1}^{N} \overleftrightarrow{w}_{t}^{(i)} = 1$. 
        Conventional TFS set $\overleftrightarrow{x}_{t}^{(1:N)} = \overleftarrow{x}_{t}^{(1:N)}$, which similar to FFBS, makes performance heavily dependant on significant overlap in support between $p(x_t|y_{t+1:T})$ and $p(x_t|y_{1:T})$. Like FFBS, TFS also restrictively requires evaluation (not just simulation) of the state transition dynamics.
        
        
        \begin{figure}[t]
            \centering
            \includegraphics[width=0.97\textwidth]{resources/main_paper/mapillary_recall_curve_plot_mdpf_trained_solo.pdf}
            \vskip -0.05in
            \caption{\small{Position and error recall using the MGL \cite{sarlin2023orienternet} dataset. Recall is computed with the top posterior mode as well as with the best of the top-3 posterior modes, extracted via non-maximal suppression. As expected, Retrieval \cite{noe2020eccv} methods do poorly due to their lack of discrimination power between neighboring map patches. Dense search \cite{sarlin2023orienternet} does better by using fine map details during localization, but it requires a ground truth hint (``Cheating" with GT, which artificially improves performance) to work well at city-scale environments.  Retrieval (PF) \cite{9635972GausePF} uses unlearned state dynamics, which proves useful, but still suffers from the poor discriminative ability of retrieval. In contrast, MDPF \cite{younis2023mdpf} uses end-to-end learned dynamics and measurement models, allowing for good performance but suffering from only using  past information when estimating posterior densities.  Our MDPS is able to learn similar strong dynamics and measurement models as MDPF, and also incorporates future as well as past information to achieve a more accurate posterior density and thus higher recall.}}
            \label{fig:mapillary_recall_curves}
            \vskip -0.1in
        \end{figure}


        


        
        
        
        

        

    
        
        