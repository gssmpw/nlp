% start iclr2025
% \documentclass{article} % For LaTeX2e
% \usepackage{iclr2025_conference,times}
% \usepackage{natbib}
% \bibliographystyle{unsrtnat}
% Comment out the line below if using A4 paper size
% start iaict
% \documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\documentclass{article}
\usepackage{hyperref}
\usepackage[accepted]{icml2025}
\usepackage{cite}

% \usepackage{natbib}
% \usepackage[letterpaper]{geometry}
% \usepackage[a4paper, total={6in, 8in}]{geometry}

% \usepackage{ltexpprt}
\usepackage{hyperref}
\usepackage[pdftex]{graphicx}

% \usepackage{float}
% \documentclass[9pt,technote]{IEEan}

% \usepackage[english]{babel}

% % \usepackage[top=2cm,bottom=2cmodel.ingright=3cm,marginparwidth=1.75cm]{geometry}

% \usepackage{lipsum}
% \usepackage{mwe}

% \uis exceptionally long.exsym}
% \usepackage{amsmath}
% \usepackage{graphicx}
% \usepackage[colorlinks=true, allcolors=blue]{hyperref}
%writtenpackage[table,xcdraw]{xcolor}
\usepackage{multirow}
\usepackage{algorithm,float}
% \usepackage{algpseudocode}

% \usepackage{algorthem}
% \usepackage{wrapfig}
% \usepackage{changepage}
\usepackage{booktabs}
\DeclareUnicodeCharacter{2212}{-}
\usepackage{hhline}
% \usepackage{array}
% \newcolumntype{L}{>{\arraybackslash}m{1.5cm}}
% % \usepackage{algpseudocode}


% %\newlength\myincorecorded timesrade-offdent{2em}
% \newcommand\bindent{%
%   \begingroup
%   \setlength{\itemindent}{\myindent}
%   \addtolength{\algo\citep{subtab},\myindent}
% }
% \newcommand\eindent{\endgroup}

% \renewcommand{\algorithmicrequire}{\textbf{Input:}}
% \renewcommand{\algorithmicensure}{\textbf{Output:}}

% \usepackage{makecell}

% \renewcommand\theadalign{bc}
% \renewcommand\theadfont{\bfthe top three models.wcommand\theadgape{\Gape[4pt]}
% \renewcommand\cellgape{\Gape[4pt]}


% \usepackage{authblk}
% \usepackage{orcidlink}
% \title{Learning from Tabular Data with Out of Distribution}
\title{Representation Learning on Out of Distribution in Tabular Data}

\icmltitlerunning{Representation Learning on Out of Distribution in Tabular Data}
% \makeatletter
% \author{Achmad Ginanjar, Xue Li \& Priyanka Singh \thanks{ } \\
% School of Information Technology and Electrical Engineering\\
% The University of Queensland\\
% Brisbane, Queensland 4067, Australia \\
% \texttt{a.ginanjar@uq.edu.au} \\
%  \And
% Wen Hua \\
% Department of Computing \\
% The Hong Kong Polytechnic University \\
% Hong Kong \\
% }

% \author{\IEEEauthorblockN{1\textsuperscript{st} Achmad Ginanjar}
% \IEEEauthorblockA{\textit{School of EECS} \\
% \textit{The University of Queensland}\\
% Brisbane, Queensland, Australia \\
% a.ginanjar@uq.edu.au}
% \and
% \IEEEauthorblockN{2\textsuperscript{nd} Xue Li}
% \IEEEauthorblockA{\textit{School of EECS} \\
% \textit{The University of Queensland}\\
% Brisbane, Queensland, Australia}
% \and
% \IEEEauthorblockN{3\textsuperscript{rd} Priyanka Singh}
% \IEEEauthorblockA{\textit{School of EECS} \\
% \textit{The University of Queensland}\\
% Brisbane, Queensland, Australia}
% \and
% \IEEEauthorblockN{4\textsuperscript{th} Wen Hua}
% \IEEEauthorblockA{\textit{Department of Computing} \\
% \textit{The Hong Kong Polytechnic University}\\
% Hong Kong}
% }

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
% \usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
    
\usepackage{url}
\usepackage{subfig} % for multiple image


\usepackage{array}
\newcolumntype{L}{>{\arraybackslash}m{2.5cm}}

\begin{document}


% \maketitle
\twocolumn[
\icmltitle{Representation Learning on Out of Distribution in Tabular Data}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Achmad Ginanjar}{a,c}
\icmlauthor{Xue Li}{a}
\icmlauthor{Priyanka Singh}{a}
\icmlauthor{Wen Hua}{b}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{a}{
School of EECS, The University of Queensland, Brisbane, Queensland, Australia
}
\icmlaffiliation{b}{
Department of Computing, The Hong Kong Polytechnic University, Hong Kong
}
\icmlaffiliation{c}{Indonesia Tax Office, Indonesia}

\icmlcorrespondingauthor{Achmad Ginanjar}{a.ginanjar@uq.edu.au}
\icmlkeywords{Machine Learning, Tabular Data, Representation Learning, OOD}

% \vskip 0.3in
]
\begin{abstract}

% The open-world assumption in model development indicates that a model may not have enough information to effectively manage data that is completely different or out of distribution (OOD). When a model encounters OOD data, its performance declined. To enhance a model's ability to handle OOD data, generalization techniques can be used, such as adding noise, which is easily implemented using deep learning methods. However, many advanced machine learning models are resource-intensive and optimized for use with specialized hardware like GPUs, which may not always be accessible to users with limited hardware capabilities. This study, however, provides practical solutions for handling OOD data, even on common consumer hardware (CPUs), making it accessible to a wider audience. This study explores detection, evaluation, and prediction tasks within the context of OOD on tabular datasets, demonstrating how users can identify OOD data from available datasets and offer guidance on evaluating the selection of OOD data through straightforward experiments and visualizations. Additionally, this study introduces a technique called Tabular Contrast Learning (TCL), a representation learning technique which is specifically designed for tabular prediction tasks. TCL achieves better results compared to heavier models while being more efficient, even when trained on non-specialized hardware. This makes it particularly beneficial for general machine learning users who face computational constraints. The results show that TCL outperforms other models in classification tasks.
The open-world assumption in model development suggests that a model might lack sufficient information to adequately handle data that is entirely distinct or out of distribution (OOD). While deep learning methods have shown promising results in handling OOD data through generalization techniques, they often require specialized hardware that may not be accessible to all users. We present TCL, a lightweight yet effective solution that operates efficiently on standard CPU hardware. Our approach adapts contrastive learning principles specifically for tabular data structures, incorporating full matrix augmentation and simplified loss calculation. Through comprehensive experiments across 10 diverse datasets, we demonstrate that TCL outperforms existing models, including FT-Transformer and ResNet, particularly in classification tasks, while maintaining competitive performance in regression problems. TCL achieves these results with significantly reduced computational requirements, making it accessible to users with limited hardware capabilities. This study also provides practical guidance for detecting and evaluating OOD data through straightforward experiments and visualizations. Our findings show that TCL offers a promising balance between performance and efficiency in handling OOD prediction tasks, which is particularly beneficial for general machine learning practitioners working with computational constraints. The code for our experiment can be found online (attached for submision)
\end{abstract}

\section{Introduction}
% The concept of open-world assumption in model development means that a model may not have enough information to effectively handle data that is completely different or out of distribution (OOD). When a model meets OOD data, it may suffer a significant decrease in performance \citep{Hsu2020,OODBaseline}. To handle this, model generalisation by introducing noise can be used, which can be achieved easily with deep learning. However, advanced deep learning algorithms such as FT-Transformer benefit from the advancement of specialised hardware such as GPU or TPU \citep{Hwang2018Background}, this type of hardware is not always available to the general user \citep{ahmed2020dedemocratizationaideeplearning}.  These demand the user to find the best way to deal with these challenges and emphasize the importance of our research.

% While out-of-distribution (OOD) detection has been extensively studied \citep{Lee2020}, the challenge of prediction tasks for OOD data, particularly in tabular datasets, remains underexplored. Significant progress has been made in OOD detection with algorithms like MCCD \citep{multiClass}, OpenMax \citep{Bendale2016}, Monte Carlo Dropout \citep{Gal2016}, and ODIN \citep{Liang2017}. However, the study of prediction tasks on OOD for tabular data is limited. Tree-based classical models are known to be reliable for tabular data  \citep{Grinsztajn2022} , but our experiments show that these models exhibit a decrease in performance when dealing with OOD data.

% In this study, we made several contributions. First, we show step by step how to implement existing methods for detecting, separating, evaluating, and visualizing out-of-distribution (OOD) data using real-world datasets. Second, we assess the performance of existing tabular machine learning algorithms in handling OOD data. Lastly, we introduce a new approach called TCL, which provides efficiency and flexibility while achieving comparable performance.


% Tabular Contrast Learning (TCL), Figure \ref{fig:tcl}, is a local adaptation of Contrastive Federated Learning (CFL) \citep{anonymizedMethod} designed for prediction tasks on tabular datasets for a general user. TCL is based on the principles of contrastive learning \citep{Chen2020SimClr,subtab} but is optimized for tabular data structures. TCL approach offers several advantages, e.g. 
% \textbf{Efficiency}: TCL is designed to be faster and more compact compared to current state-of-the-art models,
% \textbf{Flexibility}: TCL can be integrated with various supervised learning algorithms and 
% \textbf{Performance}: TCL achieves competitive performance.

% Our experiment demonstrates that TCL delivers performance and efficiency \citep{huang2017speedaccuracy} (defined by a higher speed/accuracy trade-off score)  compared to other models. 
\begin{figure*}[]
    \centering
    \includegraphics[width=0.8\linewidth]{TCL-TCL.drawio.png}
    \caption{Tabular Contrastive Learning (TCL). The data $[x]$ is duplicated $([x]_1,[x]_2)$ and noise is added. Both duplicates are then encoded and decoded to compute the loss. During inference, TCL only uses the encoder to produce new data $[x]'$ that enhances supervised learning performance $f([x]') \rightarrow Y $. The decoder is omitted during inference and used only for training.}
    \label{fig:tcl}
\end{figure*}
 The open-world assumption in machine learning presents a significant challenge: models often lack sufficient information to effectively handle data that differs substantially from their training distribution, known as out-of-distribution (OOD) data. When encountering OOD data, models typically experience a marked decline in performance \citep{Hsu2020,OODBaseline}, compromising their reliability in real-world applications. While various generalization techniques exist to address this issue, such as noise injection through deep learning methods, these solutions often come with substantial computational requirements.

A particular challenge emerges in the context of modern machine learning: many advanced algorithms are optimized for specialized hardware like GPUs or TPUs \citep{Hwang2018Background}, creating a significant barrier for users with limited computational resources. This hardware dependency has led to what some researchers call the "democratization gap" in artificial intelligence \citep{ahmed2020dedemocratizationaideeplearning}, where cutting-edge solutions become inaccessible to a broader user base relying on standard computing infrastructure.

While OOD detection has been extensively researched \citep{Lee2020}, with notable contributions such as MCCD \citep{multiClass}, OpenMax \citep{Bendale2016}, Monte Carlo Dropout \citep{Gal2016}, and ODIN \citep{Liang2017}, the specific challenge of prediction tasks for OOD data in tabular datasets remains relatively unexplored. Traditional tree-based models, despite their proven reliability with tabular data  \citep{Grinsztajn2022}, show significant performance degradation when confronted with OOD samples, as demonstrated in our experiments.

Our research makes three key contributions to address these challenges:
\begin{enumerate}
    \item We provide a comprehensive, step-by-step framework for implementing existing methods to detect, separate, evaluate, and visualize OOD data using real-world datasets.
    \item We conduct a thorough assessment of current tabular machine learning algorithms' capabilities in handling OOD data, establishing a benchmark for future research.
    \item We introduce Tabular Contrastive Learning (TCL), a novel approach that offers both efficiency and flexibility while achieving competitive performance, particularly designed for users with limited computational resources.
\end{enumerate}
TCL, Figure \ref{fig:tcl}, builds upon the principles of contrastive learning \citep{Chen2020SimClr,subtab} but is specifically optimized for tabular data structures. Our approach offers several advantages: computational efficiency compared to state-of-the-art models, flexibility in integration with various supervised learning algorithms, and robust performance across different types of prediction tasks.

Through extensive experimentation, we demonstrate that TCL delivers superior performance while maintaining efficiency, as measured by a higher speed/accuracy trade-off score \citep{huang2017speedaccuracy} compared to existing models. This makes TCL particularly valuable for general machine learning practitioners who face computational constraints while requiring reliable performance on OOD data.


\section{Related Work}
The study of out-of-distribution (OOD) data handling spans multiple research directions, each contributing to our understanding of model behavior and robustness. This section reviews key developments in OOD detection, representation learning for tabular data, and contrastive learning approaches.
\subsection{OOD detection}
% \textbf{OpenMax} \citep{Bendale2016} uses the concept of Meta-Recognition to estimate the probability that an input belongs to an unknown class. OpenMax characterizes the failure of the recognition system and handles unknown/unseen classes during operation. In deep learning, SoftMax calculates  as $ P(y=j|x) = \dfrac{e^{v_j(x)}}{\sum^N_{i=1} e^{v_i(x)} }$
% OpenMax recognizes that in out of distribution (OOD), the denominator of the SoftMax layer does not require the probabilities to sum to 1.

% \textbf{TemperatureScaling} \citep{platt1999probabilistic} is a single-parameter variant of the Platt scaling. In a study by Guo\textit{ et al.}  \citep{Guo2017}, despite its simplicity, temperature scaling is effective in calibrating a model for deep learning. This also suggests that temperature scaling can be used to detect OOD.  Our study uses these two approaches to separate OOD from the dataset and use it as validation data.

% \textbf{Multi-class classification, deep neural networks, Gaussian discriminant analysis (MCCD)} \citep{multiClass} is OOD detection algorithm based deep neural network that claim to have better classification inference performance. It is focuses on finding sperical-decission across classes.
Recent years have seen significant advances in OOD detection methodologies. Traditional approaches like ODIN \citep{Liang2017} and OpenMax \citep{Bendale2016} established foundational techniques for identifying OOD samples. Monte Carlo Dropout \citep{Gal2016}introduced uncertainty estimation as a means of OOD detection, while MCCD \citep{Lee2020} advanced the field with density-based detection methods. However, these methods primarily focus on detection rather than prediction tasks, leaving a gap in handling OOD data post-detection.

Our work primarily utilizes OpenMax and Temperature Scaling. While the original algorithms are not new, both algorithms have received the latest updates and provide better support under PyTorch-ood \citep{kirchheim2022pytorch} compared to MCCD \citep{deepMCCD}.

\subsection{Tabular data prediction}
\textbf{Neural Network-based Methods:}\\
    Multilayer Perceptron (MLP) \citep{mlp,tabr}: A simple deep learning method designed for tabular datasets. \\ 
    Self-Normalizing Neural Networks (SNN)  \citep{snn}: Employs SELU activation to enhance the training of deeper neural networks.

\textbf{Advanced Architectures:}\\
Feature Tokenizer Transformer / FT-Transformer \citep{vaswani2017attentiontransformer}: Modifies the transformer model for tabular datasets, consistently achieving excellent performance.  \\
Residual Network / ResNet \citep{restnet}: Employs parallel hidden layers to effectively capture intricate feature interactions.  \\
Deep Cross Network / DCN V2 \citep{DCNV2}: Integrates a feature-crossing component alongside linear layers and multiplications.  \\
Automatic Feature Interaction / AutoInt\citep{AutoInt}: Utilizes attention mechanisms applied to feature embeddings.  \\
Neural Oblivious Decision Ensembles / NODE \citep{NODE}: Represents a differentiable ensemble of oblivious decision trees.  \\
Tabular Network / TabNet \citep{TabNet}: Implements a recurrent design with periodic adjustments to feature weights, emphasizing an attention framework.

\textbf{Ensemble Methods:}\\
   GrowNet \citep{GrowNet}: This method applies gradient boosting to less robust multi-layer perceptrons (MLPs), primarily for tasks involving classification and regression.
\textbf{Gradient Boosting Decision Tree (GBDT) } \citep{Grinsztajn2022} : \\
    XGBoost: A tree-based ensemble technique that utilizes second-order gradients and regularization to avoid overfitting while enhancing computational efficiency.\\
    LightGBM: A rapid and memory-efficient boosting framework that employs histogram-based algorithms and a leaf-wise tree growth approach for quicker training.\\
    CatBoost: A gradient boosting implementation tailored for categorical features, featuring built-in ordered boosting to minimize prediction shifts.

These models have demonstrated varying degrees of success in predicting tabular data. However, their performance on out-of-distribution data remains a critical area for investigation. We include the mentioned models as our base model.

\subsection{Tabular contrastive learning}
    SubTab \citep{subtab} and SCARF \citep{scarf} are a contrastive learning model designed specifically for tabular datasets. They operate under a concept similar to the core idea of contrastive learning for images as described in SimCLR \citep{Chen2020SimClr}. SubTab and SCARF compute contrastive loss using either cosine or Euclidean distance. Both methods are not designed for out-of-distribution problems. We include both methods in our comparison.
    
    CFL \citep{anonymizedMethod} is a federated learning algorithm designed to address vertical partitioning within data silos. CFL investigates the potential of applying contrastive learning to vertically separated data without requiring data exchange. CFL integrates weights by recognizing that the data is derived from a global imaginary dataset that is vertically partitioned. CFL employs contrastive learning as a strategy for black-box learning. CFL emphasizes cooperative learning across different silos. In this research, we examine learning from local data with OOD, an area that has not been previously investigated by CFL. While CFL operates within a federated learning framework, our focus is on standard tabular data. Despite having a similar name, CFL incorporates partial data augmentation as part of its federated learning approach and resembles image contrastive learning. Conversely, TCL utilizes complete matrix augmentation to accommodate tabular data.
% \section{Problem Formulation}
% \subsection{Definition}
% \textbf{Definition 1: Tabular Data.}
% Let $D \in R^{n×d}$ be a tabular dataset with $n$ samples and $d$ features, and $Y \in R^n$ be the corresponding labels. Tabular data is characterized by its structured format, where each row represents a sample and each column represents a feature.  

% \textbf{Definition 2: Out-of-Distribution Prediction.}
% Given a model trained on in-distribution data $D_{in}=\{(x_i,y_i)|x_i \in X_{in},y_i \in Y_{in}\}$, where $X_{in}$ follows a distribution $p_{in}$, the task is to make accurate predictions on OOD data $X_{ood}$ that follows a different distribution $p_{ood}$, where $p_{ood} \neq p_{in}$.

% \textbf{Definition 3: Efficiency-Accuracy Trade-off.}
% We use a speed/accuracy trade off \citep{huang2017speedaccuracy} from the total performance matrix. Let $T$ be the total performance , then $ T=\frac{P}{t}$ for classification or  $T=\frac{1/P}{t} $ for regression.

% A performance evaluation $P$ used is F1 or RMSE for the prediction task and the time $t$ in seconds for the duration of training. The $P$ is used to obtain the standard performance of a model. The $t$ is used to evaluate the time it takes to train a model. A smaller $t$ means a smaller resource to find the best model by tuning the hyperparameters.  The adjustment $\frac{1}{P}$ for regression is necessary because in regression tasks, RMSE is used as the performance metric, and smaller values are better. 
\section{Problem Statement}
We consider the pair of $D_{train} = D_{in}$ and $D_{test} = D_{ood}$. A training dataset $D_{train}$ is  drawn from a source distribution $P_{train}$. A model must perform effectively not only on data from this training distribution but also on samples drawn from different test distributions $P_{test}$, where significant distributional shifts may occur. This requirement for robust performance must be balanced against strict computational constraints, represented by a budget B\textit{B} that limits the computational resources available for both training and inference.

The core of our problem can be expressed as finding a function $f:x\rightarrow y$  that maximizes the efficiency score $S_{eff} = \frac{\text{\textbf{max} }P_{ood}}{\text{\textbf{min }} t} = \frac{ 1 / \textbf{min } E(x,y) _{D_{ood}}}{\text{\textbf{min }} t}$, defined as the ratio of OOD performance to computational time. This optimization must be achieved while ensuring the model operates within our specified computational budget and maintains a minimum acceptable performance threshold $\alpha$. 

% that generalizes unseen data. However, if the model is exposed to samples outside the distribution during inference, it may make unreliable predictions or exhibit unexpected behaviour.

% Formally, a prediction task can be defined as finding a model $f:(.)$ that minimizes the expected error over a dataset   $D_{in}$ with distribution $p_{in}$.  This can be defined as $\textbf{min } \text{Error}(x,y) _{D} = [L(f(x), y)]$, where $L$ is a loss function that measures the discrepancy between the prediction of the model $f(x)$ and the true label $y$. A bigger $E$ means poor model performance $P$ or can be denoted as $E\uparrow = P\downarrow$. When a different distribution $p_{ood}$ is introduced to a model, the performance decreased or $P(f((x)_{D_{in}})) > P(f((x)_{D_{ood}}))$. 

% The time $t$ to find the best model should also be considered. A time-consuming model takes more resources to train and tune. When dealing with a large dataset, the time used to train and tune a model is a big concern. A larger and longer model does not always equal better performance $P$. This can be written as $t\uparrow \ne P\uparrow$.

% We evaluated the total/overall performance of the models when dealing with tabular dataset with OOD. The overall objection can be writen as $T=\frac{\text{\textbf{max} }P_{ood}}{\text{\textbf{min }} t} = \frac{ 1 / \textbf{min } E(x,y) _{D_{ood}}}{\text{\textbf{min }} t}$.

\section{Proposed Method}
% We introduce Tabular Contrastive Learning (TCL), an improved approach designed to enhance prediction tasks on tabular data, particularly with hardware limitations. 
% \subsection{TCL Main Architecture}
%  \textbf{Augmented Data}\\
%  As a contrastive learning based algorithm, TCL works based on augmented data. TCL creates two data augmentations. Denotated as $\{x^1,x^2\} = \text{Aug}(x)$.  Noise was added to these augmented data. A loss function then applied berween augmented data.

%  \textbf{Matrix Augmentation}\\
%  In TCL, all original data (without slicing or splitting) is utilized as a representation. Unlike previous approaches such as simCLR \citep{Chen2020SimClr} and SubTab \citep{subtab} that use slice, TCL utilizes the entire original data matrix for representation. This allows for capturing more comprehensive feature interactions in tabular data. 

% \textbf{Encoder-Decoder Structure}\\
% The contrastive learning architecture includes two main components: an encoder and a decoder. The encoder transforms input data into a compressed representation called the latent space, denoted $E: x;\omega^e \rightarrow x^e$ where $\omega$ is parameter and $e$ is encoder notation, while the decoder reconstructs the original data from this representation denoted $P:x^e;\omega^p \rightarrow x^p$ where $p$ is notation for decoder. During training, both components are used, but only the encoder is employed during inference, allowing efficient compression of new data into its learned latent representation without reconstruction.

% \textbf{Modified Contrastive Loss}\\
% Loss is calculated based on augmented data, not original data. TCL  simplifies contrastive loss calculation to enhance both performance and training speed. In contrastive learning, the loss is computed based on the similarity or dissimilarity of the augmented noisy data. Since TCL deals with row-based tabular data and it is a unsupervised learning, the method used is similarity.  TCL aims to pull the noisy data points that originated from the same data. This is achieved by minimizing the total loss $L_c$ between representations. During training, the total loss is calculated as follows:
%  \begin{gather}
%  L_t(x) = 
%  (L_r(x) + L_c(x) + L_d(x)) 
% \end{gather}
% Where $L_r$ is the reconstruction loss, $L_c$ is the contrastive loss, and $L_d$ is the distance loss. The objective of contrastive learning is to minimize the total loss $L_t$.  When $D$ is dataset, and sliced data $\mathcal{B} \in D$ , then:
% \begin{equation}
% \begin{split}
%     \text{min } L_t(.;\omega^e,\omega^p) &= 
%     \text{min }  \frac{1}{J} \Sigma_{j=1} ^{J} L_t( P(E(.;\omega^e);\omega^p)) \\
%      % L_t(.;\omega^e,\omega^p) &= \frac{1}{J} \Sigma_{j=1} ^{J} L_t( x)
% \end{split}
% \end{equation}
% with $w$ is weight, $P(.)$ is decoder function, and $ E(.)$ is encoder function. 
% When $MSE(.)$ is the mean square error function, and $[x]$ is noisy data of $\mathcal{B}$, then:
%   $  L_r(x) = \dfrac{1}{N} \sum_n^N MSE(\hat{x},x) $ and 
% $
% L_d(x) = \dfrac{1}{N}  \sum_n^N MSE(x^{e1},x^{e2})
% $.
% While $L_r$ is calculated from decoded data and original data,  $L_d$ is calculated from encoded data only. We simplified the contrastive loss $L_c$  by using only the result of a dot product compared with other contrastive learning that used euclidean distance.  
% \begin{gather}
% % L_c (x)  =  \dfrac{1 }{N} \sum_n^N  (−log \frac{\exp ( MSE([0],dot( x^{e1} \cdot x^{e2})) \text{/} \mathcal{T})}{\sum^K_{k=1} \exp ( MSE([0],dot(x^{e1} \cdot x^{e2} ))\text{/} \mathcal{T})})
% MSE([0],dot( x^{e1} \cdot x^{e2})) \text{/} \mathcal{T}
% \end{gather}
% We introduce Tabular Contrastive Learning (TCL), a lightweight approach designed to enhance prediction tasks on tabular data, particularly when operating under hardware limitations. TCL's architecture incorporates several key components and innovations:

\subsection{Core Components}
\textbf{Data Augmentation}\\
TCL employs a dual augmentation strategy where each input data point $x$ generates two augmented versions, denoted as  $\{x^1,x^2\} = \text{Aug}(x)$. These augmentations undergo controlled noise injection to create slightly varied representations of the same data point. The augmented pairs serve as the foundation for the contrastive learning process.

\textbf{Full Matrix Augmentation}\\
Unlike traditional approaches like SimCLR or SubTab, which typically rely on data slicing, TCL adopts a more comprehensive strategy by utilizing the complete original data matrix for representation learning. This holistic approach allows for the preservation of all feature interactions, enabling a deeper understanding of how different features relate to one another. It also captures global data patterns, which can provide significant insights into the overall structure of the dataset. Furthermore, TCL maintains the structural relationships within the data, ensuring that the intrinsic connections among various data points are not lost in the learning process.

\textbf{Encoder-Decoder Architecture}\\
TCL utilizes a two-component architecture consisting of an encoder ($E: x;\omega^e \rightarrow x^e$) and a decoder ($P:x^e;\omega^p \rightarrow x^p$). The encoder is responsible for transforming input data into a compressed latent representation, with its parameters optimized for efficient feature extraction. On the other hand, the decoder reconstructs the original data from this latent space, although its parameters are not utilized during inference; they are only employed during the training process.
\subsection{Loss Function Design}
TCL follows CFL that employs a composite loss function that combines three components $L_t(x) = 
 (L_r(x) + L_c(x) + L_d(x)) $\\
\textbf{Loss Components:}\\
Reconstruction Loss $  L_r(x) = \dfrac{1}{N} \sum_n^N MSE(\hat{x},x) $ \\
Distance Loss $L_d(x) = \dfrac{1}{N}  \sum_n^N MSE(x^{e1},x^{e2})$ \\
Simplified Contrastive Loss $L_c(x)=MSE([0],dot( x^{e1} \cdot x^{e2})) \text{/} \mathcal{T}$ \\
TCL simplifies the contrastive loss calculation by using dot product similarity instead of traditional Euclidean distance, enhancing both computational efficiency and training speed. The optimization objective during training is:
\begin{gather}
    \text{min } L_t(.;\omega^e,\omega^p) = 
    \text{min }  \frac{1}{J} \Sigma_{j=1} ^{J} L_t( P(E(.;\omega^e);\omega^p))
\end{gather}
% \begin{equation}
% \begin{split}
%     \text{min } L_t(.;\omega^e,\omega^p) &= 
%     \text{min }  \frac{1}{J} \Sigma_{j=1} ^{J} L_t( P(E(.;\omega^e);\omega^p))
%      % L_t(.;\omega^e,\omega^p) &= \frac{1}{J} \Sigma_{j=1} ^{J} L_t( x)
% \end{split}
% \end{equation}
% \subsection{Training and Inference}
% During the training phase, TCL processes data by utilizing both its encoder and decoder components. It computes all three components of loss, enabling the model to update its parameters effectively to minimize the total loss. In contrast, during the inference phase, TCL relies solely on the encoder component. A model replaces decoder during inference. The model can be any conventional, such as logistic, or deep learning, such as MLP. 

\section{TCL Algorithm}
The TCL process consists of several steps. First, a minibatch of \( N \) samples is drawn from the dataset. For each sample in the batch, two augmented views are created, each with added noise. Although both views originate from the same data, they differ due to the augmentation processes applied. These augmented views are then passed through an encoder network to obtain their encoded representations. Subsequently, a decoder is applied to these encoded representations. The loss function calculates the difference between the two augmented views. By minimizing this loss, the noisy data is effectively consolidated. Since TCL employs a full matrix representation, the process brings together the noisy data row by row, resulting in generalized data that enhance the inference performance.

During the training phase, TCL processes data by utilizing both its encoder and decoder components. It computes all three components of loss, enabling the model to update its parameters effectively to minimize the total loss. In contrast, during the inference phase, TCL relies solely on the encoder component. A model replaces decoder during inference. The model can be any conventional, such as logistic, or deep learning, such as MLP. 
% The complete steps are presented on Algorithm \ref{alg:tcl} in the Appendix section.
\section{Experiment}

\subsection{Datasets}
We utilize 10 diverse tabular datasets: Adult \citep{adult_2}, Helena \citep{helenaJannis}, Jannis \citep{helenaJannis}, Higgs Small \citep{higgssmall}, Aloi \citep{aloi}, Cover Type \citep{covtype}, California Housing \citep{ca}, Year \citep{year}, Yahoo \citep{chapelle2011yahoo}, and Microsoft\citep{microsoft}. 

\subsection{OOD Detection}
To identify and handle out-of-distribution data, we employed two detection methods: OpenMax \citep{Bendale2016} and TemperatureScaling \citep{platt1999probabilistic}. These methods were systematically applied to each dataset to transform the data and establish appropriate thresholds for OOD detection. Through careful observation of the graphs generated by the OOD detection algorithms, we manually determined these thresholds by selecting specific points along the tail of the distribution. Using these established thresholds, we separated the data into two distinct sets:  $D_{in}^M$ and $D_{ood}^N$, where $M$ and $N$ represent the total number of samples in each set, with their sum constituting the complete dataset $(D_{in} + D_{ood} = D)$. By design, we anticipated and confirmed that the in-distribution set would be larger than the OOD set  $M>N$. To validate our separation approach, we employed linear regression as a verification method. The effectiveness of this separation was then evaluated by comparing model performance across both sets, where we consistently observed the expected pattern of decreased performance on the OOD set compared to the in-distribution data  $f:D_{in} > f:D_{ood}$, confirming the successful identification of out-of-distribution samples.

The process results two distinct datasets: $D_{in},D_{ood}$. We use these sets by designating $D_{in}$ them as our training dataset while $D_{ood}$ serving as our test dataset. This separation allows us to evaluate our model's performance on out-of-distribution data in a controlled manner.
% The Algorithm \ref{alg:OODDetection} in the Appendix section explains step by step the OOD detection is done.

\subsection{Prediction ON OOD Dataset}
Thi study uses seven baseline models, including several deep learning approaches specifically designed for tabular data: FT-T, DCN2, GrowNet, ResNet, MLP, AutoInt, and TabR-MLP. We also incorporated two recent contrastive learning implementations for tabular data—SubTab \citep{subtab} and SCARF \citep{scarf}—which share similar methodological foundations with our proposed TCL approach. It is worth noting that we had to exclude FT-Transformer from certain dataset evaluations due to its computational intensity exceeding our hardware capabilities. In addition, we included GBDT models in our comparative analysis to provide a broader perspective. 

While most models were trained using an NVIDIA H100 GPU, we deliberately conducted TCL training on CPU hardware only to demonstrate our method's effectiveness under hardware constraints, highlighting its practical applicability in resource-limited environments.

\section{Results}

\subsection{OOD Detection}
\begin{table*}[]
\small
\centering
\caption{The OOD detection settings.  Performances are results of model trained with linear regression ($r^2$) and logistic regression (accuracy). When OOD dataset is separated and used as test dataset in  $(^b)$ the performance of the model is decreased. Where Det for detector, O for openMax, T for TemperatureScalling, and Norm for normalisation applied.
% OOD case in the epsilon $(^*)$ dataset cannot be identified. 
}
\begin{tabular}{|l|l|l|l|ll|ll|}
\hline
\multirow{3}{*}{Dataset}      & \multirow{3}{*}{Det} & \multirow{3}{*}{Norms} & \multirow{3}{*}{Threshold} & \multicolumn{2}{l|}{ID Accuracy $^a$}                         & \multicolumn{2}{l|}{OOD Accuracy $^b$}                             \\ &                      &                        &                               & \multicolumn{1}{l|}{Train}  & Test& \multicolumn{1}{l|}{Train}                   & Test                     \\ &                      &                        &                               & \multicolumn{1}{l|}{}                        &                         & \multicolumn{1}{l|}{ID}                      & OOD                      \\ \hline
Adult       & O & L2 & 0.1628    & 0.7825 & 0.783  & 0.7978 & 0.2674  \\
Helena      & O & L1 & 0.045     & 0.1945 & 0.1966 & 0.1464 & 0.0475  \\
Jannis      & T & L1 & -0.02     & 0.5619 & 0.5639 & 0.5772 & 0.4742  \\
Higgs small & O & L1 & 0.042     & 0.6222 & 0.6168 & 0.6226 & 0.5684  \\
Aloi        & O & L1 & 0.016     & 0.2606 & 0.2325 & 0.3282 & 0.0711  \\
Covtype     & T & L1 & -0.035    & 0.6046 & 0.6043 & 0.6035 & 0.4354  \\
California  & O & L1 & 0.11      & 0.3334 & 0.1806 & 0.4771 & -6.0335 \\
Year        & O & L2 & 0.045     & 0.1686 & 0.167  & 0.1697 & -0.7141 \\
Yahoo       & T & L1 & 1.46E-03  & 0.3256 & 0.3262 & 0.3255 & -0.2978 \\
Microsoft   & T & L1 & -8.30E-03 & 0.0456 & 0.0441 & 0.0473 & -0.8418 \\ \hline
\end{tabular}
\label{tab:oodSetting}
\end{table*}
Our analysis of OOD detection, as detailed in Table  \ref{tab:oodSetting} , reveals distinct performance patterns across different experimental settings. In the standard setting outlined in Section a of Table  \ref{tab:oodSetting} , the training and test results indicate comparable performance levels, demonstrating the model's consistency under normal conditions. Conversely, in the OOD setting discussed in Section b, we observe a significant performance decrease of 20\% in classification tasks, while regression tasks yield negative $r^2$ scores. These findings clearly illustrate the challenging nature of OOD prediction.

% The OOD separation process is visualized in Figure \ref{fig:oodFigures}, which presents histogram graphs of the transformed data with detectors. The Epsilon dataset shows two peaks, indicating complexity, and outliers cannot be detected. In contrast, the Microsoft dataset shows a performance decrease with OOD. 
% Figures \ref{oodvisualisation} show the results of separating in-distribution (ID) and out-of-distribution (OOD) data using TSNE in an unsupervised manner. The figures demonstrate that OOD data fills the space between ID data, indicating a strong presence of OOD.Table  \ref{tab:oodSetting}, Figure \ref{fig:oodFigures}, and Figure \ref{oodvisualisation} show strong indications of the existence of out-of-distribution (OOD) data.
% \begin{figure}[]
%     % \centering
%     \subfloat[Adult]{
%         \label{imgAdult}
%         \includegraphics[width=0.20\textwidth]{tsne_adult.png}
%     }
%     \subfloat[Helana]{
%         \label{imgHelena}
%         \includegraphics[width=0.20\textwidth]{tsne_helena.png}
%     }
%     \subfloat[Jannis]{
%         \label{imgJannis}
%         \includegraphics[width=0.20\textwidth]{tsne_jannis.png}
%     }
%     \subfloat[Higgs Small]{
%         \label{imgHS}
%         \includegraphics[width=0.20\textwidth]{tsne_higgs_small.png}
%     }
%     \subfloat[Aloi]{
%         \label{imgAloi}
%         \includegraphics[width=0.20\textwidth]{tsne_aloi.png}
%     }
%     \newline
%     \subfloat[CovType]{
%         \label{imgcovtype}
%         \includegraphics[width=0.2\textwidth]{tsne_covtype.png}
%     }
%     \subfloat[California Housing]{
%         \label{imgCa}
%         \includegraphics[width=0.20\textwidth]{tsne_california_housing.png}
%     }
%     \subfloat[Year]{
%         \label{imgYear}
%         \includegraphics[width=0.20\textwidth]{tsne_year.png}
%     }
%     \subfloat[Yahoo]{
%         \label{imgYahoo}
%         \includegraphics[width=0.20\textwidth]{tsne_yahoo.png}
%     }
%     \subfloat[Microsoft]{
%         \label{imgMi}
%         \includegraphics[width=0.20\textwidth]{tsne_microsoft.png}
%     }
%     \caption{OOD Visualisation. (.) or blue color is the in distribution data (ID), (+) or red is out of distrobution data (OOD). In all dataset, except for Jannis, it is clearl that OOD fills empty space between ID. Jannis data is evenly distributed, the visualisation capture neither ID nor OOD.}
%     \label{oodvisualisation}
% \end{figure}

\subsection{Models Performance}
The comprehensive model comparison presented in Table \ref{tab:results} reveals several key findings. Notably, the TCL model consistently outperforms other models across various datasets, demonstrating particularly strong performance in classification tasks while also maintaining competitive results in regression problems. 

In contrast, specific models exhibit notable weaknesses. For instance, GrowNet tends to underperform when evaluated on the Adult and Yahoo datasets. Similarly, DCN V2 shows limitations on the California Housing dataset. Overall, other models typically display comparable performance across the datasets examined.
\begin{table*}
\small
    \centering
    \caption{Experiment result. F1 score for classification and RMSE for regression. Datasets with (*) mean a regression problem. Models with ($^c$) are contrastive learning based models.}
    \begin{tabular}{l|cccccc|cccc} \hline 
         &  AD$\uparrow$&  HE$\uparrow$&  JA$\uparrow$&  HI$\uparrow$&  AL$\uparrow$& CO$\uparrow$&   CA*$\downarrow$&YE*$\downarrow$&YA*$\downarrow$&MI*$\downarrow$\\ \hline  
         FT-T&  0.782&  0.153&  0.572&  0.738&  0.407&  -&   0.867&\textbf{6.461}&-&-\\ 
         DCN2&  0.744&  0.129&  0.542&  0.710&  0.414&  0.58&   2.602&7.054&0.645&0.746\\   
 GrowNet& 0.465& -& -& 0.685& -& -& 0.969& 7.605& 1.01&0.769\\  
 ResNet& 0.652& 0.10& 0.574& 0.753& 0.437& 0.694& 0.892& 6.496& \textbf{0.639}&\textbf{0.736}\\ 
 MLP& 0.508& 0.146& 0.561& 0.753& 0.326& 0.617& 0.894& 6.488& 0.657&0.741\\  
 AutoInt& 0.78& 0.133& 0.549& 0.719& 0.401& 0.608& 0.89& 6.673& -&0.739\\
 TabR-MLP& 0.688& 0.165& 0.541& 0.753& 0.429& 0.688& 2.677& 2e5& 1.285&0.79\\ \hline
 TCL$^c$& \textbf{0.831}& \textbf{0.154}& \textbf{0.575}& \textbf{0.758}& \textbf{0.447}& \textbf{0.880}& \textbf{0.843}&6.491&0.652&0.738\\
 Scarf$^c$& 0.720& 0.00& 0.122& 0.308& 0.00& 0.091& -& -& -&-\\
 SubTab$^c$& 0.714& 0.146& 0.504& 0.602& 0.322& 0.59&   1.012&6.668&0.656&0.744\\ 
    \end{tabular}
    \label{tab:results}
\end{table*}
\begin{table*}
\small
    \centering
    \caption{Experiment result of TCL compared to GBDT. F1 score for classification and RMSE for regression. Datasets with (*) mean a regression problem. Model with ($^c$) means contrastive learning based model, models with ($^x$) mean GBDT based models. }
    \begin{tabular}{l|cccccc|cccc} \hline 
         &  AD$\uparrow$&  HE$\uparrow$&  JA$\uparrow$&  HI$\uparrow$&  AL$\uparrow$& CO$\uparrow$&   CA*$\downarrow$&YE*$\downarrow$&YA*$\downarrow$&MI*$\downarrow$\\ \hline  
 TCL$^c$& 0.831& \textbf{0.154}& \textbf{0.575}& \textbf{0.758}& \textbf{0.447}& \textbf{0.880}& 0.843&\textbf{6.491}&\textbf{0.652}&0.738\\ \hline
 Lightgbm$^x$& 0.591& 0.080& 0.432& 0.609& 0.177& 0.219& 0.848& 6.565& 0.661&0.740\\
 CatBoost$^x$& \textbf{0.927}& 0.152& 0.533& 0.718& -& 0.753& \textbf{0.827}& 6.622& 0.655&\textbf{0.733}\\
 XGB$^x$& 0.925& 0.127& 0.532& 0.739& 0.328& 0.700& 0.845& 6.867& 0.654&0.739\\
    \end{tabular}
    
    \label{tab:resultsGBDT}
\end{table*}

When compared to the GBDT method, TCL demonstrates superior performance across most datasets, particularly in classification tasks, as shown in Table  \ref{tab:resultsGBDT}. Among the classification problems, the adult dataset stands out with a relatively higher score compared to other datasets. This indicates that the adult dataset requires less generalization during prediction, which explains why TCL performs slightly below CatBoost in this case. Notably, CatBoost dominates in four datasets, outperforming any other GBDT algorithm.

\subsection{Training Efficiency}
Table  \ref{tab:resultsTime} presents the training durations for the top three deep learning models, each characterized by unique features and training processes. A total of seven models—FT-T, DCN 2, GrowNet, ResNet, MLP, AutoInt, and TabR-MLP—underwent extensive parameter tuning. The complete tuning process for the Yahoo and Microsoft datasets spanned five days. For FT-T and ResNet, a single training time was recorded after completing the tuning phase. In the case of TCL, which involves unsupervised training, the recorded time reflects the duration required for each model to stabilize its loss using a batch size of 256, typically achieved within approximately 15 epochs. Notably, TCL demonstrates a relatively short training time.
\begin{table*}
\small
    \centering
    \caption{Table of training duration in second of each dataset. Datasets with (*) means a regression problem. All model except for TCL are trained with GPU. TCL were trained with CPU}
    \begin{tabular}{l|cccccc|cccc} \hline 
         &  AD$\downarrow$&  HE$\downarrow$&  JA$\downarrow$&  HI$\downarrow$&  AL$\downarrow$& CO$\downarrow$&   CA*$\downarrow$&YE*$\downarrow$&YA*$\downarrow$&MI*$\downarrow$\\ \hline  
         FT-T&  1027&  130&  155&  94&  1205&  -&   88&1290&-&-\\ 
         % DCN2&  42&  68&  53&  60&  685&  690&   18&85&218&655\\   
 % GrowNet& 3.6e+02& -& -& 92& -& -& 92& 223& 382&2400\\  
 ResNet& 2.1e+02& 32& 21& 56& 44& 618& 15& 236& 284&950\\ 
 % MLP& 30& 29& 15& 18& 74& 293& 11& 53& 34&110\\  
 % AutoInt& 38& 72& 32& 27& 348& 1037& 51& -& -&1212\\ 
 TCL& 15& 23& 23& 38& 40& 330&   7&240&620&820\\
 % SubTab& 1400& 1700& 2400& 2800& 3400& 1.8e+06&   640&1.5e+04&3.6e+04&4e+04\\\hline
    \end{tabular}
    
    \label{tab:resultsTime}
\end{table*}
\subsection{Efficiency Trade-offs}
\begin{table*}[h!]
\small
\centering
\caption{A speed/accuracy trade off matrix $S = \frac{P}{t}$ where $P$ performance matrix used and $t$ is time in second required.  A higher result is better. Datasets with (*) mean a regression problem.}
\begin{tabular}{r|rrrrrr|rrrr}
\toprule
 & AD      & HE     & JA     & HI     & AL      & CO     & CA*     & YE*     & YA*     & MI*     \\
\midrule
FT-T  & 0.00076 & 0.0012 & 0.0037 & 0.0079 & 0.00034 & -      & 0.013& 0.00012& -       & -       \\
ResNet& 0.0031& 0.0031& 0.027& 0.013& 0.0099& 0.0011& 0.075& 0.00065& 0.0055& 0.0014\\
TCL& 0.055& 0.0066& 0.025& 0.028& 0.0199& 0.0026& 0.16& 0.00064& 0.0024& 0.0016\\ \hline

\end{tabular}

\label{tab:tradeOff}
\end{table*}
The speed/accuracy trade-off analysis  from Table \ref{tab:tradeOff} reveals important distinctions between high-performance models and the advantages of TCL. Among the high-performance models, both the FT-Transformer and ResNet demonstrate excellent F1 and RMSE scores; however, they are notably resource-intensive. The FT-Transformer features a complex architecture that leads to exponential growth in computational demands, whereas ResNet operates with multiple parallel subnetworks that require heavy filtering.

In contrast, TCL offers several advantages with its simpler MLP-like architecture. It employs narrow layers in both the encoder and decoder, as well as a single hidden layer combined with a normalization layer. This design results in a superior speed-to-accuracy trade-off that stands out among competing models. The only drawback to TCL is that it requires double the training time due to the pair operations involved. Nonetheless, these results clearly demonstrate TCL's effectiveness as a lightweight yet powerful solution for out-of-distribution prediction tasks, making it particularly valuable in resource-constrained environments.

% \subsection{TCL Efficiency Evaluation}
% Our TCL has undergone significant algorithm modifications, making the original similarity loss function inapplicable. We compare TCL with SubTab, which employs a similarity function for tabular contrastive learning, to evaluate TCL's efficiency.

% Table \ref{tab:compareO} shows that the dot product applied on TCL consistently faster compared to similarity distance function applied to similar contrastive learning under SubTab. The efficiency gain from using the dot product supports our decision to incorporate it into the TCL model. Implementation of the entire original data matrix for representation removes matrix splitting as used in common contrastive learning. Implementation of dot product removes the requirement to calculate more complex similarity scores. Both algorithms were evaluated under CPU.  
% \begin{table*}[]
% \small
%     \centering
%     \caption{Table of training duration in second of each dataset. Datasets with (*) mean a regression problem. TCL uses the dot product, and SubTab uses the similarity function. Both algorithms were evaluated under CPU.}
%     \begin{tabular}{l|cccccc|cccc} \hline 
%          &  AD$\downarrow$&  HE$\downarrow$&  JA$\downarrow$&  HI$\downarrow$&  AL$\downarrow$& CO$\downarrow$&   CA*$\downarrow$&YE*$\downarrow$&YA*$\downarrow$&MI*$\downarrow$\\ \hline  
%  TCL& 15& 23& 23& 38& 40& 330&   7&240&620&820\\
%  SubTab& 1400& 1700& 2400& 2800& 3400& 1.8e+06&   640&1.5e+04&3.6e+04&4e+04\\\hline
%     \end{tabular}
    
%     \label{tab:compareO}
% \end{table*}


\section{Conclusion }
Our research highlights that the selection of models for managing out-of-distribution (OOD) tabular data hinges on two key factors: performance needs and resource availability. In terms of performance, TCL demonstrates superior results in classification tasks on OOD data while maintaining competitive efficiency metrics and operating effectively on CPU hardware. On the other hand, traditional models like ResNet and FT-Transformer exhibit strong overall performance but come with significant computational demands, including a reliance on GPU resources, which limits their accessibility. The distinction in hardware requirements is notable, as TCL's ability to function efficiently on CPUs makes it more accessible to a wider range of users compared to ResNet and FT-Transformer, which are constrained by their need for GPUs.

Several promising areas for future research have been identified. One key direction is the integration of continual learning, which holds a potential for performance enhancement through continuous adaptation and the exploration of dynamic learning approaches. Another area is optimization, where further refinement of the contrastive learning process and investigations into efficiency improvements could yield significant benefits. Expanding the application domains of TCL is also crucial, with opportunities to test its performance on more diverse, domain-specific tabular datasets and validate its effectiveness in various real-world scenarios. Additionally, interpretability research remains an important focus, emphasizing the development of methods to enhance model


% \section{Reproducibility}
% The code for this work can be found online \citep{tclCode} (submitted as a supplementary file). The dataset is also available online and can be downloaded using the information provided in the citation.



% \bibliographystyle{ieeetr}
\bibliographystyle{icml2025}
\bibliography{sample}
% \bibliographystyle{iclr2025_conference}

% \appendix
% \section{Appendix}
% \begin{algorithm}[H]
% \caption{OOD Detection and Train-Test Separation}
% \label{alg:OODDetection}
% \begin{algorithmic}
% \Require Dataset $D$, OOD detection methods $M = \{OpenMax, TemperatureScaling\}$
% \Ensure In-distribution dataset $D_{in}$, Out-of-distribution dataset $D_{ood}$

% \For{each method $m \in M$}
%     \State Apply $m$ to $D$
%     \State Obtain transformed data $D_m$
% \EndFor

% \For{each $D_m$}
%     \State Visualize histogram of $D_m$
%     \State Manually set threshold $t_m$ based on histogram
% \EndFor

% \State Initialize $D_{in} \gets \emptyset$, $D_{ood} \gets \emptyset$

% \For{each sample $x \in D$}
%     \If{$\forall m \in M: D_m(x) < t_m$}
%         \State $D_{in} \gets D_{in} \cup \{x\}$
%     \Else
%         \State $D_{ood} \gets D_{ood} \cup \{x\}$
%     \EndIf
% \EndFor

% \State Validate OOD separation using linear regression
% \State Compare model performance: $f(D_{in})$ vs $f(D_{ood})$

% \State \Return $D_{in}$, $D_{ood}$
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[]
% \caption{Tabular Contrastive Learning (TCL) Algorithm}
% \label{alg:tcl}
% \begin{algorithmic}
% \Require Tabular dataset $\mathcal{D}$, encoder $E$, decode $P$, batch size $N$, temperature $\tau$
% \For{each epoch}
%     \For{each batch $\mathcal{B} \in \mathcal{D}$}
%         \For{each sample $x_i \in \mathcal{B}$}
%             \State Create augmented views $x_{i}^1, x_{i}^2 = \text{Augment}(x_i)$
%         \EndFor
%         \State $\mathcal{B}_\text{aug} = \{x_{i}^1, x_{i}^2 | i = 1, \ldots, N\}$
%         \For{each $\tilde{x}_i \in \mathcal{B}_\text{aug}$}
%             \State $x^e = E(\tilde{x}_i)$ \Comment{Encode}
%             \State $x^p = P(x^e)$ \Comment{Decode}
%         \EndFor
%         \If{inference}
%         \Return $x^e$
%         \EndIf
%         \For{$i = 1$ to $2N$}
%             \State $i^+ = (i + N) \bmod 2N$ \Comment{Pair index}
%             % \State $ L_r(x)$
%             % \State $ L_d(x)$
%             % \State $ L_t(x)$
%             \State $ L_t = L_r + L_c + L_d$
%         \EndFor
%         \State $L_{tN} = \frac{1}{N} \sum_1^N L_t $
%         \State Update $E$ and $P$ by optimizing $L_{tN}$
%     \EndFor
% \EndFor
% \end{algorithmic}
% \end{algorithm}
\end{document}