

\IEEEPARstart{B}{ecause} of breakthroughs achieved in the last decade, \emph{\gls{genai}} stands as one of the most important stepping stones toward the intelligence era.
At its core, \gls{genai} excels in ($i$) distilling features of complex data distributions (uncovering intricate patterns) and ($ii$) utilizing these features to generate new, similar, yet distinct data.
This contrasts with the usual \emph{discriminative \gls{ai}} models that focus
on analyzing, interpreting, and classifying data to solve specific inference tasks.
This two-fold ability (\ie complex analysis and generation) positions \gls{genai} as a crucial technology in advancing both scientific research and industrial applications.
Accordingly, \gls{genai} supports tools designed to generate new content---text, images, videos, and more---based on patterns and information learned from large datasets. 

At a higher abstraction level, such capabilities showcase \gls{genai} as a powerful tool to solve intelligence-level tasks that are common to different domains: content generation, data augmentation,  conversational agents and question-answering tools, human-machine interactions, and automation.
%
Noteworthy examples of novel \gls{genai} models are represented by \glspl{llm}, Diffusion Models, and \glspl{ssm}.
To specify, \glspl{llm} are language models built on the \fmtTT{Transformer} architecture, and they are referred to as ``large'' due to their vast number of parameters.
Hereinafter, we use the terms ``\gls{llm}'' and ``\fmtTT{Transformer}'' synonymously to indicate the AI model~\cite{yang2024harnessing}.
Notable examples for these novel \gls{genai} solutions are represented by \texttt{GPT} and \texttt{LLaMA} for \gls{llm}, \texttt{DALL$\cdot$E} and \texttt{Stable Diffusion} for Diffusion Models, and \texttt{Mamba} for \gls{ssm}.
These models
have demonstrated significant commercial value and technical potential. 
They 
show notable reasoning, generalization, and emergent abilities in different applications, like text-to-text, text-to-image, and text-to-code.
%
As a consequence of such potential, the global \gls{genai} market stood at just under $45$ billion USD at the end of $2023$ (doubling its value compared to $2022$), and forecasts indicate an impressive growth of $\approx 20$ billion USD per-year through $2030$~\cite{statista1}.


The rapid development of \gls{genai} has been fueled by \textbf{three main drivers}: 
($i$) the availability of \emph{large-scale data corpora}; 
($ii$) methodological advancements in the \gls{ai} field, \ie the shift toward \emph{deep and foundational generative models}; 
($iii$) technological innovations supporting model building, \ie \emph{high-performance massive \glspl{gpu}}.
Notably, despite these drivers, only a few global stakeholders (to date) are capable of training \gls{genai} models from scratch. 
Hence, pre-trained large models are beginning to be shared by the open-source part of the \gls{genai} community.%
\footnote{See \eg \url{https://llama.meta.com/}.}

On the other side, recent networking research has focused on using \gls{dl} to develop efficient tools for \emph{\gls{nmm}} to meet modern Internet traffic needs.
In this respect, \gls{genai} can empower intent-based and autonomous networks by automating the translation of user objectives into actionable network policies~\cite{huang2024digital}.
This allows networks to self-configure, self-optimize, and self-heal, improving responsiveness and resilience. 
By leveraging \gls{genai}'s predictive capabilities, networks can indeed anticipate traffic patterns and issues, ensuring seamless operation. 
This reduces manual management complexity, accelerates innovation, and enhances user experience in a dynamically changing digital landscape. 
However, the full utilization of \gls{genai} for \gls{nmm} requires shifting from common text, audio, and image generation to network-focused synthetic content---%
fulfilling the concept of ``\gls{ai}-generated everything''~\cite{du2024age}.
Despite the interest in integrating \gls{genai} into networks and the Internet (trying to echo similar breakthroughs obtained in verticals such as computer vision or \gls{nlp}) to date, general deployment issues~\cite{lavin2022technology} and unique networking challenges remain~\cite{rossi2022landing}.




\subsection{Contributions and Survey Organization}
%

This article deepens the technical understanding of \gls{genai} within the context of \gls{nmm}. 
Accordingly, the \textbf{main contributions} provided by this manuscript can be summarized as follows:


\begin{itemize}

\item we discuss the \textbf{motivation behind our ``\gls{genai} landscape mapping''} effort in the field of \gls{nmm}, highlighting the shared interest in \gls{genai} from different stakeholders, as well as the gap in the (quickly-evolving) scientific literature we aim to fill with our work (Sec.~\ref{sec:motivation_rw});

\item 
we 
present
\textbf{a categorization of novel \gls{genai} methods}, 
offering the necessary background to help readers understand the distinctive aspects of \gls{nmm}-specific research efforts and applications (Sec.~\ref{sec:background});


\item we offer a \textbf{use-case-centric viewpoint}, discussing each \textbf{practical \gls{nmm} use case and its interplay with \gls{genai}} (Sec.~\ref{sec:genai_landscape}), along with a \textbf{model-centric viewpoint} (Sec.~\ref{sec:genai_model_overview}) to obtain a nuanced perspective. 
In addition, for the newly-branded \gls{genai} solutions, we detail the proposed modifications to reference \gls{genai} architectures and their code availability.





\item we provide a comprehensive view of
the \textbf{public datasets} leveraged for \gls{genai} model lifecycle and 
the
\textbf{available computing platforms} that can support and accelerate the design of novel \gls{genai}-based \gls{nmm} solutions (Sec.~\ref{sec:dataset_code_platforms});

\item finally, 
we briefly wrap-up the current \gls{genai} \textbf{limitations} and identify potential methodological/technological \textbf{enablers} for deploying it safely and at scale in the \gls{nmm} field (Sec.~\ref{sec:future directions}).
\end{itemize}
%
Figure~\ref{fig: survey_organization} outlines the organization of the present survey, sketching the details of the sections constituting the manuscript.







