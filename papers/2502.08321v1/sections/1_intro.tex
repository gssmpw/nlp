% !TEX root = ../main.tex

\section{Introduction}
\label{sec:intro}

\input{figures/first_page}

Accurate identification, localization, and classification of \emph{all} pathological findings in 3D medical images remain a significant challenge in medical computer vision. While supervised models have shown promise, their utility is limited by the scarcity of labeled datasets, which often contain annotations for only a few pathologies. For example, Figure~\ref{fig:first_page} shows 2D slices of 3D computed tomography (CT) images (first row) from public datasets~\cite{lidc,midrc,kits,lits} providing annotations of lung cancer, pneumonia, kidney tumors or liver tumors, while annotations of other pathologies, e.g., pneumothorax, are missing. This restricts the functionality of supervised models to narrow, task-specific applications.

Unlabeled CT images, however, are abundant: large-scale datasets~\cite{nlst,amos,abdomen_atlas} are publicly available but often remain unused for training. Leveraging these datasets, we aim to develop an unsupervised model capable of distinguishing pathological regions from normal ones. Our core assumption is that pathological patterns are significantly rarer than healthy patterns in CT images. This motivates framing pathology segmentation as an unsupervised visual anomaly segmentation (UVAS) problem, where anomalies correspond to pathological regions.

While existing UVAS methods have been explored extensively for natural images, their adaptation to medical imaging is challenging. One obstacle is that uncurated CT datasets include many patients with pathologies, and there is no automatic way to filter them out to ensure a training set composed entirely of normal (healthy) images --- a common requirement for synthetic-based~\cite{draem,mood_top1} and reconstruction-based~\cite{autoencoder,fanogan} UVAS methods.

Density-based approaches are better suited for this setting because they model the distribution of image patterns probabilistically and assume that abnormal patterns are rare rather than entirely absent in the training dataset. To model the density of image patterns, these methods encode them into vector representations using a pre-trained encoder. The existing methods~\cite{cflow,msflow} rely on encoders pre-trained on ImageNet~\cite{imagenet}, and their performance degrades when applied to medical images due to the significant domain shift. One could using medical domain-specific supervised encoders, such as STU-Net~\cite{stu_net}. However, our experiments show that this approach also works poorly, likely because the features learned by supervised encoders are too specific and do not contain information needed for distinguishing between pathological and healthy image regions.

To address these challenges, we propose using dense self-supervised learning (SSL) methods~\cite{vader,dense_cl,vicregl,vox2vec} to pre-train informative feature maps of CT images and employ them in the density-based UVAS framework. Thus, our model learns the distribution of dense SSL embeddings and assigns high anomaly scores to image regions where embeddings fall into low-density regions.

Inspired by dense self-supervised learning, we also generalize the idea of conditioning in density-based UVAS methods. Existing works~\cite{cflow,msflow} use hand-crafted conditioning variables like standard positional embeddings. We propose to replace them by pre-trained dense self-supervised features capturing context, i.e. global characteristics, of individual image regions, e.g. their anatomical position, patient's age. At the same time, we eliminate local information about presence of pathologies from the learned conditioning variables by enforcing their invariance to image masking.

We refer to the resulting model as Screener and train it on over 30,000 unlabeled CT volumes spanning chest and abdominal regions. As shown in Figure~\ref{fig:first_page} (third row), our model successfully segments pathological regions across different organs.
We demonstrate the Screener's superior performance compared to baseline UVAS methods on four large-scale test datasets comprising 1,820 scans with diverse pathologies. As shown in Figure~\ref{fig:first_page}, Screener, being a fully unsupervised model, demonstrates remarkable performance across diverse organs and conditions.
%We evaluate our model on four large-scale test datasets comprising 1,820 scans in two different setups. First, we compare our fully unsupervised model with baseline UVAS methods. Second, we distill the whole Screenerâ€™s inference pipeline into a simple U-Net model and compare it with baseline pre-trained U-Net models by fine-tuning them for segmentation of four specific pathologies.

Our key contributions are three-fold:
\begin{itemize}
	\item \textbf{Self-supervised encoder in density-based UVAS.} We demonstrate that dense self-supervised representations can be successfully used and even preferred over supervised feature extractors in density-based UVAS methods. This enables a novel fully self-supervised UVAS framework for domains with limited labeled data.

	\item \textbf{Learned conditioning variables.} We introduce novel self-supervised conditioning variables for density-based models, simplifying the estimation of conditional distributions and achieving remarkable segmentation performance using a simple Gaussian density model.

	\item \textbf{First large-scale study of UVAS in CT images.} This work presents the first large-scale evaluation of UVAS methods for CT images, showing state-of-the-art performance on unsupervised semantic segmentation of pathologies in diverse anatomical regions, including lung cancer, pneumonia, liver and kidney tumors.
\end{itemize}
