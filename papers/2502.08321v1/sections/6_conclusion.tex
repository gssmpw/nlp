% !TEX root = ../main.tex

\section{Conclusion}
\label{sec:conclusion}
This work explores a fully self-supervised approach to pathology segmentation in 3D medical images using a density-based UVAS framework. Existing UVAS methods rely on anomaly-free training datasets or supervised feature extractors, which are unavailable for CT images. To address these limitations, we introduce Screener, extending the density-based UVAS framework with two key innovations: (1) a self-supervised representation learning descriptor for image features, and (2) a trainable conditioning model that enhances simpler density models. Screener, being domain-specific and self-supervised, overcomes the limitations of earlier methods and achieves superior performance, as demonstrated by our empirical results.

\paragraph{Limitations.}
This work serves as a proof-of-concept for two hypotheses: (1) pathology segmentation in CT images can be approached as UVAS, and (2) density estimation in dense self-supervised feature spaces yields meaningful anomaly scores. However, unsupervised approach inevitably has limitations. Statistically abnormal visual patterns do not always align with clinically significant abnormalities, leading to unavoidable false positives and negatives. Additionally, our training dataset is biased toward chest CTs, resulting in more false positives in abdominal regions. Generalization to other anatomical regions requires training on corresponding datasets.

%We note that this work is largely a proof-of-concept for two hypotheses: (1) pathology segmentation in CT images can be approached as UVAS; (2) density estimation in dense self-supervised features' space yields meaningful anomaly scores. Of course, our unsupervised approach has its limitations: visual patterns abnormal in a \emph{statistical} sense do not always correspond to \emph{clinical} abnormalities, and vice versa, which leads to unavoidable false positive and false negative errors in terms of pathology segmentation.
%Another limitation concerns representativeness of the training sample. Our training dataset contains chest and abdominal CTs with much more chest samples. This causes more false positive errors in abdominal region. To work in other anatomical regions, our model needs to be trained on the corresponding images.

\paragraph{Future work.} While the performance gains compared to baselines are already significant, we note that further improvements might be achieved from increasing descriptors and conditions dimensionality and experiments with multi-scale representations (e.g. by building feature pyramids). Another possible avenue for future work is to study scaling laws, i.e. self-supervised models typically scale well with increasing pre-training dataset sizes. Distillation of Screener into UNet and subsequent supervised fine-tuning is also an interesting practical application of our work but needs further exploration.
