% !TEX root = ../main.tex

\section{Related work}
\label{sec:related_work}

\subsection{Visual unsupervised anomaly localization}

% In recent years the creation of the MVTec AD benchmark~\cite{mvtec} has given impetus to the development of new methods for visual unsupervised anomaly detection and localization. We review several main approaches which have representatives among top-5 methods on the localization track of the MVTec AD leaderboard
% The MVTec AD benchmark~\cite{mvtec}, developed in recent years, has been instrumental in propelling research towards new methods in visual unsupervised anomaly detection and localization.
In this section, we review several key approaches, each represented among the top five methods on the localization track of the MVTec AD benchmark~\cite{mvtec}, developed to stir progress in visual unsupervised anomaly detection and localization. 
% \footnote{\url{https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad}}.
% \paragraph{Synthetic anomalies} In unsupervised setting, real anomalies are either not present or not labeled in the training images. Some methods~\cite{memseg,mood_top1}, however, propose synthetic procedures that corrupt random regions in the images and train a segmentation model to predict the corrupted regions' masks.

\paragraph{Synthetic anomalies.} In unsupervised settings, real anomalies are typically absent or unlabeled in training images. To simulate anomalies, researchers synthetically corrupt random regions by replacing them with noise, random patterns from a special set~\cite{memseg}, or parts of other training images~\cite{mood_top1}. A segmentation model is trained to predict binary masks of corrupted regions, providing well-calibrated anomaly scores for individual pixels. While straightforward to train, these models may overfit to synthetic anomalies and struggle with real ones.
% . Unlabeled real anomalies in training images cannot be included in the binary masks, leading the model to predict zero scores for these regions and resulting in false negatives.

% One limitation of this approach is that the models may overfit to synthetic anomalies and generalize poorly to real anomalies. Another limitation is that training images may contain real anomalies which are unlabeled and cannot be included in the training binary masks. Thus, segmentation model is trained to predict zero scores for these regions which leads to false negatives.

% \paragraph{Reconstruction-based} Reconstruction-based methods build a generative model that takes an image $x$ as input and generates its normal (anomaly-free) version $\hat{x}$. Then anomaly scores are obtained as pixel-wise reconstruction errors between $x$ and $\hat{x}$. SotA methods from this family, e.g. DRAEM~\cite{draem}, DiffusionAD~\cite{diffusionad}, POUTA~\cite{pouta}, present a combination of reconstruction-based and synthetic-based approaches. First, they train a generative model to reconstruct synthetically corrupted image regions. Then, they train a segmentation model that takes a corrupted image and its reconstructed version as input and predicts the mask of the corrupted regions.

\paragraph{Reconstruction-based.} 
% In reconstruction-based methods, anomaly scores are obtained as reconstruction errors between the input image $x$ and generated normal (anomaly-free) counterpart $\hat{x}$.
% Reconstruction-based methods build a generative model that takes an image $x$ as input and generates its normal (anomaly-free) version $\hat{x}$. Then anomaly scores are obtained as reconstruction errors between $x$ and $\hat{x}$.
Trained solely on normal images, reconstruction-based approaches~\cite{autoencoder, vae, fanogan}, poorly reconstruct anomalous regions, allowing pixel-wise or feature-wise discrepancies to serve as anomaly scores. Later generative approaches~\cite{draem, diffusionad, pouta} integrate synthetic anomalies. The limitation stemming from anomaly-free train set assumption still persists -- if anomalous images are present, the model may learn to reconstruct anomalies as well as normal regions, undermining the ability to detect anomalies through differences between $x$ and $\hat{x}$.
% Early approaches, such as Autoencoders~\cite{autoencoder} and Variational Autoencoders~\cite{vae}, are trained solely on normal images. During inference, these models poorly reconstruct anomalous regions, allowing pixel-wise squared errors ${(x - \hat{x})^2}$ to serve as anomaly scores. Methods like f-AnoGAN~\cite{fanogan} enhance this by training W-GAN~\cite{wgan} $g$ to generate normal images and an encoder $f$ to map images to the GAN's latent space, ensuring ${\hat{x} = g(f(x)) \approx x}$. Anomalies are detected using a weighted average of reconstruction errors in pixel space and discrepancies in feature maps from GAN discriminator.

% State-of-the-art methods such as DRAEM~\cite{draem}, DiffusionAD~\cite{diffusionad}, and POUTA~\cite{pouta} integrate synthetic anomalies into the reconstruction process. They first train a generative model (autoencoder / diffusion model) to reconstruct synthetically corrupted regions. Then, they train a segmentation model that takes both the corrupted image and its reconstruction as input to predict masks of the corrupted regions.

% A major limitation of reconstruction-based methods is the assumption that the training set contains only normal images. If anomalous images are present, the generative model may learn to reconstruct anomalies as well as normal regions, undermining the ability to detect anomalies through differences between $x$ and $\hat{x}$.

% The earliest methods from this family are based on Autoencoder~\cite{autoencoder} or Variational Autoencoder~\cite{vae}, which are trained on anomaly-free images. At the inference stage, when it takes an image $x$ with anomalies it is intended to badly reconstruct the anomalous regions in $\hat{x}$, so that pixel-wise squared errors $(x - \hat{x})^2$ can be used as anomaly scores.

% Another method, f-AnoGAN~\cite{fanogan} at the first step trains W-GAN~\cite{wgan}, consisting of generator $g$ and discriminator $d$, to generate anomaly-free images $x \sim g(z)$ from latent variables $z \sim \mathcal{N}(0, I)$. Then, at the second step, it trains encoder $f$ to map anomaly-free images $x$ to the GAN's latent space, s.t. $\hat{x} = g(f(x)) \approx x$. At the inference stage, when $x$ is anomalous image, generator is assumed to generate its anomaly-free version $\hat{x}$, as it is trained only on normal images. Anomaly score are then obtained as a weighted average of reconstruction errors $(x - \hat{x})^2$ in pixel space and squared differences $(\varphi_d(x) - \varphi_d(x'))^2$ between feature maps $\varphi_d(x)$ and $\varphi_d(x')$ taken intermediate layers of GAN discriminator $d$.

% The SotA reconstruction-based methods, e.g. DRAEM~\cite{draem}, DiffusionAD~\cite{diffusionad}, POUTA~\cite{pouta}, present a combination with the approach based on synthetic anomalies. First, they train a generative model, e.g. autoencoder~\cite{draem,pouta} or diffusion model~\cite{diffusionad}, to reconstruct synthetically corrupted image regions. Then, they train a segmentation model that takes a corrupted image and its reconstructed version as input and predicts the mask of the corrupted regions.

% The main limitation of reconstruction-based methods is that they assume that training set does not contain anomalous images. Otherwise, generative model may learn to reconstruct anomalous regions as well as normal ones, which does not allow to detect anomalies by comparison of $x$ and $\hat{x}$.

\paragraph{Density-based.} Density-based methods for anomaly detection model the distribution of the training image patterns. As modeling of the joint distribution of raw pixel values is infeasible, these methods usually model the marginal or conditional distribution of pixel-wise deep feature vectors.

Some methods~\cite{ttr, pni} perform a non-parametric density estimation using memory banks. More scalable flow-based methods~\cite{fastflow,cflow,msflow}, leverage normalizing flows to assign low likelihoods to anomalies. From this family, we selected MSFlow as a representative baseline, because it is simpler than PNI, and yields similar top-5 results on the MVTec AD. 


\subsection{Medical unsupervised anomaly localization}
While there's no standard benchmark for pathology localization on CT images, MOOD~\cite{mood} offers a relevant benchmark with synthetic target anomalies. Unfortunately, at the time of preparing this work, the benchmark is closed for submissions, preventing us from evaluating our method on it. We include the top-performing method from MOOD~\cite{mood_top1} in our comparison, that relies on synthetic anomalies.

Other recognized methods for anomaly localization in medical images are reconstruction-based: variants of AE / VAE~\cite{autoencoder, dylov}, f-AnoGAN~\cite{fanogan}, and diffusion-based~\cite{latent_diffusion}. These approaches highly rely on the fact that the the training set consists of normal images only. However, it is challenging and costly to collect a large dataset of CT images of normal patients. While these methods work acceptable in the domain of 2D medical images and MRI, the capabilities of the methods have not been fully explored in a more complex CT data domain. We have adapted these methods to 3D.
