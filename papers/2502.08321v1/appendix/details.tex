\section{Other implementation details}
\label{appendix:details}

For our Screener model, we pre-process CT volumes by cropping them to dense foreground voxels (thresholded by $-500$HU), resizing to $1.5 \times 1.5 \times 2.25$ mm$^3$ voxel spacing, clipping intensities to $[-1000, 300]$HU and rescaling them to $[0, 1]$ range. As an important final step we apply CLAHE~\cite{clahe}. CLAHE ensures that color jitter augmentations preserve information about presence of pathologies during descriptor model training (otherwise, the quality of our method degrades largely).

We train both the descriptor model and the condition model for 300k batches of $m = 8$ pairs of overlapping patches with $N = 8192$ positive pairs of voxels. The training takes about $3$ days on a single NVIDIA RTX H100-80GB GPU. We use AdamW optimizer, warm-up learning rate from $0.0$ to $0.0003$ during first 10K batches, and then reduce it to zero till the end of the training. Weight decay is set to $10^{-6}$ and gradient clipping to $1.0$ norm. Patch size is set to $H \times W \times S = 96 \times 96 \times 64$.

During the density model training we apply average pooling operations with $3 \times 3 \times 2$ stride to feature maps produced by the descriptor model as well as the condition model, following~\cite{cflow,msflow}. Thus $h \times w \times s = 32 \times 32 \times 32$. We inject gaussian noise with $0.1$ standard deviation both to the descriptors and to the conditions in order to stabilize the training. We train the density model for 500k batches each containing $m = 4$ patches. This training stage again takes about $3$ days on a single NVIDIA RTX H100-80GB GPU. We use the same optimizer and the learning rate scheduler as for the descriptor and condition models.