\section{Related Work}
Recent advances in embedding models have shown remarkable success in general domain tasks, yet their effectiveness in specialized domains remains a critical challenge. 
% In this section, we first review the development of embedding models and existing evaluation frameworks, then discuss current approaches to domain specialization, ultimately highlighting the pressing need for comprehensive domain-specific embedding evaluation.

\subsection{General-purpose Embedding Models}
The evolution of embedding models marks significant progress in natural language processing. Starting with static word representations like Word2Vec ____ and GloVe ____, the field advanced to contextualized embeddings through transformer-based architectures such as BERT ____ and RoBERTa ____. A notable advancement came with Sentence-BERT ____, which introduced Siamese and triplet network architectures to generate meaningful sentence-level representations. Recent developments in large language models have further pushed the boundaries, with models such as e5-mistral-7b-instruct ____ and gte-Qwen2-1.5B-instruct ____ achieving better performance in various embedding tasks. However, these general-purpose models may not adequately capture the nuanced semantics of specialized domains.

\subsection{Current Embedding Evaluation Landscape}
To assess embedding quality, several evaluation frameworks have been developed. General-purpose embedding benchmarks, such as the Massive Text Embedding Benchmark (MTEB) ____, provide broad coverage across multiple tasks and languages. Specialized benchmarks like BEIR ____ focus on specific aspects, such as information retrieval. Although they incorporate some domain-specific datasets, such as FiQA ____, the size of the data and the coverage of the task are limited. 
% Recent frameworks ____ concentrate on particular use cases such as retrieval-augmented generation. Although these benchmarks offer valuable insights, they mainly focus on general domain performance or specific retrieval tasks, leaving a significant gap in comprehensive finance domain-specific embedding evaluation. 


\subsection{Domain Adaptation Approaches}
Recognizing the limitations of general-purpose models in specialized domains, researchers have pursued two main adaptation strategies. The first approach develops domain-specific models from scratch, exemplified by BioMedLM ____ for biomedicine, SaulLM-7B ____ for legal texts, and BloombergGPT ____ for finance. The second strategy fine-tunes existing models for domain-specific tasks, as demonstrated by InvestLM ____ and FinGPT ____. This trend extends to embedding models, with specialized versions such as BioWordVec ____, BioSentVec ____, and FinBERT ____ showing superior domain-specific performance. However, evaluating these specialized embedding models remains challenging due to the lack of comprehensive domain-specific benchmarks.


\subsection{The Gap in Domain-specific Evaluation}
While domain-specific language models have stimulated the development of specialized evaluation frameworks across various fields, these benchmarks primarily emphasize generative and reasoning capabilities instead of embedding quality. The financial sector has seen the emergence of frameworks like CFLUE ____, FinEval ____, and FinanceBench ____, whereas the legal and medical domains have introduced LawBench ____, MedBench ____, and DrBenchmark ____. These benchmarks consistently illustrate that general-purpose models often fall short in specialized areas ____, highlighting the necessity of domain adaptation ____. Despite this acknowledgment, there is still a critical lack of comprehensive evaluation frameworks for domain-specific embeddings that assess performance across essential tasks such as semantic similarity, classification, and retrieval. Even recent financial embedding developments, such as BAM embedding____, rely on narrow evaluation frameworks, typically focusing on single-task performance metrics (e.g., FinanceBench____ for retrieval tasks). 
This limited evaluation may not fully reflect how the models perform in real-world financial applications.



% \subsection{General-purpose Embedding Models}
% Embedding models have evolved significantly from early word-level approaches like Word2Vec ____ and GloVe ____ to transformer-based models such as BERT ____ and RoBERTa ____. These later models enabled contextualized word embeddings through deep bidirectional encoders. Sentence-BERT ____ further advanced the field by introducing Siamese and triplet networks for generating semantically meaningful sentence embeddings. Recent developments in LLMs have led to more powerful embedding models, such as e5-mistral-7b-instruct ____ and gte-Qwen2-1.5B-instruct ____, achieving state-of-the-art performance across various NLP tasks.


% \subsection{Embedding Evaluation Benchmarks}
% Current embedding evaluation frameworks can be categorized into general-purpose and specialized benchmarks, each with distinct strengths and limitations. The Massive Text Embedding Benchmark (MTEB) ____ represents a comprehensive general-purpose framework, evaluating models across multiple tasks and languages to assess their broad applicability and performance. In the specialized category, the BEIR benchmark ____ focuses specifically on information retrieval tasks, incorporating 18 diverse datasets. While BEIR includes some domain-specific collections, such as the financial QA dataset FiQA ____, its coverage of specialized domains remains limited. This limitation becomes particularly apparent when evaluating models intended for specific professional or technical fields, where specialized vocabulary and context play crucial roles. More recent developments include scenario-specific benchmarks like RAGeval ____, which addresses the particular needs of retrieval-augmented generation systems. While these specialized benchmarks effectively evaluate retrieval performance in specific contexts, they often have a narrow focus. Important aspects of embedding quality, such as semantic similarity assessment and classification capabilities, are frequently overlooked.


% \subsection{Domain-Specific Models} 
% The adaptation of language models to specific domains typically follows two main strategies. The first approach involves training dedicated models from scratch on domain-specific corpora. Notable examples include BioMedLM ____ for biomedical literature, SaulLM-7B ____ for legal texts, and BloombergGPT ____ for financial content. These models benefit from deep exposure to domain-specific patterns and terminology during the pre-training phase. The second strategy focuses on fine-tuning existing models for specialized tasks within a domain. In the financial sector, for example, models like InvestLM ____ and FinGPT ____ have been instruction-tuned to perform specific financial analysis tasks. This approach leverages the general language understanding capabilities of base models while adapting them to domain-specific applications. Similar specialization trends are evident in embedding models, where domain-specific versions have been developed to better represent specialized vocabulary and concepts. For example, BioWordVec ____ and BioSentVec ____ provide specialized embeddings for biomedical terminology, while FinBERT ____ offers targeted representations for financial language. These specialized embedding models demonstrate superior performance in their respective domains compared to general-purpose alternatives.


% \subsection{Domain-specific Model Benchmarks}
% The rise of domain-specific large language models (LLMs) has sparked the creation of specialized benchmarks across different professional areas.  These benchmarks serve a crucial role in evaluating how well LLMs can handle domain-specific knowledge and tasks. In the financial sector, several comprehensive benchmarks have emerged. CFLUE ____ and FinEval ____ assess financial language understanding, while DocMath-Eval ____ focuses on mathematical reasoning in financial documents. FinanceBench ____ provides a broader evaluation framework for financial applications. Similar developments can be observed in other specialized fields. The legal domain has LawBench ____, which evaluates legal reasoning and comprehension across multiple jurisdictions. In healthcare, MedBench ____, MedEval ____, and DrBenchmark ____ have been established to assess medical knowledge understanding and clinical reasoning capabilities. Most of these benchmarking papers conclude that general-purpose LLMs may fall short on domain tasks ____. The importance of domain adaptation has gradually gained attention ____. However, to our knowledge, there is little work benchmarking the embedding model's performance on domain texts across different tasks.