@inproceedings{Bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

@article{CFLUE,
  title={Benchmarking Large Language Models on CFLUE--A Chinese Financial Language Understanding Evaluation Dataset},
  author={Zhu, Jie and Li, Junhui and Wen, Yalong and Guo, Lifan},
  journal={arXiv preprint arXiv:2405.10542},
  year={2024}
}

@inproceedings{DocMath-Eval,
  title={DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents},
  author={Zhao, Yilun and Long, Yitao and Liu, Hongjun and Kamoi, Ryo and Nan, Linyong and Chen, Lyuhao and Liu, Yixin and Tang, Xiangru and Zhang, Rui and Cohan, Arman},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={16103--16120},
  year={2024}
}

@misc{FiQA,
      title={Financial question answering.}, 
      author={FiQA},
      year = "2018",
      note  = {\url{https://sites.google.com/view/fiqa}}
}

@inproceedings{anderson-etal-2024-finance_text_embedding,
    title = "Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt",
    author = "Anderson, Peter  and
      Janardhanan, Mano Vikash  and
      He, Jason  and
      Cheng, Wei  and
      Flanagan, Charlie",
    editor = "Dernoncourt, Franck  and
      Preo{\c{t}}iuc-Pietro, Daniel  and
      Shimorina, Anastasia",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track",
    month = nov,
    year = "2024",
    address = "Miami, Florida, US",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-industry.26/",
    doi = "10.18653/v1/2024.emnlp-industry.26",
    pages = "362--370",
}

@article{biomedlm,
  title={Biomedlm: A 2.7 b parameter language model trained on biomedical text},
  author={Bolton, Elliot and Venigalla, Abhinav and Yasunaga, Michihiro and Hall, David and Xiong, Betty and Lee, Tony and Daneshjou, Roxana and Frankle, Jonathan and Liang, Percy and Carbin, Michael and others},
  journal={arXiv preprint arXiv:2403.18421},
  year={2024}
}

@inproceedings{biosentvec,
  title={BioSentVec: creating sentence embeddings for biomedical texts},
  author={Chen, Qingyu and Peng, Yifan and Lu, Zhiyong},
  booktitle={2019 IEEE International Conference on Healthcare Informatics (ICHI)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}

@article{biowordvec,
  title={BioWordVec, improving biomedical word embeddings with subword information and MeSH},
  author={Zhang, Yijia and Chen, Qingyu and Yang, Zhihao and Lin, Hongfei and Lu, Zhiyong},
  journal={Scientific data},
  volume={6},
  number={1},
  pages={52},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{bloomberggpt,
  title={Bloomberggpt: A large language model for finance},
  author={Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
  journal={arXiv preprint arXiv:2303.17564},
  year={2023}
}

@article{domainiskey,
  title={Domain specialization as the key to make large language models disruptive: A comprehensive survey},
  author={Ling, Chen and Zhao, Xujiang and Lu, Jiaying and Deng, Chengyuan and Zheng, Can and Wang, Junxiang and Chowdhury, Tanmoy and Li, Yun and Cui, Hejie and Zhang, Xuchao and others},
  journal={arXiv preprint arXiv:2305.18703},
  year={2023}
}

@article{drbenchmark,
  title={DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain},
  author={Labrak, Yanis and Bazoge, Adrien and Khettari, Oumaima El and Rouvier, Micka{\"e}l and Grabar, Natalia and Daille, Beatrice and Quiniou, Solen and Morin, Emmanuel and Gourraud, Pierre-Antoine and Dufour, Richard and others},
  journal={arXiv preprint arXiv:2402.13432},
  year={2024}
}

@article{e5,
  title={Improving Text Embeddings with Large Language Models},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2401.00368},
  year={2023}
}

@article{financebench,
  title={Financebench: A new benchmark for financial question answering},
  author={Islam, Pranab and Kannappan, Anand and Kiela, Douwe and Qian, Rebecca and Scherrer, Nino and Vidgen, Bertie},
  journal={arXiv preprint arXiv:2311.11944},
  year={2023}
}

@article{finbert,
  title={Finbert: A pretrained language model for financial communications},
  author={Yang, Yi and Uy, Mark Christopher Siy and Huang, Allen},
  journal={arXiv preprint arXiv:2006.08097},
  year={2020}
}

@article{fineval,
  title={Fineval: A chinese financial domain knowledge evaluation benchmark for large language models},
  author={Zhang, Liwen and Cai, Weige and Liu, Zhaowei and Yang, Zhi and Dai, Wei and Liao, Yujie and Qin, Qianru and Li, Yifei and Liu, Xingyu and Liu, Zhiqiang and others},
  journal={arXiv preprint arXiv:2308.09975},
  year={2023}
}

@article{fingpt,
  title={Fingpt: Open-source financial large language models},
  author={Yang, Hongyang and Liu, Xiao-Yang and Wang, Christina Dan},
  journal={arXiv preprint arXiv:2306.06031},
  year={2023}
}

@article{investlm,
  title={Investlm: A large language model for investment using financial domain instruction tuning},
  author={Yang, Yi and Tang, Yixuan and Tam, Kar Yan},
  journal={arXiv preprint arXiv:2309.13064},
  year={2023}
}

@article{lawbench,
  title={LawBench: Benchmarking Legal Knowledge of Large Language Models},
  author={Fei, Zhiwei and Shen, Xiaoyu and Zhu, Dawei and Zhou, Fengzhe and Han, Zhuo and Zhang, Songyang and Chen, Kai and Shen, Zongwen and Ge, Jidong},
  journal={arXiv preprint arXiv:2309.16289},
  year={2023}
}

@article{medbench,
  title={MedBench: A Comprehensive, Standardized, and Reliable Benchmarking System for Evaluating Chinese Medical Large Language Models},
  author={Liu, Mianxin and Ding, Jinru and Xu, Jie and Hu, Weiguo and Li, Xiaoyang and Zhu, Lifeng and Bai, Zhian and Shi, Xiaoming and Wang, Benyou and Song, Haitao and others},
  journal={arXiv preprint arXiv:2407.10990},
  year={2024}
}

@inproceedings{medeval,
    title = "{M}ed{E}val: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation",
    author = "He, Zexue  and
      Wang, Yu  and
      Yan, An  and
      Liu, Yao  and
      Chang, Eric  and
      Gentili, Amilcare  and
      McAuley, Julian  and
      Hsu, Chun-Nan",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2023.emnlp-main.540",
    pages = "8725--8744",
}

@article{mteb,
  title={MTEB: Massive text embedding benchmark},
  author={Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"\i}c and Reimers, Nils},
  journal={arXiv preprint arXiv:2210.07316},
  year={2022}
}

@inproceedings{pennington-etal-2014-glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@article{qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article{rageval,
  title={RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework},
  author={Zhu, Kunlun and Luo, Yifan and Xu, Dingling and Wang, Ruobing and Yu, Shi and Wang, Shuo and Yan, Yukun and Liu, Zhenghao and Han, Xu and Liu, Zhiyuan and others},
  journal={arXiv preprint arXiv:2408.01262},
  year={2024}
}

@article{roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{saullm,
  title={Saullm-7b: A pioneering large language model for law},
  author={Colombo, Pierre and Pires, Telmo Pessoa and Boudiaf, Malik and Culver, Dominic and Melo, Rui and Corro, Caio and Martins, Andre FT and Esposito, Fabrizio and Raposo, Vera L{\'u}cia and Morgado, Sofia and others},
  journal={arXiv preprint arXiv:2403.03883},
  year={2024}
}

@inproceedings{sentence-bert,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}

@article{word2vector,
    title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint arXiv:1301.3781},
}

