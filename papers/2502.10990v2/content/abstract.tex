Embedding models play a crucial role in representing and retrieving information across various NLP applications. Recent advancements in Large Language Models (LLMs) have further enhanced the performance of embedding models. While these models are often benchmarked on general-purpose datasets, real-world applications demand domain-specific evaluation. In this work, we introduce the \textbf{Fin}ance \textbf{M}assive \textbf{T}ext \textbf{E}mbedding \textbf{B}enchmark (FinMTEB), a specialized counterpart to MTEB designed for the financial domain. FinMTEB comprises 64 financial domain-specific text datasets across 7 tasks that cover diverse textual types in both Chinese and English, including financial news articles, corporate annual reports, ESG reports, regulatory filings, earnings call transcripts, among others. Through comprehensive evaluation of state-of-the-art embedding models on FinMTEB and our newly developed finance-adapted model FinE5, we observe several interesting findings: (1) performance on general-purpose benchmarks does not necessarily translate to domain-specific tasks, (2) domain-adapted models consistently achieve better performance than their general-purpose counterparts, and (3) the competitive performance of BOW in financial STS tasks indicates current limitations of dense embeddings. This study provides valuable insights for developing domain-specific embedding models and establishes a robust evaluation framework for financial NLP applications.
