\section{The case against specialisation}
\label{sec:against}


Before making our case for specialisation, let us highlight the most common arguments against specialisation, and discuss why they feel ill-fit to today's AI systems.

\subsection{The case of humans}

\paragraph{Overspecialisation harms workers' mental health and flourishing.}

Although some arguments may have been anterior, the most severe criticisms of the division of labor opposed Taylorism, assembly line work, and what came to be known as Scientific Management\cite{bookwalter1918scientific}. This work organisation generated an extreme division of labour with a fragmentation of tasks, a sustained pace of execution, a high degree of dependence between workers, and the impossibility of envisaging the unexpected events. Criticisms from the social sciences of work were to emerge in the middle of the twentieth century and the rise of increasing industrialisation (particularly in the automobile sector) and mechanisation. Friedmann \cite{friedmann1955travail, friedman1961anatomy} talks of ``work in crumbs''\footnote{Better captured by the original French expression ``Travail en miettes''.}” to describe the evolution of forms of work with a high level of automation, and in particular the work in the factories. There have also been concerned with the psychological damage caused to workers by alienating, unskilled, and depersonalized work.

Today, criticisms of the excessive division of labor and hyper-specialisation concern many economic sectors (food industry, logistics, textile industry, etc.). They particularly focus on the aspects that are detrimental to the body and mind of individuals. One of these industries is precisely the information and communications technology industry, and particularly digital platforms (on-demand platforms, social media), and more generally artificial intelligence using digital labor, micro-work and data workers, especially in the global south countries~\cite{casilli2020virtual, williams2022exploited}. 


\paragraph{Overspecialisation leads to a loss of meaning/purpose.}

High specialisation can cause workers to lose interest and motivation in their work, and can impact performance \cite{loukidou2009boredom}. A high level of specialisation tends to lower workers’ stimulation and motivation levels, while increasing their boredom and disengagement \cite{hackman1969nature, mccauley1994assessing}. 

However, while the psychological and physical damages on human workers are important to consider, algorithms are arguably not subject to such concerns. At least following~\cite{gibert2022search}, while they could be regarded as \emph{moral agents} (i.e. they have moral duties), they should not be regarded as \emph{moral patients} (i.e. there is no moral duty to protect them). Therefore, the above arguments do not seem to apply to non-human agents.


\subsection{Arguments from economics}

In economics, instead of specialising in a given step of the production chain, 
companies may be tempted to invest in \emph{vertical integration}~\cite{coase1937,bresnahan2012vertical}. 
Namely, they could want to own their entire supply and delivery chain. 
The theoretical analysis of \cite{arrow1975vertical} indeed found that imperfect information can incentivize such vertical integration, 
while that of \cite{carlton1979vertical} instead stresses the role of transaction costs.
\cite{grossman1986costs} further underlined contractualisation costs:
if specifying the conditions of an agreement between a supplier and a producer is challenging,
then there will be strong incentives for vertical integration.
The theories of \cite{arrow1975vertical} and \cite{carlton1979vertical} have both found support,
e.g. by \cite{lieberman1991determinants} in the chemical industry.
On top of this, \cite{fetz2010economies} empirically observed
better investment coordination and less financial risk 
following the vertical integration of the Swiss electricity sector.
In practice, varying working conditions may instead incentivize outsourcing,
and thus vertical disintegration~\cite{ricardo1817,kakabadse2005outsourcing}.

In the software industry, 
yet another phenomenon may incentivize both vertical and lateral integration,
namely the \emph{network effect} \cite{shapiro1999information}.
This describes situations where the value of a product is increased by the wide use of this product,
or of similar related products.
A classical instance of this is Facebook's huge investments in social media.
For instance, by acquiring Instagram and by connecting it with their other platforms,
Facebook has exploited the network effect to increase the value of their anterior assets~\cite{li2017platform}.
Similarly, Google and Apple now produce both hardware, operating systems and applications,
thereby offering a unifying solution to their customers.
The value of the hardware is then augmented by a corresponding optimized optimized system,
which is itself augmented by its connection to a dedicated cloud system \cite{vergara2012samsung}.
Further, software companies have incentives to invest in lateral integration,
to propose all-in-one highly connected digital workspaces,
as is the case for instance of the Microsoft 365 product.
This further helped them push AI-based solutions, such as Microsoft co-pilot \cite{skendzic2012microsoft}.

However, while there may be some positive consequences for some users,
critics point out that such integrations incur societal risks, 
especially in terms of market power \cite{landes1997market}.
In particular, the technology sector has been repeatedly criticized
for its dependence on a small number of actors,
as exemplified by the landmark antitrust case against Microsoft~\cite{economides2001microsoft},
and by the numerous recent calls to enforce antitrust laws
to other actors~\cite{munir2024google,davies2024google,worsdorfer2024apple}.

Additionally, integration can increase systemic risks. 
This is well illustrated by the report of the Cybersecurity and Infrastructure Security Agency on the 2023 Microsoft Online Exchange Incident \cite{cisa}. 
The penetration of Microsoft's cloud infrastructure by foreign actors has not only compromised the targeted US institutions; it may also be endangering \emph{all} of Microsoft's customers. 
Moreover, the high connectivity of all of Microsoft's cloud services means that a given customer may be compromised, even if they only use some of these services.

Having said this, at the scale of a country,
especially in a context of tensed geopolitical tension,
vertical integration could in fact be a consideration of national security. 
More generally, it could be in a given system's best interest to seek generality, if they want autonomy and resilience.
However, it may not be other others' best interest to depend on a general system.
In any case, we recall that our case \emph{for} specialisation is focused on \emph{external uses} of a system.


\subsection{Arguments from statistics}

In artificial intelligence, 
much of the recent interest for general AIs derives 
from the observed ``scaling laws"~\cite{kaplan2020scaling},
which argue that learning from all sorts of (non-specialised) data 
is the driving force of dramatic performances.
While these observations have been criticized~\cite{diaz2024scaling},
they do have some theoretical backgrounds.

In particular, they may be argued to be 
an instance of Stein's paradox~\cite{efron1977stein}.
Strikingly, this paradox shows that, 
when performing statistical learning on three or more disjoint subsets of data, 
it is statistically \emph{inadmissible} to learn separately on each subset.
More precisely, for each subset, 
consider any (specialised) estimator of a ground truth statistics of the subset.
Then there is a (general) estimator that learns from the union of all subsets such that,
no matter what the ground truth is,
the general estimator's expected mean square error will be lower than the specialised estimators'.
Moreover, for at least one value of the ground truth, it is strictly lower.
The general estimator is said to strictly dominate the specialised estimators.

This is especially evident in the case of collaborative filtering~\cite{ekstrand2011collaborative}.
To better optimize what content should be recommended to a given user,
it is extremely useful to leverage the preferences of similar users,
rather than to learn exclusively from the given user's data.

While this statistical argument is very compelling,
it is important to highlight two key weaknesses.
First, it is a statistical, and thus \emph{information-theoretical}, argument.
It thus neglects the computational costs.
In particular, the general estimator may require significantly more resources than the specialised estimators.
And while we use a very computer-science terminology,
this remark holds for both algorithms and human organisations.
One striking example is that of science:
scientists have self-organised themselves in specialised communities.

But more importantly, the subsets of data have thus far been assumed to safe to learn from.
However, in practice, most datasets raise privacy and poisoning issues.
On one hand, general estimator can more easily cross information 
that would allow for user de-anonymisation,
even if ``privacy-preserving learning" solutions like differential privacy are used \cite{DBLP:conf/sigmod/KiferM11,DBLP:journals/tifs/ZhuXLZ15}.
On the other hand, malicious users can more easily poison the union of all subsets,
thereby biasing or harming the general estimator~\cite{DBLP:conf/icml/BiggioNL12,DBLP:conf/icml/SuyaMS0021,DBLP:conf/icml/FarhadkhaniGHV22}.
In particular, the introduction of collaborative filtering has given fake accounts
an enormous influence on the daily information exposure of billions of humans.
