\section{Related Work}
\paragraph{The secretary problem and its variants.} 
The classical secretary problem is often attributed to____, though the exact origin of the problem is obscure____; different versions of the problem were studied in the contemporary work of____. 

The natural extension of selecting up to $k$ elements (i.e., the $k$-secretary problem) were studied by____ under various objectives (e.g., the probability of selecting the $k$ largest elements exactly, or the largest element being among the chosen ones). We followed the formulation of____ in terms of the competitive ratio. ____ showed that the optimal competitive ratio is $1 - \Theta(1/\sqrt{k})$ as $k \to \infty$. ____ subsequently gave $1/e$-competitive algorithms for all $k \ge 1$, improving the result of____ in the small-$k$ regime. A more recent work of____ also focused on the non-asymptotic regime, and gave a deterministic algorithm with a competitive ratio $> 1/e$ for all $k \ge 2$.

A further extension of the $k$-secretary problem considers selecting multiple elements subject to a more general combinatorial constraint. ____ studied the knapsack secretary problem. ____ introduced the \emph{matroid secretary problem}, in which the player is asked to select elements that form an independent set of a given matroid. This problem has been extensively studied____, and it remains a long-standing open problem whether an $O(1)$-competitive algorithm exists in general. Other variants of the secretary problem consider alternative models for how the player accesses the elements and makes decisions, including models of interview costs____, shortlists____, reservation costs____, and a ``pen testing'' variant____.

\paragraph{Quantile estimation.} For the quantile estimation problem in random-order streams, ____ gave an exact selection algorithm for the $k = \lfloor n/2\rfloor$ case (i.e., finding the median) with $O(\sqrt{n})$ memory, and proved a matching $\Omega(\sqrt{n})$ memory lower bound. Our \Cref{thm:quantile-exact} generalizes their result to general values of $k$, and their lower bound implies that the $O(\sqrt{k})$ memory usage cannot be improved in general (specifically, in the $n = 2k$ case).

For approximate selection, ____  proposed an algorithm that uses $O(1)$ words of memory and finds the $k$-th largest element up to an error of $O(\sqrt{k}\log^2 n\cdot\log(1/\delta))$ with probability $1 - \delta$. In comparison, \Cref{thm:quantile-approx} bounds the expected error and avoids the extra $\polylog(n)$ factor, both of which are crucial for the optimality of the resulting $k$-secretary algorithm. A subsequent work of____ solved median estimation with an $n^{1/3 + o(1)}$ error using $O(1)$ words of memory. In comparison, \Cref{thm:quantile-approx} applies to all values of $k$ and makes the error dependent only on $k$ and not $n$, at the cost of a larger exponent of $1/2$ and a logarithmic memory usage. We note that, even if we could improve the error to $O(k^{1/3})$, the reduction from $k$-secretary still introduces an $\Omega(\sqrt{k})$ error, which would dominate the quantile estimation error.

While we focus on the random-order setup of quantile estimation, many prior work also addressed the more challenging setup in which elements arrive in an arbitrary order____. The multi-pass setting, in which the algorithm may scan the stream multiple times, were also considered____.

\paragraph{Learning and decision making under memory constraints.} More broadly, our work is part of the endeavor to understand the role of memory in learning, prediction, and decision-making. Prior work along this line studied the memory bounds for parity learning in a streaming setting____, for the experts problem in online learning____, as well as the fundamental problem of linear regression____.