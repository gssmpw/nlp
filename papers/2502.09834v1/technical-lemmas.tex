\section{Technical Lemmas}\label{sec:technical-lemmas}
\lemmasubsample*

\begin{proof}[Proof of \Cref{lemma:subsample}]
    It suffices to show that, for every subset $S' \subseteq S$, $\{s_1, s_2, \ldots, s_B\} = S'$ holds with probability exactly $p^{m}(1-p)^{n-m}$, where $m = |S'|$.

    For $\{s_1, s_2, \ldots, s_B\}$ to be equal to $S'$, the following two conditions must hold: (1) $B = m$ is sampled from $\Binomial(n, p)$; (2) The first $m$ elements of the stream constitute the set $S'$. The former happens with probability $p^{m}(1-p)^{n-m} \cdot \binom{n}{m}$. Since $s$ and $B$ are independent, conditioning on $B = m$, $s_1, s_2, \ldots, s_n$ is still uniformly distributed among all permutations. In particular, $\{s_1, s_2, \ldots, s_m\}$ is uniformly distributed among all size-$m$ subsets of $S$. Therefore, the latter condition holds with probability $1 / \binom{n}{m}$. Therefore, the overall probability is given by
    \[
        \left[p^{m}(1-p)^{n-m} \cdot \binom{n}{m}\right] \cdot\frac{1}{\binom{n}{m}} = p^{m}(1-p)^{n-m}.
    \]
\end{proof}

\subsetrankconcentration*

The proof of \Cref{lemma:subset-rank-concentration} is based on the following lemma, which relates sampling without replacement to sampling with replacement.
\begin{lemma}[\cite{bardenet2015concentration}]\label{lemma.cite}
    Let $\mathcal{X} = (x_1, \ldots,  x_N)$ be a finite population of $N$ real points, $X_1, \ldots , X_n$ denote a random sample without replacement from $\mathcal{X}$ and $Y_1, \ldots , Y_n$ denote a random sample with replacement from $\mathcal{X}$. If $f : \mathbbm{R} \rightarrow \mathbbm{R}$ is continuous and convex, then
    \[
        \Ex{}{f\left(\sum_{i=1}^n X_i\right)}
    \le \Ex{}{f\left(\sum_{i=1}^n Y_i\right)}.
    \]
\end{lemma}
 
\begin{proof}[Proof of \Cref{lemma:subset-rank-concentration}]
Define binary random variables $X_1, X_2, \ldots, X_n$ such that $X_j = 1$ if  element $j \in [n]$ is included in the size-$k$ subset, and $X_j = 0$ otherwise. Then, $X_1$ through $X_n$ can be viewed as being sampled from the size-$n$ population
\[
    \mathcal{X} = (\underbrace{0, 0, \ldots, 0}_{n-k\text{ copies}}, \underbrace{1, 1, \ldots, 1}_{k\text{ copies}})
\]
without replacement. Towards applying \Cref{lemma.cite}, we consider random variables $Y_1, Y_2, \ldots, Y_n$ that are sampled from $\mathcal{X}$ \emph{with} replacement. Equivalently, $Y_1$ through $Y_n$ are independently sampled from $\Bern(k/n)$. Since the function $x \mapsto \exp(tx)$ is convex for any $t \in \mathbb{R}$, \Cref{lemma.cite} implies that, for any $n' \in [n]$,
\begin{equation}\label{eq:without-to-with-replacement}
    \Ex{X}{\exp\left(t\cdot \sum_{j=1}^{n'}X_j\right)}
\le \Ex{Y}{\exp\left(t\cdot \sum_{j=1}^{n'}Y_j\right)}.
\end{equation}

In the rest of the proof, we first control the tail probabilities of $x - i\cdot \frac{n}{k}$ on both sides. We then get an upper bound on the expectation via integration.

\paragraph{Control the left-tail.} Fix $m \ge 0$. Recall that $x$ denotes the $i$-th smallest element in the random size-$k$ subset. Our goal is to upper bound the tail probability $\pr{}{x \le i \cdot \frac{n}{k} - m\cdot\sqrt{i \cdot \frac{n}{k}}}$. When $i \cdot \frac{n}{k} - m\cdot\sqrt{i \cdot \frac{n}{k}} < 1$, this probability is trivially $0$. Otherwise, we note that, for $x \le j$ to hold, we must have $\sum_{r = 1}^j X_r \ge i$. Applying this observation to $j = \left\lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right\rfloor$ gives
\begin{align*}
        \pr{}{x \le i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}}
    &=  \pr{}{x \le \left\lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right\rfloor}\\
    &\le\pr{X}{\sum_{r=1}^{\left \lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right\rfloor } X_r \ge i}
    =   \inf_{t > 0}\pr{X}{e^{t\sum_{r=1}^{\left \lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rfloor }X_r} \ge e^{ti}}\\
    &\le\inf_{t>0}\frac{\Ex{X}{e^{t\sum_{r=1}^{\left \lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rfloor }X_r}}}{e^{ti}} \tag{Markov's inequality} \\
    &\le\inf_{t>0}\frac{\Ex{Y}{e^{t\sum_{r=1}^{\left \lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rfloor }Y_r}}}{e^{ti}} \tag{\Cref{eq:without-to-with-replacement}}\\
    &=  \inf_{t>0}\frac{\Pi_{r=1}^{\left \lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}} \right \rfloor }\Ex{Y_r}{e^{t \cdot Y_r}}}{e^{ti}},
\end{align*}
where the last step holds since $Y_1, Y_2, \ldots$ are independent.

Recall that each $Y_r$ follows $\Bern(k/n)$. By Hoeffding's lemma, we have $\Ex{Y_r}{e^{t\cdot \left(Y_r - \frac{k}{n}\right)}} \le e^{t^2/8}$, which further implies
\[
    \Ex{Y_r}{e^{t\cdot Y_r}} \le \exp\left(\frac{t^2}{8} + t\cdot \frac{k}{n}\right).
\]
Plugging the above into the tail bound gives
\begin{align*}
    \pr{}{x \le i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}}
    &\le\inf_{t>0}\exp\left(\left(\frac{t^2}{8} + t\cdot \frac{k}{n}\right)\cdot \left\lfloor i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right\rfloor - ti\right)\\
    &\le\inf_{t>0}\exp\left(\left(\frac{t^2}{8} + t\cdot \frac{k}{n}\right)\cdot \left( i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}\right) - ti\right)\\
    &=  \inf_{t > 0}\exp\left(\frac{t^2}{8}\cdot\left(i\cdot\frac{n}{k} - m\cdot\sqrt{i \cdot \frac{n}{k}}\right) - t\cdot m\cdot\sqrt{i\cdot \frac{k}{n}}\right)\\
    &=  \exp\left(-\frac{2m^2 \cdot i\cdot \frac{k}{n}}{i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}}\right)\\
    &\le\exp\left(-\frac{2m^2 \cdot i\cdot \frac{k}{n}}{i\cdot \frac{n}{k}}\right)
    =   \exp\left(-2m^2\cdot \frac{k^2}{n^2}\right), \tag{$m \ge 0$}
\end{align*}
where the fourth step applies $\inf_{t > 0}(at^2 - bt) = -\frac{b^2}{4a}$ for $a, b > 0$.

We conclude that, for all $m \ge 0$,
\begin{equation}\label{eq:left-tail-bound}
    \pr{}{x \le i\cdot \frac{n}{k} - m\cdot \sqrt{i\cdot \frac{n}{k}}}
\le \exp\left(-2m^2\cdot \frac{k^2}{n^2}\right).
\end{equation}

\paragraph{Control the right-tail.} Similarly, we fix $m \ge 0$. If $i\cdot\frac{n}{k} + m\cdot\sqrt{i \cdot\frac{n}{k}} > n$, the tail probability $\pr{}{x \ge i\cdot\frac{n}{k} + m\cdot\sqrt{i \cdot\frac{n}{k}}}$ is trivially $0$. Otherwise, note that, for the $i$-th smallest element in the size-$k$ subset (namely, $x$) to be larger than or equal to $j$, we must have $\sum_{r = 1}^j X_r \le i$. This gives
\begin{align*}
    \pr{}{x \ge i\cdot\frac{n}{k} + m\cdot\sqrt{i \cdot\frac{n}{k}}}
&=  \pr{}{x \ge \left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right\rceil}\\
&\le\pr{X}{\sum_{r=1}^{\left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rceil } X_r \le i}
=   \inf_{t > 0}\pr{X}{e^{-t\cdot \sum_{r=1}^{\left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rceil }X_r} \ge e^{-ti}}\\
&\le\inf_{t>0}\frac{\Ex{X}{e^{-t\sum_{r=1}^{\left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}} \right \rceil}X_r}}}{e^{-ti}} \tag{Markov's inequality}\\
&\le\inf_{t>0}\frac{\Ex{Y}{e^{-t\sum_{r=1}^{\left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rceil }Y_r}}}{e^{-ti}} \tag{\Cref{eq:without-to-with-replacement}}\\
&=  \inf_{t>0}\frac{\Ex{Y}{\Pi_{r=1}^{\left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rceil } e^{-t \cdot Y_r}}}{e^{-ti}}\\
&=  \inf_{t>0}\frac{\Pi_{r=1}^{\left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right \rceil }\Ex{Y_r}{e^{-t \cdot Y_r}}}{e^{-ti}},
\end{align*}
where the last step follows from the independence among $Y_1, Y_2, \ldots, Y_n$.

Again, recall that each $Y_r$ follows $\Bern(k/n)$, so Hoeffding's lemma gives $\Ex{Y_r}{[e^{-t\cdot \left(Y_r - \frac{k}{n}\right)}} \le e^{t^2/8}$. Thus,
\[
    \Ex{Y_r}{e^{-t\cdot Y_r}} \le \exp\left(\frac{t^2}{8} - t\cdot \frac{k}{n}\right).
\]
Plugging the above into the upper bound on the right-tail gives
\[
    \pr{}{x \ge i\cdot\frac{n}{k} + m\cdot\sqrt{i \cdot\frac{n}{k}}}
\le \inf_{t>0}\exp\left(\left(\frac{t^2}{8} - t\cdot \frac{k}{n}\right)\cdot \left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right\rceil + ti\right).
\]
Let $\overline{m} \in \mathbb{R}$ be the unique value such that $i \cdot \frac{n}{k} + \overline{m}\cdot\sqrt{i \cdot \frac{n}{k}} = \left\lceil i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}\right\rceil$. Clearly, we have $\overline{m} \ge m$. Then, we can re-write the above into
\begin{align*}
        \pr{}{x \ge i\cdot\frac{n}{k} + m\cdot\sqrt{i \cdot\frac{n}{k}}}
&\le    \inf_{t>0}\exp\left(\left(\frac{t^2}{8} - t\cdot \frac{k}{n}\right)\cdot \left( i\cdot \frac{n}{k} + \overline{m}\cdot \sqrt{i\cdot \frac{n}{k}}\right) + ti\right)\\
&=      \inf_{t>0}\exp\left(\frac{t^2}{8}\cdot \left( i\cdot \frac{n}{k} + \overline{m}\cdot \sqrt{i\cdot \frac{n}{k}}\right) - t \cdot \overline{m} \cdot \sqrt{i \cdot \frac{k}{n}}\right)\\
&=      \exp\left(-\frac{2\cdot  \overline{m}^2\cdot i\cdot \frac{k}{n}}{i\cdot \frac{n}{k} + \overline{m}\cdot \sqrt{i\cdot \frac{n}{k}}}\right).
\end{align*}
Again, the last step above follows from $\inf_{t > 0}(at^2 - bt) = -\frac{b^2}{4a}$, which holds for $a, b > 0$.

Note that for any $a, b > 0$, the function $x \mapsto \frac{x^2}{ax + b}$ is monotone increasing on $(0, +\infty)$. Since $\overline{m} \ge m$, we have
\[
    \frac{2\cdot  \overline{m}^2\cdot i\cdot \frac{k}{n}}{i\cdot \frac{n}{k} + \overline{m}\cdot \sqrt{i\cdot \frac{n}{k}}}
\ge \frac{2\cdot  m^2\cdot i\cdot \frac{k}{n}}{i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}},
\]
which further implies
\begin{align*}
        \pr{}{x \ge i\cdot\frac{n}{k} + m\cdot\sqrt{i \cdot\frac{n}{k}}}
&\le    \exp\left(-\frac{2\cdot  m^2\cdot i\cdot \frac{k}{n}}{i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}}\right)\\
&\le    \exp\left(-m^2\cdot \frac{k^2}{n^2}\right) + \exp\left(-m\cdot \sqrt{i\cdot \frac{k}{n}}\cdot \frac{k}{n}\right).
\end{align*}

We conclude that, for all $m \ge 0$,
\begin{equation}\label{eq:right-tail-bound}
    \pr{}{x \ge i\cdot \frac{n}{k} + m\cdot \sqrt{i\cdot \frac{n}{k}}}
\le \exp\left(-m^2\cdot \frac{k^2}{n^2}\right) + \exp\left(-m\cdot \sqrt{i\cdot \frac{k}{n}}\cdot \frac{k}{n}\right).
\end{equation}

    \paragraph{Put everything together.} Using the fact that $\Ex{}{X} = \int_{0}^{+\infty}\pr{}{X \ge \tau}~\rmd\tau$ holds for any non-negative random variable $X$, we can write the expectation of interest into the following:
    \[
        \Ex{}{\left|x - i\cdot\frac{n}{k}\right|}
    =   \int_{0}^{+\infty}\pr{}{x \le i\cdot\frac{n}{k} - \tau}~\rmd\tau + \int_{0}^{+\infty}\pr{}{x \ge i\cdot\frac{n}{k} + \tau}~\rmd\tau.
    \]

    Let $I_{-}$ and $I_{+}$ denote the two integrals above. By a change of variables, we have
    \begin{align*}
        I_{-}
    &=  \sqrt{i \cdot\frac{n}{k}}\cdot\int_{0}^{+\infty}\pr{}{x \le i\cdot\frac{n}{k} - \tau\cdot \sqrt{i \cdot\frac{n}{k}}}~\rmd\tau\\
    &\le\sqrt{i \cdot\frac{n}{k}}\cdot\int_{0}^{+\infty}\exp\left(-2\tau^2\cdot\frac{k^2}{n^2}\right)~\rmd\tau \tag{\Cref{eq:left-tail-bound}}\\
    &=  \sqrt{i \cdot\frac{n}{k}}\cdot\frac{n}{k}\cdot\int_{0}^{+\infty}\exp\left(-2\tau^2\right)~\rmd\tau.
    \end{align*}

    Similarly, we have
    \begin{align*}
        I_{+}
    &=  \sqrt{i \cdot\frac{n}{k}}\cdot\int_{0}^{+\infty}\pr{}{x \ge i\cdot\frac{n}{k} + \tau\cdot \sqrt{i \cdot\frac{n}{k}}}~\rmd\tau\\
    &\le\sqrt{i \cdot\frac{n}{k}}\cdot\left[\int_{0}^{+\infty}\exp\left(-\tau^2\cdot\frac{k^2}{n^2}\right)~\rmd\tau + \int_{0}^{+\infty}\exp\left(-\tau\cdot\sqrt{i \cdot \frac{k}{n}}\cdot\frac{k}{n}\right)~\rmd\tau\right] \tag{\Cref{eq:right-tail-bound}}\\
    &=  \sqrt{i \cdot\frac{n}{k}}\cdot\left[\frac{n}{k}\cdot\int_{0}^{+\infty}\exp\left(-\tau^2\right)~\rmd\tau + \frac{1}{\sqrt{i \cdot \frac{k}{n}}\cdot\frac{k}{n}}\right]\\
    &=  \sqrt{i\cdot\frac{n}{k}}\cdot\frac{n}{k}\cdot \int_{0}^{+\infty}\exp\left(-\tau^2\right)~\rmd\tau + \frac{n^2}{k^2}.
    \end{align*}

    Finally, since
    \[
        \int_{0}^{+\infty}e^{-\tau^2} + e^{-2\tau^2}~\rmd\tau
    =   \frac{2 + \sqrt{2}}{4}\cdot\sqrt{\pi}
    \le 1.513
    <   2,
    \]
    we have the desired upper bound:
    \[
        \Ex{}{\left|x - i\cdot\frac{n}{k}\right|}
    =   I_{-} + I_{+}
    \le 2\sqrt{i\cdot\frac{n}{k}}\cdot\frac{n}{k} + \frac{n^2}{k^2}.
    \]
\end{proof}

\expectednoverb*

\begin{proof}[Proof of \Cref{lemma.integral1}]
    By a Chernoff bound,
    \[
        \pr{B \sim \Binomial\left(n, 1/2\right)}{B \le \frac{n}{4}}  \le \exp\left(-2n \cdot  (1/4)^2\right) = e^{-n/8}.
    \]
    Then, since $|n/B - 2| \le n$ holds for every $B \in \{1, 2, \ldots, n\}$, we have
    \[
        \Ex{B \sim \Binomial(n, 1/2)}{\left|\frac{n}{B} - 2\right| \cdot \1{1 \le B \le n/4}}
    \le n \cdot \pr{B}{1 \le B \le n/4}
    \le n\cdot e^{-n/8}.
    \]
    
    It remains to upper bound the contribution from the $B > n / 4$ case. Note that, for every $B > n/4$, we have
    \[
        \left|\frac{n}{B} - 2\right|
    =   \frac{2}{B}\left|\frac{n}{2} - B\right|
    \le \frac{8}{n}\left|\frac{n}{2} - B\right|.
    \]
    Taking an expectation over $B \sim \Binomial(n, 1/2)$ gives
    \[
        \Ex{B \sim \Binomial(n, 1/2)}{\left|\frac{n}{B} - 2\right| \cdot \1{B > n/4}}\\
    \le \frac{8}{n}\cdot\Ex{B \sim \Binomial(n, 1/2)}{|B - n/2|}.
    \]
    Then, by Jensen's inequality,
    \[
        \Ex{B \sim \Binomial(n, 1/2)}{|B - n/2|}
    \le \sqrt{\Ex{B}{(B - n/2)^2}}
    =   \sqrt{\Var{}{B}}
    =   \sqrt{n/4} = \frac{\sqrt{n}}{2}.
    \]
    It follows that
    \[
        \Ex{B \sim \Binomial(n, 1/2)}{\left|\frac{n}{B} - 2\right| \cdot \1{B > n/4}}
    \le \frac{8}{n}\cdot\frac{\sqrt{n}}{2} = \frac{4}{\sqrt{n}}.
    \]
    
    In total, we have
    \begin{align*}
        &~\Ex{B \sim \Binomial(n, 1/2)}{\left|\frac{n}{B} - 2\right|\cdot\1{B \ne 0}}\\
    =   &~\Ex{B \sim \Binomial(n, 1/2)}{\left|\frac{n}{B} - 2\right|\cdot\1{1 \le B \le n/4}} + \Ex{B \sim \Binomial(n, 1/2)}{\left|\frac{n}{B} - 2\right|\cdot\1{B > n/4}}\\
    \le &~\frac{4}{\sqrt{n}} + n\cdot e^{-n/8}
    \le \frac{14}{\sqrt{n}},
    \end{align*}
    where the last step applies $x^{3/2} \cdot e^{-x/8} \le 10$, which holds for all $x \ge 0$.
\end{proof}