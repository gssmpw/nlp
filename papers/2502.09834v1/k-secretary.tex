\section{From Quantile Estimation to $k$-Secretary}\label{section.3}
In this section, we prove \Cref{prop:reduction} (restated below) by showing that an algorithm for the quantile estimation problem (\Cref{def.quantile_estimation}) can be transformed into a competitive algorithm for $k$-secretary (\Cref{def.ksecretary}), with a mild additive increase in the space usage. Concretely, if the quantile estimation algorithm has an $O(k^{\alpha})$ rank error in expectation, the resulting $k$-secretary algorithm achieves a competitive ratio of $1 - O(k^{\alpha} / k)$.

\reduction*

In \Cref{sec:reduction-weaker}, we prove a weaker version of \Cref{prop:reduction}, in which the memory usage increases by a factor of $O(\log k)$. We then derive the actual version from the weaker reduction in \Cref{sec:reduction-stronger}.

\subsection{A Weaker Reduction}\label{sec:reduction-weaker}
We start by stating the weaker reduction below. Recall the definition of comparison-based algorithms from \Cref{def:comparison-based}.

\begin{proposition}[Weaker version of \Cref{prop:reduction}]\label{prop:reduction-weaker}
    Suppose that, for some $\alpha \in [1/2, 1]$, there is a comparison-based quantile estimation algorithm with memory usage $m$ and an error of $O(k^{\alpha})$ in expectation. Then, there is a $k$-secretary algorithm that uses $O(m \log k)$ memory and achieves a competitive ratio of
    \[
        1 -O\left(\frac{1}{k^{1 - \alpha}}\right).
    \]
\end{proposition}

Compared to \Cref{prop:reduction}, the only change in the proposition above is that the memory bound gets relaxed from $m + O(1)$ to $O(m\log k)$.

We prove \Cref{prop:reduction-weaker} by constructing a $k$-secretary algorithm (\Cref{algo:k-secretary}) that applies the quantile estimator as a black box. Note that this algorithm is almost identical to the algorithm of~\cite{Kleinberg05}, except that the straightforward algorithm for finding the $k$-th largest element---which requires $\Omega(k)$ memory---is replaced by algorithm $\A$, which uses much less memory but only finds an approximately $k$-th largest element.

Another minor change is that we take the first $B \coloneqq \lfloor n/2\rfloor$ elements of the sequence as ``the first half''. In contrast, Kleinberg's algorithm draws $B$ from $\Binomial(n, 1/2)$ randomly, so that $\{s_1, s_2, \ldots, s_B\}$ would be uniformly distributed among all subsets of $\{s_1, s_2, \ldots, s_B\}$. This makes the subsequent concentration argument a bit easier. In our proof, we decided against choosing $B$ randomly because, in that case, the value of $B$ factors into the realization of $\rank_{1:B}(x^*)$ (via the black box quantile estimator). Then, in our analysis, the conditioning on the value of $\rank_{1:B}(x^*)$ would then bias the distribution of $B$ and renders the conditional distribution of $\{s_1, s_2, \ldots, s_B\}$ non-uniform.

\begin{algorithm2e}
    \caption{$\choosetopk(n, k, s)$}
    \label{algo:k-secretary}
    \KwIn{String length $n$, target rank $k$, access to random-order sequence $s = (s_1, s_2, \ldots, s_n)$. Quantile estimation algorithm $\A$.}
    \KwOut{At most $k$ accepted elements in $s$.}
    \lIf{$k = 1$}
    {Run the $(1/e)$-competitive algorithm for $1$-secretary}
    $B \leftarrow \lfloor n/2\rfloor$\;
    Run $\choosetopk(B, \lfloor k/2\rfloor, s_{1:B})$ on the first $B$ elements\label{algoksec.recursive}\;
    In parallel with the line above, run $x^* \leftarrow \A\left(B, \left\lfloor k/2\right\rfloor, s_{1:B}\right)$\label{algoksec.findkth}\;
    $\counter \gets 0$\;
    \For{$i = B+1, B+2, \ldots, n$}{
        Read $s_i$\;
        \If{$s_i > x^*$ and $\counter < \lfloor k / 2\rfloor$} {
            \textbf{Accept} $s_i$\;
            $\counter \gets \counter + 1$\;
        }
    }
\end{algorithm2e}

We will analyze $\choosetopk$ (\Cref{algo:k-secretary}) using an inductive proof. The inductive step in the analysis is stated in the following lemma.

\begin{lemma}\label{lemma:k-secretary-inductive}
    Suppose that the following are true for some constant $C_3 \ge 1$: (1) $n \ge k \ge 10$; (2) \Cref{algo:k-secretary} leads to a competitive ratio of at least 
    \[
        1 - \frac{200C_3}{(k')^{1 - \alpha}}
    \]
    in the recursive call $\choosetopk(B, k', s_{1:B})$ on Line~\ref{algoksec.recursive} for $k' = \lfloor k/2 \rfloor$ and $B = \lfloor n/2 \rfloor$; (3) Line~\ref{algoksec.findkth} returns an element $x^*$ that satisfies 
    \[
    \Ex{}{\left|\rank_{1:B}(x^*) - k'\right|} \le C_3\cdot (k')^{\alpha}.
    \]
    Then, on the instance with parameters $n$ and $k$, \Cref{algo:k-secretary} has a competitive ratio of
    \[
    1 - \frac{200C_3}{k^{1-\alpha}}.
    \]
\end{lemma}

We first show how the lemma implies \Cref{prop:reduction-weaker}.

\begin{proof}[Proof of \Cref{prop:reduction-weaker} assuming \Cref{lemma:k-secretary-inductive}]
    On a $k$-secretary instance, \Cref{algo:k-secretary} involves $O(\log k)$ levels of recursion, since each recursive call shrinks the parameter $k$ by a factor of $2$. Furthermore, each recursive call of $\choosetopk$ uses memory $m$ to call the quantile estimation algorithm $\A$ and an additional $O(1)$ words for storing the remaining variables. Therefore, the algorithm uses $O(m\log k)$ memory in total.
    
    Regarding the competitive ratio, when $k \le 10$, since any algorithm is trivially $0$-competitive, the competitive ratio is indeed lower bounded by
    \[
        0
    \ge 1 - \frac{\sqrt{10}}{\sqrt{k}}
    \ge 1 -200C_3\cdot \frac{1}{k^{1 - \alpha}}.
    \]
    The proposition then follows from \Cref{lemma:k-secretary-inductive} and an induction on $k$.
\end{proof}

Now we turn to the proof of \Cref{lemma:k-secretary-inductive}.

\begin{proof}[Proof of \Cref{lemma:k-secretary-inductive}]
We analyze the execution of $\choosetopk(n, k, s_{1:n})$ on the random-order sequence $s_{1:n}$. Let $x_1 > x_2 > \cdots > x_n$ denote the elements of $s_{1:n}$ when sorted in descending order. Let $\SOL$ denote the expected sum of the elements accepted by \Cref{algo:k-secretary}, over the randomness in both the algorithm and the random ordering. We can decompose $\SOL$ into two parts, $\SOL_1$ and $\SOL_2$, defined as the expected sums of the accepted elements in the first and the second halves, respectively:
\begin{align*}
        \SOL
&=      \SOL_1 + \SOL_2\\
&\ge    \CR_{k'} \cdot\sum_{i=1}^k x_i\cdot \pr{}{\text{$x_i$ is among the $k'$ largest elements in the first half}}\\
&\quad + \sum_{i=1}^k x_i\cdot \pr{}{\text{$x_i$ is among the second half and accepted}},
\end{align*}
where $k' = \lfloor k/2\rfloor$, and $\CR_{k'} \coloneqq 1 - 200C_3 / (k')^{1 - \alpha}$ denotes the lower bound on the competitive ratio of the algorithm on an instance of $k'$-secretary.

In the rest of the proof, we will show that both $\SOL_1$ and $\SOL_2$ are lower bounded by $\OPT \cdot (1/2 - O(1/k^{1 - \alpha}))$, so the entire algorithm has a competitive ratio of $1 - O(1/k^{1-\alpha})$.

\paragraph{Lower bound the first part.} Define binary random variables $X_1, X_2, \ldots, X_n$ such that $X_i = 1$ if and only if $x_i$ is in the first half $s_{1:B}$. Note that $X_1$ through $X_n$ can be viewed as being drawn without replacement from the size-$n$ population $(0, 0, \ldots, 0, 1, 1, \ldots, 1)$ with $B$ copies of $1$ and $n - B$ copies of $0$.

Then, the event ``$x_i$ is among the $k'$ largest elements in the first half'' can be equivalently written as
\[
    X_i = 1 \wedge X_1 + X_2 + \cdots + X_i \le k'.
\]
Let $p_i \coloneqq \pr{}{X_i = 1 \wedge X_1 + X_2 + \cdots + X_i \le k'}$ denote the probability of the event above over the randomness in $X_1, \ldots, X_n$. Note that $p_1 \ge p_2 \ge \cdots \ge p_n$. The lower bound on $\SOL_1$ can then be simplified into
\[
    \SOL_1
\ge \CR_{k'}\cdot\sum_{i=1}^{k}(x_i\cdot p_i)
\ge \CR_{k'}\cdot\frac{1}{k}\cdot\left(\sum_{i=1}^{k}x_i\right)\cdot\left(\sum_{i=1}^{k}p_i\right)
=   \OPT\cdot \CR_{k'}\cdot\frac{1}{k}\sum_{i=1}^{k}p_i,
\]
where $\OPT \coloneqq \sum_{i=1}^{k}x_i$ is the benchmark with which the algorithm competes. The second step above holds since both $x$ and $p$ are non-negative and monotone non-increasing.

It remains to lower bound the term $\sum_{i=1}^{k}p_i$. Note that for any realization of $X_1, \ldots, X_n$, we have
\[
    \sum_{i=1}^k \1{X_i = 1 \wedge X_1 + X_2 + \cdots + X_i \le k'} = \min\left\{\sum_{i=1}^k X_i, k'\right\},
\]
which follows from a case analysis on whether $\sum_{i=1}^k X_i \ge k'$. Taking an expectation on both sides gives
\[
    \sum_{i=1}^k p_i
=   \Ex{X}{\min\left\{\sum_{i=1}^{k}X_i, k'\right\}}.
\]

The right-hand side above can be further lower bounded as follows:
\begin{align*}
        \Ex{X}{\min\left\{\sum_{i=1}^k X_i, k'\right\}}
&\ge    \Ex{X}{\sum_{i=1}^k X_i} - \Ex{X}{\left|\sum_{i=1}^k X_i - k'\right|} \tag{$\min\{a, b\} \ge a - |a-b|$}\\
&\ge    k\cdot \frac{B}{n} - \sqrt{\Ex{X}{\left(\sum_{i=1}^kX_i - k'\right)^2}}. \tag{Jensen's Inequality}
\end{align*}
To control the remaining expectation in the above, we note that the function $x \mapsto (x - k')^2$ is convex, so \Cref{lemma.cite} implies that
\[
    \Ex{X}{\left(\sum_{i=1}^kX_i - k'\right)^2}
\le \Ex{Y}{\left(\sum_{i=1}^kY_i - k'\right)^2},
\]
where $Y_1, Y_2, \ldots, Y_k$ are sampled \emph{with} replacement from the same population (with $B = \lfloor n/2\rfloor$ copies of $1$ and $n - B$ copies of $0$). Equivalently, $Y_i$s are independent samples from $\Bern(B / n)$. It follows that
\[
    \Ex{Y}{\left(\sum_{i=1}^kY_i - k'\right)^2}
=   \Var{Y}{\sum_{i=1}^kY_i} + \left(\Ex{Y}{\sum_{i=1}^kY_i} - k'\right)^2
=   k\cdot\frac{B}{n}\cdot\left(1 - \frac{B}{n}\right) + \left(k\cdot \frac{B}{n} - k'\right)^2.
\]
Note that $(B/n)\cdot (1 - B/n) \le 1/4$. Furthermore, it can be verified that, for all integers $n \ge k \ge 1$,
\[
    \left(k\cdot \frac{B}{n} - k'\right)^2 \le \frac{1}{4}.
\]
Plugging the above back to the lower bound on $\Ex{X}{\min\left\{\sum_{i=1}^{k}X_i, k'\right\}}$ gives
\[
    \Ex{X}{\min\left\{\sum_{i=1}^{k}X_i, k'\right\}}
\ge k\cdot\frac{B}{n} - \sqrt{\frac{k+1}{4}}.
\]
It follows that
\[
    \SOL_1
\ge \OPT\cdot \CR_{k'} \cdot \frac{1}{k}\sum_{i=1}^{k}p_i
\ge \OPT\cdot\CR_{k'}\cdot \left(\frac{B}{n} - \sqrt{\frac{k+1}{4k^2}}\right).
\]
Plugging $B = \lfloor n / 2\rfloor \ge n / 2 - 1/2$ and $\sqrt{\frac{k+1}{4k^2}} \le \sqrt{\frac{4k}{4k^2}} = 1 / \sqrt{k}$ into the above gives
\begin{equation}\label{eq:SOL-1-bound}
    \SOL_1
\ge \OPT\cdot\CR_{k'}\cdot \left(\frac{1}{2} - \frac{1}{2n} - \frac{1}{\sqrt{k}}\right)
\ge \OPT\cdot\CR_{k'}\cdot \left(\frac{1}{2} - \frac{2}{\sqrt{k}}\right).
\end{equation}

\paragraph{The second part after conditioning.} Let $l\coloneqq\rank_{1:B} (x^*)$ denote the actual rank of $x^*$---the output of the quantile estimator on Line~\ref{algoksec.findkth}---among the first half $s_{1:B}$. Let $Z$ denote the number of elements in the second half $s_{(B+1):n}$ that are larger than $x^*$. Note that conditioning on the values of $l$ and $Z$, we have $\rank_{1:n}(x^*) = l + Z$. Equivalently, $x^*$ is given by $x_{l+Z}$.

In the following, we condition on the realization of $(l, Z)$ and examine the contribution to $\SOL_2$, namely, the conditional expectation
\[
    \sum_{i=1}^{k}x_i\cdot\pr{}{x_i\text{ is among the second half and accepted} \mid l, Z}.
\]
Later in the proof, we will take an expectation over the randomness in $(l, Z)$. 

Specifically, we consider four cases, depending on whether $Z \le k'$ and $l + Z - 1 \ge k$ hold:
\begin{enumerate}
    \item[\textbf{Case 1.}] $Z \le k'$. In this case, at most $k' = \lfloor k/2\rfloor$ elements among $s_{B+1}, s_{B+2}, \ldots, s_n$ exceed the threshold $x^*$. Then, by \Cref{algo:k-secretary}, all those elements are accepted. In other words, an element $x_i$ counts towards $\SOL_2$ as long as: (1) $i \le k$; (2) $i \le l + Z - 1$, so that $x_i > x_{l+Z} = x^*$. In the following, we consider two sub-cases, depending on whether $k$ or $l + Z - 1$ is larger.

    \begin{enumerate}
        \item[\textbf{Case 1a.}] $Z \le k'$ and $l + Z - 1 \ge k$. In this case, each element $x_i$ contributes to $\SOL_2$ as long as $x_i$ is among the second half of the sequence. Note that, given the values of $l$ and $Z$, it holds that $\rank_{1:B}(x_{l+Z}) = \rank_{1:B}(x^*) = l$, which implies $|\{s_1, s_2, \ldots, s_B\} \cap \{x_1, x_2, \ldots, x_{l+Z-1}\}| = l - 1$ and $|s_{(B+1):n} \cap \{x_1, x_2, \ldots, x_{l+Z-1}\}| = Z$. Furthermore, conditioning on the realization of $(l, Z)$, $s_{(B+1):n} \cap \{x_1, x_2, \ldots, x_{l+Z-1}\}$ is still uniformly distributed among all size-$Z$ subsets of $\{x_1, x_2, \ldots, x_{l+Z-1}\}$. In particular, each of $x_1, x_2, \ldots, x_{l+Z-1}$ appears in the second half with a conditional probability of $\frac{Z}{l+Z-1}$. It follows that the conditional contribution to $\SOL_2$ is given by
        \begin{align*}
            &~\sum_{i=1}^{k}x_i\cdot\pr{}{x_i\text{ is among the second half and accepted} \mid l, Z}\\
        =   &~\sum_{i=1}^{k}x_i\cdot\frac{Z}{l+Z-1}
        =   \OPT \cdot \frac{Z}{l+Z-1}.
        \end{align*}
        \item[\textbf{Case 1b.}] $Z \le k'$ and $l + Z -1 < k$. This case is similar to Case~1a, except that only the elements $x_1, x_2, \ldots, x_{l+Z-1}$ can contribute to $\SOL_2$, since an element $x_i$ needs to exceed $x^* = x_{l+Z}$ to be accepted. Since $x_1 > x_2 > \cdots > x_n$ are in descending order, we have the inequality
        \[
            \frac{1}{l+Z-1}\sum_{i=1}^{l+Z-1}x_i
        \ge \frac{1}{k}\sum_{i=1}^{k}x_i
        =   \frac{1}{k}\OPT.
        \]
        It follows that the conditional contribution in this case is at least
        \[
            \sum_{i=1}^{l + Z - 1}x_i\cdot \frac{Z}{l + Z - 1}
        =   Z\cdot\frac{1}{l+Z-1}\sum_{i=1}^{l+Z-1}x_i
        \ge \OPT\cdot \frac{Z}{k}.
        \]
    \end{enumerate}
    \item[\textbf{Case 2.}] $Z > k'$. In this case, the second half of the sequence, $s_{(B+1):n}$, contains $Z > k' = \lfloor k/2 \rfloor$ elements that exceed the threshold $x^*$ (namely, the elements in $\{s_{B+1}, s_{B+2}, \ldots, s_n\} \cap \{x_1, x_2, \ldots, x_{l+Z-1}\}$). Then, $\choosetopk$ would accept the $k'$ such elements that arrive first (out of the $Z$ elements).

    Note that, even after conditioning on the values of $(l, Z)$ as well as the size-$Z$ set
    \[
        \{s_{B+1}, s_{B+2}, \ldots, s_n\} \cap \{x_1, x_2, \ldots, x_{l+Z-1}\},
    \]
    the ordering of these $Z$ elements in the sequence is still uniformly distributed. Therefore, each of the $Z$ elements gets accepted with a probability of $k' / Z$.
    
    Again, to calculate the contribution of this case to $\SOL_2$, we need to separately consider the two cases $l + Z - 1 \ge k$ and $l + Z - 1 < k$.
    \begin{enumerate}
        \item[\textbf{Case 2a.}] $Z > k'$ and $l + Z - 1 \ge k$. In this case, each of $x_1, x_2, \ldots, x_k$ can potentially contribute to $\SOL_2$. For each $i \in [k]$, $x_i$ contributes to $\SOL_2$ if: (1) $x_i$ appears in the second half, which happens with probability $\frac{Z}{l + Z - 1}$, by the same argument as in Case~1a; (2) $x_i$ is among the $k'$ elements in the second half (out of $Z$ in total) that the algorithm accepts. This happens with probability $k'/Z$. Therefore, the conditional contribution to $\SOL_2$ is given by
        \[
            \sum_{i=1}^{k}x_i\cdot\frac{Z}{l + Z - 1}\cdot\frac{k'}{Z}
        =   \frac{k'}{l+Z-1}\cdot\OPT.
        \]
        
        \item[\textbf{Case 2b.}] $Z > k'$ and $l + Z - 1 < k$. Finally, compared to Case~2a, only elements $x_1, x_2, \ldots, x_{l+Z-1}$ can contribute to $\SOL_2$. Applying the inequality
        \[
            \frac{1}{l + Z - 1}\sum_{i=1}^{l+Z-1}x_i
        \ge \frac{1}{k}\sum_{i=1}^{k}x_i
        =   \frac{1}{k}\OPT
        \]
        again shows that the conditional contribution to $\SOL_2$ is at least
        \[
             \sum_{i=1}^{l+Z-1}x_i\cdot\frac{Z}{l + Z - 1}\cdot\frac{k'}{Z}
        =   k'\cdot\frac{1}{l+Z-1}\sum_{i=1}^{l+Z-1}x_i
        \ge \frac{k'}{k}\cdot\OPT.
        \]
    \end{enumerate}  
\end{enumerate}
Summarizing the four cases above, we have that, conditioning on the realization of $(l, Z)$, the conditional contribution to the expectation in $\SOL_2$ is lower bounded by
\[
    \frac{\min\{Z, k'\}}{\max\{l+Z-1, k\}}\cdot \OPT.
\]

\paragraph{Lower bound the second part.} It remains to lower bound the expectation of the ratio
\begin{equation}\label{eq:ratio-of-interest}
    \frac{\min\{Z, k'\}}{\max\{l+Z-1, k\}}
\end{equation}
over the randomness in $l \coloneqq \rank_{1:B}(x^*)$ and $Z \coloneqq |s_{(B+1):n} \cap (-\infty, x^*)|$. Equivalently, $Z$ can be defined as the value such that $l + Z = \rank_{1:n}(x^*)$.

Note that, conditioning on the value of $l$, $l + Z$ is identically distributed as the $l$-th smallest number in a size-$B$ subset of $[n] = \{1, 2, \ldots, n\}$ chosen uniformly at random. Thus, the distribution of $Z \mid l$ can be analyzed using \Cref{lemma:subset-rank-concentration}. Concretely, applying the lemma with parameters
\[
    \tilde n = n, \quad \tilde k = B = \lfloor n/2\rfloor, \quad \tilde i = l
\]
gives
\[
    \Ex{}{\left|l + Z-l\cdot \frac{n}{\lfloor n/2\rfloor}\right|}
\le 2\cdot\frac{n}{\lfloor n/2\rfloor}\cdot \sqrt{l\cdot \frac{n}{\lfloor n/2\rfloor}} + \left(\frac{n}{\lfloor n/2\rfloor}\right)^2
\le 7\sqrt{l} + 5,
\]
where the last step applies $n / \lfloor n/2\rfloor \le 11/5$, which holds for any integer $n \ge 10$.
It follows that
\[
    \Ex{}{\left|Z -l\right|}
\le \Ex{}{\left|l + Z-l\cdot \frac{n}{\lfloor n/2\rfloor}\right|} + \Ex{}{\left|l\cdot \frac{n}{\lfloor n/2\rfloor} - 2l\right|} 
\le 7\sqrt{l} + 5 + \frac{2l}{n-1}
\le 7\sqrt{l} + 7.
\]
The last step above applies $l \le B = \lfloor n/2\rfloor \le n/2$.

To further control the $\sqrt{l}$ term (after taking an expectation over $l$), we note that
\[
    \Ex{}{\sqrt{l}}
\le \sqrt{\Ex{}{l}}
\le \sqrt{k' + \Ex{}{|l - k'|}}
\le \sqrt{k' + C_3\cdot(k')^{\alpha}},
\]
where the last step applies the assumption of the lemma. We can further simplify the above into
\[
    \Ex{}{\sqrt{l}}
\le \sqrt{(C_3 + 1)k'}
\le \sqrt{2C_3k'},
\]
which gives the upper bound
\[
    \Ex{}{|Z - l|}
\le \Ex{}{7\sqrt{l} + 7}
\le 7\cdot\sqrt{2C_3k'} + 7.
\]

For each realization of $(l, Z)$, we can lower bound \Cref{eq:ratio-of-interest} as follows:
\begin{align*}
        &~\frac{\min\{Z, k'\}}{\max\{l+Z-1, k\}}\\
\ge     &~\frac{k' - |k'-Z|}{\max\{l+Z-1, k\}} \tag{$\min\{a, b\} \ge a - |a - b|$}\\
\ge     &~\frac{k' - |Z - l| - |l - k'|}{\max\{l+Z-1, k\}} \tag{triangle inequality}\\
\ge     &~\frac{k'}{\max\{l+Z-1, k\}}-\frac{|Z - l| + |l - k'|}{k} \tag{$\max\{l+Z-1, k\} \ge k$}\\
\ge     &~\frac{k' - |l+Z-1 -k|}{k}-\frac{|Z - l| + |l - k'|}{k}\\
\ge     &~\frac{k'}{k} - \frac{|Z - l| + |2l - 2k'| + |2k' - k - 1|}{k}-\frac{|Z - l| + |l - k'|}{k} \tag{triangle inequality}\\
=       &~\frac{k'}{ k}-\frac{2\cdot|Z - l| + 3\cdot|l - k'|+2}{k}.
\end{align*}
The fourth step above applies the inequality
\[
    \frac{a}{\max\{b, c\}}
\ge \frac{a - |b - c|}{c}
\]
for $a = k'$, $b = l + Z - 1$ and $c = k$. The above, in turn, follows from a case analysis: (1) If $b \le c$, the left-hand side is given by $a / c \ge (a - |b - c|) / c$; (2) If $b > c$, we have $a < c < b$, which gives
\[
    \frac{a}{\max\{b, c\}}
=   \frac{a}{b}
\ge \frac{a - |b - c|}{b - |b - c|}
=   \frac{a - |b - c|}{c}.
\]

Now, we analyze the expectation of the above using the inequalities
\[
    \Ex{}{|Z - l|} \le 7\cdot\sqrt{2C_3k'} + 7
\quad\text{and}\quad
    \Ex{}{|l - k'|} \le C_3 \cdot (k')^{\alpha},
\]
the second of which follows from the assumption of the lemma. We obtain
\begin{align*}
    \Ex{}{\frac{\min\{Z, k'\}}{\max\{l+Z-1, k\}}}
\ge &~\frac{k'-2}{k} - \frac{2}{k}\Ex{}{|Z-l|} - \frac{3}{k}\Ex{}{|l-k'|}\\
\ge &~\frac{k/2 - 5/2}{k} - \frac{14\sqrt{2C_3k'} + 14}{k} - \frac{3C_3(k')^{\alpha}}{k} \tag{$k' \ge (k-1)/2$}\\
\ge &~\frac{1}{2} - \frac{(3C_3 + 14\sqrt{2C_3})(k')^{\alpha} + 16.5}{k} \tag{$\alpha \ge 1/2$}.
\end{align*}
It follows that
\begin{equation}\label{eq:SOL-2-bound}
    \SOL_2
\ge \OPT\cdot \left(\frac{1}{2} - \frac{(3C_3 + 14\sqrt{2C_3})(k')^{\alpha} + 16.5}{k}\right).
\end{equation}

\paragraph{Adding the two terms.} Combining the bounds in \Cref{eq:SOL-1-bound,eq:SOL-2-bound} gives
\[
    \frac{\SOL}{\OPT}
\ge \frac{1}{2}\cdot\left(1 - \frac{200C_3}{(k')^{1-\alpha}}\right)\cdot\left(1 - \frac{4}{\sqrt{k}}\right) + \left(\frac{1}{2} - \frac{(3C_3 + 14\sqrt{2C_3})(k')^{\alpha} + 16.5}{k}\right).
\]
Rearranging and applying the relaxation $(1-a)(1-b) \ge 1 - a - b$ gives
\[
    1 - \frac{\SOL}{\OPT}
\le \frac{100C_3}{(k')^{1-\alpha}} + \frac{2}{\sqrt{k}} + \frac{(3C_3 + 14\sqrt{2C_3})(k')^{\alpha} + 16.5}{k}.
\]
For the first term, we note that $k' = \lfloor k/2\rfloor \ge \frac{5}{11}k$ holds for every integer $k \ge 10$. It follows that
\[
    \frac{100C_3}{(k')^{1-\alpha}}
\le \frac{100C_3 \cdot (11/5)^{1 - \alpha}}{k^{1-\alpha}}
\le \frac{149C_3}{k^{1 - \alpha}}.
\]
The second term, $2/\sqrt{k}$, is easily upper bounded by $2C_3/k^{1 - \alpha}$, since $C_3 \ge 1$ and $\alpha \in [1/2, 1]$. Finally, since $k' \le k/2$, the last term can be relaxed to
\[
    \frac{(3 + 14\sqrt{2})C_3\cdot(k/2)^{\alpha} + 16.5}{k}
\le \frac{(3/\sqrt{2} + 14)C_3\cdot k^{\alpha} + 16.5}{k}
\le \frac{33C_3}{k^{1 - \alpha}}.
\]

Therefore, we conclude that the competitive ratio of the algorithm is lower bounded by
\[
    1 - (149 + 2 + 33)\cdot \frac{C_3}{k^{1 - \alpha}}
\ge 1 - \frac{200C_3}{k^{1 - \alpha}}.
\]
\end{proof}

\subsection{Proof of \Cref{prop:reduction}}\label{sec:reduction-stronger}
Now, we derive \Cref{prop:reduction} from \Cref{prop:reduction-weaker}. The only missing piece is the following simple reduction that transforms a quantile estimation algorithm into one that only reads the second half of the stream, at a moderate cost on the accuracy.

\begin{lemma}\label{lemma:only-read-second-half}
    Suppose that, for some $\alpha \in [1/2, 1]$, there is a comparison-based quantile estimation algorithm $\A$ with memory usage $m(k)$ and an error of $O(k^{\alpha})$ in expectation. Then, there is a comparison-based quantile estimation algorithm $\A'$ with memory usage $m(\lfloor k/2\rfloor)$ and an $O(k^{\alpha})$ expected error. Furthermore, $\A'$ ignores all but the last $\lfloor n/2\rfloor$ elements in the length-$n$ stream.
\end{lemma}

The construction of $\A'$ is very simple: it ignores the first half of the stream, and finds the $(k/2)$-th largest element among the second half using $\A$. We can then translate the error of $\A'$ into the error of $\A$ using the concentration bound from \Cref{lemma:subset-rank-concentration}. This follows from a calculation similar to (but simpler than) that in \Cref{lemma:rank-in-second-half-to-overall-simplified}.

\begin{proof}
    Let $B \coloneqq \lfloor n / 2\rfloor$. We define the alternative algorithm $\A'$ as follows: If $k = 1$, we simply find the largest element using $O(1)$ memory. Otherwise, $\A'$ ignores the first $n - B$ elements and simulates algorithm $\A$ on the last $B$ elements with parameter $k' \coloneqq \lfloor k/2\rfloor$.

    It suffices to analyze $\A'$ in the non-trivial case that $n \ge k \ge 2$. Let $x^*$ denote the output of $\A$ (and thus the output of $\A'$). Let $l \coloneqq \rank_{(n-B+1):n}(x^*)$ denote its rank among the second half.

    By the triangle inequality, the expected error can be upper bounded as follows:
    \[
        \Ex{}{|\rank_{1:n}(x^*) - k|}
    \le \Ex{}{\left|\rank_{1:n}(x^*) - l \cdot \frac{n}{B}\right|} + \Ex{}{\left|l \cdot \frac{n}{B} - k\right|}.
    \]
    In the rest of the proof, we upper bound both terms on the right-hand side by $O(k^{\alpha})$.

    \paragraph{Upper bound the first term.} We first analyze the conditional expectation given the realization of $l$. Since $\A$ is comparison-based, conditioning on the value of $l$, $\{s_{n-B+1}, s_{n-B+2}, \ldots, s_n\}$ is still uniformly distributed among all size-$B$ subsets of $\{s_1, s_2, \ldots, s_n\}$. Applying \Cref{lemma:subset-rank-concentration} with parameters
    \[
        \tilde n = n, \quad \tilde k = B, \quad \tilde i = l
    \]
    gives
    \[
        \Ex{}{\left|\rank_{1:n}(x^*) - l \cdot \frac{n}{B}\right|}
    \le 2\sqrt{l \cdot \frac{n}{B}}\cdot\frac{n}{B} + \frac{n^2}{B^2}.
    \]
    Since $B = \lfloor n / 2\rfloor$ and $n \ge 2$, we have $n / B \le 3$. The above can then be simplified into
    \[
        \Ex{}{\left|\rank_{1:n}(x^*) - l \cdot \frac{n}{B}\right|}
    \le 6\sqrt{3}\cdot\sqrt{l} + 9.
    \]
    It remains to take an expectation over $l$. By the assumption on quantile estimator $\A$, we have
    \begin{equation}\label{eq:l-minus-k-prime-upper-bound}
        \Ex{}{|l - k'|} \le C(k')^{\alpha} \le Ck^{\alpha}
    \end{equation}
    for some universal constant $C$. Applying the triangle inequality gives
    \begin{equation}\label{eq:l-upper-bound}
        \Ex{}{l}
    \le \Ex{}{k' + |l - k'|}
    \le k' + Ck^{\alpha}
    \le (C + 1)k.
    \end{equation}
    By Jensen's inequality, we have
    \[
        \Ex{}{\sqrt{l}}
    \le \sqrt{\Ex{}{l}}
    \le \sqrt{C + 1}\cdot\sqrt{k},
    \]
    and
    \[
        \Ex{}{\left|\rank_{1:n}(x^*) - l \cdot \frac{n}{B}\right|}
    \le 6\sqrt{3(C+1)}\cdot\sqrt{k} + 9
    \le O(\sqrt{k})
    \le O(k^{\alpha}),
    \]
    where the $O(\cdot)$ notation hides a universal constant that only depends on $C$. The last step above holds since $\alpha \ge 1/2$.

    \paragraph{Upper bound the second term.} We can upper bound $\left|l\cdot \frac{n}{B} - k\right|$ by
    \[
        \left|l\cdot \frac{n}{B} - 2l\right| + |2l - 2k'| + |2k' - k|.
    \]

    For the expectation of the first term, note that $B = \lfloor n/2 \rfloor$ and $n \ge 2$ implies $n / B = 2 + O(1/n)$. It follows that
    \[
        \Ex{}{\left|l\cdot \frac{n}{B} - 2l\right|}
    =   \left|\frac{n}{B} - 2\right|\cdot \Ex{}{l}
    =   O(1/n) \cdot \Ex{}{l}
    \le O(1/n) \cdot (C + 1)k
    =   O(1),
    \]
    where the third step applies \Cref{eq:l-upper-bound}, and the last step follows from $k \le n$.
    
    For the second term $|2l - 2k'|$, \Cref{eq:l-minus-k-prime-upper-bound} gives
    \[
        \Ex{}{|2l - 2k'|}
    \le 2Ck^{\alpha}.
    \]
    
    Finally, the last term $|2k' - k|$ is either $0$ or $1$. Therefore, we conclude that
    \[
        \Ex{}{\left|l\cdot \frac{n}{B} - k\right|}
    \le O(1) + 2Ck^{\alpha} + 1
    =   O(k^{\alpha}).
    \]
    Again, the $O(\cdot)$ notation hides a constant factor that only depends on $C$.

    Therefore, we conclude that the expected error of $\A'$ is $O(k^{\alpha})$.
\end{proof}

We end by deriving \Cref{prop:reduction} from \Cref{prop:reduction-weaker} and \Cref{lemma:only-read-second-half}.

\begin{proof}[Proof of \Cref{prop:reduction}]
    Let $\A$ be the quantile estimator with memory usage $m$ and an $O(k^{\alpha})$ expected error. By \Cref{lemma:only-read-second-half}, we have an algorithm $\A'$ with the same memory usage and expected error. By \Cref{prop:reduction-weaker}, using $\A'$ as the quantile estimation algorithm, $\choosetopk$ (\Cref{algo:k-secretary}) has a competitive ratio of $1 - O(1/k^{1-\alpha})$.

    It remains to show that \Cref{algo:k-secretary} can be implemented using $m + O(1)$ memory (instead of $O(m\log k)$ memory). To see this, note that when we call $\choosetopk(n, k, s)$, the algorithm makes a recursive call $\choosetopk(\lfloor n / 2\rfloor, \lfloor k/2\rfloor, s_{1:\lfloor n / 2\rfloor})$, and also runs the quantile estimation algorithm $\A'(\lfloor n / 2\rfloor, \lfloor k/2\rfloor, s_{1:\lfloor n / 2\rfloor})$ in parallel. By the construction of $\A'$ (from \Cref{lemma:only-read-second-half}), $\A'(\lfloor n / 2\rfloor, \lfloor k/2\rfloor, s_{1:\lfloor n / 2\rfloor})$ only accesses the elements 
    \[
        s_{\lfloor n / 2\rfloor - \lfloor n / 4\rfloor + 1}, s_{\lfloor n / 2\rfloor - \lfloor n / 4\rfloor + 2}, \ldots, s_{\lfloor n / 2\rfloor}.
    \]
    More generally, the $i$-th recursive call (where $i \in \{1, 2, \ldots, \lfloor \log_2 k\rfloor\})$) of $\choosetopk$ calls $\A'$ on the first $\lfloor n/2^i\rfloor$ elements. By \Cref{lemma:only-read-second-half}, $\A'$ only reads the elements with indices between
    \[
        \lfloor n / 2^i\rfloor - \lfloor n / 2^{i+1}\rfloor + 1
    \]
    and $\lfloor n / 2^i\rfloor$ (inclusive). It follows that the $\Theta(\log k)$ calls to $\A'$ do not overlap in terms of the (contiguous) subsequence of $s_1, s_2, \ldots, s_n$ that they access. Therefore, we only need to allocate a memory of $m$ for procedure $\A'$. Apart from this, $\choosetopk$ performs $O(\log k)$ levels of recursion, each of which takes $O(1)$ words of memory. If we further expand the recursion into a loop implementation, at any time, we only need to store $O(1)$ different values of $x^*$ (either being computed by algorithm $\A'$, or being used as a threshold for accepting elements). Therefore, we can implement the algorithm with the desired competitive ratio using $m + O(1)$ space.
\end{proof}