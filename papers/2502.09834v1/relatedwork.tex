\section{Related Work}
\paragraph{The secretary problem and its variants.} 
The classical secretary problem is often attributed to~\cite{dynkin1963optimum}, though the exact origin of the problem is obscure~\cite{freeman1983secretary,Ferguson1989}; different versions of the problem were studied in the contemporary work of~\cite{Lindley61,CMRS64,GM66}. 

The natural extension of selecting up to $k$ elements (i.e., the $k$-secretary problem) were studied by~\cite{GM66,AMW01,Kleinberg05,BIKK07} under various objectives (e.g., the probability of selecting the $k$ largest elements exactly, or the largest element being among the chosen ones). We followed the formulation of~\cite{Kleinberg05} in terms of the competitive ratio. \cite{Kleinberg05} showed that the optimal competitive ratio is $1 - \Theta(1/\sqrt{k})$ as $k \to \infty$. \cite{BIKK07} subsequently gave $1/e$-competitive algorithms for all $k \ge 1$, improving the result of~\cite{Kleinberg05} in the small-$k$ regime. A more recent work of~\cite{AL21} also focused on the non-asymptotic regime, and gave a deterministic algorithm with a competitive ratio $> 1/e$ for all $k \ge 2$.

A further extension of the $k$-secretary problem considers selecting multiple elements subject to a more general combinatorial constraint. \cite{BIKK07} studied the knapsack secretary problem. \cite{BIK07,BIKK18} introduced the \emph{matroid secretary problem}, in which the player is asked to select elements that form an independent set of a given matroid. This problem has been extensively studied~\cite{chakraborty2012improved,soto2013matroid,jaillet2013advances,dinitz2014matroid,lachish2014log, feldman2014simple,huynh2020matroid,soto2021strong,AKKO23}, and it remains a long-standing open problem whether an $O(1)$-competitive algorithm exists in general. Other variants of the secretary problem consider alternative models for how the player accesses the elements and makes decisions, including models of interview costs~\cite{bartoszynski1978secretary}, shortlists~\cite{ASS19}, reservation costs~\cite{burjons2021secretary}, and a ``pen testing'' variant~\cite{QV23,ganesh2023combinatorial}.

\paragraph{Quantile estimation.} For the quantile estimation problem in random-order streams, \cite{MP80} gave an exact selection algorithm for the $k = \lfloor n/2\rfloor$ case (i.e., finding the median) with $O(\sqrt{n})$ memory, and proved a matching $\Omega(\sqrt{n})$ memory lower bound. Our \Cref{thm:quantile-exact} generalizes their result to general values of $k$, and their lower bound implies that the $O(\sqrt{k})$ memory usage cannot be improved in general (specifically, in the $n = 2k$ case).

For approximate selection, \cite{guha2009stream}  proposed an algorithm that uses $O(1)$ words of memory and finds the $k$-th largest element up to an error of $O(\sqrt{k}\log^2 n\cdot\log(1/\delta))$ with probability $1 - \delta$. In comparison, \Cref{thm:quantile-approx} bounds the expected error and avoids the extra $\polylog(n)$ factor, both of which are crucial for the optimality of the resulting $k$-secretary algorithm. A subsequent work of~\cite{MV12} solved median estimation with an $n^{1/3 + o(1)}$ error using $O(1)$ words of memory. In comparison, \Cref{thm:quantile-approx} applies to all values of $k$ and makes the error dependent only on $k$ and not $n$, at the cost of a larger exponent of $1/2$ and a logarithmic memory usage. We note that, even if we could improve the error to $O(k^{1/3})$, the reduction from $k$-secretary still introduces an $\Omega(\sqrt{k})$ error, which would dominate the quantile estimation error.

While we focus on the random-order setup of quantile estimation, many prior work also addressed the more challenging setup in which elements arrive in an arbitrary order~\cite{MP80,manku1998approximate,KLL16,masson2019ddsketch,gupta2024optimal}. The multi-pass setting, in which the algorithm may scan the stream multiple times, were also considered~\cite{MP80,guha2009stream}.

\paragraph{Learning and decision making under memory constraints.} More broadly, our work is part of the endeavor to understand the role of memory in learning, prediction, and decision-making. Prior work along this line studied the memory bounds for parity learning in a streaming setting~\cite{valiant2016information,steinhardt2016memory,kol2017time,raz2018fast, garg2018extractor}, for the experts problem in online learning~\cite{srinivas2022memory,PZ23,peng2023near}, as well as the fundamental problem of linear regression~\cite{sharan2019memory, marsden2022efficient, blanchard2023memory, blanchard2024gradient}.