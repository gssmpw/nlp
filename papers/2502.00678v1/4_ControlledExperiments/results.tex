
%\input{A_Tables/req2}
\subsection{Experimental Results}
\label{sec:er}


\paragraph{Kernel divergence score satisfies the monotonicity requirement.}
To evaluate compliance with the monotonicity requirement, we analyze the correlation between scores and contamination rates  $\lambda \in \{0.0, 0.05, 0.10, \ldots, 0.95, 1.0\}$.
The primary metric used is the Spearman correlation coefficient, which directly evaluates the monotonic relationship between scores and contamination rates, ensuring alignment with the expected trend.
Additionally, we compute the Pearson correlation coefficient to provide insight into the linearity of the trends, with higher values indicating a stronger linear pattern in the scores.

In Table~\ref{tab:req1}, we present the correlation coefficients for the three benchmark datasets. We keep the dataset size fixed while varying the contamination ratios.
%For WikiMIA and ArxivTection, we fix the total number of samples to be 700, while varying the contamination ratios.  We use 1,000 samples for BookMIA. 
We observe that existing approaches often exhibit highly varying correlation and even reversed signs.
For instance, in the BookMIA dataset, our thorough evaluation across five random subsets consistently revealed negative correlation values for several baseline methods. 
In contrast, KDS consistently achieves a near-perfect correlation on all datasets.
On average, it demonstrates the strongest compliance with the monotonicity requirement. 

Moreover, it is noteworthy that compared to FSD~\citep{zhang2024fine} in Table~\ref{tab:req1}, which also leverages fine-tuning information in detecting pre-training data, our method demonstrates more consistent performance improvements.
We attribute this improvement to our KDS's direct assessment of the structural information within model representations, bypassing the reliance on intermediate scoring adjustments in FSD methods. 
This direct approach allows our score to effectively capture the intrinsic characteristics of the data, leading to more reliable scoring.

\input{B_Figures/trend}
\textbf{Kernel divergence score satisfies the consistency requirement.}
To verify the Consistency requirement, we test whether our score remains stable across independently and identically distributed datasets sampled from the same distribution and with the same contamination rate $\lambda$.
For each contamination rate $\lambda \in \{0.0, 0.05, 0.10, \ldots, 0.95, 1.0\}$, we create datasets by randomly sampling 5 independent subsets from each dataset.
Each subset complies with the mixing rate $\lambda$, consisting of seen and unseen samples in proportions determined by $\lambda$. 
All datasets are fixed to the same size to ensure comparability. 
In Figure~\ref{fig:consistency_verification}, we observe that the kernel divergence score demonstrates relatively low standard deviations, indicating compliance with the Consistency requirement. 
This shows that our method can produce stable and reliable scores, independent of the specific random subset used.

