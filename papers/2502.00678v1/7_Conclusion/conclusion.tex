\section{Conclusion}
In this work, we addressed the critical issue of dataset contamination in LLM  by introducing the Kernel Divergence Score. By capturing fine-tuning-induced shifts in sample embeddings, KDS provides a robust and interpretable measure of contamination. Extensive experiments on controlled scenarios demonstrated the effectiveness of KDS in satisfying key properties like monotonicity and consistency, outperforming existing baselines. This work paves the way for more reliable benchmark evaluations, fostering better dataset curation practices in LLM research.



