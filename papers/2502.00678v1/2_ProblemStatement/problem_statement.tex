\section{Problem Statement}
\label{sec:problem_statement}

\subsection{Quantifying Benchmark Contamination}

The objective is to quantify the relative degree to which a benchmark evaluation dataset, $\mathcal{D}$, has been exposed to the pre-training process of a given LLM, $\mathcal{M}$. 
In modern LLMs, the pre-training dataset is typically unavailable, making it difficult to directly assess the contamination level.
Accordingly, we consider a generalized characterization of the benchmark evaluation data, modeling it as a mixture of both seen and unseen data:
\begin{equation}
\begin{split}
   &  \mathcal{D} = \mathcal{D}_{\mathcal{M}}^\text{seen} \cup \mathcal{D}_{\mathcal{M}}^\text{unseen} \\
    & |\mathcal{D}_{\mathcal{M}}^\text{seen}| / |\mathcal{D}| = \lambda,
    \end{split}
\end{equation}
where $\mathcal{D}_{\mathcal{M}}^\text{seen}$ is the data seen during $\mathcal{M}$'s pre-training, $\mathcal{D}_{\mathcal{M}}^\text{unseen}$ is the data not seen by $\mathcal{M}$, and $\lambda \in [0,1]$ is an unknown parameter indicating the fraction of seen data in $\mathcal{D}$.
Within this framework, we aim to develop a dataset-level scoring function 
$$S: (\mathcal{D}, \mathcal{M}) \rightarrow \mathbb{R},$$ 
which relatively quantifies the contamination of dataset $\mathcal{D}$ with respect to model $\mathcal{M}$. A larger score indicates more contamination and vice versa. 

\paragraph{Practical utility.} A reliable scoring function is practically valuable because it allows us to identify benchmark datasets that are less contaminated with respect to model $\mathcal{M}$. By ranking the contamination scores across datasets, we can prioritize benchmark datasets with minimal contamination, ensuring that evaluation results reliably reflect the model's generalization capabilities rather than memorization of pretraining data. This framework is particularly useful for selecting datasets for fair and trustworthy benchmarking of LLMs. Next, we discuss the desired properties of the scoring function $S$.


\subsection{Reliable Contamination Scores}
\label{sec:rcsr}
A comparative study on the contamination level across datasets is reliable only if the scoring function satisfies specific key properties.
In this section, we state two essential requirements for a reliable contamination scoring function: \textbf{Monotonicity} and \textbf{Consistency}.

\noindent\textbf{Requirement 1.} \textit{\textbf{(Monotonicity)} If dataset $\mathcal{D}$ is more independent of model $\mathcal{M}$ than dataset $\mathcal{D}'$, i.e., $\lambda < \lambda'$, then}
\begin{equation*}
    S(\mathcal{D}, \mathcal{M}) < S(\mathcal{D}', \mathcal{M})
\end{equation*}
\textit{should hold with statistical significance.  In other words, a dataset with a smaller $\lambda$, the fraction of seen data, should have accordingly a smaller contamination score $S(\mathcal{D}, \mathcal{M})$.}

\noindent\textbf{Requirement 2.} \textit{\textbf{(Consistency)} If datasets $\mathcal{D}$ and $\mathcal{D}'$ both comprise of independently and identically distributed~(i.i.d.) samples from a distribution with the same contamination ratio $\lambda$,}
\begin{equation*}
    S(\mathcal{D},\mathcal{M}) \approx S(\mathcal{D}', \mathcal{M})
\end{equation*}
\textit{should hold with statistical significance.}


The Monotonicity requirement ensures that the scoring function exhibits a \textbf{positive correlation} with the dataset's contamination rate, even though the true contamination rate is typically unknown in real-world scenarios.
A scoring function satisfying this requirement enables reliable ranking of benchmark datasets for each model based on their contamination scores.
The Consistency requirement, on the other hand, ensures that the scores are robust to variations in the specific samples drawn from the same underlying distribution, under the same $\lambda$.
This property ensures that the randomness induced from sampling does not substantially affect the overall scoring.