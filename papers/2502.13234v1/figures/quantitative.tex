\begin{table*}[t]
  \centering
  \begin{tabular}{lcccc}
    \toprule
    Methods & CLIP-T ($\uparrow$) & ImageReward ($\uparrow$) & \makecell{Frame\\Consistency ($\uparrow$)} & \makecell{Motion\\Discrepancy ($\downarrow$)} \\
    \midrule
    DMT$^*$ & 29.19 & -0.0742 & 97.13 & \textbf{0.0284} \\
    MotionClone$^*$ & 29.69 & -0.1133	& 96.91 & 0.0503 \\
    VMC & 29.20 & -0.3292 & 96.89 & 0.0353 \\
    MotionDirector & \underline{30.31} & \underline{-0.0162} & \underline{97.19} & 0.0544 \\
    % \midrule
    \textbf{Ours} & \textbf{30.43} & \textbf{0.2301} & \textbf{97.20} & \underline{0.0330} \\
    \bottomrule
  \end{tabular}
  \caption{{\bf Quantitative evaluation.} Our method outperforms baseline approaches in text alignment, frame consistency, and overall human preference as measured by ImageReward~\cite{ir}. Note that $^*$ denotes diffusion guidance-based methods.}
  \label{tab:quantitative}
\end{table*}