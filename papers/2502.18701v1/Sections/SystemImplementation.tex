% \begin{itemize}
%     \item Browser plugin with hotkeys
%     \item Using GenAI to sort the tags in one fashion
%     \item or alternatively rewriting the website in another fashion
%     \item any other feature support?
% \end{itemize}

% Using these design considerations, we then created a screen reader prototype which was then further evaluated in a user study.

% Matt (add tool development)

% Architecture:
%     Why Chrome plugin?
%     What version of Chrome?
%     What was used for prompting? What model what API?
%     Prompt workflow - what do we host where? What prompts do we use?
% Two options 
%     Changing the tags   
%     Rewriting the website
% Do we run it on users desktop computers (specify why no mobile)
% Why we did it this way? Was it only based on design considerations above?

\section{System Implementation}
\label{sec:phase2}
% \yaman{Outline:
% \begin{itemize}
%     \item 1. System Overview and Purpose: Building on the findings in Sections 3.3 and 3.4, we propose a system designed to enhance accessibility on shopping websites by optimizing HTML structures, tags, and descriptions. This system is not directly intended for screen reader users but is a tool for developers and website hosts to improve website accessibility on the backend. The system allows them to identify and rectify accessibility issues, such as improper use of HTML tags, missing or unclear alt text, and inconsistent heading structures, providing a version of the website that is more accessible to screen reader users.
%     \item 2. System Features and Options:
% Then we can illustrate the system's functionality by including screenshots that showcase the user interface and the step-by-step user journey. It is more like a user guide, ensure everyone who read the paper understand what our tool can do and how to use.
% \item 2.1 option 1
% \item 2.2 option 2
% \item if needed, we can give one example scenario to help understand why our tool is needed and how would it work.
% \item 3. Implementation
% \item 3.1 overall system architecture and workflow (better have figure)
% For example, pipeline1~\ref{fig:1} and pipeline2~\ref{fig:2}
% \item 3.2 justify implementation decisions in each step (steps like getting input, processing data, send to api, get response api, replace)
% 3.2.1 e.g., what model we used and how did we process with context window size 
% 3.2.2 e.g., compare similarity of generated HTML with original website before replacing
% \end{itemize}}
% % \subsection{Method}

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{figures/pipeline1.png}
%     \caption{Option 1 pipeline}
%     \label{fig:1}
% \end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{figures/pipeline2.png}
%     \caption{Option 2 pipeline}
%     \label{fig:2}
% \end{figure}



\subsection{System Overview and Purpose}
Based on formative study findings, we propose a system to enhance shopping website accessibility by optimizing HTML structures, tags, and descriptions. While participants identified a lack of descriptive image labels as an issue, we excluded image description generation, as participants and previous research already used GenAI to address this independently\cite{10.1145/3234695.3236337, huh2023genassist}. In contrast, addressing website information hierarchy and navigation barriers for screen readers remains underexplored, which is the focus of our study.
Our system leverages a large language model (LLM) to regenerate or reorganize HTML structures, enhancing information hierarchy and labeling for improved screen reader navigation \cite{llmhtml_gur2022understanding}. 
We developed a Chrome extension to apply these modifications to websites, and the revised versions were tested with screen reader users to assess accessibility improvements. This study focuses on developing and validating the LLM-based pipeline rather than the system's interaction design, which future work can refine for various use cases. For example, screen reader users could use the browser extension to dynamically reorganize websites to meet their preferences. Alternatively and more economic efficiently,  the pipeline
could be integrated into a developerâ€™s workflow during the testing phase, providing valuable insights and automated
suggestions to quickly identify and fix accessibility barriers within their product. For example, a developer could install the extension and check in the inspect console on the browser what has been updated and changed by LLM in the
revised version of the website. This approach minimizes the required expertise and effort for company to improve accessibility beyond WCAG compliance. We also highlight the design implications in more detail in Discussion~\ref{sec:discuss}.

% Based on the findings in the formative study, we propose a system designed to enhance accessibility of shopping websites by optimizing HTML structures, tags, and descriptions. Although participants have previously identified a lack of descriptive labels on images as a problem, we decided not to include image description generation within the scope of our study, as participants were already using GenAI to mitigate this issue independently. Furthermore, as discussed earlier, image description and alternative text generation has been addressed in the prior literature, including tools for online shopping \cite{10.1145/3234695.3236337} and image generation \cite{huh2023genassist}. In contrast, the problem of fixing the information hierarchy of a website remains relatively unexplored by existing solutions and is thus addressed in our study.

% Our system utilizes a computational model from the family of large language models (LLMs), which is capable of text generation including HTML code \cite{llmhtml_gur2022understanding}, to regenerate or reorganize the HTML structure of existing websites, improving the information hierarchy and labeling to better align with screen reader navigation patterns. We then developed a Google Chrome web browser extension to apply LLM-generated modifications to websites. To evaluate the effectiveness of these changes, we tested the revised websites with screen reader users to assess our prototype's impact on accessibility. 

% This study focuses primarily on the development and validation of the LLM-based pipeline rather than the interaction design of the system. The system interface and interaction logic can be further improved based on different use cases by future research. One potential use case is for screen reader users to directly utilize the pipeline by installing a browser extension that dynamically reorganizes websites to better suit their browsing needs. In this scenario, the system could be tailored to accommodate the specific preferences and requirements of screen reader users. Alternatively, the pipeline could be integrated into a developer's workflow during the testing phase, providing valuable insights and automated suggestions to quickly identify and fix accessibility barriers within their product. For example, a developer could install the extension and check in the inspect console on the browser what has been updated and changed by LLM in the revised version of the website. This could potentially lower the barrier in required expertise and experience in web accessibility for developers and reduce the time and effort required to further improve the website accessibility beyond WCAG compliance. %For instance, our prototype could explicitly highl changes made by the LLM and providing clear suggestions and explanations for developers. 
% While this study focuses on the development and validation of the LLM-based pipeline, the system's interface and interaction logic could be further refined for various use cases, which is beyond the current scope of this study. For example, one potential use case involves screen reader users directly utilizing the pipeline through a browser extension that dynamically reorganizes website content to better meet their browsing needs. In this context, the system could be customized to accommodate the specific preferences and requirements of screen reader users.
% We also highlight the design implications in more detail in Discussion (Section \ref{sec:discuss}).

% Our system takes an existing website and employs a Large Language Model (LLM) to either regenerate or reorganize the HTML structure, enhancing the information hierarchy and labeling to better suit screen readers' navigation patterns. We then evaluate the effectiveness of these LLM-generated modifications by testing the revised websites with screen reader users to assess improvements in accessibility. The primary objective of this study is to develop a pipeline that explores and validates the potential of LLMs to refine website HTML for enhanced accessibility. The system interface or interaction logic could be further refined and adapted to different use cases, which is beyond the current scope. For instance, one potential use case is for screen reader users to directly utilize the pipeline by installing a browser extension that dynamically reorganizes websites to better suit their browsing needs. In this scenario, the system could be tailored to accommodate the specific preferences and requirements of screen reader users. Alternatively, the pipeline could be integrated into a developer's workflow during the testing phase, providing valuable insights and automated suggestions to quickly identify and fix accessibility barriers within their product. For example, developer could install the extension and check in inspect console on browser what have been update and changed by LLM revised version on interface, which would lower the accessiblity knowledge and experience barrier for developers and reduce the time and effort they need to further improve the website accessibility beyond WCAG compliance. Even though this interaction ways may not be the best, it can be improved by redesigning the interface of the system. For example, explicitly highlight where have been changed by LLM and providing suggestions and clarification for developers would be ideal. But in this study, we only focus on the pipeline itself instead of the interaction design. We will talk more of the design implication in section \ref{sec:discuss}.



% The expected users of the tool are website designers and developers, who can use the output of our system to see how their site could be modified to improve its accessibility. The system allows them to identify and rectify accessibility issues, such as improper use of HTML tags, missing or unclear alt text, and inconsistent heading structures, providing a version of the website that is more accessible to screen reader users.

\subsection{System Features and Options}

When used on a website, our system offers two different options: %\textbf{(1)} rewriting the entire website, or \textbf{ (2)} only modifying the tag structure but leaving the website otherwise unmodified.

\begin{enumerate}
    \item \textbf{Rewrite the Document: Regenerated HTML Version (Option1) } In this option, we produce an HTML document which is re-created from scratch to provide an accessible screen reader experience. The content is preserved, but all other aspects of the site can be modified. The elements can be re-ordered, and visual design aspects may be removed, since the usability of the screen reader is the only criteria under consideration.
    \item \textbf{Replace the Tags: Reorganized HTML Tags Version (Option2).} The second option is to only improve the information hierarchy of the site and enhance mislabeled elements. This task is achieved by re-writing part of the website's Document Object Model (DOM) to reorganize HTML tags, fix misused elements, and provide better labels.
\end{enumerate}

We chose these two options as the primary methods for interacting with the website content for two key reasons. First, we aimed to explore whether LLMs can generate an accessible website in its entirety or only through targeted modifications to specific parts of the HTML code. Second, we sought to evaluate whether significant or minimal changes to the original webpage design yield better results when validating the prototype. Option 1 involves a comprehensive reconstruction of the site, potentially providing the best screen reader experience, while Option 2 focuses on minimal changes, making it easier to compare with the original webpageâ€”a feature particularly valuable for developers using this system.

% There were two main reasons for choosing these options as the primary way of interacting with the content of the website. Firstly, we wanted to investigate whether LLMs are capable of generating an accessible website as a whole or only through modification of certain parts of the HTML code. 
% Secondly, we wanted to determine whether a significant or minimal modification of the original page's design would lead to better results when validating the prototype. Option 1 allows for a more significant reconstruction of the site, which might produce the best experience when viewed through a screen reader, but the output of Option 2 would be easier to compare with the original website, which might be useful to the developers who will use this system. %It may also be the case the preserving the original design of the site leads to better coherence. 
%we needed to assess the capability of LLMs to generate accessible HTML. 
% With multiple approaches, we could better understand if our results reflected the general capabilities of the model or only reflected something specific to our use case. Furthermore, we could then evaluate the resulting code in a series of user interviews with visually impaired users. %Then, by conducting user interviews with visually impaired users using the HTML produced by an LLM, as we did in the next step, we could confirm that LLMs are capable of making genuine accessibility improvements.

% \textbf{Option 1: Rewrite the Document.} In this option, we produce an HTML document which is re-created from scratch to provide an accessible screen reader experience. The content is preserved, but all other aspects of the site can be modified. The elements can be re-ordered, and visual design aspects may be removed, since the usability of the screen reader is the only criteria under consideration.

% To use Option 1, a user performs the following actions:
% \begin{enumerate}
%     \item Ensure that our Chrome Extension is active in the Chrome Browser
%     \item Navigate to a website
%     \item Press \texttt{Control-Shift-1} (\texttt{Command-Shift-1} on a Mac)
%     \item Wait for the replacement website to appear in the browser
%     \item Explore the HTML in the Developer Tools
% \end{enumerate}

% \textbf{Option 2: Replace the Tags.} The second option is to only improve the information hierarchy of the site and enhance mislabeled elements. This task is achieved by re-writing part of the website's Document Object Model (DOM) to reorganize header tags, fix misused elements, and provide better labels.

% To use Option 2, a user performs the following actions:
% \begin{enumerate}
% \item Ensure that our Chrome Extension is active in the Chrome Browser
% \item Navigate to a website
% \item Press \texttt{Control-Shift-2} (\texttt{Command-Shift-2} on a Mac)
% \item Wait for the replacement website to appear in the browser
% \item Explore the HTML in the Developer Tools
% \end{enumerate}

\subsection{Implementation} 

\subsubsection{System Specifications}

% Our system requires access to the Document Object Model (DOM) of a website and Internet access to use the Application Programming Interface (API) of an LLM. For that reason, we implemented it in the form of a web browser plugin that communicates with the LLM API in the background to complete the tasks.
We developed a Google Chrome Extension and tested it in Google Chrome Official Build 127.0.6533.122 (arm64). Google Chrome was the most widely-used browser and had largest number of screen readers deployed in a desktop context \cite{webaim_screen_reader_survey_10}. The extension supports our requirement to access and modify the Document Object Model (DOM) in real time. The pipeline of our system is applicable to other browsers and computing environments, including mobile web browsers that support plugins.
% As a result, it is an appropriate environment for web developers to test the screen reader function of a website.



\textbf{Large Language Model.} The extension's background script uses the OpenAI API to access GPT-4o~\cite{gpt4o} for processing HTML input, implemented via the \texttt{fetch} function in the browser's Web API~\cite{openai_jsonmode}. We selected GPT-4o for the Regenerated HTML and Reorganized HTML Tags versions due to its large input (128,000 tokens) and output (16,384 tokens) capacities~\cite{gpt4o-tokens}, enabling extensive content changes while preserving essential information and enhancing accessibility for screen readers.

To ensure optimal performance for accessibility-related tasks, we configured the model with the following parameters: \textit{temperature = 0.2}, \textit{max\_tokens = 16,384}, \textit{top\_p = 1}, \textit{frequency\_penalty = 0}, and \textit{presence\_penalty = 0}. A low temperature (0.2) was chosen to prioritize deterministic and consistent outputs, as minor variations in HTML structure could introduce unnecessary complexity. The maximum token limit (16,384) accommodates larger HTML segments, ensuring that even complex webpages are processed in a single call. The \textit{top\_p = 1} setting ensures the full probability distribution is considered, maximizing output completeness. Both frequency and presence penalties were set to 0 to avoid suppressing repeated elements critical for maintaining semantic and structural accuracy in HTML, such as recurring tags or headings.

Processing a webpage takes 1â€“5 minutes on average, with approximately 220,000 tokens (combined input and output) per session. Based on OpenAIâ€™s pricing policy\footnote{https://openai.com/api/pricing/}, this costs \$0.5â€“2.2 USD per webpage, which could be reduced in production by implementing caching or using a cost-effective model with comparable performance.

%We chose the \textit{ChatGPT-4o-latest} model for the Regenerated HTML version and the \textit{GPT-4o} model for the Reorganized HTML Tags version because the former has a larger output window size. This allows it to handle more extensive content changes, making it suitable for completely regenerating an entire webpage's HTML structure while retaining all essential information and improving accessibility for screen reader users. In contrast, the \textit{GPT-4o} model, with a slightly smaller output window size, is well-suited for more focused tasks such as reorganizing HTML tags~\cite{gpt4o-tokens}.
% We passed the \texttt{chatgpt-4o-latest} option, which selects the latest version of GPT-4o.



 %}
 % Conversely, for the Reorganized HTML Tags version, we selected the \textit{GPT-4o} model, which has an input window size of 32,768 tokens. Its slightly smaller output window size is well-suited for more focused tasks such as reorganizing HTML tags ~\cite{gpt4o-tokens}.}


% Since the GPT-4o model is frequently updated, the response of the model may vary between usages. Although this possibility exists, we did not encounter any issues related to the model output (e.g., invalid HTML code) during testing. 
Furthermore, we also tried our prototype with similar models such as Google Gemini 1.5 Pro \cite{gemini} and Anthropic Claude 3.5 Sonnet \cite{claude}, and found that in all cases the models could generate valid HTML code consistent with the intended prompt. Therefore, we believe that our approach can be sufficiently robust in multiple advanced LLMs.

\subsubsection{Functionality}

% Given the specifications, we implemented both options as follows. In either option, a typical workflow would consist of the following actions:

% \begin{enumerate}
%     \item Ensure that our Google Chrome Extension is active in the Google Chrome Browser
% Gathering the original HTML content using our developed Google Chrome Extension
%     \item Navigate to a website
%     \item Press \texttt{Control-Shift-1} or \texttt{Control-Shift-2} for option 1 or 2 respectively\\ (\texttt{Command-Shift-1} or \texttt{Command-Shift-2} on a Mac)
%     \item Wait for the replacement website to appear in the browser
%     \item (Optional) Explore the HTML in the Developer Tools
% \end{enumerate}

% recover
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{figures/option1.jpg}
    \caption[This diagram illustrates the process of using GPT-4o to rewrite HTML code for improved accessibility. The process flows from left to right, starting with opening the webpage HTML code, represented by a product page showing items like cameras, headphones, and smartwatches with prices. The HTML is then broken down into multiple chunks that fit within the LLM's context window, labeled as ``Chunk\[1\]'' to ``Chunk\[n\]''. These chunks are fed into GPT-4o, depicted by a stylized brain icon, which combines all parts and rewrites the HTML code for the entire webpage. The final step shows the output webpage, visually similar to the original, but potentially restructured for better accessibility. Arrows connect each stage, illustrating the progression from the initial webpage through the GPT-4o processing to the final, accessibility-enhanced output. The diagram emphasizes the seamless transformation of web content for improved screen reader compatibility while maintaining visual consistency.]{Option 1 pipeline overview, prompting GPT-4o model to completely rewrite HTML code}
    \label{fig:1}
\end{figure}

We then detail the implementation of Options 1 and 2. For both, the HTML DOM was extracted from the website via the extension, but the data processing and the extent of modifications applied to the webpage differ between the two approaches.

% Both workflows involve using a Google Chrome Extension to collect original HTML content, which is then processed by a Large Language Model (LLM) to optimize the structure and accessibility of the webpage for screen reader users. The distinction between the two options lies in the extent of modification to the HTML content and the specific LLM models chosen for each task.

\indent \textbf{Implementation of Option 1.} 
To implement Option 1 (Fig. \ref{fig:1}), we begin by collecting and preprocessing the webpage's HTML content. The content, including HTML text, links, tags, and other attributes following the reading sequence on the page, is extracted into JSON format and segmented into manageable chunks for processing by the LLM. Sequential API calls are made to the LLM using the browser's \texttt{fetch} function, with each new chunk incorporating the previous LLM response as context in the prompt. The appended previous output informs the model of prior content and ensures that subsequent HTML segments are generated in a consistent style and structure. These API requests include a \textbf{System Prompt}, \textbf{User Input Prompts}, and an \textbf{Assistant Prompt} to guide the model in generating accessible HTML. The \textbf{System Prompt} instructs the LLM to enhance accessibility for blind screen reader users by reorganizing headings, improving the information hierarchy, and removing non-essential elements like styles and scripts while retaining all critical content. The \textbf{User Input Prompts} feed the model with processed HTML chunks, and the \textbf{Assistant Prompt} provides context from previous outputs. Detailed prompts are included in Appendix~\ref{sec:prompt}. After all chunks are regenerated and combined, a similarity check ensures the new HTML retains the original content's structure and meaning before rendering the page. Once the regenerated HTML passes these checks, the Chrome Extension uses JavaScript DOM manipulation methods to inject the updated HTML back into the webpage. For a more detailed description of the workflow and implementation techniques, please refer to Appendix~\ref{sec:imple_detail}.


%To implement Option 1 (Fig. \ref{fig:1}), we regenerate the HTML content of a webpage to enhance accessibility using the ChatGPT-4o-latest model, which offers a larger input window size of 128,000 tokens and an output window size of 16,384 tokens. The collected HTML is often too large for a single API call due to the LLM's context window limitations. After collecting and preprocessing the HTML content, we segment it into manageable chunks for processing by the LLM. For each HTML chunk, we make sequential API calls to the LLM via the browser fetch function. Each API request includes a \textbf{System Prompt} and two \textbf{User Input Prompts} to guide the model in generating accessible HTML:

% \begin{enumerate}
%     \item \textbf{System Prompt:} we summarized general guidance for accessibility improvements from formative study findings and WCAG guideline: ``You are an accessibility expert. You understand that screen reader users have a unique browsing behavior while navigating websites, which differs from visual browsing...''
%     \item \textbf{User Input Prompt 1:} specifies the task for each HTML chunk: ``Follow the accessibility guidelines to generate executable text-only screen reader user friendly HTML code that does not omit any information...''
%     \item \textbf{User Input Prompt 2:} send the chunk data: ``This is part 3 of the HTML document: \textit{<HTML content>}''
% \end{enumerate}

% Importantly, the output from each processed chunk is used as context for the subsequent API call to maintain continuity and coherence across the entire webpage. This is done by appending the previously generated HTML output to the next user prompt, which informs the model of the prior content and allows it to generate the subsequent HTML segment in a consistent style and structure. For example, if chunk 1 produces a regenerated <header> section, chunk 2 will include that output in its prompt to ensure the newly generated <body> segment aligns seamlessly with the already processed <header>. Thus, we will add one \textbf{Assistant Prompt} into the message send to API: ``This is previous response from the system: \textit{<HTML content>}'' For detailed prompt, please refer to Appendix \ref{sec:prompt}. 
% To implement Option 1 (Fig. \ref{fig:1}), we used the JavaScript DOM API to navigate the web page and send its contents to the LLM. 

% \textbf{chatgpt-4o-latest} model, which offers a larger input window size of 128,000 tokens and an output window size of 16,384 tokens.

% GPT-4o has a context window of 128000 tokens \cite{gpt4o-tokens} (i.e., how many tokenized \cite{webster1992tokenization} strings of text can be simultaneously processed by a model in one API request). Thus we split the website into parts, performed multiple calls, and reassembled the results. 

% Since the length of many web pages exceed the context window, i.e., how many tokenized \cite{webster1992tokenization} strings of text can be simultaneously processed by a model in one API request, of GPT-4o (128000 tokens \cite{gpt4o-tokens}), 

% In each call to the model (see \ref{appendix}ppendix for detailed text of the prompts), we also passed the current state of the results to each subsequent call to the model, providing the model with enough context about the current progress of the task at each step to provide a useful result. Once we assembled the completed HTML document from LLM, we replaced the website's DOM with a new DOM based on the resulting HTML. 

% We also implemented a function that checks if the original website and resulting websites had similar content. We compared the version by stripping the HTML from both the original and updated versions, partitioning the text content into individual words, and checking that the number and frequency of the words were similar between both versions. This process helped us confirm that the LLM did not significantly alter the content of the page.\\


% recover
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/option2.jpg}
    \caption[This diagram illustrates a process for improving web accessibility using GPT-4o, progressing from left to right through six stages. It begins with opening the webpage HTML code, shown as a product page displaying items like cameras and headphones. The next step involves traversing the Document Object Model (DOM) and collecting information about each text node, represented by a snippet of HTML code. This collected data is then serialized into a JSON object, containing details such as HTML text, tags, IDs, classes, and attributes. The JSON object is fed into GPT-4o, symbolized by a stylized brain icon, which modifies the tag structure. Following this, the webpage's DOM is rewritten with the updated tags. The final step compares the modified version with the original webpage, displaying the result to the user if the code is complete. The output appears visually similar to the input, suggesting that the accessibility improvements maintain the page's visual integrity while enhancing its structure for screen readers. Arrows connect each stage, depicting the flow from the initial webpage through the GPT-4o processing to the final, accessibility-enhanced output.]{Option 2 pipeline overview, prompting GPT-4o to rewrite only some parts of the HTML code}
    \label{fig:2}
\end{figure}

\textbf{Implementation of Option 2.} To implement Option 2 (Fig. \ref{fig:2}), we focus on directly modifying specific HTML tags while preserving the webpageâ€™s original structure. Similar to Option 1, the HTML content, including attributes, tags, and text, is extracted into a structured JSON format and segmented into manageable chunks for processing by the LLM. Sequential API calls include System Prompt, User Input Prompts, and Assistant Prompt to ensure consistency and accuracy across chunks. In Option 2, the System Prompt instructs the LLM to revise individual HTML tags to enhance accessibility, such as improving label clarity or reorganizing headings, while maintaining the existing layout. The User Input Prompts provide the current JSON chunk, detailing the HTML attributes and text content, while the Assistant Prompt includes context from prior outputs to ensure alignment across processed chunks. Unlike Option 1, the output is not a fully reconstructed HTML file but a JSON object containing the original HTML component attributes and their LLM-revised tags. Once processing is complete, the revised tags from the JSON output are directly injected into the existing webpage using JavaScript DOM manipulation methods. This method updates the HTML tags in place, preserving the visual layout and avoiding the need to re-render the entire page. For detailed prompt configurations and workflow, see Appendix~\ref{sec:prompt}.
%To implement Option 2 (Fig. \ref{fig:2}), we modify the existing HTML tags directly to enhance accessibility while preserving the webpage's original structure. This approach leverages the ChatGPT-4o model to incrementally adjust HTML elements, ensuring the output remains aligned with accessibility standards without a complete regeneration of the HTML. Similar to Option 1, the HTML content is extracted from the webpage using a Google Chrome Extension that interacts with the DOM. The HTML is then converted into a structured JSON object, which represents the tags, attributes, and text content. The JSON input is divided into chunks that fit within the model's input window size of 32,768 tokens for \textbf{GPT-4o}. For each chunk, we make an API call via the browser's fetch function. Each API request includes a \textbf{System Prompt} and two \textbf{User Input Prompts} to guide the model in adjusting HTML tags:

% \begin{enumerate}
%     \item \textbf{System Prompt:} we summarized general guidance for accessibility improvements from formative study findings and WCAG guideline: ``You are an accessibility expert. You understand that screen reader users have a unique browsing behavior while navigating websites, which differs from visual browsing...''
%     \item \textbf{User Input Prompt 1:} specifies the task for each chunk: ``Please adjust the HTML tags according to screen reader users'  browsing behavior and expectations for navigating a shopping website...''
%     \item \textbf{User Input Prompt 2:} send the chunk data: ``This is part 3 of the HTML document: \textit{<JSON content>}''
% \end{enumerate}

% We include an additional \textbf{Assistant Prompt} to provide the output from each processed chunk as context for the subsequent API call: ``This is previous response from the system: \textit{<JSON content>}''. Before applying the reorganized HTML tags to the live webpage, a similarity check is performed between the original and modified versions to ensure that the optimizations do not introduce significant deviations from the original content. Once the output passes the similarity checks, the reorganized HTML tags are used to update the DOM of the active webpage. For a more detailed description of the workflow and implementation techniques, please see Appendix \ref{sec:imple_detail}.
% The implementation of Option 2 (Fig. \ref{fig:2}) was similar to Option 1. The key difference is that, instead of sending the HTML, we first traversed the DOM using JavaScript and collected information about each text node, such as its tag name, content, and attributes. We then serialized this data into a JSON object and sent this JSON object to the model. In the prompt (see \ref{appendix}ppendix), we asked the model to modify the tag structure in the JSON object to improve the navigation with a screen reader and used the resulting JSON object to rewrite the web page's DOM, replacing the original tag with an updated tag



% In both cases, the plugin ran natively in a user's web browser, communicating directly with OpenAI API. Although this is a research prototype, a production version of such plugin would either need to communicate with an LLM running locally on a user's device, or communicate through an intermediary server (as recommended by OpenAI guidelines \cite{openai_guidelines}). Upon confirming the functionality, we then tested our system and its both options in a series of user interviews.

\subsubsection{Changes in the Regenerated HTML Version}

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{figures/option2_upd.png}
%     \caption{Option 2 pipeline overview, prompting GPT-4o to rewrite only some parts of the HTML code}
%     \label{fig:2}
% \end{figure}

The regenerated HTML version introduces several key changes compared to the original website to improve accessibility for screen reader users. Below, we summarize the main changes with specific examples for clarity. Note that these examples are illustrative and do not represent the only modifications made. Additional changes may be present across different parts of the website. Screenshots of the HTML for each version are provided in the linked resources (Fig. \ref{fig:teaser}).

\begin{itemize}
    \item Consistent and Semantic Heading Structure: The regenerated HTML ensures a clear and consistent use of heading tags (<h1>, <h2>, <h3>, etc.) throughout the pages, following a logical order. This makes it easier for screen reader users to understand the page layout and navigate to relevant sections. For example, on the homepage, the <h1> tag is appropriately used for the main title, ``Shop Popular Items,'' while sub-sections such as ``Featured Categories'' and ``Today's Picks'' use <h2>. This prevents the confusion caused by random or missing headings in the original version.
    \item Replace headings to distinguish and highlight information: The content is logically organized with unnecessary elements removed from headings, and summarizing titles added to enhance clarity and reduce clutter. This makes it easier for users to focus on the relevant information without distractions. For example, on the search result page, instead of showing all filter options and categories as separate headings, the LLM-regenerated version groups them under a single ``Filter Results'' section, allowing users to navigate efficiently.
    \item Reordered Sections for Logical Screen Reader Browsing Sequence: The order of sections on each page is rearranged to provide a more logical flow for screen reader users. This adjustment ensures that the most important information is encountered first, reducing the need for excessive navigation. For example, on the product details page, the regenerated HTML places ``Product Name'' and ``Product Details'' before sections such as ``Reviews'' and ``Similar Products.'' This contrasts with the original layout where reviews could appear before key product information. This change aligns better with the linear browsing patterns of screen reader users, who prefer accessing critical information first.
    \item Enhanced Use of ARIA Roles and Attributes: ARIA roles (e.g., role=``navigation'', role = ``main'', role = ``banner'') and attributes (e.g., aria-label, aria-labelledby) are added to provide additional context for assistive technologies. This allows screen readers to better interpret the purpose of various sections and elements. For exmaple, on the product details page, buttons such as ``Add to Cart'' are given specific aria-label attributes (aria-label = ``Add item to cart''), enhancing clarity for screen reader users who cannot see the button's text.
\end{itemize}

% \begin{figure*}
%     \centering
%     \includegraphics[width=1\linewidth]{figures/web_prompt2.png}
%     \caption[This image compares three versions of a web page: the original website, Option 1 (Regenerated HTML), and Option 2 (Reorganized HTML Tags). The original website, shown on the left, is the Mercari marketplace featuring a colorful layout with product categories, a search bar, and a prominent ``Mercari x Japan'' banner. In the center, Option 1 displays a text-only version of the site, with a hierarchical structure of headings and links, removing visual elements to focus on content accessibility. On the right, Option 2 appears visually identical to the original but with potential structural changes to improve screen reader navigation. Each version includes a zoomed-in section highlighting accessibility information: the original shows a ``Women'' heading with contrast ratio and role details; Option 1's zoomed section displays a ``Sign up'' link with improved contrast and keyboard accessibility; Option 2's zoomed area is similar to the original but with a ``generic'' role instead of ``heading''. This comparison illustrates different approaches to enhancing web accessibility: complete HTML regeneration for a text-focused experience, and HTML tag reorganization for improved structure while maintaining visual design.]{From left to right: the original website, regenerated HTML version of the website for Option 1, and the version for Option 2 with replaced tags. We present an example of changes in the Regenerated HTML and Reorganized HTML tags versions compared to the original website. Both the Regenerated HTML and Reorganized HTML tags versions remove single-category headings to reduce clutter and prevent fatigue, enhancing navigation for screen reader users. The Reorganized HTML tags version retains the original website's visual design.}
%     \label{fig:web_prompt}
% \end{figure*}



\subsubsection{Changes in the Reorganized HTML Tags Version}

\begin{itemize}
    \item Replace headings to distinguish and highlight information: this version focuses on ensuring that headings are used appropriately to reflect the content hierarchy, removing unnecessary elements from being tagged as headings and adding key information into headings. Uses appropriate headings (<h1>, <h2>, <h3>, etc.) and paragraphs (<p>) to present content hierarchically and semantically. For example, the product name ``oster blender'' is an <h1>, ensuring it stands out as the primary focus. 
    \item Enhanced Heading Hierarchy for Logical Screen Reader Navigation: This version focuses on adjusting the levels of headings to emphasize the content's structure and hierarchy without altering the page layout. By refining the heading levels, it provides a clearer and more logical flow for screen readers. For example, on the search result page, the filter sections such as ``Filter by,'' ``Status,'' ``Item origin,'' and ``Size'' are clearly marked with <h2>, <h3>, and <h4> tags, providing a hierarchical structure that is more accessible for screen readers and improves the overall user experience.
\end{itemize}
\vspace{-0.14in}