\section{Related Work}
With the advent of multimodal representation learning, the cross-modal text-molecule retrieval task has garnered significant attention. Existing methods can be broadly categorized into three groups: statistic-based, hashing-based, and deep learning-based approaches.

\subsection{Statistic-Based Methods}
Statistic-based methods aim to bridge the modality gap by analyzing feature correlations in subspace projections. Canonical correlation analysis **Hastie et al., "The Elements of Statistical Learning"**, kernel canonical correlation analysis **Hardoon et al., "Canonical Correlation Analysis: A Tutorial on Implementation, with R Examples"**, and deep canonical correlation analysis **Ando et al., "Deep Canonical Correlation Analysis"** are representative methods that maximize correlations between text and molecule embeddings in a shared latent space. While these methods demonstrated initial success, they often struggle with complex, high-dimensional data and fail to capture deep semantic relationships between different modalities.

\subsection{Hashing-Based Methods}
Hashing-based methods focus on mapping high-dimensional multimodal features into binary codes to enable efficient similarity search. Techniques such as spectral hashing **Liu et al., "Spectral Hashing"**, self-taught hashing **Raina et al., "Self-Taught Learning: Transfer Learning with Minimal Supervision"**, and iterative quantization **Gong et al., "Iterative Quantization: A Restorable Projection Approach to Learning Binary Codes"** project text and molecule representations into a shared Hamming space, where retrieval is accelerated by comparing binary codes. Notably, the discretization process may overlook nuanced semantic dependencies between textual concepts and molecular structural motifs, thereby limiting retrieval accuracy.

\begin{figure*}[!htbp]
\centering
\includegraphics[scale=0.48]{CLASS.pdf}
\caption{Overview of CLASS. All the molecules are represented by white spheres for H, red for O, gray for C, and yellow for P. Initially, the \textbf{multimodal encoder} (\textcircled{1}) encodes $z_i$ and $z_j$, and then inputs them into the \textbf{sample difficulty quantification} (\textcircled{2}) to calculate the similarity between samples, quantifying the difficulty of sample $z_i$ based on the number $\mathcal{N}_{i}$ of confusing samples. Thereafter, the \textbf{sample scheduler} (\textcircled{3}) based on a curriculum learning strategy introduces training samples via an easy-to-hard paradigm. Finally, the \textbf{adaptive intensity learning} (\textcircled{4}) dynamically adjusts the model's training intensity to control the global training process of the model.}
\vspace{-5pt}
\label{fig:overview}
\end{figure*}

\subsection{Deep Learning-Based Methods}
Deep learning pays attention to mapping the semantic representations of different modalities into a shared embedding space to facilitate similarity evaluation. Adversarial networks are widely employed in image-recipe retrieval tasks **Edraki et al., "Recipe Retrieval via Visual and Textual Cues"**. For instance, **Li et al., "Adversarial Training for Unsupervised Multimodal Alignment"** introduces adversarial training to align text and molecule representations, achieving robust modality alignment through triplet loss and a min-max game strategy. Another line of work involves the introduction of contrastive learning, with **Chen et al., "Contrastive Learning for Molecular Graphs and Text Embeddings"** deploying contrastive learning on molecular graphs and text embeddings. Additionally, **Fukuda et al., "Optimal Transport for Multi-Grained Alignment"** leverages optimal transport for multi-grained alignment. **Zhang et al., "Hierarchical Optimal Transport for Multimodal Alignment"** decomposes molecules into hierarchical graphs and aligns them with text at multiple granularities using optimal transport, significantly improving retrieval precision. However, these methods overlook the aspect of enhancing training efficiency and varying difficulty across samples.