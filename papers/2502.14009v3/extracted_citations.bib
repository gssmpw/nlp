@inproceedings{aali_ambient_2024,
	title = {Ambient {Diffusion} {Posterior} {Sampling}: {Solving} {Inverse} {Problems} with {Diffusion} {Models} {Trained} on {Corrupted} {Data}},
	shorttitle = {Ambient {Diffusion} {Posterior} {Sampling}},
	url = {https://openreview.net/forum?id=qeXcMutEZY},
	abstract = {We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data. Firstly, we extend the Ambient Diffusion framework to enable training directly from measurements corrupted in the Fourier domain. Subsequently, we train diffusion models for MRI with access only to Fourier subsampled multi-coil measurements at acceleration factors R\$=2, 4, 6, 8\$. Secondly, we propose \${\textbackslash}textit\{Ambient Diffusion Posterior Sampling\}\$ (A-DPS), a reconstruction algorithm that leverages generative models pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling on measurements from a different forward process (e.g. image blurring). For MRI reconstruction in high acceleration regimes, we observe that A-DPS models trained on subsampled data are better suited to solving inverse problems than models trained on fully sampled data. We also test the efficacy of A-DPS on natural image datasets (CelebA, FFHQ, and AFHQ) and show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance.},
	language = {en},
	urldate = {2025-03-10},
	author = {Aali, Asad and Daras, Giannis and Levac, Brett and Kumar, Sidharth and Dimakis, Alex and Tamir, Jon},
	month = oct,
	year = {2024},
}

@inproceedings{acar_self-supervised_2021,
	title = {Self-supervised {Dynamic} {MRI} {Reconstruction}},
	doi = {10.1007/978-3-030-88552-6_4},
	abstract = {Deep learning techniques have recently been adopted for accelerating dynamic MRI acquisitions. Yet, common frameworks for model training rely on availability of large sets of fully-sampled MRI data to construct a ground-truth for the network output. This heavy reliance is undesirable as it is challenging to collect such large datasets in many applications, and even impossible for high spatiotemporal-resolution protocols. In this paper, we introduce self-supervised training to deep neural architectures for dynamic reconstruction of cardiac MRI. We hypothesize that, in the absence of ground-truth data, elevating complexity in self-supervised models can instead constrain model performance due to the deficiencies in training data. To test this working hypothesis, we adopt self-supervised learning on recent state-of-the-art deep models for dynamic MRI, with varying degrees of model complexity. Comparison of supervised and self-supervised variants of deep reconstruction models reveals that compact models have a remarkable advantage in reliability against performance loss in self-supervised settings.},
	booktitle = {Machine {Learning} for {Medical} {Image} {Reconstruction}},
	publisher = {Springer International Publishing},
	author = {Acar, Mert and Çukur, Tolga and Öksüz, Ilkay},
	year = {2021},
	keywords = {Cardiac MRI, Convolutional Neural Networks, Dynamic reconstruction, Self-supervised learning},
	pages = {35--44},
}

@article{aggarwal_ensure_2023,
	title = {{ENSURE}: {A} {General} {Approach} for {Unsupervised} {Training} of {Deep} {Image} {Reconstruction} {Algorithms}},
	volume = {42},
	issn = {1558-254X},
	shorttitle = {{ENSURE}},
	url = {https://ieeexplore.ieee.org/document/9961145},
	doi = {10.1109/TMI.2022.3224359},
	abstract = {Image reconstruction using deep learning algorithms offers improved reconstruction quality and lower reconstruction time than classical compressed sensing and model-based algorithms. Unfortunately, clean and fully sampled ground-truth data to train the deep networks is often unavailable in several applications, restricting the applicability of the above methods. We introduce a novel metric termed the ENsemble Stein’s Unbiased Risk Estimate (ENSURE) framework, which can be used to train deep image reconstruction algorithms without fully sampled and noise-free images. The proposed framework is the generalization of the classical SURE and GSURE formulation to the setting where the images are sampled by different measurement operators, chosen randomly from a set. We evaluate the expectation of the GSURE loss functions over the sampling patterns to obtain the ENSURE loss function. We show that this loss is an unbiased estimate for the true mean-square error, which offers a better alternative to GSURE, which only offers an unbiased estimate for the projected error. Our experiments show that the networks trained with this loss function can offer reconstructions comparable to the supervised setting. While we demonstrate this framework in the context of MR image recovery, the ENSURE framework is generally applicable to arbitrary inverse problems.},
	number = {4},
	urldate = {2025-02-20},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Aggarwal, Hemant Kumar and Pramanik, Aniket and John, Maneesh and Jacob, Mathews},
	month = apr,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Image reconstruction, Loss measurement, MRI, Magnetic resonance imaging, Measurement, Noise measurement, SURE, Training, Unsupervised learning, Weight measurement, deep learning, inverse problems},
	pages = {1133--1144},
}

@inproceedings{bora_ambientgan_2018,
	title = {{AmbientGAN}: {Generative} models from lossy measurements},
	abstract = {Generative models provide a way to model structure in complex distributions and have been shown to be useful for many tasks of practical interest. However, current techniques for training generative models require access to fully-observed samples. In many settings, it is expensive or even impossible to obtain fully-observed samples, but economical to obtain partial, noisy observations. We consider the task of learning an implicit generative model given only lossy measurements of samples from the distribution of interest. We show that the true underlying distribution can be provably recovered even in the presence of per-sample information loss for a class of measurement models. Based on this, we propose a new method of training Generative Adversarial Networks (GANs) which we call AmbientGAN. On three benchmark datasets, and for various measurement models, we demonstrate substantial qualitative and quantitative improvements. Generative models trained with our method can obtain \$2\$-\$4\$x higher inception scores than the baselines.},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Bora, Ashish and Price, Eric and Dimakis, Alexandros G.},
	month = feb,
	year = {2018},
}

@inproceedings{chen_equivariant_2021,
	title = {Equivariant {Imaging}: {Learning} {Beyond} the {Range} {Space}},
	doi = {10.1109/ICCV48922.2021.00434},
	abstract = {In various imaging problems, we only have access to compressed measurements of the underlying signals, hindering most learning-based strategies which usually require pairs of signals and associated measurements for training Learning only from compressed measurements is impossible in general, as the compressed observations do not contain information outside the range of the forward sensing operator. We propose a new end-to-end self-supervised framework that overcomes this limitation by exploiting the equivariances present in natural signals. Our proposed learning strategy performs as well as fully supervised methods. Experiments demonstrate the potential of this frame- work on inverse problems including sparse-view X-ray computed tomography on real clinical data and image inpainting on natural images. Code has been made available at: https://github.com/edongdongchen/EI.},
	language = {English},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Chen, Dongdong and Tachella, Julián and Davies, Mike E.},
	month = oct,
	year = {2021},
}

@inproceedings{chen_robust_2022,
	title = {Robust {Equivariant} {Imaging}: a fully unsupervised framework for learning to image from noisy and partial measurements},
	doi = {10.1109/CVPR52688.2022.00556},
	abstract = {Deep networks provide state-of-the-art performance in multiple imaging inverse problems ranging from medical imaging to computational photography. However, most existing networks are trained with clean signals which are often hard or impossible to obtain. Equivariant imaging (EI) is a recent self-supervised learning framework that exploits the group invariance present in signal distributions to learn a reconstruction function from partial measurement data alone. While EI results are impressive, its performance degrades with increasing noise. In this paper, we propose a Robust Equivariant Imaging (REI) framework which can learn to image from noisy partial measurements alone. The proposed method uses Stein's Unbiased Risk Estimator (SURE) to obtain a fully unsupervised training loss that is robust to noise. We show that REI leads to considerable performance gains on linear and nonlinear inverse problems, thereby paving the way for robust unsupervised imaging with deep networks. Code is available at https://github.com/edongdongchen/REI.},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Chen, Dongdong and Tachella, Julián and Davies, Mike E.},
	month = jun,
	year = {2022},
}

@inproceedings{cole_fast_2021,
	title = {Fast {Unsupervised} {MRI} {Reconstruction} {Without} {Fully}-{Sampled} {Ground} {Truth} {Data} {Using} {Generative} {Adversarial} {Networks}},
	url = {https://ieeexplore.ieee.org/document/9607486},
	doi = {10.1109/ICCVW54120.2021.00444},
	abstract = {Most deep learning (DL) magnetic resonance imaging (MRI) reconstruction approaches rely on supervised training algorithms, which require access to high-quality, fully-sampled ground truth datasets. In MRI, acquiring fully-sampled data is time-consuming, expensive, and, in some cases, impossible due to limitations on data acquisition speed. We present a DL framework for MRI reconstruction that does not require any fully-sampled data using unsupervised generative adversarial networks. We test our proposed method on 2D knee MRI data and 2D+time abdominal dynamic contrast enhanced (DCE) MRI data. In the DCE-MRI dataset, as is the case with many dynamic MRI sequences, ground truth was not possible to acquire and therefore, supervised DL reconstruction was not feasible. We show that our unsupervised method produces reconstructions which are better than compressed sensing in terms of image metrics and the recovery of anatomical structure, with faster inference time. In contrast to most deep learning reconstruction techniques, which are supervised, this method does not need any fully-sampled data. With the proposed method, accelerated imaging and accurate reconstruction can be performed in applications in cases where fully-sampled datasets are difficult to obtain or unavailable.},
	urldate = {2025-02-13},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} {Workshops} ({ICCVW})},
	author = {Cole, Elizabeth K. and Ong, Frank and Vasanawala, Shreyas S. and Pauly, John M.},
	month = oct,
	year = {2021},
	note = {ISSN: 2473-9944},
	keywords = {Computer vision, Conferences, Data acquisition, Deep learning, Magnetic resonance imaging, Measurement, Training},
	pages = {3971--3980},
}

@misc{daras_ambient_2023,
	title = {Ambient {Diffusion}: {Learning} {Clean} {Distributions} from {Corrupted} {Data}},
	shorttitle = {Ambient {Diffusion}},
	doi = {10.48550/arXiv.2305.19256},
	abstract = {We present the first diffusion-based framework that can learn an unknown distribution using only highly-corrupted samples. This problem arises in scientific applications where access to uncorrupted samples is impossible or expensive to acquire. Another benefit of our approach is the ability to train generative models that are less likely to memorize individual training samples since they never observe clean training data. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image. We prove that our method leads to models that learn the conditional expectation of the full uncorrupted image given this additional measurement corruption. This holds for any corruption process that satisfies some technical conditions (and in particular includes inpainting and compressed sensing). We train models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) and show that we can learn the distribution even when all the training samples have \$90{\textbackslash}\%\$ of their pixels missing. We also show that we can finetune foundation models on small corrupted datasets (e.g. MRI scans with block corruptions) and learn the clean distribution without memorizing the training set.},
	urldate = {2024-02-27},
	publisher = {arXiv},
	author = {Daras, Giannis and Shah, Kulin and Dagan, Yuval and Gollakota, Aravind and Dimakis, Alexandros G. and Klivans, Adam},
	month = may,
	year = {2023},
	note = {arXiv:2305.19256 [cs, math]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Information Theory, Computer Science - Machine Learning},
}

@misc{darestani_accelerated_2021,
	title = {Accelerated {MRI} with {Un}-trained {Neural} {Networks}},
	url = {http://arxiv.org/abs/2007.02471},
	doi = {10.48550/arXiv.2007.02471},
	abstract = {Convolutional Neural Networks (CNNs) are highly effective for image reconstruction problems. Typically, CNNs are trained on large amounts of training images. Recently, however, un-trained CNNs such as the Deep Image Prior and Deep Decoder have achieved excellent performance for image reconstruction problems such as denoising and inpainting, {\textbackslash}emph\{without using any training data\}. Motivated by this development, we address the reconstruction problem arising in accelerated MRI with un-trained neural networks. We propose a highly optimized un-trained recovery approach based on a variation of the Deep Decoder and show that it significantly outperforms other un-trained methods, in particular sparsity-based classical compressed sensing methods and naive applications of un-trained neural networks. We also compare performance (both in terms of reconstruction accuracy and computational cost) in an ideal setup for trained methods, specifically on the fastMRI dataset, where the training and test data come from the same distribution. We find that our un-trained algorithm achieves similar performance to a baseline trained neural network, but a state-of-the-art trained network outperforms the un-trained one. Finally, we perform a comparison on a non-ideal setup where the train and test distributions are slightly different, and find that our un-trained method achieves similar performance to a state-of-the-art accelerated MRI reconstruction method.},
	urldate = {2025-02-17},
	publisher = {arXiv},
	author = {Darestani, Mohammad Zalbagi and Heckel, Reinhard},
	month = apr,
	year = {2021},
	note = {arXiv:2007.02471 [eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, Statistics - Machine Learning},
}

@inproceedings{darestani_test-time_2022,
	title = {Test-{Time} {Training} {Can} {Close} the {Natural} {Distribution} {Shift} {Performance} {Gap} in {Deep} {Learning} {Based} {Compressed} {Sensing}},
	url = {https://proceedings.mlr.press/v162/darestani22a.html},
	abstract = {Deep learning based image reconstruction methods outperform traditional methods. However, neural networks suffer from a performance drop when applied to images from a different distribution than the training images. For example, a model trained for reconstructing knees in accelerated magnetic resonance imaging (MRI) does not reconstruct brains well, even though the same network trained on brains reconstructs brains perfectly well. Thus there is a distribution shift performance gap for a given neural network, defined as the difference in performance when training on a distribution PPP and training on another distribution QQQ, and evaluating both models on QQQ. In this work, we propose a domain adaptation method for deep learning based compressive sensing that relies on self-supervision during training paired with test-time training at inference. We show that for four natural distribution shifts, this method essentially closes the distribution shift performance gap for state-of-the-art architectures for accelerated MRI.},
	language = {en},
	urldate = {2025-02-13},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Darestani, Mohammad Zalbagi and Liu, Jiayu and Heckel, Reinhard},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {4754--4776},
}

@misc{desai_noise2recon_2022,
	title = {{Noise2Recon}: {Enabling} {Joint} {MRI} {Reconstruction} and {Denoising} with {Semi}-{Supervised} and {Self}-{Supervised} {Learning}},
	shorttitle = {{Noise2Recon}},
	url = {http://arxiv.org/abs/2110.00075},
	doi = {10.48550/arXiv.2110.00075},
	abstract = {Deep learning (DL) has shown promise for faster, high quality accelerated MRI reconstruction. However, supervised DL methods depend on extensive amounts of fully-sampled (labeled) data and are sensitive to out-of-distribution (OOD) shifts, particularly low signal-to-noise ratio (SNR) acquisitions. To alleviate this challenge, we propose Noise2Recon, a model-agnostic, consistency training method for joint MRI reconstruction and denoising that can use both fully-sampled (labeled) and undersampled (unlabeled) scans in semi-supervised and self-supervised settings. With limited or no labeled training data, Noise2Recon outperforms compressed sensing and deep learning baselines, including supervised networks, augmentation-based training, fine-tuned denoisers, and self-supervised methods, and matches performance of supervised models, which were trained with 14x more fully-sampled scans. Noise2Recon also outperforms all baselines, including state-of-the-art fine-tuning and augmentation techniques, among low-SNR scans and when generalizing to other OOD factors, such as changes in acceleration factors and different datasets. Augmentation extent and loss weighting hyperparameters had negligible impact on Noise2Recon compared to supervised methods, which may indicate increased training stability. Our code is available at https://github.com/ad12/meddlr.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Desai, Arjun D. and Ozturkler, Batu M. and Sandino, Christopher M. and Boutin, Robert and Willis, Marc and Vasanawala, Shreyas and Hargreaves, Brian A. and Ré, Christopher M. and Pauly, John M. and Chaudhari, Akshay S.},
	month = oct,
	year = {2022},
	note = {arXiv:2110.00075 [eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{desai_vortex_2022,
	title = {{VORTEX}: {Physics}-{Driven} {Data} {Augmentations} {Using} {Consistency} {Training} for {Robust} {Accelerated} {MRI} {Reconstruction}},
	shorttitle = {{VORTEX}},
	url = {http://arxiv.org/abs/2111.02549},
	doi = {10.48550/arXiv.2111.02549},
	abstract = {Deep neural networks have enabled improved image quality and fast inference times for various inverse problems, including accelerated magnetic resonance imaging (MRI) reconstruction. However, such models require a large number of fully-sampled ground truth datasets, which are difficult to curate, and are sensitive to distribution drifts. In this work, we propose applying physics-driven data augmentations for consistency training that leverage our domain knowledge of the forward MRI data acquisition process and MRI physics to achieve improved label efficiency and robustness to clinically-relevant distribution drifts. Our approach, termed VORTEX, (1) demonstrates strong improvements over supervised baselines with and without data augmentation in robustness to signal-to-noise ratio change and motion corruption in data-limited regimes; (2) considerably outperforms state-of-the-art purely image-based data augmentation techniques and self-supervised reconstruction methods on both in-distribution and out-of-distribution data; and (3) enables composing heterogeneous image-based and physics-driven data augmentations. Our code is available at https://github.com/ad12/meddlr.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Desai, Arjun D. and Gunel, Beliz and Ozturkler, Batu M. and Beg, Harris and Vasanawala, Shreyas and Hargreaves, Brian A. and Ré, Christopher and Pauly, John M. and Chaudhari, Akshay S.},
	month = jun,
	year = {2022},
	note = {arXiv:2111.02549 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Physics - Medical Physics},
}

@inproceedings{fabian_data_2021,
	title = {Data augmentation for deep learning based accelerated {MRI} reconstruction with limited data},
	abstract = {Deep neural networks have emerged as very successful tools for image restoration and reconstruction tasks. These networks are often trained end-to-end to directly reconstruct an image from a noisy or corrupted measurement of that image. To achieve state-of-the-art performance, training on large and diverse sets of images is considered critical. However, it is often difficult and/or expensive to collect large amounts of training images. Inspired by the success of Data Augmentation (DA) for classification problems, in this paper, we propose a pipeline for data augmentation for accelerated MRI reconstruction and study its effectiveness at reducing the required training data in a variety of settings. Our DA pipeline, MRAugment, is specifically designed to utilize the invariances present in medical imaging measurements as naive DA strategies that neglect the physics of the problem fail. Through extensive studies on multiple datasets we demonstrate that in the low-data regime DA prevents overfitting and can match or even surpass the state of the art while using significantly fewer training data, whereas in the high-data regime it has diminishing returns. Furthermore, our findings show that DA improves the robustness of the model against various shifts in the test distribution.},
	urldate = {2024-02-14},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	author = {Fabian, Zalan and Heckel, Reinhard and Soltanolkotabi, Mahdi},
	month = jul,
	year = {2021},
	pages = {3057--3067},
}

@inproceedings{gan_deep_2021,
	title = {Deep {Image} {Reconstruction} {Using} {Unregistered} {Measurements} {Without} {Groundtruth}},
	url = {https://ieeexplore.ieee.org/document/9434079},
	doi = {10.1109/ISBI48211.2021.9434079},
	abstract = {One of the key limitations in conventional deep learning based image reconstruction is the need for registered pairs of training images containing a set of high-quality groundtruth images. This paper addresses this limitation by proposing a novel unsupervised deep registration-augmented reconstruction method (U-Dream) for training deep neural nets to reconstruct high-quality images by directly mapping pairs of unregistered and artifact-corrupted images. The ability of U-Dream to circumvent the need for accurately registered data makes it widely applicable to many biomedical image reconstruction tasks. We validate it in accelerated magnetic resonance imaging (MRI) by training an image reconstruction model directly on pairs of undersampled measurements from images that have undergone nonrigid deformations.},
	urldate = {2024-09-07},
	booktitle = {2021 {IEEE} 18th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Gan, Weijie and Sun, Yu and Eldeniz, Cihat and Liu, Jiaming and An, Hongyu and Kamilov, Ulugbek S.},
	month = apr,
	year = {2021},
	keywords = {Biomedical measurement, Image reconstruction, Image registration, Magnetic resonance imaging, Neural networks, Reconstruction algorithms, Task analysis, Training, deep learning, deformable image registration, magnetic resonance imaging},
	pages = {1531--1534},
}

@article{gan_deformation-compensated_2022,
	title = {Deformation-{Compensated} {Learning} for {Image} {Reconstruction} {Without} {Ground} {Truth}},
	volume = {41},
	issn = {1558-254X},
	doi = {10.1109/TMI.2022.3163018},
	abstract = {Deep neural networks for medical image reconstruction are traditionally trained using high-quality ground-truth images as training targets. Recent work on Noise2Noise (N2N) has shown the potential of using multiple noisy measurements of the same object as an alternative to having a ground-truth. However, existing N2N-based methods are not suitable for learning from the measurements of an object undergoing nonrigid deformation. This paper addresses this issue by proposing the deformation-compensated learning (DeCoLearn) method for training deep reconstruction networks by compensating for object deformations. A key component of DeCoLearn is a deep registration module, which is jointly trained with the deep reconstruction network without any ground-truth supervision. We validate DeCoLearn on both simulated and experimentally collected magnetic resonance imaging (MRI) data and show that it significantly improves imaging quality.},
	number = {9},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Gan, Weijie and Sun, Yu and Eldeniz, Cihat and Liu, Jiaming and An, Hongyu and Kamilov, Ulugbek S.},
	month = sep,
	year = {2022},
	keywords = {Convolutional neural networks, Image reconstruction, Imaging, Inverse problems, Magnetic resonance imaging, Noise measurement, Strain, Training, deep learning, image reconstruction, magnetic resonance imaging (MRI)},
	pages = {2371--2384},
}

@article{hendriksen_noise2inverse_2020,
	title = {{Noise2Inverse}: {Self}-{Supervised} {Deep} {Convolutional} {Denoising} for {Tomography}},
	volume = {6},
	doi = {10.1109/TCI.2020.3019647},
	abstract = {Recovering a high-quality image from noisy indirect measurements is an important problem with many applications. For such inverse problems, supervised deep convolutional neural network (CNN)-based denoising methods have shown strong results, but the success of these supervised methods critically depends on the availability of a high-quality training dataset of similar measurements. For image denoising, methods are available that enable training without a separate training dataset by assuming that the noise in two different pixels is uncorrelated. However, this assumption does not hold for inverse problems, resulting in artifacts in the denoised images produced by existing methods. Here, we propose Noise2Inverse, a deep CNN-based denoising method for linear image reconstruction algorithms that does not require any additional clean or noisy data. Training a CNN-based denoiser is enabled by exploiting the noise model to compute multiple statistically independent reconstructions. We develop a theoretical framework which shows that such training indeed obtains a denoising CNN, assuming the measured noise is element-wise independent, and zero-mean. On simulated CT datasets, Noise2Inverse demonstrates an improvement in peak signal-to-noise ratio and structural similarity index compared to state-of-the-art image denoising methods, and conventional reconstruction methods, such as Total-Variation Minimization. We also demonstrate that the method is able to significantly reduce noise in challenging real-world experimental datasets.},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Hendriksen, Allard Adriaan and Pelt, Daniël Maria and Batenburg, K. Joost},
	year = {2020},
	keywords = {Deep learning, Image denoising, Image reconstruction, Imaging, Inverse problems, Noise measurement, Noise reduction, Training, image reconstruction, inverse problems, reconstruction algorithms, tomography},
	pages = {1320--1335},
}

@inproceedings{hu_self-supervised_2021,
	address = {Cham},
	title = {Self-supervised {Learning} for {MRI} {Reconstruction} with a {Parallel} {Network} {Training} {Framework}},
	isbn = {978-3-030-87231-1},
	doi = {10.1007/978-3-030-87231-1_37},
	abstract = {Image reconstruction from undersampled k-space data plays an important role in accelerating the acquisition of MR data, and a lot of deep learning-based methods have been exploited recently. Despite the achieved inspiring results, the optimization of these methods commonly relies on the fully-sampled reference data, which are time-consuming and difficult to collect. To address this issue, we propose a novel self-supervised learning method. Specifically, during model optimization, two subsets are constructed by randomly selecting part of k-space data from the undersampled data and then fed into two parallel reconstruction networks to perform information recovery. Two reconstruction losses are defined on all the scanned data points to enhance the network’s capability of recovering the frequency information. Meanwhile, to constrain the learned unscanned data points of the network, a difference loss is designed to enforce consistency between the two parallel networks. In this way, the reconstruction model can be properly trained with only the undersampled data. During the model evaluation, the undersampled data are treated as the inputs and either of the two trained networks is expected to reconstruct the high-quality results. The proposed method is flexible and can be employed in any existing deep learning-based method. The effectiveness of the method is evaluated on an open brain MRI dataset. Experimental results demonstrate that the proposed self-supervised method can achieve competitive reconstruction performance compared to the corresponding supervised learning method at high acceleration rates (4 and 8). The code is publicly available at https://github.com/chenhu96/Self-Supervised-MRI-Reconstruction.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2021},
	publisher = {Springer International Publishing},
	author = {Hu, Chen and Li, Cheng and Wang, Haifeng and Liu, Qiegen and Zheng, Hairong and Wang, Shanshan},
	editor = {de Bruijne, Marleen and Cattin, Philippe C. and Cotin, Stéphane and Padoy, Nicolas and Speidel, Stefanie and Zheng, Yefeng and Essert, Caroline},
	year = {2021},
	keywords = {Deep learning, Image reconstruction, Parallel network, Self-supervised learning},
	pages = {382--391},
}

@misc{hu_spicer_2024,
	title = {{SPICER}: {Self}-{Supervised} {Learning} for {MRI} with {Automatic} {Coil} {Sensitivity} {Estimation} and {Reconstruction}},
	shorttitle = {{SPICER}},
	url = {http://arxiv.org/abs/2210.02584},
	doi = {10.48550/arXiv.2210.02584},
	abstract = {Deep model-based architectures (DMBAs) integrating physical measurement models and learned image regularizers are widely used in parallel magnetic resonance imaging (PMRI). Traditional DMBAs for PMRI rely on pre-estimated coil sensitivity maps (CSMs) as a component of the measurement model. However, estimation of accurate CSMs is a challenging problem when measurements are highly undersampled. Additionally, traditional training of DMBAs requires high-quality groundtruth images, limiting their use in applications where groundtruth is difficult to obtain. This paper addresses these issues by presenting SPICE as a new method that integrates self-supervised learning and automatic coil sensitivity estimation. Instead of using pre-estimated CSMs, SPICE simultaneously reconstructs accurate MR images and estimates high-quality CSMs. SPICE also enables learning from undersampled noisy measurements without any groundtruth. We validate SPICE on experimentally collected data, showing that it can achieve state-of-the-art performance in highly accelerated data acquisition settings (up to 10x).},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Hu, Yuyang and Gan, Weijie and Ying, Chunwei and Wang, Tongyao and Eldeniz, Cihat and Liu, Jiaming and Chen, Yasheng and An, Hongyu and Kamilov, Ulugbek S.},
	month = jun,
	year = {2024},
	note = {arXiv:2210.02584 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{huang_self-supervised_2024,
	title = {Self-{Supervised} {Deep} {Unrolled} {Reconstruction} {Using} {Regularization} by {Denoising}},
	volume = {43},
	issn = {1558-254X},
	url = {https://ieeexplore.ieee.org/document/10318101},
	doi = {10.1109/TMI.2023.3332614},
	abstract = {Deep learning methods have been successfully used in various computer vision tasks. Inspired by that success, deep learning has been explored in magnetic resonance imaging (MRI) reconstruction. In particular, integrating deep learning and model-based optimization methods has shown considerable advantages. However, a large amount of labeled training data is typically needed for high reconstruction quality, which is challenging for some MRI applications. In this paper, we propose a novel reconstruction method, named DURED-Net, that enables interpretable self-supervised learning for MR image reconstruction by combining a self-supervised denoising network and a plug-and-play method. We aim to boost the reconstruction performance of Noise2Noise in MR reconstruction by adding an explicit prior that utilizes imaging physics. Specifically, the leverage of a denoising network for MRI reconstruction is achieved using Regularization by Denoising (RED). Experiment results demonstrate that the proposed method requires a reduced amount of training data to achieve high reconstruction quality among the state-of-the-art approaches utilizing Noise2Noise.},
	number = {3},
	urldate = {2025-02-20},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Huang, Peizhou and Zhang, Chaoyi and Zhang, Xiaoliang and Li, Xiaojuan and Dong, Liang and Ying, Leslie},
	month = mar,
	year = {2024},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Image reconstruction, Imaging, Iterative methods, Magnetic resonance image reconstruction, Magnetic resonance imaging, Noise reduction, Training, Training data, deep neural network, regularization by denoising, self-supervised},
	pages = {1203--1213},
}

@misc{kawar_gsure-based_2024,
	title = {{GSURE}-{Based} {Diffusion} {Model} {Training} with {Corrupted} {Data}},
	url = {http://arxiv.org/abs/2305.13128},
	doi = {10.48550/arXiv.2305.13128},
	abstract = {Diffusion models have demonstrated impressive results in both data generation and downstream tasks such as inverse problems, text-based editing, classification, and more. However, training such models usually requires large amounts of clean signals which are often difficult or impossible to obtain. In this work, we propose a novel training technique for generative diffusion models based only on corrupted data. We introduce a loss function based on the Generalized Stein's Unbiased Risk Estimator (GSURE), and prove that under some conditions, it is equivalent to the training objective used in fully supervised diffusion models. We demonstrate our technique on face images as well as Magnetic Resonance Imaging (MRI), where the use of undersampled data significantly alleviates data collection costs. Our approach achieves generative performance comparable to its fully supervised counterpart without training on any clean signals. In addition, we deploy the resulting diffusion model in various downstream tasks beyond the degradation present in the training set, showcasing promising results.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Kawar, Bahjat and Elata, Noam and Michaeli, Tomer and Elad, Michael},
	month = jun,
	year = {2024},
	note = {arXiv:2305.13128 [eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{liu_rare_2020,
	title = {{RARE}: {Image} {Reconstruction} {Using} {Deep} {Priors} {Learned} {Without} {Groundtruth}},
	volume = {14},
	url = {https://ieeexplore.ieee.org/document/9103213},
	doi = {10.1109/JSTSP.2020.2998402},
	abstract = {Regularization by denoising (RED) is an image reconstruction framework that uses an image denoiser as a prior. Recent work has shown the state-of-the-art performance of RED with learned denoisers corresponding to pre-trained convolutional neural nets (CNNs). In this work, we propose to broaden the current denoiser-centric view of RED by considering priors corresponding to networks trained for more general artifact-removal. The key benefit of the proposed family of algorithms, called regularization by artifact-removal (RARE), is that it can leverage priors learned on datasets containing only undersampled measurements. This makes RARE applicable to problems where it is practically impossible to have fully-sampled groundtruth data for training. We validate RARE on both simulated and experimentally collected data by reconstructing a free-breathing whole-body 3D MRIs into ten respiratory phases from heavily undersampled k-space measurements. Our results corroborate the potential of learning regularizers for iterative inversion directly on undersampled and noisy measurements.},
	number = {6},
	urldate = {2024-08-31},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Liu, Jiaming and Sun, Yu and Eldeniz, Cihat and Gan, Weijie and An, Hongyu and Kamilov, Ulugbek S.},
	month = oct,
	year = {2020},
	keywords = {Deep learning, Image denoising, Image reconstruction, Imaging inverse problems, Inverse problems, MRI, Magnetic resonance imaging, Noise measurement, deep learning, plug-and-play priors, regularization by denoising},
	pages = {1088--1099},
}

@misc{metzler_unsupervised_2020,
	title = {Unsupervised {Learning} with {Stein}'s {Unbiased} {Risk} {Estimator}},
	url = {http://arxiv.org/abs/1805.10531},
	doi = {10.48550/arXiv.1805.10531},
	abstract = {Learning from unlabeled and noisy data is one of the grand challenges of machine learning. As such, it has seen a flurry of research with new ideas proposed continuously. In this work, we revisit a classical idea: Stein's Unbiased Risk Estimator (SURE). We show that, in the context of image recovery, SURE and its generalizations can be used to train convolutional neural networks (CNNs) for a range of image denoising and recovery problems without any ground truth data. Specifically, our goal is to reconstruct an image \$x\$ from a noisy linear transformation (measurement) of the image. We consider two scenarios: one where no additional data is available and one where we have measurements of other images that are drawn from the same noisy distribution as \$x\$, but have no access to the clean images. Such is the case, for instance, in the context of medical imaging, microscopy, and astronomy, where noise-less ground truth data is rarely available. We show that in this situation, SURE can be used to estimate the mean-squared-error loss associated with an estimate of \$x\$. Using this estimate of the loss, we train networks to perform denoising and compressed sensing recovery. In addition, we also use the SURE framework to partially explain and improve upon an intriguing results presented by Ulyanov et al. in "Deep Image Prior": that a network initialized with random weights and fit to a single noisy image can effectively denoise that image. Public implementations of the networks and methods described in this paper can be found at https://github.com/ricedsp/D-AMP\_Toolbox.},
	urldate = {2025-02-20},
	publisher = {arXiv},
	author = {Metzler, Christopher A. and Mousavi, Ali and Heckel, Reinhard and Baraniuk, Richard G.},
	month = jul,
	year = {2020},
	note = {arXiv:1805.10531 [stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{millard_clean_2024,
	title = {Clean self-supervised {MRI} reconstruction from noisy, sub-sampled training data with {Robust} {SSDU}},
	url = {http://arxiv.org/abs/2210.01696},
	doi = {10.48550/arXiv.2210.01696},
	abstract = {Most existing methods for Magnetic Resonance Imaging (MRI) reconstruction with deep learning use fully supervised training, which assumes that a high signal-to-noise ratio (SNR), fully sampled dataset is available for training. In many circumstances, however, such a dataset is highly impractical or even technically infeasible to acquire. Recently, a number of self-supervised methods for MR reconstruction have been proposed, which use sub-sampled data only. However, the majority of such methods, such as Self-Supervised Learning via Data Undersampling (SSDU), are susceptible to reconstruction errors arising from noise in the measured data. In response, we propose Robust SSDU, which provably recovers clean images from noisy, sub-sampled training data by simultaneously estimating missing k-space samples and denoising the available samples. Robust SSDU trains the reconstruction network to map from a further noisy and sub-sampled version of the data to the original, singly noisy and sub-sampled data, and applies an additive Noisier2Noise correction term at inference. We also present a related method, Noiser2Full, that recovers clean images when noisy, fully sampled data is available for training. Both proposed methods are applicable to any network architecture, straight-forward to implement and have similar computational cost to standard training. We evaluate our methods on the multi-coil fastMRI brain dataset with a novel denoising-specific architecture and find that it performs competitively with a benchmark trained on clean, fully sampled data.},
	urldate = {2025-02-17},
	publisher = {arXiv},
	author = {Millard, Charles and Chiew, Mark},
	month = jun,
	year = {2024},
	note = {arXiv:2210.01696 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{millard_theoretical_2023,
	title = {A {Theoretical} {Framework} for {Self}-{Supervised} {MR} {Image} {Reconstruction} {Using} {Sub}-{Sampling} via {Variable} {Density} {Noisier2Noise}},
	volume = {9},
	url = {https://ieeexplore.ieee.org/document/10194985?denied=},
	doi = {10.1109/TCI.2023.3299212},
	abstract = {In recent years, there has been attention on leveraging the statistical modeling capabilities of neural networks for reconstructing sub-sampled Magnetic Resonance Imaging (MRI) data. Most proposed methods assume the existence of a representative fully-sampled dataset and use fully-supervised training. However, for many applications, fully sampled training data is not available, and may be highly impractical to acquire. The development and understanding of self-supervised methods, which use only sub-sampled data for training, are therefore highly desirable. This work extends the Noisier2Noise framework, which was originally constructed for self-supervised denoising tasks, to variable density sub-sampled MRI data. We use the Noisier2Noise framework to analytically explain the performance of Self-Supervised Learning via Data Undersampling (SSDU), a recently proposed method that performs well in practice but until now lacked theoretical justification. Further, we propose two modifications of SSDU that arise as a consequence of the theoretical developments. Firstly, we propose partitioning the sampling set so that the subsets have the same type of distribution as the original sampling mask. Secondly, we propose a loss weighting that compensates for the sampling and partitioning densities. On the fastMRI dataset we show that these changes significantly improve SSDU's image restoration quality and robustness to the partitioning parameters.},
	urldate = {2024-08-31},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Millard, Charles and Chiew, Mark},
	year = {2023},
	keywords = {Deep learning, Image reconstruction, Imaging, Magnetic resonance imaging, Random variables, Standards, Training, Training data, image reconstruction, magnetic resonance imaging},
	pages = {707--720},
}

@misc{moran_noisier2noise_2019,
	title = {{Noisier2Noise}: {Learning} to {Denoise} from {Unpaired} {Noisy} {Data}},
	shorttitle = {{Noisier2Noise}},
	doi = {10.48550/arXiv.1910.11908},
	abstract = {We present a method for training a neural network to perform image denoising without access to clean training examples or access to paired noisy training examples. Our method requires only a single noisy realization of each training example and a statistical model of the noise distribution, and is applicable to a wide variety of noise models, including spatially structured noise. Our model produces results which are competitive with other learned methods which require richer training data, and outperforms traditional non-learned denoising methods. We present derivations of our method for arbitrary additive noise, an improvement specific to Gaussian additive noise, and an extension to multiplicative Bernoulli noise.},
	publisher = {arXiv},
	author = {Moran, Nick and Schmidt, Dan and Zhong, Yu and Coady, Patrick},
	month = oct,
	year = {2019},
	note = {arXiv:1910.11908 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{oh_unpaired_2020,
	title = {Unpaired {Deep} {Learning} for {Accelerated} {MRI} {Using} {Optimal} {Transport} {Driven} {CycleGAN}},
	volume = {6},
	issn = {2333-9403},
	url = {https://ieeexplore.ieee.org/document/9173689},
	doi = {10.1109/TCI.2020.3018562},
	abstract = {Recently, deep learning approaches for accelerated MRI have been extensively studied thanks to their high performance reconstruction in spite of significantly reduced run-time complexity. These neural networks are usually trained in a supervised manner, so matched pairs of subsampled, and fully sampled k-space data are required. Unfortunately, it is often difficult to acquire matched fully sampled k-space data, since the acquisition of fully sampled k-space data requires long scan time, and often leads to the change of the acquisition protocol. Therefore, unpaired deep learning without matched label data has become a very important research topic. In this article, we propose an unpaired deep learning approach using a optimal transport driven cycle-consistent generative adversarial network (OT-cycleGAN) that employs a single pair of generator, and discriminator. The proposed OT-cycleGAN architecture is rigorously derived from a dual formulation of the optimal transport formulation using a specially designed penalized least squares cost. The experimental results show that our method can reconstruct high resolution MR images from accelerated k-space data from both single, and multiple coil acquisition, without requiring matched reference data.},
	urldate = {2025-02-13},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Oh, Gyutaek and Sim, Byeongsu and Chung, HyungJin and Sunwoo, Leonard and Ye, Jong Chul},
	year = {2020},
	note = {Conference Name: IEEE Transactions on Computational Imaging},
	keywords = {Accelerated MRI, Acceleration, Deep learning, Gallium nitride, Generative adversarial networks, Image reconstruction, Magnetic resonance imaging, cycleGAN, optimal transport, penalized least squares (PLS), unpaired deep learning},
	pages = {1285--1296},
}

@inproceedings{pajot_unsupervised_2018,
	title = {Unsupervised {Adversarial} {Image} {Reconstruction}},
	abstract = {We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the {\textbackslash}textit\{maximum a posteriori\} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Pajot, Arthur and Bezenac, Emmanuel de and Gallinari, Patrick},
	month = sep,
	year = {2018},
}

@article{shafique_mri_2024,
	title = {{MRI} {Recovery} with {Self}-{Calibrated} {Denoisers} without {Fully}-{Sampled} {Data}},
	volume = {38},
	issn = {1352-8661},
	url = {http://arxiv.org/abs/2304.12890},
	doi = {10.1007/s10334-024-01207-1},
	abstract = {Objective: Acquiring fully sampled training data is challenging for many MRI applications. We present a self-supervised image reconstruction method, termed ReSiDe, capable of recovering images solely from undersampled data. Materials and Methods: ReSiDe is inspired by plug-and-play (PnP) methods, but unlike traditional PnP approaches that utilize pre-trained denoisers, ReSiDe iteratively trains the denoiser on the image or images that are being reconstructed. We introduce two variations of our method: ReSiDe-S and ReSiDe-M. ReSiDe-S is scan-specific and works with a single set of undersampled measurements, while ReSiDe-M operates on multiple sets of undersampled measurements and provides faster inference. Studies I, II, and III compare ReSiDe-S and ReSiDe-M against other self-supervised or unsupervised methods using data from T1- and T2-weighted brain MRI, MRXCAT digital perfusion phantom, and first-pass cardiac perfusion, respectively. Results: ReSiDe-S and ReSiDe-M outperform other methods in terms of peak signal-to-noise ratio and structural similarity index measure for Studies I and II, and in terms of expert scoring for Study III. Discussion: We present a self-supervised image reconstruction method and validate it in both static and dynamic MRI applications. These developments can benefit MRI applications where the availability of fully sampled training data is limited.},
	number = {1},
	urldate = {2025-02-20},
	journal = {Magnetic Resonance Materials in Physics, Biology and Medicine},
	author = {Shafique, Muhammad and Liu, Sizhuo and Schniter, Philip and Ahmad, Rizwan},
	month = oct,
	year = {2024},
	note = {arXiv:2304.12890 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
	pages = {53--66},
}

@article{shen_nerp_2024,
	title = {{NeRP}: {Implicit} {Neural} {Representation} {Learning} {With} {Prior} {Embedding} for {Sparsely} {Sampled} {Image} {Reconstruction}},
	volume = {35},
	issn = {2162-2388},
	shorttitle = {{NeRP}},
	url = {https://ieeexplore.ieee.org/document/9788018},
	doi = {10.1109/TNNLS.2022.3177134},
	abstract = {Image reconstruction is an inverse problem that solves for a computational image based on sampled sensor measurement. Sparsely sampled image reconstruction poses additional challenges due to limited measurements. In this work, we propose a methodology of implicit Neural Representation learning with Prior embedding (NeRP) to reconstruct a computational image from sparsely sampled measurements. The method differs fundamentally from previous deep learning-based image reconstruction approaches in that NeRP exploits the internal information in an image prior and the physics of the sparsely sampled measurements to produce a representation of the unknown subject. No large-scale data is required to train the NeRP except for a prior image and sparsely sampled measurements. In addition, we demonstrate that NeRP is a general methodology that generalizes to different imaging modalities such as computed tomography (CT) and magnetic resonance imaging (MRI). We also show that NeRP can robustly capture the subtle yet significant image changes required for assessing tumor progression.},
	number = {1},
	urldate = {2025-02-19},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Shen, Liyue and Pauly, John and Xing, Lei},
	month = jan,
	year = {2024},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Computed tomography, Deep learning, Image reconstruction, Imaging, Implicit neural representation, Magnetic resonance imaging, Neural networks, Training, inverse problem, prior embedding, sparsely sampled image reconstruction},
	pages = {770--782},
}

@misc{tachella_deepinverse_2023,
	title = {{DeepInverse}: {A} deep learning framework for inverse problems in imaging},
	url = {https://github.com/deepinv/deepinv},
	author = {Tachella, Julian and Chen, Dongdong and Hurault, Samuel and Terris, Matthieu and Wang, Andrew},
	month = jun,
	year = {2023},
	doi = {10.5281/zenodo.7982256},
}

@inproceedings{tachella_unsupervised_2022,
	title = {Unsupervised {Learning} to {Solve} {Inverse} {Problems}: {Application} to {Single}-{Pixel} {Imaging}},
	abstract = {In recent years, learning-based approaches have obtained state-of-the-art performance in multiple imaging inverse problems ranging from medical imaging to computational photography. These methods generally require pairs of signals and associated measurements for training. However, in various imaging problems, we usually only have access to compressed measurements of the underlying signals, hindering this learning-based approach. Learning from measurement data only is impossible in general, as the compressed observations do not contain information in the nullspace of the forward sensing operator. The recent equivariant imaging framework overcomes this limitation by exploiting the invariance to transformations (translations, rotations, etc.) present in natural signals. In this paper, we leverage this novel unsupervised learning framework for reconstructing single-pixel imaging data from compressed measurements alone. A series of experiments show that the proposed method performs comparably to the standard supervised approach.},
	language = {en},
	booktitle = {{XXVIIIème} {Colloque} {Francophone} de {Traitement} du {Signal} et des {Images} ({GRETSI} 2022)},
	author = {Tachella, Julian and Chen, Dongdong and Davies, Mike},
	month = sep,
	year = {2022},
}

@misc{tachella_unsure_2025,
	title = {{UNSURE}: self-supervised learning with {Unknown} {Noise} level and {Stein}'s {Unbiased} {Risk} {Estimate}},
	shorttitle = {{UNSURE}},
	url = {http://arxiv.org/abs/2409.01985},
	doi = {10.48550/arXiv.2409.01985},
	abstract = {Recently, many self-supervised learning methods for image reconstruction have been proposed that can learn from noisy data alone, bypassing the need for ground-truth references. Most existing methods cluster around two classes: i) Stein's Unbiased Risk Estimate (SURE) and similar approaches that assume full knowledge of the noise distribution, and ii) Noise2Self and similar cross-validation methods that require very mild knowledge about the noise distribution. The first class of methods tends to be impractical, as the noise level is often unknown in real-world applications, and the second class is often suboptimal compared to supervised learning. In this paper, we provide a theoretical framework that characterizes this expressivity-robustness trade-off and propose a new approach based on SURE, but unlike the standard SURE, does not require knowledge about the noise level. Throughout a series of experiments, we show that the proposed estimator outperforms other existing self-supervised methods on various imaging inverse problems.},
	urldate = {2025-02-17},
	publisher = {arXiv},
	author = {Tachella, Julián and Davies, Mike and Jacques, Laurent},
	month = feb,
	year = {2025},
	note = {arXiv:2409.01985 [stat]},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
}

@misc{wang_fully_2024,
	title = {Fully {Unsupervised} {Dynamic} {MRI} {Reconstruction} via {Diffeo}-{Temporal} {Equivariance}},
	url = {http://arxiv.org/abs/2410.08646},
	doi = {10.48550/arXiv.2410.08646},
	abstract = {Reconstructing dynamic MRI image sequences from undersampled accelerated measurements is crucial for faster and higher spatiotemporal resolution real-time imaging of cardiac motion, free breathing motion and many other applications. Classical paradigms, such as gated cine MRI, assume periodicity, disallowing imaging of true motion. Supervised deep learning methods are fundamentally flawed as, in dynamic imaging, ground truth fully-sampled videos are impossible to truly obtain. We propose an unsupervised framework to learn to reconstruct dynamic MRI sequences from undersampled measurements alone by leveraging natural geometric spatiotemporal equivariances of MRI. Dynamic Diffeomorphic Equivariant Imaging (DDEI) significantly outperforms state-of-the-art unsupervised methods such as SSDU on highly accelerated dynamic cardiac imaging. Our method is agnostic to the underlying neural network architecture and can be used to adapt the latest models and post-processing approaches. Our code and video demos are at https://github.com/Andrewwango/ddei.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Wang, Andrew and Davies, Mike},
	month = oct,
	year = {2024},
	note = {arXiv:2410.08646 [eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{wang_perspective-equivariance_2024,
	title = {Perspective-{Equivariance} for {Unsupervised} {Imaging} with {Camera} {Geometry}},
	shorttitle = {Perspective-{Equivariant} {Imaging}},
	doi = {10.48550/arXiv.2403.09327},
	abstract = {Ill-posed image reconstruction problems appear in many scenarios such as remote sensing, where obtaining high quality images is crucial for environmental monitoring, disaster management and urban planning. Deep learning has seen great success in overcoming the limitations of traditional methods. However, these inverse problems rarely come with ground truth data, highlighting the importance of unsupervised learning from partial and noisy measurements alone. We propose perspective-equivariant imaging (EI), a framework that leverages perspective variability in optical camera-based imaging systems, such as satellites or handheld cameras, to recover information lost in ill-posed optical camera imaging problems. This extends previous EI work to include a much richer non-linear class of group transforms and is shown to be an excellent prior for satellite and urban image data, where perspective-EI achieves state-of-the-art results in multispectral pansharpening, outperforming other unsupervised methods in the literature. Code at https://andrewwango.github.io/perspective-equivariant-imaging},
	publisher = {arXiv},
	author = {Wang, Andrew and Davies, Mike},
	month = mar,
	year = {2024},
	note = {arXiv:2403.09327 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{yaman_self-supervised_2020,
	title = {Self-supervised learning of physics-guided reconstruction neural networks without fully sampled reference data},
	volume = {84},
	doi = {10.1002/mrm.28378},
	abstract = {Purpose To develop a strategy for training a physics-guided MRI reconstruction neural network without a database of fully sampled data sets. Methods Self-supervised learning via data undersampling (SSDU) for physics-guided deep learning reconstruction partitions available measurements into two disjoint sets, one of which is used in the data consistency (DC) units in the unrolled network and the other is used to define the loss for training. The proposed training without fully sampled data is compared with fully supervised training with ground-truth data, as well as conventional compressed-sensing and parallel imaging methods using the publicly available fastMRI knee database. The same physics-guided neural network is used for both proposed SSDU and supervised training. The SSDU training is also applied to prospectively two-fold accelerated high-resolution brain data sets at different acceleration rates, and compared with parallel imaging. Results Results on five different knee sequences at an acceleration rate of 4 shows that the proposed self-supervised approach performs closely with supervised learning, while significantly outperforming conventional compressed-sensing and parallel imaging, as characterized by quantitative metrics and a clinical reader study. The results on prospectively subsampled brain data sets, in which supervised learning cannot be used due to lack of ground-truth reference, show that the proposed self-supervised approach successfully performs reconstruction at high acceleration rates (4, 6, and 8). Image readings indicate improved visual reconstruction quality with the proposed approach compared with parallel imaging at acquisition acceleration. Conclusion The proposed SSDU approach allows training of physics-guided deep learning MRI reconstruction without fully sampled data, while achieving comparable results with supervised deep learning MRI trained on fully sampled data.},
	language = {en},
	number = {6},
	journal = {Magnetic Resonance in Medicine},
	author = {Yaman, Burhaneddin and Hosseini, Seyed Amir Hossein and Moeller, Steen and Ellermann, Jutta and Uğurbil, Kâmil and Akçakaya, Mehmet},
	year = {2020},
	keywords = {accelerated imaging, convolutional neural networks, deep learning, image reconstruction, parallel imaging, self-supervised learning},
	pages = {3172--3191},
}

@article{zhou_dual-domain_2022,
	title = {Dual-domain self-supervised learning for accelerated non-{Cartesian} {MRI} reconstruction},
	volume = {81},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522001852},
	doi = {10.1016/j.media.2022.102538},
	abstract = {While enabling accelerated acquisition and improved reconstruction accuracy, current deep MRI reconstruction networks are typically supervised, require fully sampled data, and are limited to Cartesian sampling patterns. These factors limit their practical adoption as fully-sampled MRI is prohibitively time-consuming to acquire clinically. Further, non-Cartesian sampling patterns are particularly desirable as they are more amenable to acceleration and show improved motion robustness. To this end, we present a fully self-supervised approach for accelerated non-Cartesian MRI reconstruction which leverages self-supervision in both k-space and image domains. In training, the undersampled data are split into disjoint k-space domain partitions. For the k-space self-supervision, we train a network to reconstruct the input undersampled data from both the disjoint partitions and from itself. For the image-level self-supervision, we enforce appearance consistency obtained from the original undersampled data and the two partitions. Experimental results on our simulated multi-coil non-Cartesian MRI dataset demonstrate that DDSS can generate high-quality reconstruction that approaches the accuracy of the fully supervised reconstruction, outperforming previous baseline methods. Finally, DDSS is shown to scale to highly challenging real-world clinical MRI reconstruction acquired on a portable low-field (0.064 T) MRI scanner with no data available for supervised training while demonstrating improved image quality as compared to traditional reconstruction, as determined by a radiologist study.},
	urldate = {2025-02-22},
	journal = {Medical Image Analysis},
	author = {Zhou, Bo and Schlemper, Jo and Dey, Neel and Mohseni Salehi, Seyed Sadegh and Sheth, Kevin and Liu, Chi and Duncan, James S. and Sofka, Michal},
	month = oct,
	year = {2022},
	keywords = {Accelerated MRI, Dual-domain learning, Low-field portable MRI, Non-Cartesian MRI, Self-supervised learning},
	pages = {102538},
}

