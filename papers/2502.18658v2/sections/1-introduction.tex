\section{Introduction}
% ::::TOPIC SENTENCES::::
% While there are guidelines from Horwitz and human-AI interaction, the rules are vague about how to apply in programming context, specifically timing of assistance, type of assistance, visibility of actions, etc.
% We implemented system as a design probe to explore the benefits and drawbacks of a proactive programming assistant and offer design implications
% We report findings…

% PARAGRAPH 1: LLM Programming tools and limitations to existing approaches
% LLM programming tools are becoming popular, becoming integrated into software engineering workflows
Large language models (LLMs) have enabled generative programming assistance tools to provide powerful in-situ developer support for novices and experts alike \cite{vaithilingam2022expectation, murillo2023exploreaccelerate, majeed2024novice, majeed2023intro, Khojah2024BeyondCG}.
Many existing LLM-based programming tools rely on user-initiated interactions, requiring prompts or partial code snippets as input to provide sufficient context and to trigger help-seeking \cite{vaithilingam2022expectation, Nam2023InIDEGI, Mcnutt2023OnTD, ross2023programmerassistant, jiang2022genline}.
These systems offer help in the form of code output and natural language explanations to assist users with coding tasks. 
However, research indicates that users invest considerable effort in formulating prompts, interpreting responses, assessing suggestions, and integrating results into their code \cite{Mozannar2022ReadingBT, vaithilingam2022expectation, jiang2022genline}. 
% REVISION DELETE
% This leads to substantial expression and evaluative costs as users navigate the gulfs of execution (crafting prompts) and evaluation (assessing AI-generated assistance) \cite{gulf1985norman}.

% Some preliminary tools are beginning to be more autonomous, providing proactive help (Genius by Diagram, Devin, etc.). But some tools (e.g. programmer’s assistant) avoid doing these (changing tools into collaborator)
% Identify the gap, citing mixed-initiative interface design and human-AI principles
To alleviate the user intent specification costs, recent AI programming tools and designs aim to become more autonomous, allowing the system to initiate interaction and provide proactive assistance.
Tools like Github Copilot \cite{githubcopilot} and Visual Studio’s IntelliCode \cite{Svyatkovskiy2020intellicode} offer the auto-completion feature, which fills the code line as the user is typing, to alleviate prompt engineering efforts and proactively provide in-situ support.
However, the AI tool's generated code is not always accurate and the output still requires significant user effort to verify \cite{vaithilingam2022expectation, Vaithilingam2023intellicode, Mozannar2022ReadingBT, liang2024usabilityCopilot}.
% , how users can invoke the AI assistance (i.e. explicit prompt and code snippet), and the modality of the assistance (i.e. natural language and code), all central categories outlined by the human-AI interaction guidelines.
To address this, commercial and research prototypes constructed intelligent AI agents with distinct focuses on the \revise{\emph{timing of assistance}}, \revise{\emph{the representation of the agent}}, and \revise{\emph{the scope of the interaction context}}, aiming to work with the user as collaborators and tackle coding tasks autonomously and preemptively.
These approaches involve advancing on the timing of auto-completion feature to proactively make intelligent file changes with an AI caret in the code editor \cite{cursorcopilot++}, representing the AI's presence in the editor with an automated AI cursor \cite{geniusbydiagram}, \revise{or grounding interactions context in different scopes, such as conversational dialogue \cite{copilotX, ross2023programmerassistant, ReplitAI}, specific code lines \cite{jiang2022genline, githubcopilot}, or an agent-managed workspace to tackle software engineering tasks autonomously \cite{devinAISWE, yang2024sweagentagentcomputerinterfacesenable, wang2024opendevinopenplatformai}}.
However, the effects of these new designs of system-driven programming assistance on the human workflows, compared to the existing user-initiated paradigm, remain to be explored.
% Efforts to develop proactive AI that provides automatic support have been explored across various domains, including personalized notifications for weather or calendars \cite{sun2016contextualintent, sarikaya2017digitalassistant}, health and fitness interventions \cite{schmidt2015fitness, rabbi2015healthfeedback}, and support for office workflows \cite{Baym2019clippy, Jacobs2019BeyondCC, matejka2011ambient}. 
% Well-designed, effective invocation of systems' proactive assistance can lower the cost of user manipulation, resolve uncertainties preemptively, and lead to unintentional learning of the system's functionalities \cite{matejka2011ambient, horwitz1999mixedinitiative, Sawyer_2014_learning}.
% Meanwhile, poorly designed proactive assistance can lead to negative user experiences, diminished control \cite{MORADIDAKHEL2023copilotliability, meurisch2020proactiveexpectation, barkhuus2003losecontrol}, and in some cases, rendering the tool ineffective \cite{meurisch2020proactiveexpectation, Baym2019clippy, Jacobs2019BeyondCC}.
% % Similarly, programming tools have explored designs of system assistance in non-text formats, such as visualization \cite{guo2013pythontutor}, code uncertainty highlights \cite{Vasconcelos2023GenerationPA}, and output preview \cite{jiang2022genline}.
% % However, these systems target assistance at each line of code, which does not necessarily generalize to the diverse context of user's help-seeking scenarios in programming.
% While general guidelines on designing mixed-initiative interfaces and human-AI interactions have been established \cite{horwitz1999mixedinitiative, amershi2019haiprinciple}, it is unclear how the design principles can be transferred to system designs under the context of LLM-assisted programming.
% For example, while the timing of assistance is one key metric of human-AI interaction design, existing AI programming systems almost always provide immediate response upon output generation without considering interruption to user's workflow.
Visions of more ``\textit{proactive}\footnote{\revise{In this paper, we refer to system-initiated assistance in the programming environment as ``proactive'' programming support.}}'' AI programmers additionally raise questions about the potential for harm. 
Researchers have raised on concerns that excessive automation without proper human control can lead to unreliable and unsafe systems \cite{Shneiderman_2020_hcai}, and thus some AI systems deliberately avoid proactive AI assistance \cite{ross2023programmerassistant}.
Therefore, there remain the questions of \revise{\emph{when}} should AI programming tools provide proactive support, \revise{\emph{how} should the support be delivered, and \emph{where} should the user interact with such support.} \revise{Subsequently}, what are the effects of a proactive AI programming tool on user experience? \revise{In which programming processes and tasks} is proactivity helpful, and where might it be harmful? 

\revise{This research explores the design space of proactive AI programming tools in three dimensions -- the timing of assistance, the representation of the AI programming tool, and the scope of interaction context.} We then evaluate the effects of this human-AI interaction paradigm on software engineering practice, illustrating the advantages and drawbacks to provide insights for future designs. We were guided by these research questions:
\begin{itemize}
    \item \textbf{RQ1:} How can we design \revise{proactive assistance in an AI programming tool} to reduce user effort?
    \item \textbf{RQ2:} What are the benefits and drawbacks of a proactive AI programming tool compared to user-initiated systems?
    \item \textbf{RQ3:} In which programming processes and task contexts can proactivity be helpful, and where can it be harmful?
    % \item \textbf{RQ2:} How can we design an AI agent that collaborates with the user and provides help in the code editor beyond textual response in code or conversational exchange?
    % \item \textbf{RQ3:} What are the effects of a proactive AI programming tool that provides non-language support compared to the existing AI programming tool interaction?
\end{itemize}

To answer these research questions, 
we \revise{incorporate} theories of \revise{interruption management, social transparency, and help-seeking behavior in programming (Fig.\ref{fig:theory}) to identify specific design rationales for each dimension}.
% Through the lens of social transparency, interactions with AI could evolve to feel more like partnerships, addressing expertise mismatches and adapting to developers' unique working contexts, enhancing human-machine teamwork \cite{bradshaw2013myth}.
Informed by prior literature, we develop \sys{}, a technology probe \cite{hutchinson2003techprobe} that employs an AI programming agent providing \emph{proactive timings of assistance} to explore different forms of human-AI programming collaboration.
\sys{}'s proactive abilities allow it to initiate interaction via messages (Fig.\ref{fig:ui}.a,e) in response to various user activities in the coding environment, and also to commit code edits directly in the editor (Fig.\ref{fig:ui}.c). 
To mitigate potential disruptions, we derive three design rationales for the timing to introduce assistance and operationalize them into six design principles in the context of a coding task and an editor environment (Table \ref{table:proactive-features}).
To \revise{evaluate designs of \emph{AI agent representations} in the editor}, we additionally implemented \textit{presence} features for the AI agent. 
In \sys{}, the agent presence is represented by a cursor and caret (Fig.\ref{fig:ui}.d,b), capable of autonomous movement around the editor, signaling its action, status, and attention focus. 
To \revise{evaluate different \emph{scopes of interaction}, both the agent and the user can utilize global chat messages \revise{on the side-panel}, or initialize locally-scoped threads of conversations called ``breakouts'', anchored to\revise{specific locations in the editor as context} (Fig.\ref{fig:ui}.a)}. 

To study the impact of proactive support in an autonomous coding agent on human-AI collaborative programming workflows, we conducted a within-subject experiment using three versions of \sys{} with 18 participants.
In the PromptOnly condition, the ablated system only responds to user prompts and in-line code comments, similar to ChatGPT \cite{chatgpt} and Github Copilot \cite{githubcopilot} with low to no proactive features. 
In the CodeGhost condition, the system proactively initiates interactions and assistance, but \revise{the interactions are constrained in the global context of chat messages and direct code changes, with no visual representation of the agent.} 
In the \sys{} condition, all of the agent's visual representation, \revise{scopes of interaction}, and proactive timing features are utilized. 

Our study showed that, through the heuristic-based timing to provide contextualized assistance at task boundaries, the CodeGhost condition reduced the time users took to comprehend system responses compared to the PromptOnly condition.
But it also caused workflow disruptions and diminished users' awareness of AI's actions, as participants reported a lack of clear signals for agent interaction and working context. 
In contrast, the \sys{} condition, with its agent visual presence and \revise{flexible context scope}, significantly lessened these disruptions and improved users' awareness of the AI, leading to a user experience more akin to collaborating with a partner than using a tool.
\revise{Participants felt ambivalent to adopt highly proactive programming assistants. Many embraced the efficiency and capability to allow developers to focus on high-level designs rather than low-level work, but some participants experienced a loss of code understanding, expressing concerns on maintainability and extendability of the code artifact.}
% However, in the latter two conditions, participants also experienced over a loss of control, ownership due to increased AI involvement in the task with proactive assistance.

In the discussion, we summarize our findings and propose five design implications for proactive assistance in human-AI programming.
% We also discuss participants' ambivalence to adopt a proactive AI tool due to concerns about code maintainability and scalability in real-life scenarios.
Through these findings, we present a deeper understanding of the impacts of proactive AI support on programming experience and identify key areas that require further research.
In this work, we contribute:
\begin{itemize}
    \item A design exploration to enable different interaction timings, \revise{visual representations, and interaction scopes} of proactive assistance that expand upon existing AI programming systems.
    \item \sys{}, as a technology probe that implements a proactive AI agent to study in-situ assistance and communication in programming support.
    \item A empirical study to assess the impact of proactive agent support in a code editor, providing design implications for future AI programming tools.
\end{itemize}

