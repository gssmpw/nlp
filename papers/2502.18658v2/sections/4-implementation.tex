\section{The \sys{} Probe}
In this section, we introduce three main components of the \sys{} probe and how they are implemented to achieve our design goals: \revise{timely proactive support, AI agent's visual representation, and multi-level scopes of interaction}, supporting modular comparisons of different mechanisms.
% The prototype integrates an LLM-powered AI agent in a Python editor environment. 
Below we detail the design and implementation of the probe.
% The AI administers proactive assistance and intervention via chat messages and direct code edits in the file (Fig.\ref{fig:ui}.e,c) and is represented by an autonomous cursor and caret (Fig.\ref{fig:ui}.d,b).
% To manage past human-AI interactions, the system allows both the user and the AI to create contextualized threads of conversation locally scoped in the file (Fig.\ref{fig:ui}.a).
% We detail the system tech stack and LLM configuration at the end of the section.

% Our prototype for \sys{} began as a Visual Studio Code\footnote{Visual Studio Code. Retrieved August 16, 2023 from \url{https://code.visualstudio.com/}} extension, since one of the primary objectives was to support as much of the development workflow as possible, including refactoring, executing, and debugging code. While using a full-fledged IDE was perfect for this, we quickly discovered that the extension API provided by VS Code was too limited, preventing us from exploring more novel features. For instance, it would have been impossible to overlay arbitrary shapes or graphics above the editor, which we needed to provide several presence features (\emph{e.g.} the assistant's cursor and caret).

% After this realization, we switched our prototype to a browser-based React\footnote{React. Retrieved August 16, 2023 from \url{https://react.dev/}} application. The code editor was implemented using Monaco Editor\footnote{Monaco Editor. Retrieved August 16, 2023 from \url{https://microsoft.github.io/monaco-editor/}}, which VS Code is also built on, allowing us to migrate much of the existing functionality from the extension to the web app. We also continued to use LangChain\footnote{LangChain. Retrieved August 16, 2023 from \url{https://docs.langchain.com/docs/}}, a JavaScript library for interacting with LLMs. LangChain provides a set of abstractions, like a memory interface for keeping track of past messages, an “agent executor” interface to configure your chosen model, and even custom tools (or functions) for the model to use. The latter feature was especially important when development on the prototype first began, since OpenAI had not yet released models designed to support function calling. Rather, we had to depend on LangChain’s built-in tools system, which was often unreliable. Following the release of OpenAI’s new function calling models (namely \verb|gpt-4-0613|)\footnote{Atty Eleti, Jeff Harris, and Logan Kilpatrick. 2023. Function calling and other API updates. Retrieved August 16, 2023 from \url{https://openai.com/blog/function-calling-and-other-api-updates}}, and a timely update to LangChain, we were quickly able to improve the performance and reliability of the system.

% Since we could no longer rely on VS Code’s built-in IDE features, we had to manually implement a code execution system. 

\subsection{\revise{Timely Proactive Programming Assistance}}
% \sys{} relies on function calling to enable the model to directly change the contents of the file by inserting, deleting, or replacing a range of lines. These functions are implemented using LangChain’s \verb|StructuredTool| class, which also provides a schema that the model uses to format the function arguments (\emph{e.g.} in the case of the insertion tool, a line number and the code to be inserted). When the model “calls” a function, LangChain formats the request using the tool’s schema, and then executes tool’s \verb|call| function, which contains code that initiates a Monaco Editor edit operation.
Timing services based on context is a key consideration in AI system design \cite{amershi2019haiprinciple}.
To explore the design for proactive timings specifically in the context of programming support, 
% we defined five types of system proactivity in response to user's nonverbal actions \todo{ref table}.
we adopted a set of findings from research on \textit{interruption management}, and distilled them down to three proactivity design principles \cite{Miyata1986, iqbal2005towards, czerwinski2000instant, bailey2001effects}. 
To operationalize, we instantiated six proactivity features in our design probe to minimize interruptions to the user (DG1), summarized in Table \ref{table:proactive-features}.
% While we inform our implementation with findings from human collaboration research, we do not claim that our probe is the optimal design for proactive intervention.
The proactive assistance in \sys{} serves to present one design approach that expands upon existing AI programming features, allowing us to investigate the effects of an AI agent equipped with highly proactive capabilities on users' programming workflow.

\textbf{The first principle} states that the most opportune moments for interruption occur during periods of low mental workload~\cite{bailey2001effects,czerwinski2000instant}. 
In our system, we predict low mental workloads when users are not performing actions, such as writing code, moving around the file, and selecting ranges (i.e. when the user is idle).
Since idleness could also mean the user is engaged in thoughts, the AI agent only intervenes after an extended period of inactivity in both editing and cursor movement, which could signal that the user is mentally stuck and needs assistance (Table \ref{table:proactive-features}, 1).
This is a rough estimation to interpret the user's working states, and future works could employ more advanced models to identify the user's cognitive process.
% In this case, a request with the user's idle status and relevant information, such as the user’s caret position in the editor and local code context, would be sent to the LLM. The AI agent would triage the situation and decide whether to intervene and what type of help to offer (Table \ref{table:proactive-features}, 1).


\begin{table*}[]
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{lll}
\hline
\textbf{User Action} &
  \textbf{System Reaction Trigger} &
  \textbf{Possible Action Space} \\ \hline
\multicolumn{3}{l}{\textbf{Design Rationale 1:} intervene at moments of low mental workload \cite{bailey2001effects, czerwinski2000instant}} \\ \hline
\multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}1. User has been idle\\ (no code edit, \\ caret movement, \\ or selection change)\end{tabular}} &
  \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Initial idle threshold is 30 seconds.\\ If user ignores and maintains idle,\\ add 30 seconds to the threshold.\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}1. If the user is on an empty \\ or trivial line (e.g. pass), no response\\ 2. Offer help via message\end{tabular} \\ \hline
\multicolumn{3}{l}{\begin{tabular}[c]{@{}l@{}}\textbf{Design Rationale 2:} intervene at task boundary (i.e. when completed one subtask and formulating the next) \cite{iqbal2005towards, Miyata1986}\end{tabular}} \\ \hline
\multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}2. User has completed \\ a block of code\end{tabular}} &
  \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User outdents from a code scope in Python \\ (e.g. an if- statement, loop, or function).\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}1. If block is insignificant, no response\\ 2. Notify user of code issues\\ 3. Suggest optimization to user\\ 4. Adds documentation in editor\end{tabular} \\ \hline
\multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}3. User has executed \\ the program\end{tabular}} &
  \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User executes the program in editor.\\ Output displays in console.\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}Acknowledge the code execution. \\ If output contains error, offer to help.\end{tabular} \\ \hline
\multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}4. User has made \\ a multi-line \\ code change\end{tabular}} &
  \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User pastes code \\ that's more than 1 line.\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}1. If change is insignificant, no response\\ 2. Add documentation in editor\\ 3. Notify user of code issues\end{tabular} \\ \hline
\multicolumn{3}{l}{\textbf{Design Rationale 3:} intervene when user is potentially communicating through implicit signals \cite{Nam2023InIDEGI,githubcopilot,copilotX}} \\ \hline
\multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}5. User has made \\ a code comment\end{tabular}} &
  \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User starts a newline after \\ a single line or multi-line comment.\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}1. If nothing to address, no response\\ 2. If the comment describes function, \\ generate code suggestion\\ 3. If posing a question, offer help\end{tabular} \\ \hline
\multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}6. User maintains selection \\ on a range of code\end{tabular}} &
  \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Initial selection threshold is 15 seconds. \\ If user ignores and maintains selection, \\ add 15 seconds to the threshold.\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}1. If insignificant selection, no response\\ 2. Explain the selected code\\ 3. Analyze selection to error-check\end{tabular}
\\ \hline
\end{tabular}
\caption{\textbf{Proactivity features in \sys{}}. \textnormal{The table details the design rationales derived from interruption management literature \cite{Miyata1986, iqbal2005towards, czerwinski2000instant, bailey2001effects} and prior tools \cite{copilotX, githubcopilot, Nam2023InIDEGI}. We designed six proactivity features triggered by user activities. \revise{For each feature, the AI agent evaluates the working context (i.e. the changed code, the user's caret location, and local file content) provided via prompts (Appendix \ref{appendix:prompt}) and decides on one action from the defined list of possible actions, employing necessary tools to make editor changes.}}
}
\label{table:proactive-features}
\end{table*}


\textbf{The second principle} posits that people perceive interventions as less disruptive at the beginning of a task or subtask boundaries \cite{czerwinski2000instant, iqbal2005towards, Miyata1986}.
Task boundaries are defined as when one subtask is completed (evaluation) or when the next subtask begins (goal formulation) \cite{Miyata1986}.
To convert this implication to a system feature, we used event listeners to detect users' task beginnings and boundaries in programming, specifically, when the user completed a block of code (i.e., after outdenting in Python), executed the code, or made a multi-line edit (i.e. pasting a block of code) (Table \ref{table:proactive-features}, 2-4).



Finally, we draw inspiration from existing AI programming tools \cite{githubcopilot, copilotX, Nam2023InIDEGI} and propose \textbf{the third principle}: intervene when users are communicating through implicit signals.
Existing systems don't always use direct messages as the means of human-AI communication.
For example, in Github Copilot \cite{githubcopilot}, creating a new line after a comment prompts the tool to generate code based on the comment content. 
Another example is in Nam et al.'s work, where the system uses the user's current selection in the editor as context to provide code generation \cite{Nam2023InIDEGI}.
While these features demonstrate a low level of proactivity individually, we assimilate the existing designs to enhance the proactivity of \sys{}.



\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figures/Codellaborator_UI.pdf}
    \caption{\textbf{\sys{} UI in action.} \textnormal{The user asks the AI agent for help with implementing \texttt{get\_sorted\_events} using a breakout chat \textcircled{\raisebox{-0.5pt}{a}} on line 30. The AI adds code with its caret \textcircled{\raisebox{-0.5pt}{b}} in the editor and replies to the user in the breakout to discuss the next steps. The purple highlight  \textcircled{\raisebox{-0.5pt}{c}} indicates the provenance of the added code and fades away after 5 seconds. The AI agent's cursor displays ``Thinking...'' \textcircled{\raisebox{-0.5pt}{d}} to indicate its working process of generating a response. In the main chat panel to the left, messages are automatically organized by topic with summaries \textcircled{\raisebox{-0.5pt}{e}}. Note that during actual usage, when a breakout is opened, the main chat panel is blurred to alleviate cognitive load and signal context focus switch, but this feature was disabled for UI demonstration purposes.}}
    \label{fig:ui}
    % link: https://docs.google.com/drawings/d/1NknNUSHp2Fahnl67BBIBY8f2xmVYK_Lz0uzu3l74Qkc/edit
\end{figure*}

% One example is when the AI agent detected an extended period of user inactivity.  Similarly, the system would detect when the user has completed a block of code (i.e., outdenting it from a scope in Python), created a new line after an in-code comment \todo{cite copilot}, maintained a code selection on a range of lines, made a multi-line edit (i.e. cutting or pasting), or executed the code. 
% In each case, the AI agent would be aware of the user's action and make a new request to the LLM to decide if, and which, intervention was appropriate based on context of the user’s caret position in the editor and local code context
In each proactivity feature, the AI agent receives the user's caret position and local code context.
It then leverages the LLM to reason, triage, and decide whether to intervene, selecting an option from the defined list of editor actions if deemed necessary.
% This decision was based on the context of the user's action, evaluated by the LLM.
We also implemented adaptiveness within the AI agent's proactivity. 
For example, each time an idle or selection intervention (Table \ref{table:proactive-features}.1,6) was ignored by the user (i.e. no follow-up interaction with the agent), we imposed a penalty on the action and increased the time threshold to trigger an intervention to make it less frequent in the future to decrease unnecessary interventions.
Additionally, we prioritized the user's initiative and actions over the AI agent's, providing the user with ultimate control. When the user was initiating a conversation with the assistant, we canceled pending AI agent actions and active API requests, so as to not disrupt the user’s train of thought and wait for their updated input. 
\revise{However, to support parallel workflows (e.g., when the user is writing code while the agent proactively modifies other parts of the code), the agent does not cancel its actions if the user is making changes in the editor.}
To enable users to control the amount of visual signals they receive, the chat interface could be fully collapsed, providing more space for the code editor and hiding potentially distracting messages. 

In general, these guidelines lead the probe system to create proactive LLM-based agents for coding support. The agent accounts for the user's current text context and past interactions before evaluating which action to take and when to intervene. When appropriate, the agent can \textbf{proactively} make requests to the LLM and take agent actions to help facilitate direct communication and collaboration with the user.
With this approach, we attempt to improve the intervention timing using both rule-based heuristics and LLM decision-making predictions, constraining the model to take feasible and reasonable actions in a programming assistance context.
We conduct interaction-level analysis in a user study to evaluate the effectiveness of each timing principle and offer design insights for future proactive AI programming systems.


% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \begin{table}[]
% \begin{tabular}{@{}lll@{}}
% \toprule
% \textbf{User action} &
%   \textbf{System reaction trigger} &
%   \textbf{Possible actions} \\ \midrule
% \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}1. User is idle\\ (no code editing, \\ caret movement, \\ or selection change)\end{tabular}} &
%   \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Initial idle threshold is 30 seconds.\\ If user ignores and remains idle,\\ add 30 seconds to the threshold.\end{tabular}} &
%   \begin{tabular}[c]{@{}l@{}}1. If the user is on an empty \\ or trivial line (e.g., pass), no response\\ 2. Offer help via message. \end{tabular} \\ \midrule
% \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}2. User has completed \\ a block of code\end{tabular}} &
%   \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User outdents from a code scope \\ (e.g. an if statement, loop, or function).\end{tabular}} &
%   \begin{tabular}[c]{@{}l@{}}1. If block is insignificant, no response\\ 2. Notify user of issues\\ 3. Suggest optimization to user\\ 4. Add documentation in editor. \\rationale: Cutrell et al. demonstrated that interruptions arriving at the beginning of a primary task are perceived as less disruptive than interruptions occurring at other phases of a task execution. They suggested that interruptions should be deferred until a user is switching tasks, rather than delivering them immediately~\cite{horvitz2001notification}.\end{tabular} \\ \midrule
% \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}3. User has made \\ a code comment\end{tabular}} &
%   \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User starts a newline after \\ a single line or multi-line comment.\end{tabular}} &
%   \begin{tabular}[c]{@{}l@{}}1. If nothing to address, no response\\ 2. If the comment describes code, \\ provide code suggestion\\ 3. If posing a question, offer help\end{tabular} \\ \midrule
% \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}4. User maintains their \\ selection on a range \\ of  code\end{tabular}} &
%   \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Initial selection threshold is 15 seconds. \\ If user ignores and maintains selection, \\ add 15 seconds to the threshold.\end{tabular}} &
%   \begin{tabular}[c]{@{}l@{}}1. If insignificant selection, no response\\ 2. Explain the selection\\ 3. Error-check the selection \end{tabular} \\ \midrule
% \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}5. User has made \\ a multi-line \\ code change\end{tabular}} &
%   \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User cuts or pastes code \\ that's more than 1 line.\end{tabular}} &
%   \begin{tabular}[c]{@{}l@{}}1. If change is insignificant, no response\\ 2. Add documentation in editor\\ 3. Notify user of issues\end{tabular} \\ \midrule
% \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}User has executed \\ the code\end{tabular}} &
%   \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}6. User executes the program. \\ Output is displayed in the console.\end{tabular}} &
%   \begin{tabular}[c]{@{}l@{}}Acknowledge the code execution. \\ If output contains an error, offer to help.\\rational:  Researchers have long argued that opportune moments for interruption occur during periods of low mental
% workload~\cite{bailey2001effects,czerwinski2000instant}, and posit that these periods occur at subtask boundaries during task execution, and workload decreases at subtask boundaries~\cite{iqbal2005towards}\end{tabular} \\ \bottomrule
% \end{tabular}
% \caption{Proactivity features in \sys{}. Miyata and Norman theorize that moments of lower mental workload occur between the completion (evaluation) of one subtask and the beginning (goal formulation) of the next subtask, i.e. at a subtask boundary~\cite{Miyata1986}
% yc{we can say we derive these action/trigger based on this theory.}}
% \label{table:proactive-features}
% \end{table}



% Given that the system can provide many proactive interruptions, we sought to reduce the system's disruptive nature so a user could remain focused on the task at hand. 
% The first disruption-reducing strategy was to provide the AI agent with the option to not act if the user's action did not require any intervention. 
% This decision was based on the context of the user's action, evaluated by the LLM.
% We also implemented adaptiveness within the AI agent's proactivity. For example, if an idle or selection signal was ignored by the user, we imposed a penalty on this action and made it less frequent in the future to decrease unnecessary reactions.
% Additionally, we prioritized the user's initiative and actions over the AI agent's. When the user was initiating a conversation with the assistant, we cancelled current AI agent actions, such as code suggestions or inactivity messages, and active API requests, so as not to disrupt the user’s train of thought. 
% To enable users to control the amount of visual signals they receive, the chat interface could be fully collapsed, providing more space for the code editor and hiding potentially distracting chat messages. 
% For the same reason, when the user is inactive, we ensure that the assistant only offers help once, rather than pestering the user on a regular interval. 
% Also, whenever we provide a list of predefined actions for the assistant to take, we also give the option to not act at all, so it can ignore the user’s actions if there are no significant contributions to be made.

% Figure~\ref{fig:architecture} shows the architecture of our interruption management system.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.5\textwidth]{figures/architecture.JPG}
%     \caption{Caption}
%     \label{fig:architecture}
% \end{figure}

\subsection{\revise{AI Agent's Visual Representation in the Code Editor}}
% As mentioned, our prototype also includes several features aimed at increasing the social presence of the assistant. 
% \yc{start with the goal of this design}
% To increase the user's awareness of the AI agent's action, intentions, and decision-making process (DG2), 
\revise{To explore the effects of enhanced visual representation, our prototype makes visible the agent's actions, status, and process (DG2).}
\sys{} manifests the AI's presence with visual cues guided by the Social Transparency theory \cite{stuart2012social, erickson2003social} and existing design explorations for programming agents \cite{ehsan2021expanding, cursorcopilot++, geniusbydiagram}.
Specifically, we were inspired by the concept of interaction transparency, which posits that the visibility of the presence of other parties and sources of information in human collaboration can reduce interaction friction \cite{gutwin2004group, erickson2003social}.

To do so, we added a visual caret and cursor in the editor workspace automated by the AI agent. The AI caret indicated its position in the text buffer and moved as the AI agent selected and edited code (Fig.\ref{fig:ui}.b). 
The AI cursor, which moved independently of the caret, serves as an indicator of the AI agent’s “attention” and demonstrates its actions (Fig.\ref{fig:ui}.d). 
For example, to rewrite a block of code, the AI cursor would select a range of code, delete the range, and stream the new code in a typing motion, similar to how a human user would act.
We introduced human elements into the AI agent's actions to elicit the social collaboration heuristics to facilitate better human-AI collaboration \cite{ehsan2021expanding}.

While the AI agent is processing or taking action, a thought-bubble overlay floats adjacent to the cursor and contains an emoji and short text to convey the AI agent's working state (Fig.\ref{fig:ui}.d). 
For example, a writing hand emoji with ``Writing code...'' indicated that the AI agent was writing code in the editor, whereas a tool and laptop emoji with ``Program executing...'' indicated that it was analyzing the program execution output. 
The system also indicated its working progress by streaming a response with a ``pending'' indicator in the chat panel and a ``Loading'' signal on the AI cursor, thus preventing confusion about whether the system was responsive or stalled.
% We also enabled the AI agent to include emojis in their message response to add variety. A subset of emojis that conveyed system actions was parsed from the AI messages and displayed alongside the AI cursor. 
This design enabled users to be aware of system actions even when the chat panel was collapsed, allowing them to decide whether to engage based on the status displayed. 
The option to attend to the textual messages or the visual presence afforded different levels of interaction details, handing users control over the amount of information to be received from the AI agent.
% The system also streams responses from the OpenAI API so there can be a visual indicator when the assistant is composing a new message. Additionally, this “pending” indicator is localized to the specific chat they are writing in (\emph{i.e.} the global chat, or a particular breakout chat).


\subsection{\revise{Different Scopes of Interaction}}
% \yc{start with the goal of this design}
\revise{To examine the effects of different scopes of human-AI interaction within the code editor (DG3), \sys{} affords two channels for either the user or the agent to initiate an interaction. 
This was inspired by the literature on help-seeking in programming, where users often need to define the context (i.e. relevant code snippets \cite{chen2017codeon}, code annotations \cite{Horvath2021UnderstandingHP}, or search history \cite{Hartmann2011HyperSourceBT}) to request assistance.
Existing AI programming tools often adopt conversational interactions on a dedicated interface or provide in-line generated suggestions.
To evaluate the effects of different interaction scopes, \sys{} includes a global chat side panel, as well as local threads of conversations anchored in specific code lines, called the ``breakout''.
The user can initiate breakout chats for specific local context; the agent also automatically summarizes interactions and arranges them in relevant locations in the code editor.}

% As part of facilitating and improving collaboration between the human user and AI agent (DG1), \sys{} maintained content transparency by providing a rich context to both the user and the AI agent. 
% We stem this feature from the concept of content transparency in the Social Transparency theory, which relates to the awareness of the origin and history of the content and actions that occurred during the interactions \cite{stuart2012social}. 
% This includes preserving context over time, representing context visually, and maintaining the provenance of information and generated artifacts (i.e. code). 
% For example, \sys{} establishes one consistent AI agent that communicates with the user and generates code edits to execute in the file. This is in contrast to existing tools, like GitHub Copilot X \cite{copilotX}, where the chat agent and auto-complete provider [appear to] exist independently. 
% The main benefit of this is that higher-level conversations about the coding task can be used by the assistant as context for generating or refactoring code. 

\revise{To facilitate the transition between global and local scopes,} the AI agent consistently tracked many forms of context, such as the user’s current caret position in the file, the contents of the file, the user’s activity (or lack thereof), and the editor console output. 
% Supplying the user's working context and editor environment state enabled the AI agent to better address the needs of the user and prevent disruptions.
Using this context, the AI agent organized the past conversation context by grouping semantically relevant messages by topic and “breaking out” the subset of messages from the chat. 
The selected messages were collapsed in the main chat panel and anchored to an expandable thread at the appropriate area of code in the editor (Fig.\ref{fig:ui}.e). 
This enabled the conversation about a specific code section to be placed directly in a localized context, so the link between the code and the process that created it was represented visually. 
Breakouts also provide an easy way to access past conversations without needing to scroll through the chat when the collaboration session is prolonged. 
The breakout function also required that the AI agent provide a short summary, which was displayed in the chat in a collapsed component (Fig.\ref{fig:ui}.e). The collapsed component preserved the provenance of the original messages and also provided a button to navigate to the attached thread in the code editor. 
The new breakout chat remained interactive, so the user could continue the conversation with the AI agent and suggest edits, ask for explanations, and more, in situ (Fig.\ref{fig:ui}.a). 
The user could also manually initiate a breakout in the file. By doing this, they anchored their queries to a specific line, providing the AI agent with a local scope of context to inform their responses and/or actions.
% One prior study demonstrated increased performance when the user is aware of the human and AI code provenance \cite{Tang2024ASO}. To provide provenance information on the code artifact, the AI agent's code edits were highlighted in purple (Fig.\ref{fig:ui}.c) to distinguish authorship from user-written code. 
% The highlights faded away after 5 seconds to avoid visual distraction and could reappear when the user clicks between the range of the AI code edits.

\subsection{Probe System Implementation}
\sys{} was implemented as a React \cite{React} web application using \texttt{TypeScript}. The front-end code IDE was built on top of the Monaco Editor \cite{MonacoEditor}. The code execution relied on a separate web server powered by Node.js \cite{nodejs} and the Fastify library \cite{fastify}. 
The scope of \sys{} enabled users to execute single-file Python3 code for proof of concept.
The back-end of the system was powered by the GPT-4 \cite{OpenAI2023GPT4TR} large-language model that was connected via the OpenAI API \cite{openaiapi}. Specifically, we used the \verb|gpt-4-0613| model which enabled function-calling\footnote{Atty Eleti, Jeff Harris, and Logan Kilpatrick. 2023. Function calling and other API updates. Retrieved August 16, 2023 from \url{https://openai.com/blog/function-calling-and-other-api-updates}}. This allowed the system to define functional tools that the LLM was aware of and could employ to make editor changes if it saw fit according to a defined schema. 
We created four such tools for the model, i.e., to authorize code insertion, deletion, replacement, and message grouping to create breakouts. To configure the LLM agent, LangChain \cite{Langchain} was used to maintain a memory of the past message contexts and provide system messages to define the role and responsibility of the agent. 

To provide a collaborative experience, we delegated the AI agent with the role of a pair programming partner (system prompt in Appendix \ref{appendix:prompt}). 
% This corresponds with the HAI guideline of matching relevant social norms with the user \cite{amershi2019haiprinciple}. 
We also provided the basic context of the IDE interface, including the chat panel, the editor, and the console. The AI agent was asked to follow human pair programming guidelines \cite{cockburn2000costs, williams2003pair}, which defined the observer-driver responsibilities and enforced a friendly tone, constructive feedback, and a fair delegation of labor.
