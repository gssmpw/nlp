\section{Related Work}

\subsection{AI Programming Tools}
\label{RW:AI_Programming_Tools}
\revise{AI-assisted programming tools are increasingly integrated in developers' workflows.}
However, even tools that prioritize productivity, such as Github Copilot \cite{githubcopilot}, do not consistently demonstrate a significant improvement over traditional code completion tools such as IntelliSense \cite{intellisense, vaithilingam2022expectation, Khojah2024BeyondCG}. 
\revise{Existing research to improve AI programming support has focused on improving the quality and usability of the code generation.}
For example, recent works made advancements in structuring code generation \cite{Yen2023CoLadderSP}, expanding support to specific task domains (e.g., data analysis) \cite{Mcnutt2023OnTD}, or highlighting high-probability tokens to reduce uncertainties \cite{Vasconcelos2023GenerationPA}.
However, AI-generated assistance could result in discrepancies with the user's expectations, creating barriers to interpreting and utilizing the code output, or even steering the AI in the desired direction in the first place \cite{vaithilingam2022expectation}.
Another recurrent concern is the potential mismatch in expertise levels between developers and AI agents, leading to reduced productivity in pair programming scenarios~\cite{Ma2023IsAT}.
% Scope of interactions
\revise{To improve the usability of generated code, researchers enhanced the context within the \emph{scope of interaction} in the code editor.
For example, Yan et al. proposed Ivie, which generates visible explanations positioned adjacent to the code \cite{yan2024ivie}. Similarly, recent systems improved the discoverability of the code suggestion scope \cite{Vaithilingam2023intellicode} or provided more in-IDE code contexts to scaffold user understanding \cite{Nam2023InIDEGI}.
Alternatively, some tools integrates dialogue-based interactions to enable holistic queries at the editor level and enhanced interaction histories \cite{copilotX, ross2023programmerassistant, ReplitAI}.
\revise{Expanding the scope further, Meta-Manager enhances developers' sensemaking by collecting and organizing meta-information, such as code provenance and design rationale, making it easier to answer complex questions about the code base \cite{horvath2024meta-manager}.}
However, it remains unclear whether these approaches to scoping human-AI collaboration will be effective in a system-initiated paradigm and further research is needed to investigate the impact of different scopes of system-initiated actions on developer experience.
}

% Proactivity in general
\revise{Existing AI programming tools predominantly operate within the command-response paradigm, where the user triggers help-seeking and obtains generated code and explanations.}
An emerging approach to enhance AI programming is leveraging LLMs' generative power to build intelligent programming agents that proactively support users and autonomously complete tasks.
Efforts to develop proactive tools that provide automatic support have been explored across various domains, including personalized notifications for weather or calendars \cite{sun2016contextualintent, sarikaya2017digitalassistant}, health and fitness interventions \cite{schmidt2015fitness, rabbi2015healthfeedback}, and support for office workflows \cite{Baym2019clippy, Jacobs2019BeyondCC, matejka2011ambient}. 
Well-designed, effective invocation of systems' proactive assistance can lower the cost of user manipulation, resolve uncertainties preemptively, and lead to unintentional learning of the system's functionalities \cite{matejka2011ambient, horwitz1999mixedinitiative, Sawyer_2014_learning}.
Meanwhile, poorly designed proactive assistance can lead to negative user experiences, diminished control \cite{MORADIDAKHEL2023copilotliability, meurisch2020proactiveexpectation, barkhuus2003losecontrol}, and in some cases, rendering the tool ineffective \cite{meurisch2020proactiveexpectation, Baym2019clippy, Jacobs2019BeyondCC}.
While general guidelines on designing mixed-initiative interfaces and human-AI interactions have been established \cite{horwitz1999mixedinitiative, amershi2019haiprinciple}, it is uncertain how the design principles can translate to concrete system designs under the context of LLM-assisted programming.
For instance, while the \emph{timing of assistance} is one key metric of human-AI interaction design, existing AI programming systems almost always provide immediate response upon output generation without considering interruption to the user's workflow.

Recent research and commercial prototypes have explored many \revise{\emph{representation of the AI agent} to facilitate proactive support in programming.}
Some approaches include expanding on the auto-completion feature to proactively make intelligent file changes with an AI caret in the code editor \cite{cursorcopilot++}, or manifesting the AI's presence in the editor with an automated AI cursor \cite{geniusbydiagram} that mimic the user's workflow and automate repetitive tasks.
Some tools take an additional step towards fully autonomous AI and construct a group of AI agents capable of composing the task plan with executable steps and hosting its own workspace with code editor, console, and web browser to autonomously tackle software engineering tasks in response to a single user prompt \cite{devinAISWE, wang2024opendevinopenplatformai, yang2024sweagentagentcomputerinterfacesenable}.
However, the accuracy of the task completion suggests that the fully autonomous agent might not yet be fully scaled to real-life programming tasks. For example, based on evaluation on SWE-bench \cite{jimenez2024swebenchlanguagemodelsresolve}, a dataset designed to assess AI agent's capabilities in real-world Github issues, SWE-agent and OpenDevin reported 12.5\% and 26.0\% task completion rate.
\revise{This prompts a more balanced design where both the human and the AI agent are engaged in the programming process.}

% Expand on these systems
Further, the impact of proactive programming assistance for human users, as opposed to the current prompt-initiated paradigm, remains to be formally assessed.
Similarly, the resulting benefits and drawbacks to user experience from employing these specific design approaches need to be measured.
Our research not only aims to explore how to effectively design and integrate proactive AI assistance into developers' workflows but also seeks to gain a deeper understanding of the impact on the programming experience through a comprehensive study.
% It remains unknown how we can effectively design and effectively integrate proactive AI assistance into developers' programming workflow.
% The present research seeks to fill this gap by probing the designs of human-AI collaboration within the context of collaborative programming, and evaluating its usage in a study.


\begin{figure*}[h]
    \centering
    \includegraphics[width=0.76\textwidth,keepaspectratio]{figures/Theory_Diagram.png}
    \caption{\revise{\textbf{System Design Dimensions.} \textnormal{\sys{} explores three design dimensions. Each dimension is motivated by relevant theories under the framework of effective human collaboration; 
    The \emph{Timing of Assistance} (DG1) design takes inspiration from works in proactivity \cite{kim2020psychological} and interruption management in human collaboration \cite{mcfarlane2002scope, bailey2000measuring,horvitz2001notification,czerwinski2000instant, Miyata1986, iqbal2005towards} and specifically the software engineering context \cite{Solingen1998InterruptsJA, Ko2007InformationNI, parnin2010cues-resuming, parnin2011resumption-strategies}.  
    The \emph{AI Agent Representation} (DG2) dimension draws from literature in social and interaction transparency \cite{stuart2012social, erickson2003social, gutwin2004group}, pair programming signals \cite{cockburn2000costs, williams2003pair, Begel_pair, lee2017exploring, stein2004another, dourish1992awarness_workspace}, and existing AI programming agent designs \cite{wang2024opendevinopenplatformai, yang2024sweagentagentcomputerinterfacesenable, ehsan2021expanding}.
    The \emph{Scope of Interaction} (DG3) design is informed by works in information foraging in coding \cite{Fleming2013AnIF, Deline2006CodeTU, DualaEkoko2010TheIG,Aghajani2019SoftwareDI, Horvath2021UnderstandingHP}, community question-answering tools \cite{Goldman2008CodetrailCS, cordeiro2012contextQA, Hartmann2011HyperSourceBT}, research in understanding developer need and context \cite{chen2016towards, mamykina2011design, chen2017codeon}, and editor context scopes for AI code generation \cite{yan2024ivie, Vaithilingam2023intellicode, Nam2023InIDEGI, ross2023programmerassistant, horvath2024meta-manager}.
    \sys{} is a design probe that explores designs that intersect each dimensions and evaluates their impacts on users' programming experiences. Two other probes are described in Section \ref{Evaluation:study-design} (DG4). CodeGhost explores the effect of proactive timing heuristics without the agent representation and scope of interaction designs, and PromptOnly is the baseline condition that does not inherit any of the design explorations and thus is not illustrated on the diagram. Please note that we categorized each reference based on the primary aspect it informs within our framework, but some of the cited works may span multiple dimensions and we acknowledge their relevance across overlaps.}}}
    \label{fig:theory}
    % link: https://www.figma.com/design/rNYeRi41OD09OqNAtt0HvB/Codellaborator--Figure?node-id=206-2&t=kvk7zl2kpoPqo5p1-1
\end{figure*}




\subsection{\revise{Proactive Assistance and Interruption}}
Designing a proactive AI assistant that enables positive experiences and outcomes is a challenging endeavor. The nuances of effective human-to-human collaboration are still not fully understood and vary greatly depending on the context, making it difficult to craft effective human-AI collaboration paradigms. 
Past research has shown that two factors, i.e., proactivity and interruption, play pivotal roles in shaping the outcomes of team collaborations. 
Prior work in psychology has revealed that proactivity, when effectively managed, can provide positive affective outcomes during collaborative work \cite{kim2020psychological}. However, the current landscape of human-AI collaboration is often characterized by either human-dominant or AI-dominant dynamics. 
In such situations, both human and AI agents operate reactively. \revise{This paradigm often leave the cognitive burdens for human developers due to the expression, sensemaking, and verification process for the code assistance \cite{vaithilingam2022expectation, liang2024usabilityCopilot}.}

Interruption, or \textit{``an event that breaks the coherence of an ongoing task and blocks its further flow, though allowing the primary task to resume once the interruption is removed''} has been a subject of study for decades \cite{mcfarlane2002scope}. 
Numerous studies have highlighted the detrimental effects interruptions can have on users' memory, emotional well-being, and ongoing task execution~\cite{bailey2000measuring,horvitz2001notification,czerwinski2000instant}. 
\revise{Specifically, in the context of software engineering, Solingen et al. defined interruption as a multi-phase process that occurs when a developer stops their planned activities, handles the interruption, then finally recovers by returning to the point in their work at which they were interrupted \cite{Solingen1998InterruptsJA}.
In existing practices, Ko et al. observed developers daily activities and identified multiple interruptions per day, mainly due to communication requests and notifications \cite{Ko2007InformationNI}.
Parnin et al. also found that developers spend significant time rebuilding context after each interruption, creating ``resumption lag'' which increases errors and frustration \cite{parnin2010cues-resuming, parnin2011resumption-strategies}.}
To mitigate the challenges posed by interruptions, we drew insights from psychology and behavioral science to foster collaborations that would be perceived as less disruptive.
For instance, as the perceived level of disruption is influenced by a user's mental load at the time of the interruption~\cite{czerwinski2000instant,bailey2000measuring,bailey2001effects}, we designed interactions that were aware of a user's working context before generating notifications.
% previous research has indicated that individuals perceive less disruption when an interruption is closely related to their current task~\cite{czerwinski2000instant}. This transforms to system features that will first detect the relevancy of the response and the current task.
%In our evaluation, we also took into account both qualitative and quantitative measures to gauge this. 
Furthermore, prior works have highlighted that people experience varying degrees of disruption during different sub-tasks~\cite{horvitz2001notification,czerwinski2000instant, Miyata1986, iqbal2005towards}. 
We apply these principles when designing the timing of service of our probe to adopt a proactive collaborator role at moments when the programming task context was most appropriate.


\subsection{Help-Seeking and Collaboration in Programming}
Our research was additionally informed by existing research on collaboration during software engineering, specifically help-seeking behaviors and pair programming.

\subsubsection{Help-Seeking in Programming}
\revise{Developers often forage information from the code itself to resolve their issues, during processes like debugging \cite{Fleming2013AnIF}. To facilitate this process, researchers have built tools to scaffold navigation and understanding the source code \cite{Deline2006CodeTU}.
Documentation is another source developers rely on to find assistance.
However, studies have identified challenges for users to pinpoint relevant information and to maintain the documentation in an up-to-date state \cite{DualaEkoko2010TheIG,Aghajani2019SoftwareDI}.
Annotations on documentation, as demonstrated in Adamite, can support comprehension and foster collaboration by addressing gaps in traditional documentation \cite{Horvath2021UnderstandingHP}.}
To seek more targeted help, Community Question-Answering (CQA) websites, such as Stack Overflow \cite{stackoverflow}, also allow developers to post questions but also archive answers for future reference, a concept rooted in Answer Garden's creation of an ``organizational memory''~\cite{ackerman1996answer,ackerman1998augmenting}.
\revise{To more seamlessly connect developer's working context to help seeking, researchers have connected the integrated development environment (IDE) with web browser \cite{Goldman2008CodetrailCS}, web-based Q\&A search \cite{cordeiro2012contextQA}, and annotated the source code with browser histories \cite{Hartmann2011HyperSourceBT}.}
However, many questions that are well-suited for an intelligent agent are misaligned with the design of CQA websites. 
A previous study utilized a ``hypothetical intelligent agent'' as a probe to understand developers' ideal help-seeking needs~\cite{chen2016towards}. 
The findings, along with other studies' results, highlighted several limitations of CQA sites, including delayed feedback, lack of context, and the necessity for self-contained questions~\cite{mamykina2011design}.
Consistent with this, prior work has advocated for systems that intuitively captured a developer's context and used it to enable developers to \revise{identify the scope of assistance by selecting} a code snippet, asking the system to ``please refactor this'', and promptly receiving pertinent responses~\cite{chen2017codeon}.
\revise{Like described in Section \ref{RW:AI_Programming_Tools}, existing AI programming tools often employ different scopes of interaction with the intelligent assistant, translating the consideration of interaction context scope from human help-seeking to human-AI collaboration.}
Inspired by this research, we designed our probe to \revise{allow users to seek help with different granularity of support, receiving assistance on the overall codebase via a global chat interface and on specific code snippets via localized conversation threads. This way, we can evaluate the impacts of different scope of interactions in a more system-initiated programming paradigm.}



\subsubsection{Pair Programming}
Pair programming is a paradigm where two users collaborate in real-time while at a single computer, with one user writing the code (i.e., the driver) and the other reviewing the code (i.e., the observer) \cite{cockburn2000costs}. 
Pair programming has been shown to lead to better design, more concise code, and fewer errors within approximately the same person-hours~\cite{williams2003pair, Begel_pair}.
Other research has reported that these benefits may have been due to the awareness of another's focus within the code, which can be invaluable for problem-solving~\cite{lee2017exploring}.
For example, Stein and Brennan found that when novices observed the gaze patterns of expert programmers during code reviews, they pinpointed bugs faster~\cite{stein2004another}.
However, the most prominent challenges associated with pair programming include cost inefficiency, scheduling conflicts, and personality clashes~\cite{Begel_pair}.
Facilitating visible presence and actions between collaboration partners has previously demonstrated its efficacy in physical workspaces \cite{dourish1992awarness_workspace}.
Our design probe loosely adopted the pair programming paradigm where the AI agent and the user can adapt and exchange the roles of the driver and the observer.
We also implemented visible presence and clear context information to enhance mutual awareness between the user and the AI.

% should add human-ai pair programming work, like https://arxiv.org/pdf/2306.05153.pdf
% Trade-offs for substituting a human with an agent in a pair programming context: the good, the bad, and the ugly

% \subsection{Social Transparency}
% The design of social transparency features builds on previous work that examined social transparency and related concepts during human-human interaction \cite{star1999layers,suchman1995making}. Social transparency has been a key focus in HCI, especially in the Computer-Supported Cooperative Work literature. Erickson and Kellogg introduced the idea of Social Translucence, which involves making others' actions visible in computational systems, raising awareness, and allowing people to adapt social rules to improve online communication and collaboration \cite{erickson2003social}. The social translucence theory was later expanded upon by Stuart et al., who developed the concept of Social Transparency. Compared to social translucence, social transparency extended beyond direct interactions to also include one's role as an observer of others' actions \cite{stuart2012social}. Their framework outlined three social dimensions made visible through Social Transparency, i.e., identity transparency, content transparency, and interaction transparency, and explored the social inferences people could make based on these visible dimensions (e.g., perceived similarity, accountability, activity awareness, and norms). The social transparency framework has also been introduced to incorporate the socio-organizational context into explaining AI-mediated decision-making \cite{ehsan2021expanding}. 

% The social transparency framework has informed numerous groupware and social technologies to support effective and cohesive technology-mediated group collaboration \cite{gutwin2002descriptive, gilbert2012designing, gutwin2004group}. By making invisible team members' interaction visible, the socially transparent design facilitates group awareness, which ultimately reduces interaction friction \cite{gutwin2004group}. The present study extends the social transparency research in human teams to the design of a collaborative AI. We argue making an AI agent's activities visible, i.e., socially transparent, to the users could benefit their collaboration with such an agent. 



