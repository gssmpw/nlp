\section{Experiment} \label{sec:experiment}

In this section, we evaluate our algorithms presented in the previous sections. We profile the GPU memory usage when training two linear feedforward DNN models with the optimal checkpoint subset returned by the algorithms. We do the same for comparison by profiling the training of the same models with non-optimal checkpoint subsets. Finally, we run the algorithm implementation of Feng et al.~\cite{feng2021optimal} to find and compare the differences between their works and ours.


\subsection{Environment Settings}

\subsubsection{Models and Definitions}

We use VGG-19~\cite{Simonyan2014VeryDC} and AlexNet~\cite{krizhevsky2017imagenet} as our DNN model to evaluate our algorithm.
VGG-19 has 16 convolution layers and 5 max-pooling layers, and 3 fully connected layers.
AlexNet has 5 convolution layers and 3 max-pooling layers, and 3 fully connected layers.

We define the term {\em training phase index} to describe every stage of training, including both the forward and backward phases. It is a number ranging from 0 to $2N+1$, where $N$ is the number of layers of the model. The value $0$ represents the stage before the training, and $2N+1$ represents the stage after training.
The training is in the forward phase when $i$ is in the range $1 \leq i \leq N$, and it is in the backward phase when $i$ is in the range $N+1 \leq i \leq 2N$. Now we can index the entire training.
Notice that we always measure the GPU memory at the end of every stage. For ease of index calculation, we do not merge the forward phase and the backward phase of the last layer.
Figures~\ref{fig:vgg19_layers} and \ref{fig:alexnet_layers} depict the training phase indices for VGG-19 and AlexNet, respectively. For example, the training phase index 29 of VGG-19 means that it is the stage in the backward phase of the 20th layer, i.e. we are in the backward phase of the last convolutional layer with 512 output channels.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Fig/vgg19_layers.pdf}
    \caption{Training phase indices of VGG-19.} 
    \label{fig:vgg19_layers}
\end{figure}
\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{Fig/alexnet_layers.pdf}
    \caption{Training phase indices of AlexNet.} 
    \label{fig:alexnet_layers}
\end{figure}

\subsubsection{Benchmarks}

%We use ImageNet~\cite{russakovsky2015imagenet} and TinyImageNet to evaluate our algorithm.
%ImageNet consists of around 1.3 million color images of different sizes in 1000 classes.
%TinyImageNet~ consists of 0.1 million color images of the same size (64 by 64) in 200 classes.

%For ImageNet, we will crop all images into size 224 by 224 before feeding them into our model.

We use ImageNet~\cite{russakovsky2015imagenet} to evaluate our algorithms.
ImageNet consists of around 1.3 million color images of different sizes in 1000 classes.
We crop all images into size 224 by 224 before feeding them into the model.

\subsubsection{Implementation}

We use PyTorch~\cite{paszke2019pytorch} deep learning platform to implement the two DNN models VGG-19 and AlexNet.
To implement the recomputing of a segment in the checkpoint technique, we use the PyTorch API \texttt{torch.utils.checkpoint}.
To profile the GPU memory usage, we use the PyTorch API \texttt{torch.cuda.memory\_allocated}.
We include the fully-connected layers of both VGG-19 and AlexNet when selecting the candidate of checkpoints, in addition to convolution layers. 
This is because the memory cost of fully-connected layers is large.
Additionally, we exclude the layers of AdaptiveAvgPool2d, Flatten, and Dropout in VGG-19, but include these layers as checkpoint candidates in AlexNet.
This simplifies the selection of checkpoints for the $O(\sqrt{n})$ algorithm~\cite{chen2016training}.
We perform all experiments with GPUs of the same specs, NVIDIA GeForce RTX 3090, 24 GiB memory on a server with 16-core, 2.90 GHz Intel Xeon Gold 6226R CPU, 192 GiB RAM.


\subsection{Algorithm Prediction versus PyTorch Report} \label{sec:prediction}

In this experiment, we demonstrate the importance of the consideration of the output gradient buffer as we have mentioned in section~\ref{sec:dynamic_checkpoint}. We show that the prediction of GPU memory usage by our algorithm is aligned with the report from PyTorch.

\begin{figure}[h!t]
    \centering
    \input{tikz/algo_pred_vs_pytorch_report}
    \caption{GPU Memory Usage: Algorithm Prediction vs PyTorch Report on VGG-19 with Checkpoint Subset \{3, 11, 24\}.} 
    \label{fig:algo_pred_vs_pytorch_report}
\end{figure}

In Figure~\ref{fig:algo_pred_vs_pytorch_report}, we profile our training of VGG-19 with the checkpoint subset returned by our algorithm and draw the GPU memory usage prediction using the same checkpoint subset.
The blue dashed line represents the GPU memory usage reported by PyTorch.
On the other hand, the red line is the GPU memory usage predicted by our algorithm. Notice that we use the checkpoint subset \{3, 11, 24\} reported by our algorithm when running on VGG-19 to mark the corresponding stages on the x-axis for both the forward and backward phases, so the six ticks on the x-axis are all stages about checkpoints.
The average error of our prediction is 2.8\%.


\subsection{Comparison with $O(\sqrt{n})$ Memory Cost Algorithm}

In this experiment, we compare the GPU memory usage when training VGG-19 using the checkpoint subset provided by our algorithm and the one by the sublinear memory cost algorithm proposed by Chen et al.

\begin{figure}[h!tb]
    \centering
    \input{tikz/our_algo_vs_sublinear}
    \caption{GPU Memory Usage: Our Algorithm vs $O(\sqrt{n})$ Memory cost Algorithm Proposed by Chen et al. on VGG-19} 
    \label{fig:our_algo_vs_sublinear}
\end{figure}

In Figure~\ref{fig:our_algo_vs_sublinear}, the red line represents the GPU memory usage of the training on VGG-19 reported by PyTorch using the checkpoint subset returned by our algorithm. On the other hand, the blue dashed line represents the GPU memory usage of the training using the checkpoint subset calculated by the sublinear memory cost algorithm. We mark the ticks of the x-axis using the checkpoint subset of the latter, which is the set \{5, 10, 15, 20, 24\}.

\subsection{Comparison with Optimal Arbitrary Computation Graph Algorithm}

In this experiment, we compare the GPU memory usage when training VGG-19 using the checkpoint subset provided by our algorithm and the one by the optimal arbitrary computation graph algorithm proposed by Feng et al.

\begin{figure}[h!tb]
    \centering
    \input{tikz/our_algo_vs_optimal_ACG}
    \caption{GPU Memory Usage: Our Algorithm vs Optimal Arbitrary Computation Graph (ACG) Algorithm Proposed by Feng et al. on VGG-19} 
    \label{fig:our_algo_vs_optimal_ACG}
\end{figure}

In Figure~\ref{fig:our_algo_vs_optimal_ACG}, the red line represents the GPU memory usage of the training on VGG-19 reported by PyTorch using the checkpoint subset returned by our algorithm. On the other hand, the blue dashed line represents the GPU memory usage of the training using the checkpoint subset returned by the optimal arbitrary computation graph algorithm. We mark the ticks of the x-axis using the checkpoint subset of the latter, which is the set \{3, 6, 24\}.
In the figure, we can see that both algorithms have the same peak memory usage that occurs at the start of the last segment in the backward phase. During the same training phase index range from 25 to 43, the training using the optimal ACG algorithm spends around 2 GiB more memory compared to our algorithm on the first half and more of the first segment during the backward phase. On the other hand, our algorithm also spends around 2 GiB more memory compared to the optimal ACG algorithm on the remaining part of the first segment during the backward phase.

\subsection{Comparison: The Peak Memory Usage on Different Experiment Settings}

\begin{table*}[h!tb]
\centering
\caption{The Profiling Results of Peak Memory Usage: Finding the Checkpoint Subset Using Different Methods}
\label{tab:PR_Peak_Memory_Usage}
\footnotesize
\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Peak Mem.(MiB) & Algorithm~\ref{alg:dynamic-checkpoint-selection} & Algorithm~\ref{alg:checkpoint-selection} & ACG Solver & $O(\sqrt{n})$ & PyTorch \\
    \hline
    \hline
%    VGG-19, b=128 & {6,444 \{2,4,6,9,11,14,\par 16,19,21,23,24\}} & 6,835 \{3,6,24\} & 6,836 \{3,6,24\} & {8,404 \{5,10,15,\par 20,24\}} & 11,262 \\
    VGG-19, b=128 & 6,444 & 6,835 & 6,836 & 8,404 & 11,262 \\
    & {\{2,4,6,9,11,14,\par 16,19,21,23,24\}} & \{3,6,24\} & \{3,6,24\} & {\{5,10,15,\par 20,24\}} & \\
    \hline
    VGG-19, b=256 & 11,220 & 12,004 & 12,004 & 15,139 & 20,850 \\
    \hline
    VGG-19, b=320 & 13,609 & 14,592 & 14,592 & 18,511 & OOM \\
    \hline
    VGG-19, b=384 & 15,997 & 17,177 & 17,177 & OOM & OOM \\
    \hline
    VGG-19, b=400 & 16,594 & 17,824 & 17,824 & OOM & OOM \\
    \hline
    \hline
%    AlexNet, b=128 & 1,002 \{2,4,6,8\} & 1,003 \{2,4,12,15\} & 1,003 \{2,4,12,15\} & 1,106 \{4,8,12,15\} & 1,174 \\
    AlexNet, b=128 & 1,002 & 1,003 & 1,003 & 1,106 & 1,174 \\
    & \{2,4,6,8,12,14,15\} & \{2,4,12,15\} & \{2,4,12,15\} & \{4,8,12,15\} & \\
    \hline
    AlexNet, b=4096 & 9,866 & 9,866 & 9,866 & 13,182 & 15,275 \\
    \hline
\end{tabular}
\end{table*}

In this experiment, we compare the GPU memory usage when training both VGG-19 and AlexNet with different batch sizes and checkpoint subsets that are computed using different algorithms. The results are shown in Table~\ref{tab:PR_Peak_Memory_Usage}.
In the first column, the shorthand b=$N$ means that we use the number $N$ as the batch size for all experiments of the current row. The abbreviation OOM means that the experiment cannot be carried out due to the out-of-memory error reported by PyTorch.
For the benchmark, we use a single batch from the ImageNet database for testing. (In the implementation of Feng et al., they randomly generate a batch of images for testing.)

For the VGG-19 results in Table~\ref{tab:PR_Peak_Memory_Usage}, both algorithm~\ref{alg:checkpoint-selection} and the optimal ACG algorithm have the same peak memory usage reported by PyTorch since the checkpoint subsets returned by the two algorithms are the same. On the other hand, algorithm~\ref{alg:dynamic-checkpoint-selection} has the lowest peak GPU memory usage. The checkpoint subset returned by algorithm~\ref{alg:checkpoint-selection} and the optimal ACG algorithm is \{3, 6, 24\}. The checkpoint subset returned by algorithm~\ref{alg:dynamic-checkpoint-selection} is \{2, 4, 6, 9, 11, 14, 16, 19, 21, 23, 24\}.
Compared to the $O(\sqrt{n})$ algorithm and ACG Solver, algorithm~\ref{alg:dynamic-checkpoint-selection} reduces 2 GiB (23\%) and 392 MiB (5.7\%) of peak memory usage with a batch size of 128, respectively.
More importantly, the checkpoint subsets do not change when we increase the batch size since the batch size is a factor in the output data size of every layer.

\subsection{The Granularity of Model Specs Matters: Testing The Optimal Checkpoints on AlexNet with Extended Model Specs}

In this subsection, we run Algorithm~\ref{alg:dynamic-checkpoint-selection} on AlexNet model to get the optimal checkpoint subset, and train and profile AlexNet with these checkpoints accordingly. From our prior experiments with VGG-19 models, we observe that the peak GPU memory usage usually occurs at one of the max-pooling layers. But in the plain model specs of AlexNet, all of its max-pooling layers are embedded into {\em larger, abstract} convolution layers, i.e. it is {\em hidden} from the selection of checkpoints. We move all of these max-pooling layers out of the convolution layers since the behavior of our algorithm is dependent on the granularity, i.e. the length, of the model specs. We expect that the peak GPU memory usage will decrease with the new model specs because more combinations are considered.

\subsubsection{AlexNet: Using the Plain Specs}

In this trial, we use the plain model specs of AlexNet, i.e. it has 5 convolution layers and 3 fully-connected layers. The result in Figure~\ref{fig:GMU_AlexNet_Ckpt_Optimal} indicates that our algorithm chose checkpoints \{3, 4, 5, 9, 11, 12\}. This means that the third and fourth convolution layers (Conv2d/ReLU), the fifth convolution layer (Conv2d/ReLU + MaxPool2d), and
%fourth(Conv2d(in=384, out=256), relu, MaxPool2d)  convolution layers
all three fully-connected layers are chosen as checkpoints.

\input{tikz/alexnet_optimal}

\subsubsection{AlexNet: Standalone Max-Pooling Layers}


\input{tikz/alexnet_optimal2}

In this trial, we use the extended model specs of AlexNet, i.e. it has 5 convolution layers and 3 standalone max-pooling layers, and 3 fully-connected layers. From the result in Figure~\ref{fig:GMU_AlexNet_Ckpt_Optimal2}, we can see that the checkpoint subset \{2, 4, 6, 8, 12, 14, 15\} is chosen by our algorithm.
%At first look, it might seem that the first checkpoint did not change, but
We should note that since we have changed the granularity of the specs, the numbers (which are indexes) now have a different meaning. It means that the three standalone max-pooling layers (i.e. indices 2, 4, and 8) are chosen as the checkpoints.

In the first convolution layer (Conv2d/ReLU + MaxPool2d) of AlexNet, the output tensor sizes of Conv2d/ReLU and MaxPool2d are 103 MiB and 26 MiB for a batch size of 128, respectively.
Without separating the max-pooling, only the tensor of size 26 MiB can be selected as the checkpoint.
By moving max-pooling out of the layer, the tensor of size 103 MiB becomes a selectable checkpoint.
Consequently, our algorithm identifies a better solution by selecting it as a checkpoint, reducing the peak memory usage by 100 MiB compared to the plain AlexNet model.
The result aligns with our expectations.
We can have a lower peak memory usage if there are more candidates in the model specs as if checkpointing at the middle of an abstract, high-level layer. 

This also shows the advantage of our algorithm. Because the time complexity of our algorithm is linear, the increase in model length caused by the increase in granularity will not affect the speed of our algorithm a lot. (in our cases, there will be at most 7 max-pooling layers given the image size is 224 by 224)



\subsection{Comparison: The Training Time on Different Experiment Settings}

\begin{table*}[h!tb]
\centering
\caption{The Training Time of One Batch Using Different Methods}
\label{tab:training_time}
\footnotesize
\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Exec. time per batch & Algorithm~\ref{alg:dynamic-checkpoint-selection} & Algorithm~\ref{alg:checkpoint-selection} & ACG Solver & $O(\sqrt{n})$ & PyTorch \\
     (second) & & & & & \\
    \hline
    \hline
%    VGG-19, b=128 & {6,444 \{2,4,6,9,11,14,\par 16,19,21,23,24\}} & 6,835 \{3,6,24\} & 6,836 \{3,6,24\} & {8,404 \{5,10,15,\par 20,24\}} & 11,262 \\
    VGG-19, b=128 & 0.779 & 0.779 & 0.779 & 0.780 & 0.585 \\
    & {\{2,4,6,9,11,14,\par 16,19,21,23,24\}} & \{3,6,24\} & \{3,6,24\} & {\{5,10,15,\par 20,24\}} & \\
    \hline
    VGG-19, b=256 & 1.541 & 1.540 & 1.540 & 1.541 & 1.158 \\
    \hline
    VGG-19, b=320 & 1.921 & 1.920 & 1.920 & 1.922 & OOM \\
    \hline
    VGG-19, b=384 & 2.292 & 2.289 & 2.289 & OOM & OOM \\
    \hline
    VGG-19, b=400 & 2.849 & 2.335 & 2.335 & OOM & OOM \\
    \hline
    \hline
%    AlexNet, b=128 & 1,002 \{2,4,6,8\} & 1,003 \{2,4,12,15\} & 1,003 \{2,4,12,15\} & 1,106 \{4,8,12,15\} & 1,174 \\
    AlexNet, b=128 & 0.046 & 0.046 & 0.046 & 0.046 & 0.038 \\
    & \{2,4,6,8,12,14,15\} & \{2,4,12,15\} & \{2,4,12,15\} & \{4,8,12,15\} & \\
    \hline
    AlexNet, b=4096 & 1.206 & 1.206 & 1.206 & 1.216 & 1.058 \\
    \hline
\end{tabular}
\end{table*}

In this experiment, we compare the training time of VGG-19 and AlexNet with different algorithms.
We train the model for one epoch on the ImageNet dataset and measure the average training time of a single batch.
The results are shown in Table~\ref{tab:training_time}.

For VGG-19, the training time is close with all checkpoint selection methods, irrespective of the number of segments.
The only exception is algorithm~\ref{alg:dynamic-checkpoint-selection} with a batch size of 400, which exhibits 22\% longer time compared to other checkpoint selection methods.
Since this paper focuses on finding the optimal checkpoints with minimal peak memory usage, we will investigate its reason in the future.
Compared with PyTorch, the checkpoint selection methods incur 33\% additional training time with batch sizes of 128 and 256.

As for AlexNet, since AlexNet is a relatively small model, data augmentation becomes a bottleneck and the GPU often becomes idle when waiting for the input data from the CPU.
Therefore, we disable data augmentation and reuse the same input batch data when measuring the training time of AlexNet.
This way avoids extra overhead and ensures full GPU utilization.
The result in Table~\ref{tab:training_time} indicates that the checkpointing methods require 14\% more training time compared to PyTorch with a batch size of 4096.

%For AlexNet, the training time is close with all methods.
%This is because data augmentation is enabled for training, where the augmentation process runs on the CPU.
%Since AlexNet is a relatively small model, this data augmentation becomes a bottleneck, and it often causes the GPU to be idle when waiting for the input data.
%We conduct another experiment without enabling data augmentation and reuse the same input batch data for training AlexNet. This way avoids extra overhead and ensures full GPU utilization. The result indicates that all checkpointing methods require 14\% more training time compared to PyTorch without checkpointing.

We implemented our checkpoint selection algorithms using Python. Algorithm~\ref{alg:checkpoint-selection} and algorithm~\ref{alg:dynamic-checkpoint-selection} respectively take 20 milliseconds and 1.1 milliseconds to find the checkpoint subset for VGG-19, executed on the Intel Xeon Gold 6226R CPU. 