\section{Related Work}
\label{sec:related}

In this section, we describe some works related to the checkpoint technique in the previous section for reducing the peak memory requirement.

In Deep Neural Networks training, the memory of data for backward propagation has outweighed that of model parameters**Chen et al., "Recomputing Gradients for Backward Propagation"**. 
This causes severe memory pressure in Algorithm~\ref{alg:train}. 
Chen et al. introduced checkpoints (Algorithm~\ref{alg:train-checkpoint}) to reduce the memory pressure by recomputing and gave a very simple estimate on the number of checkpoints required**Feng et al., "Memory-Efficient Training for Deep Neural Networks"**.
After that several efforts tried to find the optimal set of checkpoints to reduce the peak memory requirement**Kirisame et al., "Dynamic Tensor Rematerialization"**. 
\comment{
inally, we list a few applications where the checkpoint technique is used in combination with some other techniques to solve different kinds of problems.
}

\subsection{Trading computation for memory}

The question about the trade-off between allocating more memory for either checkpoints or the maximum-sized segment at the end of the previous section corresponds to the general methodology known as {\em trading computation for memory}.
Chen et al.**Chen et al., "Recomputing Gradients for Backward Propagation"** showed that one can train a $n$-layer linear chain feedforward model in $O(\sqrt{n})$ memory at the cost of an additional forward pass in the backward phase during training.
\comment{We can verify it by dividing the model into $\sqrt{n}$ number of equal-size segments and by only keeping the output (the checkpoints) of these segments during training. }
The memory cost to train the model is $O(n/\sqrt{n})+O(\sqrt{n}) = O(\sqrt{n})$, which is optimal when the size of data of every layer are the same.
In practice the $\sqrt{n}$ estimate might not be an optimal solution since the amount of data in different layers will differ.
As a result, dividing the model into $\sqrt{n}$ number of equal-size segments does not guarantee the optimal results.
Nevertheless, the simple technique still reduces the peak memory requirement.

Modern deep-learning platforms do support checkpoints.
For example, PyTorch**Chen et al., "PyTorch Implementation"**, provides the tool API \texttt{torch.utils.checkpoint\_sequential} to implement Algorithm~\ref{alg:train-checkpoint} for sequential models and \texttt{torch.utils.checkpoint} to specify segments by adding checkpoints.
However, these functions are user-dependent, which means that its users have to find a set of checkpoints and divide their model into segments on their own accordingly to facilitate the tool API. To get the optimal result for all cases on linear models, we need to look for algorithms that work for models with non-uniform costs.

\subsection{Finding checkpoints within a given budget automatically}

To find the set of checkpoints, Chen et al. proposed another algorithm**Chen et al., "Memory-Efficient Training for Deep Neural Networks"**, in their work to generate a {\em memory allocation plan} (the placement of the checkpoints) within a given {\em budget} (the restriction on the memory of the maximum-sized segment). 
The algorithm can be seen as the {\em preprocessing step}**Feng et al., "Efficient Memory Allocation for Deep Neural Networks"**, before the execution of Algorithm~\ref{alg:train-checkpoint}. 
In addition, it can be applied to general computation graphs without the assumption of uniform cost of layer data.
In short, it works by running a heuristic search over all possible budgets, and for each given budget it does greedy allocation to get the exact memory for each memory allocation plan.
**Kirisame et al., "Dynamic Tensor Rematerialization"**, also proposed a method to find the checkpoints under a given memory budget but focused on minimizing the model training time.
Their method is based on a dynamic programming algorithm of $O(mn^3)$ time complexity, where $m$ is the memory limit and $n$ is the number of layers.
In contrast, this paper focuses on finding the optimal checkpoints with minimal peak memory usage, and we propose a linear time algorithm to solve the checkpoint selection problem.

\comment{While the algorithm relies on approximate memory estimation for faster speed, it still takes several seconds to generate the plan, as reported in the supplement section of their work. 
Even worse, the solution is not optimal due to the approximate estimation. 
Instead, our work will improve these two parts in the later sections and achieve a linear algorithm with precise memory estimation.}


\subsection{Finding the optimal checkpoints for arbitrary DNN model}

To find the optimal set of checkpoints to reduce peak memory, the scheme proposed by Feng et al.**Feng et al., "Efficient Memory Allocation for Deep Neural Networks"**, is the first work that is applicable for arbitrary computation graphs (ACGs), as they did not pose any assumption on the computation graph of DNN models. They can achieve maximum memory cut-offs at the cost of moderate time overhead (\textasciitilde 30\%-50\%).

To provide an overview of their algorithm, they denoted the computation graph of a DNN model as an acyclic-directed graph where the vertices are the intermediate tensors and the edges are the operations of the DNN model**Chen et al., "Memory-Efficient Training for Deep Neural Networks"**. 
After the computation graph of a DNN model is built, they run their algorithm to divide the computation graph into {\em independent segments} (ISs), which means that there is no data dependency between the non-checkpoint vertexes in the subgraph and the other part of the graph. While the context is different, they use the same objective function for the peak memory requirement as the one defined by Chen et al, i.e. the memory of each segment is the sum of the memory of the non-checkpoint vertexes within the segment.

\subsection{Summary}

Table~\ref{tbl:comparison} summarizes checkpoint models and algorithms for linear neural networks.
%
%The first half of the table describes the memory model of Algorithm~\ref{alg:train-checkpoint}.
%This paper improves the execution time to find the minimum memory for this memory model from $O(n^3 \log n)$ to $O(n^3)$ (Section~\ref{sec:partition}).
%The algorithm is suitable for deep learning frameworks that do not optimize memory usage.
The upper half of Table~\ref{tbl:comparison} focuses on the memory usage model proposed by Chen et. al**Chen et al., "Memory-Efficient Training for Deep Neural Networks"**.
In this paper, we improve the execution time for finding the minimum memory usage from $O(n^3 \log n)$ to $O(n^3)$.

%In the second half of the table, as we will see in Section~\ref{sec:dynamic_checkpoint}, the memory model of Algorithm~\ref{alg:train-checkpoint} is inconsistent with the PyTorch implementation, which may lead to non-optimal memory usage.
%PyTorch implementation will not keep all the checkpoints in memory during the entire backward phase.
%Instead, it will release those checkpoints when they will not be used afterward.
%Therefore we derive a more accurate memory usage model, including the output gradient, and design an optimal linear time algorithm that ensures optimal memory utilization in PyTorch (Section~\ref{sec:dynamic_checkpoint}).
%Note that this paper focuses on finding the minimum memory footprint and does not consider the trade-off between memory and computation time.
The lower half of Table~\ref{tbl:comparison} focuses on the memory usage model derived from PyTorch's implementation.
The memory model of Algorithm~\ref{alg:train-checkpoint} is inconsistent with that of PyTorch's implementation.
In this paper, we derive the memory usage model that fits the memory usage reported by PyTorch, as will be demonstrated in Section~\ref{sec:experiment}.
Based on this accurate memory usage model, we design a linear time algorithm that ensures optimal memory utilization (Section~\ref{sec:dynamic_checkpoint}).
Note that this paper focuses on finding the minimum memory footprint and does not consider the trade-off between memory and computation time.

\newpage
\begin{table} 
\begin{center}
\begin{tabular}{|l|c|c|c|c|}
\hline
Chen et al., "Memory-Efficient Training for Deep Neural Networks" &  \checkmark   & \checkmark    & \checkmark    &  \\ 
Feng et al., "Efficient Memory Allocation for Deep Neural Networks" & \checkmark & \checkmark & \checkmark & \checkmark \\
\hline
\end{tabular}
\caption{The comparison of optimization on linear neural networks} \label{tbl:comparison}
\end{table}

\comment{
\subsection{Beyond finding the optimal peak memory using the checkpoint technique}

Many other schemes using the checkpoints have been proposed to solve different problems.

Kirisame et al.**Kirisame et al., "Dynamic Tensor Rematerialization"**, proposed a scheme called {\em Dynamic Tensor Rematerialization}, which is a greedy online algorithm that can checkpoint any DNN model and achieve comparable performance with the current checkpoint techniques. In the simulation, they can achieve $\Omega(\sqrt{N})$ memory budget with only $O(N)$ tensor operations for a $n$-layer linear feedforward network.
}