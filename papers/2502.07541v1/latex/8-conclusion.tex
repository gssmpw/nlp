\section{Conclusion}
\label{sec:conclusion}



In this survey, we have provided a comprehensive overview of current research initiatives on detection of greenwashing in textual corporate communications.  
Determining whether a communication contains greenwashing presents three fundamental challenges. First, the absence of a commonly accepted and actionable definition of greenwashing creates ambiguity, complicating any attempt at standardized assessment. Second, there are significant legal and reputational consequences of being accused of greenwashing. Finally, there are no explicit precedents that could serve as jurisprudence for systematic labeling.
This makes the annotation of actual examples of greenwashing challenging, and indeed, there is currently no large-scale dataset of instances of greenwashing.
For this reason, the detection of greenwashing has remained on a theoretical level without empirical validation~\cite{moodaley_conceptual_2023}. 
Most existing works target intermediate tasks such as identifying climate-relatedness or green claims. This work also serves its purposes: First, determining whether a text can contain greenwashing at all helps restricting attention to the relevant resources.  
Second, decomposing greenwashing into more manageable steps can lead to an overall better performance, as supported by the principles behind the Chain-of-Thought~\cite{cot}. 
Third, using frugal approaches helps reduce costs and energy consumption.
Finally, intermediate tasks can help humans understand the final verdict, which is important for the explainability of decisions. 
Several challenges remain in these works: 
\begin{itemize}
    \item \textit{Evaluation methodology.} As models are capable of tackling more complex tasks, we need tools to correctly evaluate models on these complex tasks. This include building robust evaluation methods for generated texts or building classification benchmarks that are difficult to solve but simple to evaluate. Current results often lack hyper-parameter tuning,  simple baselines, and inter-annotator agreement measures, making it difficult to draw definitive conclusions from them.
    \item  \textit{Model robustness.} When evaluating models, we need to make sure to evaluate also their robustness in real-world applications that exhibit data quality issues or highly imbalanced classes. This includes quantifying the uncertainty of the performance measures. Current works often do not provide confidence intervals or robustness assessments.
    \item \textit{Quantifying information.} Most of the studies we reviewed quantify the amount of text related to a topic, rather than the amount of information. Future work should quantify also the information itself. 
    %, but when dealing with greenwashing, the most important is to quantify the amount of information communicated. Moreover, the information is distributed across many paragraphs and documents. 
    \item \textit{Relying on regulatory texts.} Most existing works identify one or more supposed characteristics of a misleading claim, but do not confront the statements to regulatory texts. As regulatory texts are becoming more precise about the requirements of environmental communications, they will increasingly become the gold standard %might be sufficient basis 
    for identifying problematic claims.
\end{itemize}

%Greenwashing is a barrier to combating climate change, as it misleads consumers who want to choose environmentally responsible products, attracts green investment that should better have gone to truly committed companies, and stifles innovation if companies become convinced that they can get away with merely advertising climate friendliness rather than achieving it. 

Any step toward understanding the characteristics and formalizing greenwashing is a step toward developing AI systems capable of automatically identifying these misleading communications. 
While previous research has laid a foundation for the theoretical understanding of greenwashing, and for the detection of signals that can indicate misleading climate-related communications, future research should focus on building a representative and diverse corpus of real-world cases of potential greenwashing  to first evaluate models and, secondly, to empirically analyze its mechanisms and patterns. We hope that future research will help identify and combat greenwashing more reliably, thereby fostering transparency and accountability in climate communication.

\paragraph{Limitations} This survey provides a comprehensive overview of studies on automatic detection of misleading
climate-related corporate communications and its related tasks as of early 2025. A number of limitations remain: Given the extensive scope of the field, our review concentrated on NLP-based research, providing only limited discussion of topics like ESG prediction, which are predominantly explored through quantitative methods. Furthermore, our review relied  primarily on keyword searches on arXiv, Google Scholar, and ResearchGate, complemented by references from identified papers. In this, we may have overlooked % This approach may have introduced biases, potentially overlooking 
relevant studies that use alternative terminology or are published in less accessible venues. Finally, much of greenwashing happens not on the text level, but on the factual level (with claims that contradict data) or on the multi-modal level (across images or videos). These remain out of scope for our survey.

\paragraph{Acknowledgment} We would like to express our sincere gratitude to Nina Godart and AEF Info for their invaluable contributions and knowledge on the topic. We also extend our thanks to Takaya Sekine CFA for his insightful comments. This work was partially supported by the grant ANR-20-CHIA-0012-01 (“NoRDF”).
