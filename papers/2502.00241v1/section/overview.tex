


% \newpage
\section{Mordal Overview}
\label{sec:overview}

% \mosharaf{Use job or request consistently instead of going back and forth between job, request, and job request.}

Mordal is an efficient pretrained model selection framework that systematically explores pretrained model combinations to create bespoke VLMs for individual use cases. 
It minimizes the search space by leveraging representation similarities across pretrained models and accelerates the exploration process by leveraging observational scaling laws.
Mordal reduces not only computational costs but also enables effective adaptation to new vision encoders and language models, fostering rapid experimentation and innovation in MLLMs.

\paragraph{Design Space.}
Mordal enables users with varying levels of expertise find the best VLM for their downstream tasks. 
Therefore, it must minimize the information needed from the users and the overhead incurred for each job, while offering sufficient flexibility. 
% Determining which alignment dataset to use and the source of pretrained model zoo is as yet an open problem in the VLM community \cite{tong2024cambrian}. 
Specifically, Mordal requires the user to provide an alignment dataset for their task and (optionally) a model zoo containing diverse pretrained models.
Thereafter, it automatically selects pretrained model combination to create a bespoke VLM for the task.
% The process is independent of alignment data and will continue to benefit the community as new datasets and models come out. 

\paragraph{Components.}
% \mosharaf{Components and lifecycle are saying the same thing. Components should be boxes that do things -- systems perspective. Lifecycle should be what the boxes do -- job perspective. We need a litle bit more details of the three/four? pieces from a systems perspective.}

\Cref{fig:overview} outlines the steps involved in Mordal to efficiently explore and evaluate VLM candidates for a given job. 
The framework is structured around three key phases, which designed to streamline the entire process:
% \mosharaf{Fix. Three phases.}

\begin{itemize}
    % \item \textbf{Job Submission.} All pretrained models are gathered and organized. 
    %     The user will submit the alignment data along with target task to initialize a search job.
    
    \item \textbf{Pretrained Model and Candidate Clustering.} Pretrained model takes data for target task as the input to generate representations. Mordal then clusters these models according to their representation similarities. 
    % To obtain the clustered candidate pool, By generating image representations and logits, Mordal .

    \item \textbf{Inter- and Intra-Cluster Mordal Exploration.} Based on the clustering results, Mordal generates a VLM candidate pool and leverages two-stage successive halving to eliminate poor-performing clusters and candidates. 
    % first explores representative combinations from each VLM cluster and then eliminates . Then, the remaining VLM combinations will go through the same exploration process. We use successive halving for exploration.

    \item \textbf{Scaling Prediction.} The scaling prediction is conducted on VLM candidates left after the two-stage exploration. Based on candidates' historical performance on sampled training sets, Mordal constructs linear regression models to predict their final performance on full-size dataset.
\end{itemize}

\paragraph{Lifecyle of a Search Job.}
% The exploration will be performned on sampled dataset.
The lifecycle of a job to Mordal begins with the Job Submission phase, wherein users provide the alignment and target datasets alongside a pretrained model zoo to initialize the search process. For preparation, the alignment data will be automatically sampled for later exploration and prediction.  
Mordal subsequently performs (1) Model Clustering, utilizing image representations and hidden states generated by the pretrained models. 
By employing Centered Kernel Alignment (CKA) as the similarity measurement metric, Mordal efficiently reduces the number of Vision-Language Model (VLM) candidates to evaluate. 
In the (2) Inter-Cluster Exploration phase, representative models from each cluster are assessed, with poorly performing clusters systematically eliminated through an iterative successive halving process. 
This is followed by (3) Intra-Cluster Exploration, wherein the VLM candidates within the remaining clusters are evaluated concurrently using similar strategies. 
Finally, (4) leveraging a Log-Linear Scaling Law, Mordal constructs linear regression models for the remaining candidates according to their historical performance, significantly expediting the search process while preserving search accuracy. 
Together, these components constitute an optimized pipeline for the efficient identification of top-performing vision-language models.
% \mosharaf{Describe this while using 1, 2, etc. step numbers that match with the figure.}
