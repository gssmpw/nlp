@article{thompson2023scope,
  title={On the scope of scientific hypotheses},
  author={Thompson, William Hedley and Skau, Simon},
  journal={Royal Society Open Science},
  volume={10},
  number={8},
  pages={230607},
  year={2023},
  publisher={The Royal Society}
}


@article{majumder2024discoverybench,
  title={Discoverybench: Towards data-driven discovery with large language models},
  author={Majumder, Bodhisattwa Prasad and Surana, Harshit and Agarwal, Dhruv and Mishra, Bhavana Dalvi and Meena, Abhijeetsingh and Prakhar, Aryan and Vora, Tirth and Khot, Tushar and Sabharwal, Ashish and Clark, Peter},
  journal={arXiv preprint arXiv:2407.01725},
  year={2024}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={NeurIPS},
  volume={36},
  year={2024}
}

@article{schmidt2022crispr,
  title={CRISPR activation and interference screens decode stimulation responses in primary human T cells},
  author={Schmidt, Ralf and Steinhart, Zachary and Layeghi, Madeline and Freimer, Jacob W and Bueno, Raymund and Nguyen, Vinh Q and Blaeschke, Franziska and Ye, Chun Jimmie and Marson, Alexander},
  journal={Science},
  volume={375},
  number={6580},
  pages={eabj4008},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{oughtred2019biogrid,
  title={The BioGRID interaction database: 2019 update},
  author={Oughtred, Rose and Stark, Chris and Breitkreutz, Bobby-Joe and Rust, Jennifer and Boucher, Lorrie and Chang, Christie and Kolas, Nadine and O’Donnell, Lara and Leung, Genie and McAdam, Rochelle and others},
  journal={Nucleic acids research},
  volume={47},
  number={D1},
  pages={D529--D541},
  year={2019},
  publisher={Oxford University Press}
}

@article{ghoussaini2021open,
  title={Open Targets Genetics: systematic identification of trait-associated genes using large-scale genetics and functional genomics},
  author={Ghoussaini, Maya and Mountjoy, Edward and Carmona, Miguel and Peat, Gareth and Schmidt, Ellen M and Hercules, Andrew and Fumis, Luca and Miranda, Alfredo and Carvalho-Silva, Denise and Buniello, Annalisa and others},
  journal={Nucleic acids research},
  volume={49},
  number={D1},
  pages={D1311--D1320},
  year={2021},
  publisher={Oxford University Press}
}



@inproceedings{grunwald2020safe,
  title={Safe testing},
  author={Gr{\"u}nwald, Peter and de Heide, Rianne and Koolen, Wouter M},
  booktitle={2020 Information Theory and Applications Workshop (ITA)},
  pages={1--54},
  year={2020},
  organization={IEEE}
}

@article{gtex2020gtex,
  title={The GTEx Consortium atlas of genetic regulatory effects across human tissues},
  author={GTEx Consortium},
  journal={Science},
  volume={369},
  number={6509},
  pages={1318--1330},
  year={2020},
  publisher={American Association for the Advancement of Science}
}

@article{macarthur2017new,
  title={The new NHGRI-EBI Catalog of published genome-wide association studies (GWAS Catalog)},
  author={MacArthur, Jacqueline and Bowler, Emily and Cerezo, Maria and Gil, Laurent and Hall, Peggy and Hastings, Emma and Junkins, Heather and McMahon, Aoife and Milano, Annalisa and Morales, Joannella and others},
  journal={Nucleic acids research},
  volume={45},
  number={D1},
  pages={D896--D901},
  year={2017},
  publisher={Oxford University Press}
}

@article{bycroft2018uk,
  title={The UK Biobank resource with deep phenotyping and genomic data},
  author={Bycroft, Clare and Freeman, Colin and Petkova, Desislava and Band, Gavin and Elliott, Lloyd T and Sharp, Kevin and Motyer, Allan and Vukcevic, Damjan and Delaneau, Olivier and O’Connell, Jared and others},
  journal={Nature},
  volume={562},
  number={7726},
  pages={203--209},
  year={2018},
  publisher={Nature Publishing Group}
}



@incollection{fisher1970statistical,
  title={Statistical methods for research workers},
  author={Fisher, Ronald Aylmer},
  booktitle={Breakthroughs in statistics: Methodology and distribution},
  pages={66--70},
  year={1970},
  publisher={Springer}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@book{popper1959logic,
  author    = {Popper, Karl},
  title     = {The Logic of Scientific Discovery},
  year      = {1959},
  publisher = {Hutchinson},
  address   = {London}
}

@book{kuhn1962structure,
  author    = {Kuhn, Thomas S.},
  title     = {The Structure of Scientific Revolutions},
  year      = {1962},
  publisher = {University of Chicago Press},
  address   = {Chicago},
  edition   = {1st}
}

@book{lakatos1978methodology,
  author    = {Lakatos, Imre},
  title     = {The Methodology of Scientific Research Programmes},
  year      = {1978},
  publisher = {Cambridge University Press},
  address   = {Cambridge}
}

@book{vanfraassen1980scientific,
  author    = {van Fraassen, Bas C.},
  title     = {The Scientific Image},
  year      = {1980},
  publisher = {Clarendon Press},
  address   = {Oxford}
}

@book{goodman1983fact,
  author    = {Goodman, Nelson},
  title     = {Fact, Fiction, and Forecast},
  year      = {1983},
  publisher = {Harvard University Press},
  address   = {Cambridge, MA}
}

@article{maxwell2012popper,
  author    = {Maxwell, Nicholas},
  title     = {Popper, Kuhn, Lakatos and Aim-Oriented Empiricism},
  journal   = {arXiv preprint},
  year      = {2012},
  eprint    = {1208.5219},
  archiveprefix = {arXiv},
  primaryclass = {physics.hist-ph}
}

@article{rubin2025replication,
  author    = {Rubin, Mark},
  title     = {The Replication Crisis is Less of a "Crisis" in Lakatos' Philosophy of Science},
  journal   = {European Journal for Philosophy of Science},
  year      = {2025},
  volume    = {15},
  number    = {5},
  doi       = {10.1007/s13194-024-00629-x}
}

@misc{lakatos2023bridge,
  author    = {{Philosophy Institute}},
  title     = {Imre Lakatos’ Approach: Bridging Popper and Kuhn in Philosophy of Science},
  year      = {2023},
  url       = {https://philosophy.institute/philosophy-of-science-and-cosmology/imre-lakatos-philosophy-science-bridge/},
  note      = {Accessed: 2025-01-29}
}

@article{ridnik2024code,
  title={Code generation with alphacodium: From prompt engineering to flow engineering},
  author={Ridnik, Tal and Kredo, Dedy and Friedman, Itamar},
  journal={arXiv preprint arXiv:2401.08500},
  year={2024}
}
@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}

@incollection{agassi2014popper,
  author    = {Agassi, Joseph},
  title     = {Popper and His Popular Critics: Thomas Kuhn, Paul Feyerabend and Imre Lakatos},
  booktitle = {SpringerBriefs in Philosophy},
  year      = {2014},
  publisher = {Springer},
  doi       = {10.1007/978-3-319-06587-8}
}

@article{webpage10,
  author    = {Cambridge University Press},
  title     = {Normal Science and Dogmatism, Paradigms and Progress: Kuhn ‘versus’ Popper and Lakatos},
  year      = {2009},
}

@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@misc{gendron2024largelanguagemodelsstrong,
      title={Large Language Models Are Not Strong Abstract Reasoners}, 
      author={Gaël Gendron and Qiming Bao and Michael Witbrock and Gillian Dobbie},
      year={2024},
      eprint={2305.19555},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.19555}, 
}

@misc{yang2024languagemodelsinductivereasoners,
      title={Language Models as Inductive Reasoners}, 
      author={Zonglin Yang and Li Dong and Xinya Du and Hao Cheng and Erik Cambria and Xiaodong Liu and Jianfeng Gao and Furu Wei},
      year={2024},
      eprint={2212.10923},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.10923}, 
}

@misc{moskvichev2023conceptarcbenchmarkevaluatingunderstanding,
      title={The ConceptARC Benchmark: Evaluating Understanding and Generalization in the ARC Domain}, 
      author={Arseny Moskvichev and Victor Vikram Odouard and Melanie Mitchell},
      year={2023},
      eprint={2305.07141},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.07141}, 
}

@misc{mirchandani2023largelanguagemodelsgeneral,
      title={Large Language Models as General Pattern Machines}, 
      author={Suvir Mirchandani and Fei Xia and Pete Florence and Brian Ichter and Danny Driess and Montserrat Gonzalez Arenas and Kanishka Rao and Dorsa Sadigh and Andy Zeng},
      year={2023},
      eprint={2307.04721},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2307.04721}, 
}

@misc{tang2023largelanguagemodelsincontext,
      title={Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners}, 
      author={Xiaojuan Tang and Zilong Zheng and Jiaqi Li and Fanxu Meng and Song-Chun Zhu and Yitao Liang and Muhan Zhang},
      year={2023},
      eprint={2305.14825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14825}, 
}

@misc{xu2024largelanguagemodelsreally,
      title={Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation and Beyond}, 
      author={Fangzhi Xu and Qika Lin and Jiawei Han and Tianzhe Zhao and Jun Liu and Erik Cambria},
      year={2024},
      eprint={2306.09841},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.09841}, 
}


@misc{han2023inductivereasoninghumanslarge,
      title={Inductive reasoning in humans and large language models}, 
      author={Simon J. Han and Keith Ransom and Andrew Perfors and Charles Kemp},
      year={2023},
      eprint={2306.06548},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.06548}, 
}


@misc{xu2024llmsabstractionreasoningcorpus,
      title={LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and the Importance of Object-based Representations}, 
      author={Yudong Xu and Wenhao Li and Pashootan Vaezipoor and Scott Sanner and Elias B. Khalil},
      year={2024},
      eprint={2305.18354},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.18354}, 
}



@InProceedings{pmlr-v139-alet21a,
  title = 	 {A large-scale benchmark for few-shot program induction and synthesis},
  author =       {Alet, Ferran and Lopez-Contreras, Javier and Koppel, James and Nye, Maxwell and Solar-Lezama, Armando and Lozano-Perez, Tomas and Kaelbling, Leslie and Tenenbaum, Joshua},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {175--186},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/alet21a/alet21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/alet21a.html},
  abstract = 	 {A landmark challenge for AI is to learn flexible, powerful representations from small numbers of examples. On an important class of tasks, hypotheses in the form of programs provide extreme generalization capabilities from surprisingly few examples. However, whereas large natural few-shot learning image benchmarks have spurred progress in meta-learning for deep networks, there is no comparably big, natural program-synthesis dataset that can play a similar role. This is because, whereas images are relatively easy to label from internet meta-data or annotated by non-experts, generating meaningful input-output examples for program induction has proven hard to scale. In this work, we propose a new way of leveraging unit tests and natural inputs for small programs as meaningful input-output examples for each sub-program of the overall program. This allows us to create a large-scale naturalistic few-shot program-induction benchmark and propose new challenges in this domain. The evaluation of multiple program induction and synthesis algorithms points to shortcomings of current methods and suggests multiple avenues for future work.}
}


@misc{webb2023emergentanalogicalreasoninglarge,
      title={Emergent Analogical Reasoning in Large Language Models}, 
      author={Taylor Webb and Keith J. Holyoak and Hongjing Lu},
      year={2023},
      eprint={2212.09196},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2212.09196}, 
}


@inproceedings{honovich-etal-2023-instruction,
    title = "Instruction Induction: From Few Examples to Natural Language Task Descriptions",
    author = "Honovich, Or  and
      Shaham, Uri  and
      Bowman, Samuel R.  and
      Levy, Omer",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.108",
    doi = "10.18653/v1/2023.acl-long.108",
    pages = "1935--1952",
    abstract = "Large language models are able to perform a task by conditioning on a few input-output demonstrations - a paradigm known as in-context learning. We show that language models can explicitly infer an underlying task from a few demonstrations by prompting them to generate a natural language instruction that fits the examples. To explore this ability, we introduce the instruction induction challenge, compile a dataset consisting of 24 tasks, and define a novel evaluation metric based on executing the generated instruction. We discover that, to a large extent, the ability to generate instructions does indeed emerge when using a model that is both large enough and aligned to follow instructions; InstructGPT achieves 65.7{\%} of human performance in our execution-based metric, while the original GPT-3 model reaches only 9.8{\%} of human performance. This surprising result suggests that instruction induction might be a viable learning paradigm in and of itself, where instead of fitting a set of latent continuous parameters to the data, one searches for the best description in the natural language hypothesis space.",
}


@misc{qiu2024phenomenalpuzzlingtestinginductive,
      title={Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement}, 
      author={Linlu Qiu and Liwei Jiang and Ximing Lu and Melanie Sclar and Valentina Pyatkin and Chandra Bhagavatula and Bailin Wang and Yoon Kim and Yejin Choi and Nouha Dziri and Xiang Ren},
      year={2024},
      eprint={2310.08559},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.08559}, 
}

@misc{wang2024hypothesissearchinductivereasoning,
      title={Hypothesis Search: Inductive Reasoning with Language Models}, 
      author={Ruocheng Wang and Eric Zelikman and Gabriel Poesia and Yewen Pu and Nick Haber and Noah D. Goodman},
      year={2024},
      eprint={2309.05660},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.05660}, 
}


@misc{wang2024scimonscientificinspirationmachines,
      title={SciMON: Scientific Inspiration Machines Optimized for Novelty}, 
      author={Qingyun Wang and Doug Downey and Heng Ji and Tom Hope},
      year={2024},
      eprint={2305.14259},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14259}, 
}


@misc{baek2024researchagentiterativeresearchidea,
      title={ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models}, 
      author={Jinheon Baek and Sujay Kumar Jauhar and Silviu Cucerzan and Sung Ju Hwang},
      year={2024},
      eprint={2404.07738},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.07738}, 
}

@misc{yang2024largelanguagemodelsautomated,
      title={Large Language Models for Automated Open-domain Scientific Hypotheses Discovery}, 
      author={Zonglin Yang and Xinya Du and Junxian Li and Jie Zheng and Soujanya Poria and Erik Cambria},
      year={2024},
      eprint={2309.02726},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.02726}, 
}

@misc{huang2024mlagentbenchevaluatinglanguageagents,
      title={MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation}, 
      author={Qian Huang and Jian Vora and Percy Liang and Jure Leskovec},
      year={2024},
      eprint={2310.03302},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.03302}, 
}

@misc{tian2024scicoderesearchcodingbenchmark,
      title={SciCode: A Research Coding Benchmark Curated by Scientists}, 
      author={Minyang Tian and Luyu Gao and Shizhuo Dylan Zhang and Xinan Chen and Cunwei Fan and Xuefei Guo and Roland Haas and Pan Ji and Kittithat Krongchon and Yao Li and Shengyan Liu and Di Luo and Yutao Ma and Hao Tong and Kha Trinh and Chenyu Tian and Zihan Wang and Bohao Wu and Yanyu Xiong and Shengzhu Yin and Minhui Zhu and Kilian Lieret and Yanxin Lu and Genglin Liu and Yufeng Du and Tianhua Tao and Ofir Press and Jamie Callan and Eliu Huerta and Hao Peng},
      year={2024},
      eprint={2407.13168},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.13168}, 
}

@misc{li2024mlrcopilotautonomousmachinelearning,
      title={MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents}, 
      author={Ruochen Li and Teerth Patel and Qingyun Wang and Xinya Du},
      year={2024},
      eprint={2408.14033},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.14033}, 
}

@misc{lu2024aiscientistfullyautomated,
      title={The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery}, 
      author={Chris Lu and Cong Lu and Robert Tjarko Lange and Jakob Foerster and Jeff Clune and David Ha},
      year={2024},
      eprint={2408.06292},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.06292}, 
}

@misc{si2024llmsgeneratenovelresearch,
      title={Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers}, 
      author={Chenglei Si and Diyi Yang and Tatsunori Hashimoto},
      year={2024},
      eprint={2409.04109},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.04109}, 
}

@misc{gu2024bladebenchmarkinglanguagemodel,
      title={BLADE: Benchmarking Language Model Agents for Data-Driven Science}, 
      author={Ken Gu and Ruoxi Shang and Ruien Jiang and Keying Kuang and Richard-John Lin and Donghe Lyu and Yue Mao and Youran Pan and Teng Wu and Jiaqian Yu and Yikun Zhang and Tianmai M. Zhang and Lanyi Zhu and Mike A. Merrill and Jeffrey Heer and Tim Althoff},
      year={2024},
      eprint={2408.09667},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.09667}, 
}

@misc{guo2024dsagentautomateddatascience,
      title={DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning}, 
      author={Siyuan Guo and Cheng Deng and Ying Wen and Hechang Chen and Yi Chang and Jun Wang},
      year={2024},
      eprint={2402.17453},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.17453}, 
}

@misc{hu2024infiagentdabenchevaluatingagentsdata,
      title={InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks}, 
      author={Xueyu Hu and Ziyu Zhao and Shuang Wei and Ziwei Chai and Qianli Ma and Guoyin Wang and Xuwu Wang and Jing Su and Jingjing Xu and Ming Zhu and Yao Cheng and Jianbo Yuan and Jiwei Li and Kun Kuang and Yang Yang and Hongxia Yang and Fei Wu},
      year={2024},
      eprint={2401.05507},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.05507}, 
}

@misc{majumder2024discoverybenchdatadrivendiscoverylarge,
      title={DiscoveryBench: Towards Data-Driven Discovery with Large Language Models}, 
      author={Bodhisattwa Prasad Majumder and Harshit Surana and Dhruv Agarwal and Bhavana Dalvi Mishra and Abhijeetsingh Meena and Aryan Prakhar and Tirth Vora and Tushar Khot and Ashish Sabharwal and Peter Clark},
      year={2024},
      eprint={2407.01725},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.01725}, 
}

@misc{ifargan2024autonomousllmdrivenresearchdata,
      title={Autonomous LLM-driven research from data to human-verifiable research papers}, 
      author={Tal Ifargan and Lukas Hafner and Maor Kern and Ori Alcalay and Roy Kishony},
      year={2024},
      eprint={2404.17605},
      archivePrefix={arXiv},
      primaryClass={q-bio.OT},
      url={https://arxiv.org/abs/2404.17605}, 
}


@article{boiko_autonomous_2023,
	title = {Autonomous chemical research with large language models},
	volume = {624},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/s41586-023-06792-0},
	doi = {10.1038/s41586-023-06792-0},
	abstract = {Transformer-based large language models are making significant strides in various fields, such as natural language processing1–5, biology6,7, chemistry8–10 and computer programming11,12. Here, we show the development and capabilities of Coscientist, an artificial intelligence system driven by GPT-4 that autonomously designs, plans and performs complex experiments by incorporating large language models empowered by tools such as internet and documentation search, code execution and experimental automation. Coscientist showcases its potential for accelerating research across six diverse tasks, including the successful reaction optimization of palladium-catalysed cross-couplings, while exhibiting advanced capabilities for (semi-)autonomous experimental design and execution. Our findings demonstrate the versatility, efficacy and explainability of artificial intelligence systems like Coscientist in advancing research.},
	number = {7992},
	journal = {Nature},
	author = {Boiko, Daniil A. and MacKnight, Robert and Kline, Ben and Gomes, Gabe},
	month = dec,
	year = {2023},
	pages = {570--578},
}


@misc{liu2024aigsgeneratingscienceaipowered,
      title={AIGS: Generating Science from AI-Powered Automated Falsification}, 
      author={Zijun Liu and Kaiming Liu and Yiqi Zhu and Xuanyu Lei and Zonghan Yang and Zhenhe Zhang and Peng Li and Yang Liu},
      year={2024},
      eprint={2411.11910},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.11910}, 
}


@misc{ajith2024litsearchretrievalbenchmarkscientific,
      title={LitSearch: A Retrieval Benchmark for Scientific Literature Search}, 
      author={Anirudh Ajith and Mengzhou Xia and Alexis Chevalier and Tanya Goyal and Danqi Chen and Tianyu Gao},
      year={2024},
      eprint={2407.18940},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2407.18940}, 
}


@misc{press2024citemelanguagemodelsaccurately,
      title={CiteME: Can Language Models Accurately Cite Scientific Claims?}, 
      author={Ori Press and Andreas Hochlehnert and Ameya Prabhu and Vishaal Udandarao and Ofir Press and Matthias Bethge},
      year={2024},
      eprint={2407.12861},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12861}, 
}


@misc{darcy2024margmultiagentreviewgeneration,
      title={MARG: Multi-Agent Review Generation for Scientific Papers}, 
      author={Mike D'Arcy and Tom Hope and Larry Birnbaum and Doug Downey},
      year={2024},
      eprint={2401.04259},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.04259}, 
}


@misc{liang2023largelanguagemodelsprovide,
      title={Can large language models provide useful feedback on research papers? A large-scale empirical analysis}, 
      author={Weixin Liang and Yuhui Zhang and Hancheng Cao and Binglu Wang and Daisy Ding and Xinyu Yang and Kailas Vodrahalli and Siyu He and Daniel Smith and Yian Yin and Daniel McFarland and James Zou},
      year={2023},
      eprint={2310.01783},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.01783}, 
}


@misc{zhang2024masswnewdatasetbenchmark,
      title={MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows}, 
      author={Xingjian Zhang and Yutong Xie and Jin Huang and Jinge Ma and Zhaoying Pan and Qijia Liu and Ziyang Xiong and Tolga Ergen and Dongsub Shim and Honglak Lee and Qiaozhu Mei},
      year={2024},
      eprint={2406.06357},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.06357}, 
}

@book{Popper1935-POPTLO-7,
	address = {London, England},
	author = {Karl R. Popper},
	editor = {},
	publisher = {Routledge},
	title = {The Logic of Scientific Discovery},
	year = {1935}
}

@misc{majumder2024datadrivendiscoverylargegenerative,
      title={Data-driven Discovery with Large Generative Models}, 
      author={Bodhisattwa Prasad Majumder and Harshit Surana and Dhruv Agarwal and Sanchaita Hazra and Ashish Sabharwal and Peter Clark},
      year={2024},
      eprint={2402.13610},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13610}, 
}


@misc{roohani2024biodiscoveryagentaiagentdesigning,
      title={BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments}, 
      author={Yusuf Roohani and Andrew Lee and Qian Huang and Jian Vora and Zachary Steinhart and Kexin Huang and Alexander Marson and Percy Liang and Jure Leskovec},
      year={2024},
      eprint={2405.17631},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.17631}, 
}


@misc{madaan2023selfrefineiterativerefinementselffeedback,
      title={Self-Refine: Iterative Refinement with Self-Feedback}, 
      author={Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark},
      year={2023},
      eprint={2303.17651},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.17651}, 
}

@misc{ridnik2024codegenerationalphacodiumprompt,
      title={Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering}, 
      author={Tal Ridnik and Dedy Kredo and Itamar Friedman},
      year={2024},
      eprint={2401.08500},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.08500}, 
}



@Inbook{Fisher1992,
author="Fisher, R. A.",
editor="Kotz, Samuel
and Johnson, Norman L.",
title="Statistical Methods for Research Workers",
bookTitle="Breakthroughs in Statistics: Methodology and Distribution",
year="1992",
publisher="Springer New York",
address="New York, NY",
pages="66--70",
abstract="The prime object of this book is to put into the hands of research workers, and especially of biologists, the means of applying statistical tests accurately to numerical data accumulated in their own laboratories or available in the literature.",
isbn="978-1-4612-4380-9",
doi="10.1007/978-1-4612-4380-9_6",
url="https://doi.org/10.1007/978-1-4612-4380-9_6"
}


@misc{grünwald2023safetesting,
      title={Safe Testing}, 
      author={Peter Grünwald and Rianne de Heide and Wouter Koolen},
      year={2023},
      eprint={1906.07801},
      archivePrefix={arXiv},
      primaryClass={math.ST},
      url={https://arxiv.org/abs/1906.07801}, 
}


@article{
doi:10.1126/science.abj4008,
author = {Ralf Schmidt  and Zachary Steinhart  and Madeline Layeghi  and Jacob W. Freimer  and Raymund Bueno  and Vinh Q. Nguyen  and Franziska Blaeschke  and Chun Jimmie Ye  and Alexander Marson },
title = {CRISPR activation and interference screens decode stimulation responses in primary human T cells},
journal = {Science},
volume = {375},
number = {6580},
pages = {eabj4008},
year = {2022},
doi = {10.1126/science.abj4008},
URL = {https://www.science.org/doi/abs/10.1126/science.abj4008},
eprint = {https://www.science.org/doi/pdf/10.1126/science.abj4008},
abstract = {Regulation of cytokine production in stimulated T cells can be disrupted in autoimmunity, immunodeficiencies, and cancer. Systematic discovery of stimulation-dependent cytokine regulators requires both loss-of-function and gain-of-function studies, which have been challenging in primary human cells. We now report genome-wide CRISPR activation (CRISPRa) and interference (CRISPRi) screens in primary human T cells to identify gene networks controlling interleukin-2 (IL-2) and interferon-γ (IFN-γ) production. Arrayed CRISPRa confirmed key hits and enabled multiplexed secretome characterization, revealing reshaped cytokine responses. Coupling CRISPRa screening with single-cell RNA sequencing enabled deep molecular characterization of screen hits, revealing how perturbations tuned T cell activation and promoted cell states characterized by distinct cytokine expression profiles. These screens reveal genes that reprogram critical immune cell functions, which could inform the design of immunotherapies. CRISPR activation (CRISPRa) and CRISPR interference (CRISPRi) screens are powerful tools to test the gain and loss of gene function, but their use has largely been limited to immortalized cell lines. Schmidt et al. report an optimized method that allowed them to perform genome-wide CRISPRa and CRISPRi screens on primary human T cells. This approach was then used to scrutinize genes regulating the production of key therapeutically relevant cytokines. The combination of pooled CRISPRa perturbations with single-cell RNA sequencing (CRISPRa Perturb-seq) then allowed them to interrogate how the regulators of cytokine production can control T cell activation and programming into distinct postactivation states. —STS Complementary gain- and loss-of-function CRISPR-based genetic screens reveal tunable regulators of human T cell activity.}}


@article{Wasserstein29032019,
author = {Ronald L. Wasserstein, Allen L. Schirm and Nicole A. Lazar},
title = {Moving to a World Beyond “p<0.05”},
journal = {The American Statistician},
volume = {73},
number = {sup1},
pages = {1--19},
year = {2019},
publisher = {ASA Website},
doi = {10.1080/00031305.2019.1583913},
URL = { 
        https://doi.org/10.1080/00031305.2019.1583913
},
eprint = { 
        https://doi.org/10.1080/00031305.2019.1583913
}
}


@article{li2024critical,
  title={CriticAL: Critic Automation with Language Models},
  author={Li, Michael Y and Vajipey, Vivek and Goodman, Noah D and Fox, Emily B},
  journal={arXiv preprint arXiv:2411.06590},
  year={2024}
}

@misc{manning2024automatedsocialsciencelanguage,
      title={Automated Social Science: Language Models as Scientist and Subjects}, 
      author={Benjamin S. Manning and Kehang Zhu and John J. Horton},
      year={2024},
      eprint={2404.11794},
      archivePrefix={arXiv},
      primaryClass={econ.GN},
      url={https://arxiv.org/abs/2404.11794}, 
}

@article{vovk2021values,
  title={E-values: Calibration, combination and applications},
  author={Vovk, Vladimir and Wang, Ruodu},
  journal={The Annals of Statistics},
  volume={49},
  number={3},
  pages={1736--1754},
  year={2021},
  publisher={Institute of Mathematical Statistics}
}

@misc{lehr2024chatgptresearchscientistprobing,
      title={ChatGPT as Research Scientist: Probing GPT's Capabilities as a Research Librarian, Research Ethicist, Data Generator and Data Predictor}, 
      author={Steven A. Lehr and Aylin Caliskan and Suneragiri Liyanage and Mahzarin R. Banaji},
      year={2024},
      eprint={2406.14765},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.14765}, 
}

@techreport{shafer2023statistical,
  title={Statistical testing with optional continuation},
  author={Shafer, Glenn},
  year={2023},
  institution={Working Paper 63 at probabilityandfinance. com}
}

@article{newey1994large,
  title={Large sample estimation and hypothesis testing},
  author={Newey, Whitney K and McFadden, Daniel},
  journal={Handbook of econometrics},
  volume={4},
  pages={2111--2245},
  year={1994},
  publisher={Elsevier}
}

@article{brown1975400,
  title={400: A method for combining non-independent, one-sided tests of significance},
  author={Brown, Morton B},
  journal={Biometrics},
  pages={987--992},
  year={1975},
  publisher={JSTOR}
}

@article{yao2023react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={ICLR},
  year={2023}
}

@book{popper2005logic,
  title={The logic of scientific discovery},
  author={Popper, Karl},
  year={2005},
  publisher={Routledge}
}

@article{zhou2024hypothesis,
  title={Hypothesis Generation with Large Language Models},
  author={Zhou, Yangqiaoyu and Liu, Haokun and Srivastava, Tejes and Mei, Hongyuan and Tan, Chenhao},
  journal={arXiv preprint arXiv:2404.04326},
  year={2024}
}

@article{jun2022hypothesis,
  title={Hypothesis formalization: Empirical findings, software limitations, and design implications},
  author={Jun, Eunice and Birchfield, Melissa and De Moura, Nicole and Heer, Jeffrey and Just, Ren{\'e}},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={29},
  number={1},
  pages={1--28},
  year={2022},
  publisher={ACM New York, NY}
}

@book{godfrey2009theory,
  title={Theory and reality: An introduction to the philosophy of science},
  author={Godfrey-Smith, Peter},
  year={2009},
  publisher={University of Chicago Press}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={ACM Transactions on Information Systems},
  year={2023},
  publisher={ACM New York, NY}
}

@article{wang2023hypothesis,
  title={Hypothesis search: Inductive reasoning with language models},
  author={Wang, Ruocheng and Zelikman, Eric and Poesia, Gabriel and Pu, Yewen and Haber, Nick and Goodman, Noah D},
  journal={ICLR},
  year={2024}
}


@article{shafer2019language,
  title={The language of betting as a strategy for statistical and scientific communication},
  author={Shafer, Glenn},
  journal={arXiv preprint arXiv:1903.06991},
  year={2019}
}

@article{neyman1928use,
  title={On the use and interpretation of certain test criteria for purposes of statistical inference part I},
  author={Neyman, Jerzy and Pearson, Egon S},
  journal={Biometrika},
  volume={20},
  number={1-2},
  pages={175--240},
  year={1928},
  publisher={Oxford University Press}
}

@inproceedings{neyman1933testing,
  title={The testing of statistical hypotheses in relation to probabilities a priori},
  author={Neyman, Jerzy and Pearson, Egon S},
  booktitle={Mathematical proceedings of the Cambridge philosophical society},
  volume={29},
  pages={492--510},
  year={1933},
  organization={Cambridge University Press}
}

@article{fisher1936design,
  title={Design of experiments},
  author={Fisher, Ronald Aylmer},
  journal={British Medical Journal},
  volume={1},
  number={3923},
  pages={554},
  year={1936},
  publisher={BMJ Publishing Group}
}

@article{ioannidis2005most,
  title={Why most published research findings are false},
  author={Ioannidis, John PA},
  journal={PLoS medicine},
  volume={2},
  number={8},
  pages={e124},
  year={2005},
  publisher={Public Library of Science}
}

@article{open2015estimating,
  title={Estimating the reproducibility of psychological science},
  author={Open Science Collaboration},
  journal={Science},
  volume={349},
  number={6251},
  pages={aac4716},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{benjamini2020selective,
  title={Selective inference: The silent killer of replicability},
  author={Benjamini, Yoav},
  year={2020},
  publisher={PubPub}
}

@article{benjamini1995controlling,
  title={Controlling the false discovery rate: a practical and powerful approach to multiple testing},
  author={Benjamini, Yoav and Hochberg, Yosef},
  journal={Journal of the Royal statistical society: series B (Methodological)},
  volume={57},
  number={1},
  pages={289--300},
  year={1995},
  publisher={Wiley Online Library}
}

@article{wang2022false,
  title={False discovery rate control with e-values},
  author={Wang, Ruodu and Ramdas, Aaditya},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={84},
  number={3},
  pages={822--852},
  year={2022},
  publisher={Oxford University Press}
}