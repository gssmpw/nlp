\section{Proof of Result in \Cref{sec:strat_evaluation}}


\begin{proof}[\textbf{Proof of \Cref{thm:evaluation}}]
To prove this result, we will apply Bauer Maximum Principle (see 7.69 of \citealt{aliprantis2006infinite}). 

In a first step, we establish that the mapping $H \mapsto \reg_F(s,H) = \sup_{s' \in \Scal} \U[F]{s',H} - \U[F]{s,H}$ is convex and upper semi-continuous on $\Delta([0,1])$ under the weak topology.

We start by establishing the upper semi-continuity of the utility $u(b,h;v)$ of the buyer. In particular, we claim that $(b,h, v) \mapsto u(b,h;v) = (v - b) \mathbbm{1}(b \geq h)$ is upper semi-continuous on $[0,1]^3$. To see this, note that
	\begin{itemize}
		\item $(b,h,v) \mapsto (v-b)$ is continuous and therefore upper semi-continuous on $[0,1]^3$;
		\item $(b,h,v) \mapsto \mathbbm{1}(b \geq h)$ is upper semi-continuous on $[0,1]^3$ because for every $y \in \mathbb{R}$, the level set $\{(b,h,v) \mid \mathbbm{1}(b \geq h) \geq y\}$ is either empty or equal to $\{(b,h,v) \mid b \geq h\}$, both of which are closed.
	\end{itemize} 
	As the product of two upper semi-continuous functions is upper semi-continuous, we get that $u(b,h;v)$ is upper semi-continuous on $[0,1]^3$, as desired.
	
	Next, we show that $\mathcal{U}: (J,H) \mapsto  \E_{((v,b), h) \sim J \times H}[u(b,h;v)]$ is upper semi-continuous on $\Delta([0,1]^2) \times \Delta([0,1])$ with respect to the weak topology. Let $(J,H) \in \Delta([0,1]^2) \times \Delta([0,1])$ and consider a sequence $(J_n, H_n)$ which converges to $(J,H)$ in the weak topology. As we established that $u$ upper semi-continuous on $[0,1]^3$, we have by the Portmonteau lemma that $\limsup_{n \to \infty} \E_{J_n \times H_n}[u(b,h;v)] \leq \E_{J \times H}[u(b,h;v)]$. Therefore, $U$ is upper semi-continuous on\\ ${\Delta([0,1]^2) \times \Delta([0,1])}$ with respect to the weak topology.
	
	Now, recall that each $s' \in \Scal$ has an associated joint distribution $J_{s',F}$ of value-bid pairs $(v,b)$ such that the marginal distribution of $v$ is $F$. Moreover, by Fubini's Theorem, we have
	\begin{align*}
		\U[F]{s',H} = \mathbb{E}_{(v, h) \sim F \times H}  \left[ \mathbb{E}_{b \sim s'(v)} \left[ u(b,h;v) \right] \right] = \E_{((v,b), h) \sim J_{s',F} \times H}[u(b,h;v)] = \U{J_{s',F},H}\,.
	\end{align*}
	
    For a given $F$, let $\mathcal J \coloneqq \{J \in \Delta([0,1]^2) \mid \Prob_{(v,b) \sim J}(v \leq x) = F(x)\}$ be the set of all value-bid joint distributions with $F$ as the marginal distribution of $v$. Then, for every highest-bid distribution $H \in \Delta([0,1])$, we have
	\begin{align*}
		\sup_{s' \in \Scal}\ \U[F]{s',H}\ =\ \sup_{J \in \mathcal J}\ \U{J,H}\,.
	\end{align*}
	It is straightforward to check that $\mathcal J$ is closed under the weak topology. We also note that $\Delta([0,1]^2)$ is compact under the weak topology as it is the set of distributions over a compact domain. Therefore, $\mathcal{J}$ is compact as it is a closed subset of a compact set. Combining this with the upper semi-continuity of $\U{J,H}$ allows us to invoke the Maximum Theorem (see Lemma~17.30 of \citealt{aliprantis2006infinite}) , which implies that the optimal-value function $H \mapsto \sup_{J \in \mathcal J} \U{J,H}$ is also upper semi-continuous.
	
    To conclude that $H \mapsto \reg_F(s,H)$ is upper semi-continuous, we need one more ingredient: continuity of $H \mapsto \U[F]{s,H}$. 
    Consider the function $f(h) \coloneqq \E_{v \sim F, b \sim s(v)}[(v-b) \cdot \mathbbm{1} \{b \geq h\}]$. Note that, as $f$ is bounded,  it is sufficient to prove that $f$ is continuous on $[0,1]$ to conclude that $H \mapsto \U[F]{s,H}$ is continuous in $\Delta([0,1])$ under the weak topology. This follows from the definition of the weak convergence. 
    
    Let us prove that $f$ is continuous. Recall that by assumption, the bid distribution $P_{s,F}$ is absolutely continuous. Hence, for every $\epsilon > 0$, there exists a $\delta$ such that for every measurable set $A \subset [0,1]$, we have that $P_{s,F}(A) \leq \epsilon$ whenever $\lambda(A) \leq \delta$, where $\lambda(\cdot)$ denotes the Lebesgue measure on $[0,1]$. Moreover, remark that for every $h_1,h_2 \in [0,1]$ we have that
    \begin{align*}
        |f(h_1) - f(h_2)| 
        &= \left| \E_{v \sim F, b\sim s(v)}[(v - b) \mathbbm{1}(\min\{h_1, h_2\} \leq b < \max\{h_1, h_2\}) \right| \\
        &\leq P_{s,F}(\min\{h_1, h_2\} \leq b < \max\{h_1, h_2\}) \,.
    \end{align*}
    Hence, for every $\epsilon > 0$, there exists $\delta$ such that for every for every $h_1,h_2 \in [0,1]$ with $|h_1 - h_2| \leq \delta$, we have that
	\begin{align*}
		|f(h_1) - f(h_2)| \leq
		P_{s,F}(\min\{h_1, h_2\} \leq b < \max\{h_1, h_2\})
		\leq \epsilon\,.
	\end{align*}
	This implies that $f$ is continuous. Hence, $H \mapsto \U[F]{s,H}$ is continuous.
    
	Altogether, we can combine the upper semi-continuity of $H \mapsto \sup_{s' \in \Scal} \U[F]{s',H}$ and the continuity of $H \mapsto \U[F]{s,H}$ to get the upper semi-continuity of $H \mapsto \reg_F(s,H) = \sup_{s' \in \Scal} \U[F]{s',H} - \U[F]{s,H}$. 
    
    Moreover, as $H \mapsto \reg_F(s,H)$ is the pointwise supremum of linear functionals $H \mapsto \U[F]{s',H} - \U[F]{s,H}$ on $\Delta([0,1])$, it is convex. Together with the fact that $\Delta([0,1])$ is a compact and convex locally-convex Hausdorff space in the weak topology, this allows us to apply the Bauer Maximum Principle (see 7.69 of \citealt{aliprantis2006infinite}). Therefore,  $H \mapsto \reg_F(s,H)$ has a maximizer that is an extreme point of $\Delta([0,1])$, i.e., it has a maximizer of the form $H = \delta_h$ for some $h \in [0,1]$. Therefore, we have shown the first equality of the proposition, namely
	\begin{align*}
		\sup_{H \in \Delta([0,1])} \reg_F(s,H)\ =\ \sup_{h\in [0,1]} \reg_F(s,\delta_h)\,.
	\end{align*}
	To see the second equality, observe that if the highest competing bid distribution is known to be the point mass on $h$, i.e., $H = \delta_h$, then the utility-maximizing bidding strategy simply bids $h$ whenever the value $v$ is greater than or equal to $h$. In other words, $\reg_F(s,\delta_h)\ =\ \E_{v \sim F}\left[ (v-h) \cdot \mathbbm{1}(v \geq h) \right]\ -\ \U[F]{s,\delta_h}.$
\end{proof}


\section{Proofs of Results in \Cref{sec:minimax}}

\subsection{Proof of \Cref{remark:kernel}}\label{appendix:minimax-remark}
Given a quantile-based bidding strategy $Q \in \mathcal{Q}$, we note that for any fixed $B = (b,1] \in \borel$, the map 
	\begin{align*}
		v \mapsto \kappa_{\s[Q]}(B, v) = \begin{cases}
			\mathbbm{1} \{ Q(F(v)) \in B \} &\text{if }Y(v) \in \{\{F(v)\}, \emptyset\}\\
			\frac{\lambda(Q^{-1}(B) \cap Y(v))}{\lambda(Y(v))} &\text{otherwise}
		\end{cases}
	\end{align*} 
is a non-decreasing function, and therefore measurable, because $Y(v_1)\succcurlyeq Y(v_2)$ for all $v_1 \geq v_2$. As ${\{(b,1]\mid b\in [0,1]\}}$ generates $\mathcal B$, $\kappa_{\s[Q]}$ is a Markov kernel and $\s[Q] \in \Scal$.


\subsection{Proof of Lemmas in \Cref{sec:minimax}}\label{appendix:minimax-lemmas}

\begin{proof}[\textbf{Proof of \Cref{lemma:quantile-based-bidding}}]
	Define $V \coloneqq \{v \in[0,1] \mid \lambda(Y(v)) = F(\{v\}) > 0\}$ to be the set of values $v$ for which $\s[Q]$ plays a randomized bid. Since every distribution admits at most countably many atoms, the set $V$ must be countable.
	
	For every $v \in V$, we have
	\begin{align*}
		\E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)] = \E_{t \sim \unif(Y(v))}[(v - Q(t))\mathbbm{1}(Q(t) \geq Q(y))] = \E_{t \sim \unif(Y(v))}[(v - Q(t))\mathbbm{1}(t \geq y)]
	\end{align*}
	Now, for any interval $Y(v)$ with $\lambda(Y(v))> 0$, the uniform distribution on $Y(v)$ is the same as the uniform distribution on $[0,1]$ conditioned on the event $Y(v)$. Therefore,
	\begin{align*}
		\E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)] &= \E_{t \sim \unif(0,1)}[(v - Q(t))\mathbbm{1}(t \geq y) \mid t \in Y(v)]\\
		&= \frac{1}{\lambda(Y(v))} \cdot \E_{t \sim \unif(0,1)}[(v - Q(t))\mathbbm{1}(t \geq y,  t \in Y(v))]\\
		&= \frac{1}{F(\{v\})} \cdot \E_{t \sim \unif(0,1)}[(F^-(t) - Q(t))\mathbbm{1}(t \geq y,  F^-(t) = v)]
	\end{align*}
	Taking an expectation over all $v \in V$ yields
	\begin{align*}
		\E_{v \sim F}\left[ \E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)] \mathbbm{1}(v \in V) \right] &= \sum_{v \in V} F(\{v\}) \cdot \E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)]\\
		&= \sum_{v \in V} \E_{t \sim \unif(0,1)}[(F^-(t) - Q(t))\mathbbm{1}(t \geq y,  F^-(t) = v)]\\
		&= \E_{t \sim \unif(0,1)}[(F^-(t) - Q(t))\mathbbm{1}(t \geq y,  F^-(t) \in V)] \tag{I}
	\end{align*}
	
	On the other hand, if we take an expectation over $v \notin V$, we get 
	\begin{align*}
		\E_{v \sim F}\left[ \E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)] \mathbbm{1}(v \notin V) \right] &= \E_{v \sim F}\left[(v - Q(F(v))) \mathbbm{1}(Q(F(v)) \geq Q(y)) \mathbbm{1}(v \notin V) \right]\\
			&= \E_{v \sim F}\left[\underbrace{(v - Q(F(v))) \mathbbm{1}(Q(F(v)) \geq Q(y), v \notin V)}_{g(v)} \right]
	\end{align*}
	Recall that, if $y \sim \unif(0,1)$, then $F^-(y) \sim F$~\citep{embrechts2013note}. Therefore, $\E_{v \sim F}[g(v)] = \E_{t \sim \unif(0,1)}[g(F^-(t))]$. Now, consider $t \in [0,1]$ such that $F^-(t) \notin V$. As $Y(F^-(t))$ is an interval with measure zero and $t \in Y(F^-(t))$, we must have that $Y(F^-(t)) = \{t\}$. We claim that $F(F^-(t)) = t$. For contradiction, suppose not. Then, as $F(F^-(t)) \geq t$ always holds~\citet{embrechts2013note}, we must have $F(F^-(t)) > t$. Applying $F^-$ to both sides yields $F^-(F(F^-(t))) \geq F^-(t)$. However, we always have $F^-(F(x)) \leq x$~\citep{embrechts2013note}, which for $x = F^-(t)$ implies $F^-(F(F^-(t))) \leq F^-(t)$. Hence, we must have $F^-(F(F^-(t))) = F^-(t)$, i.e, $F^-(F(F^-(t))) \in Y(F^-(t))$. Since we assumed $F(F^-(t)) > t$, this implies $\lambda(Y(v)) > 0$, which contradicts $F^-(t) \notin V$. Thus, we must have $F(F^-(t)) = t$, and as a consequence $Q(F(F^-(t)) = Q(t)$. Altogether, we get
	\begin{align*}
		&\E_{v \sim F}\left[ \E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)] \mathbbm{1}(v \notin V) \right]\\ = &\E_{v \sim F}[g(v)]\\
		= &\E_{t \sim \unif(0,1)}[g(F^-(t))]\\
		= &\E_{t \sim \unif(0,1)}\left[(F^-(t) - Q(t)) \mathbbm{1}(Q(t) \geq Q(y), F^-(t) \notin V) \right]\\
		= &\E_{t \sim \unif(0,1)}\left[(F^-(t) - Q(t)) \mathbbm{1}(t \geq y, F^-(t) \notin V) \right] \tag{II}
	\end{align*} 
	Finally, adding together (I) and (II) yields
	\begin{align*}
		& \E_{v \sim F}[ \E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)]]\\
		=\ &\E_{v \sim F}\left[ \E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)] \mathbbm{1}(v \in V) \right] + \E_{v \sim F}\left[ \E_{b \sim \s[Q](v)} [(v - b) \mathbbm{1}(b \geq h)] \mathbbm{1}(v \notin V) \right]\\
		=\ &\E_{t \sim \unif(0,1)}[(F^-(t) - Q(t))\mathbbm{1}(t \geq y,  F^-(t) \in V)] + \E_{t \sim \unif(0,1)}\left[(F^-(t) - Q(t)) \mathbbm{1}(t \geq y, F^-(t) \notin V) \right]\\
		=\ &\E_{t \sim \unif(0,1)}[(F^-(t) - Q(t))\mathbbm{1}(t \geq y)]\\
		=\ &\int_y^1 (F^-(t) - Q(t))dt\,.
	\end{align*}

    Similarly, for $h = Q(y)$, if we replace the random variable $(v - b) \cdot \mathbbm{1}(b \geq h)$ with $\mathbbm{1}(b \geq h)$, we get
    \begin{align*}
        \Prob(b \geq h\mid b \sim P_{\s[Q],F}) = \E_{v \sim F}[ \E_{b \sim \s[Q](v)} [\mathbbm{1}(b \geq h)]]\ =\ \E_{t \sim \unif(0,1)}[\mathbbm{1}(t \geq y)] = \Prob_{t \sim \unif(0,1)}(Q(t) \geq h) \,.
    \end{align*}
    On the other hand, if $h < Q(0)$ (respectively $h > Q(1)$), then $\Prob(b \geq h\mid b \sim P_{\s[Q],F}) = 1$ (respectively $\Prob(b \geq h\mid b \sim P_{\s[Q],F}) = 0$). Therefore, for all $h \in [0,1]$, we have
    \begin{align*}
        \Prob(b \geq h\mid b \sim P_{\s[Q],F}) = \Prob_{t \sim \unif(0,1)}(Q(t) \geq h)\,,
    \end{align*}
    Hence, the induced bid distribution $P_{s,f}$ is equal to $\{Q(t)\mid t \sim \unif(0,1)\}$.
\end{proof}


\begin{proof}[\textbf{Proof of \Cref{lemma:ode-existence}}]
	We start by rewriting the ODE \eqref{eq:first-ode} in a more standard form 
	\begin{align}\label{eq:first-ode-rewrite}
		x'(t) = g(t,x(t)) \quad \text{where}\quad g(t,x) \coloneqq \frac{F^-(t) - x}{1 - F(x)}\,,
	\end{align}
	where the denominator is only well-defined for $x < F^-(1)$. For the remainder of the proof, set $\bar v = F^-(1)$. Then, $F(x) < 1$ for all $x < \bar v$. Moreover, we assume $F(x) = 0$ for $x < 0$.
	
	To prove the existence of $Q^*$, we will use a generalization of Caratheodary's existence theorem proven in \citet{biles1997caratheodory} (see \citealt{biles2000solvability} for the more general version which applies to initial value problems). We refer to it as the Generalized Caratheodary's Existence Theorem, or simply GCET.
	\begin{theorem*}[GCET]
		Consider the initial value problem (IVP) defined by $x'(t) = f(t,x(t))$ for all $t\in [0,1]$ and $x(0) = 0$. Suppose $f:[0,1] \times \R \to \R$ satisfies the following conditions:
		\begin{itemize}
			\item[(a)] For almost all $t$, $f(t,\cdot)$ is quasi-semicontinuous, i.e., for all $x \in \R$, we have
						\begin{align*}
							\limsup_{\tilde x \uparrow x} f(t,\tilde x) \leq f(t,x) \leq \liminf_{\tilde x \downarrow x} f(t, \tilde x)\,.
						\end{align*}
			\item[(b)] For each $x \in \R$, $f(\cdot, x)$ is measurable.
			\item[(c)] There exists an integrable function $\beta:[0,1] \to \R$ such that $|f(t,x)| \leq \beta(t)$ for all $t,x$.
		\end{itemize}
		Then, there exists an absolutely continuous function $x:[0,1] \to \R$ such that $x(0) = 0$ and $x'(t) = f(t,x(t))$ almost surely on $[0,1]$. We call such a function a \emph{solution} of the initial value problem (IVP).
	\end{theorem*}
	
    We cannot directly apply GCET to $g$ because it cannot be bounded with an integrable function; in fact $g$ is not well-defined for all $x \in \R$. This motivates us to consider a modified IVP parameterized by $\alpha > 0$: $x'_\alpha(t) = g_\alpha(t, x_\alpha(t))$ for all $t \in [0,1]$ and $x_\alpha(0)= 0$, where
	\begin{align}\label{eq:IVP-alpha}
		g_\alpha(t,x) \coloneqq \frac{F^-(t) - I(x)}{1 - F(\min\{x, \alpha\})} \quad \text{with} \quad I(x) = \max\{0, \min\{x,1\}\} \,.
	\end{align}
	
	Note that, for every $\alpha \in (0,\bar v)$, the conditions of GCET are satisfied by $g_\alpha$:
	\begin{itemize}
		\item[(a)] For every $t \in [0,1]$, we have $ \limsup_{\tilde x \uparrow x} g_\alpha(t,\tilde x) \leq g_\alpha(t,x)$ as $F$ is non-decreasing and $ \liminf_{\tilde x \downarrow x} g_\alpha(t,\tilde x) = g_\alpha(t,x)$ due to the right-continuity of $F$.
		\item[(b)] For each $x \in \R$, $g_\alpha(\cdot,x)$ is measurable because $F^-$ is measurable.
		\item[(c)] We have $g_\alpha(t,x) \leq 1/(1 - F(\alpha))$ for all $t,x$.
	\end{itemize}
	
	Therefore, for every $\alpha > 0$, there exists a solution $x_\alpha$ for IVP \eqref{eq:IVP-alpha}. To complete the proof, we will show the existence of a positive constant $\alpha > 0$ such that $0 \leq x_{\alpha}(t) \leq \alpha$ for all $t \in [0,1]$, thereby making it a solution to the original IVP defined by $g$. Looking forward, we first specify the value of $\alpha$ which will make the proof work, and then focus on establishing that $0 \leq x_{\alpha}(t) \leq \alpha$ for all $t \in [0,1]$ in the remainder of the proof. 
	
Consider the auxiliary function $h:(0,\bar v] \to [0,1]$ defined as follows. For $x \in (0,\bar v]$, we let $h(x)$ be the unique $z \in [0,x]$ which satisfies 
	\begin{align*}
		\int_{0}^{z} y \cdot (1 - F(y))dy\ = \int_{z}^{x}  (1 - F(y))dy \,.
	\end{align*}
	Observe that $\int_{0}^{z} y \cdot (1 - F(y))dy$ is a continuous strictly increasing function of $z$ and $\int_{z}^{x}  (1 - F(y))dy$ a continuous strictly decreasing $z$; this is because $1 - F(y) > 0$ for all $y <\bar v$. Thus, the Intermediate Value Theorem ensures that $h$ is well-defined. 
    
    Moreover, we have that $h(x) < x$ for all $x \in (0,\bar v]$ because $\int_{x}^{x}  (1 - F(y))dy = 0$ but $\int_{0}^{x} y \cdot (1 - F(y))dy > 0$, and we have that $h(x) > 0$ for all $x \in (0,\bar v]$ because $\int_{0}^{0} y \cdot (1 - F(y))dy = 0$ but $\int_{0}^{x}  (1 - F(y))dy > 0$.
    
    We define our candidate $\alpha$ as, $\alpha \coloneqq (h(\bar v) + \bar v)/2$ and note that, $0 < h(\bar v) < \alpha < \bar v$. By definition of $\bar v$ we have that $F(\alpha) < 1$.
	
	In order to bound $x_\alpha(t)$ from above, we will compare it with solutions of the parameterized family of IVP's defined for every $n \geq 1$, by $  \bar x'_n(t) = \bar g_n(t,x(t))$ with $\bar x_n(0) =0$, where
	\begin{align}\label{eq:IVP-n}
		\bar g_n(t,x)\ \coloneqq\ \frac{\{F^-(t) + 1/n\} \cdot  (1 - x)}{1 - F(x)} \,.
	\end{align}
	Note that $\bar g_n(t,x) \geq g_\alpha(t,x)$, and therefore, intuitively, we should have $\bar x_n(t) \geq x_\alpha(t)$; we formally show this fact now.
	
	First, we explicitly construct a solution for the IVP corresponding to $\bar g_n(t,x)$. Consider $\gamma: [0,\alpha] \to \R_+$ defined for every $x \in [0,\alpha]$ as 
	\begin{align*}
		\gamma(x)\ \coloneqq\ \int_{0}^x \frac{1 - F(z)}{1 - z} dz\,.
	\end{align*}  
	%$\gamma(\cdot)$ is well-defined because $h(\bar v) < \bar v \leq 1$ . 
    Note that $\gamma$ is a strictly increasing function because $1 - F(z) > 0$ for all $z < \bar v$. Therefore, $\gamma$ is invertible on its range which contains $[0, \bar \gamma]$, where  $\bar \gamma\ \coloneqq\ \E_F[v]\ +\ \frac{1 - F(\alpha)}{1 - h(\bar v)} \cdot \frac{\bar v - h(\bar v)}{2}\,.$
	To see this, observe that
	\begin{align*}
		\gamma(\alpha) &= \int_{0}^{h(\bar v)} \frac{1 - F(z)}{1 - z} dz\ +\ \int_{h(\bar v)}^\alpha \frac{1 - F(z)}{1 - z} dz\\
		&\geq \int_{0}^{h(\bar v)} (1 - F(z))(1 + z) dz\ +\ \frac{1 - F(\alpha)}{1 - h(\bar v)} \cdot (\alpha - h(\bar v))\\
		&= \int_{0}^{h(\bar v)} (1 - F(z)) dz\ +\ \int_{0}^{h(\bar v)} z \cdot (1 - F(z)) dz\ +\ \frac{1 - F(\alpha)}{1 - h(\bar v)} \cdot (\alpha - h(\bar v))\\
		&= \int_{0}^{h(\bar v)} (1 - F(z)) dz\ +\ \int_{h(\bar v)}^{1} (1 - F(z)) dz\ +\ \frac{1 - F(\alpha)}{1 - h(\bar v)} \cdot (\alpha - h(\bar v))\\
		%&= \int_{0}^{\bar v} (1 - F(z)) dz\ +\ \frac{1 - F(\alpha)}{1 - h(\bar v)} \cdot (\alpha - h(\bar v))\\
		&= \E_F[v]\ +\ \frac{1 - F(\alpha)}{1 - h(\bar v)} \cdot (\alpha - h(\bar v))\,.
	\end{align*}
	
	
	Let $n$ be such that $\E_F[v] + 1/n \leq \bar \gamma$ and define $\bar x_n: [0,1] \to [0,\alpha]$ as follows
	\begin{align*}
		\bar x_n(t)\ \coloneqq\ \gamma^{-1}\left( \int_0^t \{F^-(z) + 1/n\} dz \right)\,.
	\end{align*}
	$\bar x_n$ is well-defined because $\int_0^t \{F^-(z) + 1/n\} dz \leq \int_0^1 F^-(z) dz + 1/n = \E_F[v] + 1/n$. Since $\bar x_n$ is a composition of two strictly increasing functions, it is itself strictly increasing. Moreover, we also have $\bar x_n(0) =0$.
	
	Let $\Gamma_n$ be the set of points $t \in (0,1)$ such that $F^-$ is continuous at $t$ and $F$ is continuous at $\bar x_n(t)$. Since both $F^-$ and $F$ are discontinuous at atmost countably many points, and $\bar x_n$ is a strictly increasing function, we get that $\Gamma_n$ has measure 1, i.e., $\lambda(\Gamma_n) = 1$. Fix a point $t \in \Gamma_n$. Then, as $F$ is continuous at $\bar x_n(t)$, the Fundamental Theorem of Calculus implies that $\gamma$ is differentiable at $\bar x_n(t)$ with $\gamma'(\bar x_n(t)) = (1- F(\bar x_n(t)))/(1 - \bar x_n(t)) > 0$. Consequently, we get that $\gamma^{-1}$ is differentiable at $\bar x_n(t)$ and
	\begin{align*}
		(\gamma^{-1})'(\gamma(\bar x_n(t)))\ =\ \frac{1 - \bar x_n(t)}{1 - F(x_n(t))}\,.
	\end{align*}
	Finally, using the continuity of $F^-$ at $t$, the Fundamental Theorem of Calculus, and the Chain Rule for derivatives, we get
	\begin{align*}
		x'_n(t)\ =\ \frac{1 - \bar x_n(t)}{1 - F(x_n(t))} \cdot \{F^-(t) + 1/n\} &&\forall\ t\in \Gamma_n\,.
	\end{align*}
	Therefore, we have established that $\bar x_n$ is a solution of the IVP described in \eqref{eq:IVP-n}. 
	
	We are now ready to prove $\bar x_n(t) \geq x_\alpha(t)$ for all $t \in [0,1]$. For contradiction, suppose not and let $t^* = \inf\{t \in [0,1] \mid x_\alpha(t) > \bar x_n(t)\} \in [0,1)$. We note that by continuity of the functions $x_\alpha$ and $\bar x_n$ and because $x_\alpha(0) = \bar x_n(0) =0$ we have that $x_\alpha(t^*) = \bar x_n(t^*) = x^*$. 
    
    Consider a sequence $t_k \downarrow t^*$ such that, for all $k \geq 1$, we have
	\begin{align*}
		\frac{x_\alpha(t_k) - x_\alpha(t^*)}{t_k - t^*}\ >\ \frac{\bar x_n(t_k) - \bar x_n(t^*)}{t_k - t^*}\, \tag{\#}.
	\end{align*}
	As $x_\alpha$ is a solution of IVP \eqref{eq:IVP-alpha}, we get
	\begin{align*}
		\frac{x_\alpha(t_k) - x_\alpha(t^*)}{t_k - t^*} &= \frac{1}{t_k - t^*} \cdot \int_{t^*}^{t_k} g_\alpha(z, x_\alpha(z)) dz\\ 
		&= \frac{1}{t_k - t^*} \cdot \int_{t^*}^{t_k} \frac{F^-(z) - I(x_\alpha(z))}{1 - F(\max\{x_\alpha(z), \alpha\})} dz\\
		&\leq \frac{1}{t_k - t^*} \cdot \int_{t^*}^{t_k} \frac{F^-(t_k) - I(x_\alpha(t^*))}{1 - F(\max\{x_\alpha(t_k), \alpha\})} dz\\
		&= \frac{F^-(t_k) - x^*}{1 - F(\max\{x_\alpha(t_k), \alpha\})}\,.
	\end{align*}
	Similarly, as $\bar x_n$ is a solution of IVP \eqref{eq:IVP-n}, we get
	\begin{align*}
		\frac{\bar x_n(t_k) - \bar x_n(t^*)}{t_k - t^*} &= \frac{1}{t_k - t^*} \cdot \int_{t^*}^{t_k} \bar g_n(z, \bar x_n(z)) dz\\
		&= \frac{1}{t_k - t^*} \cdot \int_{t^*}^{t_k} \frac{\{F^-(t) + 1/n\} \cdot  (1 - \bar x_n(z))}{1 - F(\bar x_n(z))} dz\\
		&\geq \frac{1}{t_k - t^*} \cdot \int_{t^*}^{t_k} \frac{\{F^-(t^*)_+ + 1/n\} \cdot  (1 - \bar x_n(t_k))}{1 - F(\bar x_n(t^*))} dz\\
		&= \frac{\{F^-(t^*)_+ + 1/n\} \cdot  (1 - \bar x_n(t_k))}{1 - F(x^*)}\,,
	\end{align*}
	where $F^-(t^*)_+$ is the right limit of $F^-$ at $t^*$, i.e., $F^-(t^*)_+ = \lim_{s \downarrow t^*} F^-(s)$. Combining this with $(\#)$ yields
	\begin{align*}
		\frac{F^-(t_k) - x^*}{1 - F(\max\{x_\alpha(t_k), \alpha\})} \geq \frac{\{F^-(t^*)_+ + 1/n\} \cdot  (1 - \bar x_n(t_k))}{1 - F(x^*)} &&\forall\ k \geq 1\,.
	\end{align*}
	Note that $x_\alpha$ and $\bar x_n$ are both continuous and non-decreasing, and $F$ is right continuous. Therefore, we have that $\lim_{t_k \downarrow t^*} F(x_\alpha(t_k)) = F(x^*)$ and $\lim_{t_k \downarrow t^*} \bar x_n(t_k) = x^*$. Hence, taking the limit as $t_k \downarrow t^*$ yields
	\begin{align*}
		\frac{F^-(t^*)_+ - x^*}{1 - F(\max\{x^*, \alpha\})} \geq \frac{\{F^-(t^*)_+ + 1/n\} \cdot  (1 -  x^*)}{1 - F(x^*)}\,.
	\end{align*}
	This gives the desired contradiction because $1 - F(\max\{x^*, \alpha\}) \geq 1 - F(x^*)$ and
	\begin{align*}
		&F^-(t^*)_+ - x^* \leq F^-(t^*)_+ \cdot (1 - x^*) <  \{F^-(t^*)_+ + 1/n\} \cdot  (1 -  x^*)\,.
	\end{align*}
    where we have used the fact that $x^* = \bar x_n(t) \leq \alpha < 1$. Hence, we must have $x_\alpha(t) \leq \bar x_n(t)$ for all $t \in [0,1]$. Finally, sending $n \to \infty$ and using the continuity of $\gamma^{-1}$ yields for every $t \in [0,1]$,
	\begin{align*}
		x_\alpha(t)\ \leq\ \lim_{n \to \infty}\ \bar x_n(t)\ =\ \bar x(t) \coloneqq \gamma^{-1}\left( \int_0^t F^-(z) dz \right)\, \tag{$\spadesuit$}
	\end{align*}
	

    We are now ready to finish the proof of the lemma. In particular, note that for all $t \in [0,1]$, we can use the monotonicity of $\gamma$ in combination with $(\spadesuit)$ to get
	\begin{align*}
		\gamma(\max\{x_\alpha(t), 0\})\ &\leq \int_0^t F^-(z) dz\\ 
		&\leq \int_0^{F^-(t)} (1 - F(z))dz\\ 
		&= \int_0^{h(F^-(t))} (1 - F(z))dz + \int_{h(F^-(t))}^{F^-(t)} (1 - F(z))dz\\
		&= \int_0^{h(F^-(t))} (1 - F(z))dz + \int_0^{h(F^-(t))} (1 - F(z))\cdot z dz\\
		&= \int_0^{h(F^-(t))} (1 - F(z))(1 + z)dz\\
		&\leq \int_0^{h(F^-(t))} \frac{1 - F(z)}{1 - z}dz\\
		&= \gamma(h(F^-(t)))\,.
	\end{align*}
	As $h(x) < x$ for all $x \in (0,\bar v]$ and $\gamma$ is strictly increasing, we get $x_\alpha(t) \leq h(F^-(t)) < F^-(t)$ for all $t \in (0,1]$. Therefore, $g_\alpha(t, x_\alpha(t)) \geq 0$ for all $t \in [0,1]$, and consequently $x_\alpha(t) \geq 0$ for all $t \in [0,1]$. Hence, there exists a set $A\subset [0,1]$ with measure $\lambda(A) = 1$ such that, for all $t \in [0,1]$, we have
	\begin{align*}
		x_\alpha'(t)\ =\ \frac{F^-(t) - I(x_\alpha(t))}{1 - F(\min\{x_\alpha(t), \alpha\})} =\ \frac{F^-(t) - x_\alpha(t)}{1 - F(x_\alpha(t))}\,,
	\end{align*}
	where we have used the fact that $x_\alpha(t) \leq h(\bar v) \leq \alpha$ for all $t \in [0,1]$. In other words, $Q^* = x_\alpha$ satisfies part 1 of the lemma.
	
	For parts $2$ and $3$, note that $x_\alpha$ being a solution of IVP \eqref{eq:IVP-alpha} implies
	\begin{align*}
		x_\alpha(t)\ =\ \int_0^t g_\alpha(z, x_\alpha(z)) dz\ =\ \int_0^t \frac{F^-(z) - x_\alpha(z)}{1 - F(x_\alpha(z))} dz\,.
	\end{align*}
	As $F^-(z) > 0$ and $x_\alpha(z) < F^-(z)$ for all $z > 0$, we get that $x_\alpha(t)$ is strictly increasing as a function of $t$, and $x_\alpha(t) > 0$ for all $t >0$. Since we have already established $x_\alpha(t) < F^-(t)$ for all $t \in (0,1]$, we get that $Q^* = x_\alpha$ also satisfies parts 2 and 3 of the lemma.
\end{proof}



\begin{proof}[\textbf{Proof of \Cref{lemma:saddle-max-prob}}]

We would like to show that the function
\begin{equation*}
		y\ \mapsto\ \int_{Q^*(y)}^1 (1 - F(t)) dt\ -\ \int_y^1 (F^-(t) - Q^*(t)) dt,
\end{equation*}
is constant on $ [0,1]$. Part~1 of \Cref{lemma:ode-existence} established that this mapping has a vanishing derivative at any point where it is differentiable. To conclude that it is constant, we will show that it is absolutely continuous using the following lemma
\begin{lemma}\label{lemma:regret-abs-cont}
	If $Q:[0,1] \to [0,1]$ is absolutely continuous, then the mapping
	\begin{align*}
		y\ \mapsto\ \int_{Q(y)}^1 (1 - F(t)) dt\ -\ \int_y^1 (F^-(t) - Q(t)) dt
	\end{align*}
	 is also absolutely continuous on $[0,1]$.
\end{lemma}
\begin{proof}
	First, note that the second term is absolutely continuous on $[0,1]$ because it is the integral of a bounded integrable function $t \mapsto F^-(t) - Q(t)$. Next, observe that the function $g(x) = \int_x^1 (1 - F(t))dt$ is Lipschitz continuous with Lipschitz constant 1 because for $x < z$
	\begin{align*}
		|f(x) - f(z)| \leq \int_x^z (1 - F(t)) dt \leq z - x\,. 
	\end{align*}
	Since the composition of an absolutely continuous with a globally Lipschitz-continuous function is absolutely continuous, we get that
	\begin{align*}
		y \mapsto\ g\left( Q(y) \right) = \int_{Q(y)}^1 (1 - F(t)) dt
	\end{align*}
	is absolutely continuous on $[0,1]$. Finally, the difference of two absolutely continuous functions is also absolutely continuous, thereby establishing the lemma.
\end{proof}
Lemma~\ref{lemma:regret-abs-cont} in combination with Lemma~\ref{lemma:ode-existence} allows us to show that all $y \in [0,1]$ are optimal for the inner-maximization problem in the saddle-point problem \eqref{eq:simpler-saddle}, i.e. that the regret incurred by the quantile-based bidding strategy $Q^*$ is constant on $[0,1]$.

    Define $g: [0, 1] \to \R_+$ as
	\begin{align*}
		g(y)\ \coloneqq\ \int_{Q^*(y)}^1 (1 - F(t)) dt\ -\ \int_y^1 (F^-(t) - Q^*(t)) dt\,.
	\end{align*}
	Then, since $Q^*$ is absolutely continuous, Lemma~\ref{lemma:regret-abs-cont} implies that $g$ is also absolutely continuous. Therefore, $g$ is differentiable almost surely and we can alternatively write $g$ as
	\begin{align*}
		g(y)\ =\ g(0) + \int_0^y g'(t)dt.
	\end{align*}
	In order to show that $g$ is constant, we show that $g'(y) = 0$ almost surely. Let $\mathcal{Y}$ be the set of $y \in [0,1]$ such that the derivate ${Q^*}'(y)$ exists, $F$ is continuous at $Q^*(y)$, and $F^-$ is continuous at $y$. Note that $Y$ has measure $\lambda(Y) = 1$ because $Q^*$ is differentiable almost surely, and both $F$ and $F^{-}$ have only countably many discontinuities (as they are non-decreasing). For every $y \in \mathcal{Y}$, we obtain by the Chain Rule that
	\begin{align*}
		g'(y)\ &= -(1 - F(Q^*(y))\cdot {Q^*}'(y)\ + (F^-(y) - Q^*(y))\\
		&= -(1 - F(Q^*(y))\cdot \frac{F^-(y) - Q^*(y)}{1 - F(Q^*(y))}\ + (F^-(y) - Q^*(y))\\
		&= 0\,,
	\end{align*}
	where we use part 1 of Lemma~\ref{lemma:ode-existence} in the second equality. As $\mathcal{Y}$ has measure $1$, we have shown that $g'(y) = 0$ almost surely. Therefore,
	\begin{align*}
		g(y)\ =\ g(0) + \int_0^y g'(t)dt\ =\ g(0)\ =\ \int_0^1 (1 - F(t)) dt\ -\ \int_0^1 (F^-(t) - Q^*(t)) dt = \int_0^1 Q^*(t) dt\,,
	\end{align*} 
	where the last equality follows from $\int_0^1 (1 - F(t))dt = \E_F[v] = \int_0^1 F^-(t) dt$.
\end{proof}

\begin{proof}[\textbf{Proof of \Cref{lemma:second-ode}}]
    We established in part 3 of \Cref{lemma:ode-existence}  that $Q^*(1) < F^-(1)$ which implies that $F(Q^*(1)) < 1$. Note that $G:[0,1] \to [0,1]$ is defined to be
	\begin{align*}
		G(y)\ \coloneqq\ H( Q^*(y))\ =\ \exp\left(- \int_{y}^1 \frac{1}{1 - F(Q^*(t))} dt \right)\,.
	\end{align*}
	First, note that:
	\begin{itemize}
		\item $G$ is the composition of the exponential function, which is globally Lipschitz on $[-(1 - F(Q^*(1))^{-1}, 0]$;
		\item the map $y \mapsto \int_{y}^1 \frac{1}{1 - F(Q^*(t))} dt$ which is also Lipschitz because
			\begin{align*}
				\left| \int_{y}^1 \frac{1}{1 - F(Q^*(t))} dt - \int_{x}^1 \frac{1}{1 - F(Q^*(t))} dt \right| \leq \frac{1}{1 - F(Q^*(1))} \cdot |x - y|\,.
			\end{align*}
	\end{itemize}
	 Therefore, $G$ is Lipschitz continuous on $[0,1]$. In particular, it is differentiable almost surely. 
	
	Let $\Gamma$ be the set of $y \in (0,1)$ for which $y \mapsto F(Q^*(y))$ is continuous and $Q^*$ is differentiable. $\Gamma$ has measure $\lambda(\Gamma) = 1$ because $F$ is discontinuous on at most countably many points, and $Q^*$ is strictly increasing and differentiable almost surely. For every $y \in \Gamma$, the Chain Rule of derivatives yields
	\begin{align*}
		G'(y)\ =\ G(y) \cdot \frac{1}{1 - F(Q^*(y))}\ =\ G(y) \cdot \frac{(Q^*)'(y)}{F^-(y) - Q^*(y)}\,,
	\end{align*}
	where the last equality follows from part~1 of \Cref{lemma:ode-existence}. Importantly, $F(y) - Q^*(y) > 0$ for all $y > 0$ by part~3 of \Cref{lemma:ode-existence}. 
\end{proof}


\begin{proof}[\textbf{Proof of \Cref{lemma:bid-strat-optimality}}]
	Fix a value $v \in [0,1]$ and let $Y(v) =\{z \in [0,1] \mid F^-(z) = v\}$. If $Y(v)$ is empty the result is straightforward. We next assume that $Y(v)$ is not empty.
	
    We first show that,
    \begin{equation}
    \label{eq:support_reduction}
        \max_{b \in [0,1]}\ u(b \mid v, H^*)\ =\ \max_{b \in [0,Q^*(1)]}\ u(b \mid v, H^*)\,.
    \end{equation}

    Let $b > Q^*(1)$. If $b \geq v$, we note that $u(b \mid v, H^*) \leq 0 = u(0 \mid v, H^*).$ If $b \in (Q^*(1),v)$, then
	\begin{align*}
		u(b \mid v, H)\ =\ (v - b) \cdot H^*(b) \leq v - b < v - Q^*(1) \stackrel{(a)}{=} (v - Q^*(1))\cdot H^*(Q^*(1))\ =\ u(Q^*(1)\mid v,H^*)\,,
	\end{align*}
    where $(a)$ holds because $H^*(Q^*(1)) = 1$ by definition of $H^*$. Therefore $\eqref{eq:support_reduction}$ holds.
    
	As $Q^*:[0,1] \to [0, Q^*(1)]$ is a strictly increasing invertible function, we further get
	\begin{align*}
		\max_{b \in [0,1]}\ u(b \mid v, H^*)\ =\ \max_{y \in [0,1]}\ u(Q^*(y) \mid v, H^*)\,.
	\end{align*}
	Hence, to prove the lemma, it suffices to show that
	\begin{align}\label{eq:lemma-bid-strat-inter}
		Y(v)\ \subseteq\ \argmax_{y \in [0,1]}\ u(Q^*(y) \mid v, H^*)\,.
	\end{align}
	As $v$ and $H^*$ have been fixed, we set $u(y) \coloneqq u(Q^*(y) \mid v, H^*)$ to simplify notation. Observe that
	\begin{align*}
		u(y)\ =\ (v - Q^*(y)) \cdot H^*(Q^*(y))\ =\ (v - Q^*(y)) \cdot G(y)\,.
	\end{align*}
	Using the fact that the product of two absolutely continuous functions (on a bounded interval) is also absolutely continuous, we get that $y \mapsto u(y \mid v, H^*)$ is absolutely continuous. Consider a point $y\in [0,1]$ such that both $Q^*$ and $G$ are differentiable at $y$. The set of such points has measure 1 because both $Q^*$ and $G$ are absolutely continuous and almost surely differentiable. Then, the Chain Rule of derivatives applies and we get that almost surely 
	\begin{align*}
		u'(y)\ &=\ - (Q^*)'(y) \cdot G(y)\ +\ (v - Q^*(y)) \cdot G'(y)\\
		&= (v - F^-(y)) \cdot G'(y) \ +\ (F^-(y) - Q^*(y)) \cdot G'(y)\ -\ (Q^*)'(y) \cdot G(y) \,.\\
        &= (v - F^-(y)) \cdot \frac{G(y)}{1 - F(Q^*(y))},
	\end{align*} 
    where the last equality holds almost surely by replacing $G'$ with the expression derived in \Cref{lemma:second-ode}.

    Furthermore, as $u$ is absolutely continuous on $[0,1]$, we can write
	\begin{align*}
		u(y)\ =\ u(0)\ +\ \int_0^y u'(t) \cdot dt\,.
	\end{align*}
	
    As $F^-$ is a non-decreasing function, $Y(v)$ is an interval included in $[0,1]$. Let $y_1 \coloneqq \inf\ Y(v)$ and $y_2 \coloneqq \sup Y(v)$ and fix $y^* \in Y(v)$. To complete the proof, we establish the sufficient condition in \eqref{eq:lemma-bid-strat-inter} by showing that $y^* \in \argmax_{y \in [0,1]}\ u(y)$. 
    
    Note that $F^-(y) < v$ for $y < y_1$, $F^-(y) = v$ for $y \in (y_1, y_2)$, and $F^-(y) > v$ for $y > y_2$ Therefore, $u'(t) > 0$ for $t < y_1$, $u'(t) = 0$ for $t \in (y_1, y_2)$, and $u'(t) < 0$ for $y > y_2$. As a consequence,
	\begin{align*}
		u(y^*)\ -\ u(y)\ =\ \int_{y}^{y^*} u'(t) dt\ \geq 0 &&\forall\ y \leq y^*\,,
	\end{align*}
	and
	\begin{align*}
		u(y)\ -\ u(y^*)\ =\ \int_{y^*}^{y} u'(t) dt\ \leq 0 &&\forall\ y \geq y^*\,.
	\end{align*}
	Thus, we have $y^* \in \argmax_{y \in [0,1]}\ u(y)$ as desired.
\end{proof}



\subsection{Proof of \Cref{thm:main-result}}

\begin{proof}[\textbf{Proof of \Cref{thm:main-result}}]
	\Cref{lemma:ode-existence} establishes the existence of a quantile-based bidding strategy $Q^* \in \mathcal{Q}$ with the required properties. Here, we to show that $(Q^*, H^*)$ is a saddle point of $\rr[F]{\cdot, \cdot }$.
	
	For the first part, consider $H^*$ as defined in \Cref{lemma:second-ode} and an arbitrary bidding strategy $s \in \Scal$. Then, \Cref{lemma:bid-strat-optimality} implies that, for every value $v \in [0,1]$, we have
	\begin{align*}
		Y(v)\ \coloneqq\ \{Q^*(y) \mid y \in[0,1],F^-(y) = v\}\ \subseteq\ \argmax_{b \in [0,1]}\ \E_{h \sim H^*}[(v - b) \cdot \mathbbm{1}(b \geq h)]\,.
	\end{align*}
	Therefore, for every value $v \in [0,1]$, we must have
	\begin{align}\label{eq:main-result-inter-1}
		\E_{h \sim H^*}[(v - Q(y)) \cdot \mathbbm{1}(Q(y) \geq h)]\ \geq\ \E_{b \sim s(v)}\left[ \E_{h \sim H^*}[(v - b) \cdot \mathbbm{1}(b \geq h)] \right] &&\forall\ y \in Y(v)\,.
	\end{align}
	Now, for every $v \in [0,1]$ such that $Y(v) \neq \emptyset$, the definition of $\s[Q^*](v)$ (\Cref{def:quantile-based-bidding-strategy}) implies that, when $b \sim \s[Q^*](v)$, there \emph{always} exists some $y \in Y(v)$ such that $b = Q(y)$. Moreover, as $F^-(t) \sim F$ when $t \sim \unif(0,1)$~\citep{embrechts2013note}, we get
	\begin{align*}
		\Prob_{v \sim F}(Y(v) = \emptyset)\ =\ \Prob_{t \sim \unif(0,1)}(Y(F^-(t)) = \emptyset)\ =\ 0\,.
	\end{align*}
	Hence, taking an expectation over $v\sim F$ in \eqref{eq:main-result-inter-1} yields
	\begin{align*}
		\U[F]{\s[Q^*], H^*} = \mathbb{E}_{(v, h) \sim F \times H^*}  \left[ \mathbb{E}_{b \sim \s[Q^*](v)} \left[ u(b,h; v) \right] \right]\ \geq\ \mathbb{E}_{(v, h) \sim F \times H^*}  \left[ \mathbb{E}_{b \sim s(v)} \left[ u(b,h; v) \right] \right] = \U[F]{s, H^*}\,.
	\end{align*}
	As a direct consequence, we get the first part of the saddle point result:
	\begin{align*}
		\rr[F]{\s[Q^*], H^*}\ =\ \mathcal{O}_{F}(H^*) - \U[F]{\s[Q^*], H^*} \leq \mathcal{O}_{F}(H^*) - \U[F]{\s, H^*} = \rr[F]{s,H^*} \quad \forall\ s\in \Scal\,.
	\end{align*}
	
	For the second part, consider the bidding strategy corresponding to $Q^*$ as described in \Cref{def:quantile-based-bidding-strategy}. The definition of $\rr[F]{s,H}$ implies that $\rr[F]{s,h} = \E_{h \sim H}[\rr[F]{s,h}]$. Since the maximum value of a random variable is larger than its expectation, it suffices to show that
	\begin{align*}
		\rr[F]{\s[Q^*], H^*} \geq \rr[F]{\s[Q^*],h} \quad \forall\ h \in [0,1]\,.
	\end{align*}
	Furthermore, as $\s[Q^*]$ never bids above $Q^*(1)$, we get for all $h > Q^*(1)$ that,
	\begin{align*}
		\rr[F]{\s[Q^*], h} &= \mathcal{O}_{F}(h) - \U[F]{\s[Q^*], h}\\
        &\stackrel{(a)}{=} \mathcal{O}_{F}(h)  \stackrel{(b)}{\leq} \mathcal{O}_{F}(Q^*(1)) \stackrel{(c)}{=} \mathcal{O}_{F}(Q^*(1)) - \U[F]{\s[Q^*], Q^*(1)} = \rr[F]{\s[Q^*], Q^*(1)}\,
	\end{align*}
    where $(a)$ and $(c)$ holds because for every $h' \geq Q^*(1)$, the characterization of the induced bid distribution of $\s[Q^*]$ derived in \Cref{lemma:quantile-based-bidding} implies that $\Prob_{v \sim F, b \sim \s[Q^*]}(b < Q^*(1)) = 1$ which implies that  $\U[F]{\s[Q^*], h'} = 0 $ and $(b)$ holds because $\mathcal{O}_{F}(\cdot)$ is non-increasing. 
    Hence, it suffices to show
	\begin{align*}
		\rr[F]{\s[Q^*], H^*} \geq \rr[F]{\s[Q^*],Q^*(y)} \quad \forall\ y \in [0,1]\,.
	\end{align*}
	
	Now, we obtain by Riemann-Stieltjes integration by part that,
	\begin{align*}
		\mathcal O_{F}(h)\ =\ \E_{v \sim F}[(v - h)\mathbbm{1}(v \geq h)] = \ \int_h^1 (t - h) \cdot dF(t) =\ (1 - h) -  \int_h^1 F(t) dt =\ \int_h^1 (1 - F(t)) dt\,.
	\end{align*}
	By combining this equality with \Cref{lemma:quantile-based-bidding}, we rewrite the regret for all $y \in [0,1]$ as,
	\begin{align*}
		 \rr[F]{\s[Q^*],Q^*(y)}\ =\ \mathcal{O}_{F}(Q^*(y))\ -\ \U[F]{\s[Q^*], Q^*(y)} =\  \int_{Q^*(y)}^1 (1 - F(t))dt -\ \int_y^1 (F^-(t) - Q(t))dt\,.
	\end{align*}
	Finally, \Cref{lemma:saddle-max-prob} implies that all $y \in [0,1]$ satisfy
	\begin{align*}
		\int_{Q^*(y)}^1 (1 - F(t)) dt\ -\ \int_y^1 (F^-(t) - Q^*(t)) dt\ =\ \int_0^1 Q^*(t) dt\,.
	\end{align*}
	As $H^*$ is supported on $[0, Q^*(1)] = \{Q(y) \mid y \in [0,1]\}$, we get
	\begin{align*}
		\rr[F]{\s[Q^*], H^*} = \int_0^1 Q^*(t) dt = \rr[F]{\s[Q^*],Q^*(y)} \quad \forall\ y \in [0,1]\,,
	\end{align*}
	thereby establishing the second part of the saddle-point result.
\end{proof}

\subsection{Proof of \Cref{cor:partial-info-saddle}}

\begin{proof}[\textbf{Proof of \Cref{cor:partial-info-saddle}}]
	Observe that $\reg_F(s, \delta_h) = \rr[F]{s,h}$ for all $h \in [0,1]$, i.e., the partial-information and full-information are identical when the highest competing bid $h$ is deterministic. Therefore, for all $s \in \Scal$, we have
	\begin{align*}
		\reg_F(s, \mathcal H^*) = \E_{h \sim H^*}[\reg_F(s, \delta_h)] = \E_{h \sim H^*}[\rr[F]{s, h}] = \rr[F]{s, H^*}\,.
	\end{align*}
	Hence, \Cref{thm:main-result} immediately implies
	\begin{align}\label{eq:cor-partial-info-inter-1}
		\reg_F(\s[Q^*], \mathcal H^*) = \rr[F]{\s[Q^*], H^*} \leq \inf_{s \in \Scal}\ \rr[F]{s, H^*} = \inf_{s \in \Scal} \reg_F(s, \mathcal H^*) \leq  \inf_{s \in \Scal} \sup_{H \in \Delta([0,1])} \reg_F(s, H)\,.
	\end{align}
	
	Next, note that the bid distribution $P_{\s[Q^*], F}$ induced by $\s[Q^*]$ is absolutely continuous. Indeed, \Cref{lemma:quantile-based-bidding} implies that $P_{\s[Q^*], F} = \{Q^*(t) \mid t \sim \unif(0,1)\}$, and the latter is absolutely continuous because $Q^*$ is strictly increasing and absolutely continuous. Therefore, \Cref{thm:full-info} applies, and we get
	\begin{align}\label{eq:cor-partial-info-inter-2}
		\inf_{s \in \Scal} \sup_{H \in \Delta([0,1])} \reg_F(s, H) \leq \sup_{H}\ \reg_F(\s[Q^*], H) = \sup_{h \in [0,1]} \rr[F]{\s[Q^*], h} \leq \rr[F]{\s[Q^*], H^*} = \reg_F(\s[Q^*], \mathcal H^*)\,.
	\end{align}
    Combining \eqref{eq:cor-partial-info-inter-1} and \eqref{eq:cor-partial-info-inter-2} immediately yields
    \begin{align*}
        \inf_{s \in \Scal} \sup_{H \in \Delta([0,1])} \reg_F(s, H)\ =\ \reg_F(\s[Q^*], \mathcal H^*) = \rr[F]{\s[Q^*], H^*} = \int_0^1 Q^*(t)dt\,. \qquad \qedhere
    \end{align*}
\end{proof}

\section{Proofs of Results in \Cref{sec:value-dist-impact}}

\begin{proof}[\textbf{Proof of \Cref{thm:worst-value-dist}}]
	Define $\mathcal Q_0 \coloneqq \{Q \in \mathcal {Q} \mid Q(0) = 0\}$. In \Cref{appendix:atom-at-0}, we show that for every value distribution $F$ such that $F(0)>0$, there exists another distribution $\tilde F$ with $\tilde F(0) = 0$ such that
    \begin{align*}
        \inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])}\ \reg_F(s,H) \leq \inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])}\ \reg_{\tilde F}(s,H)\,.
    \end{align*}
    Thus, without loss of generality, we will assume $F(0) = 0$ for all value distributions in this proof.

	Fix any value distribution $F \in \Delta([0,1])$ with $F(0)= 0$. Using \Cref{thm:full-info} and Corollary~\ref{cor:partial-info-saddle}, and the fact that $\s[Q^*] \in \mathcal{Q}_0$, we get
	\begin{align*}
		\inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])}\ \reg_F(s,H)\ =\ \inf_{Q \in \mathcal Q_0}\ \sup_{H \in \Delta([0,1])}\ \reg_F(\s[Q],H)\ = \inf_{Q\in \mathcal Q_0}\ \sup_{h \in [0,1]}\ \rr[F]{\s[Q], h}\,.
	\end{align*}
	
	Furthermore, for any $Q \in \mathcal{Q}$, as $\s[Q]$ never bids above $Q(1)$, we have for all $h > Q(1)$ that,
	\begin{align*}
		\rr[F]{\s[Q], h} = \mathcal{O}_{F}(h) - \U[F]{\s[Q], h} \leq \mathcal{O}_{F}(Q(1)) = \mathcal{O}_{F}(h) - \U[F]{\s[Q], h} = \rr[F]{\s[Q], Q(1)}\,.
	\end{align*}
    Here, we have used the fact that $\Prob_{v \sim F, b \sim \s[Q]}(b < Q(1)) = 1$, which follows from the characterization of the induced bid distribution of $\s[Q]$ in \Cref{lemma:quantile-based-bidding}. Therefore,
	\begin{align*}
		\inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])}\ \reg_F(s,H)\ =\ \inf_{Q\in \mathcal Q_0}\ \sup_{y \in [0,1]}\ \rr[F]{\s[Q], Q(y)}\,.
	\end{align*}
	
	Now, for $Q \in \mathcal{Q}_0$ and $y \in [0,1]$, we have
	\begin{align*}
		\rr[F]{\s[Q], Q(y)}\ &=\ \mathcal{O}_{F}(Q(y))\ -\ \U[F]{\s[Q], Q(y)}\\
		&=\ \E_{v \sim F}[(v - Q(y))\mathbbm{1}(v\geq Q(y))]\ -\ \int_y^1 (F^-(t) - Q(t)) dt \tag{\Cref{lemma:quantile-based-bidding}}\\
		&=\ \E_{t \sim \unif(0,1)}[(F^-(t) - Q(y))\mathbbm{1}(F^-(t)\geq Q(y))]\ -\ \int_y^1 (F^-(t) - Q(t)) dt\\
		&=\ \int_{F(Q(y))}^1 (F^-(t) - Q(y)) dt\ -\ \int_y^1 (F^-(t) - Q(t)) dt\\
		&=\ \int_{F(Q(y))}^y (F^-(t) - Q(y)) dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\,.
	\end{align*}
	
	Therefore,
	\begin{align*}
		\inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])}\ \reg_F(s,H)\ =\ \inf_{Q\in \mathcal Q_0}\ \sup_{y \in [0,1]}\ \int_{F(Q(y))}^y (F^-(t) - Q(y)) dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\,.
	\end{align*}
	
	As $\s[Q^*]$ is a minimax-optimal strategy and $Q^*(y) \leq F^-(y)$ for all $y \in [0,1]$, we get
	\begin{align*}
		&\inf_{Q\in \mathcal Q_0}\ \sup_{y \in [0,1]}\ \int_{F(Q(y))}^y (F^-(t) - Q(y)) dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\\
		=\ &\inf_{Q\in \mathcal Q_0}\ \sup_{\substack{y \in [0,1]: \\ F(Q(y)) \leq y}}\ \int_{F(Q(y))}^y (F^-(t) - Q(y)) dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\\
		=\ &\inf_{Q\in \mathcal Q_0}\ \sup_{\substack{y \in [0,1]: \\ F(Q(y)) \leq y}}\ \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\\
		\leq\ &\inf_{Q\in \mathcal Q_0}\ \sup_{y \in [0,1]}\ \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\\
	\end{align*}
	
	Hence, we have shown that the following statement holds for all $F$ such that $F(0) = 0$:
	\begin{align*}
		\inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])}\ \reg_F(s,H)\ \leq\ \inf_{Q\in \mathcal Q_0}\ \sup_{y \in [0,1]}\ \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\,. \tag{\#}
	\end{align*}
	
	Next, fix a $\rho \in [1,\infty]$ and set $F_\rho \coloneqq \unif(1 - \tfrac{1}{\rho}, 1)$, where $F_\infty = \delta_1$. Taking an supremum over $F \in \mathcal F_\rho$ on both sides of $(\#)$ yields
	\begin{align*}
		&\sup_{F \in \F_\rho}\ \inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])}\ \reg_F(s,H)\\
		\leq\ &\sup_{F \in \F_\rho}\ \inf_{Q\in \mathcal Q_0}\ \sup_{y \in [0,1]}\ \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\\
		\leq\ &\inf_{Q\in \mathcal Q_0}\ \sup_{F \in \F_\rho}\  \sup_{y \in [0,1]}\ \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\\
		=\ &\inf_{Q\in \mathcal Q_0}\ \sup_{y \in [0,1]}\ \sup_{F \in \F_\rho}\   \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt\ +\ \int_y^1 (Q(t) - Q(y)) dt
	\end{align*}
	
	If we can show that
	\begin{align*}
		F_\rho\ \in \argmax_{F \in \F_\rho} \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt &&\forall\ Q\in \mathcal{Q}_0,\ y\in [0,1]\,, \tag{$\diamond$}
	\end{align*}
	then we would be done because we would have shown
	\begin{align*}
		\sup_{F \in \F_\rho}\ \inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])} \reg_F(s,H)\ &\leq\ \inf_{Q\in \mathcal Q_0}\sup_{y \in [0,1]}\   \int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt\ +\ \int_y^1 (Q(t) - Q(y)) dt\\
		&=\ \inf_{s \in \Scal}\ \sup_{H \in \Delta([0,1])} \reg_{F_{\rho}}(s,H)\,.
	\end{align*}
	
	To finish the proof, we now establish $(\diamond)$. We do so in two steps: we fix $F \in \mathcal{F}_{\rho}$ and (i) we show that $F_\rho(h) \leq F(h)$ for all $h \in [0,1]$; (ii)  we show that $F^-(t) \leq F_\rho^-(t)$ for all $t \in [0,1]$.
	\begin{itemize}
		\item[(i)] Fix any $h \in [0,1]$. Then, $$F(h) = 1 - F((h,1]) \geq 1 - \min\{1, \rho\cdot \lambda((h,1])\} = 1 - F_\rho((h, 1]) = F_\rho(h)\,.$$
		\item[(ii)] As $F^-(0) = F^-_\rho(0)$, we focus on $t \in (0,1]$. Then, $F_\rho^-(t) = 1 + (t-1)/\rho$ and 
		\begin{align*}
			F(F^-_\rho(t)) = F\left(1 + \frac{t-1}{\rho} \right) = 1 - F\left(\left(1 + \frac{t-1}{\rho}, 1\right] \right) \geq 1 - \rho \cdot \lambda\left(\left(1 + \frac{t-1}{\rho}, 1\right] \right) = 1- (t-1) = t\,.
		\end{align*}
		As a consequence, we get $F^-(t) \leq F_\rho^-(t)$.
	\end{itemize}
	
	Finally, (i) and (ii) together imply $(\diamond)$ because
	\begin{align*}
		\int_{F(Q(y))}^y (F^-(t) - Q(y))^+ dt \leq \int_{F_\rho(Q(y))}^y (F_\rho^-(t) - Q(y))^+ dt &&\forall\ Q\in \mathcal{Q}_0,\ y\in [0,1]\,.
	\end{align*}  
	As proving $(\diamond)$ was sufficient to complete the proof, we have established the theorem.
\end{proof}