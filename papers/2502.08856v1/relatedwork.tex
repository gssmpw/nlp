\section{Related Work}
\label{sec:related}

\subsection{Generative Models} Generative Adversarial Networks (GANs) \cite{GAN} are among the most widely used generative models. It employs a generator and a discriminator, two competing neural networks; the generator tries to trick the discriminator to classify the fake data as real, while the discriminator tries to differentiate real and fake data.

Variational Autoencoders (VAEs) \cite{vae} are another class of generative models, which map real data to a distribution within a latent space by an encoder, then a decoder maps from the latent space to the input space.  

Diffusion models represent the latest advancement in generative models \cite{DDPM
% ,song2019generativeModeling
}. They involve a forward diffusion process and a reverse denoising process. In the forward process, noise is gradually added to the training data with increasing magnitude until the data becomes pure noise. In the reverse process, a model is trained to denoise the noisy data, effectively reconstructing the clean data and learning the underlying data distribution.

\subsection{Tabular Data Generation}
Tabular data pose unique challenges for synthetic data generation. Unlike image data, tabular data often consist of a mix of continuous and discrete variables. Moreover, values in the discrete columns frequently exhibit imbalanced distributions, adding an additional layer of complexity to the generation process. \cite{ctgan} proposes a conditional tabular GAN (CTGAN) to address these challenges. CTGAN employs two distinct sampling approaches to handle discrete and continuous variables in the training data. For discrete variables, it first randomly selects a discrete column, then samples rows based on the logarithm frequency of categorical values in that column. The sampled categorical values will serve as conditional inputs to GAN. For continuous variables, it estimates the number of modes for each column with variational Gaussian mixture models \cite{bishop2006pattern} and samples by modes and normalizes the values. \cite{ctgan} also proposed tabular VAE (TVAE) by adapting VAE to tabular data.

\cite{ctab-gan} makes improvements upon CTGAN motivated by several observations: \emph{Within one variable} of the tabular data there may be mixed continuous and categorical data types, and its distribution may be skewed and have a long tail. The authors address these issues by proposing mode-value pair for mixed data types, logarithmic transformation for variables with long tail distribution, and an additional continuous mode as the conditional input to GAN.

\cite{kotelnikov2023tabddpm} proposed TabDDPM by adapting diffusion models to the tabular data domain, employing Gaussian diffusion models for continuous variables and multinomial diffusion models for categorical variables \cite{hoogeboom2021argmax}. \cite{kim2022stasy} proposed the STaSy model by directly adapting score-based generative modeling \cite{song2021scorebased_sde} to the tabular data domain.

While these techniques have shown promise in tabular data, to the best of our knowledge, they have not been evaluated in the context of transportation data with their unique characteristics. 
In this work, we evaluate the aforementioned tabular synthetic data generation techniques within the context of a transportation data use case.

\input{sections/background}