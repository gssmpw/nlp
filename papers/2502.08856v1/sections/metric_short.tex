
\subsection{Evaluation Metrics for Generative Models} \label{sec:metrics}
The quality of synthetic data is evaluated based on its utility and its ability to preserve privacy. However, higher privacy protection can potentially reduce a model's utility. Conversely, higher utility (i.e., synthetic data that closely resembles real data) may increase the privacy risks. Balancing utility and privacy in synthetic data generation is challenging and remains an active research area \cite{groundhog}. 

In this context, utility can be assessed through various measures, including downstream task performance, statistical similarity, and diversity. Privacy preservation can be evaluated by measuring the distance between synthetic data point and real data. Below, we present a brief description of these measures.

\textbf{Downstream Task Performance} To evaluate the utility of the generated synthetic data, we employ a selected downstream task. In the context of taxi ride information, one critical piece of information is the total cost of the ride. The key question, therefore, is how effectively the synthetic data can be used to train a machine learning model capable of accurately predicting the total cost of a taxi ride. More specifically, we generate synthetic data with the trained generative model, train a prediction model ``Gradient Boosting for Regression" \cite{gradient_boosting} with the synthetic data, then we predict the ``total amount" (i.e., the total amount paid for the taxi ride) with the training data and synthetic data respectively. The performance is represented by $R^2$, the coefficient of determination~\cite{coefficient_determination}. The best possible value of $R^2$ is 1.

\textbf{Similarity} We use Wasserstein distance \cite{WGAN} to measure the similarity between two distributions (i.e., real vs synthetic data).

\textbf{Diversity} We use coverage \cite{coverage} to measure the diversity of a distribution, enabling us to assess whether mode collapse \cite{GAN} has occurred. Coverage is calculated as the percentage of real sample hyperspheres which contain a generated sample. The real sample hypersphere is calculated with its $K^{th}$ nearest neighbor. It is found to be more robust than the metric recall \cite{
% improved_precision_recall, 
thompson2022evaluation}.

\textbf{Privacy Measure} \label{sec:dcr}
The distance of a synthetic data point to its closest real data neighbor (DCR) serves as a metric for evaluating privacy preservation in synthetic data generation \cite{
% dcr_renmin, 
ctab-gan}. This ensures that synthetic records are not overly similar to individual records in the original dataset, thereby reducing the risk of privacy breaches. This metric is also closely related to membership inference attacks \cite{membership_MIA}, where a distance-based metric \cite{hilprecht2019_gan_attack} is utilized to determine whether a data point was included in the training dataset of the model under attack. We explore this connection in greater detail in Section \ref{sec:rDCR}.