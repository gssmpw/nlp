
\subsection{Evaluation Metrics for Generative Models} \label{sec:metrics}
The quality of synthetic data is evaluated based on its utility and its ability to preserve privacy. However, higher privacy protection can potentially reduce a model's utility. Conversely, higher utility (i.e., synthetic data that closely resembles real data) may increase the privacy risks. Balancing utility and privacy in synthetic data generation is challenging and remains an active research area \cite{groundhog}. 

In this context, utility can be assessed through various measures, including downstream task performance (e.g., using synthetic data for machine learning tasks), statistical similarity between the original data and the generated synthetic data, such as the Wasserstein distance \cite{wasserstein-distance}, and diversity metrics, such as coverage \cite{coverage}. Privacy preservation can be evaluated by measuring the distance between a synthetic data point and its nearest neighbor in the real data, which provides an indication of how closely the synthetic data mirrors individual records in the original dataset \cite{hilprecht2019_gan_attack}. Below, we present the mathematical formalization of these measures.

\subsubsection{Downstream Task Performance} To evaluate the utility of the generated synthetic data, we employ a selected downstream task. In the context of taxi ride information, one critical piece of information is the total cost of the ride. The key question, therefore, is how effectively the synthetic data can be used to train a machine learning model capable of accurately predicting the total cost of a taxi ride. More specifically, we generate synthetic data with the trained generative model, train a prediction model ``Gradient Boosting for Regression" \cite{gradient_boosting} with the synthetic data, then we predict the ``total amount" (i.e., the total amount paid for the taxi ride) with the training data and synthetic data respectively. The performance is represented by coefficient of determination \cite{coefficient_determination}
\begin{equation}
   R^2=(1-\frac{u}{v}),
\end{equation}
where
\begin{equation}
   u=\sum_i(y-\hat{y})^2, v=\sum_i(y-\bar{y})^2,
\end{equation}
where $y$ is the true value, $\hat{y}$ is the predicted value and $\bar{y}$ is the mean of the true values. 
The best possible value of $R^2$ is 1.

\subsubsection{Similarity}
%One metric is similarity score \cite{sdv_score}, which is $1-\delta_{KS}$ for numerical value, and $1-\delta_{TVD}$ for discrete values, where $\delta_{KS}$ is KS statistics and $\delta_{TVD}$ is Total Variation Distance. The range of the score value is [0, 1]: the higher the score, the more similar of two distributions.

We use Wasserstein distance to measure the similarity between two distributions (i.e., real vs synthetic data), which can be represented as \cite{WGAN}:
%\mk{Do you need the brackets \textbackslash[ \textbackslash ] in the formula below.} % notation convention: E[]
\begin{equation}
    W(\mathbb{P}_r,\mathbb{P}_g)=\inf_{\gamma\in\Pi(\mathbb{P}_r,\mathbb{P}_g))}\mathbb{E}_{(x,y)\in\gamma}[\|(x-y)\|]
\end{equation}
where $\Pi(\mathbb{P}_r,\mathbb{P}_g)$ is the set of all joint distributions $\gamma(x,y)$ whose marginals are $\mathbb{P}_r$ and $\mathbb{P}_g$, respectively.

\subsubsection{Diversity} We use coverage \cite{coverage} to measure the diversity of a distribution, enabling us to assess whether mode collapse \cite{GAN} has occurred. Coverage is calculated as the percentage of real sample hyperspheres which contain a generated sample. The real sample hypersphere is calculated with its $K^{th}$ nearest neighbor. It is found to be more robust than the metric recall \cite{improved_precision_recall, thompson2022evaluation}.

\subsubsection{Privacy Measure} \label{sec:dcr}
The distance of a synthetic data point to its closest real data neighbor (DCR) serves as a metric for evaluating privacy preservation in synthetic data generation \cite{dcr_renmin, ctab-gan}. This ensures that synthetic records are not overly similar to individual records in the original dataset, thereby reducing the risk of privacy breaches.
%\mk{the next sentence is not clear need to expand on it.}
This metric is also closely related to membership inference attacks \cite{membership_MIA}, where a distance-based metric \cite{hilprecht2019_gan_attack} is utilized to determine whether a data point was included in the training dataset of the model under attack. We explore this connection in greater detail in Section \ref{sec:rDCR}.