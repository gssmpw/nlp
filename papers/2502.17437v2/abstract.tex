% Recent progress of autoregressive models for image generation often relies on tokenizers to compress images into token sequences. In this work, we show that a fully pixel-level autoregressive approach can also effectively generate high-resolution images. We propose \name, a recursive autoregressive framework that divides and conquers long pixel sequences by multiple levels of autoregressive models. By recursively fractalizing images into smaller patches, we limit the sequence length within each level to a manageable size, and thus reduce the quadratic complexity of pixel-level modeling to a log-linear scale. 
% \name~achieves strong results with fast speed, generating ImageNet 256$\times$256 images in under 0.5 seconds per image while achieving an FID \red{below 5.0}. Moreover, its fine-grained pixel-by-pixel generation naturally supports multiple editing tasks such as inpainting, outpainting, and interactive human-in-the-loop generation. We hope this work could rekindle interest in pixel-level autoregressive generation and encourage the exploration of autoregressive models in other domains that lack specialized tokenizers.

% Autoregression can be viewed as a recursive process, reflecting a divide-and-conquer spirit by decomposing complex distributions into simpler ones. In this paper, we take this concept a step further by introducing a recursive \emph{fractal} approach for autoregressive modeling. Instead of processing a single, potentially massive sequence in one pass, our method recursively constructs new autoregressive modules \emph{within} existing autoregressive steps, forming a fractal architecture of autoregressive models.
% As a running example, we apply \name~to pixel-level autoregressive image generation, treating images as extremely long sequences. Our experiments show that \name~achieves strong performance on high-resolution image synthesis, highlighting both the simplicity and effectiveness of the fractal approach. We hope this work will inspire future research in the recursive paradigms of autoregressive modeling, both for images and beyond.

Modularization is a cornerstone of computer science, abstracting complex functions into atomic building blocks. In this paper, we introduce a new level of modularization by abstracting generative models into atomic generative modules. Analogous to fractals in mathematics, our method constructs a new type of generative model by recursively invoking atomic generative modules, resulting in self-similar fractal architectures that we call \emph{\textbf{fractal generative models}}.
As a running example, we instantiate our fractal framework using autoregressive models as the atomic generative modules and examine it on the challenging task of pixel-by-pixel image generation, demonstrating strong performance in both likelihood estimation and generation quality. We hope this work could open a new paradigm in generative modeling and provide a fertile ground for future research. Code is available at \href{https://github.com/LTH14/fractalgen}{\textcolor{LightRed}{\scriptsize{\texttt{https://github.com/LTH14/fractalgen}}}}.
\vspace{-15pt}