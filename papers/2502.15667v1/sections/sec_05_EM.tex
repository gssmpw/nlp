\section{Expectation-Maximization Approach}\label{sec:An Expectation-Maximization Approach}
% In the previous section, we presented an ML approach for system identification. However, calculating the derivative of the likelihood function can be computationally expensive, making this approach less suitable for scenarios involving large datasets.To address this limitation, we propose an alternative expectation-maximization (EM) approach. Compared to the ML approach, the EM approach provides a more computationally efficient iterative framework, especially when finding a closed-form solution for maximum likelihood estimation is computationally challenging. The EM algorithm proceeds iteratively, with each iteration comprising two main steps: the expectation (E) step and the maximization (M) step. In the E step, using the measurement data and an initial parameter estimate, a probability distribution is determined for the state trajectories, e.g. with the Rauch-Tung-Striebel smoother \cite{rauch1965maximum}. In the subsequent M step, these state estimates and distributions are used to update the system parameters by maximizing the expected log-likelihood function derived from the distributions obtained in the E step.
%---
% In the previous section, we proposed an ML estimation approach for the system identification problem outlined in Section~\ref{sec:pf}. 
% %As we have discussed above, 
% % As discussed,
% % We have noted above that obtaining the derivative of the likelihood function can be computationally demanding for scenarios involving large datasets, making the introduced ML approach less suitable for real world situations. 
% % As noted earlier, obtaining the derivative of the likelihood function can be computationally intensive, particularly in scenarios involving large datasets. This limitation makes the proposed ML approach less practical for real-world applications.
% As noted earlier, obtaining the derivative of the likelihood function can be computationally intensive, particularly in scenarios involving large datasets, making the discussed ML approach limited and less suitable for real-world applications.
% To address this limitation, we propose an alternative method in this section based on expectation-maximization (EM) framework. 
% Compared to the introduced ML estimation method, the EM approach provides a more numerically efficient iterative framework, particularly when solving the maximum likelihood optimization problem is computationally challenging.
%---
% In the previous section, we proposed an ML estimation approach for the system identification problem outlined in Section~\ref{sec:pf}. As noted earlier, obtaining the derivative of the likelihood function can be computationally intensive, particularly in scenarios involving large datasets, making the discussed ML approach limited and less suitable for real-world applications. To address this limitation, we propose an alternative method in this section based on expectation-maximization (EM) framework. Compared to the introduced ML estimation method, the EM approach provides a more numerically efficient iterative framework, particularly when solving the maximum likelihood optimization problem is computationally challenging.
%---
In the previous section, we proposed an ML estimation approach for the system identification problem outlined in Section~\ref{sec:pf}. As noted earlier, obtaining the derivative of the likelihood function can be computationally intensive, particularly in scenarios involving large datasets, making the discussed ML approach limited and less suitable for real-world applications. To address this limitation, we propose an alternative method in this section based on the expectation-maximization (EM) framework. Compared to the introduced ML estimation method, the EM approach provides a more numerically efficient iterative framework, particularly when solving the maximum likelihood optimization problem is computationally challenging.
%---
% In the previous section, we introduced an ML estimation approach for the system identification problem outlined in Section~\ref{sec:pf}. As discussed, computing the derivative of the likelihood function can be computationally intensive, making this approach less practical for large datasets. To overcome this limitation, we propose an alternative method in this section based on the expectation-maximization (EM) framework. Compared to the ML approach, the EM method offers a more computationally efficient iterative process, particularly when solving the maximum likelihood optimization problem is prohibitively expensive.
%---
%---
% The EM algorithm proceeds iteratively, with each iteration consisting of two main steps, namely the expectation (E) step and the maximization (M) step. 
% In the E step, a probability distribution for the state trajectories is determined using the measurement data and an initial parameter estimate, e.g., through employing a suitably adapted version of the Rauch-Tung-Striebel smoother \cite{rauch1965maximum}. 
% % Subsequently, the obtained state estimates and distributions are used in the M step to update the estimation of the system parameters by maximizing the expected log-likelihood function derived from the distributions obtained in the E step. 
% % In the subsequent M step, the estimation of the system parameters is then updated by maximizing the expected log-likelihood function derived from the state estimates and distributions obtained in the E step. 
% In the subsequent M step, the estimation of system parameters is then updated by maximizing the expected log-likelihood function, derived from the state estimates and distributions obtained in the E step. The resulting updated parameter estimates are then employed in the next EM iteration. 
%---
% The EM algorithm proceeds iteratively, with each iteration consisting of two main steps, namely the expectation (E) step and the maximization (M) step. In the E step, a probability distribution for the state trajectories is determined using the measurement data and an initial parameter estimate, e.g., through employing a suitably adapted version of the Rauch-Tung-Striebel smoother \cite{rauch1965maximum}. In the subsequent M step, the estimation of system parameters is then updated by maximizing the expected log-likelihood function, derived from the state estimates and distributions obtained in the E step. The resulting updated parameter estimates are then employed in the next EM iteration. 
%---
The EM algorithm proceeds iteratively, with each iteration consisting of two main steps, namely the expectation (E) step and the maximization (M) step. In the E step, a probability distribution for the state trajectories is determined using the measurement data and an initial parameter estimate, e.g., through employing a suitably adapted version of the Rauch-Tung-Striebel smoother \cite{rauch1965maximum}. In the subsequent M step, the estimation of system parameters is then updated by maximizing the expected log-likelihood function derived from the state estimates and distributions obtained in the E step. The resulting updated parameter estimates are then employed in the next EM iteration. 
%---
% The EM algorithm operates iteratively, with each iteration consisting of two main steps: the expectation (E) step and the maximization (M) step. In the E step, a probability distribution for the state trajectories is determined using the measurement data and an initial parameter estimate, often with a suitably adapted version of the Rauch-Tung-Striebel smoother \cite{rauch1965maximum}. In the M step, these state estimates and distributions are used to update the system parameters by maximizing the expected log-likelihood function derived from the E step. The updated parameter estimates are then used in the subsequent EM iteration.
%---
%---
% In the sequel, we provide the details of our proposed EM approach addressing the identification problem outlined in Section~\ref{sec:pf}. More precisely, we present the details of E step, i.e., suitable adaptation of the Rauch-Tung-Striebel smoother for the dynamics considered in this paper. Furthermore, we discuss how to solve the optimization problem in the M step, showing that the expected log-likelihood maximization problem has a tractable closed-form solution.
%---
% In the following, we detail the proposed EM approach for addressing the identification problem outlined in Section~\ref{sec:pf}. Specifically, we describe the E step, which involves an appropriate adaptation of the Rauch-Tung-Striebel smoother to the considered dynamics. Additionally, we outline the solution to the optimization problem in the M step, demonstrating that the expected log-likelihood maximization admits a tractable closed-form solution.
%---
In the following, we describe the proposed EM approach for addressing the identification problem outlined in Section~\ref{sec:pf}. More precisely, we describe the E step, namely details of the appropriate adaptation of the Rauch-Tung-Striebel smoother to the considered dynamics. Additionally, we outline how to solve the optimization problem in the M step, i.e., showing that the expected log-likelihood maximization admits a tractable closed-form solution.

\subsection{Rauch-Tung-Striebel Smoother}
\label{sec:RTS smoother}
% The Rauch–Tung–Striebel smoother is widely used in states variables estimation. Besides the filtering part which is same as the Kalman filter algorithm \cite{kalman1960new}, the RTS smoother has an additional smoothing part using the estimated states distributions computed by the Kalman filter. 

% For E step, the Rauch-Tung-Striebel (RTS) smoother is used to obtain a probability distribution for the state trajectory. The RTS smoother is widely used in the estimation of state variables, which adds an additional smoothing part by using the estimated state distributions computed by the Kalman filter \cite{kalman1960new}. 
% 
In the E step, we obtain an estimation for the state trajectory. To this end, an appropriate variant of the Rauch-Tung-Striebel (RTS) smoother can be employed to derive a probability distribution for the state variables and, subsequently, estimate them.
% 
% E step
% Rauch-Tung-Striebel (RTS) smoother
% obtain aprobability distribution for the state trajectory
% the estimation of state variables
% additional smoothing part by using the estimated state distributions computed by the Kalman filter \cite{kalman1960new}. 
% 
% In the E step, we need to utilize a variant of Rauch-Tung-Striebel (RTS) smoother to obtain a probability distribution for the state trajectory given measurement data and an estimation of the parameters
% 
% In the E step, we need the estimation of the state trajectory. To this end, a suitable variant of Rauch-Tung-Striebel (RTS) smoother can be utilized to obtain a probability distribution for the state variables, and subsequently, estimate them.
% given measurement data and an estimation of the parameters.
% The RTS smoother additional smoothing part by using the estimated state distributions computed by the Kalman filter \cite{kalman1960new}. 
% 
% 
% Given measurement data $\Dcal$, we want to obtain $\hat{\vctheta}$, the estimate $\vctheta$, defined as 
% \begin{equation}
%     \begin{split}
%     \hat{\vctheta} :  =\,\,[\text{vec}(\hat{\mxA})^\tr , \text{vec}(\hat{\mxB})^\tr,\text{vec}(\hat{\mxC}_0)^\tr,\text{vec}(\hat{\mxC}_1)^\tr,...,\text{vec}(\hat{\mxC}_{\Nu})^\tr, \text{vec}(\hat{\mxD})^\tr, \text{vec}(\hat{\vcmu}_{\vcx_0})^\tr,\text{vec}(\hat{\mxS}_{\vcx_0})^\tr,\text{vec}(\hat{\mxS}_\vcw)^\tr,\text{vec}(\hat{\mxS}_\vcv)^\tr].
%     \end{split}
% \end{equation}
%
% The RTS smoother is widely used for the estimation of state variables, which adds an additional smoothing part by using the estimated state distributions computed by the Kalman filter \cite{kalman1960new}.  
% We begin with the Kalman filter, an algorithm designed to estimate a system's state variables by integrating measurement data with prior knowledge of noise's statistical properties.
%
% The RTS smoother utilizes the Kalman filter \cite{kalman1960new}, providing an initial estimation for the state variables of the system based on the measurement data and the knowledge of the statistical properties of the process and measurement noise, and an additional smoothing part to improve the accuracy of the estimated state variables.
%
% The RTS smoother employs the Kalman filter \cite{kalman1960new} to provide an initial estimate for the state variables of the system based on the measurement data and the statistics of process and measurement noise. It then applies a smoothing step to improve the accuracy of the estimated state variables.
%
% The RTS smoother utilizes the Kalman filter \cite{kalman1960new} to provide an initial estimate for the state variables of the system based on the measurement data and the statistics of process and measurement noise. It then applies a smoothing step to improve the accuracy of the estimated state variables.
%
% The RTS smoother employs the Kalman filter \cite{kalman1960new}, providing an initial estimate for the state variables of the system, and then, applies a smoothing step to improve the accuracy of the estimation results.
% %% based on the measurement data and the statistics of process and measurement noise. It then
%
The RTS smoother employs the Kalman filter \cite{kalman1960new}, which utilizes an estimate of parameters, the measurement data and the statistics of process and measurement noise to provide an initial estimation for the state variables of the system. It then applies a smoothing step to improve the accuracy of the estimated state variables.
%
% In each RTS iteration, the estimated parameters, along with the measurements, are used to obtain the mean and covariance of the state variables, providing estimates over time.

%--------
% In each iteration, the estimated parameters, along with the measurements, are used to obtain the mean and covariance of the state variables, providing estimates over time.
% Although the true parameters of the system are unknown, we start with an initial guess and iteratively update these estimates, denoted $\hat{\vctheta}$. 
%
% Given parameter estimate $\hat{\vctheta}$, along with the measurement data, Kalman filter returns a Gaussian distribution for the state variables. More precisely, for any $t$, Kalman filter provides the mean and covariance of the state variables as
%
% In each RTS iteration, the estimated parameters, along with the measurements, are used to obtain the mean and covariance of the state variables, providing estimates over time. More precisely, for any $t$, Kalman filter provides
% 
% Given an estimation for the $\hat{\vctheta}$, along with the measurement data, Kalman filter yields a Gaussian distribution for the state variables. More precisely, for any time step $t$, Kalman filter computes the mean and covariance of the state variables, denoted as $\hat{\vcx}_{t|t}$ and $\mxP_{t|t}$, respectively, as
%
% Given the measurement data and an estimation for the parameters, the Kalman filter provides a Gaussian distribution for the state variables. More precisely, for any time step $t=0,1,\ldots,\nD-1$, Kalman filter computes the mean and covariance of the state variables, respectively denoted by $\hat{\vcx}_{t|t}$ and $\mxP_{t|t}$, as
%
Given the measurement data and an estimation of the parameters, the Kalman filter provides a Gaussian distribution for the state variables. In particular, for any time step $t = 0, 1, \ldots, \nD-1$, the Kalman filter computes the mean and covariance for the state variables estimates, denoted by $\hat{\vcx}_{t|t}$ and $\mxP_{t|t}$, respectively, as 
% \begin{equation}
% \begin{split}
%     \hat{\vcx}_{t|t} &= \mathbb{E}[\vcx_t | \vcy_0, \ldots, \vcy_t, \hat{\vctheta}], \\
%     \mxP_{t|t} &= \mathbb{E}[(\vcx_t - \hat{\vcx}_{t|t})(\vcx_t - \hat{\vcx}_{t|t})^\tr | \vcy_0, \ldots, \vcy_t, \hat{\vctheta}],
% \end{split}
% \end{equation}
\begin{equation}
    \hat{\vcx}_{t|t} := \mathbb{E}\big[\vcx_t | \vcy_0, \ldots, \vcy_t, \hat{\vctheta}\big], 
\end{equation}
and
\begin{equation}
    \mxP_{t|t} := \mathbb{E}\big[(\vcx_t - \hat{\vcx}_{t|t})(\vcx_t - \hat{\vcx}_{t|t})^\tr | \vcy_0, \ldots, \vcy_t, \hat{\vctheta}\big],
\end{equation}
% where $\hat{\vctheta}$ denotes the given estimates for the parameters. 
where $\hat{\vctheta}$ represents the given estimates of the parameters. 
%
% In the above equation, estimates $\hat{x}_{0|0}$ and $\mxP_{0|0}$ are provided by $\hat{\vctheta}$, which are $\hat{\mu}_{\vcx_0}$ and $\hat{\mxS}_{\vcx_0}$, respectively.
%
% Note that, for $t=0$, ... are essentially 
% 
% Note that, for $t=0$, we know that $\hat{\vcx}_{t|t}$ and $\mxP_{t|t}$ corresponds to $\hat{\mu}_{\vcx_0}$ and $\hat{\mxS}_{\vcx_0}$, respectively, and hence, can be obtained from $\hat{\vctheta}$.
% To estimate the state variables for all time steps $t>0$, an additional inner iteration is required throughout the length of the data. Based on the dynamics given in \eqref{eqn:dynamics1} and \eqref{eqn:dynamics2}, this process follows an iterative scheme as,
%
Note that, for $t=0$, $\hat{\vcx}_{t|t}$ and $\mxP_{t|t}$ corresponds to $\hat{\mu}_{\vcx_0}$ and $\hat{\mxS}_{\vcx_0}$, respectively, and can thus be obtained from $\hat{\vctheta}$.
To estimate the state variables for time steps $t = 1, \ldots, \nD-1$, an additional inner iteration needs to be performed. More precisely, based on the dynamics described in \eqref{eqn:dynamics1} and \eqref{eqn:dynamics2}, the Kalman filter employs an iterative scheme as
\begin{equation}\label{eq:kalman filter}
    \begin{split}
        \hat{\vcx}_{t|t}   =&\,\, \hat{\vcx}_{t|t-1} + \mxK_t(\vcy_t - \hat{\Xi}_t \hat{\vcx}_{t|t-1}),\\
        \mxP_{t|t}   =&\,\, (\mathbb{I}_{\Nx} - \mxK_t \hat{\Xi}_t)\mxP_{t|t-1},\\
        \mxK_t   =&\,\, \mxP_{t|t-1}\hat{\Xi}_t^\tr[\hat{\Xi}_t \mxP_{t|t-1}\hat{\Xi}_t^\tr + \hat{\mxS}_\vcv]^{-1},\\
        \hat{\vcx}_{t+1|t}   =&\,\, \hat{\mxA}\hat{\vcx}_{t|t} + \hat{\mxB} \vcu_{t},\\
        \mxP_{t+1|t}   =&\,\, \hat{\mxA}\mxP_{t|t}\hat{\mxA}^\tr + \hat{\mxS}_\vcw,\\
    \end{split}
\end{equation}
where $\hat{\Xi}_t$ is defined as
\begin{equation}
\hat{\Xi}_t = \hat{\mxC}_0 + \sum_{i=1}^{\Nu} \hat{\mxC}_iu_{t,i}.    
\end{equation}
%
% After applying the Kalman filter algorithm, the RTS smoother is used to improve the accuracy of the state estimates. The RTS smoother introduces an additional backward recursively pass to smooth the estimates obtained from the forward pass. Using the smoother, the estimated mean $\hat{\vcx}_{t|{\nD}} = \mathbb{E}[\vcx_t|\mathbf{y},\hat{\vctheta}]$ and estimated covariance $\mxP_{t|{\nD}} = \mathbb{E}[(\vcx_t - \hat{\vcx}_{t|{\nD}})(\vcx_t - \hat{\vcx}_{t|{\nD}})^\tr|\mathbf{y},\hat{\vctheta}]$ can be recursively obtained as 
%
% Subsequently, the RTS smoother improves the accuracy of the state estimates following an additional backward procedure, recursively smoothing the estimates obtained from the Kalman filter. More specifically, the mean and covariance of the state variables estimation, namely  $\hat{\vcx}_{t|{\nD}}$ and $\mxP_{t|{\nD}}$ defined respectively as $\hat{\vcx}_{t|{\nD}} := \mathbb{E}[\vcx_t|\mathbf{y},\hat{\vctheta}]$ and $\mxP_{t|{\nD}} := \mathbb{E}[(\vcx_t - \hat{\vcx}{t|{\nD}})(\vcx_t - \hat{\vcx}{t|{\nD}})^\tr|\mathbf{y},\hat{\vctheta}]$, are recursively obtained as 
%
% Subsequently, the RTS smoother enhances the accuracy of state estimates through an additional backward recursion procedure, which refines the estimates initially produced by the Kalman filter. Specifically, the mean and covariance of the state variable estimates, denoted by $\hat{\vcx}_{t|{\nD}}$ and $\mxP{t|{\nD}}$, are defined as $\hat{\vcx}_{t|{\nD}} := \mathbb{E}[\vcx_t|\mathbf{y},\hat{\vctheta}]$ and $\mxP{t|{\nD}} := \mathbb{E}[(\vcx_t - \hat{\vcx}{t|{\nD}})(\vcx_t - \hat{\vcx}{t|{\nD}})^\tr|\mathbf{y},\hat{\vctheta}]$, respectively, and recursively obtained as 
%
Subsequently, the RTS smoother improves the accuracy of the state estimates following an additional backward procedure, recursively smoothing the estimates obtained from the Kalman filter. More specifically, we obtain the mean and covariance of the state variables estimation, namely  $\hat{\vcx}_{t|{\nD}}$ and $\mxP_{t|{\nD}}$ defined respectively as $\hat{\vcx}_{t|{\nD}} := \mathbb{E}[\vcx_t|\mathbf{y},\hat{\vctheta}]$ and $\mxP_{t|{\nD}} := \mathbb{E}[(\vcx_t - \hat{\vcx}_{t|{\nD}})(\vcx_t - \hat{\vcx}_{t|{\nD}})^\tr|\mathbf{y},\hat{\vctheta}]$. To this end, for $t = 0,1, \ldots, \nD-2$, we employ a recursive procedure as 
\begin{equation}\label{eq:mean and covariance}
    \begin{split}
        \hat{\vcx}_{t|{\nD}}   =&\,\, \hat{\vcx}_{t|t} + {\mxL}_t(\hat{\vcx}_{t+1|\nD} - \hat{\vcx}_{t+1|t}),\\
        \mxP_{t|{\nD}}   =&\,\, \mxP_{t|t} + {\mxL}_t(\mxP_{t+1|{\nD}} - \mxP_{t+1|t}){\mxL}_t^\tr,\\
        \mxL_t   =&\,\, \mxP_{t|t}\hat{\mxA}^\tr\mxP_{t+1|t}^{-1},\\
    \end{split}
\end{equation}
%  where the initial conditions $\hat{\vcx}_{{\nD}|{\nD}}$ and $\mxP_{{\nD}|{\nD}}$ are set by the results of Kalman filter.
% Moreover, we can further derive the following estimations \cite{sarkka2023bayesian} 
% \begin{equation} \label{eq:correlation}
%     \begin{split}
%         \mathbb{E}[\vcx_t \vcx_t^{\tr}|\mathbf{y}, \hat{\vctheta}]   =&\,\, \hat{\vcx}_{t|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t|{\nD}},\\
%         \mathbb{E}[\vcx_{t+1} \vcx_t^{\tr}|\mathbf{y}, \hat{\vctheta}]   =&\,\, \hat{\vcx}_{t+1|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t+1|{\nD}}\mxH_t^\tr,\\
%     \end{split}
% \end{equation}
% which will be used later in the EM algorithm as discussed in the remainder of this section.
% which will be utilized later in the EM algorithm, as discussed in the remainder of this section.
%---
% Moreover, one can additionally obtain \cite{sarkka2023bayesian} 
% \begin{equation} \label{eq:correlation}
%         \mathbb{E}[\vcx_t \vcx_t^{\tr}|\mathbf{y}, \hat{\vctheta}]   = \, \hat{\vcx}_{t|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t|{\nD}},
% \end{equation}
% for $t = 0,1, \ldots, \nD-1$, and 
% \begin{equation} \label{eq:correlation_next}
%         \mathbb{E}[\vcx_{t+1} \vcx_t^{\tr}|\mathbf{y}, \hat{\vctheta}]   = \, \hat{\vcx}_{t+1|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t+1|{\nD}}\mxH_t^\tr,
% \end{equation}
% for $t = 0,1, \ldots, \nD-2$,
% %which will be used later in the EM algorithm as discussed in the remainder of this section.
% which will be utilized later in the EM algorithm, as discussed in the remainder of this section.
%
Moreover, one can additionally obtain 
\begin{equation} \label{eq:correlation}
    \begin{split}
        \mathbb{E}[\vcx_t \vcx_t^{\tr}|\mathbf{y}, \hat{\vctheta}]   =&\,\, \hat{\vcx}_{t|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t|{\nD}},
        \qquad\qquad\quad \ \;\!
        \forall\,t = 0,1, \ldots, \nD-1,
        \\
        \mathbb{E}[\vcx_{t+1} \vcx_t^{\tr}|\mathbf{y}, \hat{\vctheta}]   =&\,\, \hat{\vcx}_{t+1|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t+1|{\nD}}\mxL_t^\tr,
        \qquad
        \forall\,t = 0,1, \ldots, \nD-2,
        \\
    \end{split}
\end{equation}
%which will be used later in the EM algorithm as discussed in the remainder of this section.
which will be utilized later in the EM algorithm, as discussed in the remainder of this section.


\subsection{Parameters Estimation using EM Algorithm} 
\label{sec:Parameters Estimation using EM algorithm}

% The EM contains two basic steps, which are discussed in the sequel. The expectation step formulates a log-likelihood function of parameters from the current estimates and given data. The maximization step finds the parameters that maximize the log-likelihood function. In this section, the EM algorithm is used with the RTS smoother to estimate parameters for the dynamical system $\Scal$. 
% The previous subsection introduces RTS smoother for the E step. After obtaining the state estimates, in the M step, the estimated parameter $\hat{\theta}$ is updated by maximizing an expected log-likelihood function. Specifically, denote $\hat{\vctheta}_k$ as the estimate of $\vctheta$ at iteration $k$ and define 
In the M step, the estimated parameter, denoted by $\hat{\theta}$ in the E step, is updated by maximizing an expected log-likelihood function. Specifically, let  $\hat{\vctheta}_k$ denote the estimate of $\vctheta$ at iteration $k$ of the EM algorithm, and define function $Q(\cdot|\hat{\vctheta}_k):\Theta\to\Rbb$ as
\begin{equation} \label{eqn:Q_theta_theta_k}
    Q(\vctheta|\hat{\vctheta}_k) 
    := 
    \mathbb{E}_{p(\mathbf{x} |\mathbf{y},\hat{\vctheta}_k,\mathbf{u})} \big[\log p(\mathbf{x},\mathbf{y}|\vctheta,\mathbf{u})\big],    
\end{equation}
for any $\vctheta\in\Theta$.
% Rather than maximizing the likelihood $p(\mathbf{y}|\vctheta,\mathbf{u})$  directly as discussed in Section~\ref{sec:ML}, the EM algorithm iteratively maximizes the auxiliary function $Q(\vctheta|\hat{\vctheta}_k)$ \cite{little2019statistical}, which in turn improves $\log p(\mathbf{y}|\vctheta,\mathbf{u})$. In contrast to the ML approach that naturally focuses on finding the parameters that maximize the probability of observing the measurement data, the EM algorithm achieves this by iteratively improving $Q(\vctheta|\hat{\vctheta}_k)$, and thus, indirectly increasing the probability of observations.
Rather than directly maximizing the likelihood $p(\mathbf{y}|\vctheta,\mathbf{u})$ as discussed in Section~\ref{sec:ML}, the EM algorithm employs an iterative scheme that maximizes the auxiliary function $Q(\vctheta|\hat{\vctheta}_k)$ \cite{little2019statistical}.
% , i.e.,
% it generates a sequence of parameter estimations as
% \begin{equation}\label{eq:EM optimization}
%     \hat{\vctheta}_{k+1}
%     =
%     \argmaxOp_{\vctheta\in\Theta}\,
%     Q(\vctheta|\hat{\vctheta}_k),
% \end{equation}
% for $k\ge 0$, where $\vctheta_0$ is an initial guess for the parameters $\vctheta$.
More precisely, given $\vctheta_0\in\Theta$, an initial guess for the parameters $\vctheta$, EM iteratively generates a sequence of parameter estimations given by
\begin{equation}\label{eq:EM optimization}
    \hat{\vctheta}_{k+1}
    =
    \argmaxOp_{\vctheta\in\Theta}\,
    Q(\vctheta|\hat{\vctheta}_k),
\end{equation}
for $k\ge 0$.
% More formally, starting with an initial guess $\vctheta_0$ for the parameters $\vctheta$, the EM algorithm iteratively generates a sequence of parameter estimates given by  
% \begin{equation}\label{eq:EM optimization}  
%     \hat{\vctheta}_{k+1}  
%     =  
%     \argmaxOp_{\vctheta\in\Theta}\,  
%     Q(\vctheta|\hat{\vctheta}_k),  
% \end{equation}  
% for \(k \geq 0\).
%----
% The resulting iterative procedure leads to the improvement of $\log p(\mathbf{y}|\vctheta,\mathbf{u})$. Unlike the ML approach, which focuses on directly identifying the parameters that maximize the likelihood of the observed data, the EM algorithm increases the likelihood indirectly by successively refining $Q(\vctheta|\hat{\vctheta}_k)$.
% The resulting iterative procedure progressively enhances $\log p(\mathbf{y}|\vctheta,\mathbf{u})$. Unlike the ML approach, which aims to directly identify the parameters that maximize the likelihood of the observed data, the EM algorithm indirectly increases the likelihood by iteratively refining $Q(\vctheta|\hat{\vctheta}_k)$.
The resulting iterative procedure leads to the improvement of $\log p(\mathbf{y}|\vctheta,\mathbf{u})$. Unlike the ML approach, which aims to directly identify the parameters that maximize the likelihood of the observed data, the EM algorithm indirectly increases the likelihood by successively refining $Q(\vctheta|\hat{\vctheta}_k)$.
%
More precisely, one can see that
% \begin{equation} \label{eq:log likelihoood}
%     \begin{split}
%         \log p(\mathbf{y}|\vctheta&) = \log p(\mathbf{x},\mathbf{y}|\vctheta,\mathbf{u}) - \log p(\mathbf{x}|\mathbf{y},\vctheta,\mathbf{u})\\
%           =&\,\, \sum_{\mathbf{x}}p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})[\log p(\mathbf{x},\mathbf{y}|\vctheta,\mathbf{u}) - \log p(\mathbf{x}|\mathbf{y},\vctheta,\mathbf{u})].\\
%     \end{split} 
% \end{equation}
\begin{equation} \label{eq:log likelihoood}
    \begin{split}
        \log p(\mathbf{y}|\vctheta,\mathbf{u}) \, \, 
        % &= \,\, \log p(\mathbf{x},\mathbf{y}|\vctheta,\mathbf{u}) - \log p(\mathbf{x}|\mathbf{y},\vctheta,\mathbf{u})
        % \\  
        &=\,\, 
        \int_{\Xbb} p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})
        \big[
        \log p(\mathbf{x},\mathbf{y}|\vctheta,\mathbf{u}) - \log p(\mathbf{x}|\mathbf{y},\vctheta,\mathbf{u})
        \big]\,\drm \mathbf{x}\\
        &= Q(\vctheta|\hat{\vctheta}_k) + I(\vctheta|\hat{\vctheta}_k),
    \end{split} 
\end{equation}
where function $I(\cdot|\hat{\vctheta}_k):\Theta\to\Rbb$ is defined as 
\begin{equation}
    I(\vctheta|\hat{\vctheta}_k) 
    := 
    -\, \mathbb{E}_{p(\mathbf{x} | \mathbf{y},\hat{\vctheta}_k,\mathbf{u})} 
    \big[
    \log p(\mathbf{x}|\mathbf{y},\vctheta,\mathbf{u})
    \big], 
\end{equation}
for any $\vctheta\in\Theta$.
% Define $I(\vctheta|\hat{\vctheta}_k) = -\mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})} \log p(\mathbf{x}|\mathbf{y},\vctheta,\mathbf{u})$. Note that \eqref{eq:log likelihoood} is equivalent to
% \begin{equation}
%     \log p(\mathbf{y}|\vctheta,\mathbf{u}) = Q(\vctheta|\hat{\vctheta}_k) + I(\vctheta|\hat{\vctheta}_k) .
% \end{equation}
Comparing $\log p(\mathbf{y}|\vctheta,\mathbf{u})$ with $\log p(\mathbf{y}|\hat{\vctheta}_k,\mathbf{u})$, the log-likelihood in the current iteration, we have
\begin{equation} \label{eq:Q convengence}
    \begin{split}
        \log p(\mathbf{y}|\vctheta,\mathbf{u}) 
        - 
        \log p(\mathbf{y}|\hat{\vctheta}_k,\mathbf{u}) =  Q(\vctheta|\hat{\vctheta}_k) - Q(\hat{\vctheta}_k|\hat{\vctheta}_k) + I(\vctheta|\hat{\vctheta}_k) - I(\hat{\vctheta}_k|\hat{\vctheta}_k).
    \end{split}
\end{equation}
From the Gibbs' inequality \cite{bremaud2012introduction}, we know that  $I(\vctheta|\hat{\vctheta}_k) \ge I(\hat{\vctheta}_k|\hat{\vctheta}_k)$, for any $\vctheta\in\Theta$. Accordingly, from \eqref{eq:Q convengence}, it is implied that
\begin{equation} \label{eq:Q convengence_2}
    \begin{split}
        \log p(\mathbf{y}|\vctheta,\mathbf{u}) 
        - 
        \log p(\mathbf{y}|\hat{\vctheta}_k,\mathbf{u}) 
        \ge 
        Q(\vctheta|\hat{\vctheta}_k) - Q(\hat{\vctheta}_k|\hat{\vctheta}_k).
    \end{split}
\end{equation}
for any $\vctheta\in\Theta$. 
% Therefore, $Q(\vctheta|\hat{\vctheta}_k)$ provides a lower bound for $\log p(\mathbf{y}|\vctheta,\mathbf{u})$, and consequently, its successive improvement will ultimately result in improving the log-likelihood function. Hence, the EM algorithm does not find the maximizer of $\log p(\mathbf{y}|\vctheta,\mathbf{u})$ directly, but improves the value through each iteration until it reaches convergence. 
Therefore, $Q(\vctheta|\hat{\vctheta}_k)$ provides a lower bound for $\log p(\mathbf{y}|\vctheta,\mathbf{u})$, and consequently, its successive improvement will ultimately result in improving the log-likelihood function. Hence, the EM algorithm does not find the maximizer of $\log p(\mathbf{y}|\vctheta,\mathbf{u})$ directly but improves the value through each iteration until it reaches convergence. 
%
% As discussed in Section~\ref{sec:Complexity Analysis}, while ML provides a more direct and intuitive approach to finding optimal parameters, it is computationally demanding. On the other hand, as elaborated below, the EM algorithm is more practical for large datasets, since maximizing $Q(\vctheta|\hat{\vctheta}_k)$ is computationally cheaper compared to maximizing log-likelihood $\log p(\mathbf{y}|\vctheta,\mathbf{u})$. 
As discussed in Section~\ref{sec:Complexity Analysis}, the ML approach offers a direct and intuitive approach to finding optimal parameters, albeit at a high computational cost. In contrast, as detailed below, the EM algorithm is better suited for large datasets, as maximizing $Q(\vctheta|\hat{\vctheta}_k)$ is computationally less expensive than maximizing the log-likelihood $\log p(\mathbf{y}|\vctheta,\mathbf{u})$. 
%In the following, we show how to derive $Q(\vctheta|\hat{\vctheta}_k)$ and, subsequently, demonstrate how to solve \eqref{eq:EM optimization}. 
In the following, we derive $Q(\vctheta|\hat{\vctheta}_k)$ and subsequently demonstrate how to solve \eqref{eq:EM optimization}.

% Consider the following function
Recall that we have
\begin{equation}\label{eq:likelihood function}
    p(\mathbf{x},\mathbf{y}|\vctheta,\mathbf{u}) = p(\mathbf{y}|\mathbf{x},\vctheta)p(\mathbf{x}|\vctheta,\mathbf{u}).
\end{equation}
Using Markov properties \cite{ross2014introduction}, $p(\mathbf{y}|\mathbf{x},\vctheta)$ 
%and $p(\mathbf{x}|\vctheta,\mathbf{u})$ 
can be decomposed as
\begin{equation}
    p(\mathbf{y}|\mathbf{x},\vctheta) 
    = 
    \prod_{t=0}^{\nD-1} p(\vcy_t|\mathbf{x},\vctheta)
    = 
    \prod_{t=0}^{\nD-1} p(\vcy_t|\vcx_t,\vctheta).
\end{equation}
Furthermore, for $p(\mathbf{x}|\vctheta,\mathbf{u})$, we have
\begin{equation}
    p(\mathbf{x}|\vctheta,\mathbf{u}) 
    = 
    \prod_{t=0}^{\nsmD-1} p(\vcx_t|\vctheta,\mathbf{u})
    = 
    p(\vcx_0|\vctheta,\mathbf{u}) \prod_{t=0}^{\nD-1} p(\vcx_{t+1}|\vcx_{t},\vctheta).
\end{equation}
% \begin{equation}
% \begin{split}
%     p(\mathbf{y}|\mathbf{x},\vctheta) &= \prod_{t=0}^{\nD-1} p(\vcy_t|\mathbf{x},\vctheta)
%     %\\&
%                   = \prod_{t=0}^{\nD-1} p(\vcy_t|\vcx_t,\vctheta),
% \end{split}
% \end{equation}
% and
% \begin{equation}
% \begin{split}
%     p(\mathbf{x}|\vctheta,\mathbf{u}) &= \prod_{t=0}^{\nD} p(\vcx_t|\vctheta,\mathbf{u})
%     %\\&
%     = p(\vcx_0|\vctheta,\mathbf{u}) \prod_{t=1}^{\nD} p(\vcx_t|\vcx_{t-1},\vctheta).
% \end{split}
% \end{equation}
Thus, the log function of \eqref{eq:likelihood function} can be derived as 
\begin{equation}\label{eq:log-likelihood function}
    \begin{split}
        \log p(\mathbf{x},\mathbf{y}|\vctheta,\mathbf{u}) = \log p(\vcx_0|\vctheta,\mathbf{u}) + \sum_{t=0}^{\nD-1}\log p(\vcy_t|\vcx_t,\vctheta) + \sum_{t=0}^{\nD-1}\log p(\vcx_{t+1}|\vcx_{t},\vctheta).
    \end{split}
\end{equation} 
% Consider each term $p(\vcy_t|\vcx_t,\vctheta)$ and $p(\vcx_t|\vcx_{t-1},\vctheta)$ in the above summation. First, recall that $p(\vcy_t|\vcx_t,\vctheta)$ is subject to a Gaussian distribution $\mathcal{N}(\vcmu_{\vcy_t},\mxS_\vcv)$, where $\vcmu_{\vcy_t} = \Xi_t(\vctheta) \vcx_t + \mxD \vcu_t$. 
% % and $\Xi_t(\vctheta) = \mxC_0 + \sum_{i=1}^{\Nu} \mxC_i \vcu_{t,i}.$
% % \begin{equation}
% % \begin{split}
% %     \vcmu_{\vcy_t} =& \Xi_t(\vctheta) \vcx_t + \mxD \vcu_t, \\
% %     \Xi_t(\vctheta) =& \mxC_0 + \sum_{i=1}^{\Nu} \mxC_i \vcu_{t,i}.
% %  \end{split}
% % \end{equation}
% Besides, from \eqref{eqn:dynamics1}, $p(\vcx_t|\vcx_{t-1}, \vctheta)$ is subject to a Gaussian distribution $\mathcal{N}(\vcmu_{\vcx_t},\mxS_\vcw)$, where $\vcmu_{\vcx_t} = \mxA \vcx_{t-1} + \mxB \vcu_{t-1}$, $\forall t \geq 1$. Therefore, using these Gaussian distributions, $Q(\vctheta|\hat{\vctheta}_k)$ can be rewritten as
% Following same line of arguments as in Section~\ref{sec:ML}, one can see that $\vcy_t|\vcx_t,\vctheta$ and $\vcx_{t+1}|\vcx_{t},\vctheta$ have Gaussian distributions respectively as  $\mathcal{N}(\Xi_t(\vctheta) \vcx_t + \mxD \vcu_t,\mxS_\vcv)$ and $\mathcal{N}(\Xi_t(\vctheta) \vcx_t + \mxD \vcu_t,\mxS_\vcw)$, for any $t=0,\ldots,\nD-1$. Therefore, due to \eqref{eqn:Q_theta_theta_k} and \eqref{eq:log-likelihood function}, for $Q(\vctheta|\hat{\vctheta}_k)$, we have
% Following the same line of arguments as in Section~\ref{sec:ML}, it can be seen that $\vcy_t|\vcx_t,\vctheta$ and $\vcx_{t+1}|\vcx_t,\vctheta$ follow Gaussian distributions, given respectively by $\mathcal{N}(\Xi_t(\vctheta) \vcx_t + \mxD \vcu_t, \mxS_\vcv)$ and $\mathcal{N}(\Xi_t(\vctheta) \vcx_t + \mxD \vcu_t, \mxS_\vcw)$ for any $t=0,\ldots,\nD-1$. Therefore, from \eqref{eqn:Q_theta_theta_k} and \eqref{eq:log-likelihood function}, it follows that for $Q(\vctheta|\hat{\vctheta}_k)$, we have
% Following the same line of arguments as in Section~\ref{sec:ML}, it can be seen that $\vcy_t|\vcx_t,\vctheta$ and $\vcx_{t+1}|\vcx_t,\vctheta$ follow Gaussian distributions, given respectively by $\mathcal{N}(\Xi_t(\vctheta) \vcx_t + \mxD \vcu_t, \mxS_\vcv)$ and $\mathcal{N}(\mxA \vcx_t + \mxB \vcu_t, \mxS_\vcw)$, for any $t=0,\ldots,\nD-1$, where $\Xi_t(\vctheta)$ is defined in \eqref{eqn:Xi_t}. Therefore, from \eqref{eqn:Q_theta_theta_k} and \eqref{eq:log-likelihood function}, it is implied that
% Following the same line of arguments as in Section~\ref{sec:ML}, it can be seen that $\vcy_t|\vcx_t,\vctheta$ and $\vcx_{t+1}|\vcx_t,\vctheta$ follow Gaussian distributions, given respectively by $\mathcal{N}(\Xi_t(\vctheta) \vcx_t + \mxD \vcu_t, \mxS_\vcv)$ and $\mathcal{N}(\mxA \vcx_t + \mxB \vcu_t, \mxS_\vcw)$, for $t=0,\ldots,\nD-1$, where $\Xi_t(\vctheta)$ is defined in \eqref{eqn:Xi_t}. 
Following the same line of arguments as in Section~\ref{sec:ML}, it can be seen that $\vcy_t|\vcx_t,\vctheta$ and $\vcx_{t+1}|\vcx_t,\vctheta$ follow Gaussian distributions, given respectively by $\mathcal{N}(\Xi_t(\vctheta) \vcx_t + \mxD \vcu_t, \mxS_\vcv)$ and $\mathcal{N}(\mxA \vcx_t + \mxB \vcu_t, \mxS_\vcw)$, for $t=0,\ldots,\nD-1$, where $\Xi_t(\vctheta)$ is defined in \eqref{eqn:Xi_t}. 
For $t=0,\ldots,\nD-1$, 
%note that 
it is worth noting that $\Xi_t$ is indeed function of matrix $\mxC$ defined as $\mxC := [\mxC_0,\, \mxC_1,\, ... \,,\,{\mxC}_{\Nu}]$, and thus, one can equivalently write $\Xi_t(\mxC)$ instead of $\Xi_t(\vctheta)$.
% For $t=0,\ldots,\nD-1$, note that $\Xi_t$ is indeed a function of the matrix $\mxC$, defined as $\mxC := [\mxC_0,\, \mxC_1,\, ... \,,\,{\mxC}_{\Nu}]$. Thus, one can equivalently  write $\Xi_t(\mxC)$ instead of $\Xi_t(\vctheta)$.
Accordingly, from \eqref{eqn:Q_theta_theta_k} and \eqref{eq:log-likelihood function}, it is implied that
\begin{equation}\label{eq:Q function}
    \begin{split}\!\!\!
        Q(\vctheta|\hat{\vctheta}_k) = &\mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
        \Big[
        -\frac{1}{2}   \logdet(\mxS_{\vcx_0}) 
        -\frac{\nD}{2} \logdet(\mxS_\vcv) 
        -\frac{\nD}{2} \logdet(\mxS_\vcw) 
        -\frac{1}{2}(\vcx_0-\vcmu_{\vcx_0})^\tr \mxS_{\vcx_0}^{-1} (\vcx_0-\vcmu_{\vcx_0})
        \\
        & \!\!\!\! \!\!\!\! 
        -\frac{1}{2} \sum_{t=0}^{\nD-1} (\vcy_t - \Xi_t(\mxC) \vcx_t - \mxD \vcu_t)^\tr \mxS_\vcv^{-1} (\vcy_t - \Xi_t(\mxC) \vcx_t - \mxD \vcu_t) 
         \\
        & \!\!\!\! \!\!\!\! 
        -\frac{1}{2} \sum_{t=0}^{\nD-1} (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t)^\tr \mxS_\vcw^{-1} (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t) 
        \Big].
    \end{split}\!\!\!\!
\end{equation}
% \begin{equation}\label{eq:Q function}
%     \begin{split}
%         Q(\vctheta|\hat{\vctheta}_k) = &\mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}\Big\{-\frac{\nD}{2}\logdet \mxS_\vcv - \frac{1}{2}\logdet\mxS_{\vcx_0} -\frac{\nD}{2}\logdet\mxS_\vcw \\
%         & \, - \frac{1}{2} \sum_{t=0}^{\nD-1} (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t)^\tr \mxS_\vcv^{-1} (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t) - \frac{1}{2}(\vcx_0-\vcmu_{\vcx_0})^\tr \mxS_{\vcx_0}^{-1} (\vcx_0-\vcmu_{\vcx_0})\\
%         &-\frac{1}{2} \sum_{t=1}^{\nD} (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t)^\tr \mxS_\vcw^{-1} (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t) \Big\}.
%     \end{split}%
% \end{equation}
% Using the property that $\vcx^\tr \mxM \vcx = \trace(\mxM \vcx \vcx^\tr)$, for any matrix $\mxM \in \Rbb^{\Nx\times\Nx}$, we can simplify $Q(\vctheta|\hat{\vctheta}_k)$ as
Note that, for any matrix $\mxR\in\Rbb^{n\times n}$ and any vector $\vcx\in\Rbb^n$, we have $\vcx^\tr\mxR\vcx = \trace(\mxR\vcx\vcx^\tr)$. 
% Using this property, for $Q(\vctheta|\hat{\vctheta}_k)$, we have that
From this property, it follows for $Q(\vctheta|\hat{\vctheta}_k)$ that
\begin{equation}\label{eq:Q function2}
    \begin{split}\!\!\!\!\!\!\!\!
        Q(\vctheta|\hat{\vctheta}_k) 
        = & \,\,
        \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
        \Big[
        -\frac{\nD}{2} \logdet(\mxS_\vcv) 
        -\frac{1}{2}   \logdet(\mxS_{\vcx_0})
        -\frac{\nD}{2} \logdet(\mxS_\vcw) 
        -\frac{1}{2}\trace\left(\mxS_{\vcx_0}^{-1}\, (\vcx_0-\vcmu_{\vcx_0}) (\vcx_0-\vcmu_{\vcx_0})^\tr\right)
        \\ &
        \qquad \qquad \qquad \qquad \qquad 
        -\frac{1}{2} \sum_{t=0}^{\nD-1} \trace\left(\mxS_\vcv^{-1} (\vcy_t - \Xi_t(\mxC) \vcx_t - \mxD \vcu_t) (\vcy_t - \Xi_t(\mxC) \vcx_t - \mxD \vcu_t)^\tr\right) 
        \\ &
        \qquad \qquad \qquad \qquad \qquad 
        -\frac{1}{2} \sum_{t=0}^{\nD-1}\trace\left(\mxS_\vcw^{-1} (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t) (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t)^\tr\right)
        \Big].
    \end{split}\!\!\!\!\!\!
\end{equation}
% Subsequently, given the linearity of trace and expectation, it follows that
% \begin{equation}\label{eq:Q function2_a}
%     \begin{split}
%         Q(\vctheta|\hat{\vctheta}_k) 
%         = &\,\,
%         -\frac{\nD}{2} \logdet(\mxS_\vcv) 
%         -\frac{1}{2}   \logdet(\mxS_{\vcx_0})
%         -\frac{\nD}{2} \logdet(\mxS_\vcw) 
%         -\frac{1}{2}
%         \trace\big(\mxS_{\vcx_0}^{-1}\, \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}\left[(\vcx_0-\vcmu_{\vcx_0}) (\vcx_0-\vcmu_{\vcx_0})^\tr\right]\big)
%         \\ & \quad
%         -\frac{1}{2} \trace\left(\mxS_\vcv^{-1}\, 
%         \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
%         \left[
%         \sum_{t=0}^{\nD-1}  (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t) (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t)^\tr\right]\right) 
%         \\ & \quad
%         -\frac{1}{2} \trace\left(\mxS_\vcw^{-1}\,        
%         \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
%         \left[
%         \sum_{t=1}^{\nD}(\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t) (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t)^\tr\right]\right).
%     \end{split}
% \end{equation}
% \begin{equation}\label{eq:Q function2_a}
%     \begin{split}
%         Q(\vctheta|\hat{\vctheta}_k) 
%         = &\,\,
%         -\frac{\nD}{2} \logdet(\mxS_\vcv) 
%         -\frac{1}{2}   \logdet(\mxS_{\vcx_0})
%         -\frac{\nD}{2} \logdet(\mxS_\vcw) 
%         -\frac{1}{2}
%         \trace\big(\mxS_{\vcx_0}^{-1}\, \cmr{\mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}\left[(\vcx_0-\vcmu_{\vcx_0}) (\vcx_0-\vcmu_{\vcx_0})^\tr\right]}\big)
%         \\ & \quad
%         -\frac{1}{2} \trace\left(\mxS_\vcv^{-1}\, 
%         \cmr{\mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
%         \left[
%         \sum_{t=0}^{\nD-1}  (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t) (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t)^\tr\right]}\right) 
%         \\ & \quad
%         -\frac{1}{2} \trace\left(\mxS_\vcw^{-1}\,        
%         \cmr{\mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
%         \left[
%         \sum_{t=1}^{\nD}(\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t) (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t)^\tr\right]}\right).
%     \end{split}
% \end{equation}
To simplify the notation, let the matrices $\mxM$ and $\mxN$ be defined as $\mxM := [\mxA,\, \mxB]$ and $\mxN := [\mxC, \, \mxD]$, respectively. 
% Furthermore, we define matrix-valued functions 
% $\mxF_k:\Rbb^{\Nx}\to\Sbb^{\Nx\times\Nx}$,
% $\mxG_k:\Rbb^{\Ny\times\Nx} \times \cdots \times \Rbb^{\Ny\times\Nx} \times \Rbb^{\Ny\times\Nu}\to\Sbb^{\Ny\times\Ny}$, and
% $\mxH_k:\Rbb^{\Nx\times\Nx} \times \Rbb^{\Nx\times\Nu} \to\Sbb^{\Nx\times\Nx}$ respectively as
Furthermore, we define matrix-valued functions 
$\mxF_k:\Rbb^{\Nx}\to\Sbb^{\Nx\times\Nx}$,
$\mxG_k: \Rbb^{\Ny \times (\Nu + \Nx + \Nx\Nu)} \to\Sbb^{\Ny\times\Ny}$, and
$\mxH_k: \Rbb^{\Nx \times (\Nx + \Nu)} \to\Sbb^{\Nx\times\Nx}$ respectively as
% \begin{equation}
%     \begin{split}
%         \mxF_k(\mu_{\vcx_0}) &:= \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})} \left[(\vcx_0-\vcmu_{\vcx_0}) (\vcx_0-\vcmu_{\vcx_0})^\tr\right],\\
%         %%
%         \mxG_k(\mxN) &:= \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
%         \left[
%         \sum_{t=0}^{\nD-1}  (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t) (\vcy_t - \Xi_t(\vctheta) \vcx_t - \mxD \vcu_t)^\tr\right],\\
%         %%
%         \mxH_k(\mxM) &:= \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
%         \left[
%         \sum_{t=0}^{\nD-1}(\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t) (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t)^\tr\right].\\
%     \end{split}
% \end{equation}
\begin{align}
        \mxF_k(\mu_{\vcx_0})\!\, &:= \,
        \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})} \left[(\vcx_0-\vcmu_{\vcx_0}) (\vcx_0-\vcmu_{\vcx_0})^\tr\right], \label{eq:F_k}\\
        %%
        \mxG_k(\mxN)\, &:= \,
        \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
        \left[
        \sum_{t=0}^{\nD-1}  (\vcy_t - \Xi_t(\mxC) \vcx_t - \mxD \vcu_t) (\vcy_t - \Xi_t(\mxC) \vcx_t - \mxD \vcu_t)^\tr\right],\label{eq:G_k}
\end{align}
and, 
\begin{align}
    \mxH_k(\mxM) &:= \mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})}
    \left[
    \sum_{t=0}^{\nD-1}(\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t) (\vcx_{t+1} - \mxA \vcx_t - \mxB \vcu_t)^\tr\right],\label{eq:H_k}
\end{align}
for any 
% $\mu_{\vcx_0} \in \Rbb^{\Nx}$,
% $\mxN \in \Rbb^{\Ny\times\Nx} \times \cdots \times \Rbb^{\Ny\times\Nx} \times \Rbb^{\Ny\times\Nu}$, 
% and
% $\mxM \in \Rbb^{\Nx\times\Nx} \times \Rbb^{\Nx\times\Nu}$.
$\mu_{\vcx_0} \in \Rbb^{\Nx}$, 
$\mxM \in \Rbb^{\Nx \times (\Nx + \Nu)}$, and $\mxN \in \Rbb^{\Ny \times (\Nu + \Nx + \Nx\Nu)}$.
Additionally, for $k \in \Nbb$, let the function $J_k: \Vbb \to \extendedR$ be defined as 
\begin{equation}\label{eq:J function}
    J_k(\vctheta) := 
        \frac{\nD}{2} \logdet(\mxS_\vcv) 
        +\frac{1}{2}   \logdet(\mxS_{\vcx_0})
        +\frac{\nD}{2} \logdet(\mxS_\vcw) 
        +\frac{1}{2} \trace \left(\mxS_{\vcx_0}^{-1}\, \mxF_k(\mu_{\vcx_0}) \right)
        +\frac{1}{2} \trace \left(\mxS_\vcv^{-1}\, \mxG_k(\mxN)\right) 
        +\frac{1}{2} \trace \left(\mxS_\vcw^{-1}\, \mxH_k(\mxM)\right),
\end{equation}
for any $\theta\in\Vbb$.
According to the linearity of trace and expectation, it follows from \eqref{eq:Q function2} that
% \begin{equation}\label{eq:J function}
%     J_k(\vctheta) := -Q(\vctheta|\hat{\vctheta}_k),
% \end{equation}
$J_k(\vctheta) := -Q(\vctheta|\hat{\vctheta}_k)$,
for any $\theta\in\Theta$.
Thus, one can see that the EM iterative generation of the sequence of parameter estimation, as formulated through the optimization problem \eqref{eq:EM optimization}, is equivalent to
\begin{equation}\label{eq:EM optimization J_k}
\begin{split}
    \hat{\vctheta}_{k+1}
    &=
    \argminOp_{\vctheta \in \Theta}\,
    J_k(\vctheta),\\
    % \text{s.t.}
    % \qquad
    % &\hat{\mxS}_{\vcw,k+1},\hat{\mxS}_{\vcv,k+1},\hat{\mxS}_{\vcx_0,k+1} \succ 0.
\end{split}
\end{equation}
for $k \in \Nbb$. 
To proceed further and elaborate on the properties of the introduced functions and the optimization problem \eqref{eq:EM optimization J_k}, suitable assumptions are required.

\begin{assumption}\label{assum:input}
For the input sequence     
$\vcu_0,\vcu_1,\ldots,\vcu_{\nsmD-1}$, we have 
% \begin{equation}
%         \sum_{t=0}^{\nD-1}
%         \begin{bmatrix} 1\\\vcu_t \end{bmatrix}
%         \begin{bmatrix} 1\\\vcu_t \end{bmatrix}^\tr
%         \succ 0.
% \end{equation}
\begin{equation} \label{eqn:rank_1_u_i_s}
    \rank\left(
    \begin{bmatrix} 
    1       & 1      & \cdots & 1 \\
    \vcu_0  & \vcu_1 & \cdots & \vcu_{\nsmD-1}
    \end{bmatrix}
    \right) = \Nu+1.
\end{equation}
\end{assumption}

\begin{remark}
    Assumption~\ref{assum:input} is equivalent to the property that the variation of input sequence spans $\Rbb^{\Nu}$. More precisely, \eqref{eqn:rank_1_u_i_s} holds if and only if
    \begin{equation}
        \Rbb^{\Nu}
        =
        \linspan
        \big\{
        \vcu_1 - \vcu_0,
        \vcu_2 - \vcu_1, 
        \ldots,
        \vcu_{\nsmD-1} - \vcu_{\nsmD-2}
        \big\}.
    \end{equation}
    Accordingly, Assumption~\ref{assum:input} can be interpreted as a weak form of persistent excitation for the input sequence 
    $\vcu_0\!,\!\ldots\!,\!\vcu_{\nsmD-1}$.
\end{remark}

% \begin{assumption}\label{assum:output}
% % Assume the output sequence satisfies the following equation
% % \begin{equation}
% %     \sum_{t=0}^{\nD-1} \vcy_t\vcy_t^\tr \succ 0.
% % \end{equation}
% For the output measurements    
% $\vcy_0,\vcy_1,\ldots,\vcy_{\nsmD-1}$, 
% we have 
% \begin{equation} \label{eqn:rank_y_i_s}
%     \rank\left(
%     \begin{bmatrix} 
%     \vcy_0  & \vcy_1 & \cdots & \vcy_{\nsmD-1}
%     \end{bmatrix}
%     \right) = \Ny.
% \end{equation}
% \end{assumption}

% \begin{remark}
% % The Assumption~\ref{assum:output} is equivalent to the property that $\vcy_0,\vcy_1,\ldots,\vcy_{\nsmD-1}$ spans $\Rbb^{\Ny}$, which means that the output measurement data is non-degenerate. Note that, since the support of output measurement noise is $\Rbb^{\Ny}$, one can expect that \eqref{eqn:rank_y_i_s} holds with probability one.
% % Assumption~\ref{assum:output} is equivalent to the condition that $\vcy_0, \vcy_1, \ldots, \vcy_{\nsmD-1}$ span $\Rbb^{\Ny}$, implying that the output measurement data is non-degenerate. Observe that since the support of the output measurement noise is $\Rbb^{\Ny}$, the condition \eqref{eqn:rank_y_i_s} is expected to hold with probability one.
% Assumption~\ref{assum:output} is equivalent to the condition that $\vcy_0, \vcy_1, \ldots, \vcy_{\nsmD-1}$ span $\Rbb^{\Ny}$, implying that the output measurement data is non-degenerate. Note that, since the support of output measurement noise is $\Rbb^{\Ny}$, one can expect that \eqref{eqn:rank_y_i_s} holds with probability one.
% \end{remark}

\begin{assumption}\label{assum:output}
% Assume the output sequence satisfies the following equation
% \begin{equation}
%     \sum_{t=0}^{\nD-1} \vcy_t\vcy_t^\tr \succ 0.
% \end{equation}
For the output measurements    
$\vcy_0,\vcy_1,\ldots,\vcy_{\nsmD-1}$, 
we have 
\begin{equation} \label{eqn:rank_y_i_s}
    \rank\left(
    \begin{bmatrix} 
    \vcu_0  & \vcu_1 & \cdots & \vcu_{\nsmD-1}\\
    \vcy_0  & \vcy_1 & \cdots & \vcy_{\nsmD-1}
    \end{bmatrix}
    \right) = \Nu + \Ny.
\end{equation}
\end{assumption}

\begin{remark}
% The Assumption~\ref{assum:output} is equivalent to the property that $\vcy_0,\vcy_1,\ldots,\vcy_{\nsmD-1}$ spans $\Rbb^{\Ny}$, which means that the output measurement data is non-degenerate. Note that, since the support of output measurement noise is $\Rbb^{\Ny}$, one can expect that \eqref{eqn:rank_y_i_s} holds with probability one.
% Assumption~\ref{assum:output} is equivalent to the condition that $\vcy_0, \vcy_1, \ldots, \vcy_{\nsmD-1}$ span $\Rbb^{\Ny}$, implying that the output measurement data is non-degenerate. Observe that since the support of the output measurement noise is $\Rbb^{\Ny}$, the condition \eqref{eqn:rank_y_i_s} is expected to hold with probability one.
Assumption~\ref{assum:output} is equivalent to the condition that $[\vcu_0^\tr, \vcy_0^\tr]^\tr, [\vcu_1^\tr, \vcy_1^\tr]^\tr, \ldots, [\vcu_\nsmD^\tr, \vcy_\nsmD^\tr]^\tr$ span $\Rbb^{\Nu+\Ny}$.
\end{remark}

\begin{proposition}\label{pro: PD for expectation}
    Under Assumption~\ref{assum:input} and \ref{assum:output}, the matrices $\mxF_k(\mu_{\vcx_0})$, $\mxG_k(\mxN)$, and $\mxH_k(\mxM)$ are positive definite for any $\mu_{\vcx_0} \in \Rbb^{\Nx}, \mxM \in \Rbb^{\Nx \times (\Nx + \Nu)}$, and $\mxN \in \Rbb^{\Ny \times (\Nu + \Nx + \Nx\Nu)}$.
\end{proposition}
\begin{proof}
    The proof is provided in Appendix~\ref{app:proof PD of Expectation}.
\end{proof}
% Note that 
% For the ease of discussion, we assume $\mxD = 0$ in the remainder of this section. Furthermore, we define matrices $\mxM$ and $\mxC$ as $\mxM := [\mxA,\, \mxB]$ and $\mxC := [\mxC_0,\, \mxC_1,\, ... \,,\,{\mxC}_{\Nu}]$, respectively. For $k\in\Nbb$, let function $J_k:\Theta\to \Rbb$ be defined as 
% For the ease of discussion, we assume $\mxD = 0$ in the remainder of this section. Furthermore, we define the matrices $\mxM$ and $\mxC$ as $\mxM := [\mxA,\, \mxB]$ and $\mxC := [\mxC_0,\, \mxC_1,\, ... \,,\,{\mxC}_{\Nu}]$, respectively. 
% Additionally, for $k \in \Nbb$, let the function $J_k: \Vbb \to \Rbb$ be defined as 
% \begin{equation}\label{eq:J function}
%     J_k(\vctheta) := -Q(\vctheta|\hat{\vctheta}_k),
% \end{equation}
% for any $\theta\in\Vbb$.
% For $k \in \Nbb$, let the function $J_k: \Vbb \to \Rbb$ be defined as 
% \begin{equation}\label{eq:J function}
%     J_k(\vctheta) := 
%         \frac{\nD}{2} \logdet(\mxS_\vcv) 
%         +\frac{1}{2}   \logdet(\mxS_{\vcx_0})
%         +\frac{\nD}{2} \logdet(\mxS_\vcw) 
%         +\frac{1}{2} \trace \left(\mxS_{\vcx_0}^{-1}\, \mxF_k(\mu_{\vcx_0}) \right)
%         +\frac{1}{2} \trace \left(\mxS_\vcv^{-1}\, \mxG_k(\mxN)\right) 
%         +\frac{1}{2} \trace \left(\mxS_\vcw^{-1}\, \mxH_k(\mxM)\right),
% \end{equation}
% for any $\theta\in\Vbb$.
% According to the linearity of trace and expectation, it follows that
% \begin{equation}\label{eq:J function}
%     J_k(\vctheta) := -Q(\vctheta|\hat{\vctheta}_k),
% \end{equation}
% for any $\theta\in\Theta$.
% One can see that the EM iterative generation of the sequence of parameter estimations performed through the optimization problem \eqref{eq:EM optimization} is equivalent to
% One can see that EM iterative process of parameter estimation, as formulated through the optimization problem \eqref{eq:EM optimization}, is equivalent to establishing that
% Thus, one can see that the EM iterative generation of the sequence of parameter estimation, as formulated through the optimization problem \eqref{eq:EM optimization}, is equivalent to
% \begin{equation}\label{eq:EM optimization J_k}
% \begin{split}
%     \hat{\vctheta}_{k+1}
%     &=
%     \argminOp_{\vctheta \in \Theta}\,
%     J_k(\vctheta),\\
%     % \text{s.t.}
%     % \qquad
%     % &\hat{\mxS}_{\vcw,k+1},\hat{\mxS}_{\vcv,k+1},\hat{\mxS}_{\vcx_0,k+1} \succ 0.
% \end{split}
% \end{equation}
% for $k \in \Nbb$. 
% Before
% \begin{assumption}\label{assum:input}
% For the input sequence     
% $\vcu_0,\vcu_1,\ldots,\vcu_{\nsmD-1}$, we have 
% % \begin{equation}
% %         \sum_{t=0}^{\nD-1}
% %         \begin{bmatrix} 1\\\vcu_t \end{bmatrix}
% %         \begin{bmatrix} 1\\\vcu_t \end{bmatrix}^\tr
% %         \succ 0.
% % \end{equation}
% \begin{equation} \label{eqn:rank_1_u_i_s}
%     \rank\left(
%     \begin{bmatrix} 
%     1       & 1      & \cdots & 1 \\
%     \vcu_0  & \vcu_1 & \cdots & \vcu_{\nsmD-1}
%     \end{bmatrix}
%     \right) = \Nu+1.
% \end{equation}
% \end{assumption}

% \begin{remark}
%     Assumption~\ref{assum:input} is equivalent to the property that the variation of input sequence spans $\Rbb^{\Nu}$. More precisely, \eqref{eqn:rank_1_u_i_s} holds if and only if
%     \begin{equation}
%         \Rbb^{\Nu}
%         =
%         \linspan
%         \big\{
%         \vcu_1 - \vcu_0,
%         \vcu_2 - \vcu_1, 
%         \ldots,
%         \vcu_{\nsmD-1} - \vcu_{\nsmD-2}
%         \big\}.
%     \end{equation}
%     Accordingly, Assumption~\ref{assum:input} can be interpreted as a weak form of persistent excitation for the input sequence 
%     $\vcu_0,\vcu_1,\ldots,\vcu_{\nsmD-1}$.
% \end{remark}
% Through the next propositions, we show that \eqref{eq:EM optimization J_k} is well-define by demonstrating the existence and uniqueness of solution.
Through the next propositions, we show that \eqref{eq:EM optimization J_k} is well-defined by demonstrating the existence and uniqueness of its solution. 
\begin{proposition}[Stationary Point Uniqueness]\label{pro:local minimum}
% Under Assumption~\ref{assum:input}, the system of equations $\nabla J_k(\vctheta) = 0$ has a unique solution in $\Theta$, which can be expressed in closed form as 
% Let Assumption~\ref{assum:input} hold. Then, $J_k$ has a unique stationary point in $\Theta$, i.e., the system of equations $\nabla J_k(\vctheta) = 0$ has a unique solution in $\Theta$, which can be expressed in closed form as 
Let Assumption~\ref{assum:input} hold. Then, $J_k$ has a \emph{unique stationary point} in $\Theta$, meaning the system of equations $\nabla J_k(\vctheta) = 0$ admits a unique solution in $\Theta$, which can be expressed in closed form as 
% \begin{align} 
%         \hat{\mxM}_{k+1} =& \sum_{t=1}^{\nD} (\begin{bmatrix} \hat{\vcx}_{t+1|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t+1|{\nD}}\mxL_t^\tr & \hat{\vcx}_{t+1|\nD}\vcu_t^\tr  \end{bmatrix} \begin{bmatrix}\hat{\vcx}_{t|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD}  &\hat{\vcx}_{t|\nD}\vcu_t^\tr 
%         \\ \vcu_t\hat{\vcx}_{t|\nD}^\tr &\vcu_t \vcu_t^\tr \end{bmatrix}^{-1}), 
%         %\nonumber
%         \label{eq: closed form M}
%         \\
%         \hat{\mxC}_{k+1}   =&\,\, \sum_{t=0}^{\nD-1} \vcy_t (\begin{bmatrix}1\\ \vcu_t \end{bmatrix} \otimes \hat{\vcx}_{t|\nD})^\tr
%         \left(\sum_{t=0}^{\nD-1} \begin{bmatrix}1\\ \vcu_t \end{bmatrix} \begin{bmatrix}1\\ \vcu_t \end{bmatrix}^\tr \otimes (\hat{\vcx}_{t|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD})\right)^{-1}, 
%         %\nonumber
%         \label{eq: closed form C}
%         \\
%         \hat{\mxS}_{\vcw,k+1}   =&\,\, \frac{1}{\nD}\sum_{t=0}^{\nD-1} (\hat{\vcx}_{t+1|\nD}\hat{\vcx}_{t+1|\nD}^\tr + \mxP_{t+1|\nD}) - \frac{1}{\nD}\sum_{t=0}^{\nD-1} \begin{bmatrix}\hat{\vcx}_{t+1|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t+1|\nD}\mxL_t^\tr &\,\, \hat{\vcx}_{t+1|\nD} \vcu_t^\tr  \end{bmatrix} 
%         \nonumber
%         \\
%         &
%         \qquad
%         \left(\sum_{t=0}^{\nD-1} \begin{bmatrix}\hat{\vcx}_{t|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD} & \hat{\vcx}_{t|\nD}\vcu_t^\tr\\ \vcu_t\hat{\vcx}_{t|\nD}^\tr &\vcu_t \vcu_t^\tr\end{bmatrix}\right)^{-1}
%         \sum_{t=0}^{\nD-1}\begin{bmatrix}\hat{\vcx}_{t+1|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t+1|\nD}\mxH_t^\tr &\, \,\hat{\vcx}_{t+1|\nD} \vcu_t^\tr  \end{bmatrix}^\tr, 
%         %\nonumber
%         \label{eq: closed form Sw}
%         \\
%         \hat{\mxS}_{\vcv,k+1}   =&\,\, \frac{1}{\nD}\sum_{t=0}^{\nD-1} \vcy_t  \vcy_t^\tr - \frac{1}{\nD}  \sum_{t=0}^{\nD-1} \vcy_t(\begin{bmatrix}1\\ \vcu_t \end{bmatrix} \otimes \hat{\vcx}_{t|\nD})^\tr 
%         \nonumber
%         \\
%         &\Big(\sum_{t=0}^{\nD-1} \begin{bmatrix}1\\ \vcu_t \end{bmatrix} \begin{bmatrix}1\\ \vcu_t \end{bmatrix}^\tr \otimes (\hat{\vcx}_{t|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD})\Big)^{-1}\sum_{t=0}^{\nD-1} (\begin{bmatrix}1\\ \vcu_t \end{bmatrix} \otimes \hat{\vcx}_{t|\nD}) \vcy_t^\tr, 
%         %\nonumber
%         \label{eq: closed form Sv}\\
%         \hat{\vcmu}_{x_0,k+1}   =&\,\, \hat{\vcx}_{0|\nD}, 
%         %\nonumber
%         \label{eq: closed form mux0}\\
%         \hat{\mxS}_{\vcx_0,k+1}   =&\,\, \mxP_{0|\nD}. \label{eq: closed form Sx0} 
% \end{align}
\begin{align} 
        \hat{\mxM}_{k+1} =&  \sum_{t=0}^{\nD-1} \begin{bmatrix} \hat{\vcx}_{t+1|{\nD}}\hat{\vcx}_{t|{\nD}}^\tr + \mxP_{t+1|{\nD}}\mxL_t^\tr & \quad \hat{\vcx}_{t+1|\nD}\vcu_t^\tr  \end{bmatrix} 
        \left(\sum_{t=0}^{\nD-1} \begin{bmatrix}\hat{\vcx}_{t|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD}  &\hat{\vcx}_{t|\nD}\vcu_t^\tr 
        \\ \vcu_t\hat{\vcx}_{t|\nD}^\tr &\vcu_t \vcu_t^\tr \end{bmatrix}\right)^{-1}, 
        %\nonumber
        \label{eq: closed form M}
        \\
        \hat{\mxN}_{k+1}   =&\,\, \sum_{t=0}^{\nD-1} \vcy_t \begin{bmatrix} 
        \hat{\vcx}_{t|\nD}\\ \vcu_t \otimes \hat{\vcx}_{t|\nD} \\ \vcu_t\end{bmatrix}^\tr
        \left(\sum_{t=0}^{\nD-1}
        \begin{bmatrix} 
        %%row 1 column1
        \hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD} 
        %%row 1 column2
        & \vcu_t^\tr \otimes \left(\hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD} \right) 
        %%row 1 column3
        & \hat{\vcx}_{t|\nD} \vcu_t^\tr \\ 
        %%row 2 column1
        \vcu_t \otimes \left(\hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr +    \mxP_{t|\nD} \right)
        %%row 2 column2
        & \vcu_t \vcu_t^\tr \otimes \left(\hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr     + \mxP_{t|\nD} \right)
        %%row 2 column3
        & \vcu_t\vcu_t^\tr \otimes \hat{\vcx}_{t|\nD}\\
        %%row 3 column1
        \vcu_t \hat{\vcx}_{t|\nD}^\tr 
        %%row 3 column2
        & \vcu_t \vcu_t^\tr \otimes \hat{\vcx}_{t|\nD}^\tr
        %%row 3 column3
        & \vcu_t \vcu_t^\tr 
        \end{bmatrix}\right)^{-1}\!\!\!\!\!\!, 
        %\nonumber
        \label{eq: closed form C}
        \\
        \hat{\mxS}_{\vcw,k+1}   =&\,\, \frac{1}{\nD}\sum_{t=0}^{\nD-1} (\hat{\vcx}_{t+1|\nD}\hat{\vcx}_{t+1|\nD}^\tr + \mxP_{t+1|\nD}) - \frac{1}{\nD}\sum_{t=0}^{\nD-1} \begin{bmatrix}\hat{\vcx}_{t+1|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t+1|\nD}\mxL_t^\tr &\,\, \hat{\vcx}_{t+1|\nD} \vcu_t^\tr  \end{bmatrix} 
        \nonumber
        \\
        &
        \qquad
        \left(\sum_{t=0}^{\nD-1} \begin{bmatrix}\hat{\vcx}_{t|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD} & \hat{\vcx}_{t|\nD}\vcu_t^\tr\\ \vcu_t\hat{\vcx}_{t|\nD}^\tr &\vcu_t \vcu_t^\tr\end{bmatrix}\right)^{-1}
        \sum_{t=0}^{\nD-1}\begin{bmatrix}\hat{\vcx}_{t+1|\nD}\hat{\vcx}_{t|\nD}^\tr + \mxP_{t+1|\nD}\mxH_t^\tr &\, \,\hat{\vcx}_{t+1|\nD} \vcu_t^\tr  \end{bmatrix}^\tr, 
        %\nonumber
        \label{eq: closed form Sw}
        \\
        \hat{\mxS}_{\vcv,k+1}   =&\,\, \frac{1}{\nD}\sum_{t=0}^{\nD-1} \vcy_t  \vcy_t^\tr - \frac{1}{\nD}  \sum_{t=0}^{\nD-1} \vcy_t\begin{bmatrix} 
        \hat{\vcx}_{t|\nD}\\ \vcu_t \otimes \hat{\vcx}_{t|\nD} \\ \vcu_t\end{bmatrix}^\tr 
        \nonumber
        \\
        &\left(\sum_{t=0}^{\nD-1}
        \begin{bmatrix} 
        %%row 1 column1
        \hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD} 
        %%row 1 column2
        & \vcu_t^\tr \otimes \left(\hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr + \mxP_{t|\nD} \right) 
        %%row 1 column3
        & \hat{\vcx}_{t|\nD} \vcu_t^\tr \\ 
        %%row 2 column1
        \vcu_t \otimes \left(\hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr +    \mxP_{t|\nD} \right)
        %%row 2 column2
        & \vcu_t \vcu_t^\tr \otimes \left(\hat{\vcx}_{t|\nD} \hat{\vcx}_{t|\nD}^\tr     + \mxP_{t|\nD} \right)
        %%row 2 column3
        & \vcu_t\vcu_t^\tr \otimes \hat{\vcx}_{t|\nD}\\
        %%row 3 column1
        \vcu_t \hat{\vcx}_{t|\nD}^\tr 
        %%row 3 column2
        & \vcu_t \vcu_t^\tr \otimes \hat{\vcx}_{t|\nD}^\tr
        %%row 3 column3
        & \vcu_t \vcu_t^\tr 
        \end{bmatrix}\right)^{-1}
        \sum_{t=0}^{\nD-1} \begin{bmatrix} 
        \hat{\vcx}_{t|\nD}\\ \vcu_t \otimes \hat{\vcx}_{t|\nD} \\ \vcu_t\end{bmatrix} \vcy_t^\tr, 
        %\nonumber
        \label{eq: closed form Sv}\\
        \hat{\vcmu}_{x_0,k+1}   =&\,\, \hat{\vcx}_{0|\nD}, 
        %\nonumber
        \label{eq: closed form mux0}\\
        \hat{\mxS}_{\vcx_0,k+1}   =&\,\, \mxP_{0|\nD}. \label{eq: closed form Sx0} 
\end{align}
\end{proposition}
\begin{proof}
    The proof is provided in Appendix~\ref{app:Stationary Point Uniqueness}.
\end{proof}

% \begin{assumption}\label{assum:output}
% % Assume the output sequence satisfies the following equation
% % \begin{equation}
% %     \sum_{t=0}^{\nD-1} \vcy_t\vcy_t^\tr \succ 0.
% % \end{equation}
% For the output measurements    
% $\vcy_0,\vcy_1,\ldots,\vcy_{\nsmD-1}$, 
% we have 
% \begin{equation} \label{eqn:rank_y_i_s}
%     \rank\left(
%     \begin{bmatrix} 
%     \vcy_0  & \vcy_1 & \cdots & \vcy_{\nsmD-1}
%     \end{bmatrix}
%     \right) = \Ny.
% \end{equation}
% \end{assumption}

% \begin{remark}
% % The Assumption~\ref{assum:output} is equivalent to the property that $\vcy_0,\vcy_1,\ldots,\vcy_{\nsmD-1}$ spans $\Rbb^{\Ny}$, which means that the output measurement data is non-degenerate. Note that, since the support of output measurement noise is $\Rbb^{\Ny}$, one can expect that \eqref{eqn:rank_y_i_s} holds with probability one.
% % Assumption~\ref{assum:output} is equivalent to the condition that $\vcy_0, \vcy_1, \ldots, \vcy_{\nsmD-1}$ span $\Rbb^{\Ny}$, implying that the output measurement data is non-degenerate. Observe that since the support of the output measurement noise is $\Rbb^{\Ny}$, the condition \eqref{eqn:rank_y_i_s} is expected to hold with probability one.
% Assumption~\ref{assum:output} is equivalent to the condition that $\vcy_0, \vcy_1, \ldots, \vcy_{\nsmD-1}$ span $\Rbb^{\Ny}$, implying that the output measurement data is non-degenerate. Note that, since the support of output measurement noise is $\Rbb^{\Ny}$, one can expect that \eqref{eqn:rank_y_i_s} holds with probability one.
% \end{remark}

\begin{corollary}\label{cor: invex function}
     The function $J_k$ is invex, that is, $J_k$ has exactly one local minima, which is the unique optimizer of $J_k$.
\end{corollary}
\begin{proof}
    The proof is provided in Appendix~\ref{app:Proof of Corollary 1}.
\end{proof}



\begin{proposition}[Recursive Feasibility]\label{pro: postive definite}
% Under Assumption~\ref{assum:input} and \ref{assum:output}, and given $\hat{\mxS}_{\vcw,0} \in \Sbb_{++}^{\Nx\times \Nx} $, $\hat{\mxS}_{\vcv,0} \in \Sbb_{++}^{\Ny\times \Ny}$ and $\hat{\mxS}_{\vcx_0,0} \in \Sbb_{++}^{\Nx\times \Nx}$, then \eqref{eq: closed form M}-\eqref{eq: closed form Sx0} is a feasible solution of optimization problem \eqref{eq:EM optimization J_k}, which implies the problem is recursive feasible.
% Let Assumption~\ref{assum:input} and Assumption~\ref{assum:output} hold, and $\hat{\mxS}_{\vcw,0} \in \Sbb_{++}^{\Nx\times \Nx} $, $\hat{\mxS}_{\vcv,0} \in \Sbb_{++}^{\Ny\times \Ny}$ and $\hat{\mxS}_{\vcx_0,0} \in \Sbb_{++}^{\Nx\times \Nx}$. Then, \eqref{eq: closed form M}-\eqref{eq: closed form Sx0} provides a feasible solution for the optimization problem \eqref{eq:EM optimization J_k}, i.e., it belongs to $\Theta$. This property implies the EM procedure admits recursive feasibility feature.
Let Assumption~\ref{assum:input} and Assumption~\ref{assum:output} hold, and suppose $\hat{\mxS}_{\vcw,0} \in \Sbb_{++}^{\Nx\times \Nx} $, $\hat{\mxS}_{\vcv,0} \in \Sbb_{++}^{\Ny\times \Ny}$, and $\hat{\mxS}_{\vcx_0,0} \in \Sbb_{++}^{\Nx\times \Nx}$. Then, \eqref{eq: closed form M}-\eqref{eq: closed form Sx0} provides a feasible solution for the optimization problem \eqref{eq:EM optimization J_k}, meaning it lies within $\Theta$. This result ensures that the EM procedure admits the \emph{recursive feasibility} property.
\end{proposition}
\begin{proof}
    The proof is provided in Appendix~\ref{app:recursive feaisbility}.
    % To show \eqref{eq: closed form M}-\eqref{eq: closed form Sx0} is a feasible solution for \eqref{eq:EM optimization J_k}, we need to prove that $\hat{\mxS}_{\vcw,k+1}$, $\hat{\mxS}_{\vcv,k+1}$ and $\hat{\mxS}_{\vcx_0,k+1}$ are positive definite matrices. Consider $\hat{\mxS}_{\vcv,k+1}$ for example. The other two terms can be proven to be positive definite in a similar way. By substituting \eqref{eq: closed form C} into \eqref{eq:G_theta|hat_theta PD 2} and comparing with \eqref{eq: closed form Sv}, we can observe that
    % \begin{equation}
    %    \hat{\mxS}_{\vcv,k+1} = \frac{1}{\nD}\mxG_k(\hat{\mxN}_{k+1}).
    % \end{equation}
    % From Proposition~\ref{pro: postive definite}, we have shown that $\mxG_k(\mxN)$ is positive definite for any $\mxN \in \Rbb^{\Ny \times (\Nu + \Nx + \Nx\Nu)}$, which implies $\hat{\mxS}_{\vcv,k+1}$ is positive definite.
\end{proof}




% \begin{remark}
%     Equation \eqref{eq: closed form M}-\eqref{eq: closed form Sx0} implies that there is an optimal parameter $\vctheta$ that allows the partial derivatives to be zero. Intuitively, if we only consider $\mxS_\vcw$ and $\mxM$ and assume $\Nx=1$, $\, J_k$ can be simplified to $\mathbb{E}_{p(\mathbf{x}|\mathbf{y},\hat{\vctheta}_k,\mathbf{u})} \frac{\nD}{2} \log \mxS_\vcw + \frac{1}{2}\sum_{t=1}^{\nD} \frac{(\vcx_{t+1}-\mxM \vcz_t)^2}{\mxS_\vcw}$. As $\,f(x) = a \log x + \frac{b}{x}, \forall a,b \in \mathbb{R}^+$ only has one minimum at $x=\frac{b}{a}$, there is only one optimal ${\mxS}_\vcw$. In addition, for any given $\mxS_\vcw$, there is also only one optimal $\mxM$. For other parameters, using a similar method, there is one local minimum which is also a global minimum for $J_k$.
% \end{remark}

The Algorithm~\ref{Al:EM ID} summarizes the EM approach introduced for the identification of linear dynamics with bilinear observation models.
\begin{algorithm}[t]
    \caption{EM Estimation Approach for Identification of Linear Dynamics with Bilinear Observation Models}\label{Al:EM ID}
    \begin{algorithmic}
        \Statex \textbf{Input:} $\Dcal$.
        \Statex \textbf{Output:} $\vctheta$.
        \State \textbf{Initial guess:} $\hat{\vctheta}_0$
        \State $k \gets 0$
        \While{$\mathbf{1}$}
            \State Current parameters estimates: $\hat{\vctheta} \gets \hat{\vctheta}_k$
            \For{$t \gets 0$ to $\nD$}
               \State Kalman Filter: \eqref{eq:kalman filter}
            \EndFor
            \For{$t \gets \nD$ to $0$}
               \State RTS smoother: \eqref{eq:mean and covariance}
            \EndFor
            \State EM approach: compute \eqref{eq: closed form M}-\eqref{eq: closed form Sx0} to find a new parameters estimates. $\hat{\vctheta}_{k+1} \gets \argminOp_{\vctheta \in \Theta} J_k(\vctheta)$.
            \If{$\lVert \hat{\vctheta}_{k+1} - \hat{\vctheta}_k \rVert< \epsilon$}
            \State break
            \Else
            \State $k \gets k+1$
            \EndIf
        \EndWhile
        \State $\vctheta \gets \hat{\vctheta}_k$
    \end{algorithmic}
    \label{alg_1}
\end{algorithm}



% \begin{equation}
%     \begin{split}
%         \hat{\mxR}_{k+1}& = \frac{1}{\nD}\sum_{t=0}^{\nD-1} y_t y_t^\tr - \frac{1}{\nD} \Bigg[ \sum_{t=0}^{\nD-1} y_t(\begin{bmatrix}1\\ u_t \end{bmatrix} \otimes \hat{x}_{t|N})^\tr \\
%         &
%         \Big(\sum_{t=0}^{\nD-1} \begin{bmatrix}1\\ u_t \end{bmatrix} \begin{bmatrix}1\\ u_t \end{bmatrix}^\tr \otimes (\hat{x}_{t|N}\hat{x}_{t|N}^\tr + \mxP_{t|N})\Big)^{-1}\\
%         &
%         \qquad\qquad\quad
%         \sum_{t=0}^{\nD-1} (\begin{bmatrix}1\\ u_t \end{bmatrix} \otimes \hat{x}_{t|N}) y_t^\tr\Bigg], \\
%     \end{split} 
% \end{equation}
