% In this paper, we focus on identifying systems described by linear time-invariant dynamics with bilinear observation models. Specifically, we consider a suitable parametric formulation of the system. Based on observed input-output data, we frame an identification problem as the estimation of parameters that we use to define the system’s mathematical model. To this end, we propose two probabilistic frameworks. The first framework uses the Maximum Likelihood (ML) approach, which finds the optimal parameter estimates by maximizing a likelihood function. The first-order approach is used to solve the optimization problem. Furthermore, to improve tractability and computational efficiency, we propose a framework using the Expectation- Maximization (EM) approach to estimate the parameters based on a designed cost function. We show that the cost function is invex and thus has a unique optimum. The closed-form solution of the optimum is given. In addition, we demonstrate the recursive feasibility of the EM procedure. The effectiveness and performance of the proposed approaches are evaluated through numerical experiments. The results demonstrate the methods’ capacity to estimate system parameters and show their potential for practical applications in scenarios with bilinear observational structures.

\section{Introduction} \label{sec:intro}
% Paragraph 1: System identification  
% Paragraph 2: System identification  via parameter estimation 
%   ---> parametric models for different class of systems, linear, nonlinear,
%        bilinear..., e.g. PEM is widely used for linear sysid  
%   ---> minimizing an empirical cost --> (regularized) sum of squares of error
%   ---> alternative--> probabilistic framework ... Bayesian approaches
%   ---> ML, MAP, and their variant
% Paragraph 3: system identification for bilinear systems
%   --> bilinear systems can be seen as a bridge between the linear systems and general nonlinear systems
%   --> or, they can be interpreted as one step extension of linear models
%   --> Also, they apear in various situations and applications like in building dynamics 
%       and (find some examples and references)
%   --> 
%
%       MAYBE we should swap par. 2 and par. 3!!!
%%
%
%
%
System identification, as originally introduced in \cite{zadeh1956identification}, is an active area of research \cite{ljung2010perspectives} that focuses on the theory and methods for data-driven modeling of dynamical systems \cite{luenberger1979dynamic}. 
This field has gained substantial attention \cite{LjungBooK2,chiuso2019system} due to the ubiquitous nature of dynamical systems in various science and technology domains such as physics, economics, biology, and engineering, and, considering the particular importance of accurate models for tasks such as prediction, monitoring, and control \cite{khansari2014learning,tang2021expectation,ferrari2012system,franco2023parameter,shastry2023system}. 
% With the vast areas of applications relying on well-defined models, numerous methodologies are developed for different categories of systems, ranging from linear dynamics to nonlinear dynamical systems, \cite{schoukens2019nonlinear,khosravi2021Koopman,khosravi2021FDI,liu2024learning}.
% With the vast areas of applications relying on precise models representing reality well, numerous methodologies are developed for different categories of systems, ranging from linear dynamics to nonlinear dynamical systems, discrete-time to continuous-time, deterministic to stochastic, and lumped-parameter systems to the distributed-parameter ones, and many other classes of systems \cite{schoukens2019nonlinear,khosravi2021Koopman,khosravi2021FDI,liu2024learning}.
% With vast areas of application relying on precise models that accurately represent reality, numerous methodologies have been developed for different categories of systems, ranging from linear to nonlinear dynamics, discrete-time to continuous-time ... a variety of methodologies have been developed to address different system categories, including linear and nonlinear dynamical systems, discrete-time and continuous-time frameworks, deterministic and stochastic models, as well as lumped-parameter and distributed-parameter systems, among many others \cite{schoukens2019nonlinear,khosravi2021Koopman,khosravi2021FDI,liu2024learning}.
With vast areas of application relying on precise models that accurately represent reality, numerous methodologies have been developed for different categories of systems, ranging from linear to nonlinear dynamics, discrete-time to continuous-time systems, deterministic to stochastic models, as well as lumped-parameter and distributed-parameter systems, and many other classes of systems \cite{schoukens2019nonlinear,sattar2022non,khosravi2021Koopman,umenberger2018maximum,khansari2017learning,liu2024learning,khosravi2021SSG}.
%
% The key role of linear dynamics in practice has led to increased research in their identification, for linear systems of various structures and types, i.e., with different features, such as stability \cite{lacy2003subspace,van2001identification,pillonetto2014kernel,maciejowski1995guaranteed},
% positivity \cite{de2002identification,khosravi2021POS,zheng2021bayesian,grussler2017identification,khosravi2020regularized},
% being compartmental \cite{benvenuti2002model},
% positive-realness \cite{goethals2003identification}, 
% passivity \cite{rodrigues2021novel,hoagg2004first,goethals2003identification}
% circulant, cascade, and parallel-cascade structure \cite{hagg2011identification,hagg2010subspace,massioni2008subspace,pillonetto2016AtomicNuclearKernel},
% internal low-complexity 
% \cite{smith2014frequency,fazel2013hankel,shah2012linear,khosravi2020low}, 
% specific frequency domain attributes \cite{khosravi2021FDI,marconato2016filter,khosravi2021SSG},
% and many other properties \cite{fujimoto2017extension,risuleo2017nonparametric,risuleo2019bayesian,everitt2018empirical}.
% The pivotal role of linear dynamics in practical applications has driven extensive research into their identification, addressing linear systems with various structures and properties. These include stability \cite{lacy2003subspace,van2001identification,pillonetto2014kernel,maciejowski1995guaranteed}, positivity \cite{de2002identification,khosravi2021POS,zheng2021bayesian,grussler2017identification,khosravi2020regularized}, compartmental characteristics \cite{benvenuti2002model}, positive-realness \cite{goethals2003identification}, and passivity \cite{rodrigues2021novel,hoagg2004first,goethals2003identification}. Additionally, research has explored circulant, cascade, and parallel-cascade structures \cite{hagg2011identification,hagg2010subspace,massioni2008subspace,pillonetto2016AtomicNuclearKernel}, internal low-complexity \cite{smith2014frequency,fazel2013hankel,shah2012linear,khosravi2020low}, specific frequency-domain attributes \cite{khosravi2021FDI,marconato2016filter,khosravi2021SSG}, and other significant properties \cite{fujimoto2017extension,risuleo2017nonparametric,risuleo2019bayesian,everitt2018empirical}.
% The pivotal role of linear dynamics in practical applications has driven extensive research into their identification, addressing linear systems with various structures and properties, including 
% The key role of linear dynamics in practice has led to increased research in the identification of linear systems of various structures and types with different features, such as
% The key role of linear dynamics in practical applications has driven extensive research into the identification problem for the linear systems of various structures and types with different features, such as
% stability
% The key role of linear dynamics in practical applications has driven extensive research into the identification problem for the linear systems of various structures and types with different features, such as
% The key role of linear dynamics in practical applications has motivated extensive research into identifying different classes of linear systems, covering various structures, types, and features, such as 
% The key role of linear dynamics in practical applications has motivated extensive research into identifying different classes of linear systems, covering various structures, types, and features, such as
% The key role of linear dynamics in practical applications has motivated extensive research into the identification problem for different classes of linear systems, covering various structures, types, and features, such as 
The key role of linear dynamics in practical applications has motivated extensive research into the identification problem for different classes of linear systems, covering various structures, types, and features, such as 
stability.
\cite{lacy2003subspace,pillonetto2014kernel}, 
%\cite{lacy2003subspace,van2001identification,pillonetto2014kernel,maciejowski1995guaranteed}, 
positivity 
\cite{khosravi2021POS,zheng2021bayesian,khosravi2020regularized},
% \cite{de2002identification, khosravi2021POS,zheng2021bayesian,grussler2017identification,khosravi2020regularized}, 
being compartmental 
\cite{benvenuti2002model}, 
positive-realness 
\cite{goethals2003identification}, 
passivity 
\cite{rodrigues2021novel},
%\cite{rodrigues2021novel,hoagg2004first,goethals2003identification},
% admitting circulant, cascade, and parallel-cascade structures 
% \cite{hagg2011identification,hagg2010subspace,massioni2008subspace}, 
low internal complexity 
\cite{smith2014frequency,khosravi2020low,pillonetto2016AtomicNuclearKernel}, 
%\cite{smith2014frequency,fazel2013hankel,shah2012linear,khosravi2020low,pillonetto2016AtomicNuclearKernel}, 
specific frequency-domain attributes 
\cite{khosravi2021FDI,marconato2016filter}, 
and many other significant properties \cite{risuleo2019bayesian,everitt2018empirical}.
%
% Linear system identification techniques are often more straightforward and computationally efficient, making them suitable for systems that exhibit predominantly linear behavior \cite{aastrom1971system,orlov2003adaptive}.
% Accordingly, linear system identification techniques have advanced significantly, are often more straightforward and computationally efficient, making them suitable for systems that exhibit predominantly linear behavior \cite{aastrom1971system,orlov2003adaptive}. 
Consequently, linear system identification techniques have undergone significant advancements, often demonstrating remarkable estimation performance and computational efficiency, making them well-suited for systems exhibiting predominantly linear behavior \cite{aastrom1971system,orlov2003adaptive}.
%
% However, as many systems exhibit nonlinear or stochastic properties, the complexity of real-world systems presents a significant challenge in accurately capturing their behaviors. 
% However, as many real-world systems exhibit nonlinear or stochastic behaviors, the resulting complexity poses significant challenges in accurately capturing their properties in the model. 
However, since many real-world systems exhibit nonlinear, stochastic, or generally complex behaviors, the resulting complexity presents significant challenges in accurately capturing their properties in the model.
% To address this issue, system identification utilized various advanced tools and techniques in statistics and optimization theory. These tools include parametric approaches, which assume a specific structure for the model and estimate the parameters within this structure \cite{astrom1979maximum,bremaud2012introduction,little2019statistical}, and non-parametric estimation techniques, which make fewer structural assumptions and rely more heavily on the data \cite{khosravi2022Lut,khosravi2021SSG,zorzi2022nonparametric}.
%
% To address this issue,  various advanced tools and techniques in statistics and optimization theory are utilized in system identification, to propose suitable parametric and nonparametric approaches. The non-parametric estimation techniques, which make fewer structural assumptions and rely more heavily on the data \cite{khosravi2022Lut,khosravi2021SSG,zorzi2022nonparametric}, are more suitable for the case where the system structure is less known. Meanwhile, parametric approaches \cite{astrom1979maximum,bremaud2012introduction,little2019statistical}, which assume a specific structure for the model, can be particularly useful when a suitable structure for the system is given.
%
% To address this issue, system identification employs various advanced tools and techniques from statistics and optimization theory. These methods encompass both parametric and nonparametric approaches. Nonparametric estimation techniques, which make fewer structural assumptions and rely more heavily on data, are generally more suitable for systems with unknown structures. In contrast, parametric approaches, which assume a specific model structure, can be particularly effective when prior knowledge about the system structure is available.
%
% To address this issue, various advanced tools and techniques from statistics and optimization theory are employed in system identification to propose suitable parametric and nonparametric approaches. Nonparametric estimation techniques, which make fewer structural assumptions and rely more heavily on the data, are particularly suitable when the system structure is less known. In contrast, parametric approaches, which assume a specific model structure, are especially useful when a suitable structure for the system is known.
%
% To address this issue, system identification employs various advanced tools and techniques from statistics and optimization theory. These methods encompass both parametric and nonparametric approaches. Nonparametric estimation techniques, which make fewer structural assumptions and rely more heavily on data, are generally more suitable for systems with unknown structures. In contrast, parametric approaches, which assume a specific model structure, can be particularly effective when prior knowledge about the system structure is available.
% 
% To address this issue, various advanced tools and techniques from statistics and optimization theory are employed in nonlinear system identification to propose suitable parametric and nonparametric approaches. Nonparametric estimation techniques, which make fewer structural assumptions and rely more heavily on the data, are particularly suitable when the system structure is less known. In contrast, parametric approaches are particularly useful when an appropriate specific structure for the system is known.
% 
% To address this issue, various advanced tools and techniques from statistics and optimization theory are applied in nonlinear system identification to propose parametric and nonparametric approaches. Nonparametric estimation techniques, which make fewer structural assumptions and rely more heavily on the data, are especially suitable when the system structure is less understood. In contrast, parametric approaches are particularly useful when a well-defined specific appropriate structure for the system is known.
% 
% To address this issue, advanced tools and techniques from statistics and optimization theory are employed in nonlinear system identification, proposing both parametric and nonparametric approaches. Nonparametric estimation techniques, which make fewer structural assumptions and rely more heavily on the data, are particularly suited for situations where the system structure is not well understood. In contrast, parametric approaches are valuable when a well-defined and appropriate structure for the system is known, which is often the case in various real-world scenarios.
% 
% To address this issue, various advanced tools and techniques from statistics and optimization theory are applied in nonlinear system identification to propose parametric and nonparametric approaches. Nonparametric estimation techniques, which make fewer structural assumptions and rely more heavily on the data, are especially suitable when the system structure is less understood. In contrast, parametric approaches are particularly useful when a well-defined and appropriate specific structure for the system is known, which is often the case in various real-world scenarios.
% 
To address this issue, various advanced tools and techniques from statistics and optimization theory are employed in linear and nonlinear system identification, leading to the development of parametric and nonparametric approaches. Nonparametric estimation techniques \cite{khosravi2022Lut,zorzi2022nonparametric,khosravi2021ROA,khosravi2021grad}, which impose fewer structural assumptions and rely more significantly on the data, are particularly well-suited when the system structure is less known. In contrast, parametric approaches are especially useful when a specific well-defined and appropriate structure for the system is given, which is often the case in many real-world scenarios \cite{astrom1979maximum,bremaud2012introduction,little2019statistical}.









% One of the common approaches in system identification is parametric system identification, which assumes a specific parametric form for the system dynamics. By selecting appropriate parameters, these parametric models accurately predict the behaviour of real systems. Various classes of parametric models and system identification methods are studied across different types of systems. For example, for linear systems, the prediction error method (PEM) \cite{astrom1979maximum} is widely used, which adjusts the parameters iteratively to minimize the difference between the predicted output from the model and the actual output from the real system. 
% Parametric system identification is a common method that considers a rich class of models with specific structures, and subsequently, the parameters characterizing the model are estimated using measurement data. In this context, various classes of parametric models and a broad range of systems are considered, and different parameter estimation methods are employed. For example, the prediction error method (PEM) \cite{astrom1979maximum}  is widely used in identification of linear time-invariant systems, which adjusts the parameters iteratively to minimize the norm of the losses, evaluated based on the difference between the model's predicted output and the actual output from the real system. 
% Parametric system identification is a widely/ an extensively used approach, which assumes a rich class of models with specific structure for the mathematical representation/description of the system, and then estimates the parameters that characterize these models using measurement data. 
% In this context, a broad range of systems that can be described by a mathematical model in a specific form are considered. 
% Thus, it can be applied to a broad range of systems with such parametric mathematical model representation. 
% Accordingly, it can be applied to a broad range of systems of various natures, when such parametric mathematical description is available. 
%that can be described by a mathematical model in a specific form are considered. 
% In parametric system identification, the structure of the model is defined by a set of parameters that must be tuned to best represent the observed data.
% Hence, the main objective is to tune parameters characterizing the model best such that the resulting system best represent the observed data.
% In parametric system identification, the structure of the model is defined by a set of parameters that must be tuned to best represent the observed data.
%
% Parametric system identification is a widely used approach, which assumes a rich class of models with specific structure for the mathematical description of the system, and then estimates the parameters that characterize these models using measurement data. In this context, a broad range of systems that can be described by a mathematical model in a specific form are considered. Parametric system identification is a widely used approach, which assumes a rich class of models with specific structure for the mathematical description of the system, and then estimates the parameters that characterize these models using measurement data. In this context, a broad range of systems that can be described by a mathematical model in a specific form are considered.
%
% Parametric system identification is a widely employed method that presumes a sufficiently comprehensive class of models with a predefined structure to mathematically represent the system. Using measurement data, it estimates the parameters characterizing these models. This approach applies to a broad range of systems across various types and natures, as long as an appropriate parametric mathematical description is available. The primary goal is to refine the model parameters to ensure the resulting system most accurately represents the observed data.
%
% Parametric system identification is a widely used approach that assumes a sufficiently comprehensive class of models with a predefined specific structure for the mathematical representation of the system and then estimates the parameters characterizing these models using measurement data. Accordingly, it can be applied to a broad range of systems of various types and natures, provided that a suitable parametric mathematical characterization is available. The subsequent primary objective is to fine-tune the parameters of the model so that the resulting system most accurately describes the observed data.
%
Parametric system identification is an extensively used framework that assumes a sufficiently comprehensive class of models with a predefined specific structure for the mathematical representation of the system and then estimates the parameters characterizing these models using measurement data. Accordingly, it can be applied to a broad range of systems of various types and natures, provided that a suitable parametric mathematical characterization is available. The subsequent primary objective is to fine-tune the parameters of the model so that the resulting system most accurately describes the observed data.
%-----------
To this end, different parameter estimation methods are employed depending on the nature of the system and the objectives of the identification process. 
%-----------
For example, the prediction error method (PEM) \cite{astrom1979maximum}  is widely used in the identification of linear time-invariant systems, which iteratively adjusts the parameters to minimize the fitting loss, evaluated based on the difference between the output values predicted by the resulting model and the actual output from the real system.
% In addition, to estimate parameters of systems affected by noise, probabilistic frameworks are commonly utilized to improve estimation accuracy and robustness. 
Furthermore, to improve the accuracy and robustness of parameter estimation in noisy systems, probabilistic frameworks are widely employed.
Unlike deterministic methods, these approaches incorporate uncertainty into the estimation process, making them well suited for handling noisy measurement data and unmodeled system dynamics. For example, the Bayesian approach \cite{bernardo2009bayesian} treats parameters as random variables with probability distributions of specific forms. 
%These parameters are given a prior distribution, which will be updated using the information from measurements. 
% With sufficient data, the Bayesian approach obtains accurate probability distributions of the parameters of interest. This approach is particularly effective for handling noisy or limited data, making it a versatile choice in many system identification application techniques. 
% The Bayesian approach excels in providing accurate probability distributions for parameters of interest, particularly when dealing with noisy or limited data. This robustness makes it a highly versatile tool in many system identification applications.
% The Bayesian approach excels in providing accurate probability distributions for parameters of interest, particularly when dealing with noisy or limited data, and thus, making it a highly versatile choice of  technique in many system identification application. 
The Bayesian approaches exhibit remarkable performance in providing accurate probability distributions for parameters of interest, particularly when dealing with noisy or limited data, thus making it a universally applicable choice of technique in numerous system identification applications. 
%---------
% For instance, the maximum likelihood (ML) estimation \cite{rossi2018mathematical} is commonly used in system identification, aiming to find parameter values that maximize the likelihood function, which is defined as the probability of observing the given measurement data under specified parameter settings. 
% The maximum likelihood (ML) estimation approach \cite{rossi2018mathematical} is one of the most widely used Bayesian methods in system identification. It aims to determine the parameter values that maximize the likelihood function, which represents the probability of observing the given measurement data under specified parameter settings.
The maximum likelihood (ML) estimation approach \cite{rossi2018mathematical} is one of the most prominent Bayesian methods used in system identification, aiming to determine the parameter values that maximize the likelihood function, which indicates the probability of observing the given measurement data under specified parameter settings.
%---------
% In practical terms, ML estimation identifies the parameter values that make the observed data most probable, given the model. This method is particularly effective when large amounts of data are available, as it converges to the true parameter values in many cases as the dataset grows. 
% In practical terms, ML estimation approach determines the parameter values that maximize the likelihood of the observed data, given the model. As the dataset size increases, the ML estimates often converge to the true parameter values under suitable conditions
In practical terms, ML estimation approach identifies the parameter values that maximize the likelihood of the observed data under the model. As the dataset size increases, the ML estimation results often converge to the true parameter values.
%---------
% Another widely used method is maximum a posteriori (MAP) estimation \cite{gauvain1994maximum}. The MAP estimation method is similar to the ML estimation method, but instead of maximizing the likelihood function, it finds the parameter values that maximize the posterior distribution. 
% In addition to ML approaches, Maximum a Posteriori (MAP) estimation  \cite{gauvain1994maximum} is another widely used method, which incorporates knowledge into the estimation problem by assuming a prior distribution for the parameters. Unlike ML, which maximizes the likelihood function, MAP determines the parameter values that maximize the posterior distribution.
% In addition to Maximum Likelihood (ML) approaches, Maximum a Posteriori (MAP) estimation \cite{gauvain1994maximum} is another widely used method. MAP incorporates prior knowledge into the estimation problem by assuming a prior distribution for the parameters. Unlike ML, which focuses on maximizing the likelihood function, MAP identifies the parameter values that maximize the posterior distribution.
%---------
% This posterior is a product of the likelihood function and the prior distribution, which incorporates the information from prior knowledge compared to the ML estimation approach. Therefore, MAP estimation is more robust than ML estimation when an informative prior is available, especially in the cases of limited or noisy measurements. 
% The posterior distribution, which is the product of the likelihood function and the prior distribution,  incorporates the information from prior knowledge compared to the ML estimation approach. Therefore, MAP estimation is more robust than ML estimation when an informative prior is available, especially in the cases of limited or noisy measurements. 
%---------
% In addition to Maximum Likelihood (ML) approaches, Maximum a Posteriori (MAP) estimation \cite{gauvain1994maximum} is another widely used method. MAP incorporates prior knowledge into the estimation problem by assuming a prior distribution for the parameters. More precisely, the posterior distribution, which is the product of the likelihood function and the prior distribution. Unlike ML, which focuses on maximizing the likelihood function, MAP identifies the parameter values that maximize the posterior distribution. Thus, compared to the ML estimation approach
%
% Besides the ML approaches, Maximum a Posteriori (MAP) estimation \cite{gauvain1994maximum} is another widely used method when we are provided with prior knowledge to be incorporated into the estimation problem. In this regard, MAP employs a suitable prior distribution for the parameters, obtains the posterior distribution as the product of the likelihood function and the prior distribution, and then identifies the parameter values that maximize the posterior distribution. The MAP is mainly applicable when, in addition to the measurement data, we are provided with additional information about the parameters describing the system.
% 
% Aside from the ML approach, Maximum a Posteriori (MAP) estimation \cite{gauvain1994maximum} is another widely used method when we are provided with prior knowledge to be incorporated into the estimation problem. In this regard, MAP employs a suitable prior distribution for the parameters, obtains the posterior distribution as the product of the likelihood function and the prior distribution, and then identifies the parameter values that maximize the posterior distribution. The MAP is only applicable when, along with the measurement data, additional information about the parameters describing the system is given.
% 
% Aside from the ML approach, Maximum a Posteriori (MAP) estimation \cite{gauvain1994maximum} is another widely used method, particularly when prior knowledge is available for incorporation into the estimation process. MAP estimation involves selecting a suitable prior distribution for the parameters, deriving the posterior distribution by combining the likelihood function with the prior, and identifying the parameter values that maximize the obtained posterior distribution. It is essential to note that MAP can be applied only when additional information about the parameters describing the system is available alongside the measurement data.
%
Aside from the ML approach, Maximum a Posteriori (MAP) estimation \cite{gauvain1994maximum} is another widely used method, particularly when prior knowledge is available for incorporation into the estimation process. MAP estimation involves selecting a suitable prior distribution for the parameters, deriving the posterior distribution by combining the likelihood function with the prior, and identifying the parameter values that maximize the obtained posterior distribution. It is essential to note that MAP can be applied only when, along with the measurement data, additional information about the parameters describing the system is available.


In addition to linear system identification, there is a growing interest in methods for identifying nonlinear systems \cite{sattar2022non,bouvrie2017kernel,khosravi2021Koopman,umenberger2018maximum}. The identification of nonlinear systems often requires advanced techniques that can accurately model and predict their complex dynamics. One classic approach is to employ schemes based on linearization \cite{chen2004identification}, e.g.,  \cite{sharabiany2024nonlinear} presents a method to identify nonlinear systems through local linear approximations along the trajectory. Additionally, probabilistic frameworks are also commonly used in nonlinear systems identification. In \cite{wills2013identification}, the authors proposed an ML-based algorithm for Hammerstein--Wiener models, which is a serial combination of systems, 
% where a linear dynamics is followed and proceeded with two  static nonlinear blocks. 
which consist of a linear dynamic system cascaded with two  static nonlinear blocks.
%
%
Moreover, in \cite{liu2021identification}, a Bayesian approach-based method is introduced to identify Wiener--Hammerstein models, which involve a static nonlinearity between two linear dynamic systems. 
% Besides the study of general nonlinear systems, bilinear systems, as a special and bridging case of nonlinear systems, are also widely studied due to their technical tractability and relevance in various fields \cite{pardalos2010optimization}.  
% Besides the study of general nonlinear systems, bilinear systems are studied, as a special and bridging case of nonlinear systems due to their technical tractability and relevance in various fields \cite{pardalos2010optimization}.  
Among general nonlinear systems, bilinear systems are of particular interest as the bridging case between linear and nonlinear systems, and also due to their technical tractability and relevance in various fields \cite{pardalos2010optimization}.
Bilinear systems combine linear dynamics with input-dependent nonlinearities, which can be exploited in designing effective identification methods with computational tractability. For example, in \cite{verdult2001identification,verdult2005kernel}, subspace techniques are used to identify bilinear state space systems. Furthermore, in \cite{liu2020moving} and \cite{liu2022expectation}, a bilinear system in canonical form of observability is considered. In \cite{liu2020moving}, the authors proposed an approach using the Kalman filter to estimate the state of the system and a gradient-based iterative algorithm to identify the parameters of the system. In \cite{liu2022expectation}, the Rauch–Tung–Striebel smoother (RTS) is used to estimate the state variables and the expectation-maximization (EM) algorithm to identify parameters. These papers consider systems with bilinear dynamics and linear observation models. Inspired by the Wiener-Hammerstein models and Hammerstein–Wiener models, in this current work, we extend the approach to consider bilinear systems with linear dynamics and bilinear observation models. By developing identification methods for systems with bilinear observations, aiming to provide more flexible and realistic models capable of capturing interactions that standard linear or bilinear dynamics alone cannot fully describe. 
 
% In this paper, we focus on identifying systems with linear dynamics and bilinear observation models. To this end, we first propose a scheme using the ML approach. 
% % The system matrices, the initial state and the mean and covariance of the noise distributions are treated as parameters to be estimated. 
% % The system matrices, the initial state, and the noise characteristics (mean and covariance) are treated as unknown parameters to be estimated
% % The system matrices, initial state, and noise distributions, including their means and covariances, are considered unknown parameters subject to estimation.
% The system matrices, initial state, and noise distributions, including their means and covariances, are considered as unknown parameters to be estimated.
% Subsequently, a likelihood function is formulated to identify the optimal parameters that maximize the likelihood of the observed data. Following that, we develop a practical first-order method to efficiently solve the optimization problem associated with the proposed ML approach.
%
% In this paper, we focus on identifying systems with linear dynamics and bilinear observation models. We consider the system matrices, initial state, and noise distributions, including their means and covariances, as unknown parameters to be estimated. To this end, we first propose a scheme using the ML approach. Accordingly, a likelihood function is formulated to identify the optimal parameters that maximize the likelihood of the observed data. Following that, we develop a practical first-order method to efficiently solve the optimization problem associated with the proposed ML approach. Additionally, to further improve the tractability and computational efficiency, an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum} is proposed. The developed scheme consists of two iterative steps. In the first step, state estimates are obtained using the estimated parameters at the current stage. To this end, one may employ the Kalman filter \cite{kalman1960new}, a commonly used method for state estimation, which recursively updates state estimates by combining information from previous and new measurements. In the literature, various extensions of the Kalman filter have been proposed to improve estimation accuracy \cite{julier2004unscented,julier1995new}. In this paper, we utilize the RTS smoother, further refining the estimates by incorporating information from future measurements with past and current data. The RTS smoothing procedure produces more accurate state estimates compared to the Kalman filter estimation results. Using the estimated states, a suitable cost function is then defined based on the expectation of the log-likelihood function of the parameters. In the second step, we update the estimated parameters by minimizing the cost function. We show the invexity of the cost function, guaranteeing the existence and uniqueness of the optimal solution. Additionally, we derive a closed-form expression for the optimal parameters and prove the recursive feasibility property for the EM procedure. 
%
% In this paper, we focus on identifying systems with linear dynamics and bilinear observation models. We consider the system matrices, initial state, and noise distributions, including their means and covariances, as unknown parameters to be estimated. To this end, we first propose a scheme using the ML approach. Accordingly, a likelihood function is formulated to identify the optimal parameters that maximize the likelihood of the observed data. Following that, we develop a practical first-order method to efficiently solve the optimization problem associated with the proposed ML approach. Additionally, to further improve the tractability and computational efficiency, an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum} is proposed. The developed scheme consists of two iterative steps. In the first step, state estimates are obtained using the estimated parameters at the current stage. To this end, one may employ the Kalman filter \cite{kalman1960new}, a commonly used method for state estimation, which recursively updates state estimates by combining information from previous and new measurements. In the literature, various extensions of the Kalman filter have been proposed to improve estimation accuracy \cite{julier2004unscented,julier1995new}. In this paper, we utilize the RTS smoother, further refining the estimates by incorporating information from future measurements with past and current data. The RTS smoothing procedure produces more accurate state estimates compared to the Kalman filter estimation results. Using the estimated states, a suitable cost function is then defined based on the expectation of the log-likelihood function of the parameters. We update the estimated parameters in the second step by minimizing the cost function. We show the invexity of the cost function, guaranteeing the existence and uniqueness of the optimal solution. Additionally, we derive a closed-form expression for the optimal parameters and prove the recursive feasibility property for the EM procedure. 
% % %
% In this paper, we focus on identifying systems with linear dynamics and bilinear observation models. We consider the system matrices, initial state, and noise distributions, including their means and covariances, as unknown parameters to be estimated. 
In this paper, we focus on identifying systems with linear dynamics and bilinear observation models, where the system matrices, initial state, and noise distributions, including their means and covariances, are treated as unknown parameters to be estimated. 
% In this paper, we focus on identifying systems with linear dynamics and bilinear observation models, where we treat the system matrices, initial state, and noise distributions, including their means and covariances, as unknown parameters to be estimated. 
%
To address this problem, we first propose a scheme using the ML approach. 
%This paper extends our previous work [37] and 
%
% More precisely, a likelihood function is formulated to identify the optimal parameters that maximize the likelihood of the observed data. 
More precisely, we formulate a likelihood function to identify the optimal parameters that maximize the likelihood of the observed data. 
%
% Following that, we develop a practical first-order method to efficiently solve the optimization problem associated with the proposed ML approach. 
% Subsequently, we develop a practical first-order method to efficiently solve the associated optimization problem.
Subsequently, we develop a practical first-order method to efficiently solve the optimization problem associated with the proposed ML approach. 
%
% Additionally, to further improve the tractability and computational efficiency, an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum} is proposed. 
% To further improve tractability and computational efficiency, we propose an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum}.
%--
% Additionally, to further improve the tractability and computational efficiency, we propose an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum}.
Additionally, to further improve the tractability and computational efficiency, we extends our previous work \cite{liu2024system} and propose an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum}.
%
The developed scheme consists of two iterative steps. 
%
% In the first step, state estimates are obtained using the estimated parameters at the current stage.
In the first step, state estimates are obtained using the estimated parameters in the current iteration. 
%
% To this end, one may employ the Kalman filter \cite{kalman1960new}, a commonly used method for state estimation, which recursively updates state estimates by combining information from previous and new measurements. In the literature, various extensions of the Kalman filter have been proposed to improve estimation accuracy \cite{julier2004unscented,julier1995new}. 
% This process can leverage the Kalman filter \cite{kalman1960new}, a well-established method for state estimation that recursively updates state estimates by combining information from previous and current measurements. Various extensions of the Kalman filter have been proposed to improve estimation accuracy \cite{julier2004unscented,julier1995new}.
To this end, one may employ the Kalman filter \cite{kalman1960new}, a well-established method for state estimation that recursively updates state estimates by combining information from previous and current measurements. In the literature, various extensions of the Kalman filter have been proposed to improve estimation accuracy \cite{julier2004unscented,julier1995new}. 
%
% In this paper, we utilize the RTS smoother, further refining the estimates by incorporating information from future measurements with past and current data. 
% In this work, we use the RTS smoother, which refines state estimates by incorporating information from future measurements alongside past and current data.
In this work, we utilize the RTS smoother, further refining the state estimates by incorporating information from future measurements alongside past and current data.
%
% The RTS smoothing procedure produces more accurate state estimates compared to the Kalman filter estimation results. 
% Compared to the Kalman filter, the RTS smoother produces more accurate state estimates.
Notably, the RTS smoothing procedure produces more accurate state estimates compared to the Kalman filter estimation results.
%
% Using the estimated states, a suitable cost function is then defined based on the expectation of the log-likelihood function of the parameters. We update the estimated parameters in the second step by minimizing the cost function.
% In the second step, using the estimated states, we define a cost function based on the expectation of the log-likelihood of the parameters. The estimated parameters are then updated by minimizing this cost function.  
% In the second step, using the estimated states, we define a suitable cost function based on the expectation of the log-likelihood of the parameters. The estimated parameters are then updated by minimizing this cost function.
% In the second step, leveraging the estimated states, using the estimated states, we define a suitable cost function based on the expectation of the log-likelihood of the parameters and minimize it to obtain updated parameter estimates.
% In the second step, leveraging the estimated states, we define a suitable cost function based on the expected log-likelihood of the parameters and minimize it to update the parameter estimates.
% In the second step, using the estimated states, we define a suitable cost function based on the expectation of the log-likelihood of the parameters, and subsequently, minimize it to update parameter estimates.
% In the second step, using the estimated states, we define a suitable cost function based on the expectation of the log-likelihood of the parameters and, subsequently, minimize it to update parameter estimates.
In the second step, we use the estimated states to define a suitable cost function based on the expected log-likelihood of the parameters and subsequently minimize it to update the parameter estimates.
%
We show the invexity of the cost function, guaranteeing the existence and uniqueness of the optimal solution. Additionally, we derive a closed-form expression for the optimal parameters and prove the recursive feasibility property for the EM procedure. 
% We demonstrate that the cost function is invex, ensuring the existence and uniqueness of the optimal solution. Additionally, we derive a closed-form expression for the optimal parameters and prove the recursive feasibility of the EM procedure.
%
% In this paper, we focus on identifying systems with linear dynamics and bilinear observation models. The system matrices, initial state, and noise distributions—including their means and covariances—are treated as unknown parameters to be estimated. To address this problem, we first propose a scheme using the ML approach. More precisely, we formulate a likelihood function to identify the optimal parameters that maximize the likelihood of the observed data. Subsequently, we develop a practical first-order method to efficiently solve the associated optimization problem. To further improve tractability and computational efficiency, we propose an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum}. This scheme involves two iterative steps. In the first step, state estimates are obtained using the parameters estimated in the current iteration. This process can leverage the Kalman filter \cite{kalman1960new}, a well-established method for state estimation that recursively updates state estimates by combining information from previous and current measurements. Various extensions of the Kalman filter have been proposed to improve estimation accuracy \cite{julier2004unscented,julier1995new}. In this work, we use the RTS smoother, which refines state estimates by incorporating information from future measurements alongside past and current data. Compared to the Kalman filter, the RTS smoother produces more accurate state estimates. In the second step, using the estimated states, we define a cost function based on the expectation of the log-likelihood of the parameters. The estimated parameters are then updated by minimizing this cost function. We demonstrate that the cost function is invex, ensuring the existence and uniqueness of the optimal solution. Additionally, we derive a closed-form expression for the optimal parameters and prove the recursive feasibility of the EM procedure.
% % %
% In this paper, we focus on identifying systems with linear dynamics and bilinear observation models. The system matrices, initial state, and noise distributions—including their means and covariances—are treated as unknown parameters to be estimated. To address this problem, we first propose a scheme using the ML approach. Specifically, we formulate a likelihood function to identify the optimal parameters that maximize the likelihood of the observed data. Subsequently, we develop a practical first-order method to efficiently solve the associated optimization problem. To further enhance tractability and computational efficiency, we propose an alternative identification scheme based on the RTS smoother \cite{rauch1965maximum} and the EM approach \cite{dempster1977maximum}. This scheme involves two iterative steps. In the first step, state estimates are obtained using the parameters estimated in the current iteration. This process can leverage the Kalman filter \cite{kalman1960new}, a well-established method for state estimation that recursively updates state estimates by combining information from previous and current measurements. Various extensions of the Kalman filter have been proposed to improve estimation accuracy \cite{julier2004unscented,julier1995new}. In this work, we use the RTS smoother, which refines state estimates by incorporating information from future measurements alongside past and current data. Compared to the Kalman filter, the RTS smoother produces more accurate state estimates. In the second step, using the estimated states, we define a cost function based on the expectation of the log-likelihood of the parameters. The estimated parameters are then updated by minimizing this cost function. We demonstrate that the cost function is invex, ensuring the existence and uniqueness of the optimal solution. Additionally, we derive a closed-form expression for the optimal parameters and prove the recursive feasibility of the EM procedure.
%
%----
The main contributions of this work are outlined below. 
\begin{itemize}
    \item 
    We develop a system identification framework based on the maximum likelihood approach and formulate accordingly an optimization problem to identify systems with linear dynamics and bilinear observation models.
    % We develop a system identification framework using the maximum likelihood approach, formulating an optimization problem to identify systems characterized by linear dynamics and bilinear observation models.
    \item  
    %By deriving the necessary derivatives and using first-order approaches, this paper proposes a tractable approach to solve the optimization problem formulated within the maximum likelihood estimation framework.
    % Towards practical implementation of the proposed maximum likelihood based approach, we propose first-order methods to solve the related optimization problem and thus obtain necessary derivatives.
    To facilitate the practical implementation of the introduced maximum likelihood-based approach, we propose first-order methods to solve the associated optimization problem and compute the necessary derivatives.
    \item 
    % Additionally, an alternative framework combining the RTS smoother and the EM approach is used to address the identification problem, with estimated parameters iteratively updated by solving an optimization problem.
    % To further improve tractability and computational efficiency of the estimation of the parameters describing the system, an alternative framework combining the Rauch–Tung–Striebel smoother and the Expectation--Maximization  approach is proposed to address the identification problem, with estimated parameters iteratively updated by solving an optimization problem.
    % To enhance the tractability and computational efficiency of parameter estimation for the system, an alternative framework is proposed. This framework integrates the Rauch–Tung–Striebel smoother with the Expectation–Maximization approach to tackle the identification problem, wherein the parameters are iteratively updated by solving an optimization problem.
    To further improve tractability and computational efficiency of the estimation of the parameters describing the system, an alternative framework combining the Rauch–Tung–Striebel smoother and the Expectation--Maximization approach is proposed to address the identification problem, with estimated parameters iteratively updated by solving an optimization problem.
    \item 
    % We show that the EM optimization problem has a unique optimum and provides a closed-form solution. Furthermore, we show the recursive feasibility of the proposed EM procedure.
    % We show that the EM cost function is invex, which ensures the existence and uniqueness of the optimal solution. Furthermore, we derive the closed-form solution for the optimal parameters and also prove the recursive feasibility of the EM procedure
    % We demonstrate that the EM cost function is invex, ensuring the existence and uniqueness of the optimal solution for the EM optimization problem. Furthermore, we derive a closed-form solution for the optimal parameters and establish the recursive feasibility of the EM procedure.
    % We demonstrate invexity of the EM cost function and show the existence and uniqueness of the optimal solution for the EM optimization problem. Furthermore, we derive the closed-form solution for the optimal parameters and also prove the recursive feasibility of the EM procedure.
    % candidate 1:
    % We show the existence and uniqueness of the optimal solution for the EM optimization problem. Furthermore, we derive the closed-form solution for the optimal parameters and also prove the recursive feasibility of the EM procedure.
    % candidate 2:      
    We show the invexity of the EM cost function and prove the existence and uniqueness of the optimal solution for the EM optimization problem. Furthermore, we derive the closed-form solution for the optimal parameters and also verify the recursive feasibility of the EM procedure.    
    \item 
    % Algorithms suitable for implementation and numerical experiments are provided to demonstrate the performance of the proposed schemes. Moreover, simulations are presented to study the performance of the proposed algorithms.
    % To facilitate the numerical implementation of the proposed methods, we have provided algorithms detailing all the steps.
    To facilitate the practical application of the proposed methods and for ease of numerical implementation, we have included detailed algorithms outlining all the steps.
    \item
    % We have provided extensive numerical experiments to demonstrate the performance of the proposed schemes and, subsequently, rigorously discussed the features and phenomena observed, giving insight.
    % We have conducted extensive numerical experiments to demonstrate the performance of the proposed schemes, followed by a rigorous discussion of the observed features and phenomena to provide valuable insights.
    % Having conducted extensive numerical experiments to demonstrate the performance of the proposed schemes, we subsequently engaged in a rigorous analysis of the observed features and phenomena, providing valuable insights.
    % We have provided extensive numerical experiments to demonstrate the performance of the proposed schemes. Subsequently, we rigorously discussed the observed features and phenomena, providing crucial intuition for their underlying behavior.
    % We have provided the results of extensive numerical experiments conducted to demonstrate the performance of the proposed schemes, followed by a rigorous discussion of the observed features and phenomena to provide valuable insights about their underlying behavior.
    % We present the results of extensive numerical experiments conducted to evaluate the performance of the proposed schemes. These results are followed by a rigorous discussion of the observed features and phenomena, offering valuable insights into their underlying behavior.
    We present the results of extensive numerical experiments conducted to demonstrate and evaluate the performance of the proposed schemes, followed by a rigorous discussion of the observed features and phenomena, offering valuable insights into their underlying behavior.
\end{itemize}

% The remainder of this paper is structured as follows. In Section \ref{sec:notation}, the main notations used in this paper are listed. The details of identification problem is discussed in Section \ref{sec:pf}. In Section \ref{sec:ML}, a scheme using the ML approach is proposed. In Section \ref{sec:An Expectation-Maximization Approach}, we develop the alternative scheme based on the EM approach. In Section \ref{sec:numerical experiments}, numerical examples are provided to verify the performance of the proposed approaches. Finally, Section~\ref{sec:conclusion} concludes this paper. 
The remainder of this paper is organized as follows. Section \ref{sec:notation} lists the main notations used throughout the paper. The identification problem is discussed in detail in Section \ref{sec:pf}. A scheme employing the ML approach is proposed in Section \ref{sec:ML}. In Section \ref{sec:An Expectation-Maximization Approach}, we develop an alternative scheme based on the EM approach. Section \ref{sec:numerical experiments} presents numerical examples to evaluate the performance of the proposed approaches. Finally, Section~\ref{sec:conclusion} concludes the paper.