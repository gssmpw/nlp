[
  {
    "index": 0,
    "papers": [
      {
        "key": "saito2017temporal",
        "author": "Saito, Masaki and Matsumoto, Eiichi and Saito, Shunta",
        "title": "Temporal generative adversarial nets with singular value clipping"
      },
      {
        "key": "tulyakov2018mocogan",
        "author": "Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan",
        "title": "Mocogan: Decomposing motion and content for video generation"
      },
      {
        "key": "wang2018video",
        "author": "Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan",
        "title": "Video-to-video synthesis"
      },
      {
        "key": "li2018video",
        "author": "Li, Yitong and Min, Martin and Shen, Dinghan and Carlson, David and Carin, Lawrence",
        "title": "Video generation from text"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "he2022latent",
        "author": "He, Yingqing and Yang, Tianyu and Zhang, Yong and Shan, Ying and Chen, Qifeng",
        "title": "Latent video diffusion models for high-fidelity long video generation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2023modelscope",
        "author": "Wang, Jiuniu and Yuan, Hangjie and Chen, Dayou and Zhang, Yingya and Wang, Xiang and Zhang, Shiwei",
        "title": "Modelscope text-to-video technical report"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ronneberger2015u",
        "author": "Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas",
        "title": "U-net: Convolutional networks for biomedical image segmentation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "ho2022imagen",
        "author": "Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others",
        "title": "Imagen video: High definition video generation with diffusion models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "singer2022make",
        "author": "Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others",
        "title": "Make-a-video: Text-to-video generation without text-video data"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "yin2023dragnuwa",
        "author": "Yin, Shengming and Wu, Chenfei and Liang, Jian and Shi, Jie and Li, Houqiang and Ming, Gong and Duan, Nan",
        "title": "Dragnuwa: Fine-grained control in video generation by integrating text, image, and trajectory"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "dai2023fine",
        "author": "Dai, Zuozhuo and Zhang, Zhenghao and Yao, Yao and Qiu, Bingxue and Zhu, Siyu and Qin, Long and Wang, Weizhi",
        "title": "Fine-grained open domain image animation with motion guidance"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "guo2023animatediff",
        "author": "Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo",
        "title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning"
      },
      {
        "key": "wang2023lavie",
        "author": "Wang, Yaohui and Chen, Xinyuan and Ma, Xin and Zhou, Shangchen and Huang, Ziqi and Wang, Yi and Yang, Ceyuan and He, Yinan and Yu, Jiashuo and Yang, Peiqing and others",
        "title": "Lavie: High-quality video generation with cascaded latent diffusion models"
      }
    ]
  }
]