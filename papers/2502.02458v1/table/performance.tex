\begin{table*}[t]
  \centering
  % \resizebox{\textwidth}{!}
  {
  \renewcommand{\arraystretch}{1.0}
  % \scalebox{0.8}
  % {
 
 \begin{tabular}{ll|c|c|c|c|c|cc|c}
    \toprule
    \multicolumn{1}{l}{\multirow{2}[2]{*}{Method}} & \multirow{2}[2]{*}{LLM} & \#Vis. & Training & Inference & MMMU & \multirow{2}[2]{*}{MME~\cite{fu2024mmecomprehensiveevaluationbenchmark}} & \multicolumn{2}{c|}{MMBench~\cite{liu2024mmbenchmultimodalmodelallaround}} & SEED~\cite{li2023seedbenchbenchmarkingmultimodalllms} \\
          &       & Tok. & Data$\downarrow$ & TFLOPs$\downarrow$ & VAL~\cite{yue2024mmmumassivemultidisciplinemultimodal} &       & EN & CN & Image \\
    \midrule
    BLIP-2 & Vicuna-7B & 32    & 129M  & 1.25  & -     & 1293.8 & -     & -     & - \\
    InstructBLIP & Vicuna-7B & 32    & 130M  & 1.25  & 30.6  & 1137.1 & 36.0  & 23.7  & 58.8 \\
    MiniGPT-4 & Vicuna-7B & 32    & 517k  & 1.25  & 23.6  & 770.6 & 32.7  & 11.9  & 31.4 \\
    MiniGPT-v2 & Llama2-7B & 256   & 326M   & 4.20  & 25.0  & 708.4 & 24.3  & -     & 29.4 \\
    Otter & Llama-7B & 64    & 2.1B  & 1.67  & -     & 1292.3 & 48.3  & -     & 35.2 \\
    Shikra & Vicuna-7B & 256   & 6.1M  & 4.20  & -     & -     & 58.8  & -     & - \\
    IDEFICS & Llama-7B & 64    & 354M  & 1.67  & 18.4  & 942.0  & 48.2  & 25.2  & 44.5 \\
    IDEFICS & Llama-65B & 64    & 354M  & 16.62 & -     & 1244.9     & 54.5  & 38.1  & 53.2 \\
    Qwen-VL-Chat & Qwen-7B & 256   & 1.4B  & 4.20  & 36.0  & 1435.2 & 60.6  & 56.7  & 65.4 \\
    LLaVA-1.5 & Vicuna-7B & 576   & 1.2M  & 8.53  & 35.7  & \textbf{1510.7} & 64.3  & 58.3  & \textbf{66.1} \\
    \rowcolor{cyan!20} SAISA (Ours) & Vicuna-7B & 576   & 1.2M  & 2.86  & \textbf{36.9} & 1461.9 & \textbf{65.7} & \textbf{59.0} & 64.5 \\
    \bottomrule
    \end{tabular}%
    }
  % }
  \caption{\textbf{Performance on comprehensive benchmarks for instruction-following MLLMs.}
  \#Vis. Tok.: the number of visual tokens involved in a single image.
  \#Training Data: accumulated multimodal pre-training and fine-tuning data volume.
  Inference TFLOPs: the computational cost of processing a single image when the number of text tokens is 64.
  $\downarrow$: a lower value in these columns is better.
    SAISA achieves the best performance on 3/5 benchmarks, while reducing inference TFLOPs by 66\% compared to LLaVA-1.5.
  }
  \label{tab:mllms}%
\end{table*}