@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{awadalla2023openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  year={2023}
}

@inproceedings{blip2,
  author       = {Junnan Li and
                  Dongxu Li and
                  Silvio Savarese and
                  Steven C. H. Hoi},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image
                  Encoders and Large Language Models},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {19730--19742},
  publisher    = {{PMLR}},
  year         = {2023},
  timestamp    = {Mon, 04 Dec 2023 11:29:49 +0100},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{chen2024far,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}

@inproceedings{cui2024robustness,
  title={On the robustness of large multimodal models against image adversarial attacks},
  author={Cui, Xuanming and Aparcedo, Alejandro and Jang, Young Kyun and Lim, Ser-Nam},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24625--24634},
  year={2024}
}

@article{gu2022watermarking,
  title={Watermarking pre-trained language models with backdooring},
  author={Gu, Chenxi and Huang, Chengsong and Zheng, Xiaoqing and Chang, Kai-Wei and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2210.07543},
  year={2022}
}

@misc{instructfinger,
      title={Instructional Fingerprinting of Large Language Models}, 
      author={Jiashu Xu and Fei Wang and Mingyu Derek Ma and Pang Wei Koh and Chaowei Xiao and Muhao Chen},
      year={2024},
      eprint={2401.12255},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{kurita2020weight,
  title={Weight poisoning attacks on pre-trained models},
  author={Kurita, Keita and Michel, Paul and Neubig, Graham},
  journal={arXiv preprint arXiv:2004.06660},
  year={2020}
}

@article{li2024mini,
  title={Mini-gemini: Mining the potential of multi-modality vision language models},
  author={Li, Yanwei and Zhang, Yuechen and Wang, Chengyao and Zhong, Zhisheng and Chen, Yixin and Chu, Ruihang and Liu, Shaoteng and Jia, Jiaya},
  journal={arXiv preprint arXiv:2403.18814},
  year={2024}
}

@article{lishen,
  author       = {Shen Li and
                  Liuyi Yao and
                  Jinyang Gao and
                  Lan Zhang and
                  Yaliang Li},
  title        = {Double-I Watermark: Protecting Model Copyright for {LLM} Fine-tuning},
  journal      = {CoRR},
  volume       = {abs/2402.14883},
  year         = {2024},
  doi          = {10.48550/ARXIV.2402.14883},
  eprinttype    = {arXiv},
  eprint       = {2402.14883},
  timestamp    = {Fri, 22 Mar 2024 12:19:03 +0100},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@misc{liu2024llava,
  title={Llava-next: Improved reasoning, ocr, and world knowledge},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
  year={2024}
}

@article{llava,
  author       = {Haotian Liu and
                  Chunyuan Li and
                  Qingyang Wu and
                  Yong Jae Lee},
  title        = {Visual Instruction Tuning},
  journal      = {CoRR},
  volume       = {abs/2304.08485},
  year         = {2023},
  doi          = {10.48550/arXiv.2304.08485},
  eprinttype    = {arXiv},
  eprint       = {2304.08485},
  timestamp    = {Fri, 21 Apr 2023 11:01:56 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{minigpt4,
  author       = {Deyao Zhu and
                  Jun Chen and
                  Xiaoqian Shen and
                  Xiang Li and
                  Mohamed Elhoseiny},
  title        = {MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2304.10592},
  year         = {2023},
  doi          = {10.48550/arXiv.2304.10592},
  eprinttype    = {arXiv},
  eprint       = {2304.10592},
  timestamp    = {Tue, 02 May 2023 18:58:23 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{nips23zhao,
  author       = {Yunqing Zhao and
                  Tianyu Pang and
                  Chao Du and
                  Xiao Yang and
                  Chongxuan Li and
                  Ngai{-}Man Cheung and
                  Min Lin},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {On Evaluating Adversarial Robustness of Large Vision-Language Models},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  timestamp    = {Fri, 01 Mar 2024 16:26:20 +0100}
}

@inproceedings{non_iccv,
  author       = {Christian Schlarmann and
                  Matthias Hein},
  title        = {On the Adversarial Robustness of Multi-Modal Foundation Models},
  booktitle    = {{IEEE/CVF} International Conference on Computer Vision, {ICCV} 2023
                  - Workshops, Paris, France, October 2-6, 2023},
  pages        = {3679--3687},
  publisher    = {{IEEE}},
  year         = {2023},
  doi          = {10.1109/ICCVW60793.2023.00395},
  timestamp    = {Wed, 10 Jan 2024 15:47:41 +0100}
}

@inproceedings{shayegani2023jailbreak,
  title={Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models},
  author={Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{wang2024break,
  title={Break the visual perception: Adversarial attacks targeting encoded visual tokens of large vision-language models},
  author={Wang, Yubo and Liu, Chaohu and Qu, Yanqiu and Cao, Haoyu and Jiang, Deqiang and Xu, Linli},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={1072--1081},
  year={2024}
}

@inproceedings{xiangaaai2024,
  author       = {Xiangyu Qi and
                  Kaixuan Huang and
                  Ashwinee Panda and
                  Peter Henderson and
                  Mengdi Wang and
                  Prateek Mittal},
  editor       = {Michael J. Wooldridge and
                  Jennifer G. Dy and
                  Sriraam Natarajan},
  title        = {Visual Adversarial Examples Jailbreak Aligned Large Language Models},
  booktitle    = {Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2024, Thirty-Sixth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
  pages        = {21527--21536},
  publisher    = {{AAAI} Press},
  year         = {2024},
  doi          = {10.1609/AAAI.V38I19.30150},
  timestamp    = {Tue, 02 Apr 2024 16:32:09 +0200}
}

@article{xu2023instructions,
  title={Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models},
  author={Xu, Jiashu and Ma, Mingyu Derek and Wang, Fei and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2305.14710},
  year={2023}
}

@article{yin2023,
  author       = {Shukang Yin and
                  Chaoyou Fu and
                  Sirui Zhao and
                  Ke Li and
                  Xing Sun and
                  Tong Xu and
                  Enhong Chen},
  title        = {A Survey on Multimodal Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2306.13549},
  year         = {2023},
  doi          = {10.48550/arXiv.2306.13549},
  eprinttype    = {arXiv},
  eprint       = {2306.13549},
  timestamp    = {Tue, 27 Jun 2023 17:45:46 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

