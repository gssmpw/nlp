@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@inproceedings{kazemzadeh2014referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={787--798},
  year={2014}
}

@article{kiela2020hateful,
  title={The hateful memes challenge: Detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={2611--2624},
  year={2020}
}

@article{chen2023internvl,
  title={InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and Li, Bin and Luo, Ping and Lu, Tong and Qiao, Yu and Dai, Jifeng},
  journal={arXiv preprint arXiv:2312.14238},
  year={2023}
}

@inproceedings{luo2023image,
  title={An image is worth 1000 lies: Transferability of adversarial images across prompts on vision-language models},
  author={Luo, Haochen and Gu, Jindong and Liu, Fengyuan and Torr, Philip},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{dong2018boosting,
  title={Boosting adversarial attacks with momentum},
  author={Dong, Yinpeng and Liao, Fangzhou and Pang, Tianyu and Su, Hang and Zhu, Jun and Hu, Xiaolin and Li, Jianguo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9185--9193},
  year={2018}
}

@inproceedings{xie2019improving,
  title={Improving transferability of adversarial examples with input diversity},
  author={Xie, Cihang and Zhang, Zhishuai and Zhou, Yuyin and Bai, Song and Wang, Jianyu and Ren, Zhou and Yuille, Alan L},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2730--2739},
  year={2019}
}

@inproceedings{liu2024hrvda,
  title={Hrvda: High-resolution visual document assistant},
  author={Liu, Chaohu and Yin, Kun and Cao, Haoyu and Jiang, Xinghua and Li, Xin and Liu, Yinsong and Jiang, Deqiang and Sun, Xing and Xu, Linli},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15534--15545},
  year={2024}
}

@inproceedings{wang2024break,
  title={Break the visual perception: Adversarial attacks targeting encoded visual tokens of large vision-language models},
  author={Wang, Yubo and Liu, Chaohu and Qu, Yanqiu and Cao, Haoyu and Jiang, Deqiang and Xu, Linli},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={1072--1081},
  year={2024}
}

@misc{dai2023instructblip,
      title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning}, 
      author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi},
      year={2023},
      eprint={2305.06500},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.06500}, 
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@article{wang2024qwen2,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{lishen,
  author       = {Shen Li and
                  Liuyi Yao and
                  Jinyang Gao and
                  Lan Zhang and
                  Yaliang Li},
  title        = {Double-I Watermark: Protecting Model Copyright for {LLM} Fine-tuning},
  journal      = {CoRR},
  volume       = {abs/2402.14883},
  year         = {2024},
  doi          = {10.48550/ARXIV.2402.14883},
  eprinttype    = {arXiv},
  eprint       = {2402.14883},
  timestamp    = {Fri, 22 Mar 2024 12:19:03 +0100},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  pages={39--57},
  year={2017},
  organization={Ieee}
}

@misc{instructfinger,
      title={Instructional Fingerprinting of Large Language Models}, 
      author={Jiashu Xu and Fei Wang and Mingyu Derek Ma and Pang Wei Koh and Chaowei Xiao and Muhao Chen},
      year={2024},
      eprint={2401.12255},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{yin2023,
  author       = {Shukang Yin and
                  Chaoyou Fu and
                  Sirui Zhao and
                  Ke Li and
                  Xing Sun and
                  Tong Xu and
                  Enhong Chen},
  title        = {A Survey on Multimodal Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2306.13549},
  year         = {2023},
  doi          = {10.48550/arXiv.2306.13549},
  eprinttype    = {arXiv},
  eprint       = {2306.13549},
  timestamp    = {Tue, 27 Jun 2023 17:45:46 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{blip2,
  author       = {Junnan Li and
                  Dongxu Li and
                  Silvio Savarese and
                  Steven C. H. Hoi},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image
                  Encoders and Large Language Models},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {19730--19742},
  publisher    = {{PMLR}},
  year         = {2023},
  timestamp    = {Mon, 04 Dec 2023 11:29:49 +0100},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{awadalla2023openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@misc{liu2024llava,
  title={Llava-next: Improved reasoning, ocr, and world knowledge},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
  year={2024}
}

@article{kurita2020weight,
  title={Weight poisoning attacks on pre-trained models},
  author={Kurita, Keita and Michel, Paul and Neubig, Graham},
  journal={arXiv preprint arXiv:2004.06660},
  year={2020}
}

@article{li2024mini,
  title={Mini-gemini: Mining the potential of multi-modality vision language models},
  author={Li, Yanwei and Zhang, Yuechen and Wang, Chengyao and Zhong, Zhisheng and Chen, Yixin and Chu, Ruihang and Liu, Shaoteng and Jia, Jiaya},
  journal={arXiv preprint arXiv:2403.18814},
  year={2024}
}


@article{minigpt4,
  author       = {Deyao Zhu and
                  Jun Chen and
                  Xiaoqian Shen and
                  Xiang Li and
                  Mohamed Elhoseiny},
  title        = {MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2304.10592},
  year         = {2023},
  doi          = {10.48550/arXiv.2304.10592},
  eprinttype    = {arXiv},
  eprint       = {2304.10592},
  timestamp    = {Tue, 02 May 2023 18:58:23 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{llava,
  author       = {Haotian Liu and
                  Chunyuan Li and
                  Qingyang Wu and
                  Yong Jae Lee},
  title        = {Visual Instruction Tuning},
  journal      = {CoRR},
  volume       = {abs/2304.08485},
  year         = {2023},
  doi          = {10.48550/arXiv.2304.08485},
  eprinttype    = {arXiv},
  eprint       = {2304.08485},
  timestamp    = {Fri, 21 Apr 2023 11:01:56 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  year={2023}
}

@article{bin2024gallerygpt,
  title={GalleryGPT: Analyzing Paintings with Large Multimodal Models},
  author={Bin, Yi and Shi, Wenhao and Ding, Yujuan and Hu, Zhiqiang and Wang, Zheng and Yang, Yang and Ng, See-Kiong and Shen, Heng Tao},
  journal={arXiv preprint arXiv:2408.00491},
  year={2024}
}

@article{shi2024math,
  title={Math-llava: Bootstrapping mathematical reasoning for multimodal large language models},
  author={Shi, Wenhao and Hu, Zhiqiang and Bin, Yi and Liu, Junhua and Yang, Yang and Ng, See-Kiong and Bing, Lidong and Lee, Roy Ka-Wei},
  journal={arXiv preprint arXiv:2406.17294},
  year={2024}
}

@inproceedings{edwards2021text2mol,
  title={Text2mol: Cross-modal molecule retrieval with natural language queries},
  author={Edwards, Carl and Zhai, ChengXiang and Ji, Heng},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={595--607},
  year={2021}
}

@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8317--8326},
  year={2019}
}

@inproceedings{biten2019scene,
  title={Scene Text Visual Question Answering},
  author={Biten, Ali Furkan and Tito, Ruben and Mafla, Andres and Gomez, Lluis and Rusinol, Marcal and Jawahar, CV and Valveny, Ernest and Karatzas, Dimosthenis},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019},
  organization={IEEE}
}

@inproceedings{zhu2016visual7w,
  title={Visual7w: Grounded question answering in images},
  author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4995--5004},
  year={2016}
}

@article{chen2024far,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@article{li2024llava,
  title={Llava-med: Training a large language-and-vision assistant for biomedicine in one day},
  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{you2024ferret,
  title={Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs},
  author={You, Keen and Zhang, Haotian and Schoop, Eldon and Weers, Floris and Swearngin, Amanda and Nichols, Jeffrey and Yang, Yinfei and Gan, Zhe},
  journal={arXiv preprint arXiv:2404.05719},
  year={2024}
}

@article{gu2022watermarking,
  title={Watermarking pre-trained language models with backdooring},
  author={Gu, Chenxi and Huang, Chengsong and Zheng, Xiaoqing and Chang, Kai-Wei and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2210.07543},
  year={2022}
}

@inproceedings{li2023plmmark,
  title={Plmmark: a secure and robust black-box watermarking framework for pre-trained language models},
  author={Li, Peixuan and Cheng, Pengzhou and Li, Fangqi and Du, Wei and Zhao, Haodong and Liu, Gongshen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={12},
  pages={14991--14999},
  year={2023}
}

@article{xu2023instructions,
  title={Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models},
  author={Xu, Jiashu and Ma, Mingyu Derek and Wang, Fei and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2305.14710},
  year={2023}
}

@inproceedings{nips23zhao,
  author       = {Yunqing Zhao and
                  Tianyu Pang and
                  Chao Du and
                  Xiao Yang and
                  Chongxuan Li and
                  Ngai{-}Man Cheung and
                  Min Lin},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {On Evaluating Adversarial Robustness of Large Vision-Language Models},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  timestamp    = {Fri, 01 Mar 2024 16:26:20 +0100}
}

@inproceedings{cui2024robustness,
  title={On the robustness of large multimodal models against image adversarial attacks},
  author={Cui, Xuanming and Aparcedo, Alejandro and Jang, Young Kyun and Lim, Ser-Nam},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24625--24634},
  year={2024}
}

@inproceedings{shayegani2023jailbreak,
  title={Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models},
  author={Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{non_iccv,
  author       = {Christian Schlarmann and
                  Matthias Hein},
  title        = {On the Adversarial Robustness of Multi-Modal Foundation Models},
  booktitle    = {{IEEE/CVF} International Conference on Computer Vision, {ICCV} 2023
                  - Workshops, Paris, France, October 2-6, 2023},
  pages        = {3679--3687},
  publisher    = {{IEEE}},
  year         = {2023},
  doi          = {10.1109/ICCVW60793.2023.00395},
  timestamp    = {Wed, 10 Jan 2024 15:47:41 +0100}
}


@inproceedings{xiangaaai2024,
  author       = {Xiangyu Qi and
                  Kaixuan Huang and
                  Ashwinee Panda and
                  Peter Henderson and
                  Mengdi Wang and
                  Prateek Mittal},
  editor       = {Michael J. Wooldridge and
                  Jennifer G. Dy and
                  Sriraam Natarajan},
  title        = {Visual Adversarial Examples Jailbreak Aligned Large Language Models},
  booktitle    = {Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2024, Thirty-Sixth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
  pages        = {21527--21536},
  publisher    = {{AAAI} Press},
  year         = {2024},
  doi          = {10.1609/AAAI.V38I19.30150},
  timestamp    = {Tue, 02 Apr 2024 16:32:09 +0200}
}