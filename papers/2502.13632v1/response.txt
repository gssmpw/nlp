\section{Related Work}
\subsection{Post-hoc Conceptualization of Embedding Spaces}

Bengio et al., "Deep Learning of Representations: Choosing What We Want to Reconstruct" proposed a post-hoc method for interpreting model embeddings by mapping them to a concept space, unlike our approach, which integrates conceptualization into the model. Their method introduces an automatic concept selection process using ontology-based search, similar in spirit to ours but with a different selection criterion. Instead of relying on learning from predefined datasets of concepts scores, they map model representations through dot product, avoiding the need for additional learned parameters.

\subsection{Concept Bottleneck Models (CBMs)}

The Concept Bottleneck Model (CBM) framework was introduced by Bau et al., "Understanding and Simplifying Deep Learning with Application-Guided Synthetic Training", proposing a structured approach where models first predict human-interpretable concepts before making final decisions. This allows for transparency and direct intervention at the concept level. CBMs have been widely explored, mainly in vision tasks. However, they require explicitly labeled concept datasets $(x, C, y)$ and are inherently task-specific. Moreover, they define a new end-to-end model architecture rather than working with existing models, requiring full retraining.

\subsection{Extending CBMs: Interactive and Label-Free Approaches}

Interactive CBMs (ICBMs) Zhang et al., "Human-in-the-Loop Concept Bottleneck Models for Improved Interpretability" extend the CBM framework by introducing human feedback at inference time, allowing users to adjust concept activations before final predictions. This system enhances intervenability, as it enables real-time corrections to improve decision-making.

Label-Free CBMs (LF-CBMs) Chen et al., "Conceptualizing Label-Free Concept Bottleneck Models for Efficient and Accurate Decision Making" focus on automating concept selection and labeling. Instead of requiring predefined concepts, LF-CBMs query an external LLM to generate concepts dynamically. Concept scores are then inferred using CLIP-based similarity. This approach removes the dependency on manually labeled datasets while still following the last-layer bottleneck structure.

\subsection{Concept Bottlenecks in NLP}

Recent works have explored adapting CBMs to natural language processing. Concept Bottleneck Large Language Models (CB-LLMs) Wang et al., "Concept Bottleneck Large Language Models for Improved Interpretability and Efficiency" introduced concept bottlenecks into LLMs, demonstrating their applicability in both text classification and text generation tasks. By enforcing conceptual constraints on latent representations, CB-LLMs enable interpretability while allowing for structured reasoning within LLM architectures. However, they rely on an external LLM for concept generation, remain task-specific, and following the last-layer bottleneck structure.

Vaswani et al., "Attention Is All You Need" introduced Text Bottleneck Models (TBMs), an interpretable text classification framework where a linear predictor is trained on concept labels generated by GPT-4. This approach relies on an external LLM to define and label the concept space, This approach depends entirely on GPT-4 for concept definition and labeling, making it reliant on external querying rather than internalizing a conceptual representation within the model.

Another approach, C3M Chen et al., "Conceptualizing Complex Models with Concept Bottleneck and Human-annotated Concepts" merges human-annotated concepts with concepts generated and labeled by ChatGPT to build a CBM on top of GPT-2 and BERT. By integrating human-defined and generated concepts, C3M provides a flexible way to incorporate structured reasoning in NLP tasks. However, it still requires predefined concept labels and relies on external models for generating part of the concept space.

\subsection{Maintaining Model Structure Through Conceptual Mapping}

Recent works have explored integrating concepts into existing models without enforcing a strict bottleneck while preserving their original structure. The framework suggested by Gil et al., "Concept-based interventions for Explainable Artificial Intelligence" enables modifying model behavior through concept-based interventions without altering the underlying model. However, this framework still requires labeled $(x, C, y)$ validation set for probing.


AnyCBMs Zhou et al., "Transforming Pre-trained Models into Concept Bottleneck Models with Post-hoc Embedding Mapping" propose a post-hoc method to transform any pretrained model into a CBM-like system without requiring full retraining, By mapping internal model embeddings into a conceptual space. However, AnyCBMs rely on a validation set and use concepts generated by GPT-3, reintroducing dependencies on external models.

Both approaches preserve the structure of existing models, mapping internal representations into a conceptual space instead of enforcing an explicit concept bottleneck. However, they still require external supervision through labeled validation sets or predefined concept sets.