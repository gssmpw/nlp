\documentclass[conference]{IEEEtran}
%\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
%\usepackage{microtype}      % microtypography
%\usepackage{lipsum}		% Can be removed after putting your text content
%\usepackage{natbib}
%\usepackage{biblatex}
%\addbibresource{references.bib}
\usepackage{doi}
\usepackage{orcidlink}
\usepackage{marvosym}
\usepackage{authblk}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{etoolbox}
\newcommand{\insertfig}{
  \begin{center}
    \setcounter{figure}{0}
    \captionsetup{belowskip=0pt}
    \includegraphics[width=\textwidth]{Figures/CoverPic2.png}
    \captionof{figure}{Real-time haptic interaction between two physically distant users within the same VR environment}
  \end{center}
}

%\newcommand{\insertfig}{\includegraphics[width=\textwidth]{Figures/CoverPic1.png}}% define the image

\makeatletter
\apptocmd{\@maketitle}{\centering\insertfig}{}{}% insert the figure after authors
\makeatother

\begin{document}
\title{Virtual Encounters of the Haptic Kind: Towards a Multi-User VR System for Real-Time Social Touch}
\author[1]{Premankur Banerjee\orcidlink{0000-0002-0865-3634} \thanks{\href{mailto:premankur.banerjee@usc.edu}{premankur.banerjee@usc.edu}}}
\author[1]{Jiaxuan Wang\orcidlink{}}
\author[2]{Lauren Tomita\orcidlink{0009-0009-9245-2007}}
\author[2]{Mia P Montiel\orcidlink{0009-0000-7972-1166}}
\author[1]{Heather Culbertson\orcidlink{0000-0002-9187-2706}}

\affil[1]{Thomas Lord Department of Computer Science}
\affil[2]{Alfred E. Mann Department of Biomedical Engineering}
\affil[1,2]{Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089, USA}

% Uncomment to remove the date
\date{}

% Uncomment to override  the `A preprint' in the header
% \renewcommand{\headeright}{P. Banerjee et al.}
% \renewcommand{\undertitle}{}
% \renewcommand{\shorttitle}{Towards a Multi-User VR System for Real-Time Social Touch}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={Virtual Encounters of the Haptic Kind: Towards a Multi-User VR System for Real-Time Social Touch},
%pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={Premankur Banerjee, Jiaxuan Wang, Lauren Tomita, Mia P Montiel, Heather Culbertson},
pdfkeywords={Virtual Reality, Motion Simulation, Acceleration Perception, Surfing},
}

% \begin{document}
\maketitle
%\twocolumn

\begin{abstract}
    Physical touch, a fundamental aspect of human social interaction, remains largely absent in real-time virtual communication. We present a haptic-enabled multi-user Virtual Reality (VR) system that facilitates real-time, bi-directional social touch communication among physically distant users.
We developed wearable gloves and forearm sleeves, embedded with 26 vibrotactile actuators for each hand and arm, actuated via a WiFi-based communication system. The system enables VR-transmitted data to be universally interpreted by haptic devices, allowing feedback rendering based on their capabilities. 
Users can perform and receive social touch gestures such as stroke, pat, poke, and squeeze, with other users within a shared virtual space or interact with other virtual objects, and they receive vibrotactile feedback.
Through a two-part user study involving six pairs of participants, we investigate the impact of gesture speed, haptic feedback modality, and user roles, during real-time haptic communication in VR, on affective and sensory experiences, as well as evaluate the overall system usability.
Our findings highlight key design considerations that significantly improve affective experiences, presence, embodiment, pleasantness, and naturalness, to foster more immersive and expressive mediated social touch experiences in VR.
\end{abstract}


% keywords can be removed
% \keywords{Multi-user Virtual Reality \and Social Touch \and Vibrotactile \and Wearables \and Haptic devices}
\begin{IEEEkeywords}
Multi-user Virtual Reality, Social Touch, Vibrotactile, Wearables, Haptic devices
\end{IEEEkeywords}

% \begin{figure*}
%     \centering
%     \includegraphics[width=\textwidth]{Figures/CoverPic2.png}
%     \caption{Caption}
%     \label{fig:enter-label}
% \end{figure*}

\section{Motivation}

The COVID-19 pandemic and the resulting need for social distancing~\cite{DH3, DH4, DH5, DH6} significantly accelerated the adoption of social Virtual Reality (VR) as a medium for virtual communication. Applications such as virtual meetings and negotiations~\cite{DH7, DH8, DH9, qiu2023vigather} have demonstrated the potential of VR to improve convenience and productivity in human interaction. However, these virtual environments often struggle to effectively convey social intentions~\cite{DH10, DH11}, particularly non-verbal behaviors, which are estimated to have five times the impact of verbal communication on expressing emotional connections~\cite{DH12}. This limitation is particularly pronounced in the absence of physical touch -- a critical element of human interaction that fosters social bonding and connection~\cite{DH13, DH14}.

Physical touch is an evolutionarily fundamental mode of interaction~\cite{ST8}, fulfilling an innate human need for social contact. Mediated touch, which uses technology to replicate touch sensations in remote settings, has gained considerable attention in recent years~\cite{ST27,wei2023mediated}. The growing interest has been further fueled by the emergence of the Metaverse, a conceptual framework for an integrated, immersive ecosystem where the boundaries between the virtual and real worlds are seamless~\cite{DH43, DH44}. The Metaverse seeks to improve the psychological and emotional engagement of users, highlighting the importance of replicating the social presence and emotional connection in real-world and virtual environments.
The increasing need for remote social interaction and the evolution of the Metaverse underscore the need to integrate mediated touch into virtual communication systems. Such technologies must not only provide a sense of presence, but also enable the authentic transmission of social intentions and emotions. However, substantial challenges remain in accurately and effectively transmitting genuine emotions and intentions through mediated touch platforms~\cite{ST27}.

This paper presents a multiplayer VR application supporting up to 16 geographically distributed users, enabling real-time social interaction with their avatars as well as collaboration with other virtual objects in a shared virtual space. Haptic feedback corresponding to the interactions is rendered through 26 vibrotactile actuators or Eccentric Rotating Mass (ERM) motors distributed across each hand and forearms. The application can be used on Meta VR headsets and uses a WiFi-based communication system. It is designed to ensure that the data transmitted from VR can be universally interpreted by various haptic devices, to render feedback in accordance with their specific rendering capabilities.


\subsection{Affective Touch Technology}

Efforts to develop devices capable of rendering affective haptic stimuli have explored various mechanisms and body sites, with several approaches targeting specific use cases like social touch communication, affective messaging, enhancing multimedia experiences, among others~\cite{ALT17, ALT18, ALT19, ALT20, ALT21, ALT22, ALT27}. Many devices focus on the forearm due to the ease of mounting actuators and the appropriateness of this location for social touch~\cite{suvilehto2015topography}. The modalities leveraged by these systems, including vibration~\cite{ALT16, ALT28, ALT29, ALT30, kirchner2023phantom}, slow or static pressure cues~\cite{ALT31}, force~\cite{wang2012keep}, or temperature~\cite{he2024affective}, determine how realistic and/or expressive the affective touch is. Their actuation techniques, such as linear actuators~\cite{ALT32}, pneumatic actuators~\cite{ALT33}, voice coil actuators~\cite{ALT7, ALT34}, and mid-air~\cite{he2024affective}, determine scalability and wearability of the device. Vibrational illusions~\cite{ALT45, ALT44, tactilebrush}, in particular, offer versatility, enabling arbitrary continuous movement patterns, including in two-dimensions~\cite{ALT30, kirchner2023phantom}, making them well-suited for reproducing social touch.
Efforts to enhance mediated touch have focused on enriching the range of emotions and sensations conveyed~\cite{ALT18}. However, attempts to create more authentic reproductions of social touch often encounter trade-offs, including limitations in versatility, latency, and bulkiness compared to vibratory approaches.

A recent study~\cite{kirchner2023phantom} introduced a novel vibrotactile armband system that leverages phantom illusion and parametric design to render affective touch patterns on the forearm, which supports live rendering and automatic generation of touch patterns. However, the system would require a sensor armband to capture and recognize the touch patterns before the touch parameters are transmitted and rendered on the receiver armband. This would still not enable seamless, naturalistic feedback for the toucher in virtual environments, when they perform the gestures directly with their hands on the touchee. Sensors and communication play a critical role in mediated social touch, as they determine the fidelity of feedback and its emotional interpretation. High-quality sensors enable precise capture of input gestures like squeezes or strokes~\cite{rantala2013touch}, while effective communication systems ensure accurate transmission of these gestures to the receiver, adhering to the intended affective intent~\cite{bailenson2007virtual}. Previous approaches to two-dimensional touch pattern reproduction have often been based on recordings of real touches~\cite{ALT7, ALT28, ALT35}. Touchers aim to convey specific emotions such as delight, anger, or relaxation through tailored gestures like squeezing or stroking~\cite{huisman2013towards,smith2007communicating}, and the type of gesture often correlates with the intended valence and arousal of the emotion~\cite{rantala2013touch}.

To further enhance the authenticity of mediated social touch, it is important to integrate visual information, since body language is a vital component of non-verbal communication~\cite{bailenson2005digital}. Incorporating visual cues, such as gestures, postures, or facial expressions, together with haptic feedback, could create richer, more holistic representations of social interactions~\cite{maloney2020talking}. Visual information significantly influences the perception of affect and intention during communication~\cite{zamuner2013role, blom2021perceiving}. Thus, combining visual and haptic modalities offers a promising avenue to bridge the gap between mediated and naturalistic social interactions, enabling a more immersive and emotionally expressive experience.


\subsection{Social Touch in Virtual Reality}

Modern VR technology has demonstrated the ability to induce a strong illusion of virtual body ownership, often referred to as a sense of embodiment~\cite{ST28, ST34, ST40, ST43, ST49, ST50}. This phenomenon allows users to perceive interactions with their virtual body as if they were occurring with their physical body. For instance, observing one's virtual body being touched or interacting with another avatar can elicit reactions akin to those experienced during physical touch in the real world~\cite{jacucci2024haptics,genay2021being}. Studies further indicate that technologically mediated social touch can evoke physiological, emotional, and behavioral responses comparable to real-world touch~\cite{ST18, ST27, ST60}.

Research into social touch in VR categorizes findings based on the type of interaction partners (human-human vs. human-agent) and the direction of the touch (participant-initiated vs. participant-received).
Rendering touch using artificial hands were shown to enhance human-likeness in avatars~\cite{ST26} (human-agent, receiving touch), while force-feedback devices revealed variations in touch force strength and duration based on a virtual agent's characteristics, touch location, and participant factors like sex and anti-fat attitudes~\cite{ST2, ST59} (human-agent, initiating touch). These findings align with results from face-to-face studies in this field~\cite{ST15, ST46}, suggesting similar underlying behavioral dynamics.
%Social touch enhances perceptions of human-likeness in avatars(human-agent, receiving touch) as shown in~\cite{ST26} by using an artificial hand. In an earlier study (human-agent, initiating touch), virtual agents were observed to be touched with less force than virtual geometric objects~\cite{ST2} with the force applied varying depending on the location of the touch and the agent’s sex.
The perceived appropriateness and erogeneity of visual-only virtual touch on different zones of an embodied avatar (human-agent, receiving touch)~\cite{ST14} were influenced by factors like touch location, sex of the touching avatar and the participant, and the participant’s sexual orientation. %No haptic feedback was provided, and the touches were induced solely by visual stimuli~\cite{ST14}. 
The role of touch in economic decision-making (human-agent, receiving and initiating touch) reported no effect of touch on compliance behavior~\cite{ST55}, in contrast to previous findings in VR settings involving human-agent interactions and receiving touch~\cite{ST21, ST65}.
The perception of virtual touch supported by tactile feedback (human-agent, receiving) was found to be modulated by the facial expressions of virtual agents as well as individual differences related to the participants’ sex~\cite{ST20}. Haptic feedback via ultrasonic arrays and silicone hand was also found to enhance the affective perception of the toucher (human-agent, initiating touch) during social touch~\cite{toucherFeedback}.

For human-human initiating and receiving interactions, there has been significant research into replicating remote handshakes in virtual environments using a robot to provide the haptic feedback%, with human-robot handshake systems being a notable focus
~\cite{DH32, DH33, DH34}. These systems facilitate remote communication~\cite{DH35, DH36, DH37}, especially by incorporating tactile modalities to achieve multimodality~\cite{DH38}. Haptic feedback devices have also been developed to provide remote handshake sensations~\cite{tong2024distant, DH39, DH40, DH42}.

Emotional responses to social touch in a two-user VR scenario (human-human, receiving and initiating) were investigated in~\cite{sykownik2020experience}, highlighting how factors like intimacy, touch direction, and participant sex influence these reactions. Although emotional responses mirrored those of physical touch, the study relied on minimal haptic feedback, using a simple vibration from a Vive VR controller for the person initiating touch (toucher) only. In~\cite{ST7}, vibrotactile feedback provided to a user's shoulder (touchee only) in multi-user VR (human-human, receiving) did not increase willingness to engage in embarrassing social situations; however, it enhanced the perceived realism of touch, emphasizing the importance of tactile cues in virtual interactions. A more recent study~\cite{peng2024impact} (human-human, receiving and initiating) explored the effects of vibrotactile feedback on Autonomous Sensory Meridian Response (ASMR) experiences in a two-person VR environment. The findings showed that vibrotactile feedback enhances relaxation, comfort, and enjoyment while increasing avatar embodiment and immersion. In this case, only the touchee (viewer) received tactile feedback through a bHaptics vest, arm, and gloves, while the toucher (ASMRtist) did not.

This review highlights that previous studies have rarely examined emotional responses in direct human-to-human interactions within a receiving-and-initiating setting, where real-time haptic feedback is provided simultaneously to both the toucher and the touchee in VR. Most existing research has focused on aspects such as the haptic experience of touch, touching behavior, and behavioral responses.
To the best of our knowledge, no VR application utilizing devices from the aforementioned works has been developed to enable live, real-time multi-user human-to-human mediated touch. Specifically, systems capable of providing multi-point haptic feedback for both the toucher and the touchee, allowing them to convey or receive emotions or perform gestures such as stroking, patting, or poking in VR, have not yet been demonstrated or systematically studied.

\subsection{Research Questions}

A two-part experimental study was conducted to address three primary research questions: 
\textbf{RQ1}: \textit{How effectively can users convey social touch gestures remotely through the VR system with and without tactile feedback?}
\textbf{RQ2}: \textit{What are the affective and sensory experiences associated with remote social touch gestures, both from the perspective of the initiator (toucher) and the recipient (touchee) in real-time VR interactions?}
\textbf{RQ3}: \textit{How does the VR system perform in terms of usability, user embodiment, sense of presence, and cybersickness?}


% \begin{itemize}
%     \item Developed a standalone multiplayer VR application supporting up to 16 users from different geographical locations, enabling them to interact with virtual objects and each other in a shared virtual space.
%     \item Designed and implemented basic collision detection algorithms to generate haptic feedback for interactions:
%     \begin{itemize}
%         \item Between virtual avatars and virtual objects.
%         \item Between virtual avatars during direct interaction.
%     \end{itemize}
%     to both the ``toucher" and the ``touchee", currently limited to hands and forearms only.
%     \item Created a standalone implementation deployable directly on Meta VR headsets and ensured device-agnostic compatibility by enabling wireless communication with any tactile device via WiFi.
%     \item Investigated the ability and affective perception of initiating and receiving remote social touch in our VR application with the developed tactile wearables.
%     \item Investigated how users (touchees) actually perceive social touch gestures when performed in real-time by another user (toucher) in VR remotely with and without haptic feedback through the developed wearable vibrotactile glove and sleeve.
% \end{itemize}

\section{System Design}

\subsection{Multiplayer VR Environment}
% Our multi-user VR system was developed in Unity 3D. We use Meta Quest 2 and 3 for rendering the VR. We are using Photon Fusion for multiplayer in Unity (add details here). In addition to allowing multiplayer mode, it allows voice chat too. We use Meta's Avatar SDK for avatar rendering, i.e. to represent the player as an avatar in VR. We have the option for the player to choose which avatar they want to pick. Our VR uses Meta's hand tracking support and controller support both. Multiple users can join our VR room/virtual space. They can join from different physical geographical locations as long as they have the app and are connected to the internet. It is a simple scene of a room where we have a table and all the objects on the table are interactable by all the players in the scene. The multiplayer mode can host up to XXX players at a time. Users are free to move around in the scene - either physically or using the controller joystick if they cannot move around in the physical space.
We developed our multi-user VR system using Unity 3D, targeting the Meta Quest headsets for rendering. Our system supports both controller inputs and hand tracking, leveraging Meta's hand tracking technology. For avatar representation, we use Meta's Avatar SDK, which allows users to select and customize their avatars. We integrated Photon Fusion, a high-performance networking engine that supports seamless synchronization and networked physics, for real-time multiplayer interactions. Photon Fusion enables multiplayer capabilities and provides built-in voice chat functionality, so users can communicate verbally within the virtual environment.

Multiple users can join our virtual space from different physical or geographical locations, provided that they have the application on their headset and a stable internet connection. The VR application we developed is designed to be a standalone application on the Meta headsets and can also be run in Quest Link or Air Link modes. The VR environment is designed as a simple room that contains a table with various interactable objects that all players can manipulate collaboratively or individually. The main aim of the VR application is to facilitate multi-user human-human social touch. Users are free to navigate the scene either by physically moving within their play area or using the controller's joystick for locomotion if physical space is limited. Our multiplayer mode can host up to 16 players simultaneously.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{Figures/HardwareOnly.png}
    \captionsetup{belowskip=-10pt}
    \caption{(A) Glove and sleeve with 26 ERMs, (B) Control unit consisting of 2 stacked PWM shields, an Arduino Uno R4 WiFI, and an integrated power bank, (C) Spatial arrangement of actuators across the hand and forearm when the glove and sleeve are worn}
    \label{fig:hardware}
\end{figure}
\begin{figure*}[t!]
    \centering
    % Subfigure 1
    \begin{subfigure}[t]{0.54\textwidth}
        \centering
        \includegraphics[width=\columnwidth]{Figures/VRSshots.png}
        \caption{Stills from the VR showing: (A) Spheres attached to the hands and lower arms to detect collision, (B) Visual representation of touch interactions between the hand and forearm. The spheres are not shown to users when they are (C), (D) interacting with each other in VR, and (E) with other virtual objects in the VR environment}
        \label{fig:VRSshots}
    \end{subfigure}
    \hfill
    % Subfigure 2
    \begin{subfigure}[t]{0.425\textwidth}
        \centering
        \includegraphics[width=\columnwidth]{Figures/Collision1.png}
        \caption{Sphere Colliding with a Virtual Object, where $r$: radius of sphere, $S_p$: distance from point of initial point of contact on surface of object, $D$: maximum penetrable distance, \textit{PDI}: Penetration Depth Information; Green dot: center of sphere, Red dot: first point of collision of sphere with virtual object}
        \label{fig:Collision1}
    \end{subfigure}
    \caption{Visualization of the VR environment interactions and collision dynamics}
    \label{PDI_diagram}
\end{figure*}
\subsection{Collision Information}\label{CollisionInformation}
In our VR setup, avatar collisions are detected using a system of colliders attached to spherical structures that represent joints on the avatar. These spheres, distributed based on the number of actuators in our haptic device, allow for a tailored mapping of tactile feedback. If another device can support a higher tactile resolution/contact points, then there is always an option to add more depending on the number of actuation points of the device.
The developed glove incorporates 14 ERMs across the hand, inspired by the design principles outlined in~\cite{ariza2016inducing}, and 12 ERMs across the lower arm (6 dorsal, 6 volar) inspired by the design principles in~\cite{israrForearm} to ensure continuous, smooth, pleasant motion. These actuators are placed to align with neurological aspects, particularly focusing on the fast-adapting Pacinian corpuscles in the fingers and palm, which are highly responsive to vibrations. Following the approach in \cite{ariza2016inducing}, actuators are distributed to balance device mobility, power consumption, and user comfort, ensuring a functional and unobtrusive wearable device. 

Each finger is equipped with two actuators, one at the fingertip or just above the distal interphalangeal joint, and another just below the proximal interphalangeal joint. Four actuators are placed on the palm, with two below the metacarpophalangeal joints of the index and pinky fingers, one near the carpometacarpal joint, and one just above the wrist joint. Placing a vibration motor in the center of the palm was avoided, as it may not maintain contact with the skin in certain hand postures~\cite{giannopoulos2012touching}.
%We have six actuators installed on the dorsal side of the forearm (when the palm is facing down) and six actuators on the ventral side (when the palm is facing up). 
The forearm contains six actuators each on the dorsal and ventral sides, spanning a 14 cm distance, as configured in~\cite{israrForearm}. There are a total of 26 ERM actuators distributed across each hand (14) and forearm (12), as shown in Figure~\ref{fig:hardware}, creating 52 ERMs in total for each user (left and right hands combined).

We control the ERM actuators using Pulse Width Modulated (PWM) signals, which correspond to the amplitude or intensity of the vibration. These signals were optimized in an initial pilot study involving 8 participants. This optimization aimed to ensure that the vibrations effectively conveyed the desired information while remaining pleasant at the same time. Two key parameters were accounted for: (1) user comfort, as prolonged exposure to continuous vibrations was anticipated, and (2) perceptual variability, ensuring the range was sufficiently wide to allow users to reliably perceive changes in vibration intensity based on the desired information conveyed. %These values and ranges will be referred to in the subsequent discussion.

Our algorithm for detecting and encoding collision information for haptic feedback operates as a two-stage process. In addition to simply identifying the occurrence of a collision (binary yes/no), the algorithm encodes quantitative information about the degree of contact, specifically the amount or distance penetrated into a virtual object. The data sent to each microcontroller consists of a string containing the actuator ID, indicating which actuator should be actuated, alongside collision information that prompts actuation of the specified actuator via the ID. This collision information consists of the Penetration Depth Information (PDI), the contact normal, and a flag that indicates if a collision occurred for the first time. For the remainder of this paper, PDI that is sent over to the microcontroller will be defined as the difference between the maximum possible penetration distance and the distance from the point of initial contact on the surface of the object, as shown in Figure~\ref{fig:Collision1}. 

Each sphere in arrays on the hand and arm is equipped with colliders and tagged to distinguish them from other colliders that do not belong to the spheres specifically attached to the avatar. Upon initial contact with any other collider, we send the collision information to the microcontroller with the PDI set to 0, and set the flag variable to 1 or ``true". This indicates that it is a first-time contact. For our wearable device, the ERM corresponding to the colliding sphere is programmed to produce a short, sharp vibration pulse at the maximum possible amplitude, providing a tactile ``click" sensation that signals the beginning or making of contact. This feature allows users to feel a discrete, high-amplitude pulse upon tapping. If the sphere continues to remain in contact, The flag variable is set to 0 or ``false" immediately after, indicating that it is no longer first contact.

% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=\columnwidth]{Figures/VRSshots.png}
%     %\captionsetup{belowskip=-15pt}
%     \caption{}
%     \label{PDI_diagram}
% \end{figure}

% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=0.7\columnwidth]{Figures/Collision1.png}
%     %\captionsetup{belowskip=-15pt}
%     \caption{Visual depiction of a Sphere Colliding with a Virtual Object, where $r$: radius of sphere, $S_p$: distance from the point of initial point of contact on the surface of the object, $D$: maximum penetrable distance, \textit{PDI}: Penetration Depth Information; Green dot: center of the sphere, Red dot: first point of collision of the sphere with the virtual object}
%     \label{PDI_diagram}
% \end{figure}

\emph{\textbf{Interacting with Virtual Objects:}} When the user touches a virtual object (which is not a sphere attached to the avatar), if the sphere continues to remain in contact with the collider without pressing further, the PDI is sent as the difference between the maximum possible penetration distance and the distance from the initial contact point on the surface of the object that the sphere collides with. The corresponding ERM begins a continuous vibration but at a reduced amplitude (12\% duty cycle for the hand,  24\% duty cycle for the arm). As the user presses into the collider, the vibration amplitude increases linearly as the PDI decreases. The vibration amplitude is highest (25\% duty cycle for the hand and 50\% for the arm) when the maximum possible penetration distance is reached (i.e. when PDI is 0). Each virtual object in the VR scene has a predefined stiffness, which determines the maximum penetration distance: higher stiffness correlates with a shorter maximum penetrable distance. Once this maximum possible penetration depth is reached, the ERM maintains the highest vibration amplitude, reflecting the resistance of stiffer objects.

If the virtual object is ``grabbable" in the virtual environment and the algorithm detects the user performing a ``grabbing" action, such as picking up the object or holding it in their hand, rather than merely pressing against it while it remains static, the haptic feedback transitions accordingly. Following the initial ``click" sensation, the vibration amplitude is gradually reduced until it reaches a minimal level (12\% duty cycle for the hand). This gradual attenuation of vibrations provides the user with the sensation of holding or grasping the object while mitigating discomfort or unpleasantness caused by prolonged continuous high-intensity vibrations.

\emph{\textbf{Interacting with other Avatars: }} Each avatar has spheres attached to their fingers and forearms, corresponding to the ERMs, which serve as the points of interaction. The radius of the spheres attached to the fingers are smaller in comparison to those across the forearm. On the forearm, larger spheres are used to cover a broader surface area, to ensure smooth, continuous, and consistent vibrations across the skin. In contrast, the smaller spheres on the fingers provide greater precision and accuracy, accommodating the higher density of actuation points required for interactions in a more localized area. When two virtual avatars interact, the collision information between their respective spheres triggers vibrations. The vibration intensity is designed to reflect the extent of their overlap. The constant maximum penetrable distance is set to a constant value, which is the diameter of the smaller sphere involved in the collision.

At the point of initial contact, vibrations are triggered with a minimum amplitude (12\% duty cycle for the hand and 24\% duty cycle for the lower arm). As the overlap increases, the vibration amplitude scales linearly, reaching its maximum when the smaller sphere penetrates another smaller or larger sphere by a depth equal to its own diameter. This design ensures that when two small spheres collide, the maximum amplitude (24\% duty cycle) is achieved when the spheres are completely overlapping. When a larger sphere (attached to the lower arm) interacts with a smaller sphere, or when two larger spheres interact, maximum vibration amplitude (50\% duty cycle) is reached when the smaller sphere is fully enclosed within the larger one or when the larger spheres overlap each other by a distance equal to the smaller sphere's diameter.

When no collision happens, no information is sent over to the microcontroller, and the flag variable is reset to 1 or ``true", indicating that whenever the next collision happens, it will again collide for the first time.

\subsection{Hardware Setup}

The system is designed to be wireless and plug-and-play, making it adaptable to any tactile device that supports WiFi connectivity and/or serial communication. For controlling the wearables that we developed, we employed the Arduino Uno R4 WiFi microcontroller, with two separate microcontrollers connected to the same WiFi network as the VR headset -- one designated for the left hand and the other for the right hand. For each hand, a user is equipped with a haptic glove, a forearm sleeve, an Arduino Uno R4 WiFi module, two 16-Channel 12-bit PWM shields (Adafruit, PCA9685) that are stacked on top of each other on top of the Arduino (Figure~\ref{fig:hardware}), a 5V 10000mAh power bank that is capable of powering the glove, sleeve, Arduino, and the PWM shields, and a running armband that securely houses the power bank along with all associated electronic components. This makes our hardware easily wearable and portable, without needing to be connected to an external computer or power source. Furthermore, the gloves and sleeves we use are made of quality spandex, a soft and smooth material that is comfortable to wear, designed to be breathable, and fits a large variety of hand sizes.

Each microcontroller together with the PWM shields is configured to drive simple 11000 RPM 5V vibration motors or ERMs (Adafruit, 1528-1177-ND) integrated into the hand gloves and armbands. ERMs were chosen for their low latency, small form factor, and simplicity of operation in real-time applications. These qualities allow for VR compatibility, ease of integration into wearable designs, and perceptible haptic feedback within a usable range of frequencies and amplitudes. Each ERM is connected to the PWM shield via a transistor, which controls the amount of current flow to generate a wide range of vibrotactile sensations. 
%The intensity of the ERM vibration is modulated by adjusting the duty cycle of a Pulse-Width Modulated (PWM) signal. Different vibration amplitude levels are achieved by sending specific PWM duty cycle values ranging from 0\% (no vibration) to 100\% (maximum intensity vibrations) over a WiFi connection. The frequency of vibration is regulated by toggling the ERM between its desired PWM intensity and its off state. This also allows for generating various vibration patterns by modulating the signal amplitude and frequency. 

\subsection{Wireless Communication}
To identify and communicate with each device over WiFi, each microcontroller sends an initial User Datagram Packet (UDP) containing its identifier, i.e. ``left” or ``right” hand, along with its local IP address. The Unity application initiates the connection process by broadcasting a message and receiving callbacks from both microcontrollers. Once local IP addresses are obtained, Unity establishes a stable, dedicated connection with each microcontroller for each hand using the Transmission Control Protocol (TCP). TCP was chosen over UDP to ensure reliable packet delivery.%, as packet loss could disrupt the information sent to the microcontroller, which in turn would disrupt driving the ERMs.

The information sent is maximum 21 bytes, which is well below the Arduino's Maximum Transmission Unit (MTU) limits, ensuring minimal impact on transmission speed and latency. Therefore, if needed, we can append and transmit more information than our algorithm currently does. The PDI is updated in every Unity frame which is set to run at 120 FPS, and the frequency of the entire system (including the refresh rate of the microcontroller) ranges from 100-120 Hz. All calculations of amplitude and frequency are processed on the Arduino. 
Although amplitude and frequency values could be sent directly, the choice of transmitting collision data provides greater flexibility and universality. Most importantly, this approach enables compatibility with a range of devices, as the information is encoded and sent in such a way that each device can decode the collision data according to its unique actuation mechanism. For example, devices capable of rendering force or pressure may interpret collision data differently than those using voice coil or ultrasonic actuation, ensuring a versatile, device-agnostic solution. In our case we do not make use of the contact normals that are sent, as our device only provides vibrotactile feedback, but it can be useful for devices that provide pressure or force feedback. 
%Alternatively, we can transmit specific amplitude and frequency values for the vibration; however, collision data was chosen for its universality and adaptability. This approach allows the system to be compatible with various tactile devices, as it enables each device to interpret the collision information based on its unique actuation mechanism. For instance, devices capable of rendering force or pressure may interpret collision data differently than devices that rely on voice coil or ultrasonic actuation, thus providing a flexible, device-agnostic solution.

% \subsection{Collision Information}\label{CollisionInformation}
% In our VR setup, avatar collisions are detected using a system of colliders attached to spherical structures that represent joints on the avatar. These spheres, distributed based on the number of actuators in our haptic device, allow for a tailored mapping of tactile feedback. If another device can support a higher tactile resolution/contact points, then there is always an option to add more depending on the number of actuation points of the device.
% The glove developed incorporates 14 ERMs strategically distributed across the hand, inspired by the design principles outlined in detail in \cite{ariza2016inducing}, and 12 ERMs across the lower arm (6 dorsal, 6 volar) inspired by the design principles outlines in~\cite{israrForearm} to ensure continuous, smooth, pleasant strokes. These actuators are placed to align with neurological aspects, particularly focusing on the fast-adapting Pacinian corpuscles (PC) in the fingers and palm, which are highly responsive to vibrations. Following the approach in \cite{ariza2016inducing}, actuators are distributed to balance device mobility, power consumption, and user comfort, ensuring a wearable device that is functional and unobtrusive. 

% Each finger is equipped with two actuators, one at the fingertip or just above the distal interphalangeal joint, and another just below the proximal interphalangeal joint. Four actuators are positioned on the palm, with placements including two below the metacarpophalangeal joints of the index and pinky fingers, one near the carpometacarpal joint, and one just above the wrist joint. Placing a vibration motor in the center of the palm was avoided, as it may not maintain contact with the skin in certain hand postures~\cite{giannopoulos2012touching}.
% %We have six actuators installed on the dorsal side of the forearm (when the palm is facing down) and six actuators on the ventral side (when the palm is facing up). 
% The forearm contains six actuators each on the dorsal and ventral sides, spanning a 14 cm distance, as configured in~\cite{israrForearm}. There are a total of 26 ERM actuators distributed across the hand (14) and forearm (12), and thus, 52 ERMs in total for each user (left and right hands).

% For the next paragraphs, the PWM value ranges mentioned corresponding to the amplitude or intensity of vibration for each ERM, across the hand and forearm, were optimized in an initial pilot study involving 8 participants. This optimization aimed to ensure the vibrations effectively conveyed the desired information while remaining pleasant to perceive at the same time. Two key parameters were accounted for: (1) user comfort, as prolonged exposure to continuous vibrations was anticipated, and (2) perceptual variability, ensuring the range was sufficiently wide to allow users to reliably perceive changes in vibration intensity based on the desired information conveyed. These values and ranges will be referred to in the subsequent discussion.

% Our algorithm for detecting and encoding collision information for haptic feedback operates as a two-stage process. In addition to simply identifying the occurrence of a collision (binary yes/no), the algorithm encodes quantitative information about the degree of contact, specifically the amount or distance penetrated into a virtual object, enabling a more nuanced representation of collision events. Each sphere in the hand and arm sphere array is equipped with colliders and tagged to distinguish them from other colliders that do not belong to the spheres specifically attached to the avatar. Upon initial contact with any other collider, we send the collision information to the microcontroller with the PDI set to 0, and flag variable set to 1 or ``true". This indicates that it is a first-time contact. For our wearable device, the ERM corresponding to the colliding sphere is programmed to produce a short, sharp vibration pulse at the maximum possible amplitude, providing a tactile ``click" sensation that signals the beginning or making of contact. This feature allows users to feel a discrete, high-amplitude pulse upon tapping. If the sphere continues to remain in contact, The flag variable is set to 0 or ``false" immediately after, indicating that it is no longer first contact.
% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=0.7\columnwidth]{Figures/Collision1.png}
%     %\captionsetup{belowskip=-15pt}
%     \caption{Visual depiction of a Sphere Colliding with a Virtual Object, where $r$: radius of sphere, $S_p$: distance from the point of initial point of contact on the surface of the object, $D$: maximum penetrable distance, \textit{PDI}: Penetration Depth Information; Green dot: center of the sphere, Red dot: first point of collision of the sphere with the virtual object}
%     \label{PDI_diagram}
% \end{figure}

% \emph{\textbf{Interacting with Virtual Objects:}} When the user touches a virtual object (which is not a sphere attached to the avatar), if the sphere continues to remain in contact with the collider without pressing further, the PDI is sent as the difference between the maximum possible penetration distance and the distance from the initial contact point on the surface of the object that the sphere collides with. The corresponding ERM begins a continuous vibration but at a reduced amplitude, typically around 12\% duty cycle for the hand and 24\% duty cycle for the arm. As the user presses into the collider, the vibration amplitude increases as the PDI decreases. The vibration amplitude is highest (25\% duty cycle for the hand and 50\% for the arm) when the maximum possible penetration distance is reached (i.e. when PDI is 0). Each virtual object in the VR scene has a predefined stiffness, which determines the maximum penetration distance: higher stiffness correlates with a shorter maximum penetrable distance. Once this maximum possible penetration depth is reached, the ERM maintains the highest vibration amplitude, reflecting the resistance of stiffer objects.

% If the virtual object is ``grabbable" in the virtual environment and the algorithm detects the user performing a ``grabbing" action - such as picking up the object or holding it in their hand - rather than merely pressing against it while it remains static, the haptic feedback transitions accordingly. Following the initial ``click" sensation, the vibration amplitude is gradually reduced until it reaches a minimal level (12\% duty cycle for the hand). This gradual attenuation of vibrations provides the user with a sensation of holding or grasping the object while mitigating discomfort or unpleasantness caused by prolonged continuous high-intensity vibrations.

% \emph{\textbf{Interacting with other Avatars: }} Each avatar has spheres attached to their fingers and lower arms, corresponding to the ERMs, which serve as the points of interaction. When two virtual avatars interact, the collision information between their respective spheres triggers vibrations. The vibration intensity is designed to reflect the extent of their overlap. The constant maximum penetrable distance is set to a constant value, which is the diameter of the smaller sphere involved in the collision.

% At the point of initial contact, vibrations are triggered with a minimum amplitude: 12\% duty cycle for the hand and 24\% duty cycle for the lower arm. As the overlap increases, the vibration amplitude scales linearly, reaching its maximum when the smaller sphere penetrates another smaller or larger sphere by a depth equal to its own diameter. This design ensures that when two small spheres collide, maximum amplitude (24\% duty cycle) is achieved when the spheres are completely overlapping. When a larger sphere (attached to the lower arm) interacts with a smaller sphere, or when two larger spheres interact, maximum vibration amplitude (50\% duty cycle) is reached when the smaller sphere is fully enclosed within the larger one or when the larger spheres overlap each other by a distance equal to the smaller sphere's diameter.

% When no collision happens, no information is sent over to the microcontroller, and the flag variable is reset to 1 or ``true", indicating that whenever the next collision happens, it will again collide for the first time.

%This two-stage collision detection and haptic feedback mechanism enable a nuanced tactile experience, allowing for both sharp contact signals and continuous pressure-based feedback.
%Our algorithm for detecting collision information is two-fold. Each sphere for the hand and arm sphere array has colliders attached to it. When the spheres first come in contact with another collider, they send a sharp vibration pulse at the highest amplitude that indicates that contact has taken place. That means, if someone were to use their fingers to tap, they would receive sharp vibration pulses or clicks at the highest amplitude simulating the tapping information. Following that, if they were to stay on the surface of the collider, then the LRA corresponding to that sphere would slowly start vibrating constantly, i.e. at its resonant frequency, but a lower amplitude of around 60 on a scale of 0-255. If then the user presses into the collider, then the amplitude keeps linearly increasing w.r.t how much it has travelled into the collider from the surface or point of initial contact on the surface. If a sphere (attached to one of the joints) interacts with a virtual object, the maximum penetrable distance is set depending on the stiffness of the virtual object. Higher the stiffness, lower the maximum penetrable distance. The LRAs continuously vibrate at the highest amplitude when they reach the maximum penetrable distance. The amplitude increases linearly from the point of initial contact on the surface to the maximum penetrable distance. Since when interacting with other avatars, we are sending information of how much one sphere is colliding with another sphere, we set a constant maximum penetrable distance if a sphere is colliding with another sphere. We set that distance as the radius of the smallest sphere, i.e. those attached to the fingers. So the vibrations start at the amplitude of around 60 when the spheres are in contact with one another (point of initial contact on the surface), and then keep increasing when the spheres overlap, and is maximum (255) when the centre of the smaller sphere penetrates into the other sphere by a distance from point of initial contact on the surface equal to the radius of the smaller sphere. So if a small sphere is colliding with another small sphere, then their corresponding LRAs will vibrate at the highest amplitude when they are completely overlapping. But when a small sphere is colliding with a bigger sphere (e.g. on the arm), then their corresponding LRAs will vibrate at the highest amplitude when the smaller sphere is completely inside the larger sphere, or in other words when the penetration distance measured from the centre of the smaller sphere to the point of initial contact of the larger sphere is equal to the raidus of the smaller sphere.


%Write about the software used, communication protocols, algorithms too maybe?

%Write about hardware built for the project using LRAs. 2 devices corresponding to 2 sets of users.

\section{Experimental Methods}

We developed four haptic glove and sleeve prototypes to facilitate bilateral interactions between two users and provide haptic feedback to both users on each hand and forearm (left and right). %Our study aimed to address three primary objectives: 1) Assess the ability of users to convey social touch gestures remotely using the VR system with haptic feedback; 2) Investigate the affective perception of touch gestures by the toucher and touchee when initiating or receiving these gestures in real time; 3) Evaluate the system's overall performance in terms of usability, user embodiment, presence, and cybersickness.

We conducted a two-part user study with experiments involving two participants, each located in separate physical spaces. The order of the two experiments in this study design was counterbalanced across participant pairs to mitigate order effects.
\textit{Part 1: Prescribed Touch} - Participants engaged in a structured task where the toucher performed specific touch gestures on the touchee as directed by the experimenter. 
\textit{Part 2: Free-Form Interaction} - In this exploratory task, participants interacted freely with each other and with other virtual objects within the VR environment.
%We developed 4 sets of the haptic glove + sleeve prototype - one for each hand of each user, and for a total of 2 users. We did our experiments using two users in our VR system. Our goal was to: 1) determine if people could convey social touch gestures remotely using our VR system, while themselves being in two different physical spaces, 2) how the touchee/toucher would affectively perceive these physical gestures when receiving/initiating in real-time over VR with haptic feedback, 3) to evaluate the system overall for its usability, user embodiment, presence, and cybersickness. We did a 2-part user study, counterbalanced across participants to prevent any order effect. The first part was a prescribed touch experiment where touchers had to perform gestures to the touchee as directed by the experimenter. In the second experiment, the two users were free to explore the environment and interact with each other, with the condition being that there should be some form of physical touch involved via the hand or forearm.

\subsection{Participants}
In this study, pairs of individuals participated in the study together. 
Since people had to interact through touch and perform gestures such as stroking, poking, patting and squeezing, we recruited pairs of participants who had a current relationship (i.e., friends, family, or romantic partners)~\cite{thompson2011effect}. 
In total, 12 participants (6 female, 5 male, 1 non-binary, $M_{age} = 25 \pm 3.22$), were recruited for the study, of which 2 had prior experience with haptic devices and VR. None of the participants had sensory or motor impairments. The study was approved by the University XX Institutional Review Board under protocol XXXX, and all participants gave informed consent. Participants wore noise-cancelling earphones connected to the VR headset, which mitigated noise from the ERMs; the earphones also delivered audio from the VR simulation for Experiment 2 only. To eliminate potential auditory bias, audio feedback was intentionally removed for Experiment 1.

\subsection{Procedure}
Experiments 1 and 2 were evenly balanced across all pairs of participants to eliminate any potential order effects. Half of the pairs of participants performed Experiment 1 first, followed by Experiment 2, while the remaining half performed Experiment 2 first, followed by Experiment 1. In both the experiments, we utilized two avatars from the Meta Avatar SDK pack. The exploration of variables such as appearance, gender, skin tone, facial expressions, or other avatar characteristics is beyond the scope of this study. To minimize bias or personalization, participants were informed that the avatars might not resemble their actual selves.

\subsubsection{\textbf{Experiment 1 -- Prescribed Touch}} 
This experiment assessed the ability of our VR application, in combination with the developed haptic glove and sleeve, to facilitate the remote communication of social touch gestures. The experiment involved a structured task where the toucher, guided by the experimenter, performed four predefined gestures - stroke, pat, poke, and squeeze~\cite{hertenstein2009communication} - on the touchee. A within-subjects experiment was conducted, wherein participants alternated roles as the toucher and the touchee. Participants were asked to complete the gestures at three distinct speeds: slow (S), medium (M), and fast (F). Participants performed these gestures under two feedback conditions: (1) visual feedback only (V) and (2) combined visual and haptic feedback (VH). The 24 trials (4 gestures $\times$ 3 speeds $\times$ 2 feedback) were counterbalanced using a Graeco-Latin square design to preclude any potential order effects. Consequently, a participant pair performed 48 trials (24 $\times$ 2 user modes) in total. During each trial, participants were instructed to perform the gesture three times, and were instructed to not verbally communicate with each other in VR. %for this task. 

Before starting the experiment, each toucher underwent a training phase of approximately 5 minutes, during which they were shown and asked to practice performing poke, pat, squeeze and stroke gestures on a static avatar's arm, receiving visual feedback only (no haptic feedback). The medium (M) speed was chosen as the normal speed at which users would typically perform the gesture. For the other two speeds, slow (S) and fast (F), users were asked to perform the gesture at a speed significantly slower and faster than the medium (M) speed. Only during the training phase were the real-time hand velocities and mean velocity for each gesture performed as visual feedback to all participants. This was intended to help them better assess the relative speed of their movements and maintain consistency throughout the experiment.

% In the actual experiment, each gesture was performed at 3 different speeds under 2 different conditions, resulting in a total of 24 gestures performed by each toucher. Consequently, a participant pair performed 48 gestures in total. Performing each gesture (three times at each speed under each feedback condition) and answering the associated questions during the experiment took about 2 minutes on average. 
A 10-minute break was provided when participants exchanged roles as the toucher and touchee. Thus, each participant pair completed the entire experiment in approximately 1 hour and 30 minutes.

\emph{\textbf{Experimental Measures:}}
To investigate the relationship between participants' real-world comfort with interpersonal touch and their experience of virtual social body contact, we administered the Comfort with Interpersonal Touch (CIT) questionnaire~\cite{webb2015individual} prior to the experiment. %This questionnaire required participants to rate six items on a 7-point Likert scale ranging from \textit{strongly disagree} to \textit{strongly agree}. 
To monitor potential cybersickness, participants also completed the Simulator Sickness Questionnaire (SSQ)~\cite{kennedy1993simulator} both before and after the experiment.

During the experiment, we collected both objective and subjective data. From the toucher, we recorded the real-time trajectory of the hand (3D position) and the velocity within the VR environment. We also recorded the different speeds at which the toucher performed the gestures. For stroking, we calculated the mean velocity at which the toucher performed the gesture in $cm/s$. For squeeze, poke and pat, we measured the time taken to perform each gesture 3 times for each speed and each feedback condition, and then averaged them to calculate the number of squeezes/second, pokes/second, or pats/second. 

After initiating/receiving each gesture, both toucher and touchee provided feedback through the following subjective measures in VR: (a) Emotional responses -- Valence and Arousal -- on a 2D Valence-Arousal Emojigrid ranging from -1 to +1~\cite{toet2019emojigrid}, (b) \textbf{S1 (Plausibility\footnote{Degree to which the haptic feedback aligns with user's expectations of how something should feel, in relation to visual cues or the user's prior experience}):} \textit{The touch sensation I felt in my body corresponded to the virtual touch I saw}, (c) \textbf{S2 (Pleasantness):} \textit{How `pleasant' did the interaction feel?}, and (d) \textbf{S3 (Naturalness):} \textit{How `natural' did the interaction feel?} Ratings for (b), (c) and (d) were provided on a 7-point Likert scale, where 1 = \textit{not at all} to 7 = \textit{very much so}. %These are our Dependent Variables (DVs).

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{Figures/VR_4.png}
    \captionsetup{belowskip = -15pt}
    \caption{Interactable virtual objects and 2D Valence-Arousal Emojigrid~\cite{toet2019emojigrid}}
    \label{fig:enter-label}
\end{figure}
To evaluate participants’ sense of presence in the VR environment, we administered the Slater-Usoh-Steed (SUS) questionnaire~\cite{slater1998,usoh1999}, rephrased for VR, at the end of the experiment. %This 6-point instrument, scored on a 7-point Likert scale, was chosen for its focus on measuring the sense of ''being there" in virtual environments with fewer items, making it less susceptible to cognitive biases and better suited for rapid assessments. 
Additionally, first-time touchers (participants who had not previously been touchees) answered an open-ended question: \textit{``What visual indications did you compare the performed touch gestures to?”}

%This experiment addressed the ability of our VR application along with the developed haptic glove and sleeve to communicate social touch gestures remotely. In this experiment, the toucher was directed by the experimenter to perform three gestures - stroke, pat, and poke - on the touchee. The toucher had to perform these three gestures at three different speeds - slow, medium and fast - once with visual feedback only (V), and once with visual + haptic feedback (VH). 

%We measured the comfort with receiving and initiating interpersonal touch of the participants to evaluate if this real-world trait is associated with the experience of virtual social body contact. Participants filled out the Comfort with Interpersonal Touch (CIT) questionnaire that requires to rate 6 items on a 7-point Likert-scale ``\textit{strongly disagree}" to``\textit{strongly agree}"[ST62], prior to the experiment. They also filled out the Simulator Sickness Questionnaire (SSQ) pre and post the experiment. 
%During the experiment, we recorded objective data of the toucher from within the VR - hand trajectory (3D position data) and velocity. We also gathered the following subjective data from both the toucher and touchee, after each gesture was performed: (a) Rate their emotions felt after initiating/receiving the touch gesture on a 2D Valence-Arousal grid, (b) ``\textit{How closely did the touch match the visual indication of the gesture?}" This was rated on a 7-point Likert scale, 1 being \textit{not at all} and 7 being \textit{very much so}, (c) "How pleasant did the interaction feel?", and (d) "How natural did the interaction feel?" ((c) and (d) were also scored on a 7-point Likert scale similar to (b)).
%After completion of the experiment, we asked participants to fill out the Slater-Usoh-Steed (SUS) questionnaire that also requires to rate 6 items on a 7-point Likert-scale, that allowed us to measure their sense of presence in the VR. Additionally, we asked every participant an open question at the end, "What visual indications did you compare the touch gestures performed to?"

\subsubsection{\textbf{Experiment 2 -- Free Interaction}}
Participants were instructed on the proper usage of the gloves and sleeves, as well as the procedure for launching the VR application on the Meta Quest headset. Following this, they were asked to independently don the hardware and initiate the VR application without further assistance. After launching the VR application, participants were asked to explore and interact freely within the VR environment, the only condition being that they find a way to interact with each other through touch using their hands or lower arms. If direct interaction felt uncomfortable or unnatural, participants were encouraged to create a secret handshake that involved their hands and/or lower arms. Beyond this requirement, participants were free to interact with other virtual objects or collaboratively perform tasks of their choice. The experiment was conducted under two feedback conditions, counterbalanced to preclude any order effects: (1) visual feedback only (V) and (2) combined visual and haptic feedback (VH). Each free exploration session lasted 10 minutes, with a 5-minute break between feedback conditions. The total duration of the experiment was 25 minutes. Participants were allowed to verbally communicate with each other in VR during the task.

%We used the Unidimensional Relationship Closeness Scale (URCS) questionnaire, which measures the closeness of a person's social and personal relationships, to assess the level of intimacy or connection between participant pairs both pre- and post-experiment. This allowed us to evaluate whether our VR system influenced the closeness between participant pairs. Additionally, 
\emph{\textbf{Experimental Measures:}}
We used the Embodiment Questionnaire~\cite{peck2021avatar} to measure how strongly participants felt connected to their virtual avatars in the VR system, the SUS questionnaire, rephrased for VR, to assess presence, and the SSQ both pre- and post-experiment to monitor cybersickness. To evaluate the perceived usability of our VR system, participants were asked to complete the System Usability Scale questionnaire~\cite{brooke1996sus}. All of these questionnaires were administered for both the V and VH conditions. After the VH condition, participants documented their haptic experience (HX) using the 5-point Likert scale questionnaire from~\cite{anwar2023factors}.

\section{Results}
% We conducted a series of statistical tests to analyze the data from the two experiments. 
\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{Figures/Minimized_labels_2.png}
    %\captionsetup{belowskip=-15pt}
    \caption{Prescribed Touch Experiment: Ratings of both toucher and touchee across different speeds, user modes, and feedback conditions for each gesture performed}
    \label{}
\end{figure*}

No order effects were observed across Experiments 1 and 2, the results were consistent regardless of whether participants completed Experiment 1 or Experiment 2 first.

\subsection{Experiment 1 -- Prescribed Touch}
% There were 4 gestures performed (Stroke, Poke, Pat, Squeeze), 3 different speeds (S, M, F), 2 Feedback Modalities (V, VH), and 2 User Modes (\textit{Toucher} and \textit{Touchee}). Our DVs were - \textit{Valence}, \textit{Arousal}, \textit{S1} (correspondence of touch sensation to virtual touch), \textit{S2} (Pleasantness) and \textit{S3} (Naturalness). 
\subsubsection{Subjective Measures} For each gesture (Stroke, Poke, Pat, Squeeze) that was performed, we conducted separate 3-way ANOVAs to analyze the effect of Speed (S, M, F), Feedback Modality (V, VH), and User Mode (\textit{Toucher}, \textit{Touchee}) on the \textit{Valence}, \textit{Arousal}, \textit{S1} (Plausibility), %(correspondence of touch sensation to virtual touch)
\textit{S2} (Pleasantness) and \textit{S3} (Naturalness).

\begin{table*}[]
\caption{Tukey's HSD Post Hoc Analysis Results across the different Speed conditions for each Gesture performed}
\label{TablePostHoc}
%\setlength{\tabcolsep}{2pt}
\renewcommand{\arraystretch}{1.7}
\resizebox{\textwidth}{!}{%
\fontsize{20}{20}\selectfont
\begin{tabular}{|c|ccc|ccc|ccc|ccc|}
\hline
\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Dependent\\ Variables\end{tabular}}} & \multicolumn{3}{c|}{\textit{\textbf{Stroke}}}                                                                                                                                                                                                                         & \multicolumn{3}{c|}{\textit{\textbf{Poke}}}                                                                                                                                                                                                                          & \multicolumn{3}{c|}{\textit{\textbf{Pat}}}                                                                                                                                                                                                                           & \multicolumn{3}{c|}{\textit{\textbf{Squeeze}}}                                                                                                                                                                                                                      \\[10pt] \cline{2-13} 
                                                                                        & \multicolumn{1}{c|}{\textbf{S vs M}}                                                         & \multicolumn{1}{c|}{\textbf{M vs F}}                                                         & \textbf{F vs S}                                                         & \multicolumn{1}{c|}{\textbf{S vs M}}                                                        & \multicolumn{1}{c|}{\textbf{M vs F}}                                                         & \textbf{F vs S}                                                         & \multicolumn{1}{c|}{\textbf{S vs M}}                                                        & \multicolumn{1}{c|}{\textbf{M vs F}}                                                         & \textbf{F vs S}                                                         & \multicolumn{1}{c|}{\textbf{S vs M}}                                                        & \multicolumn{1}{c|}{\textbf{M vs F}}                                                         & \textbf{F vs S}                                                        \\[10pt]\hline
Valence                                                                                 & \multicolumn{1}{c|}{$p > 0.05$}                                                      & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -0.5$ \\ $(p < 0.001)$\end{tabular}}  & \begin{tabular}[c]{@{}c@{}}$\Delta M = 0.43$ \\ $(p < 0.001)$\end{tabular}  & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.18$ \\ $(p = 0.02)$\end{tabular}}          & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -0.16$ \\ $(p = 0.045)$\end{tabular}}         & $p > 0.05$                                                      & \multicolumn{1}{c|}{$p > 0.05$}                                                     & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -0.53$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 0.47$ \\ $(p 0< .001)$\end{tabular}  & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.21$ \\ $(p < 0.001)$\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -0.35$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 0.14$ \\ $(p = 0.036)$\end{tabular}         \\[10pt] \hline
Arousal                                                                                 & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -0.46$ \\ $(p < 0.001)$\end{tabular}} & \multicolumn{1}{c|}{$p > 0.05$}                                                      & \begin{tabular}[c]{@{}c@{}}$\Delta M = -0.66$ \\ $(p < 0.001)$\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.49$ \\ $(p < 0.001)$\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.27$ \\ $(p < 0.001)$\end{tabular}}  & \begin{tabular}[c]{@{}c@{}}$\Delta M = -0.76$ \\ $(p < 0.001)$\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.4$ \\ $(p < 0.001)$\end{tabular}}  & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.26$ \\ $(p < 0.001)$\end{tabular}}  & \begin{tabular}[c]{@{}c@{}}$\Delta M = -0.66$ \\ $(p < 0.001)$\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.39$ \\ $(p < 0.001)$\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -0.22$ \\ $(p = 0.002)$\end{tabular}}         & \begin{tabular}[c]{@{}c@{}}$\Delta M = -0.6$ \\ $(p < 0.001)$\end{tabular} \\[10pt] \hline
Plausibility                                                                                      & \multicolumn{1}{c|}{$p > 0.05$}                                                      & \multicolumn{1}{c|}{$p > 0.05$}                                                      & $p > 0.05$                                                      & \multicolumn{1}{c|}{$p > 0.05$}                                                     & \multicolumn{1}{c|}{$p > 0.05$}                                                      & $p > 0.05$                                                      & \multicolumn{1}{c|}{$p > 0.05$}                                                     & \multicolumn{1}{c|}{$p > 0.05$}                                                      & $p > 0.05$                                                      & \multicolumn{1}{c|}{$p > 0.05$}                                                     & \multicolumn{1}{c|}{$p > 0.05$}                                                      & $p > 0.05$                                                     \\[10pt] \hline
Pleasantness                                                                                      & \multicolumn{1}{c|}{$p > 0.05$}                                                      & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -2.5$ \\ $(p < 0.001)$\end{tabular}}  & \begin{tabular}[c]{@{}c@{}}$\Delta M = 2.67$ \\ $(p < 0.001)$\end{tabular}  & \multicolumn{1}{c|}{$p > 0.05$}                                                     & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -1.21$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 0.71$ \\ $(p = 0.023)$\end{tabular}          & \multicolumn{1}{c|}{$p > 0.05$}                                                     & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -2.96$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 2.79$ \\ $(p < 0.001)$\end{tabular}  & \multicolumn{1}{c|}{$p > 0.05$}                                                     & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -1.71$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 1.42$ \\ $(p < 0.001)$\end{tabular} \\[10pt] \hline
Naturalness                                                                                      & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 0.96$ \\ $(p = 0.003)$\end{tabular}}          & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -3.83$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 2.88$ \\ $(p < 0.001)$\end{tabular}  & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 2.79$ \\ $(p < 0.001)$\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -2.33$ \\ $(p < 0.001)$\end{tabular}} & $p > 0.05$                                                      & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 2.12$ \\ $(p < 0.001)$\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -3.92$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 1.79$ \\ $(p < 0.001)$\end{tabular}  & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = 1.33$ \\ $(p < 0.001)$\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\Delta M = -2.67$ \\ $(p < 0.001)$\end{tabular}} & \begin{tabular}[c]{@{}c@{}}$\Delta M = 1.33$ \\ $(p < 0.001)$\end{tabular} \\[10pt] \hline
\end{tabular}
}
\end{table*}

\textbf{Stroke: }Speed had a main effect on \textit{Valence} ($F(2, 132) = 58.78, p < 0.001, \eta_p^2 = 0.25$), \textit{Arousal} ($F(2, 132) = 36.44, p < 0.001, \eta_p^2 = 0.19$), \textit{Plausibility} ($F(2, 132) = 6.97, p = 0.001, \eta_p^2 = 0.02)$, \textit{Pleasantness} ($F(2, 132) = 77.97, p < 0.001, \eta_p^2 = 0.29$), and \textit{Naturalness} ($F(2, 132) = 116.20, p < 0.001, \eta_p^2 = 0.44$). %Tukey's HSD post hoc analysis revealed significant differences in \textit{Valence} between F and M ($\Delta M = 0.50, p < 0.001$), and F and S ($\Delta M = 0.43, p < 0.001$); for \textit{Arousal}, between F and S ($\Delta M = -0.66, p < 0.001$) and M and S ($\Delta M = -0.46, p < 0.001$); for \textit{S2}, between F and M ($\Delta M = 2.50, p < 0.001$), and F and S ($\Delta M = 2.67, p < 0.001$); for \textit{S3}, between F and M ($\Delta M = 3.83, p < 0.001$), F and S ($\Delta M = 2.88, p < 0.001$), and M and S ($\Delta M = -0.96, p = 0.003$).
Feedback modality had a main effect on \textit{Valence} ($F(1, 132) = 65.17, p < 0.001, \eta_p^2 = 0.14$), \textit{Arousal} ($F(1, 132) = 24.24, p < 0.001, \eta_p^2 = 0.06$), \textit{Plausibility} ($F(1, 132) = 404.59, p < 0.001, \eta_p^2 = 0.58$), \textit{Pleasantness} ($F(1, 132) = 104.82, p < 0.001, \eta_p^2 = 0.20$), and \textit{Naturalness} ($F(1, 132) = 25.70, p < 0.001, \eta_p^2 = 0.05$). %Tukey's HSD revealed significant differences in \textit{Valence} between V and VH ($\Delta M = 0.33, p < 0.001$), \textit{Arousal} between V and VH ($\Delta M = 0.32, p < 0.001$), \textit{S1} between V and VH ($\Delta M = 4.08, p < 0.001$), \textit{S2} between V and VH ($\Delta M = 2.00, p < 0.001$), and \textit{S3} between V and VH ($\Delta M = 1.08, p = 0.002$).
User Mode had no significant main effects on any dependent variables ($p > 0.05$), except for a significant interaction effect with Feedback on \textit{Plausibility} ($F(1, 132) = 9.06, p = 0.003, \eta_p^2 = 0.01$) and \textit{Arousal} ($F(1,132) = 4.45, p = 0.04, \eta_p^2 = 0.01$), and with Speed on \textit{Arousal} ($F(2, 132) = 6.42, p = 0.002, \eta_p^2 = 0.03$) and \textit{Pleasantness} ($F(2, 132) = 3.48, p = 0.033, \eta_p^2 = 0.01$).
Significant interaction effects were observed for Speed and Feedback on \textit{Valence} ($F(2, 132) = 6.54, p = 0.002, \eta_p^2 = 0.03$), \textit{Arousal} ($F(2, 132) = 3.92, p = 0.022, \eta_p^2 = 0.02$), and \textit{Naturalness} ($F(2,132) = 3.40, p = 0.04, \eta_p^2 = 0.01$). Tukey's HSD posthoc results are shown in Table~\ref{TablePostHoc}.%No other interactions were significant (all $p > 0.05$).

\textbf{Poke: }Speed had a main effect on \textit{Valence} ($F(2, 132) = 5.39, p = 0.006, \eta_p^2 = 0.03$), \textit{Arousal} ($F(2, 132) = 75.88, p < 0.001, \eta_p^2 = 0.34$), \textit{Pleasantness} ($F(2, 132) = 12.93, p < 0.001, \eta_p^2 = 0.08$), and \textit{Naturalness} ($F(2, 132) = 43.08, p < 0.001, \eta_p^2 = 0.23$).
 %Tukey's HSD post hoc analysis revealed significant differences in \textit{Valence} between F and M ($\Delta M = 0.16, p = 0.045$), and M and S ($\Delta M = -0.18, p = 0.021$); for \textit{Arousal}, between F and M ($\Delta M = -0.27, p < 0.001$), F and S ($\Delta M = -0.76, p < 0.001$), and M and S ($\Delta M = -0.49, p < 0.001$); for \textit{S2}, between F and M ($\Delta M = 1.21, p < 0.001$), and F and S ($\Delta M = 0.71, p = 0.023$); for \textit{S3}, between F and M ($\Delta M = 2.33, p < 0.001$) and M and S ($\Delta M = -2.79, p < 0.001$).
Feedback modality had a main effect on \textit{Plausibility} ($F(1, 132) = 173.54, p < 0.001, \eta_p^2 = 0.38$), \textit{Pleasantness} ($F(1, 132) = 15.91, p < 0.001, \eta_p^2 = 0.05$), and \textit{Naturalness} ($F(1, 132) = 15.23, p < 0.001, \eta_p^2 = 0.04$). 
User Mode had a main effect on \textit{Valence} ($F(1, 132) = 9.78, p = 0.002, \eta_p^2 = 0.03$), \textit{Arousal} ($F(1, 132) = 21.68, p < 0.001, \eta_p^2 = 0.05$), and \textit{Pleasantness} ($F(1, 132) = 6.58, p = 0.011, \eta_p^2 = 0.02$).
Significant interaction effects were observed between Speed and User Mode on \textit{Valence} ($F(2, 132) = 10.58, p < 0.001, \eta_p^2 = 0.07$) and \textit{Pleasantness} ($F(2, 132) = 6.64, p = 0.002, \eta_p^2 = 0.04$) only. Tukey's HSD posthoc results are shown in Table~\ref{TablePostHoc}.

\textbf{Pat:}
Speed had a main effect on \textit{Valence} ($F(2, 132) = 56.89, p < 0.001, \eta_p^2 = 0.26$), \textit{Arousal} ($F(2, 132) = 70.66, p < 0.001, \eta_p^2 = 0.33$), \textit{Plausibility} ($F(2, 132) = 5.58, p = 0.005, \eta_p^2 = 0.02$), \textit{Pleasantness} ($F(2, 132) = 80.53, p < 0.001, \eta_p^2 = 0.34$), and \textit{Naturalness} ($F(2, 132) = 76.76, p < 0.001, \eta_p^2 = 0.35$). %Tukey's HSD post hoc analysis revealed significant differences for \textit{Valence}, between F and M ($\Delta M = 0.53, p < 0.001$), and F and S ($\Delta M = 0.47, p < 0.001$), for \textit{Arousal}, between F and M ($\Delta M = -0.26, p < 0.001$), F and S ($\Delta M = -0.66, p < 0.001$), and M and S ($\Delta M = -0.40, p < 0.001$), for \textit{S2}, between F and M ($\Delta M = 2.96, p < 0.001$), and F and S ($\Delta M = 2.79, p < 0.001$), for \textit{S3}, between F and M ($\Delta M = 3.92, p < 0.001$), F and S ($\Delta M = 1.79, p < 0.001$), and M and S ($\Delta M = -2.13, p < 0.001$).
Feedback modality had a main effect on \textit{Valence} ($F(1, 132) = 13.50, p < 0.001, \eta_p^2 = 0.03$), \textit{Plausibility} ($F(1, 132) = 228.86, p < 0.001, \eta_p^2 = 0.45$), \textit{Pleasantness} ($F(1, 132) = 29.76, p < 0.001, \eta_p^2 = 0.06$), and \textit{Naturalness} ($F(1, 132) = 14.97, p < 0.001, \eta_p^2 = 0.03$), respectively. 
User Mode had a main effect on \textit{Valence} ($F(1, 132) = 7.72, p = 0.006, \eta_p^2 = 0.02$) and \textit{Arousal} ($F(1, 132) = 11.93, p < 0.001, \eta_p^2 = 0.03$).
Significant interaction effects were observed for Speed and Feedback on \textit{Valence} ($F(2, 132) = 14.71, p < 0.001, \eta_p^2 = 0.07$) and \textit{Pleasantness} ($F(2, 132) = 7.64, p < 0.001, \eta_p^2 = 0.03$); for Speed and User Mode on \textit{Valence} ($F(2, 132) = 3.60, p = 0.030, \eta_p^2 = 0.02$) and \textit{Arousal} ($F(2, 132) = 3.55, p = 0.031, \eta_p^2 = 0.02$); and for Feedback and User Mode on \textit{Plausibility} ($F(1, 132) = 4.23, p = 0.042, \eta_p^2 = 0.01$) and \textit{Pleasantness} ($F(1, 132) = 5.47, p = 0.021, \eta_p^2 = 0.01$). Tukey's HSD posthoc results are shown in Table~\ref{TablePostHoc}.

\textbf{Squeeze:}
Speed had a main effect on \textit{Valence} ($F(2, 132) = 27.25, p < 0.001, \eta_p^2 = 0.14$), \textit{Arousal} ($F(2, 132) = 56.67, p < 0.001, \eta_p^2 = 0.28$), \textit{Plausibility} ($F(2, 132) = 11.16, p < 0.001, \eta_p^2 = 0.02$), \textit{Pleasantness} ($F(2, 132) = 35.43, p < 0.001, \eta_p^2 = 0.14$), and \textit{Naturalness} ($F(2, 132) = 45.06, p < 0.001, \eta_p^2 = 0.22$).
%Tukey's HSD post hoc analysis revealed significant differences for \textit{Valence}, between F and M ($\Delta M = 0.35, p < 0.001$), F and S ($\Delta M = 0.14, p = 0.036$), and M and S ($\Delta M = -0.21, p = 0.001$); for \textit{Arousal}, between F and M ($\Delta M = -0.22, p = 0.002$), F and S ($\Delta M = -0.61, p < 0.001$), and M and S ($\Delta M = -0.39, p < 0.001$); for \textit{S2}, between F and M ($\Delta M = 1.71, p < 0.001$), and F and S ($\Delta M = 1.42, p < 0.001$); for \textit{S3}, between F and M ($\Delta M = 2.67, p < 0.001$), F and S ($\Delta M = 1.33, p = 0.0003$), and M and S ($\Delta M = -1.33, p = 0.0003$).
Feedback modality had a main effect on \textit{Valence} ($F(1, 132) = 37.74, p < 0.001, \eta_p^2 = 0.10$), \textit{Arousal} ($F(1, 132) = 21.18, p < 0.001, \eta_p^2 = 0.05$), \textit{Plausibility} ($F(1, 132) = 722.07, p < 0.001, \eta_p^2 = 0.71$), \textit{Pleasantness} ($F(1, 132) = 173.25, p < 0.001, \eta_p^2 = 0.33$), and \textit{Naturalness} ($F(1, 132) = 45.99, p < 0.001, \eta_p^2 = 0.11$).
User Mode had no significant main effects on any dependent variables ($p > 0.05$). Significant interaction effects were observed for Speed and Feedback on \textit{Valence}, $F(2, 132) = 6.18, p = 0.003, \eta_p^2 = 0.03$, \textit{Plausibility}, $F(2, 132) = 3.72, p = 0.027, \eta_p^2 = 0.01$, and \textit{Naturalness}, $F(2, 132) = 5.87, p = 0.004, \eta_p^2 = 0.03$ only. Tukey's HSD posthoc results are shown in Table~\ref{TablePostHoc}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{Figures/RecordedSpeedvsSpeed2.png}
    \captionsetup{belowskip=-15pt}
    \caption{Recorded gesture speed performed by Toucher, categorized into the three prescribed speed levels}
    \label{recordedSpeed}
\end{figure}
\subsubsection{Objective Measures During Experiment}

Objective measures of the interaction -- stroking speed and the frequency of poke, pat, and squeeze actions per second -- varied significantly between participants (Figure~\ref{recordedSpeed}), corresponding to the 3 speed conditions (S, M, F). To assess whether these objective measures significantly influenced participant ratings of \textit{Valence}, \textit{Arousal}, \textit{Plausibility}, \textit{Pleasantness} and \textit{Naturalness}, we conducted Pearson correlation analyses separately for both the \textit{Toucher} and the \textit{Touchee}.

\textbf{Stroke: }
For the \textit{Toucher}, there was a negative correlation between stroking speed and Valence ($r(70) = -0.44$, $p < 0.001$), Pleasantness ($r(70) = -0.50$, $p < 0.001$), and Naturalness ($r(70) = -0.59$, $p < 0.001$), and a positive correlation with Arousal ($r(70) = 0.43$, $p < 0.001$). No significant correlation was observed for Plausibility ($p > 0.05$).
For the \textit{Touchee}, a similar pattern was found with negative correlations between stroking speed and Valence ($r(70) = -0.46$, $p < 0.001$), Pleasantness ($r(70) = -0.52$, $p < 0.001$), and Naturalness ($r(70) = -0.49$, $p < 0.001$), and a positive correlation with Arousal ($r(70) = 0.60$, $p < 0.001$). No significant correlation was observed for Plausibility ($p > 0.05$).

\textbf{Poke: }
For the \textit{Toucher}, there was a positive correlation between number of pokes per second and Arousal ($r(70) = 0.67$, $p < 0.001$) and Valence ($r(70) = 0.28$, $p < 0.05$). No significant correlation was observed for Plausibility, Pleasantness, or Naturalness ($p > 0.05$).
For the \textit{Touchee}, there was a strong positive correlation between number of pokes per second and Arousal ($r(70) = 0.82$, $p < 0.001$) and a moderate negative correlation with Pleasantness ($r(70) = -0.44$, $p < 0.001$). No significant correlation was observed for Valence, Plausibility, or Naturalness ($p > 0.05$).

\textbf{Pat: }
For the \textit{Toucher}, there was a negative correlation between number of pats per second and Valence ($r(70) = -0.39$, $p < 0.001$), Pleasantness ($r(70) = -0.56$, $p < 0.001$), and Naturalness ($r(70) = -0.33$, $p < 0.01$), and a positive correlation with Arousal ($r(70) = 0.52$, $p < 0.001$). No significant correlation was observed for Plausibility ($p > 0.05$).
For the \textit{Touchee}, there was a negative correlation between number of pats per second and Valence ($r(70) = -0.49$, $p < 0.001$), Pleasantness ($r(70) = -0.60$, $p < 0.001$), and Naturalness ($r(70) = -0.34$, $p < 0.01$), and a positive correlation with Arousal ($r(70) = 0.62$, $p < 0.001$). A weak negative correlation was observed for Plausibility ($r(70) = -0.25$, $p < 0.05$).

\textbf{Squeeze: }
For the \textit{Toucher}, there was a positive correlation between number of squeezes per second and Arousal ($r(70) = 0.59$, $p < 0.001$), and negative correlations with Pleasantness ($r(70) = -0.36$, $p < 0.01$) and Naturalness ($r(70) = -0.45$, $p < 0.001$). No significant correlation was observed for Valence or Plausibility ($p > 0.05$).
For the \textit{Touchee}, there was a positive correlation between number of squeezes per second and Arousal ($r(70) = 0.50$, $p < 0.001$), and a negative correlation with Pleasantness ($r(70) = -0.36$, $p < 0.01$). No significant correlation was observed for Valence, Plausibility, or Naturalness ($p > 0.05$).

\subsubsection{Subjective Measures After Experiment} 
Out of the 12 participants, only 3 reported experiencing moderate headache symptoms, while 2 out of those 3 participants reported moderate eyestrain symptoms based on the SSQ analysis. For the remaining participants, no changes were observed in SSQ scores between the pre- and post-experiment assessments.

We conducted a paired-samples t-test to compare overall presence between the User modes. There was a significant difference in presence scores between the Touchee ($M = 6.04, SD= 0.31$) and Toucher ($M = 4.96, SD = 0.7$), $t(11) = -6.02, p < 0.001, d = 0.71$.

\subsection{Experiment 2 -- Free Interaction}

No order effects were detected within participants, indicating that the sequence of the feedback conditions (V and VH) presented did not influence the results.

A paired-samples t-test revealed significant differences between the feedback conditions for all categories of the Embodiment questionnaire: Appearance ($t(11) = -6.07, p < 0.001, d = 1.75$), Response ($t(11) = -11.73, p < 0.001, d = 3.39$), Ownership ($t(11) = -10.15, p < 0.001, d = 2.93$), Multi-Sensory ($t(11) = -13.18, p < 0.001, d = 3.81$), and Embodiment ($t(11) = -11.43, p < 0.001, d = 3.30$). Scores were consistently higher for VH compared to V across all measures (Figure~\ref{embodiment}).

Paired-samples t-test conducted to compare overall presence between the Feedback conditions revealed a significant difference between V ($M = 4.09, SD= 0.78$) and VH ($M = 5.93, SD = 0.64$), $t(11) = -9.77, p < 0.001, d = 1.15$.

For System Usability, there was no significant difference ($p > 0.05$) between V ($M = 86.04, SD = 9.85$) and VH ($M = 89.58, SD = 6.64$) conditions.

None of the participants reported any changes in SSQ symptoms before and after the experiment.

The results from the HX questionnaire for the VH condition only are listed in Table~\ref{Table1}. Scores are out of a maximum of 5 points.
\begin{table}[b!]
%\centering
\caption{Results from Factors of HX Questionnaire~\cite{anwar2023factors}}\label{Table1}
\begin{tabularx}{\columnwidth}{|X|c|c|}
\hline
\textbf{Question: The haptic feedback …}             & \textbf{Mean (SD)} & \textbf{Factors}                                       \\ \hline
\rowcolor[HTML]{FFFFFF} 
Felt realistic (+)                                     & 3.67 (0.49)        & \cellcolor[HTML]{FFE5E3}                               \\ \cline{1-2}
\rowcolor[HTML]{FFFFFF} 
Was believable (+)                                    & 4.33 (0.65)        & \cellcolor[HTML]{FFE5E3}                               \\ \cline{1-2}
\rowcolor[HTML]{FFFFFF} 
Was convincing (+)                                       & 4.58 (0.51)        & \multirow{-3}{*}{\cellcolor[HTML]{FFE5E3}Realism}      \\ \hline
\rowcolor[HTML]{FFFFFF} 
Felt disconnected from the rest of the experience (-)    & 1.25 (0.45)        & \cellcolor[HTML]{DAFFDA}                               \\ \cline{1-2}
\rowcolor[HTML]{FFFFFF} 
Felt out of place (-)                                    & 1.00 (0.00)        & \cellcolor[HTML]{DAFFDA}                               \\ \cline{1-2}
\rowcolor[HTML]{FFFFFF} 
Distracted me from the task (-)                          & 1.17 (0.58)        & \multirow{-3}{*}{\cellcolor[HTML]{DAFFDA}Harmony}      \\ \hline
\rowcolor[HTML]{FFFFFF} 
Enjoyable as part of the experience (+)                  & 4.67 (0.49)        & \cellcolor[HTML]{DCDEFF}                               \\ \cline{1-2}
\rowcolor[HTML]{FFFFFF} 
Felt engaging with the system (+)                        & 4.41 (0.51)        & \multirow{-2}{*}{\cellcolor[HTML]{DCDEFF}Involvement}  \\ \hline
\rowcolor[HTML]{FFFFFF} 
All felt the same (-)                                   & 1.25 (0.45)        & \cellcolor[HTML]{D8FFFE}                               \\ \cline{1-2}
\rowcolor[HTML]{FFFFFF} 
Changes depending on how things change in the system (+) & 4.50 (0.80)        & \cellcolor[HTML]{D8FFFE}                               \\ \cline{1-2}
\rowcolor[HTML]{FFFFFF} 
Reflects varying inputs and events (+)                   & 4.92 (0.29)        & \multirow{-3}{*}{\cellcolor[HTML]{D8FFFE}Expressivity} \\ \hline
\end{tabularx}
\vspace{-10pt}
\end{table}
\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{Figures/Embodiment2.png}
    %\captionsetup{belowskip=-15pt}
    \caption{Embodiment scores of 12 participants across the two feedback modality conditions after the free interaction experiment}
    \label{embodiment}
\end{figure}

% \begin{figure}[t!]
%     \centering
%     \begin{subfigure}[t]{0.325\columnwidth}
%         \centering
%         \includegraphics[width=\columnwidth]{Figures/SUS_Prescribed.png}
%         \caption{Prescribed Interaction}
%         \label{fig:prescribed}
%     \end{subfigure}
%     %\hfill
%     \begin{subfigure}[t]{0.325\columnwidth}
%         \centering
%         \includegraphics[width=\columnwidth]{Figures/SUS_FreeExploration.png}
%         \caption{Free Exploration}
%         \label{fig:freeexploration}
%     \end{subfigure}
%     %\hfill
%     \begin{subfigure}[t]{0.325\columnwidth}
%         \centering
%         \includegraphics[width=\columnwidth]{Figures/SystemUsability.png}
%         \caption{System Usability}
%         \label{fig:usability}
%     \end{subfigure}
%     \caption{Comparison of SUS scores across different interaction conditions: prescribed interaction, free exploration, and overall system usability.}
%     \label{fig:embodiment_combined}
% \end{figure}
\begin{figure}[t!]
    \centering
    \begin{subfigure}[t]{0.316\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{Figures/SUS_Prescribed.png}
        %\caption{Prescribed touch Presence scores}
        \caption{}
        \label{fig:prescribed}
    \end{subfigure}
    %\hfill
    \begin{subfigure}[t]{0.316\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{Figures/SUS_FreeExploration.png}
        %\caption{Free interaction Presence scores}
        \caption{}
        \label{fig:freeexploration}
    \end{subfigure}
    %\hfill
    \begin{subfigure}[t]{0.316\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{Figures/SystemUsability.png}
        %\caption{System Usability scores for VR system}
        \caption{}
        \label{fig:usability}
    \end{subfigure}
    \caption{SUS Presence scores for (a) Prescribed Touch and (b) Free Interaction; (c) Overall VR System Usability scores across 12 participants}
    \label{fig:embodiment_combined}
\end{figure}



\section{Discussion}
%No order effects were observed in Experiments 1 and 2, the results were consistent regardless of whether participants completed Experiment 1 or Experiment 2 first.

No participants reported challenges or discomfort wearing the vibrotactile glove and sleeve. They fit all users, effectively accommodating large variations in hand and arm sizes.

\subsection{Experiment 1 -- Prescribed Touch}

The results across all gestures reveal the critical roles of speed at which the gesture was performed, feedback modality, and user roles in shaping emotional and sensory experiences. Speed had a consistent influence, with faster interactions heightening arousal but often reducing valence, pleasantness, and naturalness. Slower or more deliberate gestures generally produced more positive and natural experiences, fostering higher valence and pleasantness with moderate arousal levels. Normal speeds often achieved the best balance, suggesting that deviations from natural pacing -- whether faster or slower -- tend to diminish the quality of the interaction.

Multimodal feedback emerged as a key factor in enhancing emotional and sensory outcomes. Compared to visual-only feedback, visual-haptic consistently improved valence, arousal, plausibility, pleasantness, and naturalness. This effect was particularly pronounced during faster gestures, where the added plausibility, pleasantness, and naturalness  mitigated some of the negative effects of rapid interactions. For slower gestures, visual-haptic feedback further amplified the already positive experiences, making it a critical design element for fostering pleasantness and realism.

User roles also shaped the interaction dynamics, though their effects were often secondary to speed and feedback modality. Touchers and Touchees displayed distinct patterns of emotional and sensory responses. For Touchers, faster gestures often correlated with increased arousal and emotional engagement, suggesting that actively delivering rapid interactions can enhance feelings of control and involvement. However, for Touchees, faster gestures typically resulted in heightened arousal coupled with reduced valence, pleasantness, and naturalness, indicating that receiving rapid interactions may become overwhelming or uncomfortable. These differences highlight the sensory-emotional trade-offs that are particularly pronounced for Touchees and emphasize the need to account for user roles when designing interaction dynamics.

For stroking gestures, rapid motions stimulated heightened arousal but reduced emotional positivity, and naturalness, whereas slower or natural speeds elicited high valence, moderate arousal, and enhanced plausibility, pleasantness and naturalness. Visual-haptic feedback enhanced both sensory and emotional experiences. Both Touchers and Touchees displayed similar response patterns, underscoring the centrality of speed and feedback mode in shaping the experience. These findings align with the well-established role of moderate stroking speeds (1–10 $cm/s$)~\cite{strokingVelocity} in optimally engaging CT afferents, maximizing the perceived pleasantness.

Faster pokes increased arousal but decreased valence, pleasantness, and naturalness, with both slow and fast pokes seen as less natural than normal-speed ones. Touchers found rapid pokes more engaging and positive, while Touchees experienced heightened arousal and reduced pleasantness, reflecting the sensory-emotional tension of receiving fast gestures. Lack of significant correlations with plausibility for Touchers suggests speed mainly affects emotional activation, while Touchees experience both sensory and emotional impacts.

Speed similarly affected patting, with faster pats lowering valence, pleasantness, naturalness, and increasing arousal. Visual-haptic feedback mitigated these effects, especially at higher speeds, by improving positivity and comfort. Touchers reported slightly higher valence but lower arousal than Touchees, who were more sensitive to speed changes, showing greater declines in valence and pleasantness with faster pats. Correlation analyses confirmed stronger negative correlations between speed and perceived pleasantness or naturalness for Touchees, highlighting the sensory-emotional trade-offs of faster interactions.


Faster squeezing increased arousal but reduced plausibility, pleasantness, naturalness, and slightly valence. Visual-haptic feedback improved overall sensory-emotional experience, noticeably at moderate speeds. User roles had minimal direct effects, but correlations showed that for Touchers, faster squeezes increased arousal reducing naturalness, while for Touchees, there was a trade-off between increased arousal and reduced pleasantness.

Across all gestures, the interplay of speed, feedback, and user roles followed clear patterns. Faster speeds heightened arousal but at the expense of pleasantness, naturalness, and emotional positivity, while visual-haptic feedback improved plausibility and mitigated these effects to some extent. Touchers subtly derived greater emotional engagement, whereas Touchees were more sensitive to rapid gestures.
In summary, slower, deliberate gestures with multimodal feedback produced the most positive and natural experiences, particularly for Touchees. Faster gestures increase arousal and engagement but should be used carefully to avoid reducing the sensory-emotional quality. By considering the interplay of speed, feedback, and user roles, designers can optimize VR touch interactions for greater emotional engagement and user satisfaction.

% Across all gestures, the interaction between speed, feedback, and user roles revealed clear patterns. Faster speeds tended to enhance arousal but at the expense of pleasantness, naturalness, and emotional positivity. Visual-haptic feedback consistently improved plausibility, emotional outcomes, and naturalness, demonstrating its importance in mitigating the negative effects of rapid interactions. User roles introduced nuanced differences, with Touchers subtly deriving greater emotional engagement, and Touchees displaying greater sensitivity to rapid dynamics. 
% In summary, slower, deliberate gestures with multimodal feedback provide the most positive and natural experiences, especially for Touchees. Faster gestures increase arousal and engagement but should be used carefully to avoid reducing the sensory-emotional quality. By considering speed, feedback, and user roles, designers can create touch-based VR interactions that enhance emotional engagement, plausibility, and user satisfaction, tailoring dynamics to optimize the user experience.

The higher presence scores observed for the Touchees compared to the Touchers are likely due to the experimental instructions given to the Touchers, requiring them to perform specific gestures at different speeds. These instructions may have disrupted their sense of ``being" or immersiveness within the VR environment.


% \textbf{SECOND WAY -- FELT MORE ELABORATE}

% \textbf{Stroke :} The results for the stroking reveal that rapid stroking, while stimulating heightened alertness, can diminish the emotional positivity and perceived naturalness of the interaction. Slow strokes or natural stroking speeds stimulate high valence, low to medium arousal, high perceived pleasantness and naturalness. Interestingly, no significant effects or correlations were observed for \textcolor{red}{S1}, indicating that speed primarily impacts emotional and experiential dimensions rather than tactile perception.

% Visual-haptic feedback significantly enhanced valence, arousal, sensory congruence (\textcolor{red}{S1}), pleasantness, and naturalness compared to visual-only feedback. However, user mode had limited effects overall, suggesting that both Touchers and Touchees experience similar emotional and sensory responses to the stroke gesture, with differences primarily driven by interaction speed.
% The correlation patterns further emphasize this dynamic. For both Touchers and Touchees, faster stroking was positively correlated with arousal, but negatively with valence, pleasantness, and naturalness. 

% \textbf{Poke: } Speed significantly influenced all DVs, with faster pokes generally leading to heightened arousal, reduced valence and pleasantness, as suggested by the significant post-hoc differences. Slow and fast pokes also felt unnatural, as compared to pokes performed at a normal speed. Feedback also played a key role, with visual-haptic feedback eliciting stronger sensory congruence (\textcolor{red}{S1}) and greater naturalness, compared to visual-only feedback. Touchers experienced higher valence and pleasantness compared to Touchees. The interactions, particularly between speed and user mode, revealed that the sensory and emotional impact of speed varied depending on whether the participant was delivering or receiving the poke. Furthermore, for the Toucher, the positive correlation between the number of pokes performed per second and both arousal and valence suggests that actively delivering faster pokes is perceived as more engaging and emotionally positive. %This aligns with the idea that control and active involvement in the interaction can enhance emotional engagement. 
% In contrast, for the Touchee, faster pokes strongly increase arousal but reduce pleasantness, indicating that receiving rapid pokes may become overwhelming or uncomfortable, even if they heighten alertness. Interestingly, the lack of significant correlations with sensory congruence (\textcolor{red}{S1}), pleasantness, or naturalness for the Toucher suggests that speed primarily impacts emotions for those delivering the gesture. For Touchees, however, the trade-off between heightened arousal and diminished pleasantness highlights a more pronounced sensory-emotional tension in receiving faster pokes. 
% %Together, these results reinforce the idea that slower, more deliberate pokes may better balance arousal and pleasantness for Touchees, while Touchers may prefer faster paces for greater emotional engagement, emphasizing the need of adapting interaction dynamics based on user roles and context.

% \textbf{Pat: } Regarding speed, faster pats were associated with heightened arousal but reduced valence, pleasantness, and naturalness, indicating a trade-off between alertness and emotional positivity or sensory quality. Feedback played a key role, with visual-haptic feedback consistently enhancing valence, touch sensation, pleasantness, and naturalness compared to visual-only feedback, particularly at higher speeds, suggesting that multimodal feedback mitigates the negative effects of rapid interaction. User mode revealed differences in perception, with Touchers experiencing slightly higher valence but lower arousal compared to Touchees, indicating that user roles shape the emotional and sensory experience of the gesture. For valence and pleasantness, visual-haptic feedback buffered the decline in positivity and comfort at faster speeds. Speed and user mode interactions showed that Touchees experienced a sharper decline in valence and pleasantness with increasing speed, reflecting heightened sensitivity to rapid interaction dynamics when passively receiving gestures. The feedback and user mode interaction suggested that Touchers derived greater pleasantness from visual-haptic feedback compared to Touchees, during the gesture.
% Correlation analyses reinforced these patterns, showing positive correlations between patting speed and arousal, but negative correlations with valence, pleasantness, and naturalness for both roles. Touchees exhibited slightly stronger negative correlations, emphasizing the greater impact of speed on touch receivers. A weak negative correlation between speed and touch sensation was observed for Touchees, suggesting diminished tactile perception with faster interaction.
% %Overall, slower, deliberate pats and visual-haptic feedback create the most positive and natural experiences for both Touchers and Touchees. 

% \textbf{Squeeze: } Speed consistently influenced all DVs, with faster squeezes heightening arousal but reducing pleasantness and naturalness. Faster and slower speeds showed only a slight decrease in valence, suggesting arousal and sensory factors are more sensitive to speed changes. Visual-haptic feedback significantly enhanced all the DVs compared to visual-only feedback. User mode had minimal direct effects but interacted with speed in shaping outcomes, particularly \textcolor{red}{S1}.
% Speed and feedback interacted significantly for valence, indicating that the positive impact of VH feedback was more pronounced at slower speeds, where pleasantness and positivity are prioritized. For S1 and naturalness, speed-feedback interactions suggested that visual-haptic feedback amplifies sensory congruence and realism, especially under faster speeds, offsetting some of the negative sensory effects of rapid squeezing. However, the interaction between speed and user mode showed minimal significance, implying that the emotional and sensory responses to speed of squeezing are largely consistent across roles.
% Correlation patterns complement these findings. For both Touchers and Touchees, faster squeezing strongly correlated with increased arousal, while negatively correlating with pleasantness and, for Touchers, naturalness. This indicates that rapid squeezes heighten alertness but at the expense of comfort and realism, particularly for those delivering the interaction. Interestingly, no significant correlations emerged for valence or \textcolor{red}{S1}, suggesting that squeezing speed primarily affects emotional activation and sensory quality rather than tactile or emotional positivity directly.
% %In summary, slower, deliberate squeezes with haptic feedback create a balanced experience, fostering pleasantness, naturalness, and sensory congruence, while faster squeezes are better suited for eliciting arousal. Interaction effects further reveal that tailoring speed and feedback combinations can optimize experiences for different goals, roles, and contexts in VR.


\subsection{Experiment 2 -- Free Interaction}
%No order effects were detected within participants, indicating that the sequence of the feedback conditions presented did not influence the results.

Visual plus haptic feedback together consistently outperformed visual-only feedback in Appearance, Response, Ownership, Multi-Sensory integration, and overall Embodiment scores. The substantial effect sizes further emphasize the magnitude of these improvements. This highlights the importance of incorporating richer haptic feedback to improve the experience of a multi-user VR system. The condition with haptic feedback included likely provides more immersive and cohesive sensory cues, which contribute to a stronger perception of body ownership and response to the interaction. Questions addressing the perception of touch sensations, interactions between the avatar and other objects or avatars in VR, and the ability to influence the user’s own body through the avatar received significantly higher ratings with haptic feedback present, compared to the visual-only condition.

The significantly higher sense of presence reported in the added haptic feedback condition % ($M = 5.93, SD = 0.64$)
compared to the visual-only condition % ($M = 4.09, SD = 0.78$) 
suggests that the addition of haptic feedback enhances immersion and the feeling of ``being" in the virtual environment. This aligns with the SUS presence model, which emphasizes the role of multi-sensory inputs in strengthening spatial presence. Some participants reported that the haptic feedback made the VR environment feel more tangible and interactive, leading to a deeper sense of ``being" in the VR.

Our VR system received high usability scores, with no significant differences between using haptic feedback or not. This indicates the system is intuitive, user-friendly, and accessible, allowing easy learning and navigation. Participants efficiently used the armband, sleeves, gloves, and headset without assistance, even though 10 out of 12 had no prior VR or haptic device experience. These results suggest the system holds promise for haptic and VR research, providing a strong foundation for exploring mediated social touch.

High ratings for \textit{Harmony},
% ($M = 4.86, SD = 0.42$), 
\textit{Involvement}, 
% ($M = 4.54, SD = 0.50$),
and \textit{Expressivity}, of the system's haptic feedback 
% ($M = 4.72, SD = 0.57$), 
indicated that it was well-integrated, engaging, and dynamic based on interaction types. However, \textit{Realism} scores were comparatively lower,
%($M = 4.19, SD = 0.67$), 
suggesting that simple vibrations were less effective at conveying a realistic sensation. Participants noted that, while the vibrations as feedback were convincing, they did not always feel natural or fully aligned with their expectations for certain interactions.

\subsection{User Feedback}
Participants were highly enthusiastic about the VR experience, especially interacting with friends in a shared virtual space and seeing their body movements reflected in their avatars. They enjoyed interacting with multiple virtual objects and receiving touch feedback, praising the adaptive vibration feedback and system synchronization. Many highlighted the nearly imperceptible latency and the instantaneous haptic feedback. Participants particularly enjoyed the Free Interaction experiment, engaging in activities like dancing and playing games, which added fun and spontaneity to the experience.

For the Prescribed Touch experiment, among touchees, the stroking gesture on the forearm was highly praised, with many describing it as pleasant and relaxing. Participants also appreciated the haptic experience of other gestures, particularly when performed at slow or medium speeds. The ``normal" speed of gestures was often described as the most natural. Touchers similarly reported a positive experience with stroking, patting, and squeezing gestures. However, the poking gesture received less favorable feedback. We suspect this was largely due to hand tracking inaccuracies caused by the Meta Quest's limitations in detecting hand poses when participants wore the gloves.

To the open-ended question for the Touchees after the Prescribed Touch Experiment, they related the touch gestures performed as ``grabbing my arm", ``patting", ``tapping", ``poking", ``trying to grab my attention", ``caressing", ``hold and squeezing".
Some participants suggested that adding pressure cues to the hands (for touchers) and the forearm (for touchees) during squeezing and poking gestures could enhance the realism of these interactions. Notably, the patting gesture, when performed at a fast pace, was universally disliked. Participants described it as feeling unnatural, overly abrupt, or disconcerting, highlighting the need for careful consideration of intentions in mediated social touch system design.


\section{Conclusion, limitations and Future Work}

This paper introduces a standalone, device-agnostic multiplayer VR system for real-time mediated social touch with haptic feedback, designed for Meta Quest headsets and supporting up to 16 physically distant users. It integrates wireless vibrotactile feedback via gloves and sleeves with 52 ERM actuators, enabling users to perform and receive remote touch gestures. Our evaluation with 12 participants revealed the impact of interaction speed, feedback modality, and user roles on emotional and sensory experiences, alongside high system usability, presence, and embodiment scores.
%This paper introduces a standalone multiplayer VR system for real-time mediated social touch with haptic feedback between users in different locations. Designed for Meta Quest headsets, it supports up to 16 users, enabling dynamic interactions with avatars and objects. The system integrates vibrotactile feedback via wearable gloves and sleeves with 52 ERM actuators, allowing users to perform and receive remote touch gestures through wireless communication. It is designed to be device-agnostic, versatile, and adaptable.
%Our evaluation with 12 participants highlights the impact of interaction speed, feedback modality, and user roles on emotional and sensory experiences in VR. Participants also reported high scores for system usability, presence, and embodiment, underscoring the system's potential for immersive social touch experiences.

%This work presents the importance of multimodal feedback in real-time multi-user mediated social touch or haptic communication settings in VR. The presented system can serve as a valuable platform for further research and applications in social VR, particularly in fostering emotional connections, enhancing presence, and enabling naturalistic interactions in virtual environments. By addressing current challenges and expanding its scope, this system has the potential to become a benchmark for exploring the role of social touch in the metaverse and beyond.

This work has several limitations that highlight opportunities for future research and development. The use of ERMs in our device restricts haptic fidelity by providing only vibrotactile feedback, which cannot fully substitute for the broad range of feedback modalities. %Participants noted that the vibrations did not always feel realistic in every interaction, especially for gestures like ``squeezing". %While LRAs or voice coil actuators could provide slightly improved fidelity, their implementation introduces added complexity, including the need for additional drivers that would increase the system's bulkiness. 
Moreover, our current design is limited to actuation on the hands and forearms. Expanding to full-body haptic feedback would pose significant challenges in terms of hardware design and power consumption. To address these limitations, future research must explore alternative actuation techniques capable of replicating complex sensations, such as pressure, temperature, and skin stretch, in real-time VR interactions with minimal latency.

However, our VR system is designed to be device-agnostic, enabling researchers to integrate and test their own devices within our framework. As future work, we plan to evaluate our VR system using haptic feedback provided to both the toucher and touchee from commercially available devices (e.g. Ultraleap module or bHaptic gloves), to further strengthen our claim and broaden its applicability. Furthermore, this study did not examine the influence of gender, sexual orientation, avatar characteristics, such as appearance, skin tone, and facial expressions, on user experience, an aspect worth exploring in future research. Our participant sample consisted of pairs of individuals who were familiar with each other prior to the study. Although our participant population was gender-diverse, the group size was too small to study either the effect of gender or relationship in mediated social touch. %Although a significant interaction effect was observed involving gender and sexual orientation, these factors did not show significant main effects. We also did not observe an effect of CIT initiating or receiving scores. However, given the limited diversity and small sample size in our study, it is important to note that the lack of main effects may reflect insufficient variation in participant demographics rather than the absence of an underlying relationship. 
These effects should be studied in the future with more diverse and larger participant groups including strangers to improve the reliability and generalizability of the findings.
A key goal for future work is to make this VR system open source, enabling researchers to develop, evaluate, and compare their own haptic devices within our VR platform. The scope of this VR framework can be expanded, exploring its potential as a benchmark application to evaluate and compare tactile devices in diverse contexts~\cite{VRsuite}, beyond social touch interactions alone.

\section*{Acknowledgment}

This research was supported by the National Science Foundation under Grant No. 2047867.

%\section*{References}
\bibliographystyle{ieeetr}
\bibliography{References_Social_Touch.bib}

\end{document}