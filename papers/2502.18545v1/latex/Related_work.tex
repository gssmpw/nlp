\section{Related Work}
\subsection{Privacy-Preserving Text Processing}
Text privacy protection has emerged as a critical challenge in natural language processing applications. \citet{papadopoulou2022neural} proposed text sanitization that combines entity detection with privacy risk assessment to guide masking decisions. \citet{shen2024fire} extended this approach with an end-to-end framework that preserves task utility during privacy protection. Exploring information preservation, \citet{meisenbacher2024just} introduced differential privacy techniques for text modification, demonstrating improved semantic retention over traditional masking methods.
While these approaches have advanced privacy protection techniques, they primarily focus on document-level sanitization without considering the dynamic nature of user interactions. Our work introduces query-aware privacy protection that adaptively balances information utility with privacy requirements.

\subsection{Query-Aware PII Detection}
Traditional PII detection has evolved from rule-based systems (\citealp{ruch2000medical};~\citealp{douglass2005identification}) to neural architectures (\citealp{deleger2013large};~\citealp{dernoncourt2017identification};~\citealp{johnson2020deidentification}), with recent work demonstrating the effectiveness of transformer-based models in identifying sensitive information \citep{asimopoulos2024benchmarking}. Large language models have shown promising results in recognizing diverse PII types (\citealp{singhal2024identifying};~\citealp{gpt4pii}), yet they treat all sensitive information with uniform importance.
Our framework introduces a novel dimension to PII detection by incorporating query relevance assessment. Rather than applying uniform protection measures, we focus on identifying which PII elements are essential for addressing user queries. This approach enables more nuanced privacy protection by distinguishing between query-related and query-unrelated sensitive information, though the actual masking or protection mechanisms are left to downstream applications.

\subsection{Privacy Protection Benchmarks}
Existing benchmarks for evaluating privacy protection methods have primarily focused on general PII detection capabilities. \citet{pilan2022text} introduced TAB, a benchmark based on legal court cases, which evaluates text anonymization performance. However, it does not assess the model's ability to distinguish query-related information. The recent work by \citet{sun2024deprompt} proposed evaluation metrics for privacy-preserving prompts, but their focus remains limited to general desensitization effectiveness. \citet{li2024llm} developed LLM-PBE to assess privacy risks in language models, though their emphasis is on model-side privacy rather than input text protection.

PII-Bench addresses these limitations by providing a comprehensive evaluation framework that assesses both PII detection accuracy and the ability to determine query-related information. This dual focus enables more realistic evaluation of privacy protection systems in interactive scenarios, where the relevance of sensitive information varies with user queries.
