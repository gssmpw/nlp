\section{PII-Benchmark}
\begin{figure*}[t]
\includegraphics[width=1\linewidth]{fig/Method.pdf}
\caption{
\textbf{PII-Bench} synthesis process consists of three main modules: (a) PII Entity Generation, (b) User Description Generation, and (c) Query Generation.
}
\label{fig:method}
\vspace{-5mm}
\end{figure*}


\begin{table}[t]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{cl}
\toprule
\textbf{Symbol} & \textbf{Description} \\
\hline
$p$ & A prompt consisting of a user description and a query \\
$d$ & User description containing personal information \\
$q$ & User query specifying the information need \\
$d'$ & Modified description with masked PII \\
$p'$ & Modified prompt $(d', q)$ after PII masking \\
$\mathcal{S}$ & Set of subject individuals mentioned in the description \\
$s_i$ & The $i$-th subject individual \\
$\mathcal{E}$ & Complete set of PII entities in the prompt \\
$\mathcal{E}_i$ & Set of PII entities associated with subject $s_i$ \\
$e^i_j$ & The $j$-th PII entity of subject $s_i$ \\
$\mathcal{E}_q$ & Subset of PII entities necessary for answering query $q$ \\
$\mathcal{T}$ & Set of predefined PII types \\
\bottomrule
\end{tabular}}
\caption{Notation used throughout in Task Definition.}
\label{tab:notation}
\vspace{-5mm}
\end{table}

\subsection{Task Definition}

Privacy Protection Systems target at maintaining LLM functionality while maximizing user privacy protection.
Let $p$ be a prompt consisting of a user description $d$ and a query $q$. The description $d$ contains information about multiple subject individuals $\mathcal{S} = \{s_1, ..., s_m\}$.
For each subject $s_i$, there exists an associated set of PII entities $\mathcal{E}_i = \{e^{i}_{1}, ..., e^{i}_{k}\}$. 
The complete set of PII entities in prompt $p$ is defined as $\mathcal{E} = \bigcup_{i=1}^m \mathcal{E}_i$, where each entity $e \in \mathcal{E}$ belongs to a predefined PII type from set $\mathcal{T}$ (see Appendix~\ref{sec:type}).
Let $\mathcal{E}_q \subseteq \mathcal{E}$ denote the subset of PII entities that are necessary for answering query $q$.

Based on this definition, we propose three fundamental evaluation tasks for Privacy Protection Systems:

\textbf{(1) PII Detection Task}:
Given prompt $p$, the model needs to: 
identify the minimal text spans for all PII entities $e \in \mathcal{E}$;
establish associations between each entity $e$ and its corresponding subject $s \in \mathcal{S}$;
assign the correct PII type $t \in \mathcal{T}$ to each entity $e$.

\textbf{(2) Query-Related PII Detection Task}:
Given prompt $p$, the model needs to determine the minimal subset of PII entities $\mathcal{E}_q \subseteq \mathcal{E}$. 
This subset should only contain PII entities necessary to answer query $q$, maximizing protection of non-relevant personal information.

\textbf{(3) Query-Unrelated PII Masking Task}:
This task is what we propose the optimal form of privacy protection system.
Given prompt $p$, the model should generate a modified description $d'$ where query-unrelated PII entities are masked while preserving the necessary ones. Formally, the model should identify $\mathcal{E}_q$ and generate $d'$ where all PII entities in $\mathcal{E} \setminus \mathcal{E}_q$ are masked while preserving those in $\mathcal{E}_q$. 
The masking operation should maintain text coherence and readability while ensuring effective privacy protection for non-essential personal information.
The resulting prompt $p' = (d', q)$ should enable LLMs to accurately address the query while minimizing exposure of irrelevant personal information.


\subsection{PII-Bench Construction}

Based on the task definition above, we designed an automated process for constructing the PII evaluation dataset, as illustrated in Fig.~\ref{fig:method}.

\subsubsection{PII Entity Generation}
Following \citet{papadopoulou2022neural}, we expanded the PII type set $\mathcal{T}$ into 55 subcategories (see Appendix \ref{sec:pii}), employing two complementary strategies for entity generation:

(1) Rule-based Generation: Applicable for deterministic PII types with fixed formats or enumerable value sets, such as phone numbers, email addresses, and standardized ID numbers.
(2) LLM-based Generation: Applicable for non-deterministic PII types requiring contextual understanding and real-world knowledge, such as occupation descriptions and detailed addresses.
This method leverages GPT-4-0806 to generate semantically appropriate and contextually relevant entities.

\subsubsection{User Description Generation}
\textbf{Single-Subject Description Construction}:
The construction of single-subject descriptions follows a three-stage process:

(1) Entity Selection: 
For subject $s$, randomly sample $n$ entities ($4 \leq n \leq 16$) from different PII types to construct entity set $\mathcal{E}$.
The sampling process ensures diversity of PII types while considering their natural distribution in real-world scenarios.
(2) Consistency Optimization: 
Ensure logical compatibility among entities in $\mathcal{E}$ through designed verification rules. 
For example, verifies reasonable correspondence between age and  educational history as shown in Fig.~\ref{fig:method}.
(3) User Desc Generation: 
Selects appropriate expression styles to generate the user description.
It employs formal description formats like job resumes and employee records in professional scenarios; casual expressions like personal profiles and self-introductions in social scenarios.

\textbf{Multi-Subject Description Construction}:
The construction process for multi-subject related descriptions includes these key steps:

(1) Entity Selection: Construct relationship network $R(s_i, s_j)$ for subject pairs $(s_i, s_j)$. Relationship types include intersection relationships like colleagues and alumni, hierarchical relationships like parent-child and teacher-student, and non-intersection relationships with no direct connection.
(2) Consistency Optimization: 
This stage first establishes entity dependency rules based on relationship type $R$.
Then ensures consistency of shared attributes among related subjects, such as company address for employees of the same company.
This stage also derives related attributes based on relationship type, such as age differences in parent-child relationships.
And finally remove the sample which contains contradictions.
(3) User Desc Generation: 
This stage designs natural interaction environments matching relationship characteristics, placing subjects in realistic scenarios (like meetings, family activities) and constructing multi-party dialogue flows to reflect interactive relationships.



\subsubsection{Query Construction}
For each description $d$, query construction follows a four-phase process:

(1) Entity Selection: Randomly sample $k$ entities ($1 \leq k \leq 3$) from $\mathcal{E}$ to form query-relevant entity set $\mathcal{E}_q$.
(2) Scenario Design: Construct query contexts that align with real-world application scenarios. The goal is to simulate actual user needs for PII information in specific situations. For example, when $\mathcal{E}_q$ contains {``Work Experience'': ``5 years as Machine Learning Engineer'', ``Education Background'': ``Stanford University Ph.D. in Computer Science''}, this stage generates query scenarios like ``As a hiring manager, I need to verify if this candidate's education and relevant work experience meet the requirements for the Senior Researcher position''.
(3) Entity Abstraction: Map specific PII entities in $\mathcal{E}_q$ to abstract representations, maintaining basic semantic properties while enhancing privacy protection.
(4) Query Generation: Integrate abstract entities into corresponding scenarios through GPT-4-0806 model to generate natural queries $q$ that fit practical application scenarios.

\subsubsection{Human Verification}
All content generated by GPT-4-0806 undergoes rigorous verification by five professional annotators and the authors, focusing on:
(1) Completeness and accuracy of PII entity annotations in description $d$.
(2) Correspondence between query $q$ and query-relevant entity set $\mathcal{E}_q$.
(3) Overall semantic coherence and scenario authenticity.
Complete annotation guidelines and quality control procedures are detailed in Appendix \ref{sec:annotation}.

\subsection{Dataset Partitioning and Statistics}


Table~\ref{tab:stats} presents the partition and key statistics of PII-Bench, which comprises two main datasets (PII-single and PII-multi) and two specialized test sets (PII-hard and PII-distract).
Each sample follows a consistent JSON structure containing four key components:
user description, query, comprehensive PII entity annotations, and query-relevant PII labels, as illustrated in Fig.~\ref{fig:sample}.


\textbf{PII-Single and PII-Multi}:
Based on the number of subjects in descriptions, the dataset is divided into two main subsets.
PII-Single contains 2000 description-query pairs involving single subjects, focusing on model performance in handling individual information.
PII-Multi contains 2000 description-query pairs involving multiple related subjects, evaluating model capability in handling privacy information within complex interpersonal networks.

\textbf{Test-Hard Construction}:
Select 200 challenging instances from PII-Single and PII-Multi to construct Test-Hard dataset, based on criteria including:
(1) Maximum character length of description text $d$.
(2) Highest PII entity density ($|\mathcal{E}|/|d|$).
(3) Samples with the most query-relevant entities ($|\mathcal{E}_q|$).

\textbf{Test-Distract Construction}:
Construct 200 samples simulating complex multi-user interaction scenarios.
Each sample integrates five different descriptions $\{d_1,...,d_5\}$ from PII-Single and PII-Multi, and constructs queries $q$ involving three of these descriptions based on professional networks, knowledge platforms, and community forum interaction templates.
The generation process employs specific dialogue flow transformation strategies to ensure natural transitions and semantic coherence between multiple descriptions.
Scenario design particularly emphasizes simulating real-world information interference and complex interaction patterns.

\subsection{Human Performance}
To establish a human baseline for PII-Bench, we recruited 25 graduate students specializing in data security from top universities across China. 
All participants had at least two years of research experience in privacy protection and information security. 
Before the formal evaluation, participants completed a comprehensive training session and passed a qualification test (detailed in Appendix~\ref{sec:human_eval}).

We designed two evaluation sets: a main test set comprising 400 randomly sampled instances (200 each from PII-single and PII-multi), and a challenging set of 100 instances from PII-distract. 
Each instance underwent independent assessment by five participants through our online evaluation platform. 
Participants performed two sequential tasks: 
PII recognition, which involved determining minimal text spans, associated subjects, and PII types for all entities in the user description, followed by query-relevant PII detection to identify entities essential for addressing the given query. 
The result of the human baseline is shown in Table~\ref{tab:human_perf}.

\begin{table}[t]
\small
\centering
\begin{tabular}{cccc}
\toprule
\textbf{Dataset} & \textbf{PII-F1} & \textbf{Query-F1} \\ \hline
PII-single & 97.2 ± 1.1 & 95.1 ± 1.3 \\ \hline
PII-multi & 95.4 ± 1.2 & 94.3 ± 1.5 \\ \hline
PII-hard & 91.3 ± 1.1 & 90.3 ± 1.2 \\ \hline
PII-distract & 92.8 ± 1.8 & 91.5 ± 2.1 \\ 
\bottomrule
\end{tabular}
\caption{Human performance in PII-Bench. Desc-F1 measures accuracy in the PII recognition task while Query-F1 evaluates the query-relevant PII detection task.}
\label{tab:human_perf}
\vspace{-4mm}
\end{table}

\begin{table}[t]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\textbf{Name} &
  \textbf{\#Sample} &
  \textbf{Avg \#Subject} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Avg \#Char\\ (Desc)\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Avg \#PII\\ (Desc)\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Avg \#Char\\ (Query)\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Avg \#PII\\ (Query)\end{tabular}} \\ \hline
PII-single   & 1,214          & 1.0           & 893.48           & 7.67           & 211.21          & 1.95          \\ \hline
PII-multi    & 1,228          & 2.0           & 652.65           & 13.14          & 236.21          & 2.06          \\ \hline \hline
PII-hard     & 200           & 1.5          & 778.03           & 10.60           & 222.09          & 2.10          \\ \hline
PII-distract & 200           & 7.5           & 4,403.64          & 51.08          & 859.69          & 5.82          \\ \hline \hline
\textbf{All} & \textbf{2,842} & \textbf{1.92} & \textbf{1,028.32} & \textbf{13.30} & \textbf{268.41} & \textbf{2.28} \\ 
\bottomrule
\end{tabular}
}
\vspace{-3mm}
\caption{Statistic information of PII-Bench.}
\label{tab:stats}
\vspace{-5mm}
\end{table}

\begin{figure*}[ht]
\includegraphics[width=1\linewidth]{fig/Sample.pdf}
\vspace{-5mm}
\caption{
An example from \textbf{PII-Bench}, which aims to evaluate Privacy Protection System's ability by masking maximize PII while maintain LLM's functionality.
The evaluation is seperated by two fundamental tasks: 
(a) The PII Detection Task: Identify and classify PII entities for each subject in the prompt, with ground truth labels shown on the right side. 
(b) The Query-Related PII Detection Task: Determine which PII entities are necessary for answering the user query, enabling selective masking of irrelevant personal information. 
}
\label{fig:sample}
\vspace{-5mm}
\end{figure*}