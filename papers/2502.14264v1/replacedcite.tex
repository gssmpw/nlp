\section{Related Work}
Integrating perception and decision-making in RL has become an interesting subdomain, especially in environments with high-dimensional sensory inputs. The Perception and Decision-making Interleaving Transformer (PDiT; ____) uses separate transformers for perception and decision-making, leading to enhanced performance in complex tasks. Incorporating game-theoretic principles, ____ proposed the Stackelberg Actor-Critic framework, modeling the actor-critic interaction as a Stackelberg game to improve learning stability. Extending this approach, ____ addressed robustness in uncertain environments by formulating robust RL as a Stackelberg game, demonstrating the adaptability of leader-follower structures in RL. Attention mechanisms have also been explored for adaptive feature extraction in RL. For instance, ____ introduced a self-supervised attention model that significantly improved performance in the Arcade Learning Environment, highlighting the potential of attention mechanisms in RL.

Our work advances these approaches by introducing a framework with theoretical guarantees through a modified Bellman operator that explicitly accounts for perception-policy interaction, while maintaining the advantages of modern policy optimization. Our cooperative game formulation creates a natural balance between feature extraction and decision-making, complementing previous approaches by adding provable convergence properties for the entire system and demonstrating empirical improvements.