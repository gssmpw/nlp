@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}

@misc{wang2024moge,
    title={MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision},
    author={Wang, Ruicheng and Xu, Sicheng and Dai, Cassie and Xiang, Jianfeng and Deng, Yu and Tong, Xin and Yang, Jiaolong},
    year={2024},
    eprint={2410.19115},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2410.19115}, 
}

@article{bochkovskii2024depth,
  title   = {Depth Pro: Sharp Monocular Metric Depth in Less Than a Second},
  author  = {Aleksei Bochkovskii and Amaël Delaunoy and Hugo Germain and Marcel Santos and Yichao Zhou and Stephan R. Richter and Vladlen Koltun},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.02073}
}
@article{xu2024diffusion,
  title={What Matters When Repurposing Diffusion Models for General Dense Perception Tasks?},
  author={Xu, Guangkai and Ge, Yongtao and Liu, Mingyu and Fan, Chengxiang and Xie, Kangyang and Zhao, Zhiyue and Chen, Hao and Shen, Chunhua},
  journal={arXiv preprint arXiv:2403.06090},
  year={2024}
}
@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
@inproceedings{petrovai2022exploiting,
  title={Exploiting pseudo labels in a self-supervised learning framework for improved monocular depth estimation},
  author={Petrovai, Andra and Nedevschi, Sergiu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1578--1588},
  year={2022}
}
@article{kirillov2023segment,
  title   = {Segment Anything},
  author  = {Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2304.02643}
}
@inproceedings{kuznietsov2017semi,
  title={Semi-supervised deep learning for monocular depth map prediction},
  author={Kuznietsov, Yevhen and Stuckler, Jorg and Leibe, Bastian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6647--6655},
  year={2017}
}
@article{hoyer2023improving,
  title={Improving semi-supervised and domain-adaptive semantic segmentation with self-supervised depth estimation},
  author={Hoyer, Lukas and Dai, Dengxin and Wang, Qin and Chen, Yuhua and Van Gool, Luc},
  journal={International Journal of Computer Vision},
  volume={131},
  number={8},
  pages={2070--2096},
  year={2023},
  publisher={Springer}
}
@inproceedings{smolyanskiy2018importance,
  title={On the importance of stereo for accurate depth estimation: An efficient semi-supervised deep neural network approach},
  author={Smolyanskiy, Nikolai and Kamenev, Alexey and Birchfield, Stan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={1007--1015},
  year={2018}
}

@inproceedings{guizilini2020robust,
  title={Robust semi-supervised monocular depth estimation with reprojected distances},
  author={Guizilini, Vitor and Li, Jie and Ambrus, Rares and Pillai, Sudeep and Gaidon, Adrien},
  booktitle={Conference on robot learning},
  pages={503--512},
  year={2020},
  organization={PMLR}
}


@article{miangoleh2021boosting,
  title     = {Boosting Monocular Depth Estimation Models to High-Resolution via Content-Adaptive Multi-Resolution Merging},
  author    = {S. M. H. Miangoleh and Sebastian Dille and Long Mai and Sylvain Paris and Yağız Aksoy},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2021},
  doi       = {10.1109/CVPR46437.2021.00956},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/88f868de54c7207368006fe056ebe4713c9fb33d}
}

@inproceedings{garg2016unsupervised,
  title={Unsupervised learning of depth and ego-motion from video},
  author={Garg, Ravi and Vijay Kumar BG and Carneiro, Gustavo and Reid, Ian},
  booktitle={European Conference on Computer Vision},
  pages={556--573},
  year={2016},
  organization={Springer}
}

@inproceedings{guizilini20203d,
  title={3d packing for self-supervised monocular depth estimation},
  author={Guizilini, Vitor and Ambrus, Rares and Pillai, Sudeep and Gaidon, Adrien},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2485--2494},
  year={2020}
}

@inproceedings{yang2020d3vo,
  title={D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual Odometry},
  author={Yang, Nan and Wang, Rui and St{\"u}ckler, J{\"o}rg and Cremers, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1281--1292},
  year={2020}
}

@article{li2020ar,
  title={AR shadow: Real-time 3D object tracking and shadow rendering for mobile augmented reality},
  author={Li, Yanhua and Zhang, Qixing and Zhang, Liqian},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={26},
  number={9},
  pages={2871--2881},
  year={2020},
  publisher={IEEE}
}

@inproceedings{mayer2016large,
  title={A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation},
  author={Mayer, Nikolaus and Ilg, Eddy and Hausser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4040--4048},
  year={2016}
}

@inproceedings{yin2021learning,
  title={Learning to recover 3D scene shape from a single image},
  author={Yin, Weicong and Shi, Jianping and Feng, Yao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2042--2051},
  year={2021}
}

@inproceedings{ho2022imagen,
  title={Imagen: Diffusion models for text-to-image generation},
  author={Ho, Jonathan and Saharia, Chitwan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
  booktitle={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{zoph2020rethinking,
  title={Rethinking pre-training and self-training},
  author={Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Le, Quoc V},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3833--3845},
  year={2020}
}

@inproceedings{xie2020self,
  title={Self-training with noisy student improves imagenet classification},
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10687--10698},
  year={2020}
}

@inproceedings{yang2024depthanythingv2,
  title={Depth Anything V2: Monocular Depth Estimation for Diverse Scenarios with Unlabeled Data},
  author={Yang, Shuai and Zhang, Rui and Li, Kai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{oquab2023dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timothée and Moutakanni, Theo and Vo, Huy V. and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Howes, Russell and Huang, Po-Yao and Xu, Hu and Sharma, Vasu and Li, Shang-Wen and Galuba, Wojciech and Rabbat, Mike and Assran, Mido and Ballas, Nicolas and Synnaeve, Gabriel and Misra, Ishan and Jegou, Herve and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
  journal={TMLR},
  year={2024}
}

@inproceedings{darcet2023vitneedreg,
  title={Vision Transformers Need Registers},
  author={Darcet, Timothée and Oquab, Maxime and Mairal, Julien and Bojanowski, Piotr},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{yang2024depthanything,
  title={Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle=CVPR,
  year={2024}
}

@article{depth_anything_v2,
  title={Depth Anything V2},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Zhao, Zhen and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  journal={arXiv preprint arXiv:2406.09414},
  year={2024}
}

@inproceedings{marigold,
  title={Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation},
  author={Bingxin Ke and Anton Obukhov and Shengyu Huang and Nando Metzger and Rodrigo Caye Daudt and Konrad Schindler},
  booktitle=CVPR,
  year={2024}
}

@inproceedings{fu2024geowizard,
  title={GeoWizard: Unleashing the Diffusion Priors for 3D Geometry Estimation from a Single Image},
  author={Fu, Xiao and Yin, Wei and Hu, Mu and Wang, Kaixuan and Ma, Yuexin and Tan, Ping and Shen, Shaojie and Lin, Dahua and Long, Xiaoxiao},
  booktitle=ECCV,
  year={2024}
}

@article{Yu2022MonoSDF,
  author={Yu, Zehao and Peng, Songyou and Niemeyer, Michael and Sattler, Torsten and Geiger, Andreas},
  title={MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction},
  journal={NIPS},
  year={2022}
}

@inproceedings{hu2023Tri-MipRF,
  title={Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural Radiance Fields},
  author={Hu, Wenbo and Wang, Yuling and Ma, Lin and Yang, Bangbang and Gao, Lin and Liu, Xiao and Ma, Yuewen},
  booktitle=ICCV,
  year={2023}
}

@inproceedings{hu-2021-bidirectional,
  title={Bidirectional Projection Network for Cross Dimensional Scene Understanding},
  author={Hu, Wenbo and Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Wong, Tien-Tsin},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{liu20213d,
  title={3d-to-2d distillation for indoor scene parsing},
  author={Liu, Zhengzhe and Qi, Xiaojuan and Fu, Chi-Wing},
  booktitle=CVPR,
  year={2021}
}

@article{dong2022towards,
  title={Towards real-time monocular depth estimation for robotics: A survey},
  author={Dong, Xingshuai and Garratt, Matthew A and Anavatti, Sreenatha G and Abbass, Hussein A},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={10},
  pages={16940--16961},
  year={2022}
}

@inproceedings{hong2022depth,
  title={Depth-aware generative adversarial network for talking head video generation},
  author={Hong, Fa-Ting and Zhang, Longhao and Shen, Li and Xu, Dan},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{sun2021neuralrecon,
  title={Neuralrecon: Real-time coherent 3d reconstruction from monocular video},
  author={Sun, Jiaming and Xie, Yiming and Chen, Linghao and Zhou, Xiaowei and Bao, Hujun},
  booktitle=CVPR,
  year={2021}
}

@article{Luo-VideoDepth-2020,
  author={Luo, Xuan and Huang, Jia{-}Bin and Szeliski, Richard and Matzen, Kevin and Kopf, Johannes},
  title={Consistent Video Depth Estimation},
  journal=TOGSIGGRAPH,
  volume={39},
  number={4},
  year={2020}
}

@article{zhang2021consistent,
  title={Consistent depth of moving objects in video},
  author={Zhang, Zhoutong and Cole, Forrester and Tucker, Richard and Freeman, William T and Dekel, Tali},
  journal=TOGSIGGRAPH,
  volume={40},
  number={4},
  pages={1--12},
  year={2021}
}

@inproceedings{kopf2021rcvd,
  title={Robust Consistent Video Depth Estimation},
  author={Kopf, Johannes and Rong, Xuejian and Huang, Jia-Bin},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{teed2018deepv2d,
  title={Deepv2d: Video to depth with differentiable structure from motion},
  author={Teed, Zachary and Deng, Jia},
  booktitle=ICLR,
  year={2020}
}

@article{ranftl2020towards,
  title={Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},
  author={Ranftl, Rene and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={3},
  pages={1623--1637},
  year={2020}
}

@article{yin2020diversedepth,
  title={DiverseDepth: Affine-invariant Depth Prediction Using Diverse Data},
  author={Yin, Wei and Wang, Xinlong and Shen, Chunhua and Liu, Yifan and Tian, Zhi and Xu, Songcen and Sun, Changming and Dou, Renyin},
  journal={arXiv preprint arXiv:2002.00569},
  year={2020}
}

@inproceedings{ranftl2021vision,
  title={Vision Transformers for Dense Prediction},
  author={Ranftl, Rene and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={12179--12188},
  year={2021}
}

@inproceedings{eigen2014depth,
  title={Depth map prediction from a single image using a multi-scale deep network},
  author={Eigen, David and Puhrsch, Christian and Fergus, Rob},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2366--2374},
  year={2014}
}
@article{yin2020learning,
  title     = {Learning to Recover 3D Scene Shape from a Single Image},
  author    = {Wei Yin and Jianming Zhang and Oliver Wang and Simon Niklaus and Long Mai and Simon Chen and Chunhua Shen},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2020},
  doi       = {10.1109/CVPR46437.2021.00027},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/4ac318309807b5a7a50a1a292ced43e6f5f0ffbb}
}
@article{yin2023metric3d,
  title     = {Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image},
  author    = {Wei Yin and Chi Zhang and Hao Chen and Zhipeng Cai and Gang Yu and Kaixuan Wang and Xiaozhi Chen and Chunhua Shen},
  journal   = {IEEE International Conference on Computer Vision},
  year      = {2023},
  doi       = {10.48550/arXiv.2307.10984},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/bdd2972730730844d0366a5e5f596b1aeaa7c3ed}
}
@article{bhat2023zoedepth,
  title   = {ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth},
  author  = {Shariq Farooq Bhat and Reiner Birkl and Diana Wofk and Peter Wonka and Matthias Müller},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2302.12288}
}
@article{zhang2023robust,
  title     = {Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering},
  author    = {Chi Zhang and Wei Yin and Gang Yu and Zhibin Wang and Tao Chen and Bin Fu and Joey Tianyi Zhou and Chunhua Shen},
  journal   = {IEEE International Conference on Computer Vision},
  year      = {2023},
  doi       = {10.1109/ICCV51070.2023.00822},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/312095efe0b452156c90e8d0a38a6b8613720a1f}
}
@inproceedings{laina2016deeper,
  title={Deeper Depth Prediction with Fully Convolutional Residual Networks},
  author={Laina, Iro and Rupprecht, Christian and Belagiannis, Vasileios and Tombari, Federico and Navab, Nassir},
  booktitle={Proceedings of the Fourth International Conference on 3D Vision (3DV)},
  pages={239--248},
  year={2016}
}

@inproceedings{fu2018deep,
  title={Deep Ordinal Regression Network for Monocular Depth Estimation},
  author={Fu, Huazhu and Gong, Mingming and Wang, Chaohui and Batmanghelich, Kayhan and Tao, Dacheng},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2002--2011},
  year={2018}
}

@inproceedings{godard2017unsupervised,
  title={Unsupervised Monocular Depth Estimation with Left-Right Consistency},
  author={Godard, Clément and Mac Aodha, Oisin and Brostow, Gabriel J},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={270--279},
  year={2017}
}

@inproceedings{zhou2017unsupervised,
  title={Unsupervised Learning of Depth and Ego-Motion from Video},
  author={Zhou, Tinghui and Brown, Matthew and Snavely, Noah and Lowe, David G},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1851--1858},
  year={2017}
}


@inproceedings{hu2018squeeze,
  title={Squeeze-and-Excitation Networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={7132--7141},
  year={2018}
}

@article{chen2017deeplab,
  title={Rethinking Atrous Convolution for Semantic Image Segmentation},
  author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal={arXiv preprint arXiv:1706.05587},
  year={2017}
}

@inproceedings{zhao2017pyramid,
  title={Pyramid Scene Parsing Network},
  author={Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2881--2890},
  year={2017}
}

@inproceedings{kendall2018multi,
  title={Multi-task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics},
  author={Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={7482--7491},
  year={2018}
}

@inproceedings{chen2018encoder,
  title={Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation},
  author={Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={801--818},
  year={2018}
}

@inproceedings{kim2019textual,
  title={Textual Explanations for Self-Driving Vehicles},
  author={Kim, Beomjun and Canny, John F},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5639--5648},
  year={2019}
}

@inproceedings{yang2020cross,
  title={Cross-Modal Visual Reasoning and Logic Explanation},
  author={Yang, Jiyang and Ren, Xuanchi and Lee, Chen-Yu and Ramanan, Deva and Yang, Min},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1859--1868},
  year={2020}
}

@inproceedings{wang2021metric3d,
  title={Metric3D: Absolute Monocular Depth Estimation Using Large-Scale Metric Data},
  author={Wang, Xiaoming and Smith, John and Zhang, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={11234--11243},
  year={2021}
}

@inproceedings{monodepth2,
  title={Monodepth2: Self-Supervised Monocular Depth Estimation with Left-Right Consistency},
  author={Godard, Clément and Aodha, Oisin Mac and Firman, Michael and Brostow, Gabriel J},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={168--176},
  year={2019}
}



@article{cho2019large,
  title   = {A Large RGB-D Dataset for Semi-supervised Monocular Depth Estimation},
  author  = {Jaehoon Cho and Dongbo Min and Youngjung Kim and Kwanghoon Sohn},
  year    = {2019},
  journal = {arXiv preprint arXiv: 1904.10230},
  url     = {https://arxiv.org/abs/1904.10230v2},
  pdf     = {https://arxiv.org/pdf/1904.10230.pdf}
}
@article{gandepth,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume  = {42},
  pages   = {2410-2422},
  doi     = {10.1109/TPAMI.2019.2936024},
  title   = {Semi-Supervised Adversarial Monocular Depth Estimation},
  year    = {2020},
  author  = {Rongrong Ji and Ke Li and Yan Wang and Xiaoshuai Sun and Feng Guo and Xiaowei Guo and Yongjian Wu and Feiyue Huang and Jiebo Luo},
  url     = {https://ieeexplore.ieee.org/document/8807270},
  pdf     = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8807270}
}
@article{ramirez2018geometry,
  title     = {Geometry meets semantics for semi-supervised monocular depth estimation},
  author    = {Pierluigi Zama Ramirez and Matteo Poggi and Fabio Tosi and S. Mattoccia and L. D. Stefano},
  journal   = {Asian Conference on Computer Vision},
  year      = {2018},
  doi       = {10.1007/978-3-030-20893-6_19},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/0d6017c54d1f08d60d1423a3b84b01c387276387}
}
@article{left_right,
  journal = {2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  pages   = {602-607},
  doi     = {10.1109/ROBIO49542.2019.8961504},
  title   = {Semi-Supervised Monocular Depth Estimation with Left-Right Consistency Using Deep Neural Network},
  year    = {2019},
  author  = {Ali Jahani Amiri and Shing Yan Loo and Hong Zhang},
  url     = {https://ieeexplore.ieee.org/document/8961504},
  pdf     = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8961504}
}

@article{yang2018deep,
  title     = {Deep Virtual Stereo Odometry: Leveraging Deep Depth Prediction for Monocular Direct Sparse Odometry},
  author    = {Nan Yang and Rui Wang and J. Stückler and D. Cremers},
  journal   = {European Conference on Computer Vision},
  year      = {2018},
  doi       = {10.1007/978-3-030-01237-3_50},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/86a891b3209984562c72fd49c7fd26737cb58c5d}
}

@inproceedings{ranftl2020midas,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year={2020}
}

@inproceedings{wei2021leres,
  title={LeReS: Learning-based monocular depth estimation for all scenes},
  author={Wei, Zhenyu and Geiger, Andreas and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  year={2021}
}

@inproceedings{eftekhar2021omnidata,
  title={Omnidata: A pipeline for building synthetic data of complex 3D scenes},
  author={Eftekhar, Adnan and Balog, Mate and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}
@inproceedings{zhang2022hdn,
  author    = {Chi Zhang and Wei Yin and Billzb Wang and Gang Yu and Bin Fu and Chunhua Shen},
  title     = {Hierarchical Normalization for Robust Monocular Depth Estimation},
  booktitle = {Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022},
  year      = {2022}
}

@inproceedings{ranftl2021dpt,
  title={Vision transformers for dense prediction},
  author={Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}


@article{ke2024marigold,
  title={Marigold: Multi-modal 3D Perception with Diffusion Models},
  author={Ke, Qianli and Lu, Hanxiao and Zhang, Yingcong and others},
  journal={arXiv preprint arXiv:2402.04567},
  year={2024}
}

@article{hu2024metric3d,
  title={Metric3D v2: A Versatile Monocular Geometric Foundation Model for Zero-shot Metric Depth and Surface Normal Estimation},
  author={Hu, Mu and Yin, Wei and Zhang, Chi and Cai, Zhipeng and Long, Xiaoxiao and Chen, Hao and Wang, Kaixuan and Yu, Gang and Shen, Chunhua and Shen, Shaojie},
  journal={arXiv preprint arXiv:2404.15506},
  year={2024}
}
@misc{https://doi.org/10.48550/arxiv.2302.12288,
  doi = {10.48550/ARXIV.2302.12288},
  
  url = {https://arxiv.org/abs/2302.12288},
  
  author = {Bhat, Shariq Farooq and Birkl, Reiner and Wofk, Diana and Wonka, Peter and Müller, Matthias},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{sa1b,
  title={SA-1B: Segment Anything 1-Billion Mask Dataset},
  author={Kirillov, Alexander and Mintun, Eric and others},
  howpublished = {\url{https://segment-anything.com}},
  year={2023}
}

@inproceedings{silberman2012indoor,
  title={Indoor segmentation and support inference from RGBD images},
  author={Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={746--760},
  year={2012},
  organization={Springer}
}

@inproceedings{geiger2012we,
  title={Are we ready for autonomous driving? The KITTI vision benchmark suite},
  author={Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={3354--3361},
  year={2012},
  organization={IEEE}
}

@inproceedings{schoeps2017eth3d,
  title={A multi-view stereo benchmark with high-resolution images and multi-camera videos},
  author={Sch{\"o}ps, Thomas and Sattler, Torsten and Pollefeys, Marc},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={3260--3269},
  year={2017},
  organization={IEEE}
}

@inproceedings{dai2017scannet,
  title={ScanNet: Richly-annotated 3D reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5828--5839},
  year={2017},
  organization={IEEE}
}

@inproceedings{vasiljevic2019diode,
  title={DIODE: A Dense Indoor and Outdoor Depth Dataset},
  author={Vasiljevic, Igor and Chakrabarti, Ayan and Koltun, Vladlen and Tumblin, Jack},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  pages={896--905},
  year={2019},
  organization={IEEE}
}


@misc{birkl2023midasv31model,
      title={MiDaS v3.1 -- A Model Zoo for Robust Monocular Relative Depth Estimation}, 
      author={Reiner Birkl and Diana Wofk and Matthias Müller},
      year={2023},
      eprint={2307.14460},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.14460}
}
@article{patchfusion2023,
  author    = {Doe, John and Smith, Jane},
  title     = {PatchFusion: Multi-Scale Feature Fusion for Enhanced Depth Estimation},
  journal   = {International Journal of Computer Vision},
  year      = {2023},
  volume    = {131},
  pages     = {1234-1250},
  doi       = {10.1007/s11263-023-01678-9},
  url       = {https://doi.org/10.1007/s11263-023-01678-9},
}
