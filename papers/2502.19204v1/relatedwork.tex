\section{Related Work}
\label{sec:Related}
% \vspace{-0.05in}
\subsection{Monocular Depth Estimation}
% \vspace{-0.05in}
Monocular depth estimation (MDE) has evolved from hand-crafted methods to deep learning, significantly improving accuracy \cite{eigen2014depth, laina2016deeper, fu2018deep, godard2017unsupervised, zhou2017unsupervised, ranftl2021vision}. Architectural refinements, such as multi-scale designs and attention mechanisms, have further enhanced feature extraction \cite{hu2018squeeze, chen2017deeplab, zhao2017pyramid}. However, most models remain reliant on labeled data and struggle to generalize across diverse environments.
Zero-shot MDE improves generalization by leveraging large-scale datasets, geometric constraints, and multi-task learning \cite{ranftl2020midas,yin2020diversedepth,yin2020learning,zhang2023robust}. Metric depth estimation incorporates intrinsic data for absolute depth learning \cite{bhat2023zoedepth, yin2023metric3d, hu2024metric3d, wang2024moge}, while generative models such as Marigold refine depth details using diffusion priors \cite{marigold, xu2024diffusion}. 
%Despite these advances, effectively utilizing unlabeled data remains a challenge, as pseudo-labels often contain noise and suffer from inconsistencies across different contexts.
Despite these advances, effectively utilizing unlabeled data remains a challenge due to pseudo-label noise and inconsistencies across different contexts. DepthAnything \cite{depth_anything_v2} explores large-scale unlabeled data but struggles with pseudo-label reliability. PatchFusion \cite{patchfusion2023, miangoleh2021boosting} improves depth estimation by refining high-resolution image representations but lacks adaptability in generative settings.
To address these issues, we propose Cross-Context and Multi-Teacher Distillation, which enhances pseudo-label supervision by leveraging diverse contextual information and multiple expert models, improving both accuracy and generalization ability.

% \vspace{-0.05in}
\subsection{Semi-supervised Monocular Depth Estimation}
% \vspace{-0.05in}

Semi-supervised depth estimation has gained attention by utilizing temporal consistency to better use unlabeled data~\cite{kuznietsov2017semi, guizilini2020robust}. Some methods~\cite{left_right, smolyanskiy2018importance, cho2019large, yang2018deep, monodepth2} apply stereo geometric constraints, enforcing left-right consistency to enhance depth accuracy, while others use additional supervision like semantic priors~\cite{ramirez2018geometry,hoyer2023improving} or GANs, such as DepthGAN~\cite{gandepth}. However, these approaches are limited by their reliance on temporal cues or stereo constraints, restricting their applicability. Recent work~\cite{petrovai2022exploiting} explored pseudo-labeling for semi-supervised MDE but lacks generative modeling capabilities. DepthAnything~\cite{yang2024depthanything} demonstrated the potential of large-scale unlabeled data, though pseudo-label reliability remains challenging. In contrast, our approach improves pseudo-label reliability and enhances MDE accuracy, relying solely on unlabeled data without additional constraints.

\begin{figure}[t]
    \centering  \includegraphics[width=0.47\textwidth]{image/ssi_problem6.pdf}
    % \vspace{-1em}
    \caption{
    \textbf{Issue with Global Normalization (SSI).} 
    In (a), we compare two alignment strategies for the central \( w/2, h/2 \) region: (1) \textit{Global Least-Square}, where alignment is applied to the full image before cropping, and (2) \textit{Local Least-Square}, where alignment is performed on the cropped region. Metrics are computed on the cropped region. As shown in (b), 
    the outperformed local strategy demonstrates
    that \textbf{global normalization degrades local accuracy compared to local normalization}.
    }
    % \vspace{-1.5em}
    \label{fig:normalization}
\end{figure}

\begin{figure*}[!t]
    \centering    \includegraphics[width=0.9\textwidth]{image/method6.pdf}
    \vspace{-1em}
    \caption{
    \textbf{Overview of Cross-Context Distillation.} 
    Our method combines local and global depth information to enhance the student modelâ€™s predictions. It includes two scenarios: (1) \textit{Shared-Context Distillation}, where both models use the same image for distillation;
    and (2) \textit{Local-Global Distillation}, where the teacher predicts depth for overlapping patches while the student predicts the full image. The Local-Global loss $\mathcal{L}_{\text{lg}}$ (Top Right) ensures consistency between local and global predictions, enabling the student to learn both fine details and broad structures, improving accuracy and robustness.
    }
    \vspace{-1em}
    \label{fig:method}
\end{figure*}