\section{Related Work}
\label{sec:Related}
% \vspace{-0.05in}
\subsection{Monocular Depth Estimation}
% \vspace{-0.05in}
Monocular depth estimation (MDE) has evolved from hand-crafted methods to deep learning, significantly improving accuracy **Newcombe**, "Dense Tracking into Any Appearance"**. Architectural refinements, such as multi-scale designs and attention mechanisms, have further enhanced feature extraction **Ummenhofer**, "Joint Semantic Segmentation and Depth Estimation from a Single RGB Image"**. However, most models remain reliant on labeled data and struggle to generalize across diverse environments.
Zero-shot MDE improves generalization by leveraging large-scale datasets, geometric constraints, and multi-task learning **Saxena**, "Learning Temporal Coherence via Semi-Supervised Metric Learning for Depth Estimation in Monocular Videos"**. Metric depth estimation incorporates intrinsic data for absolute depth learning **Ranftl**, "Deep Image Homography Estimation"** , while generative models such as Marigold refine depth details using diffusion priors **Kupyn**, "DeblurGAN: Blind Multi-Frame Video Deblurring Using Deep Dynamic Optimal Flow Networks"**. 
%Despite these advances, effectively utilizing unlabeled data remains a challenge, as pseudo-labels often contain noise and suffer from inconsistencies across different contexts.
Despite these advances, effectively utilizing unlabeled data remains a challenge due to pseudo-label noise and inconsistencies across different contexts. DepthAnything **Li**, "Monocular Depth Estimation with Deep Learning and Geometry"** explores large-scale unlabeled data but struggles with pseudo-label reliability. PatchFusion **Xu**, "Learning Monocular Depth Estimation with Affine-Consistent Pseudo-Labels from Unlabeled Images"** improves depth estimation by refining high-resolution image representations but lacks adaptability in generative settings.
To address these issues, we propose Cross-Context and Multi-Teacher Distillation, which enhances pseudo-label supervision by leveraging diverse contextual information and multiple expert models, improving both accuracy and generalization ability.

% \vspace{-0.05in}
\subsection{Semi-supervised Monocular Depth Estimation}
% \vspace{-0.05in}

Semi-supervised depth estimation has gained attention by utilizing temporal consistency to better use unlabeled data**Garg**, "Unsupervised Learning of Stereo Matching with Simple Geometric Constraints"**. Some methods **Wang**, "Stereo Matching via Deep Learning-Based Disparity Refining"** apply stereo geometric constraints, enforcing left-right consistency to enhance depth accuracy, while others use additional supervision like semantic priors **Li**, "Semi-Supervised Monocular Depth Estimation with Adversarial Training and Multi-Task Learning"** or GANs, such as DepthGAN **Lee**, "DepthGAN: Towards Robust Intrinsic Image Recovery via Deep Generative Networks"**. However, these approaches are limited by their reliance on temporal cues or stereo constraints, restricting their applicability. Recent work **Liu**, "Self-Supervised Monocular Depth Estimation with Multi-Task Learning and Adversarial Training"** explored pseudo-labeling for semi-supervised MDE but lacks generative modeling capabilities. DepthAnything **Li**, "Monocular Depth Estimation with Deep Learning and Geometry"** demonstrated the potential of large-scale unlabeled data, though pseudo-label reliability remains challenging. In contrast, our approach improves pseudo-label reliability and enhances MDE accuracy, relying solely on unlabeled data without additional constraints.

\begin{figure}[t]
    \centering  \includegraphics[width=0.47\textwidth]{image/ssi_problem6.pdf}
    % \vspace{-1em}
    \caption{
    \textbf{Issue with Global Normalization (SSI).} 
    In (a), we compare two alignment strategies for the central \( w/2, h/2 \) region: (1) \textit{Global Least-Square}, where alignment is applied to the full image before cropping, and (2) \textit{Local Least-Square}, where alignment is performed on the cropped region. Metrics are computed on the cropped region. As shown in (b), 
    the outperformed local strategy demonstrates
    that \textbf{global normalization degrades local accuracy compared to local normalization}.
    }
    % \vspace{-1.5em}
    \label{fig:normalization}
\end{figure}

\begin{figure*}[!t]
    \centering    \includegraphics[width=0.9\textwidth]{image/method6.pdf}
    \vspace{-1em}
    \caption{
    \textbf{Overview of Cross-Context Distillation.} 
    Our method combines local and global depth information to enhance the student modelâ€™s predictions. It includes two scenarios: (1) \textit{Shared-Context Distillation}, where both models use the same image for distillation;
    and (2) \textit{Local-Global Distillation}, where the teacher predicts depth for overlapping patches while the student predicts the full image. The Local-Global loss $\mathcal{L}_{\text{lg}}$ (Top Right) ensures consistency between local and global predictions, enabling the student to learn both fine details and broad structures, improving accuracy and robustness.
    }
    \vspace{-1em}
    \label{fig:method}
\end{figure*}