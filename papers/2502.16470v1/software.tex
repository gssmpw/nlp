\section{Software Manager and Interface}
\label{sec:software}

The software interface of \name{} wraps around both the Xilinx XRT environment and the compression functionalities, to provide a familiar and transparent interface to acceleration on both compressed and uncompressed data.

\subsection{Programming Interface}

The \name{} software interface provides a familiar, XRT-style wrapper around accelerated kernel calls.
Let's consider a kernel \texttt{accel} with two device-side buffers ``\texttt{a}'' and ``\texttt{b}'' as parameters, where ``\texttt{a}'' is a genome data source.
If ``\texttt{a}'' comes from a \name{}-managed compressed source, subsections of the file can be transmitted as part of the kernel execution simply by setting \texttt{a.source = \name{}.compressed\_file(1); a.offset = N; a.size = M;}, and then passing it to the kernel via \texttt{accel.kernel(a,b)}.

The current version of the \name{} decompressor only supports stream sources, meaning transmitted buffers are decompressed immediately and provided to the kernel over a FIFO interface.
If the kernel requires random access into a buffer, it must copy the decompressed data to a separate in-memory buffer.
We are working on building an on-device index for compressed data to overcome this limitation.


\subsection{Index Structure}

One of the most important features of compressed data management is random access.
Downstream processing, such as graph construction based on reads, requires each read to be accessed separately, and the fundamental workload of reference-based alignment requires random access capabilities into the reference.

\name{} achieves this feature using a B+tree data structure, as hinted at in Figure~\ref{fig:overall}.
During compression, a B+tree is constructed with the file-internal offset as the key.
The unit element of insertion and lookup is a chunk of compressed data, which shares a single 32-bit header.
While the size of a decompressed chunk can be up to 128 bytes large in our prototype, we discovered that the random access requirement is typically coarser than this, in the unit of long reads.


\subsection{Reference Genome Encoding}

The software environment also must store the reference genome used for compression, because the compression process is split between hardware and software, as described in Section~\ref{sec:compression_arch}.
As described in Section~\ref{sec:compression_arch}, the hardware portion of compression is primarily responsible for calculating the hash function.
On the other hand, the software must perform a lookup into the cuckoo hash table, which is too large to store comfortably in the accelerator, and discover the correct cuckoo hash slot (if any) by comparing the target k-mer against up to four k-mer substrings sampled from the reference genome according to the cuckoo hash lookup.

Because \name{} stores the reference in a compact 2-bit encoded format, comparing k-mers can cause performance overhead due to sub-byte addressing.
For example, if a k-mer starts from offset 7, with two bit encoding, the 7th base starts in bit 6 of byte 2.
Comparing k-mers in this setting requires repeated shifting operations, which can have performance overhead.
To overcome this, \name{} stores four copies of the reference, each shifted from the original by 2 to 6 bits.
During compression, one of the copies are chosen according to the ``offset mod 4'' value, and then fast \texttt{memcmp} can be used since the string would be aligned along byte boundaries.

Both alternatives to storing four binary copies: Storing byte-alined ASCII files, and performing shifts on the fly, showed performance degradation by 4$\times$ on average.

