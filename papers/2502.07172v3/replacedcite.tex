\section{Related work}
\label{sec2}
\subsection{HMER} \label{sec2.1}
Handwritten mathematical expression recognition (HMER) in the field of optical character recognition (OCR) faces significant challenges due to the diverse writing styles and the nested, hierarchical structures of handwritten expressions. Traditional methods____ typically involve two steps: first identifying individual characters and then applying grammatical rules for correction. However, Limited feature-learning capabilities and complex grammatical rules make these traditional methods inadequate for practical applications. With the widespread application and impressive performance of machine learning and deep learning networks in academia, encoder-decoder architectures have increasingly been applied to handwritten formula recognition. This end-to-end recognition framework, resembling a global recognition approach, has significantly improved accuracy in handwritten expression recognition and effectively handles the strong contextual dependencies within formulas. 

Current deep learning-based formula recognition methods can be categorized into two types based on the decoding strategy: one method decodes the formula as a LaTeX expression string, while the other employs tree decoding based on the positional relationships between parent and child nodes. Both approaches have surpassed traditional formula recognition methods in terms of accuracy.

\begin{itemize}
    \item [•] 
    \textbf{Sequence-based Methods.}
    The sequence-based decoding approach for handwritten formula recognition was first introduced by Deng et al.____, achieving the initial transformation from image to LaTeX expression via an encoder-decoder architecture. Building on this, Zhang et al.____ proposed the WAP model which utilizes a fully convolutional encoder to extract image features and introduces a coverage attention mechanism to address attention inaccuracies in long-distance decoding, establishing WAP as the foundational model for most sequence-based recognition methods. Zhang et al.____ further improved upon this with DenseWAP, which employs a DenseNet structure to enhance the encoder and proposes a multi-scale attention decoding model to address challenges in recognizing characters of varying sizes within formulas. In recent years, numerous advancements____ have been built on this model. Wu et al.____ introduced adversarial learning with handwritten and printed text, while Guo et al.____ and Ling et al.____ incorporated contrastive learning, aiding the model in learning style-invariant semantic features and reducing the influence of handwriting styles on formula recognition. Truong et al.____ and Li et al.____ incorporated weak supervision modules into the encoder-decoder framework to provide additional feature information, enhancing model performance. Bian et al.____ introduced mutual learning to handwritten formula recognition, leveraging complementary information to alleviate challenges in long-distance decoding. SAM____ builds a semantic graph based on statistical co-occurrence probabilities, which explicitly demonstrates the dependencies between different symbols; it also proposes a semantic-aware module that takes visual and classification features as inputs and maps them into the semantic space. 
\end{itemize}
\begin{itemize}
    \item [•] 
    \textbf{Tree-based Methods.}
    Tree-based methods convert data expressions into tree structures, which allows for hierarchical relationships to be modeled and enables tree decoders to learn features grounded in grammatical rules. Zhang et al.____ proposed the first image-to-token tree decoding model TDv1. Building on this, Wu et al.____ introduced the TDv2 model, which removes prioritization among branches of tree nodes to enhance the model’s generalization capability and employs a diversified tree structure labeling system to greatly simplify the decoding process. Yuan et al.____ presented the first tree decoding model that integrates syntactic information into the encoder-decoder architecture, introducing decomposition rules based on the syntactic characteristics of formulas. This approach segments formulas into different components to construct the formula tree, effectively mitigating ambiguities associated with tree structures. TAMER____ integrates the strengths of both sequence and tree decoding models, enhancing the model's comprehension and generalization of complex mathematical expression structures through the simultaneous optimization of sequence prediction and tree structure prediction objectives. PosFormer____ jointly optimizes expression recognition and position recognition tasks to explicitly enable position-aware symbol feature learning for representation.
\end{itemize}

\subsection{Semi-supervised learning} \label{sec2.2}
SSL(Semi-supervised learning) is an effective approach to improve model recognition accuracy in scenarios where there is a small amount of labeled data and a larger amount of unlabeled data. These algorithms can be broadly divided into the following categories:

\begin{itemize}
    \item [•] 
    \textbf{Consistency training.}
    Based on the assumption that if a reasonable perturbation is applied to an unlabeled dataset, the model's prediction should not change significantly. Therefore, the model can be trained to produce consistent predictions on a given unlabeled sample and its perturbed version.
\end{itemize}

\begin{itemize}
    \item [•]
    \textbf{Pseudo-label Method.}
    Pseudo-labeling or self-training is a typical technique for leveraging unlabeled data. It alternates between pseudo-label prediction and feature learning, encouraging the model to make confident predictions for unlabeled data. 
\end{itemize}

Semi-supervised learning has been extensively applied in various areas such as image classification, object detection, and image segmentation.

\textbf{Semi-supervised classification}. 
UDA____ employs a back-translation data augmentation method and then utilizes semi-supervised data augmentation techniques in classification tasks, thereby improving classification accuracy. Yalniz et al.____ adopts a teacher/student learning mechanism and leveraging a billion-level amount of unlabeled data along with a relatively small quantity of labeled data, the performance of existing models in image classification tasks has been improved. GLA-DA____ proposed a domain adaptation method for multivariate time series data that leverages global and local feature alignment to improve classification performance in both unsupervised and semi-supervised settings. 

\textbf{Semi-supervised segmentation}.
ST++____ method introduces a reliable pseudo-label selection mechanism along with a weak-to-strong consistency strategy. This allows the model to more accurately identify and leverage high-quality pseudo-labels, reducing the negative impact of noisy data on the segmentation model. MixMatch____, combines data augmentation, consistency regularization, and entropy minimization. It mixes labeled and unlabeled data while applying data augmentation, which helps the model learn more effectively from limited labeled data.  CPS____ uses two networks with identical structures but different initialization. It adds a constraint such that the one-hot pseudo-label generated by one network for a given sample is used as the target for the other network's prediction, with the process supervised by cross-entropy loss. 

\textbf{Semi-supervised object detection}.
STAC____ proposed a semi-supervised object detection algorithm based on hard pseudo-labels. Ambiguity-Resistant Semi-supervised Learning (ARSL)____, including Joint-Confidence Estimation (JCE) and Task-Separation Assignment (TSA), is generally applicable to single-stage semi-supervised object detection tasks. ISTM____ proposed an interactive self-training model. It integrates object detection results from different iterations using Non-Maximum Suppression (NMS) and uses two ROI heads with different structures to estimate each other's pseudo-labels.  TLDR____ proposed a new semi-supervised object detector called Consistent-Teacher by analyzing the existing issues of pseudo-label misalignment and inconsistency in semi-supervised object detection. 

Despite these advancements, there is almost no research on the application of semi-supervised learning in the field of handwritten mathematical expression recognition.