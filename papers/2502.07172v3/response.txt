\section{Related work}
\label{sec2}
\subsection{HMER} \label{sec2.1}
Handwritten mathematical expression recognition (HMER) in the field of optical character recognition (OCR) faces significant challenges due to the diverse writing styles and the nested, hierarchical structures of handwritten expressions. Traditional methods **Deng et al., "Image-to-String: A Deep Learning Framework for Handwritten Formula Recognition"**, **Zhang et al., "WAP: A Deep Learning Model for Handwritten Formula Recognition"** typically involve two steps: first identifying individual characters and then applying grammatical rules for correction. However, Limited feature-learning capabilities and complex grammatical rules make these traditional methods inadequate for practical applications. With the widespread application and impressive performance of machine learning and deep learning networks in academia, encoder-decoder architectures have increasingly been applied to handwritten formula recognition. This end-to-end recognition framework, resembling a global recognition approach, has significantly improved accuracy in handwritten expression recognition and effectively handles the strong contextual dependencies within formulas. 

Current deep learning-based formula recognition methods can be categorized into two types based on the decoding strategy: one method decodes the formula as a LaTeX expression string, while the other employs tree decoding based on the positional relationships between parent and child nodes. Both approaches have surpassed traditional formula recognition methods in terms of accuracy.

\begin{itemize}
    \item [•] 
    \textbf{Sequence-based Methods.}
    The sequence-based decoding approach for handwritten formula recognition was first introduced by **Deng et al., "Image-to-String: A Deep Learning Framework for Handwritten Formula Recognition"**, achieving the initial transformation from image to LaTeX expression via an encoder-decoder architecture. Building on this, **Zhang et al., "WAP: A Deep Learning Model for Handwritten Formula Recognition"** proposed the WAP model which utilizes a fully convolutional encoder to extract image features and introduces a coverage attention mechanism to address attention inaccuracies in long-distance decoding, establishing WAP as the foundational model for most sequence-based recognition methods. **Zhang et al., "DenseWAP: A DenseNet-Based Model for Handwritten Formula Recognition"** further improved upon this with DenseWAP, which employs a DenseNet structure to enhance the encoder and proposes a multi-scale attention decoding model to address challenges in recognizing characters of varying sizes within formulas. In recent years, numerous advancements **Bian et al., "Mutual Learning for Handwritten Formula Recognition"**, **Guo et al., "Contrastive Learning for Handwritten Formula Recognition"**, **Ling et al., "Contrastive Learning for Handwritten Formula Recognition"**, **Truong et al., "Weak Supervision for Handwritten Formula Recognition"**, **Li et al., "Weak Supervision for Handwritten Formula Recognition"**, **Wu et al., "Adversarial Learning for Handwritten and Printed Text"** have been built on this model. **SAM: A Semantic Graph-Based Model for Handwritten Formula Recognition** builds a semantic graph based on statistical co-occurrence probabilities, which explicitly demonstrates the dependencies between different symbols; it also proposes a semantic-aware module that takes visual and classification features as inputs and maps them into the semantic space. 
\end{itemize}
\begin{itemize}
    \item [•] 
    \textbf{Tree-based Methods.}
    Tree-based methods convert data expressions into tree structures, which allows for hierarchical relationships to be modeled and enables tree decoders to learn features grounded in grammatical rules. **Zhang et al., "TDv1: A Deep Learning Model for Handwritten Formula Recognition"** proposed the first image-to-token tree decoding model TDv1. Building on this, **Wu et al., "TDv2: An Improved Tree Decoding Model for Handwritten Formula Recognition"** introduced the TDv2 model, which removes prioritization among branches of tree nodes to enhance the model’s generalization capability and employs a diversified tree structure labeling system to greatly simplify the decoding process. **Yuan et al., "A Syntactic-Aware Tree Decoding Model for Handwritten Formula Recognition"** presented the first tree decoding model that integrates syntactic information into the encoder-decoder architecture, introducing decomposition rules based on the syntactic characteristics of formulas. This approach segments formulas into different components to construct the formula tree, effectively mitigating ambiguities associated with tree structures. **TAMER: A Tree-Aware Model for Handwritten Formula Recognition** integrates the strengths of both sequence and tree decoding models, enhancing the model's comprehension and generalization of complex mathematical expression structures through the simultaneous optimization of sequence prediction and tree structure prediction objectives. **PosFormer: A Position-Aware Symbol Feature Learning Model for Handwritten Formula Recognition** jointly optimizes expression recognition and position recognition tasks to explicitly enable position-aware symbol feature learning for representation.
\end{itemize}

\subsection{Semi-supervised learning} \label{sec2.2}
SSL(Semi-supervised learning) is an effective approach to improve model recognition accuracy in scenarios where there is a small amount of labeled data and a larger amount of unlabeled data. These algorithms can be broadly divided into the following categories:

\begin{itemize}
    \item [•] 
    \textbf{Consistency training.}
    Based on the assumption that if a reasonable perturbation is applied to an unlabeled dataset, the model's prediction should not change significantly. Therefore, the model can be trained to produce consistent predictions on a given unlabeled sample and its perturbed version.
\end{itemize}

\begin{itemize}
    \item [•]
    \textbf{Pseudo-label Method.}
    Pseudo-labeling or self-training is a typical technique for leveraging unlabeled data. It alternates between pseudo-label prediction and feature learning, encouraging the model to make confident predictions for unlabeled data. 
\end{itemize}

Semi-supervised learning has been extensively applied in various areas such as image classification, object detection, and image segmentation.

\textbf{Semi-supervised classification}. 
**UDA: A Semi-Supervised Classification Method** employs a back-translation data augmentation method and then utilizes semi-supervised data augmentation techniques in classification tasks, thereby improving classification accuracy. **Yalniz et al., "Billion-Scale Semi-Supervised Learning for Image Classification"** adopts a teacher/student learning mechanism and leveraging a billion-level amount of unlabeled data along with a relatively small quantity of labeled data, the performance of existing models in image classification tasks has been improved. **GLA-DA: A Domain Adaptation Method for Multivariate Time Series Data** proposed a domain adaptation method that leverages global and local feature alignment to improve classification performance in both unsupervised and semi-supervised settings. 

\textbf{Semi-supervised segmentation}.
**ST++: A Semi-Supervised Segmentation Method** introduces a reliable pseudo-label selection mechanism along with a weak-to-strong consistency strategy. This allows the model to more accurately identify and leverage high-quality pseudo-labels, reducing the negative impact of noisy data on the segmentation model. **MixMatch: A Semi-Supervised Learning Method for Image Classification** combines data augmentation, consistency regularization, and entropy minimization. It mixes labeled and unlabeled data while applying data augmentation, which helps the model learn more effectively from limited labeled data.  **CPS: A Consistency-Based Pseudo-Labeling Method** uses two networks with identical structures but different initialization. It adds a constraint such that the one-hot pseudo-label generated by one network for a given sample is used as the target for the other network's prediction, with the process supervised by cross-entropy loss. 

\textbf{Semi-supervised object detection}.
**STAC: A Semi-Supervised Object Detection Algorithm** proposed a semi-supervised object detection algorithm based on hard pseudo-labels. **Ambiguity-Resistant Semi-supervised Learning (ARSL)**, including Joint-Confidence Estimation (JCE) and Task-Separation Assignment (TSA), is generally applicable to single-stage semi-supervised object detection tasks. **ISTM: An Interactive Self-Training Model** proposed an interactive self-training model. It integrates object detection results from different iterations using Non-Maximum Suppression (NMS) and uses two ROI heads with different structures to estimate each other's pseudo-labels.  **TLDR: A Consistent-Teacher Object Detection Method** proposed a new semi-supervised object detector called Consistent-Teacher by analyzing the existing issues of pseudo-label misalignment and inconsistency in semi-supervised object detection. 

Despite these advancements, there is almost no research on the application of semi-supervised learning in the field of handwritten mathematical expression recognition.