\section{Algorithms for Synthetic Histograms with Relative Accuracy}\label{sec:upper-bounds}

In this section, we introduce the $\PREM$ framework for generating synthetic histograms with relative error guarantees, starting with the case of approximate-DP.

\subsection{Approximate-DP Algorithm}

\label{sec:approx_DP_synthetic_data}


\begin{theorem} \label{thm:main}
For all $0< \eps \leq 1$, $\delta \in (0, 1)$, $\beta \in (0, 1)$, and $\zeta \in (0, \nicefrac12)$, 
there is an $(\eps, \delta)$-DP $(\zeta,\alpha,\beta,\cF)$-accurate synthetic data generator for any domain $\cX$ and query family $\cF$ with
\[
    \alpha = \tO\prn{\frac{1}{\zeta\eps} \cdot \Big(\log n \cdot  \log\frac1\delta \Big)^{\frac32} \cdot \log^{\frac12} |\cX| \cdot \log \prn{\textstyle \frac{|\cF|}{\beta}}
    }.
\]
\end{theorem}

\paragraph{Proof Intuition.} 
Let us start by recalling the PMWU framework  of~\citet{HardtR10,HardtLM12}, which uses a private version of the multiplicative weights update (MWU) rule and yields nearly tight guarantee in the additive-only setting. At a high level, this algorithm starts with a synthetic dataset $\hbh$ and iteratively updates it. In each iteration, PMWU identifies a query $f \in \cF$ with large error. The synthetic dataset $\hbh$ is then updated using an MWU rule.

A key parameter that governs the number of required iterations is the \emph{margin}, which can be defined as the normalized error of $f$ between the synthetic dataset $\hbh$ and the true dataset $\bh$  (i.e., $|f(\hbh) - f(\bh)| / n$). When the margin is $\gamma$, the number of required updates is $\tO(1/\gamma^2)$. 
%
As discussed in \Cref{tab:prior-work-our-results}, all previous works~\citep{HardtR10,HardtLM12,GuptaRU12} incur error that is polynomial in $n$ 
because the number of updates required in their  algorithm is polynomial in $n$. 
This is because the guaranteed margin of a large additive-gap query is only 
$\alpha / n$, which leads to a bound of 
$\tOmega((n/\alpha)^2)$ iterations in PMWU. 

At a high level, our main observation is that we can make this margin $\zeta$ instead of $\alpha/n$, allowing us to (drastically) 
reduce the number of iterations to $\tO(1/\zeta^2)$. 
However, achieving such a margin is quite challenging: previous frameworks~\citep{HardtR10,HardtLM12,GuptaRU12} use either the 
exponential mechanism or \textsc{SVT} to select a \emph{single} query from $\cF$ for which the current distribution performs poorly and use it
as the example for update. Unfortunately, this does not suffice: if all counting queries are sparse (e.g.,~counting a single domain element), 
then it is possible that the margin of any query in $\cF$ here is only $O(\alpha/n)$.
Our key technique to overcome this is the observation that when queries are sparse, we can run $\OutsideIntervalMonitor$, which using the target charging can select \emph{multiple} queries that---after appropriate corrections from previous queries---differ by more than $1 \pm \zeta$ from the target value. Roughly speaking, this allows us to combine all these queries together to construct a bad ``example'' with margin $\Omega(\zeta)$.


\subsubsection{Finding a Bad Margin Example with $\OutsideIntervalMonitor$}

As discussed above, a key ingredient of our approach is identifying a bad ``example'' i.e.~a large support set where the candidate histogram fails to multiplicatively approximate the true counts; if such example does not exist, we certify a uniform relative approximation for all queries over a large set. We present this subroutine, \Cref{alg:find-example}, together with its privacy and accuracy guarantees. This algorithm maintains two violating sets, $\cS^+$, $\cS^-$: these sets aggregate the supports of queries that violate the respective upper and lower bounds imposed by the desired relative approximation. 

\begin{algorithm}[t]
\small
\caption{$\FindMarginExample_{\cF,\eps,\delta,\beta,\zeta}$}
    \label{alg:find-example}
        \textbf{Parameters:}
            {\footnotesize $\bullet$ } privacy parameters $ \eps >0$ and $0 < \delta < 1$; 
            \,
            {\footnotesize $\bullet$ } confidence parameter $0 < \beta < 1$;\\
        \phantom{{\bf Parameters}:}
            {\footnotesize $\bullet$ } approximation factor $0 < \zeta < 1 / 2$;
            \quad \quad \quad
            {\footnotesize $\bullet$ } set of counting queries $\cF\subseteq \{0, 1\}^{\cX}$;\\[-2mm]
        
        \textbf{Input:}
        {\footnotesize $\bullet$ } private input histogram $\bh^{\ast} \in \Z_{\ge 0}^{\cX}$ with $\|\bh^{\ast}\|_1=n$;\\
        \phantom{{\bf Input:}}
        {\footnotesize $\bullet$ } currently estimated histogram $\hbh\in \R_{\geq 0}^{\cX}$;\\
        \phantom{{\bf Input:}}
        {\footnotesize $\bullet$ } active set $\cY\subseteq \cX$;\\[-2mm]
        
        $\Splus, \Sminus \gets \emptyset$ and 
        $\Sactive \gets \cY$\\
        $\OIM \gets \OutsideIntervalMonitor^{\mathrm{apx}}_{\bh^{\ast},a,\cY}$ for $a = \eps / O(\log(1/\delta))$\\[1mm]
        \mbox{}\algcomment{initialized with $a$ such that $\OIM$ satisfies $(\eps, \delta)$-DP (via \Cref{prop:oim-approx-dp})}\\
        $\alpha_0\gets \frac{4(1+\zeta)}{a}\ln\big(\frac{|\cF|}{\beta}\big)$\algcomment{equals $2(1+\zeta)C$ for $C$ given in \Cref{prop:oim-approx-dp} for $R = |\cF|^2$.}\\
        $\Factive\gets \cF$\; \hfill\algcomment{maintains a set of queries not already handled}
        
        \Repeat{\textsc{Accurate}}{
            \textsc{Accurate} $\gets$ \textsc{True}
            
            \For{$f\in\Factive$}{
                $\tau_u \gets \frac{1}{(1-\zeta)}\big( f(\hbh|_{\Sactive})+\frac{\alpha_0}{2}\big)$ and $\tau_\ell \gets \frac{1}{(1+\zeta)}\big(f(\hbh|_{\Sactive})-\frac{\alpha_0}{2}\big)$

                $s \gets \OIM(f, \tau_u, \tau_\ell)$

                \If{$s \ne \Between$}{
                    \If{$s = \textsc{Above}$}{
                        $\Splus\gets\Splus\cup(\Sactive\cap f^{-1}(1))$\;
                    }
                    \Else {
                        $\Sminus\gets\Sminus\cup(\Sactive\cap f^{-1}(1))$\;
                    }
                    
                    $\Sactive\gets \Sactive \smallsetminus f^{-1}(1)$\; \algcomment{Identical to $\Sactive$ maintained in state of $\OIM$.}\\
                    $\Factive\gets \Factive\smallsetminus \{f\}$\;\\
                    \textsc{Accurate} $\gets$  \textsc{False}\;
                }
            }
        }
        \Return{$(\theta,\cS)\gets \begin{cases}
            (\plus,\Splus) & \text{\em if } \ind_{\Splus}(\hbh) \ge \max\{ \ind_{\Sminus}(\hbh), \ind_{\Sactive}(\hbh) \} \\
            (\minus,\Sminus) & \text{\em if } \ind_{\Sminus}(\hbh) \ge \max\{ \ind_{\Splus}(\hbh), \ind_{\Sactive}(\hbh) \}  \\
            (\equal, \Sactive) & \text{\em if } \ind_{\Sactive}(\hbh) \ge \max\{ \ind_{\Sminus}(\hbh), \ind_{\Splus}(\hbh) \} 
            \end{cases}$
        }
\end{algorithm}



\begin{lemma} \label{lem:bad-margin}
    For all $\cF$, $0<\eps \leq 1$, 
    $\delta, \beta, \zeta \in (0, 1)$, $\FindMarginExample_{\cF,\eps,\delta,\beta,\zeta}$ (\Cref{alg:find-example}) satisfies $(\eps, \delta)$-DP. 
    Moreover, given active set $\cY\subseteq\cX$, private histogram $\bh^{\ast}\in\N_+^{\cX}$, 
    and an estimate histogram $\hbh\in\R_+^{\cX}$, the output $(\theta, \cS)$ satisfies:
    \begin{itemize}
    \item $\ind_\cS(\hbh) \geq \frac{1}{3} \ind_{\cY}(\hbh)$.
    \item With probability $1-\beta$ (see the pseudocode for the value of $\alpha_0$):
        \begin{itemize}
            \item If $\theta = \equal$, for all $f\in \cF$, $(1 - \zeta) \cdot f(\bh^{\ast}|_{\cS}) - \alpha_0 \leq f(\hbh|_{\cS})  \leq (1 + \zeta) \cdot f(\bh^{\ast}|_{\cS}) + \alpha_0$.
            \item If $\theta = \plus$, $\ind_{\cS}(\bh^{\ast})  \geq (1 + \zeta) \cdot \ind_{\cS}(\hbh)$.
            \item If $\theta = \minus$, $\ind_{\cS}(\bh^{\ast}) \leq (1 - \zeta/2) \cdot \ind_{\cS}(\hbh)$.
        \end{itemize}
    \end{itemize}
\end{lemma}

\begin{proof}
The privacy guarantee follows immediately from \Cref{prop:oim-approx-dp} (for suitable $a = \eps / O(\log \frac1\delta)$), since the private histogram $\bh^\ast$ is only accessed through queries to $\OutsideIntervalMonitor$.

Since $\Splus$, $\Sminus$, $\Sactive$ form a partition of $\cY$, we have $\max\{ \ind_{\Splus}(\hbh), \ind_{\Sminus}(\hbh), \ind_{\Sactive}(\hbh) \}\geq \|\hbh\|_1/3$. And hence $\ind_{\cS}(\hbh) \geq \frac{1}{3}  \ind_\cY(\hbh)$.

Next, we proceed to the second part. Note that there can be at most $|\cF|$ iterations in the \textbf{repeat}--\textbf{until} loop, since $|\Factive|$ decreases every iteration if the loop does not terminate. Therefore, the number of queries made to $\OIM$ is at most $|\cF|^2$. Thus, from \Cref{prop:oim-approx-dp}, with probability at least $1 - \beta$, all the responses of $\OIM$ are accurate to within 
$C = \frac2a \log \frac{|\cF|}{\beta} = \frac{\alpha_0}{2(1+\zeta)}$. 
Conditioned on this event, we obtain the accuracy guarantee for each of the three cases of $\theta$ as follows:
    \begin{description}[leftmargin=5pt]
        \item[{\boldmath Case $\theta=\textsc{Approx}$}:] Let $\Factive$ refer to the state of this set at the end of the algorithm. For $f\notin\Factive$ it holds that $f(x) = 0$ for all $x \in \Sactive$, and hence $f(\hbh|_{\Sactive}) = f(\bh^{\ast}|_{\Sactive}) = 0$.

        In the last loop of \textbf{repeat}--\textbf{until}, we have that $\OIM(f, \tau_u, \tau_\ell)$ returns a response of $\Between$ for all $f \in \Factive$. Hence conditioned on the accuracy guarantee of $\OIM$, we have that
            \begin{eqnarray*}
                \frac{1}{1+\zeta}\left( f(\hbh|_{\Sactive}) - \frac{\alpha_0}{2} \right) - C\leq & 
                f(\bh^{\ast}|_{\Sactive})
                & \leq \frac{1}{1-\zeta}\left( f(\hbh|_{\Sactive}) + \frac{\alpha_0}{2} \right) + C \\
                \Longrightarrow
                (1-\zeta)f(\bh^{\ast}|_{\Sactive}) -\alpha_0 \leq 
                & f(\hbh|_{\Sactive}) &
                \leq (1+\zeta)f(\bh^{\ast}|_{\Sactive}) + \alpha_0.
            \end{eqnarray*}
            We conclude that $\hbh|_{\Sactive}$ is $(\zeta,\alpha_0,\Factive)$-accurate, and in conjunction with the perfect accuracy over $\cF\setminus\Factive$ concludes the proof of the claim.
        \item[{\boldmath Case $\theta=\plus$}:] Conditioned on the accuracy guarantee of $\OIM$, at every query $(f,\tau_\ell,\tau_u)$ where $\OIM$'s output is $\Above$, we have that
        \begin{align*}
        \textstyle
        \ind_{\Sactive\cap f^{-1}(1)}(\bh^{\ast})
            & \textstyle = f(\bh^{\ast}|_{\Sactive})
            ~\geq~ \frac{1}{(1-\zeta)}\big( f(\hbh|_{\Sactive}) + \frac{\alpha_0}{2} \big) - C\\
            &\textstyle\geq \frac{1}{(1-\zeta)} \cdot   \ind_{\Sactive\cap f^{-1}(1)}(\hbh) 
            ~\geq~ (1+\zeta) \cdot \ind_{\Sactive\cap f^{-1}(1)}(\hbh),
        \end{align*}
        where $\Sactive$ is the state before the query is performed.
            Finally, since the subsets $\Sactive\cap f^{-1}(1)$
        obtained are disjoint across iterations, and their union is $\Splus$, adding up these inequalities we get
            $\ind_{\Splus}(\bh^{\ast}) 
            \geq (1+\zeta) \cdot \ind_{\Splus}(\hbh)$.
        \item[{\boldmath Case $\theta=\minus$}:] Conditioned on the accuracy guarantee of $\OIM$, at every query $(f, \tau_\ell, \tau_u)$ where $\OIM$'s output is $\Below$, we have 
        (since $\alpha_0 = 2(1+\zeta) C$), that
        \begin{align*}
            \textstyle \ind_{\Sactive\cap f^{-1}(1)}(\bh^{\ast})
            &\textstyle= f(\bh^{\ast}|_{\Sactive})
            \leq \frac{1}{(1+\zeta)}\big( f(\hbh|_{\Sactive}) - \frac{\alpha_0}{2} \big) + C\\
            &\textstyle\leq \frac{1}{(1+\zeta)} \cdot  \ind_{\Sactive\cap f^{-1}(1)}(\hbh) 
            \leq (1-\frac\zeta2) \cdot \ind_{\Sactive\cap f^{-1}(1)}(\hbh),
        \end{align*}
        where $\Sactive$ is the state before the query is performed.
        Finally, since the subsets $\Sactive\cap f^{-1}(1)$
        obtained are disjoint across iterations, and their union is $\Sminus$, adding up these inequalities we get
        $
            \ind_{\Sminus}(\bh^{\ast})  
            \leq (1-\frac\zeta2) \cdot \ind_{\Sminus}( \hbh)
        $.
    \end{description}
    \vspace{-6mm}
\end{proof}



\subsubsection{$\PREM$ and Proof of \Cref{thm:main}}

We now present $\PREM$ (\Cref{alg:dp-mwu}) for $\delta>0$ (the case of $\delta=0$ is considered in \Cref{sec:pure_DP_UB}), that underlies \Cref{thm:main}. We sketch the main idea at an intuitive level.
This algorithm operates in multiple rounds, which work as follows with high probability.

At the start of round $i$, an ``active set'' $\cX^i$ is maintained such that we have an estimate $\hbh$ supported on ${\cX \smallsetminus \cX^i}$ satisfying $\hbh \approx_{\cF,\zeta,\alpha_*} \bh^*|_{\cX \smallsetminus \cX^i}$ (denoting that $f(\hbh) \in (1 \pm \zeta) f(\bh^{\ast}|_{\cX \smallsetminus \cX^i}) \pm \alpha_*$ for all queries $f \in \cF$).
At the end of round $i$, we identify a new set $\cS^i \subseteq \cX^i$ such that $\bh^{\ast}|_{\cS^i}$ contains a constant fraction of the active set mass of $\bh^{\ast}|_{\cX^i}$, and an estimate $\hbh^{i}$ supported only on $\cS^i$ such that $\hbh^{i} \approx_{\cF, \zeta, \alpha_0} \bh^{\ast}|_{\cS^i}$. By setting $\hbh \gets \hbh + \hbh^i$ and $\cX^{i+1} \gets \cX^i \smallsetminus \cS^i$, the invariant is maintained (for $\alpha_* \gets \alpha_* + \alpha_0$), and the active set mass shrinks by a constant factor. Thus, in at most $I = O(\log n)$ rounds, most of the mass of $\bh^*$ is accounted for.

To identify the subset $\cS^i$ and the estimate $\hbh^i$ at every round, we start with $\hbh^i$ being uniform over $\cX^i$ and use $\FindMarginExample$ (\Cref{alg:find-example}) iteratively to either update $\hbh^i$ using a MWU or certify its accuracy on a large support $\cS^i$. Using a potential function argument, we show that this terminates in a small number of rounds with high probability.
\begin{algorithm}[t]
\small
    \caption{$\PREM_{\cF,\eps,\delta,\beta,\zeta}$ : \textsc{Private Relative Error MWU}}
    \label{alg:dp-mwu}
        \textbf{Parameters:}
            {\footnotesize $\bullet$ } privacy parameters $\eps > 0$ and $0 \leq \delta < 1$;
            \ \ {\footnotesize $\bullet$ } confidence parameter $0 < \beta < 1$;\\
        \phantom{\textbf{Parameters:}}
            {\footnotesize $\bullet$ } approximation factor $0 < \zeta < 1 / 2$;
            \quad \quad \quad
            {\footnotesize $\bullet$ } query family $\cF\subseteq \{0, 1\}^{\cX}$;

        \textbf{Input:} input histogram $\bh^{\ast} \in \N^{\cX}$ with $\|\bh^{\ast}\|_1=n$.
        
        $I \gets \lceil \frac{\log n}{\ln 6/5}\rceil$\\
        $T \gets \lceil\frac{128\log |\cX|}{\zeta^2}\rceil$

        $\eta\gets \zeta/4$; $\beta'\gets \beta/(2IT)$; $\cX^1 \gets \cX$
        
        \If{$\delta=0$}{
            $\delta'\gets 0$;\,\, $\eps'\gets\eps/(2IT)$\;\\
            $a\gets \eps/I$;\,\, $\alpha\gets \tilde O\Big( \max\big\{\sqrt{\frac{n \log^3 n}{\zeta^2\eps}\log|\cX|\log\big(\frac{|\cF|}{\beta}\big)},\frac{\log n}{\eps} \big\} \Big)$\;
        }\Else{
            $\delta'\gets\delta/(4IT)$\;\\
            Let $\eps'>0$ be the unique solution to $\frac{\eps}{2} =\eps' O(\log(1/\delta'))\big( \sqrt{2IT\ln(1/\delta')}+IT\big(\frac{e^{\eps'}-1}{e^{\eps'}+1}\big)\big)$\\
            \mbox{}\algcomment{$IT$-fold composition of $\OutsideIntervalMonitor$ must satisfy $(\eps/2,\delta/2)$-DP.}\\
            $a\gets \eps/(4\sqrt{2I\log(I/\delta)})$; 
            $\alpha \gets 
            \frac{200 I}{\eps'}\log\big(\frac{4|\cF|}{\beta'}\big)$\;
        }

        $\hbh \gets {\bm 0} \in \Z_{\ge 0}^{\cX}$\algcomment{Current estimate of the histogram}

        \For{$i = 1$ to $I$}{
            $\tilde n_i \gets \|\bh^{\ast}|_{\cX^i}\|_1+\mbox{Lap}\big(1/a\big)$

            \If{$\tilde n_i\leq \alpha/4$}{
                \textsc{Break}
            }
            $\hbh^{i} \gets \frac{\tilde n_i}{|\cX^i|}\ind_{\cX^i}$ \algcomment{Initialize as uniform over active set, with roughly the right total mass}\\
            \For{$t = 1,\ldots,T+1$}{
        	\If{$t=T+1$}{
        		  \Return{\textsc{Failure}}
        	}
        	$(\theta^i, \cS^i) \gets \textsc{FindMarginExample}_{\cF,\eps',\delta',\beta',\zeta}(\bh^{\ast}, \hbh^{i}, \cX^i)$\\
        	\If{$\theta^i = \equal$}{
                        $\hbh \gets \hbh + \hbh^{i}|_{\cS^i}$\\
            		$\cX^{i+1} \gets \cX^i \setminus {\cS^i}$\\
            		\textsc{Break}
        	}
                \Else{
                    $\hbh^{i} \gets \tilde n_i \cdot \frac{\hbh^{i}\odot \exp\big\{\theta^i\eta\ind_{\cS^i}\big\}}{\|\hbh^{i}\odot \exp\big\{\theta^i\eta\ind_{\cS^i}\big\}\|_1} $\algcomment{where $a \odot b$ denotes pointwise product of $a, b \in \R_{\ge 0}^{\cX}$.}
                }
            }
        }

        \Return{$\hbh$}
\end{algorithm}



Before proving the theorem, we establish a non-failure probability guarantee for the algorithm.

\begin{claim} \label{claim:failure_PREM}
\Cref{alg:dp-mwu} returns \textsc{Failure} with probability at most $2\beta'IT$.
\end{claim}

\begin{proof}
First, notice that as $i$ plays no role in this analysis, we will omit its dependence. In this context, we work on the restricted sample space $\cX\gets\cX^i$, together with private data $\bh^{\ast}\gets \bh^{\ast}|_{\cX^i}$, sample size $n\gets n_i:=\|\bh^{\ast}|_{\cX^i}\|_1$ and $\tilde n\gets \tilde n_i=\|\hbh^{i,t}\|_1$. Note that by the properties of Laplace noise, with probability $1-I\beta'$, 
\begin{equation} \label{eqn:Laplace_concentration_MWU}
\textstyle |n_i-\tilde n_i|\leq \frac{4\sqrt{2I\ln(I/\delta)}}{\eps}\ln\big(\frac{1}{\beta'}\big) \quad(\forall i=1,\ldots,I). 
\end{equation}
This concentration bound implies that if $\tilde n_i> \alpha/4$ then $n_i> \alpha/6$, by the definition of $\alpha$.


Next we proceed with a large-margin analysis of the MWU method. 
In particular, \Cref{alg:find-example} provides the following guarantee (\Cref{lem:bad-margin}): denoting by $(\theta_t,\cS_t)$ its output and $\hbh^t$ the histogram $\hbh^i$, at their $t$-th inner iteration, 
if $\theta_t\in\{\plus,\minus\}$ then with probability $1-\beta'IT$, for all $t,i$ 
\begin{align} 
\theta_t \left( \ind_{\cS_t}(\bh^{\ast}) - \ind_{\cS_t}(\hbh^t) \right) &\geq \frac{\zeta}{2} \ind_{\cS_t}(\hbh^t)  \label{eqn:large_margin_convergence} \\
\ind_{\cS_t}(\hbh) &\geq \frac13 \ind_{\cX}(\hbh). \label{eqn:large_weight_convergence}
\end{align}
%
We now proceed with a potential function analysis for upper bounding the failure probability~\citep[see, e.g., Chapter 7 in][]{Mohri:2018}. Consider the
potential function $\Phi_t=\mbox{KL}\big(\frac{\bh^{\ast}}{\|\bh^{\ast}\|_1}\big|\big|\frac{\hbh^t}{\|\hbh^t\|_1}\big)=\sum_{x\in \cX} \frac{\bh^{\ast}(x)}{n}\ln\Big( \frac{\bh^{\ast}(x)/n}{\hbh^t/\tilde n} \Big)$. 
Note that $\Phi_1 \le \ln |\cX|$ since $\hbh^t / \|\hbh^t\|_1$ is the uniform distribution and $\Phi_{T+1} \ge 0$. Hence. $\Phi_{T+1}-\Phi_1 \geq - \ln|\cX|.$ On the other hand, under the events established above:
\begin{align*}
\Phi_{t+1}-\Phi_t 
&= \sum_{x\in \cX} \frac{\bh^{\ast}(x)}{n}\ln\Big( e^{-\theta_t\eta \ind_{\cS_t}(x)} \sum_{y\in \cX}\frac{\hbh^t(y)}{\tilde n}e^{\theta_t\eta \ind_{\cS_t}(y)} \Big) \\
&=-\sum_{x\in \cX}\frac{\bh^{\ast}(x)}{n}\cdot\theta_t\eta\ind_{\cS_t}(x)+\ln\Big( \sum_{y\in \cX} \frac{\hbh^t(y)}{\tilde n}\exp\{\theta_t\eta\ind_{\cS_t}(y)\} \Big).
\end{align*}
Let now $P_t$ be the probability over $\cX$ where $P_t(x)=\hbh^t(x)/\tilde n$, and let $\mu_t=\mathbb{E}_{y\sim P_t}[\theta_t\eta \cdot \ind_{\cS_t}(y)]=\theta_t\eta \cdot \ind_{\cS_t}(\frac{\hbh^t}{\tilde n})$. Hoeffding's bound in \citet[Lemma B.7]{ShalevShwartz:2014} implies 
\[ \ln\Big( \sum_{y\in \cX} \frac{\hbh^t(y)}{\tilde n}\exp\{\theta_t\eta\ind_{\cS_t}(y)-\mu_t\} \Big) = \ln\Big( \mathbb{E}_{y\sim P_t} \big[\exp\{\theta_t\eta   \ind_{\cS_t}(y)-\mu_t\}\big]\Big) \leq \frac{\eta^2}{8}. \]
Re-arranging the potential drop to incorporate this term, we conclude that
\begin{align*}
\Phi_{t+1}-\Phi_t 
&\leq-\theta_t\eta \cdot \left( \ind_{\cS_t}\left(\frac{\bh^{\ast}}{n}\right) - \ind_{\cS_t}\left(\frac{\hbh^t}{\tilde n}\right) \right)
+\frac{\eta^2}{8}\\
&= -\frac{\theta_t\eta}{n} \cdot ( \ind_{\cS_t}(\bh^{\ast}) - \ind_{\cS_t}(\hbh^t) ) - \theta_t\eta \cdot \left(\frac1n-\frac{1}{\tilde n}\right) \cdot \ind_{\cS_t}(\hbh^t) + \frac{\eta^2}{8}.
\end{align*}
Now to bound the resulting expression, note that the first summand can be bounded using \eqref{eqn:large_margin_convergence}, 
whereas for the second one we can use \eqref{eqn:Laplace_concentration_MWU} to conclude that
\[\textstyle - \theta_t\eta\big(\frac1n-\frac{1}{\tilde n}\big) \cdot \ind_{\cS_t}(\hbh^t) \leq \frac{\eta}{n\tilde n} \frac{4\sqrt{2I\ln(I/\delta)}}{\eps}\log \frac{1}{\beta'} \cdot \ind_{\cS_t}(\hbh^t). \]
Now, noting that upon non-termination of the algorithm, $\tilde n > \frac{\alpha}{4} \geq \frac{64\sqrt{2I\ln(I/\delta)}}{\zeta\eps}\ln \frac{1}{\beta'}$, we have
\begin{align*} 
&\textstyle-\frac{\zeta\eta}{2n} \cdot \ind_{\cS_t}(\hbh^t) +\frac{\eta}{n\tilde n} \frac{4\sqrt{2I\ln(I/\delta)}}{\eps}\log \frac{1}{\beta'} \cdot \ind_{\cS_t}(\hbh^t) \textstyle = -\frac{\zeta\eta}{2n}\Big(1-\frac{8\sqrt{2I\ln(I/\delta)}}{\zeta\tilde n\eps}\log \frac{1}{\beta'} \Big) \cdot \ind_{\cS_t}(\hbh^t) \\
& \leq -\frac{3\zeta \eta}{8n} \cdot \ind_{\cS_t}(\hbh^t) \textstyle \leq -\frac{\zeta \eta}{8n} \cdot \ind_{\cX}(\hbh^t) \leq-\frac{\zeta \eta}{8n} \Big( n-\frac{4\sqrt{2I\ln(I/\delta)}}{\eps}\ln \frac{1}{\beta'} \Big) 
\leq  -\frac{\zeta \eta}{16}, 
\end{align*}
where in the third inequality we used again the bound \eqref{eqn:Laplace_concentration_MWU}, and in the last one the fact that upon non-termination and \eqref{eqn:Laplace_concentration_MWU}, $n\geq \frac{\alpha}{6}\geq \frac{16\sqrt{2I\ln(I/\delta)}}{\eps}\log(1/\beta')$. 

By the choice $\eta=\frac{\zeta}{4}$, we get $-\ln|\cX| \leq \Phi_{t+1}-\Phi_1\leq -\frac{(t+1)\zeta^2}{128}$. 
We conclude that under the established event (which happens with probability at least $1-2\beta'TI=1-\beta$) the algorithm must break its inner loop within $t\leq T$ steps. This concludes the proof of the claim. 
\end{proof}

\begin{proofof}{\Cref{thm:main}}
The privacy of \Cref{alg:dp-mwu} follows from the privacy of \Cref{alg:find-example} and the adaptive composition theorem (\Cref{prop:dp-composition}). 
First, the counts $\tilde n_i$ incur a cumulative privacy budget of $(\eps/2,\delta/2)$ by adaptive composition; and second, our definition of $(\eps',\delta')$ is such that the total privacy budget incurred by the composition of $IT$ applications of $\OutsideIntervalMonitor$ is  $(\eps/2,\delta/2)$. 

%\Restructured Proof
We proceed to the accuracy analysis of the algorithm. Throughout, we condition on event \eqref{eqn:Laplace_concentration_MWU}. 
We first observe that  the weight of the restricted histograms  decreases exponentially quickly, which gives a bound on the number of steps until the outer loop breaks. First, by definition of $\cX^i$:
\begin{align*} 
\|\bh^{\ast}|_{\cX^i}\|_1-\|\bh^{\ast}|_{\cX^{i+1}}\|_1 =\|\bh^{\ast}|_{\cS^i}\|_1
\geq \frac{\|\bh^{\ast}|_{\cX^i}\|_1}{6}-\frac53\alpha_0,
\end{align*}
where the last step follows from \Cref{lem:bad-margin} as follows:\footnote{In the first inequality that follows, we are implicitly assuming that the ``all-ones'' query, $f\equiv \mathds{1}\in\cF$. This is without loss of generality, as it only increases the query family by one element.}
\begin{align*}
\textstyle \|\bh^{\ast}|_{\cS^i}\|_1 
&\textstyle = \ind_{\cS^i}(\bh^{\ast})   
\geq \frac{1}{1+\zeta}\left( \ind_{\cS^i}(\hbh^{i}) -\alpha_0 \right)
\geq 
\frac{1}{1+\zeta}\left(\frac{ \|\hbh^{i}\|_1 }{3} -\alpha_0\right) 
 =  \frac{1}{1+\zeta}\left(\frac{ \tilde n_i }{3} -\alpha_0\right) \\
&\textstyle \geq  \frac{1}{1+\zeta}\left(\frac{ \|\bh^{\ast}|_{\cX^i}\|_1 }{3} -\frac{4\sqrt{2I\ln(I/\delta)}}{3\eps}\ln \frac{1}{\beta'}-\alpha_0\right) 
\geq \frac{\|\bh^{\ast}|_{\cX^i}\|_1}{6}-\frac{5}{3}\alpha_0.
\end{align*}
This implies that $n_i:=\|\bh^{\ast}|_{\cX^i}\|_1$ satisfies the recurrence $n_{i+1} \leq \frac56 n_i+\frac53\alpha_0$, thus
$n_I \leq \big(\frac56\big)^In+10\alpha_0.$ 
In particular, selecting $I=\frac{\ln n}{\ln 6/5}$, we have that $n_I\leq 11\alpha_0\leq \alpha/8$ (where the last inequality is by definition of $\alpha$). Note that under \eqref{eqn:Laplace_concentration_MWU}, $n_i\leq \alpha/8$ implies $\tilde n_i\leq \alpha/4$, hence the outer loop breaks.




Let $i^*\in[I]$ be the iteration where the outer loop breaks. We claim that the sum of the final histograms, $\sum_{i< i^{\ast}}\hbh^{i}|_{\cS^i}$, is $(\zeta,2\alpha/3,\cF)$-accurate w.r.t. $\bh^{\ast}|_{\cY}$, where $\cY=\bigcup_{i<i^{\ast}}\cS^i$.


By \Cref{lem:bad-margin},
if the algorithm never fails, we obtain at every $i<i^{\ast}$ a pair $\hbh^{i},\cS^i$ such that 
\[ (1-\zeta) \cdot f(\bh^{\ast}|_{\cS^i}) - \alpha_0 \leq   f(\hbh^{i}|_{\cS^i}) \leq (1+\zeta) \cdot  f(\bh^{\ast}|_{\cS^i}) +\alpha_0 \quad(\forall f\in \cF),\]
where we recall that $\alpha_0=\frac{4(1+\zeta)}{a}\ln \frac{|\cF|}{\beta'}$ from \Cref{alg:find-example}. Moreover, 
adding up these inequalities, and noting that $\cY=\bigcup_{i<i^{\ast}} \cS^i$ be the (disjoint) union of the supports of $(\hbh^{i})_{i=1,\ldots,I}$, we get
\[ (1-\zeta) \cdot f(\bh^{\ast}|_{\cY}) - I\alpha_0 \leq f(\hbh) \leq (1+\zeta) \cdot f(\bh^{\ast}|_\cY) +I\alpha_0 \quad(\forall f\in \cF).\]
Notice that $I\alpha_0\leq 2\alpha/3$, by definition of $\alpha$. This proves our claim.

Next, 
note that the zero histogram 
is $(0,\alpha/3,\cF)$-accurate w.r.t.~$\bh^{\ast}|_{\cX_{i^{\ast}}}$. This  follows from the event \eqref{eqn:Laplace_concentration_MWU} and $\tilde n_{i^{\ast}}\leq \alpha/4$, which implies $\ind_{\cX^{i^*}}(\bh^{\ast}) \leq \alpha/4+4\sqrt{2I\ln(I/\delta)}\ln(1/\beta')/\eps\leq \alpha/3$. This and the previous claim show that $\sum_{i<i^{\ast}} \hbh^i$ is $(\zeta,\alpha,\cF)$-accurate w.r.t.~$\bh^{\ast}$, concluding the proof.
\end{proofof}



\subsection{Pure-DP Algorithm}

\label{sec:pure_DP_UB}


We provide a pure-DP synthetic data generation algorithm with relative accuracy guarantees. Our algorithm is based on the $\PREM$ framework, where we modify the $\FindMarginExample$ subroutine by one that uses SVT with pure-DP composition (details in \Cref{sec:OIM_pure_DP}).

We point out that very similar (but slightly sharper) rates from the ones we derive in this section can be obtained by applying the exponential mechanism in a similar spirit to the additive-only mechanism of~\cite{BlumLR13}. However, the running time of that approach is quasi-polynomial (in $n, |\cX|, |\cF|$) whereas our approach results in a polynomial-time algorithm (details in \Cref{app:exponential_mechanism}).

As mentioned earlier, the first building block is an adaptation of $\FindMarginExample$ that satisfies pure-DP. This mechanism, \Cref{alg:find-example-pure-DP}, is presented and analyzed in \Cref{sec:PREM_pure_DP}.
\begin{lemma} \label{lem:privacy_accuracy_find_example_pure_DP}
\Cref{alg:find-example-pure-DP} is $\eps$-DP and 
with probability at least $1 - \beta$, satisfies:
    \begin{itemize}[topsep=3pt,itemsep=-3pt]
    \item $\ind_{\cS}(\hbh) \geq \frac{1}{3} \ind_{\cY}(\hbh)$.
    \item If $(\theta,\cS)$ is the output of the algorithm, (see the pseudocode for the value of $\alpha_0$):
        \begin{itemize}[topsep=3pt,itemsep=-3pt]
            \item If $\theta = \equal$, for all $f\in \cF$, $(1 - \zeta) \cdot f(\bh^{\ast}|_{\cS}) - \alpha_0 \leq  f(\hbh|_{\cS}) \leq (1 + \zeta) \cdot  f(\bh^{\ast}|_{\cS}) + \alpha_0$.
            \item If $\theta = \plus$, $\ind_{\cS}(\bh^{\ast}) \geq (1 + \zeta) \cdot \ind_{\cS}(\hbh)$.
            \item If $\theta = \minus$, $\ind_{\cS}(\bh^{\ast})  \leq (1 - \zeta/2) \cdot \ind_{\cS}(\hbh)$.
        \end{itemize}
    \end{itemize}
\end{lemma}
%
We now proceed to $\PREM$. For brevity, we only emphasize the main aspects of this algorithm that require adaptation for the pure-DP case. Namely,
we make the simple observation that the MWU analysis works analogously to the approximate-DP case, with the caveat that for Claim \ref{claim:failure_PREM} to hold, we need $\tilde n_i>\alpha/4$ implies $n_i>\alpha/6$ with sufficiently high probability. This property depends on Laplace concentration \eqref{eqn:Laplace_concentration_MWU}, where for pure-DP we require instead
$\alpha \geq  O\Big(\frac{I}{\eps}\ln \frac{1}{\beta'} \Big).$
The rest of the proof works analogously, and noting that the bound $\alpha \geq O\Big(I\alpha_0\Big)=\tilde O\Big( \sqrt{\frac{n \log^3 n}{\zeta^2\eps}\log|\cX|\log \frac{|\cF|}{\beta} } \Big),$ is required, we conclude the following result.
\begin{theorem} \label{thm:efficient_pure_DP_UP}
For all $\eps \leq 1$, $\beta \in (0, 1)$, and $\zeta \in (0, \nicefrac12)$, 
there is an $\eps$-DP $(\zeta,\alpha,\beta,\cF)$-accurate synthetic data generator for any domain $\cX$ and query family $\cF$ with
\[ \alpha =\tilde O\Big( \sqrt{\frac{n \log^3 n}{\zeta^2\eps}\log|\cX|\log \frac{|\cF|}{\beta}} 
+\frac{\log n}{\eps}\log \frac{1}{\beta} \Big). \]
\end{theorem}
