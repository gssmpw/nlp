\section{Related Work}
This section provides an overview of related work in bug localization and existing approaches in GitHub issue fixing.

\subsection{Bug localization}

Bug localization involves identifying the relevance between a bug report and program elements, typically by recommending the most relevant program components**Zhou et al., "BugLocator"**. Earlier approaches in bug localization extensively employed the Support Vector Model (SVM) due to their proven effectiveness. For instance, **Kim et al., "A Two-Phase Bug Localization Model"** introduced a two-phase model that predicts suspicious files based on the content and quality of bug reports. More recently, the emergence of a large language model (LLM) with advanced code comprehension capabilities has further advanced bug localization. For example, **Ciborowska et al., "Fine-Grained Bug Localization via BERT"** introduced FBL-BERT, the first application of BERT, to calculate the correlation between change code and bug reports.

While these approaches are effective, most research has focused on Java and C programming languages, with limited attention to Python**Hindle et al., "On the Automated Debugging of Simple Programming Assignments"**. Additionally, many existing approaches concentrate on a single granularity of localization, such as file-level or function-level recommendations, which do not fully address the multi-level (file, function, statement) needs of users. Unlike existing bug localization techniques, our work, BugCerberus, focuses on Python and aims to learn across multiple levels of granularity. We utilize specialized models tailored to each granularity, ensuring accurate and comprehensive bug localization to meet the unique requirements at the file, function, and statement levels.

\subsection{GitHub Issue Fixing}
GitHub issue fixing is tasked to repair the GitHub issue using the given issue information automatically. Several approaches have been proposed for this task. For instance, **Vo et al., "RAG: Retrieval-Augmented Generation for Constrained Code Completion"** employs the BM25 retriever to search for bug-related code files and trains the Llama model to address the issue based on the retrieved files. 
CODER integrates BM25 and Ochiai retrievers to identify suspicious files, which are then used as inputs for the repair agent. 
SWE-Agent leverages GPT-4o to consult relevant files and code contents using commands such as find\_file, search\_file, and search\_dir. 
Lastly, Agentless queries GPT-4o for relevant code elements at various levels (file, function, and statement) based on a problem description and designed prompts.

Bug localization is essential in GitHub issue fixing. However, most bug localization techniques in issue-fixing approaches rely on coarse-grained file-level similarity computations. Even those with fine-grained localization often overlook contextual inconsistencies across different levels (file, function, and statement) and fail to provide comprehensive code characterization at each granularity level.

In contrast, our proposed BugCerberus addresses these gaps by focusing on code feature extraction and learning across multiple levels of granularity. BugCerberus fine-tunes three specialized models to meet the unique localization requirements at each granularity, ensuring accurate and comprehensive bug localization for Python programs.