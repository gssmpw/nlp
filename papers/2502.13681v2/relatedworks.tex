
\subsection{Environment configuration and Dockerfile generation}




Oss-Fuzz-Gen~\cite{Liu_OSS-Fuzz-Gen_Automated_Fuzz_2024} relies on predefined build instructions (such as ``\texttt{./bootstrap.sh}'', ``\texttt{./configure}'', ``\texttt{make}'') to build projects for fuzzing but lacks of flexibility for diverse projects when specified files are absent.

Existing solutions that help developers write Dockerfiles broadly fall into three categories: (1) Template-based generators that create Dockerfiles based on project context~\cite{starter, generatordocker}, (2) Task-specific tools such as DockerizeMe which supports environment dependency inference for Python projects ~\cite{horton2019dockerizeme} and DockerGen ~\cite{ye2021dockergen} for dependency recommendations based on knowledge graphs built from existing Dockerfiles, and (3) Code completion tools including GitHub Copilot~\cite{copilot} and HumpBack~\cite{hanayama2020humpback} that generate suggestions for developers while writing Dockerfiles. The use of deep learning models to generate Dockerfiles based on natural language specifications of software requirements is also investigated~\cite{rosa2023automatically}. While these approaches provide valuable assistance, they either require significant manual input from developers or are limited to specific use cases.


\subsection{LLM-based agent}


% In recent years, LLMs have been widely applied in software engineering, showing great potential in various software development and maintenance tasks~\cite{llm1, llm2, llm3}. Unlike standalone LLMs, 
% LLM-based agents enhance the versatility and expertise of LLMs by equipping them with the ability to utilize external resources and tools. 

LLM-based agents typically consist of four key components: planning, memory, perception, and action~\cite{components}. Planning is crucial for agent systems, as it schedules agents to ensure a smooth process. LLM-based agents employ various planning strategies, including single~\cite{plan1} or multiple planners~\cite{plan2}, single~\cite{plan3} or multi-turn planning~\cite{plan4}, and single~\cite{plan5} or multi-path planning~\cite{plan6}. The memory component in LLM-based agents stores historical data to support coherent reasoning and complex tasks. Implementations vary in terms of memory duration (short-term~\cite{memory1} or long-term memory~\cite{memory2}), memory ownership (specific~\cite{memory3} or shared memory~\cite{memory4}).
% and memory format (such as natural languages, programming languages, structured messages, key-value pairs, embeddings and trees). 
For perception, LLM-based agents primarily utilize textual input~\cite{perception1, memory2} (natural language and programming language) and visual input~\cite{perception3, perception4} (images and diagrams) to perceive and process information.
% taking advantage of LLMs' strengths in natural language processing and external visual models for image data. 
To extend capabilities beyond interactive dialogue, the action component employs various external tools~\cite{action1, action2}, such as searching tools, file operations, and GUI operations. 
% testing tools, fault localization tools, and version control tools. 
Nowadays, LLM-based agents have demonstrated superior performance compared to standalone LLMs in various software engineering tasks~\cite{agent1, agent2, agent3}.
% including code generation~\cite{agent1}, bug detection~\cite{agent2}, and program repair~\cite{agent3}. 
However, no LLM-based agents are specifically designed for environment configuration currently. To fill this gap, this paper employs a novel approach for automated coding environment configuration and Dockerfile generation. 

% that combines environment requirement analysis with LLM-powered configuration generation based on Docker containerization.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.5\textwidth]{figs/case_study.pdf}

    \caption{An example of ``\texttt{module not found}'' error due to the absence of updating the unit tests in the repository.}
\label{figs:case_study}

\end{figure}
% 