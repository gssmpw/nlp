\section{Related Work}

\textbf{3D hand pose estimation:}
The task of 3D hand pose estimation aims to regress 3D hand joints. Since annotating 3D hand poses is challenging, only limited labeled datasets are available~\citep{ohkawa:ijcv23}, and most of which are constructed in controlled laboratory settings~\citep{zimmermann:iccv19,chao:cvpr21,moon:eccv20,ohkawa:cvpr23}. Given this challenge, two approaches have been proposed to facilitate learning from limited annotations: pseudo-labeling and self-supervised pre-training. Pseudo-labeling methods learn from pseudo-ground-truth assigned on unlabeled images~\citep{chen:cvpr21,zheng:iccv23,liu:cvpr21,yang:iccv21,ohkawa:eccv22,liu:cvpr24}. For example, S2Hand~\citep{chen:cvpr21} attempts to learn 3D pose only from noisy 2D keypoints on a single-view image, while HaMuCo~\citep{zheng:iccv23} extends such self-supervised learning to multi-view setups. Alternatively, pre-training methods aim to find well-initialized models with unlabeled data for downstream tasks. Prior works propose contrastive learning approaches but rely on relatively small pre-training sets (\eg, 32-47K images in \citep{spurr:iccv21} and 86K images in \citep{ziani:3dv22}). We collect hand images from large human-centric datasets such as Ego4D~\citep{grauman:cvpr22} and 100DOH~\citep{shan:cvpr20}, expanding our pre-training set to 2.0M images.

\textbf{Contrastive learning:}
Contrastive learning has emerged as a powerful technique in self-supervised learning, bringing positive samples closer while pushing negative samples apart~\citep{chopra:cvpr05, schroff:cvpr15, ohsong:cvpr16, sohn:nips16, he:cvpr20, huang:cvpr23}. Standard methods generate positive samples from an identical image with data augmentation (\ie, self-positives)~\citep{grill:neurips20, caron:neurips20, chen_2:cvpr21, radford:icml21, caron:iccv21}, thus the positive supervision doesn't explicitly model inter-sample relationships. To address this, Zhang~\etal propose a relaxed extension of self-positives, \textit{non-self-positives}~\citep{zhang:eccv22}, which share similar characteristics but originate different images, such as images capturing the same scene~\citep{Arandjelovic:cvpr16, ge:eccv20, berton:cvpr22, Hausler:cvpr21}, the same person ID~\citep{chen:iccv21, chen_3:cvpr21}, and multi-view images~\citep{jie:neurips20}. The positive supervision from non-self-positives enables considering diverse inter-sample alignment and facilitates the learning of semantics more easily. Zhang~\etal identify non-self-positives by searching similar human skeletons from single-view images and adapt in action recognition~\citep{zhang:eccv22}. Jie~\etal rely on multi-view (\ie paired) images to define non-self-positives and propose pair-wise weights to adaptively leverage useful multi-view  pairs~\citep{jie:neurips20}. Our work proposes the mining of non-self-positives from 2D keypoint cues with additional pair-wise weighting to account for similarity from \textit{unpaired} data in pre-training.