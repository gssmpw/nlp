\renewcommand{\arraystretch}{1.2}
\begin{table}[!t]
\centering
\resizebox{0.70\textwidth}{!}{%
    \begin{tabular}{cc|cc}
     \Xhline{1.0pt}

    \rowcolor{COLOR_MEAN} &  & \multicolumn{2}{c}{\textbf{FreiHand*}} \\
       
    \rowcolor{COLOR_MEAN}  \multirow{-2}{*}{\textbf{Setting}} &  \multirow{-2}{*}{\textbf{Unlabeled data}}  & \textit{MPJPE}  $\downarrow$ & \textit{PCK-AUC}  $\uparrow$ \\ 
    
    \Xhline{0.6pt}

        Weakly-supervised & Ego-100K & 61.65 & 33.92 \\
       
    \Xhline{0.6pt}

        Pre-training \& Fine-tuning & Ego-100K & \textbf{31.06} & \textbf{68.66} \\

     \Xhline{1.0pt}
   \end{tabular}
}
\captionof{table}{\textbf{Comparison with weakly-supervised learning setting.} We observe that directly incorporating noisy labels into the joint training in the weakly-supervised setting leads to a decline in model performance, indicating that applying noisy labels for training presents certain challenges.
}
\label{tab:exp_wsl}
\end{table}