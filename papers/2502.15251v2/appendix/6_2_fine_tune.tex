\subsection{Finetune for 3D hand pose estimation}\label{sec:appendix_fine_tuning}
In the fine-tuning stage, we discard the projection head and fine-tuning only the encoders. We load the pre-training model weights into a heatmap-based 3D hand pose estimationand predition method: DetNet\citep{zhou:cvpr20}. To train DetNet, we utilize a comprehensive loss function designed to optimize both 2D pose estimation and 3D spatial localization. The loss function is defined as:
%
\begin{equation}
\label{eq:L_total}
\mathcal{L}_\mathrm{heat} +
\mathcal{L}_\mathrm{loc} +
\mathcal{L}_\mathrm{delta} +
\mathcal{L}_\mathrm{reg}
\end{equation}
%
where $\mathcal{L}_\mathrm{heat}$ ensures that the predicted heatmaps $H$ align closely with the ground truth heatmaps $H^\mathrm{GT}$, $\mathcal{L}_\mathrm{loc}$ and $\mathcal{L}_\mathrm{delta}$ measure the discrepancies between the predicted location maps $L$ and delta maps $D$ and their corresponding ground truth $L^\mathrm{GT}$ and $D^\mathrm{GT}$, with $H^\mathrm{GT}$ weighting these discrepancies to focus on the maxima of the heatmaps. Additionally, $\mathcal{L}_\mathrm{reg}$ is an $L2$ regularization term to prevent overfitting. Note that after passing through the encoder, we made simple adjustments to the model, applying some upsampling to the features to fit the input.

This multi-task learning framework enables the network to simultaneously learn pose features from 2D images and spatial information from 3D data, enhancing the accuracy and robustness of detection in real-world applications. For more details on fine-tuning, please refer to the \citep{zhou:cvpr20}.