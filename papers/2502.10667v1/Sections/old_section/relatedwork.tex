\section{RELATED WORK}
\label{sec:relatedwork}

Data quality is a critical area of research that focuses on ensuring datasets meet specific quality benchmarks to support accurate and reliable data analysis. Data quality profiling and assessment are fundamental components of this field. Data profiling generates metadata about data sources, capturing attributes such as data types, missing values, and distinct values. This metadata is essential for various applications, including data cleansing, data integration, and query optimization \cite{DBLP:journals/sigmod/Naumann13, oliveira2006data, abedjan2017data}. Profiling helps identify data quality issues, such as missing values, syntax violations, and referential integrity problems \cite{chiang2008discovering, ilyas2015trends, razniewski2011completeness}. The subsequent data quality assessment uses these profiling outputs to measure data quality dimensions like accuracy, completeness, and consistency, categorized into intrinsic, accessibility, contextual, and representational qualities \cite{DBLP:journals/jmis/WangS96, sidi2012data}. This assessment ensures that datasets adhere to quality standards, facilitating their effective use in various applications \cite{jayawardene2013curse, jayawardene2015analysis, YEGANEH201424}.


Addressing quality issues in ML pipelines is a field with growing interest in recent years. Several research works studied the relationship between data quality and ML-model performance, including the impact of data quality dimensions on ML algorithms \cite{Budach2022TheEO}, their link to MLOps \cite{renggli2021data,Xin2021ProductionML}, cleaning for ML \cite{DBLP:journals/corr/abs-1904-09483, krishnan2016activeclean} and quality verification of ML pipelines \cite{schelter2018automating}. The quality of an ML model is often related to the quality of the underlying data, namely training and serving data. This has led to proposed approaches for data preparation, like assessing data across various quality dimensions \cite{gupta2021data} and task-dependant quality assessment \cite{Foroni2021EstimatingTE}. Several approaches focused on the completeness of data \cite{karlavs2020nearest, schelter2020learning}. Others focus on the data drift between training and serving data. 

Data quality verification is essential for ensuring that datasets meet predefined quality standards before they are used for analysis or model training. Various studies have addressed different aspects of this topic. Fadlallah et al. \cite{fadlallah2023context}, Caveness et al. \cite{caveness2020tensorflow}, and Sinthong et al. \cite{sinthong2021dqdf} emphasize context-awareness, continuous ML pipelines, and data-quality-aware dataframes, yet they often depend on predefined rules and constraints that require expert intervention. Gu et al. \cite{bertino2018adaptive} and Li et al. \cite{li2022blindly} focus on visual data quality, presenting techniques that are not easily generalizable to other datasets. Schelter and colleagues \cite{schelter2018automating, schelter2019differential} explore automating data quality verification in large-scale scenarios but struggle with detecting hidden data relationships. Shrivastava et al. \cite{shrivastava2019dqa} introduce an interactive advisor for scalable data quality, yet it still relies heavily on expert-defined rules. These methods, while insightful, often fall short of providing fully automated, comprehensive solutions adaptable to various data types and scales without extensive expert input.



