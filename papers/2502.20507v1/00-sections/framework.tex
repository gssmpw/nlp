\section{APIKS Automotive Platform} \label{sec:framework}

\begin{figure*}[!t] \centering \includegraphics[width=0.68\textwidth]{01-figures/LogicalArchitecture_APIKS.png} 
\vspace{-0.3cm} 
\caption{Logical architecture of the APIKS platform} 
\vspace{-0.3cm} 
\label{fig:apiks} 
\end{figure*}

The APIKS automotive platform, depicted in Figure \ref{fig:apiks}, is structured into a SOA composed of multiple interconnected layers, each responsible for distinct functions essential to AV operations. This layered approach facilitates modular development and seamless integration, ensuring that each component can be independently developed and maintained while contributing to the overall system's efficiency and safety. At the core, the \emph{sensing Layer} gathers raw data from various sensors, which is then processed by the \emph{perception layer} to build an accurate representation of the vehicle’s environment. This information is further refined by the \emph{operational design domain (ODD) handling layer}, which adjusts operational parameters based on real-time conditions.

Building on this foundation, the \emph{drive planning layer} formulates safe and effective trajectories, which are executed by the \emph{motion control layer} and the \emph{actuation layer} to manage the vehicle's movements. Overseeing these processes, the \emph{ADS mode manager} ensures that the vehicle operates within appropriate modes, adapting to changing scenarios and driver inputs. The \emph{human-machine interface (HMI) layer} provides essential communication between the vehicle and the driver, while the \emph{monitoring and data collection} components enable continuous system evaluation and improvement. In the following subsections, we will delve into each of these layers in detail.

\subsection{High Definition Map Layer} The High Definition (HD) Map provides precise spatial information critical for vehicle localization and trajectory planning. APIKS employs Lanelet2 \cite{poggenhansLanelet2HighdefinitionMap2018}, an open-source mapping framework, to develop and maintain these HD maps. Lanelet2 effectively represents road networks, including lane boundaries, traffic signs, signals, and other infrastructure elements, ensuring detailed and accurate map data.

\subsection{Sensing Layer} The Sensing Layer is responsible for acquiring raw data from an array of sensors, including LiDAR, radar, and cameras. This layer performs initial data processing to extract pertinent features such as object detections and environmental cues, providing foundational inputs for subsequent perception and planning modules.

\subsection{Perception Layer} Building on the processed sensor data, the Perception Layer receives inputs such as images from cameras and point clouds from LiDAR sensors. It processes this data to produce outputs like 2D and 3D object lists, which detail the positions and classifications of detected objects. These outputs collectively create a map of the surrounding environment, providing the vehicle with an accurate and real-time understanding of its operational surroundings.
\begin{figure*}[ht]
    \centering
    %\includesvg[inkscapelatex=false,width=0.5\textwidth]{graphics/gsn.svg}
    \includegraphics[width=0.7\textwidth]{01-figures/CZA_RGB_back.png}
    \vspace{-0.3cm}
    \caption{Example scenario of Construction Zone Assist use case.}
    \vspace{-0.3cm}
    \label{fig:cza}
\end{figure*}
\subsection{Operational Design Domain Handling Layer} The ODD Handling Layer dynamically manages the vehicle's operational parameters by interpreting real-time data from various sources. ODD messages are modeled in accordance with ISO 34503 \cite{isoRoadVehiclesTest2023}, ensuring standardized communication and interoperability across different systems. By evaluating current driving conditions—including road boundaries, traffic scenarios, and the presence of dynamic obstacles—this layer enables the vehicle to adjust its behavior within its defined operational domain. Additionally, the ODD handler facilitates the Automated Driving System (AS) mode manager in determining the availability of specific functionalities based on the current ODD. For instance, adverse weather conditions such as heavy rainfall may reduce visibility, prompting the system to disable autopilot features or initiate a handover to the driver.

\subsection{Drive Planning Layer} The Drive Planning Layer is tasked with generating safe and feasible trajectories based on the vehicle's environmental understanding. It integrates data from the Perception and ODD Handling Layers to navigate complex environments while avoiding obstacles and adhering to traffic regulations. This layer can employ various methodologies to achieve robust and adaptable planning. For example, ground-truth-based planning involves following a pre-calculated global path with comprehensive knowledge of surrounding objects, ensuring precise adherence to the planned route under known conditions. Additionally, other drive planning methods tested within APIKS include Model Predictive Control (MPC) \cite{richaletModelPredictiveHeuristic1978} and integration with TUM's Frenetix framework \cite{trauthFRENETIXHighPerformanceModular2024}. MPC optimizes trajectories in real time by continuously predicting and adjusting the vehicle's path, allowing for responsive maneuvering in unpredictable environments. The Frenetix framework utilizes a Frenet \cite{werlingOptimalTrajectoryGeneration2010} path planner to generate smooth and efficient paths relative to a reference trajectory, simplifying complex path planning by transforming it into longitudinal and lateral components. The use of these diverse planning approaches underscores the architecture's modularity: as long as the interfaces are properly defined and adhered to, different planning algorithms can be developed and integrated seamlessly.

\subsection{Motion Control Layer} Translating planned trajectories into executable commands, the Motion Control Layer employs a decoupled architecture that independently manages longitudinal and lateral vehicle dynamics. Longitudinal control is managed by a Proportional-Integral-Derivative (PID) controller, which precisely regulates acceleration and braking to maintain desired speed profiles and respond to dynamic conditions. For lateral control, the Stanley controller is utilized. The Stanley controller is designed to minimize both the cross-track error, which is the lateral deviation from the planned path, and the heading error, which is the angular difference between the vehicle's orientation and the desired trajectory. By addressing these two error components, the Stanley controller ensures accurate steering adjustments that align the vehicle with the intended path. This separation of control functions allows each controller to specialize and optimize its specific task. 

\subsection{Actuation Layer} The Actuation Layer interfaces directly with the vehicle's hardware components, executing control commands issued by the Motion Control Layer. It manages systems such as the engine, brakes, and steering mechanisms, ensuring that the vehicle's physical actions correspond accurately to the planned trajectories and control inputs.

\subsection{ADS Mode Manager} The Automated Driving System Mode Manager is responsible for overseeing the operational modes of the vehicle by managing the activation and deactivation of autonomous driving functionalities. It ensures that the system operates in modes that are appropriate to the current context and aligned with the driver’s intentions, thereby facilitating seamless transitions between manual and autonomous control as required. The Mode Manager interacts closely with other system components, such as the ODD handler, to evaluate environmental conditions and system status. Additionally, the Mode Manager coordinates with the Drive Planner, requesting modifications to the planning algorithms based on prevailing conditions. For instance, navigating a construction zone may necessitate a specialized drive planner that accounts for temporary road structures and altered traffic patterns, which differs from the drive planner optimized for highway environments. Furthermore, the Mode Manager continuously monitors the performance and status of various system modules, enabling it to detect anomalies or critical situations promptly. In scenarios requiring immediate action, such as initiating emergency braking, the Mode Manager can override standard procedures and bypass components like the Drive Planner to execute necessary emergency maneuvers.



\subsection{Human-Machine Interface Layer} The Human-Machine Interface (HMI) Layer serves as the communication bridge between the autonomous system and the driver. It provides essential feedback, including system status updates, warnings, and take-over requests, enabling the driver to remain informed and intervene when required.

\subsection{Monitoring and Data Collection} By leveraging ROS2’s publish–subscribe architecture, monitoring and data collection can be seamlessly integrated into the system for real-time observation and data acquisition. Although APIKS does not currently include built-in data collection and monitoring capabilities, its design makes it easy to implement these features. This enables post-operation analysis and continuous system improvement by gathering data on algorithm performance and system effectiveness across various operating conditions, thereby supporting informed enhancements to the platform.