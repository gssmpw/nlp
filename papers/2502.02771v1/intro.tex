\section{Introduction}
\label{sec:intro}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{figs/fig1-hallucifat.png}
    \caption{\textbf{Diffusion priors produce convincing results with extremely few projections. }We show reconstructions using classical (top) and diffusion (bottom) priors for varying number of projections $n_{proj}$. We show the fat segmentation in purple. Under limited $n_{proj}$, we observe the diffusion method perceptually outperforming the classical priors, but under sufficiently large $n_{proj}$, classical priors produce reconstructions whose fat segmentation's adhere more closely to the ground truth.}
    \label{fig:halluci-fat}
\end{figure*}
% Fig: example reconstructions versus projections. put fat mask of reconstruction and ground truth image.
% medical image reconstruction are ubiquitous and are used for many downstream applications

Medical image modalities, such as magnetic resonance imaging (MRI) and computed tomography (CT) scans, are typically reconstructed from a set of projections. For example, CT algorithms combine many x-ray projections to produce an image volume. These volumes may then be used on various downstream tasks, such as disease diagnosis and fat measurement. Image reconstruction accuracy and reliability can, therefore, directly impact the patient's standard of care.

Generally, the more projections used in reconstruction, the better the image quality. However, in settings requiring limited resources~\cite{court2023addressing} or radiation dose~\cite{rampinelli2012low}, the number of projections can be small ($<100$ instead of $100$s).
In this scenario, image reconstruction problems are ill-posed - meaning the number of projections is insufficient to fully capture the underlying anatomy of the patient.
% introduce the notion of priors. for example, L1, L2 are pre-dominantly used in practice
Many past works have addressed this ``ill-posedness'' through different priors, which drive the algorithm towards a solution with certain desirable characteristics~\cite{sun2024difr3ct}.
For example, an $L_1$ prior drives the algorithm towards a solution that is sparse in some domain ~\cite{zhang2018regularization}.
Another example is $L_2$, or Tikhonov, prior that drives the algorithm towards a solution that is smooth~\cite{zhang2018regularization}.

% more recently diffusion models have become state of the art
% diffusion models can be thought of as priors
Unlike classical priors based on simple analytical forms, an emerging alternative is to use deep generative models trained on large data distributions with neural networks. The most powerful current deep generative family are \emph{diffusion models}~\cite{dhariwal2021diffusion}, which demonstrate impressive results on a range of image generation tasks. Several recent studies show that diffusion models can produce convincing results in sparse image reconstruction with very limited projections~\cite{sun2024difr3ct} where classical priors struggle. However, diffusion models are not yet safe for deployment in practice because they can generate reconstructions that superficially look correct, but contain fabricated anatomical detail. This discrepancy highlights the need for a more nuanced evaluation framework. %By optimizing the errors between the reconstructed and ground truth projections, an unconditional diffusion model can be ``guided'' toward a reasonable solution.
% pros and cons for L1/2: CS typically requires less training data, CS can be faster for inference, CS is more easily adapted to different sensing scenarios
% pros and cons for diffusion models: Diffusion models often need large datasets for training, Traditional diffusion models can be slow for sampling, though recent work aims to address this, Diffusion models may require retraining for new tasks
% While classical priors require no training data and have faster inference, diffusion priors often need large datasets for training and require high computation for sampling.
% As a result, classical priors can be adapted for many different settings, while diffusion models may require retraining.

% evaluate using pixel-based and structural-based metrics like PSNR and SSIM
% {\color{red} There is a conceptual jump from the previous paragraph to this...not sure why this follows from the previous diffusion paragraph.} During evaluation, reconstructions from varying numbers of projections (usually extremely few: 3-10) are evaluated using pixel-based (peak-signal-to-noise ratio, PSNR) and structural-based (structural similarity index, SSIM) metrics.
% while PSNR and SSIM provide important quantitative evaluation, they do not link image reconstruction with downstream clinical applications, and are therefore not meaningful
While PSNR and SSIM provide important quantitative evaluation for a machine learning practitioner, they do not link image reconstruction with downstream clinical applications and are, therefore, not meaningful and practical~\cite{cheung2024metric}.
% based on these projections, there are two questions that arise: 
% do diffusion models perform better when the number of projections is sufficient?
% are the downstream metric trends similar to psnr and ssim?
Since prior work does not fully cover the entire range of projections or assess downstream metrics comprehensively, key questions emerge: 1) Do diffusion priors outperform classical priors across a wide range of projections (e.g., hundreds of X-rays for CT scans)? and 2) Do downstream metrics align with trends observed in pixel- and structure-based metrics?
We tackle these questions by comparing classical ($L_1$ and $L_2$) and diffusion priors over a wide range of projections and find interesting results.

% One application is estimating fat content.
% Fat content and localization are import to monitor because ...
% People want to do this without exposing patients to excessive radiation or if have limited access.
% These reconstructions are ill-posed: i.e., from limited number of projections.
We explore the real-life, practical, and clinically relevant problem of quantifying thoracic fat mass and its distribution using low-dose CT. Quantifying thoracic fat mass and its distribution is crucial to understanding its role in cardiometabolic risk and other health outcomes~\cite{wang2014imaging,dey2012epicardial}.
Traditional methods, such as full-projection computed tomography (CT) scans, offer high accuracy but are associated with significant levels of ionizing radiation. 
This concern is particularly important for individuals with obesity, who often require higher radiation doses due to increased tissue density~\cite{yanch2009increased}. 
Reducing radiation exposure while maintaining diagnostic accuracy is, therefore, critical for population-level screening and individual-level longitudinal assessments.
Using a low number of projections (low-dose CT) offers a promising solution to balance radiation safety and diagnostic effectiveness. 
% Thus enabling scalable, repeatable imaging protocols and supporting large-scale population health studies where repeated imaging is necessary.

% we provide a principled method to determine the range of the number of projections when diffusion priors are superior than classical priors
% We explore and determine the range of the number of projections when diffusion priors are superior to classical priors.
Our key findings are as follows: 1) diffusion priors excel in extremely sparse settings often succeeding only with several projections, 2) classical priors are superior to diffusion priors when the number of projections is ``sufficient'', and 3) diffusion prior performance plateaus after few ($\approx$10-15) projections.
Ultimately, our work paves the way for more meaningful, practical, and clinically relevant comparisons between medical image reconstruction methods in sparse regimes.