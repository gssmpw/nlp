\section{Results}

\noindent\textbf{Diffusion priors work well with extremely few projections. }
We find that diffusion priors excel in extremely sparse settings to estimate pixel-based, structural-based, and downstream metrics, often already succeeding in capturing many details only with several projections (Fig. \ref{fig:halluci-fat}).
However, they fall short of capturing all details accurately, like vasculature, even with many observations.
On the other hand, we find that classical priors are superior to diffusion priors when the number of projections is ``sufficient'' (i.e., exceeds extremely few projections).
We leverage results from Fig. \ref{fig:trend} to identify the regions where diffusion priors are \textit{guaranteed} to be better than classical priors. 
% First, we identify the lower bound, which can be given by a user-defined minimum or maximum threshold of the metric, depending on whether the metric is better minimized or maximized. Next, we identify the prediction regions where the probability that a randomly chosen value from one method is larger than a randomly chosen value from another.
% This can be formulated as a Mann-Whitney U-test (or the Wilcoxon rank-sum test), a non-parametric test with only assumptions that the data from the two groups are independent and the measurements are ordinal or continuous ~\cite{}.
We can define the number of projections ($n_{proj}$) as the interval $I=[LB,UB]$ where diffusion priors perform statistically better than classical priors.
The lower and upper bounds are denoted as $LB,UB\in\mathbb{R}\times\mathbb{R}$.
For a monotonically increasing (can be positive or zero slope) metric ($M$) as number of projections ($n_{proj}$) increases, the lower bound is given by $n$ at the minimum acceptable metric ($\tau_M$), and the upper bound is given by the maximum $n_{proj}$ when the Mann-Whitney U-test has a p-value of less than a user-defined threshold ($\tau_p$; for example, $0.05$): $I=[\min \{n_{proj}\in\mathbb{R}: M\geq\tau_M\}, \max\{n_{proj}\in\mathbb{R}:p\leq\tau_p\}]$.
The upper bound of the interval gives the highest number of projections where the probability that a randomly chosen metric value generated from one method is larger than a randomly chosen metric value generated from another $P(M_1>M_2)$.
% For instance, $M_1$ is PSNR from a diffusion prior, and $M_2$ is PSNR from a classical prior.
For a monotonically decreasing $M$, maximum and minimum are used for the lower and upper bounds.
We choose the lower bound to be the ``corner'' of the plots where performance starts to plateau.
We show these bounds in Table. \ref{tab:bounds}.
We find that diffusion priors perform better than classical priors between extremely few observations (5 to 10) and 10s of projections.
Beyond $10$s of projections, classical priors perform better overall.
\begin{table}[t]
\label{tab:bounds}
\centering
% \resizebox{\columnwidth}{!}
{%
\begin{tabular}{c|cl|cc|}
\cline{2-5}
 & \multicolumn{2}{c|}{\multirow{2}{*}{LB}} & \multicolumn{2}{c|}{UB (p-value)} \\ \cline{1-1} \cline{4-5} 
\multicolumn{1}{|c|}{\textbf{Metric}} & \multicolumn{2}{c|}{} & \multicolumn{1}{c|}{$L_1$ Prior} & $L_2$ Prior \\ \hline
\multicolumn{1}{|c|}{MSE} & \multicolumn{2}{c|}{7} & \multicolumn{1}{c|}{15 (3.7e-40)} & 15 (2.4e-42) \\ \hline
\multicolumn{1}{|c|}{SSIM} & \multicolumn{2}{c|}{7} & \multicolumn{1}{c|}{25 (4.24e-120)} & 60 (7.4e-40) \\ \hline
\multicolumn{1}{|c|}{Fat Content} & \multicolumn{2}{c|}{9} & \multicolumn{1}{c|}{40 (9.1e-43)} & 40 (1.25e-72) \\ \hline
\multicolumn{1}{|c|}{Fat Localization} & \multicolumn{2}{c|}{7} & \multicolumn{1}{c|}{25 (1.2e-69)} & 25 (5.39e-120) \\ \hline
\end{tabular}%
}
\caption{\textbf{Diffusion priors perform statistically better than classical priors for extremely low number of projections.} Upper (UB) and Lower (LB) bounds for number of projections where diffusion performs better than classical priors. The lower bound is from the ``corner'' of the performance curve and upper bound is based on the Mann-Whitney U-test.
% {\color{red} What is the takeaway from this table?}
}
\end{table}

\noindent\textbf{Diffusion prior performance plateaus after extremely few projections. }
We observe that as the number of projections gets larger, the performance curves plateau and do not reach perfect reconstruction (Fig. \ref{fig:trend}).
In contrast, the performance of classical priors continually increases and supersedes diffusion priors beyond extremely few projections.
Furthermore, we show the inter-quantile range for quantiles 0.05 to 0.95 ($IQR_{5,95}$) in Fig. \ref{fig:trend}.
While the diffusion prior curves are heteroscedastic for extremely few projections, they get more homoscedastic when the performance plateaus.
These observations show that the diffusion priors do not leverage the extra information well for reconstruction beyond extremely few projections.
Thus, diffusion priors get high-level structures (i.e., the shape of the body) correct but not low-level structures (i.e., vasculature) (Fig. \ref{fig:halluci-fat}).

% Fig: metrics (pixel, structural, downstream) vs number of projections plot
% 1 more fig: interpretation. correlations between metrics. pixel vs structural vs downstream
% concordance overall in image
% distribution of fat - all slices of a patient