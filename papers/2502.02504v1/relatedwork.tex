\section{Related Work}
\subsection{Spatial-Temporal Modeling for Trajectory Prediction}
Spatial-temporal architecture is widely used in trajectory prediction which considers both spatial interactions and temporal dependencies. Pioneering methods such as Social-LSTM \cite{Alexandre2016lstm} and Social-GAN \cite{gupta2018socialgan} propose pooling window mechanisms to compute pedestrian spatial interactions and Long Short-Term Memory (LSTM) \cite{HochSchm1997lstm} for temporal aggregation. Due to the outstanding performance of graphs in representation learning, they are widely used to represent pedestrian interactions. STGAT \cite{huang2019stgat} and Social-BiGAT \cite{kosaraju2019socialbigat} employ Graph Attention Network (GAT) \cite{petar2017GAT} to measure interactions strength and LSTM to capture temporal dependencies. Social-STGCNN \cite{Mohamed2020socialstgcnn} proposes to use a Graph Convolutional Network (GCN) \cite{kipf2016GCN} combined with the TCN \cite{bai2018TCN} to model pedestrian trajectories. To simplify the complexity of the graph, sparse GCN-based approaches \cite{shi2021sgcn, bae2023eigentrajectory, ruochen2022multiclassSGCN} further propose directed graphs to dynamically update graph topology during message passing, and TCN is used to learn temporal correlations. In recent years, group-wise methods \cite{Xu2022GroupNetMH, bae2022gpgraph} have garnered attention due to their superior capability in analyzing group behaviors. 

However, these methods characterize spatial interactions and temporal dependencies separately, leading to diluted information and delayed responses in complex scenarios. To this end, we introduce unified ST graphs that transform high-order interactions into simplified first-order relationships, efficiently capture ST inter-dependencies.

\subsection{Graph Neural Networks}
Graph Neural Networks (GNNs) have gained considerable traction in computer vision tasks due to their ability to model complex relationships and interactions between entities. Harnessing their representational power, GNNs have been successfully applied across various domains, including human skeleton analysis \cite{qiao20222ggcn, yan2018spatial, liu2023skeletonrecognition}, drug design \cite{li2022graphdrug2}, and recommendation systems \cite{wang2019rs1}. In the trajectory prediction domain, the evolution of GNN architectures reflects increasingly sophisticated approaches to modeling social interactions. Early works \cite{Mohamed2020socialstgcnn, yu2018spatiotraffic} primarily relied on the representation capabilities of GCN to model social interactions. Following the success of the self-attention mechanism \cite{vaswani2017transformer}, subsequent studies \cite{kosaraju2019socialbigat, huang2019stgat, shi2021sgcn, ruochen2022multiclassSGCN, shi2023TUTR} enhanced this N2N paradigm by incorporating attention-based GNNs, enabling more adaptive and context-aware relationship modeling. Recent works have begun exploring E2N interactions to capture richer relational information between edge and node. GroupNet \cite{Xu2022GroupNetMH} pioneered this direction by introducing interaction strength and category features to enhance edge significance beyond simple connections. Following this trend, GC-VRNN \cite{xu2023gcvrnn}, HEAT \cite{mo2021edge_mask}, and MFAN \cite{li2024mfan} further advanced E2N modeling by integrating edge features into node embeddings, enhancing relational reasoning capabilities. 

However, existing trajectory prediction methods primarily focus on updating node representations. In this paper, we introduce \modulename, a dual-graph architecture that jointly captures both explicit N2N social interactions and implicit E2E influence propagation, providing a more comprehensive modeling of social interactions.


\subsection{Trajectory Predictor}
\RCC{Trajectory prediction has seen various architectural developments. Early RNN-based approaches \cite{Alexandre2016lstm, gupta2018socialgan, pei2022socialVAE,pei2024autofocusing,sun2021reciprocaltrajectory, Berenguer2021contextual} process trajectories sequentially through hidden states. Among these methods, Social-LSTM \cite{Alexandre2016lstm} processes trajectories where hidden states are updated recursively to capture temporal patterns. Recent works like Social-VAE \cite{pei2022socialVAE} and ATP-VAE \cite{pei2024autofocusing} combine RNN with variational autoencoders to model the uncertainty in trajectory predictions, achieving promising results. Subsequently, TCN-based predictor \cite{Mohamed2020socialstgcnn, shi2021sgcn, ruochen2022multiclassSGCN, li2024mfan} emerged as an alternative approach. Social-STGCNN \cite{Mohamed2020socialstgcnn} combines graph convolutions with TCN to achieve efficient parallel processing through increased receptive fields. SGCN \cite{shi2021sgcn} further advances this design by introducing sparse attention mechanisms to adaptively aggregate temporal features. Recently, transformer-based methods \cite{shi2023TUTR, peng2024mrgtraj, chen2023ppnet} have gained prominence in trajectory prediction, where self-attention mechanisms compute pairwise interactions between all time steps, enabling global temporal modeling without the constraints of sequential processing or fixed receptive fields.}

\RCC{However, RNNs suffer from long-term dependencies due to their auto-regressive nature, and TCNs are limited by fixed receptive fields due to their convolutional structure, while full transformer models have high computational costs. To balance modeling capability and efficiency, we propose a Transformer encoder-based predictor that learns global dependencies within the sequence without high computational costs.}



% ==================== Overview Figure ====================
\begin{figure*}[h]
  \centering
  \includegraphics[width=0.84\textwidth]{paper_figure/figure3/Overview_1102.png}
  \caption{\RCC{Overview of the proposed UniEdge. (a) Construction of patch-based unified ST graphs that simplify cross-time interactions into first-order relationships, (b) Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN) that jointly processes N2N interactions and E2E influence propagation, and (c) Transformer Encoder-based trajectory predictor.}}
  \label{fig:overview}
\end{figure*}
% ==================== Overview Figure ====================