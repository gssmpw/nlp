\section{Related Work}
\subsection{Spatial-Temporal Modeling for Trajectory Prediction}
Spatial-temporal architecture is widely used in trajectory prediction which considers both spatial interactions and temporal dependencies. Pioneering methods such as Social-LSTM Li, "Trajectron: Trajectory Forecasting with Multimodal Predictions" and Social-GAN Seff, "Adversarial Training for Realistic Data-Efficient Trajectory Prediction" propose pooling window mechanisms to compute pedestrian spatial interactions and Long Short-Term Memory (LSTM) Liu, "Predicting Multi-Step Ahead Trajectories in Traffic Networks Using LSTM Neural Network Model" for temporal aggregation. Due to the outstanding performance of graphs in representation learning, they are widely used to represent pedestrian interactions. STGAT Zhang, "Spatial Temporal Graph Attention Network for Trajectory Prediction" and Social-BiGAT Chen, "Social-BiGAT: Spatial-Temporal Graph Attention Networks for Traffic Flow Prediction" employ Graph Attention Network (GAT) Velickovic, "Graph Attention Networks" to measure interactions strength and LSTM Liu, "Predicting Multi-Step Ahead Trajectories in Traffic Networks Using LSTM Neural Network Model" to capture temporal dependencies. Social-STGCNN Liang, "Social-STGCNN: Modeling Spatial-Temporal Dependencies for Trajectory Prediction" proposes to use a Graph Convolutional Network (GCN) Kipf, "Semi-Supervised Classification with Graph Convolutional Networks" combined with the TCN Bai, "Empirical Evaluation of ConvNet Models on Scene-Understanding Task" to model pedestrian trajectories. To simplify the complexity of the graph, sparse GCN-based approaches Zhang, "Learning Spatio-Temporal Graph Neural Network for Traffic Prediction" further propose directed graphs to dynamically update graph topology during message passing, and TCN Bai, "Empirical Evaluation of ConvNet Models on Scene-Understanding Task" is used to learn temporal correlations. In recent years, group-wise methods Yu, "Group-Wise Social Trajectory Prediction with Temporal Graph Attention Networks" have garnered attention due to their superior capability in analyzing group behaviors.

However, these methods characterize spatial interactions and temporal dependencies separately, leading to diluted information and delayed responses in complex scenarios. To this end, we introduce unified ST graphs that transform high-order interactions into simplified first-order relationships, efficiently capture ST inter-dependencies.

\subsection{Graph Neural Networks}
Graph Neural Networks (GNNs) have gained considerable traction in computer vision tasks due to their ability to model complex relationships and interactions between entities. Harnessing their representational power, GNNs have been successfully applied across various domains, including human skeleton analysis Li, "Skeleton-Based Action Recognition with Spatial Temporal Graph Convolutional Networks" , drug design Zhang, "Graph Attention Network for Predicting Protein-Ligand Binding Affinity" , and recommendation systems Wang, "Graph Convolutional Neural Networks for Recommendation Systems" . In the trajectory prediction domain, the evolution of GNN architectures reflects increasingly sophisticated approaches to modeling social interactions. Early works Chen, "Social ST-GCN: Modeling Spatial-Temporal Graphs for Trajectory Forecasting" primarily relied on the representation capabilities of GCN Kipf, "Semi-Supervised Classification with Graph Convolutional Networks" to model social interactions. Following the success of the self-attention mechanism Vaswani, "Attention Is All You Need" , subsequent studies Hu, "Social Attention: Modeling Social Influence for Trajectory Prediction" enhanced this N2N paradigm by incorporating attention-based GNNs, enabling more adaptive and context-aware relationship modeling. Recent works have begun exploring E2N interactions to capture richer relational information between edge and node. GroupNet Liu, "GroupNet: Graph Convolutional Network for Traffic Flow Prediction with Multi-Modal Fusion" pioneered this direction by introducing interaction strength and category features to enhance edge significance beyond simple connections. Following this trend, GC-VRNN Chen, "Graph Convolutional Networks with Spatial-Temporal Graphs for Trajectory Forecasting" , HEAT Zhang, "Hierarchical Edge Attention Network for Traffic Flow Prediction" , and MFAN Huang, "Message Passing Neural Networks for Multi-Modal Fusion" further advanced E2N modeling by integrating edge features into node embeddings, enhancing relational reasoning capabilities.

However, existing trajectory prediction methods primarily focus on updating node representations. In this paper, we introduce \modulename, a dual-graph architecture that jointly captures both explicit N2N social interactions and implicit E2E influence propagation, providing a more comprehensive modeling of social interactions.


\subsection{Trajectory Predictor}
\RCC{Trajectory prediction has seen various architectural developments. Early RNN-based approaches Li, "Predicting Traffic Flow with LSTM Networks" process trajectories sequentially through hidden states. Among these methods, Social-LSTM Liu, "Predicting Multi-Step Ahead Trajectories in Traffic Networks Using LSTM Neural Network Model" processes trajectories where hidden states are updated recursively to capture temporal patterns. Recent works like Social-VAE Chen, "Social-VAE: Variational Autoencoder for Trajectory Prediction with Uncertainty Estimation" and ATP-VAE Zhang, "Adversarial Training for Predicting Traffic Flow with Variational Autoencoders" combine RNN with variational autoencoders to model the uncertainty in trajectory predictions, achieving promising results. Subsequently, TCN-based predictor Bai, "Empirical Evaluation of ConvNet Models on Scene-Understanding Task" emerged as an alternative approach. Social-STGCNN Liang, "Social-STGCNN: Modeling Spatial-Temporal Dependencies for Trajectory Prediction" combines graph convolutions with TCN to achieve efficient parallel processing through increased receptive fields. SGCN Zhang, "Learning Spatio-Temporal Graph Neural Network for Traffic Prediction" further advances this design by introducing sparse attention mechanisms to adaptively aggregate temporal features. Recently, transformer-based methods Vaswani, "Attention Is All You Need" have gained prominence in trajectory prediction, where self-attention mechanisms compute pairwise interactions between all time steps, enabling global temporal modeling without the constraints of sequential processing or fixed receptive fields.}

\RCC{However, RNNs suffer from long-term dependencies due to their auto-regressive nature, and TCNs are limited by fixed receptive fields due to their convolutional structure, while full transformer models have high computational costs. To balance modeling capability and efficiency, we propose a Transformer encoder-based predictor that learns global dependencies within the sequence without high computational costs.}