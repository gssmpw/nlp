[
  {
    "index": 0,
    "papers": [
      {
        "key": "arjona2019rudder",
        "author": "Arjona-Medina, Jose A and Gillhofer, Michael and Widrich, Michael and Unterthiner, Thomas and Brandstetter, Johannes and Hochreiter, Sepp",
        "title": "Rudder: Return decomposition for delayed rewards"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liu2019sequence",
        "author": "Liu, Yang and Luo, Yunan and Zhong, Yuanyi and Chen, Xi and Liu, Qiang and Peng, Jian",
        "title": "Sequence modeling of temporal credit assignment for episodic reinforcement learning"
      },
      {
        "key": "han2022off",
        "author": "Han, Beining and Ren, Zhizhou and Wu, Zuofan and Zhou, Yuan and Peng, Jian",
        "title": "Off-policy reinforcement learning with delayed rewards"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ren2021learning",
        "author": "Ren, Zhizhou and Guo, Ruihan and Zhou, Yuan and Peng, Jian",
        "title": "Learning long-term reward redistribution via randomized return decomposition"
      },
      {
        "key": "zhu2023towards",
        "author": "Zhu, Tianchen and Qiu, Yue and Zhou, Haoyi and Li, Jianxin",
        "title": "Towards Long-delayed Sparsity: Learning a Better Transformer through Reward Redistribution"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "harutyunyan2019hindsight",
        "author": "Harutyunyan, Anna and Dabney, Will and Mesnard, Thomas and Gheshlaghi Azar, Mohammad and Piot, Bilal and Heess, Nicolas and van Hasselt, Hado P and Wayne, Gregory and Singh, Satinder and Precup, Doina and others",
        "title": "Hindsight credit assignment"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xiao2022agent",
        "author": "Xiao, Baicen and Ramasubramanian, Bhaskar and Poovendran, Radha",
        "title": "Agent-temporal attention for reward redistribution in episodic multi-agent reinforcement learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "foerster2018counterfactual",
        "author": "Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon",
        "title": "Counterfactual multi-agent policy gradients"
      },
      {
        "key": "devlin2014potential",
        "author": "Devlin, Sam and Yliniemi, Logan and Kudenko, Daniel and Tumer, Kagan",
        "title": "Potential-based difference rewards for multiagent reinforcement learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "sunehag2017value",
        "author": "Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others",
        "title": "Value-decomposition networks for cooperative multi-agent learning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "rashid2020monotonic",
        "author": "Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon",
        "title": "Monotonic value function factorisation for deep multi-agent reinforcement learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wang2020shapley",
        "author": "Wang, Jianhong and Zhang, Yuan and Kim, Tae-Kyun and Gu, Yunjie",
        "title": "Shapley q-value: A local reward approach to solve global reward games"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "freed2021learning",
        "author": "Freed, Benjamin and Kapoor, Aditya and Abraham, Ian and Schneider, Jeff and Choset, Howie",
        "title": "Learning Cooperative Multi-Agent Policies With Partial Reward Decoupling"
      },
      {
        "key": "kapoor2024assigning",
        "author": "Kapoor, Aditya and Freed, Benjamin and Choset, Howie and Schneider, Jeff",
        "title": "Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization"
      },
      {
        "key": "kapoor2024agenttemporalcreditassignmentoptimal",
        "author": "Aditya Kapoor and Sushant Swamy and Kale-ab Tessera and Mayank Baranwal and Mingfei Sun and Harshad Khadilkar and Stefano V. Albrecht",
        "title": "Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "she2022agent",
        "author": "She, Jennifer and Gupta, Jayesh K and Kochenderfer, Mykel J",
        "title": "Agent-time attention for sparse rewards multi-agent reinforcement learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Chen2023STASSR",
        "author": "Sirui Chen and Zhaowei Zhang and Yali Du and Yaodong Yang",
        "title": "STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning"
      }
    ]
  }
]