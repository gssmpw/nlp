@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}

@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  month = "June",
  year = "1992"
}

@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  month = "May",
  year = "2002"
}

@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  month = "July",
  year = "1984"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

 @misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}

@book{marl-book,
  author = {Stefano V. Albrecht and Filippos Christianos and Lukas Sch\"afer},
  title = {Multi-Agent Reinforcement Learning: Foundations and Modern Approaches},
  publisher = {MIT Press},
  year = {2024},
  url = {https://www.marl-book.com}
}


@book{sutton1998introduction,
    title={Reinforcement Learning: {A}n Introduction},
    author={Sutton, Richard S. and Barto, Andrew G.},
	publisher={The MIT Press},
	year={1998},
	address={Cambridge, MA},
}

@article{gae,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@inproceedings{Papoudakis2020BenchmarkingMD,
  title={Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks},
  author={Georgios Papoudakis and Filippos Christianos and Lukas Sch{\"a}fer and Stefano V. Albrecht},
  booktitle={NeurIPS Datasets and Benchmarks},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:235417602}
}

% MARL survey
@ARTICLE{busoniu_2008,
  author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
  title={A Comprehensive Survey of Multiagent Reinforcement Learning}, 
  year={2008},
  volume={38},
  number={2},
  pages={156-172},
  keywords={Learning;Multiagent systems;Robots;Control systems;Resource management;Marine technology;Feedback;Distributed control;Environmental economics;Mechanical engineering;Distributed control;game theory;multiagent systems;reinforcement learning;Distributed control;game theory;multiagent systems;reinforcement learning},
  doi={10.1109/TSMCC.2007.913919}}

% MARL video games
@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{Vinyals2019GrandmasterLI,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Oriol Vinyals and Igor Babuschkin and Wojciech M. Czarnecki and Micha{\"e}l Mathieu and Andrew Dudzik and Junyoung Chung and David Choi and Richard Powell and Timo Ewalds and Petko Georgiev and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and L. Sifre and Trevor Cai and John P. Agapiou and Max Jaderberg and Alexander Sasha Vezhnevets and R{\'e}mi Leblond and Tobias Pohlen and Valentin Dalibard and David Budden and Yury Sulsky and James Molloy and Tom Le Paine and Caglar Gulcehre and Ziyun Wang and Tobias Pfaff and Yuhuai Wu and Roman Ring and Dani Yogatama and Dario W{\"u}nsch and Katrina McKinney and Oliver Smith and Tom Schaul and Timothy P. Lillicrap and Koray Kavukcuoglu and Demis Hassabis and Chris Apps and David Silver},
  journal={Nature},
  year={2019},
  volume={575},
  pages={350 - 354},
  url={https://api.semanticscholar.org/CorpusID:204972004}
}

@inproceedings{kurach2020google,
  title={Google research football: A novel reinforcement learning environment},
  author={Kurach, Karol and Raichuk, Anton and Sta{\'n}czyk, Piotr and Zaj{\k{a}}c, Micha{\l} and Bachem, Olivier and Espeholt, Lasse and Riquelme, Carlos and Vincent, Damien and Michalski, Marcin and Bousquet, Olivier and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  pages={4501--4510},
  year={2020}
}

@article{jaderberg2019human,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
  volume={364},
  number={6443},
  pages={859--865},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{michalski2023smaclite,
  title={SMAClite: A Lightweight Environment for Multi-Agent Reinforcement Learning},
  author={Michalski, Adam and Christianos, Filippos and Albrecht, Stefano V},
  journal={arXiv preprint arXiv:2305.05566},
  year={2023}
}

@article{samvelyan2019starcraft,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}


% MARL Real world applications
@article{krnjaic2022scalable,
  title={Scalable multi-agent reinforcement learning for warehouse logistics with robotic and human co-workers},
  author={Krnjaic, Aleksandar and Steleac, Raul D and Thomas, Jonathan D and Papoudakis, Georgios and Sch{\"a}fer, Lukas and To, Andrew Wing Keung and Lao, Kuan-Ho and Cubuktepe, Murat and Haley, Matthew and B{\"o}rsting, Peter and others},
  journal={arXiv preprint arXiv:2212.11498},
  year={2022}
}

@INPROCEEDINGS{RTAW,
  author={Agrawal, Aakriti and Bedi, Amrit Singh and Manocha, Dinesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={RTAW: An Attention Inspired Reinforcement Learning Method for Multi-Robot Task Allocation in Warehouse Environments}, 
  year={2023},
  volume={},
  number={},
  pages={1393-1399},
  keywords={Training;Navigation;Scalability;Layout;Reinforcement learning;Minimization;Resource management},
  doi={10.1109/ICRA48891.2023.10161310}}

@article{sartoretti2019primal,
  title={Primal: Pathfinding via reinforcement and imitation multi-agent learning},
  author={Sartoretti, Guillaume and Kerr, Justin and Shi, Yunfei and Wagner, Glenn and Kumar, TK Satish and Koenig, Sven and Choset, Howie},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={3},
  pages={2378--2385},
  year={2019},
  publisher={IEEE}
}

@article{damani2021primal,
  title={PRIMAL $ \_2 $: Pathfinding via reinforcement and imitation multi-agent learning-lifelong},
  author={Damani, Mehul and Luo, Zhiyao and Wenzel, Emerson and Sartoretti, Guillaume},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={2},
  pages={2666--2673},
  year={2021},
  publisher={IEEE}
}


@INPROCEEDINGS{baer2019,
  author={Baer, Schirin and Bakakeu, Jupiter and Meyes, Richard and Meisen, Tobias},
  booktitle={2019 Second International Conference on Artificial Intelligence for Industries (AI4I)}, 
  title={Multi-Agent Reinforcement Learning for Job Shop Scheduling in Flexible Manufacturing Systems}, 
  year={2019},
  volume={},
  number={},
  pages={22-25},
  keywords={Optimization;Training;Task analysis;Topology;Frequency modulation;Job shop scheduling;Petri nets;Job Shop Scheduling, Flexible Manufacturing System, Reinforcement Learning, Multi-Agent System},
  doi={10.1109/AI4I46381.2019.00014}
}

@article{shelke2023multi,
  title={Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in E-Commerce},
  author={Shelke, Omkar and Pathakota, Pranavi and Chauhan, Anandsingh and Khadilkar, Harshad and Meisheri, Hardik and Ravindran, Balaraman},
  journal={arXiv preprint arXiv:2311.16171},
  year={2023}
}

@inproceedings{zhang2018fully,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  booktitle={International Conference on Machine Learning},
  pages={5872--5881},
  year={2018},
  organization={PMLR}
}

@article{vinitsky2020optimizing,
  title={Optimizing mixed autonomy traffic flow with decentralized autonomous vehicles and multi-agent rl},
  author={Vinitsky, Eugene and Lichtle, Nathan and Parvate, Kanaad and Bayen, Alexandre},
  journal={arXiv preprint arXiv:2011.00120},
  year={2020}
}

@article{zhang2023learning,
  title={Learning a robust multiagent driving policy for traffic congestion reduction},
  author={Zhang, Yulin and Macke, William and Cui, Jiaxun and Hornstein, Sharon and Urieli, Daniel and Stone, Peter},
  journal={Neural Computing and Applications},
  pages={1--14},
  year={2023},
  publisher={Springer}
}

% agent credit assignment
@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@article{rashid2020monotonic,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={178},
  pages={1--51},
  year={2020}
}

@inproceedings{son2019qtran,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International conference on machine learning},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}

@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@article{freed2021learning,
   title={Learning Cooperative Multi-Agent Policies With Partial Reward Decoupling},
   volume={7},
   ISSN={2377-3774},
   url={http://dx.doi.org/10.1109/LRA.2021.3135930},
   DOI={10.1109/lra.2021.3135930},
   number={2},
   journal={IEEE Robotics and Automation Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Freed, Benjamin and Kapoor, Aditya and Abraham, Ian and Schneider, Jeff and Choset, Howie},
   year={2022},
   month=apr, pages={890–897} }

@article{kapoor2024assigning,
  title={Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization},
  author={Kapoor, Aditya and Freed, Benjamin and Choset, Howie and Schneider, Jeff},
  journal={arXiv preprint arXiv:2408.04295},
  year={2024}
}

@misc{kapoor2024agenttemporalcreditassignmentoptimal,
      title={Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning}, 
      author={Aditya Kapoor and Sushant Swamy and Kale-ab Tessera and Mayank Baranwal and Mingfei Sun and Harshad Khadilkar and Stefano V. Albrecht},
      year={2024},
      eprint={2412.14779},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2412.14779}, 
}

@inproceedings{devlin2014potential,
  title={Potential-based difference rewards for multiagent reinforcement learning},
  author={Devlin, Sam and Yliniemi, Logan and Kudenko, Daniel and Tumer, Kagan},
  booktitle={Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems},
  pages={165--172},
  year={2014}
}

@inproceedings{wang2020shapley,
  title={Shapley q-value: A local reward approach to solve global reward games},
  author={Wang, Jianhong and Zhang, Yuan and Kim, Tae-Kyun and Gu, Yunjie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={7285--7292},
  year={2020}
}

@article{zhou2020learning,
  title={Learning implicit credit assignment for cooperative multi-agent reinforcement learning},
  author={Zhou, Meng and Liu, Ziyu and Sui, Pengwei and Li, Yixuan and Chung, Yuk Ying},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={11853--11864},
  year={2020}
}




% temporal credit assignment (single agent)
@article{arjona2019rudder,
  title={Rudder: Return decomposition for delayed rewards},
  author={Arjona-Medina, Jose A and Gillhofer, Michael and Widrich, Michael and Unterthiner, Thomas and Brandstetter, Johannes and Hochreiter, Sepp},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{liu2019sequence,
  title={Sequence modeling of temporal credit assignment for episodic reinforcement learning},
  author={Liu, Yang and Luo, Yunan and Zhong, Yuanyi and Chen, Xi and Liu, Qiang and Peng, Jian},
  journal={arXiv preprint arXiv:1905.13420},
  year={2019}
}

@article{ren2021learning,
  title={Learning long-term reward redistribution via randomized return decomposition},
  author={Ren, Zhizhou and Guo, Ruihan and Zhou, Yuan and Peng, Jian},
  journal={arXiv preprint arXiv:2111.13485},
  year={2021}
}

@article{gangwani2020learning,
  title={Learning guidance rewards with trajectory-space smoothing},
  author={Gangwani, Tanmay and Zhou, Yuan and Peng, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={822--832},
  year={2020}
}

@inproceedings{han2022off,
  title={Off-policy reinforcement learning with delayed rewards},
  author={Han, Beining and Ren, Zhizhou and Wu, Zuofan and Zhou, Yuan and Peng, Jian},
  booktitle={International Conference on Machine Learning},
  pages={8280--8303},
  year={2022},
  organization={PMLR}
}

@article{harutyunyan2019hindsight,
  title={Hindsight credit assignment},
  author={Harutyunyan, Anna and Dabney, Will and Mesnard, Thomas and Gheshlaghi Azar, Mohammad and Piot, Bilal and Heess, Nicolas and van Hasselt, Hado P and Wayne, Gregory and Singh, Satinder and Precup, Doina and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{zhu2023towards,
  title     = {Towards Long-delayed Sparsity: Learning a Better Transformer through Reward Redistribution},
  author    = {Zhu, Tianchen and Qiu, Yue and Zhou, Haoyi and Li, Jianxin},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {4693--4701},
  year      = {2023},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2023/522},
  url       = {https://doi.org/10.24963/ijcai.2023/522},
}


@article{patil2020align,
  title={Align-rudder: Learning from few demonstrations by reward redistribution},
  author={Patil, Vihang P and Hofmarcher, Markus and Dinu, Marius-Constantin and Dorfer, Matthias and Blies, Patrick M and Brandstetter, Johannes and Arjona-Medina, Jose A and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2009.14108},
  year={2020}
}

@article{zhang2023grd,
  title={GRD: A Generative Approach for Interpretable Reward Redistribution in Reinforcement Learning},
  author={Zhang, Yudi and Du, Yali and Huang, Biwei and Wang, Ziyan and Wang, Jun and Fang, Meng and Pechenizkiy, Mykola},
  journal={arXiv preprint arXiv:2305.18427},
  year={2023}
}

@inproceedings{efroni2021reinforcement,
  title={Reinforcement learning with trajectory feedback},
  author={Efroni, Yonathan and Merlis, Nadav and Mannor, Shie},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  pages={7288--7295},
  year={2021}
}


% temporal credit assignment (multi-agent case)
@article{xiao2022agent,
  title={Agent-temporal attention for reward redistribution in episodic multi-agent reinforcement learning},
  author={Xiao, Baicen and Ramasubramanian, Bhaskar and Poovendran, Radha},
  journal={arXiv preprint arXiv:2201.04612},
  year={2022}
}

@article{Chen2023STASSR,
  title={STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning},
  author={Sirui Chen and Zhaowei Zhang and Yali Du and Yaodong Yang},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.07520},
  url={https://api.semanticscholar.org/CorpusID:258179477}
}

@article{she2022agent,
  title={Agent-time attention for sparse rewards multi-agent reinforcement learning},
  author={She, Jennifer and Gupta, Jayesh K and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:2210.17540},
  year={2022}
}

@inproceedings{Yu2021TheSE,
  title={The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games},
  author={Chao Yu and Akash Velu and Eugene Vinitsky and Yu Wang and Alexandre M. Bayen and Yi Wu},
  booktitle={Neural Information Processing Systems},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:232092445}
}

% learning paradigms, MDPs, surveys
@inproceedings{Oliehoek2016ACI,
  title={A Concise Introduction to Decentralized POMDPs},
  author={Frans A. Oliehoek and Chris Amato},
  booktitle={SpringerBriefs in Intelligent Systems},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:3263887}
}

@article{amato2024partial,
  title={(A Partial Survey of) Decentralized, Cooperative Multi-Agent Reinforcement Learning},
  author={Amato, Christopher},
  journal={arXiv preprint arXiv:2405.06161},
  year={2024}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of reinforcement learning and control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}


@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% independent learning algorithms
@inproceedings{Tan1997MultiAgentRL,
  title={Multi-Agent Reinforcement Learning: Independent versus Cooperative Agents},
  author={Ming Tan},
  booktitle={International Conference on Machine Learning},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:268857333}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{de2020independent,
  title={Is independent learning all you need in the starcraft multi-agent challenge?},
  author={De Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2011.09533},
  year={2020}
}

% potential based reward shaping
@inproceedings{ng1999policy,
  title={Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping.},
  author={Ng, AY},
  booktitle={Proceedings of the 16th International Conference on Machine Learning},
  pages={278},
  year={1999}
}

@article{lu2011policy,
  title={Policy invariance under reward transformations for general-sum stochastic games},
  author={Xiaosong Lu, Howard M. Schwartz, Sidney N. Givigi Jr},
  journal={Journal of Artificial Intelligence Research},
  volume={41},
  pages={397--406},
  year={2011}
}

@inproceedings{Devlin2011TheoreticalCO,
  title={Theoretical considerations of potential-based reward shaping for multi-agent systems},
  author={Sam Devlin and Daniel Kudenko},
  booktitle={Adaptive Agents and Multi-Agent Systems},
  year={2011},
  url={https://api.semanticscholar.org/CorpusID:1116773}
}

@article{devlin2011empirical,
  title={An empirical study of potential-based reward shaping and advice in complex, multi-agent systems},
  author={Devlin, Sam and Kudenko, Daniel and Grze{\'s}, Marek},
  journal={Advances in Complex Systems},
  volume={14},
  number={02},
  pages={251--278},
  year={2011},
  publisher={World Scientific}
}



@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}v

@article{yu2022surprising,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
}

@article{Amir2023StatesAG,
  title={States as goal-directed concepts: an epistemic approach to state-representation learning},
  author={Nadav Amir and Yael Niv and Angela Langdon},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.02367},
  url={https://api.semanticscholar.org/CorpusID:265659011}
}

@misc{pathak2017curiosity,
      title={Curiosity-driven Exploration by Self-supervised Prediction}, 
      author={Deepak Pathak and Pulkit Agrawal and Alexei A. Efros and Trevor Darrell},
      year={2017},
      eprint={1705.05363},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1705.05363}, 
}

@misc{agrawal2015learning,
      title={Learning to See by Moving}, 
      author={Pulkit Agrawal and Joao Carreira and Jitendra Malik},
      year={2015},
      eprint={1505.01596},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.01596}, 
}