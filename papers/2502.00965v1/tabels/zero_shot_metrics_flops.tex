\begin{table*}[t]
% \small
\vskip -0.1in
\caption{Comparing performance of \name and baseline models including LIMOE~\cite{mustafa2022multimodalcontrastivelearninglimoe} across different model sizes. The sparse upcycling leverages the CLIP dense checkpoint trained for 440k steps. \name is further trained for additional 350k steps (790k steps in total). We also train CLIP with 790k steps to have comparable training steps to \name.}
\label{zero-shot-metrics-flops-steps}
\begin{center}
%\vskip -10pt
\small
\begin{sc}
\setlength{\tabcolsep}{5pt}
%\renewcommand{\arraystretch}{1.15}
%\resizebox{1.0\textwidth}{!}{
\begin{tabular}{l|c|c|cc|cccc|cccc}
\toprule
\multirow{3}{*}{Model} &\multirow{3}{*}{Steps} &\multirow{3}{*}{Inference} &\multicolumn{2}{c|}{Imagenet} &\multicolumn{4}{c|}{COCO retrieval} &\multicolumn{4}{c}{Flickr30k retrieval} \\
& & & \multicolumn{2}{c|}{classification} &T2I &T2I &I2T &I2T &T2I &T2I &I2T &I2T \\
&(k) &GFLOPS &Acc@1 &Acc@5 &R@1 &R@5 &R@1 &R@5 &R@1 &R@5 &R@1 &R@5 \\
\midrule
\multicolumn{13}{c}{\bf \textit{B/32}} \\
\midrule
OpenAI-CLIP &- &14.8 &63.2 &88.8 &30.8 &55.9 &51.6 &75.7 &- &- &- &- \rule{0pt}{3ex} \\
LIMOE &- &22.3 &67.5 &- &31.0 &- &45.7 &- &- &- &- &- \rule{0pt}{3ex} \\
\cdashline{1-13}
CLIP (ours) &440 &14.8 &72.4 &92.8 &41.7 &68.2 &62.3 &84.3 &68.0 &90.0 &\textbf{86.5} &\textbf{97.7} \rule{0pt}{3ex} \\
CLIP (ours) &790 &14.8 &72.4 &92.8 &41.9 &67.8 &62.4 &84.1 &67.8 &88.7 &85.6 &96.4 \rule{0pt}{3ex} \\
\rowcolor{lightblue}
\name & 790 &19.6 &\textbf{73.2} &\textbf{93.3} &\textbf{47.3} &\textbf{74.0} &\textbf{66.6} &\textbf{86.7} &\textbf{72.9} &\textbf{91.9} &85.9 &96.9 \rule{0pt}{3ex} \\
\midrule
\multicolumn{13}{c}{\bf \textit{B/16}} \\
\midrule
OpenAI-CLIP &- &41.2 &68.4 &91.9 &33.1 &58.4 &53.8 &77.9 &- &- &- &- \rule{0pt}{3ex} \\
LIMOE &- &48.7 &73.7 &- &36.2 &- &51.3 &- &- &- &- &-\rule{0pt}{3ex} \\
\cdashline{1-13}
CLIP (ours) &440 &41.2 &76.0 &94.7 &44.4 &70.3 &65.7 &87.0 &73.6 &92.1 &88.0 &97.8 \rule{0pt}{3ex} \\
CLIP (ours) &790 &41.2 &76.8 &\textbf{95.1} &44.9 &70.8 &66.0 &86.6 &74.3 &92.7 &88.9 &98.0 \rule{0pt}{3ex} \\
\rowcolor{lightblue}
\name & 790 &54.3 &\textbf{76.9} &\textbf{95.1} &\textbf{52.1} &\textbf{77.6} &\textbf{71.5} &\textbf{89.2}  &\textbf{80.9} &\textbf{95.6} &\textbf{92.3} &\textbf{99.2} \rule{0pt}{3ex} \\
\midrule
\multicolumn{13}{c}{\bf \textit{L/14}} \\
\midrule
OpenAI-CLIP &- &175.5 &75.3 &94.5 &36.1 &60.8 &57.7 &79.1 &- &- &- &- \rule{0pt}{3ex} \\
\cdashline{1-13}
CLIP (ours) &440 &175.5 &81.1 &96.4 &49.6 &74.4 &70.9 &89.6 &78.4 &94.7 &91.9 &\textbf{99.2} \rule{0pt}{3ex} \\
CLIP (ours) &790 &175.5 &\textbf{81.6} &\textbf{96.6} &50.2 &75.2 &71.4 &89.9 &79.3 &94.9 &91.7 &99.0 \rule{0pt}{3ex} \\
\rowcolor{lightblue}
\name & 790 &231.7 &81.2 & \textbf{96.6} &\textbf{53.9} &\textbf{79.4} &\textbf{73.8} &\textbf{92.0}  &\textbf{82.0} &\textbf{96.1} &\textbf{92.4} &99.1 \rule{0pt}{3ex} \\
\bottomrule
\end{tabular}
%}
\end{sc}
\end{center}
\end{table*}
