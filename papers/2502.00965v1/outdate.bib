@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@misc{wu2024mofilearningimagerepresentations,
      title={MOFI: Learning Image Representations from Noisy Entity Annotated Images}, 
      author={Wentao Wu and Aleksei Timofeev and Chen Chen and Bowen Zhang and Kun Duan and Shuangning Liu and Yantao Zheng and Jonathon Shlens and Xianzhi Du and Zhe Gan and Yinfei Yang},
      year={2024},
      eprint={2306.07952},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.07952}, 
}

@misc{fang2023datafilteringnetworks,
      title={Data Filtering Networks}, 
      author={Alex Fang and Albin Madappally Jose and Amit Jain and Ludwig Schmidt and Alexander Toshev and Vaishaal Shankar},
      year={2023},
      eprint={2309.17425},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.17425}, 
}

@misc{sun2024evaclip18bscalingclip18,
      title={EVA-CLIP-18B: Scaling CLIP to 18 Billion Parameters}, 
      author={Quan Sun and Jinsheng Wang and Qiying Yu and Yufeng Cui and Fan Zhang and Xiaosong Zhang and Xinlong Wang},
      year={2024},
      eprint={2402.04252},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.04252}, 
}

@misc{riquelme2021scalingvisionsparsemixture,
      title={Scaling Vision with Sparse Mixture of Experts}, 
      author={Carlos Riquelme and Joan Puigcerver and Basil Mustafa and Maxim Neumann and Rodolphe Jenatton and André Susano Pinto and Daniel Keysers and Neil Houlsby},
      year={2021},
      eprint={2106.05974},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2106.05974}, 
}

@misc{fedus2022switchtransformersscalingtrillion,
      title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity}, 
      author={William Fedus and Barret Zoph and Noam Shazeer},
      year={2022},
      eprint={2101.03961},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2101.03961}, 
}

@misc{mustafa2022multimodalcontrastivelearninglimoe,
      title={Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts}, 
      author={Basil Mustafa and Carlos Riquelme and Joan Puigcerver and Rodolphe Jenatton and Neil Houlsby},
      year={2022},
      eprint={2206.02770},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2206.02770}, 
}

@misc{lou2022crosstokenmodelingconditionalcomputation,
      title={Cross-token Modeling with Conditional Computation}, 
      author={Yuxuan Lou and Fuzhao Xue and Zangwei Zheng and Yang You},
      year={2022},
      eprint={2109.02008},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2109.02008}, 
}

@misc{zoph2022stmoedesigningstabletransferable,
      title={ST-MoE: Designing Stable and Transferable Sparse Expert Models}, 
      author={Barret Zoph and Irwan Bello and Sameer Kumar and Nan Du and Yanping Huang and Jeff Dean and Noam Shazeer and William Fedus},
      year={2022},
      eprint={2202.08906},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.08906}, 
}

@misc{komatsuzaki2023sparseupcyclingtrainingmixtureofexperts,
      title={Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints}, 
      author={Aran Komatsuzaki and Joan Puigcerver and James Lee-Thorp and Carlos Riquelme Ruiz and Basil Mustafa and Joshua Ainslie and Yi Tay and Mostafa Dehghani and Neil Houlsby},
      year={2023},
      eprint={2212.05055},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2212.05055}, 
}

@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@misc{lepikhin2020gshardscalinggiantmodels,
      title={GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding}, 
      author={Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},
      year={2020},
      eprint={2006.16668},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.16668}, 
}


@article{Zhou_2022,
   title={Learning to Prompt for Vision-Language Models},
   volume={130},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-022-01653-1},
   DOI={10.1007/s11263-022-01653-1},
   number={9},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
   year={2022},
   month=jul, pages={2337–2348} }

@misc{rao2022densecliplanguageguideddenseprediction,
      title={DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting}, 
      author={Yongming Rao and Wenliang Zhao and Guangyi Chen and Yansong Tang and Zheng Zhu and Guan Huang and Jie Zhou and Jiwen Lu},
      year={2022},
      eprint={2112.01518},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.01518}, 
}

@misc{gan2022visionlanguagepretrainingbasicsrecent,
      title={Vision-Language Pre-training: Basics, Recent Advances, and Future Trends}, 
      author={Zhe Gan and Linjie Li and Chunyuan Li and Lijuan Wang and Zicheng Liu and Jianfeng Gao},
      year={2022},
      eprint={2210.09263},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.09263}, 
}

@misc{ramesh2021zeroshottexttoimagegeneration,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2102.12092}, 
}

@misc{liu2023visualinstructiontuning,
      title={Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
      year={2023},
      eprint={2304.08485},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.08485}, 
}

@inproceedings{Cherti_2023,
   title={Reproducible Scaling Laws for Contrastive Language-Image Learning},
   url={http://dx.doi.org/10.1109/CVPR52729.2023.00276},
   DOI={10.1109/cvpr52729.2023.00276},
   booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
   year={2023},
   month=jun }

@misc{shazeer2017outrageouslylargeneuralnetworks,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
      eprint={1701.06538},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1701.06538}, 
}

@misc{zhang2024clipmoebuildingmixtureexperts,
      title={CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling}, 
      author={Jihai Zhang and Xiaoye Qu and Tong Zhu and Yu Cheng},
      year={2024},
      eprint={2409.19291},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.19291}, 
}
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@InProceedings{pmlr-v119-shankar20c,
  title = 	 {Evaluating Machine Accuracy on {I}mage{N}et},
  author =       {Shankar, Vaishaal and Roelofs, Rebecca and Mania, Horia and Fang, Alex and Recht, Benjamin and Schmidt, Ludwig},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {8634--8644},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}
@article{flickr30k,
    author = {Plummer, Bryan A. and Wang, Liwei and Cervantes, Chris M. and Caicedo, Juan C. and Hockenmaier, Julia and Lazebnik, Svetlana},
    title = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models},
    year = {2017},
    issue_date = {May       2017},
    publisher = {Kluwer Academic Publishers},
    address = {USA},
    volume = {123},
    number = {1},
    issn = {0920-5691},
    url = {https://doi.org/10.1007/s11263-016-0965-7},
    doi = {10.1007/s11263-016-0965-7},
    journal = {Int. J. Comput. Vision},
    month = may,
    pages = {74–93},
    numpages = {20},
    keywords = {Computer vision, Crowdsourcing, Datasets, Language, Region phrase correspondence}
}
@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@misc{zeng2024turnwasteworthrectifying,
      title={Turn Waste into Worth: Rectifying Top-$k$ Router of MoE}, 
      author={Zhiyuan Zeng and Qipeng Guo and Zhaoye Fei and Zhangyue Yin and Yunhua Zhou and Linyang Li and Tianxiang Sun and Hang Yan and Dahua Lin and Xipeng Qiu},
      year={2024},
      eprint={2402.12399},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.12399}, 
}

@misc{jiang2024mixtralexperts,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.04088}, 
}

@misc{dai2024deepseekmoeultimateexpertspecialization,
      title={DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models}, 
      author={Damai Dai and Chengqi Deng and Chenggang Zhao and R. X. Xu and Huazuo Gao and Deli Chen and Jiashi Li and Wangding Zeng and Xingkai Yu and Y. Wu and Zhenda Xie and Y. K. Li and Panpan Huang and Fuli Luo and Chong Ruan and Zhifang Sui and Wenfeng Liang},
      year={2024},
      eprint={2401.06066},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.06066}, 
}

@misc{xue2024openmoeearlyeffortopen,
      title={OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models}, 
      author={Fuzhao Xue and Zian Zheng and Yao Fu and Jinjie Ni and Zangwei Zheng and Wangchunshu Zhou and Yang You},
      year={2024},
      eprint={2402.01739},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.01739}, 
}

@misc{du2024revisitingmoedensespeedaccuracy,
      title={Revisiting MoE and Dense Speed-Accuracy Comparisons for LLM Training}, 
      author={Xianzhi Du and Tom Gunter and Xiang Kong and Mark Lee and Zirui Wang and Aonan Zhang and Nan Du and Ruoming Pang},
      year={2024},
      eprint={2405.15052},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.15052}, 
}

@misc{he2024upcyclinglargelanguagemodels,
      title={Upcycling Large Language Models into Mixture of Experts}, 
      author={Ethan He and Abhinav Khattar and Ryan Prenger and Vijay Korthikanti and Zijie Yan and Tong Liu and Shiqing Fan and Ashwath Aithal and Mohammad Shoeybi and Bryan Catanzaro},
      year={2024},
      eprint={2410.07524},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.07524}, 
}

@misc{raffel2023exploringlimitstransferlearning,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2023},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.10683}, 
}

@misc{xiong2020layernormalizationtransformerarchitecture,
      title={On Layer Normalization in the Transformer Architecture}, 
      author={Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan and Liwei Wang and Tie-Yan Liu},
      year={2020},
      eprint={2002.04745},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.04745}, 
}