\section{Necessary condition for the injectivity of polynomials}\label{section:cond_nec_poly_FDDS_inj}
	
	We will now show that the sufficient condition for injectivity of Proposition \ref{prop:condSufInj} is actually necessary.
	As previously, we start by considering polynomials without constant terms.
	Our starting point for this proof is given by  \cite[Theorem 34]{article_arbre}, which characterizes the injectivity of linear monomials.
	Furthermore \cite[Lemma 33]{article_arbre} proves that this condition is necessary for linear monomials.
	We begin by extending the proof of \cite[Lemma 33]{article_arbre} to show that this is necessary for \emph{all} monomials. 
	
	For this, let $\delta_J$ be the sequence recursively defined by $\delta_\emptyset = 1$ and $\delta_{J \cup \{a\}} = \gcd(a, \lcm(J)) \delta_J$ for all $a \in \N$. 
	Now let~$\mathcal{A}$ be a set of integers strictly larger than $1$ and for $I \subseteq \mathcal{A}$ we define $\alpha_I = \delta_\mathcal{A}\prod_{a \in \mathcal{A}} a$ and $\beta_I = \alpha_I + (-1)^{|I|}\delta_I \prod_{a \in \mathcal{A} - I} a$.
	
	We will use $\alpha_I$ and $\beta_I$ to construct two different FDDS $X$ and $Y$ such that $AX = AY$ if $A$ is not cancelable.
	We will start with the case where $A$ is a cycle, denoted by $C_b$ where $b = \cycle(C_b)$.
	% We First set a technical lemma.
	
	\begin{lemma}\label{lemme:cycleNonInjTech}
		% Let $\mathcal{A}$ be a set of integers strictly larger than $1$ and
                Let $k \ge 1$ be an integer, $b \in \mathcal{A}$, $I \subseteq \mathcal{A} - \{b\}$ and $J = I \cup \{b\}$. Then
                \begin{equation}
                \label{eq:kToKMinus1}
                C_b (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)})^k = C_b (\alpha_I C_{\lcm(I)} + \alpha_J C_{\lcm(J)})^k.
                \end{equation}
	\end{lemma}
	
	\begin{proof}
		% We have
		% \begin{equation}
		% 	C_b (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)})^k = C_b (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)}) (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)})^{k-1}.
		% \end{equation}
		The proof of \cite[Lemma 33]{article_arbre} shows that $C_b (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)}) = C_b (\alpha_I C_{\lcm(I)} + \alpha_J C_{\lcm(J)})$.
		Thus, we can replace one instance $C_b (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)})$ in \eqref{eq:kToKMinus1} % by $C_b (\alpha_I C_{\lcm(I)} + \alpha_J C_{\lcm(J)})$
                and obtain:
		\[C_b (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)})^k =(\alpha_I C_{\lcm(I)} + \alpha_J C_{\lcm(J)}) C_b (\beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)})^{k-1}.\]
		By repeating the same substitution, the thesis follows.
	\end{proof}
	
	Now we can prove that monomials of the form $A X^k$, with $k \ge 1$ and where $A$ is a sum of cycles (\ie, a
        \emph{permutation}) with no cycle of length~$1$, are never injective.
	
	\begin{lemma}\label{lemme:noInjMonomeP1}
		% Let $\mathcal{A}$ be a set of integer strictly superior to $1$ and
                Let~$A = A_1 + \cdots + A_m$ be a sum of cycles of length greater than~$1$ and $k \ge 1$ be an integer.
		Then, there exist two different $FDDS$ $X,Y$ such that $A_j X^k = A_j Y^k$ for all~$1 \le j \le m$ and, by consequence, $A X^k = A Y^k$.
	\end{lemma}

	\begin{proof}
                Let~$\mathcal{A}$ be the set of cycle lengths of~$A$.      
                Let $X = \sum_{I \subseteq \mathcal{A}} \alpha_I C_{\lcm(I)}$ and $Y = \sum_{I \subseteq \mathcal{A}} \beta_I C_{\lcm(I)}$. Remark that~$\alpha_I \ne \beta_I$ for all~$I \subseteq \mathcal{A}$, since~$\beta_I$ is $\alpha_I$ plus a nonzero term; in particular, $\alpha_\emptyset \ne \beta_\emptyset$ and, since these two integers are the number of fixed points of~$X$ and~$Y$ respectively, we have~$X \ne Y$.

                Let us consider a generic term $A_j$, which is a cycle $C_b$ for some $b>1$ for all~$j$. Let~$I_1, \ldots, I_n$ be an enumeration of the subsets of~$\mathcal{A}-\{b\}$ and let~$J_i = I_i \cup \{b\}$ for all~$1 \le i \le n$. Then~$Y = \sum_{i=1}^n (\beta_{I_i} C_{\lcm(I_i)} + \beta_{J_i} C_{\lcm(J_i)})$
		
		% We have that $C_b Y^k = C_b (\sum_{I \subseteq \mathcal{A} - \{b\}} \beta_I C_{\lcm(I)} + \beta_J C_{\lcm(J)})^k$.
		In order to compute~$A_j Y^k = C_b Y^k$ we can distribute the power over the sum, then the product over the sum, and we obtain:
		\begin{equation}\label{eq:distProdSum}
			C_b Y^k = \sum_{k_1+\cdots+k_n=k}\binom{k}{k_1,\ldots,k_n} C_b (\beta_{I_1} C_{\lcm(I_1)} + \beta_{J_1} C_{\lcm(J_1)})^{k_1}\prod_{i=2}^{n} (\beta_{I_i} C_{\lcm(I_i)} + \beta_{J_i} C_{\lcm(J_i)})^{k_i}.
		\end{equation}
		By Lemma \ref{lemme:cycleNonInjTech}, we have $C_b (\beta_{I_1} C_{\lcm(I_1)} + \beta_{J_1} C_{\lcm(J_1)})^{k_1} = C_b (\alpha_{I_1} C_{\lcm(I_1)} + \alpha_{J_1} C_{\lcm(J_1)})^{k_1}$.
		Thus, by replacing this in Equation \eqref{eq:distProdSum}, we have
		\[C_b Y^k = \sum_{k_1+\cdots+k_n=k}\binom{k}{k_1,\ldots,k_n} C_b (\alpha_{I_1} C_{\lcm(I_1)} + \alpha_{J_1} C_{\lcm(J_1)})^{k_1} \prod_{i=2}^{n} (\beta_{I_i} C_{\lcm(I_i)} + \beta_{J_i} C_{\lcm(J_i)})^{k_i}.\]
		If we repeat this substitution for all $2 \le i \le n$ and factor $C_b$ from each term of the sum we obtain
		\[C_b Y^k = C_b \sum_{k_1+\cdots+k_n=k}\binom{k}{k_1,\ldots,k_n}  \prod_{i=1}^{n} (\alpha_{I_i} C_{\lcm(I_i)} + \alpha_{J_i} C_{\lcm(J_i)})^{k_i}.\] 
		Since $\sum_{k_1+\cdots+k_n=k}\binom{k}{k_1,\ldots,k_n}  \prod_{i=1}^{n} (\alpha_{I_i} C_{\lcm(I_i)} + \alpha_{J_i} C_{\lcm(J_i)})^{k_i}$ is just $X^k$, we conclude that $C_b Y^k = C_b X^k$, \ie, $A_j Y^k = A_j X^k$.

                This holds separately for each connected component~$A_j$ of~$A$; by adding all terms and factoring $X^k$ and $Y^k$ we obtain $AX^k = AY^k$.
	\end{proof}
	
	We remark that the $X$ and $Y$ which we have built are just permutations. 
	An interesting property of permutations is that they are closed under sums and products (and thus nonnegative integer powers).
	Thus $X^k$ and $Y^k$ are also permutations.
	Another useful property of permutations is, intuitively, that if we multiply a sum of connected components $A = A_1 + \cdots + A_n$ with a sum of cycles $X = X_1 + \cdots + X_m$, the trees rooted in each connected component of $A_i X_j$ are just a periodic repetition of the trees rooted in the cycle of $A_i$ for all $i,j$ \cite[Corollary 14]{article_arbre}.
	Thanks to these properties, we can characterize the injectivity of monomials.
	
	\begin{proposition}\label{prop:charaInjMonome}
		A monomial over FDDS is injective if and only if its coefficient is cancelable.
	\end{proposition}
	
	\begin{proof}
		Assume that the monomial $AX^k$, where $A = A_1 + \cdots + A_n$ as a sum of connected components and~$k>0$, is not cancelable. Hence, by \cite[Theorem 34]{article_arbre}, $A$ does not have a cycle of length 1 (a fixed point).
		Let $B = B_1 + \cdots + B_n$ the permutation such that~$\cycle(B_i) = \cycle(A_i)$ for all~$i$.
		By Lemma \ref{lemme:noInjMonomeP1}, there exist two distinct permutations $X,Y$ such that $B_i X^k = B_i Y^k$ for all $i$. 
		Thus, by~\cite[Corollary 14]{article_arbre}, we have $A_i X^k = A_i Y^k$ and, by summing, $A X^k = A Y^k$.

		The inverse implication was already proved in Proposition \ref{prop:condSufInj}.
        \end{proof}
	
	In the rest of this section, we will prove that a polynomial is injective if and only if a certain monomial is injective.
	Remark that the sum of any FDDS with a cancelable FDDS is also cancelable.
	Hence, the sum of the coefficients of a polynomial is cancelable if and only if at least one of them is cancelable.
	
	From the characterization of injective monomials (Proposition~\ref{prop:charaInjMonome}) we can deduce that there exists an positive integer $k$ such that $A X^k$ is injective if and only if $A X^n$ is injective for \emph{all} positive integer $n$.
	
	\begin{proposition}\label{prop:charaInj}
		Let $P = \sum_{i=1}^{m} A_i X^{i}$ be a polynomial without constant term and consider the monomial~$M = (\sum_{i=1}^{m} A_i)X$. Then, $P$ is injective if and only if $M$ is injective.
	\end{proposition}
	
	\begin{proof}
		Assume that $M$ is injective.
		Thus, by the Proposition \ref{prop:charaInjMonome}, its coefficient is cancelable.
		Hence, at least one coefficient of $P$ is cancelable.
		By Proposition \ref{prop:condSufInj}, we conclude that $P$ is injective. 
		
		For the other direction, assume that $M$ is not injective.
		Let $X$ and $Y$ the FDDS constructed in the proof of Proposition \ref{prop:charaInjMonome}.
		As previously, $X \neq Y$ but $A_i X^i = A_i Y^i$ for all $i \in \{1,\ldots, m\}$. 
		So, by sum, we have $P(X) = P(Y)$.
	\end{proof}
	
	Thanks to this characterization, we conclude that the condition given in Proposition \ref{prop:condSufInj} is also necessary for polynomials without a constant term.
	All it remains to prove is that this is also necessary in the presence of a constant term.
	
	\begin{theorem}\label{th:charaInjPoly}
		Let $P = \sum_{i=0}^{m} A_i X^{i}$ a polynomial. Then $P$ is injective if and only if at least one of $A_i$ is cancelable for some~$i \ge 1$.
	\end{theorem}
	
	\begin{proof}
                Assume that no non-constant coefficient of $P$ is cancelable.
		Let $P' = \sum_{i=1}^{m} A_i X^{i}$ the polynomial $P$ without the term $A_0$.
		By the Proposition \ref{prop:charaInj}, there exist two different FDDS $X,Y$ such that $P'(X) = P'(Y)$.
		Then $P'(X) + A_0 = P'(Y) + A_0$, which implies $P(X) = P(Y)$. 
		Thus, $P$ is not injective.

		The inverse implication is due to Proposition \ref{prop:condSufInj}.
	\end{proof}
	%%% Local Variables:
	%%% mode: LaTeX
	%%% TeX-master: "main"
	%%% End:
