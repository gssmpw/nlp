\section{Search and Rescue}
\label{sec:sar_mission}


%Goal
We concentrate on the multidrone-based SAR task with a single human operator supervising and controlling a fleet of $\DronesNum$ drones in search of an unknown number of targets in a large area (e.g., searching for victims after an earthquake). The use of multiple drones working together as a team can reduce the time required to locate persons in distress, offering significant advantages over traditional methods \cite{hoang2023droneswarms}.  The typical overarching goal of such tasks, as in our setting, is to maximize the number of targets found during the mission's fixed time.
For a comprehensive review of the current state and challenges of drone applications in disaster management, including search and rescue, see~\cite{daud2022applications}.


%Foundations from du
Mission planning for multiple drones involves complex strategies to ensure efficient coverage and task completion \cite{song2023survey}.
We build on top of the drone-based SAR task modeling provided by \cite{du2019evolutionary}. Specifically, we assume that the entire search zone is known in advance and is partitioned into smaller sub-areas, denoted by $E$ the set of the sub-areas. Each sub-area is assigned a probability indicating the likelihood of finding at least one target within that specific sub-area. Assuming no prior knowledge, all sub-areas are given the same likelihood. Nonetheless, these probabilities may change dynamically based on the real-time information provided by the drones and/or manually by the operator (e.g.,  based on gathered intelligence that occasionally provided to the user through \say{intelligence messages}). In turn, these probabilities can influence the operator's decision to assign drones to specific sub-areas.
% \footnote{In our system, the allocation algorithm is designed to assign a search area and an associated altitude for each drone to scan that area. However, when the operator manually adjusts the altitude, our algorithm respects this decision and does not output a new altitude. This ensures that the operator's on-the-fly adjustments are prioritized and the drone continues to operate at the operator-modified altitude.} 
%Drones are assigned to different sub-areas based on a complex algorithm (see Appendix~\ref{CentralizedAlgorithm} for more details).

%Our system environment: 
In our environment, drones scan their designated sub-areas following a lawn mower pattern. The scanning process is governed by four parameters - the drone's velocity, altitude, and two thresholds to determine the minimal confidence for a low-confidence suspected target and a high-confidence suspected target. Specifically, during the scanning phase, the drones' cameras capture images rapidly. These images are then processed through a neural network (NN) to produce bounding boxes and associated confidence indicating the presence of potential targets. To that end, a Retina net \cite{retina:20} NN model is trained using the approach provided in \cite{AIR:21} on the Heridal dataset \cite{heridal-lrbkc_dataset} and subsequently fine-tuned using manually tagged images from our simulated environment. It was shown that drones have difficulties identifying victims in SAR in the wild. Manzini and  Murphy \cite{manzini2023open} demonstrated that despite achieving performance that is statistically equivalent to the state-of-the-art on benchmark datasets, the models they tested fail to translate these achievements to the real world in terms of many false positives (e.g., identifying tree limbs and rocks as people), and false negatives (e.g., failing to identify victims). Similar problems were observed in our SAR environment in preliminary testing. 
%hodaya: need to add fp and fn
Therefore, in our environment, the human operator needs to approve a suspected target. To balance between false alarms and missed detections, we define two thresholds: low-confidence (\pausetreshold) and high-confidence (\detectiothreshold). If the confidence of the NN exceeds \detectiothreshold, the drone stops, and an alert with the associated confidence is sent to the operator. If the confidence only surpasses the \pausetreshold, the drone further scans around the suspected object, and an alert with a timeout and the (relatively low) confidence of the detection is sent to the operator, allowing her to observe the object if she has the time. If no high confidence is achieved during further scanning, the drone dismisses the detection; otherwise, it elevates the alert to a high-confidence one and waits for the operator's handling of the event.
The drone's altitude, velocity, and the two confidence thresholds are determined by the operator based on the area's characteristics, existing intelligence, and the operator's capabilities, to name a few.
For example, highly dense sub-areas (e.g., forest) may be better assigned different parameters than sparse sub-areas (e.g., desert). The operator can determine the parameters of a given sub-area by designating its so-called \say{area type} as \say{high}, \say{medium}, or \say{low} difficulty area. Complementary, the operator can manually select the parameters for each area. Note that at the beginning of the simulation, the operator is required to set all these parameters (or confirm the provided default values).  
Finally, drones may have simulated malfunctions, in such cases, an alert is generated and requires the operator's attention.  

%Human operator





% Additionally, the operator  has the authority to adjust the parameters of the drones, such as altering altitude or speed. Furthermore,  the operator can modify the search parameters, including areas' probabilities of finding targets and the assignment of drones to areas. 
%By leveraging their expertise and making informed decisions, the human operator significantly influences the search mission's outcomes, ultimately increasing the chances of locating more targets in a timely and efficient manner.

Overall, the set of actions that the operator can take, $A$, consists of five types of actions: 
(i) Changing the assumed probability of finding (additional) targets within any specific sub-area; (ii) Changing the area type of a given sub-area, denoted by $CT$; (iii) changing the scanning parameters associated with an area (i.e., altitude, velocity, and thresholds), denoted by $CP$;  (iv) Manually flying a drone that is suspected of being stuck, manually reporting on a target (without relevant alerts), and manually assigning a specific drone to a sub-area (v) Handling alerts such as detection, malfunctions, and intelligent messages (note that base on the information in the intelligent message the operator may decide to change the probabilities of the sub-areas or manually change the assignment of drones to sub-areas).

%Ariel: consider adding a sentence saying that the simulation is high-resolution and realistic (i.e., wind is simulated, trees are moving.... and as such, it is non-deterministic...
The simulation is high-resolution and realistic, incorporating advanced features such as simulated wind, dynamic movement of trees, and real-time imaging from drones, as can be seen in a short illustration video.\footnote{\url{https://youtu.be/W-HHF8s2O8c}}  
% This realism introduces non-deterministic outcomes; for instance, handling a detection alert could result in either approving or rejecting a suspected target. In addition to the uncertainties arising from the environment itself, such as the number of incoming alerts, the possibility of drones getting stuck, and other factors.  
%move to 4 
%In our experiment an advice can be either a simple action ($a \in A$) or a complex action, that is, a sequence of some actions from $A$ of same type. 
%hodaya: need to edit the connection
%\sarit{I suggest to move this before the state observation because you use it previously and then you return } \odaya{done}
%Let $\Pfunc{\stateS}{\action}{\stateS'} \ $ be the transition function that denotes the probability that doing the action $a$ at state $\stateS$ will lead to state $\stateS'$. For all $\stateS \in S$, $\sum_{s' \in S} \Pfunc{\stateS}{\action}{\stateS'}=1$.
%The transition model captures the uncertainty in the system's dynamics and is calculated using assumptions and probabilities. It describes the probability of the system transitioning to a new state given the current state and the action taken by the operator.
%Finally, let $R(s,a)$ be the reward function which refers to the number of targets found while doing action $a$ at state $s$. %[encouraging the agent to find targets efficiently].
%this is the reward we chose in order to encourage the agent to find targets %efficiently, encouraging exploration of the area, and encouraging accurate %workload on the operator.
%represents the operator's preference for immediate rewards versus future rewards. A higher discount factor places more emphasis on immediate rewards, while a lower one favors long-term planning.
%A policy $\pi$ is a function from state $s$ to a complex action $a^v\subset A$.
%In the ideal case, the agent computes the optimal policy for the specific operator, $\pi^*_\operator: S \rightarrow A$, that maximizes the expected accumulative future reward. However, the uncertainty of the environment, the exponential size of the state space, $S$, and the combinatorial size of the action set, $A$, cause this problem to be intractable.
%We trained a model, that given a state return a value that is a predicted accumulate rewards along the game's trajectory.
%
%\label{DetectionModel}
%[Finalized - Sarit please review]
% How detect? threshold?X2 stacked, generalization.
% SAR Drones: ML based module to detect survivels -- better performance when cooperating with human.
%[todo: remove yolo. add FP  and TP here and on heridial in AIR. check what was according AIR and if it was simply retina net at the end (i think we remove their additional to the retina net, we use their advice on the details such as backbone)]
%\subsection{Detection Model}\label{DetectionModel}
%
% They showed in the article () that the combination of an operator and the presentation of the marking achieves better toys, therefore also with us the operator is required to perform the task and we chose to present the square in order to help in the search
%Two different known models were implemented for this task and tested on the actual simulator to determine  the better model to use. after training YoloV5 and RetinaNet (AIR) on our data (trained first on Heridal followed by a training on the generated AirSim images), RetinaNet performed better giving better results for true positives and false positives. 
%\subsection{Allocation Algorithm}
% \label{AllocationAlgorithm}
%  Centralized algo for drone allocation and path planning: input: map divided to areas. based on probablity of finding surviers in a given area; how it is updated
%\subsection{Human Operator}
%[ Finalized - Sarit please review ]
%The role of the human operator in Search and Rescue (SAR) environments plays a pivotal role in the overall success of the mission. Their decisions and actions are of utmost importance in enhancing the efficiency of the drones' search operations. As a central figure, the human operator is responsible for providing essential instructions and guidelines to the drones, ensuring that they carry out their search tasks effectively. 
%\subsection{The User Interface}
%\label{sec:sar}
% In Figure~\ref{fig:sar_simulator}, the interface is displayed. Further details regarding the interface and the design choices made are provided in the Appendix.

% \begin{figure}[t]
% \centering
% \setlength{\belowcaptionskip}{-10pt}
% \includegraphics[width=0.9\columnwidth]{media/SAR_simulator.jpg} % Reduce the figure size so that it is slightly narrower than the column. Don't use precise values for figure width.This setup will avoid overfull boxes.
% \caption{The SAR simulator.}
% \label{fig:sar_simulator}
% \end{figure}

\subsection{The User Interface}
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{media/SAR_simulator.jpg} % Reduce the figure size so that it is slightly narrower than the column. Don't use precise values for figure width.This setup will avoid overfull boxes.
\caption{The SAR User Interface.}
\label{fig:sar_simulator}
\end{figure}



\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\linewidth]{media/manual_control.jpeg}
    \caption{Manual control panel, during handling detection alert.}
    \label{fig:manual_control}
\end{figure}
\label{sec:sar}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{media/left_panel.png}
    \caption{The left panel contain four tabs: Drones, Areas, Status and Parameters.}
    \label{fig:left_panel}
\end{figure}

Similar to the goal described by Chen et al. \cite{chen2022multi}, our SAR system aims to provide the operator with comprehensive situational awareness while minimizing the need for low-level control of each drone. The \say{task mode} includes automated allocation of the sub-areas to drones, where each drone scans its designated sub-area based on the difficulty level defined for that sub-area. The drones search for targets and alert the operator to suspected targets.
In the \say{command mode}, our system offers the flexibility for the operator to manually assign sub-areas to specific drones, manually control a drone, or manually report targets as necessary.

The central part of the user interface has two modes: a map mode and a drone mode. 
In the map mode, the map is displayed, divided into sub-areas, showing the locations of the drones on the map.  Each drone is labeled with a number, as recommended in~\cite{hoang2023challenges}.
At the top, there are small images for each drone displaying what the drone sees (see Figure~\ref{fig:sar_simulator}). In the drone mode, a specific drone's view is shown in at the central area in a larger format, allowing the operator to manually control the drone and consider the specific details observed by the drone. For example, the operator can better handle a detected target in this mode (see Figure~\ref{fig:manual_control}).

The left-side panel contains four tabs (see Figure~\ref{fig:left_panel}):
\begin{itemize}
    \item \textbf{Drones} - This tab provides each drone a list of its assigned sub-areas, with the option to manually change it.
    \item \textbf{Areas} - This tab displays all sub-areas, allowing the operator to change the probability of finding a target in a specific sub-area and amend the sub-areas difficulty levels.
    \item \textbf{Status} - Controlling the simulation mode - choosing a scenario and switching between scanning and parameters phases. 
    \item \textbf{Parameters} - In this tab, the operator can set the parameters (altitude, velocity, and thresholds) for each area.
\end{itemize}


On the right-hand side, there is a panel containing the alerts from drones, which are displayed in light green, and other messages, such as those from the agent, which are displayed in light orange (see Figure~\ref{fig:sar_simulator}). 

In a preliminary experiment, we separated these messages into two different tabs: drone and agent messages. However, we noticed that this setup was less convenient for most operators given the high number of alerts from the drones. In particular, operators noted that they felt pressured to respond to them and often missed important messages from the agent. Therefore, in our ensuing human evaluation, we combined both types of messages into a single tab, but with different colors, providing the operator with a simpler way to see and distinguish the alerts and agent's messages. 

