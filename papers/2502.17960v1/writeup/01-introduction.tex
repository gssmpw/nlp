\section{Introduction}
\label{Introduction}

Multi-drone systems are revolutionizing various industries including agriculture \cite{tsouros2019review}, construction \cite{sai2022survey}, and search and rescue (SAR) \cite{lyu2023unmanned}, to name a few \cite{hassanalian2017classifications}. 
As drone technology advances, the potential for innovative applications and their societal impact is expected to continue to grow \cite{tezza2019state}. Nevertheless, there are some inherent limitations to what multi-drone systems can handle autonomously. As such, it is common for human operators to provide an extra layer of monitoring, decision-making, and situational awareness, thus forming a so-called \say{human-multi-drone team} \cite{rebensky2022teammates,francos2023role}.  
% The collaboration between a human operator and multi-drone system  team. 

Supervising and controlling multiple drones in dynamic and uncertain environments is a highly challenging task~\cite{nischal2024challenges}. Model-driven approaches have been proposed to facilitate human-on-the-loop drone missions, where autonomous decisions are made by drones but guided by human oversight to improve mission success in time-critical operations \cite{agrawal2020modeldriven}. In particular, the human operator is typically expected to monitor and respond to the drones' locations, statuses, sensor readings, and various other signals and information in a timely fashion while managing unexpected events, emergencies, and changing circumstances. 
Research by \cite{porat2016supervising} demonstrated that when control tasks are extensive, human operators can effectively collaborate with two drones. However, even experienced operators encountered difficulties managing three drones (or more) in complex settings, leading to a reduction in the overall team performance.


The integration of intelligent agents into mixed teams is becoming increasingly prevalent, offering new opportunities and challenges in team dynamics \cite{HumanAgent_Team_Dynamics,natarajan2024mixedinitiative}. Aligned with this important line of work, in this paper, we develop and evaluate a novel advising agent for supporting human-multi-drone team collaboration for lifelike tasks. 
In our setting, advice refers to action recommendations aimed at improving the overall team performance, which the advising agent generates based on contextual information. The presented agent relies on machine learning estimations of the long-term effects of various human-like actions which, in turn, are translated into useful advice. 
Central to our approach is the generation of \textit{realistic} trajectories that mimic human operators, using very few human demonstrations. Specifically, in order to adequately utilize machine learning to estimate the long-term effects of different actions, we propose a method to simulate the trajectories resulting from (unseen) human-like actions from a given setting using a limited number of human-generated examples. 
% while relying on very few demonstrations.
We instantiate our approach to a realistic SAR simulation, and through an extensive human study, we show that our agent is capable of providing high-quality advice, which, in turn, brings about favorable team performance compared to baseline conditions.
%Our paper specifically focuses on the development and evaluation of an advising agent that supports real-time decision-making, which is crucial for managing multiple drones effectively. 
%In contrast, 

%The study by  \cite{agrawal2021explaining} discusses the challenges in explaining autonomous decisions in swarms of human-on-the-loop small unmanned aerial systems, emphasizing the need for clear explanations to maintain situational awareness. This is particularly different as it concentrates on the transparency of autonomous systems to aid human understanding and trust, rather than directly enhancing team performance through an advising agent.




% and a reduced cognitive load on the human operator. 

%hodaya - add what does the acronym AA mean?
% Above all, the contributions of this paper are the following:
% \begin{itemize}
%     \item Designing the agent model within the constraints of limited real data availability and sparse data conditions.
%     \item Introducing a methodology for annotating trajectories in scenarios where the outcomes of states and actions are not unequivocally clear, and a manual annotation by a human is not feasible.
%     \item Describing a methodology for generating tasks for an operator based on the current state.
%     \item Presenting an algorithm for prioritizing tasks for operators.
%     \item Conducting extensive experiments, including a human study, to both develop the AA agent and evaluate its impact on performance in Search and Rescue (SAR) missions. %odaya - where to note that the results in the paper are on the first agent and not the new one?
% \end{itemize}
%\section{Related work}
\section{Related Work}

Various techniques have been proposed to assist human operators in managing multiple drones.  Roughly speaking, these can be divided into two groups: Intelligent User Interfaces (IUIs) and intelligent advising agents. The former group typically seeks to  assist the operator in gaining a better situational awareness and understanding and providing more efficient command and control capabilities. Several prior works explore natural user interfaces, such as speech, gestures, body position, and eye-tracking, to facilitate intuitive drone interaction (e.g., \cite{fernandez2016natural, implementation2020Brandon, natural2022marina}). \cite{agrawal2021explaining} examines how different IUI design choices affect human situational awareness, while \cite{chen2022multi} proposes a task-based graphical interface to enhance control and situational awareness. Similarly, \cite{kostenko2022supervised} explores classifying operator functional states using physiological data to dynamically improve human-machine interaction in drone swarm piloting.
Boggess et al. \cite{boggess2023explainable,boggess2022toward} propose XAI methods to explain the behavior and decision-making processes of a team of robots to a human collaborator.

%\cite{rebensky2022impact} studied the effectiveness of heads-up displays in which the system information was overlaid on the environmental view. 

Previous research has introduced methods to improve interaction between a single automated team member (e.g., a robot) and a human operator to enhance overall collaboration \cite{edgar2023humanrobot,schleibaum2024adesse,azaria2015,azaria2012}. Projects like HADRON have developed AI-driven control systems to reduce human workload by improving tasks such as target and defect detection \cite{casado2024hadron}. \cite{al2020generating} proposed a forward simulation-based alert system to notify supervisors of potential negative events. In \cite{wu2024hierarchical}, natural language processed by LLMs allows human operators to communicate with a drone team, though no human studies were conducted, and timely comment generation was not evaluated.

We focus on intelligent advising agents that seek to support the operator by advising the operator on which actions to take  \cite{rosenfeld2017intelligent}. This approach complements the previously discussed methods, as it is interface-agnostic (i.e., capable of being integrated with any user interface) and independent of the AI tools used by the drones.  It is shown to be highly effective (i.e., better team performance).
The intelligent advising agents on which actions to take approach was explored in several domains; for example, \cite{trabelsi2023advice} provides an intelligent agent for the teleoperation of autonomous vehicles, and \cite{vered2020demand} developed an intelligent agent for a multi-vehicle setting in order to study ways to increase user trust. 

Most closely related to our work is  \cite{rosenfeld2017intelligent}, who tackled a similar challenge in a non-aerial environment. The authors suggested the use of a so-called \say{utopic environment} where they simulate the effects of different actions by assuming their ground robots operate optimally, never malfunction, and require no supervision or control from the human operator. In other words, the authors assume that the utopically-simulated long-term effects of an action are a reasonable approximation of the actual long-term effects. The rationale for using such a utopic environment is clear -  it makes the collection and annotation of extensive human demonstrations unnecessary, as these simulations execute fully autonomously. Unfortunately, this assumption is highly unrealistic in complex real-world environments, as noted by the original authors themselves. In particular, when considering multiple drones deployed in unexpected dynamic conditions that require human intervention, this oversimplifying assumption may lead to poor estimations and sub-optimal advice provision. In this work, we propose a new method to overcome this limitation by relaying on a small set of human demonstrations.  

% This approach is more focused on enhancing the decision-making performance of human operators by introducing alerts based on simulation data, which is a different approach from the real-time advising agent discussed in our article
% The Firefly Algorithm has been effectively utilized for path optimization in dynamic environments, such as flood-affected areas, demonstrating its efficacy in drone surveillance tasks \cite{kumar2023firefly}.
% 

%

% Our work complements this work by adding an intelligent agent that recommends
% to the operator which tasks to take. For our studies, we designed the interface (see Figure~\ref{??}) following common practice used, for example in \cite{rosenfeld2017intelligent}.

% This approach is more focused on the operator's physiological responses rather than the interactive decision-making process.
%
%The paper \cite{besada2019drones} proposes a microservice-oriented architecture to optimize drone fleet management. This architecture facilitates coordinated resource allocation and simultaneous drone control, enabling more efficient and effective operations.
%
%The paper \cite{aggravi2020connectivity} highlights the importance of intuitive control and effective feedback, demonstrating that haptic feedback outperforms no feedback or visual feedback in maintaining connectivity within a UAV fleet.
%*********************************************************************************
%(e.g.,\cite{fernandez2016natural,besada2019drones,aggravi2020connectivity, chen2022multi}). 


% as well as to reduce the operators' cognitive workload. 

% , where the effects of some actions, such as changing the altitude of a given drone, can only be effectively observed in the long term using much longer trajectories \cite{}.
% That is, relying on the short-term effect of an action may provide a poor estimation of its actual long-term benefit, resulting in suboptimal advice provision.  

% \paragraph{Contribution}
% [Sarit: Write here what is our contribution]


