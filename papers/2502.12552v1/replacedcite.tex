\section{Related Work}
Integrating child safety with technology research is challenging due to its multidisciplinary nature and the lack of a unified framework ____. While most studies focus on traditional media and internet technologies, AI's recent adoption among children has resulted in sparse literature, which this work addresses.

A lot of existing technological child safety literature revolves around the use of television, video-games, mobiles, internet and social media. Mainstream usage of AI among children is relatively recent, resulting in sparse literature on the topic. We broadly cover two segments of literature focusing on child safety and AI.

\subsection{Using AI to improve Child Safety}
AI is increasingly being utilized in various domains to enhance child safety, including areas such as \textit{Detecting child abuse using AI}, \textit{AI-based personal therapist} and \textit{AI for safety against technology}. Detecting child abuse using AI has been widely explored across various domains. ____ surveys AI predictive models for child abuse, while works like ____ explore approaches for the detection of children at risk of physical abuse based on textual clinical records. In case of an AI-based personal therapist, as demonstrated by ____, it suggests that children may disclose challenging personal events more openly to AI assistants than to human therapists or parents, presenting a new opportunity. Furthermore, AI for safety against technology has been explored in several studies.____ shows that AI-based moderation is better than parental control for child sustainability and reducing continued exposure to digital devices.____ highlights several ways AI can help tackle risks of Metaverse with personalized approaches that is able to provide nuanced safety tailored for the child.


Despite the existing body of work in this area, our primary focus is to highlight key directions that promote the beneficial applications of AI by child safeguarding.



\subsection{Evaluating Child Safety of LLMs }
\label{subsec:eval_child_safety}
There has been effort toward evaluating LLMs for child safety, but it is often restricted to a few dimensions under general RAI evaluations or focused on a limited set of applications.
____ explore the protections of a few open-source and commercial LLMs against child grooming. They find all LLMs to be severely vulnerable to child grooming. ____ provide a taxonomy of ethical risks in AI for education, while ____ explore the ethical implications of exposing children to emotional AI through toys and digital devices.
____ provide a test set that covers various AI harms including child-specific harms like child abuse and eating disorders. These areas of harm within LLMs are consistently observed as being the least protected. 
While ____ survey 29 harms, one of which is harm to minors. Other works also target general safety, for example how incorrect instructions can be generated regarding supervising children around water bodies____.

Overall, research on evaluating the safety of LLMs for children is limited. Existing studies tend to focus on either narrowly defined applications such as educational or emotional AI, or address specific harms, such as child grooming, using simplistic, template-based prompts.
In this paper, we build on this line of work by evaluating six state-of-the-art LLMs, across twelve child harm categories using diverse child user models that engage in conversations with LLMs to ensure high-level of safety testing.