@article{cao2023stealthy,
  title={Stealthy and persistent unalignment on large language models via backdoor injections},
  author={Cao, Yuanpu and Cao, Bochuan and Chen, Jinghui},
  journal={arXiv preprint arXiv:2312.00027},
  year={2023}
}

@article{chen2023towards,
  title={Towards Imperceptible Document Manipulations against Neural Ranking Models},
  author={Chen, Xuanang and He, Ben and Ye, Zheng and Sun, Le and Sun, Yingfei},
  journal={arXiv preprint arXiv:2305.01860},
  year={2023}
}

@misc{chen2025flipedragblackboxopinionmanipulation,
      title={FlipedRAG: Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models}, 
      author={Zhuo Chen and Yuyang Gong and Miaokun Chen and Haotan Liu and Qikai Cheng and Fan Zhang and Wei Lu and Xiaozhong Liu and Jiawei Liu},
      year={2025},
      eprint={2501.02968},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2501.02968}, 
}

@article{cho2024typos,
  title={Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations},
  author={Cho, Sukmin and Jeong, Soyeong and Seo, Jeongyeon and Hwang, Taeho and Park, Jong C},
  journal={arXiv preprint arXiv:2404.13948},
  year={2024}
}

@inproceedings{deng2024masterkey,
  title={Masterkey: Automated jailbreaking of large language model chatbots},
  author={Deng, Gelei and Liu, Yi and Li, Yuekang and Wang, Kailong and Zhang, Ying and Li, Zefeng and Wang, Haoyu and Zhang, Tianwei and Liu, Yang},
  booktitle={Proc. ISOC NDSS},
  year={2024}
}

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}

@inproceedings{goren2018ranking,
  title={Ranking robustness under adversarial document manipulations},
  author={Goren, Gregory and Kurland, Oren and Tennenholtz, Moshe and Raiber, Fiana},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={395--404},
  year={2018}
}

@inproceedings{greshake2023not,
  title={Not what you've signed up for: Compromising real-world llm-integrated applications with indirect prompt injection},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  booktitle={Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
  pages={79--90},
  year={2023}
}

@inproceedings{gyongyi2005web,
  title={Web spam taxonomy},
  author={Gyongyi, Zoltan and Garcia-Molina, Hector},
  booktitle={First international workshop on adversarial information retrieval on the web (AIRWeb 2005)},
  year={2005}
}

@article{kandpal2023backdoor,
  title={Backdoor attacks for in-context learning with language models},
  author={Kandpal, Nikhil and Jagielski, Matthew and Tram{\`e}r, Florian and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2307.14692},
  year={2023}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{li2023multi,
  title={Multi-step jailbreaking privacy attacks on chatgpt},
  author={Li, Haoran and Guo, Dadi and Fan, Wei and Xu, Mingshi and Huang, Jie and Meng, Fanpu and Song, Yangqiu},
  journal={arXiv preprint arXiv:2304.05197},
  year={2023}
}

@article{lin2024figure,
  title={Figure it Out: Analyzing-based Jailbreak Attack on Large Language Models},
  author={Lin, Shi and Li, Rongchang and Wang, Xun and Lin, Changting and Xing, Wenpeng and Han, Meng},
  journal={arXiv preprint arXiv:2407.16205},
  year={2024}
}

@inproceedings{liu2022order,
  title={Order-disorder: Imitation adversarial attacks for black-box neural ranking models},
  author={Liu, Jiawei and Kang, Yangyang and Tang, Di and Song, Kaisong and Sun, Changlong and Wang, Xiaofeng and Lu, Wei and Liu, Xiaozhong},
  booktitle={Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
  pages={2025--2039},
  year={2022}
}

@inproceedings{liu2023black,
  title={Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method},
  author={Liu, Yu-An and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages={1647--1656},
  year={2023}
}

@article{liu2023prompt,
  title={Prompt injection attacks and defenses in llm-integrated applications},
  author={Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2310.12815},
  year={2023}
}

@inproceedings{liu2023topic,
  title={Topic-oriented adversarial attacks against black-box neural ranking models},
  author={Liu, Yu-An and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1700--1709},
  year={2023}
}

@inproceedings{liu2023webglm,
  title={WebGLM: Towards an efficient web-enhanced question answering system with human preferences},
  author={Liu, Xiao and Lai, Hanyu and Yu, Hao and Xu, Yifan and Zeng, Aohan and Du, Zhengxiao and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={4549--4560},
  year={2023}
}

@inproceedings{liu2024multi,
  title={Multi-granular Adversarial Attacks against Black-box Neural Ranking Models},
  author={Liu, Yu-An and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Fan, Yixing and Cheng, Xueqi},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1391--1400},
  year={2024}
}

@article{lu2024test,
  title={Test-time backdoor attacks on multimodal large language models},
  author={Lu, Dong and Pang, Tianyu and Du, Chao and Liu, Qian and Yang, Xianjun and Lin, Min},
  journal={arXiv preprint arXiv:2402.08577},
  year={2024}
}

@article{perez2022ignore,
  title={Ignore previous prompt: Attack techniques for language models},
  author={Perez, F{\'a}bio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2211.09527},
  year={2022}
}

@article{raval2020one,
  title={One word at a time: adversarial attacks on retrieval models},
  author={Raval, Nisarg and Verma, Manisha},
  journal={arXiv preprint arXiv:2008.02197},
  year={2020}
}

@article{shafran2024machine,
  title={Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents},
  author={Shafran, Avital and Schuster, Roei and Shmatikov, Vitaly},
  journal={arXiv preprint arXiv:2406.05870},
  year={2024}
}

@article{shi2025know,
  title={Know where to go: Make LLM a relevant, responsible, and trustworthy searchers},
  author={Shi, Xiang and Liu, Jiawei and Liu, Yinpeng and Cheng, Qikai and Lu, Wei},
  journal={Decision Support Systems},
  volume={188},
  pages={114354},
  year={2025},
  publisher={Elsevier}
}

@article{siyue2024mrag,
  title={MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering},
  author={Siyue, Zhang and Yuxiang, Xue and Yiming, Zhang and Xiaobao, Wu and Tuan, Luu Anh and Chen, Zhao},
  journal={arXiv preprint arXiv:2412.15540},
  year={2024}
}

@article{song2020adversarial,
  title={Adversarial semantic collisions},
  author={Song, Congzheng and Rush, Alexander M and Shmatikov, Vitaly},
  journal={arXiv preprint arXiv:2011.04743},
  year={2020}
}

@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wu2023prada,
  title={Prada: Practical black-box adversarial attacks against neural ranking models},
  author={Wu, Chen and Zhang, Ruqing and Guo, Jiafeng and De Rijke, Maarten and Fan, Yixing and Cheng, Xueqi},
  journal={ACM Transactions on Information Systems},
  volume={41},
  number={4},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY}
}

@article{wu2024retrieval,
  title={Retrieval-augmented generation for natural language processing: A survey},
  author={Wu, Shangyu and Xiong, Ying and Cui, Yufei and Wu, Haolun and Chen, Can and Yuan, Ye and Huang, Lianming and Liu, Xue and Kuo, Tei-Wei and Guan, Nan and others},
  journal={arXiv preprint arXiv:2407.13193},
  year={2024}
}

@article{xue2024badrag,
  title={BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models},
  author={Xue, Jiaqi and Zheng, Mengxin and Hu, Yebowen and Liu, Fei and Chen, Xun and Lou, Qian},
  journal={arXiv preprint arXiv:2406.00083},
  year={2024}
}

@article{zhang2024hijackrag,
  title={HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models},
  author={Zhang, Yucheng and Li, Qinfeng and Du, Tianyu and Zhang, Xuhong and Zhao, Xinkui and Feng, Zhengwen and Yin, Jianwei},
  journal={arXiv preprint arXiv:2410.22832},
  year={2024}
}

@article{zhong2023poisoning,
  title={Poisoning retrieval corpora by injecting adversarial passages},
  author={Zhong, Zexuan and Huang, Ziqing and Wettig, Alexander and Chen, Danqi},
  journal={arXiv preprint arXiv:2310.19156},
  year={2023}
}

@article{zou2024poisonedrag,
  title={Poisonedrag: Knowledge corruption attacks to retrieval-augmented generation of large language models},
  author={Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan},
  journal={arXiv preprint arXiv:2402.07867},
  year={2024}
}

