\section{Experimental Results Analysis}




\subsection{RQ1: Can our method significantly enhance the rankings of target documents in the RAG retriever for topic-queries?}

To explore RQ1, we first conducted white-box IR manipulation experiments on  MS MARCO and PROCON datasets. The results of these experiments are presented in Table~\ref{tab:ms_ir_attack_results} and Table~\ref{tab:IR_attck_opinion}, respectively.

\textbf{MS MARCO Dataset Validation.}
The results demonstrate that Topic-FlipRAG significantly outperforms all other baselines across all evaluation metrics, even under challenging conditions where the MS MARCO dataset was configured with reduced internal similarity among topic-queries to simulate more extreme scenarios. On this dataset (Table~\ref{tab:ms_ir_attack_results}), Topic-FlipRAG achieves an almost perfect Retrieval Attack Success Rate (RASR) of 99.29\%, substantially higher than Poisoned-RAG (64.39\%), Collision (93.19\%), and PAT (89.63\%). Furthermore, it achieves the highest B-rank (521.30) and superior coverage of top-ranked documents, with 18.35\% for top-50\% and 79.49\% for top-500\% metrics. These results highlight Topic-FlipRAG's ability to effectively manipulate rankings across the entire topic-queries set, achieving significant ranking enhancements for each query while simultaneously targeting multiple queries with high success rates.

\begin{table}[t]
  \centering
  \caption{White-box IR attack performance (RASR, Top-50, and Top-500 are reported in \%) on MS MARCO dataset. \textit{Bold} indicates the best attack performance.}
  \resizebox{0.45\textwidth}{!}{
    \begin{tabular}{lcccc}
    \toprule
    Method & RASR & B-rank & Top-50 & Top-500 \\
    \midrule
    Collision & 93.19 & 245.19 & 0.46 & 40.56 \\
    PAT & 89.63 & 208.06 & 0.31 & 33.90 \\
    PoisonedRAG & 64.39 & 73.52 & 2.94 & 11.15 \\
    \textbf{Topic-FlipRAG} & \textbf{99.29} & \textbf{521.30} & \textbf{18.35} & \textbf{79.49} \\
    \bottomrule
    \end{tabular}
  \label{tab:ms_ir_attack_results}
  }
\end{table}

\begin{table*}[!t]
  \centering
  \caption{White-box and Black-box IR attack results (\%) on PROCON dataset. \textit{Bold} indicates the best attack performance.}
  \resizebox{0.7\textwidth}{!}{
    \begin{tabular}{cccccccccc}
    \toprule
    \multicolumn{2}{c}{\textbf{Setting}} & \multicolumn{2}{c}{\textbf{White-box}} & \multicolumn{6}{c}{\textbf{Black-box}} \\
    \cmidrule(r){1-2}\cmidrule(r){3-4}\cmidrule(r){5-10}
    \textbf{Target IR model} & \multirow{2}[4]{*}{\textbf{Target Stance}} & \multicolumn{2}{c}{\textbf{BERT}} & \multicolumn{2}{c}{\textbf{Contriever}} & \multicolumn{2}{c}{\textbf{ANCE}} & \multicolumn{2}{c}{\textbf{DPR}} \\
    \cmidrule(r){1-1}\cmidrule(r){3-4}\cmidrule(r){5-10} 
    \textbf{Method} &       & \textbf{RASR} & \textbf{top3-v} & \textbf{RASR} & \textbf{top3-v} & \textbf{RASR} & \textbf{top3-v} & \textbf{RASR} & \textbf{top3-v} \\
    \midrule
    \multirow{2}[2]{*}{Collision} & CON   & 48.44 & 23.23 & 21.27 & 8.38 & 18.79 & 10.41 & 16.87 & 5.97 \\
          & PRO   & 43.64 & 20.85 & 21.44 & 8.24 & 15.97 & 7.73 & 14.49 & 5.23 \\
    \midrule
    \multirow{2}[2]{*}{PAT} & CON   & 37.85 & 17.23 & 16.40 & 7.15 & 19.51 & 12.36 & 13.99 & 5.65 \\
          & PRO   & 31.99 & 13.35 & 13.07 & 4.30 & 13.44 & 9.14 & 8.61 & 2.26 \\
    \midrule
    \multirow{2}[2]{*}{PoisonedRAG} & CON   & 39.87 & 18.64 & 25.52 & 11.99 & 34.10 & 14.91 & 31.25 & 14.13 \\
          & PRO   & 32.75 & 14.04 & 22.04 & 8.71 & 25.37 & 9.81 & 21.26 & 8.31 \\
    \midrule
    \multirow{2}[2]{*}{Topic-FlipRAG} & CON   & \textbf{79.42} & \textbf{44.71} & \textbf{51.90} & \textbf{25.57} & \textbf{45.69} & \textbf{20.12} & \textbf{42.27} & \textbf{18.83} \\
          & PRO   & \textbf{75.01} & \textbf{37.04} & \textbf{49.20} & \textbf{21.55} & \textbf{42.12} & \textbf{20.57} & \textbf{41.84} & \textbf{16.41} \\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:IR_attck_opinion}
\end{table*}

\textbf{PROCON Dataset Validation.}
On the PROCON dataset (Table~\ref{tab:IR_attck_opinion}), the results strongly confirm the superiority of Topic-FlipRAG. \textbf{In the white-box setting}, for both target stances (CON and PRO), Topic-FlipRAG achieves the highest RASR (0.79 for CON, 0.75 for PRO) and the largest top3-v (0.45 for CON, 0.37 for PRO). In contrast, Poisoned-RAG, which uses a simple query+ strategy, shows considerably lower effectiveness (RASR: 0.40 for CON, 0.33 for PRO), illustrating the limitations of its approach for topic-oriented attacks. While the gradient-based methods Collision and PAT match or exceed Poisoned-RAG in opinion manipulation, they still trail Topic-FlipRAG. This outcome highlights Topic-FlipRAG’s ability to conduct effective manipulation across entire sets of topic-queries.

To further evaluate our method’s practical effectiveness, we conducted \textbf{black-box IR manipulation} experiments on the PROCON dataset using three widely adopted dense retrievers (Contriever, ANCE, DPR). Owing to the inherent robustness of these retrievers, performance declined for all attack methods compared to the white-box setting. Nevertheless, Topic-FlipRAG displays the most consistent performance, retaining relatively high manipulation effectiveness across all models and metrics. For instance, under Contriever, Topic-FlipRAG achieves the highest RASR (0.52 for CON, 0.49 for PRO) and top3-v (0.26 for CON, 0.22 for PRO), notably outperforming Poisoned-RAG, Collision, and PAT. A similar pattern emerges for ANCE and DPR, where Topic-FlipRAG continues to hold a clear advantage.

Topic-FlipRAG's superior performance in transfer attack settings can be attributed to its integration of the LLM’s general semantic knowledge and NRM gradient guidance, along with a design specifically tailored for the topic-queries context. This combination enables the method to generate adversarial triggers that are both generalizable and contextually precise, allowing it to adapt effectively to varying retriever architectures without relying on the target IR model’s parameters. In contrast, gradient-based methods like Collision and PAT depend heavily on gradient information from the target model, leading to substantial performance degradation in transfer attack scenarios. For instance, Collision achieves a maximum RASR of only 0.21 on Contriever for both CON and PRO stances, while PAT performs even worse, with RASR values of 0.16 (CON) and 0.13 (PRO).

Additionally, our findings reveal varying levels of vulnerability among dense retrievers. Contriever appears the most susceptible (exhibiting higher RASR and top3-v scores for all attackers), whereas DPR is notably more resilient (e.g., RASR for Topic-FlipRAG falls to 0.42). These observations underscore the importance of careful retriever selection when designing RAG systems to mitigate adversarial risks.

\begin{table*}[htbp]
  \centering
  \caption{Topic-Oriented RAG attack results on PROCON dataset, including ASV on different domains (Health \& Environment, Government \& Politics, Education, and Society \& Culture), average ASV, and $\Delta$ASV. \textit{Bold} shows the best performances.}
    \resizebox{0.9\textwidth}{!}{
    \begin{tabular}{cccccccccccccc}
    \toprule
    \multirow{2}[4]{*}{\textbf{Method}} & \multirow{2}[4]{*}{\textbf{Target Stance}} & \multicolumn{5}{c}{\textbf{Contriever + qwen-2.5-8B-instruct}} &       & \multicolumn{5}{c}{\textbf{Contriever + llama3.1-8B-instruct}} &  \\
\cmidrule(r){3-8}\cmidrule(r){9-14}          &       & \textbf{H\&E} & \textbf{G\&P} & \textbf{EDU} & \textbf{S\&C} & \textbf{avg. ASV} & \textbf{$\Delta$ ASV} & \textbf{H\&E} & \textbf{G\&P} & \textbf{EDU} & \textbf{S\&C} & \textbf{avg. ASV} & \textbf{$\Delta$ ASV} \\
    \midrule
    \multirow{2}[2]{*}{Clean} & CON   & 0.21  & 0.27  & 0.24  & 0.23  & 0.24  & --    & 0.22  & 0.26  & 0.18  & 0.27  & 0.24  & -- \\
          & PRO   & 0.21  & 0.26  & 0.24  & 0.24  & 0.24  & --    & 0.23  & 0.27  & 0.21  & 0.27  & 0.25  & -- \\
    \midrule
    \multirow{2}[2]{*}{Collision} & CON   & 0.30  & 0.36  & 0.35  & 0.34  & 0.34  & 0.10  & 0.30  & 0.35  & 0.23  & 0.27  & 0.30  & 0.06  \\
          & PRO   & 0.27  & 0.40  & 0.30  & 0.28  & 0.32  & 0.08  & 0.29  & 0.37  & 0.24  & 0.28  & 0.31  & 0.06  \\
    \midrule
    \multirow{2}[2]{*}{PAT} & CON   & 0.30  & 0.27  & 0.28  & 0.27  & 0.28  & 0.04  & 0.26  & 0.35  & 0.25  & 0.32  & 0.30  & 0.06  \\
          & PRO   & 0.29  & 0.25  & 0.31  & 0.33  & 0.29  & 0.05  & 0.28  & 0.30  & 0.30  & 0.30  & 0.29  & 0.04  \\
    \midrule
    \multirow{2}[2]{*}{PoisonedRAG} & CON   & 0.30  & 0.35  & 0.26  & 0.38  & 0.33  & 0.09  & 0.34  & 0.39  & 0.31  & 0.46  & 0.38  & 0.14  \\
          & PRO   & 0.27  & 0.41  & 0.28  & 0.32  & 0.34  & 0.10  & 0.31  & 0.38  & 0.29  & 0.39  & 0.35  & 0.10  \\
    \midrule
    \multirow{2}[2]{*}{Topic-FlipRAG} & CON   & \textbf{0.51 } & \textbf{0.46 } & \textbf{0.48 } & \textbf{0.55 } & \textbf{0.49 } & \textbf{0.25 } & \textbf{0.54 } & \textbf{0.51 } & \textbf{0.30 } & \textbf{0.64 } & \textbf{0.50 } & \textbf{0.26 } \\
          & PRO   & \textbf{0.43 } & \textbf{0.55 } & \textbf{0.42 } & \textbf{0.51 } & \textbf{0.49 } & \textbf{0.25 } & \textbf{0.44 } & \textbf{0.58 } & \textbf{0.41 } & \textbf{0.44 } & \textbf{0.48 } & \textbf{0.24 } \\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:rag-procon}%
\end{table*}%


\subsection{RQ2: To what extent does Topic-FlipRAG affect the answers
generated by the target RAG systems?}

\begin{figure*}
  \centering
  \vspace{-70pt}  \includegraphics[width=0.95\textwidth]{figs/case-study.pdf}
  \caption{Case study of Topic-oriented Opinion Manipulation On Topic: "Is Binge-Watching Good for You?"}
  \label{case-study}
  \vspace{10pt}
\end{figure*}

Table~\ref{tab:rag-procon} presents the results of different methods on RAG output opinion manipulation, comparing the performance of two retrieval-augmented generation (RAG) systems: contriever + qwen-2.5-8B-instruct and contriever + llama3.1-8B-instruct. Additionally, experiments were conducted using alternative retrievers such as ANCE and DPR, with results provided in Table\ref{tab:rag-ance} and Table \ref{tab:rag-dpr} (in Appendix). 

To evaluate the manipulation effectiveness across different topic domains, the PROCON dataset was divided into four subsets: Health \& Environment (H\&E), Government \& Politics (G\&P), Education (EDU), and Society \& Culture (S\&C). Each reported avg-ASV reflects the average manipulated stance polarity (PRO or CON) of the RAG outputs across all domains, while avg-$\Delta$-ASV represents the manipulation effect, computed by subtracting the clean-state avg-ASV (\textsubscript{clean}) from the manipulated avg-ASV. Both ASV and $\Delta$-ASV range from 0 to 2, where higher values indicate stronger manipulation effects.

The results demonstrate that \textbf{Topic-FlipRAG achieves significantly better manipulation across all domains compared to baseline methods, including PoisonedRAG}. Specifically, Topic-FlipRAG achieves an avg-ASV of 0.49 for qwen-2.5 and 0.48 for llama3.1, outperforming all other methods. PoisonedRAG, the second most effective method, achieves avg-ASV values of 0.33 for qwen-2.5 and 0.35 for llama3.1, while other baselines such as Collision and PAT remain within the range of 0.28–0.31. In terms of manipulation effect, measured by avg-$\Delta$-ASV, Topic-FlipRAG also achieves the highest values: 0.26 for qwen-2.5 and 0.24 for llama3.1. These results highlight the robust manipulation capability of Topic-FlipRAG, surpassing both direct adversarial document injection methods like PoisonedRAG (0.09 for qwen-2.5 and 0.10 for llama3.1) and stance-optimization methods such as  and PAT (0.06 for both LLMs).

Table~\ref{tab:rag-procon} and the appendix results further reveal notable differences between LLMs and retrievers regarding susceptibility to topic-oriented opinion manipulation. Overall, llama3.1 exhibits higher avg-ASV and avg-$\Delta$-ASV across all baseline methods compared to qwen-2.5, indicating that llama3.1 is more vulnerable to adversarial documents promoted to the top-3 of the ranking. This suggests that llama3.1 tends to generate responses that are more aligned with adversarial stances in the context. Similarly, among retrievers, contriever-based RAG systems achieve higher avg-$\Delta$-ASV values compared to ANCE and DPR, as detailed in the appendix, aligning with RQ1 findings that contriever produces superior ranking distortion, particularly for top-3 results.

The manipulation effectiveness of Topic-FlipRAG also varies across different topic domains. For instance, for llama3.1, Society \& Culture (S\&C) questions are the most susceptible to opposing stance manipulation (avg-ASV = 0.55), while Education (EDU) questions are relatively resistant (avg-ASV = 0.41). Health \& Environment (H\&E) questions demonstrate greater difficulty in manipulating supporting stances (PRO) compared to opposing stances (CON). Both qwen-2.5 and llama3.1 display higher avg-ASV values for supporting stance manipulation in Government \& Politics (G\&P), while Education (EDU) emerges as the most challenging domain for stance manipulation across both LLMs.



In order to illustrate the manipulation results more vividly, we randomly selected the topic “Is Binge-Watching Good for You?” for a case study, with the findings presented in Figure~\ref{case-study}. As demonstrated by the distribution variation of RAG response opinions in the figure,, Topic-FlipRAG can manipulate RAG-generated content across multiple queries within the specific topic, shifting the overall opinion distribution to match a specified stance. Initially, responses on this topic span a mix of supportive, opposing, and neutral perspectives; following manipulation, the distribution becomes predominantly supportive when the target stance is “Pro” (blue) or predominantly opposing when the target stance is “Con” (red).


Figure~\ref{case-study} further demonstrates Topic-FlipRAG’s impact on multiple sub-queries. For instance, in “Binge-watching: addictive or relaxing?”, the unmanipulated response presents a balanced view. However, once manipulated, it adopts a distinctly polarized stance—emphasizing the relaxing aspects under “Pro,” or highlighting detrimental, addictive effects under “Con.” Similarly, for “Opinions on binge-watching trends?”, the original responses encompass diverse perspectives, whereas the manipulated version exhibits a consistent bias aligned with the designated stance. These examples underscore Topic-FlipRAG’s capacity to impose coherent opinion shifts across multiple queries under a single topic.


\subsection{RQ3: Does topic-oriented opinion manipulation significantly impact users’ perceptions of controversial topics?}

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.43\textwidth]{figs/user-experiment.pdf}
  \caption{Empirical comparative experiments of adversarial opinion manipulation attacks on user cognition.}
  \label{user_experiment}
\end{figure}
To explore the effect of opinion manipulation on users’ perceptions of controversial topics, we conducted a user study involving 54 college students (29 males, 25 females) to assess how opinion manipulation influences perceptions of controversial topics. Participants were split into two equal groups (Group-clean and Group-poisoned, 27 members each), remaining unaware of the study’s true purpose and operating independently. A simple QA service based on RAG was implemented, and Topic-FlipRAG was employed to poison documents with specific stances on two designated controversial topics. For one topic, supporting documents were poisoned; for the other, opposing documents were poisoned. Each participant interacted with the QA system over three rounds per topic, mirroring real-world usage patterns, and subsequently rated their stance on a 7-point Likert scale (normalized to 0 for strong opposition, 1 for strong support).

% case study of user

Figure~\ref{user_experiment} illustrates the significant shifts in user opinions resulting from Topic-FlipRAG. For Topic 1 (\textit{Should People Become Vegetarian?}), the manipulated stance was PRO. Group-clean exhibited a dispersed distribution with an average score of 0.45, reflecting diverse views on this controversial issue. By contrast, Group-poisoned recorded a notably higher mean score of 0.61, indicating successful manipulation toward pro-vegetarian sentiment. For Topic 2 (\textit{Should Humans Colonize Space?}), the stance was CON. Although Group-clean originally showed strong support (average score 0.76), Group-poisoned achieved a reduction to 0.59, effectively nudging opinions toward neutrality.

These findings underscore the potency of Topic-FlipRAG in altering user perceptions via RAG, whether opinions are initially neutral or polarized. The consistent polarity shifts across both topics reveal the potential risks posed by adversarial attacks in shaping public discourse on contentious issues.

\begin{table}[t]
  \centering
  \caption{Ablation study (top3-ori, top3-att, and top3-v are reported in \%) on the PROCON dataset. w/o denotes ``without''.}
  \resizebox{0.49\textwidth}{!}{
    \begin{tabular}{cccccccc}
    \toprule
    \multirow{2}[2]{*}{Method} & \multicolumn{3}{c}{IR} & \multicolumn{2}{c}{Llama3.1} & \multicolumn{2}{c}{Qwen2.5} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8}
          & top3-ori & top3-att & top3-v & ASV & $\Delta$ ASV & ASV & $\Delta$ ASV \\
    \midrule
    Topic-FlipRAG & 42.83  & 70.24  & 27.41  & 0.64  & 0.37  & 0.55  & 0.32  \\
    w/o adv-trigger & 42.83  & 51.12  & 8.29  & 0.37  & 0.10  & 0.38  & 0.15  \\
    w/o know-attack & 42.83  & 59.40  & 16.57  & 0.40  & 0.12  & 0.41  & 0.18  \\
    clean & --    & --    & --    & 0.27  & --    & 0.23  & --    \\
    \bottomrule
    \end{tabular}%
  }
  \label{tab:ablation_study_component}
\end{table}

\subsection{Ablation Study}
\textbf{Effectiveness of Core Components of Topic-FlipRAG.} We investigated the individual contributions of the two main components of Topic-FlipRAG: know-attack and adversarial trigger generation (referred to as adv-trigger). As shown in Table~\ref{tab:ablation_study_component}, both components play significant roles in achieving the overall attack effectiveness, albeit with varying impacts on different aspects of the task.

Adv-trigger and know-attack complement each other by leveraging distinct strengths to enhance the overall effectiveness of the Topic-FlipRAG framework. Adv-trigger, through its gradient-based generation process, directly optimizes the retriever mechanism, resulting in significant ranking improvements for adversarially targeted documents. In contrast, know-attack, while less impactful on ranking optimization, utilizes general semantic knowledge to achieve precise and consistent polarity manipulation in LLM outputs, reinforcing the adversarial influence on generated responses. This synergy allows for more comprehensive and precise control over the RAG framework's behavior, thereby maximizing the overall efficacy of the attack strategy.


\textbf{Impact of Rewarding Function in Topic-FlipRAG.} The rewarding function in Topic-FlipRAG dynamically adjusts the augment factor \(t\) in the know-attack process (as described in Algorithm \ref{alg:topic-rag}), controlling the aggressiveness of edits in each iteration. By leveraging semantic similarity and edit distance filtering, the rewarding function ensures an adaptive improvement strategy, enhancing the overall performance.

As shown in Table~\ref{tab:reward-IR}, the rewarding function significantly impacts the effectiveness of know-attack in IR manipulation. Compared to fixed augment factor \(t\) values, the dynamic adjustment achieves higher attack breadth (evidenced by increased RASR) and depth (higher top3-v scores). Table~\ref{tab:reward-RAG} further highlights its influence on RAG opinion manipulation, where the dynamic approach yields higher ASV and \(\Delta\) ASV compared to fixed \(t\) settings. Notably, the rewarding function's influence on RAG output polarity manipulation surpasses its impact on IR manipulation. This can be attributed to its role in improving the quality of generated $\text{doc}_{\text{know}}$, where quality encompasses both enhanced ranking boosts (related to IR manipulation) and stronger polarity reinforcement. These findings underscore the rewarding function's critical contribution to optimizing the know-attack strategy for both ranking and opinion manipulation objectives.



\begin{table}[!t]
  \centering
  \caption{Comparative analyses of rewarding function and fixed augment factor $t$ on IR manipulation attacks (\%).}
  \resizebox{0.4\textwidth}{!}{
    \begin{tabular}{cccccc}
    \toprule

          & RASR & top3-ori & top3-att & top3-v \\
    \midrule
    know-attack & 22.25  & 42.83  & 52.12  & 8.29\\
    t=1     & 17.42  & 42.83  & 49.28  & 6.45 \\
    t=2     & 16.83  & 42.83  & 49.73  & 6.89 \\
    t=3     & 18.54  & 42.83  & 49.02  & 6.18 \\
    \bottomrule
    \end{tabular}%
  }
  \label{tab:reward-IR}
\end{table}

\begin{table}[t]
  \centering
  \caption{Comparative analyses of rewarding function and fixed augment factor $t$ on RAG opinion manipulation.}
  \resizebox{0.3\textwidth}{!}{
    \begin{tabular}{lcccc}
    \toprule
    Setting & Topic-FlipRAG & t=1 & t=2 & t=3 \\
    \midrule
      ASV& 0.64 & 0.58 & 0.56 & 0.59 \\
    $\Delta$ ASV & 0.37 & 0.31 & 0.29 & 0.32 \\
    \bottomrule
    \end{tabular}%
  }
  \label{tab:reward-RAG}
\end{table}

\textbf{Impact of Polarity Control in Topic-FlipRAG.}
Figure~\ref{sentiment-know} illustrates the effect of the Polarity Control component on the sentiment of adversarial documents (\(\text{doc}_{\text{adv}}\)) when the target polarity is set to CON. Negative sentiment scores represent negative polarity, while positive scores indicate positive polarity. (For PRO, see Figure~\ref{sentiment-know-1} in the Appendix.) The results show that, without Polarity Control, \(\text{doc}_{\text{adv}}\) gravitates toward a neutral polarity. With Polarity Control enabled, Topic-FlipRAG effectively aligns \(\text{doc}_{\text{adv}}\) with the desired target polarity (CON).To further investigate the influence of attacks on document sentiment, we present measurement results in Figure~\ref{baseline-sentiment-0} and Figure~\ref{baseline-sentiment-1} in the Appendix.


To further investigate how Polarity Control influences RAG opinion manipulation, we examine not only the sentiment but also the stance of \(\text{doc}_{\text{adv}}\) (i.e., its degree of alignment with the target polarity). For both PRO and CON settings, we randomly selected five topics and measured stance (normalized from \(-1\) to \(1\), where \(-1\) signifies strong opposition and \(1\) signifies strong support). As shown in Figure~\ref{ablation-stance} (in the Appendix), without Polarity Control, the stance of \(\text{doc}_{\text{adv}}\) shifts closer to neutrality, weakening its polarity. In contrast, incorporating Polarity Control preserves stance, enabling more effective manipulation of the LLM’s final outputs.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.42\textwidth]{figs/0-ablation-sentiment.pdf}
  \caption{Impact of Polarity Control module on documents sentiment. w/o denotes ``without''. (target polarity:CON). }
  \label{sentiment-know}
\end{figure}


% how 
The notable deviation in \(\text{doc}_{\text{adv}}\) polarity without Polarity Control arises from the nature of know-attack: while it leverages the internal knowledge and reasoning capabilities of LLMs, it also inherits inherent polarity biases. Absent strict polarity enforcement during each editing step, the generated \(\text{doc}_{\text{adv}}\) tends to drift from the intended polarity. By enforcing the desired polarity at every phase of know-attack, the Polarity Control component supports a more consistent and effective manipulation of RAG polarity outcomes.


\begin{figure*}[!t]
  \centering
  \includegraphics[width=0.95\textwidth]{figs/ppl_defense.pdf}
  \vspace{0pt}
  \caption{ Log perplexity (PPL) distributions on the PROCON dataset.}
  \vspace{10pt}
  \label{ppl_defense}
\end{figure*}


\textbf{Potential Effectiveness by Altering Poisoning Target.} Table~\ref{tab:sample_methods} illustrates the impact of different poisoned methods on IR and RAG manipulation results. In our prior experiments, we selected the least relevant five documents (last5) as the poisoning targets to evaluate Topic-FlipRAG’s performance in a challenging manipulation scenario. This design aimed to test the robustness of the attack under more constrained conditions. However, in real-world attack scenarios, an attacker might reasonably choose the topically most relevant documents (top5) as poisoned targets to achieve more effective opinion manipulation.

The experimental results show that poisoning the top5 documents yields improved manipulation performance, as evidenced by higher top3-v and ASV scores. Specifically, poisoning the top5 documents achieves a top3-v score of 0.37 and an ASV score of 0.71, both surpassing the performance observed with the last5 method. This indicates that Topic-FlipedRAG could cause even greater harm if deployed in real-world scenarios, where attackers have the flexibility to select highly relevant documents as targets. These findings underscore the pressing need to develop robust defenses against such advanced adversarial strategies.

\begin{table}[t]
  \centering
  \caption{Performance comparison of poisoning target on the PROCON dataset.(top3-ori, top3-att, top3-v are reported in \%.)}
  \resizebox{0.47\textwidth}{!}{
    \begin{tabular}{ccccccc}
    \toprule
    \multirow{2}[2]{*}{Poisoning Target} & \multicolumn{3}{c}{IR} & \multicolumn{2}{c}{Llama3.1} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-6}
          & top3-ori & top3-att & top3-v & ASV & $\Delta$ ASV \\
    \midrule
    last5 & 42.63  & 70.24  & \textbf{27.61} & \textbf{0.64} & \textbf{0.37} \\
    top5  & 42.63  & 79.18  & \textbf{36.55} & \textbf{0.72} & \textbf{0.44} \\
    clean & --     & --     & --             & 0.27 & -- \\
    \bottomrule
    \end{tabular}%
  }
  \label{tab:sample_methods}
\end{table}



\subsection{RQ4: How robust does Topic-FlipRAG against exisiting mitigation mechanism?}
\textbf{Mitigation by perplexity.}
Perplexity (PPL) is widely used to measure the quality of texts, which is also utilized to defend against attacks to LLMs and IR model\cite{jain2023baseline,gonen2022demystifying,liu2022order}. A large perplexity of a text means it is of low quality. We utilize perplexity to detect malicious texts.

Figure~\ref{ppl_defense} shows the log perplexity (PPL) distributions evaluated using GPT-2~\cite{radford2019language} on PROCON dataset documents manipulated by various attack methods. The results reveal the limitations of perplexity-based defenses in distinguishing poisoned documents from clean ones, as significant overlaps in PPL distributions persist. This overlap makes it difficult to set effective thresholds: strict thresholds lead to high false positive rates, while loose thresholds fail to detect attacks, undermining the defense's efficacy.

Specifically,Collision exhibits the largest deviation in PPL distribution, making it relatively easier to detect. In contrast, Topic-FlipRAG and PAT produce poisoned documents with distributions closely resembling the original dataset, posing significant challenges for detection. PoisonedRAG, which lacks gradient-guided optimization, shows almost no shift in PPL, further highlighting the insufficiency of perplexity-based filtering for nuanced manipulations.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.45\textwidth]{figs/random_mask.pdf}
  \caption{Attack performance of different random mask rate.}
  \label{random_mask}
\end{figure}



\textbf{Mitigation by Random Mask.} Random Mask is a robustness enhancement method that randomly masks a proportion of tokens with a placeholder token $m$ during embedding~\cite{zeng2023certified}. By averaging predictions over multiple masked input versions, it reduces sensitivity to small perturbations and enhances model stability. In our implementation, we averaged outputs over three masked copies of each input to assess performance under varying mask rates.



Figure~\ref{random_mask} presents experimental results on the PROCON-Dataset targeting the CON stance. When the mask rate is below 0.3, Topic-FlipRAG achieves notably higher manipulation metrics (RASR~>~55\%, top3-v~>~20\%) compared to other baselines, underscoring its robust manipulation capability. As the mask rate increases, the effectiveness of all methods declines; however, Topic-FlipRAG still maintains the highest attack success among the baselines. Nonetheless, excessively large mask rates also degrade normal RAG performance, revealing the trade-off between heightened defense and overall system functionality. Consequently, Random Mask alone is insufficient against sophisticated attacks like Topic-FlipRAG, indicating that additional measures are required to strengthen system robustness without undermining functionality.

\textbf{Mitigation by reranking.} We investigate a reranking mechanism within the RAG framework to defend against adversarial attacks. This approach uses a different IR model to refine and reorder initial retrieval results, thus diminishing attack efficacy. The defense rationale is twofold: (1) existing attacks typically rely on simulating the target IR model~\cite{cho2024typos,liu2022order,liu2024multi}, and introducing a distinct reranker weakens this dependency; (2) varying IR models exhibit different robustness levels, and reranking adds resilience. 

We tested this method on the PROCON-Dataset with the stance CON, using Contriever for retrieval and DPR for reranking. As illustrated in Figure~\ref{rerank}, most adversarial methods show a slight decline in manipulation effectiveness under reranking, except for PoisonedRAG, which is less sensitive due to its simpler query-plus strategy. In contrast, Collision, PAT, and Topic-FlipRAG depend on gradient information from open-sourced IR models, leading to varied transferability when attacking a different black-box IR pipeline. Despite the overall decrease in attack performance, Topic-FlipRAG maintains a relatively high success rate, demonstrating that reranking alone offers only partial defense against sophisticated adversarial techniques.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.45\textwidth]{figs/rerank.pdf}
  \caption{Comparative analysis of the performance metrics (RASR and top3-v) across different baselines before and after reranking mitigation.}
  \label{rerank}
\end{figure}
