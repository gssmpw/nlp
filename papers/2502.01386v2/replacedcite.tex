\section{Background and Related Work}
\subsection{Retrieval Augmented Generation (RAG)}
RAG models enhance their responses by accessing and incorporating external knowledge from large-scale databases or corpora during the generation process ____. By leveraging external data sources, RAG can provide more accurate and comprehensive answers, especially for queries requiring up-to-date information or specialized knowledge that may not be well-represented in the model's training data ____. Moreover, it can scale more effectively and flexibly by updating the retrieval corpus without necessitating extensive retraining of the generative component ____.


The workflow of a RAG systems is generally divided into two sequential phases: \textit{retrieval} and \textit{generation}. 
In the retrieval phase, upon the submission of a user query $q$, the RAG system retrieves $k$ relevant documents from the corpus $D$ with the highest embedding similarities to the query $q$. Specifically, for each document $d \in D$, the relevance score with the query $q$ is computed as $R(q, d)$. In this paper, we adopt the a more practical and widely used framework in LangChain that the retrieval phase is incorporated with historical-aware query rewriting and intention reasoning. 
In the generation phase, Given a the rewritten query $q'$ , a set of top-k retrieved documents $D_k$, and access to the LLM, one can query the LLM with $q'$ with the top-k retrieved documents $D_k$, the LLM generates an answer for original query $q$ by leveraging $D_k$ as context. This process is detailed in Appendix \ref{exp-detail}.

\subsection{Attacks to Retriever}

Retriever vulnerabilities in RAG systems pose significant security risks due to their neural ranking dependencies ____. Adversarial attacks manipulate document rankings through semantic perturbations to promote target documents in query-specific results ____, undermining RAG's core assumption of reliable high-ranked contexts.
Current attacks are characterized along two axes: (1) Knowledge accessibility: White-box (full model access) vs. black-box (query-only) approaches. (2) Perturbation granularity: Word-level ____, Phrase-level ____, Sentence-level ____, and Hybrid ____.These neural semantic attacks parallel black-hat SEO tactics ____ but introduce novel challenges. Successful attacks propagate adversarial content to generators, enabling misinformation injection while evading traditional safeguards ____, necessitating integrated security frameworks for RAG systems.

\subsection{Attacks to LLMs}

Existing attacks on LLMs include jailbreak attacks ____, backdoor attacks ____, prompt injection ____, and poisoning attacks ____. Poisoning attacks uniquely threaten RAG systems by injecting adversarial content into retrieval corpora to manipulate outputs. Current RAG poisoning studies focus on closed-domain factoid QA pairs (e.g., "CEO of OpenAI") ____, overlooking the multi-query nature of real-world topic exploration____, e.g., "smartwatch battery life" and "health tracking accuracy" under the "wearable tech" theme. This motivates our focus on practical topic-level universal perturbations mirroring universal adversarial examples.

Furthermore, existing defenses based on fact-checking are insufficient for opinion-based queries, such as "Should genetic testing be regulated?", which require nuanced reasoning rather than simple factual recall. Building on the insights from FlipedRAG ____, we tackle this significant gap by examining the adversarial manipulation of controversial topics. In such cases, LLMs are required to reason and synthesize multiple perspectives, making them particularly vulnerable to systematic knowledge poisoning.