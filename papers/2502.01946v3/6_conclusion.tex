% \begin{figure}[!t]
%     \centering
%     \includegraphics[trim= 3.6cm 8.6cm 4cm 9.1cm, clip,width=0.8\linewidth]{figure/benchmark.pdf}
%     % \caption{Estimated odometry of Fast-LIO, 4DRadarSLAM and ORORA with the ground truth for \texttt{Sport complex}.}
%     % \label{fig:slam1}
%     \vspace{-3mm}
% \end{figure}

% \begin{figure}[!t]
%     \centering
%     \includegraphics[trim= 3.6cm 8.6cm 4cm 9.1cm, clip,width=0.8\linewidth]{figure/benchmark.pdf}
%     \caption{Estimated odometry of Fast-LIO, 4DRadarSLAM and ORORA with the ground truth.}
%     \label{fig:slam}
%     \vspace{-3mm}
% \end{figure}
%TABLE
%TABLE
\input{tab/PR_tab}
%TABLE

\begin{figure}[!t]
    \centering
    \includegraphics[trim= 3.9cm 0.8cm 5.7cm 1.8cm, clip,width=\linewidth]{figure/pr.pdf}
    \caption{Place recognition result for \texttt{Sports Complex}.}
    \label{fig:pr}
    \vspace{-3mm}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[trim= 3.9cm 0.8cm 5.7cm 1.8cm, clip,width=\linewidth]{figure/pr2.pdf}
    \caption{Place recognition result for \texttt{Library}.}
    \label{fig:pr2}
    \vspace{-5mm}
\end{figure}


\section{Conclusion}
\label{sec:conclusion}

The HeRCULES dataset is a comprehensive benchmark for \ac{SLAM} and sensor fusion research in autonomous driving, uniquely integrating a diverse sensor suite including 4D radar, spinning radar, \ac{FMCW} \ac{LiDAR}, \ac{IMU}, \ac{GPS}, and cameras. It is the first public dataset to combine 4D radar, spinning radar, and \ac{FMCW} \ac{LiDAR}, offering unique localization, mapping, and place recognition capabilities. Including both 4D radar and \ac{FMCW} \ac{LiDAR} supports diverse research in radar-\ac{LiDAR} fusion \ac{SLAM}, cross-sensor place recognition, and radar point upsampling. Covering diverse weather, lighting, and traffic conditions with sequences that revisit the same locations, the dataset is ideal for robust place recognition and \ac{SLAM} evaluation. Additionally, the HeRCULES dataset includes \ac{ROS}-compatible tools and ground truth pose data for each sensor, facilitating the development of advanced \ac{SLAM} and localization algorithms. Through benchmark evaluations for \ac{SLAM}, we identified the limitations of single radar \ac{SLAM} in various environments, underscoring the need for sensor fusion SLAM research. Additionally, benchmark evaluations for place recognition tasks highlighted the necessity for cross-sensor place recognition research. By offering rich, multi-modal data under varied conditions, HeRCULES sets a new standard for research in autonomous navigation, enabling the creation of next-generation perception systems.


% The HeRCULES dataset is a comprehensive benchmark for SLAM and sensor fusion research in autonomous driving. It includes 4D radar, spinning radar, FMCW LiDAR, IMU, GPS, and cameras. As the first public dataset to include both 4D radar and scanning radar, it offers unique localization, mapping, and place recognition capabilities. Its combination of 4D radar with FMCW LiDAR makes it particularly valuable for sensor fusion research, enabling the development of robust perception systems. The dataset covers a variety of weather, lighting, urban traffic conditions, and dynamic environments, allowing for a thorough evaluation of SLAM algorithms under challenging scenarios. With extensive-distance coverage and sequences designed for revisits, it supports effective place recognition and SLAM evaluation.

% Overall, the HeRCULES dataset fills a crucial gap by providing high-quality, multi-modal data under diverse conditions, pushing forward research in autonomous driving, particularly in challenging environments. Combining high-resolution spatial and velocity data from both radar and LiDAR sets a new benchmark for developing next-generation autonomous navigation systems.


%최초의 데이터셋이다가 첫 문장ㅇ으로 it 줄이기 이종센서





\newpage