\begin{abstract}

%\hl{WIP} Recently, radar has been increasingly utilized due to its robustness in conditions like fog, rain, and nighttime. Radars are categorized into spinning radar and phased-array radar based on their field of view and data dimensionality. 
Recently, radars have been widely featured in robotics for their robustness in challenging weather conditions. Two commonly used radar types are spinning radars and phased-array radars, each offering distinct sensor characteristics.
% spinning radars provide a wider \ac{FOV} and generate 2D data in a bird's-eye view (BEV) image format; the phased-array radars typically have a narrower forward-facing \ac{FOV} and produce data in a sparse point cloud format.
%Due to these differences, each type has distinct advantages that complement the other. However, existing datasets are typically limited to a single type of radar. 
Existing datasets typically feature only a single type of radar, leading to the development of algorithms limited to that specific kind. In this work, we highlight that combining different radar types offers complementary advantages, which can be leveraged through a heterogeneous radar dataset. Moreover, this new dataset fosters research in multi-session and multi-robot scenarios where robots are equipped with different types of radars.
In this context, we introduce the HeRCULES dataset, a comprehensive, multi-modal dataset with heterogeneous radars, \acs{FMCW} \acs{LiDAR}, \acs{IMU}, \acs{GPS}, and cameras. This is the first dataset to integrate 4D radar and spinning radar alongside \acs{FMCW} \acs{LiDAR}, offering unparalleled localization, mapping, and place recognition capabilities. The dataset covers diverse weather and lighting conditions and a range of urban traffic scenarios, enabling a comprehensive analysis across various environments. The sequence paths with multiple revisits and ground truth pose for each sensor enhance its suitability for place recognition research. We expect the HeRCULES dataset to facilitate odometry, mapping, place recognition, and sensor fusion research. The dataset and development tools are available at 
\href{https://sites.google.com/view/herculesdataset}{https://sites.google.com/view/herculesdataset}.

% Recently, the development of 4D radar and LiDAR sensors has gained momentum due to their ability to provide robust environmental perception in challenging conditions such as fog, rain, and night. However, existing datasets are typically limited to a single type of radar and primarily feature 3D spinning LiDAR, making direct comparisons between LiDAR and radar sensors difficult. In this context, we present the HeRCULES dataset, a comprehensive, multi-modal dataset featuring not only heterogeneous radars, including both 4D radar and spinning radar, but also FMCW LiDAR, IMU, GPS, and cameras. This dataset is the first to incorporate both 4D radar and scanning radar, alongside FMCW LiDAR, providing unparalleled capabilities for localization, mapping, and place recognition. The dataset encompasses various weather and lighting conditions and a range of urban traffic scenarios, ensuring a thorough analysis across different environments. The intentional design of sequence paths with multiple revisits enhances the suitability for place recognition research. With ROS tool support, the HeRCULES dataset provides a versatile resource for developing next-generation localization algorithms, advancing research in SLAM, and sensor fusion. The dataset is accessible
% at https://sites.google.com/view/herculesdataset.

 % We also propose a novel calibration method for radar and LiDAR sensors to improve their integration in multi-modal systems.
% \textcolor{green}{\lipsum[1]}
\end{abstract}
