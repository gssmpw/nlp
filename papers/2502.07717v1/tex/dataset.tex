\subsection{Dataset}
\label{sec:dataset}

We begin by extracting all sentences \hl{from Wikipedia} containing negation that are not the first sentence of a section, 
ensuring that each has a preceding sentence ($S_1$) to provide context for \hl{the next sentence} ($S_2$).
Next, we retain only the sentences where our rules for reversing polarity can be applied.
We also extract affirmative sentences (i.e., without negation cues) along with their preceding sentences ($S_1$).
To ensure the sentences are truly affirmative, we verify that none of the negation cues from CondaQA are present.
Additionally, 
we aim to select the same number of affirmative sentences from the same article as the negated sentences.
If this is not possible, the remaining sentences are drawn from a different article.
We obtain an equal number of negated and affirmative sentences, resulting in a total of $\approx$6.4M $(S_1, S_2)$ pairs. 
The negated and affirmative sentences are used as the positive and negative examples for the NSPP task, respectively.
Next, we create $(S_1, S_2')$ pairs by reversing the polarity of the $S_2$ sentences.
We add only one negation cue to the affirmative sentences
and ensure that we have the same distribution than in the negated sentences for each article.


We randomly choose $25,000$ ($S_1, S_2$) pairs along with their corresponding $(S_1, S_2')$ pairs to create the validation sets for pre-training.
Half of the $S_2$ sentences are negated and the other half are affirmative.
The NSPP task does not need the ($S_1, S_2'$) pairs.
Therefore, the validation sets consists of $25,000$ and $50,000$ pairs for the NSPP and NSP tasks, respectively.