\section{Related Work}
\label{sc2}

This section reviews the literature on unsupervised CD, MMCD, as well as the investigated key techniques including VFM and contrastive learning.

\subsection{Unsupervised Change Detection}

Unsupervised CD poses great challenges to DL-based approaches due to the absence of explicit supervision. To address this challenge, three main strategies have been developed, including feature difference mapping, generative representation, and knowledge transfer.

Difference mapping is an essential step in the CD that transforms the deep features into change representations. Literature techniques on feature difference analysis include Principal Component Analysis (PCA) ~\cite{Bruzzone2000diff, Gao2016Automatic}, change vector analysis \cite{saha2019unsupervised, wu2021unsupervised}, slow feature analysis ~\cite{Wu2014Slow, Du2019Unsupervised}, half-sibling regression \cite{Kondmann2022Spatial}, etc. Due to the absence of explicit supervision, these methods typically employ pretrained deep neural networks (DNNs) for feature extraction, resulting in weak semantic representations. Meanwhile, generative representation-based methods typically employ image generation methods to reduce the style differences between multitemporal observations, a strategy known as generative transcoding. The frequently employed image generation approaches include AutoEncoders (AEs) \cite{Chen2022Unsupervised} and Generative Adversarial Networks (GANs) \cite{noh2022unsupervised}. Differently from generative transcoding, Wu et al. \cite{wu2023fully} introduce a generative framework to iteratively optimize CD results. 

\subsection{Multimodal Change Detection}

In Earth monitoring applications, it is common that the multi-temporal images are captured by sensors with different imaging mechanisms \cite{hong2023cross}. MMCD extracts change regions with RS images of different modalities, such as optical, synthetic aperture radar (SAR) images, hyperspectral \cite{liu2019HyperCDReview}, digital surface models, etc. Key challenges in unsupervised MMCD involve aligning semantic representations from different image modalities. Recent literature methodologies to solve this challenge include: \textit{i) Generative transcoding.} Generative networks such as AEs~\cite{liu2018coupling, wu2022CommonalityAE} and GANs \cite{saha2021building, Luppino2024CAAE} are employed to learn transition patterns between different image modalities, thereby aligning their representations. \textit{ii) Graph modeling.} Graphs are employed to model the modality-invariant structural information and segment the difference regions~\cite{sun2021itertivegraph, Chen2022Unsupervised, sun2024LPEM}. \textit{iii) Metric learning.} Local distribution patterns or statistics are collected from multimodal images to measure similarity or distances \cite{prendes2015Multivariate, touati2019multimodal}. 

However, due to difficulties in the registration and annotation of MMCD datasets \cite{lv2022cdhetreview}, most MMCD methods are developed on a single pair of images with very few instances. For instance, several literature methods exhibit sensitivity to the tuning of hyperparameters. Their generalization to diverse areas with various change instances remains largely unevaluated.

\subsection{Contrastive Learning}

Contrastive learning (CL), a type of self-supervision approach, constructs and compares positive and negative pairs to exploit the semantic consistency in unlabeled data. An established paradigm of CL in visual recognition is to introduce weak-to-strong perturbations, thus regularizing the DNNs to learn robust semantic representations \cite{sohn2020fixmatch}. These perturbations can be introduced into input images or embedded features \cite{yang2023revisiting}.

In CD, bi-temporal images of the same/different regions are often utilized to construct contrastive pairs. In \cite{chen2021self} a simple contrastive learning paradigm for CD is introduced, where change pairs are constructed with cropped RSIs at the same and different locations. Differently, Bandara et al. \cite{bandara2022revisiting} introduce perturbations on the bi-temporal difference features and perform consistency-regularized CL. In \cite{mall2023changeaware} a CL framework for CD with long-term temporal observations is introduced.

Overall, CL is mostly utilized in semi-supervised CD \cite{yang2023revisiting, bandara2022revisiting} and weakly-supervised CD ~\cite{zhao2024pixellevel} to leverage the sparse supervision signals available. Literature methods on CL-based UCD predominately exploit the temporal similarity embeddings \cite{chen2021self}, yet there exists a notable gap in the exploration of temporal difference embeddings. In this study, we investigate the joint exploitation of temporal consistency and difference embeddings employing CL techniques.

\begin{figure*}[!t]
\centering
    \includegraphics[width=1\linewidth]{illu_pic/S2C_flowchart.png}
    \caption{Overview of the proposed S2C framework for UCD. Triplet losses are calculated with bitemporal images and their augmented copies to learn temporal differences; discriminative losses are calculated between bitemporal images of different regions to learn temporal consistency. Random perturbations are introduced to simulate the spectral and spatial variations.}
\label{fig.flowchar}
\end{figure*}


\subsection{VFM-Based Change Detection}

In recent years, there has been a trend towards developing Visual Foundation Models (VFMs), such as CLIP \cite{radford2021CLIP} and Segment Anything Model (SAM) \cite{Kirillov2023Segment}, to acquire comprehensive recognition capabilities. VFMs are trained on large datasets to capture universal features applicable to various tasks. However, since these VFMs are mostly trained on common natural scenes, they demonstrate biases while applied to the recognition of RS scenes \cite{ji2024segment}. Considering the spectral and temporal characteristics of RSIs, several RS foundation models (FMs) have been developed, including SpectralGPT \cite{hong2024spectralgpt} and SkySense \cite{guo2024skysense}. However, employing these models for CD still necessitates incorporating CD-specific modules and performing fully supervised fine-tuning.

Considering that FMs contain implicit knowledge of the image content, several recent methods have explored employing FMs to achieve sample-efficient CD. SAM-CD\cite{ding2024samcd}, the first work on adapting VFMs to the RS domain using a semantic alignment technique, obtains high accuracy and demonstrates label-efficiency over several semisupervised CD methods. 

In \cite{wang2023cs}, SAM is utilized to generate pseudo labels from vague change maps used as prompts. In \cite{chen2024change}, Chen et al. employed SAM to achieve unsupervised CD between optical images and map data. In \cite{zheng2024segment}, zero-shot CD is achieved by measuring the similarity of SAM-encoded features. Dong et al. \cite{dong2024changeclip} utilized CLIP to learn visual-language representations to improve CD accuracy.

Despite these previous works on leveraging VFM for CD, UCD in HR RSIs is still a challenging tasks and the SOTA accuracy is limited. In this research, we further improve SAM-CD by incorporating self-supervision techniques to replace explicit supervision.