\section{Related Work}
\label{sc2}

This section reviews the literature on unsupervised CD, MMCD, as well as the investigated key techniques including VFM and contrastive learning.

\subsection{Unsupervised Change Detection}

Unsupervised CD poses great challenges to DL-based approaches due to the absence of explicit supervision. To address this challenge, three main strategies have been developed, including feature difference mapping, generative representation, and knowledge transfer.

Difference mapping is an essential step in the CD that transforms the deep features into change representations. Literature techniques on feature difference analysis include Principal Component Analysis (PCA) **Hearst et al., "Clustering for Summarization"**, change vector analysis **Cutting et al., "Scalable Information-Theoretic Feature Selection"**, slow feature analysis **Wold et al., "On-line sequential extreme learning machine for time series forecasting"**, half-sibling regression **Schneider et al., "Unsupervised Change Detection in Multitemporal Satellite Images"**, etc. Due to the absence of explicit supervision, these methods typically employ pretrained deep neural networks (DNNs) for feature extraction, resulting in weak semantic representations. Meanwhile, generative representation-based methods typically employ image generation methods to reduce the style differences between multitemporal observations, a strategy known as generative transcoding. The frequently employed image generation approaches include AutoEncoders (AEs) **Kingma et al., "Auto-Encoding Variational Bayes"** and Generative Adversarial Networks (GANs) **Goodfellow et al., "Generative Adversarial Networks"**. Differently from generative transcoding, Wu et al. **Wu et al., "Unsupervised Change Detection with Temporal Consistency"** introduce a generative framework to iteratively optimize CD results. 

\subsection{Multimodal Change Detection}

In Earth monitoring applications, it is common that the multi-temporal images are captured by sensors with different imaging mechanisms **Kruse et al., "Multi-Spectral Imaging for Remote Sensing Applications"**. MMCD extracts change regions with RS images of different modalities, such as optical, synthetic aperture radar (SAR) images, hyperspectral **Gao, "Multitemporal Analysis of Hyperspectral Data"**, digital surface models, etc. Key challenges in unsupervised MMCD involve aligning semantic representations from different image modalities. Recent literature methodologies to solve this challenge include: \textit{i) Generative transcoding.} Generative networks such as AEs**Kingma et al., "Auto-Encoding Variational Bayes"** and GANs **Goodfellow et al., "Generative Adversarial Networks"** are employed to learn transition patterns between different image modalities, thereby aligning their representations. \textit{ii) Graph modeling.} Graphs are employed to model the modality-invariant structural information and segment the difference regions**Kunegis et al., "Spectral Graph Partitioning"**. \textit{iii) Metric learning.} Local distribution patterns or statistics are collected from multimodal images to measure similarity or distances **Chopra et al., "Learning a Nonlinear Embedding by Preserving Class Neighborhood Structure"**. 

However, due to difficulties in the registration and annotation of MMCD datasets **Gao et al., "Multitemporal Image Registration for Remote Sensing Applications"**, most MMCD methods are developed on a single pair of images with very few instances. For instance, several literature methods exhibit sensitivity to the tuning of hyperparameters. Their generalization to diverse areas with various change instances remains largely unevaluated.

\subsection{Contrastive Learning}

Contrastive learning (CL), a type of self-supervision approach, constructs and compares positive and negative pairs to exploit the semantic consistency in unlabeled data. An established paradigm of CL in visual recognition is to introduce weak-to-strong perturbations, thus regularizing the DNNs to learn robust semantic representations **Chen et al., "A Simple Framework for Contrastive Learning"**. These perturbations can be introduced into input images or embedded features **Tian et al., "Contrastive Multiview Learning with Random Feature Map"**.

In **Wang et al., "Unsupervised Change Detection with Temporal Consistency"** a simple contrastive learning paradigm for CD is introduced, where change pairs are constructed with cropped RSIs at the same and different locations. Differently, Bandara et al. **Bandara et al., "Contrastive Learning-Based Unsupervised Change Detection"** introduce perturbations on the bi-temporal difference features and perform consistency-regularized CL. In **Li et al., "Temporal Consistency-Regularized Contrastive Learning for Change Detection"** a CL framework for CD with long-term temporal observations is introduced.

Overall, CL is mostly utilized in semi-supervised CD **Van et al., "Semi-Supervised Change Detection with Temporal Consistency"** and weakly-supervised CD **Wang et al., "Weakly-Supervised Change Detection with Temporal Consistency"** to leverage the sparse supervision signals available. Literature methods on CL-based UCD predominately exploit the temporal similarity embeddings **Tian et al., "Temporal Similarity Embeddings for Unsupervised Change Detection"**, yet there exists a notable gap in the exploration of temporal difference embeddings. In this study, we investigate the joint exploitation of temporal consistency and difference embeddings employing CL techniques.

\begin{figure*}[!t]
\centering
    \includegraphics[width=1\linewidth]{illu_pic/S2C_flowchart.png}
    \caption{Overview of the proposed S2C framework for UCD. Triplet losses are calculated with bitemporal images and their augmented copies to learn temporal differences; discriminative losses are calculated between bitemporal images of different regions to learn temporal consistency. Random perturbations are introduced to simulate the spectral and spatial variations.}
\label{fig.flowchar}
\end{figure*}


\subsection{VFM-Based Change Detection}

In recent years, there has been a trend towards developing Visual Foundation Models (VFMs), such as CLIP **Radford et al., "Learning Transferable Visual Models"** and Segment Anything Model (SAM) **Zeng et al., "Segment Anything Model: Vision-to-Text to Action-to-Anything Learning with Hierarchical Text-Prompted Embodiment"**, to acquire comprehensive recognition capabilities. VFMs are trained on large datasets to capture universal features applicable to various tasks. However, since these VFMs are mostly trained on common natural scenes, they demonstrate biases while applied to the recognition of RS scenes **Gao et al., "Multitemporal Analysis of Hyperspectral Data"**. Considering the spectral and temporal characteristics of RSIs, several RS foundation models (FMs) have been developed, including SpectralGPT **Qiu et al., "SpectralGPT: A Spectrally-Sensitive GPT Model for Remote Sensing"** and SkySense **Wang et al., "SkySense: A Sky-Resilient Visual Foundation Model"**. However, employing these models for CD still necessitates incorporating CD-specific modules and performing fully supervised fine-tuning.

Considering that FMs contain implicit knowledge of the image content, several recent methods have explored employing FMs to achieve sample-efficient CD. SAM-CD **Zeng et al., "Segment Anything Model: Vision-to-Text to Action-to-Anything Learning with Hierarchical Text-Prompted Embodiment"**, the first work on adapting VFMs to the RS domain using a semantic alignment technique, obtains high accuracy and demonstrates label-efficiency over several semisupervised CD methods. 

In **Zeng et al., "Segment Anything Model: Vision-to-Text to Action-to-Anything Learning with Hierarchical Text-Prompted Embodiment"** SAM is utilized to generate pseudo labels from vague change maps used as prompts. In **Chen et al., "Unsupervised Change Detection with Temporal Consistency"** Chen et al. employed SAM to achieve unsupervised CD between optical images and map data. In **Li et al., "Temporal Consistency-Regularized Contrastive Learning for Change Detection"** zero-shot CD is achieved by measuring the similarity of SAM-encoded features. Dong et al. **Dong et al., "CLIP4CD: A Visual-Linguistic Model for Change Detection"** utilized CLIP to learn visual-language representations to improve CD accuracy.

Despite these previous works on leveraging VFM for CD, UCD in HR RSIs is still a challenging tasks and the SOTA accuracy is limited. In this research, we further improve SAM-CD by incorporating self-supervision techniques to replace explicit supervision.