@article{haider2024looking,
  title={Looking into Black Box Code Language Models},
  author={Haider, Muhammad Umair and Farooq, Umar and Siddique, AB and Marron, Mark},
  journal={arXiv preprint arXiv:2407.04868},
  year={2024}
}

@article{BurkartH21,
  author       = {Nadia Burkart and
                  Marco F. Huber},
  title        = {A Survey on the Explainability of Supervised Machine Learning},
  journal      = {J. Artif. Intell. Res.},
  volume       = {70},
  pages        = {245--317},
  year         = {2021},
  url          = {https://doi.org/10.1613/jair.1.12228},
  doi          = {10.1613/JAIR.1.12228},
  timestamp    = {Thu, 28 Jan 2021 17:08:48 +0100},
  biburl       = {https://dblp.org/rec/journals/jair/BurkartH21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DalviDSBBG19,
  author       = {Fahim Dalvi and
                  Nadir Durrani and
                  Hassan Sajjad and
                  Yonatan Belinkov and
                  Anthony Bau and
                  James R. Glass},
  title        = {What Is One Grain of Sand in the Desert? Analyzing Individual Neurons
                  in Deep {NLP} Models},
  booktitle    = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2019, The Thirty-First Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
                  USA, January 27 - February 1, 2019},
  pages        = {6309--6317},
  publisher    = {{AAAI} Press},
  year         = {2019},
  url          = {https://doi.org/10.1609/aaai.v33i01.33016309},
  doi          = {10.1609/AAAI.V33I01.33016309},
  timestamp    = {Fri, 15 Sep 2023 14:10:05 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/DalviDSBBG19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{AntvergB22,
  author       = {Omer Antverg and
                  Yonatan Belinkov},
  title        = {On the Pitfalls of Analyzing Individual Neurons in Language Models},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=8uz0EWPQIMu},
  timestamp    = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/AntvergB22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{marks2024sparse,
  author       = {Samuel Marks and
                  Can Rager and
                  Eric J. Michaud and
                  Yonatan Belinkov and
                  David Bau and
                  Aaron Mueller},
  title        = {Sparse Feature Circuits: Discovering and Editing Interpretable Causal
                  Graphs in Language Models},
  journal      = {CoRR},
  volume       = {abs/2403.19647},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2403.19647},
  doi          = {10.48550/ARXIV.2403.19647},
  eprinttype    = {arXiv},
  eprint       = {2403.19647},
  timestamp    = {Wed, 10 Apr 2024 17:37:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2403-19647.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{ConmyMLHG23,
  title={Towards automated circuit discovery for mechanistic interpretability},
  author={Conmy, Arthur and Mavor-Parker, Augustine and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adri{\`a}},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={16318--16352},
  year={2023}
}

@misc{frankle2019lotterytickethypothesisfinding,
      title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks}, 
      author={Jonathan Frankle and Michael Carbin},
      year={2019},
      eprint={1803.03635},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1803.03635}, 
}
@INPROCEEDINGS{9506252,
  author={Haider, Muhammad Umair and Taj, Murtaza},
  booktitle={2021 IEEE International Conference on Image Processing (ICIP)}, 
  title={Comprehensive Online Network Pruning Via Learnable Scaling Factors}, 
  year={2021},
  volume={},
  number={},
  pages={3557-3561},
  keywords={Deep learning;Image coding;Conferences;Neurons;Memory management;Logic gates;Benchmark testing;Neural Networks;synaptic pruning;recognition},
  doi={10.1109/ICIP42928.2021.9506252}
}chrome://whats-new/
@inproceedings{WeiHHXQXMW024,
  author       = {Boyi Wei and
                  Kaixuan Huang and
                  Yangsibo Huang and
                  Tinghao Xie and
                  Xiangyu Qi and
                  Mengzhou Xia and
                  Prateek Mittal and
                  Mengdi Wang and
                  Peter Henderson},
  title        = {Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank
                  Modifications},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=K6xxnKN2gm},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/WeiHHXQXMW024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{he2024jailbreaklens,
  title={JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit},
  author={He, Zeqing and Wang, Zhibo and Chu, Zhixuan and Xu, Huiyu and Zheng, Rui and Ren, Kui and Chen, Chun},
  journal={arXiv preprint arXiv:2411.11114},
  year={2024}
}
@inproceedings{SubramaniSP22,
  author       = {Nishant Subramani and
                  Nivedita Suresh and
                  Matthew E. Peters},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {Extracting Latent Steering Vectors from Pretrained Language Models},
  booktitle    = {Findings of the Association for Computational Linguistics: {ACL} 2022,
                  Dublin, Ireland, May 22-27, 2022},
  pages        = {566--581},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.findings-acl.48},
  doi          = {10.18653/V1/2022.FINDINGS-ACL.48},
  timestamp    = {Mon, 01 Aug 2022 16:27:40 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/SubramaniSP22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{MengSABB23,
  author       = {Kevin Meng and
                  Arnab Sen Sharma and
                  Alex J. Andonian and
                  Yonatan Belinkov and
                  David Bau},
  title        = {Mass-Editing Memory in a Transformer},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=MkbcAHIYgyS},
  timestamp    = {Wed, 24 Jul 2024 16:50:34 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/MengSABB23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{rizwan2024resolving,
  title={Resolving Lexical Bias in Edit Scoping with Projector Editor Networks},
  author={Rizwan, Hammad and Rosati, Domenic and Wu, Ga and Sajjad, Hassan},
  journal={arXiv preprint arXiv:2408.10411},
  year={2024}
}
@article{geva2020transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal={arXiv preprint arXiv:2012.14913},
  year={2020}
}
@article{geva2022transformer,
  title={Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space},
  author={Geva, Mor and Caciularu, Avi and Wang, Kevin Ro and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2203.14680},
  year={2022}
}
@article{voita2023neurons,
  title={Neurons in large language models: Dead, n-gram, positional},
  author={Voita, Elena and Ferrando, Javier and Nalmpantis, Christoforos},
  journal={arXiv preprint arXiv:2309.04827},
  year={2023}
}
@article{foote2023n2g,
  title={N2g: A scalable approach for quantifying interpretable neuron representations in large language models},
  author={Foote, Alex and Nanda, Neel and Kran, Esben and Konstas, Ionnis and Barez, Fazl},
  journal={arXiv preprint arXiv:2304.12918},
  year={2023}
}
@article{vig2020investigating,
  title={Investigating gender bias in language models using causal mediation analysis},
  author={Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12388--12401},
  year={2020}
}
@inproceedings{lecomte2024causes,
  title={What Causes Polysemanticity? An Alternative Origin Story of Mixed Selectivity from Incidental Causes},
  author={Lecomte, Victor and Thaman, Kushal and Schaeffer, Rylan and Bashkansky, Naomi and Chow, Trevor and Koyejo, Sanmi},
  year={2024},
  booktitle={ICLR 2024 Workshop on Representational Alignment}
}
@misc{marshall2024understandingpolysemanticityneuralnetworks,
      title={Understanding polysemanticity in neural networks through coding theory}, 
      author={Simon C. Marshall and Jan H. Kirchner},
      year={2024},
      eprint={2401.17975},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.17975}, 
}
@article{olah2020zoom,
  title={Zoom in: An introduction to circuits},
  author={Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  journal={Distill},
  volume={5},
  number={3},
  pages={e00024--001},
  year={2020}
}

@inproceedings{grain:aaai19-1,
 author = {Fahim Dalvi and Nadir Durrani and Hassan Sajjad and Yonatan Belinkov  and D. Anthony Bau and James Glass},
 booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
 keywords = {conference},
 location = {Honolulu, US},
 month = {March},
 title = {What is one Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models},
 year = {2019}
}

@inproceedings{dai2021knowledge,
    title = "Knowledge Neurons in Pretrained Transformers",
    author = "Dai, Damai  and
      Dong, Li  and
      Hao, Yaru  and
      Sui, Zhifang  and
      Chang, Baobao  and
      Wei, Furu",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.581/",
    doi = "10.18653/v1/2022.acl-long.581",
    pages = "8493--8502",
    abstract = "Large-scale pretrained language models are surprisingly good at recalling factual knowledge presented in the training corpus. In this paper, we present preliminary studies on how factual knowledge is stored in pretrained Transformers by introducing the concept of knowledge neurons. Specifically, we examine the fill-in-the-blank cloze task for BERT. Given a relational fact, we propose a knowledge attribution method to identify the neurons that express the fact. We find that the activation of such knowledge neurons is positively correlated to the expression of their corresponding facts. In our case studies, we attempt to leverage knowledge neurons to edit (such as update, and erase) specific factual knowledge without fine-tuning. Our results shed light on understanding the storage of knowledge within pretrained Transformers."
}


@misc{morcos2018importancesingledirectionsgeneralization,
      title={On the importance of single directions for generalization}, 
      author={Ari S. Morcos and David G. T. Barrett and Neil C. Rabinowitz and Matthew Botvinick},
      year={2018},
      eprint={1803.06959},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1803.06959}, 
}
@article{dalvi2019neurox,
  title={NeuroX: A Toolkit for Analyzing Individual Neurons in Neural Networks},
  author={Dalvi, Fahim
    and Nortonsmith, Avery
    and Bau, D Anthony
    and Belinkov, Yonatan
    and Sajjad, Hassan
    and Durrani, Nadir
    and Glass, James},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2019}
}

@article{anthropic2023toy,
    title={A Toy Model of Double Descent from Sparsely-Gated Routing},
    author={{Anthropic}},
    year={2023},
    journal={Transformer Circuits},
    url={https://transformer-circuits.pub/2023/toy-double-descent/index.html}
}

@article{sennrich2016neural,
    title={Neural Machine Translation of Rare Words with Subword Units},
    author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
    journal={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics},
    year={2016}
}

@article{elhage2022superposition,
    title={Superposition, Memorization, and Double Descent},
    author={Elhage, Nelson and others},
    year={2022},
    journal={Transformer Circuits}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    year={2022}
}

@misc{lecomte2024,
      title={What Causes Polysemanticity? An Alternative Origin Story of Mixed Selectivity from Incidental Causes}, 
      author={Victor Lecomte and Kushal Thaman and Rylan Schaeffer and Naomi Bashkansky and Trevor Chow and Sanmi Koyejo},
      year={2024},
      eprint={2312.03096},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.03096}, 
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@misc{sanh2020distilbertdistilledversionbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.01108}, 
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@inproceedings{saravia-etal-2018-carer,
    title = "{CARER}: Contextualized Affect Representations for Emotion Recognition",
    author = "Saravia, Elvis  and
      Liu, Hsien-Chi Toby  and
      Huang, Yen-Hao  and
      Wu, Junlin  and
      Chen, Yi-Shin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1404",
    doi = "10.18653/v1/D18-1404",
    pages = "3687--3697",
    abstract = "Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.",
}

@inproceedings{Zhang2015CharacterlevelCN,
  title={Character-level Convolutional Networks for Text Classification},
  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},
  booktitle={NIPS},
  year={2015}
}

@inproceedings{NIPS2015_250cf8b5,
 author = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Character-level Convolutional Networks for Text Classification},
 url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf},
 volume = {28},
 year = {2015}
}

@inproceedings{Casanueva2020,
    author      = {I{\~{n}}igo Casanueva and Tadas Temcinas and Daniela Gerz and Matthew Henderson and Ivan Vulic},
    title       = {Efficient Intent Detection with Dual Sentence Encoders},
    year        = {2020},
    month       = {mar},
    note        = {Data available at https://github.com/PolyAI-LDN/task-specific-datasets},
    url         = {https://arxiv.org/abs/2003.04807},
    booktitle   = {Proceedings of the 2nd Workshop on NLP for ConvAI - ACL 2020}
}

@inproceedings{larson-etal-2019-evaluation,
    title = "An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction",
    author = "Larson, Stefan  and
      Mahendran, Anish  and
      Peper, Joseph J.  and
      Clarke, Christopher  and
      Lee, Andrew  and
      Hill, Parker  and
      Kummerfeld, Jonathan K.  and
      Leach, Kevin  and
      Laurenzano, Michael A.  and
      Tang, Lingjia  and
      Mars, Jason",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    year = "2019",
    url = "https://www.aclweb.org/anthology/D19-1131"
}
@online{millidge2023basic,
    author = {Millidge, Beren and Winsor, Eric},
    title = {Basic Facts about Language Model Internals},
    year = {2023},
    month = {1},
    day = {4},
    url = {https://www.alignmentforum.org/posts/PDLfpRwSynu73mxGw/basic-facts-about-language-model-internals-1#Activations_Are_Nearly_Gaussian_With_Outliers},
    organization = {AI Alignment Forum}
}
@article{massey1951kolmogorov,
  title={The Kolmogorov-Smirnov test for goodness of fit},
  author={Massey Jr, Frank J},
  journal={Journal of the American statistical Association},
  volume={46},
  number={253},
  pages={68--78},
  year={1951},
  publisher={Taylor \& Francis}
}

@article{joanes1998comparing,
  title={Comparing measures of sample skewness and kurtosis},
  author={Joanes, Derrick N and Gill, Christine A},
  journal={Journal of the Royal Statistical Society: Series D (The Statistician)},
  volume={47},
  number={1},
  pages={183--189},
  year={1998},
  publisher={Wiley Online Library}
}
@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{bommasani2022opportunities,
      title={On the Opportunities and Risks of Foundation Models}, 
      author={Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tramèr and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
      year={2022},
      eprint={2108.07258},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{touvron2023llama,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}
@misc{sparseautoencoderpaper,
      title={Sparse Autoencoders Find Highly Interpretable Features in Language Models}, 
      author={Hoagy Cunningham and Aidan Ewart and Logan Riggs and Robert Huben and Lee Sharkey},
      year={2023},
      eprint={2309.08600},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.08600}, 
}
@misc{sajjad2022neuronlevelinterpretationdeepnlp,
      title={Neuron-level Interpretation of Deep NLP Models: A Survey}, 
      author={Hassan Sajjad and Nadir Durrani and Fahim Dalvi},
      year={2022},
      eprint={2108.13138},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2108.13138}, 
}

@inproceedings{
dalvi2022discovering,
title={Discovering Latent Concepts Learned in {BERT}},
author={Fahim Dalvi and Abdul Rafae Khan and Firoj Alam and Nadir Durrani and Jia Xu and Hassan Sajjad},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=POTMtpYI1xH}
}
@misc{sundararajan2017axiomaticattributiondeepnetworks,
      title={Axiomatic Attribution for Deep Networks}, 
      author={Mukund Sundararajan and Ankur Taly and Qiqi Yan},
      year={2017},
      eprint={1703.01365},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.01365}, 
}
@misc{vig2020causalmediationanalysisinterpreting,
      title={Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias}, 
      author={Jesse Vig and Sebastian Gehrmann and Yonatan Belinkov and Sharon Qian and Daniel Nevo and Simas Sakenis and Jason Huang and Yaron Singer and Stuart Shieber},
      year={2020},
      eprint={2004.12265},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.12265}, 
}
@misc{belrose2023elicitinglatentpredictionstransformers,
      title={Eliciting Latent Predictions from Transformers with the Tuned Lens}, 
      author={Nora Belrose and Zach Furman and Logan Smith and Danny Halawi and Igor Ostrovsky and Lev McKinney and Stella Biderman and Jacob Steinhardt},
      year={2023},
      eprint={2303.08112},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.08112}, 
}
@misc{gurnee2023findingneuronshaystackcase,
      title={Finding Neurons in a Haystack: Case Studies with Sparse Probing}, 
      author={Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas},
      year={2023},
      eprint={2305.01610},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.01610}, 
}
@misc{logitlens,
author = {nostalgebraist},
  title = {interpreting GPT: the logit lens — LessWrong},
  url = "https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens",
month = {8},
year = {2020},
  note = "[Online; accessed 2025-01-29]"
}