\section{Background and Related Work}
\label{sec:related-work}
\subsection{Gaussian Processes}
A \ac{GP} is a stochastic process that models an unknown function. 
It is characterized by the property that any finite set of function evaluations follows a multivariate Gaussian distribution. 
Assuming that the prior has a zero mean, a \ac{GP} is uniquely determined by the current observations $\mathcal{D}_t\coloneqq\{(\bm x_i, y_{\bm x_i})\}_{i=1}^t$ and the kernel function $\kappa(\bm x, \bm x')$. 
Given these, at stage $t$, the predicted mean of $y_{\bm{x}}$ at a new point $\bm x$ is $\mu_t(\bm x) = \bm\kappa_t(\bm x)^T (\bm K_t)^{-1} \bm y_t$, and the predicted covariance between points $\bm x$ and $\bm x'$ is $\textup{Cov}_t(\bm x, \bm x') = \kappa(\bm x, \bm x') - \bm\kappa_t(\bm x)^T (\bm K_t+\tilde{\sigma}\bm I)^{-1} \bm\kappa_t(\bm x')$,
where $[\bm\kappa_t(\bm x)]_i = \kappa(\bm x_i, \bm x)$, $[\bm y_t]_i = y_{\bm x_i}$, $\tilde{\sigma}$ is noise level, and $[\bm K_t]_{i, j} = \kappa(\bm x_i, \bm x_j)$. At point $\bm x$, the \ac{GP} posterior $y_{\bm x}\sim\mathcal{N}(\mu_t(\bm x), \sigma_t(\bm x))$, where $\sigma_t(\bm x)\coloneqq \textup{Cov}_t(\bm x, \bm x)$; see ____ for more details. 


\subsection{Acquisition Functions}
\paragraph{One-step.} 
One commonly used \ac{AF} for \ac{BO} is \acf{EI}____, defined as $ \alpha_{\text{EI}}(\bm{x}) \coloneqq \mathbb{E}\bigl[\max\{y_{\bm{x}} - y_t^\ast, 0\}\bigr]$, where $y_t^\ast$ denotes the current-best (i.e., incumbent) observation. A closely related function is \ac{PI}____, which considers only the probability that a new observation $y_{\bm{x}}$ exceeds the incumbent $y_t^\ast$, without accounting for the magnitude of improvement: $ \alpha_{\text{PI}}(\bm{x}) \coloneqq \mathbb{P}\bigl[y_{\bm{x}} > y_t^\ast\bigr]$. Both \ac{EI} and \ac{PI} have closed-form expressions and are therefore computationally efficient. Similarly, \ac{UCB} is defined as $ \alpha_{\text{UCB}}(\bm{x}) \coloneqq \mu_t(\bm{x}) + \sqrt{\beta_t}\,\sigma_t(\bm{x})$, where $\beta_t$ is a parameter that balances exploration and exploitation. In contrast, information-theoretic \acp{AF} select the next sampling point to reduce uncertainty about a particular property of the optimum -- whether its location as in \ac{ES} or \ac{PES}____, its value as in \ac{MES}____, or both as in \ac{JES}____. 
\ac{TS} implicitly balances the exploration-exploitation trade-off by maximizing posterior samples from a Gaussian process whose accuracy improves as more observations are incorporated ____. However, \ac{TS} has been criticized for being overly explorative.
To address this, several approaches have been proposed to make it less explorative, including \acp{TR} that restrict the space over which the \ac{AF} is maximized to a subregion of $\mathcal{X}$____ and \ac{RAASP} sampling that only considers points close to the incumbent observation for the maximization of the \ac{AF}____.

\paragraph{Multi-step.}
One common property of all aforementioned \acp{AF} is that they assume that the next evaluation will be the last, i.e., they greedily maximize the simple or inference regret for the next iteration, assuming no more evaluations will be performed____.
In contrast, multi-step \acp{AF}____ consider the impact of the current choice for future evaluations: $\alpha_{\text{MS}}(\bm{x}) = v_1(\bm{x}|\mathcal{D}_t)+\mathbb{E}_y\left[\max_{\bm{x}_2}\left(v_1(\bm{x}_2\vert\mathcal{D}_t\cup\left\{(\bm{x},y_{\bm x})\right\}+\mathbb{E}_{y_2}\left[\ldots\right]\right)\right]$,
where $v_1(\bm{x})$ is the one-step marginal value of $\bm{x}$, e.g., the expected improvement upon observing $\bm{x}$.
See____ for details.
Multi-step \acp{AF}, such as \ac{KG}____, are computationally expensive since the expectations of $\alpha_{\text{MS}}$ must be approximated with Monte-Carlo methods and, therefore, are often limited to one lookahead step even though the theoretical framework can usually be extended to arbitrarily many lookahead steps____.
At the same time, they are fundamentally different from previous \acp{AF} and may be characterized by a unique \ac{EETO}____.

\paragraph{Batch.}

Batching is a technique used where multiple function evaluations can be performed in parallel.
Instead of re-conditioning the \ac{GP} after a single new observation, one observes $q$ points in parallel.
Batching requires modifications of the \ac{AF} to ensure that a batch contains a diverse set of candidates.
One strategy for batch \ac{BO} is using multi-point \acp{AF} that estimate the improvement of some utility upon observing $q$ new points____.
Other approaches include \emph{local penalization}____ that repels points from regions around points already included in the batch.

\subsection{Expressions of Exploration}

\paragraph{Quantifying Exploration.}
Although achieving a good balance between exploration and exploitation is widely recognized as a crucial component of an effective acquisition function, the \ac{BO} community still lacks a simple and convenient metric for quantifying exploration. Several related metrics have been proposed -- such as \ac{TCD}____ and incumbent distance____ -- but each has notable shortcomings. For instance, \ac{TCD} focuses solely on the movement of the incumbent, and it fails when the first sample lands on the optimum (yielding a \ac{TCD} of zero) or when the search oscillates between multiple optima. Similarly, incumbent distance measures the distance between the next query and the incumbent but does not reliably capture exploration, as repeatedly querying the opposite corner of the space can yield high values without representing meaningful explorative behavior.

Another approach employs Pareto analysis- 
to interpret the \ac{EETO}____. In this framework, exploration and exploitation are treated as distinct objectives, with the utility function depending on both the predicted mean $\mu$ and variance $\sigma$. Under this interpretation, many \acp{AF}, such as \ac{PI}, \ac{EI}, and \ac{UCB}, can be accommodated. However, more sophisticated \acp{AF}, particularly those based on information-theoretic principles, do not conform to this framework.

\paragraph{Quantifying Exploration in Evolutionary Algorithms.}
The measurement of the exploration extends beyond Bayesian optimization. In evolutionary algorithms (EA)____, this quantity is evaluated from two perspectives: genotypic and phenotypic____. Genotypic measures assess diversity in the input space using tree-based techniques____, Euclidean distance quantities____, entropy-based methods____, and individual-population similarity indices____. In contrast, phenotypic measures evaluate diversity in terms of fitness or performance, employing distance-based methods____, entropy-based measures____, and local-attraction metrics____. Notably, the distance-based approaches mentioned above typically measure the distance from each individual to the population's center rather than the aggregate distance connecting all individuals, distinguishing them from our method. Additionally, entropy-based approaches have mainly focused on low-dimensional discrete domains -- often using binning methods to approximate entropy -- whereas our proposed techniques target high-dimensional continuous domains.

\paragraph{Quantifying Exploration in Reinforcement Learning.}
In \ac{RL}, whether in simpler settings like \acp{MAB}, a special case of \acp{MDP} where the state remains constant, or in more complex \ac{MDP} scenarios, an agent must balance exploration and exploitation to achieve long-term benefits.

In \ac{MAB} problems, one measure of exploration is tracking the frequency with which each action (arm) is selected ____. For general \ac{RL} tasks, both states and actions must be considered. 
Some methods promote exploration by maximizing the entropy of the action distribution____ to encourage the agent to try diverse actions. 
Curiosity-driven exploration, often quantified using information gain____, provides another approach to exploration in the state-action space. 
Existing entropy-based exploration methods in \ac{RL} often rely on parametric methods, like variational inference, which leverage prior knowledge of the underlying density functions (e.g., for actions) but may be inaccurate when the parametric assumptions fail. In \ac{BO}, we do not have access to the true density of observations, so we adopt a non-parametric approach for density estimation. Consequently, our method is not directly comparable to previous entropy-based approaches in \ac{RL} that depend on specific parametric families.