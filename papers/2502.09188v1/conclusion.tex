\section{Conclusion}

In conclusion, the Matina corpus provides a crucial resource for advancing Persian NLP by addressing the limitations of existing datasets in terms of scale and diversity. With 72.9 billion tokens, it enables the training of more advanced and accurate models for tasks such as machine translation, summarization, and large-scale language modeling. We further demonstrate its effectiveness by training and evaluating transformer-based models on key NLP tasks as well as LLM pretraining, highlighting the benefits of high-quality Persian data. By making both the dataset and preprocessing tools publicly available, we aim to support further research and foster collaboration in the development of open-source tools and models for Persian.