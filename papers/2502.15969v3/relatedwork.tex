\section{Related Works}
Despite the success of MLLMs, emerging research highlights their struggles with reasoning.~\citet{alhamoud2025vision} find that vision-language models struggle to negate in retrieval and multiple-choice tasks. Beyond general reasoning, open-source, closed-source, and math-specific MLLMs perform poorly on visual math benchmarks \cite{mathvision, zhang2024mathversedoesmultimodalllm}. 

A key limitation in MLLMs is the vision encoder. \citet{clip-blind} show CLIP-based vision encoders fail to capture fine-grained details \textemdash a detrimental trait for tasks requiring precise visual reasoning. Similarly, in the visual-mathematics domain, \citet{g-llava, math-llava, mavis, mathpuma} demonstrate that vision encoders produce inadequate representations of mathematical diagrams and vision-text misalignments  hinder multimodal reasoning.

One way to address these challenges is fine-tuning. Recent works adopt a multi-step approach: (1) fine-tuning vision encoders to enhance visual representation, (2) training modality projectors for better alignment, and (3) instruction-tuning with CoT datasets \cite{g-llava, math-llava, mavis, mathpuma}. While this may increase performance on math benchmarks, studies show that fine-tuning foundation models often reduces generalization ability and does not address overarching reasoning capability \cite{generalization_fine_tuning, sft_generalize}.

In the language domain, Chain-of-Thought (CoT) prompting has proven highly effective in encouraging System 2 reasoning in LLMs \cite{cot}. \citet{xiang2025towards} further reinforces this, demonstrating that structuring reasoning through CoT can significantly improve logical inference and problem-solving. However, applying CoT to MLLMs has been far less successful. \citet{vlm_cot} show that open-source MLLMs struggle with CoT, largely due to limitations in existing visual-instruction tuning datasets, which prioritize short, simplistic responses over structured reasoning. Thus, recent works explicitly fine-tune MLLMs for CoT reasoning, particularly in object counting and mathematical reasoning tasks \cite{vlm_cot, mavis, mathpuma, molmo}. However, even these fine-tuned models continue to struggle on complex visual-mathematical benchmarks such as MathVista \cite{math-vista}, and MathVerse \cite{zhang2024mathversedoesmultimodalllm}. These challenges highlight that despite recent efforts, System 2 reasoning in MLLMs remains an open problem, with current approaches failing to achieve generalizable reasoning abilities.