\subsection{Dataset}
To explore the impact of enhancing preference alignment while assessing its effects on the original level of safety, We conducted additional preference alignment experiments on the safety alignment dataset PKU-SafeRLHF\cite{ji2024beavertails,ji2024pku}.
It is a high-quality dataset consisting of 83.4K preference entries, which is annotated across two dimensions: harmlessness and helpfulness. Specifically, each entry in this dataset includes two responses to a question, accompanied by safety meta-labels and preferences for both responses based on their helpfulness and harmlessness as shown in Figure~\ref{fig::pkusafe}. We consider helpfulness and harmlessness as two intrinsic attributes of responses. 
When applying our proposed SeAdpra method, we treat helpfulness and harmlessness as two intrinsic attributes of the responses to construct the Multiple Attribute-Perceptual Distance matrix.

To avoid biases introduced by inconsistencies between the preference alignment and safety alignment objectives, as well as malicious data, we select data from the benign set where the preference alignment and safety alignment objectives are consistent for training. 
These data are considered absolutely safe, with their training, validation, and test sets consisting of 6,226, 659, and 2,848 entries.
\subsection{Safety Evaluation}
\textbf{Existing Harmfulness Evaluation} can be classified into three categories:  
1) The first category relies on keyword detection, using a predefined set of keywords (e.g., "sorry," "as," and 47 other keywords). These methods have been used \cite{zou2023universal} and are referred to as keyword-based methods in the study \cite{qi2023fine}. Although this approach is efficient and cost-effective, it can lead to false positives and false negatives when harmful content contains these keywords or when harmless content does not.  
The second category is based on GPT-4's automated harmfulness evaluation, i.e., GPT-4 Judge \cite{qi2023fine}, which introduces more policy-specific knowledge and contextual understanding into the evaluation mechanism to effectively assess harmful content in conversations. However, it depends on complex policy knowledge, conversation context, and manually predefined scoring rules. Additionally, the reasoning based on chain-of-thought makes the evaluation process time-consuming and expensive.  
The third category is based on pre-trained content moderation classifiers, such as OpenAI's Moderation API \cite{OpenAI2023a}, Perspective API \cite{lees2022new}, and Detoxify's pre-trained toxicity prediction models \cite{Hanu2020}. In this study, we choose the Perspective API \footnote{https://www.perspectiveapi.com/} in the third category, as it is a high-accuracy used and cost-effective evaluation approach.

\textbf{The transfer of PrefHit to SaferHit.}
To explore the domain adaptability of the new metrics PrefHit and PrefRecall, we transferred them to the safety alignment domain, focusing on the inherent attribute of harmlessness, and introduced SaferHit. 
\begin{equation}
\begin{aligned}
    \text{SaferHit} = 
    \begin{cases}
    1, & \text{if } \Phi (x,R) = \text{gold} \\
    0, & \text{if } \Phi (x,R) \neq \text{gold}
    \end{cases}
\end{aligned}
    \label{eq::saferhit}
\end{equation}
Here, \( R  = \{R_1, R_2\} \) is shown in Figure \ref{fig::pkusafe}, the \(Gold\) represents the safer response. \( \Phi(x, R) \) is explained in Eq.(\ref{eq::sim}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht]
\centering
\renewcommand{\arraystretch}{1.1}
\tabcolsep=0.25cm
\caption{Performance of baselines implemented on Llama2-7B in terms of preference and safety at inference length = 64 on the dataset PKU-SafeRLHF.}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{PrefHit} & \textbf{SaferHit} & \textbf{Toxicity} \\
\midrule
SFT & 0.545 & 0.550 & 0.192 \\
PRO       & 0.556 & 0.542 & 0.006 \\
SeAdpra   & 0.566 & 0.551 & 0.006 \\
\bottomrule
\end{tabular}
\label{tab:safe64}
\end{table}
\begin{table}[ht]
\centering
\renewcommand{\arraystretch}{1.1}
\tabcolsep=0.25cm
\caption{Performance of baselines implemented on Llama2-7B in terms of preference and safety at inference length = 32 on the dataset PKU-SafeRLHF.}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{PrefHit} & \textbf{SaferHit} & \textbf{Toxicity} \\
\midrule
SFT & 0.525 & 0.522 & 0.025 \\
PRO       & 0.537 & 0.540 & 0.006 \\
SeAdpra   & 0.546 & 0.544 & 0.005 \\
\bottomrule
\end{tabular}
\label{tab:safe32}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{latex/pic/pkusafe.pdf}
    \caption{An example from the PKU-SafeRLHF dataset.}
    \label{fig::pkusafe}
\end{figure*}


