%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[t]
\caption{Self-supervised Dynamic Ranking}
\label{algo1}
\KwIn{ \\
$\Delta_{MuAPDF}$: Multi-APDF matrix \\
$ARank$: the order of semantics adopted \(E(Q,R)\) \\
$M$: the size of response \(R = \{R_1, \ldots, R_M\}\) \\}
\KwOut{$DyRank$} 
$DyRank \gets [ \ ]$ \\
\For{$i \gets 0$ \KwTo $M - 1$}{
     $\delta_{max} \gets \max(\Delta_{MuAPDF})$\ ; \\
    $index \gets \text{where}(\Delta_{MuAPDF} == \delta_{max})$\ ; \\
    $row \gets index(0,0)$\ ; 
    $col \gets index(1,0)$\ ; \\
    \If{$ARank(row) < ARank(col)$}{ 
        $DyRank.\text{append}(row)$\ ; \\
        $\Delta_{MuAPDF}(:, row) \gets 0$\ ; \\
        $\Delta_{MuAPDF}(row, :) \gets 0$\ ; 
    } 
    \Else{ 
        $DyRank.\text{append}(col)$\ ; \\
        $\Delta_{MuAPDF}(:, col) \gets 0$\ ; \\
        $\Delta_{MuAPDF}(col, :) \gets 0$\ ; 
    } 
}
$DyRank.\text{append}(ARank.\text{notin}(DyRank))$ \\
\Return $DyRank$\ 
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.1}
\tabcolsep=0.025cm
\begin{tabular}{lcc|lcc}
\toprule
Domain & Volume & RLen & Domain & Volume & RLen \\ 
\midrule
Academia & 16,783 & 4 & Chemistry & 11,058 & 3 \\ 
Cooking & 15,036 & 5 & Electronics & 20,384 & 5 \\ 
History & 6,600 & 3 & Math & 25,860 & 6 \\ 
Music & 16,200 & 4 & Politics & 8,014 & 3 \\ 
Security & 31,327 & 6 & Code & 23,926 & 7 \\ 
\bottomrule
\end{tabular}
\caption{Statistics of the public dataset for Community QA. We align LLMs to QA in different domains, each with varying ranking size (RLen) and data volume.}
\label{domain}
\vspace{-0.2cm}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Baseline} 
Following the DPO \cite{rafailov2024direct}, we evaluated several existing approaches aligned with human preference, including GPT-J \cite{gpt-j} and Pythia-2.8B \cite{biderman2023pythia}.  
Next, we assessed StarCoder2 \cite{lozhkov2024starcoder}, which has demonstrated strong performance in code generation, alongside several general-purpose LLMs: Qwen2 \cite{qwen2}, ChatGLM4 \cite{wang2023cogvlm, glm2024chatglm} and LLaMA serials \cite{touvron2023llama,llama3modelcard}.
Finally, we fine-tuned LLaMA2-7B on the StaCoCoQA and compared its performance with other strong baselines for supervised learning in preference alignment, including SFT, RRHF \cite{yuan2024rrhf}, Silc \cite{zhao2023slic}, DPO, and PRO \cite{song2024preference}.
% \subsection{The Dataset: StaCoCoQA}
% \label{sec::stacocoqa}
% Due to the lack of high-quality, authentic multi-answer preference datasets in code communities, there is an urgent need to construct a new dataset. To address this gap, we have turned to StackExchange \footnote{https://archive.org/details/stackexchange}, a platform whose forums are accompanied by rich question-answering metadata information. A publicly available dump of user-contributed content from Stack Overflow, provided by StackExchange under a cc-by-sa 4.0 license, has formed the foundation for the creation of our dataset StaCoCoQA. It contains over 60,738 programming directories shown in Table~\ref{tab:stacocoqa_tags} and 9,978,474 entries, with partial data statistics shown in Figure~\ref{fig:dataset}.

% The initial dataset \(D_I\) is in XML and contains 24,101,803 entries, and is processed by the following steps:
% \begin{itemize}[leftmargin=*]
%     \item Select entries with "Questioner-picked answer" pairs to represent the preferences of the questioners, resulting in 12,260,106 entries in the \(D_Q\).
%     \item Select data where the question includes at least one code block to focus on specific-domain programming QA, resulting in 9,978,474 entries in the dataset \(D_C\).
%     \item All HTML tags were cleaned using BeautifulSoup \footnote{https://beautiful-soup-4.readthedocs.io/en/latest/} to ensure that the model is not affected by overly complex and meaningless content.
%     \item Control the quality of the dataset by considering factors such as the time the question was posted, the size of the response pool, the difference between the highest and lowest votes within a pool, the number of votes for each response, the token-level length of the question and the answers, which yields datasets of varying sizes: 3K, 8K, 18K, 29K, and 64K. Examples of some control variables are shown in Table~\ref{tab:statistics}.
% \end{itemize}

\begin{table*}[t]
\centering
\renewcommand{\arraystretch}{1.1}
\tabcolsep=0.55cm
\caption{Caption: Statistics of the number of questions with different response pool sizes (Size) in various posting periods (Year) in \(D_I\). Statistics of the number of questions with different response pool sizes (Size) in \(D_Q\) and \(D_C\)}
\begin{tabular}{@{}lcccccc@{}}
\toprule
Year & Size=3 & Size=5 & Size=8 & Size=10 & Size=15 & Size=20 \\ \midrule
Last 2 years & 42,945  & 3,452  & 364    & 148    & 37     & 13     \\
Last 4 years & 178,264 & 18,050 & 2,622  & 1,304  & 408    & 181    \\
Last 6 years & 405,634 & 49,278 & 8,026  & 4,126  & 1,394  & 642    \\
Last 8 years & 719,155 & 100,464 & 18,354 & 9,731  & 3,420  & 1,632  \\ \bottomrule

Step 1 \(D_Q\) & 1,800,588 & 418,688 & 99,646 & 53,681 & 18,429 & 8,513 \\
Step 2 \(D_C\) & 1,428,796 & 311,275 & 69,300 & 37,121 & 12,952 & 6,119 \\ \bottomrule
\end{tabular}
\label{tab:statistics}
\end{table*}

\begin{table*}[h]
\centering
  \renewcommand{\arraystretch}{1.2}
  \tabcolsep=0.44cm
\caption{Statistics on the top 90 categories of StaCoCoQA: Programming Language Categories, Data Volume, and Percentages}
\begin{adjustbox}{width=\linewidth}  
\begin{tabular}{lcc | lcc}
\toprule
\textbf{Category} & \textbf{Volume} & \textbf{Percentage} & \textbf{Category} & \textbf{Volume} & \textbf{Percentage} \\
\midrule
JavaScript & 1,200,942 & 0.120 & Python & 1,028,686 & 0.103 \\
C\# & 741,524 & 0.074 & PHP & 657,849 & 0.066 \\
jQuery & 541,142 & 0.054 & Android & 476,301 & 0.048 \\
CSS & 384,623 & 0.039 & SQL & 341,592 & 0.034 \\
R & 270,346 & 0.027 & Arrays & 247,129 & 0.025 \\
C & 199,767 & 0.020 & ReactJS & 186,690 & 0.019 \\
Node.js & 182,107 & 0.018 & Regex & 169,717 & 0.017 \\
Ruby on Rails & 164,889 & 0.017 & Pandas & 164,879 & 0.017 \\
Python 3.x & 161,735 & 0.016 & SQL Server & 148,887 & 0.015 \\
Swift & 145,214 & 0.015 & ASP.NET & 143,419 & 0.014 \\
.NET & 138,558 & 0.014 & Django & 137,415 & 0.014 \\
Objective-C & 131,735 & 0.013 & Ruby & 122,249 & 0.012 \\
Angular & 120,107 & 0.012 & AngularJS & 119,819 & 0.012 \\
String & 108,758 & 0.011 & Excel & 107,546 & 0.011 \\
XML & 107,448 & 0.011 & TypeScript & 106,706 & 0.011 \\
Ajax & 96,775 & 0.010 & VBA & 90,516 & 0.009 \\
ASP.NET MVC & 88,847 & 0.009 & Bash & 88,632 & 0.009 \\
Laravel & 88,507 & 0.009 & DataFrame & 86,629 & 0.009 \\
Linux & 86,535 & 0.009 & List & 85,043 & 0.009 \\
Spring & 79,137 & 0.008 & WPF & 78,873 & 0.008 \\
PostgreSQL & 78,662 & 0.008 & iPhone & 74,505 & 0.007 \\
MongoDB & 72,507 & 0.007 & Database & 67,669 & 0.007 \\
Oracle & 63,778 & 0.006 & NumPy & 63,055 & 0.006 \\
Multithreading & 61,404 & 0.006 & Scala & 60,979 & 0.006 \\
Function & 60,682 & 0.006 & VB.NET & 59,283 & 0.006 \\
Flutter & 58,351 & 0.006 & & & \\
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:stacocoqa_tags}
\end{table*}



\subsection{Implementation Details}
\label{sec::imp}

By limiting the input lengths of \(Q\) and \(R\), and setting thresholds based on the popularity of \(R\), we sampled datasets of various scales from StaCoCoQA: 3K, 8K, 18K, 29K, and 64K, splitting them into training and test sets with a 9:1 ratio. Due to the cost of constructing Gold labels, we selected data from the past four years that are highly popular and feature concise questions as the high-quality test set, totaling 276 samples.
The maximum number of new tokens generated during inference is 128, and beam search decoding is used.
In all following experimental results, PrefHit and PrefRecall correspond to PrefHit@1 and PrefRecall@3, respectively.
We conducted extensive experiments to explore hyperparameters that adapt to datasets of different scales, with varying settings. For detailed information, please refer to the Table~\ref{table::lr}, Table~\ref{table::bs}, Table~\ref{table::w} and Table~\ref{table::scale}.
\begin{table*}[t]
  \renewcommand{\arraystretch}{1.1}
\centering
\caption{Hyperparameter Settings for Training Datasets of Different Scales. The cs represents the convergence step}
  \tabcolsep=0.3cm
  \begin{tabular}{ lcc cccc ccc}
    \toprule
     Scale & batch size &learning rate & evaluation step & epoch & PRO cs & SeAdpra cs  \\ \midrule
        \(Scale=3k\) & 4 & 5e-7 & 200 & 4 &640  & 4,221 \\ 
         \(Scale=8k\) & 4 & 5e-7 & 500 & 3 &2000  &1,000 \\ 
         \(Scale=18k\) & 8 & 5e-7 & 1,000 & 2 & 8000& 2,000 \\ 
         \(Scale=29k\)& 16 & 5e-7& 2,000 & 2 &4000& 6,000\\ 
         \(Scale=64k\) & 32 & 5e-7 & 2,000 & 1&1000 & 3,000\\ 
  \bottomrule
\end{tabular}
\label{table::scale}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[t]
\centering
\caption{Results of experiments with different weight \(\alpha\) in Perceptual Alignment.}
\label{alpha}
\renewcommand{\arraystretch}{1.13} % Adjust row height
\tabcolsep=0.15cm % Adjust column spacing
\begin{tabular}{lccccccccc}
\toprule
\multirow{2}{*}{Method} & \multicolumn{6}{c}{Preference \((\uparrow)\)} & \multicolumn{3}{c}{Accuracy \((\uparrow)\)} \\ 
\cmidrule(lr){2-7} \cmidrule(lr){8-10}
& \small{PrefHit@1} & \small{PrefHit@3} & \small{PrefRec@2} & \small{PrefRec@4} & \small{Reward1} & \small{Reward2} 
& \small{CodeSim} & \small{BLEU} & \small{RougeL} \\ 
\midrule
\( \alpha=0.01 \) & 0.3659 & 0.5326 & 0.5036 & 0.8279 & 0.2301 & 0.8233 & 0.6900 & 0.1412 & 0.2078 \\
\(\alpha=0.05\)  & 0.3478 & 0.5471 & 0.5127 & 0.8252 & 0.2233 & 0.8405 & 0.6914 & 0.1741 & 0.2182 \\
\(\alpha=0.1\)   & 0.3225 & 0.5072 & 0.4819 & 0.8315 & 0.2311 & 0.8320 & 0.6901 & 0.2177 & 0.1557 \\  
\( \alpha=0.2 \) & 0.3370 & 0.5254 & 0.4964 & 0.8297 & 0.2304 & 0.8212 & 0.6896 & 0.1352 & 0.2080 \\
\( \alpha=0.5 \)  & 0.2826 & 0.4819 & 0.4565 & 0.8179 & 0.1901 & 0.7612 & 0.6752 & 0.1013 & 0.1654 \\
\( \alpha=1 \)   & 0.3225 & 0.5145 & 0.4891 & 0.8342 & 0.2241 & 0.8330 & 0.6901 & 0.1534 & 0.2168 \\
\bottomrule
\end{tabular}
\label{table::w}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{table*}[h]
\setlength{\tabcolsep}{1.5pt}
\centering
 \caption{Results of experiments on the different sizes of response \(Step\). }
\label{size}
\renewcommand{\arraystretch}{1.13}
   \tabcolsep=0.15cm
% \resizebox{\textwidth}{3cm}{
\begin{tabular}{ lc ccc ccccc}
\toprule
\multirow{2}{*}{Method}&\multicolumn{6}{c}{Preference \((\uparrow)\)} & \multicolumn{3}{c}{Accuracy \((\uparrow)\)} \\ \Xcline{2-7 }{0.4pt}  \Xcline{ 8-10}{0.4pt} 
 & \small{PrefHit@1} & \small{PrefHit@3} & \small{PrefRec@2} & \small{PrefRec@4} &\small{Reward1} &\small{Reward2}&\small{CodeSim}  & \small{BLEU}&\small{RougeL}   \\ \midrule
      \( Step=2\) & 0.3333 & 0.5217 & 0.5000 & 0.8279 & 0.2347 & 0.8226 & 0.6902 & 0.2081 & 0.1436 \\
      
          \( Step=3\) & 0.3370 & 0.5217 & 0.4891 & 0.8270 & 0.2339 & 0.8219 & 0.6904 & 0.2085 & 0.1420 \\
      
          \( Step=4\) & 0.3261 & 0.5145 & 0.4801 & 0.8252 & 0.2309 & 0.8136 & 0.6881 & 0.2065 &  0.1432 \\
       
          \( Step=5\) & 0.3261 & 0.5109 & 0.4873 & 0.8388 & 0.2245 & 0.8307 & 0.6898 & 0.2172 & 0.1548 \\
  \bottomrule
\end{tabular}
\label{table::step}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[h]
\setlength{\tabcolsep}{2pt}
\centering
 \caption{Results of experiments on the different learning rate \(lr\). }
\label{lr}
\renewcommand{\arraystretch}{1.13}
   \tabcolsep=0.15cm
% \resizebox{\textwidth}{3cm}{
\begin{tabular}{ lc ccc ccccc}
\toprule
\multirow{2}{*}{Method}&\multicolumn{6}{c}{Preference \((\uparrow)\)} & \multicolumn{3}{c}{Accuracy \((\uparrow)\)} \\ \Xcline{2-7 }{0.4pt}  \Xcline{ 8-10}{0.4pt} 
 & \small{PrefHit@1} & \small{PrefHit@3} & \small{PrefRec@2} & \small{PrefRec@4} &\small{Reward1} &\small{Reward2}&\small{CodeSim}  & \small{BLEU}&\small{RougeL}   \\ \midrule
          \( lr=1e-7\) & 0.3333 & 0.5217 & 0.5000 & 0.8279 & 0.2347 & 0.8226 & 0.6902 & 0.2081 & 0.1436 \\
      
          \( lr=3e-7\) & 0.3370 & 0.5217 & 0.4891 & 0.8270 & 0.2339 & 0.8219 & 0.6904 & 0.2085 & 0.1420 \\
      
          \( lr=5e-7\) & 0.3478 & 0.5471 & 0.5127 & 0.8252 & 0.2233 & 0.8405 & 0.6914 & 0.1741 & 0.2182 \\
       
          \( lr=1e-6\) & 0.2899 & 0.4891 & 0.4692 & 0.8297 & 0.2322 & 0.8082 & 0.6872 & 0.1330 & 0.2056 \\
          \( lr=5e-6\) & 0.3080 & 0.5471 & 0.4964 & 0.8234 & 0.2156 & 0.8465 & 0.6945 & 0.1742 & 0.2274 \\
          \( lr=1e-5\) & 0.3261 & 0.5109 & 0.4783 & 0.8225 & 0.2021 & 0.8494 & 0.6971 & 0.1955 & 0.2216 \\
  \bottomrule
\end{tabular}
\label{table::lr}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{table*}[h]
% \centering
% \caption{Results of experiments on the different training data scale \(Scale\).}
%   \renewcommand{\arraystretch}{1.1}
%   \tabcolsep=0.15cm
%   \begin{tabular}{ lcc cccc ccc}
%     \toprule
% \multirow{2}{*}{Method}&\multicolumn{6}{c}{Preference \((\uparrow)\)} & \multicolumn{3}{c}{Accuracy \((\uparrow)\)} \\ \Xcline{2-7 }{0.4pt}  \Xcline{ 8-10}{0.4pt} 
%  & \small{PrefHit@1} & \small{PrefHit@3} & \small{PrefRec@2} & \small{PrefRec@4} &\small{Reward1} &\small{Reward2}&\small{CodeSim}  & \small{BLEU}&\small{RougeL}   \\ \midrule
      

%         \(Scale=3k\) & 32.61 & 53.26 & 48.91 & 82.43 & 69.28 & 26.32 &26.45& 16.31 \\ 
%          \(Scale=8k\) & 25.72 & 42.49 & 41.30 & 81.25 & 68.63 & 24.90&23.33 & 11.41 \\ 
%          \(Scale=18k\) & 25.72 & 42.49 & 41.30 & 81.25 & 68.63 & 24.90&23.33 & 11.41 \\ 

%          \(Scale=29k\)& - & -& 41.30 & 81.25 & 68.63 & 24.90&23.33 & 11.41 \\ 
%          \(Scale=64k\) & - & 42.49 & 41.30 & 81.25 & 68.63 & 24.90&23.33 & 11.41 \\ 
%   \bottomrule
% \end{tabular}
% \end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[t]
\setlength{\tabcolsep}{3pt}
\centering
 \caption{Results of experiments on the different batch sizes \(size\) during training. }
\label{bs}
\renewcommand{\arraystretch}{1.13}
   \tabcolsep=0.15cm
% \resizebox{\textwidth}{3cm}{
\begin{tabular}{ lc ccc ccccc}
\toprule
\multirow{2}{*}{Method}&\multicolumn{6}{c}{Preference \((\uparrow)\)} & \multicolumn{3}{c}{Accuracy \((\uparrow)\)} \\ \Xcline{2-7 }{0.4pt}  \Xcline{ 8-10}{0.4pt} 
 & \small{PrefHit@1} & \small{PrefHit@3} & \small{PrefRec@2} & \small{PrefRec@4} &\small{Reward1} &\small{Reward2}&\small{CodeSim}  & \small{BLEU}&\small{RougeL}   \\ \midrule
       \( size=4\) & 0.3659 & 0.5326 & 0.5036 & 0.8279 & 0.2301 & 0.8233 & 0.6900 & 0.2079 & 0.1412 \\
        \( size=8\)& 0.3261 & 0.5471 & 0.5072 & 0.8225 & 0.2220 & 0.8369 & 0.6903 & 0.1603 & 0.2159 \\ 
   

         \(size=16\)& 0.3514 & 0.5326 & 0.4946 & 0.8225 & 0.2392 & 0.8294 & 0.6911 & 0.1571 & 0.2160 \\ 
       
        \(size=32\) & 0.2609 & 0.4275 & 0.4094 & 0.8107 & 0.4454 & 0.7396 & 0.6856 & 0.1326 & 0.1330 \\ 
      
        \(size=64\) & 0.2572 & 0.4384 & 0.4130 & 0.8116 & 0.4595 & 0.7448 & 0.6860 & 0.1372 & 0.1374 \\ 
       
        \(size=128\) & 0.2428 & 0.4167 & 0.4185 & 0.8125 & 0.4738 & 0.7464 & 0.6862 & 0.1364 & 0.1370 \\ 
       
  \bottomrule
\end{tabular}
\label{table::bs}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{latex/pic/stacocoqa.pdf}
    \caption{An example from the our proposed programming dataset StaCoCoQA.}
    \label{fig::stacocoqa}
\end{figure*}
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{latex/pic/gpt4.pdf}
    \caption{Rules for labeling StaCoCoQA testing data, whether manually or AI-assisted, consider semantic relevance, popularity, and creation time, with a time-decay adjustment applied to popularity.}
    \label{fig::gpt4}
\end{figure*}
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{latex/pic/hot1.pdf}
    \caption{The visualization of Attribute-Perceptual Distance Factors (APDF) for diifferent selected samples having five candidates. The blue represents the alignment target of the corresponding APDF. The green indicates that the second alignment target is suboptimal compared to the blue one. We have three key findings: (1) The alignment of the Multi-attribute Perceptual Distance Matrix \(\Delta_{M}\) could be the alignment target of the Semantic Perceptual Distance Matrix \(\Delta_{Se}\). (2) The alignment target of the \(\Delta_{M}\) could also be the alignment target of the Popularity Perceptual Distance Matrix \(\Delta_{Po}\). (3) The alignment target of the \(\Delta_{M}\) may neither be the alignment target of the \(\Delta_{Se}\) nor the \(\Delta_{Po}\).}
    \label{fig::hot1}
\end{figure*}
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{latex/pic/hot2.pdf}
    \caption{Visualization of the alignment target evolution for a sample throughout the training process. The orange represents the alignment target of the Semantic Perceptual Distance Matrix \(\Delta_{Se}\). The yellow represents the alignment target of the Popularity Perceptual Distance Matrix \(\Delta_{Po}\). The red represents the alignment target of the Multi-attribute Perceptual Distance Matrix \(\Delta_{M}\). We have two key findings. (1) At the same epoch, the alignment targets may differ across the Semantic Perceptual Distance Matrix \(\Delta_{Se}\), the Popularity Perceptual Distance Matrix \(\Delta_{Po}\), and the Multi-attribute Perceptual Distance Matrix \(\Delta_{M}\). (2) Across different epochs, the alignment targets for the same Attribute-Perceptual Distance Matrix may evolve.}
    \label{fig::hot2}
\end{figure*}



