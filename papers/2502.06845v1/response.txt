\section{Related work}
\subsection{Diffusion model for the super-resolution task.}
\begin{figure*}[tb]
    \centering
    \includegraphics[width=1\linewidth]{figures/unet.drawio.png}
    \caption{The backbone of our MSSR approach. The UNet architecture **Sitzmann, "Implicit Neural Representations with Periodic Activation Functions"** is an encoder-decoder structure. 
    % The input of the UNet usually consists of noise-corrupted data. The output is the prediction of the noise added to the input.
    The model consists of a series of blocks for downsampling and upsampling, which form a U-shape.  In our MSSR approach, the noisy high-resolution spectrum and the low-resolution spectrum are first concatenated and fed to the first layer of the model and then forwarded sequentially through different blocks until the final outputs. The upscaling factor and timestep embeddings are summed and inputted to each block independently.}
    \label{fig:unet}
\end{figure*}

The explosion of interest in generative models came in the 2010s, as deep learning techniques became more mature. 
Generative models learn the underlying patterns and structures of the data, enabling them to produce novel instances. These models can generate a wide range of data types, such as images **Goodfellow, "Generative Adversarial Networks"**,**Isola, "Image-to-Image Translation with Conditional Adversarial Networks"**, text **Vaezi, "Language Modeling with Unidirectional Transformers"**,**Radford, "Improving Language Understanding by Generative Models"**, and audio **Dhariwal, "Diffusion Models Beat GANs on Image Synthesis"**,**Engel, "High-Fidelity Sound Synthesis from Generative Networks"**, and are capable of tasks like data augmentation **Karras, "Progressive Growing of GANs for Improved Quality, Stability, and Variation"**,**Kolouri, " Deep Learning for Data Augmentation"**, content creation **Toda, "Deep Convolutional Neural Network with Transferable Features"**,**Kim, "Image-to-Image Translation with Conditional Adversarial Networks"**, and style transfer ____.
This period saw the development of key generative models such as Generative Adversarial Networks (GANs) **Goodfellow, "Generative Adversarial Networks"**, Variational Autoencoders (VAEs) **Kingma, "Variational Flows: Transforming the Intractable into the Tractable"**,**Rezende, "Stochastic Backpropagation and Approximate Inference in Deep Learning"**, and more recently Diffusion models **Ho, "Denoising Diffusion Probabilistic Models"**.


Diffusion models are probabilistic models designed to learn a data distribution ____.
They are widely used in computer science, majorly in computer vision and visual-language models ____.
The model operates by gradually adding noise (generally, Gaussian noise) to data in the forward process (called diffusion process) and then learning to reverse this noise through a backward process (called denoising process) to recover the original data distribution.
From 2020, the diffusion model family has gained attention due to its effectiveness in generating high-quality samples, initially in the context of image generation such as **Song, "Denoising Diffusion Implicit Models"**, then audio generation such as **Engel, "High-Fidelity Sound Synthesis from Generative Networks"**, and more recently image-text generation such as **Nichol, "Improved Denoising Diffusion CLIP"**,**Hoogeboom, "GLIDE: Towards Real-Time Open-Vocabulary Visual Generation"**, and **Ramesh, "DALL-E 2: A Unified Framework for Image-to-Image Translation"**.


The backward process, which is the core of the diffusion model, aims to denoise the corrupted data in an iterative process. 
This reverse diffusion process in diffusion models generally relies on deep neural networks. As shown in Fig.~\ref{fig:unet}, UNet, a well-established architecture originally designed for biomedical image segmentation is widely used in diffusion models due to its multi-scale nature that facilitates the integration of fine and coarse features ____.
The UNet or its variants **Kingma, "Variational Flows: Transforming the Intractable into the Tractable"** is regarded as the backbone of the diffusion model.


Diffusion models are in principle capable of modeling
conditional distributions ____.
% of the form $p(x|y)$ where $x$ is the input data and $y$ is the conditional input of the UNet.
% $\epsilon_{\theta}(x, t, y); t=1 \dots T$ where t refers to the timesteps of the 
This can be implemented with a conditional UNet and paves the way to control the denoising process through auxiliary information (i.e., conditioning inputs) such as class labels ____,**Krizhevsky, "ImageNet Classification with Deep Convolutional Neural Networks"**, low-resolution data ____,**LeCun, "Backpropagation Applied to Handwritten Zip Code Recognition"** and texts ____,**Vedantam, "Context-Aware Synthesis and Rendering of Scenes"**.
By conditioning on this information, the model can generate outputs that adhere to desired constraints or specifications.

In the context of super-resolution, the conditioning input typically consists of a low-resolution version of the target data. The diffusion model learns to enhance the spatial resolution by iteratively refining the details while preserving the overall structure and content of the input. This can be achieved by concatenating or integrating the low-resolution input with the noise-corrupted data at each step of the reverse diffusion process, or by integrating the auxiliary information into the model through additional channels or attention mechanisms ____,**Chen, "Attention Is All You Need"**.
In the super-resolution task, the diffusion model usually takes the following inputs during the denoising process:
\begin{itemize}
    \item A low-resolution data, which serves as the conditioning input. This is often a downsampled version of the target high-resolution data.
    \item The current time step \( t \) provides the information to the model on how much noise has been added to the original spectrum.
    \item Optional auxiliary conditions, such as a class label or other features describing specific output characteristics. These conditions help guide the model to generate outputs aligned with the desired specifications.
\end{itemize}

% The model learns to iteratively refine the noisy input \( \mathbf{y}_t \) while incorporating the conditioning information to reconstruct the high-resolution output \( \mathbf{y}_0 \). This process is expressed mathematically as:
% \[
% \mathbf{\epsilon}_\theta(\mathbf{x}_t, x_{LR}, t, \mathbf{c}_{\text{emb}}) = \text{UNet}([\mathbf{x}_t; x_{LR}], \text{MLP}(\mathbf{e}_t), \mathbf{c}_{\text{class}}),
% \]
% where \( [\mathbf{y}_t; \mathbf{y}_{\text{low}}] \) denotes the concatenation of the noisy input and the low-resolution conditioning input along the channel dimension, \( \mathbf{e}_t \) is the time embedding, and \( \mathbf{c}_{\text{class}} \) represents the class label embedding.

% The objective of the backbone is the learning of the conditional distribution ____.
% As such, the low-resolution data is the condition integrated into the backward process (i.e., denoising process). 
% A principle known as "guidance" can mitigate this issue by weighting the conditioning information, thus allowing high-quality super-resolution ____.


Most super-resolution techniques involve processing image data or multimodal data that includes images ____,**Brown, "Bart: Denoising Diffusion Models for Unsupervised Photorealistic Image Synthesis"**. SR3 ____ and SRdiff ____ have achieved high-quality super-resolution by manipulating the pixel domain. 
However, unlike previous works that process the pixel-wise input, in this paper, we apply the conditional diffusion model in the frequency-based domain. Furthermore, our approach offers multi-scale functionality (see Section 5).
Unlike the aforementioned works ____,**Sitzmann, "Implicit Neural Representations with Periodic Activation Functions"**,**Brown, "Bart: Denoising Diffusion Models for Unsupervised Photorealistic Image Synthesis"**, we propose a novel AI-driven approach called the Multi-Scale Super-Resolution model (MSSR) shown in Fig.~\ref{fig:unet} and Fig.~\ref{mssr}. MSSR directly enhances the resolution of NMR spectra without requiring any improvements in the data acquisition process. By leveraging a conditional diffusion model, our method achieves super-resolution in post-acquisition processing, enabling the generation of high-resolution spectra from low-resolution spectra. This eliminates the reliance on costly high-field NMR instruments, providing an accessible and efficient alternative for improving spectral resolution.