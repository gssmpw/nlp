[
  {
    "index": 0,
    "papers": [
      {
        "key": "openai-o1-mini",
        "author": "OpenAI",
        "title": "OpenAI o1-mini Advancing Cost-efficient Reasoning."
      },
      {
        "key": "openai-o1",
        "author": "OpenAI",
        "title": "Learning to reason with LLMs"
      },
      {
        "key": "jaech2024openai",
        "author": "Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others",
        "title": "Openai o1 system card"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "gemini-2",
        "author": "Google",
        "title": "Introducing Gemini 2.0: our new AI model for the agentic era"
      },
      {
        "key": "deepseek-r1",
        "author": "DeepSeek-AI",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      },
      {
        "key": "qwq",
        "author": "Qwen",
        "title": "Qwq: Reflect deeply on the boundaries of the unknown"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "hendrycks2021measuring",
        "author": "Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring mathematical problem solving with the math dataset"
      },
      {
        "key": "gsm8k",
        "author": "OpenAI",
        "title": "GSM8K"
      },
      {
        "key": "aime24",
        "author": "AI-MO",
        "title": "AIME 2024"
      },
      {
        "key": "amc23",
        "author": "AI-MO",
        "title": "AMC 2023"
      },
      {
        "key": "math500",
        "author": "OpenAI",
        "title": "Math-500"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "jain2024livecodebench",
        "author": "Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion",
        "title": "Livecodebench: Holistic and contamination free evaluation of large language models for code"
      },
      {
        "key": "humaneval",
        "author": "OpenAI",
        "title": "OpenAI HumanEval"
      },
      {
        "key": "codeforces",
        "author": "CodeForces",
        "title": "CodeForces Dataset"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "hendrycks2020measuring",
        "author": "Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring massive multitask language understanding"
      },
      {
        "key": "rein2023gpqa",
        "author": "Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R",
        "title": "Gpqa: A graduate-level google-proof q\\&a benchmark"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wang2024openr",
        "author": "Wang, Jun and Fang, Meng and Wan, Ziyu and Wen, Muning and Zhu, Jiachen and Liu, Anjie and Gong, Ziqin and Song, Yan and Chen, Lei and Ni, Lionel M and others",
        "title": "Openr: An open source framework for advanced reasoning with large language models"
      },
      {
        "key": "zhang2024rest",
        "author": "Zhang, Dan and Zhoubian, Sining and Hu, Ziniu and Yue, Yisong and Dong, Yuxiao and Tang, Jie",
        "title": "Rest-mcts*: Llm self-training via process reward guided tree search"
      },
      {
        "key": "zhang2024llama",
        "author": "Zhang, Di and Wu, Jianbo and Lei, Jingdi and Che, Tong and Li, Jiatong and Xie, Tong and Huang, Xiaoshui and Zhang, Shufei and Pavone, Marco and Li, Yuqiang and others",
        "title": "Llama-berry: Pairwise optimization for o1-like olympiad-level mathematical reasoning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "huang2024o1",
        "author": "Huang, Zhen and Zou, Haoyang and Li, Xuefeng and Liu, Yixiu and Zheng, Yuxiang and Chern, Ethan and Xia, Shijie and Qin, Yiwei and Yuan, Weizhe and Liu, Pengfei",
        "title": "O1 Replication Journey--Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?"
      },
      {
        "key": "huang2025o1replicationjourney",
        "author": "Zhongzhen Huang and Gui Geng and Shengyi Hua and Zhen Huang and Haoyang Zou and Shaoting Zhang and Pengfei Liu and Xiaofan Zhang",
        "title": "O1 Replication Journey -- Part 3: Inference-time Scaling for Medical Reasoning"
      },
      {
        "key": "skyt1",
        "author": "NovaSky",
        "title": "Sky-T1: Train your own O1 preview model within \\$450"
      },
      {
        "key": "min2024imitate",
        "author": "Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others",
        "title": "Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "cui2024process",
        "author": "Ganqu Cui and Lifan Yuan and Zefan Wang and Hanbin Wang and Wendi Li and Bingxiang He and Yuchen Fan and Tianyu Yu and Qixin Xu and Weize Chen and Jiarui Yuan and Huayu Chen and Kaiyan Zhang and Xingtai Lv and Shuo Wang and Yuan Yao and Hao Peng and Yu Cheng and Zhiyuan Liu and Maosong Sun and Bowen Zhou and Ning Ding",
        "title": "Process Reinforcement through Implicit Rewards"
      },
      {
        "key": "guan2025rstar",
        "author": "Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "kimi-k15",
        "author": "Kimi",
        "title": "Kimi k1.5: Scaling Reinforcement Learning with LLMs"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "deepseek-r1",
        "author": "DeepSeek-AI",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2024openr",
        "author": "Wang, Jun and Fang, Meng and Wan, Ziyu and Wen, Muning and Zhu, Jiachen and Liu, Anjie and Gong, Ziqin and Song, Yan and Chen, Lei and Ni, Lionel M and others",
        "title": "Openr: An open source framework for advanced reasoning with large language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zhang2024rest",
        "author": "Zhang, Dan and Zhoubian, Sining and Hu, Ziniu and Yue, Yisong and Dong, Yuxiao and Tang, Jie",
        "title": "Rest-mcts*: Llm self-training via process reward guided tree search"
      },
      {
        "key": "qin2024o1",
        "author": "Qin, Yiwei and Li, Xuefeng and Zou, Haoyang and Liu, Yixiu and Xia, Shijie and Huang, Zhen and Ye, Yixin and Yuan, Weizhe and Liu, Hector and Li, Yuanzhi and others",
        "title": "O1 Replication Journey: A Strategic Progress Report--Part 1"
      },
      {
        "key": "guan2025rstar",
        "author": "Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking"
      },
      {
        "key": "jiang2024technical",
        "author": "Jiang, Jinhao and Chen, Zhipeng and Min, Yingqian and Chen, Jie and Cheng, Xiaoxue and Wang, Jiapeng and Tang, Yiru and Sun, Haoxiang and Deng, Jia and Zhao, Wayne Xin and others",
        "title": "Technical Report: Enhancing LLM Reasoning with Reward-guided Tree Search"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhang2024llama",
        "author": "Zhang, Di and Wu, Jianbo and Lei, Jingdi and Che, Tong and Li, Jiatong and Xie, Tong and Huang, Xiaoshui and Zhang, Shufei and Pavone, Marco and Li, Yuqiang and others",
        "title": "Llama-berry: Pairwise optimization for o1-like olympiad-level mathematical reasoning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      },
      {
        "key": "wu2024empirical",
        "author": "Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming",
        "title": "An empirical analysis of compute-optimal inference for problem-solving with language models"
      },
      {
        "key": "brown2024large",
        "author": "Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\\'e}, Christopher and Mirhoseini, Azalia",
        "title": "Large language monkeys: Scaling inference compute with repeated sampling"
      },
      {
        "key": "beeching2024scalingtesttimecompute",
        "author": "Edward Beeching and Lewis Tunstall and Sasha Rush",
        "title": "Scaling test-time compute with open models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "muennighoff2025s1",
        "author": "Muennighoff, Niklas and Yang, Zitong and Shi, Weijia and Li, Xiang Lisa and Fei-Fei, Li and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Liang, Percy and Cand{\\`e}s, Emmanuel and Hashimoto, Tatsunori",
        "title": "s1: Simple test-time scaling"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "hou2025advancing",
        "author": "Hou, Zhenyu and Lv, Xin and Lu, Rui and Zhang, Jiajie and Li, Yujiang and Yao, Zijun and Li, Juanzi and Tang, Jie and Dong, Yuxiao",
        "title": "Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "kang2024mindstar",
        "author": "Kang, Jikun and Li, Xin Zhe and Chen, Xi and Kazemi, Amirreza and Sun, Qianyi and Chen, Boxing and Li, Dong and He, Xu and He, Quan and Wen, Feng and others",
        "title": "Mindstar: Enhancing math reasoning in pre-trained llms at inference time"
      },
      {
        "key": "wang2024q",
        "author": "Wang, Chaojie and Deng, Yanchen and Lyu, Zhiyi and Zeng, Liang and He, Jujie and Yan, Shuicheng and An, Bo",
        "title": "Q*: Improving multi-step reasoning for llms with deliberative planning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yao2024tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      },
      {
        "key": "hao2023reasoning",
        "author": "Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting",
        "title": "Reasoning with language model is planning with world model"
      },
      {
        "key": "zhang2024accessing",
        "author": "Zhang, Di and Li, Jiatong and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli",
        "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B"
      },
      {
        "key": "qi2024mutual",
        "author": "Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao",
        "title": "Mutual reasoning makes smaller llms stronger problem-solvers"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "smoke1961program",
        "author": "Smoke, W and Dubinsky, E",
        "title": "A program for the machine translation of natural languages."
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "su2024dualformer",
        "author": "Su, DiJia and Sukhbaatar, Sainbayar and Rabbat, Michael and Tian, Yuandong and Zheng, Qinqing",
        "title": "Dualformer: Controllable fast and slow thinking by learning with randomized reasoning traces"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "bai2024longwriter",
        "author": "Bai, Yushi and Zhang, Jiajie and Lv, Xin and Zheng, Linzhi and Zhu, Siqi and Hou, Lei and Dong, Yuxiao and Tang, Jie and Li, Juanzi",
        "title": "Longwriter: Unleashing 10,000+ word generation from long context llms"
      },
      {
        "key": "abdin2024phi",
        "author": "Abdin, Marah and Aneja, Jyoti and Behl, Harkirat and Bubeck, S{\\'e}bastien and Eldan, Ronen and Gunasekar, Suriya and Harrison, Michael and Hewett, Russell J and Javaheripi, Mojan and Kauffmann, Piero and others",
        "title": "Phi-4 technical report"
      },
      {
        "key": "min2024imitate",
        "author": "Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others",
        "title": "Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems"
      },
      {
        "key": "huang2024o1",
        "author": "Huang, Zhen and Zou, Haoyang and Li, Xuefeng and Liu, Yixiu and Zheng, Yuxiang and Chern, Ethan and Xia, Shijie and Qin, Yiwei and Yuan, Weizhe and Liu, Pengfei",
        "title": "O1 Replication Journey--Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?"
      },
      {
        "key": "qin2024o1",
        "author": "Qin, Yiwei and Li, Xuefeng and Zou, Haoyang and Liu, Yixiu and Xia, Shijie and Huang, Zhen and Ye, Yixin and Yuan, Weizhe and Liu, Hector and Li, Yuanzhi and others",
        "title": "O1 Replication Journey: A Strategic Progress Report--Part 1"
      },
      {
        "key": "wang2024enhancing",
        "author": "Wang, Weiyun and Chen, Zhe and Wang, Wenhai and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Zhu, Jinguo and Zhu, Xizhou and Lu, Lewei and Qiao, Yu and others",
        "title": "Enhancing the reasoning ability of multimodal large language models via mixed preference optimization"
      },
      {
        "key": "xu2024llava",
        "author": "Xu, Guowei and Jin, Peng and Hao, Li and Song, Yibing and Sun, Lichao and Yuan, Li",
        "title": "LLaVA-o1: Let Vision Language Models Reason Step-by-Step"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "li2024numinamath",
        "author": "Li, Jia and Beeching, Edward and Tunstall, Lewis and Lipkin, Ben and Soletskyi, Roman and Huang, Shengyi and Rasul, Kashif and Yu, Longhui and Jiang, Albert Q and Shen, Ziju and others",
        "title": "Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions"
      },
      {
        "key": "luo2023wizardmath",
        "author": "Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei",
        "title": "Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct"
      },
      {
        "key": "yu2023metamath",
        "author": "Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang",
        "title": "Metamath: Bootstrap your own mathematical questions for large language models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "qwq-longcot",
        "author": "Qwen",
        "title": "QwQ-LongCoT-130K-cleaned"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "guan2025rstar",
        "author": "Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking"
      },
      {
        "key": "zhang2024rest",
        "author": "Zhang, Dan and Zhoubian, Sining and Hu, Ziniu and Yue, Yisong and Dong, Yuxiao and Tang, Jie",
        "title": "Rest-mcts*: Llm self-training via process reward guided tree search"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "yuan2023scaling",
        "author": "Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Lu, Keming and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren",
        "title": "Scaling relationship on learning mathematical reasoning with large language models"
      },
      {
        "key": "brown2024large",
        "author": "Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\\'e}, Christopher and Mirhoseini, Azalia",
        "title": "Large language monkeys: Scaling inference compute with repeated sampling"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "simplerl",
        "author": "Zeng, Weihao and  Huang, Yuzhen and Liu, Wei and He, Keqing and Liu, Qian and Ma, Zejun and He, Junxian",
        "title": "7B Model and 8K Examples: Emerging Reasoning with Reinforcement Learning is Both Effective and Efficient"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "open-r1",
        "author": "Bakouch, Elie and von Werra, Leandro and Tunstall, Lewis",
        "title": "Open-R1: a fully open reproduction of DeepSeek-R1"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "yeo2025demystifying",
        "author": "Yeo, Edward and Tong, Yuxuan and Niu, Morry and Neubig, Graham and Yue, Xiang",
        "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "xiang2025towards",
        "author": "Xiang, Violet and Snell, Charlie and Gandhi, Kanishk and Albalak, Alon and Singh, Anikait and Blagden, Chase and Phung, Duy and Rafailov, Rafael and Lile, Nathan and Mahan, Dakota and others",
        "title": "Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "min2024imitate",
        "author": "Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others",
        "title": "Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems"
      },
      {
        "key": "qu2024recursive",
        "author": "Qu, Yuxiao and Zhang, Tianjun and Garg, Naman and Kumar, Aviral",
        "title": "Recursive introspection: Teaching language model agents how to self-improve"
      },
      {
        "key": "zhang2024small",
        "author": "Zhang, Yunxiang and Khalifa, Muhammad and Logeswaran, Lajanugen and Kim, Jaekyeom and Lee, Moontae and Lee, Honglak and Wang, Lu",
        "title": "Small Language Models Need Strong Verifiers to Self-Correct Reasoning"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "huang2023large",
        "author": "Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny",
        "title": "Large language models cannot self-correct reasoning yet"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "zhang2024accessing",
        "author": "Zhang, Di and Li, Jiatong and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli",
        "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B"
      },
      {
        "key": "yang2024qwen2",
        "author": "Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others",
        "title": "Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement"
      },
      {
        "key": "tian2024toward",
        "author": "Tian, Ye and Peng, Baolin and Song, Linfeng and Jin, Lifeng and Yu, Dian and Mi, Haitao and Yu, Dong",
        "title": "Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing"
      },
      {
        "key": "wang2024towards",
        "author": "Wang, Xiyao and Song, Linfeng and Tian, Ye and Yu, Dian and Peng, Baolin and Mi, Haitao and Huang, Furong and Yu, Dong",
        "title": "Towards Self-Improvement of LLMs via MCTS: Leveraging Stepwise Knowledge with Curriculum Preference Learning"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "kumar2024training",
        "author": "Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others",
        "title": "Training language models to self-correct via reinforcement learning"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "yang2024qwen2",
        "author": "Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others",
        "title": "Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement"
      },
      {
        "key": "choi2024self",
        "author": "Choi, Eugene and Ahmadian, Arash and Geist, Matthieu and Pietquin, Oilvier and Azar, Mohammad Gheshlaghi",
        "title": "Self-Improving Robust Preference Optimization"
      },
      {
        "key": "kumar2024training",
        "author": "Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others",
        "title": "Training language models to self-correct via reinforcement learning"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "wang2024towards",
        "author": "Wang, Xiyao and Song, Linfeng and Tian, Ye and Yu, Dian and Peng, Baolin and Mi, Haitao and Huang, Furong and Yu, Dong",
        "title": "Towards Self-Improvement of LLMs via MCTS: Leveraging Stepwise Knowledge with Curriculum Preference Learning"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "jaderberg2016reinforcement",
        "author": "Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray",
        "title": "Reinforcement learning with unsupervised auxiliary tasks"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "havrilla2024teaching",
        "author": "Havrilla, Alex and Du, Yuqing and Raparthy, Sharath Chandra and Nalmpantis, Christoforos and Dwivedi-Yu, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Sukhbaatar, Sainbayar and Raileanu, Roberta",
        "title": "Teaching large language models to reason with reinforcement learning"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "setlur2024rewarding",
        "author": "Setlur, Amrith and Nagpal, Chirag and Fisch, Adam and Geng, Xinyang and Eisenstein, Jacob and Agarwal, Rishabh and Agarwal, Alekh and Berant, Jonathan and Kumar, Aviral",
        "title": "Rewarding progress: Scaling automated process verifiers for llm reasoning"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "luo2023wizardmath",
        "author": "Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei",
        "title": "Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct"
      }
    ]
  }
]