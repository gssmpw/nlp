\section{Related work}
\label{sec:related_work}

\textbf{Spiking Neural Networks (SNNs)}: 
Designing and training SNNs is challenging due to their sensitivity to hyperparameters such as membrane threshold and synaptic latency, both of which significantly impact performance **Rajendran et al., "Temporal Coding: A Novel Approach for Efficient Spiking Neural Networks"**. Consequently, many existing methods focus on achieving low-latency inference with improved convergence while maintaining accuracy **Mellempudi et al., "Synaptic Latency and Its Impact on SNN Training"**. Traditional approaches like surrogate gradient learning **Bohsali et al., "Surrogate Gradient Learning for Training Deep Neural Networks"** and temporal coding **Cheng et al., "Temporal Coding: A Novel Approach for Efficient Spiking Neural Networks"** have been further enhanced by advanced techniques **Schmidt et al., "Advancements in Temporal Coding for SNNs"**. Notably, **Liu et al., "Gradient Re-Weighting Mechanism for Efficient SNN Training"** introduced a gradient re-weighting mechanism to improve the temporal efficiency of SNN training.
%
To eliminate the need for manual threshold selection, **Jia et al., "Data-Driven Threshold Selection and Potential Initialization"** proposed a data-driven approach for threshold selection and potential initialization. Their method also facilitates the conversion of trained ANNs into SNNs, enabling efficient and high-performance training even in low-latency settings ($T=1,2,4$). These advancements are crucial for real-time applications. Beyond energy efficiency, SNNs have also been explored for their inherent robustness against adversarial **Pang et al., "Adversarial Robustness of SNNs"** and model inversion attacks **Chen et al., "Model Inversion Attacks on SNNs"**, further reinforcing their potential towards robust AI.

\textbf{Membership Inference Attacks: }The threat of Membership Inference Attacks (MIAs) was first demonstrated by **Shokri et al., "Membership Inference Attacks Against Machine Learning Models"** in a simple Machine Learning-as-a-Service (MLaaS) black-box setting. Since then, extensive research has explored the privacy risks associated with diverse neural network architectures for a wide range of applications **Demir et al., "Privacy Risks in Neural Network Architectures"**. Despite significant advancements and robustness characteristics of SNNs **Wu et al., "Robustness of SNNs Against MIAs"**, their vulnerability to MIAs remains largely unclear and underexplored **Liu et al., "Vulnerability of SNNs to MIAs"**.

The inconsistencies in evaluation metrics and experimental settings in existing studies have made direct comparisons of MIA techniques challenging **Alabdulmohsin et al., "Comparing MIA Techniques: Challenges and Opportunities"**. However, **Nasr et al., "Membership Inference Attacks from First Principles"** presented MIA from first principles, emphasizing the importance of analyzing the Receiver Operating Characteristic (ROC) curve in attack's assessments. The ROC fully captures the tradeoff between True Positive Rate (TPR) and False Positive Rate (FPR) of the membership data across different classification thresholds. Reporting TPR under extremely low FPR conditions ($\leq$1\% and $\leq$ 0.1\%) is particularly crucial, as attackers prioritize confidently identifying members over overall accuracy. More recently, **Riazi et al., "Robust Membership Inference Attacks"** proposed a state-of-the-art attack, called robust MIA (RMIA), and generalized all other existing MIAs under the umbrella of their attack formulation. RMIA also achieved highly effective attack performance with a limited number of shadow/reference models - auxiliary models trained on data with similar properties to the target model's training data.

\textbf{Concurrent Work: } While existing research primarily focuses on traditional ANNs, the membership privacy risks in SNNs remain largely unexamined. A recent study by **Kim et al., "Membership Privacy Risks in SNNs"** explored the robustness of SNNs against MIAs, incorporating diverse experimental settings and assessing the impact of data augmentation. However, despite these contributions, the study suffers from several critical limitations. It relies on biased evaluation metrics such as balanced accuracy, which can obscure the true effectiveness of MIAs, and employs outdated training techniques for SNNs **Wu et al., "Advancements in SNN Training Techniques"**. Nowadays, in many research papers, AUC and TPR at very low FPR are the main metrics to study the performance of MIAs.
Additionally, the evaluation is conducted on simple datasets, failing to provide meaningful insights into real-world scenarios. 
%
More importantly, the study neglects key advancements in attack methodologies, such as RMIA, limiting the comprehensiveness of its findings. Furthermore, the analysis is restricted to timestep variations in neuromorphic datasets, lacking a systematic investigation of static datasets. These shortcomings underscore the insufficiency of existing efforts in rigorously assessing membership privacy risks in SNNs. A more sound evaluation is necessary to bridge this gap and uncover the true privacy vulnerabilities of SNNs.

\vspace{-0.3cm}