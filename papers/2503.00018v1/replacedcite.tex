\section{Related Work}
\paragraph{LLM-Based Patient Simulation in Mental Health.} 
Recent work has explored using LLMs to simulate therapy clients for clinician training ____. Early approaches relied on generic LLM prompting ____, but concerns about clinical validity and ethical risks ____ have led to structured modeling efforts. Patient-$\psi$ ____ integrates cognitive modeling from clinical frameworks to enhance realism, while Roleplay-doh ____ applies principle-adherence prompting to improve consistency. However, these methods struggle with generating nuanced, profile-consistent responses, highlighting the need for systematic alignment strategies.

\paragraph{Preference Optimization for Alignment.}
Optimizing LLMs with human preference data has been widely studied ____, with Direct Preference Optimization (DPO) emerging as an efficient alternative to reinforcement learning ____. While DPO has been applied in general chatbot alignment and some scientific domains ____, its use in simulation for clinical psychology practice remains underexplored. Recent methods propose augmenting preference data through automated techniques ____, which aligns with our approach of leveraging model-based augmentation to enhance preference learning for profile-guided mental health simulations.