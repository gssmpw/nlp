\documentclass[conference]{IEEEtran}
\usepackage{times}

% numbers option provides compact numerical references in the text. 
\usepackage[numbers]{natbib}
\usepackage{multicol}

\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amssymb}


\usepackage{booktabs}
\usepackage{color}
\usepackage{amsmath,bm}
\usepackage{multirow}
\usepackage{float}
\usepackage{subcaption} % 提供子标题功能
\usepackage{tabularray}
\usepackage{array}
\usepackage{pifont}
\let\labelindent\relax
\usepackage{enumitem}
\usepackage{colortbl}
\usepackage{algorithm}
\usepackage{makecell}
\usepackage{float} 
\usepackage{comment}
\usepackage{adjustbox}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[bookmarks=true,pagebackref,breaklinks,colorlinks]{hyperref}

\newcommand{\boldparagraph}[1]{
    \refstepcounter{boldpara}
    \vspace{0.1em}\noindent{\bf #1}
}
\pdfinfo{
   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

\begin{document}


% paper title
\title{\textbf{\emph{OpenFly}}: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation}

% You will get a Paper-ID when submitting a pdf file to the conference system
\author{Yunpeng Gao$^{1,2*}$, Chenhui Li$^{1*}$, Zhongrui You$^{1,3*}$, Junli Liu$^{1,2*}$, Zhen Li$^{1,4*}$, Pengan CHEN$^{1,5}$, \\
Qizhi Chen$^{1,6}$, Zhonghan Tang$^{1,7}$, Liansheng Wang$^{1}$, Penghui Yang$^{1,8}$, Yiwen Tang$^{1,2}$, Yuhang Tang$^{1,2}$, \\
Shuai Liang$^{1,9}$, Songyi Zhu$^{1}$, Ziqin Xiong$^{1,4}$, Yifei Su$^{1,10}$, Xinyi Ye$^{1}$, Jianan Li$^{1}$, \\ Yan Ding$^{1}$, 
Dong Wang$^{1}$, Zhigang Wang$^{1 ^{\dagger}}$, Bin Zhao$^{1,2 ^{\dagger}}$, Xuelong Li$^{1,11}$
\\
$^1$Shanghai AI Laboratory, 
$^2$Northwestern Polytechnical University, \\
$^3$Beijing University of Posts and Telecommunications, 
$^4$Shanghai Jiao Tong University, \\
$^5$The University of Hong Kong,
$^6$Zhejiang University,  \\
$^7$University of Science and Technology of China, \\
$^8$East China University of Science and Technology, 
$^9$Fudan University, \\
$^{10}$Institute of Automation, Chinese Academy of Sciences,
$^{11}$TeleAI 
\\
$^*$Equal Contribution, $^{\dagger}$Corresponding Author
\\
\url{https://shailab-ipec.github.io/openfly/}
}

%\maketitle

\twocolumn[
{%
\renewcommand\twocolumn[1][]{#1}
\maketitle
\begin{center}
\centering
\begin{minipage}[t]{\linewidth}
\vspace{-0.8cm}
{\captionsetup{type=figure}  
\includegraphics[width=\textwidth]{Fig/OpenFly.pdf}
\captionof{figure}{\footnotesize{{
Overview of OpenFly. This work consists of an automatic toolchain for data generation, a large-scale aerial VLN dataset comprising 100K trajectories and instructions, and a keyframe-aware VLN model emphasizing key observations.
}}}
\label{fig:OpenFly}}
\end{minipage}
\end{center}
}]



\begin{abstract}
Vision-Language Navigation (VLN) aims to guide agents through an environment by leveraging both language instructions and visual cues, playing a pivotal role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial view encompasses vast areas, making data collection more challenging, which results in a lack of benchmarks. To address this problem, we propose \textit{OpenFly}, a platform comprising a versatile toolchain and large-scale benchmark for aerial VLN. Firstly, we develop a highly automated toolchain for data collection, enabling automatic point cloud acquisition, scene semantic segmentation, flight trajectory creation, and instruction generation. Secondly, based on the toolchain, we construct a large-scale aerial VLN dataset with 100k trajectories, covering diverse heights and lengths across 18 scenes. The corresponding visual data are generated using various rendering engines and advanced techniques, including Unreal Engine, GTA V, Google Earth, and 3D Gaussian Splatting (3D GS). All data exhibit high visual quality. Particularly, 3D GS supports real-to-sim rendering, further enhancing the realism of the dataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, which takes language instructions, current observations, and historical keyframes as input, and outputs flight actions directly. Extensive analyses and experiments are conducted, showcasing the superiority of our OpenFly platform and OpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.
\end{abstract}

\IEEEpeerreviewmaketitle

\input{sec/1_introduction}
\input{sec/2_related_work}
\input{sec/3_Dataset}
\input{sec/4_Methodology}
\input{sec/5_Experiments}
\input{sec/6_Conclusion}
%\input{sec/supp}
\bibliographystyle{plainnat}
%\bibliography{references}
\bibliography{BibForOpenFly}

\end{document}


