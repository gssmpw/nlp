\section{Details of 3D GS Data Collection}
From the drone's perspective, choosing the appropriate shooting altitude poses a dilemma, \emph{i.e.,} if the altitude is too low, the sparse point cloud generated during the initialization of the 3D GS reconstruction will be suboptimal, due to insufficient feature point matches between photos. In contrast, if the altitude is too high, the Gaussian reconstruction will result in an overly coarse training of details. After multiple attempts, the data collection plan using the M30T was determined as follows. For large-scale block scenes, oblique photography is performed at approximately twice the average building height using the default parameters of the M30T’s wide-angle camera, with a tilt angle of -45°. For landmark buildings with heights significantly different from the average height, additional targeted data collection is conducted at twice their height. This altitude setting can, to a certain extent, ensure both higher-quality point cloud initialization and Gaussian splatting training.


\section{Details of Instruction Generation}

Except for the instruction generation described in the main paper. The remaining process is mainly divided into two parts: landmark feature extraction and sub-instruction fusion. A simplified prompt to the VLM and corresponding response are probably like this.

\begin{itemize}[left=0pt]
    \item Get Landmark features. \\
    \textbf{System Prompt}: You are an assistant who is proficient in image recognition. You can accurately identify the object in the picture and its characteristics that are different from the surrounding objects. I will give you the three final images you will see. Please focus on the last image and tell me the features of the target building and reply to me in the form of JSON.

    \textbf{User}: The target building is at info`aim-landmark' of the image. Answer me a dictionary like color:--, feature: --, size: --, type: --.

    \textbf{GPT 4o}: color: blue, feature: Steel, glass, size: medium size, type: building.

    \item Instruction Fusion. \\
    \textbf{System Prompt}: You are an assistant proficient in text processing. You need to help me combine these scattered actions and landmarks into a sentence using words with similar meanings and more appropriate words, making them smooth, fluent, and accurate. If the landmarks of adjacent actions are similar or even identical, please use pronouns to refer to them.

    \textbf{User}: Multiple sub-instructions.

    \textbf{GPT 4o}: Move forward and slightly turn left to a high-rise building with a noticeable logo at the top. Then turn left and go straight to a futuristic tower with a large spherical structure in the middle.
\end{itemize}

\begin{comment}
\textbf{Get Landmark} 

\textbf{System}:You are an assistant who is proficient in image recognition. You can accurately identify the object in the picture and its characteristics that are different from the surrounding objects. I will give you the three final images you will see. Please focus on the last image and tell me the features of the target building and reply to me in the form of JSON.

\textbf{User}: The target building is at info'aim-landmark' of the image. Answer me a dictionary like color:--, feature: --, size: --, type: --.

\textbf{GPT 4o}: color: blue, feature: Steel, glass, size: medium size, type: building.



\textbf{Get Instruction }

\textbf{System}:You are an assistant proficient in text processing. You need to help me combine these scattered actions and landmarks into a sentence using words with similar meanings and more appropriate words, making them smooth, fluent, and accurate. If the landmarks of adjacent actions are similar or even identical, please use pronouns to refer to them.

\textbf{User}: Data: actions

\textbf{GPT 4o}: Move forward and slightly turn left to a high-rise building with a noticeable logo at the top. Then turn left and go straight to a futuristic tower with a large spherical structure in the middle.
\end{comment}

\section{Qualitative Results}
Fig.~\ref{fig:success_case} presents another successful aerial VLN example in a 3D GS scene. The image style, flight heights, and viewpoints are significantly different from UE's scenarios. In this case, our OpenFly-Agent exhibits robustness to handle data with great diversity. 


\begin{figure*}[t]
\centering
    \includegraphics[width=0.98\linewidth]{Fig/success_case.pdf}
    \caption{Illustration of aerial VLN trajectories generated by OpenFly-Agent.}
    \label{fig:success_case}
\end{figure*}
