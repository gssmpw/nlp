% This version of CVPR template is provided by Ming-Ming Cheng.
% Please leave an issue if you found a bug:
% https://github.com/MCG-NKU/CVPR_Template.

\documentclass[review]{cvpr}
%\documentclass[final]{cvpr}
%\documentclass[review]{IEEEtran}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}


\usepackage{booktabs}
\usepackage{color}
\usepackage{amsmath,bm}
\usepackage{multirow}
\usepackage{float}
\usepackage{subcaption} % 提供子标题功能
\usepackage{tabularray}
\usepackage{pifont}
\usepackage{enumitem}
\usepackage{colortbl}
\usepackage{algorithm}
\usepackage{makecell}
\usepackage{float} 
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\confName{ICCV}
\def\confYear{2025}
\graphicspath{{./figs/}}
%\setcounter{page}{4321} % For final version only


\begin{document}

%%%%%%%%% TITLE
\title{OpenFly: A Versatile Toolchain and a High-Quality Benchmark for Aerial Vision-and-Language Navigation}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle


%%%%%%%%% ABSTRACT
\begin{abstract}
Vision-and-language navigation (VLN) seeks to guide agents through complex environments using language instructions and visual cues, playing a critical role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial perspectives cover vast scene areas, making data collection challenging, which in turn leads to a lack of corresponding benchmarks. To address this problem, we propose \textbf{OpenFly}, a platform comprising a versatile toolchain and a high-quality benchmark for aerial VLN. \textbf{First}, we develop a highly automated toolchain for data generation, enabling automatic scene semantic extraction, point cloud acquisition, flight trajectory creation, and instruction generation, thus significantly improving efficiency. \textbf{Second}, based on the developed toolchain, we construct a large-scale aerial VLN dataset with \textbf{100k} trajectories, covering samples of diverse heights and difficulty levels across 16 distinct scenes. The corresponding visual data are generated using various rendering engines or techniques, including Unreal Engine (UE), GTA5, Google Earth, and 3D Gaussian Splatting (3D GS). All data feature high visual quality, with 3D GS supporting real-to-sim rendering, further enhancing the realism of the dataset. \textbf{Third}, we propose a keyframe-aware vision-language-action (VLA) model to directly output flight actions based on instructions, current observations, and key histories. Extensive experiments are conducted to evaluate the proposed model and comparison methods, establishing a comprehensive benchmark for aerial VLN. The toolchain, dataset, and codes will be available upon the acceptance of the paper.
%at \url{openfly.github.io}. 
\end{abstract}

%%%%%%%%% BODY TEXT
\input{sec/1_introduction}
\input{sec/2_related_work}
\input{sec/3_Dataset}
\input{sec/4_Methodology}
\input{sec/5_Experiments}
\input{sec/6_Conclusion}


{\small
\bibliographystyle{ieee_fullname}
\bibliography{BibForOpenFly}
}

\end{document}
