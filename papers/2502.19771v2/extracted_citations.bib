@article{Bossert2021,
   abstract = {Artificial intelligence (AI) technologies and their fields of application are among the most debated developments of recent times. Although being widely discussed academically, publicly and in policy debates, certain aspects of their research, development and application are completely ignored, namely the impact AI has on animals. Animals are affected by the research on and development of this technology since it partially relies on animal testing. In addition, AI is also being applied to improve monitoring and marketing of animals in an agricultural context. We argue that it is insufficient to exclude these aspects from debates around AI. In addition to the surveillance-applications on animals, which can be evaluated as impacting them negatively, AI applications, from which individual animals can benefit, do exist. These can primarily be found in nature and wildlife conservation, as we point out at the end of the paper. By providing an overview on how these technologies are applied to animals and how this affects them, this paper aims to fill a previously existing research gap.},
   author = {Leonie Bossert and Thilo Hagendorff},
   doi = {10.1016/j.techsoc.2021.101678},
   issn = {0160791X},
   journal = {Technology in Society},
   keywords = {AI for Conservation,Animal ethics,Animal experiments,Artificial intelligence,Machine learning},
   month = {11},
   publisher = {Elsevier Ltd},
   title = {Animals and AI. The role of animals in AI research and application – An overview and ethical evaluation},
   volume = {67},
   year = {2021},
}

@article{Coghlan2023,
   abstract = {This paper provides a systematic account of how artificial intelligence (AI) technologies could harm nonhuman animals and explains why animal harms, often neglected in AI ethics, should be better recognised. After giving reasons for caring about animals and outlining the nature of animal harm, interests, and wellbeing, the paper develops a comprehensive ‘harms framework’ which draws on scientist David Fraser’s influential mapping of human activities that impact on sentient animals. The harms framework is fleshed out with examples inspired by both scholarly literature and media reports. This systematic account and framework should help inform ethical analyses of AI’s impact on animals and serve as a comprehensive and clear basis for the development and regulation of AI technologies to prevent and mitigate harm to nonhumans.},
   author = {Simon Coghlan and Christine Parker},
   doi = {10.1007/s13347-023-00627-6},
   issn = {22105441},
   issue = {2},
   journal = {Philosophy and Technology},
   keywords = {Animal welfare,Artificial intelligence,Big data,Nonhuman animal ethics,Precision agriculture},
   month = {6},
   publisher = {Springer Science and Business Media B.V.},
   title = {Harm to Nonhuman Animals from AI: a Systematic Account and Framework},
   volume = {36},
   year = {2023},
}

@article{Hagendorff2022,
   abstract = {This paper critically discusses blind spots in AI ethics. AI ethics discourses typically stick to a certain set of topics concerning principles evolving mainly around explainability, fairness, and privacy. All these principles can be framed in a way that enables their operationalization by technical means. However, this requires stripping down the multidimensionality of very complex social constructs to something that is idealized, measurable, and calculable. Consequently, rather conservative, mainstream notions of the mentioned principles are conveyed, whereas critical research, alternative perspectives, and non-ideal approaches are largely neglected. Hence, one part of the paper considers specific blind spots regarding the very topics AI ethics focusses on. The other part, then, critically discusses blind spots regarding to topics that hold significant ethical importance but are hardly or not discussed at all in AI ethics. Here, the paper focuses on negative externalities of AI systems, exemplarily discussing the casualization of clickwork, AI ethics’ strict anthropocentrism, and AI’s environmental impact. Ultimately, the paper is intended to be a critical commentary on the ongoing development of the field of AI ethics. It makes the case for a rediscovery of the strength of ethics in the AI field, namely its sensitivity to suffering and harms that are caused by and connected to AI technologies.},
   author = {Thilo Hagendorff},
   doi = {10.1007/s43681-021-00122-8},
   issn = {2730-5953},
   issue = {4},
   journal = {AI and Ethics},
   month = {11},
   pages = {851-867},
   publisher = {Springer Science and Business Media LLC},
   title = {Blind spots in AI ethics},
   volume = {2},
   year = {2022},
}

@article{Hagendorff2023,
   abstract = {Massive efforts are made to reduce biases in both data and algorithms to render AI applications fair. These efforts are propelled by various high-profile cases where biased algorithmic decision-making caused harm to women, people of color, minorities, etc. However, the AI fairness field still succumbs to a blind spot, namely its insensitivity to discrimination against animals. This paper is a critical comment on current fairness research in AI. It is the first to describe the ‘speciesist bias’ and investigate it in several different AI systems by reflecting on the problem via a normative analysis and by probing, in several case studies, image recognition, word embedding, and language models with established methods for bias detection. We claim that animals matter morally and that discriminating against them is unethical. Furthermore, we provide evidence for speciesist biases in all the mentioned areas of AI. We find that speciesist biases are solidified by many mainstream AI applications, especially in the fields of computer vision as well as natural language processing. In both cases, this occurs because the models are trained on datasets in which speciesist patterns prevail. Therefore, AI technologies currently play a significant role in perpetuating and normalizing violence against animals. To change this, AI fairness frameworks must widen their scope and include mitigation measures for speciesist biases. This paper addresses the AI community in this regard and stresses the influence AI systems can have on either increasing or reducing the violence that is inflicted on animals, especially on farmed animals.},
   author = {Thilo Hagendorff and Leonie N. Bossert and Yip Fai Tse and Peter Singer},
   doi = {10.1007/s43681-022-00199-9},
   issn = {2730-5953},
   issue = {3},
   journal = {AI and Ethics},
   month = {8},
   pages = {717-734},
   publisher = {Springer Science and Business Media LLC},
   title = {Speciesist bias in AI: how AI applications perpetuate discrimination and unfair outcomes against animals},
   volume = {3},
   year = {2023},
}

@book{Singer1975,
   author = {Peter Singer},
   pages = {1-23},
   publisher = {HarperCollins},
   title = {Animal Liberation},
   year = {1975},
}

@article{Singer2023,
   abstract = {The ethics of artificial intelligence, or AI ethics, is a rapidly growing field, and rightly so. While the range of issues and groups of stakeholders concerned by the field of AI ethics is expanding, with speculation about whether it extends even to the machines themselves, there is a group of sentient beings who are also affected by AI, but are rarely mentioned within the field of AI ethics—the nonhuman animals. This paper seeks to explore the kinds of impact AI has on nonhuman animals, the severity of these impacts, and their moral implications. We hope that this paper will facilitate the development of a new field of philosophical and technical research regarding the impacts of AI on animals, namely, the ethics of AI as it affects nonhuman animals.},
   author = {Peter Singer and Yip Fai Tse},
   doi = {10.1007/s43681-022-00187-z},
   issn = {2730-5953},
   issue = {2},
   journal = {AI and Ethics},
   month = {5},
   pages = {539-551},
   publisher = {Springer Science and Business Media LLC},
   title = {AI ethics: the case for including animals},
   volume = {3},
   year = {2023},
}

@article{Ziesche2021,
   abstract = {This article is about a specific, but so far neglected peril of AI, which is that AI systems may become existential as well as causing suffering risks for nonhuman animals. The AI value alignment problem has now been acknowledged as critical for AI safety as well as very hard. However, currently it has only been attempted to align the values of AI systems with human values. It is argued here that this ought to be extended to the values of nonhuman animals since it would be speciesism not to do so. The article focuses on the two subproblems—value extraction and value aggregation—discusses challenges for the integration of values of nonhuman animals and explores approaches to how AI systems could address them.},
   author = {Soenke Ziesche},
   doi = {10.3390/philosophies6020031},
   issn = {24099287},
   issue = {2},
   journal = {Philosophies},
   keywords = {AI ethics,AI safety,AI value alignment problem,Nonhuman animals,Speciesism,Value aggregation,Value extraction},
   month = {6},
   publisher = {MDPI AG},
   title = {AI ethics and value alignment for nonhuman animals},
   volume = {6},
   year = {2021},
}

