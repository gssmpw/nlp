\section{Related Work}
\label{S2}
In this section, we briefly summarize existing works on graph federation learning, graph contrastive learning, and graph adversarial attack.


\subsection{ Graph Federation Learning}\label{HypergraphLearning}

GFL trains models across multiple data owners without exchanging the original data and can effectively protect user privacy ____. Ni et al. ____ proposed a federated privacy-preserving node GCN learning framework (FedVGCN), which is suitable for the case where data is vertically distributed. FedVGCN splits the computational graph data into two parts. For each iteration of training, both sides pass intermediate results under homomorphic encryption. The literature ____ proposed vertical federated graph neural network (VFGNN), VFGNN keeps the private data (i.e., edges, node features, and labels) on the clients, and the rest of the information is given to be uploaded to a semi-honest server for training. Liu et al. ____ proposed a federated learning of subgraphs with global graph reconstruction (FedGGR).  For the data silo problem, Zhang et al. ____ proposed FedEgo, FedEgo uses GraphSAGE on ego-graphs to fully exploit the structural information and Mixup to address the privacy issues. Xue et al. ____ proposed a new framework for federated learning of personality graphs based on variational graph self-encoders (FedVGAE). Du et al. ____ proposed a new efficient GFL framework (FedHGCN), FedHGCN is able to be co-trained in high-dimensional space to obtain graph-rich hierarchical features. In addition, FedHGCN uses a node selection strategy to remove nodes with redundant information from the graph representation to improve efficiency.  Huang et al. ____ proposed a federated learning cross-domain knowledge graph embedding model (FedCKE) in which entity/relationship embeddings between different domains can interact securely without data sharing. Zheng et al. ____ proposed a cross-firm recommendation GNNs training framework (FL-GMT), which no longer uses traditional federation learning training methods (e.g., averaged federation), and designs a loss-based federation aggregation algorithm to improve the sample quality. The literature ____ proposed a federated multi-task graph learning (FMTGL) framework to address issues in privacy preserving and scalable schemes.

\subsection{Graph Contrastive Learning}\label{2.2}
Graph contrastive learning is an unsupervised learning method that aims to learn effective representations from graph data ____.
Meng et al. ____ proposed an informative contrastive learning (IMCL) which uses a graph augmentation generator for distinguishing the augmented view from the original view. Besides, IMCL uses a pseudo-label generator to generate pseudo-labels as a supervisory signal to ensure that the results of the augmented view classification are consistent with the original view.  Feng et al. ____ proposed the ArieL method, which introduces an adversarial graph view for data augmentation and also uses information regularization methods for stable training. In addition, ArieL uses subgraph sampling to extend to different graphs. Jiang et al. ____ proposed probabilistic graph complementary contrastive learning (PGCCL) for adaptive construction of complementary graphs, which employs a Beta mixture model to distinguish intraclass similarity and interclass similarity, and solves the problem of inconsistent similarity distributions of data. Yang et al. ____ proposed a graph knowledge contrastive learning (GKCL), which uses exploits multilevel graph knowledge to create noise-free contrastive views that can alleviate the problem of introducing noise and generating samples that require additional storage space during graph augmentation. The literature ____ proposed an implicit graph contrastive learning (IGCL), which avoids the situation where changing certain edges or nodes may accidentally change the graph features by reconfiguring the topology of the graph. Li et al. ____ proposed a line graph contrastive learning (Linegcl), the core of which is to transform the original graph into the corresponding line graph, solving the deficiencies of the existing methods in understanding the overall features and topology of the graph. Since the similarity-based methods are defective in terms of node information loss and similarity metric generalization ability.
The literature ____ proposed a linear graph contrastive learning (LGCL), which obtains subgraph views by sampling h-hop subgraphs of target node pairs, and then maximizes mutual information after transforming the sampled subgraphs into linear graphs. The literature ____ proposed a dyadic contrastive learning network (DCLN), which is based on a self-supervised learning approach to enhance the model performance through the pairwise reduction of redundant information about the learned latent variables.

\subsection{Graph Adversarial Attack}\label{2.3}

GNNs have achieved significant success in many domains and are vulnerable to adversarial attacks due to their high dependence on graph structure and node features. Graph Adversarial Attacks are defined as small modifications to the input graph that can cause GNNs to output incorrect predictions or classification results ____.
The literature ____ proposed a generalized attack framework (CAMA) that generates the importance of nodes through graph activation mapping and its variants.
Zhang et al. ____ proposed the first framework for training adversarial attacks on distributed GNNs (Disttack), which centers on disrupting the gradient synchronization between computational nodes by injecting adversarial attacks into individual computational nodes. Ennadir et al. ____ proposed a model for generating adversarial perturbations by generating entirely new nodes (UnboundAttack), which uses advances in graph generation to generate subgraphs. Zhao et al. ____ proposed a new gradient-based attack method for the robustness of dynamic graph neural networks from an optimization point of view, which centers on using gradient dynamics to attack the structure of the graph. Zhu et al. ____ proposed a partial graph attack (PGA) which uses a hierarchical target selection strategy that allows the attacker to focus only on vulnerable nodes. Then, the optimal perturbed edges are selected by a cost-effective node selection strategy. Aburidi et al. ____ proposed an attack based on training time optimization, which first optimizes the graph as hyperparameters and then uses convex relaxation and projected momentum optimization techniques to generate structural attacks. Since existing attackers need to access the target model without considering the budget allocation, the literature ____ proposed a targeted labeling attack (ETLA), which allocates the attack budget in terms of both the search space and the optimized target, allowing the attack to achieve the best performance. The literature ____ proposed a backdoor attack for the link prediction task that uses individual nodes as triggers and selects poisoned pairs of nodes in a training graph, and then embeds the backdoor in the training process of their GNNs.