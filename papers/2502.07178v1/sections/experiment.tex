%!TEX root = ../root.tex
\section{Experiments}
\label{sec:experiment}

We study the performance of our framework on the \nuscenes dataset~\cite{caesar2020nuscenes} and the \lyft dataset ~\cite{houston2021one}.

Since trajectory prediction is a well-studied subfield of autonomous driving, our goal here is not to study whether our framework can deliver state-of-the-art performance against other methods, but rather to study the dynamics of our algorithm in the context of trajectory prediction, \ie to investigate whether the OCO machinery and its variants can be a useful tool for trajectory prediction.

{\bf Pretraining Trajectory Predictors on City Splits}. 
Our set of expert trajectory predictors contains three trajectory prediction models that share a common transformer-based architecture, but are trained on three location-based subsets of the training split of the NuPlan dataset \cite{caesar2022nuplan}: Boston, Singapore, and Las Vegas, with the Pittsburgh subset reserved for evaluation. The model architecture uses the factored spatio-temporal attention mechanism used in the Scene Transformer \cite{ngiam2021scene} to encode the agent and neighbor histories, as well as a set of fixed anchor future trajectories. The models predict a mixture model, which consists of a categorical distribution over Gaussian modes whose means are computed as corrections to the fixed anchor trajectories.

{\bf Rule-based Predictor}.
The rule hierarchy (RH) predictor~\cite[Section IV.A]{patrikar2024rulefuser} serves as our rule-based predictor, encoding expected agent behaviors through a prioritized set of rules~\cite{veer23icra-receding}. These rules are arranged in decreasing order of importance: \texttt{collision avoidance}, \texttt{stay within drivable area}, \texttt{traffic lights}, \texttt{speed limit}, \texttt{minimum forward progression}, \texttt{stay near the current lane polyline}, \texttt{stay aligned with the current lane polyline}. The hierarchy is accompanied by a reward function $W$ that quantifies how well a trajectory adheres to these rules.
Trajectory prediction with the RH predictor involves the following steps: First, we generate a trajectory tree that represents potential maneuvers that the vehicle can execute. Then, using the rule hierarchy reward $W$, we compute the reward for each branch of the trajectory tree. Finally, we treat these rewards as negative energy of a Boltzmann distribution to generate a discrete probability distribution over the branches of the trajectory tree. Sampling trajectories from this discrete probability distribution gives us the predicted trajectories. 
% In the interest of space, the exposition here was kept short; 
Interested readers can find more details in \cite{patrikar2024rulefuser}.

{\bf Performance Metrics}. 
We evaluate the model's performance on three popular performance metrics.

\begin{enumerate}
    \item Top-$k$ Minimum Average Displacement Error (minADE$_k$). Using the same notation from (minFRDE$_k$), we denote $\phi_t=(\phi_{1,t},\dots,\phi_{k,t}) \in [NL]$ as the indices of the top-$k$ modes in the MoE model. 
The minimum average displacement error (minADE$_k$) is then computed as
\begin{align*}
    \min_{i = 1, \dots, k} \cbrace{ \frac{1}{K} \sum_{\tau=1}^{K} \norm{x_t(\tau)  - \mu(\phi_i, \tau)} }, 
\end{align*} where $K$ is the prediction horizon.

    \item Top-$k$ Minimum Final Displacement Error (minFDE$_k$). Calculating minFDE$_k$ is the same as calculating minADE$_k$, but only considering the error of the final predicted timestep:
    \begin{align*}
        \min_{i = 1, \dots, k} \cbrace{  \norm{x_t(K)  - \mu(\phi_i, K)} }. 
    \end{align*}

    \item Negative Log Likelihood (NLL). The negative log likelihood of observing the groundtruth $x_t$ under the predicted (Mixture of Gaussian) distribution, \ie applying $-\log(\cdot)$ to \eqref{eq:prob-x-given-Gamma}.


\end{enumerate}

These performance metrics are averaged over a sliding window of length $500$ (stationary) and $5000$ (nonstationary) for better visualization.
 


\subsection{Stationary Environment}

\input{sections/fig-stationary}

\input{sections/fig-lyft}

{\bf Convex Loss}. 
We first evaluate the performance of MoE using the convex probability loss~\eqref{eq:probability-loss}. Since the rule-based trajectory predictor does not output covariance in its predictions, we only aggregate the three learned predictors. To simulate distribution shifts, we tested the MoE on the Pittsburgh environment of \nuscenes. Fig.~\ref{fig:stationary}(a) plots the results. We have the following observations. (i) Looking at Fig.~\ref{fig:stationary}(a) bottom, as the theory predicted, the \squint algorithm converges to choosing the best expert in hindsight, which is the model pretrained in the Boston split (this intuitively makes sense because Boston is similar to Pittsburgh). (ii) Looking at Fig.~\ref{fig:stationary}(a) top and middle, we see the MoE's performance, in terms of both NLL and minADE, is better than any of the singular models, and is even close to the oracle Pittsburgh model (that is trained on Pittsburgh). Similar observations hold for the minFDE performance and are shown in Appendix~\ref{app:experiments}. 
We then aggregate the pretrained models and test on the \lyft dataset~\cite{houston2021one}, whose results are shown in Fig.~\ref{fig:lyft}(a). We observe that the MoE model quickly converges to choosing the Las Vegas model as the best expert, and the performance of the MoE model closely tracks that of the best expert Las Vegas.

{\bf Nonconvex Loss}.
We then evaluate the MoE's performance using the nonconvex minFRDE$_k$ loss. In this case, we have two MoEs, one that only aggregates the learned predictors (denoted MoE w/o RB), and the other that aggregates the rule-based predictor in addition (denoted MoE with RB). Fig.~\ref{fig:stationary}(b) plots the results of aggregation on the Pittsburgh dataset. We have the following observations. (i) Looking at Fig.~\ref{fig:stationary}(b) bottom, we see that, unlike the case of convex loss, the probability vector $\alpha$ does not converge. (ii) Even though the probability vector does not converge, the MoE's performance is still better than all the other singular models when evaluated using the minADE performance metric (\cf Fig.~\ref{fig:stationary}(b) middle). (iii) When evaluated using the NLL performance metric (in which case we only evaluate MoE w/o RB because the rule-based predictor does not output covariance), the MoE's performance is better than the Las Vegas model and close to the Boston and Singapore model, though slightly worse. This is expected because the minFRDE loss function does not encourage the minimization of the NLL metric. Fig.~\ref{fig:lyft}(b) plots the results of aggregation on the \lyft dataset. We observe that since the \lyft dataset is very different from \nuscenes, pretrained models on \nuscenes perform poorly but the rule-based predictor maintains good performance. In this case, the MoE model quickly converges to choosing the rule-based model as the best expert. We emphasize that the incorporation of the rule-based model into MoE would not have been possible without generalizing the OCO framework to handle the nonconvex and nonsmooth minFRDE$_k$ loss.


\subsection{Nonstationary Environment}
\input{sections/fig-nonstationary}

We then let the distribution shifts happen three times, at roughly timestep 25,000, 60,000, and 130,000 from Las Vegas to Boston to Singapore to Pittsburgh.

{\bf Convex Loss}.
Fig.~\ref{fig:non-stationary}(a) plots the result using the convex probability loss. We observe that (i) the \squint algorithm rapidly adapts the probability vector during shifts (Fig.~\ref{fig:non-stationary}(a) bottom). In each distribution shift, the algorithm quickly converges to the best expert within that time window. Notably, the \squint algorithm accomplishes this without any prior knowledge of when the distribution shifts occur. (ii) The result of this rapid adaptation is shown in the performance plots (Fig.~\ref{fig:non-stationary}(a) top and middle). The MoE model's performance \emph{tracks the performance of the best expert}. Though the performance of each singular model fluctuates, the MoE's performance is always close to the best singular model.

{\bf Nonconvex Loss}.
When using the nonconvex loss, the probability vector does not converge and it is hard to observe a pattern in the time series of probability vectors (Fig.~\ref{fig:non-stationary}(b) bottom). However, the performance of the MoE model remains robust to distribution shifts, consistently achieving near-optimal performance at all time steps.

