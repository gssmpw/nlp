%!TEX root = ../root.tex

\appendix 


\subsection{Exponentiated Gradient and Comparison with \squint}
\label{app:eg-squint}


The \emph{exponentiated gradient} (EG) algorithm~\cite{orabona19book-modern} is presented in Algorithm~\ref{alg:EG} (See~\cite{uwashington_lecture_10_2012} for a brief introduction).

\vspace{-3mm}
\input{sections/alg-exponentiated-gradient}
\vspace{-3mm}

We evaluated both the EG algorithm and \squint on the Las Vegas dataset, where we expect the algorithms to converge on choosing the Las Vegas model as the best expert. Fig.~\ref{fig:squintvsEG} shows the evolution of the probability vector $\alpha_t$ over time for (a) EG and (b) \squint. Notably, \squint converges approximately 25 times faster than EG, demonstrating a significant improvement in adaptation speed.


\vspace{-2mm}
\begin{figure}[h]
    \begin{minipage}{\columnwidth}
        \begin{tabular}{cc}
            \hspace{-4mm}
            \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/eg_lv_data_stationary-Prob-weights.pdf}
            {(a) Exponentiated Gradient}
            \end{minipage}
            &
            \hspace{-4mm}\begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/squint_lv_data_stationary-Prob-weights.pdf}
            {(b) \squint}
            \end{minipage}
            \\
        \end{tabular}
    \end{minipage}
    \caption{\squint vs EG on the Las Vegas dataset.
    \label{fig:squintvsEG}}
    % \vspace{2mm}
\end{figure}

\subsection{Experimental Details}
For the stationary environment, we evaluate our models using the \texttt{nuplan_mini-pittsburgh} dataset from \nuscenes. To test performance under nonstationary conditions, we concatenate multiple datasets together in sequence: \texttt{nuplan_mini-las_vegas}, \texttt{nuplan_val-boston}, \texttt{nuplan_val-singapore}, \texttt{nuplan_val-pittsburgh}.

We use $\beta=10$ as the temperature scaling factor in $\mathrm{softmin}$.

We set the discount factor $\lambda=0.9999$ in the nonstationary setup.

We use $k=10$ in choosing the top-$k$ modes.



\subsection{Further Experimental Results}
\label{app:experiments}

Fig.~\ref{fig:stationary-extra} plots extra results in the stationary setup.

Fig.~\ref{fig:nonstationary-extra} plots extra results in the nonstationary setup.

At first glance, the behavior shown in Fig.~\ref{fig:stationary-extra} may seem counterintuitive since the probability vector favors the rule-based expert despite its poor performance. However, this preference stems from the rule-based expert's underlying design: it first predicts the agent's desired lane and then plans to maintain that position. While this strategy is typically effective, prediction errors jump up drastically when the initial lane choice is incorrect. This is then heavily emphasized by the sliding window averaging we employ, making the rule-based expert's overall performance appear significantly worse than other experts, even though it performs well in most cases where the lane prediction is accurate.

\begin{figure}[h]
    \begin{minipage}{\columnwidth}
        \begin{tabular}{cc}
            \hspace{-8mm}
            \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/stationary-Prob-loss-minFDE-PM-comparison.pdf}
            \end{minipage}
            &
            \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/stationary-minFrDE-loss-minFDE-PM-comparison.pdf}
            \end{minipage}
            \\
            \hspace{-8mm}
            \begin{minipage}{0.5\textwidth}
            \centering
            \vspace{26.5mm}
            % \includegraphics[width=\columnwidth]{}
            {(a) Convex probability loss~\eqref{eq:probability-loss}}
            \end{minipage}
            &
            \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/stationary-minFRDE-weights-RB.pdf} 
            {(b) Nonconvex minFRDE$_k$ loss~\eqref{eq:minFRDEk} with RB}
            \end{minipage}
            \\
        \end{tabular}
    \end{minipage}
    \caption{More results on the performance of MoE in a stationary setting using (a) probability loss and (b) minFRDE loss. (a) shows the minFDE performance metric. (b) top shows the minFDE performance metric and (b) bottom shows the evolution of the probability vector when aggregating three learned predictors and one rule-based predictor. 
    \label{fig:stationary-extra}}
    \vspace{2mm}
\end{figure}

\begin{figure}[h]
    \begin{minipage}{\columnwidth}
        \begin{tabular}{cc}
            \hspace{-8mm}
            \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/nonstationary-minFRDE-loss-minFDE-PM-comparison-5000.pdf}
            {(a) Convex probability loss~\eqref{eq:probability-loss}}
            \end{minipage}
            &
            \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/nonstationary-Prob-loss-minFDE-PM-comparison-5000.pdf}
            {(b) Nonconvex minFRDE$_k$ loss~\eqref{eq:minFRDEk}}
            \end{minipage}
            \\
        \end{tabular}
    \end{minipage}
    \caption{minFDE performance metric in a nonstationary setting using (a) convex probability loss and (b) nonconvex minFRDE loss. 
    \label{fig:nonstationary-extra}}
    \vspace{2mm}
\end{figure}


\subsection{Generality of the Framework}
\label{app:generality}

In this section, we elaborate on Remark~\ref{remark:general} and show that our online aggregation framework presented in Section~\ref{sec:online-agg} can handle cases where the pretrained predictors output arbitrary distributions (\ie not necessarily GMMs), as long as they can be sampled from.

{\bf Problem Setup} At time $t$, we are given $N$ expert trajectory predictors, where each predictor predicts an arbitrary distribution of trajectories. We assume that this arbitrary distribution can be sampled from, and, in particular, the $i$-th expert generates $M$ trajectory samples
\bea 
\calT^i_t = \{ x^i_{1,t}, x^i_{2,t},\dots, x^i_{M,t} \}, \quad i=1,\dots,N,
\eea
where the superscript $i$ denotes the expert index. Similar to Section~\ref{sec:online-agg}, we want to choose a probability vector $\alpha_t \in \Delta_N$, where each $\alpha_{i,t}$ represents the weight assigned to the $i$-th trajectory predictor. 

{\bf Loss Function for OCO} To evaluate the performance of our MoE, a natural strategy is to compute a suitable loss between the individual trajectory samples $\calT^i_t,i=1,\dots,N$ and the groundtruth trajectory $x_t$, and then seek to minimize the weighted sum of the individual losses. Formally, at time $t$, we design the loss function of $\alpha_t$ as
\bea \label{eq:loss-samples}
\ell_t(\alpha_t) = \sum_{i=1}^N \alpha_{i,t} \ell_{t}^i (\calT^i_t, x_t),
\eea 
where the individual loss of each expert, $\ell_t^i(\cdot)$, is any meaningful loss function that computes the performance of the $i$-th expert. The simplest choice would be
\bea 
\ell^i_t (\calT^i_t, x_t) = \frac{1}{M} \sum_{j=1}^M \Vert x^i_{j,t} - x_t \Vert^2, 
\eea 
where the mean squared error is computed. Another choice, if the designer is only concerned with the ``good'' trajectory samples, is to pick the best $k$ samples and compute their mean squared error, \ie 
\bea 
\ell^i_t (\calT^i_t, x_t) = \frac{1}{k} \sum_{j=1}^k \mathrm{topk} \left\{ \Vert x^i_{j,t} - x_t \Vert^2 \right\}_{j=1}^M, 
\eea
where the function $\mathrm{topk}(\cdot)$ selects the $k$ minimum scalars. 

{\bf \squint}. A crucial observation is that the loss function $\ell_t(\alpha_t)$ in~\eqref{eq:loss-samples} remains \emph{a linear function} of $\alpha_t$. Therefore, \squint presented in Algorithm~\ref{alg:squint} can still be applied without any modifications.

{\bf Mixture of Experts from Importance Sampling}. How do we form the Mixture-of-Experts (MoE) model in this case? The answer is to use importance sampling. Specically, the MoE model consists of a new set of $M$ trajectory samples drawn from the mixture of distributions (each generated by one expert), with the mixing weights being $\alpha_t$. One way to achieve this is to draw $\lfloor M \alpha_{i,t} \rfloor$ random samples from the $i$-th expert. Intuitively, if the weight of the first expert $\alpha_{1,t}$ decreases to near zero (due to the loss $\ell^1_t(\calT^1_t, x_t)$ being very large), then the MoE samples will effectively exclude the first expert. 

{\bf Comparison with GMM}. After the discussion above, we see that Online Convex Optimization (OCO) can be applied to the online aggregation of arbitrary distributions, as long as they can be sampled from. Moreover, the algorithm remains unchanged, with the only difference being in the computation of the loss functions. However, we emphasize that a key drawback of the loss function~\eqref{eq:loss-samples} is its reliance on sampling from the distributions, which may require a large number of samples $M$ to ensure fast convergence.
