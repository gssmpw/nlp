%!TEX root = ../root.tex
\section{Introduction}
\label{sec:intro}

Predicting future trajectories of traffic agents is a central task in autonomous driving. Traditionally, rule-based methods were used for their simplicity, efficiency, and explainability~\cite{censi19icra-liability,veer23icra-receding,helou21iros-reasonable}. In contrast, recent studies have shown that deep learning-based approaches~\cite{salzmann20eccv-trajectron++,chen22cvpr-scept,yuan21iccv-agentformer} achieve superior performance due to their ability to learn spatial relationships and inter-agent dynamics from rich high-dimensional data.

However, each trajectory predictor is often trained on a specific dataset with a specific architecture, raising challenges when encountering new unseen datasets, as distribution shifts can significantly degrade a model's test-time performance. A standard approach to mitigate this issue is \emph{data augmentation}, \ie combine all possible datasets and train a large model that hopefully becomes a generalist. While the promise of general foundational models trained from large datasets has (mostly) been fulfilled by large language and vision models~\cite{bommasani21arxiv-opportunities}, their out-of-distribution (OOD) generalization ability remains to be rigorously evaluated~\cite{wang2023decodingtrust,nguyen2023out,liu2024survey}. Moreover, in the context of trajectory prediction, it is unclear yet whether such a \emph{globally} dominant model exists, as the distribution of future agent behavior can be heavily influenced by local traffic rules and driving norms across geographical locations.

In this paper, we explore the use of \emph{online aggregation} of trajectory predictors as an alternative approach to out-of-distribution generalization. In statistical learning terms, our framework can be considered an example of \emph{boosting}~\cite{schapire99ijcai-brief,meir03ml-introduction}.  Particularly, we treat each trajectory predictor as a black-box ``expert'' --whether the predictor was hand-crafted or learned, what architecture was used for learning, and which dataset it was trained on are all unknown to us-- and use a probability vector to mix the outputs of different experts. The technical problem then becomes how to update the probability vector such that the \emph{mixture-of-experts} (MoE) model remains robust to distribution shifts.

To solve this problem, we leverage theory from the emerging field of \emph{online convex optimization} (OCO)~\cite{orabona19book-modern}. In particular, OCO considers a dynamic game between a player and an adversarial environment. In each round $t$, the player outputs a decision $z_t$, the environment chooses a (potentially adversarial) convex loss function $l_t(z_t)$ and reveals the gradient $g_t = \nabla l_t(z_t)$. The goal of the player is to design an algorithm that takes in $g_t$ and outputs $z_t$ to minimize the notion of \emph{regret}:
\bea \label{eq:regret}
\regret_T(l_{1:T},u) := \sum_{t=1}^T l_t(z_t) - \sum_{t=1}^T l_t(u),
\eea 
where $T$ is the horizon of the game and $u$ is any fixed comparator. Intuitively, we wish the regret to be \emph{sublinear} in $T$, then the algorithm will converge to the best fixed decision in hindsight. Classical and recent literature in online learning established that \emph{gradient descent} and its variants can indeed attain sublinear regret, see~\cite{orabona19book-modern,zhang2024improving} and references therein.

{\bf Contribution}. 
We borrow the OCO framework to design a principled and lightweight framework for online aggregation of multiple trajectory predictors. We first assume the output of each trajectory predictor is a Gaussian mixture model (GMM). Then, using the OCO language presented above, the player's decision $z_t$ is the probability vector, resulting in an MoE model that is a mixture of GMMs, which is a new GMM. The loss function $l_t$ uses the true agent state revealed at time $t$ to evaluate the performance of the MoE model. The player finally uses the gradient of $l_t$ to perform ``online gradient descent'' to update the probability vector. When the loss function is chosen as the negative probability loss, it becomes \emph{linear} in $z_t$. In this case, the most well-known algorithm for online minimization of a linear function over $z_t$ (a probability vector) is called \emph{exponentiated gradient} (EG)~\cite{orabona19book-modern}. However, we found the empirical convergence rate of EG is too slow to be practical. To mitigate this issue, we depart from EG and choose the recent \squint algorithm~\cite{koolen2015secondorder} with Cutkosky clipping~\cite{cutkosky2019artificial} to update the probability vector online, which demonstrated roughly 25 times faster empirical convergence (see Appendix~\ref{app:eg-squint}).

We then go beyond the convexity and stationarity assumptions in OCO and engineer two heuristics for a nonconvex loss function and nonstationary environments (\ie the distribution shift happens more than once). First, when the loss function is chosen as the top-$k$ minimum first displacement error (minFRDE$_{k}$, a variant of a common performance metric in the literature), we approximate it using a differentiable surrogate~\cite{grover2019stochastic} and then apply \squint. Second, if the environment is nonstationary, we apply a discount factor when computing losses from previous steps~\cite{zhang2024discountedn}, which allows the algorithm to gracefully forget the past and adapt to new distribution shifts. 

To study the performance of our algorithm, we pretrain three trajectory predictors on the Boston, Singapore, and Las Vegas splits of the \nuscenes dataset~\cite{caesar2020nuscenes}. Together with a rule-based trajectory predictor~\cite{veer23arxiv-mpf}, we perform online aggregation on two out-of-distribution datasets: (i) the Pittsburgh split of \nuscenes and (ii) the \lyft dataset~\cite{houston2021one}. We show that the MoE model performs on par or better than any singular model on various performance metrics. 

To summarize, our contributions are:
\begin{itemize}
    \item We introduce a framework for online aggregation of multiple trajectory predictors to gain robustness against distribution shifts. Notably, our framework is agnostic to the design of individual predictors, as long as each of them outputs a distribution of trajectories.

    \item We apply the theory of online convex optimization to design a lightweight algorithm for online aggregation. Specifically, we identified that the classical EG algorithm in OCO is impractical for online aggregation in trajectory prediction, whereas the recent \squint algorithm enables fast adaptation.
    
    \item We extend the OCO framework to handle nonconvexity and nonstationarity, allowing the online aggregation algorithm to optimize for diverse scenarios.
\end{itemize}
