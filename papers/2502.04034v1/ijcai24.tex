%%%% ijcai24.tex

\typeout{IJCAI--24 Instructions for Authors}

% These are the instructions for authors for IJCAI-24.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai24.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai24}
\usepackage{flushend}
% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{stfloats}
\usepackage[switch]{lineno}
\usepackage{subfig}
\captionsetup[subfigure]{position=top,justification=raggedright,,labelsep=space,}
\renewcommand\thesubfigure{\alph{subfigure}}
\setcounter{subfigure}{0}
% Comment out this line in the camera-ready submission
%\linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2024.0)
}

\title{Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization}


% Single author syntax
% \author{
%     Author Name
%     \affiliations
%     Affiliation
%     \emails
%     email@example.com
% }


\author{
Ran Song$^1$
\and
Yinpu Bai$^1$
\and
Hui Liu$^{1,*}$\\
\affiliations
$^1$ College of Computer and Information Engineering, Nanjing Tech University, Nanjing, 211816, China\\
% $^2$Second Affiliation\\
% $^3$Third Affiliation\\
% $^4$Fourth Affiliation\\
\emails
hliu@njtech.edu.cn
}


\begin{document}

\maketitle

\begin{abstract}
The accurate prediction of drug responses remains a formidable challenge, particularly at the single-cell level and in clinical treatment contexts. Some studies employ transfer learning techniques to predict drug responses in individual cells and patients, but they require access to target-domain data during training, which is often unavailable or only obtainable in future. In this study, we propose a novel domain generalization framework, termed panCancerDR, to address this challenge. We conceptualize each cancer type as a distinct source domain, with its cell lines serving as domain-specific samples. Our primary objective is to extract domain-invariant features from the expression profiles of cell lines across diverse cancer types, thereby generalize the predictive capacity to out-of-distribution samples. To enhance robustness, we introduce a latent independence projection (LIP) module that encourages the encoder to extract informative yet non-redundant features. Also, we propose an asymmetric adaptive clustering constraint, which clusters drug-sensitive samples into a compact group while drives resistant samples dispersed across separate clusters in the latent space. Our empirical experiments demonstrate that panCancerDR effectively learns task-relevant features from diverse source domains, and achieves accurate predictions of drug response for unseen cancer type during training. Furthermore, when evaluated on single-cell and patient-level prediction tasks, our model—trained solely on \textit{in vitro} cell line data without access to target-domain information—consistently outperforms and matched current state-of-the-art methods. These findings highlights the potential of our method for real-world clinical applications. The source code and datasets are available at: \url{https://anonymous.4open.science/r/panCancerDR-FC03}.
\end{abstract}

\section{Introduction}\label{sec1}
To explore the drug responses of \textit{in vitro} cancer cells, several projects have utilized high-throughput profiling to assess cell viability when subjected to varying drug concentration treatments and yielded half-maximal inhibitory concentration. For instance, the Genomics of Drug Sensitivity in Cancer project (GDSC)~\cite{yang2012genomics} has assayed the sensitivity of more than one thousand of cancer cell lines to more than two hundreds of compounds. The Cancer Cell Line Encyclopedia (CCLE)~\cite{Barretina2012} is another effort that compiles genomic, transcriptomic, and drug sensitivity data for over 1,000 cancer cell lines. These public resources promote the development of machine learning methods for predicting drug response based on gene expression profiles~\cite{he2022context,chawla2022gene,ma2021few}. However, while some drugs exhibit promising sensitivity against tumor cells cultured under laboratory conditions, such observations offer limited guidance for clinical drug selection due to substantial discrepancy between \textit{in vitro} cellular context and \textit{in vivo} physiological environment. This disparity results in predictive methods that perform well on cell lines being less effective in predicting drug response in patients.

Recent advances in single-cell RNA sequencing (scRNA-seq) promote the generation of large-scale  scRNA-seq data~\cite{franzen2019panglaodb,han2023tisch2}, offering an opportunity to identify the drug responses at single-cell level. However, scRNA-seq data showed notably different distribution relative to bulk RNA-seq data, posing substantial challenges on drug response prediction for out-of-distribution individual cells. A few studies have employed deep transfer learning techniques to translate drug response insights derived from source domains (e.g., cell lines) to target domains (e.g., single cells or patients). For example, scDEAl~\cite{chen2022deep}  and SCAD~\cite{zheng2023enabling} utilizes domain adaptation to extract domain-invariant features between source and target domains, thereby transferring drug response knowledge from cell lines to single cells. The CODE-AE model~\cite{he2022context} applies the domain separation network to extract shared features between cell line and patient expression profiles to predict clinical drug responses. However, existing methods predominantly rely on domain adaptation, which requires model training on a predefined target domain, making them unsuitable for applications involving unseen target domains during training. In some real-world scenario, target-domain data may be currently unavailable or only accessible in future (e.g., data from newly diagnosed tumor patients). 

%With advances in single-cell sequencing yielding abundant single-cell transcriptomics data, various methods have been introduced, such as Precily, ChemCPA, DeepCE, and GEARS, to predict transcriptional responses induced by drug or genetic perturbations.

To overcome this limitation, we propose a novel domain generalization framework, termed panCancerDR, to generalize the predictive capacity of drug response on cell lines to out-of-distribution samples, such as individual cells and patients. We conceptualize each cancer type as a distinct source domain, with its cell lines serving as domain-specific samples, and then employed adversarial domain generalization to capture essential task-relevant features across multiple source domains. In particular, we introduce a plug-and-play module, referred to as latent independence projection (LIP), which encourages the encoder to extract informative and decorrelated features from expression profiles. We are further inspired by the observation that an anticancer drug exhibit initial effectiveness in inhibiting cancer cells. However, over time, cancer cells often develop resistance through various biological mechanisms. The phenomenon suggests that drug-sensitive cells share common feature, whereas drug-resistant cells exhibit diverse and heterogeneous traits. So, we propose an asymmetric adaptive clustering constraint that drives the sensitive samples aggregated into a single compact cluster, while resistant samples dispersed across multiple separate clusters in the latent space. To validate panCancerDR's performance, we firstly evaluate it on bulk RNA-seq and drug response data from cell lines, using a leave-one-out validation strategy to assess its generalizability in predicting drug responses for unseen cancer types during training. The results demonstrated that panCancerDR achieved superior predictive performance across ten major cancer types. Moreover, we applied the model, trained exclusively on bulk RNA-seq of cell lines, to single-cell and patient-level prediction tasks. The results confirmed it achieved better or comparable performance compared to current state-of-the-art (SOTA) methods. 


The primary contributions of this study are as follows:
\begin{itemize}
    \item \textbf{Development of a novel latent independent projection module}: We introduce a plug-and-play module capable of extracting informative and mutually decorrelated features from versatile cancer types so that each feature dimension represents a unique signal associated to prediction task. This module has been empirically validated to significantly mitigate overfitting.
    \item \textbf{Proposal of asymmetric domain generalization}:
    Inspired by the observation that sensitive cells share common feature, whereas resistant cells exhibit significant variability and heterogeneity, we introduce an asymmetric adaptive clustering constraint to ensure that sensitive samples are aggregated into a single compact cluster, while resistant samples are dispersed across multiple separate clusters.    
    \item \textbf{Extensive performance validation across diverse datasets}: We conducted a comprehensive evaluation of panCancerDR on bulk RNA-seq, scRNA-seq, and patient drug response datasets. The results demonstrate that our model, trained exclusively on \textit{in vitro} cell line bulk RNA-seq data, can effectively generalize to predict drug responses in both single-cell and patient-specific contexts, exemplifying a ``train once, adapt anywhere" framework.
\end{itemize}


\section{Related Works}
\subsection{Domain Generalization}
Domain generalization (DG) is proposed to construct models that perform well on unseen domains without access to their data during training. Recent advancements in DG have achieved remarkable progress~\cite{wang2022generalizing}, with approaches generally categorized into three main groups: data manipulation~\cite{shankar2018generalizing,yue2019domain,zhou2021domain}, representation learning~\cite{ghifary2015domain,li2018domain,shao2019multi,sicilia2023domain,zhang2022towards}, and learning strategy~\cite{chen2022discriminative,tian2022neuron,carlucci2019domain}. While our method falls within the realm of representation learning, it significantly differs from existing domain adversarial learning-based methods. Specifically, we introduce an asymmetric adaptive clustering constraint, enabling the model to better capture the nuances of real-world drug response data. The most closely related work is the SSDG\cite{jia2020single}, a single-sided domain generalization approach for face anti-spoofing. However, our method distinguishes itself through the incorporation of contrastive learning-based asymmetric clustering constraints and the proposal of a latent independent projection module, allowing the encoder to learn non-redundant features and thereby enhance the model's generalization capability.


\subsection{Drug Response Prediction}
The prediction of clinical drug responses has drawn considerable attention from machine learning community. Some studies employed patient drug response data to fine-tune models initially trained on cell line datasets. For instance, CODE-AE~\cite{he2022context} is based on domain separation network~\cite{bousmalis2016domain}to extract shared features between cell lines and patients. It was trained on cell line drug sensitivity data and then used to predict the drug response for tumor patients. Precily ~\cite{chawla2022gene} integrated signaling pathway and drug feature to predict drug responses \textit{in vitro} and \textit{in vivo}. In contrast, drug response prediction at the single-cell level is still in its infancy, due to the scarcity of drug response data in single-cell context. Only a few studies leveraged domain adaptation between bulk RNA-seq (source domain) and scRNA-seq (target domain) data to predict drug sensitivity of individual cells. For example, scDEAL ~\cite{chen2022deep} aligned the bulk RNA-seq and scRNA-seq features by minimizing the maximum mean discrepancy (MMD)~\cite{gretton2012kernel} in the latent space for single-cell drug response prediction. SCAD~\cite{zheng2023enabling} adopted adversarial domain adaptation to learn drug-gene signatures from the GDSC dataset~\cite{yang2012genomics} for inferring drug sensitivity in single cells. Distinct from the existing methods, we aim to establish a predictive model with superior generalizability across distinct target domains, spanning both single-cell and patient-level datasets, without access to target-domain data during training.



\section{Methods}
\subsection{Problem Definition}
Assume we have $M$ domains $D=\{D_1,D_2...D_M\}$, with each domain correspons to a specific cancer type. Each domain $D_k$ comprises the gene expression profiles of $N_k$ cell lines regarding to $k$-th cancer type, denoted as $D_k=\{X_1,X_2,\ldots X_{N_k}\}$. For a given drug, the response labels of the $N_k$ cell lines in domain $D_k$ are represented by $Y_{k}=\{y_{1},y_{2},\ldots,y_{N_k}\}$. Our primary objective is to build a deep learning-based model that accurately map the gene expression profiles of the cell line to their respective drug response labels. Once trained, the model can generalize effectively to predict drug responses in target domains, such as single-cell or patient samples.
\begin{figure*}[htpb]
    \centering
\centerline{\includegraphics[width=\linewidth]{fig/framework.pdf}}
    \caption{Illustrative diagram of panCancerDR architecture characterized by latent independence project (LIP) module and asymmetric adaptive clustering constraint, with the adversarial domain generalization implemented by gradient reversal layer (GRL).} 
    \label{fig:framework}
\end{figure*} 



\subsection{PanCancerDR Framework}
The panCancerDR architecture consists of five components: an encoder $G$, a classifier $P$, a domain discriminator $D$, a latent independence projection (LIP) module, and an asymmetric adaptive clustering constraint. As shown in Figure~\ref{fig:framework}, the expression profile of a cell line is taken as input to the encoder for feature extraction. The latent independence projection module functions to decorrelate extracted features, which is then used by the classifier to identify its drug response label. Meanwhile, the domain discriminator aims to distinguish the domain of each sample (i.e., to identify the cancer type from the expression profile). The encoder and the domain discriminator are adversarially trained so that the encoder is incentivized to learn features that make it increasingly difficult for the domain discriminator to correctly identify the domains. This adversarial training enables the encoder to capture domain-invariant features pertinent to drug response. The asymmetric adaptive clustering imposes the constraint that would aggregate sensitive samples tightly together while dispersing resistant samples across distinct clusters.

\subsection{Latent Independence Projection}
The encoder maps input expression profiles into high-dimensional feature representations in the latent space. However, not all dimensions of the primary feature contribute equally to the prediction task, i.e., certain dimensions carry valuable insights, while others may represent redundant or irrelevant information. To promote the extraction of independent and non-redundant features, we project the extracted features onto an orthogonal basis. Formally, let $G(X_i)$ denote the feature extracted from expression profile $X_i$, the independence project is implemented as follows:
\begin{equation}
    z_i=L\cdot G(X_i)
\end{equation}
in which $L$ is a well-designed matrix whose row vectors are mutually orthogonal, serving as an orthogonal basis in the latent space. For simplicity, we term the orthogonal projection in the latent space as latent independent projection (LIP). To construct $L$, we employ the sine and cosine waves of varying periods, from which evenly spaced points are sampled within the interval $[-1, 1]$. By exploiting the orthogonality properties of trigonometric functions, we ensure that pairwise row vectors sampled from different periods are approximately orthogonal (see Appendix for further details). %The LIP module enables the encoding of distinct dimensions of the same sample in latent space onto unique frequencies, while mapping identical dimensions across different samples to the same period, thereby maintaining dimensional independence.

It is noteworthy that LIP has three distinctive characteristics that distinguish it from other approaches. First, LIP differs from the sinusoidal positional encoding employed in the Transformer architecture~\cite{vaswani2017attention}. While sinusoidal positional encoding introduces position-dependent constants to generate differential embeddings for identical tokens appeared at different positions, it is not inherently orthogonal. This limitation constrains its capacity for feature disentanglement and prevents the realization of independent projections. Second, LIP circumvents the need to directly impose orthogonality constraints on embeddings, which is employed by prior approaches~\cite{lv2022causality,Liu2024scAdaDrug}. The orthogonality constraints introduce additional loss terms, which complicate the total loss function, posing challenges on parameter optimization and increasing the risk of model instability or collapse. Instead, LIP establishes an explicit orthogonal basis and projects the primary feature onto the basis, thereby facilitating the decomposition of features into independent components. By virtue of the inherent orthogonality, each component is meaningfully correlated with the prediction tasks. This design not only enhances model interpretability but also enables the derivation of quantifiable metrics. Finally, LIP employs a hard-coded orthogonal basis without trainable parameters, setting it apart from a fully connected layer that are susceptible to overfitting.

\subsection{Adversarial Domain Generalization}
The objective of domain generalization is to learn domain-invariant features relevant to the prediction task, while eliminating domain-specific information. For this purpose, we introduce a domain discriminator designed to classify the domain of each input sample. The encoder and domain discriminator are trained in an adversarial manner, with the encoder learning to extract features that prevent the discriminator from accurately identifying the domain. This adversarial training process encourages the encoder to capture features that are both predictive of drug response and consistent across all domains. Denote by $L_{adv}$ the cross entropy loss for domain discrimination, we have
\begin{multline}
   \min_D\max_G \mathcal{L}_{adv}=-\sum_{k=1}^{M}\sum_{i=1}^{N_k}(y_i^{(D)}\log D(z_{i})+\\(1-y_i^{(D)})\log(1-D(z_{i})))
\end{multline}
in which $y_i^{(D)}$ is the true domain label of the input sample $X_i$, $D(z_i)$ represents the domain label predicted by the domain discriminator. The domain discriminator $D$ aims to minimize the loss, whereas the encoder strives to maximize it. In our practice, we employ the Gradient Reversal Layer (GRL) to implement the adversarial training between the encoder and the domain discriminator. 


\subsection{Asymmetric Adaptive Clustering Constraint}
Anticancer drugs are typically designed to target specific molecules or disrupt the biological processes critical for tumor cell proliferation. So, we observed that the tumor cells responsive to a specific drug often exhibit similar characteristics, while non-responsive tumor cells develop drug resistance through diverse biological mechanisms, such as genetic mutations, alterations in cell cycle checkpoints, activation of alternative proliferation signaling pathways, and epigenetic modifications. Without loss of generality, we assume that sensitive cells share common features, while resistant cells exhibit diverse heterogeneity in their features. To reflect this observation, we introduce an asymmetric adaptive clustering constraint. Specifically, we require the encoder $G$ to extract the features so that sensitive samples are aggregated closely together in the latent space, whereas the resistant samples are dispersed into different clusters. 

We leverage an approach inspired by InfoNCE loss~\cite{oord2018representation} to achieve our objectives: 1) aggregating the sensitive samples from all source domains; 2) pulling apart the resistant samples away from all the sensitive sample; 3) separating the resistant samples from different domains. Formally, given an anchor sample $a$ included in the sensitive set, the encoder is trained to minimize the following loss function:
\begin{multline}
    \min_{G} \mathcal{L}_{asy}=\\-\sum_{j\in \mathcal{S}}log\frac{\exp(s(z_{a},z_{j})/\tau)}{\exp(s(z_{a}, z_{j})/\tau)+\sum_{k\in \mathcal{R}}\exp(s(z_{a}, z_{k})/\tau)}
\end{multline}
where function $s()$ quantifies the similarity between two variables, with $\mathcal{S}$ and $\mathcal{R}$ respectively denoting the sets of sensitive and resistant samples in a given mini-batch. %This loss encourages sensitive samples to form a compact cluster in the latent space, while allowing resistant samples to remain dispersed across multiple clusters.
 
\subsection{Drug Response Prediction}
The drug response labels of cell lines subjected to specific drug exposure is used to train the classifier. It takes as input the features after latent independence encoding to predict the response labels. We use cross-entropy as the classification loss, with the loss function $\mathcal{L}_{cls}$ defined as: 
\begin{equation}
    \min_P\mathcal{L}_{cls}=-\sum_{k=1}^{M}\sum_{i=1}^{N_k}y_i\log(P(z_i))+(1-y_i)\log(1-P(z_i))
\end{equation}
in which $P(z_i)$ represents the predicted drug response label by the predictor.

Finally, the total loss is defined as below:
\begin{equation}
\mathcal{L}=\mathcal{L}_{adv}+\lambda_1\mathcal{L}_{asy}+\lambda_2\mathcal{L}_{cls}
\end{equation}
where $\lambda_1$ and $\lambda_1$ are the balanced parameters. 

In our practice, the encoder are realized using fully-connected feed-forward networks with rectified linear unit (ReLU) activation function. It consist of only two feed-forward layers with sizes of 1024 and 740, respectively. Each feed-forward layer is followed by a batch normalization layer, and a dropout layer with the dropout probability set to 0.1. The learning rate is set to 8e-5. Our model was implemented in PyTorch 3.10, and all experiments were conducted on a CentOS Linux 8.2.2004 (Core) system, equipped with a GeForce RTX 4090 GPU and 128GB memory. During the model training and cross-validation stage, these loss terms were appropriately weighted.



\begin{figure*}[htb]
    \centering
\centerline{\includegraphics[width=\linewidth]{fig/Figure2.pdf}}
    \caption{Performance evaluation of panCancerDR in predicting bulk drug responses for hold-out cancer types. (a) ROC curves for ten hold-out cancer types. (b) AUROC values achieved by our model with and without latent independence project (LIP) module. (c) UMAP plots of the learned features of 20 cancer types included in the training set. } 
    \label{fig:bulk}
\end{figure*} 


\section{Experiments}
\subsection{Data Resource and Preprocessing}
We regard the bulk RNA-seq data from different cell lines of same cancer type as a source domain, with drug response (sensitive vs resistant) as class labels. The dataset were obtained from the Genomics of Drug Sensitivity in Cancer (GDSC) project~\cite{yang2012genomics}, which contained a wealth of data about the responses of 1074 cancer cell lines to 226 therapeutic agents. These cell lines come from more than 20 cancer types. The drug sensitivity were quantified using the half maximal inhibitory concentration (IC50). 

From the GDSC dataset, we first identified all cell lines treated by the drug of interest. Next, the cell lines were then ranked based on their IC50 values and categorized into two classes: sensitive (labeled as 1) and resistant (labeled as 0), with the threshold defined as the average IC50 value. Besides, because drug-induced changes in gene expression  reflect the substantial effect of a drug on cellular phenotype, we selected 3,000 highly variable genes from the expression profiles of over 10,000 genes available  in the bulk RNA-seq data of cell lines. These selected genes were used as inputs to our model.




\subsection{Drug Response Prediction on Leave-One-Out Cancer Type}
We first evaluated the performance of panCancerDR in predicting drug response for unseen cancer types during training. For objective evaluation, all cell lines of a specific cancer type were designated as the test set, while cell lines from other cancer types were used for training. This leave-one-out approach enabled us to evaluate the performance of panCancerDR on unseen cancer types for a specific drug. Notably, some cancer types have an insufficient number of samples (cell lines) for reliable performance evaluation. These cancer types were excluded from testing but were still included as source domains in the training set. As a result, the leave-one-out test set included ten cancer types: Lung Adenocarcinoma (LUAD), Small Cell Lung Cancer (SCLC), Breast Cancer (BRCA), Colorectal Adenocarcinoma (COREAD), Head and Neck Squamous Cell Carcinoma (HNSC), Ovarian Cancer (OV), Neuroblastoma (NB), Pancreatic Adenocarcinoma (PAAD), Acute Myeloid Leukemia (LAML), and Mesothelioma (MESO). Our evaluation considered five distinct drugs: Afatinib, AR-42, Docetaxel, Etoposide, and PLX4720. These drugs represent a diverse array of therapeutic classes, including chemotherapy agents, targeted therapies, and broad-spectrum inhibitors. 

The experimental results demonstrated that our model achieved superior performance in predicting drug responses across ten major cancer types (Figure~\ref{fig:bulk}a), with particularly high AUC values exceeding 0.9 in the cancers such as neuroblastoma (NB), mesothelioma (MESO), and acute myeloid leukemia (LAML). Next, we validated the effectiveness of the latent independent projection in improving performance. As illustrated in Figure~\ref{fig:bulk}b, inclusion of this module led to remarkably improved model performance. To further validate that the encoder captured the discriminative feature related to drug response, we used UMAP to project the learned features into the two-dimensional space. It can be found that the sensitive and resistant sample were clearly separated (Figure~\ref{fig:bulk}c). Particularly, the sensitive samples gathered into a cluster closely, whereas the resistant samples dispersed into multiple separate clusters. This results strongly verified the validity of the asymmetric adaptive clustering. Moreover, we performed regression analysis between the learned features and the real IC50 values, comparing them to PCA features that accounted for 95\% variance across all genes. The results indicated that the features extracted by the encoder provided a better fit to the IC50 values (Figure S1). These findings confirmed that our model successfully captured drug response-related features from gene expression profiles, rather than simply memorizing drug response labels, thereby enabling it to predict the drug responses for unseen cancer types during training.




\subsection{Generalization to Single-Cell Drug Response}
The inherent heterogeneity of tumors often leads to significant variability in gene expression profiles of individual cancer cells within a tumor. Meanwhile, the noise present in single-cell RNA sequencing (scRNA-seq) data further complicates this issue, leading to data distributions that differ substantially from the bulk RNA-seq data used during model training. To assess the generalizability of our proposed method, we systematically evaluated its performance in predicting drug responses at the single-cell level.

\begin{figure*}[htbp]
    \centering
\centerline{\includegraphics[width=\linewidth]{fig/Figure3.pdf}}
    \caption{Performance evaluation of panCancerDR trained on bulk RNA-seq in predicting single-cell drug response. (a) Performance comparison with baseline and SCAD for nine distinct drugs. (b-c) AUC curves with respect to training epochs of panCancerDR with and without latent independence project (LIP) module, respectively.} 
    \label{fig:scRNA}
\end{figure*} 



The single-cell drug response datasets used for performance evaluation comprised both pre-treatment scRNA-seq data from CCLE~\cite{Barretina2012} and post-treatment scRNA-seq data from GEO repository (accession numbers: GSE149215 and GSE108383). The pre-treatment dataset included the expression profiles and drug response labels of JUH006 cell line to the treatment of three distinct drugs (Gefitinib, Vorinostat and AR-42), as well as the data of SCC47 cell line treated with other four distinct drugs (NVP-TAE684, Afatinib, Sorafenib, Cetuximab). The post-treatment datasets contained the expression profiles and drug response labels of PC9 cell line following Etoposide treatment~\cite{aissa2021single}, as well as the A375 and 451Lu cell line treated with PLX4720~\cite{ho2018single}. For performance evaluation on scRNA-seq data, we selected a subset of highly variable genes that exhibited the most significant differences in expression levels across both bulk and single-cell RNA-seq data, and used these genes as inputs into our model. The details about the single-cell drug response datasets are listed in Table~\ref{tab:scRNA-seq}.


To benchmark performance, we build a baseline model composed of only three fully-connected layers. The baseline model was trained on the GDSC dataset and directly applied to the single-cell datasets. Meanwhile, we conducted performance comparison to three state-of-the-art methods: SCAD~\cite{zheng2023enabling}, scDEAL~\cite{chen2022deep} and CODE-AE~\cite{he2022context}. SCAD and scDEAL are domain adaptation-based methods designed for predicting single-cell drug responses, while CODE-AE leverages feature disentanglement to extract common feature between source and target domains. We obtained the source codes of these competing methods, trained them using the GDSC dataset, and evaluated their performance on the single-cell datasets. The experimental results showed that our method remarkably outperformed the baseline model across all drugs (Figure~\ref{fig:scRNA}a). Particularly, compared to SCAD that used SMOTE sampling for class balance and top 4k highly variable gene as input (smote\_tp4k), our method achieved better or comparable performance for most drugs. The performance of CODE-AE is highly unstable. While it achieves outstanding results for specific drugs, such as Gefitinib and Cetuximab, it performs poorly for other drugs, including Vorinostat, AR-42, Sorafenib, and Etoposide. Notably, these competing methods utilized the scRNA-seq data as target domain during the training stage, while our method never used scRNA-seq data during training. This highlights the ability of our method to extract generalizable features related to drug response from gene expression profiles across diverse source domains via domain generalization. So, it achieves robust performance without the need for target domain data during training, exemplifying a ``train once, adapt anywhere" framework. 

Furthermore, we assess the effectiveness of the latent independence projection in improving model generalizability. By comparing the performance with and without LIP module, we evaluate its impact on predicting single-cell drug response. The experimental results demonstrate that incorporating the latent independence projection module effectively prevents overfitting (Figure~\ref{fig:scRNA}b, Figure S1), thereby improving our model's generalizability to out-of-distribution data.


\begin{table}[htpb]
\caption{Detail of single-cell drug response datasets for testing}
\label{tab:scRNA-seq}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Source & Drug & Cell line & \begin{tabular}[c]{@{}c@{}}No.\\ Res\end{tabular} & \begin{tabular}[c]{@{}c@{}}No.\\ Sen\end{tabular} & \begin{tabular}[c]{@{}c@{}}No.\\ Gene\end{tabular} \\ \hline
GSE149215 & Etoposide & PC9 & 764 & 629 & 9738 \\ \hline
GSE108383 & PLX4720 & A375 & 46 & 62 & 11937 \\ \hline
CCLE & Geftinib & JUH006 & 33 & 33 & 10610 \\ \hline
CCLE & Vorinostat & JUH006 & 33 & 33 & 10610 \\ \hline
CCLE & AR-42 & JUH006 & 33 & 33 & 10610 \\ \hline
CCLE & NVP-TAE684 & SCC47 & 60 & 60 & 10684 \\ \hline
CCLE & Afatinib & SCC47 & 60 & 60 & 10684 \\ \hline
CCLE & Sorafenib & SCC47 & 60 & 60 & 10684 \\ \hline
CCLE & Cetuximab & SCC47 & 60 & 60 & 10684 \\ \hline
\end{tabular}
\end{table}


\subsection{Generalization to Patient Drug Response}
For further evaluation, we applied panCancerDR to predict clinical drug responses in patients. \textit{In vivo} drug response prediction poses significant challenges due to the influence of many biochemical factors, making it inherently more difficult than \textit{in vitro} predictions on cell lines. This experimental setting provides a more stringent evaluation of the model’s generalizability. 

The expression profiles and clinical metadata of patients were obtained from the TCGA repository~\cite{hutter2018cancer}. The patients treated with one of four drugs—Fluorouracil, Gemcitabine, Temozolomide, or Cisplatin—were selected for analysis. These drugs were chosen due to the relatively large number of patients undergoing their treatments, enabling objective and reliable performance evaluations. Patients exhibiting a complete response or partial response were labeled as sensitive, while those with clinically progressive or stable disease were labeled as resistant. From the patient expression profiles, 3,000 differentially expressed genes (DEGs) were identified based on a significance threshold of $p-value\leq 0.05$. The DEGs were then intersected with gene expression data from the GDSC dataset, and the overlapping genes were subsequently used as inputs for our model.

For performance evaluation, we compared it with ten previously published methods. These methods include conventional machine learning classifiers (e.g., MLP, EN) and deep learning models (e.g., AE, VAE, DAE), as well as various domain adaptation methods (e.g., ADAE, CORAL, DSN variants, CODE-AE variants). As illustrated in Figure~\ref{fig:patient}, our model demonstrated superior performance across all drugs except Cisplatin, where it marginally underperformed relative to CODE-AE-ADV~\cite{he2022context} and DSN-ADV~\cite{bousmalis2016domain} but outperformed other methods. Notably, for Temozolomide, our method remarkably outperformed all competing methods. 

Furthermore, we conducted ablation studies on four additional drugs—Docetaxel, Paclitaxel, Sorafenib, and Vinorelbine—to evaluate the contribution of the latent independent projection module. The results verified that the inclusion of this module brought substantial performance gains, exceeding 10\% across all four drugs (Figure S2). The most pronounced improvement was observed for Sorafenib, with an AUC increase by over 30\%.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{fig/Figure4.pdf}
    \caption{Performance comparison of panCancerDR with ten existing methods on TCGA patient drug response prediction.}  \label{fig:patient}
\end{figure} 



\section{Conclusion}
In this study, we propose a novel domain generalization framework designed to predict drug responses without access to target-domain data during training. By treating each cancer type as a distinct source domain, the model extracts domain-invariant features and generalizes to out-of-distribution samples. Our primary innovations include a latent independence projection (LIP) module for non-redundant feature extraction and an asymmetric adaptive clustering constraint to improve latent space organization. Our empirical experiments confirmed that our method outperforms current state-of-the-art methods in predicting drug responses at both single-cell and patient levels, demonstrating its potential for clinical applications.

%Our approach leverages adversarial neural networks to capture domain-invariant features. This enables us to generalize knowledge from known cancer domains to unseen cancer samples, facilitating robust and accurate predictions of drug sensitivity. By incorporating adversarial learning, we enhance the ability of the model to identify shared representations across domains while minimizing domain-specific variations, resulting in a more effective and generalizable framework for this challenging task.



%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{ijcai24}

\appendix
\renewcommand*{\thefigure}{A\arabic{figure}}
\setcounter{figure}{0}%重置图像计数器
\section*{Appendix} \nonumber
\subsection*{Constructing latent independence projection matrix}
The sine and cosine waves with varying periods are widely acknowledged as an effective basis set in vector spaces. Following this principle, we generated $m$ sinusoidal waves with distinct periods and sampled each wave across a defined interval, resulting in a discretized matrix representation as below:
\begin{equation}
L=\begin{pmatrix}L_{11}&\cdots&L_{1n}\\\vdots&\ddots&\vdots\\L_{m1}&\cdots&L_{mn}\end{pmatrix}
\end{equation}
in which each row represents $n$ samples taken from a sinusoidal wave with a specific period. 

According to the orthogonality of sine waves, we know that the inner product of two sinusoidal functions with distinct frequencies equals zero over a complete period. 
Mathematically, for sinusoidal functions $\sin(ax)$ and $\sin(bx)$, where $a\neq b$, their inner product over an interval \([-\pi, \pi]\) satisfies:  
\begin{equation}
\int_{-\pi}^{\pi} \sin(ax)\sin(bx) dx = 0.
\end{equation}

Therefore, the orthogonality between discrete row vectors becomes increasingly pronounced as the density of sampling points increases. When the number of sampling points $n$ approaches infinity, the inner product of any two distinct row vectors is equal to the integral of two sine waves with corresponding periods. Formally, we have
\begin{equation}
    \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^nL_{ik}\cdot L_{jk}=\int_{-\pi}^{\pi} \sin(ax)\sin(bx) dx.
\end{equation}

According to the formulation (7), we have $\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^nL_{ik}\cdot L_{jk}=0$ ($i\neq j$). 


Similarly, the cross terms between sine and cosine also vanish: 
\begin{equation}
\int_{-\pi}^{\pi} \sin(ax)\cos(bx) dx = 0.
\end{equation}
Therefore, the $L$ matrix can be constructed by sampling from sine and cosine waves with varying periods.


Furthermore, let $x=\pi t$, the integral for sine wave within the interval $[-\pi, \pi]$ can be changed to $\pi\int_{-1}^1\sin(a\pi t)\sin(b\pi t)dt$ through integral transform. This effectively shifts the orthogonal interval from  $(-\pi, \pi)$ to $(-1, 1)$. As a result, for the same number of sampling points, the sampling density is increased. In our practice, the odd rows are sampled from the sine wave, while the even rows are sampled from the cosine wave. Assuming the number of sampling points are $n$, we have:


\begin{equation}
\begin{aligned}
 L_{i,k} &= \cos\left(-\pi + \frac{2\pi \cdot k}{n-1} \cdot (i-1)\right), \\ 
    L_{i+1,k} &= \sin\left(-\pi + \frac{2\pi \cdot k}{n-1} \cdot (i-1)\right)
\end{aligned}
\end{equation}

To validate the orthogonality, we sampled 740 points from 16 waves with distinct periods (Figure 4a) and computed the pairwise inner products of these sampled waves, yielding a 16×16 matrix (Figure 4b). The resulting matrix closely approximates the identity matrix, characterized by diagonal elements equal to 1 and off-diagonal elements near 0. This result demonstrates that the generated matrix successfully forms an orthogonal basis.


\begin{figure}[htpb]
    \centering
    \begin{minipage}[t]{\linewidth}
        \centering
         \subfloat[]{\includegraphics[width=\linewidth]{fig/wave.pdf}}
    \end{minipage} 
    \begin{minipage}[t]{\linewidth}
        \centering
         \subfloat[]{\includegraphics[width=\linewidth]{fig/Heatmap.pdf}}
    \end{minipage} 
        \caption{Illustration of latent independence projection for validation of orthogonality. (a) Sixteen exemplar waves with 740 sampling points. (b) Heatmap of pairwise inner products of the sampled waves.}
    \label{fig:external}
\end{figure}



\flushend



\end{document}

