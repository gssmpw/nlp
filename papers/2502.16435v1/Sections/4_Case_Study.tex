\section{Limitations of Current MLLMs}

\begin{figure*}[t]
  \centering
  \subfloat[CS2 Concealed Words Test.]{
    \includegraphics[width=0.28\linewidth]{Figures/example-CS2.pdf}
    \label{fig:cs2}
  }
  \subfloat[CF2 Hidden Patterns Test.]{
    \includegraphics[width=0.28\linewidth]{Figures/example-CF2.pdf}
    \label{fig:cf2}
  }
  \subfloat[CF3 Copying Test.]{
    \includegraphics[width=0.285\linewidth]{Figures/example-CF3.pdf}
    \label{fig:cf3}
  } \\
  \subfloat[VZ1 Form Board Test.]{
    \includegraphics[width=0.28\linewidth]{Figures/example-VZ1.pdf}
    \label{fig:vz1}
  }
  \subfloat[VZ3 Surface Development Test.]{
    \includegraphics[width=0.28\linewidth]{Figures/example-VZ3.pdf}
    \label{fig:vz3}
  }
  \subfloat[An example of using OpenCV.]{
    \includegraphics[width=0.28\linewidth]{Figures/example-OpenCV.png}
    \label{fig:opencv}
  }
  \caption{Failure case study.}
  \label{fig:questionnaire}
\end{figure*}

\subsection{Insufficient Attention to Critical Details}

In image content recognition tasks, capturing fine-grained local features is essential, as uniform attention across the image can overlook critical details.
However, the current model struggles to focus effectively on key regions, resulting in missed information.
For example, in the ``CS2 Concealed Words Test'' (Fig.~\ref{fig:cs2}), the task involves identifying the partially erased word ``women.''
Correct identification of the first character requires recognizing the faint stroke in the lower left corner that differentiates ``w'' from ``v.''
Similarly, identifying the fifth character as ``n'' relies on detecting a small vertical stroke in the lower right corner of the letter.
The model, however, misclassified these characters as ``v'' and ``r,'' respectively, indicating its limited ability to prioritize critical local features. 
This limitation suggests that GPT-4o's visual attention mechanism is insufficient for capturing subtle cues necessary for accurate recognition.

\subsection{Low Sensitivity to Length and Scale}

GPT-4o exhibits notable limitations in processing geometric shapes, particularly in assessing length and proportion.
In the ``CF3 Copying Test,'' the model is tasked with replicating lines from the left side onto a $5 \times 5$ dot matrix on the right.
While the model can approximate line directions, it frequently errs in determining their lengths.
For instance, in Fig.~\ref{fig:cf3}, the first line segment should extend two units upward from the starting point, but the model extends it only one unit.
Similarly, in the ``VZ1 Form Board Test'' (Fig.~\ref{fig:vz1}), although the model correctly identifies the need for a rectangle to construct a complex figure, it fails to select sides of the appropriate length.
These results indicate that while the model possesses some geometric recognition abilities, it struggles with accurately gauging line lengths and proportions, limiting its performance in tasks requiring precise spatial measurements.

\subsection{Difficulty in Assessing Relative Positions}

GPT-4o exhibits limited spatial reasoning when assessing the relative positions of graphical elements.
In ``CF2 Hidden Patterns Test,'' the prompt instructs the model to first map the image onto a numbered $2 \times 2$ grid and then generate the corresponding undirected graph.
However, the model demonstrates insensitivity to spatial relationships between elements.
For instance, in Fig.~\ref{fig:cf2}, the correct connection should be between points 2 and 3, not points 1 and 2.
This is because linking points 1 and 2 would place their lower-left region outside the $2 \times 2$ grid.
Nonetheless, the model misinterprets this spatial relationship, incorrectly identifying a connection between points 1 and 2, resulting in an error.
This indicates that GPT-4o struggles with reasoning about relative spatial relationships and interpreting complex spatial configurations.

\subsection{Restricted Visual Reasoning Capability}

GPT-4o's reasoning ability primarily relies on textual descriptions of images rather than genuine visual reasoning.
In the ``VZ3 Surface Development Test,'' the model accurately describes components of a 2D unfolded image but struggles to infer the corresponding 3D structure (Fig.~\ref{fig:vz3}).
Solving such tasks typically requires ``spatial imagination,'' which the model fails to exhibit.
This indicates that, although GPT-4o excels at generating textual descriptions of visual content, it is limited in performing complex spatial reasoning and cannot effectively infer three-dimensional structures or spatial configurations from two-dimensional information.

\subsection{Inability to Draw Auxiliary Lines}

We also aim to enhance GPT-4o's performance by instructing it to draw auxiliary lines on images, which can facilitate solving various tasks within {\methodname}.
Inspired by Visual Sketchpad~\cite{hu2024visual}, we guide GPT-4o to use functions from OpenCV\footnote{\url{https://opencv.org/}} a Python library, to draw auxiliary lines for specific tasks.
However, as shown in Fig.~\ref{fig:opencv}, the code generated by the model for the ``CF3 Copying Test,'' after uploading an image is entirely independent of the image's content.
It consistently produces identical auxiliary lines, regardless of the input.
This indicates that GPT-4o still lacks the ability to establish a coherent logical sequence connecting ``image features $\to$ coordinate computation $\to$ geometric drawing.''