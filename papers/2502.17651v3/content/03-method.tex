

In this section, we introduce our method for generating precise chart representations from a given reference chart. Section~\ref{sec:task_definition} formally defines the task, Section~\ref{sec:multi_agents_system} outlines the components of our proposed approach \model{}, and Section~\ref{sec:test-time-scaling} presents the inference process of \model{}.

\subsection{Task Definition}
\label{sec:task_definition}
Given a reference chart image \(x_{\text{ref}}\) and a chart generation model, the objective is to learn the mapping
\[
    f: x_{\text{ref}} \to y,
\]
where \(y\) is a programmatic specification (e.g., Python code). When executed, \(y\) should render a chart \(O(y)\) that faithfully replicates the reference \(x_{\text{ref}}\).


\subsection{\model{}}
\label{sec:multi_agents_system}


As illustrated in Figure~\ref{fig:method}, \model{} is structured with four specialized agents  (\(G, C, V, R\)) and a multi-criteria verifier. 
% each operating within its own action space \kw{what does this mean?} 
All components collaborate together to iteratively refine the final output, making it more accurately replicates the reference chart. The framework is composed as follows:

\paragraph{\textbf{Generation Agent ( \(G\) )}}  
This agent is tasked to generate an initial program from the reference:
\[
    y_0 = G(x_{\text{ref}}), \quad G: \mathcal{X} \to \mathcal{Y}.
\]
This serves as the basis for further refinement.

\paragraph{\textbf{Visual Critique Agent ( \(V\) )}}  
This agent is tasked to assess the rendered chart \(O(y_t)\) against \(x_{\text{ref}}\) to detect visual discrepancies:
\[
    v_t = V(O(y_t), x_{\text{ref}}), \quad V: \mathcal{O} \times \mathcal{X} \to \mathcal{V}.
\]
Here, \(\mathcal{O}\) represents the space of visual outputs, and \(\mathcal{V}\) denotes the space of visual feedback metrics.

\paragraph{\textbf{Code Critique Agent ( \(C\) )}}  
This agent is tasked to review the generated code and provide structured critique to improve the generated code:
\[
    c_t = C(y_t), \quad C: \mathcal{Y} \to \mathcal{C}.
\]
\(\mathcal{C}\) represents the set of code critique messages ensuring correctness and efficiency.

\paragraph{\textbf{Revision Agent ( \(R\) )}}  
This agent integrates feedback from both critique agents to update the generated code:
\[
    y_{t+1} = R(y_t, v_t, c_t), \quad R: \mathcal{Y} \times \mathcal{V} \times \mathcal{C} \to \mathcal{Y}.
\]


\paragraph{\textbf{Multi-Criteria Verifier}} 
% \violet{should talk about the goal of the verifier, and how does it work with the 4 agents. Also, what does $j$ indexes? what does $\bigwedge$ mean here?}
We design a heuristic-based verifier to evaluate the chart quality. The goal of verifier is to provided external source of feedback to guide four agents collaborate more efficiently.

Let \(m_j\) be the verification metrics for \(j=1,2,3\), and let \(\theta^t\) be dynamic thresholds. Then,
\[
    Q_t(O(y_t), x_{\text{ref}}) = 
    \begin{cases}
        1, & \bigwedge_{j=1}^3 m_j(O(y_t), x_{\text{ref}}) \geq \theta^t \\
        0, & \text{otherwise}.
    \end{cases}
\]

Here, we developed three verification metrics—color (\(m_1\)), text (\(m_2\)), and overall structure (\(m_3\))—to quantify the similarity between the reference and generated charts. If the generated chart meets the desired quality (i.e., the verification score of each verification metrics (\(m_1\), \(m_2\), \(m_3\)) exceeds the predefined threshold), the system triggers an early stop. More details on the implementation of the verifier, such as each verification metric, are introduced in Appendix \ref{app:verifier}.

% \kw{should mention how these agents are implemented.}

\begin{algorithm} [tb]
\caption{Inference Procedure of \model{}}
\label{alg:inference}
\begin{algorithmic}[1]
\State \(y_0 \gets G(x_{\text{ref}})\)
\While{\(t < T_{\max}\)}
    \State \(O(y_t) \gets\) Render chart from \(y_t\)
    \State \(v_t \gets V(O(y_t), x_{\text{ref}})\) \Comment{Visual critique}
    \State \(c_t \gets C(y_t)\) \Comment{Code critique}
    \If{\(\forall j:\; m_j(O(y_t), x_{\text{ref}}) \geq \theta^t\)}
        \State \textbf{break} \Comment{Verification passed}
    \Else
        \State \(y_{t+1} \gets R(y_t, v_t, c_t)\) \Comment{Revise code}
    \EndIf
    \State \(t \gets t+1\)
\EndWhile
\State \Return \(y_t\)
\end{algorithmic}
\end{algorithm}

\subsection{Inference Procedure}
\label{sec:test-time-scaling}
Algorithm \ref{alg:inference} illustrates the inference procedure of \model{}. During inference, \model{} iteratively refines the generated code until the rendered chart meets the predefined verification threshold or reaches the maximum attempts limit $T_{\max}$. The refinement process is as follows:
\begin{align}
    y_0 &= G(x_{\text{ref}}), \\
    v_t &= V(O(y_t), x_{\text{ref}}), \\
    c_t &= C(y_t), \\
    y_{t+1} &= R(y_t, v_t, c_t).
\end{align}
The iterations terminate when
\[
    Q_t(O(y_t), x_{\text{ref}}) < \epsilon,
\]
where \(\epsilon > 0\) is the predefined threshold for the discrepancy between the generated chart and the reference chart. 










