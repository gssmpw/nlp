\section{PAPI: Overview}

Given that LLM inference exhibits varying parallelization levels during runtime, an intelligent dynamic scheduling policy is necessary to identify the most suitable computing hardware for a given kernel at a given time. 
The \textbf{key challenge} is to design a kernel offloading and allocation scheme that monitors dynamic parallelism online at low cost (in terms of latency and energy consumption) and selects the best-fit computing hardware to fully and efficiently utilize the available hardware resources.




\subsection{PAPI: Key Components}
We propose the PAPI architecture and framework. Figure~\ref{fig:heter_arch} shows the overview of the PAPI framework. PAPI has three key components explained next.



\noindent\textbf{Heterogeneous Architecture.}
We propose a heterogeneous architecture to effectively cater to both compute-bound and memory-bound kernels of LLMs. This architecture includes (1) a host CPU, (2) a high-performance processor with PIM memory units (FC-PIM), and (3) physically separated (i.e., disaggregated) PIM units (Attn-PIM). The high-performance processor includes processing units (hereafter referred to as PUs), e.g., GPU tensor cores~\cite{tensorcore}, PIM memory units (i.e., HBM-based PIM devices), and a hardware scheduler. In our evaluation, we use GPU tensor cores for the PUs, but any other high-performance processor designed for compute-bound kernels (e.g., TPU~\cite{jouppi2017datacenter} or NPU~\cite{chen2014diannao}) could also be used for this design. The host CPU sends instructions to the high-performance processor and the physically separate Attn-PIM devices, which are disaggregated from the high-performance processor.

\noindent\textbf{Hybrid PIM Units.}
We propose two types of PIM units to cater to the different parallelization levels of the FC and attention kernels of LLMs.
FC-PIM units offer relatively high computation capabilities to cater to the FC kernels, while Attn-PIM units provide a larger memory capacity tailored to the attention kernel.
The hybrid PIM units are designed to overcome the limitations of prior existing PIM designs for LLMs (e.g., \cite{lee2021hardware, kwon2022system, park2024attacc}), which typically support a single PIM unit type with fixed computation capabilities.
PAPI separates FC and attention kernels across different PIM devices. 
Since attention kernels are always memory-bound, they are assigned to the Attn-PIM devices.
FC kernels can be either compute- or memory-bound, and thus they can be dynamically allocated by the scheduler to either PUs or FC-PIM units.

\noindent\textbf{Dynamic Parallelism-Aware Scheduling.}
As analyzed in Section~\ref{sec:3.2}, we need to identify whether or not the FC layer is memory-bound and dynamically offload it to the FC-PIM units or the PUs of the high-performance processor. Instead, the attention kernel is always memory-bound, only running on the Attn-PIM units. 
We introduce a hardware scheduler (green block in Figure~\ref{fig:heter_arch}(a)) that monitors runtime parallelization changes and implements dynamic scheduling. When the parallelization level changes, our scheduler executes a low-cost identification step, and offloads the FC kernel to the best-fit computing hardware. 
When the scheduler identifies the FC kernel as memory-bound, it executes FC on the FC-PIM devices. When it identifies FC as compute-bound, it executes FC on the high-performance processor PUs. In the latter case, FC-PIM memory units are used as main memory to keep the weight parameters, which are loaded and processed by the PUs. 
Figure~\ref{fig:heter_arch}(d) illustrates an example of PAPI's dynamic monitoring. Every time the parallelization level of the FC kernel changes, our dynamic monitoring framework is involved, identifying memory-bound or compute-bound kernels, and reallocating them to different units as needed.

