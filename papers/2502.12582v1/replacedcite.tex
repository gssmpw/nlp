\section{Related Works}
\label{related}


\paragraph{Vision Language Pre-training.}

Recently, the Vision Language pre-training model has garnered significant attention due to its remarkable generalization ability and effectiveness. By training on billions of image-text pairs, ____ have achieved impressive results in the image-text matching task. Building upon its success, adaptations ____ have been developed for Action Recognition, introducing methods for few-shot learning and zero-shot action recognition. However, these methods did not fully exploit the expressive power of the VLP model for text features. For better vision-text alignment, ____ try to learn the adaptive text prompt vectors to enhance the text feature. However, the starting point of these methods is flawed, since the text feature plays the role in defining the classification logic; a wiser idea is to use the text feature as a constraint for visual feature. More importantly, most existing downstream tasks ____ only fine-tune on the single attribute of action, compromising the generalization ability of the VLP model. During the fine-tuning process, feature encoder becomes more specialized and may result in semantic drift issues ____ for the text encoder. Our AAPM maximizes the generalizability of the VLP model through the proposed modules and training strategy, enabling the model to recognize a broader range of attributes.


\paragraph{Few-shot Action Recognition.}
Few-shot Learning ____ aims to enable models to optimize from a small number of data, to classify the data in new classes. Due to the efficiency and effectiveness, it has been widely used in action recognition. The majority of existing few-shot recognition approaches ____ follow the metric-based manner to optimize the model and design robust alignment metrics to calculate the distances between the query and support data. 
Recently, a significant amount of researches ____ have made progress on few-shot action recognition by leveraging temporal relations in video data. However, these methods have encountered a dilemma as they focus primarily on exploring the temporal dimension while neglecting the pursuit of richer information in the spatial dimension. 
One vital reason is that metric-based manner may cause prototypical confusion when dealing with multiple attributes. Since we are committed to provide more action-related information through few-shot action recognition, solving this confusion problem is inevitable.
On the other hand, ____ consider that a well-initialized model makes the fine-tuning process much easier; only a small number of gradient update steps are required to reach the optimum point. Since the CLIP model shows its strong ability in text-vision tasks, ____ using the CLIP initialization to achieve good few-shot performance. But these methods are essentially not different from those of traditional action recognition; these fine-tuning-based methods still focus on a single attribute due to the generalization gap. In a word, there is no existing method that has leveraged the text information to enhance visual prototypes without compromising the generalization of the model. Therefore, our AAPM fills the gap in this field.


\paragraph{Multi-lablel Classification.}
Multi-label classification aims to provide more information by adding multiple labels. Standard multi-label classification tasks aim to predict a set of labels associated with a single data point. A conventional approach ____ involves training individual binary classifiers for each label present in the training dataset, without taking into account the dependencies among the labels.
Furthermore, ____ consider the correlation characteristics between labels and complete the learning of multi-label tasks through methods such as graph learning and structural learning. However, the labels of these methods are fixed and still require a significant amount of retraining when faced with newly introduced information. To overcome this problem, ____ follow zero-shot methods, they use the VLP model to align visual and textual embedding to deal with unseen labels. But these methods only discriminate whether the label appears in the image/video and do not work with a standard recognition task. Since most existing multi-label datasets, such as ____, lack explicit logic during the annotation process, only annotate different objects present in the images. As a result, the existing multi-label approaches based on these datasets have significant limitations ____, they can't precisely recognize the desired attributes to meet specific requirements. In this work, we create a attribute-based multi-label dataset Multi-Kinetics, introducing a more practical task AMFAR for multi-label methods.



% \begin{table*}[h]
%   \caption{Few-shot data example}
%   \label{sample-table1}
%   \centering
%   % \small
%   \setlength{\tabcolsep}{2pt}
%     \begin{tabular}{c*{5}{c}c}
%       \hline
%       \multicolumn{1}{c}{Attribute} & \multicolumn{5}{c}{Support Data} & \multicolumn{1}{c}{Query Data} \\
%       \cline{2-6}
%       &1 & 2 & 3 & 4 & 5 & \\
%       \hline
%       Action & playing soccer & dancing & swimming &  playing soccer & making up  & dancing \\
%       Scene & soccer field  & dance studio  & river  & soccer field & living room & soccer filed \\
%       Human group & single man  & multi-human  & single child  & single woman  & man & multi-human \\
%       Style & photograph & photograph  & oil painting & sketch  & photograph & photograph \\
%       \hline
%     \end{tabular}
% \end{table*}