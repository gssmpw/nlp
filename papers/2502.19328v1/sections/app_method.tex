\section{\ourmethod Details}
\label{sec:app_method}

\looseness=-1
Tables~\ref{tab:planner} to~\ref{tab:if_agent} present the LLM prompts used for the implementation of \ourmethod. We employed Serper\footnote{\url{https://serper.dev/}} to implement our external search engine and we utilize the \texttt{gpt-4o-mini-2024-07-18} model in the \ourmethodmini version.
%Prompts，可以更换为example

% \begin{table*}
%     \centering
%     \small
%     \begin{adjustbox}{max width=1\linewidth}
%     {
%     \begin{tabular}{p{\linewidth}}
%     \toprule
%     % \textbf{Prompt For Router} \\
%     % \midrule
%    Given the following instruction, determine whether the following check in needed. \\
%     \\
%         \text{[Instruction]} \\
%         \{instruction\} \\
%     \\
%         \text{[Checks]} \\
%        \{ 
%             ``name'': ``constraint check'', 
%             ``desp'': ``A `constraint check' is required if the instruction contains any additional constraints or requirements on the output, such as length, keywords, format, number of sections, frequency, order, etc.'', 
%             ``identifier'': ``[[A]]'' 
%         \}, 
%         \{  
%             ``name'': ``factuality check'', 
%             ``desp'': ``A `factuality check' is required if the generated response to the instruction potentially contains claims about factual information or world knowledge.'', 
%             ``identifier'': ``[[B]]'' 
%         \} \\
%         \\
%         If the instruction requires some checks, please output the corresponding identifiers (such as [[A]], [[B]]). \\
%         Please do not output other identifiers if the corresponding checkers not needed. \\
%     \bottomrule
%     \end{tabular}
%     }
%     \end{adjustbox}
%     \caption{Our prompt for the router, where the \{instruction\} part varies based on the input. }
%     \label{tab:planner}
% \end{table*}

% \begin{table*}
%     \centering
%     \small
%     \begin{adjustbox}{max width=1\linewidth}
%     {
%     \begin{tabular}{p{\linewidth}}
%     \toprule
%     % \textbf{Prompt For Difference Proposal} \\
%     % \midrule
%     \textbf{Prompt For Difference Proposal} \\
%         \text{[Answers]} \\
%         \{formatted\_answers\} \\
%         \\
%         \text{[Your Task]} \\
%         Given the above responses, please identify and summarize one key points of contradiction or inconsistency between the claims. \\
%         \\
%         \text{[Requirements]} \\
%         1. Return a Python list containing only the most significant differences between the two answers. \\
%         2. Do not include any additional explanations, only output the list. \\
%         3. If there are no inconsistencies, return an empty list. \\
%     \midrule
%     \textbf{Prompt For Query Generation} \\
%     \text{[Original question that caused the inconsistency]} \\
%         \{instruction\} \\
% \\
%         \text{[Inconsistencies]} \\
%         \{inconsistencies\} \\
%         \\
%         \text{[Your Task]} \\
%         To resolve the inconsistencies, We need to query search engine. For each contradiction, please generate a corresponding query that can be used to retrieve knowledge to resolve the contradiction.  \\
%         \\
%         \text{[Requirements]} \\
%         1. Each query should be specific and targeted, aiming to verify or disprove the conflicting points.  \\
%         2. Provide the queries in a clear and concise manner, returning a Python list of queries corrresponding to the inconsistencies. \\
%         3. Do not provide any additional explanations, only output the list. \\
%         \midrule
%     \textbf{Prompt For Verification} \\
%     Evaluate which of the two answers is more factual based on the supporting information. \\
%         \text{[Support knowledge sources]}: \\
%         \{supports\} \\
%         \\
%         \text{[Original Answers]}: \\
%         \{formatted\_answers\} \\
%         \\
%         \text{[Remeber]} \\
%         For each answer, provide a score between 1 and 10, where 10 represents the highest factual accuracy. Your output should only consist of the following: \\
%         Answer A: [[score]] (Wrap the score of A with [[ and ]]) \\
%         Answer B: <<score>> (Wrap the score of B with << and >>) \\
%         Please also provide a compact explanation. \\
%     \bottomrule
%     \end{tabular}
%     }
%     \end{adjustbox}
%     \caption{Our prompt for assessing factuality in verification agents, with the \{formatted\_answers\}, \{supports\}, \{inconsistencies\}, \{instruction\} and \{supports\} parts varying based on the input. }
%     \label{tab:factuality_agent}
% \end{table*}


% \begin{table*}
%     \centering
%     \small
%     \begin{adjustbox}{max width=1\linewidth}
%     {
%     \begin{tabular}{p{\linewidth}}
%     \toprule
%     % \textbf{Prompt For Difference Proposal} \\
%     % \midrule
%     \textbf{Prompt For Constraint Parsing} \\
%        You are an expert in natural language processing and constraint checking. Your task is to analyze a given instruction and identify which constraints need to be checked. \\
%         \\
%         The `instruction' contains a specific task query along with several explicitly stated constraints. Based on the instructions, you need to return a list of checker names that should be applied to the constraints. \\
%         \\
%         Task Example: \\  
%         Instruction: Write a 300+ word summary of the Wikipedia page ``https://en.wikipedia.org/wiki/Raymond\_III,\_Count\_of\_Tripol''. Do not use any commas and highlight at least 3 sections that have titles in markdown format, for example, *highlighted section part 1*, *highlighted section part 2*, *highlighted section part 3*.\\
%         Response: \\
%         NumberOfWordsChecker: 300+ word \\
%         HighlightSectionChecker: highlight at least 3 sections that have titles in markdown format\\
%         ForbiddenWordsChecker: Do not use any commas \\
%         \\
%         Task Instruction: \\
%         \{instruction\} \\
%         \\
%         \#\#\# Your task: \\
%         - Generate the appropriate checker names with corresponding descriptions from the original instruction description. \\
%         - Return the checker names with their descriptions separated by `\textbackslash n'  \\
%         - Focus only on the constraints explicitly mentioned in the instruction (e.g., length, format, specific exclusions).  \\
%         - Do **not** generate checkers for the task query itself or its quality. \\
%         - Do **not** infer or output constraints that are implicitly included in the instruction (e.g., general style or unstated rules). \\
%         - Each checker should be responsible for checking only one constraint. \\
%     \midrule
%     \textbf{Prompt For Code Generation} \\
%     You are tasked with implementing a Python function `check\_following' that determines whether a given `response' satisfies a constraint defined by a checker. The function should return `True' if the constraint is satisfied, and `False' otherwise. \\
% \\
%         \text{[Instruction to check]}: \\
%         \{instruction\} \\
% \\
%         \text{[Specific Checker and Description]}: \\
%         \{checker\_name\} \\
% \\
%         Requirements: \\
%         - The function accepts only one parameter: `response' which is a Python string. \\
%         - The function must return a boolean value (`True' or `False') based on whether the `response' adheres to the constraint described by the checker. \\
%         - The function must not include any I/O operations, such as `input()' or `ArgumentParser'. \\
%         - The Python code for each checker should be designed to be generalizable, e.g., using regular expressions or other suitable techniques. \\
%         - Only return the exact Python code, with no additional explanations. \\
%     \bottomrule
%     \end{tabular}
%     }
%     \end{adjustbox}
%     \caption{Our prompt for assessing instruction-following in verification agents, with the \{instruction\} and \{checker\_name\} parts varying based on the input. }
%     \label{tab:if_agent}
% \end{table*}