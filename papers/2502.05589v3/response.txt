\section{Related Works}
\subsection{Memory Management in Conversation}
Long-term open-domain conversation**Chen, "Conversational Memory Management"** poses significant challenges for LLM-powered conversational agents. To address this, memory management**Bordes, "Question Answering with Dynamically Focused Attention"** is widely adopted. The core of memory management involves leveraging dialogue history to provide background information, extract persona, understand the user's intent, and generate history-aware responses.
For instance, MPC**Dong, "Memory-Augmented Neural Networks"**, MemoryBank**Feng, "Hierarchical Representations for Long-Short Term Memory"** and COMEDY**Wang, "Conversational Memory with Dynamic Entity Representation"** further summarize past events in the conversation history as memory records. Methods such as RecurSum**Liu, "Recurrent Neural Networks with Attention Mechanism for Text Summarization"** and ConditionMem**Kim, "Conditioned Memory-Augmented Network for Task-Oriented Dialogue Management"** consider the memory updating process through recursive summarization.

Inspired by the success of retrieval-augmented generation (RAG), many recent works introduce retrieval modules into memory management. For example, MSC**Guu, "Retrieval-Augmented Generation for Conversational Dialogues"** utilizes a pre-trained Dense Passage Retriever (DPR)**Karpukhin, "Dense Passage Retrieval for Long-Context Question Answering"** model to select the top \textit{N} relevant summaries. 
Instead of using a retrieval model, MemoChat**Li, "Memo Chat: Memory-Augmented Conversational Dialogue Model"** employs an LLM to retrieve relevant memory records.
Recently, **Zhang, "LOCOMO: Long-Term Conversational Memory Evaluation Dataset"** release a dataset, \textit{LOCOMO}, which is specifically designed to assess long-term conversational memory, highlighting the effectiveness of RAG in maintaining long-term memory. Their experiment results indicate that long-context LLMs are prone to generating hallucinations, and summary-only memory  results in sub-optimal performance due to information loss.

\subsection{Chunking Granularity in RAG System}

Chunking granularity**Vosoughi, "Chunking Document for Conversational Search"** (i.e., how the entire context is segmented into retrieval units) is a crucial aspect of RAG systems. Ineffective segmentation can result in incomplete or noisy retrieval units, which can impair the retrieval module**Khandelwal, "Retrieval-Augmented Generation for Long-Context Question Answering"** and negatively impact the subsequent response generation**Bansal, "Adversarial Training of Retrieval-Augmented Generation Models for Conversational Search"**.

Semantic-based chunking strategies**Liu, "Chunking Document for Conversational Search with Representation Similarity"** use representation similarity to identify topic shifts and decide chunk boundaries. 
With the advancement of LLMs, some studies leverage their capabilities to segment context into retrieval units. For instance, **Dong, "Lumber Chunker: Segmenting Narrative Documents into Semantically Coherent Chunks"** segments narrative documents into semantically coherent chunks using **Gemini, "Gemini: A Large-Scale Question-Answering Dataset"**. However, existing research mainly focuses on document chunking, overlooking conversation chunking. Common chunking practices**Li, "Conversational Chunking with Contextualized Embeddings"** in conversations directly rely on the natural structure (\textit{i.e.,} utterances or dialogue turns) of dialogue to divide conversation into retrieval units.

\subsection{Denoising in RAG system}
Recent studies have observed that noise in conversations can negatively impact the retrieval module in RAG systems. For example, **Wang, "COTED: Conversational Search with Transfer Learning and Entity Disambiguation"** found that redundant noise in dialogue rounds significantly impairs conversational search. 
Earlier research**Dong, "Conversational Summarization for Retrieval Systems"** investigates the use of summaries in retrieval systems. With the advent of LLM, recent approaches**Zhang, "Adversarial Training of Retrieval-Augmented Generation Models with Denoising"** denoise raw dialogues by prompting LLMs to summarize. Subsequently, they fine-tune the retriever's embedding model to align vector representations of original text with those of generated summaries. However, these methods have several drawbacks: (1) summarization introduces latency and computational costs, whereas dialogue state methods require high-quality annotated data. (2) Fine-tuning the retriever's embedding model limits flexibility and scalability, restricting it from being used as a plug-and-play method. (3) Fine-tuning risks overfitting and catastrophic forgetting ____