\begin{figure*}[!h]
\centering
\subfloat[Retrieval recall v.s. compression rate: $\frac{\text{\# tokens after compression}}{{\text{\# tokens before compression}}}$.\\K: number of retrieved segments. \\Retriever: BM25]{
    \label{fig: recall_wrt_comp_rate_bm25} \includegraphics[width=0.3\columnwidth]{figures/recall_mtbp_bm25.pdf}
}
\hspace{0.5em}
\subfloat[Retrieval recall v.s. compression rate: $\frac{\text{\# tokens after compression}}{{\text{\# tokens before compression}}}$.\\K: number of retrieved segments. Retriever: MPNet]{
    \label{fig: recall_wrt_comp_rate_mpnet} \includegraphics[width=0.29\columnwidth]{figures/recall_mtbp_mpnet.pdf}
}
\hspace{0.5em}
\subfloat[Similarity between the query and different dialogue segments. Blue: \textcolor{blue}{relevant} segments. Orange: \textcolor{orange}{irrelevant} segments. Retriever: MPNet]
{
    \label{fig: similarity_change}
    \includegraphics[width=0.33\columnwidth]{figures/similarity_mpnet.pdf}
}
  \caption{Prompt compression method (LLMLingua-2) can serve as an effective denoising technique to enhance the memory retrieval system by: (a) improving the retrieval recall with varying context budget $K$; (b) benefiting the retrieval system by increasing the similarity between the query and relevant segments while decreasing the similarity with irrelevant ones.}
  \label{fig: similarity_mpnet}
\end{figure*}