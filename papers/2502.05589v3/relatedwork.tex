\section{Related Works}
\subsection{Memory Management in Conversation}
Long-term open-domain conversation~\citep{feng2020doc2dial, xu2022beyond, maharana2024evaluating} poses significant challenges for LLM-powered conversational agents. To address this, memory management~\citep{lu2023memochat, wang2023recursively, zhong2024memorybank, wu2024tokenselect, li2024hello, zhang2024survey} is widely adopted. The core of memory management involves leveraging dialogue history to provide background information, extract persona, understand the user's intent, and generate history-aware responses.
For instance, MPC~\citep{lee2023prompted}, MemoryBank~\citep{zhong2024memorybank} and COMEDY~\citep{chen2024compress} further summarize past events in the conversation history as memory records. Methods such as RecurSum~\citep{wang2023recursively} and ConditionMem~\citep{yuan2023evolving} consider the memory updating process through recursive summarization.

Inspired by the success of retrieval-augmented generation (RAG), many recent works introduce retrieval modules into memory management. For example, MSC~\citep{xu2022beyond} utilizes a pre-trained Dense Passage Retriever (DPR)~\citep{karpukhin2020dense} model to select the top \textit{N} relevant summaries. 
Instead of using a retrieval model, MemoChat~\citep{lu2023memochat} employs an LLM to retrieve relevant memory records.
Recently, \citet{maharana2024evaluating} release a dataset, \textit{LOCOMO}, which is specifically designed to assess long-term conversational memory, highlighting the effectiveness of RAG in maintaining long-term memory. Their experiment results indicate that long-context LLMs are prone to generating hallucinations, and summary-only memory  results in sub-optimal performance due to information loss.

\subsection{Chunking Granularity in RAG System}

Chunking granularity~\citep{duarte2024lumberchunker} (i.e., how the entire context is segmented into retrieval units) is a crucial aspect of RAG systems. Ineffective segmentation can result in incomplete or noisy retrieval units, which can impair the retrieval module~\citep{yu2023chain} and negatively impact the subsequent response generation~\citep{shi2023large}.

Semantic-based chunking strategies~\citep{anurag2023chunkingstrategies, antematter2024optimizing, kamradt2024semantic} use representation similarity to identify topic shifts and decide chunk boundaries. 
With the advancement of LLMs, some studies leverage their capabilities to segment context into retrieval units. For instance, 
LumberChunker~\citep{duarte2024lumberchunker} segments narrative documents into semantically coherent chunks using Gemini~\citep{team2023gemini}. However, existing research mainly focuses on document chunking, overlooking conversation chunking. Common chunking practices~\citep{langchain2023conversational, llamaindex2023buffer} in conversations directly rely on the natural structure (\textit{i.e.,} utterances or dialogue turns) of dialogue to divide conversation into retrieval units.

\subsection{Denoising in RAG system}
Recent studies have observed that noise in conversations can negatively impact the retrieval module in RAG systems. For example, COTED~\citep{mao2022curriculum} found that redundant noise in dialogue rounds significantly impairs conversational search. 
Earlier research~\citep{strzalkowski1998summarization, wasson2002using} investigates the use of summaries in retrieval systems. With the advent of LLM, recent approaches~\citep{ravfogel2023retrieving, lee2024effective} denoise raw dialogues by prompting LLMs to summarize. Subsequently, they fine-tune the retriever's embedding model to align vector representations of original text with those of generated summaries. However, these methods have several drawbacks: (1) summarization introduces latency and computational costs, whereas dialogue state methods require high-quality annotated data. (2) Fine-tuning the retriever's embedding model limits flexibility and scalability, restricting it from being used as a plug-and-play method. (3) Fine-tuning risks overfitting and catastrophic forgetting \citep{mccloskey1989catastrophic, lee2022sequential}, potentially impeding domain adaptation and generalization ability of pre-trained retrievers.