\begin{table*}[h]
    \small
    \centering
    \caption{Performance comparison on \textit{Long-MT-Bench+} using \texttt{Mistral-7B-Instruct-v0.3}. Other settings are the same as Table~\ref{tab: main_results}.
    }
    \label{tab: main_mistral}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l|cccccc|cc}
    \toprule
    
    \multirow{2}{*}{\textbf{Methods}} &  \multicolumn{6}{@{}c|}{{\bf QA Performance}} & \multicolumn{2}{@{}c}{{\bf Context Length}} \\
    \cmidrule (lr){2-7} \cmidrule (lr){8-9}
    & GPT4Score & BLEU & Rouge1 & Rouge2 & RougeL & BERTScore & \# Turns & \# Tokens \\
    
    \midrule
    Full History & 78.73 & 10.25 & 29.43 & 14.32 & 23.37 & 86.77 & 65.45 & 19,287 \\
    \midrule
    \multicolumn{9}{@{}c}{{ \textit{ BM25 Based Retriever } }} 
    \\
    \midrule
    Turn-Level & 83.14 & 13.60 & 33.28 & 19.11 & 27.32 & 87.52 & 3.00 & 1,047 \\
    Session-Level & 81.03 & 12.49 & 32.39 & 17.11 & 25.66 & 87.21 & 13.35 & 4,118 \\
    \sysname\ & \textbf{89.43} & \textbf{15.06} & \textbf{35.77} & \textbf{21.35} & \textbf{29.50} & \textbf{87.89} & 2.87 & 906 \\
    \midrule
    \multicolumn{9}{@{}c}{{ \textit{ MPNet Based Retriever } }} 
    \\
    \midrule
    Turn-Level & 85.61 & 12.78 & 35.06 & 19.61 & 28.51 & 87.77 & 3.00 & 909 \\
    Session-Level & 75.29 & 9.14 & 28.65 & 13.91 & 22.52 & 86.51 & 13.43 & 3,680 \\
    \sysname\ & \textbf{90.58} & \textbf{15.80} & \textbf{36.14} & \textbf{21.49} & \textbf{29.94} & \textbf{88.07} & 2.77 & 820 \\
    
    \bottomrule
    \end{tabular}
    }
\end{table*}