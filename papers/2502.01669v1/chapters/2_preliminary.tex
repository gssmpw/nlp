\section{Preliminaries}
\subsection{Problem Formulation}
The fundamental task of CVR prediction is to estimate the rate of conversion from the user clicks into purchases, based on historical data. Throughout this paper, we represent the $i$-th training sample as $z_i = (x_i, y_i^{O})$, where $x_i$ encompasses the features, $y_i^{O}$ is the observed label. Furthermore, in CVR prediction, each sample is also associated with a true label $y_i^{T}$, which is inaccessible within the training dataset. The feature set $x_i$ typically comprises temporal components --- click timestamp $c_i$, payment timestamp $p_i$, and the elapsed time $e_i$ from the click to a model-training-start timestamp $T$  --- along with user/item characteristics.
Here, the default value of $p_i$ is $-1$ if no conversion has occurred before $T$. The training set accumulated up to $T$ can be described as $\mathcal{Z} = \{ z_i \,|\, i=1,2,...,n\}$, where $n$ is the sample size. Due to the delayed feedback issue, where the ground truth $y_i^{T}$ is absent, the training process could be misled by fake negative samples. 
\begin{figure}[t]
    \centering
    \includegraphics[width=0.44\textwidth]{figures/demo.pdf}
    \vspace{-15pt}
    \caption{An illustration of the delayed feedback problem in CVR tasks.}
    \label{fig:demo}
    \vspace{-15pt}
\end{figure}
The relationship between the sample label and the timeline can be found in Figure \ref{fig:demo}. Specifically, if the conversion happens before $T$ (\ie $p_i < T$), the sample is labeled as $y_i^{O} = 1$ and $y_i^{O} = y_i^{T}$, indicating a true positive; In contrast, if the conversion is unobserved (\ie $p_i > T$), the sample is labeled as $y_i^{O} = 0$, which may not reflect $y_i^T$, creating a `fake negative' --- a delayed conversion might happen later. That is, the delayed feedback is only caused by the fake negative issue, implying that only negative samples may turn into positive samples after $T$. The CVR model trained with such data will be evaluated at timestamp $T'$, using only the test samples with their true labels.

\subsection{Vanilla and Retrain Versions of Loss}
The CVR model, $f(x,\theta)$ parameterized by $\theta$, operates as a binary classifier, predicting whether a click action $x$ will result in a conversion. Training such models typically employs binary cross-entropy loss \cite{dai2023dually,wang2023unbiased}. We first describe its \textbf{Vanilla} version \cite{chapelle2014modeling,yasui2020feedback}, wherein all observed non-converting instances are considered negatives:
\begin{equation}
\label{vanilla}
\mathcal{L}_{ {V }} (\theta) = \frac{1}{n} \sum_{i=1}^{n} \mathcal{L}_{BCE}(z_i, \theta),
\end{equation}
where for any sample $z = (x, y)$ and model parameter $\theta$,
$$\mathcal{L}_{BCE}(z, \theta) = - [ y \log f\left(x ,\theta\right)+\left(1-y\right) \log \left(1-f\left(x ,\theta\right)\right) ]$$ 
is the commonly used binary cross-entropy loss.

The vanilla version calculates loss over the observed labels without label adjustments, thereby serving as the lower bound of CVR prediction performance. Conversely, the \textbf{Oracle} version, which presumes access to the true labels $y^{T}$, represents the upper performance bound. Let $z_i^T = (x_i, y_i^T)$. The oracle loss is defined as:
\begin{equation}
\label{oracle}
\mathcal{L}_{{O}} (\theta) =\frac{1}{n} \sum_{i=1}^{n}\mathcal{L}_{BCE}(z_i^T, \theta).
\end{equation}

In fact, many conversions occur long after the testing phase, making it unrealistic to assume that the true labels of all are known during testing. Based on this, we propose a practically achievable \textbf{Retrain} version, and the loss function is as follows:
\begin{equation}
\label{retrain}
\mathcal{L}_{{R}}(\theta) =\frac{1}{n} \sum_{i=1}^{n}\mathcal{L}_{BCE}(\tilde{z}_i, \theta),
\end{equation}
where $\tilde{z}_i = (x_i, \tilde{y_i})$ and $\tilde{y}_i$ is defined as:
\[
\tilde{y_i} =
\begin{cases} 
y_i^{O} & \text{the sample was not converted before testing}, \\
y_i^{T} & \text{the sample converted before testing}. 
\end{cases}
\]
In other words, the retrain loss has access to all true conversions that happened up to the testing time, which is the best possible practical retrain model.

\subsection{Influence Function} 
Influence function \cite{hampel1974influence}, which is a classical tool in robust statistics for measuring the changes of the model parameters to small changes in the weights of training samples, has been recently introduced in the machine learning community for understanding black-box predictions and beyond \cite{koh2017understanding}. Given a training data set $\mathcal{Z} = \{z_1, z_2, ..., z_n\}$, we consider the following empirical risk minimization problem:
\begin{equation}
\hat{\theta} \in \mathop{\arg\min}_{\theta} R(\theta) := \frac{1}{n} \sum_{i=1}^n \mathcal{L}\left(z_i, \theta\right),
\end{equation}
where $\mathcal{L}(\cdot, \theta)$ is the loss function (\eg Equatioins \eqref{vanilla} \eqref{oracle}), $\theta$ is the model parameter.

We are interested in estimating the model parameter change $\Delta\theta(\epsilon) = \hat{\theta}_{{new}}(\epsilon) - \hat{\theta}$ if some training sample $z_j$ is slightly reweighted by $\epsilon$, where
\begin{equation}
\label{eq: if-newtheta}
\hat{\theta}_{{new}}(\epsilon) \in \mathop{\arg\min}_{\theta} ~ \widehat{\mathcal{L}}(z_j; \theta, \epsilon) = R(\theta) + \epsilon\mathcal{L}(z_j, \theta).
\end{equation}
When $\epsilon \approx 0$, the influence function provides an elegant tool for estimating $\Delta\theta(\epsilon)$ without solving \eqref{eq: if-newtheta} as
\begin{equation}
\label{dalta}
\Delta \theta(\epsilon) \approx -\epsilon H_{\hat{\theta}}^{-1} \nabla_\theta \mathcal{L}(z_j, \hat{\theta}) ~\mbox{and}~ \left.\frac{d \Delta\theta(\epsilon)}{d \epsilon}\right|_{\epsilon=0} = -H_{\hat{\theta}}^{-1} \nabla_\theta \mathcal{L}(z_j, \hat{\theta}),
\end{equation}
where $H_{\hat{\theta}} = \nabla_\theta^2 R(\hat{\theta})$ is the Hessian matrix of $R(\cdot)$ at $\theta = \hat{\theta}$. A detailed derivation of the expression in \eqref{dalta} can be found in \cite{koh2017understanding}. 

The key for applying the influence function to estimate $\Delta\theta$ is to calculate the right-hand side of \eqref{dalta} accurately and efficiently, which is challenging in real applications with an extremely high-dimensional model parameter $\theta$ and a huge number of data. As one of the key contributions of this paper, we will design a novel stochastic algorithm to address this computational challenge and release the power of the influence function in real applications.


