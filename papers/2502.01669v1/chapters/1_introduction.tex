\section{Introduction}
In online digital advertising, predicting conversion rate (CVR) is crucial for maximizing revenue under the cost-per-conversion (CPA) model \cite{ma2018entire,lu2017practical, lee2012estimating}, where advertisers pay only after users complete predefined actions, such as purchases. However, unlike user clicks that typically happen within minutes of ad impressions, conversions can occur hours to weeks after a user clicks an ad, highlighting the \emph{delayed feedback issue} \cite{chapelle2014modeling,ktena2019addressing,yang2021capturing} in CVR modeling.
To address this, online platforms commonly set a time window to await the conversion signal and periodically update the prediction model \cite{dai2023dually}.
In this context, clicks resulting in conversions within this window are labeled as positive samples, while those not leading to conversions, or where the conversion delay surpasses the window, are considered as negative \cite{guo2022calibrated,ktena2019addressing,li2021follow}.
Consequently, such a delay in conversions introduces a trade-off between label correctness and model freshness.

Many efforts have been made to mitigate the delayed feedback issue in CVR, which can be roughly categorized into offline and online approaches.
Offline methods \cite{yoshikawa2018nonparametric,saito2020dual, yasui2020feedback} rely on historical data to train models, usually with an extra component to model the distribution of the delay time \cite{chapelle2014modeling} or adjust for the correct labels \cite{wang2023unbiased}. They generally work under the i.i.d assumption that future data distributions will remain consistent with historical patterns.
On the other hand, online methods \cite{chen2022asymptotically, gu2021real, li2021follow} attempt to update the model by ingesting newly observed data and correcting labels in near real-time or waiting short intervals. Such updates are conducted on the duplicated data with corrected labels \cite{yang2021capturing} or using a surrogate loss, to approach the oracle model \cite{dai2023dually,ktena2019addressing}. The framework of offline CVR methods, online
CVR methods can be found in Figure~\ref{fig:compare}.

Despite effectiveness, current approaches suffer from two significant limitations:
\begin{itemize}[leftmargin=*]
    \item \textbf{Inadequate Adaptation to Evolving User Interest.} {The dynamic nature of user interests challenges the assumption of an unchanged data distribution, which may not hold in environments characterized by evolving user behavior \cite{dai2023dually}.} Offline methods, operating under the i.i.d assumption, struggle to capture users' emerging behaviors and preference shifts. {Online methods, while adapting more swiftly by incorporating new data, often suffer from sample reduplication during the label correction process, which can lead to model confusion and hinder the effective integration of accurate label information.}
    \item \textbf{Reliance on Auxiliary Models.} The mainstream approaches typically incorporate auxiliary components to estimate potential label reversals for observed negatives or to model the probabilities of fake negatives as latent variables. However, developing these additional components can be as complex as constructing the primary CVR model. Moreover, their effectiveness are limited by the quality and quantity of historical data. This dependency may result in computational inefficiencies and add additional complexities to the CVR prediction task.
\end{itemize}

\begin{figure}[t]
    \centering
\includegraphics[width=0.47\textwidth]{figures/INTRO124.pdf}
    \vspace{-10pt}
    \caption{The framework of offline CVR methods, online CVR methods, and IF-DFM.}
    \label{fig:compare}
    \vspace{-15pt}
\end{figure}

In this work, we explore a new paradigm for mitigating the delayed feedback issue, which can naturally adapt to new data without requiring auxiliary models.
Although retraining models from scratch with correctly labeled data is intuitive, it becomes prohibitively resource-intensive, particularly in large-scale CVR scenarios.
To overcome this, we propose to leverage the influence function, a concept rooted in robust statistics but drawing increasing attention in machine learning \cite{koh2017understanding}.
The basic idea of the influence function is to estimate parameter changes induced by modifications to a sample (\eg removing a sample \cite{zhang2023recommendation} or editing its feature \cite{wu2023gif}) by up-weighting the individual loss \wrt the target sample, resulting in the formulation of inverse Hessian-vector-products.
Conceptually, incorporating the influence function to mitigate the delayed feedback problem offers a notable benefit:
it allows for the direct modification of model parameters based on the estimated impact of newly injected data.

However, given the significant computational and space complexities of inverting the Hessian matrix, integrating the influence function also presents its unique challenge: How to efficiently get model parameter changes for CVR tasks?
In most cases, CVR tasks have much larger datasets and model sizes compared to traditional tasks using the influence function.

In this paper, we introduce an \underline{i}nfluence \underline{f}unction-empowered framework for \underline{d}elayed \underline{f}eedback \underline{m}odeling (IF-DFM).
At its core is to leverage the influence function to estimate the impact of newly injected data
% , including both the revised labels for fake negatives and newly acquired behavior data,
and directly modify model parameters without retraining.
Specifically, for a deployed CVR model, IF-DFM utilizes the influence function to calculate the parameter changes induced by transitioning from mislabeled samples to their correct counterparts.
This correction is performed by removing the sample with the incorrect label and adding its correct version, thus avoiding sample duplication and eliminating the need for auxiliary models.
Importantly, IF-DFM also supports the incorporation of newly arrived behavioral data (\eg clicks occurred post-deployment), allowing the model to adapt to the latest user interactions. This effectively updates the model parameters to capture current user preferences, thus improving the prediction accuracy.
To mitigate the computational cost, we propose a novel strategy that accelerates the calculation of parameter changes by reformulating the inverse Hessian-vector-product computation as a finite-sum quadratic programming problem.
This enables us to solve it using efficient stochastic optimization algorithms, such as stochastic gradient descent (SGD) \cite{robbins1951stochastic} and its variants \cite{duchi2011adaptive,kingma2014adam}, eliminating the need for full-batch gradient computations.
We conduct extensive experiments on two benchmark datasets, demonstrating the superiority of the proposed method.
Our main contributions can be summarized as follows:

\begin{itemize}[leftmargin=*]
    \item We propose a novel paradigm IF-DFM for mitigating the delayed feedback problem.
    It utilizes the influence function to estimate the impact of fake label correction and new behavior data integration, and directly modify model parameters without retraining.
    \item We propose to compute the influence function by formulating the inverse Hessian-vector-product calculation as an optimization problem, achieving a balance between computational efficiency and effectiveness.
    \item Extensive experiments on benchmark datasets demonstrate the superiority of IF-DFM. 
\end{itemize}
