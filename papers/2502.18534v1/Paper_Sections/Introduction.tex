\label{intro}

As artificial intelligence (AI) and machine learning (ML) become increasingly embedded in everyday life, concerns about their potential to exacerbate social biases have grown~\cite{sweeney2013discrimination, angwin2016machine, LarsonCompas, buolamwini2018gender}. 
Algorithms aimed at addressing these issues, known as \textit{algorithmic fairness}, must minimize bias, integrate seamlessly into decision-making systems, and provide meaningful interventions against systemic disparities. Early approaches focused on mitigating static biases, such as group~\cite{kamiran2012data, hardt2016equality}, individual~\cite{dwork2012fairness}, and causal~\cite{kusner2017counterfactual, coston2020counterfactual} bias. 

However, studies have shown that these methods can fail to address, or even worsen, the differential harms that emerge as decisions unfold over time~\cite{liu2018delayed, d2020fairness}. For example, in healthcare, a treatment algorithm may allocate resources equally at diagnosis, ensuring the fairness of an isolated decision. However, as time progresses, differing demographic factors---such as access to follow-up care or socioeconomic disparitiesâ€”can lead to worsened outcomes for certain groups, highlighting the need for interventions that can continuously address and mitigate these disparities dynamically over time.

To address this issue, recent works have reframed fairness as a sequential decision-making problem, often modeled using Markov Decision Processes (MDPs)~\cite{yin2024long, xuadapting} or structural causal models~\cite{hu2022achieving}. While these methods often model the decision-making process of an agent at a single decision point within the system, many real-world systems involve multiple decision points that cumulatively impact the entire system. For example, in healthcare, one decision point might be providing insurance to individuals, while another consists of ensuring they have access to timely and quality healthcare services, such as a hospital bed, when such resources are limited. If some individuals receive insurance but live in areas with restricted healthcare access, disparities in outcomes may still emerge. Comprehensive strategies---such as insurance assistance or access to healthcare---are thus essential to address systemic disparities and ensure fairness across decision stages.

\begin{figure*}[ht!]
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{figures/MAFE_Diagram_v3.png}
    \caption[MAFE Diagram]{ MAFE Diagram.} 
    \label{fig:MAFE_Diragram}
  \end{subfigure}%
  \hspace*{\fill}   % maximize separation between the subfigures
  \begin{subfigure}{0.555\textwidth}
    \includegraphics[width=\linewidth]{figures/MAFE_Diagram_Health_Ex_v6.png}
    \caption[Healthcare MAFE Example]{ Healthcare MAFE Example.}
    \label{fig:MAFE_Diagram_Health_Ex}
  \end{subfigure}%
\caption{\textbf{Illustration of our MAFE definition}. (a) A diagram capturing the elements of our MAFE. The actions produce by the model(s) are imported to the environment to be taken by environmental agents. This leads to state transition within the environment that produces a set collection of observations, rewards, and fairness components for each agent which are output by the environment for the model(s) to use to produce actions in the next time step. (b) An example illustrating this process for a healthcare MAFE that particularly captures how the component functions can be used to construct measures of rewards and fairness.} \label{fig:MAFE_diagram_overview}
\vspace{-3mm}
\end{figure*}

This underscores the need for realistic frameworks to study fairness dynamics in multi-agent systems over time. However, the lack of realistic multi-agent environments for studying such systems presents a major obstacle for developing and evaluating effective algorithms for addressing disparities in various social contexts. To bridge this gap, we propose a framework for \textit{Multi-agent Fair Environments} (MAFEs) that simulate modular social systems.

\textbf{Summary of Contributions:} We introduce MAFEs as a novel framework for analyzing fairness in multi-agent systems and present three benchmark MAFEs designed to simulate critical social domains: loan processing, healthcare, and higher education. To demonstrate the versatility of MAFEs and facilitate empirical evaluation, we present a cooperative use case. Within this use case, we define success metrics tailored to algorithms operating in these MAFEs and showcase the adaptability of a multi-agent reinforcement learning (MARL) algorithm in this setting. Additionally, we conduct thorough experimental analysis of our MAFEs and offer insights into their dynamics.