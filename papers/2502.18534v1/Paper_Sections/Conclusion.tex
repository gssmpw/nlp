\label{conclusion}
\vspace{-2mm}
In this work, we introduce the concept of Multi-Agent Fair Environments (MAFEs) as a framework for analyzing fairness in multi-agent systems. We provide a formal definition of algorithmic success within a MAFE, and develop three MAFEs modeling key social systems using a Python-based code implementation akin to popular reinforcement learning libraries like Gym, Gymnasium, and Petting Zoo. Through experimental analysis, we validate that our MAFEs can be used to analyze interventions that correct for system biases.

Fairness-aware algorithms require testing in environments that closely replicate real-world systems. While modeling human-centric systems involves some simplification, our MAFEs enhance the realism of decision-making in FairAI research. Acknowledging that domain experts may have varying perspectives on realism, our modular MAFEs offer flexible customization to meet diverse research needs. The models presented here represent one implementation, but our framework is adaptable and extensions will be analyzed in future work.

\paragraph{Disclaimer.}

This paper was prepared for informational purposes in part by the Artificial Intelligence Research group of JPMorgan Chase \& Co. and its affiliates (``JP Morgan'') and is not a product of the Research Department of JP Morgan. JP Morgan makes no representation and warranty whatsoever and disclaims all liability, for the completeness, accuracy or reliability of the information contained herein. This document is not intended as investment research or investment advice, or a recommendation, offer or solicitation for the purchase or sale of any security, financial instrument, financial product or service, or to be used in any way for evaluating the merits of participating in any transaction, and shall not constitute a solicitation under any jurisdiction or to any person, if such solicitation under such jurisdiction or to such person would be unlawful.