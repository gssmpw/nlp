\documentclass{article}

\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[hyphens,spaces,obeyspaces]{url}
\usepackage{hyperref}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\usepackage{tabularx}
\usepackage{multirow}

\input{packages} % PACKAGES
\input{macros}
%Flow chart library
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usepackage{pgfplots}
\pgfmathdeclarefunction{gauss}{2}{%
\pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%
}
%Bar plots library
\usepackage{pgfplots}  
\pgfplotsset{width = 0.75\linewidth ,compat=1.17} 

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{A Tutorial On Intersectionality in Fair Rankings}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}
  
%% Title
\title{A Tutorial On Intersectionality in Fair Rankings
}

\author{
  Chiara Criscuolo \\
  % Department of Electronics, Information and Bioengineering \\
  Politecnico di Milano \\
  Milan, Italy\\
  \texttt{chiara.criscuolo@polimi.it}
\And
  Davide Martinenghi \\
  Politecnico di Milano \\
  Milan, Italy\\
  \texttt{davide.martinenghi@polimi.it}
\And
  Giuseppe Piccirillo \\
  Politecnico di Milano \\
  Milan, Italy\\
  \texttt{giuseppe1.piccirillo@mail.polimi.it}
}

\begin{document}
\maketitle

\begin{abstract}
We address the critical issue of biased algorithms and unfair rankings, which have permeated various sectors, including search engines, recommendation systems, and workforce management. These biases can lead to discriminatory outcomes in a data-driven world, especially against marginalized and underrepresented groups. Efforts towards responsible data science and responsible artificial intelligence aim to mitigate these biases and promote fairness, diversity, and transparency. However, most fairness-aware ranking methods singularly focus on protected attributes such as race, gender, or socio-economic status, neglecting the intersectionality of these attributes, i.e., the interplay between multiple social identities. Understanding intersectionality is crucial to ensure that existing inequalities are not preserved by fair rankings. We offer a description of the main ways to incorporate intersectionality in fair ranking systems through practical examples and provide a comparative overview of existing literature and a synoptic table summarizing the various methodologies. Our analysis highlights the need for intersectionality to attain fairness, while also emphasizing that fairness, alone, does not necessarily imply intersectionality.
\end{abstract}


% keywords can be removed
\keywords{Ranking \and Intersectionality \and Fairness \and Protected Attributes \and Responsible Data Science}

\input{sections/1-introduction}
\input{sections/2-ethical-ranking}
\input{sections/3-intersectionality}
\input{sections/4-intersectionality-fairness}
\input{sections/5-conclusion}

\section*{Acknowledgments} 
Davide Martinenghi acknowledges support from the Italian PRIN project 2022XERWK9 ``S-PIC4CHU'' -- Semantics-based Provenance, Integrity, and Curation for Consistent, High-quality, and Unbiased data science

%Bibliography
\bibliographystyle{unsrt}  
\bibliography{references}  

\end{document}
