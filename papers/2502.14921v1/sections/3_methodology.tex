\subsection{Computing the membership score}
\label{sec:membership_method}

In Algorithm~\ref{alg:mia}, the adversary computes a membership score $\beta$ indicating their confidence that $\theta$ was trained on $\canary{x}$ (\ie that $b = 1$). 
%
We specify first how to compute a membership signal $\alpha$ for model- and data-based adversaries, and then how we compute $\beta$ from $\alpha$ adapting the RMIA methodology of \citet{zarifzadeh2024low}. 

\subsubsection{Model-based attacks}
\label{subsec:model_score}

The larger the target model $\theta$'s probability for canary $\canary{x} = (\canary{s}, \canary{\ell})$, $P_{\theta}(\canary{s} \mid \prompt{\canary{\ell}})$, as compared to its probability on reference models, the more likely that the model has seen this record during training. 
%
We compute the probability for canary \canary{x} as the product of token-level probabilities for \canary{s} conditioned on the prompt \prompt{\canary{\ell}}. 
%
Given a target canary text $\canary{s} = t_1,\ldots,t_n$, we compute
$P_{\theta}(\canary{s} \mid \prompt{\canary{\ell}})$ as $P_{\theta}(\canary{x}) = \prod_{j=1}^n P_{\theta}(t_j \mid \prompt{\canary{\ell}}, t_1, \ldots, t_{j-1})$. 
%
We consider this probability as the membership inference signal against a model, \ie $\alpha = P_{\theta}(\canary{s} \mid \prompt{\canary{\ell}})$.


\subsubsection{Data-based attacks}
\label{subsec:data_score}

When the attacker only has access to the synthetic data \synthetic{D}, we need to extract a signal purely from \synthetic{D} that correlates with membership. 
%
We next describe two methods to compute a membership signal $\alpha$ based on \synthetic{D}. For more details, refer to their pseudo-code in Appendix~\ref{app:pseudo_code}. 

\textbf{$n$-gram model.} 
The attacker first fits an $n$-gram model using \synthetic{D} as training corpus.
%
An $n$-gram model computes the probability of the next token $w_j$ in a sequence based solely on the previous $n-1$ tokens~\citep{jurafsky2024speech}.
%
The conditional probability of a token $w_j$ given the previous $n-1$ tokens is estimated from the counts of $n$-grams in the training corpus. 
%
Formally, $P_{\text{$n$-gram}}(w_j \!\mid\! w_{j-(n-1)}, \ldots, w_{j-1}) =
    %\frac{C(w_{j-(n-1)}, \ldots, w_j) + 1}{\sum_w \left( C(w_{j-(n-1)}, \ldots, w_{j-1}, w) + 1 \right)} =
    \frac{C(w_{j-(n-1)}, \ldots, w_j) + 1}{C(w_{j-(n-1)}, \ldots, w_{j-1}) + V} \,$,
where $C(s)$ is the number of times the sequence $s$ appears in the training corpus and $V$ is the vocabulary size.
%
We use Laplace smoothing to deal with $n$-grams that do not appear in the training corpus, incrementing the count of every $n$-gram by 1.
The probability that the model assigns to a sequence of tokens $s = (w_1, \ldots, w_k)$ can be computed as
$P_{\text{$n$-gram}}(s) = \prod_{j=2}^{k} P_{\text{$n$-gram}}(w_j \mid w_{j-(n-1)}, \ldots, w_{j-1})$. 
%
With the $n$-gram model fitted on the synthetic dataset, the attacker computes the $n$-gram model probability of the target canary $\canary{x} = (\canary{s}, \canary{\ell})$ as its membership signal, \ie $\alpha = P_{\text{$n$-gram}}(\canary{s})$. Intuitively, if the canary \canary{x} was present in the training data, the generated synthetic data $\synthetic{D}$ will better reflect the patterns of $\canary{s}$, resulting in the $n$-gram model assigning a higher probability to \canary{s} than if it was not present.


\textbf{Similarity metric.} 
The attacker computes the similarity between the target canary text \canary{s} and all synthetic sequences $\synthetic{s}_i$ in $\synthetic{D}$ using similarity metric $\textsc{SIM}$, \ie $\sigma_i = \textsc{SIM}(\canary{s}, \synthetic{s}_i)$ for $i = 1, \ldots, \synthetic{N}$. 
%
Next, the attacker identifies the $k$ synthetic sequences with the largest similarity to \canary{s}. With $\sigma_{i(j)}$ the $j$-th largest similarity, the membership inference signal is computed as the mean of the $k$ most similar examples, \ie $\alpha = \frac{1}{k} \sum_{j=1}^{k} \sigma_{i(j)}$. 
%
Intuitively, if \canary{s} was part of the training data, the synthetic data $\synthetic{D}$ will likely contain sequences $\synthetic{s}_i$ more similar to \canary{s} than if \canary{s} was not part of the training data, resulting in a larger mean similarity.
%
Various similarity metrics can be used. We consider Jaccard similarity ($\textsc{SIM}_\textrm{Jac}$), often used to measure string similarity, and cosine similarity between the embeddings of the two sequences, computed using a pre-trained embedding model ($\textsc{SIM}_\textrm{emb}$).

\subsubsection{Computing RMIA scores}
\label{sec:method_rmia}

Reference models, also called \emph{shadow} models, are surrogate models designed to approximate the behavior of a target model.
%
MIAs based on reference models perform better but are more costly to run than MIAs that do not use them, with the additional practical challenge that they require access to data distributed similarly to the training data of the target model~\citep{shokri2017membership,ye2022enhanced}. Obtaining multiple reference models in our scenario requires fine-tuning a large number of parameters in an LLM and quickly becomes computationally prohibitive. We use the state-of-the-art RMIA method~\citep{zarifzadeh2024low} to maximize attack performance with a limited number of reference models $M$. Specifically, for the target model $\theta$, we calculate the membership score of a canary \canary{x} using reference models $\{ \theta'_i \}_{i=1}^M$ as follows (details on applying RMIA to our setup are in Appendix~\ref{app:rmia_details}): 
$\beta_\theta(\canary{x}) = \frac{\alpha_{\theta}(\canary{x})}{\frac{1}{M} \sum_{i=1}^M \alpha_{\theta'_i}(\canary{x})} \,$.

\subsection{Canary generation}
\label{sec:method_canaries}

Prior work has shown that canaries with high perplexity are more likely to be memorized by language models~\citep{meeuscopyright}.
High perplexity sequences are less predictable and require the model to encode more specific, non-generalizable details about them.
However, high perplexity canaries are not necessarily more susceptible to leakage via synthetic data generation, as they are outliers in the text distribution when conditioned on a given in-distribution prompt.
This misalignment with the model's natural generative behavior means that even when memorized, these canaries are unlikely to be reproduced during regular model inference, making them ineffective for detecting memorization of training examples in generated synthetic data.

To address this issue, we take advantage of the greedy nature of popular autoregressive decoding strategies (\eg beam search, top-$k$ and top-$p$ sampling).
%
We can encourage such decoding strategies to generate text closer to canaries by crafting canaries with a low perplexity prefix.
To ensure memorization, we follow established practices and choose a high perplexity suffix.
Specifically, we design canaries $\canary{x} = (\canary{s}, \canary{\ell})$, where \canary{s} has an \textbf{in-distribution prefix} and an \textbf{out-of-distribution suffix}.
%
In practice, we split the original dataset $D$ into a training dataset and a canary source dataset.
For each record $x = (s, \ell)$ in the canary source dataset, we design a new canary $\canary{x} = (\canary{s}, \canary{\ell})$. We truncate $s$ to get an in-distribution prefix of length $F$ and generate a suffix using the pre-trained language model $\theta_0$, adjusting the sampling temperature to achieve a desired target perplexity $\mathcal{P}_{\textnormal{target}}$.
We use rejection sampling to ensure that the perplexity of the generated canaries falls within the range $[0.9 ~ \mathcal{P}_{\textnormal{target}}, 1.1 ~ \mathcal{P}_{\textnormal{target}} ]$.
We ensure the length is consistent across canaries, as this impacts memorization~\citep{carlini2022quantifying,kandpal2022deduplicating}.
By adjusting the length of the in-distribution prefix, we can guide the generation of either entirely in-distribution or out-of-distribution canaries.

We insert each canary $n_{\text{rep}}$ times in the training dataset of target and reference models.
When a canary is selected as a \emph{member}, the canary is repeated $n_{\text{rep}}$ times in the training dataset, while canaries selected as \emph{non-members} are excluded from the training dataset.
As in prior work~\citep{carlini2022quantifying,kandpal2022deduplicating,meeuscopyright}, we opt for $n_{\text{rep}} > 1$ to increase memorization, thus facilitating privacy auditing and the observation of the effect of different factors on the performance of MIAs during ablation studies.

