
To ensure we audit the privacy of synthetic text data in a realistic setup, the synthetic data needs to bear high utility. We measure the synthetic data utility by comparing the downstream classification performance of RoBERTa-base~\citep{DBLP:journals/corr/abs-1907-11692} when fine-tuned exclusively on real or synthetic data. We fine-tune models for binary (SST-2) and multi-class classification (AG News) for 1 epoch on the same number of real or synthetic data records using a batch size of $16$ and learning rate $\eta = \num{1e-5}$. We report the macro-averaged AUC score and accuracy on a held-out test dataset of real records. 

Table~\ref{tab:utility_no_canaries} summarizes the results for synthetic data generated based on original data which does not contain any canaries. While we do see a slight drop in downstream performance when considering synthetic data instead of the original data, AUC and accuracy remain high for both tasks. 

\begin{table}[ht]
    \centering
    \begin{tabular}{ccrr}
    \toprule
        & \multirow{2}{*}{Fine-tuning data} & \multicolumn{2}{c}{Classification} \\
        \cmidrule(lr){3-4}
        Dataset &  & AUC & Accuracy \\
        \midrule 
        \multirow{2}{*}{\parbox{2cm}{\centering SST-2}} & Real & $0.984$ & \SI{92.3}{\percent} \\ 
         & Synthetic & $0.968$ & \SI{91.5}{\percent} \\
         \midrule
        \multirow{2}{*}{\parbox{2cm}{\centering AG News}} & Real & $0.992$ & \SI{94.4}{\percent} \\ 
         & Synthetic & $0.978$ & \SI{90.0}{\percent} \\ 
        \bottomrule
    \end{tabular}
    \caption{Utility of synthetic data generated from real data \emph{without} canaries. We compare the performance of text classifiers trained on real or synthetic data---both evaluated on real, held-out test data.}
    \label{tab:utility_no_canaries}
\end{table}

We further measure the synthetic data utility when the original data contains standard canaries (see Sec.~\ref{sec:baseline_results}). Specifically, we consider synthetic data generated from a target model trained on data containing \num{500} canaries repeated $n_\textrm{rep} = 12$ times, so \num{6000} data records. When inserting canaries with an artificial label, we remove all synthetic data associated with labels not present originally when fine-tuning the RoBERTa-base model. 

\begin{table}[h]
    \centering
    \begin{tabular}{ccc@{\hskip 15pt}rr}
    \toprule
        & \multicolumn{2}{c}{Canary injection} & \multicolumn{2}{c}{Classification}\\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        Dataset & Source & Label & AUC & Accuracy \\
        \midrule
        \multirow{3}{*}{\parbox{1cm}{\centering SST-2}} & \multicolumn{2}{l}{In-distribution} & $0.972$ & \SI{91.6}{\percent} \\ 
        \cmidrule{2-5}
         & \multirow{2}{*}{\parbox{1.8cm}{Synthetic}} & Natural & $0.959$ & \SI{89.3}{\percent} \\ 
         & & Artificial & $0.962$ & \SI{89.9}{\percent} \\ 
        \midrule
        \multirow{3}{*}{\parbox{2cm}{\centering AG News}} & \multicolumn{2}{l}{In-distribution} & $0.978$ & \SI{89.8}{\percent}\\ 
        \cmidrule{2-5} 
         & \multirow{2}{*}{\parbox{1.8cm}{Synthetic}} & Natural & $0.977$ & \SI{88.6}{\percent} \\ 
         & & Artificial & $0.980$ & \SI{90.1}{\percent} \\         
         \bottomrule
    \end{tabular}
    \caption{Utility of synthetic data generated from real data \emph{with} canaries ($n_\textrm{rep}=12$). We compare the performance of text classifiers trained on real or synthetic data---both evaluated on real, held-out test data.}
    \label{tab:utility_canaries}
\end{table}

Table~\ref{tab:utility_canaries} summarizes the results. Across all canary injection methods, we find limited impact of canaries on the downstream utility of synthetic data. While the difference is minor, the natural canary labels lead to the largest utility degradation. This makes sense, as the high perplexity synthetic sequences likely distort the distribution of synthetic text associated with a certain real label. In contrast, in-distribution canaries can be seen as up-sampling certain real data points during fine-tuning, while canaries with artificial labels merely reduce the capacity of the model to learn from real data and do not interfere with this process as much as canaries with natural labels do.
