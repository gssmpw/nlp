
\begin{algorithm*}[tpb!]
\caption{Membership inference against an LLM-based synthetic text generator}
\label{alg:mia}
\begin{algorithmic}[1]
\STATE \textbf{Input}: Fine-tuning algorithm $\mathcal{T}$, pre-trained model $\theta_0$, private dataset $D = \{ x_i = (s_i, \ell_i) \}_{i=1}^N$, labels $\{\synthetic{\ell}_i\}_{i=1}^{\synthetic{N}}$, prompt template \prompt{\cdot}, canary repetitions $n_\text{rep}$, sampling method $\textsf{sample}$, adversary $\mathcal{A}$
\STATE \textbf{Output}: Membership score $\beta$

\STATE $\canary{x} \gets \mathcal{A}(\mathcal{T}, \theta_0, D, \{\synthetic{\ell}_i\}_{i=1}^{\synthetic{N}}, \prompt{\cdot})$ 
\hfill \COMMENT{Adversarially craft a canary (see Sec.~\ref{sec:method_canaries})}

\STATE $b \sim \{0,1\}$ 
\hfill \COMMENT{Flip a fair coin}

\IF{b = 1}
    \STATE $\theta \gets \mathcal{T}(\theta_0, D \cup \{\canary{x}\}^{n_\textrm{rep}})$
    \hfill \COMMENT{Fine-tune $\theta_0$ with canary repeated $n_\textrm{rep}$ times}
\ELSE
    \STATE $\theta \gets \mathcal{T}(\theta_0, D)$
    \hfill \COMMENT{Fine-tune $\theta_0$ without canary}
\ENDIF

\FOR{$i = 1 \ldots \synthetic{N}$}
    \STATE $\synthetic{s}_i \sim \textsf{sample}(\theta(\prompt{\synthetic{\ell}_i}))$
    \hfill \COMMENT{Sample synthetic records using prompt template}
\ENDFOR

\STATE $\synthetic{D} \gets \left\{ (\synthetic{s}_i, \synthetic{\ell}_i) \right\}_{i=1}^\synthetic{N}$

%\hfill \COMMENT{}
\IF{\textsf{synthetic}} 
    \STATE $\beta \gets \mathcal{A}(\synthetic{D}, \canary{x})$
    \hfill \COMMENT{Compute membership score $\beta$ of $\canary{x}$, see Sec.~\ref{subsec:data_score} and algorithms in Appendix~\ref{app:pseudo_code}}
\ELSE
    \STATE $\beta \gets \mathcal{A}(\theta, \canary{x})$ 
    \hfill \COMMENT{Compute membership score $\beta$ of $\canary{x}$, see Sec.~\ref{subsec:model_score}}
\ENDIF

\STATE \textbf{return} $\beta$
\end{algorithmic}
\end{algorithm*}
