
We clarify the capabilities of adversaries in model- and data-based attacks according to the threat model specified in Section~\ref{sec:preliminary}. We note: 
%
\begin{enumerate}
    \item A model-based attack is strictly more powerful than a data-based attack. This is because with access to the fine-tuned model $\theta$ and the prompt template $\textsf{p}(\cdot)$, a model-based attack can synthesize $\synthetic{\mathcal{D}}$ for any set of synthetic labels and perfectly simulate the membership inference experiment for a data-based attack.
    \item In both threat models, the adversary can train reference models $\{ \theta'_i \}_{i=1}^M$. This assumes access to the private dataset $D$, and the training procedure of target model $\theta$, including hyperparameters. This is made clear in line 3 in Algorithm~\ref{alg:mia}.
    \item In our experiments, we consider model-based attacks that use the prompt template \prompt{\cdot} to compute the model loss for target records, as specified in Sec.~\ref{subsec:model_score}. Our data-based attacks use the prompt template \prompt{\cdot} to generate synthetic data $\synthetic{D}$ from reference models.
    \item Only the model-based attack has query-access to the target model $\theta$. The attacks used in our experiments use $\theta$ to compute token-level predicted logits for input sequences and do not use white-box features, although this is not excluded by the threat model.
    \item Only the data-based attack generates synthetic data from reference models, so only this threat model leverages the sampling procedure $\textsf{sample}(\cdot)$. 
\end{enumerate} 

Table~\ref{tab:adversary_assumptions} summarizes the adversary capabilities used in the attacks in our experiments.

\begin{table*}[h!]
\centering
\begin{tabular}{p{8cm}cc}
\toprule
Assumptions & Model-based MIA & Data-based MIA \\ 
\midrule
Knowledge of the private dataset $D$ used to fine-tune the target model $\theta$ (apart from knowledge of canaries). & \checkmark & \checkmark \\
\midrule
Knowledge of the training procedure of target model $\theta$. & \checkmark & \checkmark \\
\midrule
Knowledge of the prompt template \prompt{\ell_i} used to generate the synthetic data. & \checkmark & \checkmark \\
\midrule
Query-access to target model $\theta$, returning predicted logits. & \checkmark & -- \\ 
\midrule
Access to synthetic data $\synthetic{D}$ generated by target model $\theta$. & -- & \checkmark \\ 
\midrule
Knowledge of the decoding strategy employed to sample synthetic data $\synthetic{D}$ (\eg, temperature, top-$k$). & -- & \checkmark \\ 
\bottomrule
\end{tabular}
\caption{Adversary capabilities effectively used by attacks in our experiments.}
\label{tab:adversary_assumptions}
\end{table*}
