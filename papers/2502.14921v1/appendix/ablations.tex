
\paragraph{Synthetic multiple} 
Thus far, we have exclusively considered that the number of generated synthetic records equals the number of records in the real data, \ie, $N = \synthetic{N}$. We now consider the case when more synthetic data is made available to a data-based adversary ($\synthetic{\mathcal{A}}$). Specifically, we denote the \emph{synthetic multiple} $m = \nicefrac{\synthetic{N}}{N}$ and evaluate how different MIAs perform for varying values of $m$.
%
Figure~\ref{fig:synthetic_multiple} shows how the ROC AUC score varies as $m$ increases. As expected, the ROC AUC score for the attack that uses membership signals computed using a 2-gram model trained on synthetic data increases when more synthetic data is available. In contrast, attacks based on similarity metrics do not seem to benefit significantly from this additional synthetic data.

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.4\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/synthetic_multiple_sst2.pdf}
  \end{subfigure}
  \hspace{0.05\textwidth}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{figures/synthetic_multiple_agnews.pdf}
  \end{subfigure}
  \caption{ROC AUC score for increasing value of the synthetic multiple $m$ across data-based attack methods for SST-2 (left) and AG News (right). Canaries are synthetically generated with target perplexity of $\mathcal{P}_{\textrm{target}}=250$,  with a natural label, with no in-distribution prefix ($F=0$), and inserted $n_\textrm{rep}=12$ times.} 
  \label{fig:synthetic_multiple}
\end{figure} 


\paragraph{Hyperparameters in data-based attacks}
The data-based attacks that we presented in Sec.~\ref{sec:membership_method} rely on certain hyperparameters.
%
The attack that uses $n$-gram models to compute membership signals is parameterized by the order $n$. Using a too small value for $n$ might not suffice to capture the information leaked from canaries into the synthetic data used to train the $n$-gram model. When using a too large order $n$, on the other hand, we would expect less overlap between $n$-grams present in the synthetic data and the canaries, lowering the membership signal.

Further, the similarity-based methods rely on the computation of the mean similarity of the closest $k$ synthetic records to the a canary. When $k$ is very small, \eg $k=1$, the method takes into account a single synthetic record, potentially missing on leakage of membership information from other close synthetic data records. When $k$ becomes too large, larger regions of the synthetic data are taken into account, which might dilute the membership signal among the noise.

Table~\ref{tab:ablations_synthetic} reports the ROC AUC scores of data-based attacks for different values of the hyperparameters $n$ and $k$ when using standard canaries (Sec.~\ref{sec:baseline_results}). We find that for both datasets, training a $2$-gram model on the synthetic data to compute the membership signal yields the best performance. For the data-based MIAs relying on the similarity between the canary and the synthetic records, both when considering Jaccard distance and cosine distance in the embedding space, we find that considering the $k=25$ closest synthetic records yields the best performance. 

\begin{table}[ht]
    \centering
    \begin{tabular}{ccc@{\hskip 20pt}cc@{\hskip 20pt}cc}
    \toprule
         & \multicolumn{2}{c}{$n$-gram} 
         & \multicolumn{2}{c}{$\textsc{SIM}_\textrm{Jac}$} 
         & \multicolumn{2}{c}{$\textsc{SIM}_\textrm{emb}$} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
        Dataset & $n$ & AUC & $k$ & AUC & $k$ & AUC\\
        \midrule
        \multirow{4}{*}{\parbox{1.8cm}{\centering SST-2}} 
        & $1$ & $0.415$ & $1$ & $0.520$ & $1$ & $0.516$ \\ 
        & $2$ & \bm{$0.616$} & $5$ & $0.535$ & $5$ & $0.516$ \\ 
        & $3$ & $0.581$ & $10$ & $0.538$ & $10$ & $0.519$ \\ 
        & $4$ & $0.530$ & $25$ & \bm{$0.547$} & $25$ & \bm{$0.530$} \\   
        \midrule
        \multirow{4}{*}{\parbox{1.8cm}{\centering AG News}} 
        & $1$ & $0.603$ & $1$ & $0.522$ & $1$ & $0.503$ \\ 
        & $2$ & \bm{$0.644$} & $5$ & $0.525$ & $5$ & $0.498$ \\ 
        & $3$ & $0.567$ & $10$ & $0.537$ & $10$ & $0.503$ \\ 
        & $4$ & $0.527$ & $25$ & \bm{$0.552$} & $25$ & \bm{$0.506$} \\        
        \bottomrule
    \end{tabular}
    \caption{Ablation over hyperparameters of data-based MIAs. We report ROC AUC scores across different values of the hyperparameters $n$ and $k$ (see Sec.~\ref{sec:membership_method}). Canaries are synthetically generated with target perplexity $\mathcal{P}_\textrm{target}=250$, with a natural label, with no in-distribution prefix ($F=0$), and inserted $n_\textrm{rep}=12$ times.}
    \label{tab:ablations_synthetic}
\end{table}