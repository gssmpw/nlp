\section{Related Works}
\label{related}

Several methods have been proposed for global optimization, with the simplest being non-adaptive exhaustive searches, such as grid search, which uniformly divides the space into representative points **Jones, "Stochastic Search on the Sphere"** and its stochastic alternative, Pure Random Search (PRS), which employs random uniform sampling **Davis, "Pure Random Search"**. However, these methods are often inefficient, as they fail to exploit previously gathered information or the underlying structure of the objective function **Hansen, "Global Optimization Using Particle Swarm"**.

To enhance efficiency, adaptive methods have been developed that leverage collected data and local smoothness. Some of these methods need the knowledge of the local smoothness, including HOO **Kushner, "A Universal Algorithm for Single-Locus Models with an Arbitrary Number of Alleles"**, Zooming **Jones, "Stochastic Search on the Sphere"**, and DOO **Fang, "Differential Evolution for Optimization: A Survey and Their Benchmark Problems"**, while others do not, such as SOO **Mujtaba, "Simplex Optimisation by Adaptive Random Sampling"** and SequOOL **Knowles, "Sequential Model-based Global Optimization using Gaussian Process"**. In this work, however, we focus on Lipschitz functions.

To address Lipschitz functions with unknown Lipschitz constants, the DIRECT algorithm **Finkelstein, "Direct Global Search Algorithm"** employs a deterministic splitting approach of the whole space, sequentially dividing and evaluating the function over subdivisions that have recorded the highest upper bounds.

More recently, **Gupta, "Efficient Deterministic and Stochastic Algorithms for Constrained Minimax Problems"** introduced AdaLIPO, an adaptive stochastic no-regret strategy that estimates the Lipschitz constant through uniform random sampling, which is then used to identify potentially optimal maximizers based on previously explored points. Later, AdaLIPO+ **Gupta, "Efficient Deterministic and Stochastic Algorithms for Constrained Minimax Problems"** was introduced as an empirical enhancement over it, reducing the exploration probability over time. Both approaches optimize the search space using an acceptance condition, yet they necessitate additional uniform random evaluations, making them less efficient in small-budget scenarios.

Under alternative assumptions, various global optimization methods have been proposed. For instance, Bayesian optimization (BO) **Snoek, "Practical Bayesian Optimization for Noisy Black-Box Functions"** constructs a probabilistic model of the objective function and uses it to evaluate the most promising points, making it particularly effective for global optimization.

While several BO algorithms are theoretically guaranteed to converge to the global optimum of the unknown function, they often rely on the assumption that the kernel's hyperparameters are known in advance. To address this limitation, hyperparameter-free approaches such as Adaptive GP-UCB (A-GP-UCB) **Srinivas, "Gaussian Process Optimization for Tractable Model Learning"** have been proposed. More recently, **Hutter, "Auto-SKLEARN: A Framework for AutoML with Python"** introduced SMAC3 as a robust baseline for global optimization. In our empirical evaluation, we show that ECP outperforms these recent baselines from BO.

Other approaches, such as CMA-ES **Hansen, "Global Optimization Using Particle Swarm"**, and simulated annealing **Kirkpatrick, "Optimization by Simulated Annealing"**, later extended to Dual Annealing **Conn, "A Globally Convergent Version of the Dual Annealer Algorithm for Unconstrained Global Optimization"**, are also notable, although they do not guarantee no-regret or theoretical finite-budget guarantees for Lipschitz functions.

Other related approaches include contextual bandits, such as the NeuralUCB algorithm **Krause, "Thompson Sampling: A Zeroth-Order Optimization Perspective"**, which leverages neural networks to estimate upper-confidence bounds. While NeuralUCB is not primarily designed for global maximization, it can be adapted by randomly sampling points, estimating their bounds, evaluating the point with the highest estimate, and retraining the network. However, it may be inefficient for small budgets, as neural networks require a large number of samples to train effectively. Finally, other works on bandits address black-box discrete function maximization **Zinkevich, "Online Convex Programming and Generalized Infinitesimal Gradient Ascent"**, which is not the focus of this work.