\section{Related Work}
\label{sec:relatedwork}
\subsection{Animatable Avatar Reconstruction}
Reconstructing 3D humans from images or videos is a challenging task.
Recent works~\cite{alldieck2018detailed,alldieck2018video,ma2020learning} use morphable mesh models like SMPL~\cite{SMPL:2015} to reconstruct 3D humans from monocular videos or single images.
However, explicit mesh representations are incapable of capturing intricate clothing details. 

To address these limitations, neural representations have been introduced \cite{saito2019pifu,saito2020pifuhd,han2023high} for 3D human reconstruction. Implicit representations, like PIFU~\cite{saito2019pifu} and its variants, achieve impressive results in handling complex details such as hairstyle and clothing while . ICON~\cite{xiu2022icon} and ECON~\cite{xiu2023econ} leverage SMPL prior to handling extreme poses. Other methods \cite{zheng2021pamir,huang2020arch,he2021arch++} use parametric models to handle dynamic scenes and obtain animatable 3D human models. Recent advancements involve using neural networks for representing dynamic human models. Extensions of NeRF \cite{mildenhall2021nerf} into dynamic scenes \cite{pumarola2021d,park2021nerfies,park2021hypernerf} and methods for animatable 3D human models in multi-view scenarios \cite{isik2023humanrf,lin2023im4d,peng2021animatable,li2022tava,li2023posevocab,weng2022humannerf} or monocular videos \cite{zhao2022human,peng2021neural,chen2021animatable,jiang2023instantavatar} have shown promising results. Signal Distance Function (SDF) is also employed \cite{liao2023high,jiang2022selfrecon,guo2023vid2avatar} to establish a differentiable rendering framework or use NeRF-based volume rendering to estimate the surface. However, most implicit representations are unfortunately struggling to handle the balance between the cost of long training process and achieving high quality rendering result.

3D Gaussian Splatting (3D-GS) model~\cite{kerbl20233d} is deemed as a promising improvement of the previous implicit representations. With 3D-GS backbone, the training and inference speed could be improved by reducing a large amount of time. In this work, we incorporate the latest 3D-GS idea into the animatable avatar reconstruction topic to enhance both the time efficiency and training robustness.

\subsection{Dynamic Gaussian Splatting}
Similar to NeRF, 3D-GS could reconstruct dynamic scenes from multi-view pictures with an additional network with the time features\cite{yang2023deformable3dgs, Wu_2024_CVPR} or with rigidly physical-based prior\cite{xie2023physgaussian, feng2024gaussian, jiang2024vrgs}. With control ability of the explicit point cloud, SC-GS\cite{huang2023sc} combines 3D Gaussian with a learnable graph to provide a control layer to deform the gaussian splats and corresponding features.

Many recent works also try to model 3D-GS avatars with human body prior like SMPL. With multi-view input, Animatbale 3D Gaussian~\cite{li2023animatable} adopts the SDF representation as the geometry proxy and introduces 2D-CNNs to generate the Gaussian map as neural texture. With single-view input, GaussianAvatar~\cite{hu2023gaussianavatar} employs the UV texture of SMPL as the pose feature to generate a Gaussian point cloud. SplattingAvatar~\cite{shao2024splattingavatar} binds the Gaussian point with triangular mesh facet along with additional translation on surface. Other methods\cite{lei2023gart, hu2023gauhuman, kocabas2023hugs} use the learnable skinning weight to associate the Gaussian point cloud to the bone transformation. However, these methods do not consider the local pose-dependent deformation and thus fail to efficiently use the local guidance of SMPL prior. In this work, our method targets at learning the Gaussian Splatting models across pose-deformed frames and improves the visual quality for dynamic details.
