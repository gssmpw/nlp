\section{Related Work}
\paragraph{In-context learning.}
In-context learning (ICL) is a task adaptation strategy where a large language model (LLM) is provided with examples or demonstrations within the input prompt to guide its responses for various tasks____. ICL enables LLMs to adapt to unseen tasks by observing a few demonstrations in their input, without requiring additional training data or fine-tuning____.
Since in-context demonstrations are crucial for ICL performance, various strategies have been proposed to improve demonstration selection, including retrieving semantically similar examples____, employing chain-of-thought reasoning____, and decomposing tasks into subproblems using least-to-most prompting____. Additionally, research has shown that the effectiveness of ICL can be significantly improved through fine-tuning____ or adaptation during pretraining____, even for smaller language models____. Recent work continues to refine demonstration selection strategies, further enhancing the adaptability and efficiency of in-context learning____.


\paragraph{Retrieval-augmented generation.}
Retrieval-augmented generation (RAG) is a context-based strategy that enhances LLMs by dynamically retrieving relevant information from a knowledge base or document corpus____. Unlike ICL, which relies solely on in-prompt demonstrations, RAG provides external context to guide LLM responses, making it particularly effective for tasks that require up-to-date or domain-specific information where static prompts may be insufficient____.
RAG can also be integrated with ICL techniques, leveraging both retrieved knowledge and example-based reasoning to improve performance across diverse tasks____. More recently, several studies have explored the use of graph-aware retrieval mechanisms to improve RAG by providing structured contextual information____.



\paragraph{Graph neural networks.}
GNNs are powerful tools designed to operate on graph-structured data____.
They have revolutionized the landscape by introducing the message-passing mechanism, where nodes iteratively aggregate information from their neighbors____.
This paradigm has led to the development of several influential GNN architectures.
Popular GNN variants include graph convolutional networks (GCN)____, graph attention networks (GAT)____, and scalable architectures such as GraphSAGE____ and RevGAT____, each advancing the message-passing paradigm in distinct ways.
While both GNNs and RAG leverage contextual information beyond the raw input, little work has explored the fundamental connections between them.