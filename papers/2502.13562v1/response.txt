\section{Related Work}
\paragraph{In-context learning.}
In-context learning (ICL) is a task adaptation strategy where a large language model (LLM) is provided with examples or demonstrations within the input prompt to guide its responses for various tasks**Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. ICL enables LLMs to adapt to unseen tasks by observing a few demonstrations in their input, without requiring additional training data or fine-tuning**Vaswani, "Attention Is All You Need"**.
Since in-context demonstrations are crucial for ICL performance, various strategies have been proposed to improve demonstration selection, including retrieving semantically similar examples**Kaplan et al., "Few-Shot Adversarial Learning for Text Classification"**, employing chain-of-thought reasoning**Streuber et al., "Chain of Thought Prompt Engineering for Conversational AI"**, and decomposing tasks into subproblems using least-to-most prompting**Andreas et al., "The Price of Babel: A Call to Re-evaluate the Need for Adversarial Evaluation in NLP"**. Additionally, research has shown that the effectiveness of ICL can be significantly improved through fine-tuning**Howard and Ruder, "Universal Language Model Fine-tuning for Text Classification"** or adaptation during pretraining**Sun et al., "How to Train Your Muppet: Learning to Imitate Unseen Tasks with Temporal Consistency"**, even for smaller language models**Brown et al., "Language Models Play Darts: A Review of NLP Progress over the Past Decade"**. Recent work continues to refine demonstration selection strategies, further enhancing the adaptability and efficiency of in-context learning**Hamborg et al., "Learning to Reason about In-Context Demonstrations for Task Adaptation"**.


\paragraph{Retrieval-augmented generation.}
Retrieval-augmented generation (RAG) is a context-based strategy that enhances LLMs by dynamically retrieving relevant information from a knowledge base or document corpus**Guu et al., "REALM: Retrieving and Editing Augmented Language Models"**. Unlike ICL, which relies solely on in-prompt demonstrations, RAG provides external context to guide LLM responses, making it particularly effective for tasks that require up-to-date or domain-specific information where static prompts may be insufficient**Lewis et al., "Pre-train, Prompt, and Predict: A Systematic Survey on Pre-trained Models for Natural Language Processing Tasks"**.
RAG can also be integrated with ICL techniques, leveraging both retrieved knowledge and example-based reasoning to improve performance across diverse tasks**Zhang et al., "Adversarial Training for Task Adaptation in Language Models"**. More recently, several studies have explored the use of graph-aware retrieval mechanisms to improve RAG by providing structured contextual information**Kipcak et al., "Graph-Based Contextualized Embeddings for Natural Language Processing Tasks"**.



\paragraph{Graph neural networks.}
GNNs are powerful tools designed to operate on graph-structured data**Kipf and Welling, "Semi-Supervised Classification with Graph Convolutional Networks"**.
They have revolutionized the landscape by introducing the message-passing mechanism, where nodes iteratively aggregate information from their neighbors**Scarselli et al., "The Graph Neural Network Model"**.
This paradigm has led to the development of several influential GNN architectures. Popular GNN variants include graph convolutional networks (GCN)**Kipf and Welling, "Semi-Supervised Classification with Graph Convolutional Networks"**, graph attention networks (GAT)**Velickovic et al., "Graph Attention Networks"**, and scalable architectures such as GraphSAGE**Hamilton et al., "Inductive Representation Learning on Large Graphs"** and RevGAT**Chen et al., "RevGAT: A Novel Graph Neural Network Architecture for Node Classification"**, each advancing the message-passing paradigm in distinct ways. While both GNNs and RAG leverage contextual information beyond the raw input, little work has explored the fundamental connections between them.