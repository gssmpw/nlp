\section{Related Work}

\subsection{Game Mechanics Design}


Assisting human in game mechanics design has been a long time topic, where early work applied search-based methods to optimize game mechanics in a prefined parameter space \cite{automaticgame2008}. Later, with the help of large-scale game data in domain specific languages, prior work framed game mechanics design as a recommendation problem \cite{pitako}: game mechanics is represented as entities (e.g. shooter, enemy) and the interaction rules between them. Then, the framework recommend additional mechanics by maximizing entity overlaps between mechanics input and mechanics in the database.
Recently, as LLMs have shown its capabilities in creating content for interactive experience \cite{Ammanabrolu_2020,Todd_2023,words2worldsLi2024}, prior work further enhanced the recommendation pipeline by using LLMs to composite retrieved entities into game mechanics in short phrases \cite{charity2023conceptualgame}.

However, the following gaps exist: 
(1) Prior work fail to represent game mechanics with hierarchical dependency. For example, mechanics in platformer games are less dependent on each other: adding a double jump capability to the player will not affect the game experience when the player hit the trap. But in card games, adding a card stealing capability may contradict to a more fundamental mechanic where player wins by emptying its hand. Without a representation in hierarchical dependency, downstream tasks such as recommendation may not work well. 
(2) It remains unclear how to encourage novel mechanics design. We define ``novel design" here as creating game mechanics that are not seen in databases, which differs from ``recommendation" that retrieves existing game mechanics from databases~\cite{pitako}. To propose game mechanics that differ from database, it is necessary to gain a global understanding over the entire database, which has not been well discussed in prior game design studies.


Our method offers two improvements: 
(1) considering the prevalence of hierarchical dependencies in card game mechanics, we propose a new method to represent and extract game mechanics in directed graphs. 
(2) Inspired from \cite{edge2024localglobalgraphrag} that gains a global understanding of the database by summarizing and querying in entity clusters, we group similar game mechanics across all games into clusters, which are summarized, mutated, and retrieved in novel game design.



\subsection{Program synthesis in games}

Traditionally, many works focus on generating short code snippets in a specific domain such as matrix operations \cite{tfcoder} or list processing \cite{ellis_dreamcoder_2021}
. However, it is challenging to apply similar approach to game code generation, as it involves much larger search space, which does not suit iteration-based methods. 
Recently, large language models (LLM) have emerged as strong methods for program synthesis, where domain-specific fine-tuning~\cite{wu2024instructiondriven}, in-context learning 
\cite{Gao2023},
LLM agent systems
\cite{chatdev}
, and LLM pipelines \cite{agentless} are heavily studied. These methods have greatly improved code generation quality in many aspects, ranging from code snippets to real-world software engineering tasks~\cite{jimenez2024swebench}. 

However, it remains unclear how to validate the consistency between user instructions and generated code for interactive code environments, since I/O examples~\cite{liu2023is} are hard to generate in these cases.

\subsection{Game Intelligence}

Creating AI systems capable of playing games intelligently has been a long-standing research focus. Early approaches relied on manually crafted game features, optimized through combination processes \cite{sturtevant_feature_2007}. Over time, neural networks have automated both feature extraction and policy formulation \cite{schmid_student_2023,zha_douzero_2021,brown_superhuman_2019}. While these neural network-based approaches demonstrate exceptional gameplay intelligence, their model structures and game representations are often tailored to specific cases, limiting scalability across diverse games.


Recent advancements in large language models (LLMs) offer a promising solution to this limitation. Using natural language for inputs and reasoning, LLMs can adapt to a wide variety of games without case-specific customization. In related studies, LLMs have been employed as gameplay agents, wherein the models are invoked at every game turn \cite{yao_react_2023}, optionally supported by external storage for long-term memory or reflection~\cite{guo_suspicion-agent_2023,shinn_reflexion_2023,zhang2024agentpro}. 
Other studies combine LLMs with other neural networks by using LLMs to design reward functions \cite{ma_eureka_2023,baek2024chatpcg}, using neural networks to narrown down the search space for LLMs \cite{Yim2024guandan}, or training LLMs from scratch to predict game actions using real gameplay data \cite{schultz2024masteringboard}. 

To achieve scalable gameplay AI large-scale evaluations, we explore the following techniques that minimize the cost and latency in both construction and application stages: (1) we aims to get a gameplay policy in code \cite{liang_code_2023,light2024strategist} rather than leveraging LLMs in each game decision. (2) We do not optimize the policy by LLM-based reflections with gameplay data \cite{shinn_reflexion_2023}, as it can hardly be paralleled and introduce large noises. (3) We directly use win rate as optimization target rather than any fine-grained signals (such as reward by MCTS \cite{light2024strategist}), as they may not be effective in certain games (e.g. extremely unbalanced game state trees).