\section{Discussion}
Our work benefits the related research communities in the following ways: 

\paragraph{Game mechanics Representation}
The new graph-based game representation in our work, along with the corresponding extraction method, can be applied in various downstream tasks in related domain. For example, compared to game distance metrics that builds on low-level code structure \cite{distancemapping2021}, our work could facilitate a more explainable distance metric, as its node units incorporates higher-level abstractions with increased legibility. Also, as our graph-indexed database reveals the dependency between game mechanics (in Figure \ref{fig:mechanic_dependencies}), it can be integrated into a game mechanics recommendation framework with friendly user interface as \cite{pitako}, thus enabling a human-in-the-loop game design. In addition, our work can pre-process game descriptions to graphs, paving the way to a concept-based game generation model with a structure like \cite{lcmteam2024largeconceptmodelslanguage}.


\paragraph{Game Code Data Generator} Our work can be treated as a synthetic data generator specialized in creating programs with long and complex instruction. Its generated game code can be used to fine-tune domain specific code generative models \cite{wu2024instructiondriven}, or be used as test case data for general program synthesis methods.

\paragraph{Scalable Gameplay AI} 
Our experiments shows for a large proportion of card games, our method that does not require LLM calls during the gameplay, achieves similar performance as prior methods with gameplay LLM inference. Therefore, we could enable large applications of gameplay AI without the cost that increases with gameplay rounds, which benefits both consumer-oriented entertainment usse, and more affordable game prototyping.

\paragraph{Extendable Gameplay AI Benchmark}
Compared to prior work that focus on a small set of card games \cite{costarelli2024gamebench,zha_douzero_2021}, we provide a much larger scale game benchmark environment for gameplay AIs. 
Additionally, prior work in LLM-based gameplay AI suffers a limitation in evaluation: LLMs may have seen the game strategy during their training, making it challenge to evaluate the true performance of the gameplay framework. By designing and constructing novel game environments with minimal human effort, our work can help bridging this gap.

\paragraph{Limitation and Future Work}

In game mechanics design, the consistencies between game mechanics is a critical issue. While prior work \cite{pitako} advocates a human-computer cooperation to solve the potential conflicts, our work relies on the reflection capability of LLMs to mitigate this problem. However, as our work can extract game mechanics graphs from text descriptions, it would be beneficial to explore whether the mechanics graph can help the advanced reasoning on potential game mechanics conflicts.

In game code generation, the current validation process is inefficient, making its token cost close to that of adavanced model (such as o1). Future work may aim to lower the token use by other agent pipeline designs.

Currently, our game AI does not explicitly consider other players' intention, which is a commonly-used component in prior work \cite{zhang2024agentpro,guo_suspicion-agent_2023}. Besides, it could also be promising to explore whether the reasoning results from LLM agents (such as Reflexion \cite{shinn_reflexion_2023}) can be distilled to our policy-code-based results.