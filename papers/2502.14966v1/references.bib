@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{biggio2013evasion,
  title={Evasion attacks against machine learning at test time},
  author={Biggio, Battista and Corona, Igor and Maiorca, Davide and Nelson, Blaine and {\v{S}}rndi{\'c}, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
  journal={Machine learning and knowledge discovery in databases},
  pages={387--402},
  year={2013},
  publisher={Springer}
}

@article{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  journal={IEEE Symposium on Security and Privacy (SP)},
  pages={39--57},
  year={2017}
}

@article{buczak2016survey,
  title={A survey of data mining and machine learning methods for cyber security intrusion detection},
  author={Buczak, Anna L and Guven, Erhan},
  journal={IEEE Communications Surveys \& Tutorials},
  volume={18},
  number={2},
  pages={1153--1176},
  year={2016},
  publisher={IEEE}
}

@article{papernot2016limitations,
  title={The limitations of deep learning in adversarial settings},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  journal={IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={372--387},
  year={2016}
}

@article{tramer2017ensemble,
  title={Ensemble adversarial training: Attacks and defenses},
  author={Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  journal={arXiv preprint arXiv:1705.07204},
  year={2017}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{russell2022human,
  title={Human-compatible AI: Ensuring AI aligns with human values},
  author={Russell, Stuart},
  journal={AI Safety Journal},
  volume={7},
  pages={45--62},
  year={2022}
}

@article{sharif2016accessorize,
  title={Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition},
  author={Sharif, Mahmood and Bhagavatula, Sruti and Bauer, Lujo and Reiter, Michael K},
  journal={ACM SIGSAC Conference on Computer and Communications Security (CCS)},
  pages={1528--1540},
  year={2016}
}

@article{li2020deep,
  title={Deep learning for cyber security intrusion detection: Approaches, datasets, and comparative study},
  author={Li, Yuchao and Ma, Tao and Wang, Yong},
  journal={Journal of Information Security and Applications},
  volume={54},
  pages={102523},
  year={2020},
  publisher={Elsevier}
}

@article{kurakin2018adversarial,
  title={Adversarial attacks and defences competition},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy and others},
  journal={NeurIPS Workshop on Machine Learning and Security},
  year={2018}
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={7472--7482},
  year={2019}
}

@article{xu2018feature,
  title={Feature squeezing: Detecting adversarial examples in deep neural networks},
  author={Xu, Weilin and Evans, David and Qi, Yanjun},
  journal={Network and Distributed System Security (NDSS) Symposium},
  year={2018}
}

@article{lin2020framework,
  title={A framework for AI governance: Managing AI risks and building trustworthy AI},
  author={Lin, Herbert and Kerr, Jaclyn},
  journal={Journal of Cyber Policy},
  volume={5},
  number={1},
  pages={58--80},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{lecun2022path,
  title={Path towards autonomous machine intelligence},
  author={LeCun, Yann},
  journal={arXiv preprint arXiv:2206.04178},
  year={2022}
}

@article{mitchell2019explanation,
  title={Explanation in artificial intelligence: Insights from the social sciences},
  author={Mitchell, Sandra and Tolk, Andreas},
  journal={Artificial Intelligence Review},
  volume={53},
  pages={563--590},
  year={2019},
  publisher={Springer}
}

@article{ribeiro2016should,
  title={"Why should I trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  journal={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1135--1144},
  year={2016},
  publisher={ACM}
}

@article{hendrycks2021unsolved,
  title={Unsolved problems in ML safety},
  author={Hendrycks, Dan and Mazeika, Mantas and Kadavath, Saurav and Song, Dawn},
  journal={arXiv preprint arXiv:2109.13916},
  year={2021}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{doshi2020considerations,
  title={Considerations for differential privacy with machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={Nature Machine Intelligence},
  volume={2},
  number={7},
  pages={391--400},
  year={2020},
  publisher={Springer}
}

@article{carlin2020evaluating,
  title={Evaluating model robustness to adversarial attacks},
  author={Carlin, Nicholas and Wagner, David},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={15},
  pages={2483--2497},
  year={2020},
  publisher={IEEE}
}

@article{weidinger2022taxonomy,
  title={A taxonomy of risks posed by language models},
  author={Weidinger, Laura and Mellor, Joe and Rauh, Maribeth and others},
  journal={arXiv preprint arXiv:2206.05896},
  year={2022}
}

@article{goldblum2022dataset,
  title={Dataset security for machine learning: A survey},
  author={Goldblum, Micah and Carlini, Nicholas and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, Brendan and Avent, Brendan and others},
  journal={Foundations and Trends in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021}
}

@article{bhatt2021machine,
  title={Machine learning interpretability: A survey of methods and metrics},
  author={Bhatt, Umang and Weller, Adrian and Xiang, Alice},
  journal={ACM Computing Surveys},
  volume={54},
  number={5},
  pages={1--36},
  year={2021}
}

@article{brundage2020toward,
  title={Toward trustworthy AI development: Mechanisms for supporting verifiable claims},
  author={Brundage, Miles and Avin, Shahar and Wang, Jasmine and others},
  journal={arXiv preprint arXiv:2004.07213},
  year={2020}
}

@article{carlini2020evaluating,
  title={Evaluating the robustness of machine learning models to adversarial examples},
  author={Carlini, Nicholas and Wagner, David},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={15},
  pages={2483--2497},
  year={2020},
  publisher={IEEE}
}