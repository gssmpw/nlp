@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{kim2024biggen,
  title={The BiGGen Bench: A Principled Benchmark for Fine-grained Evaluation of Language Models with Language Models},
  author={Kim, Seungone and Suk, Juyoung and Cho, Ji Yong and Longpre, Shayne and Kim, Chaeeun and Yoon, Dongkeun and Son, Guijin and Cho, Yejin and Shafayat, Sheikh and Baek, Jinheon and others},
  journal={arXiv preprint arXiv:2406.05761},
  year={2024}
}

@article{zhang2024safe,
  title={Safe unlearning: A surprisingly effective and generalizable solution to defend against jailbreak attacks},
  author={Zhang, Zhexin and Yang, Junxiao and Ke, Pei and Cui, Shiyao and Zheng, Chujie and Wang, Hongning and Huang, Minlie},
  journal={arXiv preprint arXiv:2407.02855},
  year={2024}
}

@article{gallego2024configurable,
  title={Configurable Safety Tuning of Language Models with Synthetic Preference Data},
  author={Gallego, Victor},
  journal={arXiv preprint arXiv:2404.00495},
  year={2024}
}

@article{Xie2023DefendingCA,
  title={Defending ChatGPT against jailbreak attack via self-reminders},
  author={Yueqi Xie and Jingwei Yi and Jiawei Shao and Justin Curl and Lingjuan Lyu and Qifeng Chen and Xing Xie and Fangzhao Wu},
  journal={Nature Machine Intelligence},
  year={2023},
  volume={5},
  pages={1486-1496},
  url={https://api.semanticscholar.org/CorpusID:266289038}
}

@article{Wei2023JailbreakAG,
  title={Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations},
  author={Zeming Wei and Yifei Wang and Yisen Wang},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.06387},
  url={https://api.semanticscholar.org/CorpusID:263830179}
}

@article{mo2024studious,
  title={Studious bob fight back against jailbreaking via prompt adversarial tuning},
  author={Mo, Yichuan and Wang, Yuji and Wei, Zeming and Wang, Yisen},
  journal={arXiv preprint arXiv:2402.06255},
  year={2024}
}

@misc{
alon2024detecting,
title={Detecting Language Model Attacks With Perplexity},
author={Gabriel Alon and Michael J Kamfonas},
year={2024},
url={https://openreview.net/forum?id=lNLVvdHyAw}
}

@article{robey2023smoothllm,
  title={Smoothllm: Defending large language models against jailbreaking attacks},
  author={Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George J},
  journal={arXiv preprint arXiv:2310.03684},
  year={2023}
}

@article{ganguli2023capacity,
  title={The capacity for moral self-correction in large language models},
  author={Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas I and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others},
  journal={arXiv preprint arXiv:2302.07459},
  year={2023}
}

@article{shridhar2023art,
  title={The art of llm refinement: Ask, refine, and trust},
  author={Shridhar, Kumar and Sinha, Koustuv and Cohen, Andrew and Wang, Tianlu and Yu, Ping and Pasunuru, Ram and Sachan, Mrinmaya and Weston, Jason and Celikyilmaz, Asli},
  journal={arXiv preprint arXiv:2311.07961},
  year={2023}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{gu2024survey,
  title={A Survey on LLM-as-a-Judge},
  author={Gu, Jiawei and Jiang, Xuhui and Shi, Zhichao and Tan, Hexiang and Zhai, Xuehao and Xu, Chengjin and Li, Wei and Shen, Yinghan and Ma, Shengjie and Liu, Honghao and others},
  journal={arXiv preprint arXiv:2411.15594},
  year={2024}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@misc{metallamaguard2,
  author =       {LlamaTeam},
  title =        {Meta Llama Guard 2},
  howpublished = {\url{https://github.com/meta-llama/PurpleLlama/blob/main/Llama-Guard2/MODEL_CARD.md}},
  year =         {2024}
}


@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{kim2023prometheus,
  title={Prometheus: Inducing fine-grained evaluation capability in language models},
  author={Kim, Seungone and Shin, Jamin and Cho, Yejin and Jang, Joel and Longpre, Shayne and Lee, Hwaran and Yun, Sangdoo and Shin, Seongjin and Kim, Sungdong and Thorne, James and others},
  journal={arXiv preprint arXiv:2310.08491},
  year={2023}
}

@article{kim2024prometheus,
  title={Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models},
  author={Kim, Seungone and Suk, Juyoung and Longpre, Shayne and Lin, Bill Yuchen and Shin, Jamin and Welleck, Sean and Neubig, Graham and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon},
  journal={arXiv preprint arXiv:2405.01535},
  year={2024}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@misc{anil2024many,
  title={Many-shot Jailbreaking},
  author={Anil, Cem and Durmus, Esin and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Rimsky, Nina and Tong, Meg and Mu, Jesse and Ford, Daniel and others},
  year={2024}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{hinton2002training,
  title={Training products of experts by minimizing contrastive divergence},
  author={Hinton, Geoffrey E},
  journal={Neural computation},
  volume={14},
  number={8},
  pages={1771--1800},
  year={2002},
  publisher={MIT Press}
}

@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{textbooks2,
  title={Textbooks Are All You Need II: \textbf{phi-1.5} technical report},
  author={Li, Yuanzhi and Bubeck, S{\'e}bastien and Eldan, Ronen and Del Giorno, Allie and Gunasekar, Suriya and Lee, Yin Tat},
  journal={arXiv preprint arXiv:2309.05463},
  year={2023}
}

@article{gulcehre2023reinforced,
  title={Reinforced self-training (rest) for language modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}

@article{lee2023rlaif,
  title={Rlaif: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}

@article{conneau2019unsupervised,
  title={Unsupervised Cross-lingual Representation Learning at Scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@misc{zou2023universal,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{korbak2022rl,
  title={RL with KL penalties is better viewed as Bayesian inference},
  author={Korbak, Tomasz and Perez, Ethan and Buckley, Christopher},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={1083--1091},
  year={2022}
}

@article{eldan2023s,
  title={Who's Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{qiang2023hijacking,
  title={Hijacking Large Language Models via Adversarial In-Context Learning},
  author={Qiang, Yao and Zhou, Xiangyu and Zhu, Dongxiao},
  journal={arXiv preprint arXiv:2311.09948},
  year={2023}
}

@article{casper2023explore,
  title={Explore, Establish, Exploit: Red Teaming Language Models from Scratch},
  author={Casper, Stephen and Lin, Jason and Kwon, Joe and Culp, Gatlen and Hadfield-Menell, Dylan},
  journal={arXiv preprint arXiv:2306.09442},
  year={2023}
}


@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}

@article{deng2022rlprompt,
  title={Rlprompt: Optimizing discrete text prompts with reinforcement learning},
  author={Deng, Mingkai and Wang, Jianyu and Hsieh, Cheng-Ping and Wang, Yihan and Guo, Han and Shu, Tianmin and Song, Meng and Xing, Eric P and Hu, Zhiting},
  journal={arXiv preprint arXiv:2205.12548},
  year={2022}
}

@misc{open-llm-leaderboard,
  author = {Edward Beeching and Clémentine Fourrier and Nathan Habib and Sheon Han and Nathan Lambert and Nazneen Rajani and Omar Sanseviero and Lewis Tunstall and Thomas Wolf},
  title = {Open LLM Leaderboard},
  year = {2023},
  publisher = {Hugging Face},
  howpublished = "\url{https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard}"
}


@article{jones2023automatically,
  title={Automatically Auditing Large Language Models via Discrete Optimization},
  author={Jones, Erik and Dragan, Anca and Raghunathan, Aditi and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2303.04381},
  year={2023}
}

@article{carlini2023aligned,
  title={Are aligned neural networks adversarially aligned?},
  author={Carlini, Nicholas and Nasr, Milad and Choquette-Choo, Christopher A and Jagielski, Matthew and Gao, Irena and Awadalla, Anas and Koh, Pang Wei and Ippolito, Daphne and Lee, Katherine and Tramer, Florian and others},
  journal={arXiv preprint arXiv:2306.15447},
  year={2023}
}

@article{liu2023jailbreaking,
  title={Jailbreaking chatgpt via prompt engineering: An empirical study},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Liu, Yang},
  journal={arXiv preprint arXiv:2305.13860},
  year={2023}
}

@article{wei2023jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2307.02483},
  year={2023}
}

@article{shah2023scalable,
  title={Scalable and transferable black-box jailbreaks for language models via persona modulation},
  author={Shah, Rusheb and Pour, Soroush and Tagade, Arush and Casper, Stephen and Rando, Javier and others},
  journal={arXiv preprint arXiv:2311.03348},
  year={2023}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@misc{openhermes,
author = {@Teknium},
  title = {OpenHermes 2.5 - Mistral 7B},
  howpublished = {\url{https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B}},
  note = {Accessed: 2023-12-09},
year = {2023}
}

@article{tunstall2023zephyr,
  title={Zephyr: Direct distillation of lm alignment},
  author={Tunstall, Lewis and Beeching, Edward and Lambert, Nathan and Rajani, Nazneen and Rasul, Kashif and Belkada, Younes and Huang, Shengyi and von Werra, Leandro and Fourrier, Cl{\'e}mentine and Habib, Nathan and others},
  journal={arXiv preprint arXiv:2310.16944},
  year={2023}
}

@misc{bge-m3,
      title={BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation}, 
      author={Jianlv Chen and Shitao Xiao and Peitian Zhang and Kun Luo and Defu Lian and Zheng Liu},
      year={2024},
      eprint={2402.03216},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{deng2023rephrase,
  title={Rephrase and respond: Let large language models ask better questions for themselves},
  author={Deng, Yihe and Zhang, Weitong and Chen, Zixiang and Gu, Quanquan},
  journal={arXiv preprint arXiv:2311.04205},
  year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@inproceedings{josifoski-etal-2023-exploiting,
    title = "Exploiting Asymmetry for Synthetic Training Data Generation: {S}ynth{IE} and the Case of Information Extraction",
    author = "Josifoski, Martin  and
      Sakota, Marija  and
      Peyrard, Maxime  and
      West, Robert",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.96",
    doi = "10.18653/v1/2023.emnlp-main.96",
    pages = "1555--1574",
    abstract = "Large language models (LLMs) have great potential for synthetic data generation. This work shows that useful data can be synthetically generated even for tasks that cannot be solved directly by LLMs: for problems with structured outputs, it is possible to prompt an LLM to perform the task in the reverse direction, by generating plausible input text for a target output structure. Leveraging this asymmetry in task difficulty makes it possible to produce large-scale, high-quality data for complex tasks. We demonstrate the effectiveness of this approach on closed information extraction, where collecting ground-truth data is challenging, and no satisfactory dataset exists to date. We synthetically generate a dataset of 1.8M data points, establish its superior quality compared to existing datasets in a human evaluation, and use it to finetune small models (220M and 770M parameters), termed SynthIE, that outperform the prior state of the art (with equal model size) by a substantial margin of 57 absolute points in micro-F1 and 79 points in macro-F1. Code, data, and models are available at anonymous.",
}

@inproceedings{
gallego2024distilled,
title={Distilled Self-Critique of {LLM}s with Synthetic Data: a Bayesian Perspective},
author={Victor Gallego},
booktitle={The Second Tiny Papers Track at ICLR 2024},
year={2024},
url={https://openreview.net/forum?id=AfVtVrCH9U}
}

@inproceedings{
yadav2023tiesmerging,
title={{TIES}-Merging: Resolving Interference When Merging Models},
author={Prateek Yadav and Derek Tam and Leshem Choshen and Colin Raffel and Mohit Bansal},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=xtaX3WyCj1}
}

@article{yu2023language,
  title={Language models are super mario: Absorbing abilities from homologous models as a free lunch},
  author={Yu, Le and Yu, Bowen and Yu, Haiyang and Huang, Fei and Li, Yongbin},
  journal={arXiv preprint arXiv:2311.03099},
  year={2023}
}

@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@misc{lu2024online,
      title={Online Merging Optimizers for Boosting Rewards and Mitigating Tax in Alignment}, 
      author={Keming Lu and Bowen Yu and Fei Huang and Yang Fan and Runji Lin and Chang Zhou},
      year={2024},
      eprint={2405.17931},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@inproceedings{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, P and Wilson, AG and Podoprikhin, D and Vetrov, D and Garipov, T},
  booktitle={34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018},
  pages={876--885},
  year={2018}
}

@inproceedings{
entezari2022the,
title={The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks},
author={Rahim Entezari and Hanie Sedghi and Olga Saukh and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=dNigytemkL}
}

@inproceedings{stoica2023zipit,
  title={ZipIt! Merging Models from Different Tasks without Training},
  author={Stoica, George and Bolya, Daniel and Bjorner, Jakob Brandt and Ramesh, Pratik and Hearn, Taylor and Hoffman, Judy},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International conference on machine learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@article{verma2024merging,
  title={Merging text transformer models from different initializations},
  author={Verma, Neha and Elbayad, Maha},
  journal={arXiv preprint arXiv:2403.00986},
  year={2024}
}

@article{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023}
}

@article{shanahan2023role,
  title={Role play with large language models},
  author={Shanahan, Murray and McDonell, Kyle and Reynolds, Laria},
  journal={Nature},
  volume={623},
  number={7987},
  pages={493--498},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{wang2024defending,
  title={Defending LLMs against Jailbreaking Attacks via Backtranslation},
  author={Wang, Yihan and Shi, Zhouxing and Bai, Andrew and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2402.16459},
  year={2024}
}

@inproceedings{deshpande-etal-2023-toxicity,
    title = "Toxicity in chatgpt: Analyzing persona-assigned language models",
    author = "Deshpande, Ameet  and
      Murahari, Vishvak  and
      Rajpurohit, Tanmay  and
      Kalyan, Ashwin  and
      Narasimhan, Karthik",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.88",
    doi = "10.18653/v1/2023.findings-emnlp.88",
    pages = "1236--1270",
    abstract = "Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Legislation has recognized its significance and recently drafted a {``}Blueprint For An AI Bill Of Rights{''} which calls for domain experts to identify risks and potential impact of AI systems. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to $6\times$, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others ($3\times$ more) irrespective of the assigned persona, reflecting discriminatory biases in the model. Our findings show that multiple provisions in the legislative blueprint are being violated, and we hope that the broader AI community rethinks the efficacy of current safety guardrails and develops better techniques that lead to robust, safe, and trustworthy AI.",
}


@inproceedings{utans1996weight,
  title={Weight averaging for neural networks and local resampling schemes},
  author={Utans, Joachim},
  booktitle={Proc. AAAI-96 Workshop on Integrating Multiple Learned Models. AAAI Press},
  pages={133--138},
  year={1996},
  organization={Citeseer}
}

@article{liu2023tinygsm,
  title={Tinygsm: achieving> 80\% on gsm8k with small language models},
  author={Liu, Bingbin and Bubeck, Sebastien and Eldan, Ronen and Kulkarni, Janardhan and Li, Yuanzhi and Nguyen, Anh and Ward, Rachel and Zhang, Yi},
  journal={arXiv preprint arXiv:2312.09241},
  year={2023}
}

@inproceedings{
ainsworth2023git,
title={Git Re-Basin: Merging Models modulo Permutation Symmetries},
author={Samuel Ainsworth and Jonathan Hayase and Siddhartha Srinivasa},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=CQsmMYmlP5T}
}

@article{yu2023metamath,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}

@article{liu2023autodan,
  title={Autodan: Generating stealthy jailbreak prompts on aligned large language models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2310.04451},
  year={2023}
}

@inproceedings{ward2023honesty,
  title={Honesty is the best policy: defining and mitigating AI deception},
  author={Ward, Francis Rhys and Everitt, Tom and Belardinelli, Francesco and Toni, Francesca},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{jailbreaks,
      author = {Xinyue Shen and Zeyuan Chen and Michael Backes and Yun Shen and Yang Zhang},
      title = {{"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models}},
      journal = {{CoRR abs/2308.03825}},
      year = {2023}
}



@article{zhu2023autodan,
  title={AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models},
  author={Zhu, Sicheng and Zhang, Ruiyi and An, Bang and Wu, Gang and Barrow, Joe and Wang, Zichao and Huang, Furong and Nenkova, Ani and Sun, Tong},
  journal={arXiv preprint arXiv:2310.15140},
  year={2023}
}

@inproceedings{gallego2019reinforcement,
  title={Reinforcement learning under threats},
  author={Gallego, Victor and Naveiro, Roi and Insua, David Rios},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={9939--9940},
  year={2019}
}

@article{gallego2020protecting,
  title={Protecting classifiers from attacks. a bayesian approach},
  author={Gallego, Victor and Naveiro, Roi and Redondo, Alberto and Insua, David Rios and Ruggeri, Fabrizio},
  journal={arXiv preprint arXiv:2004.08705},
  year={2020}
}

@article{rios2023adversarial,
  title={Adversarial machine learning: Bayesian perspectives},
  author={Rios Insua, David and Naveiro, Roi and Gallego, V{\'\i}ctor and Poulos, Jason},
  journal={Journal of the American Statistical Association},
  pages={1--12},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{weston2023system,
  title={System 2 Attention (is something you might need too)},
  author={Weston, Jason and Sukhbaatar, Sainbayar},
  journal={arXiv preprint arXiv:2311.11829},
  year={2023}
}

@article{hhh,
  author    = {Amanda Askell and
               Yuntao Bai and
               Anna Chen and
               Dawn Drain and
               Deep Ganguli and
               Tom Henighan and
               Andy Jones and
               Nicholas Joseph and
               Benjamin Mann and
               Nova DasSarma and
               Nelson Elhage and
               Zac Hatfield{-}Dodds and
               Danny Hernandez and
               Jackson Kernion and
               Kamal Ndousse and
               Catherine Olsson and
               Dario Amodei and
               Tom B. Brown and
               Jack Clark and
               Sam McCandlish and
               Chris Olah and
               Jared Kaplan},
  title     = {A General Language Assistant as a Laboratory for Alignment},
  journal   = {CoRR},
  volume    = {abs/2112.00861},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.00861},
  eprinttype = {arXiv},
  eprint    = {2112.00861},
  timestamp = {Tue, 07 Dec 2021 12:15:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-00861.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bertsch2023s,
  title={It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk},
  author={Bertsch, Amanda and Xie, Alex and Neubig, Graham and Gormley, Matthew R},
  booktitle={Proceedings of the Big Picture Workshop},
  pages={108--122},
  year={2023}
}


@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}

@inproceedings{shen2024anything,
  title={" do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models},
  author={Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
  booktitle={Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages={1671--1685},
  year={2024}
}

@inproceedings{
gallego2024merging,
title={Merging Improves Self-Critique Against Jailbreak Attacks},
author={Victor Gallego},
booktitle={ICML 2024 Workshop on Foundation Models in the Wild},
year={2024},
url={https://openreview.net/forum?id=HmYJ16ehbX}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{wang2025critique,
  title={Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate},
  author={Wang, Yubo and Yue, Xiang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2501.17703},
  year={2025}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{guan2024deliberative,
  title={Deliberative alignment: Reasoning enables safer language models},
  author={Guan, Melody Y and Joglekar, Manas and Wallace, Eric and Jain, Saachi and Barak, Boaz and Heylar, Alec and Dias, Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and others},
  journal={arXiv preprint arXiv:2412.16339},
  year={2024}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2024language,
  title={Language models are hidden reasoners: Unlocking latent reasoning capabilities via self-rewarding},
  author={Chen, Haolin and Feng, Yihao and Liu, Zuxin and Yao, Weiran and Prabhakar, Akshara and Heinecke, Shelby and Ho, Ricky and Mui, Phil and Savarese, Silvio and Xiong, Caiming and others},
  journal={arXiv preprint arXiv:2411.04282},
  year={2024}
}