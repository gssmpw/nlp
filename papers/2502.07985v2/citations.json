[
  {
    "index": 0,
    "papers": [
      {
        "key": "madaan2024self",
        "author": "Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others",
        "title": "Self-refine: Iterative refinement with self-feedback"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "shinn2024reflexion",
        "author": "Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu",
        "title": "Reflexion: Language agents with verbal reinforcement learning"
      },
      {
        "key": "shridhar2023art",
        "author": "Shridhar, Kumar and Sinha, Koustuv and Cohen, Andrew and Wang, Tianlu and Yu, Ping and Pasunuru, Ram and Sachan, Mrinmaya and Weston, Jason and Celikyilmaz, Asli",
        "title": "The art of llm refinement: Ask, refine, and trust"
      },
      {
        "key": "ganguli2023capacity",
        "author": "Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas I and Luko{\\v{s}}i{\\=u}t{\\.e}, Kamil{\\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others",
        "title": "The capacity for moral self-correction in large language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2025critique",
        "author": "Wang, Yubo and Yue, Xiang and Chen, Wenhu",
        "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "christiano2017deep",
        "author": "Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario",
        "title": "Deep reinforcement learning from human preferences"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional ai: Harmlessness from ai feedback"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "alon2024detecting",
        "author": "Gabriel Alon and Michael J Kamfonas",
        "title": "Detecting Language Model Attacks With Perplexity"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "robey2023smoothllm",
        "author": "Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George J",
        "title": "Smoothllm: Defending large language models against jailbreaking attacks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "mo2024studious",
        "author": "Mo, Yichuan and Wang, Yuji and Wei, Zeming and Wang, Yisen",
        "title": "Studious bob fight back against jailbreaking via prompt adversarial tuning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "Wei2023JailbreakAG",
        "author": "Zeming Wei and Yifei Wang and Yisen Wang",
        "title": "Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Xie2023DefendingCA",
        "author": "Yueqi Xie and Jingwei Yi and Jiawei Shao and Justin Curl and Lingjuan Lyu and Qifeng Chen and Xing Xie and Fangzhao Wu",
        "title": "Defending ChatGPT against jailbreak attack via self-reminders"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "gallego2024configurable",
        "author": "Gallego, Victor",
        "title": "Configurable Safety Tuning of Language Models with Synthetic Preference Data"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhang2024safe",
        "author": "Zhang, Zhexin and Yang, Junxiao and Ke, Pei and Cui, Shiyao and Zheng, Chujie and Wang, Hongning and Huang, Minlie",
        "title": "Safe unlearning: A surprisingly effective and generalizable solution to defend against jailbreak attacks"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "guan2024deliberative",
        "author": "Guan, Melody Y and Joglekar, Manas and Wallace, Eric and Jain, Saachi and Barak, Boaz and Heylar, Alec and Dias, Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and others",
        "title": "Deliberative alignment: Reasoning enables safer language models"
      }
    ]
  }
]