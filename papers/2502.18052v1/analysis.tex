\section{Analysis}

In this section we set out to
% give a theoretical characterization
analyze basic properties of accuracy markets. 
% from multiple perspectives.
To permit tractable analysis,
here we focus on simple two player markets.
We start with a restricted model class,
and then proceed to consider more general classes.
% \blue{To permit tractable analysis, we focus on simple markets,
% starting with markets having two players with restricted model classes, 
% and then moving on to consider more general model classes and additional providers.}\nir{rephrase}
Proofs for all results are deferred to Appendix~\ref{appx:proofs}.

We begin with some basic notation and properties that are useful for games
with $n=2$. Fix $p$, and consider some $H$.
For each provider $s_i$,
denote the accuracy of its chosen $h_i$ as:
\squeeze
\begin{equation}
\label{eq:acc}
a_i = \expect{p}{\one{h_i(x)=y}}
\end{equation}
We define the \emph{partial discrepancy} of $h_i$ relative to $h_j$ as:
\begin{equation}
\label{eq:discrepancy}    
\delta_{ij} = \delta_{i}(h_j) = \expect{p}{\one{h_i(x)=y \,\wedge\, h_j(x) \neq y}}
\end{equation}
which sums points on which $h_i$ is correct on but $h_j$ is wrong.
% \ohadadd{do we mention conn. to pred. multiplicity paper?}
% We use $\delta_{ij}=\delta_i(h_j)$.

\begin{proposition}
\label{prop:utils_of_players}
% Fix $p$, and let $H=\{h_1,h_2\}$, then
Let $h_i,h_j$,
% it holds that 
then
$\ms(h_i \mid h_j) = \frac{1}{2}(a_i + \delta_{ij})$.
\end{proposition}
% Prop.~\ref{prop:utils_of_players}
This implies that there are two ways to increase market share: by improving overall accuracy ($a_i$),
or by being exclusively correct on more points ($\delta_{ij}$).
Thus, the choice of $h$ should consider how these two terms trade off.
Note that points in $\delta_{ij}$ are counted twice,
since they are also included in $a_i$.
\squeeze

% \ohadadd{\cref{prop:utils_of_players} exemplifies the trade-off between the accuracy and the partial discrepancy of the chosen model. points in the partial discrepancy are twice as important, since they are counted in both $a_i$ and $\delta_{ij}$. }

% When both providers choose the same classifier,
% they share the same user base, and each market share is half of the classifier's accuracy.
% In contrast,
% when they choose different classifiers, then gains depend on accuracy \emph{and} on discrepancy in equal parts.
% This means that providers aim for accuracy, 
% but also compete over who gains exclusive access to certain segments of the user population.

Interestingly, %in $2 \times 2$ games,
as long as the classifiers are distinct,
then whoever has higher accuracy also secures a larger market share:
\squeeze
\begin{proposition}
\label{prop:acc_iff_ms}
For any $h_i \neq h_j$,
it holds that:
\begin{equation}
\label{eq:acc_iff_ms}
\ms(h_i \mid h_j) > \ms(h_j \mid h_i)
\,\,\Leftrightarrow\,\,
a_i > a_j
\end{equation}
\end{proposition}
This, however, should not be taken to imply that maximizing accuracy is a good strategy,
since providers seek to maximize their \emph{absolute} market share---not their market share in relation to others.
Regardless of the other's market share, a provider may 
switch to an equally accurate classifier%
\footnote{This is a likely scenario: see works on the `Rashomon' effect \citep{paes2023inevitability}
and model multiplicity \citep{semenova2022existence}.
\squeeze}%
--- or even sacrifice in accuracy
to gain greater discrepancy--- if this results in market share increasing.
Empirically we observe that sacrificing accuracy is both common and effective.
% since once e.g. $s_i$ has $a_i > a_j$,
% provider $s_j$ will respond by choosing $h_j$ to improve its \emph{absolute}

% Such sacrifice is possible, but not always necessary,
% in the likely case where there are multiple models with equally high accuracy

% Note that switching from one classifier to another with the same accuracy


% \todo{need/have other notation/properties/results that should go here?}

% {\green{\rule{\columnwidth}{3pt}}}

%---------------------------------------------------------------------

% \ohad{\\
% - \cref{prop:utils_of_players}, \ref{prop:acc_iff_ms} are 2xH results, so they are more general than the 2X2 game.
% Perhaps we should state them  before the 2x2 warmup, meaning split the analysis into 2 general sections: 2 player vs. N player, and then within 2 player have subsections based on $H$. \\
% - 
% }

%======================================
%---------PAYOFF MATRIX TABLE----------
\begin{table}[t!]
    \setlength{\extrarowheight}{8pt}
    \centering
    \resizebox{0.46\textwidth}{!}{
    \begin{NiceTabular}{ccc}[cell-space-limits=2pt]
       & \tableblue{$h_1$}     & \tableblue{$h_2$} \\
      \tablered{$h_1$} & \Block[hvlines]{2-2}{}
           $\tablered{\frac{1}{2}a_1},\tableblue{\frac{1}{2}a_1}$ & $\tablered{\frac{1}{2}(a_1 + \delta_{12})},\tableblue{\frac{1}{2}(a_2 + \delta_{21})}$ \\
      \tablered{$h_2$} & $\tablered{\frac{1}{2}(a_2 + \delta_{21})},\tableblue{\frac{1}{2}(a_1 + \delta_{12})}$ &$\tablered{\frac{1}{2}a_2},\tableblue{\frac{1}{2}a_2}$ 
\end{NiceTabular}}
    \caption{Payoff matrix of the 2x2 game}
    \label{tab:payoff_matrix_2x2}
\end{table}
%======================================
%====================================

\subsection{Warmup: $2 \times 2$ accuracy markets} \label{sec:2x2}
Consider a simple setting with $n=2$ providers and a shared model class of size two, $H=\{h_1,h_2\}$.
For example, these could be two available pre-trained models,
or an existing model that is already in deployment and a new model that is a possible alternative.
Such $2 \times 2$ games are fully determined by the tuple
$(a_1, a_2, \delta_{12}, \delta_{21})$---see \cref{tab:payoff_matrix_2x2}.
This formulation enables a characterization of all possible equilibria:
\squeeze
\begin{theorem}
\label{thm:2x2_pne}
Let $H = \{h_1,h_2\}$. Then for any $p$, 
the game admits one of two following types:
% 's pure Nash equilibria admit one of two possible types:
\begin{enumerate}[leftmargin=1.3em,topsep=0em,itemsep=0.1em]
\item \textbf{Dominant-strategy}: either $(h_1,h_1)$ or $(h_2,h_2)$ is a PNE
\item \textbf{Anti-coordination}: both $(h_1,h_2)$ and $(h_2,h_1)$ are PNEs 
\squeeze
\end{enumerate}
% Let $H = \{h_1,h_2\}$. Then for any $p$, either:
% \begin{enumerate}[leftmargin=1.7em,topsep=0em,itemsep=0.1em]
% \item There is a single dominant-strategy equilibrium, or
% \item Anti-coordination is the only stable outcome
% \end{enumerate}
\end{theorem}
In the latter case, 
the game admits a chicken-like%
\footnote{The standard Chicken game has payoffs of the form
\textbf{T}emptation$>$\textbf{C}oordination$>$\textbf{N}eutral$>$\textbf{P}unishment;
our variant has
\textbf{T}$>$\textbf{N}$>$\textbf{P}$>$\textbf{C}$>0$,
which preserves the same PNE.
}
structure:
one provider obtains a larger market share by choosing the `better' classifier, while the other must settle for the smaller share.
Note that better here does not mean more accurate,
as outcomes at equilibrium also depend on discrepancy.
% \squeeze
% We next show that the above properties hold more broadly.
The proof of Thm.~\ref{thm:2x2_pne} relies on the following result:
\begin{lemma}
\label{lem:2x2_pne}
Providers will choose differing strategies at equilibrium if and only if
$|a_1-a_2| \le \frac{1}{3}(\delta_{12} + \delta_{21})$.
% $|\delta_{12} - \delta_{21}| \le \frac{1}{3}(\delta_{12} + \delta_{21})$.
\end{lemma}
Thus, anti-coordination emerges when $h_1,h_2$ are sufficiently similar in terms of accuracy, but note that the condition is fairly lenient.
Empirically, we observe that chicken play
is by far the more prevalent scenario,
and that the order of play (which is only hinted to here) is highly significant.
We next show that the above properties hold more broadly.

% this breaks for $n>2$


% \todo{say that bounded $|\delta_{12}-\delta_{21}|$ }

% \ohadadd{Together with Prop.~\ref{prop:acc_iff_ms}, we receive that}
% accuracy markets admit an anti-coordination structure:
% as long as $h_1$ and $h_2$
% % the classifiers in $H$
% are sufficiently \ohadadd{similar in power},
% % distinct (in terms of partial discrepancy), then
% % in terms of who they are correct on,
% % then using the same classifier is suboptimal, and 
% providers will compete over who secures the better classifier.
% Note `better' here is not in terms of accuracy alone,
% but also in discrepancy, i.e. securing exclusive access to a larger subset of users.
% In terms of dynamics, the chicken-like structure of the game implies that 
%  providers gain more when playing second, 
%  \ohadadd{meaning it is better to wait for the competitors to act first.}
%  % i.e., entering an existing market is more advantageous than forming one.


% \squeeze


% RESULT: either we have a DS (claim 1), or a chicken game PNE (observation 3):
% – DSNE: if deltas are close together H > X > L, Y
% – chicken PNE: if both start with better classifier, both would benefit from switching but prefer the
% other does. H > L > X > Y


%---------------------------------------------------------------------

\subsection{Accuracy markets with threshold classifiers} \label{sec:2xH}
Keeping $n=2$,
consider a more general accuracy game
in which $y \in \{0,1\}$, inputs are scalar ($x \in \R$),
and $H$ comprises threshold classifiers $h_\tau(x)=\one{x > \tau}$.
This also captures settings with general inputs $x$
where there is a pre-trained score function $f(x)$
and each $s_i$ can set its own thresholds as $h_i(x)=\one{f(x) > \tau_i}$;
i.e., competition revolves around different ways to `set the bar' w.r.t. $f(x)$.
% \squeeze
 
% \todo{real example(s) for threshold competition?}

Our next result shows that under certain conditions,
even though $H$ includes a continuum of models,
the game simplifies significantly.
% effectively reduces to the $2 \times 2$ setting in terms of its equilibrium.
Consider the following common property:
% We make use of the \emph{monotone likelihood ratio} property:
\begin{definition}[MLR]
\label{def:mlrp}
Let $p(x,y)$ be continuous in $x$,
and $f_y$ the PDF of each conditional $p(x|y)$ for $y \in \{0,1\}$.
We say that $p$ exhibits a \emph{(strict) monotone likelihood ratio} (MLR)
if the density ratio $\ratio(x) = \frac{f_1(x)}{f_0(x)}$ is (strictly) increasing.
\end{definition}
We show that MLR entails a simple closed-form solution
to the best-response classifier against any other classifier:
\squeeze
\begin{theorem}
\label{thm:mlr_br}
Fix $n=2$, and let $H = \{h_\tau\}$ be a class of threshold classifiers over $d=1$.
Let $p$ be such that it is strictly MLR in some interval $[a,b]$.
Then for any $\tau \in [a,b]$:
\[
\br_{[a,b]}(\tau) \in \left\{
\max\{a, \ratio^{-1}(1/2)\},
\min \{b, \ratio^{-1}(2) \}
\right\}
\]
where $\br_{[a,b]}(\tau)$ is the best-response to $\tau$ from the set $[a,b]$.
\end{theorem}

Thm.~\ref{thm:mlr_br} states that of all thresholds in the range where MLR holds, the set of candidates for a best-response classifier reduces to just two. 
For natural cases in which the extreme choices of $\tau < a$ and $\tau > b$ are not optimal,%
\footnote{For example, a mixture of two Gaussians is MLR everywhere
except possibly in the far tails, where thresholding is ineffective.}
the structure of the game simplifies even further.
\begin{corollary}
\label{corr:thresh-2x2_reduction}
For $n=2$ and $H=\{h_\tau\}$,
any accuracy game played on an MLR region of $p$ reduces
to a $2 \times 2$ game. Hence, all results from Sec.~\ref{sec:2x2} hold.
\end{corollary}
Note the reduced model class is
$H = \{\ratio^{-1}(1/2), \ratio^{-1}(2)\}$.\footnote{If they exist; otherwise the optimal models are at $a,b$; see Thm.~\ref{thm:mlr_br}.}
This is not by chance:
under MLR, these ratios are precisely the points in which accuracy and discrepancy balance each other.
Interestingly, this partitions the population into three segments:
mostly negative points, mostly positive, and a mixed subpopulation.
% (lower than $\ratio^{-1}(1/2)$, higher than $\ratio^{-1}(2)$, and between them),
Providers then compete over who obtains exclusive access to the more rewarding segments.

% \nir{note to self: vs general 1D result, MLR gives (1) reduction to 2x2, (2) closed form $H$, that (3) does not depend on $h^0$}

% `tipping points' determining which
% segments of the user population each classifier should target.

% \todo{closed form solution for effective $H$? if yes, in appx}

Thm.~\ref{thm:mlr_br} can be generalized to any 1D distribution:
\begin{theorem}
\label{thm:generalized_br_1d}
Fix $n=2$, and let $H = \{h_\tau\}$ be a class of threshold classifiers.
% over $d=1$.
Then for any interval $[a,b]$ and any $\tau$:
\[
\br_{[a,b]}(\tau) \in \{ a,\,b, \, \tau \} \cup  P_+^{-1}(1/2) \cup P_+^{-1}(2)
\]
where $P_+^{-1}(z) = \{\tau: \rho(\tau) = z \land \rho'(\tau) >0 \}$.
\end{theorem}
For reasonable distributions, 
it is likely that $| P_+^{-1}(z)| < c$ for some small constant $c$.
This then implies that $H$ effectively reduces to include only
% Thm.~\ref{thm:generalized_br_1d} shows that these games are $c$-reasonable, meaning they reduce to
$O(c)$ candidate strategies.

The above results
% Thm.~\ref{thm:mlr_br}
% This observation
also have implications on dynamics:
\begin{proposition}
\label{prop:gen-br-1rd}
For $n=2$ and $H = \{h_\tau\}$,
% In the above setting,
best-response dynamics converge after one round.
\end{proposition}
We therefore receive that for threshold classifiers, not only is calculating the best-response a simple task, but the market also converges immediately.
The difference from the MLR setting is that
there can now be multiple equilibria,
and convergence can depend on the initial choices of $\{h_i^0\}$.

Best-response dynamics imply that model updates can  improve market share only for the provider that responds.
Interestingly, in the above setting, we can show that a best-response by one player improves outcomes also for the other.
\squeeze
% \todo{state "I improve, you improve" result}
\begin{proposition} %n=2, d=1, H=thresh
\label{prop:i-improve-you-improve}
Let $h_i^0 = h_{opt}, \, \forall i$.
Then for each $s_i$, market share $\ms_i$ increases even when the other $s_j$ best-responds.
% Let $h_i = \br{h_j}$, then $\ms(h_i \,|\, h_j) \ge $
\end{proposition}
Empirically, we observe that this form of implicit cooperation emerges
also in broader settings.
For $n>2$, outcomes improve once all other players have responded.





% \nir{\\%
% - do we assume $\ratio^{-1}(1/2), \ratio^{-1}(2) \in [a,b]$? \\
% - rashomon results? \\
% - more general pointwise condition for arbitrary $H$?
% }


%---------------------------------------------------------------------

\subsection{Accuracy markets for general model classes}
% We now turn to our most general market formulation
% that supports any number of providers $n$,
% general data distributions $p(x,y)$,
% and arbitrary (and possibly distinct) model classes $H_1,\dots, H_m$.

For general classes and $n=2$,
several properties of the market can still be established.
The first considers providers:
\begin{proposition}
\label{prop:ms_increases}
If $h_i^0=h^0 \,\, \forall i$,  for some $h^0$,
then $\ms_i^* \ge \ms_i^0$.
\end{proposition}
That is, if providers start at the same initial classifier,
then all of them will provably gain from competition.
This directly implies that competition also improves welfare for users:
\begin{corollary}
\label{corr:welfare}
% Competition improves welfare.
Fix initial classifier $\h^0 \,  \forall i$, and let $\h^*$
be the set of classifiers at equilibrium. Then
$\welf(\h^*) \ge \welf(\h^0)$.
% \squeeze
\end{corollary}

In terms of the market, we can bound its concentration:
\begin{proposition}
\label{prop:bounded_market_concentration}
Let $\h^*=(h_i,h_j)$ be any equilibrium.
Then $ \ms(h_i|h_j)\le 2\cdot\ms(h_j|h_i)$.
% \todo{bound on difference of partial discrepancies}
\end{proposition}
Thus,
despite the tendency for differentiation under competition,
no player can dominate more than $2/3$ of the market.

% \ohad{Perhaps we should talk about bounded difference in market share instead ($ \ms(h_1|h_2)\le 2\cdot\ms(h_2|h_1)$). also can we put this result in the previous section? applies to 2xH as well}


\paragraph{General accuracy markets.}
% We observe this holds empirically, along with 
Empirically, many of our above results hold also for any number of players
and general model classes:
quick convergence, implicit cooperation,
an incentive to differentiate, sacrificing accuracy for market share,
bounded market concentration, and high welfare.
% and the need to result to approximate solutions.
Some results however do not carry over to $n>2$;
for example, the order of play becomes much more intricate,
and whether moving first is good or bad can depend on context.
% The only result we are familiar with that applies to the general setting
% is \citet{ben2019regression} who show that best-response dynamics converge to a PNE after a finite number of rounds.
Importantly, our results hold despite the intractability of computing best responses exactly,
and by using our method for learning approximate best responses---%
presented next.



% and $p$ and $H_i$, OBP shows BR converge to PNE \\
% - result: concentration [prop 3] \\
% - result: if $h_i^0=h^0 \, \forall i$, then at equi $\ms_i^* \ge \ms_i^0$ \\
% - corr: welfare at equi is better

% \todo{say that empirically we observe that all we said for 2xH hold also for $d>1$ and $n>2$ almost always.}


% Nonetheless, our experiments show that quick convergence occurs also for
% $n>2$ players, $d>1$ features, and general $H$.

% \todo{result on welfare at equilibrium?}


% \todo{\\%
% 1. Learner: after round \#1, if one player improves for self, then this improves for all  [PROVE] \\
% 2. Information: better to share your weights [PROVE] \\
% 3. Welfare: always increases! \\
% 4. Market: Competition by cooperation [!]
% }

% Our main result here is that accuracy games form a subclass of
% congestion games.
% This is useful since congestion games enjoy many desirable properties,
% with implications on both theory and practice, as we discuss below.
% We begin with a definition of congestion games;
% for convenience we consider a game over a discrete resource set,
% but this naturally extends to continuous resources.
% \begin{definition}[Congestion game]
% \label{def:congestion_game}
% \todo{define congestion game}
% \end{definition}

% \begin{theorem}
% \label{thm:acc_game_is_congestion}
% \todo{acc games are congestion games}
% \end{theorem}


% \blue{%
% When utility is defined over a sample set, we will make use of the following form (which makes tie braking explicit):
% % \squeeze
% \todo{here or later?}
% \begin{equation}
% \label{eq:sp_utility_emp}
% \ms_\smplst(h_i \mid h_{-i}) = 
% % \frac{1}{m} \sum_{i=1}^m = 
% \frac{1}{m} \sum_{k=1}^n \frac{s_i^k}{k}
% \end{equation}
% where $s_i^k$ is the number of examples that provider $i$ is accurate on
% along with $k-1$ other providers.
% When referring to utility in general we will simply use $\ms$.
% }
