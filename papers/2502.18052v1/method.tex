\section{Method}  \label{sec:method}

% A key modeling point in our setup is that although providers seek increased market share, their means to achieve this is by satisfying user interests---namely improving predictive accuracy.
% To see this, consider that
% the event $s(x)=s_i$ holds only if $h_i$ is accurate on $x$, namely $h_i(x)=y$.

We now turn to the question of how to implement a best response,
i.e., by solving Eq.~\eqref{eq:br} for any setting.
Our main observation is that a provider's market share objective
(Eq.~\eqref{eq:sp_utility_exp})
can be rewritten as a weighted expected accuracy objective with a particular choice of per-example weights:
\begin{equation}
\label{eq:weighted_acc_obj}
\ms_i = \expect{p}{w_i(x) \cdot \one{h_i(x)=y}}, \quad
w_i(x) = \frac{1}{1+\kappa_{-i}(x)}
\end{equation}
where $\kappa_{-i}(x)=|\{s_j \neq s_i : h_j(x)=y \}|$,
i.e., the number of other providers that are correct on $x$.
Thus, weights $w_i(x)$ determine the importance of input $x$ for provider $i$,
and inform the objective of which inputs to target, or avoid.
\squeeze

% should be targeted, and which are best avoided.

% \todo{elaborate - w = which points are more/less important, target vs avoid}

%========================================================================
\begin{figure*}[t!]

\includegraphics[width=\textwidth]{graphics/1d_gauss_together_2.pdf}
\caption{%
\textbf{Two-player threshold market.}
\textbf{(Left:)} 
Data consists of two class-conditional Gaussians $p(x\,|\,y) = \N(ay,\sigma_y)$
%  with differing variance.
Beginning at $\hopt$, providers compete over who gets the better classifier,
$h_2$, which secures exclusive access to the larger sector of positive users (blue).
\textbf{(Center:)}
The game as played over time. Each best response improves market share for both providers, but the second mover ($s_2$) prevails.
\textbf{(Right:)}
Outcomes for increasingly distanced $p(x\,|\,y)$ (here $\sigma_y=\sigma$).
Equilibrium classifiers are pulled further away, and sacrifice accuracy 
for increased market share.
}
\label{fig:synth}
\end{figure*}
%========================================================================

\paragraph{Hardness.}
In terms of 
tractability,
% optimizing Eq.~\eqref{eq:weighted_acc_obj}, 
our results are mixed:
% \squeeze
\begin{observation}
For any choice of $H$,
and given $w_i$, computing the best-response classifier
$h_i = \br(h_{-i})$ is just as hard as maximizing expected accuracy over $H$.
\end{observation}
This holds since weights in Eq.~\eqref{eq:weighted_acc_obj} simply modify the data distribution,
a change to which learning algorithms should be agnostic.%
\footnote{E.g., consider how the PAC framework defines a class $H$ as learnable if there exists an (efficient) algorithm that maximizes accuracy well simultaneously for \emph{all} distributions
\citep{valiant1984theory}.}
Unfortunately, because maximizing the expected 0-1 accuracy is computationally intractable (and statistically challenging) for the vast majority of classification problems,
computing a best-response classifier exactly will mostly be infeasible.
The bright side is that this is precisely the problem that machine learning practice aims to solve.
Hence, any solution that works well for general machine learning tasks
should also work well to learn best responses.
% simply by appropriately reweighing examples. 
\squeeze

\paragraph{Learning (approximate) best-response classifiers.}
% In particular, and
Since the game is played on the empirical distribution,
we can adapt any method of empirical risk minimization that supports custom example weights, i.e., that aims to solve:
\begin{equation}
\label{eq:erm}
\hhat_i = \argmin_{h \in H}
\frac{1}{m} \sum_{j=1}^m  w_i(x_j) \loss(y_j, h(x_j))
+ \lambda R(h)
\end{equation}
where $\ell$ is a proxy loss (e.g., hinge loss or cross-entropy)
and $\reg$ is an (optional) regularization term.
This approach applies to any type of data and choice of model class $H$.
We refer to $\hhat_i$ as the approximate best-response classifier of $s_i$.
% \paragraph{Information.}
Note that optimizing $\hhat_i$ %for Eq.~\eqref{eq:weighted_acc_obj}
depends on the other classifiers $h_{-i}$ only through the example weights $w_i(x_j)$.
This means that computing the empirical best-response classifier requires
only access to the number of other providers that are correct on each data point---%
%  correctness of predictions of other providers---%
not to the actual classifiers in $h_{-i}$.
Also, we can observe that the average weight $\frac{1}{|S|}\sum_{i \in S} w_i$ has an intuitive meaning: it is the maximum possible market share that could be achieved by a perfect classifier, i.e., when all its predictions are correct.
The actual $\ms_i$ is then this optimal market share minus the weighted
loss incurred by the chosen classifier $\hhat_i$.
% When $m=1$, Eq.~\eqref{eq:weighted_acc_obj} resorts to the standard accuracy objective for a single provider;
% but when $m>1$, the more providers that are correct on a certain $x$,
% the lower its weight $w_i(x)$ is for a given $s_i$.
% Hence, when there is competition, providers gain more from examples on which they are \emph{exclusively correct}.
% This reveals two key properties of our setup:
% In general, providers will work to improve accuracy,
% and so as a collective, their incentives are aligned with user interests at large.
% However,
% providers compete over who provides better service, and to which users.
% This leads to the formation of a `market for accuracy'.
% % \squeeze
\paragraph{Performativity.}
Eq.~\eqref{eq:exp_accuracy} casts maximizing market share
% can be viewed as a particular instance of
as a problem of
learning under distribution shift,
where shift is due to competition, as expressed by weights $w_i(x)$.
From the perspective of a single provider $s_i$ at time $t$,
weights $w_i^t(x)$ describe how the market has changed
\emph{in response to its own actions},
i.e., the choice of $h_i^{t-1}$.
This reveals that learning in a market setting is of a performative nature:
the choice of classifier at the current time step $t$ shapes the (effective) distribution at the next, $p_i^{t+1}(x,y)$.
When there are only two providers, performativity is \emph{stateless},
meaning that $p_i^{t+1}$ depends only on the current $h_i^{t}$
through how $s_j$ will best-respond; this relates to the common (and simpler) setting often studied in performative prediction \citep{perdomo2020performative}.
When $n>2$, dynamics become \emph{stateful}, i.e.,
are path-dependent, and so choices accumulate over time---%
a generally much more challenging setting \citep{brown2022performative,li2022state}.
Luckily, our market construction adds structure that makes it a tractable instance.
An interesting point to make is that performativity in our setting
has no `real' effect on the distribution.
Rather, it only changes how providers should \emph{perceive} the distribution
in order to effectively maximize their utility in the market.

% no `actual' effect on dist - only in the eyes of providers

% Under best-responses, deploying a set of models $f_1,\dots,f_n$
% can be viewed as having a performative effect on the data distribution.

% \begin{equation}
% \label{eq:sp_utility_alt}
% \ms_p(h_i \mid h_{-i})
% % = \expect{p}{\prob{}{s(x)=i}}
% = \expect{p^{f_{i}}}{\one{s(x)=i}}
% \end{equation}
% where $p^{h_i}$ factors in the best responses of all $-i$
% \[
% p^{h_{i}}(x,y) \propto p(x,y) \cdot \prob{}{s^t(x)=i}
% \]
% where $s^t$ is wrt $h_{-i}^{t}$

% dist map

% sequence $(f_t,p^t)$ where $p^t = p^{h_{-i}^{t}}$ -- trajectory, driven by agency

% coupled
% stateful/less, sync/a-sync, $m=2$ vs $>2$
% no `actual' effect on dist - only in the eyes of providers / partitioning across providers

% If we factor then randomness of user choices into $p$,
% then optimizing Eq.~\eqref{eq:sp_utility_exp} becomes equivalent to maximizing accuracy on an induced distribution:%
% \footnote{Under non-uniform tie-braking, each supplier may face a different induced distribution, $p^\h_i(x,y) \propto p(x,y) \prob{}{s(x)=s_i}$.}
% \begin{equation}
% \label{eq:objective}
% \expect{p^\h}{\one{h_i(x)=y}}, \quad\,\,
% % p^\h_i \propto p(x,y) \prob{}{s(x)=s_i}
% p^\h(x,y) \propto \frac{p(x,y)}{\kappa(x)}
% \end{equation}
% % where $p^\h_i \propto p(x,y) \prob{}{s(x)=s_i}$
