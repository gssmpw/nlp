
\input{table.tex}

\section{Experiments}
\label{sec:exp}

We now present our empirical investigation of learning in accuracy markets.
We begin by demonstrating the basic mechanics of competitive learning on simple synthetic data which allows us to compute best-response classifiers exactly.
Then we switch to real data and apply our method from Sec.~\ref{sec:method} to accuracy markets across multiple datasets
and various learning algorithms.
Code is available at \url{https://github.com/Ohadeinav/competition_games}.

\subsection{Synthetic data}
\label{sec:exp:synth}
To gain an understanding of how accuracy markets work,
consider a simple setting with $n=2$ providers, binary labels $y \in \{\pm 1\}$,
univariate features $x \in \R$ sampled from class-conditional Gaussians
$x \sim p(x \,|\,y) = \N(ay,\sigma_y)$,
and threshold classifiers $H=\{h_\tau(x) = \one{x > \tau} \mid \tau \in \R\}$.
\cref{fig:synth} (left) illustrates this setup for
$a=1,\sigma_{-1}=2$,
and $\sigma_{+1}=1$,
and shows the learned classifiers at equilibrium,
$h_1$ and $h_2$;
as Thm.~\ref{thm:mlr_br} suggests, these are precisely $\rho^{-1}(1/2)$ and $\rho^{-1}(2)$.
Note how the region between $h_1$ and $h_2$ (hatches) is split between the providers:
$s_1$ is exclusively correct on positive examples,
and $s_2$ on negatives.
The regions to the right of $h_1$ and left of $h_2$ are shared. 
% \ohad{Changed from $h_1^* \text{to} h_1$}


Fig.~\ref{fig:synth} (center) shows how market shares $\ms_1,\ms_2$ evolve over 
rounds of best-responses.
Here we initialize $h_1^0=h_2^0=\hopt$ where
$\hopt$ is the optimal classifier (i.e., which maximizes accuracy on $p$).
In line with our results from Sec.~\ref{sec:2xH},
dynamics converge after one round, i.e., each provider responds once,
and so $h_1=h_1^1$ and $h_2=h_2^1$.
Although $s_1$ moves first and improves $\ms_1$,
this not only improves $\ms_2$ for $s_2$, but also \emph{to a greater extent than that of $s_1$}.
When $s_2$ then moves, again both $\ms_1,\ms_2$ increase,
but $\ms_2$ retains its advantage over $\ms_1$.
Hence, $s_2$ `wins' the chicken game by playing second
and obtaining access to the larger exclusive subgroup of positives.
Regardless of who wins,
users gain from the competition since welfare ($=\ms_1+\ms_2$)
always increases.
\squeeze

Fig.~\ref{fig:synth} (right) shows how outcomes change for matching gaussians ($\sigma_{+1}, \sigma_{-1}=1$)
when the class-conditional distributions
$p(x\,|\,y=-1)$ and $p(x\,|\,y=1)$
are pulled closer together, achieved by decreasing $a$.
When the distributions are far away,
$h_1$ and $h_2$ are at $\hopt$ and so fully share the market.
But as overlap increases, several effects take place.
First, $h_1$ and $h_2$ grow further apart and become more distinct in who they target,
causing the exclusivity regions to grow in size.
Second, since classification becomes harder,
the maximal attainable accuracy decreases.
The accuracies of $h_1,h_2$ also decrease, but at a faster rate---%
a result of specialization.
Third, we see that welfare---as the sum of market shares---
begins at its maximal value of 1 (when the gaussians are perfectly separable),
then decreases when the exclusivity doesn't extend to the tails, and finally returns to 1 when the providers play opposite thresholds.
We explore additional aspects on non-matching gaussians in \cref{app:add_exps:synth}.
\squeeze

% \todo{explain why this happens. even crazier when asymmetric (in App. ~\ref{appx:add_exps}) - tipping point! happens when $\rho^{-1}(2)$ no longer exists, solution jumps to extreme end}
% \todo{talk about what happens to market shares in relation. \ohadadd{all in \cref{app:add_exps:synth}}}



%========================================================



\subsection{Real data}
\label{sec:exp:real}
Our goal in this section is to explore accuracy markets under
our three perspectives: (learning) providers, users, and the market.
We experiment with
three datasets: COMPAS-Arrest, COMPAS-Violence, and Adult,
and consider several learning algorithms, including
linear SVMs, boosted trees (using XGBoost), and random forests.
These generally work well for standard accuracy tasks on the above datasets.
% and allow us to experimentally vary model complexity both within and across model classes.
Appendix~\ref{appx:exp_details} includes full details on datasets, methods, and our experimental setup.
Appendix~\ref{appx:add_exps} includes additional experiments that extend and complement those presented here.
\squeeze


\paragraph{Learning.}
Table~\ref{tbl:main} shows performance under several measures of interest across multiple datasets and for varying number of providers.
Here we show results for Linear SVMs, but note that other learning algorithms exhibit overall similar trends (see Appendix~\ref{appx:tables}).
All results are averaged over 10 random train-test splits.
The table describes outcomes after $t=2$ rounds,
which we found sufficed to obtain near-convergence across all settings---%
regardless of training set size, model class complexity, and the use of a proxy objective to implement (approximate) best responses.

% \todo{describe table resutls}

In terms of market share improvement, we see that competition is helpful for all providers; nonetheless, there can be a large gap between the minimal and maximal improvement.
In the COMPAS datasets, this gap begins at smaller values,
but grows as $n$ increases.
For Adult, whose baseline accuracy is higher,
the gap remains mostly stable, but is large to begin with.
As competition progresses, the market becomes more concentrated,
which also generally increases with $n$.
Overall welfare gains are quite high, reaching up to $+65\%$.



\paragraph{Market outcomes.}
\Cref{fig:upset} shows how the market is partitioned across providers at equilibrium.
Here we focus on COMPAS-Arrest with XGBoost and $n=3$ providers;
% see Appendix~\ref{appx:upset_plots} for more setups.
providers are numbered by their order of play (i.e., $s_1 \prec s_2 \prec s_3$),
where this order is preserved across rounds.
The plot shows for each provider $s_i$ its total market share
(bottom left) and accuracy on the entire population (top left)
due to its final learned $h_i$.
The plot also shows the decomposition of the market 
% in terms of the intersections between all subsets of providers
across all subsets of providers: what proportion is exclusive to $s_1$, what is joint to $s_2$ and $s_3$, what is shared by all, etc. (right).
Here we see that $s_1$, who moved first, attained the largest market share (36\%).
However, its accuracy is significantly lower than others, and below 50\%.
The subsets plot reveals the reason:
$s_1$ was able to gain exclusive access to 28.5\% of the market;
it shares an additional $19\%$ with all providers,
but only $1\%$ with each of them alone.
In contrast, $s_2$ and $s_3$ share almost all of their users,
either as a pair ($44\%$) or along with $s_1$.
This shows how $s_1$ has come to dominate the market by learning a classifier $h_1$ that 
sacrifices accuracy in order to effectively target an exclusive user sector.
The low overall accuracy of $h_1$ suggests that {\naive}ly optimizing for accuracy without considering the effects of competition can be highly suboptimal in terms of market outcomes.
\squeeze

\extended{
\todo{idea: give insight as to what determines user sectors}
}




%========================================================================
\begin{figure}[t!]
\centering
% \includegraphics[width=\columnwidth]{graphics/upset_plot_29_01_25.png}
\includegraphics[width=\columnwidth]{graphics/upset_join.png}
\caption{%
\textbf{Market share.}
An example for $n=3$ where the first mover ($s_1$) dominates the market,
achieved by sacrificing overall accuracy for exclusive access to a large user sector.
Other providers are left to share the remaining sector.
}
\label{fig:upset}
\end{figure}
%========================================================================
 \paragraph{Order of play.}
Whereas our $2\times2$ analysis from Sec.~\ref{sec:2x2}
suggested that the game either has a dominant strategy or a chicken-like structure
(which implies that moving second is preferable),
we see in Fig.~\ref{fig:upset} that for $n>2$ providers  reality is more complex, and in fact moving \emph{first} allows to dominate the market. Interestingly, this first move induces a 2-player game on the other providers
whose equilibrium admits a dominant strategy.
To quantify this phenomenon, and assert its robustness across methods,  we ran experiments for every combination of datasets and model classes, listed in \cref{appx:exp_details}.
For each experiment, namely for each combination of model class and dataset, the final market shares were calculated for each provider along with his/her relative position of play, i.e., at what position did the provider perform a best-response. Additionally, each experiment was performed for competitions with 2,3,4,5, and 6  players, so that we can compare dynamics across different market saturations.
\Cref{fig:order_of_play} shows the order of play comparisons, averaged out across all of the experiments that were described above. 
When the competition game is played with $n=2$ providers, we see a clear preference to be the provider that moves last, characterized by the market share term $\mu_2$.
The vast majority of experiments showed a significant gain in market share, as seen by the fact that the 25\% quantile of values already shows a net-positive gain from moving last. We also note that the expected (mean) competitive advantage of moving last is 3.6\% with a median of 4.8\%.
Given that for 2 players with equal model classes, the market share of a single provider will never exceed $\frac{2}{3} = 0.67$ (see \cref{prop:bounded_market_concentration}), then a $4.8\%$ difference in market share is  quite significant.


%========================================================================
\begin{figure}[t!]
\centering
% \includegraphics[width=\columnwidth]{graphics/upset_plot_29_01_25.png}
\includegraphics[width=\columnwidth]{graphics/25_02_18_chicken_order_of_play_comparison_edit_positions.pdf}
\caption{%
\textbf{Influence of order of play on market share. }
The orange densities measure the difference in market share between the provider that moved 2nd and the provider that moved 1st, and the blue densities measure the difference in market share between the provider that moved 2nd and the provider that moved 3rd, for $n>2$. Dashed lines inside the densities represent the 25\%, 50\%, and 75\% quantiles of values, respectively, from bottom to top.
}
\label{fig:order_of_play}
\end{figure}
%========================================================================

 When the competition game is played with $n\ge3$ providers, however,  we observe an entirely different dynamic.
\cref{fig:order_of_play} provides two densities: The orange density is as in the 2-provider setting ($\mu_2 - \mu_1$). The blue density is the difference in market share between the player who moved 2nd versus the player who moved 3rd ($\mu_2 - \mu_3$).
We find here that the ratios have switched: it is in fact more advantageous to be the provider that moves 1st, as evidenced by the negative orientation of the orange density plot. The next interesting thing that we note is the seeming insignificance of order-of-play beyond the first two positions, as we can observe that the blue density hovers around 0 with relatively low variance. This alludes to the premise put stated above that in competitive settings with 3 or more players, the person who moves 1st is in essence \quot{grabbing his territory}, which then induces all of the other players to play among themselves for the other resources, i.e, consumers.
% We explore dynamics and order of play
% for other settings and more providers
% in Appendix~\ref{appx:chicken}.

% \blue{%
% We further explore this idea 
% which shows that other markets with $n=3$ can induce different sub-games,
% and that more general markets with $n>3$ exhibit more intricate phenomena.
% }

\paragraph{User welfare.}
Our result in Cor.~\ref{corr:welfare} states that competition is conductive to welfare.
It remains to consider \emph{how} conductive it is,
as well as how \emph{quickly} welfare improves.
Fig.~\ref{fig:welfare} left shows how welfare changes over time
and for increasing number of providers $n$.
Here we focus on COMPAS-arrest and LinearSVC,
with other settings shown in Appendix~\ref{appx:welfare}.
The plot shows a clear trend of welfare increasing throughout competition.
It also makes apparent the effect of $n$:
as the number of providers increases, welfare climbs higher and faster.
For $n=2$, welfare attains a maximum of 0.85,
reached only at the second round.
For $n=3$, welfare maximizes at 0.95 by the end of the first round.
Notice that welfare reaches the upper bound of 1 already at $n=5$
and before the end of the first round (i.e., before all providers have moved).
With $n=6$ providers, this occurs even earlier.

The above depicts accuracy markets as highly efficient.
On the one hand, our market setting allows for the free flow of information,
and models users as making informed (rational) decisions---%
which are necessary to enable efficient outcomes.
But on the other, providers are restricted in that they cannot compute best-responses exactly.
We therefore take the results above to again suggest that maximizing market share using proxy objectives can work well in practice.
% \squeeze

Since market share should generally align with accuracy,
another interesting question is how does the capacity to maximize accuracy affect the overall welfare.
For a different setting of competing predictors,
\citet{jagadeesan2024improved} argue that increased capacity can result in \emph{lower} welfare for users.
We show that this occurs quite distinctly in our setting as well:
When the complexity goes down, maximizing accuracy may be harder, but gaining discrepancy is easier, as there are more users to specialize on.
Following the idea of controlling capacity by the quality of representation,
we implement this by varying the number of features available for learning.
Fig.~\ref{fig:welfare} (right) shows welfare for increasing number of features
and for $n=2$ (see Appendix~\ref{appx:welfare} for more settings).
As expected, at time $t=0$, better representations entail higher accuracy, and therefore higher welfare.
But once providers respond, the trend inverts: 
restricting learning to use only two features attains the optimal welfare of 1, while using all features gives welfare of $0.84$. 

% \todo{can/need to explain?}
\extended{
\todo{say when complexity goes down, maximizing accuracy becomes harder, but in comparison improving discrepancy becomes easier. in the extreme of $H=\{0,1\}$ (or any two opposite classifiers), this is immediate. [can we quantify this?]}

\todo{what else can/should we say about mina's vs our results? what is the best way to relate the two papers/results?}
}

%========================================================================
\begin{figure}[t!]
\centering
% \includegraphics[width=\columnwidth]{graphics/29-01-2025_social_welfares_COMPAS_arrest.pdf}
\includegraphics[width=\columnwidth]{graphics/29-01-2025_social_welfares_arrest-crop.pdf}
\caption{%
\textbf{Welfare over rounds.}
Competition consistently increases welfare over time, until convergence.
Welfare improves with the number of providers \textbf{(left)},
but (perhaps counterintuitively) decreases with the quality of data \textbf{(right)}.
}
\label{fig:welfare}
\end{figure}
%========================================================================
    