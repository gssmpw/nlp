\newcommand{\cmark}{\textcolor[rgb]{0,0.6,0}{\checkmark}}
\newcommand{\xmark}{\textcolor{red}{$\times$}}

\section{LLM Prompting} \label{app:prompting}
We use the following prompt templates across datasets.
As shown below, we provide predefined answer options for the DDInter and PharmacotherapyDB datasets. 
However, we do not include options for the DrugBank dataset for two reasons: 
(1) DrugBank contains 86 possible interaction types, making inference for approximately 30,000 examples computationally expensive.
and (2) preliminary experiments showed that the model performed better without predefined options.
As baselines, we either exclude knowledge graph information entirely or provide textual definitions of the drugs or diseases.
\input{prompts2}


\section{QLORA Fine-tuning} \label{app:qlora}
For the supervised LLM experiments, we fine-tuned Llama 3.1 8B Instruct using QLoRA. We conducted training experiments under two distinct scenarios across our datasets.
In the first scenario, we trained the model using the retrieved paths for each training query.  
In the second scenario, we trained the model using text definitions of the drugs or diseases. 
To manage excessively long definitions, we truncated each entity definition to a maximum of 200 tokens.

In both scenarios, we trained for 10 epochs using the same settings as the QLoRA repository, with the following modifications: 
We adopted a learning rate of 1e-3 and set the maximum input length to the average token length of the input across the respective dataset. 
The training was conducted on 8 A100-80G GPUs and typically completed within 24 hours, depending on the dataset.
During inference, we first retrieved reasoning paths using K-Paths.
These retrieved paths were then appended to the original query and fed into the fine-tuned LLM to generate the final answers.

\section{GNN Baselines}
In this section we explain the GNN models used in our study
\subsection{Relational Graph Convolutional Network (RGCN)}

We implement the Relational Graph Convolutional Network (RGCN) \cite{Schlichtkrull2017ModelingRD}, which operates on the augmented graph with multiple relation types and employs message passing to propagate structured information across nodes. The model is implemented using PyTorch and PyTorch Geometric.

\subsubsection{Node Feature Initialization}
The initialization of node features follows a hybrid approach.
Drug and disease nodes are initialized using RoBERTa \cite{liu2019robertarobustlyoptimizedbert} embeddings extracted from their PubMed-scraped descriptions.
Other entity nodes (genes, anatomy, etc.) are initialized randomly, allowing the model to learn meaningful representations during training.

\subsubsection{Training Setup}
We follow the inductive setting for dataset splitting, as described in Section \ref{sec:datasets}. 
The training follows a link prediction framework where training nodes are sampled with all their relations observed, while test nodes are introduced to evaluate generalization. We consider two training settings:
\begin{enumerate}
    \item Training on the entire augmented KG \textit{Complete KG} and testing on test nodes along with their retrieved test KG.
    \item Training on the diverse retrieved train paths and testing on test nodes along with their retrieved test paths.
\end{enumerate}

\subsubsection{Model Architecture \& Training Details}

The RGCN model is trained using stochastic gradient descent with the Adam optimizer, along with a learning rate scheduler that dynamically adjusts the learning rate based on validation loss. The training loss is computed using cross-entropy loss, applied to the predicted drug-drug or drug-disease interactions. Training runs for 1,000 epochs, with early stopping based on validation loss. To maintain a balanced class representation, stratified sampling is employed, selecting a maximum of 1,000 samples per epoch and up to 10 samples per class. The model consists of three layers of relational graph convolution (GCN layers), each followed by a ReLU activation function. Node embeddings are projected into a 128-dimensional space, then processed through batch normalization, ReLU activation, and dropout with a rate of 0.5 to prevent overfitting. For interaction prediction, a separate edge classifier takes the final node embeddings of two entities and predicts their interaction type. To improve computational efficiency, the model employs basis decomposition with two bases. The learning rate is set to 1e-3, ensuring stable convergence while training.


\subsection{EmerGNN}

To compare against RGCN, we evaluate EmerGNN, a graph neural network designed for emerging drug-drug interaction prediction \cite{zhang2023emergingdruginteractionprediction}. We use the official implementation and apply it to our datasets without modifying the model architecture or training pipeline.  
Unlike RGCN, which relies on RoBERTa embeddings for node initialization, EmerGNN incorporates molecular features, leveraging structural and chemical properties to enhance node representation.
We compare the performance of both models in terms of interaction prediction accuracy, assessing the impact of different node initialization strategies and augmented KG utilization.

\section{Additional Experimental Results}
\label{sec:additional_results}

This section presents additional experimental results, including retrieved paths from the augmented KG, dataset statistics, path retrieval efficiency, and model performance comparisons.

\subsection{Dataset Overview}
Table \ref{tab:datasets} summarizes the datasets used in our experiments, categorized by prediction task and the connectivity between interaction query nodes (entities) in the augmented KG.

\begin{itemize}
    \item DrugBank involves inductive and transductive tasks, predicting drug-drug interactions among 86 labels. The transductive setting has more drug pairs connected in the augmented KG (38,411) than the inductive setting (27,983).
    \item DDInter predicts drug-drug interaction severity levels (Major, Moderate, or Minor). It contains 13,367 connecting drug pairs, and 5,909 interaction queries contain information about a single entity.
    \item Drug repurposing focuses on whether a drug is disease-modifying, palliates, or has no indication of a disease.
\end{itemize}


\begin{table}[t]
    \centering
    \scriptsize %
    \setlength{\tabcolsep}{2pt} %
    \renewcommand{\arraystretch}{1.1} %
    \begin{tabular}{@{}lp{1.8cm}rrr@{}}
        \toprule
        \textbf{Dataset} & \textbf{Task} & \textbf{Two Nodes} & \textbf{Single Nodes} & \textbf{No Node} \\ 
        \midrule
        DrugBank (Ind.) & Open-ended & 27,983 & 3,987 & 14 \\ 
        DrugBank (Trans.) & Open-ended & 38,411 & 8 & 0 \\ 
        DDInter & Categorical & 13,841 & 5,494 & 104 \\ 
        Drug Repurposing & Categorical & 252 & 0 & 0 \\ 
        \bottomrule
    \end{tabular}
    \caption{Summary of datasets and tasks.}
    \label{tab:datasets}
\end{table}



 

\subsection{Transductive Results}\label{sec-transd}
\begin{table}[t]
    \centering
    \footnotesize %
    \renewcommand{\arraystretch}{0.9} %
    \setlength{\tabcolsep}{4pt} %
    \begin{tabular}{llccc}
        \toprule
        \textbf{Model} & \textbf{Setting} & \textbf{Accuracy} & \textbf{F1} & \textbf{Kappa} \\
        \midrule
        \multicolumn{5}{l}{\textbf{Graph-Based Models (GNNs)}} \\
        EmerGNN & Complete KG & \textbf{97.40} & \underline{94.00} & \underline{96.60} \\
        EmerGNN & K-Paths & \underline{97.01} & \textbf{94.25} & \textbf{97.01} \\
        RGCN & Complete KG & 90.01 & 87.62 & 89.85 \\
        RGCN & K-Paths & 90.86 & 88.43 & 90.11 \\
        SumGNN & Reported & 86.85 & 92.66 & 92.66 \\
        KnowDDI & Reported & 91.53 & 93.17 & 91.89 \\
        \midrule
        \multicolumn{5}{l}{\textbf{LLM-Based Models}} \\
        QLoRA-Llama & Definitions & 93.45 & 91.71 & 92.28 \\
        QLoRA-Llama & K-Paths & 93.58 & 88.98 & 92.41 \\
        \bottomrule
    \end{tabular}
    \caption{Performance of various models on the Transductive DrugBank setting. Bold indicates the best performance, and
underlined denotes the second-best. LLMs leverage both knowledge types effectively with supervision, and K-Paths enhance GNN efficiency
without significant performance loss.}
    \label{tab:results-transductive}
\end{table}

\begin{table*}[h]
    \centering
     \footnotesize
    \begin{adjustbox}{max width=0.7\textwidth}
    \begin{tabular}{lcccccc}
        \toprule
        \multirow{2}{*}{Dataset} & \multicolumn{3}{c}{Before Retrieval (Augmented KG)} & \multicolumn{3}{c}{After Retrieval (K-Paths)} \\
        \cmidrule(lr){2-4} \cmidrule(lr){5-7}
         & \#Nodes & \#Relations & \#Triplets & \#Nodes & \#Relations & \#Triplets \\
        \midrule
        DrugBank & 35,146 & 102 & 1,722,677 & 6,378 & 94 & 175,698 \\
        DDInter  & 35,169 & 26 & 1,710,079 & 5,647 & 18 & 102,854  \\
        PharmacotherapyDB & 33,952 & 26 & 1,690,945 & 2,847 & 23 & 13,942 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Statistics: Comparison of the Augmented KG with extracted subgraph at test time.}
    \label{tab:path_retrieval}
\end{table*}

\begin{table*}[h]
    \centering
    \scriptsize
    \renewcommand{\arraystretch}{1.0}
    \begin{tabular}{>{\centering\arraybackslash}p{1.0cm}>{\centering\arraybackslash}p{6cm} >{\centering\arraybackslash}p{2.0cm} >{\centering\arraybackslash}p{1.8cm} >{\centering\arraybackslash}p{2.8cm}}
        \toprule
        \textbf{Relation ID} & \textbf{Description} & \textbf{Retained for DrugBank} & \textbf{Retained for DDInter} & \textbf{Retained for PharmacotherapyDB} \\
        \midrule
        0  & Anatomy--downregulates--Gene (AdG) & \xmark & \xmark & \cmark \\
        1  & Anatomy--expresses--Gene (AeG) & \xmark & \xmark & \cmark \\
        2  & Anatomy--upregulates--Gene (AuG) & \xmark & \xmark & \cmark \\
        3  & Compound--binds--Gene (CbG) & \cmark & \cmark & \cmark \\
        4  & Compound--causes--Side Effect (CcSE) & \cmark & \cmark & \cmark \\
        5  & Compound--downregulates--Gene (CdG) & \cmark & \cmark & \cmark \\
        6  & Compound--palliates--Disease (CpD) & \cmark & \cmark & \cmark \\
        7  & Compound--resembles--Compound (CrC) & \cmark & \cmark & \cmark \\
        8  & Compound--treats--Disease (CtD) & \cmark & \cmark & \cmark \\
        9  & Compound--upregulates--Gene (CuG) & \cmark & \cmark & \cmark \\
        10 & Disease--associates--Gene (DaG) & \cmark & \cmark & \cmark \\
        11 & Disease--downregulates--Gene (DdG) & \cmark & \cmark & \cmark \\
        12 & Disease--localizes--Anatomy (DlA) & \xmark & \xmark & \cmark \\
        13 & Disease--presents--Symptom (DpS) & \xmark & \xmark & \cmark \\
        14 & Disease--resembles--Disease (DrD) & \cmark & \cmark & \cmark \\
        15 & Disease--upregulates--Gene (DuG) & \cmark & \cmark & \cmark \\
        16 & Gene--covaries--Gene (GcG) & \cmark & \cmark & \cmark \\
        17 & Gene--interacts--Gene (GiG) & \cmark & \cmark & \cmark \\
        18 & Gene--participates--Biological Process (GpBP) & \xmark & \xmark & \xmark \\
        19 & Gene--participates--Cellular Component (GpCC) & \xmark & \xmark & \xmark \\
        20 & Gene--participates--Molecular Function (GpMF) & \xmark & \xmark & \xmark \\
        21 & Gene--participates--Pathway (GpPW) & \xmark & \xmark & \xmark \\
        22 &Gene$\rightarrow$regulates$\rightarrow$Gene (GrG) & \cmark & \cmark & \cmark \\
        23 & Pharmacologic Class--includes--Compound (PCiC) & \cmark & \cmark & \cmark \\
        \bottomrule
    \end{tabular}
    \caption{Hetionet relations retained by K-Paths for each dataset. \cmark indicates presence, \xmark indicates absence.}
    \label{tab:relations_pruning}
\end{table*}


Table \ref{tab:results-transductive} compares the performance of Graph Neural Networks (GNNs) and LLM-based models on the Drugbank transductive dataset. Among GNNs, EmerGNN performs best, achieving 97.40\% accuracy with the complete KG, while using our KG slightly lowers accuracy (97.01\%) but improves the F1-score. 
RGCN performs worse than EmerGNN but benefits from our KG, increasing accuracy from 90.01\% to 90.86\%. 
For LLM-based models, QLoRA-Llama achieves 93.58\% accuracy when using K-Paths, while using text-based descriptions instead of structured knowledge results in similar accuracy (93.45\%) but a slightly higher F1-score. 
Overall, EmerGNN performs best and \sys improves efficiency without significant performance loss.



\subsection{Comparison of the augmented KG and the Subgraph Extracted at Test Time}

Table \ref{tab:path_retrieval} compares the augmented KG's overall structure to the subgraph extracted at test time. 
We report the number of nodes, relations, and triplets before and after query-specific retrieval. 
Filtering for relevant subgraphs significantly reduces graph size: 
DrugBank shrinks from 1.7M to 175K triplets, DDInter from 1.71M to 102K, and PharmacotherapyDB from 1.69M to 13K. 
This demonstrates the efficiency of query-specific retrieval in extracting only the most relevant paths for inference.



\subsection{Hetionet Relations Retained Across Datasets}\label{app:hetio}
Table \ref{tab:relations_pruning} presents the Hetionet relations retained in the training and test subgraphs after K-Paths was applied to each dataset. These relations encapsulate biological interactions, such as gene participation in molecular functions (GpMF) or compounds treating diseases (CtD).

Since Hetionet serves as a structured biomedical KG, these relations may not be inherent to the datasets (DrugBank, DDInter, PharmacotherapyDB) themselves 
but instead provide additional contextual knowledge that enhances reasoning within the models. The path retrieval process selectively retains the most informative relations while discarding those less relevant to each dataset.



For example, in the DDInter dataset: 
\begin{itemize} 
    \item Hetionet originally contained 23 distinct relation types, covering diverse biological interactions. 
    \item After dataset-specific path extraction, only 15 relation types were retained by K-Paths and used for training, ensuring that only the most relevant interactions contributed to the model. 
\end{itemize}

Interestingly, while PharmacotherapyDB is the smallest dataset, it retains more relations than DrugBank and DDInter. This is because PharmacotherapyDB encompasses both drug and disease entities, covering a broader set of biomedical interactions that span multiple domains. 

