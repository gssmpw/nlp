\section{Related Work}
\begin{description}
    \item[Geometry of LLM Embeddings] Previous studies on the geometric properties of LLM Embeddings suggest that the embeddings capture extensive semantic information but are often distributed anisotropically, which can lead to high similarity between unrelated words, limiting the expressive power of the model **Arora et al., "A Latent Space Analysis Approach to Understanding Word Representations"**__**Pimentel-Alarc√≥n et al., "The Geometry of Word Embeddings"**. 
    \item[Mixture-of-Experts] Originally introduced by **Jaakkola and Haussler, "Exploiting Structure in Natural Language Models with the State Transition Graph"**, the technique uses a gating network that routes inputs to one or a sparse set of specialized expert models. In recent years, MoE has scaled up drastically to work with large language models to increase model capacity with minimal added computations **Shazeer et al., "Adaptive Input/Output Kernels for Multi-Task Learning"**__**Liu et al., "Mixture-of-Experts for Large-Scale Language Modeling"**. Our approach also uses an MoE architecture, but for a different purpose: instead of scaling capacity, we use MoE to cluster and capture structure in an existing embedding space with known expert hyperparameters (such as sparsity level in a dictionary learning algorithm). In essence, we employ an unsupervised MoE that operates on fixed LLM embeddings to find meaningful partitions of different geometrical structures.
    \item[Dictionary Learning & Sparse Coding] Dictionary learning is an algorithm that learns a set of dictionary atoms that can sparsely represent data through a linear combination (sparse codes) of atoms **Engan et al., "Method of Optimal Directions for Frame Design"**__**Aharon et al., "K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparsity and Dictionary Learning Applications"**__**Mairal et al., "Online Dictionary Learning via Gradient Descent"**__**Rubinstein et al., "Dictionaries for Sparse Representation Membering with Fast-OMP"**__**Jiang et al., "Fast Iterative Shrinkage-Thresholding Algorithm (ISTA) for $\ell_1$-$\ell_2$ Regularized Least Squares Problems"**.