
\section{Fixed Real Data Regime}

We now consider a modified regime, where there is only one batch of real data, denoted as $\bm{y}_{1}, \cdots,\bm{y}_n$ from $N(0,\bm{I})$, and the iterative procedure is as follows:

\subsection*{Iterative Procedure}

For each iteration \( t = 1, 2, \dots \):
\begin{itemize}
    \item \textbf{Sampling:}
    \begin{itemize}
        \item Sample \( \bm{x}_{t,1}, \bm{x}_{t,2}, \dots, \bm{x}_{t,n} \) independently from the multivariate normal distribution \( N(\bm{\mu}_{t-1}, \bm{\Sigma}_{t-1}) \).
    
    \end{itemize}
    
    \item \textbf{Calculating Sample Mean and Covariance:}
    \begin{itemize}
        \item Compute the sample mean vector and sample covariance matrix for each set of samples:
        \begin{align*}
            \bar{\bm{x}}_t &= \frac{1}{n} \sum_{j=1}^{n} \bm{x}_{t,j}, \quad \bm{S}_x^t = \frac{1}{n-1} \sum_{j=1}^{n} (\bm{x}_{t,j} - \bar{\bm{x}}_t)(\bm{x}_{t,j} - \bar{\bm{x}}_t)^\top, \\
            \bar{\bm{y}}_t &= \frac{1}{n} \sum_{j=1}^{n} \bm{y}_{j}\triangleq\bar{\bm{y}}, \quad \bm{S}_y^t = \frac{1}{n-1} \sum_{j=1}^{n} (\bm{y}_{j} - \bar{\bm{y}})(\bm{y}_{j} - \bar{\bm{y}})^\top \triangleq \bm{S}_y.
        \end{align*}
    \end{itemize}

    \item \textbf{Updating Parameters:}
    \begin{align*}
        \bm{\mu}_t &= w \bar{\bm{x}}_t + (1 - w) \bar{\bm{y}}_t, \\
        \bm{\Sigma}_t &= w \bm{S}_x^t + (1 - w) \bm{S}_y^t,
    \end{align*}
    where \( w \) is a weighting parameter.
\end{itemize}

\begin{remark}
In this setting, $\bar{\bm{y}}_t$ and $\bm{S}_y^t$ remain unchanged.
\end{remark}

We first analyze the variance. To begin with, we condition on $\bar{\bm
y} $ and $\bm{S}_y$, then we have

\[
\bm{\Sigma}_t = w  (\bm{\Sigma}_{t-1})^{\frac{1}{2}} \bm{M}_t (\bm{\Sigma}_{t-1})^{\frac{1}{2}} + (1 - w) \bm{S}_y
\],

where $\bm{M}_t$ is  a scaled Wishart distribution as in the previous section.

Next we analyze the MSE $
\mathbb{E}\| \bm{\Sigma}_t-I\|_F^2 $. 

First we have
\begin{align}
\mathbb{E}[\bm{\Sigma}_t | \bm{\Sigma}_{t-1}, \bm{S}_y
]= w \bm{\Sigma}_{t-1}+(1-w)\bm{S}_y,
\end{align}
then we further have
\begin{align}
\mathbb{E}[\bm{\Sigma}_t| \bm{S}_y]=\mathbb{E}[\mathbb{E}[\bm{\Sigma}_t|\bm{\Sigma}_{t-1},\bm{S}_y] | \bm{S}_y]=w\mathbb{E}[\bm{\Sigma}_{t-1}|\bm{S}_y]+(1-w)\bm{S}_y,
\end{align}
this implies
\begin{align}
\lim_{t \to \infty}\mathbb{E}[\bm{\Sigma}_t | \bm{S}_y]=\bm{S}_y,
\end{align}

next we have
\begin{align}
\begin{split}
\mathbb{E}[ \|
\bm{\Sigma}_t-\bm{I}
\|_F^2 ]&=\mathbb{E}\mathbb{E} [\|\bm{\Sigma}_t-I
\|_F^2  | \bm{S}_y] \\
&=\mathbb{E}\mathbb{E}\{\|\bm{\Sigma}_t-\bm{S}_y  \|_F^2 +\|\bm{S}_y-\bm{I} \|_F^2+ 2(
\bm{\Sigma}_t-\bm{S}_y, \bm{S}_y-\bm{I}
) |\bm{S}_y \} ,
\end{split}
\end{align}
then by Fatou's lemma, we have
\begin{align}
\begin{split}
\liminf_{t \to \infty}{\mathbb{E}[ \|
\bm{\Sigma}_t-\bm{I}
\|_F^2 ]}&\geq \mathbb{E}\liminf_{t \to \infty}{ \mathbb{E} [\|\bm{\Sigma}_t-I
\|_F^2  | \bm{S}_y]
} \\
& \geq \mathbb{E} [\liminf_{t \to \infty}\{  \|\bm{S}_y-I \|_F^2+ 2\mathbb{E}[(
\bm{\Sigma}_t-\bm{S}_y, \bm{S}_y-\bm{I}
) |\bm{S}_y]\}] \\
&=\mathbb{E}\|\bm{S}_y-I \|_F^2.
\end{split}
\end{align}
However, when $w=0$, we could see that
\begin{align}
\bm{\Sigma}_t \equiv \bm{S}_y,
\end{align}
therefore 
\begin{align}
\mathbb{E}\|\bm{\Sigma}_t-I \|_F^2 \equiv \mathbb{E}\|\bm{S}_y-I \|_F^2,
\end{align}
which means that for the estimation of variance, the optimal ratio for the synthetic data is in fact 0.

Next, we analyze the estimation of mean. Similarly to the estimation of variance, we have 
\begin{align}
\mathbb{E}[\mu_t|\bar{\bm{y}}]=w\mathbb{E}[\mu_{t-1}|\bar{\bm{y}}]+(1-w)\bar{\bm{y}},
\end{align}
and 
\begin{align}
\mathbb{E}[\mu_0|\bm{y}]=\bar{\bm{y}},
\end{align}
then we have
\begin{align}
\mathbb{E}[\mu_t | \bar{\bm{y}}]=\bar{\bm{y}},
\end{align}
Notice that 
\begin{align}
\begin{split}
\mathbb{E}[(\bm{\mu}_t-0)^2|\bm{\mu}_{t-1},\bar{\bm{y}},\bm{\Sigma}_{t-1}]&=(w\bm{\mu}_{t-1}+(1-w)\bar{\bm{y}})^2+w^2 tr(\frac{1}{n}\bm{\Sigma}_{t-1}) \\ & = w^2 \bm{\mu}_{t-1}^2 +2w(1-w)\bm{\mu}_{t-1}\bar{\bm{y}}+(1-w)^2\bar{\bm{y}}^2 + w^2 tr(\frac{1}{n}\bm{\Sigma}_{t-1}),
\end{split}
\end{align}

which implies
\begin{align}
\begin{split}
\mathbb{E}[\mu_t^2 |\bar{\bm{y}}]&=w^2 \mathbb{E}[\mu_{t-1}^2|\bar{\bm{y}}]+2w(1-w)\mathbb{E}[\bm{\mu}_{t-1}|\bar{\bm{y}}]\bar{\bm{y}}+(1-w)^2\bar{\bm{y}}^2+w^2 \mathbb{E}[tr(\frac{1}{n}\bm{\Sigma}_{t-1})] \\ 
&\geq w^2 \mathbb{E}[\bm{u}_{t-1}^2 | \bar{\bm{y}}]+(1-w^2)\bar{\bm{y}}^2,
\end{split}
\end{align}
this implies 
\begin{align}
\liminf_{t \to \infty}\mathbb{E}[\mu_t^2 | \bar{\bm{y}}]\geq \bar{\bm
{y}}^2,
\end{align}

then using Fatou's lemma, we have
\begin{align}
\liminf_{t \to \infty}
\mathbb{E}[\mu_t^2]\geq \mathbb{E}
\liminf_{t \to \infty}
\mathbb{E}[\bm{\mu}_t^2 | \bar{\bm{y}}] \geq \mathbb{E}\bar{\bm{y}}^2.
\end{align}
Again, the equality will hold when $w=0$, which means that using real data is optimal.