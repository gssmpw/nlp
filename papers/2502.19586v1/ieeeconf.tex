%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command
                                                          
\overrideIEEEmargins                                      % Needed to meet printer requirements.
%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{booktabs}
\usepackage{url}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\usepackage{optidef}
\usepackage{cite}
\usepackage{mathtools}
\usepackage{nomencl}
\renewcommand{\nomname}{LIST OF ACRONYMS}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}
\let\proof\relax
\let\endproof\relax
\usepackage{amsthm}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\usepackage{multirow}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{optidef}
\usepackage{hhline}
\usepackage{array}
\usepackage{amsthm}
\usepackage{multirow}
%\usepackage{setspace}
\usepackage{soul}
\usepackage{threeparttable}
\usepackage{acronym}


%\linespread{2} 
\title{\LARGE \bf Battery State of Health Estimation and Incremental Capacity Analysis for Charging with General Current Profiles Using Neural Networks}
\author{Qinan Zhou$^{1,*}$, Gabrielle Vuylsteke$^{2}$, R. Dyche Anderson$^{2}$, and Jing Sun$^{3}$% <-this % stops a space
\thanks{$^{1}$Qinan Zhou is with the Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI 48103, USA. Email: {\tt\small qinan@umich.edu}}%
\thanks{$^{2}$Gabrielle Vuylsteke and R. Dyche Anderson are with Research and Advanced Engineering, Ford Motor Company, Dearborn, MI 48124, USA. Email: {\tt\small \{gvuylste,rander34\}@ford.com}}%
\thanks{$^{3}$Jing Sun is with the Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI 48103, USA. Email: {\tt\small jingsun@umich.edu}}%
\thanks{$^{*}$Corresponding Author.}%
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Incremental capacity analysis (ICA) and differential voltage analysis (DVA) conventionally require constant-current conditions for battery degradation monitoring, which restricts their applicability in real-world scenarios. This paper presents a unified approach to enable ICA/DVA-based degradation monitoring under general charging current profiles, which has not been addressed previously in the literature. First, a novel concept of virtual incremental capacity (IC) and different voltage (DV) is proposed. Second, two related convolutional neural networks (CNNs), called U-Net and Conv-Net, are proposed to construct virtual IC/DV curves and estimate the state of health (SOH) from general charging profiles across any state-of-charge (SOC) ranges that satisfy some constraints. Finally, two CNNs, called Mobile U-Net and Mobile-Net, are proposed to replace the U-Net and Conv-Net, respectively, for onboard implementations. They significantly reduce the computation and memory requirements, while retaining performance in virtual IC/DV curve construction and SOH estimation. Tested on an extensive experimental dataset of battery modules with various fast-charging protocols and SOC ranges, the proposed U-Net and Mobile U-Net construct accurate virtual IC/DV curves which enable the extraction of valuable degradation features. The proposed Conv-Net and Mobile-Net provide module-level SOH estimates with root-mean-square error (RMSE) of less than 0.5\%.
\end{abstract}

\begin{keywords}
Incremental Capacity Analysis; Differential Voltage Analysis; Nonconstant-Current Charging; Fast Charging; Convolutional Neural Network; State of Health Estimation
\end{keywords}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\makenomenclature
\nomenclature{BMS}{Battery Management System}
\nomenclature{SOH}{State of Health}
\nomenclature{ICA}{Incremental Capacity Analysis}
\nomenclature{DVA}{Differential Voltage Analysis}
\nomenclature{SOC}{State of Charge}
\nomenclature{RSME}{Root-Mean-Square Error}
\nomenclature{CC}{Constant Current}
\nomenclature{MSE}{Mean Squared Error}
\nomenclature{NMC}{Lithium Nickel-Manganese-Cobalt Oxide}
\nomenclature{PH}{Peak Height}
\nomenclature{PA}{Partial Area}
\nomenclature{CNN}{Convolutional Neural Network}
\printnomenclature
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
\label{Intro}
Battery state of health (SOH) and the associated degradation information are critical for range estimation, performance optimization, safe operation, maintenance, and warranty of electrified vehicles \cite{Barre}. Estimating and monitoring SOH using onboard measurements are essential for battery management systems (BMS) \cite{Noura}. The topic has been addressed extensively by the research and engineering communities. SOH can be characterized by either capacity fading or resistance rising, both of which lead to a reduction in usable energy \cite{Berecibar,CalRegulation}. This paper focuses on capacity fading and defines SOH as $\text{SOH} = C/C_{\text{fresh}}$, where $C$ and $C_{\text{fresh}}$ are the capacities of a battery at its current and fresh state, respectively.

The battery degradation status can be accessed using intrusive and non-intrusive methods. Various intrusive methods, including photoelectron spectroscopy \cite{Philippe}, scanning electron microscopy \cite{Abellan}, X-ray diffraction \cite{Luo}, etc., provide the exact health and degradation status of batteries, but require expensive equipment and may lead to changes in battery performance or even cause permanent damage \cite{Berecibar}. Thus, they are more suitable for laboratory testing. In contrast, non-intrusive methods use measurements such as current, voltage, and temperature to infer the battery degradation status. Popular non-intrusive methods include electrochemical impedance spectroscopy \cite{Middlemiss}, incremental capacity analysis (ICA) \cite{Dubarry}, differential voltage analysis (DVA) \cite{Bloom,Bloom2}, adaptive filtering \cite{PlettEKF,PlettSPKF,Schwunk}, and data-driven techniques \cite{Yang,Chaoui}. This paper focuses on ICA and DVA, as they do not require special instrumentation and can be implemented with existing onboard vehicle sensors. 

In ICA/DVA, incremental capacity (IC) and differential voltage (DV) curves are obtained and, then, IC and DV features are extracted from these curves \cite{Weng1}. As changes in these features reveal certain aspects of degradation mechanisms within batteries \cite{Krupp, Dubarry}, one can correlate the IC/DV features and their changes with underlying degradation physics. Such an ability to provide physical insights into degradation without using complicated mechanistic models is the key strength of ICA/DVA over other data-driven or deep learning-based approaches for degradation monitoring.

ICA/DVA can be used in BMS for different applications, such as assessing remaining useful life \cite{Pang} and detecting internal short-circuit faults \cite{Zhao}. One of their most important applications is SOH estimation. Data-driven methods are utilized to build models to relate IC/DV features with cell-level SOH under different charging conditions \cite{Weng1,Weng2,Weng3,Zhou1,Stephens} and module-level SOH under cell-to-cell variations \cite{Zhou2}.

Despite all the advantages and applications, the primary limitation of ICA/DVA is that they are performed under constant-current (CC) charging \cite{Zhang}. In real-world applications, e.g. electrified vehicles, charging currents are nonconstant, especially for fast charging \cite{Tomaszewska} and constant-power charging. As a result, ICA/DVA-based degradation monitoring cannot be performed. Tang et al. attempted to extend ICA/DVA from CC charging to pulsed constant-current charging \cite{Tang}. To the best of our knowledge, extending ICA/DVA to more general real-world charging current profiles has not been addressed by any paper in the literature. 

This paper extends ICA/DVA to general charging profiles\footnote{Hereafter, the term ``general current profiles'' refers to current profiles that are not necessarily constant, and the term ``general charging profiles'' denotes profiles that can be measured from charging with general current profiles, such as profiles of voltage, current, transferred charge, etc.\label{shared-footnote}} by proposing a unified approach. For the first time, the proposed approach enables ICA/DVA-based SOH estimation and degradation monitoring without requiring constant-current conditions and broad state-of-charge (SOC) charging ranges. For performance assessment, a large experimental dataset of battery modules with three cells connected in parallel is used. Specifically, the contributions of the paper are four-fold: 
\begin{itemize}
    \item First, notions of virtual IC/DV curves and features are proposed. For cells or modules charged using general current profiles\hyperref[shared-footnote]{\footnotemark[\value{footnote}]}, virtual IC/DV curves are defined as the IC/DV curves that the same cells or modules, in the identical state of degradation, would exhibit under CC charging at a reference C-rate of interest. Features extracted from virtual IC/DV curves are defined as virtual IC/DV features. Virtual IC/DV curves and features reflect degradation mechanisms and can be used for SOH estimation, enabling ICA/DVA-based degradation monitoring for general charging profiles\hyperref[shared-footnote]{\footnotemark[\value{footnote}]}. 
    \item Second, a convolutional neural network (CNN), called U-Net, constructs virtual IC/DV curves from general charging profiles with any SOC ranges satisfying some constraints. Applied to the aforementioned dataset, virtual IC/DV curves approximate actual IC/DV curves very well. As a case study of leveraging virtual IC/DV curves for SOH estimation, 0.6\% root-mean-square error (RMSE) is achieved using only two extracted virtual IC/DV features.
    \item Third, by simplifying the architecture of U-Net, a CNN called Conv-Net is proposed to estimate SOH directly. For the same dataset, Conv-Net provides SOH estimates from general charging profiles with RMSE of 0.49\% SOH. 
    \item Fourth, for onboard implementations, two more computationally efficient CNNs, called Mobile U-Net and Mobile-Net, are developed to replace U-Net and Conv-Net, respectively. For the same dataset, the Mobile U-Net and Mobile-Net significantly reduce the computation and memory demands, with the number of parameters in neural networks being roughly 1/3 of U-Net and Conv-Net, while keeping similar performance for virtual IC/DV curve construction and SOH estimation. 
\end{itemize}
Therefore, the unified approach provides different aspects of ICA/DVA, including virtual IC/DV curves, virtual IC/DV features, and SOH estimates. 

To elucidate the proposed approach, the paper is organized as follows. Section \ref{ICA} defines virtual IC/DV curves and features. Section \ref{UNet} describes the proposed U-Net and Mobile U-Net, while Section \ref{Conv-Net} explains the proposed Conv-Net and Mobile-Net. Section \ref{DataAndPrep} discusses the battery module dataset used in this study. Section \ref{Result} assesses the performance of the proposed methods using the experimental data. Section \ref{Conclusion} summarizes the paper.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%o%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{VIRTUAL INCREMENTAL CAPACITY AND DIFFERENTIAL VOLTAGE CURVES}
\label{ICA}
This section defines the fundamental concepts that underpin this work. First, virtual IC/DV curves are defined. Then, virtual IC/DV features are briefly discussed.

IC/DV curves are originally defined in fully relaxed open-circuit conditions \cite{Dubarry}, which are rarely encountered in onboard BMS applications. To adapt to real-world scenarios, IC/DV curves are, later in the literature \cite{Weng1, Zhou1, Wong, ZhouR, Chen}, defined as:
\begin{itemize}
    \item \textbf{IC Curve}: $\text{IC}_{\text{CC}} = dQ_{\text{CC}}/dV_{\text{CC}}$ as a function of $V_{\text{CC}}$,
    \item \textbf{DV Curve}: $\text{DV}_{\text{CC}} = dV_{\text{CC}}/dQ_{\text{CC}}$ as a function of $Q_{\text{CC}}$,
\end{itemize}
where $V_{\text{CC}}$ is voltage and $Q_{\text{CC}}$ is the charged capacity under CC charging with a reference C-rate of interest. Note that the subscript ``CC'' is used here to emphasize that these quantities are obtained from the constant-current conditions and the shapes of IC/DV curves depend on the C-rate \cite{Fly}.  

Consider cells or modules charged with general current profiles. Even though $Q$-$V$ profiles can be measured and their derivatives can be computed, the obtained derivative curves are not meaningful for ICA/DVA purposes. 

To overcome this limitation, this paper defines the virtual IC/DV curves as the IC/DV curves that the same cells or modules, in the identical state of degradation, would exhibit under CC charging at the same reference C-rate, denoted as: 
\begin{itemize}
    \item \textbf{Virtual IC Curve}: $\widehat{\text{IC}}_{\text{CC}}$ as a function of $\widehat{V}_{\text{CC}}$,
    \item \textbf{Virtual DV Curve}: $\widehat{\text{DV}}_{\text{CC}}$ as a function of $\widehat{Q}_{\text{CC}}$,
\end{itemize}
where $\widehat{V}_{\text{CC}}$, $\widehat{Q}_{\text{CC}}$, $\widehat{\text{IC}}_{\text{CC}}$, and  $\widehat{\text{DV}}_{\text{CC}}$ are estimates constructed from measured general charging profiles. Note that the annotation $\widehat{\cdot}$ is used to emphasize that they are estimates based on charging profiles that are not necessarily constant-current. 

Features extracted from virtual IC/DV curves are called virtual IC/DV features and defined similarly to the corresponding actual IC/DV features defined in \cite{Dubarry,Krupp,Bloom,AnseÃ¡n,ZhouR}. The specific virtual IC/DV features used in this paper are defined in Section \ref{Dataset}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{U-NET AND MOBILE U-NET FOR VIRTUAL IC/DV CURVE CONSTRUCTION}
\label{UNet}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.99\textwidth,trim=12 9 9 5,clip]{Results/Algorithm_Overview.png}
    \caption{Overview of Proposed Method for Virtual IC/DV Curve Construction}
    \label{fig:Algorithm}
\end{figure*} 

\begin{algorithm*}[ht]
\textbf{Output}: $\left\{ \widehat{Q}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{V}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{IC}}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{DV}}_{\text{CC}} ( k ) \right\}$ \

\textbf{Input}: $\left\{I\left( \Delta Q \right)\right\}$ and $\left\{V\left( \Delta Q \right)\right\}$ from general charging, a pre-stored increment $\Delta q$  \

 \

 $\left\{\tilde{I}\left( k \right)\right\}$, $\left\{\tilde{V}\left( k \right)\right\} \leftarrow$ Process $\left\{I\left( \Delta Q \right)\right\}$, $\left\{V\left( \Delta Q \right)\right\}$ using Algorithm \ref{alg:Downsampling} \

 $\left\{\tilde{I}^{\left( s \right)}\left( k \right)\right\}$, $\left\{\tilde{V}^{\left( s \right)}\left( k \right)\right\} \leftarrow$ Equation (\ref{eqn:ConvertStandardize}) \
 
 $\left\{ \widehat{Q}^{\left( s \right)}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{V}^{\left( s \right)}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{IC}}^{\left( s \right)}_{\text{CC}} ( k ) \right\} \leftarrow $  U-Net/Mobile U-Net$\left(\left\{\tilde{I}^{\left( s \right)}\left( k \right)\right\}, \left\{\tilde{V}^{\left( s \right)}\left( k \right)\right\}\right)$ \

 $\left\{ \widehat{Q}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{V}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{IC}}_{\text{CC}} ( k ) \right\} \leftarrow$ Equation (\ref{eqn:ConvertStandardize}) \ 

 $\left\{ \widehat{\text{DV}}_{\text{CC}} ( k ) \right\} \leftarrow 1/\left\{ \widehat{\text{IC}}_{\text{CC}} ( k ) \right\}$ \ 

    \
    
  \tcc{$\Delta Q \in \left[0,\overline{\Delta Q}\right]$, $k\in\{1,2,...,N_{\text{nn}}\}$}  
 
\caption{Proposed Method for Constructing Virtual IC and DV Curves (Fig. \ref{fig:Algorithm})}
\label{alg:Method1}
\end{algorithm*}

With key concepts defined, the next step is to develop a mapping from general charging profiles to virtual IC/DV curves so that ICA/DVA can be performed. Because such a mapping is complicated to formulate, a CNN-based approach is adopted. This section elaborates on the proposed method shown in Fig. \ref{fig:Algorithm}. The main components of the proposed method in Fig. \ref{fig:Algorithm} are the U-Net and Mobile U-Net in Step 2, while Step 1 ensures that inputs to the CNNs are properly prepared. The overall procedure of the proposed method is also summarized in Algorithm \ref{alg:Method1}. 

Compared to other CNNs, U-Net is chosen for two reasons. First, its encoder-decoder structure provides a clear separation between feature extraction and profile construction, which leads to better explainability \cite{Siddique}. Second, its skip connections preserve spatial information at both local and global levels and allow the neural network to optimally integrate such information for profile construction \cite{Azad}. 

Inspired by \cite{Howard}, this paper derives a more computationally efficient CNN called Mobile U-Net to replace U-Net for onboard implementations. By modifying layers and keeping the architecture of U-Net, Mobile U-Net reduces computational and memory requirements significantly, without compromising performance in virtual IC/DV curve construction.

The details of the proposed method in Fig. \ref{fig:Algorithm} and the training of the proposed CNNs are explained in the following subsections. 

\subsection{Input}
\label{Input}

\begin{algorithm*}[h]
\textbf{Output}: downsampled and symmetrically padded current $\left\{\tilde{I}\left( k \right)\right\}$ and voltage $\left\{\tilde{V}\left( k \right)\right\}$ \

\textbf{Input}: current $\left\{I\left( \Delta Q \right)\right\}$, voltage $\left\{V\left( \Delta Q \right)\right\}$, a pre-stored increment $\Delta q$  \

 \

 $\left\{\tilde{I}\left( \Delta Q \right)\right\}$, $\left\{\tilde{V}\left( \Delta Q \right)\right\} \leftarrow$ Downsample current and voltage so that there is one datapoint every $\Delta q$ \ 

 $\left\{\tilde{I}\left( k \right)\right\}$, $\left\{\tilde{V}\left( k \right)\right\} \leftarrow$ One-sided symmetrically pad $\left\{\tilde{I}\left( \Delta Q \right)\right\}$ and $\left\{\tilde{V}\left( \Delta Q \right)\right\}$ until $N_{\text{nn}}$ points \

    \
    
  \tcc{$\Delta Q \in \left[0,\overline{\Delta Q}\right]$, $k\in\{1,2,...,N_{\text{nn}}\}$ } 
  
\caption{Proposed Downsampling and One-Sided Symmetric Padding Algorithm}
\label{alg:Downsampling}
\end{algorithm*}

Define $\text{SOC}_{\text{initial}}$, $\text{SOC}_{\text{final}}$, $\Delta\text{SOC} = \text{SOC}_{\text{final}} - \text{SOC}_{\text{initial}}$ as initial SOC, finial SOC, and partial charging range, respectively. Consider a general charging event with a charging SOC range falling in the following SOC window:
\begin{equation}
\label{eqn:SOCwindow}
\begin{cases}
    \text{SOC}_{\text{initial}} \leq \overline{\text{SOC}}_{\text{initial}} \\ 
    \text{SOC}_{\text{final}} \geq  \underline{\text{SOC}}_{\text{final}} \\ 
    \Delta\text{SOC} \geq \underline{\Delta\text{SOC}}
\end{cases}, 
\end{equation} 
where the underline $\underline{\cdot}$ and overline $\overline{\cdot}$ represent the lower and upper bounds for corresponding variables, respectively. Note that a minimum SOC window is needed for the proposed method, because charging profiles need to contain sufficient information for constructing virtual IC/DV curves properly.

Let $\left\{I\left(t\right)\right\}$, $\left\{V\left(t\right)\right\}$, $\left\{\Delta Q\left(t\right)\right\}$, $t\in \left[0,T\right]$ be the profiles of current, voltage, and transferred charge from the charging, respectively, where $t$ is time and $T$ is the total charging time. The transferred charge is defined as: 
\begin{equation}
    \Delta Q \left( t \right) = \int_{0}^{t} I \left( \tau \right) d\tau \in \left[ 0, \overline{\Delta Q} \right]. \label{eqn:CoulombCounting}
\end{equation}
$\left\{\Delta Q\left(t\right)\right\}$ always starts at 0 and ends at the total amount of transferred charge ($\overline{\Delta Q}$). Furthermore, both $\left\{I\left(t\right)\right\}$ and $\left\{V \left(t\right)\right\}$ can be re-written as functions of $\left\{\Delta Q\left(t\right)\right\}$, denoted as $\left\{I\left( \Delta Q \right)\right\}$, $\left\{V\left( \Delta Q \right)\right\}$, $\Delta Q \in \left[0,\overline{\Delta Q}\right]$, respectively. 

The inputs to the proposed method in Fig. \ref{fig:Algorithm} are $\left\{I\left( \Delta Q \right)\right\}$ and $\left\{V\left( \Delta Q \right)\right\}$. Hence, the proposed method does not use SOC as an input.

\subsection{Downsampling and One-Sided Symmetric Padding}
\label{DownsamplingAndSymmetricPadding}
$\left\{I\left( \Delta Q \right)\right\}$ and $\left\{V\left( \Delta Q \right)\right\}$ profiles measured onboard, even for a limited SOC range, typically have different profile lengths and a lot more datapoints than the number of datapoints required by the proposed CNNs. Thus, downsampling and one-sided symmetric padding in Step 1 of Fig. \ref{fig:Algorithm} are used to prepare the input signals to a standard format, as implemented in Algorithm \ref{alg:Downsampling}.

This paper proposes to downsample profiles based on transferred charge ($\Delta Q$) for the following reasons. First, time-based downsampling does not capture the most important information to represent a charging profile. For example, in fast charging, charging from 80\% to 100\% SOC takes a significant portion of the charging time because of low current magnitude \cite{Tomaszewska}, and therefore has the most number of the datapoints after downsampling. However, this only covers a small portion of the charging range. Second, downsampling based on SOC or $\Delta Q$ will overcome the limitations of time-based downsampling, but SOC needs to be estimated in practice \cite{PlettBook}, and using estimates brings additional uncertainty to the proposed method. Thus, downsampling based on $\Delta Q$ is the most suitable.

Specifically, $\left\{I\left( \Delta Q \right)\right\}$ and $\left\{V\left( \Delta Q \right)\right\}$ are downsampled for every incremental $\Delta q$ defined as: 
\begin{equation}
    \Delta q = \frac{ \Delta Q_{\text{max}} }{ N_{\text{nn}} }, \label{eqn:DownsamplingIncrement}
\end{equation}
where $N_{\text{nn}}$ is the number of datapoints required by the proposed CNNs, and $\Delta Q_{\text{max}}$ is the maximum amount of transferred charge the proposed method needs to handle. One way to determine $\Delta Q_{\text{max}}$ is:
\begin{equation}
    \Delta Q_{\text{max}} = \overline{\Delta \text{SOC}} \cdot C_{\text{fresh}}, \label{eqn:DeltaQ_max}
\end{equation}
where $\overline{\Delta \text{SOC}}$ is the maximum charging SOC range to be handled, and $C_{\text{fresh}}$ is the capacity of a battery at the fresh state. Note that $\Delta Q_{\text{max}}$ and $\Delta q$ only need to be computed once at the calibration phase of the proposed algorithm and stored in the algorithm. Hence, the proposed downsampling algorithm does not require any SOC information at the deployment phase.

\begin{remark}
     The total amount of transferred charge $\overline{\Delta Q}$ in $\left\{I\left( \Delta Q \right)\right\}$ and $\left\{V\left( \Delta Q \right)\right\}$ profiles is not necessarily divisible by $\Delta q$. Thus, after downsampling, each original profile often has a small remainder portion with the amount of transferred charge less than $\Delta q$. Because $\Delta q$ is chosen to be small, this remainder can be omitted for the rest of the proposed method.  
\end{remark}

\begin{figure*}[ht]
    \centering
    %\includegraphics[width=0.99\textwidth,trim=15 35 5 20,clip]{Results/UNet_V2.png}
    \includegraphics[width=0.99\textwidth,trim=10 5 5 25,clip]{Results/UNet_V2.png}
    \caption{Proposed U-Net and Mobile U-Net for Constructing Virtual IC/DV Curves}
    \label{fig:UNet}
\end{figure*} 

Note that, because profiles have different $\overline{\Delta Q}$ originally, the number of datapoints in downsampled profiles ($N_{\text{point}}$) is different for different profiles and smaller than the required number of datapoints by the proposed CNNs ($N_{\text{nn}}$). This is the consequence of making downsampled profiles have the same measurement frequency in the $\Delta q$-domain, which is required as CNN filters have fixed kernel sizes \cite{Siddique}. Thus, padding is adopted to meet the dimension requirement. 

While there are many different padding methods \cite{Innamorati}, this paper adopts and modifies the symmetric padding proposed by \cite{Fan} because of its ability to reduce construction errors at the borders of the constructed profiles. Specifically, this paper performs the one-sided symmetric padding, which adds mirrored datapoints to the end of the target profile until the desired length is reached. For example, if one wants to pad the profile array $\left[a,b,c\right]$ to have 8 points in length, then one keeps these three points at the beginning (left side) of the array and then adds additional mirrored points at the end (right side). The resulting padded array is $\left[a,b,c,c,b,a,a,b\right]$. For any downsampled profiles with $N_\text{point}$ points, they will be one-sided symmetrically padded to have $N_\text{nn}$ points by adding $\left( N_\text{nn} - N_\text{point} \right)$ points at the end (right side). 

After these two steps of processing, the resulting current and voltage profiles, denoted as $\left\{\tilde{I}\left( k \right)\right\}$, $\left\{\tilde{V}\left( k \right)\right\}$, $k\in\{1,2,...,N_{\text{nn}}\}$, respectively, are sent as two separate channels to the proposed CNNs, where $k$ is an index. $\Delta Q$ profile is no longer needed, as it is implicitly embedded in the downsampled current and voltage profiles. 

\subsection{Output}
\label{Output}
The outputs of Fig. \ref{fig:Algorithm} contain three separate channels, namely $\left\{ \widehat{Q}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{V}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{IC}}_{\text{CC}} ( k ) \right\}$, $k\in \left\{1,2,...,N_{\text{nn}}\right\}$. $\left\{ \widehat{\text{DV}}_{\text{CC}} ( k ) \right\}$ is obtained using $\widehat{\text{DV}}_{\text{CC}}( k ) = 1/\widehat{\text{IC}}_{\text{CC}}( k )$. The SOC range of the outputs is fixed and the same, no matter what SOC ranges the inputs have. The fixed SOC range does not need to be full-range and just needs to be broad enough to encompass all the IC/DV features of interest. This paper denotes this fixed SOC range as $\widehat{\text{SOC}} \in \left[ \widehat{\text{SOC}}_{\text{initial}}, \widehat{\text{SOC}}_{\text{final}} \right]$. Furthermore, datapoints are evenly distributed from $\widehat{\text{SOC}}_{\text{initial}}$ to $\widehat{\text{SOC}}_{\text{final}}$ for $\left\{ \widehat{Q}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{V}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{IC}}_{\text{CC}} ( k ) \right\}$ profiles. Also, due to the symmetry of the U-Net architecture (to be discussed in Sections \ref{U-Net} and \ref{U-Net-Design}), the number of datapoints for the outputs is the same as the inputs and equal to $N_{\text{nn}}$. 

\subsection{Overview of U-Net and Mobile U-Net}
\label{U-Net}
This subsection elaborates on the intuitions and working mechanisms of U-Net and Mobile U-Net used in Step 2 of Fig. \ref{fig:Algorithm}. The proposed U-Net and Mobile U-Net are shown in Fig. \ref{fig:UNet}. The software package Keras \cite{Keras} is used to build, train, validate, and test the proposed CNNs. 

The U-Net shown in Fig. \ref{fig:UNet} consists of three main components, namely the contraction path, skip connections, and expansion path \cite{Ronneberger}. The contraction path (or encoder) consists of convolution and max pooling \cite{Siddique}. The purpose of the contraction path is to extract features at different levels. As the neural network goes deeper into the contraction path (following the direction of the dashed red arrow in Fig. \ref{fig:UNet}), more global and less local features are extracted \cite{Zeiler}. The skip connections, i.e., concatenations shown in Fig. \ref{fig:UNet}, send the extracted features to the expansion path and allow the neural network to leverage both local and global features for profile constructions \cite{Azad}. The expansion path (or decoder) consists of convolution and transposed convolution \cite{Siddique}. The purpose of the expansion path is to construct profiles using received features. During the construction phase, transposed convolution finds an optimal way to expand dimensions and increase resolutions of constructed profiles, while convolution combines the constructed profiles with received features \cite{Ronneberger}. Finally, as a result of these main components, the U-Net has a symmetric architecture and forms the shape of ``U''. 

\begin{table*}[ht]
\centering
\caption{Summary of Settings for Proposed U-Net and Conv-Net}
\label{table:UNetSetup}
\begin{threeparttable}
\begin{tabular}{|c|cl|}
\hline
\textbf{Layers} & \multicolumn{2}{c|}{\textbf{Settings}} \\ \hline \hline 
\multirow{8}{*}{1D Convolution} & \multicolumn{1}{l|}{Number of Filters} & Varies, Numbers Given in Fig. \ref{fig:UNet} and Fig. \ref{fig:ConvNet} in Black \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Kernel Size} & \begin{tabular}[c]{@{}l@{}}(A): 11\\ (B): 3\\ (C): 11 for U-Net, 3 for Conv-Net\end{tabular} \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Stride} & 1 \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Padding} & Same-Padding Strategy \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Parameter Initializer} & He Normal \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Bias Used} & \begin{tabular}[c]{@{}l@{}}(A): False \\ (B): False \\ (C): True \end{tabular}  \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Batch Normalization} & \begin{tabular}[c]{@{}l@{}}(A): Applied After Linear Operation and Before Nonlinear Activation\\ (B): Applied After Linear Operation and Before Nonlinear Activation\\ (C): None \end{tabular} \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Activation Function} & \begin{tabular}[c]{@{}l@{}}(A): Parametric ReLU with Shared Axis = Axis 1\tnote{*} \\ (B): Parametric ReLU with Shared Axis = Axis 1\tnote{*} \\ (C): None\end{tabular} \\ \hline
 \multirow{8}{*}{1D Transposed Convolution} & \multicolumn{1}{l|}{Number of Filters} & Varies, Numbers Given in Fig. \ref{fig:UNet} and Fig. \ref{fig:ConvNet} in Black \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Kernel Size} & 3 \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Stride} & 2 \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Padding} & Same-Padding Strategy \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Parameter Initializer} & He Normal \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Bias Used} & False \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Batch Normalization} & Applied After Linear Operation and Before Nonlinear Activation \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Activation Function} & Parametric ReLU with Shared Axis = Axis 1\tnote{*} \\ \hline
 1D Max Pooling & \multicolumn{1}{l|}{Pool Size} & 2 \\ \hline
 Concatenation & \multicolumn{1}{l|}{Concatenation Axis} & Axis 2\tnote{*} \\ \hline
\end{tabular}
\begin{tablenotes}
\item[*] Array Format of Proposed Neural Networks: (Axis 0, Axis 1, Axis 2) = (Batch Size, Profile Length, Number of Channels).
\end{tablenotes}
\end{threeparttable}
\end{table*}

\begin{table*}[ht]
\centering
\caption{Summary of Settings for Proposed Mobile U-Net and Mobile-Net}
\label{table:MobileUNetSetup}
\begin{threeparttable}
\begin{tabular}{|c|cl|}
\hline
\textbf{Layers} & \multicolumn{2}{c|}{\textbf{Settings}} \\ \hline \hline 
 \multirow{8}{*}{\begin{tabular}[c]{@{}c@{}}1D Depthwise \\ Separable Convolution \end{tabular}} & \multicolumn{1}{l|}{ \begin{tabular}[c]{@{}l@{}}Number of Filters\\ (in Pointwise Convolution)\end{tabular} } & Varies, Numbers Given in Fig. \ref{fig:UNet} and Fig. \ref{fig:ConvNet} in Black \\ \cline{2-3} 
 & \multicolumn{1}{l|}{ \begin{tabular}[c]{@{}l@{}}Kernel Size\\ (in Depthwise Convolution)\end{tabular} } & \begin{tabular}[c]{@{}l@{}}(A): 11\\ (B): 3\\ (C): 11 for Mobile U-Net, 3 for Mobile-Net\end{tabular} \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Stride} & 1 \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Padding} & Same-Padding Strategy \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Parameter Initializer} & He Normal for Both Depthwise and Pointwise Convolutions \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Bias Used} & \begin{tabular}[c]{@{}l@{}}(A): False \\ (B): False \\ (C): True \end{tabular} \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Batch Normalization} & \begin{tabular}[c]{@{}l@{}}(A): Applied After Linear Operation and Before Nonlinear Activation\\ (B): Applied After Linear Operation and Before Nonlinear Activation\\ (C): None \end{tabular} \\ \cline{2-3} 
 & \multicolumn{1}{l|}{Activation Function} & \begin{tabular}[c]{@{}l@{}}(A): Parametric ReLU with Shared Axis = Axis 1\tnote{*} \\ (B): Parametric ReLU with Shared Axis = Axis 1\tnote{*} \\ (C): None\end{tabular} \\ \hline
 1D Upsampling & \multicolumn{1}{l|}{Size} & 2 \\ \hline
  1D Max Pooling & \multicolumn{1}{l|}{Pool Size} & 2 \\ \hline
 Concatenation & \multicolumn{1}{l|}{Concatenation Axis} & Axis 2\tnote{*} \\ \hline
\end{tabular}
\begin{tablenotes}
\item[*] Array Format of Proposed Neural Networks: (Axis 0, Axis 1, Axis 2) = (Batch Size, Profile Length, Number of Channels).
\end{tablenotes}
\end{threeparttable}
\end{table*}


For onboard implementations, the computational and memory demands of the proposed U-Net can be further reduced without compromising performance. Thus, Mobile U-Net is proposed. The Mobile U-Net in Fig. \ref{fig:UNet} has the same architecture as the proposed U-Net, but uses different layers. First, depthwise separable convolution is used to replace convolution. Depthwise separable convolution is proposed in \cite{Howard} and widely used in various CNNs \cite{Howard,Chollet,Sandler,Howard2} for mobile and embedded applications. It contains a depthwise convolution followed by a pointwise convolution, where the former performs filtering and the latter combines the filtered results \cite{Howard}. Based on \cite{Howard}, the computation and memory reduction is significant, when switching from convolution to depthwise separable convolution. Second, upsampling with simple repetition from Keras \cite{Keras} is used to replace transposed convolution. Such upsampling has no parameters to be learned. Thus, compared to transposed convolution, upsampling reduces the computation and memory significantly, but loses the ability to learn an optimal way for expanding dimensions and increasing resolutions. A more detailed discussion about the computation and memory for U-Net and Mobile U-Net will be given in Section \ref{OnboardImplementation}.

\subsection{Specific Designs of U-Net and Mobile U-Net} 
\label{U-Net-Design}

\begin{algorithm*}[h]
\textbf{Output}: SOH estimate $\widehat{\text{SOH}} \in [0,1]$ \

\textbf{Input}: $\left\{I\left( \Delta Q \right)\right\}$ and $\left\{V\left( \Delta Q \right)\right\}$ from general charging, a pre-stored increment $\Delta q$  \

 \

 $\left\{\tilde{I}\left( k \right)\right\}$, $\left\{\tilde{V}\left( k \right)\right\} \leftarrow$ Process $\left\{I\left( \Delta Q \right)\right\}$, $\left\{V\left( \Delta Q \right)\right\}$ using Algorithm \ref{alg:Downsampling} \

 $\left\{\tilde{I}^{\left( s \right)}\left( k \right)\right\}$, $\left\{\tilde{V}^{\left( s \right)}\left( k \right)\right\} \leftarrow$ Equation (\ref{eqn:ConvertStandardize}) \
 
 $\widehat{\text{SOH}} \leftarrow $  Conv-Net/Mobile-Net$\left(\left\{\tilde{I}^{\left( s \right)}\left( k \right)\right\}, \left\{\tilde{V}^{\left( s \right)}\left( k \right)\right\}\right)$ \

 \

   \tcc{$\Delta Q \in \left[0,\overline{\Delta Q}\right]$, $k\in\{1,2,...,N_{\text{nn}}\}$ } 
 
\caption{Proposed Method for Constructing SOH Estimates (Fig. \ref{fig:Algorithm_2})}
\label{alg:Method2}
\end{algorithm*}

U-Net and Mobile U-Net offer a high degree of design freedom, including the number of levels and layers per level in contraction and expansion paths. Fig. \ref{fig:UNet} shows the specific design used by this paper. Furthermore, every layer can be customized. Tables \ref{table:UNetSetup} and \ref{table:MobileUNetSetup} summarize the detailed settings used for the proposed U-Net and Mobile U-Net, respectively. 

For layer design, while some settings are directly adopted from \cite{Ronneberger}, some are customized to fit the needs of this study and are worthy of discussion. 
\begin{itemize}
    \item \textbf{Performance Enhancement}: Kernel size and activation function are designed for better construction performance. Larger kernel sizes are used in ``1D convolution A'' and ``1D depthwise separable convolution A'' (defined in Fig. \ref{fig:UNet}) to filter out input noises in the contraction path and generate smoother profiles in the expansion path. Parametric rectified linear unit (PReLU) \cite{He} is used for activation. It learns optimal leakage hyperparameters to solve the dying ReLU problem, thereby leading to better performance without an increase in computational complexity \cite{He}. Following \cite{He}, the PReLU used by this paper has one leakage hyperparameter shared within a channel and has different leakage hyperparameters across different channels. 
    \item \textbf{Improved Training Efficiency}: He Normal parameter initialization \cite{He} and batch normalization \cite{Ioffe} are used to mitigate vanishing gradient problems during the training process \cite{CNN_Book}. Following \cite{Ioffe}, batch normalization is applied after linear operations and before nonlinear activations to remove the effects of biases in linear operations. Default hyperparameters for batch normalization in Keras \cite{Keras} are adopted.
\end{itemize}

\subsection{Standardization and Training}
\label{U-Net-Training}
To make the training process unbiased and converge faster, the input profiles ($\left\{\tilde{I}\left( k \right)\right\}$, $\left\{\tilde{V}\left( k \right)\right\}$) and output profiles ($\left\{ \widehat{Q}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{V}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{IC}}_{\text{CC}} ( k ) \right\}$) are standardized first by using 
\begin{equation}
\left\{ z^{\left( s \right)} ( k ) \right\} = \frac{{\left\{ z ( k ) \right\} } - \mu_z}{\sigma_z}, \label{eqn:ConvertStandardize}
\end{equation}
where $z$ can be any variable, e.g., $\tilde{I}$, $\tilde{V}$, $\widehat{Q}_{\text{CC}}$, $\widehat{V}_{\text{CC}}$, and $\widehat{\text{IC}}_{\text{CC}}$. $\mu_z$ and $\sigma_z$ are the mean and standard deviation computed over all the points in all the training samples as:
\begin{eqnarray}
    \mu_z &=& \text{mean} \left( \left\{\left[\left\{ z ( k ) \right\} \right]_j \right\}_{j=1}^{N} \right), \\ 
     \sigma_z &=& \text{std} \left( \left\{\left[\left\{ z ( k ) \right\} \right]_j \right\}_{j=1}^{N} \right), 
\end{eqnarray}
where $\left[\left\{ z ( k ) \right\} \right]_j$ represents the profile $\left\{ z ( k ) \right\}$ from the $j$-th training sample, $k\in\{1,2,...,N_{\text{nn}}\}$, and $N$ is the total number of training samples.

The mean squared error (MSE) loss function from Keras \cite{Keras} is used in this paper. The ADAM solver \cite{Kingma} with default settings in Keras \cite{Keras} is used to solve the optimization problem, allowing adaptive learning rate, faster convergence, and bias corrections during the training process. As a regularization technique, early stopping is used to halt the training process when the validation MSE loss does not decrease for consecutive $N_{\text{th}}$ epochs \cite{CNN_Book}. 

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.99\textwidth,trim=12 9 8 5,clip]{Results/Algorithm_Overview_2.png}
    \caption{Overview of Proposed Method for State of Health (SOH) Estimation}
    \label{fig:Algorithm_2}
\end{figure*} 

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.99\textwidth,trim=10 5 10 25,clip]{Results/ConvNet_V2.png}
    \caption{Proposed Conv-Net and Mobile-Net for Estimating State of Health (SOH)}
    \label{fig:ConvNet}
\end{figure*} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONV-NET AND MOBILE-NET FOR SOH ESTIMATION}
\label{Conv-Net}
With the trained U-Net and Mobile U-Net, virtual IC/DV curves can be constructed and the virtual IC/DV features can be extracted. The U-Net and Mobile U-Net can be simplified to provide SOH estimates directly from general charging profiles with any SOC ranges satisfying Constraint (\ref{eqn:SOCwindow}). The simplified CNNs are called Conv-Net and Mobile-Net.

There is a rich literature on CNNs for SOH estimation, e.g. \cite{Yang, Gu, Chemali}. Most use fully connected layers to achieve accurate SOH estimation, but fully connected layers have a significant number of parameters and require very large computational resources. Compared to these methods in the literature, the advantage of the proposed Conv-Net is that it contains only convolutions with significantly fewer parameters, thereby providing a substantial computational advantage. Then, for mobile and embedded applications, Mobile-Net is proposed to replace the Conv-Net, with even simpler computations and less memory requirements, while maintaining SOH estimation performance. A more detailed discussion about the computation and memory for Conv-Net and Mobile-Net will be given in Section \ref{OnboardImplementation}.

The proposed method is shown in Fig. \ref{fig:Algorithm_2}. The input, downsampling, and one-sided symmetric padding are the same as what is discussed in Sections \ref{Input} and \ref{DownsamplingAndSymmetricPadding}. The outputs are SOH estimates ranging from 0 to 1. The overall procedure of the proposed method is summarized in Algorithm \ref{alg:Method2}.  

The designed Conv-Net and Mobile-Net are shown in Fig. \ref{fig:ConvNet}. It should be noted that one can train the proposed Conv-Net and Mobile-Net from scratch independently from the U-Net and Mobile U-Net. However, to have a unified approach for virtual IC/DV curves, virtual IC/DV features, and SOH estimates, transfer learning is utilized here. Specifically, the entire contraction path of the trained U-Net and Mobile U-Net is transferred to the Conv-Net and Mobile-Net, respectively, for feature extraction. For the intuition behind this, features extracted from the contraction path are used to construct virtual IC/DV curves and, thus, contain degradation information that can be leveraged to construct SOH estimates directly. The parameters associated with the contraction path are fixed during the training of the Conv-Net and Mobile-Net. New trainable layers of convolution or depthwise separable convolution are attached after the contraction path for regression purposes. Tables \ref{table:UNetSetup} and \ref{table:MobileUNetSetup} summarize the settings used for the proposed Conv-Net and Mobile-Net, respectively. The design logic is the same as what is discussed in Section \ref{U-Net-Design}. 

Similar to Section \ref{U-Net-Training}, the MSE loss, ADAM solver \cite{Kingma}, and early stopping are used for training. Since SOH takes values from 0 to 1, no additional standardization step is needed for outputs of the Conv-Net and Mobile-Net. In contrast, inputs to the Conv-Net and Mobile-Net should still be standardized using Equation (\ref{eqn:ConvertStandardize}) for faster convergence. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{BATTERY DATASETS FOR EVALUATION}
\label{DataAndPrep}
This section describes the battery module dataset used by this study for performance evaluation. Note that, given a charging profile with a specific charging SOC range, one can randomly truncate the profile to have different profiles with different charging SOC ranges. 

\subsection{Original Battery Dataset}
\label{Dataset}
The performance of the proposed unified approach delineated in Fig. \ref{fig:Algorithm} and Fig. \ref{fig:Algorithm_2} is demonstrated using a large experimental dataset of battery modules. Table \ref{table:Datasets} summarizes the key attributes of the dataset.

\begin{table}[H]
\centering
\caption{Key Attributes of the Battery Dataset}
\label{table:Datasets}
\begin{tabular}{|l|l|} 
\hline
\textbf{Attributes} & \textbf{Descriptions} \\ \hline\hline
Chemistry & NMC622 \\ \hline
Module Nominal Capacity & 208Ah \\ \hline
Module Configuration & 3 Cells in Parallel \\ \hline
No. of Modules & 96 \\ \hline
Module-Level SOH Range & 100\% - 86\% \\ \hline
No. of Fast Charging Protocols & 3 \\ \hline
No. of Input-Output Pairs & 40512 \\ \hline
No. of Input-Output Pairs Derived by Truncating & 405120 \\ \hline
\end{tabular}
\end{table}

Specifically, a proprietary dataset of lithium nickel-manganese-cobalt oxide 622 (NMC622) modules is used. 96 NMC622 modules consist of three NMC622 cells connected in parallel. These NMC622 modules are cycled using low C-rate charging profiles and fast charging profiles alternately. The low C-rate charging profile consists of two CC charging regimes with 86A and 64.5A module-level currents, respectively, and one subsequent constant-voltage regime. The module-level IC/DV curves are obtained using the first CC regime, as it contains all the module-level IC/DV features for this dataset. Three types of fast-charging protocols, as shown in Fig. \ref{fig:NonCC_Current_Profiles}, are used in this dataset, which improves the generalizability of the proposed CNNs.  

\begin{figure}[H]
    \centering
    \includegraphics[width=0.49\textwidth,trim=40 1 45 15,clip]{Results/NonCC_Current_Module.png}
\caption{Examples of Fast-Charging Current Profiles in the Dataset}
\label{fig:NonCC_Current_Profiles}
\end{figure}

Fig. \ref{fig:NMC622_Example_IC} shows one example of module-level IC/DV curves. Features such as IC peak height (IC PH) and IC partial areas (IC PA) are used in this paper. As shown in Fig. \ref{fig:NMC622_Example_IC}, the IC PH is defined as the $y$-coordinate of the IC peak, and the IC PA is defined as the area either above a user-defined horizontal cutoff line (IC PA 2) or within a user-defined symmetric voltage window around a target IC peak (IC PA 1) \cite{ZhouR}. 

For the training of the proposed U-Net and Mobile U-Net, the IC/DV curves from one low C-rate charging cycle are used as the ground truth for the outputs, while the fast charging profiles from the next cycle are used as inputs.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.49\textwidth,trim=35 15 80 25,clip]{Results/NMC622_Example_IC_new.png}
\caption{Example Module-Level IC/DV Curves and Related IC/DV Features in the Dataset}
\label{fig:NMC622_Example_IC}
\end{figure}

\subsection{Dataset Used for Training, Validation, and Testing of Proposed Neural Networks}
\label{Prep}
The original dataset only contains one wide SOC range for fast charging, namely 13\%-91\% SOC. To develop, train, validate, and test the proposed methods under any charging SOC ranges that satisfy Constraint (\ref{eqn:SOCwindow}), the fast-charging profiles in the original dataset are randomly truncated to have different SOC ranges. 

One example SOC window described by Constraint (\ref{eqn:SOCwindow}) can be: $\text{SOC}_{\text{initial}} \leq 50\%$, $\text{SOC}_{\text{final}} \geq 75\%$, and $ \Delta\text{SOC} \geq 40\%$. Note that this window is chosen as an example and it can be varied depending on applications. Most importantly, a minimum SOC window is required, because the charging range has to be long enough to contain sufficient information for constructing virtual IC/DV curves and SOH estimates properly, as discussed in Section \ref{Input}. Furthermore, for this dataset, $\overline{\Delta \text{SOC}} = 91\%-13\% = 78\%$. Then, with $N_{\text{nn}}$ set in Section \ref{Result}, $\Delta Q_{\text{max}}$ and $\Delta q$ for the downsampling discussed in Section \ref{DownsamplingAndSymmetricPadding} are determined using Equations (\ref{eqn:DownsamplingIncrement}) and (\ref{eqn:DeltaQ_max}). 

When truncating a given profile to obtain different SOC ranges, randomness is required to enable the trained CNNs to handle any SOC ranges within the specified SOC window. Assuming all different SOC ranges are equally important, the sampling distribution should be a uniform distribution satisfying Constraint (\ref{eqn:SOCwindow}). The Dirichlet-rescale algorithm proposed by \cite{Griffin} is used to generate random SOC ranges from such a constrained uniform distribution. In this case study, each input profile from the original dataset is truncated into 10 profiles with different random SOC ranges. The number ``10'' is chosen empirically. The number of input-output pairs after random truncations is given in Table \ref{table:Datasets}. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PERFORMANCE OF PROPOSED METHOD}
\label{Result}

\begin{figure*}[ht]
    \centering
    \begin{subfigure}[h]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=4 5 5 1,clip]{Results/Module_Error_Distribution.png}
        \caption{Testing Error Distribution}
        \label{fig:ModuleErrorDistribution}
    \end{subfigure} \hfill

    \begin{subfigure}[h]{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=1 5 1 1,clip]{Results/Module_CategoryA.png}
        \caption{Category A}
        \label{fig:Module_CategoryA}
    \end{subfigure}
        \begin{subfigure}[h]{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=1 5 1 1,clip]{Results/Module_CategoryB.png}
        \caption{Category B}
        \label{fig:Module_CategoryB}
    \end{subfigure}
        \begin{subfigure}[h]{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=1 5 1 1,clip]{Results/Module_CategoryC.png}
        \caption{Category C}
        \label{fig:Module_CategoryC}
    \end{subfigure}
        \begin{subfigure}[h]{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=1 5 1 1,clip]{Results/Module_CategoryD.png}
        \caption{Category D}
        \label{fig:Module_CategoryD}
    \end{subfigure}
\caption{Performance of Module-Level Virtual IC/DV Curve Construction under Random Input SOC Ranges}
\label{fig:Module_IC_Curve_Construction}
\end{figure*}

This section evaluates the performance of the proposed CNNs using the dataset described in Section \ref{Prep}. The dataset containing inputs with random SOC ranges that satisfy constraints given in Section \ref{Prep} is randomly split into 60\% training, 20\% validation, and 20\% testing sets for developments and evaluations. The comparisons among proposed U-Net, Mobile U-Net, Conv-Net, and Mobile-Net are elucidated. $N_{\text{nn}}=128$ for the proposed CNNs, downsampling, and one-sided symmetric padding in Sections \ref{UNet} and \ref{Conv-Net}. The value of $N_{\text{nn}}$ is a design choice that can be determined through trial and error. Lower $N_{\text{nn}}$ reduces computation and memory requirements, while higher $N_{\text{nn}}$ enhances the resolution of virtual IC/DV curves. The optimal value can be determined to balance the trade-off. 

\subsection{Accuracy of Constructed Virtual IC/DV Curves}
\label{CurvesResult}

\begin{figure*}[ht]
    \centering
    \begin{subfigure}[h]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=4 5 5 1,clip]{Results/Module_U_Net_Error_Distribution_CaseStudy.png}
        \caption{U-Net}
        \label{fig:Module_U_Net_Error_Distribution_CaseStudy}
    \end{subfigure} \hfill

    \begin{subfigure}[h]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=4 5 5 1,clip]{Results/Module_Mobile_U_Net_Error_Distribution_CaseStudy.png}
        \caption{Mobile U-Net}
        \label{fig:Module_Mobile_U_Net_Error_Distribution_CaseStudy}
    \end{subfigure} 
\caption{Testing Error Distributions of Module-Level Virtual IC/DV Curve Construction under Different Input SOC Ranges}
\label{fig:Module_Error_Distribution_Specific_Ranges}
\end{figure*}

This subsection examines the accuracy of virtual IC/DV curve construction and compares the performance of U-Net and Mobile U-Net. 

Recall that outputs of the proposed U-Net and Mobile U-Net are standardized virtual profiles, $\left\{ \widehat{Q}^{\left(s\right)}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{V}^{\left(s\right)}_{\text{CC}} ( k ) \right\}$, $\left\{ \widehat{\text{IC}}^{\left(s\right)}_{\text{CC}} ( k ) \right\}$, which are estimates for standardized actual curves, $\left\{ Q^{\left(s\right)}_{\text{CC}} ( k ) \right\}$, $\left\{ V^{\left(s\right)}_{\text{CC}} ( k ) \right\}$, $\left\{ \text{IC}^{\left(s\right)}_{\text{CC}} ( k ) \right\}$. The metric to evaluate each constructed virtual IC/DV curve is defined as:
\begin{equation}
    \text{Error} = \frac{1}{N_{\text{nn}}} \sum_{k=1}^{N_{\text{nn}}} \left\|  \begin{bmatrix} \text{IC}^{\left(s\right)}_{\text{CC}} ( k ) \\  V^{\left(s\right)}_{\text{CC}} ( k ) \\ Q^{\left(s\right)}_{\text{CC}} ( k ) \end{bmatrix} - \begin{bmatrix} \widehat{\text{IC}}^{\left(s\right)}_{\text{CC}} ( k ) \\  \widehat{V}^{\left(s\right)}_{\text{CC}} ( k ) \\ \widehat{Q}^{\left(s\right)}_{\text{CC}} ( k ) \end{bmatrix} \right\|_2^2, \label{eqn:MSE}
\end{equation}
where $\| \cdot \|_2$ is the Euclidean norm. 

Fig. \ref{fig:ModuleErrorDistribution} shows the defined error distribution of the testing set under random input SOC ranges, divided into four categories. For each category, a pair of virtual and actual IC/DV curves from Mobile U-Net with an average error is shown in the rest of Fig. \ref{fig:Module_IC_Curve_Construction}. Based on Fig. \ref{fig:Module_IC_Curve_Construction}, there are several observations. First, most virtual IC/DV curves are close to their corresponding actual IC/DV curves. Therefore, the U-Net and Mobile U-Net can successfully construct virtual IC/DV curves with a fixed SOC range that covers all important IC/DV features. As a result, by using the U-Net and Mobile U-Net, one can perform ICA/DVA-based degradation monitoring under general charging, which cannot be done previously in the literature. Second, by comparing the error distributions of U-Net and Mobile U-Net in Fig. \ref{fig:ModuleErrorDistribution}, the Mobile U-Net has similar performance for virtual IC/DV curve construction, but reduces the computation and memory significantly (to be discussed in Section \ref{OnboardImplementation}).

To show how well the U-Net and Mobile U-Net trained from random input SOC ranges perform when they are used in specific input SOC ranges, this paper investigates three cases, namely long-range (15\%-90\% SOC), medium-range (30\%-80\% SOC), and short-range (45\%-90\% SOC) fast charging. Data for these three cases are obtained by directly truncating the original dataset. The U-Net and Mobile U-Net trained from random input SOC ranges are not re-trained for any specific ranges, and all the data from specific ranges are used for testing. Fig. \ref{fig:Module_Error_Distribution_Specific_Ranges} shows how error distributions from different specific ranges compared to the error distribution from random input ranges. Based on Fig. \ref{fig:Module_Error_Distribution_Specific_Ranges}, the performance of the virtual IC/DV curve construction at specific input SOC ranges stays similar to the random input SOC range, but slightly deteriorates as the input SOC range decreases, because a shorter SOC range contains less information for virtual IC/DV curve construction. 

In summary, the U-Net and Mobile U-Net trained from random input SOC ranges can be used directly without re-training for fast charging with any specific SOC ranges that satisfy constraints given in Section \ref{Prep}. 

\subsection{Applications of Virtual IC/DV Curves and Features}
\label{FeaturesResult}
To demonstrate that the constructed virtual IC/DV curves can be used for various degradation monitoring tasks, this paper uses module-level SOH estimation as a case study. 

\begin{table}[H]
\centering
\caption{Module-Level SOH Estimation Performance Using Virtual IC/DV Features}
\label{table:ModuleUsefulnessOfVirtualCurves}
\begin{tabular}{|c|c|c|c|c|} 
\hline
\begin{tabular}[c]{@{}c@{}}\textbf{Neural}  \\ \textbf{Network} \end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{Charging}  \\ \textbf{Scheme} \end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{Test}  \\ \textbf{RMSE} \end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{Average} \\ \textbf{Three-Sigma} \\ \textbf{Value} \end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{No. of} \\ \textbf{Relevenace} \\ \textbf{Vectors} \end{tabular}\\ 
\hline\hline
- & CC & \begin{tabular}[c]{@{}c@{}} 0.53\% \\ SOH \end{tabular} & \begin{tabular}[c]{@{}c@{}}  1.56\% \\ SOH \end{tabular} & 7 \\ 
\hline
U-Net & Fast & \begin{tabular}[c]{@{}c@{}} 0.60\% \\ SOH \end{tabular} & \begin{tabular}[c]{@{}c@{}} 1.74\% \\ SOH \end{tabular} & 6 \\ 
\hline
Mobile U-Net & Fast & \begin{tabular}[c]{@{}c@{}} 0.61\% \\ SOH \end{tabular} & \begin{tabular}[c]{@{}c@{}} 1.77\% \\ SOH \end{tabular} & 8 \\ 
\hline
\end{tabular}
\end{table}

For module-level SOH estimation, an optimal set of IC/DV features can be found by using an information theory-based feature selection algorithm \cite{Zhou2}. For this dataset, IC partial areas (IC PA 1 and IC PA 2 defined in Fig. \ref{fig:NMC622_Example_IC}) are ranked top two \cite{Zhou2} and will be used in this paper. Using the relevance vector regression from \cite{Zhou2}, models can be built to correlate these selected features with SOH. The relevance vector regression models provide point estimates for SOH, three-sigma (99.7\%) credible intervals for estimation uncertainty, and relevance vectors to indicate model complexity. 

Table \ref{table:ModuleUsefulnessOfVirtualCurves} summarizes the SOH estimation performance under fast charging with random input SOC ranges for different proposed CNNs. Based on Table \ref{table:ModuleUsefulnessOfVirtualCurves}, virtual IC/DV features extracted from virtual IC/DV curves provide SOH estimation performance that significantly surpasses California's regulatory requirements (less than 5\% SOH estimation error \cite{CalRegulation}). Furthermore, this SOH performance is similar to that achieved using the same features derived directly from actual IC/DV curves obtained during CC charging. Thus, these virtual IC/DV curves constructed by the proposed U-Net and Mobile U-Net are effective for extending ICA/DVA-based SOH estimation to general charging, which previously could not be done. 

\subsection{Accuracy of Direct SOH Estimates}
\label{SOHResult}

\begin{figure*}[ht]
    \centering

    \includegraphics[width=0.9\textwidth,trim=4 5 5 1,clip]{Results/Module_SOH_Estimation.png}

\caption{Testing Absolute SOH Estimation Error Using Conv-Net and Mobile-Net under Random Input SOC Ranges}
\label{fig:SOHEstimationErrorDistribution}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \begin{subfigure}[h]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=4 5 5 1,clip]{Results/Module_ConvNet_SOH_Estimation_DiffRange.png}
        \caption{Conv-Net}
        \label{fig:Module_ConvNet_SOH_Estimation_DiffRange.png}
    \end{subfigure} \hfill

    \begin{subfigure}[h]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=4 5 5 1,clip]{Results/Module_MobileNet_SOH_Estimation_DiffRange.png}
        \caption{Mobile-Net}
        \label{fig:Module_MobileNet_SOH_Estimation_DiffRange}
    \end{subfigure} 
\caption{Testing Absolute Error Distributions for Module-Level SOH Estimation under Different Input SOC Ranges}
\label{fig:Module_SOH_Estimation_Error_Distribution_Specific_Ranges}
\end{figure*}


When the sole focus is on SOH estimation, the proposed U-Net and Mobile U-Net can be simplified into Conv-Net and Mobile-Net, respectively. This subsection examines and compares the performance of direct SOH estimation using the proposed Conv-Net and Mobile-Net.

Table \ref{table:SOH_RMSE} summarizes the testing RMSEs for SOH estimation using Conv-Net and Mobile-Net, next to the results obtained from U-Net and Mobile U-Net (discussed in Section \ref{FeaturesResult}). From Table \ref{table:SOH_RMSE}, Conv-Net and Mobile-Net provide SOH estimation performance that outperforms virtual IC/DV features and also significantly surpasses California's regulatory requirements discussed in Section \ref{FeaturesResult}. Therefore, Conv-Net and Mobile-Net have the advantage of providing better SOH estimation performance, while U-Net and Mobile U-Net provide IC/DV features that can be used for physical interpretations and additional information about battery degradation besides SOH (as discussed in Sections \ref{Intro} and \ref{ICA}). 

\begin{table}[H]
\centering
\caption{SOH Estimation Performance Using Conv-Net and Mobile-Net under Random Input SOC Ranges}
\label{table:SOH_RMSE}
\begin{tabular}{|c|c|c|}
\cline{1-3}
\textbf{Estimation Mode} & \textbf{Neural Network} & \textbf{Test RMSE}  \\ \cline{1-3} \hline\hline
\multirow{2}{*}{Direct Estimation} & Conv-Net & 0.49\% SOH  \\ \cline{2-3}
 & Mobile-Net & 0.51\% SOH \\ \cline{1-3}
 \multirow{2}{*}{Through Virtual IC/DV Curves} & U-Net & 0.60\% SOH  \\ \cline{2-3}
 & Mobile U-Net & 0.61\% SOH \\ \cline{1-3}
\end{tabular}
\end{table}

Fig. \ref{fig:SOHEstimationErrorDistribution} shows the testing absolute error distributions for SOH estimation under random input SOC ranges satisfying constraints in Section \ref{Prep}. Based on Fig. \ref{fig:SOHEstimationErrorDistribution} and Table \ref{table:SOH_RMSE}, one can have the following observations. First, both Conv-Net and Mobile-Net can estimate SOH directly under general charging with good accuracy, while their computation and memory requirements are smaller than other CNNs in the literature as discussed in Section \ref{Conv-Net}. Second, comparing the results between Conv-Net and Mobile-Net, Mobile-Net does not lose too much performance for SOH estimation, but further reduces the computation and memory (to be discussed in Section \ref{OnboardImplementation}).

To examine how well the Conv-Net and Mobile-Net trained from random input SOC ranges specialize to specific input SOC ranges, the same three cases in Section \ref{CurvesResult} are used. Similarly, the proposed Conv-Net and Mobile-Net are not re-trained, and all the data from these 3 cases are used as testing data. Fig. \ref{fig:Module_SOH_Estimation_Error_Distribution_Specific_Ranges} shows the absolute error distributions for the testing set. Based on Fig. \ref{fig:Module_SOH_Estimation_Error_Distribution_Specific_Ranges}, the performance of the SOH estimation using Conv-Net and Mobile-Net at specific input SOC ranges stays similar to the random input SOC ranges, but decreases as the input SOC range decreases, because a shorter input SOC range contains less information for SOH estimation. 

In summary, the Conv-Net and Mobile-Net trained from random input SOC ranges can be applied directly without re-training for general charging with any specific SOC ranges that meet constraints in Section \ref{Prep}. 

\subsection{Computational Footprint Comparison among Proposed Neural Networks}
\label{OnboardImplementation}
The computation and memory demands are crucial for onboard implementation feasibility and are directly proportional to the total number of parameters in neural networks. Henceforth, this subsection compares the total number of parameters in the proposed CNNs. 

\begin{table}[H]
\centering
\caption{Number of Parameters in Proposed Convolutional Neural Networks}
\label{table:ParamNum}
\begin{tabular}{|c|c|c|c|} 
\hline
\textbf{Models} & \begin{tabular}[c]{@{}c@{}}\textbf{Total No. of }  \\ \textbf{Parameters} \end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{No. of} \\ \textbf{Trainable}  \\ \textbf{Parameters} \end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{No. of} \\ \textbf{Fixed} \\ \textbf{Parameters} \end{tabular}\\ 
\hline\hline

U-Net & 95503 & 94323 & 1180 \\ 
\hline
Mobile U-Net & 32425 & 31385 & 1040 \\ 
\hline
Conv-Net & 73361 & 12991 & 60370 \\ 
\hline
Mobile-Net & 27118 & 4946 & 22172 \\ 
\hline
\end{tabular}
\end{table}

Table \ref{table:ParamNum} summarizes the number of parameters for different proposed CNNs. Based on Table \ref{table:ParamNum}, one can have the following observations. First, most of the parameters in the Conv-Net and Mobile-Net are fixed and inherited from the contraction path of the U-Net and Mobile U-Net for extracting degradation-related features. Second, by comparing U-Net and Mobile U-Net or comparing Conv-Net and Mobile-Net, the mobile versions of the proposed CNNs have only 1/3 of the parameters. Much lower computation and memory demands make them more feasible for onboard implementation. As seen in Sections \ref{CurvesResult}, \ref{FeaturesResult}, and \ref{SOHResult}, with such a significant reduction in the numbers of parameters, the Mobile U-Net and Mobile-Net still maintain good performance for virtual IC/DV curve construction and SOH estimation, compared to the U-Net and Conv-Net. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}
\label{Conclusion}
This paper proposes a unified approach shown in Fig. \ref{fig:Algorithm} and Fig. \ref{fig:Algorithm_2} and, for the first time, makes ICA/DVA-based degradation monitoring feasible under general charging profiles with any SOC ranges that satisfy Constraint (\ref{eqn:SOCwindow}). 

With the concepts of virtual IC/DV curves defined, the proposed U-Net constructs virtual IC/DV curves, which approximate actual IC/DV curves with proven accuracy. SOH estimation is used as a case study to demonstrate the utility of virtual IC/DV curves for degradation monitoring. Applied to a large experimental dataset of NMC622 modules with three parallel-connected cells, virtual IC/DV features achieve 0.60\% SOH RMSE and 1.74\% average SOH three-sigma value for module-level SOH estimation. The proposed Conv-Net provides accurate SOH estimates directly, if SOH is the only information of interest. For the same dataset, 0.50\% SOH RMSE for module-level SOH estimation is achieved. The low demand for computation and memory is the advantage of the proposed Conv-Net over other CNNs in the literature. 

The proposed Mobile U-Net and Mobile-Net can replace U-Net and Conv-Net, respectively, to significantly reduce computation and memory requirements for onboard implementations. The mobile versions of the proposed CNNs reduce the number of parameters in CNNs to 1/3 of the original, without losing performance in virtual IC/DV curve construction and SOH estimation. Applied to the same dataset, virtual IC/DV features from Mobile U-Net achieve 0.61\% SOH RMSE and 1.77\% average SOH three-sigma value for module-level SOH estimation. Mobile-Net achieves 0.51\% SOH RMSE for module-level SOH estimation. 

Nevertheless, there are some directions for future work. First, a method to determine the minimum required input SOC range for the proposed CNNs to have accurate virtual IC/DV curve construction and SOH estimation needs to be developed. Second, whether the proposed CNNs can work for discharging cases is of interest to be investigated. Third, the effects of measurement noise and vehicle chronometrics on the proposed method will be investigated. Fourth, how to efficiently scale the proposed methods to a large number of modules within a battery pack needs to be researched. 


%\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{APPENDIX}

%\section*{ACKNOWLEDGMENT}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ieeeconf.bst}
\bibliography{ieeeconf.bib}
\end{document}
