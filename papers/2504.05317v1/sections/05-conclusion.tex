\section{Conclusion}
We investigated the task of context attribution in QA. We focused on approaches that enhance attribution performance without relying on prohibitive human annotations. Our proposed data synthesis strategy, \synqa, enables the generation of high-quality synthetic attribution data, leading to substantial improvements in fine-tuned small models.

Through extensive experiments on six datasets across single turn QA and dialogue QA attribution, we demonstrated that small models fine-tuned with \synqa data (i) significantly outperform models trained on alternative synthetic attributions, (ii) exceed the performance of zero-shot LLMs that are orders of magnitude larger, and (iii) generalize better to out-of-domain distributions compared to models trained on gold in-domain data. These findings suggest that \synqa reduces reliance on large-scale human-labeled datasets, while improving attribution robustness across diverse scenarios.

% Furthermore, our analysis of scaling trends shows that increasing synthetic data volume consistently enhances performance, indicating that further gains can be achieved with additional data. The success of \synqa highlights the potential of synthetic data generation for context attribution and opens new avenues for improving the transparency and reliability of LLM-based question answering systems.

Finally, our user study validates the practical utility of fine-tuned small models in real-world question-answering applications. These results highlight the viability of scalable, data-efficient context attribution techniques, paving the way for more interpretable and trustworthy AI systems. 
%Next we plan to scale the user study and investigate how context attribution and \synqa can help users in real world applications.

% - We don't explore other levels of granularity; why is that important?

% - All question-answer pairs contain one chunk; while in practice, the questions and the answers might contain conjunctions, etc.

% - We do not explore RAG settings (with dialogue), where both the nature of the QAs is conversational + the context changes --> OR-QUAC in the future with RAG

% - We don't explore other tasks: context-attribution in e.g., summarization 