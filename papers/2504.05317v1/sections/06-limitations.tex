\section*{Limitations}
While our work demonstrates the effectiveness of \synqa for context attribution in question answering, we leave some important directions for future research. First, all models we train operate exclusively at the sentence level. Even though \citet{slobodkin2024attribute} found through a user study that sentence-level granularity of context attribution QA is probably the best suited granularity for manual verification of LLM output, this might not always be the optimal granularity for attribution in other tasks or scenarios. Namely, some context elements might be better captured at different levels: e.g., from individual phrases to multi-sentence passagesâ€”depending on the semantic structure of the text.

Second, while we evaluated our approach on OR-QuAC, we have not fully explored context attribution in retrieval-augmented generation (RAG) settings with dialogue. This represents a particularly challenging scenario where both the conversational nature of questions and dynamic context updating must be handled simultaneously. Future work should investigate how context attribution models can adapt to streaming contexts when the relevant context continuously evolves throughout a conversation.

Third, we focused primarily on question answering, but context attribution is valuable for many other natural language processing tasks: e.g., in text summarization, attributing summary sentences to source document segments could enhance transparency and fact-checking capabilities. Future research should examine how \synqa's synthetic data generation approach can be adapted for different tasks, potentially revealing task-specific challenges and opportunities for improving attribution mechanisms.

Fourth, our user study (\S\ref{sec:user-study}), while providing valuable initial insights into the effectiveness of context attribution to help users verify the LLM model outputs in QA settings, was conducted with a limited sample of 12 participants. A larger-scale study with more participants would strengthen the statistical validity of our findings and potentially reveal more nuanced patterns. Future work should extend this evaluation to a more diverse and larger participant pool, ideally, including users with varying levels of domain expertise and familiarity with language model outputs.