\section{Prompts to generate \synqa synthetic training data}\label{app:prompts}
In order to generate the question-answer pairs, we provide Llama 70B with the following prompts:

\begin{prompt}
\textbf{SYSTEM PROMPT}

You are tasked with generating a concise and focused question-answer pair using information from provided Wikipedia sentences. Follow these instructions carefully:


1. You will be provided with multiple Wikipedia articles, each containing:

   - The title of the article.
   
   - One specific sentence from the article.


2. Your goal is to generate a \textbf{short, factual question} and a \textbf{concise answer}, ensuring:

   - The question-answer pair is grounded in the provided sentences.
   
   - The reasoning is logical, clear, and references all sentences used.


3. \textbf{Key Constraints}:

   - Questions must address a \textbf{single coherent topic} or concept that can be logically inferred from the provided sentences.
     
   - Avoid combining unrelated pieces of information into a single question.
   
   - The \texttt{"reasoning"} must explain how each sentence in the \texttt{"ids"} field contributes  to answering the question but should remain \textbf{brief} and \textbf{to the point}.


4. Aim for \textbf{brevity}:

   - Questions should be concise and avoid unnecessary details.
   
   - Answers should be short, typically no more than one sentence.
   
   - Keep the reasoning concise, focusing only on the necessary logical connections.


5. Multi-hop reasoning is encouraged but must be natural and focused:

   - Combine information only when it is logical and directly relevant to the question.
   
   - Do not create overly complex questions that combine weakly related information.


6. Provide your response in \textbf{raw JSON format} with the following keys:

   - \texttt{"question"}: A concise and clear question string.
   
   - \texttt{"answer"}: A short and factual answer string.
   
   - \texttt{"ids"}: A list of JSON-compatible arrays (e.g., \texttt{[[0, 0], [1, 0]]}) representing the indices of all sentences used to generate the question-answer pair.
   
   - \texttt{"reasoning"}: A brief explanation of how \textbf{each sentence in \texttt{"ids"}} was used to 
     generate the question-answer pair.


\textbf{Important Notes}:

- Ensure the question-answer pair is entirely self-contained and logically consistent.

- Do not include unnecessary or weakly related information in the question or answer.

- Avoid introducing information not present in the provided sentences.

- Do not include additional formatting, explanations, or markdown in your response.
\end{prompt}

\begin{prompt}
\textbf{USER PROMPT}

Here are the titles and sentences:

Title: [First Article Title]

[0, 0] [First sentence from the article]

Title: [Second Article Title]

[1, 0] [Second sentence from the article]

Title: [Third Article Title]

[2, 0] [Third sentence from the article]

Use the provided sentences to generate a question-answer pair following the specified guidelines. Respond \textbf{only in raw JSON} with no additional formatting or markdown.
\end{prompt}

Given the \textbf{SYSTEM} and the \textbf{USER} prompt, the LLM is generating the question-answer pair, which when combined with the full articles, yields a single \synqa training data sample.

Should we want to generate a \synqa dialog training data sample, we make the prompts a bit simpler:

\begin{prompt}
\textbf{SYSTEM PROMPT}

You are an AI assistant that generates structured question-answer pairs based on a passage. Your goal is to create meaningful, factual, and reasoning-based questions that require connecting multiple sentences.

Follow these strict guidelines:

- Format the output as a \textbf{valid JSON array}, where each item has:

  - \texttt{"question"}: A clear, concise question.
  
  - \texttt{"answer"}: A short, factual response.
  
  - \texttt{"sentence\_numbers"}: A list of integers pointing to \textbf{all} relevant supporting sentences.

- \textbf{Ensure questions are generated in a random sentence order} (not sequential).

- Some questions \textbf{must reference multiple sentences} for reasoning.

- Some sentences should be \textbf{reused} across multiple questions.

- \textbf{Later questions should rely on earlier information} and use pronouns or indirect references to maintain logical flow.

- Introduce a mix of \textbf{fact-based, causal, and inference questions}.

- Avoid introducing \textbf{information not present in the passage}.

- Ensure \textbf{all relevant sentences are cited} for each answer.

Your response must be \textbf{valid JSON} containing 5 to 10 question-answer pairs.
\end{prompt}

and the user prompt:

\begin{prompt}
\textbf{USER PROMPT}

Here is a passage:

Title: [Title of the passage]

0. [First sentence of the passage]

1. [Second sentence of the passage]

2. [Third sentence of the passage]

3. [Fourth sentence of the passage]

...

Generate structured question-answer pairs following these constraints:

- \textbf{Return output in JSON format only}: \texttt{[{"question": "...", "answer": "...", "sentence\_numbers": [..]}, ...]}

- Use \textbf{random sentence order}, not sequential.

- Some questions should require \textbf{multiple sentences}.

- Some sentences should be \textbf{reused} across different Q\&A pairs.

- \textbf{Later questions must reference earlier ones} using pronouns or indirect mentions.

- \textbf{Include a mix of question types}:

  - Factual questions that can be answered directly from the passage.
  
  - Causal questions that require understanding relationships between sentences.
  
  - Inference-based questions that require implicit reasoning.

- Ensure \textbf{sentence numbers fully cover the reasoning required}.

Return \textbf{only} JSON, with no extra text.
\end{prompt}