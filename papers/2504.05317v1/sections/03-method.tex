\section{Synthesizing Attribution Data}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{img/pipeline.drawio.pdf}
    \caption{\textbf{Top:} The \synatt baseline method for synthetic attribution data generation. Given context and question-answer pairs, we prompt an LLM to identify supporting sentences, which are then used to train a smaller attribution model. However, this discriminative approach may yield noisy training data as LLMs are less suited for classification tasks (see \S\ref{sec:experiments-zero-shot}). \textbf{Bottom:} The \synqa data generation pipeline leverages LLMs' generative strengths through four steps: (1) collection of Wikipedia articles as source data; (2) extraction of context attributions by creating chains of sentences that form hops between articles; (3) generation of QA pairs by prompting an LLM with only these context attribution sentences; (4) compilation of the final training samples, each containing the generated QA pair, its context attributions, and the original articles enriched with related distractors.}
    % \caption{\textbf{Top:} The \synatt baseline. Intuitively, we can prompt an LLM for context-attribution by providing the context and question-answer pairs. Then, we train a smaller model on the obtained synthetic data. However, LLMs are less suitable for discriminative (i.e., classification) tasks, and may yield noisy training data (see \S\ref{sec:experiments-zero-shot}). \textbf{Bottom:} The \synqa data generation pipeline consists of four main steps: (1) collection of Wikipedia articles as the source data; (2) extracting the context attributions by creating chains of sentences that form hops between articles; (3) generation of QA pairs by prompting an LLM with only the context attribution sentences; (4) we obtain the resulting \synqa training sample containing three components: the generated QA pair, the context attributions, and the original articles supplemented with related distractor articles.}
    \label{fig:method}
\end{figure*}

Context attribution identifies which parts of a reference text support a given question-answer pair~\cite{rashkin2023measuring}. Formally, given a question $q$, its answer $a$, and a context text $c$ consisting of sentences ${s_1, ..., s_n}$, the task is to identify the subset of sentences $S \subseteq c$ that fully support the answer $a$ to question $q$. To train efficient attribution models without requiring expensive human annotations, we explore synthetic data generation approaches using LLMs.
% Context attribution poses the following question~\cite{rashkin2023measuring}: given a generated text $t_g$ and a context text $t_c$, is $t_g$ attributable to $t_c$? To train models to perform well on this task, we explore how to best generate synthetic attribution data using LLMs. We implement two methods: a discriminative and generative method. 
We implement two methods for synthetic data generation. Our baseline method (\synatt) is discriminative: given existing question-answer pairs and their context, an LLM identifies supporting sentences, which are then used to train a smaller attribution model. Our proposed method (\synqa) takes a generative approach: given selected context sentences, an LLM generates question-answer pairs that are fully supported by these sentences. This approach better leverages LLMs' natural strengths in text generation while ensuring clear attribution paths in the synthetic training data.

%The first method is relatively straightforward and termed \synatt. A simple way to generate synthetic data for context attribution is to ask an LLM to pick out the sentences that support a given question-answer pair. 

% \subsection{Discriminative and Generative Synthetic Data Generation}

% The first method (\synatt) is relatively straightforward: ask the LLM to pick relevant sentences from a provided context that support a given question-answer pair. However, this \textit{discriminative} approach of performing sentence classification overlooks the fact that LLMs excel at \textit{generating} text. Therefore, we design a second data generation method (\synqa) that is generative and thus capitalizes on the strength of LLMs. It involves the following pipeline steps (see also Fig.~\ref{fig:method}): context collection, question-answering generation and distractor mining, which increases the difficulty of the task, thus reflecting more realistic scenarios.

%\textbf{Attribution Synthesis.} The most straightforward approach to generating synthetic data for context attribution is discriminative: prompting an LLM to identify relevant sentences from context documents given a question-answer pair. While intuitive, this approach underutilizes LLMs' capabilities, as they excel at generative rather than discriminative tasks. LLMs are fundamentally designed to generate coherent text following instructions rather than perform binary classification of sentences. In our experiments (\S\ref{sec:experiments}) we dub this method as \synatt.

\subsection{\synqa: Generative Synthetic Data Generation Method}

\synqa consists of three parts: context selection, QA generation, and distractors mining (for an illustration of the method, see Figure~\ref{fig:method}). In what follows, we describe each part in detail.

\textbf{Context Collection.} We use Wikipedia as our data source, as each article consists of sentences about a coherent and connected topic, with two collection strategies. In the first, we select individual Wikipedia articles for dialogue-centric generation and use their sentences as context. In the second, for multi-hop reasoning, we identify sentences containing Wikipedia links and follow these links to create ``hops'' between articles, limiting to a maximum of two paths to maintain semantic coherence, while enabling more complex reasoning patterns (for more details, see Appendix~\ref{app:synthetic_data}).
% \textbf{Context Collection.}  The first step is to select a dataset where each data point is a set of sentences about a coherent and connected topic. These sentences will serve as the context in which we want to find relevant attributions later. We use Wikipedia as the data source
%To better leverage LLMs' generative capabilities, we propose \synqa, a novel and simple approach for synthesizing context attribution data (see Fig.~\ref{fig:method}). 
%We first collect Wikipedia articles that are not present in our testing datasets\footnote{We detect potential data leakage by representing each Wikipedia article as a MinHash signature. Then, for each training Wikipedia article, we retrieve candidates from the testing datasets via Locality Sensitivity Hashing and compute their Jaccard similarity \cite{dasgupta2011fast}. Pairs exceeding a tunable threshold (empirically set to 0.8) are flagged as potential leaks.}.
%For each article, 
% we implement two distinct collection strategies that differ in difficulty. First, we select individual Wikipedia articles and randomly select multiple sentences within each article. Second, we start from a randomly selected sentence containing at least one Wikipedia link
%\footnote{These are human annotated in the Wikipedia articles, or alternatively, can be obtained from entity linking methods \cite{de-cao-etal-2022-multilingual}.} 
% and follow the links to other articles, creating ``hops'' between related content. We limit the chain to a maximum of two hops (connecting up to three articles) to maintain semantic coherence while enabling the more difficult multi-hop reasoning scenarios (for more details, see Appendix~\ref{app:synthetic_data}). 
%In the second strategy, we select individual Wikipedia articles and randomly select multiple sentences within each article that can serve as evidence for generated questions.

\textbf{Question-Answer Generation.} Given the set of contexts, an LLM can now generate question-answer pairs. For single articles, we prompt the model to generate multiple question-answer pairs, each grounded in specific sentences. This creates a set of dialogue-centric samples where questions build upon the previous context. For linked articles, we prompt the model to generate questions that necessitate connecting information across the articles, encouraging multi-hop reasoning.
%\footnote{Note that multi-hop reasoning is not guranteed here; rather, the LLM has the ability to decide whether the question-answer pair involves multiple hops of reasoning. See App. for details.}. 
This yields multi-hop samples requiring integration of information across documents, as well as samples that mimic a dialogue about a specific topic given the context. We provide the full prompts used for generation in Appendix \ref{app:prompts}.

\textbf{Distractors Mining.} To make the attribution task more realistic, we augment each sample with distractor articles. With E5 \cite{wang2022text}, we embed each Wikipedia article in our collection. For each article in the training sample, we randomly select up to three distractors with the highest semantic similarity to the source articles. These distractors share thematic elements with the source articles, but lack information to answer the questions.%do not contain the information necessary to answer the generated questions.

\subsection{Advantages of \synqa}
The \synqa approach has three key advantages:
%over discriminative data generation:
% (1) it leverages LLMs' natural strength in generative tasks; (2) produces diverse multi-hop reasoning scenarios; and (3) creates coherent question-answer pairs with clear attribution paths.
(1) it leverages LLMs' strength in generation rather than classification; (2) creates diverse training samples requiring both dialogue understanding and multi-hop reasoning; and (3) ensures generated questions have clear attribution paths since they are derived from specific context sentences.
By generating both entity-centric and dialogue-centric samples, \synqa produces training data that reflects the variety of real-world QA scenarios, helping models develop robust attribution capabilities, which our experiments demonstrate to generalize across different contexts and domains.
% We formalize the problem of Context Attribution QA as follows: Given a pre-defined context $T_c=\lbrace s_1, s_2, \ldots , s_n \rbrace$---where $s_i$ is a sentence---and an answer text $t_a$ generated by an LLM, the context attribution model should provide a vector $a=(a_1, \ldots , a_n)$, where each element $a_i$ has the following possible values:
% \[
% a_i =
% \begin{cases}
%     1, & \text{if } s_i \text{ supports the generated answer } t_a\\
%     0,  & \text{otherwise} 
% \end{cases}
% \]
% In our setup, we should have at least one entry $a_i = 1$.
% \begin{itemize}
%     \item The simplest way to generate synthetic data for context-attribution is in a discriminative manner: we prompt an LLM to provide the sentence level context attributions given the context documents, question and answer. We deem this generation as discriminative as the model effectively classifies the sentences that are most relevant to the question-answer pair.
%     \item The issue with this approach is that LLM are not best suitable for discriminative tasks, but rather generative. That is, an LLM is better at generating text by following instructions, than classifing sentences/etc.
%     \item To leverage what LLMs are good for, we create a simple context attribution data generation approach where we perform the following: (1) We find wikipedia articles (which are not contained in the testing datasets)\footnote{Describe the approach for dealing with data leakage}; (2) We select a random sentence in a wikipedia article, and find the links to other wikipedia articles (the hops). We select that sentence, and hop to the other Wikipedia article (given by the link). (3) We perform the hop step for maximum of 2 times (i.e., we connect at most 3 articles, and 1 at least). We end up with 3 Wikipedia articles which constitute the hops.
%     \item We provide Llama70B with either 1 wikipedia article or the hops and ask the model to generate a multi-hop question-answer pair which ideally connects all connected articles, or as many as it can; alternatively, if we provide the model with only 1 wikipedia article, we ask the model to select as many sentences as possible in the article, and for each, generate a question-answer pair (we provide the full prompts we use in Appendix).
%     \item The output of the model is a set of question-answer pairs (or a single one), that is grounded in the evidence provided by the sentence(s). We dub the entire approach as \synqa.
%     \item In summary, we develop two settings to generate synthetic data for context attribution in question answering: one is entity-centric and yield data which might be multi-hop; and the other is dialog-centric where subsequent questions build on top of previous ones.
%     \item Finally, to all context + question + answer + context-attribution samples we add distractors: we obtain embeddings using E5 of each wikipedia page, and for each sample we select up to 3 distractors which we add to the data sample. These distractors are similar are document with similar context as the one from which the context-attributions are.
% \end{itemize}

