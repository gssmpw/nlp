% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{xspace}

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=.6pt] (char) {#1};}}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{pgfplots}
% \renewcommand{\arraystretch}{1.15}

\usepackage{paralist}
\usepackage{xcolor}

\usepackage[most]{tcolorbox}
\usepackage{colortbl}
\usepackage{enumitem}
\newtcolorbox{mybox}[2][]{
    colback=white,
    colframe=green!45,
    fonttitle=\bfseries,
    coltitle=black,
    sharp corners,
    title=#2,
    #1
}

% Squad QA - based on blue (#0073C2)
\definecolor{squadbase}{HTML}{0073C2}
\newcommand{\squadcolor}[1]{\setlength{\fboxsep}{1.5pt}\colorbox{squadbase!25}{#1}}

% HotPot QA - based on yellow (#EFC000)
\definecolor{hotpotbase}{HTML}{EFC000}
\newcommand{\hotpotcolor}[1]{\setlength{\fboxsep}{1.5pt}\colorbox{hotpotbase!35}{#1}}

% QuAC - based on teal (#00A087)
\definecolor{quacbase}{HTML}{00A087}
\newcommand{\quaccolor}[1]{\setlength{\fboxsep}{1.5pt}\colorbox{quacbase!25}{#1}}

% CoQA - based on red (#CD534C)
\definecolor{coqabase}{HTML}{CD534C}
\newcommand{\coqacolor}[1]{\setlength{\fboxsep}{1.5pt}\colorbox{coqabase!25}{#1}}

% DoQA - using orange (#FF8C38)
\definecolor{doqabase}{HTML}{FF8C38}
\newcommand{\doqacolor}[1]{\setlength{\fboxsep}{1.5pt}\colorbox{doqabase!25}{#1}}

% OR-QuAC - using green (#2ECC71)
\definecolor{orquacbase}{HTML}{2ECC71}
\newcommand{\orquaccolor}[1]{\setlength{\fboxsep}{1.5pt}\colorbox{orquacbase!25}{#1}}

% Synthetic QA - using a complementary color
\definecolor{syntheticbase}{HTML}{9B4DCA}
\newcommand{\syntheticcolor}[1]{\setlength{\fboxsep}{1.5pt}\colorbox{syntheticbase!25}{#1}}

% Table style improvements
\usepackage{booktabs}
\usepackage{multirow}

% abbreviations/dataset/model names
\newcommand{\synqa}{\textsc{SynQA}\xspace}
\newcommand{\synatt}{\textsc{Syn-Att}\xspace}

%% Paragraph customisation
\newcommand{\rparagraph}[1]{\vspace{1.6mm}\noindent\textbf{#1.}}
\newcommand{\rrparagraph}[1]{\vspace{0.4mm}\noindent\textit{#1.}}
\newcommand{\sparagraph}[1]{\vspace{0.0mm}\noindent\textbf{#1.}}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{booktabs} % toprule, bottomrule

\usepackage{multirow}

\usepackage{tcolorbox}

% Define a custom box style for AI prompts
% Define a custom style for system prompts
\newtcolorbox{prompt}{
    colback=black!3,
    colframe=black!40,
    boxrule=0.5pt,
    left=8pt,
    right=8pt,
    top=8pt,
    bottom=8pt,
    arc=2pt,
    breakable,
    enhanced,
    before skip=10pt,
    after skip=10pt
}

\newcommand{\cl}[1]{\textcolor{teal}{\bf\small [#1 --CL]}}

%% text coloring for instructions/TODOs
\newcommand{\gog}[1]{{\color{red}{[TODO]#1}}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

%\title{ALIGN-QA: Attributing LLM Inference Text to a Predefined Context for Question Answering}
%\title{LLM Explainer: Mitigating Hallucinations by Linking to Reference Sources for Human-Centric Safe Guards to Enable LLMs in High-Risk Domains}
%\title{LLM Explainer: Mitigating Hallucinations with Source Attribution for Easy Verification of LLM Output}
\title{On Synthesizing Data for Context Attribution in Question Answering}
%\title{Synthesizing Data for Context Attribution in Question Answering\\ to Mitigate LLM Hallucinations}
%\title{Synthesizing Data for Context Attribution in Question Answering for LLM Output Verification}
%with Large Language Models

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

%Gorjan, Kiril (shared 1st authorship), Shahbaz, Christopher, Sebastien, Chia-Chien, Timo, Verena, Wiem, Enomoto, Takeoka, Oyamada, Goran, Carolin.
\author{Gorjan Radevski\footnotemark[1]$^{1,6}$, Kiril Gashteovski\footnotemark[1]$^{1, 4}$, Shahbaz Syed$^1$, Christopher Malon$^2$, Sebastien Nicolas$^1$, \\ \textbf{Chia-Chien Hung$^1$, Timo Sztyler$^1$, Verena Heußer$^1$, Wiem Ben Rim$^5$,  Masafumi Enomoto$^3$,} \\ \textbf{Kunihiro Takeoka$^3$, Masafumi Oyamada$^3$, Goran Glavaš$^7$, Carolin Lawrence$^1$}
 \\
  $^1$NEC Laboratories Europe, Germany; $^2$NEC Laboratories America, USA; $^3$NEC Corporation, Japan; \\
  $^4$CAIR, Ss. Cyril and Methodius University of Skopje, North Macedonia; \\ 
  $^5$University College London, UK; $^6$ KU Leuven, Belgium; \\ 
  $^7$Center for Artificial Intelligence and Data Science, University of Würzburg, Germany %\\
  %\texttt{email@domain}
  }


  %\\\And
  %Second Author \\
  %Affiliation / Address line 1 \\
  %Affiliation / Address line 2 \\
  %Affiliation / Address line 3 \\
  %\texttt{email@domain} \\}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

%%%%% PITCH %%%%%%%%%%%%%
%% TASK and MOTIVATION
% 1. Question answering accounts for a significant portion of LLM usage "In the wild". Given the LLMs' tendency to hallucinate, that is, generate incorrect or unfaithful answers, it is paramount for LLMs' trustworthiness to equip them with the ability to ground the answers they generate in contextually provided information (i.e., provide evidence for the generated answer). 
%% KEY CONTRIBUTION(S)
% 2. In this work, we systematically investigate LLM-based approaches for this task---known as \textit{context attribution} for question answering---namely, (i) zero-shot inference, (ii) ensembling, and (iii) fine-tuning of (smaller) LLMs on synthetic data generated by larger LLMs. As a central contribution, we propose a novel strategy for synthesizing context attribution data, dubbed \synqa, in which we prompt LLMs to generate question-answer pairs for a given a set of reference sentences (from Wikipedia, mutually related via entities) meant to be the attribution context. 
%% RESULTS AND FINDINGS
%We show that the attribution data synthesized via \synqa is highly effective for fine-tuning (small) LLMs for context attribution. Our extensive experiments encompassing six datasets and two context attribution protocols (in \textit{isolation} vs. in \textit{dialog}) reveal that a small (1B) LLM fine-tuned with \synqa data (1) significantly outperform its counterpart fine-tuned with data synthesized by directly prompting the LLMs to generate attributions given the reference text and question-answer pair, (2) outperforms zero-shot context attribution of orders of magnitude larger LLMs, and (3) generalizes better, that is, is more robust to distribution shifts (e.g., in domain transfer) than models trained on gold context attribution data. Finally, we carry out a user study, the results of which validate the usefulness of small fine-tuned LMs for context attribution for question answering. 



\begin{document}
\maketitle

% Change footnote style to symbols
\renewcommand{\thefootnote}{\fnsymbol{footnote}}

% Manually reset the footnote counter to ensure the first footnote is *
\setcounter{footnote}{0}

\footnotetext[1]{Both authors contributed equally to this work.}

\footnotetext[3]{Correspondance to: gorjan.radevski@gmail.com, kiril.gashteovski@neclab.eu, carolin.lawrence@neclab.eu}

\begin{abstract}


%%%%% PITCH %%%%%%%%%%%%%
%% TASK and MOTIVATION
Question Answering (QA) accounts for a significant portion of LLM usage ``in the wild''. However, LLMs sometimes produce false or misleading responses, also known as ``hallucinations''. Therefore, grounding the generated answers in contextually provided information---i.e., providing evidence for the generated text---is paramount for LLMs' trustworthiness. Providing this information is the task of \textit{context attribution}. In this paper, we systematically study LLM-based approaches for this task, namely we investigate (i) zero-shot inference, (ii) LLM ensembling, and (iii) fine-tuning of small LMs on synthetic data generated by larger LLMs. Our key contribution is \synqa: a novel generative strategy for synthesizing context attribution data. Given selected context sentences, an LLM generates QA pairs that are supported by these sentences. This leverages LLMs’ natural strengths in text generation while ensuring clear attribution paths in the synthetic training data. We show that the attribution data synthesized via \synqa is highly effective for fine-tuning small LMs for context attribution in different QA tasks and domains. Finally, with a user study, we validate the usefulness of small LMs (fine-tuned on synthetic data from \synqa) in context attribution for QA. 

%Our extensive experiments, encompassing six datasets and two context attribution protocols (in \textit{isolation} vs. in \textit{dialog}), reveal that a small (1B) LLM fine-tuned with \synqa data (1) significantly outperforms its counterpart fine-tuned on data obtained by directly prompting the LLMs to generate attributions given the context and question-answer pair (denoted as \synatt), (2) outperforms zero-shot context attribution of orders of magnitude larger LLMs, and (3) generalizes better, i.e., is more robust to distribution shifts (e.g., domain transfer) than models trained on gold attribution data. Finally, we carry out a user study which validates the usefulness of small fine-tuned LMs in context attribution for question answering. 

%Large Language Models (LLMs) are used for a wide range of variety of tasks. People mostly use them as Question Answering (QA) systems, by posing queries (i.e., questions) to them and the LLMs provide answers. The generated answers, however, sometimes contain information that is factually incorrect; i.e., the LLMs sometimes hallucinate. Therefore, it is important for people to have a context attributor: an alignment model that links the generated inference text to a predefined context. In this paper, we study the capabilities of current LLMs to perform the QA attribution task. We found that (1) large zero-shot LLMs have decent performance, but are limited by their large size; (2) fine-tuning smaller LMs is good for in-domain cases, but is severely limited with out-of-domain cases; (3) discrimantive and generative synthetic generation strategies for fine-tuning smaller LMs are superior to using large LMs; (4) a user study which verifies that our small fine-tuned LMs are indeed helpful for human users. We will release the data, benchmark and code upon acceptance.
\end{abstract}

\input{sections/01-introduction}
\input{sections/03-method}
\input{sections/04-experiments}
\input{sections/02-rel-work}
\input{sections/05-conclusion}
%\clearpage
\input{sections/06-limitations}

\bibliography{custom}

\clearpage

\appendix
\input{sections/appendix_rel_work}
\input{sections/appendix_data_synthesis_generation}
\input{sections/appendix_prompts}
\input{sections/appendix_zero_shot_prompts}
\input{sections/appendix_user_study}
\end{document}