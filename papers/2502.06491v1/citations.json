[
  {
    "index": 0,
    "papers": [
      {
        "key": "DBLP:KidambiRNJ20",
        "author": "Rahul Kidambi and\nAravind Rajeswaran and\nPraneeth Netrapalli and\nThorsten Joachims",
        "title": "MOReL: Model-Based Offline Reinforcement Learning"
      },
      {
        "key": "DBLP:SwazinnaUR21",
        "author": "Phillip Swazinna and\nSteffen Udluft and\nThomas A. Runkler",
        "title": "Overcoming model bias for robust offline deep reinforcement learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "DBLP:Talvitie17",
        "author": "Erik Talvitie",
        "title": "Self-Correcting Models for Model-Based Reinforcement Learning"
      },
      {
        "key": "DBLP:AsadiML18",
        "author": "Kavosh Asadi and\nDipendra Misra and\nMichael L. Littman",
        "title": "Lipschitz Continuity in Model-based Reinforcement Learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "DBLP:YuTYEZLFM20",
        "author": "Tianhe Yu and\nGarrett Thomas and\nLantao Yu and\nStefano Ermon and\nJames Y. Zou and\nSergey Levine and\nChelsea Finn and\nTengyu Ma",
        "title": "{MOPO:} Model-based Offline Policy Optimization"
      },
      {
        "key": "DBLP:abs-2111-11097",
        "author": "Christopher Diehl and\nTimo Sievernich and\nMartin Kr{\\\"{u}}ger and\nFrank Hoffmann and\nTorsten Bertram",
        "title": "{UMBRELLA:} Uncertainty-Aware Model-Based Offline Reinforcement Learning\nLeveraging Planning"
      },
      {
        "key": "DBLP:ZhengWXH23",
        "author": "Ruijie Zheng and\nXiyao Wang and\nHuazhe Xu and\nFurong Huang",
        "title": "Is Model Ensemble Necessary? Model-based {RL} via a Single Model with\nLipschitz Regularized Value Function"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2022lapo",
        "author": "Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Wang, Jianhao and Gao, Alex Yuan and Li, Wenzhe and Bin, Liang and Finn, Chelsea and Zhang, Chongjie",
        "title": "Lapo: Latent-variable advantage-weighted policy optimization for offline reinforcement learning"
      },
      {
        "key": "DBLP:YangJZMS22",
        "author": "Yijun Yang and\nJing Jiang and\nTianyi Zhou and\nJie Ma and\nYuhui Shi",
        "title": "Pareto Policy Pool for Model-based Offline Reinforcement Learning"
      },
      {
        "key": "DBLP:MaT0M23",
        "author": "Yi Ma and\nHongyao Tang and\nDong Li and\nZhaopeng Meng",
        "title": "Reining Generalization in Offline Reinforcement Learning via Representation\nDistinction"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "DBLP:WangLJZLZ21",
        "author": "Jianhao Wang and\nWenzhe Li and\nHaozhe Jiang and\nGuangxiang Zhu and\nSiyuan Li and\nChongjie Zhang",
        "title": "Offline Reinforcement Learning with Reverse Model-based Imagination"
      },
      {
        "key": "DBLP:LyuLL22",
        "author": "Jiafei Lyu and\nXiu Li and\nZongqing Lu",
        "title": "Double Check Your State Before Trusting It: Confidence-Aware Bidirectional\nOffline Model-Based Imagination"
      },
      {
        "key": "DBLP:LuBTP23",
        "author": "Cong Lu and\nPhilip J. Ball and\nYee Whye Teh and\nJack Parker{-}Holder",
        "title": "Synthetic Experience Replay"
      },
      {
        "key": "DBLP:abs-2406-12550",
        "author": "Jie{-}Jing Shao and\nHao{-}Sen Shi and\nLan{-}Zhe Guo and\nYu{-}Feng Li",
        "title": "Offline Imitation Learning with Model-based Reverse Augmentation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "DBLP:JannerFZL19",
        "author": "Michael Janner and\nJustin Fu and\nMarvin Zhang and\nSergey Levine",
        "title": "When to Trust Your Model: Model-Based Policy Optimization"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "DBLP:JannerLL21",
        "author": "Michael Janner and\nQiyang Li and\nSergey Levine",
        "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"
      },
      {
        "key": "DBLP:DT",
        "author": "Lili Chen and\nKevin Lu and\nAravind Rajeswaran and\nKimin Lee and\nAditya Grover and\nMichael Laskin and\nPieter Abbeel and\nAravind Srinivas and\nIgor Mordatch",
        "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"
      },
      {
        "key": "DBLP:YamagataKS23",
        "author": "Taku Yamagata and\nAhmed Khalil and\nRa{\\'{u}}l Santos{-}Rodr{\\'{\\i}}guez",
        "title": "Q-learning Decision Transformer: Leveraging Dynamic Programming for\nConditional Sequence Modelling in Offline {RL}"
      },
      {
        "key": "DBLP:BadrinathFNB23",
        "author": "Anirudhan Badrinath and\nYannis Flet{-}Berliac and\nAllen Nie and\nEmma Brunskill",
        "title": "Waypoint Transformer: Reinforcement Learning via Supervised Learning\nwith Intermediate Targets"
      },
      {
        "key": "DBLP:GaoWCKZ024",
        "author": "Chenxiao Gao and\nChenyang Wu and\nMingjun Cao and\nRui Kong and\nZongzhang Zhang and\nYang Yu",
        "title": "{ACT:} Empowering Decision Transformer with Dynamic Programming via\nAdvantage Conditioning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "DBLP:JannerLL21",
        "author": "Michael Janner and\nQiyang Li and\nSergey Levine",
        "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"
      },
      {
        "key": "DBLP:DT",
        "author": "Lili Chen and\nKevin Lu and\nAravind Rajeswaran and\nKimin Lee and\nAditya Grover and\nMichael Laskin and\nPieter Abbeel and\nAravind Srinivas and\nIgor Mordatch",
        "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"
      },
      {
        "key": "DBLP:YamagataKS23",
        "author": "Taku Yamagata and\nAhmed Khalil and\nRa{\\'{u}}l Santos{-}Rodr{\\'{\\i}}guez",
        "title": "Q-learning Decision Transformer: Leveraging Dynamic Programming for\nConditional Sequence Modelling in Offline {RL}"
      },
      {
        "key": "DBLP:BadrinathFNB23",
        "author": "Anirudhan Badrinath and\nYannis Flet{-}Berliac and\nAllen Nie and\nEmma Brunskill",
        "title": "Waypoint Transformer: Reinforcement Learning via Supervised Learning\nwith Intermediate Targets"
      },
      {
        "key": "DBLP:GaoWCKZ024",
        "author": "Chenxiao Gao and\nChenyang Wu and\nMingjun Cao and\nRui Kong and\nZongzhang Zhang and\nYang Yu",
        "title": "{ACT:} Empowering Decision Transformer with Dynamic Programming via\nAdvantage Conditioning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "DBLP:JannerLL21",
        "author": "Michael Janner and\nQiyang Li and\nSergey Levine",
        "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "DBLP:DT",
        "author": "Lili Chen and\nKevin Lu and\nAravind Rajeswaran and\nKimin Lee and\nAditya Grover and\nMichael Laskin and\nPieter Abbeel and\nAravind Srinivas and\nIgor Mordatch",
        "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "DBLP:YamagataKS23",
        "author": "Taku Yamagata and\nAhmed Khalil and\nRa{\\'{u}}l Santos{-}Rodr{\\'{\\i}}guez",
        "title": "Q-learning Decision Transformer: Leveraging Dynamic Programming for\nConditional Sequence Modelling in Offline {RL}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "DBLP:LeeNYLFGFXJMM22",
        "author": "Kuang{-}Huei Lee and\nOfir Nachum and\nMengjiao Yang and\nLisa Lee and\nDaniel Freeman and\nSergio Guadarrama and\nIan Fischer and\nWinnie Xu and\nEric Jang and\nHenryk Michalewski and\nIgor Mordatch",
        "title": "Multi-Game Decision Transformers"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "DBLP:BadrinathFNB23",
        "author": "Anirudhan Badrinath and\nYannis Flet{-}Berliac and\nAllen Nie and\nEmma Brunskill",
        "title": "Waypoint Transformer: Reinforcement Learning via Supervised Learning\nwith Intermediate Targets"
      }
    ]
  }
]