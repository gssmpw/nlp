@inproceedings{DBLP:AsadiML18,
  author       = {Kavosh Asadi and
                  Dipendra Misra and
                  Michael L. Littman},
  title        = {Lipschitz Continuity in Model-based Reinforcement Learning},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {80},
  pages        = {264--273},
  publisher    = {{PMLR}},
  year         = {2018}
}

@inproceedings{DBLP:BadrinathFNB23,
  author       = {Anirudhan Badrinath and
                  Yannis Flet{-}Berliac and
                  Allen Nie and
                  Emma Brunskill},
  title        = {Waypoint Transformer: Reinforcement Learning via Supervised Learning
                  with Intermediate Targets},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@inproceedings{DBLP:DT,
  author       = {Lili Chen and
                  Kevin Lu and
                  Aravind Rajeswaran and
                  Kimin Lee and
                  Aditya Grover and
                  Michael Laskin and
                  Pieter Abbeel and
                  Aravind Srinivas and
                  Igor Mordatch},
  title        = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
  booktitle    = {NeurIPS},
  pages        = {15084--15097},
  year         = {2021}
}

@inproceedings{DBLP:GaoWCKZ024,
  author       = {Chenxiao Gao and
                  Chenyang Wu and
                  Mingjun Cao and
                  Rui Kong and
                  Zongzhang Zhang and
                  Yang Yu},
  title        = {{ACT:} Empowering Decision Transformer with Dynamic Programming via
                  Advantage Conditioning},
  booktitle    = {{AAAI}},
  pages        = {12127--12135},
  publisher    = {{AAAI} Press},
  year         = {2024}
}

@inproceedings{DBLP:JannerFZL19,
  author       = {Michael Janner and
                  Justin Fu and
                  Marvin Zhang and
                  Sergey Levine},
  title        = {When to Trust Your Model: Model-Based Policy Optimization},
  booktitle    = {NeurIPS},
  pages        = {12498--12509},
  year         = {2019}
}

@inproceedings{DBLP:JannerLL21,
  author       = {Michael Janner and
                  Qiyang Li and
                  Sergey Levine},
  title        = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  booktitle    = {NeurIPS},
  pages        = {1273--1286},
  year         = {2021}
}

@inproceedings{DBLP:KidambiRNJ20,
  author       = {Rahul Kidambi and
                  Aravind Rajeswaran and
                  Praneeth Netrapalli and
                  Thorsten Joachims},
  title        = {MOReL: Model-Based Offline Reinforcement Learning},
  booktitle    = {NeurIPS},
  year         = {2020}
}

@inproceedings{DBLP:LeeNYLFGFXJMM22,
  author       = {Kuang{-}Huei Lee and
                  Ofir Nachum and
                  Mengjiao Yang and
                  Lisa Lee and
                  Daniel Freeman and
                  Sergio Guadarrama and
                  Ian Fischer and
                  Winnie Xu and
                  Eric Jang and
                  Henryk Michalewski and
                  Igor Mordatch},
  title        = {Multi-Game Decision Transformers},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@inproceedings{DBLP:LuBTP23,
  author       = {Cong Lu and
                  Philip J. Ball and
                  Yee Whye Teh and
                  Jack Parker{-}Holder},
  title        = {Synthetic Experience Replay},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@inproceedings{DBLP:LyuLL22,
  author       = {Jiafei Lyu and
                  Xiu Li and
                  Zongqing Lu},
  title        = {Double Check Your State Before Trusting It: Confidence-Aware Bidirectional
                  Offline Model-Based Imagination},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@inproceedings{DBLP:MaT0M23,
  author       = {Yi Ma and
                  Hongyao Tang and
                  Dong Li and
                  Zhaopeng Meng},
  title        = {Reining Generalization in Offline Reinforcement Learning via Representation
                  Distinction},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{DBLP:SwazinnaUR21,
  author       = {Phillip Swazinna and
                  Steffen Udluft and
                  Thomas A. Runkler},
  title        = {Overcoming model bias for robust offline deep reinforcement learning},
  journal      = {Eng. Appl. Artif. Intell.},
  volume       = {104},
  pages        = {104366},
  year         = {2021}
}

@inproceedings{DBLP:Talvitie17,
  author       = {Erik Talvitie},
  editor       = {Satinder Singh and
                  Shaul Markovitch},
  title        = {Self-Correcting Models for Model-Based Reinforcement Learning},
  booktitle    = {{AAAI}},
  pages        = {2597--2603},
  publisher    = {{AAAI} Press},
  year         = {2017}
}

@inproceedings{DBLP:WangLJZLZ21,
  author       = {Jianhao Wang and
                  Wenzhe Li and
                  Haozhe Jiang and
                  Guangxiang Zhu and
                  Siyuan Li and
                  Chongjie Zhang},
  title        = {Offline Reinforcement Learning with Reverse Model-based Imagination},
  booktitle    = {NeurIPS},
  pages        = {29420--29432},
  year         = {2021}
}

@inproceedings{DBLP:YamagataKS23,
  author       = {Taku Yamagata and
                  Ahmed Khalil and
                  Ra{\'{u}}l Santos{-}Rodr{\'{\i}}guez},
  title        = {Q-learning Decision Transformer: Leveraging Dynamic Programming for
                  Conditional Sequence Modelling in Offline {RL}},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {38989--39007},
  publisher    = {{PMLR}},
  year         = {2023}
}

@inproceedings{DBLP:YangJZMS22,
  author       = {Yijun Yang and
                  Jing Jiang and
                  Tianyi Zhou and
                  Jie Ma and
                  Yuhui Shi},
  title        = {Pareto Policy Pool for Model-based Offline Reinforcement Learning},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2022}
}

@inproceedings{DBLP:YuTYEZLFM20,
  author       = {Tianhe Yu and
                  Garrett Thomas and
                  Lantao Yu and
                  Stefano Ermon and
                  James Y. Zou and
                  Sergey Levine and
                  Chelsea Finn and
                  Tengyu Ma},
  title        = {{MOPO:} Model-based Offline Policy Optimization},
  booktitle    = {NeurIPS},
  year         = {2020}
}

@inproceedings{DBLP:ZhengWXH23,
  author       = {Ruijie Zheng and
                  Xiyao Wang and
                  Huazhe Xu and
                  Furong Huang},
  title        = {Is Model Ensemble Necessary? Model-based {RL} via a Single Model with
                  Lipschitz Regularized Value Function},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@article{DBLP:abs-2111-11097,
  author       = {Christopher Diehl and
                  Timo Sievernich and
                  Martin Kr{\"{u}}ger and
                  Frank Hoffmann and
                  Torsten Bertram},
  title        = {{UMBRELLA:} Uncertainty-Aware Model-Based Offline Reinforcement Learning
                  Leveraging Planning},
  journal      = {CoRR},
  volume       = {abs/2111.11097},
  year         = {2021},
  url          = {https://arxiv.org/abs/2111.11097},
  eprinttype    = {arXiv}
}

@article{DBLP:abs-2406-12550,
  author       = {Jie{-}Jing Shao and
                  Hao{-}Sen Shi and
                  Lan{-}Zhe Guo and
                  Yu{-}Feng Li},
  title        = {Offline Imitation Learning with Model-based Reverse Augmentation},
  journal      = {CoRR},
  volume       = {abs/2406.12550},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.12550},
  doi          = {10.48550/ARXIV.2406.12550},
  eprinttype    = {arXiv}
}

@article{chen2022lapo,
  author={Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Wang, Jianhao and Gao, Alex Yuan and Li, Wenzhe and Bin, Liang and Finn, Chelsea and Zhang, Chongjie},
  title={Lapo: Latent-variable advantage-weighted policy optimization for offline reinforcement learning},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36902--36913},
  year={2022}
}

