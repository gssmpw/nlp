\section{Introduction}
\label{sec:intro}


\begin{figure}[t]
  \centering
    \includegraphics[width=\linewidth]{img/teaser}

  \captionof{figure}{
  While \textbf{global equivariant} designs ensure robustness to whole-scene rotations, they fail with randomly rotated scene parts or elements. In contrast, \textbf{local equivariant} operations maintain robustness by handling local geometry rotations around each point.
  }
  \label{fig:teaser}
\end{figure}


In 3D vision, point clouds are the most commonly used representation to process 3D data given that they are relatively cheap to capture and process. This representation is composed of multiple point coordinates, with additional attributes such as color or normal vector, from samples on the surface of 3D objects.
In the past years, several neural network architectures have been proposed to process such data~\cite{qi2017pointnet,atzmon2018pccnn,thomas2019KPConv,boulch2020convpoint,hermosilla2018mccnn,wu2019pointconv}.
Approaches learning directly from 3D data often take inspiration from the success in 2D vision and address two of the main challenges in such data representation, order invariance and translation equivariance. Yet, 3D data entails more variations and complex group transformations due to an increased number of degrees of freedom (DoF); for the roto-translation group SE(3), $\text{DoF}=6$. Objects in 3D space do not have a predefined canonical orientation and many rotational variances are present. 

%introduce invariance, equivariance
Equivariance is the property of an operator that allows the prediction of the transformation of the output given an input transformation, while group-invariant operators produce identical features under various group transforms of the input. The latter can be seen as an information loss; they struggle to differentiate between unique instances with internal symmetries, e.g., "$8$" vs. "$\infty$". Baking SE(3)-equivariance into the network architecture can thus be beneficial since equivariant features maintain information about the input group transform across neural layers, making them more expressive and generalizable by capturing the variance that is present in the data. 

Traditionally, to obtain such properties, data augmentation techniques are used, but this requires neural networks to store latent orientations of the objects, limiting the network capacity.
Whilst this might be a viable solution for network architectures for 2D images, neural networks for 3D point clouds usually require large amounts of memory, limiting the number of parameters of the models and making it impossible to achieve such equivariance from the data.
Recent advances have been made to address this problem~\cite{deng2021vector, puny2022frame}, where several neural network architectures can match or even surpass the performance of the standard architectures relying on data augmentations.

Unfortunately, many of those solutions only address the problem of global rotation equivariance, \ie rotations of a single 3D object or scene as a whole.
3D objects or scenes are composed of multiple parts or objects that can have arbitrary orientations \wrt each other, see Fig.~\ref{fig:teaser}.
The relative orientations of different objects in the scene cannot be captured by global equivariance as obtained by existing architectures or by data augmentation techniques.



Group convolution is an operation that is, per definition, equivariant to a specific group and, hence, capable of coping with such problems.
These operations aggregate information from neighboring samples, not only from the translation group T(3) as standard convolutions, but from the rotation and translation group SE(3).
By restricting the receptive field of these operations, they become rotation equivariant \wrt the local geometry inside the receptive field, allowing them to be equivariant to the relative rotations of different parts of the scene.
To successfully compute such operations in the continuous domain a complex integral over the full group needs to be solved (6D convolution), which makes such operations not practical for large networks since it has large memory and computational burden. Further, defining a grid on SE(3) is not trivial, where recent works try to address these problems by using \ac{MC} integration~\cite{finzi2020generalizing} or by discretizing the SO(3) group~\cite{chen2021equivariant, zhu2023e2pn}.
However, as we will show, these approximations limit the performance of the network.

%method
In this paper, we propose using a finite subset $\mathcal{F}(x) \subset$ SE(3), referred to as a frame, to solve the group equivariant integral, which allows for exact equivariance (as opposed to approaches based on \ac{MC} sampling or discretization), while reducing the computational burden. 
The elements $g \in \mathcal{F}(x)$ can be seen as \ac{LRF}, that together with their corresponding point $x$ build a grid on SE(3), where the integral of the group convolution can be computed efficiently.
Further, our approach stochastically samples $g \in \mathcal{F}(x)$ during training with only a few samples, two or even one, which reduces the additional computational and memory burden significantly and for the case of one sample to almost zero.
Our extensive experiments show that such group convolution is able to achieve local rotation equivariance, surpassing other local equivariant designs by a large margin.
Moreover, our experiments also show that a network constructed using such convolutions as building blocks is able to be robust to local transformations not seen during training, where popular global equivariant frameworks fail.
