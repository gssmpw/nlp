\section{Introduction}



\begin{figure}[t!]
    \centering
    \includegraphics[width=0.99\linewidth]{article/figures/intro.pdf}
    \caption{An illustration of successive paraphrasing using GPT-4o-mini: Here, $T_0$ denotes the original human-written text, while $T_i$ indicates the i-th round of paraphrases. The nodes depicted in the lower section represent valid paraphrases for the input sentence, with distance reflecting textual variation. Successive paraphrases generated by LLMs are confined to alternating between two limited clusters, represented as blue and orange nodes.} 
    \label{figs:intro}
\end{figure}

Dynamical systems theory provides a mathematical framework for understanding how iterative processes evolve over time~\cite{system1,system2}. 
In such systems, repetitive transformation can guide the state of the system toward stable configurations, known as attractors~\cite{attractor1}. 
These attractors can manifest as fixed points, limit cycles, or more complex structures. 
Applying this perspective to large language models, which iteratively map input text to output text, allows us to characterize their long-term behavioral patterns in a principled manner.

Paraphrase generation can serve as a valuable testbed for exploring these dynamics. 
Paraphrases are re-expressions of the same underlying meaning, differing only in their textual or linguistic form~\cite{bhagat_what_2013}. 
They serve multiple purposes: improving the readability of text for language learners~\cite{motlagh_impact_nodate,roe_what_2022,kim_how_2024}, enriching datasets in low-resource scenarios~\cite{okur_data_2022,sobrevilla_cabezudo_investigating_2024}, and enhancing stylistic variation~\cite{krishna-etal-2020-reformulating}. 
With recent advances in LLMs~\cite{touvron2023llama2openfoundation,alpaca,gpt3,gpt4}, machine-generated paraphrases can rival or surpass human quality, exhibiting remarkable generalization across diverse domains and text lengths.



While producing a single paraphrase demonstrates an LLM’s ability to exploit its prior knowledge to create textual variety while preserving semantic equivalance, \textbf{successive paraphrasing} pushes this capacity further. 
Instead of generating just one re-expression, the model recursively paraphrases its own output over multiple rounds~\cite{can_ai,ship}. 
Intuitively, this iterative process is expected to explore an expansive linguistic landscape, generating a rich tapestry of forms. Each subsequent paraphrase, based on previously transformed text, could theoretically diverge into increasingly varied structures—similar to depth-first exploration of the paraphrase search space in contrast to breadth-first approaches like beam search~\cite{Holtzman2020The,huang-etal-2023-affective,meister-etal-2023-locally}.



In practice, however, we find that this expected variety does not materialize. 
Instead of diverging across a vast combinatorial space, the LLM’s successive paraphrasing converges onto a limited set of recurring solutions, as depicted in Figure~\ref{figs:intro}. 
When studied through the lens of dynamical systems, these recurring solutions resemble \textit{a stable attractor cycle—a low-order periodic orbit in the space of possible paraphrases}~\cite{attractor1}. 
Rather than continuously discovering new linguistic configurations, the model settles into a pattern where the paraphrased outputs repeat with a fixed period. 
This phenomenon is subtle: it does not always manifest as explicit repetition but rather as a recurring rotation among a small set of structurally similar forms. 
Such periodic attractors challenge the intuition that longer or more complex texts should accomodate a broad array of distinct paraphrases. 
Instead, the LLM gravitates toward a small closed orbit, revealing inherent limitations in its expressive variability.


Specifically, to investigate this attractor-like behavior, we compile a diverse collection of human-written texts~\cite{li2023mage} and prompt a range of both open-source and commercial LLMs to perform 15 rounds of successive paraphrasing. 
Using normalized Levenshtein distance to quantify textual variation, we consistently observe a \textbf{2-period cycle}: each new paraphrase resembles the one generated two steps prior. 
This periodicity proves robust, remaining consistent across multiple models, text lengths, and prompts.
We further analyze model perplexity and generation diversity as successive paraphrasing unfolds. 
The results indicate that, rather than wandering freely in the paraphrase space, LLMs grow increasingly confident in a narrow set of solutions, effectively collapsing onto these attractors. 
Modifying generation hyperparameters or introducing perturbations, such as alternating prompts and models, only subtly disrupts these obstinate attractor cycles.
Moreover, this tendency to settle into attractor cycles extends beyond paraphrasing. Any invertible task, i.e., one that allows reconstructions of previous inputs, shows similar behavior, suggesting that such cycles are a general characteristic of LLM iterative behavior.


Finally, we propose a straightforward method to disrupt attractor cycles while maintaining semantic fidelity.
By intervening in the iterative process, we can reintroduce meaningful variation and prevent the model from settling into stable yet constrained periodic orbits.
% We utilize successive paraphrasing as a means to gain broader insights into the inherent dynamical constraints of large language models.
In summary, we propose to leverage successive paraphrasing to reveal that LLM outputs, when treated as a dynamical system, tend to converge onto stable attractor cycles rather than exploring open-ended linguistic variety. 
Understanding these attractors and identifying strategies to escape them is key to unlocking the full expressive potential of LLMs.
We will release our data and code after the anonymous period.
% , not only for paraphrasing but for a broad range of iterative NLP tasks.