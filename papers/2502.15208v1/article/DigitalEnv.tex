%\section{Discussion}
%In this section, we will explore the significance and potential applications of our findings, and discuss their impact on the Internet.
%Firstly, our findings reflect the self-enhancement nature of large language models (LLMs). Secondly, these findings can be applied to defend against current successive paraphrasing attacks, leading to a more robust AI text detection system. Furthermore, we illustrate how to break out of the periodic cycle. Finally, we discuss the potential risks and impacts of the widespread utilization of LLMs for paraphrasing.
%These points will be illustrated in detail in the following subsections.
\section{Digital Environment Homogenization}
Digital environment homogenization has raised a great concern in the research community, with the widespread use of LLMs.
In this paper, We have already demonstrated how successive paraphrasing contributes to this homogenization and the inherent principal behind it.
What concerns us most is that homogenization will become even more severe as LLMs grow more powerful.
We further conducted the same experiments across a series of LLMs with well-recognized performance rankings. 
The results in Appendix \ref{} indicate that as LLMs continue to develop, they are likely to exacerbate the issue of homogenization.
We believe that current LLMs are enhancing their ability to answer factual questions with precise responses, which leads to more specific answers. 
However, this increased specificity contributes to homogenization. 
As LLMs continue to advance, the issue of homogenization will become more pronounced, resulting in a more uniform digital world, which seems like the curse of statistic AI.


We face a future where the internet is saturated with AI-paraphrased content, and whether its impacts are entirely negative needs to be discussed.


From a negative perspective, The digital environment can be likened to natural ecosystems. 
Just as a loss of biodiversity makes a natural ecosystem more vulnerable and less robust, homogenization in the digital environment can have similar weakening effects. 
The diminishing of linguistic diversity in the digital world will lead to a dilemma in preserving the complexity, resilience, and richness of our culture,  potentially reshaping the thinking of future generations. 
At an AI level, this could also influence the training of next-generation LLMs. 
The study by \citealt{} highlights the potential risk that incorporating model-generated content into the training process of future models might lead to model collapse.


From a positive perspective, however, paraphrasing tools based on LLMs have been widely used in education, news, and academic, and a series of studies have shown that they can help children learn language more effectively.
Besides, the increased presence of texts generated by LLMs aligned with human values on the internet can also help shape a positive personality in future generations, leading to a harmonious and peaceful world.
For LLMs, We can also leverage homogenization to accelerate model training. 
The web corpus, which consists of paraphrased texts rather than directly generated ones, can update factual knowledge while improving grammatical fluency. 
Utilizing these model-preferred corpora—designed to avoid repetitive memorization—may result in a more efficient training process, faster convergence due to the consistent distribution, and a reduced risk of model collapse.

%\subsection{AI Homogenization}
%\label{AI homognization}
%In Section \ref{SPwithDiverseModel}, we have pointed out the problem we refer to as AI homogenization within LLMs.
%We argue that it is caused by similar training processes, significant overlap in datasets, and similar model structures.
%AI homogenization raises serious philosophical and copyright issues concerning model rights and presents significant challenges in AI text attribution. 
%Philosophically speaking, if two teams independently train two models and these models exhibit similar distributions, can it still be said that each model possesses a unique right?
%Except the model rights, it also brings challenge in text source attribution, which means determining which AI model or system generated a specific piece of text.


