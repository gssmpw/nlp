\section{Related Work}
\textbf{GCN-based Methods.}\quad
The skeletal representation of humans, characterized by joints and their adjacent links, can be effectively modeled as a graph. This correlation has been extensively explored by researchers **Kipf, "Semi-Supervised Classification with Graph Convolutional Networks"**__**Niepert, "Learning on Graphs by Node Sampling"**
In **Simonovsky, "Dynamic Graph CNN for Learning on Point Clouds"**, a multi-scale graph was introduced that adeptly captures features across multiple scales, enabling the accurate prediction of future human motions. Concurrently, **Katzir, "Semi-Constrained Graph Convolutional Networks for Human Motion Prediction"** developed a semi-constrained graph that explicitly encodes skeletal connections and integrates prior knowledge. Building on this, they proposed a multi-scale spatial-temporal graph **Battaglia, "Interaction Networks for Learning about Actions and Objects from Natural Language Descriptions"** to achieve comprehensive modeling.
Differently, our work simulate the human visual system. We design a unique GCN structure that handles dynamic and static information separately, thereby eliminating the disruption of irrelevant data. Moreover, we encode the data hierarchically to obtain richer localized human information.

\textbf{TCN-based methods.} \quad
RNNs are inherently prone to error accumulation **Chen, "Temporal Convolutional Networks for Efficient Processing of Real-World Sequences"**. Conversely, Temporal Recurrent Networks (TCNs) mitigate common issues such as gradient explosion or vanishing gradients, as their back-propagation paths diverge from the temporal sequence direction. These strengths have led to the increasing application of TCNs in HMP.  
For instance, in **Bai, "An Empirical Evaluation of Generic Convolutional and Recurrent Network Architectures"**, TCNs are employed to decode the dynamics of sub-motions and the spatial correlations within the entire motion sequence to predict future movements. Subsequently, **Dekkers, "Efficient Temporal Convolutional Networks for Human Motion Prediction"** propounds a residual TCN that is characterized by a minimalist design yet delivers high efficiency.
Diverging from conventional methods, we have developed a TCN-based model. This network harmoniously fuses the strengths of both RNNs and TCNs, creating a recurrent temporal convolutional network adept at predicting future movements. 

\textbf{GAN-based Methods.} \quad
GANs have emerged as a pivotal tool in addressing HMP challenges, not only for constructing novel networks but also for advancing learning algorithms. Recent advancements include specialized adaptations such as HP-GAN, which modifies the improved WGAN-GP for probabilistic HMP **Bergman, "Human Pose Estimation via Graph Convolutional Networks and Adversarial Training"**. Additionally, Bi-GANs **Zhang, "Bi-Directional Generative Adversarial Networks for Human Motion Prediction"** and GAN-poser **Duan, "GAN-Pose: A Novel 3D Human Pose Synthesis Method via GAN"** introduce bi-directional structures to enhance prediction accuracy. An AMGAN **Li, "Adversarial Multi-GAN Network for Human Kinematic Chain Modeling"** targets kinematic chains.
Adversarial strategies in motion analysis also be leveraged for network training **Wang, "Simulating Path Integral using GANs for Efficient Motion Synthesis"**, demonstrating their effectiveness in various contexts. Notably, SGRU **Chen, "Simulated Gradient-based Recurrent Unit Network for Human Motion Prediction"** employs GANs to simulate path integral, offering a distinct perspective on motion modeling.
In our investigation, we contribute a theoretical demonstration that dimension reduction significantly enhances the convergence of WGAN. Moreover, we utilize GANs for motion context modeling.

\begin{figure*}[t]
\begin{center}
\includegraphics[width=.9\linewidth]{Fig/F2.pdf}
\caption{HVIS including two components: Human-like vision module (HVM) and Human-like inference module (HIM).}
\label{fig:2}
\end{center}
\end{figure*}