\section{Conclusions}

We present FastAtlas, a novel GPU-based method for the generation of dynamic texture atlases for texture-space shading. As our experiments demonstrate, FastAtlas can be used across the entire spectrum of TSS applications. Our method addresses the main sources of visual artifacts present in prior methods: uneven sampling rate, undersampling, and shading discontinuities along visible texture seams. It generates charts with invisible seams, and bijectively parameterizes and packs their visible fragments into texture atlases with high packing efficiency in real time. We validate our method by performing texture-space shading on complex scenes, and demonstrating its superiority over the state of the art in terms of shading quality given the same application driven setup. 

\paragraph*{Limitations and Future Work} Like all projection-based TSS methods, when charts are downscaled triangles on screen with near-subpixel geometry may not be rasterized into the shading atlas due to the hardware rasterizer's crack-free rendering rules. In rare cases, this can lead to tiny but distinct details being removed. A potential solution could be to support per chart scaling that prevents visible triangles from shrinking to size below one pixel.

Like prior work, FastAtlas only considers the geometry of the scenes being rendered and is agnostic to the texture or material properties of the rendered content. However, as pointed out by \cite{sander2002signal}, the impact of atlas stretch on actual visual output quality depends on the properties of the data stored in the atlas. A data (shading) dependent atlasing strategy is therefore a promising area of future work. It is also interesting to further explore GPU based texture atlasing algorithms that further increase packing efficiency.

\paragraph*{Acknowledgements} The authors wish to thank the authors of Neff et al. \shortcite{Neff2022MSA} and Mueller et al. \shortcite{mueller2018shading}, especially Markus Steinberger, for their assistance and meshlet generation source code. We also thank Jinfan Yang and Suzuran Takikawa for their help with figures. We acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC) grant RGPIN-2024-03981. F. Gu was supported by an NSERC CGS-M scholarship. Finally, this work is supported in part by the Institute for Computing, Information and Cognitive Systems (ICICS) at UBC.
