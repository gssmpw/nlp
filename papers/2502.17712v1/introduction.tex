\section{Introduction}

In modern rendering, shading is traditionally performed jointly with visibility determination during rasterization or ray tracing, and is typically the most time-consuming part of image synthesis.
With standard forward rendering, the shading rate per-pixel, per-frame, is equal to the number of visible samples. Decoupling shading from visibility computation allows shading to be computed at a different frame rate than rasterization ({\em temporal} decoupling), or at a different spatial resolution ({\em spatial} decoupling). 
Decoupled shading has many applications \cite{ragan2011decoupled,baker2012rock,mueller2021tasa,baker:2016,hillesland2016texel,Neff2022MSA,Baker2022,mueller2018shading,hladky2019tessellated,hladky2021snakebinning,Neff2022MSA}.
Shading at a lower frame rate and/or resolution can yield significant time savings \cite{mueller2021tasa}; alternatively, shading at a higher resolution than display resolution can improve visual quality through more accuracy or reduced flicker \cite{baker2012rock,Baker2022}. 
Decoupled shading can also facilitate applications such as streaming shading across a network, and improve the performance of applications that benefit from shading at a lower resolution than rasterization, such as foveated rendering for near-eye virtual reality displays, and depth-of-field blur. 
Since decoupled shading is not directly supported on commercially available GPUs, the most promising approach for implementing it on existing architectures has historically been Texture-Space Shading (TSS) (e.g. \cite{baker:2016,hillesland2016texel,Neff2022MSA,mueller2018shading,Baker2022}). 
TSS methods first compute shading information and store it in a texture atlas, and then use the shaded atlas during rasterization. We propose {\em FastAtlas}, a new real-time texture atlasing approach that specifically targets TSS applications. FastAtlas computes atlas charts and packing dynamically  and enables better render quality than the state of the art (e.g. Figs. ~\ref{fig:teaser},~\ref{fig:static}).

\begin{figure}
\includegraphics[width=\linewidth]{fig_vs_static32k_v1.pdf}
\caption{(a) Input frame shaded using forward rendering; (b) $32\operatorname{k} \times 32\operatorname{k}$ static atlas of the scene (bottom, content not visible in the frame shaded in red) and TSS render of the input scene using this atlas (top); (c) FastAtlas $2\operatorname{k} \times 2\operatorname{k}$ atlas of the frame (bottom) and corresponding TSS render (top). As reflected by the \FLIP error, using static atlases leads to significant undersampling even at high atlas resolutions. Our results yield higher quality than traditional static atlases at 1/256th of the memory footprint. (Zoom in to check the dessert of the day.)}
\vspace{-6mm}
\label{fig:static}
\end{figure}

Early TSS approaches used {\em static}, pre-computed, texture atlases covering {\em entire scenes} \cite{baker:2016, hillesland2016texel,Baker2022}. Consequently, each individual frame only used a small portion of the charts stored in each atlas, leading to significant memory underutilization. Even when the overall atlas size is very large, this workflow often results in undersampling (low texel-to-pixel ratio) of the content visible in individual frames. This undersampling is particularly pronounced on content close to the camera \cite{Neff2022MSA,Karis:NaniteTalk} (Sec. ~\ref{sec:results}, Fig.~\ref{fig:static}b).
More recent {\em dynamic} atlasing methods \cite{mueller2018shading,hladky2019tessellated,hladky2021snakebinning,Neff2022MSA} pre-compute atlas charts once, and then each frame generate a new atlas containing only fully or partially visible charts. Dynamic atlassing significantly reduces per-frame atlas memory waste, and thus helps reduce undersampling. 
While static methods can use time-consuming CPU-based atlassing strategies (Sec.~\ref{sec:related}), dynamic ones must form atlases in real-time. Existing dynamic methods generate atlases with relatively low packing efficiency, negatively impacting sampling rate (Figs. ~\ref{fig:teaser}bc, ~\ref{fig:atlas}b, ~\ref{fig:prev_work}bc). Moreover, most dynamic methods have uneven sampling rate, and often exhibit extreme and highly visible undersampling across portions of rendered scenes (see floor and over-door frieze in Fig. ~\ref{fig:teaser}bc). This makes them ill-suited for applications which seek to control, or at least bound, sampling rate (Sec~\ref{sec:related}).
While the method of \cite{Neff2022MSA} allows better control of sampling rate than the alternatives, it produces renders with notable shading artifacts along visible chart seams (Figs.~\ref{fig:seams}b, ~\ref{fig:atlas}b (wall)); these artifacts become increasingly noticeable as the resolution of the texture atlas and/or sampling rate decreases. 

Avoiding these pitfalls while supporting a broad range of TSS applications requires a dynamic atlassing method that is real-time; can operate across a range of atlas sizes, including ones small enough to be efficiently transmitted over a network; allows control of texel-to-pixel ratio; does not introduce seam artifacts; and lastly, yet critically, is bijective across the visible portion of the rendered scenes. FastAtlas addresses all of these goals through a combination of new GPU-based chartification, parameterization, and atlas packing methods (Sec.~\ref{sec:overview}). Unlike prior approaches, which use offline pre-computed charts, we use the connected components of the visible surfaces in each frame as the texture atlas charts, eliminating visible seams and consequently seam artifacts. We then bijectively parameterize the visible portions of our charts in real-time via simple perspective projection. Projection evenly distributes undersampling, both within each chart and across different charts, making extreme blurring of the type that prior methods are prone to (Fig. ~\ref{fig:teaser}, Fig. ~\ref{fig:prev_work}) highly unlikely. 

\begin{figure*}
\includegraphics[width=\linewidth]{fig_fig3_v8.pdf}
\vspace{-6pt}
\caption{
FastAtlas vs. \cite{Neff2022MSA}: (a) reference forward renderer; (b) atlas computed using \cite{Neff2022MSA}, and resulting render; (c) atlas computed by packing FastAtlas charts using \cite{Neff2022MSA} packing algorithm and resulting render; (d) atlas computed by applying FastAtlas packing to \cite{Neff2022MSA} charts and resulting render; (e) FastAtlas generated atlas and resulting render. All atlases are $2K \times 2K$. While both methods use projection to parameterize charts, FastAtlas  preserves the input chart scale much better than \cite{Neff2022MSA} ($L^{\infty}$ stretch of 1.17 (e) vs. 4.06 (b)). Lower stretch leads to better render quality (b,d). We further improve visual quality by using charts with no visible seams (a vs b and c). Highlighted regions and their corresponding charts (insets) directly illustrate the impact of stretch (scale) on render quality.}   
\label{fig:atlas}
\label{fig:san_miguel}
\end{figure*}

Our remaining, and core, challenge is to quickly and efficiently pack the parameterized charts into an atlas (higher packing efficiency allows for a higher sampling rate; Fig.~\ref{fig:atlas}). Traditional packing methods \cite{levy2002least,igarashi2001adaptive,Noll2011,sander2002signal} are too slow for our needs. Prior dynamic atlasing methods rely on strong assumptions about the shape and size of the parameterized charts, which either make them inapplicable in our setting (\cite{mueller2018shading,hladky2019tessellated,hladky2021snakebinning}) or result in highly inefficient packing on our more general charts (\cite{Neff2022MSA}; Fig \ref{fig:atlas}c). We pack the parameterized charts, or more specifically their bounding boxes, using a new and efficient GPU-based parallel algorithm which wastes significantly less space than prior real-time approaches (Sec.~\ref{sec:results}). We compute conservative bounding boxes for the parameterized charts directly in homogenous clip space, avoiding compute-heavy explicit clipping, by reviving a 1978 method by Blinn \cite{Blinn:CalculatingScreenCoverage}. Our method is deterministic, generating identical atlases for identical frames, thus avoiding undesirable flicker. It can be used in other settings where real time packing of general 2D charts or boxes is useful.

We validate our method by generating and shading texture atlases, in real-time, with settings that reflect the requirements of different decoupled shading applications, including spatial and temporal decoupling, and streaming (Sec~\ref{sec:results}). 
Our method is able to generate atlases for most scenes in under 1.5 msec per frame, and is fast enough to be performed every frame on complex scenes (e.g. San Miguel 9M triangles; Fig. ~\ref{fig:san_miguel}).
We compare our method against existing alternatives in the context of reduced rate shading and memory limited applications such as atlas streaming.  When shading at reduced rate, FastAtlas outperforms the closest alternative by 25\% on average in terms of visual quality (perceptual difference vis-a-vis forward rendering). When using fixed size atlases with dimensions ranging from 2K to 8K, we outperform the closest alternative by 35\% on average in terms of visual quality. A major factor in these improvements is the quality of the atlases we produce, measured via the stretch metric \cite{sander2001texture}. Our average $L^2$ stretch, across all atlas sizes and screen resolutions, is 1.66 (a value of 1 is ideal); this value is 17.8 for the closest alternative.
We further demonstrate the versatility of our approach by using FastAtlas atlases for overshading, temporal reuse, and other rendering applications (depth-of-field and foveated rendering); see supplementary.

