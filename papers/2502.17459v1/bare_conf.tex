
%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}

\renewcommand{\baselinestretch}{0.96} 

%\newcommand{\bigrho}{\raisebox{-.35\baselineskip}{\huge\ensuremath{\rho}}}
\newcommand{\bigrho}{\makebox{\Large\ensuremath{\rho}}}

% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.

\usepackage{color}

\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{algpseudocode}
% \usepackage{algorithmic}
\usepackage{mathtools, cuted}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\usepackage{multicol}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{caption}
\captionsetup{justification = justified, singlelinecheck = false}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{mathrsfs} 


\usepackage[margin=0.8in, top=0.92in,bottom=1.1in, columnsep=0.24in]{geometry}
\DeclareMathOperator{\diag}{diag}

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
% \title{Analysis of the Latent Dimension of AI/ML-based CSI compression}
\title{Study on Downlink CSI compression: Are Neural Networks the Only Solution?}

% What does AI/ML based CSI compression learn?

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations


%=================uncomment later=================%
\author{\IEEEauthorblockN{K. Sai Praneeth\IEEEauthorrefmark{1}, Anil Kumar Yerrapragada\IEEEauthorrefmark{2}, 
Achyuth Sagireddi\IEEEauthorrefmark{3},
Sai Prasad\IEEEauthorrefmark{4}
and Radha Krishna Ganti\IEEEauthorrefmark{5}}
\IEEEauthorblockA{Department of Electrical Engineering\\
Indian Institute of Technology
Madras \\ Chennai, India  600036\\
Email: \IEEEauthorrefmark{1}praneethk@smail.iitm.ac.in,
        \{\IEEEauthorrefmark{2}anilkumar,
        \IEEEauthorrefmark{3}achyuth,
        \IEEEauthorrefmark{4}venkatasiva\}@5gtbiitm.in,
		\IEEEauthorrefmark{5}rganti@ee.iitm.ac.in
% Email: http://www.michaelshell.org/contact.html
}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}

Massive Multi Input Multi Output (MIMO) systems enable higher data rates in the downlink (DL) with spatial multiplexing achieved by forming narrow beams. 
%The performance gain is dependent on the availability of accurate Channel State Information (CSI) at the base station (gNB), which is obtained through feedback from the User Equipment (UE). In Massive MIMO systems, CSI feedback constitutes significant overhead. 
The higher DL data rates are achieved by effective implementation of spatial multiplexing and beamforming which is subject to availability of DL channel state information (CSI) at the base station. For Frequency Division Duplexing (FDD) systems, the DL CSI has to be transmitted by User Equipment (UE) to the gNB and it constitutes a significant overhead which scales with the number of transmitter antennas and the granularity of the CSI.
To address the overhead issue, AI/ML methods using auto-encoders have been investigated, where an encoder neural network model at the UE compresses the CSI and a decoder neural network model at the gNB reconstructs it. However, the use of AI/ML methods has a number of challenges related to (1) model complexity, (2) model generalization across channel scenarios and (3) inter-vendor compatibility of the two sides of the model. In this work, we investigate a more traditional dimensionality reduction method that uses Principal Component Analysis (PCA) and therefore does not suffer from the above challenges. Simulation results show that PCA based CSI compression actually achieves comparable reconstruction performance to commonly used deep neural networks based models.


% Downlink (DL) Channel State Information (CSI), transmitted by user equipment (UE) to the base-station, plays a vital role in MIMO operation, importantly in Frequency Division Duplexing (FDD) mode of communication.
% Transmission of accurate CSI introduces significant overhead on the uplink. 
% To address the overhead issue, deep learning methods such as auto-encoders have been investigated, where encoder at the UEs are used to compress the channel state information, and decoder at the base-station reconstruct it. 
% However, the use of an AI/ML models for CSI compression has significant number of challenges such as 1) model generalization over multiple scenarios 2) Number of AI/ML models required 3) Computational complexity vs overhead reduction 4) Inter-vendor compatibility of models at UE, NW and 5) standardization effort required to implement AI/ML models and 6) Computational power required by UE. 
% %Despite these advancements, a critical question remains: what exactly are these AI/ML models learning to compress the channel? This paper investigates this issue and presents conclusive findings on the underlying mechanisms in AI/ML-based CSI compression techniques.
% In this work, we investigate more traditional dimensionality reduction methods such as Principal Component Analysis (PCA). 



% The advantages of PCA based CSI compression compared to model based CSI compression is that PCA based method does not have the challenges mentioned earlier for AI/ML model based methods. However, the PCA based CSI reconstruction requires the compressed CSI and the transformation matrix used for compression to be fedback from UE to NW. 

%We use a conventional Principle Component Analysis (PCA) technique to compress the CSI and attempt to understand if AI/ML induced CSI compression is necessary and also the various drawbacks associated with such methods in terms of complexity and generalisation.

\end{abstract}

% no keywords

\IEEEpeerreviewmaketitle

% \section{What are we trying to understand}
% \begin{itemize}
%     \item Do auto-encoders learn 1) CIR  or 2) delay-doppler as the latent dimensions in AI/ML based CSI compression
%     \item Can we achieve good CSI compression performance if we enforce the latent dimension to be CIR or delay-doppler domain
%     \item Does encoder and decoder trained separately learn IDFT and DFT respectively ?
% \end{itemize}

% \section{Flow for Simulations and Training}
% \begin{itemize}
%     \item Assumptions - Rx antennas = 1
%     \item Generate MATLAB based channel in both time and frequency domains as initial step
%     \item The training data is CFR in angular-delay domain
%     \item Dimensions and data fix for encoder's output (choice of Lest) and decoder's input (feedback) - $N_t'L$

%     $svd(H_t) = U\Sigma V$\\
%     $L\times L, L\times N_t , N_t\times N_t$\\
%     $L\times L, L\times N_t' , N_t'\times N_t$
% \end{itemize}

% \section{Data generation}
% \begin{itemize}
%     \item How many taps to consider in CIR 
%     \item How to combine CIRs of all tx-antenna, rx-antenna pairs
% \end{itemize}
% \section{Tasks for the paper}
% 1. Generate time domain data (freq to time truncation) \\
% 2. Train encoder with time domain channel $L\times N_t$ dimension as input. During training, the output of encoder which is the compressed dimension is $L \times N_t'$. Choice of $N_t' = N_t/4, N_t/8 etc..$. Should see at what $N_t'$ this gives good accuracy. (PCA based technique for labels)\\
% 3. Decoder with compressed dimension and $\hat{H_t}$.\\
% 4. Similarity score $H_t - \hat{H_t}$\\

% what we have to communicate about codebooks. 
% Low-resolution (Type-1) and High resolution (Type-II)
% e-Type II has some compression

\section{Introduction}
In OFDM-based MIMO systems, with Time Division Duplexing (TDD) mode of operation, channel reciprocity is used to deduce Downlink Channel State Information (CSI) from the Uplink channel characteristics. 
However for Frequency Division Duplexing (FDD) based systems, the downlink CSI has to be transmitted by the UE to the base station (sometimes referred to as network).
%However for Frequency Division Duplexing (FDD) based systems, this might not be the scenario, the channel is estimated at the UE based on known reference signal sent by the base-station. 
This feedback typically requires huge uplink resources in order to transfer the whole CSI. To reduce overhead on the uplink, 3GPP has introduced codebook-based methods which allow partial CSI feedback to be conveyed, helping the base station to understand the channel conditions. 
In \cite{38214_3gpp}, the Type-I codebook was developed, which communicates only wide-band channel information. This was followed by the Type-II codebook, which communicates higher resolution of CSI feedback such as sub-band level channel information along with wide-band information.
Further improvements were added in \cite{38214_3gpp_r16} with the introduction of the enhanced Type II (eType-II) codebook, which reduces overhead by compressing the sub-band level channel information using a DFT based transformation. The Type-I codebook has the least overhead but suffers from performance degradation \cite{10339312} compared to Type-II and eType-II. The Type-II and eType-II codebooks allow higher granularity of CSI reporting but at the cost of higher overheads. \cite{38214_3gpp_r18} supports Doppler codebooks which are applicable to high mobility scenarios but also suffer from higher overhead. 

To address the increased overhead issues, \cite{38214_3gpp_r18} introduced the study of AI/ML based CSI compression, which essentially uses neural networks to compress the channel at the UE and re-construct it at the base station as depicted in Figure \ref{fig:architecture_csi_overview}. Deep learning techniques such as auto-encoders, have obtained considerable attention because of their potential to further reduce the overhead and optimize CSI compression~\cite{8918798,wen2018deeplearningmassivemimo,9768327,9296555,9466243,9171358,9473840,9538824,9126231,9446900,9417115,9481880,8744528}.  
 \begin{figure}[ht!]
    \centering
    %\captionsetup{justification=centering}
    \includegraphics[width = 0.48\textwidth]{Figures/CSI_NEt.png}
    \caption{AI/ML induced CSI compression framework over-view.}
    \label{fig:architecture_csi_overview}
\end{figure}
%These methods offer a promising solution to the overhead issue by enabling efficient CSI transmission. However, an important question still persists: what exactly are these AI/ML models learning during the compression process? Are they merely optimizing traditional transformations like the Discrete Fourier Transform (DFT), or are they discovering more complex patterns and distributions within the channel data? Understanding this can open further advancements in CSI compression for next-generation wireless systems like 5G beyond and 6G.



Despite the promise shown by AI/ML for CSI compression, there are several issues related to their practical deployment. In this paper: 
\begin{itemize}
    \item  We investigate the necessity of neural network-based CSI compression by considering factors like computational complexity, generalization across channel scenarios, and inter-vendor compatibility of the two sides of the CSI compression models. 
    \item We propose a PCA based method which does not suffer from the above issues. Using two representations of the channel (angular-delay domain and eigenvector) we compare the performance of PCA based compression with state-of-art neural networks.
\end{itemize}

% The remainder of the paper is organized as follows: Section \ref{sectionII} provides a detailed overview of the system model and the PCA based compression for both angular-delay and eigen vector data. Section \ref{sec:III} delves into architectures for AI/ML-based CSI compression which including the processes of model training and inference. Section \ref{sec:IV} investigates whether the  AI/ML simulations which is followed by performance comparison and results in section \ref{sec:V}. Section \ref{sec:VI} concludes the paper along with the future directions of this work.

\section{System Model and PCA based compression}\label{sectionII}
% We consider a zero doppler, multi antenna user $N_{rx}$ which communicates with a base-station\footnote{The term \textit{network} is used in place of base-station at times in the paper.} of $N_t$ transmit antennas. 
In this work, we consider two different representations of the wireless channel i.e., $1)$ Angular-Delay domain representation and $2)$ Eigenvector representation. In this section, we explain the channel modeling followed by the Principal Component Analysis (PCA) for both domains. 

\subsection{System Model}
We consider an $N$ sub-carrier OFDM system with $N_t$ transmit antenna ports and $N_{rx}$ receive antennas. Without loss of generality, we assume that the base station is the transmitter and the UE is the receiver. 
The received signal at the $s^{th}$ sub-carrier $\mathbf{Y}[s]$ is given by

\begin{equation} \label{eq:1}
    \mathbf{Y}[s] = \mathbf{H}[s]\mathbf{x}[s]  + \mathbf{W}[s],
\end{equation}

where $\mathbf{Y}[s]$ is of size $N_{rx}\times 1$. $\mathbf{H}[s]$ is the $N_{rx}\times N_{t}$ channel, $\mathbf{x}[s]$ is the $N_{t}\times 1$ transmitted sequence and $\mathbf{W}[s]$ is the $N_{rx}\times 1$ noise vector. 


In this paper we consider perfect knowledge of channel. We also assume that $N_{rx} = 1$. In this case, the channel across the entire bandwidth (all $N$ sub-carriers) can be represented by the $N\times N_{t}$ matrix $\mathbf{H_f}$ given by,
\begin{equation}\label{freq_spatial}
    \mathbf{H_f} = 
    \begin{bmatrix}
  \mathbf{h}[1] \\
  \mathbf{h}[2] \\
  \vdots \\
  \mathbf{h}[N] \\
\end{bmatrix}
    % \mathbf{H_f} \in \mathbb{C}^{N \times N_t}.
\end{equation}
where $\mathbf{h}[\cdot]$ is the $1\times N_{t}$ representation of $\mathbf{H}[\cdot]$.
\subsection{Angular-Delay (AD) Domain Data}
The spatial-frequency domain channel matrix $\mathbf{H_f}$ can be sparsed in the angular-delay domain using a 2D discrete Fourier transform (DFT) as given in~\cite{wen2018deeplearningmassivemimo}.

\begin{equation}\label{angle_delay_eq}
    \mathbf{H_{ad}} = \mathbf{F_d} \mathbf{H_f} \mathbf{F_a}^H,
\end{equation}
where $\mathbf{F_d}$ and $\mathbf{F_a}$ are $N \times N$ and $N_t \times N_t$ DFT matrices respectively.

It is important to note that only a few rows, say $L$, in $\mathbf{H_{ad}}$ are significant and all other rows would have values close to zero. Thus, by selecting the significant rows, the final angular-delay representation of channel is given by 
\begin{equation}\label{final_angle_delay_eq}
    \mathbf{H_{t_L}} \in \mathbb{C}^{L \times N_t} 
\end{equation}
$\mathbf{H_{t_L}}$ can be interpreted as a time domain channel with $L$ taps. 
%The truncated $L\times N_t$ channel matrix is represented using $H_{t_L}$. The highest level of compression for a frequency domain channel $H_f$ can be achieved by representing the channel through its time-domain components.

%To apply PCA on top of the channel $H_{t_L}$, two operations are required.
The Principal Component Analysis of the angular-delay domain channel involves finding the independent time-domain channels across all the transmitter antennas i.e, the angular domain. 
The PCA on the antenna dimension determines the minimum number of components (antennas with unique channel properties are chosen whereas those antennas with redundant channel information are ignored) that capture the angular properties of the channel. 
%These two operations will result in compression of actual channel estimated in spatial-frequency domain. 

This technique, when applied at the UE, performs compression and is analogous to an encoder neural network. The task at the base-station would be to perform the inverse PCA to recover the angular-delay representation of the channel. The compression ratio scales with the choice of number of delays/taps and the number of principal components.
Note that the transformation of PCA would be different for each instance of the channel and each UE. 
The initial reduction of the channel $\mathbf{H_{f}}$ to $L\times N_t$, originally from $N\times N_t$, is achieved by the transformations in Eq.~\eqref{angle_delay_eq} and further reduction in the spatial dimension from $N_t$ to $N_t'$, is achieved by the implementation of PCA. 
%PCA identifies the $N_t'$ principle components with the highest variance, allowing us to focus on the dominant spatial features and truncate the channel effectively. 

The overall CSI feedback with PCA is $\mathbf{H}_{PCA,AD}$ of dimension $L\times N_t'$ along with a transformation matrix $\mathbf{H}_{N_t'}$ of dimension $N_t'\times N_t$ to aid in inverse PCA at the network side. 
The overhead reduction of PCA for angular-delay domain data $OR_{PCA,AD}$ is given as
\begin{equation} \label{eq:3}
    {OR_{PCA,AD} = \frac{(LN_t) - (L+N_t)N_t'}{LN_t}}
\end{equation}

It can be observed from Eq.~\eqref{eq:3} that the compression ratio is scaled with the number of principal components $N_t'$ chosen for a given $L$ and $N_t$. 

At the network side, the inverse PCA, performed using the two received matrices is given by
\begin{equation} \label{eq:4}
    \mathbf{\hat{H}}_{PCA,AD}  = \mathbf{\Tilde{H}}_{PCA,AD} \big(\mathbf{\Tilde{H}}_{N_t'}\big)^H + Q_L,
\end{equation}
where $\mathbf{\Tilde{H}}_{PCA,AD}$ and $\mathbf{\Tilde{H}}_{N_t'}$ are the received PCA-based compressed channel and received PCA transformation matrices respectively and $Q_L$ is the loss incurred due to quantization.

$\mathbf{\hat{H}_{PCA,AD}} $ is the reconstructed angular-delay channel at base station.
The reconstructed spatial-frequency domain channel can be obtained by performing inverse operations to the transformations given in Eq.~\eqref{angle_delay_eq} as 

\begin{equation} \label{eq:5}
    %\mathbf{\hat{H}_{f}} = F_L \hat{H}_{PCA,AD}.
    \mathbf{\hat{H}_{f}} = \mathbf{F_d}^H \mathbf{\hat{H}_{PCA,AD} } \mathbf{F_a}
\end{equation}
%$\hat{H}_f$ is again reshaped to its original dimension $NN_t\times 1$. 

We use an approximated version of Generalized Cosine Similarity (GCS) as a metric to evaluate the closeness of reconstructed channel matrix $\mathbf{\hat{H}_{f}}$ and the true channel $\mathbf{H_{f}}$. The approximated GCS is given by,
\begin{equation} \label{eq:6}
    {\text{GCS} = \bigrho_{AD} = \frac{ | \mathbf{\hat{H}_f}^{H} \mathbf{H_f}|}{\lVert\mathbf{\hat{H}_f}\rVert_2 \lVert \mathbf{{H}_f}\rVert_2}}.
\end{equation}

\subsection{Eigenvector (EV) Data}
For the eigenvector representation of the channel, we divide the total bandwidth ($N$ sub-carriers) into $N_{SB}$ sub-bands. In this paper we assume that a sub-band consists of $4$ resource blocks. The sub-band channel matrix $\mathbf{H}_k$ is the average of channel matrices of all Resource Elements (REs) of $k_{th}$ sub-band. The eigenvector data is generated by computing the Eigen Value Decomposition (EVD) of $ \mathbf{H}_k^H \mathbf{H}_k$. Concatenating the eigenvectors of each sub-band as given below we obtain
\begin{equation} \label{eq:7}
     \mathbf{H}_{EV} = [\mathbf{E}_1,\mathbf{E}_2,\hdots,\mathbf{E}_{N_{SB}} ],
\end{equation}
where, $\mathbf{E}_k$ ($k=1,2\hdots N_{SB}$), is an $N_t\times R$ matrix. 
Note that $N_t$ is number of transmitter antenna ports, $R$ is the rank of sub-band channel $\mathbf{H}_k$. Assuming $N_{rx} = 1$, the rank $R$ is $1$. Therefore the dimension of $\mathbf{H}_{EV}$ is $N_t \times N_{SB}$.
 
For $\mathbf{H}_{EV}$ as given by Eq.~\eqref{eq:7}, we perform PCA on the sub-band dimension $N_{SB}$. 
The idea is to select unique eigenvectors across all the sub-bands.
Similar to the angular-delay domain data, the reconstruction of eigenvector data at the base station is performed by making use of the $N_{SB}\times N_{SB}'$ PCA transformation matrix $\mathbf{\Tilde{H}}_{N_{SB}'}$, transmitted along with the PCA compressed eigenvector data $\mathbf{\Tilde{H}}_{PCA,EV}$ as feedback from the user. Here $N_{SB}'$ is the number of significant principal components.
The reconstructed eigenvector data $\hat{\mathbf{H}}_{EV}$ at the base station is given by 
\begin{equation} \label{eq:9}
    {\mathbf{\hat{H}}}_{EV} = \mathbf{\tilde{H}}_{PCA,EV} \big(\mathbf{\tilde{H}}_{N_{SB}'}\big)^H + Q_L,
\end{equation}
where $\mathbf{\tilde{H}}_{PCA,EV}$ and $\mathbf{\tilde{H}}_{N_{SB}'}^{bs}$ are received PCA-based compressed channel and received PCA transformation matrices respectively and $Q_L$ is the quantization loss.

Thus the overhead reduction for the eigenvector data $OR_{PCA,EV}$ is given as 
\begin{equation} \label{eq:CR_EV_PCA}
    {OR_{PCA,EV} = \frac{(N_{SB} N_t) - (N_{SB}+N_t)N_{SB}'}{N_{SB}N_t}}.
\end{equation}
where, $N_{SB}'$ is the number of principle components in the sub-band dimension. The closeness of the true channel and the reconstructed channel is computed using an approximated cosine similarity as given by,
\begin{equation} \label{eq:6}
    {\text{GCS} = \bigrho_{EV} = \frac{ |\mathbf{\hat{H}}_{EV}^H \mathbf{H}_{EV} |}{\lVert\mathbf{\hat{H}}_{EV}\rVert_2 \lVert \mathbf{ {H}}_{EV}\rVert_2}}.
\end{equation}

For both angular-delay domain and eigenvector representation of the channel, the PCA based CSI compression requires us to choose the right number of principal components $N_t'$ and $N_{SB}'$ respectively. 
The following section, describes the prominent neural networks used for CSI compression with which we make a comparison with our PCA based compression method.

\subsection{Feedback bits required}
This sub-section explores the total number of feedback bits needed to perform PCA based CSI compression. We define the total feedback bits $B_T$ needed, for sending PCA based CSI feedback for both angular-delay and eigenvector data as follows,

\begin{align*}\label{eq:13}
    B_T &= B_C + B_R \left(\frac{\tau_{p}}{\tau_r} \right),\\
    &= \left( LN_t' + N_t'N_t \left(\frac{\tau_{p}}{\tau_r}\right)\right)\left(2Q\right) \text{ - for AD data}\\
    &= \left( N_t N_{SB}' +N_{SB}' N_{SB} \left( \frac{\tau_{p}}{\tau_r} \right)\right)\left(2Q\right)\text{ - for EV data}
\end{align*}
where, $B_C$ represents the compressed bits, $B_R$ represents the bits needed to perform reconstruction of the channel at the network side, $\tau_p$ represents the CSI reporting periodicity, $\tau_r = k\tau_p$, for $k=1,2,3\hdots,$ represents the periodicity at which reconstruction bits $B_R$ are fed-back to the network from UE, $Q$ represents the quantization bits and factor $2$ indicates the real and imaginary split of the complex numbers.

\section{AI/ML for CSI compression}\label{sec: ai_ml}
 We study two architectures: CSINet~\cite{wen2018deeplearningmassivemimo} and EVCSINet~\cite{9538824} which work on angular-delay domain data and eigenvector data respectively. 

\subsection{CSINet}
For the CSINet model we use the same architecture described in~\cite{wen2018deeplearningmassivemimo}. The encoder has a series of convolutional layers for feature extraction followed by a dense layer for feature compression. The decoder has a dense layer to decompress the features followed by a ResNet \cite{resnet_arch} like architecture to generate the reconstructed channel from the features.  

\subsection{EVCSINet}
For the EVCSINet model we use the same architecture described in~\cite{9538824}. The encoder is based on fully connected layers to learn a lower dimensional representation of the eigenvectors. The decoder is a ResNet \cite{resnet_arch} like architecture for the reconstruction of the eigenvectors. We note that while the decoder architecture in~\cite{9538824} contains 27 convolutional blocks, in this paper we use a lighter version with only 15 convolutional blocks. 

\subsection{Data Generation}
For simulation purposes we use two types of data. The first is from publicly available datasets of channel scenarios like CDLA-30 and CDLA-300~\cite{Oppo}. Additionally we also use our own channel data of the Urban Macro (UMa) scenario. Our datasets are generated using QuaDRiGa~\cite{Quadriga}, a MATLAB based software tool for developing 3GPP compliant channels. 
\renewcommand{\arraystretch}{1.1}
\begin{table}
\caption{Simulation parameters for generation of a private data using Quadriga.}
\centering
\begin{tabular}{ |l||c|  }
 \hline
 %\multicolumn{2}{|c|}\hline
\textbf{Parameter}  & \textbf{Value} \\\hline
  Scenario  & Urban Macro (UMa) \\
  Center Frequency & $2$ GHz \\
  Bandwidth & $10$ MHz \\
    Sub-carrier spacing (SCS) & $15$ KHz \\
    Number of Physical Resource Blocks & $52$ \\
    Number of Resource Elements ($N$) & $624$ \\
    Number of sub-bands ($N_{SB}$) & $13$ \\
    Number of Transmit Antennas at BS ($N_{tx}$) & $16$ \\
    Number of CSI-RS ports ($N_t$) & $32$ \\
    Number of Receiver Elements at UE ($N_{rx}$) & $1$ \\
    Antenna panel dimensions of BS & $2 \times 8 \times 2 \times 1 \times 1$ \\
    Antenna panel dimensions of UE & $1 \times 1 \times 1 \times 1 \times 1$         \\
    Cell radius & $100$ m \\
    Number of sectors  & $3$ \\ \hline
\end{tabular}
\label{tab:simulation parameters}
\end{table}

The data generation for our UMa data is based on the simulation parameters defined in Table~\ref{tab:simulation parameters}. Using Quadriga, we place users uniformly across a $100$m, 3-sector site. Quadriga generates the Channel Impulse Response (CIR) between each UE and the base station located at the center of the site. By applying a DFT to the CIR, the Channel Frequency Response (CFR) is derived, capturing the effects of multipath delays in the channel. This CFR data is then used to generate two distinct types of wireless channel data.

\subsubsection{Angular-Delay domain data}
To generate the angular-delay data, we multiply the CFR (Eq.~\eqref{freq_spatial}) with DFT matrices as indicated in Eq.~\eqref{angle_delay_eq}. We then consider only the first $L$ significant rows to obtain $\mathbf{H_{t_L}}$ indicating that the channel has $L$ significant paths. The values of $L$ are given in Table~\ref{table:L_NSB_Channels}. The CSINet model input is derived from $\mathbf{H_{t_L}}$ with the real and imaginary parts split such that model input is of size $L\times N_t\times 2$.  

\subsubsection{Eigenvector data}
The first step in generating eigenvector data is performing sub-band level averaging of the CFR in each of the $N_{SB}$ sub-bands. This involves grouping the channels of each resource element within each sub-band and averaging them. The average channel in each sub-band is then decomposed using EVD, as shown in Eq.~\eqref{eq:7}. Then the selection of top eigenvectors is based on the rank of the channel matrix, which is determined by the minimum of $N_t$ and $N_{rx}$. In our case, since $N_{rx}=1$, we choose the top eigenvector in each sub-band. For input to EVCSINet, the eigenvectors across all sub-bands are concatenated followed by a split of the real and imaginary parts. The split is such that all the real values of eigenvectors of all sub-bands appear together followed by all the imaginary parts.

\renewcommand{\arraystretch}{1.3}
\begin{table}
\caption{Choice of $L$ and $N_{SB}$ for various channels for Angular-Delay and Eigen Vector data respectively}
\centering
\begin{tabular}{ |c||c||c| }
 \hline
 %\multicolumn{2}{|c|}\hline
\textbf{Channel} & \textbf{Angular-Delay data} & \textbf{Eigen Vector data} \\
 & \textbf{\# Taps ($L$)} & \textbf{\# Sub-Bands ($N_{SB}$)}\\ \hline
CDLA-30 & 5 & 12 \\
CDLA-300 & 25 & 12\\
Own Data & 25 & 13\\\hline

\end{tabular}\label{table:L_NSB_Channels}
\end{table}

% \subsection{Decoder training data generation}
% We perform PCA on each data point and choose only the components that are more significant, i.e., the sum of explained variance of the selected components should be greater than $95\%$. The input dimension of the decoder is data.


\section{Performance comparison and Results} \label{sec:V}
% \subsection{Angular-delay domain data}
% \subsection{Eigen Vector data}
We compare the compression accuracy of PCA based CSI feedback with the well-known CSINet and EVCSINet architectures. 
In this work, we consider three different datasets to evaluate the effectiveness of CSI compression with PCA-based method and AI/ML methods mentioned above. We use two publicly available datasets along with one of our own generated dataset as discussed in Section \ref{sec: ai_ml}. 

\subsection{CSI compression : PCA vs AI/ML}
For the angular-delay domain data of dimension $L\times N_t$, we perform PCA on the transmit antenna ports (CSI-RS ports) dimension $N_t$ to determine the principal components with significant variance. Similarly for eigenvector data we perform PCA on the sub-band dimension of the channel.
% The idea is to select only the unique time-domain channel across the antennas and leave out the redundant or less significant channels.
For the different data sets considered, i,e., CDLA-30, CDLA-300, and (our) UMa, it is interesting to note that $99\%$ of the channel instances require only $2$ principal components for angular-delay data and $3$ principal components for eigenvector data to capture most of the variance (as illustrated in Figure~\ref{fig:accuracy_loss_vs_epoch}).
% to capture $95\%$ of the data variance.

\begin{figure}[h!]
    \captionsetup{justification=centering}
     \centering
     \begin{subfigure}[b]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/AD_pc_var.png}
         \caption{}
         \label{fig:accuracy_vs_epoch}
     \end{subfigure}
     \\
     \begin{subfigure}[b]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/EV_pc_var.png}
         \caption{}
         \label{fig:loss_vs_epoch}
     \end{subfigure}
        \caption{Percentage of variance captured by each principal component for CDLA300 channel represented as (a) Angle Delay Domain data and (b) Eignevector data}
        \label{fig:accuracy_loss_vs_epoch}
\end{figure}




\renewcommand{\arraystretch}{1.7}
\begin{table*}
\caption{Results comparing AI/ML CSINet with PCA}
\centering
\begin{tabular}{|*{20}{c|}}
\hline
% \multicolumn{9}{|c}{k-means clustering} & \multicolumn{9}{|c|}{Fuzzy c-means clustering} \\ \hline

\multicolumn{2}{|c|}{\textbf{Model/Dataset}}  & \multicolumn{1}{|c}{\textbf{Train : CDLA-30}} & \multicolumn{1}{|c}{\textbf{Train : CDLA-300}} & \multicolumn{1}{|c|}{\textbf{Train : Own data}} \\ \hline

 \textbf{Model} & \textbf{Parameter} & \textbf{Test : CDLA-30} & \textbf{Test : CDLA-300} & \textbf{Test : Own data}  \\ \hline
CSINet  & Cosine Similarity & 0.9973 & 0.9707 &  0.9322 \\ 

& Overhead Reduction (\%) - $OR_{CSINet}$&  77&  93&  93\\
\hline
PCA with $N_t'=1 $& Cosine Similarity & 0.8943 & 0.9384 &  0.8492  \\ 

& Overhead Reduction (\%) - $OR_{PCA,AD}$ &  77&  93&  93\\ 
\hline

%& Complexity &  &  &   \\ \hline

% CSINet  & Cosine Similarity & 0.9973 & 0.9707 &  0.9322 \\ 

% & Compression Ratio (\%) &  23&  7&  7\\ \hline

%& Complexity &  &  &   \\ \hline

PCA with $N_t'=2$ & Cosine Similarity & 0.8944 & 0.9796 & 0.9404  \\ 

& Overhead Reduction (\%) - $OR_{PCA,AD}$ &  54&  86&  86\\ 
\hline
%& Complexity &  &  &  \\ \hline

% CSINet  & Cosine Similarity & 0.9989 & 0.9885 &  0.9280 \\ 

% & Compression Ratio  (\%) &  46&  14&  14\\ \hline

%& Complexity &  &  &  \\ \hline

PCA with $N_t'=3$& Cosine Similarity & 0.8944 & 0.9798 & 0.9687 \\ 

& Overhead Reduction (\%) - $OR_{PCA,AD}$ &  31&  79&  79\\
\hline
%& Complexity&  &  &  \\ \hline

% CSINet  & Cosine Similarity & 0.9993 & 0.9958 & 0.9647\\ 

% & Compression Ratio  (\%) &  69&  21&  21\\ \hline


%& Complexity &  &  & \\ \hline

\end{tabular}\label{table:CSINet_vs_PCA}
\end{table*}

\renewcommand{\arraystretch}{1.7}
\begin{table*}
\caption{Results comparing AI/ML EVCSINet with PCA}
\centering
\begin{tabular}{|*{20}{c|}}
\hline
% \multicolumn{9}{|c}{k-means clustering} & \multicolumn{9}{|c|}{Fuzzy c-means clustering} \\ \hline

\multicolumn{2}{|c|}{\textbf{Model/Dataset}}  & \multicolumn{1}{|c}{\textbf{Train : CDLA-30}} & \multicolumn{1}{|c}{\textbf{Train : CDLA-300}} & \multicolumn{1}{|c|}{\textbf{Train : Own data}} \\ \hline

 \textbf{Model} & \textbf{Parameter} & \textbf{Test : CDLA-30} & \textbf{Test : CDLA-300} & \textbf{Test : Own data}  \\ \hline

EVCSINet  & Cosine Similarity & 0.9865 & 0.9859 &  0.9172 \\ 

& Overhead Reduction (\%) - $OR_{EVCSINet}$ &  89&  89&  89\\ 
\hline
PCA with $N_{SB}'=1 $& Cosine Similarity & 0.9539 & 0.9526 & 0.8508   \\ 

&  Overhead Reduction (\%) - $OR_{PCA,EV}$ &  89&  89&  89\\ 
\hline
%& Complexity &  &  &   \\ \hline


%& Complexity &  &  &   \\ \hline

PCA with $N_{SB}'=2$ & Cosine Similarity & 0.9727 & 0.9716 &  0.9327 \\ 

& Overhead Reduction (\%) - $OR_{PCA,EV}$ &  77&  77&  78\\ 
\hline
%& Complexity &  &  &  \\ \hline

% EVCSINet  & Cosine Similarity & 0.9888 & 0.9866 &  0.9534 \\ 

% & Compression Ratio (\%) &  23&  23&  22\\ \hline

%& Complexity &  &  &  \\ \hline

PCA with $N_{SB}'=3$& Cosine Similarity & 0.9730 & 0.9719 & 0.9539 \\ 

& Overhead Reduction (\%) - $OR_{PCA,EV}$ &  65&  65&  67\\ 
\hline
%& Complexity&  &  &  \\ \hline

% EVCSINet  & Cosine Similarity & 0.9888 & 0.9889 & 0.9528\\ 

% & Compression Ratio(\%) &  35&  35&  33\\ \hline


%& Complexity &  &  & \\ \hline

\end{tabular}\label{table:EVCSINet_vs_PCA}
\end{table*}

  
%We compared the performance of PCA-based CSI compression with AI/ML model-based CSI compression. 

Our evaluations show that for the angular-delay domain data, the choice of number of channel taps is crucial for PCA to achieve comparable compression performance compared to CSINet. With sufficient number of channel taps (as indicated in Table \ref{table:L_NSB_Channels}), PCA is able to achieve similar CSI compression performance to that of CSINet, as given in the last two columns of Table \ref{table:CSINet_vs_PCA}.
With eigenvector data, for CDLA-30 and CDLA-300 datasets, PCA with $N_{SB}'=1$ principal components is able to achieve almost similar CSI compression metrics to that of EVCSINet with same overhead reduction as shown in  Table \ref{table:EVCSINet_vs_PCA}. In the case of UMa, PCA with $N_{SB}'=2$ offers comparable results with EVCSINet with a slight increase in overhead.

% CSINet architecture is trained with processed channel data of the sub-bands. The raw channel data of all the sub-bands is converted into delay-domain data and only significant delays are considered for model training. The results in Table \ref{table:CSINet_vs_PCA} show comparison of PCA with CSINet for different data sets and different values of principal components. EVCSINet architecture is trained with Eigen vector data of the sub-bands. The results in Table \ref{table:EVCSINet_vs_PCA} show comparison of PCA with EVCSINet for different data sets and different values of principal components.

% \begin{enumerate}
    % \item \textit{Generalization} :
    \subsection{Generalisation and Vendor Inter-operability} It is a known fact that one of the major drawbacks of AI/ML models is the lack of generalization. In some cases where training is done using data from a specific channel scenario and inference is performed on data from another channel scenario, the model finds it difficult to generalize and the performance drops significantly. For example, our experiments show that with angle-delay domain data, the CSINet model trained on CDLA300 channels and tested on UMa Channels shows a cosine similarity of only $55\%$. This is in contrast to the $99\%$ when model is tested on the same scenario as that of the training.  Such generalization issues lead to developing a large number of AI/ML models to cater different cells and scenarios. 
    
    Another drawback for AI/ML models is the issue of inter vendor compatibility.
    There are multiple UE and base station vendors, each of which could develop proprietary models for CSI compression. 
    With PCA-based CSI feedback, the compressed channel and the transformation matrix required for reconstruction are transmitted in every CSI report instance.
    This way, there is no fixed compression matrix at the UE and no fixed reconstruction matrix at the base station. This eliminates the need for vendor inter-operability.
    Since the compression matrix and reconstruction matrix are computed for each instance of CSI report, there is no need for generalization across multiple cells and scenarios. 
    Thus, with the PCA-based approach, we don't encounter the issues of generalization and inter-operability.

    %\subsection{Specification Enhancements}
%     \item \textit{Computational Complexity}: The complexity of a neural network is pretty high, while PCA method has lesser complexity. In 3GPP based codebook TypeI the precoding matrix is given by,
% \begin{equation} \label{eq:9}
%     {W = W_1 W_2}.
% \end{equation}
% where $W_1$ describes the wide-band characteristics associated with two polarizations of the channel and $W_2$ represents the side-band characteristics such as co-phasing and beam selection indicators of the channel. The overall complexity of code-book TypeI is \textcolor{red}{$\mathcal{O}(4N_1N_2BN_3)$, where $N_1$ and $N_2$ indicates the horizontal and vertical dimensions of the antenna array, $B$ is the number of beams chosen from $N_1N_2$ beams and $N_3$ is the number of sub-band for the channel}. Similarly, eTypeII code-book can be represented as
% \begin{equation} \label{eq:10}
%     {W = W_1 \Tilde{W_2} W_f^H}.
% \end{equation}
% where, $W_1$ is similar to that of codebook TypeI. $W_2$ and $W_f$ are the linear combination coefficient matrix and compressed DFT matrix in frequency domain. The complexity of this code-book is \textcolor{red}{$\mathcal{O}(4N_1N_2BM_vN_3)$, where $M_v$ represents the }
% \end{enumerate}
 



% \renewcommand{\arraystretch}{2}
% \begin{table*}
% \caption{Results comparing AI/ML CSINet with PCA}
% \centering
% \begin{tabular}{|*{20}{c|}}
% \hline
% % \multicolumn{9}{|c}{k-means clustering} & \multicolumn{9}{|c|}{Fuzzy c-means clustering} \\ \hline
% \multicolumn{2}{|c|}{\textbf{Dataset / Model}}  & \multicolumn{3}{|c}{\textbf{PCA with $N_t'=1$}} & \multicolumn{3}{|c}{\textbf{CSINet}} & 
% \multicolumn{3}{|c}{\textbf{PCA with $N_t'=2$}} & \multicolumn{3}{|c|}{\textbf{CSINet}} \\ \hline

%  \textbf{Training} & \textbf{Inference} & \textbf{CS} & \textbf{CR} & \textbf{Complexity} & \textbf{CS} & \textbf{CR} & \textbf{Complexity} & \textbf{CS} & \textbf{CR} & \textbf{Complexity} & \textbf{CS} & \textbf{CR} & \textbf{Complexity}\\ \hline

% CDLA-30& CDLA-30 &  &  &  &  &  &  &  &  &  &  &  &    \\ 

% & CDLA-300 &  &  &  &  &  &  &  &  &  &  &  &    \\ 

% & Our Data &  &  &  &  &  &  &  &  &  &  &  &    \\ \hline

% CDLA-300& CDLA-30 &  &  &  &  &  &  &  &  &  &  &  &   \\ 

% & CDLA-300 &  &  &  &  &  &  &  &  &  &  &  &     \\ 

% & Our Data &  &  &  &  &  &  &  &  &  &  &  &  \\ \hline

% Our Data& CDLA-30 &  &  &  &  &  &  &  &  &  &  &  &    \\ 

% & CDLA-300 &  &  &  &  &  &  &  &  &  &  &  &    \\ 

% & Our Data &  &  &  &  &  &  &  &  &  &  &  &     \\ \hline

% \end{tabular}
% \end{table*}

% \begin{table*}
% \caption{Results comparing AI/ML EVCSINet with PCA}
% \centering
% \begin{tabular}{|*{20}{c|}}
% \hline
% % \multicolumn{9}{|c}{k-means clustering} & \multicolumn{9}{|c|}{Fuzzy c-means clustering} \\ \hline
% \multicolumn{2}{|c|}{Dataset / Model}  & \multicolumn{3}{|c}{PCA with $N_t'=1$} & \multicolumn{3}{|c}{EVCSINet} & 
% \multicolumn{3}{|c}{PCA with $N_t'=2$} & \multicolumn{3}{|c|}{EVCSINet} \\ \hline

%  Training & Inference & CS & CR & Complexity & CS & CR & Complexity & CS & CR & Complexity & CS & CR & Complexity\\ \hline

% CDLA-30& CDLA-30 &  &  &  &  &  &  &  &  &  &  &  &    \\ 

% & CDLA-300 &  &  &  &  &  &  &  &  &  &  &  &    \\

% & Our Data &  &  &  &  &  &  &  &  &  &  &  &    \\ \hline

% CDLA-300& CDLA-30 &  &  &  &  &  &  &  &  &  &  &  &   \\ 

% & CDLA-300 &  &  &  &  &  &  &  &  &  &  &  &     \\ 

% & Our Data &  &  &  &  &  &  &  &  &  &  &  &  \\ \hline

% Our Data& CDLA-30 &  &  &  &  &  &  &  &  &  &  &  &    \\ 

% & CDLA-300 &  &  &  &  &  &  &  &  &  &  &  &    \\ 

% & Our Data &  &  &  &  &  &  &  &  &  &  &  &     \\ \hline

% \end{tabular}
% \end{table*}



\section{Conclusion and Further Work}\label{sec:VI}
%In this paper, we have explored on what the AI/ML induced CSI compression models learn. 
% use section* for acknowledgment
In this work, we compared the compression efficiency and overhead reduction of deep neural network based CSI feedback and a conventional machine learning approach, PCA. The PCA method is a linear dimensionality reduction method that helps us to find the minimum number of principal components required to represent the maximum variance of the data. We considered two different representations of the wireless channel i.e., $1)$ Angular-Delay domain representation $2)$ Eigenvector representation. 
%We compared the performance of PCA-based CSI compression with AI/ML model-based CSI compression. 
The deep neural network model architectures considered are CSINet and EVCSINet and these models are trained with angular-delay domain channel data and eigenvector channel data respectively.

% Our evaluations show that for the angular-delay domain data, number of channel taps is crucial for PCA to achieve comparable compression performance compared to CSINet. With sufficient number of channel taps (25 taps for CDLA-300 dataset and our data), PCA is able to achieve similar CSI compression performance to that of CSINet.
% With eigenvector data, for $3$ different data sets (public and private), PCA with 2 principal components is able to achieve almost same CSI compression metrics to that of EVCSINet with slight increase in overhead. 
Based on our results, PCA based CSI compression achieves almost similar CSI compression metrics as compared to neural networks. Additionally PCA based CSI compression doesn't suffer from issues like generalisation and vendor inter-operability.
Thus, we suggest that PCA based CSI compression can also be considered as a choice for CSI compression. 
% Further, the PCA-based CSI feedback would need minimum or no additional specification impact compared to high specification impact necessary for the AI/ML model based CSI feedback. Moreover the PCA-based CSI feedback doesn't have challenges like inter vendor compatibility that requires AI/ML model/data transfer over the air (mostly on downlink) which reduces the downlink throughput.
We would like to further investigate the PCA-based approach with all 3GPP channel models and scenarios to verify if the observations drawn here hold true. Additionally we would like to employ non-linear dimensionality reduction techniques such as manifold learning to compress CSI feedback and thus reduce CSI-related overhead on the uplink.
%Further, the evaluation results suggest that, for PCA based CSI compression, the angle-delay channel representation is preferred for large number of antennas and eigenvector channel representation is preferred for large bandwidths.




 \section*{Acknowledgment}
This work was funded by MEiTY, Government of India, through the project, Next Generation Wireless Research and Standardization on 5G and Beyond, by the Department of Telecommunications (DoT), Government of India, through the 5G testbed project, and by ANSYS Software Pvt. Ltd. through their Doctoral Fellowship award program. 

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{bibfile}





% that's all folks
\end{document}


