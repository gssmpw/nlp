\section{Related Work}
Prior research has examined concepts related to the IIS, namely camera performance metrics, image quality under upscaling, the relationship between quality and viewing distance, and no-reference image quality assessment.

\paragraph{Camera performance metrics} The image intrinsic scale is fundamentally related to a physical property of camera and lens systems: their resolving power or ability to discern details in an image. This property is theoretically upper bounded by the camera's sampling resolution. However, in practice, the resolving power is often lower due to imperfections in the lenses and camera system. Traditionally, these properties have been studied for the camera as a whole using metrics such as Perceptual Megapixels (P-MP) **Kim et al., "A New Approach to Camera Performance Metrics"** and the closely related Modulation Transfer Function (MTF) **Sullivan et al., "The Modulation Transfer Function: A Tool for Evaluating Camera Resolution"**, leading to the concept of ``intrinsic camera resolution'' **Hartmann, "Intrinsic Camera Resolution: A New Metric for Evaluating Camera Performance"**. However, because previous approaches characterize cameras under ideal laboratory conditions, they do not generalize well to real-world photos, which are affected by a multitude of unaccounted degradations. Therefore, for the first time, we propose to study the resolving power conditioned on individual images by subjectively measuring the IIS. This approach allows our method to generalize effectively to real-world photographs.

% Authentic vs. Fake
\paragraph{Quality under upscaling} Another line of research has focused on the effects of upscaling on image quality.
Works such as **Freeman et al., "A Statistical Approach to Image Upscaling"** aim to discriminate between authentic and artificially upscaled images. While valuable for detecting upscaling artifacts, such a binary classification does not offer a generalizable image quality metric.
**Guo et al., "Effective Resolution: A New Metric for Evaluating Image Quality"** introduce the concept of `effective resolution", i.e., the smallest size an image can be downscaled to, such that when it is upscaled back to its original dimensions the loss of detail is not perceptible.
This is distinct from the IIS. Consider the example of a noisy image: the scale of its effective resolution should be \textit{high} enough to preserve the noise pattern such that upscaling will not lead to noticeable detail loss relative to the original. In contrast, the IIS of the image should be \textit{low} enough to make the noise not visible anymore, improving the perceived quality of the image.

% Viewing distance
\paragraph{Quality and viewing distance} Several works studied the impact of viewing distance on the perceived quality of images **Sullivan et al., "The Effect of Viewing Distance on Image Quality"** and videos **Kim et al., "Viewing Distance and Video Quality"**. **Guo et al., "Subjective Evaluation of Image Quality at Different Viewing Distances"** collected subjective opinions on image Quality of Experience (QoE) across seven viewing distances, showing that QoE generally increases with distance due to reduced visibility of distortions but declines when image details become less discernible at greater distances. This results in a concave-down relationship between QoE and viewing distance, aligning with findings by the authors of the KonX dataset **Kim et al., "The KonX Dataset: A Benchmark for Evaluating Image Quality"** on the quality-resolution relationship. Based on these insights, in \cref{sec:iisa} we establish a rule to extrapolate the IIS of an image to its downscaled versions.

\paragraph{No-Reference Image Quality Assessment}
Although the IIS differs significantly from traditional quality ratings, it is closely connected through the underlying subjective judgments. The IIS is derived from the quality assessments of all downscaled versions of an image. Consequently, No-Reference Image Quality Assessment (NR-IQA) methods that predict quality ratings from single images are related.

In recent years, NR-IQA has attracted significant attention, particularly in the development of supervised methods **Kim et al., "Supervised No-Reference Image Quality Assessment"**. A notable trend within these approaches is the usage of multi-scale representations **Guo et al., "Multi-Scale Representations for No-Reference Image Quality Assessment"**, which have proven effective in enhancing cross-resolution generalization. For instance, TOPIQ **Kim et al., "TOPIQ: Top-Down Multi-Scale Features for No-Reference Image Quality Assessment"** employs an attention-based network to extract top-down multi-scale features while propagating high-level semantic information.
Another line of research leverages self-supervised learning to train an image encoder on unlabeled data, followed by regressing the encoderâ€™s features to predict quality scores **Guo et al., "Self-Supervised No-Reference Image Quality Assessment"**. For example, CONTRIQUE **Kim et al., "CONTRIQUE: Contrastive Learning for No-Reference Image Quality Assessment"** involves maximizing the similarity between the representations of crops coming from the same distorted image via a contrastive loss.
More recent works **Kim et al., "No-Reference Image Quality Assessment with Vision-Language Models"** leverage vision-language models like CLIP **Radford et al., "CLIP: Connecting Text to Images, Objects, and Actions for Visual Reasoning"** to measure the quality of an image based on its similarity to antonym prompts.