\section{Related Work}
Prior research has examined concepts related to the IIS, namely camera performance metrics, image quality under upscaling, the relationship between quality and viewing distance, and no-reference image quality assessment.

\paragraph{Camera performance metrics} The image intrinsic scale is fundamentally related to a physical property of camera and lens systems: their resolving power or ability to discern details in an image. This property is theoretically upper bounded by the camera's sampling resolution. However, in practice, the resolving power is often lower due to imperfections in the lenses and camera system. Traditionally, these properties have been studied for the camera as a whole using metrics such as Perceptual Megapixels (P-MP) \cite{dxomark2012perceptual} and the closely related Modulation Transfer Function (MTF) \cite{boreman2001}, leading to the concept of ``intrinsic camera resolution'' \cite{burns2015intrinsic}. However, because previous approaches characterize cameras under ideal laboratory conditions, they do not generalize well to real-world photos, which are affected by a multitude of unaccounted degradations. Therefore, for the first time, we propose to study the resolving power conditioned on individual images by subjectively measuring the IIS. This approach allows our method to generalize effectively to real-world photographs.

% Authentic vs. Fake
\paragraph{Quality under upscaling} Another line of research has focused on the effects of upscaling on image quality.
Works such as \cite{shah2021real, zhu2021perceptual} aim to discriminate between authentic and artificially upscaled images. While valuable for detecting upscaling artifacts, such a binary classification does not offer a generalizable image quality metric.
\citet{kansy2023self} introduce the concept of `effective resolution", \ie, the smallest size an image can be downscaled to, such that when it is upscaled back to its original dimensions the loss of detail is not perceptible.
This is distinct from the IIS. Consider the example of a noisy image: the scale of its effective resolution should be \textit{high} enough to preserve the noise pattern such that upscaling will not lead to noticeable detail loss relative to the original. In contrast, the IIS of the image should be \textit{low} enough to make the noise not visible anymore, improving the perceived quality of the image.

% Viewing distance
\paragraph{Quality and viewing distance} Several works studied the impact of viewing distance on the perceived quality of images \cite{liu2014cid, gu2015quality, fang2015evaluation} and videos \cite{hammou2024effect, keller2023influence, kufa2019visual}. \citet{fang2015evaluation} collected subjective opinions on image Quality of Experience (QoE) across seven viewing distances, showing that QoE generally increases with distance due to reduced visibility of distortions but declines when image details become less discernible at greater distances. This results in a concave-down relationship between QoE and viewing distance, aligning with findings by the authors of the KonX dataset \cite{wiedemann2023konx} on the quality-resolution relationship. Based on these insights, in \cref{sec:iisa} we establish a rule to extrapolate the IIS of an image to its downscaled versions.

\paragraph{No-Reference Image Quality Assessment}
Although the IIS differs significantly from traditional quality ratings, it is closely connected through the underlying subjective judgments. The IIS is derived from the quality assessments of all downscaled versions of an image. Consequently, No-Reference Image Quality Assessment (NR-IQA) methods that predict quality ratings from single images are related.

In recent years, NR-IQA has attracted significant attention, particularly in the development of supervised methods \cite{su2020blindly, ke2021musiq, chen2024topiq, golestaneh2022no, wiedemann2023konx}. A notable trend within these approaches is the usage of multi-scale representations \cite{ke2021musiq, wiedemann2023konx, chen2024topiq}, which have proven effective in enhancing cross-resolution generalization. For instance, TOPIQ \cite{chen2024topiq} employs an attention-based network to extract top-down multi-scale features while propagating high-level semantic information.
Another line of research leverages self-supervised learning to train an image encoder on unlabeled data, followed by regressing the encoderâ€™s features to predict quality scores \cite{madhusudana2022image, agnolucci2024arniqa, zhao2023quality, saha2023re}. For example, CONTRIQUE \cite{madhusudana2022image} involves maximizing the similarity between the representations of crops coming from the same distorted image via a contrastive loss.
More recent works \cite{wang2023exploring, agnolucci2024quality, zhang2023blind} leverage vision-language models like CLIP \cite{radford2021learning} to measure the quality of an image based on its similarity to antonym prompts.


%%%%%%%%% Task