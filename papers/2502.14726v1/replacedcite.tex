\section{Related Work}
\label{sec:relwork} 
 
The emergence and advancement of raw audio generation techniques have vastly improved the quality of audio attempting to sound organic/natural to the human ear____.  Deepfake audio aims to impersonate real people to make the differentiation between deepfake and human speech
difficult____.  The potential for dangerous applications of fake audio has created the need for automated demarcation of humans from deepfakes. 

Audio deepfake detection was associated with spoof detection for automatic speaker verification (ASV) systems and spawned challenges such as ASVspoof2015____ and ASVspoof2019____.  However, the term ``audio
deepfake'' evolved to aim to fool humans.  This evolution spurred the
ASVspoof2021 DeepFake____ and Audio Deep Synthesis Detection____  challenges. Current detection methods primarily employ complex Neural Networks____.  These models generally focus on low-level features (e.g., spectrogram, MFCC, and CQCC). 


Recent work has explored the comparison between the abilities for humans to act as deepfake detectors____. While humans do not perform as well as most detection models, Warren et al.____ demonstrate that models do not strictly improve upon human performance, but rather have a difference in the way that they detect, and that both are necessary in the detection process. They demonstrate that humans are more sensitive to false negative decisions (i.e., believing deepfakes are humans), while models are sensitive to false positive decisions (i.e., believing humans are deepfakes). Several of these studies____ show that humans rely on linguistic features like prosody, pace, disfluencies and accents to aid in their decision process. Our work aims to explore the ability for models to detect using the same features as humans.