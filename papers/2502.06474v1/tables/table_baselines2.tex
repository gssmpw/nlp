

\definecolor{myyellow}{rgb}{1,1, 0.6}
\definecolor{myorange}{rgb}{1, 0.8, 0.6}
\definecolor{myred}{rgb}{1, 0.6, 0.6}
\definecolor{mygray}{gray}{0.6} 

\begin{table*}[t]
\centering
\resizebox{\linewidth}{!}{ 
\begin{tabular}{llccccccccc}
        \toprule

             Model & Method & Params & TFLOPS$\downarrow$ & Training Cost$\downarrow$  & POPE$\uparrow$ & MME$\uparrow$ & VQAv2$_{\text{(test)}}$$\uparrow$ & GQA$\uparrow$ & MMMU$\uparrow$ &GenEval$\uparrow$  \\
    	\midrule
             \multirow{4}{*}{Show-o}&
            Full Computation & 1.3B & 30.94 & 32G & \underline{77.94} & \underline{1032} & \textbf{62.39} & \textbf{52.54} & \textbf{27.44} & \textbf{0.64}\\  
            
             & LayerSkip &1.3B  & \textbf{15.65}& \textbf{22G}& 73.69 & 796 & 51.25 & 43.55 &25.67 &  0.37\\ 
             
             & EarlyExit & 1.3B & \textbf{15.65} & \textbf{22G}& 77.47 & 968  &  57.26 & 48.6 & 26.11 & \underline{0.42} \\  
             
             & \method{} & 1.3B & \underline{23.30}& \underline{27G} & \textbf{78.07} & \textbf{1045} & \underline{61.51} &  \underline{51.80} & \underline{27.22}  & \textbf{0.64}\\   
            
        \bottomrule

\end{tabular}
}
\caption{Comparison with Baseline Methods. We evaluate our approach against EarlyExit, LayerSkip, and Full Computation baselines on both Multi-Modal Understanding (MMU) and Text-to-Image (T2I) benchmarks. Additionally, we compare TFLOPs and training memory usage. Our method achieves the best balance between performance and efficiency across all metrics. We color code each cell, highlighting \textbf{the best results} and \underline{the second-best results}.}
\label{tab:table_baselines2}
\end{table*}
