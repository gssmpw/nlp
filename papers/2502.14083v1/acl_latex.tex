\pdfoutput=1
\documentclass[11pt, table, dvipsnames]{article}
\usepackage[]{acl}

\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

\usepackage[inline]{enumitem}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{caption}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{tabularx}
\usepackage{ragged2e}
\usepackage{makecell}
\usepackage{CJKutf8}
\usepackage[main=english,russian]{babel} 
\usepackage{sidecap, caption}
\usepackage{blindtext}
\usepackage[most]{tcolorbox}

\newcommand{\dataset}{\textsc{UniMoral}}

\newcommand{\camerareadytext}[1]{\xspace}

\renewcommand\theadfont{\bfseries}
\newcolumntype{Y}{>{\RaggedRight\arraybackslash}X}

\makeatletter
\newenvironment{myboxtype}
{\begin{tcolorbox}[colback=gray!10, colframe=black!80, breakable, bottomrule=0mm, toprule=0mm, left=5mm, right=5mm]%
 \itshape}
{\end{tcolorbox}}

\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}

\newcommand{\onelong}{\textcolor{ques1}{\textbf{[\rom{1}] \texttt{Action Prediction}}}}
\newcommand{\twolong}{\textcolor{ques2}{\textbf{[\rom{2}] \texttt{Moral Typology Classification}}}}
\newcommand{\threelong}{\textcolor{ques3}{\textbf{[\rom{3}] \texttt{Factor Attribution Analysis}}}}
\newcommand{\fourlong}{\textcolor{ques4}{\textbf{[\rom{4}]\ \texttt{Consequence Generation}}}}

\newcommand{\oneshort}{\textcolor{ques1}{\textbf{\texttt{AP}}}}
\newcommand{\twoshort}{\textcolor{ques2}{\textbf{\texttt{MTC}}}}
\newcommand{\threeshort}{\textcolor{ques3}{\textbf{\texttt{FAA}}}}
\newcommand{\fourshort}{\textcolor{ques4}{\textbf{\texttt{CG}}}}

\definecolor{ques1}{HTML}{A05C7B}
\definecolor{ques2}{HTML}{2A1E5C}
\definecolor{ques3}{HTML}{054A29}
\definecolor{ques4}{HTML}{99621E}

\definecolor{myred}{HTML}{C41E3A}

\title{\textit{Are Rules Meant to be Broken?} Understanding Multilingual Moral Reasoning as a Computational Pipeline with \dataset}

\author{Shivani Kumar \\
  University of Michigan \\
  \texttt{kshivan@umich.edu} \\\And
  David Jurgens \\
  University of Michigan \\
  \texttt{jurgens@umich.edu} \\}

\begin{document}
\maketitle

\begin{abstract}
Moral reasoning is a complex cognitive process shaped by individual experiences and cultural contexts and presents unique challenges for computational analysis. While natural language processing (NLP) offers promising tools for studying this phenomenon, current research lacks cohesion, employing discordant datasets and tasks that examine isolated aspects of moral reasoning. We bridge this gap with \dataset, a unified dataset integrating psychologically grounded and social-media-derived moral dilemmas annotated with labels for action choices, ethical principles, contributing factors, and consequences, alongside annotators’ moral and cultural profiles. Recognizing the cultural relativity of moral reasoning, \dataset\ spans six languages, Arabic, Chinese, English, Hindi, Russian, and Spanish, capturing diverse socio-cultural contexts. We demonstrate \dataset's utility through a benchmark evaluations of three large language models (LLMs) across four tasks: action prediction, moral typology classification, factor attribution analysis, and consequence generation. Key findings reveal that while implicitly embedded moral contexts enhance the moral reasoning capability of LLMs, there remains a critical need for increasingly specialized approaches to further advance moral reasoning in these models.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
Computational reasoning systems excel at processing structured domains like mathematics \cite{imani-etal-2023-mathprompter} and commonsense problem-solving \cite{sap-etal-2020-commonsense} through logical and probabilistic frameworks \cite{10.1145/3664194}. Moral reasoning, however, introduces multidimensional complexity by requiring the integration of emotional intelligence \cite{zangari-etal-2025-me2} and ethical principles such as fairness \cite{schramowski2019bert}, harm mitigation \cite{graham2018moral}, and duty \cite{doi:10.1177/1088868318811759}. Consider the canonical dilemma of discovering a lost wallet (Figure \ref{fig:pipeline}): Human moral cognition synthesizes perceptual inputs \cite{haidt2001emotional}, value-based judgments \cite{greene2007vmpfc}, and post-hoc rationalizations \cite{nabavi2012bandura} into actionable decisions \cite{3a82aa95-7b7a-3947-8618-2a305b9c1d4e}. While this integrated pipeline reflects natural human reasoning \cite{kohlberg1963moral}, existing NLP approaches analyze moral decision-making through fragmented methodologies \cite{hendrycks2021aligning, vida-etal-2023-values}, limiting both holistic understanding and cross-cultural applicability.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{pipeline.pdf}
    \caption{Moral Reasoning pipeline: An individual encounters a moral scenario, they list out the potential actions they can take, and select one. The chosen action yields outcomes affecting stakeholders and societal norms. The ``Moralsphere'' conceptualizes this dynamic interplay between reasoning, action, and societal impact in resolving moral dilemmas.}
    \label{fig:pipeline}
    \vspace{-5mm}
\end{figure}

In this work, we bridge this gap by introducing \dataset, a multilingual dataset designed to capture the phased nature of moral reasoning. Grounded in psychological theories and enriched by real-world social media discourse, \dataset\ provides annotations across the entire moral reasoning process, covering scenario perception, action selection, ethical judgment, justification through contributing factors, and the consequences of the chosen action. Broadly, to construct \dataset, we present crowd-sourced participants with moral scenarios where participants select preferred actions, justify decisions via follow-up questions, and complete post-annotation moral \cite{atari2023morality} and cultural value questionnaires \cite{hofstede1994vsm94}.

Recognizing the cultural relativity of morality \cite{KENNEDY2021104696, yang2024sociallyawarelanguagetechnologies}, \dataset\ encompasses six linguistically distinct contexts, Arabic, Chinese, English, Hindi, Russian, and Spanish, enabling researchers to probe how moral frameworks vary across populations. While \dataset\ supports diverse applications, in this study we focus on four pivotal research questions to analyze how current LLMs handle moral reasoning:
\begin{enumerate*}
    \item[\onelong\ (\oneshort):] How does contextual cues, like cultural orientation and individual's moral values influence computational models' capability for action prediction in \dataset, and to what extent do these predictions generalize across its six languages?
    \item[\twolong\ (\twoshort):] Can computational models classify moral actions in \dataset\ into psychologically grounded categories (e.g., deontological and virtuous) using its hierarchical annotations, and how do these categorizations vary across languages?
    \item[\threelong\ (\threeshort):] To what extent can a model determine the contributing factors dominating a person's moral decision making, and how do these factors interact across languages?
    \item[\fourlong\ (\fourshort):] Are computational models capable of generating coherent consequences of scenario-action pairs in \dataset?
\end{enumerate*}

Although the \oneshort\ and \fourshort\ can be addressed using existing datasets for individual languages, \dataset\ facilitates cross-linguistic comparison and extends its utility to addressing additional inquiries as posed by the \twoshort\ and \threeshort.
Through systematic benchmarking, we demonstrate \dataset’s utility in addressing these questions, revealing nuanced patterns in how cultural narratives and personal values shape moral evaluations. In a nutshell, the contributions of this work can be summarized as:
\begin{enumerate}[topsep=0pt, noitemsep]
    \item We identify the different stages of moral reasoning and present a systematic, holistic, and psychologically-motivated pipeline for structured computational modeling.
    
    \item We present \dataset\footnote{\url{https://huggingface.co/datasets/shivaniku/UniMoral}}, a diverse, multilingual, and holistic dataset of moral dilemmas derived from psychological theories and social media, with rich annotations spanning all phases of moral reasoning (perception, judgment, justification, action, and consequence) and individualized moral and cultural profiles derived from participant responses.
    \item Through four targeted research questions\footnote{\url{https://github.com/shivanik96/UniMoral.git}}, facilitated by \dataset, we analyze current LLMs and examine the influence of cultural narratives and personal ethical values on shaping their moral reasoning.
\end{enumerate}

\section{Morality in NLP}
Ethics, in NLP, has garnered significant traction in recent years, with many contemporary studies investigating the notion of morality in hypothetical texts, such as stories \cite{emelin-etal-2021-moral, guan-etal-2022-corpus}, and social media texts, like Reddit posts \cite{trager2022moral} and tweets \cite{doi:10.1177/1948550619876629}. The tasks coming under the umbrella of ``morality in NLP" generally falls under two categories: quantification and judgment. 

\paragraph{Moral quantification.} This subdomain of tasks typically addresses scenarios where the action of an individual is known, and the computational system is tasked with identifying specific aspects of the action or the individual performing it. For instance, tasks such as moral value identification \cite{teernstra2016morality, mokhberian2020moral, Lan2022, Pavan2023Morality}, moral stance detection \cite{santos-paraboni-2019-moral, roy-goldwasser-2021-analysis, botzer2022analysis}, and moral sentiment classification \cite{Mooijman2018, kobbe-etal-2020-exploring, roy-etal-2021-identifying, Qian2021} fall into this category. The methodologies employed to tackle such tasks frequently involve the use of lexicons \cite{Anderson2006Approach, Garten2016MoralityBT, alfano2018identifying}, machine learning approaches \cite{asprino-etal-2022-uncovering, hsu-etal-2021-corpus}, and, more recently, large language models \cite{alhassan-etal-2022-bad, alshomary-etal-2022-moral}.

\paragraph{Moral judgment.} The tasks in this category involve making judgment about either the action taken by an individual \cite{ammanabrolu-etal-2022-aligning, shen-etal-2022-social, Yamamoto2014Moral}, the consequence of those actions \cite{komuda2013aristotelian, emelin-etal-2021-moral}, or the individuals themselves \cite{hendrycks2020aligning, Lourie2021}. Action judgment tasks are often presented in two formats: choosing the moral action from a set of alternatives \cite{emelin-etal-2021-moral, guan-etal-2022-corpus}, or evaluating whether a completed action was moral \cite{Jin2022WhenTM, hendrycks2020aligning}. However, many existing studies overlook the critical aspect of moral evaluation: assuming only one action is moral and ignoring the decision-maker's context. In \dataset, we focus on this personalization aspect, ensuring that moral reasoning considers both actions and contextual factors.

\paragraph{Morality across languages and cultures.} Contributions, like  Moral Foundations Theory \cite{graham2018moral} and its extensions \cite{Hopp2020} offer lexicons for analyzing moral sentiment but frequently prioritize Western-centric frameworks. Cross-cultural adaptations, such as the Japanese MFD \cite{Matsuo2019}, and multilingual resources like MoralConvIta \cite{Stranisci2021}, alongside studies of cultural variations in moral priorities \cite{atari2023morality} highlight the importance of linguistic and cultural diversity, paving the way for more inclusive approaches.

\paragraph{The moral reasoning pipeline.} Just as a mathematical problem is solved by following a step-by-step approach \cite{imani-etal-2023-mathprompter}, moral reasoning involves sequential steps to arrive at an appropriate action for a scenario. While numerous psychological studies discuss the phases of moral reasoning \cite{kohlberg1963moral, carpendale2009piaget, haidt2001emotional, greene2007vmpfc, nabavi2012bandura}, no work in NLP, to the best of our knowledge, has translated these psychological concepts into a computational format to explore moral reasoning as a systematic sequence.

To this end, we construct a pipeline, as shown in Figure \ref{fig:pipeline}, that captures the various stages of moral reasoning.
According to Rest's four-component model \cite{narvaez1995four} and Haidt's Social Intuitionist Model \cite{haidt2001emotional}, the pipeline begins with scenario assessment. Subsequently, possible actions are contemplated, with each influenced by various factors, akin to the Dual-Process Theory of Moral Judgment \cite{greene2007vmpfc}. After identifying possible actions, a decision is made. Similar to real-life situations, every action has consequences; in moral reasoning, these consequences can be judged as moral or immoral, providing a learning opportunity as outlined in Bandura's social learning theory \cite{nabavi2012bandura}. 

Throughout these stages, we also examine aspects of each phase, such as moral values and sentiments. We refer to this overarching process as the ``Moralsphere" since it spans all phases of moral reasoning.
These processes within the moral pipeline collectively function and interact to enable informed moral decision-making. To support the computational study of this pipeline, we introduce \dataset, which 
provides comprehensive annotations for all the phases of moral reasoning.

\section{Constructing \dataset}
This section outlines the data collection, annotation framework, and analysis of \dataset.

\subsection{Collecting Data for Annotation}
Broadly, the data construction pipeline encompasses the following five steps: 1) generating scenarios rooted in psychological theories, 2) determining the most probable action options within these scenarios, 3) gathering moral dilemmas from Reddit along with their corresponding action options, 4) translating the collected data into target languages for study, and 5) obtaining annotations through crowd-sourcing. We provide an in-depth discussion of each of these steps below.

\label{sec:psychological_scenarios}
\paragraph{Psychologically grounded scenarios and their actions}
Numerous psychology studies have examined human morality by presenting participants with morally charged dilemmas and inquiring about their actions \cite{2375721c-389b-30be-a9c3-521d36fd52b2, rest1979development, Lind2008meani-1361}. These studies curate scenarios to ensure decisions require moral reasoning rather than mere logic. We focus on three prominent theories: the Moral Judgment Interview (MJI) \cite{2375721c-389b-30be-a9c3-521d36fd52b2}, the Defining Issues Test (DIT) \cite{rest1979development}, and the Moral Competence Test (MCT) \cite{Lind2008meani-1361}. Together, these theories provide $18$ psychological scenarios—seven from both MJI and DIT, and four from MCT—designed to trigger moral reasoning. After reviewing them, we identified two as repetitive, resulting in $16$ unique dilemmas or our ``seed scenarios" ($S$). More details on these theories and scenarios are present in Appendix \ref{app:seed_scenarios}.

Additionally, we draw upon established psychological theories that identify the elements affecting human decision-making \cite{graham2013moral, damasio1996somatic, doi:10.1111/j.1467-9248.1971.tb01922.x, hofstede1994vsm94} and summarize nine major contributing factors as $C = $ \{`Emotions', `Moral', `Culture', `Responsibilities', `Relationships', `Legality', `Rules', `Politeness', `Sacred values'\}. To generate new scenarios that emulate the seed scenarios, we use Llama-3.1-70B Instruct \cite{meta_2024}, prompting it to create scenarios similar to $S$ with contributing factors derived from $C$. That is, our new set of scenarios, $S^{p}_e$, is defined as $S^{p}_e = \{f(s,c)\ |\ \forall s \in S, \forall c \in C\}$, resulting in a total of $144$ scenarios ($|S| \times|C|$). For each of these new scenarios, we prompt the language model to generate the two most probable mutually exclusive actions, denoted as $A^p_e = \{(a_1^{s_e},a_2^{s_e})\ |\ \forall s_e \in S^p_e\}$, which we then present to the annotators. More information about what prompts we use and examples of scenario-action pairs generated, see Appendix Section \ref{app:prompts}.

\paragraph{Reddit scenarios and actions.}
To enhance the utility of \dataset, we extend beyond hypothetical scenarios by incorporating real-life examples of moral dilemmas sourced from Reddit. We focus on subreddits that frequently feature moral judgments, namely r/AmItheAsshole, r/moraldilemmas,  r/AITAH, r/TwoHotTakes, and r/AmIOverreacting. Posts made to these subreddits are carefully filtered and rephrased to have standard formatting (see Appendix~\ref{app:reddit} for details). To generate our data, we prompt the Llama3.3-70B to rephrase the described scenario as a moral dilemma and generate two mutually exclusive actions applicable to that scenario. Through this methodology, we extract $\sim400k$ Reddit scenarios. We randomly select $10k$ scenarios from the paraphrased Reddit data and perform topic modeling using LDA \cite{blei2003latent} to identify $200$ topics. To diversify the types of dilemmas in our data, we cluster the scenarios into 200 clusters using $k$-means \cite{hartigan1979algorithm} on the scenarios' topic distributions. We then select the centroid of each cluster as a representative scenario, resulting in a collection of $200$ Reddit-based dilemmas, denoted as $S^r_e$, along with their corresponding actions, $A^r_e$. By combining $S^r_e$ with $S^p_e$, we obtain the final list of moral scenarios $S^m_e = \{S^p_e \cup S^r_e\}$ and, similarly, actions $A^m_e = \{A^p_e \cup A^r_e\}$.

\paragraph{Adding multilingualism.}
In this study, we create moral and cultural profiles of the participants using standardized questionnaires. Specifically, we employ the Moral Foundations Questionnaire 2 (MFQ2) \cite{atari2023morality} and Hofstede's Value Survey Module (VSM 2013) \cite{hofstede1994vsm94} to capture various moral and cultural dimensions (see Apendix Section \ref{app:mfq_vsm_scores} for more details). These questionnaires, originally available in English, contain translations in several other languages as well. From the translations, we select five languages---Arabic, Chinese, English, Russian, and Spanish---for which both, MFQ2 and VSM, have translations, enabling the study of cultural and moral value variations across these languages. Additionally, to incorporate views from South Asia as well, we manually translate these questionnaires into Hindi using the standard method of translation and back-translation \cite{doi:10.1177/135910457000100301}. Consequently, we have the questionnaires available in six languages for our study. Next, we translate the collected scenarios $S^m_e$ and actions $A^m_e$ into these languages using the large version of the Seamlessm4t-v2 model \cite{seamless2023}, giving us $S^m = \{T_{e \mapsto x}(S^m_e)\}$ and $A^m = \{T_{e \mapsto x}(A^m_e)\}$ where $x \in \{A,C,H,R,S\}\}$ where $A, C, H, R, S$ stands for Arabic, Chinese, Hindi, Russian, and Spanish, respectively, and $T$ is the translation function. See Appendix Table \ref{tab:scenario_example} for translation examples. These translations are manually verified to ensure quality for our crowd-sourced collection.

\begin{figure*}[th]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{action_dist_horizontal.pdf}
        \caption{Actions have almost equal distributions across languages.}
        \label{fig:action_dist}
    \end{subfigure}%
    ~
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{ethical_criteria_dotplot.pdf}
        \caption{Ethical preferences in action choices show correlation with annotators' first language, along with global trend.}
        \label{fig:action_type}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=1.4in]{contributing_factor_heatmap.pdf}
        \caption{Moral decisions are influenced by varying factors, such as emotions and legal frameworks, across languages.}
        \label{fig:action_factor}
    \end{subfigure}%
    
    \begin{subfigure}[t]{0.64\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Moral_culture_bar.pdf}
        \caption{Moral and cultural values vary across languages as revealed by MFQ2 and VSM assessments.}
        \label{fig:mfq_vsm}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Combined_tsne.pdf}
        \caption{The TSNE plot reveals moral and cultural (dis)similarities between languages.}
        \label{fig:combined_tsne}
    \end{subfigure}
    \caption{\dataset\ at a glance. [Abbreviations -- PDI: Power Distance, IDV: Individualism, MAS: Masculity, UAI: Uncertainty Avoidance, LTO: Long Term Orientation, IVR: Indulgence vs Restraint]}
    \label{fig:data_dist}
\end{figure*}

\subsection{Crowd-sourced Annotation}
\label{sec:crowd_sourced}
After establishing $S^m$ and $A^m$, we initiate a crowd-sourced data collection process to obtain annotations for each scenario-action pair in our dataset, $\{(s^m_i,(a^{m_i}_1, a^{m_i}_2) | 1\leq i \leq |S^m|\}$. We solicit input from annotators on the following points:
\begin{enumerate}[topsep=0pt, noitemsep, leftmargin=15pt]
    \item Which action would you choose?
    \item Explain your choice and its consequence.
    \item How well does it capture ethical principles?
    \item What factors contributed to your decision?
    \item Which emotion(s) influenced your decision?
    \item What values shaped your decision?
    \item Any alternative action considerable?
    \begin{enumerate}[topsep=0pt, noitemsep, leftmargin=5pt]
        \item[a.] How well does it capture ethical principles?
    \end{enumerate}
\end{enumerate}
% Questions $3$, $4$, $6$ and $7$a utilize a Likert scale format. 
Questions $3$ and $7$a assess the \textit{ethical frameworks} guiding the annotator's chosen action for a scenario (e.g. finding a wallet), categorized as following rules (e.g. handover the wallet to police), doing good for the majority (e.g. donate money to charity), respecting people's rights (e.g. return wallet to owner), and acting with good character (e.g. return the wallet and check for other missing items.). These correspond to the four main ethical frameworks in moral psychology: deontology, utilitarianism, rights-based, and virtue ethics \cite{kohlberg1963moral}. Annotators rate each principle on a scale of $1$ to $5$ based on its relevance to their decision. Question $4$ asks annotators to evaluate the influence of each contributing factor $C$ on their decision-making, also on a scale of $1$ to $5$. If emotion influenced their choice, they specify which from Plutchik primary emotions \cite{plutchikemotion}. After completing their scenario evaluations, annotators fill out the MFQ2 and VSM to capture their moral values and cultural dimensions, respectively. Additionally, we collect demographic details and a free-text self-description (excluding personal information) to serve as their persona.

\paragraph{Study type.} Gathering information for the complete set of eight questions, as specified above, demand considerable time and effort from the annotators. Consequently, each annotator could handle only a limited number of scenario-action pairs. To address this issue, we structure our study in two distinct approaches: extensive and compact. In the extensive annotation, annotators are required to respond to all eight questions associated with a given scenario. In contrast, the compact study involves responding only to the initial question, wherein annotators select their preferred action and proceed to the next scenario. This method allows us to collect more data per moral and cultural questionnaires in a shorter time frame. The extensive data collection contains a set of $144$ psychological scenarios alongside $50$ Reddit-based dilemmas while the compact study consists of another set of $144$ psychological scenarios and the remaining $150$ Reddit dilemmas.

\paragraph{Platform specific information.} We construct our annotation platform using Potato \cite{pei2022potato} and host our crowd-sourced study on Prolific.com, initiating the process with a pilot of $100$ scenarios in English and Chinese to assess the quality and distribution of the collected data. During this phase, we observe minimal to no difference between the `legal' and `rule' contributing factors, leading us to combine them into a single category (`laws') for the final annotation process, giving us $C^{'}$ such that $|C^{'}|=8$. After confirming that the data quality met our standards, we proceed with twelve studies---one extensive and one compact for each of the six languages. In the extensive study, each annotator evaluated seven scenarios, whereas in the compact study, they assessed thirty scenarios. Each scenario was reviewed by three annotators. Ultimately, \dataset\ comprises a total of $582$ instances with extensive annotations and $882$ for the compact version in each language, culminating in a total of $5256$ instances across the entire dataset. Further details on the data collection process, screenshot of the annotation framework, and data statistics, can be found in Appendix Section \ref{app:annotation} and \ref{app:data_stats}.

\subsection{Data Analysis}
As outlined in Section \ref{sec:crowd_sourced}, we collect eight types of labels in the extended annotations to explore key aspects of moral reasoning. These labels include understanding preferred actions, factors influencing moral reasoning, and examining variations across languages and cultures. 
Following, we describe aggregated trends across languages to highlight general variation in preferences.

\paragraph{What kind of actions do people prefer?} We plot the distribution of preferred actions across all languages in our dataset, finding an almost equal split, which indicates variability in preferences (Figure \ref{fig:action_dist}). Analyzing the primary ethical principles reveals global trends and a correlation with the annotators' first language (Figure \ref{fig:action_type}). For example, all language groups rate virtue highly, but Arabic and Hindi speakers also prioritize right-based ethics highly, focusing on social justice. In contrast, Spanish speakers emphasize utilitarianism, valuing collective well-being, while Russian speakers lean more toward deontology, reflecting duty-based ethics. These differences may stem from cultural variations in moral philosophy.

\paragraph{What are the factors affecting moral reasoning?} Moral decisions are often influenced by factors like emotions, culture, legal frameworks and sacred values. Figure \ref{fig:action_factor} shows the impact of these factors across the six languages. While morality is the most significant factor for all languages, sacred values are more influential for Hindi and Arabic speakers or those with high deontological tendencies. Additionally, Spanish speakers value the role of the action taker, while Chinese speakers prioritize politeness. This reflects cultural variations in moral evaluation, with Spanish speakers prioritizing agency in decision-making and Chinese speakers emphasizing social harmony and respect.

\paragraph{Why do different people take different actions?} While speakers of various languages prefer different ethical principles, we explore distinctions based on their moral and cultural values. Figure \ref{fig:mfq_vsm} shows aggregate scores from the MFQ2 and VSM assessments, revealing clear differences: Arabic speakers are more attuned to the `purity' foundation, while Spanish speakers prioritize `equality' more than English speakers. Additionally, English and Russian speakers exhibit higher `individualism,' correlating with stronger deontological tendencies. A TSNE plot, made by combining the moral and cultural information, in Figure \ref{fig:combined_tsne} highlights similarities between English, Spanish, and Chinese speakers, and their differences from Arabic and Hindi speakers, reflecting cultural and linguistic influences. See Appendix Section \ref{app:data_stats} for more details.

\section{Experimental Analysis}
While numerous tasks can be accomplished using \dataset, we focus on four core concepts of moral reasoning: \onelong\ (\oneshort), \twolong\ (\twoshort), \threelong\ (\threeshort), and \fourlong\ (\fourshort).
Considering the proposed pipeline (Figure \ref{fig:pipeline}), our objective is to explore all the phases of moral reasoning and determine how \dataset\ can be used to study these phases. 

\subsection{Experimental Setup}
We use three large language models: Phi-3.5-mini Instruct \cite{abdin2024phi3technicalreporthighly}, Llama-3.1-8B Instruct \cite{meta_2024}, and DeepSeek-R1-Distill Llama-8B \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}, for analyzing the four questions. Additional details, including prompt selection, are provided in Appendix Section \ref{app:prompts}.

\paragraph{\onelong.}
With the growing interest in agent-based modeling \cite{gao2024large}, and synthetic annotations \cite{ivey2024real}, it becomes critical that LLMs are able to mirror behavior of certain groups. Consequently, we test whether an LLM, when provided with information about an individual's values, can replicate their decision-making process. To do this, we focus on three key aspects from our annotation phase: (1) moral values from MFQ2 ($m$), (2) cultural principles from VSM ($c$), and (3) self-descriptions, or persona, providing an alternative way of capturing the person's value framework via lived experience ($p$). Additionally, we test an alternative approach using few-shot learning ($fs$), where past decisions guide the model in predicting future responses.
The four attributes ($m,c,p,fs$) serve as inputs to three different LLMs, which select the most appropriate action $a^*_i$ given a scenario $s^m_i$ and its possible actions $(a^{m_i}_1,a^{m_i}_2)$. The task is framed as: $a^*_i = \text{argmax}_{j \in \{1,2\}}P(a^{m_i}_j|s,x)$, where $x \in \{m,c,p,fs\}$ and $P$ denotes the conditional probability. Weighted F1-score acts as our primary metric to capture class variability.

\paragraph{\twolong.}
As outlined in Section \ref{sec:crowd_sourced}, annotators rated the ethical principles of their chosen actions on a Likert scale. This experiment tests whether an LLM can predict these principles by comparing its predictions to the ground truth, which is based on the highest-rated principle(s). If multiple principles share the highest rating, they are all included. The LLM is prompted to identify the ethical factor influencing the user's choice, and its prediction is deemed correct if it matches any principle in the ground truth set. We consider the four contextual cues of $\{m,c,p,fs\}$, similar to \oneshort\ to evaluate the LLM's performance. In this approach, the few-shot examples are constructed by considering the ethical principle selected by the annotator for another scenario-action pair. Formally, $t^*_i = \text{argmax}_{t \in T}P(t|s^m_i,(a^{m_i}_1,a^{m_i}_2),a^*_i,x)$, where $x \in \{m,c,p,fs\}$. The weighted F1-score is again employed as the metric of choice.

\paragraph{\threelong.} Moral decisions are influenced by factors such as emotions, responsibilities, and legal considerations. To capture these influences, annotators rated $8$ contributing factors ($F$) on a scale of $1$ to $5$, as outlined in Section \ref{sec:crowd_sourced}. This analysis investigates whether an LLM can accurately identify these factors when given contextual information about the annotator ($m, c, p, fs$). The few-shot examples are created using the contributing factors selected by the annotator in another scenario-action pair. The LLM's task is to predict the most significant factor influencing the decision. If the prediction matches the ground truth---determined by selecting the highest-rated contributing factor (similar to \twoshort)---it is considered correct. Formally, this is represented as $f^*_i = \text{argmax}_{f \in F}P(f|s^m_i,(a^{m_i}_1,a^{m_i}_2),a^*_i,x)$, where $x \in \{m,c,p,fs\}$. Because this classification involves $8$ potential classes, the weighted F1-score is chosen as the preferred metric.

\paragraph{\fourlong.} For this task, we evaluate the ability of an LLM to generate the consequence for a selected action, given a moral dilemma. For each language, we compile all consequences provided by annotators for a scenario serves as the ground truth set for that specific scenario-action pair. The LLM is then prompted to generate a consequence for that scenario-action pair. LLM outputs are scored according to the maximum similarity with any ground truth consequence for that scenario. 
Formally, this task can be defined as $c_{i} = G(s^m_i,a^*_i)$, where $G$ represents the generative function of the LLM. To ensure a semantically meaningful comparison, we use multilingual BERTScore \cite{zhang2020bertscore} as our evaluation metric, as it emphasizes semantic similarity rather than exact word matches.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Result1_new2.pdf}
    \caption{Models perform best in English, Spanish, and Russian while struggling for Arabic, Chinese, and Hindi as shown by their language-specific performance. The scores are average weighted F1 scores for \oneshort, \twoshort, and \threeshort, and BERTScore for \fourshort. Dotted line represents random performance for each task.}
    \label{fig:result1}
    \vspace{-3mm}
\end{figure}

\subsection{Experimental Results}
We evaluate the models across three dimensions: \textbf{language-specific performance}, assessing their effectiveness across languages for \oneshort, \twoshort, \threeshort, and \fourshort; \textbf{contextual-cue-specific performance}, examining the impact of cues ($p, m, c, fs$) on \oneshort, \twoshort, and \threeshort; and \textbf{Reddit vs. psychological scenario performance}, comparing model performance on Reddit-derived and hypothetical scenarios. In the following paragraphs we highlight the important results, while the full set of results can be found in Appendix Section \ref{app:results}.

% \subsection{Experimental Result Analysis}
\paragraph{Language-specific performance.}
To evaluate language-specific performance, we compute the average scores across contextual cues \((m,c,p,fs)\) and across models for all tasks. Figure \ref{fig:result1} presents these results, highlighting substantial variability across languages. English consistently ranks among the highest-performing languages, alongside Spanish and Russian, across all four tasks. In contrast, models exhibit significantly lower confidence in Arabic and Hindi. These disparities can be attributed to factors such as the availability of high-quality training data and linguistic complexity. While English and Spanish benefit from extensive resources (especially in terms of moral datasets) and structural similarities, Arabic and Hindi face challenges related to data scarcity, dialectal variation, and complex morphology.

\paragraph{Contextual cue specific performance.} In this section, we examine the impact of different contextual cues \((m,c,p,fs)\) on task performance. Figure \ref{fig:result2} presents the average weighted F1 score, aggregated across languages and models, to illustrate how these cues influence capabilities in \oneshort, \twoshort, and \threeshort. For \oneshort, explicitly providing moral information results in the highest performance, with persona-based inputs following closely. However, the performance is not significantly different from chance. This suggests that while the self-descriptions provided by annotators make effective proxies for moral reasoning, LLMs still struggle to internalize ethical principles, often relying on surface-level patterns rather than genuine moral understanding.
In \twoshort, few-shot examples prove to be the most influential, and the only cue to give statistically better performance from chance, in determining the ethical principle guiding the selected action, followed by moral values and user persona. Similarly, in \threeshort, persona and few-shot examples play a crucial role in helping the model understand individuals and accurately identify the factors influencing their decisions. While \threeshort\ performs worse than \oneshort\ and \twoshort, it remains significantly above chance, likely because identifying responsible factors relies more on surface linguistic patterns than deep moral reasoning. These results highlight moral reasoning as a challenge for LLMs, which future research—enabled by datasets like \dataset—can help address.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Result2_new2.pdf}
    \caption{Contextual-cues like moral values and persona help LLMs make better moral decisions. The scores are average weighted F1 scores. Dotted line represents random performance for each task.}
    \label{fig:result2}
    \vspace{-5mm}
\end{figure}

\paragraph{Reddit vs. psychological scenario performance.}
Are models better able to morally reason about the real-world scenarios from Reddit versus hypothetical psychological scenarios?
No. Across all tasks and languages, models perform consistently better on psychologically grounded scenarios than on Reddit-based dilemmas (Figure \ref{fig:result3}). While the performance difference is modest in \oneshort\ and \fourshort, it becomes more pronounced in \twoshort\ and \threeshort. This disparity likely stems from the structured and controlled nature of psychologically grounded scenarios, which provide explicit cues that help models isolate and interpret ethical principles. In contrast, Reddit-based dilemmas introduce real-world noise, ambiguity, and implicit cultural or situational biases, making moral reasoning more challenging—particularly in tasks like \twoshort\ and \threeshort, which require precise, context-aware judgment.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Result3_new2.pdf}
    \caption{Models perform better on psychologically grounded scenarios than on Reddit-based dilemmas across all tasks and languages. The scores are average weighted F1 scores for \oneshort, \twoshort, and \threeshort, and BERTScore for \fourshort. Dotted line represents random performance for each task.}
    \label{fig:result3}
    \vspace{-5mm}
\end{figure}

\section{Conclusion}
Moral reasoning is a complex process and here we introduce  \dataset\ to unify the multiple strands of NLP research on moral reasoning.  \dataset\ is a holistic multilingual dataset covering the full moral reasoning pipeline---from scenario perception to consequence evaluation---across six linguistically and culturally diverse contexts. It combines psychologically grounded dilemmas with real-world examples from social media, providing annotations on action choices, ethical principles, contributing factors, and consequences, enriched with annotators’ moral and cultural profiles. Our analysis reveals key insights: (1) models exhibit significant performance disparities across languages, (2) explicit contextual cues—such as moral values and persona descriptions—greatly enhance performance, emphasizing the role of contextual awareness in ethical AI, and (3) tasks like moral typology classification and factor attribution remain challenging, exposing gaps in models’ ability to reason about the broader effects of moral actions. While this paper explores four verticals of moral reasoning, \dataset\ enables further studies on cross-cultural moral generalization, bias detection, and moral or cultural value quantification. \camerareadytext{Beyond morality, it can also support general NLP tasks such as cross-lingual transfer learning, multilingual text generation, and sentiment analysis.}

\section{Limitations}
In this work, we introduce the \dataset\ dataset, which includes annotations capturing action preferences, ethical justifications, and decision factors alongside individual moral and cultural profiles. While \dataset\ has significant potential for both morality-related and general NLP tasks, this study serves as an initial exploration. Rather than attempting an exhaustive analysis of all possible applications, we focus on four exploratory tasks and evaluate existing systems on these tasks without fine-tuning.
The scope of \dataset\ is influenced by the availability of the MFQ2 and the VSM across different languages. Since these questionnaires have only been translated into a limited number of languages, and due to our team's restricted proficiency in certain languages, we conducted annotations in six languages only. Future research can expand on our framework to extend \dataset\ to additional languages.
Additionally, our data collection was conducted on Prolific, meaning that the dataset reflects the perspectives of those who choose to participate on this platform. To ensure diversity, we take deliberate steps to collect moral and value-based information from a broad range of participants. However, as with any dataset, it may not fully capture the moral reasoning of the global population. Future work can further expand participation to enhance representation across different cultural and linguistic backgrounds.

\section{Ethical Considerations}
To construct \dataset, we gathered data from crowd-sourced workers while ensuring that all information remained strictly anonymous. We employed Prolific and the Potato framework for data collection, both of which rigorously anonymize data by assigning each annotator a unique key. All data recorded for an annotator is linked to this key, with no names associated with the dataset. We obtained informed consent from all participants and ensured prompt and fair compensation for those who completed our study. Additionally, the data collection process was deemed exempt by our institution's ethics review board.

\bibliography{custom,anthology}

\appendix

\section{Appendix}
\label{sec:appendix}
\subsection{Seed Scenario Development}
\label{app:seed_scenarios}
In order to collect our initial set of scenarios that elicit the moral reasoning pipeline in an individual, we consider the scenarios discussed in three psychological theories as discussed below. We show the collected $16$ scenarios in Table \ref{tab:seed_scenarios}.

\paragraph{Moral Judgment Interview (MJI).} The Moral Judgment Interview \cite{kohlberg1963moral}, developed by Lawrence Kohlberg, is a structured interview method used to assess an individual’s moral reasoning based on their responses to hypothetical moral dilemmas. Participants are asked to justify their decisions, and their reasoning is evaluated according to Kohlberg’s six-stage theory of moral development.

\paragraph{Defining Issues Test (DIT).} The Defining Issues Test \cite{rest1979development}, introduced by James Rest, is a standardized multiple-choice assessment designed to measure moral reasoning through the lens of neo-Kohlbergian theory \cite{kohlberg1963moral}. Unlike the MJI, which relies on open-ended responses, the DIT presents participants with moral dilemmas and asks them to rank predefined considerations based on their importance in decision-making. 

\paragraph{Moral Competence Test (MCT).} The Moral Competence Test \cite{Lind2008meani-1361}, developed by Georg Lind, assesses moral competence as the ability to apply moral principles consistently across varying contexts. Unlike the MJI and DIT, the MCT evaluates both moral orientation and consistency in reasoning by presenting respondents with moral dilemmas and asking them to rate arguments for and against different positions. It emphasizes cognitive-affective integration, reflecting how individuals balance moral ideals with practical decision-making. The MCT's design makes it a useful tool for studying moral competence development and the effectiveness of moral education programs.  

\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|p{45em}}
\hline
\textbf{Theories} & \textbf{Moral Dilemma} \\ \hline
  \multirow{7}{*}[-4em]{\textbf{\rotatebox{90}{Moral Judgment Interview}}} &
  Heinz's wife is dying from a particular type of cancer. There is a drug that might save her, but it is very expensive, and Heinz cannot afford it. The pharmacist who discovered the drug refuses to sell it for any less or to let Heinz pay later. Heinz is considering breaking into the pharmacy to steal the drug.
   \\ \cline{2-2} 
\textbf{} &
  A man is traveling with his sick father, who is dying. The father begs his son to end his suffering by giving him a fatal dose of medicine. The son is torn between ending his father's pain and the moral implications of killing him. 
   \\ \cline{2-2}
\textbf{} &
  A drug addict is considering stealing money from his family to buy drugs. He knows that if he doesn't get his fix, he will suffer severe withdrawal symptoms. 
   \\ \cline{2-2}
\textbf{} &
  A judge is faced with a difficult decision. A man has committed a minor crime but is a significant public figure. Sentencing him to prison could lead to public unrest and negative consequences for society. 
   \\ \cline{2-2}
\textbf{} &
    A doctor has five patients in critical condition, each requiring a different organ transplant to survive. A healthy person walks into the hospital for a routine check-up. The doctor realizes that this person could save the five patients if their organs were harvested. 
   \\ \cline{2-2}
\textbf{} &
  Two prisoners are accused of a crime. The authorities offer each prisoner a deal: if one testifies against the other, the testifying prisoner will go free while the other receives a harsh sentence. If both remain silent, they both receive moderate sentences. If both testify against each other, both receive harsh sentences. 
   \\ \cline{2-2}
\textbf{} &
  A trolley is headed towards five people tied up on the tracks. You are standing next to a lever that can switch the trolley to another track where only one person is tied up. 
   \\ \hline
\multirow{6}{*}[-3em]{\rotatebox{90}{\textbf{Defining Issues Test}}} &
  An escaped prisoner has lived an exemplary life for many years but is discovered and arrested. The dilemma is whether he should be sent back to prison. 
   \\  \cline{2-2}
 &
  A reporter must decide whether to publish a controversial story that could cause public unrest but would expose a significant injustice.
   \\ \cline{2-2}
 &
  A school board must decide whether to allocate limited resources to a special education program or a program for gifted students. 
   \\ \cline{2-2}
 &
  A doctor must decide whether to administer a high-risk treatment to a terminally ill patient. The treatment could either extend the patient's life or cause severe side effects.
   \\ \cline{2-2}
 &
  A father is a widower with two young children. He must decide whether to remarry for the sake of his children, despite personal reservations. 
   \\ \cline{2-2}
 &
  A reporter knows of a scandal involving a public official. Publishing the story could harm innocent people but also serve the public interest. 
   \\ \hline
\multirow{3}{*}[-1em]{\rotatebox{90}{\parbox{2cm}{\textbf{Moral Competence Test}}}} &
  A group of workers goes on strike to demand higher wages. The strike causes significant disruption to the company and the public. 
   \\ \cline{2-2}
 &
    A prestigious school has limited spaces and must decide whether to admit a talented student from a disadvantaged background or a student with excellent academic records but from a well-off family.
   \\ \cline{2-2}
 &
  A police officer must decide whether to enforce a law that they believe is unjust but is required by their duty to uphold the law. 
   \\ \hline
\end{tabular}%
}
\caption{Seed Scenarios or moral dilemmas extracted from the Moral Judgment Interview, Defining Issues Test, and Moral Competence Test theories.}
\label{tab:seed_scenarios}
\end{table*}


\subsection{Reddit Moral Dilemma Preprocessing}
\label{app:reddit}
Reddit contains multiple communities where users submit posts describing a moral dilemma and asking for help or describing a dilemma and what action the user took and asking for judgment. One of the most well-known of these is r/AmItheAsshole which attracts hundreds of posts or more per day. We curate a dataset of dilemmas by synthesizing dilemmas from the real-world scenarios described by users in ‘AmItheAsshole’, ‘moraldilemmas’, ‘AITAH’, ‘TwoHotTakes’, and ‘AmIOverreacting’. Some scenarios are too short so we restrict our candidate scenarios to those with at least 50 words. To avoid dilemmas that are Reddit-specific or require access to external material to understand, we exclude posts that mention Reddit, another subreddit, or a URL. Some users come back to provide additional details or updates using the edit functionality and leave a note ``EDIT:'' ; we anticipated that these might be more challenging to paragraph due to the more complex post structure so we remove any posts that have been explicitly edited.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{demographics_nationality_dist.pdf}
    \caption{Distribution of nationalities of the Prolific participants who participated in our studies. The size of the circle is proportional to the number of participants from that country.}
    \label{fig:nationality}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{unimoral_flowchart-2.pdf}
    \caption{Data collection process for \dataset. Final data comes from a mix of psychological scenarios and Reddit based dilemmas.}
    \label{fig:unimoral-flowchart}
\end{figure}

\subsection{\dataset\ Annotation Framework}
\label{app:annotation}
We collect \dataset\ through crowd-sourcing, wherein we use Potato \cite{pei2022potato} to develop our annotation platform and use Prolific to deploy it. Each annotator is shown an introduction page before they begin the annotation process which described their task in the annotation process and collect their informed consent. Figure \ref{fig:potato_introduction} shows the introduction and consent page that we show to the annotator to prime them for the study, while Figure \ref{fig:potato_screenshot} shows how the annotation framework looks to the Prolific participant.

\begin{table*}[th]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|p{20em}|p{20em}|p{20em}}
\hline
 &
  \textbf{English} &
  \textbf{Chinese} &
  \textbf{Russian} \\ \hline
  & & &\\
  \multirow{2}{*}[-1em]{\rotatebox{90}{\parbox{2cm}{\textbf{Scenario}}}} &
  Kevin, a police officer, has been assigned to arrest a suspect in a serious crime case. The suspect is his cousin. After reviewing the evidence, Kevin finds it to be circumstantial, leading him to question his cousin's guilt. Meanwhile, the actual perpetrator remains at large. What course of action should Kevin take? &
  \begin{CJK*}{UTF8}{gbsn}
  警官凯文被派去逮捕一个严重犯罪案的嫌疑人嫌疑人是他的堂兄经过审查证据后,凯文发现证据是间接的,这让他质疑堂兄的罪恶与此同时,实际的罪犯仍然在逃凯文应该采取什么行动? \end{CJK*} &
  \foreignlanguage{russian}{Кевин, полицейский, получил задание арестовать подозреваемого в серьезном преступном деле. Подозреваемый - его двоюродный брат. После рассмотрения доказательств, Кевин считает, что это косвенные, что заставляет его сомневаться в вине своего двоюродного брата. Тем временем, фактический преступник остается на свободе. Какой курс действий должен принять Кевин?} \\
  & & &\\ \hline
  & & &\\
  \multirow{2}{*}[4em]{\rotatebox{90}{\parbox{3cm}{\textbf{Possible Actions}}}} &
  \begin{tabular}[c]{@{}p{20em}@{}}1. Arrest the cousin based on the available evidence, potentially sacrificing family ties and his cousin's freedom, even if he may be innocent.\\ 2. Withhold the arrest and further investigate, risking the actual perpetrator claiming more victims and damaging public trust in the police, but also preserving the possibility of his cousin's innocence.\end{tabular} &
  \begin{tabular}[c]{@{}p{20em}@{}}\begin{CJK*}{UTF8}{gbsn} 1. 基于现有的证据逮捕表兄弟, 潜在地牺牲家庭关系和表兄弟的自由, 即使他可能无辜.\end{CJK*} \\ \begin{CJK*}{UTF8}{gbsn} 2. 风险是实际的罪犯声称更多受害者, 损害公众对警方的信任,\end{CJK*} \end{tabular} &
  \begin{tabular}[c]{@{}p{20em}@{}} \foreignlanguage{russian}{1. Арестуйте двоюродного брата на основе имеющихся доказательств, потенциально пожертвовав семейными связями и свободой его двоюродного брата, даже если он может быть невиновным.}\\  \foreignlanguage{russian}{2. Остановить арест и продолжить расследование, рискуя тем, что фактический преступник претендует на больше жертв и наносит ущерб доверию общественности к полиции, но также сохраняя возможность невиновности его двоюродного брата.}\end{tabular} \\
  & & &\\ \hline
\end{tabular}%
}
\caption{Example scenario and possible action set from \dataset\ with the English version along with the Chinese and Russian translated versions.}
\label{tab:scenario_example}
\end{table*}

For each language, up to 113 participants were enrolled to perform annotations for both the extensive and compact studies. Participants were compensated at an average rate of \$13 per hour for their annotation work. Given the multilingual nature of our data collection, we staggered the study start times across different time zones to recruit participants from regions where the target languages are commonly spoken. For example, the Chinese-language study began at 10 AM CST, while the English-language study started at 5 PM EST. To illustrate the diversity of our participants, we visualize their nationalities in Figure \ref{fig:nationality}. This figure demonstrate that \dataset\ captures a broad geographic range, reflecting a variety of cultural backgrounds.
Participants in our data collection were able to access a separate webpage displaying their consolidated moral and cultural scores, allowing them to gain insights from the results. This also serves as an additional incentive for participation. Figure \ref{fig:result_site} provides a preview of this webpage. The entire pipeline for collecting \dataset\ is visualised in Figure \ref{fig:unimoral-flowchart}.

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{country_moral.pdf}
        \caption{Country-wise distribution of most prominent moral values collected via MFQ2 in our study.}
        \label{fig:nationality_moral}
    \end{subfigure}
    \begin{subfigure}[t]{\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{country_culture.pdf}
        \caption{Country-wise distribution of most prominent cultural principles collected via VSM in our study.}
        \label{fig:nationality_culture}
    \end{subfigure}
    \caption{Distribution of moral values and cultural dimensions across countries from \dataset.}
    \label{fig:enter-label}
\end{figure}


\begin{figure*}[th]
    \centering
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[height=3.2in]{potato_intro.png}
        \caption{Introduction shown to the participants for their informed consent.}
        \label{fig:potato_introduction}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[height=3.2in]{potato.png}
        \caption{Sample annotation page the user see and has to fill.}
        \label{fig:potato_screenshot}
    \end{subfigure}
    \caption{Screenshots from our annotation platform developed using Potato.}
    \label{fig:potato}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{quiz_results.png}
    \caption{Moral and Cultural score results shown to the user, as aggregated from the MFQ2 and VSM of the participant.}
    \label{fig:result_site}
\end{figure*}

\subsection{Calculation of the Moral and Cultural Scores from Participant Responses}
\label{app:mfq_vsm_scores}
The Moral Foundation Questionnaire (MFQ) \cite{kohlberg1963moral} is designed to measure moral values based on Moral Foundations Theory (MFT), which identifies five key moral dimensions: Care, Fairness, Loyalty, Authority, and Purity. A recent extension of this, the MFQ2 \cite{atari2023morality}, introduces another dimension of Proportionality and add relevant questions to the original MFQ questionnaire. The MFQ and MFQ2 consists of two sections: one assessing the relevance of different moral concerns (e.g., ``Whether or not someone suffered emotionally") and another evaluating agreement with moral statements (e.g., ``Compassion for those who are suffering is the most crucial virtue"). Participants respond using a Likert scale, typically ranging from 1 (not at all relevant/strongly disagree) to 5 (extremely relevant/strongly agree). To compute moral scores, responses for each moral foundation are averaged separately from the relevance and endorsement sections. A higher score on a particular foundation indicates a stronger inclination toward that moral dimension. We use the MFQ2 in our study, thus dealing with 6 dimension score of morality.

The Values Survey Module (VSM) \cite{hofstede1994vsm94}, developed by Geert Hofstede, measures cultural dimensions across societies, focusing on six key aspects:  
\begin{enumerate}[noitemsep, topsep=0pt]
    \item Power Distance (PDI) – The degree to which inequality in power and authority is accepted.
    \item Individualism vs. Collectivism (IDV) – The extent to which people prioritize personal autonomy over group loyalty.
    \item Masculinity vs. Femininity (MAS) – Whether a culture values competitiveness and achievement (masculine) or care and quality of life (feminine).
    \item Uncertainty Avoidance (UAI) – The preference for structured, rule-based environments over ambiguity.
    \item Long-Term Orientation vs. Short-Term Orientation (LTO) – The extent to which a society values perseverance and future rewards versus tradition and immediate gratification.
    \item Indulgence vs. Restraint (IVR) – The level of emphasis on personal enjoyment and leisure versus strict social norms.
\end{enumerate}

Each cultural dimension is measured using multiple questionnaire items, with responses typically rated on a five-point Likert scale. Scores for each dimension are calculated by averaging the responses associated with that dimension, then adjusting using Hofstede’s formula. These scores provide insights into dominant cultural values and their influence on decision-making and social behavior.

We calculate the moral and cultural scores and compare the average score across the participants having different nationalities. Figure \ref{fig:nationality_moral} and Figure \ref{fig:nationality_culture} shows the most prominent values of morals and culture preferred by the annotators of each country.

\begin{table}[t]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{l S[table-format=1.0] S[table-format=3.0] S[table-format=1.0] S[table-format=4.0]}
        \toprule
        {Study type} & {\# Langs} & {\# Sc/lang} & {\# Ann/sc} & {\# Inst/lang} \\
        \midrule
        Extensive   & 6 & 194 & 3 & 582  \\
        Compact     & 6 & 294 & 3 & 882  \\
        \midrule
                    & 6 & 488 & 3 & 1464 \\
        \bottomrule
    \end{tabular}}
    \caption{Language wise statistics for the \dataset\ dataset.}
    \label{tab:data_stats}
\end{table}

\subsection{\dataset\ Statistics}
\label{app:data_stats}
Table \ref{tab:data_stats} illustrates the language wise statistics for \dataset. As can be observed, each language contains a total of $1464$ instances, making the total number of instances in \dataset\ across the six languages as $8784$. We also show one example scenario and possible action set generated using the Llama-3.1-70B Instruct model in Table \ref{tab:scenario_example}. Translations for Chinese and Russian, obtained via the Seamless-m4t-v2 model, are also shown.

\subsection{Prompts}
\label{app:prompts}
This study involves the usage of prompts in two ways -- 1) generating the data for human annotation, and 2) prompting the LLMs for evaluation of the data. All prompts that are selected for final use, whether in data generation or model evaluation, are finalized from an initial pool of possible prompts. We consider a number of candidate prompts, conduct initial experiment using them over a small subset of the English data and compare the results manually. We then select the best performing prompts and translate them to all the six languages required. We use chain of thought prompting for data generation while single prompts are used for evaluating LLMs. We list the prompts selected below. Anything in between square brackets is a placeholder, which is replaced with content before prompting any model.

\begin{myboxtype}
\textbf{Scenario generation Prompt 1:}

\noindent You are a moral psychology expert. Given the following example scenario: [SEED SCENARIO], write its moral information, decision maker role, emotions elicited in the decision maker, consequence of the possible actions, and non moral and non emotional factors, such as legality, game rules, sacred values, culture, and social relations, involved in the decision making process.\\

\noindent Mention all these in no more than one line each. Just return the characteristics as a JSON file.
\end{myboxtype}

\begin{myboxtype}
\textbf{Scenario generation Prompt 2:}

\noindent Given the following definition of a scenario:\\

\noindent A scenario is a detailed and structured description of a hypothetical situation designed to explore potential actions and outcomes. It includes several key elements. The Actor Role identifies the primary individual or group involved in the scenario. The Context provides the background and setting where the scenario takes place. Key Players are other significant individuals or groups that interact with the main actor. The Actor Objectives outline the goals, conflicts, and dilemmas faced by the actor within the scenario. Finally, the Action Question is a prompt that asks the actor to determine the best course of action based on the given information.\\

\noindent Write [NUM SCENARIOS] scenarios, in third person mode, similar to the following example scenario: [SEED SCENARIO]. The key characteristics of the scenario is described here: [PROMPT1 RESPONSE].\\

\noindent Write the scenarios in a paragraph format in no more than five lines, eliciting a similar moral dilemma such that each scenario contains the following characteristic: The [MOTIVATION] becomes the driving force of the decision making process. This scenario should not be different from the past scenarios. Just return the scenarios as a JSON file with keys as scenatio number and value as the scenario.
\end{myboxtype}

\begin{myboxtype}
\textbf{Scenario generation Prompt 3:} 

\noindent Rewrite the following scenario so that it focuses only on the facts and ends with an open-ended question about what to do, removing any motivational details. Here is the scenario: [SCENARIO]
\end{myboxtype}

\begin{myboxtype}
\textbf{Action generation Prompt 1:} 

\noindent Consider the following scenario: [SCENARIO].\\

\noindent Deconstruct it to find out the immediate key stakeholders, list out their emotions, needs, biases in terms of pro and anti, and social influence given the scenario. Answer succinctly in a nested JSON format with the first level keys being the stakeholders and the second level keys are 'emotion', 'need', 'bias', and 'social influence'.
\end{myboxtype}

\begin{myboxtype}
\textbf{Action generation Prompt 2:} 

\noindent Give me the most apparent two actions that the main actor can take irrespective of them being morally correct or not based on the following scenario: [SCENARIO] and the following aspects of stakeholders: [PROMPT1 RESPONSE].\\

\noindent Give me one JSON file with the keys being action id and the values being the actions.
\end{myboxtype}

\begin{myboxtype}
\textbf{Action generation Prompt 3:}

\noindent Rephrase these actions in a way that they look like possible options. Consider this scenario -- [SCENARIO]; and add a sense of what they'll lose to the action options without being definitive. For e.g. rephrase "Spend time searching for cure" to "Spend time searching for cure knowing that it might reduce time spent with wife during her last days". [ACTIONS]. Keep the rephrased response short. Return only a JSON file with keys being the serial number and the value being the rephrased action.
\end{myboxtype}

\begin{myboxtype}
\textbf{\oneshort\ -- with persona:}

\noindent Consider this scenario: [SCENARIO]; and the following possible actions: [ACTIONS].\\

\noindent Your job is to think like a person who introduces them as follows: [PERSONA], and choose one of the possible actions given the scenario. Strictly give your answer using the following format: "Selected action is <a or b>.". Do not write any explanation.
\end{myboxtype}

\begin{myboxtype}
\textbf{\twoshort\ -- with moral values:}

\noindent Consider the following definition of moral values:\\

\noindent Care - Prioritizing kindness, compassion, and the prevention of harm to others. 

\noindent Equality - Ensuring that all individuals have the same rights, opportunities, and treatment.

\noindent Proportionality - Rewarding or punishing individuals in fair proportion to their actions.

\noindent Loyalty - Maintaining steadfast commitment and allegiance to ones group or community. 

\noindent Authority - Respecting and upholding legitimate leadership, rules, and social order. 

\noindent Purity - Valuing cleanliness, sanctity, and self-discipline in thoughts and actions. \\

\noindent Now, consider this scenario: [SCENARIO]; and the following possible actions: [ACTIONS]. Your job is to think like a person who values [MORAL VALUE 1] the most followed by [MORAL VALUE 2], [MORAL VALUE 3], [MORAL VALUE 4], [MORAL VALUE 5], [MORAL VALUE 6]; who selected to do the following action: [SELECTED ACTION].\\

\noindent Identify what type of action this is out of the following [`Deontological', `Utilitarianism', `Rights-based', `Virtous'].\\

\noindent Strictly give your answer using the following format: "Selected action is <'Deontological' or 'Utilitarianism' or 'Rights-based' or 'Virtous'>.". Do not write any explanation.
\end{myboxtype}

\begin{myboxtype}
\textbf{\threeshort\ -- with few shot examples:}

\noindent Consider the following example scenario, the action selected by person A, and the contributing factor this action was influenced by. \\

\noindent Scenario: [FS SCENARIO]; Selection Action: [FS ACTION]; Action type: [FS CONTRIBUTING FACTOR]\\

\noindent Now, given the following scenario, and the action taken for the scenario by person A, your job is to identify the most important factor that contributed in the person's decision making out of the following [`Emotions', `Moral', `Culture', `Responsibilities', `Relationships', `Legality', `Politeness', `Sacred values'].\\ 

\noindent Strictly give your answer using the following format: "Selected action is <`Emotions', or `Moral', or `Culture', or `Responsibilities', or `Relationships', or `Legality', or `Politeness', or `Sacred values'>.". Do not write any explanation.
\end{myboxtype}

\begin{myboxtype}
\textbf{\fourshort: } 

\noindent Consider this scenario: [SCENARIO]; and the following selected action: [SELECTED ACTION].\\

\noindent Your job is to generate the consequence of this action, given the scenario in a concise manner. Be brief. Strictly give your answer using the following format: "Consequence of the action is " followed by the generation. Do not write any explanation.
\end{myboxtype}

\subsection{Results for \oneshort, \twoshort, \threeshort, and \fourshort}
\label{app:results}
The main paper highlights the key findings obtained from our analysis in a concise and graphical way. Here, we enumerate the results obtained in a Tabular way to illustrate all intermediate values obtained as well. Table \ref{tab:rq1_results}, Table \ref{tab:rq2_results}, and Table \ref{tab:rq3_results} illustrates the results obtained for \oneshort, \twoshort, and \threeshort, respectively, where we have highlighted the best performance obtained across models (rows) and languages (columns). Table \ref{tab:rq4_results} showcases the results obtained for \fourshort. We see from Table \ref{tab:rq4_results} that we obtain high score for semantic similarity and a low score for syntactic similarity indicating that the generated consequences, may not follow a similar wordings than what is written by annotation participants, but they mean similar. We show an example generation and its corresponding ground truth in Table \ref{tab:rq4_examples}. As can be seen from the table, and manually observed in other cases as well, LLMs tend to generate longer text when compared with human annotators, and they try to include more context in the consequence as well. While this results in low score over syntactic metrics, it, in no way, means that the consequence generated are bad. BERTScore supports our claim.

\begin{table}[t]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{ll|r|r|r|r|r|r}
\hline
\multicolumn{2}{l|}{\textbf{}} &
  \multicolumn{1}{l|}{\textbf{Arabic}} &
  \multicolumn{1}{l|}{\textbf{Chinese}} &
  \multicolumn{1}{l|}{\textbf{English}} &
  \multicolumn{1}{l|}{\textbf{Hindi}} &
  \multicolumn{1}{l|}{\textbf{Russian}} &
  \multicolumn{1}{l}{\textbf{Spanish}} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Persona}}}} &
  \textbf{Phi} &
  50.72 &
  59.74 &
  61.56 &
  \textcolor{myred}{46.40} &
  58.69 &
  \underline{63.45} \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  \textbf{61.80} &
  61.62 &
  66.05 &
  \textbf{64.05} &
  61.92 &
  \underline{\textbf{66.17}} \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  \textcolor{myred}{49.41} &
  51.71 &
  50.79 &
  \textcolor{myred}{44.87}&
  \underline{53.26} &
  50.60 \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Moral}}}} &
  \textbf{Phi} &
  51.14 &
  57.42 &
  \underline{\textbf{66.38}} &
  51.10 &
  58.66 &
  62.60 \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  53.43 &
  61.64 &
  59.97 &
  58.06 &
  \textbf{61.94} &
  \underline{65.20} \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  55.02 &
  51.57 &
  51.60 &
  50.27 &
  54.98 &
  \underline{55.09} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Culture}}}} &
  \textbf{Phi} &
  51.81 &
  55.11 &
  \underline{65.58} &
  53.56 &
  60.10 &
  60.08 \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  50.57 &
  \underline{\textbf{61.95}} &
  59.00 &
  53.34 &
  61.66 &
  61.38 \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  52.51 &
  \textcolor{myred}{48.96} &
  \textcolor{myred}{47.06} &
  \textcolor{myred}{44.32} &
  52.31 &
  \underline{53.89} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Fewshot}}}} &
  \textbf{Phi} &
  55.66 &
  53.99 &
  \underline{62.65} &
  50.53 &
  57.39 &
  62.07 \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  51.29 &
  57.60 &
  59.52 &
  55.73 &
  58.58 &
  \underline{65.11} \\ %\cline{2-8} 
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  53.09 &
  \underline{53.16} &
  \textcolor{myred}{46.72} &
  52.07 &
  51.38 &
  \textcolor{myred}{48.37} \\ \hline
\end{tabular}%
}
\caption{Results for \onelong. The numbers shown are weighted F1-scores where \textbf{bold} highlights best performance across language, and \underline{underline} highlights best performance across model. \textcolor{myred}{Red color} signifies performance below random. [Abbreviations -- Phi: Phi-3.5-mini Instruct, Llama: Llama-3.1-8b-Instruct, R1: DeepSeek-R1-Distill-Llama-8B]}
\label{tab:rq1_results}
\end{table}

\begin{table}[t]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{ll|r|r|r|r|r|r}
\hline
\multicolumn{2}{l|}{\textbf{}} &
  \multicolumn{1}{l|}{\textbf{Arabic}} &
  \multicolumn{1}{l|}{\textbf{Chinese}} &
  \multicolumn{1}{l|}{\textbf{English}} &
  \multicolumn{1}{l|}{\textbf{Hindi}} &
  \multicolumn{1}{l|}{\textbf{Russian}} &
  \multicolumn{1}{l}{\textbf{Spanish}} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Persona}}}} &
  \textbf{Phi} &
  39.00 &
  \textbf{37.27} &
  \underline{46.37} &
  38.19 &
  38.41 &
  41.35 \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  33.44 &
  29.86 &
  \underline{34.56} &
  33.35 &
  34.05 &
  40.30 \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  26.37 &
  \textcolor{myred}{16.33} &
  \textcolor{myred}{23.63} &
  \underline{34.77} &
  26.63 &
  \textcolor{myred}{13.82} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Moral}}}} &
  \textbf{Phi} &
  \textcolor{myred}{14.18} &
  36.82 &
  \underline{45.66} &
  \textcolor{myred}{13.65} &
  \textcolor{myred}{22.83} &
  \textcolor{myred}{17.10} \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  \textcolor{myred}{21.09} &
  28.59 &
  45.99 &
  30.39 &
  \textbf{50.85} &
  \underline{\textbf{57.01}} \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  40.72 &
  \textcolor{myred}{21.67} &
  25.23 &
  41.07 &
  \underline{45.09} &
  30.25 \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Culture}}}} &
  \textbf{Phi} &
  \textcolor{myred}{16.25} &
  33.26 &
  \underline{37.34} &
  \textcolor{myred}{15.10} &
  30.24 &
  \textcolor{myred}{19.18} \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  28.57 &
  29.41 &
  33.39 &
  \textcolor{myred}{17.42} &
  35.57 &
  \underline{54.92} \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  42.70 &
  \textcolor{myred}{23.24} &
  27.04 &
  39.40 &
  \underline{44.76} &
  \textcolor{myred}{23.09} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Fewshot}}}} &
  \textbf{Phi} &
  \textcolor{myred}{20.84} &
  34.49 &
  \underline{\textbf{54.07}} &
  \textcolor{myred}{22.54} &
  32.75 &
  37.26 \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  \underline{38.62} &
  34.23 &
  29.56 &
  35.35 &
  \textcolor{myred}{23.84} &
  30.69 \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  \underline{\textbf{53.82}} &
  27.10 &
  42.96 &
  \textbf{46.06} &
  44.67 &
  29.01 \\ \hline
\end{tabular}%
}
\caption{Results for \twolong. The numbers shown are weighted F1-scores where \textbf{bold} highlights best performance across language, and \underline{underline} highlights best performance across model. \textcolor{myred}{Red color} signifies performance below random. [Abbreviations -- See Table \ref{tab:rq1_results}]}
\label{tab:rq2_results}
\end{table}

\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{ll|r|r|r|r|r|r}
\hline
\multicolumn{2}{l|}{\textbf{}} &
  \multicolumn{1}{l|}{\textbf{Arabic}} &
  \multicolumn{1}{l|}{\textbf{Chinese}} &
  \multicolumn{1}{l|}{\textbf{English}} &
  \multicolumn{1}{l|}{\textbf{Hindi}} &
  \multicolumn{1}{l|}{\textbf{Russian}} &
  \multicolumn{1}{l}{\textbf{Spanish}} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Persona}}}} &
  \textbf{Phi} &
  23.94 &
  26.81 &
  27.69 &
  25.86 &
  32.70 &
  \underline{34.59} \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  32.48 &
  31.95 &
  \textbf{35.11} &
  29.82 &
  35.55 &
  \underline{\textbf{36.55}} \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  25.89 &
  18.65 &
  27.15 &
  24.30 &
  30.32 &
  \underline{28.57} \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Moral}}}} &
  \textbf{Phi} &
  19.86 &
  29.94 &
  \underline{33.25} &
  28.86 &
  28.64 &
  27.38 \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  \underline{34.14} &
  \textbf{33.82} &
  24.98 &
  19.46 &
  29.98 &
  21.23 \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  \underline{30.52} &
  17.69 &
  22.81 &
  21.86 &
  29.57 &
  26.37 \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Culture}}}} &
  \textbf{Phi} &
  15.15 &
  26.12 &
  \underline{33.54} &
  26.04 &
  26.10 &
  29.16 \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  \textcolor{myred}{6.30} &
  12.69 &
  \underline{13.31} &
  \textcolor{myred}{11.81} &
  \textcolor{myred}{11.54} &
  \textcolor{myred}{11.99} \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  21.77 &
  18.33 &
  \underline{26.24} &
  16.50 &
  25.75 &
  25.89 \\ \hline
\multicolumn{1}{l|}{\multirow{3}{*}{\rotatebox{90}{\textbf{Fewshot}}}} &
  \textbf{Phi} &
  29.01 &
  21.34 &
  30.58 &
  \underline{32.59} &
  32.30 &
  28.16 \\
\multicolumn{1}{l|}{} &
  \textbf{Llama} &
  26.84 &
  26.23 &
  27.33 &
  15.68 &
  \underline{\textbf{38.59}} &
  25.31 \\
\multicolumn{1}{l|}{} &
  \textbf{R1} &
  \underline{\textbf{36.61}} &
  14.82 &
  24.34 &
  \textbf{33.36} &
  28.36 &
  19.68 \\ \hline
\end{tabular}%
}
\caption{Results for \threelong. The numbers shown are weighted F1-scores where \textbf{bold} highlights best performance across language, and \underline{underline} highlights best performance across model. \textcolor{myred}{Red color} signifies performance below random. [Abbreviations -- See Table \ref{tab:rq1_results}]}
\label{tab:rq3_results}
\end{table}

\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l|rrr|rrr|rrr}
\hline
\multirow{2}{*}{} & \multicolumn{3}{c|}{\textbf{Phi}} & \multicolumn{3}{c|}{\textbf{Llama}} & \multicolumn{3}{c}{\textbf{R1}} \\ \cline{2-10} 
 &
  \multicolumn{1}{c}{\textbf{B}} &
  \multicolumn{1}{c}{\textbf{M}} &
  \multicolumn{1}{c|}{\textbf{BS}} &
  \multicolumn{1}{c}{\textbf{B}} &
  \multicolumn{1}{c}{\textbf{M}} &
  \multicolumn{1}{c|}{\textbf{BS}} &
  \multicolumn{1}{c}{\textbf{B}} &
  \multicolumn{1}{c}{\textbf{M}} &
  \multicolumn{1}{c}{\textbf{BS}} \\ \hline
\textbf{Arabic}                      & 1.27   & \textcolor{myred}{3.68}   & \textbf{71.31}  & 1.20    & 6.38    & 69.84   & \textcolor{myred}{0.48}  & \textcolor{myred}{2.79}   & \textcolor{myred}{64.77} \\
\textbf{Chinese}                       & \textcolor{myred}{0.06}   & \textcolor{myred}{0.17}   & \textcolor{myred}{64.84}  & \textcolor{myred}{0.01}   & \textcolor{myred}{0.06}    & \textcolor{myred}{\textbf{65.89}}   & \textcolor{myred}{0.00}     & \textcolor{myred}{0.00}      & \textcolor{myred}{62.99} \\
\textbf{English}                       & \underline{3.29}   & \underline{13.65}  & \underline{86.48}  & \underline{2.37}   & \underline{19.08}   & \underline{\textbf{87.44}}   & \underline{2.42}  & \underline{16.71}  & \underline{87.07} \\
\textbf{Hindi}                       & 0.73   & \textcolor{myred}{2.99}   & \textcolor{myred}{67.81}  & 2.08   & 11.12   & \textbf{70.78}   & 1.14  & 7.37   & 68.56 \\
\textbf{Russian}                       & 0.88   & \textcolor{myred}{2.71}   & \textcolor{myred}{\textbf{67.88}}  & 0.95   & 5.81    & \textcolor{myred}{67.07}   & \textcolor{myred}{0.49}  & 4.20    & \textcolor{myred}{65.26} \\
\textbf{Spanish}                       & 1.87   & 9.57   & 68.69  & 1.66   & 15.60    & \textbf{70.56}   & 1.51  & 11.14  & 69.92 \\ \hline
\end{tabular}%
}
\caption{Results for \fourlong. The numbers shown are BLEU (B), METEOR (M), and BERTScore (BS) where \textbf{bold} highlights best performance across language, and \underline{underline} highlights best performance across model. \textcolor{myred}{Red color} signifies performance below random. [Abbreviations -- See Table \ref{tab:rq1_results}]}
\label{tab:rq4_results}
\end{table}

\begin{table}[h!]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|m{1em}m{5em}|m{20em}|}
\hline
\multicolumn{2}{|c|}{\rotatebox[origin=c]{0}{{\textbf{Scenario}}}} &
  A teacher has discovered that a student has plagiarized a significant portion of their thesis. The student is the sole caregiver for a disabled family member and is relying on the degree to secure a better job. Reporting the plagiarism could jeopardize the student's future, while not reporting it could allow the student to graduate. What action should the teacher take? \\ \hline
\multicolumn{2}{|c|}{\rotatebox[origin=c]{0}{{\textbf{Selected Action}}}} &
  Report the plagiarism to the university administration, potentially jeopardizing the student's future and their ability to support their disabled family member. \\ \hline
\multicolumn{2}{|c|}{{\textbf{GT}}} &
  there would be potential harm to the student. \\ \hline
\multicolumn{1}{|l|}{\multirow{3}{*}[-1em]{\rotatebox[origin=c]{90}{\textbf{Predictions}}}} &
  \rotatebox[origin=c]{0}{\textbf{Phi}} &
  the student facing academic disciplinary action, risking their job prospect \\ \cline{2-3} 
\multicolumn{1}{|l|}{} &
  \rotatebox[origin=c]{0}{\textbf{Llama}} &
  The student will be required to redo the thesis or face academic penalties, potentially jeopardizing their future and their ability to secure a better job and support their disabled family member. \\ \cline{2-3} 
\multicolumn{1}{|l|}{} &
  \rotatebox[origin=c]{0}{\textbf{R1}} &
  The student may face disciplinary action, potentially losing their degree and jeopardizing their ability to secure employment, which could negatively impact their ability to support their disabled family member. \\ \hline
\end{tabular}%
}
\caption{Sample predictions made by the model given the scenario. [Abbreviations -- GT: Ground Truth, Phi: Phi-3.5-mini Instruct, Llama: Llama-3.1-8B-Instruct, R1: DeepSeek-R1-Distill-Llama-8B]}
\label{tab:rq4_examples}
\end{table}

\subsubsection{Reproducibility Details}
\label{sec:inferencedetail}
Experiments are conducted on 4 NVIDIA A100-SXM4-80GB GPUs using Hugging Face Transformers 4.43.3 \cite{wolf-etal-2020-transformers} and PyTorch 2.4.0 \cite{NEURIPS2019_9015} on a CUDA 12.4 environment. To ensure reproducibility, we set all random seeds in Python to be $42$, including PyTorch and NumPy. We keep max generation length as $2000$ tokens, rest all settings are default. Additionally, we plan to publicly release \dataset\ upon the acceptance of this paper to support further research in moral reasoning and NLP.

\end{document}