\section{RELATED WORK}
%% Proposed section order:  
% 1. 3D Sound design (in-general, e.g., DAWs, binaural rendering, spatial audio, 3DoF vs. 6DoF)
% 2. Audio Augmentation in AR
% 3. Authoring Sound in XR environments 
We present an overview of relevant concepts and prior work in 3D sound design and rendering, spatial localization in XR and the utilization of expanded degrees of freedom, a brief outline of sonified experiences in XR, and XR tools for sound design and audio mixing.

\subsection{3D Sound Design and Rendering}

Modern audio production is frequently carried out within DAWs -- software environments for music creation ____. Popular DAWs such as Cubase, Nuendo, Logic Pro, Ableton, and Pro Tools provide visual interfaces for manipulating %two primary data types: MIDI (musical note) information and 
digital audio, often adopting a skeumorphic design to replicate the look and feel of legacy hardware (e.g., mixers, drum machines, or synthesizers). While this approach helps users transition from traditional studio setups by mimicking familiar controls and interaction paradigms, it can constrain the interfaces to 2D representations. Furthermore, most DAWs rely on a timeline-based structure which encourages the sequential arrangement of audio objects ____. This temporal editing view does not take into account the \enquote{spatial} aspect of audio. Under the \emph{object-based audio} paradigm, each sound source (or \enquote{object}) is treated as an independent entity accompanied by metadata describing its spatial attributes -- namely, the location of \emph{spatial audio} in a 3D space ____. For spatial editing, DAWs offer 3D panners, which are tools to control the position of each audio object in a 3D space ____. A prime example is the Dolby Atmos Panner available in Pro Tools. 

There are several approaches to spatial audio rendering, and we can highlight two in the context of object-based audio workflows ____. The first is \emph{loudspeaker stereophony}, which consists in placing multiple speakers around the listener to create a surround sound experience commonly used in cinemas, home theaters, and gaming. A limitation of loudspeaker-based setups is that the listener must typically remain in an optimal \enquote{sweet spot} to fully appreciate the intended spatial effect, and phantom sound sources (i.e., perceptual illusions of sound sources) are restricted to positions between the speakers. The second approach, thanks to which many of audio-augmented XR applications are possible, is \emph{binaural rendering}. This method reproduces 3D audio using only two channels, simulating how sound is perceived by the human auditory system ____. By convolving audio signals with head-related transfer functions (HRTFs), which model how sound interacts with anthropometric features, binaural rendering can simulate the localization, timbre, and externalization of sound sources, creating a realistic perception of spatial objects in a 3D environment.
However, this technique can suffer from perceptual errors, such as front-back or up-down confusions and \enquote{in-head localization} effects ____. 

Once a spatial mix is finalized, the sequence of objects is sent to the renderer -- for example, the Dolby Atmos Renderer (potentially configured with personalized HRTFs). The renderer interprets the scene metadata to produce the final output for various configurations, whether loudspeaker arrays (e.g., 5.1.4, 7.1.4, 22.1) or headphone-based binaural playback. 

\subsection{Spatial Localization with Expanded Degrees of Freedom in XR}
%%Include audio localization

XR spans both augmented reality (AR) and virtual reality (VR), combining the physical world with a digital twin world in an interactable environment ____. A central factor in XR experiences is the notion of \emph{degrees of freedom} (DoF), which refers to the number of independent ways users can move within these virtual or augmented environments, and consists of translational and rotational components. Per convention, 3DoF restricts head tracking to the three rotational axes (pitch, yaw, roll), allowing users to look around but not physically move in space. A more immersive XR experience comes from adding to the equation the translational component (right/left, up/down, forward/back), resulting in 6DoF movement, which enables a more immersive and naturalistic exploration and navigation. An essential component for a user's navigation in an XR environment is building the cognitive map -- an internal representation of locations within a world-reference frame. Prior work has shown that 6DoF movement develops a more accurate cognitive map compared to 3DoF or purely joystick-based navigation ____. When users can physically walk around, rather than just pivot in place or point a controller, they gain a richer \enquote{movement fidelity} of real-world locomotion. 

Beyond navigation, 6DoF also permits precise placement of virtual objects. Instead of pointing a device (e.g., controller) or hand gesture in 3DoF to interact with graphical user interfaces (GUIs) situated spatially around them, with 6DoF, users can physically move to the target location and place those virtual directly ____. This approach magnifies the realism of XR soundscapes in 6DoF audio experiences for storytelling or entertainment. 
For instance, many 360$\degree$ cinematic experiences are in 3DoF and allow the user to look around the scene as if they were also co-located with the actors. Video games involving 6DoF interactions facilitate realism due to the envelopment of a user's entire body as an input device to interact with the content, encouraging direct engagement with XR content ____.  

Spatial audio is central to audio augmentation, such that virtual sounds are perceived as emanating from specific locations in 3D space ____. Humans rely on multiple sensory modalities when they engage with their environment ____, and the auditory sense remains highly significant for localization even when visual cues is limited, sometimes replacing visual information altogether (e.g., \enquote{watching} television from another room) ____. Research indicates that the use of spatial audio encourages users to adopt a more active role in spatial navigation, leading to even more accurate cognitive maps ____, while simultaneously reinforcing the sense of presence in XR environments ____. As reported in ____, audio interaction techniques should present directional and distance cues in contextually meaningful ways. Finally, an enhanced feeling of immersion often requires not just \enquote{looking and hearing around}, but also \enquote{moving around} in 6DoF to achieve the full benefits of spatial localization ____.


\subsection{Sound Experiences in XR}
%%At the end of 
%-- XR authoring tools for XR experiences (prior works have been primarily focused on this; this is where we are different) -- We are focused on the affordances of XR can have for 3D/spatial sound design in general with the inclusion of 3dof/6dof 
%Tools for creating music and soundscapes in AR and VR are primarily centered on composition with virtual instruments. 
Sound experiences in XR focus on interactions that leverage multimodal GUIs afforded by AR or VR head-mounted displays (HMDs), providing audio experiences that are more expressive and facilitate engagement for users. A notable example is \emph{Spatial Orchestra}, an AR interface, presented by ____ which allowed users to walk into \enquote{bubbles} in a fixed position and co-located near each other emitting musical notes, that can only be heard once they were fully inside the bubble. This provided users with an audio experience where they could interact with music with their body without having to play a traditional instrument; although in order for the interface to work, users had to remain within a confined virtual space that was 3.3 m by 3.3 m, thus limiting their translational movements. This work is one example of audiovisual experiences that have taken advantage of the spatial cues to visualize and interact with audio using methods to render 3D visualizations of sound that are reported in the literature to form stronger connections with the audio content engaging multiple senses of users due to the multimodal feedback ____. Other forms of sound experiences in XR include VR or AR music-based video games like \emph{Beat Saber} where users wield a saber to hit oncoming blocks containing parts of the song's beat ____. In this game users are able to stand up and use their body's orientation in a fixed location to interact with the game. The visual-aural feedback provided in music-based video games provide an engaging experience where musical notes tend to take a physical form engaging users in a multisensory experience. These works consist of different combinations of haptic feedback, visual representations, 3DoF, or physical interactions.  However, these approaches are experiential and do not allow for precise control of audio to compose soundscapes intended for 3D audio, for example, music, cinematic scenes, or video games. To illustrate, ____ and ____ discussed the use of spatial sound in VR for creating immersive virtual environments with a focus on computer games.

Research in audio augmented reality (AAR) has leveraged the physical environment to augment auditory feedback rendered to the user targeted \emph{navigation and location-awareness}, as spatialized \enquote{audio beacons}, verbal instructions, or guides ____, studies have underscored its potential for diverse domains, including  \emph{presentation and display}, particularly in museums or archaeological sites that use audio augmentations to deliver contextual information about cultural artifacts ____, or increase engagement with visitors at art exhibitions through spatialized sonic artwork like \emph{Sonic Sculpture} ____. 

\subsection{XR tools for Sound Design and Audio Mixing}
 A subset of design tools in XR utilize the flexibility of a spatial interface to interact with floating GUIs comprising of drag-and-drop UIs that can be manipulated with controllers. A notable commercial example is \emph{DearVR}, which uses virtual knobs and faders with a similar appearance of a music production studio ____. Several research works in sound design ____ have utilized a VR headset to recreate a virtual mixing environment, similar to the panning tools in DAWs, where users can control audio objects positioned at a distance with a controller and raycast to select the objects while remaining stationary.% while they enabling them to mix in a virtual world . 
 While all of these tools utilize some spatial aspects applied to sound design, they rely on a stationary user position and none of them exploit 6DoF direct manipulation, in which users can physically move around the environment to locate and place virtual audio objects. 
By contrast, AudioMiXR integrates 6DoF direct free-hand manipulation into the audio mixing workflow, allowing the user to traverse a real or virtual environment, directly grab virtual audio objects, and reposition them wherever they see fit -- this way, enabling true \emph{hands-on} editing of spatial sound as if the users were \enquote{inside the panner}, in ways conventional DAW panners or existing VR mixing tools cannot. 

% localization of sound and visual elements for object placement that can be facilitated with 6DoF. %%%% Can specify theirs is not 6DoF
%--- ADD THAT WE DO DIRECT INTERACTIONS FOR MIXING WHERE THE MIXING TOOLS SPECIFICALLY DO NOT
%Another example is LeMo which leverages a virtual MIDI-based tool in VR similar to MIDI controllers used by producers and DJs and they found their interface to enable collaboration for multiple users and demonstrate strategies for communication among users ____
%These interfaces and others in sound design research for XR design interfaces that do not fully depend on the users position, translation, and orientation to assist in creating the soundscape or mix.


%Studies have shown that the integration of auditory events is essential for a holistic AR experience ____ -- spatial audio cues can improve depth perception in AR environments, increase the sense of presence and task performance, as well as the overall immersion and realism of the AR environments  ____.

%Although initial efforts in audio augmentation targeted \emph{navigation and location-awareness}, as spatialized \enquote{audio beacons}, verbal instructions, or guides ____, recent studies have underscored its potential for diverse domains, including  \emph{presentation and display}, particularly in museums or archaeological sites that use audio augmentations to deliver contextual information about cultural artifacts ____, or increase engagement with visitors at art exhibitions through spatialized sonic artwork like \emph{Sonic Sculpture} ____. ____ discussed the use of spatial sound in VR for creating immersive virtual environments with a focus on computer games.Beyond gaming, audio-visual augmentations have been embedded in a variety of prototypes for \emph{entertainment and recreation}, such as the AR/DJ system ____, which introduced
% visualizes sound sources in a virtual 3D model of the dance floor.real-time 3D sound placement in a club setting by allowing the DJ to visualize a virtual 3D model of the dance floor, %offering DJs the ability to place 3D audio objects anywhere in the room. 
\begin{comment}
    \begin{itemize}
    \item ____ presents an augmented reality authoring tool that generates a sound library depending on the context of the scene (e.g., wooden table, virtual object materials) for authoring sound in augmented reality. They have a good example in their experiment where an augmented reality virtual robot is situated on top of a table and the recommended sounds to assign to this virtual element resemble metal walking on a wooden table. 
    \begin{itemize}
        \item "For example, imagine sliding an AR tea cup across a real-world surface such as a wood table. SonifyAR observes this user action (a slide gesture), the action source (the user), and the action target (a virtual ceramic teacup), infers scene information such as the surface material (a wood table), and uses a custom AI backend to recommend, retrieve, generate, or sound-style transfer sound effects."
        \item 
    \end{itemize}
    \item ____ Describes an automated sonification method based on data from 3D sensors (LiDAR) to map appropriate sound to the 3D environment based on the dimensions of the physical objects captured by the sensors. 
    \item The state of the art for sound authoring or sonification methods for 3D or AR environments primarily relies on automated processes that do not consider human perception -- This is what separates AudioMiXR from existing methods. AudioMiXR is intended to be a flexible UI approach where users leverage free-hand manipulation to mimic real world actions of placing objects and AudioMiXR relies on the human perceptual system in order to place objects 'accurately' (subjective). People share common perceptual systems which implies that a more 'direct' approach towards sound design in augmented reality or 3D environments may allow for more realistic spatial audio renderings that are representative of how we perceive sound in real life. 
    \item ____ Spatial audio authoring tool using ArUco markers.
   
\end{itemize}
\end{comment}