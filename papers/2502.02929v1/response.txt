\section{RELATED WORK}
%% Proposed section order:  
% 1. 3D Sound design (in-general, e.g., DAWs, binaural rendering, spatial audio, 3DoF vs. 6DoF)
% 2. Audio Augmentation in AR
% 3. Authoring Sound in XR environments 
We present an overview of relevant concepts and prior work in 3D sound design and rendering, spatial localization in XR and the utilization of expanded degrees of freedom, a brief outline of sonified experiences in XR, and XR tools for sound design and audio mixing.

\subsection{3D Sound Design and Rendering}

Modern audio production is frequently carried out within DAWs -- software environments for music creation **MÃ¼ller, "Real-Time Audio Processing"**. Popular DAWs such as Cubase, Nuendo, Logic Pro, Ableton, and Pro Tools provide visual interfaces for manipulating %two primary data types: MIDI (musical note) information and 
digital audio, often adopting a skeumorphic design to replicate the look and feel of legacy hardware (e.g., mixers, drum machines, or synthesizers). While this approach helps users transition from traditional studio setups by mimicking familiar controls and interaction paradigms, it can constrain the interfaces to 2D representations. Furthermore, most DAWs rely on a timeline-based structure which encourages the sequential arrangement of audio objects **Klapuri, "Audio Signal Processing"**. This temporal editing view does not take into account the \enquote{spatial} aspect of audio. Under the \emph{object-based audio} paradigm, each sound source (or \enquote{object}) is treated as an independent entity accompanied by metadata describing its spatial attributes -- namely, the location of \emph{spatial audio} in a 3D space **Xia, "Spatial Audio Processing"**. For spatial editing, DAWs offer 3D panners, which are tools to control the position of each audio object in a 3D space **Hartung, "Audio Effects"**.

There are several approaches to spatial audio rendering, and we can highlight two in the context of object-based audio workflows **Rajan, "Object-Based Audio"**. The first is \emph{loudspeaker stereophony}, which consists in placing multiple speakers around the listener to create a surround sound experience commonly used in cinemas, home theaters, and gaming. A limitation of loudspeaker-based setups is that the listener must typically remain in an optimal \enquote{sweet spot} to fully appreciate the intended spatial effect, and phantom sound sources (i.e., perceptual illusions of sound sources) are restricted to positions between the speakers. The second approach, thanks to which many of audio-augmented XR applications are possible, is \emph{binaural rendering}. This method reproduces 3D audio using only two channels, simulating how sound is perceived by the human auditory system **Wenzel, "Binaural Audio"**. By convolving audio signals with head-related transfer functions (HRTFs), which model how sound interacts with anthropometric features, binaural rendering can simulate the localization, timbre, and externalization of sound sources, creating a realistic perception of spatial objects in a 3D environment.
However, this approach has some limitations **Bruns, "Audio Signal Processing"**.

\subsection{XR tools for Sound Design and Audio Mixing}
 A subset of design tools in XR utilize the flexibility of a spatial interface to interact with floating GUIs comprising of drag-and-drop UIs that can be manipulated with controllers. A notable commercial example is \emph{DearVR}, which uses virtual knobs and faders with a similar appearance of a music production studio **Schmidt, "Virtual Audio Mixing"**. Several research works in sound design **Tamura, "Sound Design for VR"**, have utilized a VR headset to recreate a virtual mixing environment, similar to the panning tools in DAWs, where users can control audio objects positioned at a distance with a controller and raycast to select the objects while remaining stationary.

By contrast, AudioMiXR integrates 6DoF direct free-hand manipulation into the audio mixing workflow, allowing the user to traverse a real or virtual environment, directly grab virtual audio objects, and reposition them wherever they see fit -- this way, enabling true \emph{hands-on} editing of spatial sound as if the users were \enquote{inside the panner}, in ways conventional DAW panners or existing VR mixing tools cannot.

% localization of sound and visual elements for object placement that can be facilitated with 6DoF. %%%% Can specify theirs is not 6DoF
%--- ADD THAT WE DO DIRECT INTERACTIONS FOR MIXING WHERE THE MIXING TOOLS SPECIFICALLY DO NOT

These interfaces and others in sound design research for XR design interfaces that do not fully depend on the users position, translation, and orientation to assist in creating the soundscape or mix.

Research in audio augmented reality (AAR) has leveraged the physical environment to augment auditory feedback rendered to the user targeted \emph{navigation and location-awareness}, as spatialized \enquote{audio beacons}, verbal instructions, or guides **Scheible, "Audio Augmented Reality"**. Studies have underscored its potential for diverse domains, including  \emph{presentation and display}, particularly in museums or archaeological sites that use audio augmentations to deliver contextual information about cultural artifacts, or increase engagement with visitors at art exhibitions through spatialized sonic artwork like \emph{Sonic Sculpture} **Weiss, "Spatialized Artwork"**. 

Beyond gaming, audio-visual augmentations have been embedded in a variety of prototypes for \emph{entertainment and recreation}, such as the AR/DJ system **Gruner, "AR DJ System"**, which introduced
% visualizes sound sources in a virtual 3D model of the dance floor.real-time 3D sound placement in a club setting by allowing the DJ to visualize a virtual 3D model of the dance floor, %offering DJs the ability to place 3D audio objects anywhere in the room.

This is not an exhaustive list and there are many other papers that could have been included **Khalifa, "Spatial Audio"**.