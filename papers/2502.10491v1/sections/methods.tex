\section{Methods} \label{section:methods}

\subsection{Structure-informed Positional Encoding}

As we hinted in Section \ref{section:background}, positional encoding depends on a sequence $\mathcal{P} = [ p_1, p_2, ... , p_T ]$ of positional indices. In standard PE, which does not utilize structure, $p_i = i$, which makes $\mathcal{P}$ a linear grid. When structure is included in PE, $p_i = s_\ell (i)$, where $s_\ell (i)$ gives the structural label at level $\ell$ (e.g. chord) for timestep $i$. In this case, $s_\ell (i) = s_\ell (i^{\prime})$ is possible for $i \neq i^{\prime}$, making $\mathcal{P}$ a non-linear grid. In fact, we can consider vectorial positional indices with multiple resolutions of structural organization. Consequently, we obtain $p_i = \mathbf{s} (i)$, where $\mathbf{s} (i) = [ s_1 (i) , ..., s_\ell (i), ..., s_L (i) ]$ is a vector of $L$ structural labels. Viewed in this way, PEs with structure can simply be used as a drop-in replacement for PEs without structure by replacing the form of $p_i$, giving us richer positional information. This is a way to flexibly represent domain-specific prior knowledge about the underlying data domain.

\subsection{Asymptotic case of SPE: Random Fourier Features} \label{ssection:asymptotic_rff}

We can express the SFF approximation of the positional matrix $\mathbf{P}_d$ for arbitrary timesteps $m$ and $n$ as:
\begin{equation} \label{eq:sff_mn}
    \mathbf{P}_d[m, n] \approx \left[ \Omega_\mathcal{Q}^d [m, :] (\mathbf{Z}_d \mathbf{Z}_d^\top) \Omega_\mathcal{K}^{d^\top} [:, n] \right] / R \\
\end{equation}

where we use the abbreviation $\Omega_\mathcal{A}^d = \boldsymbol{\Omega}\left(\mathcal{P}_\mathcal{A}, \boldsymbol{f}_d, \boldsymbol{\theta}_d^A \right) \text{diag}\left(\ddot{\boldsymbol{\lambda}_d}\right)$. We observe that $\mathbf{Z}_d \mathbf{Z}_d^\top = \widehat{\mathbf{C}}_d$ acts as an empirical covariance matrix for the sinusoidal features $\Omega_\mathcal{Q}^d$ and $\Omega_\mathcal{K}^d$. Since $\mathbf{Z}_d$ has zero mean and unit variance, as $R \to \infty$, $\widehat{\mathbf{C}}_d$ approaches the theoretical covariance matrix $\mathbf{C}_d = \mathbf{I}_{2K}$.
In the ideal case of $\mathbf{C}_d$, Equation \ref{eq:sff_mn} simplifies to $\mathbf{P}_d[m, n] \approx \Omega_\mathcal{Q}^d [m, :] \Omega_\mathcal{K}^{d^\top} [:, n]$, giving:
\begin{equation} \label{eq:ideal_C}
    \mathbf{P}_d[m, n] \approx  \frac{1}{N_f}  \sum_{\omega = 1}^{N_f} \Lambda_\omega \cos \big( f_{\omega} ( \mathcal{P}_Q[m] - \mathcal{P}_K[n] ) + \Theta_\omega \big)
\end{equation}
where $\Lambda_\omega$ is the gain contributed by the matrices $\text{diag}\left(\ddot{\boldsymbol{\lambda}_d}\right)$ and $\Theta_\omega$ is the phase-shift contributed by $\boldsymbol{\theta}^Q_d$ and $\boldsymbol{\theta}^K_d$.

This representation has been studied in previous work, where it is called \textit{Random Fourier Features} (RFF) \cite{rahimi_random_2007, sutherland_error_2015}.

\subsection{F-StrIPE}

We can redesign the positional feature matrices to be:
\begin{equation} \label{eq:rff}
    \mathbf{P}^{Q/K}_d = \boldsymbol{\Omega}\left(\mathcal{P}_{Q/K}, \boldsymbol{f}_d, \boldsymbol{\theta}_d^{Q/K}\right) \text{diag}\left(\ddot{\boldsymbol{\lambda}_d}\right) / \sqrt{N_f}
\end{equation}
where the sinusoidal feature matrix $\boldsymbol{\Omega}$ is given by:
\begin{equation} \label{eq:sff:sinusoidal_features}
    [\boldsymbol{\Omega}(\mathcal{P}, \boldsymbol{f}, \boldsymbol{\theta})]_{i j}= \begin{cases}\cos \left(2 \pi \mathbf{f}[\omega, :]^\top p_i+\boldsymbol{\theta}[\omega]\right) & \text { if } j = 2\omega \\ \sin \left(2 \pi \mathbf{f}[\omega, :]^\top p_i+\boldsymbol{\theta}[\omega] \right) & \text { else }\end{cases}
\end{equation}
Here, unlike (\ref{eq:sff:sine_features}) where $\mathbf{f}[\omega]$ was a single frequency, $\mathbf{f}[\omega, :]$ is a vector of frequencies. Each frequency $\mathbf{f}[\omega, \ell]$ in this vector acts on the $\ell^{\text{th}}$ structural label at timestep $i$, where we can use the vectorial formulation of structure-aware positional indices $p_i = \mathbf{s}(i)$.

With this, we can now formulate F-StrIPE by modifying (\ref{eq:spe:ohyeah}) to use $\mathbf{P}^{Q/K}_d$ in place of $\thicktilde{\mathbf{P}}^{Q/K}_d$, giving us $\mathbf{Q}^{\text{RFF}}/\mathbf{K}^{\text{RFF}}$ in place of $\mathbf{Q}^{\text{SFF}}/\mathbf{K}^{\text{SFF}}$. In the second row of Figure \ref{fig:visualize_matrices}, similar to SFF, we show the different components of RFF in the case where we assume gains to be 1 and phase shifts to be 0. RFF can be understood as the ideal case of SFF where $R \to \infty$. Seen in this way, RFF can give us a noiseless estimate of $\mathbf{P}_d$ with direct access to the theoretical covariance matrix $\mathbf{C}_d$.

In addition, if we pair $\mathbf{Q}^{\text{SFF}}/\mathbf{K}^{\text{SFF}}$ with the sinusoidal features given in Equation \ref{eq:sff:sinusoidal_features}, in place of those given in Equation \ref{eq:sff:sine_features}, we obtain a richer version of SPE which accepts multi-dimensional structural information instead of time indices. To distinguish it from SPE, we name this variant F-StrIPE:SFF.

\subsection{Assessing with music generation}

\subsubsection{Dataset and Input Representation} \label{sssection:data_input}
We use the Chinese POP909 dataset~\cite{wang_pop909_2020} and three levels of structural labels with different resolutions~\cite{dai_automatic_2020}: melodic pitch ($16^{th}$-note), chord (quarter-note) and phrase (bar). Each MIDI file in this dataset consists of three tracks: melody, bridge (second melody) and piano (accompaniment). 
We use the POP909 alignment dataset~\cite{agarwal_structure_2024} to correctly match the structural labels with the input. We convert the MIDI files to binary pianorolls $\mathbf{X} \in \mathbb{B}^{(n_\text{tracks} \times 128) \times n_\text{time}}, \mathbb{B} = \{0, 1\}$, where $n_\text{tracks}$ is the number of tracks and $n_\text{time}$ is the number of timesteps in the pianoroll.

\subsubsection{Task Setup}
We use a symbolic music generation task, namely, melody harmonization, to test the efficacy of our method. Given the pianoroll for the melody and bridge tracks $\left[ \mathbf{x}_n \in \mathbb{B}^{(n_\text{tracks} - 1) \times 128} \right]$, the model must predict all tracks $\left[ \mathbf{y}_n \in \mathbb{B}^{n_\text{tracks} \times 128} \right]$. We expect the model to predict the complete accompaniment track for all timesteps at once, without conditioning later predictions on earlier predictions. 
% We use three settings: (16, 16), (16, 64) and (64, 64), where the first number is the sequence length (in bars of music) used for training and the second number is that used for testing.
We use two settings: (16, 16) and (16, 64), where the first number is the sequence length (in bars of music) used for training and the second number is that used for testing.

\subsubsection{Model and Training}
We use a 2-layer causal encoder Transformer with 4 heads and 512 model dimension. Training for 15 epochs with a batch size of 8, we use gradient clipping and curriculum learning~\cite{bengio_curriculum_2009}. We use two learning rate schedulers: a linear warmup and an epoch-wise decay.
We do a grid-search for two hyperparameters: learning rate (choices: $\{ 1, 5, 10 \} \times 0.0001$) and post-processing binarization strategy~\cite{agarwal_structure_2024} (choices: thresholding, thresholding with merge). The thresholding strategy binarizes based on a fixed threshold and the thresholding with merge strategy allows us to additionally fill in the gap between two binary notes if the gap is less than a minimum merge distance.

\subsubsection{Baselines and Our Methods} \label{sssection:baselines}
We consider three types of baselines: (i) Transformers without PE (NoPE), (ii) Transformers with efficient, approximate atttention but no structural information in PE (SPE~\cite{liutkus_relative_2021}), and (iii) Transformers with structural information in PE but using inefficient, exact attention (S S-RPE~\cite{agarwal_structure_2024}).
From our methods, we use F-StrIPE with the three structural levels described in Section \ref{sssection:data_input}. We also assess the influence of different random features with F-StrIPE:SFF using all structural levels. 
We perform ablations on F-StrIPE by selecting one level at a time during training. Finally, we use the best-performing structural level from the F-StrIPE ablations to additionally do an ablation study with F-StrIPE:SFF.

\subsubsection{Evaluation}
To compare our predictions with the targets, we choose a collection of musically-motivated metrics from the literature guided by four criteria. To assess large- and small-scale structural properties, we use Self-Similarity Matrix Distance (SSMD)~\cite{wu_musemorphose_2021}, where we compute the mean absolute difference between self-similarity matrices obtained from the pairwise cosine similarity of the chromas of the target music and generated music. For rhythmic and melodic consistency, we use Grooving pattern Similarity (GS)~\cite{wu_jazz_2020} and Chroma Similarity (CS)~\cite{wu_musemorphose_2021}, respectively. GS is the overlap between the note onset histograms of the target and prediction, whereas CS is the average cosine similarity between the chroma onset vectors of the target and prediction. To gauge polyphonicity, we use Note Density Distance (NDD)~\cite{agarwal_structure_2024, haki_real_2022}, which is the mean absolute difference in note density between the target and prediction. For a more detailed description of the metrics, we refer readers to previous work~\cite{agarwal_structure_2024}.
