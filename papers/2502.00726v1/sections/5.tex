\section{Perspectives}

\subsection{MADRL Should Leverage Direct Interpretability}

Engaging and expanding interpretability is an opportunity to address existing challenges in MADRL. Direct approaches are particularly well-suited for analysing communication dynamics, coordination strategies, and emergent behaviours in MAS. Graph-based analysis, for instance, could provide insights into inter-agent interactions, while feature importance techniques can identify biases and ensure fairness in decision-making. By systematically exploring and applying scalable direct methods to trained models, researchers can better address the inherent complexities of MADRL, enabling the development of more transparent, robust, and accountable systems for real-world applications.

Although previous calls to action are prone to integrate interpretability beforehand \cite{rodriguez2024explainable}, this paper claims that the interpretation of models post hoc is highly valuable. Direct interpretability offers greater flexibility, particularly for existing models where architectural modifications are impractical. 

\subsection{Robust Evaluation Protocols}

As repeatedly outlined, direct post-hoc methods are easily actionable and scalable.
However, their adoption requires acknowledging and addressing limitations such as the inherent shortcomings of saliency maps \cite{Adebayo2018SanityCF,Bilodeau2022ImpossibilityTF}, counterfactual explanations \cite{Laugel2019TheDO}, or other interpretability illusions \cite{Bolukbasi2021AnII,Friedman2023InterpretabilityII,Friedman2023InterpretabilityII}. In fact, these methods often generate metrics with limited predictive power, and thus, claims should be reasonable.


A key priority is the development of robust evaluation protocols for direct methods. Given the absence of ground-truth explanations, reliable metrics and standardized evaluation frameworks must be established to assess the quality and utility of these methods \cite{Gill2020ARM,Madsen2021PosthocIF,Amorim2023EvaluatingPI,Hedstrm2022QuantusAE,Wei2024RevisitingTR,Huang2024RAVELEI,Chaudhary2024EvaluatingOS}. 
Advancing evaluation thoroughly, e.g., by evaluating out of distribution, is especially important to develop scalable, effective, and actionable interpretability solutions.
