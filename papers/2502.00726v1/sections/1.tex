
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/XMADRL.pdf}
    \caption{Visual taxonomy of MADRL challenges that could benefit from direct interpretability methods. In green (dots) challenges related to a single agent, in blue (short dashes) to multiple agents and in red (long dashes) to the training process.
    }
    \label{fig:xmadrl}
\end{figure}

\section{Introduction}
\label{sec:introduction}
The increasing complexity of agents trained by Reinforcement Learning (RL) has raised significant safety and ethical concerns \cite{mitelut2023intentaligned,shavit2023practices,Vishwanath2024ReinforcementLA}. These considerations are even more crucial when training multiple agents based on Deep Neural Networks (DNNs), commonly referred to as black boxes, i.e., in Multi-Agent Deep Reinforcement Learning \cite{Chelarescu2021DeceptionIS}. MADRL enables solving more complex problems through cooperation or opponent modelling \cite{HernandezLeal2018ASA,Gronauer2021MultiagentDR,Wong2021MultiagentDR}, and finds applications in robotics \cite{Orr2023MultiAgentDR}, video games \cite{Vinyals2019GrandmasterLI} or even health \cite{Shaik2023AdaptiveMD}.
Recent advancements, such as pre-trained world models \cite{Reed2022AGA,Yang2023FoundationMF, alonso2024diffusionworldmodelingvisual,Bruce2024GenieGI} and the integration of Large Language Models (LLMs), as standalone agents \cite{Wang2023ASO} or within Multi-Agent Systems (MAS) \cite{wu2023autogen,Li2024ASO,Han2024LLMMS}, further exacerbate the interpretability challenge.
While the field of eXplainable RL (XRL) is growing by the year \cite{Heuillet2020ExplainabilityID,Milani2023ExplainableRL,Qing2022ASO,Hickling2022ExplainabilityID,Bekkemoen2023ExplainableRL}, with one of the first dedicated workshops organised at the first RL Conference edition \cite{Kohler2024TowardsAR}, interpretability is anecdotal in MADRL \cite{Heuillet2021CollectiveEA,Wang2021SHAQIS,Milani2022MAVIPERLD, Zabounidis2023ConceptLF, Mahjoub2023EfficientlyQI,Khlifi2023OnDF}. Yet, as we expose in Section~\ref{sec:advocate}, interpretability could help advance specific challenges in MADRL, such as team identification, swarm coordination and sample efficiency.

Existing efforts in agent interpretability predominantly focus on intrinsically interpretable models \cite{Heuillet2020ExplainabilityID,Milani2023ExplainableRL,Qing2022ASO,Hickling2022ExplainabilityID,Bekkemoen2023ExplainableRL}, emphasising simplicity in architecture to make systems inherently understandable \cite{Chattopadhyay2022InterpretableBD,Rodriguez2024DesignPF}. However, these approaches often need to be revised for large and performant systems where expressiveness, scalability and flexibility are essential \cite{Rudin2021InterpretableML}. 
We thus propose to focus on direct interpretability, i.e., methods that are post-hoc, applicable after training, and generate explanations directly from DNNs. This class of methods enables probing complex systems without constraining their design or needing to extract an interpretable model.
Inspired by modern interpretability methods \cite{zou2023representation,Cunningham2023SparseAF, Dunefsky2024TranscodersFI,Katz2024BackwardLP}, and new XRL approaches \cite{Levin2023ClusteredPD,Seong2024SelfSupervisedIE,Lange2024InterpretableBR}, we decided to anticipate the adoption of explainability in the expanding field of MADRL and encourage the AAMAS community to use and engage more systematically with modern direct interpretability methods.
% %

We list our contributions as follows:
\begin{itemize}
    \item Arguments to engage with
    direct interpretability methods.
    \item A taxonomy to position direct interpretability in MADRL.
    \item Potential applications of direct interpretability to solve modern MADRL challenges.
\end{itemize}
In this article, we first present an initial background about the systems of study and the methods advocated. Then, we propose a simple taxonomy to position modern interpretability methods in the MADRL framework. Finally, we outline the limitations of some current works while proposing alternative ideas tracks.

