\section{Concluding Remarks}
The training framework of Satori exhibits significant potential for enhancing LLM reasoning capabilities. The small-scale format tuning stage serves as a warm-up phase, allowing the LLM policy to internalize a specific reasoning format, while large-scale reinforcement learning (RL) plays a crucial role in incentivizing intrinsic reasoning abilities. We believe that this framework can inspire the research community to explore more methods for achieving autoregressive search, such as developing reasoning formats with a broader range of meta-actions, designing more advanced RL algorithms, and extending this approach to general domain.