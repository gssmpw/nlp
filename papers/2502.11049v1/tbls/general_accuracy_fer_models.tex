\begin{table}[b]
\caption{General accuracy of the models (in percent). Four models—MobileNet, ResNet, XceptionNet, and ViT—were trained on the full training samples of all datasets and evaluated using their respective validation sets. The CLIP model was fine-tuned on the training sets and validated using the validation set, while GPT-4o-mini was evaluated solely on the validation sets, without any training or fine-tuning.}
\label{tbl:general_accuracy_fer_models}
\centering
\small
\setlength{\tabcolsep}{4pt} % Adjust the column spacing (default is 6pt)
\resizebox{1\linewidth}{!}
{{
\begin{tabular}{l|>{\color{mediumgray}}c>{\color{mediumgray}}c>{\color{mediumgray}}c>{\color{mediumgray}}c>{\color{mediumgray}}c>{\color{mediumgray}}c>{\color{mediumgray}}c|cc}
            & \color{black}Neu & \color{black}Hap & \color{black}Sad  \color{black}
            & \color{black}Sur & \color{black}Fea & \color{black}Dis & \color{black}Ang
            & Mean & STD  \\
            \hline
MobileNet   & 66.6 & 86.8 & 53.2 & 60.1 & 45.6 & 31.0 & 57.5  & 57.3 & 17.4 \\
ResNet      & 73.8 & 84.1 & 48.0 & 60.2 & 38.2 & 24.4 & 54.0  & 54.7 & 20.4 \\
XceptionNet & 77.3 & 82.3 & 51.5 & 61.3 & 44.8 & 24.7 & 57.7  & 57.1 & 19.6 \\
ViT         & 75.3 & 86.7 & 56.5 & 64.0 & 42.8 & 25.1 & 64.3  & 59.2 & 20.4 \\
CLIP        & 79.7 & 85.1 & 44.1 & 45.1 & 25.8 & 9.4  & 43.8  & 47.5 & 25.8 \\
GPT-4o-mini & 72.6 & 79.5 & 56.8 & 62.9 & 27.6 & 34.9 & 62.1  & 56.6 & 17.5
\\
\hline
\end{tabular}
}}
\end{table}





% \begin{table*}[b] 
% \caption{General accuracy for each model (in percent). ViT model pays attention to the local and global features in the image, therefore, it provides the best results. A comparison between MobileNet and two residual-based modes (ResNet and XceptionNet) demonstrates that residual passing has no good effect on the facial expression recognition task.}
% \label{tbl:general_accuracy_fer_models}
% \centering
% \small
% \resizebox{0.65\textwidth}{!}
% {{
% \begin{tabular}{l|ccccccc|cc}
%             & Neutral & Happy & Sad  & Surprise & Fear & Disgust & Anger & Mean & STD  \\
%             \hline
% MobileNet   & 66.6    & 86.8  & 53.2 & 60.1     & 45.6 & 31.0    & 57.5  & 57.3 & 17.4 \\
% ResNet      & 73.8    & 84.1  & 48.0 & 60.2     & 38.2 & 24.4    & 54.0  & 54.7 & 20.4 \\
% XceptionNet & 77.3    & 82.3  & 51.5 & 61.3     & 44.8 & 24.7    & 57.7  & 57.1 & 19.6 \\
% ViT         & 75.3    & 86.7  & 56.5 & 64.0     & 42.8 & 25.1    & 64.3  & 59.2 & 20.4 \\
% Clip        & 79.7    & 85.1  & 44.1 & 45.1     & 25.8 & 9.4     & 43.8  & 47.5 & 25.8 \\
% GPT-4o-mini & 72.6    & 79.5  & 56.8 & 62.9     & 27.6 & 34.9    & 62.1  & 56.6 & 17.5
% \\
% \hline
% \end{tabular}
% }}
% \end{table*}