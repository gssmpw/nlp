To achieve responsive and efficient control, our proposed approach relies on a noise-relaying buffer and the implemented sequential denoising machanism at its core (\Cref{sec:noise_relaying_buffer}) with additional key design choices (\Cref{sec:key_design_choices}). More details of the implementation including policy architecture and hyperparameters are summarized in \Cref{sup:implementation_details}.

\subsection{Noise-Relaying Buffer}
\label{sec:noise_relaying_buffer}

The noise-relaying buffer \(\mathbf{\tilde{Q}}_t = \{ \mathbf{a}_{t}^{(1)}, \mathbf{a}_{t+1}^{(2)}, \dots, \mathbf{a}_{t+f-2}^{(f-1)}, \mathbf{a}_{t+f-1}^{(f)} \}\) contains a sequence of noisy actions with linearly increasing noise levels from \(1\) to \(f\), where \(f\) is the buffer capacity as well as the total number of noise levels. As shown in \Cref{fig:inference_overview}, after each denoising step, the trained network transforms \(\mathbf{\tilde{Q}}_t\) into \(\mathbf{Q}_t = \{ \mathbf{a}_{t}^{(0)}, \mathbf{a}_{t+1}^{(1)}, \dots, \mathbf{a}_{t+f-2}^{(f-2)}, \mathbf{a}_{t+f-1}^{(f-1)} \}\), producing a noise-free action \(\mathbf{a}_t^{(0)}\) at the head. This clean action is immediately executed, and a fully noisy action is appended to the buffer's tail. For the next step, the buffer reuses \(f-1\) denoising steps from previous outputs, ensuring consistency and avoiding full denoising from scratch. This sequential denoising mechanism conditions clean actions on the latest observations, enabling responsive and long-term active control. Pseudocode is provided in \Cref{alg:inference}.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.70\linewidth]{figures/main.pdf}
    \caption{
    \textbf{Inference Overview of Responsive Noise-Relaying Diffusion Policy (RNR-DP).}
    The core of RNR-DP is the noise-relaying buffer (\Cref{sec:noise_relaying_buffer}) and it has 3 stages during the entire control-loop, as exemplified by the transition between time step \(t\) and time step \(t+1\), \textbf{(1)} The buffer contains noisy actions with increasing noise levels \textbf{(2)} After denoising once, each action in the buffer is denoised for one step, clean action at the buffer's head is removed and executed (\textbf{\textcolor[HTML]{00A651}{dequeue}}) \textbf{(3)} The remaining noisy actions are left shifted for one slot and a fully noisy action is appended to the buffer's tail (\textbf{\textcolor{red}{enqueue}}).
    The conditioning data is discussed with more details in \Cref{sec:key_design_choices} and \Cref{sup:policy_architecture}.
    }
    \vspace{-8pt}
    \label{fig:inference_overview}
\end{figure*}


\subsection{Key Design Choices}
\label{sec:key_design_choices}

\textbf{Mixture Noise Scheduling}
We train the denoiser network following the DDPM \citep{ho2020denoising} framework, and allow each action in \(\mathbf{A}_t\) perturbed by independent noise levels. Given a fixed variance schedule \(\beta_1, \ldots, \beta_f\) (\(\beta_1 < \beta_f\)), any \(\mathbf{a}_j\) in \(\mathbf{A}_t\) can be perturbed by one of the \(f\) levels. During training, we use a mixed per-action noise injection scheme (\emph{mixture schedule}): with probability \(p_{\mathrm{linear}}\), actions are perturbed by linearly increasing variances (\emph{linear schedule}); with probability \(1-p_{\mathrm{linear}}\), actions are perturbed by random variances from \(\beta_1\) to \(\beta_f\) (\emph{random schedule}). The \emph{random schedule} trains the model to denoise actions independently \(p_\theta(\mathbf{a}^{(k-1)} \mid \mathbf{a}^{(k)}; \mathbf{O}), 1 \leq k \leq f\), while the \emph{linear schedule} ensures smooth transitions across consecutive actions during inference. Unlike Diffusion Policy, which applies a single variance level to all actions in \(\mathbf{A}_t\) per iteration, our mixture schedule enables diverse and robust training.

\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{%
        \includegraphics[width=0.6\linewidth]{figures/laddering_initialization.pdf}
    }
    \caption{
    \textbf{A visulization of the initialization process.} Noise-relaying buffer contains only fully noisy actions sampled from standard multivariate Gaussian distribution of dimension $T_a$ at each action index before the initialization; the buffer is denoised for $f$ times until the buffer head contains minimal noise level and can be executed with one more model forward call.
    }
    \label{fig:laddering_initialization}
\end{figure}

\textbf{Laddering Initialization}
During inference, we use a noise-relaying buffer with \(f\) noisy action frames, following \Cref{alg:inference}. Initially, the buffer contains \(f\) fully noisy actions sampled from \(\mathcal{N}(\mathbf{0}, \mathbf{I})\), i.e., \(\tilde{\mathbf{Q}} = \{\mathbf{z}_j \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \mid j = 1, \ldots, f\}\). To align with training and avoid performance drops, we initialize the buffer by iteratively denoising it \(f\) times using the \emph{random schedule} conditioned on the initial observation \(\mathbf{O}_0\). This transforms the buffer to follow the \emph{linear schedule}, ensuring smooth and responsive control. Since this process transitions the buffer from uniform noise to monotonically increasing variances like a ladder, we term it \emph{laddering initialization}, as illustrated in \Cref{fig:laddering_initialization}.

\textbf{Noise-Aware Conditioning}
Unlike Diffusion Policy \citep{chi2023diffusion}, which encodes a single diffusion step to one time embedding, our approach uses mixed scheduling and a noise-relaying buffer to handle multiple noise levels, requiring awareness of multiple diffusion steps. For each actionâ€™s noise level \(k_j \ (1 \leq k_j \leq f)\), we use an MLP to encode a time embedding, yielding \(f\) embeddings. These are appended to the observation features from the encoder \(E_{\mathrm{obs}}\). This allows the buffer, during both training and inference, to decode actions at each noise level using up-to-date observations, enabling more dynamic and consistent behaviors. See \Cref{sup:policy_architecture} for more details.
