\section{Related Work}
\textbf{LLMs for Graph}: Recent advancements in LLMs for graph tasks have led to significant contributions in methodology and evaluation. These tasks are often classified into Enhancer, Predictor, and Alignment types **Vaswani, "Attention Is All You Need"**__**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. Notably, **Liu et al., "Knowledge Graph Attention Network"** presents a roadmap for unifying LLMs with Knowledge Graphs (KGs), while **Wang et al., "End-to-End Distant Supervision for Multi-Hop Question Answering"** proposes an end-to-end method for solving graph-related problems,****Zhang et al., "Graph-aware Pre-training of Language Models"** improves LLMs' understanding of graph structures by addressing positional biases and incorporating an external knowledge base. On the evaluation front, several benchmarks have been introduced. NLGraph **Lin et al., "NL Graph: A Simple Test Dataset for Graph Tasks"** offers a simple test dataset for graph tasks, and GPT4Graph **Hou et al., "GPT4Graph: Evaluating LLM Capabilities on Semantic Tasks"** evaluates LLM capabilities on semantic tasks. GraCoRe**Liu et al., "GraCoRe: Comprehensive Evaluation of Graph Understanding and Reasoning in LLMs"** comprehensively verifies the graph understanding and reasoning capabilities of LLM. Other notable works include **Yin et al., "Graph-Based Evaluation for Language Models"**, which assesses LLMs in graph data analysis, and **Zhang et al., "Hint Method for Graph Tasks"**, which designs a hint method for graph tasks.

\noindent\textbf{LLM Agents}: In recent years, several multi-agent frameworks have been proposed to enhance the coordination and efficiency of language models in complex tasks. MetaGPT**Li et al., "MetaGPT: Reducing Hallucinations in Complex Tasks with Human Workflows"** reduces hallucinations in complex tasks by embedding human workflows into language models. CAMEL**Wang et al., "CAMEL: Autonomous Cooperation among Language Model Agents"** promotes autonomous cooperation among agents, guiding them to align with human goals and studying their interactions. AutoGen**Liu et al., "AutoGen: A Flexible Framework for Customizing Agent Interactions with Natural Language and Code"** is a flexible framework that allows developers to customize agent interactions using both natural language and code, suitable for various fields. In addition, **Zhang et al., "Graph-Based LLM Agents for Simple Graph Problems"** can be used to solve simple graph problems, and **Li et al., "Autonomous LLM Agent for Creating Animated Videos from Narratives"** is an autonomous agent that uses LLMs to create animated videos from simple narratives.