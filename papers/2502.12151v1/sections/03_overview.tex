
% \begin{figure}[t]
%     \small
%     \centering
%     \includegraphics[width=0.6\textwidth]{VoluLUT/figures/arch.pdf}
%     \vspace{-.0in}
%     \caption{\small The System Architecture of \name.}
%     \label{fig:arch}
%     \vspace{-.0in}
% \end{figure}





% \name is a novel approach to streaming volumetric video content with super-resolution enhancement. It aims to deliver high-quality volumetric video-on-demand from an Internet server to client hosts. On server side, the video is segmented into chunks with fixed number of frames and further encoded with dynamic resolution (\ie point densities). \anlan{[Why does \name need to encode a video into different quality levels, given that it does continuous ABR?]} As shown in Figure~\ref{fig:arch}, Upon receiving the downsampled frames from the server, the client performs super-resolution(SR) using our efficient approach. The SR process consists of two main steps: kNN-based interpolation and colorization (\S\ref{sec:inter}), followed by fine-tuning of the interpolated points using our model-defined LUTs (\S\ref{sec:lut}). The kNN-based interpolation increases the point density of the low-resolution point clouds, while the colorization step assigns appropriate colors to the upsampled points. The fine-tuning step, which utilizes our pre-computed LUTs, further enhances the visual quality of the upsampled point clouds. The point clouds with restored resolution are then rendered for the users. 

% To achieve real-time SR performance, \name employs several optimizations tailored for SR-enhanced volumetric video streaming. These optimizations include boosting the interpolation with dilation (\S\ref{sec:inter}), transforming the reference finetuning model to Look-up Table (LUT) for efficient inference (\S\ref{sec:lut}) and reusing the knn result to avoid extra computation. These approaches ensures the quality and latency of the SR is only slightly impacted by the quality ratio, which allows continuous scale super-resolution.

% The \name makes the crucial decision to determine an optimal downsampling ratio based on the current network and buffer conditions (\S\ref{sec:ABR}). This continuous ratio is then sent to the server, which applies it to the requested video frames before transmitting them to the client. By dynamically adjusting the downsampling ratio and combining adaptive downsampling, efficient SR techniques, and optimized streaming logic, \name adapts to varying network conditions and ensures efficient bandwidth utilization while delivering high-quality volumetric video content to clients.

\name enables high-quality streaming of volumetric video content by combining adaptive bitrate streaming with super-resolution enhancement. The server segments videos into fixed-length chunks and encodes them at requested point densities. 

As shown in Figure~\ref{fig:arch}, the client processes received low-resolution frames through three stages: kNN-based interpolation with dilation to increase point density (\S\ref{sec:inter}), colorization based on spatial relationships (\S\ref{sec:inter}), and LUT-based fine-tuning to enhance visual quality (\S\ref{sec:lut}). To achieve real-time performance, \name transforms neural networks into memory-efficient LUTs and reuses kNN results across pipeline stages, ensuring stable quality and latency across different upscaling ratios.

The system dynamically selects optimal downsampling ratios based on network conditions and buffer status (\S\ref{sec:ABR}). Through this combination of adaptive downsampling and efficient super-resolution, \name delivers high-quality volumetric video while optimizing bandwidth utilization across varying network conditions.