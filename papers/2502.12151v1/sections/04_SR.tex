

% \subsection{Enhanced Interpolation with Colorization}
% \label{sec:inter}




% \anlan{[I think there lacks a clear motivation on why we want to improve the interpolation stage, as what we essentially care about is the final SR quality. For example, a motivation could be: we try to improve the outcome of the interpolation stage because we find that the final SR quality highly depends on this intermediate result.]}

% The first stage of our SR pipeline addresses the fundamental challenge of increasing point cloud density while maintaining visual quality and computational efficiency. Traditional kNN-based interpolation approaches face critical limitations in their ability to maintain uniform point distributions, often distorting surface geometry particularly in regions with complex features (as shown in fig~\ref{fig:dila-visual}). They also require computationally expensive neighbor search operations that hinder real-time performance, while struggling to restore color information effectively. Our enhanced interpolation framework tackles these challenges through a comprehensive approach that combines dilated sampling \anlan{[We may need to briefly introduce somewhere what dilated sampling is. The reviewers may not know this concept.]}, hierarchical spatial indexing, and fast color recovery.
\begin{figure*}[t]
\small
\includegraphics[width=1\textwidth]{figures/interpolation.png} % Second image
\caption{The pipeline of two-stage Super-resolution with LUT refinement}
\label{fig:lut-pipe}
\end{figure*}





% \subsubsection{Dilated Interpolation for Uniform Upsampling}
% Our approach introduces a novel dilated interpolation technique that fundamentally rethinks point selection for interpolation. Traditional methods that rely solely on k-nearest neighbors often reinforce existing density patterns, creating clusters in already dense regions while leaving sparse areas under-sampled. Our key insight is that by carefully expanding the sampling neighborhood, we can break these density patterns and achieve more uniform point distribution. \anlan{[A potential question could be: why is uniform point distribution better than the original point distribution, as the original point distribution more faithfully follow the ground truth point distribution when the point cloud is captured?]}

% For a point cloud $P = \{p_1, p_2, \ldots, p_n\}$, we first identify a dilated neighborhood for each point $p_i$. This expanded neighborhood is defined as:
% \begin{equation}
% N_{dk}(p_i) = \{p_j \in P | \text{rank}(||p_j - p_i||) \leq d \times k\}
% \end{equation}
% where $d$ is our dilation factor (typically set to 2-4) and $k$ is the desired number of neighbors (usually 8-16). The rank function ensures we select points based on their distance \anlan{[What distance? Explain the notion $||x||$.]} ordering rather than absolute distances, making the method more robust to varying point densities.

% From this expanded pool, we select interpolation partners using a distance-weighted probability distribution:
% \begin{equation}
% P(p_j \in S_i) \propto \frac{1}{||p_j - p_i||} \cdot f(p_j)
% \end{equation}
% where $f(p_j)$ is a feature-preserving weight that considers local surface properties such as normal vectors and curvature. \anlan{[What is $S_{i}$ denoted to?]} This weighted selection strategy ensures closer points have higher selection probability, preserving local surface details, while more distant points maintain a chance of selection to help break density patterns. Surface features are preserved through the feature-aware weighting.

\begin{figure}[t]
\small
\centering
\includegraphics[width=0.48\textwidth]{figures/inter.pdf}
\vspace{-.1in}
\caption{Qualitative upsampling results (from left to right): \emph{Groundtruth}, \emph{Interpolation with dilation}, \emph{Naive knn-based interpolation}. Our method achieves more uniform point distribution while preserving geometric details.}
\vspace{-.3in}
\label{fig:dila-visual}
\end{figure}

\begin{figure}[t]
\small
\includegraphics[width=0.5\textwidth]{figures/interpolationw_dilation.png}
\caption{Interpolation with and without dilation. Receptive Field size = $k \times$ dilation. The dilated approach significantly improves point distribution uniformity and surface coverage.}
\label{fig:dilation}
\end{figure}

% \subsubsection{Hierarchical kNN Computation with Relationship Reuse}
% To make our dilated interpolation approach practical for real-time applications \anlan{[Need some evidences that the original design runs to slowly on commodity/mobile devices.]}, we implement an efficient two-layer octree structure. Unlike traditional octrees that subdivide until reaching a minimum cell size, our approach uses a fixed two-layer structure that balances spatial organization benefits against traversal overhead.

% The octree construction process begins by dividing the point cloud into eight major regions based on the point cloud centroid. Each first-layer region is then subdivided into eight sub-regions, creating leaf nodes that store rich statistical information including point count, density estimation, bounding box, centroid, average normal vector, and curvature. This octree-based spatial division enables efficient pruning during neighbor searches, as regions unlikely to contain relevant neighbors can be quickly eliminated.

% We further optimize performance through neighbor relationship reuse. For each interpolated point $p'$ generated between points $p$ and $q$, we observe that:
% \begin{equation}
% N_k(p') \approx \text{MergeAndPrune}(N_k(p), N_k(q))
% \end{equation}
% where $N_k(p')$ represents the k-nearest neighbors of $p'$. This approximation dramatically reduces computation time by avoiding full neighbor searches for interpolated points.

% \subsubsection{Fast Colorization with kNN Reuse}
% Our colorization approach leverages the spatial relationships computed during geometric interpolation to achieve efficient and accurate color assignment. For each interpolated point $p'$, we compute its color using the closest neighbour point from the original point cloud.

% The reuse of spatial relationships from the geometric interpolation phase eliminates the need for additional neighbor searches during colorization. This optimization, combined with our dilated neighbour selection, enables real-time performance while maintaining high visual quality.

% Our experimental results demonstrate that this enhanced interpolation framework achieves significantly more uniform point distribution compared to traditional kNN interpolation, faster computation through efficient neighbor reuse, and improved color preservation, particularly at object boundaries and in regions with complex texture patterns.



\begin{figure}[t]
\small
\centering
\includegraphics[width=0.48\textwidth]{figures/lut-lookup.png}
\vspace{-.2in}
\caption{ LUT look up example.}
\vspace{-.2in}
\label{fig:lut-lookup}
\end{figure}


\mysubsection{Enhanced Interpolation with Colorization}
\label{sec:inter}

Given a downsampled point cloud along with a desired upsampling ratio, we first perform interpolation to increase the point density.
The quality of the final super-resoluted point cloud critically depends on the initial interpolation stage. Our qualitative results reveal that poor initial point distributions create artifacts (Figure~\ref{fig:dila-visual}) that persist even after neural refinement. Additionally, traditional interpolation methods create a severe performance bottleneck—our measurements on GradPU show that naive kNN-based interpolation consumes over 70\% of the frame time, making real-time operation infeasible.

Central to both interpolation and subsequent refinement is the concept of receptive fields (RF)—the local spatial regions considered when processing each point. As illustrated in Figure~\ref{fig:dilation}, the receptive field determines which neighboring points influence the position and attributes of newly generated points. In traditional kNN approaches, each new point is generated by considering only its k closest neighbors, which causes two distinct problems. First, this method tends to reinforce existing density patterns because points in dense regions have closer neighbors than those in sparse regions, leading to uneven point distributions. Second, the neighbor search operations required for each new point are computationally expensive, especially as the point cloud size grows.
\name enables two optimizations in interpolation stage.

\noindent \textbf{Dilated Interpolation for Uniform Upsampling}
 Our key insight is that by carefully expanding the sampling neighborhood through dilation, we can break the artifact introduced by traditional kNN interpolation while still preserving important geometric features. As shown in Figure~\ref{fig:dilation}, our dilated approach examines a broader spatial region during interpolation, defined by a receptive field of size $k \times d$, where $k$ is the number of neighbors and $d$ is the dilation factor.

For a point cloud $P = \{p_1, p_2, \ldots, p_n\}$, we define a dilated neighborhood for each point $p_i$ as:
\begin{equation}
N_{dk}(p_i) = \{p_j \in P_{n} | P_{n} = \text{Top}_{d \times k}(||p_j - p_i||_2) \}
\end{equation}
where $d$ is the dilation factor, $k$ is the desired neighbor count, and $||x||_2$ denotes Euclidean distance. The Top function orders points by distance increasingly and keeps the first $d \times k$ ones, similar as the request of vanilla kNN. From this expanded neighborhood, we randomly select a subset $S_i$ of points for interpolation based on the target upsampling ratio requirement. 

An alternative solution may interpolate the point cloud to a higher density and perform Farthest Point Sampling~\cite{liAdjustableFarthestPoint2022} (FPS) to the target upsampling ratio. FPS iteratively samples the farthest point and updates the distance, which can preserve geometry feature but introduce unacceptable computation latency ($\geq5$ minutes to downsample a 200K points to 100K points on a commodity desktop).

\noindent \textbf{Hierarchical kNN Computation with Relationship Reuse}
To achieve real-time performance on mobile devices, we adopt an efficient two-layer octree~\cite{schnabel_octree-based_nodate} structure that balances spatial organization against traversal overhead. Our measurements show that naive dilated interpolation takes over 100ms per 100K-points-frame on an Orange Pi, making optimization essential for real-time operation.

The octree divides the point cloud into eight major regions at the first layer, with each region further subdivided into eight sub-regions. While the construction of the octree takes limited effort, its leaf nodes store a subset of the points whose neighbour points are highly likely self-contained. This hierarchical structure enables rapid neighbor search through efficient spatial pruning.

We further accelerate computation through neighbor relationship reuse. For each interpolated point $p'$ generated between points $p$ and $q$, we observe that:
\begin{equation}
N_k(p') \approx \text{MergeAndPrune}(N_k(p), N_k(q))
\end{equation}
where $N_k(p')$ represents the k-nearest neighbors of $p'$. This approximation eliminates redundant neighbor searches while maintaining accuracy.

We colorize new points based on the nearest original point, reusing spatial relationships from geometric interpolation to avoid redundant computations.


\mysubsection{Interpolation Refinement with LUT}
\label{sec:lut}

As discussed in \S~\ref{sec:pcsr}, a refinement function is required to adjust the interpolated point clouds for better visual quality. We propose an LUT-based refinement approach (shown in Figure~\ref{fig:lut-pipe}) that first captures refinement patterns through offline neural network training, then transfers this knowledge into an efficient lookup table for real-time inference.

% \subsubsection{Neural Network Training for LUT Construction}
% \label{sec:NN}

% \anlan{[I think this part needs to be moved to the front, when talking about improving SR quality.]}

% \anlan{[Question: (1) Does the training process follow the same training process applied in GradPU at a high-level? (2) Is the refinement DNN the same as that of GradPU?]}

% Unlike previous approaches that directly predict upsampled point coordinates (shown in Fig~\ref{fig:SR}), our method first learns a refinement function through a neural network, which is later transformed into a lookup table. This two stage NN-baded pointcloud super-resolution solution is firstly proposed in GradPU~\cite{he_grad-pu_2023} and achieves sota performance in terms of visual quality. This decoupling of upsampling and refinement enables more flexible system level optimization and pipelining, which allow better potential to runtime performance.

% The refinement network operates on local point neighborhoods, taking as input a patch centered at each interpolated point with its four nearest neighbors. For each point, the network learns to predict the optimal offset that would move it closer to its correct position in the high-resolution point cloud:
% \begin{equation}
% \delta_i = \text{NN}(p_i, P_h) - p_i
% \end{equation}

% To improve the network's ability to handle different refinement scenarios, we introduce Gaussian noise to the interpolated points during training. This noise injection with standard deviation of 0.02 serves two crucial purposes: it makes the network more robust to varying point positions during refinement iterations, and it helps learn smoother refinement fields around each point.

% Our training objective combines three key components. First, we ensure accurate offset prediction by minimizing the distance between predicted and ground truth offsets. Second, we encourage uniform point distribution through a repulsion term that prevents points from clustering too closely. Third, we add regularization that promotes smooth refinement fields, making the learned function more stable and suitable for LUT conversion.

% The network architecture consists of two main components. The feature extraction stage uses a simplified Point 4D Convolution that operates in 3D space, effectively capturing local geometric patterns while maintaining computational efficiency. This is followed by a lightweight MLP-based predictor that generates the final offset values.

% During training, we process patches of 256 points with a batch size of 32. The network is optimized using Adam optimizer with an initial learning rate of 1e-3, which decays by half every 20 epochs. The entire training process runs for 60 epochs, balancing between refinement accuracy and training efficiency. \anlan{[This can go to Implementation/Evaluation section.]}

% The careful design of our training process ensures that the network learns robust refinement patterns that can be effectively transferred to the lookup table format. By focusing on local geometric relationships and incorporating noise during training, we achieve a refinement function that is both accurate and generalizable. Most importantly, while the training process may be complex, the resulting knowledge can be efficiently encoded into our LUT structure, enabling real-time refinement during inference.



% \subsubsection{Position Encoding and LUT Construction}
% The key challenge in constructing a lookup table for point refinement is converting continuous 3D point positions into discrete indices while preserving geometric relationships. As shown in Figure~\ref{fig:lut-lookup}, our solution involves a three-step encoding pipeline followed by comprehensive table construction and lookup. \anlan{[We may need to clearly introduce the input and output of the LUT first.]}

% \paragraph{Position Encoding Pipeline}
% Given a point and its three nearest neighbors, our encoding process proceeds as follows:

% First, we record the raw positions of the neighborhood. As illustrated in the figure step (a), a typical neighborhood might have coordinates like (1,3,5), (1,6,5), (1,4,3), (1,5,2), representing the actual 3D positions of the points in space. These raw coordinates can span any range of values depending on the input point cloud's scale and position. 

% Next, we perform normalization to achieve translation and scale invariance, shown in step (b). The neighborhood is centered at the reference point and scaled by the neighborhood radius. This transforms our example coordinates to normalized values like (0,0,1), (0,1,1), (0,0.3,0.3), (0,0.7,1). \anlan{[How do you normalize the example coordinates to this value? The normalization process is not very clear to me.]} After this step, all neighborhoods are represented in a consistent coordinate frame within the unit cube, regardless of their original position or scale.

% Finally, in step (c), we quantize the normalized coordinates into 16 discrete levels along each dimension. Our example coordinates become (0,0,15), (0,15,15), (0,5,5), (0,11,15). We chose 16 levels based on experiments balancing precision and memory requirements - it provides sufficient geometric detail while keeping the lookup table size manageable. \anlan{[We may need some numbers to show the trade-off.]}

% \paragraph{Comprehensive LUT Construction}

% After establishing the encoding scheme, we construct the lookup table through an exhaustive enumeration process. With 16 quantization levels for each coordinate (x,y,z) and four points in each neighborhood, we generate all possible input patterns. For a single neighbor point, there are $16^{3}$ possible positions. With four neighbor points, this gives us $(16^{3})^{4}$ possible neighborhood configurations.

% The LUT construction process systematically generates each possible quantized pattern, from ((0,0,0), (0,0,0),(0,0,0),(0,0,0)) to ((15,15,15), (15,15,15), (15,15,15), (15,15,15)). These patterns are then dequantized back to normalized space and fed through our trained refinement network NN. The resulting offset is stored in the corresponding LUT entry pairing with the quantized input as the index. This process help us freeze the NN trained in \S~\ref{sec:NN} with acceptable accuracy loss and significant inference speed-up. \anlan{[How long does it take to generate the LUT? Better to report the number.]}

% For a practical point refinement LUT, the receptive field size and quantization precision must be carefully chosen as they directly impact the memory footprint and refinement quality. For point refinement in 3D space, each point requires three coordinates. Given a receptive field of size n and quantization using b bins per dimension, the LUT requires $b^{3n} \times \text{sizeof}(\text{float})$ bytes of storage, where the factor of 3n in the exponent accounts for three coordinates per point across n points.

% The bin size b determines the granularity of coordinate quantization, with each coordinate dimension divided into b discrete levels. For example, with b=16 bins, each coordinate axis is divided into 16 segments, while b=8 uses 8 bins per axis. This quantization directly affects both storage requirements and refinement precision. For n points in 3D space, we need to store $b^{3n}$ entries since each point requires three coordinates, and each coordinate can take b different values.

% Table~\ref{tab:lut_size} illustrates the memory requirements for various configurations:

% \begin{table}[t]
% \caption{Memory analysis for different LUT configurations}
% \label{tab:lut_size}
% \centering
% \begin{tabular}{@{}l r r r@{}}
% \toprule
% \multicolumn{1}{c}{RF Size (n)} & 
% \multicolumn{1}{c}{Bins (b)} & 
% \multicolumn{1}{c}{Entries ($b^{3n}$)} & 
% \multicolumn{1}{c}{Memory (4B/float)} \\ 
% \midrule
% 2 & 16 & $16^6$ & 16\,MB \\
% 2 & 8 & $8^6$ & 256\,KB \\
% 3 & 16 & $16^9$ & 4\,GB \\
% 3 & 8 & $8^9$ & 8\,MB \\
% 4 & 16 & $16^{12}$ & 1\,TB \\
% 4 & 8 & $8^{12}$ & 2\,GB \\
% \bottomrule
% \end{tabular}
% \end{table}

% Each LUT entry stores a mapping from quantized input coordinates to refinement offsets. The input coordinates are represented as n-tuples of 3D points, while the offsets are stored as floating-point values. The input space quantization follows a uniform discretization strategy, dividing each coordinate's normalized range [0,1] into equally spaced bins. This uniform quantization simplifies both the construction process and runtime lookup operations.

% The choice of bin size presents a crucial trade-off between memory efficiency and refinement precision. Reducing the number of bins from 16 to 8 decreases the memory requirement by a factor of $2^{3n}$, at the cost of reduced coordinate precision. For a receptive field size of 4, this reduction brings the memory footprint from an impractical 1 TB to a more manageable 2 GB, enabling practical deployment while maintaining acceptable refinement quality.

% \mysubsubsection{Position Encoding and LUT Construction}
% \label{sec:lut_construction}

% The key challenge in constructing a lookup table for point refinement is converting continuous 3D point positions into discrete indices while preserving geometric relationships. As shown in Figure~\ref{fig:lut-lookup}, our solution consists of an encoding pipeline for position discretization and a systematic table construction process for storing refinement offsets.

% \paragraph{LUT Construction}
% The lookup table stores precomputed refinement offsets for all possible quantized neighborhood configurations. For a receptive field of size $n$ points with 3 coordinates in 3D space and $b$ quantization bins per dimension, the total number of possible combinations for input indices is:
% \begin{equation}
% N_{entries} = b^n \times 3
% \end{equation}
% As illustrated in step (d) of Figure~\ref{fig:lut-lookup}, each LUT entry maps a sequence of quantized coordinates to a refinement offset in three dimensions:
% \begin{equation}
% \text{LUT}[\text{quantize}(\mathbf{q}_1,\dots,\mathbf{q}_n)] = \text{NN}(\mathbf{q}_1,\dots,\mathbf{q}_n)
% \end{equation}
% The memory requirement for storing these entries with 2-byte floating-point values (float16) for three coordinate offsets is:
% \begin{equation}
% M = N_{entries} \times 2\text{ bytes}
% \end{equation}
% Table~\ref{tab:lut-size} analyzes the memory requirements for different configurations. The selection of bin size $b$ presents a crucial trade-off between memory efficiency and refinement precision. Our implementation uses $b=128$ (7-bit quantization) with a receptive field size $n=4$, resulting in a 1.6 GB lookup table that stores 3D coordinate offsets in $float16$ format. This configuration achieves a good balance between memory efficiency and refinement precision, making the approach practical for real-world deployment.
\mysubsubsection{Position Encoding and LUT Construction}
\label{sec:lut_construction}
The key challenge in constructing a lookup table for point refinement is converting continuous 3D point positions into discrete indices while preserving geometric relationships. As shown in Figure~\ref{fig:lut-lookup}, we address this through a systematic encoding pipeline that transforms raw 3D coordinates into quantized indices for efficient lookup and refinement.
\paragraph{Position Encoding Pipeline}
Our encoding process consists of three key steps:

\BULLET \textbf{Position Input(Stage (a)):} The pipeline takes as input a neighborhood of 3D points represented as $(x,y,z)$ coordinates. For a receptive field of size $n$, we process the target point along with its $n-1$ neighboring points' positions in 3D space.

\BULLET \textbf{Normalization(Stage (b)):} To ensure consistent lookup behavior, we normalize the coordinates relative to the center point:
\begin{equation}
    \mathbf{n}_i = \frac{\mathbf{r}_i - \mathbf{r}_c}{R}
\end{equation}
where $\mathbf{r}_c$ is the center point coordinates and $R$ is the neighborhood radius (maximum distance from any point to the center). This transforms ensuring all points lie within the unit cube $[-1,1]^3$.

\BULLET \textbf{Quantization(Stage (c)):} The normalized coordinates are then discretized into fixed-size $b$ bins to create lookup indices:
\begin{equation}
    \mathbf{q}_i = \lfloor (\frac{\mathbf{n}_i + 1}{2}) \times (b-1) \rfloor
\end{equation}
 This step converts continuous normalized values into discrete integer indices suitable for table lookup, effectively creating a finite set of possible neighborhood configurations. 

\paragraph{LUT Construction and Usage}
The lookup table stores precomputed refinement offsets for all possible quantized neighborhood configurations. For a receptive field of size $n$ points with 3 coordinates in 3D space and $b$ quantization bins per dimension, the total number of possible combinations for input indices is:
\begin{equation}
N_{entries} = b^n \times 3
\end{equation}
As illustrated in step (d) of Figure~\ref{fig:lut-lookup}, each LUT entry maps a sequence of quantized coordinates to a refinement offset in three dimensions:
\begin{equation}
\text{LUT}[\text{quantize}(\mathbf{q}_1,\dots,\mathbf{q}_n)] = \text{NN}(\mathbf{q}_1,\dots,\mathbf{q}_n)
\end{equation}
The memory requirement for storing these entries with 2-byte floating-point values (float16) for three coordinate offsets is:
\begin{equation}
M = N_{entries} \times 2\text{ bytes}
\end{equation}
Table~\ref{tab:lut-size} analyzes the memory requirements for different configurations. The selection of bin size $b$ presents a crucial trade-off between memory efficiency and refinement precision. Our implementation uses $b=128$ (7-bit quantization) with a receptive field size $n=4$, resulting in a 1.6 GB lookup table that stores 3D coordinate offsets in $float16$ format. This configuration achieves a good balance between memory efficiency and refinement precision, making the approach practical for real-world deployment.
\begin{table}[t]
\centering
\begin{tabular}{@{}c c r r@{}}
\toprule
RF Size ($n$) & 
Bins ($b$) & 
Entries ($b^n \times 3$) & 
Size (2B/offset) \\ 
% \midrule
% 2 & 128 & $128^2 \times 3$ & 98\,KB \\
% 2 & 64 & $64^2\times3$ & 24\,KB \\
\midrule
3 & 128 & $128^3\times3$ & 12\,MB \\
3 & 64 & $64^3\times3$ & 1.5\,MB \\
\midrule
4 & 128 & $128^4\times3$ & 1.61\,GB \\
4 & 64 & $64^4\times3$ & 100\,MB \\
\midrule
5 & 128 & $128^5\times3$ & 201\,GB \\
5 & 64 & $64^5\times3$ & 6.25\,GB \\
\bottomrule
\end{tabular}
\vspace{-.1in}
\caption{Memory analysis for different LUT configurations with float16 (2B) storage}
\label{tab:lut-size}
\vspace{-.3in}
\end{table}

During runtime operation (Stage (a-f) in Figure~\ref{fig:lut-lookup}), we follow this encoding pipeline: given an interpolated point along with its neighbors, we normalize and quantize the coordinates to obtain lookup indices, retrieve the corresponding offset from the table, and apply it to refine the center point's position. Notably, the interpolated point will be placed at first in the index.


% \paragraph{Position Encoding Pipeline}
% Given a neighborhood consisting of a center point $\mathbf{p}_c$ (marked in red in Figure~\ref{fig:lut-lookup}) and its three nearest neighbors (marked in green), our encoding process transforms continuous 3D coordinates into discrete indices through three stages:

% Stage (a) records the raw positions $\mathbf{r}_i = (x_i, y_i, z_i)$ of the neighborhood points. Stage (b) performs normalization to achieve translation and scale invariance:
% \begin{equation}
%     \mathbf{n}_i = \frac{\mathbf{r}_i - \mathbf{r}_c}{R}
% \end{equation}
% where $\mathbf{r}_c$ is the center point coordinates and $R$ is the neighborhood radius (maximum distance from any point to the center). This transforms ensuring all points lie within the unit cube $[-1,1]^3$.

% Stage (c) quantizes the normalized coordinates into $b$ discrete levels per dimension:
% \begin{equation}
%     \mathbf{q}_i = \lfloor (\frac{\mathbf{n}_i + 1}{2}) \times (b-1) \rfloor
% \end{equation}
% \paragraph{LUT Construction}
% The lookup table stores precomputed refinement offsets for all possible quantized neighborhood configurations. For a receptive field of size $n$ points with 3 coordinates in 3D space and $b$ quantization bins per dimension, the total number of possible entries is:
% \begin{equation}
%     N_{entries} = b^{3n}
% \end{equation}
% As illustrated in step (d) of Figure~\ref{fig:lut-lookup}, each LUT entry maps a sequence of quantized coordinates to a refinement offset:
% \begin{equation}
%     \text{LUT}[\mathbf{q}_1,\dots,\mathbf{q}_n] = \text{NN}(\text{dequantize}(\mathbf{q}_1,\dots,\mathbf{q}_n))
% \end{equation}
% where dequantize converts discrete indices back to normalized coordinates for neural network processing.

% The memory requirement for storing these entries with 4-byte floating-point values is:
% \begin{equation}
%     M = b^{3n} \times 4\text{ bytes}
% \end{equation}
% Table~\ref{tab:lut-size} analyzes the memory requirements for different configurations.


% \begin{table}[t]

% \centering
% \begin{tabular}{@{}c c r r@{}}
% \toprule
% RF Size ($n$) & 
% Bins ($b$) & 
% Entries ($b^{3n}$) & 
% Memory (4B/float) \\ 
% \midrule
% 2 & 16 & $16^6$ & 16\,MB \\
% 2 & 8 & $8^6$ & 256\,KB \\
% 3 & 16 & $16^9$ & 4\,GB \\
% 3 & 8 & $8^9$ & 8\,MB \\
% 4 & 16 & $16^{12}$ & 1\,TB \\
% 4 & 8 & $8^{12}$ & 1.5\,GB \\
% \bottomrule
% \end{tabular}
% \vspace{-.1in}
% \caption{Memory analysis for different LUT configurations}
% \label{tab:lut-size}
% \vspace{-.2in}
% \end{table}


% During runtime operation (steps a-f in Figure~\ref{fig:lut-lookup}), we follow this encoding pipeline: given an interpolated point along with its neighbors, we normalize and quantize the coordinates to obtain lookup indices, retrieve the corresponding offset from the table, and apply it to refine the center point's position. Notably, the interpolated point will be placed at first in the index. This approach transforms the computationally intensive neural network inference into efficient table lookups, enabling real-time refinement while maintaining high quality results.

% The selection of bin size $b$ presents a crucial trade-off between memory efficiency and refinement precision. With receptive field size $n=4$, reducing $b$ from 16 to 8 decreases the memory footprint from 1 TB to 1.5 GB while introducing only minimal quality degradation, making the approach practical for real-world deployment.


\mysubsubsection{Neural Network for LUT Construction}
\label{sec:NN}

The refinement network follows the design from GradPU~\cite{he_grad-pu_2023}. Given a interpolated point as the central point $\mathbf{p}_c$ and its $n-1$ nearest neighbors $\{\mathbf{p}_i\}_{i=1}^{n-1}$, our network $\textit{NN}$ computes a refinement offset through:
\begin{equation}
    \boldsymbol{\delta} = \textit{NN}(\mathbf{p}_c, \{\mathbf{p}_i\}_{i=1}^{n-1})
\end{equation}
The receptive field size $n$ is specifically chosen to balance LUT memory requirements and refinement quality. The offset $\boldsymbol{\delta}$ represents the mean displacement between the interpolated points and their groundtruth counterparts:
\begin{equation}
\boldsymbol{\delta} = \frac{1}{|P|}\sum{p_c \in P} ||\mathbf{p}_{gt} - \mathbf{p}_c||_2
\end{equation}
Training $\textit{NN}$ is equivalent to minimize the target loss function  $\boldsymbol{\delta}$.

To assist robust LUT construction, we incorporate two key design elements into the network training. First, Gaussian noise injection ($\sigma = 0.02$) to interpolated points during training improves the network's resilience to quantization artifacts that may arise during the discretization process. Second, we constrain the network's prediction space through normalized coordinate inputs, ensuring the learned function maps well to the LUT's discrete indexing scheme. The complete network training process is detailed in Section~\ref{sec:eval-setup}.

% \paragraph{Runtime Usage}
% During inference, shown in Fig~\ref{fig:lut-lookup}, we simply follow the encoding pipeline to convert each point's neighborhood into a quantized pattern, then use this pattern as an index into our precomputed table. More specifically, given a point with neighborhood coordinates (step (a)), we apply normalization and quantization (step (b) and (c)) to obtain lookup indices, retrieve the corresponding offset (step (d) and (e)), and apply it to refine the point's position (step (f)).

% \chendong{
% \section{Interpolation Refinement with LUT}
% \label{sec:lut}
% While interpolation effectively increases point density, directly predicting 3D coordinates or residuals for point refinement often leads to outliers and shrinkage artifacts. We propose a novel LUT-based refinement approach that first captures refinement patterns through offline neural network training, then transfers this knowledge into an efficient lookup table for real-time inference.
% \subsection{Training Improvements}
% Our refinement network operates on local point neighborhoods, taking as input a patch centered at each interpolated point with its k-nearest neighbors. To enhance robustness and generalization, we introduce Gaussian noise ($\sigma = 0.02$) to the interpolated points during training, improving network resilience to position variations. The network is trained with a multi-objective loss function that combines coordinate accuracy and distribution uniformity constraints.
% \subsection{Position Encoding}
% The transformation of continuous 3D positions into discrete indices requires careful consideration of precision and efficiency. Our encoding pipeline first establishes translation and scale invariance through coordinate centering and neighborhood radius scaling, mapping all neighborhoods into a consistent unit cube representation. The normalized coordinates are then discretized through a quantization process that balances precision with memory requirements.
% \subsection{LUT Construction}
% For a practical point refinement LUT, the receptive field size and quantization precision must be carefully chosen as they directly impact the memory footprint and refinement quality. Given a receptive field of size n and quantization using b bits, the LUT requires $(2^b)^n \times d \times \text{sizeof}(\text{float})$ bytes of storage, where d represents the output dimensions of the refinement offset.
% The bin size b determines the granularity of coordinate quantization, with each input dimension divided into $2^b$ discrete levels. For example, with 8-bit quantization (b=8), each coordinate axis is divided into 256 bins, while 4-bit quantization (b=4) uses 16 bins per axis. This quantization directly affects both storage requirements and refinement precision.
% Table~\ref{tab:lut_size} illustrates the memory requirements for various configurations:
% \begin{table}[t]
% \caption{Memory analysis for different LUT configurations}
% \label{tab:lut_size}
% \centering
% \begin{tabular}{cccc}
% \toprule
% Receptive Field & Bits & Bins per Dim & Memory \
% \midrule
% 2 & 8 & 256 & 192 KB \
% 2 & 4 & 16 & 0.75 KB \
% 3 & 8 & 256 & 48 MB \
% 3 & 4 & 16 & 12 KB \
% 4 & 8 & 256 & 12 GB \
% 4 & 4 & 16 & 192 KB \
% \bottomrule
% \end{tabular}
% \end{table}
% Each LUT entry stores a mapping from quantized input coordinates to refinement offsets. The input coordinates are represented as n-dimensional integer tuples, while the offsets are stored as 3D floating-point vectors. The input space quantization follows a uniform discretization strategy, dividing the normalized coordinate range [0,1] into equally spaced bins. This uniform quantization simplifies both the construction process and runtime lookup operations.
% The choice of bin size presents a crucial trade-off between memory efficiency and refinement precision. Reducing the quantization from 8 bits to 4 bits decreases the memory requirement by a factor of $2^{4n}$, at the cost of reduced coordinate precision. For a receptive field size of 4, this reduction brings the memory footprint from an impractical 12 GB to a manageable 192 KB, enabling practical deployment while maintaining acceptable refinement quality.
% }