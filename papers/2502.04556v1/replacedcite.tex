\section{Related Work}
\label{sec:related_work}

\paragraph{Representation Intervention.}
Representation intervention aims to edit the LLMs' hidden representations at certain layers to guide their behavior ____. In particular, several efforts have been made to steer them toward more truthful generation. ITI ____ utilizes fine-grained probing accuracy on each layer's attention heads to locate the most ``truthfulness-related" attention heads and improves truthfulness. TruthX ____ projects the LLM's internal representations into truthful and semantic latent spaces and refines the model within the truthful space, thereby improving its truthfulness. LITO ____ aims to improve upon ITI and break the ``one-size-fits-all" intervention solution by sweeping through several intervention intensities to generate candidate responses and trains LSTM to predict which response to select. NL-ITI ____ adopts MLP to replace the logistics regression in ITI to improve the probing accuracy, which results in a more appropriate choice of attention heads.

\paragraph{Other Approaches to Mitigate Hallucination.} Traditionally, post-training or fine-tuning is the default method for mitigating hallucination issues in LLMs. Typical methods include Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF) ____, Direct Preference Optimization ____, and many other techniques to align LLMs with human values, especially truthfulness ____. Although these methods have been successful in certain applications, they also exhibit significant shortcomings, such as high computational costs and instability during training ____. 
Aside from training-time mitigation and representation intervention, other inference-time approaches have been developed. Contrastive decoding aims to modify the output logits by contrasting strong and weak model outputs ____. ____ attempted to contrast an expert LLM with an amateur LLM to improve fluency and coherence. DoLa ____ contrasted the final layer and early layers to edit output logits, leading to more truthful generation. ____ refined output logits based on key tokens and context sharpness measured by contextual entropy, respectively.