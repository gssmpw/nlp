@inproceedings{bayat2024enhanced,
  title={Enhanced language model truthfulness with learnable intervention and uncertainty expression},
  author={Bayat, Farima Fatahi and Liu, Xin and Jagadish, H and Wang, Lu},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={12388--12400},
  year={2024}
}

@article{cao2024personalized,
  title={Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization},
  author={Cao, Yuanpu and Zhang, Tianrong and Cao, Bochuan and Yin, Ziyi and Lin, Lu and Ma, Fenglong and Chen, Jinghui},
  journal={arXiv preprint arXiv:2406.00045},
  year={2024}
}

@article{casper2023open,
  title={Open problems and fundamental limitations of reinforcement learning from human feedback},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
  journal={arXiv preprint arXiv:2307.15217},
  year={2023}
}

@article{chen2024context,
  title={In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation},
  author={Chen, Shiqi and Xiong, Miao and Liu, Junteng and Wu, Zhengxuan and Xiao, Teng and Gao, Siyang and He, Junxian},
  journal={arXiv preprint arXiv:2403.01548},
  year={2024}
}

@article{chen2024grath,
  title={GRATH: Gradual Self-Truthifying for Large Language Models},
  author={Chen, Weixin and Song, Dawn and Li, Bo},
  journal={arXiv preprint arXiv:2401.12292},
  year={2024}
}

@article{chen2024lower,
  title={Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused},
  author={Chen, Dingwei and Fang, Feiteng and Ni, Shiwen and Liang, Feng and Xu, Ruifeng and Yang, Min and Li, Chengming},
  journal={arXiv preprint arXiv:2408.08769},
  year={2024}
}

@inproceedings{chen2024truth,
  title={Truth forest: Toward multi-scale truthfulness in large language models through intervention without tuning},
  author={Chen, Zhongzhi and Sun, Xingwu and Jiao, Xianfeng and Lian, Fengzong and Kang, Zhanhui and Wang, Di and Xu, Chengzhong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={20967--20974},
  year={2024}
}

@article{chuang2023dola,
  title={Dola: Decoding by contrasting layers improves factuality in large language models},
  author={Chuang, Yung-Sung and Xie, Yujia and Luo, Hongyin and Kim, Yoon and Glass, James and He, Pengcheng},
  journal={arXiv preprint arXiv:2309.03883},
  year={2023}
}

@article{hoscilowicz2024nl,
  title={NL-ITI: Optimizing Probing and Intervention for Improvement of ITI Method},
  author={Hoscilowicz, Jakub and Wiacek, Adam and Chojnacki, Jan and Cieslak, Adam and Michon, Leszek and Urbanevych, Vitalii and Janicki, Artur},
  journal={arXiv preprint arXiv:2403.18680},
  year={2024}
}

@article{hu2024mitigating,
  title={Mitigating Large Language Model Hallucination with Faithful Finetuning},
  author={Hu, Minda and He, Bowei and Wang, Yufei and Li, Liangyou and Ma, Chen and King, Irwin},
  journal={arXiv preprint arXiv:2406.11267},
  year={2024}
}

@article{kai2024sh2,
  title={SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully},
  author={Kai, Jushi and Zhang, Tianhang and Hu, Hai and Lin, Zhouhan},
  journal={arXiv preprint arXiv:2401.05930},
  year={2024}
}

@article{li2022contrastive,
  title={Contrastive decoding: Open-ended text generation as optimization},
  author={Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori and Zettlemoyer, Luke and Lewis, Mike},
  journal={arXiv preprint arXiv:2210.15097},
  year={2022}
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{o2023contrastive,
  title={Contrastive decoding improves reasoning in large language models},
  author={O'Brien, Sean and Lewis, Mike},
  journal={arXiv preprint arXiv:2309.09117},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{panickssery2023steering,
  title={Steering llama 2 via contrastive activation addition},
  author={Panickssery, Nina and Gabrieli, Nick and Schulz, Julian and Tong, Meg and Hubinger, Evan and Turner, Alexander Matt},
  journal={arXiv preprint arXiv:2312.06681},
  year={2023}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{tian2023fine,
  title={Fine-tuning language models for factuality},
  author={Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2311.08401},
  year={2023}
}

@article{zhang2023alleviating,
  title={Alleviating hallucinations of large language models through induced hallucinations},
  author={Zhang, Yue and Cui, Leyang and Bi, Wei and Shi, Shuming},
  journal={arXiv preprint arXiv:2312.15710},
  year={2023}
}

@article{zhang2024truthx,
  title={Truthx: Alleviating hallucinations by editing large language models in truthful space},
  author={Zhang, Shaolei and Yu, Tian and Feng, Yang},
  journal={arXiv preprint arXiv:2402.17811},
  year={2024}
}

@article{zou2023representation,
  title={Representation engineering: A top-down approach to ai transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={arXiv preprint arXiv:2310.01405},
  year={2023}
}

