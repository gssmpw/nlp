\section{Related Work}
\label{related}
Visual object tracking in underwater environments has a wide range of applications \cite{6263248, 9904898}, including monitoring animal behavior, tracking pollutants and habitat changes, exploring shipwrecks, intrusion detection, surveillance, and various industrial uses such as pipeline inspection, seabed mapping, and offshore operations. However, underwater environments present unique challenges such as poor visibility, dynamic lighting conditions, and occlusions caused by water turbidity \cite{fabbri2018underwater}. Although numerous benchmarks are available for the evaluation of object trackers in open-air environments, research on underwater-specific benchmarks remains limited \cite{9032954,Panetta:IJOE:2022, Alawode_2022_ACCV}.

In open-air environments, several benchmarks have been developed for both single-object and multi-object tracking. Among the most notable are Visual Object Tracking (VOT) \cite{kristan2015vot}, Multi Object Tracking (MOT) \cite{leal2015motchallenge} and the National University of Singapore People and Rigid Objects (NUS-PRO) tracking \cite{Li2015NUSPRO}, which have significantly helped advance the field, driving improvements in speed, precision, and success rates. In fact, object tracking is a highly important and active research area and a variety of visual object trackers have been proposed in the past few years \cite{chen2022visual}. Among the prominent and openly available Machine Learning-based one-shot trackers are Channel and Spatial Reliability Tracker \textit{(CSRT)} \cite{Lukezic2017}, Kernelized Correlation Filters \textit{(KCF)} \cite{henriques2014high}, \textit{Boosting} method \cite{Grabner2006}, Multiple Instance Learning tracker \textit{(MIL)} \cite{5206737}, Tracking-Learning-Detection method \textit{(TLD)} \cite{kalal2011tracking}, \textit{MedianFlow} \cite{5596017}, and Minimum Output Sum of Squared Error tracker \textit{(MOSSE)} \cite{5539960}. These trackers have been widely exploited in diverse computer vision applications, mostly in on-land and open-air applications \cite{dardagan2021multiple}.%Some of the prominent and openly available visual object trackers are \textit{channel and spatial reliability tracker \cite{Lukezic2017}, kernelized correlation filters tracker \cite{henriques2014high}, boosting tracker \cite{Grabner2006}, multiple instance learning tracker \cite{5206737}, tracking learning detection tracker \cite{kalal2011tracking}, median flow tracker \cite{5596017}, and minimum output sum of squared error tracker\cite{5539960}}, which are exploited in diverse computer vision applications \cite{dardagan2021multiple}.

Several studies \cite{9032954, Panetta:IJOE:2022, Alawode_2022_ACCV} emphasize the need to develop datasets and evaluation frameworks specifically tailored to underwater scenarios. Various one-shot visual object trackers such as \textit{KCF}, \textit{MOSSE}, \textit{Boosting}, as well as a number of deep learning (DL)-based trackers were evaluated within these object tracking benchmarks. But crucially, none of these benchmarks proposes to close the perception-control loop and to provide an assessment of the different trackers within a ROV navigation and position control context (as opposed to our study in this paper).

In addition to not assessing the tracking quality within a real-world ROV control scenario \cite{10638434}, most of these prior work focus on the use of DL-based tracker, which requires a prior offline training phase, demanding the availability and acquisition of a training data set that faithfully captures the scenarios that the ROV will encounter during its deployment underwater. In contrast, in this paper, we focus on the use of ML-based one-shot tracker algorithms that do not require any offline training phase or any tedious training data acquisition, making these methods more \textit{generalizable} to any application context and underwater environment encountered by the ROV. 
%such as multidomain network (MDNet), siamese fully convolutional (SiamFC), efficient convolution operators (ECO), and to name a few were exploited for benchmarking.  %Building on this, the authors of \cite{Alawode_2022_ACCV} introduced UTB180, a new underwater tracking benchmark comprising 180 sequences and 58,000 annotated frames, designed to address challenges like low visibility and motion blur using 15 different deep trackers.

%A variety of visual object trackers, including those based on deep learning, have been developed for general applications. 


%\subsection{Limitations of the state of the art}
 %Existing related benchmarking visual trackers for underwater objects works \cite{9032954,Panetta:IJOE:2022,Alawode_2022_ACCV} predominantly leverage deep trackers for benchmarking, utilizing frames or videos sourced from databases or passive platforms like YouTube, and Pexels. However, 
 
However, real-world and real-time benchmark experiments involving ROV platforms remains significantly unexplored. Real-time setups inherently introduce a range of complexities, including motion-induced blur from the dynamic movement of ROVs, latency in system response affecting tracking precision, and environmental disturbances particulate and bubble interference as well as underwater currents pushing the ROV platform away from its desired position. %such as varying water turbidity, particulate and bubble interference, and light refraction. 
%
This paper addresses these gaps by systematically benchmarking more than seven popular ML-based one-shot trackers within numerous real-world ROV position control and locking experiments in order to directly benchmark the effect of each tracker under test with the position control precision achieved by the ROV platform.
 %In this regard we outlined our contribution as follow:

% \begin{enumerate}
% %      %\item We acquire a dataset for indoor mapping with a flying drone in a highly-redundant warehouse environment, leading to highly non-stationary data streams.
% \item We use under remote operating vehicle to do real-time tracking and locking of underwater objects.
%       \item \textcolor{blue}{put}
%       \item To help alleviate the scarcity of open-source underwater ROV datasets, we openly release the dataset used in this work with the hope of benefiting future research.
%   \end{enumerate}



%However, all existing tracking benchmark datasets are exclusively focused on target tracking in open-air environments \cite{}. 
%Visual object tracking in underwater environments has diverse applications, including marine biology (monitoring animal behavior and coral reefs) and environmental monitoring (tracking pollutants and habitat changes). It aids maritime archaeology (shipwreck exploration), aquaculture (fish health and predator management), and security (intrusion detection and surveillance). Industrial uses include pipeline inspection, seabed mapping, and offshore operations, while it supports scientific exploration (deep-sea research) and disaster response (search and rescue). Recreationally, it enhances scuba diving safety and underwater filming, with robotics leveraging it for navigation and object retrieval despite underwater visibility challenges.
% Deep learning is exploited for underwater object tracking \cite{Panetta:IJOE:2022,}
% \\
% survey \cite{rout2024underwater, Alawode_2022_ACCV},
% \textbf{Datasets:}
% This paper \cite{Panetta:IJOE:2022} introduces UOT100, a comprehensive underwater object tracking benchmark dataset with 104 videos and over 74,000 annotated frames. It evaluates 20 tracking algorithms, revealing their challenges in underwater environments. A GAN-based cascaded residual network is proposed to enhance image quality, improving tracking performance. Precision and success rate metrics demonstrate significant improvements with enhanced data. The study aims to advance underwater applications like robotics, security, and exploration, with plans for future enhancements. 

% Following the previous paper, authors in \cite{Alawode_2022_ACCV} introduces UTB180, a high-quality underwater tracking benchmark with 180 sequences and 58,000 annotated frames, tackling challenges like low visibility and motion blur. It benchmarks 15 state-of-the-art trackers, revealing their limitations in underwater environments compared to open-air datasets. Fine-tuning efforts on UTB180 showed only minor performance gains, highlighting the need for specialized underwater trackers. The study emphasizes the dataset's complexity and its role in advancing underwater tracking research.
% \cite{Ronny:IJMET:2018}, \cite{Katija:WACV:2021}, \cite{li2023underwater}\cite{kartal2024autonomous},