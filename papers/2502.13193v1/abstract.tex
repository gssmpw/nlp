\begin{abstract}
We explore how private synthetic text can be generated by suitably prompting a large language model (LLM).
This addresses a challenge for organizations like hospitals, which hold sensitive text data like patient medical records, and wish to share it in order to train machine learning models for medical tasks, while preserving patient privacy.  
Methods that rely on training or finetuning a model may be out of reach, either due to API limits of third-party LLMs, or due to ethical and legal prohibitions on sharing the private data with the LLM itself. 

We propose Differentially Private Keyphrase Prompt Seeding (\alg), a method that generates a private synthetic text corpus from a sensitive input corpus, by accessing an LLM only through privatized prompts. 
It is based on seeding the prompts with private samples from a distribution over phrase embeddings, thus capturing the input corpus while achieving requisite output diversity and maintaining differential privacy.
We evaluate \alg\ on downstream ML text classification tasks, and show that the corpora it generates preserve much of the predictive power of the original ones.   
Our findings offer hope that institutions can reap ML insights by privately sharing data with simple prompts and little compute. 
\end{abstract}

%This paper explores how private synthetic text can be generated by suitably prompting a large language model (LLM).
%The motivation comes from organizations who hold private data and wish to share their data while preserving privacy.  
%Prior methods focus on privately fine-tuning an LLM. 
%However, such a solution may be out of reach for organizations that lack access to the massive number of learned LLM model weights and/or compute resources required to fine-tune an LLM.  Keyword-based prompts are investigated, specifically those drawn from a private kernel density distribution over keyword embeddings.  New methods are given for sampling a sequence of keywords privately.   To evaluate private prompts, experiments compare their effectiveness on downstream ML tasks.  Privately-prompted, LLM-generated data are shown to have similar predictive power as the original data.   Our findings offer hope that institutions can privately share data with simple prompts, little compute and yet still reap ML insights.