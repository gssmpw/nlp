\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage{tikz}

\newcommand{\circlednumber}[3][red]{
  \tikz[baseline=(char.base)]{
    \node[shape=circle, draw=#1, fill=#2, text=white, inner sep=1pt] (char) {\textbf{#3}};
  }
}

\input{preamble}

\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}




\def\paperID{3065} %
\def\confName{CVPR}
\def\confYear{2025}

\begin{document}
\noindent \textbf{Resposes to Reviewer }\textcolor{purple}{\textit{\textbf{R1 (zGcr)}}} \textcolor{blue}{\textit{\textbf{R2 (b5s5)}}} \textcolor{orange}{\textit{\textbf{R3 (1Zym)}}}
\PAR{Q1-\textcolor{purple}{R1}\textcolor{blue}{R2}\textcolor{orange}{R3} Necessity of data augmentation (DA):} The two DA steps introduced in the paper play an important role in our framework. Splitting point clouds into multi-range images exacerbates class imbalance (e.g., distant or small objects occupy much fewer pixels) and introduces projection noise at split boundaries. WPD+ mitigates imbalance by fusing semantic contexts with paste-drop operations, while MCF (tailored to multi-range settings) addresses the noise at boundaries by filling invalid regions. These steps are however unnecessary or limitedly beneficial in standard single-range setups. Additional experiments in Tab.\ref{tab:ablation_wpd+} (A-D) show that removing WPD+ can make our framework suffer from significantly larger performance drop. The DA steps are not new. However, our contribution lies in adapting and refining these existing methods to tackle the specific challenges of achieving better performance.

\begin{table}[b]
\tiny
\vspace{-6.4mm}
\resizebox{\columnwidth}{!}{%
    \begin{tabular}{ l|c|c|c
    } 
    \hline
    Model  & WPD+  & mIoU  & $\Delta$ \\ 
    \hline
    A ($64\times 2048$)& \checkmark   & 64.8 & -\\
    B ($64\times 2048$) &  & 63.6 & \textcolor{red}{-1.2}   \\
    \hline
    C ($(3\times)64\times512$) &\checkmark  & 67.5 & -\\ 
    D ($(3\times)64\times512$)& & 65.2 & \textcolor{red}{-2.3}\\ 
    +LaserMix (Kong et al.) &\checkmark  & 67.7 & \textcolor{teal}{+0.2} \\
    +PolarMix (Xiao et al.) &\checkmark  & 68.0 & \textcolor{teal}{+0.5} \\
    \hline
     Model & Latency (vs C) &mIoU &$\Delta$ (vs C)\\
    \hline
    E ($64\times512$) & 16 ms \textcolor{teal}{(-6)}  & 65.1 & \textcolor{red}{-2.4}   \\
    F ($(2\times)64\times512$) & 19 ms \textcolor{teal}{(-3)}  &  66.9 & \textcolor{red}{-0.6}\\
    G ($(4\times)64\times512$) & 29 ms \textcolor{red}{(+5)}   & 67.5 & +0\\
    H ($(5\times)64\times512$) & 36 ms \textcolor{red}{(+12)}   & 67.2 & \textcolor{red}{-0.3}\\ 
    \hline
         
    \end{tabular}
    }
    \caption{Experiments on SemanticKITTI \textit{val} set with CENet}
    \vspace{-1.5mm}
    \label{tab:ablation_wpd+}
\end{table}
\PAR{Q2-\textcolor{purple}{R1}\textcolor{blue}{R2}\textcolor{orange}{R3} Discussion \& Exploration in splitting:}  As shown in Fig.\ref{fig:str_flares_diff}, \coolname{}'s splitting aligns with LiDARâ€™s spherical coordinate, ensuring consistent angular resolution within sub-images. This avoids distortions caused by cartesian grid splits like STR, and preserves local geometric coherence, ensuring that semantic contexts can be more effectively shared across sub-images. In addition, STR splits high-resolution images heuristically, while \coolname{} splits raw point clouds in 3D space and retains the scene completeness. The performance advantage of \coolname{} is experimentally demonstrated in Tab.3 in the paper. Furthermore, greater efficiency gains are achieved as our method operates exclusively on low-resolution inputs. After testing various grid sizes for splitting, we opted for the best and the most efficient configuration: representing each grid with a single point and excluding the voxelization process. Future work will focus on learning-based point cloud splitting that mitigates the issue of losing critical information. Such an approach can potentially eliminate the need for DA steps and improve robustness in more challenging conditions such as adverse weather or limited annotations.


\PAR{Q3-\textcolor{blue}{R2} Questions about MCF and inference speed:} MCF fills the invalid regions to restore information of local geometry after sub-sampling (some visual examples are provided in Fig.5 in supplementary material). Model performance can thus benefit from reduced amount of clutter. What the inference speed reported in Tab.2 is concerned, it is measured on the complete image for fair comparison.
\begin{figure}[t]
\vspace{-2.7mm}
  \centering
    \includegraphics[width=0.97\linewidth]{pics_rebuttal/str_flares_difference.png}
    \caption{Visual comparison between STR (top) and FLARES. \circlednumber[red]{white}{\textcolor{red}{1}}: Range-view projection, \circlednumber[red]{white}{\textcolor{red}{2}}: Splitting, \circlednumber[red]{white}{\textcolor{red}{3}}: Segmentation, \circlednumber[red]{white}{\textcolor{red}{4}}: Image concatenation, \circlednumber[red]{white}{\textcolor{red}{5}}: Post-processing}
    \label{fig:str_flares_diff}
    \vspace{-7.2mm}
\end{figure}
\PAR{Q4-\textcolor{blue}{R2} Ablation on number of sub-images:} Results in Tab.\ref{tab:ablation_wpd+}(E-H) show that increasing the number of sub-images beyond 4 degrades performance due to insufficient occupancy and projection artifacts. Conversely, fewer sub-images improve the inference speed but reduce accuracy due to decreased amount of information. Our choice of 3 sub-images optimally balances efficiency and accuracy.
\PAR{Q5-\textcolor{orange}{R3} Motivation \& Contribution:} We review our contributions: \textbf{1) Pre-processing}: see \textbf{\textit{Q2}}; \textbf{2) DA}: see \textbf{\textit{Q1}}; \textbf{3) Post-processing}: our novel contribution is NNRI, \textbf{not} KNN-Ensembling. The latter is briefly mentioned for fair comparison, as no existing approach is directly applicable to multi-range settings.  \textbf{4) Combination}: All components are specifically tailored for multi-range settings of \coolname{}. Extensive experiments in the paper demonstrate that their synergy drives significant performance improvement across various networks and benchmarks. %
\PAR{Q6-\textcolor{orange}{R3} Comparative study:} Besides the 3 lightweight networks, we also evaluated RangeViT (Ando et al.'23), which is a recent and large Vision-Transformer-based backbone. Other large networks, such as RangeFormer (Kong et al.'23) and MaskRange (Gu et al.'22), are not open-sourced, making it challenging to reproduce results relevant to our work. FRNet (Xu et al.'24) is a 3D frustum-based network that does not create real range images and require any post-processing step. Notably, FRNet uses CENet as its backbone, which we have extensively tested in the paper. We would greatly appreciate it if reviewer could suggest additional references for comparison.
\PAR{Q7-\textcolor{orange}{R3} Ablation study:} The referenced 3D DA methods are purposed to improve the model generalization, rather than to address the specific challenges of \coolname{} (outlined in \textit{\textbf{Q1}}). Therefore, they are not necessary in our framework, and they can be seamlessly attached as an additional component to further enhance the model performance. For reviewer's interest, we provide these results in Tab.\ref{tab:ablation_wpd+}.
\PAR{\textcolor{purple}{R1}\textcolor{blue}{R2}\textcolor{orange}{R3} In general:} We will incorporate the discussions from this rebuttal to improve the overall quality of the paper presentation and address all remaining reviewers' comments. We sincerely thank the reviewers for their time, insightful feedback and constructive suggestions.









\end{document}
