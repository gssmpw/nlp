\section{Experimental Setup}
\label{sec:experiments}

We design three dynamic scenarios to evaluate:
\begin{enumerate}[itemsep=1pt, parsep=1pt, leftmargin=*]
    \item \textbf{Q1}: Does implicit consensus outperform explicit coordination in volatile or adversarial conditions?
    \item \textbf{Q2}: Under what conditions do moderate deviations (diversity) improve system robustness?
    \item \textbf{Q3}: How do LLM agents’ in-context chain-of-thought updates reflect an evolving consensus, as opposed to a static single-step approach?
\end{enumerate}
In Section~\ref{sec:results}, we present both quantitative outcomes and example dialogues illustrating these points for scenario 1. For experimental results of scenarios 2 and 3, please refer to Appendix~\ref{sec:appendix:e}.

\subsection{Scenario Overviews}

This section shows the scenario of our three case studies, please refer to Appendix~\ref{sec:appendix:a} for the details of environment setup and key experimental factors.

\paragraph{Scenario 1: Dynamic Disaster Response.}
Autonomous drones on a $10\times10$ grid must allocate limited firefighting/medical resources to disasters with \emph{varying severity}, which can shift unpredictably every few rounds. The environment produces textual “reports” about possible severity changes or contradictory statements from local observers. Agents decide either via \emph{explicit} single-plan consensus or \emph{implicit} free decisions post-discussion. Key metrics are \emph{correct coverage rate}, \emph{misallocation penalty}, and \emph{average response delay}. Further details (map setup, severity scoring) are in Appendix~\ref{appendix:disaster}.

\paragraph{Scenario 2: Information Spread \& Manipulation.}
A graph of 50 nodes experiences \emph{misinformation injections} by an adversary. Multiple LLM “defender” agents attempt to contain or debunk false claims by selecting which nodes to fact-check each round. Contradictory or misleading textual updates about which nodes are infected test the defenders’ interpretive skills. We measure \emph{final spread of misinformation}, \emph{time to contain} each outbreak, and \emph{coverage diversity} (how many distinct nodes are fact-checked). Detailed mechanics (e.g., infection probabilities, network structure, role prompts) appear in Appendix~\ref{appendix:infospread}.

\paragraph{Scenario 3: Dynamic Public-Goods Provision.}
$N$ LLM agents contribute to a shared public good each round, which requires surpassing a threshold $\theta(t)$ to be “funded.” The threshold or benefit $B(t)$ can shift unpredictably (economic shocks, rumored changes), forcing agents to adapt. Under \emph{explicit} consensus, they all pay the same. Under \emph{implicit} consensus, each agent invests independently after discussion. We measure \emph{provision rate}, \emph{total welfare}, and \emph{free-rider disparity}. Appendix~\ref{appendix:publicgood} explains cost functions, threshold updates, etc.

\subsection{Experimental Design \& Metrics}
Each scenario runs for $T=20\sim30$ rounds. In every round:
\begin{enumerate}[itemsep=1pt, parsep=1pt, leftmargin=*]
    \item \emph{Agents observe environment states and textual updates}. Some updates may be contradictory or incomplete.
    \item \emph{They produce textual messages} (one or two “turns” of dialogue), referencing role-specific priorities, prior round outcomes, or suspicious rumors.
    \item \textbf{Implicit consensus}: each agent finalizes $a_i(t)$ individually. \textbf{Explicit consensus}: a forced voting step merges all votes into a single plan.
    \item \emph{We compute} each agent's deviation $d_i(t)$ and aggregate performance metrics (coverage, misinformation spread, or public-good provision). 
\end{enumerate}

\vspace{-0.5em}
We vary:
\vspace{-0.5em}
\begin{itemize}[itemsep=1pt, parsep=1pt, leftmargin=*]
    \item \textbf{Diversity Level}: \textit{low} (identical prompts), \textit{medium} (2--3 distinct roles), \textit{high} (conflicting or adversarial roles).
    \item \textbf{Volatility}: \textit{low} (rare changes), \textit{moderate}, or \textit{high} (continuous shocks or frequent adversarial injections).
    \item \textbf{LLM Variants}: Two open-source models and two closed-source models: GPT-4, Claude, Llama-2, Qwen, in homogeneous teams, to observe how different LLM reasoning styles impact outcomes.
\end{itemize}

We perform 5 runs for each setting to enhance the statistical significance, an example of a setting is: ``diversity (low) + volatility (moderate) + model (GPT-4o)''.

\subsubsection{Baselines and Additional Protocols}
We include the baselines enumerated in Section~\ref{ssec:baselines}, e.g., \emph{no diversity} vs.\ \emph{random strategy} vs.\ \emph{single-LLM}. We also track how scaling from $N=3$ to $N=100$ affects performance and discussion overhead. The full set of hyperparameters and sample prompts is documented in Appendix~\ref{sec:appendix:b}.

\subsubsection{Data Logging and NLP-Driven Analysis}
Throughout each run:
\begin{itemize}[itemsep=1pt, parsep=1pt, leftmargin=*]
    \item We \emph{log} every agent’s final action $a_i(t)$, enabling us to compute $\bar{d}(t)$.
    \item We store the textual messages to examine \emph{how} agents refer to past statements or contradictory reports. 
    \item At the end of $T$ rounds, we compute final performance metrics and produce \emph{time-series} plots correlating $\bar{d}(t)$ with system success.
\end{itemize}
To spotlight NLP innovations, we qualitatively assess how the \emph{dialogue content} reveals in-context adaptation, e.g., “Agent 2 responding to an erroneous rumor introduced by Agent 3,” or referencing last round’s failure to unify in the results.

\subsection{Theoretical Cross-Validation}
\label{subsec:cross-validation}
Finally, we compare empirical findings to the simplified theoretical model (Appendix~\ref{sec:appendix:c}). Specifically, we check whether the \emph{range of partial deviation} predicted to be optimal aligns with the observed performance peaks in the real LLM-driven environment. Where discrepancies appear, we discuss potential factors like hallucination, incomplete role prompts, or synergy in language-based discussions that deviate from the simplified numeric assumptions.
