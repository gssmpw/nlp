\section{Methodology}
\label{sec:methodology}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{fig/task.pdf}
    \vspace{-1.5em}
    \caption{Workflow in dynamic disaster response scenario. For explicit consensus, agents determine a collective action through a majority voting mechanism. In implicit consensus, agents individually assess others' opinions and independently choose the behavior they consider most appropriate as shown in this figure.}
    \vspace{-1.5em}
    \label{fig:workflow}
\end{figure}

In this section, we extend our framework for implicit and explicit consensus in LLM-based multi-agent systems and elaborate how we measure and exploit partial diversity for robust performance. We particularly focus on \emph{time-series} analyses of agent opinion deviation to capture how consensus evolves across rounds under different dynamic conditions. Figure~\ref{fig:workflow} shows the workflow of our case studies.

\subsection{Framework for Consensus \& Diversity}
\paragraph{Implicit vs.\ Explicit Consensus.}
We consider $N$ LLM agents $\{1, 2, \dots, N\}$ collaborating over discrete rounds $t \in \{1,2,\ldots\}$ to adapt to dynamic tasks. Each round, each agent $i$:
\begin{enumerate}[itemsep=1pt, parsep=1pt, leftmargin=*]
    \item \emph{Receives} transcripts from previous rounds (or partial observations, if the environment limits communication).
    \item \emph{Generates} a textual message containing suggestions, arguments, or evidence.
    \item \emph{Interprets} others' messages \emph{in context} via its chain-of-thought, then commits to a final \emph{action} $a_i(t)$.
\end{enumerate}

\paragraph{Explicit Consensus:}
    Agents unify into a single final action or plan, e.g., via majority voting:
    \begin{equation}
    a_i(t) \;=\; \arg\max_{a\in\mathcal{A}} \,\sum_{j=1}^N \mathbb{I}[v_j(t) = a],
    \end{equation}
    or through a forced-alignment prompt (\emph{“Please converge on one plan. Do not deviate.”}). This can expedite coordination but typically suppresses opinion diversity, risking suboptimal group behavior in rapidly changing or adversarial tasks.

\paragraph{Implicit Consensus:}
    Agents discuss but \emph{each still decides independently}:
    \begin{equation}
    a_i(t) \,\sim\, \textsc{LLM}_i\Bigl(\scriptstyle\text{``Given discussion } D(t)\text{, choose action''}\Bigr),
    \end{equation}
    where $D(t)$ collects the textual messages from all agents at round~$t$. Because each agent interprets $D(t)$ subjectively, the system’s final distribution $C(t) = \tfrac{1}{N}\sum_i \delta\bigl(a_i(t)\bigr)$ may exhibit \emph{partial} alignment. Residual deviations can foster exploration and heterogeneous strategies that enhance long-term robustness.

\subsection{Dynamic Consensus-Diversity Model}
Real-world environments evolve over time; hence, the \emph{optimal} action $a^*(t)$ may shift due to exogenous shocks. We define:
\begin{align}
C(t) &= \tfrac{1}{N}\sum_{i=1}^N \delta\bigl(a_i(t)\bigr), 
&\mu(t) &= \mathbb{E}_{a \sim C(t)}[a], \\
d_i(t) &= \lVert a_i(t) - \mu(t)\rVert, 
&\bar{d}(t) &= \tfrac{1}{N}\sum_{i=1}^N d_i(t),
\end{align}
where $d_i(t)$ measures agent $i$’s deviation from the mean action $\mu(t)$. We hypothesize an \emph{inverted-U} curve relating \(\bar{d}(t)\) to performance~\cite{curșeu2017stakeholder, shang2019resilient}:
\[
\text{Performance}(t) \;\approx\; f\Bigl(\sum_{i=1}^N d_i(t)\Bigr),
\]
where $f$ is unimodal, peaking at moderate $\bar{d}(t)$ but dropping if $\bar{d}(t)=0$ (premature consensus) or if $\bar{d}(t)$ is too large (excessive fragmentation).

\paragraph{In-Context Learning \& NLP Innovation.}
Unlike algorithmic methods (e.g., classical consensus protocols), each agent updates its reasoning purely through repeated \emph{natural language dialogue}. This harnesses:
\begin{enumerate}[itemsep=1pt, parsep=1pt, leftmargin=*]
    \item \textbf{Role Prompts}: Each agent has a specialized textual description (e.g., “You are a disaster medic,” “You are resource-averse”), injecting innate diversity.
    \item \textbf{Dialogue-Driven Adaptation}: Agents see partial environment cues and possibly contradictory or misleading textual updates each round. By analyzing how they revise their chain-of-thought in the discussion logs, we highlight an \textbf{NLP-centric} perspective: \emph{the conversation itself} fosters or impedes consensus, distinguishing our approach from standard numeric MAS solutions.
\end{enumerate}

\subsection{Stability and Scale Considerations}
\label{ssec:stability-scale}
\paragraph{Theoretical Underpinnings.}
To address concerns that implicit consensus might never settle:
\begin{itemize}
    \item In Appendix~\ref{sec:appendix:c}, we outline a simplified random-iteration model showing that if environment shocks are not too large and communication remains reliable, the system converges (or quasi-converges) in a region around a stable consensus state. 
    \item We also demonstrate the existence of a \emph{balance point} for the diversity parameter under moderate noise, yielding an emergent “optimal” partial consensus in expectation.
\end{itemize}

\paragraph{Scalability.}
For large $N$, the cost of multi-round discussion might become prohibitive. We thus allow (in future expansions) group-level parallelism or hierarchical chat structures that keep the method feasible as $N$ grows. In our current experiments ($3\le N \le100$), we handle direct group discussion. The code is structured so that the approach generalizes to $N>100$ if computational resources permit.

\subsection{Baselines \& Comparison Points}
\label{ssec:baselines}
We compare \textbf{implicit consensus} to multiple baselines:
\begin{itemize}[itemsep=1pt, parsep=1pt, leftmargin=*]
    \item \textbf{Single-LLM} or \textbf{No-Interaction} baseline: a single agent or $N$ identical agents each acting without coordination.
    \item \textbf{Fully Aligned (Explicit) Consensus}: forced majority voting or prompts that mandate uniform actions.
    \item \textbf{Random or Heuristic Strategy}: to show how LLM-based adaptive collaboration surpasses naive approaches.
    \item \textbf{No-Diversity} setting: all agents share identical role prompts, demonstrating the cost of suppressed heterogeneity.
\end{itemize}
These baselines allow us to quantify the net benefit of multi-agent discussion, partial autonomy, and diverse roles.
