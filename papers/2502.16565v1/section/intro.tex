\section{Introduction}

Multi-agent systems (MAS) have long studied how autonomous agents coordinate to achieve shared objectives in domains such as disaster response, resource allocation, information management, and task solving~\cite{chen2023multi, cur»ôeu2017stakeholder, hongmetagpt, qian2024chatdev}. The recent advent of large language models (LLMs) as general-purpose agents~\cite{li2023camel, wu2023smart, xing2024designing} presents novel opportunities for MAS: LLM agents can dynamically exchange information, interpret instructions, and reason in natural language. This flexible communication paradigm potentially enables more \emph{human-like} approaches to consensus formation, diverging from rigid algorithms in conventional distributed systems.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{fig/illustration.pdf}
    \vspace{-1.5em}
    \caption{An illustration of the concept of consensus-diversity tradeoff, using crop selection to show how concentrated opinions limit adaptation and lead to path dependence, which is a common real-world issue.}
    \vspace{-1.5em}
    \label{fig:illustration}
\end{figure}

However, an important challenge emerges: while strong \emph{explicit consensus} (e.g., centralized voting or forced agreement prompts) can unify the system (e.g., multi-agent debates~\cite{chanchateval}), it risks extinguishing critical diversity in agent opinions, limiting exploration and adaptability. Drawing on social science perspectives -- particularly the notion of \emph{limited collective common sense}~\cite{whiting2024framework} -- we observe that humans seldom rely on complete agreement to collaborate. Instead, model diversity, partial alignment, and tolerance for individual deviations often yields robust group outcomes, especially in uncertain or changing environments~\cite{chen-etal-2024-reconcile, dippel2024eliminating, duan2024enhancing, shang2019resilient}.

Motivated by these insights, this paper proposes a \textbf{dynamic consensus-diversity tradeoff} that addresses the tension between shared understanding and autonomy in LLM-based MAS. Our key hypothesis is that implicit consensus, in which agents discuss but act based on their own subjective interpretations (via in-context learning), can outperform explicit consensus in tasks with high environmental volatility and the need for persistent exploration. By allowing each agent's internal chain-of-thought to incorporate external signals yet still maintain independence, the group collectively retains a broader search space of strategies, mitigating groupthink risks~\cite{shang2019resilient} and providing higher resiliency to unexpected shifts. Figure~\ref{fig:illustration} demonstrates the concept of this consensus-diversity tradeoff.

\paragraph{Contributions.}

(1)~We present a new framework for LLM-driven multi-agent implicit consensus, defining how to quantify behavioral alignment and tolerance windows for diversity.  
(2)~We propose metrics to assess when and why implicit consensus can outperform explicit coordination, shedding light on how moderate deviations can enhance system performance.  
(3)~We instantiate and validate these ideas on three dynamic scenarios -- Dynamic Disaster Response, Information Spread and Manipulation, and Dynamic Public-Goods Provision -- demonstrating that an in-context, discussion-based approach leads to significantly higher robustness against shocks (e.g., black swan events) and adversarial behaviors.

In contrast to prior works that focus on forced alignment, single-step voting, or preset solidified agent roles~\cite{al2024project, li2023camel}, our approach does not fine-tune the model nor rely on explicit majority rule. Instead, we exploit LLMs' innate capacity for in-context learning, enabling them to interpret repeated dialogues among agents and adapt to emergent cues~\cite{han2023guinea,li2023camel,wu-etal-2024-shall,xing2024designing}. Through controlled experiments, we reveal how partial heterogeneity in agent preferences fosters resilience, aligning with social and cognitive theories emphasizing that incomplete consensus can yield robust group decisions.
