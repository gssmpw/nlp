\begin{figure*}[t]
    \centering
    \begin{subfigure}{0.49\linewidth}
        \includegraphics[width=\linewidth]{figure/01_01_realworld_dissimilarity_similarity_comparison.pdf}
        \caption{Real-world Scenario}
        \label{fig:real-world_main}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\linewidth}
    \label{fig:tofu_main}
        \includegraphics[width=\linewidth]{figure/01_02_tofu_dissimilarity_similarity_comparison.pdf}
        \caption{TOFU}
        \label{fig:tofu_main}
    \end{subfigure}
    \caption{Relative Utility Drop (\%) for different neighbor sets across real-world scenario (left) and TOFU (right). Each method (GA, NPO, IDK, DPO) is evaluated based on its model utility before and after unlearning, with lower bars indicating greater utility loss. Model utility values before and after unlearning are provided in Appendix~\ref{appendix:detailedResultsPerMethods}}
    \label{fig:experiment1}
\end{figure*}
\section{Experimental Setup}
\subsection{Evaluation Metrics}
We evaluate the unlearned model using several metrics to assess its performance from various perspectives~\citep{closerlookat, maini2024tofu}. Specifically, we employ \emph{ROUGE} to measure word-level similarity, \emph{BERT Cosine Similarity} to assess semantic consistency between outputs before and after unlearning, \emph{Probability} to evaluate the model's confidence to predict the ground truth answer, and \emph{Entailment Score} to assess factual correctness relative to the ground truth.

\noindent
Since all metrics range from zero to one, we aggregate them using the arithmetic mean. Applying this to the retain set defines \textbf{Model Utility (MU)}, while applying it to the forget set defines \textbf{Forget Efficacy (FE)}.

\noindent
To quantify the impact of unlearning on neighbor sets, we define the \textbf{Relative Utility Drop (RUD)} as:
\begin{equation}
\resizebox{0.6\hsize}{!}{$
\textstyle \text{RUD} = \frac{MU_{\text{after}} - MU_{\text{before}}}{MU_{\text{before}}} \times 100.$}
\end{equation}
Since unlearning typically reduces MU, RUD is usually negative, indicating the degree of performance drop. This metric shows which neighbor set suffers the most performance decline after unlearning. Further details on metric computation are provided in Appendix~\ref{appendix:evaluationMetrics}.
\subsection{Unlearning Methods}
We explore various unlearning strategies, each of which aims to erase knowledge of target entities in distinct ways. A comprehensive explanation of these methods is provided in Appendix~\ref{appendix:overviewUnlearningMethods}.
\begin{itemize}[leftmargin=6pt]
    \item \textbf{GA}~\cite{jang2023knowledgeunlearning}: Utilizes gradient ascent on the forget set to counteract learned knowledge.
    \item \textbf{DPO}~\cite{rafailov2023dpo}: Treats unlearning as a preference optimization problem by applying the standard DPO loss. It uses answers in the forget set as negative samples and rejection templates (e.g., ``I don't know'') as positive samples to guide the model's response.
    \item \textbf{NPO}~\cite{zhang2024npo}: A variant of DPO that removes positive samples from the optimization process. It retains only negative examples from the forget set, encouraging the model to suppress forgotten information without explicit reinforcement of alternative responses.
    \item \textbf{IDK}~\cite{maini2024tofu}: Fine-tunes the model to default to ``I don't know'' responses when queried about the forget set.
\end{itemize}


\subsection{Implementation Details}
For the TOFU benchmark~\citep{maini2024tofu}, we utilize fine-tuned Llama-2-7b-chat~\citep{touvron2023llama2}, which has been trained on the constructed dataset to ensure it precisely answers questions in TOFU. For the real-world scenario benchmark, we employ Llama-3-8B-Instruct~\citep{dubey2024llama3}.
\noindent
To enable a fair comparison of different unlearning methods at similar levels of forgetting, we adjust the hyperparameters to keep Forget Efficacy between 0.65 and 0.75. Further details are provided in Appendix~\ref{appendix:implementationDetails}.
