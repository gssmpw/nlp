\section{Introduction}
\begin{figure}[!t]
\label{fig:introFig}
\includegraphics[width=\linewidth]{figure/00_figure.pdf}
\vspace{-10mm}
\caption{Impact of unlearning across different neighbor sets. Syntactically similar neighbors are most affected (in red). In contrast, entity and domain neighbors retain correct knowledge (in blue).}
\label{fig:intro}
\end{figure}
\input{table/neighbor_definition}
Large language models (LLMs), trained on vast text corpora, exhibit remarkable capabilities~\citep{dubey2024llama3}. However, their deployment raises concerns about retaining unauthorized content, posing risks in copyright~\citep{karamolegkou2023copyrightviolation}, privacy~\citep{neel2023privacy}. These issues are critical under regulations like GDPR~\citep{voigt2017gdpr}, which mandates post-training data removal and the right to erasure.

To address these challenges, language model unlearning~\citep{yao2023llmunlearningsurvey} has emerged as a promising approach. It aims to achieve two primary objectives. First, the model should effectively forget the information in the forget set, such as private data.  Second, the unlearning process should preserve the model's ability to perform well on tasks unrelated to the forget set, which is represented by the retain set - the remaining subset of the training data that excludes the forget set. Many studies have primarily focused on the first objective, proposing methods to effectively remove the forget set~\citep{sinha2024unstar, eldan2023swhosharrypotter}, or developing metrics to verify whether forgetting has been successful~\citep{lynch2024eight, hu2024joggingthememory}. 
%However, unlearning  remains rarely adopted in practice, primarily due to the challenge of preserving retain set performance.
However, unlearning is still rarely used in practice because it is difficult to maintain performance on the retain set.

In this paper, we take a closer look at which areas of the retain set are significantly affected by unlearning through a case study on entity unlearning. Entity unlearning~\citep{maini2024tofu,rwku} aims to remove knowledge about particular entities, typically expressed through QA pairs. 
%Given the impracticality of evaluating the entire retain set, prior work has established the use of neighbor sets - subsets of the retain set that share similar distributions with the forget set but exclude the unlearning target. 
Since it is not practical to test the whole retain set, previous work has used smaller groups called neighbor sets~\cite{choi2024opt, closerlookat}.
These neighbor sets have similar properties to the data being removed, but they do not include the target data.
They are particularly important as they are expected to experience significant performance degradation during the unlearning process. 
Building on previous work, we conduct an in-depth analysis of these neighbor sets and address two key research questions:
\begin{enumerate}[wide, labelwidth=!, label={\textbf{RQ\arabic*.}}, labelindent=0pt, topsep=2pt, itemsep=-1pt, itemindent=0pt, leftmargin=*, before=\setlength{\listparindent}{-\leftmargin}]
\item How does performance degradation vary across different neighbor sets? (\S\ref{sec:problem})
\item What is the optimal neighbor set for effective regularization?  (\S\ref{sec:solution})
\end{enumerate}

To answer the research questions, we first challenge the conventional approach to neighbor set construction. 
While previous work~\cite{choi2024opt, closerlookat} primarily focused on \textit{Domain Neighbor Sets} containing instances from the same professional domain and \textit{Entity Neighbor Sets}~\cite{rwku, choi2024opt} comprising closely associated entities,
our research reveals that one key factor has been overlooked:  \textit{Syntactic Similarity}. To address this, we introduce the \textit{Syntactically Similar Neighbor Set}, which contains questions sharing similar syntactic structures with the forget set. 
%Our experiments demonstrate that \texit{Syntactically Similar Neighbor Set} consistently experiences significantly higher relative utility drops compared to both traditional neighbor sets (\S\ref{sec:problem}).
Our experiments show that this set suffers a much larger drop in performance compared to the traditional neighbor sets. (\S\ref{sec:problem}). 
%This finding challenges the previous assumption that entity or domain similarity are the primary drivers of forgetting patterns. The robustness of this result is confirmed through paraphrasing experiments and gradient analysis, which reveals stronger interdependencies within syntactically related information.
This finding challenges the earlier belief~\cite{closerlookat} that entity or domain similarity is the main driver of forgetting patterns. Our paraphrasing experiments and gradient analysis confirm this result by revealing stronger interdependencies within syntactically similar information

Building on this insight, we evaluate different retain set configurations for regularization during unlearning. 
Despite conventional wisdom~\citep{choi2024opt} suggesting that domain or entity-based retain sets would be most effective, our results demonstrate that training with \textit{Syntactically Similar Neighbor Set} not only best preserves performance on syntactically similar cases but also but also performs as well or better on other parts of the retain set. (\S\ref{sec:solution}). 
This indicates that syntactic similarity, rather than domain or entity relationships, provides a more reliable foundation for maintaining model utility while ensuring effective unlearning.
