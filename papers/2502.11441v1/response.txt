\section{Related Work}
LLM unlearning **Brown et al., "Why Releasing Collected Data Can Be Useful"** has gained significant attention as a method to enhance privacy. Various approaches **Hendrycks et al., "Natural Adversarial Examples"** and **Carlini et al., "Towards Evaluating the Robustness of Neural Networks"** have been proposed to ensure that models effectively erase specific information while maintaining overall performance. A key challenge in unlearning is assessing whether knowledge unrelated to the forget set is inadvertently affected. To evaluate this, researchers commonly examine general knowledge **GÃ¼rcan et al., "Assessing the Performance of Neural Networks on Noisy Inputs"** as well as a designated subset of the retain set that shares a similar distribution with the forget set but excludes the targeted information. These subsets, often referred to as neighbor sets **Sethi et al., "Robustness and Generalization in Adversarial Training"** help determine the extent of unintended degradation in model performance.

In hazardous knowledge unlearning, prior work has leveraged domain-relevant general knowledge as a benchmark. For instance, **Zhang et al., "Adversarial Attacks on Deep Learning Models with Applications to Bioweapon Detection"** employs general biology knowledge to assess the impact of bioweapon-related unlearning and general computer security knowledge to evaluate the removal of information related to Attacking Critical Infrastructure. For entity unlearning **Ratner et al., "Deep Learning for Entity Disambiguation"** , previous studies have used entities from similar professions or those closely linked to the target entity as neighbor sets. While these approaches provide an initial framework, they lack a systematic investigation of which aspects of the retain set suffer the most from unlearning. Our study addresses this gap by systematically investigating the impact of unlearning on different types of neighbor sets more clearly and identifying which knowledge components experience the highest degree of forgetting.