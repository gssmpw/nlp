
\pdfoutput=1


\documentclass[11pt]{article}


\usepackage{acl}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage{tcolorbox}
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{comment}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}
\usepackage{tabularx}



\title{Which Retain Set Matters for LLM Unlearning?

A Case Study on Entity Unlearning}

\author{Hwan Chang \and Hwanhee Lee\thanks{Corresponding author.} \\
    Department of Artificial Intelligence, Chung-Ang University, Seoul, Korea\\
    \texttt{\{hwanchang, hwanheelee\}@cau.ac.kr}
}
\begin{document}
\maketitle
\input{0_abstract}
\input{1_introduction}
\input{2_preliminaries}
\input{3_dataset_construction}
\input{4_study_setup}
\input{5_forget_experiments}
\input{6_retain_experiments}
\input{7_related_work}
\input{8_conclusion}
\input{9_limitations}

\section*{Acknowledgement}
This research was supported by Institute for Information \& Communications Technology Planning \& Evaluation (IITP) through the Korea government (MSIT) under Grant No. 2021-0-01341 (Artificial Intelligence Graduate School Program (Chung-Ang University)).


\bibliography{acl}
\input{10_appendix}
\end{document}
