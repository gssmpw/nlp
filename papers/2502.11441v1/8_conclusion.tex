\section{Conclusion}
In this paper, we examine unlearning's impact on retain sets and highlight the Syntactically Similar Neighbor Set as key to forgetting patterns. Our results show syntactic similarity, not domain or entity ties, drives retained knowledge degradation. Experiments confirm that syntactically similar neighbors face the highest utility drop, challenging prior assumptions. We also find that using such data for regularization improves performance retention. These findings refine unlearning strategies and emphasize the role of syntactic structure in minimizing unintended knowledge loss.

