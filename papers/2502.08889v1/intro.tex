\section{Introduction}
With the rapid development and widespread applications of modern machine learning and artificial intelligence, particularly driven by advancements in large language models (LLMs), privacy concerns have come to the forefront. 
For example, recent studies have highlighted significant privacy risks associated with LLMs, including well-documented instances of training data leakage \citep{carlini2021extracting,lukas2023analyzing}. These challenges underscore the urgent need for privacy-preserving mechanisms in machine learning systems.

Differential Privacy (DP) \citep{dwork2006calibrating} has emerged as a rigorous mathematical framework for ensuring privacy and is now the gold standard for addressing privacy concerns in machine learning. The classic definition of DP, referred to as \textit{item-level DP}, guarantees that the replacement of any single training example has a negligible impact on the model’s output. Formally, a mechanism $\calM$ is said to satisfy $(\epsilon,\delta)$-item-level DP if, for any pair $\calD$ and $\calD'$ of neighboring datasets that differ by a single item, and for any event $\calO \in \mathrm{Range}(\calM)$, the following condition holds: \begin{align} \label{eq:dp_def} \Pr[\calM(\calD) \in \calO] \leq e^{\epsilon} \Pr[\calM(\calD') \in \calO] + \delta. \end{align}

Item-level DP provides a strong guarantee against the leakage of private information associated with any single element in a dataset. 
However, in many real-world applications, a single user may contribute multiple elements to the training dataset \citep{Xu2024}. 
This introduces the need to safeguard the privacy of each user as a whole, which motivates a stronger notion of \textit{user-level DP}.  This notion ensures that replacing one user (who may contribute up to $m$ items) in the dataset has only a negligible effect on the model’s output. 
Formally, \eqref{eq:dp_def} still holds when $\calD$ and $\calD'$ differ by one user, i.e., up to $m$ items in total. Notably, when $m = 1$, user-level DP reduces to item-level DP.

\paragraph{DP-SCO}
As one of the central problems in privacy-preserving machine learning and statistical learning, DP stochastic convex optimization (DP-SCO) has garnered significant attention in recent years (e.g., \cite{bst14,bftt19,FKT20,bfgt20,bgm21,shw22,gopi2022private,alt24}). 
In DP-SCO, we are provided with a dataset $\{Z_i\}_{i \in [n]}$ of users, where each user $Z_i$ contributes samples drawn from an underlying distribution $\calP$. 
The goal is to minimize the population objective function under the DP constraint: 
\begin{align*} 
F(x) := \E_{z \sim \calP} f(x; z), 
\end{align*} 
where $f(x; z): \calX \to \mathbb{R}$ is a convex function defined on the convex domain $\calX$.


DP-SCO was initially studied in the item-level setting, where significant progress has been made with numerous exciting results. 
The study of user-level DP-SCO, to our knowledge, was first initiated by \cite{levy2021learning}, where the problem was considered in Euclidean spaces, with the Lipschitz constant and the diameter of the convex domain defined under the $\ell_2$-norm.
They achieved an error rate of $O\left(\frac{1}{\sqrt{mn}} + \frac{d}{n \epsilon \sqrt{m}}\right)$ for smooth functions, along with a lower bound of $\Omega\left(\frac{1}{\sqrt{mn}} + \frac{\sqrt{d}}{n \epsilon \sqrt{m}}\right)$. 

Building on this, \cite{bassily2023user} introduced new algorithms based on DP-SGD, incorporating improved mean estimation procedures to achieve an asymptotically optimal rate of $\frac{1}{\sqrt{nm}} + \frac{\sqrt{d}}{n \sqrt{m} \epsilon}$. 
However, their approach relies on the smoothness of the loss function and imposes parameter restrictions, including $n \geq \sqrt{d}/\epsilon$ and $m \leq \max\{\sqrt{d}, n\epsilon^2/\sqrt{d}\}$. 
On the other hand, \cite{GKKM+23} observed that user-level DP-SCO has low local sensitivity to user deletions. 
Using the propose-test-release mechanism, they developed algorithms applicable even to non-smooth functions and requiring only $n \geq \log(d)/\epsilon$ users. 
However, their approach is computationally inefficient, running in super-polynomial time and achieving a sub-optimal error rate of $O\left(\frac{1}{\sqrt{nm}} + \frac{\sqrt{d}}{n \sqrt{m} \epsilon^{2.5}}\right)$.  \cite{asi2023user} proposed an algorithm that achieves optimal excess risk in polynomial time, requiring only $n \geq \log(md)/\epsilon$ users and accommodating non-smooth losses. 
However, their algorithm is also computationally expensive:  
for $\beta$-smooth losses, it requires $\beta \cdot (nm)^{3/2}$ gradient evaluations, while for non-smooth losses, it requires  $(nm)^3$ gradient evaluations.
Motivated by these inefficiencies, \cite{LLA24} focused on improving the computational cost of user-level DP-SCO while maintaining optimal excess risk. For $\beta$-smooth losses, they designed an algorithm requiring $\max\{\beta^{1/4}(nm)^{9/8}, \beta^{1/2}n^{1/4}m^{5/4}\}$ gradient evaluations;  for non-smooth losses, they achieved the same optimal excess risk using $n^{11/8}m^{5/4}$ evaluations.

Linear-time algorithms have also been explored in the user-level DP-SCO setting. \cite{bassily2023user} proposed a linear-time algorithm in the local DP model, achieving an error rate of $O\left(\sqrt{d}/\sqrt{nm}\epsilon\right)$ under the constraints $m < d/\epsilon^2$, $n > d/\epsilon^2$, and $\beta \leq \sqrt{n^3/md^3}$. Similarly, \cite{LLA24} achieved the same rate under slightly relaxed conditions, requiring $n \geq \log(ndm)/\epsilon$ and $\beta \leq \sqrt{nmd}$.


In our work, we consider user-level DP-SCO under $\ell_\infty$-norm assumptions, in contrast to most of prior results, which were established under the $\ell_2$-norm. This distinction is significant, as the $\ell_\infty$-norm provides stronger per-coordinate guarantees and hence is more desirable.  Furthermore, the $\ell_\infty$-norm enjoys properties that are crucial to our algorithmic design but do not hold in the $\ell_2$-norm  setting. These properties influence both the development of our algorithm and the corresponding theoretical guarantees. The implications of this distinction and its role in our results will be discussed in detail in the subsequent sections.



\subsection{Technical Challenges in User-Level DP-SCO}

A key challenge in solving user-level DP-SCO using DP-SGD lies in obtaining more accurate gradient estimates while maintaining privacy. 
Consider a simple scenario where we perform gradient descent for $t$ steps and seek an estimate of $\nabla F(x_t)$. 
To achieve this, we sample $B$ users to estimate $\nabla F(x_t)$ and compute $q_t(Z_i):=\frac{1}{m}\sum_{z\in Z_i}\nabla f(x_t;z)$, the average of the $m$ gradients from user $Z_i$ at point $x_t$. 
If each user's $m$ functions are i.i.d. drawn from the distribution $\mathcal{P}$, then with high probability, we know that 
$
\|q_t(Z_i) - \nabla F(x_t)\| \leq \Tilde{O}(1/\sqrt{m}).
$

This naturally leads to the following mean-estimation problem: Given points $q_t(Z_1), \cdots, q_t(Z_B)$ in the unit ball, with most of them likely to be within a distance of $1/\sqrt{m}$ from each other (under the i.i.d. assumption for utility guarantees), how can we accurately and privately estimate their mean? 

A straightforward approach to recover the item-level rate is to apply the Gaussian mechanism:
\begin{align}
\label{eq:gaussian_mechanism}
\frac{1}{B} \sum_{i \in [B]} q_t(Z_i) + \calN(0, \sigma_1^2 I_d),
\end{align}
where the noise level is set as $\sigma_1 \propto 1/B$.

\paragraph{Mean Estimation and Sensitivity Control}

To improve upon this, prior works \citep{asi2023user, LLA24} designed mean-estimation sub-procedures with the following properties:
\begin{itemize}[topsep=3pt,itemsep=-3pt]
    \item \textbf{Outlier Detection:} The procedure tests whether the number of ``bad'' users (whose gradients significantly deviate from the majority) exceeds a predefined threshold (or ``break point'').
    \item \textbf{Outlier Removal and Sensitivity Reduction:} If the number of ``bad'' users is below the threshold, the procedure removes outliers and produces an estimate $g_t$ with sensitivity $\Tilde{O}(1/B\sqrt{m})$. The privatized gradient is then:
    $
    % \label{eq:sub_procedure}
    g_t + \calN(0, \sigma_2^2 I_d),
    $
    where $\sigma_2 \propto \frac{1}{B\sqrt{m}}$.
    \item \textbf{Better Variance Control:} When all users provide consistent estimates, the output follows 
    \begin{align*}
        \frac{1}{B}\sum_{i\in[B]}q_t(Z_i)+\calN(0,\sigma_2^2I_d), \sigma_2\propto \frac{1}{B\sqrt{m}},
    \end{align*}
    resulting in significantly smaller noise compared to the naive Gaussian mechanism in~\eqref{eq:gaussian_mechanism}.
\end{itemize}

By leveraging such sub-procedures, prior works have achieved the optimal excess risk rate in polynomial time. However, extending these to obtain \textit{linear-time} algorithms poses new challenges.

\paragraph{Challenges in Linear-Time User-Level DP-SCO}

Several linear-time algorithms exist for item-level DP-SCO. \cite{zhang2022differentially} and \cite{choquetteoptimal} achieved the optimal item-level rate $O\left(\frac{1}{\sqrt{n}} + \frac{\sqrt{d}}{n\epsilon}\right)$ under the smoothness assumption $\beta = O(1)$.\footnote{One can roughly interpolate the optimal item-level rate by setting $m=1$ in user-level DP.} Their approach maintains privacy by adding noise to all intermediate iterations of DP-SGD.

\cite{FKT20} notably relaxed the smoothness requirement to $\beta \leq \sqrt{n} + \sqrt{d}/\epsilon$ by analyzing the stability of non-private SGD. They showed that for neighboring datasets, the sequence $\{x_t\}_{t \in [T]}$ and $\{x_t'\}_{t \in [T]}$ remain close, ensuring that the sensitivity of the average iterate $\frac{1}{T} \sum_{t \in [T]} x_t$ is low. This allows them to apply the Gaussian mechanism directly to privatize the average iterate.

Motivated by this stability-based analysis, \cite{LLA24} attempted to generalize the linear-time approach of \cite{FKT20} to the user-level setting. However, a key difficulty arises when incorporating the mean-estimation sub-procedure. Specifically, even if one can bound $\|x_t - x_t'\|$, where $\{x_t\}$ and $\{x_t'\}$ represent the trajectories corresponding to neighboring datasets, there is no clear understanding of how applying the sub-procedure impacts stability in subsequent iterations. In particular, after performing one gradient descent step using gradient estimations from sub-procedure, we do not have guarantees on how well $\|x_{t+1} - x'_{t+1}\|$ remains bounded.

Due to this lack of stability analysis for the sub-procedure, \cite{LLA24} resorted to privatizing all iterations, resulting  in excessive Gaussian noise accumulation. Consequently, their algorithm achieved only a suboptimal error rate of $O\left(\frac{\sqrt{d}}{\sqrt{nm} \epsilon}\right)$, highlighting the fundamental challenge of designing a linear-time user-level DP-SCO algorithm by controlling the stability of the sub-procedures.

\paragraph{Generalizing Other Linear-Time Algorithms}

The linear-time algorithms proposed in \cite{zhang2022differentially} and \cite{choquetteoptimal} for item-level DP-SCO represent promising approaches to generalize  to the user-level setting. These algorithms achieve the optimal item-level rate $O\left(\frac{1}{\sqrt{n}} + \frac{\sqrt{d}}{n\epsilon}\right)$ by privatizing all intermediate iterations of variants of DP-SGD. This approach avoids the need for additional stability analysis, as the noise added at every iteration directly ensures privacy without relying on intermediate sensitivity bounds. Generalizing such algorithms to the user-level setting may, therefore, be easier compared to other approaches, as they sidestep the stability issues associated with mean-estimation sub-procedures.

In a private communication, the authors of \cite{LLA24} indicated that it is possible to generalize the linear-time algorithm of \cite{zhang2022differentially} to the user-level setting. 
However, this generalization introduces a dependence on the smoothness parameter $\beta$, which may impose restrictive smoothness constraints on the types of functions for which the algorithm is effective. 
Despite this limitation, such a generalization represents a natural direction for extending linear-time algorithms to user-level DP-SCO.

While these developments are promising, a more challenging and interesting direction lies in generalizing stability-based analyses from the item-level setting to the user-level setting. Stability-based methods, as seen in \cite{FKT20}, rely on carefully bounding the sensitivity of the entire optimization trajectory. Extending this approach to the user-level setting requires incorporating an appropriate sub-procedure for mean estimation, tailored to handle user-level sensitivity. 
This introduces additional layers of complexity, as the interactions between the sub-procedure and the iterative optimization process must be carefully analyzed to ensure stability and privacy. Overcoming these challenges would not only advance the theoretical understanding of user-level DP-SCO but might also lead to more efficient algorithms with broader applicability.

\subsection{Our Techniques and Contributions}

In this work, we design a novel mean-estimation sub-procedure based on robust statistics, such as the median and trimmed mean, specifically tailored for user-level DP-SCO. By incorporating the sub-procedure into (non-private) SGD, we establish an upper bound on $\|x_t - x_t'\|_\infty$ for all iterations $t \in [T]$. This ensures stability throughout the optimization process.

\paragraph{Key Idea: 1-Lipschitz Property of Robust Statistics}  
In one dimension, many robust statistics, such as the median, satisfy a \textit{1-Lipschitz property}. This means that if each data point is perturbed by a distance of at most $\iota$, the robust statistic shifts by at most $\iota$. This property makes robust statistics particularly well-suited for mean estimation in user-level DP-SCO.

To see this, recall that we define  
$
q_t(Z_i) := \frac{1}{m} \sum_{z \in Z_i} \nabla f(x_t; z)
$  
as the average of the $m$ gradients from user $Z_i$ at point $x_t$. Similarly, we define  
$q_t'(Z_i) := \frac{1}{m} \sum_{z \in Z_i} \nabla f(x_t'; z)$  
for the gradients at $x_t'$.  
If $|x_t - x_t'|$ is bounded, then by the smoothness of $f$, we have  
$
|q_t(Z_i) - q_t'(Z_i)| \leq \beta |x_t - x_t'|.
$  
This implies that the robust statistic computed from $\{q_t(Z_i)\}_{i \in [B]}$ and $\{q_t'(Z_i)\}_{i \in [B]}$ remains bounded by $\beta |x_t - x_t'|$ from the 1-Lipschitz property. 
As a result, the desired stability is naturally established in the one-dimensional setting.

\paragraph{Extending Stability to High Dimensions}  
In high-dimensional settings, robust statistics that satisfy the 1-Lipschitz property are not well understood. To address this, we adopt \textit{coordinate-wise robust statistics} for gradient estimation. This approach ensures stability at each coordinate level. In turn, this allows us to establish \textit{iteration sensitivity} in the $\ell_\infty$-norm.

\paragraph{Debiasing Technique}  
While robust statistics are effective in controlling sensitivity, using them directly introduces a significant bias in gradient estimation. This bias occurs even in "good" datasets where all functions are i.i.d. from the underlying distribution. If not handled properly, the bias can dominate the utility guarantee and degrade performance.

To address this issue, we propose a novel \textit{debiasing technique}: If the mean and the robust statistic are sufficiently close, we directly use the mean; otherwise, we project the mean onto the ball centered at the robust statistic.  
Both the mean and robust statistics individually satisfy the 1-Lipschitz property. We prove that this \textit{coordinate-wise projection preserves the 1-Lipschitz property in the} $\ell_\infty$-\textit{norm}. The resulting robust mean-estimation sub-procedure ensures iteration sensitivity while remaining \textit{unbiased when the dataset is well-behaved}. This property holds with high probability when all functions are i.i.d. from the distribution.

\paragraph{Improving Robust Mean Estimation: Smoothed Concentration Test}  
To further enhance stability, we introduce a \textit{smoothed version of the concentration score} for testing whether the number of ``bad'' users exceeds a threshold (the ``break point''). Prior works relied on an indicator function:  
$ 
\mathbf{1}(\|q_t(Z_i) - q_t(Z_j)\| \leq 1/\tau),
$ 
which is non-smooth and prone to instability. We replace this with a smoother function:  
$
\exp\left(-\tau \|q_t(Z_i) - q_t(Z_j)\|\right),  
$  which allows for a more stable and robust concentration test by providing a continuous measure of closeness.

\paragraph{Main Result and Implications}  
Using our sub-procedure and sensitivity bounds, we achieve a utility rate of  
\[
\Tilde{O}\left(\frac{d}{\sqrt{nm}} + \frac{d^{3/2}}{n\sqrt{m}\epsilon^2}\right),
\]  
for smooth functions defined over an $\ell_\infty$-ball, with gradients bounded in the $\ell_1$-norm and diagonally dominant Hessians (see Section~\ref{sec:prel} for detailed assumptions). We also construct a lower bound:  
\[
\Tilde{\Omega}\left(\frac{d}{\sqrt{nm}} + \frac{d^{3/2}}{n\sqrt{m}\epsilon}\right),
\]  
using the fingerprinting lemma, showing that our upper bound is nearly optimal except for the dependence on $\epsilon$.  
We discuss this loose dependence further in Section~\ref{sec:discussion}.

These assumptions are strong in terms of the properties of the norm: the $\ell_\infty$-ball is the largest among all $\ell_p$-balls and Lipschitz continuity in the $\ell_1$-norm implies that the $\ell_\infty$-norm of the gradient is bounded, which is the weakest possible assumption on gradient norms.

\paragraph{Comparison with Prior Work}  
The best-known item-level rate for this setting (i.e., Lipschitz in the $\ell_1$-norm and optimization over an $\ell_\infty$-ball) is:  
$ 
O\left(\frac{d}{\sqrt{n}} + \frac{d^{3/2}}{n\epsilon}\right),
$  
as established in the work of \cite{asi2021private}. To our knowledge, our result is the first to extend item-level rates to the user-level setting, incorporating the dependence on $m$.

Existing user-level DP-SCO results have primarily been studied in \textit{Euclidean spaces}, where functions are assumed to be Lipschitz in the $\ell_2$-norm and optimized over an $\ell_2$-ball. Since the $\ell_2$ diameter of an $\ell_\infty$-ball is $\sqrt{d}$, applying existing linear-time algorithms to our setting yields a suboptimal rate:  
$
O\left(\frac{d^{3/2}}{\sqrt{nm}\epsilon}\right).
$ 
This suboptimal dependence on $n$ arises because existing methods privatize all intermediate steps, leading to excessive noise accumulation. However, we acknowledge that our approach requires an additional assumption on the diagonal dominance of Hessians. Despite this restriction, our techniques are well-suited to the $\ell_\infty$-ball and gradient norm setting. We provide a detailed discussion of our assumptions, limitations, and open problems in Section~\ref{sec:discussion}.


\paragraph{DP and Robustness}  
There is a rich body of work exploring the connections between DP and robustness, with robust statistics playing a central role in many DP applications \citep{dwork2009differential, slavkovic2012perturbed, liu2022differential, asi2023robustness}. However, to the best of our knowledge, the application of robust statistics in private optimization remains relatively under-explored.  
We view our work as an important step in this direction and hope it inspires further research into leveraging robust statistics for private optimization.





% We design a linear-time algorithms based on DP-SGD, that can achieve rate $O(\frac{\sqrt{d}}{mn\epsilon})$

% In this work, we achieve the first stability analysis of the outlier removal and combined it with the geometric median to design a linear-time algorithm for user-level DP-SCO.

% \begin{itemize}
%     \item One can choose the batch size in $[1,m]$ freely for our algorithm.
% \end{itemize}

% \subsection{Technical Overview}
% \Daogao{Consider moving to later sections.}





% \subsection{Other Related Work}
% Improve the running-time in item-level;

% Geometric median is used in the optimization \cite{yin2018byzantine};
% \cite{haghifam2024private} studied how to find geometric median under DP constraint.