\section{Introduction}
\label{sec:intro}

% \begin{comment}
% diverse workloads

% motivation of using heterogeneous GPU resources

% short summarize: cost-efficient xxx

% contrib 1: comprehensive benchmark
% - gpu composition
% - parallel configuration
% - workload assignment

% contrib 2: design and eval
% \end{comment}

Large Language Models (LLMs), including GPT-4~\cite{gpt4o}, Gemini~\cite{reid2024gemini}, Llama3~\cite{dubey2024llama}, Claude~\cite{claude3}, Mixtral~\cite{jiang2024mixtral}, and DeepSeek-V3~\cite{deepseek_v3}, have demonstrated unprecedented performance across a wide range of real-world applications~\cite{copilot,jeon2023large,peng2023study}, such as chatbots, education, and healthcare, profoundly impacting human lives. In this context, enhancing the cost-efficiency of LLM serving is crucial for democratizing access to these cutting-edge technologies.

Currently, predominant practices utilize homogeneous GPU resources to deploy LLMs and serve the incoming requests~\cite{li2023alpaserve,kwon2023efficient,agrawal2024taming}. 
However, with the broadening application domains, serving LLMs is facing progressively varying request patterns, driving the serving workloads dynamic and diverse--- a phenomenon referred to as \textit{workload heterogeneity}~\cite{sun2024llumnix,zhao2024blendserve}.
This contradiction makes the use of homogeneous GPU resources unsuitable. 

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{imgs/ai_center_traces.pdf}
    \caption{\small{The real-world workload traces from the Swiss AI Center comprise over 500,000 traces collected over one month. We categorize the workload types based on input and output token lengths (longer than 512 and 128 are characterized as long).}}
    \vspace{-1em}
    \label{fig:req trace}
\end{figure}

To be specific, the requests to be served have varying input and output token lengths, as exemplified by the real-world LLM serving traces at the Swiss AI Center shown in~\autoref{fig:req trace}. 
Such differences can exhibit significantly divergent resource (compute and memory) demands across different types of workloads, owing to the distinct characteristics of the two phases of inference--- the prefill phase is compute-bounded as it processes input prompts in a single step, while the decoding phase is memory-bounded as it generates subsequent tokens step by step~\cite{zhong2024distserve,patel2024splitwise}. 
% Therefore, different types of workloads have varying resource demands, making the use of homogeneous GPU resources an unfit choice. 
Therefore, when using homogeneous GPU resources, it is hard to fit the varying resource demands well. 


% To be specific, the requests to be served can exhibit varying resource demands due to differences in input and output token lengths. 
% For example, coding and summarization requests are typically compute-bounded processes characterized by long input and short output token lengths, whereas conversational and complex reasoning requests are typically memory-bound processes with short input and long output token lengths~\cite{patel2024splitwise}.
% This distinction arises from the differing computational characteristics of the two phases of inference: the prefill phase is compute-bounded as it processes input prompts in a single step, while the decoding phase is memory-bounded as it generates subsequent tokens step by step~\cite{zhong2024distserve}.
% As shown in~\autoref{fig:req trace}, the real-world LLM serving workloads at the Swiss AI Center exhibit significant heterogeneity.
% \red{(Need refinement.)}



On the contrary, the heterogeneity in resource demands presents a unique opportunity to enhance the overall serving efficiency by leveraging different GPU types. As shown in~\autoref{tab:gpu_specs}, various GPU types offer diverse compute and memory capabilities, making them well-suited for processing different types of workloads. 
Motivated as such, we try to explore two questions: \textit{Can serving LLMs over heterogeneous GPU resources achieve better cost-efficiency than homogeneous GPU resources? If yes, how can we enhance the cost-efficiency?}
To this end, this work makes two technical contributions correspondingly.

\textbf{\textit{The first contribution}} is a comprehensive benchmarking of LLM serving over various GPU types, which offers a detailed understanding of cost-efficiency with heterogeneous GPU resources. 
Based on the benchmarking results, we reveal three key factors that are vital to the cost-efficiency:
\begin{itemize}[topsep=5pt, leftmargin=*]
    \vspace{-0.5em}
    \item \textbf{GPU composition} (i.e., the number and types of GPUs that make up a heterogeneous cluster) is essential for optimizing the cost-efficiency of LLM serving. Different GPU types exhibit varying characteristics (e.g., computational capabilities, memory bandwidths, and memory capacities), making them more suitable for distinct workloads and model types.
    % For example, data center GPUs (e.g., H100) with high compute throughput excel in compute-intensive tasks, while workstation GPUs (e.g., A6000), which offer greater memory capacity per unit cost, are more effective for memory-intensive workloads. 
    Given the varying types of incoming workloads, we need to strategically optimize GPU composition to improve resource utilization, reduce latency, and enhance overall serving performance.
    \vspace{-0.5em}
    \item \textbf{Deployment configurations} (i.e., how many model replicas to deploy and the parallelism strategy for each) are necessary for maximizing overall system performance. The optimal configurations is influenced by the model, workload, and GPU type, so using a unique deployment configuration for all replicas is impractical.
    % For example, model parallelism is often the most cost-effective approach for workloads with high computational and memory demands, whereas data parallelism (i.e., model replication) performs better for workloads with lower compute and memory requirements. Additionally, different GPU types may have distinct optimal deployment configurations for the same workload. 
    Therefore, we should adaptively optimize the deployment configurations so that the system efficiency can be improved.
    \vspace{-0.5em}
    \item \textbf{Workload assignment} (i.e., allocating incoming workloads to GPUs) becomes crucial as different replicas are deployed with varying configurations (i.e., resources and parallelisms) and different workloads have their preferable resource needs. 
    As a result, to improve resource utilization, it necessitates assigning requests to more suitable replicas while balancing the burden across all replicas. 
    % when co-optimized with GPU composition and deployment configuration, further enhances system cost-efficiency. 
    % Effective workload assignment ensures that requests are preferentially directed to the most suitable GPU types and deployment configurations based on resource demands while also balancing workloads across GPUs to maximize resource utilization. By dynamically adapting workload assignment in response to system demands, operational costs can be minimized while maintaining high overall performance.
    \vspace{-0.5em}
\end{itemize}


\begin{table}[!t]
    \centering
    \caption{\small{GPU Specifications and Pricing}}
    \vspace{-1em}
    \small
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l | c | c | c | c}
        \hline
        \textbf{GPU} & \textbf{Peak} & \textbf{Memory Access} & \textbf{Memory} & \textbf{Price} \\
                      \textbf{Type} & \textbf{FP16 FLOPS}         & \textbf{Bandwidth}           & \textbf{Limit}            & \textbf{(per GPU)} \\ \hline
        A6000 & 91 TFLOPS  & 960 GB/s  & 48 GB & 0.83 \$/h \\
        A40           & 150 TFLOPS  & 696 GB/s  & 48 GB  & 0.55 \$/h \\
        L40          & 181 TFLOPS  & 864 GB/s  & 48 GB  & 0.83 \$/h \\
        A100          & 312 TFLOPS   & 1555 GB/s & 80 GB  & 1.75 \$/h \\
        H100          & 1979 TFLOPS & 3.35 TB/s & 80 GB  & 2.99 \$/h \\
        4090      & 83 TFLOPS  & 1008 GB/s & 24 GB  & 0.53 \$/h \\ 
        \hline
    \end{tabular}
    }
    \vspace{-1em}
    \label{tab:gpu_specs}
\end{table}



\textbf{\textit{The second contribution}} is to design a brand new LLM serving framework following the benchmarking, which aims at maximizing the cost-efficiency of LLM serving over heterogeneous GPU resources in cloud platforms. 

Given the three factors above, a straightforward approach is to rent the most suitable GPUs for each workload type and assign requests accordingly. 
Nevertheless, this is impractical for two reasons. 
For one thing, due to the high demand for cloud GPUs, although cloud platforms (e.g., Vast.ai, RunPod, and AWS) offer a variety of GPU types, they usually have limited quantities of each type. 
We present the availability of different GPU types on Vast.ai over a 24-hour period in~\autoref{fig:cloud gpus}. 
For another, the user-defined price budget is often constrained, making it impractical to always allocate sufficient GPUs for each workload demand. 
% Consequently, it becomes crucial to devise a proper scheduling algorithm that balances trade-offs and takes into account both current GPU availability and the user-defined budget to optimize cost-efficiency.
% Consequently, it becomes crucial to take account of both real-time GPU availability on cloud platforms and the user-defined price budgets while co-optimizing the three key factors. 

Consequently, we formulate a scheduling algorithm based on mixed-integer linear programming (MILP), which takes account of both \textbf{real-time GPU availability} on cloud platforms and the \textbf{user-defined price budget}, while co-optimizing how to rent GPUs from the available pool (GPU composition), how to deploy the models over the rent GPUs (deployment configuration), and how to dispatch the workloads among the model replicas (workload assignment). 
We further incorporate practical heuristics and a binary search mechanism, as well as extend our approach to the multi-model scenario, improving scalability and solving efficiency for large-scale clusters.


\begin{figure}[!t]
    \centering
    \includegraphics[width=0.8\linewidth]{imgs/GPU_change.pdf}
    \caption{\small{The number of different types of GPUs on Vast.ai during a 24-hour period.}}
    \vspace{-1em}
    \label{fig:cloud gpus}
\end{figure}

We empirically evaluate our framework by comparing it with both homogeneous and heterogeneous baselines across a variety of scenarios, covering diverse workload traces, varying GPU availabilities, and multi-model serving. The results demonstrate that, within the same price budget, our approach can achieve up to 41\% and on average 20\% higher throughput, or reduce the serving latency by up to 54\% and on average 20\%.

% To tackle this challenge, we formulate the scheduling algorithm as a constraint optimization problem, co-optimizing the three key factors while considering user-defined total price budges and real-time GPU availability on cloud platforms.
% Our framework co-optimizes the three factors above, while considering user-defined total price budges and GPU availability on cloud platforms. 


% We formulate the scheduling problem as a constraint optimization problem, focusing on optimizing the heterogeneous GPU composition, parallelism strategies, and workload assignments. To solve this problem efficiently, we design a sophisticated scheduling algorithm based on mixed-integer linear programming (MILP) that accounts for user-defined budget constraints and real-time GPU availability on cloud platforms. Additionally, we incorporate practical heuristics and a binary search mechanism into our algorithm to improve scalability and search efficiency for large-scale clusters.



% , current practices mainly utilize homogeneous GPU resources to deploy and serve the LLMs. 

% poses challenges to enhancing the cost-efficiency of LLM serving, since current practices mainly utilize homogeneous GPU resources to deploy and serve the LLMs. 

% This heterogeneity in resource demands presents a unique opportunity to enhance the hardware efficiency of the serving system by leveraging different GPU types. As shown in~\autoref{tab:gpu_specs}, various GPU types offer diverse compute and memory capabilities, making them well-suited for processing different types of workloads.
% By leveraging the diversity of available GPU types and allocating inference requests to GPU types that best match their resource requirements, the hardware efficiency of the serving system can be significantly improved.


% \red{=== REFACTOR END ===}

% \clearpage

% Large Language Models (LLMs), including GPT-4~\cite{gpt4o}, Gemini~\cite{reid2024gemini}, Llama3~\cite{dubey2024llama}, Claude~\cite{claude3}, Mixtral~\cite{jiang2024mixtral}, and DeepSeek-V3~\cite{deepseek_v3}, have demonstrated unprecedented performance across a wide range of real-world applications~\cite{copilot,jeon2023large,peng2023study}, such as chatbots, education, and healthcare, profoundly impacting human lives. In this context, enhancing the cost-efficiency of LLM serving is crucial for democratizing access to these cutting-edge technologies. However, serving LLMs can be expensive, often requiring a substantial number of homogeneous data center GPUs for efficient operation. In this paper, we propose leveraging heterogeneous GPU resources available on cloud platforms to mitigate the high serving costs while ensuring efficient and cost-effective LLM serving.
% % \red{(Lack motivations!)}





% LLMs are designed to support a wide range of applications~\cite{naveed2023comprehensive,hendrycks2020measuring,liu2024understanding,zhao2024wildchat,zheng2023lmsys,wang2024burstgpt}, and the serving workloads associated with these applications are often dynamic and diverse—a phenomenon referred to as \textit{workload heterogeneity}~\cite{sun2024llumnix,zhao2024blendserve}. Inference requests can exhibit varying resource demands due to differences in input and output token lengths. For example, coding and summarization requests are typically compute-bounded processes characterized by long input and short output token lengths, whereas conversational and complex reasoning requests are typically memory-bound processes with short input and long output token lengths~\cite{patel2024splitwise}. This distinction arises from the differing computational characteristics of the two phases of inference: the prefill phase is compute-bounded as it processes input prompts in a single step, while the decoding phase is memory-bounded as it generates subsequent tokens step by step~\cite{zhong2024distserve}. As shown in~\autoref{fig:req trace}, the real-world LLM serving workloads at the Swiss AI Center exhibit significant heterogeneity.
% This heterogeneity in resource demands presents a unique opportunity to enhance the hardware efficiency of the serving system by leveraging different GPU types. As shown in~\autoref{tab:gpu_specs}, various GPU types offer diverse compute and memory capabilities, making them well-suited for processing different types of workloads.
% By leveraging the diversity of available GPU types and allocating inference requests to GPU types that best match their resource requirements, the hardware efficiency of the serving system can be significantly improved.


% Due to the substantial computation and memory demands of LLMs, several parallelism strategies have been developed to enable efficient inference across multiple GPUs. These strategies include data parallelism (i.e., model replication), tensor parallelism~\cite{shoeybi2019megatron}, and pipeline parallelism~\cite{huang2019gpipe}, each of which presents specific trade-offs. For example, data parallelism increases system throughput but introduces additional memory overhead, while tensor parallelism reduces inference request latency but incurs high communication overhead. Recent efforts have focused on the efficient combination and orchestration of these parallelism strategies to further improve LLM serving efficiency~\cite{li2023alpaserve}. We find that optimizing parallelism strategies is crucial for handling heterogeneous workloads and make full use of different GPU types. Such optimizations can significantly improve the hardware efficiency and cost-efficiency of LLM serving systems.



% A straightforward approach to utilizing heterogeneous GPUs for serving heterogeneous workloads is to allocate the most suitable GPUs based on workload demands. However, due to the high demand for cloud GPUs, platforms such as Vast.ai, while offering a variety of GPU types, have limited quantities of each type. We present the availability of different GPU types on Vast.ai over a 24-hour period in~\autoref{fig:cloud gpus}. Additionally, user-defined serving budgets are often constrained, making it impractical to always allocate GPUs that perfectly match workload demands. In this context, it becomes crucial to devise a proper serving plan that balances trade-offs and takes into account both current GPU availability and the user-defined budget to optimize cost-efficiency.

% Current systems primarily focus on using homogeneous data center GPUs for LLM serving, overlooking the cost-efficiency potential of other GPU types (e.g., workstation and consumer GPUs)~\cite{li2023alpaserve,kwon2023efficient,agrawal2024taming}. Existing heterogeneous serving systems typically optimize performance within a predefined heterogeneous cluster, and fail to consider GPU availability and user-defined budget constraints on cloud platforms~\cite{jiang2023hexgen,mei2024helix,griggs2024m,zhao2024llm}. Similarly, existing distributed serving systems generally optimize parallelism strategies without considering workload heterogeneity~\cite{li2023alpaserve,jiang2023hexgen,zhong2024distserve}. 

% Motivated by these limitations, we propose a \textbf{cost-efficient} LLM serving framework that co-optimizes the GPU rental plan (i.e., the heterogeneous GPU composition of the serving cluster) and the model deployment plan (i.e., parallelism strategies). Our solution is designed to accommodate incoming heterogeneous workloads while considering user-defined total budgets and GPU availability on cloud platforms. Our contributions can be summarized as follows:

% \textbf{\underline{Contribution 1:}} We conduct a comprehensive benchmarking of the cost-efficiency of various GPU types across different parallelism strategies, workload types, and model sizes. This analysis offers a detailed understanding of the cost-efficiency performance of heterogeneous GPUs and guides the design of our scheduling algorithm.

% \textbf{\underline{Contribution 2:}} We formulate the scheduling problem as a constraint optimization problem, focusing on optimizing the heterogeneous GPU composition, parallelism strategies, and workload assignments. To solve this problem efficiently, we design a sophisticated scheduling algorithm based on mixed-integer linear programming (MILP) that accounts for user-defined budget constraints and real-time GPU availability on cloud platforms. Additionally, we incorporate practical heuristics and a binary search mechanism into our algorithm to improve scalability and search efficiency for large-scale clusters.

% \textbf{\underline{Contribution 3:}}
% We evaluate our framework through extensive experiments, comparing it with both homogeneous and heterogeneous baselines across a variety of heterogeneous workloads, including real-world workload traces from the Swiss AI Center. The experiments are conducted using popular LLM models, Llama3-8B and Llama3-70B. Our results demonstrate that, within the same cloud service budget, our approach can achieve up to 41\% and an average of 20\% higher throughput, or reduce the system's serving latency by up to 54\% and on average 20\%.


% \clearpage

