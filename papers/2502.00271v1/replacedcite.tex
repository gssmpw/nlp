\section{Related Works}
\paragraph{Search algorithms} 
Search algorithms often face a tradeoff between effectiveness and efficiency. Approaches like Monte Carlo Tree Search____ improve effectiveness by incorporating backtracking, but at the cost of efficiency. Other methods prioritize efficiency with minimal sacrifice in effectiveness____. In this work, we use a simple beam search algorithm____ for our experiments, focusing on highlighting challenges in the candidate evaluation and selection stage, orthogonal to these advanced techniques.

% , such as dynamically allocating resources during the search
% adaptively selecting search algorithms based on problem difficulty


\paragraph{Candidate evaluation in search} 
Candidate evaluation is a crucial stage that determines which paths are more valuable for further selection and exploration. Some methods rely on the some rule-based heuristics____, with limited effectiveness. Some approaches involve lookahead techniques to assess candidates by simulating their subsequent outcomes____, which significantly increases computational cost. Other methods incorporate external verifier models____ to evaluate each candidate. In this work, we focus on the challenges and limitations of the this approach.

% \paragraph{Verifiers} 
% Verifiers for candidate evaluation are main two categories: outcome-supervised value models (OVMs)____ and process-supervised reward models (PRMs)____. OVMs assess a candidate's future potential using only final answer correctness as training labels, whereas PRMs evaluate step-wise correctness, requiring step-level annotations for training. Some studies propose automated approaches for collecting step-level labels____. In this work, we investigate both OVM- and PRM-guided search, utilizing open-source data for PRM training.