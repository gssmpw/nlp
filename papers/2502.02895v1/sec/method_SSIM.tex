\subsection{A faster implementation of SSIM}
\label{sec:ssim_impl}
% 通常SSIMは画像のペアに対して計算される場合が多い一方、私たちのアプリケーションでは$n$個の候補Bbox、$n(n-1)/2$組に対するSSIMを計算する必要がある。既存のSSIMライブラリは従来の目的に対して十分高速であるが、私たちのユースケースでは更に効率的な計算方法を考える必要がある。
% SSIM計算を高速化するため、私たちは以下の工夫を導入する。
% \begin{enumerate}
%     \item GPUを用いた並列化
%     \item メモリ使用量を抑えるための分割統治法
%     \item 冗長な計算の回避
% \end{enumerate}
Although SSIM is usually computed for a pair of images, we have to compute SSIM for combinations of $n$ predictions, i.e., $n(n-1)/2$ pairs of predictions.
Existing software is sufficiently fast for usual purposes, but we need a much faster implementation. 
To achieve this, we introduce the three techniques: parallelization on GPU, divide-and-conquer algorithm to reduce memory usage, and omission of redundant computation. % Please refer to our source code for more information.
% To achieve this, we introduce the following techniques.
% \begin{enumerate}
%     \item Parallelization on GPU.
%     \item Divide-and-conquer algorithm to reduce memory usage.
%     \item Omit redundant computation.
% \end{enumerate}

\vskip.5\baselineskip\noindent\textbf{Parallelization on GPU. }
% \paragraph{Parallelization on GPU.}
% SSIM Loss\footnote{\url{https://github.com/kornia/kornia/tree/main}}\footnote{\url{https://github.com/pytorch/ignite/blob/master/ignite/metrics/ssim.py}}と同様、二次元のガウスフィルタをウィンドウとする畳み込み計算を活用することで、GPU上での並列計算を容易に実現できる。
% 予測ボックスを同じ大きさにリサイズし、バッチ処理を行うことで$n(n-1)/2$組に対するSSIMを一度に求めることができる。
% 経験的には、$\mathrm{width}\times\mathrm{height}=48\times 48$程度まで小さくリサイズしても性能に影響を与えない。
% GPUを用いたバッチ処理により、各ペアに対するSSIMをsequentialに計算する場合と比較して大幅に高速に計算することができる。
% 一方で計算に必要なすべてのデータをGPUに載せるため、GPUメモリ使用量が増加しやすい。少なくとも$n\times n \times \#\mathrm{channel} \times \mathrm{width} \times \mathrm{height} \times 4$ bytes以上のメモリが必要となる。
SSIM computation is easily parallelized on GPU using the convolution operator with a two-dimensional Gaussian filter\footnote{\url{https://github.com/kornia/kornia/tree/main}}\footnote{\url{https://github.com/pytorch/ignite/blob/master/ignite/metrics/ssim.py}}.
We simultaneously compute SSIM for $n(n-1)/2$ combinations through batch parallelization by resizing all predictions to the same shape.
Empirically, resizing to around $48\times48$ does not affect performance.
This parallelization significantly reduces the computation time compared to the sequential computation of SSIM.
However, memory usage tends to be large because all data should be on GPU memory at the same time. 
% We need at least $n\times n \times \#\mathrm{channel} \times \mathrm{width} \times \mathrm{height} \times 4$ bytes GPU memory.

\vskip.5\baselineskip\noindent\textbf{Divide-and-conquer algorithm to reduce memory usage. }
% \paragraph{Divide-and-conquer algorithm to reduce memory usage.}
% GPUを用いた並列計算の欠点として、メモリ使用量の増大が挙げられる。分割統治法を用いて一度にGPUメモリに載せるデータ量を削減することでこの問題に対処する。
% 大きな元問題をそれよりも小さいsub problemに分解し、全てのsub problemを解くことで元問題を解決するアルゴリズムを総称して分割統治法と呼ぶ。
% \Cref{fig:divideandconquer}に分割統治法の概略を示す。
% また、分割統治法を用いることで冗長な計算を省略する効果も期待できる。
% 単純な実装では$n^2$個の要素を持つ行列として一度にSSIMを計算するため、$n(n-1)/2$個分余計な計算をする必要がある。しかし、SSIM行列の対称性を考慮した分割統治法を考えることで、SSIM行列を上三角（下三角）行列に近い形で計算することができるようになる。
We use the divide-and-conquer algorithm to reduce the peak memory usage during parallelization on GPU.
Divide-and-conquer is a paradigm that solves a problem by breaking it into smaller sub-problems and solving all the sub-problems.
\Cref{fig:divideandconquer} illustrates the divide-and-conquer algorithm for our SSIM computation.
SSIM is calculated as a matrix with $n^2$ elements at once with simple GPU parallelization. However, our divide-and-conquer-based implementation first computes SSIM for sub-matrices of the overall matrix of appearance feature ($A$) and merges them later.
As a result, our implementation computes the SSIM matrix as nearly upper triangular and significantly reduces the peak GPU memory usage. 
% Our divide-and-conquer algorithm considers this feature to compute the SSIM matrix as close to the upper triangular as possible.
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/miscellaneous/divide-and-conquer.pdf}
    \caption{Illustration of our divide-and-conquer algorithm for SSIM calculation. 
    First, the matrix of appearance feature ($A$) is recursively divided into four blocks at each recursion step. Second, the SSIM values of each block are calculated in parallel when the size of the divided blocks becomes sufficiently small. Blocks of lower triangular parts are excluded from the computation target because this part can be completed using the symmetry of $A$. Finally, computation results for small blocks are merged. 
    % The lower triangular part can be completed using symmetry.
    }
    \label{fig:divideandconquer}
\end{figure}
% \begin{algorithm}
% \caption{Divide-and-Conquer for SSIM}\label{alg:cap}
% \begin{algorithmic}
% \Require
% \Ensure
% \State $i \gets 10$
% \If{$i\geq 5$} 
%     \State $i \gets i-1$
% \Else
%     \If{$i\leq 3$}
%         \State $i \gets i+2$
%     \EndIf
% \EndIf 
% \end{algorithmic}
% \end{algorithm}

\vskip.5\baselineskip\noindent\textbf{Omission of redundant computation. }
% \paragraph{Omission of redundant computation.}
% 直前のセクションに記述した分割統治法の使用を前提として、冗長な計算を更に回避するための工夫について述べる。
% 説明に用いる用語として、まずIntersection行列を定義する。Intersection行列とは、Bbox $i$と$j$が重なるなら$1$, そうでないなら$0$を$ij$成分に持つような行列であるとする。
% Based on our divide-and-conquer algorithm, we can further reduce the SSIM computation between predictions with no overlap because $P_1$ and $P_2$ in~\cref{eq:qaqs,eq:qaqs_c} take $0$ for these predictions.
The SSIM calculation for predictions with no overlap can be omitted without affecting the coefficient matrix because the corresponding pairwise scores ($P_1$ and $P_2$) are 0.
To enhance the effectiveness of this technique, we permute the order of predictions before SSIM computation.
% \paragraph{Ignore prediction pairs with no overlap}
% % 提案手法であるQAQSアルゴリズムでは、外観特徴量を$Q$行列の非対角成分のみに作用させる。加えて、非対角成分を構成する$P_1, P_2$はBbox $i$と$j$が重なりを持たない場合$0$になる。従って、Intersection行列の要素が0となるようなBboxの組についてはSSIMを計算しなくてもQ行列の構成に影響を与えることはない。
% The appearance feature is only multiplied by the non-diagonal components of the coefficient matrix $Q$, which takes $0$ when the predictions $i$ and $j$ do not overlap.
% Thus, we can omit the SSIM computation of pairs of predictions corresponding elements of the \textit{Intersection Matrix} are 0 without any impact on the overall $Q$ matrix construction.
% \paragraph{Permuting intersection matrix}
% Intersection行列の要素が0となるようなBboxの組がなるべく隣り合うようにIntersection行列を構成することができれば、そのような組に対するSSIM計算を省略することができ、計算コストを大幅に削減できると考えられる。
% このようなIntersection行列の構成は、例えばReverse Cuthill Mckee (RCM) アルゴリズム~\cite{Cuthill1969RCM}を用いてIntersection行列を並べ替えることで実現できる。
% RCMアルゴリズムは行列の帯域幅（非ゼロ成分の対角線からの距離の最大値）を削減するために用いられる。
% \Cref{fig:plot_intersection_mat}にRCMアルゴリズム適用前後のIntersection行列の様子を可視化する。
% このように、Intersection行列の非ゼロ要素がなるべく対角成分に近づくよう並べ替えることで、対角線から離れた成分の計算を省略することができる。
% RCMアルゴリズムは幅優先探索 (BFS)に基づいているため、Intersection行列の列数（行数）を$n$, 非ゼロ要素数を$m$とした時、計算量は高々$O(n+m)$である。$n$は予測ボックス数なので高々$100$程度であることを考慮すると、RCMアルゴリズムの実行時間は極めて軽微である。
We define the \textit{Intersection Matrix} $I\in\{0, 1\}^{n\times n}$ as a symmetric matrix whose $ij$ element takes 1 if predictions $i$ and $j$ are overlapped and otherwise 0.
Then, we permute $I$ using the Reverse Cuthill Mckee (RCM) algorithm~\cite{Cuthill1969RCM} so that the non-zero elements of $I$ are as close as possible to diagonals.
As shown in \cref{fig:plot_intersection_mat}, the permuted $I$ has large zero matrix blocks, where corresponding SSIM computations are efficiently omitted.
The RCM algorithm is based on breadth-first search and minimizes the bandwidth of the matrix, i.e., the maximum distance between non-zero and diagonal elements.
The time complexity of the RCM algorithm is $O(n+m)$, where $n$ is the number of columns and rows of $I$, and $m$ is the number of non-zero elements of $I$.
The overhead of the RCM algorithm is negligible because the number of predictions, $n$, is not so large.
% By permuting $I$ so that it has as large zero matrix blocks as possible, the SSIM calculation for those zero matrix blocks can be efficiently omitted. 
% To achieve this, we use the Reverse Cuthill Mckee (RCM) algorithm~\cite{Cuthill1969RCM} so that the non-zero elements of $I$ are as close as possible to diagonals.
% The RCM algorithm permutes the matrix to minimize its bandwidth, i.e., the maximum distance between non-zero and diagonal elements.
% \Cref{fig:plot_intersection_mat} visualizes the \textit{Intersection Matrix} $I$ before and after applying the RCM algorithm.
% The RCM algorithm is based on breadth-first search. Thus, its time complexity is $O(n+m)$, where $n$ is the number of columns and rows of $I$, and $m$ is the number of non-zero elements of $I$. The overhead of the RCM algorithm is negligible because the number of predictions, $n$, is not so large.
\begin{figure}
    \centering
    % \includegraphics[width=0.8\linewidth]{fig/miscellaneous/sample.pdf}
    \begin{subfigure}[b]{0.45\linewidth}
         \centering
         \includegraphics[width=\linewidth]{fig/before.pdf}
         \caption{Before RCM algorithm.}
     \end{subfigure}
     \hfill
    \begin{subfigure}[b]{0.45\linewidth}
         \centering
         \includegraphics[width=\linewidth]{fig/after.pdf}
         \caption{After RCM algorithm.}
     \end{subfigure}
    \caption{Visualization of \textit{Intersection Matrix} $I\in\{0,1\}^{n\times n}$. 
    % The left figure shows $I$ before applying the RCM algorithm, and the right figure shows after the RCM algorithm. 
    Zero-value elements are colored in purple, and one-value elements are colored in yellow.
    }
    \label{fig:plot_intersection_mat}
\end{figure}
