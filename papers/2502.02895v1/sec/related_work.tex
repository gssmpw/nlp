This section reviews the related studies from three topics: object detection, image similarity metric, and application of quantum computing for computer vision.

% \paragraph{Object detection}
\vskip.5\baselineskip\noindent\textbf{Object detection. }
% Non-Maximum Suppression (NMS)冗長な予測を抑制するために多くの物体検出モデルに適用されるアルゴリズムである。
% NMSは予測スコアの降順に予測ボックス間のoverlapを評価し、overlapが閾値以上の予測は全て棄却するというアルゴリズムである。
% したがって、occlusionなどの予測が重なりやすい状況で物体を見逃したり、閾値の設定によって性能が大きくされるという課題が知られている。
% これらの課題に対処するため、アーキテクチャを含むモデルの改善~\cite{Chen2022DATE,YOLOV10,Lv2024detr}や後処理手法の改善~\cite{bodla2017snms,ShenJXLK22CPCluster,shepley2023confluence}といった研究が行われている。
% 後処理手法の改善は、大きくNMSの変種、グラフに基づくフレームワーク, 最適化に基づくフレームワークに大別される。
% NMSの変種としては、NMSの抑制をスコアに対するペナルティという形で緩和したSoftNMS~\cite{bodla2017snms}や、サブネットワークを用いてハイパラを適応的に決定する手法~\cite{Liu2019AdaNMS}, 学習過程を考慮した改善~\cite{Nils2020vgnms,Huang2020VFGNMS}, IoUにかわる新たな指標Proximityを用いた手法~\cite{shepley2023confluence}などがある。複数の予測boxをfuseする手法~\cite{zhou2017cad,solovyev2021weighted}も考案されている。
% グラフに基づく手法~\cite{ShenJXLK22CPCluster}は予測ボックスの重なりに基づき予測集合をグラフとしてモデル化する。信頼度の高い予測には報酬を与えるpositive message, 冗長な検出にはペナルティを与えるnegative messageを生成し、予測スコアを調整することで後処理を行う。
% 本論文の主なターゲットである最適化に基づくフレームワーク~\cite{rujikietgumjorn2013qubo,lee2016individual,li2020qsqs}は、後処理プロセスを最適化問題とみなし、予測スコアと予測ペアに対するスコアに基づく目的関数を最適化することで後処理を行う。
% 本研究の趣旨はQUBOベースの後処理アルゴリズムをさらに洗練させ、量子コンピューターの有望な応用先を開拓することである。究極の後処理アルゴリズムの提案ではない。
Non-Maximum Suppression (NMS) is applied to many object detection models to suppress redundant predictions.
NMS iteratively chooses a prediction in descending order of confidence score and removes predictions whose IoU is higher than the threshold.
This procedure causes a well-known drawback of NMS, such as high sensitivity of the threshold and missing objects in crowded scenes where many objects are likely to be occluded.
To address these issues, the model architectures~\cite{Chen2022DATE,YOLOV10,Lv2024detr} and suppression algorithms~\cite{bodla2017snms,ShenJXLK22CPCluster,shepley2023confluence} have been studied.
The recent suppression algorithms are mainly categorized into NMS variants~\cite{bodla2017snms,zhou2017cad,Liu2019AdaNMS,He2019SofterNMS,Nils2020vgnms,Huang2020VFGNMS,solovyev2021weighted,shepley2023confluence}, graph-based methods~\cite{ShenJXLK22CPCluster}, and optimization-based methods~\cite{rujikietgumjorn2013qubo,lee2016individual,li2020qsqs}.
The most famous NMS variant is Soft-NMS~\cite{bodla2017snms}, which uses a scoring-based penalty for overlapped predictions instead of threshold-based suppression.
CP-Cluster~\cite{ShenJXLK22CPCluster} is a graph-based method that treats the predictions as a graph whose adjacent matrix is based on the overlap among predictions. 
The main focus of our study is optimization-based suppression, which formulates the suppression as an optimization problem. The redundant predictions are suppressed by optimizing the objective function that considers the confidence score and pairwise score of predictions.
Our primary goal is to foster promising applications for quantum computers by refining the QUBO-based suppression algorithm rather than developing an ultimate suppression algorithm that outperforms all other suppression algorithms in every possible scenario.

\vskip.5\baselineskip\noindent\textbf{Image similarity metric. }
% \paragraph{Image similarity metric}
% 類似画像検索や画像品質評価などを目的として、画像同士の類似度を定量化する手法が研究されている。最も単純な方法は、画素値の出現頻度を元に作成したヒストグラム同士を比較する方法である。QUBOへの応用を考える場合、値の範囲が$[0, 1]$に収まるため係数行列のスケールを調整しやすい一方で計算の並列化が難しく、計算時間の点で課題がある。
% AKAZE~\cite{alcantarilla2013akaze}やSIFT~\cite{lowe1999sift}に代表される特徴点検出手法を用いた画像類似度評価手法も提案されている。これらの手法は比較的計算コストが低いものの、画像サイズが小さいと特徴点検出がうまくいかないなどの課題がある。
% SSIM~\cite{wang2004ssim,hore2010psnr_ssim}やPeak Signal to Noise Ratio (PSNR)~\cite{hore2010psnr_ssim}は人間の知覚を反映するように設計された、主に画像品質評価等で使用される指標である。SSIMは画像生成モデルの損失関数として用いられることもある~\cite{ZhaoGFK17ImgRestore}。
% 深層学習モデルを用いた類似度評価手法も研究されている。Learned Perceptual Image Patch Similarity (LPIPS)~\cite{zhang2018lpips}は事前学習された画像分類モデルの特徴マップを元に複数の画像の視覚的類似性を定量化する。画像のピクセル値や輝度のみに注目した従来の手法と比較してより人間の認識を反映した定量化が可能であるが、画像特徴量を抽出する必要があるという点で従来手法よりも計算コストが高い。
Towards similar image retrieval and image quality evaluation, methods to quantify the similarity between images have been developed. The simplest method is to compare the color histograms of images computed from the frequency of pixel values. Considering its application to QUBO, its value range $[0, 1]$ is preferable to adjust the scale of the coefficient matrix but computationally expensive.
Keypoint-based methods~\cite{lowe1999sift,alcantarilla2013akaze} are computationally reasonable but do not work well for small images.
SSIM~\cite{wang2004ssim,hore2010psnr_ssim} and Peak Signal to Noise Ratio (PSNR)~\cite{hore2010psnr_ssim} are designed to reflect human perception and are mainly used for image quality evaluation. SSIM is also used as the loss function of generative models~\cite{ZhaoGFK17ImgRestore}. In contrast to SSIM, PSNR is unsuitable for integration into QUBO because its value range is not scaled to $[0, 1]$.
Deep learning-based methods have also been studied. 
\citet{lee2016individual} used CNN features for optimization-based suppression, but this approach is model-specific and computationally expensive.
Learned Perceptual Image Patch Similarity (LPIPS)~\cite{zhang2018lpips} quantifies the visual similarity of images based on the feature maps of a pre-trained image classifier. LPIPS is closer to human perceptions but computationally expensive than conventional metrics directly calculated from pixel values.

\vskip.5\baselineskip\noindent\textbf{Application of quantum computing for computer vision. }
% \paragraph{Application of quantum computing for computer vision}
% 本論文が扱う、物体検出における後処理のようなComputer visionに現れる組合せ最適化問題をQUBOとして定式化することで、quantum computingをcomputer visionに応用する研究が行われている。
% Multi-object Tracking~\cite{Ngeni2023,zaech2022}への応用では、動画フレーム間の検出結果を対応づける問題をQUBOとして定式化することで量子計算を適用している。
% \citet{meli2022}は点群から剛体変換を推定する問題をQUBOとして近似し、QUBOを反復的に解くことで変換を推定する手法を提案した。
Quantum computing has recently been applied to computer vision tasks that involve combinatorial optimization problems~\cite{o2018nonnegative,golyanik2020quantum,birdal2021quantum,doan2022}.
In multi-object tracking~\cite{Ngeni2023,zaech2022}, the detection of the same object between consecutive video frames should be matched. Quantum computer solves the QUBO formulation for this matching problem.
\citet{meli2022} approximates the estimation problem of momentum transformation from point crowd as QUBO. The momentum transformation is estimated by iteratively solving the approximated QUBO.
Although these applications are formulated as constrained problems, the QUBO-based suppression is unconstrained.

% Quantum annealing vs quantum gate simulator, application in computer vision (Multi-object tracking \cite{Ngeni2023,zaech2022}, transformation estimation \cite{meli2022}, robust fitting \cite{doan2022}), QAOA \cite{farhi2014quantum}
% As noted by \cite{Harashta2022}, current applications of quantum computing in computer vision were based on quantum annealing (adiabatic quantum computing (AQC)). On the contrary, we apply QAOA, which works on gate-based quantum computers, to post-processing in object detection.

% \subsection{Object detection}
% \subsubsection{OC-cost}
% Optimal Correction Cost（OC-cost）と呼ばれる物体検知の新しい評価指標。
% 推論結果からgroud truthへの最適輸送問題として扱い、画像ごとに修正コストを算出して低いほど良い評価指標とするOC-costを提案。コスト行列のそれぞれの要素はクラス識別に関する誤差と予測位置の誤差から計算したもの。このコスト行列からトータルの修正コストが最小となるような検出結果と真値アノテーションの対応を最適輸送問題を解くことで求め, 修正にかかったコストをOC-costとする。良い点は次のとおり。
% \begin{itemize}
%     \item 識別の誤差と位置ずれの誤差を同時に評価できる
%     \item 余分な検出に対してペナルティを与える
% \end{itemize}
% 性質的に良し悪しあるので、mAPを置き換えるものではなく、違った観点から評価できるものと捉えるべき。

% \subsubsection{Faster R-CNN}
% 候補提案型の物体検知モデルでFast R-CNNの改良版。1.特徴抽出ネットワーク, 2.候補領域抽出ネットワーク, 3.物体検知ネットワークの3つの要素から構成されている。Fast R-CNNでボトルネックになっていた領域提案（Region-proposal）のSelective Searchアルゴリズム\cite{uijlings2013selective}をRegion Proposal Network（RPN）に置き換えることでend-to-endでの学習を可能にした。特徴抽出ネットワークを新しいものに変更することで性能向上が可能なため現在でも比較手法として用いられる。

% \subsubsection{YOLOv5}
% Ultralytics社により公開されているもので査読付きの研究として公開されているわけではないため信頼性に疑念があったが、いくつかのアプリケーションで利用され効果的な結果を得たので物体検知モデルとして信頼性がある\cite{ex1, ex2}。

% \cite{ex1}は地震による被害家屋の検知を目的とした産業応用。（かなり局所的だけど）小さな人工ターゲットの検出についてはYOLOシリーズの性能が良いことが知られている。YOLOv5sに対して特徴抽出ネットワークにViT構造を、マルチスケール特徴融合のために双方向特徴ピラミッドネットワーク(BiFPN)を適用して改良をすることで、精度と速度の両面で既存手法を凌駕する。

% \cite{ex2}は養殖魚の追跡と異常行動の検知を目的とした産業応用。画像中の魚はターゲットとして非常に小さく、オクルージョン状態であることが多いが、特徴マッピングを追加してYOLOV5sを改良することで高精度なリアルタイムでの検知・追跡を可能にする。

% \subsubsection{YOLOv8}
% 上と同じ会社によるもので査読つき論文はない。こちらもいくつかのアプリケーションで利用されて効果的な結果を得ている\cite{reis2023real, varghese2024yolov8}。2024年2月時点での最先端モデル。

% \cite{reis2023real}は飛行物体のリアルタイムでの検知を目的とした応用（ドローンや無人航空機を想定しているので日本ではあまり関係なさそう）。2022年時点でのSOTAと考えられていたYOLOv8を再学習して利用、YOLOv8に公の論文がないので中身のアーキテクチャについても調査。YOLOv8はCSPDarknet53をバックボーンに利用し、徐々にダウンサンプリングすることで複数のスケールで特徴を抽出できる。YOLOv8は異なるスケールで異なる特徴マップを組み込むことができ、ほとんどの物体検出タスクで高い精度達成する。2つのデータセットで学習し、高い精度を達成。

% \cite{varghese2024yolov8}はYOLOv8の調査論文。YOLOv7から小物体検知へに対する課題を克服。様々なデータセットでの実験結果から、多様なシナリオにおけるYOLOv8が検出精度と計算効率の両面で優れた有効性を確認し実世界のアプリケーションへの適性を検証。

% \subsubsection{DETR}
% Detection Transformer（DETR）は2020年に発表されたもので自然言語分野のTransformerを物体検出に応用したもの。Transformerの注意機構を利用することで、物体同士の関係性を捉え予測とground truthの1対１の学習を可能にし候補領域の設定（アンカー生成）とNMSなどの後処理を排除することに成功した。近年最も注目されている手法ではあるが、小物体の検出精度や学習量などに課題が残る。

% \subsubsection{RT-DETR}
% DETR以降NMSフリーなモデルが提案されているが、計算コストの高さから実用性が制限されNMSを除外する利点を十分に活用できていない。Real-time Detection Transformerは初のリアルタイムで動作するend-to-endな物体検知器である。RT-DETR-R50はCOCO val2017で53.1\%、T4 GPUで108FPSを達成し、RTDETR-R101は54.3\%のmAPと74FPSを達成し、速度と精度の両方でYOLOv8のLとXモデルを上回った（Rの後ろの数字はResNetの層数）。scaled RT-DETRとして層を減らすことで、精度を落として速度を獲得することも可能 (YOLOシリーズのs, m, lのイメージ)。RT-DETRは総合的に同程度のモデルサイズの最先端のリアルタイム検出器を凌駕するが、他のDETR亜種と同様に小さな物体に対する性能はリアルタイム検出器よりまだ劣ることは課題として残る。

% \subsubsection{ATSS}
% anchor-basedの検出器とanchor-freeの検出器の本質的な違いについての研究\cite{zhang2020bridging}で、アンカーの有無ではなく学習時におけるpositive-negativeなサンプルの定義に差があることを実験的に明らかにした。anchor-base、freeどちらにも適用可能な、物体の統計的特徴に応じてpos-negなサンプルを自動的に選択するAdaptive Training Sample Selection（ATSS）を提案。

% \subsection{Post-processing for object detection}
% \subsubsection{NMS, Soft-NMS}
% 最も広く使われる手法。NMSはbboxをスコア順に並べて一番高いものを選択し、閾値以上の重なりを持つbboxを全て削る。Soft-NMSは閾値以上の重なりを持つものに対してgaussian関数でconfidence scoreをリスコアし、スコアが閾値以下のbboxを削除することでNMSの過剰消しを改善。

% \subsubsection{QSQS}
% QUBOを利用した後処理手法。QUBOベースの後処理手法\cite{rujikietgumjorn2013qubo}に対して、全てのbboxの分類スコアとそれら全てのペア間の重複が等しく考慮されるため, 混雑したobjectや部分的な重なりがある検出には適さないという指摘があり、その改善として\cite{lee2016individual}の空間特徴量を取り入れて精度を改善した手法。

% \subsubsection{Adaptive-NMS}
% ターゲット密度に応じて、インスタンスに動的抑制閾値を適用するadaptive-NMSを提案。密度スコアを学習するための効率的なサブネットワークを設計し、これを1段検出器と2段検出器の両方に組み込む。CityPersonsとCrowdHumanベンチマークで最先端の結果を達成。NMS閾値が高いと混雑した（bboxを消せないので）インスタンスが多くなり、NMS閾値が低いと（bboxを消しすぎるので）偽陽性を一掃する。このように、adaptive-NMSは、インスタンスが集まり、互いに閉塞するにつれて閾値が上昇し、インスタンスが別々に現れると減衰する、動的抑制戦略を適用する。この目的のために、各インスタンスの適応的NMS閾値を予測するための補助的で学習可能なサブネットワークを設計する。異なるように見えて実際には、greedy-NMSとsoft-NMSの設計は同じ仮説に従う:Mとの重なりが大きい検出ボックスは偽陽性である可能性が高いはず
% この仮説は、オクルージョンがほとんど起こらないのであれば、一般的な物体検出など、問題はない。しかしこの仮定は人間のインスタンスが互いに高度に重複しており、偽陽性として扱われるべきでない混雑したシナリオでは成立しない。計算量はこれまでのNMSと同じ。物体密度を定義して適応的に閾値を変化させる。

% \subsubsection{softer-NMS}
% bboxのラベルの座標が一貫しないサンプルの悪影響を緩和するために、bbox座標を確率的な表現でモデル化し、得られたbbox座標予測のuncertaintyを利用してNMSにおいてクラス予測の精度とbbox回帰の精度をともに加味して間引く手法？？？

% \subsubsection{vg-NMS}
% 追加のサブネットワークなしにはピクセルベースとアモーダルオブジェクトの検出を可能にする手法。アモーダルな検出とは、脳内で欠けた部分を補完するように、対象物の一部が隠れて見えないとき、全体像として認識する検出。特に自律走行用に調整されたデータセットで優位。Adaptive-NMSやLearning NMSのようにネットワークを追加すると、推論時間が長くなり、計算量が限られ、リアルタイムで実行可能なアルゴリズムが重要な完全自律走行のメリットが減少する。SSDのアーキテクチャを一部改良してモデル化。vg-NMSの主なアイデアは、オブジェクトの実際に見える部分を記述するピクセルベースのバウンディングボックスに対してNMSを実行することであるが、ピクセルベースのNMS中に保持されるインデックスに属するアモーダルバウンディングボックスを出力すること。vg-NMSは、標準的なNMSと2つの異なる物体予測セット$B_{pix}$と$B_{amodal}$を組み合わせ、$B_{pix}$に対して標準的なNMSを実行し、インデックスセット$I_{pix}$を返す。ピクセルベースの$_{pix}$とアモーダルバウンディングボックス$D_{amodal}$の両方に対する最終的な有効検出は、$I_{pix}$によって選択される。

% \subsubsection{VFG-NMS}
% vg-NMSと同じで, 視覚できるbboxと（補完することで）考えられる完全なbboxが焦点でVFGメカニズムを提案。学習では、RPNは目に見えるbboxの提案のみを生成するように制限し、可視特徴量を導入して可視bboxと完全bboxを同時に回帰する。ハンガリーアルゴリズムで解いた割り当て問題に変換することで、同じインスタンスに対して、完全なbbox、可視bbox、パーツローカライゼーション（パーツの位置特定のための出力）の結合出力を効果的に生成する。
% vfg-NMSとvg-NMSは学習から工夫することでocclusionに対応。

% \subsubsection{CP-cluster}
% 後処理手法においてSoft-NMSは広く応用できるが、上記にあるようなそれ以外のほとんどは汎用性がない。後処理が必要な全ての物体検知器に対して適用可能なグラフモデルに基づく新しいフレームワークCP-clusterを提案。NMS, Soft-NMSとの差別化点として、1.グラフモデルと信頼メッセージの伝搬によるものでNMSフレームワークに従わない、2.CP-Clusterは真陽性を強化し, 同時に冗長なbboxにペナルティを与える、3. 信頼度でbboxをソートしないことが挙げられる。
% 従来のNMSと違って以下の点で異なる。
% 1.confidence scoreの最も高いbboxが最良の選択という仮説は危ない（何処かでも言及されてた。）、2.冗長なbboxを抑制するだけでなく、真陽性の信頼度を高める、3.各候補のbboxは隣接するbboxによってのみ影響を受ける

% \subsection{Image similarity (SSIMに限定しても良いかも)}
% \subsubsection{SSIM}
% 画像の構造的な類似性を評価するための指標で3つの軸の席を用いて同サイズ画像の類似性を評価する。
% \begin{align}
%     & SSIM\\
%     & = l(\boldsymbol{x}, \boldsymbol{y}) \times c(\boldsymbol{x}, \boldsymbol{y}) \times s(\boldsymbol{x}, \boldsymbol{y})\\
%     & = \left(\dfrac{2\mu_{\boldsymbol{x}}\mu_{\boldsymbol{y}}+C_1}{\mu_{\boldsymbol{x}}^2+\mu_{\boldsymbol{y}}^2+C_2}\right)\cdot \left(\dfrac{2\sigma_{\boldsymbol{x}}\sigma_{\boldsymbol{y}} + C_2}{\sigma_{\boldsymbol{x}}^2+\sigma_{\boldsymbol{y}}^2+C_2}\right) \cdot \left(\dfrac{2\sigma_{\boldsymbol{x}\boldsymbol{y}}+C_3}{\sigma_{\boldsymbol{x}}\sigma_{\boldsymbol{y}}+C_3}\right)
% \end{align}
% ただし$l(\boldsymbol{x}, \boldsymbol{y})$は輝度平均の差、$c(\boldsymbol{x}, \boldsymbol{y})$は画素値の標準偏差、$s(\boldsymbol{x}, \boldsymbol{y})$は画素間の共分散, $C$は定数、$\mu$が平均画素値、$\sigma$が標準偏差。

% \subsubsection{LPIPS}
% Learned Perceptual Image Patch Similarity (LPIPS)は真相学習に基づく画像間の類似度評価に用いられる手法。入力画像に対して、AlexNetやVGGといった学習済み画像分類ネットワークの畳み込み層が出力する特徴量(deep features)を元に算出される。ピクセルの輝度やコントラストのみに注目した従来の手法に比べて、深層学習に基づいた特徴抽出を用いるLPIPSはより精度が高いことがわかっている。「知覚的距離」を定量化して、人間の認識と近いレベルで2つの画像がどれだけ似ているかを測定できるようになりたいというモチベーションによる研究。LPIPSは視覚的な類似性評価には有用だが、正確なピクセル単位の一致が必要なタスクには適していないことが多い。For a given convolutional layer, we compute cosine distance (inthe channel dimension) and average across spatial dimensions and layers of the network. 

% \subsubsection{AKAZE, SIFT etc.}
% SIFT, SURF, KAZE, AKAZE, ORB, そして BRISKなどの特徴点抽出手法。主な用途として、異なる視点から撮影された2つ以上のシーンの画像をマッチングさせ画像統合を図る（3Dモデルの作成など）。\cite{tareen2018comparative}に各手法の調査結果が記載されている。マッチングを学習する手法\cite{sarlin2020superglue}なども提案されている。
% 個人的に実験してきた感想だが、bag-of-visual-wordsや特徴点の上位点でソートできたとしても、解像度の低いもの（画像に対してbboxのサイズがどうしても小さくなるため）は特徴点を取れないので本研究には不向きだと思う、類似度のスケーリングも難しい、もしかしたら高解像度なら（bboxが今のテストデータくらいのサイズになれば）うまくいくかも。

% \subsubsection{perceptual hash}
% A-HASH (TODO: reference). 査読つきの論文はおそらくなく、開発者の個人的なブログで公開されている程度。画像を$8\times8$にリサイズして、画素値の平均$\mu$をとる。各ピクセルに対して$\mu$以上以下を判定し0,1に振り分ける。拡大縮小にロバストで明るさやコントラストの変化に対しても大幅に変わることはない。そのため、occlusionなのか冗長な検知boxなのかについての比較には不適切に思える。P-HASHなどもhash化の方法が異なるだけで画像比較の考え方としては同じ。一応調査論文はあった\cite{hamadouche2021comparative}。

% \subsubsection{PSNR}
% PSNR (TODO: reference)
% \begin{align}
%     & PSNR = 10\log_{10} (\frac{255}{MSE})^2\\
%     & MSE = \frac{1}{MN}\sum_{i}^{M}\sum_{j}^{N}(x_{ij}-y_{ij})^2
% \end{align}
% 2枚の画像の差が少ないとMSEは小さくなり、差が大きいとMSEは大きくなる. よって差が小さいならPSNRは大きくなり、差が大きいならばPSNRは小さくなる。PSNRとSSIMは（一応）どちらも人間の知覚に近い客観的指標とされている。違いは\cite{hore2010psnr_ssim}で述べられている。

% \subsubsection{CNN-Feature}
% 外観特徴量として画像分類CNNの特徴抽出層を用いることもできる。実際\cite{lee2016individual}では空間特徴量だけで個別性を表現しきれなかったためCNN特徴を導入。AlexNet\cite{krizhevsky2012imagenet}、VGG\cite{simonyan2014very}、ResNet\cite{he2016deep}など数多く存在する。画像分類モデルとしての評価であるが、AlexNetはシンプルな画像認識に適していて軽量で手軽、VGGは風景や複数オブジェクトが含まれる画像、精緻な特徴が必要なものに適していて、ResNetは高解像度、複雑なパターン、またはノイズの多い画像に対して非常に優れた表現力を持っている。自分の研究でもこれらは実装していて、そこそこの精度は出せる。LPIPSとどっちがいいのかは分からない。

% \subsubsection{その他}
% 画像の品質を測るFsim\cite{zhang2011fsim}や、SSIMの高速化Fast-SSIM\cite{chen2011fast}。Fast-SSIMで引用されているMuitiscale-SSIM\cite{wang2003multiscale}、Percential Pooling SSIM\cite{wang2003multiscale}、Complex-Wavelet SSIM\cite{wang2005translation}、Gradient-based SSIM\cite{chen2006gradient}、Three-Component Weighted SSIM\cite{li2009three}などが存在するが、どれも計算量を度外視して精度のみに重点を置いている。モバイル機器の急増により複雑性の低いアルゴリズムが必要とされていて、SSIMの計算複雑度の低減に焦点を当て、SSIMと同程度のレベルで動作する、低複雑度のSSIMインデックス(Fast SSIMと呼ぶ)を提案。輝度項の計算に積分画像法\cite{porikli2005integral}を用いて画像の輝度類似度を算出。分散項の計算は、SSIMアルゴリズムの中で最も時間を消費するところなので、勾配値を代入する。

% \subsection{Quantum computing}
% \subsubsection{Multi-object tracking}
% \cite{Ngeni2023}は交通における車両のおクルージョン問題への応用に関する論文。実行速度など期待されている量子ではあるが、その信頼性の低さから量子古典アルゴリズムのハイブリットな手法がよく使われている。後処理におけるQUBOフレームワークの引用\cite{hu2019quantum, li2020qsqs}。DeepSORTアルゴリズムに量子オプティマイザを追加することで、現在の古典的なコスト関数値を最小化するディープ機械学習と人工知能技術を組み込む。これらの技術は、交通データ、特に車両数と分類における計算時間とオクルージョンエラーを大幅に削減する。
% \cite{zaech2022}は断熱量子コンピューティング（AQC）で解くために設計された多オブジェクト追跡（MOT）定式化を提案。QUBO形式へのモデル化は他の手法と変わらない。量子の実用範囲的にまだまだ小規模。

% \subsubsection{transformation estimation}
% \cite{meli2022}は点集合から剛体変換を推定する反復法を提案。実用的な最適化問題をQUBO問題の形で符号化することは、一般的にAQCベースのアルゴリズムを開発するための最初の、そして最も重要なステップである。

% \subsubsection{robust fitting}
% \cite{doan2022}はロバストフィッティングのためのハイブリッド量子古典アルゴリズムを提案。ロバストフィッティングを解くことはランダムサンプリングヒューリスティックに依存しており、最適性の保証や誤差の境界を提供しない。したがって、コストのかかる厳密な解決策と、品質保証を提供しない高速なヒューリスティックとの間のギャップを埋められる、新しいアプローチを開発することが重要。

% \subsubsection{QAOA}
% \cite{farhi2014quantum}は、量子アニーリングと同様に組み合わせ最適化問題の解を求めるためのアルゴリズムで「量子ゲート方式による」組合せ最適化問題の解法。よく扱われるのはネットワーク経路を分割するMaxcut問題だが、物理モデル化による定式化が可能なものは理論上、QAOAにて解を求めることが可能。QAOAは計算量がビット数nではなく、計算の繰り返し回数p、トロッター数ｍで決まる。これによりQAOAはビット数ｎが大きくなっても、古典アルゴリズムのような計算量の爆発が起きない。QAと同じところは多く、固有値問題を扱うところ、QAAを基にしているところ、イジングモデルでハミルトニアン$\boldsymbol{H}{cost}$を作るところ。違うところはQAOA=デジタル、アニーリング=アナログであるところでQAAの時間発展をステップに分けて実現するか、連続的に行うかが主な違いのひとつ\cite{streif2019comparison}。アプリケーションへの応用が可能か？ → 量子ゲートで使える量子ビット数が少ないこと、精度を上げるために反復回数pを多くすると、量子回路が長くなってノイズが大きくなるため現状難しい。

%-----追加-----
%\subsubsection{NMW}
%NMW\cite{zhou2017cad}は重なりあったbBoxをスコアとIoUで重み付けして足し合わせることで、1つの新たなbBoxを作り出すアルゴリズム。密集したbboxに対して平均的なbboxを作った方が物体を捉えられるのではないかという考え。
%\begin{align}
%    & b_{pre}=\frac{\sum_{i=1}^n \omega_i \times b_i}{\sum_{i=1}^n\omega_i}\\
%    & \omega=c_i \times iou(b_i, b_{argmax_{i}c_i})
%\end{align}

%\subsubsection{WBF}
%WBF\cite{solovyev2021weighted}は医療画像の異常検知などリアルタイム検知が不要な場合に精度よく検出するための手法として提案されたアルゴリズム。複数モデルの推論結果をアンサンブルして検出の見落としを防いだり、誤検知をなくしたいという考え。$N$個のモデルに対して、$T$個のbboxが検出されたとき、bboxの座標$(x_i, x_2, y_1, y2)$を再計算する。
%\begin{align}
%    & C=\frac{\sum_{i=1}^T c_i}{T}\\
%    & x_1=\frac{\sum_{i=1}^Tc_{i}x_{1i}}{\sum_{i=1}^T c_i}\\
%    & x_2=\frac{\sum_{i=1}^Tc_{i}x_{2i}}{\sum_{i=1}^T c_i}\\
%    & y_1=\frac{\sum_{i=1}^Tc_{i}y_{1i}}{\sum_{i=1}^T c_i}\\
%    & y_2=\frac{\sum_{i=1}^Tc_{i}y_{2i}}{\sum_{i=1}^T c_i}
%\end{align}

%最後に次の式いずれかでconfidence scoreをリスコアする。
%\begin{align}
%    & C=C \times \frac{min(T, N)}{N}\\
%    & C=C \times \frac{T}{N}
%\end{align}

%\section{object detection mdoel}
%\subsection{2段階検出器}
%\label{detection_model:two-stage}
%物体検出を1.物体がありそうな領域（つまり背景でないと思われる領域）を事前に決める候補領域（Region Proposal）の生成と2.クラス分類＆ボックス回帰の2つのフェーズに分ける手法。R-CNN、Faster R-CNN、 Mask R-CNNに代表される。小さい物体や複雑な背景での検出に強い一方で、2段階のため処理速度が比較的遅い。

%\subsection{1段階検出器}
%フレーム単位でのリアルタイムな物体検出を可能にした物体検出器。YOLOシリーズ、SSD、RetinaNetに代表される。\cref{detection_model:two-stage}の候補領域生成のフェーズを省略し、位置の特定とクラス分類の2つの処理を同時に行うようにすることで、精度は2段階に劣るものの（研究初期の頃の話）高速な推論を可能にした。画像を一つのネットワークに入力して物体検出の結果を得られるend-to-endな手法。

%\subsubsection{関係抽出型}
%注意機構を利用することで、予測bboxとground truthの1対1の関係性を学習しNMSフリーな検出を実現した検知モデル。DETRに代表される。学習量の多さ、小物体の検知精度、（多くの場合で）推論速度は課題。

%\subsection{量子アルゴリズム}
%\subsubsection{QA}
%古典アルゴリズムのSAに対応する量子によるメタヒューリスティック？な手法。数理最適化の「コスト関数の最小化」が物理の「ハミルトニアンにより決まるエネルギー関数の基底状態のスピンを配位を見つける（最も安定した状態を見つける）」ことに対応する。SAの熱揺らぎに対応して量子揺らぎを利用して探索することでエネルギー関数の最適値を見つけようというのが基本思想。理論上トンネル効果が期待できるため、エネルギーの増加が大きくてもSAよりは次の探索点を見つけやすい。SAの温度に対応する、良い基底状態を得るための量子揺らぎを制御するための定数は知られていて、減衰の仕方もSAよりは速いため高速ではあるが、理論上の話であくまでも最悪評価。どのような量子揺らぎを導入するとより高速で汎用的なアルゴリズムとなりうるか，という問題はおそらく解決されていない。QAの枠組みの中で非常にゆっくりとした制御で確実に最適化問題の成果を得る手法を特に量子断熱計算（QAA）と呼ぶ。\cite{rajak2023quantum, streif2019comparison}

%\subsubsection{量子応用}
%Nonnegative/binary matrix factorization with a D-Wave quantum annealer\cite{o2018nonnegative}
%:顔画像の特徴学習を題材に、行列分解をする際、その行列分解の計算の一部にD-Wave量子アニーラーを利用する。

%A Quantum Computational Approach to Correspondence Problems on Point Sets\cite{golyanik2020quantum}
%：（2次元）点集合を一致させるもの、変換推定と点集合の整列（順序付）をQUBOに埋め込んで解く。

%Quantum Permutation Synchronization\cite{birdal2021quantum}
%：同期化（Synchronization）は複数のカメラやセンサーからの映像データを時間的に一致させるプロセスで、それをQUBOに定式化してさらに順列制約を加えることで複雑ではあるが、高度な同期化を可能にする。そしてそれをQAで解く。一つ上の論文を引用していて、関連度が高い。