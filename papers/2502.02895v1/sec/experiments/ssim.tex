\subsection{Ablation study of our implementation of SSIM}
\begin{figure}[t]
     \centering
     \begin{subfigure}[b]{0.45\linewidth}
         \centering
         \includegraphics[width=\linewidth]{fig/ssim/time_CH.pdf}
         \caption{Computation time}
         \label{fig:ssim_time}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.45\linewidth}
         \centering
         \includegraphics[width=\linewidth]{fig/ssim/mem_CH.pdf}
         \caption{GPU memory usage}
         \label{fig:ssim_memory}
     \end{subfigure}
        \caption{Ablation study of SSIM computation. \textit{Naive} is the sequential computation on the CPU based on the implementation of scikit-image. \textit{GPU} represents the GPU parallelization. \textit{Rec} represents the recursive computation using the divide-and-conquer algorithm. \textit{Ord} shows the reordering of \textit{Intersection Matrix} to avoid redundant computation.}
        \label{fig:ssim_ablation}
\end{figure}
% SSIM高速化手法に含まれる各工夫の効果を検証するため、SSIM計算時間及び必要なGPUメモリ量を調査する。
% COCOデータセットを用いる場合は NVIDIA Geforce RTX 3090搭載の計算機を、CrowdHumanデータセットを用いる場合はGPUのout of memoryを避けるため、NVIDIA RTX A6000搭載の計算機を用いて実験を行う。
% \Cref{fig:ssim_ablation}に、高速化の恩恵がより顕著である、CrowdHumanデータセットに対する測定結果を示す。
% scikit-image\footnote{\url{https://scikit-image.org/docs/stable/auto_examples/transform/plot_ssim.html}}の実装を用いた逐次計算をベースラインとする。
% 全ての工夫を適用することで、1GiB弱のGPUメモリ消費と引き換えに、処理時間をベースラインの2.0 sec/image,  10.5 sec/imageから6ms/image, 14ms/imageまで削減することができる。
We investigate the impact of each technique in our SSIM implementation on the computation time and peak GPU memory usage.
% The experiments for the COCO dataset are conducted on NVIDIA RTX 3090, and those for the CrowdHuman dataset are conducted on NVIDIA RTX A6000 to avoid out-of-memory errors.
\Cref{fig:ssim_ablation} shows the results for the CrowdHuman dataset, which has more pronounced benefits from our faster implementation.
We use the sequential computation of SSIM implemented on scikit-image
% \footnote{\url{https://scikit-image.org/docs/stable/auto_examples/transform/plot_ssim.html}}
\footnote{\url{https://scikit-image.org}} % ページ数対策
as the baseline.
To summarize the experiments, applying all the techniques reduces the computation time from the baseline of approximately 2.0 and 10.5~s/image to 6 and 14~ms/image, respectively, at the cost of under 1~GB GPU memory usage.

\vskip.5\baselineskip\noindent\textbf{Effect of parallelization on GPU. }
% \paragraph{Effect of parallelization on GPU.}
% ガウスフィルタをウインドウとする畳み込み演算を用いたGPU並列化の効果を検証するため、ベースラインと実行時間を比較する。ベースラインはCPUのみで計算を行うため、必要メモリ量は考慮しない。
% COCOデータセットの場合、ベースラインは9,866秒、畳み込み演算に基づくGPU並列では43秒でバリデーションデータに含まれる全ての画像に対するSSIM計算が完了する。
% CrowdHumanデータセットの場合、ベースラインは46,178秒、畳み込み演算に基づくGPU並列では163秒でバリデーションデータ全てに対するSSIM計算が完了する。
% 計算速度に関しては畳み込み演算を活用したGPU並列化の効果が最も大きく、COCOデータセットでは計算時間が約2.0 sec/imageから約8.6 ms/imageに, CrowdHumanデータセットでは約10.5 sec/imageから約37 ms/imageに改善した。
We validate the efficacy of GPU parallelization by comparing it to baseline implementation. We do not consider GPU memory usage because the baseline only uses CPU.
Although the baseline requires 9,866 and 46,178 seconds to compute SSIM for all COCO and CrowdHuman validation images, the GPU-parallelized version only takes 43 and 163 seconds, respectively.
This parallelization significantly enhances the throughput, reducing the compute time from approximately 2 and 11~s/image to 8.6 and 37~ms/image for the COCO and CrowdHuman datasets.

\vskip.5\baselineskip\noindent\textbf{Effect of divide-and-conquer algorithm on GPU memory usage. }
% \paragraph{Effect of divide-and-conquer algorithm on GPU memory usage.}
% 分割統治法の導入によるメモリ使用量及び計算時間への影響を調査するため、ガウスフィルタをウインドウとする畳み込み演算を用いたGPU並列との比較を行う。
% 分割統治法の導入により、COCOデータセットでは実行時間が43秒から33秒に、メモリ使用量が24032MiBから828MiBに減少し、CrowdHumanデータセットでは実行時間が163秒から95秒に、メモリ使用量が41472MiBから924MiBに減少する。
We examine the impact of our divide-and-conquer algorithm on memory usage and calculation time by comparing GPU parallelization with and without divide-and-conquer.
By introducing the divide-and-conquer algorithm, the execution time is reduced from 43 and 163 seconds to 33 and 95 seconds on the COCO and CroudHuman datasets, respectively.
GPU memory usage is also significantly reduced from 
% 24,032 and 41,472~MiB to 828 and 924~MiB for the COCO and CrowdHuman datasets.
24 and 41~GB to 0.83 and 0.92~GB for the COCO and CrowdHuman datasets.
% 改善量を倍率で表現すると、COCOデータセットでは計算時間が約0.77倍, メモリ使用量が約0.034倍に、CrowdHumanデータセットでは計算時間が約0.58倍に, メモリ使用量が約0.022倍に改善した。

\vskip.5\baselineskip\noindent\textbf{Effect of the omission of redundant computations. }
% \paragraph{Effect of the omission of redundant computations.}
% 冗長な計算を回避することで、メモリ使用量はそのままに、計算速度をさらに改善することが期待できる。
% 冗長な計算を回避することの効果を検証するため、畳み込み演算+分割統治法での実行時間との比較を行う。
% COCOデータセットでは実行時間が33秒から30秒に減少し、CrowdHumanデータセットでは実行時間が95秒から62秒に減少した。
The runtime is further reduced with no extra GPU usage by omitting the redundant computation.
We demonstrate this by comparing divide-and-conquer+GPU parallelization with and without omitting redundant computation.
By omitting redundant computation, the computation time is reduced from 33 and 95 seconds to 30 and 62 seconds for the COCO and CrowdHuman datasets without any increase in GPU memory usage.
% 改善量を倍率で表現すると、COCOデータセットでは約0.91倍、CrowdHumanデータセットでは約0.65倍に改善した。
