\subsection{Results}

\noindent\textbf{COCO 2017 dataset. }
% \paragraph{COCO 2017 dataset}
% \begin{itemize}
%     \item QAQS family (proposed methods) outperform QSQS, an existing QUBO-based post-processing.
%     \item QAQS family shows competitive or slightly better performance than S-NMS, a de facto standard method.
%     \item Variations of C-NMS shows the best performance.
% \end{itemize}
% \Cref{tab:coco_f_r_cnn}にCOCOデータセットにおける実験結果を記載する。提案手法であるQAQS, QAQS-Cは既存手法であるQSQSと比較してそれぞれmAPが1.21, 1.31 point高く、ARが最大で3.93, 4.38 point高い。特に大きな物体に対するmAP, mARの改善が顕著である。
% mAPとARの両方が改善しているということは、見逃し (true negative)が少なく、過検知 (false positive)が少ないことを意味する。この実験結果は、冗長な検出（過検知, false positive）を減らしつつ、見逃し (true negative)を極力少なくするという、提案手法の設計思想を反映したものだと言える。提案手法はNMSやSoftNMSに対しても良好な性能を示している。
The left part of \cref{tab:results_faster_rcnn} shows the results on the COCO dataset. The proposed methods, QAQS and QAQS-C, outperform QSQS by 1.21 and 1.31 points in mAP and 3.93 and 4.38 points in mAR, respectively.
The proposed methods significantly improve mAP and mAR for large objects (mAP@L and mAR@L).
The higher value of mAP and mAR indicates a lower number of false positives and false negatives. These results demonstrate our approach's effectiveness in reducing the number of redundant predictions while detecting more (occluded) true positives. Our methods also show promising results compared to conventional NMS and Soft-NMS for reference.
\setlength\tabcolsep{0.75mm} 
\begin{table*}
    \centering
    \begin{tabular}{l r ccccc c ccccc}
    \toprule
     & & \multicolumn{5}{c}{COCO 2017}& & \multicolumn{5}{c}{CrowdHuman} \\
    \cmidrule(lr){3-7}
    \cmidrule(lr){9-13}
    \multicolumn{2}{c}{Metric} & NMS & Soft-NMS & QSQS$^{*}$ & QAQS$^{*,\dag}$ & QAQS-C$^{*,\dag}$ && NMS & Soft-NMS & QSQS$^{*}$ & QAQS$^{*,\dag}$ & QAQS-C$^{*,\dag}$ \\
    \cmidrule(lr){1-2}
    \cmidrule(lr){3-7}
    \cmidrule(lr){9-13}
    mAP        & ($\uparrow$) & 34.61 & 35.20 & 34.04 & \underline{35.25} & \textbf{35.35} && 34.01 & 34.97 & 31.23 & \underline{35.62} & \textbf{35.77} \\
    mAP@50     & ($\uparrow$) & 54.08 & 55.27 & 52.94 & \underline{55.33} & \textbf{55.50} && 58.47 & 61.23 & 53.28 & \underline{61.89} & \textbf{62.44} \\
    mAP@75     & ($\uparrow$) & 37.69 & 38.14 & 37.19 & \underline{38.17} & \textbf{38.22}& & 35.09 & 35.68 & 32.32 & \textbf{36.15} & \underline{36.14} \\
    mAP@S  & ($\uparrow$)     & 14.70 & \underline{14.82} & 14.63 & 14.79 & \textbf{14.83} &&  9.72 &  9.94 &  9.42 & \textbf{10.09} & \underline{10.08} \\
    mAP@M & ($\uparrow$)      & 33.22 & 33.78 & 32.91 & \underline{33.88} & \textbf{34.02} && 29.16 & 29.93 & 27.11 & \underline{30.35} & \textbf{30.38} \\
    mAP@L  & ($\uparrow$)     & 45.68 & 46.61 & 44.43 & \underline{46.64} & \textbf{46.78} && 48.50 & 50.62 & 43.79 & \underline{51.55} & \textbf{51.81} \\
    \cmidrule(lr){1-2}
    \cmidrule(lr){3-7}
    \cmidrule(lr){9-13}
    mAR@1      & ($\uparrow$) & \textbf{29.26} & \textbf{29.26} & \underline{28.92} & \textbf{29.26} & \textbf{29.26} &  &\textbf{3.36} &  \textbf{3.36} &  \underline{3.34} &  \textbf{3.36} & \textbf{ 3.36} \\
    mAR@10     & ($\uparrow$) & 42.73 & 43.92 & 42.13 & \underline{44.19} & \textbf{44.38} && 24.01 & 24.09 & 23.38 & \underline{24.45} & \textbf{24.46} \\
    mAR@100    & ($\uparrow$) & 43.79 & 45.22 & 42.90 & \underline{45.50} & \textbf{45.90} && 39.77 & 41.92 & 36.19 & \underline{42.57} & \textbf{42.91} \\
    mAR@S  & ($\uparrow$)     & 22.37 & 22.91 & 22.10 & \underline{23.01} & \textbf{23.30} && 16.41 & 17.10 & 15.55 & \underline{17.56} & \textbf{17.78} \\
    mAR@M & ($\uparrow$)      & 43.18 & 44.55 & 42.47 & \underline{44.76} & \textbf{45.17} && 37.00 & 38.61 & 33.86 & \underline{39.29} & \textbf{39.59} \\
    mAR@L  & ($\uparrow$)     & 53.85 & 55.70 & 52.14 & \underline{56.07} & \textbf{56.52} && 54.03 & 57.42 & 48.66 & \underline{58.13} & \textbf{58.55} \\
    \cmidrule(lr){1-7}
    \cmidrule(lr){9-13}
    \end{tabular}
    \\\footnotesize{$^{*}$We report the suppression results only after QUBO, not including soft-scoring in QSQS. $^{\dag}$Proposed method}
    \caption{The experimental results. The best values are shown in \textbf{bold}, and the second-best values are \underline{underlined}. ``S'', ``M'', and ``L'' denote the size of bounding boxes such as small, medium, and large.}
    \label{tab:results_faster_rcnn}
\end{table*}
% \begin{table}
%     \centering
%     \caption{Results on COCO 2017 validation set.}
%     \label{tab:coco_f_r_cnn}
%     \begin{tabular}{l r ccccc}
%     \toprule
%     \multicolumn{2}{c}{Metric} & NMS & S-NMS & QSQS$^{*}$ & QAQS$^{*,\dag}$ & QAQS-C$^{*,\dag}$ \\
%     \midrule 
%     % OC cost    &($\downarrow$)& 31.70 & 33.62 & 35.60 & \textbf{30.99} & 33.00 & 35.32 \\
%     % \midrule
%     mAP        & ($\uparrow$) & 34.61 & 35.20 & 34.04 & 35.25 & 35.35 \\
%     mAP@50     & ($\uparrow$) & 54.08 & 55.27 & 52.94 & 55.33 & 55.50 \\
%     mAP@75     & ($\uparrow$) & 37.69 & 38.14 & 37.19 & 38.17 & 38.22 \\
%     mAP@S  & ($\uparrow$) & 14.70 & 14.82     & 14.63 & 14.79 & 14.83 \\
%     mAP@M & ($\uparrow$) & 33.22 & 33.78      & 32.91 & 33.88 & 34.02 \\
%     mAP@L  & ($\uparrow$) & 45.68 & 46.61     & 44.43 & 46.64 & 46.78 \\
%     \midrule
%     mAR@1      & ($\uparrow$) & 29.26 & 29.26 & 28.92 & 29.26 & 29.26 \\
%     mAR@10     & ($\uparrow$) & 42.73 & 43.92 & 42.13 & 44.19 & 44.38 \\
%     mAR@100    & ($\uparrow$) & 43.79 & 45.22 & 42.90 & 45.50 & 45.90 \\
%     mAR@S  & ($\uparrow$) & 22.37 & 22.91     & 22.10 & 23.01 & 23.30 \\
%     mAR@M & ($\uparrow$) & 43.18 & 44.55      & 42.47 & 44.76 & 45.17 \\
%     mAR@L  & ($\uparrow$) & 53.85 & 55.70     & 52.14 & 56.07 & 56.52 \\
%     \bottomrule
%     \end{tabular}
%     \footnotesize{$^{*}$ QSQSにおけるsoft-scoringを含まない、QUBOのみを用いた後処理結果に対応する指標を報告しています。 $^{\dag}$ 提案手法}
% \end{table}

% \begin{table}
%     \centering
%     \caption{COCO2017Val (5000(4980) images), C-NMS: threshold=0.1, NMS: IoU threshold=0.3}
%     \label{tab:coco_f_r_cnn}
%     \begin{tabular}{l r cccccc}
%     \toprule
%     \multicolumn{2}{c}{Metric} & NMS & S-NMS & C-NMS & QSQS & QAQS & QAQS-2 \\
%     \midrule 
%     % OC cost    &($\downarrow$)& 31.70 & 33.62 & 35.60 & \textbf{30.99} & 33.00 & 35.32 \\
%     % \midrule
%     mAP        & ($\uparrow$) & 34.61 & 35.20 & \textbf{35.36} & 34.04 & 34.90 & 35.25 \\
%     mAP@50     & ($\uparrow$) & 54.08 & 55.27 & \textbf{55.51} & 52.94 & 54.59 & 55.32 \\
%     mAP@75     & ($\uparrow$) & 37.69 & 38.14 & \textbf{38.24} & 37.19 & 37.90 & 38.15 \\
%     mAP@S  & ($\uparrow$) & 14.70 & 14.82 & \textbf{14.84} & 14.63 & 14.69 & 14.82 \\
%     mAP@M & ($\uparrow$) & 33.22 & 33.78 & \textbf{33.99} & 32.91 & 33.50 & 33.87 \\
%     mAP@L  & ($\uparrow$) & 45.68 & 46.61 & \textbf{46.81} & 44.43 & 46.08 & 46.62 \\
%     \midrule
%     mAR@1      & ($\uparrow$) & \textbf{29.26} & \textbf{29.26} & \textbf{29.26} & 28.92 & 29.19 & 29.24 \\
%     mAR@10     & ($\uparrow$) & 42.73 & 43.92 & \textbf{44.39} & 42.13 & 43.48 & 44.21 \\
%     mAR@100    & ($\uparrow$) & 43.79 & 45.22 & \textbf{45.92} & 42.90 & 44.56 & 45.63 \\
%     mAR@S  & ($\uparrow$) & 22.37 & 22.91 & \textbf{23.30} & 22.10 & 22.47 & 23.13 \\
%     mAR@M & ($\uparrow$) & 43.18 & 44.55 & \textbf{45.18} & 42.47 & 43.79 & 44.91 \\
%     mAR@L  & ($\uparrow$) & 53.85 & 55.70 & \textbf{56.57} & 52.14 & 54.94 & 56.19 \\
%     \bottomrule
%     \end{tabular}
% \end{table}

\vskip.5\baselineskip\noindent\textbf{CrowdHuman dataset. }
% \paragraph{CrowdHuman dataset. }
% \begin{itemize}
%     \item QAQS family (proposed methods) outperform QSQS, an existing QUBO-based post-processing.
%     \item QAQS family shows competitive or better performance than S-NMS, a de facto standard method.
%     \item QAQS family tends to show better mAP, and the C-NMS family is likely to show better mAR.
% \end{itemize}
% \Cref{tab:crowdhuman_fasterrcnn}にCrowdHumanデータセットにおける実験結果を示す。提案手法であるQAQS, QAQS-2は既存手法であるQSQSよりもmAPが4.39, 4.54 point高く、mARが最大9.47, 9.89 point高い。特に大きな物体に対する指標の改善が顕著である。COCOデータセットに対する実験結果と同様、提案手法はNMSやSoftNMSに対しても良好な性能を示している。また、全体的な指標の改善度合いはCOCOの場合よりも大きい。これは、提案手法が混雑した状況においてより有効性が高いことを示唆している。
The right part of \cref{tab:results_faster_rcnn} shows the results on the CrowdHuman dataset. The proposed methods, QAQS and QAQS-C, outperform QSQS by 4.39 and 4.54 points in mAP and 9.47 and 9.89 points in mAR, respectively.
Like the COCO dataset, the proposed methods significantly improve mAP and mAR for large objects (mAP@L and mAR@L).
However, the degree of improvement is larger than that for the COCO dataset.
This indicates that the proposed methods are more effective for crowded scenes where (partial) occlusion is likely to occur.
% \setlength\tabcolsep{0.75mm} 
% \begin{table}
%     \centering
%     \caption{Results on CrowdHuman dataset.}
%     \label{tab:crowdhuman_fasterrcnn}
%     \begin{tabular}{l r ccccc}
%     \toprule
%     \multicolumn{2}{c}{Metric} & NMS & S-NMS & QSQS$^{*}$ & QAQS$^{*,\dag}$ & QAQS-C$^{*,\dag}$ \\
%     \midrule 
%     % OC cost    &($\downarrow$)& \textbf{22.72} & 24.89 & 27.60 & 22.82 & 23.42 & 27.60 \\
%     % \midrule
%     mAP        & ($\uparrow$) & 34.01 & 34.97 & 31.23 & 35.62 & 35.77 \\
%     mAP@50     & ($\uparrow$) & 58.47 & 61.23 & 53.28 & 61.89 & 62.44 \\
%     mAP@75     & ($\uparrow$) & 35.09 & 35.68 & 32.32 & 36.15 & 36.14 \\
%     mAP@S      & ($\uparrow$) &  9.72 &  9.94 &  9.42 &  10.09 & 10.08 \\
%     mAP@M      & ($\uparrow$) & 29.16 & 29.93  & 27.11 & 30.35 & 30.38 \\
%     mAP@L      & ($\uparrow$) & 48.50 & 50.62  & 43.79 & 51.55 & 51.81 \\
%     \midrule
%     mAR@1      & ($\uparrow$) &  3.36 &  3.36 &  3.34 &  3.36 &  3.36 \\
%     mAR@10     & ($\uparrow$) & 24.01 & 24.09 & 23.38 & 24.45 & 24.46 \\
%     mAR@100    & ($\uparrow$) & 39.77 & 41.92 & 36.19 & 42.57 & 42.91 \\
%     mAR@S      & ($\uparrow$) & 16.41 & 17.10 & 15.55 & 17.56 & 17.78 \\
%     mAR@M      & ($\uparrow$) & 37.00 & 38.61  & 33.86 & 39.29 & 39.59 \\
%     mAR@L      & ($\uparrow$) & 54.03 & 57.42 & 48.66 & 58.13 & 58.55 \\
%     \bottomrule
%     \end{tabular}
%     \footnotesize{$^{*}$ QSQSにおけるsoft-scoringを含まない、QUBOのみを用いた後処理結果に対応する指標を報告しています。 $^{\dag}$ 提案手法}
% \end{table}
% \begin{table}
%     \centering
%     \caption{CrowdHuman (4370 images), C-NMS: threshold=0.1, NMS: IoU threshold=0.3}
%     \label{tab:crowdhuman_yolo8}
%     \begin{tabular}{l r cccccc}
%     \toprule
%     \multicolumn{2}{c}{Metric} & NMS & S-NMS & C-NMS & QSQS & QAQS & QAQS-2 \\
%     \midrule 
%     % OC cost    &($\downarrow$)& \textbf{22.72} & 24.89 & 27.60 & 22.82 & 23.42 & 27.60 \\
%     % \midrule
%     mAP        & ($\uparrow$) & 34.01 & 34.97 & \textbf{35.77} & 31.23 & 35.05 & 35.77 \\
%     mAP@50     & ($\uparrow$) & 58.47 & 61.23 & 62.44 & 53.28 & 60.72 & 62.44 \\
%     mAP@75     & ($\uparrow$) & 35.09 & 35.68 & \textbf{36.14} & 32.32 & 35.74 & 36.14 \\
%     mAP@S  & ($\uparrow$) &  9.72 &  9.94 & 10.08 &  9.42 &  9.88 & 10.08 \\
%     mAP@M & ($\uparrow$) & 29.16 & 29.93 & 30.38  & 27.11 & 29.67 & 30.38 \\
%     mAP@L  & ($\uparrow$) & 48.50 & 50.62 & \textbf{51.81}  & 43.79 & 50.66 & 51.81 \\
%     \midrule
%     mAR@1      & ($\uparrow$) &  \textbf{3.36} &  \textbf{3.36} &  \textbf{3.36} &  3.34 &  \textbf{3.36} &  3.36 \\
%     mAR@10     & ($\uparrow$) & 24.01 & 24.09 & \textbf{24.46} & 23.38 & 24.39 & 24.46 \\
%     mAR@100    & ($\uparrow$) & 39.77 & 41.92 & \textbf{42.91} & 36.19 & 41.44 & 42.91 \\
%     mAR@S  & ($\uparrow$) & 16.41 & 17.10 & \textbf{17.78} & 15.55 & 16.79 & 17.78 \\
%     mAR@M & ($\uparrow$) & 37.00 & 38.61 & \textbf{39.59} & 33.86 & 38.04 & 39.59 \\
%     mAR@L  & ($\uparrow$) & 54.03 & 57.42 & \textbf{58.55} & 48.66 & 56.94 & 58.55 \\
%     \bottomrule
%     \end{tabular}
% \end{table}
% \begin{table}
%     \centering
%     \caption{Faster R-CNN, CrowdHuman (4370 images), C-NMS: threshold=0.1}
%     \label{tab:crowdhuman_yolo8}
%     \begin{tabular}{l r cccccc}
%     \toprule
%     \multicolumn{2}{c}{Metric} & NMS & S-NMS & C-NMS & QSQS & QAQS & QAQS-2 \\
%     \midrule 
%     OC cost    &($\downarrow$)& \textbf{22.72} & 24.89 & 27.60 & 22.82 & 23.42 & 27.23 \\
%     \midrule
%     mAP        & ($\uparrow$) & 34.01 & 34.97 & \textbf{35.77} & 31.23 & 35.05 & 35.72 \\
%     mAP@50     & ($\uparrow$) & 58.47 & 61.23 & 62.44 & 53.28 & 60.72 & \textbf{62.48} \\
%     mAP@75     & ($\uparrow$) & 35.09 & 35.68 & \textbf{36.14} & 32.32 & 35.74 & \textbf{36.14} \\
%     mAP@S  & ($\uparrow$) &  9.72 &  9.94 & 10.08 &  9.42 &  9.88 & \textbf{10.09} \\
%     mAP@M & ($\uparrow$) & 29.16 & 29.93 & 30.38  & 27.11 & 29.67 & \textbf{30.40} \\
%     mAP@L  & ($\uparrow$) & 48.50 & 50.62 & \textbf{51.81}  & 43.79 & 50.66 & 51.60 \\
%     \midrule
%     mAR@1      & ($\uparrow$) &  \textbf{3.36} &  \textbf{3.36} &  \textbf{3.36} &  3.34 &  \textbf{3.36} &  \textbf{3.36} \\
%     mAR@10     & ($\uparrow$) & 24.01 & 24.09 & \textbf{24.46} & 23.38 & 24.39 & 24.44 \\
%     mAR@100    & ($\uparrow$) & 39.77 & 41.92 & \textbf{42.91} & 36.19 & 41.44 & 42.78 \\
%     mAR@S  & ($\uparrow$) & 16.41 & 17.10 & \textbf{17.78} & 15.55 & 16.79 & 17.74 \\
%     mAR@M & ($\uparrow$) & 37.00 & 38.61 & \textbf{39.59} & 33.86 & 38.04 & 39.51 \\
%     mAR@L  & ($\uparrow$) & 54.03 & 57.42 & \textbf{58.55} & 48.66 & 56.94 & 58.33 \\
%     \bottomrule
%     \end{tabular}
% \end{table}

% \paragraph{Parameter sensitivity of QAQS (Optional)}
% \begin{itemize}
%     \item Visualize the objective value (mAP, mAR, OC cost) during parameter optimization
%     \item Discuss the relationship between parameter values and evaluation metrics
% \end{itemize}

% \paragraph{解の分布を比較する？}
% 画像一枚あたりのOC costの分布が後処理手法によってどう変化するかを観察してみる？

\vskip.5\baselineskip\noindent\textbf{Qualitative results. }
% \paragraph{Qualitative results}
% 後処理結果を可視化して既存手法と比較する。\Cref{fig:qualitative}に示されるように、提案手法を用いることで(partially-) occluded objectsを検出することができるようになる。一方で、Appearance featureを導入することで悪影響を及ぼす場合がある。代表的な例を\cref{fig:potential_drawback}に示す。複数の物体を中途半端に含むような予測ボックスは、主に単独の物体を表す予測ボックスとは見た目が大きく異なる。Appearance featureを導入するとこのような予測に対するペナルティは相対的に小さくなるため、過検知に繋がる場合がある。
\Cref{fig:visualization} visualizes the detection results after QUBO-based suppressions.
As shown in \cref{fig:qualitative}, the proposed methods can detect the (partially-) occluded objects suppressed by the existing method, QSQS.
The objects suppressed by QSQS overlap with multiple predictions, leading QSQS to impose a larger penalty on these predictions. This excessive penalty can be appropriately mitigated by incorporating appearance features.
The drawback of introducing an appearance feature is shown in \cref{fig:potential_drawback}. 
A prediction that partially contains multiple objects has a different appearance from a prediction that mainly represents a single object. The appearance feature may lead to over-detection, as it limits the penalty for such predictions.
\begin{figure*}[t]
     \centering
     \begin{subfigure}[b]{0.71\linewidth}
         \centering
         \includegraphics[width=\linewidth]{fig/qualitative/qualitative1_v6.pdf}
         \caption{Qualitative results}
         \label{fig:qualitative}
     \end{subfigure}
     % \hfill
     \begin{subfigure}[b]{0.22\linewidth}
         \centering
         \includegraphics[width=\linewidth]{fig/qualitative/qualitative2_v6.pdf}
         \caption{Potential drawbacks}
         \label{fig:potential_drawback}
     \end{subfigure}
        \caption{Visualization of suppressed predictions. Confidence scores of false negatives (\cref{fig:qualitative}) and false positives (\cref{fig:potential_drawback}) are shown outside of each picture.}
        \label{fig:visualization}
\end{figure*}