% \begin{itemize}
%     \item 二つの主要なデータセットに対して実験を行った
%     \item 既存研究(QSQS)に倣い、Faster R-CNNを用いて実験を行った（暫定）
%     \begin{itemize}
%         \item two-stageのbaseline detectorとしてFaster-RCNNを用いた(QSQS, 2020)
%         \item State-of-the-artなtwo-stage detectorを2種類用いた（C-NMS, 採択は2023, preprintとしての公開は2020）
%         \item 様々な種類の検出器に対して既存の後処理手法を明確に上回った後処理アルゴリズムである（CP-Cluster, 2022）
%     \end{itemize}
%     \item ハイパーパラメーターは、一連の探索の末、QSQSと同じ値を用いることにした($w_1=0.4, w_2=w_3=0.3$)
% \end{itemize}
% crowded and non-crowdedなデータセットの両方を用いた実験により、精度及び実行時間の観点から提案手法の有効性を検証する。
% We demonstrate that our QUBO formulations are more accurate than the formulation of QSQS through experiments using both crowded and non-crowded datasets.
We demonstrate the superiority of our QUBO formulations for suppression over the QSQS formulation through experiments on both crowded and non-crowded datasets.
\subsection{Setting}
\noindent\textbf{Dataset and Model. }
% \paragraph{Dataset and Model. }
We use the COCO 2017~\cite{lin2015microsoft} validation set (5,000 images) for non-crowded scenes and the CrowdHuman~\cite{shao2018crowdhuman} validation set (4,370 images) for crowded scenes.
% As follow the existing work~\cite{li2020qsqs}, the QUBO-based suppressions are implemented on two-stage Faster R-CNN~\cite{ren2015faster_r_cnn} baseline detector with ResNet~\cite{HeZRS16resnet} backbone. Although \citet{li2020qsqs} trained the model themselves, we use pre-trained models with ResNet-50 backbone and Feature Pyramid Network~\cite{LinDGHHB17FPN} for reproducibility. 
Following the experimental setting in the existing study~\cite{li2020qsqs}, we implement QUBO-based suppressions on two-stage Faster R-CNN~\cite{ren2015faster_r_cnn} baseline detector with ResNet~\cite{HeZRS16resnet} backbone. While \citet{li2020qsqs} trained their model starting from the public model, we utilize pre-trained models with ResNet-50 backbone and Feature Pyramid Network (FPN)~\cite{LinDGHHB17FPN} to enhance reproducibility.
The pre-trained weight for the COCO dataset is available at PyTorch website\footnote{\url{https://pytorch.org/vision/stable/models/faster_rcnn.html}}. For the CrowdHuman dataset, we use the pre-trained weight\footnote{\url{https://github.com/aibeedetect/bfjdet}} trained by \citet{Wan2021Body}.

\vskip.5\baselineskip\noindent\textbf{Evaluation metrics. }
% \paragraph{Evaluation metrics}
Similar to the existing studies~\cite{ren2015faster_r_cnn,li2020qsqs,shepley2023confluence}, we report the mean average precision (mAP) and mean average recall (mAR), a standard metric for generic object detection. The precise definition of mAP and mAR is the same as those of COCO~\cite{lin2015microsoft}. We report results for a single run because suppression methods are deterministic.

\vskip.5\baselineskip\noindent\textbf{Computer specification. }
% \paragraph{Computer specification}
The experiments are mainly done with Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz and NVIDIA GeForce RTX 3090. Due to the GPU memory usage, ablation studies of SSIM computation with the CrowdHuman dataset are conducted on Intel(R) Xeon(R) Gold 5220R CPU @ 2.20GHz and NVIDIA RTX A6000.
% 1. Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz, NVIDIA GeForce RTX 3090
% 2. Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz, NVIDIA GeForce RTX 3090 (only for fine-tuning)

\subsection{Implementation Details}

\vskip.5\baselineskip\noindent\textbf{Baselines. }
% \paragraph{Baselines}
% 本研究の主なターゲットはQUBO定式化に基づく後処理手法である。そのため、QUBOベースの最先端後処理アルゴリズムであるQSQSをベースラインとして実験を行う。QUBOとしての定式化の良さに焦点を当てるため、従来のQSQSフレームワークに含まれるsoft-scoringは行わず、QUBOの解を後処理結果として比較する。
% 参考までに、従来用いられる後処理アルゴリズムである、NMS、SoftNMS~\cite{bodla2017snms}を適用した際の実験結果も併記する。
Our goal is to propose a better QUBO formulation to suppress redundant predictions. For this purpose, QSQS, the SOTA QUBO-based suppression, is a good baseline. However, the soft-scoring in QSQS obscures the contribution of QUBO formulation quality. Therefore, we directly compare the solutions for each QUBO formulation in our experiments.
See Supplementary B for results with soft-scoring.
For reference, we also report the experimental results with the conventional suppression algorithms, including NMS and Soft-NMS.

\vskip.5\baselineskip\noindent\textbf{Preprocessing before suppression. }
% \paragraph{Preprocessing before suppression}
% \citet{li2020qsqs}の実験では、QUBOの問題サイズが大きくなりすぎないように、IoU閾値を0.5としたNMSによって抑制されなかった検出のみを対象にQUBO-based suppressionを実行している。
% 私たちは、QUBOとしての定式化の良さに焦点を当てるため、NMSの代わりに信頼度スコアに対する閾値を用いて低品質な予測を除外する。
\citet{li2020qsqs} applied NMS-based preprocessing to detections before solving QUBO to prevent solving too large QUBO problems in their experiments.
Instead, we apply confidence-based preprocessing that excludes low-quality predictions whose scores are lower than 0.25 to focus on evaluating the quality of QUBO formulations. The score threshold is determined by considering the balance between quantitative and qualitative results.

\vskip.5\baselineskip\noindent\textbf{Hyperparameter. }
% \paragraph{Hyperparameter}
The hyperparameters of QUBO-based suppression, $w_1, w_2, w_3$ are tuned via a black-box optimization based on Tree-structured Parzen Estimator~\cite{BergstraBBK11TPE,BergstraYC13TPE} implemented on Optuna~\cite{AkibaSYOK19Optuna}. After a group of hyperparameter optimization, we fix these parameters to the same values as the original QSQS implementation, i.e., $w_1=0.4, w_2=0.3, w_3=0.3$.
Considering the quantitative and qualitative performance, the IoU threshold of NMS and $\sigma$ of Gaussian weighting in Soft-NMS are fixed at $0.3$ and $0.5$, respectively.
% 定性的・定量的な予備実験から、NMSのIoU閾値は0.3, SoftNMSのスコアリングパラメーターは$\sigma=0.5$に固定する。

\vskip.5\baselineskip\noindent\textbf{Solver. }
% \paragraph{Solver}
The QUBO problems are solved by the exact solver, Gurobi Optimizer (Gurobi)~\cite{gurobi} version 11.0.3. Gurobi uses two CPU threads and terminates when the execution time reaches 60 seconds. In the experiments, Gurobi finds the optimal solution for each QUBO problem within 60 seconds.