@inproceedings{kim2016exact,
  title={Exact sampling with integer linear programs and random perturbations},
  author={Kim, Carolyn and Sabharwal, Ashish and Ermon, Stefano},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  year={2016}
}

@inproceedings{chen2018learning,
  title={Learning to explain: An information-theoretic perspective on model interpretation},
  author={Chen, Jianbo and Song, Le and Wainwright, Martin and Jordan, Michael},
  booktitle={International conference on machine learning},
  pages={883--892},
  year={2018},
  organization={PMLR}
}

@inproceedings{
grover2019stochastic,
title={Stochastic Optimization of Sorting Networks via Continuous Relaxations},
author={Aditya Grover and Eric Wang and Aaron Zweig and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2019},
}


@inproceedings{ahmed2022simple,
  author 	= {Ahmed, Kareem and Zeng, Zhe and Niepert, Mathias and Van den Broeck, Guy},
  title     = {SIMPLE: A Gradient Estimator for k-subset sampling},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  month     = {may},
  year      = {2023},
}

@inproceedings{altmann2014sampling,
  title={Sampling from a multivariate Gaussian distribution truncated on a simplex: a review},
  author={Altmann, Yoann and McLaughlin, Steve and Dobigeon, Nicolas},
  booktitle={2014 IEEE Workshop on Statistical Signal Processing (SSP)},
  pages={113--116},
  year={2014},
  organization={IEEE}
}

@article{maatouk2022note,
  title={A note on simulating hyperplane-truncated multivariate normal distributions},
  author={Maatouk, Hassan and Bay, Xavier and Rulli{\`e}re, Didier},
  journal={Statistics \& Probability Letters},
  volume={191},
  pages={109650},
  year={2022},
  publisher={Elsevier}
}

@article{cong2017fast,
  title={Fast simulation of hyperplane-truncated multivariate normal distributions},
  author={Cong, Yulai and Chen, Bo and Zhou, Mingyuan},
  year={2017}
}

@article{miller1981inverse,
  title={On the inverse of the sum of matrices},
  author={Miller, Kenneth S},
  journal={Mathematics magazine},
  volume={54},
  number={2},
  pages={67--72},
  year={1981},
  publisher={Taylor \& Francis}
}

@BOOK{Gut2009,
  TITLE = {An Intermediate Course in Probability},
  AUTHOR = {Allan Gut},
  YEAR = {2009},
  PUBLISHER = {Springer},
}

@BOOK{Holt2023,
  TITLE = {Introduction to Bayesian Data Imputation},
  AUTHOR = {William Holt and Duy Nguyen},
  YEAR = {2023},
  PUBLISHER = {SSRN},
}

@article{niepert2021implicit,
  title={Implicit MLE: backpropagating through discrete exponential family distributions},
  author={Niepert, Mathias and Minervini, Pasquale and Franceschi, Luca},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14567--14579},
  year={2021}
}

@article{raza2020message,
  title={Message passing neural networks for partial charge assignment to metal--organic frameworks},
  author={Raza, Ali and Sturluson, Arni and Simon, Cory M and Fern, Xiaoli},
  journal={The Journal of Physical Chemistry C},
  volume={124},
  number={35},
  pages={19070--19082},
  year={2020},
  publisher={ACS Publications}
}

@article{rolfe2016discrete,
  title={Discrete variational autoencoders},
  author={Rolfe, Jason Tyler},
  journal={arXiv preprint arXiv:1609.02200},
  year={2016}
}

@inproceedings{
maddison2016concrete,
title={The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
author={Chris J. Maddison and Andriy Mnih and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2017}
}

@inproceedings{
jang2016categorical,
title={Categorical Reparameterization with Gumbel-Softmax},
author={Eric Jang and Shixiang Gu and Ben Poole},
booktitle={International Conference on Learning Representations},
year={2017}
}

@article{liu2023sonar,
  title={SONAR enables cell type deconvolution with spatially weighted Poisson-Gamma model for spatial transcriptomics},
  author={Liu, Zhiyuan and Wu, Dafei and Zhai, Weiwei and Ma, Liang},
  journal={Nature Communications},
  volume={14},
  number={1},
  pages={4727},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{sang2019reparameterizable,
  author    = {Sang Michael Xie and Stefano Ermon},
  title     = {Reparameterizable Subset Sampling via Continuous Relaxations},
  journal   = {International Joint Conference on Artificial Intelligence (IJCAI)},
  year      = {2019}
}

@article{diaconis1991closed,
  title={Closed form summation for classical distributions: variations on a theme of de Moivre},
  author={Diaconis, Persi and Zabell, Sandy},
  journal={Statistical Science},
  pages={284--302},
  year={1991},
  publisher={JSTOR}
}

@article{kingma2022autoencoding,
  title={Auto-Encoding Variational Bayes},
  author={Diederik P. Kingma and Max Welling},
  journal={CoRR},
  year={2013},
  volume={abs/1312.6114}
}

@inproceedings{sønderby2016ladder,
 author = {S\o nderby, Casper Kaae and Raiko, Tapani and Maal\o e, Lars and S\o nderby, S\o ren Kaae and Winther, Ole},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Ladder Variational Autoencoders},
 volume = {29},
 year = {2016}
}


@inproceedings{he2018variational,
  title={Variational autoencoders with jointly optimized latent dependency structure},
  author={He, Jiawei and Gong, Yu and Marino, Joseph and Mori, Greg and Lehrmann, Andreas},
  booktitle={International conference on learning representations},
  year={2018}
}

@article{diligenti2012bridging,
  title={Bridging logic and kernel machines},
  author={Diligenti, Michelangelo and Gori, Marco and Maggini, Marco and Rigutini, Leonardo},
  journal={Machine learning},
  volume={86},
  pages={57--88},
  year={2012},
  publisher={Springer}
}

@inproceedings{xu2018semantic,
  title={A semantic loss function for deep learning with symbolic knowledge},
  author={Xu, Jingyi and Zhang, Zilu and Friedman, Tal and Liang, Yitao and Broeck, Guy},
  booktitle={International conference on machine learning},
  pages={5502--5511},
  year={2018},
  organization={PMLR}
}

@inproceedings{fischer2019dl2,
  title={DL2: training and querying neural networks with logic},
  author={Fischer, Marc and Balunovic, Mislav and Drachsler-Cohen, Dana and Gehr, Timon and Zhang, Ce and Vechev, Martin},
  booktitle={International Conference on Machine Learning},
  pages={1931--1941},
  year={2019},
  organization={PMLR}
}

@article{badreddine2022logic,
  title={Logic tensor networks},
  author={Badreddine, Samy and Garcez, Artur d'Avila and Serafini, Luciano and Spranger, Michael},
  journal={Artificial Intelligence},
  volume={303},
  pages={103649},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{stoian2024exploiting,
  title = "Exploiting T-norms for Deep Learning in Autonomous Driving",
  author = "Mihaela Catalina Stoian and Eleonora Giunchiglia and Thomas Lukasiewicz",
  year = "2023",
  booktitle = "Proceedings of the 17th International Workshop on Neural-Symbolic Learning and Reasoning, NeSy 2023, La Certosa di Pontignano, Siena, Italy, 3--5 July 2023",
  editor = "Artur S. d'Avila Garcez and Tarek R. Besold and Marco Gori and Ernesto Jiménez-Ruiz",
  month = "July",
  pages = "369--380",
}

@article{ahmed2022semantic,
  title={Semantic probabilistic layers for neuro-symbolic learning},
  author={Ahmed, Kareem and Teso, Stefano and Chang, Kai-Wei and Van den Broeck, Guy and Vergari, Antonio},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={29944--29959},
  year={2022}
}

@article{giunchiglia2021multi,
  title={Multi-label classification neural networks with hard logical constraints},
  author={Giunchiglia, Eleonora and Lukasiewicz, Thomas},
  journal={Journal of Artificial Intelligence Research},
  volume={72},
  pages={759--818},
  year={2021}
}

@inproceedings{stoian2024realistic,
  title={How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data},
  author={Stoian, Mihaela C and Dyrmishi, Salijona and Cordy, Maxime and Lukasiewicz, Thomas and Giunchiglia, Eleonora},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{di2020efficient,
  title={Efficient generation of structured objects with constrained adversarial networks},
  author={Di Liello, Luca and Ardino, Pierfrancesco and Gobbi, Jacopo and Morettin, Paolo and Teso, Stefano and Passerini, Andrea},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={14663--14674},
  year={2020}
}

@article{misino2022vael,
  title={Vael: Bridging variational autoencoders and probabilistic logic programming},
  author={Misino, Eleonora and Marra, Giuseppe and Sansone, Emanuele},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4667--4679},
  year={2022}
}

@inproceedings{de2007problog,
  title={ProbLog: A probabilistic Prolog and its application in link discovery},
  author={De Raedt, Luc and Kimmig, Angelika and Toivonen, Hannu},
  booktitle={IJCAI 2007, Proceedings of the 20th international joint conference on artificial intelligence},
  pages={2462--2467},
  year={2007},
  organization={IJCAI-INT JOINT CONF ARTIF INTELL}
}


@inproceedings{frerix2020homogeneous,
  title={Homogeneous linear inequality constraints for neural network activations},
  author={Frerix, Thomas and Nie{\ss}ner, Matthias and Cremers, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={748--749},
  year={2020}
}

@article{agrawal2019differentiable,
  title={Differentiable convex optimization layers},
  author={Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen and Diamond, Steven and Kolter, J Zico},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{burda2016importance,
  title = {Importance Weighted Autoencoders},
  author = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
  year = {2016},
  booktitle = {International Conference on Learning Representations (ICLR)}
}

@inproceedings{zhang2023paradox,
  title={On the paradox of learning to reason from data},
  author={Zhang, Honghua and Li, Liunian Harold and Meng, Tao and Chang, Kai-Wei and Van den Broeck, Guy},
  booktitle={Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
  pages={3365--3373},
  year={2023}
}

@article{chen2024hard,
title = {Physics-informed neural networks with hard linear equality constraints},
journal = {Computers Chemical Engineering},
volume = {189},
pages = {108764},
year = {2024},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2024.108764},
author = {Hao Chen and Gonzalo E. Constante Flores and Can Li},
keywords = {Surrogate modeling, Physics-informed neural network, Artificial intelligence},
abstract = {Surrogate modeling is used to replace computationally expensive simulations. Neural networks have been widely applied as surrogate models that enable efficient evaluations over complex physical systems. Despite this, neural networks are data-driven models and devoid of any physics. The incorporation of physics into neural networks can improve generalization and data efficiency. The physics-informed neural network (PINN) is an approach to leverage known physical constraints present in the data, but it cannot strictly satisfy them in the predictions. This work proposes a novel physics-informed neural network, KKT-hPINN, which rigorously guarantees hard linear equality constraints through projection layers derived from KKT conditions. Numerical experiments on Aspen models of a continuous stirred-tank reactor (CSTR) unit, an extractive distillation subsystem, and a chemical plant demonstrate that this model can further enhance the prediction accuracy.}
}

@article{cao2020spectral,
  title={Spectral Temporal Graph Neural Network for Multivariate Time-Series Forecasting},
  author={Cao, Daoyuan and Wang, Yue and Duan, Jinjing and Zhang, Chang and Zhu, Xi and Huang, Chenguang and Tong, Yu and Xu, Bing and Bai, Jianfei and Tong, Jian and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17766--17778},
  year={2020}
}

@article{zhang2020deep,
  title={Deep Learning for Portfolio Optimization},
  author={Zhang, Ziyao and Zohren, Stefan and Roberts, Stephen},
  journal={The Journal of Financial Data Science},
  volume={2},
  number={4},
  pages={8--20},
  year={2020}
}

@article{butler2021integrating,
  title={Integrating Prediction in Mean-Variance Portfolio Optimization},
  author={Butler, Alex and Kwon, Ryan},
  journal={Available at SSRN 3788875},
  year={2021}
}

@article{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
  year={2020},
  journal={arXiv preprint arxiv:2006.11239}
}

@inproceedings{
song2021denoising,
title={Denoising Diffusion Implicit Models},
author={Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{yuan2023physdiff,
  title={PhysDiff: Physics-Guided Human Motion Diffusion Model},
  author={Yuan, Ye and Song, Jiaming and Iqbal, Umar and Vahdat, Arash and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023}
}

@inproceedings{
liu2024image,
title={Image Inpainting via Tractable Steering of Diffusion Models},
author={Anji Liu and Mathias Niepert and Guy Van den Broeck},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex},
  year={2009},
  institution={University of Toronto},
  type={Technical Report},
  number={TR-2009}
}

@inproceedings{liu2015deep,
  title={Deep Learning Face Attributes in the Wild},
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={3730--3738},
  year={2015}
}

@inproceedings{yu2015lsun,
  title={LSUN: Construction of a Large-scale Image Dataset Using Deep Learning with Humans in the Loop},
  author={Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  pages={1--10},
  year={2015}
}

@article{sharpe1966mutual,
  title={Mutual fund performance},
  author={Sharpe, William F.},
  journal={Journal of Business},
  volume={39},
  number={1},
  pages={119--138},
  year={1966},
  publisher={University of Chicago Press}
}

@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{NeuralODE,
 author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Neural Ordinary Differential Equations},
 volume = {31},
 year = {2018}
}

@article{poli2019graph,
  title={Graph Neural Ordinary Differential Equations},
  author={Poli, Michael and Massaroli, Stefano and Park, Junyoung and Yamashita, Atsushi and Asama, Hajime and Park, Jinkyoo},
  journal={arXiv preprint arXiv:1911.07532},
  year={2019}
}

@article{qi2016pointnet,
  title={PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1612.00593},
  year={2016}
}

@inproceedings{
kipf2017semisupervised,
title={Semi-Supervised Classification with Graph Convolutional Networks},
author={Thomas N. Kipf and Max Welling},
booktitle={International Conference on Learning Representations},
year={2017}
}

@inproceedings{WangICML23,
  title={{LinSATNet}: The Positive Linear Satisfiability Neural Networks},
  author={Wang, Runzhong and Zhang, Yunhao and Guo, Ziao and Chen, Tianyi and Yang, Xiaokang and Yan, Junchi},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2023}
}

@inproceedings{Geweke1991EfficientSF,
  title={Efficient Simulation from the Multivariate Normal and Student-t Distributions Subject to Linear Constraints and the Evaluation of Constraint Probabilities},
  author={John Geweke},
  year={1991}
}

@misc{pakman2013exacthamiltonianmontecarlo,
      title={Exact Hamiltonian Monte Carlo for Truncated Multivariate Gaussians}, 
      author={Ari Pakman and Liam Paninski},
      year={2013},
      eprint={1208.4118},
      archivePrefix={arXiv},
      primaryClass={stat.CO}
}

@article{Hendriks2020LinearlyCN,
  title={Linearly Constrained Neural Networks},
  author={Johannes N. Hendriks and Carl Jidling and Adrian G. Wills and Thomas Bo Sch{\"o}n},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.01600}
}

@InProceedings{amos2017optnet,
  title = {{O}pt{N}et: Differentiable Optimization as a Layer in Neural Networks},
  author = {Brandon Amos and J. Zico Kolter},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  pages = {136--145},
  year = {2017},
  volume = {70},
  series = {Proceedings of Machine Learning Research},
  publisher ={PMLR},
}

@inproceedings{Wang2019SATNetBD,
  title={SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver},
  author={Po-Wei Wang and Priya L. Donti and Bryan Wilder and Zico Kolter},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@inproceedings{donti2017task,
  title={Task-based end-to-end model learning in stochastic optimization},
  author={Donti, Priya and Amos, Brandon and Kolter, J Zico},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5484--5494},
  year={2017}
}

@inproceedings{Djolonga2017,
 author = {Djolonga, Josip and Krause, Andreas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Differentiable Learning of Submodular Models},
 volume = {30},
 year = {2017}
}

@inproceedings{Tschiatschek2018DifferentiableSM,
  title={Differentiable Submodular Maximization},
  author={Sebastian Tschiatschek and Aytunc Sahin and Andreas Krause},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{wilder2019melding,
 author = {Wilder, Bryan},
 title = {Melding the Data-Decisions Pipeline: Decision-Focused Learning for Combinatorial Optimization},
 booktitle = {Proceedings of the 33rd AAAI Conference on Artificial Intelligence},
 year = {2019}
}

@inproceedings{song2019generative,
  title={Generative Modeling by Estimating Gradients of the Data Distribution},
  author={Song, Yang and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11895--11907},
  year={2019}
}

@article{lu2022dpm,
  title={DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={arXiv preprint arXiv:2206.00927},
  year={2022}
}


@Article{risks6030064,
AUTHOR = {Vrins, Frédéric},
TITLE = {Sampling the Multivariate Standard Normal Distribution under a Weighted Sum Constraint},
JOURNAL = {Risks},
VOLUME = {6},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {64},
ISSN = {2227-9091},
ABSTRACT = {Statistical modeling techniques—and factor models in particular—are extensively used in practice, especially in the insurance and finance industry, where many risks have to be accounted for. In risk management applications, it might be important to analyze the situation when fixing the value of a weighted sum of factors, for example to a given quantile. In this work, we derive the (n−1)-dimensional distribution corresponding to a n-dimensional i.i.d. standard Normal vector Z=(Z1,Z2,…,Zn)′ subject to the weighted sum constraint w′Z=c, where w=(w1,w2,…,wn)′ and wi≠0. This law is proven to be a Normal distribution, whose mean vector μ and covariance matrix Σ are explicitly derived as a function of (w,c). The derivation of the density relies on the analytical inversion of a very specific positive definite matrix. We show that it does not correspond to naive sampling techniques one could think of. This result is then used to design algorithms for sampling Z under constraint that w′Z=c or w′Z≤c and is illustrated on two applications dealing with Value-at-Risk and Expected Shortfall.},
DOI = {10.3390/risks6030064}
}

@article{LAMBONI2022199,
title = {Efficient dependency models: Simulating dependent random variables},
journal = {Mathematics and Computers in Simulation},
volume = {200},
pages = {199-217},
year = {2022},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2022.04.018},
author = {Matieyendou Lamboni},
keywords = {Dependent generalized sensitivity indices, Dependent variables, Efficient sampling, Multivariate distributions, Random values},
abstract = {Dependency functions of dependent variables are relevant for (i) performing uncertainty quantification and sensitivity analysis in presence of dependent variables and/or correlated variables, and (ii) simulating random dependent variables. In this paper, we mathematically derive practical dependency functions for classical multivariate distributions such as Dirichlet, elliptical distributions and independent uniform (resp. gamma and Gaussian) variables under constraints that are ready to be used. Since such dependency models are used for sampling random values and we have many dependency models for every joint cumulative distribution function, we provide a way for choosing the efficient sampling function using multivariate sensitivity analysis. We illustrate our approach by means of numerical simulations.}
}

@inproceedings{de2018learning,
  title={Learning constraints from examples},
  author={De Raedt, Luc and Passerini, Andrea and Teso, Stefano},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{garcez2023neurosymbolic,
  title={Neurosymbolic AI: The 3 rd wave},
  author={Garcez, Artur d’Avila and Lamb, Luis C},
  journal={Artificial Intelligence Review},
  volume={56},
  number={11},
  pages={12387--12406},
  year={2023},
  publisher={Springer}
}

@article{shukla2024unified,
  title={A Unified Approach to Count-Based Weakly Supervised Learning},
  author={Shukla, Vinay and Zeng, Zhe and Ahmed, Kareem and Van den Broeck, Guy},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{heusel2017gans,
  title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@inproceedings{salimans2016improved,
  title={Improved Techniques for Training GANs},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2016}
}
