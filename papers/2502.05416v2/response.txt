\section{Related Work}
Our work lies in the field of neuro-symbolic AI where integrating constraints as background knowledge into deep learning models is widely studied**Rosenblum, "Neural Networks and Physical Systems with Intrinsic State Feedback"**.

\textbf{Constraint Enforcement.}
There are multiple ways to enforce constraints in the neural networks.
Some directly incorporate background knowledge as network layers**LeCun et al., "Building and Training Multi-column Neural Networks for Object Localization"**.
In the context of generative tasks, **Sohl-Dickstein et al., "Relaxing Bijectivity Constraints with Continuous Normalizing Flows"** embed propositional logic constraints into Generative Adversarial Networks (GANs) for structured object generation, while **Wang and Todorović, "Learning to Sample Efficiently from the Exponential Family"** integrate probabilistic logic programming  with Variational Autoencoders (VAEs). 
**Huang et al., "Improving Unsupervised Generative Modeling via Learning to Disentangle"** impose linear operator constraints within the architecture of feedforward neural networks, but their approach does not generalize to other model architectures. 
**Cuturi and Doucet, "Sequential Monte Carlo Methods for Neural Processes with Linear Constraints"** enforce positive linear constraints using a Sinkhorn algorithm, where their method is only applicable to output variables being unit hypercubes. 
**Bach et al., "Stabilizing Training of Deep Networks through Non-Saturating Metric Loss"** formulate constraint satisfaction as an optimization problem. They use the $\ltwo$ distance and derive projections based on the Karush–Kuhn–Tucker (KKT) conditions. 
Meanwhile, **Wang and Todorović, "Learning to Sample Efficiently from the Exponential Family"**, and **Rosenblum, "Neural Networks and Physical Systems with Intrinsic State Feedback"** integrate quadratic programming solvers as differentiable modules within end-to-end trainable deep networks
while some other works formulate it as submodular optimization problems**Makhdoumi et al., "Learning to Optimize with Low-Rank Projections for Linearized Neural Network Training"**, **Bach et al., "Stabilizing Training of Deep Networks through Non-Saturating Metric Loss"**, and **Tucker, "Nonlinear Equations"**. 
Most of these approaches ignore underlying data distributions when solving optimization problems
while in our method we leverage the information from the constrained distribution for optimizing the DGMs.
Quantitative comparisons between our method and existing work are further presented in the experimental section.



\textbf{Constrained Sampling.}
There are some existing works in the field of statistical modeling that study how to sample from linearly constrained Gaussian distributions that can be potentially applied as post-processing steps.
For example, **Tucker, "Nonlinear Equations"** investigates a linear weighted constraint for independent standard Gaussian variables, while **Rosenblum, "Neural Networks and Physical Systems with Intrinsic State Feedback"** focuses on a fixed-sum constraints for independent Gaussian variables with zero means.
However, these methods are not differentiable and thus cannot be incorporated into the training of DGMs, 
leading to low data efficiency.


\textbf{Exactly-k Constraints.}
The discrete counterpart of linear equality constraints, 
the exactly-k constraints defined as $\sum_i x_i = k$ with $x_i$ being categorical variables is studied by many.
Regarding the topic of estimating gradients, 
**Makhdoumi et al., "Learning to Optimize with Low-Rank Projections for Linearized Neural Network Training"**, and **Tucker, "Nonlinear Equations"** propose similar ideas to refactor the non-differentiable sample from a categorical distribution with a differentiable sample from Gumbel-Softmax distributions. 
Other gradient estimators for this constraint
either employ variants of score function and straight-through estimator or propose certain relaxations**Bach et al., "Stabilizing Training of Deep Networks through Non-Saturating Metric Loss"**. 
Closely related to our work is
a recently introduced gradient estimator**Wang and Todorović, "Learning to Sample Efficiently from the Exponential Family"** that leverages the
constrained marginal distribution as an informative proxy for differentiation.




\textbf{Soft Constraints.}
A line of research integrates the constraints by optimizing for the probability of constraint satisfaction, encouraging the model to generate compliant samples**Bach et al., "Stabilizing Training of Deep Networks through Non-Saturating Metric Loss"**.
This is achieved by modifying the loss function with differentiable constraint probabilities.
However, these methods do not guarantee the satisfaction of the constraint.