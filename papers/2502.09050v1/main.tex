%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
\let\Bbbk\relax
\makeatother
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{tikz}
\usepackage{pgfplots} 
\pgfplotsset{compat=1.16} 
\usepackage{balance}
\usepackage{bigstrut,array,multirow,tabularx}
\usepackage{caption}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% \usepackage{subcaption}
\usepackage{dsfont}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
% \usepackage[dvipsnames]{xcolor}
%Table
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{makecell} 
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{subcaption}
% \usepackage[table]{xcolor} % Import xcolor package with table option
\definecolor{lightblue}{RGB}{0.93,0.95,1.0} % Define light blue color
\definecolor{lightred}{RGB}{1.0,0.93,0.93} % Define light red color
\setlength{\textfloatsep}{5pt}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{array}
\usepackage{filecontents}
\usepackage{pifont}
% \usepackage{adjustbox}
\usepackage[export]{adjustbox}
% \usepackage[svgnames]{xcolor}  



%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\newcommand{\jd}[1]{\textcolor{blue}{#1}}%
\newcommand{\ch}[1]{\textcolor{brown}{#1}}% 
\newcommand{\yn}[1]{\textcolor{teal}{#1}}% 
\newcommand{\gf}[1]{\textcolor{RoyalBlue}{#1}}


% \setcopyright{acmlicensed}
% \copyrightyear{2025}
% \acmYear{2025}
% \acmDOI{10.1145/3701716.3715482}
% %% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[WWW Companion '25]{Companion Proceedings of the ACM Web Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
% \acmISBN{979-8-4007-1331-6/25/04}

% % \copyrightyear{2025}
% % \acmYear{2025}
% % \setcopyright{cc}
% % \setcctype{by}
% % \acmConference[WWW Companion '25]{Companion Proceedings of the ACM Web Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
% % \acmBooktitle{Companion Proceedings of the ACM Web Conference 2025 (WWW Companion '25), April 28-May 2, 2025, Sydney, NSW, Australia}
% % \acmDOI{10.1145/3701716.3715482}
% % \acmISBN{979-8-4007-1331-6/25/04}


\copyrightyear{2025}
\acmYear{2025}
\setcopyright{cc}
\setcctype{by}
\acmConference[WWW Companion '25]{Companion Proceedings of the ACM Web Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
\acmBooktitle{Companion Proceedings of the ACM Web Conference 2025 (WWW Companion '25), April 28-May 2, 2025, Sydney, NSW, Australia}
\acmDOI{10.1145/3701716.3715482}
\acmISBN{979-8-4007-1331-6/25/04}


% The following includes the CC license icon appropriate for your paper.
% Download the image from www.scomminc.com/pp/acmsig/4ACM-CC-by-88x31.eps
% and place within your figs or figures folder

\makeatletter
\gdef\@copyrightpermission{
 \begin{minipage}{0.2\columnwidth}
  \href{https://creativecommons.org/licenses/by/4.0/}
  {\includegraphics[width=0.90\textwidth]{figures/4ACM-CC-by-88x31.pdf}}
 \end{minipage}\hfill
 \begin{minipage}{0.8\columnwidth}
  \href{https://creativecommons.org/licenses/by/4.0/}{This work is licensed under a Creative Commons Attribution International 4.0 License.}
 \end{minipage}
 \vspace{5pt}
}
\makeatother


% {\includegraphics[width=0.90\textwidth]{figures/4ACM-CC-by-88x31.eps}}


\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
% \title{Leveraging Member--Group Relations via Multi-View Graph Filtering for Effective Group Recommendation}
\title[Leveraging Member–Group Relations via Multi-View Graph Filtering 
       \protect\linebreak for Effective Group Recommendation]{
       Leveraging Member–Group Relations via Multi-View Graph Filtering for Effective Group Recommendation}



%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Chae-Hyun Kim}
\authornote{Equal contribution (co-first authors)}
\affiliation{%
  \institution{Yonsei University}
  \city{Seoul}
  \country{Republic of Korea}
}
\email{kimchaehyun0315@yonsei.ac.kr}
% \orcid{1234-5678-9012}

\author{Yoon-Ryung Choi}
\authornotemark[1]
\affiliation{%
  \institution{Sookmyung Women's University}
  \city{Seoul}
  \country{Republic of Korea}
}
\email{wendych@sookmyung.ac.kr}

\author{Jin-Duk Park}
\authornote{Co-corresponding authors}
\affiliation{%
  \institution{Yonsei University}
  \city{Seoul}
  \country{Republic of Korea}
}
\email{jindeok6@yonsei.ac.kr}

\author{Won-Yong Shin}
\authornotemark[2]
\affiliation{%
  \institution{Yonsei University}
  \city{Seoul}
  \country{Republic of Korea}
}
\email{wy.shin@yonsei.ac.kr}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Chae-Hyun Kim, Yoon-Ryung Choi, Jin-Duk Park, and Won-Yong Shin}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
 Group recommendation aims at providing optimized recommendations tailored to diverse groups, enabling groups to enjoy appropriate items. On the other hand, most existing group recommendation methods are built upon deep neural network (DNN) architectures designed to capture the intricate relationships between member-level and group-level interactions. While these DNN-based approaches have proven their effectiveness, they require complex and expensive training procedures to incorporate group-level interactions in addition to member-level interactions. To overcome such limitations, we introduce \textsf{Group-GF}, a new approach for extremely fast recommendations of items to each group via \textit{multi-view graph filtering (GF)} that offers a holistic view of complex member--group dynamics, without the need for costly model training. Specifically, in \textsf{Group-GF}, we first construct three item similarity graphs manifesting different viewpoints for GF. Then, we discover a {\it distinct} polynomial graph filter for each similarity graph and judiciously aggregate the three graph filters. Extensive experiments demonstrate the effectiveness of \textsf{Group-GF} in terms of significantly reducing runtime and achieving state-of-the-art recommendation accuracy. 
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10002951.10003317.10003347.10003350</concept_id>
%   <concept_desc>Information systems~Recommender systems</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003260.10003261.10003269</concept_id>
<concept_desc>Information systems~Collaborative filtering</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Collaborative filtering}
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Graph filtering; group-level interaction; group recommendation; recommender system; similarity graph.}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.


% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\label{section 1} 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\columnwidth]{figures/intro.pdf}
    \caption{Examples of both group and member consumption patterns on TV and trip platforms.}
    \label{fig_intro}
\end{figure}

Group recommender systems aim to provide precise recommendations tailored to a collection of members rather than individuals \cite{guo2021hierarchical, cao2018attentive, jia2021hypergraph, wu2023consrec, sankar2020groupim}. In group recommendations, capturing the intricate relationships between member-level and group-level interactions is essential for accurate group recommendations \cite{cao2018attentive, wu2023consrec}. For example, the preferences of a travel group on a trip platform may differ from individual members' preferences, as shown in Figure \ref{fig_intro}. In this context, it is of paramount importance to effectively integrate such dissimilar preferences for accurate group recommendations \cite{hu2014deep, baltrunas2010group}. In other words, treating both member-level and group-level interactions separately can result in a failure to account for the nuanced dynamics that occur within group contexts \cite{yadati2019hypergcn, yang2023group, jia2021hypergraph}. 

To jointly deal with both member-level and group-level interactions, existing approaches often resort to hypergraph-based \cite{yadati2019hypergcn, yang2023group, wu2023consrec, jia2021hypergraph} and self-supervised learning (SSL)-based \cite{zhang2021double,wu2023consrec, sankar2020groupim} methods. However, the aforementioned methods often involve complex hypergraph modeling or expensive model training costs for SSL, which can hinder their responsiveness to rapidly changing member preferences.  

To address these practical challenges, we propose \textsf{Group-GF}, the first attempt at group recommendations built upon {\it graph filtering} {\it (GF)}. Our \textsf{Group-GF} method is composed of 1) the construction of three item similarity graphs exhibiting different viewpoints and 2) the optimal design of {\it distinct} polynomial graph filters that are hardware-friendly without costly matrix decomposition. More precisely, \textsf{Group-GF} starts by constructing two {\it augmented item similarity graphs} concatenating the member--group matrix and a {\it unified item similarity graph} concatenating the  member--item and group--item interaction matrices, thereby seamlessly integrating member and group information for accurate group recommendations. Next, based on the three constructed graphs, we {\it distinctly} and {\it optimally} perform polynomial GF for each similarity graph and then aggregate the three graph filters.

Through extensive evaluations on benchmark datasets, \textsf{Group-GF} achieves not only state-of-the-art accuracy but also extraordinary \textbf{efficient runtime up to 1.55 seconds}. This remarkable performance can be attributed to its training-free multi-view GF, which accommodates complex member--group dynamics while relying solely on simple matrix operations. In addition, we theoretically connect \textsf{Group-GF}’s filtering process to optimization with smoothness regularization, offering clearer interpretability of the model’s behavior.



\section{Preliminary}
\label{section 2}
\subsection{Graph Filtering}
We provide fundamental principles of GF. Suppose a weighted graph $G = (V, E)$ represented by an adjacency matrix $A \in\mathbb{R}^{|V|\times |V|}$. A $d$-dimensional vector $\mathbf{x} \in \mathbb{R}^{|V|}$ is a graph signal, where $x_i$ represents the signal strength of node $i$ in ${\bf x}$. 
The graph Laplacian $L$ of $G$ is $L = D - A$, where $D=\text{diag}(A\mathbf{1})$. 
The smoothness measure $S({\bf x})$ is expressed as \cite{shen2021powerful, shuman2013emerging}: 
    \begin{equation}
        \label{eq:Sm_1}
        S({\bf x}) = \sum_{i,j}A_{i,j}(x_i-x_j)^2 =  \mathbf{x}^T L \mathbf{x}.
    \end{equation} 
Smaller values of $S(x)$ indicate that the signal $\mathbf{x}$ is smoother on the graph. By the eigen-decomposition $L = U\Lambda U^T$, we can formally define the graph Fourier transform (GFT) of a graph signal $\mathbf{x}$ as $\hat{\mathbf{x}} = U^T \mathbf{x}$, where $U\in\mathbb{R}^{|V|\times |V|}$ is the matrix whose $i$-th column is the eigenvector $u_i$ of $L$. Here, the signal $\mathbf{x}$ is considered smooth if the dot product of the eigenvectors corresponding to smaller eigenvalues of $L$ is high. Given a graph Laplacian matrix $L$, a graph filter $H(L)\in\mathbb{R}^{|V|\times |V|}$ is given by
\begin{equation}
H(L) = U \text{diag}(h(\lambda_1), \cdots, h(\lambda_{|V|})) U^T,
\end{equation}
where $h:\mathbb{C} \rightarrow \mathbb{R}$ is the frequency response function that maps eigenvalues $\{\lambda_1,\cdots,\lambda_{|V|}\}$ of $L$ to $\{h(\lambda_1),\cdots,h(\lambda_{|V|})\}$. The convolution of a  graph signal $\mathbf{x}$ with a graph filter $H(L)$ is then represented as $H(L)\mathbf{x}=U\text{diag}(h(\lambda_1), \cdots, h(\lambda_{|V|})) U^T\mathbf{x}$.


\subsection{Problem Definition}
Consider the sets of members, items, and groups, denoted by $\mathcal{U} = \{u_1, u_2, \cdots, u_{|\mathcal{U}|}\}$, $\mathcal{I} = \{i_1, i_2, \cdots, i_{|\mathcal{I}|}\}$, and $\mathcal{G} = \{g_1, g_2, \ldots, g_{|\mathcal{G}|}\}$, respectively. Each member and group interacts with various items, reflecting their own preferences. Among $\mathcal{U}$, $\mathcal{I}$, and $\mathcal{G}$, there are two types of interactions: 1) interactions between members and items and 2) interactions between groups and items.
We denote the member--item interaction matrix by $R_u \in \mathbb{R}^{|\mathcal{U}|\times|\mathcal{I}|}$ and the group--item interaction matrix by $R_g \in \mathbb{R}^{|\mathcal{G}|\times|\mathcal{I}|}$, where $r_{ui}= 1$ ({\it resp.} $r_{gi}= 1) $ if member $u$ ({\it resp.} group $g$) is associated with item $i$, and $r_{ui}= 0$ ({\it resp.} $r_{gi}= 0) $ otherwise. The $t$-th group $\mathcal{G}_t=\{u_1,u_2,\cdots,u_s,\cdots,u_{|\mathcal{G}_t|} \} \in \mathcal{G}$ consists of a set of members in the belonging group. For a given target group $\mathcal{G}_t$, the objective of the group recommendation task is to recommend items to {\it each group} $\mathcal{G}_t$ \cite{wu2023consrec, jia2021hypergraph}.

\begin{figure}[t] 
    \centering 
    \includegraphics[width=0.48\textwidth]{figures/figure.pdf} 
    \caption{The schematic overview of \textsf{Group-GF}.} 
    \label{overview}
\end{figure}


\section{Methodology}
In this section, we elaborate on \textsf{Group-GF}, a method that judiciously performs multi-view GF to model complex interactions between members and groups. The schematic overview of \textsf{Group-GF} is shown in Figure \ref{overview}.
\label{sec 3.2}
\subsection{Augmented Graph Construction}\label{sec 3.2.1}
% Standard GF-based recommendation methods for individual tasks construct a graph as follows:
Standard GF-based recommendation methods \cite{liu2023personalized, park2024turbo, shen2021powerful, choi2023blurring, xia2022fire, he2020lightgcn} for the individual recommendation task begin with constructing a graph structure, where each item is represented as a node and the similarities between items are modeled as edges. The construction process is formulated as follows:
\begin{equation}
    \label{canonical_rec_eq}
    \tilde{P} = \tilde{R}^T\tilde{R}; \tilde{R} = D^{-1/2}_{\mathcal{U}}RD^{-1/2}_\mathcal{I}, 
\end{equation}
where the operator | | denotes the concatenation of matrices, and $R \in \mathbb{R}^{|\mathcal{U}| \times |\mathcal{I}|}$ is the member--item interaction matrix; $\tilde{R}$ is the normalized interaction matrix; $D_\mathcal{U}=\text{diag}(R\mathbf{1})$ and $D_\mathcal{I} = \text{diag}(\mathbf{1}^TR)$; and $\tilde{P}$ is the adjacency matrix of the item--item similarity graph. However, constructing separate graphs for member--item and group--item interactions overlooks the member--group relations. Thus, we present a nontrivial strategy that constructs \textit{augmented item similarity graphs} using a member--group relation matrix $M \in \mathbb{R}^{|\mathcal{G}|\times|\mathcal{U}|}$, where $M_{ij} = 1$ indicates that member $j$ belongs to group $i$, and $M_{ij} = 0$ otherwise. We first augment $R_u$ and $R_g$ by concatenating the member--group relation matrix $M$:
\begin{equation}
\label{aug_inters}
    \hat{R}_u = R_u || M^\top;\hat{R}_g = R_g || M,
\end{equation}
where the operator $||$ denotes the concatenation of matrices, and $\hat{R}_u \in \mathbb{R}^{|\mathcal{U}|\times(|\mathcal{I}|+|\mathcal{G}|)}$ and $\hat{R}_g \in \mathbb{R}^{|\mathcal{G}|\times(|\mathcal{I}|+|\mathcal{U}|)}$ are the augmented member-level and group-level interaction matrices, respectively. It is worth noting that this augmentation allows us to jointly leverage the information of member--group relations as well as member-level interactions and group-level interactions for GF. Next, we construct two augmented similarity graphs as follows:
\begin{equation}
% \label{conventional_graph}
\begin{aligned}
    \tilde{P}_u = \tilde{R}_u^\top \tilde{R}_u; \quad \tilde{R}_u = D_\mathcal{U}^{-0.5} \hat{R}_u D_{\mathcal{I}_u}^{-0.5}, \\
    \tilde{P}_g = \tilde{R}_g^\top \tilde{R}_g; \quad \tilde{R}_g = D_\mathcal{G}^{-0.5} \hat{R}_g D_{\mathcal{I}_g}^{-0.5},
    \label{P_tilde}
\end{aligned}   
\end{equation}
where $\tilde{P}_u \in \mathbb{R}^{(|\mathcal{I}|+ |\mathcal{G}|)\times(|\mathcal{I}| + |\mathcal{G}|)}$ and $\tilde{P}_g \in \mathbb{R}^{(|\mathcal{I}| + |\mathcal{U}|)\times(|\mathcal{I}| + |\mathcal{U}|)}$ represent the member-level and group-level item similarity graphs, respectively; $\tilde{R}_u$ and $\tilde{R}_g$ are the normalized augmented interaction matrices; and $D_\mathcal{U} = \text{diag}(\hat{R}_u \mathbf{1})$, $D_{\mathcal{I}_u} = \text{diag}(\mathbf{1}^\top \hat{R}_u)$, $D_\mathcal{G} = \text{diag}(\hat{R}_g \mathbf{1})$, and $D_{\mathcal{I}_g} = \text{diag}(\mathbf{1}^\top \hat{R}_g)$ are used for normalization. To construct item similarity graphs, we use $\tilde{P}_u^{\dagger} = \tilde{P}_{u[:|\mathcal{I}|,\ :|\mathcal{I}|]}$ and $\tilde{P}_g^{\dagger} =\tilde{P}_{g[:|\mathcal{I}|,\ :|\mathcal{I}|]}$ by extracting the first $|\mathcal{I}|$ rows and columns from $\tilde{P}_u$ and $\tilde{P}_g$. Additionally, we adjust the difference of similarities in the constructed item similarity graphs to prevent over/under-smoothing via using the Hadamard power \cite{park2024turbo,park2025criteria}. Finally, we characterize two adjusted similarity graphs $\bar{P}_{u}$ and $\bar{P}_{g} $ as 
\begin{equation}
\label{adj_graph_ug}
    \bar{P}_{u}=\tilde{P}_u^{\mathop{\dagger}^{\circ s}};
    \bar{P}_{g}=\tilde{P}_g^{\mathop{\dagger}^{\circ s}},
\end{equation} 
where $s$ is the adjustment parameter.\footnote{Although using two separate adjustment parameters for $\bar{P}_{u}$ and $\bar{P}_{g}$ certainly yields better results, we use a single hyperparameter $s$ for both graphs for simplicity.}
% Graph adjustment 
% Graph combination with cutting dims -> 


\subsection{Unified Graph Construction}\label{sec 3.2.2} 
We further construct a \textit{unified item similarity graph} $\bar{P}_{\text{uni}}$ to comprehensively grasp the relationships among items. This unified graph enables us to perceive the extensive preference of items by simultaneously taking into account both member--item and group--item interaction matrices. We begin with concatenating $R_g$ and $R_u$ along the item dimension:
\begin{equation}
    R_{\text{uni}} = \begin{bmatrix} R_g \\ R_u \end{bmatrix} \in \mathbb{R}^{(|\mathcal{G}| + |\mathcal{U}|) \times |\mathcal{I}|},
\end{equation}
which effectively combines all possible interactions at the item level. Next, we normalize $R_{\text{uni}}$ to obtain $\tilde{R}_{\text{uni}}$, then compute the graph as: 
\begin{equation}
\tilde{P}_{\text{uni}} = \tilde{R}_{\text{uni}}^\top \tilde{R}_{\text{uni}}; \quad \tilde{R}_{\text{uni}} = D_{\text{uni}}^{-0.5} R_{\text{uni}} D_{\mathcal{I}_{\text{uni}}}^{-0.5},
\label{p_tilde_uni}
\end{equation}
where $D_{\text{uni}} = \operatorname{diag}(R_{\text{uni}} \mathbf{1})$ and $\quad D_{\mathcal{I}_{\text{uni}}} = \operatorname{diag}(\mathbf{1}^\top R_{\text{uni}})$. Finally,  we also adjust the unified item similarity graph using the Hadamard power as follows:
\begin{equation}
\label{adj_graph_uni}
\bar{P}_{\text{uni}} = \tilde{P}_{\text{uni}}^{\circ s}.
\end{equation}
This process results in the unified item similarity graph $\bar{P}_{\text{uni}}$, capturing comprehensive relationships from an item-centric view derived from both group-level and member-level interactions. 

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/P_g_eigenvalue_distribution.pdf}
        
        \caption{$\bar{P}_g$}
        \label{fig:L}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/P_u_eigenvalue_distribution.pdf}
        
        \caption{$\bar{P}_u$}
        \label{fig:I}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/P_uni_eigenvalue_distribution.pdf}
        
        \caption{$\bar{P}_{\text{uni}}$}
        \label{fig:O}
    \end{subfigure}
    % \vspace{-0.2cm}
    \caption{Eigenvalue distributions of the three item similarity graphs on the CAMRa2011 dataset.}
    \label{eigen_dist}
\end{figure}


\subsection{Filter Design}\label{sec 3.2.3}
% graph filter generation
% We start by addressing the design principle of our multi-view \textsf{Group-GF} method based on the eigenvalue distributions of the three item similarity graphs $\bar{P}_{g}$, $\bar{P}_{u}$, and $\bar{P}_{\text{uni}}$. 
We address the design principle of our multi-view GF in \textsf{Group-GF} based on the constructed item similarity graphs. To this end, we investigate the eigenvalue (\textit{i.e.}, the graph frequency) distributions of the three item similarity graphs $\bar{P}_{g}$, $\bar{P}_{u}$, and $\bar{P}_{\text{uni}}$. As illustrated in Figure \ref{eigen_dist}, the eigenvalue distributions of $\bar{P}_{g}$, $\bar{P}_{u}$, and $\bar{P}_{\text{uni}}$ tend to differ noticeably.\footnote{We empirically confirm this by measuring the Kullback-Leibler (KL) divergence: $\mathbb{KL}(p_{g}||p_{u})= 0.1010$, $\mathbb{KL}(p_{\text{uni}}||p_{g})= 0.1570$, and $\mathbb{KL}(p_{\text{uni}}||p_{u})= 0.0901$, where $p_*$ denotes the eigenvalue distribution of $\bar{P}_*$ ($*\in\{u,g,\text{uni}\}$). }   
% This motivates us to design {\it distinct} polynomial graph filters for $\bar{P}_{u}$, $\bar{P}_{g}$, and $\bar{P}_{\text{uni}}$ to optimally account for their unique structural properties, which are expressed as
In this context, employing the same LPF across all item similarity graphs may not optimally take advantage of the unique structural properties of each graph. Instead, we discover a {\it distinct} graph filter for each item similarity graph, ensuring that the dynamics of both groups and members are optimally captured. More specifically, based on the three item similarity graphs $\bar{P}_{u}$, $\bar{P}_{g}$, and $\bar{P}_{\text{uni}}$, we are interested in optimally discovering the polynomial graph filter for each graph, which is expressed as
\begin{equation}
    f_1(\bar{P}_{u}) = \sum_{k=1}^{K_u}{a_{k}}\bar{P}_{u}^k;  \\
    f_2(\bar{P}_{g}) = \sum_{k=1}^{K_g}{b_{k}}\bar{P}_{g}^k;  \\
    f_3(\bar{P}_{\text{uni}}) = \sum_{k=1}^{K_{\text{uni}}}{c_{k}}\bar{P}_{\text{uni}}^k,
    \label{gf_filter}
\end{equation}
where $f_1(\bar{P}_{u})$, $f_2 (\bar{P}_g)$, and $f_3 (\bar{P}_\text{uni})$ are the polynomial graph filters for $\bar{P}_{u}$, $\bar{P}_g$, and $\bar{P}_\text{uni}$, respectively; $K_u$, $K_g$, and $K_{\text{uni}}$ are the maximum order of polynomial filters for $\bar{P}_u$, $\bar{P}_g$, and $\bar{P}_\text{uni}$, respectively; and $a_k$, $b_k$, and $c_k$ are polynomial coefficients. As an example, we can use a polynomial graph filter $f_2(\bar{P}_g)=2\bar{P}_{g}-\bar{P}^2_{g}$ to find the graph filter whose frequency response function is $h(\lambda) = 1-\lambda^2$ \cite{park2024turbo,park2025criteria}. 
%$f_3(\bar{P}_{\text{uni}})$ is the polynomial graph filter for $\bar{P}_{\text{uni}}$ 

Due to the fact that the member-level and group-level interactions behave differently depending on group recommendation scenarios \cite{guo2021hierarchical, cao2018attentive, jia2021hypergraph}, \textsf{Group-GF} optimally aggregates the three graph filters $f_1(\bar{P}_{u}), f_2(\bar{P}_{g}),$ and $f_3(\bar{P}_{\text{uni}})$ according to
\begin{equation}
\label{group-gf}
    \mathbf{s}_g = \mathbf{r}_g((1-\alpha-\beta)f_1(\bar{P}_{u}) + \alpha f_2(\bar{P}_{g}) + \beta f_3(\bar{P}_{\text{uni}})),
\end{equation}
where ${\mathbf{r}}_{g}$ is the $g$-th row of $R_g$, representing the graph signal for group $g$; $\mathbf{s}_g$ is the predicted score for group $g$; and $\alpha$ and $\beta$ are the parameters that balance among the three types of polynomial graph filters. The final prediction optimally combines the preferences propagated through member-level, group-level, and unified interactions via hyperparameter tuning on the validation set. 

% \begin{remark}
% \textsf{Group-GF} utilizes simple matrix operations, enabling efficient computation on modern hardware (\textit{i.e.}, CPU and GPU) using PyTorch \cite{paszke2019pytorch} with CUDA \cite{sanders2010cuda}. The fast computation allows us to efficiently determine the optimal filter for each item similarity graph.
% \end{remark}

% Next, let us turn to providing a theoretical foundation for \textsf{Group-GF}, which bridges between multi-view GF and optimization via smoothness regularization.  The smoothness regularization assures that similar nodes (\textit{i.e.}, items) in the graph have similar preference scores, thereby leading to more accurate recommendations.

Next, let us turn to providing a theoretical foundation for \textsf{Group-GF}, which bridges between multi-view GF and optimization via smoothness regularization. We consider smoothness regularization in the context of group recommendation, because the preferences of individual members and the preferences of the belonging group as a whole are interconnected within the graph structure. The smoothness regularization assures that similar nodes (\textit{i.e.}, items) in each graph have similar preference scores, leading to more accurate recommendations.
\begin{theorem}
\small{
\label{theorem1}
Let $L_u = I - \bar{P}_u$, $L_g = I - \bar{P}_g$, and $L_{\text{uni}} = I - \bar{P}_{\text{uni}}$ be the graph Laplacians corresponding to $\bar{P}_u$, $\bar{P}_g$, and $\bar{P}_{\text{uni}}$, respectively. Then, the predicted group preference scores $\mathbf{s}_g$ in Eq. \eqref{group-gf} are an approximate solution to the following optimization problem:
\begin{equation}
\label{smootheness_eq}
\begin{split}
\mathbf{s}_g \approx \arg\min_{\mathbf{s}} \Biggl\{ & \|\mathbf{s} - \mathbf{r}_g\|^2 + \lambda \mathbf{s}^\top \left( (1 - \alpha - \beta) L_u + \alpha L_g + \beta L_{\text{uni}} \right) \mathbf{s} \Biggr\},
\end{split}
\end{equation}
where $\lambda > 0$ is a regularization parameter and $0<\alpha,\beta<1$ are balancing parameters.
}
\end{theorem} 
% \vspace{-0.2cm}
The proof of this theorem is available at \url{https://github.com/chaehyun1/Group-GF}. 
% Theorem \ref{theorem1} implies that group preference scores ${\bf s}_g$ can be obtained in a closed-form expression without costly solving the optimization problem in Eq. \eqref{smootheness_eq} whose solution ensures smoothness over the member-level, group-level, and unified interactions.
From Theorem \ref{theorem1}, it is shown that the predicted group preference scores $\mathbf{s}_g$ in Eq. \eqref{group-gf} are indeed an approximate solution to the optimization problem in Eq. \eqref{smootheness_eq} that contains smoothness over the member-level, group-level, and unified interactions. Here, without the regularization term (\textit{i.e.}, $\lambda = 0$), the predicted group preference scores $\mathbf{s}_g$ are equal to the observed group-level interactions $\mathbf{r}_g$. This implies that the \textsf{Group-GF} method does not integrate any information from the three item similarity graphs, thereby ignoring the relationships captured by the member-level, group-level, and unified interactions. This theoretical finding enhances the interpretability of the \textsf{Group-GF} method by linking group preference propagation with smoothness regularization. In other words, this interpretation provides a clearer understanding of how preferences are identified from the three different interactions.


\section{Experimental Evaluation}

\definecolor{lightgray}{gray}{0.9}
\begin{table}[t]
\footnotesize
  \captionsetup{skip=1pt}
  \caption{The statistics of the three real-world benchmark datasets having both group--item and member--item interactions.}
  \begin{tabular}{@{}ccccccl@{}}
    \toprule
    Dataset & \# Members & \# Items & \# Groups & \# M-I inter. & \# G-I inter. \\ 
    \midrule
    CAMRa2011 & 602 & 7,710 & 290 & 116,344 & 145,068 \\
    Mafengwo & 5,275 & 1,513 & 995 & 39,761 & 3,595 \\
    Douban  & 3,481 & 43,916 & 1,162 & 829,229 & 9,245 \\
  \bottomrule
\end{tabular}
\label{table:datasets}
\end{table}

\label{sec4}

\subsection{Experimental Settings}
\noindent\textbf{Datasets.} We adopt three widely used benchmark datasets on group recommendations \cite{wu2023consrec, cao2018attentive, jia2021hypergraph, yin2019social}, including CAMRa2011, Mafengwo, and Douban. Table \ref{table:datasets} summarizes the statistics of the three datasets. We note that the size of group recommendation datasets are inherently smaller in scale than that of canonical (user) recommendation datasets, reflecting their focus on collective interactions rather than individual-level data.

\noindent\textbf{Competitors.} We compare \textsf{Group-GF} with eight state-of-the-art group recommendation methods, including DNN-based (NCF \cite{he2017neural}), attentive aggregation-based (AGREE \cite{cao2018attentive}), hypergraph-based (HyperGroup \cite{guo2021hierarchical}, HCR \cite{jia2021hypergraph}, and ConsRec \cite{wu2023consrec}), and SSL-based (GroupIM \cite{sankar2020groupim}, S$^2$-HHGR \cite{zhang2021double}, and CubeRec \cite{chen2022thinking}) methods.

\noindent\textbf{Evaluation protocols.} Following the evaluation protocol outlined in \cite{jia2021hypergraph, wu2023consrec}, we adopt performance metrics such as the hit ratio (HR@$k$) and the normalized discounted cumulative gain (NDCG@$k$), where $k$ is set to 10 by default, due to the space limitation. 
% \yn{Precisely, we utilize a dataset where 100 negative items are randomly sampled for each ground truth item and rank them based on the calculated interaction probabilities, while using the same data split for training, test, and validation sets.} 

\noindent\textbf{Implementation details.} In our experiments, rather than exhaustively searching for polynomial coefficients, we use the polynomial graph filters presented in \cite{park2024turbo} ({\it i.e.}, pre-defined polynomial coefficients in Eq. (\ref{gf_filter})) for efficient filter search, because it was empirically confirmed that exhaustive search leads to only negligible gains in recommendation accuracy. \textsf{Group-GF} is basically training-free; however, similarly as in training-based recommendation methods, it adjusts hyperparameters on the validation set. All experiments are carried out with the same device: Intel (R) 12-Core (TM) i7-9700K CPUs @ 3.60 GHz and GPU of NVIDIA GeForce RTX A6000.

\noindent\textbf{Additional experiments.} Further experimental results, including 1) scalability, 2) analysis on different group sizes, 3) comparison with canonical recommendation methods, and 4) sensitivity analysis, as well as the reproducibility code, can be found at \url{https://github.com/chaehyun1/Group-GF}.

\begin{table}[t]
\footnotesize % 글씨 크기 조정
\centering
\caption{Runtime comparison. The best and second-best performers are highlighted in bold and underline, respectively. Here, `OOM' denotes an out-of-memory issue.}
% \vspace{-0.3cm}
\label{runtime_table}
\begin{tabular}{lccccc} % 테이블 크기 수동으로 설정
\hline
 & AGREE & GroupIM & CubeRec & ConsRec & \textbf{Group-GF} \\ \hline
CAMRa2011 & 1h41m6s & \underline{1m34s} & 4h16m4s & 12m19s & \textbf{6.71s} \\ 
Mafengwo  & 24m1s  & \underline{57.13s} & 5m45s   & 14m57s & \textbf{1.55s} \\ 
Douban  & 12h1m36s  & OOM & 1h28m51s & \underline{1h21m1s} & \textbf{3m26s} \\ 
\hline
Training  & \textcolor{blue}{\cmark} & \textcolor{blue}{\cmark} & \textcolor{blue}{\cmark} & \textcolor{blue}{\cmark} & \textcolor{purple}{\xmark} \\ \hline
\end{tabular}
\end{table}



\begin{table}[t!] %t!
\vspace{-3mm}
\footnotesize
\centering
\caption{Recommendation accuracy (HR@10 and NDCG@10). The best and second-best performers are highlighted in bold and underline, respectively.}

\label{main_results}
\begin{tabular}{lcccccc}
\toprule
 & \multicolumn{2}{c}{\textbf{CAMRa2011}} & \multicolumn{2}{c}{\textbf{Mafengwo}} & \multicolumn{2}{c}{\textbf{Douban}} \\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
 & HR & NDCG & HR & NDCG& HR & NDCG \\
\midrule
% Pop & 0.5793 & 0.3302 & 0.4251 & 0.2537 & 0.1174 & 0.0625 \\
NCF & 0.7693 & 0.4448 & 0.6269 & 0.4141 &0.4132 & 0.2446 \\
AGREE & 0.7789 & 0.4530 & 0.6321 & 0.4203 & 0.7701 & \underline{0.6859} \\
HyperGroup & 0.7986 & 0.4538 & 0.6482 & 0.5018 & \underline{0.7757} & 0.5318 \\
HCR & 0.7821 & 0.4670 & 0.8503 & 0.6852 & 0.6537 & 0.6441 \\
GroupIM & \underline{0.8407} & 0.4914 & 0.8161 & 0.6330 & \multicolumn{2}{c}{------ OOM ------} \\
S$^2$-HHGR & 0.7903 & 0.4453 & 0.7779 & 0.7391 & 0.7180 & 0.4565 \\
CubeRec & 0.8207 & 0.4935 & 0.9025 & 0.7708 & 0.6992 & 0.4240 \\
ConsRec & 0.8248 & \underline{0.4945} & \underline{0.9156} & \underline{0.7794} & 0.7403 & 0.6621 \\
\rowcolor{lightgray}\textbf{Group-GF} & \textbf{0.9552} & \textbf{0.5030} & \textbf{0.9266} & \textbf{0.8451} & \textbf{0.9028} & \textbf{0.7291} \\
\bottomrule
\end{tabular}
\end{table}

\vspace{-2mm}

\subsection{Runtime Analysis}
Table \ref{runtime_table} presents the runtime of \textsf{Group-GF} compared to the four DNN-based competitors that perform well (AGREE, GroupIM, CubeRec, and ConsRec) on the three benchmark datasets. Here, the runtime indicates the training duration for DNN-based methods, while referring to the processing time for \textsf{Group-GF}. 
% \textsf{Group-GF} exhibits its remarkable computational efficiency, achieving up to \underline{$\times558.3$ faster runtime} than that of the second-best performer (\textit{i.e.}, ConsRec) on the Mafengwo dataset. 
\textsf{Group-GF} exhibits its remarkable computational efficiency, achieving up to \underline{$\times36.85$ faster runtime} than that of the second-best performer ({\it i.e.}, GroupIM) on the Mafengwo dataset.
This is because \textsf{Group-GF} operates solely on straightforward matrix operations, eliminating the need for a costly training process to learn patterns in group-level and member-level interactions. A similar tendency can be observed in both the CAMRa2011 and Douban datasets.


\subsection{Recommendation Accuracy}
The performance of \textsf{Group-GF} and all competitors is summarized in Table \ref{main_results}. Our key observations are made as follows:
\begin{enumerate}[label=(\roman*)]
    \item In spite of not requiring any training, \textsf{Group-GF} consistently outperforms state-of-the-art group recommendation methods across all datasets and metrics. Specifically, on the Douban dataset, it achieves up to 16.4\% higher HR@10 than that of the best competitor. This is due to \textsf{Group-GF}'s ability to effectively integrate member and group information while capturing complex member-level, group-level, and unified interactions.
    \item In contrast to early-developed methods such as AGREE, techniques based on hypergraph structures and SSL show comparatively competing performance. This implies the importance of modeling the complex interactions between each group and its belonging members in capturing group preferences.
    % \ch{which is possible due to the effective modeling of group preferences through the complex interrelations between diverse preferences of each group and its belonging members.}
\end{enumerate}
\vspace{-2mm}

\begin{table}[t]
\small
\centering
\caption{Performance comparison among \textsf{Group-GF} and its four variants in terms of NDCG@10.}

\label{ablation_table_modified_ndcg}
\begin{tabular}{lccc}
\hline
\textbf{} & \textbf{CAMRa2011} & \textbf{Mafengwo} & \textbf{Douban}\\  \hline
\textsf{Group-GF} & \textbf{0.5030} & \textbf{0.8451} & \textbf{0.7291}\\ 
\textsf{Group-GF-m} & 0.4769 & 0.8376 & 0.6104\\ 
\textsf{Group-GF-g} & 0.5003 & 0.8367 & 0.7272\\ 
\textsf{Group-GF-uni} & 0.4999 & 0.8272& 0.6665\\ 
\textsf{Group-GF-a} & 0.5025 & 0.8446& 0.6728\\ 
\hline
\end{tabular}
\end{table}


\subsection{Ablation Study}

To assess the contribution of each component in \textsf{Group-GF}, we perform an extensive ablation study alongside four variants, each based on different sources accounting for \textsf{Group-GF}: 1) \textsf{Group-GF-m}: excludes the member-level component $\bar{P}_{u}$ in Eq. (\ref{adj_graph_ug}); 2) \textsf{Group-GF-g}: excludes the group-level component $\bar{P}_{g}$ in Eq. (\ref{adj_graph_ug}); 3) \textsf{Group-GF-uni}: excludes the unified item similarity graph $\bar{P}_{\text{uni}}$ in Eq. (\ref{adj_graph_uni}); 4) \textsf{Group-GF-a}: removes the member--group relation matrix $M$ in Eq. (\ref{aug_inters}).
%uni in Eq. (8);
% : 1) \textsf{Group-GF-m}: excludes the member-level component $\bar{P}_{u}$ in Eq. \eqref{adj_graph_ug}; 2) \textsf{Group-GF-g}: excludes the group-level component $\bar{P}_{g}$ in Eq. \eqref{adj_graph_ug}; 3) \textsf{Group-GF-uni}: excludes the unified item similarity graph $\bar{P}_{\text{uni}}$ in Eq. \eqref{adj_graph_uni}; 4) \textsf{Group-GF-a}: removes the member--group relation matrix $M$ in Eq. \eqref{aug_inters}. 
 The performance comparison among the original \textsf{Group-GF} and its four variants is summarized in Table \ref{ablation_table_modified_ndcg} {\it w.r.t.} the NDCG@10. Our findings are as follows:


\begin{enumerate}[label=(\roman*)]

    \item \textsf{Group-GF} consistently outperforms all four variants, emphasizing the vital role of each component in ensuring accurate group recommendations.

    \item \textsf{Group-GF-m} exhibits the largest decline on CAMRa2011 and Douban, while \textsf{Group-GF-uni} on Mafengwo. This implies that the importance of types of interactions varies depending on the dataset characteristics.
    % This implies that the significance of interaction types varies across the dataset characteristics.
        
    % \item \textsf{Group-GF-uni} leads to performance drops consistently across all the datasets, highlighting the importance of jointly incorporating group-level and member-level interactions in GF to achieve state-of-the-art recommendation accuracy. \gf{This suggests that the unified item similarity graph plays a crucial role in effectively capturing complex relationships among items, thereby enhancing the overall performance of group recommendations.}

    \item The absence of $\bar{P}_{\text{uni}}$ leads to significant performance drops consistently across all the datasets, highlighting the importance of jointly incorporating group-level and member-level interactions in GF. A more nuanced reflection of all possible interactions between members and groups can facilitate more accurate group recommendations.

    \item The removal of $M$ from Eq. \eqref{aug_inters} also results in a non-negligible performance decrease on all the datasets. This observation indicates that reflecting group--member relationship information in GF is crucial for achieving state-of-the-art recommendation performance.
\end{enumerate}

\section{Conclusions and Future Work}
% We addressed an underexplored challenge of designing efficient and effective GF methods for group recommendations. 
We addressed an unexplored yet important challenge of designing GF methods for group recommendations.
% To this end, we proposed \textsf{Group-GF}, a training-free multi-view GF method that leverages all available interactions through the construction of multi-view-enabled item similarity graphs and the optimal design of distinct polynomial graph filters. 
To this end, we proposed \textsf{Group-GF}, an innovative group recommendation method via training-free multi-view GF, which is capable of jointly leveraging all available interactions. In \textsf{Group-GF}, we showed 1) how to construct two augmented item similarity graphs and one unified item similarity graph, which manifest different viewpoints for GF, and 2) how to efficiently and optimally discover each of distinct polynomial graph filters and aggregate them.
% Through systematic evaluations and analyses, we demonstrated \textsf{Group-GF}'s (a) superior performance, (b) runtime efficiency, and (c) theoretical foundations that supports model performance. 
Through systematic evaluations and analyses, we demonstrated (a) the remarkable computational efficiency of \textsf{Group-GF}, (b) the superior recommendation accuracy over state-of-the-art methods in various circumstances, and (c) the theoretical finding that supports the model's performance and interpretability.
As the three similarity graphs $\bar{P}_{u}$, $\bar{P}_{g}$, and $\bar{P}_{\text{uni}}$ need to be loaded into memory, which is memory-demanding, potential avenues of our future research include the design of a memory-efficient and scalable GF method for large-scale group recommendation scenarios.

\section*{Acknowledgments}
This work was supported by the National Research Foundation of Korea (NRF), Republic of Korea Grant by the Korean Government through MSIT under Grants RS-2021-NR059723 and RS-2023-00220762 and by the Institute of Information and Communications Technology Planning and Evaluation (IITP), Republic of Korea Grant by the Korean Government through MSIT (6G Post-MAC–POsitioning and Spectrum-Aware intelligenT MAC for Computing and Communication Convergence) under Grant 2021-0-00347.
\vspace{-1mm}

% Reference
\bibliographystyle{ACM-Reference-Format}

% \bibliography{sample-base, citation_list}
\bibliography{citation_list}


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
