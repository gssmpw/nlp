\section{Related Work}
In recent years, argument mining has become a productive field of research. Although limited to a small number of corpora, various approaches have been developed for the automatic extraction of argument structures. This section will explore the methods employed to extract arguments from text and evaluate their advantages and disadvantages. The selected works were chosen based on their relevance, the reliability of their findings, and the range of technologies utilised.
\subsection{ Integer Linear Programming (\textbf{ILP}) Joint Model } \label{sec:ILP}
\textcite{ParsingArgumentationStructures} introduce a corpus of persuasive essays annotated with argumentation structure in their paper. For the corpus they provide numbers on the Inter-Annotator Agreement (\textbf{IAA}), reporting an overall agreement of \(\alpha_U = 0.767\). Taking into account the IAA's of their previous work \parencite{stab-gurevych-2014-identifying}, they tentatively conclude, "that overall human annotators agree on the argument components in persuasive essays" \parencite{ParsingArgumentationStructures}. Additionally, they present a parser for argumentation structure, which uses the corpus for training and validating a machine learning model.  For their parser they propose an architecture shown in Figure \ref{fig:IlpJointModel}. They use a directed sequential approach with a joint model to classify component types and identify their relations. The authors argue that their model is more effective than identifying argumentative relations and components individually using the base classifiers, as their model can more reliably link premises. They have also defined a ruleset to converge the results into a tree structure. In the final step, they classify the argumentative relations. This process considers pairs of components that are linked in the tree structure for classification.
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/ILPJointModel.png}
    \caption{Task architecture of an argumentation structure parser \parencite{ParsingArgumentationStructures}}
    \label{fig:IlpJointModel}
\end{figure}

To fit and evaluate their model they opted for a 5-fold cross-validation on their own Essay corpus consisting of 6089 argument components. As their main performance metric they use the macro F1 score. It is a popular metric for evaluating binary classification models and represents the harmonic mean of precision and recall over all labels/classes. They report achieving significant improvements over their heuristic baseline models. These are the resulting macro F1 scores for the individual classification sub-tasks with their ILP joint model: 
\begin{itemize}
    \item Components: 0.826
    \item Relations: 0.751
    \item Stance Recognition: 0.680 
\end{itemize}
For the component identification model they use a CRF model. The resulting component spans are then fed into their ILP model, which combines the use of two Support Vector Machines in conjunction, to recognize the argumentation structure. According to one of their earlier works, the reason for this is that argumentative types and relations share information \parencite{stab-gurevych-2014-identifying}. For instance, the probability of an outgoing relationship is lower for a component classified as a claim than for a premise. That is why an independent approach to those problems holds less potential for good results. In their ILP model the authors present a method for determining the weights of argumentative relations in an adjacency matrix. Claim scores are calculated based on predicted relations, with higher weights assigned to relations pointing to claims and weights set to 0 for relations pointing to premises. This method considers predicted relations, claim scores, and component types to accurately predict argumentative relations.

\subsection{Transformer-Based Argument Mining } \label{sec:Transformer}
\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Transformer_Based_Pipeline.png}
    \caption{Pipeline of clinical trial argument mining \parencite{TransformerHealthcareAM}. }
    \label{fig:TransformerPipe}
\end{figure*}
In their paper \textcite{TransformerHealthcareAM} focus on mining argumentation in abstracts of Randomized Control Trials (\textbf{AbstRCT}). They extended a corpus from the MEDLINE database, totaling a number of 4198 annotated argument components and 2601 relations. For measuring the IAA, a sample of 30 abstracts from the corpus was drawn. According to the authors, Fleiss' kappa was 0.72 for component annotation and 0.62 for relation annotation, demonstrating moderate to substantial agreement between annotators. They presented an argument mining pipeline that uses neural networks in combination with transformer-embeddings. The neural architectures used in this study include Long Short-Term Memory (\textbf{LSTM}) networks, Gated Recurrent Unit (\textbf{GRU}) networks, and CRFs with various types of embeddings. These range from static, context-insensitive embeddings such as \textbf{GloVe} \parencite{glove}, \textbf{fastText} \parencite{bojanowski2016enriching}, and \textbf{BPEmb} \parencite{bpemb} to dynamic embeddings like \textbf{ELMo} \parencite{ELMo}, \textbf{FlairPM} \parencite{flair}, and \textbf{BERT} \parencite{bert}. The main difference between these two categories is that dynamic embeddings contextualize not only a single word but the entire input sequence. It is important to note that the researchers also experimented with more fine-tuned versions of BERT: \textbf{BioBERT} \parencite{biobert} and \textbf{SciBERT} \parencite{scibert} are transformers specifically trained on biomedical texts and scientific papers respectively. Figure \ref{fig:TransformerPipe} illustrates their architecture, which combines the detection and classification of components into a single task, called multi-class sequence tagging. Tokens \textbf{w} are tagged with a modified Beggining-Inside-Outside-tagging (\textbf{BIO-tagging}) scheme using five labels, B-Claim, I-Claim, B-Evidence, I-Evidence and Outside. Adjacent tagged tokens \textbf{L} can be directly converted to their corresponding component, shown as \textbf{a}, \textbf{b} and \textbf{c}. E.g. this sequence of tokens \(B \mhyphen Claim \rightarrow I \mhyphen Claim \rightarrow I \mhyphen Claim \rightarrow Outside\) would represent a claim. This departs from the conventional sequential pipeline and suggests a more end-to-end oriented approach by combining multiple tasks in a single model. The relationships between the extracted components from the tagged tokens, are then classified by a second model. After that a graph is constructed, reflecting the argument structure of the text.

The results of the sequence tagging task show a clear performance advantage of the dynamic embeddings. The combination of fine-tuned BioBERT embeddings with GRU networks and CRFs resulted in an overall macro F1 score of 0.91. The model's performance was then tested for relation classification, where the use of SciBERT embeddings achieved a macro F1 score of 0.69.

\subsection{Multi-Task Argument Mining (\textbf{MT-AM})}
In their work, \textcite{EndToEndAM} try to address the issue of shortage of training data by proposing a method called Multi-Task Argument Mining (MT-AM). The approach utilises various corpora with different annotation schemes, structures (graph/tree-based) and domains to enhance overall argument mining performance. By leveraging similar argumentation patterns across multiple corpora, they hope, that their model's overall performance can be improved. An overview of the used corpora can be seen in Figure \ref{fig:E2ECorpora}, where AAEC refers to the Essay corpus from \textcite{ParsingArgumentationStructures} in section \ref{sec:ILP} and AbstRCT is the non-extended version of the corpus used by \textcite{TransformerHealthcareAM} in section \ref{sec:Transformer}. Their thorough analysis of the corpora revealed similar characteristics of the annotations and argumentative structure, indicating their potential usefulness in MT-AM. This for example includes the almost universal distinction of relations in support and attack, that can also be seen marked in blue and red in Figure \ref{fig:E2ECorpora}.
\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Corpora.png}
    \caption{A table of the various corpora used by \textcite{EndToEndAM}}
    \label{fig:E2ECorpora}
\end{figure*}

The two-staged MT-AM model incorporates as first stage a pre-training phase using multiple auxiliary corpora. This approach enhances the model's ability to recognise transferrable linguistic structures among corpora, aiding its generalisation across tasks. The model's significant feature is its adoption of end-to-end learning. Unlike transition-based parsing methods, it does not require the mapping of component and relation labels on the bases of semantic commonality. Instead, it is trained to recognize these labels directly from the data. During the fine-tuning phase, the model is trained again using the defined target corpus and different hyperparameters, such as a higher loss weight during learning. This is done to prevent performance degradation by supressing distant information from the auxiliary corpora. The model is then ready to be applied to text, preferably with an argument structure similar to that of the target corpus.

The pipeline parsing routine consists of the following steps: The Longformer \parencite{beltagy2020longformer}, a transformer model, is used to generate sequence embeddings. It is specifically designed to handle long text sequences, making it ideal for argument mining tasks, that require understanding of extensive context. After generating the sequence embedding, the next step is to identify and classify spans using a Multilayer Perceptron (\textbf{MLP}) neural network \parencite{nn_foundation}. After identifying and classifying the spans, the sequence embedding undergoes an average pooling operation to transform it into a fixed-size embedding. This enables subsequent layers of the model to process the embedding, regardless of the original sequence length. Finally, a biaffine classifier is used to detect links and classify labels. The biaffine classifier is a type of classifier that models complex relationships between different parts of the data, making it particularly effective for tasks, that are dependent on each other like link detection and label classification. 

As a baseline for evaluation they use, their Single Task (\textbf{ST}) model, which is only trained on the target corpus. Generally the MT-AM pre-trained on all auxiliary corpora and fine-tuned on the target corpus outperformed the ST models. In a comparison with other models, including the ILP Joint model from \textcite{ParsingArgumentationStructures} and a transformer-based approach similar to \textcite{TransformerHealthcareAM}, their ST model performed on par with the competition. It managed to outperform the ILP Joint model on the Essay corpus with a macro F1 score of 0.868 at component classification \parencite{mtc} 

\subsection{Model discussion}
____'s (____) joint model approach already hints to a development, that can be seen in the following works discussed in this section. They shift away from designated sub-tasks, to a model integrated approach. Even though they succeed in creating a well-performing parser for their Essay corpus, their feature-based approach has shown its limits. Later studies improve on capturing context more intuitively, with for example transformer embeddings, instead of single structural, lexical or syntactical features.  Another notable feature of the presented work is the end-to-end learning of \textcite{EndToEndAM}. They have been able to demonstrate the effectiveness of multitask argument mining integrating various corpora into one model. This highlights two characteristics in the field of argument mining: argumentative structures in different domains contain overlapping information, that can be exploited; models are likely to perform well, when they are specifically trained on their tasks target domain. This claim is also supported by the results of \textcite{TransformerHealthcareAM}. By using a domain-specific transformer, embeddings are created that better represent the context of the domain. This allows machine learning models working with these embeddings to learn argumentative patterns in the language more effectively.