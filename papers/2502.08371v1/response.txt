\section{Related Work}
In recent years, argument mining has become a productive field of research. Although limited to a small number of corpora, various approaches have been developed for the automatic extraction of argument structures. This section will explore the methods employed to extract arguments from text and evaluate their advantages and disadvantages. The selected works were chosen based on their relevance, the reliability of their findings, and the range of technologies utilised.
\subsection{ Integer Linear Programming (\textbf{ILP}) Joint Model } \label{sec:ILP}
\textcite{stab-gurevych-2014-identifying} introduce a corpus of persuasive essays annotated with argumentation structure in their paper. For the corpus they provide numbers on the Inter-Annotator Agreement (\textbf{IAA}), reporting an overall agreement of \(\alpha_U = 0.767\). Taking into account the IAA's of their previous work \parencite{stab-gurevych-2014-identifying}, they tentatively conclude, "that overall human annotators agree on the argument components in persuasive essays" \parencite{ParsingArgumentationStructures}. Additionally, they present a parser for argumentation structure, which uses the corpus for training and validating a machine learning model.  For their parser they propose an architecture shown in Figure \ref{fig:IlpJointModel}. They use a directed sequential approach with a joint model to classify component types and identify their relations. The authors argue that their model is more effective than identifying argumentative relations and components individually using the base classifiers, as their model can more reliably link premises. They have also defined a ruleset to converge the results into a tree structure. In the final step, they classify the argumentative relations. This process considers pairs of components that are linked in the tree structure for classification.
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/ILPJointModel.png}
    \caption{Task architecture of an argumentation structure parser \parencite{ParsingArgumentationStructures}}
    \label{fig:IlpJointModel}
\end{figure}

To fit and evaluate their model they opted for a 5-fold cross-validation on their own Essay corpus consisting of 6089 argument components. As their main performance metric they use the macro F1 score. It is a popular metric for evaluating binary classification models and represents the harmonic mean of precision and recall over all labels/classes. They report achieving significant improvements over their heuristic baseline models. These are the resulting macro F1 scores for the individual classification sub-tasks with their ILP joint model: 
\begin{itemize}
    \item Components: 0.826
    \item Relations: 0.751
    \item Stance Recognition: 0.680 
\end{itemize}
For the component identification model they use a CRF model. The resulting component spans are then fed into their ILP model, which combines the use of two Support Vector Machines in conjunction, to recognize the argumentation structure. According to one of their earlier works, the reason for this is that argumentative types and relations share information \parencite{stab-gurevych-2014-identifying}. For instance, the probability of an outgoing relationship is lower for a component classified as a claim than for a premise. That is why an independent approach to those problems holds less potential for good results. In their ILP model the authors present a method for determining the weights of argumentative relations in an adjacency matrix. Claim scores are calculated based on predicted relations, with higher weights assigned to relations pointing to claims and weights set to 0 for relations pointing to premises. This method considers predicted relations, claim scores, and component types to accurately predict argumentative relations.

\subsection{Transformer-Based Argument Mining } \label{sec:Transformer}
\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Transformer_Based_Pipeline.png}
    \caption{Pipeline of clinical trial argument mining \parencite{TransformerHealthcareAM}. }
    \label{fig:TransformerPipe}
\end{figure*}
In their paper \textcite{TransformerHealthcareAM} focus on mining argumentation in abstracts of Randomized Control Trials (\textbf{AbstRCT}). They extended a corpus from the MEDLINE database, totaling a number of 4198 annotated argument components and 2601 relations. For measuring the IAA, a sample of 30 abstracts from the corpus was drawn. According to the authors, Fleiss' kappa was 0.72 for component annotation and 0.62 for relation annotation, demonstrating moderate to substantial agreement between annotators. They presented an argument mining pipeline that uses neural networks in combination with transformer-embeddings. The neural architectures used in this study include Long Short-Term Memory (\textbf{LSTM}) networks, Gated Recurrent Unit (\textbf{GRU}) networks, and CRFs with various types of embeddings. These range from static, context-insensitive embeddings such as \textbf{GloVe} \parencite{glove}, \textbf{fastText} \parencite{bojanowski2016enriching}, and \textbf{BPEmb} \parencite{bpemb} to dynamic embeddings like \textbf{ELMo} \parencite{ELMo}, \textbf{FlairPM} \parencite{flair}, and \textbf{BERT} \parencite{bert}. The main difference between these two categories is that dynamic embeddings contextualize not only a single word but the entire input sequence. It is important to note that the researchers also experimented with more fine-tuned models, including a transformer-based approach similar to \textcite{TransformerHealthcareAM}. Their Single Task (\textbf{ST}) model performed on par with the competition, managing to outperform the ILP Joint model on the Essay corpus with a macro F1 score of 0.868 at component classification \parencite{mtc} 

\subsection{Model discussion}
Gurevych and Kim's (2016) joint model approach already hints to a development, that can be seen in the following works discussed in this section. They shift away from designated sub-tasks, to a model integrated approach. Even though they succeed in creating a well-performing parser for their Essay corpus, their feature-based approach has shown its limits. Later studies improve on capturing context more intuitively, with for example transformer embeddings, instead of single structural, lexical or syntactical features.  Another notable feature of the presented work is the end-to-end learning of \textcite{EndToEndAM}. They have been able to demonstrate the effectiveness of multitask argument mining integrating various corpora into one model. This highlights two characteristics in the field of argument mining: argumentative structures in different domains contain overlapping information, that can be exploited; models are likely to perform well, when they are specifically trained on their tasks target domain. This claim is also supported by the results of \textcite{TransformerHealthcareAM}. By using a domain-specific transformer, embeddings are created that better represent the context of the domain. This allows machine learning models working with these embeddings to learn argumentative patterns in the language more effectively.