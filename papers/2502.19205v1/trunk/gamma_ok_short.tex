\section{Adversarial edge  sequences}\label{sec:gammaok}
We next study our lazy-update algorithm in an adversarial framework. We  show  in \Cref{ssec:lowerbound} that if the adversary can \textit{both}: i) choose a worst-case  graph $G$ \textit{and} ii)   submit $G$ according to an \textit{adaptive} sequence of edge insertions, then it is possible to prove a strong lower bound on the achievable update-time/approximation trade-off of the whole parameterized scheme $\lazyscheme (\varphi,k)$.

On the other hand, in \Cref{ssec:gammaok} we provide a \textit{necessary} condition for the adversarial, worst-case framework above: the \textit{girth} \cite{diestel2024graph} of $G$ must be smaller than 5. More precisely, $G$ must contain an unbounded number of triangles and cycles of length 4. We do this by showing that for a suitable parameter setting, algorithm $\lazyscheme (\varphi,k)$ achieves almost-optimal trade-offs even on adversarial edge insertion sequences, for every graph that has a bounded number of such small cycles (see \Cref{def:gammaok} for a formal definition of this class of graphs).

\subsection{A lower bound for adversarial sequences} \label{ssec:lowerbound}
The lower bound for the adversarial framework described above is formalized in the following result on the approximation ratio (see Def. \ref{def:coverage})


\begin{theorem}\label{thm:lower}
    For every $\varphi \in [0,1]$, and integer $k \geq 0$, if  \lazyscheme$(\varphi,k)$ has approximation ratio $\rho \ge 1$, then it must have an amortized update cost  of $\Omega(\Delta/\rho^3)$, where $\Delta$ is the maximum degree of the graph.
\end{theorem}\label{le:lb1}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.66\linewidth]{img/lower-bound.pdf}
    \caption{Black edges are present at $t = 0$, while red ones are inserted in the interval $\{1, 2,\ldots , \Delta \rho^2\}$. At time $t > 0$, an edge with one endpoint in $u_{1t\mod\Delta}$ and the other in a distinct 0-degree vertex in $S_2$ is added.}
    \label{fig:lb1}
\end{figure}

\begin{proof}
Fix $\rho \ge 1$, and assume that \lazyscheme$(\varphi,k)$ has an approximation ratio of at most $\rho$. We will show that there exist an initial graph $G^{(0)}$ with degree $\Delta$ and a sequence of edge insertions against which \lazyscheme$(\varphi,k)$ must incur an amortized update time of $\Omega(\Delta/\rho^3)$.

Note that for $k>0$, the algorithm is randomized. In order to address this, we prove our lower bound for every possible realization of the randomness used by the algorithm. Therefore, we assume the values of the random bits used by \lazyscheme$(\varphi,k)$ are fixed arbitrarily (and optimally) and we assume henceforth that the behavior of the algorithm is completely deterministic. 

The initial graph $G^{(0)}$ consists on $2 \Delta$ vertices forming a complete bipartite graph with sides $S_0=\{u_{01},\dots,u_{0\Delta}\}$ and $S_1=\{u_{11},\dots,u_{1\Delta}\}$, along with an additional set $S_2$ of $\Delta \rho^2$ isolated vertices (see \Cref{fig:lb1}).
The sequence of edge insertions is defined as follows: 
for each vertex in $S_1$, we insert $\rho^2$ new edges. Each of these $\Delta\rho^2$ edges connects a vertex in $S_1$ to a previously isolated vertex in $S_2$.
% We insert $\rho^2$ new edges incident to each vertex in $S_1$. Each of these $\Delta \rho^2$ new edges has an endpoint in $S_1$, while the other is a previously $0$-degree vertex in $S_2$. 

%These edges are inserted in a round-robin fashion: we first insert an edge incident to $u_{11}$, then one incident to $u_{12}$ up to one incident to $u_{1\Delta}$, then again another incident to $u_{11}$ and so on. We can view the sequence of insertions as organized in $\rho^2$ rounds of $\Delta$ steps each.
%In the $i$-th step of the $j$-th round one edge is added from $u_{1i}$ to a different vertex belonging to $S_2$.


Consider the time instant right after all edge insertions. 
Since we assumed that the algorithm guarantees an approximation ratio of $\rho$, it holds that for every vertex $u \in S_0$, $|\apxball_2(u)| \ge \frac{1}{\rho} |\ball_2(u)|=\frac{1}{\rho} (2\Delta+\Delta \rho^2) = \Delta \rho + 2\Delta/\rho$. This implies that after all edge insertions, $u$ must be aware of at least $\Delta \rho + 2\Delta/\rho - 2\Delta=\Delta\rho -2 \Delta(1-1/\rho)$ vertices from $S_2$. 

We say that there is a \emph{message} from $v$ to $u$ if vertex $v$ performs a union operation of the form $\apxball_2(u) \gets \apxball_2(u) \cup \apxball_1(v)$.

Since, at any time, every vertex $v \in S_1$ is adjacent to at most $\rho^2$ vertices in $S_2$, it must be that each $u \in S_0$ must have received at least 
$\frac{\Delta\rho -2 \Delta(1-1/\rho)}{\rho^2}=\Omega(\Delta/\rho)$
messages from vertices in $S_1$. As a consequence, the total number of messages are at least $\Omega(\Delta^2/\rho)$. As the number of insertions is $\Delta \rho^2$, the amortized update cost per insertion is at least $\frac{\Omega(\Delta^2/\rho)}{\Delta \rho^2}=\Omega(\Delta/\rho^3)$.
\end{proof}

We have special cases as corollaries. We need amortized update cost $\Omega(\Delta)$ if we want $\rho = O(1)$, $\Omega(\sqrt[4]{\Delta})$ if we want $\rho = O(\sqrt[4]{\Delta})$ and so on. 

\begin{remark}
    The lower bound in \Cref{le:lb1} in fact holds for a wider class of algorithms. Informally speaking, this class includes any \textit{local} algorithm that limits its online updates to the 2-hop neighbors of $u$ and $v$ only. Making this claim more formal requires addressing several technical issues that are outside the scope of the present work. 
\end{remark}

%\subsection{Adversarial edge sequences of large girth}
\subsection{Locally \texorpdfstring{$\gamma$}{gamma}-sparse graphs} \label{ssec:gammaok}

In this section, we provide the characterization of a class of graphs for which our lazy-update approach always guarantees good amortized cost/approximation trade-offs, even under the assumption of adversarial edge insertion sequences.

% In this section, we analyze the performance of our lazy-update approach over a class of graphs that satisfy a property of ``local-sparsity''.
Given a graph $G(V,E)$ and a subset $V' \subseteq V$, we denote by $G[V']$ the subgraph induced by $V'$. 
Informally, a graph is \gammaok\ if every node in $\ball_2(u) \setminus \{u\}$ has roughly at most $\gamma$ neighbors in $\lset_1(u)$. This notion can be formalized as follows. 

%We will prove that, for constant values of $\gamma$, it is possible to obtain a $(1-\varepsilon)$-covering with amortized update  cost   $O(\frac{1}{\varepsilon})$.

 

\begin{definition}[\gammaok\ graphs] \label{def:gammaok}
 Let  $\gamma \in 
 \{ 0,1\ldots , n-1\}$. A graph $G(V,E)$ is said \gammaok\ if for each vertex $u \in V$:
    (i) $\forall v \in \lset_1(u)$ the degree of $v$ in $G[\lset_1(u)]$ is at most $\gamma$, and (ii) $\forall w \in \lset_2(u)$ the degree of $w$ in $G[\lset_1(v) \cup \{ w \}]$ is at most $\gamma+1$.
\end{definition}

%In the following, we make an abuse of notation and say that a dynamic graph $G$ is \gammaok if any $G^{(t)}$ is at most \gammaok, for any $t$.

Observe that the class of \gammaok\ graphs grows monotonically with $\gamma$, including all possible graphs for $\gamma=n-1$, while the most restricted class is obtained for $\gamma=0$. It is interesting to note that \gammaok\ graphs are not necessarily sparse in absolute terms. For example, for $\gamma=0$, the class coincides with the well-known class of graphs with \emph{girth} at least $5$: these graphs can have up to $\Theta(n^{\frac{3}{2}})$ edges assuming Erd{\"o}s' Girth Conjecture \cite{erdos1965some} (the proof of such equivalence is given in \Cref{apx:gamma-ok-deterministic}).

A first, preliminary analysis of our lazy-update approach considers the deterministic version of \Cref{alg:det_thresh}, i.e., when $k = 0$. It turns out that this version achieves an approximation ratio of  $\frac{\gamma + 1}{1-\varepsilon}$ and amortized cost $O(1/\varepsilon)$ (see \Cref{apx:gamma-ok-deterministic}). So, the approximation accuracy decreases linearly in the parameter $\gamma$. 
Interestingly enough, we instead show that a suitable number of random light updates allows \Cref{alg:det_thresh} to perform much better than its deterministic version. This is the main result of this section and it is formalized in the next 

\begin{theorem}\label{thm:gamma-ok-main}
Let $\varepsilon \in (0,1)$, and let $G^{(0)}$ be an initial graph. Consider any sequence of edge insertions that yields a final graph $G$. If $G$ is \gammaok\, \lazyscheme$\left(\varphi =1,nk=\frac{4(\gamma+1)}{\varepsilon}\right)$ has approximation ratio of $\frac{1}{1-\varepsilon}$ and amortized cost $O\left(\frac{\gamma+1}{\varepsilon}\right)$.     
\end{theorem}

%We in fact prove that, by setting $k = \frac{4(\gamma + 1)}{\varepsilon}$ and $\varphi = 1$, \lazyscheme\ achieves an approximation ratio of $\frac{1}{1-\varepsilon}$ and amortized update cost of $O(\frac{\gamma+1}{\varepsilon})$ for \gammaok graphs. 

\subsubsection*{Proof of \Cref{thm:gamma-ok-main}}
% For the remainder of this proof, we define the notion of \emph{quasi-black} edge. Informally, a red edge $(v,w)$, with $v \in \lset_1(u)$ and $w \in \lset_2(u)$, is \textit{quasi-black} for $u$ if $u$ is selected in Line 14 of \Cref{alg:det_thresh} for the subsequent insertion of an edge $(v,w')$, ensuring that $w \in \apxball_2(u)$. More formally: \rem{forse la def formale si pu√≤ togliere}

% \begin{definition}
% Let $u \in V$, and $v \in \lset_1(u)$. For $i=1,\dots,\rd_v$, let $e_i$ be the $i$-th red edge w.r.t. $v$ inserted in the graph. We say that $e_i$ is a \emph{quasi-black edge for $u$} if $u$ has been randomly selected at least once during the insertions of $e_i,\dots,e_{\rd_v}$ (\Cref{alg:det_thresh} lines 14-16). 
% \end{definition}

For the remainder of this proof, we define the notion of \emph{quasi-black} edge. A red edge $(v,w)$, with $v \in \lset_1(u)$ and $w \in \lset_2(u)$, is said to be \textit{quasi-black} for $u$ if $u$ has been randomly selected by $v$ at \Cref{line:random_selection} of \Cref{alg:det_thresh} \emph{at least once} during or after the insertion of $(v,w)$, ensuring that $w \in \apxball_2(u)$.

In this section, we use $\lrdr_v$ and $\lrd_v$ to denote the number of \emph{quasi-black} and \emph{red} edges, respectively, that connect $v$ to vertices in $\lset_2(u)$. Similarly, we use $\lbdd_v$ to represent the number of \emph{black} edges of $v$ having the other endpoint in $\lset_2(u)$. Notice that $\lrdr_v$ is a random variable that counts how many vertices out of $\lrd_v$ are in $\apxball_2(u)$. We now proceed by first stating a property whose proof can be found in Appendix~\ref{apx:proof_gamma_ok_expect_lowerbound}.

\begin{lemma}\label{le:gamma_ok_expect_lowerbound}
     For each $v \in \lset_1(u)$, we have $\Expec{}{\lrdr_v} \geq \lrd_v - \frac{2(\lbdd_v + \gamma + 1)}{k}$.
\end{lemma}

\iffalse
\begin{proof}
Let $e_1, \dots, e_{\ell_v}$ be the \emph{red edges} between $v$ and $\lset_2(u)$, and define the binary random variable $\lrdr_v(i)$ that is equal to $1$ if $e_i$ is a \emph{quasi-black edge} for $u$, $0$ otherwise, for $i = 1, \dots, \lrd_v$. Thus we can express $\lrdr_v = \sum_{i=1}^{\lrd_v} \lrdr_v(i)$, with expectation

\begin{equation}\label{eq:gamma_ok_lb_fact_eq_1}
\begin{aligned}
  \Expec{}{\lrdr_v} & = \sum_{i=1}^{\lrd_v}{\Prob{}{\lrdr_v(i)=1}} = \lrd_v - \sum_{i=1}^{\lrd_v} {\Prob{}{\lrdr_v(i)=0}}.
\end{aligned}
\end{equation}

Without loss of generality, assume that the edges $e_1, \dots, e_{\lrd_v}$ have been inserted at times $t_1 < \dots < t_{\lrd_v}$, respectively.
If $e_i$ is not a quasi-black edge for $u$, then it must be that $u$ is not selected by $v$ at \Cref{line:random_selection} of \Cref{alg:det_thresh}, at times $t_i, t_{i+1},\dots, t_{\lrd_v}$.
This holds with probability 
\begin{equation}\label{eq:gamma_ok_lb_fact_eq_2}
\begin{aligned} 
    &\Prob{}{\lrdr_v(i) = 0}
    \leq \prod_{j=i}^{\lrd_v} \left( 1-\frac{k}{\deg_v^{(t_j)}} \right)
    \leq \prod_{j=i}^{\lrd_v} \left( 1 - \frac{k}{\deg_{v}^{(t_{\lrd_v})}} \right) \\
    &\leq \left( 1-\frac{k}{\lbdd_v + \lrd_v + \gamma + 1}\right)^{\lrd_v - i + 1} 
    \leq \left(1-\frac{k}{2(\lbdd_v + \gamma + 1)}\right)^{\lrd_v - i}.
\end{aligned}
\end{equation}
The third inequality holds since the edges incident to $v$ having endpoints in $L_1(u)$ are at most $\gamma$, while those having endpoints in $L_2(u)$ are exactly $\lbdd_v+ \lrd_v$. Moreover, the last inequality holds because $\lrd_v \leq \rd_v \leq \bd_v \leq \lbdd_v + \gamma + 1$, given the assumption $\varphi = 1$.

By plugging in \eqref{eq:gamma_ok_lb_fact_eq_2} into \eqref{eq:gamma_ok_lb_fact_eq_1} and we obtain
\begin{align*}
    &\Expec{}{\lrdr_v} \geq \lrd_v - \sum_{i=1}^{\lrd_v}\left( 1-\frac{k}{2(\lbdd_v + \gamma + 1)}\right)^{\lrd_v - i} \\
    &= \lrd_v - \sum_{i=0}^{\lrd_v-1} \left(1-\frac{k}{2(\lbdd_v + \gamma + 1)}\right)^i 
    \leq \lrd_v - \frac{1-\left(1-\frac{k}{2(\lbdd_v+\gamma+1)}\right)^{\lrd_v}}{1-\left(1-\frac{k}{2(\lbdd_v + \gamma + 1)}\right)} \\
    &\geq \lrd_v - \frac{1}{1-\left(1-\frac{k}{2(\lbdd_v + \gamma + 1)}\right)}
    \geq \lrd_v - \frac{2(\lbdd_v + \gamma + 1)}{k}.
\end{align*}
\end{proof}
\fi
Now, let $\lbddt$ denote the number of vertices in $\lset_2(u)$ that have at least one black edge from $\lset_1(u)$. Consequently, these vertices are included in $\apxball_2(u)$. We have the following:

\begin{lemma}\label{lemma:gamma_ok_properties}
Let $G=(V,E)$ be \gammaok, and $u \in V$. Then
\begin{align*}
     \lbddt\geq \sum_{v \in \lset_1(u)} \frac{\lbdd_v}{\gamma + 1}.
\end{align*}
\end{lemma}
\begin{proof}
    The inequality  follows from the fact that every node in $\lset_2(u)$ can have at most $\gamma + 1$ neighbors in $\lset_1(u)$.  
\end{proof}
  
We are now ready to prove \Cref{thm:gamma-ok-main}. 

%%% BEGIN OF THE PROOF OF THE THEOREM %%%%%
%\begin{proof}

The amortized update cost follows directly from \Cref{lm:amortized_det_alg}.

For the approximation quality, let us consider any vertex $u \in V$. For technical convenience, we will define a subgraph $\widetilde{G}$ of $G$ by removing suitable edges from $G$, and we establish the following two properties: (i) if $k\ge \frac{2(\gamma+1)}{\varepsilon}$, the \lazyscheme\ guarantees a $(1-\varepsilon)$-covering of $\ball_2(u)$ when the sequence of edge insertion is restricted to edges in $\widetilde{G}$; (ii) property (i) implies that the \lazyscheme\ also guarantees a $(1-\varepsilon)$-covering of $\ball_2(u)$ for $G$, provided that $k \geq \frac{4(\gamma+1)}{\varepsilon}$.

% We start by defining $\widetilde{G}$ which is obtained from $G$ as follows.
% For each $w \in \lset_2(u)$, if there exists a vertex $v \in \lset_1(u)$ such that edge $(v,w)$ is black for $v$, then we remove all the red edges incident to $w$ that comes from $\lset_1(u)$. Otherwise, we have that all the edges coming from $\lset_1(u)$ are red. In this case we remove all such edges but one. See Figure-?? for an example.\rem{Dobbiamo fare una piccola figura esplicativa.}
The subgraph $\widetilde{G}$ is obtained from $G$ through the following process.
For each vertex $w \in \lset_2(u)$, if there exists a black edge $(v,w)$ with $v \in \lset_1(u)$, then we remove all the red edges incident to $w$ that originate from $\lset_1(u)$.
Otherwise, if all edges from $\lset_1(u)$ to $w$ are red, we retain only one and remove the rest (see \Cref{fig:pruned_graph}).

\begin{figure}[h]
    \centering
    \includegraphics[width=.8\linewidth]{img/pruned_graph.pdf}
    \caption{The $2$-hop neighborhood of a vertex $u$ (left), and its corresponding structure in the subgraph $\widetilde{G}$ (right).}
    \label{fig:pruned_graph}
\end{figure}

We now prove property (i). 
We analyze the process at a generic time $t>0$.
We want to prove that $\Expec{}{\vert \apxball_2(u) \vert} \ge (1-\varepsilon)\vert \ball_2(u) \vert$, for any vertex $u \in V$. 
% Since the set $\lset_1(u)$ is always contained in $\apxball_2(u)$, we focus on vertices belonging to $\lset_2(u)$.
Since $\lset_1(u)$ is always included in $\apxball_2(u)$, it is sufficient to prove that $\vert \apxball_2(u) \cap \lset_2(u) \vert \geq (1-\varepsilon) \vert \lset_2(u) \vert$ in expectation.

% Let $\lambda$ and $\hat{\lambda}$ be the number of vertices in $\lset_2(u)$ attached to $\lset_1(u)$ with a red and with a quasi-black edge, respectively.
By construction of $\widetilde{G}$, we have that $\vert \apxball_2(u) \cap \lset_2(u) \vert = \beta + \sum_{v \in \lset_1(v)} \lrdr_v$, while $\vert \lset_2(u) \vert = \beta + \sum_{v \in \lset_1(v)} \lrd_v$.
% Thus, we now want to show that $\lbddt+ \hat{\lambda} \geq (1-\varepsilon)(\lbddt+ \lambda)$ in expectation, i.e.
% \begin{align} \label{eq:errro_bound_2}
%     \hat{\lambda} \ge (1-\varepsilon)\lambda - \varepsilon \lbddt.
% \end{align}
Thus, we want to show that
\begin{align} \label{eq:errro_bound_2}
    \sum_{v \in \lset_1(v)} \lrdr_v \ge (1-\varepsilon)\sum_{v \in \lset_1(v)} \lrd_v - \varepsilon \beta.
\end{align}
%Then, by definition of $\lambda$ and $\hat{\lambda}$ and by \Cref{lemma:gamma_ok_properties}, we get that  \Cref{eq:errro_bound_2} in turn is implied by 
By \Cref{lemma:gamma_ok_properties}, \eqref{eq:errro_bound_2} is true when 
\begin{equation}
\begin{aligned} \label{eq:error_bound_3}
    \sum_{v \in \lset_1(u)}{\lrdr_v} &\ge (1-\varepsilon)\sum_{v \in \lset_1(u)}{\lrd_v} - \frac{\varepsilon}{\gamma + 1}\sum_{v \in \lset_1(u)}{\lbdd_v}\\
    &= \sum_{v \in \lset_1(u)}{\left((1-\varepsilon)\lrd_v - \frac{\varepsilon}{\gamma + 1}\lbdd_v \right)}.
\end{aligned}
\end{equation}
In turn, the inequality in \eqref{eq:error_bound_3} holds in expectation if it holds term-by-term, i.e., when
\begin{equation*}
    \Expec{}{\lrdr_v} \ge (1-\varepsilon)\lrd_v - \frac{\varepsilon}{1+\gamma}\lbdd_v, \;\; \forall v \in \lset_1(u).
\end{equation*}
Clearly, if $\lrd_v = 0$ then $\lrdr_v = 0$ and the inequality holds; thus we focus on the case $\lrd_v > 0$.
From \Cref{le:gamma_ok_expect_lowerbound} we know that $\Expec{}{\lrdr_v} \geq \lrd_v - \frac{2(\lbdd_v + \gamma + 1)}{k}$.
By setting $k \geq \frac{2(\gamma+1)}{\varepsilon}$ we have
\begin{align*}
    \lrd_v - \frac{2(\lbdd_v + \gamma + 1)}{k} \geq \lrd_v - \frac{\varepsilon}{\gamma + 1} \lbdd_v \geq (1-\varepsilon)\lrd_v - \frac{\varepsilon}{\gamma + 1} \lbdd_v,
\end{align*}
therefore proving property (i).

\iffalse
Therefore, we obtain
\begin{align*}
    &\lrd_v - \frac{2(\lbdd_v + \gamma + 1)}{k} \ge (1-\varepsilon)\lrd_v - \frac{\varepsilon}{1+\gamma}\lbdd_v\\
    &\iff \frac{2(\lbdd_v + \gamma + 1)}{k} \leq \varepsilon \lrd_v - \frac{\varepsilon}{1 + \gamma}\lbdd_v \\
    &\iff \frac{k}{2(\lbdd_v + \gamma + 1)} \geq \frac{1+\gamma}{(1+\gamma)\varepsilon \lrd_v + \varepsilon \lbdd_v} \\
    &\iff k \geq \frac{2(1+\gamma + \lbdd_v)(1 + \gamma)}{(1 + \gamma)\varepsilon \lrd_v +\varepsilon \lbdd_v}
\end{align*}
Lastly, observe that
\begin{align*}
    k \ge \frac{2(1+\gamma)}{\varepsilon} \implies k \ge \frac{2(1+\gamma + \lbdd_v)(1 + \gamma)}{(1 + \gamma)\varepsilon \lrd_v + \varepsilon \lbdd_v} =  \frac{2(1+\gamma)}{\varepsilon} \frac{1 + \gamma + \lbdd_v}{(1+\gamma)\lrd_v + \lbdd_v}.    
\end{align*}
Therefore, property (i) is proven.
\fi

% Finally, we prove (ii). Notice that we build $\widetilde{G}$ by removing \emph{only} red edges from $G$.
% On the one hand, this reduces (AUMENTA) the chance to select $u$ at Line 14 in \Cref{alg:det_thresh} as random neighbor of some vertex in $\lset_1(u)$. On the other hand, we reduce the degree of some vertex in $\lset_1(u)$. However, since $\varphi=1$, we have that the red degree of any vertex is at most its black degree. So, in $\widetilde{G}$ the degree of a vertex in $\lset_1(u)$ can at most be halved. In order to manage this we simply double the value of $k$, and the claim follows.
%\end{proof}

Finally, we prove (ii). Notice that we build $\widetilde{G}$ by removing \emph{only} red edges from $G$.
Since $\varphi = 1$, the degrees of the vertices $v \in \lset_1(u)$ in $\widetilde{G}$ are \emph{at most halved} compared to $G$. As a consequence, the probability that $v$ selects $u$ at \Cref{line:random_selection} of \Cref{alg:det_thresh} in $G$ is at most half of the probability we have in $\widetilde{G}$. Therefore, doubling the value of $k$ to $\frac{4(\gamma + 1)}{\varepsilon}$ ensures that the analysis we conducted on $\widetilde{G}$ also holds on $G$, guaranteeing a $(1-\varepsilon)$-covering of $\ball_2(u)$ in expectation on $G$ as well.






