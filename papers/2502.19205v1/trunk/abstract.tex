In this work, we propose, analyze and empirically validate a lazy-update approach to  maintain accurate approximations  of  the $2$-hop neighborhoods of dynamic graphs resulting from sequences of edge insertions. 

We first show that under random input sequences, our algorithm exhibits an optimal trade-off between accuracy and insertion cost: it only performs $O(\frac{1}{\varepsilon})$ (amortized) updates per edge insertion, while the estimated size of any vertex's $2$-hop neighborhood is at most a factor $\varepsilon$ away from its true value in most cases, \emph{regardless} of the underlying graph topology and for any $\varepsilon > 0$. 
%Our results can be extended  to other functions of $2$-hops neighbors, including union, %intersection and Jaccard similarity.

As a further theoretical contribution, we explore adversarial scenarios that can force our approach into a worst-case behavior at any given time $t$ of interest. 
We show that while worst-case input sequences do exist, a necessary condition for them to occur is that the \textit{girth} of the graph released up to time $t$ be at most $4$. 

Finally, we conduct extensive experiments on a collection of real, incremental social networks of different sizes, which typically have low girth. Empirical results are consistent with and typically better than our theoretical analysis anticipates. This further supports the robustness of our theoretical findings: forcing our algorithm into a worst-case behavior not only requires topologies characterized by a low girth, but also carefully crafted input sequences that are unlikely to occur in practice. 

Combined with standard sketching techniques, our lazy approach proves an effective and efficient tool to support key neighborhood queries on large, incremental graphs, including neighborhood size, Jaccard similarity between neighborhoods and, in general, functions of the union and/or intersection of $2$-hop neighborhoods.

\iffalse
We present a lazy-update algorithm that keeps an approximation  of  the $2$-hop neighborhoods of a dynamic graph which is given to the algorithm as a stream (sequence) of edge insertions. Combined with standard data sketches, this  approximation allows to efficiently manage fundamental graph mining queries such as size estimation and Jaccard similarity.

When the edge input sequence is a random permutation of an arbitrary graph $G(V,E)$, we prove that, for any desired $0 < \varepsilon < 1$, our algorithm only performs $\bigO(\frac{1}{\varepsilon})$ (amortized) updates per edge insertion, while at any time $t$ and for every vertex $v$, the estimated size of $v$'s $2$-hop neighborhood is, in expectation,  at most a factor $\varepsilon$ away from its true value. 
%We further prove that this  performance result holds with a probability that exponentially increases with the true size of the $2$-ball itself. 
Our results can be extended  to other functions of $2$-hops neighbors, including union, intersection and Jaccard similarity.

We then explore the adversarial scenario with  \textit{worst-case, adaptive sequences} that force our approach to behave poorly and, in this case, charcterize  whether any conditions on the graph topology are \textit{necessary} for this to happen. 
We first show that  worst-case sequences of edge insertions exist that force our algorithm to perform arbitrarily worse than the random setting.  However, as a further contribution, we also prove that worst-case input sequences exist \textit{only if} the \textit{girth}  of the final graph is at most $4$.
Our algorithm indeed achieves asymptotically optimal performance on \textit{any} edge sequence forming a  graph with girth at least $5$.

Finally, we provide experiments on a wide set of incremental graphs that confirm our theoretical analysis. In particular, we consider  samples of real social networks. As such, they have relatively large local and global clustering coefficients and thus low girth. Hence, our experimental analysis further supports the robustness of our theoretical findings: forcing our algorithm into a worst-case behavior not only requires topologies characterized by a low girth, but also carefully crafted input sequences that are unlikely to occur in practice.  
\fi