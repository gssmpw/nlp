@misc{zhang2021ganserselfsuperviseddataaugmentation,
      title={GANSER: A Self-supervised Data Augmentation Framework for EEG-based Emotion Recognition}, 
      author={Zhi Zhang and Sheng-hua Zhong and Yan Liu},
      year={2021},
      eprint={2109.03124},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2109.03124}, 
}

@article{Zhu2020,
 author = {Zhu, Renjie and Zhang, Xinpeng and Shi, Mengte and Tang, Zhenjun},
 title = {Secure Neural Network Watermarking Protocol Against Forging Attack},
 journal = {EURASIP Journal on Image and Video Processing},
 volume = {2020},
 number = {1},
 pages = {37},
 year = {2020},
 doi = {10.1186/s13640-020-00527-1},
 url = {https://doi.org/10.1186/s13640-020-00527-1}
}

@inproceedings{inproceedings,
author = {Zhang, Jialong and Gu, Zhongshu and Jang, Jiyong and Wu, Hui and Stoecklin, Marc and Huang, Heqing and Molloy, Ian},
year = {2018},
month = {05},
pages = {159-172},
title = {Protecting Intellectual Property of Deep Neural Networks with Watermarking},
doi = {10.1145/3196494.3196550}
}

@INPROCEEDINGS{8784727,
  author={Zhu, Junjie and Zhao, Xibin and Hu, Han and Gao, Yue},
  booktitle={2019 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Emotion Recognition from Physiological Signals using Multi-Hypergraph Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={610-615},
  keywords={Physiology;Emotion recognition;Neural networks;Correlation;Brain modeling;Convolution;Task analysis;Emotion Recognition;Physiological Signals;Multi-Modal Fusion;Multi-Hypergraph Neural Networks},
  doi={10.1109/ICME.2019.00111}}


@inproceedings{uchida2017embedding,
author = {Uchida, Yusuke and Nagai, Yuki and Sakazawa, Shigeyuki and Satoh, Shin'ichi},
title = {Embedding Watermarks into Deep Neural Networks},
year = {2017},
isbn = {9781450347013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078971.3078974},
doi = {10.1145/3078971.3078974},
abstract = {Significant progress has been made with deep neural networks recently. Sharing trained models of deep neural networks has been a very important in the rapid progress of research and development of these systems. At the same time, it is necessary to protect the rights to shared trained models. To this end, we propose to use digital watermarking technology to protect intellectual property and detect intellectual property infringement in the use of trained models. First, we formulate a new problem: embedding watermarks into deep neural networks. Second, we propose a general framework for embedding a watermark in model parameters, using a parameter regularizer. Our approach does not impair the performance of networks into which a watermark is placed because the watermark is embedded while training the host network. Finally, we perform comprehensive experiments to reveal the potential of watermarking deep neural networks as the basis of this new research effort. We show that our framework can embed a watermark during the training of a deep neural network from scratch, and during fine-tuning and distilling, without impairing its performance. The embedded watermark does not disappear even after fine-tuning or parameter pruning; the watermark remains complete even after 65\% of parameters are pruned.},
booktitle = {Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval},
pages = {269–277},
numpages = {9},
keywords = {deep neural networks, regularizer, watermarking},
location = {Bucharest, Romania},
series = {ICMR '17}
}

@inproceedings {adi2018turning,
author = {Yossi Adi and Carsten Baum and Moustapha Cisse and Benny Pinkas and Joseph Keshet},
title = {Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring},
booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
year = {2018},
isbn = {978-1-939133-04-5},
address = {Baltimore, MD},
pages = {1615--1631},
url = {https://www.usenix.org/conference/usenixsecurity18/presentation/adi},
publisher = {USENIX Association},
month = aug
}

@inproceedings{fan2019rethinking,
 author = {Fan, Lixin and Ng, Kam Woh and Chan, Chee Seng},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Rethinking Deep Neural Network Ownership Verification: Embedding Passports to Defeat Ambiguity Attacks},
 volume = {32},
 year = {2019}
}

@inproceedings{zhang2018protecting,
author = {Zhang, Jialong and Gu, Zhongshu and Jang, Jiyong and Wu, Hui and Stoecklin, Marc and Huang, Heqing and Molloy, Ian},
year = {2018},
month = {05},
pages = {159-172},
title = {Protecting Intellectual Property of Deep Neural Networks with Watermarking},
doi = {10.1145/3196494.3196550}
}

@inproceedings{wang2021riga,
author = {Wang, Tianhao and Kerschbaum, Florian},
title = {RIGA: Covert and Robust White-Box Watermarking of Deep Neural Networks},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450000},
doi = {10.1145/3442381.3450000},
abstract = {Watermarking of deep neural networks (DNN) can enable their tracing once released by a data owner to an online platform. In this paper, we generalize white-box watermarking algorithms for DNNs, where the data owner needs white-box access to the model to extract the watermark. White-box watermarking algorithms have the advantage that they do not impact the accuracy of the watermarked model. We propose Robust whIte-box GAn watermarking (RIGA), a novel white-box watermarking algorithm that uses adversarial training. Our extensive experiments demonstrate that the proposed watermarking algorithm not only does not impact accuracy, but also significantly improves the covertness and robustness over the current state-of-art.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {993–1004},
numpages = {12},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{guan2020are,
 author = {Guan, Jiyang and Liang, Jian and He, Ran},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {36571--36584},
 publisher = {Curran Associates, Inc.},
 title = {Are You Stealing My Model? Sample Correlation for Fingerprinting Deep Neural Networks},
 volume = {35},
 year = {2022}
}

@unknown{li2022persistent,
author = {Li, Huiying and Willson, Emily and Zheng, Haitao and Zhao, Ben},
year = {2019},
month = {10},
pages = {},
title = {Persistent and Unforgeable Watermarks for Deep Neural Networks},
doi = {10.48550/arXiv.1910.01226}
}

@inproceedings{lou2022reversible,
author = {Guan, Xiquan and Feng, Huamin and Zhang, Weiming and Zhou, Hang and Zhang, Jie and Yu, Nenghai},
year = {2020},
month = {10},
pages = {2273-2280},
title = {Reversible Watermarking in Deep Convolutional Neural Networks for Integrity Authentication},
doi = {10.1145/3394171.3413729}
}

@article{zhang2021robustness,
author = {Singh, Himanshu Kumar and Singh, Amit},
year = {2022},
month = {11},
pages = {1-23},
title = {Comprehensive review of watermarking techniques in deep-learning environments},
volume = {32},
doi = {10.1117/1.JEI.32.3.031804}
}

@article{kuribayashi2021survey,
author = {Li, Yue and Wang, Hongxia and Barni, Mauro},
year = {2021},
month = {07},
pages = {},
title = {A survey of Deep Neural Network watermarking techniques},
volume = {461},
journal = {Neurocomputing},
doi = {10.1016/j.neucom.2021.07.051}
}

@misc{fan2021ownership,
      title={FedIPR: Ownership Verification for Federated Deep Neural Network Models}, 
      author={Bowen Li and Lixin Fan and Hanlin Gu and Jie Li and Qiang Yang},
      year={2022},
      eprint={2109.13236},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2109.13236}, 
}

@inproceedings{xu2023protecting,
author = {Xu, Tianhua and Zhong, Sheng-hua and Xiao, Zhijiao},
year = {2023},
month = {07},
pages = {37-42},
title = {Protecting Intellectual Property of EEG-based Model with Watermarking},
doi = {10.1109/ICME55011.2023.00015}
}

@article{koelstra2011deap,
author = {Koelstra, Sander and Mühl, Christian and Soleymani, Mohammad and Lee, Jong-Seok and Yazdani, Ashkan and Ebrahimi, Touradj and Pun, Thierry and Nijholt, Anton and Patras, Ioannis},
year = {2011},
month = {12},
pages = {18-31},
title = {DEAP: A Database for Emotion Analysis Using Physiological Signals},
volume = {3},
journal = {IEEE Transactions on Affective Computing},
doi = {10.1109/T-AFFC.2011.15}
}

@inproceedings{yang2018ccnn,
author = {Yang, Yilong and Wu, Qingfeng and Fu, Yazhen},
year = {2018},
month = {10},
pages = {},
title = {Continuous Convolutional Neural Network with 3D Input for EEG-Based Emotion Recognition}
}

@article{ding2023tsception,
   title={TSception: Capturing Temporal Dynamics and Spatial Asymmetry From EEG for Emotion Recognition},
   volume={14},
   ISSN={2371-9850},
   url={http://dx.doi.org/10.1109/TAFFC.2022.3169001},
   DOI={10.1109/taffc.2022.3169001},
   number={3},
   journal={IEEE Transactions on Affective Computing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Ding, Yi and Robinson, Neethu and Zhang, Su and Zeng, Qiuhao and Guan, Cuntai},
   year={2023},
   month=jul, pages={2238–2250}
}

@article{lawhern2018eegnet,
   title={EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces},
   volume={15},
   ISSN={1741-2552},
   url={http://dx.doi.org/10.1088/1741-2552/aace8c},
   DOI={10.1088/1741-2552/aace8c},
   number={5},
   journal={Journal of Neural Engineering},
   publisher={IOP Publishing},
   author={Lawhern, Vernon J and Solon, Amelia J and Waytowich, Nicholas R and Gordon, Stephen M and Hung, Chou P and Lance, Brent J},
   year={2018},
   month=jul, pages={056013}
}

@misc{peng2022fingerprinting,
      title={Fingerprinting Deep Neural Networks Globally via Universal Adversarial Perturbations}, 
      author={Zirui Peng and Shaofeng Li and Guoxing Chen and Cheng Zhang and Haojin Zhu and Minhui Xue},
      year={2022},
      eprint={2202.08602},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2202.08602}, 
}

@misc{rouhani2018deepsigns,
      title={DeepSigns: A Generic Watermarking Framework for IP Protection of Deep Learning Models}, 
      author={Bita Darvish Rouhani and Huili Chen and Farinaz Koushanfar},
      year={2018},
      eprint={1804.00750},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1804.00750}, 
}

@inproceedings{rouhani2019deepmarks,
author = {Chen, Huili and Rouhani, Bita Darvish and Fu, Cheng and Zhao, Jishen and Koushanfar, Farinaz},
title = {DeepMarks: A Secure Fingerprinting Framework for Digital Rights Management of Deep Learning Models},
year = {2019},
isbn = {9781450367653},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3323873.3325042},
doi = {10.1145/3323873.3325042},
abstract = {Deep Neural Networks (DNNs) are revolutionizing various critical fields by providing an unprecedented leap in terms of accuracy and functionality. Due to the costly training procedure, high-performance DNNs are typically considered as the Intellectual Property (IP) of the model builder and need to be protected. While DNNs are increasingly commercialized, the pre-trained models might be illegally copied or redistributed after they are delivered to malicious users. In this paper, we introduce DeepMarks, the first end-to-end collusion-secure fingerprinting framework that enables the owner to retrieve model authorship information and identification of unique users in the context of deep learning (DL). DeepMarks consists of two main modules: (i) Designing unique fingerprints using anti-collusion codebooks for individual users; and (ii) Encoding each constructed fingerprint (FP) in the probability density function (pdf) of the weights by incorporating an FP-specific regularization loss during DNN re-training. We investigate the performance of DeepMarks on various datasets and DNN architectures. Experimental results show that the embedded FP preserves the accuracy of the host DNN and is robust against different model modifications that might be conducted by the malicious user. Furthermore, our framework is scalable and yields perfect detection rates and no false alarms when identifying the participants of FP collusion attacks under theoretical guarantee. The runtime overhead of retrieving the embedded FP from the marked DNN can be as low as 0.056\%.},
booktitle = {Proceedings of the 2019 on International Conference on Multimedia Retrieval},
pages = {105–113},
numpages = {9},
keywords = {deep neural networks, digital fingerprinting, digital right management, intellectual property protection},
location = {Ottawa ON, Canada},
series = {ICMR '19}
}

@misc{chen2018deepmarks,
      title={DeepMarks: A Digital Fingerprinting Framework for Deep Neural Networks}, 
      author={Huili Chen and Bita Darvish Rohani and Farinaz Koushanfar},
      year={2018},
      eprint={1804.03648},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1804.03648}, 
}

@article{lemerrer2019adversial,
   title={Adversarial frontier stitching for remote neural network watermarking},
   volume={32},
   ISSN={1433-3058},
   url={http://dx.doi.org/10.1007/s00521-019-04434-z},
   DOI={10.1007/s00521-019-04434-z},
   number={13},
   journal={Neural Computing and Applications},
   publisher={Springer Science and Business Media LLC},
   author={Le Merrer, Erwan and Pérez, Patrick and Trédan, Gilles},
   year={2019},
   month=aug, pages={9233–9244} }


@InProceedings{liu2021greedy,
  title = 	 {Watermarking Deep Neural Networks with Greedy Residuals},
  author =       {Liu, Hanwen and Weng, Zhenyu and Zhu, Yuesheng},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {6978--6988},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/liu21x/liu21x.pdf},
  url = 	 {https://proceedings.mlr.press/v139/liu21x.html},
  abstract = 	 {Deep neural networks (DNNs) are considered as intellectual property of their corresponding owners and thus are in urgent need of ownership protection, due to the massive amount of time and resources invested in designing, tuning and training them. In this paper, we propose a novel watermark-based ownership protection method by using the residuals of important parameters. Different from other watermark-based ownership protection methods that rely on some specific neural network architectures and during verification require external data source, namely ownership indicators, our method does not explicitly use ownership indicators for verification to defeat various attacks against DNN watermarks. Specifically, we greedily select a few and important model parameters for embedding so that the impairment caused by the changed parameters can be reduced and the robustness against different attacks can be improved as the selected parameters can well preserve the model information. Also, without the external data sources for verification, the adversary can hardly cast doubts on ownership verification by forging counterfeit watermarks. The extensive experiments show that our method outperforms previous state-of-the-art methods in five tasks.}
}

@misc{sun2023deepintellectualpropertyprotection,
      title={Deep Intellectual Property Protection: A Survey}, 
      author={Yuchen Sun and Tianpeng Liu and Panhe Hu and Qing Liao and Shaojing Fu and Nenghai Yu and Deke Guo and Yongxiang Liu and Li Liu},
      year={2023},
      eprint={2304.14613},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2304.14613}, 
}

@article{korus2022computational,
author = {Korus, Pawel and Memon, Nasir},
year = {2022},
month = {01},
pages = {1-1},
title = {Computational Sensor Fingerprints},
volume = {17},
journal = {IEEE Transactions on Information Forensics and Security},
doi = {10.1109/TIFS.2022.3179945}
}