 % This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[dvipsnames]{xcolor}
\usepackage{tcolorbox}
\usepackage{authblk}
\usepackage{BCISURVEY}
\usepackage{hyperref}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{placeins}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{array} % required for text wrapping in tables


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{4.2cm}
%
% and set <dim> to something 5cm or larger.

\usepackage{graphicx}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}

\usepackage[labelfont=bf]{caption}
\captionsetup{labelfont=bf}

\usepackage{adjustbox}

\usepackage{natbib}

\usepackage{tikz}
\usetikzlibrary{positioning, shapes, arrows}
\usepackage{colortbl} % Required for setting table line colors
\usepackage{xcolor} % For color definitions
\definecolor{lightgray}{gray}{0.7}

\title{A Survey on Bridging EEG Signals and Generative AI: From Image and
Text to Beyond}


% For several authors from the same institution:
\author{ \textbf{\ Shreya Shukla,\ Jose Torres, \ Abhijit Mishra,\ Jacek Gwizdka,\ Shounak Roychowdhury} \\
        School of Information, University of Texas at Austin\\
        \{shreya.shukla, jtorres1221, abhijitmishra, jacekg, shounak.roychowdhury\}@utexas.edu}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\



\begin{document}
\maketitle

%\def\thefootnote{*}\footnotetext{These authors contributed equally to this work}\def\thefootnote{\arabic{footnote}}

\begin{abstract}

Integration of Brain-Computer Interfaces (BCIs) and Generative Artificial Intelligence (GenAI) has opened new frontiers in brain signal decoding, enabling assistive communication, neural representation learning, and multimodal integration. BCIs, particularly those leveraging Electroencephalography (EEG), provide a non-invasive means of translating neural activity into meaningful outputs. Recent advances in deep learning, including Generative Adversarial Networks (GANs) and Transformer-based Large Language Models (LLMs), have significantly improved EEG-based generation of images, text, and speech. This paper provides a literature review of the state-of-the-art in EEG-based multimodal generation, focusing on (i) EEG-to-image generation through GANs, Variational Autoencoders (VAEs), and Diffusion Models, and (ii) EEG-to-text generation leveraging Transformer based language models and contrastive learning methods.  Additionally, we discuss the emerging domain of \emph{EEG-to-speech synthesis}, an evolving multimodal frontier. We highlight key datasets, use cases, challenges, and EEG feature encoding methods that underpin generative approaches. By providing a structured overview of EEG-based generative AI, this survey aims to equip researchers and practitioners with insights to advance neural decoding, enhance assistive technologies, and expand the frontiers of brain-computer interaction.

\end{abstract}

\input{1_introduction}
\input{2_relatedwork}
\input{4_bci_cv}
\input{5_bci_nlp}
\input{6_bci_beyond}
\input{7_conclusion}

\section*{Limitations}
\label{sec:limitations}

While this survey provides a comprehensive overview of EEG-based generative AI applications, certain limitations exist due to the focused scope of this work. Firstly, this survey primarily covers EEG-based Brain-Computer Interfaces (BCIs), deliberately excluding other neuroimaging techniques such as fMRI, Magnetoencephalography (MEG), and Near-Infrared Spectroscopy (NIRS). Although these modalities play a significant role in BCI research and offer complementary advantages in terms of spatial resolution and multimodal integration, their detailed discussion is beyond the scope of this work.

Secondly, due to space constraints, in-depth discussions on the cognitive underpinnings of EEG signals -- such as their biological origins, neural interpretations, and relationships with brain activity—have been omitted. Similarly, technical details regarding EEG hardware, electrode configurations, and device specifications have been largely excluded for brevity. While these aspects are crucial for practical EEG-based applications, our focus remains on the computational and generative modeling aspects of EEG data processing.

Finally, this survey assumes a general background in EEG signal processing, and generative modeling and expects familiarity with these foundational concepts. While we provide essential explanations, a more in-depth introduction to the fundamentals of EEG and BCI technology is outside the scope of this review. 
%Future work could expand upon these missing aspects to provide a more holistic perspective on the intersection of neuroscience and generative AI.
\section*{Ethics Statement}
EEG data is inherently sensitive, as it contains neural activity patterns that can potentially reveal cognitive states and sometimes personal information. While the majority of the works covered in this survey adhere to established ethical guidelines and standards, some studies may require additional ethical justifications. We have not conducted an exhaustive review of the ethical compliance of each cited work but emphasize the importance of ethical transparency in EEG research. We do not endorse studies that raise ethical concerns or lack proper ethical oversight. Any research involving EEG data collection and analysis should rigorously follow ethical protocols, including obtaining informed consent, ensuring data anonymity, and minimizing risks to participants.

Additionally, we acknowledge the use of OpenAI’s ChatGPT-4 system solely for enhancing writing efficiency, generating LaTeX code, and aiding in error debugging. No content related to the survey's research findings, citations, or factual discussions was autogenerated or retrieved using Generative AI-based search mechanisms. Our work remains grounded in peer-reviewed literature and ethical academic standards.


% \section*{Acknowledgements}

% Entries for the entire Anthology, followed by custom entries
\bibliography{bcisurvey}
\bibliographystyle{acl_natbib}
% \bibliographystyle{unsrtnat}

\end{document}
