\section{EEG-to-Text Generation}

This section discusses how AI learns brain signal representations from EEG data and maps them to linguistic representations, with an overview depicted in Figure \ref{fig:EEG-text}. We survey use cases, techniques, concerns, and EEG feature encoding methods for text generation.

\begin{figure}[t]
     \centering
    {\includegraphics[width=0.45\textwidth]{images/EEG-text.png}}
   \caption{Reconstructing text from EEG, with eye-tracking data used to capture word-level EEG signals}
	\label{fig:EEG-text}
\end{figure}

\subsection{Use Cases and Addressed Concerns}

The studies referenced in this section share a common use case: generating text from EEG signals. Several studies \cite{biswal2019eegtotext,srivastava2020think2type,yang2023thoughts,rathod2024folded} use the closed vocabulary approach, relying on a fixed set of pre-defined words for EEG-based decoding. Among these, \citet{srivastava2020think2type,yang2023thoughts} investigate text generation using morse code representation of EEG signals, where users' active intent is captured, mapped to morse codes, and then translated to text format.

Recent studies \cite{wang2022open,feng2023aligning,duan2023dewave,liu2024eeg2text,wang2024enhancing,amrani2024deep,tao2024see,mishra2024thought2text,ikegawa2024text,chen2025decoding} overcome closed-vocabulary limitations by exploring open-vocabulary text generation to emulate naturalistic conversations. These studies also address the impact of subjectivity in subject-dependent EEG representation \cite{feng2023aligning,amrani2024deep}, learn cross-modal representation \cite{wang2024enhancing,tao2024see}, and capture long-term dependencies in text and also global contextual information from EEG data that transformers might miss \cite{rathod2024folded,chen2025decoding}.

A significant challenge is the reliance on eye-tracking fixation data as a marker for word-level EEG, which studies like \cite{duan2023dewave,liu2024eeg2text} aim to address. To overcome challenges like defining word-level boundaries in EEG signals and other language processing tasks, some studies have proposed language-agnostic solutions \cite{mishra2024thought2text, ikegawa2024text} which capture signals through image modality and leverage advancements in image-text intermodality to generate text from the collected data. Additionally, \citet{yu2025decoding} introduce a VAE-based augmentation technique to address the issue of limited EEG-text datasets.  

\subsection{Techniques Used Across Studies}

A noteworthy aspect of these studies is the utilization of \textbf{Large Language Models (LLMs)}, particularly BART. Several works \cite{wang2022open, liu2024eeg2text, wang2024enhancing, amrani2024deep, tao2024see, chen2025decoding} have used BART for text generation. In a study by \citet{mishra2024thought2text}, LLMs were fine-tuned on EEG embeddings, image and text data in the training stage to generate text from just EEG signals during inference.

\textbf{Contrastive learning} is widely used in studies like \cite{feng2023aligning, tao2024see, wang2024enhancing} to identify positive EEG-text pairs (e.g., EEG data from the same sentence across subjects) and negative pairs (e.g., EEG data from different sentences or subjects), improving the model's ability to align EEG signals with corresponding text representations. Another key technique is masked signal modeling, employed by \citet{liu2024eeg2text}, where a transformer model is pre-trained to reconstruct randomly masked EEG signals from raw data, enabling the model to learn context, relationships, and semantics within sentence-level EEG signals. An integrated approach by \citet{tao2024see} combines contrastive learning with \textbf{masked signal modeling}, where word-level EEG feature sequences are randomly masked and sentence-level sequences deliberately masked, guided by an intra-modality self-reconstruction objective.

In addition to these techniques, bi-directional Gated Recurrent Units (GRUs) are used to dynamically handle the varying lengths of word-level raw EEG signals \cite{amrani2024deep}. Hierarchical GRUs further improve EEG data processing by capturing both long-range dependencies and local contextual information through the organization of hidden layers hierarchically \cite{chen2025decoding}. A unique approach by \cite{rathod2024folded} employs a folded ensemble deep CNN for text suggestion and a folded ensemble Bidirectional LSTM for text generation, effectively addressing class imbalance and significantly enhancing the accuracy of text generation in closed-vocabulary tasks.

\subsection{EEG Feature Encoding Techniques}

For text generation tasks, EEG signals are encoded into features to capture \textbf{temporal patterns and semantic information}. In the study by \citet{biswal2019eegtotext}, which focuses on generating medical reports, EEG signals are encoded using stacked CNNs to capture \textbf{shift-invariant features} and RCNNs to capture \textbf{temporal patterns}. These features are then used to generate key phenotypes, which hierarchical LSTMs utilize to produce detailed explanations. \citet{srivastava2020think2type} employs an ensemble model to extract EEG embeddings, using CNNs to capture spatial variations and LSTMs to model temporal sequences and long-range dependencies. Another study by \citet{yu2025decoding}, proposes two objectives: classification and sequence-to-sequence (seq2seq) text generation, employing residual blocks for feature extraction in both tasks to capture both \textbf{spatial and temporal features} of the EEG signals effectively. 

Other studies explore the extraction of \textbf{spectral and statistical features} alongside temporal or spatial patterns. \citet{yang2023thoughts}, aiming to translate active intention into text using Morse code, employed Short-Term Fourier Transform (STFT) to extract spectral features and concatenated these with statistical features (e.g., min, max etc. for each channel), in addition to using 1D CNN for spatial features and RNN for temporal features. \citet{rathod2024folded}, another closed-vocabulary solution, used features such as Wavelet Transform (WT), Common Spatial Patterns (CSP), and \textbf{statistical features} to generate EEG feature vectors for classification. 

Various studies have used state-of-the-art transformer architecture for encoding EEG features. \cite{wang2022open} uses a multi-layer transformer encoder to obtain \textbf{EEG mapping from word-level EEG sequences}. \citet{feng2023aligning} uses a transformer-based pre-encoder to convert word-level EEG features into the Seq2Seq embedding space. Another study by \citet{tao2024see} also uses an encoder to extract EEG embeddings and store them in a cross-modal codebook alongside word embeddings obtained from a transformer-based BART model. 

Obtaining word-level EEG signals typically requires markers, often from eye-fixation data like in the Zuco dataset, limiting generalizability. Some studies address this by using \textbf{marker-free and sentence-level EEG signals}. \citet{duan2023dewave} extracts both word-level EEG and raw EEG embeddings. For word-level EEG features with markers, a multi-head transformer layer projects embeddings into feature sequences. For raw EEG waves, a multi-layer transformer encoder is trained for self-reconstruction of waveforms and the transformation of raw EEG signals into sequences of embeddings. In a study by \citet{liu2024eeg2text}, a convolutional transformer model is pretrained with sentence-level EEG signals using a masking technique. It uses a multi-view transformer to encode different brain regions with separate convolutional transformers. \citet{wang2024enhancing} uses both word-level and sentence-level EEG features. It employs a masking technique where word-level sequences are randomly masked and sentence-level features are compulsorily masked.

\citet{chen2025decoding} uses a stacked Hierarchical GRU-based decoder along with Masked Residual Attention Mechanism to obtain EEG representations that capture both \textbf{local and global contextual information}. \citet{amrani2024deep} employs a module consisting of bi-directional GRUs to dynamically address varying lengths of word-level raw EEG signals, a subject-specific 1D convolutional layer, and a multi-layer transformer encoder to encode word-level EEG signals.

\subsection{Evaluation Metrics}
In the surveyed studies, generated text is evaluated against reference text using various established metrics. The commonly used text evaluation metrics are as follows: \textit{METEOR} \cite{banerjee2005meteor}, employed by \cite{biswal2019eegtotext, chen2025decoding}; \textit{BLEU} score \cite{papineni2002bleu}, utilized by \cite{biswal2019eegtotext, wang2022open, feng2023aligning}; \textit{ROUGE} score \cite{lin2004rouge}, adopted by \cite{wang2022open, feng2023aligning, duan2023dewave, liu2024eeg2text, wang2024enhancing}; and \textit{BERTScore} \cite{zhang2019bertscore}, used by \cite{amrani2024deep, mishra2024thought2text}. Other metrics include \textit{Word Error Rate (WER)} used by \cite{feng2023aligning}, \textit{Translation Error Rate (TER)}, and \textit{BLEURT} \cite{sellam2020bleurt}, used by \cite{chen2025decoding}.


