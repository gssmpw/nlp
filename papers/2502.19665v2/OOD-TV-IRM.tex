
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%\usepackage{hyperref}这个错误来自 hyperref 包，它不能在生成PDF的超链接或书签时处理数学模式或特殊字符。LaTeX中的数学模式（例如 $\rho$）在某些上下文（如 \section{}、 \caption{} 或者 \href{}）中会导致这个问题。
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{multirow}

\usepackage{titlesec}
\titleformat{\section}{\large\scshape}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\scshape}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalsize\scshape}{\thesubsubsection}{1em}{}

\usepackage{url}
\usepackage{listings}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{mathrsfs}

%\usepackage{hyperref}[bookmarks=false]    % 禁止用书签
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

\usepackage[capitalize,noabbrev]{cleveref}

\usepackage{wrapfig}

\theoremstyle{plain}
%\newtheorem{theorem}{Theorem}[section]
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}




\title{Out-of-distribution Generalization for Total\\ Variation based Invariant Risk Minimization}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Yuanchao Wang\textsuperscript{\rm 1,\rm 2}, Zhao-Rong Lai\textsuperscript{\rm 1}\thanks{Corresponding author.}\ \ , Tianqi Zhong\textsuperscript{\rm 3} \\
	\textsuperscript{\rm 1}College of Cyber Security, Jinan University\\
	\textsuperscript{\rm 2}Pratt School of Engineering, Duke University\\
	\textsuperscript{\rm 3}Sino-French Engineer School, Beihang University\\
	\texttt{yuanchao.wang@duke.edu, laizhr@jnu.edu.cn, zhongtianqi@buaa.edu.cn} 
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}

\def \bbE {\mathbb E}
\def \bbI {\mathbb I}
\def \bbR {\mathbb R}
\def \bbN {\mathbb N}
\def \bbV {\mathbb V}
\def \bbZ {\mathbb Z}

\def \mA {\mathcal{A}}
\def \mB {\mathcal{B}}
\def \mD {\mathcal{D}}
\def \mE {\mathcal{E}}
\def \mF {\mathcal{F}}
\def \mG {\mathcal{G}}
\def \mI {\mathcal{I}}
\def \mH {\mathcal{H}}
\def \mL {\mathcal{L}}
\def \mM {\mathcal{M}}
\def \mN {\mathcal{N}}
\def \mO {\mathcal{O}}
\def \mP {\mathcal{P}}
\def \mQ {\mathcal{Q}}
\def \mR {\mathcal{R}}
\def \mS {\mathcal{S}}
\def \mT {\mathcal{T}}
\def \mU {\mathcal{U}}
\def \mX {\mathcal{X}}
\def \mY {\mathcal{Y}}
\def \mZ {\mathcal{Z}}

\def \ff {\mathfrak{f}}

\def \sF {\mathscr{F}}
\def \sL {\mathscr{L}}
\def \sS {\mathscr{S}}

\def \ba {\bm{a}}
\def \bb {\bm{b}}
\def \bc {\bm{c}}
\def \bd {\bm{d}}
\def \bh {\bm{h}}
\def \bp {\bm{p}}
\def \bq {\bm{q}}
\def \bx {\bm{x}}
\def \by {\bm{y}}
\def \bz {\bm{z}}
\def \bw {\bm{w}}
\def \bu {\bm{u}}
\def \bv {\bm{v}}
\def \br {\bm{r}}
\def \bs {\bm{s}}
\def \bR {\bm{R}}
\def \bS {\bm{S}}
\def \bI {\bm{I}}
\def \bA {\bm{A}}
\def \bB {\bm{B}}
\def \bC {\bm{C}}
\def \bD {\bm{D}}
\def \bE {\bm{E}}
\def \bF {\bm{F}}
\def \bG {\bm{G}}
\def \bH {\bm{H}}
\def \bP {\bm{P}}
\def \bQ {\bm{Q}}
\def \bR {\bm{R}}
\def \bU {\bm{U}}
\def \bV {\bm{V}}
\def \bW {\bm{W}}
\def \bX {\bm{X}}
\def \bY {\bm{Y}}

\def \bone {\mathbf{1}}

\def \blambda {\bm{\lambda}}

\def \fp {\mathfrak{p}}
\def \frs {\mathfrak{s}}

\def \fE {\mathfrak{E}}

\def \bbRd {\bbR^{d}}
\def \bbRn {\bbR^{n}}
\def \bbRm {\bbR^{m}}
\def \bbRdmY {\bbR^{d_{\mY}}}
\def \bbRdmH {\bbR^{d_{\mH}}}
\def \bbRE {\bbR^{E}}
\def \bbRN {\bbR^{N}}
\def \bbRM {\bbR^{M}}
\def \bbRT {\bbR^{T}}
\def \bbNM {\bbN_M}
\def \bbNk {\bbN_k}
\def \bbNn {\bbN_n}
\def \bbNm {\bbN_m}

\def \tS {\tilde{S}}
\def \tbQ {\tilde{\bQ}}
\def \tbq {\widetilde{\bq}}
\def \tbI {\widetilde{\bI}}

\def \rB {\mathrm{B}}
\def \st {\text{s.\ t.}}
\def \and {\text{and}}
\def \tr {\mathrm{tr}}
\def \prox {\mathrm{prox}}
\def \env {\mathrm{env}}
\def \supp {\mathrm{supp}}
\def \sign {\mathrm{sign}}
\def \trun {\mathrm{trun}}
\def \dist {\mathrm{dist}}
\def \div {\mathrm{div}}
\def \diag {\mathrm{diag}}
\def \Fix {\mathrm{Fix}}
\def \VaR {\mathrm{VaR}}
\def \CVaR {\mathrm{CVaR}}
\def \gra {\mathrm{gra}\hspace{2pt}}
\def \dom {\mathrm{dom}\hspace{2pt}}
\def \crit {\mathrm{crit}\hspace{2pt}}


\def \Argmax {\mathop{\rm Arg\,max}}
\def \Argmin {\mathop{\rm Arg\,min}}

\def \argmax {\mathop{\rm arg\,max}}
\def \argmin {\mathop{\rm arg\,min}}

\def \leqs {\leqslant}
\def \geqs {\geqslant}

\newcommand{\ud}{\,\mathrm{d}}
\def \dmu {\ud\mu}
\def \dnu {\ud\nu}
\def \drho {\ud\rho}




\maketitle

\begin{abstract}
Invariant risk minimization is an important general machine learning framework that has recently been interpreted as a total variation model (IRM-TV). However, how to improve out-of-distribution (OOD) generalization in the IRM-TV setting remains unsolved. In this paper, we extend IRM-TV to a Lagrangian multiplier model named OOD-TV-IRM. We find that the autonomous TV penalty hyperparameter is exactly the Lagrangian multiplier. Thus OOD-TV-IRM is essentially a primal-dual optimization model, where the primal optimization minimizes the entire invariant risk and the dual optimization strengthens the TV penalty. The objective is to reach a semi-Nash equilibrium where the balance between the training loss and OOD generalization is maintained. We also develop a convergent primal-dual algorithm that facilitates an adversarial learning scheme. Experimental results show that OOD-TV-IRM outperforms IRM-TV in most situations. 
\end{abstract}

\section{Introduction}
Traditional risk minimization methods such as Empirical Risk Minimization (ERM) are widely used in machine learning. 
ERM generally assumes that both training and test data come from the same distribution. Based on this assumption, ERM learns model parameters by minimizing the average loss on the training data. However, the distributions between training and test data or even within the training or test data are often different in practical situations, which affects the model's performance in new environments. Besides, ERM tends to exploit correlations in the training data, even if these correlations do not hold in different environments. This may cause the model to learn some spurious features that are irrelevant to the target, so as to perform poorly in new environments. Because ERM only focuses on the average performance on a given data distribution, the model may overfit to specific training data and thus perform unstably when facing distribution changes or outliers. These problems lead to the poor generalization ability of ERM across different environments \citep{1,2,3}.

The key to solving the above problems is to distinguish between invariant features and spurious features that cause distribution shifts, so that a trained model can be generalized to an unseen domain. This leads to the concept of out-of-distribution (OOD) generalization \citep{4,OODcite1}. One important methodology is the Invariant Risk Minimization (IRM, \citealt{2}) criterion. It aims to extract invariant features across different environments to improve the generalization and robustness of the model \citep{OODcite2,OODcite3}. Specifically, it introduces a gradient norm penalty that measures the optimality of the virtual classifier in each environment. Then it minimizes the risk in all potential environments to ensure that the model can still work effectively when facing distribution drift. In summary, IRM copes with distribution changes by introducing environmental invariance constraints in order to make the trained model more robust in a wider range of application scenarios \citep{IRMG}. There are various variants and improvements of IRM, such as Heterogeneous Risk Minimization (HRM, \citealt{HRM}), Risk Extrapolation (REx, \citealt{5}), SparseIRM \citep{6}, jointly learning with auxiliary information (ZIN, \citealt{3}), and invariant feature learning through independent variables (TIVA, \citealt{7}). Diversifying spurious features \citep{spuriousfeat} can also be an effective approach to improve IRM. These approaches not only provide new IRM settings or new application scenarios, but also improve the robustness and extensibility of IRM. They contribute to the theoretical understanding of OOD generalization. 

A recent work reveals that the mathematical essence of IRM is a total variation (TV) model \citep{8}. TV measures the locally varying nature of a function, which is widely applied to different areas of mathematics and engineering, such as signal processing and image restoration. Its core idea is to eliminate noise by minimizing the TV of a function while preserving sharp discontinuities in the function (e.g., edges in an image \citep{dey2006richardson}). The interpretation of IRM as a TV model not only provides a unified mathematical framework, but also reveals why the IRM approach can work effectively across different environments. The original IRM actually contains a TV term based on the $\ell_2$ norm (TV-$\ell_2$). Compared with TV-$\ell_2$, TV-$\ell_1$ further has the coarea formula that provides a geometric nature of preserving sharp discontinuities. This property is well-suited for the invariant feature extraction of IRM. Hence an IRM-TV-$\ell_1$ framework is proposed and it shows better performance than the IRM-TV-$\ell_2$ framework. When considering the learning risk as part of the full-variance model, IRM-TV-$\ell_1$ performs better in OOD generalization. This finding helps to address distributional drift and improve model robustness in machine learning. 

However, IRM-TV-$\ell_1$ may not achieve complete OOD generalization, due to insufficient diversity in the training environments and the inflexible TV penalty. \citet{8} investigate some additional requirements for IRM-TV-$\ell_1$ to achieve OOD generalization. A key point is to let the penalty parameter vary according to the invariant feature extractor; however, the authors do not specify a tractable implementation. It leaves unsolved how to construct and optimize this framework for broader practical applications, resulting in an urgent need for effective solutions.

To fill this gap, we have found that the TV penalty hyperparameter can be used as a Lagrangian multiplier. We propose to extend the IRM-TV framework to a \textbf{Lagrangian multiplier framework}, named \textbf{OOD-TV-IRM}. It is essentially a primal-dual optimization framework. The primal optimization reduces the entire invariant risk, in order to learn invariant features, while the dual optimization strengthens the TV penalty, in order to provide an adversarial interference with spurious features. The objective is to reach a \textbf{semi-Nash equilibrium} where the balance between the training loss and OOD generalization is maintained. We also develop a \textbf{convergent primal-dual algorithm} that facilitates an \textbf{adversarial learning} scheme.  This work not only extends the theoretical foundation of previous work, but also provides a concrete implementation scheme to improve OOD generalization of machine learning methods across unknown environments.






\section{Preliminaries and Related Works}
\subsection{Invariant Risk Minimization}
In machine learning tasks, we often work with a data set consisting of multiple samples, where each sample includes input and output variables. These samples are typically drawn from various environments, but in many scenarios, the specific environment labels are not explicitly available. As a result, the challenge is to train a model that can generalize well across these different environments, even when the environment information is unknown.

IRM \citep{2} addresses this challenge by structuring the model into two components: a feature extractor and a classifier. The feature extractor is responsible for identifying invariant features from the input data, while the classifier makes predictions based on these features. IRM aims to minimize the invariant risk across different training environments, in order to find a representation that performs consistently well across all environments.

For a given training data set of $n$ samples $\mD:=\{(x_i,y_i)\in \mX\times \mY\}_{i=1}^n$, the empirical risk in a given environment $e$ is computed using a loss function $\mathcal{L}$, which measures the discrepancy between the predicted value and the true output. This risk is expressed as:
\begin{equation}\label{1}
R(w \circ \Phi, e) := \frac{1}{n} \sum_{i=1}^n \mathcal{L}(w \circ \Phi(x_i), y_i, e),
\end{equation}
which represents the mean loss over $n$ samples in environment $e$. IRM simultaneously learns an invariant feature extractor $\Phi$ and a classifier $w$ across multiple training environments, so that the risk is minimized in all environments:
\begin{equation}\label{2}
\min_{w, \Phi} \sum_{e \in \mathcal{E}_{\text{tr}}} R(w \circ \Phi, e),\quad \st \quad w \in \arg\min_{w'} R(w' \circ \Phi, e), \forall e \in \mathcal{E}_{\text{tr}},
\end{equation}
where the classifier $w$ should be the optimal solution for minimizing the risk in each environment $e$. However, it is a challenging bilevel optimization problem. Hence \citet{2} further propose a practical variant of IRM as follows:
\begin{equation}\label{4}
\min_{\Phi} \sum_{e \in \mathcal{E}_{\text{tr}}} \left\{ R(1 \circ \Phi, e) + \lambda \|\nabla_w |_{w=1} R(w \circ \Phi, e)\|_2^2 \right\}.
\end{equation}
In this version, the classifier $w$ is set to a scalar value of 1, and a gradient norm penalty term is introduced to convert the objective into a single-level optimization problem.

ZIN \citep{3} further extends the IRM framework by introducing auxiliary information $z_i \in \mathcal{Z}$ to simultaneously learn environment partitioning and invariant feature representation. It assumes that the space of training environments $\mathcal{E}_{\text{tr}}$ is the convex hull of $E$ linearly independent fundamental environments. By learning a mapping $\rho : \mathcal{Z} \to \Delta_E$ that provides weights for different environments, ZIN optimizes the following objective:
\begin{equation}\label{5}
\min_{w, \Phi} \left\{ R(w \circ \Phi, \frac{1}{E}1_{(E)}) \cdot 1_{(E)} + \lambda \max_{\rho} \|\nabla_w R(w \circ \Phi, \rho)\|_2^2 \right\}.
\end{equation}

By this means, ZIN can effectively learn invariant features even without explicit environment partition information.




\subsection{Total Variation}
TV is a mathematical operator widely recognized for its ability to measure the global variability of a function. It has been extensively applied in various fields such as optimal control, data transmission, and signal processing. The central concept behind TV is to quantify the overall amount of change in a function across its domain. It is able to preserve sharp discontinuities (such as edges in images) while removing noise, making it a useful tool in image restoration and signal denoising. This property is further elucidated through the coarea formula \citep{Chen2006}. For a function $f \in L^1(\Omega)$, where $\Omega$ is an open subset of $\mathbb{R}^d$, 
\begin{equation}\label{7}
\int_{\Omega} |\nabla f| := \int_{-\infty}^{\infty} \int_{f^{-1}(\gamma)} ds \, d\gamma,
\end{equation}
where $f^{-1}(\gamma)$ represents the level set of $f$ at the value $\gamma$. This formulation shows that TV integrates over all the contours of the function, reinforcing its capability in capturing piecewise-constant features. \citet{mumford1985boundary} and \citet{Rudin1992} propose the following TV-$\ell_2$ and TV-$\ell_1$ models, respectively.
\begin{align}\label{eqn:TVL1sigrecover}
&\inf_{f \in L^2(\Omega)} \left\{ \int_{\Omega} |\nabla f|^2 + \lambda \int_{\Omega} (f - \tilde{f})^2 \, dx \right\},\quad \inf_{f\in  L^2(\Omega)} \left\{ \int_\Omega |\nabla f|+ \lambda\int_\Omega (f-\tilde{f})^2\ud x \right\},
\end{align}
where $\tilde{f}\in  L^2(\Omega)$ is the ground-truth signal and $\lambda$ is a hyperparameter that affects accuracy. These models aim to preserve target features in the approximation $f$ and leave noise in the residual $(f-\tilde{f})$. In general, TV-$\ell_1$ can better preserve useful features and sharp discontinuities in the approximation $f$.





\subsection{Invariant Risk Minimization based on Total Variation}
It can be seen that the penalties of (\ref{4}) and (\ref{5}) are similar to a TV-$\ell_2$ term, which has been verified by \citet{8} under some mild conditions, such as measurability of the involved functions, non-correlation between the feature extractor and the environment variable, representability of $w$ by $e$, etc. In this sense, (\ref{4}) and (\ref{5}) are actually IRM-TV-$\ell_2$ and Minimax-TV-$\ell_2$ models. Considering the superiority of TV-$\ell_1$ over TV-$\ell_2$ in sharp feature preservation, \citet{8} further propose the following IRM-TV-$\ell_1$ (\ref{eqn:IRMv1wTVL1}) and Minimax-TV-$\ell_1$ (\ref{eqn:MinimaxTVL1}) models:
\begin{align}
	\label{eqn:IRMv1wTVL1}
	\min_{\Phi}\ &\left\{ \mathbb{E}_{w} [R(w \circ \Phi)] + \lambda (\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2 \right\}, \\
	\label{eqn:MinimaxTVL1}
	\min_{\Phi}\ &\left\{ \mathbb{E}_{w \leftarrow \frac{1_{(E)}}{E}} [ R(w \circ \Phi)] + \lambda \max_{\rho} (\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2 \right\},
\end{align}
where $\bbE_{w\leftarrow \rho}$ denotes the mathematical expectation with respect to (w.r.t.) $w$ whose measure is induced by $\rho$, and $\frac{1_{(E)}}{E}$ denotes the uniform probability measure for the environment $e$. The maximization w.r.t. $\rho $ identifies the worst-case inferred environment causing the greatest variation in the risk function. Hence, Minimax-TV-$\ell_1$ can be seen as the TV-$\ell_1$ version of ZIN. The corresponding coarea formula for IRM-TV-$\ell_1$ or Minimax-TV-$\ell_1$ is
\begin{equation}\label{15}
\int_{\Omega} |\nabla_w R(w \circ \Phi)| \, d\nu = \int_{-\infty}^{\infty} \int_{\{w \in \Omega : R(w \circ \Phi) = \gamma\}} ds \, d\gamma,
\end{equation}
where $ \{w \in \Omega : R(w \circ \Phi) = \gamma\} $ denotes the level set, and $ s $ is the Hausdorff measure in the corresponding dimensions. This formula ensures that IRM-TV-$\ell_1$ or Minimax-TV-$\ell_1$ preserves essential structural features while maintaining robustness across different environments. In the rest of this paper, we abbreviate IRM-TV-$\ell_1$ as IRM-TV if not specified otherwise. 




\section{Methodology}


\subsection{Autonomous Total Variation Penalty and Lagrangian Multiplier}
OOD generalization represents the generalization ability of a trained model to an unseen domain. From the perspective of IRM-TV, it can be represented by \citep{4,2,3,8}
\begin{align}
\label{eqn:OODwfrome}
 &\min_{\Phi}\max_{w} R(w\circ \Phi). 
\end{align}
In general, IRM-TV cannot achieve OOD generalization without additional conditions, due to insufficient diversity in the training environments and the inflexible TV penalty. However, \citet{8} indicate that the penalty hyperparameter $\lambda_{\Phi}$ of IRM-TV should be variable according to the invariant feature extractor $\Phi $:
\begin{align}
	\label{eqn:IRMv1wTVL1phi}
	\min_{\Phi}\ &\left\{ \mathbb{E}_{w} [R(w \circ \Phi)] + \lambda_{\Phi} (\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2 \right\}, \\
	\label{eqn:MinimaxTVL1phi}
	\min_{\Phi}\ &\left\{ \mathbb{E}_{w \leftarrow \frac{1_{(E)}}{E}} [ R(w \circ \Phi)] + \lambda_{\Phi} \max_{\rho} (\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2 \right\}.
\end{align}
The main reason is that a variable $\lambda_{\Phi}$ can fill the gap between the objective value of (\ref{eqn:IRMv1wTVL1phi}) or (\ref{eqn:MinimaxTVL1phi}) and the objective value of (\ref{eqn:OODwfrome}). \citet{8} further indicate that this variable $\lambda_{\Phi}$ exists in general situations. However, they do not specify any tractable and concrete implementation of $\lambda_{\Phi}$. 

To fill this gap, we find that $\lambda_{\Phi}$ actually serves as a Lagrangian multiplier in (\ref{eqn:IRMv1wTVL1phi}) and (\ref{eqn:MinimaxTVL1phi}). Hence we use it as an autonomous parameter, which is also taken into the training scheme. Specifically, the parameters for the invariant feature extractor, also denoted by $\Phi $, are directly taken as inputs for $\lambda$. Next, $\lambda$ can be parameterized by another set of parameters $\Psi$. By this means, $\lambda$ can be represented as a function of both $\Psi$ and $\Phi $: $\lambda(\Psi,\Phi)$. Then $\lambda$ not only depends on $\Phi$, but also adjusts its strength through $\Psi$. Now it can be deployed in a primal-dual optimization model, as illustrated in the next section.




\subsection{Primal-dual Optimization and Semi-Nash Equilibrium}
\label{sec:primdual}
Replacing $\lambda_{\Phi}$ by $\lambda(\Psi,\Phi)$ in (\ref{eqn:IRMv1wTVL1phi}) and (\ref{eqn:MinimaxTVL1phi}), we obtain the corresponding Lagrangian functions:
\begin{align}
	\label{eqn:IRMv1wTVL1obj}
	g(\Psi,\Phi)&:=\mathbb{E}_{w} [R(w \circ \Phi)] +  \lambda(\Psi,\Phi) (\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2 , \\
	\label{eqn:MinimaxTVL1obj}
	h(\rho,\Psi,\Phi)&:=\mathbb{E}_{w \leftarrow \frac{1_{(E)}}{E}} [ R(w \circ \Phi)] + \lambda(\Psi,\Phi)(\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2.
\end{align}
Applying the OOD generalization criterion (\ref{eqn:OODwfrome}) in the literature of IRM, we adopt a minimax scheme to optimize $\Phi$ and $\Psi$.
\begin{itemize}
	\item \textbf{Outer Minimization (Primal):} the primal variable $\Phi$ is trained to minimize the entire invariant risk, in order to capture invariant features across different environments.
	\item \textbf{Inner Maximization (Dual):} the dual variable $\Psi$ (or $(\rho,\Psi)$) is trained to maximize the autonomous TV penalty $\lambda(\Psi,\Phi) (\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2$ (or $\lambda(\Psi,\Phi)(\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2$), which confronts the most adverse scenarios with spurious features. 
\end{itemize}
They lead to the following proposed OOD-TV-IRM (\ref{eqn:IRMv1wTVL1ood}) and OOD-TV-Minimax (\ref{eqn:MinimaxTVL1ood}) models:
\begin{align}
	\label{eqn:IRMv1wTVL1ood}
\min_{\Phi}\max_{\Psi}  g(\Psi,\Phi):=	\min_{\Phi}\ &\left\{ \mathbb{E}_{w} [R(w \circ \Phi)] + \max_{\Psi} \left[\lambda(\Psi,\Phi) (\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2\right] \right\}, \\
	\label{eqn:MinimaxTVL1ood}
\min_{\Phi}\max_{\rho,\Psi}h(\rho,\Psi,\Phi):=\min_{\Phi}\ &\left\{ \mathbb{E}_{w \leftarrow \frac{1_{(E)}}{E}} [ R(w \circ \Phi)] +  \max_{\rho,\Psi} \left[\lambda(\Psi,\Phi)(\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2\right] \right\}.
\end{align}
They are essentially primal-dual optimization models. To further understand their functions, we introduce the concept of semi-Nash equilibrium in the context of this paper, without loss of generality.

\begin{definition}
\label{def:seminash}
A semi-Nash equilibrium $(\Psi^*,\Phi^*)$ of a Lagrangian function $g(\Psi,\Phi)$ satisfies the following conditions:
\vspace{-5pt}
\begin{enumerate}
	\item $g(\Psi^*,\Phi^*)\geqs g(\Psi,\Phi^*)$ for any $\Psi$ in the parameter space.
	\item $g(\Psi^*,\Phi^*)=g(\Psi_{max}(\Phi^*),\Phi^*)\leqs g(\Psi_{max}(\Phi),\Phi)$ for any $\Phi$ in the parameter space, where $\Psi_{max}(\Phi)\in \argmax_{\Psi} \left[\lambda(\Psi,\Phi) (\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2\right]$. In other words,$\Psi_{max}(\Phi)$ is a solution to the dual optimization with $\Phi$ fixed.
\end{enumerate}
\vspace{-5pt}
A semi-Nash equilibrium $(\rho^*,\Psi^*,\Phi^*)$ of a Lagrangian function $h(\rho,\Psi,\Phi)$ follows the same definition with the unified dual variable $(\rho,\Psi)$.
\end{definition}
\noindent\textbf{Remark:} in the context of game theory, OOD-TV-IRM (\ref{eqn:IRMv1wTVL1ood}) (or OOD-TV-Minimax Eq. \ref{eqn:MinimaxTVL1ood}) can be seen as a two-player zero-sum game, where $g(\Psi,\Phi)$ and $-g(\Psi,\Phi)$ are the gains for players $\Psi$ and $\Phi$, respectively. Item 1 in Definition \ref{def:seminash} indicates that $\Psi^*$ is the best strategy for dual optimization given $\Phi^*$ (which is independent of $\Psi$). On the other hand, Item 2 indicates that $\Phi^*$ is the conditional best strategy for primal optimization only when $\Psi_{max}(\Phi)$ is optimized over each $\Phi$. In this sense, $(\Psi^*,\Phi^*)$ is only a semi-Nash equilibrium instead of a full Nash equilibrium. It accords with our task where $\Phi$ is the feature extractor and primary variable that should confront the most adverse scenarios, while $\Psi$ is the TV penalty parameter and secondary variable that provides OOD generalization depending on $\Phi$. 

\begin{theorem}
\label{thm:seminash}
Assume that $R(w \circ \Phi)$ is continuous w.r.t. $(w,\Phi)$ and differentiable w.r.t. $w$, $\lambda(\Psi,\Phi)$ is continuous w.r.t. $(\Psi,\Phi)$, and the feasible set of parameters $(\rho,\Psi,\Phi)$ is bounded and closed. Then any solution to OOD-TV-IRM (\ref{eqn:IRMv1wTVL1ood}) or OOD-TV-Minimax (\ref{eqn:MinimaxTVL1ood}) is a semi-Nash equilibrium.
\end{theorem}
\vspace{-10pt}
\begin{proof}
The proof is given in Appendix \ref{proof:seminash}.
\end{proof}
\vspace{-10pt}
Most of the widely-used loss functions and deep neural networks satisfy the conditions of Theorem \ref{thm:seminash}, such as the squared loss, cross-entropy loss, multilayer perceptron, convolutional neural networks, etc. In practical computation, a bounded and closed feasible parameter set is also satisfied due to the maximum float point value. Hence Theorem \ref{thm:seminash} is applicable to general situations. It indicates that OOD-TV-IRM and OOD-TV-Minimax balance between the training loss and OOD generalization at a semi-Nash equilibrium.









\subsection{Primal-dual Algorithm and Adversarial Learning}
\label{sec:advlearn}
We develop a primal-dual algorithm to solve OOD-TV-IRM (\ref{eqn:IRMv1wTVL1ood}) or OOD-TV-Minimax (\ref{eqn:MinimaxTVL1ood}). To do this, we further assume that $R(w \circ \Phi)$ and $\lambda(\Psi,\Phi)$ are differentiable w.r.t. their corresponding arguments $w$, $\Phi$, and $\Psi$. As indicated in \citep{8}, $|\nabla_w R(w \circ \Phi)|$ in (\ref{eqn:IRMv1wTVL1ood}) or (\ref{eqn:MinimaxTVL1ood}) is non-differentiable w.r.t. $\Phi$. Hence we adopt the subgradient descent method to update these parameters, as illustrated in Appendix \ref{proof:primdualalgo}. Then the primal and dual updates for (\ref{eqn:IRMv1wTVL1ood}) or (\ref{eqn:MinimaxTVL1ood}) are:
\begin{align}
\label{eqn:IRMTVL1update}
&\begin{cases}
\Phi^{(k+1)}=\Phi^{(k)}-\eta_1^{(k)} \partial_{\Phi} g(\Psi^{(k)},\Phi^{(k)}),  \\
\Psi^{(k+1)}=\Psi^{(k)}+\eta_2^{(k)} \nabla_{\Psi} g(\Psi^{(k)},\Phi^{(k+1)});
\end{cases}\\
\label{eqn:MinimaxTVL1update2}
&\begin{cases}
\Phi^{(k+1)}=\Phi^{(k)}-\eta_1^{(k)} \partial_{\Phi} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k)}),  \\
(\rho^{(k+1)},\Psi^{(k+1)})=(\rho^{(k)},\Psi^{(k)})+\eta_2^{(k)} \nabla_{(\rho,\Psi)} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k+1)}),
\end{cases}
\end{align}
where $\eta_1^{(k)}$,$\eta_2^{(k)}>0$ are the learning rates for the primal and dual updates, respectively. The computation of the above (sub)gradients is illustrated in Appendix \ref{proof:primdualalgo}. In general machine learning scenarios, the smoothness and convexity of the Lagrangian functions $g$ and $h$ are usually unknown, thus $\eta_1^{(k)}$ and $\eta_2^{(k)}$ should be set according to different specific tasks. In addition, we provide a convergent scheme as follows.

\begin{theorem}
\label{thm:primdualalgo}
The same assumptions in Theorem \ref{thm:seminash} are used. By setting
\begin{align}
\label{eqn:primdualalgog}
&\eta_1^{(k)}{:=}\begin{cases}
\frac{1}{k^p \|\partial_{\Phi} g(\Psi^{(k)},\Phi^{(k)})\|_2 }, &\text{if}\quad\partial_{\Phi} g(\Psi^{(k)},\Phi^{(k)})\ne 0; \\ 0, &\text{if}\quad\partial_{\Phi} g(\Psi^{(k)},\Phi^{(k)})= 0. 
\end{cases} \nonumber\\
&\eta_2^{(k)}{:=}\begin{cases}
\frac{1}{k^p \|\nabla_{\Psi} g(\Psi^{(k)},\Phi^{(k+1)})\|_2 }, &\text{if}\quad\nabla_{\Psi} g(\Psi^{(k)},\Phi^{(k+1)})\ne 0; \\ 0, &\text{if}\quad\nabla_{\Psi} g(\Psi^{(k)},\Phi^{(k+1)})= 0. 
\end{cases} \\
\label{eqn:primdualalgoh}
\text{or}\quad&\eta_1^{(k)}{:=}\begin{cases}
\frac{1}{k^p \|\partial_{\Phi} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k)})\|_2 }, &\text{if}\quad\partial_{\Phi} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k)})\ne 0; \\ 0, &\text{if}\quad\partial_{\Phi} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k)})= 0. 
\end{cases} \nonumber\\
&\eta_2^{(k)}{:=}\begin{cases}
\frac{1}{k^p \|\nabla_{(\rho,\Psi)} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k+1)})\|_2 }, &\text{if}\quad\nabla_{(\rho,\Psi)} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k+1)})\ne 0; \\ 0, &\text{if}\quad\nabla_{(\rho,\Psi)} h(\rho^{(k)},\Psi^{(k)},\Phi^{(k+1)})= 0. 
\end{cases}
\end{align}
with an arbitrary $p>1$, the primal-dual algorithm (\ref{eqn:IRMTVL1update}) or (\ref{eqn:MinimaxTVL1update2}) achieves convergent sequences $\{ (\Psi^{(k)},\Phi^{(k)})\}_{k=1}^{\infty}$ or $\{ (\rho^{(k)},\Psi^{(k)},\Phi^{(k)})\}_{k=1}^{\infty}$, respectively. Moreover, its computational complexity is $\mO(((p-1)\epsilon)^{-\frac{1}{p-1}})$ to achieve a convergence tolerance of $\epsilon>0$.
\end{theorem}
\vspace{-10pt}
\begin{proof}
The proof is given in Appendix \ref{proof:primdualalgo}.
\end{proof}
\vspace{-10pt}
In fact, (\ref{eqn:IRMTVL1update}) or (\ref{eqn:MinimaxTVL1update2}) facilitates adversarial learning to dynamically adjust model parameters $(\Psi,\Phi)$ or $(\rho,\Psi,\Phi)$ to balance training loss and OOD generalization. This approach extends the theoretical work of IRM-TV by providing a practical, dynamic implementation of $\lambda(\Psi,\Phi)$ that adapts to the most adverse environments.

\noindent\textbf{Remark:} the above OOD-TV-IRM and OOD-TV-Minimax models as well as the primal-dual algorithm can also be applied to the TV-$\ell_2$ versions, which are omitted here since they are simpler differentiable cases. 









\subsection{Implementation with Neural Networks}
\label{sec:implenet}

First, we note that all the theoretical results in this section hold with any functions satisfying the corresponding conditions (e.g., continuity, differentiability), not limited to neural networks. To provide a specific instance, we implement $\lambda(\Psi,\Phi)$ with neural networks that take $\Psi$ and $\Phi$ as network trainable parameters and network inputs, respectively. Besides $\lambda(\Psi,\Phi)$, $\Phi$ and $\rho$ can also be developed by neural networks. Specifically, $\Phi: \mX\rightarrow \mH$ is the feature extractor that maps a sample $x$ from the sample space $\mX$ to the feature space $\mH$. It can be implemented by different types of neural networks depending on the practical situation, as shown in Table \ref{architecture}. The data sets correspond to different synthetic or real-world tasks, which will be illustrated in Section \ref{sec:experiment}. For example, $\Phi$ can be a multilayer perceptron in Simulation, or a convolutional neural network in Landcover. Similarly, $\rho: \mZ\rightarrow \Delta^E$ is the environment inference operator that maps the auxiliary variables $z\in\mZ$ to the probability space $\Delta^E:=\{v\in\bbRE: v\geqs 0_{(E)} \ \text{and} \ v\cdot 1_{(E)}=1  \}$, where $\bbRE$ denotes the $E$-dimensional real space (i.e., $E$ environments). Moreover, the architectures of $\rho$ are developed by multilayer perceptrons, which are compatible with the corresponding $\Phi$, as shown in Table \ref{architecture}.

Without ambiguity, we can also use $\Phi$ to denote the parameters of the feature extractor. Then $\lambda(\Psi,\Phi)$ can be implemented as a neural network that takes $\Phi$ as input and $\Psi$ as network parameters. We provide tractable architectures of $\lambda$ in Table \ref{architecture}, which should also be compatible with the corresponding $\Phi$. With the primal-dual algorithm in Section \ref{sec:advlearn}, $\Phi$ and $\Psi$ can be learned in an adversarial way to improve OOD generalization, which puts Theorem \ref{thm:seminash} into practice.






\begin{table}[h]
\caption{Network architectures of the invariant feature extractor $\Phi$, the environment inference operator $\rho$, and the TV penalty strength $\lambda$ w.r.t. their corresponding inputs.}
\label{architecture}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\scalebox{0.735}{
\begin{tabular}{@{}lll@{}}
%\abovespace\belowspace
\toprule
\multicolumn{1}{c}{\textbf{Data Set}} & \multicolumn{1}{c}{$x\to \Phi$} & \multicolumn{1}{c}{$z\to\rho$} \\
\hline
%\abovespace\belowspace
Simulation  & {Linear(15, 1)} & {Linear(1, 16)$\rightarrow$ReLu()$\rightarrow$Linear(16, 1) $\rightarrow$Sigmoid() }\\
%\abovespace\belowspace
%House Prices  & Linear(15, 32)$\rightarrow$ReLu()$\rightarrow$Linear(32, 1) & Linear(1, 64)$\rightarrow$ReLu()$\rightarrow$Linear(64, 4)$\rightarrow$Softmax() \\ 
%\abovespace\belowspace
CelebA & Linear(512, 16)$\rightarrow$ReLu()$\rightarrow$Linear(16, 1) & Linear(7, 16)$\rightarrow$ReLu()$\rightarrow$Linear(16, 1)$\rightarrow$Sigmoid() \\ 
%\abovespace
\multirow{4}{*}{Landcover} & Conv1d(8, 32, 5)$\rightarrow$ReLu()$\rightarrow$Conv1d(32, 32, 3) & \multirow{4}{*}{Linear(2, 16)$\rightarrow$ReLu()$\rightarrow$Linear(16, 2)$\rightarrow$Softmax()}\\
   & $\rightarrow$ReLu()$\rightarrow$MaxPool1d(2, 2)$\rightarrow$Conv1d(32, 64, 3)    &    \\
     & $\rightarrow$ReLu()$\rightarrow$MaxPool1d(2, 2)$\rightarrow$Conv1d(64, 6, 3)  &   \\
%\belowspace
     & $\rightarrow$ReLu()$\rightarrow$AvePool1d(1)  &   \\
%\abovespace\belowspace
Adult  & Linear(59, 16)$\rightarrow$ReLu()$\rightarrow$Linear(16, 1) & Linear(6, 16)$\rightarrow$ReLu()$\rightarrow$Linear(16, 4)$\rightarrow$Softmax() \\ 
House Price &  Linear(15,32) $\rightarrow$ReLu() $\rightarrow$ Linear(32,1) & Linear(1,64)$\rightarrow$ ReLu() $\rightarrow$ Linear(64,4) $\rightarrow$ Softmax() \\
\multirow{4}{*}{Colored MNIST} & Conv2d(3,32,3) $\rightarrow$  MaxPool2d(2,2)  & 
\multirow{4}{*}{Linear(3,16) $\rightarrow$ ReLU()  $\rightarrow$ Linear(16,1) $\rightarrow$ Softmax() }\\
&$\rightarrow$Conv2d(32,64,3) $\rightarrow$ MaxPool2d(2,2) &\\
&$\rightarrow$ Conv2d(64,128,3) $\rightarrow$ MaxPool2d(2,2)&\\
& $\rightarrow$ Linear(128*3*3,128)$\rightarrow$ Linear(128,10)&           \\

NICO  &  ResNet-18()  &   Linear(3,16) $\rightarrow$ ReLU()  $\rightarrow$ Linear(16,1)$\rightarrow$ Softmax() \\
\bottomrule
\end{tabular}}
	\scalebox{0.9}{\begin{tabular}{@{}l l}
		\toprule
		\multicolumn{1}{c}{\textbf{Data Set}} & \multicolumn{1}{c}{$\Phi\to \lambda$} \\
		\hline 
		Simulation & Linear(11, 1) $\rightarrow$ ReLU() $\rightarrow$ Linear(1, 1) $\rightarrow$ Softplus() \\

		CelebA & Linear(8225, 16) $\rightarrow$ ReLU() $\rightarrow$ Linear(16, 1) $\rightarrow$ Softplus() \\

		Landcover & Linear(173574, 32) $\rightarrow$ ReLU() $\rightarrow$ Linear(32, 1) $\rightarrow$ Softplus() \\
		Adult & Linear(977, 16) $\rightarrow$ ReLU() $\rightarrow$ Linear(16, 1) $\rightarrow$ Softplus() \\
		House Price & Linear(545, 32) $\rightarrow$ ReLU() $\rightarrow$ Linear(32, 16) $\rightarrow$ Softplus() $\rightarrow$ Linear(16,1)\\
		Colored MNIST & Linear(242122,32) $\rightarrow$ ReLU() $\rightarrow$ Linear(32,1) $\rightarrow$ Softplus()  \\
		NICO   & Linear(11180113,32) $\rightarrow$ ReLU() $\rightarrow$ Linear(32,1) $\rightarrow$ Softplus()\\
\bottomrule
	\end{tabular}}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}








\section{Experimental Results}
\label{sec:experiment}
We conduct experiments on $7$ simulation and real-world data sets to evaluate the effectiveness of the proposed OOD-TV-IRM and OOD-TV-Minimax in different OOD generalization tasks. These tasks largely follow the settings in the literature of IRM \citep{3,8}. We also include the original IRM \citep{2}, ZIN \citep{3}, IRM-TV-$\ell_1$, Minimax-TV-$\ell_1$ \citep{8}, EIIL \citep{EIIL}, LfF \citep{LfF}, and TIVA \citep{TIVA} frameworks in comparisons to verify the effectiveness of the proposed primal-dual optimization and adversarial learning scheme. Note that IRM and ZIN are equivalent to IRM-TV-$\ell_2$ and Minimax-TV-$\ell_2$, respectively. Each experiment is repeated $10$ times to record the mean and standard deviation (STD) of the results for each compared method. The code is available at \url{https://github.com/laizhr/OOD-TV-IRM}.




\subsection{Simulation Data}
The simulation data consists of temporal heterogeneity observations with distributional shift w.r.t time, which is used in \citep{3, 7} to evaluate OOD generalization. Details of generating this data set are provided in Appendix \ref{app:simugen}. Among all the parameter settings, the most challenging one is $(p_{s}^{-}, p_{s}^{+}, p_{v})=(0.999, 0.9, 0.8)$, thus we use this setting in the evaluation.




Table \ref{tb:celeba} (left) shows the mean and worst accuracies of different methods over the four test environments on simulation data. The proposed OOD-TV-based methods outperform their counterparts in all the mean and  worst accuracy cases. Moreover, OOD-TV-IRM-$\ell_1$ achieves the highest accuracies among all the compared methods in all the cases, while OOD-TV-Minimax-$\ell_2$ achieves the highest accuracies among all the compared methods without environment partition in all the cases. Hence the OOD-TV-based methods achieve the best performance regardless of whether the environment partition is available or not. 



\begin{table}[h]
	\caption{Accuracies of different methods on simulation data (left) and CelebA (right).}
	\label{tb:celeba}
	\centering
	\resizebox{\textwidth}{!}{ % 自动缩放表格
		\begin{tabular}{lll}
\toprule
			\multicolumn{1}{c}{\textbf{Method}} & \multicolumn{1}{c}{\textbf{Mean $\pm$ STD}} & \multicolumn{1}{c}{\textbf{Worst $\pm$ STD}} \\
			\hline 
			EIIL    &  $ 0.8161 \pm 0.0364 $  & $ 0.7159 \pm 0.0540 $  \\
			LfF		&  $ 0.7240\pm 0.0894 $  & $  0.6965 \pm 0.1049 $ \\
			TIVA    &   $ 0.8274 \pm 0.0454 $	 & $ 0.8139 \pm 0.0479 $ \\
			\hline
			ZIN       &   $ 0.7916 \pm 0.0349  $ & $ 0.7338 \pm 0.0573  $  \\
			OOD-TV-Minimax-$\ell_2$      & $\mathbf{0.8916 \pm 0.0202 } $ & $\mathbf{0.8858\pm 0.0223}  $        \\
			\hline
			Minimax-TV-$\ell_1$    &  $ 0.7555\pm 0.0742 $  &  $0.6931\pm0.0965$  \\
			OOD-TV-Minimax-$\ell_1$    & $\mathbf{0.8379 \pm 0.0418 } $  &  $\mathbf{0.7805 \pm 0.0612 } $     \\
			\hline
			IRM       & $ 0.8670\pm 0.0193$  & $ 0.8559\pm 0.0285$  \\
			OOD-TV-IRM-$\ell_2$    & $\mathbf{0.8904 \pm 0.0150 } $ & $\mathbf{0.8831 \pm 0.0195 } $ \\
			\hline
			IRM-TV-$\ell_1$       & $ 0.8713\pm 0.0201$ & $ 0.8618\pm 0.0209$ \\
			OOD-TV-IRM-$\ell_1$ &  $\mathbf{0.8944 \pm 0.0150 } $ & $\mathbf{0.8877 \pm 0.0168 } $  \\
\bottomrule
		\end{tabular}
		\hspace{2em}
		\begin{tabular}{lll}
\toprule
			\multicolumn{1}{c}{\textbf{Method}} & \multicolumn{1}{c}{\textbf{Mean $\pm$ STD}} & \multicolumn{1}{c}{\textbf{Worst $\pm$ STD}} \\
			\hline 
			EIIL    &  $ 0.7323 \pm 0.0284 $  & $ 0.7240 \pm 0.0291 $  \\
			LfF		&  $ 0.6092 \pm 0.0529 $  & $  0.5983 \pm 0.0598 $ \\
            TIVA  	&	$ 0.7695 \pm 0.0199 $	 & $ 0.7283 \pm 0.0209 $ \\
			\hline
			ZIN       & $ 0.7155 \pm 0.0298 $  &  $ 0.6034 \pm 0.0544 $ \\
			OOD-TV-Minimax-$\ell_2$      & $\mathbf{0.7608 \pm 0.0187 } $  & $\mathbf{0.6895 \pm 0.0243 } $        \\
			\hline
			Minimax-TV-$\ell_1$    &  $ 0.6876 \pm 0.0190 $  &  $ 0.5541 \pm 0.0301 $   \\
			OOD-TV-Minimax-$\ell_1$      &  $ \mathbf{  0.7044 \pm 0.0361} $ & $\mathbf{0.6180 \pm 0.0580 }$      \\
			\hline
			IRM        &  $ 0.7630 \pm 0.0261 $ &$ 0.7410 \pm 0.0215 $ \\
			OOD-TV-IRM-$\ell_2$    & $\mathbf{ 0.7786 \pm 0.0157 }$  & $ \mathbf{  0.7549 \pm 0.0227} $ \\
			\hline
			IRM-TV-$\ell_1$       & $ 0.7751 \pm 0.0203 $  & $ 0.7461 \pm 0.0170 $ \\
			OOD-TV-IRM-$\ell_1$ & $\mathbf{ 0.7945 \pm 0.0162} $  & $ \mathbf{0.7560 \pm 0.0170} $  \\
\bottomrule
		\end{tabular}
	}
\end{table}




\subsection{CelebA}

The CelebA data set \citep{celebA} contains face images of celebrities. The task is to identify smiling faces, which are deliberately correlated with the gender variable. The 512-dimensional deep features of the face images are extracted using a pre-trained ResNet18 model \citep{resnet}, while the invariant features are learned using subsequent multilayer perceptrons (MLP). EIIL, LfF, TIVA, ZIN, OOD-TV-Minimax-$\ell_2$, Minimax-TV-$\ell_1$ and OOD-TV-Minimax-$\ell_1$ take seven additional descriptive variables for environment inference, including \textit{Young}, \textit{Blond Hair}, \textit{Eyeglasses}, \textit{High Cheekbones}, \textit{Big Nose}, \textit{Bags Under Eyes}, and \textit{Chubby}. As for IRM, OOD-TV-IRM-$\ell_2$, IRM-TV-$\ell_1$, and OOD-TV-IRM-$\ell_1$, they use the gender variable as the environment indicator.

Table \ref{tb:celeba} (right) shows the accuracies of different methods on CelebA. The proposed OOD-TV-based methods outperform their counterparts in all the 8 cases with both mean and worst accuracies. Moreover, OOD-TV-IRM-$\ell_1$ achieves the highest accuracies among all the competitors. Hence OOD-TV-IRM improves OOD generalization compared with IRM-TV.









\subsection{Landcover}

The Landcover data set consists of time series data and the corresponding land cover types derived from satellite images \citep{landcover2006, landcover2020, landcover2021}. The input data has dimensions of $46 \times 8$ and is used to identify one of six land cover types. The invariant feature extractor $\Phi$ is implemented as a 1D-CNN to process the time series input, following the approaches of \citet{landcover2021} and \citet{3}. In scenarios where ground-truth environment partitions are unavailable, latitude and longitude are used as auxiliary information for environment inference. All methods are trained on non-African data, and then tested on both non-African (from regions not overlapping with the training data) and African regions. This is a complex and challenging experiment among the 7 experiments of this paper.

Table \ref{tb:landcover} (left) shows the accuracies of different methods on Landcover. The proposed OOD-TV-based methods outperform their counterparts in all the 8 cases with both mean and worst accuracies. Hence the OOD-TV-based methods show competitive performance in this challenging task.



\begin{table}[h]
	\caption{Accuracies of different methods on Landcover (left) and adult income prediction (right).}
	\label{tb:landcover}
	\centering
	\resizebox{\textwidth}{!}{ % 调整表格大小
		\begin{tabular}{lll}
\toprule
			\multicolumn{1}{c}{\textbf{Method}} & \multicolumn{1}{c}{\textbf{Mean $\pm$ STD}} & \multicolumn{1}{c}{\textbf{Worst $\pm$ STD}} \\
			\hline 
			EIIL    &  $ 0.6653 \pm 0.0152 $  & $ 0.6614 \pm 0.0156 $  \\
			LfF		&  $ 0.5097 \pm 0.0567 $  & $  0.5017 \pm 0.0580 $ \\
			TIVA  	&	$ 0.5388 \pm 0.0154 $	 & $ 0.5351 \pm 0.0175 $ \\
			\hline
			ZIN       & $ 0.6511 \pm 0.0254 $  &  $ 0.6468 \pm 0.0228$ \\
			OOD-TV-Minimax-$\ell_2$      & $\mathbf{0.6530 \pm 0.0178 } $  & $\mathbf{0.6490 \pm 0.0124 } $        \\
			\hline
			Minimax-TV-$\ell_1$    &  $ 0.6573 \pm 0.0219 $  &  $ 0.6551 \pm 0.0176 $   \\
			OOD-TV-Minimax-$\ell_1$      &  $ \mathbf{  0.6604 \pm 0.0151} $ & $\mathbf{0.6566 \pm 0.0150 }$      \\
			\hline
			IRM        &  $ 0.6472 \pm 0.0185 $ &$ 0.6427 \pm 0.0154 $ \\
			OOD-TV-IRM-$\ell_2$    & $\mathbf{ 0.6705 \pm 0.0132 }$  & $ \mathbf{  0.6672 \pm 0.0174} $ \\
			\hline
			IRM-TV-$\ell_1$       & $ 0.6422 \pm 0.0196 $  & $ 0.6390 \pm 0.0208 $ \\
			OOD-TV-IRM-$\ell_1$ & $\mathbf{ 0.6672 \pm 0.0182} $  & $ \mathbf{0.6636 \pm 0.0197} $  \\
\bottomrule
		\end{tabular}
		\hspace{2em}
		\begin{tabular}{lll}
\toprule
			\multicolumn{1}{c}{\textbf{Method}} & \multicolumn{1}{c}{\textbf{Mean $\pm$ STD}} & \multicolumn{1}{c}{\textbf{Worst $\pm$ STD}} \\
			\hline 
			EIIL    &  $ 0.7734 \pm 0.0120 $  & $ 0.7395 \pm 0.0132 $  \\
			LfF		&  $ 0.7785 \pm 0.0089 $  & $  0.7545 \pm 0.0084 $ \\
			TIVA  	&	$ 0.8226 \pm 0.0071 $	 & $ 0.8085 \pm 0.0086 $ \\
			\hline
			ZIN       & $ 0.8201 \pm 0.0093 $  &  $ 0.8058 \pm 0.0101$ \\
			OOD-TV-Minimax-$\ell_2$      & $\mathbf{0.8345 \pm 0.0055 } $  & $\mathbf{0.8105 \pm 0.0063 } $        \\
			\hline
			Minimax-TV-$\ell_1$    &  $ 0.8101 \pm 0.0082 $  &  $ 0.7958 \pm 0.0103 $   \\
			OOD-TV-Minimax-$\ell_1$      &  $ \mathbf{  0.8330 \pm 0.0058} $ & $\mathbf{0.8093 \pm 0.0075 }$      \\
			\hline
			IRM        &  $ 0.8257 \pm 0.0069 $ &$ 0.8052 \pm 0.0112 $ \\
			OOD-TV-IRM-$\ell_2$    & $\mathbf{ 0.8369 \pm 0.0109 }$  & $ \mathbf{  0.8103 \pm 0.0091} $ \\
			\hline
			IRM-TV-$\ell_1$       & $ 0.8298 \pm 0.0074 $  & $ 0.8054 \pm 0.0075 $ \\
			OOD-TV-IRM-$\ell_1$ & $\mathbf{ 0.8435 \pm 0.0089} $  & $ \mathbf{0.8197 \pm 0.0091} $  \\
\bottomrule
		\end{tabular}
	}
\end{table}




\subsection{Adult Income Prediction}

This task uses the Adult data set\footnote{https://archive.ics.uci.edu/dataset/2/adult} to predict whether an individual's income exceeds \$50K per year based on census data. The data set is split into four subgroups representing different environments based on \textit{race} $\in$ \{Black, Non-Black\} and \textit{sex} $\in$ \{Male, Female\}. Two-thirds of the data from the Black Male and Non-Black Female subgroups are randomly selected for training, and the compared methods are verified across all four subgroups using the remaining data. Six integer variables — \textit{Age}, \textit{FNLWGT}, \textit{Education-Number}, \textit{Capital-Gain}, \textit{Capital-Loss}, and \textit{Hours-Per-Week} — are fed into EIIL, LfF, TIVA, ZIN, OOD-TV-Minimax-$\ell_2$, Minimax-TV-$\ell_1$ and OOD-TV-Minimax-$\ell_1$ for environment inference. Ground-truth environment indicators are provided for IRM, OOD-TV-IRM-$\ell_2$, IRM-TV-$\ell_1$, and OOD-TV-IRM-$\ell_1$. Categorical variables, excluding race and sex, are encoded using one-hot encoding, followed by principal component analysis (PCA), retaining over 99\% of the cumulative explained variance. The transformed features are then combined with the six integer variables, resulting in 59-dimensional representations, which are normalized to have zero mean and unit variance for invariant feature learning.

Table \ref{tb:landcover} (right) shows the accuracies of different methods on this income prediction task. The proposed OOD-TV-based methods outperform their counterparts in all the 8 cases with both mean and worst accuracies. Hence they are more effective and robust than the original IRM-TV methods in this prediction task regardless of whether the environment partition is available or not.





\subsection{House Price Prediction}
The above four experiments are all classification tasks. We also perform a regression task with the House Prices data set\footnote{https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data}. This task uses $15$ variables, such as the number of bathrooms, locations, and other similar features, to predict the house price. The training and test sets consist of samples with built years in periods $[1900, 1950]$ and $(1950, 2000]$, respectively. The house prices within the same built year are normalized. The built year variable is fed into EIIL, TIVA, ZIN, OOD-TV-Minimax-$\ell_2$, Minimax-TV-$\ell_1$, and OOD-TV-Minimax-$\ell_1$ for environment inference. LfF is not suitable for this regression task due to the unstable training process and poor performance. The training set is partitioned into $5$ subsets with $10$-year range in each subset. Samples in the same subset can be seen as having the same environment.

Table \ref{tb:houseprice} (left) provides the mean squared errors (MSE) of different methods in this regression task. The OOD-TV-based methods achieves lower MSEs than their counterparts in the mean result of all the environments and the worst environment. Hence they are more effective and robust than the original IRM-TV methods in the regression task.




\begin{table}[h]
	\centering
	\caption{Mean squared errors of different methods on house price prediction (left) and accuracies of different methods on Colored MNIST (right).}
	\label{tb:houseprice}
	\resizebox{\textwidth}{!}{ % 缩放表格以适应页面宽度
		\begin{tabular}{lcc}
\toprule
			\multicolumn{1}{c}{\textbf{Method}} & \multicolumn{1}{c}{\textbf{Mean $\pm$ STD}} & \multicolumn{1}{c}{\textbf{Worst $\pm$ STD}} \\
			\hline 
			EIIL    &  $ 0.3644 \pm 0.0512 $  & $ 0.4953 \pm 0.0587 $ \\
			TIVA  	&	$ 0.3869 \pm 0.0413 $	 & $ 0.5519 \pm 0.0508 $ \\
			\hline    
			ZIN       & $ 0.3203 \pm 0.0378 $  &  $ 0.4465 \pm 0.0552$ \\
			OOD-TV-Minimax-$\ell_2$      & $\mathbf{0.2743 \pm 0.0438 } $  & $\mathbf{0.3983 \pm 0.0586 } $        \\
			\hline
			Minimax-TV-$\ell_1$    &  $ 0.3339 \pm 0.0508 $  &  $ 0.4741 \pm 0.0520 $   \\
			OOD-TV-Minimax-$\ell_1$      &  $ \mathbf{  0.2621 \pm 0.0510} $ & $\mathbf{0.3706 \pm 0.0549 }$      \\
			\hline
			IRM        &  $ 0.4589 \pm 0.0762 $ &$ 0.6378 \pm 0.0873 $ \\
			OOD-TV-IRM-$\ell_2$    & $\mathbf{ 0.3549 \pm 0.0519 }$  & $ \mathbf{  0.4772 \pm 0.0591} $ \\
			\hline
			IRM-TV-$\ell_1$       & $ 0.4009 \pm 0.0355 $  & $ 0.5642 \pm 0.0615 $ \\
			OOD-TV-IRM-$\ell_1$ & $\mathbf{ 0.3383 \pm 0.0303} $  & $ \mathbf{0.4763 \pm 0.0428} $  \\
\bottomrule
		\end{tabular}\hspace{2em}
		\begin{tabular}{lc}
\toprule
			\multicolumn{1}{c}{\textbf{Method}} & \multicolumn{1}{c}{\textbf{Mean $\pm$ STD}} \\
			\hline 
			EIIL    &  $ 0.8236 \pm 0.0265 $   \\
			LfF  	&	$ 0.8964 \pm 0.0250 $	 \\
			\hline
			ZIN &  $ 0.9502 \pm 0.0153 $ \\
			OOD-TV-Minimax-$\ell_2$ &  $ \mathbf{  0.9671 \pm 0.0060} $ \\
			\hline
			Minimax-TV-$\ell_1$ &  $ 0.9322 \pm 0.0362 $ \\
			OOD-TV-Minimax-$\ell_1$ &  $ \mathbf{  0.9514 \pm 0.0242} $ \\
			\bottomrule
	\end{tabular}}
\end{table}



\subsection{Colored MNIST}
We use the Colored MNIST data set\footnote{https://www.kaggle.com/datasets/youssifhisham/colored-mnist-dataset} to evaluate the performance of our approach in multi-group classification of a more general scenario. It consists of hand-written digits of $0$ to $9$ with different background colors of red, green, and blue. To make it more challenging, we remove the background color information of samples, so that only the mean values of the red, green, and blue channels of a sample can be used as three auxiliary variables for environment inference. EIIL, LfF, OOD-TV-Minimax, and Minimax-TV are suitable for this setting, while TIVA is unavailable due to unknown auxiliary feature extractions. Their classification accuracies are shown in Table \ref{tb:houseprice} (right). The two OOD-TV-Minimax methods achieve the highest accuracies among all the compared methods in this multi-group classification task. Thus OOD-TV-Minimax is effective in improving OOD generalization for such a complex scenario.





\subsection{NICO}     
The NICO data set \citep{NICO} is a widely-used benchmark in Non-Independent and Identically Distributed (Non-I.I.D.) image classification with contexts. This data set presents challenges due to both correlation shift and diversity shift. There are two superclasses in NICO: \emph{Vehicle} and \emph{Animal}, which consist of $9$ classes and $10$ classes, respectively. Each class has several contexts, while different classes may have different context sets. We randomly split each context into $80\%$ training samples and $20\%$ test samples. Then we remove the context information of samples and unite all the contexts to form a whole class. Therefore, only the mean values of the red, green, and blue channels of a sample can be used as three auxiliary variables for environment inference. EIIL, OOD-TV-Minimax, and Minimax-TV can be used in this setting, while LfF has unstable training process and poor performance, and TIVA is unavailable due to unknown auxiliary feature extractions. As shown in Table \ref{tb:nico}, the two OOD-TV-Minimax methods outperform other competitors in terms of classification accuracy. Thus OOD-TV-Minimax is effective in improving OOD generalization with both correlation shift and diversity shift.




\begin{table}[h]
	\centering
	\caption{Accuracies of different methods on NICO. }
	\label{tb:nico}
	\begin{tabular}{lcc}
\toprule
		\textbf{Method} & \textbf{ Vehicle (Mean $\pm$ STD)} & \textbf{Animal (Mean $\pm$ STD)} \\ 
		\hline 
		EIIL  	&	$ 0.6902 \pm 0.0357 $ &		$ 0.8664 \pm 0.0110 $  \\
		\hline
		ZIN & $ 0.7176 \pm 0.0374 $ & $ 0.8541 \pm 0.0250 $ \\ 
		OOD-TV-Minimax-$\ell_2$ & $ \mathbf{  0.7872 \pm 0.0275} $ & $ \mathbf{  0.8826 \pm 0.0249} $ \\ 
		\hline
		Minimax-TV-$\ell_1$ & $ 0.7104 \pm 0.0236 $ & $ 0.8289 \pm 0.0311 $ \\ 
		OOD-TV-Minimax-$\ell_1$ & $ \mathbf{  0.7289 \pm 0.0206} $ & $ \mathbf{  0.9112 \pm 0.0154} $ \\ 
		\bottomrule
	\end{tabular}
\end{table}



\subsection{Adversarial Learning Process}

To visualize the adversarial learning process, we plot the objective values and parameter changes for OOD-TV-IRM and OOD-TV-Minimax on simulation data in Figure \ref{fig:advtrain}. Specifically, the overall objectives are the $g(\Psi,\Phi)$ and $h(\rho,\Psi,\Phi)$ defined in (\ref{eqn:IRMv1wTVL1obj}) and (\ref{eqn:MinimaxTVL1obj}), respectively. The penalty terms correspond to the second terms in (\ref{eqn:IRMv1wTVL1obj}) and (\ref{eqn:MinimaxTVL1obj}), respectively. The parameter changes correspond to $\|\Phi^{(k+1)}-\Phi^{(k)}\|_2$ and $\|\Psi^{(k+1)}-\Psi^{(k)}\|_2$, respectively. We follow the annealing strategy of \citep{3} in the early epochs, thus the adversarial learning starts from the $2001$st epoch. The Adam scheme \citep{adam} is adopted as the optimizer. Figure \ref{fig:advtrain} indicates that the adversarial learning process becomes stable with $400$ epochs. Both of the overall objective and the penalty term converge to form a stable gap, which corresponds to the fidelity term to be optimized. Besides, both $\|\Phi^{(k+1)}-\Phi^{(k)}\|_2$ and $\|\Psi^{(k+1)}-\Psi^{(k)}\|_2$ converge to small values, which indicates that the parameters $\Phi^{(k)}$ and $\Psi^{(k)}$ are rarely updated. 

We also demonstrate the adversarial learning process for OOD-TV-Minimax (since OOD-TV-IRM is not applicable) on Colored MNIST in Figure \ref{fig:advtrain2}. The Adam optimizer is used for the primal parameter $\Phi$, while the dual update (\ref{eqn:MinimaxTVL1update2}, \ref{eqn:primdualalgoh}) is used for $\Psi$ to ensure convergence. Results show that the adversarial learning process effectively converges after $600$ epochs for OOD-TV-Minimax-$\ell_1$ and after $300$ epochs for OOD-TV-Minimax-$\ell_2$. All these results indicate that the adversarial learning process is feasible.









\section{Conclusion and Discussion}
We extend the invariant risk minimization based on total variation model (IRM-TV) to a Lagrangian multiplier model OOD-TV-IRM, in order to improve out-of-distribution (OOD) generalization. OOD-TV-IRM is essentially a primal-dual optimization model. The primal optimization minimizes the entire invariant risk to extract invariant features, while the dual optimization strengthens the autonomous TV penalty to provide an adversarial interference. The objective of OOD-TV-IRM is to find a semi-Nash equilibrium that balances the training loss and OOD generalization. We further develop a convergent primal-dual algorithm to facilitate adversarial learning for invariant features and adverse environments. Experimental results show that the proposed OOD-TV-IRM framework improves effectiveness and robustness in most experimental tasks, achieving competitive mean accuracies, worst accuracies, and mean squared errors across different test environments. 

One potential future direction is to maximize the benefits of OOD-TV-IRM by improving the diversity and representation of training environments. Another potential approach is to improve the effectiveness of the primal-dual optimization scheme. A third potential approach is to develop new penalties with different variations beyond the widely-used TV penalty.




\section*{Acknowledgments}
This work is supported in part by the National Natural Science Foundation of China under grant 62176103, and in part by the Science and Technology Planning Project of Guangzhou under grant 2024A04J9896.





%\newpage
\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}




\clearpage

\appendix

\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\section{Appendix}


\subsection{Proof of Theorem \ref{thm:seminash}}
\label{proof:seminash}

\begin{proof}
\noindent\textbf{Part (a).} 

First, we verify that there exists at least one solution to (\ref{eqn:IRMv1wTVL1ood}). Since $\lambda(\Psi,\Phi)$ is continuous w.r.t. $(\Psi,\Phi)$ and $(\Psi,\Phi)$ belongs to a bounded and closed set, a solution to $\max_{\Psi} \lambda(\Psi,\Phi)$ can be obtained for any given $\Phi$ by the Weierstrass extreme value theorem, denoted as $\Psi_{max}(\Phi)$. Let $\Lambda(\Phi):=\lambda(\Psi_{max}(\Phi),\Phi)$. We then turn to prove that $\Lambda(\Phi)$ is a continuous function w.r.t. $\Phi$. For $\Phi_1\ne \Phi_2$, we have
\begin{align}
\label{eqn:continlambda}
\lambda(\Psi_{max}(\Phi_2),\Phi_1)\leqs \lambda(\Psi_{max}(\Phi_1),\Phi_1).
\end{align}
From the continuity of $\lambda$, for any given $\epsilon>0$, there exists some $\delta_1>0$, such that for any $\Phi\in \rB(\Phi_1,\delta_1)$, we have
\begin{align}
\label{eqn:continlambda2}
\lambda(\Psi_{max}(\Phi_2),\Phi)-\epsilon<\lambda(\Psi_{max}(\Phi_2),\Phi_1),
\end{align}
where $\rB(\Phi_1,\delta_1)$ denotes an open ball centered at $\Phi_1$ with radius $\delta_1$. Letting $\Phi_2\in \rB(\Phi_1,\delta_1)$ in (\ref{eqn:continlambda2}) and combining it with (\ref{eqn:continlambda}), we have
\begin{align}
\label{eqn:continlambda3}
\lambda(\Psi_{max}(\Phi_2),\Phi_2)-\epsilon<\lambda(\Psi_{max}(\Phi_1),\Phi_1).
\end{align}
Following a similar deduction, for the above $\epsilon>0$, there exists some $\delta_2>0$, such that for $\Phi_1\in \rB(\Phi_2,\delta_2)$, we have
\begin{align}
\label{eqn:continlambda4}
\lambda(\Psi_{max}(\Phi_1),\Phi_1)-\epsilon<\lambda(\Psi_{max}(\Phi_2),\Phi_2).
\end{align}
Combining (\ref{eqn:continlambda3}) and (\ref{eqn:continlambda4}), for any given $\epsilon>0$, as long as $\| \Phi_1-\Phi_2 \|_2 < \min\{\delta_1,\delta_2\}$, we have
\begin{align}
\label{eqn:continlambda5}
|\lambda(\Psi_{max}(\Phi_1),\Phi_1)-\lambda(\Psi_{max}(\Phi_2),\Phi_2)|<\epsilon.
\end{align}
This proves that $\Lambda(\Phi)$ is continuous w.r.t. $\Phi$.

As for $(\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2$, the TV operator and the expectation are taken on the variable $w$, which does not affect the continuity w.r.t. $\Phi$. Define
\begin{align}
\label{eqn:continG}
G(\Phi):=g(\Psi_{max}(\Phi),\Phi)=\mathbb{E}_{w} [R(w \circ \Phi)] + \Lambda(\Phi)(\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2.
\end{align}
It can be seen that $G(\Phi)$ is the sum, multiplication, and composition of continuous functions w.r.t. $\Phi$, thus it is also continuous w.r.t. $\Phi$. Using the Weierstrass extreme value theorem again, there exists a solution to $\min_{\Phi} G(\Phi)$, denoted by $\Phi^*$. Let $\Psi^*:=\Psi_{max}(\Phi^*)$, then $(\Psi^*,\Phi^*)$ is a solution to (\ref{eqn:IRMv1wTVL1ood}).

\noindent\textbf{Part (b).} 

Next, we turn to investigate $h(\rho,\Psi,\Phi)$ in (\ref{eqn:MinimaxTVL1ood}). From Appendix A.3 of IRM-TV \citep{8},
\begin{align}
\label{eqn:continexpect}
\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ]=\sum_{i=1}^E|\nabla_w R(w{\circ} \Phi,e_i)| \rho_i,
\end{align}
where $e_i$ denotes the $i$-th training environment in the literature of IRM, and $\rho_i$ denotes the environment inference operator for the $i$-th training environment. (\ref{eqn:continexpect}) indicates that $\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ]$ is a linear function w.r.t. $\rho\in \Delta^E$, where $\Delta^E$ is the $E$-dimensional simplex defined in Section \ref{sec:implenet}. Thus $\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ]$ as well as $(\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2$ is continuous w.r.t. $\rho$. On the other hand, $\lambda(\Psi,\Phi)$ is continuous w.r.t. $\Psi$. Define
\begin{align}
\label{eqn:continexpect2}
\fE(\rho,\Phi):=(\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2.
\end{align}
To examine the continuity of $\lambda(\Psi,\Phi)\fE(\rho,\Phi)$ w.r.t. the entire dual variable $(\rho,\Psi)$, we check its values at two different points $(\rho_1,\Psi_1)$ and $(\rho_2,\Psi_2)$:
\begin{align}
\label{eqn:continlamexpect}
&|\lambda(\Psi_1,\Phi)\fE(\rho_1,\Phi)-\lambda(\Psi_2,\Phi)\fE(\rho_2,\Phi)|\nonumber\\
<&|\lambda(\Psi_1,\Phi)\fE(\rho_1,\Phi)-\lambda(\Psi_1,\Phi)\fE(\rho_2,\Phi)|+|\lambda(\Psi_1,\Phi)\fE(\rho_2,\Phi)-\lambda(\Psi_2,\Phi)\fE(\rho_2,\Phi)|\nonumber\\
=&|\lambda(\Psi_1,\Phi)|\cdot |\fE(\rho_1,\Phi)-\fE(\rho_2,\Phi)|+|\fE(\rho_2,\Phi)|\cdot|\lambda(\Psi_1,\Phi)-\lambda(\Psi_2,\Phi)|.
\end{align}
When $(\rho_2,\Psi_2)\to (\rho_1,\Psi_1)$, the right hand side of (\ref{eqn:continlamexpect}) tends to zero, thus the left hand side of (\ref{eqn:continlamexpect}) also tends to zero. This verifies that $\lambda(\Psi,\Phi)\fE(\rho,\Phi)$ is continuous w.r.t. $(\rho,\Psi)$ for any given $\Phi$. 

Using the Weierstrass extreme value theorem, there exists at least one solution to $\max_{\rho,\Psi}[\lambda(\Psi,\Phi)\fE(\rho,\Phi)]$ for any given $\Phi$, denoted by $(\rho,\Psi)_{max}(\Phi)$. Define 
\begin{align}
\label{eqn:continH}
H(\Phi):=h((\rho,\Psi)_{max}(\Phi),\Phi)=\mathbb{E}_{w \leftarrow \frac{1_{(E)}}{E}} [ R(w \circ \Phi)] +\max_{\rho,\Psi}[\lambda(\Psi,\Phi)\fE(\rho,\Phi)],
\end{align}
which is continuous w.r.t. $\Phi$. Following similar deductions to Part (a), there exists a solution to $\min_{\Phi} H(\Phi)$, denoted by $\Phi^*$. Let $(\rho^*,\Psi^*):=(\rho,\Psi)_{max}(\Phi^*)$, then $(\rho^*,\Psi^*,\Phi^*)$ is a solution to (\ref{eqn:MinimaxTVL1ood}).


\noindent\textbf{Part (c).} 

Lastly, we turn to verify that any solutions $(\Psi^*,\Phi^*)$ to (\ref{eqn:IRMv1wTVL1ood}) and $(\rho^*,\Psi^*,\Phi^*)$ to (\ref{eqn:MinimaxTVL1ood}) are semi-Nash equilibria. We first fix $\Phi^*$, since $\Psi^*=\Psi_{max}(\Phi^*)$ and $(\rho^*,\Psi^*)=(\rho,\Psi)_{max}(\Phi^*)$, we have $g(\Psi^*,\Phi^*)\geqs g(\Psi,\Phi^*)$ or $h(\rho^*,\Psi^*,\Phi^*)\geqs h(\rho,\Psi,\Phi^*)$ for any $\Psi$ or $(\rho,\Psi)$ in the parameter space. Hence Item 1 in Definition \ref{def:seminash} is satisfied.

On the other hand, from (\ref{eqn:continG}) and (\ref{eqn:continH}), we have $G(\Phi^*)\leqs G(\Phi)$ and $H(\Phi^*)\leqs H(\Phi)$ in the parameter space. Hence Item 2 in Definition \ref{def:seminash} is also satisfied. In summary, Theorem \ref{thm:seminash} is proved.


\end{proof}




\subsection{Proof of Theorem \ref{thm:primdualalgo}}
\label{proof:primdualalgo}
Before starting the proof, we compute some gradients or subgradients in place of the conventional gradients at non-differentiable points for $g$ and $h$. This allows us to maintain the optimization flow with the autograd module of mainstream learning architectures (like Pytorch\footnote{https://pytorch.org/}). First, the subgradient of $|\nabla_w R(w \circ \Phi)|$ w.r.t. $\Phi$ is:
\begin{align}
\label{eqn:subgradnabR}
&\partial_{\Phi} |\nabla_w R(w\circ \Phi)|{=}\left\{\begin{array}{ll}
\frac{J_{\Phi}^\top[\nabla_w R(w\circ \Phi)]*\nabla_w R(w\circ \Phi)}{|\nabla_w R(w\circ \Phi)|} & \text{if}\quad \nabla_w R(w\circ \Phi)\ne 0,\\
0  &  \text{if}\quad   \nabla_w R(w\circ \Phi)=0,
\end{array} \right.
\end{align}
where $J_{\Phi}[\cdot]$ is the Jacobian matrix w.r.t. $\Phi$, and $*$ is the matrix multiplication. 





By the chain rule of derivative, the (sub)gradients of $g$ w.r.t. $\Phi$ and $\Psi$ are:
\begin{align}
\label{eqn:IRMTVL1objsubgrad}
\partial_{\Phi} g(\Psi,\Phi) =&\bbE_{w} [\nabla_{\Phi} R(w\circ \Phi)] +2\lambda(\Psi,\Phi)\cdot\bbE_{w} [|\nabla_w R(w\circ \Phi)| ]\cdot\bbE_{w} [\partial_{\Phi}|\nabla_w R(w\circ \Phi)| ]   \nonumber \\
&\quad +\nabla_{\Phi}\lambda(\Psi,\Phi)\cdot(\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2,\nonumber \\
\nabla_{\Psi} g(\Psi,\Phi) =&\nabla_{\Psi}\lambda(\Psi,\Phi)\cdot(\mathbb{E}_{w} [|\nabla_w R(w \circ \Phi)| ])^2.
\end{align}
Similarly, the (sub)gradients of $h$  w.r.t. $\rho$, $\Psi$, and $\Phi$ are:
\begin{align}
\label{eqn:MinimaxTVL1objgrad}
\nabla_{\rho} h(\rho,\Psi,\Phi)=& 2\lambda(\Psi,\Phi)\cdot \bbE_{w{\leftarrow} \rho} [|\nabla_w R(w{\circ} \Phi)| ] \cdot\nabla_{\rho}(\bbE_{w{\leftarrow} \rho} [|\nabla_w R(w{\circ} \Phi)| ]),\nonumber\\
\nabla_{\Psi} h(\rho,\Psi,\Phi)=& \nabla_{\Psi} \lambda(\Psi,\Phi)\cdot(\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2, \nonumber \\
\partial_{\Phi} h(\rho,\Psi,\Phi)=& \bbE_{w \leftarrow \frac{1_{(E)}}{E}} [ \nabla_{\Phi}R(w{\circ} \Phi)]\nonumber \\
&+2\lambda(\Psi,\Phi)\cdot\bbE_{w{\leftarrow} \rho} [|\nabla_w R(w\circ \Phi)| ]\cdot\bbE_{w{\leftarrow} \rho} [\partial_{\Phi}|\nabla_w R(w\circ \Phi)| ] \nonumber \\
&+ \nabla_{\Phi}\lambda(\Psi,\Phi)\cdot(\mathbb{E}_{w \leftarrow \rho} [|\nabla_w R(w \circ \Phi)| ])^2.
\end{align}


\begin{proof}[Proof of Theorem \ref{thm:primdualalgo}]
We first investigate the sequence $\{\Phi^{(k)}\}$. Combining (\ref{eqn:IRMTVL1update}) and (\ref{eqn:primdualalgog}), we have
\begin{align}
\label{eqn:convphi}
\| \Phi^{(k+1)}-\Phi^{(k)}  \|_2\leqs \frac{1}{k^p}.
\end{align}
Summing up both sides of (\ref{eqn:convphi}) from $k=2$ to $\infty$ yields
\begin{align}
\label{eqn:convphia}
\sum_{k=2}^{\infty}\| \Phi^{(k+1)}-\Phi^{(k)}  \|_2\leqs \sum_{k=2}^{\infty}\frac{1}{k^p}<\int_{1}^{\infty} \frac{1}{\zeta^p}\ud \zeta=\frac{1}{1-p}\cdot\frac{1}{\zeta^{p-1}}\arrowvert_{1}^{\infty}=\frac{1}{p-1}<\infty.
\end{align}
It means that the sum of infinite series $\sum_{k=2}^{\infty}\| \Phi^{(k+1)}-\Phi^{(k)}  \|_2$ is convergent. Then for any given $\epsilon>0$, there exists some $N$ such that $\sum_{k=N}^{\infty}\| \Phi^{(k+1)}-\Phi^{(k)}  \|_2<\epsilon$. Hence for any $k>N$ and any $m\in \bbN_+$,
\begin{align}
\label{eqn:convphi2}
\| \Phi^{(k+m)}-\Phi^{(k)}  \|_2\leqs  \sum_{j=k}^{k+m-1} \| \Phi^{(j+1)}-\Phi^{(j)}  \|_2 \leqs \sum_{j=N}^{\infty}\| \Phi^{(j+1)}-\Phi^{(j)}  \|_2<\epsilon.
\end{align}
It indicates that $\{\Phi^{(k)}\}$ is a Cauchy sequence. From the completeness of the parameter space for $\Phi$, $\Phi^{(k)}$ converges to some point $\Phi^\bullet$. Following similar deductions, the sequences $\{\Psi^{(k)}\}$ associated with $g$, $\{\Phi^{(k)}\}$ associated with $h$, and $\{(\rho^{(k)},\Psi^{(k)})\}$ associated with $h$ also converge.

Next, we turn to analyze the computational complexity of this primal-dual algorithm. Without loss of generality, we consider one iteration as having a complexity of $\mO(1)$, since the complexity within one iteration depends on specific forms of $g$ or $h$ and is relatively constant across different (sub)gradient-type algorithms. Suppose the algorithm needs $N$ iterations in order to achieve a convergence tolerance of $\epsilon$. From the above deduction,
we have
\begin{align}
\label{eqn:convphi3}
\|\Phi^{(N)}- \Phi^{\bullet}\|_2 \leqs \sum_{k=N}^{\infty}\| \Phi^{(k+1)}-\Phi^{(k)}  \|_2<\int_{N-1}^{\infty} \frac{1}{\zeta^p}\ud \zeta=\frac{1}{p-1}\cdot \frac{1}{(N-1)^{p-1}}<\epsilon.
\end{align}
The last inequality in (\ref{eqn:convphi3}) indicates that the convergence tolerance $\epsilon$ can be achieved as long as
\begin{align}
\label{eqn:convphi4}
N>((p-1)\epsilon)^{-\frac{1}{p-1}}+1.
\end{align}
By taking the smallest integer for $N$ in (\ref{eqn:convphi4}), we obtain the computational complexity $\mO(((p-1)\epsilon)^{-\frac{1}{p-1}})$.





\end{proof}












%\subsection{Additional Experimental Results}
%\label{app:addexp}



\subsection{Simulation Data Generation}
\label{app:simugen}
The binary outcome of interest $Y(t)$ with time $t \in [0, 1]$ is caused and influenced by the invariant features $X_{v}(t)\in \mathbb{R}$ and the spurious features $X_{s}(t) \in \mathbb{R}$:
\begin{align*}
&X_{v}(t)\sim\begin{cases}
\mathcal{N}(1, 1), ~\text{w.p.}~0.5; \\ \mathcal{N}(-1, 1), \text{w.p.}~0.5. 
\end{cases} 
Y(t)\sim\begin{cases}
\text{sign}(X_{v}(t)), &\text{w.p.}~p_{v}; \\ -\text{sign}(X_{v}(t)), &\text{w.p.}~1-p_{v}.
\end{cases} \\
&\qquad \qquad \qquad  \quad X_{s}(t)\sim\begin{cases}
\mathcal{N}(Y(t), 1), &\text{w.p.}~p_{s}(t); \\ \mathcal{N}(-Y(t), 1), &\text{w.p.}~1-p_{s}(t).
\end{cases}
\end{align*}
$X_{v}(t)$ and $X_{s}(t)$ are further extended to $5$ and $10$ dimensional sequences by adding standard Gaussian noise, respectively. We control the correlation between $X_{v}(t)$ and $Y(t)$ by a parameter $p_{v}$, keeping it constant, but change the correlation between $X_{s}(t)$ and $Y(t)$ as a function of $t$ over the interval $[0, 1]$ by a parameter $p_{s}(t)$. Hence, the training data is generated with parameter settings $(p_{s}^{-}, p_{s}^{+}, p_{v})$, where $p_{s}^{-}$ and $p_{s}^{+}$ denote the $p_{s}(t)$ setting for $t\in[0, 0.5)$ and $t\in[0.5, 1]$, respectively. As for the test data, we set $p_{s}\in\{0.999, 0.8, 0.2, 0.001\}$ and keep the same $p_{v}$. Time $t$ can be exploited as the auxiliary variable in EIIL, LfF, TIVA, ZIN, OOD-TV-Minimax-$\ell_2$, Minimax-TV-$\ell_1$, and OOD-TV-Minimax-$\ell_1$ for environment inference. 











\subsection{More Results of Adversarial Learning Process}
\label{app:advlearn}






\begin{figure*}[h]
\centering
\subfloat{
\includegraphics[width=0.47\textwidth]{./objectiveirm.pdf}}
\hspace{4pt}\subfloat{
\includegraphics[width=0.495\linewidth]{./parameterirm.pdf}}\\
\subfloat{
\includegraphics[width=0.47\linewidth]{./objectivemini.pdf}}
\subfloat{
\hspace{4pt}\includegraphics[width=0.495\linewidth]{./parametermini.pdf}}
\caption{Objective value and parameter change of adversarial learning for OOD-TV-IRM and OOD-TV-Minimax on simulation data.}
\label{fig:advtrain}
\end{figure*}





\begin{figure*}[h]
\centering
\subfloat{
\includegraphics[width=0.44\linewidth]{./mnistObjectiveMinimaxl1.pdf}}
\subfloat{
\hspace{4pt}\includegraphics[width=0.525\linewidth]{./mnistParameterMinimaxl1.pdf}}\\
\subfloat{
\includegraphics[width=0.435\linewidth]{./mnistObjectiveMinimaxl2.pdf}}
\subfloat{
\hspace{4pt}\includegraphics[width=0.54\linewidth]{./mnistParameterMinimaxl2.pdf}}
\caption{Objective value and parameter change of adversarial learning for OOD-TV-Minimax on the Colored MNIST data set. The top two figures correspond to OOD-TV-Minimax-$\ell_1$, while the bottom two figures correspond to OOD-TV-Minimax-$\ell_2$.}
\label{fig:advtrain2}
\end{figure*}










\end{document}
