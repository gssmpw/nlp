\section{Conclusion}\label{sec:conclusion}

For users to trust LLMs, they need assurance that
these models will not confidently produce wrong answers. To address this, \name{} offers a benchmark for fine-grained calibration evaluation,
grounded in human calibration. Our analyses on
\name{} reveal that models are often miscalibrated relative to
well-informed humans. Specifically, model calibration errors came from difficulty with abstract descriptions, far-fetched incorrect guesses, and confidently incorrect answers given few clues.
% Furthermore, \name{} reveals how models commit a
% range of calibration errors that humans do not: difficulty with abstract descriptions, far-fetched incorrect guesses, and confidently incorrect answers given little information.
%\efcomment{todo}\jbgcomment{Remind the user what these errors are}
%
Our new metric, \metric{}, combined with \name{}, evaluates the performance of six LLMs, revealing significant room for improvement.

%
%\efcomment{todo}\jbgcomment{I think we can spell out the future work in a little more detail: e.g., how our metric can be an explicit objective, how we can have human--computer teams to explicitly measure how effective the verbalized confidence is}
%
\name{} provides a blueprint for developing human-focused improvements to calibration: improving verbalized confidences that measurably help human decision-making, personalizing abstention based on individual human skill, and measuring these interactions via human-model teaming. %  using IRT~\citep{lalor2024item}
% For future work, \name{} aims to guide the development of well-calibrated language models. 
% This can extended to AI personalization research, given varying calibration levels among participants, with item response theory~\citep{lalor2024item}.
% We also encourage HCI-NLP research to test when or whether users should rely on models by assessing LLM trustworthiness in a realistic setting.% with \name{} and \metric{} as baseline benchmarks.
%Improving the calibration of language models to
%avoid confidently incorrect responses is an important area for future
%work. 
