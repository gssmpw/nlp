% \jbgcomment{Before we move on to our new metric, I think it would be worthwhile to have an analysis that looks more like ECE to get a more straightforward estimate of human calibration.  I think it would go something like:

% - Let's assume that all agents have some internal notion of confidence
% - They have a threshold, and whenever they are over that threshold, they buzz
% - We don't know that for humans, but we do for computers
% - However, we can can plot human ECE error for the ``buzzing'' bin based on where the threshold is (and you can assume that the confidence in uniformly distributed within the bin for humans).  And then compare that calibration error vs. computer models.
% - You can then compute an accuracy \emph{conditioned on the decision to buzz} and we can show the distribution over humans and models

% Then, based on this initial analysis, we can move on to why this falls short of what we want in a metric.

% }

% \efcomment{Just to keep our terminology consistent throughout the paper:

% A buzzpoint is the point within a question at which a human team buzzed.

% A match is a single game between two teams, played on one 20-question packet.

% A round consists of all matches played on one packet (all matches played at the same time).
% }

%\jbgcomment{Survey should also be described here.}




%Prizes were awarded to the top human teams at each tournament. %The primary objectives of the tournament were twofold: to assess whether models could outperform humans when leveraging calibrated confidence and to 
%
% \begin{enumerate}
%     \item They validated that the questions are answerable by humans and provided an extra check on dataset quality.
%     \item They allow us to provide statistics on human performance, including that of humans with varying skill levels, for our dataset. Our dataset thus provides human buzzpoints for future research on calibration measurement.
%     \item They allow us to compare the confidence calibration of humans and models on the same dataset.
% \end{enumerate}

%
%\subsection{Human vs. model matches}


% In the next two sections, we discuss how these buzzpoints are used to ground model calibration in human performance and analyze differences in human and model performance.




