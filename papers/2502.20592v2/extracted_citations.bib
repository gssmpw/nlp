@article{ACKLEY1985147,
title = {A learning algorithm for boltzmann machines},
journal = {Cognitive Science},
volume = {9},
number = {1},
pages = {147-169},
year = {1985},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(85)80012-4},
url = {https://www.sciencedirect.com/science/article/pii/S0364021385800124},
author = {David H. Ackley and Geoffrey E. Hinton and Terrence J. Sejnowski}}

@inproceedings{DBLP:conf/iclr/HoltzmanBDFC20,
  author       = {Ari Holtzman and
                  Jan Buys and
                  Li Du and
                  Maxwell Forbes and
                  Yejin Choi},
  title        = {The Curious Case of Neural Text Degeneration},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},
  url          = {https://openreview.net/forum?id=rygGQyrFvH},
  timestamp    = {Sat, 29 Apr 2023 10:09:26 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/HoltzmanBDFC20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Erkan2004LexRankGL,
  title={LexRank: Graph-based Lexical Centrality as Salience in Text Summarization},
  author={G{\"u}nes Erkan and Dragomir R. Radev},
  journal={ArXiv},
  year={2004},
  volume={abs/1109.2128},
  url={https://api.semanticscholar.org/CorpusID:506350}
}

@inproceedings{Giorgi2022OpenDM,
  title={Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval},
  author={John Giorgi and Luca Soldaini and Bo Wang and Gary Bader and Kyle Lo and Lucy Lu Wang and Arman Cohan},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:258865156}
}

@article{Yuan2021BARTScoreEG,
  title={BARTScore: Evaluating Generated Text as Text Generation},
  author={Weizhe Yuan and Graham Neubig and Pengfei Liu},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.11520},
  url={https://api.semanticscholar.org/CorpusID:235593404}
}

@misc{belem2024singlemultillmshallucinate,
      title={From Single to Multi: How LLMs Hallucinate in Multi-Document Summarization}, 
      author={Catarina G. Belem and Pouya Pezeskhpour and Hayate Iso and Seiji Maekawa and Nikita Bhutani and Estevam Hruschka},
      year={2024},
      eprint={2410.13961},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.13961}, 
}

@inproceedings{bhandari-etal-2020-metrics,
    title = "Metrics also Disagree in the Low Scoring Range: Revisiting Summarization Evaluation Metrics",
    author = "Bhandari, Manik  and
      Gour, Pranav Narayan  and
      Ashfaq, Atabak  and
      Liu, Pengfei",
    editor = "Scott, Donia  and
      Bel, Nuria  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.501/",
    doi = "10.18653/v1/2020.coling-main.501",
    pages = "5702--5711",
    abstract = "In text summarization, evaluating the efficacy of automatic metrics without human judgments has become recently popular. One exemplar work (Peyrard, 2019) concludes that automatic metrics strongly disagree when ranking high-scoring summaries. In this paper, we revisit their experiments and find that their observations stem from the fact that metrics disagree in ranking summaries from any narrow scoring range. We hypothesize that this may be because summaries are similar to each other in a narrow scoring range and are thus, difficult to rank. Apart from the width of the scoring range of summaries, we analyze three other properties that impact inter-metric agreement - Ease of Summarization, Abstractiveness, and Coverage."
}

@misc{brown2024largelanguagemonkeysscaling,
      title={Large Language Monkeys: Scaling Inference Compute with Repeated Sampling}, 
      author={Bradley Brown and Jordan Juravsky and Ryan Ehrlich and Ronald Clark and Quoc V. Le and Christopher RÃ© and Azalia Mirhoseini},
      year={2024},
      eprint={2407.21787},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.21787}, 
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{gerani-etal-2014-abstractive,
    title = "Abstractive Summarization of Product Reviews Using Discourse Structure",
    author = "Gerani, Shima  and
      Mehdad, Yashar  and
      Carenini, Giuseppe  and
      Ng, Raymond T.  and
      Nejat, Bita",
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1168/",
    doi = "10.3115/v1/D14-1168",
    pages = "1602--1613"
}

@inproceedings{jin2024contranovo,
  title={Contranovo: A contrastive learning approach to enhance de novo peptide sequencing},
  author={Jin, Zhi and Xu, Sheng and Zhang, Xiang and Ling, Tianze and Dong, Nanqing and Ouyang, Wanli and Gao, Zhiqiang and Chang, Cheng and Sun, Siqi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={144--152},
  year={2024}
}

@inproceedings{li-etal-2023-making,
    title = "Making Language Models Better Reasoners with Step-Aware Verifier",
    author = "Li, Yifei  and
      Lin, Zeqi  and
      Zhang, Shizhuo  and
      Fu, Qiang  and
      Chen, Bei  and
      Lou, Jian-Guang  and
      Chen, Weizhu",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.291/",
    doi = "10.18653/v1/2023.acl-long.291",
    pages = "5315--5333",
    abstract = "Few-shot learning is a challenging task that requires language models to generalize from limited examples. Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems. To improve their reasoning skills, previous work has proposed to guide the language model with prompts that elicit a series of reasoning steps before giving the final answer, achieving a significant improvement on GSM8K from 17.9{\%} to 58.1{\%} in problem-solving rate. In this paper, we present DiVeRSe (Diverse Verifier on Reasoning Step), a novel approach that further enhances the reasoning capability of language models. DiVeRSe has three main components: first, it generates diverse prompts to explore different reasoning paths for the same question; second, it uses a verifier to filter out incorrect answers based on a weighted voting scheme; and third, it verifies each reasoning step individually instead of the whole chain. We evaluate DiVeRSe on the latest language model code-davinci-002 and show that it achieves new state-of-the-art results on six of eight reasoning benchmarks (e.g., GSM8K 74.4{\%} to 83.2{\%})."
}

@misc{li2022humanguidedexploitationinterpretable,
      title={Human Guided Exploitation of Interpretable Attention Patterns in Summarization and Topic Segmentation}, 
      author={Raymond Li and Wen Xiao and Linzi Xing and Lanjun Wang and Gabriel Murray and Giuseppe Carenini},
      year={2022},
      eprint={2112.05364},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2112.05364}, 
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013/",
    pages = "74--81"
}

@inproceedings{liu-etal-2024-benchmarking,
    title = "Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization",
    author = "Liu, Yixin  and
      Fabbri, Alexander  and
      Chen, Jiawen  and
      Zhao, Yilun  and
      Han, Simeng  and
      Joty, Shafiq  and
      Liu, Pengfei  and
      Radev, Dragomir  and
      Wu, Chien-Sheng  and
      Cohan, Arman",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.280/",
    doi = "10.18653/v1/2024.findings-naacl.280",
    pages = "4481--4501",
    abstract = "While large language models (LLMs) can already achieve strong performance on standard generic summarization benchmarks, their performance on more complex summarization task settings is less studied. Therefore, we benchmark LLMs on instruction controllable text summarization, where the model input consists of both a source article and a natural language requirement for desired summary characteristics. To this end, we curate an evaluation-only dataset for this task setting and conduct human evaluations of five LLM-based systems to assess their instruction-following capabilities in controllable summarization. We then benchmark LLM-based automatic evaluation for this task with 4 different evaluation protocols and 11 LLMs, resulting in 40 evaluation methods. Our study reveals that instruction controllable text summarization remains a challenging task for LLMs, since (1) all LLMs evaluated still make factual and other types of errors in their summaries; (2) no LLM-based evaluation methods can achieve a strong alignment with human annotators when judging the quality of candidate summaries; (3) different LLMs show large performance gaps in summary generation and evaluation capabilities. We make our collected benchmark InstruSum publicly available to facilitate future research in this direction."
}

@inproceedings{liu-lapata-2019-hierarchical,
    title = "Hierarchical Transformers for Multi-Document Summarization",
    author = "Liu, Yang  and
      Lapata, Mirella",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1500/",
    doi = "10.18653/v1/P19-1500",
    pages = "5070--5081",
    abstract = "In this paper, we develop a neural summarization model which can effectively process multiple input documents and distill Transformer architecture with the ability to encode documents in a hierarchical manner. We represent cross-document relationships via an attention mechanism which allows to share information as opposed to simply concatenating text spans and processing them as a flat sequence. Our model learns latent dependencies among textual units, but can also take advantage of explicit graph representations focusing on similarity or discourse relations. Empirical results on the WikiSum dataset demonstrate that the proposed architecture brings substantial improvements over several strong baselines."
}

@misc{liu2024reifereevaluatinginstructionfollowingevaluation,
      title={ReIFE: Re-evaluating Instruction-Following Evaluation}, 
      author={Yixin Liu and Kejian Shi and Alexander R. Fabbri and Yilun Zhao and Peifeng Wang and Chien-Sheng Wu and Shafiq Joty and Arman Cohan},
      year={2024},
      eprint={2410.07069},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.07069}, 
}

@inproceedings{mehdad-etal-2014-abstractive,
    title = "Abstractive Summarization of Spoken and Written Conversations Based on Phrasal Queries",
    author = "Mehdad, Yashar  and
      Carenini, Giuseppe  and
      Ng, Raymond T.",
    editor = "Toutanova, Kristina  and
      Wu, Hua",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P14-1115/",
    doi = "10.3115/v1/P14-1115",
    pages = "1220--1230"
}

@misc{shi2024judgingjudgessystematicstudy,
      title={Judging the Judges: A Systematic Study of Position Bias in LLM-as-a-Judge}, 
      author={Lin Shi and Chiyu Ma and Wenhua Liang and Weicheng Ma and Soroush Vosoughi},
      year={2024},
      eprint={2406.07791},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.07791}, 
}

@misc{stroebl2024inferencescalingflawslimits,
      title={Inference Scaling fLaws: The Limits of LLM Resampling with Imperfect Verifiers}, 
      author={Benedikt Stroebl and Sayash Kapoor and Arvind Narayanan},
      year={2024},
      eprint={2411.17501},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.17501}, 
}

@misc{tian2024selfimprovementllmsimaginationsearching,
      title={Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing}, 
      author={Ye Tian and Baolin Peng and Linfeng Song and Lifeng Jin and Dian Yu and Haitao Mi and Dong Yu},
      year={2024},
      eprint={2404.12253},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.12253}, 
}

@inproceedings{wang-etal-2024-large-language-models-fair,
    title = "Large Language Models are not Fair Evaluators",
    author = "Wang, Peiyi  and
      Li, Lei  and
      Chen, Liang  and
      Cai, Zefan  and
      Zhu, Dawei  and
      Lin, Binghuai  and
      Cao, Yunbo  and
      Kong, Lingpeng  and
      Liu, Qi  and
      Liu, Tianyu  and
      Sui, Zhifang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.511/",
    doi = "10.18653/v1/2024.acl-long.511",
    pages = "9440--9450",
    abstract = "In this paper, we uncover a positional bias in the evaluation paradigm of adopting large language models (LLMs), e.g., GPT-4, as a referee to score and compare the quality of responses generated by candidate models. We find that the quality ranking of candidate responses can be easily hacked by simply altering their order of appearance in the context. This manipulation allows us to skew the evaluation result, making one model appear considerably superior to the other, e.g., Vicuna-13B could beat ChatGPT on 66 over 80 tested queries with ChatGPT as an evaluator. We propose a simple yet effective calibration framework to address our discovered positional bias.To evaluate the effectiveness of our framework, we manually annotate the {\textquotedblleft}win/tie/lose{\textquotedblright} outcomes of responses from ChatGPT and Vicuna-13B in the Vicuna Benchmark`s question prompt. Extensive experiments demonstrate that our approach successfully alleviates evaluation bias, resulting in closer alignment with human judgments."
}

@misc{wang2024mixtureofagentsenhanceslargelanguage,
      title={Mixture-of-Agents Enhances Large Language Model Capabilities}, 
      author={Junlin Wang and Jue Wang and Ben Athiwaratkun and Ce Zhang and James Zou},
      year={2024},
      eprint={2406.04692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.04692}, 
}

@article{wang2024q,
  title={Q*: Improving multi-step reasoning for llms with deliberative planning},
  author={Wang, Chaojie and Deng, Yanchen and Lyu, Zhiyi and Zeng, Liang and He, Jujie and Yan, Shuicheng and An, Bo},
  journal={arXiv preprint arXiv:2406.14283},
  year={2024}
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@inproceedings{xiao-etal-2024-personalized,
    title = "Personalized Abstractive Summarization by Tri-agent Generation Pipeline",
    author = "Xiao, Wen  and
      Xie, Yujia  and
      Carenini, Giuseppe  and
      He, Pengcheng",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.39/",
    pages = "570--581",
    abstract = "Tailoring outputs from large language models, like ChatGPT, to implicit user preferences remains a challenge despite their impressive generative capabilities. In this paper, we propose a tri-agent generation pipeline comprising a generator, an instructor, and an editor to enhance output personalization. The generator produces an initial output, the instructor automatically generates editing instructions based on user preferences, and the editor refines the output to align with those preferences. The inference-only large language model (ChatGPT) serves as both the generator and editor, with a smaller model acting as the instructor to guide output generation. We train the instructor using editor-steered reinforcement learning, leveraging feedback from a large-scale editor model to optimize instruction generation. Experimental results on two abstractive summarization datasets demonstrate the effectiveness of our approach in generating outputs that better meet user expectations."
}

@misc{yao2023reactsynergizingreasoningacting,
      title={ReAct: Synergizing Reasoning and Acting in Language Models}, 
      author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
      year={2023},
      eprint={2210.03629},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.03629}, 
}

@misc{zelikman2024quietstarlanguagemodelsteach,
      title={Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking}, 
      author={Eric Zelikman and Georges Harik and Yijia Shao and Varuna Jayasiri and Nick Haber and Noah D. Goodman},
      year={2024},
      eprint={2403.09629},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.09629}, 
}

@article{zhang-etal-2024-benchmarking,
    title = "Benchmarking Large Language Models for News Summarization",
    author = "Zhang, Tianyi  and
      Ladhak, Faisal  and
      Durmus, Esin  and
      Liang, Percy  and
      McKeown, Kathleen  and
      Hashimoto, Tatsunori B.",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.tacl-1.3/",
    doi = "10.1162/tacl_a_00632",
    pages = "39--57",
    abstract = "Large language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we find instruction tuning, not model size, is the key to the LLM`s zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and finetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we find that LLM summaries are judged to be on par with human written summaries."
}

@misc{zhang2020bertscoreevaluatingtextgeneration,
      title={BERTScore: Evaluating Text Generation with BERT}, 
      author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
      year={2020},
      eprint={1904.09675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09675}, 
}

@misc{zhang2020pegasuspretrainingextractedgapsentences,
      title={PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization}, 
      author={Jingqing Zhang and Yao Zhao and Mohammad Saleh and Peter J. Liu},
      year={2020},
      eprint={1912.08777},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1912.08777}, 
}

@misc{zhang2024llamaberrypairwiseoptimizationo1like,
      title={LLaMA-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning}, 
      author={Di Zhang and Jianbo Wu and Jingdi Lei and Tong Che and Jiatong Li and Tong Xie and Xiaoshui Huang and Shufei Zhang and Marco Pavone and Yuqiang Li and Wanli Ouyang and Dongzhan Zhou},
      year={2024},
      eprint={2410.02884},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.02884}, 
}

@misc{zhang2024restmctsllmselftrainingprocess,
      title={ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search}, 
      author={Dan Zhang and Sining Zhoubian and Ziniu Hu and Yisong Yue and Yuxiao Dong and Jie Tang},
      year={2024},
      eprint={2406.03816},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.03816}, 
}

@misc{zhao2025samplescrutinizescaleeffective,
      title={Sample, Scrutinize and Scale: Effective Inference-Time Search by Scaling Verification}, 
      author={Eric Zhao and Pranjal Awasthi and Sreenivas Gollapudi},
      year={2025},
      eprint={2502.01839},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.01839}, 
}

