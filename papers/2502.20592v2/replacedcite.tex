\section{Related Work}
\subsection{Test-time scaling}
Test-time scaling strategies can be broadly classified into three categories: repeated sampling, deliberative approaches, and self-refinement. Repeated sampling leverages techniques like temperature sampling ____, top-$k$, and top-$p$ sampling ____ to generate diverse outputs, which are then enhanced through aggregation strategies such as majority voting ____, weighted majority voting ____, or best-of-$n$ selection ____. 

Recent work ____ demonstrates that repeated sampling can significantly expand LLM capabilities across various domains. \textbf{Deliberative approaches} incorporate structured reasoning through methods like chain-of-thought prompting ____ and tree search. These approaches range from informed search methods ____ to Monte Carlo Tree Search (MCTS) variants ____. A key characteristic of tree search methods is to use process reward models (PRMs) to guide the search trajectory during generation ____. 
\textbf{Self-refinement}  ____ enables models to iteratively improve their responses through self-critique and editing. Additionally, all categories of test-time scaling methods can be enhanced through model ensembling ____ to combine the strengths of multiple models to achieve better performance.

Tree search methods often struggle with the high-dimensional search space created by multiple source documents, making it computationally intensive to explore meaningful trajectories. Self-refinement approaches, which rely on iterative improvements, may lead to information loss as they tend to focus on refining a single perspective rather than maintaining diverse viewpoints from multiple documents. Therefore, we adopt the repeated sampling approach to scale MDS at test time, using diverse prompts to generate multiple perspectives that are then consolidated through specialized aggregation methods.

\subsection{Multi Document Summarization}

Multi-document summarization (MDS) has evolved significantly from traditional methods ____ to modern  approaches powered by neural networks, which introduced encoder-decoder architectures for better summary generation ____.
The advent of LLMs has boosted MDS capabilities even further, with models demonstrating impressive zero- and few-shot performance ____. Recent work has shifted the focus from architectural modifications to improve LLMs' summarization abilities to exploring various prompting strategies ____. Despite these advances, MDS continues to face challenges including maintaining cross-document consistency, ensuring factual accuracy, and addressing content incompleteness where key information may be omitted ____. In this paper, we propose to tackle these challenges through a scaling approach that leverages prompt ensemble techniques to generate more comprehensive and accurate summaries. 

Traditional evaluation metrics for summarization, such as ROUGE ____, only rely on lexical overlap with reference summaries. These metrics often fail to capture semantic similarity and summary quality adequately ____. This limitation has led to the development of learned metrics that better align with human judgments ____.
The emergence of LLMs has enabled even more sophisticated evaluation approaches. Recent work has explored using LLMs as evaluation agents ____, demonstrating their ability to assess multiple quality dimensions including coherence, faithfulness, and informativeness. However, these approaches face challenges such as positional bias and inconsistency across different model sizes ____. In this paper, we address these limitations by proposing two novel metrics that remain consistent regardless of position or choice of evaluation model.