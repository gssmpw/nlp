\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l l c c c c c }
        \toprule
        & Models & \begin{tabular}{@{}c@{}}Object \\ Shape\end{tabular} & \begin{tabular}{@{}c@{}}Con \\ cyclic\end{tabular} & \begin{tabular}{@{}c@{}}Two \\ Lines\end{tabular} & \begin{tabular}{@{}c@{}}Square \\ Shape\end{tabular} & \begin{tabular}{@{}c@{}}Angle \\ Detection\end{tabular} \\
        % &Models & ObjectShape & Concyclic & TwoLines & SquareShape & AngleDetection \\
        \midrule
        \multirow{4}{*}{%
    \rotatebox[origin=c]{90}{%
        \parbox{1.3cm}{\centering \footnotesize \emph{Baseline}}%
    }%
}  
        &OpenCLIP & \textbf{100.00} & 99.13 & 86.57 & 85.20 & 64.81 \\
        &SigLIP & \textbf{100.00} & \textbf{99.71} & 89.26 & 89.31 & 76.86 \\
        &DinoV2 & \textbf{100.00} & 98.01 & 85.30 & 91.24 & 22.43 \\
        &ConvNeXT & \textbf{100.00} & 99.20 & 89.39 & 88.13 & 61.84 \\
        \midrule
        \multirow{3}{*}{%
    \rotatebox[origin=c]{90}{%
        \parbox{1.3cm}{\centering \footnotesize \emph{SSL}}%
    }%
}  
        &Jigsaw & 86.11 & 63.85 & 49.98 & 61.88 & 11.44 \\
        &MAE & 93.99 & 72.25 & 71.73 & 82.70 & 13.08 \\
        &VQ-VAE & 63.05 & 60.97 & 48.10 & 57.35 & 9.22 \\
        \midrule
        \multirow{3}{*}{%
    \rotatebox[origin=c]{90}{%
        \parbox{1.3cm}{\centering \footnotesize \emph{GeoCLIP}}%
    }%
}  
        &GeoCLIP (F $\times$) & 99.52 & 98.61 & 88.33 & 86.76 & 65.68 \\
        &GeoCLIP (2K) & 99.32 & 98.73 & 94.73 & 89.22 & 74.95 \\
        &GeoCLIP & 99.21 & 99.24 & \textbf{96.05} & \textbf{95.95} & \textbf{78.56} \\
        \bottomrule
    \end{tabular}
    }
    \caption{Results on the proposed visual feature benchmark. We report the test accuracy of the models with the best validation performance. }
    \label{tab:linear_probing}
\end{table}

% \begin{table}[t!]
%     \centering
%     \resizebox{\linewidth}{!}{
%     \begin{tabular}{l l c c c c c }
%         \toprule
%         & Models & \begin{tabular}{@{}c@{}}Object \\ Shape\end{tabular} & \begin{tabular}{@{}c@{}}Con \\ cyclic\end{tabular} & \begin{tabular}{@{}c@{}}Two \\ Lines\end{tabular} & \begin{tabular}{@{}c@{}}Square \\ Shape\end{tabular} & \begin{tabular}{@{}c@{}}Angle \\ Detection\end{tabular} \\
%         % &Models & ObjectShape & Concyclic & TwoLines & SquareShape & AngleDetection \\
%         \midrule
%         \multirow{4}{*}{Baseline}
%         &OpenCLIP & \textbf{100.00} & 99.13 & 86.57 & 85.20 & 64.81 \\
%         &SigLIP & \textbf{100.00} & \textbf{99.71} & 89.26 & 89.31 & 76.86 \\
%         &DinoV2 & \textbf{100.00} & 98.01 & 85.30 & 91.24 & 22.43 \\
%         &ConvNeXT & \textbf{100.00} & 99.20 & 89.39 & 88.13 & 61.84 \\
%         \midrule
%         \multirow{3}{*}{SSL}
%         &Jigsaw & 86.11 & 63.85 & 49.98 & 61.88 & 11.44 \\
%         &MAE & 93.99 & 72.25 & 71.73 & 82.70 & 13.08 \\
%         &VQ-VAE & 63.05 & 60.97 & 48.10 & 57.35 & 9.22 \\
%         \midrule
%         \multirow{3}{*}{GeoCLIP}
%         &GeoCLIP (F $\times$) & 99.52 & 98.61 & 88.33 & 86.76 & 65.68 \\
%         &GeoCLIP (2K) & 99.32 & 98.73 & 94.73 & 89.22 & 74.95 \\
%         &GeoCLIP & 99.21 & 99.24 & \textbf{96.05} & \textbf{95.95} & \textbf{78.56} \\
%         \bottomrule
%     \end{tabular}
%     }
%     \caption{Results on the proposed visual feature benchmark. We report the test accuracy of the models with the best validation performance. }
%     \label{tab:linear_probing}
% \end{table}

% \multirow{7}{*}{%
%     \rotatebox[origin=c]{90}{%
%         \parbox{1.3cm}{\centering \emph{Unseen}}%
%     }%
% }  