\begin{comment}
\begin{figure}
  \begin{minipage}[b]{.45\linewidth}
    \centering
    \includegraphics[width=0.9\linewidth]{images/chexpert-steps-ablation.pdf}
    \caption{\textbf{A majority voting scheme leads to better performance}. We find that tallying the minimum reconstruction error across steps leads to better classification than averaging reconstruction error across steps. Results are seen on the CheXpert dataset.}% \caption{Figure caption}
    \label{fig:majority-vs-average}
  \end{minipage}\hfill
  \begin{minipage}[b]{.50\linewidth}
    \centering
    \renewcommand{\arraystretch}{1.25} % Increase row spacing
    \centering
    %\label{tab:classification_results}
    \scalebox{0.7}{
    \begin{tabular}{lccccc}
        \toprule
        & \textbf{Method} & \multicolumn{2}{c}{\textbf{CheXpert}} & \multicolumn{2}{c}{\textbf{ISIC}} \\
        \cmidrule(lr){3-4} \cmidrule(lr){5-6}
         & & \textbf{Accuracy} & \textbf{F1} & \textbf{Accuracy} & \textbf{F1} \\
        \midrule \multirow{4}{*}{\rotatebox{90}{\textbf{CNN }}}
        & ResNet-18                    & 90.9 & 0.910 & 94.4 & 0.943 \\ 
        & ResNet-50                    & 91.6 & 0.914 & 93.6 & 0.935 \\
        & EfficientNet-B0              & 90.5 & 0.907 & 93.1 & 0.930 \\
        & EfficientNet-B4              & 90.4 & 0.904 & 93.2 & 0.930 \\ \hline \multirow{3}{*}{\rotatebox{90}{\textbf{TF }}}
        & ViT-S/16                     & 86.9 & 0.869 & 95.0 & 0.949 \\
        & ViT-B/16                     & 85.1 & 0.857 & 94.8 & 0.948 \\
        & Swin-B                       & 86.1 & 0.863 & 95.9 & 0.958 \\ \hline \multirow{4}{*}{\rotatebox{90}{\textbf{DDPM }}}
        & DiT-B/4                      & 86.1 & 0.860 & 90.4 & 0.901 \\
        & UNet                         & 84.5 & 0.854 & 91.8 & 0.919 \\
        & Stable Diffusion$^*$         & 85.0 & 0.839 & 94.8 & 0.946 \\
        & Stable Diffusion$^{\dagger}$ & 48.8 & 0.656 & 39.7 & 0.521 \\
        \bottomrule
    \end{tabular}
    }
    \captionsetup{type=table}
    \caption{\textbf{Diffusion classifiers are competitive with discriminative baselines}. $^*$ and $^\dagger$ denote fine-tuned and zero-shot versions, respectively. Diffusion classifier results are with 501 classification steps, a majority vote, and minimal hyperparameter tuning/data augmentation.}
    \label{tab:classification_results}
  \end{minipage}
\end{figure}
\end{comment}

\begin{figure}[!h]
  \begin{minipage}[b]{.45\linewidth}
    \centering
    \includegraphics[width=0.9\linewidth]{images/chexpert-steps-ablation.pdf}
    \captionof{figure}{\textbf{A majority voting scheme leads to better performance.} We find that tallying the minimum reconstruction error across steps leads to better classification than averaging reconstruction error across steps. Results are seen on the CheXpert dataset.}
    \label{fig:majority-vs-average}
  \end{minipage}\hfill
  \begin{minipage}[b]{.50\linewidth}
    \centering
    \renewcommand{\arraystretch}{1.28} % Increase row spacing
    \centering
    \scalebox{0.78}{
    \begin{tabular}{lccccc}
        \toprule
        & \textbf{Method} & \multicolumn{2}{c}{\textbf{CheXpert}} & \multicolumn{2}{c}{\textbf{ISIC}} \\
        \cmidrule(lr){3-4} \cmidrule(lr){5-6}
         & & \textbf{Accuracy} & \textbf{F1} & \textbf{Accuracy} & \textbf{F1} \\
        \midrule \multirow{4}{*}{\rotatebox{90}{\textbf{CNN }}}
        & ResNet-18                    & 90.9 & 0.910 & 94.4 & 0.943 \\ 
        & ResNet-50                    & 91.6 & 0.914 & 93.6 & 0.935 \\
        & EfficientNet-B0              & 90.5 & 0.907 & 93.1 & 0.930 \\
        & EfficientNet-B4              & 90.4 & 0.904 & 93.2 & 0.930 \\ \hline \multirow{3}{*}{\rotatebox{90}{\textbf{TF }}}
        & ViT-S/16                     & 86.9 & 0.869 & 95.0 & 0.949 \\
        & ViT-B/16                     & 85.1 & 0.857 & 94.8 & 0.948 \\
        & Swin-B                       & 86.1 & 0.863 & 95.9 & 0.958 \\ \hline \multirow{4}{*}{\rotatebox{90}{\textbf{DM }}}
        & DiT-B/4                      & 86.1 & 0.860 & 90.4 & 0.901 \\
        & UNet                         & 84.5 & 0.854 & 91.8 & 0.919 \\
        & Stable Diffusion$^*$         & 85.0 & 0.839 & 94.8 & 0.946 \\
        & Stable Diffusion$^{\dagger}$ & 48.8 & 0.656 & 39.7 & 0.521 \\
        \bottomrule
    \end{tabular}
    }
    \captionof{table}{\textbf{Diffusion classifiers are competitive with discriminative baselines.} $^*$ and $^\dagger$ denote fine-tuned and zero-shot versions, respectively. Diffusion classifier results (DM) are with 501 classification steps, majority voting, minimal hyperparameter tuning/data augmentation.}
    \label{tab:classification_results}
  \end{minipage}
\end{figure}

\subsection{Ablating on the Classification Algorithm}
\begin{comment}
Many ablations on the diffusion classification algorithm are explored in natural images~\cite{Li:arXiv:2023:diffusionClassifier} including but not limited to: sampling steps ($N$), step range $(t_{min},t_{max})$, and step distribution (strided, normal/uniform random). In medical imaging, we too find that classification performance improves with more sampling steps, a maximal timestep range, $t \in (0,1)$, and uniformly sampling $t$ in its range. 
\end{comment}

We propose a simple but effective majority voting scheme that, instead of accumulating errors at each timestep, tallies the amount of times a reconstruction error was smaller for each test condition and then chooses the class with the most votes. Figure~\ref{fig:majority-vs-average} shows that using majority voting increases classification performance across the board, and specifically so at larger values of $N$. This result is intuitive: at greater values of $N$ there are more reconstructions attempted from high noise disturbance which can introduce large sources of variance in the average error. Majority voting is used for all diffusion results in this paper.

\subsection{Classification Performance on Benchmark Datasets}

Table~\ref{tab:classification_results} shows the classification accuracy and F1-score of each model on the CheXpert and ISIC Melanoma test sets. Note that the models are grouped by architecture: convolution-based (CNN), transformer-based (TF), and diffusion-based (DM). Our experiments across both datasets demonstrate that diffusion classifiers perform competitively with discriminative classifiers. Notably, diffusion classifiers achieve this performance with minimal hyperparameter tuning, no augmentations, and without being trained on a classification objective.

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \vspace{-30pt}
    \includegraphics[width=0.40\textwidth]{images/uncertainty-all-models-improved-accuracy.pdf}
    \caption{\textbf{Diffusion classifiers inherently produce uncertainty estimates.} Filtering uncertain predictions improves performance, showing that when the model is certain, it is correct.} %Diffusion classifiers are more certain about their correct predictions.}
    \label{fig:uncertainty}
\end{wrapfigure}

\subsection{Intrinsic Explainability}%Explainability Comes for Free}

\begin{comment}
    A key advantage of diffusion classifiers lies in their inherent interpretability. Unlike discriminative classifiers, which require techniques such as GradCAM~\cite{gradcam} or classifier-guidance~\cite{dhariwal2021diffusionmodelsbeatgans} with a separate generative model to provide indirect insights into their decision-making process, diffusion classifiers offer a unique paradigm: while their classification is indirect, their explanations are direct. This duality positions diffusion classifiers as not only effective but also transparent; an elegant solution to the challenge of interpretability in deep learning. We show examples of this feature of diffusion classifiers in Figure~\ref{fig:interpretability}.
\end{comment}

A key advantage of diffusion classifiers lies in their intrinsic interpretability, which positions diffusion classifiers as not only effective but also transparent. Importantly, diffusion classifiers are able to produce counterfactual explanations, as opposed to other interpretability methods that simply highlight regions of interest. This can be seen in Figure~\ref{fig:interpretability}: On the left example (skin lesion), the counterfactual of a malignant lesion (melanoma) has changed colour and intensity to become healthy. In the right example (chest X-ray), the counterfactual image of a sick patient (Plural Effusion) shows decreased disease pathology in the left and right lungs. The natural interpretability of diffusion classifiers provides both transparency on how the model is learning (thus allowing the identification of shortcut learning), and specific class information which improves understanding of the disease. In addition to providing disease explainability, the difference maps also reveal how the model makes its decision: the condition with the least reconstruction error is selected as the predicted class. % -- qualitatively this is observed by comparing the difference maps. 
%This image also contains a medical device in the top left corner, which has been removed in both the healthy and sick reconstructions. This demonstrates that the model is unbiased and does not focus on potential shortcuts (\textit{e.g.,} associating sick images with medical devices). Since the diffusion classifier is trained on a separate task from classification, the predictions rely less on spurious correlations and biases. 

\begin{figure}
    \centering
    \includegraphics[width=0.98\textwidth]{images/explainablity-figures.pdf}  % Replace with your image file path
    \caption{\textbf{Diffusion classifiers are naturally explainable} and highlight why they make classification decisions using classifier-free guided sampling. Difference maps show conditional areas of interest (pathology added/removed) during reconstruction. For CheXpert, the heatmap represents a simple difference map, as the images are grayscale and signed differences help capture the directional change. For ISIC, the heatmap represents an absolute difference map, since the images are colored and an absolute difference better reflects overall pixel-wise changes. For CheXpert noise is added at t=0.5. For ISIC: t=0.3. CFG scale is 7.5. All images are generated from the UNet model with 256 sampling steps. }
    \label{fig:interpretability}
\end{figure}

%subsection{Uncertainty Comes for Free}
\subsection{Uncertainty Quantification}
The uncertainty quantification of diffusion classifiers is demonstrated in Figure \ref{fig:uncertainty}. In addition to competitive classification performance and intrinsic explainability, uncertainty quantifications can be estimated without any model modifications. In medical imaging, uncertainty measures are validated by confirming that when the model is confident, the prediction is correct, and when it is incorrect, it is uncertain~\cite{NAIR2020101557}. 
%A good uncertainty measure, particularly for medical imaging, is confident for correct predictions, and uncertain for incorrect predictions. 
We therefore validate the diffusion model's uncertainty quantification by filtering out the most uncertain predictions and examining the change in performance.
%The uncertainty is validated through measuring model performance as uncertain predictions are filtered out. 
Each of the models show accuracy increases as the most uncertain predictions are filtered out for CheXpert (- -) and ISIC (-). %This confirms the effectiveness of their uncertainty measure and potential value across medical applications. %We show that this same phenomenon holds with the trained DiT and pre-trained Stable Diffusion classifiers in Appendix \ref{ref:uncertainty-accuracy}.

\begin{comment}
\subsection{Failure Set Performance}
On hold as this does not seem to work as well with Stable Diffusion.

\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/failure_sets.png}  % Replace with your image file path
    \caption{\textbf{Diffusion classifiers outperform on failure sets}. We find that diffusion classifiers (bottom right) are able to perform most consistently in subsets of the data where discriminative classifiers struggle.}
    \label{fig:failure_group}
\end{figure}
\end{comment}

%\begin{figure}
\begin{comment}
\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \includegraphics[width=0.4\textwidth]{images/chexpert-steps-ablation.pdf}  % Replace with your image file path
    \caption{\textbf{A majority voting scheme leads to better performance}. We find that tallying the minimum reconstruction error across steps leads to better classification than averaging reconstruction error across steps. Results are seen on the CheXpert dataset.}
    \label{fig:majority-vs-average}
\end{wrapfigure}
\end{comment}