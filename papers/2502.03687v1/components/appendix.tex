\raggedbottom

\section{Additional Background on Diffusion Classifiers} \label{ref: majority-vote}
We provide the pseudocode for the diffusion classification algorithm used in the experiments. We opt for a majority voting scheme as opposed to the average reconstruction error approach outlined by~\cite{Li:arXiv:2023:diffusionClassifier}.

\begin{verbatim}
def classify(x, num_classes, classification_steps):
    errors = fill((x.shape[0], num_classes, classification_steps), inf)
    for step in classification_steps:
        t = rand(0,1)
        z_t, eps_t = diffuse(x, t) # add noise to image at t
        # Get the errors for each class
        for c in range(num_classes):
            pred = model(z_t, t, c) # get noise pred for given class
            error = mse(pred, eps_t)
            errors[:,c,step] = error # store the error
    # Find the class with the lowest error for each step
    end_of_stage_votes = errors[:, :, :classification_steps].argmin(dim=1)

    # Count the votes for each class across all steps
    votes = zeros(x.shape[0], num_classes)
    for b in range(x.shape[0]):
        for step in range(classification_steps):
            class_with_lowest_error = end_of_stage_votes[b, step]
            votes[b, class_with_lowest_error] += 1
    final_classes = votes.argmax(dim=1)

    return final_classes           
\end{verbatim}

\section{Experimental Details} \label{ref: experimental-details}

\subsection{Optimization Settings}

\begin{verbatim}
resnet/efficientnet optimization settings on isic: (3x256x256):
    batch size=64
    optimizer=Adam
    learning_rate=1E-4
    weight_decay=1E-5

resnet/efficientnet optimization settings on chexpert: (3x256x256):
    batch size=64
    optimizer=Adam
    learning_rate=1E-4
    weight_decay=1E-3

vit/swin optimization settings (3x256x256):
    batch size=64,
    optimizer=Adam,
    learning_rate=1E-5

diffusion optimization settings (3x256x256):
    batch size=128,
    optimizer=Adam,
    learning_rate=1E-4,
    learning_rate_warmup_steps=250,
    grad_clip=1.0,
    ema={beta: 0.999, warmup: 50, update_freq: 5}
\end{verbatim}

\subsection{Discriminative Baseline Settings}
We use official implementations of ResNet-based (\verb|torchvision|), EfficientNet- and ViT-based (\verb|timm|) classifiers in our experiments. 

For training, we apply the following augmentations: 
\begin{itemize}
    \item Random rotation with degree range of (-30, 30)
    \item Random horizontal flip with probability of 0.5
    \item Random vertical flip with probability of 0.5
    \item Random Gaussian blur with kernel size of 5 and sigma range of (0.1, 2)
\end{itemize}

\subsection{UNet Settings}
The ADM architecture~\cite{dhariwal2021diffusionmodelsbeatgans} is used as a starting point, with minor alterations based on capacity requirements of each experiment. Class conditions are integrated into the model using cross-attention with a trainable module \verb|nn.encoder|.

\begin{verbatim}
unet settings (3x256x256):
    prediction_param=v-prediction,
    noise_schedule=shifted cosine, base-64,
    wavelet_transform=single-stage haar wavelet
    sample_size=128,
    channels=12,
    resnet_layers_per_block=2,
    base_channels=128,
    channel_multiplier=(1,1,2,4,8),
    cross_attn_res=16
    encoder_type=nn,
    cross_attn_dim=512,
\end{verbatim}

\subsection{DiT Settings}
The DiT-B/4 architecture is followed as presented in~\cite{peebles2023scalablediffusionmodelstransformers}.
\begin{verbatim}
dit settings (3x256x256):
    prediction_param=v-prediction,
    noise_schedule=shifted cosine, base-64,
    wavelet_transform=single-stage haar wavelet,
    sample_size=128,
    channels=12,
    num_attention_heads=12,
    attention_head_dim=64,
    num_layers=12,
    patch_size=4,
\end{verbatim}

\section{Training Dynamics}

During training, we monitored classification performance using the F1 score and accuracy metrics. Figure \ref{fig:training-dynamics} illustrates the performance of the UNet and DiT models on the ISIC validation set across different training steps. The results indicate that classification performance can serve as a useful metric for tracking training progress.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.4\linewidth]{images/training-dynamics.pdf}
    \caption{Classification performance of DiT and UNet models on ISIC validation set during training}
    \label{fig:training-dynamics}
\end{figure}

\section{Stable Diffusion v2 Fine-Tuning} \label{ref: sd-fine-tuning}

We fine-tune Stable Diffusion v2-base~\cite{rombach2022highresolutionimagesynthesislatent} using the \verb|Hugging Face| training pipeline for a total of 15k iterations. We construct the fine-tuning dataset by amalgamating our CheXpert and ISIC Melanoma training splits. Given that the model is designed for text-to-image generation, we replace labels in the datasets with text prompts, ie. ``a benign skin lesion'', or, ``a frontal chest xray of a sick patient with pleural effusion''. Fine-tuning dramatically increased Stable Diffusion's domain knowledge and subsequent classification performance on our benchmark datasets. 

\begin{figure}[!h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/before-finetuning.png}  % Replace with your image file path
        \caption{No fine-tuning}
        \label{fig:before-fine-tuning}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/after-finetuning.png}  % Replace with your image file path
        \caption{After fine-tuning for 15k steps}
        \label{fig:after-fine-tuning}
    \end{minipage}
    \caption{Task-related generation from the Stable Diffusion v2-base model before (left) and after (right) fine-tuning. Training for only a few thousand iterations dramatically increased in-distribution inference and classification performance.}
    \label{fig:sd-fine-tuning-image}
\end{figure}

\section{Uncertainty Quantification} \label{ref:uncertainty-accuracy}

We validate our model uncertainty through measuring performance as uncertain predictions are filtered out. For both the pre-trained Stable Diffusion classifier and our diffusion classifiers trained from scratch, accuracy increases for both datasets as the most uncertain predictions are filtered out. This indicates that the model is most uncertain about its incorrect predictions, which is highly valuable across medical applications. See Figure \ref{fig:uncertainty-boxplots} for a breakdown of this quantification in boxplot form.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/combined_uncertainty_boxplot_chexpert.pdf}
        \subcaption{Uncertainty estimates, CheXpert}
        \label{fig:chexpert-boxplot}
    \end{minipage}
    \vspace{0.5cm}  % Adjust the vertical space between the two figures if needed
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/combined_uncertainty_boxplot_isic.pdf}
        \subcaption{Uncertainty estimates, ISIC}
        \label{fig:isic-boxplot}
    \end{minipage}
    \caption{We find that all of our diffusion classifier models are more confident about their correct predictions (TP, TN) than their incorrect predictions (FP, FN).}
    \label{fig:uncertainty-boxplots}
\end{figure}

\section{More Explainability Results}

More explainability results can be found in Figure \ref{fig:more-explain-chexpert}, and Figure \ref{fig:more-explain-isic}. Input sick images have been altered to healthy class by adding noise to the input image and denoising with the healhty class. For CheXpert t=0.5 and for ISIC t=0.3 are used.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/explainability-appendix/16.pdf}  
    \end{minipage}
    \vfill
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/explainability-appendix/77.pdf}  
    \end{minipage}
    \vfill
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/explainability-appendix/84.pdf}  
    \end{minipage}
    \caption{More explainability results for CheXpert by converting input sick images to healthy images. t=0.5 and CFG=7.5 are used for generating these images.}
    \label{fig:more-explain-chexpert}
\end{figure}


\begin{figure}[h]
    \centering
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/explainability-appendix/15-isic.pdf}  
    \end{minipage}
    \vfill
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/explainability-appendix/16-isic.pdf}  
    \end{minipage}
    \vfill
    \begin{minipage}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/explainability-appendix/83-isic.pdf}  
    \end{minipage}
    \caption{More explainability results for ISIC by converting input sick images to healthy images. t=0.3 and CFG=7.5 are used for generating these images.}
    \label{fig:more-explain-isic}
\end{figure}


\section{Computational Resources}
All models were trained or fine-tuned a compute cluster of 80 GB A100 GPUs for all experiments in this paper. For inference, a single 80 GB A100 GPU is used.