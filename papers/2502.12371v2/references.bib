@article{chi2023diffusion,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Xu, Zhenjia and Feng, Siyuan and Cousineau, Eric and Du, Yilun and Burchfiel, Benjamin and Tedrake, Russ and Song, Shuran},
  journal={The International Journal of Robotics Research},
  pages={02783649241273668},
  year={2023},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{dppo,
  title={Diffusion policy policy optimization},
  author={Ren, Allen Z and Lidard, Justin and Ankile, Lars L and Simeonov, Anthony and Agrawal, Pulkit and Majumdar, Anirudha and Burchfiel, Benjamin and Dai, Hongkai and Simchowitz, Max},
  journal={arXiv preprint arXiv:2409.00588},
  year={2024}
}

@misc{cadene2024lerobot,
    author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Wolf, Thomas},
    title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch},
    howpublished = "\url{https://github.com/huggingface/lerobot}",
    year = {2024}
}


@inproceedings{o2024open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models: Open x-embodiment collaboration 0},
  author={O’Neill, Abby and Rehman, Abdul and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and Jain, Ajinkya and others},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6892--6903},
  year={2024},
  organization={IEEE}
}
@article{liu2024rdt,
    title={RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation},
    author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
    journal={arXiv preprint arXiv:2410.07864},
    year={2024}
}
@article{liu2024bidirectional,
  title={Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling},
  author={Liu, Yuejiang and Hamid, Jubayer Ibn and Xie, Annie and Lee, Yoonho and Du, Maximilian and Finn, Chelsea},
  journal={arXiv preprint arXiv:2408.17355},
  year={2024}
}
@inproceedings{lipmanflow,
  title={Flow Matching for Generative Modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matthew},
  booktitle={The Eleventh International Conference on Learning Representations}
} 
@inproceedings{liuflow,
  title={Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
  author={Liu, Xingchao and Gong, Chengyue and others},
  booktitle={The Eleventh International Conference on Learning Representations}
}
@article{hu2024adaflow,
  title={AdaFlow: Imitation Learning with Variance-Adaptive Flow-Based Policies},
  author={Hu, Xixi and Liu, Bo and Liu, Xingchao and Liu, Qiang},
  journal={arXiv preprint arXiv:2402.04292},
  year={2024}
}
@article{black2024pi_0,
  title={pi0: A Vision-Language-Action Flow Model for General Robot Control},
  author={Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and others},
  journal={arXiv preprint arXiv:2410.24164},
  year={2024}
}
@misc{høeg2024streamingdiffusionpolicyfast,
      title={Streaming Diffusion Policy: Fast Policy Synthesis with Variable Noise Diffusion Models}, 
      author={Sigmund H. Høeg and Yilun Du and Olav Egeland},
      year={2024},
      eprint={2406.04806},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2406.04806}, 
}
@article{zhang2024affordance,
  title={Affordance-based Robot Manipulation with Flow Matching},
  author={Zhang, Fan and Gienger, Michael},
  journal={arXiv preprint arXiv:2409.01083},
  year={2024}
}

@article{imle,
  title={Implicit maximum likelihood estimation},
  author={Li, Ke and Malik, Jitendra},
  journal={arXiv preprint arXiv:1809.09087},
  year={2018}
}

@inproceedings{rsimle,
  title={Rejection Sampling IMLE: Designing Priors for Better Few-Shot Image Synthesis},
  author={Vashist, Chirag and Peng, Shichong and Li, Ke},
  booktitle={European Conference on Computer Vision},
  pages={441--456},
  year={2025},
  organization={Springer}
}

@inproceedings{leebehavior,
  title={Behavior Generation with Latent Actions},
  author={Lee, Seungjae and Wang, Yibin and Etukuru, Haritheja and Kim, H Jin and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  booktitle={Forty-first International Conference on Machine Learning}
}

@inproceedings{lynch2020learning,
  title={Learning latent plans from play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  booktitle={Conference on robot learning},
  pages={1113--1132},
  year={2020},
  organization={PMLR}
} 
@article{rana2024affordance,
  title={Affordance-Centric Policy Learning: Sample Efficient and Generalisable Robot Policy Learning using Affordance-Centric Task Frames},
  author={Rana, Krishan and Abou-Chakra, Jad and Garg, Sourav and Lee, Robert and Reid, Ian and Suenderhauf, Niko},
  journal={arXiv preprint arXiv:2410.12124},
  year={2024}
}
@article{ze20243d,
  title={3d diffusion policy},
  author={Ze, Yanjie and Zhang, Gu and Zhang, Kangning and Hu, Chenyuan and Wang, Muhan and Xu, Huazhe},
  journal={arXiv preprint arXiv:2403.03954},
  year={2024}
}

@article{prasad2024consistency,
  title={Consistency policy: Accelerated visuomotor policies via consistency distillation},
  author={Prasad, Aaditya and Lin, Kevin and Wu, Jimmy and Zhou, Linqi and Bohg, Jeannette},
  journal={arXiv preprint arXiv:2405.07503},
  year={2024}
}

@inproceedings{yang2024equibot,
  title={EquiBot: SIM (3)-Equivariant Diffusion Policy for Generalizable and Data Efficient Learning},
  author={Yang, Jingyun and Cao, Ziang and Deng, Congyue and Antonova, Rika and Song, Shuran and Bohg, Jeannette},
  booktitle={CoRL 2024 Workshop on Whole-body Control and Bimanual Manipulation: Applications in Humanoids and Beyond}
} 

@inproceedings{wangequivariant,
  title={Equivariant Diffusion Policy},
  author={Wang, Dian and Hart, Stephen and Surovik, David and Kelestemur, Tarik and Huang, Haojie and Zhao, Haibo and Yeatman, Mark and Wang, Jiuguang and Walters, Robin and Platt, Robert},
  booktitle={8th Annual Conference on Robot Learning}
}

@inproceedings{songImprovedTechniquesTraining2023a,
	title        = {Improved Techniques for Training Consistency Models},
	author       = {Song, Yang and Dhariwal, Prafulla},
	url          = {https://openreview.net/forum?id=WNzy9bRDvG},
	urldate      = {2024-06-04},
	abstract     = {Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training. Current consistency models achieve optimal sample quality by distilling from pre-trained diffusion models and employing learned metrics such as {LPIPS}. However, distillation limits the quality of consistency models to that of the pre-trained diffusion model, and {LPIPS} causes undesirable bias in evaluation. To tackle these challenges, we present improved techniques for consistency training, where consistency models learn directly from data without distillation. We delve into the theory behind consistency training and identify a previously overlooked flaw, which we address by eliminating Exponential Moving Average from the teacher consistency model. To replace learned metrics like {LPIPS}, we adopt Pseudo-Huber losses from robust statistics. Additionally, we introduce a lognormal noise schedule for the consistency training objective, and propose to double total discretization steps every set number of training iterations. Combined with better hyperparameter tuning, these modifications enable consistency models to achieve {FID} scores of 2.51 and 3.25 on {CIFAR}-10 and {ImageNet} \$64{\textbackslash}times 64\$ respectively in a single sampling step. These scores mark a 3.5\${\textbackslash}times\$ and 4\${\textbackslash}times\$ improvement compared to prior consistency training approaches. Through two-step sampling, we further reduce {FID} scores to 2.24 and 2.77 on these two datasets, surpassing those obtained via distillation in both one-step and two-step settings, while narrowing the gap between consistency models and other state-of-the-art generative models.},
	eventtitle   = {The Twelfth International Conference on Learning Representations},
	date         = {2023-10-13},
	langid       = {english}
}
@inproceedings{kim2024consistency,
	title        = {Consistency Trajectory Models: Learning Probability Flow {ODE} Trajectory of Diffusion},
	author       = {Dongjun Kim and Chieh-Hsin Lai and Wei-Hsiang Liao and Naoki Murata and Yuhta Takida and Toshimitsu Uesaka and Yutong He and Yuki Mitsufuji and Stefano Ermon},
	year         = 2024,
	booktitle    = {The Twelfth International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=ymjI8feDTD}
}
@inproceedings{reussGoalConditionedImitationLearning2023a,
	title        = {Goal-Conditioned Imitation Learning using Score-based Diffusion Policies},
	author       = {Reuss, Moritz and Li, Maximilian and Jia, Xiaogang and Lioutikov, Rudolf},
	booktitle    = {Robotics: Science and Systems 2023},
	publisher    = {Robotics: Science and Systems Foundation},
	doi          = {10.15607/RSS.2023.XIX.028},
	isbn         = {978-0-9923747-9-2},
	url          = {http://www.roboticsproceedings.org/rss19/p028.pdf},
	urldate      = {2024-06-04},
	eventtitle   = {Robotics: Science and Systems 2023},
	date         = {2023-07-10}
}
@inproceedings{jannerPlanningDiffusionFlexible2022a,
	title        = {Planning with Diffusion for Flexible Behavior Synthesis},
	author       = {Janner, Michael and Du, Yilun and Tenenbaum, Joshua and Levine, Sergey},
	booktitle    = {Proceedings of the 39th International Conference on Machine Learning},
	publisher    = {{PMLR}},
	pages        = {9902--9915},
	url          = {https://proceedings.mlr.press/v162/janner22a.html},
	urldate      = {2024-06-04},
	note         = {{ISSN}: 2640-3498},
	abstract     = {Model-based reinforcement learning methods often use learning only for the purpose of recovering an approximate dynamics model, offloading the rest of the decision-making work to classical trajectory optimizers. While conceptually simple, this combination has a number of empirical shortcomings, suggesting that learned models may not be well-suited to standard trajectory optimization. In this paper, we consider what it would look like to fold as much of the trajectory optimization pipeline as possible into the modeling problem, such that sampling from the model and planning with it become nearly identical. The core of our technical approach lies in a diffusion probabilistic model that plans by iteratively denoising trajectories. We show how classifier-guided sampling and image inpainting can be reinterpreted as coherent planning strategies, explore the unusual and useful properties of diffusion-based planning methods, and demonstrate the effectiveness of our framework in control settings that emphasize long-horizon decision-making and test-time flexibility.},
	booktitle   = {International Conference on Machine Learning},
	date         = {2022-06-28},
	langid       = {english},
year = {2022},
}
@inproceedings{pearceImitatingHumanBehaviour2022,
	title        = {Imitating Human Behaviour with Diffusion Models},
	author       = {Pearce, Tim and Rashid, Tabish and Kanervisto, Anssi and Bignell, Dave and Sun, Mingfei and Georgescu, Raluca and Macua, Sergio Valcarcel and Tan, Shan Zheng and Momennejad, Ida and Hofmann, Katja and Devlin, Sam},
	booktitle   = {The Eleventh International Conference on Learning Representations},
	date         = {2022-09-29},
	langid       = {english},
        year = {2023},
}
@article{karrasElucidatingDesignSpace2022a,
	title        = {Elucidating the Design Space of Diffusion-Based Generative Models},
	author       = {Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
	volume       = 35,
	pages        = {26565--26577},
	url          = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/a98846e9d9cc01cfb87eb694d946ce6b-Abstract-Conference.html},
	urldate      = {2024-06-04},
	journaltitle = {Advances in Neural Information Processing Systems},
	date         = {2022-12-06},
	langid       = {english}
}
@online{ethanperezFiLMVisualReasoning,
	title        = {{FiLM}: Visual Reasoning with a General Conditioning Layer},
	shorttitle   = {{FiLM}},
	author       = {Ethan Perez, Florian Strub},
	url          = {https://aaai.org/papers/11671-film-visual-reasoning-with-a-general-conditioning-layer/},
	urldate      = {2024-06-04},
	titleaddon   = {{AAAI}},
	langid       = {american}
}
@inproceedings{zhaoLearningFineGrainedBimanual2023,
	title        = {Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware},
	author       = {Zhao, Tony Z. and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
	volume       = 19,
	isbn         = {978-0-9923747-9-2},
	url          = {https://www.roboticsproceedings.org/rss19/p016.html},
	urldate      = {2024-06-04},
	eventtitle   = {Robotics: Science and Systems {XIX}},
	date         = {2023-07-10}
}
@inproceedings{songDenoisingDiffusionImplicit2020,
	title        = {Denoising Diffusion Implicit Models},
	author       = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	url          = {https://openreview.net/forum?id=St1giarCHLP},
	urldate      = {2024-06-04},
	abstract     = {Denoising diffusion probabilistic models ({DDPMs}) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps in order to produce a sample. To accelerate sampling, we present denoising diffusion implicit models ({DDIMs}), a more efficient class of iterative implicit probabilistic models with the same training procedure as {DDPMs}. In {DDPMs}, the generative process is defined as the reverse of a particular Markovian diffusion process. We generalize {DDPMs} via a class of non-Markovian diffusion processes that lead to the same training objective. These non-Markovian processes can correspond to generative processes that are deterministic, giving rise to implicit models that produce high quality samples much faster. We empirically demonstrate that {DDIMs} can produce high quality samples \$10 {\textbackslash}times\$ to \$50 {\textbackslash}times\$ faster in terms of wall-clock time compared to {DDPMs}, allow us to trade off computation for sample quality, perform semantically meaningful image interpolation directly in the latent space, and reconstruct observations with very low error.},
	eventtitle   = {International Conference on Learning Representations},
	date         = {2020-10-02},
	langid       = {english}
}
@inproceedings{songConsistencyModels2023a,
	title        = {Consistency Models},
	author       = {Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
	booktitle    = {Proceedings of the 40th International Conference on Machine Learning},
	publisher    = {{PMLR}},
	pages        = {32211--32252},
	url          = {https://proceedings.mlr.press/v202/song23a.html},
	urldate      = {2024-06-04},
	note         = {{ISSN}: 2640-3498},
	abstract     = {Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation. To overcome this limitation, we propose consistency models, a new family of models that generate high quality samples by directly mapping noise to data. They support fast one-step generation by design, while still allowing multistep sampling to trade compute for sample quality. They also support zero-shot data editing, such as image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either by distilling pre-trained diffusion models, or as standalone generative models altogether. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one- and few-step sampling, achieving the new state-of-the-art {FID} of 3.55 on {CIFAR}-10 and 6.20 on {ImageNet} 64x64 for one-step generation. When trained in isolation, consistency models become a new family of generative models that can outperform existing one-step, non-adversarial generative models on standard benchmarks such as {CIFAR}-10, {ImageNet} 64x64 and {LSUN} 256x256.},
	eventtitle   = {International Conference on Machine Learning},
	date         = {2023-07-03},
	langid       = {english}
}
@inproceedings{hoDenoisingDiffusionProbabilistic2020a,
	title        = {Denoising Diffusion Probabilistic Models},
	author       = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 33,
	pages        = {6840--6851},
	url          = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
	urldate      = {2024-06-04},
	abstract     = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional {CIFAR}10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art {FID} score of 3.17. On 256x256 {LSUN}, we obtain sample quality similar to {ProgressiveGAN}.},
	date         = 2020
}
@inproceedings{chiDiffusionPolicyVisuomotor2023b,
	title        = {Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	shorttitle   = {Diffusion Policy},
	author       = {Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
	booktitle    = {Robotics: Science and Systems 2023},
	publisher    = {Robotics: Science and Systems Foundation},
	doi          = {10.15607/RSS.2023.XIX.026},
	isbn         = {978-0-9923747-9-2},
	url          = {http://www.roboticsproceedings.org/rss19/p026.pdf},
	urldate      = {2024-06-04},
	eventtitle   = {Robotics: Science and Systems 2023},
	date         = {2023-07-10}
}
@inproceedings{zhangTEDiTemporallyEntangledDiffusion2023,
author = {Zhang, Zihan and Liu, Richard and Hanocka, Rana and Aberman, Kfir},
title = {TEDi: Temporally-Entangled Diffusion for Long-Term Motion Synthesis},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657515},
doi = {10.1145/3641519.3657515},
abstract = {The gradual nature of a diffusion process that synthesizes samples in small increments constitutes a key ingredient of Denoising Diffusion Probabilistic Models (DDPM), which have presented unprecedented quality in image synthesis and been recently explored in the motion domain. In this work, we propose to adapt the gradual diffusion concept (operating along a diffusion time-axis) into the temporal-axis of the motion sequence. Our key idea is to extend the DDPM framework to support temporally varying denoising, thereby entangling the two axes. Using our special formulation, we iteratively denoise a motion buffer that contains a set of increasingly-noised poses, which auto-regressively produces an arbitrarily long stream of frames. With a stationary diffusion time-axis, in each diffusion step we increment only the temporal-axis of the motion such that the framework produces a new, clean frame which is removed from the beginning of the buffer, followed by a newly drawn noise vector that is appended to it. This new mechanism paves the way towards a new framework for long-term motion synthesis with applications to character animation and other domains.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {68},
numpages = {11},
keywords = {denoising diffusion models, motion synthesis, neural motion processing},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@misc{prasadConsistencyPolicyAccelerated2024,
	title = {Consistency Policy: Accelerated Visuomotor Policies via Consistency Distillation},
	url = {http://arxiv.org/abs/2405.07503},
	shorttitle = {Consistency Policy},
	abstract = {Many robotic systems, such as mobile manipulators or quadrotors, cannot be equipped with high-end {GPUs} due to space, weight, and power constraints. These constraints prevent these systems from leveraging recent developments in visuomotor policy architectures that require high-end {GPUs} to achieve fast policy inference. In this paper, we propose Consistency Policy, a faster and similarly powerful alternative to Diffusion Policy for learning visuomotor robot control. By virtue of its fast inference speed, Consistency Policy can enable low latency decision making in resource-constrained robotic setups. A Consistency Policy is distilled from a pretrained Diffusion Policy by enforcing selfconsistency along the Diffusion Policy’s learned trajectories. We compare Consistency Policy with Diffusion Policy and other related speed-up methods across 6 simulation tasks as well as two real-world tasks where we demonstrate inference on a laptop {GPU}. For all these tasks, Consistency Policy speeds up inference by an order of magnitude compared to the fastest alternative method and maintains competitive success rates. We also show that the Conistency Policy training procedure is robust to the pretrained Diffusion Policy’s quality, a useful result that helps practioners avoid extensive testing of the pretrained model. Key design decisions that enabled this performance are the choice of consistency objective, reduced initial sample variance, and the choice of preset chaining steps. Code and training details will be released publicly.},
	number = {{arXiv}:2405.07503},
	publisher = {{arXiv}},
	author = {Prasad, Aaditya and Lin, Kevin and Wu, Jimmy and Zhou, Linqi and Bohg, Jeannette},
	urldate = {2024-05-27},
	date = {2024-05-13},
        year = {2024},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2405.07503 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@misc{hansen-estruchIDQLImplicitQLearning2023,
	title = {{IDQL}: Implicit {Q}-Learning as an Actor-Critic Method with Diffusion Policies},
	url = {http://arxiv.org/abs/2304.10573},
	doi = {10.48550/arXiv.2304.10573},
	shorttitle = {{IDQL}},
	abstract = {Effective offline {RL} methods require properly handling out-of-distribution actions. Implicit Q-learning ({IQL}) addresses this by training a Q-function using only dataset actions through a modified Bellman backup. However, it is unclear which policy actually attains the values represented by this implicitly trained Q-function. In this paper, we reinterpret {IQL} as an actor-critic method by generalizing the critic objective and connecting it to a behavior-regularized implicit actor. This generalization shows how the induced actor balances reward maximization and divergence from the behavior policy, with the specific loss choice determining the nature of this tradeoff. Notably, this actor can exhibit complex and multimodal characteristics, suggesting issues with the conditional Gaussian actor fit with advantage weighted regression ({AWR}) used in prior methods. Instead, we propose using samples from a diffusion parameterized behavior policy and weights computed from the critic to then importance sampled our intended policy. We introduce Implicit Diffusion Q-learning ({IDQL}), combining our general {IQL} critic with the policy extraction method. {IDQL} maintains the ease of implementation of {IQL} while outperforming prior offline {RL} methods and demonstrating robustness to hyperparameters. Code is available at https://github.com/philippe-eecs/{IDQL}.},
	number = {{arXiv}:2304.10573},
	publisher = {{arXiv}},
	author = {Hansen-Estruch, Philippe and Kostrikov, Ilya and Janner, Michael and Kuba, Jakub Grudzien and Levine, Sergey},
	urldate = {2024-04-12},
	date = {2023-05-19},
	eprinttype = {arxiv},
	eprint = {2304.10573 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}


@misc{shihParallelSamplingDiffusion2023,
	title = {Parallel Sampling of Diffusion Models},
	url = {http://arxiv.org/abs/2305.16317},
	abstract = {Diffusion models are powerful generative models but suffer from slow sampling, often taking 1000 sequential denoising steps for one sample. As a result, considerable efforts have been directed toward reducing the number of denoising steps, but these methods hurt sample quality. Instead of reducing the number of denoising steps (trading quality for speed), in this paper we explore an orthogonal approach: can we run the denoising steps in parallel (trading compute for speed)? In spite of the sequential nature of the denoising steps, we show that surprisingly it is possible to parallelize sampling via Picard iterations, by guessing the solution of future denoising steps and iteratively refining until convergence. With this insight, we present {ParaDiGMS}, a novel method to accelerate the sampling of pretrained diffusion models by denoising multiple steps in parallel. {ParaDiGMS} is the first diffusion sampling method that enables trading compute for speed and is even compatible with existing fast sampling techniques such as {DDIM} and {DPMSolver}. Using {ParaDiGMS}, we improve sampling speed by 2-4x across a range of robotics and image generation models, giving state-of-the-art sampling speeds of 0.2s on 100-step {DiffusionPolicy} and 14.6s on 1000-step {StableDiffusion}-v2 with no measurable degradation of task reward, {FID} score, or {CLIP} score.},
	number = {{arXiv}:2305.16317},
	publisher = {{arXiv}},
	author = {Shih, Andy and Belkhale, Suneel and Ermon, Stefano and Sadigh, Dorsa and Anari, Nima},
	urldate = {2024-05-27},
	date = {2023-10-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2305.16317 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{liCrosswayDiffusionImproving2024,
	title = {Crossway Diffusion: Improving Diffusion-based Visuomotor Policy via Self-supervised Learning},
	url = {http://arxiv.org/abs/2307.01849},
	shorttitle = {Crossway Diffusion},
	abstract = {Sequence modeling approaches have shown promising results in robot imitation learning. Recently, diffusion models have been adopted for behavioral cloning in a sequence modeling fashion, benefiting from their exceptional capabilities in modeling complex data distributions. The standard diffusionbased policy iteratively generates action sequences from random noise conditioned on the input states. Nonetheless, the model for diffusion policy can be further improved in terms of visual representations. In this work, we propose Crossway Diffusion, a simple yet effective method to enhance diffusionbased visuomotor policy learning via a carefully designed state decoder and an auxiliary self-supervised learning ({SSL}) objective. The state decoder reconstructs raw image pixels and other state information from the intermediate representations of the reverse diffusion process. The whole model is jointly optimized by the {SSL} objective and the original diffusion loss. Our experiments demonstrate the effectiveness of Crossway Diffusion in various simulated and real-world robot tasks, confirming its consistent advantages over the standard diffusionbased policy and substantial improvements over the baselines.},
	number = {{arXiv}:2307.01849},
	publisher = {{arXiv}},
	author = {Li, Xiang and Belagali, Varun and Shang, Jinghuan and Ryoo, Michael S.},
	urldate = {2024-04-25},
	date = {2024-01-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2307.01849 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
}

@InProceedings{perez2018film,
  title={{FiLM}: Visual Reasoning with a General Conditioning Layer},
  author={Ethan Perez and Florian Strub and Harm de Vries and Vincent Dumoulin and Aaron C. Courville},
  booktitle={AAAI},
  year={2018}
}

@article{Scheikl2024MPD,
  author={Scheikl, Paul Maria and Schreiber, Nicolas and Haas, Christoph and Freymuth, Niklas and Neumann, Gerhard and Lioutikov, Rudolf and Mathis-Ullrich, Franziska},
  title={Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of Deformable Objects},
  journal={IEEE Robotics and Automation Letters}, 
  year={2024},
  volume={9},
  number={6},
  pages={5338-5345},
  doi={10.1109/LRA.2024.3382529},
}

@inproceedings{meng2023distillation,
  title={On distillation of guided diffusion models},
  author={Meng, Chenlin and Rombach, Robin and Gao, Ruiqi and Kingma, Diederik and Ermon, Stefano and Ho, Jonathan and Salimans, Tim},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14297--14306},
  year={2023}
}

@article{zhou2024adaptive,
  title={Adaptive online replanning with diffusion models},
  author={Zhou, Siyuan and Du, Yilun and Zhang, Shun and Xu, Mengdi and Shen, Yikang and Xiao, Wei and Yeung, Dit-Yan and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{du2023reduce,
  title={Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and {MCMC}},
  author={Du, Yilun and Durkan, Conor and Strudel, Robin and Tenenbaum, Joshua B and Dieleman, Sander and Fergus, Rob and Sohl-Dickstein, Jascha and Doucet, Arnaud and Grathwohl, Will Sussman},
  booktitle={International Conference on Machine Learning},
  pages={8489--8510},
  year={2023},
  organization={PMLR}
}

@article{wang2024poco,
  title={{PoCo}: Policy composition from and for heterogeneous robot learning},
  author={Wang, Lirui and Zhao, Jialiang and Du, Yilun and Adelson, Edward H and Tedrake, Russ},
  journal={arXiv preprint arXiv:2402.02511},
  year={2024}
}
@article{ibarzHowTrainYour2021,
  title = {How to {{Train Your Robot}} with {{Deep Reinforcement Learning}}; {{Lessons We}}'ve {{Learned}}},
  author = {Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
  date = {2021-04},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {40},
  number = {4-5},
  eprint = {2102.02915},
  eprinttype = {arXiv},
  pages = {698--721},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364920987859},
  url = {http://arxiv.org/abs/2102.02915},
  urldate = {2022-05-11},
  abstract = {Deep reinforcement learning (RL) has emerged as a promising approach for autonomously acquiring complex behaviors from low level sensor observations. Although a large portion of deep RL research has focused on applications in video games and simulated control, which does not connect with the constraints of learning in real environments, deep RL has also demonstrated promise in enabling physical robots to learn complex skills in the real world. At the same time,real world robotics provides an appealing domain for evaluating such algorithms, as it connects directly to how humans learn; as an embodied agent in the real world. Learning to perceive and move in the real world presents numerous challenges, some of which are easier to address than others, and some of which are often not considered in RL research that focuses only on simulated domains. In this review article, we present a number of case studies involving robotic deep RL. Building off of these case studies, we discuss commonly perceived challenges in deep RL and how they have been addressed in these works. We also provide an overview of other outstanding challenges, many of which are unique to the real-world robotics setting and are not often the focus of mainstream RL research. Our goal is to provide a resource both for roboticists and machine learning researchers who are interested in furthering the progress of deep RL in the real world.},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/sigmundhoeg/Zotero/storage/WTZ2T5XX/Ibarz et al. - 2021 - How to Train Your Robot with Deep Reinforcement Le.pdf;/Users/sigmundhoeg/Zotero/storage/L4NWV4LD/2102.html}
}

@InProceedings{pmlr-v164-mandlekar22a,
  title = 	 {What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
  author =       {Mandlekar, Ajay and Xu, Danfei and Wong, Josiah and Nasiriany, Soroush and Wang, Chen and Kulkarni, Rohun and Fei-Fei, Li and Savarese, Silvio and Zhu, Yuke and Mart\'in-Mart\'in, Roberto},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {1678--1690},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v164/mandlekar22a/mandlekar22a.pdf},
  url = 	 {https://proceedings.mlr.press/v164/mandlekar22a.html},
  abstract = 	 {Imitating human demonstrations is a promising approach to endow robots with various manipulation capabilities. While recent advances have been made in imitation learning and batch (offline) reinforcement learning, a lack of open-source human datasets and reproducible learning methods make assessing the state of the field difficult. In this paper, we conduct an extensive study of six offline learning algorithms for robot manipulation on five simulated and three real-world multi-stage manipulation tasks of varying complexity, and with datasets of varying quality. Our study analyzes the most critical challenges when learning from offline human data for manipulation. Based on the study, we derive a series of lessons including the sensitivity to different algorithmic design choices, the dependence on the quality of the demonstrations, and the variability based on the stopping criteria due to the different objectives in training and evaluation. We also highlight opportunities for learning from human datasets, such as the ability to learn proficient policies on challenging, multi-stage tasks beyond the scope of current reinforcement learning methods, and the ability to easily scale to natural, real-world manipulation scenarios where only raw sensory signals are available. We have open-sourced our datasets and all algorithm implementations to facilitate future research and fair comparisons in learning from human demonstration data at https://arise-initiative.github.io/robomimic-web/}
}

@inproceedings{
    luo2024potential,
    title={Potential Based Diffusion Motion Planning},
    author={Yunhao Luo and Chen Sun and Joshua B. Tenenbaum and Yilun Du},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
  }

@inproceedings{carvalho2023mpd,
  title={Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models},
  author={Carvalho, J. and  Le, A.T. and  Baierl, M. and  Koert, D. and  Peters, J.},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2023}
}

@INPROCEEDINGS{10610519,
  author={Saha, Kallol and Mandadi, Vishal and Reddy, Jayaram and Srikanth, Ajit and Agarwal, Aditya and Sen, Bipasha and Singh, Arun and Krishna, Madhava},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={EDMP: Ensemble-of-costs-guided Diffusion for Motion Planning}, 
  year={2024},
  volume={},
  number={},
  pages={10351-10358},
  keywords={Training;Costs;Diffusion processes;Cost function;Planning;Trajectory;Robots},
  doi={10.1109/ICRA57147.2024.10610519}}


@InProceedings{pmlr-v229-ha23a,
  title = 	 {Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition},
  author =       {Ha, Huy and Florence, Pete and Song, Shuran},
  booktitle = 	 {Proceedings of The 7th Conference on Robot Learning},
  pages = 	 {3766--3777},
  year = 	 {2023},
  editor = 	 {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  volume = 	 {229},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v229/ha23a/ha23a.pdf},
  url = 	 {https://proceedings.mlr.press/v229/ha23a.html},
  abstract = 	 {We present a framework for robot skill acquisition, which 1) efficiently scale up data generation of language-labelled robot data and 2) effectively distills this data down into a robust multi-task language-conditioned visuo-motor policy. For (1), we use a large language model (LLM) to guide high-level planning, and sampling-based robot planners (e.g. motion or grasp samplers) for generating diverse and rich manipulation trajectories. To robustify this data-collection process, the LLM also infers a code-snippet for the success condition of each task, simultaneously enabling the data-collection process to detect failure and retry as well as the automatic labeling of trajectories with success/failure. For (2), we extend the diffusion policy single-task behavior-cloning approach to multi-task settings with language conditioning. Finally, we propose a new multi-task benchmark with 18 tasks across five domains to test long-horizon behavior, common-sense reasoning, tool-use, and intuitive physics. We find that our distilled policy successfully learned the robust retrying behavior in its data collection procedure, while improving absolute success rates by $33.2%$ on average across five domains. Code, data, and additional qualitative results are available on https://www.cs.columbia.edu/&nbsp;huy/scalingup/.}
}


@InProceedings{pmlr-v229-xian23a,
  title = 	 {ChainedDiffuser: Unifying Trajectory Diffusion and Keypose Prediction for Robotic Manipulation},
  author =       {Xian, Zhou and Gkanatsios, Nikolaos and Gervet, Theophile and Ke, Tsung-Wei and Fragkiadaki, Katerina},
  booktitle = 	 {Proceedings of The 7th Conference on Robot Learning},
  pages = 	 {2323--2339},
  year = 	 {2023},
  editor = 	 {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  volume = 	 {229},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v229/xian23a/xian23a.pdf},
  url = 	 {https://proceedings.mlr.press/v229/xian23a.html},
  abstract = 	 {We present ChainedDiffuser, a policy architecture that unifies action keypose prediction and trajectory diffusion generation for learning robot manipulation from demonstrations. Our main innovation is to use a global transformer-based action predictor to predict actions at keyframes, a task that requires multi- modal semantic scene understanding, and to use a local trajectory diffuser to predict trajectory segments that connect predicted macro-actions. ChainedDiffuser sets a new record on established manipulation benchmarks, and outperforms both state-of-the-art keypose (macro-action) prediction models that use motion plan- ners for trajectory prediction, and trajectory diffusion policies that do not predict keyframe macro-actions. We conduct experiments in both simulated and real-world environments and demonstrate ChainedDiffuser’s ability to solve a wide range of manipulation tasks involving interactions with diverse objects.}
}

@inproceedings{Ze2024DP3,
	title={3D Diffusion Policy: Generalizable Visuomotor Policy Learning via Simple 3D Representations},
	author={Yanjie Ze and Gu Zhang and Kangning Zhang and Chenyuan Hu and Muhan Wang and Huazhe Xu},
	booktitle={Proceedings of Robotics: Science and Systems (RSS)},
	year={2024}
}

@INPROCEEDINGS{Wang-RSS-24, 
    AUTHOR    = {Lirui Wang AND Jialiang Zhao AND Yilun Du AND Edward Adelson AND Russ Tedrake}, 
    TITLE     = {{PoCo: Policy Composition from and for Heterogeneous Robot Learning}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.127} 
} 

@INPROCEEDINGS{Chen-RSS-24, 
    AUTHOR    = {Kaiqi Chen AND Eugene Lim AND Lin Kelvin AND Yiyang Chen AND Harold Soh}, 
    TITLE     = {{Don't Start From Scratch: Behavioral Refinement via Interpolant-based Policy Diffusion}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.122} 
} 

@misc{sridhar2023memoryconsistent,
      title={Memory-Consistent Neural Networks for Imitation Learning}, 
      author={Kaustubh Sridhar and Souradeep Dutta and Dinesh Jayaraman and James Weimer and Insup Lee},
      year={2023},
      eprint={2310.06171},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{Reuss-RSS-24, 
    AUTHOR    = {Moritz Reuss AND Ömer Erdinç Yağmurlu AND Fabian Wenzel AND Rudolf Lioutikov}, 
    TITLE     = {{Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.121} 
}

@inproceedings{chen2023playfusion,
  title={PlayFusion: Skill Acquisition via Diffusion from Language-Annotated Play},
  author={Chen, Lili and Bahl, Shikhar and Pathak, Deepak},
  booktitle={CoRL},
  year={2023}
}

@article{language-control-diffusion,
  author={Zhang, Edwin and Lu, Yujie and Wang, William and Zhang, Amy},
  title={LAD: Language Control Diffusion: efficiently scaling through Space, Time, and Tasks},
  year = {2023},
  journal={arXiv preprint arXiv:2210.15629},
  howpublished = {\url{https://github.com/ezhang7423/language-control-diffusion}}
}

@article{urain2022se3dif,
  title={SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion},
  author={Urain, Julen and Funk, Niklas and Peters, Jan and Chalvatzaki, Georgia},
  journal={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023}
}


@InProceedings{pmlr-v235-ruhe24a,
  title = 	 {Rolling Diffusion Models},
  author =       {Ruhe, David and Heek, Jonathan and Salimans, Tim and Hoogeboom, Emiel},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {42818--42835},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/ruhe24a/ruhe24a.pdf},
  url = 	 {https://proceedings.mlr.press/v235/ruhe24a.html},
  abstract = 	 {Diffusion models have recently been increasingly applied to temporal data such as video, fluid mechanics simulations, or climate data. These methods generally treat subsequent frames equally regarding the amount of noise in the diffusion process. This paper explores Rolling Diffusion: a new approach that uses a sliding window denoising process. It ensures that the diffusion process progressively corrupts through time by assigning more noise to frames that appear later in a sequence, reflecting greater uncertainty about the future as the generation process unfolds. Empirically, we show that when the temporal dynamics are complex, Rolling Diffusion is superior to standard diffusion. In particular, this result is demonstrated in a video prediction task using the Kinetics-600 video dataset and in a chaotic fluid dynamics forecasting experiment.}
}

@misc{chen2024diffusionforcingnexttokenprediction,
      title={Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion},
      author={Boyuan Chen and Diego Marti Monso and Yilun Du and Max Simchowitz and Russ Tedrake and Vincent Sitzmann},
      year={2024},
      eprint={2407.01392},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.01392},
}

@inproceedings{10.5555/3666122.3667859,
author = {Wu, Tong and Fan, Zhihao and Liu, Xiao and Zheng, Hai-Tao and Gong, Yeyun and Shen, Yelong and Jiao, Jian and Li, Juntao and Wei, Zhongyu and Guo, Jian and Duan, Nan and Chen, Weizhu},
title = {AR-DIFFUSION: auto-regressive diffusion model for text generation},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Diffusion models have gained significant attention in the realm of image generation due to their exceptional performance. Their success has been recently expanded to text generation via generating all tokens within a sequence concurrently. However, natural language exhibits a far more pronounced sequential dependency in comparison to images, and the majority of existing language models are trained with a left-to-right auto-regressive approach. To account for the inherent sequential characteristic of natural language, we introduce Auto-Regressive Diffusion (AR-DIFFUSION). AR-DIFFUSION ensures that the generation of tokens on the right depends on the generated ones on the left, a mechanism achieved through employing a dynamic number of denoising steps that vary based on token position. This results in tokens on the left undergoing fewer denoising steps than those on the right, thereby enabling them to generate earlier and subsequently influence the generation of tokens on the right. In a series of experiments on various text generation tasks, including text summarization, machine translation, and common sense generation, AR-DIFFUSION clearly demonstrated its superiority over existing diffusion language models and that it can be 100 \texttimes{} ~ 600 \texttimes{} faster when achieving comparable results. Our code is available at https://github.com/microsoft/ProphetNet/tree/master/AR-diffusion.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {1737},
numpages = {18},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@article{chen2024diffusion,
  title={Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion},
  author={Chen, Boyuan and Monso, Diego Marti and Du, Yilun and Simchowitz, Max and Tedrake, Russ and Sitzmann, Vincent},
  journal={arXiv preprint arXiv:2407.01392},
  year={2024}
}

@inproceedings{
zhao2024aloha,
title={{ALOHA} Unleashed: A Simple Recipe for Robot Dexterity},
author={Tony Z. Zhao and Jonathan Tompson and Danny Driess and Pete Florence and Seyed Kamyar Seyed Ghasemipour and Chelsea Finn and Ayzaan Wahid},
booktitle={8th Annual Conference on Robot Learning},
year={2024},
url={https://openreview.net/forum?id=gvdXE7ikHI}
}

@INPROCEEDINGS{Chi-RSS-24, 
    AUTHOR    = {Cheng Chi AND Zhenjia Xu AND Chuer Pan AND Eric Cousineau AND Benjamin Burchfiel AND Siyuan Feng AND Russ Tedrake AND Shuran Song}, 
    TITLE     = {{Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.045} 
}

@inproceedings{huang2023diffusion,
  title={Diffusion-based Generation, Optimization, and Planning in 3D Scenes},
  author={Huang, Siyuan and Wang, Zan and Li, Puhao and Jia, Baoxiong and Liu, Tengyu and Zhu, Yixin and Liang, Wei and Zhu, Song-Chun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}





@article{McGeer01041990,
  author = {McGeer, Tad}, 
  title = {\href{http://ijr.sagepub.com/content/9/2/62.abstract}{Passive Dynamic Walking}}, 
  volume = {9}, 
  number = {2}, 
  pages = {62-82}, 
  year = {1990}, 
  doi = {10.1177/027836499000900206}, 
  journal = {The International Journal of Robotics Research}
}

@article{ta2022conditional,
  title={Conditional Energy-Based Models for Implicit Policies: The Gap between Theory and Practice},
  author={Ta, Duy-Nguyen and Cousineau, Eric and Zhao, Huihua and Feng, Siyuan},
  journal={arXiv preprint arXiv:2207.05824},
  year={2022}
}
@inproceedings{wu2020spatial,
  title = {Spatial Action Maps for Mobile Manipulation},
  author = {Wu, Jimmy and Sun, Xingyuan and Zeng, Andy and Song, Shuran and Lee, Johnny and Rusinkiewicz, Szymon and Funkhouser, Thomas},
  booktitle = {Proceedings of Robotics: Science and Systems (RSS)},
  year = {2020}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, R.E.},
  journal={Journal of Basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={Citeseer}
}

@inproceedings{atkeson1997robot,
  title={Robot learning from demonstration},
  author={Atkeson, Christopher G and Schaal, Stefan},
  booktitle={ICML},
  volume={97},
  pages={12--20},
  year={1997}
}

@article{argall2009survey,
  title={A survey of robot learning from demonstration},
  author={Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  journal={Robotics and autonomous systems},
  volume={57},
  number={5},
  pages={469--483},
  year={2009},
  publisher={Elsevier}
}

@article{ravichandar2020recent,
  title={Recent advances in robot learning from demonstration},
  author={Ravichandar, Harish and Polydoros, Athanasios S and Chernova, Sonia and Billard, Aude},
  journal={Annual review of control, robotics, and autonomous systems},
  volume={3},
  pages={297--330},
  year={2020},
  publisher={Annual Reviews}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{
robomimic,
title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Li Fei-Fei and Silvio Savarese and Yuke Zhu and Roberto Mart{\'\i}n-Mart{\'\i}n},
booktitle={5th Annual Conference on Robot Learning },
year={2021}
}

@inproceedings{
ibc,
title={Implicit Behavioral Cloning},
author={Pete Florence and Corey Lynch and Andy Zeng and Oscar A Ramirez and Ayzaan Wahid and Laura Downs and Adrian Wong and Johnny Lee and Igor Mordatch and Jonathan Tompson},
booktitle={5th Annual Conference on Robot Learning },
year={2021}
}

@inproceedings{
bet,
title={Behavior Transformers: Cloning \$k\$ modes with one stone},
author={Nur Muhammad Mahi Shafiullah and Zichen Jeff Cui and Ariuntuya Altanzaya and Lerrel Pinto},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022}
}


@inproceedings{
resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{batchnorm,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@inproceedings{groupnorm,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International Conference on Machine Learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}

@inproceedings{
song2021ddim,
title={Denoising Diffusion Implicit Models},
author={Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{zhou2019continuity,
  title={On the continuity of rotation representations in neural networks},
  author={Zhou, Yi and Barnes, Connelly and Lu, Jingwan and Yang, Jimei and Li, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5745--5753},
  year={2019}
}


@InProceedings{pmlr-v162-janner22a,
  title = 	 {Planning with Diffusion for Flexible Behavior Synthesis},
  author =       {Janner, Michael and Du, Yilun and Tenenbaum, Joshua and Levine, Sergey},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{gpt,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}


@article{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2006.11239},
  year={2020}
}

@article{liu2022compositional,
  title={Compositional Visual Generation with Composable Diffusion Models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:2206.01714},
  year={2022}
}

@article{neal2011mcmc,
  title={MCMC using Hamiltonian dynamics},
  author={Neal, Radford M and others},
  journal={Handbook of markov chain monte carlo},
  year={2011},
  publisher={Chapman and Hall/CRC}
}

@article{du2020improved,
  title={Improved contrastive divergence training of energy based models},
  author={Du, Yilun and Li, Shuang and Tenenbaum, Joshua and Mordatch, Igor},
  journal={arXiv preprint arXiv:2012.01316},
  year={2020}
}

@inproceedings{sohldickstein2015nonequilibrium,
    title = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
    author = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
    booktitle = {International Conference on Machine Learning},
    year = 	 {2015},
}

@inproceedings{janner2022diffuser,
  title = {Planning with Diffusion for Flexible Behavior Synthesis},
  author = {Michael Janner and Yilun Du and Joshua Tenenbaum and Sergey Levine},
  booktitle = {International Conference on Machine Learning},
  year = {2022},
}

@article{urain2022se,
  title={SE (3)-DiffusionFields: Learning cost functions for joint grasp and motion optimization through diffusion},
  author={Urain, Julen and Funk, Niklas and Chalvatzaki, Georgia and Peters, Jan},
  journal={arXiv preprint arXiv:2209.03855},
  year={2022}
}

@article{ajay2022conditional,
  title={Is Conditional Generative Modeling all you need for Decision-Making?},
  author={Ajay, Anurag and Du, Yilun and Gupta, Abhi and Tenenbaum, Joshua and Jaakkola, Tommi and Agrawal, Pulkit},
  journal={arXiv preprint arXiv:2211.15657},
  year={2022}
}

@article{du2019implicit,
  title={Implicit generation and generalization in energy-based models},
  author={Du, Yilun and Mordatch, Igor},
  journal={arXiv preprint arXiv:1903.08689},
  year={2019}
}

@inproceedings{du2019model,
  title={Model Based Planning with Energy Based Models},
  author={Du, Yilun and Lin, Toru and Mordatch, Igor},
  booktitle={Conference on Robot Learning },
  year={2019},
}

@inproceedings{lecun06atutorial,
    author = {Yann LeCun and Sumit Chopra and Raia Hadsell and Fu Jie Huang and et al.},
    title = {A tutorial on energy-based learning},
    booktitle = {Predicting Structured Data},
    year = {2006},
    publisher = {MIT Press}
}

@InProceedings{grathwohl2020stein,
  title = {Learning the Stein Discrepancy for Training and Evaluating Energy-Based Models without Sampling},
  author = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Joern-Henrik and Duvenaud, David and Zemel, Richard},
  booktitle = {International Conference on Machine Learning},
  year = {2020},
}

@article{dai2019exponential,
  title={Exponential family estimation via adversarial dynamics embedding},
  author={Dai, Bo and Liu, Zhen and Dai, Hanjun and He, Niao and Gretton, Arthur and Song, Le and Schuurmans, Dale},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{zhu2020robosuite,
  title={robosuite: A modular simulation framework and benchmark for robot learning},
  author={Zhu, Yuke and Wong, Josiah and Mandlekar, Ajay and Mart{\'\i}n-Mart{\'\i}n, Roberto},
  journal={arXiv preprint arXiv:2009.12293},
  year={2020}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{gupta2019relay,
  title={Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{
nair2022r3m,
title={R3M: A Universal Visual Representation for Robot Manipulation},
author={Suraj Nair and Aravind Rajeswaran and Vikash Kumar and Chelsea Finn and Abhinav Gupta},
booktitle={6th Annual Conference on Robot Learning},
year={2022}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{mayne1988receding,
  title={Receding horizon control of nonlinear systems},
  author={Mayne, David Q and Michalska, Hannah},
  booktitle={Proceedings of the 27th IEEE Conference on Decision and Control},
  pages={464--465},
  year={1988},
  organization={IEEE}
}

@article{song2019score,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{pearce2023imitating,
  title={Imitating Human Behaviour with Diffusion Models},
  author={Pearce, Tim and Rashid, Tabish and Kanervisto, Anssi and Bignell, Dave and Sun, Mingfei and Georgescu, Raluca and Macua, Sergio Valcarcel and Tan, Shan Zheng and Momennejad, Ida and Hofmann, Katja and others},
  journal={arXiv preprint arXiv:2301.10677},
  year={2023}
}

@article{jarrett2020strictly,
  title={Strictly batch imitation learning by energy-based distribution matching},
  author={Jarrett, Daniel and Bica, Ioana and van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7354--7365},
  year={2020}
}

@conference{mathieu2016mse,
title = "Deep multi-scale video prediction beyond mean square error",
abstract = "Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition, while optical flow has been a very studied problem in computer vision for a long time, future frame prediction is rarely approached. Still, many vision applications could benefit from the knowledge of the next frames of videos, that does not require the complexity of tracking every pixel trajectory. In this work, we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function, we propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset.",
author = "Michael Mathieu and Camille Couprie and Yann LeCun",
year = "2016",
month = jan,
day = "1",
language = "English (US)",
note = "4th International Conference on Learning Representations, ICLR 2016 ; Conference date: 02-05-2016 Through 04-05-2016",
}

@article{pomerleau1988alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  journal={Advances in neural information processing systems},
  volume={1},
  year={1988}
}

@inproceedings{zhang2018deep,
  title={Deep imitation learning for complex manipulation tasks from virtual reality teleoperation},
  author={Zhang, Tianhao and McCarthy, Zoe and Jow, Owen and Lee, Dennis and Chen, Xi and Goldberg, Ken and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5628--5635},
  year={2018},
  organization={IEEE}
}

@article{florence2019self,
  title={Self-supervised correspondence in visuomotor policy learning},
  author={Florence, Peter and Manuelli, Lucas and Tedrake, Russ},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={492--499},
  year={2019},
  publisher={IEEE}
}

@article{mandlekar2020learning,
  title={Learning to generalize across long-horizon tasks from human demonstrations},
  author={Mandlekar, Ajay and Xu, Danfei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2003.06085},
  year={2020}
}

@inproceedings{sharma2018multiple,
  title={Multiple interactions made easy (mime): Large scale demonstrations data for imitation},
  author={Sharma, Pratyusha and Mohan, Lekha and Pinto, Lerrel and Gupta, Abhinav},
  booktitle={Conference on robot learning},
  year={2018},
  organization={PMLR}
}

@inproceedings{mandlekar2020iris,
  title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
  author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2020},
  organization={IEEE}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{toyer2020magical,
  title={The magical benchmark for robust imitation},
  author={Toyer, Sam and Shah, Rohin and Critch, Andrew and Russell, Stuart},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18284--18295},
  year={2020}
}

@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{zeng2021transporter,
  title={Transporter networks: Rearranging the visual world for robotic manipulation},
  author={Zeng, Andy and Florence, Pete and Tompson, Jonathan and Welker, Stefan and Chien, Jonathan and Attarian, Maria and Armstrong, Travis and Krasin, Ivan and Duong, Dan and Sindhwani, Vikas and others},
  booktitle={Conference on Robot Learning},
  pages={726--747},
  year={2021},
  organization={PMLR}
}


@inproceedings{pfrommer2021contactnets,
  title={Contactnets: Learning discontinuous contact dynamics with smooth, implicit representations},
  author={Pfrommer, Samuel and Halm, Mathew and Posa, Michael},
  booktitle={Conference on Robot Learning},
  pages={2279--2291},
  year={2021},
  organization={PMLR}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1352--1361},
  year={2017},
  organization={PMLR}
}

@inproceedings{boney2020regularizing,
  title={Regularizing model-based planning with energy-based models},
  author={Boney, Rinu and Kannala, Juho and Ilin, Alexander},
  booktitle={Conference on Robot Learning},
  pages={182--191},
  year={2020},
  organization={PMLR}
}

@article{liu2020energy,
  title={Energy-based imitation learning},
  author={Liu, Minghuan and He, Tairan and Xu, Minkai and Zhang, Weinan},
  journal={arXiv preprint arXiv:2004.09395},
  year={2020}
}

@inproceedings{rahmatizadeh2018vision,
  title={Vision-based multi-task manipulation for inexpensive robots using end-to-end learning from demonstration},
  author={Rahmatizadeh, Rouhollah and Abolghasemi, Pooya and B{\"o}l{\"o}ni, Ladislau and Levine, Sergey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3758--3765},
  year={2018},
  organization={IEEE}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{hausman2017multi,
  title={Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets},
  author={Hausman, Karol and Chebotar, Yevgen and Schaal, Stefan and Sukhatme, Gaurav and Lim, Joseph J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@inproceedings{avigal2022speedfolding,
  title={Speedfolding: Learning efficient bimanual folding of garments},
  author={Avigal, Yahav and Berscheid, Lars and Asfour, Tamim and Kr{\"o}ger, Torsten and Goldberg, Ken},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}

@book{bishop1994mixture,
  title={Mixture density networks},
  author={Bishop, Christopher M},
  year={1994},
  publisher={Aston University}
}

@inproceedings{yang2022periodic,
  title={Learning periodic tasks from human demonstrations},
  author={Yang, Jingyun and Zhang, Junwu and Settle, Connor and Rai, Akshara and Antonova, Rika and Bohg, Jeannette},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={8658--8665},
  year={2022},
  organization={IEEE}
}

@inproceedings{he2020moco,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@article{tancik2020fourier,
  title={Fourier features let networks learn high frequency functions in low dimensional domains},
  author={Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7537--7547},
  year={2020}
}

@article{liu2020understanding,
  title={Understanding the difficulty of training transformers},
  author={Liu, Liyuan and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu and Han, Jiawei},
  journal={arXiv preprint arXiv:2004.08249},
  year={2020}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{wang2022diffusion,
  title={Diffusion policies as an expressive policy class for offline reinforcement learning},
  author={Wang, Zhendong and Hunt, Jonathan J and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2208.06193},
  year={2022}
}

@inproceedings{wang2023diffusion,
title={Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning},
author={Zhendong Wang and Jonathan J Hunt and Mingyuan Zhou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=AHvFDPi-FA}
}

@article{huang2023diffusion,
  title={Diffusion-based Generation, Optimization, and Planning in 3D Scenes},
  author={Huang, Siyuan and Wang, Zan and Li, Puhao and Jia, Baoxiong and Liu, Tengyu and Zhu, Yixin and Liang, Wei and Zhu, Song-Chun},
  journal={arXiv preprint arXiv:2301.06015},
  year={2023}
}

@inproceedings{reuss2023goal,
  title={Goal-Conditioned Imitation Learning using Score-based Diffusion Policies},
  author={Reuss, Moritz and Li, Maximilian and Jia, Xiaogang and Lioutikov, Rudolf},
  booktitle={Proceedings of Robotics: Science and Systems (RSS)},
  year={2023}
}

@article{hansen2023idql,
  title={IDQL: Implicit Q-Learning as an Actor-Critic Method with Diffusion Policies},
  author={Hansen-Estruch, Philippe and Kostrikov, Ilya and Janner, Michael and Kuba, Jakub Grudzien and Levine, Sergey},
  journal={arXiv preprint arXiv:2304.10573},
  year={2023}
}

@article{song2023consistency,
  title={Consistency models},
  author={Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2303.01469},
  year={2023}
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={arXiv preprint arXiv:2206.00364},
  year={2022}
}

@article{chen2023importance,
  title={On the importance of noise scheduling for diffusion models},
  author={Chen, Ting},
  journal={arXiv preprint arXiv:2301.10972},
  year={2023}
}

@article{kim2022automating,
  title={Automating reinforcement learning with example-based resets},
  author={Kim, Jigang and hyeon Park, J and Cho, Daesol and Kim, H Jin},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={3},
  pages={6606--6613},
  year={2022},
  publisher={IEEE}
}
