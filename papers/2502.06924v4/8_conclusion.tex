\section{Conclusion \& Future Work}\label{conclusion}
This work presents XAMBA, the first framework optimizing SSMs on COTS NPUs, removing the need for specialized accelerators. XAMBA mitigates key bottlenecks in SSMs like CumSum, ReduceSum, and activations using ActiBA, CumBA, and ReduBA, transforming sequential operations into parallel computations. These optimizations improve latency, throughput (Tokens/s), and memory efficiency. Future work will extend XAMBA to other models, explore compression, and develop dynamic optimizations for broader hardware platforms.



% This work introduces XAMBA, the first framework to optimize SSMs on COTS NPUs, eliminating the need for specialized hardware accelerators. XAMBA addresses key bottlenecks in SSM execution, including CumSum, ReduceSum, and activation functions, through techniques like ActiBA, CumBA, and ReduBA, which restructure sequential operations into parallel matrix computations. These optimizations reduce latency, enhance throughput, and improve memory efficiency. 
% Experimental results show up to 2.6$\times$ performance improvement on Intel\textregistered\ Core\texttrademark\ Ultra Series 2 AI PC. 
% Future work will extend XAMBA to other models, incorporate compression techniques, and explore dynamic optimization strategies for broader hardware platforms.


% This work presents XAMBA, an optimization framework that enhances the performance of SSMs on NPUs. Unlike transformers, SSMs rely on structured state transitions and implicit recurrence, which introduce sequential dependencies that challenge efficient hardware execution. XAMBA addresses these inefficiencies by introducing CumBA, ReduBA, and ActiBA, which optimize cumulative summation, ReduceSum, and activation functions, respectively, significantly reducing latency and improving throughput. By restructuring sequential computations into parallelizable matrix operations and leveraging specialized hardware acceleration, XAMBA enables efficient execution of SSMs on NPUs. Future work will extend XAMBA to other state-space models, integrate advanced compression techniques like pruning and quantization, and explore dynamic optimization strategies to further enhance performance across various hardware platforms and frameworks.
% This work presents XAMBA, an optimization framework that enhances the performance of SSMs on NPUs. Key techniques, including CumBA, ReduBA, and ActiBA, achieve significant latency reductions by optimizing operations like cumulative summation, ReduceSum, and activation functions. Future work will focus on extending XAMBA to other state-space models, integrating advanced compression techniques, and exploring dynamic optimization strategies to further improve performance across various hardware platforms and frameworks.

% This work introduces XAMBA, an optimization framework for improving the performance of Mamba-2 and Mamba models on NPUs. XAMBA includes three key techniques: CumBA, ReduBA, and ActiBA. CumBA reduces latency by transforming cumulative summation operations into matrix multiplication using precomputed masks. ReduBA optimizes the ReduceSum operation through matrix-vector multiplication, reducing execution time. ActiBA accelerates activation functions like Swish and Softplus by mapping them to specialized hardware during the DPUâ€™s drain phase, avoiding sequential execution bottlenecks. Additionally, XAMBA enhances memory efficiency by reducing SRAM access, increasing data reuse, and utilizing Zero Value Compression (ZVC) for masks. The framework provides significant latency reductions, with CumBA, ReduBA, and ActiBA achieving up to 1.8X, 1.1X, and 2.6X reductions, respectively, compared to the baseline.
% Future work includes extending XAMBA to other state-space models (SSMs) and exploring further hardware optimizations for emerging NPUs. Additionally, integrating advanced compression techniques like pruning and quantization, and developing adaptive strategies for dynamic optimization, could enhance performance. Expanding XAMBA's compatibility with other frameworks and deployment environments will ensure broader adoption across various hardware platforms.