\section{Motivation} \label{sec_motivation}


While SSMs provide notable efficiency advantages, deploying them on NPUs presents unique challenges due to their computational patterns and hardware requirements. Unlike traditional deep learning models, SSMs exhibit characteristics that deviate from standard kernel operations, necessitating specialized optimizations. Existing NPUs are designed primarily for data-parallel operations like matrix multiplications, which dominate workloads in transformers and CNNs. SSMs, however, involve sequential computations and specialized operators, such as activation functions (e.g., Swish and Softplus) and cumulative summations (CumSum). These operations do not align with the highly parallelized architecture of NPUs, leading to inefficient execution when mapped directly. Fig.~\ref{fig:motivation_exec_lat_brkdwn} highlights execution bottlenecks for Mamba and Mamba-2 models on the Intel\textregistered\ Core\texttrademark\ Ultra Series 2~\cite{lnl} NPU. For Mamba, the majority of execution time is consumed by activation functions, such as Swish (SiLU) and Softplus, which are executed sequentially on DSPs. These DSPs are less optimized for such operations, resulting in prolonged execution times and underutilization of the data-parallel units. In Mamba-2, CumSum and ReduceSum emerge as primary bottlenecks, as these operations also rely on DSPs for sequential processing. This sequential nature hinders efficient reuse of local SRAM, increasing memory traffic and access latency. Both models further face challenges with elementwise multiplication (Multiply), which similarly runs on DSPs and contributes to inefficiencies. Handling long sequences in SSMs requires careful memory optimization. Limited on-chip memory must be utilized effectively to avoid frequent off-chip memory accesses, which incur significant latency and energy costs. The lack of optimized dataflow alignment for SSM computations exacerbates this issue, leading to poor performance. Blind, out-of-the-box mapping of SSMs on NPUs results in suboptimal performance, leaving much of their potential benefits untapped. Addressing these challenges is essential to fully leverage the advantages of SSMs in resource-constrained environments.




