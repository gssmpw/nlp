State-Space Models (SSMs) have emerged as efficient alternatives to transformers for sequential data tasks, offering linear or near-linear scalability with sequence length, unlike transformers with quadratic-complexity attention. This makes SSMs ideal for long-sequence tasks in natural language processing (NLP), vision, and edge AI applications such as real-time transcription, translation, and contextual search. These applications demand lightweight, high-performance models for deployment on resource-constrained devices like laptops and PCs. 
\textcolor{black}{While specialized accelerators have been proposed for emerging neural networks, designing new hardware is time-intensive, costly, and impractical for every model. Instead, optimizing models for existing neural processing units (NPUs) in AI PCs offers a scalable and efficient solution.
Towards this end, we propose \textbf{XAMBA}, \textit{the first framework to enable and optimize SSMs on commercial off-the-shelf (COTS) state-of-the-art (SOTA) NPUs}.}
Our approach follows a systematic three-step methodology: (1) enabling SSMs on NPUs, (2) optimizing performance to meet target Key Performance Indicator (KPI) requirements, and (3) trading accuracy for additional performance gains. After enabling SSMs on NPUs, XAMBA addresses key performance bottlenecks with two techniques: \textbf{CumBA} and \textbf{ReduBA}. These replace sequential CumSum and ReduceSum operations with matrix-based computations, significantly improving execution speed and memory efficiency. In addition, \textbf{ActiBA} further enhances performance by mapping computationally expensive activation functions (\emph{e.g.}, Swish, Softplus) to NPU hardware using piecewise linear approximations, reducing latency with minimal accuracy loss. Experimental evaluations on an Intel\textregistered\ Core\texttrademark\ Ultra Series 2 AI PC demonstrate that XAMBA achieves significant performance improvements, reducing execution latency by up to 4.8$\times$ compared to baseline implementation. Our code implementation is available at \href{https://github.com/arghadippurdue/XAMBA}{this link}.

% Our code implementation is available at \href{https://anonymous.4open.science/r/XAMBA/}{https://anonymous.4open.science/r/XAMBA/}.
% XAMBA bridges the gap between SSMs and existing hardware, demonstrating how NPUs can be repurposed to accelerate SSMs without requiring new hardware designs. 




% v-2
% State-Space Models (SSMs) have emerged as efficient alternatives to transformers for sequential data tasks, offering linear or near-linear scalability with sequence length, unlike transformers with quadratic-complexity attention. This makes SSMs ideal for long-sequence tasks in natural language processing (NLP), vision, and edge AI applications such as real-time transcription, translation, and contextual search. These applications demand lightweight, high-performance models for deployment on resource-constrained devices like laptops and PCs. Neural Processing Units (NPUs), specialized for data-parallel tasks, are key to unlocking SSMs' potential at the edge. However, deploying SSMs on NPUs is challenging due to misaligned sequential computations (e.g., Cumulative Sum a.k.a. CumSum, Swish, Softplus) and inefficient memory usage, leading to resource underutilization and increased latency.
% To address these challenges, we propose \textbf{XAMBA}, the first framework to enable and optimize SSMs on commercial off-the-shelf (COTS) state-of-the-art (SOTA) NPUs. Our approach follows a systematic three-step methodology: (1) enabling SSMs on NPUs, (2) optimizing performance, and (3) trading accuracy for further gains. After enabling SSMs on NPUs, XAMBA addresses key performance bottlenecks with two techniques: \textbf{CumBA} and \textbf{ReduBA}. These replace sequential CumSum and ReduceSum operations with matrix-based computations, significantly improving execution speed and memory efficiency. Building on this, another technique \textbf{ActiBA} further enhances performance by mapping computationally expensive activation functions (e.g., Swish, Softplus) to NPU hardware using piecewise linear approximations, reducing latency with minimal accuracy loss. Experimental evaluations on an Intel\textregistered\ Core\texttrademark\ Ultra Series 2 AI PC demonstrate that, XAMBA achieves significant performance improvements, reducing execution latency by up to 2.6$\times$ compared to baseline implementation. 


% State-Space Models (SSMs) have emerged as efficient alternatives to transformers for sequential data tasks, offering linear or near-linear scalability with sequence length.
% DeepSeek
% Unlike transformers, which rely on quadratic-complexity attention mechanisms, SSMs achieve computational efficiency by leveraging principles from convolutional and recurrent neural networks. This makes SSMs highly suitable for long-sequence tasks like natural language processing, computer vision, and edge applications such as personal assistants, real-time transcription, language translation, and contextual search. These applications demand lightweight, high-performance models for deployment on resource-constrained client devices like laptops and PCs. Enabling SSMs on Neural Processing Units (NPUs), specialized accelerators for data-parallel tasks, is critical to unlocking their full potential for edge AI. However, deploying SSMs on NPUs presents unique challenges due to misaligned sequential computations (e.g., CumSum, Swish, Softplus) and inefficient memory usage, leading to underutilized resources and increased latency.
% ChatGPT
% Unlike transformers with quadratic-complexity attention, SSMs achieve efficiency using convolutional and recurrent principles, making them ideal for long-sequence tasks in natural language processing (NLP), vision, and edge AI (e.g., real-time transcription, translation, and contextual search). 





% By bridging the gap between SSMs and NPUs, XAMBA makes SSMs viable for real-world applications on resource-constrained devices.
% \noindent State-Space Models (SSMs) have emerged as efficient alternatives to transformers for sequential data tasks, offering linear or near-linear scalability with sequence length. Unlike transformers, which rely on quadratic-complexity attention mechanisms, SSMs achieve computational efficiency by leveraging principles from convolutional and recurrent neural networks. This makes SSMs highly suitable for long-sequence tasks like natural language processing, computer vision, and medicine, as well as edge applications such as personal assistants and real-time transcription, where they enable transformative AI with reduced resource consumption and improved energy efficiency. However, deploying SSMs on Neural Processing Units (NPUs) presents unique challenges due to misaligned sequential computations (e.g., CumSum, Swish, Softplus) and inefficient memory usage. To address these challenges, we propose \textbf{XAMBA}, the first framework to enable and optimize SSMs on commercial off-the-shelf (COTS) NPUs. XAMBA introduces three key techniques: \textbf{CumBA}, which replaces sequential CumSum with matrix multiplication; \textbf{ReduBA}, which optimizes ReduceSum via matrix-vector multiplication; and \textbf{ActiBA}, which maps activation functions to NPU hardware using piecewise linear approximations with negligible accuracy loss. These innovations reduce execution latency by up to 2.6$\times$ while enhancing memory efficiency, making SSMs viable for real-world applications on resource-constrained devices.
% \noindent State-Space Models (SSMs) such as Mamba and Mamba-2 are increasingly employed in applications requiring sequential data processing, including signal processing, time-series forecasting, and natural language modeling. Efficient execution of these models on Neural Processing Units (NPUs) is crucial to achieving low-latency, energy-efficient inference in resource-constrained environments. However, SSMs pose significant challenges for NPUs due to their memory-bound nature, sequential operations, and irregular data access patterns, which lead to suboptimal performance and resource utilization.
% In this paper, we introduce \textbf{XAMBA}, a framework that addresses these challenges through three key optimizations: \textbf{CumBA}, \textbf{ReduBA}, and \textbf{ActiBA}. CumBA leverages precomputed masks and matrix multiplication to replace the inherently sequential CumSum operation, improving data reuse and eliminating redundant memory accesses. ReduBA employs matrix-vector multiplication for ReduceSum, reducing memory traffic and increasing effective bandwidth by reusing precomputed masks across operations. ActiBA integrates computationally expensive activation functions, such as Swish and Softplus, into the data-drain phase using Configurable Lookup Tables (C-LUTs), thereby avoiding memory overhead and eliminating sequential execution bottlenecks. Additionally, XAMBA exploits the inherent sparsity of CumSum masks using Zero Value Compression (ZVC) and compute skipping via sparsity bitmaps, further reducing memory storage, bandwidth, and compute requirements.
% Our framework is implemented with minimal compiler-level changes, ensuring compatibility with existing NPU architectures without requiring hardware modifications. Experimental results on Intel\textregistered\ Core\texttrademark\ Ultra Series 2 NPUs demonstrate significant performance gains, with CumBA achieving $1.8\times$, ReduBA $1.1\times$, and ActiBA up to $2.6\times$ reductions in execution latency, resulting in an overall speedup of up to $2.6\times$ for Mamba-based models compared to initial out-of-the-box mappings. XAMBA represents a lightweight yet effective solution for optimizing SSM execution on NPUs, improving both performance and resource efficiency.
