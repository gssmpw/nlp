
This document is based on \textit{Datasheets for Datasets} by~\cite{gebru2021datasheets}.


\subsection{Motivation}

    \textcolor{\sectioncolor}{\textbf{For what purpose was the dataset created?
    }
    Was there a specific task in mind? Was there
    a specific gap that needed to be filled? Please provide a description.
    } \\
    %%%
    The dataset was created to enable large language models (LLMs) to tackle complex Partial Differential Equation (PDE) control problems. The specific purpose is to advance automated formalization and reasoning in applied mathematics, addressing the lack of datasets tailored to PDE-related tasks. The dataset bridges informal natural language problems and formal specifications/code for PDE systems, fostering research in scientific computing and engineering.
    \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Who created this dataset (e.g., which team, research group) and on behalf
    of which entity (e.g., company, institution, organization)?
    }
    } \\
    %%%
    The dataset was created by the anonymous authors of this PDE-Controller paper, affiliated with a research group focused on AI-for-math applications. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{What support was needed to make this dataset?
    }
    (e.g.who funded the creation of the dataset? If there is an associated
    grant, provide the name of the grantor and the grant name and number, or if
    it was supported by a company or government agency, give those details.)
    } \\
    %%%
    The creation of the dataset was supported by research funding for developing novel applications of LLMs in applied mathematics. Further support included computational resources for fine-tuning LLMs and manual curation by domain experts. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Any other comments?
    }} \\
    %%%
    The dataset represents a pioneering effort to merge AI capabilities with PDE-based scientific reasoning, significantly expanding the potential applications of LLMs. \\
    %%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Composition}
    \textcolor{\sectioncolor}{\textbf{What do the instances that comprise the dataset represent (e.g., documents,
    photos, people, countries)?
    }
    Are there multiple types of instances (e.g., movies, users, and ratings;
    people and interactions between them; nodes and edges)? Please provide a
    description.
    } \\
    %%%
    Each instance represents a PDE control problem, including:
1) Informal problem descriptions in natural language;
2) Formal specifications in Signal Temporal Logic (STL);
3) Python code that integrates PDE simulation and optimization tools. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{How many instances are there in total (of each type, if appropriate)?
    }
    } \\
    %%%
    The dataset comprises over 2.13 million synthetic (natural language, STL, Python code) triplets, with additional real-world examples including 17 manually written heat problems and 17 wave problems.
    \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Does the dataset contain all possible instances or is it a sample (not
    necessarily random) of instances from a larger set?
    }
    If the dataset is a sample, then what is the larger set? Is the sample
    representative of the larger set (e.g., geographic coverage)? If so, please
    describe how this representativeness was validated/verified. If it is not
    representative of the larger set, please describe why not (e.g., to cover a
    more diverse range of instances, because instances were withheld or
    unavailable).
    } \\
    %%%
    It is a synthesized dataset designed to cover a diverse range of PDE control problems, sampled and augmented from representative templates to ensure coverage of key scenarios and complexities. \\
    %%%
    
    \textcolor{\sectioncolor}{\textbf{What data does each instance consist of?
    }
    “Raw” data (e.g., unprocessed text or images) or features? In either case,
    please provide a description.
    } \\
    %%%
    Each instance includes:
1) Informal natural language descriptions of PDE problems;
2) Formal representations in STL syntax;
3) Python code for solving the PDE problem using optimizers such as Gurobi.
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Is there a label or target associated with each instance?
    }
    If so, please provide a description.
    } \\
    %%%
    Yes, each instance includes ground-truth STL and Python code, verified for alignment and executability. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Is any information missing from individual instances?
    }
    If so, please provide a description, explaining why this information is
    missing (e.g., because it was unavailable). This does not include
    intentionally removed information, but might include, e.g., redacted text.
    } \\
    %%%
    Not Applicable. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Are relationships between individual instances made explicit (e.g., users’
    movie ratings, social network links)?
    }
    If so, please describe how these relationships are made explicit.
    } \\
    %%%
    Yes, relationships between natural language, STL specifications, and Python code are explicitly maintained for traceability. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Are there recommended data splits (e.g., training, development/validation,
    testing)?
    }
    If so, please provide a description of these splits, explaining the
    rationale behind them.
    } \\
    %%%
    Yes, the dataset is split into training and testing sets, with specific splits for heat and wave problems. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Are there any errors, sources of noise, or redundancies in the dataset?
    }
    If so, please provide a description.
    } \\
    %%%
    Synthetic data is validated through automated checks and human verification. Errors may arise from annotation inconsistencies, especially in manually curated problems. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Is the dataset self-contained, or does it link to or otherwise rely on
    external resources (e.g., websites, tweets, other datasets)?
    }
    If it links to or relies on external resources, a) are there guarantees
    that they will exist, and remain constant, over time; b) are there official
    archival versions of the complete dataset (i.e., including the external
    resources as they existed at the time the dataset was created); c) are
    there any restrictions (e.g., licenses, fees) associated with any of the
    external resources that might apply to a future user? Please provide
    descriptions of all external resources and any restrictions associated with
    them, as well as links or other access points, as appropriate.
    } \\
    %%%
    The dataset is self-contained, with no reliance on external or dynamic resources. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Does the dataset contain data that might be considered confidential (e.g.,
    data that is protected by legal privilege or by doctor-patient
    confidentiality, data that includes the content of individuals’ non-public
    communications)?
    }
    If so, please provide a description.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Does the dataset contain data that, if viewed directly, might be offensive,
    insulting, threatening, or might otherwise cause anxiety?
    }
    If so, please describe why.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Does the dataset relate to people?
    }
    If not, you may skip the remaining questions in this section.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Does the dataset identify any subpopulations (e.g., by age, gender)?
    }
    If so, please describe how these subpopulations are identified and
    provide a description of their respective distributions within the dataset.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Is it possible to identify individuals (i.e., one or more natural persons),
    either directly or indirectly (i.e., in combination with other data) from
    the dataset?
    }
    If so, please describe how.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Does the dataset contain data that might be considered sensitive in any way
    (e.g., data that reveals racial or ethnic origins, sexual orientations,
    religious beliefs, political opinions or union memberships, or locations;
    financial or health data; biometric or genetic data; forms of government
    identification, such as social security numbers; criminal history)?
    }
    If so, please provide a description.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Any other comments?
    }} \\
    %%%
    The dataset’s richness in complexity and diversity makes it a significant resource for advancing applied mathematics via AI. \\
    %%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Collection}

    \textcolor{\sectioncolor}{\textbf{How was the data associated with each instance acquired?
    }
    Was the data directly observable (e.g., raw text, movie ratings),
    reported by subjects (e.g., survey responses), or indirectly
    inferred/derived from other data (e.g., part-of-speech tags, model-based
    guesses for age or language)? If data was reported by subjects or
    indirectly inferred/derived from other data, was the data
    validated/verified? If so, please describe how.
    } \\
    %%%
    The data was synthesized from key PDE control templates, augmented through principled methods, and verified by experts. Real-world problems were collected via a questionnaire-based manual curation process involving students and researchers. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Over what timeframe was the data collected?
    }
    Does this timeframe match the creation timeframe of the data associated
    with the instances (e.g., recent crawl of old news articles)? If not,
    please describe the timeframe in which the data associated with the
    instances was created. Finally, list when the dataset was first published.
    } \\
    %%%
    The synthetic dataset was generated in late 2024, with real-world problems curated in 2025. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{What mechanisms or procedures were used to collect the data (e.g., hardware
    apparatus or sensor, manual human curation, software program, software
    API)?
    }
    How were these mechanisms or procedures validated?
    } \\
    %%%
    Procedures included automated STL generation, natural language augmentation using GPT-4, and manual problem formulation. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{What was the resource cost of collecting the data?
    }
    (e.g. what were the required computational resources, and the associated
    financial costs, and energy consumption - estimate the carbon footprint.)} \\
    %%%
    Resource costs included computational expenses for data synthesis and human time for manual curation and validation.
    \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{If the dataset is a sample from a larger set, what was the sampling
    strategy (e.g., deterministic, probabilistic with specific sampling
    probabilities)?
    }
    } \\
    %%%
    Not applicable. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Who was involved in the data collection process (e.g., students,
    crowdworkers, contractors) and how were they compensated (e.g., how much
    were crowdworkers paid)?
    }
    } \\
    %%%
    Graduate students and researchers with expertise in applied mathematics and AI. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Were any ethical review processes conducted (e.g., by an institutional
    review board)?
    }
    If so, please provide a description of these review processes, including
    the outcomes, as well as a link or other access point to any supporting
    documentation.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Does the dataset relate to people?
    }
    If not, you may skip the remainder of the questions in this section.
    } \\
    %%%
    No. \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Did you collect the data from the individuals in question directly, or
    obtain it via third parties or other sources (e.g., websites)?
    }
    } \\
    %%%
    Our manually written data is collected from each individual with questions.\\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Were the individuals in question notified about the data collection?
    }
    If so, please describe (or show with screenshots or other information) how
    notice was provided, and provide a link or other access point to, or
    otherwise reproduce, the exact language of the notification itself.
    } \\
    %%%
    N/A \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Did the individuals in question consent to the collection and use of their
    data?
    }
    If so, please describe (or show with screenshots or other information) how
    consent was requested and provided, and provide a link or other access
    point to, or otherwise reproduce, the exact language to which the
    individuals consented.
    } \\
    %%%
    N/A \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{If consent was obtained, were the consenting individuals provided with a
    mechanism to revoke their consent in the future or for certain uses?
    }
     If so, please provide a description, as well as a link or other access
     point to the mechanism (if appropriate)
    } \\
    %%%
    N/A \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Has an analysis of the potential impact of the dataset and its use on data
    subjects (e.g., a data protection impact analysis)been conducted?
    }
    If so, please provide a description of this analysis, including the
    outcomes, as well as a link or other access point to any supporting
    documentation.
    } \\
    %%%
    No. Our data are intended to be used in evaluation only and all charts are publicly avialable.  \\
    %%% 
    
    \textcolor{\sectioncolor}{\textbf{Any other comments?
    }} N/A \\
    %%%
    %%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preprocessing / Cleaning / Labeling}

    \textcolor{\sectioncolor}{\textbf{Was any preprocessing/cleaning/labeling of the data
    done(e.g.,discretization or bucketing, tokenization, part-of-speech
    tagging, SIFT feature extraction, removal of instances, processing of
    missing values)?
    }
    If so, please provide a description. If not, you may skip the remainder of
    the questions in this section.
    } \\
    %%%
    Yes, preprocessing included:
1) Reformatting natural language prompts;
2) Validating STL and Python code for correctness and executability;
3) Augmenting natural language data using rephrasing techniques. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Was the “raw” data saved in addition to the preprocessed/cleaned/labeled
    data (e.g., to support unanticipated future uses)?
    }
    If so, please provide a link or other access point to the “raw” data.
    } \\
    %%%
    Yes, raw data and intermediate representations are retained for reproducibility and future use. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Is the software used to preprocess/clean/label the instances available?
    }
    If so, please provide a link or other access point.
    } \\
    %%%
    The tools and scripts for preprocessing are included in the supplementary materials of the PDE-Controller framework. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Any other comments?
    }} \\
    %%%
    Preprocessing ensures high-quality alignment between natural language, formal logic, and executable code. \\
    %%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Uses}

    \textcolor{\sectioncolor}{\textbf{Has the dataset been used for any tasks already?
    }
    If so, please provide a description.
    } \\
    %%%
    Yes, it was used to train and evaluate the PDE-Controller framework and benchmark its performance against state-of-the-art LLMs. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Is there a repository that links to any or all papers or systems that use the dataset?
    }
    If so, please provide a link or other access point.
    } \\
    %%%
    N/A \\
    %%%

    \textcolor{\sectioncolor}{\textbf{What (other) tasks could the dataset be used for?
    }
    } \\
    %%%
    The dataset could be used for:
1) Training models for scientific reasoning and formalization;
2) Developing tools for automated program synthesis;
3) Advancing research in AI-driven engineering and physics. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Is there anything about the composition of the dataset or the way it was
    collected and preprocessed/cleaned/labeled that might impact future uses?
    }
    For example, is there anything that a future user might need to know to
    avoid uses that could result in unfair treatment of individuals or groups
    (e.g., stereotyping, quality of service issues) or other undesirable harms
    (e.g., financial harms, legal risks) If so, please provide a description.
    Is there anything a future user could do to mitigate these undesirable
    harms?
    } \\
    %%%
    N/A \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Are there tasks for which the dataset should not be used?
    }
    If so, please provide a description.
    } \\
    %%%
    The dataset is not suitable for tasks unrelated to PDE control or tasks requiring real-world human data. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Any other comments?
    }} \\
    %%%
    The dataset's structured format supports reproducible and extensible research in applied mathematics. \\
    %%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Distribution}

    \textcolor{\sectioncolor}{\textbf{Will the dataset be distributed to third parties outside of the entity
    (e.g., company, institution, organization) on behalf of which the dataset
    was created?
    }
    If so, please provide a description.
    } \\
    %%%
    Yes, the dataset will be made publicly available for research purposes. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{How will the dataset will be distributed (e.g., tarball on website, API,
    GitHub)?
    }
    Does the dataset have a digital object identifier (DOI)?
    } \\
    %%%
    The dataset will be distributed via GitHub and academic repositories, with accompanying documentation. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{When will the dataset be distributed?
    }
    } \\
    %%%
    The dataset is expected to be released following the ICML 2025 conference. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Will the dataset be distributed under a copyright or other intellectual
    property (IP) license, and/or under applicable terms of use (ToU)?
    }
    If so, please describe this license and/or ToU, and provide a link or other
    access point to, or otherwise reproduce, any relevant licensing terms or
    ToU, as well as any fees associated with these restrictions.
    } \\
    %%%
    Yes, it will be distributed under a permissive license (e.g., CC BY-SA 4.0) to encourage research use. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Have any third parties imposed IP-based or other restrictions on the data
    associated with the instances?
    }
    If so, please describe these restrictions, and provide a link or other
    access point to, or otherwise reproduce, any relevant licensing terms, as
    well as any fees associated with these restrictions.
    } \\
    %%%
    All charts are subjected to their respective copyrights by the authors of this paper. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Do any export controls or other regulatory restrictions apply to the
    dataset or to individual instances?
    }
    If so, please describe these restrictions, and provide a link or other
    access point to, or otherwise reproduce, any supporting documentation.
    } \\
    %%%
    N/A \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Any other comments?
    }} \\
    %%%
    Distribution will include detailed usage guidelines to ensure proper application of the dataset. \\
    %%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Maintenance}

    \textcolor{\sectioncolor}{\textbf{Who is supporting/hosting/maintaining the dataset?
    }
    } \\
    %%%
    The authors of the PDE-Controller framework. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{How can the owner/curator/manager of the dataset be contacted (e.g., email
    address)?
    }
    } \\
    %%%
    Contact information will be provided with the dataset release. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Is there an erratum?
    }
    If so, please provide a link or other access point.
    } \\
    %%%
    N/A \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Will the dataset be updated (e.g., to correct labeling errors, add new
    instances, delete instances)?
    }
    If so, please describe how often, by whom, and how updates will be
    communicated to users (e.g., mailing list, GitHub)?
    } \\
    %%%
    Yes, periodic updates will incorporate additional real-world problems and refinements. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{If the dataset relates to people, are there applicable limits on the
    retention of the data associated with the instances (e.g., were individuals
    in question told that their data would be retained for a fixed period of
    time and then deleted)?
    }
    If so, please describe these limits and explain how they will be enforced.
    } \\
    %%%
    N/A \\
    %%%

    \textcolor{\sectioncolor}{\textbf{Will older versions of the dataset continue to be
    supported/hosted/maintained?
    }
    If so, please describe how. If not, please describe how its obsolescence
    will be communicated to users.
    } \\
    %%%
    Yes, previous versions will remain accessible for reproducibility. \\
    %%%

    \textcolor{\sectioncolor}{\textbf{If others want to extend/augment/build on/contribute to the dataset, is
    there a mechanism for them to do so?
    }
    If so, please provide a description. Will these contributions be
    validated/verified? If so, please describe how. If not, why not? Is there a
    process for communicating/distributing these contributions to other users?
    If so, please provide a description.
    } \\
    %%%
    Yes, contributions will be encouraged through a collaborative platform (e.g., GitHub).\\
    %%%

    \textcolor{\sectioncolor}{\textbf{Any other comments?
    }} \\
    %%%
    The dataset’s maintainers are committed to ensuring its long-term usability and relevance for scientific research.
    %%%

\vspace{-2ex}
\section{Misc.}
\textbf{URL to benchmark.} The benchmark URL can be found here: 
N/A

\textbf{URL to Croissant metadata.} The Croissant metadata URL can be found here:
N/A


\textbf{Author statement \& license information.} We the authors bear all responsibility in case of violation of rights.

\textbf{Hosting and maintenance.}
We will have a dedicated GitHub page for hosting instructions.
We are committed to performing major maintenance every 6 months.

\textbf{Dataset Structure.}
All files are stored in the JSONL format. For the translator dataset, we store separate files based on STL syntax formats, the number of constraints, and the train-test split. Each training file contains more than 600 samples, and each test file contains more than 150 samples. Each sample includes the informal question in natural language, the STL representation in LaTeX, and the corresponding Python script.

For the preference dataset, we split the files based on three difficulty levels and the train-test split. Each sample in the file contains the informal question in natural language, the winner STL that improves the informal question, and the loser STL that worsens it. For each STL, we also provide the resulting utility score. 
