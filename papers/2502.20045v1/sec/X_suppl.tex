% \clearpage
% \setcounter{page}{1}
% \maketitlesupplementary



% \maketitle
\thispagestyle{empty}
\appendix
% \setcounter{page}{1}
\maketitlesupplementary
%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
In this supplementary material, we provide additional details and results that are not included in the main paper due to the space limit.

\section{Implementation details}
% 我们的框架提供了一个简单直观的交互界面来辅助用户绘制user-specified VDM来初始化base mesh. 每一轮迭代 we 在我们设置的相机分布中随机render 四张不同视角的 normal images at a resolution of 512×512 pixels.我们的相机部分是。。。。。. We then feed them into the Stable Diffusion 2.1 to caculate SDS loss. 在烘焙过程中，我们把最终mesh的每个顶点的坐标值写入对应的像素点中，得到一张三通道, 分辨率为512×512的exr文件格式的图片，这个exr格式的图片作为最终的VDM输出. The generation process runs on a single NVIDIA RTX 4090 GPU with 10, 000 iterations per brush, which takes around 40 minutes.
\noindent
\textbf{Shape Control.}
Our framework provides a simple and intuitive interactive interface (\Cref{Fig: Interface Design}) to assist users in drawing user-specified VDMs to initialize the base mesh. 

\noindent
\textbf{Brush Optimization.}
In each iteration, We randomly sample camera poses in multi-view and render $N$ view normal images at a resolution of 512×512 pixels. We sample the elevation angle as $\phi_{\text{elev}} \sim \mathcal{U}\left(0, \frac{\pi}{3}\right)$, and the azimuth angle as $\phi_{\text{azim}} \sim \mathcal{U}(0, 2\pi)$. We set $N = 4$ in our experiment. We then feed them into the Stable Diffusion 2.1 to calculate the score distillation sampling (SDS) loss. The generation process runs on a single NVIDIA RTX 4090 GPU with 10, 000 iterations per brush, which takes around 40 minutes.

\noindent
\textbf{VDM Baking.}
For the VDM baking, we write the coordinate values of each vertex of the final mesh into the corresponding pixels, resulting in a three-channel image with a resolution of 512×512 in EXR file format. This EXR image serves as the final VDM output of the generated brush. 
 
\subsection{Interface Design for Shape Control}

\begin{figure}[tbh]
\centering
\includegraphics[width=0.5\textwidth]{sec/Figures/interface_design.pdf}
\caption{
    \textbf{Interface design.} 
}
\label{Fig: Interface Design}
\end{figure}

\subsection{Details of CFG-Weighted Blending}
% 为了获得semantic focus的text embedding来得到更精确的目标分布来缓解原生SDS来的的语义耦和问题，we propose to enhance the semantics of part-related words by applying classifier-free guidance (CFG) weighted blending to the tokens in the prompt. 具体而言, we assign each word in the prompt a CFG weight $s$ and compute the weighted embedding $e_w$ for each word by blending original text embedding $e$ with the empty text embedding $e_{\phi}$ as follows: $e_w = e_{\phi} + s\cdot (e - e_{\phi}) $. By concatenating the weighted embeddings of each word in sequence, we obtain the final semantically focused text embedding。for instance，我们输入prompt：“A horn++ of deer”, 其中++代表对“horn”这个单词进行加权，权重值为1.1^2.正文中所展示的prompt中的黄色下划线单词代表我们在计算text embedding时对该单词进行了权重值为1.21的加权。需要注意的是，这里的CFG权重是计算text embedding时使用的CFG权重，与SDS loss计算过程中使用的CFG guidance scale是分开的。 由于我们使用normal map这种与自然图片差距较大的图片来进行SDS loss计算，我们设置CFG guidance scale 为100。
To obtain semantically focused text embeddings for a more precise target distribution to mitigate the semantic coupling issue in SDS, we propose enhancing the semantics of part-related words by applying classifier-free guidance (CFG) weighted blending to the tokens in the prompt. Specifically, we assign each word in the prompt a CFG weight $s$ and compute the weighted embedding $e_w$ for each word by blending the original text embedding $e$ with the empty text embedding $e_{\phi}$ as follows: $e_w = e_{\phi} + s \cdot (e - e_{\phi})$. By concatenating the weighted embeddings of each word in sequence, we obtain the final semantically focused text embedding. For instance, consider the prompt: \textit{``A horn++ of a deer''}, where \texttt{++} indicates that the word \textit{``horn''} is weighted with a CFG weight of $1.1^2$. In the example prompt shown in the main paper, words with yellow underlines represent those weighted with a CFG value of $1.21$ during the computation of text embeddings. Notably, the CFG weights used for text embedding computation are separate from the CFG guidance scale applied during the computation of the SDS loss. Our experiment uses a CFG guidance scale of 100.

\subsection{Region Control}
% 在我们的框架中，we provide a region mask to restrict mesh deformation to the user-defined region during optimization. By adjusting the activation ratio of the region mask, the final brush effect can effectively match the user’s guidance. 在生成surface details笔刷时，我们activated the region mask for the first half of total iterations as a warm-up stage, 具体控制效果如如中所示。对于geometric structures生成，我们activated the region mask for 整个优化过程。
In our framework, we provide a region mask to restrict mesh deformation to the user-defined region during optimization. By adjusting the activation ratio of the region mask, the final brush effect can effectively match the user’s guidance. When generating surface detail brushes, we activated the region mask during the first half of the total iterations as a warm-up stage, with the specific effects shown in \Cref{Fig: Region Control}. For geometric structures generation, we activated the region mask throughout the entire optimization process.

\begin{figure}[tbh]
\centering
\includegraphics[width=0.5\textwidth]{sec/Figures/region_control.pdf}
\caption{
    \textbf{Region control.} 
}
\label{Fig: Region Control}
\end{figure}

\section{Details of Experiment Setting}

\subsection{Details of Re-framed Paint-it}
% Paint-it originally uses SDS to optimize a UNet for generating PBR textures. We reframed it to suit our VDM brush generation task. 具体而言，Paint-it原有的架构中使用Unet从一个固定的512×512的高斯噪音图中预测一个九通道输出，每三个通道分别对应diffuse，specular，normal. 我们修改Unet只输出三个通道，对应一个VDM，我们把VDM每个像素的三个值直接应用到对应的mesh顶点进行三轴displacement来得到变形后的mesh，之后我们同样渲染出normal map来计算SDS loss，为了保证mesh的质量，我们添加了促进网格平滑的regulization，如laplacian，edge，normal consistency。
Paint-it originally uses SDS to optimize a UNet for generating PBR textures. We reframed it to suit our VDM brush generation task. Specifically, in the original Paint-it architecture, a UNet is used to predict a nine-channel output from a fixed 512×512 Gaussian noise image, where every three channels correspond to diffuse, specular, and normal maps, respectively. We modified the UNet to output only three channels, representing a VDM. Each pixel's three values in the VDM are directly applied to the corresponding mesh vertices for three-axis displacement, resulting in the deformed mesh. We then render the normal map from the deformed mesh to compute the SDS loss. To ensure the quality of the mesh, we introduced regularization terms to facilitate mesh smoothness, such as Laplacian, edge, and normal consistency regularization.

\subsection{Base Mesh Initialization}
%在我们生成geometric structures的实验中，为了保证与Text2Mesh,TextDeformer工作的公平比较，我们使用同样的初始base mesh as shown in 图片，具体的prompt与base mesh的对应我们在table1中进行了标注。因为Pint-it是直接生成VDM的方法，我们只使用planar base mesh。
In our experiments for generating geometric structures, to ensure a fair comparison with Text2Mesh and TextDeformer, we used the same initial base mesh as shown in \Cref{Fig: Base Mesh Initialization}. The specific correspondence between prompts and base meshes is detailed in \Cref{tab:table1}. Since Paint-it directly generates VDMs, we only used a planar base mesh.
\begin{figure}[tbh]
\centering
\includegraphics[width=0.4\textwidth]{sec/Figures/base_initialization.pdf}
\caption{
    \textbf{Base mesh initialization.} 
}
\label{Fig: Base Mesh Initialization}
\end{figure}

\subsection{Text Prompt of Quantitative Comparison}
As described in Section 4.2 of the main paper, we used 40 text prompts for VDM generation and quantitative evaluation, with 20 focusing on surface details and the remaining 20 on geometric structures. The specific text prompts are detailed in \Cref{tab:table1}.

% A Table
\begin{table}[thb]\centering
    \caption{Text Prompts for VDM Generation.}
    \label{tab:table1}
    \resizebox{0.48\textwidth}{!}{
    \large
    \begin{tabular}{*{10}{c}}
       %\toprule
       VDM Type &  Text Prompt\\
        \midrule
        Surface Details 
         &  A blanket surface with many flowers \\
         &  A brick wall surface with neat brick \\
         &  A broken brick wall surface with many cracks \\
         &  A broken glass surface like spider web \\
         &  A broken wall surface damaged by a cannonball \\
         &  A broken wall surface with many cracks \\
         &  A cloth surface with a rose pattern \\
         &  A cloth surface with a sunflower pattern \\
         &  A torn cloth surface \\
         &  An arid land surface \\
         &  A stone surface with many cracks \\
         &  A broken stone surface with many cracks \\
         &  A dragon skin surface with many scales \\
         &  A lion fur surface \\
         &  A new wooden floor \\
         &  An aged wooden surface \\
         &  A rusty metal surface with many cracks \\
         &  A surface of rusty metal \\
         &  A skin surface with a scar mended by needle and thread \\
         &   A skin surface with terrible wounds \\
        \midrule
         Geometric Structures  
         &  A lip of human (a)\\
         &  A human spine (a)\\
         &  A mouth of a monster (a)\\
         &  A skeleton hand (a)\\
         &  A tortoiseshell (a)\\
         &  A round snail shell (a)\\
         &  An eye of a monster (a)\\
         &  A dragon wing (b)\\
         &  An angel wing (b) \\
         &  An ear of the devil (b)\\
         &  A dorsal fin of a fish (c)\\
         &  A horn of a dragon (d)\\
         &  A goat horn (d)\\
         &  A horn of the devil (d)\\
         &  A horn of a deer (d)\\
         &  An octopus tentacle (d)\\
         &  An ox horn (d)\\
         &  A royal pauldron (e)\\
         &  A beard of a man (e)\\
         &  A human ear (f)\\
        %\bottomrule
    \end{tabular}
    }
\end{table}


\section{Additional Results}

\subsection{More Examples of Semantic Coupling}
%我们在这小节中展示了更多语义耦合的例子. 如图所示，直接使用SDS进行鹿角的生成会导致生成整个的鹿头，或者在生成胡子时会连带生成鼻子。我们的方法能够显著缓解语义耦生成高质量的sub-object structure.
In this subsection, we present more examples of semantic coupling. As shown in \Cref{Fig: More Examples of Semantic Coupling}, directly using SDS for generating a deer horn leads to the generation of the entire deer head, or generating a beard also results in the generation of the nose. Our method significantly alleviates this semantic coupling issue, enabling the generation of high-quality sub-object structures.
\begin{figure}[tbh]
\centering
\includegraphics[width=0.5\textwidth]{sec/Figures/more sman.pdf}
\caption{
    \textbf{More examples of semantic coupling.} 
}
\label{Fig: More Examples of Semantic Coupling}
\end{figure}

\subsection{More Comparison Results}
%我们展示了更多的Qualitative Results for surface details and geometric structures. 我们的方法能够生成更高质量更vivid的结果，as shown in 图片. 
We provide more qualitative results for surface details and geometric structures. Our method can generate higher-quality and more vivid results, as shown in \Cref{Fig: surface details} and \Cref{Fig: geometric structures}.



\begin{figure*}[t!]
\centering
\includegraphics[width=1\textwidth]{sec/Figures/2.png}
\caption{
    \textbf{More application examples of interactive modeling.} 
}
\label{Fig: Application}
\end{figure*}

\begin{figure*}[t!]
\centering
\includegraphics[width=1\textwidth]{sec/Figures/helmet.pdf}
\caption{
    \textbf{More application examples of mesh stylization.} 
}
\label{Fig: Application}
\end{figure*}




\subsection{More Application Examples}
%我们展示了更多使用我们生成的笔刷进行雕刻的例子，We enable users to interactively use a variety of generated brushes to sculpt diverse and expressive models from a plain shape.
We also provide more examples of sculpted models using the generated VDM brushes. We enable users to interactively use a variety of generated brushes to sculpt diverse and expressive models from a plain shape.

\begin{figure*}
\centering
\includegraphics[width=0.65\textwidth]{sec/Figures/more_surface_details.pdf}
\caption{
    \textbf{More comparison results of brushes for surface details.} 
}
\label{Fig: surface details}
\end{figure*}

\begin{figure*}
\centering
\includegraphics[width=1\textwidth]{sec/Figures/more_geo_quali1-1.pdf}
\caption{
    \textbf{More comparison results of brushes for geometric structures.} 
}
\label{Fig: geometric structures}
\end{figure*}

