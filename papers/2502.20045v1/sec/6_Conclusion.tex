\begin{figure}
\centering
\includegraphics[width=0.48\textwidth]{sec/Figures/cloth.png}
\caption{\textbf{Coarse to fine interactive modeling.} By combining geometric structures brushes and surface details brushes for iterative sculpting in modeling software, users can rapidly create an expressive model from a plain shape (top left).}
\label{Fig: Coarse to Fine Interactive Modeling}
\end{figure}

\section{Conclusion}
\label{sec:Conclusion}
We have presented Text2VDM, a novel framework for VDM brush generation from text. A VDM is a non-natural 2D image where each pixel stores a 3D displacement vector, making it challenging for existing T2I models to generate. Thus, We treat VDM generation as mesh deformation via the Laplace-Beltrami operator from a dense planar mesh.
% This allows users to engage in a real-time, iterative 3D model creation process. 
To generate the intended effects of surface details and geometric structures, we provide two control methods: region control and shape control. Additionally, VDM brushes often contain sub-object structures, which can lead to semantic coupling issues in SDS. We propose using CFG-weighted blending for prompt tokens to effectively mitigate this, achieving high-quality brush generation.
The generated VDM brushes are directly compatible with mainstream modeling software, enabling various applications such as mesh stylization and real-time interactive modeling.
% Additionally, VDM brushes often involve sub-object level structure, which can cause semantic coupling issues in SDS. We propose that applying CFG-weighted blending to the tokens in the prompt can effectively mitigate it, resulting in high-quality sub-object structure generation.
% We expect Text2VDM to more effectively translate recent AI achievements in text-to-image generation into the 3D asset creation workflows used by artists.

\textbf{Limitations and future work}. While our framework can generated high-quality VDM brushes, they may encounter multi-view inconsistencies, a common issue introduced by SDS. 
% For example, when generating lips, the results might produce two separate lips from different angles.
To further address it, the view-consistent diffusion model proposed in MV2MV~\cite{MV2MV} may be helpful.



%Acknowledgement
% \section*{Acknowledgments}
% \noindent This work was partially supported by Guangzhou-HKUST(GZ) Joint Funding \#2023A03J0670 and
% Guangzhou Basic Research Scheme \#2024A04J4229.