\section{Reader Study: Methodology}
% Grace (not sure we need) We want to understand whether readers prefer scientific explanations that use prevalent social media communication techniques to explain science. Do readers like explanations with an example (or could the example be unrelatable to their daily life and fail to connect the reader with the topic)? Do readers like explanations that walkthrough the example step-by-step (or does that become too complicated to follow)? Do readers like personal language (or does it undermine the authority of the writer)?

% Grace (not sure we need)  We develop hypotheses and conditions to investigate these questions. We generate science explanations on 15 STEM topics using an LLM and ask 35 readers to rate their understanding and engagement on a Likert-scale survey.  

%purpose: overview and motivate our study is interesting

% In particular, do readers like explanations that have an example (or does the example GET too specific to a single application and fail to motivate the topic)?

%We want to know whether readers prefer Tweetorials that use the science communication techniques SEEN on social media. 

%We generate tweetorials for ALL THESE CONDITIONS on multiple STEM topics using GPT-4 and ask readers to rate their understanding and engagement on a Likert Scale. 

% \grace{thinking about the paper as 3 things that writers could do when writing tweetorials, but writers are uncomfortable doing. here are 3 things that experienced writers do, but should they do it or what do readers think?? when thinking about research about features it's always about it doesn't have these features and is it good to add them, so this needs to be a bit better because we compare EWP to EWP-RemoveE, so it's not really the same structure of add/remove features}
% \grace{Tweetorials, not broadly }

\subsection{Research Questions}
Tweetorials typically include three techniques \textbf{example (E)}, \textbf{walkthrough (W)}, and \textbf{personal language (P)} \cite{10.1145/3479566}. We want to understand how each of these techniques affects readers' ratings of science communication on social media. Given that most published Tweetorials contain these three techniques, we hypothesize that science explanations that contain all three features, \textbf{EWP}, will have the highest reader preference rating. To evaluate the effect of the 3 different features, we compare narratives with all three features (\textbf{EWP}) to narratives with one of the features removed (\textbf{EW}, \textbf{EP}, \textbf{WP}). We investigate the following hypotheses in a survey study with readers:

\textbf{H1: Example (E)}: Readers prefer explanations with an example (EWP) compared to those without an example (WP). 

\textbf{H2: Walkthrough (W)}: Readers prefer explanations that include a step-by-step walkthrough of the topic using an example (EWP) compared to explanations with multiple unrelated examples (EP). 

\textbf{H3: Personal Language (P)}: 
Readers prefer explanations that use personal and subjective language (EWP) compared to explanations that have a neutral scientific voice (EW).

% \textbf{H4: All three techniques (EWP)}: Readers prefer explanations that use all three techniques of example, walkthrough, and personal language (EWP) compared to explanations that use a subset of the three techniques. \grace{we don't actually test these techniques invidiually, the accurate H4 would be: Readers prefer explanations with all 3 explanation techniques compared to explanations that only use 2 of the 3 techniques. (which i think is basically equivalent to finding H1, H2, H3...)}

Testing each of these hypotheses requires comparing two explanations for the same scientific topic that are as similar as possible and only vary in whether they contain a example, walkthrough or personal language. Parallel examples like this are unlikely to occur naturally. Thus, we use AI to generate parallel explanations in each condition (See Section \ref{narrative_generation_strategy}). 

% \color{lightgray}

% \textbf{H1:Examples}: Readers prefer explanations with examples compared to those without an example. 

% To test this we generated two explanations for the same topic: 
% Our experimental condition was generated by a prompt that included everything (with instructions to include an example, walkthrough, and personal language), or \textit{EWP (Everything)} for short.
% The baseline condition had to be as similar as possible, except for not including an example. Thus, we asked the LLM to take the EWP (Everything) explanation and simply 'remove the example'. We call this \textit{EWP-RemoveE}.

% %Compare \textit{EWP (Everything) } to \textit{EWP - RemoveE}

% \textbf{H2:Walkthrough}: Readers prefer explanations that include a step-by-step walkthrough of the topic using an example compared to explanations with multiple unrelated examples. 
% To test this we generate two explanations for the same topic: 
% The experimental condition is the same as \textit{EWP (Everything) } but without few-shot training data. we call this \textit{EWP (Everything) - NoFewShot}.
% The baseline condition was generated using a prompt that instructed GPT to not walkthrough the explanation sequentially, but to include examples and personal language.
% %and to explain the topic and its different aspects in a segmented modular approach. 
% The baseline condition also has no few-shot training data.  We call this \textit{EP - NoFewShot}. 
% %Due to walkthrough is deeply integrated in the structure of the writing, GPT was unscuccessful in removing it... 

% %Compare \textit{EWP (Everything) - NoFewShot} to \textit{EP - NoFewShot}

% \textbf{H3:Personal Language}: 
% %Readers prefer explanations that use personal and subjective language rather than explanations that are have an objective (WRONG WORD) scientific voice.
% Readers prefer explanations that use personal and subjective language compared to explanations that have a neutral scientific voice.
% To test this we generate two explanations for the same topic: 
% The experimental condition is the same as \textit{EWP (Everything)}. 
% The baseline condition is as similar as possible except for not using personal language. Thus, we asked the LLM to take EWP (Everything) explanation and simply 'remove the emotional and subjective language'. We call this \textit{EWP - RemoveP}. 

%Compare \textit{EWP (Everything)} to \textit{EWP - RemoveP}
\color{black}

% \begin{enumerate}
%     \item[\textbf{H1}] Readers prefer Twitter threads that have a relatable example (E) over X . 
%     \item[\textbf{H2}] Readers prefer Twitter threads that have a step-by-step walkthrough (W) of one example over X. 
%     \item[\textbf{H3}] Readers prefer Twitter threads that use personal language (P) over X.   
%     % The audience prefers the Twitterorial that uses personal language and speaks from the writer's first-person perspective over the one that only uses objective language. 
% \end{enumerate}

% In the study, for each hypothesis, we compare two conditions A and B.
% In condition A, which we call "everything", all three techniques are included: example (E), walkthrough (W), and personal language (P). A is compared with a condition B where one technique is missing.

% For H1, we compared two conditions - A. everything(EWP) vs. B. No example(-E). (See Table \ref{Hypothesis_Example_Conditions})

% For H2, we compared two conditions - A. everything(EWP)  vs. B. No walkthrough(-W). (See Table \ref{Hypothesis_Walkthrough_Conditions})

% For H3, we compared two conditions - A. everything(EWP) vs. B. No personal language(-P). (See Table \ref{Hypothesis_Personal_Conditions}) 

% Below, We describe what science topics are used in the study in Section \ref{topic_select}, how Twitter threads used in each condition are generated in Section \ref{Twitter-gen}, participants recruitment in Section \ref{user-study1}, survey design, data collection and analysis in Section \ref{data}. 

\subsection{Automatic Narrative Generation Strategy}
\label{narrative_generation_strategy}

We used OpenAI's GPT-4 API to generate science explanations with and without each technique in the form of Tweetorials (about 10 tweets in length) to ensure consistency and to make fair comparisons between science explanations. We describe the method for each technique in Sections \ref{H1_Prompting}, \ref{H2_Prompting}, and \ref{H3_Prompting}.

% To understand reader preferences for examples (H1), walkthrough (H2), and personal language (H3) in science communication, we need to compare science explanations with and without these three techniques for the same topic. There do not exist Twitter threads of the same topic in the wild that are rigorously written with and without each of the three techniques. No prior research has made comparisons between these conditions. As such, 

We cover 5 diverse STEM fields: a physical science field (Physics), a social science field (Psychology), a technological field (Computer Science), a mathematical field (Statistics), and an engineering field (Civil Engineering). For each field an expert selected topics for 3 different levels of complexity (introductory, intermediate, and advanced levels) for a total of 15 topics (Appendix \ref{stem_topics}). We generated 75 different science explanations (5 conditions for each topic) for readers to rate. Each science explanation was validated by a corresponding expert for accuracy. We describe exact prompting methods for each hypothesis (H1: Example (E), H2: Walkthrough (W), H3: Personal Language(P)) below.

\subsubsection{Generating Tweetorials with and without Examples (H1)} 
\label{H1_Prompting}

We used GPT-4 to generate science narratives that contain an \textbf{E}xample, \textbf{W}alkthrough, and \textbf{P}ersonal language. We included five few-shot examples of published Tweetorials on Twitter to create our experimental condition: \textbf{EWP}. Experts on each topic provided data inputs [use case] and [scenario] (described in Section \ref{example_defintion}) to define the specific example the given narrative should use throughout the explanation. We provided specific guidelines regarding how the LLM should incorporate the given example, a walkthrough, and personal language. We iterated on each line separately and in compilation to ensure that the prompt was concise, essential, and reasonably consistent (Appendix \ref{prompts}). 

To generate the baseline condition, \textbf{WP}, we use a ``remove" method which provides GPT-4 a given narrative and a set of guidelines that specifies what technique to remove from the given narrative while maintaining all other conditions. The output is a new narrative with only the specified technique removed. To generate a science narrative without an example, we use the ``remove" method on the example. We pass in the experimental condition narration, \textbf{EWP}, and a set of guidelines that specify only the example should be removed from the narrative while maintaining all other elements such as structure and style (Appendix \ref{WP_prompt}). We use this same prompting strategy to ``remove personal language" in Section \ref{H3_Prompting}.

Figure \ref{fig:example} shows a side-by-side annotated example of the experimental condition (EWP) and baseline condition (WP) for the topic of Walker's Action Decrement Theory. The lack of example highlights in green in the baseline condition shows the effect of no example in contrast with the explanation with everything.


% All generated narratives were evaluated by experts from each field to ensure technical accuracy and adherence to the given condition (EWP or WP) and regenerated until all conditions were satisfied. 
% \begin{figure}
%     \centering
%     \includegraphics[width=0.9\linewidth]{Figures/H1_prompts.png}
%     \caption{\textbf{H1:Example Prompts} Used to generate the experimental condition, EWP (Everything), and baseline condition (EWP-RemoveE)}
%     \label{fig:H1_example_prompts}
% \end{figure}


\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/Example_Annotate.png}
    \caption{\textbf{H1: Example} Sample explanation generations on the topic of "Walker's Action Decrement Theory" in Psychology comparing the experimental condition (EWP) and baseline condition (WP).}
    \label{fig:example}
\end{figure}



% We used the ``remove example" approach in order to maintain all other aspects of the science explanation such as structure, style, word choice, and flow and only remove the aspect that we wanted to test: the example (E). 

\subsubsection{Generating Tweetorials with and without Personal Language (H3)} \label{H3_Prompting}
To understand reader preferences for science explanations with and without personal language (H2:Personal Language), we followed a similar GPT-4 generation protocol as in Section \ref{H1_Prompting} to generate the experimental condition which contains all three techniques and few-shot examples, \textbf{EWP}. To generate the baseline condition, we used the ``remove" procedure from Section \ref{H1_Prompting} to ``remove personal language" from the experimental condition, \textit{EWP}. We pass in \textit{EWP} and specify guidelines to only remove the personal language while maintaining all structural elements of the science explanation to create \textbf{EW}. 

Figure \ref{fig:personal} shows a side-by-side annotated example of the experimental condition (EWP) and baseline condition (EW) for the topic of Walker's Action Decrement Theory. The lack of personal language highlights in yellow in the baseline condition shows the effect of removing personal language from EWP. 

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/PersonalLanguage_annotate.png}
    \caption{\textbf{H3:Personal Language} Sample explanation generations on the topic of Walker's Action Decrement Theory in Psychology comparing the experimental condition (EWP) and baseline condition (EW).}
    \label{fig:personal}
\end{figure}

% \grace{method is only justifable if EWP is the baseline: if we claim that removing the example is a lower line, the the lower line is a tweetorial with none of the features. EWP is the baseline that means that most existing tweetorials contain these features. baseline  = standard operating conditinos}



\subsubsection{Generating Tweetorials with and without Walkthroughs (H2)} \label{H2_Prompting}
% \grace{re-word this sentence to 

% to understand reader preferences we use GPT to evaluate reader preferences with and wihtout }
To understand reader preferences for walkthroughs (H2:Walkthrough), we used GPT-4 to generate two different science explanations with contrasting narrative structures. In preliminary testing, we found that the ``remove" method failed to generate narratives without walkthroughs because the walkthrough served as the narrative structure. Thus, we provide the data inputs of [topic] and [domain] and a new set of guidelines to GPT-4 to generate narratives without a walkthrough (Appendix \ref{EP_prompt}). The guidelines specify instructions for not using a walkthrough (e.g. the explanation should use a non-sequential approach and that every tweet stands alone). No few-shot examples were added because there were no published Tweetorials with no walkthrough to create \textbf{EP-NoFewShot}.

We used the same base prompt as the experimental conditions in Section \ref{H1_Prompting} and Section \ref{H2_Prompting} to generate a science explanation with an \textbf{E}xample, \textbf{W}alkthrough and \textbf{P}ersonal language. To maintain a fair comparison with EP-NoFewShot, we omitted few-shot examples to create \textbf{EWP-NoFewShot}. Figure \ref{fig:walkthrough} highlights the differences between science narratives with and without walkthroughs.

% We kept the same base prompt and data inputs as in Section \ref{H1_Prompting}. 

% \begin{figure}
%     \centering
%     \includegraphics[width=0.9\linewidth]{Figures/H2_prompts.png}
%     \caption{\textbf{H2:Example Prompts} Used to generate the experimental condition (EWP - NoFewShot) and baseline condition (EP - NoFewShot) }
%     \label{fig:H2_example_prompts}
% \end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/Walkthrough_Annotate.png}
    \caption{\textbf{H2: Walkthrough} Sample explanation generations on the topic of Back Propagation in Computer Science contrasting experimental condition (EWP-NoFewShot) and baseline condition (EP-NoFewShot).}
    \label{fig:walkthrough}
\end{figure}

% No few-shot training examples were used because there were no applicable, human-written Tweetorials with no walkthrough that we could include.

% \grace{want to go in the order of EPW where the walkthrough part comes last so the reader isn;t jumping around between tehse different thigns -- combine personal alnauge and example section: remove procedire doesn't work for walkthrough in the enxt section we describe the procedure that we do for that}

% \grace{if possible, add an API access date / range }

 
% we selected five STEM fields (Computer Science, Physics, Statistics, Civil Engineering, Psychology), including 1 math, 1, technology,  1 engineering, 1 physical science (Physics) and a social science (Psychology).


% For each topic, we generated one Tweetorial of each of the five conditions: \textit{EWP (Everything)}, \textit{EWP (Everything) - NoFewShot}, \textit{EWP - RemoveE}, \textit{EP - NoFewShot}, \textit{EWP - RemoveP}. 
% Our dataset contains a total of 75 Tweetorials (5 conditions × 5 fields of study ×  3 levels of complexity).

% \yy{Question to Lydia: -- To make our numbers look larger -- at one point, we had 3 topics / level, but we decided not to conduct the reader study for all of them due to time and \$\$. Do we want to say our dataset is 225 tweetorials, but study is on 75 tweetorials??}

% After LLM generation, an expert from each field read and validated the Tweetorials for their scientific accuracy. 

% \yy{Experts validated this, but don't mention they are authors.}
%Experts validated the generation. 
% Among our authors, we have experts from each field who proposed the topics and verified the scientific accuracy of GPT-generated writings. One author studied computer science for four years. 
%One author studied physics for three years. One author studied applied statistics in economics and data science for three years. One author is a licensed architect who practiced in the building construction industry for five years, a subdomain of civil engineering. One author studied cognitive psychology and behavioral science for four years. 
%All the generations are validated by experts for their scientific accuracy. 



% Figure \ref{fig:example} shows a segment of "Walker's Action Decrement Theory" in Psychology, with H1:Example experimental condition and baseline condition side by side. The lack of example highlights in green in the baseline condition shows the effect of no example in contrast of the explanation with everything.


% \yy{annotate (with color? highlight?) and describe E, W, P with the examples}


% \begin{figure}
%     \centering
%     \includegraphics[width=0.9\linewidth]{Figures/H3_prompts.png}
%     \caption{\textbf{H3:Personal Language} prompts used to generate the experimental condition with personal language (EWP) and baseline condition without personal langauge (EWP-RemoveP).}
%     \label{fig:H3_example_prompts}
% \end{figure}





% \subsubsection{\textit{EWP (Everything)} example}

% \begin{quote}
% Field: Pyschology\\
% Topic: "Walker's Action Decrement Theory"\\

% Have you ever wondered why you sometimes forget significant events as they are happening, only to remember them more clearly later on? This happened to me last Halloween. I took one of my friends to see a horror movie, and boy, was it frightening! 1/

% I was so shocked by how terrifying the movie was that my mind went completely blank. I couldn't recall the specific details or what exactly was happening in the movie. Is that weird? I was truly scared and clammy, my hands were shaking, and my heart was pounding super fast. 2/

% I barely had any memory of the movie at all! But when I reached home and my adrenaline started to wear off, something strange happened. I found that I could recall the terrifying jump scares, the horrifying scenes, and even the dull background music from each scene! 3/

% Turns out, this is all perceived just how Walker's action decrement theory would predict it. It sounds like intense scholarly jargon, right? But what it stands for is actually really simple – it states that experiencing intense emotions can temporarily interfere with memory. 4/

% According to this theory, the involvement in a highly emotional event can cause us to respond energetically, increasing our physical reactions. I think that's why my heart started pounding and I became clammy and shaky like a leaf in a whirlwind! Wild, isn't it? 5/

% At the peak of the event, the emotional impact acts as a trigger for an internal response that can block out or interfere with our ability to recall certain memories. Unbelievable as it sounds, our bodies can inadvertently play a hide and seek game with our minds! 6/

% Don't worry though, it's not as if these memories are gone for good. Once the adrenaline rush drops and our bodily responses return to normal, the memories come flooding back as if they were hiding behind a curtain, and now the show's ready to start! 7/

% Recall what happened to me? After coming home and my 'fright or flight' response eased up, I suddenly had vivid memories of those bone-chilling jump scares, the frightening scenes, the horror, and even the background music that set the movie's tone. 8/

% So next time you experience something intense that temporarily wipes your memory, don't fret! Walker's action decrement theory has got you covered. As the thrill dissipates, you'll get to enjoy the replay of the experience all over again in the movie theatre of your mind! 9/

% What a fascinating theory, isn't it? It really makes me appreciate the clever ways our brain and body work together to manage and control our experiences. Make sure to remember your own experiences with Walker's Action Decrement Theory! 10/

% \end{quote}



% \subsubsection{\textit{EWP - RemoveE} example}

% \begin{quote}
% Field: Pyschology\\
% Topic: "Walker's Action Decrement Theory"\\

% Have you ever speculated about the instances where you're unable to remember emotionally charged or significant episodes, only to recollect them much more clearly later on? The answer to this lies in understanding a specific psychological theory, known as Walker's action decrement theory. 1/

% Walker's action decrement theory provides an intriguing explanation for this. It states that experiencing intense emotions can temporarily interfere with memory. It sounds like a complex psychological concept, doesn't it? However, it's quite a simple one in reality. 2/

% The theory implies that when we are deeply involved in an emotionally intense event, we respond to it energetically, escalating our physiological responses. This heightened physical response can include an increased heart rate, sweatiness, or even trembling, due to the rush of adrenaline. 3/

% The most compelling part of this theory is that, at the apex of the event, the emotional impact initiates an internal response that can temporarily prevent or disrupt our ability to remember specific details. Figuratively speaking, there is an unexpected game of hide-and-seek happening within us! 4/

% However, these memories aren't permanently inaccessible. The theory assures us that, as the adrenaline rush subsides and our physiological responses return to their default states, the blocked memories resurface. It's as if they were concealed behind a curtain, ready to reveal themselves once the stage is set. 5/

% This mechanism allows us to relive the emotional experience in complete detail. As per Walker's action decrement theory, once the emotional intensity diminishes, all the suppressed memories of the event can significantly and vividly resurface. 6/

% Now, whenever you are confronted with a situation where something emotionally charged temporarily disrupts your memory recall, remember that Walker's action decrement theory offers the explanation. As the intensity eases, you'll find the forgotten details coming back to you in astonishing clarity. 7/

% This theory provides a fascinating explanation for the interplay of emotions, memory recall, and physiological reactions in our body. It gives us significant insight into how our brain and body coordinate to process intense experiences, and how we, in turn, perceive and remember them. 8/

% So, the next time you momentarily forget a significant event, don't worry. Walker's action decrement theory provides an elegant and simple way to understand this phenomenon. This model captures the intricate interplay of emotions and memory, making it an essential psychological theory to remember! 9/

% Aren't psychological theories simply fascinating? They provide us with a myriad of insights into the remarkable ways our brain and body coordinate to process our experiences. So remember, Walker's Action Decrement Theory offers an insightful window into the fascinating world of memory dynamics! 10/

% \end{quote}

% \subsubsection{\textit{EWP (Everything) - NoFewShot} example}



% \begin{quote}
% Field: Computer Science\\
% Topic: Back Propagation\\

% It's a lazy Sunday afternoon. The golden sunlight peeping through the windows, the crispy hint of fall in the air. As I get engrossed in a book, I get the irresistible urge to bake. I find an exciting new cookie recipe online. But will they turn out as expected? 1/

% I carefully follow the recipe down to each detail. As the warm sweet scent wafts through the room, I can hardly wait. But when I taste my first batch, they're way too sugary. Bummer, right? In that moment, I draw parallels with backpropagation in artificial intelligence. 2/

% Now, what on earth is backpropagation? It's an algorithm used in training artificial neural networks. Think of it like GPS guiding you when you've taken a wrong turn, rerouting to get to the destination faster. But how does tweaking a cookie recipe link to AI? 3/

% Just as you’d adjust your recipe based on the taste, machines learning from their mistakes and improving is the crux of backpropagation. Here's the story of one such 'intelligent' machine and its journey. Intrigued? Let's dive deep into this fascinating concept. 4/

% I go back to my cookie dough, realizing I had added too much sugar. I adjust the amount for my next batch but it’s under-sweet this time. Just like an AI model tweaking its parameters based on the error it encountered. Trying, failing, learning, improving. 5/

% Each adjustment I make to my recipe is akin to a step in the backpropagation process. The perfect batch of cookies isn’t an accident but a result of careful refinement. Isn't it amazing how a simple act of baking mirrors the complex world of artificial intelligence? 6/

% As with backpropagation, each mistake is a stepping stone to perfection. Every failure brings it closer to the goal. The sweet taste of success, in my case, a perfect batch of cookies, goes beyond the initial hurdles. That’s the beauty of learning, isn’t it? 7/

% Just like perfecting a recipe, backpropagation involves constant tweaking and learning until we get the desired output. It's not defeat that defines us, but rather how we respond to it. The machine learns, improves and eventually nails it. Much like our cookie baking endeavor. 8/

% So, the next time you find yourself stuck in a loop of trials and errors, remember backpropagation, and remember my cookie story. Every effort you make counts, every mistake brings you a step closer to success. Isn't it fascinating how life mirrors AI? 9/

% In my quest to make the perfect cookie, I found a lesson from the realm of AI. A simple Sunday baking led me to explore the profound concept of backpropagation. Like a perfect cookie recipe, AI too finds its sweet spot through continuous learning and improvement. And that's how we bake and learn, sweet folks! 10/

% \end{quote}

% \subsubsection{\textit{EP - NoFewShot} example}

% \begin{quote}
% Field: Computer Science\\
% Topic: Back Propagation\\

% Let's dive into Backpropagation, a crucial element of AI learning. If AI were a student, Backpropagation would be like its personal tutor, nudging it along to better answers. Imagine your math tutor spotting an error in calculation \& guiding you to correct it. 1/

% Backpropagation is the heart of training a neural network. Think of a Neural Network as an intricate web of neurons. It's like the brain of an AI, processing all the information. Backpropagation helps optimize this 'AI brain' to make smarter predictions. 2/

% At the core, backpropagation is about "learning from mistakes". Picture a toddler learning to walk. If they stumble, they adjust their next step. Similarly, when an AI's prediction is off, backpropagation helps it adjust its calculations. 3/

% Backpropagation hinges on Calculus. Did you ever wonder why you had to learn about derivatives in high school? Well, they're critical here. Just like how a car uses brakes to adjust its speed, AI uses calculus and backpropagation to adjust its learning. 4/

% The AI starts 'guessing' answers initially, quite like shooting darts in the dark. Backpropagation assesses how off these predictions are from the actual answer. It calculates an 'error value' that illustrates how wrong our 'AI student' was. 5/

% Think about cooking a new recipe. The first attempt might not taste perfect. So, you adjust the spices – more salt, less chili. Backpropagation does the same for AI, adjusting the model's predictive 'ingredients' (known as weights) to achieve a better result. 6/

% Think of the weights in an AI model like the dials on a sound mixer. Backpropagation is like a sound engineer, constantly fine-tuning the dials(weights) based on the difference between the desired output and actual result for improved accuracy. 7/

% Where does the term 'Backpropagation' come from? It's because after every prediction, the process sends the error value backward through the network. This ‘feedback’ enables the AI to adjust its calculations and reduce future errors. Backpropagation in essence is all about learning, improving and iterating. 8/

% If AI is like a musician learning a new tune, backpropagation is the process of listening to playback and realizing which notes need fixing. It's the way AI networks get better at hitting their notes – becoming more accurate in their predictions \& responses. 9/

% So remember, Backpropagation helps our AIs learn by 'experience'. It nudges them towards better accuracy and smarter predictions, turning them from clumsy beginners to experts capable of tackling complex problems with ease! 10/
% \end{quote}

% \subsubsection{\textit{EWP-RemoveP} example}


% \begin{quote}

% Field: Psychology\\
% Topic: Walker's Action Decrement Theory\\


% The inability to recall significant events as they unfold, only to remember them clearly later on is a phenomena commonly encountered. One such instance occurred during a screening of a horror movie. The movie was considered imposingly frightening, resulting in a sense of terror. 1/

% It was reported that due to the terror instigated by the movie, a state of amnesia was experienced where the specific details about the movie became indistinguishable. The person was found to be clammy, with a rapidly fluctuating heartbeat and trembling hands. 2/

% Immediately after the conclusion of the movie, there was a lack of memory regarding the content of the movie. However, when they returned home and the adrenaline levels dropped, they were able to recollect the scenes, sound effects, and background music from the movie. 3/

% One possible explanation for this situation is Walker's action decrement theory. According to this theory, intense emotions can temporarily interfere with memory. This theory suggests that participating in a highly emotional situation increases energetic responses and physical reactions. 4/

% At the height of such an emotional situation, it could potentially induce an internal response that displaces the ability to recall specific incidents. This indicates that physical conditions can affect memory recall in an unpredictable manner. 6/

% These memories are not permanently lost, but repressed. As the innate adrenaline rush subsidizes and the physical conditions return to normal, the memories usually return. These suppressed memories have been compared to actors waiting for their curtain call on a stage. 7/

% This is corroborated by the scenario where once the person was home and their body and mind were back to normal, they were suddenly flooded with vivid memories of the horror movie they had just seen. This phenomenon even applied to the sound effects and background music. 8/

% If an intense experience causes temporary memory loss, Walker's action decrement theory provides a logical explanation. As the excitement fades, the memory comes rushing back, allowing the possiblity to relive the experience akin to watching a replay in one's mind. 9/

% Walker's action decrement theory serves as a compelling method to comprehend the clever interplay between our brain and body in managing and controlling our emotional experiences. It is important to remember these encounters from the perspective of Walker's Action Deccrement Theory. 10/


% \end{quote}



% % %lydia comment
% \yy{Describe the data, terms, and have examples}
% \yy{two examples from Unaisah, back propagation, memory}









% In this study, participants were asked to read Twitter threads generated by ChatGPT and answer a short Likert Scale Survey. 



%  In the user study, we asked xx non-STEM undergraduate students to read and evaluate the xx Twitterorials and share their preferences (see \ref{user-study1}). We collected data through survey questions and follow-up interviews (see \ref{data}). 
% %We then conducted a user study with xx non-STEM undergraduate students as audience representatives to understand their preferences for the three techniques (see \ref{user-study1}). 



% %%%TABLE for H1-Example
% \begin{table}[]
% \begin{tabular}{|l|l|}
% \hline
% Condition H1-A                                                                    & Condition H1-B                                                                         \\ \hline
% \begin{tabular}[c]{@{}l@{}} Everything(EWP) \\ (w/ Few-shot)\end{tabular} & \begin{tabular}[c]{@{}l@{}}No Example \\ (EWP remove E)\end{tabular} \\ \hline
% \end{tabular}

% \caption{Conditions for H1 Readers prefer Twitter threads that have a relatable example.}
% \label{Hypothesis_Example_Conditions}
% \end{table}

% %%%TABLE for H2-Walkthrough
% \begin{table}[]
% \begin{tabular}{|l|l|} 
% \hline
% Condition H2-A                                                                   & Condition H2-B                                                      \\ \hline
% \begin{tabular}[c]{@{}l@{}}Everything(EWP) \\ (w/o Few-shot)\end{tabular} & \begin{tabular}[c]{@{}l@{}}No Walkthrough \\ (See Table \ref{PROMPT_Walkthrough_Conditions})\end{tabular} \\ \hline
% \end{tabular}

% \caption{Conditions for H2 Readers prefer Twitter threads that have a step-by-step walkthrough of one example. }
% \label{Hypothesis_Walkthrough_Conditions}
% \end{table}

% %%%TABLE for H3-Personal Language
% \begin{table}[]
% \begin{tabular}{|l|l|}
% \hline
% Condition H3-A                                                                    & Condition H3-B                                                                         \\ \hline
% \begin{tabular}[c]{@{}l@{}} Everything(EWP) \\ (w/ Few-shot) \\Same as H1-A\end{tabular} & \begin{tabular}[c]{@{}l@{}}No Personal Language \\ (EWP remove P)\end{tabular} \\ \hline
% \end{tabular}

% \caption{Conditions for H3 Readers prefer Twitter threads that use personal language.}
% \label{Hypothesis_Personal_Conditions}
% \end{table}

% \begin{table}[]
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{|l|l|l|l|l|l|}
% \hline
% Field & \textbf{Computer Science} & \textbf{Physics} & \textbf{Statistics} & \textbf{Civil Engineering} & \textbf{Psychology} \\ \hline
% Introductory Topic &
%   Depth-First Search &
%   Distance and Displacement &
%   Normal Distribution &
%   Lattice Structure &
%   Retroactive and Proactive Interference \\ \hline
% Intermediate Topic &
%   Back Propagation &
%   Thermal Equilibrium &
%   Central Limit Theorem &
%   Tensile Structure &
%   Feature Integration Theory \\ \hline
% Advanced Topic &
%   Recurrent Neural Networks &
%   Thin Film Interference &
%   Linear Regression &
%   Curtain Wall System &
%   Walker's Action Decrement Theory \\ \hline
% \end{tabular}%
% }
% \caption{Scientific fields and topics used in Reader Study}
% \label{topics}
% \end{table}


% \subsection{LLM Generation of Twitter Threads (Prompt Engineering) }
% \label{Twitter-gen}


% We conducted prompt engineering to generate the conditions used in the survey. Below we describe our process. Additionally, see Appendix \ref{prompts} for all the prompts. 

%%% Use our Hypothesis to organize 

% \yy{Organize by Hypothesis H\#}



% \subsubsection{Experimental Condition - EWP(Everything)}
% To produce the experimental condition that contains all three techniques (Example, Walkthrough, Personal Language) to be used in H1/H2/H3, we developed a prompt that has three paragraphs, each paragraph contains instructions for each of the three techniques. 

% % \yy{we have one prompt that has 3 paragraphs - E, W, P}

% % \yy{explain and give examples of how use case and scenarios are related to example. where they come from. }
% To generate explanations with an example, we included data fields [example] and [scenario], which are provided by the experts on the topics. The [example] data field is in the format of a short phrase. For instance: \textit{"Spider's Web"} is the [example] for the topic Tensile Structure in Civil Engineering. The [scenario] data field contains a scenario of a personal narrative that narrates the example through a scenario and connects with the scientific topic. For instance, for the "Spider's Web" example, the scenario is \textit{"During our late-night camping, my adventurous friend decided to challenge a playful spider. He picked up a small twig and started slowly poking its web. Upon noticing the twig, the spider ran towards it, displaying its territorial instinct. I witnessed how the web, a miraculous tensile structure, withheld the pressure without falling apart. Thanks to the constant tension in the silk material, the web stayed steady, absorbing the additional load, distributed throughout its double-curved surface, and transmitting it to its anchor points. "}

% To produce science explanations with an example incorporating the [example] and [scenario] data fields, we use the following "example" prompt paragraph: 

% \begin{quote}
% \textit{Use the given example to help explain how the topic words: [example].
% Use the scenario to provide additional context: [scenario].}
% \end{quote}

% To produce a step-by-step walkthrough of the example, we developed a three-line guideline as a prompt paragraph. We iterated on each line separately and in compilation to ensure that they are concise, essential, and reasonably consistent. The "walkthrough guidelines" prompt paragraph is: 

% \begin{quote}
% \textit{Walkthrough Guidelines:\\
% Tell the story from a first-person perspective.\\
% Walk through the story timeline in a sequence.\\
% Be sure to explain each dimension of the topic in detail, relating it back to the given use case and scenario.}
% \end{quote}

% To apply personal language to the explanation, we repeated a similar process as "walkthrough guidelines" to develop "emotional guidelines". The "emotional guidelines" prompt paragraph is:

% \begin{quote}
% \textit{Emotional Guidelines:\\
% Take the second-person audience on an emotional journey.\\
% Add visually descriptive details in the storytelling.\\
% Use emotional languages (both negative and positive).\\
% Add questions that echo with the audience and spark curiosity.}
% \end{quote}

% We compiled the 3 paragraphs above to produce a prompt that generated Twitter thread for \textit{EWP(Everything)} experimental condition with reasonable consistency and quality. To further improve the LLM performance, we included five few-shot training data. The few-shot training data are Tweetorials written by experts without the use of LLM. 


% \subsubsection{H1: Examples - Baseline Condition (EWP - RemoveE) } 

% To produce explanations for \textit{H1: Examples} baseline condition, we engineered a prompt that instructed LLM to remove the example from the output of \textit{EWP(Everything)} experimental condition. We evaluated the outputs and concluded that LLM was able to successfully produce Twitter threads without an example. The example removal prompt instruction is: 

% \begin{quote}
% \textit{Remove the example from the narrative.\\
% Do not include ANY examples.\\
% Only provide a technical walkthrough of [topic] following the same structure.}
% \end{quote}

% \subsubsection{H2: Walkthrough - Baseline Condition (EP - NoFewShot) }

% To produce explanations for \textit{H2:Walkthrough} baseline condition, we attempted the same removal prompting method, however, found that LLM was unable to accomplish this consistently. Therefore, we engineered a separate prompt paragraph to instruct LLM with guidelines what not to do :

% \begin{quote}
% \textit{
% Do not walkthrough using timeline sequence. \\
% Do not use words such as "before", "after", "then", "next", "also", "first", "second", "third", "last", "summary".\\
% Explain a different technical component of the topic in each Twitter in a non-sequential modular approach.\\
% Each Twitter stands alone and allows the reader to navigate through the explanations in various orders.}
% \end{quote}

% This prompt used to generate \textit{H2:Walkthrough} baseline condition does not contain few-shot training data. To make an equal comparison with the experimental condition, we re-generated \textit{EWP (Everything)} without few shot, which we call it \textit{EWP (Everything) - NoFewShot}. 



% \subsubsection{H3: Personal Langauge - Baseline Condition (EWP - RemoveP)}
% To produce explanations for \textit{H3: Personal Language} baseline condition, we followed a similar process as \textit{H1: Examples} baseline condition, by instructing LLM to remove personal language from the output of \textit{EWP(Everything)} experimental condition. We evaluated the outputs and concluded that LLM was able to successfully produce Twitter threads without personal language. The personal language removal prompt instruction is:

% \begin{quote}
% \textit{Edit the sentences to remove ’you’, ’I’, and ’we’ pronouns.\\
% Do not use rhetorical or confirmation questions.\\
% Use objective and generalizable language wherever possible.\\
% Remove any extraneous descriptions and adjectives.\\
% Use formal language.\\}
% \end{quote}

% \yy{add the prompt in quote}


% \yy{Add Twitter thread samples for each condition, side by side}

% \yy{Move prompts to Appendix, maybe??}

%describe how we come up with the prompts 

%describe why walkthrough needs a different approach 

%describe few-shot data written by the team

%describe hypotheses and which conditions are compared 





% %%%PROMPTS for H1-Example
% \begin{table}[]
% \resizebox{\textwidth}{!}{
% \begin{tabular}{|l|l|} 
% \hline
% GPT Prompt for H1-A                                                                   & GPT Prompt for H1-B                                                      \\ \hline
% \begin{tabular}[c]{@{}l@{}}

% [Few-shot examples]\\

% Instructions:

% Talk to a friend about the topic: [topic] in the domain: [domain].\\
% Explain how the topic works.\\
% Use the given example to help explain how the topic words: [use case]. \\
% Use the scenario to provide additional context: [scenario].\\

% \vspace{0.5}
% Output format: a piece of writing with short paragraphs (280 characters for each paragraph).\\

% Walkthrough Guidelines:\\
% Tell the story from a first-person perspective.\\
% Walk through the story timeline in a sequence.\\
% Be sure to explain each dimension of the topic in detail, \\
% relating it back to the given use case and scenario.\\


% Emotional Guidelines:\\
% Take the second-person audience on an emotional journey.\\
% Add visually descriptive details in the storytelling.\\
% Use emotional languages (both negative and positive).\\
% Add questions that echo with the audience and spark curiosity.\\


% Data:\\
% Domain: [domain]\\
% Topic: [topic]\\
% Use Case: [use case]\\
% Scenario: [scenario]\\
% Twitterorial:\\
% \end{tabular} & \begin{tabular}[c]{@{}l@{}}

% Narrative: [GPT output from H1-A]\\

% Instructions:\\
% Keep the same tone and structure as the given narrative.\\
% You are given a science narrative that explains how [topic] works. \\
% Remove the example of [example_label] from the narrative.\\
% Do not include ANY examples.\\
% Only provide a technical walkthrough of [topic] following the same structure.\\

% \end{tabular} \\ \hline
% \end{tabular}
% }

% \caption{GPT Prompts for H1 Readers prefer Twitter threads that have a relatable example.}
% \label{PROMPT_Example_Conditions}
% \end{table}

% %%%PROMPTS for H2-Walkthrough
% \begin{table}[ht]
% \resizebox{\textwidth}{!}{
% \begin{tabular}{|l|l|} 
% \hline
% GPT Prompt for H2-A                                                                   & GPT Prompt for H2-B                                                      \\ \hline
% \begin{tabular}[c]{@{}l@{}}

% Instructions:

% Talk to a friend about the topic: [topic] in the domain: [domain].\\
% Explain how the topic works.\\
% Use the given example to help explain how the topic words: [use case]. \\
% Use the scenario to provide additional context: [scenario].\\

% \vspace{0.5}
% Output format: a piece of writing with short paragraphs (280 characters for each paragraph).\\

% Walkthrough Guidelines:\\
% Tell the story from a first-person perspective.\\
% Walk through the story timeline in a sequence.\\
% Be sure to explain each dimension of the topic in detail, \\
% relating it back to the given use case and scenario.\\


% Emotional Guidelines:\\
% Take the second-person audience on an emotional journey.\\
% Add visually descriptive details in the storytelling.\\
% Use emotional languages (both negative and positive).\\
% Add questions that echo with the audience and spark curiosity.\\


% Data:\\
% Domain: [domain]\\
% Topic: [topic]\\
% Use Case: [use case]\\
% Scenario: [scenario]\\
% Twitterorial:\\
% \end{tabular} & \begin{tabular}[c]{@{}l@{}}

% Instructions:\\
% Write a series of Twitters explaining the given topic: [topic] in the domain of [domain].\\
% Make sure each Twitter is less than 280 characters.\\

% Do not use technical jargon and define all technical components.\\
% Do not walkthrough using timeline sequence. Do not use words \\such as "before", "after", "then", "next", "also", "first", "second", "third", "last", "summary".\\
% Explain a different technical component of the topic in each Twitter\\ in a non-sequential modular approach.\\
% Each Twitter stands alone and allows the reader to navigate through the explanations \\in various orders.\\


% \end{tabular} \\ \hline
% \end{tabular}
% }




% \caption{GPT Prompts for H2 Readers prefer Twitter threads that have a step-by-step walkthrough of one example. }
% \label{PROMPT_Walkthrough_Conditions}
% \end{table}

% %%%PROMPTS for H3-Personal Language
% \begin{table}[]

% \resizebox{\textwidth}{!}{
% \begin{tabular}{|l|l|} 
% \hline
% GPT Prompt for H3-A                                                                   & GPT Prompt for H3-B                                                      \\ \hline
% \begin{tabular}[c]{@{}l@{}}

% Same as H1-A
% \end{tabular} & \begin{tabular}[c]{@{}l@{}}

% Narrative: [GPT output from H3-A]\\

% Instructions:\\
% You are given a science narrative that uses emotional and engaging language to explain a concept.\\
% Your task is to write a new narrative that maintains the same structure of the given narrative \\but removes all emotional language and all subjective language.\\
% Edit the sentences to remove you, I, and we pronouns. Do not use rhetorical or confirmation questions.\\
% Maintain the active voice and use "people" or "student" or other general terms as the subject.\\
% Use objective and generalizable language wherever possible.\\
% Remove any extraneous descriptions and adjectives.\\
% Use formal language.\\


% \end{tabular} \\ \hline
% \end{tabular}
% }




% \caption{GPT prompts for H3 Readers prefer Twitter threads that use personal language.}
% \label{PROMPT_Personal_Conditions}
% \end{table}







% \subsection{Participants}


% recruitment: rationale for choosing non-STEM students + recent graduates. recruitment methods. 

% We recruited 35 undergraduate non-experts to evaluate the generated narratives to determine the quality of the science explanations. We choose non-experts because they represent everyday people, who are our target audience for science communication on social media. 


\subsection{Participant Recruitment}
\label{Recruitment}
\label{user-study1}
We recruited 35 undergraduate students and recent college graduates who did not study nor intend to study any of the 5 science fields. We chose non-experts because they represent everyday people, who are our target audience for science communication on social media. Because the Tweetorials that we aim to emulate are US-centric in the examples and language used, we disqualified participants who do not self-identify as culturally American and whose first language is not English. The participants are from 12 universities and liberal arts colleges in the United States, with an average age of 22, and a gender distribution of 4 males, 29 females, and 2 non-binary individuals. We distributed the recruitment survey via school mailing lists, Slack workspaces, Discord channels, and snowball sampling \cite{goodman_snowball_1961} among schoolmates of the participants. Each participant was compensated \$27 dollars. The study was approved by our institutional IRB. 
% \yy{AGE:  use average age}



% Following the recruitment, qualified participants attended a 15-minute onboarding session via Zoom with an experimenter. After that, they were given a link to the Qualtrics survey described in Section \ref{Data}, which took approximately 1.5 hours to complete on their own. T

\subsection{Survey Procedure}
Following recruitment, each qualified participant attended an onboarding session with an experimenter on Zoom. The experimenter explained the study procedure and data collection, and acquired participants' consent. The experimenter shared a sample Twitter thread and survey for the participant to answer and explained the Likert-scale rating criteria. The participants thought aloud while answering the sample survey, justified their rating decisions, and asked clarifying questions before completing the survey on their own. Participants' justifications for their ratings on the sample science narratives aligned with the defined definitions. 

We implemented our survey on Qualtrics, an online survey platform. On the first page, participants are asked to read a Twitter thread. The page included a one-minute timer to prevent participants from skimming or skipping the reading process. After reading the Twitter thread, the participant advances to the next page and completes four Likert-scale questions that correspond to the four evaluation dimensions (engaging, relatable, understandable, and easy-to-follow, see Section \ref{survey_design}), on the scale from 1 to 5 (1-Strongly Disagree, 5-Strongly Agree). This process repeats 15 times for the 15 science explanations for each participant. 

To minimize bias from prior knowledge, we employed a between-subjects design, ensuring that each participant only read each topic once, and no participant read the same topic under two different conditions. Each participant read a randomized selection of Twitter threads across all conditions and topics. Each Twitter thread was evaluated by 7 participants to achieve a statistical distribution and reduce individual bias.

\subsection{Data Collection and Analysis}
\label{Data}
% grace unsure if we need this??
% Participants rated science explanations on 4 dimensions (engaging, relatable, understandable, and easy-to-follow) on a Likert Scale of Strongly Agree (5-points) to Strongly Disagree (1-point). For participant's rating, we summed the scores for each of the dimensions to create an overall score (20-points max) for the science explanation. Each participant evaluated 15 different science explanations across different topics in STEM.  We used the overall score to get a comprehensive measure that captures the participants' overall perception across multiple dimensions of quality.

\subsubsection{Survey Design}
\label{survey_design}
Each science explanation was evaluated on 4 different questions: (1) I find the thread engaging, (2) I find the thread relatable, (3) I find the thread understandable, and (4) I find the thread easy to follow. \textit{Engaging} refers to the language, while \textit{relatable} refers to the example used. \textit{Understandable} refers to the presence of technical jargon, while \textit{easy-to-follow} refers to the sequence and flow of the narrative. The onboarding session demonstrated that participants were able to differentiate between each of the dimensions. We sum the participant's ratings for each Likert-scale question to create an overall score for the given science explanation (20-point max score).

% \grace{go somewhere else}
 
% For engaging explanations, participants mentioned the language that was used in the text that captured or held their attention. For relatable explanations, participants usually referenced how the example used in the explanation connected to their own lives. For understandable explanations, participants mentioned how they were able to understand the technical concepts and terms that were used in the text. For easy-to-follow explanations, participants mentioned how the sequence of information followed a clear order and structure. \grace{we define these things as xyz, in onboarding we wanted to ensure aligned of defintioin and found tnat they fid algn with partiicpants }



% \begin{itemize}
%     \item \textbf{Engaging}: covers the science explanation's ability to capture and hold a reader's attention. Evaluated by the language used in the explanation. 
%     \item \textbf{Relatable}: reflects how well the explanation connects to the reader's existing experiences, knowledge, or concerns. Evaluated by the examples used in the explanation.  
%     \item \textbf{Understandable}: measures whether the explanation successfully conveys its ideas in a way the reader can comprehend. Evaluated by the sentences used to present the science, such as technical jargon or assumed prerequisite knowledge in the explanation. 
%     \item \textbf{Easy-to-Follow}: indicates the clarity of the explanation's structure, flow, and logical progression. Evaluated by the structure of the explanation.
% \end{itemize}

% These four dimensions are non-overlapping. Engaging is about reader interest and emotional draw which is different from clarity of content (understandable), personal connection (relatable), or structural coherence (easy-to-follow). For example, a science explanation can use describe and vivid verbs to engage the reader, but fail to explain the science behind a topic which makes it not understandable. \grace{Should I continue this for each of the dimensinos? How much more justification do we need?}


% \grace{do we need this??} We use the following phrases in our survey:
% \begin{enumerate}
%     \item I find the thread engaging.
%     \item I find the thread relatable.
%     \item I find the thread understandable.
%     \item I find the thread easy to follow.
% \end{enumerate}



% The 4 Likert Scale questions evaluate 4 different dimensions of what makes a good Tweetorial: engaging, relateable, understandable, and easy-to-follow. 

% We use the following phrases 


% STILL NEED TO DO \yy{add rationale of the 4 Likert-Scale questions. }


% \subsubsection{Survey Procedure}


% % for consent process: users are asked to confirm participation in qualtrics intake survey + again in onboarding process where I re-state the expectations of the survey (15 tweetorials, 1-1.5 hours, $27, +deadline) before continuing with the survey

% 15-minute onboarding sessions with all participants to walk them through the process of answering one set of twitter thread + question pairing to ensure that annotators understand the rating criteria + were also asked to think aloud to ensure that they had a justification for their rating. after this, raters would complete the rest of the survey in their own time


% \yy{add consent process}

% \yy{add onboarding procedure}





% When distributing the survey, we took the following steps to prevent bias.

% Each participant read and evaluated 15 Twitter threads on 15 different topics. 

% To mitigate prior knowledge bias, we adopted a between-subjects method, such that no participant read the same topic from two different conditions. 

% Each participant read a randomized mixture of the 5 conditions. \yy{check w/ Grace -- Did we randomize?}

% Each Twitter thread is evaluated by 7 participants to reach a statistical significance and eliminate human bias. 





\subsubsection{Data Analysis}
\textbf{Quantitative Analysis: Survey Data} 
% To understand readers’ preferences for science explanations that incorporate specific techniques, we designed a study involving 35 participants. Each participant rated 15 different explanations on 4 different Likert scale questions. Because the Likert scale questions were unique and non-overlapping, we summed the ratings to create a overall score for each science narrative. Each explanation was independently evaluated by 7 different raters. We covered five distinct STEM topics (Physics, Computer Science, Statistics, Psychology, and Civil Engineering) to capture a broad range of content.

Our main goal was to test whether the inclusion of examples, walkthroughs, and personal language influenced readers' engagement and understanding. We used the overall score (sum of the 4 Likert responses) for the given science explanation in our analysis. Because each participant did not read the same topic twice and sampled across multiple STEM fields, our data exhibited a hierarchical structure: each rating is linked to a specific participant and a specific topic.

We used a Generalized Linear Mixed Model (GLMM) for our analyses. The GLMM framework allowed us to isolate how each technique affected the ratings for each science explanation based on the overall score of the Likert ratings, while statistically controlling for other factors. We can estimate the direction and magnitude of the effectiveness of each technique (examples, walkthroughs, and personal language) relative to explanations without them. We also accounted for individual differences in baseline rating tendencies by including random intercepts for each participant because people may vary in their strictness or leniency when rating explanations. We also included random intercepts for each of the five STEM topics to account for potential differences across fields (e.g., participants might rate Computer Science explanations differently than Physics explanations). The GLMM model allowed us to compare pairs of explanations—those with a given technique versus those without—to determine whether the presence of each technique had a significant effect on the ratings.
  

\textbf{Qualitative Analysis: Followup Interviews}
To gain more nuanced insights into participant preferences in the survey data, we randomly reached out to 17 of the 35 participants for follow-up interviews. 8 of 17 participants opted-in for a 15-minute follow-up interview on Zoom. The participants are compensated \$10 total. In the follow-up interview, we asked the participants to re-read a science explanation they had previously read and explain in detail specific instances from the science narrative that influenced their Likert ratings.  The interviews were recorded and transcribed before three researchers conducted a thematic analysis. We used grounded theory to derive insights from the interview transcripts \cite{charmaz_constructing_2006}. The first author read through all interview transcripts, inductively derived a preliminary set of codes, and then grouped the codes based on themes. The first author and two additional authors collaboratively reviewed and refined the themes until a consensus was reached.

% The purpose of these interviews was to gain deeper insights into the survey findings and explore participants’ perspectives on key themes that emerged from the quantitative data. 

% To compare the experimental condition with the baseline condition for each hypothesis, we calculated an average rating across 105 data points (15 topics × 7 participants). Then, we calculated a sum of the four Likert-Scale questions to get a total score. The total scores from Condition A and B are directly compared to conclude readers' preference. 
% To understand inter-annotator agreement among the participants, we calculated Krippendorff's alpha score (k-alpha). We used K-alpha to calculate the inter-annotator agreement due to it's flexibility in calculating agreement between multiple annotators. K-alpha ranges from -1 to 1 where 1 denotes perfect agreement and values below 0 signify random agreement. 
% We also calculated p-value on the total score values between each condition to determine the statistical significance of the results. 

% We calculated a mean of 7 participants' scores for each condition on each topic. 
% \yy{Grace: What other statistical analysis did we do?}

% \subsubsection{Follow-Up Interviews}








