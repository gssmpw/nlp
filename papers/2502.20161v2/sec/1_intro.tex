\section{Introduction}
\label{sec:intro}

Rate-distortion (R-D) optimization~\cite{sullivan1998rate} is a fundamental process in image compression, balancing the trade-off between rate (compression efficiency) and distortion (image quality). Traditional compression techniques, such as JPEG~\cite{wallace1992jpeg} and MPEG~\cite{le1991mpeg}, achieve this balance using carefully crafted transforms, quantization, and entropy coding schemes. These methods reduce data size while minimizing visual degradation through predefined, hand-tuned parameters and well-established signal processing techniques.

These codecs approach R-D optimization within a structured, deterministic parameter space. Parameters are either manually adjusted or selected via straightforward heuristics rather than through complex, gradient-based updates. This setup avoids the potential for imbalanced optimization arising from dynamic parameter adjustments, ensuring a stable alignment between rate and distortion objectives~\cite{sullivan2012overview}. However, the fixed nature of these parameters limits the flexibility of traditional methods in adapting to varying image content, constraining their overall efficiency.

In contrast, learned image compression (LIC) models utilize deep learning architectures to automatically adapt to image data. By learning intricate features directly from data, LIC models achieve higher compression ratios and enhanced reconstruction quality~\cite{he2022elic,liu2023learned,li2024frequencyaware}. In LIC, R-D optimization is typically achieved by minimizing a combined loss function for rate and distortion, controlled by a weighting factor, $\lambda$, which denotes the trade-off between them~\cite{ball√©2018variational,balle2020nonlinear}. This gradient-based approach dynamically updates parameters to minimize the loss, enabling LIC models to adapt to diverse image content. However, summing the rate and distortion gradients in this setup can result in imbalanced updates, where one objective dominates the other due to the diverse gradient direction or magnitude during the optimization process~\cite{alemi2018fixing,sener2018multi}. This imbalance may hinder convergence, as one objective is prioritized at the expense of the overall performance drop~\cite{yu2020gradient}.


\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Fig/loss_trends_zoomed.pdf}
        \caption{Testing loss trend}
        \label{subfig:std}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Fig/improvement_speed.pdf}
        \caption{Loss improvement speed}
        \label{subfig:bal}
    \end{subfigure}
\caption{Comparison of loss trends and improvement speeds for the M\&S hyperprior~\cite{minnen2018joint} model with $\lambda = 0.013$ from epoch 10 to 150, where Distortion = MSE $\times \lambda \times 255^2$. The first 10 epochs are omitted for improved readability. (a) Testing loss trend for the standard R-D optimization versus the proposed balanced R-D optimization. The balanced approach demonstrates more stable and smoother loss improvements, showing simultaneous and consistent reductions in both distortion and bits-per-pixel (bpp) metrics. In contrast, the standard method focuses on reducing distortion, with the bpp loss only gradually increasing in this period. (b) Comparison of loss improvement speeds, Eq.~\ref{eq:speed}, for standard and balanced R-D optimizations. The balanced R-D optimization yields a more consistent, less volatile improvement speed, outperforming the standard approach by achieving steady and reliable convergence across epochs. This highlights the advantage of the balanced approach in optimizing both objectives cohesively and effectively.}
    \label{fig:R_D_O}
\end{figure*}



Addressing this imbalance requires strategies to harmonize rate and distortion objectives, enabling both to be optimized effectively for higher-quality image compression. Multi-objective optimization (MOO) strategies offer promising solutions, as they are designed to make progress across multiple objectives simultaneously~\cite{desideri2012multiple,sener2018multi,yu2020gradient,navon22a,liu2024famo}. These approaches guide models towards Pareto-optimal solutions~\cite{miettinen1999nonlinear} that balance competing objectives without excessively prioritizing any single one.

In this work, we introduce a MOO-based framework for R-D optimization in LIC, treating rate and distortion as two objectives to be optimized concurrently. We propose two balanced solutions for this framework that adaptively re-weight gradient updates from the two objectives to ensure equitable progress on both objectives. The first solution employs a coarse-to-fine gradient descent approach, particularly effective for training models from scratch by iteratively refining gradient weights. The second solution reformulates the optimization as a equality constraint-quadratic programming problem to derive the gradient weights analytically, offering a precise fine-tuning mechanism for existing LIC models. Our approach achieves balanced progress in both objectives, yielding smoother convergence and enhanced R-D performance, as illustrated in Fig.~\ref{fig:R_D_O}.

Our main contributions are summarized as follows: \begin{itemize} 
\item We reformulate R-D optimization as a multi-objective optimization (MOO) problem, introducing a balanced framework to optimize rate and distortion more equitably. 

% \item We propose two balanced solutions: a coarse-to-fine gradient descent solution for new model training, and an analytical quadratic programming solution for fine-tuning existing models. 
\item {We propose two solutions for balanced R-D optimization: a coarse-to-fine gradient descent solution for training new models from scratch, and an analytical quadratic programming solution for fine-tuning existing models.}

% \item Extensive experiments validate the effectiveness of our approach in improving R-D performance in LIC models. 
\item {Extensive experiments show that our approach consistently improves the R-D performance of LIC models.} 
\end{itemize}




