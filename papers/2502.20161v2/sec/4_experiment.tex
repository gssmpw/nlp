\section{Experimental results}

\subsection{Experimental settings}

\textbf{Training.}
We use the COCO 2017 dataset~\cite{lin2014microsoft} for training, which contains 118,287 images, each having around 640×420 pixels. We randomly crop 256×256 patches.

Following the settings of CompressAI~\cite{begaint2020compressai}, we set \(\lambda\) to \{18, 35, 67, 130, 250, 483\} × \(10^{-4}\). For all models, we train each model using the Adam optimizer with \(\beta_1 = 0.9\), \(\beta_2 = 0.999\), a batch size of 32, and an initial learning rate (lr) of \(1e{-4}\). We use ReduceLROnPlateau lr scheduler with a patience of 10 and a factor of 0.5. For ``Standard'' and ``Solution 1'' models, the \(\lambda = 0.0018\) models are trained for 200 epochs. For models with other \(\lambda\) values, we fine-tune the model trained with \(\lambda = 0.0018\) for an additional 150 epochs.  For ``Solution 2'' models, we fine-tune the corresponding ``Standard'' models for 50 epochs with an initial lr of 5e-5. Solution 1 hyperparameters are set as \(\beta = 0.025\) and \(\gamma = 0.001\).

\textbf{Testing.} Three widely used benchmark datasets, including Kodak~\cite{KodakWeb}, Tecnick~\cite{asuni2014testimages}, and CLIC 2022~\cite{CLIC2022}, are used to evaluate the performance of the proposed method. 


\subsection{Quantitative results}
\label{subsec:qr}
We compare our proposed method with standard trained models on prevalent LICs including M\&S Hyperprior~\cite{minnen2018joint}, ELIC~\cite{he2022elic}\footnote{For the training of  ELIC models, we do not apply the mixed quantization strategy~\cite{minnen2020channel,he2022elic}; instead, we use uniform noise as the quantization method.}, and TCM-S~\cite{liu2023learned} to demonstrate its performance. We use standard rate-distortion trained models as the anchor to compute BD-Rate~\cite{BDrate}. 


Table~\ref{tab:bdrate} shows the BD-Rate improvement achieved by our proposed method compared to baseline approaches across three datasets. Our method consistently surpasses all baselines on both common and high-resolution test datasets, underscoring its effectiveness. For example, ELIC Solution 1 achieves BD-Rate improvement of -2.68\%, -2.63\%, and -3.00\% compared to ELIC Standard on the Kodak, Tecnick, and CLIC2022 datasets, respectively, demonstrating the substantial improvements our approach provides. Furthermore, ELIC Solution 2, which fine-tunes existing standard R-D optimized models, achieves BD-Rate improvement of -1.81\%, -2.03\%, and -2.39\% on the three test datasets, illustrating the efficacy of our fine-tuning strategy. Overall, Solution 1 yields slightly better results than Solution 2, as Solution 2 is used only for fine-tuning over a few epochs.

Fig.~\ref{fig:rd_fig} further illustrates the R-D curves for all methods. The proposed method consistently outperforms the standard optimized models, particularly in the high bpp range, demonstrating its superior R-D performance

\begin{table}[htbp]
    \centering
    \caption{BD-Rate Compared to Standard R-D optimization}
      \resizebox{1\linewidth}{!}   {
    \begin{tabular}{c|c|c|c|c}
        \hline \hline
        \multicolumn{2}{c|}{\multirow{2}{*}{Method}} &  \multicolumn{3}{c}{BD-Rate (\%) $\downarrow$} \\  \cline{3-5}
        \multicolumn{2}{c|}{} &  Kodak & Tecnick & CLIC2022 \\ \hline
        \multirow{3}{*}{\makecell{M\&S\\Hyperprior~\citep{minnen2018joint}}} &  Std.  & 0\% & 0\%&0\% \\ 
        &  Sol. 1  & \textbf{-1.95\%} &\textbf{-1.91\%} &\textbf{-2.03\%} \\ 
        &  Sol. 2  &-1.64\%&-1.55\% & -1.81\%\\\hline 
        \multirow{3}{*}{ELIC~\citep{he2022elic}} &  Std.  &0\% &0\% &0\% \\ 
        &  Sol. 1  &\textbf{-2.68\%} &\textbf{-2.63\%} &\textbf{-3.00\%} \\ 
        &  Sol. 2  &-1.81\% &-2.03\% &-2.39\% \\\hline 
        \multirow{3}{*}{TCM-S~\citep{liu2023learned}} &  Std.  & 0\%& 0\%& 0\%\\ 
        &  Sol. 1  & \textbf{-2.53\%} &\textbf{-2.73\%} & \textbf{-2.66\%}\\ 
        &  Sol. 2  &  -1.87\%&-2.09\% &-2.12\% \\
        \hline \hline
    \end{tabular}}
    \begin{tablenotes}
  % \centering
  \item ``Std.'' denotes Standard, and ``Sol.'' denotes Solution. \textbf{Bold} indicates the best result.%, while \textcolor[rgb]{ 0,  .69,  .941}{blue} indicates the second best.
  \end{tablenotes}
    \label{tab:bdrate}
\end{table}


\begin{figure*}[htbp] 
\newcommand{\mywidth}{0.324}
\centering 
\begin{subfigure}[b]{\mywidth\linewidth}
    \centering
    \includegraphics[width=\linewidth]{Fig/RD_kodak.pdf}
    \caption{Kodak}
    \label{subfig:kodak}
\end{subfigure}
\hfill
\begin{subfigure}[b]{\mywidth\linewidth}
    \centering
    \includegraphics[width=\linewidth]{Fig/RD_tecnick.pdf}
    \caption{Tecnick 1200x1200}
    \label{subfig:Tecnick}
\end{subfigure}
\hfill
\begin{subfigure}[b]{\mywidth\linewidth}
    \centering
    \includegraphics[width=\linewidth]{Fig/RD_CLIC.pdf}
    \caption{CLIC 2022}
    \label{subfig:CLIC}
\end{subfigure}
\caption{\textbf{R-D curves of various methods. }{\it Please zoom in for more details}.} 
\label{fig:rd_fig} 
\end{figure*}



\subsection{Complexity}
\label{subsec:compl}

As shown in Table~\ref{tab:comp}, our proposed methods introduce a moderate computational overhead compared to standard R-D optimization. Solution 1 requires an additional weight update (\( w_t \)) by performing two forward passes, which increases epoch training time by approximately 20\%. Solution 2, which involves calculating the Hessian matrix through matrix multiplications and performing matrix inversions, adds an overhead of 47–50\%. For example, in the M\&S Hyperprior~\citep{minnen2018joint} model, the computational cost (10 minutes, normalized to 100\%) increases by 20\% with Solution 1 and by 50\% with Solution 2. Similar trends are observed for ELIC~\citep{he2022elic} and TCM-S~\citep{liu2023learned}. Although Solution 2 incurs a higher computational cost, it is only applied during fine-tuning over fewer epochs. Both methods demonstrate significant performance gains that justify the additional complexity. Importantly, our methods do not affect the inference phase of the trained models, leaving inference time unchanged.

\begin{table}[htbp]
    \centering
    \caption{Complexity Compared to Standard R-D optimization}
    \begin{tabular}{c|c|c}
        \hline \hline
        \multicolumn{2}{c|}{{Method}} & $\Delta$ Epoch Training Time $\downarrow$ \\  \hline
        \multirow{3}{*}{\makecell{M\&S\\Hyperprior~\citep{minnen2018joint}}} &  Std.  & 10 mins\\ %10min
        &  Sol. 1  & +20\% \\ %12min
        &  Sol. 2  & +50\% \\\hline %15min
        \multirow{3}{*}{ELIC~\citep{he2022elic}} &  Std.  & 35 mins\\ %35min
        &  Sol. 1  & +20\% \\ %42min
        &  Sol. 2  & +47\% \\\hline 
        \multirow{3}{*}{TCM-S~\citep{liu2023learned}} &  Std.  &  60 mins \\ %60min
        &  Sol. 1  & +23\% \\ %74min
        &  Sol. 2  &+48\% \\\hline %
        \hline 
    \end{tabular}
    \label{tab:comp}
\end{table}


\subsection{Ablation study}
\label{subsec:ablation}
We conduct comprehensive experiments to find the impact of various factors of the proposed method. All experiments are conducted on the M\&S Hyperprior~\cite{minnen2018joint} model with $\lambda = 0.013$. The other settings are the same as the main experiments. In the R-D plane (bpp-PSNR figures), the upper left represents better results.
\begin{figure*}[htbp] 
\newcommand{\mywidth}{0.33}
\centering 
\begin{subfigure}[b]{\mywidth\linewidth}
    \centering
    \includegraphics[width=\linewidth]{Fig/RD_ablation_on_renorm.pdf}
    \caption{Renormalization}
    \label{subfig:renorm}
\end{subfigure}
\hfill
\begin{subfigure}[b]{\mywidth\linewidth}
    \centering
    \includegraphics[width=\linewidth]{Fig/RD_ablation_on_wd.pdf}
    \caption{Weight decay}
    \label{subfig:wd}
\end{subfigure}
\hfill
\begin{subfigure}[b]{\mywidth\linewidth}
    \centering
    \includegraphics[width=\linewidth]{Fig/RD_ablation_on_cross.pdf}
    \caption{Cross validation}
    \label{subfig:cross}
\end{subfigure}
\caption{Ablation experiments on proposed methods. M\&S Hyperprior model, \(\lambda\) = 0.013. Kodak dataset.} 
\label{fig:ab_fig} 
\end{figure*}

\subsubsection{Weight renormalization}
In the end stages of the training process, the loss \( \mathcal{L}_{i,t} \) can become small, which may lead to numerical instability due to the multiplicative factor \( \frac{w_{i,t}}{\mathcal{L}_{i,t}} \). To address this, we apply weight renormalization to the proposed solutions. We experimented with removing this renormalization, and the results (``w/o Re''), shown in Fig.~\ref{subfig:renorm}, indicate that renormalization improves the final convergence of both solutions.

\subsubsection{Weight decay}  
In Solution 1, we introduce a weight decay term when updating the unconstrained softmax logits to mitigate potential non-convergence issues that arise from instantaneous gradients~\cite{zhou2022convergence}. To evaluate the effect of weight decay, we perform a series of experiments, varying the decay coefficient \( \gamma \) across values \( \{0.01, 0.015, 0.005, 0.001, 0.0005, 0\} \), as shown in Fig.~\ref{subfig:wd}. Notably, setting \( \gamma = 0 \) (i.e., no weight decay) results in non-convergence issues that precluded plotting the results. Among the other tested values, \( \gamma = 0.001 \) yields the best results, and we thus adopt \( \gamma = 0.001 \).


\subsubsection{Solutions cross-validation}  
As discussed, Solution 1 is a coarse-to-fine gradient descent method along standard R-D optimization trajectories that iteratively refine the gradient weights $w_{i,t}$, whereas Solution 2 is a constrained QP approach that offers an analytically precise solution. Solution 2 is more time-intensive. Intuitively, we apply Solution 1 for training models from scratch and Solution 2 for fine-tuning pre-trained models. To validate this strategy, we reverse these roles: using Solution 1 to fine-tune pre-trained models and Solution 2 to train models from scratch. The results, shown in Fig.~\ref{subfig:cross}, reveal that Solution 1 (fine-tuning) performs worse than Solution 2 (fine-tuning), while Solution 1 (from scratch) achieves comparable performance to Solution 2 (from scratch) but requires less training time. This outcome supports our hypothesis: Solution 1 is well-suited for training from scratch, where it can operate in a coarse-to-fine manner along the optimization trajectory, while Solution 2's precision and time-consuming make it more suitable for fine-tuning. Additionally, applying Solution 2 to further fine-tune Solution 1 models only yields marginal improvements compared to fine-tuning standard models, making cascaded usage of both solutions unnecessary.



