\section{Related Work}
\subsection{Methods for Classifying Palm Fruit Ripeness}
To ensure that the maximum amount of palm oil is extracted from the fruit, it is important to harvest it at the correct stage of ripeness. As the fruit enters the under-ripe stage, its oil content begins to increase. Ripe fruit has a reddish-orange color and, at the same time, the highest oil content. However, once the fruit becomes overripe, its fatty acid content starts to increase, reducing the oil quality. In recent years, various automated fruit grading systems have been proposed and tested. These methods can be classified into two categories. One approach relies on image processing techniques, which extract color features by preprocessing palm fruit images. The other employs CNNs, which automatically learn features from data.

In the traditional method, features from RGB and HSI color models are extracted from images and used as predictors for classification. Color histogram, color moment, and color correlogram **Szeliski, "Image Features"** are derived from the original images as predictive features. RGB values and color indices, obtained from RGB color images through stepwise discriminant analysis, have been used for maturity determination **Cheng et al., "Fruit Maturity Determination"**. Additionally, the mean and range of RGB digital values have been applied to determine fruit maturity **Wang et al., "RGB Digital Values"**. To enhance feature extraction, dimensionality reduction techniques such as principal component analysis (PCA) **Jolliffe, "Principal Component Analysis"** have been employed. The extracted features are then fed into classification algorithms, including k-nearest neighbors (k-NN) **Cover and Hart, "Nearest Neighbors"**, Support Vector Machine (SVM) **Cortes and Vapnik, "Support Vector Machines"**, and Multi-Layer Perceptron (MLP) **Rumelhart et al., "Multi-Layer Perceptrons"**. However, the results obtained with this method are not reliable because ambient lighting significantly affects the values of these color models, thereby impacting the extracted features. Moreover, the camera configuration must remain fixed, which is impractical in real-world applications.

In recent years, deep learning algorithms have demonstrated remarkable performance in image processing tasks. The limitations of traditional methods can be mitigated by using deep learning techniques. AlexNet **Krizhevsky et al., "AlexNet"** was the first deep learning architecture applied to palm ripeness classification. This study utilized the pre-trained CNN model, AlexNet, on 120 images of palm oil fruit, with 30 images from each of the four ripeness levels. A more recent study **He et al., "DenseNet"** compared the performance of AlexNet and DenseNet. Both models were trained and tested using a dataset of 400 palm oil fruit images, with 60\% allocated for training, 20\% for validation, and 20\% for testing. The test accuracy was 77\% for AlexNet and 85\% for DenseNet. However, the number of images used in both studies was very limited, and all palm fruit images were captured post-harvest. As a result, the findings are not reliable, and the models cannot be effectively applied to the practical harvesting process.

To develop a more robust vision system, a larger dataset was used for palm fruit bunch maturity classification **Wang et al., "Palm Fruit Bunch Maturity Classification"**. This dataset consisted of more than 8,000 images of fruit bunches from five palm types at various pre-maturity and maturity stages. The study applied AlexNet and VGGNet architectures, achieving test accuracies of 93.36\% and 95.78\%, respectively. However, in this study, the number of test samples was larger than the training samples. Upon reviewing their work, we found that a significant number of similar images were present in both the training and test sets. Consequently, the high test accuracy depended heavily on the specific data split. If the dataset were randomly shuffled before splitting into training and test sets, similar results would not be achievable. Thus, further studies are needed to explore the feasibility of applying deep learning algorithms to practical palm bunch ripeness classification tasks.

 

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{images/Reset34.png} % Reduce the figure size so that it is slightly narrower than the column.
\caption{ The ResNet architecture }
\label{ResNet}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{images/Incept.JPG} % Reduce the figure size so that it is slightly narrower than the column.
\caption{ The InceptionV3 architecture and the Inception module }
\label{incpt}
\end{figure*}

\subsection{Dataset}
Although weaknesses exist in the previous work **Wang et al., "Palm Fruit Bunch Maturity Classification"**, the dataset used **Wang et al., "Publicly Available Dataset for Palm Research"** is valuable and meaningful for palm research. To the best of our knowledge, this is the only publicly available dataset for palm fruit pre-harvesting and harvesting applications. This dataset can support various applications in both the pre-harvesting and harvesting stages. The first dataset, designed for palm type and maturity level classification, consists of 8,079 color images, each with a resolution of $224 \times 224$, captured from 29 palms. These images represent seven palm fruit maturity stages and exhibit a high degree of variation, reflecting the challenges of real-world environments in orchards. Variations in the dataset include different viewing angles and scales, varying daylight conditions, and the presence of palm bunches covered by protective bags. For multi-scale analysis, the images include partial bunches, whole bunches, and multiple bunches within a single frame. To simulate real-world harvesting conditions, images were captured under different natural daylight settings, specifically in the morning (9:00–11:00) and afternoon (3:00–5:00). Additionally, some images were taken under poor illumination conditions from different camera angles relative to the sun. The dataset covers five palm varieties, including some high-quality varieties where bunches are covered with protective bags to shield them from dust, pests, and rain. In particular, green bags were used to cover bunches after reaching the medium-ripe stage. Overall, this dataset is comprehensive and diverse enough to support the development of a robust vision system for palm fruit maturity classification and harvesting applications.

\begin{figure}[t]
\centering
\includegraphics[width=0.4\columnwidth]{images/baseline.png} % Reduce the figure size so that it is slightly narrower than the column. Don't use precise values for figure width.This setup will avoid overfull boxes.
\caption{ Summary of the baseline model architecture.}
\label{fig_base}
\end{figure}

\subsection{Our Methodology}
In this study, we utilize deep CNNs to classify palm fruit ripeness levels, leveraging their strong capability for automatic feature extraction in this classification task. We apply transfer learning with fine-tuning using two pre-trained CNN models: ResNet50 and InceptionV3. To standardize classification, we combine certain ripeness levels from the published dataset **Wang et al., "Palm Fruit Bunch Maturity Classification"** into five categories: unripe, under-ripe, medium-ripe, ripe, and overripe. Sample images representing these five ripeness levels are shown in Figure \ref{fig1}. The dataset was split into 80\% for training and 20\% for testing.