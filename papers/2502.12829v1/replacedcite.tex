\section{Related Work}
%[Akhmed, Jonibek, Maiya, Diana, Fajri, revised by Mukhammed]

\paragraph{Language Models in Kazakh and Russian}
% First paragraph: any multilingual language models that has Kazakh and Russian.
Prominent models such as OpenAI's ChatGPT, Anthropic's Claude, and Yandex's Yandex-GPT are designed to handle multiple languages, including Russian and Kazakh, enabling a wide range of applications from translation to content generation____. Additionally, open-source models like Meta's Llama series provide multilingual support____. While these models can produce text in Kazakh, they were not specifically trained or fine-tuned for it. In contrast, the Aya model, an open-access multilingual LLM, supports 101 languages, including Kazakh____.

Kazakh-specific language models have been scarce, with most multilingual models offering only limited support. To bridge this gap, ____ introduced KazakhLLM, a model fine-tuned on Kazakh data from Llama, though its evaluation has primarily relied on machine-translated datasets.

%Second paragraph: is there any Kazakh-specific language model in the past?


\paragraph{NLP Benchmark for Kazakhstan Context}
% Divided into multilingual benchmark: XCOPA, XFGLUE, XTREME. Do they have Kazakh and Russian? Also talk about GlobalMMLU by Aya Cohere, and INCLUDE by AyaCohere? Do they have Kazakh?
% Move to Kazakh and Russian dataset; Talk about NLP datases in Kazakh, and then Russian. Highlight that the Russian dataset does not have Kazakhstan specific context.

%[MukhammedJ] Revised

Evaluating LLMs across diverse linguistic and cultural contexts is increasingly critical; however, existing benchmarks overlook Kazakhstan. While benchmarks such as XCOPA____, XFGLUE____, and XTREME____ assess cross-lingual performance, they exclude Kazakh, and GlobalMMLU____ lacks Kazakhstan-specific content.
In contrast, several Kazakh-specific datasets exist, including KazNERD____ for named entity recognition, KazQAD____ for question answering, and KazSANDRA____ for sentiment analysis. However, these datasets focus on narrow tasks and do not assess reasoning, factual recall, or domain-specific knowledge.
To address these limitations, \datasetname{} presents a large-scale, Kazakhstan-specific benchmark covering STEM, humanities, and social sciences. Unlike previous datasets, \datasetname{} supports a holistic evaluation of reasoning and domain-specific knowledge, offering a more accurate assessment of multilingual LLM capabilities and advancing AI for low-resource languages.

To further illustrate the differences between \datasetname{} and previous benchmarks, we compare it with two existing datasets, SIGTURK____ and INCLUDE____, in Table~\ref{tab:comparison-mmlu}.
As shown, \datasetname{} is the only dataset that incorporates \textbf{real-world educational materials, professional subjects}, and \textbf{domain-specific reasoning} in both Kazakh and Russian, offering a more \textbf{localized} and \textbf{comprehensive} evaluation of LLMs. This structured assessment underscores the \textbf{importance of country-specific benchmarks} in multilingual NLP research and contributes to bridging the gap in Kazakh language understanding.

% We compare \datasetname{} against existing benchmarks, namely SIGTURK 2024 ____ and INCLUDE ____, in Table~\ref{tab:comparison-mmlu}. Unlike SIGTURK, which focuses on specific NLP tasks in Kazakh, and INCLUDE, which evaluates general multilingual reasoning but lacks Kazakh content, \datasetname{} introduces a \textbf{large-scale, bilingual} evaluation benchmark tailored to Kazakhstan’s unique linguistic and educational landscape. 




% Therefore, there is a need for evaluation of low-resource languages since LLMs struggle with low-resource languages and often miss nuanced linguistic features____ due to imbalanced training data____.


% Although Russian NLP datasets are more extensive, they do not capture Kazakhstan’s unique linguistic and cultural contexts.

% Prior work has shown that LLMs struggle with low-resource languages due to imbalanced training data ____ and often miss nuanced linguistic features ____. In response, language-specific models like Vikhr ____ and Aya ____ have been developed; however, they are not tailored for the knowledge-rich reasoning required by Kazakhstan’s bilingual educational system.



%[Mukhammed] Comparison Between SIGTURK

% \begin{table*}[ht]
% \centering
% \renewcommand{\arraystretch}{1.2} % Adjust row height
% \setlength{\tabcolsep}{3pt} % Adjust column spacing
% \footnotesize % Compact text
% \begin{tabularx}{\textwidth}{|p{3.6cm}|p{3.8cm}|p{3.8cm}|p{3.8cm}|} % Ensuring equal column widths
% \hline
% \textbf{Feature} & \textbf{KazMMLU} & SIGTURK & INCLUDE\\
% \hline
% \textbf{Dataset Size} & 23,000 questions & 6 tasks, existing datasets & 197,243 questions \\
% \hline
% \textbf{Languages Covered} & \textbf{Kazakh and Russian} & Kazakh & 44 languages (but no Kazakh) \\
% \hline
% \textbf{Kazakh-Specific Content} & \textbf{Yes}, sourced from \newline local curriculum, national exams & Limited (Kazakh NLP tasks) & No \\
% \hline
% \textbf{Education Levels} & \textbf{High School, University} & Not explicitly structured & General education \\
% \hline
% \textbf{Subjects Covered} & \textbf{STEM, Humanities,} \newline \textbf{Social Sciences, Law, Medicine} & QA, MT, \newline causal reasoning & Broad general knowledge \\
% \hline
% \textbf{Task Type} & \textbf{Bilingual MCQs} \newline reflecting real-world knowledge & QA, classification, \newline generative tasks & General MCQs across languages \\
% \hline
% \textbf{Model Benchmarking} & \textbf{41 LLMs} \newline (GPT-4o, Llama-3.1, DeepSeek, etc.) & 7 models on \newline Kazakh NLP tasks & Multiple LLMs \newline across 44 languages \\
% \hline
% \end{tabularx}
% \caption{Comparison of \textbf{KazMMLU} with SIGTURK and INCLUDE.}
% \label{tab:comparison-mmlu}
% \end{table*}


\begin{table*}[t!]
\centering
\renewcommand{\arraystretch}{1.2} % Adjust row height
\setlength{\tabcolsep}{5pt} % Slightly increase column spacing
\footnotesize % Compact text
\begin{tabularx}{\textwidth}{X X X X} 
\toprule
\textbf{Feature} & \textbf{KazMMLU} & \textbf{SIGTURK} & \textbf{INCLUDE} \\
\midrule
% \bf Dataset Size & 23,000 questions & 3,000 questions & 5736 questions \\
\bf Public Dataset Size & 23,000 questions in Kazakh and Russian & 3,000 questions exclusively in Kazakh & 23,741 total questions, including 500 in Kazakh \\
\bf Languages Covered & Kazakh, Russian & Kazakh & 44 (including Kazakh) \\
\bf Kazakh-Specific Content & \textbf{Yes}, sourced from local curriculum, national exams & Limited (Kazakh NLP tasks) & Limited \\
\bf Education Levels & High School, University & Not explicitly structured & General education \\
\bf Subjects Covered & STEM, Humanities, Social Sciences, Law, Medicine & QA, MT, causal reasoning & Broad general knowledge \\
\bf Task Type & Bilingual MCQs reflecting real-world knowledge & QA, classification, generative tasks & General MCQs across languages \\
\bf Model Benchmarking & 41 LLMs (GPT-4o, Llama-3.1, DeepSeek V3, etc.) & 7 models on Kazakh NLP tasks & Multiple LLMs across 44 languages \\
\bottomrule
\end{tabularx}
\caption{Comparison of \textbf{KazMMLU} with SIGTURK and INCLUDE.}
\label{tab:comparison-mmlu}
\end{table*}





% \paragraph{Comparison with Existing Benchmarks}
% We compare \datasetname{} against existing benchmarks, namely SIGTURK 2024 ____ and INCLUDE ____, in Table~\ref{tab:comparison-mmlu}. Unlike SIGTURK, which focuses on specific NLP tasks in Kazakh, and INCLUDE, which evaluates general multilingual reasoning but lacks Kazakh content, \datasetname{} introduces a \textbf{large-scale, bilingual} evaluation benchmark tailored to Kazakhstan’s unique linguistic and educational landscape. 

% \datasetname{} is the only dataset that integrates \textbf{real-world educational materials, professional subjects}, and \textbf{domain-specific reasoning} in both Kazakh and Russian, providing a more \textbf{localized} and \textbf{comprehensive} assessment of LLMs. This structured evaluation highlights the \textbf{importance of country-specific benchmarks} in multilingual NLP research and helps bridge the existing gap in Kazakh language understanding.



%Evaluating the performance of large language models (LLMs) has become an important task, especially as these models are being deployed across a wide variety of languages and tasks. 


%The MMLU benchmark has been widely adopted for this purpose, with a focus on English and other major languages ____. However, as the demand for multilingual models grows, there is an increasing need for benchmarks that address the unique challenges of non-English languages, including Kazakh. To address this, several MMLU-style datasets in languages like Arabic, Chinese and Indonesian have been introduced ____. 


% Multilingual LLMs often demonstrate performance disparities across languages, particularly struggling with low-resource languages due to training data imbalances ____. These challenges underscore the importance of developing comprehensive evaluation frameworks that can assess model performance across diverse linguistic and cultural contexts. Recent work has shown that even state-of-the-art multilingual models may fail to capture nuanced cultural and linguistic features in low-resource settings ____. This has led to the development of language-specific models, such as Vikhr ____ for Russian and Aya ____ for Kazakh, alongside commercial solutions like YandexGPT. These models are evaluated through frameworks like the MERA project for Russian ethical diagnostics ____, but such efforts lack adaptation to Kazakhstan's unique linguistic and cultural context.

% Existing Kazakh datasets, such as KazNERD ____, KazQAD ____, and KazSANDRA ____, provide valuable resources for specific tasks like named entity recognition, question answering, and sentiment analysis. However, they do not offer a holistic evaluation of reasoning and domain-specific knowledge across multiple disciplines. Our work addresses this gap by providing a comprehensive benchmark that evaluates Kazakh language understanding across a wide range of subjects, enabling more accurate assessments of multilingual LLM performance and fostering advancements in AI for low-resource languages.

% \subsection{Multilingual and Cross-Lingual Benchmarks}

% To produce a PDF file, pdf\LaTeX{} is strongly recommended (over original \LaTeX{} plus dvips+ps2pdf or dvipdf). Xe\LaTeX{} also produces PDF files, and is especially suitable for text in non-Latin scripts.