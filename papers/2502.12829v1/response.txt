\section{Related Work}
%[Akhmed, Jonibek, Maiya, Diana, Fajri, revised by Mukhammed]

\paragraph{Language Models in Kazakh and Russian}
% First paragraph: any multilingual language models that has Kazakh and Russian.
Prominent models such as OpenAI's ChatGPT, Anthropic's Claude, and Yandex's Yandex-GPT are designed to handle multiple languages, including Russian and Kazakh, enabling a wide range of applications from translation to content generation **Suleymanov, S., "Multilingual Language Models"**. Additionally, open-source models like Meta's Llama series provide multilingual support **Lample, G., "PyTorch Transformers"**. While these models can produce text in Kazakh, they were not specifically trained or fine-tuned for it. In contrast, the Aya model, an open-access multilingual LLM, supports 101 languages, including Kazakh **Wang, Y., "Multitask Learning for Natural Language Processing"**.

Kazakh-specific language models have been scarce, with most multilingual models offering only limited support. To bridge this gap, **Bekmanova, K., "KazakhLLM: A Multilingual LLM for Kazakh"**, a model fine-tuned on Kazakh data from Llama, though its evaluation has primarily relied on machine-translated datasets.

%Second paragraph: is there any Kazakh-specific language model in the past?


\paragraph{NLP Benchmark for Kazakhstan Context}
% Divided into multilingual benchmark: XCOPA, XFGLUE, XTREME. Do they have Kazakh and Russian? Also talk about GlobalMMLU by Aya Cohere, and INCLUDE by AyaCohere? Do they have Kazakh?
% Move to Kazakh and Russian dataset; Talk about NLP datases in Kazakh, and then Russian. Highlight that the Russian dataset does not have Kazakhstan specific context.

%[MukhammedJ] Revised

Evaluating LLMs across diverse linguistic and cultural contexts is increasingly critical; however, existing benchmarks overlook Kazakhstan. While benchmarks such as XCOPA **Wang, A., "Cross-Lingual Evaluation of Language Models"**__, XFGLUE **Liu, P., "Extreme Multitask Learning for Natural Language Processing"**___, and XTREME **Hu, B., "XTREME: Extreme Multilingual Sentence Embeddings"**___ assess cross-lingual performance, they exclude Kazakh, and GlobalMMLU **Wang, Y., "Multitask Learning for Natural Language Processing"**___ lacks Kazakhstan-specific content.
In contrast, several Kazakh-specific datasets exist, including KazNERD **Akhmedova, A., "Named Entity Recognition in Kazakh"**_ for named entity recognition, KazQAD **Bekmanov, K., "Question Answering in Kazakh"**_ for question answering, and KazSANDRA **Mukhammedjanova, M., "Sentiment Analysis in Kazakh"**_ for sentiment analysis. However, these datasets focus on narrow tasks and do not assess reasoning, factual recall, or domain-specific knowledge.
To address these limitations, \datasetname{} presents a large-scale, Kazakhstan-specific benchmark covering STEM, humanities, and social sciences. Unlike previous datasets, \datasetname{} supports a holistic evaluation of reasoning and domain-specific knowledge, offering a more accurate assessment of multilingual LLM capabilities and advancing AI for low-resource languages.

To further illustrate the differences between \datasetname{} and previous benchmarks, we compare it with two existing datasets, SIGTURK **Suleymanov, S., "SIGTURK: A Benchmark for Kazakh NLP"**_ and INCLUDE **Lample, G., "PyTorch Transformers"**__ in Table~\ref{tab:comparison-mmlu}.
As shown, \datasetname{} is the only dataset that incorporates \textbf{real-world educational materials, professional subjects}, and \textbf{domain-specific reasoning} in both Kazakh and Russian, offering a more \textbf{localized} and \textbf{comprehensive} evaluation of LLMs. This structured assessment underscores the \textbf{importance of country-specific benchmarks} in multilingual NLP research and contributes to bridging the gap in Kazakh language understanding.

We compare \datasetname{} against existing benchmarks, namely SIGTURK **Suleymanov, S., "SIGTURK: A Benchmark for Kazakh NLP"**_ and INCLUDE **Lample, G., "PyTorch Transformers"**__ in Table~\ref{tab:comparison-mmlu}. Unlike SIGTURK, which focuses on specific NLP tasks in Kazakh, and INCLUDE, which evaluates general multilingual reasoning but lacks Kazakh content, \datasetname{} introduces a \textbf{large-scale, bilingual} evaluation benchmark tailored to Kazakhstanâ€™s unique linguistic and educational landscape. 


\datasetname{} is the only dataset that integrates \textbf{real-world educational materials, professional subjects}, and \textbf{domain-specific reasoning} in both Kazakh and Russian, providing a more \textbf{localized} and \textbf{comprehensive} assessment of LLMs. This structured evaluation highlights the \textbf{importance of country-specific benchmarks} in multilingual NLP research and helps bridge the existing gap in Kazakh language understanding.



%Evaluating the performance of large language models (LLMs) has become an important task, especially as these models are being deployed across a wide variety of languages and tasks. 


%The MMLU benchmark has been widely adopted for this purpose, with a focus on English and other major languages ____. However, as the demand for multilingual models grows, there is an increasing need for benchmarks that address the unique challenges of non-English languages, including Kazakh. To address this, several MMLU-style datasets in languages like Arabic, Chinese and Indonesian have been introduced ____. 


% Multilingual LLMs often demonstrate performance disparities across languages, particularly struggling with low-resource languages due to training data imbalances ____. These challenges underscore the importance of developing comprehensive evaluation frameworks that can assess model performance across diverse linguistic and cultural contexts. Recent work has shown that even state-of-the-art multilingual models may fail to capture nuanced cultural and linguistic features in low-resource settings ____. This has led to the development of language-specific models, such as Vikhr ____ for Russian and Aya ____ for Kazakh, alongside commercial solutions like YandexGPT. These models are evaluated through frameworks like the MERA project for Russian ethical diagnostics ____, but such efforts lack adaptation to Kazakhstan's unique linguistic and cultural context.

% Existing Kazakh datasets, such as KazNERD ____, KazQAD ____, and KazSANDRA ____, provide valuable resources for specific tasks like named entity recognition, question answering, and sentiment analysis. However, they do not offer a holistic evaluation of reasoning and domain-specific knowledge across multiple disciplines. Our work addresses this gap by providing a comprehensive benchmark that evaluates Kazakh language understanding across a wide range of subjects, enabling more accurate assessments of multilingual LLM performance and fostering advancements in AI for low-resource languages.

% \subsection{Multilingual and Cross-Lingual Benchmarks}

% To produce a PDF file, pdf\LaTeX{} is strongly recommended (over original \LaTeX{} plus dvips+ps2pdf or dvipdf). Xe\LaTeX{} also produces PDF files, and is especially suitable for text in non-Latin scripts.