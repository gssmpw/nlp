\section{Related Work}
\label{sec:lit}

In recent years, monocular depth estimation has been dominated both in terms of popularity and performance by self-supervised approaches, and therefore we focus this section on these. SfMLearner \cite{zhou2017unsupervised} was one of the pioneering methods of this kind. It introduced the popular concept of jointly training depth and camera pose regression networks using a loss that measures re-projected photometric consistency on pairs of overlapping views. Most of the more recent self-supervised approaches all follow a similar training methodology. Monodepth2 \cite{godard2019digging} adds a multi-scale appearance matching loss to address occluded pixels as well as an auto-masking technique to ignore static pixels that generate infinity depth values. In parallel, SC-SfMLearner \cite{bian2019unsupervised} introduced a constraint for scale consistency and added a self-discovered mask to address dynamic scenes and occlusions. Many works have built upon these methods, with MonoViT \cite{zhao2022monovit} being a notable example with state-of-the-art performance that adopts the Monodepth2 methodology while using a transformer-based depth network. 

However, these methods have sub-optimal performance when applied to endoscopy data. One of the reasons is that they all assume the visualised scene is approximately a Lambertian surface, i.e. any 3D location is viewed with the same colour and light intensity from any viewpoint. However, in endoscopy, this is not true due to the moving light source and the visualised wet tissue being highly reflective and deformable. 

In the endoscopic domain, some methods have incorporated model-free learning based models to estimate an offset that compensates small light changes in different viewpoints. One of the first solutions of this kind proposed a linear affine brightness transformer that was added to the photometric loss \cite{ozyoruk2021endoslam}. This was extended in \cite{rau2023task} by applying domain adaptation so that both real and synthetic data can be combined during training.  To further incorporate the appearance changes in endoscopy, AF-SfMLearner \cite{shao2022self} added appearance flow and correspondence networks. In \cite{zhou2023tackling}, a conﬁdence-based colour offset penalty is added to the appearance flow network to improve low-texture and drastic illumination ﬂuctuations. Some have also introduced temporal information to AF-SfMLearner \cite{lou2024ws,shi2024long}.

A different type of methods attempt to filter out regions likely to be inconsistent, such as specular reflections. This can be achieved with a separate specularity detection algorithm that either masks out regions during loss computation \cite{li2023endodepthl,yue2023tcl}, or is utilised to learn how to reconstruct surface texture underneath specular regions \cite{wu2023unleashing}. In \cite{liao2024self}, a multitask PoseNet is incorporated to generate pose and two types of masks: one for photometric loss focused on specularities and another for geometric consistency loss focused on deformations. In \cite{rodriguez2022uncertain}, specular highlights are implicitly incorporated by minimizing uncertainty estimated through Bayesian or deep ensemble learning.

%Some methods try to compensate for light-realted challenges indirectly by improving the underlying network architecture \cite{zeinoddin2024dares} or expanding the photometric loss to a multi-scale one \cite{liu2023self}. 

Finally, other methods try to model light reflection properties more explicitly. In \cite{wang2023surface}, light intensity is made dependent on its direction. In \highlight{LightDepth \cite{rodriguez2023lightdepth}, LD for short}\todo{R1.1}, a light decline model, coupled with estimated albedo and shading, is utilised as a supervision signal instead of the standard pose estimation network. They account for non-Lambertian properties by adding a specular loss term. The most closely related method to ours, IID-SfMLearner (IID for short) \cite{li2024image}, uses an intrinsic decomposition network to simultaneously estimate depth, albedo and shading.  To compensate for non-Lambertian properties, they incorporate a shading adjustment network. However, the models described in \cite{li2024image} and \cite{rodriguez2023lightdepth} can only compensate for small light changes and are still not capable of fully handling saturated specularities. In this paper, we improve on \cite{li2024image} by explicitly modelling a non-Lambertian image decomposition (albedo, shading, and specularities) instead of utilising an adjustment network.

%However, among all these methods, only some used Monodepth2's auto-masking approach \cite{liu2023self,li2023endodepthl,zhou2023tackling,wang2023surface,yue2023tcl}. In this paper we adopt this masking strategy and analyze its benefits and lack of use.