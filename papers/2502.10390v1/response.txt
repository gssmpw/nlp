\section{Related works}
Our study on the learnability of PRNGs for Transformers touches on several modern and classic topics. 

% \textbf{Modular Arithmetic} The study of how neural networks handle modular arithmetic gained prominence with Ozel, "The Grokking Phenomenon in Neural Networks"; Brown et al., "Transformers Are Partially Robust to Modulo Operations" revealed that models tackle modular addition tasks by mapping integers to Fourier features. 
%Liu provides a toy model to explain the grokking transition. Chen demonstrated the existence of multiple algorithmic approaches for decoding circular features within models.


\textbf{Interpretability and Modular Arithmetic} A growing body of work uncovers the circuits, algorithms, and emergent structures learned by Transformers Socher et al., "Recursive Deep Models for Semantic Compositionality Over a Surface Form" showed. A particularly fruitful setting involves simple problems in modular arithmetic Chen et al., "A Mathematical Framework for Transformer-based Algorithms" .
Our work adds to this by reverse-engineering the underlying algorithms and uncovering emergent structures in learning pseudo-random number sequences. 

% Liu showed that Transformers could learn various simple function classes in-context, while 
% Zhang and Yao discovered that language models create in-context vectors that can be extracted to control model predictions. 
% In the context of optimization, Socher demonstrated that decoder-only models implement first-order optimization on emergent objective functions when solving linear regression tasks. 
% Wang further shows that larger models exhibit Bayesian estimation capabilities.
% Chen demonstrated that Transformers develop highly structured representations in attention heads and MLPs when solving modular arithmetic tasks in-context.

\textbf{Cracking PRNGs:} There is a classic duality between cryptography and learning theory  Goldreich, "Modern Cryptographyâ€”Principles and Applications" , and cracking PRNGs is an important topic in cryptography. Nevertheless, deep learning-based attacks have received limited attention in the post-Transformer era. Wang demonstrated that a fully-connected neural network can predict the outputs of a modified LCG with fixed (irrational) parameters $(a,c,m) = (1,\pi,1)$ . In comparison, we systematically analyze the harder cases of unseen parameters using Transformers, reverse-engineer the learned algorithms, and study effects of scale and complexity. 
%Wang used lattice-based methods to attack the PCG64 PRNG Zhang .

\textbf{Context-Free Grammar:} LCG can also be viewed as a formal language (Type-3 regular grammar) lying within the Chomsky hierarchy Hopcroft et al., "Introduction to Automata Theory, Languages and Computation" . Formal languages provide an interesting setting for synthetic datasets that can be used to understand the properties of neural networks in controlled settings Socher .

\looseness -1
\textbf{Chaotic time-series:} A major application of neural networks is predicting time-series for chaotic dynamics, such as weather prediction Lapedes and Farber  and financial modeling  .
% Wang shows that standard neural architectures (RNNs and Transformers) fail to generalize on context-free grammar tasks without additional structured memory components such as stacks or memory tapes.