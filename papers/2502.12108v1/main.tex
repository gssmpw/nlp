
\documentclass[10pt]{article} % For LaTeX2e
%\usepackage{tmlr}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{tmlr}
% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
\usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{url}
\usepackage{amsmath}


\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{axiom}{Axiom}
\newtheorem{theorem}{Theorem}
\newtheorem{proof}{Proof}

\title{Using the Path of Least Resistance to Explain Deep Networks}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

\author{\name Sina Salek \email salek.sina@gmail.com\\
	\addr Independent Researcher
	\AND
	\name Joseph Enguehard \email joseph.enguehard@robinai.com \\
	\addr Robin AI\\ 10 Devonshire Square, City of London, London EC2M 4YP
}

% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\def\month{02}  % Insert correct month for camera-ready version
%\def\year{2025} % Insert correct year for camera-ready version
%\def\openreview{\url{https://openreview.net/forum?id=XXXX}} % Insert correct link to OpenReview for camera-ready version


\begin{document}
	
	
	\maketitle
	
	\begin{abstract}
		Integrated Gradients (IG), a widely used axiomatic path-based attribution method, assigns importance scores to input features by integrating model gradients along a straight path from a baseline to the input. While effective in some cases, we show that straight paths can lead to flawed attributions. In this paper, we identify the cause of these misattributions and propose an alternative approach that treats the input space as a Riemannian manifold, computing attributions by integrating gradients along geodesics. We call this method \emph{Geodesic Integrated Gradients} (GIG).
		To approximate geodesic paths, we introduce two techniques: a $k$-Nearest Neighbours-based approach for smaller models and a Stochastic Variational Inference-based method for larger ones. Additionally, we propose a new axiom, \emph{Strong Completeness}, extending the axioms satisfied by IG. We show that this property is desirable for attribution methods and that GIG is the only method that satisfies it.
		Through experiments on both synthetic and real-world data, we demonstrate that GIG outperforms existing explainability methods, including IG.\footnote{The code for the attribution methods and experiment reproductions is available at \href{https://github.com/sina-salek/geodesic-ig}{https://github.com/sina-salek/geodesic-ig}.}
		
		
	\end{abstract}
	\input{introduction}
	\input{method}
	\input{experiments}
	\input{related_work}
	\input{discussion}
	
	\bibliography{bib}
	\bibliographystyle{plainnat}
	
	\newpage
	\appendix
	\onecolumn
	\input{appendix}
	
\end{document}