\section{Introduction}
\label{sec:introduction}

The use of deep learning models has risen in many applications. With it, so too has the desire to understand why these models make certain predictions. These models are often referred to as ``opaque'', as it is difficult to discern the reasoning behind their predictions \cite{marcus2018deep}. Additionally, deep learning models can inadvertently learn and perpetuate biases found in their training data \cite{sap2019risk}. To create fair and trustworthy algorithms, it is essential to be able to explain a model's output \cite{das2020opportunities}. 

Some examples of the methods proposed to explain neural networks include Gradient SHAP \cite{lundberg2017unified}, Integrated Gradients  \cite{sundararajan2017axiomatic} and Guided Integrated Gradients  \cite{kapishnikov2021guided}.

Significant effort has been dedicated to designing explanation methods that satisfy certain desirable axioms. This is due to the lack of ground truth for evaluating them. The axioms can ensure that the explanations are principled. One of the most successful axiomatic methods is Integrated Gradients (IG) \cite{sundararajan2017axiomatic}. Consider a function $f : R^n \to R$, representing the neural network and an input vector $\textbf{x} \in R^n$. Furthermore, consider a baseline input vector $\overline{\textbf{x}} \in R^n$ (typically chosen such that the network gives baseline a near zero score). IG explains the network by quantifying how much of the difference $f(\textbf{x}) - f(\overline{\textbf{x}})$ can be attributed to the $i$th dimension of $\textbf{x}$, $\textbf{x}_i$.


Integrated Gradient gives attribution $IG_i$ to the $i$th dimension of the input by approximating the following path integral

\begin{equation}
IG_i(\textbf{x}) = (\textbf{x}_i - \overline{\textbf{x}}_i) \int_0^1 \frac{\partial f(\gamma(t))}{\partial \textbf{x}_i} dt, \label{eq:igi}
\end{equation}
where $\gamma(t) = \overline{\textbf{x}} + t(\textbf{x} - \overline{\textbf{x}})$ is a straight path from the baseline to input. The claim of the creators of IG is that Eq. \ref{eq:igi} tells us how the model got from predicting essentially nothing at $\overline{\textbf{x}}$ to giving the prediction at $\textbf{x}$. Considering gradients represent the rate of change of functions, the above expression should tell us how scaling each feature along the path affects the increase in the network score for the predicted class.

\begin{figure}[t!]
	\begin{center}
		\centerline{\includegraphics[width=0.85\textwidth]{figures/voc_compare_2.png}}
		\caption{Comparison of attributions generated by Integrated Gradients (middle figure) and Geodesic Integrated Gradients (right figure) for image classification with a ConvNext model. Integrated Gradients follow straight paths in Euclidean space, which can result in misleading attributions. In contrast, Geodesic Integrated Gradients integrate along geodesic paths on a Riemannian manifold defined by the model, correcting misattributions caused by poor alignment with the model's gradient landscape. In both cases, the baseline is a black image.
		For IG, since the jets are black, apart from the artefacts created outside of the boundaries of the jets, the attribution method is misled into considering the jets unimportant for classification—despite the fact that they are the objects being classified. Geodesic IG does not suffer from this issue. Further examples of such misattributions due to black segments in images are shown in Appendix \ref{app:voc}.}
		\label{fig:duck}
	\end{center}
	\vskip -0.3in
\end{figure}

\begin{figure}[b!]
	\vskip 0.2in
	\begin{center}
		\includegraphics[width=0.85\columnwidth]{figures/voc_metrics.png}
		\caption{ \textbf{Metrics Comparison.} We use a ConvNext model to classify images from the VOC dataset. The horizontal axis represents the top k\% (in absolute value) of selected features.
		The left plot, Comprehensiveness, shows the average change in the predicted class probability compared to the original image (higher is better). The right plot displays the log-odds (lower is better).
		In both cases, results are summarised using AUC, where higher values indicate better performance. Geodesic IG significantly outperforms other methods in both metrics. See Section \ref{sec:experiments} for details of the experiments.}
		\label{fig:voc_metrics}
	\end{center}
	\vskip -0.2in
\end{figure}


In this paper, we demonstrate that defining attributions along straight paths in Euclidean space can lead to flawed attributions. We examine the consequences of these misattributions through examples in computer vision, as shown in Fig. \ref{fig:duck}, along with simpler, illustrative cases in Fig. \ref{fig:ig}. To address these issues, we introduce \textbf{Geodesic Integrated Gradients}, a generalisation of IG that replaces straight paths with geodesic ones. These geodesics are defined on a Riemannian manifold, characterised by the model's input space and a metric tensor induced by the model's gradients. This approach mitigates the identified pitfalls while retaining all the axioms of IG. Furthermore, we introduce an additional axiom, Strong Completeness, which we argue is a desirable property for attribution methods. We prove that Geodesic Integrated Gradients is the only method that satisfies this axiom, further justifying its theoretical soundness.

Before making the case for our Geodesic Integrated Gradient, let us first show an example of an artefact that can arise from choosing straight paths, generating explanations which do not reflect the true behaviour of a model. 

We highlight this issue with a simple half-moons classification task. We train a three-layer multi-layer perceptron (MLP) with ReLU activations and a cross-entropy loss to distinguish the upper moon from the lower one. The cross-entropy is decomposed into a final log-softmax activation followed by a negative log-likelihood loss, allowing us to explain probabilities. The model is trained long enough that high gradients emerge at the decision boundary, while the model remains flat elsewhere, as illustrated by the gradient contour maps in Fig.~\ref{fig:ig}.  

We now compute Integrated Gradients, Eq.~\ref{eq:igi}, for this model on the test data. As an appropriate baseline, we choose the point $(-0.5, -0.5)$, which is a reasonable choice since the network should assign a near-zero score to it. Let us denote the feature along the vertical axis as the first component of $\mathbf{x}$, i.e., $x_1$. In Fig.~\ref{fig:ig}(a) (top image), we visualise the horizontal attribution of this feature, $\text{IG}_1(\mathbf{x})$, using a colour map. 

We expect in a model that is flat almost everywhere except near the decision boundary, moving slightly further from the decision boundary should not significantly change the model’s score. In such a case, the attribution should remain stable for points far from the decision boundary. Yet, as shown in Fig.~\ref{fig:ig}(a), Integrated Gradients significantly violates this for certain points. These are points, as seen in the figure, where the straight-line path from the baseline $(-0.5, -0.5)$ to the input passes mostly through high-gradient regions. This does not accurately reflect the model's behaviour. A similar issue arises in the vertical attribution, shown in Fig.~\ref{fig:ig}(b), but in the opposite direction to the horizontal attribution.  

In contrast, Geodesic Integrated Gradients (Geodesic IG), shown at the bottom of Fig.~\ref{fig:ig}(a) and (b), correctly assigns equally high attributions to all points sufficiently far from the decision boundary. In Section~\ref{subsec:half-moons}, we detail our method and explain how it achieves the results presented in this figure.  


\begin{figure}[!t]
	\vskip -0.1in
	\begin{center}
		\centerline{\includegraphics[width=0.85\columnwidth]{figures/moons_compare.pdf}}
		\vskip -0.2in
		\caption{\textbf{Integrated Gradients (IG) attributions (top) vs. Geodesic IG (bottom).} 
			We plot scatter plots of 10,000 samples from the half-moons dataset with noise parameter $\mathcal{N}(0, 0.15)$. An MLP model is trained for classification, and the model gradients are shown as contour maps. The model is nearly flat everywhere except at the decision boundary.  
			Using a baseline at $(-0.5, -0.5)$, we compute IG and Geodesic IG attributions. From left to right, the colour maps display (a) feature attributions along the horizontal axis, (b) feature attributions along the vertical axis, (c) the absolute sum of attributions, $\sum_i |A_i(\mathbf{x})|$, and (d) the total sum of attributions, $\sum_i A_i(\mathbf{x})$.  
			According to Axioms~\ref{ax:complete} and~\ref{ax:strong}, the heatmaps in the last two columns should resemble those in Fig.~\ref{fig:outcome_diff}. As shown, IG satisfies Axiom~\ref{ax:complete} (last column) but not Axiom~\ref{ax:strong} (penultimate column). In contrast, Geodesic IG satisfies both. Additionally, similar to Fig.~\ref{fig:duck}, IG is highly sensitive to the choice of baseline due to its reliance on a straight-line path, whereas Geodesic IG mitigates this sensitivity.}  
		
		\label{fig:ig}
	\end{center}
	\vskip -0.2in
\end{figure}

\begin{figure}[!b]
	\vskip -0.1in
	\begin{center}
		\centerline{\includegraphics[width=0.5\columnwidth]{figures/complete_strong.pdf}}
		\vskip -0.2in
		\caption{\textbf{Model output at the baseline vs. input points.} To assess whether our attribution methods satisfy Axioms \ref{ax:complete} and \ref{ax:strong} in the half-moons example, we plot the model output at the input points, subtracting the model output at the baseline. The left plot shows this difference, $f(\textbf{x}) - f(\overline{\textbf{x}})$, while the right plot shows the absolute difference, $|f(\textbf{x}) - f(\overline{\textbf{x}})|$. Comparing these plots with those in Fig. \ref{fig:ig}, we observe that Geodesic IG satisfies both axioms, whereas IG satisfies Completeness, only.}
		\label{fig:outcome_diff}
	\end{center}
	\vskip -0.2in
\end{figure}

The above artefacts further highlight an issue with over-reliance on the following axiom satisfied by IG: 
\begin{axiom}[{\textbf{Completeness}}]
	\label{ax:complete}
		Consider an input-baseline pair $\textbf{x}$ and $\overline{\textbf{x}}$, and a function $f$. Let $\text{A}_i(\textbf{x})$ be the attribution of $\textbf{x}_i$. The method satisfies Completeness if 
	\begin{equation}
		\sum_i{\text{A}_i(\textbf{x})} = f(\textbf{x}) - f(\overline{\textbf{x}}),
		\label{eq:completeness}
	\end{equation} 
\end{axiom}

This axiom ensures that the total attribution equals the difference in function values between the baseline and the input. While completeness guarantees certain mathematical consistency, as the previous example illustrates, it does not account for cancellation effects between features.

In the above example, we considered a two-dimensional case where the model assigns nearly the same function value to the input points belonging to the top half-moon. Completeness then requires that for all points, the total attribution must be close to the same constant, $c$, i.e. $\sum_i{\text{A}_i(\textbf{x})} \approx c\text{ } \forall \textbf{x}$. Furthermore, we \emph{know} that the horizontal feature of all points in the same half-moon have equal importance for this particular model. The same goes for the vertical features. Despite this, while IG violates the latter, it can still satisfy completeness by assigning large positive attributions to one feature and equally large negative attributions to the other—cancelling out in the sum but distorting individual attributions. This imbalance does not occur consistently across all points, further complicating interpretation.

To address this issue, we introduce a stronger axiom:

\begin{axiom}[{\textbf{Strong Completeness}}]
	\label{ax:strong}
	Consider an input-baseline pair $\textbf{x}$ and $\overline{\textbf{x}}$, and a continuously differentiable function $f$. Let $\text{A}_i(\textbf{x})$ be the attribution of $\textbf{x}_i$. The method satisfies Strong Completeness if
	\begin{equation}
		\sum_i{|\text{A}(\textbf{x}_i)|} = |f(\textbf{x}) - f(\overline{\textbf{x}})|
	\end{equation}
\end{axiom} 

This stronger version of Completeness guarantees that cancellation effect cannot superficially make the attributions to add up to the difference between the function's score at the baseline versus the input points. As we shall see in section \ref{sec:strong_comp}, Geodesic Integrated Gradients is the only path-based method that satisfies this desired axiom.

In Section \ref{sec:method}, we present two methods for approximating the geodesic path between two points on a manifold. The first method, based on $k$-nearest neighbours ($k$NN), is designed for simpler manifolds, while the second method, utilising Stochastic Variational Inference, is suited for more complex manifolds. We further demonstrate that Geodesic IG adheres to all the axioms of Integrated Gradients.


In Section \ref{sec:experiments}, we demonstrate the effectiveness of the Geodesic IG method on the real-world Pascal VOC 2012 dataset \cite{pascal-voc-2012}. Our results outperform existing methods, as we evaluate using two metrics. We preview the results of this experiment in Fig. \ref{fig:voc_metrics}.

Section \ref{sec:related_work} reviews related work, including the comparison of Geodesic IG with other methods that attempt to overcome the shortcomings of Integrated Gradients.