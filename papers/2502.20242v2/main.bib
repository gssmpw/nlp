@misc{alphazero,
      title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm}, 
      author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
      year={2017},
      eprint={1712.01815},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1712.01815}, 
  }

@misc{googleassistant,
    author = "{Wikipedia contributors}",
    title = "Google Assistant --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Google_Assistant&oldid=1236708270",
    note = "[Online; accessed 30-July-2024]"
  }

@misc{cortana,
    author = "{Wikipedia contributors}",
    title = "Cortana (virtual assistant) --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Cortana_(virtual_assistant)&oldid=1235741000",
    note = "[Online; accessed 30-July-2024]"
  }

@inproceedings{youtube,
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
title = {Deep Neural Networks for YouTube Recommendations},
year = {2016},
isbn = {9781450340359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2959100.2959190},
doi = {10.1145/2959100.2959190},
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
pages = {191–198},
numpages = {8},
keywords = {deep learning, recommender system, scalability},
location = {Boston, Massachusetts, USA},
series = {RecSys '16}
}

@ARTICLE{sanchez2021survey,
  author={Sánchez Sánchez, Pedro Miguel and Jorquera Valero, José María and Huertas Celdrán, Alberto and Bovet, Gérôme and Gil Pérez, Manuel and Martínez Pérez, Gregorio},
  journal={IEEE Communications Surveys Tutorials}, 
  title={A Survey on Device Behavior Fingerprinting: Data Sources, Techniques, Application Scenarios, and Datasets}, 
  year={2021},
  volume={23},
  number={2},
  pages={1048-1077},
  doi={10.1109/COMST.2021.3064259}
}

@misc{ deepart,
    author = "{Wikipedia contributors}",
    title = "DeepArt --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=DeepArt&oldid=1230840008",
    note = "[Online; accessed 30-July-2024]"
  }

@misc{ ibmwatson,
    author = "{Wikipedia contributors}",
    title = "IBM Watson --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=IBM_Watson&oldid=1236620087",
    note = "[Online; accessed 30-July-2024]"
  }

@misc{ hirevue,
    author = "{Wikipedia contributors}",
    title = "HireVue --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=HireVue&oldid=1232852058",
    note = "[Online; accessed 30-July-2024]"
  }

@misc{ geolitica,
    author = "{Wikipedia contributors}",
    title = "Geolitica --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Geolitica&oldid=1220433353",
    note = "[Online; accessed 30-July-2024]"
  }

@article{federatedlearning,
title = {A review of applications in federated learning},
journal = {Computers \& Industrial Engineering},
volume = {149},
pages = {106854},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2020.106854},
url = {https://www.sciencedirect.com/science/article/pii/S0360835220305532},
author = {Li Li and Yuxi Fan and Mike Tse and Kuo-Yi Lin},
keywords = {Federated learning, Literature review, Citation analysis, Research front}
}

@ARTICLE{failurevulnerabilitiesinFL,
  author={Bouacida, Nader and Mohapatra, Prasant},
  journal={IEEE Access}, 
  title={Vulnerabilities in Federated Learning}, 
  year={2021},
  volume={9},
  number={},
  pages={63229-63249},
  keywords={Training;Security;Data models;Computational modeling;Servers;Privacy;Training data;Attacks;defenses;federated learning;security threats;vulnerabilities},
  doi={10.1109/ACCESS.2021.3075203}}

@article{dfl,
   title={Decentralized Federated Learning: Fundamentals, State of the Art, Frameworks, Trends, and Challenges},
   volume={25},
   ISSN={2373-745X},
   url={http://dx.doi.org/10.1109/COMST.2023.3315746},
   DOI={10.1109/comst.2023.3315746},
   number={4},
   journal={IEEE Communications Surveys \& Tutorials},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Martínez Beltrán, Enrique Tomás and Pérez, Mario Quiles and Sánchez, Pedro Miguel Sánchez and Bernal, Sergio López and Bovet, Gérôme and Pérez, Manuel Gil and Pérez, Gregorio Martínez and Celdrán, Alberto Huertas},
   year={2023},
   pages={2983–3013} }

@misc{computaionalpower,
  author = {Henshall, W.},
  title = {4 Charts That Show Why AI Progress Is Unlikely to Slow Down},
  year = {2023},
  url = {https://time.com/6300942/ai-progress-charts/},
  note = {Accessed: 31.07.2024}
}


@Article{energycarbon,
  AUTHOR = {Andrae, Anders S. G. and Edler, Tomas},
  TITLE = {On Global Electricity Usage of Communication Technology: Trends to 2030},
  JOURNAL = {Challenges},
  VOLUME = {6},
  YEAR = {2015},
  NUMBER = {1},
  PAGES = {117--157},
  URL = {https://www.mdpi.com/2078-1547/6/1/117},
  ISSN = {2078-1547},
  DOI = {10.3390/challe6010117}
}

@misc{lynn2023,
 title={Assessing the Sustainability and Trustworthiness of Federated Learning Models}, 
      author={Chao Feng and Alberto Huertas Celdran and Pedro Miguel Sanchez Sanchez and Lynn Zumtaugwald and Gerome Bovet and Burkhard Stiller},
      year={2024},
      eprint={2310.20435},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2310.20435}, 
}


                
@article{fedstellar:2024,
    title = {{Fedstellar: A Platform for Decentralized Federated Learning}},
    author = {Mart{\'i}nez Beltr{\'a}n, Enrique Tom{\'a}s and Perales G{\'o}mez, {\'A}ngel Luis and Feng, Chao and S{\'a}nchez S{\'a}nchez, Pedro Miguel and L{\'o}pez Bernal, Sergio and Bovet, G{\'e}r{\^o}me and Gil P{\'e}rez, Manuel and Mart{\'i}nez P{\'e}rez, Gregorio and Huertas Celdr{\'a}n, Alberto},
    year = 2024,
    volume = {242},
    issn = {0957-4174},
	pages = {122861},
	journal = {Expert Systems with Applications},
  	doi = {10.1016/j.eswa.2023.122861},
	preprint = {https://arxiv.org/abs/2306.09750}
}

@article{beltran2023decentralized,
  title={Decentralized federated learning: Fundamentals, state of the art, frameworks, trends, and challenges},
  author={Beltr{\'a}n, Enrique Tom{\'a}s Mart{\'\i}nez and P{\'e}rez, Mario Quiles and S{\'a}nchez, Pedro Miguel S{\'a}nchez and Bernal, Sergio L{\'o}pez and Bovet, G{\'e}r{\^o}me and P{\'e}rez, Manuel Gil and P{\'e}rez, Gregorio Mart{\'\i}nez and Celdr{\'a}n, Alberto Huertas},
  journal={IEEE Communications Surveys \& Tutorials},
  year={2023},
  publisher={IEEE}
}

@online{renewableEnergy2023,
  author = {Lauren Edwards},
  title = {The Difference Between Renewable and Non-Renewable Resources},
  year = {2023},
  url = {https://www.nesfircroft.com/resources/blog/the-difference-between-renewable-and-non-renewable-resources/},
  urldate = {2023-08-01}
}

@misc{qiu2021federatedlearningsaveplanet,
      title={Can Federated Learning Save The Planet?}, 
      author={Xinchi Qiu and Titouan Parcollet and Daniel J. Beutel and Taner Topal and Akhil Mathur and Nicholas D. Lane},
      year={2021},
      eprint={2010.06537},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2010.06537}, 
}

@misc{patterson2022carbonfootprintmachinelearning,
      title={The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink}, 
      author={David Patterson and Joseph Gonzalez and Urs Hölzle and Quoc Le and Chen Liang and Lluis-Miquel Munguia and Daniel Rothchild and David So and Maud Texier and Jeff Dean},
      year={2022},
      eprint={2204.05149},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2204.05149}, 
}

@misc{qiu2023lookcarbonfootprintfederated,
      title={A first look into the carbon footprint of federated learning}, 
      author={Xinchi Qiu and Titouan Parcollet and Javier Fernandez-Marques and Pedro Porto Buarque de Gusmao and Yan Gao and Daniel J. Beutel and Taner Topal and Akhil Mathur and Nicholas D. Lane},
      year={2023},
      eprint={2102.07627},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2102.07627}, 
}

@misc{lacoste2019quantifyingcarbonemissionsmachine,
      title={Quantifying the Carbon Emissions of Machine Learning}, 
      author={Alexandre Lacoste and Alexandra Luccioni and Victor Schmidt and Thomas Dandres},
      year={2019},
      eprint={1910.09700},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/1910.09700}, 
}

@article{energyDFL,
   title={An Energy and Carbon Footprint Analysis of Distributed and Federated Learning},
   volume={7},
   ISSN={2473-2400},
   url={http://dx.doi.org/10.1109/TGCN.2022.3186439},
   DOI={10.1109/tgcn.2022.3186439},
   number={1},
   journal={IEEE Transactions on Green Communications and Networking},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Savazzi, Stefano and Rampa, Vittorio and Kianoush, Sanaz and Bennis, Mehdi},
   year={2023},
   month=mar, pages={248–264} }

@online{zigbee2011,
  author = {Renquan Jin},
  title = {Energy consumption calculation method for ZigBee wireless network nodes},
  year = {2011},
  url = {https://patentimages.storage.googleapis.com/31/b3/1b/bab7c2dd501afc/CN102186184A.pdf},
  urldate = {2023-08-03}
}

@article{wifi,
author = {Das, Anupam},
year = {2020},
month = {03},
journal = {International Journal of Engineering Research \& Technology (IJERT)},
ISSN={2278-0181},
pages = {},
title = {A Study on Energy Consumption of Different Wireless Devices}
}


@misc{2024nebular,
  author = {Mart{\'i}nez Beltr{\'a}n, Enrique Tom{\'a}s and Perales G{\'o}mez, {\'A}ngel Luis and Feng, Chao and S{\'a}nchez S{\'a}nchez, Pedro Miguel and L{\'o}pez Bernal, Sergio and Bovet, G{\'e}r{\^o}me and Gil P{\'e}rez, Manuel and Mart{\'i}nez P{\'e}rez, Gregorio and Huertas Celdr{\'a}n, Alberto},
  title = {Nebula},
  year = {2024},
  url = {https://github.com/CyberDataLab/nebula}
}

@misc{tdp,
  author = {PassMark, Maxon},
  title = {CPU Benchmarks Compilation},
  year = {2022},
  url = {https://www.kaggle.com/datasets/alanjo/cpu-benchmarks?resource=download},
  note = {Accessed: 2023-08-04}
}

@misc{naturalearth,
  author = {Nathaneiel V. KELSO, Tom Patterson},
  title = {nvkelso/natural-earth-vector},
  year = {2022},
  url = {https://github.com/nvkelso/natural-earth-vector/tree/master},
  note = {Accessed: 2023-08-04}
}

@misc{codecarbon,
  author = {Volunteers from Mila and the DataForGoodFR},
  title = {mlco2/codecarbon},
  year = {2023},
  url = {https://github.com/mlco2/codecarbon},
  note = {Accessed: 2023-08-04}
}
   
@manual{flask,
  title = {Flask Web Framework},
  author = {Pallets Projects},
  year = {2025},
  note = {Available: \url{https://flask.palletsprojects.com/}}
}


@manual{tensorboard,
  title = {TensorBoard: Visualization Toolkit for TensorFlow},
  author = {Google Research},
  year = {2025},
  note = {Available: \url{https://www.tensorflow.org/tensorboard}}
}

@manual{python_platform,
  title = {Python Standard Library: platform — Access system-specific information},
  author = {Python Software Foundation},
  year = {2025},
  note = {Available: \url{https://docs.python.org/3/library/platform.html}}
}

@manual{psutil,
  title = {psutil: Cross-platform process and system utilities},
  author = {Giampaolo Rodola'},
  year = {2025},
  note = {Available: \url{https://pypi.org/project/psutil/}}
}

@manual{pynvml,
  title = {pynvml: Python bindings for the NVIDIA Management Library (NVML)},
  author = {NVIDIA Corporation},
  year = {2025},
  note = {Available: \url{https://pypi.org/project/pynvml/}}
}

@book{hu2009semiconductor,
  title={Modern semiconductor devices for integrated circuits},
  author={Hu, Chenming},
  journal={(No Title)},
  year={2010}
}

@article{tucker2011green,
  title={Green optical communications—Part I: Energy limitations in transport},
  author={Tucker, Rodney S},
  journal={IEEE Journal of selected topics in quantum electronics},
  volume={17},
  number={2},
  pages={245--260},
  year={2010},
  publisher={IEEE}
}

@article{traficom2021,
  author = {Finnish Transport and Communications Agency (Traficom)},
  title = {First Study on Energy Consumption of Communications Networks},
  journal = {Research Report},
  year = {2021},
  note = {Available: \url{https://www.traficom.fi/en/news/first-study-energy-consumption-communications-networks}}
}

@article{lecun1998mnist,
  author    = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  title     = {Gradient-based learning applied to document recognition},
  journal   = {Proceedings of the IEEE},
  volume    = {86},
  number    = {11},
  pages     = {2278-2324},
  year      = {1998},
  publisher = {IEEE},
  doi       = {10.1109/5.726791}
}

@article{cohen2017emnist,
  author    = {Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, Andre},
  title     = {EMNIST: an extension of MNIST to handwritten letters},
  journal   = {arXiv preprint arXiv:1702.05373},
  year      = {2017}
}

@article{xiao2017fashionmnist,
  author    = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  title     = {Fashion-MNIST: A Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  journal   = {arXiv preprint arXiv:1708.07747},
  year      = {2017}
}

@article{krizhevsky2009cifar10,
  author    = {Krizhevsky, Alex},
  title     = {Learning Multiple Layers of Features from Tiny Images},
  journal   = {Technical Report, University of Toronto},
  year      = {2009},
  url       = {https://www.cs.toronto.edu/~kriz/cifar.html}
}

@inproceedings{howard2019searchingmobilenetv3,
  author    = {Andrew Howard and Mark Sandler and Grace Chu and Liang-Chieh Chen and Bo Chen and Mingxing Tan and Weijun Wang and Yukun Zhu and Ruoming Pang and Vijay Vasudevan and Quoc V. Le and Hartwig Adam},
  title     = {Searching for MobileNetV3},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2019},
  pages     = {1314-1324},
  doi       = {10.1109/ICCV.2019.00140}
}


@inproceedings{he2016resnet,
  author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2016},
  pages     = {770-778},
  doi       = {10.1109/CVPR.2016.90}
}
@misc{feng2025fedeptailoringattentionheterogeneous,
      title={FedEP: Tailoring Attention to Heterogeneous Data Distribution with Entropy Pooling for Decentralized Federated Learning}, 
      author={Chao Feng and Hongjie Guan and Alberto Huertas Celdrán and Jan von der Assen and Gérôme Bovet and Burkhard Stiller},
      year={2025},
      eprint={2410.07678},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.07678}, 
}

@inproceedings{mcmahan2017fedavg,
  author    = {Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Agüera y Arcas},
  title     = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year      = {2017},
  pages     = {1273-1282},
  publisher = {PMLR},
  volume    = {54},
  url       = {http://proceedings.mlr.press/v54/mcmahan17a.html}
}

@inproceedings{blanchard2017krum,
  author    = {Peva Blanchard and Rachid Guerraoui and Julien Stainer},
  title     = {Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems (NeurIPS)},
  year      = {2017},
  pages     = {118--128},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf}
}

@article{yao2024survey,
  title={A survey on large language model (llm) security and privacy: The good, the bad, and the ugly},
  author={Yao, Yifan and Duan, Jinhao and Xu, Kaidi and Cai, Yuanfang and Sun, Zhibo and Zhang, Yue},
  journal={High-Confidence Computing},
  pages={100211},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{ding2024sustainable,
  title={Sustainable LLM Serving: Environmental Implications, Challenges, and Opportunities},
  author={Ding, Yi and Shi, Tianyao},
  booktitle={2024 IEEE 15th International Green and Sustainable Computing Conference (IGSC)},
  pages={37--38},
  year={2024},
  organization={IEEE}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{feng2024dart,
  title={Dart: A solution for decentralized federated learning model robustness analysis},
  author={Feng, Chao and Celdr{\'a}n, Alberto Huertas and Von der Assen, Jan and Beltr{\'a}n, Enrique Tom{\'a}s Mart{\'\i}nez and Bovet, G{\'e}r{\^o}me and Stiller, Burkhard},
  journal={Array},
  pages={100360},
  year={2024},
  publisher={Elsevier}
}

