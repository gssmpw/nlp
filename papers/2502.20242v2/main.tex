\documentclass[a4paper,fleqn]{cas-dc}



\usepackage[numbers]{natbib}

\usepackage{eurosym,makecell,comment}
\usepackage{multirow}
\usepackage{threeparttable}
%\pagestyle{empty} 
\usepackage{framed}
\usepackage{hyperref}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{float}
\usepackage{xcolor}
\usepackage{microtype}
\usepackage{colortbl}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{tikz}
\usepackage{pgfplots}
%\usepackage{mathtools}
\usepackage{listings}
%\usepackage{adjustbox}
%\usepackage{subcaption}
%\usepackage{array} % Table

\usepackage{pifont}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{balance}

\pgfplotsset{compat=1.18} 

\newcommand{\xmark}{\ding{55}}%

\newcommand{\ie}{\textit{i.e., }}  % from the Latin id est = that is
\newcommand{\eg}{\textit{e.g., }}  % from the Latin exempli gratia = for example
\newcommand{\etal}{\textit{et al. }} % from the Latin et alii = among other
\newcommand{\cf}{\textit{cf. }} % from the Latin: confer/conferatur, meaning "compare"
\newcommand{\til}{\char`\~}


\def \1{\textit{(i)}}
\def \2{\textit{(ii)}}
\def \3{\textit{(iii)}}
\def \4{\textit{(iv)}}
\def \5{\textit{(v)}}

% ------------------------------------------------------------------------------
% Checks if the paper corresponds to a final version
\usepackage{etoolbox}
\usepackage{soul} 

\newtoggle{finalPaper}

% Sets the line color to red

\setstcolor{blue}

% Change \toggletrue <-> \togglefalse

%\togglefalse{finalPaper} % version with annotations
\toggletrue{finalPaper} % final version

\iftoggle{finalPaper} {
	\newcommand{\addtxt}[1]{#1}
	\newcommand{\change}[2]{#2}
	\newcommand{\rmvtxt}[1]{}}
{
	\newcommand{\addtxt}[1]{\textcolor{blue}{#1}}
	\newcommand{\change}[2]{\st{#1}\textcolor{blue}{#2}}
	\newcommand{\rmvtxt}[1]{\st{#1}}}

\newtoggle{removeItalic}
\togglefalse{removeItalic} % regular command
%\toggletrue{removeItalic} % renew
\iftoggle{removeItalic} {
    \renewcommand{\textit}[1]{#1}
}

% ------------------------------------------------------------------------------

\FrameSep5pt

\newcommand{\solution}{\textit{GreenDFL}}


\begin{document}
\let\WriteBookmarks\relax
\def\floatpagepagefraction{1}
\def\textpagefraction{.001}
\shorttitle{Assessing the Sustainability of Decentralized Federated Learning Systems}
\shortauthors{Feng et~al.}

\title[mode = title]{\textit{GreenDFL}: a Framework for Assessing the Sustainability of Decentralized Federated Learning Systems}

\author[1]{Chao Feng}[orcid=0000-0002-0672-1090]
\author[1,2]{Alberto {Huertas Celdrán}}[orcid=0000-0001-7125-1710]
\author[1]{Xi Cheng} []
\author[2]{Gérôme Bovet} [orcid=0000-0002-4534-3483]
\author[3]{Burkhard Stiller}[orcid=0000-0002-7461-7463]


\address[1]{Communication Systems Group CSG, Department of Informatics IfI, University of Zurich UZH, CH---8050 Zürich, Switzerland}

\address[2]{Department of Information and Communications Engineering, University of Murcia, 30100--Murcia, Spain}

\address[3]{Cyber-Defence Campus within armasuisse Science \& Technology, CH---3602 Thun, Switzerland}

\cortext[cor1]{Corresponding author.
Email address: cfeng@ifi.uzh.ch (C. Feng)}


\begin{keywords}
Federated Learning \sep Sustainability \sep Software Engineering  \sep Decentralized Machine Learning
\end{keywords}
% \date{\today}
\maketitle

\begin{abstract}
\paragraph{\textbf{Context:}} Decentralized Federated Learning (DFL) is an emerging paradigm that enables collaborative model training without centralized data and model aggregation, enhancing privacy and resilience. However, its sustainability remains underexplored, as energy consumption and carbon emissions vary across different system configurations. Understanding the environmental impact of DFL is crucial for optimizing its design and deployment.\\
\textbf{Objective:} This work aims to develop a comprehensive and operational framework for assessing the sustainability of DFL systems. To address it, this work provides a systematic method for quantifying energy consumption and carbon emissions, offering insights into improving the sustainability of DFL.\\
\textbf{Methods:} This work proposes \solution{}, a fully implementable framework that has been integrated into a real-world DFL platform. \solution{} systematically analyzes the impact of various factors, including hardware accelerators, model architecture, communication medium, data distribution, network topology, and federation size, on the sustainability of DFL systems. Besides, a sustainability-aware aggregation algorithm (\textit{GreenDFL-SA}) and a node selection algorithm (\textit{GreenDFL-SN}) are developed to optimize energy efficiency and reduce carbon emissions in DFL training.\\
\textbf{Results:} Empirical experiments are conducted on multiple datasets, measuring energy consumption and carbon emissions at different phases of the DFL lifecycle. Results indicate that local training dominates energy consumption and carbon emissions, while communication has a relatively minor impact. Optimizing model complexity, using GPUs instead of CPUs, and strategically selecting participating nodes significantly improve sustainability. Additionally, using wired communication, particularly optical fiber, effectively reduces energy consumption during the communication phase, while integrating early stopping mechanisms further minimizes overall emissions.\\ 
\textbf{Conclusion:} The proposed \solution{} provides a comprehensive and practical approach for assessing the sustainability of DFL systems. Furthermore, it offers best practices for improving environmental efficiency in DFL, making sustainability considerations more actionable in real-world deployments.
\end{abstract}

\section{Introduction}
\label{sec:intro}

% Machine Learning and Data

With the wide adoption of Artificial Intelligence (AI), especially the emergence of intelligent assistants based on Large Language Models (LLMs), Machine Learning (ML) has become deeply integrated into daily life~\cite{yao2024survey}. The \textit{neural scaling law} is no longer a prediction of real-world observations; it has come to be broadly recognized as a fundamental principle~\cite{kaplan2020scaling}. However, developing ever-larger ML models requires feeding them ever-increasing amounts of data. In the vanilla ML training process, data are typically centralized in a single entity or data center to facilitate training. This centralized approach, however, raises significant privacy concerns: users prefer not to expose their sensitive information~\cite{federatedlearning}. Meanwhile, legal and regulatory requirements increasingly restrict extensive data aggregation~\cite{beltran2023decentralized}. As a novel paradigm that mitigates these privacy challenges, Federated Learning (FL) has garnered substantial attention for its privacy-preserving capabilities and collaborative learning mechanisms~\cite{mcmahan2017fedavg}.

% FL and DFL
FL leverages a distributed training paradigm that distinguishes it from conventional ML training~\cite{federatedlearning}. In FL, data remain on local devices (clients), and each client trains a local model using its private data. These locally trained models are then sent to a central server for aggregation and subsequent redistribution. However, such a Centralized FL (CFL) architecture suffers from the drawbacks of a single point of failure and potential bottlenecks at the central server. To overcome these limitations, Decentralized FL (DFL) removes the central server, employing peer-to-peer communication such that models are directly exchanged among nodes for aggregation~\cite{beltran2023decentralized}. By eliminating the client-server distinction, DFL mitigates the single-point-of-failure risk and offers greater system robustness. In DFL, data remain on each node for local training; afterward, models are exchanged and aggregated among neighboring nodes, proceeding recursively until the federated model converges. This paradigm not only addresses the server bottleneck but also enables more flexible network topologies and improved scalability~\cite{feng2024dart}.


% Sustainable FL
As a specialized class of software systems, AI systems are increasingly becoming a critical topic in sustainability research~\cite{lacoste2019quantifyingcarbonemissionsmachine}. The scaling laws that drive larger models inherently imply massive computational demands. Supporting these large-scale computations consumes substantial amounts of energy and has significant environmental impacts, particularly greenhouse gas emissions~\cite{ding2024sustainable}. However, current studies on the sustainability of AI software systems have predominantly concentrated on energy consumption in traditional centralized ML paradigms, leaving a gap in rigorous frameworks for assessing and quantifying sustainability in distributed and especially fully decentralized FL systems~\cite{lynn2023}.

% Challenges
In DFL systems, nodes may be geographically distributed across different regions or even countries, necessitating an independent evaluation of each node's energy consumption and carbon emissions. Such complexity is not commonly encountered in centralized AI systems, where training occurs in a single data center. Moreover, in DFL, each node is responsible not only for local model training but also for model transmission and aggregation. Research on centralized ML typically focuses on the energy consumption and environmental impacts of model training alone, largely overlooking the substantial energy costs of communication and model aggregation. While studies have explored sustainability in CFL by measuring carbon emissions, research on DFL remains limited~\cite{lynn2023}. In particular, there is a lack of comprehensive solutions for systematically measuring sustainability aspects in DFL and integrating energy-efficient strategies into node selection and aggregation processes. Furthermore, heterogeneity presents additional hurdles in DFL. Nodes may vary regarding local data distributions, tasks, security requirements, model architectures, and hardware capabilities. This multi-layered heterogeneity makes it challenging to develop standardized methodologies for evaluating and reducing the environmental footprint of DFL systems, further highlighting the need for targeted research on sustainability-aware DFL frameworks.

% Contributions
To address the current research gap in assessing the sustainability of DFL systems, this paper proposes the \solution{} framework for quantitatively analyzing and evaluating DFL energy consumption and environmental impacts. The framework takes account of the entire lifecycle of the DFL model training process, encompassing local training,  communication, and model aggregation. The main contributions are as follows:
\begin{itemize}
    \item \textbf{Quantitative Sustainability Framework:} This paper proposes an operational framework, named \solution{}, for comprehensively computing energy consumption and equivalent CO$_2$ emissions in DFL systems, enabling a quantitative assessment of their sustainability and environmental impacts. A prototype of the proposed framework is implemented and integrated into an open-source DFL system, Nebula~\cite{2024nebular}, demonstrating its feasibility and effectiveness in real-world scenarios.
    \item \textbf{Sustainability-Aware Aggregation and Node Selection Algorithm:} A sustainability-aware aggregation algorithm (\textit{GreenDFL-SA}) is developed to optimize the environmental impact of the aggregation process, ensuring a more energy-efficient model update. Additionally, a node selection algorithm (\textit{GreenDFL-SN}) is introduced to determine participating nodes during each training round dynamically. This method utilizes a voting mechanism, allowing nodes to decide which participants continue training based on their reported sustainability metrics, thereby reducing overall energy consumption while maintaining model performance.
    \item \textbf{Empirical Analysis:} Through extensive experiments and case studies, the paper applies the proposed framework to identify and analyze factors affecting the sustainability of DFL, offering practical insights into energy consumption trade-offs and carbon footprint reduction strategies.    
    \item \textbf{Best Practices for Sustainable DFL:} This paper provides recommendations for enhancing the sustainability of DFL systems, including strategies for optimizing model training strategy and leveraging renewable energy sources.

\end{itemize}

The remainder of this paper is organized as follows. Section~\ref{sec:related} contains findings from the literature review on sustainability in FL. Section~\ref{sec:design} introduces the proposed \solution{} framework. Section~\ref{sec:implement} details its implementation. Section~\ref{sec:exp} presents the experimental results and analyzes key findings. Section~\ref{sec:discussion} discusses best practices for sustainable DFL. Finally, Section~\ref{sec:conclusion} summarizes the conclusions and outlines directions for future research.

\input{2related_work_table}

\section{Related Work}
\label{sec:related}
This section provides a review of the literature concerning the energy consumption and environmental impacts associated with CFL and DFL. \tablename~\ref{tab:related_work} summarizes the research findings on the environmental sustainability aspect of FL systems. 

Although the sustainability of traditional ML has already attracted attention in academia, research on the sustainability of FL remained relatively scant. \cite{patterson2022carbonfootprintmachinelearning} indicated that the geographic location of ML training servers, the composition of the energy grid, the duration of the training, and even the specific brand and hardware type significantly affected overall carbon emissions. Even though this work focused on ML, it inspired subsequent research on the sustainability of FL.

A pioneering effort in FL sustainability was presented in \cite{qiu2021federatedlearningsaveplanet}, which offered the first systematic investigation into the carbon footprint of centralized FL (CFL). This work introduced a model for quantifying the carbon footprint of CFL, thus enabling an in-depth examination of how different CFL design choices influenced carbon emissions. In addition, it compared CFL’s carbon footprint with that of centralized ML. Subsequent research generalized the carbon emissions calculation method across various CFL configurations and tested it on real CFL hardware setups, examining how different settings, model architectures, training strategies, and tasks affect sustainability \cite{qiu2023lookcarbonfootprintfederated}. Feng et al. \cite{lynn2023} expanded the trustworthiness framework for CFL by introducing sustainability as a new evaluation pillar, thereby addressing all seven key AI requirements outlined by the European Commission’s High-Level Expert Group on AI. In this expanded framework, sustainability was evaluated through qualitative metrics such as hardware efficiency, federation complexity, and the carbon intensity of local energy grids, offering insights into the environmental footprint of FL systems. However, this study employed a qualitative approach and did not provide a quantitative analysis of FL’s sustainability.

A further contribution introduced a novel framework for analyzing energy consumption and carbon emissions in ML, CFL, and DFL contexts \cite{energyDFL}. This work quantified both the energy consumption and the equivalent carbon emissions associated with classical FL approaches as well as consensus-based decentralized methods, pinpointing optimal thresholds and operational parameters that could make FL designs more environmentally friendly. This study proposed a general computational framework but did not differentiate between energy consumption and carbon emissions from training versus aggregation. Moreover, it assumed that each node's energy consumption was known, a condition that is often infeasible in practice.

In conclusion, existing research on FL sustainability primarily focused on CFL, with limited attention paid to DFL. Although DFL-focused works identified various factors affecting energy efficiency and carbon emissions, their proposed computational methods lacked practical operability. In addition, these studies often overlooked the renewable energy substitution rate in the nodes’ energy sources, relying instead on broad estimates of the local grid’s carbon intensity, which introduced inaccuracies. Moreover, existing work provided limited practical guidance for training real-world DFL systems, as it did not propose an algorithm that used sustainability metrics to optimize node selection in DFL.



\section{The \solution{} Framework}
\label{sec:design}
This section delves into the detailed methodologies of the \solution{} framework for calculating energy consumption and carbon emissions within DFL environments. 

The learning lifecycle of a DFL system can be divided into three iterative stages: model training, model transmission, and model aggregation, each characterized by distinct energy consumption patterns.

\begin{itemize}
    \item \textbf{Model Training}: This phase involves the local computation by DFL nodes, where models are trained on distributed nodes using local data. This is the most computationally intensive phase, often resulting in significant energy use and associated carbon emissions.

     \item \textbf{Communication}: Communication refers to exchanging local models among nodes in DFL systems. This stage involves sending the local model to other nodes and receiving models from them. Since the primary energy consumption arises from network transmission, the size of the model plays a critical role.

    \item \textbf{Model Aggregation}: When a node receives the desired models from other nodes, it uses an aggregation algorithm, commonly FedAvg, to aggregate its local model with the received models. This aggregation's computational load depends on the number of models being merged and the size of their parameters. Consequently, the scale and topology of the DFL system often play a critical role in determining energy consumption at this stage.
\end{itemize}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{images/GreenDFL_v2.pdf}
    \caption{Overall Architecture of the \solution{} Framework}
    \label{fig:arch}
\end{figure*}

In line with the DFL learning lifecycle, as shown in \figurename~\ref{fig:arch}, \solution{} divides the sustainability analysis of DFL systems into three phases: model training, communication, and model aggregation. Each phase is examined for its energy consumption and carbon emissions, offering a holistic view of the environmental impact of DFL systems. The following subsections decompose and explain each phase in \solution{} from energy consumption and carbon emissions perspectives, providing a practical computational framework.

\subsection{Calculation of Energy Consumption}
\label{sec:Calculation of Energy Consumption}

The energy consumption of \solution{} can be broken down into three components: model training, model communication, and model aggregation. For the training and aggregation stages, \solution{} adopts a quantifiable and implementable approach by primarily considering each node’s hardware architectures (\ie device models and different accelerators), hardware resource utilization, and computation time. For model communication, \solution{} focuses on the volume of data being sent and received, as well as the energy required to transfer one byte of data. Thus, the total energy consumption could be modeled as:
\begin{equation}
\label{eq:enenrgy_total}
E = E^{(T)} + E^{(C)} + E^{(A)}
\end{equation}
where $E^{(T)}, E^{(C)}, E^{(A)}$ are the energy consumption in the model training, communication, and aggregation, respectively. 

Before presenting the detailed energy consumption model, \tablename~\ref{tab:notations} summarizes the key notations used in the subsequent equations.

\begin{table}[h]
    \centering
    \caption{Table of Notations}
    \label{tab:notations}
    \begin{tabular}{@{} p{1cm}p{7cm} @{}}
        \toprule
        \textbf{Symbol} & \textbf{Definition} \\
        \midrule
        \( K \) & Number of nodes in the system \\
        \( n \) & Number of global learning rounds \\
        \( PUE_k \) & Power Usage Effectiveness of node \( k \), measuring power efficiency \\
        \( TDP_k \) & Thermal Design Power of node \( k \), indicating peak heat dissipation \\
        \( \beta_{k,t}^{(T)} \) & CPU utilization rate during training at node \( k \) in round \( t \) \\
        \( T_{k,t}^{(T)} \) & Duration of local training at node \( k \) in round \( t \)\\
        \( P_t^{(\text{GPU})} \) & Power consumption of GPU in round \( t \)\\
        \( \beta_{k,t}^{(A)} \) & CPU utilization rate during aggregation at node \( k \) in round \( t \) \\
        \( T_{k,t}^{(A)} \) & Duration of model aggregation at node \( k \) in round \( t \) \\
        \( B_{k,t}^{\text{sent}} \) & Total bytes sent by node \( k \) in round \( t \) \\
        \( B_{k,t}^{\text{recv}} \) & Total bytes received by node \( k \) in round \( t \) \\
        \( E_{\text{byte},k}^{(C)} \) & Energy consumption per byte transmitted at node \( k \)\\
        \bottomrule
    \end{tabular}
\end{table}


\subsubsection{Model Training Phase Energy Consumption}
The calculation of energy consumption for local model training in a node depends on the type of accelerator utilized, such as CPUs or GPUs. During the training process, nodes may employ only CPUs or a combination of CPUs and GPUs. The total energy consumption for local training is determined by summing the energy consumed by both components, with GPU energy consumption considered zero when GPUs are not in use. The energy consumption for CPU-based and GPU-based training is formulated in Equation \eqref{eq:energy_training}. 

\begin{equation}
\label{eq:energy_training}
\begin{aligned}
    E^{(T)} &= E_{\text{CPU}}^{(T)} + E_{\text{GPU}}^{(T)} \\
    E_{\text{CPU}}^{(T)} &= \sum_{k=1}^{K} \sum_{t=1}^{n} PUE_k \cdot TDP_k \cdot \beta_{k,t}^{(T)} \cdot T_{k,t}^{(T)} \\
    E_{\text{GPU}}^{(T)} &= \sum_{k=1}^{K} \sum_{t=1}^{n} P_t^{(\text{GPU})} \cdot T_{k,t}^{(T)}
\end{aligned}
\end{equation}


Equation~\ref{eq:energy_training} quantifies the total CPU energy consumption during local training. The calculation considers the power usage effectiveness (\( PUE_k \)), the thermal design power (\( TDP_k \)), CPU utilization rate (\( \beta_{k,t}^{(T)} \)), and the training duration (\( T_{k,t}^{(T)} \)). Besides, it calculates the total GPU energy consumption across all nodes and rounds, considering the training time (\( T_{k,t}^{(T)} \)) and GPU power consumption (\( P_t^{(\text{GPU})} \)).


\subsubsection{Communication Phase Energy Consumption}
In DFL systems, energy consumption is not limited to computation but also arises from communication. During model updates, nodes exchange data, contributing to overall energy consumption. The energy consumption for communication is formulated as in Equation \eqref{eq:communication_energy}:

\begin{equation}
\label{eq:communication_energy}
E^{(C)} = \sum_{k=1}^{K} \sum_{t=1}^{n} \left[ \left(B_{k,t}^{\text{sent}} + B_{k,t}^{\text{recv}}\right) \cdot E_{\text{byte},k}^{(C)} \right]
\end{equation}

Equation \eqref{eq:communication_energy} accounts for both sent (\( B_{k,t}^{\text{sent}} \)) and received (\( B_{k,t}^{\text{recv}} \)) data at each node during each training round. The energy per byte transferred (\( E_{\text{byte}}^{(C)} \)) is multiplied by the total data exchanged.

\subsubsection{Model Aggregation Phase Energy Consumption}
The energy consumption during the aggregation phase is computed as follows:  

\begin{equation}
\label{eq:aggregation_energy}
\begin{aligned}
    E^{(A)} &= E_{\text{CPU}}^{(A)} + E_{\text{GPU}}^{(A)} \\
    E_{\text{CPU}}^{(A)} &= \sum_{k=1}^{K} \sum_{t=1}^{n} PUE_k \cdot TDP_k \cdot \beta_{k,t}^{(A)} \cdot T_{k,t}^{(A)} \\
    E_{\text{GPU}}^{(A)} &= \sum_{k=1}^{K} \sum_{t=1}^{n} P_t^{(\text{GPU})} \cdot T_{k,t}^{(A)}
\end{aligned}
\end{equation}

Equation~\ref{eq:aggregation_energy} follows a similar methodology to the energy consumption calculation during training, incorporating both CPU and GPU energy consumption depending on the type of accelerator utilized.


By integrating these three aspects, \solution{} offers a comprehensive and operational framework for evaluating the sustainability of DFL systems.

\subsection{Calculation of Carbon Emissions}
After computing the energy consumption of the DFL system, the next step is to estimate its carbon emissions. This process consists of two key steps. Firstly, the carbon intensity (\( CI \)) of the energy used by each node must be identified, as it varies depending on the regional energy grid carbon intensity and the proportion of renewable energy utilized. Secondly, the total carbon emissions of the DFL system are obtained by multiplying the energy consumption of each node by its corresponding carbon intensity. The total carbon emissions of the DFL system are computed as follows:

\begin{equation}
\label{eq:carbon_emission}
C = \sum_{k=1}^{K} CI_k \cdot E_k
\end{equation}

where \( C \) represents the total carbon emissions (g CO$_2$) of the DFL system, \( CI_k \) denotes the carbon intensity (g CO$_2$/kWh) at node \( k \), and \( E_k \) represents the total energy consumption (kWh) of node \( k \). This equation provides a comprehensive assessment of the carbon footprint of a DFL system by aggregating emissions across all nodes.

Before presenting the carbon intensity and emissions calculations, Table~\ref{tab:cab_notations} summarizes the key notations used in the following equations.

\begin{table}[h]
    \centering
    \caption{Table of Notations}
    \label{tab:cab_notations}
    \begin{tabular}{@{} p{1.3cm}p{6.7cm} @{}}
        \toprule
        \textbf{Symbol} & \textbf{Definition} \\
        \midrule
        \( CI_k \) & Carbon intensity (g CO$_2$/kWh) at node \( k \) \\
        \( CI_{k, \text{local}} \) & Local carbon intensity (g CO$_2$/kWh) at node \( k \) \\
        \( CI_{k, \text{renewable}} \) & Carbon intensity for renewable energy, approximated as zero \\
        \( R_k \) & Renewable energy ratio at node \( k \) \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Carbon Intensity}


Calculating carbon intensity is crucial because it quantifies the CO$_2$ emissions produced per unit of energy consumed. Carbon intensity varies according to the geographic location of the nodes, as different regions may depend on various energy sources with distinct carbon footprints. The energy grid used by a node can be determined by its location, typically defined by the latitude and longitude, aligning with the energy mix of the country where the node operates.

Besides, carbon intensity also depends on the renewable energy ratio of the nodes' local places. An increasing number of data centers and even households are integrating self-generated renewable energy as an alternative to the traditional power grid. Considering this factor allows for a more accurate assessment of carbon emissions. The higher the renewable energy ratio, the lower the carbon intensity of the region. The carbon intensity at a given node is computed as follows:

\begin{equation}
\label{eq:CI}
CI_k = CI_{k, \text{local}} \cdot (1 - R_k)
\end{equation}

\begin{equation}
\label{eq:CI_renewable}
CI_{k, \text{renewable}} \approx 0
\end{equation}


Equation~\ref{eq:CI} adjusts the local carbon intensity (\( CI_{k, \text{local}} \)) by the proportion of energy derived from the local grid (\( 1 - R_k \)). A higher renewable energy ratio (\( R_k \)) results in lower carbon intensity. Equation~\ref{eq:CI_renewable} approximates the carbon intensity of fully renewable energy sources as zero, reflecting the minimal carbon footprint of sustainable energy usage.


\subsubsection{Carbon Emissions}
With the energy consumption and carbon intensity established, the total carbon emissions at each node are determined using the following equations. These equations integrate energy consumption for training, aggregation, and communication with the specific carbon intensity at each node.

\begin{equation}
\label{eq:carbon_emissions}
\begin{split}
C &= \sum_{k=1}^{K} CI_k \cdot E_k \\
  &= \sum_{k=1}^{K} CI_k \cdot E_k^{(T)} + E_k^{(C)} + E_k^{(A)}\\
  &= \sum_{k=1}^{K} \sum_{t=1}^{n} CI_k \cdot [PUE_k \cdot TDP_k \cdot (\beta_{k,t}^{(T)} \cdot T_{k,t}^{(T)} + \beta_{k,t}^{(A)} \cdot T_{k,t}^{(A)}) \\
  & + P_t^{(\text{GPU})} \cdot (T_{k,t}^{(T)} +  T_{k,t}^{(A)} ) + (B_{k,t}^{\text{sent}} + B_{k,t}^{\text{recv}}) \cdot E_{\text{byte},k}^{(C)}]
\end{split}
\end{equation}

As shown in Equation ~\ref{eq:carbon_emissions}, by incorporating carbon intensity and energy consumption, \solution{} provides a comprehensive assessment of the carbon emissions of DFL systems, offering insights for optimizing energy efficiency and reducing environmental impact.

\subsection{Sustainability-Aware Aggregation (\textit{SA})}
To optimize the environmental impact of the aggregation process in DFL, this paper proposes a sustainability-aware aggregation algorithm, \textit{GreenDFL-SA}, as shown in Algorithm~\ref{alg:carbon_aware_aggregation}.

\begin{algorithm}[b]
\caption{\textit{GreenDFL-SA} Algorithm}
\label{alg:carbon_aware_aggregation}
    \begin{algorithmic}[1]
        \Require Total nodes \( K \), Current node \( i \), Neighbor set \( \mathcal{N}_i \), Carbon threshold \( C_{\text{thresh}} \)
        \State \textbf{Initialize} selected neighbor set \( S_i \gets \emptyset \)
        \State \textbf{Broadcast} local model \( M_i^{(t)} \) and carbon emission \( C_i^{(t)} \) to neighbors \( \mathcal{N}_i \)
        \State \textbf{Receive} models \( \{M_j^{(t)}\}_{j \in \mathcal{N}_i} \) and emissions \( \{C_j^{(t)}\}_{j \in \mathcal{N}_i} \)
        \For{each neighbor \( j \in \mathcal{N}_i \)}
            \If{ \( C_j^{(t)} \leq C_{\text{thresh}} \) } 
                \State \( S_i \gets S_i \cup \{ j \} \) \Comment{Select neighbor \( j \) for aggregation}
            \EndIf
        \EndFor
        \State \textbf{Compute aggregated model:}
        \begin{equation}
            M_i^{(t+1)} = \sum_{j \in S_i} w_j M_j^{(t)}
        \end{equation}
        \State \textbf{Update} local model \( M_i^{(t+1)} \)
    \end{algorithmic}
\end{algorithm}

In a DFL system, nodes exchange model updates and carbon emission values with their neighboring nodes. Algorithm~\ref{alg:carbon_aware_aggregation} allows each node to dynamically select a subset of its neighbors for model aggregation based on their carbon emissions. By filtering out high-emission nodes, the system promotes sustainable collaboration, effectively reducing the overall carbon footprint of model training.

At the start of each training round, each node broadcasts its local model and carbon emissions to its neighbors and receives the same information. The node then evaluates its neighbors' emissions against a predefined threshold, selecting only those with emissions below the threshold for inclusion in the aggregation process. All decisions are made locally by each node without centralized coordination. Nodes that are not selected for aggregation still proceed with the next round of training. Therefore, this algorithm impacts only the sustainability of the aggregation phase. The selected neighbors’ models are then weighted and aggregated to update the local model. This adaptive selection strategy ensures that nodes with lower environmental impact have a greater influence on the global model, fostering a more energy-efficient and sustainable DFL process.

\subsection{Sustainability-Aware Node Selection (\textit{SN})}
The \textit{GreenDFL-SA} optimizes energy consumption during the aggregation phase. However, the training phase is the most computationally intensive stage in the DFL learning lifecycle, making it a critical target for energy optimization. To address this, this work proposes the Sustainability-Aware Node Selection Algorithm, called \textit{GreenDFL-SN}, shown in Algorithm~\ref{alg:sustainability_node_selection}, which aims to reduce energy consumption during local training by selectively enabling only the most sustainable nodes to participate in each training round.

\begin{algorithm}
    \caption{\textit{GreenDFL-SN} Algorithm}[b]
    \label{alg:sustainability_node_selection}
    \begin{algorithmic}[1]
        \Require Number of nodes \( K \), Carbon Intensity (CI) reports from all nodes, Voting threshold \( V_{\text{thresh}} \)
        \Ensure Set of selected nodes for next training round \( S \)
        
        \State \textbf{Initialize} selected node set \( S \gets \emptyset \)
        \State Each node \( i \)  \textbf{broadcasts} its carbon intensity \( CI_i \) to its neighboring nodes \( \mathcal{N}_i \)
        \State Each node \( i \) \textbf{votes} for \( V_i \) nodes to continue training, based on received CI reports
        \State Collect all votes and compute total votes for each node \( v_i \)
        
        \For{each node \( i \in \{1, 2, ..., K\} \)}
            \If{ \( v_i \geq V_{\text{thresh}} \) }
                \State \( S \gets S \cup \{ i \} \) \Comment{Node \( i \) is selected for the next round}
            \EndIf
        \EndFor
        
        \State \Return \( S \)
    \end{algorithmic}
\end{algorithm}

The \textit{GreenDFL-SN} algorithm for DFL ensures that nodes with higher carbon efficiency are prioritized after each training round for continued participation. At the end of a training round, each node reports its Carbon Intensity, representing the environmental impact of its energy consumption. Based on these reports, all nodes vote for a subset of participants that should continue in the next training round. This voting process allows the system to dynamically filter out high-carbon nodes, reducing the overall carbon footprint of the DFL system while maintaining training progress. By iteratively selecting nodes based on sustainability metrics, the algorithm helps improve DFL's energy efficiency and environmental sustainability, ensuring that model training proceeds with minimal ecological impact.

\section{Framework Implementation}
\label{sec:implement}
\solution{} provides a comprehensive and operational framework for assessing the environmental sustainability of DFL systems. This section details its implementation and integration into the Nebula DFL platform, including parameters acquisition and metrics computation.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{images/GreenDFL_implementation.pdf}
    \caption{Integration of \solution{} Framework to the \textit{Nebula} Platform}
    \label{fig:nebula_architecture}
\end{figure*}

\subsection{\textit{Nebula} Platform}
\textit{Nebula}~\cite{fedstellar:2024} was chosen as the infrastructure for integrating \solution{} due to its flexibility and advanced functionality in deploying DFL systems. \textit{Nebula} is a versatile FL platform that supports multiple FL paradigms, allowing users to deploy various types of FL models, including CFL, semi-DFL, and DFL. Additionally, \textit{Nebula} offers multiple datasets and diverse model architectures for FL training. It enables users to customize the connectivity topology among nodes, enhancing its adaptability to different research and deployment needs. \textit{Nebula} consists of three components:  Frontend, Controller, and Core. Each component plays a distinct role in facilitating FL model deployment, configuration, and execution, enabling seamless integration with \solution{}.

\begin{itemize}
    \item \textbf{Frontend}: Provides a user-friendly interface for configuring and deploying FL models. Users can specify various configurations such as FL architecture (CFL or DFL), dataset selection, data partitioning strategies, model architectures, communication topology, hardware accelerators, and aggregation algorithms. Besides, the frontend provides monitoring and visualization of the FL process. Users can track the real-time status of FL model training directly through the frontend interface, including CPU utilization and model performance.
    \item \textbf{Controller}: The controller acts as a middleware, translating user-configured scenarios into bootstrap configurations for individual nodes. It ensures that each node is correctly initialized with the designated configurations.
    \item \textbf{Core}: It is a fundamental component of the \textit{Nebula} platform, deployed into physical or virtualized devices by the controller. This component handles the execution of model training, communication, and aggregation based on the bootstrap configurations. It is responsible for orchestrating FL workflows across participating nodes.
\end{itemize}
\figurename~\ref{fig:nebula_architecture} provides an overview of the three core modules of \textit{Nebula} and illustrates how \solution{} is implemented and integrated within these modules.

\subsection{Implementation in the Frontend}
The frontend of \textit{Nebula} is built using the Flask framework~\cite{flask}, providing a web-based interface for configuring various FL parameters, including the DFL architecture, dataset selection, and training options. These configurations are transmitted to the controller via REST API, where they serve as initialization parameters for node bootstrapping.

To accommodate sustainability computations, the frontend implementation of \solution{} introduces the following additional configurations:
\begin{itemize}
 \item Communication Mode Selection: Users can specify whether wired or wireless transmission is used. Additionally, the system allows users to define the energy consumption per byte transferred, corresponding to parameter \( E_{\text{byte},k}^{(C)} \)  in the Equations~\eqref{eq:communication_energy}.
 \item Local Renewable Energy Utilization: Users can input the proportion of energy sourced from self-produced renewable energy. This factor influences the carbon intensity calculation, corresponding to parameters (\( CI_{k, \text{local}} \)) and (\( CI_{k, \text{renewable}} \))
in Equations~\eqref{eq:CI} and~\eqref{eq:CI_renewable}.
\end{itemize}
Users only need to provide these three parameters. All other required parameters for \solution{} are automatically retrieved from the backend or determined at runtime.

The federation status and model performance are also visualized through the frontend. By integrating TensorBoard~\cite{tensorboard}, users can monitor the real-time execution of FL, including device utilization, as well as the training, validation, and testing performance of the model. Correspondingly, \solution{} utilizes REST API to receive sustainability metrics from the backend, including the energy consumption and carbon emissions associated with training, communication, and aggregation at each node. These metrics are dynamically updated and displayed in real-time on the frontend.

\subsection{Implementation in the Controller}
The controller acts as a middleware component, bridging the frontend configurations with the FL nodes by converting user-defined parameters into structured initialization settings. It ensures that the FL system is correctly configured before execution. 

In the integration of \solution{}, the controller is responsible for handling sustainability-related parameters and incorporating them into the FL workflow. When the frontend transmits configurations via REST API, including communication mode and renewable energy utilization, the controller processes these inputs and encodes them into predefined JSON fields. These newly formatted fields are then injected into the node configuration files, ensuring that each node is bootstrapped with sustainability-aware parameters. This allows \solution{} to track and compute energy consumption and carbon emissions.

\subsection{Implementation in the Core}
The core module is responsible for executing of the DFL training process, including model training, aggregation, and communication. Thus, it plays a crucial role in computing the energy consumption and carbon emissions across the three phases of \solution{}.

\subsubsection{Energy Consumption and Carbon Emissions in the Training and Aggregation Phases}
To compute the energy consumption during training as described in Equation~\ref{eq:energy_training}, several key parameters must be automatically retrieved during the training process, including Power Usage Effectiveness (\( PUE_k \)), Thermal Design Power (\( TDP_k \)), GPU power consumption (\( P_t^{(\text{GPU})} \)), CPU utilization (\( \beta_{k,t}^{(T)} \)), and training duration (\( T_{k,t}^{(T)} \)).

The CPU model of each node must first be identified to obtain the \( TDP_k \) parameter. In this work, the Python platform library~\cite{python_platform} is utilized to retrieve the CPU model of each node automatically. The CPU model is then matched in a precompiled database~\cite{tdp} to obtain the corresponding \( TDP_k \) value. To measure CPU utilization related to model training, the psutil library~\cite{psutil} is employed to retrieve both CPU usage (\( \beta_{k,t}^{(T)} \)) and Power Usage Effectiveness (\( PUE_k \)). If a model is trained using a GPU accelerator, the pynvml library~\cite{pynvml} is used to monitor GPU power consumption in real time. Additionally, the training duration (\( T_{k,t}^{(T)} \)) is recorded for each node, tracking the time interval from the start to the completion of local model training in each round of local training.  

Based on these parameters, \solution{} calculates the energy consumption for each node in each training round. Using Equation~\ref{eq:carbon_emissions}, the corresponding carbon emissions per training round are determined. 

The energy consumption calculation for the aggregation phase follows a similar methodology to that of the training phase. The only difference lies in the time duration used, instead of the training duration, the aggregation energy consumption is computed based on the aggregation duration (\( T_{k,t}^{(A)} \)).

The energy consumption per round is accumulated over all training rounds to compute the total energy consumption for local training and aggregation at each node. The overall carbon emissions from local training and aggregation in the federated system are then derived by aggregating the energy consumption metrics across all nodes. 

\subsubsection{Energy Consumption and Carbon Emissions in the Communication Phase}
As shown in Equation~\ref{eq:communication_energy}, the energy consumption during the communication phase primarily depends on the amount of data sent and received by each node in every aggregation round, as well as the energy consumption per byte transmitted.

To obtain these values, the psutil library is used to retrieve the data transmission metrics of each node during each round $(B_{k,t}^{\text{sent}}$ and $B_{k,t}^{\text{recv}})$. By summing them, the total data volume per round is obtained. The total energy consumption for communication at each node is then computed by multiplying the total data volume by the energy consumption per byte (\( E_{\text{byte},k}^{(C)} \)). 

Energy consumption in data transmission varies significantly depending on the transmission medium, with wired, optical, and wireless methods exhibiting different efficiency. Optical transmission is the most energy-efficient, followed by electrical wired networks, while wireless transmission (e.g., WiFi, mobile networks) is the most energy-intensive. 

The energy required to transmit one byte of data is summarized in Table~\ref{tab:energy_per_byte}. These values highlight the significant disparity in energy efficiency across transmission technologies. The information provided by the frontend for \( E_{\text{byte},k}^{(C)} \) is derived from the data presented in Table~\ref{tab:energy_per_byte}.

\begin{table}[h]
    \centering
    \caption{Energy Consumption per Byte for Different Transmission Methods}
    \label{tab:energy_per_byte}
    \begin{tabular}{l c}
        \toprule
        \textbf{Transmission Medium} & \textbf{Energy (J/byte)} \\
        \midrule
        Wired (Electrical Signal)~\cite{hu2009semiconductor} & \( 8 \times 10^{-11} \) \\
        Optical Transmission ~\cite{tucker2011green} & \( 3.52 \times 10^{-14} \)  \\
        Mobile Network (4G/5G)~\cite{traficom2021} & \( 3.33 \times 10^{-8} \)  \\
        WiFi Transmission~\cite{wifi} & \( 5.51 \times 10^{-4} \)  \\
        \bottomrule
    \end{tabular}
\end{table}

The carbon emissions resulting from communication are calculated using Equation~\ref{eq:carbon_emissions}. Similarly, by aggregating the results across all participating nodes, the overall communication-related energy consumption and carbon emissions of the federated system can be obtained. 

All energy consumption and carbon emissions data are transmitted via REST API to TensorBoard, which continuously monitors sustainability metrics throughout the DFL process.

\section{Experimental Evaluation}
\label{sec:exp}
This study employs an experimental approach utilizing the \solution{} framework to evaluate the sustainability of DFL systems systematically. The experiments are designed to address the following Experimental Research Questions (ERQs):  
\begin{enumerate}
    \item \textit{\textbf{ERQ1}}: Which phase of the DFL lifecycle contributes the most to environmental impact?
    This experimental research question aims to determine whether training, communication, or aggregation is the primary contributor to energy consumption and carbon emissions. Identifying the most resource-intensive phase can help prioritize optimization efforts to improve the overall sustainability of DFL.  
   \item \textit{\textbf{ERQ2}}: What factors influence the sustainability of DFL?
    This experimental research question investigates the impact of various parameters, such as network topology, data distribution, model architecture, and energy carbon intensity, on the sustainability of DFL.
   \item \textit{\textbf{ERQ3}}: Can the proposed sustainability-aware algorithm improve the environmental efficiency of DFL?
    This experimental research question evaluates whether the sustainability-aware aggregation strategy enhances the environmental efficiency of DFL by reducing energy consumption and carbon emissions compared to the traditional aggregation approach. The goal is to assess the effectiveness of sustainability-aware optimizations in mitigating the environmental impact of DFL.
\end{enumerate}

Based on these research questions, this study designs various experimental settings to systematically assess the impact of different DFL configurations and sustainability-aware optimizations.

\subsection{Experiments Setup}
This section describes the experimental setup used to evaluate the sustainability of DFL under different configurations. The experiments systematically analyze various factors, including datasets, model architectures, communication mediums, geographical distribution, network topology, and aggregation algorithms. Table~\ref{tab:experiment_summary} summarizes the key experimental parameters.

\begin{table}[h]
    \centering
    \caption{Summary of Experimental Setup}
    \label{tab:experiment_summary}
    \begin{tabular}{@{} p{3.5cm}p{4.5cm}@{}}
        \toprule
        \textbf{Category} & \textbf{Experimental Configurations} \\
        \midrule
        \textbf{Datasets} & MNIST, EMNIST, FashionMNIST, CIFAR10 \\
        \textbf{Models} & MLP, ResNet-9, MobileNetV3 \\
        \textbf{Communication Mediums} & Electrical Signal, Optical Fiber, Mobile Network \\
        \textbf{Geographical Distribution} & Switzerland, Spain \\
        \textbf{Number of Nodes} & 5, 10, 15, 20 \\
        \textbf{Hardware Accelerators} & CPU, GPU \\
        \textbf{Data Distribution} & IID, Non-IID (Dirichlet $\alpha=0.1$) \\
        \textbf{Network Topologies} & Fully Connected, ER ($p=0.5$), Ring \\
        \textbf{Aggregation Algorithms} & FedAvg, Krum, \textbf{\textit{GreenDFL-SA}}, \textbf{\textit{GreenDFL-SN}} \\
        \bottomrule
    \end{tabular}
\end{table}

\paragraph{\textbf{Datasets and Models}}
The experiments utilize MNIST, EMNIST, FashionMNIST, and CIFAR-10, representing different task complexities and dataset sizes.
\begin{itemize}
    \item \textbf{MNIST}~\cite{lecun1998mnist} dataset is a widely used benchmark for handwritten digit classification in FL and CV)research. It consists of 10 classes, where each sample is a 28×28 grayscale image. The dataset contains 60,000 training samples and 10,000 test samples.  For this task, two different neural network architectures are employed: a three-layer MLP with 256-128-10 hidden units (with \(2.35 \times 10^{5}\) trainable parameters), and a ResNet-9 model (with \(1.6 \times 10^{6}\) trainable parameters)~\cite{he2016resnet}.
    
    \item \textbf{EMNIST}~\cite{cohen2017emnist} dataset is an extension of MNIST, incorporating both digits and handwritten English letters. This work used the "bymerge" configuration for the dataset, which consists of 47 classes. Like MNIST, each sample is a 28×28 grayscale image, but the EMNIST dataset is significantly larger, containing 731,668 training samples and 82,587 test samples. The model architectures used for EMNIST are similar to those employed for MNIST, with modifications to the output layer to accommodate the 47-class classification task.  

    \item \textbf{FashionMNIST}~\cite{xiao2017fashionmnist} dataset a 10-class classification task involving grayscale images of fashion items. It serves as a more challenging alternative to MNIST. The dataset structure is similar to MNIST, with each sample being a 28×28 grayscale image. It includes 60,000 training samples and 10,000 test samples. For this task, the same MLP and ResNet-9 architectures are applied.

    \item \textbf{CIFAR10}~\cite{krizhevsky2009cifar10} dataset is a 10-class classification task involving objects such as animals and vehicles. It presents a higher level of complexity compared to MNIST and FashionMNIST, as each sample is a 32×32 RGB image with three color channels. The dataset consists of 50,000 training samples and 10,000 test samples. To handle the increased complexity, two different convolutional neural network (CNN) architectures are used: MobileNetV3 (with \(1.36 \times 10^{5}\) trainable parameters)~\cite{howard2019searchingmobilenetv3} and ResNet-9  (with \(1.6 \times 10^{6}\) trainable parameters). 
    
This dataset and model selection allows the evaluation of model complexity and dataset difficulty on energy consumption and sustainability in DFL systems.     
\end{itemize}

\paragraph{\textbf{Communication Mediums}}
The choice of communication medium influences the energy consumption of DFL communication, thereby affecting the overall sustainability of the DFL system. To evaluate this impact, the experiments compare the energy consumption and carbon emissions of three different transmission mediums: Electrical Signal (Wired Ethernet), Optical Fiber, and Mobile Network (4G).

\paragraph{\textbf{Geographical Distribution}}
The carbon intensity of electricity grids varies significantly across different regions, influencing the carbon emissions of DFL systems. To analyze this effect, the experiment compares DFL deployments in two regions with different carbon intensities: 
\begin{itemize} 
\item \textbf{Spain}: Represents a moderate-carbon-intensity region, with an electricity grid carbon intensity of 217.422 grams of CO$_2$ equivalents per kilowatt-hour (gCO$_2$e/kWh).  
\item \textbf{Switzerland}: Represents a low-carbon-intensity region, with an electricity grid carbon intensity of 41.279 gCO$_2$e/kWh.  
\end{itemize}

By comparing the carbon emissions of DFL nodes in these two regions, this study aims to quantify the impact of geographical distribution on the sustainability of DFL.

\paragraph{\textbf{Federation Size}}
Experiments are conducted with 5, 10, 15, and 20 nodes to assess the effect of federation size on energy consumption and the scalability of the proposed aggregation algorithm.

\paragraph{\textbf{Hardware Accelerators}}
Training is performed on CPU-based computing and GPU-accelerated computing to compare energy efficiency. The experiments are conducted on a device equipped with an AMD EPYC 7702 64-core Processor with a TDP of 200W and an NVIDIA T4 GPU with a TDP of 70W. Each node is virtualized using Docker containers to ensure reproducibility and efficient resource allocation.

\paragraph{\textbf{Data Distribution}}
The distribution of training data across nodes significantly affects the performance of DFL models~\cite{feng2025fedeptailoringattentionheterogeneous}. However, its impact on sustainability, particularly in terms of energy consumption and carbon emissions, remains largely unexplored.

To investigate this relationship, the experiment adopts two different data partitioning strategies:

\begin{itemize}
    \item \textbf{IID (Independent and Identically Distributed)}: Each node receives an evenly distributed subset of the dataset, ensuring uniform data representation across all nodes.
    \item \textbf{Non-IID (Dirichlet Sampling, $\alpha = 0.1$)}: Data is sampled using a Dirichlet distribution with $\alpha = 0.1$, leading to highly skewed and heterogeneous data distributions among nodes.
\end{itemize}

By comparing these two data partitioning methods, this study aims to assess how data heterogeneity influences the sustainability of DFL.

\begin{table*}[h]
    \centering
    \caption{Carbon Emissions (gCO$_2$e/kWh) and Energy Consumption (kWh) Across Different Datasets}
    \label{tab:energy_carbon}
    \renewcommand{\arraystretch}{1}
    \setlength{\tabcolsep}{4pt}
    \begin{tabular}{lcccccccc}
        \toprule
        \textbf{Dataset} & \textbf{Train CE} & \textbf{Train EC} & \textbf{Agg. CE} & \textbf{Agg. EC} & \textbf{Comm. CE} & \textbf{Comm. EC} & \textbf{Total CE} & \textbf{Total EC} \\
        & (gCO$_2$e/kWh) & (kWh) & (gCO$_2$e/kWh) & (kWh) & (gCO$_2$e/kWh) & (kWh) & (gCO$_2$e/kWh) & (kWh) \\
        \midrule
        CIFAR10       & 4.047  & 0.019  & 0.534  & 0.002  & \(1.02 \times 10^{-5}\) & \(4.69 \times 10^{-8}\)  & 4.581  & 0.021 \\
        EMNIST        & 6.047  & 0.028  & 0.432  & 0.002  & \(1.74 \times 10^{-5}\) & \(8.02 \times 10^{-8}\)  & 6.479  & 0.030 \\
        FashionMNIST  & 1.300  & 0.006  & 0.413  & 0.002  & \(1.72 \times 10^{-5}\) & \(7.89 \times 10^{-8}\)  & 1.714  & 0.008 \\
        MNIST         & 1.256  & 0.006  & 0.416  & 0.002  & \(1.70 \times 10^{-5}\) & \(7.83 \times 10^{-8}\)  & 1.672  & 0.008 \\
        \bottomrule
    \end{tabular}
    
    \vspace{5pt}
    \small
    \textbf{Abbreviations:} CE: Carbon Emissions, EC: Energy Consumption, Agg.: Aggregation, Comm.: Communication.
\end{table*}


\paragraph{\textbf{Network Topology}}
Network topology defines the communication between nodes in a DFL system and influences the aggregation of models. Different levels of connectivity affect the efficiency of model updates and the overall energy consumption of the system. To analyze its impact on sustainability, the following network topologies are considered:

\begin{itemize}
    \item Fully Connected (Dense): Each node is connected to all others, providing the highest level of communication redundancy and synchronization.
    \item Erdős-Rényi (ER) Random Graph (\( p = 0.5 \)): A probabilistic model where each link exists with probability \( p = 0.5 \), representing a moderately dense network.
    \item Ring Topology (Sparse): Nodes are arranged in a circular manner, with each node connected only to its immediate neighbors.
\end{itemize}

These topologies range from dense to sparse and are used to examine their effects on energy consumption, communication overhead, and overall sustainability in a DFL system.

\paragraph{\textbf{Aggregation}}
Aggregation algorithms influence the energy consumption of the model aggregation process in DFL. To evaluate this impact, three different aggregation strategies are studied:

\begin{itemize}
    \item FedAvg~\cite{mcmahan2017fedavg}: A widely used federated averaging algorithm that computes the weighted average of local models.
    \item Krum~\cite{blanchard2017krum}: A Byzantine-robust aggregation algorithm that selects a single model update closest to the majority of other updates.
    \item \textit{GreenDFL-SA}: An algorithm designed to optimize sustainability by considering energy efficiency during aggregation.
    \item \textit{GreenDFL-SN}: An algorithm optimizes sustainability by considering energy efficiency during the local training phase.
\end{itemize}

All experiments are conducted using 20 aggregation rounds, with each round consisting of 3 local epochs.

\subsection{Analysis of Environmental Impact Across DFL Lifecycle Phases}

The first experiment investigates which phase in the DFL learning lifecycle contributes the most to environmental sustainability impact. This experiment is conducted on four datasets using a fully connected DFL system with 10 nodes. Communication is performed using Electrical Signal, training is executed on GPU, and FedAvg is employed for aggregation. All federation nodes are located in Spain, where data distribution follows an IID pattern across nodes.

Table~\ref{tab:energy_carbon} presents the total energy consumption and carbon emissions across all nodes for each of the three phases in the DFL lifecycle. The results indicate that the DFL training on the EMNIST dataset consumed the most energy. The differences in energy consumption and carbon emissions across datasets primarily stem from variations in DFL training time. The total learning duration for each dataset is as follows: CIFAR10 takes 14 minutes 46.598 seconds, EMNIST requires 21 minutes 41.565 seconds, FashionMNIST completes in 6 minutes 5.294 seconds, and MNIST finishes in 5 minutes 42.212 seconds. Among these, EMNIST has the longest training time due to its larger dataset size. Although CIFAR10 is the most complex dataset, its smaller data volume results in the second-longest training time. FashionMNIST and MNIST have similar dataset sizes and complexity, leading to nearly identical training durations.

Compared to communication and aggregation, the training phase exhibits the highest energy consumption and carbon emissions. The average local training time for one round on MNIST and FashionMNIST requires approximately 5 seconds per round, whereas EMNIST takes 20 seconds, and CIFAR10 takes 15 seconds per round. In contrast, the aggregation phase takes less than one second for all datasets. Since the computational overhead of training significantly exceeds that of aggregation, the training phase dominates overall energy consumption and carbon emissions.

Although a substantial portion of DFL runtime is spent in the model transmission phase, this stage involves minimal computational overhead, resulting in negligible energy consumption compared to training. Consequently, the training phase remains the most energy-intensive stage, contributing the most to overall carbon emissions.

Overall, these findings provide a clear answer to \textbf{\textit{ERQ1}}. Across multiple datasets, the training phase is identified as the primary contributor to carbon emissions. Consequently, optimizing the sustainability of the training process should be prioritized in DFL system design. Additionally, energy consumption and emissions from aggregation and communication should not be overlooked. 

% todo add analysis of time in each phases

\subsection{Factors Influencing the Sustainability of DFL Systems}

This experiment analyzes various factors that influence the sustainability of DFL systems, including model architecture, communication medium, geographical distribution of nodes, hardware accelerators, data distribution across nodes, network topology, and federation size.

\subsubsection{Communication Medium}
This experiment evaluates the impact of different communication media on DFL's energy consumption and carbon emissions. The study compares three transmission methods:  Electrical Signal, Optical Fiber, and  Mobile Network. 
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/comm_res.pdf}
    \caption{Carbon Emissions (gCO$_2$e/kWh) and Energy Consumption (kWh) During the Communication Phase With Various Communication Medium Across Different Datasets (Log-scaled)}
    \label{fig:energy_carbon_comm}
\end{figure}

The communication medium mainly affects energy consumption during the communication phase of the DFL system. Figure~\ref{fig:energy_carbon_comm} illustrates the energy consumption and carbon emissions during the communication phase across four datasets using three different communication mediums.

The results indicate that optical fiber, which has the lowest per-byte energy consumption, results in the lowest transmission energy consumption and carbon emissions under the same setup. In contrast, mobile communication exhibits the highest per-byte energy consumption, leading to the highest transmission energy consumption and emissions. However, even when using mobile communication, the total carbon emissions from the communication phase over 20 rounds remain relatively low, contributing only approximately 0.01 gCO$_2$e across all four datasets.

\subsubsection{Geographical Distribution}
The geographic distribution of nodes affects the carbon intensity of the electricity grid they utilize, thereby influencing the overall carbon emissions of the DFL system. This experiment compares the energy consumption and carbon emissions of DFL systems deployed in Spain and Switzerland, as illustrated in Figure~\ref{fig:energy_carbon_location}. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/loc_res.pdf}
    \caption{Total Carbon Emissions (gCO$_2$e/kWh) and Energy Consumption (kWh) of DFL Systems in Spain and Switzerland}
    \label{fig:energy_carbon_location}
\end{figure}

Under the same configuration, the geographic distribution of nodes does not impact energy consumption; however, it significantly affects carbon emissions. Since the carbon intensity of Switzerland's electricity grid (41.279 gCO$_2$e/kWh) is only about one-fourth of that in Spain (217.422 gCO$_2$e/kWh), the total carbon emissions of the DFL system in Switzerland are also approximately one-fourth of those in Spain. These results suggest that optimizing the geographic distribution of nodes can effectively reduce the environmental impact of DFL systems.

\subsubsection{Hardware Accelerator}
The choice of hardware accelerator significantly affects the sustainability of a DFL system by influencing computational efficiency during local training and aggregation. Due to their superior performance in tensor computations, GPUs can significantly reduce training time compared to CPUs. Additionally, GPUs offer better power management, resulting in lower overall energy consumption. Figure~\ref{fig:hardware_energy} compares the energy consumption and carbon emissions of DFL systems using CPUs and GPUs as accelerators.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/acc_res.pdf}
    \caption{Total Carbon Emissions (gCO$_2$e/kWh) and Energy Consumption (kWh) of DFL Systems with Using GPU and CPU Accelerators}
    \label{fig:hardware_energy}
\end{figure}

For the EMNIST, FashionMNIST, and MNIST datasets, training with the MLP model exhibits similar learning durations on both CPU and GPU, resulting in similar energy consumption. However, for the CIFAR10 dataset, training on the CPU takes nearly 80 minutes while operating at full capacity. Consequently, its energy consumption is approximately ten times that of GPU-based training, leading to a nearly tenfold increase in equivalent CO$_2$ emissions.

The results show that DFL systems utilizing GPU accelerators achieve better energy efficiency and lower carbon emissions under the same configuration. In contrast, CPU-only systems require longer training times, leading to higher energy consumption and carbon emissions.

\subsubsection{Model Architecture}
More complex models often yield better performance but require higher computational resources. This experiment evaluates the effect of simple models (MLP for MNIST, FashionMNIST, and EMNIST; MobileNet for CIFAR10) versus a more complex model (ResNet-9) on the sustainability of DFL systems. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/model_res.pdf}
    \caption{Total Carbon Emissions (gCO$_2$e/kWh), Energy Consumption (kWh) and Test F1 Score of DFL Systems with Different Model Architectures}
    \label{fig:model_performance}
\end{figure}


Figure~\ref{fig:model_performance} compares different model architectures' carbon emissions, energy consumption, and F1 score. The results indicate that while ResNet-9 improves the F1 score in all datasets, it also leads to higher carbon emissions. This is due to its significantly larger parameter count (\(1.6 \times 10^6\)), approximately seven times that of MLP and MobileNet models. Consequently, ResNet-9 has a higher computational density and requires longer training time, resulting in increased energy consumption and carbon emissions.

\subsubsection{Network Topology}
Network topology determines how models are transmitted between nodes and how many models are aggregated, influencing energy consumption and carbon emissions during the transmission and aggregation phases. To assess this impact, the experiment evaluates three topologies: fully connected, ER (\( p = 0.5 \)), and ring topology. Figure~\ref{fig:topology_impact} shows the energy consumption and carbon emissions in the communication and aggregation phases across four datasets.
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/topo_res.pdf}
    \caption{Total Carbon Emissions (gCO$_2$e/kWh) and Energy Consumption (kWh) of DFL Systems with Different Network Topologies}
    \label{fig:topology_impact}
\end{figure}
The results indicate that under different network topologies, the energy consumption and carbon emissions during the aggregation phase remain similar. This suggests that although sparse topologies, such as the ring topology, require fewer models to be processed during aggregation, the computational time for aggregation is relatively short, and the overall computational overhead remains low. Consequently, energy consumption during aggregation does not show significant differences between sparse and dense networks.

However, the communication phase exhibits notable differences. The total number of model transmissions in a DFL system per round is theoretically twice the number of edges in the network. In a fully connected network with \( N \) nodes, the total number of edges is \( {N(N-1)}/{2} \), meaning that in each round, the system transmits \( N(N-1) \) model updates. In an ER random graph with \( p = 0.5 \), the expected number of edges is \( {N(N-1)}/{4} \), resulting in \( {N(N-1)}/{2} \) model transmissions per round. In contrast, a ring topology has exactly \( N \) edges, leading to only \( 2N \) model transmissions per round.

In the 10-node DFL system used in this experiment, a fully connected topology required 90 model transmissions per round, while the ER topology required 45, and the ring topology only 20. Experimental results confirm this theoretical analysis. Using CIFAR10 as an example, over 20 training rounds, the fully connected topology consumed \( 4.69439 \times 10^{-8} \) kWh in communication, while the ER topology consumed \( 2.29197 \times 10^{-8} \) kWh, approximately half of the fully connected network’s consumption. The ring topology exhibited the lowest energy consumption, around \( 1.02738 \times 10^{-8} \) kWh, aligning with theoretical expectations.


\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/data_res.pdf}
    \caption{Total Carbon Emissions (gCO$_2$e/kWh), Energy Consumption (kWh) and Test F1 Score of DFL Systems with Different Data Distribution}
    \label{fig:data_distribution}
\end{figure}

\subsubsection{Data Distribution}
Figure~\ref{fig:data_distribution} presents the carbon emissions and energy consumption under IID and non-IID \( \alpha = 0.1 \) distributions. Under non-IID conditions, the overall energy consumption and carbon emissions of the system remain similar to those observed under IID settings when using the same model and aggregation algorithm. This suggests that data distribution has a minimal impact on the environmental sustainability of DFL.

\subsubsection{Federation Size}
This experiment evaluates the differences in energy consumption and carbon emissions when the number of participating nodes is varied between 5, 10, 15, and 20.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/node_res.pdf}
    \caption{Total Carbon Emissions (gCO$_2$e/kWh) and Energy Consumption (kWh) of DFL Systems with Different Federation Sizes}
    \label{fig:federation_size}
\end{figure}

As the number of nodes in the federation increases, the energy consumption and carbon emissions per node remain similar. However, the total energy consumption of the system increases proportionally with the number of participating nodes. A larger number of nodes in training leads to higher overall energy consumption and carbon emissions.


In conclusion, factors such as geographical distribution, hardware accelerators, model architecture, and federation size significantly impact DFL sustainability. While communication medium and network topology influence carbon emissions during the transmission phase, their overall impact on the sustainability of the DFL system is relatively small. However, data distribution has minimal effect on the system’s sustainability. These insights provide an answer to \textit{\textbf{ERQ2}}.

\subsection{Analysis of \textit{GreenDFL-SA} and \textit{GreenDFL-SN}}

This experiment evaluates the proposed \textit{GreenDFL-SA} and \textit{GreenDFL-SN} algorithms in comparison with FedAvg and Krum. This experiment was conducted on a 10-node DFL system with IID data partitioning and a fully connected network topology.  The evaluation focuses on three key aspects: energy consumption, carbon emissions, and model performance (Test F1 Score).

Table~\ref{tab:sustainability_comparison} compares the sustainability metrics and model performance across four training algorithms. The results indicate that the test F1 scores of all four algorithms are similar, demonstrating that the proposed \textit{GreenDFL-SA} and \textit{GreenDFL-SN} methods do not compromise model performance.

\begin{table*}[h]
    \centering
    \caption{Comparison of Sustainability Metrics and Model Performance Across Aggregation Algorithms}
    \label{tab:sustainability_comparison}
    \resizebox{\textwidth}{!}{%
    \renewcommand{\arraystretch}{1}
    \setlength{\tabcolsep}{4pt}
    \begin{tabular}{l l c c c c c c c c c}
        \toprule
        \textbf{Dataset} & \textbf{Alg.} & \textbf{Train. CE} & \textbf{Train. EC} & \textbf{Agg. CE} & \textbf{Agg. EC} & \textbf{Comm. CE} & \textbf{Comm. EC} & \textbf{Total CE} & \textbf{Total EC} & \textbf{F1 Score} \\
        & & (gCO$_2$) & (kWh) & (gCO$_2$) & (kWh) & (gCO$_2$) & (kWh) & (gCO$_2$) & (kWh) & \\
        \midrule
        \multirow{4}{*}{CIFAR10} 
        & FedAvg  & 4.047  & 0.019  & 0.534  & 0.002  & 1.021 $\times 10^{-5}$  & 4.694 $\times 10^{-8}$  & 4.581  & 0.021  & \textbf{0.822} \\
        & Krum    & 4.016  & 0.018  & 1.283  & 0.006  & 1.019 $\times 10^{-5}$  & 4.688 $\times 10^{-8}$  & 5.299  & 0.024  & 0.785 \\
        & \textbf{\textit{GreenDFL-SA}}      & 4.068  & 0.019  & \textbf{0.497}  & \textbf{0.002}  & 1.022 $\times 10^{-5}$  & 4.702 $\times 10^{-8}$  & 4.565  & 0.021  & 0.817 \\
        & \textbf{\textit{GreenDFL-SN}}      & \textbf{2.761}  & \textbf{0.013}  & 0.674  & 0.003  & \textbf{1.017 $\times 10^{-5}$}  & \textbf{4.675 $\times 10^{-8}$}  & \textbf{3.435}  & \textbf{0.016}  & 0.785 \\
        \midrule
        \multirow{4}{*}{EMNIST} 
        & FedAvg  & 6.047  & 0.028  & 0.432  & 0.002  & 1.743 $\times 10^{-5}$  & 8.017 $\times 10^{-8}$  & 6.479  & 0.030  & \textbf{0.726} \\
        & Krum    & 6.069  & 0.028  & 0.807  & 0.004  & 1.740 $\times 10^{-5}$  & 8.003 $\times 10^{-8}$  & 6.876  & 0.032  & 0.622 \\
        & \textbf{\textit{GreenDFL-SA}}      & 6.090  & 0.028  & 0.410  & 0.002  & 1.738 $\times 10^{-5}$  & 7.994 $\times 10^{-8}$  & 6.500  & 0.030  & 0.718 \\
        & \textbf{\textit{GreenDFL-SN}}      & \textbf{5.612}  & \textbf{0.026}  & 0.448  & 0.002  & \textbf{1.737 $\times 10^{-5}$}  & \textbf{7.991 $\times 10^{-8}$}  & \textbf{6.060}  & \textbf{0.028}  & 0.713 \\
        \midrule
        \multirow{4}{*}{FashionMNIST} 
        & FedAvg  & 1.300  & 0.006  & 0.413  & 0.002  & 1.715 $\times 10^{-5}$  & 7.890 $\times 10^{-8}$  & 1.714  & 0.008  & \textbf{0.884} \\
        & Krum    & 1.324  & 0.006  & 0.895  & 0.004  & 1.698 $\times 10^{-5}$  & 7.808 $\times 10^{-8}$  & 2.219  & 0.010  & 0.851 \\
        & \textbf{\textit{GreenDFL-SA}}      & 1.304  & 0.006  & \textbf{0.397}  & \textbf{0.002}  & \textbf{1.692 $\times 10^{-5}$}  & \textbf{7.781 $\times 10^{-8}$}  & 1.701  & 0.008  & 0.881 \\
        & \textbf{\textit{GreenDFL-SN}}      & \textbf{1.155}  & \textbf{0.005}  & 0.467  & 0.002  & 1.700 $\times 10^{-5}$  & 7.817 $\times 10^{-8}$  & \textbf{1.623}  & \textbf{0.007}  & 0.873 \\
        \midrule
        \multirow{4}{*}{MNIST} 
        & FedAvg  & 1.256  & 0.006  & 0.416  & 0.002  & 1.702 $\times 10^{-5}$  & 7.830 $\times 10^{-8}$  & 1.672  & 0.008  & \textbf{0.978} \\
        & Krum    & 1.227  & 0.006  & 0.820  & 0.004  & 1.698 $\times 10^{-5}$  & 7.811 $\times 10^{-8}$  & 2.047  & 0.009  & 0.961 \\
        & \textbf{\textit{GreenDFL-SA}}      & 1.269  & 0.006  & \textbf{0.392}  & \textbf{0.002}  & 1.698 $\times 10^{-5}$  & 7.810 $\times 10^{-8}$  & 1.661  & 0.008  & 0.976 \\
        & \textbf{\textit{GreenDFL-SN}}      & \textbf{1.056}  & \textbf{0.005}  & 0.422  & 0.002  & \textbf{1.697 $\times 10^{-5}$}  & \textbf{7.806 $\times 10^{-8}$}  & \textbf{1.478}  & \textbf{0.007}  & 0.971 \\
        \bottomrule
    \end{tabular}}
    \small
    \textbf{Abbreviations:} CE: Carbon Emissions, EC: Energy Consumption, Agg.: Aggregation, Comm.: Communication
\end{table*}


Regarding sustainability metrics, FedAvg, Krum, and the \textit{GreenDFL-SA} exhibit comparable energy consumption and carbon emissions. This similarity arises because these three methods differ mainly in the aggregation phase, which contributes relatively little to the system’s overall energy consumption. Consequently, variations in aggregation complexity do not significantly impact total energy usage. However, at the aggregation phase level, Krum exhibits higher energy consumption due to its increased computational complexity compared to FedAvg. In contrast, the \textit{GreenDFL-SA} reduces energy consumption during aggregation, contributing to improved sustainability. Notably, the \textit{GreenDFL-SN} algorithm excludes the most energy-intensive nodes from training, achieving the best overall energy efficiency.

In summary, the proposed sustainability-aware aggregation and \textit{GreenDFL-SN} algorithms effectively reduce energy consumption and carbon emissions at different stages of the DFL lifecycle, thereby enhancing the environmental sustainability of DFL systems. These findings provide a positive answer to \textit{\textbf{ERQ3}}, demonstrating the potential for sustainability-aware optimization in decentralized learning.

\section{Discussion}
\label{sec:discussion}
This work constructs an environmental sustainability assessment framework for DFL systems and employs empirical research to identify key influencing factors. The experiments also demonstrate that optimizing aggregation and node selection strategies can enhance the environmental sustainability of DFL. This section presents best practices for improving the sustainability of DFL systems.

\subsection{Balancing Model Performance and Sustainability}
Achieving a balance between model performance and sustainability is challenging. Optimizing model architecture by selecting a model with a sufficient yet minimal number of parameters appears to be a reasonable approach. However, determining the optimal model size before deployment is complex, and such optimization often becomes a post-training consideration.

The proposed \textit{GreenDFL-SN} algorithm offers an in-training strategy to effectively reduce DFL carbon emissions. However, its effectiveness relies on all nodes' accurate and timely reporting of sustainability metrics. In decentralized environments, this information may not always be reliable, limiting the applicability of the approach to scenarios where all nodes are honest. Another straightforward strategy to reduce DFL energy consumption and carbon emissions is adopting the early stopping mechanism.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/val_f1.pdf}
    \caption{Validation F1 Score Across Different Datasets}
    \label{fig:early_stopping}
\end{figure}


Typically, DFL systems follow a predetermined number of training rounds, regardless of whether the model has already converged. The early stopping strategy allows nodes to monitor their validation metrics, such as loss or accuracy, over multiple rounds and terminate training when the improvement falls within a predefined threshold. Figure~\ref{fig:early_stopping} illustrates a DFL system's validation loss and sustainability metrics on the MNIST dataset across training rounds. The results indicate that although the model converges by round 5, training continues for the predetermined 20 rounds. If early stopping were applied at round 7, energy consumption could be reduced by approximately 60\%. Therefore, automated convergence detection mechanisms, such as early stopping, can significantly improve DFL systems' energy efficiency and environmental sustainability.

\subsection{Utilization of Renewable Energy}
In the conducted experiments, it was assumed that all nodes exclusively relied on grid electricity. However, many data centers and households are generating their own renewable energy as an alternative power source. As shown in Figure~\ref{fig:renewable_energy}, when nodes utilized 50\% locally generated renewable energy, the system's total carbon emissions were reduced by approximately 50\%. Investing in and adopting local clean energy sources reduces electricity costs and enhances environmental sustainability.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{images/renew.pdf}
    \caption{Total Carbon Emissions (gCO$_2$e/kWh) and Energy Consumption (kWh) of DFL Systems with Different Local Renewable Energy Ratio}
    \label{fig:renewable_energy}
\end{figure}

\section{Conclusion}
\label{sec:conclusion}
This work presents a comprehensive framework, called \solution{}, for assessing the environmental sustainability of DFL systems. Through empirical analysis, it investigates the impact of key factors such as model architecture, hardware accelerators, communication medium, data distribution, network topology, and federation size on sustainability. The results demonstrate that local training is the primary contributor to energy consumption and carbon emissions, while communication overhead remains relatively minor. The experiments further show that optimizing aggregation and node selection strategies can effectively reduce the carbon footprint of DFL without significantly compromising model performance. Additionally, findings indicate that deploying models in regions with lower carbon intensity, leveraging early stopping mechanisms, and utilizing renewable energy sources can enhance the sustainability of DFL systems.

Despite these contributions, this study has certain limitations that provide avenues for future research. The proposed \textit{GreenDFL-SN} algorithm assumes that all nodes honestly report their energy consumption and carbon intensity, which may not always hold in real-world decentralized settings. Further research is needed to design incentive mechanisms or verification strategies to ensure reliable reporting. Additionally, this study estimates energy consumption based on hardware specifications and utilization metrics; incorporating real-time energy profiling can enhance accuracy. Future work can explore adaptive model selection strategies that dynamically adjust model complexity based on resource constraints and sustainability requirements. Moreover, integrating renewable energy-aware scheduling mechanisms and incentive models to encourage sustainable participation in DFL could further improve its environmental impact.

\section*{Declaration of Competing Interest}
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. 

\section*{CRediT authorship contribution statement}

\textbf{Chao Feng.} Methodology, Conceptualization, Writing - Review \& Editing.
\textbf{Alberto Huertas Celdrán.} Methodology, Writing - Review. 
\textbf{Xi Cheng.} Data curation, Analysis.
\textbf{Gérôme Bovet.} Project administration, Funding acquisition.
\textbf{Burkhard Stiller.} Supervision, Funding acquisition.

\balance
\section*{Acknowledgment}

This work has been partially supported by \textit{(a)} the Swiss Federal Office for Defense Procurement (armasuisse) with the CyberMind project (CYD-C-2020003) and \textit{(b)} the University of Zürich UZH.


%
% ---- Bibliography ----
%

\bibliographystyle{cas-model2-names}
\bibliography{main}

\end{document}
