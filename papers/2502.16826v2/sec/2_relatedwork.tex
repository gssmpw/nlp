\section{Related Work}
\label{sec:related work}
% In this section, we review the existing literature on point cloud denoising and unsupervised image denoising.
%-------------------------------------------------------------------------
\subsection{Point cloud denoising}

    \subsubsection{Traditional methods}
Traditional approaches to point cloud denoising include statistical methods \cite{computingpointset2003,definingpointset2004,wlop2009HH}, filtering techniques\cite{pointsetsurfaces2001,Robustmoving2005, zaman2017density}, and optimization-based methods \cite{l1sparse2010,clop2014PR,digne2017bilateral,multi-projection2018duan,hu2020featuregraph} . These techniques often rely on handcrafted features and heuristics to distinguish signal from noise. For example, statistical methods may use distribution models to identify and remove outliers. Filtering methods, such as mean or median filters, operate under the assumption that noise is statistically different from the signal. Optimization-based methods formulate denoising as an energy minimization problem, where regularization terms constrain the solution to ensure certain smoothness cirterion or adherence to prior knowledge.

%-------------------------------------------------------------------------
    \subsubsection{Supervised learning based methods}
In recent years, several deep learning-based methods \cite{rakotosaona2020PCN,hermosilla2019TotalDenoising,luo2020DMR,luo_score-based_2021} have been proposed for point cloud denoising. NPD \cite{NPD2019} is the first learning-based point cloud denoising method that directly processes noisy data without requiring noise characteristics or neighboring point definitions. This approach combines local and global information by projecting noisy points onto estimated reference planes, effectively removing noise and enhancing robustness against variations in noise intensity and curvature. PointCleanNet\cite{rakotosaona2020PCN} first removes outlier points and then combines them with residual connectivity to predict the inverse displacement \cite{Guerrero2017PCPNetLL}, and iteratively shifts noisy points to remove noise. Pistilli \etal proposed GPDNet \cite{gpdnet2020}, which is a graph convolutional network to improve denoising robustness at high noise levels. Luo \etal also proposed  DMRDenoise \cite{luo2020DMR}, which filter
points by first downsampling the noisy inputs and reconstructing the local subsurface to perform point upsampling. However, this resampling method is difficult to maintain a good local shape. ScoreDenoise \cite{luo_score-based_2021} is proposed to tackle the aforementioned issues by iteratively updating the point position in implicit gradient fields learned by neural networks. For inference, they follows an iterative procedure with a decaying step size, which stabilizes point movement and prevents over-correction, allowing points to converge gradually toward the underlying geometry. The authors of \cite{de_Silva_Edirimuni_2023_CVPR} proposed IterativePFN - an iterative method that use a novel loss function that utilizes an adaptive ground truth target at each iteration to capture the relationship between intermediate filtering results during training. Zheng \etal proposed a end-to-end network for joint normal filtering-based point cloud denoising \cite{10173632}. They introduce an auxiliary normal filtering task to enhance the network's ability to remove noise while preserving geometric features more accurately.

Supervised methods can achieve impressive results, but are limited by the availability and quality of the training data, as they typically require paired noisy and clean point clouds to train the neural network. The absence of clean data in real-world scenario pose a significant challenge on applicability of these algorithms.

%-------------------------------------------------------------------------
    \subsubsection{Unsupervised learning methods}
Unsupervised learning-based methods for point cloud denoising do not require ground-truth clean data. Instead, these methods leverage the inherent structure or distribution of the point cloud to guide the denoising process. Unsupervised methods show promise in scenarios where clean data is absent or hard to obtain.

Hermosilla \etal first introduced Total Denoising (TotalDn) \cite{hermosilla2019TotalDenoising} as an unsupervised learning approach for point cloud denoising, relying solely on noisy data without requiring clean ground truth. TotalDn approximates the underlying surfaces by regressing points from the distribution of unstructured total noise, utilizing a spatial prior term to refine the estimation of geometry. 

In DMRDenoise \cite{luo2020DMR}, an unsupervised version is proposed which utilizes a loss function that identify local neighborhoods using a probabilistic Gaussian mask on the k-nearest neighbors, which selectively retains points likely to represent the underlying surface. By leveraging an Earth Mover's Distance (EMD) assignment, it achieves a one-to-one correspondence between input and predicted points, aligning them to reduce noise within local neighborhoods.
This approach enhances robustness to noise and adapts well to varied surface geometries. However, the probabilistic masking and EMD calculation add computational complexity, which can slow down inference in dense or noisy point clouds. 

ScoreDenoise \cite{luo_score-based_2021} also introduced an unsupervised version that employs ensemble score function and an adaptive neighborhood-covering loss for model training.  
Score-u is probably the most relevant work to our method. However, the defined score in \cite{luo_score-based_2021} is only an displacement-alike version of the score function and there is no explicit formula relating the estimated score to the final denoising result. Also, the iterative process is computationally expensive, and can suffer from fluctuation, leading to perturbed and unstable solution.

Most recently, Noise4Denoise \cite{noise4Wang2024} method is proposed that use an additional doubly-noisy point cloud to learn noise displacement by comparing the two noise levels. This approach effectively leverages synthetic noise for training, allowing the model to estimate residuals without relying on clean data.
However, in practical applications, noise parameters are often unknown and variable, making it challenging to replicate the exact conditions assumed during training. This reliance on predefined noise characteristics can limit the model's applicability to real-world scenarios where noise distributions may differ significantly from synthetic settings. 
%-------------------------------------------------------------------------
\subsection{Unsupervised image denoising}
Recently unsupervised image denoising has made significant progress. Non-Bayesian methods include PURE \cite{luisier2010image}, SURE \cite{SURE2018} \textit{etc.}, which are based on various unbiased risk estimator under certain noise distribution. Other methods explore self-similarity in natural images \cite{xu2015patch, doi:10.1137/23M1614456} or exploits the statistical properties of noise to achieve denoising effect \cite{gravel2004method}.  

Noise2Noise \cite{2018Noise2NoiseLI} is a pioneering method that does not require clean data, but it requires multiple noisy versions of the same image for training. To address this limitation, methods such as Noise2Void \cite{2018Noise2VoidL}, Noise2Self \cite{2019Noise2SelfBD}, \textit{etc.}, have been developed, which use only a single noisy image. These methods are particularly important for practical applications where obtaining clean images or multiple noisy realizations of the same image is difficult or impossible. Neighbor2Neighbor \cite{huang2021neighbor2neighbor} proposed a two-step method with a a random neighbor sub-sampler that generates training  pairs and a denosing network. Kim \etal proposed Noise2Score\cite{kim_noise2score_2021}, a novel Bayesian framework for self-supervised image denoising without clean data. The core of Noise2Score is the usage of Tweedie's formula, which provides an explicit representation of the denoised image through a score function. Combined with score function estimation, Noise2Score can be applied to image denoising with any exponential family noise. Kim \etal also proposed the Noise Distribution Adaptive Self-Supervised Image Denoising method \cite{kim_noise_2022}, which further extends the application of Noise2Score by combining the Tweedie distribution with score matching. This enables adaptive handling of various noise distributions and dynamically adjusts the denoising process by estimating noise parameters. On the other hand, Xie \etal \cite{scoreXie2024} broadened the denoising scope of Noise2Score by allowing it to handle complex noise models, such as multiplicative and structurally correlated noise, demonstrating broad applicability to diverse noise models.

These development of unsupervised image denoising method motivate us to explore similar ideas in 3D point cloud denoising.



