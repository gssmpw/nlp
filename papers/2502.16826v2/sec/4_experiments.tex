\section{Experiments}

\begin{figure*}
\begin{center}
    \includegraphics[width=1.0\textwidth]{figures/qualitative.pdf}
\end{center}
\vspace{-0.05in}
\caption{Visual comparison of denoising results for different algorithms on synthetic datasets: (a) ModelNet-40, (b) PU-Net with 10k points, (c) PU-Net with 50k points, (d) ModelNet-40 with simulated LiDAR noise. Points with yellower coloring are farther from the ground truth surface.}
\label{fig:visualization}
\end{figure*}


%-------------------------------------------------------------------------
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[tb]
\begin{center}
\resizebox{\textwidth}{!}{
\begin{tabular}{cc|cccccc|cccccc}
\hline
\multicolumn{2}{c|}{Number of points}                     & \multicolumn{6}{c|}{10k}                                                     & \multicolumn{6}{c}{50k}                                                     \\
\multicolumn{2}{c|}{Noise level}                 & \multicolumn{2}{c}{1\%} & \multicolumn{2}{c}{2\%} & \multicolumn{2}{c|}{3\%} & \multicolumn{2}{c}{1\%} & \multicolumn{2}{c}{2\%} & \multicolumn{2}{c}{3\%} \\ \cline{3-14} 
\multicolumn{1}{c|}{Dataset}    & Model & CD & P2M   & CD  & P2M     & CD  & P2M   & CD & P2M   & CD& P2M        & CD         & P2M        \\ \hline
\multicolumn{1}{c|}{\multirow{5}{*}{PU-Net}} & TotalDn\cite{hermosilla2019TotalDenoising} & 3.390      & \underline{0.826}      & 7.251      & 3.485      & 13.385      & 8.740      & 1.024      & 0.314      & 2.722      & 1.567      & 7.474      & 5.729      \\
\multicolumn{1}{c|}{}                    & DMR\cite{luo2020DMR}   & 4.482      & 1.722      & 4.982      & 2.115      & \underline{5.892}       & \underline{2.846}     & 1.162      & 0.469      & \underline{1.566}      & \underline{0.800}      & \underline{2.432}      & 1.528      \\
\multicolumn{1}{c|}{}                    & DMR-u\cite{luo2020DMR}   & 5.313      & 2.522      & 6.455      & 3.317      & 8.134       & 4.647      & 1.226      & 0.521      & 2.138      & 1.251      & 2.496      & \underline{1.520}      \\
\multicolumn{1}{c|}{}                    & Score-u\cite{luo_score-based_2021} & \underline{3.107}      & 0.888      & \underline{4.675}      & \underline{1.829}      & 7.225       & 3.762      &\bf0.918      & \bf0.265      & 2.439      & 1.411      & 5.303      & 3.841      \\ \cline{2-14} 
\multicolumn{1}{c|}{}    & \bf Ours  & \bf2.806           & \bf0.661           & \bf3.868          & \bf1.173           & \bf5.192            & \bf2.228           & \underline{0.991}           & \underline{0.317}           & \bf1.438           & \bf0.623          & \bf2.418           & \bf1.389           \\ \hline
\end{tabular}}
\end{center}
\caption{Comparison with state-of-the-art denoising algorithms on PU-Net. The values for CD and P2M are multiplied by $10^4$. The best and second-best results are shown in \textbf{bold} and \underline{underlined}.}
\label{table:quantitativepu}
\end{table*}
%-------------------------------------------------------------------------

%-------------------------------------------------------------------------
\begin{table}
    \begin{center}
    \vspace{-0.05in}
\begin{tabular}{cc|ccc}
\hline
\multicolumn{2}{c|}{Type of noise}         &  \multicolumn{3}{c}{Simulated}  \\
\multicolumn{2}{c|}{Noise level} & \multicolumn{1}{c}{0.5\%} & \multicolumn{1}{c}{1.0\%} & \multicolumn{1}{c}{1.5\%} \\ \hline
\multicolumn{1}{c|}{Dataset}   & Model  & CD  & CD  & CD   \\ \hline
\multicolumn{1}{c|}{\multirow{5}{*}{Modelnet-40}} 
& TotalDn\cite{hermosilla2019TotalDenoising}   & 1.706     & 2.071  & 2.734        \\
\multicolumn{1}{c|}{}  & DMR \cite{luo2020DMR}  & 1.642 & 1.770  & 1.835     \\
\multicolumn{1}{c|}{}  & DMR-u\cite{luo2020DMR}  & 2.248  & 2.278  & 2.467   \\
\multicolumn{1}{c|}{}  & Score-u\cite{luo_score-based_2021} & \underline{1.469}   & \underline{1.426}    & \underline{1.652}    \\ \cline{2-5} 
\multicolumn{1}{c|}{}  & \bf Ours  &  \bf1.114   & \bf1.165   & \bf1.327  \\ \hline
\end{tabular}
\end{center}
\caption{Comparison of different denoising algorithms on ModelNet-40 with simulated LiDAR scanner noise.  The values for CD and P2M are multiplied by $10^4$. The best and second-best results are shown in \textbf{bold} and \underline{underlined}.}
\label{table:quantitativemd2}
\end{table}
%-------------------------------------------------------------------------

\begin{figure*}
\begin{center}
    \includegraphics[width=1.0\textwidth]{figures/rue32.pdf}
\end{center}
\vspace{-0.05in}
\caption{Visualization of denoising result of different algorithms on the real-world dataset \textit{Paris-rue-Madame} \cite{serna2014paris}. }
\label{fig:rue32}
\end{figure*}

%-------------------------------------------------------------------------

% \begin{figure*}
% \begin{center}
%     \includegraphics[width=1.0\textwidth]{figures/rue3.pdf}
% \end{center}
% \vspace{-0.05in}
% \caption{Visualization of our denoiser  vs. other algorithms on the real-world dataset \textit{Paris-rue-Madame} \cite{serna2014paris}}
% \label{fig:rue3}
% \end{figure*}

%-------------------------------------------------------------------------

%-------------------------------------------------------------------------
\subsection{Setup}
\label{sec:experiment:setup}

\textbf{Datasets}\quad
We use ModelNet-40 dataset\cite{wu2015modelnet} for model training, which is a widely used dataset in computer vision, with a comprehensive collection of 3D CAD models for common objects. For fair comparison, we adopt the same noisy subset of ModelNet-40 dataset provided by \cite{hermosilla2019TotalDenoising}, which consists 15 different classes with 7 different polygonal models for each class (5 for training and 2 for testing).  Specifically, 10K to 50K points are sampled from the surface grid using Poisson disk sampling with resolutions, which are then perturbed \emph{only by Gaussian noise} with a standard deviation of 0.5\%{} to 1.5\%{} of the radius of the bounding sphere and normalized to the unit sphere before being input to the model. Note that we do not use any clean point clouds of the dataset as in \cite{hermosilla2019TotalDenoising} to demonstrate the unsupervised nature of our method. 

For quantitative evaluation, we employ two benchmarks: the ModelNet-40 test set \cite{wu2015modelnet}, which includes 60 objects as adopted in \cite{luo2020DMR}, and the PU-Net test set \cite{yu2018PUNet}, consisting of 20 objects as adopted in \cite{luo_score-based_2021}. Similarly, we use Poisson disk sampling to sample point cloud from each shape, at resolution levels of 10K and 50K points. The performance of the model is then evaluated using data with added Gaussian noise or simulated LiDAR scanning noise model. We also evaluate the model using a real-world point cloud dataset \textit{Paris-rue-Madame}  \cite{serna2014paris}, which was obtained with a laser scanner from street scenes. 

\noindent\textbf{Model Training}\quad 
During training, we proceed as follows:
First we perturb the noisy data to generate the training point clouds. Specifically, for each point $Y_i$ in the noisy point cloud, we generate a perturbed point $Y'_i$ by adding small Gaussian noise $\epsilon_i \sim \mathcal{N}(0, \sigma'^2 I)$, in which $\epsilon_i$ is constantly changing. We carried out our experiments on an NVIDIA RTX 3080ti GPU with 12 GB memory. We trained the network for 200 epochs with Adam optimiser \cite{kingma2014adam}. The learning rate was set to 0.0002 and weight decay was set to 0.0001. During training, we anneal $\sigma_t$ linearly from $\sigma_{\text{max}}$ to $\sigma_{\text{min}}$ over time, which as we found is important for training the model to adapt to different noise level and accurately estimate the score function. Once the network has been trained to estimate the score function, we apply Tweedie's formula to estimate the clean point cloud $X$ from the noisy observations $Y$:
\begin{equation} 
\hat{X} = Y + \sigma^2 S(Y).
\end{equation}
Here, $S(Y)$ is the network's output, representing the estimated score for point $Y$.
%-------------------------------------------------------------------------

\noindent\textbf{Baseline}\quad We compare our method with the current state-of-the-art deep learning-based point cloud denoising algorithms, including Total Denoising (TotalDn) \cite{hermosilla2019TotalDenoising}, DMRDenoise (DMR) and its unsupervised version (DMR-u) \cite{luo2020DMR} and the unsupervised version of the Score-Based denoising algorithm (Score-u) \cite{luo_score-based_2021}. Note that we do not compare with \cite{noise4Wang2024} as no code or pre-trained model is provided by the paper. 

\noindent\textbf{Metrics}\quad We use Chamfer distance (CD) \cite{cdloss} and point-to-mesh distance (P2M) \cite{ravi2020pytorch3d}, two metrics commonly used in previous works to  evaluate model performance. Since point clouds vary in size, we normalize the denoising results to the unit sphere before computing the metric.


\subsection{Quantitative Results}
\label{sec:experiment:quantitative}
We first test our model using datasets with isotropic Gaussian noise. The standard deviation of the noise ranges from 1\% to 3\% of the radius of the shape boundary sphere.  \cref{table:quantitativemd} shows the comparative performance of various unsupervised denoising methods across sparse (10k) and dense (50k) point clouds with the ModelNet-40 dataset \cite{wu2015modelnet}. Notably, our proposed method achieves better results than other unsupervised approaches in both Chamfer Distance (CD) and Point-to-Mesh (P2M) metrics, even on par with the supervised version of DMRDenoise \cite{luo2020DMR}. Notably, our method demonstrates consistent performance across various noise levels, particularly at high noise levels where other unsupervised methods may produce large errors. 

Moreover, we evaluate Noise2Score3D using the PU-Net dataset \cite{yu2018PUNet}, as presented in \cref{table:quantitativepu}.  It can be seen that Noise2Score3D consistently achieve impressive results, especially under conditions of higher noise levels, underscoring its robustness against various noise intensities. It’s worth noting that our model is trained solely on the ModelNet-40 dataset, highlighting its generalization ability across various datasets..

Subsequently, we conducted evaluations on synthetic datasets that emulate realistic sensor noise \cite{hermosilla2019TotalDenoising}, specifically the Velodyne HDL-64E 3D LiDAR scanner \cite{gschwandtner2011blensor}. This dataset encompasses point clouds with varying densities, ranging from 3K to 120K points, yielding a comprehensive dataset with 12 million training points and 5 million testing points. The simulation process incorporates both per-laser unit distance bias and Gaussian noise per ray. Specifically, the standard deviation for distance bias is set to 0.5\% of the bounding box diagonal, with three distinct levels of per-ray Gaussian noise (0.5\%, 1\%, and 1.5\%) applied. The results is depicted in \cref{table:quantitativemd2}, which shows that Noise2Score3D exhibits a significant advantage when compared to other methods under various noise levels. Overall, our method demonstrates persistant denoising performance across various noise conditions, including different noise types and levels. 

%-------------------------------------------------------------------------
Additionally, as shown in \cref{tab:time}, we compare inference times across different methods on the same GPU device (NVIDIA RTX 3080ti). Our approach demonstrates a significant speed advantage: with 10K and 50K point clouds, Noise2Score3D is on-average 10$\times$ and 5$\times$ faster in inference times than other methods, confirming its efficiency and practical applicability.
%-------------------------------------------------------------------------

\subsection{Qualitative Results}
\label{sec:experiment:qualitative}
\cref{fig:visualization} shows the denoising results of the proposed method and the competing baselines under Gaussian and simulated LiDAR noise. The color of each point indicates its reconstruction error, which is measured by the point-to-grid distance presented in Section~\ref{sec:experiment:setup}. Points closer to the underlying surface are darker in color, otherwise they are brighter. From the figure, it is evident that our results are cleaner and visually superior to other unsupervised methods (e.g., TotalDn and DMR-u). 

Furthermore, we conduct a qualitative study on the real-world dataset \textit{Paris-rue-Madame} \cite{serna2014paris}. The results are shown in  \cref{fig:rue32}, where left and right part of each sub-figure are rendered from two different views. Note that since the noise-free point cloud is unknown for the real-world dataset, it is not possible to compute and visualize the error at each point. Due to the varying and intricate nature of noise in point clouds, many methods struggle to maintain a balance between effective denoising and the preservation of fine details, particularly under high noise conditions. Additionally, point clouds produced by these methods often suffer from nonuniform distribution, as shown in the right part of the 
subfigures in \cref{fig:rue32}. As a contrast, Noise2Score3D produces cleaner and smoother results, while better preserves details.

%-------------------------------------------------------------------------

\begin{table}
    \begin{center}
    \input{tables/time}
    \end{center}
    \vspace{-0.05in}
    \caption{Average inference time comparison (in seconds) for the PU-Net \cite{yu2018PUNet} dataset under identical conditions.}
\end{table}
%-------------------------------------------------------------------------

