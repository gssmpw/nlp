\section{Related Works}
\textbf{NN-based Treatment Effect Estimator}
Nowadays, 
Neural Networks (NNs) have emerged as a pivotal tool for treatment effect estimation due to their flexibility and widespread adoption.
Much of the work in this area has focused on mitigating confounding bias through balanced representation learning.
\cite{johansson2016learning,shalit2017estimating} first give a generalization bound consisting of an empirical loss and an Integral Probability Metric (IPM) distance,
thus establishing the paradigm of the balanced representation learning.
Building on this foundation, 
recent studies have incorporated the weighting strategies as an additional correction for confounding bias into this framework, 
such as \cite{johansson2018learning, hassanpour2019counterfactual, assaad2021counterfactual}.
Furthermore,
\cite{wang2022generalization, kazemi2024adversarially} extend this framework from binary treatment to continuous treatment scenarios.
In parallel, 
another prominent paradigm has been proposed for treatment effect estimation using neural networks, focusing on exploiting the sufficiency of propensity score.
Based on this,
\cite{shi2019adapting, nie2021vcnet} introduce targeted regularizations to correct the confounding bias.
Beyond standard feedforward neural networks, specialized architectures have also been explored,
including Variational Autoencoder (VAE) \cite{louizos2017causal}, 
Generative Adversarial Network (GAN) \cite{yoon2018ganite, bica2020estimating} and diffusion model \cite{sanchez2022diffusion}.
Compared to the above methods, 
our method is not limited to Gaussian-distributed outcome and equipped with theoretical guarantees for asymptotic correctness, 
addressing key limitations of prior works.

\textbf{Doubly Robustness, TMLE and Targeted Regularization} To address the bias in the plug-in estimator, \cite{Chernozhukov2017} and \cite{Chernozhukov2018} introduced doubly machine learning, which achieves doubly robustness by incorporating a bias correction term. Their theoretical work demonstrated that these doubly robust estimators attain $\sqrt{n}$-convergence rates under appropriate conditions. 
Following the doubly machine learning framework, \cite{NieRLearner} introduced the R-Learner, a general class of two-step algorithms for estimating treatment effects in observational studies. \cite{gao2022estimatingheterogeneoustreatmenteffects} extended the R-Learner framework to accommodate exponential family outcomes and introduced DINA (Difference in Natural pArameters) as a measure of treatment effects. Targeted Maximum Likelihood Estimation (TMLE) \cite{van2011targeted}, targeted regularization \cite{shi2019adapting}, and functional targeted regularization \cite{nie2021vcnet} offer an alternative framework to one-step correction by correcting bias on the distributional scale. 
\cite{kennedy2023semiparametricdoublyrobusttargeted} provides a comprehensive review of doubly robustness from a semiparametric perspective, with particular emphasis on minimax-style efficiency bounds, detailed worked examples, and practical derivation shortcuts. 
To the best of our knowledge, 
the only prior work on exponential family outcomes \cite{gao2022estimatingheterogeneoustreatmenteffects} only focuses on binary treatment and is limited to the partially linear assumption. 
Meanwhile,
prior works applying targeted regularization to neural networks \cite{shi2019adapting, nie2021vcnet} have been limited to the Gaussian-distributed outcomes setting. 
Different from them,
our work generalizes targeted functional regularization for exponential family outcomes, extending the framework to both binary and continuous treatment regimes.