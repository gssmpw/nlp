%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{subcaption}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{dsfont}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\def\cA{{\mathcal A}}
\def\cT{{\mathcal T}}
\def\cB{{\mathcal B}}
\def\cP{{\mathcal P}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Notations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bE}{\boldsymbol{E}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bZ}{\boldsymbol{Z}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\mP}{\mathbb{P}}
\newcommand{\mE}{\mathbb{E}}
\newcommand{\mR}{\mathbb{R}}
\newcommand{\cN}{\mathcal{N}}
% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Treatment Effect Estimation for Exponential Family Outcomes using Neural Networks with Targeted Regularization}

\begin{document}

\twocolumn[
\icmltitle{Treatment Effect Estimation for Exponential Family Outcomes using Neural Networks with Targeted Regularization}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Jiahong Li}{equal,yyy}
\icmlauthor{Zeqin Yang}{equal,yyy}
\icmlauthor{Jiayi Dan}{yyy}
\icmlauthor{Jixing Xu}{yyy}
\icmlauthor{Zhichao Zou}{yyy}
\icmlauthor{Peng Zhen}{yyy}
\icmlauthor{Jiecheng Guo}{yyy}
%\icmlauthor{}{sch}
%\icmlauthor{Firstname8 Lastname8}{sch}
%\icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Didi Chuxing, Beijing, China}
%\icmlaffiliation{comp}{Company Name, Location, Country}
%\icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Jiahong Li}{richardlijiahong@didiglobal.com}
%\icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
% Motivated by the increasing availability of observational data with generalized outcomes, we propose a neural network-based approach to estimate heterogeneous treatment effects under exponential family assumptions. To the best of our knowledge, existing research has primarily focused on parametric methods for exponential family treatment effect estimation with binary treatments, leaving the potential of neural networks for such estimation largely unexplored.
% In this paper, we make three key contributions: First, we use the Average Dose function of Canonical Functions (ADCF) to quantify treatment effects in exponential families and derive the von-Mises expansion of ADCF, facilitating the study of nonparametric efficiency bounds. Second, we propose a one-step estimator for ADCF and prove its asymptotic convergence to a normal distribution under mild conditions. Third, we develop a neural network-based estimation approach for ADCF by generalizing targeted regularization to exponential families. Studies on benchmark datasets for causal inference demonstrate our methods outperform existing methods. 

Neural Networks (NNs) have became a natural choice for treatment effect estimation due to their strong approximation capabilities. Nevertheless, 
how to design NN-based estimators with desirable properties, 
such as low bias and doubly robustness, %and efficiency,
still remains a significant challenge. 
A common approach to address this is targeted regularization, 
which modifies the objective function of NNs. 
However, existing works on targeted regularization are limited to Gaussian-distributed outcomes, 
significantly restricting their applicability in real-world scenarios.
In this work, 
we aim to bridge this blank by extending this framework to the boarder exponential family outcomes.
Specifically, 
we first derive the von-Mises expansion of the Average Dose function of Canonical Functions (ADCF), 
which inspires us how to construct a doubly robust estimator with good properties.
Based on this,
we develop a NN-based estimator for ADCF by generalizing functional targeted regularization to exponential families,
and provide the corresponding theoretical convergence rate. 
Extensive experimental results demonstrate the
effectiveness of our proposed model.

\end{abstract}



% 起：如何用NN/非参模型估计因果效应同时保留良好的理论性质（doubly robust, efficienc...）是很吸引人的
% 承：Dragonnet/VCNet通过修改损失函数，提出targeted regularization实现了这一点
% 转：然而，局限于高斯分布
% 合：我们提出了指数族

\section{Introduction}

% 起：因果效应估计很重要。采用神经网络估计因果效应有很大的优势。可以采取RCT/OBS数据估计，但是RCT成本高昂，主要考虑用观察数据，但观察数据存在混淆偏差。目前神经网络中有三种处理观察数据混淆偏差的方法：reweighting、表征和tatgeted regularization。如何用NN保证良好的理论性质是很重要的。
% Point1: 我们希望一个好的估计器应该有什么性质？Bias小，consistent，误差下界
% Point2: 起是否要提到tatgeted regularization 

% 从观察数据中估计因果效应，混淆偏差
% 神经网络估计器是受欢迎的工具
% 基于神经网络的估计器如何具有良好的理论性质
Due to the high cost of performing randomized trials,
estimating treatment effects from observational data has recently gained significant attention in various fields
\cite{glass2013causal, li2016matching},
which faces the primary challenge of confounding bias.
Meanwhile,
Neural Networks (NNs) have already shown strong potential in treatment effect estimation,
and have established several influential paradigms, such as balanced representation learning \cite{johansson2018learning, wang2022generalization, kazemi2024adversarially}.
However,
it still remains appealing to design a NN-based estimator that eliminates confounding bias for treatment effect estimation while achieving desirable properties,
such as low bias and double robustness.


% 承：Dragonnet/VCNet基于influence function修改了损失函数，提出targeted regularization实现了这一点，在估计reponse的同时对一阶偏差施加惩罚，可以保证神经网络的估计器具有良好的理论性质。
% Point1: Targeted Regularization bias解决性质
Based on the semiparametric theory,
two basic tools have been developed to address confounding bias while maintaining great theoretical properties:
% Two main approaches can reduce bias in naive estimators: 
the Doubly Robust (DR) estimator \cite{KennedyDR2023} and the Targeted Maximum Likelihood Estimation (TMLE) \cite{van2011targeted}. 
The DR estimator corrects bias by estimating and subtracting it from the initial plug-in estimator. 
TMLE, alternatively, eliminates bias at the distribution level by constructing a fluctuated estimator that zeroes out the bias term. 
Building on the foundation of TMLE,
\cite{shi2019adapting} makes a groundbreaking contribution by introducing targeted regularization.
It seamlessly integrating the TMLE theory into the design of neural networks,
resulting in an end-to-end NN-based estimator with non-parametrically optimal asymptotic properties for  binary treatment setting.
Subsequently,
\cite{nie2021vcnet} advanced this framework by extending the functional targeted regularization,
and then developing a doubly robust and consistent estimator to handle continuous treatment scenarios.

% \cite{shi2019adapting} developed targeted regularization, inspired by TMLE, to address first-order bias. This approach ensures theoretical soundness in neural network estimators through targeted regularization. \cite{nie2021vcnet} extended this concept to functional targeted regularization, developing a doubly robust and consistent estimator for the whole ADRF curve to handle continuous treatment scenarios. 

% 转：然而目前的Dragonnet/VCNet是局限在连续respoonse上（隐含Gauss），而对于二值响应变量和计数型变量的因果效应没有涉及。gao 2022提出了dina去度量指数族分布的因果效应，但这篇文章局限在了参数模型并且没有给出doubly robust和efficiency的估计。
% Point1: 更多笔墨花在Dragonnet/VCNet，举现实场景中非高斯响应变量的例子？
% Point2: 如何攻击Dina合适？
However,
while the above NNs-based estimators \cite{shi2019adapting, nie2021vcnet} have made significant progress,
they primarily focus on continuous outcomes, implicitly making Gaussian distribution assumption. 
Therefore,
these estimators fail to address the binary or count outcomes,
which are very common in real-world applications. 
For example, in social media advertising, platforms like Instagram show targeted ads to users (treatment) and track whether those users ultimately purchase the advertised product (binary outcome). 
Although \cite{gao2022estimatingheterogeneoustreatmenteffects} introduce DINA (Difference In Natural pArameters) to quantify the causal effect of exponential family outcomes, their extended R-learner framework is limited to the partially linear assumption. 

% 合：我们针对指数分布族的响应变量提出一种基于神经网络的因果效应估计模型。我们的贡献有如下三点：1. 得到ADCFs的Von-Mises展开进而得到了ADCFs effeciency下界，2. 利用Von-Mises展开得到ADCF的doubly Robust Estimator，并在一定条件下给出了渐进性质，3. 利用doubly Roubst Estimator的形式，推广了VCNet和Dragon Net的结果，给出了新的Targeted Regularization的形式。

% Point1: 挑战有什么？设计指数族的targeted regularization是不容易的/现有的结论无法直接用？我们希望设计一个end-to-end neural network based estimator？
% Point2: 为了解决挑战，我们的解决逻辑 von-Mises bias
% Point3: Contribution

To address these limitations, we propose an end-to-end NN-based estimator for exponential family outcomes. 
To the best of our knowledge,
although canonical(natural) parameters have been used to quantify causal effects for exponential family outcomes in \cite{gao2022estimatingheterogeneoustreatmenteffects},
how to design targeted regularization for neural networks to correct bias for it still remains unexplored. 
Following this direction, 
we must first derive and understand what the bias term is before we construct the debiased and doubly robust estimator.
% We consider the Average Dose function of Canonical Functions (ADCF) to quantify causal effects in exponential family outcomes. However, to the best of our knowledge, the existing literature has not addressed bias correction through targeted regularization for ADCF. 
% Therefore, we need to derive the bias term, constructs a debiased estimator, and ensures its consistency. 
To achieve this, we first introduce the von Mises expansion of Average Dose function of Canonical Functions (ADCF) to identify the first-order bias term for plug-in estimator,
which inspires us how to construct a doubly robust estimator by subtracting the estimated first-order bias term and analyze its asymptotic properties. 
Leveraging the above theoretical findings,
we generalize targeted regularization for exponential family outcomes using the doubly robust estimator. 
Our contributions can be summarized as follows:
\begin{enumerate}
    \item We derive the efficient influence function of the ADCF through von Mises expansion to characterize the first-order bias, which enables us to construct a doubly robust estimator with good  asymptotic properties.
    \item Building on the above findings, we develop a NN-based estimator for ADCF by generalizing functional targeted regularization to exponential familiy outcomes, and provide the corresponding convergence rate.
    \item We validate our proposed estimator using synthetic and semi-synthetic data, achieving state-of-the-art results.
\end{enumerate}
 

\section{Related Works}
\textbf{NN-based Treatment Effect Estimator}
Nowadays, 
Neural Networks (NNs) have emerged as a pivotal tool for treatment effect estimation due to their flexibility and widespread adoption.
Much of the work in this area has focused on mitigating confounding bias through balanced representation learning.
\cite{johansson2016learning,shalit2017estimating} first give a generalization bound consisting of an empirical loss and an Integral Probability Metric (IPM) distance,
thus establishing the paradigm of the balanced representation learning.
Building on this foundation, 
recent studies have incorporated the weighting strategies as an additional correction for confounding bias into this framework, 
such as \cite{johansson2018learning, hassanpour2019counterfactual, assaad2021counterfactual}.
Furthermore,
\cite{wang2022generalization, kazemi2024adversarially} extend this framework from binary treatment to continuous treatment scenarios.
In parallel, 
another prominent paradigm has been proposed for treatment effect estimation using neural networks, focusing on exploiting the sufficiency of propensity score.
Based on this,
\cite{shi2019adapting, nie2021vcnet} introduce targeted regularizations to correct the confounding bias.
Beyond standard feedforward neural networks, specialized architectures have also been explored,
including Variational Autoencoder (VAE) \cite{louizos2017causal}, 
Generative Adversarial Network (GAN) \cite{yoon2018ganite, bica2020estimating} and diffusion model \cite{sanchez2022diffusion}.
Compared to the above methods, 
our method is not limited to Gaussian-distributed outcome and equipped with theoretical guarantees for asymptotic correctness, 
addressing key limitations of prior works.

\textbf{Doubly Robustness, TMLE and Targeted Regularization} To address the bias in the plug-in estimator, \cite{Chernozhukov2017} and \cite{Chernozhukov2018} introduced doubly machine learning, which achieves doubly robustness by incorporating a bias correction term. Their theoretical work demonstrated that these doubly robust estimators attain $\sqrt{n}$-convergence rates under appropriate conditions. 
Following the doubly machine learning framework, \cite{NieRLearner} introduced the R-Learner, a general class of two-step algorithms for estimating treatment effects in observational studies. \cite{gao2022estimatingheterogeneoustreatmenteffects} extended the R-Learner framework to accommodate exponential family outcomes and introduced DINA (Difference in Natural pArameters) as a measure of treatment effects. Targeted Maximum Likelihood Estimation (TMLE) \cite{van2011targeted}, targeted regularization \cite{shi2019adapting}, and functional targeted regularization \cite{nie2021vcnet} offer an alternative framework to one-step correction by correcting bias on the distributional scale. 
\cite{kennedy2023semiparametricdoublyrobusttargeted} provides a comprehensive review of doubly robustness from a semiparametric perspective, with particular emphasis on minimax-style efficiency bounds, detailed worked examples, and practical derivation shortcuts. 
To the best of our knowledge, 
the only prior work on exponential family outcomes \cite{gao2022estimatingheterogeneoustreatmenteffects} only focuses on binary treatment and is limited to the partially linear assumption. 
Meanwhile,
prior works applying targeted regularization to neural networks \cite{shi2019adapting, nie2021vcnet} have been limited to the Gaussian-distributed outcomes setting. 
Different from them,
our work generalizes targeted functional regularization for exponential family outcomes, extending the framework to both binary and continuous treatment regimes. 

\section{Problem Statement and Notations}

Suppose we observe a sample $(\bZ_1, \ldots, \bZ_n)$ of independent and identically distributed observations from some distribution $\mP$,  where $\bZ_i = (\bX_i, A_i, Y_i)$ comprises the vector of covariates $\bX_i \in \mathcal{X} \subset \mR^d$,
the treatment of interest $A_i \in \mathcal{A} \subset \mR$, and the observed outcome $Y_i \in \mathcal{Y} \subset \mathbb{R}$. 
Throughout the paper we assume the treatment $A$ is binary with $\mathcal{A} = \{0, 1\}$ or continuous with $\mathcal{A} = [0,1]$. 
Additionally,
we assume that $Y$ is sampled from a single-parameter Exponetial Dispersion Family (EDF), which can be view as a single-parameter exponential family with nuisance parameters \cite{Wuthrich2022} as follows:
\begin{equation}
    Y \sim f(y; \theta, \varphi) = \exp \left\{\frac{y \theta - \kappa(\theta)}{\varphi} + \xi(y; \varphi) \right\}.
\end{equation}
Here, 
$\kappa: \Theta \rightarrow \mR $ is the cumulant function, 
$\theta \in \Theta$ is the canonical(natural)  parameter modeled as $\theta = \theta(\bx, a)$,
which could be further expressed as $\theta(\bx, a) = h(\mu(\bx,a))$,
where $h(\cdot)$ is the link function in exponential family and $\mu(\bx,a)=\mathbb{E}[Y|\bx, a]$ represents the conditional mean of $Y$ given $\bx$ and $a$.
Additionally,
$\varphi > 0$ is the dispersion parameter, 
and $\xi(\cdot;\cdot)$ is the normalization, 
which does not depend on the canonical parameter $\theta$. 

In this paper, we want to estimate the Average Dose Canonical Function(ADCF) of EDF, which quantify the causal effect on the canonical(natural)  parameter level. 
As highlighted by \cite{gao2022estimatingheterogeneoustreatmenteffects}, 
using the canonical  parameter $\theta$ to represent ADCF is advantageous because it aligns with common practices of comparison on the canonical parameter scale, simplifies modeling the influence of covariates, and avoids uninformative heterogeneity often seen in conditional means.
% \cite{gao2022estimatingheterogeneoustreatmenteffects} mentioned there are three advantanges of using canocial parameter:
% \begin{enumerate}
% \item Comparisons on the natural parameter scale are commonly adopted in practice.
% \item It is convenient to model the influence of covariates on the natural parameter scale.
% \item The difference in conditional means may exhibit uninteresting heterogeneity.
% \end{enumerate}
Therefore, we consider the ADCF as the causal estimand, which is given by
\begin{equation}
\psi_a :=\theta[do(A=a)] = h (\mE[Y|do(A=a)]),
\end{equation} 
where $\mathbb{E}[Y|do(A=a)]$ is the expected potential outcome that would have been observed under treatment level $a$. 
In addition,
suppose the (generalized) propensity score $\pi(a \mid \bx)$ denotes the conditional density of $A$ given $\bX$.
% $Y^a$ denotes the potential outcome that would have been observed under $A = a$.
Throughout this paper, we make the following assumptions:
\begin{assumption}[Overlap]
\label{overlap}
    There exists some constant $c > 0$ such that $\pi(a \mid \bx) \geq c$ for all $\boldsymbol{x} \in \mathcal{X}$ and $a \in \mathcal{A}$. 
    In other words,
    every unit receives treatment level $a$ with a probability greater than zero.
\end{assumption}

\begin{assumption}[Unconfoundedness]
\label{unconfoundedness}
    % $\{Y^a\}_{a\in \cA}\perp A | \bX$.
    % In other words,
    The measured covariate $\bX$ blocks all backdoor paths bewteen the treatment $A$ and outcomes $Y$.
\end{assumption}

Assumption \ref{overlap} and \ref{unconfoundedness} are standard in causal inference literature \cite{shi2019adapting, nie2021vcnet, wang2022generalization},
which ensures that the causal estimand $\psi_a$ is
identified from observational data as a statistical estimand:
    \begin{equation}\label{tarpar}
    \psi_a(\bZ;\mP) = \mathbb{E}[\theta(\bX, A=a)]= \mathbb{E}[h(\mathbb{E}[Y \mid \boldsymbol{X}, A = a])].
\end{equation}
% where $h(\cdot)$ is a link function. This paper develops neural network-based estimators for $\psi_a(\bZ;\mP)$. 

\textbf{Notation} We use $\mE$ to denote expectation, $\mP \in \mathcal{P}$ to denote true probability measure and we write $\mP(f) = \int f(\bz) d\mP(z)$, where $\mathcal{P}$ is a set of possible probability distributions.
Similarly, we use $\mP_n$ to denote the empirical measure and we write $\mP_n(f) = \int f(\bz) d\mP_n(z)$.  We denote convergence in distribution by $\overset{d}{\rightarrow}$ and convergence in probability by $\overset{p}{\rightarrow}$. 
% We use standard big-oh and little-oh notation, i.e., 
$X_n = O_{\mP}(r_n)$ means $X_n / r_n$ is bounded in probability and $X_n = o_{\mP}(r_n)$ means $X_n / r_n \overset{p}{\rightarrow} 0$. We use $\tau$ to denote Rademacher random variables. We denote Rademacher complexity of a function class $\mathcal{F}: \mathcal{X} \to \mathbb{R}$ as $\text{Rad}_n(\mathcal{F}) = \mathbb{E}(\sup_{f\in\mathcal{F}}|\frac{1}{n}\sum_{i=1}^n \tau_i f(X_i)|)$. Given two functions $f_1, f_2: \mathcal{X} \to \mathbb{R}$, we define $\|f_1-f_2\|_{\infty} = \sup_{x\in\mathcal{X}}|f_1(x)-f_2(x)|$ and $\|f_1-f_2\|_{L^2} = (\int_{x\in\mathcal{X}}(f_1(x)-f_2(x))^2 dx)^{1/2}$. For a function class $\mathcal{F}$, we define $\|\mathcal{F}\|_{\infty} = \sup_{f\in\mathcal{F}}\|f\|_{\infty}$. 
$a_n \asymp b_n$ denotes that both $a_n/b_n$ and $b_n/a_n$ are bounded. 

\section{Plug-in Estimator}
\label{plugin}
% 0. 总览
In this section,
we provide a brief overview of the plug-in estimator for $\psi_a$ using NNs,
which is very similar to VCNet \cite{nie2021vcnet}, 
with the key differences being the replacement of MSE loss of VCNet with the negative log-likelihood corresponding to the actual outcome distribution.

% 1. 引出\mu和\pi
According to Eq. (\ref{tarpar}),
a plug-in estimator is given by 
$\psi_a(\bZ;\hat{\mP})=\frac{1}{n}\sum_{i=1}^n \hat{\theta}_i(\bx_i, a) =\frac{1}{n}\sum_{i=1}^n h(\hat{\mu}(\bx_i, a))$,
where $\hat{\mu}$ is the estimator of $\mu(\bx,a)$ and $h(\cdot)$ is determined by the actual outcome distribution.
Following \cite{shi2019adapting, nie2021vcnet},
we extract the features related to treatments $A$ before downstream estimation of $\mu(\bx,a)$,
which helps reduce noise and is sufficient to estimate $\psi_a$.
Consequently, 
the neural network architecture of the plug-in estimator is shown in Fig. (\ref{fig:network}),
which consists of two heads: 
one for estimating the outcomes $\mu(\bx,a)$, 
and the other for estimating the generalized propensity scores $\pi(a \mid \bx)$.

% 2. 介绍\mu的变系数结构
A good outcome estimator $\mu(\bx,a)$ should not only enhance the impact of treatment but also preserve the continuity of ADCF.
To achieve this,
we adopt varying coefficient model \cite{hastie1993varying, fan1999statistical, chiang2001smoothing} to build $\mu(\bx,a)$,
allowing the treatment $a$ determines the parameters of neural networks.
In particular,
we use splines to model the parameters of $\mu(\bx,a)$ as $w(a)=\sum_{l=1}^{L} \alpha_l \phi_l(a)$,
where $\alpha_l$ is the coefficient and $\phi_l(\cdot)$ is the polynomial basis function.
As a result,
the ADCF produced by $\mu(\bx,a)$ is continuous once the activation function in neural networks is continuous.

% 3. 介绍\pi的条件密度估计
As for the estimator of generalized propensity scores $\pi(a|\bx)$,
the key challenge is ensuring that it produces a valid density.
To achieve this,
we first divide $[0, 1]$ equally into $B$ grids and estimate the conditional density $\pi(\cdot|\bx)$ on these $(B+1)$ grid points as 
$\pi_{grid}(\bx)=softmax(\bw\bx)\in \mathbb{R}^{B+1}$,
and then the conditional density could be given via linear interpolation,
i.e.,
$\pi(a|\bx)=\pi_{grid}^{a_1}(\bx)+B(\pi_{grid}^{a_2}(\bx)-\pi_{grid}^{a_1}(\bx))(a-a_1)$,
where $a_1=\lfloor Ba\rfloor, a_2=\lceil Ba \rceil$.

% 4. 损失函数
Since the outcomes $Y$ are sampled from an EDF, 
we use the negative log-likelihood of the EDF as the loss function for the outcome prediction head. 
For the propensity score head, 
the negative log-likelihood of $\pi(a|\bx)$ is used as its loss function. 
Consequently, 
the total loss is formulated as
\begin{equation}\label{Loss}
    \mathcal{L}(\mu, \pi) = \frac{1}{n}\sum_{i=1}^n \left[ \ell(y_i, \mu(\bx_i, a_i)) - \log(\pi(a_i|\bx_i)) \right].
\end{equation}

% 5. 引出下文
After obtaining $\hat{\mu}(\bx, a)$ by minimizing the empirical risk in Eq.(\ref{Loss}),
the plug-in estimator is given by $\psi_a(\bZ;\hat{\mP})=\frac{1}{n}\sum_{i=1}^n \hat{\theta}_i(a, \bx_i) =\frac{1}{n}\sum_{i=1}^n h(\hat{\mu}(a, \bx_i))$.
However,
the correctness of this naive estimator heavily relies on whether the function space defined by the neural network includes the truth $\mu$,
and it often fails to achieve $\sqrt{n}$- consistent and asymptotically normal estimation.
In next section,
we will show how to combine $\hat{\mu}$ and $\hat{\pi}$ to obtain doubly robust estimator with desirable properties.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.6\linewidth]{fig/network.pdf}
  \caption{Network architecture.}
  \label{fig:network}
\end{figure}

\section{Targeted Regularization for Exponential Family Outcomes}
In section \ref{doublyrobustestimator}, we derive the von-Mises expansion of ADCF, which enables us to construct a doubly robust estimator by removing the estimated first-order bias. 
Based on the doubly robust estimator, we then propose targeted regularization for exponential family outcomes to correct bias at the distribution scale in section \ref{tr}.
In section \ref{example},
we show some examples to illustrate the specific form of the targeted regularization under the exponential family distribution.

\subsection{Bias Analysis and Doubly Robust Estimator}
\label{doublyrobustestimator}
% A plug-in estimator for $\psi_a(\bZ;\mP)$ is to obtain an estimator $\hat{\theta}(a, \boldsymbol{x}_i)=h(\mu(\bx_i, a))$ of $\theta(a, \boldsymbol{x}_i)$, and use $\hat{\psi}_a =\frac{1}{n} \sum_{i=1}^n \hat{\theta}(a, \boldsymbol{x}_i)$. 
% where the estimator $\hat{\mu}$ of $\mu$ can be gained by using the link function $h$ as $\hat{\mu}(a, \boldsymbol{x}_i)=h(\hat{\theta}(a, \boldsymbol{x}_i))$. 
The plug-in estimator shown in Section \ref{plugin} usually introduces bias. 
To understand what the bias term is and address it, 
we derive the von Mises expansion of $\psi_a(\bZ;\mP)$ in Lemma \ref{vonmiseexpansion}. 
For simplicity, we drop the dependence of $a$ and $\bZ$. 

\begin{lemma}
\label{vonmiseexpansion}
Let $\psi_a(\bZ;\mP) = \mathbb{E}\left\{h(\mathbb{E}[Y \mid \boldsymbol{X}, A = a]) \right\}$ for some twise continuously differentiable link function $h$. For another probability measure $\bar{\mP}$, the $\psi$ confirms the von Mises expansion 
\begin{equation}
\label{von}
    \psi(\bar{\mP}) - \psi(\mP) = \int \phi_a(\bZ;\bar{\mP}) d (\bar{\mP}, \mP) + R_2(\bar{\mP},\mP),
\end{equation}
where the influence function is
\begin{align}
    \phi_a(\bZ;\mP) =& \frac{\mathds{1}(A=a)}{\pi(a \mid \bX)} \left\{ Y - \mu(\bX,a)\right\} h^{\prime} (\mu(\bX,a)) \nonumber \\
    &+ h (\mu(\bX, a))   - \psi, \nonumber
\end{align}
and
\begin{small}
\begin{align}
    R_2(&\bar{\mP},\mP) =
     \frac{1}{2} \int h^{\prime \prime}(\mu^*(\bx,a)) \left[\bar{\mu}(\bx,a)-\mu(\bx,a)\right]^2 d \mP(x)\nonumber \\
    & +\int \left\{\frac{\pi(a|\bx)}{\bar{\pi}(a|\bx)} -1\right\} h^{\prime} \left[\bar{\mu}(\bx,a)\right](\mu(\bx,a) - \bar{\mu}(\bx,a)) d \mP(x) \nonumber. 
\end{align}
\end{small}
where $\mu^*(\bx,a)$ lies between $\mu(\bx,a)$ and $\bar{\mu}(\bx, a)$. 
\end{lemma}
The proof of Lemma \ref{vonmiseexpansion} is in Appendix \ref{DIF}. 
The von Mises expansion in Lemma \ref{vonmiseexpansion} has several important implications. 

First, it indicates that the plug-in estimator $\psi_a(\bZ;\hat{\mathbb{P}})$ can be debiased by subtracting the first-order bias term $-\int \phi_a(\mathbf{Z};\bar{\mathbb{P}}) d\mathbb{P}$. By replacing the population distribution $\mathbb{P}$ with its empirical counterpart $\hat{\mathbb{P}}$, we can obtain the doubly robust estimator:
    \begin{equation}\label{onestep}
\begin{aligned}
\hat{\psi}_a^{\text{dr}} =& \psi_a(\bZ;\hat{\mP}) + \mP_n(\phi_a(\bZ;\hat{\mP})) \\
    =& \mP_n \left[h(\hat{\mu}(a,\bX))\right]\\
    &+\mP_n \left[\frac{\mathds{1}(A=a)}{\pi(a \mid \bX)} \left\{ Y - \mu(\bX,a)\right\} h^{\prime} (\mu(\bX,a))\right]
\end{aligned}
\end{equation}


The doubly robust estimator (\ref{onestep}) builds on $\hat{\mu}(\bx, a)$ and $\hat{\pi}(a|\bx)$,
which yields a consistent estimator even if one of them is inconsistent.
When both $\hat{\mu}(\bx, a)$ and $\hat{\pi}(a|\bx)$ are consistent,
we could get faster convergence rate.
The asymptotic behavior of this doubly robust estimator $\hat{\psi}_a(\bZ;\mP)$ can be studied through the following decomposition:
\begin{equation}\label{decomposition}
   \begin{aligned}
    \hat{\psi}_a^{\text{dr}} - \psi_a(\bZ;\mP) &= (\mP_n - \mP)\left\{ \phi_a(\bZ;\mP) \right\} \\
    &+ (\mP_n - \mP)\left\{ \phi_a(\bZ;\hat{\mP}) - \phi_a(\bZ;\mP) \right\}\\
    &+ R_2(\hat{\mP}, \mP),
\end{aligned} 
\end{equation}
where $\phi_a(\bZ;\mP)$ and $R_2(\hat{\mP}, \mP)$ are given by Lemma \ref{vonmiseexpansion}. 

The following Lemma \ref{asydistr} establishes the asymptotic properties of the doubly robust estimator.
\begin{lemma}\label{asydistr}
If 
\begin{enumerate}
    \item $(\mP_n - \mP)\left\{ \phi_a(\bZ;\hat{\mP}) - \phi_a(\bZ;\mP) \right\} = o_{\mP}(1/\sqrt{n})$;
    \item $\Vert \hat{\pi}(a|\bx) - \pi(a|\bx) \Vert = o_{\mP}(n^{-1/4})$;
    \item $\Vert \hat{\mu}(a,\bx) - \mu(a,\bx) \Vert = o_{\mP}(n^{-1/4})$.
\end{enumerate}
then $\hat{\psi}_a^{\text{dr}} - \psi_a(\bZ;\mP) = (\mP_n - \mP)\left\{ \phi_a(\bZ;\mP) \right\} + o_{\mP}(1/\sqrt{n})$ and so $\hat{\psi}_a^{\text{dr}}$ is root-$n$ consistent, asymptotically normal.
\end{lemma}

\begin{remark}
The first term of Eq (\ref{decomposition}) is a simple average of a fixed function, it convergent to a normal distribution by the central limit theorem. To confirm the $(\mP_n - \mP)\left\{ \phi_a(\bZ;\hat{\mP}) - \phi_a(\bZ;\mP) \right\} = o_{\mP}(1/\sqrt{n})$, we can use sample splitting \cite{kennedy2023semiparametricdoublyrobusttargeted}. Conditions 2 and 3 can be satisfied by various estimators including random forests and neural networks \cite{Chernozhukov2018, Farrell2021}. We prove Lemma \ref{asydistr} in Appendix \ref{P2}. 
\end{remark}


Second, since the remainder term in Eq. (\ref{von}) is quadratic in the nuisance functions, which means it consists of only second-order products of errors between $\mP$ and $\mP_{\varepsilon}$. Thus, it is obvious to verify 
 \begin{equation*}
     \frac{d}{d \epsilon} R_2(\mP, \mP_{\epsilon}) = 0.
 \end{equation*}
 
By using the Lemma 2 in \cite{KenndySCDE}, we can find out that $\psi_a(\mathbf{Z};\mathbb{P})$ is pathwise differentiable with efficient influence function $\phi_a(\mathbf{Z};\mathbb{P})$. The following Corollary \ref{efficientbound} presents the local minimax lower bound, which is determined by the efficient influence function $\phi_a(\mathbf{Z};\mathbb{P})$ in Lemma \ref{vonmiseexpansion} and follows from Corollary 2.6 of \cite{vandervaart2002semiparametric}
\begin{corollary}\label{efficientbound}
Let $\psi_a(\bZ;\mP) = \mathbb{E}\left\{h(\mathbb{E}[Y \mid \boldsymbol{X}, A = a]) \right\}$ with efficient influence function $\phi_a(\mathbf{Z};\mathbb{P})$. Assume the model is nonparametric or the tangent space is a convex cone. 
\begin{align*}
    \inf_{\delta>0} \liminf_{n \to \infty} \sup_{TV(\mathbb{P},\mathbb{Q})<\delta} n \mathbb{E}^{\mathbb{Q}}[(\widehat{\psi}-\psi(\mathbb{Q}))^2] \geq \mathrm{Var}[\phi_a(\mathbf{Z};\mathbb{P})],
\end{align*}
for any estimator sequence $\widehat{\psi}=\widehat{\psi}_n$.
\end{corollary}
Corollary \ref{efficientbound} gives a benchmark for treatment effect estimation: no estimator of $\psi_a(\bZ;\mP)$ can have smaller mean squared error than the variance of the $\phi_a(\mathbf{Z};\mathbb{P})$ in a local asymptotic minimax sense. 

% \begin{remark}
%     When considering a binary treatment i.e. $\mathcal{A} = \{0, 1\}$, we choose the DINA in \cite{gao2022estimatingheterogeneoustreatmenteffects} as a statistical estimand:
%     \begin{equation*}
%         \psi^{\prime}(\bZ;\mP) = \psi_1(\bZ;\mP) - \psi_0(\bZ;\mP).
%     \end{equation*}
%     The one-step estimator of DINA can be viewed as a "doubly robust estimator" of DINA. The one-step estimator is given by 
%     \begin{equation*}
%         \begin{aligned}
%         \hat{\psi}^{\prime} =& \mP_n \left[h(\hat{\mu}(\bX,1))\right] - \mP_n \left[h(\hat{\mu}(\bX,0))\right]\\
%         &+\mP_n\left[\frac{A}{\pi(1 \mid \bX)} \left\{ Y - \mu(\bX,1)\right\} h^{\prime} (\mu(\bX,1))\right]\\
%         &-\mP_n\left[\frac{1-A}{1-\pi(1 \mid \bX)} \left\{ Y - \mu(\bX,0)\right\} h^{\prime} (\mu(\bX,0))\right]
%         \end{aligned}
%     \end{equation*}
% \end{remark}



\subsection{Targeted Regularization}\label{tr}
As discussed in \cite{kennedy2023semiparametricdoublyrobusttargeted},
a key limitation of the doubly robust estimator (\ref{onestep}) is that even when $\psi_a(\mP;\bZ)$ and $\psi_a(\hat{\mP};\bZ)$ are bounded, the correction term $\mP_n(\phi_a(\hat{\mP};\bZ))$ may cause the estimator to fall outside the parameter space bounds. TMLE is an alternative strategy to correct bias but on the distributional scale, which construct a fluctuated estimate $\hat{\mP}^*$  for which the correction term $\mP_n(\phi_a(\hat{\mP};\bZ)) \approx 0$. By ensuring the correction term remains sufficiently small, TMLE can address the boundary issue, which inspires targeted regularization \cite{shi2019adapting, nie2021vcnet}.

Drawing inspiration from TMLE, 
targeted regularization aims to learn $\hat{\mu}^*$ and $\hat{\pi}^*$ for which 
\begin{align}
\label{tmle}
    &\mP_n(\phi_a(\bZ;\hat{\mP}^*))\nonumber \\
    =&\mP_n \left[\frac{\mathds{1}(A=a)}{\hat{\pi}^*(a \mid \bX)} \left\{ Y - \hat{\mu}^*(\bX,a)\right\} h^{\prime} (\hat{\mu}^*(\bX,a))\right] \approx 0,
\end{align}
so according to Eq. (\ref{onestep}), we have
\begin{align*}
    \psi_a(\bZ;\hat{\mP}^*) \approx \mP_n \left[h(\hat{\mu}^*(a,\bX))\right].
\end{align*}
To achieve Eq. (\ref{tmle}), 
we can construct a function $\mathcal{R}(\mu, \pi, \epsilon)$, which satisfies that
\begin{small}
\begin{align}
    \frac{\partial}{\partial \epsilon} \mathcal{R}(\mu, \pi, \epsilon) = \mP_n \left[\frac{\mathds{1}(A=a)}{\hat{\pi}^*(a \mid \bX)} \left\{ Y - \hat{\mu}^*(\bX,a)\right\} h^{\prime} (\hat{\mu}^*(\bX,a))\right], \nonumber
\end{align} 
\end{small}

where $\epsilon$ is an extra scalar perturbation function associated with $\psi_a$: $\epsilon: \mathcal{A} \subset [0,1] \rightarrow \mathbb{R}$. 
In this way, we define the loss function of plug-in estimator with functional targeted regularization as 
\begin{equation}\label{FTR}
    \mathcal{L}_{TR}(\mu, \pi, \epsilon) = \mathcal{L}(\mu, \pi) + \beta \mathcal{R}(\mu, \pi, \epsilon),
\end{equation}
where $\mathcal{L}(\mu, \pi)$ is defined in Eq. (\ref{Loss}),
and we design 
\begin{small}
\begin{align}
    \mathcal{R}(\mu, \pi, \epsilon) =& \frac{1}{n}\sum_{i=1}^n\left\{-y_i\left[h(\mu(\bx_i, a_i))\right.\right.
    +\left.\left.\frac{\epsilon(a_i)}{\pi(a_i|\bx_i)} h^{\prime}( \mu (\bx_i, a_i))\right]\right. \nonumber
    \\+&\left.\kappa\left(h(\mu(\bx_i, a_i))+\frac{\epsilon(a_i)}{\pi(a_i|\bx_i)} h^{\prime}( \mu (\bx_i, a_i))\right)\right\}, \nonumber
\end{align}
\end{small}
where $\kappa$ is the cumulant function in exponential family.

If $(\hat{\mu}, \hat{\pi}, \hat{\epsilon})$ is the minmizer of $\mathcal{L}_{TR}(\mu, \pi, \epsilon)$, 
then at the convergence of the optimization,
the estimation term of 
\begin{small}
    \begin{equation*}
    \frac{\partial}{\partial \epsilon} \mathcal{R}(\mu, \pi, \epsilon)=\mP_n \left[\frac{\mathds{1}(A=a)}{\hat{\pi}^*(a \mid \bX)} \left\{ Y - \hat{\mu}^*(\bX,a)\right\} h^{\prime} (\hat{\mu}^*(\bX,a))\right]=0
\end{equation*}
\end{small}
is no more needed.
This implies that our final estimator $\hat{\psi}_a^{\text{tr}}$ with associated $\epsilon(a)$
\begin{small}
    \begin{align}
\label{new}
    \hat{\psi}_a^{\text{tr}} &= \frac{1}{n} \sum_{i=1}^{n} h(\hat{\mu}^*(\bx_i, a))\nonumber\\
    &= \frac{1}{n} \sum_{i=1}^{n} \left(h(\hat{\mu}(\bx_i, a)) + \frac{\hat{\epsilon}_n(a)}{\hat{\pi}(a \mid \bx_i)}h^\prime(\hat{\mu}(\bx_i, a)) \right)
\end{align}
\end{small}
behaves like the doubly robust estimator (\ref{onestep}) asymptotically.  

However, optimizing $\epsilon(a)$ over the function space of all mappings from $\mathcal{A}$ to $\mathbb{R}$ is not feasible in practice. We follow \cite{nie2021vcnet} to use splines $\{B_k\}_{k=1}^{K_n}$ with $K_n$ basis function $B_k(\cdot)$ to approximate $\epsilon$. 

Next,
we first make some assumptions in Assumption \ref{assumption},
then we provide the asymptotic property of our final estimator (\ref{new}) in Theorem \ref{targetedreg}.
\begin{assumption}[Assumption 2 in \cite{nie2021vcnet}]
    \label{assumption}
    We consider the following assumptions:
    \begin{enumerate}
        \item[(i)] There exists constant $c > 0$ such that for any $a \in \mathcal{A}$, $\bx \in \mathcal{X}$, and $\hat{\pi} \in \mathcal{U}$, we have $1/c \leq \hat{\pi}(a\mid \bx) \leq c$, $1/c \leq \pi(a\mid \bx) \leq c$, $\|\mathcal{Q}\|_{\infty} \leq c$ and $\|\mu\|_{\infty} \leq c$.
        \item[(ii)] $\pi, \mu, \hat{\pi}$ and $\hat{\mu}$ have bounded second derivatives for any $\hat{\pi} \in \mathcal{Q}$ and $\hat{\mu} \in \mathcal{U}$.
        \item[(iii)] Either $\hat{\pi} = \pi$ or $\hat{\mu} = \mu$. And $\operatorname{Rad}_n(\mathcal{G}), \operatorname{Rad}_n(\mathcal{Q}), \operatorname{Rad}_n(\mathcal{U}) = O_{\mP}(n^{-1/2})$.
        \item[(iv)] $\mathcal{B}_{K_n}$ equals the closed linear span of B-spline with equally spaced knots, fixed degree, and dimension $K_n \asymp n^{1/6}$.
    \end{enumerate}
\end{assumption}
% The asymptotic property of the functional targeted regularization \ref{FTR} is therefore defined by the following theorem:
\begin{theorem}
    \label{targetedreg}
    Under Assumption\ref{assumption}, let 
    \begin{equation*}
    \hat{\psi}_a^{\text{tr}} = \frac{1}{n} \sum_{i=1}^{n} \left(h(\hat{\mu}(x_i, a)) + \frac{\hat{\epsilon}_n(a)}{\hat{\pi}(a \mid x_i)}h^\prime(\hat{\mu}(x_i, a)) \right)
    \end{equation*} and the loss function is defined as \ref{FTR}. 
    we have
    \[
    \|\hat{\psi}_a^{\text{tr}} - \psi_a\|_{L^2} = O_p(n^{-\frac{1}{3}}\sqrt{logn}+r1(n)r2(n)+r2(n)^2),
    \]
    where $\|\hat{\pi} - \pi\|_{\infty} = O_p(r_1(n))$ and $\|\hat{\mu} - \mu\|_{\infty} = O_p(r_2(n))$.
    \end{theorem}

\begin{remark}
Assumption \ref{assumption} is standard, mild conditions commonly to establish convergence rates for functional targeted regularization in \cite{nie2021vcnet}. We extended the results of \cite{nie2021vcnet} from Gaussian distributions to the broader exponential families, establishing comparable convergence rates for functional targeted regularization.
\end{remark}

The proof of Theorem \ref{targetedreg} is in Appendix \ref{P3}.
Theorem \ref{targetedreg} shows that under mild regularity conditions and appropriate control of model complexity, the targeted regularization estimator $\psi_a$ possesses a key theoretical properties. It maintains doubly robustness, i.e. when both $\hat{\pi}$ and $\hat{\mu}$ converge to their true values, $\hat{\psi}_a$ achieves a convergence rate that surpasses the individual convergence rates of either $\hat{\pi}$ and $\hat{\mu}$. 

    
    

\subsection{Exponential Family Examples}
\label{example}
Now, 
we take Bernoulli and Poisson distribution as examples,
to explain the specific forms of the influence functions and corresponding targeted regularization term in Eq. (\ref{FTR}). 
\subsubsection{Bernoulli Distribution}
If the outcome $Y$ is assumed to sample from a Bernoulli distribution, the ADCF can be defined as 
\begin{align*}
    \psi_a(\bZ;\mP)& = \mathbb{E}\left\{h(\mu(\bX,A=a)) \right\} \\
    &= \mathbb{E}\left\{ \log \frac{\mathbb{E}[Y \mid \boldsymbol{X}, A = a]}{1-\mathbb{E}[Y \mid \boldsymbol{X}, A = a]} \right\},
\end{align*}
where we choose the logit function $g(\mu)= \log \left(\frac{\mu}{1-\mu}\right)$ as link function,
and sigmoid function as the activation function of the last layer in outcome estimation head,
which yields $\mu(\bX, a)\in [0, 1]$.
As a result, 
the influence function of $\psi_a$ is given by
\begin{align*}
    \phi_a(\bZ;\mP) =& \frac{\mathds{1}(A=a)(Y - \mu(\bX,a))}{\pi(a \mid \bX)\mu(\bX,a)(1-\mu(\bX,a))}\\
    &+ \log \left(\frac{\mu(\bX,a)}{1-\mu(\bX,a)}\right)   - \psi_a.
\end{align*}
It implies that the targeted regularization term is 
\begin{small}
    \begin{equation*}
    \begin{aligned}
        \mathcal{R}(&p, \pi, \epsilon) = \frac{1}{n}\sum_{i=1}^n\left\{-y_i\left[\log\frac{\mu(\bx_i, a_i)}{1-\mu(\bx_i, a_i)}\right.\right.
    \\+&\left.\left.\frac{\epsilon(a_i)}{\pi(a_i|\bx_i)} \frac{1}{\mu(\bx_i, a_i)(1-\mu(\bx_i, a_i))}\right]\right.
    \\+&\left.\kappa\left(\log\frac{\mu(\bx_i, a_i)}{1-\mu(\bx_i, a_i)}+\frac{\epsilon(a_i)}{\pi(a_i|\bx_i)} \frac{1}{\mu(\bx_i, a_i)(1-\mu(\bx_i, a_i))}\right)\right\},
    \end{aligned}
\end{equation*}
\end{small}

where $\kappa(\cdot) = \log(1+\exp(\cdot))$.

\subsubsection{Poisson Distribution}
If the outcome $Y$ is assumed to sample from a Poisson distribution, the ADCF can be defined as 
\begin{align*}
    \psi_a(\bZ;\mP) &= \mathbb{E}\left\{h(\mu(\bX,A=a)) \right\} = \mathbb{E}\left\{ \log \mathbb{E}[Y \mid \boldsymbol{X}, A = a] \right\},
\end{align*}
where we choose the logarithm function as link function, 
and exponential function as the activation function of the last layer in outcome estimation head,
which yields $\mu(\bX, a)\in \mathbb{R}^{+}$.
As a result,
the influence function of $\psi_a$ is given by
\begin{equation*}
    \psi_a(\bZ;\mP) = \frac{\mathds{1}(A=a)\left( Y - \mu(\bX,a)\right)}{\pi(a \mid \bX)\mu(\bX, a)}  + \log \mu(\bX, a)   - \psi_a.
\end{equation*}
It implies that the target regularization is 
\begin{equation*}
    \begin{aligned}
    \mathcal{R}(\mu, \pi, \epsilon) =& \frac{1}{n}\sum_{i=1}^n\left\{-y_i\left[\log\mu(\bx_i, a_i)+\frac{\epsilon(a_i)}{\pi(a_i|\bx_i)\mu(\bx_i, a_i)} \right]\right.
    \\+&\left.\exp\left(\log\mu(\bx_i, a_i)+\frac{\epsilon(a_i)}{\pi(a_i|\bx_i)\mu(\bx_i, a_i)}\right)\right\}.
\end{aligned}
\end{equation*}


\begin{table*}[]
\centering
\caption{Results on binary treatment setting. We report the MAE with respect to ATE and highlight the best result in bold.}
\label{tab:binary results}
\resizebox{\textwidth}{!}{%
\begin{normalsize}
\begin{tabular}{cccc|ccc}
\hline
& \multicolumn{3}{c|}{Bernoulli} 
& \multicolumn{3}{c}{Poisson}                                                  \\ \hline
        & Simulation        & News       & TCGA        
        & Simulation        & News     & TCGA      \\ \hline
Causal Forest     & $1.5665_{\pm 0.0174}$ & $1.8309_{\pm 0.0269}$ & $1.8316_{\pm 0.1039}$ & $3.0082_{\pm 0.0801}$ & $7.2009_{\pm 0.1794}$ & $12.998_{\pm 1.3429}$   \\
Dragonnet     & $1.9036_{\pm 0.3238}$ & $1.8491_{\pm 1.7251}$  & $1.7854_{\pm 1.5359}$ & $2.7935_{\pm 0.0309}$ & $6.4721_{\pm 1.2242}$ & $7.1624_{\pm 3.0149}$ \\
Dragonnet(adapt)     & $1.2830_{\pm 0.3662}$ & $1.7816_{\pm 1.1453}$ & $1.5784_{\pm 1.4081}$ & $2.6909_{\pm 0.0737}$ & $5.1950_{\pm 0.9277}$ & $7.1419_{\pm 2.4739}$ \\
DINA-learner      & $0.9133_{\pm 0.2385}$ & $0.9854_{\pm 0.2985}$ & $0.8652_{\pm 0.3429}$ & $1.8522_{\pm 0.6704}$ & $1.6080_{\pm 0.7515}$ & $2.3710_{\pm 0.6003}$ \\ \hline
Ours(w/o. t-reg)      & $1.0198_{\pm 0.2340}$ & $1.0481_{\pm 0.2603}$ & $0.9198_{\pm 0.1244}$ & $1.9840_{\pm 0.1245}$ & $2.0461_{\pm 0.3602}$ & $2.8991_{\pm 0.4251}$ \\
Ours      & \pmb{$0.8283_{\pm 0.1791}$} & \pmb{$0.5817_{\pm 0.1762}$} & \pmb{$0.0635_{\pm 0.0446}$} & \pmb{$1.0470_{\pm 0.0252}$} & \pmb{$1.2127_{\pm 0.2045}$} & \pmb{$1.0962_{\pm 0.1653}$} \\
\hline
\end{tabular}
\end{normalsize}
}
\end{table*}


\section{Experiments}

\subsection{Dataset}
Since the true causal effect are not available for real-world data, 
previous methods \cite{shi2019adapting, nie2021vcnet, wang2022generalization} often use synthetic/semi-synthetic data for empirical evaluation.
Following them,
based on one synthetic dataset and two semi-synthetic datasets, News \cite{schwab2020learning} and TCGA \cite{weinstein2013cancer},
we design two distinct treatment settings to verify the effectiveness of our method: binary treatments and continuous treatments.
And for each setting, 
we assume the outcomes $Y$ follow Bernoulli distribution and Poisson distribution, respectively, serving as representative examples of the exponential family.

\subsubsection{Synthetic Data Generation}
We simulate the synthetic dataset as follows.
We first generate 10000 samples with covariates $\bX \sim \text{Unif}(0,1) \in \mathbb{R}^6$, 
and the assigned treatments and  outcomes under different settings are generated as follows:
\begin{itemize}
    \item  To generate the treatments, we set:
    \begin{align*}
        A &= \begin{cases} 
            \cB(1, \sigma(\tilde{a})), & \text{for binary case}, \\
            \sigma(\tilde{a})\;\;\;\;\;\;\;\;\;\;\;\;\;, & \text{for continuous case} ,
        \end{cases}
    \end{align*}

    where $\tilde{a} = 10 
        \frac{\sin\left(\max(\bX_1, \bX_2, \bX_3)\right) + \max(\bX_3, \bX_4, \bX_5)^3}{1 + (\bX_1 + \bX_5)^2} + \sin(0.5\bX_3)(1 + \exp(\bX_4 - 0.5\bX_3)) + \bX_3^2 + 2\sin(\bX_4) + 2\bX_5 - 6.5 + \mathcal{N}(\mu_1, 0.5)$,
        $\cB(1, p)$ denotes the Bernoulli distribution with probability $p$, 
        and $\sigma(\cdot)$ denotes the sigmoid function.

    \item After obtaining the assigned treatments, we generate the corresponding outcomes under different distributions.
    Specifically,
    we first generate $\tilde{\mu}=2(A+\gamma)\sin(\bX_4)(A+4\max(\bX_1, \bX_6)^3) /(1+2\bX_3^2) $,
    where $\gamma$ is set to -0.5 for the Bernoulli distribution and 0.5 for the Poisson distribution,
    then the corresponding outcomes are obtained as follows:
    \begin{align*}
       Y = 
    \begin{cases} 
        \cB(1, \sigma(\tilde{\mu})), & \text{for Bernoulli case}, \\
        \cP(\exp(clip(\tilde{\mu}, -4, 4))), & \text{for Poisson case} ,
    \end{cases} 
    \end{align*}

    where $\cP(\lambda)$ denotes the Poisson distribution with parameter $\lambda$, and we limit $\tilde{\mu}$ to the range of -4 to 4 to avoid extreme values after exponential scaling.
\end{itemize}


\subsubsection{Semi-synthetic Data Generation}
Following \cite{schwab2020learning, bica2020estimating, nie2021vcnet},
we reuse the covariates $X$ of the real-word datasets, News and TCGA.
To generate the assigned treatments and their corresponding outcomes,
we first generate a set of parameters $\boldsymbol{V}_{i}=\boldsymbol{U}_{i}/||\boldsymbol{U}_{i}||$ and $i=1,2,3$, where $\boldsymbol{U}_{i}$ is sampled from a normal distribution $\mathcal{N}(\mathbf{0}, \mathbf{1})$,
then:
\begin{itemize}
    \item To assign the treatments, we generate $\tilde{a}=\left| w *\frac{\mathbf{V}_3^\top \bX}{\mathbf{V}_2^\top \bX} \right|$,
    where the parameter $w$ varies depending on the dataset and treatment type.
    For the News dataset, we set $w=1.5$ for binary treatments and $w=0.5$ for continuous treatments.
    For the TCGA dataset, $w$ is set to 5 for binary treatments and 0.2 for continuous treatments. 
    Using these values, 
    the treatments are generated as:
    \begin{align*}
        A &= \begin{cases} 
            \cB(1, \sigma(\tilde{a}))\;\;, & \text{for binary case}, \\
            Beta(2, |\tilde{a}|), & \text{for continuous case} .
        \end{cases}
    \end{align*}

    \item To generate the outcomes, we first generate $\tilde{\mu}$ according to the treatments setting.
    For binary treatments, we set $\tilde{\mu}=\cos\left(1.2\pi A\right) \times 2(\max(-2, \frac{\mathbf{V}_2^\top \bX}{\mathbf{V}_3^\top \bX + 2} - 0.3)) + 10 \mathbf{V}_1^\top \bX$.
    For continuous treatments, $\tilde{\mu}$ is given by $\tilde{\mu}=20(A-0.5)\sin{(\pi A)}\left(\max(\alpha, \frac{\mathbf{V}_2^\top \bX}{\mathbf{V}_3^\top \bX + 2} - 0.3)+\beta \mathbf{V}_1^\top \bX\right)$.
    Based on the computed $\tilde{\mu}$,
    the outcomes $Y$ are generated according to the following rules:
    \begin{align*}
        Y = \begin{cases} 
            \cB(1, \sigma(\mu)), & \text{for Bernoulli case}, \\
            \cP(\exp(\max(4, \gamma*\mu))), & \text{for Poisson case} .
        \end{cases}
    \end{align*}

    In particular, we set $\alpha=-2,\beta=10,\gamma=2.5$ for the News dataset and $\alpha=-0.5,\beta=5,\gamma=4.5$ for the TCGA dataset.
    
\end{itemize}

\begin{table*}[!t]
\centering
\caption{Results on continuous treatment setting. We report the AMSE with respect to ADCF and highlight the best result in bold.}
\label{tab:continuous results}
\resizebox{\textwidth}{!}{%
\begin{normalsize}
\begin{tabular}{cccc|ccc}
\hline
& \multicolumn{3}{c|}{Bernoulli} 
& \multicolumn{3}{c}{Poisson}                                                  \\ \hline
        & Simulation        & News       & TCGA        
        & Simulation        & News     & TCGA      \\ \hline
Causal Forest      & $0.8886_{\pm 0.0178}$ & $0.4789_{\pm 0.5316}$ & $0.9468_{\pm 0.2079}$ & $0.9282_{\pm 0.0900}$ & $15.295_{\pm 4.4294}$ & $4.6775_{\pm 1.2552}$   \\
VCNet   & $0.9862_{\pm 0.9417}$ & $0.4641_{\pm 0.4874}$ & $1.9497_{\pm 1.9862}$ & $0.8394_{\pm 0.0161}$ & $9.9018_{\pm 3.7146}$ & $3.0901_{\pm 1.0139}$ \\
VCNet(adapt)      & $0.8292_{\pm 0.6323}$ & $0.3041_{\pm 0.2579}$ & $1.3134_{\pm 1.6942}$ & $0.7478_{\pm 0.0212}$ & $3.6986_{\pm 0.6073}$ & $3.0778_{\pm 1.0212}$ \\ \hline
Ours(w/o. t-reg)       & $0.4091_{\pm 0.3286}$ & $0.1992_{\pm 0.1396}$ & $0.8896_{\pm 0.3711}$ & $0.5239_{\pm 0.1546}$ & $3.0159_{\pm 0.8433}$ & $2.9032_{\pm 0.4075}$ \\
Ours      & \pmb{$0.1111_{\pm 0.1103}$} & \pmb{$0.1424_{\pm 0.1057}$} & \pmb{$0.0443_{\pm 0.0328}$} & \pmb{$0.4177_{\pm 0.0239}$} & \pmb{$2.4547_{\pm 0.5815}$} & \pmb{$2.3570_{\pm 0.2612}$} \\
\hline
\end{tabular}
\end{normalsize}
}
\end{table*}


\subsection{Baselines}
For \textit{binary treatment setting} ,
we compare our method with:
(1) \textbf{Dragonnet} \cite{shi2019adapting}. It designs a targeted regularization technique similar to ours, which is only applicable to Gaussian distribution.
(2)\textbf{Dragonnet(adapt)}. Based on Dragonnet, we replace the Mean Squared Error (MSE) loss for the outcome $Y$ with the negative log-likelihood that fits the actual outcome distribution.
(3) \textbf{DINA-learner} \cite{gao2022estimatingheterogeneoustreatmenteffects}. It extends R-learner framework to accommodate outcomes from the exponential family of distributions.

For \textit{continuous treatment setting} ,
we compare our method with:
(4) \textbf{VCNet} \cite{nie2021vcnet}, which adapts a varying coefficient model to handle continuous treatment, and designs functional targeted regularization similar to ours, which is only applicable to Gaussian distribution. 
Similarly, 
we consider (5)\textbf{VCNet(adapt)} that replaces the MSE loss for outcome $Y$ in VCNet with the negative log-likelihood that fits the actual outcome distribution.

In \textit{both treatment settings} , 
we also employ (6)\textbf{Causal Forest} \cite{wager2018estimation} as a baseline since it is a classical random forest algorithm for causal inference and does not impose specific restrictions on the treatment type.
And (7) \textbf{Ours(w/o. t-reg)} is the simplified version of our method that does not include targeted regularization.

\subsection{Metric}
For \textit{binary treatment},
we evaluate the Mean Absolute Error (MAE) of the Average Treatment Effect (ATE) as $MAE=|\psi-\hat{\psi}|$,
where $\psi$ is the true ATE and $\hat{\psi}$  is the estimated ATE.
For \textit{continuous treatment}, 
we focus on the Average Mean Squared Error (AMSE) of the ADCF, 
i.e., 
$AMSE = \int_{\cA}[\hat{\psi}(a)-\psi(a)]^2 p(a) da$,
where $p(a)$ is the marginal density of treatments.

For the simulation dataset,
we randomly sample 60\%/20\%/20\% units for training/validation/test.
For the semi-synthetic datasets, 
we randomly split each data into training (67\%), validation (23\%), and test (10\%).
The validation dataset is used for hyperparameter selection and early-stopping.
Besides,
we perform 5 replications for each dataset to report the mean and standard deviation of the corresponding metric on test set.



\begin{figure}[!t]
    \centering
    \subfigure[Bernoulli]{\includegraphics[width=.49\linewidth]{fig/sensitivity_bernoulli.pdf}}
    \subfigure[Poisson]{\includegraphics[width=.49\linewidth]{fig/sensitivity_poisson.pdf}}

    \caption{Sensitivity analysis on simulation data of binary treatment setting}
    \label{fig:sensitivity}
\end{figure}

\subsection{Result and Analysis}
\subsubsection{Overall Performance}
Table \ref{tab:binary results} presents the MAE of estimated ATE under binary treatment setting,
while Table \ref{tab:continuous results} reports the AMSE of estimated ADCF under continuous treatment setting.
Overall,
our proposed method outperforms baselines, showing its effectiveness.
And several key observations can be drawn from the results:
\begin{itemize}
    \item Causal forest, Dragonnet and VCNet exhibit limited performance across all settings, 
    since their loss functions are designed for Gaussian distribution and therefore do not align with the actual outcome distributions in the datasets.
    \item Dragonnet(adapt) and VCNet(adapt) perform better because they replaced the MSE loss in the original model with the negative log-likelihood corresponding to the distribution. 
    For instance, the binary cross-entropy for the Bernoulli distribution ensures better alignment with the target distributions, leading to improved performance.
    \item Under the binary treatment setting, 
    DINA-learner outperforms other baselines,
    since it is specifically designed to handle exponential family outcomes based on the R-learner framework. 
    However, its partially linear assumption is relatively strong and may not be suitable for the datasets.
    \item Although no targeted regularization is applied, 
    Ours (w/o. t-reg) still performs better than Dragonnet (adapt) and VCNet (adapt), 
    indicating that the targeted regularization with distribution mismatch may degrade model performance.
    \item Ours achieves significant improvements across different settings,
    highlighting the effectiveness of the targeted regularization we designed for exponential family distributions.
\end{itemize}


\subsubsection{Sensitivity Analysis}
We take simulation dataset under binary treatment setting as an example to evaluate the sensitivity of the model to the parameter $\beta$, 
which controls the strength of the targeted regularization.
By varying the values of $\beta$,
we plot the results in Fig. (\ref{fig:sensitivity}).
We observe that the MAE slightly increase when $\beta$ becomes either too small or too large.
Specifically,
when $\beta$ is set too small, 
it fails to correct the confounding bias.
Conversely,
when $\beta$ is set too large, 
it interferes with the estimation of nuisance-function estimators, 
which are crucial for constructing the targeted regularization term.
However, 
although varying $\beta$ does affect the model's performance to some extent, the model still performs competitively compared to the baselines.

\section{Conclusion }
In this work,
we address the problem of how to design a NN-based targeted estimator for exponential family outcome.
Specifically,
we first derive the von-Mises expansion of ADCF to show the first-order bias term in plug-in estimator,
then we construct a doubly robust
estimator by subtracting the estimated bias term and analyze
its asymptotic properties.
Leveraging our theoretical findings,
we develop a NN-based estimator by generalizing functional targeted regularization to exponential families and give the theoretical convergence rates.
Extensive experimental results verify the correctness of our theory and the effectiveness of our model.

\section*{Impact Statement}
This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Proof of Lemma \ref{vonmiseexpansion}}\label{DIF}
\begin{proof}
We first derive the influence function using the Gateaux Derivative Approach in  \cite{kennedy2023semiparametricdoublyrobusttargeted}. Assume that $\bz$ is discrete and the influence function we gain is also well defined of another setup, for example, continuous or mixed, as long as regression functions $\pi(a|\bx)$ and $\mu(\bx, a)$. Let $\delta_{\bz} = \mathds{1}(\bZ=\bz)$ denote the Dirac measure at $\bZ=\bz$, one computes the Gateaux derivative 
\begin{equation*}
    \frac{\partial}{\partial \epsilon} \psi\left( (1-\epsilon) d \mathbb{P}(\bz) + \epsilon \delta_{\bz^{\prime}}\right)|_{\epsilon = 0}.
\end{equation*}
which equals the influence function $\phi_a(\bZ;\mP)$. Since $\bz$ is discrete, we can work with the mass function $p_{\epsilon}^*(\bz) = (1-\epsilon)p(\bz) + \epsilon \mathds{1}(\bZ=\bz)$.

First note that for the submodel $p_{\epsilon}^*(\bz)$ we have
\begin{align*}
    p^*_\epsilon(y \mid \bx, a) &= \frac{p^*_\epsilon(\bz)}{p^*_\epsilon(a,\bx)} = \frac{(1 - \epsilon)p(\bz) + \epsilon \mathds{1}(\bZ=\bz)}{(1 - \epsilon)p(a, \bx) + \epsilon \mathds{1}(A=a, \bX=\bx)} \\
    p^*_\epsilon(a \mid \bx) &= \frac{p^*_\epsilon(a, \bx)}{p^*_\epsilon(\bx)} = \frac{(1 - \epsilon)p(a, \bx) + \epsilon \mathds{1}(A=a, \bX=\bx)}{(1 - \epsilon)p(\bx) + \epsilon \mathds{1}(\bX=\bx)} \\
    p^*_\epsilon(\bx) &= (1 - \epsilon)p(\bx) + \epsilon \mathds{1}(\bX=\bx)
\end{align*}
and 

\begin{align*}
    \left. \frac{\partial}{\partial \epsilon} p^*_\epsilon(y \mid \bx, a) \right|_{\epsilon=0} 
    &= \frac{\mathds{1}(\bZ=\bz) - p(\bz)}{(1 - \epsilon)p(a, \bx) + \epsilon \mathds{1}(A = a, \bX=\bx)} \bigg|_{\epsilon=0} \\
    &\quad - p_\epsilon^*(y \mid x, a) \frac{\mathds{1}(A = a, \bX = \bx) - p(a, \bx)}{(1 - \epsilon)p(a, \bx) + \epsilon \mathds{1}(A = a, \bX = \bx)} \bigg|_{\epsilon=0} \\
    &= \frac{\mathds{1}(\bZ = \bz) - p(\bz)}{p(a, \bx)} - p(y \mid \bx, a) \frac{\mathds{1}(A = a, \bX = \bx) - p(a, \bx)}{p(a, \bx)} \\
    &= \mathds{1}(A = a, \bX = \bx) \left\{ \frac{\mathds{1}(Y = y) - p(y \mid \bx, a)}{p(a, \bx)} \right\}
\end{align*}

Note that $\mu(\bx,a) = \mathbb{E}[Y \mid \bX= \bx, A = a]$, $\pi(a \mid \bx) = \mathbb{P}(A=a|\bX=\bx)$, and $p(\bx) = \mathbb{P}(\bX=\bx)$. We evaluate the parameter on the submodel, differentiate, and set $\epsilon = 0$, which gives

\begin{align*}
    \left. \frac{\partial}{\partial \epsilon} \psi(p^*_\epsilon) \right|_{\epsilon=0} 
    &= \left. \frac{\partial}{\partial \epsilon} \sum_{\bx} h \left\{ \sum_{y} y \, p^*_\epsilon(y \mid \bx, a)\right\} \, p^*_\epsilon(\bx) \right|_{\epsilon=0} \\
    &= \sum_{\bx} \left\{\sum_{y} y \left\{ \left. \frac{\partial}{\partial \epsilon} p^*_\epsilon(y \mid \bx, a) \, \right\}p^*_\epsilon(x) h^{\prime} \left\{\sum_{y} y p^*_\epsilon(y \mid \bx, a) \right\} \right\} \right|_{\epsilon=0} \\
    &+ \left. \left\{h \left\{ \sum_{y} y \, p^*_\epsilon(y \mid \bx, a)\right\} \, \frac{\partial}{\partial \epsilon} p^*_\epsilon(\bx) \right\} \right|_{\epsilon=0} \\
    &= \sum_{x} \sum_{y} y \, \mathds{1}(A = a, \bX = \bx) \left\{ \frac{\mathds{1}(Y = y) - p(y \mid \bx, a)}{p(a, \bx)} \, p(\bx)\right\} h^{\prime} \left\{\sum_{y} y p_\epsilon(y \mid \bx, 1) \right\} \\
    &+ \sum_{x} h\left( \sum_{y} \left\{ y p(y \mid \bx, a) \right\} \left\{\mathds{1}(\bX = \bx) - p(\bx)\right\}\right)  \\
    &= \frac{\mathds{1}(A=a)}{\pi(a \mid \bX)} \left\{ Y - \mu(\bX,a)\right\} h^{\prime} (\mu(\bX,a)) + h( \mu(\bX, a))   - \psi_a
\end{align*}
Therefore, 
\begin{align*}
    \phi_a(\bZ;\mP) =& \frac{\mathds{1}(A=a)}{\pi(a \mid \bX)} \left\{ Y - \mu(\bX,a)\right\} h^{\prime} (\mu(\bX,a)) + h (\mu(\bX, a))   - \psi_a
\end{align*}

Then, by von Mises expansion
\begin{align*}
	\begin{split}
		R_2\left({\mathbb{\bar{P}}, \mathbb{P}}\right)&=\psi(\mathbb{\bar{P}})-\psi(\mathbb{P})+\int\phi_a(\boldsymbol{Z;\mathbb{\bar{P}}})d\mathbb{P} \\
		&=\int\left\{\frac{\mathds{1}_A}{\bar{\pi}(A|\boldsymbol{X})}h^\prime(\bar{\mu}(\boldsymbol{X},A))\left(Y-\bar{\mu}(\boldsymbol{X},A)\right)+h(\bar{\mu}(\boldsymbol{X},A))\right\}d\mathbb{P}-\psi(\mathbb{P})	 \\
		&=\int_{\mathcal{X}}\int_{\mathcal{Y}}\left\{h^\prime(\bar{\mu}(\boldsymbol{x},a))\left(\frac{y-\bar{\mu}(\boldsymbol{x},a)}{\bar{\pi}(\boldsymbol{x})}\right)+h(\bar{\mu}(\boldsymbol{x},a))\right\}p(y,\boldsymbol{x},a)dyd\boldsymbol{x}-\psi(\mathbb{P}) \\
		&=\int_{\mathcal{X}}\int_{\mathcal{Y}}\left\{h^\prime(\bar{\mu}(\boldsymbol{x},a))\left(\frac{y-\bar{\mu}(\boldsymbol{x},a)}{\bar{\pi}(\boldsymbol{x})}\right)\right\}p(y|\boldsymbol{x},a)\pi(a|\boldsymbol{x})p(\boldsymbol{x})dyd\boldsymbol{x}\\
        &+\int h(\bar{\mu}(\boldsymbol{x},a))d\mathbb{P}(\boldsymbol{x})-\psi(\mathbb{P}) \\
		&=\int\frac{\pi(a|\boldsymbol{x})}{\bar{\pi}(a|\boldsymbol{x})}\int_{\mathcal{Y}}\left\{h^\prime(\bar{\mu}(\boldsymbol{x},a))(y-\bar{\mu}(\boldsymbol{x},a))\right\}p(y|\boldsymbol{x},a)dyd\mathbb{P}(\boldsymbol{x})\\
        &+\int h(\bar{\mu}(\boldsymbol{x},a))d\mathbb{P}(\boldsymbol{x})-\psi(\mathbb{P}) \\
		&=\int\frac{\pi(a,\boldsymbol{x})}{\bar{\pi}(a,\boldsymbol{x})}h^\prime(\bar{\mu}(\boldsymbol{x},a))\left(\mu(\boldsymbol{x},a)-\bar{\mu}(\boldsymbol{x},a)\right)d\mathbb{P}(\boldsymbol{x}) \\
        &+\int\left(h(\bar{\mu}(\boldsymbol{x},a))-h(\mu(\boldsymbol{x},a))\right)d\mathbb{P}(\boldsymbol{x})
	\end{split}
\end{align*}

Note that $h(\mu(\boldsymbol{x},a))-h(\bar{\mu}(\boldsymbol{x},a))=h^\prime(\bar{\mu}(\boldsymbol{x},a))\left(\mu(\boldsymbol{x},a)-\bar{\mu}(\boldsymbol{x},a)\right)+\frac{1}{2}h^{\prime\prime}(\mu^\ast(\boldsymbol{x},a))\left(\mu(\boldsymbol{x},a)-\bar{\mu}(\boldsymbol{x},a)\right)^2$, where $\mu^\ast(\boldsymbol{x},a)$ lies between $\mu(\boldsymbol{x},a)$ and $\bar{\mu}(\boldsymbol{x},a)$, we have
\begin{equation*}
	\begin{split}
		R_2(\mathbb{\bar{P}}, \mathbb{P})&=\int h^\prime(\bar{\mu}(\boldsymbol{x},a))\left(\frac{\pi(a|\boldsymbol{x})}{\bar{\pi}(a|\boldsymbol{x})}-1\right)\left(\mu(\boldsymbol{x},a)-\bar{\mu}(\boldsymbol{x},a)\right)d\mathbb{P}(\boldsymbol{x})\\
        &+\frac{1}{2}\int h^{\prime\prime}(\mu^\ast (\boldsymbol{x},a))\left(\bar{\mu}(\boldsymbol{x},a)-\mu(\boldsymbol{x},a)\right)^2d\mathbb{P}(\boldsymbol{x})\\
	% 	&=\int\frac{h^\prime(\bar{\mu}(\boldsymbol{x},a))}{\bar{\pi}(a|\boldsymbol{x})}\left(\pi(a|\boldsymbol{x})-\bar{\pi}(a|\boldsymbol{x})\right)\left(\mu(\boldsymbol{x},a)-\bar{\mu}(\boldsymbol{x},a)\right)d\mathbb{P}(\boldsymbol{x})+\frac{1}{2}\int h^{\prime\prime}(\mu^\ast(\boldsymbol{x},a))\left(\bar{\mu}(\boldsymbol{x},a)-\mu(\boldsymbol{x},a)\right)^2d\mathbb{P}(\boldsymbol{x})
	\end{split}
\end{equation*}
\end{proof}


\section{Proof of Lemma \ref{asydistr}}\label{P2}
\begin{proof}
Since $(\mP_n - \mP)\left\{ \phi_a(\bZ;\mP) \right\}$ is root-n consistent and asymptotically normal by the central limit theorem, it suffices to show that if $\Vert \hat{\pi}(a|\bx) - \pi(a|\bx) \Vert = o_{\mP}(n^{-1/4})$ and $\Vert \hat{\mu}(a,\bx) - \mu(a,\bx) \Vert = o_{\mP}(n^{-1/4})$, then $R_2(\mathbb{\hat{P}}, \mathbb{P})=o_{\mP}(1/\sqrt{n})$. \\
By Lemma \ref{vonmiseexpansion}
\begin{align*}
R_2(\mathbb{\hat{P}}, \mathbb{P}) &= \int \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})} \left(\pi(a|\boldsymbol{x}) - \hat{\pi}(a|\boldsymbol{x})\right) \left(\mu(\boldsymbol{x},a) - \hat{\mu}(\boldsymbol{x},a)\right) d\mathbb{P}(\boldsymbol{x}) \\
&\quad + \frac{1}{2} \int h^{\prime\prime}(\mu^\ast(\boldsymbol{x},a)) \left(\hat{\mu}(\boldsymbol{x},a) - \mu(\boldsymbol{x},a)\right)^2 d\mathbb{P}(\boldsymbol{x})
\end{align*}
Therefore if $\hat{\pi}(a|\bx)\geq\varepsilon$ with probability one and $
\exists M_1, M_2 \, \text{such that} \, h^\prime(y) \leq M_1 \, \text{and} \, h^{\prime\prime}(y) \leq M_2, \, \forall y \in \mathcal{Y}$, we have
\begin{align*}
 ||R_2(\mathbb{\hat{P}}, \mathbb{P})|| &\leq \frac{M_1}{\varepsilon} \int (\pi(a|\bx) - \hat{\pi}(a|\bx))(\mu(\boldsymbol{x},a) - \hat{\mu}(\boldsymbol{x},a)) \, d\mathbb{P}(x) + \frac{M_2}{2} \int (\mu(\boldsymbol{x},a) - \hat{\mu}(\boldsymbol{x},a))^2 \, d\mathbb{P}(x) \\
& \leq \frac{M_1}{\varepsilon} ||\pi(a|\bx) - \hat{\pi}(a|\bx)||\ ||\mu(\boldsymbol{x},a) - \hat{\mu}(\boldsymbol{x},a)||+ \frac{M_2}{2}||\mu(\boldsymbol{x},a) - \hat{\mu}(\boldsymbol{x},a)||^2
\end{align*}
by Cauchy-Schwarz, which implies $R_2(\mathbb{\hat{P}}, \mathbb{P})=o_{\mP}(1/\sqrt{n})$ and 
\begin{align*}
    \hat{\psi}_a^{\text{dr}} - \psi_a(\bZ;\mP) = (\mP_n - \mP)\left\{ \phi_a(\bZ;\mP) \right\} + (\mP_n - \mP)\left\{ \phi_a(\bZ;\hat{\mP}) - \phi_a(\bZ;\mP) \right\} + R_2(\hat{\mP}, \mP)=o_{\mP}(1/\sqrt{n})
\end{align*}
by Slutsky's theorem.
\end{proof}

\section{Proof of Theorem \ref{targetedreg}}
\label{P3}
Let $R=\mathbb{P}(-Y\hat{\theta}+\kappa(\hat{\theta}))$, where $\hat{\theta}=h(\hat{\mu}(\bx,\cdot))+\frac{\epsilon(\cdot)}{\hat{\pi}(\cdot|\bx)} h^{\prime}( \hat{\mu} (\bx, \cdot))$, then we get 
$$\epsilon^*=\underset{\epsilon}{argmin} R= \mathbb{P}(\frac{(h(\mu(\boldsymbol{x},a))-h(\hat{\mu}(\boldsymbol{x},a)))\hat{\pi}(\bx|a)}{h^\prime(\hat{\mu}(\boldsymbol{x},a))})$$ through simple cauculation.\\
We define 

$$\check{\epsilon}_n=\mathbb{P}\left[\frac{\left(h(\mu) - h(\hat{\mu}_n)\right)}{\hat{\pi}_nh^{\prime}(\hat{\mu})} \mid A = \cdot\right]/ \mathbb{P}\left[\hat{\pi}_n^{-2} \mid A = \cdot\right],$$
then we have $\|\hat{\epsilon}_n - \check{\epsilon}_n\|_{L^2} = O_p\left(n^{-1/3} \sqrt{\log n}\right)$ following the proof of Lemma 3 from \cite{nie2021vcnet}. 

Using Taylor Expansion, we have
$$h(\mu)-h(\hat{\mu})=h^\prime(\hat{\mu})\left(\mu-\hat{\mu}\right)+\frac{1}{2}h^{\prime\prime}(\mu^\ast)\left(\mu-\hat{\mu}\right)^2,$$ 
where $\mu^\ast$ lies between $\mu$ and $\hat{\mu}$.

Thus, we have $$\check{\epsilon}_n=\mathbb{P}\left[\frac{\mu - \hat{\mu}_n}{\hat{\pi}_n} \mid A = \cdot\right]/ \mathbb{P}\left[\hat{\pi}_n^{-2} \mid A = \cdot\right]
+\mathbb{P}\left[\frac{1}{2}\frac{h^{\prime\prime}(\mu^\ast)(\mu-\hat{\mu})^2}{\hat{\pi}_nh^{\prime}(\hat{\mu})}\mid A = \cdot\right]/ \mathbb{P}\left[\hat{\pi}_n^{-2} \mid A = \cdot\right]:=\check{\epsilon}_1+\check{\epsilon}_2.$$

Setting $$\widehat{\psi}(\cdot)^{\text{tr}} = \frac{1}{n} \sum_{i=1}^{n} \left(h(\hat{\mu}(x_i, \cdot)) + \frac{\hat{\epsilon}_n(\cdot)}{\hat{\pi}(\cdot \mid x_i)}h^\prime(\hat{\mu}(x_i, \cdot)) \right),$$ 

we have 
\begin{align*}
    &\hat{\psi}_a^{\text{tr}} - \psi_a = \frac{1}{n} \sum_{i=1}^{n} \left( h (\hat{\mu}(\boldsymbol{x}_i, a)) + \frac{\hat{\epsilon}(a)h^\prime(\hat{\mu}(x_i, a))}{\hat{\pi}(a | \boldsymbol{x}_i)} - \psi_a \right) \\
    &\leq \left\| \hat{\epsilon}(a)\int_{\mathcal{X}}\frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d\mathbb{P}_n(\boldsymbol{x})-\mathbb{P}\left[\frac{\mathds{1}_A(Y-\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}h^\prime(\hat{\mu}(\boldsymbol{x},a))\right] \right\| \\
    &+ \left\| \mathbb{P} \left[ \mathds{1}_A \frac{Y - \hat{\mu}(\boldsymbol{x}, a)}{\hat{\pi}(a | \boldsymbol{x})} h'( \hat{\mu}(\boldsymbol{x}, a)) + h (\hat{\mu}(\boldsymbol{x}, a)) - \psi(a) \right] \right\| \\
    &+ \left\| \frac{1}{n} \sum_{i=1}^{n} h (\hat{\mu}(\boldsymbol{x}_i, a)) - \mathbb{P} \left( h (\hat{\mu}(\boldsymbol{x}, a)) \right) \right\| \\
    &:= T_1 + T_2 + T_3
\end{align*}

From condition (i), we have
\begin{align*}
    T_1&=\left\| \hat{\epsilon}(a)\int_{\mathcal{X}}\frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d\mathbb{P}_n(\boldsymbol{x})-\mathbb{P}\left[\frac{\mathds{1}_A(Y-\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}h^\prime(\hat{\mu}(\boldsymbol{x},a))\right] \right\| \\
       &= \left\| \hat{\epsilon}(a)\int_{\mathcal{X}}\frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d\mathbb{P}_n(\boldsymbol{x})-\pi(a)\mathbb{P}\left(\frac{Y-\hat{\mu}_n(\boldsymbol{x},a)}{\hat{\pi}_n(a,\boldsymbol{x})}\cdot h^\prime(\hat{\mu}(\boldsymbol{x},a))|A=a \right) \right\| \\
    &\le \left\|(\hat{\epsilon}(a)-\check{\epsilon}(a))\int_{\mathcal{X}} \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})} d\mathbb{P}_n(\boldsymbol{x}) \right\|+\left\|\check{\epsilon}_1(a)\left(\int_{\mathcal{X}} \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d\mathbb{P}_n(\boldsymbol{x})-\pi(a)\mathbb{P}\left[\frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}^2(a|\boldsymbol{x})}|A=a\right]     \right) \right\| \\ 
    &+\left\|\check{\epsilon}_2(a)\int_{\mathcal{X}} \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})} d\mathbb{P}_n(\boldsymbol{x}) \right\| \\
    &\lesssim \left\|\hat{\epsilon}-\check{\epsilon}\right\|+\left\|\check{\epsilon}(a)\left(\int_{\mathcal{X}} \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d(\mathbb{P}_n-\mathbb{P})(\boldsymbol{x})\right)\right\|\\
    &+\left\|\check{\epsilon}_1(a)\left(\int_{\mathcal{X}}\frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d\mathbb{P}(\boldsymbol{x})-\pi(a)\mathbb{P}\left[ \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}^2(a|\boldsymbol{x})}|A=a\right]\right)\right\| +\left\|\check{\epsilon}_2(a)\int_{\mathcal{X}} \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})} d\mathbb{P}(\boldsymbol{x}) \right\| \\
    &\lesssim \left\|\hat{\epsilon}-\check{\epsilon}\right\|+\left\|\check{\epsilon}(a)\left(\int_{\mathcal{X}} \frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d(\mathbb{P}_n-\mathbb{P})(\boldsymbol{x})\right)\right\|\\
    &+\left\|		\mathbb{P}\left(\frac{\mu(\boldsymbol{x},a)-\hat{\mu}_n(\boldsymbol{x},a)}{\hat{\pi}_n(a|\boldsymbol{x})}|A=a\right)\int_{\mathcal{X}}\frac{\hat{\pi}(a|\boldsymbol{x})-\pi(a|\boldsymbol{x})}{\hat{\pi}(a|\boldsymbol{x})}\frac{h^\prime(\hat{\mu}(\boldsymbol{x},a))}{\hat{\pi}(a|\boldsymbol{x})}d\mathbb{P}(\boldsymbol{x})\right\|\\
    &+\left\|		\mathbb{P}\left(\frac{h^{\prime\prime}( \mu^\ast(\boldsymbol{x},a))[\mu(\boldsymbol{x},a)-\hat{\mu}_n(\boldsymbol{x},a)]^2}{2\hat{\pi}_n(a|\boldsymbol{x})}|A=a\right)
    \int_{\mathcal{X}}\frac{1}{\hat{\pi}(a|\boldsymbol{x})}d\mathbb{P}(\boldsymbol{x})\right\|\\
    &=O_p(n^{-\frac{1}{3}}\sqrt{logn}+r_1(n)r_2(n)+r_2(n)^2)
\end{align*}
For the second term, \\
\begin{align*}
		T_2&=\left\|\mathbb{P}\left[\mathds{1}_A\frac{Y-\hat{\mu}(\boldsymbol{x},a)}{\hat{\pi}(a|\boldsymbol{x})}h^\prime(\hat{\mu}(\boldsymbol{x},a))+h(\hat{\mu}(\boldsymbol{x},a))-\psi(a)\right]\right\| \\
        &=\left\|\int\phi_a(z;\hat{p})+\hat{\psi}(a)-\psi(a)\right\| \\
		&=\left\|R_2(\hat{\mathbb{P}},\mathbb{P})\right\|
\end{align*}
From the proof of lemma \ref{asydistr}, we know $T_2=O_p(r_1(n)r_2(n)+r_2(n)^2)$. From generalization bound and assumption (iii), we have $T_3=O_p(r_1(n)r_2(n))$

Thus $\left\|\psi_a-\hat{\psi}_a^{\text{tr}}\right\|=O_p(n^{-\frac{1}{3}}\sqrt{logn}+r_1(n)r_2(n)+r_2(n)^2)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
