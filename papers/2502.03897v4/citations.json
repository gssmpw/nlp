[
  {
    "index": 0,
    "papers": [
      {
        "key": "cheng2024lova",
        "author": "Cheng, Xin and Wang, Xihua and Wu, Yihan and Wang, Yuyue and Song, Ruihua",
        "title": "LoVA: Long-form Video-to-Audio Generation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "choi2023foley",
        "author": "Choi, Keunwoo and Im, Jaekwon and Heller, Laurie and McFee, Brian and Imoto, Keisuke and Okamoto, Yuki and Lagrange, Mathieu and Takamichi, Shinosuke",
        "title": "Foley Sound Synthesis at the DCASE 2023 Challenge"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liu2021conditional",
        "author": "Liu, Xubo and Iqbal, Turab and Zhao, Jinzheng and Huang, Qiushi and Plumbley, Mark D and Wang, Wenwu",
        "title": "Conditional sound generation using neural discrete time-frequency representation learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "liu2023audioldm",
        "author": "Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D",
        "title": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "iashin2021taming",
        "author": "Iashin, Vladimir and Rahtu, Esa",
        "title": "Taming visually guided sound generation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "du2023conditional",
        "author": "Du, Yuexi and Chen, Ziyang and Salamon, Justin and Russell, Bryan and Owens, Andrew",
        "title": "Conditional generation of audio from video via foley analogies"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "luo2024diff",
        "author": "Luo, Simian and Yan, Chuanhao and Hu, Chenxu and Zhao, Hang",
        "title": "Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2024foleycrafter",
        "author": "Zhang, Yiming and Gu, Yicheng and Zeng, Yanhong and Xing, Zhening and Wang, Yuancheng and Wu, Zhizheng and Chen, Kai",
        "title": "Foleycrafter: Bring silent videos to life with lifelike and synchronized sounds"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "viertola2025temporally",
        "author": "Viertola, Ilpo and Iashin, Vladimir and Rahtu, Esa",
        "title": "Temporally aligned audio for video with autoregression"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "liu2024tell",
        "author": "Liu, Xiulong and Su, Kun and Shlizerman, Eli",
        "title": "Tell What You Hear From What You See--Video to Audio Generation Through Text"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2024frieren",
        "author": "Yongqi Wang and Wenxiang Guo and Rongjie Huang and Jiawei Huang and Zehan Wang and Fuming You and Ruiqi Li and Zhou Zhao",
        "title": "Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "lee2023aadiff",
        "author": "Lee, Seungwoo and Kong, Chaerin and Jeon, Donghyeon and Kwak, Nojun",
        "title": "Aadiff: Audio-aligned video synthesis with text-to-image diffusion"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhang2025audio",
        "author": "Zhang, Lin and Mo, Shentong and Zhang, Yijing and Morgado, Pedro",
        "title": "Audio-synchronized visual animation"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "lee2022sound",
        "author": "Lee, Seung Hyun and Oh, Gyeongrok and Byeon, Wonmin and Kim, Chanyoung and Ryoo, Won Jeong and Yoon, Sang Ho and Cho, Hyunjun and Bae, Jihyun and Kim, Jinkyu and Kim, Sangpil",
        "title": "Sound-guided semantic video generation"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "jeong2023power",
        "author": "Jeong, Yujin and Ryoo, Wonjeong and Lee, Seunghyun and Seo, Dabin and Byeon, Wonmin and Kim, Sangpil and Kim, Jinkyu",
        "title": "The power of sound (tpos): Audio reactive video generation with stable diffusion"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "yariv2024diverse",
        "author": "Yariv, Guy and Gat, Itai and Benaim, Sagie and Wolf, Lior and Schwartz, Idan and Adi, Yossi",
        "title": "Diverse and aligned audio-to-video generation via text-to-video model adaptation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "ramesh2022hierarchical",
        "author": "Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark",
        "title": "Hierarchical text-conditional image generation with clip latents"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "liu2024audioldm2",
        "author": "Liu, Haohe and Yuan, Yi and Liu, Xubo and Mei, Xinhao and Kong, Qiuqiang and Tian, Qiao and Wang, Yuping and Wang, Wenwu and Wang, Yuxuan and Plumbley, Mark D.",
        "title": "AudioLDM 2: Learning Holistic Audio Generation With Self-Supervised Pretraining"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ho2020denoising",
        "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
        "title": "Denoising diffusion probabilistic models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "peebles2023scalable",
        "author": "Peebles, William and Xie, Saining",
        "title": "Scalable diffusion models with transformers"
      }
    ]
  }
]