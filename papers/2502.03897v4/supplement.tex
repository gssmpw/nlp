\documentclass[11pt]{article}

% 基础包
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
% 页边距设置（根据会议要求调整）
\usepackage[margin=1in]{geometry}
\usepackage{float}
% 定理环境
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}

% 首页格式
\title{Supplementary Material for "UniForm: A Unified Multi-Task Diffusion Transformer for Audio-Video Generation"}
\author{}
\date{}

\begin{document}
\renewcommand{\thesection}{\Alph{section}}
\maketitle

\section*{Contents}
\begin{itemize}
    \item A: Additional Results and Visualizations
    \item B: Effects of Varying Inference Steps and Classifier-Free Guidance

\end{itemize}



\clearpage
\section{Additional Results and Visualizations}
\subsection{VGGSound}
\begin{table*}[ht]
    \centering
    \caption{A2V Comparisons on the VGGSound dataset.}
    \setlength{\tabcolsep}{3.6mm}
    \begin{tabular}{ccccccc}
    \toprule
    \textbf{Dataset} & \textbf{Method}  & \textbf{Use Text?} & \textbf{FVD}$\downarrow$ & \textbf{KVD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{AV-align}$\uparrow$\\
    \midrule
    \multirow{4}{*}{VGGSound}
                  & TempoToken [39]       &   \ding{55}   &  923    & -   &  11.04            & 0.350       \\
                  & TempoToken [39]      &   \ding{51}      &  859   & -   &   \textbf{11.66}             & 0.360       \\
                  % & Seeing\&Hearing \cite{yariv2024diverse}     &    \ding{51}    &  402           &  -            & \textbf{0.522}       \\
                  & UniForm (ours)   &       \ding{55}  &  271 & 14.54& 7.47 & \textbf{0.506}   \\ 
                  & UniForm (ours)   & \ding{51}       & \textbf{92} & \textbf{8.05}& 9.50 & 0.483  \\
    \bottomrule
    \end{tabular}
\label{tab:VGGSound: A2V}
\end{table*}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{sup_fig/demo_vgg_a2v.pdf}
    \caption{Generated samples in the A2V task on the VGGSound dataset.}
    \label{fig:vgg_a2v}
\end{figure}
The comparison results of V2A generation on the VGGSound dataset are presented in Table \ref{tab:VGGSound: A2V}. 
It can be seen that, in terms of the FVD and AV-align metrics, UniForm scores higher than TempoToken. Regarding the IS metric, the proposed method exhibits slightly inferior performance in comparison with TempoToken. Additionally, it can be observed that the introduction of text prompts has improved various performance metrics of UniForm, except for AV-align. Despite a slight reduction in the AV-align score, the incorporation of textual prompts demonstrates an overall significant enhancement in the quality of video generation. Figure \ref{fig:vgg_a2v} demonstrates two generated examples of
 V2A on the VGGSound dataset.


\clearpage
\begin{table*}[t]
    \caption{T2AV results on the VGGSound dataset.}
    \centering
    \setlength{\tabcolsep}{8mm}
    \begin{tabular}{ccccc}
        \toprule
        \textbf{Dataset}  & \textbf{FVD}$\downarrow$ & \textbf{KVD}$\downarrow$& \textbf{FAD}$\downarrow$ & \textbf{AV-align}$\uparrow$\\
        \midrule
        \multirow{1}{*}{VGGSound}
                       & 89  & 8.16&  1.82 &  0.374\\
        \bottomrule
    \end{tabular}
    \label{VGGSound: T2AV}
\end{table*}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sup_fig/demo_vgg_t2av.pdf}
    \caption{Generated samples in the T2AV task on the VGGSound dataset.}
    \label{fig:vgg_t2av}
\end{figure}
Table \ref{VGGSound: T2AV} presents the results of UniForm in the T2AV task on the VGGSound dataset. Figure \ref{fig:vgg_t2av} demonstrates two generated examples.


\clearpage
\subsection{Landscape}

\begin{table*}[ht]
    \centering
    \caption{V2A Comparisons on the Landscape dataset.}
    \setlength{\tabcolsep}{1.65mm}
    \begin{tabular}{cccccccc}
    \toprule
    \textbf{Dataset} & \textbf{Method} & \textbf{Text Type} & \textbf{FAD}$\downarrow$ & \textbf{FD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{KL}$\downarrow$ & \textbf{AV-align} $\uparrow$ \\
    \midrule
    \multirow{3}{*}{Landscape}
                  & Seeing\&Hearing [37]      & Caption  &  7.61 & 39.67  & 4.04 &  3.44 & -    \\
                  & UniForm (ours)  & Label  & \textbf{2.25}    & \textbf{9.56}   & 3.29    &  \textbf{1.39} & 0.354  \\
                  & UniForm (ours)  & \ding{55}  & 4.81    & 13.24 & \textbf{4.43}    &  2.66& \textbf{0.553}\\
    \bottomrule
    \end{tabular}
    \label{tab:landscape_v2a}
\end{table*}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{sup_fig/demo_landscape_v2a.pdf}
    \caption{Generated samples in the V2A task on the Landscape dataset.}
    \label{fig:landscape_v2a}
\end{figure}
Table \ref{tab:landscape_v2a} presents a comparison between UniForm and Seeing\&Hearing on the V2A task using the Landscape dataset. The textual prompts employed in Seeing and Hearing are derived from a Vision Language Model, whereas our proposed method utilizes the class labels of the dataset. As can be seen from the table, UniForm outperforms the compared methods across most metrics, irrespective of the use of text prompts.
%Additionally, the table reveals that textual prompts seem to negatively impact audio generation in this scenario, a phenomenon not observed in the results from other datasets or tasks. We hypothesize that this might be attributed to the poor audio quality inherent in the landscape dataset, which could have compromised the accuracy of the experimental results. Figure \ref{fig:landscape_v2a} shows several generation examples on this task.

\clearpage
\subsection{AIST++}
\begin{table*}[ht]
    \centering
    \caption{Results on the AIST++ dataset.}
    \setlength{\tabcolsep}{2.6mm}
    \begin{tabular}{cccccccc}
    \toprule
    \textbf{Dataset} & \textbf{Task} & \textbf{Use Text?} & \textbf{FAD}$\downarrow$ & \textbf{FD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{KL}$\downarrow$ & \textbf{AV-align}$\uparrow$ \\
    \midrule
    \multirow{5}{*}{ AIST++}
    & \multirow{2}{*}{V2A} & \ding{51} & 1.29 & 6.19& 1.17& 1.03& 0.295\\
  & & \ding{55} & 1.88& 8.45& 1.15& 1.22 & 0.294\\\cline{2-8}
     & \textbf{Task} & \textbf{Use Text?} & \textbf{FVD}$\downarrow$  &  \textbf{KVD}$\downarrow$& \textbf{IS}$\uparrow$ & \textbf{AV-align}$\uparrow$ & \\
    \cline{2-8}
    & \multirow{2}{*}{A2V} & \ding{51} & 77& 17.37& 1.40& 0.286&   \\
  & & \ding{55} & 129& 44.42& 1.36& 0.275& \\
    \bottomrule
    \end{tabular}
    \label{tab:AIST++}
\end{table*}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{sup_fig/aist++_tv2a.pdf}
    \caption{Generated samples in the V2A task on the AIST++ dataset.}
    \label{fig:aist_v2a}
\end{figure}
Table \ref{tab:AIST++} presents the results of UniForm in the V2A and A2V tasks on the AIST++ dataset. Figure \ref{fig:aist_v2a} and \ref{fig:aist_a2v} demonstrates generated examples of the two tasks.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{sup_fig/aist++_ta2v.pdf}
    \caption{Generated samples in the A2V task on the AIST++ dataset.}
    \label{fig:aist_a2v}
\end{figure}



\clearpage
\subsection{AudioSet}
% \subsubsection{AudioSet-Strong}

% \clearpage
% \subsubsection{AudioSet Eval}
\begin{table*}[ht]
    \centering
    \caption{Results on the AudioSet dataset.}
    \setlength{\tabcolsep}{1.3mm}
    \begin{tabular}{cccccccc}
    \toprule
    \textbf{Dataset} & \textbf{Task} & \textbf{Use Text?} & \textbf{FAD}$\downarrow$ & \textbf{FD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{KL}$\downarrow$ &\textbf{AV-align}$\uparrow$\\
    \midrule
    \multirow{7}{*}{ AudioSet}
    & \multirow{2}{*}{V2A} & \ding{51} &1.38 & 6.60& 14.78&  2.65& 0.420\\
  & & \ding{55}   & 2.94& 13.90& 5.99& 3.37& 0.432\\    \cline{2-8}
     & \textbf{Task} & \textbf{Use Text?} & \textbf{FVD}$\downarrow$  & \textbf{KVD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{AV-align}$\uparrow$ &\\
    \cline{2-8}
    & \multirow{2}{*}{A2V} & \ding{51} &75 &6.70 & 9.53&  0.452&\\
  & & \ding{55}   & 259 & 14.16 & 7.42&  0.471&\\\cline{2-8}
    & \textbf{Task} & \textbf{FVD}$\downarrow$  & \textbf{KVD}$\downarrow$& \textbf{FAD}$\downarrow$ & \textbf{AV-align}$\uparrow$ & \\\cline{2-8}
    & {T2AV} & 75& 7.24& 1.94&0.363 &  &\\
    \bottomrule
    \end{tabular}
    \label{AudioSet Eval}
\end{table*}
% \begin{table*}[ht]
%     \centering
%     \caption{Results on the AudioSet dataset.}
%     \setlength{\tabcolsep}{1.mm}
%     \begin{tabular}{cccccccc}
%     \toprule
%     \textbf{Dataset} & \textbf{Task} & \textbf{Use Text?} & \textbf{FAD}$\downarrow$ & \textbf{FD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{KL}$\downarrow$ &\textbf{AV-align}$\uparrow$\\
%     \midrule
%     \multirow{7}{*}{AudioSet}
%     & \multirow{2}{*}{V2A} & \ding{51} & 1.31&7.13 & 14.27& 2.51& 0.402\\
%   & & \ding{55} & 3.03& 14.95& 5.93& 3.22&0.415\\    \cline{2-8}
%      & \textbf{Task} & \textbf{Use Text?} & \textbf{FVD}$\downarrow$ & \textbf{KVD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{AV-align}$\uparrow$ \\
%     \cline{2-8}
%     & \multirow{2}{*}{A2V} & \ding{51} & 87& 7.26& 9.44& 0.471&  \\
%   & & \ding{55}  & 259& 13.77& 7.38& 0.493& \\\cline{2-8}
%     & \textbf{Task} & \textbf{FVD}$\downarrow$ &\textbf{KVD}$\downarrow$ & \textbf{FAD}$\downarrow$ & \textbf{AV-align}$\uparrow$ & &\\\cline{2-8}
%     & {T2AV} & 85 & 7.42& 1.77& 0.388& &\\
%     \bottomrule
%     \end{tabular}
%     \label{AudioSet}
% \end{table*}

Table \ref{AudioSet Eval} presents the results of UniForm on the AudioSet dataset across different tasks. Some visualizations on this dataset are presented as follows.
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.6\textwidth]{sup_fig/demo_strong_1.pdf}
%     % \caption{A generated sample on the AudioSet-Strong dataset.}
%     \label{fig:strong_1}
% \end{figure}
% Table \ref{AudioSet-Strong} presents the results of UniForm on the AudioSet-Strong dataset across different tasks. Some generation examples of UniForm on AudioSet-Strong are illustrated in Figure \ref{fig:strong_1}, \ref{fig:strong_2}, and \ref{fig:strong_3}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{sup_fig/demo_balanced_3.pdf}
    % \caption{A generated sample on the AudioSet Eval dataset.}
    \label{fig:audioset_3}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{sup_fig/demo_strong_2.pdf}
    % \caption{A generated sample on the AudioSet-Strong dataset.}
    \label{fig:strong_2}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{sup_fig/demo_strong_3.pdf}
    % \caption{A generated sample on the AudioSet-Strong dataset.}
    \label{fig:strong_3}
\end{figure}




% \clearpage
% \subsubsection{AudioSet Eval}
% \begin{table*}[ht]
%     \centering
%     \caption{Results on the AudioSet Eval dataset.}
%     \setlength{\tabcolsep}{1.3mm}
%     \begin{tabular}{cccccccc}
%     \toprule
%     \textbf{Dataset} & \textbf{Task} & \textbf{Use Text?} & \textbf{FAD}$\downarrow$ & \textbf{FD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{KL}$\downarrow$ &\textbf{AV-align}$\uparrow$\\
%     \midrule
%     \multirow{7}{*}{ AudioSet Eval}
%     & \multirow{2}{*}{V2A} & \ding{51} &1.38 & 6.60& 14.78&  2.90& 0.398\\
%   & & \ding{55}   & 2.94& 13.90& 5.99& 3.37& 0.390\\    \cline{2-8}
%      & \textbf{Task} & \textbf{Use Text?} & \textbf{FVD}$\downarrow$  & \textbf{KVD}$\downarrow$ & \textbf{IS}$\uparrow$ & \textbf{AV-align}$\uparrow$ &\\
%     \cline{2-8}
%     & \multirow{2}{*}{A2V} & \ding{51} &77 &7.12 & 9.53&  0.466&\\
%   & & \ding{55}   & 264 & 13.90 & 7.42&  0.486&\\\cline{2-8}
%     & \textbf{Task} & \textbf{FVD}$\downarrow$  & \textbf{KVD}$\downarrow$& \textbf{FAD}$\downarrow$ & \textbf{AV-align}$\uparrow$ & \\\cline{2-8}
%     & {T2AV} & 78& 7.51& 1.94&0.367 &  &\\
%     \bottomrule
%     \end{tabular}
%     \label{AudioSet Eval}
% \end{table*}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{sup_fig/demo_balanced_1.pdf}
    % \caption{A generated sample on the AudioSet Eval dataset.}
    \label{fig:audioset_1}
\end{figure}
% Table \ref{AudioSet Eval} presents the results of UniForm across various tasks on the AudioSet Eval dataset. Figures \ref{fig:audioset_1}, \ref{fig:audioset_2}, and \ref{fig:audioset_3} demonstrate several generated examples on this dataset.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{sup_fig/demo_balanced_2.pdf}
    % \caption{A generated sample on the AudioSet Eval dataset.}
    \label{fig:audioset_2}
\end{figure}




\clearpage
\section{Effects of Varying Inference Steps and Classifier-Free Guidance}

\begin{table}[h]
    \centering
    \caption{Effect of inference steps and classifier-free guidance on FAD and FVD.}
    \setlength{\tabcolsep}{1mm}
    \begin{tabular}{c|c|cc|c|c|c|cc|c|c}
    \toprule
    \multirow{3}{*}{\textbf{Model}} & \multicolumn{5}{c|}{\textbf{Steps}} & \multicolumn{5}{c}{\textbf{Guidance}} \\
    \cline{2-11}
    & \multirow{2}{*}{\textbf{Steps}} & \multicolumn{2}{c|}{\textbf{T2AV}} &\textbf{V2A}  & \textbf{A2V}   & \multirow{2}{*}{\textbf{Guidance}} & \multicolumn{2}{c|}{\textbf{T2AV}} & \textbf{V2A}  & \textbf{A2V} \\
    \cline{3-6}\cline{8-11}
    &   & \textbf{FAD} $\downarrow$ & \textbf{FVD} $\downarrow$ & \textbf{FAD} $\downarrow$ & \textbf{FVD} $\downarrow$&  
     & \textbf{FAD} $\downarrow$ & \textbf{FVD} $\downarrow$ & \textbf{FAD} $\downarrow$ & \textbf{FVD} $\downarrow$ \\
    \hline
    \multirow{5}{*}{UniForm} 
    & 10 & 3.35 & 184 & 3.26& 261 & 3 & 2.79 & 353  & 2.51 &325\\
    & 20 & 2.51 & 186 & 2.50 & 223 & 4 & 2.65 & 223  & \textbf{2.15} &240\\
    & 30 & 2.35 & \textbf{181} & 2.25 & \textbf{219} & 5 & \textbf{2.35} & \textbf{181} & 2.25 &\textbf{219}\\
    & 40 & 2.25 & 182 & 2.28 & 227 & 6 & 2.90 & 204 & 2.53 &235\\
    & 50 & \textbf{2.21} & 193 & \textbf{2.20} & 230 & 7 & 3.36 & 239 & 2.46 &240\\
    \bottomrule
    \end{tabular}

    \label{tab:is_and_cfg}
\end{table}
Table \ref{tab:is_and_cfg} demonstrates the effects of varying the number of inference steps and classifier-free guidance scales on the Landscape dataset. It can be observed that as the number of inference steps increases, the quality of audio generation gradually improves, whereas the video generation quality does not exhibit similarly significant changes. Additionally, both audio and video generation quality reach their optimal performance when the classifier-free guidance scale is set to 5. In summary, the highest quality of generated audio and video is achieved with 30 inference steps and a guidance scale of 5.


\end{document}