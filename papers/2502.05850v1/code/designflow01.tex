\begin{lstlisting}[float=tp,emph={with},emphstyle={\bfseries}, language=Python, caption=The implementation of the pruning strategy using our framework., label=code:strategy]
# The pruning strategy architecture - Fig. 2(a)
from MetaML import * 
# design-flow architecture
with Dataflow() as df:
    join = Join() << KerasModelGen() 
    branch = Branch('B') << (VivadoHLS() << 
             (HLSML() << (Pruning() << join)))

    branch >> [join, Stop()]
# design-flow configuration
cfg = {
    'KerasModelGen::train_en': False,
    'Pruning::tolerate_accuracy_loss': 0.02,
    'Pruning::pruning_rate_threshold': 0.02,
    'B@fn': lambda metamodel:...
    'HLS4ML::default_precision': 'ap_fixed<18,8>',
    'HLS4ML::IOType': 'io_parallel',
    'HLS4ML::FPGA_part_number': 'xc7z020clg400-1',
    'HLS4ML::clock_period' : 10,
    'train_test_dataset': '/mypath/target_dataset',
    'train_epochs': 15,
    'Stop::fn': lambda metamodel: ... 
}
# run design-flow  
optimised_model = df.run(cfg)
\end{lstlisting}
%\vspace{-0.5cm}