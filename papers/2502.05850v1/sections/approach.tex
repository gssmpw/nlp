%\newpage
\section{Our Approach} \label{sec:approach}


\begin{figure}
\begin{center}
\includegraphics[width=1.00\linewidth]{img/designflow_v02.pdf}
\end{center}
%\vspace{-0.5cm}
   \caption{A typical FPGA design flow. This FPGA design flow begins with defining the specifications (SPEC), followed by implementing and testing the design in software (SW). If High-Level Synthesis (HLS) is used, high-level code (e.g., C/C++) is converted into hardware description language (HDL). The design then moves to the Register Transfer Level (RTL) stage, where it is described in HDL (e.g., Verilog/VHDL) and synthesized into a netlist of logic gates. Finally, the netlist is used to generate a bitstream, which is loaded onto the FPGA to configure the hardware. Each stage progressively refines the design from concept to implementation.}
\label{fig:designflow}
\end{figure}



\subsection{Overview}

In this paper, we introduce a novel framework for creating customizable design-flows that optimize FPGA-based DNNs, with a focus on automating both top-down and bottom-up flows between application and hardware optimization stages.

A design-flow represents a sequence of tasks that convert a high-level specification into a final hardware design. A design-flow is typically implemented as a multi-stage pipeline, with each stage operating on a specific model abstraction. As the pipeline progresses, the model abstraction is gradually reduced and optimized, taking into account the features of the target device. For example, a typical design-flow targeting FPGAs is shown in Fig.~\ref{fig:designflow}. It begins with defining specifications (SPEC) and testing the design in software (SW). If High-Level Synthesis (HLS) is used, a high-level DNN model, such as one described in TensorFlow, can be translated into a C++ HLS model using tools like HLS4ML. This model is then converted into an RTL description (e.g., Verilog/VHDL) using tools like Vivado HLS. The RTL model is further synthesized into a netlist, which is optimized for the FPGAâ€™s architecture, and finally translated into a bitstream that configures the FPGA hardware. 

Feedback information can be utilized to enable lower-stage information to refine higher-stage optimizations, employing more accurate metrics that were previously unavailable. We have developed a framework that allows users to codify fully automated optimizing design-flows with the following requirements:

\begin{itemize}

\item \textbf{Customizable}: Refers to the ability for users to customize, extend, or modify the design-flow to meet specific needs and support experimentation. Users can select a set of building tasks that implement optimization, transformation, or control tasks, combine them in a specific order, and fine-tune their parameters to generate a specific optimization flow. Additionally, they can create their own tasks and integrate them into their design-flow (see~\textbf{C1});

\item \textbf{Multi-level}: Refers to the scope of optimizations and the ability to target multiple levels of abstraction, typically associated with different stages of a design-flow. For instance, optimizations operating at the Neural Network level are performed at the graph-level, while optimizations at the HLS C++ level are performed using source-level transformations (see~\textbf{C1});

\item \textbf{Cross-stage}: Refers to the capability of a design-flow to support top-down and bottom-up flows between optimization stages, such as software and hardware, respectively (see~\textbf{C2}).

\end{itemize}

This work focuses on custom optimizations in the SW and HLS stages while using default configuration for the remaining stages, however, the same concepts can be extended to the other stages, which is left for future work.

% https://docs.google.com/drawings/d/1bM5SfGFCLphPfhn4y5qVFLgVVid5uaNU2gvQ-pYel2g/edit?usp=share_link
%https://docs.google.com/drawings/d/1Q3OecTlaum0nm7jHnb-WjoVvjxdLRfSM1q2jYUton2g/edit
% a, b

%


\subsection{Architecture}

 Fig.~\ref{fig:pipetasks} illustrates the key architectural components of a programmatically generated design flow using our approach, which comprises two main components: the pipe task and the meta-model.

The pipe task is the fundamental building block of the design flow and is responsible for implementing specific a task, such as optimization or control. By connecting pipe tasks, we  create a complete design flow. The design flow's internal architecture is represented by a cyclic directed graph, where nodes represent tasks, and edges represent \textbf{paths} between tasks. A path represents a dependency between two tasks, such that a task can only be executed if its dependencies have finished executing.

% (b) https://docs.google.com/drawings/d/1zdDvCgE3crP20FHWQHt9elGQY99qnCR-Yksse5a9rPo/edit?usp=sharing


\begin{figure}[tp]
   \centering
%  \subfloat[]{%
%    \includegraphics[width=0.2\linewidth]{img/pipeblocks_a_trets_v01.pdf}}
%   \\
%   \vspace{-0.5cm}
%   \subfloat[]{%
    \includegraphics[width=0.8\linewidth]{img/pipeblocks_b_trets_v01.pdf}
%}
  %\vspace{0.2cm}
  \caption{A connection between a $O$-task and a $K$-task. A pipe task has a uniform interface allowing any two pipe tasks to be connected (although there may be constraints about how many connections a task can handle). A $O$-task typically enhances DNN models based on specific objectives and constraints. A $K$-task on the other hand, manages the control flow. Each connection defines a unidirectional stream between a source task and a target task.}
  \label{fig:pipetasks} 
\end{figure}



The meta-model, on the other hand, is responsible for storing all of the design flow's states, including the configuration parameters of each pipe task and their respective outputs. Instead of communicating directly with each other, pipe tasks share information through the meta-model, which serves as a shared space. The meta-model has three sections, as illustrated in Fig.~\ref{fig:pipetasks}(b): configuration, log and model space.

The configuration section (\textbf{CFG}) is a key-value store that keeps the parameters of all pipe tasks in the design flow. These parameters can configure all pipe tasks of the same type or specific instances, and they can be supplied by the user or automatically modified by the pipe tasks as part of an automated tuning process.
The log section (\textbf{LOG}) stores the runtime execution trace of the design flow. This section can be useful for debugging and understanding the execution flow of the design.

Finally, the \textbf{model space} stores the models generated during the execution of a design flow. Each stored model is versioned, and models derived by different stages can coexist in the same model space. In the example shown in the figure, we have stored six models covering three abstraction levels: DNN, HLS C++ , and RTL. Each model in the model space encapsulates all its supporting files, tool reports, and computed metrics. Moreover, they can be accessed and manipulated by any pipe task in the design flow, enabling cross-stage optimizations.

\input{tables/pipetasks05.tex}

\subsection{Reusable Pipe Tasks}

Table~\ref{table:pipetasks} presents a list of pipe tasks that have been implemented in our approach, along with their roles, multiplicity, and parameters. The multiplicity denotes the number of input and output channels that a task can handle. We classify pipe tasks into three types based on their roles:

\begin{itemize}

\item \textbf{$K$-task}: These are generic tasks that control top-down and bottom-up flows. Examples include: BRANCH, which selects an output path at runtime based on a boolean condition; JOIN, which merges multiple paths into one; FORK, which allows multiple concurrent strategy paths; REDUCE, which consolidates the results of multiple strategy paths into one; and STOP, which terminates the design flow;

\item \textbf{$O$-task}: These are self-contained optimizing tasks that enhance deep learning models based on specific objectives and constraints. Our current pipe task repository includes PRUNING and SCALING, which are implemented using the Keras API (version 2.9.0), and QUANTIZATION, which is performed using C++ source-to-source transformations via the Artisan framework~\cite{fccm20_artisan};

\item \textbf{$\lambda$-task}: These tasks perform functional transformations on the model space, such as compilation and synthesis. Examples include HLS4ML (version 0.6.0), which translates a DNN model into an HLS C++ model, and Vivado HLS (version 20.1), which translates an HLS C++ model into an RTL model.

\end{itemize}

It is worth noting that our framework is customizable, allowing users to create and integrate their own pipe tasks tailored to their specific needs.

\subsection{Building a Strategy}


\input{code/designflow01}

Listing.\ref{code:strategy} provides the Python code for implementing the pruning strategy depicted in Fig.\ref{fig:design_flow}(a) and discussed in Section~\ref{sec:single_opt}. The code consists of three sections: \textbf{(i)}~lines 4--9 builds the design-flow architecture graph by connecting the corresponding tasks. The $>>$ and $<<$ operators are utilized to define the connections between task instances, and the default name of each task instance serves as its identifier, although it can be overridden by providing it as an argument (line 6). The end result is a cyclic-directed graph. \textbf{(ii)}~lines 11--23 define the configuration object, which holds all the parameters for configuring the tasks. Parameters referred to as \texttt{TaskType::parameter} are passed to all tasks of that task type (lines~16--19), whereas parameter names in the format of \texttt{InstanceName@parameter} are passed to a specific instance (line 15). All other parameters are global (lines 20--21) and accessible to any task.  Finally, \textbf{(iii}) line~25 executes the design-flow by passing the configuration object.

% This is done by first creating a context using the $with$ operator, which generates a \texttt{Dataflow} object that contains all the pipe tasks and their connections. 

The execution of the design-flow starts with graph validation, which ensures that there is at least one source task and no multiplicity constraints are violated. Tasks are executed by an internal scheduler using a thread pool, which assigns jobs to available workers or stalls until a worker becomes available. After validating the architecture graph, an empty meta-model is generated using the supplied configuration, and the scheduler runs the source task. When a task completes execution, it submits a job to execute the next set of tasks in the flow. The STOP task terminates execution when all submitted jobs are completed. Modifying the design-flow architecture and updating its configuration parameters can lead to new optimization strategies, which is discussed next.


% \subsection{User defined tasks}
% fccm reviewer A says: "I like the idea, particularly if it allows the user to define and implemnt their own lambda- and kappa- pipe tasks to add to the meta-models. "
% So it might be better to add one more section to highlight that these tasks can be user-defined.