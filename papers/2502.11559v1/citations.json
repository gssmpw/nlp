[
  {
    "index": 0,
    "papers": [
      {
        "key": "li2023survey",
        "author": "Li, Yingji and Du, Mengnan and Song, Rui and Wang, Xin and Wang, Ying",
        "title": "A survey on fairness in large language models"
      },
      {
        "key": "zayed2024fairness",
        "author": "Zayed, Abdelrahman and Mordido, Gon{\\c{c}}alo and Shabanian, Samira and Baldini, Ioana and Chandar, Sarath",
        "title": "Fairness-aware structured pruning in transformers"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "kurita2019measuring",
        "author": "Kurita, Keita and Vyas, Nidhi and Pareek, Ayush and Black, Alan W and Tsvetkov, Yulia",
        "title": "Measuring bias in contextualized word representations"
      },
      {
        "key": "may2019measuring",
        "author": "May, Chandler and Wang, Alex and Bordia, Shikha and Bowman, Samuel R and Rudinger, Rachel",
        "title": "On measuring social biases in sentence encoders"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "nangia2020crows",
        "author": "Nangia, Nikita and Vania, Clara and Bhalerao, Rasika and Bowman, Samuel R",
        "title": "CrowS-pairs: A challenge dataset for measuring social biases in masked language models"
      },
      {
        "key": "nadeem2020stereoset",
        "author": "Nadeem, Moin and Bethke, Anna and Reddy, Siva",
        "title": "StereoSet: Measuring stereotypical bias in pretrained language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "levy2021collecting",
        "author": "Levy, Shahar and Lazar, Koren and Stanovsky, Gabriel",
        "title": "Collecting a large-scale gender bias dataset for coreference resolution and machine translation"
      },
      {
        "key": "kotek2023gender",
        "author": "Kotek, Hadas and Dockum, Rikker and Sun, David",
        "title": "Gender bias and stereotypes in large language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "feng2023pretraining",
        "author": "Feng, Shangbin and Park, Chan Young and Liu, Yuhan and Tsvetkov, Yulia",
        "title": "From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair NLP models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wan2023kelly",
        "author": "Wan, Yixin and Pu, George and Sun, Jiao and Garimella, Aparna and Chang, Kai-Wei and Peng, Nanyun",
        "title": "\" kelly is a warm person, joseph is a role model\": Gender biases in llm-generated reference letters"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "de2019bias",
        "author": "De-Arteaga, Maria and Romanov, Alexey and Wallach, Hanna and Chayes, Jennifer and Borgs, Christian and Chouldechova, Alexandra and Geyik, Sahin and Kenthapadi, Krishnaram and Kalai, Adam Tauman",
        "title": "Bias in bios: A case study of semantic representation bias in a high-stakes setting"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "bartl2024showgirls",
        "author": "Bartl, Marion and Leavy, Susan",
        "title": "From'Showgirls' to'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs"
      },
      {
        "key": "dong2024disclosure",
        "author": "Dong, Xiangjue and Wang, Yibo and Yu, Philip S and Caverlee, James",
        "title": "Disclosure and mitigation of gender bias in llms"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "raza2024mbias",
        "author": "Raza, Shaina and Raval, Ananya and Chatrath, Veronica",
        "title": "MBIAS: Mitigating Bias in Large Language Models While Retaining Context"
      },
      {
        "key": "thakur2023language",
        "author": "Thakur, Himanshu and Jain, Atishay and Vaddamanu, Praneetha and Liang, Paul Pu and Morency, Louis-Philippe",
        "title": "Language models get a gender makeover: Mitigating gender bias with few-shot data interventions"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zhang2024genderalign",
        "author": "Zhang, Tao and Zeng, Ziqian and Xiao, Yuxiang and Zhuang, Huiping and Chen, Cen and Foulds, James and Pan, Shimei",
        "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models"
      },
      {
        "key": "allam2024biasdpo",
        "author": "Allam, Ahmed",
        "title": "BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "cai2024locating",
        "author": "Cai, Yuchen and Cao, Ding and Guo, Rongxi and Wen, Yaqin and Liu, Guiquan and Chen, Enhong",
        "title": "Locating and mitigating gender bias in large language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "anonymous2024Editbias",
        "author": "Anonymous",
        "title": "EDITBIAS: Debiasing Stereotyped Language Models via Model Editing"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "brown2020language",
        "author": "Brown, Tom B",
        "title": "Language models are few-shot learners"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "sant2024power",
        "author": "Sant, Aleix and Escolano, Carlos and Mash, Audrey and Fornaciari, Francesca De Luca and Melero, Maite",
        "title": "The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs"
      },
      {
        "key": "ganguli2023capacity",
        "author": "Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas I and Luko{\\v{s}}i{\\=u}t{\\.e}, Kamil{\\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others",
        "title": "The capacity for moral self-correction in large language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "si2022prompting",
        "author": "Si, Chenglei and Gan, Zhe and Yang, Zhengyuan and Wang, Shuohang and Wang, Jianfeng and Boyd-Graber, Jordan and Wang, Lijuan",
        "title": "Prompting gpt-3 to be reliable"
      },
      {
        "key": "dwivedi2023breaking",
        "author": "Dwivedi, Satyam and Ghosh, Sanjukta and Dwivedi, Shivam",
        "title": "Breaking the bias: Gender fairness in LLMs using prompt engineering and in-context learning"
      },
      {
        "key": "oba2024contextual",
        "author": "Oba, Daisuke and Kaneko, Masahiro and Bollegala, Danushka",
        "title": "In-Contextual Gender Bias Suppression for Large Language Models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhou2022large",
        "author": "Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy",
        "title": "Large language models are human-level prompt engineers"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "cheng2023black",
        "author": "Cheng, Jiale and Liu, Xiao and Zheng, Kehan and Ke, Pei and Wang, Hongning and Dong, Yuxiao and Tang, Jie and Huang, Minlie",
        "title": "Black-box prompt optimization: Aligning large language models without model training"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "sheng2020towards",
        "author": "Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun",
        "title": "Towards controllable biases in language generation"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "bauer2024believe",
        "author": "Bauer, Lisa and Mehrabi, Ninareh and Goyal, Palash and Chang, Kai-Wei and Galstyan, Aram and Gupta, Rahul",
        "title": "BELIEVE: Belief-enhanced instruction generation and augmentation for zero-shot bias mitigation"
      }
    ]
  }
]