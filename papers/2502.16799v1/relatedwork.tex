\section{Related Works}
{Benefiting from the universal approximation capability, deep neural networks (DNNs) have been acting as the workhorse in existing learnt image compression methods. Thus, we first review the methods that dominantly focus on the pixel-wise accuracy, followed by the methods for optimising the perceptual quality assisted by generative models. Regarding the emerging trends on compressing pre-defined semantics, we finally review the semantic compression methods. We visualise their distinct difference and highlight our novelty  in Fig. \ref{fig:introduction}.}

\subsection{Pixel-wise Accuracy Oriented Compression}

{Indeed, existing standard compression codecs evolved by consistently improving the mean squared error (MSE), including JPEG \cite{marcellin2000overview}, H.264/AVC \cite{wiegand2003overview}, H.265/HEVC \cite{sullivan2012overview} and H.266/VVC \cite{bross2021overview}. During the past decade, DNN-based image compression has achieved remarkable progress by jointly optimizing the rate-distortion performance, in which the pixel-wise accuracy was dominantly considered by the distortion metrics. To the best of our knowledge, Toderici \textit{et al.} proposed the first end-to-end image compression algorithm in 2015, which developed a recurrent neural network to iteratively encode image residuals \cite{toderici2015variable}; this method has surpassed JPEG when compressing small-resolution images. Benefiting from the success of convolutional neural networks (CNNs), Ball{\'e} \textit{et al.} \cite{balle2017end} proposed an end-to-end CNN-based image compression framework, significantly stabilizing and improving image compression efficiency. Follow-up improvements include the hyper-prior structure to de-correlate latent space \cite{balle2018variational}, auto-regressive model to predict context information \cite{minnen2018joint}, attention-inspired approach \cite{cheng2020learned} and invertible neural networks \cite{xie2021enhanced} to improve the feature transformation. The above methods are optimized mostly against the objective quality, e.g., minimizing the MSE or multi-scale structure similarity index measure (MS-SSIM) \cite{wang2004image,wang2003multiscale} of reconstructed images, which now have outperformed the state-of-the-art standard VVC codec regarding pixel-wise accuracy \cite{he2022elic}. However, the pixel-wise accuracy, although improved by advanced metrics such as human region of interest (ROI) weighted MSE and MS-SSIM \cite{wang2003multiscale}, are still yet to match human subjective perception \cite{kim2017deep}, in which a visually inperceptible misalignment on images can lead to remarkable degradation on those pixel-wise metrics. }

\subsection{Generative Model Assisted Compression}

{Since human perception is the ultimate end of restored images, improving the subjective quality of reconstructed images is thus the long-standing necessity in the field of image compression. Benefiting from the most recent advances of deep generative models in outputting realistic images, we have been witnessing compression methods to incorporate GANs to improve subjective quality by learning similarity across distributions, apart from minimizing the pixel-wise metrics. Rippel \textit{et al.} \cite{rippel2017real} employed the adversarial learnt discriminator to remove the block effect of compressed images. Then, Agustsson \textit{et al.} \cite{agustsson2019generative} investigated both unconditional and conditional GANs for full-resolution image compression, and demonstrated that using GAN loss with rate-distortion joint optimization can result in significant bitrate savings. Mentzer \textit{et al.} \cite{mentzer2020high} further built upon conditional GAN, with sophisticated designs including modify the normalization function to eliminate darkening artefacts and the hyperprior model to enhance compression efficiency. Subsequent researches also enhanced the encoder-decoder architecture \cite{he2022po}, with local adversarial discriminators \cite{muckley2023improving}, and the conditional generator \cite{agustsson2023multi} to further improve compression efficiency. With the rapid development of diffusion models \cite{ho2020denoising,song2020denoising}, diffusion-based autoencoder models have been also investigated to reconstruct images with high fidelity \cite{preechakul2022diffusion}. Based on this, Yang and Mandt \cite{yang2024lossy} employed the encoder to map images into a quantised contextual latent variable, which then aids the diffusion model as the decoder to yield competitive compression performance with GAN-based models. However, the above methods, in which the subjective quality is improved with the aid of deep generative models, still encounter the trade-off between the objective and subjective quality when optimizing the compression performance. }


\subsection{Semantic Image Compression}

{Human communicate by linguistic semantics, which motivates the most recent research on semantic compression to focus on restoring the semantic information instead of the pixel-wise details of images. This allows for compressing images at extremely low bit-rates. Existing semantic compression methods typically rely on pre-defined semantics, including learnt structural representations \cite{zhang2024machine}, semantic maps \cite{huang2021deep, korber2024egic, akbari2019dsslic}, texture maps \cite{chang2023semantic} and text \cite{lee2024neural}, to improve the subjective consistency of the reconstructed images. We also noticed that multiple forms of pre-defined semantics are employed to improve compression efficiency. Chang et al. \cite{chang2022conceptual} proposed to compress images by a dual-layered model, consisting of structural layer and texture layer to achieve improve bitrate-quality performances.  Li et al. \cite{li2021cross} also proposed a  cross-modal compression framework based on the text, sketch and semantic maps, to transform the redundant visual data into a compact and human-comprehensible domain. However, the above methods still derive semantic information  from images via pre-defined styles; this is still \textit{ad hoc} to summarise compact and precise image semantics for compression. }

{Most recently, with the rapid development of large-scale models, several methods \cite{lei2023text+sketch, careil2023towards, li2024misc} were built upon pre-trained text-conditioned diffusion models, to benefit the compression from the semantics embedded in the models. Those advanced methods, however, still rely on compressing the extra text or sketch information as auxiliary cues, which suffers from the deficiency on bitrates. The latent generating space of diffusion models also retains the high dimensions, which exhibits unstructured space that requires careful strategies to alter the semantics \cite{wu2023latent, guo2024smooth}. Rather than the diffusion models that retains feature sizes from the beginning to the end, the latent generating space of GANs typically resides on extremely low dimensions and essentially possesses rich intrinsic semantics, which is highly suitable for the compression task. The most recent work \cite{mao2023scalable} established an encoder to reconstruct the latent style codes for StyleGAN, which achieved superior performances on compressing face images. Its reconstruction accuracy, as well as the application scenarios, are relatively limited. To the best of our knowledge, this paper sets out the first attempt to achieve the state-of-the-art semantic compression, based on GANs for various scenarios.} 

\vspace{-1em}