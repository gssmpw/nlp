\section{Anomaly Detection in IoT}

\textbf{Graph neural networks (GNN).} In the paper, anomaly detection in Industrial Internet of Things (IIoT) systems is achieved through a structured and methodical approach using Graph Neural Networks (GNNs). The first step involves collecting vast amounts of data from IIoT devices such as sensors and actuators deployed across various industrial sectors like smart transportation, energy, and factories. These devices continuously monitor key parameters like temperature, pressure, and power consumption, generating a large and diverse dataset. To apply GNNs effectively, this raw data is transformed into a graph structure where the devices represent nodes, and their relationships, such as physical proximity or communication links, are represented as edges. Each node is associated with a feature vector containing its collected data, and edges may also carry relevant information, such as communication strength or spatial proximity. This step ensures that the non-Euclidean nature of IIoT data is captured in a format suitable for GNNs, allowing the model to process complex, interconnected relationships among the devices.

Once the graph is constructed, the GNN model is applied to detect anomalies by learning patterns from the IIoT graph. The model aggregates data from each node and its neighboring nodes, capturing the spatial and temporal relationships between the devices. GNNs such as Graph Convolutional Networks (GCNs) or Graph Attention Networks (GANs) are used depending on the complexity of the relationships in the system. GCNs are often employed for tasks that involve aggregating features from adjacent nodes, making them ideal for detecting point anomalies where a single device may deviate from normal behavior. GANs, on the other hand, can assign different weights to neighboring nodes, which is useful for detecting contextual anomalies, where a node's behavior is anomalous only in specific contexts. The GNN learns node and edge representations that encapsulate these relationships, enabling it to recognize normal patterns of operation and flag deviations that indicate potential anomalies.

After the GNN model is trained, it is applied to detect three main types of anomalies in the IIoT system: point, contextual, and collective anomalies. Point anomalies are isolated instances where a single device shows abnormal behavior, such as a sudden spike in temperature from a sensor. Contextual anomalies are detected when a device's behavior is abnormal only in relation to its surrounding context, such as high power consumption during a time when the factory should be inactive. Collective anomalies are more complex and involve a group of devices collectively exhibiting abnormal behavior, even if their individual readings appear normal. This could occur, for example, when a set of devices in a factory shows slight but coordinated deviations that signal a system-wide issue. By learning these patterns, the GNN can predict and identify anomalies in real-time, providing early warning of potential failures or security breaches.

Finally, once the GNN detects an anomaly, the system processes the output to trigger alerts or provide further analysis. GNNs like Graph Attention Networks provide a level of interpretability by showing how much each neighbor contributed to a node's anomaly score, which helps in understanding the root cause of the anomaly. This step ensures that anomalies are not just detected but are also actionable, allowing human operators or automated systems to respond effectively. This approach, leveraging the powerful feature-learning capability of GNNs, makes anomaly detection in IIoT environments more accurate, scalable, and able to handle the complexities of interconnected devices and evolving industrial networks\cite{73}.

$$********************$$

\textbf{Device Interaction Graph (DIG).} The anomaly detection approach in the paper "IoT Anomaly Detection Via Device Interaction Graph" is built around the concept of a Device Interaction Graph (DIG). This graph-based model captures the relationships between IoT devices by treating each device as a node and each interaction between devices as a directed edge. The system constructs the DIG by analyzing historical device logs to map out normal interactions, and each edge in the graph is associated with a Conditional Probability Table (CPT), which defines the likelihood of a device's state based on the state of other interacting devices. These probabilities form the baseline for detecting abnormal behavior, ensuring the system can distinguish between typical device interactions and suspicious anomalies.

Once the DIG is established, the system processes incoming real-time events and compares them to the expected behaviors stored in the graph. Each device event is checked against its respective CPT, determining whether the event falls within the normal probability distribution. If an event deviates significantly from expected behavior, it is flagged as a contextual anomaly. For example, if a light turns on without any presence detected in the room, the system recognizes that such behavior is statistically improbable based on past interactions and flags the event as suspicious. This anomaly detection is strengthened by assigning an anomaly score that quantifies how far an event diverges from normal expectations. Events with high anomaly scores are reported to the user as potential security concerns.

In addition to identifying isolated anomalous events, the system is capable of detecting collective anomalies, where a sequence of events forms an unusual chain of interactions. For instance, if an initial anomaly (such as a light turning on without presence detection) triggers a series of related device actions (like a heater turning on and a window opening), the system can track the entire sequence and flag it as a collective anomaly. This type of detection is crucial in IoT environments where one anomalous event can cascade into broader issues through device automation rules or physical interactions. The system continuously monitors interactions using a Phantom State Machine, which keeps track of recent device states and updates the DIG in real-time, ensuring that it captures both individual and chained anomalies effectively.

An illustrative example involves a smart home where a presence sensor, light switch, heater, and automated window work together to maintain the environment. Under normal conditions, the presence sensor triggers the light, the heater responds to temperature changes, and the window opens when the heater is on. However, if the system detects the light turning on without the presence sensor being activated, this would be classified as a contextual anomaly. If this initial anomaly leads to further actions, such as the heater and window operating, the system would flag the entire sequence as a collective anomaly. By identifying and reporting these anomalies, the system provides comprehensive security monitoring and helps users quickly address potential IoT vulnerabilities\cite{74}.

$$********************$$

\textbf{ hybrid (Gumbel-Softmax sampling is a technique used in deep learning, Graph Learning Transformer Anomaly detection (GTA) (deep learning model)).} The GTA (Graph Learning with Transformer Anomaly detection) framework proposed in the paper provides a robust and scalable solution for detecting anomalies in multivariate time-series data, specifically within IoT systems. Anomaly detection in such systems is crucial, as IoT networks often consist of interconnected sensors that generate continuous streams of data. Each sensor, while monitoring specific metrics, is influenced by others within the system. Traditional approaches to anomaly detection often fail to model the complex dependencies between these sensors, leading to ineffective detection of anomalies. GTA addresses this by first learning the underlying graph structure that captures the relationships between sensors, and then employing a transformer-based model to forecast normal behavior and detect deviations.

The anomaly detection process in GTA begins with graph structure learning, where the model automatically infers dependencies between sensors using a connection learning policy. This policy employs the Gumbel-softmax sampling technique, which enables the model to create a directed graph that reflects the influence of one sensor on another. For example, in a water distribution system, opening a valve could affect the flow rate and pressure measured by nearby sensors. By capturing such relationships, the model creates a structured graph that improves the understanding of how anomalies may propagate through the network. This learned graph is then processed through Influence Propagation Convolution, which models how anomalies detected in one sensor might influence others in the graph.

After constructing the graph, the framework applies temporal dependency modeling using a transformer architecture. Transformers have become well-established for their ability to model sequences, especially in long-range temporal data, which is essential for time-series anomaly detection. The transformer in GTA predicts the future state of each sensor based on historical data and its relationships with other sensors. By using a multi-branch attention mechanism, the transformer is able to reduce computational complexity, allowing the model to handle large-scale IoT systems efficiently. The predicted values are compared to the actual sensor readings, and the differences between these values are used to compute an anomaly score.

Finally, GTA detects anomalies by calculating the anomaly score, which is the difference between predicted and actual sensor readings at each timestamp. If this score exceeds a predetermined threshold, the system flags the event as an anomaly. This threshold can be determined dynamically using techniques such as extreme value theory to ensure adaptability across different types of data and systems. The framework's ability to learn sensor relationships and model temporal dependencies makes it highly effective for detecting anomalies in real-world IoT systems, where dependencies between sensors are not predefined. Extensive experiments on multiple benchmark datasets demonstrate that GTA significantly outperforms traditional methods in detecting both subtle and severe anomalies.

In essence, the GTA framework presents a comprehensive, end-to-end approach to anomaly detection in IoT systems. By integrating graph learning and transformers, it addresses the limitations of prior methods that overlooked the intricate dependencies between sensors or struggled with scalability. This approach is not only effective in detecting anomalies but also scalable and adaptable to various IoT environments, making it a valuable contribution to the field of time-series anomaly detection\cite{75}.

$$********************$$

\textbf{ML(Logistic Regression (LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), Artificial Neural Network (ANN)). } In this study, anomalies in IoT systems were detected using machine learning techniques, following a systematic approach that begins with dataset collection and preprocessing, followed by the application of various machine learning models, and concluding with model evaluation and selection. The dataset used for this research was sourced from a virtual IoT environment, Distributed Smart Space Orchestration System (DS2OS), which provides synthetic data that simulate both normal and anomalous behaviors in IoT devices. The dataset contained 357,952 samples with 13 features representing various characteristics of the IoT system, such as source and destination addresses, operation types, and timestamp. These features were critical for identifying the interactions between IoT devices, with anomalies detected across eight classes, including Denial of Service (DoS), Malicious Control, and Data Type Probing.

To prepare the data for machine learning, preprocessing steps included handling missing values, replacing them with meaningful labels like "Malicious," and transforming categorical features into numerical values using label encoding. This step was crucial in converting the dataset into a format suitable for machine learning models. The data was then split into training and testing sets, with 80\% used for training and 20\% for testing. Various machine learning algorithms—Logistic Regression (LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), and Artificial Neural Network (ANN)—were trained on the dataset to classify instances as either normal or anomalous.

After training, the models were evaluated based on several key performance metrics, including accuracy, precision, recall, and F1 score, as well as the receiver operating characteristic (ROC) curve. Among the models tested, Random Forest emerged as the most effective, achieving a high accuracy of 99.4\%. It outperformed other models in terms of precision, recall, and overall classification performance, particularly in detecting critical attacks such as Denial of Service and Malicious Control. The Random Forest model's superior performance was further validated through the analysis of confusion matrices, which showed that it correctly classified the majority of anomalies while maintaining a low rate of misclassification.

The anomaly detection process hinges on the model's ability to recognize deviations from normal IoT behavior. For instance, in a typical IoT environment, if a thermostat that usually sends temperature data to a light controller suddenly attempts to unlock a door, this would be flagged as an anomaly, possibly indicating a security breach or malfunction. By detecting such deviations, the system can trigger alerts to inform administrators, thereby enhancing the security and reliability of IoT infrastructures. The results from this study underscore the effectiveness of Random Forest in identifying both known and previously unseen anomalies in IoT networks, making it a strong candidate for future implementation in real-world IoT environments\cite{76}.

$$********************$$

\textbf{survey (Statistical and Probabilistic Methods, Pattern Matching, Distance-Based Methods, Clustering, Predictive Methods, Ensemble Methods, Dimensionality Reduction Techniques, Machine Learning Approaches).} Anomaly detection in IoT time-series data is a crucial technique for identifying unusual or unexpected behaviors in systems monitored by interconnected devices. The process begins with the collection of data from IoT sensors, which capture metrics such as temperature, pressure, or power consumption over time. This data, often organized in either univariate or multivariate time-series, serves as the foundation for detecting anomalies. Once collected, the data undergoes preprocessing, a vital step that involves cleaning the dataset by handling missing values, removing duplicates, and filtering out noise. For multivariate systems, dimensionality reduction techniques, such as Principal Component Analysis (PCA) or autoencoders, may be employed to simplify the dataset while retaining essential information. Normalization is also typically applied to bring all variables onto a comparable scale, especially when working with heterogeneous sensor inputs.

The next step involves defining normal behavior. This is typically achieved by training models on historical, non-anomalous data, allowing the system to learn the typical patterns of operation. Different methods can be applied here depending on the context. For instance, pattern-matching models identify recurring sequences of normal behavior, while statistical approaches build probabilistic models based on historical data distributions. In predictive modeling techniques, like AutoRegressive Integrated Moving Average (ARIMA) or Long Short-Term Memory (LSTM) networks, the system learns to forecast future values, establishing expected trends for variables such as temperature, pressure, or power. By modeling the normal state of the system, the anomaly detection process is primed to identify deviations.

Once the model is trained, it begins real-time monitoring of incoming data from the IoT system. Each new data point is compared against the established model to assess whether it conforms to the expected patterns. In resource-constrained environments, this process might be conducted over sliding windows, analyzing only recent observations to reduce storage and processing requirements. The model assigns anomaly scores to incoming data based on the difference between the observed and predicted values. Large deviations signal the presence of anomalies, which can be classified as point anomalies (a single abnormal data point), contextual anomalies (a normal-looking value that is unusual in its context), or collective anomalies (a group of values that together form an unusual pattern). Anomalies are flagged when their score exceeds a predefined threshold, learned during the model training phase.

Finally, reporting and action follow the detection of an anomaly. Depending on the system's setup, detected anomalies can either be labeled with a binary classification (normal or anomalous) or assigned a severity score, guiding operators in prioritizing their responses. Automated systems might trigger alerts or take immediate corrective actions, such as adjusting operational settings or scheduling maintenance. This workflow ensures that the IoT system operates efficiently, with quick identification and mitigation of issues before they escalate into failures, minimizing downtime and optimizing performance\cite{77}.

$$********************$$

\textbf{Machine learning(Random Forest).} In the paper AD-IoT: Anomaly Detection of IoT Cyberattacks in Smart City Using Machine Learning, the authors present a systematic approach to detecting anomalies in IoT networks. The detection process begins with data collection, where network traffic data from IoT devices in a smart city is gathered. This data includes various network attributes such as packet size, protocol type, connection duration, and source and destination IP addresses. A labeled dataset, the UNSW-NB15, which contains both normal and attack traffic, is used to train the machine learning model. Once collected, the data undergoes preprocessing, where it is cleaned, standardized, and split into training and testing sets. This ensures that the machine learning model is provided with structured and relevant data for further processing.

Following data preprocessing, the next step is feature selection. In this phase, the most relevant features that could indicate potential cyberattacks are selected. The selected features are crucial for accurately classifying the behavior of IoT devices and determining whether their traffic is normal or suspicious. Once the important features are identified, the Random Forest algorithm is employed to train the model. Random Forest, a popular machine learning algorithm, builds multiple decision trees based on the selected features and combines their predictions to improve classification accuracy. During this training phase, the model learns the difference between normal and anomalous traffic based on the labeled dataset, enabling it to detect malicious patterns effectively.

Once the model is trained, it is deployed in a fog computing architecture, where real-time anomaly detection takes place. The fog layer, which sits between the cloud and IoT devices, analyzes the traffic data close to the source, reducing latency and allowing for faster detection of suspicious activities. As the IoT traffic flows through the network, the trained model continuously monitors and classifies each incoming data packet. If any anomalies are detected, the system flags the behavior as potentially malicious and generates an alert. To ensure the reliability of the system, steps are taken to minimize false positives, which are critical in maintaining trust in the system. By fine-tuning the model's parameters and employing cross-validation techniques, the authors managed to achieve high detection accuracy (99.34%) while keeping false positives low.

Finally, the system takes proactive measures when an anomaly is detected. It generates alerts to notify system administrators or service providers, allowing them to investigate or block suspicious traffic. This ensures that threats such as distributed denial-of-service (DDoS) attacks can be mitigated before they affect the broader smart city infrastructure. By implementing this distributed detection system at the fog layer, the AD-IoT system enhances the security and resilience of IoT networks in smart cities\cite{78}.

$$********************$$

\textbf{survey (ML and DL).} Anomaly detection in IoT data streams is a multi-step process that leverages advanced machine learning and deep learning techniques to identify unusual behaviors or events in real time. The process begins with data collection from various IoT devices, such as sensors, which generate continuous, massive data streams. These data streams are often unstructured, noisy, and high-dimensional, requiring preprocessing to ensure quality before further analysis. Preprocessing steps typically include cleaning the data to remove noise or irrelevant information, normalizing or scaling the features to ensure consistency, and applying dimensionality reduction techniques to focus on the most significant variables. Given the continuous nature of IoT data, a windowing mechanism is applied to manage the data flow, allowing the system to process data in small, manageable chunks. Common windowing techniques include sliding windows, where data is analyzed in a rolling fashion, fading windows that prioritize more recent data, and landmark windows that capture specific time-bound events.

Once the data is preprocessed and windowed, machine learning or deep learning models are applied to detect anomalies. Supervised learning models, such as Support Vector Machines (SVM) or decision trees, can be used if labeled data is available, where the model is trained on known examples of normal and anomalous behavior. Unsupervised methods, such as clustering algorithms like K-means or Local Outlier Factor (LOF), are used when no labeled data exists, detecting anomalies based on how well new data points fit into learned clusters of normal behavior. Deep learning models, such as Autoencoders and Long Short-Term Memory (LSTM) networks, are particularly effective in handling complex, high-dimensional, and time-dependent data. Autoencoders are trained to reconstruct normal data and detect anomalies by measuring reconstruction errors, while LSTM models are used for time-series data, capturing temporal relationships to identify unexpected deviations.

After the models have been trained and deployed, they continuously evaluate new data in real-time, generating an anomaly score for each new data point. If the anomaly score exceeds a predefined threshold, the system flags the data point as anomalous. The effectiveness of these models is regularly evaluated using metrics such as accuracy, precision, recall, and the F1-score, which measure the model's ability to correctly identify anomalies while minimizing false positives. In addition, more advanced metrics like the Area Under the Curve (AUC) are employed to better handle the imbalanced nature of IoT datasets, where normal events far outnumber anomalies. This comprehensive approach ensures that the models not only detect anomalies efficiently but also adapt to evolving data patterns in IoT systems\cite{79}.

$$********************$$

\textbf{Deep Neural Network.} The proposed anomaly detection method for IoT networks involves a comprehensive, step-by-step process that leverages the capabilities of deep neural networks (DNN) to accurately identify malicious activity in network traffic. The first step is capturing network traffic using tools like tcpdump or Wireshark, which intercept and log data flowing through the IoT environment. These data packets contain important features, such as source and destination IP addresses, packet lengths, and protocols, which are crucial for distinguishing between normal and anomalous traffic patterns.

Once the network traffic is captured, the next step is feature extraction, where relevant attributes from the raw network packets are selected. These features are then preprocessed to ensure consistency and suitability for the DNN model. Preprocessing involves normalizing numerical features to bring them to a uniform scale and encoding categorical features like IP addresses or protocols into a machine-readable format using techniques such as one-hot encoding. This process ensures that the dataset is clean, well-structured, and optimized for effective training of the model.

After preprocessing, the dataset is labeled into two categories: Benign (normal traffic) and Anomalous (malicious traffic). The data is split into a training set (75\%) and a test set (25\%) to ensure the model can be evaluated on unseen data. The DNN model is then trained using the labeled dataset, adjusting its internal parameters to minimize classification errors. The architecture of the DNN involves multiple hidden layers, where each layer refines the features further, using activation functions like ReLU in the hidden layers and sigmoid in the output layer to classify traffic as either benign or anomalous.

During the testing phase, the trained DNN model processes new, unseen network traffic and predicts whether it is benign or anomalous. If an anomaly is detected, the model raises an alert, prompting the network administrator to investigate further. The model's performance is evaluated based on key metrics such as accuracy, precision, recall, and false alarm rate. By leveraging mutual information (MI) to select the most significant features, the model minimizes complexity without compromising performance, effectively reducing the false alarm rate and improving detection accuracy. This approach ensures that the IoT network is constantly monitored and protected from potential cyber threats, such as zero-day attacks or Distributed Denial of Service (DDoS) attacks\cite{80}.

$$********************$$

\textbf{Convolutional Neural Networks (CNNs).} The detection of anomalies in IoT networks, as described in this paper, follows a comprehensive approach using deep learning, specifically convolutional neural networks (CNNs). The process begins with data collection, where network traffic from IoT devices is captured and processed. The raw traffic data is then converted into structured features using a tool like CICFlowmeter, extracting key network characteristics such as flow duration, packet sizes, and protocol types. This step is essential for transforming the complex, high-dimensional data into a format suitable for machine learning. The extracted features are further processed by removing irrelevant details like IP addresses and timestamps to ensure the model can generalize across different IoT networks.

Once the features are prepared, they undergo normalization to bring all values into a common range, usually between [-1, 1], which aids in speeding up the training process and improving the model's accuracy. Feature selection is then applied using Recursive Feature Elimination (RFE) to reduce the dimensionality of the data, helping to focus the model on the most important aspects of the network traffic. This step is critical to improving the model's performance by eliminating irrelevant or redundant information that could lead to overfitting.

The anomaly detection model is built using CNN architectures, specifically CNN1D, CNN2D, and CNN3D, tailored to handle different types of input data. These models are designed with multiple layers, including convolutional layers for feature extraction, pooling layers for down-sampling, and dropout layers to prevent overfitting. A fully connected dense layer at the end makes the final classification between normal and anomalous traffic. The model is trained using both binary and multiclass classification approaches, where it learns to distinguish between normal traffic and various types of attacks, such as DDoS, MITM, and ransomware attacks.

During the training phase, the model's parameters are optimized using the Adam optimizer and a loss function, such as categorical cross-entropy for multiclass classification. The model is evaluated using metrics such as accuracy, precision, recall, and F1-score to ensure it can effectively detect anomalies while minimizing false positives. Transfer learning is also utilized to improve the model's performance and reduce training time by fine-tuning a pre-trained model on smaller datasets. This approach allows the model to be applied across different IoT environments without needing to be retrained from scratch.

In real-time applications, once the CNN model is trained and validated, it continuously monitors network traffic, classifying each flow as either normal or anomalous. If an anomaly is detected, the system can flag the suspicious traffic and take appropriate actions, such as alerting administrators or blocking the source of the attack. This deep learning-based approach ensures a high level of accuracy in detecting both known and novel cyber threats, providing a robust defense mechanism for IoT networks\cite{81}.

$$********************$$

\textbf{survey (statistical methods, machine learning methods, and deep learning methods).} In the paper "Anomaly Detection, Analysis, and Prediction Techniques in IoT Environment: A Systematic Literature Review," the process of detecting anomalies is presented through a step-by-step methodology applicable across various IoT domains such as intelligent environments, transportation systems, healthcare systems, and industrial applications. The first critical step in this process is understanding the nature of the data. IoT data streams can vary significantly, ranging from binary (e.g., on/off sensor states) to continuous and discrete forms (e.g., temperature readings or event counts). Moreover, the relationships between the data points, such as time-series dependencies or spatial correlations, need to be considered, as they guide the selection of appropriate techniques for anomaly detection.

Preprocessing the raw data follows next, involving cleaning, normalization, and feature engineering. Sensor data can often be noisy, incomplete, or imbalanced, making preprocessing crucial to prepare the dataset for analysis. For instance, missing values need to be handled, and data from different sensors might require normalization to ensure comparability. Features, such as time-based or contextual patterns, are extracted from the data to provide the model with rich information. This step is especially important when handling high-dimensional IoT data streams, where feature selection plays a significant role in improving the model's performance.

Once the data is prepared, the next step involves selecting the type of anomaly to detect. Anomalies can be classified into three main categories: point anomalies, where single data points deviate significantly from expected behavior; contextual anomalies, where data points are normal in one context but anomalous in another; and collective anomalies, where a sequence of data points shows an unusual pattern. For each type, different methods are applied. For example, statistical approaches such as Gaussian Mixture Models (GMM) or dissimilarity measures are effective for detecting simple point anomalies, while more complex patterns might require machine learning or deep learning techniques.

After identifying the anomaly type, the appropriate detection method is selected. Traditional statistical methods like percentile-based thresholds, PCA for dimensionality reduction, and correlation-based measures are commonly used for simpler or smaller datasets. Machine learning techniques such as one-class SVM and clustering methods are applied for more complex data patterns, especially in unsupervised settings where labeled data is not available. In recent years, deep learning methods like autoencoders and CNNs have been explored for handling high-dimensional and large-scale IoT data, though their application remains limited due to the computational resources they require.

The anomaly detection system is trained using historical data, typically through supervised, unsupervised, or semi-supervised learning. In supervised learning, the model is trained on labeled datasets, while unsupervised learning methods focus on identifying patterns in unlabeled data, which is more common in real-world IoT environments. Semi-supervised learning, which uses a combination of labeled and unlabeled data, is another approach that helps overcome the scarcity of anomalous examples.

Finally, the system is deployed to detect anomalies in real-time or historical datasets. Point anomalies are flagged when a single data point deviates from the learned normal patterns, while contextual anomalies are identified by analyzing the data within its specific context. Collective anomalies, on the other hand, require analyzing sequences of data points to identify unusual collective behavior. Once detected, the anomalies are further analyzed to predict potential future system failures or identify the root causes, enabling proactive maintenance or intervention in industrial, healthcare, or transportation systems\cite{82}.

$$********************$$

\textbf{Survey(geometrical, statistical, machine learning, and deep learning). } Anomaly detection in IoT systems involves a structured process that can be categorized into several key steps. The first step is data collection, where raw data from various IoT devices and sensors are continuously gathered. These data streams include sensor readings such as temperature, pressure, network traffic, and other relevant parameters. Since IoT systems operate in real-time and deal with massive amounts of data, efficient and scalable data collection is crucial to ensure timely and accurate analysis. The data collected is often noisy, incomplete, and inconsistent, so preprocessing is required to clean the data, handle missing values, and standardize or normalize it for further analysis. Feature extraction techniques are applied to distill essential attributes from the raw data, reducing complexity while retaining the critical characteristics of the dataset.

Once the data is prepared, model selection becomes the next critical step. Different anomaly detection methods are applied depending on the complexity and nature of the data. In the context of IoT, three broad categories of methods are commonly used: geometrical, statistical, and machine learning-based approaches. Geometrical methods focus on identifying anomalies based on distances or densities between data points. For example, in K-nearest neighbor (KNN) algorithms, anomalies are detected when a data point is significantly far from its neighbors. Statistical methods model normal behavior using probability distributions such as the Gaussian distribution, where anomalies are defined as deviations from the expected distribution. Meanwhile, machine learning and deep learning models like autoencoders (AEs), support vector machines (SVMs), and long short-term memory (LSTM) networks have become popular for detecting more complex patterns in large datasets. These models are particularly useful when labeled training data is available, and they can be trained to distinguish between normal and anomalous behavior.

After selecting the appropriate model, a thresholding mechanism is employed to classify data points as normal or anomalous. This threshold could be a specific distance in the case of geometrical models, a statistical deviation for probabilistic models, or a reconstruction error in deep learning models like autoencoders. The threshold helps determine when a data point should be flagged as an anomaly. The detection process can occur either in real-time (online detection) or after data collection (batch processing). For IoT applications like industrial monitoring or healthcare, real-time anomaly detection is essential to ensure immediate responses to potentially hazardous conditions.

The final step in the process is decision-making and response. Once an anomaly is detected, the IoT system triggers a predefined action, which could involve sending alerts to administrators, shutting down malfunctioning equipment, or logging the anomaly for further investigation. These actions are vital in critical applications where even a slight delay in addressing anomalies can lead to significant damage or loss. Thus, the complete anomaly detection process in IoT—from data collection to decision-making—ensures that anomalies are detected efficiently and in a timely manner, safeguarding the operational integrity of IoT systems in various domains such as smart cities, healthcare, and industrial automation\cite{83}.

$$********************$$

\textbf{Machine Learning.} Anomaly detection in IoT networks is a critical aspect of maintaining the security and integrity of interconnected devices. The process typically begins with data collection, where large volumes of data are gathered from various IoT devices such as sensors, cameras, or smart home systems. This data includes network traffic, device activity logs, and sensor readings. Given the vast and diverse nature of IoT data, it is essential to collect this information in real-time to identify potential security threats quickly. The collected data helps to establish a baseline for normal behavior, which is crucial for distinguishing between regular operations and suspicious activities.

Once the data is collected, the next step is data preprocessing. This involves cleaning the data by addressing missing values, normalizing different variables, and converting categorical data into numerical formats. Preprocessing ensures that the data is ready for machine learning models and that discrepancies, such as gaps or inconsistencies, are addressed before further analysis. After cleaning, the data undergoes feature extraction, where key characteristics, such as network traffic volume, device usage frequency, and sensor activity patterns, are identified. These features help the machine learning models understand the normal operations of the IoT network.

The machine learning models play a crucial role in detecting anomalies in the IoT network. Different algorithms can be employed based on the specific requirements of the system. Supervised learning algorithms like Random Forest and Decision Trees are commonly used when there are labeled datasets that differentiate between normal and abnormal behaviors. In cases where labeled data is unavailable, unsupervised learning techniques, such as clustering algorithms, can identify outliers or anomalies based on patterns in the data. Additionally, reinforcement learning can be applied to allow the system to adapt and improve its anomaly detection capabilities over time by learning from its environment.

Once the machine learning models are trained, they are deployed for real-time anomaly detection. As the system monitors incoming data, it compares the new observations against the baseline of normal behavior. If a significant deviation is detected, such as abnormal spikes in network traffic or unusual device activity, the system flags the event as an anomaly. These anomalies could indicate security breaches, such as denial-of-service (DoS) attacks, data tampering, or unauthorized access. Continuous monitoring ensures that the IoT network remains secure, while the performance of the anomaly detection system is evaluated through metrics like precision, recall, and accuracy\cite{84}.

$$********************$$

\textbf{ML.} In the anomaly detection process outlined in the paper, the first step involves data acquisition, where a dataset from Kaggle was used containing 357,952 samples across 13 features. These features describe different aspects of the IoT network, such as source IDs, addresses, operations, and timestamps, with each data point labeled as either normal or anomalous. The anomalies represent various attack types, including Denial of Service (DoS), malicious control, and data type probing. This dataset provides the basis for training and testing the machine learning models to detect anomalies. The data was preprocessed to clean missing values and encode categorical variables using techniques such as one-hot encoding and dummy encoding, preparing the data for machine learning.

The dataset was divided into a training set (75\%) and a test set (25\%) to evaluate the models' performance. The next step involved selecting two machine learning models—Logistic Regression and Artificial Neural Networks (ANN)—for anomaly detection. Logistic Regression was used for its simplicity and efficiency in binary and multi-class classification tasks, while ANN was chosen for its ability to model complex relationships in the data through its multiple layers of neurons. The models were trained on the training set to learn the patterns of normal and anomalous behavior in IoT networks, and their performance was validated using accuracy metrics, precision, recall, and F1-scores. These metrics helped assess how well the models classified data points as either normal or anomalous.

In the evaluation phase, both models were tested on the test set to measure their effectiveness in detecting anomalies. The confusion matrices revealed that both models performed exceptionally well, with accuracy scores of 99.4\% for both Logistic Regression and ANN in the first experiment, where the entire dataset was used. In a second experiment, where data values of 0 and 1 were omitted from one feature, the models achieved nearly perfect accuracy of 99.99\%. This demonstrates the effectiveness of machine learning in detecting various IoT network anomalies. The models learned to identify discrepancies between expected and actual behavior in the data, flagging any deviations as potential anomalies.

In practical terms, this process enables real-time monitoring and anomaly detection in IoT systems. For example, in a smart city traffic management system, if sensors report an unusual spike in vehicle count—well beyond expected traffic patterns—the trained models can detect this as an anomaly. This could indicate an attack, such as a malicious actor sending false data to disrupt the network. Upon detection, an alert is raised, allowing administrators to investigate and mitigate the issue. This process showcases how machine learning models can enhance the security and reliability of IoT networks by identifying anomalies and preventing potential threats before they escalate into larger issues\cite{85}.

$$********************$$



$$********************$$



$$********************$$