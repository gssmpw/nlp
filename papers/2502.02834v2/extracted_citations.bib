@ARTICLE{10565991,
  author={Wen, Lu and Tseng, Eric H. and Peng, Huei and Zhang, Songan},
  journal={IEEE Robotics and Automation Letters}, 
  title={Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination}, 
  year={2024},
  volume={9},
  number={11},
  pages={9701-9708},
  keywords={Task analysis;Training;Decoding;Reinforcement learning;Metalearning;Linear programming;Interpolation;Reinforcement learning;machine learning for robot control;deep learning methods},
  doi={10.1109/LRA.2024.3417114}}

@article{agarwal2021contrastive,
  title={Contrastive behavioral similarity embeddings for generalization in reinforcement learning},
  author={Agarwal, Rishabh and Machado, Marlos C and Castro, Pablo Samuel and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2101.05265},
  year={2021}
}

@article{ajay2022distributionally,
  title={Distributionally adaptive meta reinforcement learning},
  author={Ajay, Anurag and Gupta, Abhishek and Ghosh, Dibya and Levine, Sergey and Agrawal, Pulkit},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25856--25869},
  year={2022}
}

@article{cheng2022provable,
  title={Provable benefit of multitask representation learning in reinforcement learning},
  author={Cheng, Yuan and Feng, Songtao and Yang, Jing and Zhang, Hong and Liang, Yingbin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31741--31754},
  year={2022}
}

@inproceedings{choshen2023contrabar,
  title={Contrabar: Contrastive bayes-adaptive deep rl},
  author={Choshen, Era and Tamar, Aviv},
  booktitle={International Conference on Machine Learning},
  pages={6005--6027},
  year={2023},
  organization={PMLR}
}

@article{dorfman2021offline,
  title={Offline Meta Reinforcement Learning--Identifiability Challenges and Effective Data Collection Strategies},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4607--4618},
  year={2021}
}

@article{eysenbach2018diversity,
  title={Diversity is all you need: Learning skills without a reward function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.06070},
  year={2018}
}

@article{fakoor2019meta,
  title={Meta-q-learning},
  author={Fakoor, Rasool and Chaudhari, Pratik and Soatto, Stefano and Smola, Alexander J},
  journal={arXiv preprint arXiv:1910.00125},
  year={2019}
}

@article{ferns2011bisimulation,
  title={Bisimulation metrics for continuous Markov decision processes},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  pages={1662--1714},
  year={2011},
  publisher={SIAM}
}

@article{frans2017meta,
  title={Meta learning shared hierarchies},
  author={Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
  journal={arXiv preprint arXiv:1710.09767},
  year={2017}
}

@inproceedings{fu2021towards,
  title={Towards effective context for meta-reinforcement learning: an approach based on contrastive learning},
  author={Fu, Haotian and Tang, Hongyao and Hao, Jianye and Chen, Chen and Feng, Xidong and Li, Dong and Liu, Wulong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={8},
  pages={7457--7465},
  year={2021}
}

@article{fu2022meta,
  title={Meta-learning parameterized skills},
  author={Fu, Haotian and Yu, Shangqun and Tiwari, Saket and Littman, Michael and Konidaris, George},
  journal={arXiv preprint arXiv:2206.03597},
  year={2022}
}

@article{gao2024context,
  title={Context shift reduction for offline meta-reinforcement learning},
  author={Gao, Yunkai and Zhang, Rui and Guo, Jiaming and Wu, Fan and Yi, Qi and Peng, Shaohui and Lan, Siming and Chen, Ruizhi and Du, Zidong and Hu, Xing and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{greenberg2024train,
  title={Train hard, fight easy: Robust meta reinforcement learning},
  author={Greenberg, Ido and Mannor, Shie and Chechik, Gal and Meirom, Eli},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{guan2024cost,
  title={Cost-aware Offline Safe Meta Reinforcement Learning with Robust In-Distribution Online Task Adaptation.},
  author={Guan, Cong and Xue, Ruiqi and Zhang, Ziqian and Li, Lihe and Li, Yi-Chen and Yuan, Lei and Yu, Yang},
  booktitle={AAMAS},
  pages={743--751},
  year={2024}
}

@inproceedings{hansen2022bisimulation,
  title={Bisimulation makes analogies in goal-conditioned reinforcement learning},
  author={Hansen-Estruch, Philippe and Zhang, Amy and Nair, Ashvin and Yin, Patrick and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={8407--8426},
  year={2022},
  organization={PMLR}
}

@article{harrison2020continuous,
  title={Continuous meta-learning without tasks},
  author={Harrison, James and Sharma, Apoorva and Finn, Chelsea and Pavone, Marco},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17571--17581},
  year={2020}
}

@inproceedings{he2024decoupling,
  title={Decoupling Meta-Reinforcement Learning with Gaussian Task Contexts and Skills},
  author={He, Hongcai and Zhu, Anjie and Liang, Shuang and Chen, Feiyu and Shao, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={11},
  pages={12358--12366},
  year={2024}
}

@inproceedings{hejna2023few,
  title={Few-shot preference learning for human-in-the-loop rl},
  author={Hejna III, Donald Joseph and Sadigh, Dorsa},
  booktitle={Conference on Robot Learning},
  pages={2014--2025},
  year={2023},
  organization={PMLR}
}

@article{ishfaq2024offline,
  title={Offline multitask representation learning for reinforcement learning},
  author={Ishfaq, Haque and Nguyen-Tang, Thanh and Feng, Songtao and Arora, Raman and Wang, Mengdi and Yin, Ming and Precup, Doina},
  journal={arXiv preprint arXiv:2403.11574},
  year={2024}
}

@article{jiang2024doubly,
  title={Doubly robust augmented transfer for meta-reinforcement learning},
  author={Jiang, Yuankun and Kan, Nuowen and Li, Chenglin and Dai, Wenrui and Zou, Junni and Xiong, Hongkai},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{lan2019meta,
  title={Meta reinforcement learning with task embedding and shared policy},
  author={Lan, Lin and Li, Zhenguo and Guan, Xiaohong and Wang, Pinghui},
  journal={arXiv preprint arXiv:1905.06527},
  year={2019}
}

@inproceedings{laskin2020curl,
  title={Curl: Contrastive unsupervised representations for reinforcement learning},
  author={Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={5639--5650},
  year={2020},
  organization={PMLR}
}

@article{lee2021improving,
  title={Improving generalization in meta-rl with imaginary tasks from latent dynamics mixture},
  author={Lee, Suyoung and Chung, Sae-Young},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27222--27235},
  year={2021}
}

@article{lee2023parameterizing,
  title={Parameterizing non-parametric meta-reinforcement learning tasks via subtask decomposition},
  author={Lee, Suyoung and Cho, Myungsik and Sung, Youngchul},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={43356--43383},
  year={2023}
}

@article{li2020focal,
  title={Focal: Efficient fully-offline meta-reinforcement learning via distance metric learning and behavior regularization},
  author={Li, Lanqing and Yang, Rui and Luo, Dijun},
  journal={arXiv preprint arXiv:2010.01112},
  year={2020}
}

@article{li2020multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Christensen, Henrik and Su, Hao},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6197--6210},
  year={2020}
}

@article{lin2020model,
  title={Model-based adversarial meta-reinforcement learning},
  author={Lin, Zichuan and Thomas, Garrett and Yang, Guangwen and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10161--10173},
  year={2020}
}

@inproceedings{liu2023robust,
  title={Robust representation learning by clustering with bisimulation metrics for visual reinforcement learning with distractions},
  author={Liu, Qiyuan and Zhou, Qi and Yang, Rui and Wang, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={7},
  pages={8843--8851},
  year={2023}
}

@article{mehta2020curriculum,
  title={Curriculum in gradient-based meta-reinforcement learning},
  author={Mehta, Bhairav and Deleu, Tristan and Raparthy, Sharath Chandra and Pal, Chris J and Paull, Liam},
  journal={arXiv preprint arXiv:2002.07956},
  year={2020}
}

@inproceedings{melo2022transformers,
  title={Transformers are meta-reinforcement learners},
  author={Melo, Luckeciano C},
  booktitle={international conference on machine learning},
  pages={15340--15359},
  year={2022},
  organization={PMLR}
}

@article{mendonca2020meta,
  title={Meta-reinforcement learning robust to distributional shift via model identification and experience relabeling},
  author={Mendonca, Russell and Geng, Xinyang and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.07178},
  year={2020}
}

@article{mu2022domino,
  title={Domino: Decomposed mutual information optimization for generalized context in meta-reinforcement learning},
  author={Mu, Yao and Zhuang, Yuzheng and Ni, Fei and Wang, Bin and Chen, Jianyu and Hao, Jianye and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27563--27575},
  year={2022}
}

@article{nam2022skill,
  title={Skill-based meta-reinforcement learning},
  author={Nam, Taewook and Sun, Shao-Hua and Pertsch, Karl and Hwang, Sung Ju and Lim, Joseph J},
  journal={arXiv preprint arXiv:2204.11828},
  year={2022}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{packer2021hindsight,
  title={Hindsight task relabelling: Experience replay for sparse reward meta-rl},
  author={Packer, Charles and Abbeel, Pieter and Gonzalez, Joseph E},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={2466--2477},
  year={2021}
}

@InProceedings{pmlr-v162-chae22a,
  title = 	 {Robust Imitation Learning against Variations in Environment Dynamics},
  author =       {Chae, Jongseong and Han, Seungyul and Jung, Whiyoung and Cho, Myungsik and Choi, Sungho and Sung, Youngchul},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {2828--2852},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/chae22a/chae22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/chae22a.html},
  abstract = 	 {In this paper, we propose a robust imitation learning (IL) framework that improves the robustness of IL when environment dynamics are perturbed. The existing IL framework trained in a single environment can catastrophically fail with perturbations in environment dynamics because it does not capture the situation that underlying environment dynamics can be changed. Our framework effectively deals with environments with varying dynamics by imitating multiple experts in sampled environment dynamics to enhance the robustness in general variations in environment dynamics. In order to robustly imitate the multiple sample experts, we minimize the risk with respect to the Jensen-Shannon divergence between the agent’s policy and each of the sample experts. Numerical results show that our algorithm significantly improves robustness against dynamics perturbations compared to conventional IL baselines.}
}

@article{ren2022efficient,
  title={Efficient meta reinforcement learning for preference-based fast adaptation},
  author={Ren, Zhizhou and Liu, Anji and Liang, Yitao and Peng, Jian and Ma, Jianzhu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15502--15515},
  year={2022}
}

@article{rimon2024mamba,
  title={Mamba: an effective world model approach for meta-reinforcement learning},
  author={Rimon, Zohar and Jurgenson, Tom and Krupnik, Orr and Adler, Gilad and Tamar, Aviv},
  journal={arXiv preprint arXiv:2403.09859},
  year={2024}
}

@inproceedings{sodhani2021multi,
  title={Multi-task reinforcement learning with context-based representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={9767--9779},
  year={2021},
  organization={PMLR}
}

@inproceedings{sodhani2022block,
  title={Block contextual mdps for continual learning},
  author={Sodhani, Shagun and Meier, Franziska and Pineau, Joelle and Zhang, Amy},
  booktitle={Learning for Dynamics and Control Conference},
  pages={608--623},
  year={2022},
  organization={PMLR}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{wan2021hindsight,
  title={Hindsight Foresight Relabeling for Meta-Reinforcement Learning},
  author={Wan, Michael and Peng, Jian and Gangwani, Tanmay},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{wang2023meta,
  title={Meta-reinforcement learning based on self-supervised task representation learning},
  author={Wang, Mingyang and Bing, Zhenshan and Yao, Xiangtong and Wang, Shuai and Kai, Huang and Su, Hang and Yang, Chenguang and Knoll, Alois},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={8},
  pages={10157--10165},
  year={2023}
}

@article{wang2023supervised,
  title={Supervised Meta-Reinforcement Learning With Trajectory Optimization for Manipulation Tasks},
  author={Wang, Lei and Zhang, Yunzhou and Zhu, Delong and Coleman, Sonya and Kerr, Dermot},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  volume={16},
  number={2},
  pages={681--691},
  year={2023},
  publisher={IEEE}
}

@inproceedings{xumeta,
  title={Meta-Reinforcement Learning Robust to Distributional Shift Via Performing Lifelong In-Context Learning},
  author={Xu, Tengye and Li, Zihao and Ren, Qinyuan},
  booktitle={International Conference on Machine Learning},
  year={2024},
}

@inproceedings{yuan2022robust,
  title={Robust task representations for offline meta-reinforcement learning via contrastive learning},
  author={Yuan, Haoqi and Lu, Zongqing},
  booktitle={International Conference on Machine Learning},
  pages={25747--25759},
  year={2022},
  organization={PMLR}
}

@inproceedings{zhanglearning,
  title={Learning Invariant Representations for Reinforcement Learning without Reconstruction},
  author={Zhang, Amy and McAllister, Rowan Thomas and Calandra, Roberto and Gal, Yarin and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{zhou2024generalizable,
  title={Generalizable Task Representation Learning for Offline Meta-Reinforcement Learning with Data Limitations},
  author={Zhou, Renzhe and Gao, Chen-Xiao and Zhang, Zongzhang and Yu, Yang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={15},
  pages={17132--17140},
  year={2024}
}

@article{zou2024relabeling,
  title={Relabeling and policy distillation of hierarchical reinforcement learning},
  author={Zou, Qijie and Zhao, Xiling and Gao, Bing and Chen, Shuang and Liu, Zhiguo and Zhang, Zhejie},
  journal={International Journal of Machine Learning and Cybernetics},
  pages={1--17},
  year={2024},
  publisher={Springer}
}

