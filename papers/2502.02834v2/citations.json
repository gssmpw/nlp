[
  {
    "index": 0,
    "papers": [
      {
        "key": "oord2018representation",
        "author": "Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol",
        "title": "Representation learning with contrastive predictive coding"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "laskin2020curl",
        "author": "Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter",
        "title": "Curl: Contrastive unsupervised representations for reinforcement learning"
      },
      {
        "key": "fu2021towards",
        "author": "Fu, Haotian and Tang, Hongyao and Hao, Jianye and Chen, Chen and Feng, Xidong and Li, Dong and Liu, Wulong",
        "title": "Towards effective context for meta-reinforcement learning: an approach based on contrastive learning"
      },
      {
        "key": "choshen2023contrabar",
        "author": "Choshen, Era and Tamar, Aviv",
        "title": "Contrabar: Contrastive bayes-adaptive deep rl"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2020focal",
        "author": "Li, Lanqing and Yang, Rui and Luo, Dijun",
        "title": "Focal: Efficient fully-offline meta-reinforcement learning via distance metric learning and behavior regularization"
      },
      {
        "key": "gao2024context",
        "author": "Gao, Yunkai and Zhang, Rui and Guo, Jiaming and Wu, Fan and Yi, Qi and Peng, Shaohui and Lan, Siming and Chen, Ruizhi and Du, Zidong and Hu, Xing and others",
        "title": "Context shift reduction for offline meta-reinforcement learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ferns2011bisimulation",
        "author": "Ferns, Norm and Panangaden, Prakash and Precup, Doina",
        "title": "Bisimulation metrics for continuous Markov decision processes"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zhanglearning",
        "author": "Zhang, Amy and McAllister, Rowan Thomas and Calandra, Roberto and Gal, Yarin and Levine, Sergey",
        "title": "Learning Invariant Representations for Reinforcement Learning without Reconstruction"
      },
      {
        "key": "agarwal2021contrastive",
        "author": "Agarwal, Rishabh and Machado, Marlos C and Castro, Pablo Samuel and Bellemare, Marc G",
        "title": "Contrastive behavioral similarity embeddings for generalization in reinforcement learning"
      },
      {
        "key": "liu2023robust",
        "author": "Liu, Qiyuan and Zhou, Qi and Yang, Rui and Wang, Jie",
        "title": "Robust representation learning by clustering with bisimulation metrics for visual reinforcement learning with distractions"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hansen2022bisimulation",
        "author": "Hansen-Estruch, Philippe and Zhang, Amy and Nair, Ashvin and Yin, Patrick and Levine, Sergey",
        "title": "Bisimulation makes analogies in goal-conditioned reinforcement learning"
      },
      {
        "key": "sodhani2022block",
        "author": "Sodhani, Shagun and Meier, Franziska and Pineau, Joelle and Zhang, Amy",
        "title": "Block contextual mdps for continual learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "eysenbach2018diversity",
        "author": "Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey",
        "title": "Diversity is all you need: Learning skills without a reward function"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "frans2017meta",
        "author": "Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John",
        "title": "Meta learning shared hierarchies"
      },
      {
        "key": "harrison2020continuous",
        "author": "Harrison, James and Sharma, Apoorva and Finn, Chelsea and Pavone, Marco",
        "title": "Continuous meta-learning without tasks"
      },
      {
        "key": "nam2022skill",
        "author": "Nam, Taewook and Sun, Shao-Hua and Pertsch, Karl and Hwang, Sung Ju and Lim, Joseph J",
        "title": "Skill-based meta-reinforcement learning"
      },
      {
        "key": "fu2022meta",
        "author": "Fu, Haotian and Yu, Shangqun and Tiwari, Saket and Littman, Michael and Konidaris, George",
        "title": "Meta-learning parameterized skills"
      },
      {
        "key": "he2024decoupling",
        "author": "He, Hongcai and Zhu, Anjie and Liang, Shuang and Chen, Feiyu and Shao, Jie",
        "title": "Decoupling Meta-Reinforcement Learning with Gaussian Task Contexts and Skills"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "ishfaq2024offline",
        "author": "Ishfaq, Haque and Nguyen-Tang, Thanh and Feng, Songtao and Arora, Raman and Wang, Mengdi and Yin, Ming and Precup, Doina",
        "title": "Offline multitask representation learning for reinforcement learning"
      },
      {
        "key": "cheng2022provable",
        "author": "Cheng, Yuan and Feng, Songtao and Yang, Jing and Zhang, Hong and Liang, Yingbin",
        "title": "Provable benefit of multitask representation learning in reinforcement learning"
      },
      {
        "key": "sodhani2021multi",
        "author": "Sodhani, Shagun and Zhang, Amy and Pineau, Joelle",
        "title": "Multi-task reinforcement learning with context-based representations"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "lan2019meta",
        "author": "Lan, Lin and Li, Zhenguo and Guan, Xiaohong and Wang, Pinghui",
        "title": "Meta reinforcement learning with task embedding and shared policy"
      },
      {
        "key": "fakoor2019meta",
        "author": "Fakoor, Rasool and Chaudhari, Pratik and Soatto, Stefano and Smola, Alexander J",
        "title": "Meta-q-learning"
      },
      {
        "key": "mu2022domino",
        "author": "Mu, Yao and Zhuang, Yuzheng and Ni, Fei and Wang, Bin and Chen, Jianyu and Hao, Jianye and Luo, Ping",
        "title": "Domino: Decomposed mutual information optimization for generalized context in meta-reinforcement learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "lin2020model",
        "author": "Lin, Zichuan and Thomas, Garrett and Yang, Guangwen and Ma, Tengyu",
        "title": "Model-based adversarial meta-reinforcement learning"
      },
      {
        "key": "lee2021improving",
        "author": "Lee, Suyoung and Chung, Sae-Young",
        "title": "Improving generalization in meta-rl with imaginary tasks from latent dynamics mixture"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wang2023meta",
        "author": "Wang, Mingyang and Bing, Zhenshan and Yao, Xiangtong and Wang, Shuai and Kai, Huang and Su, Hang and Yang, Chenguang and Knoll, Alois",
        "title": "Meta-reinforcement learning based on self-supervised task representation learning"
      },
      {
        "key": "lee2023parameterizing",
        "author": "Lee, Suyoung and Cho, Myungsik and Sung, Youngchul",
        "title": "Parameterizing non-parametric meta-reinforcement learning tasks via subtask decomposition"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "Attention is all you need"
      },
      {
        "key": "melo2022transformers",
        "author": "Melo, Luckeciano C",
        "title": "Transformers are meta-reinforcement learners"
      },
      {
        "key": "xumeta",
        "author": "Xu, Tengye and Li, Zihao and Ren, Qinyuan",
        "title": "Meta-Reinforcement Learning Robust to Distributional Shift Via Performing Lifelong In-Context Learning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "mendonca2020meta",
        "author": "Mendonca, Russell and Geng, Xinyang and Finn, Chelsea and Levine, Sergey",
        "title": "Meta-reinforcement learning robust to distributional shift via model identification and experience relabeling"
      },
      {
        "key": "mehta2020curriculum",
        "author": "Mehta, Bhairav and Deleu, Tristan and Raparthy, Sharath Chandra and Pal, Chris J and Paull, Liam",
        "title": "Curriculum in gradient-based meta-reinforcement learning"
      },
      {
        "key": "ajay2022distributionally",
        "author": "Ajay, Anurag and Gupta, Abhishek and Ghosh, Dibya and Levine, Sergey and Agrawal, Pulkit",
        "title": "Distributionally adaptive meta reinforcement learning"
      },
      {
        "key": "pmlr-v162-chae22a",
        "author": "Chae, Jongseong and Han, Seungyul and Jung, Whiyoung and Cho, Myungsik and Choi, Sungho and Sung, Youngchul",
        "title": "Robust Imitation Learning against Variations in Environment Dynamics"
      },
      {
        "key": "greenberg2024train",
        "author": "Greenberg, Ido and Mannor, Shie and Chechik, Gal and Meirom, Eli",
        "title": "Train hard, fight easy: Robust meta reinforcement learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "rimon2024mamba",
        "author": "Rimon, Zohar and Jurgenson, Tom and Krupnik, Orr and Adler, Gilad and Tamar, Aviv",
        "title": "Mamba: an effective world model approach for meta-reinforcement learning"
      },
      {
        "key": "10565991",
        "author": "Wen, Lu and Tseng, Eric H. and Peng, Huei and Zhang, Songan",
        "title": "Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "li2020multi",
        "author": "Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Christensen, Henrik and Su, Hao",
        "title": "Multi-task batch reinforcement learning with metric learning"
      },
      {
        "key": "mendonca2020meta",
        "author": "Mendonca, Russell and Geng, Xinyang and Finn, Chelsea and Levine, Sergey",
        "title": "Meta-reinforcement learning robust to distributional shift via model identification and experience relabeling"
      },
      {
        "key": "wan2021hindsight",
        "author": "Wan, Michael and Peng, Jian and Gangwani, Tanmay",
        "title": "Hindsight Foresight Relabeling for Meta-Reinforcement Learning"
      },
      {
        "key": "zou2024relabeling",
        "author": "Zou, Qijie and Zhao, Xiling and Gao, Bing and Chen, Shuang and Liu, Zhiguo and Zhang, Zhejie",
        "title": "Relabeling and policy distillation of hierarchical reinforcement learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "packer2021hindsight",
        "author": "Packer, Charles and Abbeel, Pieter and Gonzalez, Joseph E",
        "title": "Hindsight task relabelling: Experience replay for sparse reward meta-rl"
      },
      {
        "key": "jiang2024doubly",
        "author": "Jiang, Yuankun and Kan, Nuowen and Li, Chenglin and Dai, Wenrui and Zou, Junni and Xiong, Hongkai",
        "title": "Doubly robust augmented transfer for meta-reinforcement learning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "dorfman2021offline",
        "author": "Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv",
        "title": "Offline Meta Reinforcement Learning--Identifiability Challenges and Effective Data Collection Strategies"
      },
      {
        "key": "yuan2022robust",
        "author": "Yuan, Haoqi and Lu, Zongqing",
        "title": "Robust task representations for offline meta-reinforcement learning via contrastive learning"
      },
      {
        "key": "zhou2024generalizable",
        "author": "Zhou, Renzhe and Gao, Chen-Xiao and Zhang, Zongzhang and Yu, Yang",
        "title": "Generalizable Task Representation Learning for Offline Meta-Reinforcement Learning with Data Limitations"
      },
      {
        "key": "guan2024cost",
        "author": "Guan, Cong and Xue, Ruiqi and Zhang, Ziqian and Li, Lihe and Li, Yi-Chen and Yuan, Lei and Yu, Yang",
        "title": "Cost-aware Offline Safe Meta Reinforcement Learning with Robust In-Distribution Online Task Adaptation."
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ren2022efficient",
        "author": "Ren, Zhizhou and Liu, Anji and Liang, Yitao and Peng, Jian and Ma, Jianzhu",
        "title": "Efficient meta reinforcement learning for preference-based fast adaptation"
      },
      {
        "key": "hejna2023few",
        "author": "Hejna III, Donald Joseph and Sadigh, Dorsa",
        "title": "Few-shot preference learning for human-in-the-loop rl"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "wang2023supervised",
        "author": "Wang, Lei and Zhang, Yunzhou and Zhu, Delong and Coleman, Sonya and Kerr, Dermot",
        "title": "Supervised Meta-Reinforcement Learning With Trajectory Optimization for Manipulation Tasks"
      }
    ]
  }
]