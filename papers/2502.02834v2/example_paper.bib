@inproceedings{rakelly2019efficient,
  title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle={International conference on machine learning},
  pages={5331--5340},
  year={2019},
  organization={PMLR}
}

@inproceedings{ferns2014bisimulation,
  title={Bisimulation Metrics are Optimal Value Functions.},
  author={Ferns, Norman and Precup, Doina},
  booktitle={UAI},
  pages={210--219},
  year={2014}
}
@article{lee2023parameterizing,
  title={Parameterizing non-parametric meta-reinforcement learning tasks via subtask decomposition},
  author={Lee, Suyoung and Cho, Myungsik and Sung, Youngchul},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={43356--43383},
  year={2023}
}
@inproceedings{zhanglearning,
  title={Learning Invariant Representations for Reinforcement Learning without Reconstruction},
  author={Zhang, Amy and McAllister, Rowan Thomas and Calandra, Roberto and Gal, Yarin and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2021}
}


@article{ferns2011bisimulation,
  title={Bisimulation metrics for continuous Markov decision processes},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  pages={1662--1714},
  year={2011},
  publisher={SIAM}
}

@article{li2020focal,
  title={Focal: Efficient fully-offline meta-reinforcement learning via distance metric learning and behavior regularization},
  author={Li, Lanqing and Yang, Rui and Luo, Dijun},
  journal={arXiv preprint arXiv:2010.01112},
  year={2020}
}

@inproceedings{choshen2023contrabar,
  title={Contrabar: Contrastive bayes-adaptive deep rl},
  author={Choshen, Era and Tamar, Aviv},
  booktitle={International Conference on Machine Learning},
  pages={6005--6027},
  year={2023},
  organization={PMLR}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}
@article{zintgraf2019varibad,
  title={Varibad: A very good method for bayes-adaptive deep rl via meta-learning},
  author={Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1910.08348},
  year={2019}
}

@inproceedings{fu2021towards,
  title={Towards effective context for meta-reinforcement learning: an approach based on contrastive learning},
  author={Fu, Haotian and Tang, Hongyao and Hao, Jianye and Chen, Chen and Feng, Xidong and Li, Dong and Liu, Wulong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={8},
  pages={7457--7465},
  year={2021}
}

@article{lee2021improving,
  title={Improving generalization in meta-rl with imaginary tasks from latent dynamics mixture},
  author={Lee, Suyoung and Chung, Sae-Young},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27222--27235},
  year={2021}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{grigsby2023amago,
  title={Amago: Scalable in-context reinforcement learning for adaptive agents},
  author={Grigsby, Jake and Fan, Linxi and Zhu, Yuke},
  journal={arXiv preprint arXiv:2310.09971},
  year={2023}
}

@article{gulrajani2017improved,
  title={Improved training of wasserstein gans},
  author={Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}


@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{laskin2020curl,
  title={Curl: Contrastive unsupervised representations for reinforcement learning},
  author={Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={5639--5650},
  year={2020},
  organization={PMLR}
}


@article{agarwal2021contrastive,
  title={Contrastive behavioral similarity embeddings for generalization in reinforcement learning},
  author={Agarwal, Rishabh and Machado, Marlos C and Castro, Pablo Samuel and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2101.05265},
  year={2021}
}


@inproceedings{yuan2022robust,
  title={Robust task representations for offline meta-reinforcement learning via contrastive learning},
  author={Yuan, Haoqi and Lu, Zongqing},
  booktitle={International Conference on Machine Learning},
  pages={25747--25759},
  year={2022},
  organization={PMLR}
}

@article{ajay2022distributionally,
  title={Distributionally adaptive meta reinforcement learning},
  author={Ajay, Anurag and Gupta, Abhishek and Ghosh, Dibya and Levine, Sergey and Agrawal, Pulkit},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25856--25869},
  year={2022}
}


@article{xiong2021practical,
  title={On the practical consistency of meta-reinforcement learning algorithms},
  author={Xiong, Zheng and Zintgraf, Luisa and Beck, Jacob and Vuorio, Risto and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2112.00478},
  year={2021}
}


@article{fakoor2019meta,
  title={Meta-q-learning},
  author={Fakoor, Rasool and Chaudhari, Pratik and Soatto, Stefano and Smola, Alexander J},
  journal={arXiv preprint arXiv:1910.00125},
  year={2019}
}
@inproceedings{melo2022transformers,
  title={Transformers are meta-reinforcement learners},
  author={Melo, Luckeciano C},
  booktitle={international conference on machine learning},
  pages={15340--15359},
  year={2022},
  organization={PMLR}
}
@inproceedings{wang2023meta,
  title={Meta-reinforcement learning based on self-supervised task representation learning},
  author={Wang, Mingyang and Bing, Zhenshan and Yao, Xiangtong and Wang, Shuai and Kai, Huang and Su, Hang and Yang, Chenguang and Knoll, Alois},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={8},
  pages={10157--10165},
  year={2023}
}



@article{packer2021hindsight,
  title={Hindsight task relabelling: Experience replay for sparse reward meta-rl},
  author={Packer, Charles and Abbeel, Pieter and Gonzalez, Joseph E},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={2466--2477},
  year={2021}
}

@article{dorfman2021offline,
  title={Offline Meta Reinforcement Learning--Identifiability Challenges and Effective Data Collection Strategies},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4607--4618},
  year={2021}
}

@inproceedings{wan2021hindsight,
  title={Hindsight Foresight Relabeling for Meta-Reinforcement Learning},
  author={Wan, Michael and Peng, Jian and Gangwani, Tanmay},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{jiang2024doubly,
  title={Doubly robust augmented transfer for meta-reinforcement learning},
  author={Jiang, Yuankun and Kan, Nuowen and Li, Chenglin and Dai, Wenrui and Zou, Junni and Xiong, Hongkai},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{lin2020model,
  title={Model-based adversarial meta-reinforcement learning},
  author={Lin, Zichuan and Thomas, Garrett and Yang, Guangwen and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10161--10173},
  year={2020}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{bhardwaj2024data,
  title={Data-Efficient Task Generalization via Probabilistic Model-based Meta Reinforcement Learning},
  author={Bhardwaj, Arjun and Rothfuss, Jonas and Sukhija, Bhavya and As, Yarden and Hutter, Marco and Coros, Stelian and Krause, Andreas},
  journal={IEEE Robotics and Automation Letters},
  year={2024},
  publisher={IEEE}
}

@inproceedings{hiraoka2021meta,
  title={Meta-model-based meta-policy optimization},
  author={Hiraoka, Takuya and Imagawa, Takahisa and Tangkaratt, Voot and Osa, Takayuki and Onishi, Takashi and Tsuruoka, Yoshimasa},
  booktitle={Asian Conference on Machine Learning},
  pages={129--144},
  year={2021},
  organization={PMLR}
}
@article{lin2022model,
  title={Model-based offline meta-reinforcement learning with regularization},
  author={Lin, Sen and Wan, Jialin and Xu, Tengyu and Liang, Yingbin and Zhang, Junshan},
  journal={arXiv preprint arXiv:2202.02929},
  year={2022}
}

@article{nagabandi2018learning,
  title={Learning to adapt in dynamic, real-world environments through meta-reinforcement learning},
  author={Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1803.11347},
  year={2018}
}

@article{belkhale2021model,
  title={Model-based meta-reinforcement learning for flight with suspended payloads},
  author={Belkhale, Suneel and Li, Rachel and Kahn, Gregory and McAllister, Rowan and Calandra, Roberto and Levine, Sergey},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={2},
  pages={1471--1478},
  year={2021},
  publisher={IEEE}
}

@article{zhang2020learning,
  title={Learning robust state abstractions for hidden-parameter block mdps},
  author={Zhang, Amy and Sodhani, Shagun and Khetarpal, Khimya and Pineau, Joelle},
  journal={arXiv preprint arXiv:2007.07206},
  year={2020}
}

@inproceedings{sodhani2022block,
  title={Block contextual mdps for continual learning},
  author={Sodhani, Shagun and Meier, Franziska and Pineau, Joelle and Zhang, Amy},
  booktitle={Learning for Dynamics and Control Conference},
  pages={608--623},
  year={2022},
  organization={PMLR}
}

@inproceedings{xumeta,
  title={Meta-Reinforcement Learning Robust to Distributional Shift Via Performing Lifelong In-Context Learning},
  author={Xu, Tengye and Li, Zihao and Ren, Qinyuan},
  booktitle={International Conference on Machine Learning},
  year={2024},
}

@article{mendonca2020meta,
  title={Meta-reinforcement learning robust to distributional shift via model identification and experience relabeling},
  author={Mendonca, Russell and Geng, Xinyang and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.07178},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{duan2016rl,
  title={Rl $\^{} 2$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@article{gao2024context,
  title={Context shift reduction for offline meta-reinforcement learning},
  author={Gao, Yunkai and Zhang, Rui and Guo, Jiaming and Wu, Fan and Yi, Qi and Peng, Shaohui and Lan, Siming and Chen, Ruizhi and Du, Zidong and Hu, Xing and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{greenberg2024train,
  title={Train hard, fight easy: Robust meta reinforcement learning},
  author={Greenberg, Ido and Mannor, Shie and Chechik, Gal and Meirom, Eli},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}


@inproceedings{wang2023offline,
  title={Offline meta reinforcement learning with in-distribution online adaptation},
  author={Wang, Jianhao and Zhang, Jin and Jiang, Haozhe and Zhang, Junyu and Wang, Liwei and Zhang, Chongjie},
  booktitle={International Conference on Machine Learning},
  pages={36626--36669},
  year={2023},
  organization={PMLR}
}

@inproceedings{clavera2018model,
  title={Model-based reinforcement learning via meta-policy optimization},
  author={Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  booktitle={Conference on Robot Learning},
  pages={617--629},
  year={2018},
  organization={PMLR}
}

@inproceedings{liu2023robust,
  title={Robust representation learning by clustering with bisimulation metrics for visual reinforcement learning with distractions},
  author={Liu, Qiyuan and Zhou, Qi and Yang, Rui and Wang, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={7},
  pages={8843--8851},
  year={2023}
}

@inproceedings{hansen2022bisimulation,
  title={Bisimulation makes analogies in goal-conditioned reinforcement learning},
  author={Hansen-Estruch, Philippe and Zhang, Amy and Nair, Ashvin and Yin, Patrick and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={8407--8426},
  year={2022},
  organization={PMLR}
}

@article{chen2022learning,
  title={Learning representations via a robust behavioral metric for deep reinforcement learning},
  author={Chen, Jianda and Pan, Sinno},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36654--36666},
  year={2022}
}
@article{castro2021mico,
  title={MICo: Improved representations via sampling-based state similarity for Markov decision processes},
  author={Castro, Pablo Samuel and Kastner, Tyler and Panangaden, Prakash and Rowland, Mark},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={30113--30126},
  year={2021}
}

@article{lan2019meta,
  title={Meta reinforcement learning with task embedding and shared policy},
  author={Lan, Lin and Li, Zhenguo and Guan, Xiaohong and Wang, Pinghui},
  journal={arXiv preprint arXiv:1905.06527},
  year={2019}
}
@article{mu2022domino,
  title={Domino: Decomposed mutual information optimization for generalized context in meta-reinforcement learning},
  author={Mu, Yao and Zhuang, Yuzheng and Ni, Fei and Wang, Bin and Chen, Jianyu and Hao, Jianye and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27563--27575},
  year={2022}
}

@article{li2020multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Christensen, Henrik and Su, Hao},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6197--6210},
  year={2020}
}

@article{ren2022efficient,
  title={Efficient meta reinforcement learning for preference-based fast adaptation},
  author={Ren, Zhizhou and Liu, Anji and Liang, Yitao and Peng, Jian and Ma, Jianzhu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15502--15515},
  year={2022}
}

@inproceedings{zhou2024generalizable,
  title={Generalizable Task Representation Learning for Offline Meta-Reinforcement Learning with Data Limitations},
  author={Zhou, Renzhe and Gao, Chen-Xiao and Zhang, Zongzhang and Yu, Yang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={15},
  pages={17132--17140},
  year={2024}
}


@inproceedings{guan2024cost,
  title={Cost-aware Offline Safe Meta Reinforcement Learning with Robust In-Distribution Online Task Adaptation.},
  author={Guan, Cong and Xue, Ruiqi and Zhang, Ziqian and Li, Lihe and Li, Yi-Chen and Yuan, Lei and Yu, Yang},
  booktitle={AAMAS},
  pages={743--751},
  year={2024}
}
@inproceedings{pong2022offline,
  title={Offline meta-reinforcement learning with online self-supervision},
  author={Pong, Vitchyr H and Nair, Ashvin V and Smith, Laura M and Huang, Catherine and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={17811--17829},
  year={2022},
  organization={PMLR}
}



@article{eysenbach2018diversity,
  title={Diversity is all you need: Learning skills without a reward function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.06070},
  year={2018}
}

@inproceedings{campos2020explore,
  title={Explore, discover and learn: Unsupervised discovery of state-covering skills},
  author={Campos, V{\'\i}ctor and Trott, Alexander and Xiong, Caiming and Socher, Richard and Gir{\'o}-i-Nieto, Xavier and Torres, Jordi},
  booktitle={International Conference on Machine Learning},
  pages={1317--1327},
  year={2020},
  organization={PMLR}
}

@article{park2023controllability,
  title={Controllability-aware unsupervised skill discovery},
  author={Park, Seohong and Lee, Kimin and Lee, Youngwoon and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2302.05103},
  year={2023}
}


@article{nam2022skill,
  title={Skill-based meta-reinforcement learning},
  author={Nam, Taewook and Sun, Shao-Hua and Pertsch, Karl and Hwang, Sung Ju and Lim, Joseph J},
  journal={arXiv preprint arXiv:2204.11828},
  year={2022}
}
@article{fu2022meta,
  title={Meta-learning parameterized skills},
  author={Fu, Haotian and Yu, Shangqun and Tiwari, Saket and Littman, Michael and Konidaris, George},
  journal={arXiv preprint arXiv:2206.03597},
  year={2022}
}
@inproceedings{he2024decoupling,
  title={Decoupling Meta-Reinforcement Learning with Gaussian Task Contexts and Skills},
  author={He, Hongcai and Zhu, Anjie and Liang, Shuang and Chen, Feiyu and Shao, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={11},
  pages={12358--12366},
  year={2024}
}


@article{jabri2019unsupervised,
  title={Unsupervised curricula for visual meta-reinforcement learning},
  author={Jabri, Allan and Hsu, Kyle and Gupta, Abhishek and Eysenbach, Ben and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{yoo2022skills,
  title={Skills regularized task decomposition for multi-task offline reinforcement learning},
  author={Yoo, Minjong and Cho, Sangwoo and Woo, Honguk},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={37432--37444},
  year={2022}
}



@article{wang2023supervised,
  title={Supervised Meta-Reinforcement Learning With Trajectory Optimization for Manipulation Tasks},
  author={Wang, Lei and Zhang, Yunzhou and Zhu, Delong and Coleman, Sonya and Kerr, Dermot},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  volume={16},
  number={2},
  pages={681--691},
  year={2023},
  publisher={IEEE}
}

@article{mendonca2019guided,
  title={Guided meta-policy search},
  author={Mendonca, Russell and Gupta, Abhishek and Kralev, Rosen and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{zou2024relabeling,
  title={Relabeling and policy distillation of hierarchical reinforcement learning},
  author={Zou, Qijie and Zhao, Xiling and Gao, Bing and Chen, Shuang and Liu, Zhiguo and Zhang, Zhejie},
  journal={International Journal of Machine Learning and Cybernetics},
  pages={1--17},
  year={2024},
  publisher={Springer}
}

@inproceedings{kirsch2022introducing,
  title={Introducing symmetries to black box meta reinforcement learning},
  author={Kirsch, Louis and Flennerhag, Sebastian and Van Hasselt, Hado and Friesen, Abram and Oh, Junhyuk and Chen, Yutian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={7},
  pages={7202--7210},
  year={2022}
}

@inproceedings{liu2021decoupling,
  title={Decoupling exploration and exploitation for meta-reinforcement learning without sacrifices},
  author={Liu, Evan Z and Raghunathan, Aditi and Liang, Percy and Finn, Chelsea},
  booktitle={International conference on machine learning},
  pages={6925--6935},
  year={2021},
  organization={PMLR}
}

@inproceedings{zhang2021metacure,
  title={Metacure: Meta reinforcement learning with empowerment-driven exploration},
  author={Zhang, Jin and Wang, Jianhao and Hu, Hao and Chen, Tong and Chen, Yingfeng and Fan, Changjie and Zhang, Chongjie},
  booktitle={International Conference on Machine Learning},
  pages={12600--12610},
  year={2021},
  organization={PMLR}
}


@inproceedings{zintgraf2021exploration,
  title={Exploration in approximate hyper-state space for meta reinforcement learning},
  author={Zintgraf, Luisa M and Feng, Leo and Lu, Cong and Igl, Maximilian and Hartikainen, Kristian and Hofmann, Katja and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={12991--13001},
  year={2021},
  organization={PMLR}
}


@inproceedings{wang2024metacard,
  title={MetaCARD: Meta-Reinforcement Learning with Task Uncertainty Feedback via Decoupled Context-Aware Reward and Dynamics Components},
  author={Wang, Min and Li, Xin and Zhang, Leiji and Wang, Mingzhong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={14},
  pages={15555--15562},
  year={2024}
}


@article{imagawa2022off,
  title={Off-policy meta-reinforcement learning with belief-based task inference},
  author={Imagawa, Takahisa and Hiraoka, Takuya and Tsuruoka, Yoshimasa},
  journal={IEEE Access},
  volume={10},
  pages={49494--49507},
  year={2022},
  publisher={IEEE}
}

@inproceedings{ni2023metadiffuser,
  title={Metadiffuser: Diffusion model as conditional planner for offline meta-rl},
  author={Ni, Fei and Hao, Jianye and Mu, Yao and Yuan, Yifu and Zheng, Yan and Wang, Bin and Liang, Zhixuan},
  booktitle={International Conference on Machine Learning},
  pages={26087--26105},
  year={2023},
  organization={PMLR}
}

@article{humplik2019meta,
  title={Meta reinforcement learning as task inference},
  author={Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas},
  journal={arXiv preprint arXiv:1905.06424},
  year={2019}
}

@inproceedings{lee2020context,
  title={Context-aware dynamics model for generalization in model-based reinforcement learning},
  author={Lee, Kimin and Seo, Younggyo and Lee, Seunghyun and Lee, Honglak and Shin, Jinwoo},
  booktitle={International Conference on Machine Learning},
  pages={5757--5766},
  year={2020},
  organization={PMLR}
}






@article{frans2017meta,
  title={Meta learning shared hierarchies},
  author={Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
  journal={arXiv preprint arXiv:1710.09767},
  year={2017}
}

@article{harrison2020continuous,
  title={Continuous meta-learning without tasks},
  author={Harrison, James and Sharma, Apoorva and Finn, Chelsea and Pavone, Marco},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17571--17581},
  year={2020}
}

@article{mehta2020curriculum,
  title={Curriculum in gradient-based meta-reinforcement learning},
  author={Mehta, Bhairav and Deleu, Tristan and Raparthy, Sharath Chandra and Pal, Chris J and Paull, Liam},
  journal={arXiv preprint arXiv:2002.07956},
  year={2020}
}







@inproceedings{hejna2023few,
  title={Few-shot preference learning for human-in-the-loop rl},
  author={Hejna III, Donald Joseph and Sadigh, Dorsa},
  booktitle={Conference on Robot Learning},
  pages={2014--2025},
  year={2023},
  organization={PMLR}
}



@article{ishfaq2024offline,
  title={Offline multitask representation learning for reinforcement learning},
  author={Ishfaq, Haque and Nguyen-Tang, Thanh and Feng, Songtao and Arora, Raman and Wang, Mengdi and Yin, Ming and Precup, Doina},
  journal={arXiv preprint arXiv:2403.11574},
  year={2024}
}

@article{cheng2022provable,
  title={Provable benefit of multitask representation learning in reinforcement learning},
  author={Cheng, Yuan and Feng, Songtao and Yang, Jing and Zhang, Hong and Liang, Yingbin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31741--31754},
  year={2022}
}

@inproceedings{sodhani2021multi,
  title={Multi-task reinforcement learning with context-based representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={9767--9779},
  year={2021},
  organization={PMLR}
}

@article{rimon2024mamba,
  title={Mamba: an effective world model approach for meta-reinforcement learning},
  author={Rimon, Zohar and Jurgenson, Tom and Krupnik, Orr and Adler, Gilad and Tamar, Aviv},
  journal={arXiv preprint arXiv:2403.09859},
  year={2024}
}

@ARTICLE{10565991,
  author={Wen, Lu and Tseng, Eric H. and Peng, Huei and Zhang, Songan},
  journal={IEEE Robotics and Automation Letters}, 
  title={Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination}, 
  year={2024},
  volume={9},
  number={11},
  pages={9701-9708},
  keywords={Task analysis;Training;Decoding;Reinforcement learning;Metalearning;Linear programming;Interpolation;Reinforcement learning;machine learning for robot control;deep learning methods},
  doi={10.1109/LRA.2024.3417114}}


@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@inproceedings{
yeom2024exclusively,
title={Exclusively Penalized Q-learning for Offline Reinforcement Learning},
author={Junghyuk Yeom and Yonghyeon Jo and Jeongmo Kim and Sanghyeon Lee and Seungyul Han},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=2bdSnxeQcW}
}


@InProceedings{pmlr-v162-chae22a,
  title = 	 {Robust Imitation Learning against Variations in Environment Dynamics},
  author =       {Chae, Jongseong and Han, Seungyul and Jung, Whiyoung and Cho, Myungsik and Choi, Sungho and Sung, Youngchul},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {2828--2852},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/chae22a/chae22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/chae22a.html},
  abstract = 	 {In this paper, we propose a robust imitation learning (IL) framework that improves the robustness of IL when environment dynamics are perturbed. The existing IL framework trained in a single environment can catastrophically fail with perturbations in environment dynamics because it does not capture the situation that underlying environment dynamics can be changed. Our framework effectively deals with environments with varying dynamics by imitating multiple experts in sampled environment dynamics to enhance the robustness in general variations in environment dynamics. In order to robustly imitate the multiple sample experts, we minimize the risk with respect to the Jensen-Shannon divergence between the agent’s policy and each of the sample experts. Numerical results show that our algorithm significantly improves robustness against dynamics perturbations compared to conventional IL baselines.}
}

































