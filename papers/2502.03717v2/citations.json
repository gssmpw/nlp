[
  {
    "index": 0,
    "papers": [
      {
        "key": "caluwaerts2023barkour",
        "author": "Caluwaerts, Ken and Iscen, Atil and Kew, J Chase and Yu, Wenhao and Zhang, Tingnan and Freeman, Daniel and Lee, Kuang-Huei and Lee, Lisa and Saliceti, Stefano and Zhuang, Vincent and others",
        "title": "Barkour: Benchmarking animal-level agility with quadruped robots"
      },
      {
        "key": "fu2021minimizing",
        "author": "Fu, Zipeng and Kumar, Ashish and Malik, Jitendra and Pathak, Deepak",
        "title": "Minimizing energy consumption leads to the emergence of gaits in legged robots"
      },
      {
        "key": "margolis2023walk",
        "author": "Margolis, Gabriel B and Agrawal, Pulkit",
        "title": "Walk these ways: Tuning robot control for generalization with multiplicity of behavior"
      },
      {
        "key": "kumar2021rma",
        "author": "Kumar, Ashish and Fu, Zipeng and Pathak, Deepak and Malik, Jitendra",
        "title": "Rma: Rapid motor adaptation for legged robots"
      },
      {
        "key": "lee2020learning",
        "author": "Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco",
        "title": "Learning quadrupedal locomotion over challenging terrain"
      },
      {
        "key": "yang2022fast",
        "author": "Yang, Yuxiang and Zhang, Tingnan and Coumans, Erwin and Tan, Jie and Boots, Byron",
        "title": "Fast and efficient locomotion via learned gait transitions"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "lee2020learning",
        "author": "Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco",
        "title": "Learning quadrupedal locomotion over challenging terrain"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "fu2021minimizing",
        "author": "Fu, Zipeng and Kumar, Ashish and Malik, Jitendra and Pathak, Deepak",
        "title": "Minimizing energy consumption leads to the emergence of gaits in legged robots"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "margolis2023walk",
        "author": "Margolis, Gabriel B and Agrawal, Pulkit",
        "title": "Walk these ways: Tuning robot control for generalization with multiplicity of behavior"
      },
      {
        "key": "tang2023saytap",
        "author": "Tang, Yujin and Yu, Wenhao and Tan, Jie and Zen, Heiga and Faust, Aleksandra and Harada, Tatsuya",
        "title": "Saytap: Language to quadrupedal locomotion"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "liang2023code",
        "author": "Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy",
        "title": "Code as policies: Language model programs for embodied control"
      },
      {
        "key": "brohan2023can",
        "author": "Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others",
        "title": "Do as i can, not as i say: Grounding language in robotic affordances"
      },
      {
        "key": "yu2023language",
        "author": "Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others",
        "title": "Language to rewards for robotic skill synthesis"
      },
      {
        "key": "mahadevan2024generative",
        "author": "Mahadevan, Karthik and Chien, Jonathan and Brown, Noah and Xu, Zhuo and Parada, Carolina and Xia, Fei and Zeng, Andy and Takayama, Leila and Sadigh, Dorsa",
        "title": "Generative expressive robot behaviors using large language models"
      },
      {
        "key": "thumm2024text2interaction",
        "author": "Thumm, Jakob and Agia, Christopher and Pavone, Marco and Althoff, Matthias",
        "title": "Text2Interaction: Establishing Safe and Preferable Human-Robot Interaction"
      },
      {
        "key": "ma2023eureka",
        "author": "Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima",
        "title": "Eureka: Human-level reward design via coding large language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "brohan2023can",
        "author": "Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others",
        "title": "Do as i can, not as i say: Grounding language in robotic affordances"
      },
      {
        "key": "liang2023code",
        "author": "Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy",
        "title": "Code as policies: Language model programs for embodied control"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liang2024learning",
        "author": "Liang, Jacky and Xia, Fei and Yu, Wenhao and Zeng, Andy and Arenas, Montserrat Gonzalez and Attarian, Maria and Bauza, Maria and Bennice, Matthew and Bewley, Alex and Dostmohamed, Adil and others",
        "title": "Learning to Learn Faster from Human Feedback with Language Model Predictive Control"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kwon2023reward",
        "author": "Kwon, Minae and Xie, Sang Michael and Bullard, Kalesha and Sadigh, Dorsa",
        "title": "Reward design with language models"
      },
      {
        "key": "hu2023language",
        "author": "Hu, Hengyuan and Sadigh, Dorsa",
        "title": "Language instructed reinforcement learning for human-ai coordination"
      },
      {
        "key": "yu2023language",
        "author": "Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others",
        "title": "Language to rewards for robotic skill synthesis"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yu2023language",
        "author": "Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others",
        "title": "Language to rewards for robotic skill synthesis"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "tang2023saytap",
        "author": "Tang, Yujin and Yu, Wenhao and Tan, Jie and Zen, Heiga and Faust, Aleksandra and Harada, Tatsuya",
        "title": "Saytap: Language to quadrupedal locomotion"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "casper2023open",
        "author": "Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\\'e}r{\\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others",
        "title": "Open problems and fundamental limitations of reinforcement learning from human feedback"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "li2021learning",
        "author": "Li, Mengxi and Canberk, Alper and Losey, Dylan P and Sadigh, Dorsa",
        "title": "Learning human objectives from sequences of physical corrections"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "knox2009interactively",
        "author": "Knox, W Bradley and Stone, Peter",
        "title": "Interactively shaping agents via human reinforcement: The TAMER framework"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "myers2022learning",
        "author": "Myers, Vivek and Biyik, Erdem and Anari, Nima and Sadigh, Dorsa",
        "title": "Learning multimodal rewards from rankings"
      },
      {
        "key": "brown2019extrapolating",
        "author": "Brown, Daniel and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott",
        "title": "Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "hejna2023few",
        "author": "Hejna III, Donald Joseph and Sadigh, Dorsa",
        "title": "Few-shot preference learning for human-in-the-loop rl"
      },
      {
        "key": "lee2021pebble",
        "author": "Lee, Kimin and Smith, Laura and Abbeel, Pieter",
        "title": "Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training"
      },
      {
        "key": "sadigh2017active",
        "author": "Sadigh, Dorsa and Dragan, Anca D and Sastry, Shankar and Seshia, Sanjit A",
        "title": "Active preference-based learning of reward functions"
      },
      {
        "key": "ziegler1909fine",
        "author": "Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey",
        "title": "Fine-tuning language models from human preferences. arXiv 2019"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "lee2021pebble",
        "author": "Lee, Kimin and Smith, Laura and Abbeel, Pieter",
        "title": "Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training"
      },
      {
        "key": "hejna2023few",
        "author": "Hejna III, Donald Joseph and Sadigh, Dorsa",
        "title": "Few-shot preference learning for human-in-the-loop rl"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "peng2024preference",
        "author": "Peng, Andi and Bobu, Andreea and Li, Belinda Z and Sumers, Theodore R and Sucholutsky, Ilia and Kumar, Nishanth and Griffiths, Thomas L and Shah, Julie A",
        "title": "Preference-Conditioned Language-Guided Abstraction"
      },
      {
        "key": "mahmud2024maple",
        "author": "Mahmud, Saaduddin and Nakamura, Mason and Zilberstein, Shlomo",
        "title": "MAPLE: A Framework for Active Preference Learning Guided by Large Language Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "sadigh2017active",
        "author": "Sadigh, Dorsa and Dragan, Anca D and Sastry, Shankar and Seshia, Sanjit A",
        "title": "Active preference-based learning of reward functions"
      },
      {
        "key": "biyik2018batch",
        "author": "Biyik, Erdem and Sadigh, Dorsa",
        "title": "Batch active preference-based learning of reward functions"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "yu2024few",
        "author": "Yu, Chao and Lu, Hong and Gao, Jiaxuan and Tan, Qixin and Yang, Xinting and Wang, Yu and Wu, Yi and Vinitsky, Eugene",
        "title": "Few-shot in-context preference learning using large language models"
      }
    ]
  }
]