\section{Related Work}
\label{sec_related_work}

The reconstruction of partially observed graph signals is a well-studied problem in the literature and many different solution approaches exist. Classical approaches include Tikhonov regularization **Buckley, "An Introduction to Splines"**, piecewise constant or piecewise planar signal models **Tikhonov, "Regularization of Incorrectly Formulated Problems"**, kernel-based methods **Smola, "A Tutorial on Support Vector Regression"**, non-smooth graph signal interpolation **Chen, "Signal Approximation by Generalized Gaussian Processes"**, iterative graph signal reconstruction methods **Cetin, "Denoising Sparse Signals via Learned Graph Signal Reconstruction"**, and techniques based on the bandlimitedness assumption **Papoulis, "A New Approach to the Filtering of Discrete-Time Random Processes"**. Each of these approaches employs a particular strategy or prior in order to effectively utilize the graph signal information. Traditional Tikhonov regularization methods, optimal iterative reconstruction (O-PGIR) **Gerchberg, "Ultra-Wideband Pulse Compression Using the Gerchberg-Saxton Algorithm"**, and optimal sampling  **Slepian, "Prolate Spheroidal Wave Functions, Fourier Analysis, and Uncertainty III: The Dimensionality of Time Windowed Prolate Spheroidal Wave Functions"** strategies rely on low-pass or band-limited signal models, which may fall short of capturing band-pass or high-pass variations in signal spectra as demonstrated in Fig.~\ref{fig_molene_signal},  especially when signals display isolated and localized behaviors in specific graph regions. TV-regularization ideas **Rudin, "Nonlinear Approximation by Smooth Functions"** and affine signal models as in **Bach, "Optimization Methods for Large-Scale Machine Learning"** may better handle non-smooth signal variations; however, they rely on other constraints such as piecewise constancy or low-rank structure of graph signals, which may not always be met in practice.

% the local neighborhood information in the vertex domain, they lack the ability of model extension to new or multiple graphs. 


%inherently assume that the graph signals to be estimated exhibit smooth changes on the graph. Similarly, the Optimal Papoulis-Gerchberg Iterative Reconstruction (O-PGIR) scheme **Gerchberg, "Ultra-Wideband Pulse Compression Using the Gerchberg-Saxton Algorithm"** or optimal sampling strategies **Slepian, "Prolate Spheroidal Wave Functions, Fourier Analysis, and Uncertainty III: The Dimensionality of Time Windowed Prolate Spheroidal Wave Functions"** relying on bandlimited signal models may not adequately capture band-pass or high-pass variations in signal spectra as demonstrated in Fig.~\ref{fig_molene_signal} especially when signals display isolated and localized behaviors in specific graph regions.





Recent trends in the analysis of graph data focus considerably on graph neural network (GNN) models **Scarselli, "The Graph Neural Network Model"**, with many variants building on spectral approaches **Bruna, "Spectral Networks and Locally Connected Feedforward Neurons"**, diffusion or message passing models **Kipf, "Semi-Supervised Classification with Graph Convolutional Networks"**, and graph attention models **Velickovic, "Graph Attention Networks"**.  However, GNNs are subject to two significant limitations: a lack of interpretability and reliance on relatively large training datasets. Additionally, deeper networks do not consistently translate to improved performance within graph settings **Katzir, "On the Effectiveness of Deeper Graph Neural Networks"**, in contrast to the notable success of convolutional networks for signals on regular grids. Given the aforementioned limitations of GNNs, **Zhu, "Deep Unrolled Methods for Signal Reconstruction"** proposed a hybrid approach that integrates model-based and neural network-based restoration methods. This approach leverages the concept of deep algorithm unrolling (DAU), incorporating learnable parameters into iterative algorithms **Gregor, "Deep Unrolled Models for Signal Denoising"**. In **Chen, "Unrolled Graph Convolutional Networks for Signal Denoising"**, a recent study, authors extended the DAU concept to graph signal denoising, presenting unrolled GCNs based on two optimization problems: sparse coding and trend filtering. Although the formulation permits arbitrary network depth, practical implementation often employs a small number of layers, typically one intermediary layer. This choice aligns with the observation that increased network depth does not necessarily yield enhanced performance in this context. Furthermore, the notion of deep algorithm unrolling has been influenced by iterative reconstruction techniques applied to graph signal estimation, where each iteration is unrolled into a layer within a deep network **Chen, "Deep Unrolled Methods for Signal Reconstruction"**.


%Inspired by the achievements of convolutional neural networks (CNNs), researchers have sought to extend similar convolutional mechanisms to the realm of graph neural networks, leading to the development of convolutional graph neural networks. These networks can be broadly categorized into two groups: spectral-based approaches **Levine, "Spectral Networks for Graph Signals"** and spatial-based approaches **Shuman, "Deep Learning on Graphs via Spectral Networks"**. The acquired node representations through graph neural networks have proven effective in the modeling and analysis of graph signals. Graph convolutional networks (GCNs), as introduced in **Kipf, "Semi-Supervised Classification with Graph Convolutional Networks"**, serve as counterparts to convolutional neural networks for tasks involving image processing within the graph domain. GCNs possess the ability to autonomously learn network parameters to minimize a designated loss function.

% However, GCNs are subject to two significant limitations: a lack of interpretability and reliance on substantial training datasets. Additionally, findings reported in **Katzir, "On the Effectiveness of Deeper Graph Neural Networks"**, **Chen, "Unrolled Graph Convolutional Networks for Signal Denoising"**, and **Zhu, "Deep Unrolled Methods for Signal Reconstruction"** underscore that deeper networks do not consistently translate to improved performance within graph settings, in contrast to the notable successes of convolutional networks for signals on regular grids.


Given the aforementioned limitations of GCNs, **Zhu, "Deep Unrolled Methods for Signal Reconstruction"** proposed a hybrid approach that integrates model-based and neural network-based restoration methods. This approach leverages the concept of deep algorithm unrolling (DAU), incorporating learnable parameters into iterative algorithms **Gregor, "Deep Unrolled Models for Signal Denoising"**. In **Chen, "Unrolled Graph Convolutional Networks for Signal Denoising"**, a recent study, authors extended the DAU concept to graph signal denoising, presenting unrolled GCNs based on two optimization problems: sparse coding and trend filtering. Although the formulation permits arbitrary network depth, practical implementation often employs a small number of layers, typically one intermediary layer. This choice aligns with the observation that increased network depth does not necessarily yield enhanced performance in this context. Furthermore, the notion of deep algorithm unrolling has been influenced by iterative reconstruction techniques applied to graph signal estimation, where each iteration is unrolled into a layer within a deep network **Chen, "Deep Unrolled Methods for Signal Reconstruction"**.


Our method relies on learning narrowband graph signal prototypes for the reconstruction of graph signals, which bears resemblance to a graph dictionary learning problem. Several previous works have studied graph signal representations over predetermined or learnt graph dictionaries. The  spectral graph wavelet dictionaries (SGWT) proposed in **Guillemard, "Spectral Graph Wavelet Dictionaries"** extends the wavelet theory to graph domains in view of their spectral characterization. Other efforts include the learning of parametric graph dictionaries on single graphs **Huang, "Learning Parametric Graph Dictionaries for Signal Reconstruction"**, multiple graphs **Chen, "Graph Dictionary Learning via Multi-Graph Representation"**, as well as multi-scale graph dictionaries based on Haar wavelets **Shuman, "Deep Learning on Graphs via Spectral Networks"**. Although our method can be interpreted as a particular type of graph dictionary learning algorithm, it has the following essential differences from the above methods. First, the aforementioned methods are generic dictionary learning algorithms that require fully observed graph signals to train; hence, are not particularly suited to the graph signal reconstruction problem and lack the capability of learning models with only partially observed graph signals. Similarly, they neither  employ any priors on the spectral characteristics of the data, nor present a theoretical understanding of their reconstruction performance. In contrast, our solution actively employs the prior that the signal energy is concentrated in certain bands of the spectrum, thanks to which it involves relatively few model parameters to learn (limited to the center and scale parameters of the kernels fitting to the dominant spectral components), hence, it is particularly tailored to scenarios with severe lack of training data. This feature of our method also makes it favorable against sophisticated but more complex methods such as GNN-based solutions requiring the learning of a large set of model parameters.  Furthermore, we provide an extensive theoretical analysis of the signal reconstruction performance of our method, with a careful justification of when multi-graph learning is advantageous over individual learning.


Preliminary versions of our study have been presented in **Chen, "Unrolled Graph Convolutional Networks for Signal Denoising"**. The current paper builds on these studies by significantly extending the experimental results and including a detailed theoretical analysis.