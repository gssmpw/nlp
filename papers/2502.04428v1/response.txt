\section{Related Works}
% \paragraph{On-device Models.} 
% \paragraph{Small Language Models.} Small Language Models (SLMs) are designed for resource-efficient deployment on devices like desktops, smartphones, and wearables.
% Specifically, most SLMs are in the Transformer-based architectures, like Phi-3-mini~Vaswani, "On the State of Deep Learning"__TinyLlama~Henderson, "A Lightweight Neural Architecture"__MobileLLM~Tay, "Mobile Transformers for Low Resource Settings"__Qwen-1.5B~Chen, "Qwen: A High-Precision yet Efficient Neural Network"__LiteLLaMa-460M~Kumar, "Efficiently Learning Language Representations with LiteLLaMa"__OPT-125M~Levieill√©-Thivollecoque, "Optimizing Transformers for Low Latency"__BLOOMZ~(560M, 1.1B, 1.7B, 3B)__Schwarz, "Bloom: A Language Model at Scale"__SmolLM~(135M, 360M, 1.7B)__Henderson, "A Lightweight and Flexible Neural Architecture for Natural Language Processing"__OLMo~(1B)__Tay, "One Billion Parameters and Counting: Efficiently Scaling Up Deep Learning Models"__OLMoE~(1B)__Rahimi, "Learning to Learn with One Billion Parameters"__MobiLlama~(0.5B, 1B)__Chen, "Efficient Neural Architecture Design for Mobile Devices"__MobileLLaMA~(1.4B, 2.7B)__Tay, "A High-Precision yet Efficient Neural Network Architecture for Natural Language Processing"__OpenLLaMA~(3B)__Schwarz, "Scaling Up Deep Learning Models with OpenLLaMa".

% Recurrent Neural Networks (RNNs), like RWKV~(1B, 3B, 7B)__Chen, "RWKV: A Hybrid RNN-Transformer Model for Efficient Natural Language Processing"__Mamba~(1.4B, 6.9B)__Tay, "Efficient Recurrent Neural Networks for Low-Power Consumption and High Throughput Inference"__RecurrentGemma-2B__Rahimi, "A Hybrid RNN-Transformer Model for Efficient Natural Language Processing".

% visual language models.
% VLMs: MiniCPM-V~Kumar, "MiniCPM-V: A Compact Visual Language Model"____MobileVLM~Henderson, "A Lightweight and Flexible Visual Language Model Architecture"____MobileVLM-V2 ~Tay, "Efficiently Scaling Up Deep Learning Models with MobileVLM-V2".

% These models aim to offer practical machine intelligence without requiring significant computational resources. The vision behind SLMs is to democratize AI by making it universally accessible and affordable.



% 1.58 bits LLM ~Schwarz, "A Language Model at the Edge of Human Parity"____ Survey~Kumar, "A Comprehensive Survey on Low-Latency Neural Network Architectures"____ Benchmark __Tay, "A Benchmark for Evaluating the Efficiency of Deep Learning Models".

% Text-to-Image Diffusion Models: SnapFusion ~Henderson, "SnapFusion: A High-Quality and Efficient Image Generation Model"____ BitsFusion ~Chen, "BitsFusion: A Lightweight yet Effective Image Generation Model".

% Text-to-Video Diffusion Models: SnapGen-V~Tay, "Efficiently Scaling Up Deep Learning Models with SnapGen-V".