[
  {
    "index": 0,
    "papers": [
      {
        "key": "abdin2024phi",
        "author": "Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others",
        "title": "Phi-3 technical report: A highly capable language model locally on your phone"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zhang2024tinyllama",
        "author": "Zhang, Peiyuan and Zeng, Guangtao and Wang, Tianduo and Lu, Wei",
        "title": "Tinyllama: An open-source small language model"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liu2024mobilellm",
        "author": "Liu, Zechun and Zhao, Changsheng and Iandola, Forrest and Lai, Chen and Tian, Yuandong and Fedorov, Igor and Xiong, Yunyang and Chang, Ernie and Shi, Yangyang and Krishnamoorthi, Raghuraman and others",
        "title": "Mobilellm: Optimizing sub-billion parameter language models for on-device use cases"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "bai2023qwen",
        "author": "Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others",
        "title": "Qwen technical report"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zhang2022opt",
        "author": "Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others",
        "title": "Opt: Open pre-trained transformer language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "le2023bloom",
        "author": "Le Scao, Teven and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\\'c}, Suzana and Hesslow, Daniel and Castagn{\\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\\c{c}}ois and Gall{\\'e}, Matthias and others",
        "title": "Bloom: A 176b-parameter open-access multilingual language model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "allal2024SmolLM",
        "author": "Loubna Ben Allal and Anton Lozhkov and Elie Bakouch and Leandro von Werra and Thomas Wolf",
        "title": "SmolLM - blazingly fast and remarkably powerful"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Groeneveld2023OLMo",
        "author": "Groeneveld, Dirk and Beltagy, Iz and Walsh, Pete and Bhagia, Akshita and Kinney, Rodney and Tafjord, Oyvind and Jha, Ananya Harsh and Ivison, Hamish and Magnusson, Ian and Wang, Yizhong and Arora, Shane and Atkinson, David and Authur, Russell and Chandu, Khyathi and Cohan, Arman and Dumas, Jennifer and Elazar, Yanai and Gu, Yuling and Hessel, Jack and Khot, Tushar and Merrill, William and Morrison, Jacob and Muennighoff, Niklas and Naik, Aakanksha and Nam, Crystal and Peters, Matthew E. and Pyatkin, Valentina and Ravichander, Abhilasha and Schwenk, Dustin and Shah, Saurabh and Smith, Will and Strubell, Emma and Subramani, Nishant and Wortsman, Mitchell and Dasigi, Pradeep and Lambert, Nathan and Richardson, Kyle and Zettlemoyer, Luke and Dodge, Jesse and Lo, Kyle and Soldaini, Luca and Smith, Noah A. and Hajishirzi, Hannaneh",
        "title": "OLMo: Accelerating the Science of Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "muennighoff2024olmoeopenmixtureofexpertslanguage",
        "author": "Niklas Muennighoff and Luca Soldaini and Dirk Groeneveld and Kyle Lo and Jacob Morrison and Sewon Min and Weijia Shi and Pete Walsh and Oyvind Tafjord and Nathan Lambert and Yuling Gu and Shane Arora and Akshita Bhagia and Dustin Schwenk and David Wadden and Alexander Wettig and Binyuan Hui and Tim Dettmers and Douwe Kiela and Ali Farhadi and Noah A. Smith and Pang Wei Koh and Amanpreet Singh and Hannaneh Hajishirzi",
        "title": "OLMoE: Open Mixture-of-Experts Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "thawakar2024mobillama",
        "author": "Omkar Thawakar and Ashmal Vayani and Salman Khan and Hisham Cholakkal and Rao Muhammad Anwer and Michael Felsberg and Timothy Baldwin and Eric P. Xing and Fahad Shahbaz Khan",
        "title": "MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "chu2024mobilevlm",
        "author": "Chu, Xiangxiang and Qiao, Limeng and Zhang, Xinyu and Xu, Shuang and Wei, Fei and Yang, Yang and Sun, Xiaofei and Hu, Yiming and Lin, Xinyang and Zhang, Bo and others",
        "title": "Mobilevlm v2: Faster and stronger baseline for vision language model"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "openlm2023openllama",
        "author": "Geng, Xinyang and Liu, Hao",
        "title": "OpenLLaMA: An Open Reproduction of LLaMA"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "peng2023rwkv",
        "author": "Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Biderman, Stella and Cao, Huanqi and Cheng, Xin and Chung, Michael and Grella, Matteo and others",
        "title": "Rwkv: Reinventing rnns for the transformer era"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "dao2024transformers",
        "author": "Dao, Tri and Gu, Albert",
        "title": "Transformers are SSMs: Generalized models and efficient algorithms through structured state space duality"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "griffin2024recurrentgemma",
        "author": "Griffin, RLHF and Teams, Gemma",
        "title": "Recurrentgemma: Moving past transformers for efficient open language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "yao2024minicpm",
        "author": "Yao, Yuan and Yu, Tianyu and Zhang, Ao and Wang, Chongyi and Cui, Junbo and Zhu, Hongji and Cai, Tianchi and Li, Haoyu and Zhao, Weilin and He, Zhihui and others",
        "title": "Minicpm-v: A gpt-4v level mllm on your phone"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "chu2023mobilevlm",
        "author": "Chu, Xiangxiang and Qiao, Limeng and Lin, Xinyang and Xu, Shuang and Yang, Yang and Hu, Yiming and Wei, Fei and Zhang, Xinyu and Zhang, Bo and Wei, Xiaolin and others",
        "title": "Mobilevlm: A fast, reproducible and strong vision language assistant for mobile devices"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "chu2024mobilevlm",
        "author": "Chu, Xiangxiang and Qiao, Limeng and Zhang, Xinyu and Xu, Shuang and Wei, Fei and Yang, Yang and Sun, Xiaofei and Hu, Yiming and Lin, Xinyang and Zhang, Bo and others",
        "title": "Mobilevlm v2: Faster and stronger baseline for vision language model"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ma2024era",
        "author": "Ma, Shuming and Wang, Hongyu and Ma, Lingxiao and Wang, Lei and Wang, Wenhui and Huang, Shaohan and Dong, Li and Wang, Ruiping and Xue, Jilong and Wei, Furu",
        "title": "The era of 1-bit llms: All large language models are in 1.58 bits"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "chen2024llm",
        "author": "Chen, Daihang and Liu, Yonghui and Zhou, Mingyi and Zhao, Yanjie and Wang, Haoyu and Wang, Shuai and Chen, Xiao and Bissyand{\\'e}, Tegawend{\\'e} F and Klein, Jacques and Li, Li",
        "title": "Llm for mobile: An initial roadmap"
      },
      {
        "key": "lu2024small",
        "author": "Lu, Zhenyan and Li, Xiang and Cai, Dongqi and Yi, Rongjie and Liu, Fangming and Zhang, Xiwen and Lane, Nicholas D and Xu, Mengwei",
        "title": "Small language models: Survey, measurements, and insights"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "murthy2024mobileaibench",
        "author": "Murthy, Rithesh and Yang, Liangwei and Tan, Juntao and Awalgaonkar, Tulika Manoj and Zhou, Yilun and Heinecke, Shelby and Desai, Sachin and Wu, Jason and Xu, Ran and Tan, Sarah and others",
        "title": "MobileAIBench: Benchmarking LLMs and LMMs for On-Device Use Cases"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "li2024snapfusion",
        "author": "Li, Yanyu and Wang, Huan and Jin, Qing and Hu, Ju and Chemerys, Pavlo and Fu, Yun and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian",
        "title": "Snapfusion: Text-to-image diffusion model on mobile devices within two seconds"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "sui2024bitsfusion",
        "author": "Sui, Yang and Li, Yanyu and Kag, Anil and Idelbayev, Yerlan and Cao, Junli and Hu, Ju and Sagar, Dhritiman and Yuan, Bo and Tulyakov, Sergey and Ren, Jian",
        "title": "BitsFusion: 1.99 bits Weight Quantization of Diffusion Model"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "wu2024snapgen",
        "author": "Wu, Yushu and Zhang, Zhixing and Li, Yanyu and Xu, Yanwu and Kag, Anil and Sui, Yang and Coskun, Huseyin and Ma, Ke and Lebedev, Aleksei and Hu, Ju and others",
        "title": "SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device"
      }
    ]
  }
]