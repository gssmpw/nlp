\section{Related Works}
% \paragraph{On-device Models.} 
% \paragraph{Small Language Models.} Small Language Models (SLMs) are designed for resource-efficient deployment on devices like desktops, smartphones, and wearables.
% Specifically, most SLMs are in the Transformer-based architectures, like Phi-3-mini____, TinyLlama____, MobileLLM____, and Qwen-1.5B____, LiteLLaMa-460M, OPT-125M____, BLOOMZ~(560M, 1.1B, 1.7B, 3B)____, SmolLM~(135M, 360M, 1.7B)____, OLMo~(1B)____, OLMoE~(1B)____, MobiLlama~(0.5B, 1B)____, MobileLLaMA~(1.4B, 2.7B)____, OpenLLaMA~(3B)____.
% These models are designed with lightweight architectures to operate effectively within the constraints of mobile devices and edge hardware.

% Recurrent Neural Networks (RNNs), like RWKV~(1B, 3B, 7B)____, Mamba~(1.4B, 6.9B)____, and RecurrentGemma-2B____, can provide promising solutions for on-device inference in resource-constrained environments. 
% These models leverage the recurrent nature of RNNs to process sequential data efficiently without requiring KV cache, which is suitable for resource-constrained on edge devices. 
% Specifically, RWKV introduces a hybrid RNN-Transformer backbone to capture long-term dependencies while maintaining computational efficiency. 
% Similarly, Mamba and RecurrentGemma design recurrent layers for low-power consumption and high throughput inference, which can significantly reduce memory and computational requirements, fostering low-latency applications directly on devices.

% visual language models.
% VLMs: MiniCPM-V ____, MobileVLM____, MobileVLM-V2 ____, 

% These models aim to offer practical machine intelligence without requiring significant computational resources. The vision behind SLMs is to democratize AI by making it universally accessible and affordable.



% 1.58 bits LLM ____,  Survey ____, Benchmark ____.
% Text-to-Image Diffusion Models: SnapFusion ____, BitsFusion ____, 
% Text-to-Video Diffusion Models: SnapGen-V ____

% https://github.com/NexaAI/Awesome-LLMs-on-device