\section{Related Work}
\label{Related work}
\textbf{Trajectory Prediction For Autonomous Driving.} {
In the field of trajectory prediction, the analysis of prediction performance is often categorized into short-term and long-term horizons \cite{chen2022intention, wang2025wake}. Early research employed physical models to represent vehicle motion dynamics, thereby estimating future trajectories. In \cite{brannstrom2010model}, a trajectory prediction model based on the bicycle model was proposed and successfully applied to an accident warning system. While physical models achieved significant progress in short-term prediction horizons, their inherent simplicity limited their performance in long-term predictions \cite{wang2024dynamics}. The complexity of human driving behavior, influenced by numerous factors such as cognitive processes, interactions with surrounding vehicles, and environmental conditions, renders long-term prediction a particularly challenging task \cite{wang2025wake,liao2024human2}. In response to these challenges, researchers have begun integrating deep learning models to account for these factors in the trajectory prediction process.
Notable prior efforts \cite{wang2023wsip, ijcai2024p656,liao2024bat} have explored the complex social dynamics among traffic participants, revealing crucial latent insights that enhance predictive accuracy. Transformer-based models \cite{ijcai2024p756,wang2024nest} have been increasingly employed for their ability to predict future trajectory distributions effectively. Graph Neural Networks (GNNs) are also gaining traction for capturing dynamic interactions in complex traffic scenes \cite{rowe2023fjmp,ijcai2024p657}. These approaches primarily focus on understanding the temporal and spatial interplays between traffic agents from historical data to optimize accuracy. Generative models \cite{ijcai2024p811}, including Variational Auto Encoders (VAEs), Diffusion models, and Generative Adversarial Networks (GANs), are also being explored for their potential to generate multiple future trajectory possibilities from latent distributions, offering a probabilistic perspective of future paths in this field.}

\textbf{Perceived Safety Concept.} The notion of perceived safety has been a focal point in psychology and physical human-robot interaction (pHRI) studies \cite{guiochet2017safety}. In pHRI, it is crucial for assessing and representing individuals' perceptions of danger and comfort during interactions with autonomous systems like mobile robots \cite{chen2020yard}, industrial manipulators \cite{davis2023role}, humanoid robots \cite{busch2019evaluation} and AVs \cite{sun2021joint}. Despite its relevance, perceived safety remains a challenging concept to quantify due to its subjective nature \cite{bartneck2009measurement}. Our study breaks new ground in this area by proposing a novel quantitative criterion for perceived safety in self-driving trajectory prediction, drawing from Safety State Metrics (SSMs) and human decision-making processes. This innovation enables our model to more accurately interpret driving behavior and traffic conditions, thereby enhancing prediction accuracy in mixed autonomy environments.

\textbf{Driving Behavior Understanding.} Existing studies in driving behavior have formulated various criteria and metrics for detecting and representing driving patterns, using scales like the Social Value Orientation (SVO) \cite{murphy2011measuring}, Driving Anger Scale (DAS) \cite{deffenbacher1994development}, among others \cite{taubman2004multidimensional}. While these methods have been successful, as noted by \cite{schwarting2019social} and \cite{chandra2020cmetric}, they typically depend on manually annotated labels and predetermined sliding time windows for analysis. Our research diverges from these traditional approaches by proposing a dynamic, adaptive set of behavior-aware criteria. This model captures driving behavior in real-time through continuous behavioral data representation, eliminating the reliance on manual labeling in the training phase. This novel approach not only offers enhanced flexibility over fixed-category methods but also effectively addresses the challenges of label shifts and time window selection, leading to a more accurate and fluid representation of driving behavior. This advancement significantly contributes to the development of more refined and effective behavior prediction methodologies in autonomous driving systems.
\begin{table*}[htbp]
\centering
\caption{Primary notations and their meanings.}
\begin{multicols}{2}
\begin{tabularx}{\columnwidth}{cX}
    \toprule
\textbf{Notation} & \textbf{Meaning} \\
 \midrule
$\bm{X}_{0}^{t-t_{h}:t}$ & Historical states of the target vehicle within a defined duration $t_{h}$\\
$\bm{X}_{1:n}^{t-t_{h}:t}$ & Historical states of surrounding agents $1$ to $n$ within the duration $t_{h}$ \\
$\bm{Y}_{0}^{t: t+t_{f}}$  & Predicted future trajectory of target vehicle over the ensuing \( t_{f} \) time intervals\\
$p_{0:n}^{t-t_{h}:t}$ & x- and y- coordinates of the target vehicle and surrounding agents from time horizon \( t-t_{h} \) to \( t \)\\
$v_{0:n}^{t-t_{h}:t}$ & Velocity of the target vehicle and its surrounding agents from \( t-t_{h} \) to \( t \) \\
$t_h$ & Acceleration of the target vehicle and its surrounding agents from \( t-t_{h} \) to \( t \) \\
$n$ & Number of surrounding vehicles \\
$M$ & Total number of the predicted potential trajectories\\
$\hat{\bm{x}}_i$ & Original longitudinal coordinates of vehicle $i$ \\
$\bm{M}$ & Probability of different maneuvers\\
$\tau_{\mathrm{sc}}$ & Given time threshold $i$ \\
$a_{i}$ & Acceleration of the traffic agent $i$ \\
$v_{x}^{t}$ & Lateral velocity \\
$v_{y}^{t}$ & Longitudinal position velocity at time $t$\\
$p_{x}^{t}$ & Longitudinal position coordinates at time $t$\\
$p_{y}^{t}$ & Horizontal coordinate\\
$\mathcal{S}_{i}^{t}$ &Safe Magnitude Index for the $i$-th traffic agent at time $t$ \\
$\bm{H}$ & Set of safety indices\\
$I_N$ & Identity Matrix\\
$A$ & Adjacency matrix\\
$\tilde{\mathbf{A}}$ & Degree matrix for normalizing the graph structure \\
$\mathbf{Z}^{k+1}_i$   & Learned feature matrix the $i$-th agent from GCNs \\
 ${\alpha}^{\textit{behavior }}$ & Output generated by the multi-head self-attention mechanism for DBP\\
  ${\alpha}^{\textit{priority }}$ & Output of the multi-head self-attention mechanism for the Priority-Aware Module\\
\bottomrule
\end{tabularx}

\begin{tabularx}{\columnwidth}{cX}
\toprule
\textbf{Notation} & \textbf{Meaning} \\
 \midrule
 $h_s$ & Total number of attention heads for QSA\\
 ${\alpha}^{\textit{safety }}$ & Output of the multi-head self-attention mechanism for QSA\\
${G}^{t}$ & Dynamic geometric graph at time step $t$\\
$V^{t}$ & Node set of the DGG at time step $t$\\
${v}_{i}^{t}$ & $i$-th node of the DGG at time step $t$\\
$v_{i}^{t}$ & Edge of the $i$-th node at time step $t$\\
$d(v_{i}^{t}, v_{j}^{t})$ & Shortest distance between $i$-th and $j$th node\\
$\mathcal{N}_{i}^{t}$ &Neighborhood set of $i$-th node at time step $t$\\
${\mathcal{J}}_{i}^{{t}}$ &Behavior-awre criteria of $i$-th node at time step $t$\\
${J}_{i}^{t}(D)$ & Degree centrality of $i$-th node at time step $t$\\
${J}_{i}^{t}(C)$ & Closeness centrality of $i$-th node at time step $t$\\
${J}_{i}^{t}(E)$ & Eigenvector centrality of $i$-th node at time step $t$\\
${J}_{i}^{t}(B)$ &Betweenness centrality of the $i$-th node at time step $t$\\
${J}_{i}^{t}(P)$ &Power centrality of $i$-th node at time step $t$\\
${J}_{i}^{t}(K)$ & Katz centrality of $i$-th node at time step $t$\\
$\left| \mathcal{N}_{i}^{t}\right|$ & Total elements in Neighborhood set $\mathcal{N}_{i}^{t}$ \\
$\sigma_{j,k}$ & Total number of shortest paths between $v_{j}^{t}$ and $v_{k}^{t}$ at time step $t$\\
$\sigma_{j,k}(v_{i})$ & Number of the paths traversing $v_{i}^{t}$ at time step $t$\\
$A^{k}_{ii}$ & $i$-th diagonal element of the adjacency matrix to the $k$-th power\\
 $k!$ & Factorial of $k$\\
$\alpha^{k}$ & Decay factor\\
$\beta^{k}$ & Weight for immediate neighbor nodes\\
$d_{k}$&Dimensionality of the projected key vectors for the Leanformer framework\\
${\bar{O}_{\textit{safety}}}^{t-t{h}:t}$ & Safety feature output from the QSA\\
${\bar{O}_{\textit{behavior}}}$ & Behavior feature output from the DBP\\
${\bar{O}}$ & Output from the Interaction-Aware Module\\
${{O}}_{\textit{priority}}^{t-t_{h}:t}$ & Behavior feature output from the Priority-Aware Module\\
$\mathbf{Y}^{\text{pred}}(T)$ & Predicted trajectories at the prediction horizon $T$\\
$\mathbf{Y}^{\text{gt}}(T)$ & Ground-truth trajectory at the  horizon $T$\\
 \bottomrule
\end{tabularx}
\end{multicols}
\label{table_variables}%
\end{table*}



\begin{figure*}[t]
  \centering
\includegraphics[width=0.93\textwidth]{Figures/framework.png} 
  \caption{Pipeline of CITF. It is an encoder-decoder model (a) and includes four essential parts: Perceived Safety-Aware Module generates both safety and behavior features through driver behavior profiling (b) and quantitative safety assessment (c) components, respectively. These features, along with the priority feature derived from the Priority-Aware Module, are integrated into the Interaction-Aware Module, embedded by the Leanformer framework. Finally, this integration results in a high-level fusion, which is then fed into the Multimodal Decoder to produce a multimodal prediction distribution for the target vehicle.}
  \label{fig1} 
\end{figure*}