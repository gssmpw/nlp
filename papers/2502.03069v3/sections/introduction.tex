
\section{Introduction}
Building 3D worlds and objects for Virtual Reality (VR) has become increasingly accessible, enabling users to immerse themselves in detailed environments and actively (co-)create them. Recent advances have also seen the integration of generative Artificial Intelligence (AI) in this process~\cite{10.1145/3613904.3642579}, leveraging text prompts and other inputs to generate elaborate 3D objects and even entire 3D worlds.
However, these emerging approaches often rely on a "set-it-and-forget-it" approach, where users input a prompt and receive a fully realized 3D object or world with limited opportunities for customization or interaction. 
While this trend toward AI-driven generation can democratize access to high-quality 3D objects, it challenges human agency and shifts control from humans to AI.

To empower users to get more involved in the design process, a stream of research has started exploring co-creative systems, which enable users to collaborate with AI in a creative process \cite{davis_human-computer_2013}. These systems have been applied across a variety of domains, including music, storytelling, game design, and visual arts~\cite{liapis_sentient_2013,lucas_stay_2017,davis_empirically_2016,oh_i_2018,lin_it_2020}. 
There has been growing interest in extending such co-creative systems to 3D object co-creation in recent years. AI systems can now generate and modify 3D objects based on user inputs such as text prompts or sketches~\cite{poole_dreamfusion_2022, lin_magic3d_2023, michel_text2mesh_2021, jun_shap-e_2023, mikaeili_sked_2023, lun_3d_2017}, and some systems even allow for interactive refinement of AI outputs \cite{liu_interactive_2018, urban_davis_designing_2021}.

Despite these advances, a critical question remains largely unexplored: how should the actions of a co-creative tool for object generation be represented in VR? 
This question touches on fundamental aspects of co-creative interactions and raises several essential considerations:
(1) Human collaborative work often involves asynchronous or gradual changes, making immediate modifications potentially counterintuitive. Should AI-driven changes to 3D objects be presented incrementally, mirroring the rhythm of human collaboration, or is immediate modification more appropriate in co-creation?
(2) Drawing from the literature on non-player characters (NPCs), the embodiment is often deemed crucial for effective interaction. However, does this hold for a co-creative system focused on object generation, which may not inherently require an embodied visualization as NPCs do? Does the user perception of the system change from a tool to a collaborator only through embodiment, and if yes, what are the potential downsides?
(3) Decades of HCI research and design practices emphasize highlighting focus or activity (e.g., showing all cursors in collaborative text editing tools or speaker indicators in video conferencing). 
Is visually indicating where and how AI modifications occur sufficient for co-creative object generation systems, or do these systems necessitate new ways of co-creative interaction?





Addressing these questions is pivotal to advancing the design of co-creative systems for 3D objects and world generation.
This paper contributes to answering these questions by investigating different representations of AI actions in the context of co-creating 3D objects in VR (see \autoref{fig:teaser}).
Specifically, we examine the aforementioned three aspects of co-creating a 3D object in VR in a Wizard-of-Oz user study on (1) perception of embodiment, (2) incremental visualization of co-creative contributions, and (3) effect of highlighting the area where the AI is going to perform a modification. 
Our findings show that co-creating with an embodied AI significantly influences the perceived AI contribution to the created model. Further, highlighting does not increase predictability or communication with the AI system but decreases users' enjoyment and a perceived partnership with the AI. Finally, users pay more attention to the AI when it uses an incremental generation.

In summary, the contributions of this paper are two-fold:
First, we conduct a Wizard-of-Oz user study to examine the influence of highlighting, incremental visualization, and embodiment on user perception, collaboration, overall system appeal, and behavioral engagement. We contribute empirical insights into how the different representation strategies affect the co-creative experience in VR-based object-building.
Secondly, based on the study's results, we provide implications for designing future co-creative object-building tools in VR.







