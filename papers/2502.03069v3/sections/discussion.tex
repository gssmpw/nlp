\section{Discussion and Implications}
In this section, we revisit our quantitative and qualitative analysis results to interpret them and derive implications for the future design of co-creative VR systems. Additionally, we discuss the generalizability and limitations of this work.

\subsection{Highlighting does not alleviate the confusion caused by AI actions}
We found the highlighting to decrease perceived partnership, enjoyment, and satisfaction with the finished model. At the same time, highlighting did not affect the system's predictability, the perceived communication between humans and AI, the users' attention toward the AI, or the clarity of AI intent, which we expected to be most likely affected by highlighting. On the qualitative side, the observational analysis also did not indicate that highlighting object parts caused differences in participant behavior. This result is supported by participants never referring to highlighting during the modeling sessions or interviews. 
Our quantitative and qualitative findings suggest that highlighting is not as much of a mitigator against user confusion about AI intentions as expected and might lead to a more negative overall experience. Future research should investigate whether these adverse effects can be replicated or if they occur similarly with different implementations of a highlighting variable. 


\begin{leftbar}{lightgray}
    \noindent \textbf{Design implication for highlighting}\quad
    For co-creation use cases where users create one complete object at a time, like in our use case, we recommend not highlighting changes. In particular, in combination with embodied AI avatars, it introduced more negative effects than it contributed to user satisfaction. Future work has to show if highlighting proves more useful for co-creation use cases of dynamic objects.
\end{leftbar}  


\subsection{Incremental visualization increases the attention to AI actions but introduces unexpected side effects}
Since most participants watched all incremental visualization processes from beginning to end, it is unsurprising that this variable significantly affected the attention participants paid to the AI. However, we also expected that the visualization aspect would affect the perceived efficiency of the system, which our quantitative analysis did not confirm. Considering that participants were likely aware that the AI was not generating model parts "on the spot," they likely interpreted this process as the loading time of the overall setup. This interpretation also explains why the incremental visualization did not affect predictability, competence, unusualness, value, creativity, or contribution, as we hypothesized.

Further, this lack of impact on the perception of the AI and its outputs could be caused by the specific incremental visualization we used. This incremental visualization was inspired by AI drawing agents that build images stroke-by-stroke. Transferring this concept directly into 3D space resulted in an AI agent that slowly draws individual horizontal lines of different colored pixels, which does not correspond to our experiences in the physical world. A possibly more appropriate 3D equivalent could be the molding or carving of primitives.
Future work should investigate whether alternative ways of incrementally visualizing 3D modifications affect observers' perceptions of the system differently.

Another surprising finding is that incremental visualization increased the perceived unexpectedness of AI outputs. This finding contrasts with our hypothesis that incremental visualization would lead to a decrease in unexpectedness rather than an increase, as the longer visualization duration gave participants more time to familiarize themselves with the modified version of an object part. We attribute this reverse effect to participants having had more time to engage with the version of an object part due to the extra time (e.g., to think about what the fully instantiated version of the object part would look like or what kind of change they would have expected instead at this point). As a result, they perceived the AI outputs as more unexpected than in conditions where the output appeared immediately, and participants had no choice but to immediately accept them as the new version of an object part.

Additionally, our interviews revealed that incremental visualization was perceived more positively when an avatar appeared to carry out the incremental process. We attribute this to a more sympathetic attitude towards an AI with characteristics similar to the user's. An AI that does not have a physical or virtual body might be expected not to be limited by time and space to the same degree as a human and might, therefore, seem more capable of performing actions that would be impossible for a human user. On the other hand, an embodied AI might appear to be constrained by its surroundings in similar ways to a human. It would make sense for a human user to be more sympathetic toward AI, which "has to" slowly work on its task until it is finished, and therefore, to feel more like the AI is equal to the user. One participant also applied this idea to the "tool" that the AI used in the incremental process, which was a line that looked similar to the pointer ray that participants used to interact with the VR environment. It would be interesting for future work to study whether the effects of this similarity of tools only apply when a similarity of processes (i.e., an incremental process) is also given or whether the same effect can be observed given an instantaneous visualization. 


\begin{leftbar}{lightgray}
    \noindent \textbf{Design implication for incremental visualization}\quad
    We recommend using an immediate creation of content to co-create complete objects, where the creation process is unimportant. We ground this in our findings where incremental generation did not reduce participants' feelings of unexpectedness, while at the same time, the visualization took longer. However, we recommend incremental visualization for use cases where the process of creating objects is important and where users should observe the generation more closely, and time is no relevant factor.
\end{leftbar}  

\subsection{Embodiment not only affects the relationship to the AI but also to the 3D model created}
Embodiment was the visualization aspect that participants had the most substantial feelings about. The divergence in comfort levels regarding the presence of the avatar was unexpected: To avoid an avatar design that created feelings of uncanniness in users~\cite{mori_uncanny_2012}, we intentionally chose an avatar for our AI that was heavily caricatured and only distantly resembled the form of a human, as well as one that had a friendly, child-like appearance. We do not know whether participants' discomfort with the avatar was indeed a case of the uncanny valley, whether it was only due to the surprise participants felt when they were faced with the avatar for the first time, or whether it can be attributed to characteristics that are specific to co-creative systems. 

The divergence in participants' discomfort with the avatar is also a possible explanation for why embodiment did not significantly affect ratings of factors measuring appeal. Nevertheless, our qualitative analysis indicated an improvement in the perceived relationship between users and the AI when the avatar was present, manifested by an increased tangibility of the relationship, the feeling of being less alone, and more empathy expressed towards the AI. This result is consistent with quantitative data pointing to an effect of embodiment on partnership and AI-human communication.


As hypothesized, AI embodiment did affect the extent to which participants felt that the AI contributed to the finished 3D model. This result suggests that factors external to the AI functionality can manipulate users' perceptions of who created an artifact. This finding is noteworthy considering ongoing discussions around ownership of AI-generated content, as the question of who created an artifact is often one of the most influential in deciding who owns it \cite{rezwana_user_2023}. Rezwana and Maher \cite{rezwana_user_2023} found that this decision of ownership, and additionally users' stances on other AI-related moral dilemmas, is also greatly influenced by the perception of a co-creative AI partner as either a collaborator or as a tool. Considering our finding that the embodiment of our AI significantly affected participants' perceptions of the AI as a partner rather than a tool, we argue that such ethical questions should be kept in mind when deciding whether to integrate an AI avatar into a co-creative system. This result is in line with Buschek et al. \cite{buschek_nine_2021} listing unclarity of ownership as a potential pitfall in the design of co-creative systems.


\begin{leftbar}{lightgray}
    \noindent \textbf{Design implication for embodiment}\quad
    We recommend using an embodied AI for most co-creation use cases, as it increases the perceived support of the system, leads to a higher perceived partnership and communication, and leads to users paying more attention to the creation. However, users also felt reduced ownership of the outcome, which should be considered when designing a system. For use cases where users need a tool and the creative, collaborative aspect is less relevant, the non-embodied AI might be the appropriate choice, as it is faster, and users have higher ownership of the outcome.
\end{leftbar}  







