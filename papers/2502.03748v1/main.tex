%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\input{math_commands.tex}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{bm}
\usepackage{rotating}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}
\usepackage{multirow}
\input{math_commands}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}
% \usepackage{icml2025}
% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\definecolor{c5}{HTML}{b71a3b}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{subcaption}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand{\Lapl}{\mathbf{\mathop{\mathcal{L}}}}
\newcommand{\lapl}{\mathcal{L}}
\newcommand{\Trans}[1]{{#1}^{\top}}
\newcommand{\Trace}[1]{tr\left({#1}\right)}
\newcommand{\Bracs}[1]{\left({#1}\right)}
\newcommand{\Mat}[1]{\mathbf{\boldsymbol{#1}}}
\newcommand{\MatS}[3]{\mathbf{#1}^{#2}_{#3}}
\newcommand{\Space}[1]{\mathbb{#1}}
\newcommand{\Set}[1]{\mathcal{#1}}
\newcommand{\vectornorm}[1]{\left|\left|#1\right|\right|}
\newcommand{\std}[1]{\scriptsize{$\pm$#1}}
\newcommand{\boldit}[1]{\textbf{\textit{#1}}}
% \DeclareMathOperator*{\argmax}{arg\,max}
% \DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\sgn}{sgn}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Rethinking the Residual Distribution of Locate-then-Editing Methods in Model Editing}

\begin{document}

\twocolumn[
\icmltitle{Rethinking Residual Distribution in Locate-then-Edit Model Editing}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.

\icmlsetsymbol{corr}{*}

\begin{icmlauthorlist}
\icmlauthor{Xiaopeng Li}{yyy}
\icmlauthor{Shanwen Wang}{yyy}
\icmlauthor{Shasha Li}{yyy,corr}
\icmlauthor{Shezheng Song}{yyy}
\icmlauthor{Bin Ji}{yyy}
\icmlauthor{Jun Ma}{yyy,corr}
\icmlauthor{Jie Yu}{yyy,corr}
% \icmlauthor{Xiaodong Liu}{yyy}
% \icmlauthor{Weimin Zhang}{yyy}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{National University of Defense Technology}

\icmlcorrespondingauthor{Xiaopeng Li}{\{xiaopengli\}@nudt.edu.cn}
% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{*Corresponding Author.}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Model editing is a powerful technique for updating the knowledge of Large Language Models (LLMs). Locate-then-edit methods are a popular class of approaches that first identify the critical layers storing knowledge, then compute the residual of the last critical layer based on the edited knowledge, and finally perform multi-layer updates using a least-squares solution by evenly distributing the residual from the first critical layer to the last. Although these methods achieve promising results, they have been shown to degrade the original knowledge of LLMs. We argue that residual distribution leads to this issue. To explore this, we conduct a comprehensive analysis of residual distribution in locate-then-edit methods from both empirical and theoretical perspectives, revealing that residual distribution introduces editing errors, leading to inaccurate edits. To address this issue, we propose the \textbf{B}oundary \textbf{L}ayer \textbf{U}pdat\textbf{E} (BLUE) strategy to enhance locate-then-edit methods. Sequential batch editing experiments on three LLMs and two datasets demonstrate that BLUE not only delivers an average performance improvement of 35.59\%, significantly advancing the state of the art in model editing, but also enhances the preservation of LLMs' general capabilities. Our code is available at \href{https://github.com/xpq-tech/BLUE}{this GitHub repository}.
\end{abstract}


\section{Introduction}
\label{sec:intro}
Large language models (LLMs) possess powerful comprehension and generation capabilities and have become foundational infrastructure for various AI applications \cite{zhao2023survey}. However, the knowledge encoded in the parameters of LLMs is limited to the training data and cannot be updated to reflect changes in world knowledge. Updating the parameters of LLMs through retraining to keep them in sync with world knowledge entails high computational costs \cite{wang2023knowledge}. Recently, model editing has garnered increasing attention as a promising technique for efficiently updating the parameterized knowledge in LLMs. This approach aims to correct erroneous or outdated knowledge within LLMs without compromising their other capabilities \cite{yao-etal-2023-editing}.

% Model editing methods can be broadly categorized into parameter-preserving and parameter-modifying approaches, depending on whether the original parameters of LLMs are altered. Parameter-preserving methods achieve model editing by attaching additional modules to the LLM, either modifying input contexts \cite{zhong2023mquake} or altering input representations \cite{NEURIPS2023_95b6e2ff,li2024sweaupdatingfactualknowledge}. These methods typically deliver satisfactory editing performance without directly modifying the original parameters of the model. Moreover, their detachable nature helps to safeguard the integrity of the original model.
% %
% However, the use of extra modules increases storage and inference overhead, which can impact system efficiency. This challenge becomes particularly significant when a large amount of knowledge needs to be edited.
%
% In contrast, parameter-modifying methods directly operate on the original parameters of the model \cite{zhu2020modifying,mitchell2022fast,Meng2022Locating}. While this approach introduces some perturbations to the original parameters, the edited model retains the same structure as the original model without the burden of additional modules. Moreover, with carefully designed algorithms, these perturbations can be controlled to minimize their impact on the model's other capabilities \cite{fang2024alphaedit}. 
%
Locate-then-edit methods are a popular series in model editing. They treat the Feed-Forward Network (FFN) as a key-value memory \cite{geva-etal-2021-transformer} and update the critical layers that store factual knowledge using a least-squares solution. Specifically, locate-then-edit methods first employ causal tracing analysis  to identify multiple critical layers within LLMs that store factual knowledge. They then use optimization techniques to compute the residual required for updating the final critical layer. Finally, they evenly distribute the residual of the last critical layer from the first critical layer to the last one and perform updates based on the least-squares solution~\cite{Meng2022Locating,meng2022massediting}. 

Although locate-then-edit methods have achieved remarkable results in model editing tasks \cite{fang2024alphaedit}, they have been shown to degrade the original knowledge of LLMs \cite{gu2024model}. From a coarse-grained perspective, locate-then-edit methods consist of three key elements: the key-value memory perspective, updates based on least-squares solutions, and residual distribution. The key-value memory perspective and least-squares-based updates are theoretically sound~\cite{Meng2022Locating,meng2022massediting}. 
%we empirically and theoretically find that residual distribution actually has a negative impact on locate-then-edit methods.
While the role of residual distribution remains to be verified. We argue that residual distribution leads to the degradation of original knowledge. To explore this, we analyze the rationale behind residual distribution in locate-then-edit methods.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{figs/BLUE_overview.pdf}
    \caption{Comparison of existing locate-then-edit methods and BLUE.}
    \label{fig:blue_overview}
\end{figure}
Specifically, we first empirically demonstrate that the contribution of residual distribution to model editing diminishes as the distribution distance increases and that the distributed residual is not the optimal residual for editing. Subsequently, we theoretically find that the upper bound of weight update errors increases with: (a) the size of the editing batch, (b) the number of sequential edits, and (c) the residual distribution distance. These findings indicate that \textbf{residual distribution can actually negatively impact the model editing of the locate-then-edit approaches}. Therefore, we propose the \textbf{B}oundary \textbf{L}ayer \textbf{U}pdat\textbf{E} (\textbf{BLUE}) strategy, which enhances locate-then-edit methods by updating only the first and last critical layers through direct computation of residuals, without residual distribution. The comparison between BLUE and existing locate-then-edit methods is shown in Figure \ref{fig:blue_overview}. We apply BLUE to enhance MEMIT, AlphaEdit, PRUNE, and RECT. Results from 12 sequential editing experiments conducted on three LLMs and two datasets show that BLUE improves the performance of existing locate-then-edit methods by an average of \textbf{35.59}\%. Our further analysis on downstream tasks and representation shift demonstrates that BLUE also enhances the ability of locate-then-edit methods to preserve general capabilities and mitigates representation shifts in the post-edit LLMs. In summary, our contributions are as follows:
\begin{itemize}
    \item Through empirical and theoretical analysis of residual distribution, we find that residual distribution actually leads to inaccurate model editing. 
    \item We propose the BLUE strategy, which discards residual distribution and enhances existing locate-then-edit methods by updating only the first and last critical layers through direct residual computation.
    \item Experimental results show that locate-then-edit methods enhanced with BLUE outperform the original methods and better preserve LLMs' general capabilities.
\end{itemize}
\section{Related Work}
\label{relatedwork}
Model editing can be categorized into \textbf{parameter-preserving} and \textbf{parameter-modifying} approaches, depending on whether the original model parameters are altered.

\textbf{Parameter-preserving} model editing employs techniques like prompt engineering or attaching additional parameters \cite{zhong2023mquake,li2024sweaupdatingfactualknowledge,huang2023transformer,wang2024wiserethinkingknowledgememory}. A representative method for prompt engineering is IKE \cite{zheng-etal-2023-edit}, which retrieves $n$ contexts of the edited knowledge for a query to guide the model's response without altering its internal parameters. Methods that attach additional parameters include SERAC \cite{mitchell2022memory} and GRACE \cite{hartvigsen2024aging}, which store new memories externally and internally, respectively, by introducing new parameter modules.

\textbf{Parameter-modifying} approaches achieve model editing by directly or indirectly adjusting model parameters \cite{tan2024massiveeditinglargelanguage,deng2024unke}. Direct methods, such as FT-L \cite{zhu2020modifying}, perform constrained fine-tuning on a small number of layers to integrate new knowledge. Indirect methods can be divided into \textbf{meta-learning} and \textbf{locate-then-edit} methods. \textbf{Meta-learning} methods, like MEND \cite{mitchell2022fast}, leverage a hypernetwork to transform edit-related representations and gradients into parameter updates. In contrast, \textbf{locate-then-edit} methods, such as ROME \cite{Meng2022Locating} and MEMIT \cite{meng2022massediting}, adopt a key-value memory perspective to identify and update single or multiple critical layers using least-squares optimization. Among these, locate-then-edit methods have gained popularity and inspired several variants, such as PMET \cite{li2024pmet}, which focuses on precise editing, and AlphaEdit \cite{fang2024alphaedit}, which enhances the retention of original knowledge and strengthens sequential editing capability.


\section{Background}
\label{sec:backg}
\subsection{Model Editing Problem}\label{sec:modeleditingproblem}
Model editing aims to efficiently update the knowledge of LLMs so that they remain in real-time sync with reality \cite{zhang2024comprehensive}. Factual knowledge changes rapidly, making its update in LLMs a pressing need. Factual knowledge can be represented as a triplet $(s, r, o)$, where $s$ is the subject, $r$ is the relation, and $o$ is the object. This knowledge can be transformed into a prompt $p_i + o$, where $p_i \in \mathcal{P}$ is an element of the set $\mathcal{P}$ that expresses the semantics of $(s, r)$ in natural language. The element that most directly expresses the semantics of $(s, r)$ is called $p$, while the rest elements are $p_r$. The goal of model editing is to redirect the object $o$ in the triplet to a new object $o^*$, represented as $t = (s, r, o) \rightarrow o^*$. To evaluate whether the post-edit model is effective on the post-edit knowledge triplet and does not affect other triplets, assessments are made from three aspects: efficacy, generalization, and specificity. Efficacy evaluates whether the model's prediction on $p$ is redirected to $o^*$. Generalization evaluates whether the model's prediction on $p_r$ is redirected to $o^*$. Specificit evaluates whether the model maintains its original predictions on inputs outside the set $\mathcal{P}$. To evaluate the generative capability of the post-edit model, \citet{Meng2022Locating} also uses fluency and consistency as evaluation metrics.
Fluency measures the degree of repetition in the text generated by the model after editing; higher repetition indicates lower fluency. Consistency evaluates the degree of alignment between the content generated by the post-edit model based on $s$ and the reference text of the subject associated with the new object $o^*$. For more details, refer to \citet{Meng2022Locating}.

Model editing can be categorized according to whether the editing is sequential and the batch size into sequential editing, batch editing, and sequential batch editing \cite{mazzia2023survey}. Sequential editing refers to the continuous editing of a single piece of knowledge, while batch editing involves editing multiple pieces of knowledge at once. Sequential batch editing combines these two scenarios, involving the sequential editing of batch knowledge. This problem definition is highly relevant to the ever-changing nature of bulk knowledge in practice. Therefore, we directly present the problem of sequential batch editing. Suppose there is a sequence of $ n $ knowledge sets to be updated: $[\sT_1, \sT_2, \ldots, \sT_n]$, where each knowledge set $ \sT_i = \{t_1, t_2, \ldots\} $. Sequential batch editing requires that after performing $ n $ sequential batch edits, the post-edit model can successfully predict all $ n $ knowledge sets without affecting knowledge outside these sets.
\subsection{Locate-then-Edit Model Editing}\label{sec:locate-then-edit}
The locate-then-edit model editing is one of the most popular series of model editing methods \cite{wang2023knowledge}. These approaches typically use causal tracing \cite{Meng2022Locating} to identify the critical layers $\mathcal{L}$ where knowledge is stored, and then compute weight shifts using least squares modeling to update the weights. 

Specifically, they view the feed-forward network (FFN) as key-value memories \cite{geva-etal-2021-transformer}. Let $ \vh^{l-1} $ be the residual stream of the $ l-1 $ layer, and $ \va^l $ be the output of the self-attention block of the $ l \in \mathcal{L}$ layer. The key-value memories of the FFN can be represented as follows: 
\begin{equation}
    \underbrace{\vm^l}_{\let\scriptstyle\textstyle
    \substack{\text{value}}}= \mW_{\text{out}}^l \,\underbrace{\sigma(\mW_{\text{in}}^l \, \gamma(\vh^{l-1}+\va^l)\,)}_{\let\scriptstyle\textstyle
    \substack{\text{key}:=\vk}},\label{equ:whatskv}
\end{equation}
where $ \vm^l $ is the output of the FFN block, and $ \mW_{\text{in}}^l $ and $\mW_{\text{out}}^l $ are the input and output mapping weights of the FFN block, respectively. $\sigma$ and $\gamma$ are activation functions. $\mW_{\text{out}}^l:= \mW_0^l $ is viewed as a linear associative memory that associates keys and values:
\begin{equation}
    \mK_0^l = [\vk_1^l|\vk_2^l|...|\vk_n^l], \mM_0^l = [\vm_1^l| \vm_2^l|...|\vm_n^l].
\end{equation} Before editing, the linear associative memory satisfies:
\begin{equation}
    \mW_0^l =  \arg \min_{\mW}\left\|\mW\mK_0^l-\mM_0^l\right\|^2. \label{equ:original}
\end{equation} When new memories need to be inserted, a new group of keys $\mK_1^l $ and values $\mM_1^l $ will be updated into $\mW_0^l $. Thus the new weight should satisfy:
\begin{equation}
\small
    \mW_1^l =  \arg \min_{\mW}\underbrace{\left\|\mW\mK_0^l-\mM_0^l\right\|^2}_{\let\scriptstyle\textstyle
    \substack{\text{preserve old}}}+\underbrace{\left\|\mW\mK_1^l-\mM_1^l\right\|^2}_{\let\scriptstyle\textstyle
    \substack{\text{insert new}}}. \label{equ:locate-then-edit-objective}
\end{equation} Let $\mW_1^l = \mW_0^l + \Delta^l$ where $\Delta^l$ is weight shifts.
By applying the normal equation to Eq. \eqref{equ:locate-then-edit-objective}, its closed-form solution can be written as:
\begin{equation}
\Delta^l=\mR^l {\mK_1^l}^T\left(\mK_0^l {\mK_0^l}^T+\mK_1^l {\mK_1^l}^T\right)^{-1},
\end{equation}where $\mR^l = \left(\mM_1^l-{\mW_0^l} \mK_1^l\right)$ is the residual of the new memories when evaluated on old weights $\mW_0^l$ \cite{meng2022massediting}. $\mK_1^l$ and $\mK_0^l$ are computed for each layer. In most locate-then-edit methods \cite{meng2022massediting,fang2024alphaedit}, the residual of layer $l$ is evenly distributed from the residual of last critical layer $L = \max(\mathcal{L})$:
\begin{equation}\label{equ:residual-distribution}
    \mR^l = \frac{\mR^L}{L-l+1} = \frac{\mM_1^L-{\mW_0^L} \mK_1^L}{L-l+1},
\end{equation}
where $\mM^L_1 = [\vm_1^L| \vm_2^L|...|\vm_u^L]$ represents $u$ entries of new memories. Each entry is computed using the following formula: 
\begin{equation}
    \vm_i^L = \vh_i^L + \bm{\delta}_i^L = \mW_0^L\vk_i^L + \bm{\delta}_i^L,
\end{equation} where $\bm{\delta}_i^L$ is a residual vector optimized by gradient descent \cite{meng2022massediting,Meng2022Locating}. 
For more details, please refer to \cite{meng2022massediting,Meng2022Locating,fang2024alphaedit}.

\citet{fang2024alphaedit} extends locate-then-edit methods to the sequential batch editing scenario. They cache the keys $\mK_p$ of previously edited knowledge and incorporate $\mK_p$ into the least squares optimization, ultimately deriving the following closed-form solution for sequential batch editing:
\begin{equation}\label{equ:seq_batch_solution}
\small
\Delta^l_{\text{seq}}=\mR^l {\mK_1^l}^T\left(\mK_p^l {\mK_p^l}^T + \mK_0^l {\mK_0^l}^T+\mK_1^l {\mK_1^l}^T\right)^{-1}
\end{equation}
\section{Rethinking the Residual Distribution of Locate-then-Edit Model Editing}
\label{sec:rethinking}
%In Sec. \ref{sec:locate-then-edit}, we present the details of the locate-then-edit model editing, which employs residual distribution (i.e., Eq. \eqref{equ:residual-distribution}) to evenly allocate the residuals from the final key layer to other key layers. 
In this section, we analyze the residual distribution both empirically (Sec. \ref{sec:analyze-locate-then-main}) and theoretically (Sec. \ref{sec:impact-locate-then}). Based on these insights, we further propose a novel strategy to enhance locate-then-edit model editing (Sec. \ref{sec:BLUE}).
We focus on the classic locate-then-edit model editing method, MEMIT \cite{meng2022massediting}. Experiments are conducted on three LLMs: Llama3-8B-Instruct \cite{meta2024introducing}, GPT-J (6B) \cite{wang2021gpt}, and GPT2-XL, using the CounterFact dataset \cite{Meng2022Locating}.
Unless otherwise specified, we use the first 200 samples from the CounterFact dataset. The critical layers analyzed for each model are: Llama3-8B: \{$4,5,6,7,8$\}, GPT-J (6B): \{$3, 4,5,6,7,8$\} and GPT2-XL: \{$13, 14, 15, 16, 17$\}.
\subsection{Analyzing Residual Distribution in Locate-then-Edit Model Editing}\label{sec:analyze-locate-then-main}
\subsubsection{How Does the Distributed Residual Contribute to the Editing Object?}\label{sec:analyze-locate-then}
To measure the contribution of the distributed residuals to the editing object, we first define a contribution score:
\begin{equation}
    s = \sP_{\theta^*}(o^*|p) - \sP_{\theta}(o^*|p)
\end{equation}where $\sP_{\theta^*}(o^*|p)$ represents the probability of the post-edit model $\theta^*$ regarding the edited knowledge $t = (s,r,o)\rightarrow o^*$. The rationale behind this is that the probability of the pre-edit model $\theta$ assigning to $o^*$ on knowledge $t$ is often low, while the model editing aims for the post-edit model to assign the highest probability to $o^*$.

From Equ. \eqref{equ:whatskv} and Equ. \eqref{equ:locate-then-edit-objective}, we can know that the essence of locate-then-edit is that the post-edit model can activate the new memory $\vm_i^l= \vm_i^L / (L-l+1)$ in the FFN block at layer $l$ using the key $\vk_i^l$ corresponding to $p$. Therefore, we directly replace the output of the FFN block at layer $l$ with the new memory $\vm_i^l$ to eliminate the potential impact of activation failure. For comparison, we also directly compute residuals for each layer, following the same process as $\vm_i^L$. By using the distributed residual for ``simulated editing,'' we can accurately measure the contribution of new memories while avoiding direct edits to the model. 

We perform ``simulated editing'' in each critical layer. The average contribution scores are shown in Fig. \ref{fig:avg-contri-score}. For the distributed residuals, it can be observed that only the last critical layer achieves a contribution score close to $1.0$. The contribution scores of the other layers were all below $0.7$, showing a decreasing trend layer by layer. For the first critical layer, the contribution score is below $0.1$ in three LLMs. This indicates that \textbf{the farther the residuals are distributed, the lower their contribution to the editing object. Even distribute through just one layer can lead to a significant drop in the contribution score.} In contrast, for the computed residuals, their contribution scores in each layer consistently approach $1.0$.
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figs/avg-contri-score-overlap-different-width.pdf}
    \caption{The average contribution score of different ``simulated editing'' layers.}
    \label{fig:avg-contri-score}
\end{figure}
\subsubsection{Is the Distributed Residual the Optimal Residual for Editing?}\label{sec:is_optimal}
From Sec. \ref{sec:analyze-locate-then}, we observe that directly computing $\vm_i^l$ for each layer achieves high contribution scores. Therefore, we assume that the directly computed $\vm_i^l$ represents the optimal memory for editing. To verify whether residual distribution is optimal, we first compare the similarity between residual distribution and the directly computed $\vm_i^l$, and then evaluate their performance in model editing.

\textbf{Similarity Analyzing.} The variation in cosine similarity between the distributed and the directly computed $\vm_i^l$ is shown in Fig. \ref{fig:similarity-analyzing}. It shows that the cosine similarity between the distributed and the directly computed $\vm_i^l$ exhibits a layer-by-layer decreasing trend, indicating that \textbf{the further residuals are distributed, the farther $\vm_i^l$ deviates from the optimal memory.} To further investigate how residual distribution affects model editing performance, we next perform single-layer model editing using both the distributed residuals and the directly computed residuals.
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth,trim={10pt 10pt 10pt 10pt},clip]{figs/cos-sims.pdf}
    \caption{The variation in cosine similarity between the distributed and the directly computed memory across different layers.}
    \label{fig:similarity-analyzing}
\end{figure}

\textbf{Post-edit LLM Performance.} We update single layers of the model using distributed residuals and computed residuals, respectively. The results for Llama3 under the batch editing setting are shown in Figure \ref{fig:performance-compare}, while results for GPT-J and GPT2-XL are presented in Figure \ref{fig:performance-compare-gptj-gpt2} of Appendix \ref{sec:appdx:editing_performance}. Specificity and Fluency remain comparable across different cases, with outcomes closely matching the original model. This indicates that small-batch edits effectively retain the model's original state. However, significant differences arise in Efficacy and Generalization between the two methods. For Efficacy, models edited with computed residuals outperform those with distributed residuals by over $3\times$ on average, while for Generalization, the improvement exceeds $2\times$. In terms of Consistency, computed residuals achieve an average improvement of more than 10\%. \textbf{These findings indicate that distributed residuals introduce significant information loss during model editing, leading to a higher likelihood of editing failures.}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth,trim={70pt 10pt 70pt 10pt},clip]{figs/Llama3-mcf-performance-compare.pdf}
    \caption{Performance variations when editing different single layers of the model using computed and distributed residuals separately. For better visualization, Fluency and Consistency were normalized.}
    \label{fig:performance-compare}
\end{figure}
\subsection{Theoretical Analysis of Residual Distribution in Locate-then-Edit Methods}\label{sec:impact-locate-then}
\begin{theorem}\label{theorem:error_upper_bound}
In the locate-then-edit model editing, when using residual distribution, the upper bound for the weight shift error between the exact weight shift $\Delta^{l^*}$ and the actual weight shift $\Delta^{l}$ is given by 
\begin{equation}
\begin{aligned}
      \|\Delta^{l^*} - \Delta^{l}\|_2 \leq \left ( \| \mR^{l^*} -\mR^{L}\|_2 + (L-l)\|\mR^{l} \|_2 \right)  \|\mQ\|_2,
\end{aligned}
\end{equation}where $\mR^{l^*}$ denotes the exact residual, and $\small \mQ = {\mK_1^l}^T\left(\mK_0^l {\mK_0^l}^T+\mK_1^l {\mK_1^l}^T\right)^{-1}$.
\end{theorem}
The proof of the above theorem is presented in Appendix \ref{sec:proof:theorem:error_upper_bound}. $\|\mR^{l} \|_2$ and $\|\mQ\|_2$ increase with the number of new memories (i.e., the size of the editing batch \cite{meng2022massediting}). When the number of new memories is fixed, the upper bound increases with $\| \mR^{l^*} -\mR^{L}\|_2$ and $L-l$. $L-l$ increases as the residual distributes further, while it is unclear how $\| \mR^{l^*} -\mR^{L}\|_2$ changes. To explore this, we assume the computed residual is the exact residual and analyze how $\| \mR^{l^*} -\mR^{L}\|_2$ changes across layers. In Figure \ref{fig:norm-diff}, we show how $\| \mR^{l^*} - \mR^{L} \|_2$ changes across layers. It shows that $\| \mR^{l^*} - \mR^{L} \|_2$ increases as the residual distribution extends farther. Therefore, we can conclude that when the size of the editing batch is fixed, the error of weight shift increases as the distance of the residual distribution increases. 

Considering the closed-form solution of locate-then-edit model editing in sequential batch editing, the following lemma can be derived.
\begin{lemma}\label{lem:error_upper_bound}
In sequential batch editing, when using residual distribution, the upper bound of the weight shift error between the exact weight shift $\Delta^{l^*}$ and the actual weight shift $\Delta^{l}$ for locate-then-edit methods is given by
\begin{equation}
\small
\begin{aligned}
      \|\Delta^{l^*} - \Delta^{l}\|_2 \leq \left ( \| \mR^{l^*} -\mR^{L}\|_2 + (L-l)\|\mR^{l} \|_2 \right)  \|\mQ'\|_2,
\end{aligned}
\end{equation}where $\mR^{l^*}$ denotes the exact residual, and $\mQ' = {\mK_1^l}^T\left(\mK_p^l {\mK_p^l}^T + \mK_0^l {\mK_0^l}^T+\mK_1^l {\mK_1^l}^T\right)^{-1}$.
\end{lemma}$\|\mK_p^l {\mK_p^l}^T\|_2$ increases with the number of sequential edits, and thus Sec. \ref{lem:error_upper_bound} indicates that the weight shift error also increases with the number of sequential edits.
\begin{figure}[t]
    \centering
\includegraphics[width=1\linewidth,trim={10pt 10pt 10pt 10pt},clip]{figs/mcf-direct-norms-diff.pdf}
    \caption{Variation of $\| \mR^{l^*} - \mR^{L} \|_2$ across layers.}
    \label{fig:norm-diff}
\end{figure}
\subsection{BLUE: Boundary Layer UpdatE for Improving Locate-then-Edit Model Editing}\label{sec:BLUE}
\input{tabs/steps}
\input{tabs/seq_edits}
\input{tabs/increases}
From the previous analysis, we know that the residual distribution of the locate-then-edit model editing is inherently inaccurate, and this inaccuracy increases as the residuals are distributed farther. So, \textit{how can we enable locate-then-edit model editing to perform multi-layer updates while mitigating the negative impact of the residual distribution?} A straightforward method is to compute residuals separately for each layer. However, this reduces the efficiency of the locate-then-edit approach, and it remains unclear whether it is necessary to compute residuals and perform updates for all critical layers individually. 
\vspace{-2pt}
\begin{figure}[t]
    \centering
\includegraphics[width=1\linewidth]{figs/GLUE_eval.pdf}
    \caption{F1 scores of the post-edited Llama3 (8B) on six tasks. The
dashed lines in the figure represent the general capability performance of models edited using the original editing methods, while the solid lines represent the performance of models edited using the BLUE-enhanced editing methods.}
    \label{fig:glue_eval}
\end{figure}
Therefore, we conduct experiments where residuals are computed and updates performed for all critical layers. Computation is stopped when the loss falls below 0.05. We update the critical layers sequentially in the order of increasing layers and record the number of optimization steps required to compute residuals for each layer. The results are shown in Table \ref{tab:optimization-steps}. It can be observed that after completing the first layer update, the number of residual computation steps in subsequent layers decreased significantly across all LLMs. In GPT2-XL, the decrease is 48.5\%; in GPT-J, 84.0\%; and in Llama3, 55.6\%. Furthermore, after updating the first two layers, the optimization steps in the third layer for GPT2-XL, GPT-J and Llama3 drop below 2.0, indicating that \textbf{only two layers of weights needed to be updated to achieve the editing goal. }

The above observations indicate that when calculating residuals separately for all layers, updating just two layers is sufficient to achieve the editing object. The new question is: which two layers should be updated to achieve optimal editing performance? According to Theorem \ref{theorem:error_upper_bound}, the farther the distribution of residuals, the greater the upper bound of the weight shift error. The first layer edited by the current method is most affected by residual distribution. To mitigate this effect, we select the first layer edited by the current method as the first layer for updating. For the last layer, we follow existing work and choose the layer where residuals are actually computed.

Therefore, we propose a \textbf{Boundary Layer UpdatE (BLUE)} strategy to accelerate the locate-then-edit methods. BLUE updates only the boundary layers of the critical layers by directly computing residuals of them, specifically the first critical layer and the last critical layer. This not only reduces the number of layers to be updated, but we also demonstrate in Sec. \ref{sec:exps} that it performs better and better preserves LLMsâ€™ general capabilities. BLUE is suitable for locate-then-edit methods that perform multi-layer updates using even residual distribution: MEMIT \cite{meng2022massediting}, RECT \cite{gu-etal-2024-model}, PRUNE \cite{ma2024perturbation} and AlphaEdit \cite{fang2024alphaedit}.
\vspace{-2pt}
\begin{figure*}[htbp]
    \centering
    \subfigure[MEMIT]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_seq_Llama3.pdf} 
}
\subfigure[RECT]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_rect_Llama3.pdf} 
}
\subfigure[PRUNE]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_prune_Llama3.pdf}
}
\subfigure[AlphaEdit]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/AlphaEdit_Llama3.pdf}
}
   \subfigure[MEMIT$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_seq_blue_Llama3.pdf} 
}
\subfigure[RECT$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_rect_blue_Llama3.pdf} 
}
\subfigure[PRUNE$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_prune_blue_Llama3.pdf}
}
\subfigure[AlphaEdit$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/AlphaEdit_blue_Llama3.pdf}
}
    \caption{The distribution of hidden states in pre-edited and post-edited Llama3 (8B).}
    \label{fig:hidden_states_shift}
\end{figure*}
\section{Experiments}
\label{sec:exps}
\subsection{Experimental Setup}
\textbf{Datasets \& LLMs.} Our experiments are conducted on two datasets: CounterFact \cite{Meng2022Locating} and zsRE dataset \cite{levy2017zero}. We select three LLMs as the editing subjects: GPT2-XL \cite{radford2019language}, GPT-J (6B) \cite{wang2021gpt}, Llama3 (8B) \cite{llama3modelcard}.

\textbf{Baselines.} BLUE is a facilitation strategy designed for locate-then-edit model editing that perform multi-layer updates, which has been proven in prior research to achieve the best editing performance \cite{fang2024alphaedit}. Therefore, our baselines only consider locate-then-edit model editing methods. The locate-then-edit methods we consider are: MEMIT \cite{meng2022massediting}, PRUNE \cite{ma2024perturbation}, RECT \cite{gu2024model}, and AlphaEdit \cite{fang2024alphaedit}. We present the experimental details in the Appendix \ref{sec:appdx:exp-details}. We also present the results of BLUE on the square root residual distribution method, PMET, in Appendix \ref{sec:appdx:blue-pmet}.
\subsection{Enhancing Editing Performance with BLUE}\label{sec:Enhancing Editing Performance with BLUE}
We first verify whether BLUE can enhance locate-then-edit model editing. Sequential batch editing better aligns with real-world batch knowledge updates, and we follow \citet{fang2024alphaedit} by using sequential batch editing experiments to validate the capabilities of BLUE. We randomly sample 2,000 samples from the dataset and perform sequential batch editing with a batch size of 100. The results of the sequential batch editing are shown in Table \ref{tab:seq_edits}. We use red to highlight the results enhanced by BLUE. The results indicate that \textbf{the BLUE strategy effectively enhances the performance of a range of locate-then-edit methods in sequential batch editing tasks}. 89.58\% of the results (86 out of 96) were enhanced. After using BLUE, the editing performance of different editing methods is enhanced across various LLMs, as shown in Table \ref{tab:average_increase}. It can be observed that the BLUE strategy significantly improves the performance of PRUNE and noticeably enhances the editing performance of locate-then-edit methods on Llama3 and GPT2-XL. For other cases, such as AlphaEdit on GPT-J, the improvements are minimal due to its already strong baseline performance.
\subsection{Boosting General Capability Retention via BLUE}
Model editing should not affect other aspects of LLMs. In addition to using specificity and fluency for evaluation, this goal can also be achieved by assessing changes in the general capabilities of the models after editing. Following the work of \citet{fang2024alphaedit}, we evaluate the general capabilities of LLMs before and after editing using six natural language tasks from the General Language Understanding Evaluation (GLUE) benchmark \cite{wang2018glue}. Specifically, we achieve this through the following six evaluation tasks: SST (The Stanford Sentiment Treebank) \cite{socher2013recursive}, MRPC (Microsoft Research Paraphrase Corpus) \cite{dolan2005automatically}, MMLU (Massive Multi-task Language Understanding) \cite{hendrycks2020measuring}, RTE (Recognizing Textual Entailment) \cite{bentivogli2009fifth}, CoLA (Corpus of Linguistic Acceptability) \cite{warstadt2019neural}, and NLI (Natural Language Inference) \cite{williams2017broad}. 

We conduct a total of 3,000 sequential edits on Llama3 (8B), with a batch size of 100 for each edit. Every 500 steps, we evaluate the performance of the post-edited LLMs on these six tasks. The results are shown in Fig. \ref{fig:glue_eval}. After 3,000 edits, the general capabilities of models edited by RECT, PRUNE, and MEMIT are almost entirely lost. In contrast, models edited by the BLUE-enhanced versions of these methods maintain their general capabilities well. Notably, AlphaEdit inherently demonstrates strong general capability retention, and AlphaEdit$_{\text{BLUE}}$ does not compromise this ability. These results indicate that \textbf{BLUE enhances the general capability retention of locate-then-edit methods}. 
%Model editing methods that preserve the general capabilities of LLMs enhance the practical usability of the edited LLMs, allowing them to further adapt to downstream tasks.
\subsection{Mitigating Hidden States Shifts with BLUE}
The existing locate-then-edit methods often result in shifts in the hidden states of the model after editing \cite{fang2024alphaedit}. In this part, we verify whether BLUE can alleviate this phenomenon. Specifically, we extract the hidden states of 1,000 randomly selected factual prompts from LLMs before and after editing. These hidden states are then reduced to two dimensions using t-SNE. The post-editing LLMs mentioned here are the models described in Sec. \ref{sec:Enhancing Editing Performance with BLUE}. We then visualize the hidden states, and the results are shown in Figure \ref{fig:hidden_states_shift}. It can be observed that the shifts in hidden states corresponding to the locate-then-edit method enhanced by BLUE are weaker than those of the original method. This demonstrates that \textbf{BLUE can mitigate hidden states shifts caused by locate-then-edit methods}. The results on GPT-J (6B) and GPT2-XL can be found in \cref{sec:appdx:Hidden States Shifts-GPTJ-GPT2XL}.
\section{Conclusion}
This paper analyzes the residual distribution in locate-then-edit model editing. Through empirical and theoretical analyses, we find that the residual distribution is not the optimal approach and that it causes errors in weight updates to increase with batch size, the number of sequential edits, and distribution distance. Based on these findings, we propose the BLUE strategy, which enhances locate-then-edit methods by updating only the first and last critical layers of the model. Sequential batch editing experiments on three LLMs and two datasets demonstrate that BLUE effectively enhances the editing performance of locate-then-edit methods. Further analysis shows that BLUE also improves the retention of the original general capabilities of LLMs and mitigates the shift in hidden states after editing. This enhances the practical usability of the post-edit LLMs, allowing them to undergo further fine-tuning or continuous model editing.
% \section*{Acknowledgements}

% Optional acknowledgments go here, as an unnumbered section after the main paper but before the references. 

% \section*{Impact Statement}

% Authors are should consider including an \textbf{optional} statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered and also at the end of the paper, before the references. 


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite

\bibliography{refs}
\bibliographystyle{plainnat}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\section{Proof of Theorem \ref{theorem:error_upper_bound}}
\label{sec:proof:theorem:error_upper_bound}
\begin{proof}
Let ${\mK_1^l}^T\left(\mK_0^l {\mK_0^l}^T+\mK_1^l {\mK_1^l}^T\right)^{-1}:=\mQ$, then the weight shifts error is:
\begin{align}
     \|\Delta^{l^*} - \Delta^{l}\|_2 &= \| \mR^{l^*}\mQ - \mR^{l}\mQ \|_2 \\
     &= \| \mR^{l^*} - \mR^{l}\|_2 \|\mQ\|_2 \\
     &= \| \mR^{l^*} - \frac{\mR^{L}}{L-l+1} \|_2 \|\mQ\|_2 \label{equ:proof_thm1_13}
\end{align}
According to Sec. \ref{sec:is_optimal}, the directly computed $\vm_i^l$ represents the optimal memory for editing, and thus we have $\mR^L = \mR^{L^*}$. Then, Equ. \eqref{equ:proof_thm1_13} can be written as:
\begin{align}
   & \| \mR^{l^*} - \frac{\mR^{L^*}}{L-l+1} \|_2 \|\mQ\|_2 \\
    = &\| \mR^{l^*} - \mR^{L^*} + \mR^{L^*} - \frac{\mR^{L^*}}{L-l+1} \|_2 \|\mQ\|_2  \\
    \leq & \left ( \| \mR^{l^*} - \mR^{L^*}\|_2 + \|\mR^{L^*} - \frac{\mR^{L^*}}{L-l+1} \|_2 \right)  \|\mQ\|_2 \\
     \leq &\left ( \| \mR^{l^*} - \mR^{L^*}\|_2 + \frac{L-l}{L-l+1}\|\mR^{L^*} \|_2 \right)  \|\mQ\|_2
    % \\ \leq &\left ( \| \mR^{l^*} - \mR^{L}\|_2 + \frac{L-l}{L-l+1}\|\mR^{L} \|_2 \right)  \|\mQ\|_2 
     \\ \leq &\left ( \| \mR^{l^*} -\mR^{L}\|_2 + (L-l)\|\mR^{l} \|_2 \right)  \|\mQ\|_2
\end{align}
\end{proof}
\section{Supplementary Results of Post-edit LLM Performance}\label{sec:appdx:editing_performance}
We show the supplementary results of post-edit LLM performance in Fig. \ref{fig:performance-compare-gptj-gpt2}. The results also indicate that distributed residuals introduce significant information loss during model editing, leading to a higher likelihood of editing failures.
\begin{figure}
    \centering
       \centering
    \subfigure[GPT-J (6B)]{
\includegraphics[width=1\linewidth]{figs/GPTJ-mcf-performance-compare.pdf} 
}
\subfigure[GPT-XL]{
\includegraphics[width=1\linewidth]{figs/GPT2-mcf-performance-compare.pdf} 
}
    \caption{Performance variations when editing different single layers of the model using computed and distributed residuals separately. For better visualization, Fluency and Consistency were normalized.}
    \label{fig:performance-compare-gptj-gpt2}
\end{figure}
\section{Experiment Details}\label{sec:appdx:exp-details}
All our experiments are conducted on A800 GPUs. The baseline methods used for comparison in the experiments are kept in their original settings, with PRUNE following the reproduction settings of \citet{fang2024alphaedit}. For baseline methods enhanced by BLUE, all configurations remain consistent with the original baselines, except for AlphaEdit$_{\text{BLUE}}$. For AlphaEdit$_{\text{BLUE}}$, we set the $\alpha$ values for Llama3 (8B), GPT-J (6B), and GPT2-XL to 1, 95, and 80, respectively, to ensure the invertibility of matrices during the editing process, thereby achieving better editing performance. For a clearer understanding of the baselines, please refer to \citet{fang2024alphaedit}. 
\section{Batch Model Editing}
\input{tabs/batch_edit}
In addition to sequential batch editing, large-scale batch editing is also an important aspect of evaluating the performance of model editing methods. Therefore, we conducted 10,000 batch edits for both the baseline and the BLUE-enhanced methods, with the results shown in \cref{tab:batch_edits}. The results in the table indicate that while the improvement in large-scale batch editing after applying the BLUE enhancement to the baseline is not as significant as in sequential batch editing, the baselines enhanced by BLUE still demonstrate overall stronger performance. Specifically, 70.83\% of the metrics (68 out of 96) are improved. Note that although the baselines enhanced by BLUE performed better in terms of efficacy and generalization, they show worse results in specificity. This suggests that while the BLUE-enhanced model editing methods strengthen the knowledge being edited, it also affects other unrelated knowledge. Achieving optimal performance across all three metrics simultaneously remains a major challenge in model editing \cite{wang2024wiserethinkingknowledgememory}. This is particularly true for locate-then-edit methods, as BLUE serves as an enhancement to existing editing methods without altering their original modeling. Therefore, addressing this issue may require future work on improving the original modeling of editing methods.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hidden States Shifts in GPT-J (6B) and GPT2-XL}
\label{sec:appdx:Hidden States Shifts-GPTJ-GPT2XL}
We present the hidden state shifts before and after model editing for GPT-J (6B) and GPT-2 XL in Figs. \ref{fig:hidden_states_shift_gptj} and \ref{fig:hidden_states_shift_gpt2}, respectively. Similar results to those on Llama3 (8B) are observed for GPT-J (6B) and GPT-2 XL. The BLUE-enhanced baselines have a smaller overall impact on the model's hidden states compared to the original baselines. This indicates that BLUE can mitigate the hidden state shifts caused by locate-then-edit methods, suggesting that the BLUE-enhanced baselines introduce fewer side effects to the original model.
\begin{figure*}[htbp]
    \centering
    \subfigure[MEMIT]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_seq_EleutherAI_gpt-j-6B.pdf} 
}
\subfigure[RECT]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_rect_EleutherAI_gpt-j-6B.pdf} 
}
\subfigure[PRUNE]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_prune_EleutherAI_gpt-j-6B.pdf}
}
\subfigure[AlphaEdit]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/AlphaEdit_EleutherAI_gpt-j-6B.pdf}
}
   \subfigure[MEMIT$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_seq_blue_EleutherAI_gpt-j-6B.pdf} 
}
\subfigure[RECT$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_rect_blue_EleutherAI_gpt-j-6B.pdf} 
}
\subfigure[PRUNE$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_prune_blue_EleutherAI_gpt-j-6B.pdf}
}
\subfigure[AlphaEdit$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/AlphaEdit_blue_EleutherAI_gpt-j-6B.pdf}
}
    \caption{The distribution of hidden states in pre-edited and post-edited GPT-J (6B).}
    \label{fig:hidden_states_shift_gptj}
\end{figure*}
\begin{figure*}[htbp]
    \centering
    \subfigure[MEMIT]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_seq_gpt2-xl.pdf} 
}
\subfigure[RECT]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_rect_gpt2-xl.pdf} 
}
\subfigure[PRUNE]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_prune_gpt2-xl.pdf}
}
\subfigure[AlphaEdit]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/AlphaEdit_gpt2-xl.pdf}
}
   \subfigure[MEMIT$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_seq_blue_gpt2-xl.pdf} 
}
\subfigure[RECT$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_rect_blue_gpt2-xl.pdf} 
}
\subfigure[PRUNE$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/MEMIT_prune_blue_gpt2-xl.pdf}
}
\subfigure[AlphaEdit$_{\text{BLUE}}$]{
\includegraphics[width=0.235\textwidth,trim={42pt 25pt 58pt 48pt},clip]{figs/AlphaEdit_blue_gpt2-xl.pdf}
}
    \caption{The distribution of hidden states in pre-edited and post-edited GPT2-XL.}
    \label{fig:hidden_states_shift_gpt2}
\end{figure*}
\section{BLUE in the Locate-then-edit Method with Square Root
Residual Distribution}\label{sec:appdx:blue-pmet}
Some locate-then-edit methods (e.g., PMET \cite{li2024pmet}) use a square root residual distribution instead of an even spread. They claim that the square root residual distribution can mitigate information loss during residual distribution. Since BLUE is designed for locate-then-edit methods with even residual distribution, we do not consider such methods as baselines. Nevertheless, we attempt to enhance PMET with BLUE. The results of sequential batch editing are shown in Table \ref{tab:pmet_blue_edit}. PMET$_{\text{BLUE}}$ exhibits a significant performance improvement when editing Llama3 on sequential model editing task, while its performance gains in other scenarios are relatively limited. We speculate that this may be because PMETâ€™s use of square root distribution retains more editing information compared to even distribution, leading to the limited improvement of BLUE. Additionally, PMET incorporates a self-attention module during editing optimization but only edits the FFN weights when updating model parameters. This might result in BLUEâ€™s two-layer update being insufficient to fully integrate the editing information into the model weights. Nevertheless, BLUE demonstrates notable improvements in the locate-then-edit approaches with residual even distribution, indicating that it remains applicable to most locate-then-edit methods.
\input{tabs/PMET_res}
\end{document}

