\section{Related Work}
\subsection{Text-to-SQL}
Text-to-SQL \citep{cai2017encoder, zelle1996learning, xu2017sqlnet, yu2018typesql, yaghmazadeh2017sqlizer}, which aims to convert natural language instructions or questions into SQL queries, has drawn significant attention. Since the work of \citet{dong2016language}, leading text-to-SQL models have adopted attention-based sequence-to-sequence architectures to translate questions and schemas into well-formed SQL queries. These models have increasingly benefited from pre-trained transformer architectures, ranging from BERT \citep{hwang2019comprehensive, lin2020bridging} to larger language models such as T5 \citep{raffel2020exploring} in \citet{scholak2021picard}, OpenAI CodeX \citep{chen2021evaluating}, and GPT variants \citep{rajkumar2022evaluating, liu2023divide, pourreza2024din}. Along with using pre-trained models, various task-specific enhancements have been introduced, including improved schema encoding via more effective representation learning \citep{bogin2019representing} and fine-tuned attention mechanisms for sequence-to-sequence models \citep{wang2019rat}. On the decoding side, some methods incorporate the syntactic structure of SQL \citep{hwang2019comprehensive, xu2017sqlnet, hui2021improving}.

Recent advances in LLMs have also extended their multi-task capabilities to text-to-SQL. In zero-shot scenarios, a task-specific prompt is added before the schema and the question, guiding the LLM to generate an SQL query. \citet{rajkumar2022evaluating, liu2023comprehensive} showed that OpenAI CodeX can achieve 67\% execution accuracy using this approach. Building on this, few-shot prompting strategies have been investigated. In particular, \citet{pourreza2024din, liu2023divide} proposed GPT-4-based DIN-SQL, which divides the problem into four subtasks (schema linking, classification, generation, and self-correction) and achieves strong performance on the Spider benchmark. However, \citet{pourreza2024din} also noted that DIN-SQL encounters difficulties when dealing with complex queries. In contrast to these approaches, our method reframes text-to-SQL as a reasoning task. By doing so, it leverages the inherent reasoning capabilities of LLMs to boost performance and facilitates the integration of additional reasoning techniques into text-to-SQL systems.

\subsection{Multi-step Reasoning}
Complex reasoning tasks have sparked extensive research in LLMs, which are crucial for handling challenging queries \citep{kaddour2023challenges,lightman2023let, huang2023large}. One prominent strategy is the Chain-of-Thought (CoT) prompting technique \citep{wei2022chain}, along with its variants \citep{kojima2022large, wang2022self, yao2024tree}, which decompose the reasoning process into sequential steps and systematically approach problem-solving in a human-like manner. To further enhance the accuracy of these intermediate steps, recent studies leverage extensive synthetic datasets, which are either distilled from cutting-edge models \citep{yu2023metamath, luo2023wizardmath} or composed of self-generated rationales \citep{zelikman2022star, yuan2023scaling, ni2022learning}, to fine-tune the LLMs. Such training strategy effectively sharpens the models' ability to produce correct chain-of-thought reasoning.

Additionally, there is growing interest in test-time verification, which involves generating multiple candidate solutions and ranking them with a separate verifier \citep{cobbe2021training, he2024advancing} to select the most accurate one. For example, the DIVERSE framework \citep{Li2022MakingLM} employs a variety of CoT prompts together with a verifier to address reasoning challenges, while CoRe \citep{zhu2022solving} fine-tunes both the generator and verifier in a dual-process system, improving LLM performance on math word problems.

\begin{figure*}[ht]
 \centering
 \includegraphics[width=\linewidth]{method.pdf}
 \caption{An overview of the STaR-SQL framework. It consists of three main steps: step-by-step rationale generation for self-improvement, verifier training, and test-time verification. We transform text-to-SQL into a reasoning task and further explore scaling up test-time computation by incorporating a verifier and employing best-of-N sampling.}
\end{figure*}