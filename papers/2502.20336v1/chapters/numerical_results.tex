% !TEX root = ../dual_norm_estimate_base.tex

\section{Numerical experiments} \label{sec:NumResults}
We investigate the quantitative performance of the proposed error estimators for linear elliptic and parabolic PDEs. In order to do so, we compare the quantities listed in the following table.
%-----------------------------------------------
\newcommand\myline[2]{
	\begin{tikzpicture}
	\draw[#1,line width=1pt] (0,0) -- (1,0);
	\node[scale=1.3, line width=0.8pt] at (0.5,0) {\color{#1}\pgfuseplotmark{#2}};
	\end{tikzpicture}
	}
%-----------------------------------------------
\begin{center}
	\begin{tabular}{c|l|l}
		\multicolumn{2}{c|}{legend} & computation done by \\ \hline\hline
		\myline{black}{o} 		& $\mathcal{W}$-error on $\Omega$ & high-fidelity FE computation \\ \hline
		\myline{blue}{x} 		& lower bound on $\Omega$		& high-fidelity Riesz representation \\ \hline
		\myline{blue}{triangle*} 	& upper bound on $\Omega$ 		& high-fidelity Riesz representation \\ \hline
		\myline{orange}{x} 		& lower bound on $\mycirc$		& efficient error estimator \\ \hline
		\myline{orange}{triangle*} & upper bound on $\square$		& efficient error estimator
	\end{tabular} 
\end{center}
%-----------------------------------------------

The \enquote{true} $\mathcal{W}$-error (black) is computed by comparing the PINN-solution with a high-fidelity finite element reference solution. The upper and lower bounds in $\Omega$ (blue lines) are determined by using the Riesz representation w.r.t.\ a fine discretization of the PDE on the domain $\Omega$ and computing the dual norm of the residual by determining the primal norm of the Riesz representation. For all presented examples, we derive analytical estimates for the involved constants. Of course, this could also be replaced by solving corresponding generalized eigenvalue problems. These \enquote{Riesz estimates} on $\Omega$ are used as a reference only, as those bounds require high computational cost (in that case, one could replace a PINN  by the detailed FE simulation). It is clear that our error estimates cannot be better than the Riesz bounds on $\Omega$.

In order to compute our error estimator (orange), we need to solve the PDE on $\mycirc$ and $\square$. Hence, we choose these domains in such a way that their geometry is rather simple, e.g.\ a circle or a rectangle allowing for highly efficient tensorproduct discretizations in spherical and canonical coordinates, respectively. For those, we used highly efficient and accurate spectral methods, \cite{Canuto2006}. All experiments have been been carried out in Python with FEniCSx\,\cite{Baratta2023} and PyTorch\,\cite{NEURIPS2019_9015}. Our code can be found on a \texttt{git} repository, \cite{codeGIT}.

As mentioned already above, possible scenarios for PINNs include parametric PDEs (PPDEs) and/or PDEs on (spatial) domains with complicated geometries. This also guides our numerical experiments. Denoting by $\mathcal{P}\subset\mathbb{R}^P$, $P\in\mathbb{N}$, a compact parameter set, we denote by $u^\delta_\mu$ the high-fidelity (but expensive) numerical solution of the PPDE (e.g.\ by finite elements). Then, we trained a PINN $\Phi^\theta(\cdot;\mu)$ to approximate the solution maps $\mu \mapsto u_\mu$, where $u_\mu$ is the  exact (classical, i.e., pointwise) solution\footnote{Existence and uniqueness of such a solution is \emph{not} clear!} of the PPDE on the domain $\Omega$. For our experiments, we trained the PINN using the mean-square loss function
\begin{align*}
	\mathcal{L}(\theta) := \sum\limits_{\mu \in \mathcal{S}_\mathcal{P}} \sum\limits_{x \in \mathcal{S}_\Omega} | u^\delta_\mu(x) - \Phi^\theta(x;\mu) |^2,
\end{align*}
where we used finite training data sets $\mathcal{S}_\mathcal{P} \subset \mathcal{P}$ for the parameter and $\mathcal{S}_\Omega \subset \Omega$ for the physical variable (which could also be space and time for parabolic problems). However, we stress once more the fact that our subsequent error estimation is independent on the specific loss function and training process. 


\subsection{Linear parameter-dependent diffusion problem}
%-------------------------------------------------------------
We start by a problem in space only, i.e., an elliptic problem involving parameters posed on a \enquote{complicated} domain $\Omega \subset \mathbb{R}^d$ being the nonconvex saw-blade-like domain shown in Figure\,\ref{fig:sawbladeDomain}. The subdomain $\Omega_1$ consists of the saw teeth and $\Omega_2 := \Omega \setminus \bar{\Omega}_1$ is a rectangle. In such a setting, the existence of a classical solution cannot be expected and a finite element solution will require to resolve the geometry of the domain.
\begin{figure}[!htb]
	\begin{minipage}{1.0\textwidth}
		\centering
		\input{figs/sawbladedom.tikz}
	\end{minipage}
	\caption{Saw-blade domain $\Omega=\Omega_1\cup\Omega_2$ with the partition for the diffusion coefficients. The saw teeth are made of different material than the saw blade.
		\label{fig:sawbladeDomain}}
\end{figure}
    
The variational form of the PPDE uses the trial and test space $\mathcal{W}=\mathcal{Y}=H^1_{0}(\Omega)$ yielding a Galerkin discretization and amounts finding  $u_\mu \in H^1_{0}(\Omega)$ such that 
\begin{equation*}
    \dual{r_\Omega(u_\mu),v}_{H^1_0(\Omega)} := (A_\mu \nabla u_\mu, \nabla v )_{L_2(\Omega)} - (1, v)_{L_2(\Omega)} = 0 \quad \forall v \in H^1_{0}(\Omega),
	\end{equation*}
where the parameter-dependent diffusion matrix is given by
\begin{equation*}
	A(x; \mu) := \left[ \mu_1 \chi_{\Omega_1}(x) + \mu_2 \chi_{\Omega_2}(x)\right]
	\begin{pmatrix}
		1 & 0 \\
		0 & 2 
	\end{pmatrix},
\end{equation*}	
The diffusion is parameterized ranging in $\mathcal{P} := [1/10,1] \times [5/100, 1/10]\subset\mathbb{R}^2$, $P=2$. 
	

The training set $\mathcal{S}_\mathcal{P} \subset \mathcal{P}$ consists of $7 \times 7$ equidistant distributed parameters and $\mathcal{S}_\Omega \subset \Omega$ is a randomly chosen set of $2^{14}$ points. In order to apply Corollary \ref{cor:boundsSobolev}, we define $\square := (0,4)\times(0,1)$ and $\mycirc := (0,4) \times (0,1/2) = \Omega_2$ as well as 
\begin{align*}
	\dual{r_\square(\Phi^\theta(\mu)), v }_{H^1_0(\square)} 
    &:= \dual{r_\Omega(\Phi^\theta(\mu)), v}_{H^1_0(\square)}, 
    &&\forall v \in H^1_{0}(\square), \\
	\dual{ r_\mycirc(\Phi^\theta(\mu)), v }_{H^1_0(\mycirc)} 
    &:= \dual{r_\Omega(\Phi^\theta(\mu)),\Ext_\Omega v}_{H^1_0(\Omega)},  
    &&\forall v \in H^1_{0}(\mycirc).
\end{align*}
It is readily seen that $r_\Omega(\Phi^\theta(\mu))$ is well-defined on $H^1_{0}(\square)$ and is an element of the dual space, which means in this example $\mathcal{Z}'(\square):=(H_0^1(\square))'$. Furthermore, $r_\square(\Phi^\theta(\mu))$ is an extension of $\aRBox r_\Omega(\Phi^\theta(\mu))$, because $r_\square(\Phi^\theta(\mu)) \equiv \aRBox r_\Omega(\Phi^\theta(\mu))$ on $\mathcal{U}(\square)$, defined in \eqref{eq:UdefSobolev}. With the space $\mathcal{V}(\Omega)$ defined in \eqref{eq:VdefSobolev} we define $r_\mycirc(\Phi^\theta(\mu)) := \aECirc \left( r_\Omega(\Phi^\theta(\mu)|_{\mathcal{V}(\Omega)} \right)$. Then, Corollary\,\ref{cor:boundsSobolev} applies and with the constants from Example\,\ref{example:linearPDE} we get 
\begin{equation*}
	\frac{\Vert r_\mycirc(\Phi^\theta(\mu)) \Vert_{H^{-1}(\mycirc)}}{2 \max \lbrace \mu_1, \mu_2 \rbrace} 
    \le \Vert \nabla u(\mu) - \nabla \Phi^{\theta}(\mu) \Vert_{L_2(\Omega)} \le \frac{\Vert r_\square(\Phi^\theta(\mu)) \Vert_{H^{-1}(\square)}}{\min \lbrace \mu_1, \mu_2 \rbrace}.
\end{equation*}
We use these constants in our experiments.

%=========================
\begin{figure}[!htb]
	\centering
	%--------------------------
	\begin{tikzpicture}[scale = 0.9]
		\begin{semilogyaxis}[legend cell align={left}, grid=both,width=\textwidth,height=6cm, legend columns = 2, legend style={at={(0.5,1.3)},anchor=north},cycle list name=black white, ymin=1e-2, ymax=2e1,xmin=0,xmax=48]
		\addplot[mark=o,black,line width=1pt] table [x=parameter_num, y=abs_H10_error] {figs/data_combined_sawblade.dat};
		\addlegendentry{$\mathcal{W}=H^1_0$-error on $\Omega$\hspace*{10pt}}
		%-------------
		\addplot[mark=triangle,blue,line width=1pt] table [x=parameter_num, y=abs_est_error_ub] {figs/data_combined_sawblade.dat};
		\addlegendentry{upper bound on $\Omega$}
		%-------------
		\addplot[mark=x,blue,line width=1pt] table [x=parameter_num, y=abs_est_error_lb] {figs/data_combined_sawblade.dat};
		\addlegendentry{lower bound on $\Omega$}
		%-------------
		\addplot[mark=triangle,orange,line width=1pt] table [x=parameter_num, y=abs_est_error_box_ub] {figs/data_combined_sawblade.dat};
		\addlegendentry{upper bound on $\square$}
		%-------------
		\addplot[mark=x,orange,line width=1pt] table [x=parameter_num, y=abs_est_error_box_lb] {figs/data_combined_sawblade.dat};
		\addlegendentry{lower bound on $\mycirc$}
		%-------------
		\end{semilogyaxis}
	\end{tikzpicture} 
	%-------------------------- 
	%--------------------------
	\caption{\label{fig:param_dependencev1} Absolute $H^1_0$-error as well as the estimated $H^1_0$-error on $\Omega$, $\square$ and $\mycirc$. The horizontal axis corresponds to the number $N(i,j) \in \mathbb{N}$ of data points $(\mu_i,\mu_j) \in \mathcal{S}_{\mathcal{P}}$.}
\end{figure}
%=========================
We show the results of this experiment in Figure \ref{fig:param_dependencev1}. Although the parameter space is two-dimensional, we enumerated the parameters $(\mu_i,\mu_j) \in \mathcal{S}_{\mathcal{P}}$ and plot the values against the number $N(i,j) \in \mathbb{N}$ of the parameters. The comparison of the exact error (in black) with the upper and lower Riesz bounds on $\Omega$ (blue) show that these bounds differ by a multiplicative factor up to 10. Recall that this is the best we can achieve with our error estimators (in orange). The lower bound is remarkably sharp. Recall that $\mycirc=\Omega_2$, which excludes all saw-blades. Due to the fact that the data functions are arbitrarily smooth on $\mycirc$, the computation of the lower bound with the spectral method  converges exponentially fast and is thus very efficient.

The upper bound follows the line of the Riesz-bound on $\Omega$ and is too pessimistic by another multiplicative factor of 10. A better fine-tuning of the involved constants might improve this upper bound.

\subsection{A parametric domain}
%-------------------------------------------------------------
Our next numerical experiment is particularly suited for domain embedding, namely a linear elliptic PDE, posed on a domain $\Omega_\mu$ with parameterized boundary shown in Figure \ref{fig:shapeOptdom}. It is the unit square with a cutout, which cannot be smoothly transformed into a reference domain, due to the sharp corners for angles $\mu > 0$. Such a situation occurs e.g.\ in geometry optimization, where PINNs have already been used, \cite{SUN2023116042}. 
\begin{figure}[!htb]
	\begin{minipage}{1.0\textwidth}
		\centering
		\input{figs/shapeoptdom.tikz}
	\end{minipage}
	\caption{A parameterized square, where the parameter $\mu$ is the angle of a recess.\label{fig:shapeOptdom}}
\end{figure}
	
When solving a PDE on $\Omega_\mu$ with the finite element method, re-meshing  might be necessary for different $\mu$. On the other hand, the training of a PINN is straightforward by excluding all points outside of the domain. This shows why a PINN might be an attractive tool for a PDE on $\Omega_\mu$.

Since the underlying domain is parameterized, we can consider a non-parametric elliptic equation of the form
\begin{equation*}
	\dual{r_{\Omega_\mu}(u_\mu),v}_{H^1_0(\Omega_\mu)} := (A\, \nabla u_\mu, \nabla v )_{L_2(\Omega_\mu)} + (b \cdot \nabla u_\mu + c\, u_\mu, v )_{L_2(\Omega_\mu)} - f_\mu(v) = 0, 
\end{equation*}
for all $v \in H^1_{0}(\Omega_\mu)$ with the diffusion, convection and reaction coefficients given by
\begin{equation*}
	A \equiv \begin{pmatrix}
		1/2 & 1/4 \\
		1/4 & 1/2 
	\end{pmatrix} , \quad 
	b \equiv \begin{pmatrix}
		10 \\
		-3 
	\end{pmatrix}  
	\quad \text{ and } \quad
	c(x,y) := xy+1.
\end{equation*}	
The source function is defined by $f_\mu(v) := (10, v)_{L_2(\Omega_\mu}$. We choose the training set $\mathcal{S}_{\Omega_\mu}$ as $2^{16}$ random points in $\Omega_\mu$. The parameter training set $\mathcal{S}_\mathcal{P}$ consists of five equidistant points in $\mathcal{P}=[0,\pi/2]$, $P=1$. The extended domain is chosen as $\square:= (0,1)^2$ and the imbedded domain as $\mycirc := (0,1) \times (0.25,1)$.

The extension and restriction of the residual $r_{\Omega_\mu}(u_\mu)$ can be done as in the previous example, Corollary\,\ref{cor:boundsSobolev} applies and yields the error estimate
\begin{equation*}
	\frac{\Vert r_\mycirc(\Phi^\theta(\mu)) \Vert_{H^{-1}(\mycirc)}}{\Vert A \Vert_{L_\infty} + \Vert b \Vert_{L_\infty} + \Vert c \Vert_{L_\infty}} 
    \le \Vert \nabla u_\mu - \nabla \Phi^{\theta}(\mu) \Vert_{L_2(\Omega)} 
    \le \frac{\Vert r_\square(\Phi^\theta(\mu)) \Vert_{H^{-1}(\square)}}{\lambda_{\min}(A)},
\end{equation*}
from which we deduce the constants.


%=========================
\begin{figure}[!htb]
	\centering
	%--------------------------
	\begin{tikzpicture}[scale = 0.9]
		\begin{semilogyaxis}[legend cell align={left}, grid=both, width=\textwidth,height=6cm, legend columns = 2, legend style={at={(0.5,1.3)},anchor=north}, cycle list name=black white, ymin=3e-4, ymax=1e1,xmin=0, xmax=pi/2+0.001, black, xtick distance=0.2, xticklabels={, 0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4,,},
			extra x ticks={pi/2},
			extra x tick style={%
					grid=major,
			},
			extra x tick labels={
				$\pi/2$,
			}]
		\addplot[mark=o,black,line width=1pt] table [x=mu, y=abs_H10_error] {figs/data_combined_shapeOpt.dat};
		\addlegendentry{$\mathcal{W}=H^1_0$-error on $\Omega_\mu$\hspace*{10pt}}
		%-------------
		\addplot[mark=triangle,blue,line width=1pt] table [x=mu, y=abs_est_error_ub] {figs/data_combined_shapeOpt.dat};
		\addlegendentry{upper bound on $\Omega_\mu$}
		%-------------
		\addplot[mark=x,blue,line width=1pt] table [x=mu, y=abs_est_error_lb] {figs/data_combined_shapeOpt.dat};
		\addlegendentry{lower bound on $\Omega_\mu$}
		%-------------
        \addplot[mark=triangle,orange,line width=1pt] table [x=mu, y=abs_est_error_box_ub] {figs/data_combined_shapeOpt.dat};
		\addlegendentry{upper bound on $\square$}
		%-------------
		\addplot[mark=x,orange,line width=1pt] table [x=mu, y=abs_est_error_box_lb] {figs/data_combined_shapeOpt.dat};
		\addlegendentry{lower bound on $\mycirc$}
		%-------------
		\end{semilogyaxis}
		\end{tikzpicture} 
		%-------------------------- 
		%--------------------------
		\caption{\label{fig:param_dependencev2} Absolute $H^1_0$-error as well as the estimated $H^1_0$-error on $\Omega$, $\square$ and $\mycirc$. The horizontal axis corresponds to the angle $\mu$.}
\end{figure}
%------------------
The results for a set of nine parameters, which serve as the test set for the PINN, are depicted in Figure \ref{fig:param_dependencev2}. The Riesz bounds on $\Omega_\mu$ (blue) follow the slope of the exact error (black), the upper bound being quite sharp, the lower one too optimistic by a factor of about 10. The lower bound for the error estimator (orange), calculated on $\mycirc$, follows the slope and is quite sharp. The reason might be that the cut-off region does neither concern the Riesz lower bound nor the one on $\mycirc$. On the other hand, however, the upper bound does not follow the slope of the error and is too pessimistic by a factor of 10 -- which overall seems acceptable, but is by far worse than the Riesz upper bound on $\Omega_\mu$. The change of the geometry obviously has only a small effect on the proposed upper error bound. 

\subsection{A parabolic problem on a non-convex polytope}
%-------------------------------------------------------------
Finally, we report results for a time-dependent problem on a domain with \enquote{complicated} geometry. To this end, consider the parameterized parabolic problem $\dot{u}_\mu+A_\mu u_\mu = f$, $u_\mu(0)=0$ on $Q:=I\times\Omega$, $I:=(0,1)$ being the time horizon and $\Omega\subset\mathbb{R}^2$ is the map of the state of Arkansas\,(USA) depicted in Figure \ref{fig:domain_arkansas}. The domain is a non-convex polytope and therefore has a Lipschitz-boundary.  Moreover, $\Omega$ has sharp corners on the right- and lower left-hand side. 
\begin{figure}[!htb]
	\begin{minipage}{1\textwidth}
		\centering
		\includegraphics[width=0.5\textwidth]{figs/domain_arkansas_2.png}
	\end{minipage}
	\caption{The space-time domain $Q = I\times \Omega$, where the green axis refers to the time.\label{fig:domain_arkansas}}
\end{figure}
The parametric elliptic operators $A_\mu \in \mathcal{L}(H^1_0(\Omega), H^{-1}(\Omega))$ are defined by the variational form 
\begin{equation*}
	\langle A_\mu \varphi, \psi \rangle_{H^1_0(\Omega)} 
    := (K \nabla \varphi, \nabla \psi )_{L_2(\Omega)} + (b_\mu \nabla \varphi + c \varphi, \psi )_{L_2(\Omega)}, \quad \forall \, \varphi, \psi \in H^1_0(\Omega),
\end{equation*}
where the time-independent coefficient functions are chosen as
\begin{equation*}
	K \equiv \begin{pmatrix}
		1 & 0 \\
		0 & 0.1 
	\end{pmatrix} , \quad 
	b_\mu(x,y) := (31-\mu)\begin{pmatrix}
		 \sin^2(2 y)\\
		\cos((x+1)^{\mu/4}) 
	\end{pmatrix} \text{ and } \quad
	c(x,y) := xy+1,
\end{equation*}	
with the parameter set $\mathcal{P}:= [1,10] \subset \mathbb{R}$, $P=1$. The parameter dependent convection is chosen to be \emph{not} affinely decomposable, so that this standard assumption of the reduced basis method is not valid, see e.g.\,\cite{RozzaRB}, and using a PINN seems attractive.  We use the space-time variational formulation of the parabolic PDE as introduced in Example \ref{Ex:SpaceTime} above.


The height of Arkansas is normalized to $1$ and the front upper left corner is located at $(0,1,0)^T \in \mathbb{R}^3$, so that we define $\square := (0,1.2) \times (0,1)$ and $\mycirc := (0.1345,0.783) \times  (0,1) \subset \Omega$. With this setting, the extension operator from Proposition\,\ref{prop:LisBochner} can be used and Corollary\,\ref{cor:boundsBochner} applies. 

The PINN has again been trained with a high-fidelity finite-element solution using training sets $\mathcal{S}_Q$, consisting of $1.5 \cdot 10^5$ points for the space-time domain $Q$ and $\mathcal{S}_\mathcal{P}$, consisting of $16$ equidistant points for the parameter. The error has been measured on $31$ parameters. 

%=========================
\begin{figure}[!htb]
	\centering
	%--------------------------
	\begin{tikzpicture}[scale = 0.9]
		\begin{semilogyaxis}[legend cell align={left}, grid=both, width=\textwidth,height=6cm, legend columns = 2, legend style={at={(0.5,1.3)},anchor=north}, cycle list name=black white, ymin=1e-2, ymax=3e2,xmin=1,xmax=10]
		\addplot[mark=o,black,line width=1pt] table [x=param, y=abs_X_error] {figs/data_combined_arkansas.dat};
		\addlegendentry{$\mathcal{W}$-error on $I\times\Omega$}
		%-------------
		\addplot[mark=triangle,blue,line width=1pt] table [x=param, y=abs_est_error_ub] {figs/data_combined_arkansas.dat};
		\addlegendentry{upper bound on $I\times\Omega$}
		%-------------
		\addplot[mark=x,blue,line width=1pt] table [x=param, y=abs_est_error_lb] {figs/data_combined_arkansas.dat};
		\addlegendentry{lower bound on $I\times\Omega$\hspace*{10pt}}
		%-------------
		\addplot[mark=triangle,orange,line width=1pt] table [x=param, y=abs_est_error_box_ub] {figs/data_combined_arkansas.dat};
		\addlegendentry{upper bound on $I\times\square$}
		%-------------
		\addplot[mark=x,orange,line width=1pt] table [x=param, y=abs_est_error_box_lb] {figs/data_combined_arkansas.dat};
		\addlegendentry{lower bound on $I\times\mycirc$}
		%-------------
		\end{semilogyaxis}
	\end{tikzpicture} 
	%-------------------------- 
	%--------------------------
	\caption{\label{fig:param_dependencev3} Absolute $\mathcal{W}$-error as well as the estimated $\mathcal{W}$-error on $I\times \Omega$, $I\times\square$ and $I\times\mycirc$. The horizontal axis corresponds to the parameter value $\mu \in \mathcal{P}$.}
\end{figure}
%==================================
The results are depicted in Figure \ref{fig:param_dependencev3}. The error of the PINN approximation does not depend much on the parameter $\mu$. This is also reflected by the bounds, so that they are basically multiples of the true error. The Riesz bounds on $Q=I\times\Omega$ are about a factor 10 off the true error (black). This is due to the constants in the error-residual relation, see \cite[Thm.\ 5.1]{schwab2009space} and the appendix therein. The error bounds (orange) are quite sharp, in particular the lower one. Again, the data is smooth on $I\times\mycirc$, so that we can use an efficient spectral method as we do not need to resolve the complicated geometry of $\Omega$.

\subsection{Computational times}
In order to investigate the computational overhead required for the lower and upper bounds, we collect in Table \ref{Tab:CPU} the CPU/GPU times for (i) the PINN training, (ii) the evaluation of the PINN at the points $\lbrace \mu \rbrace \times \mathcal{S}_\Omega$ for one $\mu \in \mathcal{S}_\mathcal{P}$ and (iii) solving the Riesz representation problems on $\mycirc$ and $\square$ also for one $\mu\in \mathcal{S}_\mathcal{P}$. The times with respect to all $\mu \in \mathcal{S}_\mathcal{P}$ scale linearly. The time measurement has been carried out using standard devices for each task, e.g., a NVIDIA Tesla V100 GPU has been used for the training and the evaluation of the PINN. The termination criterion of the training process has been a maximum number of iterations, which was $5 \cdot 10^3$ in the case of the saw-blade domain and $10^4$ iterations for the parametric and Arkansas domain. The evaluation of the error estimator on $\square$ has been parallelized using two Intel Xeon Gold 6230 CPUs with 20 cores each. For the discretization, we have used standard $P1$-finite elements with around $2.5 \cdot 10^5$ degrees of freedom. The Riesz problems on $\mycirc$ have been solved with the spectral method using a nodal Lagrange basis of order 12 in the 2D cases and of order 8 in the time-dependent case. This leads to small dense linear systems, which can be solved using serial direct solvers and the error can be expected to be near machine accuracy, due to the exponential convergence of spectral methods. In case of the Arkansas domain the matrix size was $729 \times 729$ and $169 \times 169$ in the stationary cases. Thus, the comparable long solving time of $2.249$ seconds may be due to the non-optimal internal routines of FEniCSx. 

We can see that the time for the error estimation is negligible in comparison to the training time. Moreover, the lower bound on $\mycirc$ can be computed efficiently and this can even be improved if one would use specialized spectral solvers. The numbers confirm the efficiency of the method, even though we did not even use a highly optimized implementation, but the standard algorithms within the FEniCSx implementation.

\begin{table}[]
    \centering
    \begin{tabular}{l|r|r|r|r}
        \multicolumn{3}{c}{} & 
        \multicolumn{2}{|r}{{\textbf{Error estimation}}}\\
         \textbf{Problem} 
         & \textbf{Training} 
         & \textbf{Evaluation}
         & $\mycirc$ & $\square$ \\ \hline
         saw-blade & 1241.52 & 0.0019 & 0.011 & 0.16\\ \hline
         parametric domain & 926.76 & 0.0128 & 0.011 & 0.15\\ \hline
         Arkansas & 7536.71 & 0.0720 & 2.249 & 1.77\\ \hline
    \end{tabular}
    \caption{Times (in seconds) for training (GPU), PINN evaluation (GPU) and error estimation (CPU) on $\mycirc$ and $\square$.}
    \label{Tab:CPU}
\end{table}

