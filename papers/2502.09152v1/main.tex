%%%% ijcai24.tex
\pdfoutput=1
\documentclass{article}
% \typeout{IJCAI--24 Instructions for Authors}

% These are the instructions for authors for IJCAI-24.


\pdfpagewidth=8.5in
\pdfpageheight=11in

% \usepackage[backend=biber,style=numeric]{biblatex}
% The file ijcai24.sty is a copy from ijcai22.sty8
% The file ijcai22.sty is NOT the same as previous years'
% \usepackage{ijcai24}
\usepackage{./ijcai24}
% Use the postscript times font!
% \usepackage{graphicx}
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}
\usepackage{arydshln}
\usepackage{color, xcolor}

% \usepackage{amsfonts}
% \usepackage{array}
% \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
% \usepackage{textcomp}
% \usepackage{stfloats}
% \usepackage{url}
% \usepackage{verbatim}
% \usepackage{graphicx}
% \usepackage{cite}

\usepackage{newfloat}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{xcolor}
%\usepackage{algpseudocode}
\usepackage{mathabx}
\usepackage{multirow}
\usepackage{float}
\usepackage{subfig}
% \usepackage{ulem}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
% %\newtheorem{proof}{Proof}
\newtheorem{assumption}{Assumption}
% \usepackage[table]{xcolor}

\usepackage{appendix}

% \usepackage{lipsum}
% \usepackage{tabularx}

% \renewcommand{\thesection}{\arabic{chapter}.\arabic{section}}
% \newcommand{\appendixsection}[1]{
%   \refstepcounter{section}
%   \renewcommand{\thesection}{\Alph{section}}
%   \section{#1}
%   \renewcommand{\thesection}{\arabic{chapter}.\Alph{section}}
% }
% \usepackage{array} 
% \usepackage{tikz,xcolor}
% \usepackage[implicit=false]{hyperref}

% Comment out this line in the camera-ready submission
% \linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
% \newtheorem{theorem}{Theorem}
% \tt \textbackslash{}appendix

\pdfinfo{
/TemplateVersion (IJCAI.2024.0)
}

\newif\ifshowcomments
\showcommentstrue % Set to true to show comments, set to false to hide
\ifshowcomments
    \newcommand{\yj}[1]{{\color{blue}[YJ: #1]}}
\else
    \newcommand{\yj}[1]{}
\fi

\title{Vertical Federated Continual Learning via Evolving Prototype Knowledge}
% \yj{Vertical Federated Continual Learning via Evolving Prototype Knowledge}}
% PLUREL: Vertical Federated Continual Learning via Prototype Knowledge Fusion

% Single author syntax
% \author{
%     Anonymous
% }

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% \iffalse
\author{
Shuo Wang$^1$
\and
Keke Gai$^1$\and
Jing Yu$^{2}$\and
Liehuang Zhu$^1$\and
Qi Wu$^3$\\
\affiliations
$^1$Beijing Institute of Technology\\
$^2$Minzu University of China\\
$^3$School of Computer Science, The University of Adelaide\\
\emails
\{3220215214, gaikeke, liehuangz\}@bit.edu.cn,
jing.yu@muc.edu.cn,
qi.wu01@adelaide.edu.au
}
% \fi

\begin{document}

\maketitle

\begin{abstract}
   \input{abstract} 
\end{abstract}

\input{intro}
\input{relatedwork}
% \input{sec/problem}
\input{framwork}
\input{experiments}
\input{conclusion}

% \input{Source/Related}
% \input{Source/Preliminaries}
% \input{Source/Method}
% \input{Source/Theoretical}
% \input{Source/Exper}
% %\input{Source/Dis}
% \input{Source/Coc}


% \bibliographystyle{named}
% \bibliography{conference}
\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Abouelnaga \bgroup \em et al.\egroup }{2016}]{abouelnaga2016cifar}
Yehya Abouelnaga, Ola~S Ali, Hager Rady, and Mohamed Moustafa.
\newblock {Cifar-10}: Knn-based ensemble of classifiers.
\newblock In {\em 2016 International Conference on Computational Science and Computational Intelligence}, pages 1192--1195, Las Vegas, NV, USA, 2016.

\bibitem[\protect\citeauthoryear{Baldominos \bgroup \em et al.\egroup }{2019}]{baldominos2019survey}
Alejandro Baldominos, Yago Saez, and Pedro Isasi.
\newblock A survey of handwritten character recognition with mnist and emnist.
\newblock {\em Applied Sciences}, 9(15):3169, 2019.

\bibitem[\protect\citeauthoryear{Cai and Ma}{2022}]{cai2022theoretical}
T~Tony Cai and Rong Ma.
\newblock Theoretical foundations of t-sne for visualizing high-dimensional clustered data.
\newblock {\em Journal of Machine Learning Research}, 23(301):1--54, 2022.

\bibitem[\protect\citeauthoryear{Casado \bgroup \em et al.\egroup }{2023}]{casado2023ensemble}
Fernando~E Casado, Dylan Lema, Roberto Iglesias, Carlos~V Regueiro, and Sen{\'e}n Barro.
\newblock Ensemble and continual federated learning for classification tasks.
\newblock {\em Machine Learning}, 112(9):3413--3453, 2023.

\bibitem[\protect\citeauthoryear{Castiglia \bgroup \em et al.\egroup }{2022}]{castiglia2022compressed}
Timothy~J Castiglia, Anirban Das, Shiqiang Wang, and Stacy Patterson.
\newblock {Compressed-VFL}: Communication-efficient learning with vertically partitioned data.
\newblock In {\em International Conference on Machine Learning}, pages 2738--2766, Baltimore, Maryland, {USA}, 2022.

\bibitem[\protect\citeauthoryear{Chen \bgroup \em et al.\egroup }{2021}]{chen2021overcoming}
Pei-Hung Chen, Wei Wei, Cho-Jui Hsieh, and Bo~Dai.
\newblock Overcoming catastrophic forgetting by bayesian generative regularization.
\newblock In {\em International Conference on Machine Learning}, pages 1760--1770, Virtual Event, 2021.

\bibitem[\protect\citeauthoryear{Das and Patterson}{2021}]{das2021multi}
Anirban Das and Stacy Patterson.
\newblock Multi-tier federated learning for vertically partitioned data.
\newblock In {\em ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing}, pages 3100--3104, Toronto, ON, Canada, 2021.

\bibitem[\protect\citeauthoryear{Feng~Qiang}{2022}]{author2024}
et~al. Feng~Qiang, Boyan~Wei.
\newblock White paper on the application of federated learning technology in finance, 3 2022.
\newblock http://www.hbbill.com/uploadFiles/-16/548/058/54/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E9%87%91%E8%9E%8D%E5%BA%94%E7%94%A8%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf#page=47.32.

\bibitem[\protect\citeauthoryear{Gao \bgroup \em et al.\egroup }{2024}]{gao2024fedprok}
Xin Gao, Xin Yang, Hao Yu, Yan Kang, and Tianrui Li.
\newblock Fedprok: Trustworthy federated class-incremental learning via prototypical feature knowledge transfer.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4205--4214, Seattle, WA, USA, 2024.

\bibitem[\protect\citeauthoryear{Hou \bgroup \em et al.\egroup }{2023}]{10227560}
Chenping Hou, Shilin Gu, Chao Xu, and Yuhua Qian.
\newblock Incremental learning for simultaneous augmentation of feature and class.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45(12):14789--14806, 2023.

\bibitem[\protect\citeauthoryear{Hu \bgroup \em et al.\egroup }{2019}]{8410016}
Chunyu Hu, Yiqiang Chen, Xiaohui Peng, Han Yu, Chenlong Gao, and Lisha Hu.
\newblock A novel feature incremental learning method for sensor-based activity recognition.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering}, 31(6):1038--1050, 2019.

\bibitem[\protect\citeauthoryear{Lebichot \bgroup \em et al.\egroup }{2024}]{lebichot2024assessment}
Bertrand Lebichot, Wissam Siblini, Gian~Marco Paldino, Y-A Le~Borgne, Fr{\'e}d{\'e}ric Obl{\'e}, and Gianluca Bontempi.
\newblock Assessment of catastrophic forgetting in continual credit card fraud detection.
\newblock {\em Expert Systems with Applications}, 249(99):123445, 2024.

\bibitem[\protect\citeauthoryear{Li \bgroup \em et al.\egroup }{2024}]{li2024towards}
Yichen Li, Qunwei Li, Haozhao Wang, Ruixuan Li, Wenliang Zhong, and Guannan Zhang.
\newblock Towards efficient replay in federated incremental learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12820--12829, Seattle, WA, USA, 2024.

\bibitem[\protect\citeauthoryear{Liu \bgroup \em et al.\egroup }{2023}]{liu2023vertical}
Zhili Liu, Heyang Sun, Jinliang Song, Bin Zhang, Yuhang Yan, Bingbing Qiu, Lihang Jiang, and Jingjing Li.
\newblock Vertical federated learning architecture for power company and financial company and electricity pricing model considering user credit evaluation.
\newblock In {\em 2023 3rd International Conference on Consumer Electronics and Computer Engineering (ICCECE)}, pages 820--826, Guangzhou, China, 2023.

\bibitem[\protect\citeauthoryear{Liu \bgroup \em et al.\egroup }{2024}]{liu2024vertical}
Yang Liu, Yan Kang, Tianyuan Zou, Yanhong Pu, Yuanqin He, Xiaozhou Ye, Ye~Ouyang, Ya-Qin Zhang, and Qiang Yang.
\newblock Vertical federated learning: Concepts, advances, and challenges.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering}, 36(7):3615 -- 3634, 2024.

\bibitem[\protect\citeauthoryear{Luo \bgroup \em et al.\egroup }{2021a}]{NEURIPS2021_2f2b2656}
Mi~Luo, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, and Jiashi Feng.
\newblock No fear of heterogeneity: Classifier calibration for federated learning with non-iid data.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, {\em Advances in Neural Information Processing Systems}, volume~34, pages 5972--5984, 2021.

\bibitem[\protect\citeauthoryear{Luo \bgroup \em et al.\egroup }{2021b}]{luo2021feature}
Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, and Beng~Chin Ooi.
\newblock Feature inference attack on model predictions in vertical federated learning.
\newblock In {\em 2021 IEEE 37th International Conference on Data Engineering}, pages 181--192, Chania, Greece, 2021.

\bibitem[\protect\citeauthoryear{Luo \bgroup \em et al.\egroup }{2023}]{luo2023gradma}
Kangyang Luo, Xiang Li, Yunshi Lan, and Ming Gao.
\newblock Gradma: A gradient-memory-based accelerated federated learning with alleviated catastrophic forgetting.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3708--3717, Seattle, WA, USA, 2023.

\bibitem[\protect\citeauthoryear{Ma \bgroup \em et al.\egroup }{2022}]{ma2022continual}
Yuhang Ma, Zhongle Xie, Jue Wang, Ke~Chen, and Lidan Shou.
\newblock Continual federated learning based on knowledge distillation.
\newblock In {\em Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence}, pages 2182--2188, Vienna, Austria, 2022.

\bibitem[\protect\citeauthoryear{Malinovskiy \bgroup \em et al.\egroup }{2020}]{malinovskiy2020local}
Grigory Malinovskiy, Dmitry Kovalev, Elnur Gasanov, Laurent Condat, and Peter Richtarik.
\newblock From local sgd to local fixed-point methods for federated learning.
\newblock In {\em International Conference on Machine Learning}, pages 6692--6701, Virtual Event, 2020.

\bibitem[\protect\citeauthoryear{Ni \bgroup \em et al.\egroup }{2024}]{ni2024feature}
Haotian Ni, Shilin Gu, Ruidong Fan, and Chenping Hou.
\newblock Feature incremental learning with causality.
\newblock {\em Pattern Recognition}, 146(99):110033, 2024.

\bibitem[\protect\citeauthoryear{Qiu \bgroup \em et al.\egroup }{2024}]{qiu2024integer}
Pengyu Qiu, Yuwen Pu, Yongchao Liu, Wenyan Liu, Yun Yue, Xiaowei Zhu, Lichun Li, Jinbao Li, and Shouling Ji.
\newblock Integer is enough: When vertical federated learning meets rounding.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, pages 14704--14712, Vancouver, Canada, 2024.

\bibitem[\protect\citeauthoryear{Romanini \bgroup \em et al.\egroup }{2021}]{romanini2021pyvertical}
Daniele Romanini, Adam~James Hall, Pavlos Papadopoulos, Tom Titcombe, Abbas Ismail, Tudor Cebere, Robert Sandmann, Robin Roehm, and Michael~A Hoeh.
\newblock Pyvertical: A vertical federated learning framework for multi-headed splitnn.
\newblock {\em arXiv preprint arXiv:2104.00489}, PP(99):1--9, 2021.

\bibitem[\protect\citeauthoryear{Sakib and Das}{2024}]{sakib2024explainable}
Shahnewaz~Karim Sakib and Anindya~Bijoy Das.
\newblock Explainable vertical federated learning for healthcare: Ensuring privacy and optimal accuracy.
\newblock In {\em 2024 IEEE International Conference on Big Data}, pages 5068--5077, Washington, DC, USA, 2024.

\bibitem[\protect\citeauthoryear{Shenaj \bgroup \em et al.\egroup }{2023}]{shenaj2023asynchronous}
Donald Shenaj, Marco Toldo, Alberto Rigon, and Pietro Zanuttigh.
\newblock Asynchronous federated continual learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 5055--5063, Vancouver, BC, Canada, 2023.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup }{2023}]{wang2023bdvfl}
Shuo Wang, Keke Gai, Jing Yu, and Liehuang Zhu.
\newblock Bdvfl: Blockchain-based decentralized vertical federated learning.
\newblock In {\em 2023 IEEE International Conference on Data Mining (ICDM)}, pages 628--637, Shanghai, China, 2023.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup }{2024a}]{wang2024unified}
Ganyu Wang, Bin Gu, Qingsong Zhang, Xiang Li, Boyu Wang, and Charles~X Ling.
\newblock A unified solution for privacy and communication efficiency in vertical federated learning.
\newblock In {\em Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023}, pages 1--12, New Orleans, LA, USA, 2024.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup }{2024b}]{wang2024traceable}
Qiang Wang, Bingyan Liu, and Yawen Li.
\newblock Traceable federated continual learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12872--12881, Seattle, WA, USA, 2024.

\bibitem[\protect\citeauthoryear{Xiao \bgroup \em et al.\egroup }{2017}]{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.
\newblock {\em arXiv preprint arXiv:1708.07747}, PP(99):1, 2017.

\bibitem[\protect\citeauthoryear{Yang \bgroup \em et al.\egroup }{2023}]{yang2023dynamic}
Xiyuan Yang, Wenke Huang, and Mang Ye.
\newblock Dynamic personalized federated learning with adaptive differential privacy.
\newblock In {\em Advances in Neural Information Processing Systems}, pages 72181--72192, New Orleans, LA, USA, 2023.

\bibitem[\protect\citeauthoryear{Yang \bgroup \em et al.\egroup }{2024}]{yang2024federated}
Xin Yang, Hao Yu, Xin Gao, Hao Wang, Junbo Zhang, and Tianrui Li.
\newblock Federated continual learning via knowledge fusion: A survey.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering}, 38(8):3832--3850, 2024.

\bibitem[\protect\citeauthoryear{Yoon \bgroup \em et al.\egroup }{2021}]{yoon2021federated}
Jaehong Yoon, Wonyong Jeong, Giwoong Lee, Eunho Yang, and Sung~Ju Hwang.
\newblock Federated continual learning with weighted inter-client transfer.
\newblock In {\em International Conference on Machine Learning}, pages 12073--12086, Virtual Event, 2021.

\bibitem[\protect\citeauthoryear{Yu \bgroup \em et al.\egroup }{2024}]{yu2024overcoming}
Hao Yu, Xin Yang, Xin Gao, Yihui Feng, Hao Wang, Yan Kang, and Tianrui Li.
\newblock Overcoming spatial-temporal catastrophic forgetting for federated class-incremental learning.
\newblock In {\em ACM Multimedia 2024}, pages 1--9, Melbourne, Australia, 2024.

\bibitem[\protect\citeauthoryear{Zhang \bgroup \em et al.\egroup }{2022a}]{zhang2022adaptive}
Jie Zhang, Song Guo, Zhihao Qu, Deze Zeng, Haozhao Wang, Qifeng Liu, and Albert~Y Zomaya.
\newblock Adaptive vertical federated learning on unbalanced features.
\newblock {\em IEEE Transactions on Parallel and Distributed Systems}, 33(12):4006--4018, 2022.

\bibitem[\protect\citeauthoryear{Zhang \bgroup \em et al.\egroup }{2022b}]{zhang2022cross}
Zhouyangzi Zhang, Bin Guo, Wen Sun, Yan Liu, and Zhiwen Yu.
\newblock {Cross-FCL}: Toward a cross-edge federated continual learning framework in mobile edge computing systems.
\newblock {\em IEEE Transactions on Mobile Computing}, 23(1):313--326, 2022.

\bibitem[\protect\citeauthoryear{Zhu \bgroup \em et al.\egroup }{2021}]{zhu2021prototype}
Fei Zhu, Xu-Yao Zhang, Chuang Wang, Fei Yin, and Cheng-Lin Liu.
\newblock Prototype augmentation and self-supervision for incremental learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 5871--5880, Virtual, 2021.

\end{thebibliography}

% \appendix
% \input{Source/Appendices}


\end{document}

