\section{Experimental Results}
\label{sec:results}

In this section, we describe the experimental results of applying \textsc{ConfD} to analyze Ext4, XFS, ZFS and WiredTiger.
First (\S\ref{sec:results-dependencies}), we show that \textsc{ConfD} can extract 160 multilevel configuration dependencies from the target systems  effectively with a low false positive rate (8.1\%).
Second (\S\ref{sec:results-issues}), we demonstrate that \textsc{ConfD} can help address configuration-related issues more effectively compared to existing dependency-agnostic solutions. 
Through the experiments, we have identified various configuration-related issues including 17 specification issues, 18 configuration handling issues, and 10 regression test failures induced by valid configurations. 



 \begin{table*}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c | c | c | c | c | c}
			\textbf{Target FS } & \multicolumn{2}{c|}{\textbf{Self Dependency (SD)}} & \multicolumn{2}{c|}{\textbf{ Cross-Param. Dep. (CPD)}}  & \multicolumn{2}{c|}{\textbf{Cross-Comp. Dep. (CCD)}} & \multicolumn{2}{c}{\textbf{All Level Combined}}\\
 \cline{2-9}
		
		 \textbf{Ecosystem} & \textbf{Extracted}  &  \textbf{FP} &  \textbf{Extracted}  &   \textbf{FP}  &  \textbf{Extracted} &  \textbf{FP}   & \textbf{Extracted} &  \textbf{FP} \\
					\hline
{Ext4}  & 17 & 0  & 48 & 1 (2.1\%) & 46 & 3 (6.5\%) & 111 & 4 (3.6\%) \\
			\hline
{XFS}  & 18 & 2 (11.1\%) & 10  & 3 (30.0\%) & 15 & 4 (26.7\%) & 43 & 9 (20.9\%)\\
			\hline
{ZFS} & 4 & 0 & 1 & 0 & 0 & 0 & 6 & 0\\
                \hline
 \multicolumn{1}{r|}{\textbf{Total}} & 39 & 2  (5.7\%) & 59 & 4 (6.9\%) & 61 &  7 (11.5\%)  &  160 & 13 (8.1\%)\\
\hline
		\end{tabular}
	\end{center}
	\caption{ {\bf  Multilevel Configuration Dependencies Extracted by \textsc{ConfD}.} This table shows the numbers of multilevel  dependencies extracted from three FS ecosystems (Ext4, XFS, ZFS) automatically.  `FP' means False Positive rate.  
}
	\label{tab:accuracyofdependency}
\end{table*}

\begin{table*}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c }
			\textbf{Target } & \multicolumn{2}{c}{\textbf{Self Dependency (SD)}} \\
            \cline{2-3}
		      \textbf{database} & \textbf{Extracted}  &  \textbf{FP}  \\
			\hline
            {WiredTiger}  & 35 & 0   \\
			\hline
		\end{tabular}
	\end{center}
	\caption{ {\bf  Configuration Dependencies Extracted by from WiredTiger.} This table shows the numbers of configuration dependencies extracted from WiredTiger automatically.  `FP' means False Positive rate.}
	\label{tab:wiredtigerdep}
\end{table*}



\begin{table}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c | c   }
 	\textbf{Target FS }  &  \multicolumn{4}{c}{\textbf{\# of Uncorrectable Images Reported}}    \\
          \cline{2-5}
           	\textbf{ Ecosystem  }  & {\texttt{rfsck} (1) }  & \multicolumn{3}{c}{{\texttt{ConfD-rfsck} (25)}  }    \\
\hline
Ext4  & 11  & $<$ 11 (4) & $=$ 11 (4) & $>$ 11 (17)   \\
			\hline
 
		\end{tabular}
	\end{center}
	\caption{ {\bf Comparison of Two FS Fault Injectors.} 
\texttt{rfsck} explores 1 default configuration state and reports 11 uncorrectable images. \texttt{ConfD-rfsck} explores 25  configuration states;   it reports 
$>$ 11 uncorrectable images (i.e., better than \texttt{rfsck}) in 17 out of 25 configuration states.}
	\label{tab:result-rfsck}
\end{table}



\subsection{Can \textsc{ConfD} extract multilevel dependencies?}
\label{sec:results-dependencies}

Table~\ref{tab:accuracyofdependency} summarizes the multilevel configuration dependencies extracted by \textsc{ConfD} from Ext4, XFS and ZFS   {automatically}. 
As shown in the table, we were able to extract 160  unique  dependencies in total, including 39 Self Dependency (SD), 59 Cross-Parameter Dependency (CPD), and 61 Cross-Component Dependency (CCD). 
The multilevel dependencies have been observed on  both Ext4 and XFS,  which is consistent with our manual study (\S\ref{sec:bugstudy}).  
 
We manually examined all the 160 dependencies extracted by \prj automatically and found that the overall false positive rate is 8.1\% (13/160), which is similar to that of the previous work on analyzing configuration constraints in other software  systems~\cite{cdep,spex}. Note that \prj is designed to handle the  unique configuration methods of FS ecosystems (\S\ref{sec:background} and \S\ref{sec:findings})  which is arguably more challenging to analyze  compared to the targets of existing work.

 Table~\ref{tab:wiredtigerdep} summarizes the extracted dependencies from WiredTiger~\cite{wt}. We were able to extract 35 self dependencies from the source code and  verified them to be correct without any false positives. This result  is expected because we focus on the database creation subsystem of WiredTiger (\S\ref{sec:DBextension}).  Broadening the scope to cover other subsystems will likely extract   more dependencies including  cross-component dependencies, which we leave as future work.
  
\vspace{-0.1in}
\subsection{Can \prj help address configuration issues?}
\label{sec:results-issues}
\input{compare}


\subsubsection{Summary of Configuration Issues}
\label{sec:summary-issues}


\begin{table}[t]
	\small
	\begin{center}
		\begin{tabular}{ l   | c | c | c }
		 	\textbf{\textsc{ConfD} Plugin}     &\multicolumn{3}{c}{\textbf{\# of Issue Reported}}  \\
		 	  \cline{2-4}
   \textbf{(Type of  Issue Reported)}   & \textbf{Ext4}  &  \textbf{XFS}  & \textbf{Total} \\
          \hline
 \texttt{ConfD-specCk}    (undoc./wrong dep.)  &    13  & 4  &   17 \\
			\hline
\texttt{ConfD-handlingCk}  (bad reaction)   & 13  &  5   &  18\\
          \hline
 \texttt{ConfD-xfstests}   (test case failure)   &    5  & 4  &   9 \\
           \hline
 \texttt{ConfD-e2fsprogs}   (test case failure)  &    1  & N/A  &   1 \\
           \hline
 \texttt{ConfD-rfsck}   (uncorrectable image)    &    280  & --  &   280 \\
           \hline
 \texttt{ConfD-gt-hydra}  (hang)   &    17  & --  &   17 \\
  	\hline
		\end{tabular}
	\end{center}
	\caption{ {\bf Summary of Issues.} 
This table summarizes configuration-related issues observed via  \prj plugins. 
}
	\label{tab:result-summary}

\end{table}



\begin{table}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c | c }
		 	\textbf{Target FS}  &\multicolumn{3}{c|}{\textbf{\# of Undocumented/Wrong Dep.}} & \textbf{Total} \\
		 	  \cline{2-4}
 	\textbf{Ecosystem}   & \textbf{\space \space \space \space SD \space \space \space \space}  & \textbf{\space \space \space \space CPD \space \space \space \space}  & \textbf{CCD}  & \\
          \hline
   Ext4  &  7  &    4  & 2  &   13 \\
			\hline
XFS    & 2 &  2 &  0   & 4 \\
	\hline
  \multicolumn{1}{r|}{\textbf{Total}} & 9 & 6  &     2& 17 \\
  	\hline
		\end{tabular}
	\end{center}
	\caption{ {\bf Specification Issues.} 
This table summarizes the undocumented or wrong dependencies observed. `SD', `CPD', and `CCD' are   defined in Table~\ref{tab:dependencies}. 
}
	\label{tab:documentation-issue}
\end{table}



\begin{table*}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c  }
 	\textbf{ID}  & \textbf{Reaction}  & \textbf{Description} & \textbf{Observed?}     \\
          \hline
 1   & Early Termination   & the  utility program exits w/o pinpointing the configuration error &  Y \\
			\hline
		 2    & Functional Failure  & the utility fails functional testing w/o pinpointing the configuration error &   Y \\
	\hline
  3  &  Silent Violation & the system changes input configurations to different values w/o notifying users & Y \\
			\hline
 4    &  Silent Ignorance  & the system  ignores input configurations & N   \\
			\hline
  5    & Crash/Hang  & the system crashes or hangs  & N   \\
			\hline		
6    &  Partial Report  & the utility  partially identify the violated configuration dependencies  & Y    \\
			\hline
		\end{tabular}
	\end{center}

	\caption{ {\bf Suboptimal Reaction of Configuration Dependency Violation.}  This table summarizes the bad handling behaviors observed when the  configuration dependencies are violated. The first five   are based on the definitions from    \cite{spex}.  
}
	\label{tab:handling}
\end{table*}

Table~\ref{tab:result-summary} summarizes 
the configuration-related issues triggered by \prj plugins in our experiments. Overall, we  observed more than 300   issues of various types.
The issues are diverse because the plugins are created for different purposes  or based on different base tools  (Table~\ref{tab:plugins}). 
Note that all the issues require   dependency-guided configuration states generated by \prj to manifest. In other words, continuously running the original research prototypes or standard test suites cannot expose the issues.
Also, since we do not change  the test logic of the base tools,  the enhancement  is purely contributed by the dependency information from \prj. Since   \texttt{ConfD-rfsck} and  \texttt{ConfD-gt-hydra} have been discussed in \S\ref{sec:dependency-aware-vs-agnostic}, we focus on others  below.


Table~\ref{tab:documentation-issue} summarizes the specification issues detected by  \texttt{ConfD-specCk}.
We have identified 17 inaccurate specification issues in total.
The issues mainly manifest as undocumented critical dependencies or wrong dependencies, which may occur to both Ext4 and XFS and involve SD, CPD, and CCD. For example, there is a CPD extracted by \prj which specifies that two  parameters of   \texttt{mke2fs} (i.e., \texttt{meta\_bg} and \texttt{resize\_inode})  cannot be used together, but this CPD is missing from the Linux man-pages.
 As another example, there is a CCD which implies that \texttt{resize2fs} may not be used for Ext4 when the \texttt{bigalloc} feature is enabled through \texttt{mke2fs}. Violating the CCD may corrupt the file system, which is unfortunately not mentioned in the specification. 

Table~\ref{tab:handling} summarizes the suboptimal handling of misconfigurations identified through \texttt{ConfD-handlingCk}. 
We follow the criteria in the literature~\cite{spex}: when a misconfiguration occurs (i.e., a dependency is violated),  the system should pinpoint either the offending parameter's name/value or its location information; failing to do so implies misconfiguration vulnerabilities. 
Specifically, there are six types of misconfiguration vulnerabilities based on different reactions, including  
`Early Termination', `Functional Failure', `Silent Violation',  `Silent Ignorance', `Crash/Hang', and `Partial Report'. The first five types are based on the definitions from~\cite{spex}, while the last one is unique in our study because we consider more complicated multilevel dependencies.   

As an example, the \texttt{mke2fs} parameter \texttt{-E encoding}  enables the \texttt{casefold} feature and set the encoding in Ext4. But if the user tries to disable the \texttt{casefold} feature when using the \texttt{-E encoding}, instead of showing an error or warning, the utility enables the \texttt{casefold} feature silently without informing the user. We consider this as  `Silent Violation'.

When more than one dependency is violated, utilities often only show a partial message (i.e., `Partial Report'). 
For example, the \texttt{mkfs.xfs} parameter \texttt{sunit}  involves two dependencies:
(1) it does not allow unit suffixes, and (2) it cannot be specified together with \texttt{su}. But when both dependencies are violated, the utility may only show one of the violations.

 In total, we have observed 4 out of the 6 types of suboptimal reactions, which suggests that FS ecosystems are not immune  from misconfiguration vulnerabilities reported in other practical systems. Note that \texttt{ConfD-handlingCk} leverages the static analysis of \textsc{ConfD} to violate specific dependencies carefully, which avoids many duplicate and valid configuration states for testing. This reduces the manual effort needed for the post-mortem analysis.    

In terms of \texttt{ConfD-xfstests} and \texttt{ConfD-e2fsprogs}, we have observed 10 new test case failures (9 from \texttt{ConfD-xfstests} and 1 from \texttt{ConfD-e2fsprogs}) which can be induced by \textit{valid} configuration states generated by \prj.
For example,  
\texttt{ConfD-xfstests} triggers an Ext4  corruption when applying the online defragmentation tool \texttt{e4defrag} to the file system with  the \texttt{bigalloc} feature enabled.
Note that a FS test case may involve multiple utilities. 
Due to the complexity of the test case and the FS ecosystems, a test case may fail for various subtle reasons (e.g., timing at \texttt{mount}) in practice, which is time-consuming to diagnose even for developers~\cite{howtofindExt4bugs} as discussed in \S\ref{sec:reducefalsepositives}. In our experiments, we observed more than 10 newly failed test cases after changing with valid configurations. 
We only count the cases that we have manually verified and reproduced at the time of this writing.
Also, since  \prj  limits the change to the configuration states without modifying the test logic, it may help narrow  down the root cause of a test case failure to the configuration-related code paths.

Table ~\ref{tab:testcaseresponse} further breaks down the result of test cases for different target software during  regression testing experiments.  \texttt{xfstests} classifies test cases into different groups based on different target software. For Ext4 and XFS, it has 46 and 97 test cases respectively. The Generic group has a total of 181 test cases which are designed to test all the file systems in the test suite. 
As shown in the last column of the table, \texttt{ConfD-xfstests} has triggered  failures induced by \textit{valid} configurations  in all three test case groups (i.e., 4 for Ext4, 4 for XFS, and 1 for the Generic group).

\begin{table*}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c | c }
& \textbf{Target FS} & \multicolumn{2}{c|}{\textbf{Testcases \#}} &  \textbf{Dep. Aware} \\
        \cline{3-4}
    \textbf{Plugin} & \textbf{Ecosystem}  & \textbf{\space \space \space \space \space Total \space \space \space \space \space}  & \textbf{\space \space \space \space \space Used \space \space \space \space \space} & \textbf{Config. States \#}  \\
          \hline
ConfD-zfstests & ZFS  & 1581   & 154 & 167 \\
	\hline
		\end{tabular}
	\end{center}
	\caption{ {\bf Summary of ConfD-zfstests.}  This table summarizes the statistics of Plugin \#7 ConfD-zfstests.}
	\label{tab:zfstests}
\end{table*}

For \texttt{ConfD-zfstests}, we have not observed any test case failure. The reason behind could be the less number of configuration dependencies we could extract from the source code since the effectiveness of the plugins are dependent on the critical configuration dependencies extracted from the source code. 
Table ~\ref{tab:zfstests} shows the statistics of running Plugin \#7. We have tried 167 dependency-aware configuration states based on the configuration dependency extracted by ConfD-core on 154 test cases from ZFS test suite. Since our focus was \texttt{Zfs-create} configuration parameters and ZFS doesn't group test cases for different utilities, we separated the test cases containing \texttt{Zfs-create} command from the ZFS test suite and only ran our configuration states on the selected ones. ZFS test suite has a total of 1581 test cases and separating the test cases bases on our interest saves time spent running irrelevant test cases and doesn't incur any false positives. Additionally, our plugin also allows to adding new test cases same as the original test suite.

 
\iffalse
\begin{table*}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c | c | c }
         & & & & \multicolumn{2}{c}{\textbf{Failed}} \\
                    \cline{5-6}
 	\textbf{Test}  & \textbf{Target}  & \textbf{Total} & \textbf{} & \textbf{Due to } & \textbf{Due to}     \\
        \textbf{Suite}  & \textbf{Software}  & \textbf{test cases \#} & \textbf{Successful} & \textbf{test case induced} & \textbf{target software induced}     \\
          \hline
 ConfD-xfstests   & Ext4   & 64 &  30  & 34 & 4\\
			\cline{2-6}
		     & XFS  & 536 &   106 & 430  & 4 \\
             \cline{2-6}
             & Generic & 689 & 180 & 509 & 1 \\
	\hline
   ConfD-e2fsprogs   & e2fsck   & 23 &  21  & 2 & 0\\
			\cline{2-6}
		     & resize2fs  & 19 &   13 & 6  & 1\\
			\hline
		\end{tabular}
	\end{center}

	\caption{ {\bf Summary of Test Case Response.}  This table summarizes the total number of test cases used during our experiments and their results.  
}
	\label{tab:testcaseresponse}
\end{table*}
\fi


\begin{table*}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c |  c }
        \textbf{Plugin}  & \textbf{ Target Software}  & \textbf{\space \space Total Test \# \space \space} & \textbf{\space \space Failed Test \space \space}  & \textbf{ Induced by Config.}     \\
          \hline
 ConfD-xfstests   & Ext4   & 46 &  18   & 4  \\
			\cline{2-5}
		     & XFS  & 97 &   11  & 4   \\
             \cline{2-5}
             & Generic & 181 & 173 &   1   \\
	\hline
   ConfD-e2fsprogs   & e2fsck   & 23 & 2  & 0  \\
			\cline{2-5}
		     & resize2fs  & 19 &   6  & 1  \\
			\hline
		\end{tabular}
	\end{center}

	\caption{ {\bf Test Case Result for Different Target Software.} 
    This table breaks down the result of regression tests for different target software.
    The last column shows the number of failures induced by valid configurations after our manual validation. 
}
	\label{tab:testcaseresponse}
\end{table*}


\begin{table*}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c | c }
         & & & \multicolumn{2}{c}{\textbf{False Positives}} \\
                    \cline{4-5}
 	\textbf{Plugin}  & \textbf{Target}  & \textbf{Total} & \textbf{Before } & \textbf{After}     \\
        \textbf{ }  & \textbf{Software}  & \textbf{test cases \#} & \textbf{Optimization} & \textbf{Optimization}     \\
          \hline
ConfD-xfstests   & Ext4   & 46 & 14 (30.43\%) & 1 (2.17\%)\\
			\cline{2-5}
 & XFS  & 97 &  7 (7.22\%) & 4 (4.12\%) \\
	\hline
		\end{tabular}
	\end{center}

	\caption{ {\bf Summary of False Positive Reduction.}  This table summarizes the number of false positives before and after our optimization to the testing script. 
}
	\label{tab:FPreduction}
\end{table*}

\vspace{-0.05in}
\subsubsection{Reduction of False Positive Rate.}
\label{sec:FalsePositiveExp}
As discussed in \S\ref{sec:reducefalsepositives}, it is important to avoid \textit{plugin-caused failures} to reduce false positives for regression testing. 
 Table ~\ref{tab:FPreduction} summarizes the false positive rate before and after our optimization for \texttt{ConfD-xfstests} (\S\ref{sec:reducefalsepositives}). 
Before the optimization,  
30.43\% (14/46) of the Ext4, and 7.22\% (7/97) of the XFS tests exhibited plugin-caused failures.
 After the optimization, we were able to reduce the percentages to 2.17\% (3/46) and 4.12\% (6/97) for Ext4 and XFS respectively,  which results in improvement of false positive rate by 92.87\% (for Ext4) and 42.93\% (for XFS) respectively. 

An example of the false positive reduction,  we examines a case from \texttt{ext4/011} in details. The original test invokes \texttt{mkfs} with two necessary configurations (\texttt{-O mmp} and \texttt{-E mmp\_update\_interval=2}). Before the optimization, these configuration parameters were blindly discarded and  replaced with the configurations generated by \prj, which leads to a plugin-caused failure. After the optimization, \texttt{ConfD-xfstests} maintains these existing parameters to satisfy the necessary condition and append additional parameters of interest that do not conflict with the original test, which effectively eliminates the false positive instance.  


 



\vspace{-0.05in}
\subsubsection{State Generation:  FB-HYDRA vs. \textsc{ConfD}}
\label{sec:state-generation-vs-fb-hydra}
\vspace{-0.05in}


\begin{table}[t]
	\small
	\begin{center}
		\begin{tabular}{ c | c | c | c  }
 	\textbf{Framework}  & \textbf{\space \space \# of States \space \space}  & \textbf{\# of Duplicate}  &  \textbf{\# of Invalid} \\
          \hline
FB-HYDRA  & 56,592 &  42,745 (75.5\%)  &  15,146 (26.8\%)   \\
			\hline
		\textsc{ConfD}    & 30 &  0 &  0  \\
	\hline
 
		\end{tabular}
	\end{center}

	\caption{ {\bf Comparison of State Generation.} 
}
	\label{tab:vs-fb-hydra}
	\vspace{-0.1in}
\end{table}

One unique feature of \textsc{ConfD} is it generates configuration states based on  multilevel dependencies, which is critical for analyzing configuration issues given the huge configuration space.
To the best of our knowledge, the FB-HYDRA configuration management framework~\cite{Yadan2019Hydra} provides the most similar functionality. It includes a ``multirun'' feature to support running an application with different configurations in different runs automatically. We compare the configuration states generated by FB-HYDRA and \textsc{ConfD} in this section to demonstrate the difference.

Table~\ref{tab:vs-fb-hydra} shows  the states generated by FB-HYDRA and \textsc{ConfD} for the same program (i.e., \texttt{mke2fs}) given the same set of  configuration parameters.  For simplicity, we only use 10 parameters with limited ranges  in this experiment. 
As shown in the table, even with this simplified scenario, FB-HYDRA may generate many duplicated    or  invalid states. This is because FB-HYDRA is agnostic to the configuration constraints of \texttt{mke2fs}. 
Specifically, FB-HYDRA maintains a list for each parameter and its possible values. It  passes all lists to the \texttt{itertools.product()} function which returns the cartesian product of the values in the lists.
Such a simple algorithm is incompatible with FS ecosystems. For example, `\texttt{mke2fs -b 1024 -C 2048}' and `\texttt{mke2fs -C 2048 -b 1024}' are equivalent in practice but are considered as different in FB-HYDRA. Moreover, invalid states can easily be created by FB-HYDRA due to violation of dependencies, which suggests the importance of dependency analysis.

Note that FB-HYDRA has other features that \textsc{ConfD} does not have (e.g., Python library support). Also, FB-HYDRA supports plugins which makes it possible to benefit from the state generation of \textsc{ConfD} (see \S\ref{sec:discussion} for more discussion).
Therefore, we view FB-HYDRA and \textsc{ConfD}  as complementary.
