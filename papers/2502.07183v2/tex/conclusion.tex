\section{Conclusion}
In summary, we introduced a space-aware instruction tuning method aimed at improving guide dog robots' ability to provide accurate and effective walking guidance to the visually impaired.
We developed a novel space-aware data generation pipeline and used it to create the SAIT dataset. 
Additionally, we proposed SA-Bench and an evaluation protocol to enable the assessment of spatial awareness in VLMs.
Through comprehensive comparisons with state-of-the-art algorithms, we demonstrated the effectiveness of our approach, highlighting its potential in enhancing spatial guidance capabilities.

However, relying solely on an automated data generation pipeline can inadvertently lead to biased or noisy descriptions, resulting in lower LLM judge scores for SA-VLM. 
Hence, incorporating human-generated data is necessary to correct these inaccuracies and ensure a more robust SA-VLM.
Another challenge lies in the lack of real-world experiments, which impedes our understanding of how the method would perform under a real-world conditions such as inference latency or variations in weather and illumination. 
Future work should therefore focus on both enhancing data quality and conducting thorough real-world validations—including user studies with visually impaired individuals—to fully ascertain the method’s practical applicability. 




