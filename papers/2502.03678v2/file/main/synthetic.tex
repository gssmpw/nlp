\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[height=18ex]{file/figures/synthetic_0.pdf}
        \caption{0'th token}
        \label{fig:subfig1}
    \end{subfigure}%
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[height=18ex]{file/figures/synthetic_20.pdf}
        \caption{20'th token}
        \label{fig:subfig2}
    \end{subfigure}%
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[height=18ex]{file/figures/synthetic_50.pdf}
        \caption{50'th token}
        \label{fig:subfig3}
    \end{subfigure}%
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[height=18ex]{file/figures/synthetic_200.pdf}
        \caption{200'th token}
        \label{fig:subfig4}
    \end{subfigure}%
    \begin{subfigure}[b]{0.12\textwidth}
        \centering
        \raisebox{3ex}{\includegraphics[height=18ex]{file/figures/synthetic_legend.pdf}}
        % \caption{Legend}
        \label{fig:subfig5}
    \end{subfigure}
    \caption{%\small
        The probability that greedy decoding can attain globally optimal response, with respect to the number of newly generated tokens, and with different starting positions in the generation history.
        The legend is shared across sub-figures.
    }
    \label{fig:synthetic_setting}
    % \vspace{-1em}
\end{figure*}

\section{Sanity Check: Semi-Synthetic Settings}\label{main:synthetic}
The implication of our theoretical analysis is straightforward.
However, it is natural to ask whether the phenomenon actually occurs in real-world LLM decoding scenarios.
To provide clear empirical evidence accompanying our theoretical analysis, in this section, we present semi-synthetic experiments that serves as a sanity check.
In particular, in moderately realistic settings, we show that greedy decoding for text generation with stepwise optimization results in suboptimal responses.
We first outline the semi-synthetic setting, and then present the empirical findings.

% \vspace{-2ex}
\paragraph{Illustrative Approximation}
\looseness=-1
For any modern LLM with a vocabulary size $|\Vcal|$ (typically on the order of $10^4$ to $10^5$), identifying the globally optimal sequence across multiple steps becomes computationally intractable, even for relatively short sequence lengths ($<100$).
To ensure the validity of our claim while providing a clear and accessible illustration, we adopt beam search as an approximation strategy of obtaining globally optimal sequence.
Since we measure the chance that greedy decoding can attain the global optimum with the stepwise optimal response, this approximation serves as an upper bound on achievable performance, indicating the discrepancy between greedy decoding and the true globally optimal response.

% \vspace{-2ex}
\paragraph{Approximating Natural Language Scenarios}
Since the prompt or context of the generation influence model behavior, we align our experimental setting with common human-LLM interactions.
Specifically, we utilize MT-Bench \citep{zheng2023judging} questions as curated prompts, which are designed to evaluate conversational chat models.
These samples serve as an approximation of real-world natural language context distributions, ensuring that our findings are grounded in practical scenarios.


% \vspace{-2ex}
\paragraph{Findings}
For each prompt, together with a certain length of generation history ($0$ means only the prompt is given), we evaluate whether the joint probability of the sequence generated with greedy decoding is greater than or equal to that produced by beam search (the proxy of the global optimum).
This comparison indicates the extent to which greedy decoding deviates from the globally optimal response.
As illustrated in Figure~\ref{fig:subfig1}, greedy decoding consistently results in suboptimal sequences, and the phenomenon can be observed with a small number of newly generated tokens.

In addition, the potential deviation may behave differently across various positions in the generated text.
For instance, when openings of response diverge, it is hard for greedy decoding to achieve optimal results afterwards.
To reduce potential inductive bias resulting from the diversity at early stages of generation, we evaluate generations starting/continuing from various positions throughout generation history, as presented in Figures~\ref{fig:subfig2}--\ref{fig:subfig4}.
We can observe that the deviation persists across different positions, which empirically demonstrate the common existence of sub-optimality in autoregressive decoding for text generation.

% \section{(Semi)-Synthetic Experiments}
% The principles behind our approach are straightforward; however, one might question whether the observed phenomenon persists in real-world LLM decoding scenarios. To provide a clear evidence of the previous theoretical analysis and also address the aforementioned concern, we introduce a (semi)-synthetic experiment designed to demonstrate that, in moderately realistic settings, greedy decoding during text generation with step-wise optimization results in suboptimal response. Before presenting the experimental results, we first outline the semi-synthetic setup.

% \paragraph{Illustrative Approximation}\looseness=-1
% Although there is no doubt on the existence of optimal response, for any modern large language model with a vocabulary size \(|\Vcal|\) ( typically on the order of \(O(10^4)\) to \(O(10^5)\)), identifying the joint optimal sequence across multiple steps becomes computationally intractable, even for relatively short sequence lengths (\(<100\)). To uphold the validity of our claim while offering an accessible illustration, we adopt beam search as an approximation of the globally optimal sequence. Since we measure the probability that greedy decoding achieves optimal response, this approximation serves as an upper bound on achievable performance, highlighting the discrepancy between greedy decoding and the true global optimal response.

% \paragraph{Approximating Natural Language Scenarios}
% One may also curious about the prompt or context in the generation since those factors will influence the generation behaviour as well. It is crucial to demonstrate in realistic scenarios. Specifically, we align our experiment setting with common human interactions with large language models. To achieve this, we utilize MT-Bench questions as curated prompts and contexts, which are designed for evaluating conversational, open-ended chat models. These samples serve as an approximation of real-world natural language context distributions, ensuring that our findings are grounded in practical, human-like use cases.

% \paragraph{Results}
% For each prompt or context, we evaluate whether the joint probability of the sequence generated through greedy decoding is greater than or equal to that of the sequence produced by the approximate global optimum method, i.e., beam search. This comparison highlights the extent to which greedy decoding diverges from the optimal sequence. As demonstrated in Figure \ref{fig: synthetic exp}, greedy decoding consistently results in suboptimal sequences, even when generating a small number ($<10$) of new tokens. Additionally, the behavior varies across positions in the generated text. For example, the beginning of the answer are usually diverge and it can be harder for greedy decoding to achieve optimal. To reduce potential inductive biases arising from greater diversity at the initial stages of generation, we evaluate sequences at various positions throughout the generated text (Figure \ref{fig:subfig1}-\ref{fig:subfig4} capture different starting positions for the evaluation). Our findings indicate that this behavior persists across all evaluated positions, underscoring the importance of the issue. This observation naturally suggests a solution: a reflective decoding strategy using a sliding window mechanism.



