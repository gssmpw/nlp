\section*{Broader Impact}\label{sec:broader_impact}
\looseness=-1
In this paper, we theoretically characterize and empirically address the sub-optimality of the autoregressive decoding for text generation.
In particular, we propose a selective refinement framework and implement it with a sliding reflection window mechanism, enabling interchangeable refinement and generation as the decoding proceeds.
Our approach strikes a balance between efficiency and optimality.
There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

\section*{Acknowledgment}  % intentionally subsection
\looseness=-1
We would also like to acknowledge the support from NSF Award No. 2229881, AI Institute for Societal Decision Making (AI-SDM), the National Institutes of Health (NIH) under Contract R01HL159805, and grants from Quris AI, Florin Court Capital, and MBZUAI-WIS Joint Program.
ZT is supported by the National Institute of Justice (NIJ) Graduate Research Fellowship, Award No. 15PNIJ-24-GG-01565-RESS.