\section{The Proof of Theoretical Result}

\begin{theorem}[Indication of Deviation from the Globally Optimal Length-$T$ Response]\label{supp:thm:small_conditional_prob}
    % Suppose that the context length $N$ of LLM is sufficiently large.
    Given the prompt $X_{\leq 0}$, when an oracle LLM (Assumption~\ref{aspt:oracle_LLM}) generates a stepwise optimal length-$T$ response which is not the globally optimal response with the same length, let $L \leq T$ denote the minimum length of prefix-sequence needed in order for such deviation to manifest itself (Assumptions \ref{aspt:strict_preference} and \ref{aspt:no_return_after_detour}).
    Then, the deviation from the globally optimal response happens at some step $K < L$.
    Furthermore, the conditional probability when generating the token $w_{v_L} \in \Vcal$ is strictly smaller than a positive number, which itself is strictly smaller than $1$, i.e.,
    % In other words, the LLM will be relatively uncertain about
    \begin{equation}
        \begin{split}
             & 1 > \epsilon_L > \max_{w \in \Vcal} g(X_L = w \mid X_{1:L-1} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \ldots w_{\widehat{\vbf}_T[L - 1]}, X_{\leq 0}),                                                                                                         \\
             & \text{        where } \epsilon_L = \frac{f(X_{1:L} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \ldots w_{\vbf_T^*[L - 1]} w_{\vbf_T^*[L]} \mid X_{\leq 0})}{f(X_{1:L - 1} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \ldots w_{\widehat{\vbf}_T[L - 1]} \mid X_{\leq 0})}.
        \end{split}
    \end{equation}
\end{theorem}

\begin{proof}
    We first show that the deviation from the globally optimal response happens before step $L$.
    Then, we show that the conditional probability when generating the token $w_{v_L}$ is bounded away from $1$.

    By definition of oracle LLM (Assumption~\ref{aspt:oracle_LLM}), the advantage of the globally optimal response cannot manifest itself at $L = 1$ (even if the deviation happens at step $1$), i.e., $L > 1$.
    Since the minimum length of prefix-sequence needed in order for the deviation of stepwise optimal response from the same-length globally optimal response to manifest is $L$, then the advantage of the globally optimal response is not manifested until step $L$.
    Until step $L - 1$, in terms of the ground-truth conditional probability following the prompt $X_{\leq 0}$, prefix-sequences of the globally optimal response is \emph{not} strictly preferred compared to their same-length counterparts of the stepwise optimal response:
    \begin{equation}\label{equ:before_manifest}
        \small
        \begin{split}
            f(X_1 = w_{\widehat{\vbf}_T[1]} \mid X_{\leq 0})                             & \geq f(X_1 = w_{\vbf_T^*[1]} \mid X_{\leq 0}),                                                  \\
            f(X_{1:2} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \mid X_{\leq 0}) & \geq f(X_{1:2} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \mid X_{\leq 0}),                              \\
                                                                                         & \cdots                                                                                          \\
            f(X_{1:L-1} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \ldots w_{\widehat{\vbf}_T[L - 1]} \mid X_{\leq 0})
                                                                                         & \geq f(X_{1:L-1} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \ldots w_{\vbf_T^*[L - 1]} \mid X_{\leq 0}).
        \end{split}
    \end{equation}

    Starting from step $L$ and onwards (Assumption~\ref{aspt:no_return_after_detour}), prefix-sequences of the globally optimal response are strictly preferred compared to their counterparts of the stepwise optimal response:
    \begin{equation}\label{equ:after_manifest}
        \small
        \begin{split}
            f(X_{1:L} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]} w_{\widehat{\vbf}_T[L]} \mid X_{\leq 0})
             & < f(X_{1:L} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]} w_{\vbf_T^*[L]} \mid X_{\leq 0}), \\
             & \cdots                                                                                     \\
            f(X_{1:T} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \ldots w_{\widehat{\vbf}_T[T]} \mid X_{\leq 0})
             & < f(X_{1:T} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \ldots w_{\vbf_T^*[T]} \mid X_{\leq 0}).
        \end{split}
    \end{equation}

    Assumption~\ref{aspt:strict_preference} specifies that for any two same-length but different sequences following the prompt $X_{\leq 0}$, there is a strict ordering between them.
    Then, in order for the advantage of the globally optimal length-$T$ response to manifest, in terms of strict preferences staring from the length-$L$ prefix-sequence (\eqnref{equ:after_manifest}), there is \emph{at least one} strict preference of the prefix-sequence of stepwise optimal response over its globally optimal counterpart before step $L$.
    In other words, there is at least one step $K \in [1, L-1]$ such that a strict preference (``$>$'' instead of ``$\geq$'') is present in \eqnref{equ:before_manifest}:
    \begin{equation}\label{equ:step_of_strict_preference}
        \small
        \begin{split}
            % \exists K \in [1, L-1], ~
            f(X_{1:K} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \ldots w_{\widehat{\vbf}_T[K]} \mid X_{\leq 0})
             & > f(X_{1:K} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \ldots w_{\vbf_T^*[K]} \mid X_{\leq 0}).
        \end{split}
    \end{equation}

    In order to see why this is the case, consider the opposite scenario where there is \emph{no} strict preference in \eqnref{equ:before_manifest}.
    Under Assumption~\ref{aspt:strict_preference}, the comparison between prefix-sequences is either strict preference (they are different) or exactly the same (identical sequences).
    If there is no strict preference in \eqnref{equ:before_manifest}, then for all $t \in [1, L-1]$, $w_{\widehat{\vbf}_T[t]} = w_{\vbf_T^*[t]}$, i.e., the first $L-1$ tokens in the stepwise optimal response are the length-$(L - 1)$ prefix of the globally optimal response.
    If this is the case, the token generated at step $L$ has to deviate from the globally optimal response (since $L$ is the minimum length for the deviation to manifest) $w_{\widehat{\vbf}_T[L]} \neq w_{\vbf_T^*[L]}$:
    \begin{equation}\label{equ:opposite_preference}
        \small
        \begin{split}
                               & f(X_{1:L} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]} w_{\widehat{\vbf}_T[L]} \mid X_{\leq 0})          \\
            \overset{(i)}{=}   & g(X_L = w_{\widehat{\vbf}_T[L]} \mid X_{1:L-1} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]}, X_{\leq 0})
            \cdot f(X_{1:L - 1} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]} \mid X_{\leq 0})                                             \\
            \overset{(ii)}{=}  & g(X_L = w_{\widehat{\vbf}_T[L]} \mid X_{1:L-1} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]}, X_{\leq 0})
            \cdot f(X_{1:L - 1} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]} \mid X_{\leq 0})                                                             \\
            \overset{(iii)}{>} & g(X_L = w_{\vbf_T^*[L]} \mid X_{1:L-1} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]}, X_{\leq 0})
            \cdot f(X_{1:L - 1} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]} \mid X_{\leq 0})                                                             \\
            \overset{(iv)}{=}  & f(X_{1:L} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]} w_{\vbf_T^*[L]} \mid X_{\leq 0}),
        \end{split}
    \end{equation}
    where $(i)$ and $(iv)$ follow Assumption~\ref{aspt:oracle_LLM}, $(ii)$ corresponds to the setting in this opposite scenario, and $(iii)$ follows Definition~\ref{def:stepwise_sequence} and that $w_{\widehat{\vbf}_T[L]} \neq w_{\vbf_T^*[L]}$.
    This preference relation in \eqnref{equ:opposite_preference} contradicts with that in \eqnref{equ:after_manifest}, and therefore, \eqnref{equ:step_of_strict_preference} has to hold true.

    Therefore, when the advantage of the globally optimal response does not manifest itself until step $L$, the stepwise optimal response deviates from the globally optimal counterpart at some step $K < L$, and that under Assumption~\ref{aspt:strict_preference}, the following strict preference relations hold true:
    \begin{equation}\label{equ:before_manifest_strict}
        \small
        \begin{split}
            f(X_{1:K} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \ldots w_{\widehat{\vbf}_T[K]} \mid X_{\leq 0})
             & > f(X_{1:K} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \ldots w_{\vbf_T^*[K]} \mid X_{\leq 0}),         \\
             & \cdots                                                                                         \\
            f(X_{1:L - 1} = w_{\widehat{\vbf}_T[1]} w_{\widehat{\vbf}_T[2]} \ldots w_{\widehat{\vbf}_T[L - 1]} \mid X_{\leq 0})
             & > f(X_{1:L - 1} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \ldots w_{\vbf_T^*[L - 1]} \mid X_{\leq 0}).
        \end{split}
    \end{equation}

    This, together with \eqnref{equ:after_manifest} and Assumption~\ref{aspt:oracle_LLM}, indicates that:
    \begin{equation}
        \small
        \begin{split}
                               & g(X_L = w_{\widehat{\vbf}_T[L]} \mid X_{1:L-1} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]}, X_{\leq 0})                                                                                            \\
            \overset{(i)}{=}   & \frac{f(X_{1:L} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]} w_{\widehat{\vbf}_T[L]} \mid X_{\leq 0})}{f(X_{1:L - 1} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]} \mid X_{\leq 0})} \\
            \overset{(ii)}{<}  & \frac{f(X_{1:L} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]} w_{\vbf_T^*[L]} \mid X_{\leq 0})}{f(X_{1:L - 1} = w_{\widehat{\vbf}_T[1]} \ldots w_{\widehat{\vbf}_T[L - 1]} \mid X_{\leq 0})} = \epsilon_L            \\
            \overset{(iii)}{<} & \frac{f(X_{1:L} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]} w_{\vbf_T^*[L]} \mid X_{\leq 0})}{f(X_{1:L - 1} = w_{\vbf_T^*[1]} w_{\vbf_T^*[2]} \ldots w_{\vbf_T^*[L - 1]} \mid X_{\leq 0})}                         \\
            \overset{(iv)}{=}  & g(X_L = w_{\vbf_T^*[L]} \mid X_{1:L-1} = w_{\vbf_T^*[1]} \ldots w_{\vbf_T^*[L - 1]}, X_{\leq 0}) \leq 1,
        \end{split}
    \end{equation}
    where $(i)$ and $(iv)$ follow Assumption~\ref{aspt:oracle_LLM}, $(ii)$ follows \eqnref{equ:after_manifest}, and $(iii)$ follows \eqnref{equ:before_manifest_strict}.

    Therefore, the conditional probability of generating any $w_{v_L}$ is strictly smaller than a positive number $\epsilon_L$, which is further strictly smaller than a positive number upper-bounded by $1$.
\end{proof}







% \section{Performance across all subsets of MMLU}


% % \input{file/tables/table6}
% % \appendix
% \renewcommand{\thetable}{A1}


% \begin{table*}[t]
%     \centering
%     \caption{Model Accuracy by Subject Category on MMLU Using Different Methods}
%     \label{tab:fullresult}
%     \begin{tabular}{lccc}
%     \toprule
%     \textbf{Category} & \textbf{Greedy (\%)} & \textbf{Beam Search (\%)} & \textbf{Ours (\%)} \\
%     \midrule
%     abstract\_algebra & 47.00 & 46.00 & 47.00 \\
%     anatomy & 67.40 & 74.07 & 72.59 \\
%     astronomy & 80.92 & 73.02 & 80.26 \\
%     business\_ethics & 66.00 & 68.00 & 64.00 \\
%     clinical\_knowledge & 76.22 & 76.60 & 78.11 \\
%     college\_biology & 83.33 & 80.55 & 79.86 \\
%     college\_chemistry & 56.00 & 53.00 & 57.00 \\
%     college\_computer\_science & 55.00 & 63.00 & 58.00 \\
%     college\_mathematics & 35.00 & 47.00 & 36.00 \\
%     college\_medicine & 69.36 & 65.89 & 68.78 \\
%     college\_physics & 64.70 & 69.61 & 61.76 \\
%     computer\_security & 73.00 & 78.00 & 77.00 \\
%     conceptual\_physics & 68.93 & 69.78 & 69.78 \\
%     econometrics & 56.14 & 58.77 & 57.89 \\
%     electrical\_engineering & 58.62 & 64.82 & 61.37 \\
%     elementary\_mathematics & 88.09 & 88.62 & 89.41 \\
%     formal\_logic & 50.00 & 50.79 & 51.58 \\
%     global\_facts & 43.00 & 45.00 & 50.00 \\
%     high\_school\_biology & 79.03 & 80.96 & 80.32 \\
%     high\_school\_chemistry & 62.07 & 67.98 & 63.05 \\
%     high\_school\_computer\_science & 81.00 & 79.00 & 79.00 \\
%     high\_school\_european\_history & 76.36 & 75.15 & 75.15 \\
%     high\_school\_geography & 78.79 & 80.81 & 78.79 \\
%     high\_school\_government\_and\_politics & 88.60 & 86.53 & 88.08 \\
%     high\_school\_macroeconomics & 69.74 & 74.62 & 68.97 \\
%     high\_school\_mathematics & 64.44 & 68.89 & 68.52 \\
%     high\_school\_microeconomics & 75.63 & 76.05 & 77.33 \\
%     high\_school\_physics & 54.97 & 54.97 & 57.62 \\
%     high\_school\_psychology & 85.32 & 88.07 & 86.24 \\
%     high\_school\_statistics & 62.96 & 60.19 & 62.96 \\
%     high\_school\_us\_history & 83.33 & 80.88 & 80.39 \\
%     high\_school\_world\_history & 78.90 & 80.59 & 76.79 \\
%     human\_aging & 63.68 & 66.82 & 62.78 \\
%     human\_sexuality & 52.67 & 60.31 & 53.44 \\
%     international\_law & 80.17 & 80.17 & 77.69 \\
%     jurisprudence & 72.22 & 74.07 & 76.85 \\
%     logical\_fallacies & 78.53 & 78.53 & 79.14 \\
%     machine\_learning & 56.25 & 61.61 & 53.57 \\
%     nutrition & 73.86 & 75.82 & 76.47 \\
%     us\_foreign\_policy & 84.00 & 80.00 & 81.00 \\
%     public\_relations & 64.55 & 66.36 & 65.45 \\
%     world\_religions & 83.04 & 79.53 & 82.46 \\
%     professional\_accounting & 51.42 & 53.98 & 51.06 \\
%     security\_studies & 62.45 & 66.12 & 63.27 \\
%     professional\_law & 49.86 & 51.54 & 53.50 \\
%     professional\_psychology & 68.63 & 68.95 & 68.46 \\
%     prehistory & 70.37 & 72.22 & 70.37 \\
%     professional\_medicine & 79.41 & 79.78 & 79.78 \\
%     sociology & 74.63 & 77.11 & 73.63 \\
%     philosophy & 73.06 & 68.49 & 71.40 \\
%     virology & 48.19 & 47.59 & 49.40 \\
%     marketing & 88.03 & 84.18 & 87.17 \\
%     medical\_genetics & 77.00 & 79.00 & 75.00 \\
%     miscellaneous & 86.97 & 87.73 & 87.61 \\
%     moral\_disputes & 67.34 & 66.76 & 64.16 \\
%     moral\_scenarios & 45.47 & 48.72 & 47.03 \\
%     \bottomrule
%     \end{tabular}
% \end{table*}


% \color{blue}  % begin add-on

% \section{Parameter Analysis \& Qualitative Results}


% \begin{table*}[h]
%     \centering
% \caption{Performance Comparison of Different Methods by Mistral-Nemo on MMLU Social Science}
% \label{tab:mistral-social-science}
% \begin{tabular}{lccc}
% \toprule
% \textbf{Category} & \textbf{Greedy} & \textbf{Beam Search} & \textbf{Ours} \\
% \midrule
% Econometrics & 53.51 & 56.14 & \textbf{59.65} \\
% High School Geography & 78.79 & 77.78 & \textbf{79.80} \\
% High School Government and Politics & 87.56 & 87.05 & \textbf{88.08} \\
% High School Macroeconomics & \textbf{74.61} & 74.09 & 73.83 \\
% High School Microeconomics & 71.24 & \textbf{73.39} & \textbf{73.39} \\
% High School Psychology & \textbf{67.16} & 66.01 & 66.50 \\
% Human Sexuality & 66.41 & 64.89 & \textbf{70.99} \\
% Professional Psychology & \textbf{67.16} & 66.01 & 66.50 \\
% Public Relations & 59.26 & \textbf{63.89} & 56.48 \\
% Sociology & 76.62 & \textbf{82.09} & 74.63 \\
% Security Studies & 57.38 & 54.10 & \textbf{59.02} \\
% US Foreign Policy & \textbf{77.00} & 76.00 & \textbf{77.00} \\
% \midrule
% Macro Average (\%) & 71.93 & 72.10 & \textbf{72.20} \\
% \bottomrule
% \end{tabular}
% \end{table*}

% \subsection{Analysis on Window Size}

% \begin{table*}[h]
%     \centering
% \caption{Performance Comparison of Different Window Sizes with Llama3.1-8B on MT-Bench}
% \label{tab:llama3-performance}
% \begin{tabular}{lccc}
% \toprule
% \textbf{Method} & \textbf{Rating 1} & \textbf{Rating 2} & \textbf{Overall Mean} \\
% \midrule
% $d=2$ & 8.29 & 7.09 & 7.69 \\
% $d=3$ & 8.35 & 7.51 & 7.93 \\
% $d=4$ & \textbf{8.36} & 7.42 & 7.89 \\
% $d=5$ & 8.31 & \textbf{7.62} &\textbf{7.97} \\
% Greedy Decoding & 8.28 & 7.49 & 7.88 \\
% Beam Search & 8.07 & 7.19 & 7.63 \\
% \bottomrule
% \end{tabular}
% \end{table*}

% \begin{table*}[h]
%     \centering
% \caption{Performance Comparison of Different Window Sizes with Mistral-Nemo on MT-Bench}
% \label{tab:mistral-performance}
% \begin{tabular}{lccc}
% \toprule
% \textbf{Method} & \textbf{Rating 1} & \textbf{Rating 2} & \textbf{Overall Mean} \\
% \midrule
% $d=2$ & 8.38 & 7.28 & 7.82 \\
% $d=3$ & \textbf{8.44} & 7.42 & \textbf{7.93} \\
% $d=4$ & 8.28 & 7.41 & 7.84 \\
% Greedy Decoding & 8.38 & 7.29 & 7.83 \\
% Beam Search & 8.32 & \textbf{7.49} & 7.91 \\
% \bottomrule
% \end{tabular}
% \end{table*}

% \begin{table*}[h]
%    \centering
% \caption{Performance Comparison of Different Window Sizes with Qwen on MMLU Social Science Tasks}
% \label{tab:qwen-social-science}
% \begin{tabular}{lccccc}
% \toprule
% \textbf{Task} & \textbf{d=2} & \textbf{d=3} & \textbf{d=4} & \textbf{d=5} & \textbf{d=6} \\
% \midrule
% Econometrics & 62.28 & 62.28 & \textbf{64.91} & 64.04 & \textbf{64.91} \\
% High School Geography & 85.86 & 84.34 & 86.36 & \textbf{87.37} & 85.86 \\
% High School Government and Politics & \textbf{93.26} & \textbf{93.26} & 92.23 & 91.19 & 92.23 \\
% High School Macroeconomics & 75.90 & \textbf{76.15} & 75.13 & \textbf{76.15} & 75.64 \\
% High School Microeconomics & 83.61 & \textbf{84.03} & 83.61 & 82.77 & 83.19 \\
% High School Psychology & 87.89 & 88.07 & 88.07 & 88.07 & \textbf{88.26} \\
% Human Sexuality & 77.86 & 75.57 & 78.63 & \textbf{79.39} & 77.86 \\
% Professional Psychology & \textbf{73.86} & 73.37 & 73.20 & 72.88 & 73.37 \\
% Public Relations & 68.18 & \textbf{70.00} & \textbf{70.00} & 65.45 & 68.18 \\
% Sociology & 71.02 & 73.06 & \textbf{73.47} & 72.24 & 73.06 \\
% Security Studies & 83.08 & 83.58 & 83.08 & 84.08 & \textbf{84.58} \\
% US Foreign Policy & 86.00 & 86.00 & 86.00 & 86.00 & \textbf{88.00} \\
% \midrule
% Macro Average & 79.66 & 79.75 & 79.82 & 79.62 & \textbf{79.88} \\
% \bottomrule
% \end{tabular}
% \end{table*}



% \subsection{Analysis on Threshold}

% \begin{table*}[h]
%    \centering
% \caption{Performance Comparison of Different $\sigma$ Values on MMLU Social Science Tasks}
% \label{tab:sigma-social-science}
% \begin{tabular}{lccccc}
% \toprule
% \textbf{Task} & \textbf{$\sigma$=0.1} & \textbf{$\sigma$=0.25} & \textbf{$\sigma$=0.5} & \textbf{$\sigma$=0.75} & \textbf{$\sigma$=1.0} \\
% \midrule
% Econometrics & 62.28 & \textbf{64.91} & \textbf{64.91} & \textbf{64.91} & \textbf{64.91} \\
% High School Geography & \textbf{92.23} & 91.71 & \textbf{92.23} & \textbf{92.23} & 91.19 \\
% High School Government and Politics & \textbf{92.23} & 91.71 & \textbf{92.23} & \textbf{92.23} & 91.19 \\
% High School Macroeconomics & 75.13 & \textbf{76.67} & 75.13 & 75.90 & 75.90 \\
% High School Microeconomics & \textbf{84.45} & \textbf{84.45} & 83.61 & 83.19 & 83.61 \\
% High School Psychology & 87.52 & \textbf{88.44} & 88.07 & 88.26 & 88.07 \\
% Human Sexuality & 74.05 & 77.86 & \textbf{78.63} & 77.10 & 77.10 \\
% Professional Psychology & 73.20 & \textbf{74.35} & 73.20 & 73.20 & 73.04 \\
% Public Relations & 69.09 & \textbf{70.00} & \textbf{70.00} & 67.27 & 67.27 \\
% Sociology & 84.58 & \textbf{85.07} & 83.08 & 84.58 & 84.58 \\
% Security Studies & 72.24 & 71.43 & \textbf{73.47} & 72.24 & 72.24 \\
% US Foreign Policy & \textbf{86.00} & 85.00 & 85.00 & 85.00 & \textbf{87.00} \\
% \midrule
% Macro Average & 79.40 & \textbf{80.31} & 79.82 & 79.88 & 79.69 \\
% \bottomrule
% \end{tabular}
% \end{table*}

% \subsection{Concrete Example of MT-Bench}

% \color{black}