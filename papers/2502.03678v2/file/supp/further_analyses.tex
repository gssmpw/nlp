\section{Additional Results and Analyses}
In this section, we present additional results and further discussions on influences from hyperparameters.
We also provide concrete examples demonstrating the process and overall performance of our reflection-window decoding.

\subsection{Analysis on Window Size $d$}
We conduct extensive experiments on MT-Bench to analyze the impact of window size using both Mistral-Nemo (Table~\ref{tab:mistral_mtbench_per_d}) and Llama3.1-8B (Table~\ref{tab:llama31_mtbench_per_d}), with a fixed pausing criterion with $\sigma=0.5$.
These GPT-4o evaluator scores on MT-Bench provide additional evidence that our approach consistently outperforms traditional decoding methods.

For Mistral-Nemo, the optimal performance is achieved at $d=3$ with an overall score of 7.93, surpassing both greedy decoding and beam search.
For Llama3.1-8B, our method consistently outperforms both greedy decoding and beam search across different window sizes, with $d=5$ achieving the best overall performance.
While $d=4$ may not always yield the best result, it demonstrates robust performance across both models and serves as a reliable default setting.

We further evaluate how different window sizes affect the performance on MMLU social science tasks using Qwen2.5-7B.
The results are presented in Table~\ref{tab:qwen_mmlu_social_science_per_d}.
%, confirming its effectiveness beyond the human evaluations presented in the main text.

\begin{table*}[t]
    \centering
    \caption{Performance across different window sizes $d$ on MT-Bench with Mistral-Nemo}
    \label{tab:mistral_mtbench_per_d}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Decoding Method}  & \textbf{Rating 1} & \textbf{Rating 2} & \textbf{Overall Mean} \\
        \midrule
        Reflection-Window ($d=2$) & 8.38              & 7.28              & 7.82                  \\
        Reflection-Window ($d=3$) & \textbf{8.44}     & 7.42              & \textbf{7.93}         \\
        Reflection-Window ($d=4$) & 8.28              & 7.41              & 7.84                  \\
        Greedy Decoding           & 8.38              & 7.29              & 7.83                  \\
        Beam Search               & 8.32              & \textbf{7.49}     & 7.91                  \\
        \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}[t]
    \centering
    \caption{Performance across different window sizes $d$ on MT-Bench with Llama3.1-8B}
    \label{tab:llama31_mtbench_per_d}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Decoding Method}  & \textbf{Rating 1} & \textbf{Rating 2} & \textbf{Overall Mean} \\
        \midrule
        Reflection-Window ($d=2$) & 8.29              & 7.09              & 7.69                  \\
        Reflection-Window ($d=3$) & 8.35              & 7.51              & 7.93                  \\
        Reflection-Window ($d=4$) & \textbf{8.36}     & 7.42              & 7.89                  \\
        Reflection-Window ($d=5$) & 8.31              & \textbf{7.62}     & \textbf{7.97}         \\
        Greedy Decoding           & 8.28              & 7.49              & 7.88                  \\
        Beam Search               & 8.07              & 7.19              & 7.63                  \\
        \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}[h]
    \centering
    \caption{Accuracy ($\%$) across different window sizes $d$ on MMLU Social Sciences with Qwen2.5-7B}
    \label{tab:qwen_mmlu_social_science_per_d}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Subject}                    & $d=2$   & $d=3$   & $d=4$   & $d=5$   & $d=6$   \\
        \midrule
        Econometrics                        & 62.28          & 62.28          & \textbf{64.91} & 64.04          & \textbf{64.91} \\
        High School Geography               & 85.86          & 84.34          & 86.36          & \textbf{87.37} & 85.86          \\
        High School Government and Politics & \textbf{93.26} & \textbf{93.26} & 92.23          & 91.19          & 92.23          \\
        High School Macroeconomics          & 75.90          & \textbf{76.15} & 75.13          & \textbf{76.15} & 75.64          \\
        High School Microeconomics          & 83.61          & \textbf{84.03} & 83.61          & 82.77          & 83.19          \\
        High School Psychology              & 87.89          & 88.07          & 88.07          & 88.07          & \textbf{88.26} \\
        Human Sexuality                     & 77.86          & 75.57          & 78.63          & \textbf{79.39} & 77.86          \\
        Professional Psychology             & \textbf{73.86} & 73.37          & 73.20          & 72.88          & 73.37          \\
        Public Relations                    & 68.18          & \textbf{70.00} & \textbf{70.00} & 65.45          & 68.18          \\
        Sociology                           & 71.02          & 73.06          & \textbf{73.47} & 72.24          & 73.06          \\
        Security Studies                    & 83.08          & 83.58          & 83.08          & 84.08          & \textbf{84.58} \\
        US Foreign Policy                   & 86.00          & 86.00          & 86.00          & 86.00          & \textbf{88.00} \\
        \midrule
        Macro Average                       & 79.66          & 79.75          & 79.82          & 79.62          & \textbf{79.88} \\
        \bottomrule
    \end{tabular}
\end{table*}


\clearpage
\subsection{Analysis on Threshold $\sigma$}
We investigate the impact of threshold $\sigma$ on MMLU social science subjects using Qwen2.5-7B with a fixed window size $d=4$.
The detailed results are presented in Table~\ref{tab:qwen_mmlu_social_science_per_sigma}.

% demonstrate that our method performs robustly across $\sigma$ values ranging from 0.25 to 0.75, with $\sigma=0.25$ achieving the highest macro average of 80.31\%. While our default setting of $\sigma=0.5$ is not the absolute best in this specific experiment, it maintains strong performance and shows consistent improvements across most tasks, suggesting it serves as a reliable default configuration for general use.


% \renewcommand{\thetable}{A5}
\begin{table*}[h]
    \centering
    \caption{Accuracy ($\%$) across different entropy thresholds $\sigma$ on MMLU Social Sciences with Qwen2.5-7B}
    \label{tab:qwen_mmlu_social_science_per_sigma}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Subject}                    & $\sigma=0.1$ & $\sigma=0.25$ & $\sigma=0.5$ & $\sigma=0.75$ & $\sigma=1.0$ \\
        \midrule
        Econometrics                        & 62.28                 & \textbf{64.91}         & \textbf{64.91}        & \textbf{64.91}         & \textbf{64.91}        \\
        High School Geography               & \textbf{92.23}        & 91.71                  & \textbf{92.23}        & \textbf{92.23}         & 91.19                 \\
        High School Government and Politics & \textbf{92.23}        & 91.71                  & \textbf{92.23}        & \textbf{92.23}         & 91.19                 \\
        High School Macroeconomics          & 75.13                 & \textbf{76.67}         & 75.13                 & 75.90                  & 75.90                 \\
        High School Microeconomics          & \textbf{84.45}        & \textbf{84.45}         & 83.61                 & 83.19                  & 83.61                 \\
        High School Psychology              & 87.52                 & \textbf{88.44}         & 88.07                 & 88.26                  & 88.07                 \\
        Human Sexuality                     & 74.05                 & 77.86                  & \textbf{78.63}        & 77.10                  & 77.10                 \\
        Professional Psychology             & 73.20                 & \textbf{74.35}         & 73.20                 & 73.20                  & 73.04                 \\
        Public Relations                    & 69.09                 & \textbf{70.00}         & \textbf{70.00}        & 67.27                  & 67.27                 \\
        Sociology                           & 84.58                 & \textbf{85.07}         & 83.08                 & 84.58                  & 84.58                 \\
        Security Studies                    & 72.24                 & 71.43                  & \textbf{73.47}        & 72.24                  & 72.24                 \\
        US Foreign Policy                   & \textbf{86.00}        & 85.00                  & 85.00                 & 85.00                  & \textbf{87.00}        \\
        \midrule
        Macro Average                       & 79.40                 & \textbf{80.31}         & 79.82                 & 79.88                  & 79.69                 \\
        \bottomrule
    \end{tabular}
\end{table*}

\subsection{Analysis on Regeneration Ratio}
To further understand the computational efficiency of our method, we analyze the regeneration ratio under different window size settings.
We select six college-level subject categories from the MMLU test set (including biology, chemistry, computer science, mathematics, medicine, and physics) for analysis, and conduct experiments with the Llama3.1-8B model with a threshold of $\sigma=0.5$.
We consider the window size $d$ as the key hyperparameter, because it directly influences the regeneration ratio, which is calculate by the product of the times criterion get triggered (the regeneration call) and the window size ($d$), divided by the total length of final response.

As shown in Table \ref{tab:regeneration_ratio} and Figure~\ref{fig:regeneration_ratio}, as the window size increases from 2 to 4, the average regeneration ratio shows a clear downward trend, decreasing from $9.60\%$ to $3.70\%$.
The trend indicates that larger window sizes lead to a faster decrease in the number of modifications needed.
Notably, across all settings, the regeneration ratio remains below $15\%$, suggesting that our method maintains comparable computational workload as greedy decoding for the majority of the time.
These results demonstrate the efficiency of our approach, since it only invoke beam search to find optimal approximations for sub-sequences when necessary, while maintaining the overall efficiency comparable to greedy decoding.

\begin{table}[h]
    \centering
    \caption{Average regeneration ratio by window sizes $d$ on MMLU college-level subjects with Llama3.1-8B}
    \label{tab:regeneration_ratio}
    \begin{tabular}{lccc}
        \toprule
        Window Size $d$          & 2    & 3    & 4             \\
        \midrule
        Average Regeneration Ratio ($\%$) & 9.60 & 6.02 & \textbf{3.70} \\
        \bottomrule
    \end{tabular}
\end{table}
% \renewcommand{\thefigure}{A6}
\begin{figure}[h]
    \centering
    \includegraphics[height=35ex]{file/figures/regeneration_ratio.pdf}
    \caption{Regeneration ratio on MMLU college-level subjects with Llama3.1-8B}
    \label{fig:regeneration_ratio}
\end{figure}


\newpage
\subsection{Demonstrative Examples on MT-Bench}
In this subsection, we present three examples selected from MT-Bench to illustrate the generation process in our reflection-window decoding.
The first example is the 28th test sample from MT-Bench.
As is shown in Figure~\ref{fig:demo1}, the pausing criterion gets triggered when \textit{``part of the car"} was generated.
The part gets refined and replaced by \textit{``specific part, whereas"} which leads to a more flexible and natural answer.
Figure~\ref{fig:demo2} and Figure~\ref{fig:demo3} are selected from the 29th and 7th test sample of MT-Bench, respectively.

% \renewcommand{\thefigure}{A7}
\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{file/figures/Demo_1.pdf}  % Adjust the width as needed
    \caption{Test Sample \#28}  % Caption for the figure
    \label{fig:demo1}  % Label for referencing the figure in the text
\end{figure}
% \renewcommand{\thefigure}{A8}
\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{file/figures/demo_2.pdf}  % Adjust the width as needed
    \caption{Test Sample \#29}  % Caption for the figure
    \label{fig:demo2}  % Label for referencing the figure in the text
\end{figure}
% \renewcommand{\thefigure}{A9}
\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{file/figures/demo_3.pdf}  % Adjust the width as needed
    \caption{Test Sample \#7}  % Caption for the figure
    \label{fig:demo3}  % Label for referencing the figure in the text
\end{figure}
\color{black}