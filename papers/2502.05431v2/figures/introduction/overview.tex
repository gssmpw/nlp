\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{figures/introduction/overview_.pdf}
    \caption{
    \textbf{Overview of Our Approach.} Context-augmented generation leverages additional contexts to improve LLM response quality to user queries. 
    Sequential encoding prefills selected context chunks as a long sequence during inference, leading to high latency from on-the-fly re-encoding and low accuracy due to context window limitations.
    Parallel encoding offers an alternative method to pre-compute more and longer contexts within the same positional range but results in worse performance.
    To address these challenges, we propose \underline{A}daptive \underline{P}arallel \underline{E}ncoding (\textbf{APE}) to re-align the attention weight distribution of parallel encoding with sequential encoding via three training-free steps: shared prefix, scaling factor, and adaptive temperature, leading to fast and accurate CAG systems in real-world applications.}
    \label{fig:intro}
\end{figure}