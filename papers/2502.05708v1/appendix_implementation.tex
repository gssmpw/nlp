\section{Network Architecture}\label{appendix_network}

Figure~\ref{fig_tran_view} illustrates the architecture of our wireless scene representation module. 
It comprises a ResNet-18 feature encoder~\cite{he2016deep}, geometry embedding, a geometry-aware Transformer encoder with a cross-attention mechanism~\cite{gheini2021cross}, and two MLP networks.


\begin{figure*}[t]
\centering
{\includegraphics[width=.9\textwidth]{figs/transformer_location_v6.pdf}}
\caption{Architecture of geometry-aware wireless scene representation module, consisting of a ResNet feature extractor, geometry embedding, a Transformer encoder, and two MLPs, where a circle with a plus symbol signifies concatenation.}
	\label{fig_tran_view}
\end{figure*}




To extract compact spectral features from the neighboring spectra, we utilize a ResNet-18 encoder with filter settings of 64, 128, 256, and 512~\cite{he2016deep}.
Both the wireless scene representation and the neural-driven ray tracing algorithm are implemented with a Transformer-based architecture.
A typical Transformer consists of multiple stacked blocks; each block contains an attention layer, followed by a residual connection from the input to the post-attention layer, and then layer normalization (LayerNorm).
Subsequently, a Feed-Forward Network (FFN) with Rectified Linear Unit (ReLU) activation is applied.
This is followed by another residual connection from the output of the first LayerNorm to the output of the ReLU, and the sequence concludes with a second LayerNorm.



The Transformers in both the wireless scene representation and the ray tracing algorithm consist of two stacked blocks, each with a hidden dimension of 16, matching the voxel latent feature dimension \( d \). 
However, there are two key differences between these two Transformers. 
First, the attention mechanisms differ. 
The scene representation module incorporates a single-headed cross-attention layer, as described in Equation~(\ref{eqn_cross_att}), while the ray tracing Transformer uses a multi-headed self-attention layer, as detailed in Equation~(\ref{eqn_qkv}).
Second, the handling of token sequential information varies. 
In the scene representation module, the sequential order of spectrum features is not critical, as the focus lies in the differences between pairs of features. 
Therefore, the index of the spectrum features is not considered. 
On the other hand, in the ray tracing algorithm, the sequential information of voxels along a ray is essential, as it directly impacts the calculation of attention weights. 
Therefore, the index of each voxel along the ray is incorporated.


