\section{Related Work}
\label{related work Section}
\subsection{Text Detection \& Line Segmentation}
Previously the scene text detection process consisted of two stages, the first was to locate the characters or components, second was to group them into words. Neumann and Matas (\hyperref[Neumann2012]{Neumann et al.,2012}) made an end-to-end solution for text localization and recognition by two different stages in the first classification stage to calculate the  probability of each
ER being a character calculated using novel features calculated with O(1) complexity per region tested then choose the ERs with local maximum probability to pass it to the second stage that has improved in classification using more computationally expensive features. A highly efficient exhaustive search with feedback loops is then applied to group ERs into words and to select the most probable character segmentation. Jaderberg (\hyperref[Jaderberg2016]{Jaderberg et al.,2016}) made an end-to-end text spotting pipeline proposed with these stages: a) A combination of region proposal methods extracts many word bounding box proposals. b) Proposals are filtered with a random forest classifier reducing the number of false-positive detections. c) A CNN performs bounding box regression to refine the proposals. d) A CNN performs text recognition on each of the refined proposals. e) Detections are merged based on proximity and recognition results, and a score is assigned. f) Thresholding the detections results in the final text spotting result. Epshtein et al (\hyperref[Epshtein2010]{Epshtein et al.,2010}) uses an enhanced version of the Stroke Width Transform to find letter candidates and group letters into the region of text.\\
Newly, deep learning has dominated the scene text detection area. The deep-learning-based scene text detection methods are classified into many categories according to the granularity of the predicted target The most important of them are: part-based methods, regression-based methods, Sequence-Based methods, and segmentation-based methods.\\
Part-based methods first detect small parts by breaking the text into small parts characters or sub-regions then combine them into word or line-bounding boxes. Shi (\hyperref[Shi2017]{Shi et al.,2017}) introduce Segment Linking (SegLink) the core concept is to break down the text into two locally identifiable components: segments and links. A segment is an oriented box that refers to a part of a word or text line; a link connects two neighboring segments, signifying that they are part of the same word or text line. Both components are detected densely across various scales using an end-to-end trained, fully-convolutional neural network. The final detections are generated by merging segments that are connected by links. Tang (\hyperref[Tang2019]{Tang et al.,2019}) has overcome the difficulty in handling curved and dense texts in (\hyperref[Shi2017]{Shi et al.,2017}) by instance-aware component grouping (ICG) algorithm which is a flexible bottom-up method. To tackle the challenge of distinguishing between dense text instances that many bottom-up methods encounter, we introduce an attractive and repulsive link between text components that encourages the network to concentrate more on nearby text instances, along with instance-aware loss that Optimally uses the context to guide the network effectively. Despite the Part-based method's effectiveness, it requires a lot of complexity and time to link between text components also it may face problems with text variation in size or shape which makes them hard to tune.\\
regression-based methods are a series of models that predict the bounding boxes directly using regression. Liao (\hyperref[Liao2017]{Liao et al.,2017}) design TextBoxes that consist of an end-to-end trainable neural network model for scene text detection. Secondly, propose a word spotting/end-to-end recognition framework that effectively combines detection and recognition. Thirdly, designing a model
achieves highly competitive results while keeping its computational efficiency. Liao (\hyperref[Liao2018]{Liao et al.,2018}) designed TextBoxes++ which directly predicts arbitrary-oriented word bounding boxes by quadrilateral regression to achieve state-of-the-art performance with high efficiency for both horizontal and oriented text. Liao (\hyperref[Liao2018+]{Liao et al.,2018}) uses a method called Rotation sensitive Regression Detector (RRD) Which consists of two network branches of different designs. Concretely, the regression branch extracts rotation-sensitive features by actively rotating the
convolutional filters, while the classification branch extracts rotation-invariant features by pooling the rotation-sensitive features these methods achieve state-of-the-art performance on multi-oriented and long text instances. He (\hyperref[He2017]{He et al.,2017}) uses a text attention mechanism to make an accurate text detector that predicts word-level bounding boxes in one shot. Zhou (\hyperref[Zhou2017]{Zhou et al.,2017}) developed a pipeline that uses pixel-level regression that directly predicts words or text lines of various orientations and quadrilateral forms within complete images, removing the need for redundant intermediate processes (such as candidate aggregation and word segmentation), using a single neural network. Xie (\hyperref[Xie2019]{Xie et al.,2019}) present a novel dimension-decomposition region proposal network (DeRPN) that utilizes an anchor string mechanism to independently match object
widths and heights, which is conducive to treating variant object shapes by preventing the small items from being overshadowed by the larger ones. Despite the efficiency of the regression-based method, It has difficulty handling complex, nonlinear data, is affected by outliers, and relies on the assumptions of independence, homoscedasticity, and normality, which may not be applicable in numerous real-world situations.\\
Sequence-based methods typically detect text by dealing with them as a sequence of characters or word parts. Xie (\hyperref[Kantipudi2021]{Kantipudi et al.,2021}) This research paper proposed an approach for scene text recognition that integrates bidirectional LSTM and deep convolution neural networks. In the proposed method, first, the contour of the image is identified, and then, it is fed into the CNN. CNN is used to generate the ordered sequence of the features from the contoured image. The sequence of features is now coded using the Bi-LSTM. Bi-LSTM is a handy tool for extracting the features from the sequence of words. Thus, this paper combines the two powerful mechanisms for extracting the features from the image and contour-based input image making the recognition process faster. Despite the Sequence-based method's effectiveness, it requires a lot of complexity and time to use LSTMs, GRUs, or Transformers also depends on the order of entered data which makes it very hard to use.
\\
Segmentation-based methods typically merge pixel-wise prediction with post-processing techniques to obtain the bounding boxes. Zhang (\hyperref[Zhang2016]{Zhang et al.,2016}) presented a novel framework for multioriented scene text detection. The main idea that integrates semantic labeling by FCN and MSER provides a natural solution for handling horizontal and multi-oriented text. Wang (\hyperref[Wang2019]{Wang et al.,2019}) proposes a new method called Progressive Scale Expansion Network (PSENet), which can precisely detect text instances with arbitrary shapes. By generating different scales of kernels for each text instance and gradually expanding the minimal scale kernel to the text instance with the complete shape. Xue (\hyperref[Xue2018]{Xue et al.,2018}) introduces a scene text detection method that utilizes semantics-aware text borders and a bootstrapping approach for augmenting text segments. By incorporating semantics-aware text boundaries, the technique significantly enhances the accuracy of localizing text borders with varying meanings. Additionally, the augmented text line segments contribute to a more consistent output of predicted feature maps, resulting in more comprehensive and intact scene text detections. Tian (\hyperref[Tian2019]{Tian et al.,2019}) designed a method that maps pixels onto an embedding space where pixels belonging to the same text are encouraged to appear closer to each other and vice versa to make pixels appear in clusters. Our approach emphasizes enhancing segmentation outcomes by integrating the binarization process during the training phase, all while maintaining inference speed.\\
Most fast-scene text detection methods can not deal with text instances of irregular shapes,
such as curved shapes. Compared to the previous fast scene text detectors, our method not only runs faster but also can detect text instances of arbitrary shapes. Our proposed approach performs more accurately and more efficiently owing to the simple and efficient differentiable binarization algorithm.



\subsection{Optical Character Recognition}
Arabic handwritten text recognition is a particular challenge due to the cursive nature of the script, contextual letter forms, and the small amount of labeled datasets. In the last couple of decades, research has evolved from handcrafted feature-based systems to sophisticated deep learning architectures, driven by the availability of increased computational power and datasets. Below, we survey key methodologies, datasets, and architectural innovations in Arabic Handwritten Text Recognition.


Early AHTR systems relied on manual feature extraction and statistical models.(\hyperref[AlHajj2009]{Al-Hajj et al., 2009})
 combined structural features, such as loops and diacritics, with HMMs to achieve 92.1\% character accuracy on a proprietary dataset. Similarly, (\hyperref[Elzobi2013]{Elzobi et al. 2013}) used Gabor filters to capture texture-based features on the IFN/ENIT dataset (\hyperref[Pechwitz2002]{Pechwitz et al., 2002}), which is a benchmark of 26,459 handwritten Tunisian town names, training SVMs thereon. While these achieved a certain degree of success, their explicit-segmentation reliance and sensitivity to intra-writer variability limited the generalization capabilities.



Deep learning changed the paradigm towards E2E systems. \hyperref[Graves2009]{Graves et al. (2009)} pioneered the CNN-BLSTM-CTC architecture, where a CNN for spatial feature extraction is combined with a BLSTM network for sequence modeling and CTC for label alignment. This framework is particularly effective for cursive scripts like Arabic. \hyperref[Fasha2020]{Fasha et al. (2020)} adopted this architecture for the KHATT dataset \hyperref[Mahmoud2014]{(Mahmoud et al., 2014)}, reporting 80.02\% CRR for unconstrained paragraphs. The work stressed that BLSTMs are essential for modeling bidirectional contextual dependencies, especially because Arabic is written from right to left.

In the area of Arabic handwritten text recognition, several milestones have been achieved. \hyperref[Fasha2020]{Fasha et al. (2020)} presented the Arabic Multi-Fonts Dataset (AMFDS), a synthetically generated corpus that contains 2 million word images in 18 different fonts. The paper employed a CNN-BLSTM-CTC model, trained on this dataset and yielding an 85.15\% CRR on unseen data, proof that synthetic data can help in solving real-life problems suffering from labeled sample scarcity. However, their model gave way to difficulty for some ligatures and intersecting strokes that are very normal in handwritten Arabic texts.

In another similar study, \hyperref[Waly2024]{Waly et al. (2024)} presented an end-to-end OCR system for Arabic handwritten documents. Authors proposed a methodology that included Differentiable Binarization and Adaptive Scale Fusion for improving the accuracy of text segmentation. The AMFDS achieved a CRR of 99.20\% and a WRR of 93.75\% on single-word samples containing 7 to 10 characters, as well as a CRR of 83.76\% for sentences. These results underpin the robustness of the AMFDS for training models on high-accuracy recognition tasks.

Hybrid models and data augmentation techniques are some other methods that have been tried to increase the recognition rate.\hyperref[Gresha2023]{Gresha et al. (2023)} propose a hybrid deep learning approach for handwritten Arabic text recognition, using a combination of CNNs with Bidirectional Recurrent Neural Networks, specifically Bidirectional Long Short-Term Memory (Bi-LSTM) and Bidirectional Gated Recurrent Units (Bi-GRU). This model combines the power of capturing spatial features with that of modeling temporal dynamics and contextual relationships in handwritten Arabic text.

Following this, experiments on the Arabic Handwritten Character Dataset(AHCD)  and the Hijjaa benchmark datasets were conducted to demonstrate the effectiveness of the proposed hybrid models. In fact, for the very first time, the CNN-Bi-GRU framework outperformed state-of-the-art accuracy rates at 97.05\% and 91.78\% on the AHCD and Hijjaa datasets, respectively, compared with already proposed deep learning-based methods. These results emphasize the notable performance increase due to the incorporation of specialized temporal modeling and contextual representation capabilities within the handwriting recognition pipeline with no explicit segmentation.

Besides, it has also generated some promise regarding data augmentation with the integration of GANs. A work by \hyperref[Gresha2023]{Gresha et al. (2023)} integrated GANs within a CNN-BLSTM architecture for Arabic handwritten recognition and reported a recognition rate of 95.23\% on the \hyperref[Pechwitz2002]{Pechwitz2002}. This approach showed that GANs could generate realistic synthetic samples effectively to augment the training dataset and thus improve model performance.
The attention mechanism has contributed much to the evolution of Arabic Handwritten Text Recognition. It helps the network give more attention to the pertinent region within the text. Introduced for neural machine translation by \hyperref[Bahdanau2015]{Bahdanau et al. (2015)}, it finds applications in many domains such as OCR.

\hyperref[Gader2022]{Gader and Echi (2022)} proposed an attention-based CNN-ConvLSTM model for extracting handwritten Arabic words. The developed approach succeeded in extracting words at a rate of 91.7\% in the \hyperref[Khatt2016]{KHATT dataset}, demonstrating in this way how attention mechanisms improved recognition accuracy.


The Transformer model, first proposed by \hyperref[Vaswani2017]{Vaswani et al. (2017)}, has drastically improved several aspects of NLP through its self-attention mechanism, which efficiently captured long-range dependencies. For AHTR, the transformer models were used to handle the sequential nature of the handwriting without recourse to any form of recurrent architecture.


\hyperref[Momeni2023]{Momeni and BabaAli (2023)} proposed a transformer-based model for offline Arabic handwritten text recognition. The methodology has utilized the self-attention mechanism of transformers, which is useful in capturing the long-range dependencies of the text as one of the challenges posed by the cursive nature of Arabic script.
It is based on a pre-trained transformer for both image understanding and language modeling. Processing text line by line, the overall context of the handwritten text is taken into consideration, which is quite valuable in Arabic; the shape of any character can change according to its position inside a word. Therefore, line-level processing allows the model to deal with the peculiarities in Arabic handwriting and increase recognition accuracy.
It was evaluated on the Arabic KHATT dataset-a well-known benchmark for Arabic handwritten text recognition. The obtained results evidence that the proposed transformer-based approach clearly outperforms the performance of the traditional methods and reaches an CER of 18.5\%, thus proving the effectiveness of transformer architecture in the modeling of complex patterns of Arabic handwriting.

Scarcity of labeled datasets in AHTR has thus induced the employment of pre-trained models and transfer learning techniques. AraBERT is a pre-trained transformer model for Arabic text, developed by \hyperref[Antoun2020]{Antoun et al. (2020)}. It is trained on a large corpus of Arabic text and has been applied to several downstream tasks, including AHTR, in order to improve recognition accuracy.

Qalam realizes a key landmark in development upon the success in AHTR advancements. Qalam is a large multimodal model for Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR). Qalam's architecture is an ensemble of the SwinV2 encoder \hyperref[Liu2022]{Liu et al., 2022} and the RoBERTa decoder \hyperref[Liu2019]{Liu et al., 2019} model architecture to fully capture the different patterns and peculiarities present within Arabic.

Qalam, trained on the diverse dataset of more than 4.5 million images of Arabic manuscripts \hyperref[Manuscripts2023]{Al-Mutawa et al., 2023} and a synthetic dataset of 60,000 image-text pairs, has exceptional performance. It achieves a WER of 0.80\% in HWR tasks and 1.18\% in OCR tasks, outperforming existing methods by a wide margin \hyperref[Qalam2024]{Qalam, 2024}. More importantly, Qalam handles Arabic diacritical marking with unparalleled capability and processes high-resolution inputs nicely, two common weaknesses in current OCR systems.

These developments further illustrate how Qalam can be at the vanguard in Arabic script recognition, providing that leap in terms of accuracy and efficiency for applications both historical and modern.