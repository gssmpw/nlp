\section{Related Work}\label{sec:relate}
\subsection{PIAA models}\label{sec:relate:piaa}
The existing PIAA approaches~\cite{zhu2022personalized,zhu2023personalized,li2020personality,shi2024personalized,yun2024scaling} adapt pre-trained GIAA models through fine-tuning. A frequently chosen model is NIMA~\cite{talebi2018nima}, which predicts score distribution along with predicting aesthetic attribute~\cite{zhu2022personalized,zhu2023personalized,shi2024personalized} or personal trait~\cite{li2020personality}. Other GIAA models that utilize score-based comparison~\cite{ke2023vila} or score regression~\cite{ke2021musiq,yi2023towards,zhu2020personalized,li2022transductive} are considered less often.
The fine-tuning for personalization can be improved using several methods. One method uses a meta-learner~\cite{zhu2020personalized,li2022transductive}, either alone or combined with a prior model that predicts personal traits~\cite{zhu2021learning,li2020personality} or aesthetic attributes~\cite{zhu2023personalized,yan2024hybrid}. Importantly, these models take only images as input. 
%
Other approaches involve models that receive additional personal traits as input~\cite{yang2023multi,zhu2022personalized,shi2024personalized}. 
For example, PIAA-MIR~\cite{zhu2022personalized} and PIAA-ICI~\cite{shi2024personalized} involve learning personal scores by computing the interaction between aesthetic attributes and demographic features, \eg gender, age, and education, for personalization. Specifically, PIAA-ICI goes further by extracting aesthetic attributes from both images and demographic features, constructing separate graphs for each, and computing both internal interactions within each graph and external interactions between the two graphs. In contrast, Multi-Level Transitional Contrast Learning (MCTL)~\cite{yang2023multi} uses contrastive learning to learn trait embeddings from personal aesthetic scores, without explicit demographic features. Unlike PIAA-MIR and PIAA-ICI, which can infer image aesthetics for unseen users without fine-tuning, MCTL cannot generalize to unseen users due to its trait embeddings being tied to specific personal scores.

Despite the success of these approaches, the performance of PIAA models when directly evaluated on unseen users remains unclear, as they are typically evaluated under a meta-learning scheme where the model is fine-tuned on each user. 
While this scheme is appropriate for models that take only images as input~\cite{zhu2020personalized,li2022transductive,yan2024hybrid}, it becomes redundant for models that incorporate personal traits~\cite{zhu2022personalized,shi2024personalized}. These models %which 
should ideally infer image aesthetics for unseen users without requiring %few-shot 
fine-tuning, %\ie
thus performing zero-shot inference %performance 
on unseen users. Moreover, the current evaluation scheme emphasizes performance variation across image sampling while overlooking variation due to user sampling. This work focuses on PIAA models like PIAA-MIR and PIAA-ICI, which are capable of zero-shot inference, and explores performance variation specifically based on demographic factors.

\subsection{Transfer learning}\label{sec:relate:transfer}
Transfer learning leverages knowledge from a source task to improve performance on a related target task, especially useful when data in the target domain is limited~\cite{pan2010survey,zhuang2020comprehensive}. This approach has shown success across fields such as computer vision and natural language processing, where models pre-trained on large datasets can be fine-tuned on smaller, domain-specific datasets to achieve high performance~\cite{tajbakhsh2016convolutional, devlin2018bert,radford2018improving,yun2024scaling}, which is essential to the existing PIAA works~\cite{zhu2022personalized,zhu2023personalized,li2020personality,shi2024personalized,yun2024scaling} given the limited personal aesthetic data.  

Quantifying the similarity between source and target datasets in transfer learning is essential for optimizing knowledge transfer. Task vectors serve as a key metric by capturing the directional shifts in parameter space needed to adapt a model from a source to a target task, thus providing insight into task alignment and suitability for transfer~\cite{ilharco2022editing, achille2019task2vec}. It also allows the analysis of task similarity, providing insights on how to align the pre-trained task.
Distributional similarity metrics, such as Maximum Mean Discrepancy (MMD)~\cite{gretton2012kernel}, Kullback-Leibler (KL) divergence, and Earth Moverâ€™s Distance (EMD)~\cite{rubner2000earth}, quantify the distance between datasets with compatible sources. Additionally, performance-based metrics evaluate transfer effectiveness by measuring target task accuracy after source pre-training, guiding optimal model adaptation.
%
Among the existing IAA works~\cite{zhu2022personalized,zhu2023personalized,li2020personality,shi2024personalized,yun2024scaling}, Yun and Choo~\cite{yun2024scaling} propose using task vectors (\ie model parameters of GIAA models) 
% to analyze transfer learning from GIAA datasets to PIAA datasets, facilitating metric comparisons between GIAA datasets. 
to facilitate the metric comparisons between GIAA datasets.
% and propose an efficient PIAA fine-tuning technique that ensembles task vectors from various GIAA datasets with learnable coefficients for each dataset. 
While their approach successfully analyzes multiple GIAA datasets, demographic differences of the individuals across these datasets cannot be further examined using these task vectors.
% While their approach successfully analyzes multiple GIAA datasets, it may be unsuitable for the PIAA dataset with limited data, as learning on such data can lead to significant over-parameterization. 
% This suggests that the optimal model parameters for individual aesthetics form a manifold rather than a single optimal point, making it infeasible for precise analysis. Consequently, this approach may also struggle to capture aesthetic differences between groups and individuals.
