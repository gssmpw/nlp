\section{On the Geometry of Image Aesthetics}\label{sec:geometry}
\noindent{\textbf{Notation}}
Let $s$ represent the aesthetic score. The function $\hat{P}(s)$ denotes the output score distribution generated by an IAA model, which takes images as inputs in a $d$-dimensional space, where $d$ is the number of score intervals. The symbol $\delta_{i}(s)$ represents the groundtruth score distribution for PIAA, expressed as a one-hot vector for an individual score, with $i$ indicating the user. 


We demonstrate that for the PIAA models without incorporating personal traits~\cite{zhu2020personalized,li2022transductive,yan2024hybrid}, their performance on PIAA serves as the upper bound for their performance on GIAA, as shown in Theorem~\ref{thm:giaa_piaa_loss}. 
%
\begin{restatable}{theorem}{giaapiaaloss}
\label{thm:giaa_piaa_loss}
With the notation $\hat{P}(s)$ and $\delta_{i}(s)$ as defined above, and where $n$ is the total number of users, the GIAA and PIAA loss functions are given by
\begin{align}
    \mathcal{L}_{GIAA} &= \left| \hat{P}(s) - \frac{1}{n} \sum_{i=1}^{n} \delta_{i}(s) \right|,\\
    \mathcal{L}_{PIAA} &= \frac{1}{n} \sum_{i=1}^{n} \left| \hat{P}(s) - \delta_{i}(s) \right|.
\end{align}
respectively. Then, we have
\begin{equation}
\mathcal{L}_{GIAA} \leq \mathcal{L}_{PIAA}.
\end{equation}
Note that this result holds not only when $\hat{P}(s)$ and $\delta_{i}(s)$ represent score distributions but also when they are scalar scores.
\end{restatable}
%
% \begin{proof}
% Given $\hat{P}(s)$ is the predicted score distribution by an IAA model, $\delta_{i}(s)$ is the score distribution for user $i$, and $s$ is the score, the GIAA loss function $\mathcal{L}_{GIAA}$ is
% \begin{equation}
% \begin{aligned}
%     \mathcal{L}_{GIAA} &= | \hat{P}(s) - \frac{1}{n} \sum_{i=1}^{n} \delta_{i}(s) | 
%     \\ &= \frac{1}{n} | \sum_{i=1}^{n} ( \hat{P}(s) - \delta_{i}(s) ) | 
%     \\ &\leq \frac{1}{n} \sum_{i=1}^{n} | \hat{P}(s) - \delta_{i}(s) | = \mathcal{L}_{PIAA}
% \end{aligned}
% \end{equation}
% where the inequality holds by the triangular inequality and $\mathcal{L}_{PIAA}$ is the PIAA loss function. This inequality suggests that IAA models perform better on GIAA tasks than on PIAA tasks when the model is unconditioned to the user, even when trained on PIAA data. Note that the same proof applies when predicting scores instead of score distributions. By replacing $\hat{P}(s)$ with the predicted score and $\delta_{i}(s)$ with the score for user $i$, the sketch of proof remains unchanged.
% \end{proof}
%
See the proof in Section~1 of the supplementary materials. This theory suggests that IAA models perform better on GIAA tasks than on PIAA tasks when unconditioned on the user. 
%Moreover, i
It follows immediately that PIAA models can generalize well to GIAA data without GIAA pre-training. 

Next, we further show that the same statement holds even when the model is conditioned to the demographic traits (hereafter referred to as traits), \eg PIAA-MIR~\cite{zhu2022personalized} and PIAA-ICI~\cite{shi2024personalized}. Under this setup, the PIAA models map a pair of images and traits to scores. 
% To make this setup compatible with GIAA, we extend the definition of GIAA such that it maps pairs of mean traits and images to mean scores across users. 
To make this setup compatible with GIAA, we extend the definition of GIAA such that it maps pairs of the averaged traits distribution and images to the average score distribution across users. 
This extension is reasonable because, without accounting for traits, a GIAA model is likely to overfit the training data by simply memorizing preferences linked to the averaged traits distribution. 
This definition provides a clear way to model group preferences.
With this extension, GIAA maps averaged traits distribution to average score distribution, while PIAA maps individual traits to individual scores for given images. 
Moreover, both the input space (traits) and output space (scores) of IAA form distinct convex hulls based on all personal data, as illustrated in Figure~\ref{fig:convex_hull}. %; where they are introduced as trait convex hull and score convex hull, respectively.
% GIAA projects the center of the convex hull in the input space to the center of the convex hull in the output space, 
GIAA projects the average trait distribution located at the inner regime of the trait convex hull to the average score distribution located at the inner regime of the score convex hull,
whereas PIAA projects each vertex from the input convex hull to the corresponding point in the output convex hull. 
% Furthermore, all the possible users subset lies within this convex hull.
This shifts the transfer learning between GIAA and PIAA into a domain generalization problem, revealing the explicit geometry of IAA. Under this framework, transfer learning from GIAA to PIAA can be viewed as extrapolation in the trait domain, while the reverse is interpolation, which is generally more effective in machine learning. Thus, we conclude that PIAA models can generalize well to GIAA data without GIAA pre-training, even when the model is conditioned on users. We provide experimental results to verify this in Section~\ref{sec:results}.
