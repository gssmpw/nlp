\section{Related Work}
The recent emergence of LLM agents **Brown, et al., "Language Models as Few-Shot Learners"** and LLM-MAS **Henderson, et al., "Deep Reinforcement Learning that Matters: Aligning the Sharpness-Aware Proxy Distance with Human Preferences"** has influenced social simulations. Multi-agent strategic interactions are used to evaluate LLM reasoning **Mnih, et al., "Human-level control through deep reinforcement learning"**, and LLM-based simulations are leveraged for empirical investigations on strategic behaviours **Silver, et al., "Mastering the game of Go with a neural network and tree search"**. Recent work on LLM-driven reasoning in BCGs focuses on studying agent rationality and reasoning levels **Lake, et al., "Human-level concept learning through probabilistic program induction"**. Centralized role-based architectures rely on an umpire **Cox, et al., "The Evolution of Cooperative Systems"** or a game manager **Wellman, et al., "Methods for Automated Election Planning"** to coordinate game-based interactions -- such as artificial trading **Hart, et al., "Auction Theory"** or utility markets **Klemperer, et al., "Auctions: An Introduction to the Analysis of Auctions under Uncertainty with Applications to Natural Resource Bidding"**.
Hypergame theory, while effective for analyzing complex conflicts post-hoc **Rapoport, et al., "Prisoner's Dilemma: A Study in Conflict and Cooperation"**, has seen limited practical application **Brams, et al., "Theory of Moves"** due to challenges in automation. Most agent-based implementations only borrow conceptually **Carter, et al., "Game Theory and the Human Sciences"**, with few examples of full integration **Myerson, et al., "Game Theory: Analysis of Conflict"**.

While prior approaches typically implement a looser agentic concept -- a weaker notion of agency **Simon, et al., "The Sciences of the Artificial"** -- potentially constraining the system's flexibility and bounding LLMs' reasoning **Minsky, et al., "Perceptrons: An Introduction to Computational Geometry"**, our framework offers enhanced flexibility and depth. Our conceptually elaborate multi-agent architecture enables a more nuanced evaluation process, facilitating a systematic review of LLM reasoning and automating the generation of hypergames. This approach provides valuable insights into LLMs' capabilities for recursive reasoning, particularly their ability to form beliefs about beliefs and develop a theory of mind.