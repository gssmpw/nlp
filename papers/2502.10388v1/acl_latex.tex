% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
%\usepackage[review]{acl} 
% For figures, change folder manually
\usepackage[preprint]{acl} 


% Standard package includes
\usepackage{times}
\usepackage{latexsym}

\usepackage{amsmath}

\usepackage{booktabs}
\usepackage{graphicx}

\usepackage{tcolorbox}


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{subcaption}

\newcommand{\bestsc}[1]{\textbf{\underline{#1}}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{6cm}
%
% and set <dim> to something 5cm or larger.


% Define a macro for dataset name
\makeatletter % Enable access to @-commands
\newcommand{\McLean}{
    \ifacl@anonymize A Hosp. \else McLean \fi
}
\newcommand{\MGH}{
    \ifacl@anonymize B Hosp. \else MGH \fi
}
\newcommand{\BWH}{
    \ifacl@anonymize C Hosp. \else BWH \fi
}
\newcommand{\FH}{
    \ifacl@anonymize D Hosp. \else FH \fi
}
\newcommand{\MGBfull}{
    \ifacl@anonymize
      E Institute 
    \else 
      Mass General Brigham 
    \fi
}
\newcommand{\BCHfull}{
    \ifacl@anonymize 
    F Hospital\else 
    Boston Children's Hospital\fi
}
\makeatother


%\title{Through a different lens: Extracting complementary information with aspect-oriented summarization for psychiatric short-term readmission prediction}
\title{Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction}



\author{
WonJin Yoon \textsuperscript{1,4} \aand
  Boyu Ren \textsuperscript{2,4} \aand
  Spencer Thomas \textsuperscript{1} \aand
  Chanwhi Kim \textsuperscript{3} \\ 
{\bf Guergana Savova\textsuperscript{1,4} } \aand
{\bf Mei-Hua Hall \textsuperscript{2,4}   } \aand
{\bf Timothy Miller \textsuperscript{1,4} } \aand
  \end{tabular}\hss\egroup \hfil\hfil\egroup
           \hbox to \linewidth\bgroup\large \hfil\hfil
             \hbox to 0pt\bgroup\hss \begin{tabular}[t]{c}
\textsuperscript{1} Boston Children’s Hospital, MA, USA \aand
\textsuperscript{2} McLean Hospital, MA, USA \\
\textsuperscript{3} Korea University, South Korea \aand
\textsuperscript{4} Harvard Medical School, MA, USA \\
\small \texttt{\{wonjin.yoon, spencer.thomas, chanhwi.kim, tim.miller\}@childrens.harvard.edu} \\
\small \texttt{bren@mgb.org} \aand 
\texttt{mhall@mclean.harvard.edu}
}


% \author{
% WonJin Yoon \textsuperscript{1,5} \aand
%   Boyu Ren \textsuperscript{2,5} \aand
%   Spencer Thomas \textsuperscript{1} \aand
%   Chanwhi Kim \textsuperscript{1, 3} \\ 
% {\bf Guergana Savova\textsuperscript{1,2} } \aand
% {\bf Mei-Hua Hall \textsuperscript{4,5}   } \aand
% {\bf Timothy Miller \textsuperscript{1,2} } \aand
%   \end{tabular}\hss\egroup \hfil\hfil\egroup
%            \hbox to \linewidth\bgroup\large \hfil\hfil
%              \hbox to 0pt\bgroup\hss \begin{tabular}[t]{c}
%   \textsuperscript{1} Computational Health Informatics Program, Boston Children’s Hospital, Boston, MA, USA \\
% \textsuperscript{2} Laboratory for Psychiatric Biostatistics, McLean Hospital, Belmont, MA, USA \\
% \textsuperscript{3} Korea University, Seoul, South Korea \\
% \textsuperscript{4} Psychosis Neurobiology Laboratory, McLean Hospital, Belmont, MA, USA \\
% \textsuperscript{5} Harvard Medical School, Boston, MA, USA \\
% \texttt{\{wonjin.yoon, spencer.thomas, chanhwi.kim, tim.miller\}@childrens.harvard.edu}\\
% \texttt{bren@mgb.org} \aand
%   \texttt{mhall@mclean.harvard.edu }
% }

\begin{document}
\maketitle

\begin{abstract}
Recent progress in large language models (LLMs) has enabled the automated processing of lengthy documents even without supervised training on a task-specific dataset. Yet, their zero-shot performance in complex tasks as opposed to straightforward information extraction tasks remains suboptimal. One feasible approach for tasks with lengthy, complex input is to first summarize the document and then apply supervised fine-tuning to the summary. However, the summarization process inevitably results in some loss of information. In this study we present a method for processing the summaries of long documents aimed to capture different important aspects of the original document. We hypothesize that LLM summaries generated with different aspect-oriented prompts contain different \textit{information signals}, and we propose methods to measure these differences. We introduce approaches to effectively integrate signals from these different summaries for supervised training of transformer models. We validate our hypotheses on a high-impact task -- 30-day readmission prediction from a psychiatric discharge -- using real-world data from four hospitals, and show that our proposed method increases the prediction performance for the complex task of predicting patient outcome. 

\end{abstract}


\section{Introduction}

Recent progress in large language models (LLMs) has allowed the processing of long documents that were previously difficult to process due to limitations in the model sequence length~\cite{zeng2024vcc}. Although this enabled a variety of NLP tasks to be applied to longer documents, particularly using a zero- or few-shot approach, some tasks that require deeper text processing beyond information extraction remain challenging in zero-shot settings~\cite{yoon2024lcd, fan2024medodyssey}. One such complex task is patient outcome predictions such as out-of-hospital mortality or readmission prediction, where the task objective is to predict a future event given the summary of the patient's stay as recorded at their discharge in a type of clinical note called a \textit{discharge note}.
In this work, we are concerned with the high-impact real-world task of predicting readmissions in psychiatric hospitals.

Due to the immense computational cost required to fine-tune LLMs (especially given the length of clinical documents), and the regulatory challenges presented by transferring sensitive patient data to a large compute environment, traditional supervised training approaches are not feasible for tasks where patient data are the primary source.\footnote{Due to the Transformers architecture, a vanilla method to fine-tune a model with $n$ context size will require $O(n^2)$ of GPU memory.} On the other hand, recent studies show that one of the core LLM strengths is their ability to generate high-quality summaries \cite{zhang2024benchmarking, liu2023learning}. 
Furthermore, clinical notes contain detailed information about the patient's disease/s not all necessarily relevant to a particular classification task \cite{hultman2019challenges}. Thus, summarization emerges as a feasible approach to retain only the relevant content.


The recent advances in LLM capabilities make it possible to explore an approach where long documents are first summarized to an acceptable length, and the summaries are used to fine-tune a smaller language model.  
This approach takes advantage of the strengths of LLM while avoiding the challenges of fine-tuning them~\cite{chen2024improving}. 
However, since the summarization process shortens a document, some content details that are important signals for downstream tasks might be removed. Aspect-oriented prompting~\cite{ahuja-etal-2022-aspectnews}, where prompt variations are used to condition the summary on important aspects of the text (e.g., risk factors), could capture the relevant details more reliably.



Therefore, we address the following research questions: 1) Does the use of LLM-based aspect-oriented summarization extract measurably different information signals with different information-focused prompts (i.e. aspects)? 2) What are effective strategies for merging signals from different aspect-oriented summaries?


The present work makes the following contributions to answering these research questions. First, we develop and quantify methods for measuring the information signal differences in the summarized text. Working with our domain experts, we created three different types of prompts to summarize discharge notes from the Electronic Health Record (EHR) into a paragraph-length document. We generated summarized documents using the prompts and used them as training data for the downstream task of readmission prediction by fine-tuning smaller pre-trained language models. During this process, the differences in information contained in the summaries become internalized within the fine-tuned models, allowing to measure these differences by comparing the prediction differences. For scientific rigor, we fine-tuned repeatedly with random seed variations, setting the control group as the variation among models trained using the same prompt and the experimental group as the variation among models trained using different prompts. 

Second, we explore methods for combining summaries generated by different aspect-oriented prompts and propose their integration at the dataset level. We show that our proposed method improves the performance of fine-tuned models and demonstrate that effectively integrating information from diverse summaries generated via aspect-oriented summarization yields better performance than fine-tuning with a single summary.


%This study proposes a method to the major challenge of processing long documents in the important task of predicting psychiatric readmission, with an emphasis on how to effectively leverage LLMs in this process.


\begin{figure*}[t]
\centering
  \includegraphics[width=0.9\textwidth]{figures/figures-processing.pdf}
  \caption{Overview of our aspect-oriented summarization pipeline. Discharge notes sourced from hospitals' EHR databases and processed with LLM prompts. The summarized notes are used in the experiments detailed in Sections~\ref{sec:methods-inform-diff} and \ref{sec:read-task}.}
  \label{fig:processing}
\end{figure*}


\section{Dataset and task}

In this section, we describe the readmission prediction task and the data sourced from real-world hospital EHRs.



\subsection{Source of experimental data}

We extracted psychiatric discharge notes from the EHR databases of four hospitals within a single academic health center in the United States. %\footnote{We anonymized the hospitals' names to comply with the double-blind policy.} %TODO-ANONYMIZE
Patient encounters were selected with two criteria: (1) range for patient's age at admission of 18-65 years old; pediatric and elderly patients excluded because of the disease specifics for these age groups, and (2) ICD-10 diagnosis codes for mood disorders or psychotic disorders.~\footnote{All codes starting with F2 or F3.} Table~\ref{tab:stats} shows the number of notes in the training, development, and test sets grouped by hospital. 
This study was approved by the \textit{\MGBfull} Institutional Review Board with a formal reliance at \BCHfull.


\begin{table}[]
\centering
\resizebox{0.95\columnwidth}{!}{
\begin{tabular}{@{}l|cccc|c@{}}
\toprule
Hospital & Train & Dev  & Test & Total & Pos/Total \\ \midrule
\McLean   & 6066  & 775  & 1718 & 8559  & 0.2914    \\
\MGH      & 8840  & 1392 & 2610 & 12842 & 0.2979    \\
\BWH      & 979   & 130  & 339  & 1448  & 0.3384    \\
\FH       & 793   & 94   & 242  & 1129  & 0.2214    \\ \bottomrule
\end{tabular}%
}
\caption{Dataset distribution by hospital sites. The middle section lists the note counts for the train, development (dev), and test splits; the right section shows the positive label ratio (Pos/Total).}\label{tab:stats}

\end{table}
\setlength{\textfloatsep}{10pt}

\subsection{Task definition}

The readmission prediction task involves determining whether a patient will be readmitted to the hospital within 30 days after discharge. %The task is especially important as it is a core hospital quality metric per US Centers for Medicare and Medicaid Services (CMS).
This task is important for the patient's quality of life~\cite{owusu2022readmission, ren2024cross} as well as used by the United States Centers for Medicare and Medicaid Services (CMS) as a quality metric for some conditions that is tied to reimbursement rates~\cite{noauthor_hospital_nodate}. 
The dataset's unit is a hospital admission, and a single patient might have multiple admissions. Since discharge notes are generated once per admission at the time of discharge, there is a one-to-one correspondence between a discharge note and a hospital admission, making both units equivalent in the dataset. To ensure that discharge notes from the same patient do not scatter across the training, development and test  splits, we used the patient ID.
In this study, the model's input is the text of a psychiatric discharge note, without any EHR structured data, i.e. ICD-10 codes or medication orders. The label is binary: a positive label indicates readmission within 30 days, while a negative label indicates no readmission within that period.

\section{Methods}

Our methodology comprises of three components: aspect-oriented summarization, measuring information signal differences, and integrating information signals with a focus on readmission prediction.

\subsection{Aspect-oriented summarization}\label{sec:summarization}

The intrinsic nature of summarization leads to information loss as some of the original content is omitted from the summary~\cite{tang2023evaluating}.
Summarization becomes challenging if the document is long and if the source document is written in a nuanced language, where overlooking even small details could significantly alter the intended meaning~\cite{zhang2024closing}. 

Psychiatric discharge notes are valuable resources for assessing LLM summarization capabilities, not only due to their length but also because of their nuanced language. A plain-language description of an event could be a significant signal. For example, an event where a patient stops taking a medication is informative, but its importance and meaning is highly dependent on context -- whether it was due to side effects, ineffectiveness, or some other reason.

These factors motivate our aspect-oriented summarization approach. 
Data processing steps are shown in (Figure~\ref{fig:processing}).
We started with the raw EHR data and extracted the discharge notes. These discharge notes are summarized using an instruction-tuned LLM. Three types of prompts, \texttt{plain}, \texttt{riskfactor}, and \texttt{timeline}, were used to produce different types of summaries, i.e. aspects. The prompt templates are shown in Figure~\ref{fig:grouped_boxes}. The \texttt{plain} prompt was intended to create a generic summary;  the \texttt{riskfactor} prompt focused on specific research factors previously published in psychiatric NLP research~\cite{holderness2019analysis, ding-etal-2020-incorporating}; and the \texttt{timeline} prompt was designed to generate summaries containing an ordered sequence of important events before and during the admission. All three prompts were developed with input from researchers with clinical NLP and psychiatric expertise.

We use the summarized discharge notes in the experiments presented in Sections~\ref{sec:methods-inform-diff} and \ref{sec:read-task}.


\begin{figure*}[h!]
\small
\centering
\begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=Plain summary, width=\textwidth]
<s>[INST] The following is a discharge summary for a patient leaving a psychiatric hospital.

\textit{\textbf{Discharge note inserted here.}}

This is the end of the discharge summary. Please summarize the patient's hospital course in a paragraph. [/INST]
\end{tcolorbox}

\begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=Riskfactor-focused summary, width=\textwidth]
<s>[INST] The following is a discharge summary for a patient leaving a psychiatric hospital.

\textit{\textbf{Discharge note inserted here.}}

This is the end of the discharge summary. We would like to summarize the discharge summary in terms of risk factors for readmission within 30 days. Psychiatric experts have created a list of risk factors that they believe are important.  \\
    1: Appearance: Physical appearance, gestures, and mannerisms;\\
    2: Thought content: Suicidal/homicidal ideation, obsessions, phobias, delusions, hallucinations;\\
    3: Interpersonal: Family situation, friendships, and other social relationships;\\
    4: Mood: Feelings and overall disposition;\\
    5: Occupation: School and/or employment;\\
    6: Thought process: Pace and coherence of thoughts. Includes linear, goal-directed, perseverative, tangential, and flight of ideas;\\
    7: Substance: Drug and/or alcohol use;\\
    8: Other: Any risk factor that does not fall into one of the preceding categories;\\
These risk factors could have positive or negative valence. Please summarize the risk factors from the above list that are present in the discharge summary, along with their valence (positive, negative, neutral). [/INST]
\end{tcolorbox}


\begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=Timeline-focused summary, width=\textwidth]
<s>[INST] The following is a discharge summary for a patient leaving a psychiatric hospital.

\textit{\textbf{Discharge note inserted here.}}

This is the end of the discharge summary. Write a very brief semi-structured timeline with the major events in the patient's medical history, including prior to admission. Do not give a full medication history, though recent medications and a note of a complex medication history are useful. Each line has the form <Date/Time>: <Event description> [/INST]
\end{tcolorbox}\vspace{-8pt}
    \caption{Prompts for summarization. Three types of prompts, \texttt{plain}, \texttt{riskfactor}, and \texttt{timeline}, were used to generate different types of summaries.}
    \label{fig:grouped_boxes}
\end{figure*}
%\setlength{\textfloatsep}{0pt}




\subsection{Measuring information differences}\label{sec:methods-inform-diff}

Since we hypothesize that different types of summaries potentially contain non-overlapping pieces of information, we describe our method to quantify the degree of overlap. 

Existing methods for automatically comparing documents, such as ROUGE~\cite{lin-2004-rouge} and BERTscore~\cite{zhangbertscore}, are designed for purposes not fitting our goal to estimate the information differences of summaries intended to represent different sides of the original document. Moreover, they are inadequate for capturing subtle information differences. Based on our preliminary study, manually evaluating summaries for information preservation, i.e., determining whether important information is kept or omitted, is not scalable and is subjective. Therefore, we developed a data-driven approach. 

The intuition behind our approach is that models capture signals specific to the text used during the supervised training phase. Therefore, if during the supervised training stage the model is exposed to aspect-oriented summaries each targeting a different side of the original text, the model will learn the various aspects. Therefore, we train task-specific models on each type of summary, expecting the models to learn the summary-specific signals which in turn will be reflected in the final predictions. By comparing the outputs of the task-specific models we measure the difference in the signals present in the inputs. 
Figure~\ref{fig:venn-diff}  is the Venn diagram illustrating that models derived from different summaries make distinct decisions.\footnote{Note that these predictions are based on one experimental run, rather than the aggregation of multiple runs reported in Table~\ref{tab:perf-main}.}


\begin{figure}[t]
\centering
  \includegraphics[width=0.7\columnwidth]{figures/venn-bhosp-tp.pdf}
  \caption{Differences between predictions (True Positives) of task-specific models fine-tuned with different summary types. The non-overlapping predictions suggest that aspect-oriented prompting extracts different yet complimentary information from the source document. 
  The figure shows experiments from \MGH with a random seed set to 0.
  }
  \label{fig:venn-diff}
\end{figure}


%This measurement is only reliable when supported by robust statistical evidence. 
We iterated model training with identical settings but with different seeds on the same summary types. Intra-aspect experiments (i.e. measuring the difference between summaries generated using the same prompt) were conducted as a control group and compared against inter-aspect experiments (i.e. measuring the difference between summaries generated using different prompts). This approach aims to mitigate differences arising from sources of randomness such as random initialization.


\begin{figure*}[ht]
\centering
    \resizebox{0.95\textwidth}{!}{
    % First graph
    \begin{subfigure}[b]{0.41\textwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/fig-infodiff-box-pubmed.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.58\textwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/fig-results-all-four-pubmed.pdf}
    \end{subfigure}
    }
  \caption{Information difference by summary type combinations. Lower values indicate smaller difference observed. [Left figure] The y-axis represents the Tau-based distance $d$. The box indicates the interquartile range (the middle 50\% of the data), and the dots indicate outliers from the iterated experiments. [Right figure] The bar chart represents the Difference ($D$) (i.e. mean distance at the dataset level) by the summary type combination.}
  \label{fig:info-diff}
\end{figure*}



\subsubsection{Pair-wise similarity scores between models}
We assess the similarity between the outputs of any given pair of models. The outputs were ranked based on probabilities, and Kendall’s tau was employed to evaluate the similarity between the two ranked lists. \footnote{We utilized implementation of \textbf{SciPy v1.14.1}.}

We define a list of prediction from a model $M_1$ on $k$ notes as $L_1 = \{p^1_1, p^1_2, ... p^1_k\}$, and define $L_2 = \{p^2_1, p^2_2, ... p^2_k\}$ similarly for another model $M_2$ on the same set of $k$ notes, where $p^i_j$ is a probability value in the range [0, 1]. From here, we can define lists of ranks, $R_1 = \{R^1_1,\ldots,R^1_k\}$ and $R_2 = \{R^2_1,\ldots,R^2_k\}$ where the elements represent the rank of each element in the list.
Following the definition of \citet{kendall1945treatment} and its implementation by SciPy \cite{2020SciPy-NMeth}, the Kendall’s Tau $\tau_{(1,2)}$ between $L_1$ and $L_2$ is defined as:
\begin{equation}
\tau_{(1,2)} = \frac{P - Q}{\sqrt{ (N - T)(N - U) }} \notag 
\end{equation}
where $N = k(k-1)/2$ is the total number of pairs. $P$ represents the count of concordant pairs and $Q$ denotes the count of discordant pairs. $T$ is the number of tied pairs in $R_1$, and $U$ is the number of tied pairs in $R_2$. Here concordant pairs are all $(i,j)$ such that $R^1_i < R^1_j$ and $R^2_i<R^2_j$ or $R^1_i > R^1_j$ and $R^2_i < R^2_j$ while discordant pairs are all $(i,j)$ such that $R^1_i < R^1_j$ and $R^2_i > R^2_j$ or $R^1_i > R^1_j$ and $R^2_i < R^2_j$. $\tau$ is in the range $[-1, 1]$, where 1 indicates complete concordance, and -1 indicates complete discordance.
We define Kendall's $\tau$-based distance as $d_{i,j} = (1 - \tau_{i,j})/2$. Since \( \tau \in [-1, 1] \), it follows that \( d \in [0, 1] \).


\subsubsection{Dataset-level information difference score}
%The next step is to average the Tau scores across models. 
We perform multiple experiment runs per type of summarization and per hospital sites. 
The mean distance between the predictions of one summary type (intra-aspect difference) is calculated by averaging the distances of all combinations within the same settings. 
For example, the difference $D$ within $S_{plain}$ type summary experiments for a hospital $A$ can be defined as:
\begin{equation}
{
\text{D} (A, S_{plain}) = 
\frac{\sum_{i=1}^{n} \sum_{j=1}^{n} d_{i,j}}{n^2}
}\notag 
\end{equation}
where $n$ is the number of repeated training runs for the same settings with different random seeds (i.e. models $M_1, M_2, ... M_n$ are trained on $S_{plain}$).

The mean distance between two different types of summarization methods (inter-aspect difference) is measured analogously. For example, the difference between Plain summarization and Riskfactor summarization can be measured by:
\begin{equation}
{
\text{D} (A, S_{plain}, S_{riskfactor}) = 
\frac{\sum_{i=1}^{n} \sum_{\substack{j=1}}^{m} d_{i,j}}
{n  m}
}\notag 
\end{equation}
where $n$ is the number of repeated training runs for the Plain summarization dataset and $m$ for the Riskfactor dataset.

%We perform multiple experiment runs per type of summarization and per hospital sites.


\iffalse

\begin{equation}
{
\text{d}_3(m,d_i) = \frac{|v_1 - v_2| + |v_1 - v_3| + |v_2 - v_3|}{3}
}
\end{equation}
\begin{equation}
{
\text{D}_3(m,d) = \sum_{i}{\text{d}_3(m,d_i)}
}
\end{equation}
where $m$ and $d$ stand for language model and dataset combination, respectively.

\fi




\subsection{Readmission prediction task}\label{sec:read-task}
%In the previous section, we described how to measure the information difference of different types of summaries, i.e. summaries generated using aspect-oriented prompts.
In this section, we propose methods to utilizing the different types of summarized text for training task-specific models.




\subsubsection{Baseline models}

Discharge notes are typically long usually requiring a 10k-token window, which exceeds the capacity of most encoder-only transformer models thus rendering fine-tuning impractical. Therefore, a Bag-of-Words (BOW) approach with Support Vector Machine (SVM) \cite{cortes1995support, joachims1998text} was used as a baseline model to estimate the performance using the content of the entire document (i.e. no summarization).

For baseline classification from single summaries, we used two types of models: (1) a traditional baseline with SVM with BoW features, and (2) a transformer-based Pretrained Language Model (PLM).
%
The SVM baseline allows us to compare directly to full-document performance, while the PLM allows us to measure the capability of more advanced models.





\subsubsection{Integration of information from different summaries}


We examine two methods of data integration: \textbf{\textit{instance concatenation}}, which we refer to as \textbf{\textit{merged}}, where we combine summaries at the note level; and \textbf{\textit{dataset concatenation}}, which we refer to as \textbf{\textit{union}}, where we create one large dataset where each instance has its own summary type.

Let $s_i^{plain}$ denote a plain summarized note at the $i$-th index, and likewise  $s_i^{riskfactor}$ and $s_i^{timeline}$ for their respective summary types. The three datasets of the LLM-summarized notes, $S_{plain}$, $S_{riskfactor}$, and $ S_{timeline}$, each contain $k$ instances that can be aligned.

The \textbf{\textit{instance concatenation (merged)}} approach is represented as building a dataset composed of $s_i^{merged}$, which is three summaries, $s_i^{plain}$, $s_i^{riskfactor}$, $s_i^{timeline}$, simply concatenated together with summary demarcation indicated by ``Another summary'' to form one longer document. 
\begin{align}
s_i^{merged} &= s_i^{plain} + s_i^{riskfactor} + s_i^{timeline} \notag \\
S_{merged} &= \{s_i^{merged}  \mid i = 1, 2, \dots, k\ \}  \notag 
\end{align}

The \textbf{\textit{dataset concatenation (union)}} approach is more straightforward and can be represented as the union of three summary datasets. This approach requires a pooling strategy during testing to combine the outputs of the summaries with the same original index and produce a single prediction for each original instance.
\begin{align}
S_{union} &= S_{plain} \cup S_{riskfactor} \cup S_{timeline} \notag \\
           &= \{s_1^{plain}, s_2^{plain}, \dots, s_k^{plain}, \notag \\
           &\quad\; \quad\; s_1^{riskfactor}, \dots, s_k^{timeline} \} \notag 
\end{align}


We examined two prediction strategies for the dataset concatenation approach, \textit{\textbf{Soft voting}} and \textit{\textbf{Any voting}}. A prediction for the $i$-th input can be expressed as follows, if the prediction and probability of the model for a summary type $s_i^{type}$ are given as $\hat{y}_i^{type} \in \{0, 1\}$ and $p_i^{type} \in [0, 1]$:
\begin{align}
p_i^{soft vote} &= \operatorname{average}(p_i^{plain}, p_i^{riskfactor}, p_i^{timeline}) \notag \\
\hat{y}_i^{soft vote} &= \begin{cases} 
                    1, & \text{if } p_i^{\text{soft vote}} \geq 0.5, \\
                    0, & \text{if } p_i^{\text{soft vote}} < 0.5
                    \end{cases} \notag \\
p_i^{any vote} &= \max(p_i^{plain}, p_i^{riskfactor}, p_i^{timeline}) \notag \\
\hat{y}_i^{any vote} &= \hat{y}_i^{plain} \lor \hat{y}_i^{riskfactor} \lor \hat{y}_i^{timeline}  \notag 
\end{align}

The number of elements in $S_{union}$ will be $3*k$ whereas for $S_{merged}$ it will remain $k$. However, the length of each element for $S_{merged}$ will be longer than $S_{union}$ .




\section{Results}


\subsection{Information differences}\label{sec:info-diff-results}


We conducted our experiments with encoder-only models as they produce a list of outputs with likelihood. Figure~\ref{fig:info-diff} shows results for BiomedBERT (formerly known as PubMedBERT) \cite{pubmedbert} which we fine-tuned for the specific task of readmission prediction. Aspect-oriented summarization was done with prompts to mistral 7B instruct v0.2~\cite{jiang2023mistral} (see Appendix~\ref{sec:appendix-exp-details} for details). 

Intra-aspect information difference scores (control group) were lower than inter-aspect difference scores (experimental group). 
This implies that the different aspect-oriented prompts produce summaries with non-overlapping information, and this is not the effect of randomness introduced during initialization steps.
Further, these results provide a strong justification for developing methods that integrate signals from aspect-oriented summaries. 


In addition to experimenting with BiomedBERT, we experimented with Clinical Longformer (CLF) \cite{li2023comparative}. A detailed description is provided in Appendix~\ref{sec:appendix-infodiff}. The result patterns for CLF are consistent with those of BiomedBERT.



\subsection{Readmission prediction}


\begin{table*}[]
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{l|l|cccc|cccccc}
% \toprule
% \multicolumn{2}{l}{Model types} & \multicolumn{4}{c}{BoW}                                                            & \multicolumn{5}{c}{Transformer Model} \\ \midrule %\midrule
% \multicolumn{2}{l}{Input type } & Plain           & Riskfactor & Timeline        & \textbf{\textit{Merged}} & Plain        & Riskfactor   & Timeline         & \textbf{\textit{Soft vote}} & \textbf{\textit{Any vote}}  \\ \toprule
% \McLean  & AUROC                & \textbf{0.5784} & 0.5415     & 0.5668          & \bestsc{0.5853}          & \bestsc{0.6051} & 0.5193         & 0.5788          &\textbf{0.6005} & 0.5988         \\
%          & AUPRC                & \textbf{0.3541} & 0.3164     & 0.3490          & \bestsc{0.3717}          & \bestsc{0.3960} & 0.3074         & 0.3650          &0.3868          & \textbf{0.3943} \\ 
%          & MaAvg   F1           & 0.5531          & 0.5346     & \textbf{0.5704} & \bestsc{0.5728}          & \textbf{0.5630} & 0.5113         & 0.5500          &\bestsc{0.5694} & 0.5122          \\
%          & \;\; \textit{Neg F1} & 0.7390          & 0.7313     & 0.7392          & 0.7459                   & 0.7695          & 0.7617         & 0.7748          &0.7721          & 0.5887          \\
%          & \;\; \textit{Pos F1} & 0.3671          & 0.3379     & 0.4016          & 0.3997                   & 0.3566          & 0.2608         & 0.3252          &0.3667          & 0.4357          \\ \midrule
% \MGH     & AUROC                & 0.6075          & 0.5565     & \textbf{0.6102} & \bestsc{0.6233}          & 0.6476          & 0.5890         & 0.6494          &\bestsc{0.6672} & \textbf{0.6564} \\
%          & AUPRC                & 0.4123          & 0.3447     & \textbf{0.4127} & \bestsc{0.4233}          & 0.4730          & 0.3988         & 0.4809          &\bestsc{0.4870} & \textbf{0.4823} \\ 
%          & MaAvg   F1           & \bestsc{0.6022} & 0.5462     & 0.5949          & \textbf{0.5965}          & 0.6020          & 0.5477         & 0.6006          &\bestsc{0.6025} & \textbf{0.6025} \\
%          & \;\; \textit{Neg F1} & 0.7330          & 0.7153     & 0.7351          & 0.7401                   & 0.7684          & 0.7622         & 0.7746          &0.8044          & 0.7144           \\
%          & \;\; \textit{Pos F1} & 0.4715          & 0.3772     & 0.4547          & 0.4529                   & 0.4355          & 0.3333         & 0.4267          &0.4007          & 0.4907          \\ \midrule
% \BWH     & AUROC                & \bestsc{0.5601} & 0.5312     & \textbf{0.5527} & 0.5518                   & 0.5402          & 0.5174         & 0.5677          &\textbf{0.5938} & \bestsc{0.5966} \\
%          & AUPRC                & \textbf{0.4014} & 0.3590     & \bestsc{0.4032} & 0.3939                   & 0.3694          & 0.3457         & 0.3856          &\textbf{0.4124} & \bestsc{0.4284} \\ 
%          & MaAvg   F1           & 0.5485          & 0.5196     & \bestsc{0.5674} & \textbf{0.5669}          & 0.5383          & 0.5052         & \textbf{0.5404} &\bestsc{0.5518} & 0.5206          \\ 
%          & \;\; \textit{Neg F1} & 0.6855          & 0.6779     & 0.6944          & 0.6941                   & 0.6901          & 0.6678         & 0.7168          &0.7295          & 0.5474          \\
%          & \;\; \textit{Pos F1} & 0.4116          & 0.3614     & 0.4404          & 0.4396                   & 0.3865          & 0.3426         & 0.3640          &0.3741          & 0.4938          \\ \midrule
% \FH      & AUROC                & \textbf{0.5413} & 0.5115     & 0.5290          & \bestsc{0.5646}          & 0.4800          & 0.4905         & \textbf{0.5350} &\bestsc{0.5353} & 0.5336          \\
%          & AUPRC                & 0.3473          & 0.3224     & \bestsc{0.3541} & \textbf{0.3497}          & 0.3007          & 0.3138         & \bestsc{0.3549} &0.3415          & \textbf{0.3528} \\ 
%          & MaAvg   F1           & \textbf{0.6041} & 0.4935     & \bestsc{0.6280} & 0.4861                   & 0.4558          & \textbf{0.4755}& 0.4671          &0.4451          & \bestsc{0.5126} \\
%          & \;\; \textit{Neg F1} & 0.6899          & 0.6849     & 0.6909          & 0.6860                   & 0.7426          & 0.7106         & 0.7721          &0.8027          & 0.6996          \\
%          & \;\; \textit{Pos F1} & 0.5183          & 0.3022     & 0.5652          & 0.2862                   & 0.1691          & 0.2404         & 0.1620          &0.0874          & 0.3257          \\\hline
% \end{tabular}%
% }
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|l|c|cccc|cccccc}
\toprule
\multicolumn{2}{l}{Model types} & \multicolumn{5}{c}{SVM with BoW}                                                            & \multicolumn{5}{c}{Transformer Model (BiomedBERT)} \\ \midrule %\midrule
\multicolumn{2}{l}{Input type } & Full note       & Plain           & Riskfactor & Timeline        & \textbf{\textit{Merged}} & Plain        & Riskfactor   & Timeline         & \textbf{\textit{Soft vote}} & \textbf{\textit{Any vote}}  \\ \toprule
\McLean  & AUROC                & 0.5770          & \textbf{0.5784} & 0.5415     & 0.5668          & \bestsc{0.5853}          & \bestsc{0.6051} & 0.5193         & 0.5788          &\textbf{0.6005} & 0.5988         \\
         & AUPRC                & 0.3465          & \textbf{0.3541} & 0.3164     & 0.3490          & \bestsc{0.3717}          & \bestsc{0.3960} & 0.3074         & 0.3650          &0.3868          & \textbf{0.3943} \\ 
         & MaAvg   F1           & 0.5570          & 0.5531          & 0.5346     & \textbf{0.5704} & \bestsc{0.5728}          & \textbf{0.5630} & 0.5113         & 0.5500          &\bestsc{0.5694} & 0.5122          \\
         & \;\; \textit{Neg F1} & 0.7450          & 0.7390          & 0.7313     & 0.7392          & 0.7459                   & 0.7695          & 0.7617         & 0.7748          &0.7721          & 0.5887          \\
         & \;\; \textit{Pos F1} & 0.3689          & 0.3671          & 0.3379     & 0.4016          & 0.3997                   & 0.3566          & 0.2608         & 0.3252          &0.3667          & 0.4357          \\ \midrule
\MGH     & AUROC                & 0.5923          & 0.6075          & 0.5565     & \textbf{0.6102} & \bestsc{0.6233}          & 0.6476          & 0.5890         & 0.6494          &\bestsc{0.6672} & \textbf{0.6564} \\
         & AUPRC                & \textbf{0.4208} & 0.4123          & 0.3447     & 0.4127          & \bestsc{0.4233}          & 0.4730          & 0.3988         & 0.4809          &\bestsc{0.4870} & \textbf{0.4823} \\ 
         & MaAvg   F1           & \bestsc{0.6120} & \textbf{0.6022} & 0.5462     & 0.5949          & 0.5965                   & 0.6020          & 0.5477         & 0.6006          &\bestsc{0.6025} & \textbf{0.6025} \\
         & \;\; \textit{Neg F1} & 0.7491          & 0.7330          & 0.7153     & 0.7351          & 0.7401                   & 0.7684          & 0.7622         & 0.7746          &0.8044          & 0.7144           \\
         & \;\; \textit{Pos F1} & 0.4749          & 0.4715          & 0.3772     & 0.4547          & 0.4529                   & 0.4355          & 0.3333         & 0.4267          &0.4007          & 0.4907          \\ \midrule
\BWH     & AUROC                & 0.5420          & \bestsc{0.5601} & 0.5312     & \textbf{0.5527} & 0.5518                   & 0.5402          & 0.5174         & 0.5677          &\textbf{0.5938} & \bestsc{0.5966} \\
         & AUPRC                & 0.3803          & \textbf{0.4014} & 0.3590     & \bestsc{0.4032} & 0.3939                   & 0.3694          & 0.3457         & 0.3856          &\textbf{0.4124} & \bestsc{0.4284} \\ 
         & MaAvg   F1           & 0.5520          & 0.5485          & 0.5196     & \bestsc{0.5674} & \textbf{0.5669}          & 0.5383          & 0.5052         & \textbf{0.5404} &\bestsc{0.5518} & 0.5206          \\ 
         & \;\; \textit{Neg F1} & 0.6982          & 0.6855          & 0.6779     & 0.6944          & 0.6941                   & 0.6901          & 0.6678         & 0.7168          &0.7295          & 0.5474          \\
         & \;\; \textit{Pos F1} & 0.4059          & 0.4116          & 0.3614     & 0.4404          & 0.4396                   & 0.3865          & 0.3426         & 0.3640          &0.3741          & 0.4938          \\ \midrule
\FH      & AUROC                & \bestsc{0.5750} & 0.5413          & 0.5115     & 0.5290          & \textbf{0.5646}          & 0.4800          & 0.4905         & \textbf{0.5350} &\bestsc{0.5353} & 0.5336          \\
         & AUPRC                & \bestsc{0.4190} & 0.3473          & 0.3224     & \textbf{0.3541} & 0.3497                   & 0.3007          & 0.3138         & \bestsc{0.3549} &0.3415          & \textbf{0.3528} \\ 
         & MaAvg   F1           & 0.5703          & \textbf{0.6041} & 0.4935     & \bestsc{0.6280} & 0.4861                   & 0.4558          & \textbf{0.4755}& 0.4671          &0.4451          & \bestsc{0.5126} \\
         & \;\; \textit{Neg F1} & 0.7182          & 0.6899          & 0.6849     & 0.6909          & 0.6860                   & 0.7426          & 0.7106         & 0.7721          &0.8027          & 0.6996          \\
         & \;\; \textit{Pos F1} & 0.4223          & 0.5183          & 0.3022     & 0.5652          & 0.2862                   & 0.1691          & 0.2404         & 0.1620          &0.0874          & 0.3257          \\\hline
\end{tabular}%
}
\caption{Performance of supervised models by summarization methods. \textbf{Boldfaced} numbers indicate the top-2 performances for each model type, while \bestsc{underlined} numbers denote the best performances. Columns titled Merged, Soft vote, and Any vote show the performance of models using three types of summarized inputs. Pos F1 refers to the F1-score for the positive label (patient readmitted within 30 days), while Neg F1 represents the F1-score for the negative label (patient NOT readmitted within 30 days). MaAvg F1 denotes the macro-average of Neg F1 and Pos F1.}
\label{tab:perf-main}
\end{table*}


\paragraph{Evaluation metrics}
We utilized multiple evaluation metrics, including threshold-dependent metrics (precision, recall, and F1-score) and threshold-independent metrics such as area under the receiver operating characteristic (AUROC) and area under the precision-recall curve (AUPRC).
For the threshold-dependent metrics, we used 0.5 as a fixed threshold for positive and negative labeling. We prioritized threshold-independent metrics as our primary evaluation criteria, as threshold-dependent metrics e.g. F1-score are highly sensitive to the choice of threshold in the presence of class imbalance---a characteristic of all our datasets (see Table \ref{tab:stats}). %---due to their focus on the positive class. 
We examined threshold-dependent metrics mainly to understand how the model performs at the default threshold. We also report F1 scores for the negative class (denoted as Neg F1) and Macro average of positive and negative F1 scores (denoted as MaF1) as an alternative way to address the limitations of the F1-score.


Table~\ref{tab:perf-main} shows the results of models trained on aspect-oriented summaries and our proposed merging approaches for the 30-day readmission prediction task. The columns are grouped into two types of supervised models, SVM with BoW features and fine-tuned BiomedBERT Transformer models. 
Regardless of model types, models trained on the integrated dataset showed strong performance over those trained on monotone summarization datasets, where summaries were generated using a single-type aspect-oriented prompt.

The first column presents the results of the baseline approach (SVM with BOW features) using full discharge notes. 
These results, with AUROC values ranging from 0.54 to 0.59, indicate that the task is highly challenging, yet there are detectable signals that the models can learn.


For the SVM with BoW model results on summarized notes, the merging method showed a performance gain across all datasets. 
For PLMs, soft voting and any voting showed a large improvement over the same architecture models trained on three summary types. 


The training runs were performed 5 times (Transformer) or 10 times (SVM with BoW) using different random seeds while keeping the hyperparameters identical to ensure statistical robustness against the effects of random initialization. All reported numbers represent the averaged values of these runs. Additional statistics for these results are provided in Table~\ref{tab:appendix-stat} in Appendix~\ref{sec:appendix-stat}. 


\section{Discussion}


\begin{figure*}[htbp]
\centering
    \resizebox{0.9\textwidth}{!}{
    \begin{subfigure}[b]{0.40\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/boxplot-llm.pdf} 
        \label{fig:graph1}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[b]{0.40\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/boxplot-transformer.pdf} 
        \label{fig:graph2}
    \end{subfigure}
    }
    \vspace{-1em}
    \caption{Boxplots showing the ratio of positive-label predictions in the model outputs. The red rhombus symbol indicates the ratio in the dataset. The box represents the interquartile range of the ratio values in the iterated experiments. }
    \label{fig:pos-ratio}
\end{figure*}
%\setlength{\textfloatsep}{0pt}




\subsection{Integration method by model types}\label{sec:dis-integ}

We reported different integration methods depending on the model type: instance concatenation (Merged) for SVM with BoW, and dataset concatenation (Soft voting and Any voting) for transformer-based models. 
Because the Merged method increases input sequence length---sometimes up to 1,500 tokens (with a median range of 870 to 950 across hospitals)---we applied it only to Clinical Longformer \cite{li2023comparative}, an encoder-only transformer that can handle inputs longer than 512 tokens. The results of this experiment are provided in Appendix~\ref{sec:supp-dis-integ} (Table~\ref{tab:perf-clf}).

Our findings show that the Merged approach improves performance for the BoW model but does not benefit transformer models. One likely reason is that BoW methods are relatively unaffected by input length, whereas transformer models often exhibit degraded performance on lengthy inputs~\cite{beltagy2020longformer, ainslie2020etc, li2023comparative, yoon2024lcd}. 
When tested on Clinical Longformer, the Merged method was less effective than the Union method. Among Soft Voting and Any Voting, the results followed a similar pattern to our main findings with BiomedBERT (Table~\ref{tab:perf-main}).


\begin{table}[h]
\resizebox{\columnwidth}{!}{
\begin{tabular}{l|l|ccccc@{}}
\toprule
\multicolumn{2}{l}{Input type}   & Full   & Plain  & Risk   & Time   & Merged \\ \midrule
\McLean  & Ma F1                 & 0.5650 & 0.5458 & 0.4087 & 0.3866 & 0.3983 \\
         & \;\; \textit{NegF1}   & 0.7696 & 0.7166 & 0.3840 & 0.3338 & 0.3818 \\
         & \;\; \textit{PosF1}   & 0.3604 & 0.3750 & 0.4335 & 0.4394 & 0.4147 \\ \midrule
\MGH     & Ma F1                 & 0.4708 & 0.4895 & 0.3548 & 0.3707 & 0.3252 \\
         & \;\; \textit{NegF1}   & 0.5312 & 0.5532 & 0.2772 & 0.2927 & 0.2011 \\
         & \;\; \textit{PosF1}   & 0.4104 & 0.4257 & 0.4325 & 0.4487 & 0.4493 \\ \midrule
\BWH     & Ma F1                 & 0.4794 & 0.4590 & 0.3892 & 0.3527 & 0.3706 \\
         & \;\; \textit{NegF1}   & 0.5792 & 0.4845 & 0.2847 & 0.2420 & 0.2388 \\
         & \;\; \textit{PosF1}   & 0.3796 & 0.4334 & 0.4937 & 0.4635 & 0.5024 \\ \midrule
\FH      & Ma F1                 & 0.5093 & 0.4565 & 0.3688 & 0.2604 & 0.2986 \\
         & \;\; \textit{NegF1}   & 0.7465 & 0.5149 & 0.2462 & 0.0465 & 0.1304 \\
         & \;\; \textit{PosF1}   & 0.2720 & 0.3981 & 0.4913 & 0.4744 & 0.4667 \\ \bottomrule
\end{tabular}
}
\caption{Performance of zero-shot LLM prompting for readmission prediction. Note that we cannot calculate AUROC or AUPRC because our LLM evaluation setting only provides binary predictions and therefore, ranking of predictions is not possible.}\label{tab:zeroshotllm}
\end{table}

\subsection{Zero-shot LLM prompting}\label{sec:dis-zerollm}


Our approach is essentially a classification pipeline that employs LLMs for summarization before doing supervised training of a classifier. However, another straightforward approach would be using LLMs to directly predict readmission possibility. We tested the ability of an LLM, \texttt{Llama-3.1-8B-Instruct}, and report its performance on zero-shot short-term readmission prediction in Table~\ref{tab:zeroshotllm}.

The zero-shot results do not show superior performance when compared with supervised models. This is reasonable for the zero-shot prompting scenario as the LLM is unlikely to have been exposed to similar data during pre-training and thus cannot learn the distribution without labels.
To support this argument, %that the disparity between LLM predictions and the reference distribution contributes to underperformance, 
we examined the proportion of positive labels across LLM predictions, supervised model predictions, and gold-standard datasets, following \citealp{yoon2024lcd}, and plotted the results in Figure~\ref{fig:pos-ratio}.
Compared to the Transformer model predictions, the proportion of positive labels is notably misaligned in the LLM model predictions. This supports our assumptions that one of the reasons LLMs exhibit sub-optimal results is due to their misalignment with the true label distribution. 



%\subsection{Meaning of the information difference study (tentative title)}\label{sec:dis-meaning}


%Psychiatric discharge notes are written in subtle language, making it difficult for laypersons to understand or assess the quality of summarized notes accurately. Even for experts, evaluating loss of information by summarizing requires a significant amount of time and effort. This underlines the inherent difficulty in manually curating large-scale datasets for summarization tasks in this domain.

%While zero-shot approach provides alternatives to create datasets, the first half of this study showed that the  aspect-oriented summarized documents have non-overlapping information, suggesting that a single prompt may not fully extract all the important information available on the full original document. 

%Given these challenges, this paper proposes an alternative approach: instead of investing substantial resources in building a large, high-quality summarization dataset, a more practical strategy may be to generate multiple versions of summaries using various summarization models. This "\textit{\textbf{shotgun}}" approach increases the likelihood of including important information in at least one summary. By leveraging multiple summarization outputs, we can effectively utilize the benefit of automated summarization while minimizing the possibility of missing important information.


\section{Conclusion}
In this study, we explored a method for processing long documents using aspect-oriented summarization aimed to capture different views of the information of the original document. Our study provides three key insights: (1) we hypothesize that LLM summaries generated with different aspect-oriented prompts hold different details or \textit{information signals}, (2) we propose methods to measure these signals, (3) we investigate methods to effectively integrate signals from different types of summaries for supervised training of transformer models. We applied our methodology to the high-impact task of 30-day psychiatric re-admission prediction.


\section*{Limitations}

We collected datasets from four different sites in the US. Two of the most notable differences between those datasets are dataset size and the positive-label ratio. However, the datasets differ in the length of the notes. In this study, we did not account for these variations and leave it as future work.

This study utilized only one type of EHR documentation -- discharge notes. Other types of notes (e.g., progress notes) and additional data modalities (e.g., structured data) are available but not included in this paper. 
In terms of prompt diversity, our aspect-oriented summarization prompts could be further enriched with other critical aspects for readmission prediction, e.g. medications, trauma history and comorbidities. 
%remain only partially explored, and other critical aspects for readmission prediction—such as medication, trauma history, or comorbid physical conditions—require further investigation. This limitation reflects the study’s primary focus on proposing a framework and providing its foundational context.

Our current study is a research into the important topic of 30-day psychiatric readmission prediction. It is not an application ready for direct clinical applications. Such clinical applications require carefully designed clinical trials involving multiple domain experts. 



\section*{Acknowledgments}
%TODO-ANONYMIZE
This study was approved by \MGBfull Institutional Review Board.
Research reported in this paper was supported by National Institute of Mental Health of the National Institutes of Health under award number R01MH126977. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. 
This work was partially supported by Korean Institute for Advancement of Technology (KIAT) grant RS-2024-00435997. 
Chanwhi Kim participated in this work while he was visiting MLML Lab, lead by Tim Miller at Boston Children's Hospital and Harvard Medical School. 

All the experiments including data processing were conducted in HIPAA-compliant environments. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliography{custom}


\clearpage

\appendix
\onecolumn

\begin{center}
    {\LARGE Appendix}
\end{center}

\hspace{2em}

\section{Experimental details}\label{sec:appendix-exp-details}


\paragraph{Summarization:} Full discharge notes are summarized using a quantized version of mistral 7b instruct v0.2 \footnote{\texttt{mistral-7b-instruct-v0.2.Q4\_K\_M.gguf}} with \texttt{llama.cpp} library. Inference speed varies, but even for the largest dataset, processing was completed within a day on a workstation with a single NVIDIA GeForce RTX 4090 GPU. 
The generated summaries were always fewer than 512 tokens, and the median number of tokens varied by hospital and summary type, though all fell within the range of 256 to 356.

\paragraph{Supervised training:} For SVM with BOW features, we used the scikit-learn library \cite{scikit-learn}. For transformer models, we employed the Clinical NLP Transformers library \footnote{Available at: https://github.com/Machine-Learning-for-Medical-Language/cnlp\_transformers}, which wraps the Hugging Face Transformers library for training and testing~\cite{wolf_huggingfaces_2019}. For pretrained weights, we utilized the abstracts version of BiomedBERT \cite{pubmedbert}\footnote{\texttt{microsoft/BiomedNLP-BiomedBERT-base-uncased- abstract-fulltext}}. 


\section{Information difference for Clinical Longformer}\label{sec:appendix-infodiff}

\begin{figure*}[!h]
    \resizebox{\textwidth}{!}{
    % First graph
    \begin{subfigure}[b]{0.41\textwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/fig-infodiff-box-clf.pdf}
    \end{subfigure}
    
    %\vspace{1em} % Adjusts vertical spacing between the figures

    % Second graph
    \begin{subfigure}[b]{0.58\textwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/fig-results-all-four-clf.pdf}
    \end{subfigure}
    }
    \caption{Information difference for Clinical Longformer. The results are consistent with BiomedBERT results.}
    \label{fig:appendix-info-diff}
\end{figure*}

The number of iterated experiments is as follows: n=5 for models initialized with BiomedBERT and n=10 for models intialized with Clinical Longformer (CLF). 
%
Figure~\ref{fig:appendix-info-diff} shows the information difference scores for Clinical Longformer model outputs. The results are consistent with those provided in the main text, Section~\ref{sec:info-diff-results}.


\section{Statistics of iterated experiments}\label{sec:appendix-stat}



\begin{table*}[]
\centering
\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{llcccccc}
\toprule
Hospital & Summ Type & AUROC & AUPRC & MaAg\_F1 & \textit{Neg\_F1} & \textit{F1} & Group Size \\ 
\midrule
\McLean & Plain        & 0.0084 & 0.0162 & 0.0105 & 0.0225 & 0.0257 & 5 \\
       & Riskfactors  & 0.0101 & 0.0130 & 0.0097 & 0.0157 & 0.0296 & 5 \\
       & Timeline     & 0.0129 & 0.0156 & 0.0134 & 0.0384 & 0.0522 & 5 \\
       & Soft voting  & 0.0075 & 0.0150 & 0.0064 & 0.0133 & 0.0201 & 5 \\ \midrule
\MGH    & Plain        & 0.0265 & 0.0367 & 0.0150 & 0.0277 & 0.0344 & 5 \\
       & Riskfactors  & 0.0132 & 0.0142 & 0.0074 & 0.0238 & 0.0377 & 5 \\
       & Timeline     & 0.0371 & 0.0402 & 0.0213 & 0.0230 & 0.0500 & 5 \\
       & Soft voting  & 0.0164 & 0.0259 & 0.0217 & 0.0098 & 0.0446 & 5 \\ \midrule
\BWH    & Plain        & 0.0157 & 0.0147 & 0.0131 & 0.0286 & 0.0427 & 5 \\
       & Riskfactors  & 0.0200 & 0.0248 & 0.0360 & 0.0477 & 0.0764 & 5 \\
       & Timeline     & 0.0135 & 0.0118 & 0.0178 & 0.0251 & 0.0453 & 5 \\
       & Soft voting  & 0.0139 & 0.0094 & 0.0102 & 0.0308 & 0.0234 & 5 \\ \midrule
\FH     & Plain        & 0.0252 & 0.0195 & 0.0357 & 0.0595 & 0.1037 & 5 \\
       & Riskfactors  & 0.0413 & 0.0306 & 0.0173 & 0.0505 & 0.0484 & 5 \\
       & Timeline     & 0.0200 & 0.0222 & 0.0302 & 0.0198 & 0.0747 & 5 \\
       & Soft voting  & 0.0217 & 0.0074 & 0.0338 & 0.0066 & 0.0724 & 5 \\ 
\bottomrule
\end{tabular}%
}
\caption{Standard deviation of the performance of iterated supervised models, corresponding to the averages shown in Table~\ref{tab:perf-main} of the main paper. }
\label{tab:appendix-stat}
\end{table*}



The transformer model results in the Table~\ref{tab:perf-main} show averaged scores of 5 runs, and their standard deviation is in Table~\ref{tab:appendix-stat}.




\section{Supplementary results for Section~\ref{sec:dis-integ}}\label{sec:supp-dis-integ}

In this section we provide two tables to support the discussions in Section~\ref{sec:dis-integ}. 


\begin{table}[]
\centering
\resizebox{0.7\columnwidth}{!}{%
\begin{tabular}{l|l|cccccc}
\toprule
 % \multicolumn{2}{l}{Summarization methods} & \multicolumn{2}{c}{None (Full note)} & \multicolumn{2}{c}{Plain}  & \multicolumn{2}{c}{Riskfactors}  &   \multicolumn{2}{c}{Timelines}    & \multicolumn{2}{c}{Merged} \\ \toprule %\midrule
\multicolumn{2}{l}{Input type } & Plain           & Risk      & Time     & \textbf{\textit{Merge}} & \textbf{\textit{Soft V}} & \textbf{\textit{Any V}}  \\ \toprule
\McLean   & AUROC              & 0.587 & 0.525 & 0.569 & 0.576 & \bestsc{0.606} & \textbf{0.599} \\
         & AUPRC              & \bestsc{0.389} & 0.309 & 0.343 & 0.387 & \textbf{0.386} & 0.381 \\
         & Ma F1              & 0.556 & 0.510 & 0.532 & \textbf{0.560} & \bestsc{0.564} & 0.533 \\
         & \;\; \textit{NegF1}& 0.778 & 0.752 & 0.786 & 0.782 & 0.776 & 0.644 \\
         & \;\; \textit{PosF1}& 0.335 & 0.268 & 0.278 & 0.338 & 0.352 & 0.422 \\ \midrule
\MGH      & AUROC              & 0.633 & 0.584 & 0.615 & 0.612 & \bestsc{0.675} & \textbf{0.668} \\
         & AUPRC              & 0.440 & 0.372 & 0.417 & 0.417 & \bestsc{0.492} & \textbf{0.489} \\
         & Ma F1              & 0.595 & 0.556 & 0.583 & 0.585 & \textbf{0.601} & \bestsc{0.617} \\
         & \;\; \textit{NegF1}& 0.791 & 0.758 & 0.767 & 0.779 & 0.814 & 0.764 \\
         & \;\; \textit{PosF1}& 0.400 & 0.354 & 0.399 & 0.392 & 0.389 & 0.470 \\ \midrule
\BWH      & AUROC              & 0.547 & 0.540 & \textbf{0.563} & 0.543 & \bestsc{0.604} & 0.591 \\
         & AUPRC              & 0.373 & 0.372 & 0.395 & 0.369 & \bestsc{0.419} & \textbf{0.406} \\
         & Ma F1              & 0.530 & 0.514 & \textbf{0.537} & 0.527 & \bestsc{0.549} & 0.528 \\
         & \;\; \textit{NegF1}& 0.711 & 0.675 & 0.706 & 0.710 & 0.732 & 0.572 \\
         & \;\; \textit{PosF1}& 0.349 & 0.353 & 0.368 & 0.343 & 0.366 & 0.483 \\ \midrule
\FH       & AUROC              & 0.480 & 0.526 & \bestsc{0.526} & 0.483 & 0.507 & 0.506 \\
         & AUPRC              & 0.310 & 0.331 & \bestsc{0.348} & 0.310 & \textbf{0.333} & 0.322 \\
         & Ma F1              & 0.455 & \textbf{0.498} & 0.497 & 0.460 & 0.438 & \bestsc{0.499} \\
         & \;\; \textit{NegF1}& 0.758 & 0.745 & 0.757 & 0.765 & 0.775 & 0.662 \\
         & \;\; \textit{PosF1}& 0.152 & 0.251 & 0.237 & 0.155 & 0.100 & 0.336 \\ 
\bottomrule
\end{tabular}%               
}
\caption{Performance of the Clinical Longformer model evaluated using different summarization methods. 
The columns \textit{Soft V} and \textit{Any V} represent soft voting and any voting approaches, respectively.}
\label{tab:perf-clf}
\end{table}



%\section{Simple ensemble experiments}\label{sec:supp-ensemble-method}
%This section shows the results of ensemble experiments. (TODO)



\end{document}
