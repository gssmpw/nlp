\section{Reconstruction Attack when  $\nexamples$ is Unknown}\label{appendix:cp_model_n_unknown}

\subsection{Confidence Interval on $\nexamples$}

While reconstruction attacks targeting a complete dataset recovery in the literature generally assume knowledge of its size $\nexamples$~\cite{dwork2017exposed}, our approach can be slightly modified to be applicable without this information. In this section, we provide and empirically evaluate a CP formulation derived from the one presented in Section~\ref{sec:attack} that does not rely on knowing $\nexamples$. Note that while this setup is both more generic and more realistic, it is also more challenging.

When $\nexamples$ is unknown, it becomes a variable to infer. To bound the search, we will first calculate a confidence interval $\llbracket \nexamples_{\textsc{min}}, \nexamples_{\textsc{max}} \rrbracket$.
According to the DP RF algorithm in Section~\ref{sec:dp_rf}, each training example is used exactly once per tree. For a tree $\tree \in \forest$, the sum of the non-noisy leaves' counts equals $\nexamples$.
In our case, since the Laplace noise is centered at zero, for a tree $\tree \in \forest$, we can expect the sum $\nexamples_\tree^* = \smash{\sum\limits_{\node,\class} \nodesupport[\tree,\node,\class]^*}$ to lie close to $\nexamples$.

We know that the noisy counts are computed by the Laplace mechanism as follows:
\[
\nodesupport[\tree,\node,\class]^* = \textrm{int}(\nodesupport[\tree,\node,\class] + \noisevar_{\tree\node\class}) = \nodesupport[\tree,\node,\class]  +  \textrm{int}( \noisevar_{\tree\node\class}) ,
\]
in which $\noisevar_{\tree\node\class}$ is a random variable sampled from a Laplace distribution \( \text{Lap}(1 / \varepsilon_\node)\) and
$\textrm{int}(.)$ is the integer part function. Recall that the per-tree DP budget $\varepsilon_\node$ is computed by dividing the total privacy budget among the trees: $\varepsilon_\node = \varepsilon/\lvert \forest \rvert$.
The variance of each $\noisevar_{\tree\node\class}$ is $\text{Var}(\noisevar_{\tree\node\class}) = 2 / \varepsilon_\node^2$. Since the $\noisevar_{\tree\node\class}$ random variables are i.i.d., the variance of their sum $\sumnoisevars_\tree$ (whose $\nexamples_\tree^*$ is a realization) is:
\begin{align*}
     \text{Var}(\sumnoisevars_\tree) &= \text{Var}\left(\sum\limits_{\node \in \leaves[\tree]} \sum\limits_{\class \in \classes} \noisevar_{\tree\node\class}\right) 
     = \sum\limits_{\node \in \leaves[\tree]} \sum\limits_{\class \in \classes} \text{Var}(\noisevar_{\tree\node\class})    
    = \vert \leaves[\tree] \rvert \cdot \lvert \classes \rvert \cdot \frac{2}{\varepsilon_\node^2},
\end{align*} 
with a standard deviation:
\[
\sigma_{\nexamples_\tree^*} = \frac{\sqrt{2 \cdot \lvert \leaves[\tree] \rvert \cdot \lvert \classes \rvert}}{\varepsilon_\node}.
\]

Let $\nexamples^* = \frac{1}{\lvert \forest \rvert} \sum_{\tree \in \forest} \nexamples_\tree^*$ be the average noisy count across all trees. By the Central Limit Theorem, $\nexamples^*$ approximately follows a normal distribution for large $\lvert \forest \rvert$. Thus, the 95\% confidence interval $\llbracket \nexamples_{\textsc{min}}, \nexamples_{\textsc{max}} \rrbracket$ can be defined as:
\[
    \nexamples_{\textsc{max}} = \nexamples^* + t_{95} \frac{\sigma_{\sumnoisevars_\tree}}{\sqrt{\lvert \forest \rvert}} \quad \text{and} \quad \nexamples_{\textsc{min}} = \max\left(1,\nexamples^* - t_{95} \frac{\sigma_{\sumnoisevars_\tree}}{\sqrt{\lvert \forest \rvert}}\right),
\]
where $t_{95}$ is the Student's t-coefficient for a 95\% confidence level according to $\lvert \forest \rvert$.


\subsection{Adapted Constraint Programming Formulation}

As in the formulation presented in Section~\ref{sec:attack}, for each leaf $\node \in \leaves[\tree]$ of each tree $\tree \in \forest$, we let variables $\nodesupport[\tree,\node,\class] \in \{\max(0,\nodesupport[\tree,\node,\class]^*-\delta), \dots, \nodesupport[\tree,\node,\class]^* +\delta \}$ and $\Delta_{\tree\node\class } \in \{ -\delta, \dots, \delta \}$ respectively model the (guessed) number of examples of class $\class$ within this leaf, and the amount of noise added to it.
We also use variable $\smash{\widetilde{\nexamples}}\in\{\nexamples_{\textsc{min}},\dots, \nexamples_{\textsc{max}}\}$ encode the (guessed) number of reconstructed examples.

Since $\nexamples$ is unknown, we define variables for up to $\nexamples_{\textsc{max}}$ examples in the worst-case. For each example $\example \in \{1, \dots, \nexamples_{\textsc{max}}\}$, $\varx[\example,\feature] \in \{0,1\}$ represents the value of its attribute $\feature \in \{1, \dots, \nattributes\}$ in the reconstruction, while $\varz[\example,\class] \in \{0,1\}$ equals $1$ if and only if it belongs to class $\class$. Although these reconstruction variables are defined for $\nexamples_{\textsc{max}}$ examples, the attack's output is obtained from the first $\widetilde{\nexamples}$ examples.

Finally, we define a set of variables modeling the path of each example $\example \in \{1,\dots,\nexamples_{\textsc{max}}\}$ through each tree $\tree \in \forest$: variable $\varyb[\tree,\node,\example,\class] \in \{0,1\}$ indicates if it is classified in class $\class \in \classes$ by leaf $\node \in \leaves[\tree]$.
Given these variables, as previously, we define constraints to compute class counts and connect them to the assignments of examples to leaves:
\begin{align}
    &\sum\limits_{\node \in \leaves[\tree]} \sum\limits_{\class \in \classes} \nodesupport[\tree,\node,\class] = \widetilde{\nexamples} &\tree \in \forest \label{constr_count_sum_N_bis}\\
     &\sum\limits_{\class \in \classes}\varz[\example,\class]=1 &\example \in \{1,\dots,\nexamples_{\textsc{max}}\}\label{constr_exactly_one_class_bis}\\
    &\varz[\example,\class] = 0 \Rightarrow\sum\limits_{\tree \in \forest} \sum\limits_{\node \in \leaves[\tree]} \varyb[\tree,\node,\example,\class] = 0 &\example \in \{1,\dots,\nexamples_{\textsc{max}}\},~\class \in \classes\label{constr_not_in_class_counts_bis}\\
    &\example > \widetilde{\nexamples}  \Rightarrow\sum\limits_{\tree \in \forest} \sum\limits_{\node \in \leaves[\tree]}\sum\limits_{\class \in \classes} \varyb[\tree,\node,\example,\class] = 0 &\example \in \{1,\dots,\nexamples_{\textsc{max}}\}\label{constr_N_examples_in_reco}\\
    & \sum_{\example=1}^{\smash{\nexamples_{\textsc{max}}}} \varyb[\tree,\node,\example,\class] =\nodesupport[\tree,\node,\class] &\tree \in \forest,~\node \in \leaves[\tree],~\class \in \classes\label{constr_counts_flow_bis}
\end{align}
Constraint~\eqref{constr_count_sum_N_bis} ensures that the examples' counts sum up to $\widetilde{\nexamples}$ within each tree. Constraint~\eqref{constr_exactly_one_class_bis} guarantees that each example is associated to exactly one class. Constraint~\eqref{constr_not_in_class_counts_bis} enforces that each example can only contribute to the counts of its class. Note that this constraint differs from the formulation presented in Section~\ref{sec:attack}. Indeed, if $\varz[\example,\class] = 1$ but $\example > \widetilde{\nexamples}$, example $\example$ is actually not part of the reconstructed dataset, and hence is not assigned to any leaf of any tree, as stated in Constraint~\eqref{constr_N_examples_in_reco}.
Constraint~\eqref{constr_counts_flow_bis} ensures consistency between the examples' assignments to the leaves, and the (guessed) counts.

Finally, the rest of the model remains unchanged, the following constraint enforces consistency between the examples' assignments to the leaves, and the value of their attributes:
\begin{align}
\sum\limits_{\class \in \classes} \varyb[\tree,\node,\example,\class] = 1 \Rightarrow &\left(\displaystyle\bigwedge_{i\in\Phi_v^+} \varx[k,i] = 1 \right) \wedge
\left( \displaystyle\bigwedge_{i\in \Phi_v^-} \varx[k,i] = 0 \right) & \tree \in \forest,~\node \in \leaves[\tree],~\example \in \{1,\dots,\nexamples_{\textsc{max}}\},\label{constr_flow_attr_values_bis}
\end{align}
and the original objective is retained with $\Delta_{\tree\node\class} = \nodesupport[\tree,\node,\class]^{*} - \nodesupport[\tree,\node,\class]$:
\begin{align}
    \max \ \sum\limits_{\tree \in \forest}\sum\limits_{\node \in \leaves[\tree]} \sum\limits_{\class \in \classes} \sum\limits_{\noiseval = -\delta}^{\delta} \log(p_\noiseval) \mathds{1}_{\Delta_{\tree\node\class} = \noiseval}.
\end{align}

\subsection{Experimental Evaluation} 

To assess the effectiveness of our reconstruction attack in a context where the number of training examples $\nexamples$ is unknown, we reproduce the experimental setup as described in Section~\ref{subsec:setup}, using our modified attack formulation introduced in the previous subsection. The computation of the reconstruction error must be slightly adapted. When $\nexamples$ is known, the attack's performance is assessed by determining the correspondence between reconstructed and original examples using a minimum-cost matching. The average distance between these matched pairs defines the reconstruction error.
However, when $\nexamples$ is unknown, it is possible that the inferred reconstruction contains more (or less) than $\nexamples$ examples, making this pairwise matching not directly applicable. In the case where the number of reconstructed examples exceeds the actual one ($\widetilde{\nexamples} > \nexamples$), we randomly duplicate some (true) training examples. In contrast, if the number of reconstructed examples is smaller than the actual one ($\widetilde{\nexamples} < \nexamples$), we randomly subsample the same number of examples from the original training set. The same minimum-cost matching is then performed, and the average distance between pairs of matched examples defines the reconstruction error. 

The results of these experiments are presented in Table~\ref{tab:error-values_N_var} for all datasets, forest sizes $\lvert \forest \rvert$, and tree depths $\depth$. Comparing these results with those in Table~\ref{tab:error-values} reveals two key trends. First, a few runs failed to retrieve a feasible reconstruction within the given time frame ($2$ hours), indicating that the attack is computationally more expensive in this setup. 
This is expected, as the modified CP model introduces additional variables and constraints, leading to a larger search space and calling for longer solution times. Still, in most cases, the attack finds a feasible reconstruction. 
Second, and more importantly, the reconstruction error remains comparable to the case where $\nexamples$ is known. Despite the increased computational cost, the attack is still able to retrieve meaningful information encoded by the forest regarding its training data in most cases, thereby confirming our \textbf{Result 5}.

\input{summary_table_N_unknown}

\clearpage 

\section{Determining a Search Interval for Noise Values}\label{appendix:width_delta_search_interval}

Rather than modeling all possible (integer) random noise values $\noisevar_{\tree\node\class}$ within $\mathbb{Z}$, our CP model focuses on a (sufficient) predefined range $\{ -\delta,\dots, \delta \}$ such that $\mathbb{P}(\textrm{int}(\noisevar_{\tree\node\class}) \in \{ -\delta,\dots, \delta \} ) \geq 0.999$. In practice, we use $\delta = \lceil 12 / \varepsilon_\node \rceil$. 
As displayed in Figure~\ref{intervalle_recherche}, this value is suitable for all considered privacy budgets $\varepsilon_\node$. Indeed, it always leads to the definition of slightly wider search intervals for the variables modelling the noise, theoretically guaranteeing that the probability of the actual noise value being within it is greater than $0.999$.

\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
    \centerline{\includegraphics[width=0.6\columnwidth]{epsilon_delta.pdf}}
    \caption{Width of $\Delta_{\tree\node\class }$ search interval as a function of $\varepsilon_v$. 
    As expected, the magnitude of the noise added decreases when the privacy budget increases, resulting in a smaller search interval.}
    \label{intervalle_recherche}
    \end{center}
    \vskip -0.2in
\end{figure}


\section{Trade-offs between Predictive Performance and Reconstruction Error -- Detailed Results}\label{appendix:complete_results_tradeoffs_perf_reconstr_error}

Figures~\ref{fig:results_all_tradeoffs_predictive_perf_vs_recontr_error} and \ref{fig:results_all_tradeoffs_predictive_perf_vs_recontr_error_bis} present the detailed trade-offs between the RFs' predictive performance and the empirical reconstruction error of our attack across all experiments. These figures confirm the key trends discussed in the main paper, particularly \textbf{Results 3 \& 4}, and are consistent across all datasets, privacy budgets, tree depths, and forest sizes. In particular, most RFs are located either in the top-left or bottom-right corners of the plots. The top-left region corresponds to RFs with non-trivial predictive performance, giving some advantage to the reconstruction attack, while the bottom-right region includes RFs that provide no significant advantage for the reconstruction attack but perform worse than a majority classifier. Interestingly, the few RFs that exhibit non-trivial predictive performance while remaining resilient to reconstruction attacks (top-right corner) are either the sparsest ($\lvert \forest \rvert = 1$) or the largest ($\lvert \forest \rvert = 20$ or $\lvert \forest \rvert = 30$). 

\begin{figure*}[htb]
\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_adult_train_accuracy_vs_error_depth_3.pdf}
    \caption{UCI Adult Income dataset, depth 3 decision trees.} \label{fig:results_tradeoffs_acc_reconstr_adult_depth_3}
\end{subfigure}%
\hfill
 \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_adult_train_accuracy_vs_error_depth_5.pdf}
    \caption{UCI Adult Income dataset, depth 5 decision trees.}
\label{fig:results_tradeoffs_acc_reconstr_adult_depth_5}
\end{subfigure}%

\vspace{10pt}

\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_adult_train_accuracy_vs_error_depth_7.pdf}
    \caption{UCI Adult Income dataset, depth 7 decision trees.}
    \label{fig:results_tradeoffs_acc_reconstr_adult_depth_7}
\end{subfigure}
\hfill
\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_compas_train_accuracy_vs_error_depth_3.pdf}
    \caption{COMPAS dataset, depth 3 decision trees.}
    \label{fig:results_tradeoffs_acc_reconstr_COMPAS_depth_3}
\end{subfigure}

\vspace{10pt}

\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_compas_train_accuracy_vs_error_depth_5.pdf}
    \caption{COMPAS dataset, depth 5 decision trees.}
    \label{fig:results_tradeoffs_acc_reconstr_COMPAS_depth_5}
\end{subfigure}
\hfill
\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_compas_train_accuracy_vs_error_depth_7.pdf}
    \caption{COMPAS dataset, depth 7 decision trees.}
    \label{fig:results_tradeoffs_acc_reconstr_COMPAS_depth_7}
\end{subfigure}

\vspace{10pt}

\begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=0.6\linewidth]{legend_tradeoffs.pdf}
\end{subfigure}
\caption{Average training accuracy of $\varepsilon$-DP RFs as a function of the reconstruction error of our attack for different numbers of trees $\vert \forest \rvert$ and privacy budgets $\varepsilon$, for the considered datasets and tree depths values.}\label{fig:results_all_tradeoffs_predictive_perf_vs_recontr_error}
\end{figure*}

\begin{figure*}[t!] %\ContinuedFloat
\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_default_credit_train_accuracy_vs_error_depth_3.pdf}
    \caption{Default of Credit Card Clients dataset, depth 3 decision trees.}
    \label{fig:results_tradeoffs_acc_reconstr_default_credit_depth_3}
\end{subfigure}
\hfill
\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_default_credit_train_accuracy_vs_error_depth_5.pdf}
    \caption{Default of Credit Card Clients dataset, depth 5 decision trees.}
    \label{fig:results_tradeoffs_acc_reconstr_default_credit_depth_5}
\end{subfigure}

\vspace{10pt}

\hfill
\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\linewidth]{N_fixed_default_credit_train_accuracy_vs_error_depth_7.pdf}
    \caption{Default of Credit Card Clients dataset, depth 7 decision trees.}
    \label{fig:results_tradeoffs_acc_reconstr_default_credit_depth_7}
\end{subfigure}
\hfill
\vspace{10pt}

\begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=0.6\linewidth]{legend_tradeoffs.pdf}
\end{subfigure}

\caption{Average training accuracy of $\varepsilon$-DP RFs as a function of the reconstruction error of our attack for different numbers of trees $\vert \forest \rvert$ and privacy budgets $\varepsilon$, for the considered datasets and tree depths values (continued).}\label{fig:results_all_tradeoffs_predictive_perf_vs_recontr_error_bis}
\end{figure*}