\section{Our Method}\label{sec:method}

To address the challenges mentioned above, we propose \textbf{S}tructured-\textbf{Pru}ning-based Sparse \textbf{F}ine-\textbf{T}uning (SPruFT), as illustrated in Figure~\ref{fig:method}. This is a novel approach designed to streamline computation graphs and eliminate the need for dropout layers. This method ensures memory efficiency while maintaining competitive fine-tuning performance. 

\begin{figure}[htbp]
\begin{center}
%\vspace{-0.2cm}
\includegraphics[width=\linewidth]{figures/my_method.pdf}
%\vspace{-0.8cm}
\caption{The illustration of SPruFT: we evaluate the importance score for each neuron to select the fine-tuning indices. Then we construct the lower-dimensional fine-tuning parameter matrix $\W_f$.}\label{fig:method} %\vspace{-0.4cm}
\end{center}
\end{figure}
\unskip

\subsection{Proposed Method} \label{subsec:method}

SPruFT utilizes structured neural network pruning to select a subset of the parameters for fine-tuning. NN pruning methods have been studied extensively (see Section~\ref{sec:related}) with the goal of reducing the size of a network (often fewer neurons) while preserving accuracy. These methods develop techniques for identifying neurons that are \emph{important} for a given task. Our key insight is to use these importance metrics to indicate which neurons to focus on during fine-tuning. Note that, unlike pruning, where importance often reflects a neuron's role in the \emph{original} task, here it pertains to the downstream \emph{fine-tuning} task,  which may have a different input distribution and loss. In Section~\ref{subsec:importance}, we discuss various importance metrics from pruning research and discuss their use in fine-tuning. 

Our method selects the top-$r$ important neurons based on an importance score ${\bm \eta}$, where $r$ is determined by the desired number of fine-tuning parameters. It follows that the choice of importance matric becomes crucial, which we discuss in Section~\ref{subsec:importance}. Let the top $r$ neuron indices be $i_1, i_2, \dots, i_r$. After obtaining ${\bm \eta}$, we next construct a lower-dimensional parameter matrix $\W_f\in\R^{r\times d_{in}}$, with the row selection matrix $\M_{i_{j}j}=1$ for all $j \in [r]$ and zeros elsewhere. Using notations from Section~\ref{sec:related}, we initialize $\W_f$ to zero and  define the final parameters $\hat{\W}$ as \Eqref{eq:sft_w} where $\W_s= \M\W_f$. 

Let us now examine how to implement the forward to make backpropagation memory-efficient\footnote{While updating the corresponding rows of $\W$ is the most efficient training, updating $\W_s$ provides more flexibility for adapting multiple tasks, see discussion in LoRA~\cite{hulora}.}. If the computation graph were to pass through $\W + \M \W_f$ (as a na\"ive implementation would), the gradients would be computed for all $d_{in} \times d_{out}$ parameters, which is redundant. Instead, we use the additivity of the forward function: we have, analogous to the setting of LoRA,
\begin{align}
    f(\hat{\W},\x)&= f(\W + \M\W_f,\x) =  f(\W,\x) +  f(\M\W_f,\x),\label{eq:SPruFT_fwd}
\end{align}
As $\W$ remains frozen during fine-tuning, backpropagation only needs to keep track of the derivatives of the second term on the RHS. In addition, $\M$ is now a \emph{fixed} matrix, so the only trainable parameters are those in $\W_f$ and $f(\W_f,\x)$ will not be cached, while LoRA requires the cache of $f(\A,\x)$ for computing $\frac{\partial \h}{\partial \B}$ (backpropagation,~\citealt{rumelhart1986learning}). Besides, as an SFT framework, our method does not rely on any dropout layer, which also saves a huge amount of memory. We explain this in detail in Appendix~\ref{apdx:cache} and we show that the benefits in terms of memory cost are significant in Section~\ref{subsec:results_LLM}. 

An important strength of our approach is its flexibility: it can easily incorporate any desired choice of importance metrics. On the other end, it can also incorporate new ideas in PEFT research. For example, quantization (QLoRA,~\citealt{dettmers2024qlora}), parameter sharing (VeRA,~\citealt{kopiczko2024vera}), and combining SFT with LoRA (RoSA,~\citealt{nikdan2024rosa}) can be used. 

\subsection{Importance Metrics} \label{subsec:importance}

Importance evaluation plays a crucial role in our approach, as discussed above. We try various choices in our work: the first is the simple $\ell_2$ norm of the weight vector corresponding to each neuron; the second is the widely-used Taylor importance~\citep{lecun1989optimal}. By considering the gradients, Taylor importance captures more information about the input distribution as well as the relevance of a neuron for the fine-tuning task of interest (which can be different from the original model). We also consider different variants of Taylor importance, as we discuss below. We remark that norm-based importance can be quite powerful on its own, as is the case with norm-sampling in the matrix approximation literature~\citep{frieze-kannan}. %We also note that the variants of Taylor importance we suggest in this study can also be applied to NN pruning.  

\subsubsection{Class Aware Taylor Importance} \label{subsubsec:QMTaylor}
In our experiments on image classification tasks, we also consider a ``class aware'' variant of Taylor importance, which may be of independent interest. The motivation here comes from the observation that the importance of a neuron may depend on the class of an input example (as a toy example, a whisker-detecting neuron may be very important to the cat class, but not much to others; hence not too important on average). Another motivation comes from the observation that when we perform a vanilla (class agnostic) fine-tuning, the accuracy of some classes can be much worse than others --- an undesirable outcome. This is shown in Table~\ref{tab:labelwise_acc}. 

\begin{table}[htbp]
\tiny
\begin{center}
\begin{tabular}{l|c|c|cccccccccccl}\toprule
& \#labels & Mean & Min & Q1 & Med & Q3 & Max \\\midrule
CIFAR100 & 100 & 90.18 & 65 & 88 & 92 & 95 & 99 \\\midrule
Tiny-ImageNet & 200 & 87.55 & 62 & 84 & 88 & 92 & 100\\\bottomrule

\end{tabular}
%\vspace{-0.2cm}
\caption{The distribution of accuracies across different labels is summarized by statistics including the minimum (Min), first quartile (Q1), median (Med), third quartile (Q3), and maximum (Max) accuracies. \#labels is the number of labels. The reported accuracies are the validation results of full fine-tuning DeiT for 5 epochs. Models and Datasets are described in Section~\ref{sec:setup}.} \label{tab:labelwise_acc} 
\end{center}
\end{table}


%In practice, Taylor importance is not well-suited for LLMs because of the memory overhead required for computing gradients. Except for magnitude and Taylor importance, we also apply a modified Taylor  importance to image classification tasks as we observed that accuracies across labels tend to be significantly varies, as shown in Table~\ref{tab:labelwise_acc}. 
We define the class-wise Taylor importance as follows: for neuron $i$ and label $t$,
\begin{equation}
    {\bm \eta}_i^{t} := |L(\mathcal{D}^{t}, \Acute{F}_{\boldsymbol{c}_i}) - L(\mathcal{D}^{t}, F)|\approx |\w^\top \nabla_{\w} L(\mathcal{D}^{t}, F)|, \label{eq:qmtaylor_label}
\end{equation}
where $F$ is the forward function of the entire model, $L(\mathcal{D}^{t}, F)$ denotes the average loss of $F$ over inputs in class $t$, $\Acute{F}_{\boldsymbol{c}_i}$ represents the forward without channel/neuron $\boldsymbol{c}_i$, and $\w$ is the parameter vector of channel $\boldsymbol{c}_i$. One natural choice of importance of neuron $i$ motivated by the above discussion is $\max_t {\bm \eta}_i^t$. We find that this score is ``too sensitive'' (importance of neurons may be over-estimated because of just one class), leading to lower overall accuracy. On the other hand, the average (over $t$) of ${\bf \eta}_i^t$ corresponds to the standard Taylor importance. We find that the intermediate quantity of \emph{Quantiles-Mean}, defined as the average of the $0\%, 10\%, 20\%, \dots, 100\%$ quantiles of the ${\bm \eta}_i^t$, works well in reducing the accuracy imbalance across labels, and also achieving a high overall accuracy. Formally,
\begin{equation}
    {\bm \eta}_i=\frac{\sum_{l=0}^{10}Q_l(\{{\bm \eta_i}^{t}\}_{t=1}^{p})}{11},\label{eq:qmtaylor_mean}
\end{equation}
where $Q_l$ represents the $l \times 10$-th quantile.   % aims to mitigate the accuracy imbalance across labels:
%\begin{align}
%    &{\bm \eta}_i^{t}=|L(\mathcal{D}^{t}, F - {\boldsymbol{c}_i}) - L(\mathcal{D}^{t}, F)|\approx |\w^\top \nabla_{\w} L(\mathcal{D}^{t}, F)|, \label{eq:qmtaylor_label}
%    \\&{\bm \eta}_i=\frac{\sum_{k=0}^{10}Q_k(\{{\bm \eta_i}^{t}\}_{t=1}^{p})}{11},\label{eq:qmtaylor_mean}
%\end{align}
%where ${\bm \eta}_i^{t}$ is the importance score of label $t$ with the number of labels $p$, , and $Q_k$ represents the $k$-th $10$-quantile. 
See Appendix~\ref{apdx:imp} for more details. %(We also note that if one only cares about the overall accuracy, standard Taylor importance suffices in all our experiments.)

\subsubsection{Zero-Order Taylor Importance} \label{subsubsec:ZOTaylor}
As discussed, Taylor importance can incorporate information about the data distribution and the fine-tuning task when evaluating important neurons. However, for large models like Llama-3, it turns out that the computational overhead required for computing Taylor importances is prohibitively large!\footnote{The Taylor importance here refers to computing the exact value without relying on approximations of the importance score or the gradient matrix used for deriving the importance score.} In these cases, we apply the idea from the memory-efficient zeroth-order optimizer (MeZO,~\citealt{malladi2023fine}) to estimate the gradient in Taylor importance. % and compare the results with the norm (or magnitude) of the weight vector per neuron as the importance score. 
The classical Zeroth-Order (ZO) setting is defined as below. 

\begin{definition}[Simultaneous Perturbation Stochastic Approximation or SPSA~\cite{spall1992multivariate}]
Given a model \(F\) with parameters $\mathbf{\theta}\in \mathbb{R}^{d}$ and a loss function $L$, SPSA estimates the gradient on a dataset $\mathcal{D}$ as 
\[\hat{\nabla} L(\mathbf{\theta}, \mathcal{D}) = \frac{L(\mathbf{\theta} + \epsilon\z) - L(\mathbf{\theta} - \epsilon\z)}{2\epsilon}\z, \]
where $\z\in\mathbb{R}^{d}$ is drawn from $\z\sim \mathcal{N}(0, \mathbf{I}_d)$, and $\epsilon$ is the scale of the perturbation.  %\footnote{The initial SPSA algorithm \cite{spall1992multivariate} perturbs the model by $1/\z$, which precludes the choice of $\z$ as Gaussian. We follow the suggestion from previous works~\cite{duchi2015optimal, nesterov2017random, liu2020primer, malladi2023fine} to generate $\z$ from Gaussian distribution.} and $\epsilon$ is the perturbation scale. 
The $n$-SPSA estimate averages $\hat{\nabla} L(\mathbf{\theta}, \mathcal{D})$ over $n$ randomly sampled $\z$. Note that as $\epsilon \rightarrow 0$, the estimate above converges to $\z (\z^\top \nabla L(\mathbf{\theta}, \mathcal{D}))$, which is equal to $\nabla L(\mathbf{\theta}, \mathcal{D})$ in expectation.
\end{definition}
By applying SPSA, the Zero-Order Taylor (ZOTaylor) importance can be defined as follows: 
\begin{equation}
    {\bm \eta} := |\mathbf{\theta}^\top \hat{\g}|.\label{eq:qmtaylor_label}
\end{equation}
where we denote $[\nabla L(\mathbf{\theta}, \mathcal{D})]$ and its estimate as $\g$ and $\hat{\g}$ for convenience.

A na\"ive implementation of SPSA still requires twice the memory of inference because of the need to store $\z$. However, MeZO uses the trick of regenerating $\z$ dynamically using a random seed (of much smaller size than the model), thus eliminating the storage and ensuring memory usage that is equal to that of inference. We now assess the effectiveness of ZOTaylor for our LLM.
%SPSA offers significant memory efficiency over direct gradient computation. However, classical SPSA still requires twice the memory of inference due to storing the perturbation vector $\z$. Fortunately, MeZO allows us to further reduce memory usage by regenerating $\z$ dynamically using a random seed, eliminating storage needs. This ensures memory consumption remains equal to inference. With this memory-efficient ZOTaylor for our LLM, we now assess its effectiveness.

\begin{property}[] \label{SPSA_property}
$n$-SPSA is an unbiased and consistent estimator with the variance $\mathbf{\sigma}^2$ where 
\[\mathbf{\sigma}_i^2 = \frac{\g_i^2 + \sum_{l=1}^d \g_l^2}{n}.\] 
\end{property}
Property~\ref{SPSA_property} can be proved by simply noting that the covariance matrix of $\z$ is $\mathbf{I}_d$, details can be found in Appendix~\ref{apdx:imp}. With this property, we know that $n$-SPSA can accurately estimate the gradient. However, the variance can be large when  $d$ is large. Here, we first note that since we aim to find the most important neurons, we do not care about the gradient estimate itself. That is, given $\g_i>\g_j$, our goal is to have a higher probability $\Pr[\hat{\g}_i-\hat{\g}_j>0]$ which is exactly equal to: 
\begin{align}
    \Pr_{Z \sim \mathcal{N}(0,1)} [Z>-\frac{\g_i-\g_j}{\sqrt{(\sigma_i^2+\sigma_j^2)/2}}]. \label{eq:SPSA_prob}
\end{align}
The lower bound of Equation~\ref{eq:SPSA_prob} is $0.5$ and the probability will close to $0.5$ when the variance is large or when $\g_i$ and $\g_j$ are too close to one another. In our experiments, the values of $\hat{\g}$ from single SPSA lie in $[-100,100]$ with variances ranging from $10^7$ to $10^8$, thus the probability above turns out to be too close to $0.5$.

To address this issue, we utilize a simple but highly effective strategy~\citep{j2015variance}: we partition the training data into $k$ calibration sets. For each calibration set, we generate $n$ distinct perturbations $\z$ to perform $n$-SPSA, yielding $n\times k$ gradient estimates. Consequently, the variance of $n$-SPSA is effectively reduced to $\frac{\g_i^2 + \sum_{l=1}^d \g_l^2}{nk}$.\footnote{We note that this is not a formal guarantee; indeed, if $k$ is too large or the dataset is too small, there is additional variance across calibration sets that will become significant.} In our experiments, we set $n=5$ and $k=256$, where the variances fall within the range of $[10^4, 10^5]$, leading to a normalized value $-\frac{\g_i-\g_j}{\sqrt{(\sigma_i^2+\sigma_j^2)/2}}$ being approximately $-1$, which corresponds to the probability $\Pr[Z>-\frac{\g_i-\g_j}{\sqrt{(\sigma_i^2+\sigma_j^2)/2}}]$ being close to $0.84$. 

Importantly, our objective is to select most of the top-$x$\% important neurons (for appropriate $x$), rather than ensuring the strict selection of all top-ranked neurons. Thus, the probability $\Pr[\hat{\g}_i-\hat{\g}_j>0]$ for any specific $(i,j)$-pair does not need to be excessively high. A rigorous theoretical analysis of the optimal probability threshold is an interesting open direction. In this study, we primarily focus on demonstrating the feasibility of applying ZO-based approaches to importance metrics.