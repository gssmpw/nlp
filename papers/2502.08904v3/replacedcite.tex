\section{Related Work}
\begin{figure}[t]
    \includegraphics[height=4.5cm,width=7.8cm]{code-3.pdf}
    \centering
    \caption{The Correspondence Between Event-Driven 
Text and Programming Language.}
    \label{fig:compare}
    \end{figure}


\subsection{Synthetic Data to Reduce Hallucinations}

Recent investigations indicate that hallucination phenomena in large language models (LLMs) may stem from inherent issues within the training data. This highlights the necessity for high-quality reasoning datasets to mitigate these inconsistencies ____. Notable examples include LOGIQA ____, a dataset of logical reasoning derived from the Chinese Civil Service Examination; RECLOR ____ and AR-LSAT ____, based on standardized graduate admissions exams; and FOLIO ____, a dataset featuring first-order logic annotations. However, the resource-intensive and time-consuming nature of their creation limits the scalability and accessibility of training applications.

As a result, researchers are increasingly exploring synthetic data as a viable alternative ____. Significant synthetic mathematical datasets include KPDDS, OpenMathInstruct-1, and MathGenie ____. KPDDS synthesizes question-answer pairs using key points and exemplars, yielding KPMath, which encompasses over one million pairs. OpenMathInstruct-1 comprises 1.8 million problem-solution pairs synthesized from code-interpreter solutions for GSM8K and MATH benchmarks via the Mixtral model. MathGenie enhances a seed dataset by generating new questions through a back-translation approach. Despite these advancements, synthetic datasets are often tailored to specific tasks, particularly mathematics, which may restrict their generalizability and performance across diverse real-world applications. This underscores the necessity for further research to broaden their applicability.

    
\subsection{COT Data to Reduce Hallucinations}


Based on the investigation of synthetic datasets, Chain-of-Thought (CoT) strategies have also reduced hallucinations during reasoning tasks ____. Some research has synthesized reasoning data in the field of logical reasoning ____ while providing the reasoning process ____ during synthesis. For example, LOGIC-LM integrates LLMs with symbolic solvers, transforming natural language problems into symbolic formulations to minimize inconsistencies ____. Similarly, SymbCOT enhances CoT prompting by incorporating symbolic expressions and logical rules ____.


The expressiveness of symbolic solvers limits the applicability of these models. Not all problems can be easily encoded in first-order logic, and complexities may arise when dealing with intricate grammatical structures, such as those found in probabilistic soft logic. Therefore, while these approaches show promise, they have constraints in flexibility and generalizability, highlighting the need for solutions that can effectively address a broader range of reasoning scenarios.


\subsection{Code Data to Reduce Hallucinations}


Recent research has shown that training large language models (LLMs) on code datasets can reduce in-consistent hallucinations. Notable models such as CoCoGen and CodeRL have enhanced performance in structured reasoning and code generation by leveraging the strict syntax and semantics inherent in programming languages ____. However, the benefits observed in code-related tasks do not readily extend to general natural language processing (NLP) tasks due to the fundamental semantic differences between the two domains.


Innovative approaches like Program of Thought (PoT) utilize LLMs, particularly Codex, to express reasoning processes as programs while offloading computational tasks to external systems ____. Despite this novel framework, PoT may encounter challenges in contexts where translating natural language into code is not straightforward, which can introduce potential errors. Similarly, Program-Aided Language Models (PAL) enable LLMs to decompose natural language problems into executable steps, delegating execution to environments such as Python interpreters ____. While this structural separation simplifies the model's role, it also restricts its ability to engage in comprehensive reasoning, making it susceptible to errors during decomposition. Consequently, the effective transfer of logical consistency gained from code training to broader NLP applications remains an open challenge, highlighting the need for further research.





\begin{figure*}[t]
    \includegraphics[height=3cm,width=16cm]{code4444.pdf}
    \centering
    \caption{An overview of our proposed framework begins with filtering event-based text, followed by cyclic generation training of event-based text and parallel code based on their transformation relationship. In each iteration, a quality evaluation module is employed to assess the quality of the generated parallel code until multiple iterations result in improved capabilities in parallel corpus generation, ultimately achieving alignment between the two corpora.}
    \label{fig:prompt2}
    \end{figure*}



% \begin{figure*}[t]
%     \includegraphics[height=6cm,width=17.1cm]{figures/code4.pdf}
%     \centering
%     \caption{An overview of our proposed framework. The upper section describes how to generate high-quality text-code parallel corpus. The lower section presents a sample of a real text-code parallel corpus, illustrating the construction of two classes, `Person` and `PublishingCompany`, along with their defined attributes. By instantiating these classes, we capture the factual descriptions in the text. Additionally, the diagram demonstrates the strategy for iterative predictive training using text-code alignment, aimed at bridging the two semantic spaces and transferring the rigorous contextual coherence present in the code data to the text tasks.}
%     \label{fig:prompt2}
%     \end{figure*}