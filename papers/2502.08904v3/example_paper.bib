

@inproceedings{amayuelas2022neural,
  title={Neural Methods for Logical Reasoning over Knowledge Graphs},
  author={Amayuelas, Alfonso and Zhang, Shuai and Rao, Susie Xi and Zhang, Ce},
  booktitle={The Tenth International Conference on Learning Representations (ICLR 2022)},
  year={2022},
  organization={OpenReview}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{pan2023logic,
  title={Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning},
  author={Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={3806--3824},
  year={2023}
}

@article{sun2023indeterminacy,
  title={From indeterminacy to determinacy: Augmenting logical reasoning capabilities with large language models},
  author={Sun, Hongda and Xu, Weikai and Liu, Wei and Luan, Jian and Wang, Bin and Shang, Shuo and Wen, Ji-Rong and Yan, Rui},
  journal={arXiv preprint arXiv:2310.18659},
  year={2023}
}

@inproceedings{gaur2023reasoning,
  title={Reasoning in Large Language Models Through Symbolic Math Word Problems},
  author={Gaur, Vedant and Saunshi, Nikunj},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={5889--5903},
  year={2023}
}

@inproceedings{golovnevaroscoe,
  title={ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning},
  author={Golovneva, Olga and Chen, Moya Peng and Poff, Spencer and Corredor, Martin and Zettlemoyer, Luke and Fazel-Zarandi, Maryam and Celikyilmaz, Asli},
  booktitle={The Eleventh International Conference on Learning Representations}
}

@inproceedings{ribeirostreet,
  title={STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK},
  author={Ribeiro, Danilo Neves and Wang, Shen and Ma, Xiaofei and Zhu, Henghui and Dong, Rui and Kong, Deguang and Burger, Juliette and Ramos, Anjelica and Wang, William Yang and Karypis, George and others},
  booktitle={The Eleventh International Conference on Learning Representations}
}

@article{liu2023logiqa,
  title={Logiqa 2.0—an improved dataset for logical reasoning in natural language understanding},
  author={Liu, Hanmeng and Liu, Jian and Cui, Leyang and Teng, Zhiyang and Duan, Nan and Zhou, Ming and Zhang, Yue},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2023},
  publisher={IEEE}
}

@article{zhong2021ar,
  title={Ar-lsat: Investigating analytical reasoning of text},
  author={Zhong, Wanjun and Wang, Siyuan and Tang, Duyu and Xu, Zenan and Guo, Daya and Wang, Jiahai and Yin, Jian and Zhou, Ming and Duan, Nan},
  journal={arXiv preprint arXiv:2104.06598},
  year={2021}
}

@inproceedings{yureclor,
  title={ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning},
  author={Yu, Weihao and Jiang, Zihang and Dong, Yanfei and Feng, Jiashi},
  booktitle={International Conference on Learning Representations}
}


@article{lu2024mathgenie,
  title={Mathgenie: Generating synthetic data with question back-translation for enhancing mathematical reasoning of llms},
  author={Lu, Zimu and Zhou, Aojun and Ren, Houxing and Wang, Ke and Shi, Weikang and Pan, Junting and Zhan, Mingjie and Li, Hongsheng},
  journal={arXiv preprint arXiv:2402.16352},
  year={2024}
}

@article{huang2024key,
  title={Key-point-driven data synthesis with its enhancement on mathematical reasoning},
  author={Huang, Yiming and Liu, Xiao and Gong, Yeyun and Gou, Zhibin and Shen, Yelong and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2403.02333},
  year={2024}
}

@inproceedings{nie2020adversarial,
  title={Adversarial NLI: A New Benchmark for Natural Language Understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4885--4901},
  year={2020}
}

@inproceedings{saeed2021rulebert,
  title={RuleBERT: Teaching Soft Rules to Pre-Trained Language Models},
  author={Saeed, Mohammed and Ahmadi, Naser and Nakov, Preslav and Papotti, Paolo},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1460--1476},
  year={2021}
}



@inproceedings{dalvi2021explaining,
  title={Explaining Answers with Entailment Trees},
  author={Dalvi, Bhavana and Jansen, Peter and Tafjord, Oyvind and Xie, Zhengnan and Smith, Hannah and Pipatanangkura, Leighanna and Clark, Peter},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7358--7370},
  year={2021}
}

@article{han2022folio,
  title={Folio: Natural language reasoning with first-order logic},
  author={Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Zhou, Wenfei and Coady, James and Peng, David and Qiao, Yujie and Benson, Luke and others},
  journal={arXiv preprint arXiv:2209.00840},
  year={2022}
}

@article{toshniwal2024openmathinstruct,
  title={Openmathinstruct-1: A 1.8 million math instruction tuning dataset},
  author={Toshniwal, Shubham and Moshkov, Ivan and Narenthiran, Sean and Gitman, Daria and Jia, Fei and Gitman, Igor},
  journal={arXiv preprint arXiv:2402.10176},
  year={2024}
}

@article{xu2024faithful,
  title={Faithful Logical Reasoning via Symbolic Chain-of-Thought},
  author={Xu, Jundong and Fei, Hao and Pan, Liangming and Liu, Qian and Lee, Mong-Li and Hsu, Wynne},
  journal={arXiv preprint arXiv:2405.18357},
  year={2024}
}


@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}

@article{jiang2024survey,
  title={A survey on large language model hallucination via a creativity perspective},
  author={Jiang, Xuhui and Tian, Yuxing and Hua, Fengrui and Xu, Chengjin and Wang, Yuanzhuo and Guo, Jian},
  journal={arXiv preprint arXiv:2402.06647},
  year={2024}
}

@inproceedings{mundlerself,
  title={Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation},
  author={M{\"u}ndler, Niels and He, Jingxuan and Jenko, Slobodan and Vechev, Martin},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@inproceedings{dale2023detecting,
  title={Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better},
  author={Dale, David and Voita, Elena and Barrault, Loic and Costa-juss{\`a}, Marta R},
  booktitle={The 61st Annual Meeting Of The Association For Computational Linguistics},
  year={2023}
}

@inproceedings{zhong2021qmsum,
  title={QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization},
  author={Zhong, Ming and Yin, Da and Yu, Tao and Zaidi, Ahmad and Mutuma, Mutethia and Jha, Rahul and Hassan, Ahmed and Celikyilmaz, Asli and Liu, Yang and Qiu, Xipeng and others},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={5905--5921},
  year={2021}
}

@article{pu2023summarization,
  title={Summarization is (almost) dead},
  author={Pu, Xiao and Gao, Mingqi and Wan, Xiaojun},
  journal={arXiv preprint arXiv:2309.09558},
  year={2023}
}

@article{liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{shi2023large,
  title={Large language models can be easily distracted by irrelevant context},
  author={Shi, Freda and Chen, Xinyun and Misra, Kanishka and Scales, Nathan and Dohan, David and Chi, Ed H and Sch{\"a}rli, Nathanael and Zhou, Denny},
  booktitle={International Conference on Machine Learning},
  pages={31210--31227},
  year={2023},
  organization={PMLR}
}

@article{bao2024faithbench,
  title={FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs},
  author={Bao, Forrest Sheng and Li, Miaoran and Qu, Renyi and Luo, Ge and Wan, Erana and Tang, Yujia and Fan, Weisi and Tamber, Manveer Singh and Kazi, Suleman and Sourabh, Vivek and others},
  journal={arXiv preprint arXiv:2410.13210},
  year={2024}
}

@article{chen2023program,
  title={Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}

@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@inproceedings{wang2023review,
  title={A Review on Code Generation with LLMs: Application and Evaluation},
  author={Wang, Jianxun and Chen, Yixiang},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)},
  pages={284--289},
  year={2023},
  organization={IEEE}
}

@inproceedings{madaan2022language,
  title={Language Models of Code are Few-Shot Commonsense Learners},
  author={Madaan, Aman and Zhou, Shuyan and Alon, Uri and Yang, Yiming and Neubig, Graham},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={1384--1403},
  year={2022}
}

@inproceedings{laskari2022seq2code,
  title={Seq2Code: Transformer-Based Encoder-Decoder Model for Python Source Code Generation},
  author={Laskari, Naveen Kumar and Reddy, K Adi Narayana and Indrasena Reddy, M},
  booktitle={Congress on Intelligent Systems},
  pages={301--309},
  year={2022},
  organization={Springer}
}

@inproceedings{phan2021cotext,
  title={CoTexT: Multi-task Learning with Code-Text Transformer},
  author={Phan, Long and Tran, Hieu and Le, Daniel and Nguyen, Hieu and Annibal, James and Peltekian, Alec and Ye, Yanfang},
  booktitle={Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)},
  year={2021},
  organization={Association for Computational Linguistics}
}



@article{chenprogram,
  title={Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={Transactions on Machine Learning Research}
}

@article{le2022coderl,
  title={Coderl: Mastering code generation through pretrained models and deep reinforcement learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21314--21328},
  year={2022}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}

@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}


@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{chen2016thorough,
  title={A thorough examination of the cnn/daily mail reading comprehension task},
  author={Chen, Danqi and Bolton, Jason and Manning, Christopher D},
  journal={arXiv preprint arXiv:1606.02858},
  year={2016}
}

@article{li2023halueval,
  title={Halueval: A large-scale hallucination evaluation benchmark for large language models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.11747},
  year={2023}
}

@article{joshi2017triviaqa,
  title={Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1705.03551},
  year={2017}
}


@inproceedings{zha2023alignscore,
  title={AlignScore: Evaluating Factual Consistency with A Unified Alignment Function},
  author={Zha, Yuheng and Yang, Yichi and Li, Ruichen and Hu, Zhiting},
  booktitle={The 61st Annual Meeting Of The Association For Computational Linguistics},
  year={2023}
}

@inproceedings{zhong2022towards,
  title={Towards a Unified Multi-Dimensional Evaluator for Text Generation},
  author={Zhong, Ming and Liu, Yang and Yin, Da and Mao, Yuning and Jiao, Yizhu and Liu, Pengfei and Zhu, Chenguang and Ji, Heng and Han, Jiawei},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={2023--2038},
  year={2022}
}

@inproceedings{guanah,
  title={ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models},
  author={Gu, Yuzhe and Ji, Ziwei and Zhang, Wenwei and Lyu, Chengqi and Lin, Dahua and Chen, Kai},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}
}

@misc{conghui2022opendatalab,
  title={OpenDataLab: Empowering General Artificial Intelligence with Open Datasets},
  author={Conghui He, Wei Li, Zhenjiang Jin, Bin Wang, Chao Xu, Dahua Lin},
  journal={https://opendatalab.com/},
  year={2022}
}

@misc{conghui2022opendatalab,
  title={OpenDataLab: Empowering General Artificial Intelligence with Open Datasets},
  author={Conghui He, Wei Li, Zhenjiang Jin, Bin Wang, Chao Xu, Dahua Lin},
  journal={https://opendatalab.com/},
  year={2022}
}

@article{gu2024anah,
  title={Anah-v2: Scaling analytical hallucination annotation of large language models},
  author={Gu, Yuzhe and Ji, Ziwei and Zhang, Wenwei and Lyu, Chengqi and Lin, Dahua and Chen, Kai},
  journal={arXiv preprint arXiv:2407.04693},
  year={2024}
}


@inproceedings{guo2020wiki,
  title={Wiki-40b: Multilingual language model dataset},
  author={Guo, Mandy and Dai, Zihang and Vrande{\v{c}}i{\'c}, Denny and Al-Rfou, Rami},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={2440--2452},
  year={2020}
}

@article{yang2024qwen2,
  title={Qwen2. 5 Technical Report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}