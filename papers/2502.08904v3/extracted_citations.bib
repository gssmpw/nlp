@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{chenprogram,
  title={Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={Transactions on Machine Learning Research}
}

@inproceedings{dalvi2021explaining,
  title={Explaining Answers with Entailment Trees},
  author={Dalvi, Bhavana and Jansen, Peter and Tafjord, Oyvind and Xie, Zhengnan and Smith, Hannah and Pipatanangkura, Leighanna and Clark, Peter},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7358--7370},
  year={2021}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}

@article{han2022folio,
  title={Folio: Natural language reasoning with first-order logic},
  author={Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Zhou, Wenfei and Coady, James and Peng, David and Qiao, Yujie and Benson, Luke and others},
  journal={arXiv preprint arXiv:2209.00840},
  year={2022}
}

@article{huang2024key,
  title={Key-point-driven data synthesis with its enhancement on mathematical reasoning},
  author={Huang, Yiming and Liu, Xiao and Gong, Yeyun and Gou, Zhibin and Shen, Yelong and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2403.02333},
  year={2024}
}

@article{jiang2024survey,
  title={A survey on large language model hallucination via a creativity perspective},
  author={Jiang, Xuhui and Tian, Yuxing and Hua, Fengrui and Xu, Chengjin and Wang, Yuanzhuo and Guo, Jian},
  journal={arXiv preprint arXiv:2402.06647},
  year={2024}
}

@article{le2022coderl,
  title={Coderl: Mastering code generation through pretrained models and deep reinforcement learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21314--21328},
  year={2022}
}

@article{liu2023logiqa,
  title={Logiqa 2.0â€”an improved dataset for logical reasoning in natural language understanding},
  author={Liu, Hanmeng and Liu, Jian and Cui, Leyang and Teng, Zhiyang and Duan, Nan and Zhou, Ming and Zhang, Yue},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2023},
  publisher={IEEE}
}

@article{lu2024mathgenie,
  title={Mathgenie: Generating synthetic data with question back-translation for enhancing mathematical reasoning of llms},
  author={Lu, Zimu and Zhou, Aojun and Ren, Houxing and Wang, Ke and Shi, Weikang and Pan, Junting and Zhan, Mingjie and Li, Hongsheng},
  journal={arXiv preprint arXiv:2402.16352},
  year={2024}
}

@inproceedings{madaan2022language,
  title={Language Models of Code are Few-Shot Commonsense Learners},
  author={Madaan, Aman and Zhou, Shuyan and Alon, Uri and Yang, Yiming and Neubig, Graham},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={1384--1403},
  year={2022}
}

@inproceedings{nie2020adversarial,
  title={Adversarial NLI: A New Benchmark for Natural Language Understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4885--4901},
  year={2020}
}

@inproceedings{pan2023logic,
  title={Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning},
  author={Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={3806--3824},
  year={2023}
}

@inproceedings{saeed2021rulebert,
  title={RuleBERT: Teaching Soft Rules to Pre-Trained Language Models},
  author={Saeed, Mohammed and Ahmadi, Naser and Nakov, Preslav and Papotti, Paolo},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1460--1476},
  year={2021}
}

@article{toshniwal2024openmathinstruct,
  title={Openmathinstruct-1: A 1.8 million math instruction tuning dataset},
  author={Toshniwal, Shubham and Moshkov, Ivan and Narenthiran, Sean and Gitman, Daria and Jia, Fei and Gitman, Igor},
  journal={arXiv preprint arXiv:2402.10176},
  year={2024}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{xu2024faithful,
  title={Faithful Logical Reasoning via Symbolic Chain-of-Thought},
  author={Xu, Jundong and Fei, Hao and Pan, Liangming and Liu, Qian and Lee, Mong-Li and Hsu, Wynne},
  journal={arXiv preprint arXiv:2405.18357},
  year={2024}
}

@inproceedings{yureclor,
  title={ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning},
  author={Yu, Weihao and Jiang, Zihang and Dong, Yanfei and Feng, Jiashi},
  booktitle={International Conference on Learning Representations}
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}

@article{zhong2021ar,
  title={Ar-lsat: Investigating analytical reasoning of text},
  author={Zhong, Wanjun and Wang, Siyuan and Tang, Duyu and Xu, Zenan and Guo, Daya and Wang, Jiahai and Yin, Jian and Zhou, Ming and Duan, Nan},
  journal={arXiv preprint arXiv:2104.06598},
  year={2021}
}

