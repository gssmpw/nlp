\section{Introduction}\label{section: intro}
Collecting abundant labeled data in real-world scenarios is often prohibitively expensive, particularly in specialized domains such as medical imaging, autonomous driving, robotics, rare disease prediction, financial fraud detection, and law enforcement surveillance. It is widely believed that knowledge from different tasks shares commonalities. This implies that, despite the differences between tasks or domains, there exist underlying patterns or structures that can be exploited across them. This belief forms the foundation of transfer learning. Transfer learning seeks to leverage knowledge from a source task to improve model performance in the target task, while simultaneously reducing the required sample size from target domain.

Recently, a variety of transfer learning methodologies have been proposed, including linear models \citep{Li2021LinearTransfer, singh2023representationtransferlearningmultiple, zhao2024residualimportanceweightedtransfer, liu2024unifiedtransferlearningmodels}, generalized linear models \citep{tian2022transferlearninghighdimensionalgeneralized, Li2023GenerlizedLinearTransfer}, and nonparametric models \citep{shimodaira2000improving, ben2006analysis, blitzer2007learning, sugiyama2007direct, mansour2009domain, wang2016nonparametric, cai2019transferlearningnonparametricclassification, reeve2021adaptivetransferlearning, fan2023robusttransferlearningunreliable, maity2021linearadjustmentbasedapproach, lin2024hypothesistransferlearningfunctional, cai2024transferlearningnonparametricregression}. However, these methods either impose constraints that the model must be inherently parametric or suffer from the curse of dimensionality \citep{hollander2013nonparametric, wainwright2019high} in practical applications. In contrast, deep learning has demonstrated a remarkable ability to mitigate the curse of dimensionality, both empirically \citep{lecun2015deep, dive2021muli} and theoretically \citep{kohler2004adaptive, kohler2016nonparametric, bauer2019on, schmidt2020nonparametric}. Consequently, deep transfer learning has garnered significant attention within the research community.

A particularly effective paradigm within deep transfer learning is pretraining followed by fine-tuning, whose efficiency has been demonstrated in numerous studies \citep{schroff2015facenet, dhillon2020baseline, chen2019fewshot, chen2020newmeta}. During the pretraining phase, a encoder is learned from a large, general dataset with annotations, which is subsequently transferred to the target-specific task. In the fine-tuning stage, a relatively simple model (e.g., $k$-nn, linear model) is typically trained on the learned representation space to address the target task. However, in real-world applications, two critical observations must be considered. First, the collection of unlabeled data is generally more feasible and cost-effective than the acquisition of labeled data. Second, the absence of comprehensive annotations often leads to the loss of valuable information. As a result, learning effective representations from abundant unlabeled data presents both a highly promising and challenging problem.

Recently, a class of powerful methods known as self-supervised contrastive learning has been proposed, demonstrating remarkable performance in various real-world applications, particularly in computer vision. It strive to learn an effective encoder of augmentation invariance, where augmentation refers to predefined transformations applied to the original image, resulting in a similar but not identical version, referred to as an augmented view. Nevertheless, solely pushing different augmented views of the same image (referred to as positive samples) together lead to the phenomenon of model collapse, where the learned encoder maps all inputs to the same point in the representation space. To prevent model collapse, numerous strategies have been explored. The initial idea involved pushing positive samples closer together while ensuring negative samples far apart \citep{ye2019invarspread, he2020momentum, chen2020simclr, haochen2021spectral}, where negative samples refer to augmented views derived from different original images. However, negative samples introduce various problems simultaneously. First, since ground-truth labels for augmented samples are typically unavailable, two augmented views with similar or even identical semantic meaning, but derived from different original images, are treated as negative samples, which can hinder the model's ability to capture semantic meaning \citep{chuang2020debiased, chuang2022robust}. Second, \citet{chen2020simclr} demonstrated that contrastive learning benefits significantly from a large number of negative samples, which in turn requires substantial computational resources to process large batch sizes. As a result, many subsequent studies have explored alternative designs to prevent model collapse without relying on negative samples. For instance, \citet{zbontar2021barlow, ermolov2021whitening, adrien2022vicreg, duan2024unsupervisedtransferlearningadversarial} focused on pushing the covariance or correlation matrix towards the identity matrix, while \citet{grill2020bootstrap, chen2021exploring} showed that adopting asymmetric network structures could achieve similar result. Regardless of the design of such methods, their effectiveness has been demonstrated, at least empirically: based on the learned representation, a simple linear model trained with a limited amount of labeled data from the target domain can achieve outstanding performance. 

Intuitively, this phenomenon implies that the target data distribution in the representation space is clustered according to semantic meaning. As a result, the target classification task can almost be solved perfectly by a simple linear model trained on a few labeled samples. The key question is: why does the self-supervised learning task during the pretraining phase lead to such a distribution of the target data in the representation space? Figure~\ref{fig: aug_intro} illustrates a potential explanation for this success. There are two augmented views with gray borders (referred to as anchors) that exhibit a small Euclidean distance, while the corresponding original images are far apart due to differences in backgrounds. If the encoder possesses Lipschitz property, their representation will also be close in the representation space. Furthermore, other augmented views of the same original images will be dragged towards the anchors during the alignment positive samples. This results the formation of a cluster in the learned representation space that represents the semantic meaning of ``black dog". The remaining question is: how can we separate the clusters of different semantic meanings? For example, the cluster formed by red point and the cluster formed by black and gray points in Figure~\ref{fig: aug_intro}. To this end, \textbf{why not directly establish a reference distribution with several well-separated parts and then push the representation distribution toward it, thereby inheriting this structure?}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.65\linewidth]{augmentaion_intro.png}
    \caption{Data augmentation implicitly introduces weak-supervision signal.}
    \label{fig: aug_intro}
\end{figure}

\subsection{Contributions}\label{subsection: contributions}
Our main contributions are summarized as follows:
\begin{itemize}
    \item We introduce a novel self-supervised learning method, termed \underline{D}istribution \underline{M}atching (DM). DM drives the representation distribution towards a predefined reference distribution, resulting in a learned representation space with strong geometric intuition, while the hyperparameters are easily interpretable.   
    \item The experimental results across various real-world datasets and evaluation metrics demonstrate that the performance of DM on the target classification task is competitive with existing self-supervised learning methods. The ablation study further confirms that DM effectively captures fine-grained concepts, which aligns with our intuition. 
    \item We provide rigorous theoretical guarantees for DM, including a population theorem and an end-to-end sample theorem. The population theorem bridges the gap between the self-supervised learning task and target classification accuracy. The sample theorem demonstrates that, even with a limited number of downstream samples, DM can achieve exceptional classification performance, provided the size of the unlabeled sample set is sufficiently large.
\end{itemize}

\subsection{Related works}\label{subsection: related works}
\citet{huang2023towards} establish a theoretical foundation for various self-supervised losses at the population level, while \citet{duan2024unsupervisedtransferlearningadversarial} extend this analysis to the sample level for the adversarial loss they propose. We provide theoretical guarantees at both the population and sample levels. \citet{wang2020understanding, Awasthi2022DoMN, huang2023towards, duan2024unsupervisedtransferlearningadversarial} have investigated the structure of the representation space learned by various self-supervised learning methods, both empirically and theoretically. In contrast, DM naturally exhibits a clear geometric structure. \citet{haochen2021spectral, haochen2022beyond, haochen2023theoretical} suggest the existence of a potential subclass structure within their graph-theoretical framework, though without empirical support. By leveraging the clear geometric structure and the interpretability of DM's hyperparameters, the ablation experiment presented in Section~\ref{subsection: finer-grained concept} empirically verifies this hypothesis.

