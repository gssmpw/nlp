\section{Related works}
\label{subsection: related works}
\citet{huang2023towards} establish a theoretical foundation for various self-supervised losses at the population level, while \citet{duan2024unsupervisedtransferlearningadversarial} extend this analysis to the sample level for the adversarial loss they propose. We provide theoretical guarantees at both the population and sample levels. \citet{wang2020understanding, Awasthi2022DoMN, huang2023towards, duan2024unsupervisedtransferlearningadversarial} have investigated the structure of the representation space learned by various self-supervised learning methods, both empirically and theoretically. In contrast, DM naturally exhibits a clear geometric structure. \citet{haochen2021spectral, haochen2022beyond, haochen2023theoretical} suggest the existence of a potential subclass structure within their graph-theoretical framework, though without empirical support. By leveraging the clear geometric structure and the interpretability of DM's hyperparameters, the ablation experiment presented in Section~\ref{subsection: finer-grained concept} empirically verifies this hypothesis.