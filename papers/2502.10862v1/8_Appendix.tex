\clearpage
\appendix
\onecolumn
\section{Appendix}

% \subsection{Dataset}
% \label{appendix-dataset}

\subsection{Random robot generation}
\label{appendix-dataset-random-robot-generation}

Random morphologies were generated de novo during pretraining and as the initial seed population of evolution (gen 0). 
% (See Sect.~\ref{sec:methods} for more information about morphological pretraining and evolution.)
First, we enumerated all possible (length, width, height) tuples with length and width in $[1, 6]$ and height in $[1, 4]$, corresponding to the voxel dimensions of $\mathcal{G}$ (see Sect.~\ref{methods-morphology-design-space}). 
We then randomly sampled a volume uniformly from the set of possible volumes and subsequently sampled a compatible (length, width, height) tuple to define the bounding box for the genotype. 
This ensured our dataset contained morphologies of varying volumes and dimensions. 
Within this bounding box, all voxels were initialized as inactive (zero) and then randomly activated according to probability $p \sim \mathcal{N}(\mu=0.35, \sigma=0.125)$, clipped to $[0.1, 0.6]$.  
If the resulting structure contained no active voxels, sampling was repeated. The largest connected component of active voxels was retained to ensure a valid morphology. 
If necessary, the bounding box was zero-padded back to $6 \times 6 \times 4$ and the connected component was centered in the horizontal plane and shifted to the bottom of the workspace. 
The parameters of the sampling distribution were empirically set to produce diverse structures, a sampling of which can be visualized in Figs.~\ref{fig:results-morpho-grid}A
and 
\ref{fig:appendix-zero-shot-robot-grid}. 



\subsection{Random environment generation}
\label{appendix-dataset-random-environment-generation}

Random environments were generated during pretraining (Sect.~\ref{methods-pretraining}), 
few-shot evolution (Sect.~\ref{methods-few-shot-evolution}) 
and 
simultaneous co-design (Sect.~\ref{methods-codesign}). Zero-shot evolution did not require random environment generation since there was no model training involved and thus relied only on evaluation environments (Appx.~\ref{appendix-dataset-evaluation-environments}).
An environment consisted of a (terrain, light source position) tuple. A random terrain was generated by sampling a discrete $8 \times 8$ height map of uniformly spaced values. Each value was sampled independently from a Gaussian distribution $\mathcal{N}(\mu = 0, \sigma = \mathcal{U}(0, 0.1))$. A light source position was generated by sampling $(x, y)$ coordinates uniformly inside the circle $(x - r_x)^2 + (y - r_y)^2 = r^2$, where $r \sim \mathcal{U}(0.4, 2.0)$ and ($r_x$, $r_y$) was the initial center of mass position of each robot. Prior to the start of simulation light source positions were placed in 3D by incorporating the terrain height at the sampled (x, y) location.

\subsection{Evaluation environments}
\label{appendix-dataset-evaluation-environments}

Each generation of zero-shot evolution (Sect.~\ref{methods-zero-shot-evolution}), 
few-shot evolution (Sect.~\ref{methods-few-shot-evolution}) 
and simultaneous co-design (Sect.~\ref{methods-codesign}),
both the parents and their offspring were evaluated on a fixed set of 10 testing environments. 
This dataset was constructed as follows. 
Light sources were placed in two rings centered about the robot's starting position: five targets at radius 1.5 and five at radius 2.0, with their angular positions offset to maximize radial coverage. 
Terrains were sampled at five uniformly spaced difficulty levels, characterized by height map standard deviations in $\{0.02, 0.04, 0.06, 0.08, 0.1\}$. 
Each ring of light position targets was randomly paired with one terrain from each difficulty level.

