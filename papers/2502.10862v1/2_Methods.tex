\section{Methods}
\label{sec:methods} 

In this section we describe 
the morphological design space (the ``morphospace''; Sect.~\ref{methods-morphology-design-space}),
the simulated physical environment (Sect.~\ref{methods-simulator}),
the universal controller (Sect.~\ref{methods-universal-control}),
morphological pretraining (Sect.~\ref{methods-pretraining}),
zero shot evolution (Sect.~\ref{methods-zero-shot-evolution}),
few shot evolution with generational finetuning (Sect.~\ref{methods-few-shot-evolution}),
and 
simultaneous co-design (Sect.~\ref{methods-codesign}).


\subsection{Morphospace}
\label{methods-morphology-design-space}

Robot morphologies were genetically encoded as contiguous collections of voxels 
within a $6 \times 6 \times 4$ (Length $\times$ Width $\times$ Height) binary genotype workspace, $\mathcal{G}$. 
% Connectivity was defined through 6-neighbor adjacency (face-adjacent voxels), ensuring physically realizable robots without disconnected parts. 
Voxelized genotypes were then mapped to a phenotype space $\mathcal{P}$ comprising 
masses $\mathcal{M}$ and springs $\mathcal{S}$ 
arranged in a cubic lattice 
with 10 cm$^3$ unit cells 
(Fig.~\ref{fig:methods-geno-pheno-sim}).
% 
More specifically, a genotype voxel at position $(i,j,k)$ in $\mathcal{G}$ is expressed phenotypically by eight masses,
one in each corners of the corresponding cubic cell in $\mathcal{P}$ with coordinates $(0.1i+\delta_x,0.1j+\delta_y,0.1k+\delta_z)$ where $\delta_{x,y,z} \in \{0,0.1\}$. 
Springs are then connected to these masses in two patterns: (1) axial springs along cube edges, and (2) planar diagonal springs in each face. 
Adjacent genotype voxels share masses and springs at their interfaces, 
ensuring that contiguous structures in $\mathcal{G}$ mapped to cohesive mass-spring networks in $\mathcal{P}$.

The resultant $6 \times 6 \times 4$ workspace accommodated a maximum of $|\mathcal{M}|=245$ potential mass positions and $|\mathcal{S}|=1648$ potential springs. 
Each robot was centered in the x-y plane according to its center of mass and shifted to the bottom of the workspace to ensure ground contact prior to behavior. 
This procedure ensured stable initial conditions for locomotion while maintaining consistent relative positioning between robots of different morphologies.

To identify unique morphologies, we defined an equivalence relation on the genotype space that accounted for translations and symmetries. Two genotypes were considered identical if, after aligning their occupied voxels to the origin, one could be transformed into the other through any combination of: (1) 90Â° rotations about the z-axis, (2) reflection about the x-axis, or (3) reflection about the y-axis. Each unique design was represented by its lexicographically minimal form across all such transformations.

\subsection{Differentiable simulation}
\label{methods-simulator}

We here extend the differentiable 2D mass-springs simulators developed by \citet{hu2019difftaichi} and \cite{strgar2024evolution} to three dimensions and add exterception: perception of external stimuli outside the body, namely light.
% we simulated 3D robots using a Hookean mass-spring system with semi-implicit Euler integration. 
Masses on $\mathcal{M}$ hosting photoreceptors were connected by actuating springs on $\mathcal{S}$ (defined above in Sect.~\ref{methods-morphology-design-space}), which exerted forces on their endpoint masses to perform phototaxis: movement toward a light source. 

During simulation, 
% the universal controller (which detailed in the following section, Sect.~\ref{methods-universal-control})
spring rest lengths may be actuated continuously between $\pm 20\%$ of their initial values derived from $\mathcal{P}$ (see Sect.~\ref{methods-morphology-design-space}). 
Spring forces were computed according to Hooke's law $F = k(L - L_0)$, where $k=1.5 \times 10^4$ N/m is the spring stiffness coefficient, $L$ is the current spring length, and $L_0$ is the modulated rest length. 
Resulting impulses, as well as damping and gravitational forces, were used to update velocities for each mass, and in turn mass positions were updated using the new velocities.

The terrains along which robots behaved were modeled using randomly sampled height maps (see Appx.~\ref{appendix-dataset-random-environment-generation} for details). 
During simulation, terrain heights at arbitrary coordinates $(x, y)$ were computed through bilinear interpolation of the height map. 
For collision handling, we detected when a mass' updated $z$-coordinate fell below the interpolated terrain height at its $(x, y)$ position. Upon detection, we employed a three-phase resolution: (1) iterative bisection on the interval [0, $dt$] to estimate the time of impact and advance the mass to the contact point, (2) velocity projection onto the contact surface normal (estimated via central differences), and (3) constrained motion along the surface tangent for the remaining timestep. Following \citet{strgar2024evolution}, friction forces were computed by negating the tangential velocity component and clamping its magnitude to not exceed the magnitude of the normal velocity component.

Our simulator was implemented in the Taichi programming language \cite{hu2019difftaichi}, providing both GPU acceleration for parallel, multi-robot simulation and automatic differentiation capabilities. The simulator was directly integrated with a PyTorch-based universal controller (Sect.~\ref{methods-universal-control}), enabling end-to-end backpropagation through 1000 timesteps ($dt = 0.004$s) of physics simulation and neural control for gradient-based optimization of the controller parameters.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{3_results_fig_xover}
\input{3_results_fig_com_traces}
\input{3_results_fig_performance}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{The universal controller}
\label{methods-universal-control}

We employed a simple multi-layer perceptron (MLP) as a universal controller for adaptive phototaxis: guiding a population of thousands of morphologically diverse robots towards arbitrarily positioned light sources across randomly varying, rugged terrains.
The network mapped two input streams to spring actuation signals: photosensor readings from masses and central pattern generator (CPG) inputs. 
To accommodate all possible body plans in the morphospace (defined in Sect.~\ref{methods-morphology-design-space}), the network's input dimension was set to $|\mathcal{M}|$ (the maximum number of masses) and output dimension to $|\mathcal{S}|$ (the maximum number of springs). Sensors and actuators not present in the a specific robot's body had their corresponding signals masked to zero, providing an implicit morphological conditioning through observation and action space masking.

Each mass-bound photosensor measured light intensity following the inverse square law relative to the light source position. 
Sensor readings for each robot were normalized by subtracting the mean computed across that robot's active (unmasked) sensors, providing a zero-centered, embodied irradiance gradient. 

Following \citet{hu2019difftaichi} and \citet{strgar2024evolution},
CPG inputs consisted of five sinusoidal waves with angular frequency $\omega=10$ rad/s and phase offsets evenly spaced by $2\pi/5$ radians. Over the 4-second simulation period (1000 timesteps, $\Delta t=4e-3$s), these oscillators completed approximately six cycles.

The MLP architecture consisted of an input layer (dimension 250: $|\mathcal{M}|$ mass sensors plus 5 CPG inputs), three hidden layers (dimension 256 each), and an output layer (dimension 1648: $|\mathcal{S}|$ springs). Each hidden layer was followed by layer normalization and ReLU activation, while the output layer used a $\tanh$ activation. All layers included learnable biases. In total the model consisted of 620,912 learnable parameters. 

Network weights were initialized using a Xavier uniform distribution (gain=1.0) \cite{glorot2010understanding} with zero-initialized biases, and the network was optimized using Adam \cite{adamkingma} ($\beta_1=0.9$, $\beta_2=0.999$) with gradient norm clipping at 1.0. 
Learning rates were scheduled using variants of cosine annealing with restarts (detailed in Sects.~\ref{methods-pretraining},~\ref{methods-few-shot-evolution}, and~\ref{methods-codesign}).


\subsection{Morphological pretraining}
\label{methods-pretraining}

The universal controller was pretrained 
across a dataset of over 10 million distinct robot morphologies 
(see Appx.~\ref{appendix-dataset-random-robot-generation} for details). 
The controller was trained over 1400 learning steps to minimize the batch mean of $d_1/d_0$, where $d_1$ and $d_0$ represent each robot's final and initial distances from its target light source, respectively. 
This relative distance formulation ensured robots were not penalized for being initialized far from their targets and equally incentivized fine-grained control in robots initialized near their targets.

We used a batch size of 8192, distributed in equal partitions of 1024 across a single compute node consisting of eight H100 SXM GPUs. 
Each sample consisted of a randomly-generated robot morphology (see Appx.~\ref{appendix-dataset-random-robot-generation} for details) 
a randomly-generated terrain shape
and a randomly-positioned light source (see Appx.~\ref{appendix-dataset-random-environment-generation} for details), and was seen exactly once during training. 
Training used a cosine annealing with restarts schedule, with initial learning rate $1e^{-3}$, cycle length starting at 10 steps and doubling each restart, minimum learning rate $1e^{-5}$, and a decay rate of 0.7 applied to the starting learning rate at each cycle. 

\subsection{Zero-shot evolution}
\label{methods-zero-shot-evolution}

Here, we introduce a novel robot design paradigm that leverages a frozen, pretrained universal controller to rapidly evaluate non-differentiable changes to a given robot's body plan. 
By using a single, fixed controller for all body plans,
the design space may be efficiently explored without the computational burden of training a custom controller for each body plan. 
We refer to this method as ``zero-shot evolution''. 

We initialized a population of 8192 random robot morphologies (unseen during pretraining) and evaluated each on a fixed test set of terrain and light source position pairs (see Appx.~\ref{appendix-dataset-evaluation-environments} for details). A simple genetic algorithm was then applied iteratively: the population produced an equal number of offspring through two variation operators (described below), new offspring were evaluated once on the test set, and the top 50\% across parents and offspring (using cached evaluation scores for parents) were selected to form the next generation.

Robot offspring were produced through one of two variation operators: mutation and recombination. The population was partitioned into two distinct groups: a random 25\% of members were assigned to produce offspring through mutation, while the remaining 75\% were reserved for producing offspring through recombination (or crossover). Each member in the mutation group produced a single offspring through random bit flip mutations performed on their genotype. Flips occurred with probability $p = 1/N$ where $N = 6 \times 6 \times 4$, the total number of voxels in the robot's genotype. After mutation, genotypes were processed to ensure validity: only the largest connected component was retained, and the resulting structure was translated to the bottom center of the workspace. If a mutation produced a body that was either empty or identical to a previously seen body, the process was repeated with the mutation rate increased by 2.5\% until a valid, unique design was obtained.

From the recombination group (75\% of the population), pairs of distinct parents were randomly sampled to produce offspring through crossover (Fig.~\ref{fig:results-xover}). 
For each sampled pair, an offspring's genotype was created using a bitwise exclusive or (XOR) operation on the parent genotypes. As with mutation, post-processing retained only the largest connected component and centered it at the bottom of the workspace. If the resulting design duplicated a previous one, it was discarded. The sampling and generation process was repeated until the number of offspring equaled the size of the recombination group (75\% of the population).


\subsection{Few-shot evolution}
\label{methods-few-shot-evolution}

In this experiment we extend the zero-shot paradigm (described above in Sect.~\ref{methods-zero-shot-evolution}) by fine-tuning 
the pretrained universal controller 
to the current population
at every generation of morphological evolution.
We refer to this approach as ``few-shot evolution''.
% 
The experimental setup of few-shot evolution matched the zero-shot case, with one key difference: before evaluation, each generation received 60 fine-tuning steps (30 for parents, 30 for offspring).
The number of fine-tuning steps was
empirically chosen to balance controller adaptation against evolutionary search while maintaining comparable maximum wall-clock time across experiments. 
At the start of each generation, the controller's weights were reset to their pretrained values and the optimizer state was reinitialized. 
Fine-tuning used a cosine annealing learning rate schedule with initial and minimum rates of $3.5e^{-4}$ and $3.5e^{-5}$, respectively. The cycle length was set to 100; however each cycle was truncated to align each cycle with one generation's 60 fine-tuning steps resulting in an effective minimum learning rate of $1.5e^{-4}$. 
Since every generation re-initialized the pretrained weights, we did not decay the learning rate at the start of each cycle. 

\subsection{Simultaneous co-design from scratch}
\label{methods-codesign}

In our third and final experimental group, 
we remove morphological pretraining
and instead 
simultaneously 
evolve a population of robots
and
learn their universal controller, 
from scratch.
Unlike few-shot evolution, controller parameters and optimizer state are inherited across generations rather than being reset. The genetic algorithm operates as before, but we reduce the per-generation training to just 2 learning steps (1 for parents, 1 for offspring) to maintain parity with our pretraining experiments, where each training batch was unique.

Initially, we employed the same cosine annealing learning rate schedule used in morphological pretraining, but we found it was beneficial to reduce the start-of-cycle learning rate decay factor from 0.7 to 0.65 in order to stabilize learning across cycle restarts in this setting.