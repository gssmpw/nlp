\section{Discussion}
\label{sec:discussion}

 
In this paper, we introduced 
the large-scale pretraining and finetuning of a universal controller using differentiable simulation
and demonstrated how this approach
accelerates the 
design
of complex robots.
% 
The learned controller 
allows most 
randomly-generated morphologies (mass-spring networks)
to orient along a randomly-generated stimulus (light) vector in three dimensions, 
and to follow the vector to its source (phototaxis)
across challenging, randomly-generated environments (terrains)---more or less: 
some designs were much better
% (faster)
than others, and some outright fail (Fig.~\ref{fig:results-com-traces}).
Using the pretrained model as a prior, the designer 
can quickly
explore a diversity of changes---from subtle mutations to large recombinations---across
arbitrary numbers of
distinct designs in parallel
without destroying the functionality of working designs, and without constantly readapting the controller to support every morphological innovation.

We intentionally chose a vanilla evolutionary algorithm 
as ``the designer'' 
and a minimal neural architecture for the universal controller
to illustrate the power and potential of our approach.
We were particularly surprised by the effectiveness of a simple MLP in controlling 
such large numbers of morphologically complex robots 
across such challenging terrains.
Interestingly, the gaits generated by the universal controller were quite different from those 
tailored for individual body plans
in similar conditions 
\cite{strgar2024evolution};
instead of walking or ambling across the rugged terrain,
the universal controller
discovered patterns of saltation
(hopping) not unlike that of kangaroos, in which coordinated actuation of muscles is followed by an aerial phase.


It is important to note, however, that while this controller was universal across the robot's morphology and task environment, 
we only considered 
a single
material (soft),
percept (light),
actuator (linear),
and task (phototaxis).
Extending this approach to multiple tasks 
that demand 
more intricate, multi-material body plans with
multi-modal sensing
(e.g.~not just moving toward a single stimulus source, 
but reacting to various other stimuli, 
manipulating objects, 
and working with or against other robots...)
may require gradually complexifying the neural architecture.
This will likely also require replacing the direct genotype-to-phenotype mapping with
more a sophisticated (pleiotropic)
compression of phenotypes 
into a latent genome
\cite{li2025generating}.
Instead of presupposing voxel cells with
two dozen springs and eight masses,
latent genes could control the expression of more atomic building blocks,
such as individual masses and springs (or subatomic particles within them),
allowing other kinds of non-cubic cells \cite{hummer2024noncubic} to emerge.
If extended to self-reconfigurable robots, the latent genome or many such genomes may be expressed in myriad ways by a single robot with universal self control.
% 

We also identified in this paper a previously unknown yet inherent problem of co-designing morphology and universal control---diversity collapse---%
and showed how to solve this problem through
generational finetuning.
However, this first investigation of diversity collapse 
only considered a single measure of morphological diversity.
Other metrics at both the morphological and behavioral level could be formulated or derived from a latent genotype space.
Such metrics could then be incorporated into the design algorithm as a constraint or additional objective. 


Another important limitation of this work was that the simulated designs were not transferred to reality.
Doing so may require
higher resolution simulations (Fig.~\ref{fig:results-dog})
or
improvements to the simulator, e.g. it's model of contact, light, and light sensors.
Adding noise to these models can also ensure that the robot's behavior does not exploit inaccuracies of the simulation \cite{jakobi1995noise}.
Or the simulator could be augmented with a neural network that learns the residual physics that were not accounted for a priori \cite{gao2024sim}.
However, the universal controller itself might help reduce the simulation-reality gap since it is already by definition insensitive to a wide range of variation in the simulated robot's body and world.


Despite these limitations, the sheer scale and efficiency achieved by this work
opens a new frontier in robot co-design through automatic differentiation, 
suggesting the breadth of infrastructure and theory developed in fields of deep learning and neural networks may be leveraged by robot co-design in future work.

