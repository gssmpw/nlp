In this section, we present our empirical findings on KAD and comparison with FAD across three key perspectives: (1) Alignment with Human Perception, (2) Convergence with Sample Size and (3) Computation Cost.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{images/human_alignment.png}
    \caption{Spearman correlations between metric scores and human perceptual ratings for different embedding models. Since lower scores imply better results for both metrics, correlation values are negative. Correlation values are multiplied by -1 for the convenience of visualization. KAD (orange) consistently achieves higher alignment than FAD (blue).}
    \label{fig:human_alignment}
\end{figure}

\subsection{Experiment 1: Reliability of KAD in Perceptual Alignment}
\label{ssec:human_perception}
% Since KAD addresses a key limitation of FAD -- its reliance on the normality assumption -- we hypothesize that KAD has a stronger alignment with human perceptual judgments of audio quality.
A reliable evaluation metric for generative audio should be closely aligned with the human perception of audio quality. While FAD relies on a normality assumption that may not accurately capture the multimodal nature of real-world audio embeddings, KAD takes a distribution-free approach. This flexibility allows it to handle complex acoustic feature representations and potentially align more closely with how humans perceive audio quality.

To validate the perceptual alignment of KAD in comparison with FAD, we use data from the DCASE 2023 Challenge Task 7 submissions~\cite{dcase2023,BaiJLESS2023,ChangHYU2023,ChonGLI2023,ChunChosun2023,ChungKAIST2023,GuanHEU2023,JungKT2023,KamathNUS2023,LeeMARG2023,Leemaum2023,PillayCMU2023,WendnerJKU2023,XieSJTU2023,YiSURREY2023,QianbinBIT2023,QianXuBIT2023,ScheiblerLINE2023} for Foley sound generation. This dataset provides human rating scores on audio quality for 9 different audio generation models, making it a reliable benchmark for correlating objective metrics with subjective judgments.

We compute both KAD and FAD using embedding from several well-known models, including VGGish~\cite{vggish}, PANNs~\cite{panns}, CLAP~\cite{clap_ms, clap_laion}, and PaSST~\cite{passt}, all of which are trained on environmental sounds. These embedding models are widely used for the calculation of FAD scores for text-to-audio \cite{donahue2018adversarial,liu2023audioldm,huang2023makeanaudio,tango,audiogen,t-foley,audioldm2,consistencytta,tango2,tango_llm,auffusion,stableaudio_open,ezaudio} and vision-to-audio generation\cite{comunita2024syncfusion,video-foley,rewas,frieren,maskvat,v-aura,vatt,multifoley,ssv2a,vintage,mmaudio,clipsonic,v2a-mapper,im2wav,foleygen,tiva}. Since music-focused models can differ substantially in their learned representations, we also include MERT~\cite{mert} and CLAP-laion-music~\cite{clap_laion} for completeness. We then measure the Spearman rank correlation between each metric's scores and the average human evaluation scores, as well as the p-value. Correlations with $p > 0.05$ are shaded in \ref{fig:human_alignment} to indicate a lack of statistical significance.

As shown in Figure \ref{fig:human_alignment}, KAD exhibits a Spearman correlation of up to $-0.93$, notably outperforming FAD whose strongest correlation is $-0.80$. This suggests that KAD is more effective for differentiating the perceptual nuances captured within the audio data embeddings from a wide range of common audio representations. In contrast, embeddings trained on music data (MERT and CLAP-laion-music) show weaker alignment, consistent with previous findings\cite{tailleur2024correlation}. 


Among the tested embedding models, PANNs-WGLM(WaveGram-LogMel) achieves the strongest correlation with human judgments, aligning with prior research that highlighted its suitability for FAD-based evaluations~\cite{tailleur2024correlation}. Based on this observation, we select PANNs-WGLM as the primary embedding model in subsequent experiments to further investigate the performance of KAD.
  

\subsection{Experiment 2: Convergence with Sample Size}

To compare how KAD and FAD converge as the evaluation set size $N$ increases, we use the \textit{eval} split of the Clotho 2 dataset~\cite{drossos2020clotho} with 1045 samples as the reference set, and samples generated using AudioLDM~\cite{liu2023audioldm} as the evaluation set. The evaluation samples were generated by conditioning on text captions from the \textit{dev} split of the Clotho 2 dataset. The number of generated samples starts at $N=100$ and gradually increases up to $N=3839$ (the total size of the Clotho 2 \textit{dev} split). We compute both KAD and FAD under these varying $N$ values to observe their biases and convergence rates. 
% Unless otherwise noted, we employ the PANNs-WGLM embeddings~\cite{panns} for both KAD and FAD.

Figure \ref{fig:sample_convergence} displays how KAD and FAD evolve as $N$ increases, normalizing each metric by its extrapolated value at $N=\infty$. At small $N$, FAD shows a distinct positive bias, deviating substantially from its stable value. This deviation decreases roughly by half whenever the sample size doubles, indicating that a large $N$ is needed for FAD to become reliable.

By contrast, KAD remains close to its asymptotic value even at relatively small $N$, reflecting its unbiased nature. While KAD does exhibit a relatively larger standard deviation (the shaded region) for smaller $N$, this uncertainty band narrows quickly. Notably, even when accounting for the standard deviation, the range of error for KAD is bounded by the magnitude of bias for FAD, up to the largest sample size tested ($N=3839$). These results show that KAD can serve as a more stable evaluation metric, especially when the availability of generated audio samples is limited.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{images/convergence.png}
    \vspace{-0.3cm}
    \caption{Normalized FAD and KAD scores against increasing embedding sample size. Scores are normalized by their respective extrapolated values at $N=\infty$. The shaded regions indicate standard deviations.}
    \label{fig:sample_convergence}
\end{figure}


\subsection{Experiment 3: Computation Cost Comparison}
\label{ssec:exp_compute}
To assess the computational efficiency of KAD relative to FAD, we measure their wall-clock times on both CPU and GPU across varying embedding dimensions $d$ and sample sizes $N$. We use PANNs-WGLM~\cite{panns}, VGGish~\cite{vggish}, and CLAP~\cite{clap_ms} -- encompassing dimension sizes from $d=128$ (VGGish) to $d=2048$ (PANNs-WGLM). The sample sizes range up to 10k to cover typical open-source audio-text datasets like Clotho~\cite{drossos2020clotho} and AudioCaps~\cite{kim2019audiocaps}.

For the measurements, AMD EPYC 7413 CPU (24 cores) and an Nvidia RTX 3090 GPU were used, and the code is implemented on PyTorch for both KAD and FAD calculations. For FAD, we refactored the Microsoft FAD toolkit~\cite{gui2024adapting} for consistency in CPU/GPU usage, thereby ensuring the comparability of runtime measurements. All values were calculated in single-precision floating points.

Figure~\ref{fig:computation} shows that FAD’s computation time increases dramatically with dimension size $d$, whereas KAD remains relatively stable. This stark difference aligns with the theoretical $d^3$ scaling of FAD, in contrast to KAD’s weaker dependence on $d$. FAD exhibits significant computational overhead at high dimensions even for small sample sizes. Figure~\ref{fig:computation_n1000} highlights how FAD’s wall-clock time (blue lines) escalates with $d$, while KAD (orange lines) remains nearly flat. At $d=2048$, the runtime gap can reach three orders of magnitude. Figure \ref{fig:computation_d2048} further confirms that the main bottleneck for FAD is dimension size, rather than the number of samples. This behavior indicates that FAD is less practical when evaluating embeddings with large $d$ or on resource-limited systems.

Furthermore, KAD benefits considerably from GPU acceleration (dotted vs. solid orange lines), achieving more than an order of magnitude of speedup. Table \ref{table:compute_comparison} quantifies these observations, showing consistent performance advantages of KAD over FAD under both CPU and GPU conditions.
%Taken together, these results suggest that KAD not only maintains more stable convergence properties but also scales more efficiently.

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/computation_n1000.png}
        \vspace{-0.7cm}
        \subcaption{}
        \label{fig:computation_n1000}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/computation_d2048.png}
        \vspace{-0.7cm}
        \subcaption{}
        \label{fig:computation_d2048}
    \end{subfigure}
    \vspace{-0.2cm}
    \caption{Comparison of FAD and KAD wall-clock computation times. 
    (a) $N=1000$ with varying $d$. (b) $d=2048$ with varying $N$. Solid lines indicate CPU usage and dotted lines indicate GPU usage. Error bars mark the 5th to 95th percentile of 200 trials.}
    \label{fig:computation}
\end{figure}

\begin{table}[t!]
\centering
\resizebox{0.75\textwidth}{!}{%
\begin{tabular}{@{}ccrrrr@{}}
\toprule
\multirow{2}{*}{$d$}    & \multirow{2}{*}{$N$} & \multicolumn{2}{c}{CPU}                                                                               & \multicolumn{2}{c}{GPU}                                                                               \\
                        &                      & \multicolumn{1}{c}{KAD (ours)} & \multicolumn{1}{c}{FAD} & \multicolumn{1}{c}{KAD (ours)} & \multicolumn{1}{c}{FAD} \\ \midrule
\multirow{3}{*}{$128$}  & $100$                & 2.8 ± 0.06                                        & 5.7 ± 0.03                               & 0.6 ± 0.03                               & 5.4 ± 0.02                                        \\
                        & $5000$               & 102.8 ± 1.17                                        & 6.7 ± 0.09                                        & 4.1 ± 0.06                                        & 7.3 ± 0.12                                        \\
                        & $10000$              & 424.2 ± 4.00                                        & 6.9 ± 0.19                                        & 12.8 ± 0.10                                       & 7.9 ± 0.08                                        \\ \midrule
\multirow{3}{*}{$512$}  & $100$                & 2.8 ± 0.07                                        & 130.2 ± 0.65                               & 1.3 ± 0.01                               & 107.7 ± 0.29                                        \\
                        & $5000$               & 132.0 ± 1.37                                        & 155.5 ± 2.72                                        & 5.4 ± 0.12                                        & 128.5 ± 1.70                                        \\
                        & $10000$              & 461.5 ± 3.16                                        & 154.6 ± 2.65                                        & 17.3 ± 0.20                                       & 134.2 ± 1.83                                        \\ \midrule
\multirow{3}{*}{$2048$} & $100$                & 6.8 ± 0.12                                        & 1776.2 ± 14.5                              & 1.4 ± 0.03                               & 1829.1 ± 21.3                                       \\
                        & $5000$               & 204.6 ± 1.98                                        & 1921.1 ± 14.1                                       & 13.0 ± 0.41                                       & 2136.5 ± 21.8                                       \\
                        & $10000$              & 497.9 ± 4.35                                     & 2074.9 ± 20.5                                       & 46.3 ± 2.41                                       & 2174.4 ± 21.6                                       \\ \bottomrule
\end{tabular}%
}
\vspace{5pt}
\caption{Mean wall-clock times with 95\% confidence intervals over 200 trials, in milliseconds. KAD on GPU consistently runs faster than FAD for $N=100$ and $5000$, as well as for $N=10000$ at higher dimensions.}
\label{table:compute_comparison}
\end{table}

