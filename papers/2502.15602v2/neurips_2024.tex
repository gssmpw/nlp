\PassOptionsToPackage{prologue,dvipsnames}{xcolor}
\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
    \PassOptionsToPackage{numbers, compress, sort}{natbib}
% before loading neurips_2024

% ready for submission
% \usepackage{neurips_2024}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{neurips_2024}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}      % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{pifont}
\usepackage[dvipsnames]{xcolor}
\usepackage{caption}
\usepackage{subcaption}


\newcommand{\yj}[1]{\textcolor{blue}{(#1)}}
\newcommand{\ph}[1]{\textcolor{orange}{(#1)}}
\newcommand{\jw}[1]{\textcolor{olive}{(#1)}}

\title{KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation}
% \title{KAD: A Better-Aligned, Sample-Efficient, and Fast Alternative to FAD}
% (older title) Fast and Accurate Evaluation Metric with Better Perceptual Alignment for Audio Generation

\author{%
  % David S.~Hippocampus\thanks{Use footnote for providing further information
  %   about author (webpage, alternative address)---\emph{not} for acknowledging
  %   funding agencies.} \\
  % Department of Computer Science\\
  % Cranberry-Lemon University\\
  % Pittsburgh, PA 15213 \\
  % \texttt{hippo@cs.cranberry-lemon.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  Yoonjin Chung\thanks{Equal contribution} $^1$,
  Pilsun Eu$^{*1}$,
  Junwon Lee$^{2}$,
  Keunwoo Choi$^{1,3}$,\\
  \textbf{Juhan Nam$^{2}$,
  Ben Sangbae Chon$^{1}$}\\
  $^1$Gaudio Lab Inc., $^2$KAIST,
  $^3$Genentech
}

\begin{document}

\maketitle

% Abstract
\begin{abstract}
Although being widely adopted for evaluating generated audio signals, the Fréchet Audio Distance (FAD) suffers from significant limitations, including reliance on Gaussian assumptions, sensitivity to sample size, and high computational complexity. As an alternative, we introduce the Kernel Audio Distance (KAD), a novel, distribution-free, unbiased, and computationally efficient metric based on Maximum Mean Discrepancy (MMD). Through analysis and empirical validation, we demonstrate KAD’s advantages: (1) faster convergence with smaller sample sizes, enabling reliable evaluation with limited data; (2) lower computational cost, with scalable GPU acceleration; and (3) stronger alignment with human perceptual judgments. By leveraging advanced embeddings and characteristic kernels, KAD captures nuanced differences between real and generated audio. Open-sourced in the \texttt{kadtk}\footnote{\url{https://github.com/YoonjinXD/kadtk}} toolkit, KAD provides an efficient, reliable, and perceptually aligned benchmark for evaluating generative audio models.

\end{abstract}


\noindent\textbf{Index Terms}: audio generation, audio quality evaluation, Fréchet audio distance, maximum mean discrepancy, kernel methods

% Body
\section{Introduction}\label{sec:intro}
\input{sections/1-Introduction}

\section{Related Works and Preliminaries}\label{sec:related}
\input{sections/2-Related_Works_Preliminaries}

\section{Kernel Audio Distance}\label{sec:kad}
\input{sections/3-KAD}

\section{Experiments}\label{sec:exp_results}
\input{sections/4-Experimental_Results}

% Conclusion
\section{Conclusion}\label{sec:conclusion}

In this paper, we addressed key limitations of the Fréchet Audio Distance (FAD) for evaluating generative audio models and proposed the Kernel Audio Distance (KAD) as a more robust alternative. Built on the Maximum Mean Discrepancy (MMD), KAD avoids making statistical assumptions about the embedding distributions, provides unbiased results for all sample sizes, and offers a computational complexity  that scale more efficiently, particularly at higher dimensionalities.

We define KAD as the MMD between reference and evaluation audio embedding sets using a Gaussian RBF kernel with the median-distance bandwidth heuristic. To validate its effectiveness, we compare both KAD and FAD against human evaluation data, observe their convergence behaviors with increasing sample sizes, and measure their CPU and GPU runtimes across a range of dimensionalities and sample sizes.

Our findings show that KAD aligns more strongly with human judgments than FAD across various common audio embedding models, with especially high correlation with PANNs-WGLM. Moreover, its score remains consistent regardless of sample size, making it practical for resource-constrained or early-stage model evaluations, and its computational overhead is up to orders of magnitude lower for higher dimensional (\textasciitilde2024) embeddings compared to FAD due to the reduction of the complexity from $\mathcal{O}(dN^2 + d^3)$ to $\mathcal{O}(dN^2)$ and its amenability to parallel computation.

These advantages position KAD as an efficient, comprehensive, and scalable tool for benchmarking generative audio models.By more accurately capturing human-perceived audio quality, KAD can support the development of more reliable evaluation practices in the field. The accompanying open-source toolkit is provided to encourage widespread adoption, experimentation, and ongoing improvements to the development and assessment of generative audio models.





% Our empirical results demonstrate KAD’s advantages in multiple domains:
% \begin{itemize}
%     \item \textbf{Improved Perceptual Alignment}: KAD consistently achieves stronger correlations with human judgments on audio quality.
%     \item \textbf{Sample Efficiency}: KAD delivers reliable evaluations even at smaller sample sizes, making it ideal for resource-constrained or early-stage model evaluations.
%     \item \textbf{Computational Efficiency}: KAD sees a reduction of computational overhead from $\mathcal{O}(dN^2 + d^3)$ of FAD to $\mathcal{O}(dN^2)$, as well as further acceleration enabled by GPU parallelization.
% \end{itemize}

% These properties position KAD as a promising benchmark for generative audio tasks. We hope this work inspires further research into evaluation methodologies that bridge the gap between computational metrics and human perception, fostering the development of more reliable generative audio models. The open-source toolkit provided with this work aims to encourage widespread adoption and experimentation with KAD, contributing to the development of more reliable generative models.

% Bib
{
\small
\bibliography{ref}
\bibliographystyle{unsrt}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage

\appendix
\input{sections/Appendix}

% \section{Appendix / supplemental material}
% Optionally include supplemental material (complete proofs, additional experiments and plots) in appendix.
% All such materials \textbf{SHOULD be included in the main submission.}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}