
\subsection{(RQ2) How do parents perceive AI-generated content for young children?}\label{sec-result-2}

Parents showed mixed attitudes toward AI-generated learning content for young children. They discussed their perceived benefits and risks and envisioned ways to mitigate their concerns.

\subsubsection{Mixed Attitude towards AI-generated content}
Parents expressed a range of attitudes towards allowing AI to generate content for young children, ranging from skepticism and concern (P2--6, P10, P13--15) to open-minded caution (P9, P8, P16, P19, P20), acceptance (P6, P7, P11, P17, P18) and, in some cases, neutral (P1, P12). Parents who were \textit{\textbf{skeptical and concerned}} questioned whether AI-generated content met quality and safety standards, \textit{e.g.,} P3 questioned, ``\textit{Who's generating the content? Where is it getting the content from? Is it good? Is it safe?}'' On the other hand, parents who hold an attitude of \textit{\textbf{open-minded caution}} recognize the risks of using AI-generated content but feel open to use it under specific conditions. P16 highlighted model training, stating, ``\textit{I wouldn't be against it if the people training it were proficient in what the AI is teaching.}'' Similarly, P20 emphasized personal oversight, explaining, ``\textit{I can do my own evaluation to determine whether or not I think the content is good regardless of who it came from.}'' Furthermore, parents who have an attitude of \textit{\textbf{acceptance}} assume people who created the system have already ensure the appropriateness for children, \textit{e.g.,} P7 stated, ``\textit{I'm assuming because it's AI, there would be more research behind it.  So I would be okay with it.}'' Finally, parents who hold a \textit{\textbf{neutral}} attitude typically don't have much experience with AI and therefore feel unsure about their attitude for AI-generated content, \textit{e.g.,} P1 had ``\textit{not even thought about it until before this study.}''

\subsubsection{Perceived Benefits and Risks}
Parents identified several benefits of AI-generated content for young children. Some parents (P2, P4, P8, P10, P11, P16) highlighted AI's potential in \textit{\textbf{adaptability}} to adjust learning content to their child's evolving developmental needs, \textit{e.g.,} P11 expected AI to help ``\textit{adjust content as the child grows.}'' In addition, parents (P2, P3, P4, P16, P19) discussed \textit{\textbf{customization}}, illustrating that ``\textit{one of the big benefits would be to create material that are related to his[child's] interests and things that would be motivating to him[child]} (P4).'' Parents (P6, P7, P8, P10, P12, P17) also emphasized \textit{\textbf{efficiency}} of AI, explaining ``\textit{because it[AI] can access a huge amount of information very fast} (P12),'' enabling a ``\textit{quicker way to learn or to see something} (P7).'' Moreoever, a few parents (P1, P11, P18, P20) noted AI's potential to foster \textit{\textbf{affordability}}, suggesting that AI-generated content could enhance the scalability and accessibility of learning resources, making ``\textit{more learning materials available, more variety available} (P1),'' and making things ``\textit{cheaper and more accessible for people} (P20).'' Finally, a few parents (P14, P15) expected easier \textit{\textbf{pedagogical integration}} with AI, enabling parents to ``\textit{teach children things that sometimes parents don't know because not all parents know everything} (P14).''

Meanwhile, parents described their perceived risks of AI-generated content for children. Most parents (P1--3, P5, P11--15, P17, P19) were concerned about \textit{\textbf{age-inappropriateness}} of the content, which could be ``\textit{violent and donâ€™t match family values} (P1),'' ``\textit{physically harmful and sexually inappropriate} (P3),'' and ``\textit{stuff about body image and certain people being better than other people} (P5).'' In addition many parents (P2, P3, P9, P14, P16, P17, P18) expressed concerns about the \textit{\textbf{inaccuracy}} of the information presented through AI-generated content, worrying that AI could provide ``\textit{factually inaccurate}'' learning materials or content that might imply theories that are ``\textit{misframed or misconstructed} (P2).'' Moreover, parents (P2--4, P14, P15) raised concerns about the \textit{\textbf{training data quality}} for AI models. P2 emphasized transparency stating, ``\textit{I'd want to know a lot more about where that training data came from or who supervised that learning process}.'' A few parents (P6, P7) expressed concerns about children's \textit{\textbf{over dependence}} on AI instead of developing their own cognitive abilities. P6 worried that constant use of AI could discourage critical thinking, stating, ``\textit{if they have a question, instead of thinking through the question, they just ask AI, not using their own brain}.'' Finally, two parents shared concerns over \textit{\textbf{message dilution}}, where AI oversimplifies complex ideas and diminishes their original intent. P15 worried that AI might dilute sociopolitical issues, such as racial diversity and gender identity. Similarly, P20 emphasized concern about whether the core message being conveyed to the child aligns with parental values, stating ``\textit{I'm more concerned about the message the book is trying to impart on the child}.

\subsubsection{Envisioned Risk Mitigation Methods}
Parents described what methods they envisioned to address their concerns. First, some parents (P3, P5, P11, P12, P14, P16) stressed the need to enable \textit{\textbf{parental review and verification}}. For example, P5 stated ``\textit{I would read it to make sure that it was actually something I wanted to read with her}.'' In addition, a few parents (P2, P17, P19) expressed that \textit{\textbf{social and public validation}} could also enhance their trust in AI-generated content, \textit{e.g.,} P2 described that ``\textit{if a thousand people used it...and endorsed this model, that would give me more confidence in it}.'' Moreover, some parents (P2, P9, P15) discussed \textit{\textbf{model and data transparency}}, emphasizing the need to understand how AI models are trained. As explained by P9, ``\textit{being able to know exactly what's going on or how it works...would make me feel more secure about what my child is learning}.'' Lastly, a few parents (P1, P15, P18) highlighted the importance of \textbf{expert involvement} in creating AI-generated content. For instance, P1 emphasized the need for oversight by ``\textit{people with a background in human development.}''