Based on the above insights, a straightforward denoising method would treat higher-loss interactions within the personal loss distribution as noise. However, the sparsity of user interactions causes significant fluctuations in personal loss distributions. As a result, reweight-based methods may cause drastic changes in the weight assigned to the same interaction across consecutive epochs, undermining training stability. Additionally, due to variations in the presence and amount of noise, dropping the highest-loss interactions could negatively affect users with little or no noisy interactions. For instance, with a fixed drop rate (e.g., 10\%), a user without noisy interactions would still experience a 10\% drop in normal interactions during training, which would degrade the user's experience.


\begin{figure}
    \centering
    \includegraphics[width=0.485\textwidth]{Imgs/user_diff.pdf}
    \caption{Difference between normal and noisy interactions in personal loss distributions across all users.}
    \label{fig:user_diff}
\end{figure}

\input{Section/Table/Inter_personal}

To address these issues, we propose solving this problem through probabilistic sampling. Specifically, we aim to reduce the probability of noisy interactions being optimized while ensuring that users without noise remain unaffected. To this end, we propose a resampling strategy named PLD, which consists of two parts: Candidate Pool Construction and Item Resampling.

\textbf{Candidate Pool Construction.} To prevent items with extremely small losses from being repeatedly sampled, we pre-construct a candidate item pool, $\mathcal{C}_{u}^{k}$ of size $k$ for each user $u$. Items in $\mathcal{C}_{u}^{k}$ are randomly sampled from the user's interacted items, $\mathcal{V}_{u}$.

\textbf{Item Resampling.} Next, we calculate the loss $l_{u,v}$ for each of the $k$ items in the candidate pool. We then perform resampling based on the computed loss values. Specifically, for user $u$, the sampling probability for item $v$ in the candidate pool $\mathcal{C}_{u}^{k}$ is determined by:
\begin{equation}
\label{eq:p_i}
    P_{u, v} = \frac{\exp(-l_{u,v})}{\sum_{j \in \mathcal{C}_{u}^{k}} \exp(-l_{u,j})}.
\end{equation}
Finally, the resampled item is selected as the positive interaction for the current optimization step.

This method ensures that variances in personal loss distributions do not adversely affect the sampling process. Moreover, this approach ensures that normal interactions are optimized, even for users without noisy interactionsâ€”unlike previous methods, which always drop a subset of interactions~\cite{wang2021denoising, he2024double}.


