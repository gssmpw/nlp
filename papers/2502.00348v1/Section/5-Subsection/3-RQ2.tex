

\begin{figure}
    \centering
    \includegraphics[width=0.475\textwidth]{Imgs/noise_num.pdf}
    \caption{Number of normal interactions and noisy interactions sampled.}
    \label{fig:noise_num}
\end{figure}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.97\textwidth]{Imgs/hyper.pdf}
    \caption{Left: Analysis of hyper-parameter $k$; Right: Analysis of hyper-parameter $\tau$.}
    \label{fig:hyper}
\end{figure*}









In this section, we address \textbf{RQ2} by evaluating the generalization of our method with the pointwise loss function, analyzing the consistency between Theorem~\ref{the:p_i_j} and practical results, and verifying the advantage of our method in terms of time complexity.

\textbf{Pointwise Loss Function.}  
To further demonstrate the generalization of PLD, we evaluate its performance using the pointwise loss function, specifically Binary Cross-Entropy (BCE) loss. Table~\ref{tab:bce_loss} presents the results with MF as the backbone model on the MIND dataset. Unlike the results with pairwise loss functions shown in Table~\ref{tab:performance}, all denoising methods show improvements under MF with the BCE loss function, particularly T-CE. Since these methods are originally designed with BCE loss in mind, they perform well with BCE but struggle to adapt to BPR loss. In contrast, our method, PLD, not only adapts but also achieves the best results with BCE loss, showing a 6.98\% improvement in Recall@20 and a 4.94\% improvement in NDCG@20.


\textbf{Theorem Validation.}
To evaluate the consistency between Theorem~\ref{the:p_i_j} and practical results, and thereby demonstrate the effectiveness of PLD, we examine the alignment between the theoretical value $\mathbb{E}[\Lambda_{\text{normal}} - \Lambda_{\text{noise}}]$ and its practical counterpart. We also compare these values to the probability values under a standard training process without resampling. Since Theorem~\ref{the:p_i_j} contains a constant $C \in [\alpha, \beta]$, we approximate it by setting $C = \frac{\alpha + \beta}{2}$ for probability calculations.

We randomly selecte 6 users from the dataset and use Equation~\ref{eq:the} to calculate $\mathbb{E}[\Lambda_{\text{normal}} - \Lambda_{\text{noise}}]$. Concurrently, we compute the practical value through 100 simulations of the sampling process in lines 5-7 of Algorithm~\ref{al:dtr}. Finally, we obtain the standard value by running 100 simulations using the standard training process without resampling.

As shown in Figure~\ref{fig:exception}, the theoretical value of $\mathbb{E}[\Lambda_{\text{normal}} - \Lambda_{\text{noise}}]$ closely aligns with the practical value, verifying the correctness of our theoretical analysis. Moreover, we observe that the practical value corresponding to PLD is significantly higher than the standard value, highlighting the effectiveness of our method.

Additionally, we compare the number of normal and noisy interactions sampled in each epoch for PLD and standard training, as shown in Figure~\ref{fig:noise_num}. PLD significantly reduces the number of noisy interactions sampled. 

\begin{figure}
    \centering
    \includegraphics[width=0.475\textwidth]{Imgs/train_time.png}
    \caption{Training time per epoch (in seconds) with batch size 2048 on MIND.}
    \label{fig:time}
\end{figure}

\textbf{Time Complexity.}
To validate the advantage of our method in terms of time complexity, we compare the per-epoch runtime of baseline methods on the MIND dataset. Training is conducted on an RTX 4090, and we record the average training time over 100 epochs. To avoid GPU memory limitations, we standardize the batch size to 2048, which reduces the number of sorting operations within each batch, thereby lowering the time complexity for methods like T-CE~\cite{wang2021denoising} and DCF~\cite{he2024double} that rely on batch-level sorting.

As shown in Figure~\ref{fig:time}, BOD~\cite{wang2023efficient} incurs additional time costs due to the extra training required for the weight encoder and decoder. T-CE and DCF require sorting the loss within each batch, leading to higher time costs. DeCA~\cite{wang2022learning} involves training multiple models, further increasing time overhead. In contrast, both R-CE~\cite{wang2021denoising} and \textbf{our method}, PLD, do not significantly increase time complexity, as their time is close to that of the backbone model.

