

In this section, we address \textbf{RQ3} by exploring the effects of hyperparameters on MIND with MF as the backbone model, specifically the candidate pool size $k$ and the temperature coefficient $\tau$. The results are shown in Figure~\ref{fig:hyper}.

\textbf{Analysis of Hyper-Parameter $k$.} With $\tau$ fixed at 0.1, we vary $k$ within the range $[2, 3, 5, 10, 15, 20]$. We observe that when the candidate pool size is too small, i.e., $k = 2$, the high sampling variance often results in the candidate pool being dominated by noisy samples. At $k = 5$, the method consistently achieves good performance across all noise ratios. Beyond $k = 10$, the performance stabilizes, showing minimal additional improvements.

\textbf{Analysis of Hyper-Parameter $\tau$.} With $k$ set to 5, we vary $\tau$ within the range $[0.01, 0.05, 0.1, 0.2, 0.3, 0.4]$. We find that when $\tau$ is large, i.e., $\tau \geq 0.2$, the performance of PLD fluctuates significantly. In contrast, when $\tau \leq 0.1$, the performance becomes more stable. Specifically, at $\tau = 0.05$, the results exhibit smaller variations across different noise ratios, indicating that PLD has a stronger denoising effect under this configuration.

