
@article{huang2022towards,
  title={Towards reasoning in large language models: A survey},
  author={Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2212.10403},
  year={2022}
}
@inproceedings{kim2024translating,
  title={Translating QA is Enough: A Key to Unlocking In-context Cross-lingual Performance},
  author={Kim, Sunkyoung and Ki, Dayeon and Kim, Yireun and Lee, Jinsik},
  booktitle={ICML 2024 Workshop on In-Context Learning}
}

@article{nezhad2024drives,
  title={What Drives Performance in Multilingual Language Models?},
  author={Nezhad, Sina Bagheri and Agrawal, Ameeta},
  journal={arXiv preprint arXiv:2404.19159},
  year={2024}
}

@article{bawden2023investigating,
  title={Investigating the translation performance of a large multilingual language model: the case of bloom},
  author={Bawden, Rachel and Yvon, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:2303.01911},
  year={2023}
}

@article{kim2023boosting,
  title={Boosting cross-lingual transferability in multilingual models via in-context learning},
  author={Kim, Sunkyoung and Ki, Dayeon and Kim, Yireun and Lee, Jinsik},
  journal={arXiv preprint arXiv:2305.15233},
  year={2023}
}

@article{saba2024llms,
  title={LLMs' Understanding of Natural Language Revealed},
  author={Saba, Walid S},
  journal={arXiv preprint arXiv:2407.19630},
  year={2024}
}
@article{zhu2023multilingual,
  title={Multilingual machine translation with large language models: Empirical results and analysis},
  author={Zhu, Wenhao and Liu, Hongyi and Dong, Qingxiu and Xu, Jingjing and Huang, Shujian and Kong, Lingpeng and Chen, Jiajun and Li, Lei},
  journal={arXiv preprint arXiv:2304.04675},
  year={2023}
}

@article{shaham2024multilingual,
  title={Multilingual instruction tuning with just a pinch of multilinguality},
  author={Shaham, Uri and Herzig, Jonathan and Aharoni, Roee and Szpektor, Idan and Tsarfaty, Reut and Eyal, Matan},
  journal={arXiv preprint arXiv:2401.01854},
  year={2024}
}



@article{joshi2020state,
  title={The state and fate of linguistic diversity and inclusion in the NLP world},
  author={Joshi, Pratik and Santy, Sebastin and Budhiraja, Amar and Bali, Kalika and Choudhury, Monojit},
  journal={arXiv preprint arXiv:2004.09095},
  year={2020}
}

@article{jain2019entity,
  title={Entity projection via machine translation for cross-lingual NER},
  author={Jain, Alankar and Paranjape, Bhargavi and Lipton, Zachary C},
  journal={arXiv preprint arXiv:1909.05356},
  year={2019}
}

@article{intrator2024breaking,
  title={Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?},
  author={Intrator, Yotam and Halfon, Matan and Goldenberg, Roman and Tsarfaty, Reut and Eyal, Matan and Rivlin, Ehud and Matias, Yossi and Aizenberg, Natalia},
  journal={arXiv preprint arXiv:2403.04792},
  year={2024}
}
@article{nicholas2023lost,
  title={Lost in Translation: Large Language Models in Non-English Content Analysis},
  author={Nicholas, Gabriel and Bhatia, Aliya},
  journal={arXiv preprint arXiv:2306.07377},
  year={2023}
}
@article{cui2023efficient,
  title={Efficient and effective text encoding for chinese llama and alpaca},
  author={Cui, Yiming and Yang, Ziqing and Yao, Xin},
  journal={arXiv preprint arXiv:2304.08177},
  year={2023}
}

@inproceedings{ratinov2009design,
  title={Design challenges and misconceptions in named entity recognition},
  author={Ratinov, Lev and Roth, Dan},
  booktitle={Proceedings of the thirteenth conference on computational natural language learning (CoNLL-2009)},
  pages={147--155},
  year={2009}
}
@article{anderson2010many,
  title={How many languages are there in the world},
  author={Anderson, Stephen R},
  journal={Linguistic Society of America},
  pages={1--12},
  year={2010}
}
@inproceedings{agrawal1993mining,
  title={Mining association rules between sets of items in large databases},
  author={Agrawal, Rakesh and Imieli{\'n}ski, Tomasz and Swami, Arun},
  booktitle={Proceedings of the 1993 ACM SIGMOD international conference on Management of data},
  pages={207--216},
  year={1993}
}

@article{liu2024translation,
  title={Is translation all you need? a study on solving multilingual tasks with large language models},
  author={Liu, Chaoqun and Zhang, Wenxuan and Zhao, Yiran and Luu, Anh Tuan and Bing, Lidong},
  journal={arXiv preprint arXiv:2403.10258},
  year={2024}
}
@article{qin2023cross,
  title={Cross-lingual prompting: Improving zero-shot chain-of-thought reasoning across languages},
  author={Qin, Libo and Chen, Qiguang and Wei, Fuxuan and Huang, Shijue and Che, Wanxiang},
  journal={arXiv preprint arXiv:2310.14799},
  year={2023}
}
@article{huang2023not,
  title={Not all languages are created equal in llms: Improving multilingual capability by cross-lingual-thought prompting},
  author={Huang, Haoyang and Tang, Tianyi and Zhang, Dongdong and Zhao, Wayne Xin and Song, Ting and Xia, Yan and Wei, Furu},
  journal={arXiv preprint arXiv:2305.07004},
  year={2023}
}
@article{rei2020comet,
  title={COMET: A neural framework for MT evaluation},
  author={Rei, Ricardo and Stewart, Craig and Farinha, Ana C and Lavie, Alon},
  journal={arXiv preprint arXiv:2009.09025},
  year={2020}
}

@article{shi2022language,
  title={Language models are multilingual chain-of-thought reasoners},
  author={Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.03057},
  year={2022}
}
@article{muennighoff2022crosslingual,
  title={Crosslingual generalization through multitask finetuning},
  author={Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and others},
  journal={arXiv preprint arXiv:2211.01786},
  year={2022}
}
@article{le2023bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Le Scao, Teven and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  year={2023}
}
@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
}

@article{winata2021language,
  title={Language models are few-shot multilingual learners},
  author={Winata, Genta Indra and Madotto, Andrea and Lin, Zhaojiang and Liu, Rosanne and Yosinski, Jason and Fung, Pascale},
  journal={arXiv preprint arXiv:2109.07684},
  year={2021}
}


@inproceedings{bareiss2024english,
  title={English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts},
  author={Barei{\ss}, Patrick and Klinger, Roman and Barnes, Jeremy},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1318--1326},
  year={2024}
}
@article{zhao2021discrete,
  title={Discrete and soft prompting for multilingual models},
  author={Zhao, Mengjie and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2109.03630},
  year={2021}
}



@article{malmasi2022multiconer,
  title={MultiCoNER: A large-scale multilingual dataset for complex named entity recognition},
  author={Malmasi, Shervin and Fang, Anjie and Fetahu, Besnik and Kar, Sudipta and Rokhlenko, Oleg},
  journal={arXiv preprint arXiv:2208.14536},
  year={2022}
}
@article{heinzerling2020language,
  title={Language models as knowledge bases: On entity representations, storage capacity, and paraphrased queries},
  author={Heinzerling, Benjamin and Inui, Kentaro},
  journal={arXiv preprint arXiv:2008.09036},
  year={2020}
}

@article{hegland2007apriori,
  title={The apriori algorithm--a tutorial},
  author={Hegland, Markus},
  journal={Mathematics and computation in imaging science and information processing},
  pages={209--262},
  year={2007},
  publisher={World Scientific}
}
@article{piatetsky1991discovery,
  title={Discovery, analysis, and presentation of strong rules},
  author={Piatetsky-Shapiro, Gregory},
  journal={Knowledge Discovery in Data-bases},
  pages={229--248},
  year={1991},
  publisher={AAAI Press}
}


@article{ye2023context,
  title={In-context instruction learning},
  author={Ye, Seonghyeon and Hwang, Hyeonbin and Yang, Sohee and Yun, Hyeongu and Kim, Yireun and Seo, Minjoon},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{vilar2022prompting,
  title={Prompting palm for translation: Assessing strategies and performance},
  author={Vilar, David and Freitag, Markus and Cherry, Colin and Luo, Jiaming and Ratnakar, Viresh and Foster, George},
  journal={arXiv preprint arXiv:2211.09102},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chen2021zero,
  title={Zero-shot cross-lingual transfer of neural machine translation with multilingual pretrained encoders},
  author={Chen, Guanhua and Ma, Shuming and Chen, Yun and Dong, Li and Zhang, Dongdong and Pan, Jia and Wang, Wenping and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08757},
  year={2021}
}

@article{ma2021deltalm,
  title={Deltalm: Encoder-decoder pre-training for language generation and translation by augmenting pretrained multilingual encoders},
  author={Ma, Shuming and Dong, Li and Huang, Shaohan and Zhang, Dongdong and Muzio, Alexandre and Singhal, Saksham and Awadalla, Hany Hassan and Song, Xia and Wei, Furu},
  journal={arXiv preprint arXiv:2106.13736},
  year={2021}
}
@article{qin2024multilingual,
  title={Multilingual large language model: A survey of resources, taxonomy and frontiers},
  author={Qin, Libo and Chen, Qiguang and Zhou, Yuhang and Chen, Zhi and Li, Yinghui and Liao, Lizi and Li, Min and Che, Wanxiang and Yu, Philip S},
  journal={arXiv preprint arXiv:2404.04925},
  year={2024}
}

@article{liang2020xglue,
  title={XGLUE: A new benchmark dataset for cross-lingual pre-training, understanding and generation},
  author={Liang, Yaobo and Duan, Nan and Gong, Yeyun and Wu, Ning and Guo, Fenfei and Qi, Weizhen and Gong, Ming and Shou, Linjun and Jiang, Daxin and Cao, Guihong and others},
  journal={arXiv preprint arXiv:2004.01401},
  year={2020}
}
@inproceedings{kakwani2020indicnlpsuite,
  title={IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian languages},
  author={Kakwani, Divyanshu and Kunchukuttan, Anoop and Golla, Satish and Gokul, NC and Bhattacharyya, Avik and Khapra, Mitesh M and Kumar, Pratyush},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={4948--4961},
  year={2020}
}}


@inproceedings{hu2020xtreme,
  title={Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation},
  author={Hu, Junjie and Ruder, Sebastian and Siddhant, Aditya and Neubig, Graham and Firat, Orhan and Johnson, Melvin},
  booktitle={International Conference on Machine Learning},
  pages={4411--4421},
  year={2020},
  organization={PMLR}
}
@article{andersland2024amharic,
  title={Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages},
  author={Andersland, Michael},
  journal={arXiv preprint arXiv:2403.06354},
  year={2024}
}

@article{mullappilly2023arabic,
  title={Arabic Mini-ClimateGPT: A Climate Change and Sustainability Tailored Arabic LLM},
  author={Mullappilly, Sahal Shaji and Shaker, Abdelrahman and Thawakar, Omkar and Cholakkal, Hisham and Anwer, Rao Muhammad and Khan, Salman and Khan, Fahad Shahbaz},
  journal={arXiv preprint arXiv:2312.09366},
  year={2023}
}


@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}
@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}


@article{conneau2018xnli,
  title={XNLI: Evaluating cross-lingual sentence representations},
  author={Conneau, Alexis and Lample, Guillaume and Rinott, Ruty and Williams, Adina and Bowman, Samuel R and Schwenk, Holger and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1809.05053},
  year={2018}
}
@article{ogundepo2023afriqa,
  title={Afriqa: Cross-lingual open-retrieval question answering for african languages},
  author={Ogundepo, Odunayo and Gwadabe, Tajuddeen R and Rivera, Clara E and Clark, Jonathan H and Ruder, Sebastian and Adelani, David Ifeoluwa and Dossou, Bonaventure FP and Diop, Abdou Aziz and Sikasote, Claytone and Hacheme, Gilles and others},
  journal={arXiv preprint arXiv:2305.06897},
  year={2023}
}


@article{clark2020tydi,
  title={Tydi qa: A benchmark for information-seeking question answering in ty pologically di verse languages},
  author={Clark, Jonathan H and Choi, Eunsol and Collins, Michael and Garrette, Dan and Kwiatkowski, Tom and Nikolaev, Vitaly and Palomaki, Jennimaria},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={454--470},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{liu2019xqa,
  title={XQA: A cross-lingual open-domain question answering dataset},
  author={Liu, Jiahua and Lin, Yankai and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2358--2368},
  year={2019}
}
@inproceedings{lin2022few,
  title={Few-shot learning with multilingual generative language models},
  author={Lin, Xi Victoria and Mihaylov, Todor and Artetxe, Mikel and Wang, Tianlu and Chen, Shuohui and Simig, Daniel and Ott, Myle and Goyal, Naman and Bhosale, Shruti and Du, Jingfei and others},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={9019--9052},
  year={2022}
}
@article{qin2023chatgpt,
  title={Is chatgpt a general-purpose natural language processing task solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv preprint arXiv:2302.06476},
  year={2023}
}

@article{ahuja2023mega,
  title={Mega: Multilingual evaluation of generative ai},
  author={Ahuja, Kabir and Diddee, Harshita and Hada, Rishav and Ochieng, Millicent and Ramesh, Krithika and Jain, Prachi and Nambi, Akshay and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and others},
  journal={arXiv preprint arXiv:2303.12528},
  year={2023}
}



@article{artetxe2019cross,
  title={On the cross-lingual transferability of monolingual representations},
  author={Artetxe, Mikel and Ruder, Sebastian and Yogatama, Dani},
  journal={arXiv preprint arXiv:1910.11856},
  year={2019}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}
@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}


@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{littell2017uriel,
  title={URIEL and lang2vec: Representing languages as typological, geographical, and phylogenetic vectors},
  author={Littell, Patrick and Mortensen, David R and Lin, Ke and Kairis, Katherine and Turner, Carlisle and Levin, Lori},
  booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},
  pages={8--14},
  year={2017}
}

@inproceedings{pan2017cross,
  title={Cross-lingual name tagging and linking for 282 languages},
  author={Pan, Xiaoman and Zhang, Boliang and May, Jonathan and Nothman, Joel and Knight, Kevin and Ji, Heng},
  booktitle={Proceedings of the 55th annual meeting of the association for computational linguistics (volume 1: long papers)},
  pages={1946--1958},
  year={2017}
}


@article{adelani2021masakhaner,
  title={MasakhaNER: Named entity recognition for African languages},
  author={Adelani, David Ifeoluwa and Abbott, Jade and Neubig, Graham and D’souza, Daniel and Kreutzer, Julia and Lignos, Constantine and Palen-Michel, Chester and Buzaaba, Happy and Rijhwani, Shruti and Ruder, Sebastian and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1116--1131},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@article{hasan2021xl,
  title={XL-sum: Large-scale multilingual abstractive summarization for 44 languages},
  author={Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md Saiful and Samin, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M Sohel and Shahriyar, Rifat},
  journal={arXiv preprint arXiv:2106.13822},
  year={2021}
}

@article{doddapaneni2022indicxtreme,
  title={Indicxtreme: A multi-task benchmark for evaluating indic languages},
  author={Doddapaneni, Sumanth and Aralikatte, Rahul and Ramesh, Gowtham and Goyal, Shreya and Khapra, Mitesh M and Kunchukuttan, Anoop and Kumar, Pratyush},
  journal={arXiv preprint arXiv:2212.05409},
  year={2022}
}

@article{Artetxe:etal:2019,
      author    = {Mikel Artetxe and Sebastian Ruder and Dani Yogatama},
      title     = {On the cross-lingual transferability of monolingual representations},
      journal   = {CoRR},
      volume    = {abs/1910.11856},
      year      = {2019},
      archivePrefix = {arXiv},
      eprint    = {1910.11856}
}

@inproceedings{conneau-etal-2018-xnli,
    title = "{XNLI}: Evaluating Cross-lingual Sentence Representations",
    author = "Conneau, Alexis  and
      Rinott, Ruty  and
      Lample, Guillaume  and
      Williams, Adina  and
      Bowman, Samuel  and
      Schwenk, Holger  and
      Stoyanov, Veselin",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1269",
    doi = "10.18653/v1/D18-1269",
    pages = "2475--2485",
    abstract = "State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models. These models are generally trained on data in a single language (usually English), and cannot be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 14 languages, including low-resource languages such as Swahili and Urdu. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We find that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available baselines.",
}


@inproceedings{zhang-etal-2023-dont,
    title = "Don{'}t Trust {C}hat{GPT} when your Question is not in {E}nglish: A Study of Multilingual Abilities and Types of {LLM}s",
    author = "Zhang, Xiang  and
      Li, Senyu  and
      Hauer, Bradley  and
      Shi, Ning  and
      Kondrak, Grzegorz",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.491",
    doi = "10.18653/v1/2023.emnlp-main.491",
    pages = "7915--7927",
    abstract = "Large language models (LLMs) have demonstrated exceptional natural language understanding abilities, and have excelled in a variety of natural language processing (NLP) tasks. Despite the fact that most LLMs are trained predominantly on English, multiple studies have demonstrated their capabilities in a variety of languages. However, fundamental questions persist regarding how LLMs acquire their multilingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing how they use LLMs and interpret their output. In this work, we propose a systematic way of qualitatively and quantitatively evaluating the multilingual capabilities of LLMs. We investigate the phenomenon of cross-language generalization in LLMs, wherein limited multilingual training data leads to advanced multilingual capabilities. To accomplish this, we employ a novel prompt back-translation method. The results demonstrate that LLMs, such as GPT, can effectively transfer learned knowledge across different languages, yielding relatively consistent results in translation-equivariant tasks, in which the correct output does not depend on the language of the input. However, LLMs struggle to provide accurate results in translation-variant tasks, which lack this property, requiring careful user judgment to evaluate the answers.",
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}


@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}


@inproceedings{guzman-etal-2019-flores,
    title = "The {FLORES} Evaluation Datasets for Low-Resource Machine Translation: {N}epali{--}{E}nglish and {S}inhala{--}{E}nglish",
    author = "Guzm{\'a}n, Francisco  and
      Chen, Peng-Jen  and
      Ott, Myle  and
      Pino, Juan  and
      Lample, Guillaume  and
      Koehn, Philipp  and
      Chaudhary, Vishrav  and
      Ranzato, Marc{'}Aurelio",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1632",
    doi = "10.18653/v1/D19-1632",
    pages = "6098--6111",
    abstract = "For machine translation, a vast majority of language pairs in the world are considered low-resource because they have little parallel data available. Besides the technical challenges of learning with limited supervision, it is difficult to evaluate methods trained on low-resource language pairs because of the lack of freely and publicly available benchmarks. In this work, we introduce the FLORES evaluation datasets for Nepali{--}English and Sinhala{--} English, based on sentences translated from Wikipedia. Compared to English, these are languages with very different morphology and syntax, for which little out-of-domain parallel data is available and for which relatively large amounts of monolingual data are freely available. We describe our process to collect and cross-check the quality of translations, and we report baseline performance using several learning settings: fully supervised, weakly supervised, semi-supervised, and fully unsupervised. Our experiments demonstrate that current state-of-the-art methods perform rather poorly on this benchmark, posing a challenge to the research community working on low-resource MT. Data and code to reproduce our experiments are available at \url{https://github.com/facebookresearch/flores}.",
}


@inproceedings{zhang2023don,
  title={Don’t trust ChatGPT when your question is not in English: A study of multilingual abilities and types of LLMs},
  author={Zhang, Xiang and Li, Senyu and Hauer, Bradley and Shi, Ning and Kondrak, Grzegorz},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={7915--7927},
  year={2023}
}


@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@article{narayan2018don,
  title={Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  journal={arXiv preprint arXiv:1808.08745},
  year={2018}
}


@article{gueta2023explicit,
  title={Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew},
  author={Gueta, Eylon and Goldman, Omer and Tsarfaty, Reut},
  journal={arXiv preprint arXiv:2311.00658},
  year={2023}
}


@article{wu2020all,
  title={Are all languages created equal in multilingual BERT?},
  author={Wu, Shijie and Dredze, Mark},
  journal={arXiv preprint arXiv:2005.09093},
  year={2020}
}
@article{wu2020all,
  title={Are all languages created equal in multilingual BERT?},
  author={Wu, Shijie and Dredze, Mark},
  journal={arXiv preprint arXiv:2005.09093},
  year={2020}
}

@article{bach2022promptsource,
  title={Promptsource: An integrated development environment and repository for natural language prompts},
  author={Bach, Stephen H and Sanh, Victor and Yong, Zheng-Xin and Webson, Albert and Raffel, Colin and Nayak, Nihal V and Sharma, Abheesht and Kim, Taewoon and Bari, M Saiful and Fevry, Thibault and others},
  journal={arXiv preprint arXiv:2202.01279},
  year={2022}
}
@article{shen2023anything,
  title={" do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models},
  author={Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
  journal={arXiv preprint arXiv:2308.03825},
  year={2023}
}




@inproceedings{narayan-etal-2018-dont,
    title = "Don{'}t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization",
    author = "Narayan, Shashi  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1206",
    doi = "10.18653/v1/D18-1206",
    pages = "1797--1807",
    abstract = "We introduce {``}extreme summarization{''}, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question {``}What is the article about?{''}. We collect a real-world, large-scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC). We propose a novel abstractive model which is conditioned on the article{'}s topics and based entirely on convolutional neural networks. We demonstrate experimentally that this architecture captures long-range dependencies in a document and recognizes pertinent content, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans.",
}


@inproceedings{moratanch2016survey,
  title={A survey on abstractive text summarization},
  author={Moratanch, N and Chitrakala, S},
  booktitle={2016 International Conference on Circuit, power and computing technologies (ICCPCT)},
  pages={1--7},
  year={2016},
  organization={IEEE}
}


@article{soares2020literature,
  title={A literature review on question answering techniques, paradigms and systems},
  author={Soares, Marco Antonio Calijorne and Parreiras, Fernando Silva},
  journal={Journal of King Saud University-Computer and Information Sciences},
  volume={32},
  number={6},
  pages={635--646},
  year={2020},
  publisher={Elsevier}
}



@article{seker2021alephbert,
  title={AlephBERT: A Hebrew large pre-trained language model to start-off your Hebrew NLP application with},
  author={Seker, Amit and Bandel, Elron and Bareket, Dan and Brusilovsky, Idan and Greenfeld, Refael Shaked and Tsarfaty, Reut},
  journal={arXiv preprint arXiv:2104.04052},
  year={2021}
}


@article{shmidman2023dictabert,
  title={DictaBERT: A State-of-the-Art BERT Suite for Modern Hebrew},
  author={Shmidman, Shaltiel and Shmidman, Avi and Koppel, Moshe},
  journal={arXiv preprint arXiv:2308.16687},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{rubin2021learning,
  title={Learning to retrieve prompts for in-context learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  journal={arXiv preprint arXiv:2112.08633},
  year={2021}
}



@article{wu2023brief,
  title={A brief overview of ChatGPT: The history, status quo and potential future development},
  author={Wu, Tianyu and He, Shizhu and Liu, Jingping and Sun, Siqi and Liu, Kang and Han, Qing-Long and Tang, Yang},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={10},
  number={5},
  pages={1122--1136},
  year={2023},
  publisher={IEEE}
}




@article{muller2020being,
  title={When being unseen from mBERT is just the beginning: Handling new languages with multilingual language models},
  author={Muller, Benjamin and Anastasopoulos, Antonis and Sagot, Beno{\^\i}t and Seddah, Djam{\'e}},
  journal={arXiv preprint arXiv:2010.12858},
  year={2020}
}




@article{fang2023chatgpt,
  title={Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation},
  author={Fang, Tao and Yang, Shu and Lan, Kaixin and Wong, Derek F and Hu, Jinpeng and Chao, Lidia S and Zhang, Yue},
  journal={arXiv preprint arXiv:2304.01746},
  year={2023}
}


@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}


@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}

@article{lai2023chatgpt,
  title={Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning},
  author={Lai, Viet Dac and Ngo, Nghia Trung and Veyseh, Amir Pouran Ben and Man, Hieu and Dernoncourt, Franck and Bui, Trung and Nguyen, Thien Huu},
  journal={arXiv preprint arXiv:2304.05613},
  year={2023}
}




@inproceedings{cortes2015advances,
  title={Advances in neural information processing systems 28},
  author={Cortes, Corinna and Lawarence, N and Lee, D and Sugiyama, M and Garnett, R},
  booktitle={Proceedings of the 29th Annual Conference on Neural Information Processing Systems},
  year={2015}
}




@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}


@inproceedings{kocmi2023findings,
  title={Findings of the 2023 Conference on Machine Translation (WMT23): LLMs Are Here But Not Quite There Yet},
  author={Kocmi, Tom and Avramidis, Eleftherios and Bawden, Rachel and Bojar, Ond{\v{r}}ej and Dvorkovich, Anton and Federmann, Christian and Fishel, Mark and Freitag, Markus and Gowda, Thamme and Grundkiewicz, Roman and others},
  booktitle={Proceedings of the Eighth Conference on Machine Translation},
  pages={1--42},
  year={2023}
}


@article{hadi2023survey,
  title={A survey on large language models: Applications, challenges, limitations, and practical usage},
  author={Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  journal={Authorea Preprints},
  year={2023},
  publisher={Authorea}
}



@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}


@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}



@article{fang2023chatgpt,
  title={Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation},
  author={Fang, Tao and Yang, Shu and Lan, Kaixin and Wong, Derek F and Hu, Jinpeng and Chao, Lidia S and Zhang, Yue},
  journal={arXiv preprint arXiv:2304.01746},
  year={2023}
}





@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}


@article{floridi2020gpt,
  title={GPT-3: Its nature, scope, limits, and consequences},
  author={Floridi, Luciano and Chiriatti, Massimo},
  journal={Minds and Machines},
  volume={30},
  pages={681--694},
  year={2020},
  publisher={Springer}
}





@article{mordecai2005hebrew,
  title={Hebrew named entity recognition},
  author={Mordecai, Naama Ben and Elhadad, Michael},
  journal={MONEY},
  volume={81},
  number={83.93},
  pages={82--49},
  year={2005}
}




@article{bareket2021neural,
  title={Neural modeling for named entities and morphology (nemoˆ2)},
  author={Bareket, Dan and Tsarfaty, Reut},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={909--928},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}




@article{sang2003introduction,
  title={Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition},
  author={Sang, Erik F and De Meulder, Fien},
  journal={arXiv preprint cs/0306050},
  year={2003}
}


---------
@inproceedings{eisenstein2010latent,
  title={A latent variable model for geographic lexical variation},
  author={Eisenstein, Jacob and O’Connor, Brendan and Smith, Noah A and Xing, Eric},
  booktitle={Proceedings of the 2010 conference on empirical methods in natural language processing},
  pages={1277--1287},
  year={2010}
}


@inproceedings{wing2011simple,
  title={Simple supervised document geolocation with geodesic grids},
  author={Wing, Benjamin and Baldridge, Jason},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={955--964},
  year={2011}
}

@inproceedings{han2012geolocation,
  title={Geolocation prediction in social media data by finding location indicative words},
  author={Han, Bo and Cook, Paul and Baldwin, Timothy},
  booktitle={Proceedings of COLING 2012},
  pages={1045--1062},
  year={2012}
}

@inproceedings{wing2014hierarchical,
  title={Hierarchical discriminative classification for text-based geolocation},
  author={Wing, Benjamin and Baldridge, Jason},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={336--348},
  year={2014}
}

@inproceedings{qi2020reverie,
  title={Reverie: Remote embodied visual referring expression in real indoor environments},
  author={Qi, Yuankai and Wu, Qi and Anderson, Peter and Wang, Xin and Wang, William Yang and Shen, Chunhua and Hengel, Anton van den},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9982--9991},
  year={2020}
}

@article{bareket2021neural,
  title={Neural modeling for named entities and morphology (nemoˆ2)},
  author={Bareket, Dan and Tsarfaty, Reut},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={909--928},
  year={2021},
  publisher={MIT Press}
}

@incollection{hilbert1935stetige,
  title={{\"U}ber die stetige Abbildung einer Linie auf ein Fl{\"a}chenst{\"u}ck},
  author={Hilbert, David},
  booktitle={Dritter Band: Analysis{\textperiodcentered} Grundlagen der Mathematik{\textperiodcentered} Physik Verschiedenes},
  pages={1--2},
  year={1935},
  publisher={Springer}
}


@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@article{misra2017mapping,
  title={Mapping instructions and visual observations to actions with reinforcement learning},
  author={Misra, Dipendra and Langford, John and Artzi, Yoav},
  journal={arXiv preprint arXiv:1704.08795},
  year={2017}
}

@article{de2018talk,
  title={Talk the walk: Navigating new york city through grounded dialogue},
  author={De Vries, Harm and Shuster, Kurt and Batra, Dhruv and Parikh, Devi and Weston, Jason and Kiela, Douwe},
  journal={arXiv preprint arXiv:1807.03367},
  year={2018}
}

@article{wallgrun2018geocorpora,
  title={GeoCorpora: building a corpus to test and train microblog geoparsers},
  author={Wallgr{\"u}n, Jan Oliver and Karimzadeh, Morteza and MacEachren, Alan M and Pezanowski, Scott},
  journal={International Journal of Geographical Information Science},
  volume={32},
  number={1},
  pages={1--29},
  year={2018},
  publisher={Taylor \& Francis}
}



@article{paz2019run,
  title={Run through the streets: A new dataset and baseline models for realistic urban navigation},
  author={Paz-Argaman, Tzuf and Tsarfaty, Reut},
  journal={arXiv preprint arXiv:1909.08970},
  year={2019}
}

@article{siegel1975development,
  title={The development of spatial representations of large-scale environments},
  author={Siegel, Alexander W and White, Sheldon H},
  journal={Advances in child development and behavior},
  volume={10},
  pages={9--55},
  year={1975},
  publisher={Elsevier}
}

@inproceedings{baldridge2018points,
  title={Points, paths, and playscapes: Large-scale spatial language understanding tasks set in the real world},
  author={Baldridge, Jason and Bedrax-Weiss, Tania and Luong, Daphne and Narayanan, Srini and Pang, Bo and Pereira, Fernando and Soricut, Radu and Tseng, Michael and Zhang, Yuan},
  booktitle={Proceedings of the First International Workshop on Spatial Language Understanding},
  pages={46--52},
  year={2018}
}

@inproceedings{chen2019touchdown,
  title={Touchdown: Natural language navigation and spatial reasoning in visual street environments},
  author={Chen, Howard and Suhr, Alane and Misra, Dipendra and Snavely, Noah and Artzi, Yoav},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12538--12547},
  year={2019}
}

@article{ji2022abstract,
  title={Abstract Visual Reasoning with Tangram Shapes},
  author={Ji, Anya and Kojima, Noriyuki and Rush, Noah and Suhr, Alane and Vong, Wai Keen and Hawkins, Robert D and Artzi, Yoav},
  journal={arXiv preprint arXiv:2211.16492},
  year={2022}
}
@article{fried2022pragmatics,
  title={Pragmatics in Grounded Language Learning: Phenomena, Tasks, and Modeling Approaches},
  author={Fried, Daniel and Tomlin, Nicholas and Hu, Jennifer and Patel, Roma and Nematzadeh, Aida},
  journal={arXiv preprint arXiv:2211.08371},
  year={2022}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{milmo2023,
  title={ChatGPT reaches 100 million users},
  author={Milmo, Dan},
  booktitle={The Guardian},
  year={2023}
}


@article{cohen2023heq,
  title={HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark},
  author={Cohen, Amir and Merhav-Fine, Hilla and Goldberg, Yoav and Tsarfaty, Reut},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={13693--13705},
  year={2023}
}

@article{anderson1991hcrc,
  title={The HCRC map task corpus},
  author={Anderson, Anne H and Bader, Miles and Bard, Ellen Gurman and Boyle, Elizabeth and Doherty, Gwyneth and Garrod, Simon and Isard, Stephen and Kowtko, Jacqueline and McAllister, Jan and Miller, Jim and others},
  journal={Language and speech},
  volume={34},
  number={4},
  pages={351--366},
  year={1991},
  publisher={Sage Publications Sage UK: London, England}
}

@article{ku2020room,
  title={Room-across-room: Multilingual vision-and-language navigation with dense spatiotemporal grounding},
  author={Ku, Alexander and Anderson, Peter and Patel, Roma and Ie, Eugene and Baldridge, Jason},
  journal={arXiv preprint arXiv:2010.07954},
  year={2020}
}

@article{zhong2021silg,
  title={SILG: The Multi-environment Symbolic Interactive Language Grounding Benchmark},
  author={Zhong, Victor and Hanjie, Austin W and Wang, Sida I and Narasimhan, Karthik and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2110.10661},
  year={2021}
}


@article{macmahon2006walk,
  title={Walk the talk: Connecting language, knowledge, and action in route instructions},
  author={MacMahon, Matt and Stankiewicz, Brian and Kuipers, Benjamin},
  journal={Def},
  volume={2},
  number={6},
  pages={4},
  year={2006}
}

@article{ishikawa2006spatial,
  title={Spatial knowledge acquisition from direct experience in the environment: Individual differences in the development of metric knowledge and the integration of separately learned places},
  author={Ishikawa, Toru and Montello, Daniel R},
  journal={Cognitive psychology},
  volume={52},
  number={2},
  pages={93--129},
  year={2006},
  publisher={Elsevier}
}


@article{lynch1960image,
  title={The image of the environment},
  author={Lynch, Kevin},
  journal={The image of the city},
  volume={11},
  pages={1--13},
  year={1960}
}


@inproceedings{Adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{more2019joint,
  title={Joint transition-based models for morpho-syntactic parsing: Parsing strategies for MRLs and a case study from modern Hebrew},
  author={More, Amir and Seker, Amit and Basmova, Victoria and Tsarfaty, Reut},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={33--48},
  year={2019},
  publisher={MIT Press}
}

@article{paz2020zest,
  title={Zest: Zero-shot learning from text descriptions using textual similarity and visual summarization},
  author={Paz-Argaman, Tzuf and Atzmon, Yuval and Chechik, Gal and Tsarfaty, Reut},
  journal={arXiv preprint arXiv:2010.03276},
  year={2020}
}

@article{hayward1995spatial,
  title={Spatial language and spatial representation},
  author={Hayward, William G and Tarr, Michael J},
  journal={Cognition},
  volume={55},
  number={1},
  pages={39--84},
  year={1995},
  publisher={Elsevier}
}


@article{dutt2021fine,
  title={Fine-grained Geolocation Prediction of Tweets with Human Machine Collaboration},
  author={Dutt, Florina and Das, Subhajit},
  journal={arXiv preprint arXiv:2106.13411},
  year={2021}
}


@inproceedings{thomason2020vision,
  title={Vision-and-dialog navigation},
  author={Thomason, Jesse and Murray, Michael and Cakmak, Maya and Zettlemoyer, Luke},
  booktitle={Conference on Robot Learning},
  pages={394--406},
  year={2020},
  organization={PMLR}
}

@article{tsarfaty2020spmrl,
  title={From SPMRL to NMRL: What did we learn (and unlearn) in a decade of parsing morphologically-rich languages (MRLs)?},
  author={Tsarfaty, Reut and Bareket, Dan and Klein, Stav and Seker, Amit},
  journal={arXiv preprint arXiv:2005.01330},
  year={2020}
}

@incollection{kripke1972naming,
  title={Naming and necessity},
  author={Kripke, Saul A},
  booktitle={Semantics of natural language},
  pages={253--355},
  year={1972},
  publisher={Springer}
}

@article{tsarfaty2019s,
  title={What's Wrong with Hebrew NLP? And How to Make it Right},
  author={Tsarfaty, Reut and Seker, Amit and Sadde, Shoval and Klein, Stav},
  journal={arXiv preprint arXiv:1908.05453},
  year={2019}
}

@inproceedings{seker2022alephbert,
  title={AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level},
  author={Seker, Amit and Bandel, Elron and Bareket, Dan and Brusilovsky, Idan and Greenfeld, Refael and Tsarfaty, Reut},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={46--56},
  year={2022}
}

@article{karimzadeh2019geotxt,
  title={GeoTxt: A scalable geoparsing system for unstructured text geolocation},
  author={Karimzadeh, Morteza and Pezanowski, Scott and MacEachren, Alan M and Wallgr{\"u}n, Jan O},
  journal={Transactions in GIS},
  volume={23},
  number={1},
  pages={118--136},
  year={2019},
  publisher={Wiley Online Library}
}

@inproceedings{roller2012supervised,
  title={Supervised text-based geolocation using language models on an adaptive grid},
  author={Roller, Stephen and Speriosu, Michael and Rallapalli, Sarat and Wing, Benjamin and Baldridge, Jason},
  booktitle={Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning},
  pages={1500--1510},
  year={2012}
}



@article{kniestedt2022re,
  title={Re-framing engagement for applied games: A conceptual framework},
  author={Kniestedt, Isabelle and Lefter, Iulia and Lukosch, Stephan and Brazier, Frances M},
  journal={Entertainment Computing},
  volume={41},
  pages={100475},
  year={2022},
  publisher={Elsevier}
}