@article{ahuja2023mega,
  title={Mega: Multilingual evaluation of generative ai},
  author={Ahuja, Kabir and Diddee, Harshita and Hada, Rishav and Ochieng, Millicent and Ramesh, Krithika and Jain, Prachi and Nambi, Akshay and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and others},
  journal={arXiv preprint arXiv:2303.12528},
  year={2023}
}

@article{andersland2024amharic,
  title={Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages},
  author={Andersland, Michael},
  journal={arXiv preprint arXiv:2403.06354},
  year={2024}
}

@article{anderson2010many,
  title={How many languages are there in the world},
  author={Anderson, Stephen R},
  journal={Linguistic Society of America},
  pages={1--12},
  year={2010}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chen2021zero,
  title={Zero-shot cross-lingual transfer of neural machine translation with multilingual pretrained encoders},
  author={Chen, Guanhua and Ma, Shuming and Chen, Yun and Dong, Li and Zhang, Dongdong and Pan, Jia and Wang, Wenping and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08757},
  year={2021}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@article{cui2023efficient,
  title={Efficient and effective text encoding for chinese llama and alpaca},
  author={Cui, Yiming and Yang, Ziqing and Yao, Xin},
  journal={arXiv preprint arXiv:2304.08177},
  year={2023}
}

@inproceedings{hu2020xtreme,
  title={Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation},
  author={Hu, Junjie and Ruder, Sebastian and Siddhant, Aditya and Neubig, Graham and Firat, Orhan and Johnson, Melvin},
  booktitle={International Conference on Machine Learning},
  pages={4411--4421},
  year={2020},
  organization={PMLR}
}

@article{huang2023not,
  title={Not all languages are created equal in llms: Improving multilingual capability by cross-lingual-thought prompting},
  author={Huang, Haoyang and Tang, Tianyi and Zhang, Dongdong and Zhao, Wayne Xin and Song, Ting and Xia, Yan and Wei, Furu},
  journal={arXiv preprint arXiv:2305.07004},
  year={2023}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@inproceedings{kakwani2020indicnlpsuite,
  title={IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian languages},
  author={Kakwani, Divyanshu and Kunchukuttan, Anoop and Golla, Satish and Gokul, NC and Bhattacharyya, Avik and Khapra, Mitesh M and Kumar, Pratyush},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={4948--4961},
  year={2020}
}}

@article{le2023bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Le Scao, Teven and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  year={2023}
}

@article{liang2020xglue,
  title={XGLUE: A new benchmark dataset for cross-lingual pre-training, understanding and generation},
  author={Liang, Yaobo and Duan, Nan and Gong, Yeyun and Wu, Ning and Guo, Fenfei and Qi, Weizhen and Gong, Ming and Shou, Linjun and Jiang, Daxin and Cao, Guihong and others},
  journal={arXiv preprint arXiv:2004.01401},
  year={2020}
}

@article{liu2024translation,
  title={Is translation all you need? a study on solving multilingual tasks with large language models},
  author={Liu, Chaoqun and Zhang, Wenxuan and Zhao, Yiran and Luu, Anh Tuan and Bing, Lidong},
  journal={arXiv preprint arXiv:2403.10258},
  year={2024}
}

@article{muennighoff2022crosslingual,
  title={Crosslingual generalization through multitask finetuning},
  author={Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and others},
  journal={arXiv preprint arXiv:2211.01786},
  year={2022}
}

@article{ogundepo2023afriqa,
  title={Afriqa: Cross-lingual open-retrieval question answering for african languages},
  author={Ogundepo, Odunayo and Gwadabe, Tajuddeen R and Rivera, Clara E and Clark, Jonathan H and Ruder, Sebastian and Adelani, David Ifeoluwa and Dossou, Bonaventure FP and Diop, Abdou Aziz and Sikasote, Claytone and Hacheme, Gilles and others},
  journal={arXiv preprint arXiv:2305.06897},
  year={2023}
}

@article{qin2023chatgpt,
  title={Is chatgpt a general-purpose natural language processing task solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv preprint arXiv:2302.06476},
  year={2023}
}

@article{qin2024multilingual,
  title={Multilingual large language model: A survey of resources, taxonomy and frontiers},
  author={Qin, Libo and Chen, Qiguang and Zhou, Yuhang and Chen, Zhi and Li, Yinghui and Liao, Lizi and Li, Min and Che, Wanxiang and Yu, Philip S},
  journal={arXiv preprint arXiv:2404.04925},
  year={2024}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{seker2022alephbert,
  title={AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level},
  author={Seker, Amit and Bandel, Elron and Bareket, Dan and Brusilovsky, Idan and Greenfeld, Refael and Tsarfaty, Reut},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={46--56},
  year={2022}
}

@article{shaham2024multilingual,
  title={Multilingual instruction tuning with just a pinch of multilinguality},
  author={Shaham, Uri and Herzig, Jonathan and Aharoni, Roee and Szpektor, Idan and Tsarfaty, Reut and Eyal, Matan},
  journal={arXiv preprint arXiv:2401.01854},
  year={2024}
}

@article{shi2022language,
  title={Language models are multilingual chain-of-thought reasoners},
  author={Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.03057},
  year={2022}
}

@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
}

@article{zhao2021discrete,
  title={Discrete and soft prompting for multilingual models},
  author={Zhao, Mengjie and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2109.03630},
  year={2021}
}

