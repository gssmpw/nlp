[
  {
    "index": 0,
    "papers": [
      {
        "key": "anderson2010many",
        "author": "Anderson, Stephen R",
        "title": "How many languages are there in the world"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "seker2022alephbert",
        "author": "Seker, Amit and Bandel, Elron and Bareket, Dan and Brusilovsky, Idan and Greenfeld, Refael and Tsarfaty, Reut",
        "title": "AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level"
      },
      {
        "key": "cui2023efficient",
        "author": "Cui, Yiming and Yang, Ziqing and Yao, Xin",
        "title": "Efficient and effective text encoding for chinese llama and alpaca"
      },
      {
        "key": "andersland2024amharic",
        "author": "Andersland, Michael",
        "title": "Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "qin2024multilingual",
        "author": "Qin, Libo and Chen, Qiguang and Zhou, Yuhang and Chen, Zhi and Li, Yinghui and Liao, Lizi and Li, Min and Che, Wanxiang and Yu, Philip S",
        "title": "Multilingual large language model: A survey of resources, taxonomy and frontiers"
      },
      {
        "key": "jiang2024mixtral",
        "author": "Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others",
        "title": "Mixtral of experts"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "raffel2020exploring",
        "author": "Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J",
        "title": "Exploring the limits of transfer learning with a unified text-to-text transformer"
      },
      {
        "key": "conneau2019unsupervised",
        "author": "Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin",
        "title": "Unsupervised cross-lingual representation learning at scale"
      },
      {
        "key": "chowdhery2023palm",
        "author": "Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others",
        "title": "Palm: Scaling language modeling with pathways"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "xue2020mt5",
        "author": "Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin",
        "title": "mT5: A massively multilingual pre-trained text-to-text transformer"
      },
      {
        "key": "chen2021zero",
        "author": "Chen, Guanhua and Ma, Shuming and Chen, Yun and Dong, Li and Zhang, Dongdong and Pan, Jia and Wang, Wenping and Wei, Furu",
        "title": "Zero-shot cross-lingual transfer of neural machine translation with multilingual pretrained encoders"
      },
      {
        "key": "le2023bloom",
        "author": "Le Scao, Teven and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\\'c}, Suzana and Hesslow, Daniel and Castagn{\\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\\c{c}}ois and Gall{\\'e}, Matthias and others",
        "title": "Bloom: A 176b-parameter open-access multilingual language model"
      },
      {
        "key": "shaham2024multilingual",
        "author": "Shaham, Uri and Herzig, Jonathan and Aharoni, Roee and Szpektor, Idan and Tsarfaty, Reut and Eyal, Matan",
        "title": "Multilingual instruction tuning with just a pinch of multilinguality"
      },
      {
        "key": "muennighoff2022crosslingual",
        "author": "Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and others",
        "title": "Crosslingual generalization through multitask finetuning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "brown2020language",
        "author": "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others",
        "title": "Language models are few-shot learners"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hu2020xtreme",
        "author": "Hu, Junjie and Ruder, Sebastian and Siddhant, Aditya and Neubig, Graham and Firat, Orhan and Johnson, Melvin",
        "title": "Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation"
      },
      {
        "key": "liang2020xglue",
        "author": "Liang, Yaobo and Duan, Nan and Gong, Yeyun and Wu, Ning and Guo, Fenfei and Qi, Weizhen and Gong, Ming and Shou, Linjun and Jiang, Daxin and Cao, Guihong and others",
        "title": "XGLUE: A new benchmark dataset for cross-lingual pre-training, understanding and generation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kakwani2020indicnlpsuite",
        "author": "Kakwani, Divyanshu and Kunchukuttan, Anoop and Golla, Satish and Gokul, NC and Bhattacharyya, Avik and Khapra, Mitesh M and Kumar, Pratyush",
        "title": "IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian languages"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "ogundepo2023afriqa",
        "author": "Ogundepo, Odunayo and Gwadabe, Tajuddeen R and Rivera, Clara E and Clark, Jonathan H and Ruder, Sebastian and Adelani, David Ifeoluwa and Dossou, Bonaventure FP and Diop, Abdou Aziz and Sikasote, Claytone and Hacheme, Gilles and others",
        "title": "Afriqa: Cross-lingual open-retrieval question answering for african languages"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "huang2023not",
        "author": "Huang, Haoyang and Tang, Tianyi and Zhang, Dongdong and Zhao, Wayne Xin and Song, Ting and Xia, Yan and Wei, Furu",
        "title": "Not all languages are created equal in llms: Improving multilingual capability by cross-lingual-thought prompting"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zhao2021discrete",
        "author": "Zhao, Mengjie and Sch{\\\"u}tze, Hinrich",
        "title": "Discrete and soft prompting for multilingual models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "shi2022language",
        "author": "Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and others",
        "title": "Language models are multilingual chain-of-thought reasoners"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "chowdhery2023palm",
        "author": "Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others",
        "title": "Palm: Scaling language modeling with pathways"
      },
      {
        "key": "qin2023chatgpt",
        "author": "Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi",
        "title": "Is chatgpt a general-purpose natural language processing task solver?"
      },
      {
        "key": "ahuja2023mega",
        "author": "Ahuja, Kabir and Diddee, Harshita and Hada, Rishav and Ochieng, Millicent and Ramesh, Krithika and Jain, Prachi and Nambi, Akshay and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and others",
        "title": "Mega: Multilingual evaluation of generative ai"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2024translation",
        "author": "Liu, Chaoqun and Zhang, Wenxuan and Zhao, Yiran and Luu, Anh Tuan and Bing, Lidong",
        "title": "Is translation all you need? a study on solving multilingual tasks with large language models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ahuja2023mega",
        "author": "Ahuja, Kabir and Diddee, Harshita and Hada, Rishav and Ochieng, Millicent and Ramesh, Krithika and Jain, Prachi and Nambi, Akshay and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and others",
        "title": "Mega: Multilingual evaluation of generative ai"
      }
    ]
  }
]