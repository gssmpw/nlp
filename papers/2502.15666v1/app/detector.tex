We developed our code-base on the framework of RAID \cite{dugan2024raid}, and kept the hyperparameters for all detectors the same as RAID for a fair evaluation. 

Additionally, we identify the threshold corresponding to a $5\%$ false positive rate (FPR) -- or the lowest possible FPR if it exceeds $5\%$. We notice that -- for most detectors, the thresholds for `best accuracy' and `5\% FPR' do not vary much. Moreover, since our primary focus is on misclassification rates for both minor-polished and major-polished texts, optimizing the threshold for overall accuracy is more appropriate than minimizing FPR alone.

%In this work, we consider the threshold that gives the best accuracy. First, we take $100$ evenly spaced thresholds between minimum and maximum prediction by a detector. Then we evaluate the accuracy for each of them and finally select the one with the best accuracy. 
%Besides this, we also find the threshold that yields $5\%$ false positive rate (the lowest FPR if the lowest is more than $5\%$). We notice that -- for most detectors, the thresholds for `best accuracy' and `5\% FPR' do not vary much. Moreover, since in this work, we focus on misclassifying both the minor-polished and major-polished texts, it seems more rational to optimize the threshold over accuracy, rather than only minimizing the FPR.

Table \ref{tab:detector_threshold} shows the threshold that we found by optimizing the accuracy, and used for the evaluation of our APT-Eval dataset. 

\begin{table*}[h!]
\centering
\resizebox{0.7\textwidth}{!}{%
\begin{tabular}{lllll}
                                       & \textbf{Detector}             & \textbf{Threshold} & \textbf{Accuracy} & \textbf{FPR}    \\ \hline
\multirow{4}{*}{\textbf{Model-Based}}  & \textbf{RADAR}                & 0.8989             & 0.8017            & 0.082           \\
                                       & \textbf{RoBERTa (ChatGPT)}    & 0.333              & \textit{0.8617}   & \textit{0.0217} \\
                                       & \textbf{RoBERTa-Base (GPT2)}  & 0.091              & 0.7917            & 0.06            \\
                                       & \textbf{RoBERTa-Large (GPT2)} & 0.0408             & 0.8               & 0.0817          \\ \hline
\multirow{5}{*}{\textbf{Metric-Based}} & \textbf{GLTR}                 & 0.7038             & 0.845             & 0.0683          \\
                                       & \textbf{DetectGPT}            & 0.355              & 0.725             & 0.085           \\
                                       & \textbf{Fast-DetectGPT}       & 0.778              & 0.8317            & 0.06            \\
                                       & \textbf{LLMDet}               & 0.9798             & 0.605             & 0.2383          \\
                                       & \textbf{Binoculars}           & 0.1075             & \textbf{0.88}     & \textbf{0.018}  \\ \hline
\multirow{2}{*}{\textbf{Commercial}}   & \textbf{ZeroGPT}              & 0.2525             & 0.8067            & 0.0367          \\
                                       & \textbf{GPTZero}              & 0.03               & \textit{0.862}             & 0.075           \\ \hline
\end{tabular}%
}
\caption{Detector-based Threshold, Accuracy, and False Positive Rate. The best performance is in bold, and the second best is in italics.}
\label{tab:detector_threshold}
\end{table*}

%We used one NVIDIA RTXA5000 to run the model-based and metric-based detectors (one RTXA6000 GPU for `Binoculars' detector). For commercial detectors, we used their API subscription. 

For computational resources, we employed:
\begin{itemize}
    \item One NVIDIA RTX A5000 GPU for running model-based and metric-based detectors.
    \item One NVIDIA RTX A6000 GPU for the Binoculars detector.
    \item Commercial API subscriptions for ZeroGPT and GPTZero.
\end{itemize}


