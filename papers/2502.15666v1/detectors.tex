In this work, we evaluate a total of ten detectors from three different categories: 
\begin{enumerate}
    \item \textbf{Model-based:} RADAR \citep{hu2023radar}, RoBERTa-Base (ChatGPT) \citep{guo-etal-2023-hc3}, RoBERTa-Base (GPT2), and RoBERTa-Large (GPT2) \citep{gpt2OutputDataset}.
    
    \item \textbf{Metric-based:} GLTR \citep{gehrmann2019gltr}, DetectGPT \citep{mitchell2023detectgpt}, FastDetectGPT \citep{bao2023fast}, LLMDet \citep{wu2023llmdet}, Binoculars \citep{hans2024spotting}.
    \item \textbf{Commercial:} ZeroGPT \footnote{\url{https://www.zerogpt.com/}}, GPTZero \footnote{\url{https://gptzero.me/}}.
\end{enumerate}

\subsection{Detectors' Threshold}
AI-text detectors generate a scalar score or prediction based on a given sequence of input tokens. To transform this score into a binary classification, an appropriate threshold must be determined. \citet{dugan2024raid} highlight that a naive threshold selection can lead to poor accuracy or a high false positive rate (FPR). Therefore, we optimize the threshold for each detector to achieve maximum accuracy in detecting HWT and AI-text.

We evaluate these detectors on $300$ samples of our `no-polish-HWT' (pure human-written) set and $300$ samples of pure AI-generated texts from the dataset of \citet{zhang2024llm}. Most detectors achieve $70\% - 88\%$ accuracy, with a false positive rate of $1\% - 8\%$. Table \ref{tab:detector_threshold} shows the detector-specific threshold with their accuracy and FPR.

%false positive rate.  
