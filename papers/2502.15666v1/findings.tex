We evaluate the detectors on our APT-Eval dataset from multiple perspectives to analyze their response to AI-polished text. Our key findings are as follows -- 


\subsection{Alarming false positive rate by AI-text detectors for minor polishing.} 
%\smk{Need to merge multiple plots.}
Though most detectors can achieve a low false positive rate on pure HWT (Table \ref{tab:detector_threshold}), most of them give a high false positive rate for any polishing, especially for extremely minor and minor polishing. 
For example, GLTR, with a $6.83\%$ FPR on non-polished text, misclassifies $40.87\%$ of extremely minor and $42.81\%$ of minor-polished GPT-4o texts.
%For instance, while GLTR exhibits a $6.83\%$ FPR on the no-polish-HWT set, it misclassifies a substantial $40.87\%$ of extremely minor and $42.81\%$ of minor polished texts generated by GPT-4o. 
This trend extends to percentage-based polishing, where GLTR misclassifies $26.85\%$ of texts with just $1\%$ AI edits.
%Such an alarming high false positive rate for very minimal polishing is further found in our percentage-based polishing, where the GLTR detector misclassifies $26.85\%$ texts that are only $1\%$ polished by GPT-4o.
The issue persists across LLM polishers, with misclassification rates of:
$39.19\%$ (Llama3.1-70B), $44.86\%$ (Llama3-8B), and $52.31\%$ (Llama2-7B) for extremely minor polishing. 
Figure \ref{fig:combined_result_main} visualizes these misclassification rates, with further details in Appendix \ref{app:result_all_detectors}.


\begin{figure*}[htbp]
    \centering
    % Top row of figures with combined caption
    \begin{minipage}{\textwidth} % Grouping the top row for a combined caption
        \centering
        \begin{subfigure}{0.39\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/result_plots/modified_polish_type_gpt.pdf}
            \caption{GPT-4o}
            \label{fig:gpt4_acc_overall}
        \end{subfigure}
        \hspace{2pt}
        \begin{subfigure}{0.55\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/result_plots/combined_model_polish_type_vs_mgt_llama2.pdf}
            \caption{Llama2-7b}
            \label{fig:llama2_acc_overall}
        \end{subfigure}
    \end{minipage}
    
    \caption{Ratio of degree-based AI-polished-texts (APT) predicted as AI-text by all detectors.}
    \label{fig:combined_result_main}
\end{figure*}

\iffalse
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{images/result_plots/combined_model_polish_type_vs_mgt_llama2.png}
    \caption{Caption}
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{images/result_plots/combined_model_polish_type_vs_mgt_gpt.png}
    \caption{Caption}
    \label{fig:enter-label}
\end{figure}
\fi



\subsection{Most AI-text detectors fail to distinguish between minor and major polishing.} 
% \smk{Re-use previous figure.}

Most detectors not only misclassify a large portion of minor-polished texts but also struggle to differentiate between degrees of AI-driven polishing. For example, RoBERTa-large classifies $47.69\%$ of minor-polished texts as AI-generated, yet its rate for major-polished texts is only slightly higher at $51.98\%$.

%Not only do most detectors misclassify a significant portion of minor-polished texts, but they also struggle to differentiate among varying levels of AI-driven polishing. For instance, while the RoBERTa-large detector classifies $47.69\%$ of minor-polished texts as AI-generated, its classification rate for major-polished texts is only slightly higher at $51.98\%$.

Surprisingly, some detectors misclassify fewer major-polished texts than extremely minor ones, revealing a lack of sensitivity to modification extent. As shown in Figure \ref{fig:combined_result_main}, detectors like DetectGPT, FastDetectGPT, GLTR, RoBERTa-base, RoBERTa-large, and LLMDet follow this trend. FastDetectGPT, for instance, detects $10.07\%$ of texts with $1\%$ AI edits as AI, but only $9.59\%$ for $75\%$ polishing (Figure \ref{fig:result_combined_prct}).
%Surprisingly, some detectors exhibit an even lower AI-text classification rate for major-polished samples, indicating a lack of sensitivity to the extent of modification. As shown in Figure \ref{fig:combined_result_main}, several detectors -- including DetectGPT, FastDetectGPT, GLTR, RoBERTa-base, RoBERTa-large, and LLMDet -- misclassify fewer major-polished texts than extremely minor polished texts when polished by GPT-4o. For example, while the FastDetectGPT method detects $10.07\%$ of $1\%$ polished texts as AI, it only detects $9.59\%$ in the case of $75\%$ polishing (Figure \ref{fig:result_combined_prct}). 
This trend highlights a fundamental limitation: these detectors are largely incapable of accurately distinguishing different degrees of LLM-driven text refinement.


\subsection{Most detectors penalize more if the polisher LLM is older or smaller.}
We analyze whether AI-text detectors exhibit biases across different LLMs and find a higher misclassification rate for smaller and older models (Figure \ref{fig:polisher_llm}). For extremely minor polishing, Llama-2 has a $45\%$ misclassification rate, while GPT-4o and Llama-3 models range from $27\%$ to $32\%$.
%We also investigate whether the misclassification rate of AI-text detectors varies across different LLMs. Our analysis reveals a bias against smaller and older models, as shown in Figure \ref{fig:polisher_llm}. Specifically, detectors exhibit a higher misclassification rate for smaller models such as Llama2-7B and Llama3-8B. Moreover, for extremely-minor polishing, the gap is very significant between older and newer models -- Llama-2 having a misclassification rate of $45\%$, while GPT-4o and Llama-3 models have $27\% \sim 32\%$. 
The probable reason can be -- with time, newer LLMs have become increasingly adept at generating human-like text, making detection more challenging over time. 
However, such an imbalance can create unfair scenarios, where a student using Llama-2 is flagged for minor polishing while another using Llama-3 is found innocent.
%Though, at a glance, such an imbalance in detection rate might seem harmless, it can create an unjust environment where a student is accused guilty for minor-polishing with Llama-2, whereas another is found innocent for using Llama-3.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/polisher_plots/polish_type_results2.pdf}
    \caption{Misclassification rate of AI-polished texts for all polisher LLMs.}
    \label{fig:polisher_llm}
\end{figure}

\subsection{Some domains are more sensitive than others.}
Since our HWT dataset spans six domains, we analyze detector misclassification rates across them. Some domains are misclassified more than others -- `speech' has the highest rate ($36\% - 56\%$ for extreme-minor polishing), while `paper\_abstract' has the lowest ($17\% - 31\%$) (Figure \ref{fig:domain_ext_minor_gpt}). More detailed results are in Figure \ref{fig:domain_all_results} (Appendix \ref{app:domain_results}).
%As our HWT dataset comes from six different domains, we analyze the results for polished texts in each of them. We observe that some domains get misclassified by the detectors than others. For extreme-minor polishing, `speech' domain has the highest misclassification rate with $36\% \sim 56\%$, whereas the `paper\_abstract' domain has the lowest ($17\% \sim 31\%$). This trend is demonstrated in figure \ref{fig:domain_ext_minor_gpt} for GPT-4o polished texts. More detailed results are shown in figure \ref{fig:domain_all_results} of Appendix \ref{app:domain_results}.


Interestingly, classification rates do not always correlate with polishing levels. As shown in figure \ref{fig:domain_change_plot}, for larger models like GPT-4o and Llama3.1-70B, the AI-detection rate for `paper\_abstract' decreases as polishing increases -- likely because with more freedom in polishing, larger models tend to generate more-human-like texts. 

%Another interesting finding is -- domain-based misclassification rate does not always co-relate with the polishing level. For example, we observed that -- for larger models like GPT-4o and Llama3.1-70B, the misclassification rate for the `paper\_abstract' domain drops, if we increase the level of polishing. The probable reason can be -- with more freedom in polishing, larger models tend to generate more-human-like texts. 

\begin{figure}
    \centering
    \includegraphics[width=0.85\linewidth]{images/domain_plots/extreme_minor_domain_accuracy_gpt.pdf}
    \caption{Average misclassification rate for all domains in extreme-minor polishing by GPT-4o}
    \label{fig:domain_ext_minor_gpt}
\end{figure}

\iffalse
\subsection{Commercial Detectors are no better in the case of AI-polished texts.}
\smk{Need to plot other polisher lines in one plot.}
\smk{Write after running GPTZero.}
\fi
