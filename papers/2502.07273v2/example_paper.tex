%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{enumitem}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.

%added
\usepackage[backref=page]{hyperref}
%\usepackage[capitalize,nameinlink]{cleveref}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
\usepackage{subcaption}
\usepackage{url}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
% \usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
% Customise clever references
\crefname{section}{Sec.}{Sections}
\crefname{appendix}{App.}{Appendices}
\crefname{algorithm}{Alg.}{Algorithms}
\crefname{equation}{Eq.}{Eqs.}
\crefname{figure}{Fig.}{Figures}
\creflabelformat{equation}{#2\textup{#1}#3} % Remove the brackets around Equation numbers

% for IVON psuedo code
% save the meaning of \AND and undefine it to keep algorithmic happy
\let\classAND\AND
\let\AND\relax
% load algorithmic
\usepackage{algorithmic}
\usepackage{setspace}
% save the new meaning of \AND and restore the one of the class
\let\algoAND\AND
\let\AND\classAND
% but when we start \begin{algorithmic} we want its own \AND
%\AtBeginEnvironment{algorithmic}{\let\AND\algoAND}
%\definecolor{crimson}{HTML}{FF0000}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \theoremstyle{plain}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
%\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Variational Learning Induces Adaptive Label Smoothing}

\begin{document}

\twocolumn[
\icmltitle{Variational Learning Induces Adaptive Label Smoothing}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Sin-Han Yang}{yyy}
\icmlauthor{Zhedong Liu}{yyy}
\icmlauthor{Gian Maria Marconi}{yyy,wov}
%\icmlauthor{}{sch}
\icmlauthor{Mohammad Emtiyaz Khan}{yyy}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{RIKEN Center for Advanced Intelligence Project, Tokyo, Japan}
\icmlaffiliation{wov}{Woven by Toyota}

\icmlcorrespondingauthor{Sin-Han Yang}{sin-han.yang@riken.jp}
\icmlcorrespondingauthor{Mohammad Emtiyaz Khan}{emtiyaz.khan@riken.jp}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
    We show that variational learning naturally induces an adaptive label smoothing where label noise is specialized for each example. Such label-smoothing is useful to handle examples with labeling errors and distribution shifts, but designing a good adaptivity strategy is not always easy. We propose to skip this step and simply use the natural adaptivity induced during the optimization of a variational objective. We show empirical results where a variational
    algorithm called IVON outperforms traditional label smoothing and yields adaptivity strategies similar to those of an existing approach.~By connecting Bayesian methods to label smoothing, our work provides a new way to handle overconfident predictions.
 \end{abstract}
 
 \section{Introduction}
 
 Adaptive strategies to Label Smoothing (LS) \citep{Szegedy_rethinking} aim to adapt the label noise according to the type of data example. Such adaptation can be more effective in practice than its traditional counterpart where the label noise is the same for all examples. Adaptation is useful to handle examples that may have labeling errors, distribution shift, or calibration issues. For such cases, the effectiveness of adaptation has been extensively
 studied, for example, see \citet{ghoshal2021learning,lee2022adaptive} for 
 generalization improvements, \citet{zhang2021delving,ko2023gift} for mislabelled examples, \citet{park2023acls} for miscalibration, and \citet{xu2024adaptive} for out-of-distribution detection. Adaptivity is useful for label smoothing to handle all such cases.

 
One major problem with adaptive label smoothing is that it is not easy to design a good adaptivity strategy.
%and existing works rely on ad-hoc and heuristic strategies.
For example, a simple approach is to adapt the label noise by using model's predictions but there are many ways to do this, for examples, \citet{park2023acls} set the noise based on the logits, 
 \citet{zhang2021delving,ko2023gift} use the predictive probabilities (obtained with softmax), while \citet{lee2022adaptive} use their entropy.
All of these are reasonable ideas but the choice of a good strategy for a given problem is not always straightforward. A strategy that reduces miscalibration may not be most effective for handling outliers or mislabeling. Focusing on one issue at a time has given rise to a lot of ad-hoc and heuristic strategies, and, despite their usefulness, designing an adaptive strategy for a task in hand remains tricky.
%An alternative to these approaches is to use the Bayesian posterior over the labels, for example, \citet{li2020regularization} inject the noise using the posterior to flip the decisions, while \citet{ghoshal2021learning} motivate an adaptive approach using a PAC-Bayes bound. There also exist work on adaptivity for specific applications, for instance, using specific image sizes
% \citep{krothapalli2020adaptive} or using calibration \citep{park2023acls}.
%Despite the usefulness of these works, there is little consensus on the best way to introduce adaptivity.
Our goal here is to simplify the process by presenting and analyzing algorithms that naturally induce adaptivity. 
 
\begin{figure}[!t]
	\centering
      \includegraphics[width=\linewidth]{figures/fig1a.pdf}
   \caption{Given a regular $6$ digit (top) and an atypical one (bottom), Label Smoothing (LS) assigns the same label noise to both (gray bars) while variational learning assigns higher noise to the atypical example (red bars). Adaptivity naturally arises due to the posterior.}% (b) We plot label noise assigned by IVON and LS. Examples are ordered according to IVON's noise, and highest and lowest noise examples for 0 and 6 classes are visualize. We see that high noise is assigned to atypical examples while low noise is assigned to regular ones.}
   \label{fig:illustration}
\end{figure}

We show that variational learning naturally induces an adaptive label smoothing. The smoothing arises due to the use of the expectation of the loss in the variational objective, taken with respect to the posterior distribution. The expectation gives rise to a label noise (among other types of noises) which is customized for each example through its features.
 Our key contribution is to derive the exact form of the label noise (\cref{eq:labelnoiseGD}) for many problems and study their behavior.
 We show extensive empirical results analyzing the label noise induced by Improved Variational Online Newton (IVON) \citep{IVON}. We show the following: 
 % and Sharpness-Aware Minimization (SAM) \citep{SAM_org} which also has a variational interpretation \citep{thomassampaper}
 \begin{enumerate}[itemsep=-0.4pt]
    \item Variational learning assigns higher noise to atypical or ambiguous examples (\cref{fig:illustration} and \cref{fig: mnist_noise_distribution}).
    \item IVON's adaptive label noise behaves similarly to the proposal of \citet{zhang2021delving}.
    \item IVON consistently outperforms Label Smoothing in presence of labeling errors,  giving up to 9\% accuracy boost for pair-flip noise (\cref{fig:cifar100_all}) and sometimes even around 50\% for data-dependent noise (\cref{fig:cifar10_inc_acc}). 
 \end{enumerate}
Our work connects label smoothing literature to Bayesian methods, thereby providing a new way to handle overconfident predictions in deep learning.
 %We argue that the noise introduced by variational learning is more effective overall because it covers examples that might be missed by label noise.
 
\section{Label Smoothing and Adaptivity Strategies} \label{sec: label smoothing}
 
 Label Smoothing (LS) is a simple technique where the true label vector $\vy_i$ (length $K$) are replaced by a smoothed version. In its simplest form, a convex combination is used where the smoothed labels are defined as
 \begin{equation} \label{equ: label smoothing def}
   \vy_i'=(1-\alpha)\vy_i + \alpha \vu,
 \end{equation}
for some scalar $\alpha \in (0, 1)$ with $\vu$ as a vector of $1/K$ with $K$ being the number of classes. This simple technique is effective to penalize overconfident predictions because the noise $\alpha(\vu -\vy_i)$ reduces the importance of the label during training \citep{pereyra2017regularizing}. Multiple works have studied its effectiveness, for example, to improve calibration and representation \citep{muller2019does}, to favor flatter
 solutions \citep{damian2021label}, and improve robustness to mislabelled data \citep{lukasik2020does,liu2021understanding} due to its connections to loss correction \citep{patrini2017making}. Despite its simplicity, LS has clear practical advantages.
 
%  Define the loss function of $N$ datapoints as $\loss(\vparam) = \sum_{i=1}^N \loss_i{(\vf_i(\vparam),\vy_i)}$, where the network output $\vf_i(\vparam) \in \real^K$ is parameterized by weights $\vparam_t\in\real^P$ at the training step $t$. 
%  When the loss function is the cross entropy loss, the derivative of the loss is
%  \begin{equation*}
%      \grad \loss_i (\vf_i(\vparam),\vy_i))= \nabla \vf_i^\top(\vparam_t) \sqr{ \softmax(\vf_i(\vparam_t)) - \vy_i},
%  \end{equation*}
%  where $\softmax(\cdot)$ is the softmax link function. A gradient descent step with the smoothed label $\vy_i'$ can be written as follows
%  \begin{equation}
%     \vparam_{t+1} \leftarrow \vparam_t - \rho_t \sum_{i = 1}^N \nabla \vf_i^\top(\vparam_t) \sqr{ \softmax(\vf_i(\vparam_t)) - (\vy_i + \vepsilon_{i})},
%  \end{equation}
%  where the label noise $\vepsilon_{i}$ is
%  \begin{equation}
%      \vepsilon_{i} = \vy_i'-\vy_i=\alpha (\vu-\vy_i).
%  \end{equation}
%  The entries of $\vepsilon_i$ do not have any dependence on $t$ and remain constant throughout the learning process.
 
Adaptive label smoothing aims to inject noise according to the type of data example, for example, during learning, we may want to inject a noise to get the smoothed label
\begin{equation}
   \vy_{i|t} = \vy_i + \vepsilon_{i|t}.
\end{equation}
The noise $\vepsilon_{i|t}$ depend on the model parameter $\vparam_t$ at iteration $t$, and can be varied according the model's opinion regarding the relevance of the examples. Adaptive label smoothing uses additive noise to reweigh examples during training.
Many studies have shown the effectiveness of the adaptive noise, which ranges from improvements in generalization \citep{ghoshal2021learning,lee2022adaptive}, robustness to mislabeled data \citep{zhang2021delving,ko2023gift}, improving calibration \citep{park2023acls} and out-of-distribution (OOD) detection \citep{xu2024adaptive}. By adapting label noise, such methods aim to down-weight the problematic examples.

%Adaptive Label Smoothing aims to adapt the label noise according to the type of data examples. That is, we want to use  

While adaptivity is desirable, it also requires additional effort to design a good strategy to adapt. Each specific issues may require a different type of noise, for instance, what works to reduce miscalibration, may not be most effective for handling OOD detection or mislabling. Focusing on one issue or strategy at a time has given rise to a lot of ad-hoc and heuristic strategies, and, despite their usefulness, clarity of good ways to design adaptive strategy is lacking.

The simplest approach is to adapt by using the model predictions based on the logits $\vf_i(\vparam_t)$, but there are many ways to use them. \citet{zhang2021delving} use the following update for each example $i$ in the epoch $t$
\begin{equation}
   %\vu \leftarrow \vu + \softmax(f(\vx)),
    \vu = \sum_i \softmax\sqr{ \vf_i(\vparam_t)},
\end{equation}
 where $\softmax[\vf]$ vector (length $K$) with $j$'th entry defined as
 \begin{equation}
    \softmax_j \sqr{ \vf} = \frac{ e^{f_j}}{ \sum_{k=1}^K e^{f_k} }.
    \label{eq:softmax}
 \end{equation}
The noise injected by this method is
\begin{equation} \label{equ: ols noise}
   \vepsilon_{i|t} = \alpha (\bar{\vu}-y_i),
\end{equation}
where $\bar{\vu}$ is the normalized $\vu$. A similar rule is used by \citet{ko2023gift}. Instead of directly using the logits, \citet{lee2022adaptive} use them to adjust $\alpha$. They do so by using the entropy of the model-output distribution, assigning a smaller smoothing to high entropy samples and larger smoothing to low entropy samples. Another approach by \citet{park2023acls} decrease the label noise linearly as the logit $\vf_i(\vparam_t)$ increase.
There are multiple ways to use predictions but the choice of a good strategy for a given problem is not always straightforward.

Intuitively, using model's predictions makes sense because predictions can tell us about the relevance of examples. Regions where model is inaccurate may also contain examples that need special attention but also those that are impossible to predict. Some works have explored this from the Bayesian viewpoint, although only using the posterior over the labels. For example, \citet{li2020regularization} motivate adaptive smoothing using Bayes error rate, which
implies larger smoothing to example that lie near the decision boundary. Similarly, \citet{ghoshal2021learning} use a PAC-Bayes bound to motivate adaptivity. However, there are no approaches investigating the effectiveness of posterior over $\vparam$.

In this paper, we show that directly learning the posterior using a variational method natural yields an adaptive label noise. Adaptivity introduced in this fashion directly takes various causes of uncertainty, some of which are then handled through the label noise. The uncertainty in parameter have other desired effect that are often missed when only focusing on the label noise. In our context, this can simplify the design of adaptive label smoothing or may even allow us to
entirely skip the step. We will now discuss the adaptive label noise induced by variational learning.

\section{Variational Learning Induces Adaptive LS}

Variational learning aims to optimize for distribution over parameters $\vparam$ which is fundamentally different from traditional deep learning where we minimize empirical risk,
\begin{equation}
   \barloss(\vparam) = \sum_{i=1}^N \loss_i(\vparam) + \mathcal{R}_0(\vparam),
   \label{eq:dl}
\end{equation}
with loss $\loss_i(\vparam)$ for the $i$'th example in the training dataset.
The regularizer $\mathcal{R}_0(\param)$ is often implicitly defined through various training choices, such as, weight-decay, initialization, and architecture design. In contrast, variational learning aims to find a distribution $q(\vparam) \in\mathcal{Q}$ which minimizes
\begin{equation}
   \elbofinal(q) = \sum_{i=1}^N \myexpect_q \sqr{ \loss_i(\vparam)} + \dkls{}{q(\vparam)}{p(\vparam)}.
   \label{eq:vl}
\end{equation}

% \underset{q}{\text{min}} \sum^N_{i=1}\mathbb{E}_q \left[\ell_i(\boldsymbol{\theta}) \right] + \mathbb{D}_{\text{KL}}\left[q(\boldsymbol{\theta}) \parallel p(\boldsymbol{\theta})\right].

The second term is the Kullback-Leibler (KL) Divergence where the $p(\vparam) \propto \exp(-\mathcal{R}_0(\vparam))$ can be defined implicitly similarly to deep learning. Throughout, we will set $q(\vparam)$ to take Gaussian forms and show that, despite their differences, variational learning can be implicitly seen as minimizing a noisy version of \cref{eq:dl}. Existing works have studied the weight-noise \citep{zhang2018noisy,khan2018fastadam} but our goal here is to specifically
study its effect on label noise. 

\subsection{A Simple Example: Logistic Regression}
We start with logistic regression where we can write a closed-form expression for the adaptive label noise. The result extends to all loss functions using generalized linear model. We will consider all such extensions (including neural networks) afterwards. For now, we consider a loss function for binary labels $y_i \in \{0,1\}$ with model output $f_i(\vparam)$,
\begin{equation}
   \ell_i(\vparam) = -y_i f_i(\vparam) + \log \rnd{1+e^{f_i(\vparam)}}.
   \label{eq:bce}
\end{equation}
In logistic regression, we have $f_i(\vparam) = \vphi_i^\top\vparam$ where $\vphi_i \in\real^P$ is the feature vector. For simplicity, let us assume $\mathcal{R}_0(\vparam) = \half \|\vparam\|^2$ to be a quadratic regularizer. 
For such a model, we can solve \cref{eq:dl} with gradient descent (GD),
\begin{equation}
   \vparam_{t+1} = (1-\rho_t)\vparam_t - \rho_t \sum_{i=1}^N \vphi_i \sqr{ \sigmoid( f_i( \vparam_t) ) - y_i }   
   \label{eq:gd}
\end{equation}
The result is obtained by simply taking the derivative of \cref{eq:bce} which gives rise to $\sigmoid(f) = 1/(1+e^{-f})$, a binary version of the softmax function from \cref{eq:softmax}.
We will now show that, by choosing the family $\mathcal{Q}$ appropriately, variational learning can be seen as GD with label noise.

We choose the distribution $q_t(\vparam)$ at iteration $t$ to take a Gaussian form with mean $\vparam_t$ and covariance set to the identity,
\[
   q_t(\vparam) = \gauss(\vparam | \vparam_t, \vI),
\]
and perform GD to minimize the variational objective in \cref{eq:vl}, now denoted as $\elbofinal(\vparam_t)$, with respect to $\vparam_t$. 
%\[
%   \elbofinal(\vparam_t) = \sum_{i=1}^N \myexpect_{q_t} \sqr{ \loss_i(\vparam)} + \dkls{}{q_t(\vparam)}{p(\vparam)}.
%\]
Below is a formal statement of the result.
\begin{thm}
   A gradient update $\vparam_{t+t} = \vparam_t - \rho_t \nabla_{\vparam_t} \mathcal{L}(\vparam_t)$ is equivalent to the gradient update in \cref{eq:gd} where the label $y_i$ are replaced by $y_i +\epsilon_{i|t}$ with noise defined as 
   \begin{equation}
      \epsilon_{i|t} =  \sigmoid(f_i(\vparam_t)) - \myexpect_{q_t} [\sigmoid(f_i(\vparam))].
      \label{eq:labelnoiseGD}
   \end{equation}
\end{thm}

\begin{myproof}
The gradient of the expected loss in \cref{eq:vl} can be simplified to take a form very similar to the one in \cref{eq:gd},
\begin{equation}
   \begin{split}
      \nabla_{\vparam_t} \myexpect_{q_t} [ \loss_i(\vparam)] &= \nabla_{\vparam_t} \myexpect_{\text{\gauss}(\text{\ve}|0, \text{\vI})} [ \loss_i(\vparam_t + \ve)] \\
      &= \myexpect_{\text{\gauss}(\text{\ve}|0, \text{\vI})} \sqr{ \nabla_{\vparam_t} \loss_i(\vparam_t + \ve) } \\
      %&= \myexpect_{\text{\gauss}(\text{\ve}|0, \text{\vI})} \sqr{ \vphi_i \sqr{\sigmoid(f_i(\vparam_t+\ve)) - y_i} } \\
      &= \vphi_i  \sqr{ {\myexpect_{q_t}} [\sigmoid( f_i( \vparam) )] - y_i } 
   \end{split}
   \label{eq:expected_grad}
\end{equation}
The gradient of KL is also simplifies to
\[
   \dkls{}{q(\vparam)}{p(\vparam)} = \myexpect_q\sqr{ \log \frac{q(\vparam)}{p(\vparam)} } = \half \|\vparam\|^2 + \text{const.}
\]
%Therefore, gradient descent to minimize \cref{eq:vl} takes a very similar form to \cref{eq:gd},
   Using these, we can write the GD to minimize \cref{eq:vl} as
\[
   \vparam_{t+1} = (1-\rho_t)\vparam_t - \rho_t \sum_{i=1}^N \vphi_i \sqr{ {\color{red} \myexpect_{q_t}} [\sigmoid( f_i( \vparam) )] - y_i } ,
   %&= (1-\rho_t)\vparam_t - \rho_t \sum_{i=1}^N \vphi_i \sqr{ \sigmoid(f_i(\vparam_t)) - (y_i +\epsilon_{i|t})   }, \nonumber 
\]
   which has a similar form as \cref{eq:gd} but with one difference: $\sigmoid( f_i( \vparam) )$ are replaced by their expectation over $q$ (highlighted in red).
   By adding and subtracting $\sigmoid( f_i( \vparam_t) )$, we can rewrite the update as \cref{eq:gd} which has the label noise defined in \cref{eq:labelnoiseGD}. $\hfill\blacksquare$
\end{myproof}

\begin{figure}[!t]
	\centering
   \includegraphics[width=0.85\linewidth]{figures/toy/sigmoid.png}
   \caption{We plot label noise magnitude $\epsilon_{i|t}$ from \cref{eq:labelnoiseGD_sim} by varying the mean $f_{i|t}$ of $q_t(f_i)$ while fixing its variance to 1. The noise is large around 0 (but not at 0) with large peaks on both sides.}
   \label{fig: guassian after sigmoid}
\end{figure}

The result shows that the GD steps to optimize \cref{eq:vl} is equivalent to those to optimize \cref{eq:dl} but with a noisy label. The noise is adaptive and depends on where the Gaussian distribution is located. To show this, we derive the distribution over $f_i = \vphi_i^\top\vparam$, which takes a Gaussian form: 
\begin{equation}
   q_t(f_i) = \gauss(f_i|f_{i|t}, \vphi_i^\top\vphi_i),
   \label{eq:qf_logreg}
\end{equation}
where we denote $f_{i|t} = \vphi_i^\top\vparam_t$. The label noise then is simply the difference between the sigmoid $\sigmoid(f_{i|t})$ of the mean $f_{i|t}$ and mean of $\sigmoid(f_i)$ with respect to $q_t(f_i)$, that is
\begin{equation}\label{eq:labelnoiseGD_sim}
   \epsilon_{i|t} = \sigmoid(f_{i|t}) - \myexpect_{q_t}[\sigmoid(f_i)],
\end{equation}
where the form is similar to the noise of \citet{zhang2021delving} in \cref{equ: ols noise}. \cref{fig: guassian after sigmoid} plots the magnitude of this quantity as a function of the mean $f_{i|t}$ but fixing the variance $\vphi_i^\top\vphi_i = 1$. We see the noise to be large whenever $f_{i|t}$ around 0, with the maximum in areas slightly away from it. The $\sigmoid(f)$ is flat far away from 0 and uncertainty in $q_t$ is amplified around 0, which makes the difference large around 0 (but not at 0).

The other factor that affects the noise is the feature $\vphi_i$. Inputs with larger features induce larger variance. When the features are normalized, this is unlikely to have an effect, but this is important for the neural networks case where features
are learned. 

The two factors explain why we would expect high label noise for atypical or ambiguous examples. This is because the predictive distribution $q(f_{i|t})$ is close to 0 and may also have a higher variance. An alternate way to understand the impact of the two factors is to use a Taylor's approximation at a sample $e \sim \gauss(0,1)$,
\begin{equation}
   \epsilon_{i|t} \approx \sigmoid(f_{i|t}) - \sigmoid(f_{i|t} + \|\vphi_i\|_2 e)  \approx  \sigmoid'(f_{i|t}) (\vphi_i^\top \vphi_i)^{1/2} e .
   \label{eq:taylor_noise}
\end{equation}
We again see the two factors: one is $\sigmoid'(f)$ (which peaks around 0) and the other is the feature norm.~Note that this approximation does not get better for larger number of samples, but it roughly captures the behavior away from 0.

\subsection{Generalized Linear Model (GLM) with GD}

The result generalizes to any loss function derived using exponential-family distribution, for instance, the following generalization of \cref{eq:bce}
\begin{equation} \label{eq:glm_loss}
   \ell_i(\vparam) = -\vy_i^\top \vf_i(\vparam) + A(\vf_i(\vparam) ),
\end{equation}
where $A(\vf)$ is a convex function called the log-partition function.
The regularizer can also be a general convex function. For such models, we can derive the label noise following almost the same procedure as in the previous section. Due to its similarity, we omit the derivation and only give the final form of the noise,
\begin{equation}
   \vepsilon_{i|t} = A'(\vf_i(\vparam_t)) - \myexpect_{q_t} [A'(\vf_i(\vparam))].
   \label{eq:labelnoiseGLMGD}
\end{equation}
Essentially, we replace the $\sigmoid(f)$ by the derivative $A'(f)$. For logistic regression, $A(f) = \log (1+ e^f)$, derivative of which is $\sigmoid(f)$ and we recover the result in \cref{eq:labelnoiseGD}. We can extend this result to multiclass classification by considering $A(\vf) = \log \sum_{k=1}^K e^{f_k}$, derivative of which is the softmax function defined in \cref{eq:softmax}. Similarly to the binary case, we expect uncertainty in $q_t$ to be amplified near the
boundary. The label noise is therefore low for examples where softmax yields probabilities close to 0 or 1.

\subsection{Generalized Linear Model with Newton's Method} \label{sec: newton on GLM}

We now go beyond GD to Newton's method and show that a specific variational-learning algorithm can be seen as a noisy-label version of Newton's method. This is a useful step before we move to neural networks training. Here, we find that the form of the noise has exactly same form as \cref{eq:labelnoiseGLMGD} but the distribution $q_t$ has a flexible covariance which improves the adaptivity of the label noise. 

We consider the following Newton's update,
\begin{equation}
   \vparam_{t+1} = \vparam_t - \sqr{ \nabla^2 \barloss(\vparam_t) }^{-1} \nabla \barloss(\vparam_t)
   \label{eq:newton}
\end{equation}
which is commonly used for generalized linear models. As shown by \citet{khan2023bayesian}, the update can be seen as a special case of a Variational Online Newton (VON) algorithm \citep{khan2018fastadam} to learn a full Gaussian with covariance $\vSigma_t$,
\[
   q_t(\vparam) = \gauss(\vparam | \vparam_t, \vSigma_t) 
\]
The VON updates are given as follows,
\begin{equation}
   \begin{split}
      \vparam_{t+1} &= \vparam_t - \rho_t \vSigma_{t+1} \myexpect_{q_t} [ \nabla \barloss(\vparam)] \\
      \vSigma_{t+1}^{-1} &= (1-\rho_t) \vSigma_{t}^{-1} + \rho_t \myexpect_{q_t} [ \nabla^2 \barloss(\vparam)] .
   \end{split}
   \label{eq:von}
\end{equation}
Setting $\rho_t = 1$ yields a Newton-like update where gradients $\nabla\barloss$ and Hessian $\nabla^2\barloss$ are replaced by their terms where expectations are taken, namely, $\myexpect_{q_t}[\nabla\barloss]$ and $\myexpect_{q_t}[\nabla^2 \barloss]$. Similarly to the previous cases, the label noise in VON arises due to the expectation of the gradient, while expectation of the Hessian gives rise to other types of noise.

As shown in in \cref{app:glm_newton}, the VON updates in \cref{eq:von} are equivalent to Newton's update in \cref{eq:newton} where labels are replaced by the noisy ones with noise shown in \cref{eq:labelnoiseGLMGD}. The proof technique relies on comparing the form of the surrogates for the two algorithms. Even though the noise has the same form, there is an important difference here. Essentially, the Gaussian $q_t$ now is more flexible because its covariance $\vSigma_t$ is not fixed but learned using the Hessian. As a result the distribution over $f_i$ now has adaptive variances, 
\begin{equation}
   q_t(f_i) = \gauss(f_i|f_{i|t}, \vphi_i^\top\vSigma_t\vphi_i).
   \label{eq:qf_newton}
\end{equation}
Therefore, now both the location and spread of the Gaussians are changed for each example, and they both contribute to the adaptivity. The result shows that second-order methods yield more adaptive label noise than first order methods, and are expected to perform better in practice. We will later present experiments that support this finding. 

\subsection{Neural Network training with IVON} \label{sec: IVON on NN}

\begin{figure*}[h!]
	\centering
	\begin{subfigure}{0.45\linewidth}
		\centering
		\includegraphics[width=\linewidth]{figures/toy/mnist_noise_distribution.pdf}
	\end{subfigure} 
	\begin{subfigure}{0.44\linewidth}
		\centering
		\includegraphics[width=\linewidth]{figures/toy/mnist_visual.pdf}
	\end{subfigure}
	\caption{Label noise assigned by IVON and LS in MNIST dataset. Examples are ordered according to IVON's noise, and highest and lowest noise examples are visualized. We see that high noise is assigned to atypical examples while low noise is assigned to regular ones.}
	\label{fig: mnist_noise_distribution}
\end{figure*}

We will now show that the label noise expression have similar form for the neural network case, but to derive them we need to use Taylor's approximation. Essentially, the form of the expression then is similar to \cref{eq:taylor_noise} there the adaptive nature should roughly stay the same. We validate these findings later through numerical experiments.

We will illustrate the derivation for the binary case which can then be extended to other case as we did in previous section. Taylor's approximations is required because the gradient of $\loss_i$, shown below,
\[
   \nabla \loss_i(\vparam) = \nabla f_i(\vparam_t) \sqr{ \sigmoid( f_i( \vparam_t) ) - y_i },
\]
replaces the $\vphi_i$ term in \cref{eq:gd} by $\nabla f_i(\vparam_t)$. As a result, we cannot simply move the expectation over $q_t$ to derive the label noise as we did in \cref{eq:expected_grad}. However, we can simplify these by using Taylor's approximation.

We show this by using a single-sample $\vparam_t^{(1)} \sim q_t$ Monte-Carlo approximation (multiple samples can also be used),
\[
   \myexpect_{q_t} \sqr{ \nabla \loss_i(\vparam)} 
   \approx \nabla f_i(\vparam_t^{(1)}) \sqr{ \sigmoid( f_i( \vparam_t^{(1)}) ) - y_i } .
\]
Then, we do the following two approximations where we use Taylor's expansion but ignore the second-order terms, 
\begin{align*}
   \sigmoid(f_i(\vparam_t^{(1)})) &\approx \sigmoid(f_i(\vparam_t)) + \sigmoid'(f_i(\vparam_t)) \nabla f_i(\vparam_t) (\vparam_t^{(1)} - \vparam_t) \\
   \nabla f_i(\vparam_t^{(1)}) &\approx \nabla f_i(\vparam_t) 
\end{align*}
With these approximations, we can write,
\[
   \myexpect_{q_t} \sqr{ \nabla \loss_i(\vparam)} \approx \nabla f_i(\vparam_t) \sqr{ \sigmoid( f_i( \vparam_t) ) - (y_i + \epsilon_{i|t})},
\]
where the noise takes a very similar form to \cref{eq:taylor_noise},
\begin{equation}
   \epsilon_{i|t} \approx \sigmoid'(f_i(\vparam_t)) \nabla f_i(\vparam_t) \vSigma_t^{1/2} \ve
   \label{eq:taylor_noise_nn}
\end{equation}
where $\ve$ is a sample from a standard normal distribution. The derivation generalizes to all GLM losses by replacing $\sigmoid(\cdot)$ by $A'(\cdot)$. It also extends to variational GD and VON.

In practice, neural networks are trained with Adam-style algorithm. In our experiments, we will use an Adam-like version of VON, called IVON, which is recently proposed by \citet{IVON}. The key different to VON is that it estimates a diagonal covariance by using an Adam-like preconditioning update; a pseudo-code is added in \cref{alg:ivon}. The diagonal covariance is estimated through the scale vector. We will use the label noise expression given in \cref{eq:taylor_noise_nn} where $\vSigma_t$ is replaced by the
diagonal covariance estimated by IVON. Note that variational learning for neural neworks with IVON introduces many other noise other than label noise, for instance, the noise is introduced in the features $\nabla f(\vparam)$, as shown above. We will analyze only the label noise but the performance is affected by other noises too.

In our experiments, we also compare to Sharpness-Aware Minimization (SAM) \citep{SAM_org} which has a variational interpretation \citep{thomassampaper} and has been shown to perform well with mislabelled data. Using our techniques, it is possible to derive the label noise of SAM but the expression would be similar to the one derived here.
The difficulty with SAM is that we need to tune the `size' of adversarial perturbation, often denoted by a scalar $\rho$, while IVON can automatically estimate it using the posterior variance. In our experiments, we show that IVON performs comparably to SAM with a highly tuned $\rho$, and it does not need to set any such hyperparameters.


%To do so, we will express the gradient updates as surrogate-minimization. Then, the variational version of the algorithm can be seen as simply adding noise to different part of the surrogate. We can then read-out the noise in the labels and compare them to those of the existing proposals.
% 
% We start with the well-known interpretation of SGD as a minimization of a linearized loss function. Essentially, we use a first-order Taylor's approximation $\loss_i(\vparam) \approx \loss_i(\vparam_t) + (\vparam - \vparam_t)^\top \nabla \loss_i(\vparam_t)$. Then, by using this linearized loss (and ignoring the constants) in a proximal update, we can show that the update in the SGD step shown in \cref{eq:sgd} is equivalent to the following:
% \begin{equation}
%    \vparam_{t+1} = \,\, \arg\min_{\vparam} \,\, \vparam^\top \nabla \loss_i(\vparam_t) + \frac{1}{2\rho_t} \|\vparam - \vparam_t\|^2  
%    \label{eq:sgd_surrogate}
% \end{equation}
% The advantage of this new expression is that it can be directly compared to variational algorithms which \emph{implicitly} linearize loss. We can then show that each step of the variational learning is equivalent to SGD but with an additional noise.  
% 
% Specifically, we will use the Bayesian learning rule of \citet{khan2023bayesian} to update exponential-family approximations. We start with the simplest version of it where a variational Bayesian objective is optimized to obtain the mean $\vparam_t$ of a Gaussian approximation $q_t(\vparam) = \gauss(\vparam|\vparam_t, \vI)$. The update can be written as,
% \begin{equation}
%    q_{t+1}(\vparam) \propto q_t(\vparam) e^{ \rho_t \vparam^\top \tvlambda_{i|t}}
%    \label{eq:blr_sgd}
% \end{equation}
% where $\tvlambda_{i|t} = \myexpect_{q_t}[-\nabla \loss_i(\vparam)]$.
% We can then generalize the result derived earlier to a generic loss derived from exponential-family.
% \begin{thm}
%    Consider the following loss function derived from exponential-family distribution,
%    \begin{equation}
%       \ell(y_i, \vparam) = - y_i f_i(\vparam) + A(f_i(\vparam)).
%       \label{eq:glm_loss}
%    \end{equation}
%    with $f_i(\vparam) = \text{\vphi}_i^\top\vparam$ is the linear predictor and $A(f_i)$ is the log-partition function. Then, the Bayesian learning rule shown in \cref{eq:blr_sgd} is equivalent to SGD update in \cref{eq:sgd_surrogate} on the same loss but with a noisy label, that is, $\ell(y_i + \epsilon_{i|t}, \vparam)$ where the noise is 
%    \begin{equation}
%       \epsilon_{i|t} = \myexpect_{\text{\gauss}(e|0,\, \text{\vphi}_i^\top\text{\vphi}_i) } \sqr{A'(f_{i|t} + e)} - A'(f_{i|t}).
%       \label{eq:sgd_noise}
%    \end{equation}
%    where $f_{i|t} = \vphi_i^\top\vparam_t$ and $A'(f) = \partial A(f)/\partial f$ is the expectation parameter of the exponential family. The magnitude of the noise directly depends on the magnitude of the variance $\vphi_i^\top\vphi_i$.
% \end{thm}
% For the logistic loss, $A(f) = \log (1+e^f)$ and we get the sigmoid function $A'(f) = \sigmoid(f)$ as the expectation parameter. We can understand the magnitude of the noise $\epsilon_{i|t}$ by linearizing the sigmoid at a Monte Carlo sample of $v\sim\gauss(0, 1)$,
% \begin{equation}
%   \resizebox{\linewidth}{!}{$
%   \epsilon_{i|t} \approx A'(f_{i|t}+ v\|\vphi_i\|_2 ) - A'(f_{i|t}) \,\, \approx\,\, \|\vphi_i\|_2 \cdot A''(f_{i|t}) v .
%   $}
%   \end{equation}
% where $\|\vphi_i\|$ is the $L_2$ norm of $\phi_i$ and $A''(f)$ is the second derivative. The adaptivity in this case depends on the feature magnitude: larger magnitude features induce larger noise.
% 

 %\textbf{Previous write up}
% 
% \section{Implicit Label-Smoothing by Variational Learning -- Another View}
% 
% In this section, we show that variational learning methods implicitly induce an adaptive label-smoothing from another perspective. Variational learning optimizes the evidence lower bound:
% \begin{equation}
%     \elbo(q) = \sum_{i=1}^N \myexpect_{q(\vparam)}[\loss_i{(\vf_i(\vparam),\boldsymbol{y}_i)}] + \dkls{}{q(\vparam)}{p(\vparam)},
%     \label{eq:elbo}
% \end{equation}
% where $q(\vparam)$ is the posterior, $p(\vparam)$ is the prior distribution and $\dkls{}{\cdot}{\cdot}$ is the Kullback-Leibler divergence (KLD). For an Gaussian posterior $q(\vparam) = \gauss(\vm,\vI_p)$ and prior $p(\vparam) = \gauss(\vzero,\vI_P/\delta)$, we can rewrite the objective in \cref{eq:elbo} as
% \begin{equation}
%     \elbo(\vm) = \sum_{i=1}^N \myexpect_{\vepsilon \sim \mathcal{N}(\bm{0}, \bm{I}_p)}[\loss_i{(\vf_i(\vm+\vepsilon),\boldsymbol{y}_i)}] +\frac{\delta}{2}\|\vm\|^2,
% \end{equation}
% where we write $\vparam=\vm+\vepsilon$. Variational Learning perturbs the weights, while the existing label smoothing works perturb the labels. In the following section, we push the weight perturbation $\vepsilon$ to the output space, and derive the corresponding induced label-smoothing.
% 
% \subsection{Induced Label-Smoothing from Taylor Expansion}
% To optimize \cref{eq:elbo}, we can use a variational gradient descent algorithm through Equation (7) in \citet{khan2023bayesian} with one MC sample to approximate the expectation.  We denote the Gaussian approximation of the $t$-th iteration of VGD by $q_t(\vparam) := \mathcal{N}(\vparam|\vparam_t,\boldsymbol{I}_p)$. The update is as follows:
% \begin{equation}
%     \vparam_{t+1} \leftarrow \vparam_t - \rho_t \sum_{i = 1}^N \sqr{\nabla \vf_i^\top(\vparam_t')(\softmax(\vf_i(\vparam_t' )) - \vy_i) + \delta \vparam_t},
%     \label{eq:vgd_update}
% \end{equation}
% where $\vparam_t' \sim \mathcal{N}(\vparam_t, \vI_{P})$ is a sample from the previous approximated posterior. 
% 
%
% We could derive the induced label noise  $\vepsilon_{i,t}$ by using the first order Taylor expansion of $\softmax(\vf_i(\vparam_t' ))$ at the mean $\vparam_t$: 
% \begin{equation*}
%   \begin{split}
%      \softmax(\vf_i(\vparam_t' )) & = \softmax(\vf_i(\vparam_t + \vepsilon_t )) \\
%      & \approx \softmax(\vf_i(\vparam_t)) + \softmax'(\vf_i(\vparam_t)) \nabla \vf_i(\vparam_t) \vepsilon_t, \\
%      & \vepsilon_t \sim \mathcal{N}(\boldsymbol{0},\vI_{P}),
%   \end{split}
% \end{equation*}
% and approximate the Jacobian using the zeroth order Taylor expansion: $\nabla \vf_i(\vparam_t') \approx \nabla \vf_i(\vparam_t)$. The updates becomes:
% \begin{equation}
%      \resizebox{\linewidth}{!}{$
%     \vparam_{t+1} \leftarrow \vparam_t - \rho_t \sum_{i = 1}^N \sqr{\nabla \vf_i^\top(\vparam_t)\softmax(\vf_i(\vparam_t)) - (\vy_i + \vepsilon_{i,t}) + \delta \vparam_t},
%     $}
%     \label{eq:vgd_update_approx}
% \end{equation}
% where the induced label noise $\vepsilon_{i,t} = -\softmax'(\vf_i(\vparam_t)) \nabla \vf_i(\vparam_t) \vepsilon_t$, and the distribution is
% \begin{equation} \label{equ: VL GD noise}
%     \vepsilon_{i,t} \sim \mathcal{N}\Big(0,\softmax'(\vf_i(\vparam_t)) \nabla \vf_i(\vparam_t) \nabla \vf_i^\top(\vparam_t)\softmax'(\vf_i(\vparam_t))\Big).
% \end{equation}
%
% Similar technique can be applied to the update with preconditioner, such as IVON \citep{IVON} and VOGGN \citep{khan2019approximate}. The posterior distribution is $q_t(\vparam) := \mathcal{N}(\vparam|\vparam_t,\vSigma_t)$. Using the same technique above, we can rewrite the mean update as:
%\begin{equation}
%   \begin{split}
%       \vparam_{t+1} \leftarrow & \vparam_t - \rho_t \vSigma_{t+1} \sum_{i=1}^N \bigg[ \nabla \vf_i^\top(\vparam_t) \Big( \softmax(\vf_i(\vparam_t)) \\
%       & \quad - (\vy_i + \vepsilon_{i,t}) \Big) + \delta \vparam_t \bigg]
%   \end{split}
%   \label{eq:vgd_update_approx_preconditioner}
%   \end{equation}
%   
%% where the induced label noise $\vepsilon_{i,t}$ is:
% \begin{equation} \label{equ: VL newton noise}
% \vepsilon_{i,t} \sim \mathcal{N}\Big(0,\softmax'(\vf_i(\vparam_t)) \underbrace{\grad\vf_i(\vparam_t) \vSigma_t \grad\vf_i^\top(\vparam_t)}_{v_{i,t}}\softmax'(\vf_i(\vparam_t))\Big).
% \end{equation}
% 
% The induced label-smoothing for gradient descent \cref{equ: VL GD noise} and seconder order optimizer \cref{equ: VL newton noise} are both adaptive to each data example, specifically the Jacobian and predictions.
% Note that $v_{i,t}$ is the prediction variance of data point $i$ at step $t$, which is a component of the influence function:
% \begin{equation}
%     f_i(\vparam_t^{\backslash i})-f_i(\vparam_t) \approx \underbrace{\grad\vf_i(\vparam_t) \vSigma_t \grad\vf_i^\top(\vparam_t)}_{v_{i,t}}[\softmax(f_i(\vparam_t))-y_i],
% \end{equation}
% as shown in the previous work \citep{nickl2024memory}. This correlation implies that variational learning tends to induce stronger label-smoothing on more influential datapoints, which makes it more robust to noisy labels. This observation is aligned with the previous work \citep{li2020regularization}.
% 
%
 \input{experiment}
 
 \section{Conclusion}
 In this paper, we show that variational learning induces an adaptive label smoothing similar to an existing adaptive approach \citep{zhang2021delving} but does not require any additional effort to design. We derive the exact form for simple models and extend them to neural networks. We empirically confirm the effectiveness of noise, showing that the IVON method consistently performs better than LS, and comparably to SAM, without requiring hyperparameters to achieve desired smoothing. Our work suggests that Bayesian frameworks are naturally suitable for label noise. Specifically, we believe that variational learning algorithms, such as IVON, provide a flexible framework to further add noise to handle both the abnormalities and typicalities in the data.

\clearpage


\section*{Impact Statement}
This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here. 

\section*{Acknowledgements}
Mohammad Emtiyaz Khan was supported by the Bayes duality project, JST CREST Grant Number JPMJCR2112. Some of the experiments were carried out using the TSUBAME4.0 supercomputer at Institute of Science Tokyo.

We also would like to thank our former post-doc Lu Xu who started this project and contributed heavily to it. For reasons beyond our control, Lu was unable to join the author list but this work would not have been possible without her work. We also would like to thank Thomas Möllenhoff (RIKEN) for his help in deriving some of the results.

\section*{Author Contributions Statement}
Author list: Sin-Han Yang (SHY), Zhedong Liu (ZL), Gian Maria Marconi (GMM) and Mohammad Emtiyaz Khan (MEK).

MEK proposed the label-noise idea which was developed by Lu Xu and GMM who also performed the first set of experiments to validate the initial hypothesis.  Subsequently, ZL extended these experiments to the Clothing 1M settings.  Building up on all these experiments, SHY did most of the experiments involving IVON which are currently in the final version of the paper. MEK wrote the theory in Sec 3 with help from SHY. Both SHY and MEK contributed to the final writing with feedback from ZL and GMM.


\bibliography{reference}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\input{appendix}


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
