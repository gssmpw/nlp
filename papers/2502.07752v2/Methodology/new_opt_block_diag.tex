\subsection{\gls{alicec}: Generalization to Adam with eigenspace rotation}
\label{subsec: alicec}
\label{subsubsec: alice-c optimizer}
All structures considered above are simple and do not strictly generalize Adam's purely diagonal structure. In this and the following sections, we consider two structures that strictly generalize Adam, normalization, and whitening. Here, we first consider a block diagonal matrix with a shared eigen-space. 

Precisely, we propose the following structure that generalizes Adam\footnote{In \cref{subapp: solution to general block diagonal}, we propose an even more general block diagonal structure.}:
\begin{align}
    \family = \{\diagb(\mM_1, \ldots, \mM_n); \mM_i =\mUf\mD_i\mUf^T\}
    \label{eq: alicec structure}
\end{align} 
where $\mUf$ defines a shared \textbf{full-rank} eigen-space, and $\mD_i$ is a positive eigenvalue matrix. Adam is a special case by constraining $\mUf=\mI$. Additionally, the structures in \cref{subsec: sve} are also special cases. Whitening is obtained by a shared $\mD$ (i.e.~$\mD_i=\mD$); and normalization is by $\mUf=\mI$, $\mD_i=s_i\mI$. 
However, this structure does not directly lead to an analytic solution for \cref{eq: UFE equation}. 
Instead, we propose to approximate the solution by solving 1-iteration alternating optimization: 

\begin{theorem}[1-iteration refinement]
    For the structure in \cref{eq: alicec structure}, we consider the following 1-iteration alternating optimization of objective (\ref{eq: UFE equation}): (i) constrain $\mD_i=\mD$ to be equal, and solve $\mUf^* = \arg \min_{\mUf,\mD} \Fnorm{\diagb(\mUf\mD_1\mUf^T, \ldots, \mUf\mD_n \mUf^T) -\bm{F}} $; (ii) fix the $\mUf^*$ and find $\{\mD_i^*\} = \arg \min_{\{\mD_i\}} \Fnorm{\diagb(\mUf^*\mD_1{\mUf^*}^T, \ldots, \mUf^*\mD_n {\mUf^*}^T) -\bm{F}}$. Then, (i) and (ii) admits the following analytic solution:
    \begin{equation}
        \mUf^* = \eig(\E[\mG\mG^T]).
    \end{equation}
    where $\eig$ is the eigenvalue decomposition; and: 
    \begin{equation}
        \tilde{\mD^*} = \diagm(\E[({\mUf^*}^T\mG)\elesquare])
    \end{equation}
    where $\tilde{\mD}^* = \diagb(\mD_1^*,\ldots,\mD_n^*)$. 
    \label{thm: alicec 1 step refinement}
\end{theorem}
Based on this result, we can derive the corresponding square-root \gls{ngd} with given $\mU$ (refer to \cref{subapp: update of generlized adam}):
\begin{equation}
    \devect(\Ft^{-\frac{1}{2}}\vecg) = \mUf\frac{\mUf^T\mG}{\sqrt{\E[(\mUf^T\mG)\elesquare]}}.
    \label{eq: alicec update}
\end{equation}
This can be viewed as applying Adam's update on a space ``rotated" by eigen-matrix $\mUf$.
Consequently, we propose an optimizer, called \gls{alicec}, with the following update procedures:
\begin{align}
    &\vm_{t} = \beta_1\vm_{t-1}+(1-\beta_1)\mG_t\;\;\; (\text{first moment})\nonumber\\
    &\mQ_{t} = \beta_3\mQ_{t-1}+(1-\beta_3)\mG_t\mG_t^T\;\;\;(\text{\gls{ema} for }\E[\mG_t\mG_t^T])\nonumber\\
    & \mU_{f,t} = \eig(\mQ_{t})\nonumber\\
    & \vv_t = \beta_2\vv_{t-1}+(1-\beta_2)(\mU_{f,t}^T\mG_t)\elesquare\;\;\;(\text{second moment})\nonumber\\
    &\Delta_t = \mU_{f,t}\frac{\mU_{f,t}^T\vm_{t}}{\sqrt{\vv_t}}
\label{eq: practical alicec equations}    
\end{align}
\Cref{alg: alicec optimizer} in \cref{subapp: AdaDiag} summarizes the practical procedure. 
In fact, the above procedures closely relates to two related works: AdaDiag and one-sided SOAP \citep{anonymous2024improving, vyas2024soap}, which are heuristic memory-efficient variants of the full algorithms (i.e.~AdaDiag++ and SOAP). Before we discuss their connections, next we first show that the SOAP optimizer can also be reformulated as FIM approximation under a specific structural assumption.


\subsection{SOAP: Combination of Kronecker product with block diagonal structure}
\label{subsec: new opt combination}
All previous structures, apart from the one behind Shampoo, are under the class of block diagonal structures. However, such block-diagonal structure does not takes into account the off-diagonal part of \gls{fim}. Structure under Kronecker product, like the one behind Shampoo, can go beyond this. Therefore, we can consider combining the structure of \gls{alicec} with Shampoo, to obtain a more general structural assumption. We show this exactly recovers SOAP \citep{vyas2024soap}.

Specifically, we consider the following structural assumption: 
\begin{equation}
    \family = \{(\mU_R\otimes \mU_L)\tilde{\mD}(\mU_R\otimes \mU_L)^T\}
    \label{eq: SOAP structure}
\end{equation}
where $\mU_R\in\Rnn$, $\mU_L\in\Rmm$ are orthonormal matrix, and $\tilde{\mD}\in\mathbb{R}^{mn\times mn}$ is a diagonal matrix with positive values. We can easily show that structure behind \gls{alicec} is a special case by constraining $\mU_R=\mI_n$; and Shampoo is also a special case by constraining $\tilde{\mD}$ to be decomposed by Kronecker product (refer to \cref{subapp: connections between structural assumptions}). 

Similar to \gls{alicec}, it is hard to directly minimizing \cref{eq: UFE equation} with this assumption. We can approximate the solution by a similar 1-iteration alternating optimization procedure as \gls{alicec}. 

\begin{theorem}[SOAP as 1-iteration alternating optimization of \Cref{eq: UFE equation}]
    Assuming the above structural assumptions.
    Consider the following 1-iteration aternating optimization of \Cref{eq: UFE equation}: (i) assuming $\tilde{\mD}$ can be decomposed as Kronecker product of two diagonal matrix, then solve for $\mU_R^*$, $\mU_L^* = \arg \min_{\mU_R, \mU_L, \tilde{\mD}} \Fnorm{(\mU_R\otimes \mU_L)\tilde{\mD}(\mU_R\otimes \mU_L)^T -\bm{F}} $; (ii) fix $\mU_R^*$, $\mU_L^*$, solve for $\tilde{\mD}^* = \arg \min_{\tilde{\mD}} \Fnorm{(\mU_R^*\otimes \mU_L^*)\tilde{\mD}(\mU_R^*\otimes \mU_L^*)^T -\bm{F}}$ without Kronecker product assumption of $\tilde{\mD}$. Then,
    (i) admits analytic solution when minimizing the upper bound of \cref{eq: UFE equation} (i.e.~\cref{eq: shampoo upper bound}):
    \begin{align*}
        \mU_R^* = \eig(\E[\mG^T\mG]),\;\;\; \mU_L^* = \eig(\E[\mG\mG^T]).
    \end{align*} Step (2) admits an analytic solution for \cref{eq: UFE equation}:
    \begin{align*}
        \tilde{\mD^*} = \diagm(\E[({\mU_L^*}^T\mG{\mU_R}^*)\elesquare])
    \end{align*}. 
    \label{thm: optimal asham}
\end{theorem}
The proof is a straightforward combination of 
\cref{thm: optimal shampoo} and \cref{thm: alicec 1 step refinement}, and can be found in \cref{subapp: proof asham}. One can show that the corresponding square-root \gls{ngd} update associated with the above result exactly recovers the update rules in SOAP optimizer (refer to \cref{subapp: update formula for SOAP} for details). 



\paragraph{Connections to \gls{alicec}} Compared to \gls{alicec}, SOAP follows a more general structural assumption. However, from the FIM approximation perspective, SOAP does not exactly solve the 1-iteration alternating optimization problem. Instead, when solving for $\mU_R^*, \mU_L^* = \arg \min_{\mU_R, \mU_L, \tilde{\mD}} \Fnorm{(\mU_R\otimes \mU_L)\tilde{\mD}(\mU_R\otimes \mU_L)^T -\bm{F}}$, SOAP minimizes the upper bound instead. On the contrary, \gls{alicec} exactly solves the 1-iteration refinement problem. In addition, the structures behind \gls{alicec} and SOAP are different, and \gls{alicec} should not be viewed as a simple variant of SOAP. 



% Despite the structural generality of \gls{alicec}, it only focuses on the block diagonals of \gls{fim}. To go beyond this, one can combine the structure of \gls{alicec} with Shampoo's Kronecker product to obtain a structure that generalizes all the others in this paper. Interestingly, this turns out to be SOAP/AdaDiag++. Refer to \cref{subsec: new opt combination}. 



% \subsection{\gls{alicec} and SOAP: Two generalizations of Adam}
% \label{subsec: alicec}
% \label{subsubsec: alice-c optimizer}
% All structures considered above are simple and do not strictly generalize Adam's purely diagonal structure. In this section we consider two structures that strictly generalize Adam, normalization, and whitening: a block diagonal matrix with a shared eigen-space; and a combination of a block-diagonal matrix and Kronecker product.

% First, consider a block-diagonal structure that generalizes Adam\footnote{In \cref{subapp: solution to general block diagonal}, we propose an even more general block diagonal structure.}:
% \begin{align}
%     \family = \{\diagb(\mM_1, \ldots, \mM_n); \mM_i =\mUf\mD_i\mUf^T\}
%     \label{eq: alicec structure}
% \end{align} 
% where $\mUf$ defines a shared \textbf{full-rank} eigen-space, and $\mD_i$ is a positive eigenvalue matrix. Adam is a special case by constraining $\mUf=\mI$. Additionally, the structures in \cref{subsec: sve} are also special cases by setting $\mD_i=\mD$ (whitening); and $\mUf=\mI$, $\mD_i=s_i\mI$ (normalization). 
% However, this structure does not directly lead to an analytic solution for \cref{eq: UFE equation}. 
% Instead, we propose to approximate the solution by solving a 1-step refinement. 

% \begin{theorem}[1-step refinement]
%     For the structure in \cref{eq: alicec structure}, we consider the following 1-step refinement: (i) assuming all $\mD_i$ are equal, and find $\mUf$; (ii) fix the $\mUf$ and find $\mD_i$. Then, step (i) admits the analytic solution:
%     \begin{equation}
%         \mUf = \eig(\E[\mG\mG^T]).
%     \end{equation}
%     where $\eig$ is the eigenvalue decomposition; step (ii) admits the analytic solution: 
%     \begin{equation}
%         \tilde{\mD} = \diagm(\E[(\mUf^T\mG)\elesquare])
%     \end{equation}
%     where $\tilde{\mD} = \diagb(\mD_1,\ldots,\mD_n)$. 
%     \label{thm: alicec 1 step refinement}
% \end{theorem}
% Based on this result, we can derive the corresponding square-root \gls{ngd} with given $\mU$ (refer to \cref{subapp: update of generlized adam}):
% \begin{equation}
%     \devect(\Ft^{-\frac{1}{2}}\vecg) = \mUf\frac{\mUf^T\mG}{\sqrt{\E[(\mUf^T\mG)\elesquare]}}.
%     \label{eq: alicec update}
% \end{equation}
% This can be viewed as applying Adam's update on a space ``rotated" by $\mUf$.
% Consequently, we propose an optimizer, called \gls{alicec}, with the following update procedures:
% \begin{align}
%     &\vm_{t} = \beta_1\vm_{t-1}+(1-\beta_1)\mG_t\;\;\; (\text{first moment})\nonumber\\
%     &\mQ_{t} = \beta_3\mQ_{t-1}+(1-\beta_3)\mG_t\mG_t^T\;\;\;(\text{\gls{ema} for }\E[\mG_t\mG_t^T])\nonumber\\
%     & \mU_{f,t} = \eig(\mQ_{t})\nonumber\\
%     & \vv_t = \beta_2\vv_{t-1}+(1-\beta_2)(\mU_{f,t}^T\mG_t)\elesquare\;\;\;(\text{second moment})\nonumber\\
%     &\Delta_t = \mU_{f,t}\frac{\mU_{f,t}^T\vm_{t}}{\sqrt{\vv_t}}
% \label{eq: practical alicec equations}    
% \end{align}
% \Cref{alg: alicec optimizer} in \cref{subapp: AdaDiag} summarizes the practical procedure. 
% In fact, the above procedures coincide with two concurrent works: AdaDiag and one-sided SOAP \citep{anonymous2024improving, vyas2024soap}, which are heuristic memory-efficient variants of their main algorithms (i.e.~AdaDiag++ and SOAP).
% In the following, we show \gls{alicec} should not be classified as a sinmple variant of SOAP/AdaDiag++, since they have different underlying structures, and should be given a different name. 



% \paragraph{SOAP/AdaDiag++} Despite the structural generality of \gls{alicec}, it only focuses on the block diagonals of \gls{fim}. To go beyond this, one can combine the structure of \gls{alicec} with Shampoo's Kronecker product to obtain a structure that generalizes all the others in this paper. Interestingly, this turns out to be SOAP/AdaDiag++. Refer to \cref{subsec: new opt combination}. 