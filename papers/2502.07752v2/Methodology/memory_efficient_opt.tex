\label{sec: memory efficient opt}

In this section, we propose a novel low-rank framework consisting of three steps, low-rank \textbf{tracking}, subspace \textbf{switching}; and \textbf{compensation}. Tracking aims to reduce the memory cost of \gls{ema} states, whereas switching and compensation are designed to correct the potential issues caused by tracking and the limitations of low-rank projections. We demonstrate this procedure by converting \gls{alicec} to its low-rank version, \gls{alice}. While the procedure could be applied to SOAP in a similar manner, we leave this for future work. 

\paragraph{Reduce computational cost}
To improve the computational efficiency, we make two modifications to \gls{alicec}. First, we propose to use 1-step subspace iteration algorithm as an efficient scheme to find leading eigenvectors (\cref{alg: subspace iteration} in \cref{app: background}). Second, we only update projection $\mU$ every $K$ steps, effectively partitioning the training into time blocks with size $K$, and amortizing the cost. Consequently, $\mU$ is fixed within a time block. 

\subsection{Tracking: low-rank projections to reduce memory}
By carefully examining the \gls{alicec}'s procedure (\cref{eq: alicec update}), we notice all internal states are connected through the projection $\mU_{f,t}$. To reduce the memory cost, we can obtain a low-rank $\mU_t$ by keeping only the top $r$ eigenvectors, and denote the remaining $m-r$ basis as $\mU_{c,t}$ (i.e.~$\mU_{f,t}=[\mU_t, \mU_{c,t}]$). For tracking state $\mQ_t$, we can also apply low-rank approximation and only track the projected states. We call it \textbf{low-rank tracking}:
\begin{align}
    \bm{\sigma}_t = \mU_t^T\mG_t;\;\;\;\widetilde{\mQ}_{t+1} = \beta_3\widetilde{\mQ}_{t} + (1-\beta_3)\bm{\sigma}_{t}\bm{\sigma}_t^T
    \label{eq: tracking step}
\end{align}
where $\bm{\sigma}_t$ is the projected gradient, and $\widetilde{\mQ}_t$ is the low-rank tracking state. One can easily reconstruct back $\mQ_t \approx \mU_t\widetilde{\mQ}_t\mU_t^T$ when needed. This reduces the memory from $m^2$ to $r^2$. 

However, this low-rank projection comes with two major consequences: (1) the reconstructed state $\mQ_t$ is no longer accurate; (2) the resulting parameter update $\Delta$ in \cref{eq: alicec update} ignores the information within $\mU_{c,t}$ due to low-rank $\mU_t$. Next, we propose two additional steps, switching and compensation, rooted in theoretical insights to address these two problems, respectively.


\subsection{Switching: mixing leading basis with the complements}
\label{subsec: switching}
We omit the subscript $t$ in $\mU$ and $\mU_c$ in the following since they are fixed within a time block. 
Since the projected gradient $\bm{\sigma}_t$ only maintains the information in the space spanned by $\mU$, the low-rank tracking state $\widetilde{\mQ}_t$ necessarily discards information in $\mU_{c}$. Therefore, even if those directions should become the leading basis at the time we update the $\mU$, $\widetilde{\mQ}_t$ will ignore their contributions, causing the stability of the previous leading eigenvectors and preventing the exploration of other spaces. We prove that this is possible by showing that the true tracking state $\mQ_t$ can be decomposed into low-rank tracking reconstruction and a residual term quantifying the importance of $\mU_{c}$:
\begin{proposition}[Subspace switching]
    Assuming the setup mentioned above and all assumptions of \gls{alicec} are satisfied. We further assume the low-rank $\mU\in\Rmr$ is obtained at the beginning of $i+1$ time block by $\eig(\mQ^*_{ik},r)$ where $\mQ^*_{ik}$ is the true tracking state. Further, we assume the stability of the eigen-basis such that gradient $\mG_t$ during $i+1$ time block shares the same eigen-basis as $\mQ^*_{ik}$. Then, the true tracking state at the end of $i+1$ block, $\mQ^*_{(i+1)k}$, can be decomposed into:
    \begin{align}
        \mQ^*_{(i+1)k}=\sum_{t=ik+1}^{(i+1)k} \mG_t\mG_t^T = \sum_{t=ik+1}^{(i+1)k} \widetilde{\mG}_t\widetilde{\mG}_t^T+\mU_c\bm{\Sigma}_t\mU_c^T
        \label{eq: what is happening with low-rank U}
    \end{align}
    where $\widetilde{\mG}_t=\mU\bm{\sigma}_t$ is the low rank reconstructed gradients, $\bm{\Sigma}_t\in\mathbb{R}^{(m-r)\times (m-r)}$ is a diagonal matrix with positive values, and $\mU_c$ is the remaining eigen-basis such that $[\mU,\mU_c]$ will form the complete eigen-basis of $\mQ^*_{ik}$. 
    \label{prop: subspace switching}
\end{proposition}
When some entries in $\bm{\Sigma}_t$ become dominant, the corresponding basis in $\mU_c$ will form the new leading eigen-basis when updating the projection $\mU$ through $\eig(\mQ_{(i+1)k}^*)$. On the other hand, if $\mU$ is updated with low-rank reconstructed state alone, it is equivalent to setting $\bm{\Sigma}_t=0$, ignoring the contributions of $\mU_c$, and resulting in the stability of the previous leading basis. 
Inspired by this insight, we propose a practical scheme to update $\mU$, instead of relying on \gls{evd} of low-rank reconstructed state. We call it subspace switching (\cref{alg: subspace switching}). Intuitively, we force the new projection $\mU$ to mix the leading eigen-basis with randomly sampled eigenvectors from the remaining basis $\mU_c$, allowing the optimizer to explore other spaces. Although the true $\mU_c$ is hard to obtain in practice, we propose to approximate it by the QR decomposition of $\mU$. 

\begin{algorithm}
    \caption{Subspace switching}
    \label{alg: subspace switching}
    \begin{algorithmic}[1]
        \STATE {\bfseries Input:} Reconstructed state $\mQ$, rank $r$, leading basis number $l$, previous low-rank projection $\mU_{t-1}$
        \STATE $\mU_t'=\text{Subspace iteration}(\mQ, \mU_{t-1})$
        \STATE $\mU'_{t,1}\leftarrow \text{Keep top $l$ eigenvectors of }\mU'_t$ 
        \STATE Uniformly sample $r-l$ basis from the complement $\mU'_{c,t} = \qr(\mU'_{t})$ as $\mU'_{t,2}$
        \STATE Combine basis $\mU = [\mU'_{t,1},\mU'_{t,2}]$
        \STATE {\bfseries Return} $\mU$
    \end{algorithmic}
\end{algorithm}

\subsection{Compensation: convert low-rank update to be full-rank}
\label{subsec: compensation}
Another problem with low-rank projection $\mU$ is the information loss in the resulting parameter update $\Delta$ at each step. The goal of compensation step is to compensate for this information loss with minimal memory overhead. Firstly, we need to know which information has been discarded. We show that the update $\Delta$ with full-rank $\mU_{f}$ in \cref{eq: alicec update} can be decomposed into the low-rank update with $\mU$ and complement update controlled by $\mU_{c}$ (proof in \cref{subapp: discussion low-rank}):
\begin{align}
    \Delta =\mU\frac{\mU^T\mG}{\sqrt{\E[(\mU^T\mG)\elesquare]}}
    + \underbrace{\mU_{c}\frac{\mU_{c}^T\mG}{\sqrt{\E[(\mU_{c}^T\mG)\elesquare]}}}_{\devect(\Ft_{c}^{-\frac{1}{2}}\vecg)}
    \label{eq: alice update decomposition}
\end{align}
where $\Ft_{c}=\diagb(\mU_{c}\mD_{c,1}\mU_{c}^T,\ldots, \mU_{c}\mD_{c,n}\mU_{c}^T)$ is the approximated \gls{fim} corresponding to the complement basis $\mU_c$, $\mD_{c,i}=\diagv(\E[(\mU_c^T\vg_i)^2])$ and $^{-\frac{1}{2}}$ is the square-root pseudo-inverse. 

We notice that the discarded information, $\devect(\Ft_c^{\frac{1}{2}}\vecg)$, has the same format as the square-root \gls{ngd} with \gls{fim} $\Ft_c$. From the proposed \gls{fim} view point, the design of compensation term becomes the selection of a structure to approximate $\Ft_c$, and the application of the corresponding square-root \gls{ngd}. Considering the trade-off between structural generality and practical efficiency, one structural choice is the diagonal structure of normalization operator, which simply scales the columns of gradient matrix and is highly memory efficient. In addition, we only want to focus on the discarded information $\mU_c\mU_c^T\mG$ for compensation, rather than the entire gradient $\mG$. We propose the following compensation at each step $t$:
\begin{align}
    \mC_t= \devect((\mS\otimes\mU_c\mU_c^T)\vecg_t)=\mU_c\mU_c^T\mG_t\mS
    \label{eq: compensation term}
\end{align}
where $\mS$ is a positive diagonal matrix, $\mU_c\mU_c^T\mG=(\mG-\mU\mU^T\mG)$ is the gradient information within the remaining basis. We show that such design choice admits an optimal solution of $\mS$ to the \gls{fim} approximation problem.
\begin{theorem}[Optimal compensation]
    Assume that the conditions of \gls{alicec} are satisfied. With the proposed form of compensation (\cref{eq: compensation term}), minimizing \gls{fim} reconstruction loss
    \begin{align*}
        \Fnorm{(\mS_t^{-2}\otimes \mU_c\mU_c^T)-\Ft_{c}}
    \end{align*}
    admits analytic solution:
    \begin{equation}
        \diag(\mS_t) = \frac{\sqrt{m-r}}{\sqrt{\E[\bm{1}_m^T\mG_t\elesquare-\bm{1}_r^T(\mU^T\mG_t)\elesquare}]}
         \label{eq: optimal D for compensation}
    \end{equation}
    where $\bm{1}_m\in\mathbb{R}^m$, $\bm{1}_r\in\mathbb{R}^r$ are the column vectors with element $1$.
    \label{thm: optimal compensation}
\end{theorem}
\cref{alg: compensation} summarizes the compensation step.

\begin{algorithm}
    \caption{Compensation}
    \label{alg: compensation}
    \begin{algorithmic}[1]
        \STATE {\bfseries Input:} $\mG_t$, projection $\mU$, previous norm $\vp$, limiter norm $\bm{\phi}$, limiter threshold $\gamma$, decay rate $\beta$
        \STATE $\vp \leftarrow \beta\vp+(1-\beta)(\bm{1}_m^T\mG_t\elesquare-\bm{1}_r^T(\mU^T\mG_t)\elesquare)$
        \STATE $\mC_t\leftarrow\sqrt{m-r}(\mG_t-\mU\mU^T\mG_t)\diagv(\vp)^{-\frac{1}{2}}$
        \STATE $\eta=\gamma\slash \max\{\frac{\Vert\mC_t\Vert}{\phi},\gamma\}$ if $\phi>0$ else $1$        
        \STATE $\phi = \Vert\eta\mC_t\Vert$      
        \STATE $\mC_t\leftarrow \eta \mC_t$
        \STATE {\bfseries Return} $\mC_t$, $\vp$, $\phi$
    \end{algorithmic}
\end{algorithm}



\subsection{\Gls{alice} optimizer}
\label{subsec: alice optimizer}
By combining \gls{alicec} with low-rank $\mU$, tracking, switching and compensation, we obtain \gls{alice}, a novel low-rank optimizer. One can also design a simple variant, \gls{alicez}, by disabling the tracking for better memory efficiency.
\paragraph{Connections to GaLore}
Interestingly, GaLore, in fact, is an approximation to \gls{alice} without tracking, switching and compensation. Based on the connection of \gls{alice} to \gls{alicec}, we reveal that GaLore is a simple low-rank extension of \gls{alicec}, a more general optimizer than Adam. This also reflects the advantage of the \gls{fim} view point, which provides a deeper understanding and an explanation on its better performance than Adam under certain scenarios \citep{zhao2024galore}.
% Our derivation of \gls{alice} offers a connection of GaLore to \gls{alicec}, revealing that it is a low-rank version of a more powerful optimizer than Adam, and providing an explanation of its effectiveness. 


\begin{algorithm}
\caption{\gls{alice}/\gls{alicez} optimizer}
\label{alg: alice optimizer}
    \begin{algorithmic}[1]
        \STATE {\bfseries Input:} learning rate $\lambda$, scale $\alpha$, compensation scale $\alpha_c$, update interval $k$, $\beta_1$, $\beta_2$, $\beta_3$ ($\beta_3=0$ for \gls{alicez}),  optimization step $T$, rank $r$, loss function $\mathcal{L}$, limiter threshold $\gamma$, leading basis number $l$ 
        \STATE $\widetilde{\mQ}_0 = 0$, $\mU_0=0$, $\vp_0=0$, $\bm{\phi}=0$, $\vm_0=0$, $\vv_0=0$
        \FOR{$t=1\ldots, T$}
            \STATE $\mG_t=\nabla_{\mW_t}\mathcal{L}$
            \IF{$t==1$ or $(t\mod K)==0$}
                \STATE 
                $\mQ_t=\beta_3\mU_t\widetilde{\mQ}_{t-1}\mU_t^T+(1-\beta_3)\mG_t\mG_t^T$ 
                \STATE $\mU_t=Switch(\mQ_t, r, l, \mU_{t-1})$
            \ELSE
                \STATE $\mU_t=\mU_{t-1}$
            \ENDIF
            \STATE $\bm{\sigma}_t = \mU_t^T\mG_t$ 
            \STATE $\widetilde{\mQ}_t = \beta_3 \widetilde{\mQ}_{t-1} +(1-\beta_3)\bm{\sigma}_t\bm{\sigma}_t^T$ 
            \STATE $\vm_t = \beta_1 \vm_{t-1}+ (1-\beta_1)\bm{\sigma}_t$
            \STATE $\vv_t = \beta_2 \vv_{t-1} + (1-\beta_2) \bm{\sigma}_t\elesquare$
            \STATE $\bm{\omega} = \frac{\vm_t}{\sqrt{\vv_t}}$
            \STATE $\Delta_c, \vp_t, \bm{\phi}_t = Compensation(\mG_t, \mU_t, \vp_{t-1}, \bm{\phi}_{t-1}, \gamma, \beta_1)$ 
            \STATE $\mW_{t+1}=\mW_t-\lambda\alpha (\mU\bm{\omega}+\alpha_c\Delta_c)$
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

