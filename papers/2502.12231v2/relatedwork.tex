\section{Related Works}
\subsection{3D Reconstruction}
Recently, Neural Radiance Field (NeRF)\cite{mildenhall2020nerf} has raised a lot of attention due to its photo-realistic rendering ability. 3D Gaussian Splatting (3DGS)\cite{kerbl3Dgaussians} goes one step further to achieve real-time rendering. Some works have extended NeRF\cite{mildenhall2020nerf} and 3DGS\cite{kerbl3Dgaussians} to address their inherent limitations\cite{chen2023nerrf3dreconstructionview, Yuan_2024, liu2024ripnerf, song2024sa} or leverage these novel 3D representations for applications in other domains\cite{wu2023mars, peng2024synctalk, zhang2024droneassistedroadgaussiansplatting}. However, most of these works focus on delivering better visual quality but overlook the importance of physical properties, which is critical for application in robotics.
Some previous works focus on the accurate geometry\cite{guedon2023sugar, Huang2DGS2024, zhang2024radegsrasterizingdepthgaussian, chen2024pgsr}, in which PGSR\cite{chen2024pgsr} adds a new geometry loss that promises normal-depth consistency. NeRF2Physics\cite{zhai2024physical} utilizes NeRF\cite{mildenhall2020nerf} as a 3D representation and proposes to predict its physical property using Large Language Model (LLM) for the first time. Yet it tries to extract point clouds from NeRF as the scene's geometry to calculate mass, which is slow and may not be accurate enough.

\subsection{Physical Property Prediction}
Physical property prediction from visual data is very important for robotics\cite{zhang2024adaptigraph, shi2023robocook, li2018learning}. However, collecting paired data between images and various physical properties is very hard. Some previous works propose reasoning physical properties by observing the object's movement or interaction with other objects in a 3D physical engine\cite{li2023pacnerf, 10.1007/978-3-319-46475-6_1, NIPS2015_d09bf415, 10160731}. However, these methods are still limited to a few physical properties and are hard to use. NeRF2Physics\cite{zhai2024physical} is the first to utilize LLMs for physical property prediction tasks in a zero-shot manner and Octopi\cite{yu2024octopi} further proves its importance in grasping tasks. We aim to make the process faster and more accurate by using 3DGS and a more reliable framework.

\subsection{Vision Language Model}
Vision Language Models (VLMs)\cite{ilharco_gabriel_2021_5143773,zhu2023minigpt,li2023blip} have become increasingly popular in robotics, enabling applications across various tasks\cite{huang2023voxposer,moo2023arxiv,chen23polarnet,rt22023arxiv,qin2024langsplat,zhou2024feature,kerr2023lerf,zhou2024navgpt}. While some methods\cite{zhou2024navgpt,huang2023voxposer} utilized text and images as input to plan complex tasks, others, like\cite{kerr2023lerf,qin2024langsplat}, employ CLIP\cite{ilharco_gabriel_2021_5143773} to establish a feature distillation field for aligning 3D representions with text. In our work, We fully leverage the capabilities of VLMs. By utilizing GPT-4 for single-image physical property prediction and CLIP\cite{ilharco_gabriel_2021_5143773} for mapping these properties to 3D reconstructions, we achieve zero-shot physical property prediction with 3D reconstruction.

%%%%%%%%%%%%%%%%%%%%%%%%%%    method    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%