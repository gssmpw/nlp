\section{Introduction}
    


\textit{How does intelligence emerge?} We believe that intelligence is not an innate gift but rather a necessity shaped by \textit{Natural Selection}. The diversity of life forms we see today, including humans, animals, and plants, has addressed countless challenges imposed by the natural world.
Natural Selection can be viewed as a trial-and-error process, where subjects shall persistently explore, seek solutions in the face of uncertainty, and ultimately prevail.  
The subjects must strive to solve the challenges, experimenting again and again until they succeed. If they cannot find a solution, they fail the test and thus do not survive. 


Inspired by Natural Selection, we propose \textit{Survival Game} to evaluate intelligence. Similar to how species find a way to survive through trial and error in Natural Selection, \textit{Survival Game} evaluates intelligence by counting the number of failures before finding correct solutions in a trial-and-error process. Fewer failures correspond to higher intelligence. The number of failures is a discrete random variable, and smaller expectations and variances of the failure count indicate higher intelligence.
If expectations and variances are infinite, the subjects can never find the correct solutions and thus do not survive in the game.
Based on the convergence of the expectations and variances, \textit{Survival Game} divides intelligence into three levels: Limited, Capable, and Autonomous. If both the expectation and variance diverge, the subject is at the Limited Level. At this level, the subject is comparable to blindly enumerating possible solutions. If both the expectation and variance converge, the subject reaches the Autonomous Level. At this level, the subject can stably find the correct solution with only a few trials, thereby being able to autonomously operate at an affordable cost.
As we can see, the results of the \textit{Survival Game} have clear physical meaning about the subject's intelligence level.


The \textit{Survival Game} can be applied to any task and any species. In this paper, we are particularly interested in artificial intelligence~(AI) systems. Therefore, we conduct \textit{Survival Game} on state-of-the-art AI systems available today. The results demonstrate that a system with better modeling of the task can reach a higher level of intelligence. Current AI technologies can reach the Autonomous Level on simple tasks like handwritten digit recognition. However, they are mostly at Limited Level on more complex tasks, including vision, search, recommendation, and language. This indicates that most AI systems are at a preliminary stage: they are unable to substantially narrow down the range of possible answers and their performance is comparable to brute-force enumeration. This indicates that directly applying these AI technologies can result in very high costs and serious errors, so they cannot operate autonomously, and human supervision is essential. 
These findings challenge conclusions from previous studies~\citep{biever2023chatgpt, aharoni2024attributions, mei2024turing}, which suggest that AI has already reached a very high level of intelligence.

\begin{figure}[h]
    \subcapraggedrighttrue
    \subcaphangtrue
        \centering
        \subfigure{\includegraphics[width=0.49\textwidth]{figures/drawing_time/allenai/c4/en/perf.pdf}} \hfill
        \subfigure{\includegraphics[width=0.49\textwidth]{figures/drawing_time/allenai/c4/en/pred.pdf}}
        \caption{Experimental Results of \textit{Survival Game} in General Domain. Left: Results suggest that larger models achieve better performance.
         Right: Results suggest that achieving Autonomous-Level Intelligence requires an unimaginable parameter scale.}
        \label{fig:full_perf}
    \end{figure}

In \textit{Survival Game}, the intelligence score exhibits a log-linear relationship with the scale of AI systems. If we assume this relationship continues to hold, we can predict the scale required to achieve Autonomous-Level intelligence, as shown in Figure~\ref{fig:full_perf}. The projection suggests that, for general language tasks, an AI system would need a parameter size of $10^{26}$ to reach the Autonomous Level.
To put this scale into perspective, this is equivalent to $10^5$ times the total number of neurons in all of humanityâ€™s brains combined. Loading a model of this size onto H100 GPUs would necessitate $5 \times 10^{15}$ H100 cards, a cost equivalent to $4 \times 10^7$ times the market value of Apple Inc. If hardware development continues to follow Moore's Law, it would take 70 years of progress to support the development of such a large model.
These results suggest that attempting to solve human tasks with current AI technology is extremely difficult, if not impossible.


Why is the Autonomous Level so difficult to achieve for current AI systems? We conduct a theoretical analysis and demonstrate that the root cause lies in the complexity of human tasks and the inadequacies of current AI technologies. Specifically, we leverage self-organized criticality (SOC)~\citep{bak2013nature} to analyze \textit{Survival Game}. Results suggest that many human tasks exhibit a criticality property: even slight changes in the environment require entirely different responses. To successfully operate these tasks, it is important to fully understand their mechanisms. However, current AI systems do not fully grasp this complex mechanism and instead leverage superficial imitation: They memorize answers to some questions and attempt to solve new questions through exploration. Although scaling AI systems can make the exploration more effective and improve imitation performance, a lack of a full understanding of the underlying mechanism results in unimaginable costs.

    
The structure of this paper is as follows. In Section~\ref{sec:related_work}, we review related works on intelligence evaluation to provide a broad context for our method. In Section~\ref{sec:define_intelligence_test}, we present \textit{Survival Game} and show how it measures intelligence and categorizes it into three levels. In Section~\ref{sec:evaluate_current_ai}, we extensively evaluate existing AI systems using \textit{Survival Game}. Section~\ref{sec:future_prediction} empirically explores how scaling improves Intelligence. In Section~\ref{sec:theory}, we provide a theoretical analysis of \textit{Survival Game} to gain a deep understanding of the nature of human tasks and current AI. Finally, in Section~\ref{sec:conclusion}, we conclude the paper and outline potential directions for future research.






