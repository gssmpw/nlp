\section{Methodology}
\label{sec:define_intelligence_test}

We propose \textit{Survival Game}, a framework to evaluate intelligence via a trial-and-error process.
Its core concept is to test how well a subject can autonomously explore and find solutions.
In the following subsections, we first revisit Natural Selection and formalize it as a \textit{Survival Game}. Then, we extend Survival Game as \textit{Survival Game} to quantify intelligence at any task. Next, we interpret the results of \textit{Survival Game} into three levels of intelligence. Furthermore, we propose an approximation method to apply \textit{Survival Game} in costly tasks.
Finally, we discuss how \textit{Survival Game} differs from previous studies.


\subsection{Natural Selection as a Trial-and-Error Test}





Natural Selection is an intuitive way to test intelligence. If a subject passes Natural Selection, it signifies that this subject possesses the intelligence to operate autonomously and can sustain itself without external guidance.
The process of Natural Selection is extraordinarily complex, involving competition between species, genetic mutations, etc. Rather than delving into these intricate details, we simplify Natural Selection into a trial-and-error test as follows:

\begin{definition}
Imagine a species with a sufficiently large population. Its individuals stand in line outside a room. A sign at the entrance warns them that once inside, they will face a critical question. One by one, the individual enters the room and gives answers. An incorrect answer makes the individual vanish, while a correct answer lets it survive. One survivor can mark the species as having passed the test.
\end{definition}


Despite the simplification, this trial-and-error test captures the essence of Natural Selection. Throughout history, nature has posed countless challenges to humankind. When asked how to survive predators, the intelligent among us answered fire and tools. When faced with the threat of starvation, the intelligent among us developed agriculture. When confronted with disease, the intelligent among us advanced medicine. Civilization itself has been forged through these relentless trials and errors. 

Based on the description of the above trial-and-error process, we can translate it into mathematical terms to make it clearer.

\begin{definition}
Let $N$ be the population size of a species. Let \( X \) represent the number of individuals who fail before the correct answer is found. \( X \) takes values in the range of $0 \leq X \leq N$, where $X=0$ means the first individual answers correctly, while $X=N$ means that all individuals fail. If at least one individual succeeds, i.e., \( X < N \), the species passes the game.
\end{definition}

We can see that the number of failures, $X$, is a direct measure of a species' survival intelligence. The smaller the value of $X$, the less effort the species needs to solve problems. Inspired by this, our proposed Survival Game will similarly measure intelligence.


\subsection{Measuring Intelligence with Survival Game}

Based on the trial-and-error process in Natural Selection, we introduce \textit{Survival Game}, which evaluates intelligence by the number of failure attempts in this process. To ensure a robust evaluation result, \textit{Survival Game} models failure counts as a discrete random variable and uses statistical metrics for evaluation. The modifications are two-fold:
\begin{itemize}
	\item Modeling Failure Count as a Discrete Random Variable: One task can involve numerous variations, and failure counts may be very different across these variations. For instance, consider testing a subject's ability to solve mathematical problems. A small change in the numbers or the context of the problem could lead to a significant shift in the subject’s failure counts. Similarly, when a task is classifying images, different pictures can result in substantial fluctuations in performance. Therefore, the variability within the task can cause the results to be unstable. To account for this variability, \textit{Survival Game} models failure count as a discrete random variable, which allows us to handle the variations across task variants effectively.
	\item Statistical Criteria for Evaluation: Population size $N$ serves as a threshold value in the trial-and-error test for Natural Selection. It directly affects the conclusion. The larger the value of $N$, the more attempts are available to the subject, and consequently, the higher the likelihood of success. Yet, for tasks other than survival, the notion of what constitutes an ``appropriate'' $N$ can vary from one researcher to another. This variability in determining an appropriate N leads to inconsistencies in the conclusions. Therefore, \textit{Survival Game} does not use a pre-defined threshold for measurement. It quantifies intelligence as the distribution of failure count. A lower probability of a large failure count suggests higher intelligence. 
\end{itemize}


With these statistical improvements, we formally define \textit{Survival Game} as follows:
\begin{definition}[Survival Game]
Let a subject perform a certain task through continuous trial and error until finding the correct solution. \( X \) is a random variable representing the number of failures before the subject finds the correct solution. Then, $X$ serves as the measure of this subject's intelligence on the task. Smaller expectations and variances of $X$ correspond to higher intelligence.
\end{definition}
Smaller expectations and variances indicate that the subject can achieve success with fewer failures and thus is more intelligent.
This definition allows us to assess intelligence in any given task. We can choose to evaluate intelligence in narrow tasks such as answering domain-specific questions, or we can test a subject across diverse and complex tasks to determine whether it exhibits general intelligence, such as memorizing every information on the Internet.
The measurement of \textit{Survival Game} has a clear physical meaning: it signifies how well a subject can reliably find solutions for a given task on its own.


It is worth noting that \textit{Survival Game} assumes that subjects must keep trying until they succeed even if the cases are very difficult. For easy cases where subjects can answer correctly without trial and error, the contribution to the failure count is zero. We can see that \textit{Survival Game} essentially ignores easy cases where subjects can answer correctly right away and instead focuses on difficult cases that require repeated trials and errors.
For example, in image classification, \textit{Survival Game} focuses on images that the AI model initially misclassifies. It examines how many trial-and-error attempts are needed before achieving the correct classification. This emphasis on trial and error differentiates the Survival Game from existing evaluation methods based on accuracy.
In real-world applications, if a task is highly sensitive to errors, such as high-risk decision-making scenarios like autonomous driving, \textit{Survival Game} provides a better reflection of whether an AI model can be trusted. Additionally, in highly intellectual tasks that require AI to go through trial and error to find a solution, such as proving mathematical theorems or optimizing agent workflows, \textit{Survival Game} metric directly corresponds to computational cost and shall better reflect AI's applicability.


\subsection{Classifying Intelligence into Three Levels}


In this subsection, we analyze the distribution of failure counts obtained from the \textit{Survival Game} to gain a clear understanding of the subject's level of intelligence. First, we introduce an Infinity Assumption to define the least intelligent scenario. Based on this, we then propose three levels of intelligence. Finally, we explain how to classify subjects into these three intelligence levels based on the distribution of their failure counts.



\subsubsection{Infinity Assumption}

What situation represents a subject having almost no intelligence related to the task? Imagine a scenario in an \textit{Survival Game} where a monkey sits in front of a computer and types to see if it can produce Shakespeare’s works. If it deviates from Shakespeare’s works, we let it attempt again. The failure count refers to the number of attempts before success. The monkey has no understanding of human language and just types randomly. In theory, since the human vocabulary is finite and Shakespeare’s works are also of limited length, the monkey could use an enumeration method, blindly trying all possible combinations of words. Even though most of these combinations are completely nonsensical to us, the monkey can eventually type out Shakespeare's works. However, this blind, exhaustive enumeration shows that the subject lacks any real intelligence. It is also disconnected from practical reality because the cost of such an exhaustive search would far exceed any reasonable resource limitations, much like how it is completely unrealistic to expect a monkey to eventually produce Shakespeare’s works. Shakespeare did not create his works by randomly typing and waiting for greatness to emerge. Instead, he produced the masterpieces through intentional creativity within the limitations of human life. Therefore, when the failure count approaches the cost of exhaustive enumeration, it almost certainly indicates that the subject has no intelligence related to the task.


We note that the high cost of blind enumeration closely resembles the mathematical concept of infinity. In mathematics, infinity describes a scenario where a quantity is beyond the scale we can measure or endure. For example, when measuring objects on Earth, we can assume the distance from the Sun to the Earth is infinite, and based on this assumption, we treat sunlight as parallel rays. This is because, compared to the size of objects on Earth, the distance between the Sun and Earth is so vast that it can be approximated as infinity. This allows us to use the property of parallel sunlight to help with measurement tasks. The concept of infinity in mathematics is a way of thinking in terms of limits and approximations. While infinity does not directly exist in the physical world, it helps us understand and describe extremely large quantities and allows us to handle them more conveniently.
In the case of the \textit{Survival Game}, the characteristic of blind enumeration aligns closely with the concept of infinity. In theory, blind enumeration can eventually lead to the correct solution, but the cost of doing so far exceeds the available resources or our willingness. Therefore, we can model the cost of blind enumeration in the \textit{Survival Game} as infinity and thus can better interpret the results of the test.


We propose the following Infinity Assumption: Failure count approaches infinity if it approaches the cost of blindly enumerating all possibilities. In other words, failure count is finite if it is much smaller than the cost of exhaustive enumeration.
Under this mathematical assumption, infinity serves as a clear criterion for determining whether intelligence is present. When the failure count is finite, it indicates that the subject has excluded many possibilities in advance and is consciously engaging in trial and error, ultimately achieving success. At this point, the subject truly demonstrates intelligence in this task. This mathematical assumption allows us to clearly distinguish between different levels of intelligence.


\subsubsection{Three Intelligence Levels}

The above Infinity Assumption links intelligence with infinity. It enables us to clearly define different levels of intelligence in mathematical terms. Based on this, we compare the statistical measures of failure count with infinity and define three levels of intelligence:

\begin{itemize}
	\item \textbf{Limited Level}: A subject belongs to this category if the expectation of failures is infinite: \( E(X) \rightarrow \infty \). At this intelligence level, the subject is comparable to blindly enumerating all possible outcomes. The cost for the subject to autonomously solve the task is unacceptable in real-world scenarios. It requires external supervision to improve itself and reliably operate within the task.
	\item \textbf{Capable Level}: A subject belongs to this category if the expectation of failures is finite, but the variance remains infinite: \( E(X) < \infty , \text{Var}(X) \rightarrow \infty \). At this intelligence level, the subject is, in principle, capable of solving the given task. However, the number of failures vary drastically across different cases. Its performance is highly unpredictable and failures can still occur frequently. As a result, autonomous operation is risky, and external supervision remains necessary to ensure reliability.
	\item \textbf{Autonomous Level}: A subject belongs to this category when both the expectation and variance of failures are finite: \( E(X) < \infty , \text{Var}(X) < \infty \). Subjects at this level can reliably find solutions for the given task. They may operate autonomously without relying on external supervision.
\end{itemize}

If a subject reaches the Autonomous Level, it can reliably find solutions with affordable trials and errors. If we imagine that the subject will use the correct solutions as supervision signals to improve itself, the Autonomous Level implies that the subject no longer requires external supervision to provide correct answers. Instead, it can rely solely on their attempts to find the solution. In this way, the subject can independently generate supervision data and improve itself to further reduce the failure counts. In AI, this process is similar to reinforcement learning, where the system autonomously explores solutions and uses the results to update itself. If the subject has not reached the Autonomous Level, it is almost infeasible to find solutions on its own. More precisely, subjects at the Limited Level require an infinite number of attempts, which is completely beyond reasonable limits, while subjects at the Capable Level are very unstable in finding the solution. These factors make it challenging for the system to autonomously explore solutions and instead necessitate external supervision.

\subsubsection{Decay Rate Classification}
\label{sec:decay_rate_classification}

Before presenting how to practically determine intelligence levels, let us revisit the Infinity Assumption.
Although infinity does not exist in the physical world, this does not prevent us from treating certain quantities, which far exceed our capacity to measure or endure, as if they were infinite. 
In the case of the \textit{Survival Game}, the total number of possible solutions is finite, but as described in the Infinity Assumption, we lack the resources or willingness to blindly enumerate all of them. Therefore, the Infinity Assumption treats the number of possible solutions as if it were infinite. 

Based on the Infinity Assumption, the distribution of the failure count can be seen as extending from 0 to infinity. Therefore, we can assess the convergence of the expectation and variance according to the distribution of the failure count.
Note that the convergence of expectation and variance is determined by the tail behavior of the probability density function. Let $X$ be a discrete random variable, and \( P(X) \) be the discrete probability density function. The convergence of \( E(X) \) and \( \text{Var}(X) \) completely rely on how fast \( P(X) \) decays at the tail. Only if \( P(X) \) is sufficiently small for big \( X \) values will the expectation and variance be finite.

Since the decay rate of failure count determines the convergence of its expectation and variance, it also directly determines the subject's intelligence level. In this way, we connect the intelligence level to the decay rate of failure count.
To examine the decay rate, we introduce power law as reference distributions for comparison. Power law \( 1/x^\alpha \) has the following properties:

\begin{itemize}
    \item When \( \alpha \leq 2 \), both expectation and variance are infinite.
    \item When \( 2 < \alpha \leq 3 \), expectation is finite but variance is infinite.
    \item When \( \alpha > 3 \), both expectation and variance are finite.
\end{itemize}

Therefore, we compare the decay rate of failure count \( P(X) \) with \( x^{-2} \) and \( x^{-3} \), and propose the following classification method to determine the intelligence level:

\begin{itemize}
	\item If \( P(X) \) decays more slowly than \( x^{-2} \), both expectation and variance are infinite. The subject is at the Limited Level.
	\item If \( P(X) \) decays faster than \( x^{-2} \) but more slowly than \( x^{-3} \), expectation is finite but variance is infinite. The subject is at the Capable Level.
    \item If \( P(X) \) decays faster than \( x^{-3} \), both expectation and variance are finite. The subject is at the Autonomous Level.
\end{itemize}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.4\textwidth]{./figures/decay_rate_classification.pdf}
  \caption{Decay Rate Classification: Log-log plot of failure counts (x-axis) vs. probability (y-axis). The intelligence level is determined based on which region the distribution of the subject falls in.}
  \label{fig:decay_rate_classify}
\end{figure}

A practical way to visualize this comparison is to plot \( P(X) \) alongside these two reference power-law functions on a log-log scale. On such a plot, the reference functions appear as straight lines, allowing for an intuitive comparison of decay rates. As shown in Figure~\ref{fig:decay_rate_classify}, the two reference distributions divide the graph into three distinct regions, corresponding to Limited Level, Capable Level, and Autonomous Level, from top to bottom. We can easily determine the intelligence level of the subject by examining which region \( P(X) \) falls in. 


\subsection{Approximation with Reference Answers}

Note that \textit{Survival Game} requires to determine whether each attempt made by a subject is correct. Yet verifying correctness for every attempt can be expensive in some tasks. Consider a task where the test subject is to prove a mathematical theorem. The subject provides proof with each attempt. However, for complex mathematical theorems, the proofs can be very long and intricate, and the cost of verifying the correctness of each proof is extremely high. In such cases, directly applying \textit{Survival Game} may make the process prohibitively expensive.

Therefore, we propose an approximation method to address this problem. We will first introduce the underlying assumption and then formalize the approximation method.

\subsubsection{Scale-Invariance Assumption}


In situations where it is difficult to verify the correctness of each trial, we can adopt an alternative approach: counting the failure attempts before the subject arrives at a \textbf{predefined reference answer}.
For example, when testing whether a subject can prove mathematical theorems, we do not evaluate whether each of its outputs constitutes a valid new proof. Instead, we check whether it can produce a known proof.

To support the validity of such reference-based evaluation, we propose a Scale-Invariance Assumption:
\begin{itemize}
	\item The number of failures before finding any solution follows a power-law distribution.
	\item The number of failures before finding any solution is linearly related to the number of failures before finding a particular solution. 
\end{itemize}

Under the given assumption, we can prove that the number of failures before finding any solution and the number of failures before finding a particular solution have the same failure decay rate. Therefore, they yield the same result in our Decay Rate Classification. The proof is as follows:
\begin{equation}
    P(X = x) = C x^{-\alpha}, \quad x \geq x_{\text{min}}.
\end{equation}
\begin{equation}
    P(kX = x) = P(X = x/k) = C (x/k)^{-\alpha} = C k^{\alpha} x^{-\alpha} \propto x^{-\alpha}.
\end{equation}
Thus, the power-law distribution retains its functional form under linear scaling.
If the failure count follows the power law, a linear transformation does not change the power-law formulation and the exponent.

The first part of the Scale-Invariance Assumption is empirically and theoretically supported.
Specifically, Section~\ref{sec:future_prediction} will show that the failure count is close to a power-law distribution. In Section~\ref{sec:theory}, we theoretically analyze the cause of such a phenomenon. We demonstrate that this is because human tasks exhibit criticality property.

The second part of the Scale-Invariance Assumption requires further investigation. 
Whether it is linearly correlated depends on the relationship between references, tasks, and subjects.
In our experiments, we use human-written answers as references. For example, when assessing whether the model can write mathematical proofs, we use human-written proofs as references. When evaluating whether the model can generate high-quality legal opinions, we use legal opinions written by human judges. Similarly, when assessing whether the model can produce excellent literary works, we use human literary works as references.
In these cases, we assume that the number of failed attempts to arrive at a feasible solution is linearly related to the number of attempts to reach these reference solutions. 
We have not verified its correctness for now and will verify it in the future.

\subsubsection{Survival Game with References}

Based on the Scale-Invariance Assumption, we propose a variation named \textit{Survival Game with References}. It avoids the need for direct correctness verification while keeping the core of \textit{Survival Game}. In those tasks where the cost of correctness verification is high, it uses a reference answer and measures the number of failed attempts before producing the reference answer. The validity of this method is supported by the following theorem:
\begin{thm}[Survival Game with References]
Let \( X^* \) be a discrete random variable representing the number of failure attempts before finding a \textbf{predefined reference answer}.  
\( X^* \) is an upper bound estimation of the real failure counts.
If the Scale-Invariance Assumption holds, the failure decay rate of \( X^* \) is accurate.
\end{thm}

This approach eliminates the need for verifying every attempt and instead examines failure counts until reaching a known reference answer. It is a low-cost realization of \textit{Survival Game} and reflects an upper bound of the subjects' errors.
If the Scale-Invariance Assumption holds, this theorem shows that we can exactly evaluate the intelligence level in an efficient way. 



\subsection{Comparison with Related Work}
\label{sec:comparison_with_related_work}

Since we have introduced \textit{Survival Game}, we can pick up our discussion from Section~\ref{sec:related_work}. 
In contrast to the subjective tests in prior studies, \textit{Survival Game} provides an \textit{objective} way to evaluate intelligence:
\begin{itemize}
	\item \textit{Objective}~(Species-Agnostic) View of Intelligence: We define intelligence not by its similarity to humans, but by the ability to pass a test akin to Natural Selection. Any entity that can independently find solutions demonstrates intelligence, regardless of whether it is human, artificial, or another species. Even humans may not necessarily be at the Autonomous Level in some tasks, and the test is always applicable no matter whether AI surpasses humans.
	\item \textit{Objective} Choice of Tasks: We recognize that intelligence is inherently task-dependent. Unlike previous approaches that attempt to define universal intelligence, \textit{Survival Game} does not prescribe any specific task. Instead, it allows researchers to evaluate intelligence in any task of interest, ensuring that the definition of intelligence remains grounded in the actual demands of a given task.
	\item \textit{Objective} Evaluation Framework: The \textit{Survival Game} is mathematically well-defined and does not rely on any hyperparameters. Its conclusions are based on clear statistical criteria rather than subjective assessments. This ensures that evaluations remain consistent across different studies and applications, making it a robust and practical tool for assessing intelligence in real-world settings.
\end{itemize}

It is important to note that while we argue that intelligence is inherently task-dependent and should be evaluated within specific tasks, this does not prevent researchers from using \textit{Survival Game} as a framework for assessing Artificial General Intelligence~(AGI). 
From our point of view, an AGI system should reach the Autonomous Level in at least every basic human task. Therefore, to evaluate general intelligence, researchers can construct a diverse set of tasks and apply \textit{Survival Game} on each of them.



