\vspace{2ex}
Retrieval-Augmented Generation (RAG) is an advanced technique designed to address the challenges of Artificial Intelligence-Generated Content (AIGC). By integrating context retrieval into content generation, RAG provides reliable and up-to-date external knowledge, reduces hallucinations, and ensures relevant context across a wide range of tasks. However, despite RAG's success and potential, recent studies have shown
that the RAG paradigm also introduces new risks, including robustness issues,
privacy concerns, adversarial attacks, and accountability issues. Addressing
these risks is critical for future applications of RAG systems, as they
directly impact their trustworthiness. Although various methods have been
developed to improve the trustworthiness of RAG methods, there is a lack of a unified
perspective and framework for research in this topic. Thus, in this paper, we
aim to address this gap by providing a comprehensive roadmap for developing
trustworthy RAG systems. We place our discussion around five key perspectives: reliability, privacy, safety, fairness, explainability, and accountability. For each perspective, we present a general framework and taxonomy, offering a structured approach to understanding the current challenges, evaluating existing solutions, and identifying promising future research directions. To encourage broader adoption and innovation, we also highlight the downstream applications where trustworthy RAG systems have a significant impact. For more information about the survey, please check our GitHub repository\footnote{\url{https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation}}.
