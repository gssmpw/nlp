Accountability, in the context of AI, refers to the ability to determine whether decisions or outputs align with established procedural and substantive standards and to identify who is responsible when those standards are violated~\cite{doshi2017accountability}. While accountability focuses on policy and standards, we identify one key technical challenge towards accountability: the ability to identify \textit{ownership}. Generative AI poses unique challenges regarding the attribution of 'speech'—that is, determining who should bear responsibility for its outputs. It is crucial to identify and hold the appropriate entities responsible when outputs deviate from procedural or substantive standards. This necessitates robust mechanisms for content traceability, such as watermarking techniques, which can link outputs back to their source models, datasets, or operators.
\textit{Watermarking} thus serves as a critical tool for implementing ownership, enabling the identification of stakeholders responsible for ensuring procedural compliance and addressing any deviations. By providing a transparent means of associating outputs with their origins, watermarking helps bridge the gap between technical and policy-oriented accountability, making it an essential component of the accountability framework for generative AI systems. For the above reasons, we dedicate this section of discussion to the watermarking in LLMs. 

\subsection{Taxonomy of RAG Accountability}
\input{tables/accountability_taxonomy}
\paragraph{Retrieval.}
Accountability in retrieval in this survey refers to embedding watermarks within the sources of retrieval, encompassing both Text Watermarking and Data Watermarking techniques. These approaches aim to safeguard content and data ownership, ensuring accountability and traceability in RAG systems.

\paragraph{Generation.}
Watermarking plays a crucial role in ensuring accountability in the outputs of LLMs, with strate-
gies applicable at different stages of the generation process. Pre-generation watermarking involves
embedding watermarks during the training phase, enabling the model to generate content that inher-
ently contains identifiable markers. In-generation watermarking integrates watermarking algorithms
directly into the text generation process, embedding watermarks as the LLM produces text during
inference. This approach ensures that the watermarks are seamlessly woven into the generated output
in real time. Finally, post-generation watermarking applies text watermarking techniques to LLM-
generated content after the text is produced, embedding markers without requiring modifications
to the generation process itself. Each of these methods provides unique advantages, collectively
strengthening the traceability and authenticity of LLM-generated text. We summarize the RAG accountability taxonomy in Table \ref{accountability-taxonomy}.


\subsection{Accountability in Retrieval} 

 \subsubsection{Text Watermarking} \label{8.2.1} Text Watermarking involves embedding identifiable markers into textual content to protect copyright and authenticate ownership of the author \cite{liu2024survey}.  Format-based watermarking algorithms are commonly employed as they only embed watermarks in the text format without altering the author's contents \cite{liu2024survey}. This includes line or word shifting methods  \cite{brassil1995electronic} and unicode-based approaches \cite{por2012unispach,rizzo2016content, sato2023embarrassingly}. Specifically, the former involves adjusting text lines or words vertically and horizontally, effectively used in image-format texts, while the latter usually involves inserting or replacing Unicode codepoints such as whitespace for watermarking. Beyond the above methods, other innovative techniques have emerged, including variation in text color or font \cite{mir2014copyright} and feature embedding, e.g., bookmarks or variables \cite{iqbal2019robust}. While these approaches signify the promise of format-based watermarking in preserving text copyright, we should also be wary of their potential vulnerability to adversary attacks such as removal using canonicalization \cite{boucher2022bad} and watermark forgery due to the detectable pattern in watermarked text formats \cite{liu2024survey}.

\subsubsection{Data Watermarking} \label{8.2.2}
Data Watermarking addresses the increasing need to protect datasets used during the training of machine learning models, ensuring proper attribution and preventing unauthorized usage. A key technique in this area is backdoor watermarking, which embeds ownership information directly into the trained model by introducing trigger—specific input modifications that prompt unique, identifiable behaviors in the model.  

\textit{Trigger-based watermarking} is widely employed due to its flexibility and effectiveness as a type of backdoor watermarking. These triggers can take various forms, including word- or sentence-level modifications~\cite{sun2022coprotector}, semantically invariant transformations in code~\cite{sun2023codemark}, or distinctive input formats designed to be recognizable~\cite{xu2024hufu}. Embedding such triggers ensures that ownership can be verified through the model's behavior, even if the dataset itself is no longer accessible.

While trigger-based watermarking is robust, its effectiveness depends on careful design to ensure triggers remain inconspicuous yet detectable. Additionally, as models become more complex and versatile, challenges such as ensuring trigger persistence and avoiding unintended activations must be addressed. As the field evolves, continued innovation in embedding mechanisms and detection strategies will be essential for robust and scalable dataset protection.



\subsection{Accountability in Generation}

\subsubsection{Pre-generation Watermarking}
Pre-generation watermarking involves embedding watermarks during the training phase of LLMs, creating inherent markers within the model's outputs. This approach can be categorized into trigger-based watermarks and global watermarks.


Trigger-based watermarking has been described in detail in Section \ref{8.2.2}. As a localized method, trigger-based watermarking relies on specific inputs to reveal ownership, which minimizes its impact on regular outputs but may limit its detection capabilities in broad use cases.

On the other hand, global watermarking ensures pervasive traceability across outputs but requires careful design to balance robustness with imperceptibility, ensuring the watermark does not degrade quality or usability of the generated content. \textit{Global watermarking} embeds markers in all generated outputs, enabling consistent content tracking without the need for specific triggers. This approach integrates watermarking directly into the model's parameters, with methods including sampling-based or logit-based watermark distillation~\cite{gu2023learnability} and reinforcement learning with feedback from watermark detectors~\cite{learninglearning}. Global watermarking's broader applicability makes it an attractive option for large-scale deployment, particularly in scenarios where consistent tracking of all outputs is critical.

Together, pre-generation watermarking provides a proactive means of embedding accountability into LLMs. Future research should focus on hybrid approaches that combine the specificity of trigger-based watermarking with the universality of global watermarking, enabling robust, scalable solutions that balance protection and practicality.


\subsubsection{In-generation Watermarking} 

In-generation watermarking directly embeds watermarks as the LLM produces text in the inference time. Unlike pre-generation watermarking, which embeds markers into the model during training, in-generation watermarking dynamically modifies the generated outputs, providing flexibility and adaptability without altering the model parameters. This can be classified into two main methods: watermarking in logit generation and watermarking in token sampling.

 \textit{Watermarking in logit generation} involves modifying the logits during inference. This approach is both versatile and cost-effective, as it avoids the need for model retraining. Typically, KGW \cite{kirchenbauer2023watermark} partitions the vocabulary into distinct categories, such as red and green token lists, using a hash function that depends on the preceding token. The watermark is embedded by biasing the selection of tokens from one category (e.g., green tokens) during text generation. The detection of KGW involves analyzing the proportion of green tokens in the output and computing a z-score to determine whether the text is watermarked, reported with a high detection performance.  However, its performance can degrade in low-entropy contexts, such as code generation, where token probabilities are unevenly distributed. Optimization techniques, such as entropy-based weighting \cite{lu2024entropy} and sliding window methods \cite{kirchenbauer2023reliability}, have been proposed to enhance detectability and robustness in these challenging scenarios.

In addition to modifying logits, in-generation watermarking can be achieved during token sampling on both the token level and sentence level. Token-level sampling introduces watermarks by biasing the random seed or pseudo-random number generator guiding token selection. For instance, Christ et al. \cite{christ2024undetectable} proposed using a fixed random sequence to verify watermarked outputs by aligning tokens with pre-determined patterns. While effective, this method faces challenges related to robustness against text edits. To address these limitations, sentence-level sampling watermarking focuses on semantic-level modifications. Algorithms like SemStamp \cite{hou2023semstamp} partition the semantic space into watermarked and non-watermarked regions, ensuring that entire sentences maintain watermark integrity even after semantic-preserving modifications. This approach enhances robustness against text editing while enabling more meaningful watermark detection at a higher granularity.

In-generation watermarking offers significant advantages, such as its flexibility and adaptability during inference. However, challenges remain, including mitigating the impact on text quality, enhancing robustness against removal attacks, and achieving public verifiability. Techniques such as fine-grained vocabulary partitioning \cite{fernandez2023three} and semantic-aware watermarking \cite{fu2024watermarking} show promise in addressing these issues.
Future research should explore hybrid methods that combine the strengths of logits-based and sampling-based approaches, providing both robustness and adaptability. Additionally, developing standards for evaluating the effectiveness and detectability of in-generation watermarks across diverse applications will be critical for their broader adoption in real-world scenarios.


\subsubsection{Post-generation Watermarking} 
Post-generation watermarking involves embedding watermarks into already-generated text, which can be categorized into four primary methods: Format-based watermarking, lexical-based, syntactic-based, and generation-based watermarking\cite{liu2024survey}.  

Format-based watermarking has already been discussed in  Section \ref{8.2.1}  which displays vulnerability to adversary attacks due to detectable patterns. To address this,  Lexical-based watermarking advances by word substitution without altering the original textual semantics. Techniques often involve synonyms or contextually appropriate replacements. Early methods, such as those using WordNet or Word2Vec \cite{topkara2006hiding,fellbaum1998wordnet, mitchell2023detectgpt}, were limited by their lack of context awareness, which could compromise text quality. Recent advances, like BERT-based infill models\cite{yang2022tracing, yoo-etal-2023-robust}, have improved context sensitivity, enabling more robust and semantically coherent watermarking. These methods enhance resilience against watermarking removal like reformatting, significantly enhancing robustness.

\textit{Syntactic-based watermarking} modifies the grammatical structure of sentences to embed watermarks. This involves transformations such as adjunct movement, clefting, and passivization, \cite{atallah2001natural}, later expanded with activization and topicalization \cite{topkara2006words}. While effective in embedding watermarks, these methods are often language-dependent and may require customization to adhere to grammatical rules. Excessive syntactic changes can also disrupt the original style and fluency of the text \cite{liu2024survey}.  

\textit{Generation-based watermarking} leverages advanced neural network models to directly generate watermarked text from the original content and a watermark message. These approaches, such as AWT \cite{abdelnabi2021adversarial} and REMARK-LLM \cite{zhang2024remark}, utilize transformer-based architectures to embed high-capacity watermarks while maintaining the quality and naturalness of the text. Techniques like WATERFALL \cite{lau2024waterfall} further enhance fluency by using LLMs for paraphrasing, ensuring seamless integration of watermarks. This method offers high detectability, robustness, and scalability, making it a promising solution for embedding watermarks in LLM-generated content.  

\subsection{Accountability in RAG Systems}

While watermarking techniques for retrieval and generation have been extensively studied, most existing research addresses these stages independently. Few approaches tackle the unique challenges of watermarking in RAG systems, which require seamless integration across both retrieval and generation processes. WARD (Watermarking for RAG Dataset Inference) \cite{jovanovic2024ward} stands out as a pioneering method that integrates watermarking across both stages, distinguishing it from traditional approaches that focus solely on one.

WARD bridges the gap between retrieval and generation watermarking by embedding imperceptible signals into datasets during their creation or integration. This ensures traceability throughout both the retrieval and generation stages. Traditional watermarking techniques either track dataset provenance during retrieval or trace outputs during generation but fail to provide a unified solution for RAG systems. WARD's approach ensures that these embedded signals remain detectable even after transformations common in RAG workflows, such as paraphrasing or reformatting. By modifying token probabilities to embed watermarks, WARD offers a robust and unified solution for dataset ownership attribution that is resistant to obfuscation.

A key strength of WARD is its ability to handle complex scenarios that challenge traditional methods, such as fact redundancy where multiple documents contain overlapping or similar information. Watermarking approaches limited to the retrieval stage may fail to detect dataset usage after generative transformations, while those focusing only on the generation stage may overlook the contributions of source datasets. WARD's innovative red-green token-based scheme generates statistically significant signals that persist throughout the entire RAG pipeline. This enables data owners to confidently identify their datasets even when content is blended with other sources or altered during generation.

Furthermore, WARD provides statistical guarantees for watermark detection, significantly reducing false positives and negatives. Techniques such as aggregated queries enhance reliability without compromising computational efficiency, making WARD both scalable and practical for real-world applications. Its ability to handle large-scale datasets and the inherent complexities of RAG systems further sets it apart from traditional watermarking approaches that consider retrieval and generation stages independently.

Overall, WARD represents a significant advancement in watermarking for RAG systems by effectively integrating techniques across both retrieval and generation stages. Its comprehensive approach not only ensures robust dataset ownership attribution but also addresses the limitations of traditional methods that treat these stages separately. As RAG systems become increasingly prevalent, solutions like WARD are essential for protecting intellectual property and ensuring ethical data usage. Future developments may build upon WARD's framework to enhance watermark resilience and adapt to evolving data transformation techniques.


\subsection{Accountability Evaluation}
\subsubsection{Metrics}

Evaluating watermarking techniques for large language models involves a comprehensive framework of metrics, focusing on detectability, quality impact, output performance, output diversity, and robustness \cite{liu2024survey}. These metrics ensure the effectiveness of watermarking systems while minimizing quality degradation and maximizing resilience against attacks.

\textit{Detectability} is a fundamental metric that evaluates the ability to identify the presence of a watermark in text. For zero-bit watermarking, the focus is on determining whether a watermark exists, without recovering specific information. This is typically achieved using statistical methods such as z-scores or p-values, with careful calibration to minimize false positives, as they can misclassify human-generated text. On the other hand, multi-bit watermarking involves extracting encoded information, which is assessed using metrics like Bit Error Rate (BER) \cite{yoo-etal-2023-robust} and bit accuracy\cite{yoo-etal-2024-advancing}. Additionally, watermark size \cite{perkins2023academic}, which refers to the text length required for reliable detection, is critical, with longer texts generally improving detectability at the cost of applicability in shorter content.

  
Watermarking techniques must preserve the quality of the generated text, ensuring that the output remains coherent and natural. Quality metrics are divided into comparative and single-text methods. \textit{Comparative metrics} evaluate differences between watermarked and non-watermarked text, using surface-level measures like BLEU \cite{10.3115/1073083.1073135} and Meteor \cite{alkawaz2016concise} or semantic-level measures like Semantic Score and Entailment Score, which leverage embeddings to capture deeper relationships. \textit{Single-text} metrics, like Perplexity (PPL), focus on the coherence of the watermarked text independently. Lower PPL indicates higher fluency and coherence, while human evaluation remains the gold standard for quality assessment.


\input{tables/accountability_benchmark}

Output performance metrics assess whether the capabilities of watermarked LLMs remain intact across downstream tasks. For text completion, metrics like PPL \cite{yoo-etal-2023-robust}, GPT-4-based scoring \cite{cryptoeprint:2023/1661}, and semantic similarity measures are used to ensure the generated text aligns with prompts. Code generation tasks require precise evaluation using metrics such as CodeBLEU \cite{guan-etal-2024-codeip}, which captures lexical and semantic accuracy, and Edit Sim \cite{tu-etal-2024-waterbench}, which measures the similarity between reference and generated code. Other downstream tasks, including machine translation, summarization, and question answering, are evaluated using standard metrics like BLEU, ROUGE \cite{lin2004rouge}, and task-specific accuracy measures to ensure watermarking does not degrade model utility.


Output \textit{diversity metrics} are essential to evaluate the potential restriction in creativity or variability introduced by watermarking. Metrics like Seq-Rep-N \cite{gu2024on} measure lexical diversity by calculating the ratio of unique n-grams to total n-grams in text. Log Diversity \cite{kirchenbauer2024on} builds on this by quantifying the diversity logarithmically across different n-grams. Additionally, entropy-based metrics such as Ent-3 \cite{hou-etal-2024-semstamp} and Sem-Ent \cite{han-etal-2022-measuring} provide insights into lexical and semantic diversity, respectively. Higher entropy scores indicate greater diversity, ensuring that the watermarking process does not overly constrain model outputs.

Robustness evaluates the ability of watermarked systems to resist adversarial attacks, which can be classified into untargeted attacks and targeted attacks. For details, see Section \ref{sec:robustness} Robustness.

\subsubsection{Datasets}


According to various metrics discussed above, several benchmarks and toolkits have been developed to standardize the evaluation of text watermarking techniques in large language models (LLMs), including WaterBench \cite{tu-etal-2024-waterbench}, WaterJudge \cite{molenda2024waterjudge}, Mark My Words \cite{piet2023mark}, and MarkLLM \cite{pan2024markllm}. The details about each dataset can be viewed in Table \ref{tab-acc}.


\subsection{Future Direction of RAG Accountability}

\paragraph{Unifying Retrieval and Generation Watermarking.} 

Currently, retrieval and generation watermarking techniques operate independently within RAG systems, leaving gaps in overall accountability. Future research should develop unified frameworks that seamlessly integrate both methods. By embedding traceability throughout the entire RAG pipeline, these frameworks would enhance intellectual property protection, ensure responsible attribution, and maintain data and model integrity in complex AI systems where retrieval and generation increasingly overlap.

\paragraph{Dynamic Watermarking for Adaptive AI.}
As generative AI systems evolve to adapt to real-time inputs and changing user contexts, static watermarking becomes insufficient. Developing dynamic watermarking techniques that adjust to system updates, counter adversarial attacks, and respond to shifts in model behavior is crucial. These adaptive methods would enhance robustness and maintain traceability in RAG architectures, supporting accountability in ever-changing AI environments.

\paragraph{Governance and Ethical Integration.}

Besides technical innovation, alignment with legal and ethical frameworks is essential. Future efforts should foster collaborations among technologists, policymakers, and ethicists to establish governance models that incorporate watermarking as a foundational tool for AI accountability and intellectual property protection. Such interdisciplinary work would ensure that RAG systems adhere to global ethical standards and legal requirements.