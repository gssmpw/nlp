\section{Appendix}

\subsection{Memory Allocators}
\label{sec:memory-allocators}

We now discuss a few memory allocators, which support the design of our graph representation.

\input{src/alg-faa}


\subsubsection{Fixed Arena Allocator (FAA)}
\label{sec:faa}

We now discuss the Fixed-capacity Arena Allocator (FAA), outlined in Algorithm \ref{alg:faa}, which provides a lightweight, efficient memory allocation strategy for scenarios requiring frequent allocations and deallocations within a fixed memory budget. FAA minimizes fragmentation by recycling memory blocks and allows for rapid reset operations, making it well-suited for high-performance applications. It operates through three primary functions: \texttt{allocate()}, \texttt{deallocate()}, and \texttt{reset()}.

The allocator is instantiated with a predefined allocation size $\textsc{alloc\_size}_a$ and a total pool size $\textsc{pool\_size}_a$ (lines \ref{alg:faa--init-const-begin}-\ref{alg:faa--init-const-end}). The allocator maintains an internal memory pool $pool$, a counter $used$ tracking the number of allocated bytes, and a list $freed$ to store deallocated memory chunks for reuse (lines \ref{alg:faa--init-begin}-\ref{alg:faa--init-end}). Memory allocation is handled by the \texttt{allocate()} function. First, if any previously freed memory blocks exist in $freed$, one is retrieved and returned (line \ref{alg:faa--allocate-freed}). Otherwise, allocation proceeds from the main memory pool. If there is available space in the pool (i.e., $used < \textsc{pool\_size}$), the function assigns a pointer to the next available block, updates the $used$ counter, and returns the pointer (lines \ref{alg:faa--allocate-pool-begin}-\ref{alg:faa--allocate-pool-end}). If the pool is exhausted, the function returns a null pointer $\phi$, indicating allocation failure (line \ref{alg:faa--allocate-phi}). The \texttt{deallocate()} function allows memory to be freed by pushing the given pointer into the $freed$ list, making it available for future reuse (line \ref{alg:faa--deallocate-push}). To completely reset the allocator, the \texttt{reset()} function clears the $freed$ list and resets the $used$ counter to zero, effectively deallocating everything (lines \ref{alg:faa--reset-begin}-\ref{alg:faa--reset-end}).


\subsubsection{Variable-capacity Arena Allocator (AA)}
\label{sec:aa}

Unlike the Fixed-capacity Arena Allocator (FAA), the variable-capacity Arena Allocator (AA) does not have a fixed memory budget. Instead, it dynamically allocates additional pools as needed using \texttt{new[]} from the C++ standard library. Its pseudocode is shown in Algorithm \ref{alg:aa} and, like the FAA, it operates through three primary functions: \texttt{allocate()}, \texttt{deallocate()}, and \texttt{reset()}.

\input{src/alg-aa}

As with FAA, the allocator $AA$ is initialized with a predefined allocation size $\textsc{alloc\_size}_a$ and memory pool size $\textsc{pool\_size}_a$ (lines \ref{alg:faa--init-const-begin}-\ref{alg:faa--init-const-end}). Additionally, it maintains a list of reusable freed allocations $freed$, tracks the number of used bytes in the most recent pool $used$, and stores references to all allocated pools in $pools$ (lines \ref{alg:aa--init-begin}-\ref{alg:aa--init-end}). Memory allocation, handled by \texttt{allocate()}, follows a three-step process. \textbf{(1)} If freed allocations are available, they are reused (line \ref{alg:faa--allocate-freed}) to minimize new allocations. \textbf{(2)} If space remains in the last allocated pool, the next block is assigned, and the used counter updates accordingly (lines \ref{alg:faa--allocate-pool-begin}-\ref{alg:faa--allocate-pool-end}). \textbf{(3)} If neither condition holds, a new pool of size $\textsc{pool\_size}$ is allocated. If successful, it is added to $pools$, and allocation proceeds (lines \ref{alg:aa--allocate-new-begin}-\ref{alg:aa--allocate-new-end}); otherwise, the function returns $\phi$ to signal failure (line \ref{alg:aa--allocate-fail}). The \texttt{deallocate()} function, as earlier, allows memory to be freed by pushing freed pointers onto the $freed$ list for reuse (line \ref{alg:aa--deallocate-push}). To reset the allocator, \texttt{reset()} clears the $freed$ list, resets the $used$ counter, and releases all allocated $pools$ back to the standard library (lines \ref{alg:aa--reset-freedused-begin}-\ref{alg:aa--reset-pools-end}).


\subsubsection{Power-of-2 size Arena Allocator (P2AA)}
\label{sec:p2aa}

Unlike the AA allocator, which only supports allocating memory blocks of a fixed size, the Power-of-2 Arena Allocator (P2AA) allows arbitrary allocation sizes, specializing in handling memory allocations that are powers of two --- similar to a slab allocator \cite{bonwick1994slab}. The pseudocode for P2AA allocator is shown in Algorithm \ref{alg:p2aa}, and it builds upon the AA allocator by maintaining separate AA sub-allocators for each power-of-2 size, from $16$ bytes to $8192$ bytes. The $8192$-byte limit is chosen empirically for optimal performance.

\input{src/alg-p2aa}

At initialization, the allocator $P2AA$ is configured with a predefined memory pool size $\textsc{pool\_size}_a$ (line \ref{alg:p2aa--init-const}). It creates multiple AA sub-allocators, each responsible for a different power-of-2 allocation size, ranging from $16$ to $8192$ bytes (lines \ref{alg:p2aa--init-begin}-\ref{alg:p2aa--init-end}). Memory allocation is performed in the \texttt{allocate()} function. When a request for a standard power-of-2 size is made (e.g., $16$, $32$, or $8192$ bytes), the request is routed to corresponding AA sub-allocator handles the request (lines \ref{alg:p2aa--allocate-pow2-begin}-\ref{alg:p2aa--allocate-pow2-end}). For sizes larger than $8192$ bytes or non-power-of-2 sizes, a direct memory allocation is performed instead (line \ref{alg:p2aa--allocate-other}). Deallocation mirrors the allocation strategy. Each deallocation request, made through \texttt{deallocate()}, is dispatched to the corresponding sub-allocator, if it is a power-of-two, and ranges from $16$ to $8192$ bytes in size (lines \ref{alg:p2aa--deallocate-pow2-begin}-\ref{alg:p2aa--deallocate-pow2-end}). For other sizes, memory is freed directly using \texttt{delete[]} (line \ref{alg:p2aa--deallocate-other}). Note that, unlike \texttt{delete[]}, the user is expected to provide the size of the allocated memory. To reset all allocated memory, the \texttt{reset()} function (lines \ref{alg:p2aa--reset-begin}-\ref{alg:p2aa--reset-end}) resets each individual arena allocator. This effectively clears all memory pools, making the allocator ready for fresh allocations without explicitly deallocating each individual allocation. Finally, the \texttt{allocationSize()} function provides a mechanism for determining the optimal allocation size for a given request. If the request is $16$ bytes or smaller, it returns $16$ (line \ref{alg:p2aa--allocationsize-16}). If the request is between $17$ and $8191$ bytes, it rounds up to the next power of two using \texttt{nextPow2()} (line \ref{alg:p2aa--allocationsize-8192}). For larger requests, it rounds up to the nearest multiple of the system page size (line \ref{alg:p2aa--allocationsize-other}). This ensures that large memory allocations are page-aligned.


\subsubsection{Concurrent Power-of-2 Arena Allocator (CP2AA)}
\label{sec:cp2aa}

We now discuss our thread-safe Concurrent Power-of-2 Arena Allocator (CP2AA), which builds upon per-thread instances of the Power-of-2 Arena Allocator (P2AA). Its pseudocode is presented in Algorithm \ref{alg:cp2aa}. As above, CP2AA consists of four primary functions: \texttt{allocate()}, \texttt{deallocate()}, \texttt{reset()}, and \texttt{allocationSize()}.

\input{src/alg-cp2aa}

The $CP2AA$ allocator is initialized with a fixed memory pool size $\textsc{pool\_size}_a$ (line \ref{alg:cp2aa--init-const}), and maintains a separate instance of P2AA per thread, stored in $p2aa_T$ (line \ref{alg:cp2aa--init}) --- while ensuring that each P2AA allocator is well-separated in memory to prevent false sharing. Each thread exclusively interacts with its corresponding P2AA instance, eliminating the need for locks or atomic operations altogether. The \texttt{allocate()} function assigns memory in a thread-local manner. Given a requested size, it identifies the current thread $t$ and delegates the allocation to its corresponding P2AA instance, $p2aa_T[t]$ (lines \ref{alg:cp2aa--allocate-begin}-\ref{alg:cp2aa--allocate-end}). Similarly, \texttt{deallocate()} retrieves the current thread $t$ and forwards the deallocation request to the P2AA allocator of the current thread (lines \ref{alg:cp2aa--deallocate-begin}-\ref{alg:cp2aa--deallocate-end}). Note that it is acceptable for a thread to deallocate memory allocated by another thread. In fact, this lack of restriction is a key source of performance improvement. The \texttt{reset()} function deallocates all of the allocated memory by iterating over all per-thread allocators and calling their respective reset functions (lines \ref{alg:cp2aa--reset-begin}-\ref{alg:cp2aa--reset-end}). Finally, the \texttt{allocationSize()} function determines the appropriate power-of-2 allocation size for a given request by forwarding the query to P2AA (line \ref{alg:cp2aa--allocationsize}).

\ignore{Our initial attempt at a concurrent arena allocator used an atomic\_flag mutex to manage freed blocks, but high contention resulted in slow deallocation, especially with 64 threads.}


\subsubsection{Performance Comparison}

\input{src/fig-allocator-runtime}

To evaluate the performance of different memory allocators, we conduct three separate experiments, each designed to measure execution time under specific memory management workloads. The allocators tested include the C library allocator (\texttt{malloc()}/\texttt{free()}), the C++ runtime allocator (\texttt{new[]}/\texttt{delete[]}), the Fixed Arena Allocator (FAA), the variable-capacity Arena Allocator (AA), and the Concurrent Power-of-2 Arena Allocator (CP2AA). In the first experiment, we measure the performance of each allocator in an allocation-heavy scenario. Here, each allocator is subject to a total of $2^{28}$ memory allocations, each of size $64$ bytes. With non-concurrent allocators, i.e., FAA and AA, separate allocator objects are created for each thread to ensure thread safety, and the workload is distributed evenly across all threads. The allocated memory addresses are stored in an array to ensure they can be deallocated in the subsequent experiment. In the second experiment, we evaluate the deallocation performance of each allocator. Using the memory addresses obtained from the first experiment, each allocator is tasked with deallocating $2^{28}$ blocks of memory. Deallocations are routed to the appropriate allocator object for each thread in the case of FAA and AA. The third experiment examines allocator performance in a mixed workload, where allocation and deallocation operations occur in succession. Specifically, each allocator is tested with $2^{22}$ allocations followed by $2^{22}$ deallocations, with this cycle being repeated $64$ times. This experiment provides insight into the performance of each allocator under workloads that mimic real-world application behavior.

Figure \ref{fig:allocator-alloc--runtime} presents the relative runtime of each allocator for the allocation-only workload, while Figure \ref{fig:allocator-free--runtime} shows the deallocation-only workload. Finally, Figure \ref{fig:allocator-mixed--runtime} illustrates the performance of each allocator under the mixed workload. The results indicate that specialized allocators like FAA, AA, and CP2AA offer substantial performance improvements over general-purpose allocators (\texttt{malloc()}/\texttt{new[]}), particularly in allocation-intensive workloads, and offer around $4\times$ speedup in mixed workloads. While the AA allocator performs the best, on average, it is not thread-safe and thus not suitable for concurrent applications. The CP2AA allocator, which is both thread-safe and high-performing, is suitable.



\subsection{Evaluating Graph Representations via Graph Algorithm Performance}

As dicusssed earlier, we evaluate the performance of various graph representations on a representative algorithm by measuring the efficiency of $k$-step reverse walks from each vertex in the given input graph, and counting the number of walks ending at each vertex. This corresponds to computing $A_T^k \cdot \vec{1}$, where $A_T$ is the transposed adjacency matrix and $\vec{1}$ is a ones vector. Reverse walks are preferred as they can be executed directly on the input graph, whereas forward walks require its transpose. The results of this evaluation on each graph representation, i.e., PetGraph, SuiteSparse:GraphBLAS, cuGraph, Aspen, and our DiGraph, are discussed in Section \ref{sec:perform-reverse-walks}.

We now give a short description of the algorithm. It propagates visit counts backward along graph edges, and its psuedocode is given in Algorithm \ref{alg:visit}. Here, the \texttt{reverseWalk()} function, takes a graph $G$ and the number of reverse walk $steps$ as input. Initially, two arrays, $visits0$ and $visits1$, are allocated to track visit counts, with $visits0$ set to $1$ for all vertices and $visits1$ initialized to $0$ (lines \ref{alg:visit--init-begin}-\ref{alg:visit--init-end}). The main loop iterates $steps$ times, processing all vertices $u$ in parallel. Each iteration resets $visits1[u]$ (line \ref{alg:visit--reset}) and accumulates the visit count from each neighbor $v$ of $u$ (lines \ref{alg:visit--edges-begin}-\ref{alg:visit--edges-end}). This iterative process propagates visit counts backward through the graph. At the end of each iteration, the visit count arrays are swapped (line \ref{alg:visit--swap}), ensuring $visits0$ contains the latest counts. After the final iteration, $visits0$ contains the number of reverse walks ending at each vertex\ignore{in the graph, and is returned}.

\input{src/alg-visit}
