\subsection{Our Graph Representation}
\label{sec:digraph}

Our directed graph implementation, \textbf{DiGraph}, which leverages our Concurrent Power-of-2 Arena Allocator (CP2AA) for efficient memory management (see Section \ref{sec:cp2aa} for details), is described in Algorithms \ref{alg:digraph1} and \ref{alg:digraph2}. The implementation supports operations for inserting and deleting a batch of edges, where a batch of edges is represented using \texttt{DiGraph}. Thus, insertion of a batch of edges corresponds to a graph union operation, while deletion of a batch of edges corresponds to a graph subtraction operation.

The initialization of a \texttt{DiGraph} (lines \ref{alg:digraph--struct-begin}-\ref{alg:digraph--struct-end}) involves setting up four main data structures: \textbf{(1)} A bit array, $exists$, to track vertex existence; \textbf{(2)} An adjacency list, $edges$, to store outgoing edges; \textbf{(3)} An array, $degrees$, to track each vertex's out-degree; and \textbf{(4)} An array, $capacities$, to manage allocated edge storage per vertex. Memory allocation is handled by the CP2AA allocator, $cp2aa$. Additionally, the initialization defines key variables: reserved memory ($RES$), vertex capacity ($CAP$, the maximum vertex ID + 1), total vertices ($N$), and total edges ($M$). Configured constants include $\textsc{bool\_bits}$, which inidicates the granularity of vertex existence flags, and $\textsc{edge\_size}$, which represents the size of an edge in bytes.

The function \texttt{hasVertex()} (lines \ref{alg:digraph--has-vertex-begin}-\ref{alg:digraph--has-vertex-end}) of \texttt{DiGraph} checks whe-ther a given vertex exists in the graph by verifying if its ID falls within the allocated range ($CAP$) and whether the corresponding bit in $exists$ is set. The function \texttt{degree()} (lines \ref{alg:digraph--degree-begin}-\ref{alg:digraph--degree-end}) returns the number of outgoing edges for a vertex, defaulting to zero if the vertex is not within range. The \texttt{edges()} function (lines \ref{alg:digraph--edges-begin}-\ref{alg:digraph--edges-end}) retrieves the outgoing edges of a vertex, returning an empty set if the vertex does not exist.
%
The \texttt{reserve()} function (lines \ref{alg:digraph--reserve-begin}-\ref{alg:digraph--reserve-end}) ensures that sufficient space is allocated to accommodate new vertices. It first calculates a new reserved size by rounding up to the system's page size. If the requested capacity is greater than the current vertex capacity $CAP$, memory is reallocated (in parallel) using the \texttt{reallocate()} function (lines \ref{alg:digraph--reallocate-begin}-\ref{alg:digraph--reallocate-end}), which adjusts the size of multiple arrays, including $exists$ (bit array), $edges$, $degrees$, and $capacities$. Finally, the the graph’s vertex capacity $CAP$ and the reserved memory size $RES$ are updated.
%
The \texttt{reallocate()} function (lines \ref{alg:digraph--reallocate-begin}–\ref{alg:digraph--reallocate-end}) is responsible for resizing memory allocations while preserving existing data where possible. It first checks if the requested reserved amount $R\_1$ matches the current reserved amount $R\_0$. If they are equal, no new allocation is needed, and only the newly added portion of the array (from $N\_0$ to $N\_1$) is initialized to zero in parallel. Otherwise, new memory is allocated for $R\_1$ entries, and the existing data is copied up to the minimum of the old and new sizes ($M = min(N\_0, N\_1)$). Any remaining entries in the newly allocated space (from $M$ to $N\_1$) are initialized to zero in parallel. Once the data transfer is complete, the old memory is deallocated, and the newly allocated pointer is returned.

The \texttt{addVertex()} function (lines \ref{alg:digraph--add-vertex-begin}-\ref{alg:digraph--add-vertex-end}) ensures that a vertex exists by expanding storage if necessary and then setting its existence flag. 
%
The function \texttt{allocateEdges()} (lines \ref{alg:digraph--allocate-edges-begin}-\ref{alg:digraph--allocate-edges-end}) is responsible for allocating memory for a vertex’s outgoing edges using the CP2AA allocator. It first checks whether the vertex ID $u$ exceeds the current capacity ($CAP$) or if memory for its edges has already been allocated. If either condition is met, the function returns immediately. Otherwise, it determines the required memory size in bytes by multiplying the desired number of edges ($deg$) by $\textsc{edge\_size}$, which represents the storage size of an edge (a tuple of a destination vertex and an edge weight). The computed memory requirement is then passed to the CP2AA allocator's \texttt{allocationSize()} function, which adjusts the requested size to make it a power-of-2 size (in bytes), or a multiple of system page size. The function then allocates the necessary amount of memory (in bytes) using $cp2aa.allocate()$, stores the resulting pointer in $edges[u]$, and updates $capacities[u]$ to reflect the allocated number of edges.

Adding an edge without additional safety checks is handled by \texttt{addEdgeUnsafe()} (lines \ref{alg:digraph--add-edge-unsafe-begin}-\ref{alg:digraph--add-edge-unsafe-end}), which retrieves the pointer to the edge list $edges[u]$, increments the degree counter $degrees[u]$ atomically, and inserts the new edge.
%
The \texttt{addEdges()} function (lines \ref{alg:digraph--add-edges-begin}-\ref{alg:digraph--add-edges-end}) is responsible for adding a list of outgoing edges to a vertex while ensuring proper memory allocation. If the vertex does not exist or the provided edge list is empty, the function returns immediately. First, it records the current degree of the vertex ($deg\_prev$) and calculates the maximum possible degree after adding the new edges ($deg\_max$). It then determines the required memory allocation size using the CP2AA allocator and allocates a new memory block for storing the updated edge list. The function merges the existing edges with the new edges using the \texttt{setUnion()} operation, ensuring they are stored in the allocated memory. Note that edges in the list must be sorted. Once the new edges are successfully added, the function deallocates the previously allocated memory using CP2AA, updates the edge pointer, and records the new edge capacity. Finally, it returns the number of newly added edges by computing the difference between the updated and previous degrees.
%
The \texttt{removeEdges()} function (lines \ref{alg:digraph--remove-edges-begin}-\ref{alg:digraph--remove-edges-end}) is responsible for removing a specified list of outgoing edges from a given vertex. First, it checks whether the vertex exists in the graph using \texttt{hasVertex()} and whether the provided edge list is non-empty. If either condition is not met, the function returns immediately with a value of zero. Otherwise, it records the current out-degree of the vertex in $deg\_prev$. The function then performs a set difference operation to remove the specified edges from the vertex’s adjacency list, effectively updating the edge count. Finally, it returns the number of edges removed, calculated as the difference between the original degree and the updated degree of the vertex.

Finally, the \texttt{update()} function (lines \ref{alg:digraph--update-begin}-\ref{alg:digraph--update-end}) ensures the integrity of the graph by sorting and deduplicating edges while updating the total vertex and edge counts. First, if the edges are not already sorted, each vertex's edge list is sorted in parallel using the \texttt{sortByKey()} function. Next, if duplicate edges exist, they are removed via \texttt{uniqueByKey()}, also executed in parallel. After enforcing order and uniqueness, the function recalculates the total number of vertices, $N$, and edges, $M$, by iterating over all possible vertex IDs up to the current capacity, $CAP$.\ignore{If a vertex is marked as existing, its count is incremented, and its degree contributes to the total edge count.}

\input{src/alg-digraph1}
\input{src/alg-digraph2}


\subsubsection{Loading a Graph from Disk}
\label{sec:load}

We now describe our algorithm for loading a graph from a Matrix Market (MTX) format file as a Compressed Sparse Row (CSR) representation. The algorithm is presented in Algorithm \ref{alg:load}, and is an improvement upon GVEL\ignore{, our previous work} \cite{sahu2023gvel}. In the algorithm, the function \texttt{loadGraph()} takes as input an MTX-formatted string, which is essentially the memory-mapped data of and MTX file, and outputs the graph $G$ in CSR format.

In the algorithm, we first initialize an empty graph structure $G$ (line \ref{alg:load--init}). We then read the MTX file header using the \texttt{readHeader()} function (line \ref{alg:load--read-header}), which indicates graph properties, such as whether the graph is symmetric, the number of rows and columns $N$, and the total number of edges $M$. If the graph is symmetric, the number of edges $M$ is doubled to account for bidirectional connections. The output CSR graph $G$ is resized accordingly to accommodate the required storage space (line \ref{alg:load--resize}).
%
Next, we allocate space for storing edge data in parallel (lines \ref{alg:load--alloc-edges-begin}-\ref{alg:load--alloc-edges-end}). Each thread is responsible for allocating memory for $source$ and $target$ vertices, and $weights$, if the graph is weighted. The collection of allocated edge lists is stored in the variable $edges$ (line \ref{alg:load--edges}). Next, space is allocated for per-partition degree counts $pdegrees$ and per-partition CSRs $pcsr$, which includes per-partition offsets, edge keys, and edge values (lines \ref{alg:load--alloc-pdegrees-pcsr-begin}-\ref{alg:load--alloc-pdegrees-pcsr-end}). The first partition ($p=0$) is mapped directly to the primary degree and CSR arrays of $G$. For subsequent partitions ($p \in [1, \rho)$), where $\rho$ is the number of partitions, space is allocated separately. If the graph is weighted, additional memory is assigned for storing edge weights. Each partition, the degree array is initialized to zero to prepare for counting.

After setting up the necessary data structures, we read the edge list and processes it into CSR format (line \ref{alg:load--read-edgelist}-\ref{alg:load--convert-to-csr}). The function \texttt{readEdgelist()} populates the per-thread edges and per-partition degree counts, while \texttt{convertToCsr()} converts this data into a CSR representation. For this, \texttt{convertToCsr()} utilizes $\rho$ per-partition CSRs ($pcsr$) as intermediates, in order to generate the global CSR $G$. If the graph is symmetric, the $G$ is resized (line \ref{alg:load--resize-symmetric}). Finally, we return the constructed CSR graph $G$ (line \ref{alg:load--return}).

\input{src/alg-load}

We now discuss the psuedocode of the \texttt{readEdgelist()} function, which is described in Algorithm \ref{alg:load-el}. \texttt{readEdgelist()} takes as input the per-partition vertex degrees, $pdegrees$; an output structure for storing edges, $edges$; and the memory-mapped file data, $data$. The function processes the edgelist in parallel, in blocks of size $\beta$. The parsed edges are populated, and the number of edges read per thread is tracked using $counts$, which is returned.

In the function, we begin by initializing the count of edges processed per thread and extracting the per-thread sources, targets, and weights of edges (lines \ref{alg:el--initialize-begin}-\ref{alg:el--initialize-end}). Next, edges are loaded from the file in blocks of size $\beta$, ensuring efficient reading of large files (lines \ref{alg:el--blocks-begin}-\ref{alg:el--blocks-end}). Each thread processes a specific range of the input file, determined by its index in steps of $\beta$. The function \texttt{getBlock()} extracts the corresponding block from the memory-mapped file (line \ref{alg:el--get-block}). Within each block, edges are read sequentially (lines \ref{alg:el--block-begin}-\ref{alg:el--block-end}). Each edge consists of a pair of vertex identifiers $(u, v)$, with an optional weight $w$ if the graph is weighted (lines \ref{alg:el--parse-edge-begin}-\ref{alg:el--parse-edge-end}). The edge data is parsed by first locating the next numeric digit in the file, extracting the integer values for $u$ and $v$, and, if applicable, parsing a floating-point weight. The vertex identifiers are then converted to zero-based indexing (line \ref{alg:el--base1}). Once an edge is parsed, it is added to the corresponding thread's edge list (lines \ref{alg:el--add-edge-begin}-\ref{alg:el--add-edge-end}). Additionally, the per-partition vertex degree counter is updated atomically to reflect the addition of the edge (line \ref{alg:el--update-degrees}). If the graph is symmetric, the reverse edge $(v, u)$ is also stored, ensuring undirected connectivity is maintained (lines \ref{alg:el--reverse-edge-begin}-\ref{alg:el--reverse-edge-end}). After processing all edges in a block, the count of edges processed by each thread is updated (line \ref{alg:el--update-counts}). Once all blocks are processed, we return the total number of edges read per thread\ignore{(line \ref{alg:el--return-counts})}.

The \texttt{getBlock()} function ensures that each thread correctly extracts a contiguous chunk of the file while respecting line boundaries (lines \ref{alg:el--get-block-begin}-\ref{alg:el--get-block-end}). It first determines the starting position $b$ and the endpoint $B$ of the block within the file. If the starting position is within a partially read line, it adjusts $b$ to the beginning of the next line. Similarly, if the endpoint $B$ is within a partially read line, it extends $B$ to include the full line. The function then returns the adjusted block boundaries $[b, B]$, ensuring that each thread reads a well-formed subset of the edgelist.

\input{src/alg-load-el}

Next, we discuss the pseudocode of the \texttt{convertToCsr()} function, which is given in Algorithm \ref{alg:load-csr}. \texttt{convertToCsr()} takes as input the per-partition compressed sparse row (CSR) structure, $pcsr$; per-partition vertex degrees, $pdegrees$; the per-thread edge lists containing sources, targets, and weights of edges, $edges$; and the number of edges read per thread, $counts$. Our goal is to efficiently convert the per-thread edgelists into a partitioned CSR representation and then merge these partitioned CSRs into a final global CSR. By partitioning the CSR construction, we minimize contention when updating global data structures, significantly improving performance compared to a direct global CSR construction.

We begin by extracting the key components of the per-partition CSR: offsets ($poffsets$), edge destinations ($pedgeKeys$), and edge weights ($pedgeValues$) (lines \ref{alg:csr--initialize-begin}-\ref{alg:csr--initialize-end}). Additionally, we retrieve the per-thread sources, targets, and weights of edges. Next, we compute the global degree of each vertex and store it in $degrees[0]$. This step is essential because we use partition $0$ as the base for the final CSR, ensuring that its offsets are correctly initialized. Although we construct the CSR in four partitions ($0$ to $\rho-1$), partition $0$ is already properly set up, allowing us to merge only the remaining three partitions into it (lines \ref{alg:csr--initialize-end}-\ref{alg:csr--poffsets-begin}).
%
To construct the per-partition CSR efficiently, we compute shifted offsets for each partition (lines \ref{alg:csr--poffsets-begin}-\ref{alg:csr--poffsets-end}). This optimization ensures that offsets can be used directly as indices for inserting edges into the CSR. Once the CSR is populated, the shifted offsets will automatically reflect the final correct offsets without requiring additional post-processing steps, which used to be necessary in older approaches such as GVEL \cite{sahu2023gvel}. This avoids an extra pass over the data to adjust the offsets.

We then populate the per-partition CSR in parallel (lines \ref{alg:csr--pcsr-begin}-\ref{alg:csr--pcsr-end}). Each thread processes its assigned edges and determines which partition they belong to. For each edge $(u, v)$, we atomically increment the corresponding offset and store $v$ in $pedgeKeys$. If the graph is weighted, we also store the corresponding weight in $pedgeValues$. Partitioning the CSR generation in this manner significantly reduces contention on atomic operations, as each partition is updated independently by different sets of threads.
%
After constructing the per-partition CSRs, we merge them into a single CSR (lines \ref{alg:csr--pcsr-combine-begin}-\ref{alg:csr--pcsr-combine-end}). Since partition $0$ is already structured correctly, we only need to merge partitions $1$ to $\rho-1$ into it. This process iterates over all vertices and sequentially appends their edges from partitions $1$ to $\rho-1$ into partition $0$. As edges are copied, we maintain an index $j$ to track the insertion position in the merged CSR. If the graph is weighted, we also copy the corresponding weights. Finally, we update the offsets in partition $0$ to reflect the total number of edges per vertex, completing the global CSR construction, and return the total number of edges in the CSR, $M$.

This algorithm differs from the one used in GVEL \cite{sahu2023gvel} in several key ways. First, we compute the global degree of each vertex in $degrees[0]$ to prepare partition $0$ as the final CSR, reducing the complexity of the merging step. Second, we use shifted offsets during CSR initialization, eliminating the need for a post-processing step to fix offsets after populating the CSR.

\input{src/alg-load-csr}


\subsubsection{Cloning a Graph}
\label{sec:clone}

The \texttt{cloneGraph()} function we use for (parallel) cloning of our graph representation is shown in Algorithm \ref{alg:clone}. It takes an input graph $G$, and returns the cloned graph $G'$.

The method begins by initializing an empty graph $G'$ (line \ref{alg:clone--init}). To optimize memory allocation, we preallocate storage for vertices based on the maximum vertex ID in $G$ (line \ref{alg:clone--reserve-vertices}). Next, all vertices from $G$ are added to $G'$ in parallel (lines \ref{alg:clone--add-vertices-begin}-\ref{alg:clone--add-vertices-end}), ensuring that all nodes from $G$ are present in $G'$ before edges are processed. Following this, we reserve space for edges by preallocating memory for each vertex’s adjacency list (lines \ref{alg:clone--reserve-edges-begin}-\ref{alg:clone--reserve-edges-end}). Once vertices are inserted, we preallocate edge storage for each vertex $u$ in parallel, setting aside space based on its degree in $G$ (lines \ref{alg:clone--populate-edges-begin}-\ref{alg:clone--populate-edges-end}). Next, the edges linked to vertex $u \in V$, and its associated degree are directly copied from the original graph. Finally, we update the total vertex and edge counts in $G'$. If $G$ is stored in Compressed Sparse Row (CSR) format, a specialized \texttt{update()} function is called to additionally sort the edges of each vertex in the graph by ID (line \ref{alg:clone--update-counts-csr}) --- this is done to ensure that edge additions and insertions can be done in $O(d_u + \Delta d_u)$ time, where $d_u$ is the degree of vertex $u$, and $\Delta d_u$ is the number of edges removed are being added to the vertex. Otherwise, the vertex and edge counts are explicitly set (line \ref{alg:clone--update-counts-noncsr}). The cloned graph $G'$, which is a deep-copy of $G$, is returned in line \ref{alg:clone--return}.

\input{src/alg-clone}


\subsubsection{Performing Edge Deletions}
\label{sec:sub}

We now discuss our graph subtraction algorithms, which remove the edges of a graph $G_S$ from another graph $G$, effectively applying a batch edge deletions $E_S$ to $G$. The pseudocode is provided in Algorithm \ref{alg:sub}. Algorithm \ref{alg:sub} includes two functions: \textbf{(1)} \texttt{subtractGraphInplace()} modifies $G$ directly, removing edges in $G_S$ from $G$. \textbf{(2)} \texttt{subtractGraph()} returns a new graph $G'$ such that $G' = G \setminus G_S$ --- it is more efficient than simply cloning $G$, and then performing the graph subtraction in-place.

In \texttt{subtractGraphInplace()}, we initialize the count of removed edges, $\Delta M$, to zero. Next, we iterate over all vertices in $G_S$ in parallel (line \ref{alg:sub--inplace-for-begin}). If a vertex $u$ from $G_S$ is not present in $G$, it is skipped (line \ref{alg:sub--inplace-check}). Otherwise, we remove the edges of $u$ that are present in $G_S$ from $G$, updating $\Delta M$ accordingly (line \ref{alg:sub--inplace-remove}). Once all relevant edges have been deleted, the total edge count of $G$ is updated (line \ref{alg:sub--inplace-update-edges}), and the modified graph is returned (line \ref{alg:sub--inplace-return}). This function operates in-place, meaning the original graph $G$ is directly modified.

The \texttt{subtractGraph()} function constructs a new graph $G'$ instead of modifying $G$ directly. First, an empty graph $G'$ is initialized, and $\Delta M$ is set to zero (line \ref{alg:sub--init}). To ensure efficient memory allocation, we reserve space for the vertices in $G'$ (line \ref{alg:sub--reserve-vertices}). The vertices of $G$ are then added to $G'$ in parallel (lines \ref{alg:sub--add-vertices-begin}-\ref{alg:sub--add-vertices-end}). Similarly, memory is allocated for the edges of each vertex, based on its degree in $G$ (lines \ref{alg:sub--alloc-edges-begin}-\ref{alg:sub--alloc-edges-end}). The edge copying process is performed in two steps. First, for vertices that are not present in $G_S$, all edges from $G$ are copied directly into $G'$ (lines \ref{alg:sub--copy-untouched-begin}-\ref{alg:sub--copy-untouched-end}). This ensures that the structure of these vertices remains unchanged. Next, for vertices that do exist in $G_S$, we remove the edges that appear in $G_S$, keeping only those that are not part of $G_S$ (lines \ref{alg:sub--copy-touched-begin}-\ref{alg:sub--copy-touched-end}). The degree of each vertex is updated accordingly, and $\Delta M$ is incremented based on the number of removed edges. Finally, the vertex and edge counts for $G'$ are updated (line \ref{alg:sub--update-counts}), and the new graph $G'$ is returned (line \ref{alg:sub--return}).

\input{src/alg-sub}


\subsubsection{Performing Edge Insertions}
\label{sec:add}

Next, we describe our graph union algorithms, detailed in Algorithm \ref{alg:add}, which merges the edges of a graph $G_A$ into another graph $G$, effectively applying a batch of edge insertions $E_A$ to $G$. This done either by modifying $G$ in place (in the \texttt{addGraphInplace()} function), or by generating a new output graph $G'$ (in the \texttt{addGraph()} function).

In the first function, \texttt{addGraphInplace()}, we modify $G$ directly. Initially, the counters $\Delta N$ and $\Delta M$ are set to zero, representing the number of new vertices and edges added, respectively (line \ref{alg:add--inplace-init}). We then allocate space for vertices by reserving memory for $max(\text{vertex ID in } G, \text{vertex ID in } G_A) + 1$\ignore{(line \ref{alg:add--inplace-reserve})}. Next, new vertices from $G_A$ that are not already in $G$ are added in parallel, updating $\Delta N$ accordingly (lines \ref{alg:add--add-vertices-begin}-\ref{alg:add--add-vertices-end}). After this, edges from $G_A$ are inserted into $G$ in-place (lines \ref{alg:add--inplace-add-edges-begin}-\ref{alg:add--inplace-add-edges-end}), using the \texttt{G.addEdges()} function detailed in Algorithm \ref{alg:digraph2}, and the count of newly added edges is accumulated in $\Delta M$. Finally, the vertex and edge counts of $G$ are updated to reflect the additions (line \ref{alg:add--inplace-update}), and the modified graph $G$ is returned\ignore{(line \ref{alg:add--inplace-return})}.

The second function, \texttt{addGraph()}, constructs a new graph $G'$ containing the union of graphs $G$ and $G_A$. The function starts by initializing $G'$ as an empty graph and setting $\Delta N$ and $\Delta M$ to zero (line \ref{alg:add--init}). Similar to the in-place version, we allocate space for vertices (line \ref{alg:add--reserve}) and then iterate through the vertex range to add vertices from $G$ and $G_A$, tracking the count of new additions in $\Delta N$ (lines \ref{alg:add--add-vertices-begin}-\ref{alg:add--add-vertices-end}). After reserving memory for edges (lines \ref{alg:add--reserve-edges-begin}-\ref{alg:add--reserve-edges-end}), we proceed to populate $G'$ with edges. First, we copy edges for vertices that exist only in $G$ (lines \ref{alg:add--add-edges-untouched-begin}-\ref{alg:add--add-edges-untouched-end}). Then, for vertices present in both $G$ and $G_A$, we merge their edge sets and update the degree count (lines \ref{alg:add--add-edges-touched-begin}-\ref{alg:add--add-edges-touched-end}). The total number of newly added edges is accumulated in $\Delta M$. Finally, the vertex and edge counts for $G'$ are updated (line \ref{alg:add--update}), and the new graph is returned (line \ref{alg:add--return}).

\input{src/alg-add}








% %% DISCUSS WHAT WE NEED FOR FAST DYNAMIC GRAPHS
% Let's think what a graph would require. Concurrent allocators of various sizes.

% - Quickly free and allocate a new memory block. It also better be multi-level.
% - Ensure that vertex access is efficient, by using SoA vectors.
% - Ensure that edge weights are stored in a separate array.
% - Delay merging of edges into a single array, until the graph is finalized.
% - Select a different merging startegy, based on the number of edges inserted / deleted.
% - Perform a fast deletion of edges, i.e., deletions come first.

% Interesting to see the runtime split of duplicateIfOmpW(), which is used to convert the graph from CSR to DiGraph. Reserving space for the graph, and for the edges appear to be the largest bottlenecks, followed by updateOmpU().

% Arena-based digraph is now working. The double-free issue was due to using a single allocator across all threads. Another issue we faced was the failure to populate the edges, resulting in abrupt program crash. This was due to using \_\_builtin\_clz() for computing capacity of the slots, but \_\_builtin\_clz() only works for 32-bit integer, not size\_t. Below are the results after fixing.

% Comparison begins:
% - output-graph-openmp--approach-csr-graph-no-sort.log: Upto 2KB are handled by arena allocator (with a capacity of 8 * 64KB), remaining are managed by libc.
% - output-graph-openmp--approach-duplicate-8192.log: Upto 8KB are handled by arena allocator (with a capacity of 10 * 512KB), remaining are managed by libc. We also try to minimize the memory being held by the arena allocators. Tested on sk-2005 graph. Best config seems to be using up to 8KB arena allocators, with capacity of each allocator being 512KB.

% BTW, why is resizing the arrays for vertices too slow, particularly for kmer graphs?

% Continuing:
% - output-graph-openmp--approach-duplicate-8192-custom-arrays.log: Upto 8KB are handled by arena allocator (with a capacity of 10 * 512KB), remaining are managed by libc. Now we are managing the vertex arrays on our own, so we can initialize them in parallel. The improved locality of the variables seems to be improving the performance of add-edges as well. vector.resize() is sequential and is a bottleneck for graphs with a large number of vertices (such as k-mer graphs).
% - output-graph-openmp--measure-sort-time.log: It seems choosing a suitable chunk size has a significant impact on sorting edges.
% - output-graph-openmp--adjust-sort-method.log: Dynamic schedule with task (deg > 2048) seems best.
% - puzzlef/graph-openmp--measure-duplicate-split: Below is the phase split of duplicate graph (arena allocator-based).
% - output-graph-openmp--adjust-add-subtract-chunk-size.log: Measuring runtime with various chunk size for add and subtract graph operations.
% - output-graph-openmp--adjust-batch-fraction.log: Results with varying batch fraction.


% %% ON GRAPH LOADING
% A crash issue was observed while trying to load a graph in MTX format as CSR. This was related to improperly setting up CSR lists (before passing it to the reading function). In addition, I managed to optimize the CSR generation phase by by using the first partition CSR as the target CSR with sufficient space (adjust \texttt{degrees[0]} accordingly), and eliminating the need to fix offsets, by using shifted offsets instead. TODO: Make a figure for this.


% %% ON MEMORY ALLOCATORS
% The \texttt{FixedArenaAllocator} is fairly straightforward. It simply consists of a fixed size memory pool, a number indicating the number of bytes used in the memory pool, and a list of freed allocations, which can be reused. The allocator is created by providing the address of the memory pool, the capacity of the memory pool, and the size of each allocation (each allocation must be of the same size). The \texttt{allocate()} function allocates from the free list, popping a memory address from the freed list, if available. If not, it allocates from the memory pool, updating the used bytes. The \texttt{deallocate()} function simply pushes the provided memory address into the freed list. Finally, a \texttt{reset()} function simply sets the used bytes to $0$, and clears the freed list. The psuedocode for this is given in Algorithm X.


% % A failed attempt.
% We next consider implementing a concurrent arena allocator, which given a memory pool, returns allocated memory of fixed size memory blocks. It also maintains a list of freed memory blocks, and any new requests are serviced from the freed blocks. However, in order to be thread-safe, i.e., to support memory allocation calls from multiple threads concurrently, we are using a \texttt{atomic\_flag} which is used as a mutex to limit access to the freed list to one thread at a time only. In order to ensure that no thread has to wait for too long, we check if the \textit{flag} is set to \textit{busy}, and if so, we go ahead an return a block from the pool (which uses an atomic add). However, it is also possible that we have no free space in the pool. In such a case, we repeatedly retry acquiring the mutex (\textit{yield}ing the current thread on failure and retrying), and once obtained, fetch a memory block from the freed list. For freeing a memory block, however, we just do repeated retries to access the freed list, and then, once acquired, append the memory block to the freed list.

% When (several) allocations are being performed sequentially, the concurrent arena allocator is observed to have around $2\times$ the performance of \texttt{malloc()} and \texttt{free()}. However, when allocations are done in parallel using 64 thread, the results look quite different. The concurrent arena allocator has around the same performance as \texttt{malloc()}, while the deallocate of the concurrent memory allocator is too slow. Thus, it appears that there is high contention in our concurrent arena allocator. We could try using per-thread freed lists to resolve this. But then, we might have to implement some stealing mechanism in order to fetch memory blocks that have been freed by other threads. We might as well use \textit{libc} \texttt{malloc()} instead - particularly for large size memory allocations.

% In fact, we have another recursive arena allocator which utilizes multiple pools to allocate smaller memory blocks to requesting thread, and is not thread-safe (for one thread only). A suitable way, then, might be to use \texttt{malloc()} for large allocations, and revert to per-thread recursive arena allocator for smaller allocations - we may now called it multi arena allocator instead.


% % Continue dicusssion
% We use a pool size of $512$KB.

% Per-thread allocators are well-separated in memory to avoid false sharing.

% Sequential arena-allocator is fast, and an arena allocator with growing pool is also fast. If each thread has its own allocator, then performance is great. An interesting thing to note here is that \texttt{new[]} is quite fast, but not \texttt{malloc()}. Also, weird why \texttt{FixedArenaAllocator.deallocate()} is slow, both arena allocators reserve the same amount of memory for freed list.

% Another interesting workload, here we allocate and free memory repeatedly (in chunks). In all cases, however, the workload consists of $2^{28}$ allocations and deallocations, each of size $64$ bytes. Here, both \texttt{malloc()} and \texttt{new[]} have similar performance, and interestingly \texttt{ArenaAllocator} is quite fast.

% Now we have a concurrent pow-2 allocator.

% TODO: Make a figure for this.


% %% ON MEMORY MANAGEMENT IN GRAPH DATASTRUCTURE
