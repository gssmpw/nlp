

\subsection{CATE with Pre-Treatment Covariates} 
The primary challenge addressed here is handling confounding that arises out of biased treatment assignment in observational datasets.
The main ideas explored include: estimating pseudo-outcomes for missing treatments in the training dataset and then using these to train effect predictors~\citep{Gao2020, inducbias, rlearner, drlearner, ganite, overlapping_rep, giks};  adding targeted regularizers to ensure consistent ITE estimates~\citep{dragonnet, vcnet, TransTEE}; learning balanced representation of covariates across treatment groups~\citep{Tarnet, cfrnet, replearning_ite, chauhan2023adversarial, escfr, stablecfr}; matching to near-by covariates~\citep{matching_survey,  prop_score_matching, coarsened_exact_matching, perfect_match, deepmatch, pairnet}; and weighing losses to mitigate confounding~\citep{ctr_importance, disentangled_ite, weighted_factual, weighted_factual_2}.  

\subsection{CATE with Post-Treatment Covariates} 
This is our setting, and is more challenging because it falls into the third rung (counterfactual) of Pearl's causal ladder~\citep{pearlbook}. Please refer~\citep{post_cf_proof} \begingroup
\tmlr
to
\endgroup
for a formal proof.
In economics, post-treatment variables in trials are known to exacerbate estimated causal effects~\citep{post_trial_1, post_trial_2, post_trial_3}. Post-treatment variables have been used to estimate selection bias $P(T|Z)$ in observational data~\citep{post_selbias_1, post_selbias_2, sel_bias_3}. A closely related work  is~\citep{huang2023extracting} that leverages post-treatment variables for estimating treatment effects but differs from us since they assume: (1) covariates $X$ causally affect $Y$, and (2) an entangled version of $X, Z$ is observed; they simply focus on disentangling $Z$ through representation learning. 

