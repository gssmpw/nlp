

%%%%%%%%%%%%%
\section{Learning Causal Representations for CATE}

\label{sec:theory}
Our task involves learning four functions: $\RInvhat_t$ that extracts the causal representations from $X(t)$ and $\realmuhat_t$ that estimates the outcomes $Y(t)$ for $t \in \set{0,1}$. With access to \textit{counterfactual simulated} data $\synD$ and \textit{observational real} data $\trnD$, one can come up with the following approaches for estimating CATE: 1) \simonly, which only uses $\synD$, and
2) \realonly\, which only uses $\trnD$ to estimate $\realmu_t$,
\textit{(3)} \muonly, which uses $\synD$ to estimate $\RInv_t$ and subsequently, $\trnD$ to estimate $\realmu_t$. We now discuss the training approach for each of these methods, delve into their shortcomings, and then present our proposed method \our. 


To illustrate the shortcomings, we consider a test instance $\xb^\star$ generated under treatment $T=1$ (without loss of generality) and derive the CATE error expression for it in the population setting, as $|\trnD| \rightarrow \infty$ and $|\synD| \rightarrow \infty$.

% , \textit{(4)} \our, our proposed estimator, which uses both $\synD$ and $\trnD$.  

\input{theory_genbounds_baselines}


\subsection{The \our\ Estimator}
\label{sec:simponet}

We first conduct a theoretical analysis to derive a generalization bound that characterizes the CATE error as a function of the mismatch between the real and simulator distributions. This analysis forms the basis for our proposed method, \our, whose loss function is inspired by the bound.

\begin{filecontents*}{lemmasimponetbound.tex}
Assume $\tau$ is $K_{\tau}$-Lipschitz, and $\SInvTilde$ and $\syntauTilde$ are estimates from the simulator DGP obtained from the optimization in Eq. \ref{eq:cont_loss}, \ref{eq:syntautilde}. Then, the CATE error on the estimates $\RInvhat_t$ and $\tauhat$ admits the following bound: 
    \begin{align*}
      \ErrITE^t(\RInvhat_t, \tauhat)  \leq [8\ErrF^t + 12d_{h}(\tauhat, \syntauTilde) + 12 K_{\tau}^2 \,d_{\xb|t}(\RInvhat_t,\SInvTilde_t)] + \textcolor{blue}{[12 d_z(\tau, \syntau) + 12 K_{\tau}^2 \,d_{\xb|t}(\RInv_t,\SInv_t)]}
\end{align*}
 where $d_{\xb|t}, d_z, d_{h(z)}$ are distance functions in Sec.~\ref{sec:problem_formulation} and $\ErrF^t$ is the factual loss.\end{filecontents*}
\begin{lemma}
\label{lemma:simponetbound}
\input{lemmasimponetbound}
 [Proof in Appendix~\ref{app:lemma:simponetbound}.]
\end{lemma}
The expressions in \textcolor{blue}{blue} are constants that capture the discrepancy between real and simulated distributions and cannot be minimized. In contrast, the remaining terms can be minimized by training on $\trnD$ and $\synD$. As $|\trnD|$ approaches infinity, the factual error $\ErrF^t$ can be made to approach zero, while the other minimizable distance terms act as regularizers. The term $d_{h}(\tauhat, \syntauTilde)$ can assist in regularizing the outcome parameters $\realmuhat_t$, whereas $d_{\xb|t}(\RInvhat_t, \SInvTilde_t)$ can aid in regularizing the parameters of the causal representation extractor functions $\RInvhat_t$. This analysis leads to our proposed approach \our\ whose overall loss is as follows:



\begin{equation}
\label{eq:overall_objective}
\resizebox{\textwidth}{!}{%
  $\begin{aligned}
    \min_{\{\realmuhat_t, \RInvhat_t\}} 
     & {\underbrace{%
        \sum_{\trnD}\left(y_i - \realmuhat_{t_i}(\RInvhat_{t_i}(\xb_i))\right)^2
        }_{\text{Factual Loss on $\trnD$}}}  + 
     {\underbrace{%
          \Lphi \sum_{\trnD} \Vert \SInvCont_{t_i}(\xb_i) - \RInvhat_{t_i}(\xb_i) \Vert_2^2
        }_{d(\SInvCont_t, \RInvhat_t) \text{ regularizer}}}  +
     {\underbrace{%
        \Ltau \sum_{\synD} \sum_{t \in \{0,1\}}
        \left(\tau^S_i -  \widehat{\tau}(\SInvCont_{t}(\xb_i^S(t))) \right)^2
        }_{
        \tau^S \text{ regularizer on }\synD
        }} 
    \end{aligned}$ 
    }
\end{equation}
where $\tau^S_i = y_i^S(1) - y_i^S(0)$ and $\Ltau, \Lphi > 0$ are loss weights. $\widehat{\tau}(\bullet) = \realmuhat_1(\bullet) - \realmuhat_0(\bullet)$ denotes the estimated CATE.

\our\ relaxes the strict equality $\RInvhat_t = \SInvTilde_t$ used by \muonly, and instead uses $\SInvTilde_t$ as a regularizer, while ensuring that $\realmuhat_t$ accurately predicts the factual outcomes for instances in $\trnD$. It also imposes the $\syntau$ loss on simulated instances to leverage any potential similarity between the true treatment effect, $\tau$, and the simulated treatment effect, $\syntau$. Furthermore, the $\tau^S$ loss is essential to prevent degenerate solutions that would cause \our\ to collapse to the \muonly\ estimator. 
% Note that $\ITEx = \tau \circ \RInv_t$ has two degrees of freedom in $\tau$ and $\RInv_t$. 
This is because applying regularization solely on $\RInvhat_t$ can drive the regularizer $||\RInvhat_t(\xb) - \SInvTilde_t(\xb)||_2^2$ to zero, leading to $\RInvhat_t = \SInvTilde_t$, while still minimizing the factual error $\ErrF^t$ by updating $\realmuhat_t$ accordingly. Consequently, \our\ would collapse into the \muonly\ estimator, making the $\tau^S$ loss critical in avoiding such degeneracies.


\xhdr{Adjusting Loss Weights} \our\ adjusts the loss weight $\Lphi$ for learning $\RInvhat_t$ by comparing the \textit{factual errors} of the \realonly\ model, which trains on $X$, with those of the \muonly\ model, trained using simulated causal representations $\SInvCont_t(\xb)$. If \realonly\ consistently outperforms \muonly\ in factual error, we infer that the simulated representations may not generalize well to the real distribution, prompting \our\ to reduce $\Lphi$. By default, $\Lphi$ is set to $1$; however, if \muonly\ exhibits a notably higher factual error, \our\ lowers $\Lphi$ to $10^{-4}$.


In contrast, tuning $\Ltau$ requires $\tau$ supervision on real data, which is unavailable. Prior work~\citep{inducbias, pairnet, xlearner} argue that while outcome functions $\realmu_t$ can be complex, the difference function $\tau = \realmu_1 - \realmu_0$ is often simpler. For instance, if we consider $\realmu^S_t = \realmu_t + c$ (with $c > 0$), we can make the factual outcomes to diverge arbitrarily while their corresponding $\tau$ and $\tau^S$ remain equal. Therefore, while comparing the factual errors between \simonly\ and \realonly\ models to set $\Ltau$ is appealing, it maybe a poor choice in practice. So, \our\ always sets $\Ltau$ to its default $1$.
% We can view \our\ as a multi-task model where it predicts $\tau, \tau^S$ and an adequately parameterized neural network can handle both tasks. \todo{What if there is -ve interference?}


We present the \our's pseudocode in Appendix \ref{app:pcode}.
