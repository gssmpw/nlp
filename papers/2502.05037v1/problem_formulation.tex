
\section{Problem Formulation}
\label{sec:problem_formulation}
\vspace{-0.3cm}
We use  random variables $X, T, Y$ to denote post-treatment covariates, binary treatments, and outcomes respectively. The observational dataset has $n$ samples: $\trnD = \{(\xb_i, t_i, y_i)\}_{i=1}^n$ where $t_i \in \Tspace = \{0, 1\}$ denotes treatment, $\xb_i \in \xspace \subset \RR^{n_x}$ denotes covariates observed after $t_i$ is applied, and $y_i$ the resulting outcome. We use the Neyman-Rubin potential outcomes framework to denote $Y_i(t), X_i(t)$ as the potential outcome and covariate for unit $i$ under a treatment $t$. The main challenge is the absence of counterfactuals in $\trnD$, i.e., for each unit $i$, we observe covariates and outcomes under only one treatment $t_i$.

We use the random variable $Z \in \Zspace \subset \RR^{n_z}$ to denote the causal representations of covariates $X$. $Z$ generates $X$ via treatment-specific covariate generating functions $\R_t: \Zspace \mapsto \xspace$ for $t\in \{0,1\}$. We assume that $\R_t$ is diffeomorphic~\citep{locatello2019challenging, locatello2019disentangling, von2021self}; i.e., it is smooth, invertible, and has a smooth inverse. The assumption that $\R_t$ is diffeomorphic is required to establish the theoretical identifiability of $\tau$. A non-invertible transformation risks losing information when mapping $Z, T$ to $X$. If this lost information includes features necessary for identifiability, then $\tau$ becomes unidentifiable from the observed $X, T, Y$. Diffeomorphism ensures that all factors involved in generating $X$ are preserved within $X$ so that there exists inverse functions $\RInv_t: \xspace \mapsto \Zspace,\; \forall t \in \{0, 1\}$ that could recover the causal representations $Z$ back.  
In Sec.~\ref{app:mlp_expts}, we experiment with non-invertible transformations and find that both the baselines and \our\ maintain robust performance, even when these assumptions are violated in practice.


A sample is obtained from the real DGP as follows: (1) $z_i \sim P_Z$, (2) $t_i \sim P(T|z_i)$, (3) $\xb_i \sim P(X|z_i, t_i) = \delta(X - \R_{t_i}(z_i))$, where $\delta$ denotes the dirac-delta distribution, (4) $y_i \sim P(Y|z_i, t_i) = \mathcal{N}(\realmu_{t_i}(z_i), \sigma_y^2)$ is sampled from a Gaussian with mean $\realmu_{t_i}(z_i)$ and constant variance $\sigma_y^2$. Here, $\realmu_t : \Zspace \mapsto \yspace \;\;\forall t$ generates responses for individuals with latent representations $z$ under treatment $t$. 
We express the {\em factual} observed outcome for $i$ as $Y_i(t_i) = \realmu_{t_i}(\RInv_{t_i}(\xb_i))$, and the missing {\em counterfactual} (CF) outcome under $1-t_i$ as $Y_i(1-t_i) = \realmu_{1-t_i}(\RInv_{t_i}(\xb_i))$.

\textbf{Our Goal} is Conditional Average Treatment Effect (CATE) estimation which quantifies the difference in outcomes due to a change in treatment. Given a test unit $(\xb_j, t_j)$, its CATE is given by $\tau_j = \EE[Y_j(T=1) - Y_j(T=0) | \xb_j, t_j]$. As argued earlier, estimating $\tau$ from post-treatment data involves the sub goal of learning causal representations of observed covariates $X$ using a function $\RInv_t: X \mapsto Z$. We use $\tau : \Zspace \mapsto \yspace$ to express the treatment effect using the latent $z_j$ as $\tau(z_j) = \mu_1(z_j) - \mu_0(z_j)$. Since $\RInv_t$ inverts $X$ to give $Z$, the same effect can also be expressed for $(\xb_j, t_j)$ using $\ITEx$ as $\ITEx(\xb_j, t_j) = \mu_1(\RInv_{t_j}(\xb_j)) - \mu_0(\RInv_{t_j}(\xb_j))$ where $\ITEx: \xspace \times \Tspace \mapsto \yspace$. Notice that $\ITEx(\bullet, t) = \tau \circ \RInv_t(\bullet)$.
When estimating $\ITEx$, the factual outcome is easy, all we need to do is fit a regression model on the observation data.  The main challenge lies in estimating the counterfactual outcome under treatment $1-t_j$.

Theorem 1 in~\citep{locatello2019challenging} presents an impossibility result stating that $\RInv_t$ which maps covariates $X$ to their treatment-independent causal representations $Z$ is {\em not} identifiable solely using $\trnD$. The main hurdle is that multiple DGPs can yield the same marginal distribution $P(X, T)$, making it impossible to isolate the true DGP. However, prior work has shown how to learn $\RInv_t$ with \textit{counterfactuals}, requiring that $\trnD$ includes both covariates $X_i(t_i)$ and $X_i(1 - t_i)$. Theorem 4.4 of~\citep{von2021self} shows that such counterfactual supervision allows for recovery of $Z$ up to a diffeomorphic transformation $h$ using contrastive learning. Proposition 2 in~\citep{zimmermann2021cl} further shows that $h$ is, in particular, a rotation in an $n_z$ dimensional unit-normalized hypersphere. While some prior works assume direct access to counterfactual supervision in real data~\citep{nagalapatti2022learning, contrast_3}, others rely on high-quality synthetic counterfactuals from simulators~\citep{Simglucose2018, self_driving_cars}. In contrast, our approach seeks to leverage simulators only to the extent that they improve the downstream CATE task. We next formally define the simulator's data generating process.
% , i.e. we recover $\hat{Z} = h(Z)$. 
% However, acquiring counterfactual covariates poses challenges in real-life, and therefore we propose leveraging simulators.

\textbf{Simulator DGP} 
% Since counterfactuals are not available in real data, we seek to leverage a 
The simulator generates paired instances giving rise to a counterfactual dataset $\synD = \{\xb_i^S(0), \xb_i^S(1), y_i^S(0), y_i^S(1)\}$ generated using the DGP as shown in the lower panel in Figure~\ref{fig:our_DGP}. The simulated instances are obtained as follows: (1) $z_i \sim P_Z$; i.e., $Z$ is sampled from the same distribution as real, (2) post-treatment covariates $\xb_i^S(t) \sim P(X^S|Z = z_i, T = t) = \delta(X^S - \S_t(z_i))$ under \emph{both} treatments $t=\{0,1\}$. 
% i.e. similar to the real DGP, $X^S$ is a deterministic function of $(Z, T)$, 
$\S_t: \Zspace \mapsto \xspace\;\; \forall t$ are diffeomorphic functions, and (3) corresponding outcomes $y_i^S(0)$, $y_i^S(1)$ are sampled from $P(Y^S|Z = z_i, T = t) = \mathcal{N}(\synmu_t(z_i), \sigma_{y^S}^2)$, where $\synmu_t: \Zspace \mapsto \yspace,\; \forall t$. Note that $z_i$ remains hidden even in $\synD$. 
% We can see that simulator functions $\S$ and $\synmu$ correspond to the functions $\R$ and $\realmu$ respectively for observational data. 
We use ``$S$'' in the superscript to indicate a simulator component.  
Now we describe some metrics that assess the distance between real and simulator DGP.


% \todo[inline]{P: Remove the comments and add them later}
\textbf{\hypertarget{def:dxt}{Definition 1}} [$d_{\xb|t}(\RInv_t,\SInv_t)$] 
% Let  $P(X = \xb | T = t)$ be the distribution induced by the function $\R_t$ on $Z$. 
We assess the distance between the real and synthetic causal representation extractors $\RInv_t$ and $\SInv_t$ using the following expected distance:
$
    d_{\xb|t}(\RInv_t,\SInv_t) = \EE_{\xb \sim P(X|t)}\left[||\RInv_t(\xb) - \SInv_t(\xb)||_{2}^{2}\right]
$.
% 
\textbf{\hypertarget{def:dz}{Definition 2}} [$d_{z}(\tau, \syntau)$] We assess the distance between the real and simulator CATE functions on the $P_Z$ distribution as:
$
    d_{z}(\tau, \tau^S) = \EE_{z \sim P_Z}\left[(\tau(z)- \syntau(z))^2\right]
$.
% 
Under composition with a diffeomorphic function $h$, we write $d_{h}(\tau, \syntau) = \EE_{z \sim P_Z}\left[(\tau(h(z))- \syntau(h(z)))^2\right]$.


\xhdr{Assumptions for Identifying CATE $\ITEx$} 
We summarise the assumptions that are needed on the real dataset $\trnD$ and simulated counterfactual dataset $\synD$ to identify the CATE function $\ITEx$:
\begin{enumerate*}%[leftmargin=0.2cm, itemsep=0pt]
    % \item[(A1)] \textit{Consistency:} Observed outcome $y_i$ matches the potential outcome for assigned treatment $Y_i(t_i)$    
    \item[(A1)] \textit{Positivity:} $P(T=t| Z=z) > 0, \;\; \forall t  \in \Tspace, z \in \Zspace$.
    \item[(A2)] \textit{Diffeomorphic Covariate Generation:} Covariates in both real and synthetic distributions are obtained through diffeomorphic transformations of $Z$ under any treatment $T$.
    \item[(A3)] \textit{Identifiability of $\tau$ given $Z$:}  The causal factors $Z$ that generate $X$ form a sufficient adjustment set, blocking backdoor paths between $T$ and $Y$, thus making $\tau$ identifiable from $Z$. 
\end{enumerate*}
% \todo{revisit A3 after resolving causal reps vs latent factors}
%
%\textit{Remark: } 
Note that A2 and A3 together ensure that $X$ contains information about all the relevant latent factors that affect the outcome $Y$ and 
% corresponds to
is a weaker notion of 
the commonly used \textit{unconfoundedness} assumption.


\xhdr{CATE Error ($\ErrITE$)}
Given a test dataset $\tstD = \{(\xb_j, t_j, y_j(0), y_j(1))\}_{j=1}^m$, with each $\xb_j$ rendered under $t_j$, we compute the empirical error incurred in estimating CATE using mean squared error as
$
    \ErrITE = \frac{1}{m}\sum_{j \in \tstD} [\tau_j - \tauhat_j]^2  \label{eq:ite_error}   
$
where $\tau_j = y_j(1) - y_j(0)$ is the true effect and $\tauhat_j$ is the predicted effect for the instance $(\xb_j, t_j)$.  

The CATE error in general can be decomposed across treatment $T$ as
$$
    \ErrITE 
    = \sum_{t \in \Tspace} P(T=t) ~ \ErrITE^t~~
    \text{where }\ErrITE^t = \int_{\xb \in \xspace} [\ITEx(\xb, t) - \ITExhat(\xb, t)]^2 P(\xb|t)d\xb
$$

\xhdr{Definition 3} Let us define \textit{factual} error $\ErrF^t$ and \textit{counterfactual} error $\ErrCF^t$ on samples with observed treatment $t$ and missing treatment $1- t$ as follows:
\begin{align*}
    \ErrF^t = \int_{\xb \in \xspace} [\realmu_t(\RInv_t(\xb)) - \realmuhat_t(\RInvhat_t(\xb))]^2 P(\xb|t)d\xb \text{ and }
    \ErrCF^t = \int_{\xb \in \xspace} [\realmu_{1-t}(\RInv_t(\xb)) - \realmuhat_{1-t}(\RInvhat_t(\xb))]^2 P(\xb|t)d\xb
\end{align*}
%
\newcommand{\lemmaitedecompose}{The CATE error is related to the factual and counterfactual error as:
    % \begin{align*}
    $
        \ErrITE^t \leq 2 \ErrF^t + 2\ErrCF^t
    $}
\begin{lemma}
\label{lemma:ite_decompose}
    \lemmaitedecompose\
    % \end{align*}
    [Proof in Appendix~\ref{app:lemma:ite_decompose}]
\end{lemma}

% All symbols are summarised in Appendix~\ref{app:symbols} for convenience.
