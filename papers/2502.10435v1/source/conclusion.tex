\vspace{-0.5em}
\section{Conclusion}
In this paper, we proposed {RAMer}, a framework that refines multi-modal representations using reconstruction-based adversarial learning to address the Multi-party Multi-modal Multi-label Emotion Recognition problem. RAMer captures both the commonality and specificity across modalities using an adversarial learning module, with reconstruction and contrastive learning enhancing its ability to differentiate emotion labels, even with missing data. We also introduce a personality auxiliary task to complement incomplete modalities, improving emotion reasoning through modality-level attention. Furthermore, the stack shuffle strategy enriches the feature space and strengthens correlations between labels and modalities.
Extensive experiments on three datasets demonstrate that RAMer consistently outperforms state-of-the-art methods in both dyadic and multi-party MMER scenarios.

