%%%% ijcai25.tex

\typeout{IJCAI--25 Instructions for Authors}

% These are the instructions for authors for IJCAI-25.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}

\usepackage{bm}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{subcaption}
\let\Bbbk\relax
\usepackage{amssymb}
\usepackage{balance}

% Comment out this line in the camera-ready submission
% \linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
% \newtheorem{example}{Example}
% \newtheorem{theorem}{Theorem}

\newcommand{\stab}{\vspace{1.2ex}\noindent}
\newcommand{\sstab}{\rule{0pt}{8pt}\\[-2.2ex]}
\newcommand{\stitle}[1]{\sstab\noindent{\bf #1}}
\newcommand{\etitle}[1]{\vspace{1mm}\noindent{\underline{\em #1}}}
\newcommand{\ie}{{\em i.e.,}\xspace}
\newcommand{\eg}{{\em e.g.,}\xspace}
\newcommand{\wrt}{\emph{w.r.t.}\xspace}
\newcommand{\aka}{\emph{a.k.a.}\xspace}



% Single author syntax
% \author{
%     Anonymous Author(s)
%     % Author Name
%     % \affiliations
%     % Affiliation
%     % \emails
%     % email@example.com
% }

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% \iffalse
\author{
Xudong Yang$^1$
\and
Yizhang Zhu$^1$\and
Nan Tang$^{1,2}$\And
Yuyu Luo$^{1,2}$\\
\affiliations
\small{$^1$The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China} \\
\small{$^2$The Hong Kong University of Science and Technology, Hong Kong SAR, China} \\
% $^3$Third Affiliation\\
% $^4$Fourth Affiliation\\
\emails
\small{sootungyoung@gmail.com,
yzhu305@connect.hkust-gz.edu.cn
\{nantang, yuyuluo\}@hkust-gz.edu.cn}
}
% \fi

\begin{document}

\title{RAMer: Reconstruction-based Adversarial Model for Multi-party Multi-modal Multi-label Emotion Recognition}

\maketitle

\begin{abstract}
Conventional Multi-modal multi-label emotion recognition (MMER) from videos typically assumes full availability of visual, textual, and acoustic modalities. However, real-world \textit{multi-party} settings often violate this assumption, as non-speakers frequently lack acoustic and textual inputs, leading to a significant degradation in model performance. Existing approaches also tend to unify heterogeneous modalities into a single representation, overlooking each modalityâ€™s unique characteristics.
To address these challenges, we propose \textbf{RAMer} (\textbf{R}econstruction-based \textbf{A}dversarial \textbf{M}odel for \textbf{E}motion \textbf{R}ecognition), which leverages adversarial learning to refine multi-modal representations by exploring both modality commonality and specificity through reconstructed features enhanced by contrastive learning. \textbf{RAMer} also introduces a personality auxiliary task to complement missing modalities using modality-level attention, improving emotion reasoning. To further strengthen the model's ability to capture label and modality interdependency, we propose a stack shuffle strategy to enrich correlations between labels and modality-specific features.
Experiments on three benchmarks, i.e., MEmoR, CMU-MOSEI, and $M^3$ED, demonstrate that \textbf{RAMer} achieves state-of-the-art performance in dyadic and multi-party MMER scenarios. The code will be publicly available at https://github.com/Sootung/RAMer
\end{abstract}


\input{source/introduction}
\input{source/related_work}
\input{source/methodology}
\input{source/experimets}
\input{source/conclusion}

\clearpage

\bibliographystyle{named}
\bibliography{references}
\clearpage

\end{document}

