# A
@article{Ahilan2019,
  title={Feudal multi-agent hierarchies for cooperative reinforcement learning},
  author={Ahilan, Sanjeevan and Dayan, Peter},
  journal={arXiv preprint arXiv:1901.08492},
  year={2019}
}


# B
@inproceedings{Bacon2017,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={31},
  number={1},
  year={2017}
}

@article{Bank2023,
  title={Autoencoders},
  author={Bank, Dor and Koenigstein, Noam and Giryes, Raja},
  journal={Machine learning for data science handbook: data mining and knowledge discovery handbook},
  pages={353--374},
  year={2023},
  publisher={Springer}
}


@inproceedings{Banijamali2018,
  title={Robust locally-linear controllable embedding},
  author={Banijamali, Ershad and Shu, Rui and Bui, Hung and Ghodsi, Ali and others},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1751--1759},
  year={2018},
  organization={PMLR}
}

@inproceedings{Bettini2022,
  title={Vmas: A vectorized multi-agent simulator for collective robot learning},
  author={Bettini, Matteo and Kortvelesy, Ryan and Blumenkamp, Jan and Prorok, Amanda},
  booktitle={International Symposium on Distributed Autonomous Robotic Systems},
  pages={42--56},
  year={2022},
  organization={Springer}
}


@article{Bettini2024,
  author  = {Matteo Bettini and Amanda Prorok and Vincent Moens},
  title   = {BenchMARL: Benchmarking Multi-Agent Reinforcement Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2024},
  volume  = {25},
  number  = {217},
  pages   = {1--10},
  url     = {http://jmlr.org/papers/v25/23-1612.html}
}

@article{Berliac2019,
author = {Flet-Berliac, Yannis},
title = {The Promise of Hierarchical Reinforcement Learning},
journal = {The Gradient},
year = {2019},
howpublished = {\url{https://thegradient.pub/the-promise-of-hierarchical-reinforcement-learning/ } },
}

@article{Brockman2016,
  title={OpenAI Gym},
  author={Brockman, G},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}


# C
@article{Cassano2020,
  title={Multiagent fully decentralized value function learning with linear convergence rates},
  author={Cassano, Lucas and Yuan, Kun and Sayed, Ali H},
  journal={IEEE Transactions on Automatic Control},
  volume={66},
  number={4},
  pages={1497--1512},
  year={2020},
  publisher={IEEE}
}


# D
@article{De2020,
  title={Is independent learning all you need in the starcraft multi-agent challenge?},
  author={De Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2011.09533},
  year={2020}
}

@article{Dayan1992,
  title={Feudal reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={5},
  year={1992}
}




# F
@article{Foerster2016,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and De Freitas, Nando and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

# H
@inproceedings{Haarnoja2018,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}


@article{Hu2021,
  title={Rethinking the implementation tricks and monotonicity constraint in cooperative multi-agent reinforcement learning},
  author={Hu, Jian and Jiang, Siyang and Harding, Seth Austin and Wu, Haibin and Liao, Shih-wei},
  journal={arXiv preprint arXiv:2102.03479},
  year={2021}
}

@article{Hu2023,
  title={Uncertainty-aware hierarchical reinforcement learning for long-horizon tasks},
  author={Hu, Wenning and Wang, Hongbin and He, Ming and Wang, Nianbin},
  journal={Applied Intelligence},
  volume={53},
  number={23},
  pages={28555--28569},
  year={2023},
  publisher={Springer}
}


@article{Hutsebaut2022,
  title={Hierarchical reinforcement learning: A survey and open research challenges},
  author={Hutsebaut-Buysse, Matthias and Mets, Kevin and Latr{\'e}, Steven},
  journal={Machine Learning and Knowledge Extraction},
  volume={4},
  number={1},
  pages={172--221},
  year={2022},
  publisher={MDPI}
}


# J
@article{Jorge2016,
  title={Learning to play guess who? and inventing a grounded language as a consequence},
  author={Jorge, Emilio and K{\aa}geb{\"a}ck, Mikael and Johansson, Fredrik D and Gustavsson, Emil},
  journal={arXiv preprint arXiv:1611.03218},
  year={2016}
}

# K
@inproceedings{Kumar2017,
  title={Feudal Learning for Large Discrete Action Spaces with Recursive Substructure},
  author={Kumar, A and Swersky, K and Hinton, G},
  booktitle={Proceedings of the NIPS Workshop Hierarchical Reinforcement Learning, Long Beach, CA, USA},
  volume={9},
  year={2017}
}



# L
@article{Leibo2019,
  title={Autocurricula and the emergence of innovation from social interaction: A manifesto for multi-agent intelligence research},
  author={Leibo, Joel Z and Hughes, Edward and Lanctot, Marc and Graepel, Thore},
  journal={arXiv preprint arXiv:1903.00742},
  year={2019}
}


@article{Levin22,
  AUTHOR={Levin, Michael},   
	 TITLE={Technological Approach to Mind Everywhere: An Experimentally-Grounded Framework for Understanding Diverse Bodies and Minds},      
    JOURNAL={Frontiers in Systems Neuroscience},      
	VOLUME={16},           
	YEAR={2022},      
	  URL={https://www.frontiersin.org/articles/10.3389/fnsys.2022.768201},       
	DOI={10.3389/fnsys.2022.768201},      
	ISSN={1662-5137},   
}

@inproceedings{Li2017,
  title={An efficient approach to model-based hierarchical reinforcement learning},
  author={Li, Zhuoru and Narayan, Akshay and Leong, Tze-Yun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  number={1},
  year={2017}
}


@inproceedings{Luo2023,
  title={Hierarchical Reinforcement Learning With Attention Reward},
  author={Luo, Sihong and Chen, Jinghao and Hu, Zheng and Zhang, Chunhong and Zhuang, Benhui},
  booktitle={Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
  pages={2804--2806},
  year={2023}
}

@article{Lowe2017,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

# M 
@inproceedings{Mann2014,
  title={Scaling up approximate value iteration with options: Better policies with fewer iterations},
  author={Mann, Timothy and Mannor, Shie},
  booktitle={International conference on machine learning},
  pages={127--135},
  year={2014},
  organization={PMLR}
}

@article{Mordatch2017,
  title={Emergence of Grounded Compositional Language in Multi-Agent Populations},
  author={Mordatch, Igor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1703.04908},
  year={2017}
}


# N
@article{Nachum2019,
  title={Why does hierarchy (sometimes) work so well in reinforcement learning?},
  author={Nachum, Ofir and Tang, Haoran and Lu, Xingyu and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv preprint arXiv:1909.10618},
  year={2019}
}


@article{Nguyen2020,
  title={Deep reinforcement learning for multiagent systems: A review of challenges, solutions, and applications},
  author={Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
  journal={IEEE transactions on cybernetics},
  volume={50},
  number={9},
  pages={3826--3839},
  year={2020},
  publisher={IEEE}
}


# O
@article{Oroojlooy2023,
  title={A review of cooperative multi-agent deep reinforcement learning},
  author={Oroojlooy, Afshin and Hajinezhad, Davood},
  journal={Applied Intelligence},
  volume={53},
  number={11},
  pages={13677--13722},
  year={2023},
  publisher={Springer}
}




# P
@misc{Paolo2024,
      title={A call for embodied AI}, 
      author={Giuseppe Paolo and Jonas Gonzalez-Billandon and Balázs Kégl},
      year={2024},
      eprint={2402.03824},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.03824}, 
}

@inproceedings{Pierrot2020,
  title={Factored action spaces in deep reinforcement learning, 2021},
  author={Pierrot, Thomas and Mac{\'e}, Valentin and Sevestre, Jean-Baptiste and Monier, Louis and Laterre, Alexandre and Perrin, Nicolas and Beguir, Karim and Sigaud, Olivier},
  booktitle={URL https://openreview. net/forum},
  year={2020}
}

# S
@article{Samvelyan2019,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@article{Schulman2017,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}



@article{Silver2012,
  title={Compositional planning using optimal option models},
  author={Silver, David and Ciosek, Kamil},
  journal={arXiv preprint arXiv:1206.6473},
  year={2012}
}


@article{Spelke2007,
  title={Core knowledge},
  author={Spelke, Elizabeth S and Kinzler, Katherine D},
  journal={Developmental science},
  volume={10},
  number={1},
  pages={89--96},
  year={2007},
  publisher={Wiley Online Library}
}

@article{Sutton1999,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}





# T
@inproceedings{Tang2023,
  title={Understanding self-predictive learning for reinforcement learning},
  author={Tang, Yunhao and Guo, Zhaohan Daniel and Richemond, Pierre Harvey and Pires, Bernardo Avila and Chandak, Yash and Munos, R{\'e}mi and Rowland, Mark and Azar, Mohammad Gheshlaghi and Le Lan, Charline and Lyle, Clare and others},
  booktitle={International Conference on Machine Learning},
  pages={33632--33656},
  year={2023},
  organization={PMLR}
}

@article{Tang2022,
  title={Leveraging factored action spaces for efficient offline reinforcement learning in healthcare},
  author={Tang, Shengpu and Makar, Maggie and Sjoding, Michael and Doshi-Velez, Finale and Wiens, Jenna},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34272--34286},
  year={2022}
}

@article{Tang2018,
  title={Hierarchical deep multiagent reinforcement learning with temporal abstraction},
  author={Tang, Hongyao and Hao, Jianye and Lv, Tangjie and Chen, Yingfeng and Zhang, Zongzhang and Jia, Hangtian and Ren, Chunxu and Zheng, Yan and Meng, Zhaopeng and Fan, Changjie and others},
  journal={arXiv preprint arXiv:1809.09332},
  year={2018}
}

@article{Terry2021,
  title={Pettingzoo: Gym for multi-agent reinforcement learning},
  author={Terry, Jordan and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario and Hari, Ananth and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and Perez-Vicente, Rodrigo and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15032--15043},
  year={2021}
}

@phdthesis{Thorpe1997,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Thorpe, T},
  year={1997},
  school={Master’s thesis, Department of Computer Science, Colorado State University}
}

# V
@inproceedings{Vezhnevets2017,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={3540--3549},
  year={2017},
  organization={PMLR}
}

@article{Vincent2024,
  title={Adaptive $ Q $-Network: On-the-fly Target Selection for Deep Reinforcement Learning},
  author={Vincent, Th{\'e}o and Wahren, Fabian and Peters, Jan and Belousov, Boris and D'Eramo, Carlo},
  journal={arXiv preprint arXiv:2405.16195},
  year={2024}
}




# W
@article{Wang2024,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  publisher={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  pages={279--292},
  year={1992},
  publisher={Springer}
}


# X
@article{Xu2021,
  title={Interpretable model-based hierarchical reinforcement learning using inductive logic programming},
  author={Xu, Duo and Fekri, Faramarz},
  journal={arXiv preprint arXiv:2106.11417},
  year={2021}
}


# Y
@article{Yu2022,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
}



# Z
@inproceedings{Zhang2018,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  booktitle={International conference on machine learning},
  pages={5872--5881},
  year={2018},
  organization={PMLR}
}


@inproceedings{Zhang2019,
  title={Solar: Deep structured representations for model-based reinforcement learning},
  author={Zhang, Marvin and Vikram, Sharad and Smith, Laura and Abbeel, Pieter and Johnson, Matthew and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={7444--7453},
  year={2019},
  organization={PMLR}
}


@article{Zheng2024,
  title={Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines},
  author={Zheng, Xuejing and Yu, Chao},
  journal={arXiv preprint arXiv:2403.07005},
  year={2024}
}
