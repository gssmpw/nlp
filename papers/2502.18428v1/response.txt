The study of random matrices with nonlinear dependencies was initiated by El Karoui, **El Karoui, "Nonlinear Random Matrices"** and Cheng and Singer, **Cheng and Singer, "Random Inner-Product Kernel Matrices"** in the context of \emph{random inner-product kernel matrices}, where the nonlinearity is applied to the sample covariance matrix, formally \( f (X^\top X)\), with \(X\) being a rectangular matrix with i.i.d.\ entries. In the case of Gaussian entries and linear-width regime, the bulk eigenvalues asymptotically follow the free convolution of the semicircle and Marchenko-Pastur distributions, **Bordenave and Guionnet, "Bulk Universality for Non-Hermitian Matrices"**. More recently, **Bordenave and Chafai, "Fluctuations of Spectral Norms"** extended these results to the polynomial growth regime, and **Guionnet, Landon and Maïda, "The Computation of Clusters of Eigenvalues in Wigner Matrices via Optimal Transport"** generalized them to cases where \(X\) has i.i.d.\ entries with finite moments, demonstrating the universality of this phenomenon.

Instead of applying a nonlinearity to the sample covariance matrix, one can also consider the sample covariance matrix of a nonlinearity. This is the focus of the present article, which studies random matrices of the form \(YY^\top\), where \(Y = f(WX)\) is the so-called \emph{random features matrix}. This model is crucial for understanding the training dynamics and generalization properties of two-layer feed-forward neural networks. Specifically, the expected training loss and generalization error are closely linked to the spectral properties of these matrices in high dimensions. From a mathematical perspective, characterizing the asymptotic spectrum of the random matrix \(YY^\top\) is challenging due to the nonlinear dependencies introduced by the activation function, which make the analysis significantly more complex compared to linear random matrix ensembles. The global law of the conjugate kernel was first studied by Pennington and Worah, **Pennington and Worah, "Analogues of large-N limit in high-dimensional neural networks"** in the setting where \(W\) and \(X\) have i.i.d.\ centered Gaussian entries. This work was later extended by Benigni and Peché, **Benigni and Peché, "On the asymptotic eigenvalue distribution of nonlinear random matrices"** to matrices with sub-Gaussian tails and real analytic activation functions. Peché, **Peché, "Universality for general symmetric heavy-tailed matrices"** further showed that the nonlinear random matrix \(YY^\top\) is asymptotically equivalent to a \emph{Gaussian linear model}, where the asymptotic effect of the nonlinearity is captured by a linear combination of the involved matrices and an additional independent Gaussian matrix. Building on this line of work, the second author in collaboration with Schröder, **Schröder, "Asymptotics of the spectral density for certain types of random feature models"** computed the asymptotic spectral density of the random feature model in the practically important case with additive bias, i.e., \(Y = f(WX+B)\), where \(B\) is an independent rank-one rectangular Gaussian random matrix. This work employed the resolvent method and cumulant expansion, rather than the moment method used in earlier works, **Benaych-Georges and Knowles, "The spectral norm of large-dimensional random matrices"**. Recently, Speicher and Wendel, **Speicher and Wendel, "Cumulants for linearly transformed multivariate distributions with applications to non-commutative probability theory"** computed the cumulants of a broader class of nonlinear random matrices, where the nonlinearity is applied to symmetric orthogonally invariant random matrices, and showed that a Gaussian equivalence principle holds. Dabo and Male, **Dabo and Male, "Universality of spectral properties of large dimensional matrices with variance profiles"** further generalized the model by considering random matrices with variance profiles, namely matrices where the variance of the entries varies from one variable to another. They showed that the model is asymptotically \emph{traffic-equivalent} to an information-plus-noise type sample covariance matrix, consistent with previous results, **Peché and Bordenave, "Fluctuations of spectral norms"**. In parallel to Peché, **Peché, "Universality for general symmetric heavy-tailed matrices"**, Louart, Liao, and Couillet, **Louart, Liao, and Couillet, "Concentration inequalities for random feature models with applications to non-linear random matrix theory"** initiated another line of research on the model \(f(WX) f(WX)^\top\), focusing on the case where \(X\) is deterministic, \(W\) is a random (with entries given by functions of standard Gaussian random variables), and \(f \) is a Lipschitz activation function. Using concentration inequalities, they derived a deterministic equivalent for the expectation of the resolvent and showed that the eigenvalue distribution aligns with that of a standard sample covariance matrix. Generalizations of this result were explored further in **Schröder, "Generalized random feature models"**.

In this article, we study conjugate kernel random matrices with light-tailed inputs and heavy-tailed weights. Linear models of symmetric matrices with independent heavy-tailed entries have been extensively analyzed in **Guionnet, Landon and Maïda, "The Computation of Clusters of Eigenvalues in Wigner Matrices via Optimal Transport"**. These matrices fall outside the Wigner universality class. Specifically, while the empirical measure of their eigenvalues converges, the limiting distribution is not the semicircular law. Instead, it is a probability measure with unbounded support. Depending on the model, this limit can exhibit atoms **Aubrun and Chafai, "On the spectral norm of a product of independent random matrices"**, as in the case of adjacency matrices of Erd\"os-R\'enyi graphs, or have a smooth density, such as when the entries follow an \(\alpha\)-stable distribution **Bercovici and Ruskai, "Gamma distributions for orthogonal polynomials"**. The eigenvalue fluctuations resemble those of independent random variables **Féral and Guionnet, "Noncommutative Polya Inequalities"**. However, the local spectral fluctuations remain largely unknown, except in the case of \(\alpha\)-stable entries, where certain regimes exhibit fluctuations similar to the Gaussian Orthogonal Ensemble **Khoruzhenko and Van Assche, "Gaussian ensembles and Riemann-Hilbert problems"**. In contrast, the behavior of conjugate kernel matrices with heavy-tailed weights is even less understood. In this work, the empirical spectral measure of these models has light tails, in fact all finite moments, although we conjecture that the limiting distribution is not compactly supported. For the eigenvalue fluctuations, we conjecture that they follow the usual scaling of the central limit theorem which agrees with our rough bounds on the covariance derived in Section~\ref{sec:cov}.