\documentclass[a4paper, 10pt, reqno]{amsart}
\usepackage[a4paper,left=2.5cm,right=2.5cm,top=3cm,bottom=3cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\renewcommand{\rmdefault}{cmr}
\usepackage[foot]{amsaddr}
\usepackage{amsmath,amssymb,graphicx, mathtools, amsthm} 
\usepackage{enumerate} 
\usepackage{enumitem}
\usepackage[colorlinks, linkcolor=red, urlcolor=blue, citecolor=blue]{hyperref}
\usepackage{url}    
\numberwithin{equation}{section}
\usepackage{tikz}
%\usepackage[notcite,notref]{showkeys}

\usepackage[giveninits=true,url=false,doi=false,isbn=false,eprint=true,datamodel=mrnumber,sorting=nyt,sortcites=false,maxcitenames=4,maxbibnames=99,backref=false,block=space,backend=biber,style=phys, biblabel=brackets]{biblatex} 
\AtEveryBibitem{\clearfield{month}}
\AtEveryCitekey{\clearfield{month}} 
\renewbibmacro{in:}{}
\ExecuteBibliographyOptions{eprint=true}
\DeclareFieldFormat[article]{title}{\emph{#1}} 
\DeclareFieldFormat{mrnumber}{\ifhyperref{\href{http://www.ams.org/mathscinet-getitem?mr=#1}{\nolinkurl{MR#1}}}{\nolinkurl{#1}}}
\DeclareFieldFormat{pmid}{\ifhyperref{\href{https://www.ncbi.nlm.nih.gov/pubmed/#1}{\nolinkurl{PMID#1}}}{\nolinkurl{#1}}}
\DeclareFieldFormat{eprint}{\ifhyperref{\href{https://arxiv.org/abs/#1}{\nolinkurl{arXiv:#1}}}{\nolinkurl{#1}}}
\renewbibmacro*{doi+eprint+url}{%
  \iftoggle{bbx:doi}{\printfield{doi}}{}
  \newunit\newblock%
  \printfield{mrnumber}%
  \newunit\newblock%
  \printfield{pmid}%
  \newunit\newblock%
  \printfield{eprint}%
  \iftoggle{bbx:url}{\usebibmacro{url+urldate}}{}}
  
  
\bibliography{refs3}
\usepackage{caption}
\usepackage{float}
\usepackage{subcaption}


\DeclareMathOperator{\tr}{Tr}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\cov}{Cov}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\dif}{\operatorname{d}\!{}}
\newcommand{\norm}[1]{\lVert#1\rVert}
\newcommand{\R}{\mathbb{R}} 
\newcommand{\E}{\mathbb{E}} 
\newcommand{\N}{\mathbb{N}}  

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{claim}{Claim}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}
\newtheorem{hyp}[thm]{Assumption}
\theoremstyle{remark}
\newtheorem{rmk}[thm]{Remark}

\newcommand{\cblue}[1]{{\color{blue}#1}}
\newcommand{\cred}[1]{{\color{red}#1}}


\makeatletter
\renewcommand\subsection{\@startsection{subsection}{2}%
  \z@{-.5\linespacing\@plus-.7\linespacing}{.5\linespacing}%
  {\normalfont\scshape}}
\renewcommand\subsubsection{\@startsection{subsubsection}{3}%
  \z@{.5\linespacing\@plus.7\linespacing}{-.5em}%
  {\normalfont\scshape}}
\makeatother

\makeatletter
\@namedef{subjclassname@2020}{%
  \textup{2020} Mathematics Subject Classification}
\makeatother

\usepackage[format=plain,
            labelfont=sc]{caption}
\usepackage[toc,page]{appendix} 
\usepackage{scalerel,stackengine}
\stackMath%
\newcommand\reallywidehat[1]{%
\savestack{\tmpbox}{\stretchto{%
  \scaleto{%
    \scalerel*[\widthof{\ensuremath{#1}}]{\kern.1pt\mathchar"0362\kern.1pt}%
    {\rule{0ex}{\textheight}}
  }{\textheight}% 
}{2.4ex}}%
\stackon[-6.9pt]{#1}{\tmpbox}%
}

\makeatletter
\newsavebox\myboxA
\newsavebox\myboxB
\newlength\mylenA
\newcommand*\xoverline[2][0.75]{%
    \sbox{\myboxA}{$\m@th#2$}%
    \setbox\myboxB\null% Phantom box
    \ht\myboxB=\ht\myboxA%
    \dp\myboxB=\dp\myboxA%
    \wd\myboxB=#1\wd\myboxA% Scale phantom
    \sbox\myboxB{$\m@th\overline{\copy\myboxB}$}%  Overlined phantom
    \setlength\mylenA{\the\wd\myboxA}%   calc width diff
    \addtolength\mylenA{-\the\wd\myboxB}%
    \ifdim\wd\myboxB<\wd\myboxA%
       \rlap{\hskip 0.5\mylenA\usebox\myboxB}{\usebox\myboxA}%
    \else
        \hskip -0.5\mylenA\rlap{\usebox\myboxA}{\hskip 0.5\mylenA\usebox\myboxB}%
    \fi}
\makeatother    

\usepackage{fancyhdr}

\newcommand\shortitle{Global law of conjugate kernel random matrices with heavy-tailed weights}
\newcommand\name{Alice Guionnet and Vanessa Piccolo}

\fancyhf{}
\renewcommand\headrulewidth{0pt}
\fancyhead[CO]{\scshape\shortitle}
\fancyhead[CE]{\scshape\name}
\setlength{\headheight}{12.0pt}
\fancyhead[R]{\small\thepage\ifodd\value{page}\else\hfill\fi}
\pagestyle{fancy}


\begin{document}

\title{Global law of conjugate kernel random matrices with heavy-tailed weights}
\author{Alice Guionnet} 
\author{Vanessa Piccolo}
\address{A.G.\ and V.P.\ - Unit\'{e} de Math\'{e}matiques Pure et Appliqu\'{e}es (UMPA), ENS Lyon}
\email{alice.guionnet@ens-lyon.fr} 
\email{vanessa.piccolo@ens-lyon.fr}

\subjclass[2020]{60B20, 15B52, 68T07} 
\keywords{Two-layer conjugate kernel matrices, nonlinear random matrices, heavy-tailed weights, light-tailed data, traffic probability}
\date{\today}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We study the asymptotic spectral behavior of the conjugate kernel random matrix \(YY^\top\), where \(Y= f(WX)\) arises from a two-layer neural network model. We consider the setting where \(W\) and \(X\) are both random rectangular matrices with i.i.d.\ entries, where the entries of \(W\) follow a heavy-tailed distribution, while those of \(X\) have light tails. Our assumptions on \(W\) include a broad class of heavy-tailed distributions, such as symmetric \(\alpha\)-stable laws with \(\alpha \in (0,2)\) and sparse matrices with \(\mathcal{O}(1)\) nonzero entries per row. The activation function \(f\), applied entrywise, is nonlinear, smooth, and odd. By computing the eigenvalue distribution of \(YY^\top\) through its moments, we show that heavy-tailed weights induce strong correlations between the entries of \(Y\), leading to richer and fundamentally different spectral behavior compared to models with light-tailed weights.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{
\hypersetup{linkcolor=black}
\tableofcontents
}

\section{Introduction}

We study the asymptotic behavior of the eigenvalues of conjugate kernel random matrices \(Y Y^\top\), where \(Y = f(WX)\) is generated by a two-layer feed-forward neural network. Here, \(W\) and \(X\) are random rectangular matrices with i.i.d.\ entries, representing the weight and data matrices, respectively, and \(f\) is a smooth nonlinear activation applied entrywise. The spectral properties of such models were first studied under Gaussian assumptions by Pennington and Worah~\cite{pennington2017} and later extended to light-tailed distributions by Benigni and P\'{e}ch\'{e}~\cite{benigni2021}. Further generalizations have since been explored in~\cite{liao2018, adlam, schroder2021, pastur2022, dabo2024, speicher2024}.

In this paper, we extend these results to the case where \(W\) follows a heavy-tailed distribution. Specifically, we consider settings where the entries of \(W\) can be very large, possibly lacking finite second moments, while the entries of \(X\) remain light-tailed. This framework is motivated by empirical observations from overparameterized neural networks, where strongly correlated weights frequently emerge, defying standard Gaussian assumptions~\cite{mahoney2021, mahoney2021bis, wang2023}. Heavy-tailed distributions may thus provide a more realistic framework for understanding the complex structure of these correlations. From a mathematical perspective, random features matrices \(Y = f(WX)\) with heavy-tailed weights exhibit entirely new properties, as the entries of such matrices happen to be much more correlated than for light tails. For instance, consider the case where \(W\) is the adjacency matrix of a Erd\"os-R\'enyi graph, where each edge is drawn independently at random with probability \(q\) over the dimension. In this case, the entry \(Y_{ij} = f(W_i \cdot X_j)\) is strongly correlated with every entry \(Y_{i'j}\) whenever \(i\) and \(i'\) share a common neighbor \(k\). This arises because \(W_i \cdot X_j\) and \(W_{i'} \cdot X_j\) share the term \(X_{kj}\), which does not vanish as the dimension grows. Hence, in each column of the matrix $Y$, there are about $q$ randomly chosen entries which are strongly correlated. These strong dependencies introduce novel analytical challenges in studying the spectral behavior. In this work, we study the convergence of the moments of the empirical eigenvalue distribution for a broad class of conjugate kernel matrices with heavy-tailed weights and light-tailed features. 

\subsection{Model and main result}

Let \(W \in \R^{p \times n}\) be a random weight matrix with i.i.d.\ entries drawn from a distribution \(\nu_w\), and let \(X \in \R^{n \times m}\) a random data matrix with i.i.d.\ entries drawn from a distribution \(\nu_x\). We impose the following assumptions on \(\nu_w\) and \(\nu_x\).

\begin{hyp}[Distributions \(\nu_w\) and \(\nu_x\)] \label{hyp1}
\leavevmode
\begin{enumerate}
\item[(a)] The distribution \(\nu_w\) is symmetric and the random variables \(W_{ij}\) have a characteristic function that converges in the following way: for every \(\lambda \in \R\), 
\[
\Phi_n(\lambda) = n \log \E_W \left [\exp (i \lambda W_{ij})\right ]  \to \Phi(\lambda), \quad \text{as} \, n \to \infty,
\]
for some limiting function \(\Phi\). Moreover, this convergence is uniform over $\lambda$. Note that since \(\nu_w\) is symmetric, both \(\Phi_n\) and \(\Phi\) are even functions.
\item[(b)] The distribution \(\nu_x\) is centered, symmetric, and has finite moments of all orders. We denote its variance by \(\E_X \left [X_{ij}^2 \right ] = \sigma_x^2\).
\end{enumerate}
\end{hyp}

Item (a) in the above assumptions is satisfied if \(W\) is a \emph{L\'evy matrix}, namely if the weights \(W_{ij}\) are independent \emph{\(\alpha\)-stable symmetric} random variables with \(\alpha \in (0,2)\). Specifically, let \(A_{ij}\) be a symmetric \(\alpha\)-stable random variable, whose characteristic function is given by
\[
\E_W \left [ \exp(i \lambda A_{ij})\right ]  = \exp (-\sigma^\alpha |\lambda|^\alpha),
\]
for all \(\lambda \in \R\), where \(\sigma > 0\). Note that \(\alpha=1\) corresponds to the Cauchy distribution, and the upper bound \(\alpha=2\) corresponds to the normal distribution. To ensure appropriate scaling, we define the weight matrix as
\begin{equation}\label{levy}
W_{ij} = \frac{1}{n^{1/\alpha}} A_{ij},
\end{equation}
so that \(\E_W \left [ \exp(i \lambda W_{ij})\right ] =\exp (- n^{-1}\sigma^\alpha |\lambda|^\alpha) \), which gives \(\Phi (\lambda) = \Phi_n (\lambda) = -\sigma^\alpha |\lambda|^\alpha \). Another well-known model for heavy-tailed matrices is given by \emph{sparse Wigner matrices}, which takes the form:
\begin{equation}\label{hada}
W_{ij} = B_{ij} Z_{ij},
\end{equation}
where \(B_{ij}\) is a Bernoulli\(\left ( \frac{q}{n} \right)\) random variable with \(q \in (0,1)\), and \(Z_{ij}\) is drawn from a symmetric distribution independent of the dimension and is independent from \((B_{k \ell})\). In this case, $ \Phi_n (\lambda) = n\log ( 1+\frac{q}{n} \left (  \E [e^{i \lambda Z_{ij}}] -1\right))$ and \(\Phi(\lambda) = q \left (  \E [e^{i \lambda Z_{ij}}] -1\right)\).

We consider an activation function \(f \colon \R \to \R\) satisfying the following assumption:

\begin{hyp}[Activation function]\label{hyp2}
The activation function \(f\) is bounded, odd and belongs to \(\mathcal{C}^\infty \cap L^2\).
\end{hyp}

Note that this assumption includes classical activation functions such as $\tanh, \tan, \sin$.

We consider the two-layer conjugate kernel random matrix
\[
M \coloneqq Y_m Y_m^\top \in \R^{p \times p}, 
\]
where \(Y_m = (Y_{ij})_{i \in [p], j \in [m]}\) is given by
\begin{equation} \label{eq: matrix Y}
Y_{ij} = \frac{1}{\sqrt{m}} f( W_i \cdot X_j) =  \frac{1}{\sqrt{m}} f \left ( \sum_{k=1}^n W_{ik} X_{kj} \right).
\end{equation}
Since by Assumptions~\ref{hyp1} and~\ref{hyp2}, the distributions \(\nu_x\) and \(\nu_w\) are symmetric and \(f\) is an odd function, the random variables \(Y_{ij}\) are also symmetric. Our goal is to study the eigenvalue density of \(M\) in the asymptotic regime. 

\begin{hyp}[Linear-width regime] \label{hyp3}
We assume that
\[
\frac{n}{m} \to \phi \quad \text{and} \quad \frac{n}{p} \to \psi \quad \text{as} \enspace m,p,n \to \infty,
\]
where \(\phi\) and \(\psi\) are two positive constants.
\end{hyp}

Our first main result concerns the convergence of the moments of the empirical spectral measure \(\hat{\mu}_M = \frac{1}{p} \sum_{i=1}^p \delta_{\lambda_i}\), where \(\lambda_1, \ldots, \lambda_p\) denote the eigenvalues of \(M\).

\begin{thm}[Convergence of matrix moments] \label{main1}
Under Assumptions~\ref{hyp1}-\ref{hyp3}, the following holds. For every integer \(k \in \N\), there exists a real number \(m_k\), depending only on  \(\phi,\psi,f, \Phi, \nu_x\), such that 
\[
\lim_{m, p, n \rightarrow \infty }\frac{1}{p} \tr M^k = m_k,
\]
where the convergence holds both in expectation and in probability.
\end{thm}

The limiting moment \(m_k\) is given explicitly in Proposition~\ref{prop: main cycle}. From Theorem~\ref{main1}, we deduce the weak convergence of the empirical spectral measure \(\hat{\mu}_M\), provided the moments grow sufficiently slowly to be uniquely described as the moments of a probability measure. We establish this result in the following two cases: 
\begin{itemize}
\item[(i)] \(\Phi (\lambda) = - \sigma^\alpha |\lambda|^\alpha\) with \(\alpha \in (0,2)\) and \(\sigma >0\), and \(\nu_x\) follows a standard normal distribution;
\item[(ii)] \(\Phi\) is bounded. 
\end{itemize}
Item (i) applies to L\'{e}vy matrices, as defined in~\eqref{levy}, while item (ii) is satisfied, for instance, by sparse Wigner matrices~\eqref{hada}, where \(|\Phi (\lambda) | \le q\) for all \(\lambda \in \R\). 

\begin{thm}[Global law] \label{main1bis}
Under Assumptions~\ref{hyp1}-\ref{hyp3} and either condition (i) or (ii), the following holds. There exists a unique probability measure \(\mu\), depending on \(\phi,\psi,f, \Phi, \nu_x\), supported on the non-negative real line, such that for every integer \(k \in \N\), 
\[
m_k =\int x^k \textnormal{d} \mu (x). 
\]
Furthermore, the empirical spectral measure \(\hat{\mu}_M\) converges weakly almost surely to \(\mu\).
\end{thm}

When the limiting measure exists \(\mu\) exists (in particular, under conditions (i) or (ii)), it exhibits light-tailed behavior since \(\int_\R x \text{d} \mu(x)\le \|f\|_\infty^2\), and every \(k\)th moment \(m_k\) is finite. 
This contrasts sharply with typical heavy-tailed models, mainly due to the boundedness of the function \(f\). Figure~\ref{fig:1} illustrates the empirical spectral distribution of the conjugate kernel matrix \(M\) under condition (i), with \(\arctan\) as an activation function, for different values of the parameter \(\alpha\). As \(\alpha\) increases, the eigenvalue distribution shifts from a heavy-tailed regime with widely spread eigenvalues to a more concentrated spectrum, highlighting the effect of the weight distribution on spectral properties.


\begin{figure}[h] 
\centering
\includegraphics[scale=0.6]{hist_multiple_alphas}
\caption{Eigenvalue histogram of the conjugate kernel matrix \(Y_mY_m^\top\) for the activation function \(f(x) = \arctan(x)\). The weight distribution \(\nu_w\) follows a symmetric \(\alpha\)-stable distribution with \(\sigma = 1\) and different values of \(\alpha \in (0,2]\), while \(\nu_x\) is the standard normal distribution. Numerical experiments were conducted with \(m=n=10000\) and \(p=6500\).}
\label{fig:1}
\end{figure}

\subsection{Related work}

The study of random matrices with nonlinear dependencies was initiated by El Karoui~\cite{elkaroui} and Cheng and Singer~\cite{cheng} in the context of \emph{random inner-product kernel matrices}, where the nonlinearity is applied to the sample covariance matrix, formally \( f (X^\top X)\), with \(X\) being a rectangular matrix with i.i.d.\ entries. In the case of Gaussian entries and linear-width regime, the bulk eigenvalues asymptotically follow the free convolution of the semicircle and Marchenko-Pastur distributions~\cite{cheng,fan2019}. More recently,~\cite{lu2023} extended these results to the polynomial growth regime, and~\cite{dubova2023} generalized them to cases where \(X\) has i.i.d.\ entries with finite moments, demonstrating the universality of this phenomenon.

Instead of applying a nonlinearity to the sample covariance matrix, one can also consider the sample covariance matrix of a nonlinearity. This is the focus of the present article, which studies random matrices of the form \(YY^\top\), where \(Y = f(WX)\) is the so-called \emph{random features matrix}. This model is crucial for understanding the training dynamics and generalization properties of two-layer feed-forward neural networks. Specifically, the expected training loss and generalization error are closely linked to the spectral properties of these matrices in high dimensions. From a mathematical perspective, characterizing the asymptotic spectrum of the random matrix \(YY^\top\) is challenging due to the nonlinear dependencies introduced by the activation function, which make the analysis significantly more complex compared to linear random matrix ensembles. The global law of the conjugate kernel was first studied by Pennington and Worah~\cite{pennington2017} in the setting where \(W\) and \(X\) have i.i.d.\ centered Gaussian entries. This work was later extended by Benigni and P\'{e}ch\'{e}~\cite{benigni2021} to matrices with sub-Gaussian tails and real analytic activation functions. P\'{e}ch\'{e}~\cite{peche2019} further showed that the nonlinear random matrix \(YY^\top\) is asymptotically equivalent to a \emph{Gaussian linear model}, where the asymptotic effect of the nonlinearity is captured by a linear combination of the involved matrices and an additional independent Gaussian matrix. Building on this line of work, the second author in collaboration with Schr\"{o}der~\cite{schroder2021} computed the asymptotic spectral density of the random feature model in the practically important case with additive bias, i.e., \(Y = f(WX+B)\), where \(B\) is an independent rank-one rectangular Gaussian random matrix. This work employed the resolvent method and cumulant expansion, rather than the moment method used in earlier works~\cite{pennington2017,benigni2021}. Recently, Speicher and Wendel~\cite{speicher2024} computed the cumulants of a broader class of nonlinear random matrices, where the nonlinearity is applied to symmetric orthogonally invariant random matrices, and showed that a Gaussian equivalence principle holds. Dabo and Male~\cite{dabo2024} further generalized the model by considering random matrices with variance profiles, namely matrices where the variance of the entries varies from one variable to another. They showed that the model is asymptotically \emph{traffic-equivalent} to an information-plus-noise type sample covariance matrix, consistent with previous results~\cite{peche2019}. In parallel to~\cite{pennington2017}, Louart, Liao, and Couillet~\cite{couillet2018} initiated another line of research on the model \(f(WX) f(WX)^\top\), focusing on the case where \(X\) is deterministic, \(W\) is a random (with entries given by functions of standard Gaussian random variables), and \(f \) is a Lipschitz activation function. Using concentration inequalities, they derived a deterministic equivalent for the expectation of the resolvent and showed that the eigenvalue distribution aligns with that of a standard sample covariance matrix. Generalizations of this result were explored further in~\cite{chouard2023}.

In this article, we study conjugate kernel random matrices with light-tailed inputs and heavy-tailed weights. Linear models of symmetric matrices with independent heavy-tailed entries have been extensively analyzed in~\cite{zakarevich2006,benarous2008,bordenave2011,bordenave2011bis}. These matrices fall outside the Wigner universality class. Specifically, while the empirical measure of their eigenvalues converges, the limiting distribution is not the semicircular law. Instead, it is a probability measure with unbounded support. Depending on the model, this limit can exhibit atoms \cite{salez2015}, as in the case of adjacency matrices of Erd\"os-R\'enyi graphs, or have a smooth density, such as when the entries follow an \(\alpha\)-stable distribution \cite{Belinschi2009}. The eigenvalue fluctuations resemble those of independent random variables~\cite{BGM}. However, the local spectral fluctuations remain largely unknown, except in the case of \(\alpha\)-stable entries, where certain regimes exhibit fluctuations similar to the Gaussian Orthogonal Ensemble~\cite{bordenave2013,bordenave2017,aggarwal2021}. In contrast, the behavior of conjugate kernel matrices with heavy-tailed weights is even less understood. In this work, the empirical spectral measure of these models has light tails, in fact all finite moments, although we conjecture that the limiting distribution is not compactly supported. For the eigenvalue fluctuations, we conjecture that they follow the usual scaling of the central limit theorem which agrees with our rough bounds on the covariance derived in Section~\ref{sec:cov}. 


\subsection{Outline of proofs} \label{subsection: outline proof}

Our approach to proving the weak convergence of the empirical spectral measure of \(Y_m Y_m^\top\) relies on the classical method of moments, involving a modification inspired by Male~\cite{male2020}, which consists in studying more general functionals of the entries of the matrix (the so-called \emph{injective moments}) than only its moments. For every positive integer \(k \geq 1\), the normalized trace of the \(k\)th power of \(Y_m Y_m^\top\) can be expanded as
\begin{equation} \label{eq: moments expansion}
\E \left [\frac{1}{p} \tr (Y_m Y_m^\top)^k \right ]  = \frac{1}{p} \sum_{1 \leq i_1,\ldots, i_k \leq p} \sum_{1 \leq j_1,\ldots, j_k \leq m} \E \left [\prod_{\ell=1}^k Y_{i_\ell j_\ell} Y_{i_{\ell+1} j_\ell}\right ],
\end{equation}
with the convention that \(i_{k+1}=i_1\). We interpret this sum graphically as a sum over cycles of length \(2k\) on a bipartite graph with one set of vertices labeled by \(\{i_1, i_2, \ldots, i_k\}\) and the other set by \(\{j_1, j_2, \ldots, j_k\}\), and with edges from \(i_\ell\) to \(j_\ell\) and from \(j_\ell\) to \(i_{\ell +1}\) for \(1 \leq \ell \leq k\). To formalize this, we now introduce the notion of \emph{traffic traces} from~\cite{male2020}, which allows to compute more general functionals of the entries of the matrix.

\begin{defn} [Traffic trace~\cite{male2020}] \label{def: traffic}
\leavevmode
\begin{enumerate}
\item[(a)] A \emph{test graph of matrices} consists of a triple \(T = (V, E, \mathcal{A})\), where \(G = (V,E)\) is a finite, oriented graph (possibly with multiple edges and loops) and \(\mathcal{A} = (A_e)_{e \in E}\) is a collection of \(N \times N\) matrices labeling each edge \(e \in E\) in \(G\). 
\item[(b)] For every test graph \(T = (V, E, \mathcal{A})\), the \emph{traffic trace} is defined by
\[
\tau_N [T] \coloneqq  \E \left [\frac{1}{N^c} \sum_{\phi \colon V \to [N]} \prod_{e = (u,v) \in E} A_e(\phi(u), \phi(v)) \right ],
\]
where \(c\) denotes the number of connected components of the graph \(G = (V,E)\).
\item[(c)] For every test graph \(T = (V, E, \mathcal{A})\), the \emph{mean injective trace} is defined by
\[
\tau_N^0 [T] \coloneqq  \E \left [\frac{1}{N^c} \sum_{\phi \colon V \to [N] \atop \textnormal{s.t.} \: \phi \: \textnormal{is injective}} \prod_{e = (u,v) \in E} A_e(\phi(u), \phi(v)) \right ].
\]
The \emph{traffic trace} is then recovered via:
\[
\tau_N [T]  = \sum_{\pi \in \mathcal{P}(V)} \tau^0_N [T^\pi],
\]
where the sum runs over all partitions of \(V\) and \(T^\pi\) denotes the test graph obtained from \(T\) by identifying the vertices within each block of \(\pi\). 
\item[(d)] We say that a collection \(\mathcal{A}\) of \(N \times N\) matrices \emph{converges in traffic distribution} if, for any test graph \(T = (V, E, \mathcal{A})\), the traffic trace \(\tau_N [T]\) converges as \(N \to \infty\). 
\end{enumerate}
\end{defn} 

In our case, we only need to consider non-oriented bipartite multigraphs since the matrix \(Y_m Y_m^\top\) is self-adjoint. According to Definition~\ref{def: traffic}, for a non-oriented, finite, connected bipartite test graph \(T =(W \cup V, E,Y_m)\), where the edges run from \(W\) to \(V\) and are labeled by the random matrix \(Y_m\), the mean injective trace is given by
\begin{equation} \label{eq: tau0}
\tau^0_{p,m,n} \left [T  \right ] \coloneqq \E \left [ \frac{1}{p} \sum_{\phi_W \colon W \to [p] \atop \phi_W  \textnormal{injective}}  \sum_{\phi_V \colon V \to [m] \atop \phi_V \textnormal{injective}} \prod_{e=(w,v)\in E} \left ( Y_m(\phi_{W}(w),\phi_{V}(v))\right )^{m(e)} \right],
\end{equation}
where for each edge \(e \in E\), \(m(e)\) denotes its multiplicity. From item (c) of Definition~\ref{def: traffic}, the normalized tracial moments of \(Y_m Y_m^\top\) can thus be expressed as
\begin{equation} \label{traffic cycle}
\E \left [\frac{1}{p} \tr (Y_m Y_m^\top)^k \right] = \tau_{p, m, n} \left [T_{\text{cycle}} \right ] = \sum_{\pi\in \mathcal{P} (W\cup V)} \tau^0_{p,m,n} \left [T_{\text{cycle}}^\pi \right ],
\end{equation}
where \(T_{\text{cycle}} = (G, Y_m)\) denotes the test graph with \(G = (W \cup V, E)\) being the simple bipartite cycle of length \(2k\). Our strategy to prove the convergence of matrix moments, and thus prove item (a) of Theorem~\ref{main1}, is based on proving the convergence in traffic distribution of \(Y_m\). Due to the invariance property described in (c) of Definition~\ref{def: traffic}, this is equivalent to prove convergence of the mean injective trace.

\begin{thm}[Convergence in traffic distribution]  \label{main2} 
Under Assumptions~\ref{hyp1}-~\ref{hyp3}, the random matrix \(Y_m\) converges in traffic distribution. Specifically, for every finite, connected bipartite test graph \(T= (W \cup V, E , Y_m)\), there exists a real number \(\tau^0_G\), depending only on $G=(V\cup W, E)$ and \(\phi, \psi, f, \Phi, \nu_x\), such that 
\[
\lim_{m,p,n \rightarrow \infty} \tau^0_{p,m,n} \left [ T \right] = \tau^0_G.
\]
\end{thm}

In~\cite{dabo2024}, the traffic approach was used to compute the traffic trace of the matrix model \(M=Y_mY_m^\top\) in the setting where the matrices \(W\) and \(X\) are profiled and have light-tailed distributions. 

To compute the injective trace \(\tau^0_{p,m,n} \left [ T \right] \) for any bipartite test graph \(T= (W \cup V, E , Y_m)\), we first expand~\eqref{eq: tau0} using the Fourier inversion theorem, which states that \(f(x)=\frac{1}{2\pi}\int_{\R} \hat{f}(t) e^{itx} \textnormal{d} t\). This theorem applies here since \(f \in L^2 \cap C^\infty\) by Assumption~\ref{hyp2}. Expanding in this way, we obtain 
\[
\tau^0_{p,m,n} \left [T  \right ]  =  \frac{1}{p m^{|E|/2}} \sum_{\phi_W \colon W \to [p] \atop \phi_W  \textnormal{injective}}  \sum_{\phi_V \colon V \to [m] \atop \phi_V \textnormal{injective}} \frac{1}{(2\pi)^{|E|}} \int_{\R^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \text{d} \gamma_e^i \hat f (\gamma_e^i) \Lambda_G^n (\boldsymbol{\gamma}) ,
\]
where \(|E| = \sum_{e \in E} m(e)\), and 
\[
\Lambda_G^n (\boldsymbol{\gamma}) \coloneqq \E \left [ \exp \left ( i \sum_{e=(w,v)\in E}  (\gamma_e^1 + \ldots+ \gamma_e^{m(e)}) W_{\phi_W(w)} \cdot X_{\phi_V(v)}  \right) \right],
\]
with \(\boldsymbol{\gamma} = (\gamma_e^1, \ldots, \gamma_e^{m(e)})_{e \in E}\). To determine the leading contributions, we expand \(\Lambda_G^n\) by first taking the expectation over \(W\), using item (a) of Assumption~\ref{hyp1}. Alternatively, we could proceed by first integrating over \(X\), which provides a different perspective on the computation. Assuming that \(\nu_x\) follows a centered normal distribution, we obtain
\[
\Lambda_G^n (\boldsymbol{\gamma}) = \E \left [ e^{i \tr (X E_G(\boldsymbol{\gamma}) W)}\right ]  = \E_W \left [ e^{ - \frac{1}{2} \sigma_x^2 \sum_{v}\langle E_G(\boldsymbol{\gamma})_{v}, W W^\top E_G(\boldsymbol{\gamma})_{v}\rangle} \right ],
\]
where \(E_G(\boldsymbol{\gamma})\) is the matrix with entries given by \((E_G(\boldsymbol{\gamma}))_{wv} = (\gamma_e^1 + \cdots + \gamma_e^{m(e)}) \mathbf{1}_{e = (w,v) \in E}\) and $E_G(\boldsymbol{\gamma})_{v}$ denotes the corresponding column vector. This approach shows $Y_{m}$ as a matrix with random covariance given by $E_{G}(\gamma)^\top E_{G}(\gamma)$. However, even if this point of view clarifies the correlation between the entries, we did not succeed to use it to describe more explicitly the limit law.

\subsection{Overview}
In Section~\ref{section: convergence traffic}, we present the proof of Theorem~\ref{main2}. In particular, we identify the connected bipartite graphs that contribute to the limiting injective trace \(\tau_G^0\) relying on key combinatorial estimates from Section~\ref{section: combinatorics}. This result is then applied in Section~\ref{section: cycle} to compute the asymptotics of the normalized tracial moments of \(Y_mY_m^\top\) by studying the traffic trace \(\tau_{p,m,n} [T_{\text{cycle}}]\) associated to the simple bipartite test cycle \(T_{\text{cycle}}\). Thus, Section~\ref{section: cycle} provides the proof of the convergence in expectation stated in Theorem~\ref{main1}. The convergence in probability is derived from Chebyshev's inequality by estimating the variance in Section~\ref{sec:cov}. Finally, Section~\ref{sec:concen} proves the almost sure weak convergence of the empirical spectral measure. \\

\textbf{Acknowledgements.}\ We thank G\'{e}rard Ben Arous and Camille Male for invaluable discussions throughout the project. This work was supported by the ERC Advanced Grant LDRaM (No.\ 884584).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Convergence in traffic distribution} \label{section: convergence traffic}

The goal of this section is to compute the limiting injective trace \(\tau_G^0\) from Theorem~\ref{main2} and thereby prove convergence in traï¬ƒc distribution. To this end, we will identify the connected bipartite test graphs \(T=(G,Y_m)\) for which the limiting injective trace \(\tau_G^0\) is nonzero. 

\subsection{Preliminary remarks and definitions}

Let \(G=(W \cup V,E)\) be a finite, connected bipartite multigraph \(G=(W \cup V,E)\), where \(E\) is a multiset of edges and \(m \colon E \to \N\) assigns the multiplicity to each edge \(e\in E\). The total number of edges is then given by \(|E| = \sum_{e \in E} m(e)\), and the degree of a vertex \(x \in W \cup V\) is defined by \(\deg(x)=\sum_{y \colon y \sim x} m((x,y))\), where \(w \sim v\) stands for \((w,v) \in E\).

We first note that some test graphs have a vanishing mean injective trace due to the symmetry in the distribution of the entries \(W_{ij}\) and \(X_{ij}\). In particular, if there is a vertex in either \(W\) or \(V\) with an odd degree, the mean injective trace of the corresponding test graph will vanish, as shown by the following result.

\begin{lem} \label{lem: even degree} 
Let \(T = (W \cup V, E, Y_m)\) be a finite, connected bipartite test graph with at least one vertex in either \(W\) or \(V\) having an odd degree. Then, for every integers \(p,m,n \in \N\), it holds that \(\tau^0_{p,m,n} \left [T \right]=0\).
\end{lem}
\begin{proof} 
We first assume that there exists \(v_0 \in V\) having an odd degree. For every injective maps \(\phi_W \colon W \to [p]\) and \(\phi_V \colon V \to [m]\), according to~\eqref{eq: tau0} we have that
\[
\begin{split}
& \E \left[ \prod_{(w,v) \in E} Y_m(\phi_W(w),\phi_V(v)) \right] \\
& = \E \left[ \E \left [\prod_{(w,v_0) \in E} Y_m (\phi_W(w), \phi_V(v_0)) \, | \, \mathcal F_{\phi_V(v_0)} \right ] \prod_{(w,v)\in E, v \in V \backslash \{v_0\}} Y_m(\phi_W(w),\phi_V(v))\right]
\end{split}
\]
where \(\mathcal F_{\phi_V(v_0)}\) denotes the \(\sigma\)-algebra generated by \(\{(W_i)_{i \in [p]}, (X_j)_{j \neq \phi_V(v_0)}\}\). Now, we recall from~\eqref{eq: matrix Y} that \(Y_m(\phi_W(w),\phi_V(v))\) is given by
\[
Y_m (\phi_W(w),\phi_V(v)) = \frac{1}{\sqrt{m}} f \left ( W_{\phi_W(w)} \cdot X_{\phi_V(v)} \right) =  - \frac{1}{\sqrt{m}} f \left (  W_{\phi_W(w)} \cdot (-X_{\phi_V(v)})  \right),
\]
where we used the fact that \(f\) is an odd function. Since the law of the random vector \(X_{\phi_V(v)}\) is symmetric by Assumption~\ref{hyp1}, we obtain that
\[
\begin{split}
& \E \left [\prod_{(w,v_0) \in E} Y_m (\phi_W(w), \phi_V(v_0)) \, | \, \mathcal F_{\phi_V(v_0)} \right ] \\
&= (-1)^{\deg(v_0)} \E \left [\prod_{(w,v_0) \in E} \frac{1}{\sqrt{m}} f \left (  W_{\phi_W(w)} \cdot (-X_{\phi_V(v)})  \right)  \, | \, \mathcal F_{\phi_V(v_0)} \right ] \\
&=- \E \left [\prod_{(w,v_0) \in E} Y_m (\phi_W(w), \phi_V(v_0)) \, | \, \mathcal F_{\phi_V(v_0)} \right ],
\end{split}
\]
where we used that \(\deg(v_0)\) is an odd integer. This shows that \(\E \left [\prod_{(w,v_0) \in E} Y_m (\phi_W(w), \phi_V(v_0)) \, | \, \mathcal F_{\phi_V(v_0)}\right ]\) vanishes and so does \(\tau^0_{p,m,n} \left [T \right]\). The same argument applies to any vertex \(w_0 \in W\) with an odd degree, as the law of the entries of \(W\) is also symmetric by Assumption~\ref{hyp1}.
\end{proof}

In general, the limit of our injective trace is complicated, especially since the entries \(Y_{ij}\) are correlated. We next introduce some definitions which are needed in order to describe its limit.

\begin{defn}[Induced subgraphs]  \label{def: subgraphs}
Let \(G = (W \cup V, E)\) be a connected bipartite multigraph. For some positive integer \(K\), consider subsets \(W_1, \ldots, W_K\) of \(W\) such that \(\cup_{i=1}^K W_i \subseteq W\), which may have a nontrivial intersection. For each subset \(W_i\), we define the bipartite subgraph \(G_i = G(W_i)\) induced by \(W_i\), where 
\[
V_i= \{ v \in V \colon \exists \, w \in W_i \, \textnormal{such that} \, w \sim v\},
\]
and
\[
E_i =\{e = (w,v) \in E \colon w \in W_i, v \in V_i\}.
\] 
The degree of a vertex \(x \in W_i \cup V_i\) within the subgraph \(G_i\) is denoted by \(\deg_{G_i}(x)\) and its degree in the entire graph \(G\) by \(\deg(x)\). By construction of the subgraph \(G_i\), for every \(w \in W_i\), the set \(E_i\) includes all edges in \(G\) that are incident to \(w\), so that \(\deg(w) = \deg_{G_i}(w)\). For every \(2 \leq k \leq K\) and every \(1 \leq \ell_1 < \cdots < \ell_k \leq K\), we define the sets of common vertices in \(W\) and \(V\), respectively, as follows:
\[
W_{G_{\ell_1}, \ldots, G_{\ell_k}}=  \left \{ w \in W \colon \exists \, 1 \leq i < j \leq k \enspace \text{such that} \enspace w \in W_{\ell_i} \cap W_{\ell_j} \right \},
\]
and
\[
V_{G_{\ell_1}, \ldots, G_{\ell_k}} = \left \{ v \in V \colon \exists \, 1 \leq i < j \leq k \enspace \text{such that} \enspace v \in V_{\ell_i} \cap V_{\ell_j} \right \},
\]
respectively.
\end{defn}

\begin{ex} \label{ex1}
Figure~\ref{fig1} provides an example of connected bipartite graph \(G = (W \cup V, E)\), along with three different collections of subsets \(W_1, \ldots, W_K\) of \(W\) for some \(K \in \{2,3\}\) and their corresponding subgraphs \(G(W_1), \ldots, G(W_K)\). 
\end{ex}


\begin{figure} 
\centering

\begin{subfigure}[]{0.8\textwidth} 
\centering

\begin{tikzpicture}

\draw (0,0) circle [radius=1];
\def\nodesA{8}
\foreach \i in {1,...,\nodesA} {
    \coordinate (P\i) at ({360/\nodesA * (\i - 1)}:1); 
    \ifodd\i 
        \fill (P\i) circle [radius=2pt]; 
    \else        
        \draw[fill=white] (P\i) circle [radius=2pt]; 
    \fi
}

\node[right] at (P1) {\tiny $v_1$};
\node[above] at (P2) {\tiny $w_1$};
\node[above] at (P3) {\tiny $v_4$};
\node[left] at (P4) {\tiny $w_4$};
\node[left] at (P5) {\tiny $v_3$};
\node[below] at (P6) {\tiny $w_3$};
\node[below] at (P7) {\tiny $v_2$};
\node[below] at (P8) {\tiny $w_2$};


\draw (2.2,0) circle [radius=1.2];
\def\nodesB{12}

\foreach \i in {1, ..., \nodesB} {
        
\pgfmathsetmacro\angle{360/\nodesB * \i}
        
\pgfmathsetmacro\xpos{2.2 + 1.2 * cos(\angle)}
\pgfmathsetmacro\ypos{0 + 1.2 * sin(\angle)}
        
\coordinate (Q\i) at (\xpos, \ypos);
       
\ifodd\i
\draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    
\node[right] at (Q1) {\tiny $w_5$};
\node[above] at (Q2) {\tiny $v_{10}$};
\node[above] at (Q3) {\tiny $w_{10}$};
\node[above] at (Q4) {\tiny $v_9$};
\node[right] at (Q5) {\tiny $w_9$};
\node[right] at (Q7) {\tiny $w_8$};
\node[below] at (Q8) {\tiny $v_7$};
\node[below] at (Q9) {\tiny $w_7$};
\node[below] at (Q10) {\tiny $v_6$};
\node[right] at (Q11) {\tiny $w_6$};
\node[right] at (Q12) {\tiny $v_5$};
    
\pgfmathsetmacro\xcoord{cos(30)} 
\pgfmathsetmacro\ycoord{sin(30)} 

    
\draw (2.2 + 2 * \xcoord, 2 * \ycoord)  circle [radius=0.8];    
\def\nodesC{6}

\foreach \i in {1, ..., \nodesC} {
        
        \pgfmathsetmacro\angle{30 + 360/\nodesC * \i}
        
        \pgfmathsetmacro\xpos{2.2 + 2 * \xcoord + 0.8 * cos(\angle)}
        \pgfmathsetmacro\ypos{0 + 2 * \ycoord + 0.8 * sin(\angle)}
        
         \coordinate (R\i) at (\xpos, \ypos);
         
        \ifodd\i
             \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
	 \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }

\node[above] at (R1) {\tiny $w_{11}$};
\node[right] at (R2) {\tiny $v_{13}$};
\node[above] at (R4) {\tiny $v_{12}$};
\node[right] at (R5) {\tiny $w_{12}$};    
\node[right] at (R6) {\tiny $v_{11}$};
 
\end{tikzpicture}
\caption{A connected bipartite graph \(G = (W \cup V, E)\), where \(W = \{w_1, \ldots, w_{12}\}\) and \(V = \{v_1, \ldots, v_{12}\}\). The vertices in \(W\) are denoted by white nodes, while the vertices in \(V\) by black nodes.}
\label{subfig1}
\end{subfigure}

\hfill

\begin{subfigure}[]{0.8\textwidth}
\centering

\begin{tikzpicture}

\draw (-1.5,0) circle [radius=1];
\def\nodesA{8}

\foreach \i in {1, ..., \nodesA} {
        
\pgfmathsetmacro\angle{360/\nodesA * \i}
\pgfmathsetmacro\xpos{-1.5 + cos(\angle)}
\pgfmathsetmacro\ypos{0 + sin(\angle)}
  
 \coordinate (P\i) at (\xpos, \ypos);      
  \ifodd\i
           \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }


\node[right] at (P1) {\tiny $w_1$};
\node[above] at (P2) {\tiny $v_4$};
\node[left] at (P3) {\tiny $w_4$};
\node[left] at (P4) {\tiny $v_3$};
\node[left] at (P5) {\tiny $w_3$};
\node[below] at (P6) {\tiny $v_2$};
\node[right] at (P7) {\tiny $w_2$};
\fill[red] (P8)   circle [radius=2pt];  
\node[right] at (P8) {\tiny $v_1$};  

    
\draw (2.2,0) circle [radius=1.2];
\def\nodesB{12}

\draw (2.2,0) circle [radius=1.2];
\def\nodesB{12}

\foreach \i in {1, ..., \nodesB} {
        
\pgfmathsetmacro\angle{360/\nodesB * \i}
        
 \pgfmathsetmacro\xpos{2.2 + 1.2 * cos(\angle)}
 \pgfmathsetmacro\ypos{0 + 1.2 * sin(\angle)}
        
         \coordinate (Q\i) at (\xpos, \ypos);  
         
        \ifodd\i
           \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    
\node[right] at (Q1) {\tiny $w_5$};
\node[above] at (Q2) {\tiny $v_{10}$};
\node[above] at (Q3) {\tiny $w_{10}$};
\node[above] at (Q4) {\tiny $v_9$};
\node[left] at (Q5) {\tiny $w_9$};
\node[left] at (Q6) {\tiny $v_1$};
\fill[red] (Q6) circle [radius=2pt]; 
\node[left] at (Q7) {\tiny $w_8$};
\node[below] at (Q8) {\tiny $v_7$};
\node[below] at (Q9) {\tiny $w_7$};
\node[below] at (Q10) {\tiny $v_6$};
\node[right] at (Q11) {\tiny $w_6$};
\node[right] at (Q12) {\tiny $v_5$};

          
\pgfmathsetmacro\xcoord{cos(30)} 
\pgfmathsetmacro\ycoord{sin(30)} 

\draw (2.2 + 2 * \xcoord, 2 * \ycoord)  circle [radius=0.8];    
\def\nodesC{6}


\foreach \i in {1, ..., \nodesC} {
        
        \pgfmathsetmacro\angle{30 + 360/\nodesC * \i}
        
        \pgfmathsetmacro\xpos{2.2 + 2 * \xcoord + 0.8 * cos(\angle)}
        \pgfmathsetmacro\ypos{0 + 2 * \ycoord + 0.8 * sin(\angle)}
        
         \coordinate (R\i) at (\xpos, \ypos); 
         
        \ifodd\i
             \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
	 \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    
\node[above] at (R1) {\tiny $w_{11}$};
\node[right] at (R2) {\tiny $v_{13}$};
\node[above] at (R4) {\tiny $v_{12}$};
\node[right] at (R5) {\tiny $w_{12}$};    
\node[right] at (R6) {\tiny $v_{11}$};    
 
\end{tikzpicture}
\caption{The two connected subgraphs \(G_1=G(W_1)\) and \(G_2=G(W_2)\) obtained from the disjoint subsets \(W_1 = \{w_1, \ldots, w_4\}\) and \(W_2 = \{w_5, \ldots, w_{12}\}\), respectively, according to Definition~\ref{def: subgraphs}. Moreover, \(W_{G_1,G_2} = \emptyset\) and \(V_{G_1, G_2} = \{v_1\}\).}
\label{subfig2}
\end{subfigure}

\hfill

\begin{subfigure}[]{0.8\textwidth}

\centering

\begin{tikzpicture}

\draw (-1.5,0) circle [radius=1];
\def\nodesA{8}

\foreach \i in {1, ..., \nodesA} {
        
        \pgfmathsetmacro\angle{360/\nodesA * \i}
        
        \pgfmathsetmacro\xpos{-1.5 + cos(\angle)}
        \pgfmathsetmacro\ypos{0 + sin(\angle)}
        
        \coordinate (P\i) at (\xpos, \ypos); 
        
        \ifodd\i
           \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    

\node[right] at (P1) {\tiny $w_1$};
\node[above] at (P2) {\tiny $v_4$};
\node[left] at (P3) {\tiny $w_4$};
\node[left] at (P4) {\tiny $v_3$};
\node[left] at (P5) {\tiny $w_3$};
\node[below] at (P6) {\tiny $v_2$};
\node[right] at (P7) {\tiny $w_2$};
\node[right] at (P8) {\tiny $v_1$};  
\fill[red] (P8) circle [radius=2pt];  
    
\draw (2.2,0) circle [radius=1.2];
\def\nodesB{12}

\draw (2.2,0) circle [radius=1.2];
\def\nodesB{12}

\foreach \i in {1, ..., \nodesB} {
        
        \pgfmathsetmacro\angle{360/\nodesB * \i}
        
        \pgfmathsetmacro\xpos{2.2 + 1.2 * cos(\angle)}
        \pgfmathsetmacro\ypos{0 + 1.2 * sin(\angle)}
        
        \coordinate (Q\i) at (\xpos, \ypos); 
        
        \ifodd\i
           \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
 
\node[right] at (Q1) {\tiny $w_5$};
\node[above] at (Q2) {\tiny $v_{10}$};
\node[above] at (Q3) {\tiny $w_{10}$};
\node[above] at (Q4) {\tiny $v_9$};
\node[left] at (Q5) {\tiny $w_9$};
\node[left] at (Q6) {\tiny $v_1$};
\fill[red] (Q6) circle [radius=2pt]; 
\node[left] at (Q7) {\tiny $w_8$};
\node[below] at (Q8) {\tiny $v_7$};
\node[below] at (Q9) {\tiny $w_7$};
\node[below] at (Q10) {\tiny $v_6$};
\node[right] at (Q11) {\tiny $w_6$};
\node[right] at (Q12) {\tiny $v_5$};

\pgfmathsetmacro\xcoord{cos(30)} 
\pgfmathsetmacro\ycoord{sin(30)} 

\pgfmathsetmacro\xangle{cos(150)} 
\pgfmathsetmacro\yangle{sin(150)} 

\pgfmathsetmacro\xanglee{cos(270)} 
\pgfmathsetmacro\yanglee{sin(270)} 

\coordinate (A) at (2.2 + 1.2 * \xcoord, 1.2 * \ycoord);
\coordinate (B) at (2.2 + 2 * \xcoord + 0.8 * \xangle,  2 * \ycoord + 0.8 * \yangle);
\coordinate (C) at (2.2 + 2 * \xcoord + 0.8 * \xanglee,  2 * \ycoord + 0.8 * \yanglee);

%\node[right] at (B) {\tiny $v_{13}$}  ;
%\node[right] at (C) {\tiny $v_{12}$}  ;

 \draw (A) to[bend left = 20] (B);
 \draw (A) to[bend right = 20] (C);

\draw[fill=white] (A) circle [radius=2pt]; 
\fill[magenta] (B) circle [radius=2pt];   
\fill[teal] (C) circle [radius=2pt];
\node[right] at (B) {\tiny $v_{13}$};
\node[right] at (C) {\tiny $v_{12}$};

\pgfmathsetmacro\xcord{cos(-30)} 
\pgfmathsetmacro\ycord{sin(-30)} 
\pgfmathsetmacro\xpi{cos(180)} 
\pgfmathsetmacro\ypi{sin(180)} 

\coordinate (D) at (6+ 0.8 * \xpi, 0.8 * \ypi);
\coordinate (E) at (6 + 2 * \xpi + 1.2 * \xcoord, 1.2 * \ycoord);
\coordinate (F) at (6 + 2 * \xpi + 1.2 * \xcord, 1.2 * \ycord);

\node[left] at (D) {\tiny $w_5$}  ;
\node[left] at (E) {\tiny $v_{10}$};
\node[left] at (F) {\tiny $v_5$};
%\node[below] at (Q2) {\tiny $v_{10}$};
%\node[left] at (Q12) {\tiny $v_5$};

 \draw (E) to[bend left = 20] (D);
 \draw (F) to[bend right = 20] (D);

\fill[blue] (E) circle [radius=2pt];   
\fill[green] (F) circle [radius=2pt];
\fill[blue] (Q2) circle [radius=2pt];   
\fill[green] (Q12) circle [radius=2pt];


\draw (6,0)  circle [radius=0.8];    
\def\nodesC{6}

\foreach \i in {1, ..., \nodesC} {
        
        \pgfmathsetmacro\angle{360/\nodesC * \i}
        
        \pgfmathsetmacro\xpos{6 + 0.8 * cos(\angle)}
        \pgfmathsetmacro\ypos{0 + 0.8 *sin(\angle)}
        
         \coordinate (R\i) at (\xpos, \ypos); 
         
        \ifodd\i
             \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
	 \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }

\fill[magenta] (R2) circle [radius=2pt];   
\fill[teal] (R4) circle [radius=2pt];
\node[above] at (R2) {\tiny $v_{13}$};
\node[below] at (R4) {\tiny $v_{12}$};

\node[above] at (R1) {\tiny $w_{11}$};
%\node[above] at (R2) {\tiny $v_{13}$};
%\node[below] at (R4) {\tiny $v_{12}$};
\node[right] at (R5) {\tiny $w_{12}$};    
\node[right] at (R6) {\tiny $v_{11}$}; 
   
\end{tikzpicture}
\caption{The three connected subgraphs \(G_1=G(W_1), G_3=G(W_3)\) and \(G_4=G(W_4)\) obtained from the subsets \(W_1 = \{w_1, w_2,w_3, w_4\}\), \(W_3 = \{w_5,w_6, w_7, w_8,w_9, w_{10}\}\), and \(W_4 = \{w_5, w_{11}, w_{12}\}\), respectively, according to Definition~\ref{def: subgraphs}. The colored vertices represent vertices from the set \(V\) which belong to different subgraphs. In particular, \(W_{G_1, G_3} = \emptyset, W_{G_1, G_4} = \emptyset, W_{G_3, G_4} = \{w_5\}, W_{G_1, G_3, G_4} = \{w_5\}\) and \(V_{G_1, G_3} = \{v_1\}, V_{G_1, G_4} = \emptyset, V_{G_3, G_4} = \{v_2, v_3, v_4, v_5\}, V_{G_1, G_3, G_4} = \{v_1, v_2, v_3, v_4, v_5\}\).}
\label{subfig3}
\end{subfigure}

\hfill

\begin{subfigure}[]{0.8\textwidth}
\centering

\begin{tikzpicture}

\pgfmathsetmacro\xa{cos(45)} 
\pgfmathsetmacro\ya{sin(45)} 
\pgfmathsetmacro\xb{cos(90)} 
\pgfmathsetmacro\yb{sin(90)} 
\pgfmathsetmacro\xc{cos(135)} 
\pgfmathsetmacro\yc{sin(135)} 
\pgfmathsetmacro\xd{cos(180)} 
\pgfmathsetmacro\yd{sin(180)} 
\pgfmathsetmacro\xe{cos(225)} 
\pgfmathsetmacro\ye{sin(225)} 
\pgfmathsetmacro\xf{cos(270)} 
\pgfmathsetmacro\yf{sin(270)} 
\pgfmathsetmacro\xg{cos(315)} 
\pgfmathsetmacro\yg{sin(315)} 
\pgfmathsetmacro\xh{cos(360)} 
\pgfmathsetmacro\yh{sin(360)} 

\coordinate (1) at (-1.5 + \xa, \ya);
\coordinate (2) at (-1.5 + \xb, \yb);
\coordinate (3) at (-1.5 + \xc, \yc);
\coordinate (4) at (-1.5 + \xd, \yd);
\coordinate (6) at (-1.5 + \xf, \yf);
\coordinate (7) at (-1.5 + \xg, \yg);
\coordinate (8) at (-1.5 + \xh, \yh);

\draw (1) to[bend right=20] (2);
\draw (2) to[bend right=20]  (3);
\draw (3) to[bend right=20] (4);
\draw (6) to[bend right=20] (7);
\draw (7) to[bend right=20]  (8);
\draw (8) to[bend right=20] (1);

\draw[fill=white] (1) circle [radius=2pt]; 
 \fill[violet] (2) circle [radius=2pt];    
\draw[fill=white] (3) circle [radius=2pt];    
 \fill[cyan] (4) circle [radius=2pt];    
 \fill[orange] (6) circle [radius=2pt];    
\draw[fill=white] (7) circle [radius=2pt];  
 \fill[red] (8) circle [radius=2pt];      

\node[right] at (1) {\tiny  $w_1$}  ;
\node[above] at (2) {\tiny  $v_4$}  ;
\node[left] at (3) {\tiny  $w_4$}  ;
\node[left] at (4) {\tiny  $v_3$}  ;
\node[below] at (6) {\tiny  $v_2$}  ;
\node[right] at (7) {\tiny  $w_2$}  ;
\node[right] at (8) {\tiny  $v_1$}  ;

\coordinate (9) at (-3.5 + \xc, \yc);
\coordinate (10) at (-3.5 + \xd, \yd);
\coordinate (11) at (-3.5 + \xe, \ye);
\coordinate (12) at (-3.5 + \xf, \yf);
\coordinate (13) at (-3.5 + \xb, \yb);

\draw (13) to[bend right=20] (9);
\draw (9) to[bend right=20] (10);
\draw (10) to[bend right=20] (11);
\draw (11) to[bend right=20] (12);

 \fill[violet] (13) circle [radius=2pt]; 
\draw[fill=white] (9) circle [radius=2pt]; 
 \fill[cyan] (10) circle [radius=2pt];    
\draw[fill=white] (11) circle [radius=2pt];    
 \fill[orange] (12) circle [radius=2pt];  

\node[above] at (13) {\tiny  $v_4$}  ;
\node[below] at (12) {\tiny  $v_2$}  ;
\node[below] at (11) {\tiny  $w_3$}  ;
\node[left] at (10) {\tiny  $v_3$}  ;
\node[left] at (9) {\tiny  $w_4$}  ;

\draw (2.2,0) circle [radius=1.2];
\def\nodesB{12}

\draw (2.2,0) circle [radius=1.2];
\def\nodesB{12}

\foreach \i in {1, ..., \nodesB} {
        
\pgfmathsetmacro\angle{360/\nodesB * \i}
        
 \pgfmathsetmacro\xpos{2.2 + 1.2 * cos(\angle)}
 \pgfmathsetmacro\ypos{0 + 1.2 * sin(\angle)}
        
         \coordinate (Q\i) at (\xpos, \ypos);  
         
        \ifodd\i
           \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    
\node[right] at (Q1) {\tiny $w_5$};
\node[above] at (Q2) {\tiny $v_{10}$};
\node[above] at (Q3) {\tiny $w_{10}$};
\node[above] at (Q4) {\tiny $v_9$};
\node[left] at (Q5) {\tiny $w_9$};
\node[left] at (Q6) {\tiny $v_1$};
\fill[red] (Q6) circle [radius=2pt]; 
\node[left] at (Q7) {\tiny $w_8$};
\node[below] at (Q8) {\tiny $v_7$};
\node[below] at (Q9) {\tiny $w_7$};
\node[below] at (Q10) {\tiny $v_6$};
\node[right] at (Q11) {\tiny $w_6$};
\node[right] at (Q12) {\tiny $v_5$};

          
\pgfmathsetmacro\xcoord{cos(30)} 
\pgfmathsetmacro\ycoord{sin(30)} 

\draw (2.2 + 2 * \xcoord, 2 * \ycoord)  circle [radius=0.8];    
\def\nodesC{6}


\foreach \i in {1, ..., \nodesC} {
        
        \pgfmathsetmacro\angle{30 + 360/\nodesC * \i}
        
        \pgfmathsetmacro\xpos{2.2 + 2 * \xcoord + 0.8 * cos(\angle)}
        \pgfmathsetmacro\ypos{0 + 2 * \ycoord + 0.8 * sin(\angle)}
        
         \coordinate (R\i) at (\xpos, \ypos); 
         
        \ifodd\i
             \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
	 \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    
\node[above] at (R1) {\tiny $w_{11}$};
\node[right] at (R2) {\tiny $v_{13}$};
\node[right] at (R4) {\tiny $v_{12}$};
\node[right] at (R5) {\tiny $w_{12}$};    
\node[right] at (R6) {\tiny $v_{11}$};    

\end{tikzpicture}

\caption{The three connected subgraphs  \(G_5=G(W_5), G_6=G(W_6)\) and \(G_2=G(W_2)\) obtained from the subsets \(W_5 = \{w_1, w_2, w_4\}\), \(W_6 = \{w_3, w_4\}\), and \(W_2 = \{w_5, \ldots, w_{12}\}\), respectively, according to Definition~\ref{def: subgraphs}. The colored vertices represent vertices from the set \(V\) which belong to different subgraphs. In particular, \(W_{G_5, G_6} = \{w_4\}, W_{G_5, G_2} = W_{G_6, G_2}=\emptyset\) and \(V_{G_5, G_6} = \{v_2, v_3, v_4\}, V_{G_5, G_2} = \emptyset, V_{G_6, G_2} = \{v_1\}, V_{G_5, G_6, G_2} = \{v_1, v_2, v_3, v_4\}\). }
\label{subfig4}
\end{subfigure}

\caption{An example of a connected bipartite graph \(G = (W \cup V, E)\) along with three distinct subgraphs obtained by choosing subsets \(W_1, \ldots, W_K\) of \(W\) for \(K \in \{2,3\}\), as described by Definition~\ref{def: subgraphs}.}
\label{fig1}
\end{figure}

\begin{defn}[Block structure of connected bipartite multigraphs] \label{def: block structure}
Let \(G = (W \cup V, E)\) be a connected bipartite multigraph.
\begin{itemize}
\item[(a)] We say that a vertex \(v \in V\) is a \emph{separating vertex} if \(G\) can be decomposed into connected subgraphs \(G(W_1), \ldots, G(W_K)\), where \(W_1, \ldots, W_K \subseteq W\) and \(E_1, \ldots, E_K \subseteq E\) are disjoint, and \(v\) is the only vertex common to \(V_1, \ldots, V_K\).
\item[(b)] A \emph{block} \(B\) of \(G\) is a maximal subgraph of \(G\) that contains no separating vertices in \(V\). If \(W_B\) are the set of vertices in \(W\) which belong to \(B\), then \(B = G(W_B)\) with the notation of Definition \ref{def: subgraphs}.
\item[(c)] A graph \(G\) with \(N\) blocks \(B_1, \ldots, B_N\) is called a \emph{block tree} if for every \(2 \le k \le N\) and distinct \(\ell_1, \ldots, \ell_k \in [N]\), it holds that \(|V_{B_{\ell_1}, \ldots, B_{\ell_k}}| \le k-1\).
\end{itemize}
\end{defn}

\begin{rmk}
The term ``block tree'' reflects the fact that a random walk starting from a block \(B_1\), traversing \(k\) blocks, and returning to \(B_1\) must pass through at least one separating vertex more than once. If this were not the case, the random walk would start from \(B_1\), traverse the blocks \(B_2, \ldots, B_k\), and return to \(B_1\) without revisiting any separating vertex (effectively forming a cycle). In this case, \(|V_{B_1, \ldots, B_k}| =k\), contradicting the definition of a block tree.
\end{rmk}

Examples of block trees are cactus graphs and double trees, defined as follows.

\begin{defn}[Cactus graph and double tree]
A bipartite \emph{cactus graph} is a block tree in which each block is either a simple cycle or a union of simple cycles connected by vertices in \(W\). A bipartite \emph{double tree} is a cactus graph where every simple cycle has length two.
\end{defn}

\begin{ex} [Example~\ref{ex1} continued]
Consider the bipartite graph \(G\) of Figure~\ref{subfig1}. The vertex \(v_1 \in V\) is a separating vertex, and the subgraphs \(G_1\) and \(G_2\) of Figure~\ref{subfig2} are the two blocks of \(G\). Thus, \(G\) is a block tree. More specifically, \(G\) is a cactus graph, since \(G_1\) is a simple cycle and \(G_2\) is a union of two simple cycles connected by the vertex \(w_5 \in W\).
\end{ex}

In our case, we require a more intricate structure within the framework of a block tree, which we define as follows.

\begin{defn}[Admissible graph] \label{def: admissible graph}
We say that a connected bipartite graph \(G = (W \cup V, E)\) is \emph{admissible} if it satisfies the following conditions:
\begin{enumerate}
\item[(a)] the graph \(G\) is a block tree with separating vertices in \(V\),
\item[(b)] at least one block in \(G\) contains more than one vertex from \(W\), 
\item[(c)] within each block, every vertex in \(W\) has even degree and every vertex in \(V\) has degree \(2\). 
\end{enumerate}
Let \(R\) denote the number of blocks in an admissible graph that contain more than one vertex from \(W\). Then, there are \(S = |W| - |\cup_{i=1}^R W_{B_i}|\) blocks, each containing exactly one vertex from \(W\).
\end{defn}

\begin{rmk}
In an admissible graph, each edge has multiplicity \(1\) or \(2\). For all \(S\) blocks containing only one vertex from \(W\), edges have multiplicity \(2\), meaning that each of these blocks is a double tree.
\end{rmk}

\begin{rmk}
A block of an admissible graph forms a simple cycle if \(\deg(w)=2\) for each vertex \(w \in W\). A block of an admissible graph is a cactus graph if its cycles connect only through vertices in \(W\). If all blocks of an admissible graph are either simple cycles or cactus graphs, then \(G\) itself is a cactus graph.
\end{rmk}

For an admissible graph \(G = (W \cup V, E)\) and a block \(B = G(W_{B})\) that contains more than one vertex from \(W\), we now define an admissible decomposition of \(W_B\).

\begin{defn}[Admissible decomposition of a block] \label{def: admissible decomposition}
Let \(B = G(W_B)\) be a block of an admissible graph \(G = (W \cup V, E)\) with \(|W_B| \ge 2\). Consider \(K \ge 1\) subsets \(W_1, \ldots, W_K\) of \(W_B\) with a nontrivial intersection (in the sense that for every $i\in [K], \cup_{j\neq i} W_{i}\cap W_{j}$ is not empty)  such that \(W_B = \cup_{i=1}^K W_i\). We say that \(W_1, \ldots, W_K\) is an \emph{admissible decomposition} of \(W_B\) if the following conditions are satisfied:
\begin{enumerate}
\item[(a)] each subset \(W_i\) contains at least two vertices,
\item[(b)] each of the corresponding subgraph \(G_i = G(W_i)\) induced by \(W_i\) is connected,
\item[(c)] for every \(v \in V_B\), there exists at least one \(V_i\) such that \(\deg_{G_i}(v) \ge 2\),
\item[(d)] for every \(2 \le k \le K\) and distinct \(\ell_1, \ldots, \ell_k \in [K]\), \(|W_{G_{\ell_1}, \ldots, G_{\ell_k}}| \le k-1\).
\end{enumerate}
The set of admissible decompositions of \(W_B\) with \(K\) subsets \(W_1, \ldots, W_K\) is denoted by \(\mathcal{A}_K(W_B)\). Note that \(W_B \in \mathcal{A}_1(W_B)\).
\end{defn}

\begin{ex}[Example~\ref{ex1} continued]
The connected bipartite graph of Figure~\ref{subfig1} is an admissible graph, with its blocks given by the subgraphs \(B_1 = G (W_1)\) and \(B_2 = G(W_2)\) shown in Subfigure~\ref{subfig2}. The subset \(W_1\) has only one admissible decomposition, which is \(W_1\) itself. Thus, \(W_1 \in \mathcal{A}_1(W_1)\). For instance, the decomposition of \(W_1\) by \(W_5\) and \(W_6\), as shown in Figure~\ref{subfig4}, is not admissible. This is because condition (c) is not satisfied: in the induced subgraphs \(G(W_5)\) and \(G(W_6)\), the vertex \(v_2\) has degree \(1\) in each subgraph, whereas condition (c) requires \(\deg_{G_i}(v_2) \ge 2\) for at least on \(G_i = G(W_i)\). The subset \(W_2\) has two admissible decompositions: \(W_2 \in \mathcal{A}_1(W_2)\) and \(W_3, W_4 \in \mathcal{A}_2(W_2)\), where the subsets \(W_3\) and \(W_4\) are illustrated in Figure~\ref{subfig3}. 
\end{ex}

\begin{ex} \label{ex2}
The connected bipartite graph shown in Figure~\ref{fig2} is an admissible graph with three blocks: \(B_1 = G(W_{B_1})\), \(B_2 = G(W_{B_2})\) and \(B_3 = G(W_{B_3})\). These blocks are defined by the subsets \(W_{B_1} = \{w_1\}, W_{B_2} = \{w_2, w_3, w_4, w_5, w_6\}\) and \(W_{B_3} = \{w_7\}\). The block \(B_2\) has two admissible decomposition: the trivial decomposition \(W_{B_2} \in \mathcal{A}_1(W_{B_2})\) and the decomposition with two subsets \(W_1, W_2  \in \mathcal{A}_1(W_{B_2})\), where \(W_1 = \{w_2, w_3, w_4, w_5\}\) and \(W_2 = \{w_3, w_6\}\).
\end{ex}

\begin{figure}
\begin{tikzpicture}

\draw (0,0) circle [radius=1];
\def\nodesA{8}

\foreach \i in {1, ..., \nodesA} {
        
\pgfmathsetmacro\angle{360/\nodesA * \i}
\pgfmathsetmacro\xpos{0 + cos(\angle)}
\pgfmathsetmacro\ypos{0 + sin(\angle)}
     \coordinate (P\i) at (\xpos, \ypos); 
    
  \ifodd\i
           \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \else
           \draw[fill=white]  (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }

\node[above] at (P2) {\tiny $w_2$}  ;
\node[left] at (P4) {\tiny $w_5$}  ;
\node[below] at (P6) {\tiny $w_4$}  ;
\node[left] at (P8) {\tiny $w_3$}  ;
\node[above] at (P1) {\tiny $v_2$}  ;
\node[right] at (P3) {\tiny $v_1$}  ;
\node[below] at (P5) {\tiny $v_4$}  ;
\node[right] at (P7) {\tiny $v_3$}  ;

\pgfmathsetmacro\xangle{cos(135)} 
\pgfmathsetmacro\yangle{sin(135)}
 
\draw (-1.1,1.1)  to[bend right = 40] (\xangle, \yangle);    
\draw (-1.1,1.1)  to[bend left = 40] (\xangle, \yangle);    
\draw[fill=white]  (-1.1,1.1) circle [radius=2pt]; 
\node[above] at  (-1.1,1.1)  {\tiny $w_1$}  ;

\draw (1.5,0) circle [radius=0.5];
\def\nodesB{4}

\foreach \i in {1, ..., \nodesB} {
        
\pgfmathsetmacro\angle{360/\nodesB * \i}
\pgfmathsetmacro\xpos{1.5 + 0.5 * cos(\angle)}
\pgfmathsetmacro\ypos{0.5* sin(\angle)}
         \coordinate (Q\i) at (\xpos, \ypos); 
  \ifodd\i
           \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \else
           \draw[fill=white]  (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }

\node[right] at (Q4) {\tiny $w_6$}  ;
\node[below] at (Q1) {\tiny $v_5$}  ;
\node[below] at (Q3) {\tiny $v_6$}  ;
       
\draw (Q1) to[bend right = 40] (1.5,1);    
\draw (Q1) to[bend left = 40] (1.5,1);    
\draw (1.85,1.35)  to[bend right = 40] (1.5,1);    
\draw (1.85,1.35) to[bend left = 40] (1.5,1); 
\draw (1.15,1.35)  to[bend right = 40] (1.5,1);    
\draw (1.15,1.35) to[bend left = 40] (1.5,1);     

\draw[fill=white]  (1.5,1) circle [radius=2pt]; 
\fill[black]  (1.85,1.35) circle [radius=2pt]; 
\fill[black]  (1.15,1.35) circle [radius=2pt]; 
\node[right] at (1.5,0.9)  {\tiny $w_7$}  ;
\node[left] at  (1.15,1.35)  {\tiny $v_7$}  ;
\node[right] at  (1.85,1.35)  {\tiny $v_8$}  ;

\end{tikzpicture}
\caption{An example of an admissible graph \(G = (W \cup V, E)\) with three blocks. Block \(B_1 = G(\{w_1\})\) is a simple cycle of length \(2\); block \(B_2 = G(\{w_2, w_3, w_4, w_5, w_6\})\) is a cactus graph consisting of two simple cycles connected by the vertex \(w_3\); and block \(B_3 = G(\{w_7\})\) is a double tree. The separating vertices are \(v_1\) and \(v_5\). In particular, \(G\) is a cactus graph. Block \(B_2\) has two admissible decompositions: \(\{w_2, w_3, w_4, w_5, w_6\} \in \mathcal{A}_1(\{w_2, w_3, w_4, w_5, w_6\})\) and \(\{w_2, w_3, w_4, w_5\} , \{w_3, w_6\} \in \mathcal{A}_2(\{w_2, w_3, w_4, w_5, w_6\})\).}
\label{fig2}
\end{figure}


\subsection{Limiting injective trace}

We are now in the position to present the asymptotics of the mean injective trace \(\tau^0_{p,m,n}[T]\) for any bipartite test graph \(T = (W \cup V, E, Y_m)\). We first introduce two important parameters. 
\begin{defn}
For every vertex \(w \in W\) with even degree, we define the parameter \(C_{\deg(w)}(f)\) by
\begin{equation} \label{eq: C_deg (f)} 
\begin{split}
C_{\deg(w)}(f) & = \frac{1}{(2\pi)^{\deg(w)}} \int_{\R^{\deg(w)}} \prod_{i=1}^{\deg(w)/2} \textnormal{d} \gamma_{i}^1 \textnormal{d} \gamma_{i}^2 \hat f(\gamma_{i}^1) \hat f(\gamma_{i}^2)  e^{\E_X \left [ \Phi \left ( \sum_{i=1 }^{\deg(w)/2} (\gamma_{i}^1 + \gamma_{i}^{2}) X_i \right )  \right ]},
\end{split}
\end{equation}
where \(X_1, \ldots, X_{\deg(w)/2}\) are i.i.d.\ random variables distributed according to \(\nu_x\). 
\end{defn}
\begin{defn}
For any subsets \(W_1, \ldots, W_K\) of \(W\) with \(|W_i| \ge 2\), we define the parameter \(C_{(W_i)_{i=1}^K}(f)\) by
\begin{equation} \label{eq: C_{W_i}} 
\begin{split}
C_{(W_i)_{i=1}^K}(f) & = \frac{1}{(2\pi)^{|\cup_i^K E_i|}} \int_{\R^{|\cup_{i=1}^K E_i|}} \prod_{e \in \cup_{i=1}^K E_i} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat{f}(\gamma_e^i) e^{\sum_{w \in \cup_{i=1}^K W_i} \E_X \left [Z_w(\boldsymbol{\gamma})\right ]} \prod_{i=1}^K \E_X \left [ \prod_{w \in W_i} Z_w(\boldsymbol{\gamma}) \right ],
\end{split}
\end{equation}
where for every \(w \in W\), the random variable \(Z_w(\boldsymbol{\gamma})\) is defined by
\begin{equation} \label{eq: Z_w}
Z_w(\boldsymbol{\gamma}) = \Phi \left (  \sum_{v \in V \colon v \sim w } (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))}) X_v \right ), 
\end{equation}
with \((X_v)_{v \in V}\) being i.i.d.\ random variables distributed according to \(\nu_x\). 
\end{defn}

We now present a more detailed version of Theorem~\ref{main2}, formulated as Proposition~\ref{main3}.

\begin{prop}[Theorem~\ref{main2} continued] \label{main3}
The random matrix \(Y_m\) converges in traffic distribution: for every connected bipartite test graph \(T = (W \cup V, E , Y_m)\), it holds that
\[
\lim_{p,m,n \to \infty} \tau^0_{p,m,n} \left [T \right ] = \tau_G^0,
\]
where \(G = (W \cup V , E)\) and \( \tau_G^0 \) depends only on \(\phi, \psi, f, \Phi\), and \(\nu_x\). The limiting injective trace \(\tau_G^0\) is given as follows.
\begin{itemize}
\item[(a)] If \(G\) is a double tree, then
\begin{equation} \label{eq: tau0 double tree}
\qquad \qquad \tau_G^0 = \frac{\phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \prod_{w\in W} C_{\deg(w)}(f).
\end{equation}
\item[(b)] If \(G\) is an admissible graph, then
\begin{equation} \label{eq: tau0 general}
\quad \qquad \tau_G^0  =  
\frac{\phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \prod_{w \in W \backslash \cup_{i=1}^R W_{B_i}} C_{\deg(w)} (f)  \prod_{i=1}^R \left ( \sum_{K \geq 1} \sum_{W_1,\ldots, W_K \in \mathcal{A}_K(W_{B_i})} C_{(W_k)_{k=1}^K}(f)  \right ) .
\end{equation}
\item[(c)] Otherwise, \( \tau_G^0   = 0\).
\end{itemize}
\end{prop} 

\begin{rmk}
A fat tree is a graph that becomes a tree when the multiplicity of the edges is forgotten. In particular, a double tree is a fat tree in which every edge has multiplicity two. From Proposition~\ref{main3}, if \(G\) is a fat tree with edges of multiplicity greater than two, the limiting injective trace \( \tau_G^0 \) vanishes. This behavior contrasts with general heavy-tailed random matrices, where fat trees with edges of even multiplicity give a nonvanishing contribution, as shown in~\cite{male2017heavy}.
\end{rmk}

We present two specific examples of the limiting injective trace of admissible graphs.

\begin{ex} [Example~\ref{ex1} continued]
Let \(G = (W \cup V,E)\) denote the bipartite graph given in Figure~\ref{subfig1}. In this case, the limiting injective trace \(\tau_G^0\) is given by
\[
\tau_G^0= \frac{\phi}{\psi^{11}} C_{W_1}(f) \left (C_{W_2}(f) + C_{W_3,W_4}(f) \right),
\]
where \(W_1 = \{w_1, \ldots, w_4\}, W_2=\{w_5, \ldots, w_{12}\}, W_3 = \{w_5, w_6, w_7, w_8,w_9,w_{10}\}\), and \(W_4 = \{w_5, w_{11}, w_{12}\}\).
\end{ex}

\begin{ex} [Example~\ref{ex2} continued]
Let \(G = (W \cup V,E)\) denote the bipartite graph given in Figure~\ref{fig2}. In this case, the limiting injective trace \(\tau_G^0\) is given by
\[
\tau_G^0= \frac{\phi^2}{\psi^6} C_2(f) C_6(f) \left (C_{W_1}(f) + C_{W_2,W_3}(f) \right),
\]
where \(W_1 = \{w_1, w_2, w_3, w_4, w_5\}, W_2=\{w_1, w_2, w_3, w_4\}\), and \(W_3 = \{w_4,w_5\}\).
\end{ex}

From Proposition~\ref{main3}, we observe that if \(G\) is a double tree, the limiting injective trace \(\tau_G^0\) depends only on the parameter \(C_{\deg(w)}(f)\). Using elementary properties of the Fourier transform,~\eqref{eq: C_deg (f)} is equivalent to
\begin{equation} \label{eq: C_deg} 
C_{\deg(w)}(f) = \frac{1}{(2\pi)^{\deg(w)/2}} \int_{\R^{\deg(w)/2}} \prod_{i=1}^{\deg(w)/2} \textnormal{d} x_i f^2(x_i) \hat{\varphi}(\boldsymbol{x}),
\end{equation}
where \(\varphi(\boldsymbol{t}) = e^{\E_X \left [ \Phi  \left ( \sum_{i=1 }^{\deg(w)/2} t_i X_i \right )\right ]}\). If the weights $W_{ij}$ are symmetric \(\alpha\)-stable random variables (i.e., \(\Phi(x) = - \sigma^\alpha |x|^\alpha\)) and $X_{ij}$ are Gaussian, we note that for \(\deg(w) = 2\), \(\varphi(t)\) corresponds to the characteristic function of a symmetric \(\alpha\)-stable random variable \(S \sim S_\alpha(\sigma \E \left [ |X|^\alpha \right ]^{1/\alpha})\), where \(X \sim \mathcal{N}(0, \sigma_x^2)\). If \(f_S\) denotes its density function, we then have that 
\[
C_2(f) = \int_{\R} f^2(x) f_S(x) \textnormal{d} x = \E \left [ f^2(S)\right ].
\]
In the general case of \(\deg(w) > 2\), we see that
\[
\varphi(\boldsymbol{t}) = e^{- \sigma^\alpha \E \left [ \left |\sum_{i=1 }^{\deg(w)/2} t_i X_i \right |^\alpha \right ]} =  e^{- \sigma^\alpha \left ( \sum_{i=1}^{\deg(w)/2} t_i^2\right)^{\alpha/2} \E \left [ |X|^\alpha \right ] } = e^{- \sigma^\alpha  \E \left [ |X|^\alpha \right ]  |\boldsymbol{t}|^\alpha},
\]
where \(X \sim \mathcal{N}(0, \sigma_x^2)\). This corresponds to the joint characteristic function of the isotropic multivariate stable distribution, see e.g.~\cite{Nolan}. If \(\boldsymbol{S} = (S_1, \ldots, S_{\deg(w)/2}) \in \R^{\deg(w)/2}\) is a random vector having the isotropic multivariate stable distribution and \( f_{\boldsymbol{S}}(\boldsymbol{x})\) denotes its joint probability density function, then
\[
C_{\deg(w)}(f) = \int_{\R^{\deg(w)/2}} \prod_{i=1}^{\deg(w)/2} \textnormal{d} x_i f^2(x_i) f_{\boldsymbol{S}}(\boldsymbol{x}) = \E \left [  \prod_{i=1}^{\deg(w)/2} f^2(S_i)\right ].
\]

\begin{rmk} \label{rmk: C_deg(w) alpha=2}
Consider the special case where \(\alpha = 2\). In this case, both random matrices \(W\) and \(X\) have i.i.d.\ centered Gaussian entries with variances \(\E \left [W_{ij}^2 \right ] = \sigma_w^2\) and \(\E \left [X_{ij}^2 \right ] = \sigma_x^2\). In particular, we have that \(\sigma^2 = \sigma_w^2/2\). From the previous computation~\eqref{eq: C_deg}, the Fourier transform of the Gaussian function \(\varphi(\boldsymbol{t}) = e^{- \sigma_w^2 \sigma_x^2 |\boldsymbol{t}|^2 / 2}\) is given by 
\[
\hat{\varphi}(\boldsymbol{x}) = \left ( \frac{\sqrt{2 \pi}}{\sigma_w \sigma_x} \right )^{\deg(w)/2} e^{- |\boldsymbol{x}|^2 / (2 \sigma_w^2 \sigma_x^2)}, 
\]
leading to
\[
C_{\deg(w)}(f)  = \left (  \frac{1}{\sqrt{2 \pi \sigma_w^2 \sigma_x^2} }  \int_\R f^2(x) e^{- x^2 / (2 \sigma_w^2 \sigma_x^2)} \textnormal{d}x \right)^{\deg(w)/2} = \left ( \E_{Z \sim \mathcal{N}(0, \sigma_w^2 \sigma_x^2)} \left [ f^2(Z) \right ] \right )^{\deg(w)/2}.
\]
As a consequence, if \(G\) is a double tree and if we define \(\theta_1 (f) = \E_{Z \sim \mathcal{N}(0, \sigma_w^2 \sigma_x^2)} \left [ f^2(Z) \right ] \), according to~\eqref{eq: tau0 general} the limiting injective trace \( \tau_G^0 \) results in
\[
 \tau_G^0    = \frac{\phi^{\frac{|E|}{2}-|V|}}{\psi^{|W|-1}} \theta_1(f)^{\sum_{w \in W} \deg(w)/2} =\frac{\phi^{\frac{|E|}{2}-|V|}}{\psi^{|W|-1}}\theta_1(f)^{|W|}.  
\]
We recover formulas similar to~\cite[Theorem 3.5]{benigni2021} for more general traffics in Lemma~\ref{lem: moments alpha=2}.
\end{rmk} 

\subsection{Proof of the convergence of the injective trace} \label{subsection: proof main prop}

This section is devoted to the proof of Proposition~\ref{main3}. We consider a connected bipartite test graph \(T = (W \cup V, E, Y_m)\), where \(E\) is a multiset of edges, and write \(G = (W \cup V, E)\). According to Lemma~\ref{lem: even degree}, we assume that all vertices in \(W \cup V\) have even degree; otherwise, \(\tau^0_{p,m,n}[T]\) is zero for any integers \(p,m,n\). To compute the mean injective trace \(\tau_{p,m,n}^0 \left[T \right]\), we begin from~\eqref{eq: tau0} and expand it as follows:
\begin{equation} \label{eq: tau0 2}
\begin{split}
\tau^0_{p,m,n} \left[T \right] & =   \frac{1}{p} \sum_{\phi_W \colon W \to [p] \atop \phi_W \textnormal{injective}}  \sum_{\phi_V \colon  V \to [m] \atop \phi_V \textnormal{injective}} 
\E \left [\prod_{e = (w,v)\in E} \left (Y_m (\phi_W(w),\phi_V(v)) \right )^{m(e)} \right] \\
& =  \frac{m^{|V| }p^{ |W|}}{p m^{|E|/2}} (1 + \mathcal{O}(m^{-1})) (1 + \mathcal{O}(p^{-1})) \, \E \left [\prod_{e=(w,v) \in E} \left ( f \left ( W_{\phi_W(w)} \cdot  X_{\phi_V(v)}\right )\right )^{m(e)} \right ].
\end{split}
\end{equation}
Since \(f \in L^2 \cap C^\infty\) by Assumption~\ref{hyp2}, the Fourier inversion theorem gives that
\begin{equation} \label{eq: invFourier}
f(x)=\frac{1}{2\pi}\int_{\R} \hat{f}(t) e^{itx} \textnormal{d} t,
\end{equation}
where for any integer number \(\ell\), there exists a finite constant \(C_\ell >0\) such that for every \(t \in \R\),
\begin{equation}\label{thehypf}
|\hat f(t) |\le \frac{C_\ell}{(1+|t|)^\ell}.
\end{equation}
This implies  that for every non-negative real number $M$ and every integer number $\ell$,
\begin{equation}\label{thehypf2}
\int_{[-M,M]^{c}}|\hat f(t) |dt\le C_\ell\int_{[-M,M]^{c}}\frac{1}{(1+|t|)^\ell}dt \le C_\ell \frac{1}{1+ M^{\ell-2}}\int  \frac{1}{(1+|t|)^2}dt =:\frac{C'_{\ell}}{ 1+ M^{\ell-2}}\,.
\end{equation}
Note that, since \(f\) is odd by Assumption~\ref{hyp2}, its Fourier transform \(\hat{f}\) is also odd. Combining~\eqref{eq: tau0 2} and~\eqref{eq: invFourier} and using Assumption~\ref{hyp3}, we obtain the following expression for the mean injective trace: 
\begin{equation} \label{eq: traffic development}
\tau^0_{p,m,n} \left [T \right ] = n^{\rho(G)}  (1 + \mathcal{O}(n^{-1}))  \frac{\phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}}\int_{\R^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i) \Lambda_G^n (\boldsymbol{\gamma}),
\end{equation}
where \(\rho(G)\) is defined by
\begin{equation} \label{eq: rho(G)}
\rho(G) \coloneqq |W| + |V| - \frac{|E|}{2} -1, 
\end{equation}
and for \(\boldsymbol{\gamma} = (\gamma_e^1,\ldots, \gamma_e^{m(e)})_{e \in E}\), \(\Lambda_G^n(\boldsymbol{\gamma})\) is given by 
\[
\begin{split}
\Lambda_G^n(\boldsymbol{\gamma}) & = \E_{W,X} \left[\exp \left ( i \sum_{e = (w,v) \in E} (\gamma_e^1 + \cdots + \gamma_e^{m(e)}) \,W_w \cdot X_v \right ) \right]  \\
& = \E_{W,X} \left[\exp \left ( i \sum_{w \in W} \sum_{k=1}^n W_{wk} \left ( \sum_{v \in V \colon v \sim w } ( \gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))}) X_{kv} \right ) \right ) \right] .
\end{split}
\]
The main challenge in proving Proposition~\ref{main3} lies in estimating \(\Lambda_G^n(\boldsymbol{\gamma})\). To address this, we take the expectation with respect to \(W\), yielding
\begin{equation} \label{eq: lambda}
\Lambda_G^n(\boldsymbol{\gamma}) = \left (\E_X \left [ e^{ n^{-1} \sum_{w \in W} Z_w^n(\boldsymbol{\gamma}) } \right ] \right)^n,
\end{equation}
where 
\[
Z_w^n(\boldsymbol{\gamma}) \coloneqq n \log  \E_W \left [ e^{i W_w \left( \sum_{v \in V \colon v \sim w} (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))}) X_v\right)  }\right ] .
\]
Here, the random variables \((X_v)_{vÂ \in V}\) are i.i.d.\ with distribution \(\nu_x\), and similarly, \((W_w)_{wÂ \in W}\) are i.i.d.\ with distribution \(\nu_w\). Throughout this subsection, we define
\[
S_G^n (\boldsymbol{\gamma}) \coloneqq \sum_{w \in W} Z_w^n(\boldsymbol{\gamma}).
\]
From Assumption~\ref{hyp1}, it follows that \(S_G^n (\boldsymbol{\gamma})\) converges to \(S_G  (\boldsymbol{\gamma}) = \sum_{w \in W} Z_w (\boldsymbol{\gamma})\) as \(n \to \infty\), where 
\[
Z_w  (\boldsymbol{\gamma}) = \Phi \left (  \sum_{v \in V \colon v \sim w} (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))}) X_v \right ).
\]

Next, we wish to expand the right-hand side of~\eqref{eq: lambda} using cumulants. To this end, we first note that we may assume without loss of generality that the \(\gamma_e\)'s are bounded in absolute value by \(n^{\epsilon}\) for some \(\epsilon>0\). Indeed, if we consider the integral in the right-hand side of~\eqref{eq: traffic development}, we notice that the integral
\begin{equation} \label{largegamma}
R_n^{\epsilon}= \int (\mathbf{1}_{\R^{|E|}} - \mathbf{1}_{[-n^{\epsilon},n^{\epsilon}]^{|E|}}) \prod_{e \in E} \textnormal{d} \gamma_e^1 \cdots \textnormal{d} \gamma_e^{m(e)}\hat f(\gamma_e^1) \cdots \hat f(\gamma_e^{m(e)})  \Lambda_G^n(\boldsymbol{\gamma})
\end{equation} 
{
can be easily bounded since \(S_G^n(\boldsymbol{\gamma})\) has a non-negative real part so that \(\Lambda_G^n(\boldsymbol{\gamma})\) has modulus bounded by one, and since by hypothesis~\eqref{thehypf} and~\eqref{thehypf2} implies that for every integer number \(\ell \ge 2\), we can find finite constants \(C_2', C_\ell'>0\) such that
\[
\begin{split}
|R_n^\epsilon | & \leq \sum_{k=1}^{|E|} {|E| \choose k} \left(\int_{[-n^{\epsilon},n^{\epsilon}]^\textnormal{c}} |\hat{f}(t)| \textnormal{d} t\right)^k \left(\int_\R  |\hat{f}(t)| \textnormal{d} t \right)^{|E|-k} \\
&\le \sum_{k=1}^{|E|} {|E| \choose k} (C_{\ell}')^k (1 + n^{\epsilon (\ell-2)})^{-k} (C_2')^{|E|-k}  = (C_2')^{|E|}\left((1+\frac{C_{\ell}'}{C_2' (
1 + n^{\epsilon (\ell-2)})})^{|E|}-1\right).
 \end{split}
 \]
This quantity is as small as wished (negligible with respect to \(n^{-\rho(G)}\)), provided \(\ell\) and $n$ are sufficiently large. When the \(\gamma_i\)'s are bounded by \(n^{\epsilon}\), then \(\Lambda_G^n(\boldsymbol{\gamma})^{1/n} =  \E_X \left [\exp \left ( n^{-1} S_G^n(\boldsymbol{\gamma}) \right ) \right ]\) corresponds to the Fourier transform of random variables with finite exponential moments which are taken in the region where their parameters go to zero. We can therefore expand \(\Lambda_G^n(\boldsymbol{\gamma})\) in terms of its cumulants. 

The \(\ell\)-th cumulant \(\kappa_\ell^G\) of \(S_G^n(\boldsymbol{\gamma})\) is defined by
\begin{equation} \label{eq: cumulant}
\kappa_\ell^G (\boldsymbol{\gamma}) = \sum_{\pi \in \mathcal{P}_\ell} \mu(\pi) \prod_{i=1}^{|\pi|} \E \left [ \left (S_G^n(\boldsymbol{\gamma})\right)^{|B_i|} \right ],
\end{equation}
where the sum runs over the set of partitions \(\mathcal{P}_\ell\) of the set \(\{1, \ldots, \ell\}\), the product runs over the blocks \(B_1, \ldots, B_{|\pi|}\) of the partition \(\pi\) and \(\mu(\pi) = (-1)^{|\pi|-1} (|\pi| -1)!\). Moreover, \(|B_i|\) denotes the number of elements of the block \(B_i\) and \(|\pi|\) is the number of blocks in the partition. Since the cumulants \(\kappa_\ell^G(\boldsymbol{\gamma})\) are the coefficients in the power series expansion of the cumulant generating function, i.e., for every \(t \in \R\),
\[
\E_X \left [ e^{t S_G^n(\boldsymbol{\gamma})} \right ] = \exp \left ( \sum_{i = 1}^\infty \kappa_i^G (\boldsymbol{\gamma}) \frac{t^i}{i!} \right ),
\]
it then follows from~\eqref{eq: lambda} that
\begin{equation} \label{eq: Lambda}
\begin{split}
\Lambda_G^n(\boldsymbol{\gamma}) &  = e^{\kappa_1^G (\boldsymbol{\gamma})} \exp \left \{ \sum_{i \geq 2} \frac{1}{i ! n^{i -1 }} \kappa_i^G(\boldsymbol{\gamma}) \right \}= e^{\E_X \left [ S_G^n(\boldsymbol{\gamma}) \right]} \sum_{m_2, m_3, \ldots \geq 0} \prod_{\ell \ge 2} \frac{1}{m_\ell!} \left ( \frac{1}{\ell ! n^{\ell -1 }} \kappa_\ell^G(\boldsymbol{\gamma}) \right ) ^{m_\ell}.
\end{split}
\end{equation}
Since the sum \(S_G^n\) has all finite exponential moments when the \(\gamma_i\)'s are bounded by \(n^\epsilon\), we easily see that by Taylor expansion the above expansion holds also asymptotically up to the cumulants of order \(i\) with an error of order \((n^{\epsilon-1})^i\), which we can again neglect provided \(i(1-\epsilon)>\rho(G)\). The second expansion, which amounts to expand the exponential function, can also be stopped as \(m_\ell\) is smaller than \(\rho(G)\) up to an error smaller than \(n^{-\rho(G)}\), provided \(\epsilon\) is small enough. In the sequel, we write the expansion as infinite, having in mind that we can stop it to the finite  set of integer numbers \(m_\ell, \ell \ge 2\) so that \(\sum_{\ell \geq 2} m_{\ell}(\ell-1)\le \rho(G)\), up to a negligible error. 

We now present our expansion for \(\Lambda_G^n (\boldsymbol{\gamma})\). In the following lemma, for any subset \(E_0 \subseteq E\), let \(T_{E_0}\) denote the map on \(\R^{|E|}\) that changes \(\gamma_e^i\) into \(-\gamma_e^i\) for every \(i\in \{1,\ldots,m(e)\}\) and every \(e\in E_0\), while leaving the other entries unchanged. 

\begin{lem} \label{lem: main estimate}
Let \(G = (W \cup V, E)\) be a connected bipartite graph in which all vertices have even degree. Then, for every \(\epsilon>0\), 
\[
\Lambda_G^n(\boldsymbol{\gamma}) = e^{\E_X \left [ S_G^n(\boldsymbol{\gamma})\right ]}  \left ( 1 + h_G^n(\boldsymbol{\gamma}) + \frac{1}{n^{\rho(G)}} g_G^n(\boldsymbol{\gamma})  \mathbf{1}_{\{G \, \textnormal{is an admissible graph}\}}+ o \left (\frac{1}{n^{\rho(G)}} \right)  \right).
\]
Here, \(n^{\rho(G)}o \left (\frac{1}{n^{\rho(G)}} \right)\) goes to zero  uniformly on \(\|\gamma\|_{\infty}\le n^{\epsilon}\), \(h_G^n(\boldsymbol{\gamma})\) is a (finite) sum of functions which are invariant under \(T_{E_0}\) for some subset \(E_0 \subseteq E\) with odd cardinality \(|E_0|\), and \(g_G^n(\boldsymbol{\gamma}) \) is given by
\begin{equation} \label{eq: g_G^n}
g_G^n(\boldsymbol{\gamma}) = \prod_{i=1}^R \left ( \sum_{K \geq 1} \sum_{W_1,\ldots, W_K \in \mathcal{A}_K (W_{B_i})} \prod_{k =1}^K \E_X \left [ \prod_{w \in W_k} Z_w^n(\boldsymbol{\gamma})\right ] \right).
\end{equation}
\end{lem}

Having Lemma~\ref{lem: main estimate} at hand, we now prove Proposition~\ref{main3}. 

 \begin{proof}[\textbf{Proof of Proposition~\ref{main3}}]
From~\eqref{eq: traffic development} and~\eqref{largegamma}, it follows that
\[
\tau^0_{p,m,n} \left [ T \right ]= \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}}\left(n^{\rho(G)} \int_{[-n^{\epsilon},n^{\epsilon}]^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i) \Lambda_G^n(\boldsymbol{\gamma}) + o(1)\right).
\]
Plugging the estimate of \(\Lambda_G^n\) given by Lemma~\ref{lem: main estimate} into the above expression yields
\[
\tau_p^0 \left [T \right ]=  I^n_1 (G) +  I^n_2 (G) + I^n_3(G) + o(1),
\]
where
\[
\begin{split}
I^n_1 (G) & = \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}} n^{\rho(G)} \int_{[-n^{\epsilon},n^{\epsilon}]^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i)  e^{\E_X \left [ S_G^n(\boldsymbol{\gamma})\right ]},  \\
I^n_2 (G) &= \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}} \int_{[-n^{\epsilon},n^{\epsilon}]^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i)  e^{\E_X \left [ S_G^n(\boldsymbol{\gamma})\right ]} h_G^n (\boldsymbol{\gamma}),\\
I^n_3 (T) &= \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}} \int_{[-n^{\epsilon},n^{\epsilon}]^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i)  e^{\E_X \left [ S_G^n(\boldsymbol{\gamma})\right ]} g_G^n (\boldsymbol{\gamma})  \mathbf{1}_{\{G \, \textnormal{is an admissible graph}\}},
\end{split}
\]
and we also observe that
\[
\left|\int_{[-n^{\epsilon},n^{\epsilon}]^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i) e^{\E_X \left [ S_G^n (\boldsymbol{\gamma}) \right ]} \right| \le \left(\int_{[-n^{\epsilon},n^{\epsilon}]}|\hat f(\gamma_e)| \textnormal{d} \gamma_{e}\right)^{|E|}
\]
is finite so that the error terms in \(\Lambda_G^n(\boldsymbol{\gamma})\) become error terms in \(\tau^0_{p,m,n} \left [T \right ]\). 

We first claim that \(I^n_2 (G)\) vanishes for all integers \(n\). Since the law of \(X_v\) is symmetric, the expectation \(\E_X \left [S_G^n(\boldsymbol{\gamma}) \right ]\) does not depend on the sign of \(\sum_{i=1}^{m((w,v))} \gamma_{(w,v)}^i\) for every \(v\in V\) and \(w\in W\) such that \(v \sim w\). In particular, applying \(T_{E_0}\) with \(E_0 = (w,v)\), we find that
\[
\E_X \left [ S_G^n(\boldsymbol{\gamma}) \right ]=\E_X \left [S_G^n(T_{{(w,v)}}(\boldsymbol{\gamma})) \right ].
\]
Since \(h_G^n\) is a finite sum of functions which are left invariant under some \(T_{E_0}\), if we take such a function, say \(h\), we then notice that since \( \E_X \left [ S_G^n(\boldsymbol{\gamma})\right ]\) is left invariant under \(T_{E_0}\) and since \(\hat{f}\) is odd by Assumption~\ref{hyp2}, the change of variables \(T_{E_0}\) shows that the integral
\[
\begin{split}
& \int_{[-n^{\epsilon},n^{\epsilon}]^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i) e^{\E_X \left [ S_G^n (\boldsymbol{\gamma}) \right ]}  h(\boldsymbol{\gamma})\\
& \quad = (-1)^{|E_{0}|}\int_{[-n^{\epsilon},n^{\epsilon}]^{|E|}} \prod_{e \in E}  \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i) e^{ \E_X \left [ S_G^n (\boldsymbol{\gamma})\right ]}  h(\boldsymbol{\gamma}).
\end{split}
\]
vanishes as \(|E_0|\) is odd. The same is true for \(h_G^n\), yielding \(I^n_2 (G) = - I^n_2(G)\), which gives that the integral \(I^n_2(G)\) vanishes. 

We now focus on \(I^n_1 (G)\) and observe that if there is an edge \(e_0 \in E\) with odd multiplicity \(m(e_0)\), then the integral 
\[
\int_{[-n^\epsilon, n^\epsilon]^{|E|}} \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i) e^{\E_X \left [ S_G^n (\boldsymbol{\gamma}) \right ]}
\]
vanishes for all \(n\) by the same reasoning as above using the change of variables \(T_{e_0}\). Therefore, \(I^n_1(G)\) is nonzero only if all edges in \(G\) have even multiplicity. In this case, we claim that \(\rho(G) \leq 0\) with equality if and only if all edges \(e \in E\) have multiplicity \(m(e)\) equal to \(2\). Let \(\tilde{G} = (W \cup V, \tilde{E})\) denote the graph obtained from \(G\) by forgetting the multiplicity of the edges. Since \(G\) is a connected graph, so is \(\tilde{G}\), and it holds that \(|W| + |V| \leq |\tilde{E}| + 1\), with equality if and only if \(\tilde{G}\) is a tree. Since all edges in \(G\) have even multiplicity, \(|E| \geq 2 |\tilde{E}|\), ensuring that \(\rho(G) = |W| + |V| - |E|/2 - 1 \leq 0\). Hence, we have shown that \(\rho(G) = 0\) if and only if \(\tilde{G}\) is a tree and all edges in \(G\) have multiplicity equal to \(2\). If \(\rho(G)<0\), \(\tau^0_1 \left [T \right ]\) goes to zero as the integral is uniformly bounded by~\eqref{thehypf}. If \(\rho(G)=0\), we can replace the integral over \([-n^{\epsilon},n^{\epsilon}]^{|E|}\) by \(\R^{|E|}\) by the same argument as in~\eqref{largegamma}. We deduce that
\[
I^n_1(G) =
\begin{cases}
\frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}} \int_{\R^{|E|}} \prod_{e \in E} \prod_{i=1}^2 \textnormal{d} \gamma_e^i \hat f(\gamma_e^i)  e^{ \sum_{w \in W} \E_X \left [ Z_w(\boldsymbol{\gamma}) \right ]} + o(1) & \text{if} \enspace G \enspace \text{is a double tree},\\
o(1) & \text{otherwise},
\end{cases}
\]
where we also used the fact that \(S_G^n(\boldsymbol{\gamma})\) converges to \(\sum_{w \in W} Z_w(\boldsymbol{\gamma})\) from Assumption~\ref{hyp1}, where \(Z_w(\boldsymbol{\gamma})\) is given by
\[
Z_w (\boldsymbol{\gamma}) = \Phi \left ( \sum_{v \in V \colon v \sim w} \left ( \gamma_{(w,v)}^1 +  \gamma_{(w,v)}^2 \right) X_v \right ).
\]

It remains to estimate \(I^n_3(G)\), which is zero if \(G\) is non-admissible, and otherwise is given by 
\[
I^n_3(G) = \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}} \int_{\R^{|E|}} \prod_{e \in E}  \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i)  e^{\E_X \left [ S_G^n(\boldsymbol{\gamma})\right ]} g_G^n(\boldsymbol{\gamma}).
\]
According to Assumption~\ref{hyp1}, we have that \(S_G^n (\boldsymbol{\gamma}) = \sum_{w \in W} \E_X \left [ Z_w^n (\boldsymbol{\gamma})\right ]\) converges towards \(S_G(\boldsymbol{\gamma} = \sum_{w \in W} \E_X \left [ Z_w (\boldsymbol{\gamma})\right ]\), where \(Z_w(\boldsymbol{\gamma})\) is defined by~\eqref{eq: Z_w}. Similarly, \(g_G^n (\boldsymbol{\gamma})\) converges towards
\begin{equation} \label{eq: function g_G}
g_G (\boldsymbol{\gamma})  = \prod_{i=1}^R \left ( \sum_{K \geq 1} \sum_{W_1,\ldots, W_K \in \mathcal{A}_K (W_{B_i})} \prod_{k =1}^K \E_X \left [ \prod_{w \in W_k} Z_w(\boldsymbol{\gamma})\right ] \right).
\end{equation}
In particular, we find that
\[
\begin{split}
I^n_3(G) & = \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2\pi)^{|E|}} \int_{\R^{|E|}} \prod_{e \in E}  \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i)  e^{\E_X \left [ S_G(\boldsymbol{\gamma})\right ]} g_G(\boldsymbol{\gamma})  + o(1) \\
& =  \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}} \frac{1}{(2 \pi)^{|E \backslash \cup_{i=1}^R E_i|}} \int_{\R^{|E \backslash \cup_{i=1}^R E_i|}} \prod_{e \in E \backslash \cup_{i=1}^R E_i} \prod_{i=1}^2 \textnormal{d} \gamma_e^i  \hat f(\gamma_e^i) e^{\sum_{w \in W \backslash \cup_{i=1}^R W_{B_i}} \E_X \left [ Z_w (\boldsymbol{\gamma}) \right ]} \\
& \quad \times  \prod_{i=1}^R  \frac{1}{(2\pi)^{|E_{B_i}|}} \int_{\R^{|E_{B_i}|}} \prod_{e \in E_{B_i}}  \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i)  e^{\sum_{w \in W_{B_i}} \E_X \left [ Z_w (\boldsymbol{\gamma})\right ]} \\
& \qquad \qquad \qquad \qquad  \times  \left ( \sum_{K \ge 1} \sum_{W_1, \ldots, W_K \in \mathcal{A}_K(W_{B_i})} \prod_{k=1}^K \E_X \left [ \prod_{w \in W_i} Z_w (\boldsymbol{\gamma})  \right] \right) + o(1) \\
& = \frac{ \phi^{\frac{|E|}{2} - |V|}}{\psi^{|W|-1}}  \prod_{w \in W \backslash \cup_{i=1}^R W_{B_i}} C_{\deg(w)} (f) \prod_{i=1}^R \left ( \sum_{K \ge 1} \sum_{W_1, \ldots, W_K \in \mathcal{A}_K(W_{B_i})}  C_{(W_k)_{k=1}^K}(f)  \right ) + o(1),
\end{split}
\]
as desired.
\end{proof}

It remains to prove the crucial expansion of \(\Lambda_G^n\) stated in Lemma~\ref{lem: main estimate}. To prove this result, we will use the combinatorial estimates from Section~\ref{section: combinatorics}. 

\begin{proof}[\textbf{Proof of Lemma~\ref{lem: main estimate}}]
We now give the proof of Lemma~\ref{lem: main estimate}, based on some key combinatorial estimates provided in Section~\ref{section: combinatorics}. We again write series formally, as we have already discussed how to truncate them and control the reminder terms. According to~\eqref{eq: Lambda}, \(\Lambda_G^n\) is given by
\[
\Lambda_G^n(\boldsymbol{\gamma})=  e^{\E_X \left [ S_G^n(\boldsymbol{\gamma}) \right ]} \left ( 1 + \sum_{m_2 + m_3 + \cdots \geq 1} \prod_{\ell \geq 2} \frac{1}{m_\ell!}\left ( \frac{(- \sigma^\alpha)^{\ell}}{\ell! n^{\ell-1}}\kappa_\ell^G(\boldsymbol{\gamma}) \right )^{m_\ell} \right ).
\]
The product of cumulants in the above display can be written as 
\begin{equation} \label{eq: prod cumulants}
\prod_{\ell \geq 2} \frac{1}{m_\ell!}\left ( \frac{1}{\ell! n^{\ell-1}}\kappa_\ell^G(\boldsymbol{\gamma}) \right )^{m_\ell} = \prod_{k=1}^K  \left ( \frac{1}{\ell_k! n^{\ell_k-1}}\kappa_{\ell_k}^G(\boldsymbol{\gamma}) \right ),
\end{equation}
where 
\begin{itemize}
\item \(K = \sum_{\ell \geq 2} m_\ell \geq 1\), 
\item \(\sum_{k=1}^K \ell_k = \sum_{\ell \geq 2} \ell m_\ell\), 
\item \(\ell_k = 2\) for \(k \in \{1, \ldots, m_2\}\), \(\ell_k = 3\) for \(k \in \{m_2+1, \ldots, m_2+m_3\}\), and so on, i.e., 
\[
\ell_k = \ell \geq 2 \quad \textnormal{for} \enspace k \in \left \{ \sum_{i=2}^{\ell-1} m_i +1, \ldots, \sum_{i=2}^\ell m_i \right \}.
\]
\end{itemize}
We therefore have that 
\begin{equation} \label{eq: Lambda 2}
\Lambda_G^n(\boldsymbol{\gamma}) = e^{\E_X \left [ S_G^n(\boldsymbol{\gamma}) \right ]}   \left ( 1 + \sum_{K\geq 1\atop
\ell_{i}\ge 2, 1\le i\le K }  \prod_{k=1}^K  \left ( \frac{1}{\ell_k! n^{\ell_k-1}}\kappa_{\ell_k}^G(\boldsymbol{\gamma}) \right )\right ).
\end{equation}
We need to estimate the product \(\prod_{k=1}^K \kappa_{\ell_k}^G(\boldsymbol{\gamma})\) in~\eqref{eq: Lambda 2}. According to the definition of cumulant given by~\eqref{eq: cumulant} and the fact that \(S_G^n (\boldsymbol{\gamma}) = \sum_{w \in W} Z_w^n(\boldsymbol{\gamma})\), we can expand \(\kappa_\ell^G\) as follows:
\begin{equation} \label{eq: expansion cumulant}
\kappa_\ell^G (\boldsymbol{\gamma}) = \sum_{\pi \in \mathcal{P}_\ell} \mu(\pi) \prod_{i =1}^{|\pi|} \sum_{w_1^i, \ldots, w_{|B_i|}^i \in W} \E_X \left [ \prod_{j=1}^{|B_i|} Z_{w_j^i}^{n}(\boldsymbol{\gamma})\right ],
\end{equation}
where \(B_1, \ldots, B_{|\pi|}\) are the blocks of \(\pi\). For every \(1 \leq i \leq |\pi|\), we then note that
\begin{equation} \label{eq: expansion cumulant 2}
\sum_{w^i_1, \ldots, w^i_{|B_i|} \in W}  \E_X \left [\prod_{j=1}^{|B_i|}Z_{w^i_j}^{n}(\boldsymbol{\gamma}) \right ] = \sum_{W_i} \sum_{\boldsymbol{\eta}_{W_i}} \frac{|B_i| ! }{\prod_{w \in W_i} \eta_{W_i}(w)! } \E_X \left [\prod_{w \in W_i} \left(Z_w^n(\boldsymbol{\gamma})\right)^{\eta_{W_i}(w)} \right ],
\end{equation}
where the first summation is over a subset \(W_i\) of \(W\) such that \(|W_i| \leq |B_i|\) and the second summation is over a sequence \(\boldsymbol{\eta}_{W_i} = (\eta_{W_i}(w))_{w \in W_i} \in \N^{|W_i|}\) such that \(\sum_{w \in W_i} \eta_{W_i}(w) = |B_i|\). We observe that if \(\eta_{W_i}(w)= 1\) for every \(w \in W_i\), then \(|W_i| = |B_i|\). Moreover, we have that
\[
\sum_{i=1}^{|\pi|} \sum_{w \in W_i} \eta_{W_i}(w) = \sum_{i=1}^{|\pi|} |B_i| = \ell.
\]
It then follows from~\eqref{eq: expansion cumulant} and~\eqref{eq: expansion cumulant 2} that the \(\ell\)-th cumulant \(\kappa_\ell^G\) is given by 
\begin{equation} \label{eq: cumulant development}
\kappa_\ell^G (\boldsymbol{\gamma}) =  \sum_{\pi \in \mathcal{P}_\ell} \mu(\pi) \sum_{W_1, \ldots, W_{|\pi|}} \sum_{\boldsymbol{\eta}_{W_1},\ldots, \boldsymbol{\eta}_{W_{|\pi|}}}  \prod_{i=1}^{|\pi|} \frac{|B_i| ! }{\prod_{w \in W_i} \eta_{W_i}(w)! } \E_X \left [\prod_{w \in W_i} \left (Z_w^n(\boldsymbol{\gamma})\right)^{\eta_{W_i}(w)} \right ].
\end{equation}
From~\eqref{eq: cumulant development} we therefore obtain that 
\begin{equation} \label{eq: prod cumulant}
\hspace{-0.3cm} \prod_{k=1}^K \left ( \frac{1}{n^{\ell_k-1}}\kappa_{\ell_k}^G(\boldsymbol{\gamma}) \right ) =  \frac{1}{n^{ \sum_{k=1}^K (\ell_k -1)}}  \sum_{\pi_1, \ldots, \pi_K} \mu(\pi_1) \cdots \mu(\pi_K) \sum_{\boldsymbol{W}^1, \ldots, \boldsymbol{W}^K} \sum_{\boldsymbol{\eta}^1, \ldots, \boldsymbol{\eta}^K} P_{(\pi_k, \boldsymbol{W}^k, \boldsymbol{\eta}^k)_{k=1}^K}(\boldsymbol{\gamma}),
\end{equation}
where
\begin{itemize}
\item[(i)] the first summation is over partitions \(\pi_k \in \mathcal{P}_{\ell_k}\) with blocks \(B_1^k, \ldots, B_{|\pi_k|}^k\) for \(k\in\{1,\ldots,K\}\);
\item[(ii)] the second summation is over \(\boldsymbol{W}^1, \ldots, \boldsymbol{W}^K\), where each \(\boldsymbol{W}^k\) denotes \(\boldsymbol{W}^k= \{W^k_i, 1 \leq i \leq |\pi_k|\}\) and \(W^k_1,\ldots, W^k_{|\pi_k|}\) are subsets of \(W\) such that \(|W_i^k| \leq  |B_i^k|\),
with equality if \(\eta_{W_i^k}(w) = 1\) for every \(w \in W_i^k\);
\item[(iii)] the third summation is over \(\boldsymbol{\eta}^1, \ldots,\boldsymbol{\eta}^K\), where each \(\boldsymbol{\eta}^k\) denotes \(\boldsymbol{\eta}^k= \{ \boldsymbol{\eta}_{W^k_i}, 1 \leq i \leq |\pi_k|\}\) and \(\boldsymbol{\eta}_{W^k_i} = (\eta_{W_i^k}(w))_{w \in W_i^k}  \in \N^{|W_i^k|}\) for every \(i \in [|\pi_k|]\) such that \(\sum_{w \in W^k_i} \eta_{W_i^k}(w)  = |B_i^k|\);
\item[(iv)] the term \(P_{(\pi_k, \boldsymbol{W}^k, \boldsymbol{\eta}^k)_{k=1}^K}(\boldsymbol{\gamma})\) is given by
\begin{equation} \label{eq: product}
P_{(\pi_k, \boldsymbol{W}^k, \boldsymbol{\eta}^k)_{k=1}^K}(\boldsymbol{\gamma}) = \prod_{k=1}^K \prod_{i=1}^{|\pi_k|} \frac{|B_i^k| ! }{\prod_{w \in W_i^k} \eta_{W_i^k}(w)! }  \E_X \left [ \prod_{w \in W^k_i} \left (Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_{W_i^k}(w)} \right ].
\end{equation}
\end{itemize}
Since the subgraph \(G(W_i^k)\) associated to \(W_i^k\) is not necessarily connected, the expectation in~\eqref{eq: product} may factorize. We therefore decompose  \(\boldsymbol{W}^k = \{W_i^k, 1 \leq i \leq |\pi_k|\}\) as \(\widetilde{\boldsymbol{W}}^k = \{\tilde{W}^k_i, 1 \leq i \leq r(\pi_k)\}\), where \(|\pi_k| \leq r(\pi_k)\) and \(\cup_{i=1}^{|\pi_k|} W_i^k = \cup_{i=1}^{r(\pi_k)} \tilde{W}_i^k\), so that the subgraph \(G(\tilde{W}^k_i)\) associated to \(\tilde{W}^k_i\) is connected. By definition we also have that 
\begin{equation} \label{eq: tilde W_i^k}
\sum_{i=1}^{|\pi_k|} |W_i^k| = \sum_{i=1}^{r(\pi_k)} |\tilde{W}_i^k|. 
\end{equation}
In the following, we let \(r =\sum_{k=1}^K r(\pi_{k})\) denote the number of subsets \(\{\tilde{W}_i^k, 1 \leq i \leq r(\pi_k), 1 \leq k \leq K\}\) and we write \(\{\tilde{W}_i, 1\le i\le r\} = \{\tilde{W}_i^k, 1 \le i \le r(\pi_k), 1\le k\le K\}\) to simplify notation slightly. We also denote by \(\tilde{\boldsymbol{\eta}}_{\tilde{W}_i^k} = (\tilde{\eta}_{\tilde{W}_i^k}(w) )_{w \in \tilde{W}_i^k}\) the sequence given by \(\tilde{\eta}_{\tilde{W}_j^k}(w) = \eta_{W_i^k}(w)\) for \(w \in W_i^k \cap \tilde{W}_j^k\) and we write \(\{\tilde{\boldsymbol{\eta}}_i, 1 \leq i \leq r\} = \{\tilde{\boldsymbol{\eta}}_{\tilde{W}_i^k}, 1 \leq i \leq r(\pi_k), 1 \leq k \leq K\}\). We then rewrite the product~\eqref{eq: product} in (d) as
\[
P_{(\pi_k, \boldsymbol{W}^k, \boldsymbol{\eta}^k)_{k=1}^K}(\boldsymbol{\gamma}) = \prod_{k=1}^K \prod_{i=1}^{|\pi_k|} \frac{|B_i^k| ! }{\prod_{w \in W_i^k} \eta_{W_i^k}(w)! } 
P_{(\tilde{W}_i, \tilde{\boldsymbol{\eta}}_i)_{i=1}^r}(\boldsymbol{\gamma}),
\]
where \(P_{(\tilde{W}_i, \tilde{\boldsymbol{\eta}}_i)_{i=1}^r}(\boldsymbol{\gamma})\) is given by
\[
P_{(\tilde{W}_i, \tilde{\boldsymbol{\eta}}_i)_{i=1}^r} (\boldsymbol{\gamma})= \prod_{i=1}^r \E_X \left [ \prod_{w \in \tilde{W}_i} \left (Z_w^n(\boldsymbol{\gamma}) \right)^{\tilde{\eta}_i(w)}\right ]
\]
and \(\tilde{\boldsymbol{\eta}}_i = \{\tilde{\eta}_i(w), w \in \tilde{W}_i\}\).

We next study the right hand side of \eqref{eq: prod cumulant} using Section~\ref{section: combinatorics} and in particular Proposition~\ref{prop: combinatorics}. Since in Section~\ref{section: combinatorics} we consider connected subgraphs of \(G\), we can apply the results of Section~\ref{section: combinatorics} to the subsets \(\tilde{W}_1,\ldots, \tilde{W}_r\) since by definition the associated subgraphs \(G(\tilde{W}_1),\ldots, G(\tilde{W}_r)\) are connected. According to Proposition~\ref{prop: combinatorics}, if \(\tilde{W}_1, \ldots, \tilde{W}_r \notin \mathcal{W}_r\), then either \(P_{(\tilde{W}_i, \tilde{\boldsymbol{\eta}}_i)_{i=1}^r}(\boldsymbol{\gamma})\) is invariant under \(T_{E_0}\) for some \(E_0 \subset E\) with odd cardinality \(|E_0|\) and we can add this term to \(h_n\), or 
\[
\rho(G) = |W| + |V| - \frac{|E|}{2} - 1 < \sum_{i=1}^r (|\tilde{W}_i|-1).
\]
Since \(\sum_{i=1}^r |\tilde{W}_i| =  \sum_{k=1}^K \sum_{i=1}^{r(\pi_k)} |\tilde{W}_i^k| =  \sum_{k=1}^K \sum_{i=1}^{|\pi_k|} |W_i^k|\) by~\eqref{eq: tilde W_i^k} and since \(|W_i^k| \leq |B_i^k|\) by item (b), we have that 
\[
\sum_{i=1}^r (|\tilde{W}_i|-1) = \sum_{k=1}^K \left( \sum_{i=1}^{r(\pi_k)} |\tilde{W}_i^k| - r(\pi_k) \right ) = \sum_{k=1}^K \left( \sum_{i=1}^{|\pi_k|} |W_i^k| - r(\pi_k) \right ) \leq \sum_{k=1}^K \left( \sum_{i=1}^{|\pi_k|} |B_i^k| - |\pi_k| \right ) ,
\]
yielding 
\[
\sum_{i=1}^r (|\tilde{W}_i|-1)  \leq \sum_{k=1}^{K} \left( \ell_k-1 \right),
\]
where we used that \(\ell_k = \sum_{i=1}^{|\pi_k|} |B_i^k| \) by item (a) and that \(|\pi_k| \geq 1\). This means that if \(\rho(G) < \sum_{i=1}^r (|\tilde{W}_i|-1)\), then \(\rho(G) < \sum_{k=1}^{K} \left( \ell_k-1 \right)\), showing that this term will provide an error term in \(g_n\), see \eqref{eq: prod cumulant}. If \(\tilde{W}_1, \ldots, \tilde{W}_r \in \mathcal{W}_r\), it then follows from Proposition~\ref{prop: combinatorics} that \(\rho(G) = \sum_{i=1}^r (|\tilde{W}_i|-1)\) and by the argument above we have that
\[
\rho(G) = \sum_{i=1}^r (|\tilde{W}_i|-1) \leq \sum_{k=1}^K (\ell_k-1),
\] 
with equality if \(|W_i^k| = |B_i^k|\) (i.e., if \(\eta_{W_i^k}(w)=1\) for each \(w \in W_i^k\) by (b)) and \(r(\pi_k) = |\pi_k| =1\). This implies that in~\eqref{eq: prod cumulant} the sum simplifies drastically and we may only consider trivial  partitions which are the full set, i.e., \(\pi_k = \{\{1, \ldots, \ell_k\}\}\) for all \(k \in [K]\). The main contribution to \(\Lambda_G^n\)  is therefore given by subsets \(W_1,\ldots, W_K \in \mathcal{W}_{K}\), where we write \(W_1^k = W_k\) for every \(k \in [K]\) and \(|W_k|=\ell_k \ge 2\). From~\eqref{eq: prod cumulant} we then have that 
\[
\begin{split}
& \sum_{K \geq 1 \atop \ell_i \ge 2, 1 \leq i \leq K} \prod_{k=1}^K  \left ( \frac{1}{\ell_k! n^{\ell_k-1}}\kappa_{\ell_k}^G(\boldsymbol{\gamma}) \right ) \\
& \quad = h_G^n(\boldsymbol{\gamma}) + \frac{1}{n^{\rho(G)}} \sum_{K\ge 1} \sum_{W_1,\ldots, W_K \in \mathcal{W}_K} \prod_{k=1}^K \E_X \left [ \prod_{w \in W_k} Z_w^n(\boldsymbol{\gamma}) \right ] + o\left ( \frac{1}{n^{\rho(G)}} \right ), 
\end{split}
\]
where the error \(o\left ( \frac{1}{n^{\rho(G)}} \right )\) is uniform when \(\|\gamma\|_{\infty}\le n^\epsilon\). This yields 
\[
\begin{split}
\Lambda_G^n(\boldsymbol{\gamma}) & = e^{\E_X \left [ S_G^n(\boldsymbol{\gamma}) \right ]} \left ( 1 + h_G^n (\boldsymbol{\gamma}) +  \frac{1}{n^{\rho(G)}} \sum_{K\geq 1}  \sum_{W_1,\ldots, W_K \in \mathcal{W}_K} P_{(W_k)_{k=1}^K}(\boldsymbol{\gamma}) + o\left ( \frac{1}{n^{\rho(G) }} \right ) \right ),
\end{split}
\]
where \(h_G^n (\boldsymbol{\gamma})\) is a sum of functions which invariant under \(T_{E_0}\)  for some \(E_0 \subset E\) such that \(|E_0|\) is odd and \(P_{(W_k)_{k=1}^K}(\boldsymbol{\gamma})\) is given by \(P_{(W_k)_{k=1}^K}(\boldsymbol{\gamma})= \prod_{k=1}^K \E_X \left [ \prod_{w \in W_k} Z_w^n(\boldsymbol{\gamma}) \right ]\). Finally, from Lemma~\ref{lem: equiv def}, the connected bipartite multigraphs \(G = (W \cup V, E)\) in which all vertices have even degree and for which there exists a collection \(W_1, \ldots, W_K \in \mathcal{W}_K\) for some integer \(K \ge 1\) are admissible graphs. In particular, they have \(R \ge 1\) blocks \(B_i = G(W_{B_i})\) with \(|W_{B_i}| \ge 2\) and \(S\) blocks each containing only one vertex from \(W\). Moreover, the subsets \(W_1, \ldots, W_K\) can be decomposed so that for each \(i \in [R]\), there exists an index set \(I_i \subseteq [K]\) with \(I_i \cap I_j = \emptyset\) for \(i \neq j\), such that \((W_\ell)_{\ell \in I_i} \in \mathcal{A}_{|I_i|}(W_{B_i})\). Letting \(K_i = |I_i|\) and writing \(W_1^i, \ldots, W_{K_i}^i\) for \((W_\ell)_{\ell \in I_i} \), we have
\[
\begin{split}
& \sum_{K\geq 1}  \sum_{W_1,\ldots, W_K \in \mathcal{W}_K} P_{(W_k)_{k=1}^K}(\boldsymbol{\gamma})  \\
& = \mathbf{1}_{\{G  \, \text{is an admissible graph}\}}  \sum_{K_1, \ldots, K_R \geq 1}  \sum_{W_1^1,\ldots, W_{K_1}^1 \in \mathcal{A}_{K_1} (W_{B_1})}  \cdots \sum_{W_1^R,\ldots, W_{K_R}^R \in \mathcal{A}_{K_R} (W_{B_R})}  \prod_{i=1}^R P_{(W_k^i)_{k=1}^{K_i}}(\boldsymbol{\gamma})  \\
& = \mathbf{1}_{\{G  \, \text{is an admissible graph}\}}   \prod_{i=1}^R \left ( \sum_{K \ge 1} \sum_{W_1, \ldots, W_K \in \mathcal{A}_K (W_{B_i})} P_{(W_k)_{k=1}^K} (\boldsymbol{\gamma}) \right ).
\end{split}
\]
This completes the proof of Lemma~\ref{lem: main estimate}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Combinatorial estimates} \label{section: combinatorics}

Let \(G=(W \cup V,E)\) be a finite, connected bipartite multigraph, where  \(E\) is a multiset of edges and \(m \colon E \to \N\) assigns the multiplicity to each edge \(e\in E\). For some positive integer \(r\), consider subsets \(W_1,\ldots, W_r\) of \(W\), which may have a nontrivial intersection, and sequences \(\boldsymbol{\eta}_1, \ldots, \boldsymbol{\eta}_r\) such that \(\boldsymbol{\eta}_i = \{\eta_i(w), w \in W_i\} \in \N^{|W_i|}\). For every integer \(n \ge 1\), we define the following integral:
\begin{equation} \label{eq: integral}
\int \prod_{e \in E} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i g(\gamma_e^i) e^{\sum_{w \in W} \E_X \left [ Z_w^n(\boldsymbol{\gamma})\right ]}  P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r}  (\boldsymbol{\gamma}),
\end{equation}
where \(g \colon \R \to \R\) is an odd, \(L^1\)-integrable function and \(P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r}  (\boldsymbol{\gamma})\) is given by
\[
P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r}  (\boldsymbol{\gamma}) = \prod_{i=1}^r \E_X \left [\prod_{w \in W_i} \left ( Z_w^n(\boldsymbol{\gamma})\right)^{\eta_i(w)} \right ].
\]
For every \(w \in W\) and integer \(n\), the random variable \(Z_w^n(\boldsymbol{\gamma})\) is defined by 
\[
Z_w^n(\boldsymbol{\gamma}) = n \log \E_W \left [ e^{i  \left (\sum_{v \in V \colon v \sim w} \left ( \gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))} \right )X_v \right) W_w} \right ],
\]
where \(W_w\) are i.i.d.\ random variables distributed according to \(\nu_w\) and \(X_v\) are i.i.d.\ random variables distributed according to \(\nu_x\) (see Assumption~\ref{hyp1}). Notably, fixing \(w \in W\), we observe that \(\E_X \left [ Z_w^n(\boldsymbol{\gamma})\right ]\) remains unchanged if we replace every \(\gamma_{(w,v)}^i\) by \(-\gamma_{(w,v)}^i\) for all \(v \sim w\) and \(1 \le i \le m((w,v))\). This invariance is due to the symmetry of \(\nu_x\) and the fact that \(X_v\) appears only once inside \(\E_X \left [Z_w^n(\boldsymbol{\gamma})\right ]\). For any subset \(E_0\) of \(E\), let \(T_{E_0}\) denote the map on \(\R^{\sum_{e\in E} m(e)}\) that changes \(\gamma_e^i\) to \(-\gamma_e^i\) for every \(i\in \{1,\ldots,m(e)\}\) and every \(e \in E_0\), while leaving the other entries unchanged. Under this notation, \(\E_X \left [ Z_w^n(\boldsymbol{\gamma})\right ]\) is invariant under the transformation \(T_{\{e = (w,v) \colon v \sim w\}}\). Thus, the sum \(\E_X \left [ \sum_{w \in W} Z_w^n(\boldsymbol{\gamma})\right]\) is invariant under \(T_E\). Since \(g\) is an odd function, it follows that if \(P_{(W_i,\boldsymbol{\eta}_i)_{i=1}^r}(\boldsymbol{\gamma})\) is invariant under \(T_{E_0}\) for some subset \(E_0 \subset E\) with odd cardinality \(|E_0|\), then the integral~\eqref{eq: integral} vanishes. In the first part of this section, our goal is to determine conditions on \(W_1,\ldots, W_r\) such that \(P_{(W_i,\boldsymbol{\eta}_i)_{i=1}^r}(\boldsymbol{\gamma})\) fails to be invariant under \(T_{E_0}\) for subsets \(E_0 \subset E\) with odd cardinality. 

Given the subsets \(W_1,\ldots, W_r\) of \(W\), we let \(G_1, \ldots, G_r\) denote the bipartite subgraphs \(G_i = (W_i \cup V_i, E_i)\) given by Definition~\ref{def: subgraphs}, where 
\[
V_i = \{ v \in V \colon \exists \, w \in W_i , v \sim w\},
\]
and 
\[
E_i = \{ e = (w,v) \in E \colon w \in W_i, v \in V_i\}.
\] 
We let \(\deg_{G_i}(x)\) denote the degree of a vertex \(x \in W_i \cup V_i\) within the subgraph \(G_i\), and \(\deg(x)\) its degree within the entire graph \(G\). We assume that the subgraphs \(G_1,\ldots, G_r\) are connected, ensuring that the expectation \(\E_X \left [ \prod_{w\in W_i} \left(Z_w^n(\boldsymbol{\gamma})\right)^{\eta_i(w)} \right ]\) in \(P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r}(\boldsymbol{\gamma})\) does not factorize. We now provide the necessary conditions for the integral~\eqref{eq: integral} to be nonvanishing.

\begin{lem} \label{lem: necessary cond}
Let \(\tilde{w}_1,\ldots, \tilde{w}_q\), \(q \geq 0\), denote the vertices that belong to two or more subsets among \(W_1,\ldots, W_r\) (if \(W_1,\ldots, W_r\) are disjoint, then \(q=0\)). Consider the following conditions:
\begin{enumerate} 
\item[(A)] for every \(i \in [r]\) and every \(w \in W_i\), \(\deg(w) = \deg_{G_i}(w) \geq 2\);
\item[(B)] for every \(v\in \cup_{i=1}^r V_i\), there exists at least one \(V_i\) such that \(\deg_{G_i}(v) \geq 2\);
\item[(C)] for every \(v \in V_i\) such that \(v \not \sim \tilde{w}_1,\ldots, \tilde{w}_q\), \(\deg_{G_i}(v)\) is even (if \(W_1, \ldots,W_r\) are disjoint, then \(\deg_{G_i}(v)\) is even for all \(v \in V_i\));
\item[(D)] for every \(e \in E \backslash \cup_{i=1}^r E_i\), \(m(e)\) is even. 
\end{enumerate}
If any of the conditions (A)-(D) is not satisfied, then there exists at least one subset \(E_0 \subset E\) with odd cardinality \(|E_0|= \sum_{e \in E_0} m(e)\) such that \(P_{(W_i,\boldsymbol{\eta}_i)_{i=1}^r}(\boldsymbol{\gamma})\) is invariant under \(T_{E_0}\). As a result, the integral~\eqref{eq: integral} vanishes. 
\end{lem}

\begin{proof}
We first focus on condition (A). We observe that for every \(i \in [r]\) such that \(w \in W_i\), the degree of \(w\) in \(G_i\) is independent of \(i\) since the neighborhood of vertices in \(W\) does not depend on \(i\). This implies that \(\deg(w) = \deg_{G_i}(w)\) for all \(w \in \cup_{i=1}^r W_i\). If (A) is not satisfied, then there exists \(w_0 \in \cup_{i=1}^r W_i\) such that \(\deg(w_0) = 1\). For every \(i \in [r]\) such that \(w_0\in W_i\), it follows that
\[
\begin{split}
\E_X \left [\prod_{w \in W_i} \left(Z_w^n(\boldsymbol{\gamma})\right)^{\eta_i(w)} \right] & = \E_X \left[ \left(Z_{w_0}^n (\boldsymbol{\gamma})\right)^{\eta_i(w_0)}  \prod_{w \in W_i \backslash \{w_0\}} \left( Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_i(w)} \right ] \\
& = \E_X \left [ \left (n \log \E_W \left [ e^{i \gamma_{(w_0,v_0)} X_{v_0} W_{w_0}} \right ] \right)^{\eta_i(w_0)} \prod_{w \in W_i \backslash \{w_0\}} \left(Z_w^n(\boldsymbol{\gamma})\right)^{\eta_i(w)} \right ] 
\end{split}
\]
is even in \(\gamma_{(w_0,v_0)}\) since the law of \(X_{v_0}\) is symmetric and \(X_{v_0}\) appears only once inside the expectation. This implies that \(P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r} (\boldsymbol{\gamma})\) is invariant under \(T_{(w_0,v_0)}\) and~\eqref{eq: integral} vanishes. If (B) is not satisfied, then there exists at least one \(v_0 \in \cup_{i=1}^r V_i\) with \(\deg(v_0) =1\) in \(\cup_{i=1}^r G_i\). Let \(w_0 \in W\) such that \(w_0 \sim v_0\). For every \(i \in [r]\) such that \(w_0\in W_i\), we have that
\[
\E_X \left [\prod_{w \in W_i} \left ( Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_i(w)}  \right ] = \E_X \left [ \left(Z_{w_0}^n(\boldsymbol{\gamma})\right)^{\eta_i(w_0)} \prod_{w \in W_i \backslash \{w_0\}} \left( Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_i(w)}  \right ] ,
\]
where in this case \(Z_{w_0}^n\) is given by
\[
Z_{w_0}^n (\boldsymbol{\gamma}) = n \log \E_W \left [ e^{i \left ( \gamma_{(w_0,v_0)} X_{v_0} + \sum_{v \in V \backslash \{v_0\} \colon v \sim w_0}  (\gamma_{(w_0,v)}^1 + \cdots +\gamma_{(w_0,v)}^{m((w_0,v))})  X_v \right) W_{w_0}} \right ] .
\]
Therefore, \(\E_X \left [\prod_{w \in W_i} \left ( Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_i(w)}  \right ] \) is even in \(\gamma_{(w_0,v_0)}\) since the law of \(X_{v_0}\) is symmetric and \(X_{v_0}\) appears only once inside the expectation. This implies that \(P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r} (\boldsymbol{\gamma})\) is even in \(\gamma_{(v_0, w_0)}\) and the integral~\eqref{eq: integral} vanishes. We now consider condition (C) and we first assume that \(W_1,\ldots,W_r\) are disjoint. If (C) is not satisfied, then there exists at least one subgraph \(G_i\) with at least one \(v_0 \in V_i\) such that \(\deg_{G_i}(v_0)\) is odd. We let \(w_1, \ldots, w_k \in W_i\) denote the neighbors of \(v_0\) in \(G_i\). We then note that the expectation
\[
\begin{split}
\E_X \left [\prod_{w \in W_i} \left ( Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_i(w)}  \right ] = \E_X \left [\left ( Z_{w_1}^n (\boldsymbol{\gamma}) \right)^{\eta_i(w_1)} \cdots \left ( Z_{w_k}^n (\boldsymbol{\gamma}) \right)^{\eta_i(w_k)} \prod_{w \in W_i\backslash \{w_1,\ldots, w_k\}} \left(Z_w^n (\boldsymbol{\gamma})\right)^{\eta_i(w)} \right ] 
\end{split}
\]
is invariant under \(T_{E_0}\) for \(E_0 = \{(v_0,w_i) \colon i \in [k]\}\) by the same argument used above. Since by assumption \(W_1, \ldots, W_r\) are disjoint, it follows that \(P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r}(\boldsymbol{\gamma})\) is also invariant under \(T_{E_0}\) and \(|E_0| = \sum_{i=1}^k m((v_0,w_i)) = \deg_{G_i}(v_0)\) is odd. It remains to consider the case where \(W_1,\ldots,W_r\) are not necessarily disjoint. We let \(\mathcal{I}\) denote 
\[
\mathcal{I} = \left \{i \in [r] \colon \exists \,j \in [q] \enspace \text{such that} \enspace \tilde{w}_j \in W_i\right \} 
\]
such that \(\tilde{w}_1,\ldots, \tilde{w}_q \in \cup_{i \in \mathcal{I}} W_i\). We note that the subsets \((W_i)_{i \in \mathcal{I}^\textnormal{c}}\) are disjoint and have a trivial intersection with \(\cup_{i \in \mathcal{I}} W_i\). Assume first that there exists \(v_0 \in V_i\) for some \(i \in \mathcal{I}^\textnormal{c}\) such that \(\deg_{G_i}(v_0)\) is odd. Then, by the above computation we have that \(\E_X \left [ \prod_{w \in W_i} \left( Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_i(w)}\right ]\) is invariant under \(T_{E_0}\) for \(E_0 = \{(v_0,w) \colon w \in W_i, w \sim v_0\}\) and so does \(P_{(W_i, \boldsymbol{\eta}_i)_{i =1}^r} (\boldsymbol{\gamma})\) since \(W_i\) is disjoint from the other subsets. We therefore assume that there is \(v_0 \in V_i\) for some \(i \in \mathcal{I}\) such that \(\deg_{G_i}(v_0)\) is odd and such that the neighbors \(w_1,\ldots, w_k\) of \(v_0\) in \(G_i\) are distinct from \(\tilde{w}_1, \ldots, \tilde{w}_q\). Since the expectation \(\E \left [\prod_{w \in W_i} \left( Z_w^n(\boldsymbol{\gamma}) \right)^{\eta_i(w)}  \right ]\) is invariant under \(T_{E_0}\) for \(E_0 = \{(v_0,w_i) \colon i \in [k]\}\) by the above computation and since \(w_1,\ldots, w_k\) only belong to \(W_i\) by assumption, it then follows that the product \(P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r} (\boldsymbol{\gamma})\) is also invariant under \(T_{E_0}\). The integral~\eqref{eq: integral} vanishes since \(|E_0| = \sum_{i=1}^k m((v_0,w_i))= \deg_{G_i}(v_0)\) is odd. Finally, assume that condition (D) is not satisfied. Then, there is \(e_0 \in E \backslash \cup_{i=1}^r E_i\) such that \(m(e_0)\) is odd. The product \(P_{(W_i, \boldsymbol{\eta}_i)_{i=1}^r} (\boldsymbol{\gamma})\) is invariant under \(T_{e_0}\) since it does not depend on \(\gamma_{e_0}^1, \ldots, \gamma_{e_0}^{m(e_0)}\). The integral~\eqref{eq: integral} vanishes since \(m(e_0)\) is odd. 
\end{proof}

With the conditions (A)-(D) from Lemma~\ref{lem: necessary cond}, our aim in the remainder of this section is to estimate the sum \(\sum_{i=1}^r |W_i|\) in terms of \(|W|, |V|\), and \(|E|\). To this end, for some integer \(s \ge 0\), we partition \(W \backslash \cup_{i=1}^r W_i\) into \(s\) subsets \(W_{r+1},\ldots, W_{r+s}\) such that \(\cup_{i=1}^s W_{r+i}= W \backslash \cup_{i=1}^r W_i\), with the convention that \(s=0\) if \( W = \cup_{i=1}^r W_i\). The subsets \(W_{r+1},\ldots, W_{r+s}\) may have a nontrivial intersection. We then define the corresponding bipartite subgraphs \(G(W_{r+1}), \ldots, G(W_{r+s})\) as described in Definition~\ref{def: subgraphs} and assume that \(G(W_{r+1}), \ldots, G(W_{r+s})\) are connected. 

The first result addresses the case where the subsets \(W_1, \ldots, W_r\) and \(W_{r+1}, \ldots, W_{r+s}\) are disjoint. Since \(G\) is a connected graph and \(W_1, \ldots, W_{r+s}\) are disjoint subsets, the corresponding subgraphs \(G(W_1), \ldots, G(W_{r+s})\) must be connected through vertices of \(V\). We denote the set of common vertices of \(V\) among the subgraphs \(G_1, \ldots, G_r\) as follows: for every \(k \in [2,r+s]\) and every \(1 \leq \ell_1 < \cdots < \ell_k \leq r+s\), we set
\[
V_{G_{\ell_1}, \ldots, G_{\ell_k}} = \left \{ v \in V \colon \exists \, 1 \le i < j \le k \enspace \textnormal{such that} \enspace v \in V_{\ell_i} \cap V_{\ell_j} \right \}.
\]

\begin{lem} \label{lem: card disjoint case}
Let \(G = (W \cup V, E)\) and \(\{G_i = G(W_i), 1 \leq i \leq r+s\}\) be connected bipartite graphs such that \(G = \cup_{i=1}^r G_i \sqcup \cup_{i=1}^{s} G_{r+i}\). Assume that 
\begin{itemize}
\item[(i)] \(W_1, \ldots, W_r\) are disjoint and satisfy (A)-(C);
\item[(ii)] \(W_{r+1}, \ldots,W_{r+s}\) are disjoint and condition (D) holds, i.e., for every \(i \in [s]\) and every \(e \in E_{r+i}\), \(m(e)\) is even.
\end{itemize}
Then, it holds that
\begin{equation} \label{eq: estimate V disjoint case}
|V| \leq \frac{|E|}{2} - (r+s) + 1,
\end{equation}
from which it follows that 
\begin{equation} \label{eq: estimate W+V disjoint case}
|W| + |V| - \frac{|E|}{2} -1 \leq \sum_{i=1}^{r+s} (|W_i| -1) .
\end{equation}
Moreover, equality in~\eqref{eq: estimate V disjoint case}, and thereby in~\eqref{eq: estimate W+V disjoint case}, holds if and only if 
\begin{itemize}
\item[(a)] for every \(i \in [r]\) and every \(v\in V_i\), \(\deg_{G_i}(v)=2\);
\item[(b)] for every \(i \in [s]\) and every \(v \in V_{r+i}\), \(\deg_{G_{r+i}}(v)=2\);
\item[(c)] for every \(k \in [2,r+s]\) and every \(1 \leq \ell_1 < \cdots < \ell_k \leq r+s\), \(|V_{G_{\ell_1}, \ldots, G_{\ell_k}}| \leq k-1\).
\end{itemize}
\end{lem}

\begin{rmk} \label{rmk: cond outside 1}
The following observation concerns item (b) of Lemma~\ref{lem: card disjoint case}. In particular, we observe that, under both assumptions (i) and (ii) of Lemma~\ref{lem: card disjoint case}, for every \(i \in [s]\) and every \(v \in V_{r+i}\), \(\deg_{G_{r+i}}(v)=2\) if and only if \(|W_{r+i}| = 1\) and \(m((w,v)) = 2\) for every \(w \sim v\). Assume first that \(\deg_{G_i}(v) = \sum_{w \in W_{r+i} \colon w \sim v} m((w,v)) = 2\) for every \(v \in V_{r+i}\). Since \(m(e) \ge 2\) for every \(e \in E_{r+i}\) by assumption (ii), it follows that each vertex \(v \in V_{r+i}\) has exactly one neighbor, say \(w_i \in W_{r+i}\), and that \(m(e)=2\) for every \(e \in E_{r+i}\). This implies that \(|W_{r+i}|=1\) for every \(i \in [s]\), leading to \(\sum_{i=1}^s (|W_{r+i}|-1) = 0\) and \(s = |W| - \sum_{i=1}^r |W_i|\). Now, assume that \(W_{r+i} = \{w_i\}\) for every \(i \in [s]\), and that \(m((w_i, v)) = 2\) for every \(v \sim w_i\). In this case, each vertex \(v \in V_{r+i}\) has exactly one neighbor \(w_i \in W_{r+i}\), and since \(m((v,w_i))=2\), it follows that \(\deg_{G_{r+i}}(v) = m((w_i,v))=2\).
\end{rmk}

\begin{proof}
To prove~\eqref{eq: estimate W+V disjoint case}, it suffices to show~\eqref{eq: estimate V disjoint case}. Indeed, since \(W_1, \ldots, W_r, W_{r+1}, \ldots, W_{r+s}\) are disjoint by assumptions (i) and (ii), we have \(|W| = \sum_{i=1}^{r+s} |W_i|\) and~\eqref{eq: estimate W+V disjoint case} follows directly from~\eqref{eq: estimate V disjoint case}. For every \(i \in [r+s]\), let \(G_i = (W_i \cup V_i, E_i)\) denote the induced subgraph as defined in Definition~\ref{def: subgraphs}. Since \(G\) is a connected graph and the subsets \(W_1, \ldots, W_{r+s}\) are disjoint, the subgraphs \(G_1, \ldots, G_{r+s}\) are connected, their set of edges \(E_1, \ldots, E_{r+s}\) are disjoint, and they are connected through vertices in \(V\). By assumption (i), it holds that \(\deg_{G_i}(v) \geq 2\) for every \(v \in V_i\) and \(i \in [r]\). Similarly, by assumption (ii), \(\deg_{G_{r+i}}(v) = \sum_{w \in W_{r+i} \colon w \sim v} m((w,v)) \geq 2\) for every \(v \in V_{r+i}\) and \(i \in [s]\). This implies that the connected components \(G_1, \ldots, G_{r+s}\) are connected by vertices in \(V\) with \(\deg_{G}(v)=\sum_{i}\deg_{G_i}(v) \ge 4\). Assume that \(G_1, \ldots, G_{r+s}\) are connected by distinct vertices \(\tilde v_1, \ldots, \tilde v_p \in V\) for some integer \(p \geq 1\). For every \(i \in [p]\), let \(n(\tilde v_i)\) denote the number of components going through \(\tilde v_i\). We then see that 
\begin{equation} \label{eq: estimate V proof}
|V| = \sum_{i=1}^{r+s} |V_i| - \sum_{i=1}^p (n(\tilde v_i)-1)  \leq \sum_{i=1}^{r+s} \frac{|E_i|}{2} - \sum_{i=1}^p (n( \tilde v_i)-1) = \frac{|E|}{2}- \sum_{i=1}^p (n(\tilde v_i)-1),
\end{equation}
where the last equality follows from the fact that \(E_1, \ldots, E_{r+s}\) are disjoint and the inequality follows from 
\begin{equation} \label{eq: estimate E_i disjoint case}
|E_i| = \sum_{v \in V_i} \sum_{w \in W_i} m((w,v))\textbf{1}_{\{(w,v) \in E_i\}} = \sum_{v \in V_i} \deg_{G_i}(v) \geq 2 |V_i|.
\end{equation}
We therefore need to estimate the term \(\sum_{i=1}^p (n(\tilde v_i)-1)\) in~\eqref{eq: estimate V proof}. We first consider the \(n(\tilde v_1)\) components going through \(\tilde v_1\). One of them contains at least one vertex among \(\tilde v_2, \ldots, \tilde v_p\), say \(\tilde v_2\). There are at most \(n(\tilde v_2) - 1\) new components going through \(\tilde v_2\), since at least one component is also connected to \(\tilde v_1\). Proceeding in this way, there are at most \(n(\tilde v_3) - 1\) new components connected to \(\tilde v_3\), since at least one component is already connected to \(\tilde v_1\) or \(\tilde v_2\). Recursively, we obtain that \(n(\tilde v_1) + \sum_{i=2}^p (n(\tilde v_i)-1) \geq r+s\), yielding 
\begin{equation} \label{eq: estimate mult v_i}
\sum_{i=1}^p (n(\tilde v_i)-1) \geq r + s -1.
\end{equation}
Combining~\eqref{eq: estimate V proof} and~\eqref{eq: estimate mult v_i} we obtain that
\[
|V| \leq  \frac{|E|}{2} - \sum_{i=1}^p (n(\tilde v_i)-1) \leq  \frac{|E|}{2} - (r+s) +1,
\] 
which proves~\eqref{eq: estimate V disjoint case}. \\

We now study the case of equality in~\eqref{eq: estimate V disjoint case}. We first note from~\eqref{eq: estimate E_i disjoint case} that for every \(1 \le i \le r+s\), \(|E_i| = |V_i|/2\) if and only if \(\deg_{G_i}(v) =2\) for every \(v \in V_i\). In particular, we have equality in~\eqref{eq: estimate V proof} if and only if (a) and (b) holds. We therefore study the case of equality in~\eqref{eq: estimate mult v_i}. We first assume that item (c) holds. We consider the \(n(\tilde v_1)\) components \((G_i)_{i \in \mathcal{I}_1}\) going through \(\tilde v_1\), where \(\mathcal{I}_1 = \{1 \leq i \leq r+s \colon \tilde{v}_1 \in G_i\}\) and \(n(\tilde v_1) = |\mathcal{I}_1|\). From item (c) it follows that \(|V_{G_i, G_j}| = | \{\tilde v_1\} | = 1\) for every \(i,j \in \mathcal{I}_1\), thus each of the vertices \(\tilde v_2, \ldots, \tilde v_p\) belongs to at most one subgraph \((G_i)_{i \in \mathcal{I}_1}\). We may assume without loss of generality that \(\tilde v_2\) belongs to one of the components \((G_i)_{i \in \mathcal{I}_1}\). Then, there are exactly \(n(\tilde v_2)\) components \((G_i)_{i \in \mathcal{I}_2}\) going through \(\tilde v_2\), where \(\mathcal{I}_2 = \{1 \leq i \leq r+s \colon \tilde v_2 \in G_i\}\) and \(n(\tilde v_2) = |\mathcal{I}_2|\). More precisely, there are exactly \(n(\tilde v_2)-1\) new components going through \(\tilde v_2\) since one component is already counted as it also goes through \(\tilde v_1\). Since \(|V_{G_i, G_j}| = | \{\tilde v_2\} | = 1\) for every \(i,j \in \mathcal{I}_2\) by item (c), the \(n(\tilde v_2) -1\) new components attached to \(\tilde v_2\) do not share other vertices. Moreover, since by condition (c), \(|V_{G_i,G_j,G_k}| \leq 2\) for every \(i,j,k \in \mathcal{I}_1 \cup \mathcal{I}_2\), it follows that each vertex \(\tilde v_k\) for \(3 \le k \le p\) belongs to at most one subgraph among \((G_i)_{i \in \mathcal{I}_1 \cup \mathcal{I}_2}\). Otherwise, there are indices \(i\in \mathcal{I}_1\) and \(j \in \mathcal{I}_2 \backslash \mathcal{I}_1\) such that at least one vertex among \(\tilde v_3, \ldots, \tilde v_p\) belongs to \(V_i \cap V_j\), say \(\tilde v_3 \in V_i \cap V_j\). If we denote by \(G_k\), \(k \in \mathcal{I}_1 \cap \mathcal{I}_2\), the component containing both \(\tilde v_1\) and \(\tilde v_2\), then this implies that \(|V_{G_i,G_j,G_k}| = |\{\tilde v_1, \tilde v_2, \tilde v_3\}| = 3\), which is a contradiction to item (c). We may assume without loss of generality that \(\tilde v_3\) belongs to exactly one component among \((G_i)_{i \in \mathcal{I}_1 \cup \mathcal{I}_2}\). Then, there are exactly \(n(\tilde v_3) - 1\) new components going through \(\tilde v_3\). Iterating the argument, we see that condition (c) requires that at each time there are exactly \(n(\tilde v_i)-1\) new components going through \(\tilde v_i\). This implies equality in~\eqref{eq: estimate mult v_i}. 

We now assume by contradiction that (c) is not verified for some \(k \in [2,r+s]\). By definition, this means that there are distinct indices \(\ell_1, \ldots, \ell_k \in [r+s]\) such that the subgraphs \(G_{\ell_1}, \ldots, G_{\ell_k}\) form a cycle, i.e., \(|V_{G_{\ell_1}, \ldots, G_{\ell_k}}| =k\). We may assume without loss of generality that \(G_{\ell_1}\) and \(G_{\ell_2}\) are connected through \(\tilde v_1\), \(G_{\ell_2}\) and \(G_{\ell_3}\) through \(\tilde v_2\), and so on, and finally \(G_{\ell_k}\) and \(G_{\ell_1}\) are connected through \(\tilde v_k\). We then proceed as before. We first fix the \(n(\tilde v_1)\) components going through \(\tilde v_1\) and consider the \(n(\tilde v_2)-1\) new components going through \(\tilde v_2\), and so on, and finally we have the \(n(\tilde v_k)-2\) new components going through \(\tilde v_k\) (there are exactly \(n(\tilde v_k)-2\) new components since \(G_{\ell_k}\) and \(G_{\ell_1}\) have already been counted). Moreover, there are at most \(n(\tilde v_i)-1\) new components going through \(\tilde v_i\) for every \(i \in [k+1,p]\). This shows that
\[
n(\tilde v_1) + \sum_{i=1}^{k-1} (n(\tilde v_i) - 1) + (n(\tilde v_k) - 2) + \sum_{i = k+1}^p (n(\tilde v_i) -1) \geq r + s ,
\]
that is, \(\sum_{i=1}^p (n(\tilde v_i)-1) \geq r+s > r+s-1\), thus yielding a strict inequality in~\eqref{eq: estimate mult v_i}.
\end{proof}

It remains to address the case where \(W_1, \ldots, W_r\) and \(W_{r+1}, \ldots, W_{r+s}\) are not necessarily disjoint. Analogous to the definition for the set of common vertices of \(V\), we define the set of common vertices of \(W\) among the subgraphs \(G_1, \ldots, G_r\) as follows: for every \(k \in [2,r]\) and every \(1 \leq \ell_1 < \cdots < \ell_k \leq r\), we set 
\[
W_{G_{\ell_1}, \ldots, G_{\ell_k}} = \left \{ w \in V \colon \exists \, 1 \le i < j \le k \enspace \textnormal{such that} \enspace w \in W_{\ell_i} \cap W_{\ell_j} \right \}.
\]
We can naturally extend this definition to the set of common vertices of \(W\) among the subgraphs \(G_{r+1}, \ldots, G_{r+s}\). Note that by definition, \(W_1, \ldots, W_r\) are disjoint from \(W_{r+1}, \ldots, W_{r+s}\). We now define a merging operation for the subsets \(W_1, \ldots, W_r\) and subgraphs \(G_1, \ldots, G_r\) sharing common vertices in order to recover the original graph \(G\).

\begin{defn} [Merging procedure] \label{def: merging operation}
Since \(W_1,\ldots,W_r\) are not necessarily all disjoint, for an integer \(q \ge 0\), we let \(\tilde{w}_1, \ldots, \tilde{w}_q\) denote the vertices of \(W\) which belong to two or more subsets among \(W_1,\ldots, W_r\), with the convention that \(q=0\) if \(W_1,\ldots,W_r\) are disjoint. Specifically, we let \(\mathcal{I}\) denote the subset of \([r]\) such that \(\tilde{w}_1, \ldots, \tilde{w}_q \in \cup_{i \in \mathcal{I}} W_i\), i.e.,
\[
\mathcal{I} = \{i \in [r] \colon \exists \, j \in [q] \enspace \textnormal{such that} \enspace \tilde{w}_j \in W_i\}.
\]
By definition, the subsets \((W_i)_{i \in \mathcal{I}^\textnormal{c}}\) are disjoint and have a trivial intersection with \(\cup_{i \in \mathcal{I}} W_i\). For every \(j \in [q]\), we also let \(\mathcal{I}_j\) denote the subset of \([r]\) such that \(\tilde{w}_j \in \cap_{i \in \mathcal{I}_j} W_i\), i.e.,
\[
\mathcal{I}_j = \{i \in [r] \colon \tilde{w}_j \in W_i\}.
\]
We note that \(\mathcal{I} = \cup_{j=1}^q \mathcal{I}_j\). Let \(C\) denote the number of components of \(\cup_{i \in \mathcal{I}} W_i\). Then, for every \(i \in [C]\), we let \(\tilde{\mathcal{I}}_i\) denote the maximal subset of \(\mathcal{I}\) such that \(\cup_{j \in \tilde{\mathcal{I}}_i} W_j\) is connected and we set 
\[
\tilde{W}_i = \cup_{j \in \tilde{\mathcal{I}}_i} W_j,
\]
where we remove the repeated copies of \(\tilde{w}_j\) for every \(j \in [q]\) such that \(\tilde{\mathcal{I}}_i \cap \mathcal{I}_j \neq \emptyset\). By definition, \(\tilde{\mathcal{I}}_i \cap \tilde{\mathcal{I}}_j = \emptyset\) for every \(i \neq j\), so that \(\mathcal{I} = \sqcup_{i=1}^C \tilde{\mathcal{I}}_i\). In this way, we obtain \(C\) disjoint subsets \(\tilde{W}_1,\ldots, \tilde{W}_C\) such that
\[
\cup_{i \in \mathcal{I}} W_i = \sqcup_{i=1}^C \tilde{W}_i.
\]
Then, for every \(i \in [C]\), we merge the subgraphs \(\{G(W_j), j \in \tilde{\mathcal{I}}_i\}\) containing \(\tilde{w}_j\) for every \(j \in [q]\) such that \(\tilde{\mathcal{I}}_i \cap \mathcal{I}_j \neq \emptyset\) and remove the repeated copies of \(\tilde{w}_j\) as well as the associated edges and vertices \(v \sim \tilde{w}_j\). We also remove the repeated copies of vertices of \(V\) which are not adjacent to \(\tilde{w}_1,\ldots, \tilde{w}_q\). From this merging operation, we obtain \(C + |\mathcal{I}^\textnormal{c}|\) disjoint subsets such that \(\cup_{i=1}^r W_i = \left (\sqcup_{i =1}^C \tilde{W}_i \right )\sqcup \left (\sqcup_{i \in \mathcal{I}^\textnormal{c}} W_i \right)\).
\end{defn}

The following example refers to Figure~\ref{fig1} and aims to clarify the previous definition.

\begin{ex} \label{ex3}
Consider the connected bipartite graph of Figure~\ref{subfig1}, along with three different collections of subsets of \(W\) shown in Figures~\ref{subfig2}-\ref{subfig4}. We note the following. 
\begin{itemize}
\item Figure~\ref{subfig2}: The subsets \(W_1\) and \(W_2\) are disjoint and satisfy \(W = W_1 \sqcup W_2\), thus \(\mathcal{I} = \emptyset\). 
\item Figure~\ref{subfig3}: The subset \(W_1\) is disjoint from both \(W_3\) and \(W_4\), while \(W_3 \cap W_4 = \{w_5\}\). Thus, \(\mathcal{I} = \{3,4\}\). Applying the merging procedure from Definition~\ref{def: merging operation} to \(W_3\) and \(W_4\) results in the subset \(\tilde{W}_1 = \{w_5, \ldots w_{12}\}\), which corresponds to \(W_2\) from Figure~\ref{subfig2}. Moreover, \(W_1\) and \(\tilde{W}_1\) are disjoint, satisfying \(W = W_1 \sqcup \tilde{W}_1\). Merging the subgraphs \(G_3 = G(W_3)\) and \(G_4 = G(W_4)\) removes the repeated copy of \(w_5\), as well as the repeated copy of the vertices \(v_2, v_3, v_4\), and \(v_5\) and of their associated edges. The resulting graph \(\tilde{G}_1\) corresponds to \(G_2\) from Figure~\ref{subfig2}. 
\item Figure~\ref{subfig4}: The subsets \(W_5\) and \(W_6\) are disjoint from \(W_2\), while \(W_5 \cap W_6 = \{w_4\}\), leading to \(\mathcal{I} = \{5,6\}\). Applying the merging procedure to \(W_5\) and \(W_6\) gives \(\tilde{W}_1 = \{w_1, \ldots, w_4\}\), which corresponds to \(W_1\) from Figure~\ref{subfig2}. Merging the subgraphs \(G_5\) and \(G_6\) removes the duplicate copy of \(w_4\) as well as the repeated copy of the vertices \(v_2, v_3, v_4\) and of their associated edges. The resulting graph \(\tilde{G}_1\) thus corresponds to the graph \(G_1\) in Figure~\ref{subfig2}.
\end{itemize}
\end{ex}

For the following result, consider integer \(q \ge 0\) and let \(\tilde{w}_1, \ldots, \tilde{w}_{q}\) denote the vertices of \(W\) that belong to two or more subsets among \(W_1,\ldots, W_r\). Similarly, consider integer \(q' \ge 0\) and let \(w_1', \ldots, w'_{q'}\) denote the vertices that belong to two or more subsets among \(W_{r+1},\ldots, W_{r+s}\). More precisely, let \(\mathcal{I}\) denote the subset of \([r]\) such that \(\tilde{w}_1, \ldots, \tilde{w}_{q} \in \cup_{i \in \mathcal{I}} W_i\), and let \(\mathcal{J}\) be the subset of \(\{r+1, \ldots, r+s\}\) such that \(w'_1, \ldots, w'_{q'} \in \cup_{i \in \mathcal{J}} W_i\). Following the merging procedure outlined in Definition~\ref{def: merging operation}, we merge the subgraphs that share vertices in \(\cup_{i \in \mathcal{I}} W_i\). This results in \(C\) disjoint subgraphs, denoted by \(\{\tilde{G}_i = G(\tilde{W}_i), 1 \leq i \leq C\}\), where \(C\) is the number of connected components of \(\cup_{i \in \mathcal{I}} W_i\). Similarly, applying the merging procedure to the subgraphs that share vertices in \(\cup_{i \in \mathcal{J}} W_i\) results in \(C'\) disjoint subgraphs, denoted by \(\{G'_i = G(W'_i), 1 \leq i \leq C'\}\), where \(C'\) is the number of connected components of  \(\cup_{i \in \mathcal{J}} W_i\). Thus, \(\cup_{i=1}^s G_{r+i}\) is decomposed into disjoint subgraphs \(G_1', \ldots, G'_{C'}\), along with the subgraphs \((G_i)_{i \in \mathcal{J}^\textnormal{c}}\) that do not share vertices with others. As a result, given the subsets \(W_1, \ldots, W_r\) and \(W_{r+1}, \ldots, W_{r+s}\), along with their corresponding subgraphs \(G_i = G(W_i)\) for \(i \in [r+s]\), the merging procedure results in disjoint connected subgraphs that we denote by 
\[
\{\bar{G}_i, 1\le i\le C + C' + |\mathcal{I}^\textnormal{c}| + |\mathcal{J}^\textnormal{c}|\} = \{\tilde{G}_1,\ldots, \tilde{G}_{C}, (G_i)_{i \in \mathcal{I}^\textnormal{c}}, G'_1,\ldots, G'_{C'} ,(G_i)_{i \in \mathcal{J}^\textnormal{c}}\}.
\]

\begin{lem} \label{lem: card not disjoint case}
Let \(G = (W \cup V, E)\) and \(\{G_i = G(W_i), 1 \leq i \leq r+s\}\) be connected bipartite graphs such that \(G = \cup_{i=1}^r G_{i} \sqcup \cup_{i=1}^s G_{r+i}\). Assume that 
\begin{itemize}
\item[(i)] the subsets \(W_1,\ldots, W_r\) satisfy (A)-(C);
\item[(ii)] condition (D) holds, i.e., for every \(i \in [s]\) and every \(e \in E_{r+i}\), \(m(e)\) is even.
\end{itemize}
Then, it holds that 
\begin{equation} \label{eq: estimate W+V not disjoint case}
|W| + |V| - \frac{|E|}{2} -1 \leq \sum_{i=1}^{r+s} (|W_i| -1) .
\end{equation}
With the notation introduced above, equality in~\eqref{eq: estimate W+V not disjoint case} holds if and only if 
\begin{itemize}
\item[(a)] for every \(2 \leq k \leq |\mathcal{I}|\) and every distinct \(\ell_1, \ldots, \ell_k \in \mathcal{I}\), \(|W_{G_{\ell_1}, \ldots, G_{\ell_k}}| \leq k-1\);
\item[(b)] for every \(i \in [C]\) and \(v \in \tilde{V}_i\), \(\deg_{\tilde{G}_i}(v) = 2\), and for every \(i \in \mathcal{I}^\textnormal{c}\) and \(v \in V_i\), \(\deg_{G_i}(v) = 2\);
\item[(c)] for every \(i \in [C']\) and \(v \in V'_i\), \(\deg_{G'_i}(v) = 2\), and for every \(i \in \mathcal{J}^\textnormal{c}\) and \(v \in V_i\), \(\deg_{G_i}(v) = 2\);
\item[(d)] for every \(2 \leq k \leq C + C' + |\mathcal{I}^\textnormal{c}| +|\mathcal{J}^\textnormal{c}|\) and every distinct \(\ell_1, \ldots, \ell_k\), \(|V_{\bar{G}_{\ell_1}, \ldots, \bar{G}_{\ell_k}}| \leq k-1\).
\end{itemize}
\end{lem}

\begin{proof} 
Consider first the subsets \((W_k)_{k \in \mathcal{I}}\). The merging procedure described by Definition~\ref{def: merging operation} yields \(C\) disjoint subsets \(\tilde{W}_1,\ldots, \tilde{W}_C\) such that \(\cup_{k \in \mathcal{I}} W_k = \sqcup_{i=1}^C \tilde{W}_i\). Fix \(i \in [C]\) and recall that the subset \(\tilde W_i\) is obtained by merging the subsets \(W_k\) for \(k \in \tilde{\mathcal{I}}_i\) and by removing any repeated copy of \(\tilde{w}_j\) for every \(j \in [q]\) such that \(\mathcal{I}_j \cap \tilde{\mathcal{I}}_i \neq \emptyset\). This implies that
\[
|\tilde{W}_i| = \sum_{k \in \tilde{\mathcal{I}}_i} |W_k| - \sum_{j=1}^q (|\mathcal{I}_j \cap \tilde{\mathcal{I}}_i|-1)\mathbf{1}_{\{\mathcal{I}_j \cap \tilde{\mathcal{I}}_i \neq \emptyset\}}.
\]
Furthermore, according to Definition~\ref{def: merging operation}, if there exists \(j \in [q]\) such that \(\mathcal{I}_j \cap \tilde{\mathcal{I}}_i \neq \emptyset\), then \(\mathcal{I}_j \subseteq \tilde{\mathcal{I}}_i\), yielding 
\begin{equation} \label{eq: inequality for W tilde}
|\tilde{W}_i| = \sum_{k \in \tilde{\mathcal{I}}_i} |W_k| - \sum_{j=1}^q (|\mathcal{I}_j|-1)\mathbf{1}_{\{\mathcal{I}_j \cap \tilde{\mathcal{I}}_i \neq \emptyset\}}.
\end{equation}
We therefore need to estimate the sum \( \sum_{j=1}^q (|\mathcal{I}_j|-1)\mathbf{1}_{\{\mathcal{I}_j \cap \tilde{\mathcal{I}}_i \neq \emptyset\}}\). We can proceed in a similar way as done in the proof of Lemma~\ref{lem: card disjoint case}. Let \(j_1, \ldots, j_m \in [q]\) denote the indices such that \(\mathcal{I}_{j_k} \cap \tilde{\mathcal{I}}_i \neq \emptyset\). That is, \(\tilde{w}_{j_1}, \ldots, \tilde{w}_{j_m}\) are the vertices in \((\tilde{w}_j)_{j\in [q]}\) that belong to \(\tilde{W}_i\). We first consider the \(|\mathcal{I}_{j_1}|\) subgraphs sharing the vertex \(\tilde{w}_{j_1}\). One of them contains at least one vertex among \(\tilde{w}_{j_2}, \ldots, \tilde{w}_{j_m}\), say \(\tilde{w}_{j_2}\). Then there are at most \(|\mathcal{I}_{j_2}|-1\) new components going through \(\tilde{w}_{j_2}\), since at least one component is also connected to \(\tilde{w}_{j_1}\). Similarly, there are at most \(|\mathcal{I}_{j_3}|-1\) new components going through \(\tilde{w}_{j_3}\), since at least one component is already connected to \(\tilde{w}_{j_1}\) or \(\tilde{w}_{j_2}\). Iterating this argument for each \(\tilde{w}_{j_k}\) for \(k \in [m]\), we obtain that 
\[
|\mathcal{I}_{j_1}| + \sum_{k=2}^m (|\mathcal{I}_{j_k}| -1) \ge |\tilde{\mathcal{I}}_i|,
\]
leading to
\begin{equation}\label{eq: bound card I}
\sum_{k=1}^m (|\mathcal{I}_{j_k}| -1) \ge |\tilde{\mathcal{I}}_i| -1,
\end{equation}
Combining~\eqref{eq: inequality for W tilde} and~\eqref{eq: bound card I} yields
\[
|\tilde{W}_i| \le \sum_{k \in \tilde{\mathcal{I}}_i} |W_k| - |\tilde{\mathcal{I}}_i| + 1 =  \sum_{k \in \tilde{\mathcal{I}}_i} (|W_k|-1) + 1,
\]
so that
\begin{equation} \label{eq: inequality for W tilde 2}
\sum_{i=1}^C |\tilde{W}_i| \leq \sum_{i=1}^C \sum_{k \in \tilde{\mathcal{I}}_i} (|W_k| -1) + C = \sum_{k \in \mathcal{I}} (|W_k|-1) + C.
\end{equation}
Now, consider the subsets \((W_k)_{k \in \mathcal{J}}\). By the merging procedure described in Definition~\ref{def: merging operation}, we obtain \(C'\) disjoint subsets \(W_1',\ldots, W'_{C'}\) such that \(\cup_{k \in  \mathcal{J}} W_k = \sqcup_{i=1}^{C'} W'_i\). Following the previous arguments, we deduce that 
\begin{equation}  \label{eq: inequality for W prime 2}
\sum_{i=1}^{C'} |W'_i|  \leq \sum_{k \in  \mathcal{J}} (|W_k| - 1) + C'.
\end{equation}
The subsets \(\tilde{W}_1,\ldots, \tilde{W}_C, (W_i)_{i \in \mathcal{I}^\textnormal{c}}\) are disjoint and satisfy (A)-(C). The \(W'_1,\ldots, W'_{C'}, (W_i)_{i \in \mathcal{J}^\textnormal{c}}\) are also disjoint, and the multiplicity of each edge in \(E_i'\) for \(i \in [C']\) and in \(E_i\) for \(i \in \mathcal{J}^\textnormal{c}\) is even, as the merging operation preserves edge multiplicities. Applying Lemma~\ref{lem: card disjoint case} we therefore obtain that 
\begin{equation} \label{eq: inequality for W+V}
\begin{split}
|W| + |V| & \leq \sum_{i=1}^C (|\tilde{W}_i| -1) + \sum_{i \in \mathcal{I}^\text{c}} (|W_i| -1) +  \sum_{i=1}^{C'} (|W'_i| -1) + \sum_{i \in \mathcal{J}^\text{c}} (|W_i| -1) + \frac{|E|}{2} + 1\\
& \leq \sum_{i \in \mathcal{I}} (|W_i| -1) + \sum_{i \in \mathcal{I}^\textnormal{c}} (|W_i| -1) + \sum_{i \in \mathcal{J}} (|W_i| -1) + \sum_{i \in \mathcal{J}^\textnormal{c}} (|W_i| -1) + \frac{|E|}{2} + 1\\
& = \sum_{i=1}^{r+s} (|W_i| -1) + \frac{|E|}{2} + 1.
\end{split}
\end{equation}
Here, we used~\eqref{eq: inequality for W tilde 2} and~\eqref{eq: inequality for W prime 2} for the second inequality, along with the fact that \(\sum_{i=1}^r |W_i| = \sum_{i \in \mathcal{I}} |W_i| +  \sum_{i \in \mathcal{I}^\textnormal{c}} |W_i|\) and \(\sum_{i=1}^s |W_{r+i}| = \sum_{i \in \mathcal{J}} |W_i| +  \sum_{i \in \mathcal{J}^\textnormal{c}} |W_i|\) for the third equality. This shows the inequality~\eqref{eq: estimate W+V not disjoint case}.

Now, we study the case of equality in~\eqref{eq: estimate W+V not disjoint case}. According to Lemma~\ref{lem: card disjoint case}, we have equality in the first line of~\eqref{eq: inequality for W+V} if and only if the following conditions are satisfied:
\begin{enumerate}
\item[(b)] for every \(i \in \mathcal{I}^\text{c}\) and \(v \in V_i\), \(\deg_{G_i}(v) = 2\), and for every \(i \in [C]\) and \(v \in \tilde{V}_i\), \(\deg_{\tilde{G}_i}(v) = 2\);
\item[(c)] for every \(i \in \mathcal{J}^\text{c}\) and \(v \in V_i\), \(\deg_{G_i}(v) = 2\), and for every \(i \in [C']\) and \(v \in V_i'\), \(\deg_{G'_i}(v) = 2\);
\item[(d)] for every \(2 \leq k \leq C + C' + |\mathcal{I}^\text{c}| + |\mathcal{J}^\text{c}|\) and every distinct indices \(\ell_1, \ldots, \ell_k\), we have that \(|V_{\bar{G}_{\ell_1}, \ldots, \bar{G}_{\ell_k}}| \leq k-1\).
\end{enumerate}
Therefore, equality in~\eqref{eq: estimate W+V not disjoint case} holds if and only if we also achieve equality in the second line of~\eqref{eq: inequality for W+V}, which is equivalent to having equality in~\eqref{eq: bound card I}. It remains to show that equality in~\eqref{eq: bound card I} holds if and only if condition (a) is satisfied. Note that, by Definition~\ref{def: merging operation}, \(\mathcal{I} = \sqcup_{i=1}^C \tilde{\mathcal{I}}_i\). Condition (a) is therefore equivalent to requiring that, for every \(i \in [C]\), every \(2 \le k \le | \tilde{\mathcal{I}}_i|\), and every distinct indices \(\ell_1, \ldots, \ell_k \in \tilde{\mathcal{I}}_i\), it holds that \(|W_{G_{\ell_1}, \ldots, G_{\ell_k}}| \le k-1\). The remainder of the argument follows the same approach as in the proof of Lemma~\ref{lem: card disjoint case}.
\end{proof}

We now introduce the class \(\mathcal{W}_r\) of subsets of \(r\) subsets of \(W\) in order to state the key combinatorial identity proved in this section.

\begin{defn}[Class \(\mathcal{W}_r\) of subsets] \label{def: set W_K}
Let \(G = (W \cup V, E)\) be a finite, connected bipartite multigraph. Consider \(r \ge 1\) subsets \(W_1,\ldots, W_r\) of \(W\) such that \(\cup_{i=1}^r W_i \subseteq W\). Let \(G_1 = G(W_1),\ldots, G_r =G(W_r)\) denote the corresponding subgraphs, where \(G_i = (W_i \cup V_i, E_i)\) as defined in Definition~\ref{def: subgraphs}. Set \(s = |W| - |\cup_{i=1}^r W_i|\) and let \(w_1,\ldots, w_s\) denote the vertices of \(W \backslash \cup_{i=1}^r W_i\). Let  \(\tilde{w}_1, \ldots, \tilde{w}_q\) denote the vertices in \(W\) that are shared by several subsets \(W_i\). Let \(\mathcal{I}\) denote the subset of \([r]\) such that each \(\tilde{w}_j\) lies in \(\cup_{i\in\mathcal I} W_i\), and let \(C\) be the number of connected components of \(\cup_{i \in \mathcal{I}} W_i\). The subgraphs obtained by merging \(\{G_i, i \in \mathcal{I}\}\) as per Definition~\ref{def: merging operation} are denoted by \(\{\tilde{G}_i = G(\tilde{W}_i), 1 \leq i \leq C\}\). 

We say that the subsets \(W_1, \ldots, W_r\) belong to the class \(\mathcal{W}_r\) if the following conditions are satisfied:
\begin{enumerate}
\item for every \(i \in [r]\), \(|W_i|\ge 2\);
\item the subgraphs \(G_1, \ldots, G_r\) are connected;
\item for every \(e \in E \backslash \cup_{i=1}^r E_i\), \(m(e) = 2\); 
\item for every \(i \in [r]\) and \(w \in W_i\), \(\deg_{G_i}(w) = \deg(w) \ge 2\);
\item for every \(v \in \cup_{i=1}^r V_i\), there exists at least one \(V_i\) such that \(\deg_{G_i}(v) \geq 2\);
\item for every \(i \in \mathcal{I}^\textnormal{c}\) and \(v \in V_i\), \(\deg_{G_i}(v) = 2\), and for every \(i \in [C]\) and \(v \in \tilde{V}_i\), \(\deg_{\tilde{G}_i}(v) = 2\);
\item for every \(2 \leq k \leq |\mathcal{I}|\) and distinct \(\ell_1, \ldots, \ell_k \in \mathcal{I}\), \(|W_{G_{\ell_1}, \ldots, G_{\ell_k}} | \leq k-1\);
\item for any \(2 \leq k \leq C + |\mathcal{I}^\textnormal{c}| + s\) and distinct \(\ell_1, \ldots, \ell_k \in \{1, \ldots, C +|\mathcal{I}^\textnormal{c}| + s\}\), \(|V_{\bar{G}_{\ell_1}, \ldots, \bar{G}_{\ell_k}}| \leq k -1\), where \(\{\bar{G}_i, 1 \leq i \leq C + |\mathcal{I}^\textnormal{c}| + s\}\) denotes the set \(\{\tilde{G}_1,\ldots, \tilde{G}_C, (G_i)_{i \in \mathcal{I}^\textnormal{c}}, G(\{w_1\}),\ldots, G(\{w_s\})\}\).
\end{enumerate}
\end{defn}

\begin{ex}[Example~\ref{ex3} continued]
Consider the connected bipartite graph in Figure~\ref{subfig1}, along with three different collections of subsets of \(W\) shown in Figures~\ref{subfig2}-\ref{subfig4}. 
\begin{itemize}
\item Figure~\ref{subfig2}: The subsets \(W_1\) and \(W_2\) are elements of \(\mathcal{W}_2\).
\item Figure~\ref{subfig3}: The subsets \(W_1, W_3\), and \(W_4\) belong to \(\mathcal{W}_3\). 
\item Figure~\ref{subfig4}: The subsets \(W_5, W_6\), and \(W_2\) do not belong to \(\mathcal{W}_3\). Indeed, condition (5) of Definition~\ref{def: set W_K} is not satisfied since \(v_2 \in V_5 \cap V_6\) and \(\deg_{G_5}(v_2) = \deg_{G_6}(v_2) = 1\). 
\end{itemize}
\end{ex}

\begin{ex}
Figure~\ref{fig2} provides a second example of a connected bipartite graph \(G = (W \cup V, E)\), for which there exists at least a collection of subsets \(W_1, \ldots, W_K \in \mathcal{W}_K\) for some integer \(K \ge 1\). In particular, there are two such collections: the subset \(W_1 = \{w_2, \ldots, w_6\}\), belonging to \(\mathcal{W}_1\), and the subsets \(W_2 = \{w_2, w_3, w_4, w_5\}\) and \(W_3 = \{w_3,w_6\}\), belonging to \(\mathcal{W}_2\). Note that, in this case, the graph obtained by merging \(G(W_2)\) and \(G(W_3)\) corresponds to \(G(W_1)\). 
\end{ex}

The following result is a direct consequence of the results of this section, namely Lemmas~\ref{lem: necessary cond}, ~\ref{lem: card disjoint case}, and~\ref{lem: card not disjoint case}.

\begin{prop} \label{prop: combinatorics}
Let \(G = (W \cup V, E)\) be a finite, connected bipartite multigraph. Consider \(r\) subsets \(W_1,\ldots, W_r\) of \(W\) such that the corresponding subgraphs \(G_1, \ldots, G_r\) are connected. 
\begin{itemize}
\item[(a)] If \(W_1, \ldots,W_r \notin \mathcal{W}_r\), then either \(P_{(W_i, \eta_i)_{i=1}^r} (\boldsymbol{\gamma})\) is invariant under \(T_{E_0}\) for some \(E_0 \subset E\) with odd cardinality, or 
\[
\sum_{i=1}^r (|W_i| - 1) > |W| + |V| - \frac{|E|}{2} - 1.
\]
\item[(b)] If \(W_1, \ldots,W_r \in \mathcal{W}_r\), then
\[
\sum_{i=1}^r (|W_i| - 1) = |W| + |V| - \frac{|E|}{2} - 1.
\]
\end{itemize}
\end{prop}

The final result of this section characterizes the connected bipartite multigraphs \(G = (W \cup V, E)\) in which all vertices have even degrees and for which there exists at least one collection of subsets \(W_1, \ldots, W_K\) of \(W\) belonging to \(\mathcal{W}_K\) for some integer \(K \ge 1\). We focus on bipartite multigraphs with vertices of even degree, as this framework is used in Section~\ref{section: convergence traffic} to prove Lemma~\ref{lem: main estimate}. The following result shows that these graphs are in bijection with admissible graphs, as defined in Definition~\ref{def: admissible graph}.

\begin{lem} \label{lem: equiv def}
Let \(G= (W \cup V, E)\) be a connected bipartite multigraph in which all vertices have even degree. Then, there exists at least one collection of subsets \(W_1, \ldots, W_K \subseteq W\) belonging to \(\mathcal{W}_K\) for some integer \(K \ge 1\) if and only if the following conditions holds:
\begin{itemize}
\item[(a)] \(G\) is an admissible graph with \(R = \frac{|E|}{2} + 1 - |V| - S\) blocks such that \(B_i = G(W_{B_i})\) with \(|W_{B_i}| \ge 2\) for every \(i \in [R]\),
\item[(b)] for every \(i\in [R]\), there exists an index set \(I_i \subseteq [K]\) with \(I_i \cap I_j = \emptyset\) for every \(i \neq j\) and \(K = \sum_{i=1}^R |I_i|\), such that the subsets \((W_\ell)_{\ell \in I_i}\) belong to \(\mathcal{A}_{|I_i|}(W_{B_i})\). 
\end{itemize}
\end{lem}

\begin{proof}
We first assume that there are subsets \(W_1, \ldots, W_K \subseteq W\) such that \(W_1, \ldots, W_K \in \mathcal{W}_K\) for some integer \(K \ge 1\). Applying the merging procedure of Definition~\ref{def: merging operation} to \(W_1,\ldots, W_K\), we obtain disjoint subsets \(\bar{W}_1, \ldots, \bar{W}_R\) with \(| \bar{W}_i| \ge 2\). These subsets correspond to \(\tilde{W}_1, \ldots, \tilde{W}_C, (W_i)_{i \in \mathcal{I}^{\text{c}}}\) according to Definition~\ref{def: set W_K}. Thus, \(R = C + |\mathcal{I}^\text{c}|\). Additionally, there are \(S\) vertices in \(W \backslash \cup_{i=1}^K W_i\). From Lemma~\ref{lem: card disjoint case}, we deduce that \(R + S= |E|/2 + 1 - |V|\). This implies that \(G\) consists of \(R+S\) disjoint subgraphs connected through vertices in \(V\). Condition (8) of Definition~\ref{def: set W_K} ensures that \(G\) is a block tree with \(R+S\) blocks. Specifically, there are \(R \ge 1\) blocks \(B_i = G(W_{B_i})\) where \(W_{B_i} = \bar{W}_i\), and \(S\) blocks, each containing exactly one vertex in \(W\). The degree condition (c) of Definition~\ref{def: admissible graph} is satisfied due to the items (3), (4), and (6) of Definition~\ref{def: set W_K} and by the assumption that the vertices in \(W\cup V\) have even degree. Hence, the graph \(G\) is admissible. For every \(k \in [R]\), let \(\bar{\mathcal{I}}_k\) denote the subset of \([K]\) such that \(\bar{W}_k = \cup_{i \in \bar{\mathcal{I}}_k} W_i\) (see also Definition~\ref{def: merging operation}). By definition, \(\bar{\mathcal{I}}_k \cap \bar{\mathcal{I}}_\ell = \emptyset\) for all \(k \neq \ell\) and \(\sum_{k=1}^R |\bar{\mathcal{I}}_k| = K\). Furthermore, we have \((W_i)_{i \in \bar{\mathcal{I}}_k} \in \mathcal{A}_{|\bar{\mathcal{I}}_k|}(\bar{W}_k)\). Indeed, condition (a) of Definition~\ref{def: admissible decomposition} follows from condition (1) of Definition~\ref{def: set W_K}, condition (b) from condition (2), condition (c) from condition (5), and condition (d) from condition (7). The result follows by setting \(I_i = \bar{\mathcal{I}}_i\).

Assume now that \(G\) is an admissible graph with \(R+S\) blocks, where \(R\) blocks contain more than one vertex from \(W\) and \(S\) blocks contain exactly one vertex from \(W\). Denote the \(R\) blocks as \(B_i = G(W_{B_i})\). Assume further that for every \(i\in [R]\), there exists an admissible decomposition of \(W_{B_i}\), i.e., there exists \(W_1^i, \ldots, W_{|I_i|}^i \in \mathcal{A}_{|I_i|} (W_{B_i})\). We aim to show that the subsets \((W_1^i, \ldots, W_{|I_i|}^i)_{i \in R}\) belong to \(\mathcal{W}_K\), where \(K = \sum_{i=1}^R |I_i|\). The conditions (1), (2), (5), and (7) of Definition~\ref{def: set W_K} follow directly from conditions (a), (b), (c), and (d) of Definition~\ref{def: admissible decomposition}. Condition (4) of Definition~\ref{def: set W_K} follows from item (c) of Definition~\ref{def: admissible graph}. Condition (3) is fulfilled by condition (c) of Definition~\ref{def: admissible graph} because, in the \(S\) blocks containing exactly one vertex from \(W\), every vertex in \(V\) has degree \(2\), thus edges within such blocks have multiplicity \(2\). It remains to check conditions (6) and (8). By definition, for every \(j \in [|I_i|], \cup_{k \neq j} W_k^i \cap W_j^i \neq \emptyset \), so that merging the subsets \(W_1^i, \ldots, W_{|I_i|}^i\) results in one connected component \(\bar{W}_i = W_{B_i}\). By condition (c) of Definition~\ref{def: admissible graph}, it follows that (6) is satisfied. Moreover, condition (8) is satisfied by the fact that \(G\) is a block tree.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Convergence of matrix moments} \label{section: cycle}

This section is devoted to the proof of Theorem~\ref{main1}. We begin by proving the convergence in expectation of the moments of \(Y_m Y_m^\top\) and by computing the corresponding limit. As discussed in Subsection~\ref{subsection: outline proof}, the expected \(k\)th moment of \(Y_m Y_m^\top\) corresponds to the traffic trace associated to the test graph \(T_{\text{cycle}} = (W \cup V, E, Y_m)\), where \(G = (W \cup V, E)\) denotes the simple bipartite cycle of length \(2k\). Our approach thus relies on applying Proposition~\ref{main3}.

Throughout this section, let \(G = (W \cup V, E)\) denote the non-oriented simple bipartite cycle of length \(2k\), with edges \(e = (w, v)\) connected vertices from \(W\) to \(V\). We define \(W = \{w_1, \ldots, w_k\}\) and \(V = \{v_1, \ldots, v_k\}\) as the vertex sets and assume the vertices are labeled in cyclic order such that \(w_i < v_i < w_{i+1}\) for every \(i \in [k]\), with the convention that \(w_{k+1} = w_1\). The set of unordered edges \(E\) is then labeled by pairs of cyclically adjacent vertices, i.e., \(E = \cup_{i=1}^k \{(w_i,v_i),(w_{i+1}, v_i)\}\). See Figure~\ref{fig3} for an illustration. According to Proposition~\ref{main3}, we have that
\begin{equation} \label{eq: moments}
\lim_{m, n, p \to \infty} \E \left [ \frac{1}{p} \tr (Y_m Y_m^\top)^k \right ] = \lim_{m, n, p \to \infty} \tau_{p,m,n} \left [T_{\text{cycle}} \right ]  =  \sum_{\pi \in \mathcal{P}(V)}  \sum_{\mu \in \mathcal{P}(W)} \tau^0_{G^{\pi,\mu}},
\end{equation}
where \(G^{\pi,\mu}\) is the graph obtained from \(G\) by identifying vertices of \(V\) which belong to the same block of \(\pi\) and vertices of \(W\) which belong to the same block of \(\mu\). We do not identify edges, so \(G^{\pi,\mu}\) may have multiple edges. The limiting injective trace \(\tau^0_{G^{\pi,\mu}}\) is given by~\eqref{eq: tau0 double tree} if \(G^{\pi,\mu}\) is a double tree, by~\eqref{eq: tau0 general} if \(G^{\pi,\mu}\) is an admissible graph, and vanishes otherwise. The goal of this section is thus to compute the right-hand side of~\eqref{eq: moments}. To do so, we first need to identify the partitions \(\pi \in \mathcal{P}(V)\) and \(\mu \in \mathcal{P}(W)\) for which the graph \(G^{\pi,\mu}\) is either a double tree or an admissible graph.

\begin{figure}
\begin{tikzpicture}

\draw (0,0) circle [radius=2];
\def\nodesA{12}
\foreach \i in {1, ..., \nodesA} {
        
\pgfmathsetmacro\angle{360/\nodesA * \i}
\pgfmathsetmacro\xpos{0 + 2*cos(\angle)}
\pgfmathsetmacro\ypos{0 + 2*sin(\angle)}
     \coordinate (P\i) at (\xpos, \ypos); 
  \ifodd\i
           \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \else
           \draw[fill=white]  (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }

\node[right] at (P1) {\tiny $v_1$}  ;
\node[above] at (P2) {\tiny $w_1$}  ;
\node[above] at (P3) {\tiny $v_6$}  ;
\node[above] at (P4) {\tiny $w_6$}  ;
\node[left] at (P5) {\tiny $v_5$}  ;
\node[left] at (P6) {\tiny $w_5$}  ;
\node[left] at (P7) {\tiny $v_4$}  ;
\node[below] at (P8) {\tiny $w_4$}  ;
\node[below] at (P9) {\tiny $v_3$}  ;
\node[below] at (P10) {\tiny $w_3$}  ;
\node[right] at (P11) {\tiny $v_2$}  ;
\node[right] at (P12) {\tiny $w_2$}  ;
\end{tikzpicture}
\caption{A simple bipartite cycle of length \(12\).}
\label{fig3}
\end{figure}


\subsection{Basic definitions on partition of sets}

We first introduce some general definitions about partitions of sets that will apply to both sets \(W\) and \(V\). We start with some classical definitions.

\begin{defn} \label{def: partition}
Let \(X = \{x_1, \ldots, x_k\}\) be a set where elements are labeled in cyclic order, meaning \(x_i < x_{i+1}\), with the convention that \(x_{k+1}=x_1\).
\begin{itemize}
\item[(a)] A partition \(\pi\) of \(X\) is a decomposition \(\pi = \{B_1, \ldots, B_{|\pi|}\}\) into disjoint, non-empty subsets \(B_i\), called the \emph{blocks} of the partition. The number of blocks of \(\pi\) is denoted by \(|\pi|\). Given two elements \(x_i,x_j \in X\), we write \(x_i \sim_\pi x_j\) if \(x_i\) and \(x_j\) belong to the same block.  The set of all partitions of \(X\) is denoted by \(\mathcal{P}(X)\).
\item[(b)] The partition \(\pi = \{X\} \in \mathcal{P}(X)\) with only one block is called the \emph{singleton partition} (or the \emph{trivial partition}). The partition \(\pi = \{ \{x\} \colon x \in X\} \in \mathcal{P}(X)\) is called the \emph{partition of singletons}.
\item[(c)] A partition \(\pi\) of \(X\) is called \emph{crossing} if there exist indices \(i_1 < j_1 < i_2 < j_2\) such that \(x_{i_1} \sim_\pi x_{i_2} \not \sim_\pi x_{j_1} \sim_\pi x_{j_2}\). If no such indices exist, \(\pi \in \mathcal{P}(X)\) is \emph{noncrossing}. The set of noncrossing partitions of \(X\) is denoted by \(\mathcal{NC}(X)\). Note that \(\pi = \{X\} \in \mathcal{NC}(X)\) and \(\pi = \{\{x\} \colon x \in X\}  \in \mathcal{NC}(X)\).
\item[(d)] Let \(B_i = \{x_{i_1}, \ldots, x_{i_{|B_i|}}\}\) and \(B_j = \{x_{j_1}, \ldots, x_{j_{|B_j|}}\}\) be two blocks of a partition \(\pi \in \mathcal{P}(X)\), ordered as \(x_{i_1} < \cdots < x_{i_{|B_i|}}\) and \(x_{j_1} < \cdots < x_{j_{|B_j|}}\). We say \(B_i < B_j\) if there exist consecutive elements \(x_{j_\ell}, x_{j_\ell+1} \in B_j\) such that \(x_{j_\ell} < x_{i_1} < \cdots < x_{i_{|B_i|}} <  x_{j_\ell+1}\).
\end{itemize}
\end{defn}

We now introduce two additional definitions needed to describe the matrix moments.

\begin{defn} \label{def: partition 2}
Let \(X = \{x_1, \ldots, x_k\}\) be a cyclically ordered set.
\begin{itemize}
\item[(e)] For a partition \(\pi\) of \(X\), let \(b(\pi)\) denote the collection of \emph{nearest neighbor pairs} within a same block of \(\pi\): 
\[
\qquad \quad b(\pi) =  \cup_{i=1}^k \left \{(x_i,x_{i+1}) \colon x_i \sim_\pi x_{i+1}  \right \}.
\]
Since \(X\) is cyclic, \((x_k,x_1)\) is also included whenever \(x_k \sim_\pi x_1\). In particular, in the singleton partition \(\pi = \{ X\}\), every pair of neighbors belongs to the same block, i.e., \(b(\pi) = \{(x_i,x_{i+1}) \colon i \in [k]\}\), and \(|b(\pi)| = k\).
\item[(f)] For a partition \(\pi\) of \(X\), let \(c(\pi)\) denote the collection of pairs of next elements within a block such that, for every other pair of elements in a same block, the two pairs do not intersect: 
\[
\begin{split}
\qquad \quad c(\pi)  = \cup_{i=1}^{k-1} \cup_{j=i+1}^k \big \{(x_i,x_j) \colon x_j = \min \{x_\ell \colon & x_\ell \sim_\pi x_i \enspace \text{and} \enspace  \nexists \: x_p \sim_\pi x_q \enspace \text{such that} \enspace\\
&  x_i < x_p < x_\ell < x_q \enspace \text{or} \enspace  x_p < x_i < x_q < x_\ell\} \big \}.
\end{split}
\]
Here, pairs \((x_i,x_j)\) and \((x_p,x_q)\) are said to intersect (or cross) if they satisfy \(x_i < x_p < x_j < x_q\) or \(x_p < x_i < x_q < x_j\). For a noncrossing partition \(\pi \in \mathcal{NC}(X)\), \(c(\pi)\) simplifies to
\[
\begin{split}
\qquad c(\pi) & =   \cup_{i=1}^{k-1} \cup_{j=i+1}^k \left \{(x_i,x_j) \colon x_j = \min \{ x_\ell \colon x_\ell \sim_\pi x_i \} \right\}  = \cup_{i=1}^{|\pi|} \cup_{j=1}^{|B_i|-1} \left \{ (x_{i_j}, x_{i_{j+1}}) \right \},
\end{split}
\]
where each block \(B_i = \{x_{i_1} , \ldots, x_{i_{|B_i|}}\}\) is ordered as \(x_{i_1} < x_{i_2} < \cdots < x_{i_{|B_i|}}\). In this case, we have \(|c(\pi)| = \sum_{i=1}^{|\pi|} (|B_i|-1) = k - |\pi|\).
\end{itemize}
\end{defn}

\begin{rmk} \label{rmk: partition}
The collection \(b(\pi)\) is contained in \(c(\pi)\), except when there exists \(1 < \ell < k\) such that \(x_1 \sim_\pi x_\ell \sim_\pi x_k\) and \((x_1,x_\ell)\) is not an intersecting pair. Indeed, every $(x_{i},x_{i+1}) \in b(\pi)$ for $i \in [k-1]$ obviously belongs to $c(\pi)$. However, if $(x_{k},x_{1})\in b(\pi)$, the only case in which it does not belong to $c(\pi)$ is when there exists an element \(x_1 < x_\ell < x_k\) in the same block such that there are no pairs \((x_p,x_q)\) in another block, with \(x_p \sim_\pi x_q\), that intersect \((x_1,x_\ell)\).
\end{rmk}

We provide an example for items (e) and (f) of Definition~\ref{def: partition 2}.

\begin{ex}
Consider a set \(X = \{x_1, \ldots, x_{10}\}\) labeled in cyclic order and consider the following crossing partition:
\[
\pi = \{ \{x_1, x_3, x_5\}, \{x_2, x_4\}, \{x_6, x_7,x_9\}, \{x_8,x_{10}\}\} .
\]
In this case, there is exactly one pair of nearest neighbor elements within a block, namely, \(b(\pi) = \{(x_6, x_7)\}\). Furthermore, we have \(c(\pi) = \{(x_1,x_5), (x_6,x_7)\}\). To illustrate, consider the first block \(\{x_1, x_3, x_5\}\) in \(\pi\). This block has three possible pairs of elements, i.e., \((x_1,x_3), (x_1,x_5\), and \((x_3,x_5)\). However, only \((x_1,x_5) \in c(\pi)\), as it is the only pair that does not intersect with any pair in other blocks. For instance, the pair \((x_1,x_3) \notin c(\pi)\) since there exists \(x_2 \sim_\pi x_4\) such that \(x_1 < x_2 < x_3 < x_4\). Similarly, \((x_3,x_5) \notin \c(\pi)\) since \(x_2 < x_3 < x_5 < x_5\). The second block in \(\pi\) contains only the pair \((x_2,x_4)\), which does not belong to \(c(\pi)\) since it intersects with \((x_1,x_3)\) and \((x_3,x_5)\) in the first block. For the third block in \(\pi\), we have three possible pairs \((x_6,x_7), (x_6,x_9)\), and \((x_7,x_9)\). We have \((x_6,x_7) \in c(\pi)\) since it consists of nearest neighbor elements within the block, and thus it cannot intersect with any pairs in other blocks. The pairs \((x_7,x_9)\) and \((x_6,x_9)\) do not belong to \(c(\pi)\) because they intersect with \((x_8,x_{10})\). 
\end{ex}

Throughout, let \(G = (W \cup V, E)\) denote the simple bipartite cycle of length \(2k\), as introduced at the beginning of this section. We next describe the set \(W^\pi\) associated to a partition \(\pi \in \mathcal{P}(W \cup V)\).

\begin{defn}[\(W^\pi\) for \(\pi \in \mathcal{NC}(V)\)] \label{def: NC(V)}
Let \(w_1 \neq \cdots \neq w_k\), and consider a noncrossing partition \(\pi \in \mathcal{NC}(V)\) with blocks \(B_1,\ldots, B_{|\pi|}\). The set \(W^\pi\) corresponds to the finest partition of \(W\) constructed as follows. Consider two blocks \(B_i = \{v_{i_1}, \ldots, v_{i_{|B_i|}}\}\) and \(B_j = \{v_{j_1}, \ldots, v_{j_{|B_j|}}\}\) of \(\pi\) with \(|B_i| \ge 2\) and \(|B_j| \ge 2\), and assume that \(B_i < B_j\), say \(v_{j_1} < v_{i_1} < \cdots < v_{i_{|B_i|}} < v_{j_2} < \cdots < v_{j_{|B_j|}}\). We then define disjoint subsets for the elements of \(W\) corresponding to the block \(B_i\), denoted by \(W_1^i,\ldots, W_{|B_i|-1}^i\), as follows:
\begin{equation} \label{eq: subsets block B_i}
W^i_\ell = \{w_{i_\ell+1}, \ldots, w_{i_{\ell +1}}\} \enspace \text{for} \enspace 1 \leq \ell \leq |B_j|-1.
\end{equation}
Similarly, for the block \(B_j\), the disjoint subsets \(W_1^j,\ldots, W_{|B_j|-1}^j\) are defined by
\[
\begin{split}
W^j_1 &= \{w_{j_1+1},\ldots w_{i_1}\} \cup \{w_{i_{|B_i|}+1},\ldots,w_{j_2}\},\\
W^j_\ell &= \{w_{i_\ell+1}, \ldots, w_{i_{\ell+1}}\} \enspace \text{for} \enspace 2 \leq \ell \leq |B_j|-1.
\end{split}
\]
If a block \(B_k\) contains no other blocks within it, we define the subsets \(W_1^k,\ldots, W_{|B_k|-1}^k\) as given in~\eqref{eq: subsets block B_i}.
We proceed in this way for every block of \(\pi\) with at least two elements. Since each block \(B_i\) defines \(|B_i|-1\) disjoint subsets, we obtain \(k - |\pi| = \sum_{i=1}^{|\pi|} (|B_i|-1)\) disjoint subsets, denoted hereafter by \(W_1^\pi, \ldots, W_{k - |\pi|}^\pi\). Additionally, we set \(W_{k - |\pi| +1}^\pi = W \backslash \sqcup_{i=1}^{k - |\pi|} W_i\), which corresponds to the remaining vertices in \(W\). The finest partition of \(W^\pi\) is given by
\[
W^\pi = \sqcup_{i=1}^{k - |\pi| + 1} W_i^\pi.
\]
Let \(S_\pi\) denote the number of subsets among \(W_1^\pi, \ldots, W_{k - |\pi|}^\pi, W_{k - |\pi| + 1}^\pi\) that have exactly one element. According to Definition~\ref{def: partition 2}, \(S_\pi\) corresponds to the number \(|b(\pi)|\) of nearest neighbor pairs within a same block of \(\pi\). Thus, the number of subsets with cardinality at least \(2\) is given by \(R_\pi = k - |\pi| + 1 - S_\pi\). We denote by \(W_1^\pi,\ldots, W_{R_\pi}^\pi\) the subsets with more than one element, and by \(W_{R_\pi+1}^\pi,\ldots, W_{R_\pi+S_\pi}^\pi\) those with exactly one element. 
\end{defn}

\begin{rmk} \label{rmk: NC(V)}
The graph \(G^\pi = G(W^\pi)\) obtained from a noncrossing partition \(\pi \in \mathcal{NC}(V)\) and with \(w_1 \neq \cdots \neq w_k\) is a block tree. The blocks of \(G^\pi\) consists of the connected subgraphs \(G(W_1^\pi), \ldots, G(W_{R_\pi + S_\pi}^\pi)\), as defined according to Definition~\ref{def: subgraphs}. The separating vertices in \(V\) are those obtained by merging vertices within the same block of \(\pi\). There are \(\sum_{i=1}^{|\pi|} \mathbf{1}_{\{|B_i|\geq 2\}}\) separating vertices in \(V\). Each subgraph \(G(W_i^\pi)\) is a bipartite cycle of length \(2|W_i^\pi|\), as the vertices are arranged in a cycle and between any two adjacent elements of \(W_i^\pi\) there is exactly one element of \(V_i^\pi\). As a result, \(G^\pi\) is a cactus graph. See Figure~\ref{fig4} for an example.
\end{rmk}


\begin{figure}
\begin{tikzpicture}

\draw (0,0) circle [radius=1];
\def\nodesA{4}
\foreach \i in {1, ..., \nodesA} {
        
\pgfmathsetmacro\angle{360/\nodesA * \i}
\pgfmathsetmacro\xpos{0 + cos(\angle)}
\pgfmathsetmacro\ypos{0 + sin(\angle)}
     \coordinate (P\i) at (\xpos, \ypos); 
  \ifodd\i
            \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black]  (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }

\node[above] at (P1) {\tiny $w_1$}  ;
\node[right] at (P2) {\tiny $\tilde{v}_1$}  ;
\node[below] at (P3) {\tiny $w_5$}  ;
\node[right] at (P4) {\tiny $\tilde{v}_2$}  ;

\draw (-2,0) to[bend left = 50] (P2);
 \draw (-2,0) to[bend right = 50] (P2);
 \draw[fill=white] (-2,0) circle [radius=2pt];  
\node[left] at (-2,0) {\tiny $w_6$}  ; 

\draw (2,0) circle [radius=1];

\def\nodesB{4}

\foreach \i in {1, ..., \nodesB} {
        
        \pgfmathsetmacro\angle{360/\nodesB * \i}
        
        \pgfmathsetmacro\xpos{2 +  cos(\angle)}
        \pgfmathsetmacro\ypos{0 +  sin(\angle)}
        
        \coordinate (Q\i) at (\xpos, \ypos);
        
        \ifodd\i
           \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    
\node[above] at (Q1) {\tiny $w_3$};
\node[below] at (Q3) {\tiny $w_4$};
\node[right] at (Q4) {\tiny $v_3$};

    
\pgfmathsetmacro\xcoord{cos(30)} 
\pgfmathsetmacro\ycoord{sin(30)} 

\end{tikzpicture}
\caption{The graph \(G^\pi\) associated to the noncrossing partition \(\pi = \{\{v_1, v_5, v_6\}, \{v_2, v_4\}, v_3\}\), where the vertex \(\tilde{v}_1\) denotes the vertex obtained by merging \(v_1, v_5, v_6\) and the vertex \(\tilde{v}_2\) denotes the vertex obtained by merging \(v_2, v_4\). The subsets \(W_1^\pi = \{w_1, w_5\}, W_2^\pi = \{w_3,w_4 \}\), and \(W_3^\pi = \{w_6\}\) denote the finest partition of \(W^\pi\).}
\label{fig4}
\end{figure}


As we will see later in Lemma~\ref{lem: contr cross part in V}, if \(\pi \in \mathcal{P}(V)\) is crossing then the parameter \(\tau^0_{G^\pi}\) vanishes. We now consider the partitions of \(W\) and begin with the noncrossing ones.

\begin{defn}[\(W^\pi\) for \(\pi \in \mathcal{NC}(W)\)]  \label{def: NC(W)}
Let \(v_1 \neq \cdots \neq v_k\), and consider a noncrossing partition \(\pi \in \mathcal{NC}(W)\) with blocks \(B_1,\ldots, B_{|\pi|}\). We define \(W^\pi\) recursively as follows. 
\begin{enumerate}
\item[1.] Consider a block \(B_i = \{w_{i_1}, \ldots, w_{i_{|B_i|}}\}\) of \(\pi\) with \(|B_i| \geq 2\) and \(w_{i_1} < \cdots < w_{i_{|B_i|}}\). Define the subsets \(W_1^i, \ldots, W_{|B_i|}^i\) by 
\[
\begin{split}
W_\ell^i &= \{w_{i_\ell +1},\ldots, w_{i_{\ell+1} -1}\} \cup \{\tilde{w}_{i}\} \enspace \text{for} \enspace 1 \leq \ell \leq |B_i|-1,\\
W_{|B_i|}^i &=  \{w_{i_{|B_i|} +1}, \ldots, w_{i_1-1}\} \cup \{\tilde{w}_{i}\},
\end{split}
\]
where \(\tilde{w}_{i}\) denotes the vertex obtained by merging \(w_{i_1}, \ldots, w_{i_{|B_i|}}\). Note that \(\tilde{w}_i\) is the unique common vertex shared by the subsets \(W_1^i, \ldots, W_{|B_i|}^i\). 
\item[2.] Consider another block \(B_j = \{w_{j_1}, \ldots, w_{j_{|B_j|}}\}\) with \(|B_j| \geq 2\) and \(w_{j_1} < \cdots < w_{j_{|B_j|}}\). Since \(\pi\) is noncrossing, the vertices \(w_{j_1}, \ldots, w_{j_{|B_j|}}\) must belong to exactly one subset among \(W_1^i,\ldots, W_{|B_i|}^i\), say \(W_1^i\). The block \(B_j\) then provides a decomposition of \(W_1^i\) into subsets \(W_1^j, \ldots, W_{|B_j|}^j\) defined by
\[
\begin{split}
W_\ell^j &= \{w_{j_\ell +1},\ldots, w_{j_{\ell+1} -1}\} \cup \{\tilde{w}_{j}\}  \enspace \text{for} \enspace 1 \leq \ell \leq |B_j|-1 ,\\
W_{|B_j|}^j &=  \{w_{j_{|B_j|} +1}, \ldots, w_{i_2-1}, w_{i_1+1}, \ldots, w_{j_1-1}\} \cup \{\tilde{w}_{i}, \tilde{w}_{j}\},
\end{split}
\]
where \(\tilde{w}_{j}\) stands for the vertex obtained by merging \(w_{j_1}, \ldots, w_{j_{|B_j|}}\). Note that \(\tilde{w}_j\) is the unique common vertex shared by \(W_1^j, \ldots, W_{|B_j|}^j\). 
\item[3.] Proceed in this way for every block of \(\pi\) with at least two elements.  
\end{enumerate}
The first block \(B_i\) defines \(|B_i|\) subsets. Every subsequent block \(B_j\) introduces \(|B_j|-1\) new subsets, since the block \(B_j\) provides a decomposition of an existing subset. Thus, at the end of the procedure, we obtain a total of \(\sum_{i=1}^{|\pi|} (|B_i|-1) + 1 = k - |\pi| +1 \) subsets of \(W\), which we denote by \(W_1^\pi, \ldots, W_{k - |\pi|+1}^\pi\). Moreover, the number of vertices \(\tilde{w}_1,\ldots,\tilde{w}_q\) which belong to several \(W_i^\pi\) is given by \(q = \sum_{i=1}^{|\pi|} \mathbf{1}_{\{B_i|\geq 2\}} \leq k - |\pi|\), with equality if every block of \(\pi\) has at most two elements.

The number of subsets among \(W_1^\pi, \ldots, W_{k - |\pi|+1}^\pi\) that consist of a single element, denoted by \(S_\pi\), corresponds to the number \(|b(\pi)|\) of pairs of nearest neighbors within a same block of \(\pi\). Thus, the number of subsets with cardinality at least two is given by \(R_\pi = k - |\pi| + 1 - S_\pi\). We write \(W_1^\pi,\ldots, W_{R_\pi}^\pi\) for the subsets with more than one element and \(W_{R_\pi+1}^\pi,\ldots, W_{R_\pi+S_\pi}^\pi\) for those with exactly one element. Note that each subset \(W_{R_\pi+i}^\pi\) with exactly one element contains a common vertex \(\tilde{w}_j\). By construction there exists at least one subset among \(W_1^\pi,\ldots, W_{R_\pi}^\pi\) that also contains \(\tilde{w}_j\). Consequently, merging the subsets \(W_1^\pi,\ldots, W_{R_\pi}^\pi\) as described in Definition~\ref{def: merging operation} results in \(W^\pi\).
\end{defn}

\begin{figure}
\begin{tikzpicture}

\node[right] at (-1,0) {\tiny $\tilde{w}_1$}  ;
\node[right] at (2,0) {\tiny $\tilde{w}_2$}  ;

\draw (-2,0) to[bend left = 50] (-1,0);
\draw (-2,0) to[bend right = 50] (-1,0);
\fill[black] (-2,0) circle [radius=2pt];   
\fill[black]  (0.5, -0.5) circle [radius=2pt];  
\fill[black]  (1.25, 0.4) circle [radius=2pt];  
\fill[black]  (-0.25, 0.4) circle [radius=2pt];   
\draw (-1,0) to[bend right = 15] (0.5,-0.5);
\draw (2,0) to[bend left = 15] (0.5,-0.5);
\draw (-1,0) to[bend left = 10] (-0.25,0.4);
\draw (-0.25,0.4) to[bend left = 7] (0.5,0.5);
\draw (0.5,0.5) to[bend left = 7] (1.25,0.4);
\draw (1.25,0.4) to[bend left = 10] (2,0);
\draw[fill=white]  (-1,0) circle [radius=2pt]; 
\node[left] at (-2,0) {\tiny $v_1$}  ; 
\node[below] at (0.5,-0.5) {\tiny $v_6$}  ; 
\node[above] at (-0.25,0.4) {\tiny $v_2$}  ; 
\node[above] at (0.5,0.5) {\tiny $w_3$}  ; 
\node[above] at (1.25,0.4) {\tiny $v_3$}  ; 
\draw[fill=white]  (0.5, 0.5) circle [radius=2pt];  

\draw (3,0) circle [radius=1];

\def\nodesB{4}

\foreach \i in {1, ..., \nodesB} {
        
        \pgfmathsetmacro\angle{360/\nodesB * \i}
        
        \pgfmathsetmacro\xpos{3 +  cos(\angle)}
        \pgfmathsetmacro\ypos{0 +  sin(\angle)}
        
        \coordinate (Q\i) at (\xpos, \ypos);
        
        \ifodd\i
           \fill[black]  (\xpos, \ypos) circle [radius=2pt];  
        \else
            \draw[fill=white] (\xpos, \ypos) circle [radius=2pt];  
        \fi
    }
    
\node[above] at (Q1) {\tiny $v_4$};
\node[below] at (Q3) {\tiny $v_5$};
\node[right] at (Q4) {\tiny $w_5$};
\end{tikzpicture}
\caption{The graph \(G^\pi\) associated to the noncrossing partition \(\pi = \{\{w_1,w_2\}, w_3, \{w_4, w_6\}, w_5\}\), where the vertex \(\tilde{w}_1\) denotes the vertex obtained by merging \(w_1, w_2\) and the vertex \(\tilde{w}_2\) denotes the vertex obtained by merging \(w_4, w_6\).
Merging the subsets \(W_1^\pi = \{\tilde{w}_1, \tilde{w}_2, w_3\}\) and \(W_2^\pi = \{\tilde{w}_2, w_5\}\) gives \(W^\pi\).}
\label{fig5}
\end{figure}


It remains to consider the case of crossing partitions of \(W\).

\begin{defn}[\(W^\pi\) for \(\pi \in \mathcal{P}(W)\)]  \label{def: P(W)}
Let \(v_1 \neq \cdots \neq v_k\), and consider a partition \(\pi \in \mathcal{P}(W)\) with blocks \(B_1,\ldots, B_{|\pi|}\). Assume that \(\pi\) has a crossing. We describe the partitioning of the set \(W\) according to \(\pi \in \mathcal{P}(W)\).

Consider two blocks \(B_i={\{w_{i_1}, \ldots, w_{i_{|B_i|}}}\}\) and \(B_j={\{w_{j_1}, \ldots, w_{j_{|B_j|}}}\}\) with \(|B_i| \geq 2\) and \(|B_j| \geq 2\) and assume that \(w_{i_1} < w_{j_1} < w_{i_2} < w_{j_2} < \cdots < w_{j_{|B_j|}} < w_{i_3} < \cdots w_{i_{|B_i|}}\). As seen in Definition~\ref{def: NC(W)}, the block \(B_i\) provides a decomposition into subsets \(W_1^i, \ldots, W_{|B_i|}^i\) given by
\[
\begin{split}
W_\ell^i &= \{w_{i_\ell +1},\ldots, w_{i_{\ell+1} -1}\} \cup \{\tilde{w}_{i}\} \enspace \text{for} \enspace 1 \leq \ell \leq |B_i|-1,\\
W_{|B_i|}^i &=  \{w_{i_{|B_i|} +1}, \ldots, w_{i_1-1}\} \cup \{\tilde{w}_{i}\},
\end{split}
\]
where we recall that \(\tilde{w}_{i}\) denotes the vertex obtained by merging \(w_{i_1}, \ldots, w_{i_{|B_i|}}\). Since \(w_{j_1} \in W_1^i\) and \(w_{j_2}, \ldots, w_{j_{|B_j|}} \in W_2^i\), the block \(B_j\) defines a partition of the subset obtained by merging \(W_1^i\) and \(W_2^i\). That is, if \(\tilde{W}_i\) denotes the merging of \(W_1^i\) and \(W_2^i\), i.e., 
\[
\tilde{W}_i = \{w_{i_1+1}, \ldots, w_{i_2-1}, w_{i_2+1}, \ldots, w_{i_3-1}\} \cup \{\tilde{w}_i\},
\]
then the block \(B_j\) gives a decomposition of \(\tilde{W}_i\) into subsets \(W_1^j, \ldots, W_{|B_j|-1}^j\) defined by
\[
\begin{split}
W_\ell^j &= \{w_{j_\ell +1},\ldots, w_{j_{\ell+1} -1}\} \cup \{\tilde{w}_{j}\} \enspace \text{for} \enspace 2 \leq \ell \leq |B_j|-1,\\
W_1^j & = \{w_{i_1+1}, \ldots, w_{i_2-1}, w_{i_2+1}, \ldots, w_{j_2 - 1}, w_{j_{|B_j|} +1}, \ldots, w_{i_3-1}\} \cup \{\tilde{w}_i, \tilde{w}_j\}.
\end{split}
\]
Given the subsets \(W_3^i, \ldots, W_{|B_i|}^i, W_1^j, \ldots, W_{|B_j|-1}^j\), we then proceed recursively for every block with at least two elements. In particular, we observe that given a partition \(\pi \in \mathcal{P}(W)\), the first block \(B_i\) defines \(|B_i|\) subsets. If the elements of the next block \(B_j\) belong to exactly one subset, then we get \(|B_j|-1\) new subsets. Otherwise, if the elements of \(B_j\) belongs to \(N(B_j)\) different subsets, then we merge these \(N(B_j)\) subsets into a new subset \(\tilde{W}_i\) and \(B_j\) provides a decomposition of \(\tilde{W}_i\) into \(|B_j| - 1 - (N(B_j)-1) = |B_j| - N(B_j)\) new subsets. Given now \(|B_i| - N(B_j) + 1 +  |B_j| - N(B_j)  = |B_i| + |B_j| - 2 N(B_j) +1\) subsets, we proceed in this way for every block of \(\pi\) with more than one element. 

The number of subsets that we obtain at the end of the procedure corresponds to \(|c(\pi)| + 1\). Indeed, the procedure described above is equivalent to start from \(G\) and first define subsets associated to every pair of elements \((w,w') \in c(\pi)\). Then, inside each subset we make the crossing identifications that are present in \(\pi\). We denote the \(|c(\pi)| + 1\) subsets of \(W\) that we obtain by \(W_1^\pi, \ldots, W_{|c(\pi)|+1}^\pi\). The number \(S_\pi\) of subsets \(W_i^\pi\) of cardinality equal to one corresponds to the number \(|b(\pi)|\), so that there are \(R_\pi = |c(\pi)| + 1 - S_\pi\) subsets of cardinality at least two. In particular, merging the subsets \(W_1^\pi, \ldots, W_{R_\pi}^\pi\) results in \(W^\pi\). 
\end{defn}


\begin{rmk} \label{rmk: P(W)}
The graph \(G^\pi = G(W^\pi)\) obtained from a partition \(\pi \in \mathcal{P}(W)\) and with \(v_1 \neq \cdots \neq v_k\) is a block tree with exactly one block since there are no separating vertices in \(V\). The graph \(G(W^\pi)\) is obtained by merging the subgraphs  \(G(W_1^\pi), \ldots, G(W_{R_\pi}^\pi)\) according to the merging procedure defined in Definition~\ref{def: merging operation}. Figures~\ref{fig5} and~\ref{fig6} provide an example.
\end{rmk}

\begin{figure}
\begin{tikzpicture}

\draw (0,0) circle [radius=1.5];
\def\nodesB{8}

\foreach \i in {1, ..., \nodesB} {
        
        \pgfmathsetmacro\angle{360/\nodesB * \i}
        
        \pgfmathsetmacro\xpos{0 + 1.5 * cos(\angle)}
        \pgfmathsetmacro\ypos{0 + 1.5 * sin(\angle)}
        
        \coordinate (Q\i) at (\xpos, \ypos);
        
        \ifodd\i
           \fill[black] (\xpos, \ypos) circle [radius=2pt];  
        \else
            \draw[fill=white] (\xpos, \ypos) circle [radius=2pt]; 
        \fi
    }

\node[right] at (Q1) {\tiny $v_1$};
\node[above] at (Q2) {\tiny $\tilde{w}_1$};
\node[left] at (Q3) {\tiny $v_6$};
\node[left] at (Q4) {\tiny $w_6$};
\node[left] at (Q5) {\tiny $v_5$};
\node[below] at (Q6) {\tiny $\tilde{w}_2$};
\node[right] at (Q7) {\tiny $v_2$};
\node[right] at (Q8) {\tiny $w_2$};

\fill[black] (0.5,0) circle [radius=2pt];
\node[right] at (0.5,0)  {\tiny $v_3$};
\fill[black] (-0.5,0) circle [radius=2pt];
\node[left] at (-0.5,0)  {\tiny $v_4$};
\draw (Q2) to[bend left = 20] (0.5,0);
\draw (Q2) to[bend right = 20 ] (-0.5,0);
\draw (Q6) to[bend right = 20] (0.5,0);
\draw (Q6) to[bend left = 20 ] (-0.5,0);

\draw[fill=white] (0,1.5) circle [radius=2pt]; 
\draw[fill=white](0,-1.5) circle [radius=2pt]; 

\end{tikzpicture}
\caption{The graph \(G^\pi\) associated to the crossing partition \(\pi = \{\{w_1,w_4\}, w_2, \{w_3,w_5\},w_6\}\), where the vertex \(\tilde{w}_1\) denotes the vertex obtained by merging \(w_1, w_4\) and the vertex \(\tilde{w}_2\) denotes the vertex obtained by merging \(w_3, w_5\).}
\label{fig6}
\end{figure}


\subsection{Convergence of matrix moments in expectation}

In this subsection, we compute the limiting tracial moments of \(M=Y_m Y_m^\top\) using the limiting injective trace of Proposition~\ref{main3}. Recall that for any even integer \(d\), the parameter \(C_d(f)\) is defined by~\eqref{eq: C_deg (f)} and for any subsets \(W_1, \ldots, W_K \subseteq W\) with \(|W_i| \ge 2\), \(C_{(W_i)_{i=1}^K}(f)\) is given by~\eqref{eq: C_{W_i}}.

\begin{prop} \label{prop: main cycle}
For every integer \(k \in \mathbb{N}\), the \(k\)th moment \(\frac{1}{p} \tr M^k\) converges in expectation towards \(m_k = m_k (\phi, \psi, f, \Phi, \nu_x)\), which is given by
\[
m_k = \sum_{\pi \in \mathcal{NC}(V)} \frac{\phi^{k - |\pi|}}{\psi^{k-1}}  C_2(f)^{S_\pi}  \prod_{i=1}^{R_\pi} \left ( \sum_{\mu_i \in \mathcal{P}(W_i^\pi)} \psi^{|W_i^\pi|-|\mu_i|}  C_{G_i^{\pi, \mu_i}} (f)  \right ) ,
\]
where for every \(i \in \{1, \ldots, R_\pi\}\), 
\[
C_{G_i^{\pi, \mu_i}} (f)  =  
\begin{cases}
C_{2 |W_i^\pi|}(f) & \text{if} \enspace \mu_i = \{W_i^\pi\}, \\
\sum_{P_i \in \mathcal{P}(R_{\mu_i})}  C_{(\tilde{W}_j^{P_i})_{j=1}^{|P_i|}}(f) \mathbf{1}_{\{\textnormal{each} \: \tilde{G}_j^{P_i} \: \textnormal{is connected}\}} & \text{otherwise}.
\end{cases}
\]
Here, 
\begin{itemize}
\item for every partition \(P\) of \(W\) or \(V\), \(S_P = |b(P)|\) and \(R_P = | c( P)| + 1 - S_P\) with \(b(P)\) and \(c(P)\) given by Definition~\ref{def: partition 2};
\item for \(\pi \in \mathcal{NC}(V)\), \(W_1^\pi, \ldots, W_{R_\pi}^\pi\) are the disjoint subsets of \(W^\pi\) with at least two vertices, as described by Definition~\ref{def: NC(V)}, and \(G(W_1^\pi), \ldots, G(W_{R_\pi}^\pi)\) are their associated subgraphs;
\item for \(\mu_i \in \mathcal{P}(W_i^\pi)\), \(G_i^{\pi, \mu_i}\) is the graph obtained from \(G(W_i^\pi)\) by identifying vertices of \(W_i^\pi\) which belong to the same block of \(\mu_i\);
\item for \(\mu_i \in \mathcal{P}(W_i^\pi)\), the subsets \(W_1^{\mu_i}, \ldots, W_{R_{\mu_i}}^{\mu_i}\) denote the finest partition of \(W_i^{\pi,\mu_i}\), as described by Definitions~\ref{def: NC(W)} and~\ref{def: P(W)};
\item for any partition \(P_i \in \mathcal{P}( R_{\mu_i})\) of the set \(\{1, \ldots, R_{\mu_i}\}\) with blocks \(B_1,\ldots, B_{|P_i|}\), for every \(1 \le j \le |P_i|\), we let \(\tilde{W}_j^{P_i}\) denote the subset obtained by merging \(\{W_\ell^{\mu_i}, \ell \in B_j\}\) and \(\tilde{G}_j^{P_i} = G(\tilde{W}_j^{P_i})\) according to the merging procedure described by Definition~\ref{def: merging operation}.
\end{itemize}
\end{prop}

We now describe the previous result in words. We start with the simple bipartite cycle \(G= (W \cup V, E)\) and proceed as follows. Choose a noncrossing partition \(\pi \in \mathcal{NC}(V)\). According to Remark~\ref{rmk: NC(V)}, the resulting graph \(G^\pi\) is a cactus graph, which contains 
\begin{itemize}
\item \(S_\pi\) simple cycles of length \(2\), each contributing a parameter \(C_2(f)\),
\item \(R_\pi\) simple cycles of length \(4\) or more, denoted by \(G(W_1^\pi), \ldots G( W_{R_\pi}^\pi)\). 
\end{itemize}
Consider the cycles \(G(W_1^\pi), \ldots G( W_{R_\pi}^\pi)\). Now, for every \(i \in [R_\pi]\), choose a partition \(\mu_i \in \mathcal{P}(W_i^\pi)\) and consider the resulting subgraph \(G(W_i^{\pi, \mu_i})\), obtained by identifying the vertices in \(W_i^\pi\) that belong to the same block \(\mu_i\). Each subgraph \(G(W_i^{\pi, \mu_i})\) contributes a sum of terms, detailed as follows: 
\begin{itemize}
\item For each subset \(W_i^{\pi, \mu_i}\), define the finest partition \(W_1^{\mu_i}, \ldots, W_{R_{\mu_i}}^{\mu_i}\) according to Definitions~\ref{def: NC(W)} and~\ref{def: P(W)}. This partition provides the contribution \(C_{(W_i^{\mu_i})_{i=1}^{R_{\mu_i}}}(f)\). 
\item Consider a partition \(P_i \in \mathcal{P}( R_{\mu_i})\) with blocks \(B_1,\ldots, B_{|P_i|}\). For each block \(B_j\), merge the subsets \((W_\ell^{\mu_i})_{\ell \in B_j}\) as per Definition~\ref{def: merging operation} and denote \(\tilde{W}_j^{P_i}\) the new subset and \(\tilde{G}_j^{P_i} = G(\tilde{W}_j^{P_i})\) the corresponding subgraph. If \(\tilde{G}_j^{P_i} \) is connected for every \(1 \le j \le |P_i|\), then this partition provides the contribution \(C_{(\tilde{W}_j^{P_i})_{i=1}^{|P_i|}}(f)\), otherwise zero.
\end{itemize} 

The rest of the subsection is devoted to the proof of Proposition~\ref{prop: main cycle}. We first consider the partition of singletons for both sets \(V\) and \(W\).

\begin{lem} \label{lem: contr cycle}
If \(G = (W \cup V, E)\) is the simple bipartite cycle of length \(2k\), then
\[
\tau^0_G = 
\begin{cases}
C_2(f) & \text{if} \enspace k=1, \\
\frac{1}{\psi^{k-1}} C_{W}(f) & \text{if} \enspace k \ge 2.
\end{cases}
\]
\end{lem}
\begin{proof}
If \(k=1\), then \(G\) is a double tree. It follows from Proposition~\ref{main3} that
\[
\tau^0_G = C_2(f).
\]
Assume now that \(k \geq 2\). The simple bipartite cycle graph is a block tree with exactly one block, where \(W\) contains more than two vertices since \(k \ge 2\), and all vertices in \(W \cup V\) have degree \(2\). Thus, \(G\) is an admissible graph and by Proposition~\ref{main3}, the limiting injective trace \(\tau^0_G\) is given by~\eqref{eq: tau0 general}, i.e., 
\[
\tau^0_G = \frac{1}{\psi^{k-1}} \sum_{K \ge 1} \sum_{W_1,\ldots, W_K \in \mathcal{A}_K(W)} C_{(W_i)_{i=1}^K}(f).
\]
By definition, \(W \in \mathcal{A}_1(W)\). We claim that there are no other admissible decomposition of \(W\). First, assume by contradiction that there are \(W_1, W_2 \in \mathcal{A}_2(W)\). Then, \(W_1 \cup W_2 = W\) and \(| W_1 \cap W_2 | \geq 1\). If \(| W_1 \cap W_2 | =1\), without loss of generality we may label \(W_1\) and \(W_2\) as \(W_1 = \{w_1, \ldots, w_{j_1}\}\) and \(W_2 = \{w_{j_1}, \ldots, w_k\}\) such that \(w_{j_1} \in W_1 \cap W_2\). By construction, there exists \(v \in V_1 \cap V_2\) such that \(w_n \sim v \sim w_1\) and \(\deg_{G_1}(v) = \deg_{G_2}(v) = 1\). This contradicts condition (c) of Definition~\ref{def: admissible decomposition}. If there are two or more common vertices between \(W_1\) and \(W_2\), then \(|W_{G_1, G_2}| \geq 2\) and this is a contradiction to (d) of Definition~\ref{def: admissible decomposition}. Now, assume by contradiction that there exist \(W_1,\ldots, W_K \in \mathcal{A}_K(W)\) for some \(K > 1\). Let \(\tilde{w}_1, \ldots, \tilde{w}_q \in W\) denote the vertices which belong to two or more subsets among \(W_1, \ldots, W_K\). If \(q \geq K\), then \(|W_{G_1, \ldots, G_K}| = q \geq K\), which contradicts item (d) of Definition~\ref{def: admissible decomposition}. If \(q = K - 1\), since \(W = \cup_{i=1}^K W_i\) and there is no subset which is disjoint from the others, without loss of generality we may label the subsets \(W_1,\ldots, W_K\) by \(W_1 = \{w_1, \ldots, w_{j_1}\}, W_2 = \{w_{j_1},w_{j_1+1}, \ldots, w_{j_2}\}, \ldots, W_K = \{w_{j_{K-1}}, w_{j_{K-1} + 1}, \ldots ,w_k\}\), where \(1 < j_1 < j_2 < \ldots < j_{K-1} < k\). In particular, \(|W_i \cap W_{i+1}| =1\) for any \(1 \leq i \leq K-1\) and \(|W_1 \cap W_K| =0\). By construction, there exists \(v \in V_1 \cap V_K\) such that \(w_n \sim v \sim w_1\) and \(\deg_{G_1}(v) = \deg_{G_K}(v) =1\). This is again a contradiction to item (c) of Definition~\ref{def: admissible decomposition}. Finally, if \(q \leq K-2\), any decomposition of \(W\) into subsets \(W_1, \ldots, W_K\) fails to satisfy condition (c) of Definition~\ref{def: admissible decomposition}. 

The only contribution in \(\tau^0_G\) comes therefore from \(W \in \mathcal{A}_1(W)\), i.e., 
\[
\tau^0_G = \frac{1}{\psi^{k-1}} C_{W}(f).
\]
The parameter \(C_{W}(f)\) is given by~\eqref{eq: C_{W_i}} and, in this case, takes the following form:
\begin{equation} \label{eq: C_W cycle}
C_W (f) = \frac{1}{(2 \pi)^{2k}} \int_{\R^{2k}} \prod_{i=1}^k \textnormal{d} \gamma_{(w_i, v_{i-1})}   \textnormal{d} \gamma_{(w_i, v_i)}  \hat{f} (\gamma_{(w_i, v_{i-1})} )   \hat{f} (\gamma_{(w_i, v_i)} )  e^{ \E_X \left [ Z_{w_i}(\boldsymbol{\gamma}) \right ]} \E_X \left [ \prod_{i=1}^k Z_{w_i} (\boldsymbol{\gamma}) \right ],
\end{equation}
where \(Z_{w_i}(\boldsymbol{\gamma}) = \Phi \left( \gamma_{(w_i, v_{i-1})} X_{v_{i-1}} + \gamma_{(w_i, v_i)}X_{v_i}  \right)\), and we used the convention that \(v_0 = v_k\).
\end{proof}

We now assume that \(w_1, \ldots, w_k\) are pairwise distinct and consider a noncrossing partition of \(V\). 

\begin{lem} \label{lem: contr non-cross part in V}
If \(\mu = \{ \{w_i\} \colon i \in [k]\}\), then for every \(\pi \in \mathcal{NC}(V)\),
\[
\tau^0_{G^{\pi,\mu}} = \frac{\phi^{k - |\pi|}}{\psi^{k-1}} C_2(f)^{S_\pi} \prod_{i=1}^{R_\pi} C_{W_i^\pi}(f), 
\]
where 
\begin{itemize}
\item \(S_\pi =|b(\pi)|\) and \(R_\pi = k - |\pi| +1 - S_\pi\) (see Definition~\ref{def: partition 2}); 
\item \(W^\pi\) denotes the finest partition of \(W\) according to \(\pi\) and \(W_1^\pi, \ldots, W_{R_\pi}^\pi\) are the subsets of \(W^\pi\) with at least two vertices, as described by Definition~\ref{def: NC(V)}.
\end{itemize}
\end{lem}

According to Remark~\ref{rmk: NC(V)}, each subgraph \(G(W_i^\pi)\) is a simple bipartite cycle of length \(2 |W_i^\pi|\). Therefore, the parameter \(C_{W_i^\pi}(f)\) takes the same form  as~\eqref{eq: C_W cycle} in the proof of the previous lemma. 

\begin{proof}
We first observe that, since \(\mu \in \mathcal{P}(W)\) is the partition of singletons, the graph \(G^{\pi,\mu}\) becomes a double tree if and only if \(\pi \in \mathcal{NC}(V)\) is the singleton partition. In this case, \(\deg(w_i) = 2\) for every \(i \in [k]\). By Proposition~\ref{main3}, we obtain that
\[
\tau^0_{G^{\pi,\mu}} = \frac{\phi^{k - 1}}{\psi^{k-1}} C_2(f)^k.
\]
Here, \(S_\pi = |b(\pi)| = k\) and \(R_\pi = k - |\pi| + 1 - k = 0\). 

Now, consider a noncrossing partition \(\pi\) such that \(\pi \neq \{V\}\). According to Definition~\ref{def: NC(V)} and Remark~\ref{rmk: NC(V)}, \(W^\pi\) is decomposed into disjoint subsets \(W_1^\pi, \ldots, W_{k-|\pi|+1}^\pi\) such that the corresponding subgraphs \(G(W_1^\pi), \ldots, G(W_{k - |\pi| +1}^\pi)\) are simple bipartite cycles, connected by \(p = \sum_{i=1}^{|\pi|} \mathbf{1}_{\{|B_i| \ge 2\}} \le k - |\pi|\) vertices in \(V\). The resulting graph \(G^{\pi,\mu}\) is therefore a block tree with \(k-|\pi|+1\) blocks given by the subgraphs \(G(W_1^\pi), \ldots, G(W_{k - |\pi| +1}^\pi)\). This makes \(G^{\pi,\mu}\) an admissible graph since each block is a simple cycle. By Proposition~\ref{main3}, the limiting injective trace \(\tau^0_{G^{\pi,\mu}}\) given by~\eqref{eq: tau0 general}. Since \(S_\pi = |b(\pi)|\) denotes the number of subgraphs of length \(2\), there are \(R_\pi = k - |\pi| + 1 - S_\pi\) subsets \(W_1^\pi,\ldots, W_{R_\pi}^\pi\) of cardinality \(\ge 2\). By definition, we have that \(W_i^\pi \in \mathcal{A}_1(W_i^\pi)\) for every \(i \in [R_\pi]\). Therefore, the following term contributes to \(\tau^0_{G^{\pi,\mu}}\):
\[
\frac{\phi^{k - |\pi|}}{\psi^{k-1}} \prod_{i=1}^{R_\pi} C_{W_i^\pi}(f) \prod_{w \in W \backslash \cup_{i=1}^{R_\pi} W_i^\pi} C_{\deg(w)}(f) .
\]
Since each \(w \in W \backslash \cup_{i=1}^{R_\pi} W_i\) has degree \(2\), this simplifies to
\[ 
\frac{\phi^{k - |\pi|}}{\psi^{k-1}} C_2(f)^{S_\pi} \prod_{i=1}^{R_\pi} C_{W_i^\pi}(f).
\]
Since each subgraph \(G(W^\pi_i)\) is a simple bipartite cycle, there are no further admissible decomposition of \(W^\pi_i\), as shown in Lemma~\ref{lem: contr cycle}. Therefore, no additional terms contribute to \(\tau^0_{G^{\pi,\mu}}\), completing the proof.
\end{proof}

We next show that if \(\pi \in \mathcal{P}(V)\) is a crossing partition, then \(\tau^0_{G^{\pi,\mu}}\) vanishes for any partition \(\mu \in \mathcal{P}(W)\).

\begin{lem} \label{lem: contr cross part in V}
For every partition \(\mu \in \mathcal{P}(W)\) and every crossing partition \(\pi \in \mathcal{P}(V)\), \(\tau^0_{G^{\pi,\mu}}= 0\).
\end{lem}
\begin{proof}
Let \(\pi \in \mathcal{P}(V)\) be a partition containing a crossing. Denote by \(B_i\) and \(B_j\) the two blocks of \(\pi\) such that there are distinct vertices \(v_{i_1},v_{i_2} \in B_i\) and \(v_{j_1},v_{j_2} \in B_j\) satisfying \(v_{i_1} < v_{j_1} < v_{i_2} < v_{j_2}\). To analyze the structure of \(G^\pi\), we perform identifications on all blocks of \(\pi\) except those inside \(B_i\) and \(B_j\). As stated in Remark~\ref{rmk: NC(V)}, the graph obtained through these identifications is a block tree. The crossing can happen either within a single block or between two blocks. Suppose first that the crossing occurs within a single block, i.e., suppose that \(v_{i_1}, v_{i_2}, v_{j_1}\) and \(v_{j_2}\) belong to the same subgraph. The cyclic ordering of vertices in \(V\) implies that, when performing the identifications in \(B_i\) and \(B_j\), the resulting subgraph contains at least one vertex of degree \(4\). Condition (c) of Definition~\ref{def: admissible graph} is therefore not satisfied and the resulting graph \(G^\pi\) is inadmissible. Suppose now that the crossing occurs between two blocks, i.e., suppose for instance that \(v_{i_1},v_{j_1}\) and \(v_{i_2}\) belongs to a different subgraph than \(v_{j_2}\). Then, merging \(v_{i_1}\) with \(v_{i_2}\) forms a new block in the graph, which contains \(v_{j_1}\). Subsequently, the vertex resulting from merging \(v_{j_1}\) with \(v_{j_2}\) becomes a separating vertex, connecting the two previously distinct subgraphs. This modification introduces a cycle among the blocks of \(G^\pi\), and therefore, \(G^\pi\) is not a block tree in this case. In both cases, by Proposition~\ref{main3}, the limiting injective trace \(\tau^0_{G^{\pi,\mu}}\) vanishes.
\end{proof}

We now focus on partitions among the vertices of \(W\). According to Definition~\ref{def: NC(V)}, given a partition \(\pi \in \mathcal{NC}(V)\), the set \(W^\pi\) is decomposed into \(k - |\pi| + 1\) disjoint subsets \(W_1^\pi, \ldots, W_{k - |\pi|+1}^\pi\). If we now consider a partition \(\mu\) of the set \(W\), the vertices within a same block of \(\mu\) belong either to exactly one component or to several components among \(W_1^\pi, \ldots, W_{k - |\pi|+1}^\pi\). We first show that the latter case gives a zero contribution in \(\tau^0_{G^{\pi, \mu}}\).

\begin{lem} \label{lem: contr between V and W}
Let \(\pi \in \mathcal{NC}(V)\) and consider the partition \(W^\pi = \sqcup_{i=1}^{k - |\pi| + 1} W_i^\pi\) from Definition~\ref{def: NC(V)}. Assume that for a partition \(\mu \in \mathcal{P}(W)\) there are at least two vertices \(w_{j_1} \sim_{\mu} w_{j_2}\) such that \(w_{j_1} \in W_{i_1}^\pi\) and \(w_{j_2} \in W_{i_2}^\pi\) for \(i_1 \neq i_2\). Then, \(\tau^0_{G^{\pi, \mu}} = 0\). 
\end{lem}

\begin{proof}
According to Definition~\ref{def: NC(V)}, the subgraphs \(G (W_i^\pi), \ldots, G (W_{k - |\pi|+1}^\pi)\) are simple bipartite cycles connected by \(p \leq k - |\pi|\) vertices \(\tilde{v}_1, \ldots, \tilde{v}_p\in V\). From the proof of Lemma~\ref{lem: contr non-cross part in V}, the graph \(G^\pi\) is an admissible graph with blocks given by the subgraphs \(G (W_i^\pi), \ldots, G (W_{k - |\pi|+1}^\pi)\). Suppose that there exists a partition \(\mu \in \mathcal{P}(W)\) such that \(w_{j_1} \sim_\mu w_{j_2}\), where \(w_{j_1} \in W_{i_1}^\pi\) and \(w_{j_2} \in W_{i_2}^\pi\) for \(i_1 \neq  i_2\). We claim that the graph \(G^{\pi,\mu}\) is not admissible. First, assume that \(G_{i_1}^\pi = G(W_{i_1}^\pi)\) and \(G_{i_2}^\pi =G(W_{i_2}^\pi)\) share a common vertex \(\tilde{v} \in V\). Since each component is a simple cycle, we have that \(\deg_{G_{i_1}^\pi}(\tilde{v}) = \deg_{G_{i_2}^\pi}(\tilde{v})=2\) and \(\deg_{G^\pi}(\tilde{v})\ge 4\). By merging \(w_{j_1}\) with \(w_{j_2}\), the two subgraphs \(G_{i_1}^\pi\) and \(G_{i_2}^\pi\) result in a new connected component \(\tilde{G}^{\pi, \mu}\), as described by Definition~\ref{def: merging operation}, where \(\deg_{\tilde{G}^{\pi,\mu}}(\tilde{v}) = 4\). Condition (c) of Definition~\ref{def: admissible graph} is therefore not satisfied. Now, assume that \(G_{i_1}^\pi\) and \(G_{i_2}^\pi\) are not connected through a vertex from \(V\) and let  \(G_{i_3}^\pi, \ldots, G_{i_n}^\pi\) denote the minimal path connecting \(G_{i_1}^\pi\) to \(G_{i_2}^\pi\) through separating vertices. By merging \(w_{j_1}\) and \(w_{j_2}\) according to Definition~\ref{def: merging operation}, the subgraphs \(G_{i_1}^\pi\) and \(G_{i_2}^\pi\) result in a new connected component, which we denote again by \(\tilde{G}^{\pi, \mu}\). From this merging, we observe that the resulting graph \(G^{\pi,\mu}\) has one fewer block than \(G^\pi\), as two blocks have been merged. Moreover, the subgraphs \(\tilde{G}^{\pi, \mu}, G_{i_3}^\pi, \ldots, G_{i_n}^\pi\) form a cycle, since \(|V_{\tilde{G}^{\pi, \mu}, G_{i_3}^\pi, \ldots, G_{i_n}^\pi}| = n-1\), and \(G^{\pi, \mu}\) is no longer a block tree. Thus, \(G^{\pi, \mu}\) fails to satisfy the criteria for an admissible graph.
\end{proof}

As a consequence of Lemma~\ref{lem: contr between V and W}, the only partitions of \(W\) that gives a nonvanishing contribution are partitions of \(W_1^\pi, \ldots, W_{R_\pi}^\pi\), where we recall that \(R_\pi = k - |\pi| + 1 - |b(\pi)|\) and \(|b(\pi)|\) denotes the number of nearest neighbors in a same block of \(\pi\) (see Definition~\ref{def: partition 2}). Since each connected component \(G_i^\pi = G(W_i^\pi)\) is a simple bipartite cycle (see Remark~\ref{rmk: NC(V)}), in the following we may assume without loss of generality that \(v_1 \neq \cdots \neq v_k\) and \(\pi \in \mathcal{P}(W)\). 

\begin{lem} \label{lem: contr part in W}
If \(\pi = \{\{v_i\} \colon i \in [k]\}\), then for every \(\mu \in \mathcal{P}(W)\) it holds that
\[
\tau^0_{G^{\pi,\mu}} = 
\begin{cases}
C_{2k}(f) & \text{if} \enspace \mu = \{W\}, \\
\frac{1}{\psi^{|\mu|-1}} \sum_{P \in \mathcal{P}(R_\mu)} C_{(\tilde{W}_i^P)_{i=1}^{|P|}}(f)  \mathbf{1}_{\{\text{each} \: G(\tilde{W}_i^P) \: \text{is connected}\}} & \text{otherwise} ,
\end{cases}
\]
where 
\begin{itemize}
\item \(R_\mu = |c(\mu)| + 1 - S_\mu\), \(S_\mu = |b(\mu)|\), and \(c(\mu)\) are given by Definition~\ref{def: partition 2};
\item for \(\mu \in \mathcal{P}(W)\), the subsets \(W_1^\mu, \ldots, W_{R_\mu}^\mu\) denote the finest partition of \(W^\mu\) (see Definitions~\ref{def: NC(W)} and~\ref{def: P(W)});
\item for any partition \(P \in \mathcal{P}(R_\mu)\) of the set \(\{1,\ldots, R_\mu\}\) with blocks \(B_1,\ldots, B_{|P|}\) we denote by \(\tilde{W}_i^P\) the subset obtained by merging \(\{W_j^{\pi}, j \in B_i\}\) and similarly \(G(\tilde{W}_i^P)\) the graph obtained by merging \(\{G (W_j^\pi), j \in B_i\}\) (see Definition~\ref{def: merging operation}).
\end{itemize}
\end{lem}

\begin{proof}
We first observe that since \(\pi \in \mathcal{P}(V)\) is the partition of singletons, the graph \(G^{\pi,\mu}\) is a double tree if and only if \(\mu \in \mathcal{NC}(W)\) is the singleton partition. In this case, \(W^\pi = \{\tilde{w}\}\) where \(\tilde{w}\) denotes the vertex obtained by merging \(w_1, \ldots, w_k\). According to Proposition~\ref{main3}, we obtain that
\[
\tau^0_{G^{\pi,\mu}}  = C_{\deg(\tilde{w})}(f) = C_{2k} (f).
\]
Now, consider a partition \(\mu\) such that \(\mu \neq \{W\}\). According to Remark~\ref{rmk: P(W)}, the graph \(G^\mu\) is a block tree with a single block. It is an admissible graph since items (a), (b), (c) of Definition~\ref{def: admissible graph} are easily verified. From Proposition~\ref{main3}, the limiting injective trace \(\tau^0_{G^{\pi,\mu}}\) is given by~\eqref{eq: tau0 general}. We need to find the admissible decompositions of \(W^\mu\). By definition, \(W^\mu \in \mathcal{A}_1(W^\mu)\), so that the term
\[
\frac{1}{\psi^{|\mu| - 1}} C_{W^\mu}(f)
\]
contributes to \(\tau^0_{G^{\pi,\mu}}\). According to Definitions~\ref{def: NC(W)} and~\ref{def: P(W)}, to the partition \(\mu\) we define subsets \(W_1^\mu, \ldots, W_{R_\mu}^\mu\), which share \(q \leq k - |\pi|\) vertices \(\tilde{w}_1, \ldots, \tilde{w}_q \in W\). In particular, we have that \(W_1^\mu, \ldots, W_{R_\mu}^\mu \in \mathcal{A}_{R_\mu}(W^\mu)\). This implies that the term
\[
\frac{1}{\psi^{|\mu| - 1}} C_{(W_i^\mu)_{i=1}^{R_\mu}}(f)
\]
contributes to \(\tau^0_{G^{\pi,\mu}}\). More generally, let \(P \in \mathcal{P}(R_\mu)\) denote a partition of the set \(\{1, \ldots, R_\mu\}\) with blocks \(B_1, \ldots, B_{|P|}\) and let \(\tilde{W}_i^P\) denote the subset obtained by merging \(\{W_j^\mu, j \in B_i\}\). We also define the corresponding subgraph \(G(\tilde{W}_i^P)\) by merging the subgraphs \(\{G(W_j^P), j \in B_i\}\) and removing the repeated copies of vertices and edges (see Definition~\ref{def: merging operation}). We easily notice that if each component \(G(\tilde{W}_i^P)\) is connected, then \(\tilde{W}_1^P, \ldots, \tilde{W}_{|P|}^P \in \mathcal{A}_{|P|}(W^\mu)\). In particular, we observe that if \(P = \{\{1, \ldots, R_\mu\}\}\) is the singleton partition than \(\tilde{W}^P = W^\mu\), while if \(P = \{\{i\} \colon 1 \leq i \leq R_\mu\}\) is the partition of singletons than \(\tilde{W}_i^P = W_i^\mu\) for \(i \in \{1, \ldots, R_\mu\}\). We therefore deduce that
\[
\tau^0_{G^{\pi,\mu}} = \frac{1}{\psi^{|\mu| - 1}} \sum_{P \in \mathcal{P}(R_\mu)} C_{(\tilde{W}_i)_{i=1}^{|P|}} (f) \mathbf{1}_{\{\text{each} \: G(\tilde{W}_i^P) \: \text{is connected}\}},
\]
as desired.
\end{proof}

We are now able to prove Proposition~\ref{prop: main cycle} by combining the previous results.

\begin{proof}[\textbf{Proof of Proposition~\ref{prop: main cycle}}]
From~\eqref{eq: moments}, 
\[
\lim_{p,m,n \to \infty }  \frac{1}{p} \E \left [ \tr (Y_m Y_m^\top)^k \right ] = \sum_{\pi \in \mathcal{P}(V)}   \sum_{\mu \in \mathcal{P}(W)}  \tau^0_{G^{\pi,\mu}}.
\]
Combining Lemmas~\ref{lem: contr non-cross part in V},~\ref{lem: contr cross part in V}, and~\ref{lem: contr between V and W} yields
\[
\sum_{\pi \in \mathcal{P}(V)}   \sum_{\mu \in \mathcal{P}(W)}  \tau^0_{G^{\pi,\mu}} = \sum_{\pi \in \mathcal{NC}(V)} \phi^{k - |\pi|} C_2(f)^{S_\pi} \prod_{i=1}^{R_\pi} \left ( \sum_{\mu_i \in \mathcal{P}(W_i^\pi)} \tau^0_{G_i^{\pi, \mu_i} } \right),
\]
where \(G_i^{\pi, \mu_i}\) denotes the graph obtained from \(G_i^\pi = G(W_i^\pi)\) by identifying vertices in \(W\) which belong to the same block of \(\mu_i\). Proposition~\ref{prop: main cycle} then follows from Lemma~\ref{lem: contr part in W}.
\end{proof}

We now consider the case of symmetric \(\alpha\)-stable entries with \(\alpha=2\), i.e., for every \(\lambda \in \R\) the characteristic function of \(W_{ij}\) is given by \(\E_W \left [ \exp(\lambda tW_{ij})\right ] = \exp(- \sigma_w^2 \lambda^2/2)\). Thus, \(\Phi ( \lambda ) = - \sigma_w^2/2  \lambda^2\). We show that Proposition~\ref{prop: main cycle} reduces to~\cite[Theorem 3.5]{benigni2021}. We introduce two parameters \(\theta_1(f)\) and \(\theta_2(f)\) which depends on the activation function \(f\):
\[
\begin{split}
\theta_1(f) & = \E_{Z \sim \mathcal{N}(0, \sigma_w^2 \sigma_x^2)} \left [ f^2(Z) \right ] =  \int_\R f^2(\sigma_w \sigma_x x) \frac{e^{-x^2/2}}{\sqrt{2\pi}} \textnormal{d}x,\\
\theta_2(f) & =  \left (\E_{Z \sim \mathcal{N}(0, \sigma_w^2 \sigma_x^2)} \left [ f'(Z) \right ] \right) ^2= \left (\sigma_w \sigma_x \int_\R f'(\sigma_w \sigma_x x) \frac{e^{-x^2/2}}{\sqrt{2 \pi}} \textnormal{d}x\right )^2.
\end{split} 
\]

\begin{lem} \label{lem: moments alpha=2}
Let \(\nu_w\) be the \(\alpha\)-stable symmetric distribution with \(\alpha=2\). Then, the \(k\)th moment \(\frac{1}{p} \tr (Y_m Y_m^\top)^k\) converges in expectation towards 
\[
m_k= \sum_{\pi \in \mathcal{NC}(V)} \frac{\phi^{k-|\pi|}}{\psi^{k-1}} \,\theta_1(f)^{S_\pi}  \prod_{i=1}^{R_\pi} \left ( \sum_{\mu_i \in \mathcal{NC}(W_i^\pi)} \psi^{|W_i^\pi|-|\mu_i|} \theta_1(f)^{S_{\mu_i}} \theta_2(f)^{|W_i^\pi| - S_{\mu_i}} \right ),
\]
where 
\begin{itemize} 
\item for any noncrossing partition \(P\) of \(W\) or \(V\), \(S_P = |b(P)|\) denotes the number of nearest neighbor pairs within a same block of \(P\) (see Definition~\ref{def: partition 2}) and \(R_P = k - |P| + 1 - S_P\);
\item \(W_1^\pi, \ldots, W_{R_\pi}^\pi\) are the subsets with more than one element associated to \(\pi \in \mathcal{NC}(V)\), as described by Definition~\ref{def: NC(V)}. 
\end{itemize}
\end{lem}

In particular, Lemma~\ref{lem: moments alpha=2} says that for any partitions \(\pi \in \mathcal{P}(V)\) and \(\mu \in \mathcal{P}(W)\), the limiting injective trace \(\tau^0_{G^{\pi,\mu}}\) is nonvanishing if the graph \(G^{\pi,\mu}\) is a cactus of simple bipartite cycles. 

\begin{proof}
According to Remark~\ref{rmk: C_deg(w) alpha=2}, if \(d\) is an even integer, then the parameter \(C_d(f,2)\) is given by 
\begin{equation} \label{eq: C_d(f,2)}
C_d(f) = \theta_1(f)^{d/2}.
\end{equation}
We also observe from~\eqref{eq: C_{W_i}} that the parameter \(C_W(f)\) associated to the simple bipartite cycle \(G = (W \cup V, E)\) results in
\[
\begin{split}
C_W(f) & = \frac{(-\sigma_w^2)^{|W|}}{2^{|W|}(2\pi)^{2|W|}} \int_{\R^{2|W|}} \prod_{i=1}^{2|W|} \textnormal{d} \gamma_i \hat{f}(\gamma_i) e^{-\frac{\sigma_w^2 \sigma_x^2}{2}\gamma_i^2} \\
& \quad \times \E \left [ \prod_{i=2}^{|W|} (\gamma_{2(i-1)} X_{i-1} + \gamma_{2i-1}X_i)^2 (\gamma_1 X_1 + \gamma_{2 |W|} X_{|W|})^2\right ].
\end{split} 
\]
Note that \(C_W(f)\) is nonvanishing only for the term in the expectation containing all \(\gamma_i\)'s. Indeed, if there is a term which does not contain a parameter \(\gamma_i\), say \(\gamma_1\), then we can factorize the integral \(\int_{\R} \hat{f}(\gamma_1) e^{-\frac{\sigma_w^2\sigma_x^2}{2} \gamma_1^2} \textnormal{d} \gamma_1\) which vanishes since \(\hat{f}\) is odd by assumption. As a consequence, the parameter \(C_W(f)\) is nonvanishing only for the term in the expectation given by \(\E \left [2^{|W|} \prod_{i=1}^{2 |W|}  \gamma_i  X_i^2 \right ] = 2^{|W|} \sigma_x^{2|W|} \prod_{i=1}^{2 |W|} \gamma_i\). We therefore obtain 
\[
\begin{split}
C_W(f) & = \frac{(-\sigma_w^2Â \sigma_x^2)^{|W|}}{(2\pi)^{2|W|}} \int_{\R^{2|W|}} \prod_{i=1}^{2|W|} \textnormal{d} \gamma_i \hat{f}(\gamma_i) \gamma_i e^{-\frac{\sigma_w^2 \sigma_x^2}{2}\gamma_i^2} = \left ( \frac{\sigma_w \sigma_x}{2 \pi} \int_{\R} i \gamma \hat{f}(\gamma)  e^{-\frac{\sigma_w^2 \sigma_x^2}{2}\gamma^2}  \textnormal{d} \gamma\right )^{2 |W|}.
\end{split} 
\]  
By the Fourier property \(\hat{f'}(\gamma) = i \gamma \hat{f}(\gamma)\), we then have  
\begin{equation} \label{eq: C cycle (f,2)}
C_W(f)  = \left ( \frac{\sigma_w \sigma_x}{2 \pi} \int_\R \hat{f'}(\gamma) e^{-\frac{\sigma_w^2 \sigma_x^2}{2} \gamma^2} \textnormal{d}\gamma\right )^{2|W|} =  \left ( \frac{1}{\sqrt{2 \pi}}\int_\R f'(x) e^{-\frac{x^2}{2 \sigma_w^2 \sigma_x^2}} \textnormal{d} x \right )^{2|W|}  = \theta_2(f)^{|W|}.
\end{equation}
From Lemma~\ref{lem: contr non-cross part in V} and using~\eqref{eq: C_d(f,2)} and~\eqref{eq: C cycle (f,2)}, if \(\mu = \{\{w_i\}, i \in [k]\}\) and \(\pi \in \mathcal{NC}(V)\) it follows that
\begin{equation} \label{eq: alpha=2 V}
\tau^0_{G^{\pi,\mu}} =  \frac{\phi^{k - |\pi|}}{\psi^{k-1}} \theta_1(f)^{S_\pi}  \prod_{i=1}^{R_\pi}  \theta_2(f)^{|W_i^\pi|} =  \frac{\phi^{k - |\pi|}}{\psi^{k-1}} \theta_1(f)^{S_\pi}  \theta_2(f)^{k - S_\pi},
\end{equation}
where we used the fact that \(\sum_{i=1}^{R_\pi}  |W_i^\pi| + S_\pi=k\). 

Now, consider a partition \(\mu \in \mathcal{P}(W)\) and \(\pi = \{\{v_i\}, i \in [k]\}\). Recall from the proof of Proposition~\ref{main3} that the limiting injective trace is given by 
\[
\tau^0_{G^{\pi,\mu}} = \frac{1}{\psi^{|\mu|-1}} \frac{1}{(2\pi)^{2k}} \int_{\R^{2k}} \prod_{e \in E^{\pi,\mu}} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat f(\gamma_e^i) e^{- \frac{\sigma_w^2}{2} \sum_{w \in W^{\pi,\mu}} \E_X \left [ Z_w(\boldsymbol{\gamma})\right ]} g_{G^{\pi,\mu}}(\boldsymbol{\gamma}),
\]
where \( g_{G^{\pi,\mu}}(\boldsymbol{\gamma})\) is given by~\eqref{eq: function g_G}. In this case, \(\E_X \left [ Z_w(\boldsymbol{\gamma})\right ]\) reduces to
\[
\E_X \left [ Z_w(\boldsymbol{\gamma}) \right ] =\E_X \left [ \left( \sum_{v \colon v \sim w} (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))}) X_v\right )^2 \right ]  = \sigma_x^2 \sum_{v \colon v \sim w} (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))})^2. 
\]
Since the vertices \(v_1, \ldots, v_k\) are pairwise distinct, the edges in \(E^{\pi, \mu}\) have multiplicity at most two. Note that the number of edges with multiplicity equal to two corresponds to the number \(S_\mu = |b(\mu)|\) of pairs of adjacent elements in a same block of \(\mu\). This implies that 
\[
\tau^0_{G^{\pi,\mu}}=  \frac{1}{\psi^{|\mu|-1}} \frac{1}{(2\pi)^{2k}} \int_{\R^{2k}} \prod_{e \in E^\pi \colon \atop m(e)=1}  \textnormal{d} \gamma_e\hat{f}(\gamma_e) e^{-\frac{ \sigma_x^2 \sigma_w^2}{2}\gamma_e^2} \prod_{e \in E^\pi \colon \atop m(e)=2}  \textnormal{d} \gamma_e^1\textnormal{d} \gamma_e^2 \hat{f}(\gamma_e^2) \hat{f}(\gamma_e^2) e^{-\frac{ \sigma_x^2 \sigma_w^2}{2}(\gamma_e^1+\gamma_e^2)^2} g_{G^{\pi,\mu}}(\boldsymbol{\gamma}).
\]
We observe that \(\tau^0_{G^{\pi,\mu}}\) is nonvanishing only for those terms in \(g_{G^{\pi,\mu}}(\boldsymbol{\gamma})\) that contain all \(\gamma_e\) such that \(m(e) =1\). Indeed, as explained above, if there is a summand in \(g_{G^{\pi,\mu}}(\boldsymbol{\gamma})\) that does not contain \(\gamma_{e_0}\) for some edge \(e_0 \in E^{\pi,\mu}\) such that \(m(e_0)=1\), then we can factorize the integral \(\int_{\R} \hat{f}(\gamma_{e_0}) e^{-\frac{\sigma_w^2\sigma_x^2}{2} \gamma_{e_0}^2} \textnormal{d} \gamma_{e_0}\) which is exactly zero, and thus \(\tau^0_{G^{\pi,\mu}}\) vanishes. In particular, we note that the nonvanishing contribution comes only from the summand 
\[
\prod_{i=1}^{R_\mu} \E \left [ \prod_{w \in W_i^\mu} Z_w(\boldsymbol{\gamma)}\right ], 
\]
where \(W_1^\mu, \ldots, W_{R_\mu}^\mu\) denote the finest partition of \(W^{\pi,\mu}\) (see Definition~\ref{def: NC(W)}). In particular, if \(\mu \in \mathcal{P}(W)\) is crossing, then there are no terms in \(g_{G^{\pi,\mu}}(\boldsymbol{\gamma})\) that contain all \(\gamma_e\) for edges \(e\) with multiplicity \(m(e)=1\). As a consequence, for every \(\pi \in \mathcal{NC}(W)\) and \(\pi = \{\{v_i\}, i \in [k]\}\) we have
\[
\begin{split}
\tau^0_{G^{\pi,\mu}}& =  \frac{1}{\psi^{|\mu|-1}} \frac{1}{(2\pi)^{2S_\mu}} \int_{\R^{2S_\mu}} \prod_{e \in E^{\pi,\mu} \colon \atop m(e)=2}  \textnormal{d} \gamma_e^1\textnormal{d} \gamma_e^2 \hat{f}(\gamma_e^2) \hat{f}(\gamma_e^2) e^{-\frac{ \sigma_x^2 \sigma_w^2}{2}(\gamma_e^1+\gamma_e^2)^2} \\
& \quad \times \frac{1}{(2\mu)^{2k - 2S_\mu}} \int_{\R^{2 k - 2S_\mu}}  \prod_{i=1}^{R_\mu} (-\sigma_w^2 \sigma_x^2)^{|W_i^\pi|} \prod_{e \in E_i^{\pi,\mu} \colon \atop m(e)=1}  \textnormal{d} \gamma_e \gamma_e \hat{f}(\gamma_e) e^{-\frac{ \sigma_x^2 \sigma_w^2}{2}\gamma_e^2} \\
& =  \frac{1}{\psi^{|\mu|-1}}  C_{2S_\mu}(f,2) \left ( \frac{\sigma_w \sigma_x }{2\pi} \int_\R i \gamma \hat{f}(\gamma) e^{- \sigma_w^2 \sigma_x^2 \gamma^2 /2} \textnormal{d} \gamma \right )^{2(k -S_\mu)}\\
& =  \frac{1}{\psi^{|\mu|-1}} \theta_1(f)^{S_\mu} \theta_2(f)^{k - S_\mu},
\end{split}
\]
where we used~\eqref{eq: C_d(f,2)} and~\eqref{eq: C cycle (f,2)}. Combining this with~\eqref{eq: alpha=2 V} as done in the proof of Proposition~\ref{prop: main cycle} yields the desired result. 
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Convergence of matrix moments in probability}\label{sec:cov}

Having proved the convergence of the expected moments of the empirical eigenvalue distribution \(\hat{\mu}_M\) in the previous subsection, we now address the convergence in probability of these moments, thereby completing the proof of Theorem~\ref{main1}.

\begin{lem} 
The variances of the moments vanish asymptotically. Specifically, under Assumptions~\ref{hyp1}-\ref{hyp3}, for every integer \(k \ge 1\), 
\[
\lim_{m, p, n \to \infty} \var \left ( \frac{1}{p}  \tr  M^k \right) = 0.
\]
\end{lem}

The convergence in probability of the matrix moments follows directly from this result by applying Chebyshev's inequality. 

\begin{proof}
For every positive integer \(k \ge 1\), the variance of \( \frac{1}{p}  \tr (Y_m Y_m^\top)^k\) is given by
\[
\var \left ( \frac{1}{p}  \tr (Y_m Y_m^\top)^k \right) = \frac{1}{p^2} \sum_{1 \leq i_1, \ldots, i_k \leq p \atop 1 \leq i'_1, \ldots, i'_k \leq p} \sum_{1 \leq j_1, \ldots, j_k \leq m \atop 1 \leq j_1' , \ldots, j_k' \leq m} \left ( \E \left [ P(\boldsymbol{i},\boldsymbol{j})P(\boldsymbol{i}',\boldsymbol{j}') \right ] -\E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ]  \E \left [ P(\boldsymbol{i}',\boldsymbol{j}') \right ]\right ),
\]
where for multi-indices \(\boldsymbol{i} = (i_1,\ldots, i_k)\) and \(\boldsymbol{j} = (j_1,\ldots, j_k)\),
\[
P(\boldsymbol{i},\boldsymbol{j}) = \prod_{\ell=1}^k Y_{i_\ell j_\ell} Y_{i_{\ell+1} j_\ell}, \quad \text{with} \enspace i_{k+1} = i_1,
\]
and \(P(\boldsymbol{i}',\boldsymbol{j}')\) is defined analogously. The expectation \(\E \left [ P(\boldsymbol{i},\boldsymbol{j})P(\boldsymbol{i}',\boldsymbol{j}') \right ]\) factorizes unless there are identifications among indices in \(\boldsymbol{i}, \boldsymbol{i}'\) or \(\boldsymbol{j}, \boldsymbol{j}'\). Thus, the variance vanishes unless there exists at least one pair \((\ell, \ell')\) such that \(i_\ell = i_{\ell'}'\) or \(j_\ell = j_{\ell'}'\). This corresponds to overlap between the two bipartite cycle graphs associated with the terms \(P(\boldsymbol{i},\boldsymbol{j})\) and \(P(\boldsymbol{i}',\boldsymbol{j}')\), where vertices in these graphs are identified. Consequently, the variance can be rewritten as
\begin{equation} \label{var}
\var \left ( \frac{1}{p}  \tr (Y_m Y_m^\top)^k \right) = \frac{1}{p^2} \sum_{\exists \ell, \ell' \colon (i_\ell = i'_{\ell'}) \vee (j_\ell = j'_{\ell'})} \left ( \E \left [ P(\boldsymbol{i},\boldsymbol{j})P(\boldsymbol{i}',\boldsymbol{j}') \right ] -\E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ]  \E \left [ P(\boldsymbol{i}',\boldsymbol{j}') \right ]\right ).
\end{equation}
We focus on the first term in~\eqref{var}, which can be expanded as follows:
\[
\begin{split}
& \frac{1}{p^2} \sum_{\exists \ell, \ell' \colon (i_\ell = i'_{\ell'}) \vee (j_\ell = j'_{\ell'})} \E \left [ P(\boldsymbol{i},\boldsymbol{j})P(\boldsymbol{i}',\boldsymbol{j}') \right ] \\
& = \frac{1}{p} \sum_{\pi, \mu \in \mathcal{P}(2k) \colon \atop \exists \ell, \ell' \in [k] \colon (\ell \sim_\pi k+\ell' ) \vee (\ell \sim_\mu k+\ell')} \frac{1}{p} \sum_{\boldsymbol{i} \cup \boldsymbol{i}' \in \mathcal{I}_\pi} \sum_{\boldsymbol{j} \cup \boldsymbol{j}' \in \mathcal{J}_\mu}  \E \left [ P(\boldsymbol{i},\boldsymbol{j})P(\boldsymbol{i}',\boldsymbol{j}') \right ] \\
& = \frac{1}{p} \sum_{\pi, \mu \in \mathcal{P}(2k) \colon \atop \exists \ell, \ell' \, \text{s.t.} \, \ell \sim_\pi k+\ell' \, \text{or} \, \ell \sim_\mu k+\ell'}   \tau_{p,m,n}^0 \left [ T^{\pi,\mu} \right ],
\end{split}
\]
where \(\mathcal{P}(2k)\) is the set of partitions of \(\{1, \ldots, 2k\}\), and \(\mathcal{I}_\pi\) (respectively, \(\mathcal{J}_\mu\)) is the set of multi-indices \(\boldsymbol{i} \cup\boldsymbol{i}' \) in \(\{1, \ldots, p\}^{2k}\) (respectively, \(\boldsymbol{j} \cup\boldsymbol{j}' \) in \(\{1, \ldots, m\}^{2k}\) ) such that \(r \sim_\pi s\) if and only if \(x_r = x_s\), where \(x\) represents either \(i\) or \(i'\). Here, \(T^{\pi,\mu}\) is the connected bipartite test graph of length \(4k\) defined by identifications encoded in \(\pi\) and \(\mu\), and \(\tau_{p,m,n}^0 \left [ T^{\pi,\mu} \right ]\) denotes its mean injective trace (see Definition~\ref{def: traffic}). By Theorem~\ref{main3}, as \(p,m,n \to \infty\) such that \(n/m \to \phi, n/p \to \psi\), the mean injective trace \(\tau_{p,m,n}^0 \left [ T^{\pi,\mu} \right ]\) converges to a real number \(\tau_{G^{\pi,\mu}}^0\). As a result, each summand satisfies
\[
\frac{1}{p} \tau_{p,m,n}^0 \left [ T^{\pi,\mu} \right ] = \mathcal{O} \left ( \frac{1}{p} \right).
\]
The second term in~\eqref{var} is given by
\[
\frac{1}{p^2} \sum_{\exists \ell, \ell' \colon (i_\ell = i'_{\ell'}) \vee (j_\ell = j'_{\ell'})} \E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ]  \E \left [ P(\boldsymbol{i}',\boldsymbol{j}') \right ].
\]
We note that the expectation \( \E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ] \) depends only on the identifications among indices within \(\boldsymbol{i}\) and \(\boldsymbol{j}\), so it is unaffected by overlaps with \(\boldsymbol{i}'\) or \(\boldsymbol{j}'\). %Specifically, given any identification within \(\boldsymbol{i}\) and \(\boldsymbol{j}\), the expectation \( \E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ]\) remains unchanged if we introduce additional identifications within \(\boldsymbol{i}\) and \(\boldsymbol{i}'\) or within \(\boldsymbol{j}\) and \(\boldsymbol{j}'\). 
This invariance allows the second term to be rewritten as
\[
\begin{split}
\frac{1}{p^2} \sum_{\exists \ell, \ell' \colon (i_\ell = i'_{\ell'}) \vee (j_\ell = j'_{\ell'})} \E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ]  \E \left [ P(\boldsymbol{i}',\boldsymbol{j}') \right ] & = \mathcal{O} \left ( \frac{1}{p} + \frac{1}{m} \right) \left ( \frac{1}{p} \sum_{1 \le i_1, \ldots, i_k \le p} \sum_{1 \le j_1, \ldots, j_k \le m}\E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ] \right)^2\\
& = \mathcal{O} \left ( \frac{1}{p} + \frac{1}{m} \right) \left(\tau_{p,m,n} \left [ T_{\text{cycle}}\right ] \right)^2 ,
\end{split}
\]
where the second equality follows from~\eqref{traffic cycle} and \(T_{\text{cycle}}\) denotes the simple bipartite cycle of length \(2k\). The scaling factor \(\mathcal{O} \left ( \frac{1}{p} + \frac{1}{m} \right)\) arises from the fact that identifications such as \(i_1 = i_1'\) reduce the summation range for \(\boldsymbol{i}'\), introducing a factor \(\frac{1}{p}\). Similarly, identifications among indices in \(\boldsymbol{j}\) and \(\boldsymbol{j}'\) introduce a factor \(\frac{1}{m}\). Finally, since the traffic trace \(\tau_{p,m,n} \left [ T_{\text{cycle}}\right ] \) converges by Theorem~\ref{main3}, we obtain that
\[
\frac{1}{p^2} \sum_{\exists \ell, \ell' \colon (i_\ell = i'_{\ell'}) \vee (j_\ell = j'_{\ell'})} \E \left [ P(\boldsymbol{i},\boldsymbol{j})\right ]  \E \left [ P(\boldsymbol{i}',\boldsymbol{j}') \right ] = \mathcal{O} \left ( \frac{1}{p} + \frac{1}{m} \right) .
\]
Combining both terms, we conclude that
\[
\var \left ( \frac{1}{p}  \tr  M^k \right) = \mathcal{O}  \left ( \frac{1}{p} \right).
\]
Letting \(p \to \infty\), the result follows.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Almost sure weak convergence of the empirical spectral measure} \label{sec:concen}

In this subsection, we prove Theorem~\ref{main1bis}, which establishes the almost sure weak convergence of the empirical spectral measure \(\hat{\mu}_M\). The key step in the proof is to show that the moments \(m_k\) do not grow too quickly, ensuring they define a unique probability measure. This is achieved by verifying Carleman's condition, which states that a sequence of moments \((m_k)_{k \in \N}\) uniquely determines a probability measure \(\mu\) if \(\sum_{k=1}^\infty |m_k|^{-1/k} = + \infty\). To this end, we require sharp estimates for the moments \(m_k\), which are explicitly given in Proposition~\ref{prop: main cycle}. The moments \(m_k\) depend on certain graph-related parameters, specifically \(C_d(f)\) and \(C_{(W_i)_{i=1}^K}(f)\), defined in~\eqref{eq: C_deg (f)} and~\eqref{eq: C_{W_i}}, respectively. We first provide bounds for these parameters under specific assumptions on the distributions \(\nu_w\) and \(\nu_x\), and we remind the reader of the definition of $\Phi$ from Assumption~\ref{hyp1}.

\begin{lem} \label{lem: bound parameter}
For every even integer \(d\), let \(C_d (f)\) denote the parameter given by~\eqref{eq: C_deg (f)}. Let \(G = (W \cup V, E)\) be a finite, connected bipartite graph \(G = (W \cup V, E)\). For every subsets \(W_1, \ldots, W_K\) of \(W\) with \(|W_i| \ge 2\) and with a nontrivial intersection (i.e., for every \(i \in [K]\), \(\cup_{j \neq i} W_j\cap W_i \neq  \emptyset \)), let \(C_{(W_i)_{i=1}^K} (f)\) denote the parameter given by~\eqref{eq: C_{W_i}}. Then, the following results hold.
\begin{enumerate}
\item[(a)] Assume that there exists a constant \(M >0\) such that \(|\Phi(\lambda)| \le M\) for all \(\lambda \in \R\). Then, there exist universal constants \(c,C > 0\) such that 
\[
|C_d (f)| \le c \quad \textnormal{and} \quad | C_{(W_i)_{i=1}^K} (f) | \le C M^{\sum_{i=1}^K |W_i|}.
\]
\item[(b)] Assume that \(\Phi(\lambda) = - \sigma^\alpha |\lambda|^\alpha\) with \(\alpha \in (0,2)\) and \(\sigma >0\). Moreover, assume that \(\nu_x\) is the centered normal distribution with variance \(\sigma_x^2\). Then, there exist universal constants \(c,C > 0\) such that 
\[
|C_d (f)| \le c \quad \textnormal{and} \quad | C_{(W_i)_{i=1}^K} (f) | \le  C^{\sum_{i=1}^K |W_i|} \prod_{i=1}^K |W_i|!.
\]
\end{enumerate}
\end{lem}

Note that item (a) is satisfied by sparse Wigner matrices~\eqref{hada}, whereas item (b) concerns L\'evy matrices~\eqref{levy}.

\begin{proof}
We begin by proving statement (a). According to~\eqref{eq: C_deg (f)} and~\eqref{thehypf}, we have 
\[
|C_d (f)| \le c \left ( \frac{1}{2 \pi} \int_\R |\hat{f}(t)| \textnormal{d}t \right)^d \le \tilde{c},
\]
for some universal constant \(\tilde c >0\). Similarly, from~\eqref{eq: C_{W_i}} and using the fact that the random variables \(Z_w\), as defined in~\eqref{eq: Z_w}, are also bounded by \(M\), there exists \(C >0\) such that
\[
| C_{(W_i)_{i \le K}} (f) | \le C M^{\sum_{i=1}^K |W_i|},
\]
as desired. We now consider statement (b). The bound for \(C_d (f)\) follows again from~\eqref{eq: C_deg (f)} and~\eqref{thehypf} since we have \(e^{- \sigma^\alpha \E_X \left [ |\sum_{i=1}^{d/2} (\gamma_i^1 + \gamma_i^2) X_i|^\alpha \right ]}  \le 1\). For the parameter \(C_{(W_i)_{i \le K}} (f) \), substituting \(\Phi(\lambda) = - \sigma^\alpha |\lambda|^\alpha\) results in 
\[
C_{(W_i)_{i=1}^K}(f) = \frac{1}{(2\pi)^{|\cup_i^K E_i|}} \int_{\R^{|\cup_{i=1}^K E_i|}} \prod_{e \in \cup_{i=1}^K E_i} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i \hat{f}(\gamma_e^i) e^{\sum_{w \in \cup_{i=1}^K W_i} \E_X \left [Z_w (\boldsymbol{\gamma})\right ]} \prod_{i=1}^K \E_X \left [ \prod_{w \in W_i} Z_w (\boldsymbol{\gamma}) \right ],
\]
where 
\[
Z_w (\boldsymbol{\gamma})= -\sigma^\alpha \left | \sum_{v \in V \colon v \sim w} (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))}) X_v \right |^\alpha.
\]
For each \(w\), we note that
\[
\sum_{v \in V \colon v \sim w} (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))}) X_v \stackrel{d}{=} \sigma_x \sqrt{\sum_{v \in V\colon v \sim w} (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))})^2} G_w,
\]
where the random variables \(G_w\sim \mathcal{N}(0,1)\) may be correlated. Consequently, 
\begin{equation} \label{exp1}
\E_X \left [Z_w (\boldsymbol{\gamma}) \right ] = - \sigma^\alpha \sigma_x^\alpha \beta_\alpha \left | \sum_{v \in V \colon v \sim w }  (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))})^2\right |^{\alpha/2} ,
\end{equation}
where 
\[
\beta_\alpha \coloneqq \E \left [ |G_w|^\alpha \right ]  =2^{\alpha/2} \frac{\Gamma \left ( \frac{\alpha +1}{2} \right)}{\sqrt{\pi}}. 
\]
Similarly, we have
\begin{equation} \label{exp2}
\begin{split}
\E_X \left [ \prod_{w \in W_i} Z_w (\boldsymbol{\gamma}) \right ] & = \prod_{w \in W_i} -\sigma^\alpha \sigma_x^\alpha \left | \sum_{v \in V \colon v \sim w }  (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))})^2\right |^{\alpha/2}  \E \left [ \prod_{w \in W_i} |G_w|^\alpha \right ] \\
& \le  (- \sigma^\alpha \sigma_x^\alpha)^{|W_i|} \beta_{\alpha |W_i|} \prod_{w \in W_i} \left | \sum_{v \in V \colon v \sim w }  (\gamma_{(w,v)}^1 + \cdots + \gamma_{(w,v)}^{m((w,v))})^2\right |^{\alpha/2} ,
\end{split}
\end{equation}
where we applied H\"{o}lder's inequality. Combining~\eqref{exp1} and~\eqref{exp2}, we obtain
\[
\begin{split}
\left | C_{(W_i)_{i=1}^K}(f) \right | & \le  c^{|\cup_{i=1}^K E_i|} (-\sigma^\alpha \sigma_x^\alpha)^{\sum_{i=1}^K |W_i|} \prod_{i=1}^K \beta_{\alpha |W_i|} \\
& \quad \times \frac{1}{(2\pi)^{|\cup_i^K E_i|}}\int_{\R^{|\cup_{i=1}^K E_i|}} \prod_{e \in \cup_{i=1}^K E_i} \prod_{i=1}^{m(e)} \textnormal{d} \gamma_e^i 
\frac{C_{2}}{1+|\gamma_{e}^{i}|^{2}}\\
& \quad \times \prod_{i=1}^K  \prod_{w \in W_i} 
e^{- \sigma^\alpha \sigma_x^\alpha \beta_\alpha   \left | \sum_{v \in V \colon v \sim w }   \left ( \sum_{j=1}^{m((w,v))} \gamma_{(w,v)}^j \right )^2 \right |^{\alpha/2} }  
\left | \sum_{v \in V \colon v \sim w }  \left ( \sum_{j=1}^{m((w,v))} \gamma_{(w,v)}^j \right )^2\right |^{\alpha/2} ,
\end{split}
\]
where we used that \(|\hat{f}(t)| \le C_{2}/(1+|t|^2)\) according to~\eqref{thehypf}. Using that there exists a universal constant $C_0$ such that uniformly,
$$e^{- \sigma^\alpha \sigma_x^\alpha \beta_\alpha   \left | \sum_{v \in V \colon v \sim w }   \left ( \sum_{j=1}^{m((w,v))} \gamma_{(w,v)}^j \right )^2 \right |^{\alpha/2} }  \\
\left | \sum_{v \in V \colon v \sim w }  \left ( \sum_{j=1}^{m((w,v))} \gamma_{(w,v)}^j \right )^2\right |^{\alpha/2}\le C_{0}$$
we deduce that there exists a finite constant $C_{1}$ so that 
\[
\begin{split}
& \left | C_{(W_i)_{i=1}^K}(f) \right |  \le C_1^{\sum_{i=1}^K |W_i|} \prod_{i=1}^K \beta_{\alpha |W_i|} .
\end{split}
\]
This completes the proof for statement (b).
\end{proof}

We now show that the limiting moments of the symmetrized random matrix \(H \in \R^{(p+m) \times (p+m)}\), defined by
\[
H \coloneqq 
\begin{pmatrix}
0 & Y_m^\top\\
Y_m & 0
\end{pmatrix},
\]
satisfy Carleman's condition. Let \(\{\lambda_i (H),1\le i\le m+p\}\) denote the eigenvalues of \(H\), and let \(\{\lambda_{i},1\le i\le p\}\) be the eigenvalues of \(M=Y_m Y_m^\top\). The \(2p\) nonzero eigenvalues of \(H\) correspond to \(\pm \sqrt{\lambda_1}, \ldots, \pm \sqrt{\lambda_p}\). The empirical spectral measure \(\hat{\mu}_{H}=\frac{1}{m+p}\sum_{i=1}^{m+p}\delta_{\lambda_{i}(H)}\) of \(H\) is therefore related to the empirical spectral measure \(\hat{\mu}_M=\frac{1}{p} \sum_{i=1}^{p} \delta_{\lambda_{i}}\) of \(M\) via
\begin{equation}\label{lin}
\int f(x^{2}) \text{d} \hat{\mu}_{H} (x)  = \frac{2p}{p+m}\int f(x) \text{d} \hat{\mu}_M (x) + \frac{m-p}{m+p} f(0),
\end{equation}
for any bounded and continuous function \(f\). In particular, we see that for every integer number $k\ge 1$,
\[
\begin{split}
\lim_{m,p,n\rightarrow\infty} \int_\R x^{2k} \textnormal{d} \hat{\mu}_H (x)& = \frac{2\phi}{\phi+\psi} m_k \eqqcolon \tilde m_{2k}, \\
\lim_{m,p,n\rightarrow\infty} \int_\R x^{2k+1} \textnormal{d} \hat{\mu}_H (x) & = 0 = \tilde m_{2k+1},
\end{split}
\]
where we recall that \(\phi = \lim_{p,m,n\to \infty} n/m\) and \(\psi = \lim_{p,m,n\to \infty} n/p\). The following result shows that the sequence of moments \((\tilde{m}_k)\) satisfies Carleman's condition, thereby defining a unique limiting measure \(\hat{\mu}\).

\begin{lem}
Under assumptions (a) and (b) of Lemma~\ref{lem: bound parameter}, there exists a finite constant \(C >0\) such that for every integer number \(k\),
\[
|\tilde m_{k}|\le (C k)^k.
\]
As a result, there exists a unique probability measure \(\tilde\mu\) with moments \(\tilde m_k\). Furthermore, there exists a unique probability measure $\mu$ with moments $m_k$. Finally, the empirical spectral measure \(\hat{\mu}_M\) of \(M\) converges weakly, both in expectation and in probability, to \(\mu\).
\end{lem}

\begin{proof}
Recall that the number of noncrossing partitions of a set of size \(k\) is given by the Catalan number, which has the explicit formula \(C_k = \frac{(2k)!}{(k+1)! k!}\) and asymptotically behaves as \(C_k \sim \frac{4^k k^{-3/2}}{\sqrt{\pi}}\). On the other hand, the number of possible partitions of a set of size \(k\) is given by the Bell number \(B_k\), which can be expressed as
\[
B_k = \sum_{\ell=1}^k S(k,\ell),
\]
where \(S(k,\ell)\) are the Stirling numbers of the second kind and count the possible partitions of a set of size \(k\) into \(\ell\) nonempty subsets. Similarly, the ordered Bell numbers (or Fubini numbers) can be computed from the Stirling numbers of the second kind via
\[
a(k) = \sum_{\ell=1}^k S(k,\ell) \ell!,
\]
and asymptotically behave as \(a(k) \sim \frac{1}{2} k! \log(2)^{-(k+1)}\).

From Proposition~\ref{prop: main cycle}, the moments \(m_k\) are expressed as a sum over noncrossing partitions \(\pi\) of \(V\), over partitions \(\mu\) of the subsets \(W_i^\pi\), and over partitions of the set \(\{1, \ldots,R_\mu\}\). Using the bounds derived in Lemma~\ref{lem: bound parameter}, we claim 
\begin{equation} \label{claim}
|m_k| \leq C^k k! C_k a(k),
\end{equation}
for some constant \(C >0\). Substituting the asymptotic expressions for \(C_k\) and \(a(k)\), we find 
\[
|m_k | \sim (\tilde C k)^{2k},
\]
for some constant \(\tilde C >0\). This implies that the moments \((\tilde{m}_k)\) satisfies the bound
\[
|\tilde m_k| \leq  (\tilde C k)^k.
\]
This bound ensures that the sequence \((\tilde{m}_k)\) satisfies Carleman's condition. Thus, there exists a unique probability measure \(\tilde \mu\) such that, for every integer \(k\),
\[
\tilde m_k = \int x^k \text{d} \tilde\mu (x).
\]
By construction, \(\tilde \mu\) is symmetric. Furthermore, for every $k\ge 1$, the moments \(m_k\) satisfy
\[
m_k = \frac{\psi+\phi}{2\phi} \int x^{2k} \text{d} \tilde\mu(x) =\int x^{k} \text{d} \mu(x),
\]
where the probability measure \(\mu\) is given by 
\[
\mu=\frac{\phi+\psi}{2\phi}  x^2 \#\tilde\mu + \frac{\phi-\psi}{2\phi} \delta_0.
\]
Here, \(x^2 \#\tilde\mu\) denotes the pushforward measure of \(\tilde \mu\) under the mapping \(x \mapsto x^2\). This last point follows directly from Theorem~\ref{main1}, as convergence in moments is stronger than weak convergence. 

We now prove~\eqref{claim}. By Proposition~\ref{prop: main cycle} and Lemma~\ref{lem: bound parameter}, there are constants \(c,\tilde{c}>0\) such that
\[
|m_k|  \le  c^k |\mathcal{NC}(V)| \sum_{\mu \in \mathcal{P}(W), \mu \neq \{W\}} \sum_{P \in \mathcal{P}(R_\mu)} \tilde{c}^{\sum_{i=1}^{|P|} |\tilde{W}_i^P|} \prod_{i=1}^{|P|} |\tilde{W}_i^P|!,
\]
where we used the upper bound in item (b) of Lemma~\ref{lem: bound parameter}, as it represents the least favorable case. Recall that for a partition \(\mu \in \mathcal{P}(W)\), we obtain subsets \(W_1^\mu, \ldots, W_{R_\mu}^\mu\), which form the finest partition of \(W^\mu\) (see Definitions~\ref{def: NC(W)} and~\ref{def: P(W)}). For every partition \(P \in \mathcal{P}(R_\mu)\), merging the corresponding subsets results in the subsets \(\tilde{W}_1^P, \ldots, \tilde{W}_{|P|}^P\). The number \(R_\mu\) satisfies \(R_\mu \le k - |\mu| + 1\). For further clarification, we refer the reader to Proposition~\ref{prop: main cycle}. According to item (b) of Proposition~\ref{prop: combinatorics}, for any partition \(P \in \mathcal{P}(R_\mu)\), \(\sum_{i=1}^{|P|} |\tilde{W}_i^P| =|W^\mu| + |P| - 1  \le |\mu| + R_\mu - 1 \le k\). We bound \(\prod_{i=1}^{|P|} |\tilde{W}_i^P|! \) above by \(k!\) as follows:
\[
\begin{split}
k! & \ge (|\tilde{W}_1^P| +\cdots + |\tilde{W}_{|P|}^P|)!  > \prod_{i=1}^{|P|} |\tilde{W}_i^P|!,
\end{split}
\]
where we used the fact that \(|\tilde{W}_i^P| > 1\). This leads to the inequality
\[
\begin{split}
|m_k| &  \le c^k C_k \tilde{c}^k k!  \sum_{\mu \in \mathcal{P}(W), \mu \neq \{W\}} \sum_{P \in \mathcal{P}(R_\mu)} 1,
\end{split}
\]
Our goal is to show that 
\[
\sum_{\mu \in \mathcal{P}(W), \mu \neq \{W\}} \sum_{P \in \mathcal{P}(R_\mu)} 1 \le C' a(k),
\]
for some constant \(C'>0\). Let \(\mu\) denote a partition of \(W\) into \(\ell\) blocks, where \(2 \le \ell \le |W|=k\) (the case \(\ell=1\) corresponds to \(\mu = \{W\}\)). The number of such partitions is given by \(S(k,\ell)\). Thus, the sum can be bounded as
\[
\sum_{\mu \in \mathcal{P}(W), \mu \neq \{W\}} \sum_{P \in \mathcal{P}(R_\mu)} 1 \le C' \sum_{\ell=2}^k S(k,\ell) R_\ell! ,
\]
where \(C'>0\) is a constant and \(R_\ell\) denotes the largest possible number \(R_\mu\) associated with a partition \(\mu\) having \(\ell\) blocks.  We aim to show that \(R_\ell \le \ell\). Recall that for a partition \(\mu\), the number \(R_\mu\) is defined by 
\[
R_\mu = |c(\mu)| - |b(\mu)| +1, 
\]
where \(b(\mu)\) denotes the collection of pairs of nearest neighbor elements lying in a same block of \(\mu\), and \(c(\mu)\) the collection of pairs of next elements within a block such that, for every other pair of elements in a same block, the two pairs do not intersect (see Definition~\ref{def: partition 2}). First, consider \(\ell \ge  \lceil \frac{k+1}{2}\rceil\). In this case, we have
\[
R_\ell \le |c(\mu)| + 1 \le k - \ell + 1 \le k - \left \lceil \frac{k+1}{2} \right \rceil + 1 \le \ell,
\]
where we used the fact that \(|c(\mu)| \le k-\ell\), with equality when \(\mu\) is noncrossing. Now, let \(\ell \le \left \lceil \frac{k-1}{2} \right \rceil\). We want to show that \(|c(\mu)| - |b(\mu)| \le \ell-1\).
\begin{itemize}
\item We first consider noncrossing partitions. In this case, we have \(|c(\mu)| = k - \ell\), so proving \(R_\ell \le \ell\) is equivalent to showing that \(|b(\mu)| \ge k - 2 \ell +1\). We proceed by induction on \(\ell\), showing that \(|b(\mu)| \ge k - 2 \ell + 2\). If \(\ell=2\), then there are two blocks containing \(r\) and \(k-r\) elements, where \(r \ge 1\). Since \(\mu\) is noncrossing, the blocks contain \(r-1\) and \(k-r-1\) pairs of consecutive elements, respectively. This gives \(|b(\mu)| = k-2\), which satisfies the inequality. Assume the claim holds for some \(2 \le \ell \le  \left \lceil \frac{k-1}{2} \right \rceil -1\). To increase the number of blocks from \(\ell\) to \(\ell+1\), we split an existing block into two smaller blocks. This operation reduces the number of nearest neighbor pairs by at most \(2\). If a block contains exactly two consecutive elements, say \(x_i \sim x_{i+1}\), moving \(x_{i+1}\) to a new block results in a noncrossing partition with \(\ell+1\) blocks and the number of pairs of consecutive elements decreases by \(1\). If a block contains at least three consecutive elements, say \(x_i \sim x_{i+1} \sim x_{i+2}\), we can move \(x_{i+1}\) to a new block while keeping \(x_i \sim x_{i+2}\) in the original block. This results in a noncrossing partition with \(\ell+1\) blocks and decreases the number of pairs of consecutive elements by \(2\). Thus, after increasing \(\ell\) by \(1\), the number of nearest neighbor pairs can decrease at most by \(2\), leading to \(|b(\mu)|  \ge k - 2 \ell + 2 - 2 =  k - 2 (\ell+1) + 2\). This completes the induction and shows that for noncrossing partitions, \(|c(\mu)| - |b(\mu)| \le \ell-2\). 
\item To extend the inequality to crossing partitions, we consider the set \(c(\mu) \backslash b(\mu)\). Note that by Remark~\ref{rmk: partition}, $b(\mu)\subset c(\mu)\cup\{(x_{1},x_{k})\}$ so that 
\(|c(\mu)| - |b(\mu)|  \le  |c(\mu) \backslash b(\mu)|\le  |c(\mu)| - |b(\mu)| +1\). In particular, if \(\mu\) is noncrossing, by the previous item, we have
\begin{equation}\label{bc}
|c(\mu) \backslash b(\mu)| \le \ell-1.
\end{equation}
\item We now prove the inequality~\eqref{bc} for crossing partitions by induction on the number of crossings \(n_\text{c}\) in \(\mu\). Let \(\mu\) be a partition with \(\ell\) blocks and \(n_\text{c}\) crossings. This means that there exist \(x_p < x_q < x_r < x_s\) such that \(x_p \sim x_r \not \sim x_q \sim x_s\), i.e., \((x_p,x_r)\) and \((x_q,x_s)\) are intersecting pairs. We note that by moving \(x_q\) into the block containing $x_{q+1}$   while keeping \(x_s\) in its original block, results in a new  partition \(\mu'\) with the same number \(\ell\) of blocks. Moreover, \(|c(\mu') \backslash b(\mu')| \ge |c(\mu) \backslash b(\mu)|\), since if we create a new element of nearest neighbors in $b(\mu')$, it is also included in $c(\mu')$, while we have at most the same number of elements in $c(\mu')$. Proceeding inductively, we find a sequence of partitions $\mu=\mu_{1},\ldots,\mu_{n_{c}}$  of partitions, where $\mu_{n_{c}}$ is noncrossing and has $\ell$ blocks, satisfying 
$$ |c(\mu) \backslash b(\mu)|= |c(\mu_{1}) \backslash b(\mu_{1})|\le |c(\mu_{2}) \backslash b(\mu_{2})|\le\cdots \le  |c(\mu_{n_{c}}) \backslash b(\mu_{n_{c}})|\le \ell-1,$$
where the last step follows from~\eqref{bc}.
\end{itemize}
This completes the proof that \(R_\ell \le \ell\) for all \(\ell\), thereby proving the claim~\eqref{claim}.
\end{proof}

We conclude by showing that the empirical measure of the eigenvalues converges almost surely using concentration of measure estimates. 

\begin{lem} \label{concen} 
Let $h \colon \R \to \R$ be a function such that the map $x \mapsto h(x^{2})$ has finite total variation norm $\|h\|_{\textnormal{TV}}$. Then, for every $\epsilon>0$,
\[
\mathbb{P} \left( \left | \int_\R h(x) \, \textnormal{d} \hat{\mu}_M(x) -\E \left [\int_\R h(x) \, \textnormal{d} \hat{\mu}_M(x) \right] \right |\ge \epsilon \|h\|_{\textnormal{TV}} \right) \le 4e^{-\frac{1}{2^{5}}\epsilon^{2}p}.
\]
Here, the total variation norm of \(h \colon \R \to \R\) is defined by \( \lVert h \rVert_{\textnormal{TV}} = \sup \sum_{k \in \mathbb{Z}} |h(x_{k+1}) - h(x_k)|\), where the supremum runs over all sequences \((x_k)_{k \in \mathbb{Z}}\) such that \(x_{k+1} \ge x_k\) for every \(k \in \mathbb{Z}\).
\end{lem}

Applying the Borel-Cantelli Lemma, the above concentration inequality ensures that the convergence of the empirical spectral measure holds almost surely, thus proving Theorem~\ref{main1bis}.

\begin{proof} 
Hereafter, we assume that $g(x) \coloneqq h(x^{2})$ has a total variation norm bounded by one. According to~\eqref{lin}, it suffices to show concentration for $\int g \, \text{d} \hat{\mu}_{H}$ in order to obtain concentration for $\int h \, \text{d} \hat{\mu}_M$. To prove this concentration estimate, we apply the Azuma-Hoeffding inequality, following the approach outlined in~\cite[Lemma C.2]{bordenave2011bis}. Conditionally to $X$, $H$ has independent column vectors $\{(Y_{m}(i),0), i\le p\}$ and independent row vectors $\{(Y_{m}(i)^\top,0), i\le p\}$. Therefore, we can apply the ideas of the concentration result from~\cite[Lemma C.2]{bordenave2011bis}. To this end, we successively apply Azuma-Hoeffding's inequality with respect to integration w.r.t.\ $W$ and $X$. First, fix the $X_{i}$'s and consider the martingale
\[
D_k \coloneqq \E \left [ \frac{1}{p}\tr( g(H)) | \mathcal F_{k} \right],
\]
where $\mathcal F_{k}$ denotes the filtration generated by $\{W_{i},i\le k\}\cup \{X_{\ell j}, j\le m, \ell\le n\}$ for \(1 \le k \le p\), with \(W_i = (W_{i1}, \ldots, W_{i m})^\top \in \R^m\). Let \(\E_k \left [\cdot \right ] \coloneqq \E_W \left [ \cdot | \mathcal{F}_k \right ]\) denote the conditional expectation w.r.t.\ \(\mathcal{F}_k\).  We denote by \(\sigma_X\) the sigma-algebra of the entries of the matrix \(X\), so \(\mathcal{F}_0 = \sigma_X\).  By construction, we have 
\[
\frac{1}{p} \tr( g(H)) - \E \left [ \frac{1}{p}\tr( g(H))|\sigma_X \right ] = \sum_{k=1}^p (D_k - D_{k-1}),
\]
since \(D_p = \frac{1}{p} \tr( g(H)) \) and \(D_0 =  \E \left [ \frac{1}{p} \tr( g(H)) |\sigma_X \right ] \) is the mean with respect to the $W$ of the function $D_{p}$. We now  bound the martingale differences uniformly:
$$\Delta_{k} \coloneqq D_{k} - D_{k-1}=\mathbb E_{k} \left [ \frac{1}{p}\tr( g(H))- \frac{1}{p}\tr( g(H')) \right],$$
where $H$ and $H'$ are coupled such that they are constructed with the same $W_{i}$ for every $i\le k-1$ and every $i\ge k+1$. This implies that $H-H'$ has rank at most two, as they differ at most by one column vector and one row vector. By Weyl's interlacing property, we deduce that 
$$\left|\tr( g(H))- \tr( g(H'))\right|\le 2,$$
where we used the assumption that the total variation norm of $g$ is bounded by one. It follows that 
$$|\Delta_{k}|\le \frac{2}{p}.$$ 
Applying Azuma-Hoeffding inequality (see e.g.~\cite[Lemma 1.2]{mcdiarmid}), we obtain that uniformly with respect to the entries of $X$,
$$\mathbb P\left(\left|\frac{1}{p} \tr( g(H)) - \E \left [ \frac{1}{p}\tr( g(H))|\sigma_X \right ]\right|\ge\epsilon\right)\le 2e^{-\frac{p\epsilon^{2}}{8}}\,.$$
We can apply the same strategy to integrate $\mathbb E \left [\frac{1}{p}\tr( g(H))|\sigma_{X} \right]$ w.r.t.\ $X$  
and obtain concentration w.r.t.\ the $X_{i}$'s by considering the martingale $\mathbb E \left [\frac{1}{p}\tr( g(H))|\sigma(X_{i},i\le k) \right]$ to obtain 
$$\mathbb{P} \left(\left | \E \left [\frac{1}{p}\tr( g(H)) \right ] - \E \left [ \frac{1}{p}\tr( g(H))|\sigma_{X} \right ] \right|\ge\epsilon\right)\le 2e^{-\frac{p\epsilon^{2}}{8}}\,.$$
Combining these two results with $g(x)=h(x^{2})/\|h(\cdot ^{2})\|_{\textnormal{TV}}$, together with~\eqref{lin}, yields the announced lemma.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\printbibliography
\end{document}  
