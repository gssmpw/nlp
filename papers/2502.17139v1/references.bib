% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@misc{GitHub-Copilot,
  author = {Github},
  title = {Github Copilot},
  year = {2021},
  url = {https://github.com/features/copilot}
}

@inproceedings{zhang2024draft,
    title = {Draft \& Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding},
    author = {Zhang, Jun and Wang, Jue and Li, Huan and Shou, Lidan and Chen, Ke and Chen, Gang and Mehrotra, Sharad},
    booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    pages = {11263 - 11282},
    year = {2024}
} 

@inproceedings{he2024rest,
  title={REST: Retrieval-Based Speculative Decoding},
  author={He, Zhenyu and Zhong, Zexuan and Cai, Tianle and Lee, Jason and He, Di},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={1582--1595},
  year={2024}
}

@inproceedings{zhao2024ouroboros,
  title={Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding},
  author={Zhao, Weilin and Huang, Yuxiang and Han, Xu and Xu, Wang and Xiao, Chaojun and Zhang, Xinrong and Fang, Yewei and Zhang, Kaihuo and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={13378--13393},
  year={2024}
}

@inproceedings{leviathan2023fast,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@article{cai2024medusa,
  title={Medusa: Simple llm inference acceleration framework with multiple decoding heads},
  author={Cai, Tianle and Li, Yuhong and Geng, Zhengyang and Peng, Hongwu and Lee, Jason D and Chen, Deming and Dao, Tri},
  journal={arXiv preprint arXiv:2401.10774},
  year={2024}
}

@article{chen2023accelerating,
  title={Accelerating large language model decoding with speculative sampling},
  author={Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John},
  journal={arXiv preprint arXiv:2302.01318},
  year={2023}
}

@article{chen2023cascade,
  title={Cascade speculative drafting for even faster llm inference},
  author={Chen, Ziyi and Yang, Xiaocong and Lin, Jiacheng and Sun, Chenkai and Chang, Kevin Chen-Chuan and Huang, Jie},
  journal={arXiv preprint arXiv:2312.11462},
  year={2023}
}

@article{chen2021codex,
  title={Evaluating Large Language Models Trained on Code},
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and et al},
  year={2021},
  eprint={2107.03374},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@article{austin2021mbpp,
  title={Program Synthesis with Large Language Models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@inproceedings{li2024deveval,
  author       = {Jia Li and
                  Ge Li and
                  Yunfei Zhao and
                  Yongmin Li and
                  Huanyu Liu and
                  Hao Zhu and
                  Lecheng Wang and
                  Kaibo Liu and
                  Zheng Fang and
                  Lanshen Wang and
                  Jiazheng Ding and
                  Xuanming Zhang and
                  Yuqi Zhu and
                  Yihong Dong and
                  Zhi Jin and
                  Binhua Li and
                  Fei Huang and
                  Yongbin Li and
                  Bin Gu and
                  Mengfei Yang},
  title        = {DevEval: {A} Manually-Annotated Code Generation Benchmark Aligned
                  with Real-World Code Repositories},
  booktitle    = {{ACL} (Findings)},
  pages        = {3603--3614},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@inproceedings{yu2024codereval,
  title={Codereval: A benchmark of pragmatic code generation with generative pre-trained models},
  author={Yu, Hao and Shen, Bo and Ran, Dezhi and Zhang, Jiaxin and Zhang, Qi and Ma, Yuchi and Liang, Guangtai and Li, Ying and Wang, Qianxiang and Xie, Tao},
  booktitle={Proceedings of the 46th IEEE/ACM International Conference on Software Engineering},
  pages={1--12},
  year={2024}
}

@article{zhang2023repocoder,
  title={Repocoder: Repository-level code completion through iterative retrieval and generation},
  author={Zhang, Fengji and Chen, Bei and Zhang, Yue and Keung, Jacky and Liu, Jin and Zan, Daoguang and Mao, Yi and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2303.12570},
  year={2023}
}

@article{guo2024deepseek,
  title={DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence},
  author={Guo, Daya and Zhu, Qihao and Yang, Dejian and Xie, Zhenda and Dong, Kai and Zhang, Wentao and Chen, Guanting and Bi, Xiao and Wu, Yu and Li, YK and others},
  journal={arXiv preprint arXiv:2401.14196},
  year={2024}
}

@inproceedings{spector2023treeattention,
  title={Accelerating LLM Inference with Staged Speculative Decoding},
  author={Spector, Benjamin Frederick and Re, Christopher},
  booktitle={Workshop on Efficient Systems for Foundation Models@ ICML2023},
  year={2023}
}

@inproceedings{miao2024specinfer,
  title={Specinfer: Accelerating large language model serving with tree-based speculative inference and verification},
  author={Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Zhang, Zhengxin and Wong, Rae Ying Yee and Zhu, Alan and Yang, Lijie and Shi, Xiaoxiang and others},
  booktitle={Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  pages={932--949},
  year={2024}
}

@inproceedings{zhu2024hot,
  title={Hot or Cold? Adaptive Temperature Sampling for Code Generation with Large Language Models},
  author={Zhu, Yuqi and Li, Jia and Li, Ge and Zhao, YunFei and Jin, Zhi and Mei, Hong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={1},
  pages={437--445},
  year={2024}
}

@inproceedings{li2024eagle,
  title={EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty},
  author={Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang},
  booktitle={International Conference on Machine Learning},
  year={2024}
}

@article{yang2023llma,
  title={Inference with reference: Lossless acceleration of large language models},
  author={Yang, Nan and Ge, Tao and Wang, Liang and Jiao, Binxing and Jiang, Daxin and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2304.04487},
  year={2023}
}

@article{zhang2024ralmcache,
  title={Accelerating retrieval-augmented language model serving with speculation},
  author={Zhang, Zhihao and Zhu, Alan and Yang, Lijie and Xu, Yihua and Li, Lanting and Phothilimthana, Phitchaya Mangpo and Jia, Zhihao},
  journal={arXiv preprint arXiv:2401.14021},
  year={2024}
}

@inproceedings{fu2024lookahead,
  title={Break the Sequential Dependency of LLM Inference Using Lookahead Decoding},
  author={Fu, Yichao and Bailis, Peter and Stoica, Ion and Zhang, Hao},
  booktitle={International Conference on Machine Learning},
  year={2024}
}

@inproceedings{liu2024repobench,
  title={RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems},
  author={Liu, Tianyang and Xu, Canwen and McAuley, Julian},
  booktitle={The Twelfth International Conference on Learning Representations},
   year={2024}
}

@inproceedings{wu2024repoformer,
  title={Repoformer: Selective Retrieval for Repository-Level Code Completion},
  author={Wu, Di and Ahmad, Wasi Uddin and Zhang, Dejiao and Ramanathan, Murali Krishna and Ma, Xiaofei},
  booktitle={International Conference on Machine Learning},
  year={2024}
}

@article{ding2024crosscodeeval,
  title={Crosscodeeval: A diverse and multilingual benchmark for cross-file code completion},
  author={Ding, Yangruibo and Wang, Zijian and Ahmad, Wasi and Ding, Hantian and Tan, Ming and Jain, Nihal and Ramanathan, Murali Krishna and Nallapati, Ramesh and Bhatia, Parminder and Roth, Dan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liang2024repofuse,
  title={REPOFUSE: Repository-Level Code Completion with Fused Dual Context},
  author={Liang, Ming and Xie, Xiaoheng and Zhang, Gehao and Zheng, Xunjin and Di, Peng and Chen, Hongwei and Wang, Chengpeng and Fan, Gang and others},
  journal={arXiv preprint arXiv:2402.14323},
  year={2024}
}

@inproceedings{du2024glide,
  title={GliDe with a CaPE: A Low-Hassle Method to Accelerate Speculative Decoding},
  author={Du, Cunxiao and Jiang, Jing and Yuanchen, Xu and Wu, Jiawei and Yu, Sicheng and Li, Yongqi and Li, Shenggui and Xu, Kai and Nie, Liqiang and Tu, Zhaopeng and others},
  booktitle={International Conference on Machine Learning},
  year={2024}
}

@article{sun2024spectr,
  title={Spectr: Fast speculative decoding via optimal transport},
  author={Sun, Ziteng and Suresh, Ananda Theertha and Ro, Jae Hun and Beirami, Ahmad and Jain, Himanshu and Yu, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{roziere2023codellama,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{brown2020lfewshot,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{li2023starcoder,
  title={Starcoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{achiam2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{liu2024non,
  title={Non-Autoregressive Line-Level Code Completion},
  author={Liu, Fang and Fu, Zhiyi and Li, Ge and Jin, Zhi and Liu, Hui and Hao, Yiyang and Zhang, Li},
  journal={ACM Transactions on Software Engineering and Methodology},
  year={2024},
  publisher={ACM New York, NY}
}

@article{manber1993suffix,
  title={Suffix arrays: a new method for on-line string searches},
  author={Manber, Udi and Myers, Gene},
  journal={siam Journal on Computing},
  volume={22},
  number={5},
  pages={935--948},
  year={1993},
  publisher={SIAM}
}

% raleted work 添加的部分
% begin
@inproceedings{ghazvininejad2019maskpredict,
    title = "Mask-Predict: Parallel Decoding of Conditional Masked Language Models",
    author = "Ghazvininejad, Marjan  and
      Levy, Omer  and
      Liu, Yinhan  and
      Zettlemoyer, Luke",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1633/",
    doi = "10.18653/v1/D19-1633",
    pages = "6112--6121",
}

@inproceedings{stern2018blockwisedecoding,
 author = {Stern, Mitchell and Shazeer, Noam and Uszkoreit, Jakob},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Blockwise Parallel Decoding for Deep Autoregressive Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/c4127b9194fe8562c64dc0f5bf2c93bc-Paper.pdf},
 volume = {31},
 year = {2018}
}

@misc{liu2024aded,
      title={Adaptive Draft-Verification for Efficient Large Language Model Decoding}, 
      author={Xukun Liu and Bowen Lei and Ruqi Zhang and Dongkuan Xu},
      year={2024},
      eprint={2407.12021},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12021}, 
}

@article{zhang2024tinyllama,
  title={Tinyllama: An open-source small language model},
  author={Zhang, Peiyuan and Zeng, Guangtao and Wang, Tianduo and Lu, Wei},
  journal={arXiv preprint arXiv:2401.02385},
  year={2024}
}

@inproceedings{tu2014localness,
  title={On the localness of software},
  author={Tu, Zhaopeng and Su, Zhendong and Devanbu, Premkumar},
  booktitle={Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages={269--280},
  year={2014}
}

@article{kocetkov2022stack,
  title={The stack: 3 tb of permissively licensed source code},
  author={Kocetkov, Denis and Li, Raymond and Allal, Loubna Ben and Li, Jia and Mou, Chenghao and Ferrandis, Carlos Mu{\~n}oz and Jernite, Yacine and Mitchell, Margaret and Hughes, Sean and Wolf, Thomas and others},
  journal={arXiv preprint arXiv:2211.15533},
  year={2022}
}

% end