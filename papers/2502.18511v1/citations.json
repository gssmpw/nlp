[
  {
    "index": 0,
    "papers": [
      {
        "key": "yan2024backdooring",
        "author": "Yan, Jun and Yadav, Vikas and Li, Shiyang and Chen, Lichang and Tang, Zheng and Wang, Hai and Srinivasan, Vijay and Ren, Xiang and Jin, Hongxia",
        "title": "Backdooring instruction-tuned large language models with virtual prompt injection"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "xiang2024BadChain",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zou2024poisonedrag",
        "author": "Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan",
        "title": "Poisonedrag: Knowledge poisoning attacks to retrieval-augmented generation of large language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhao2024survey",
        "author": "Zhao, Shuai and Jia, Meihuizi and Guo, Zhongliang and Gan, Leilei and Xu, Xiaoyu and Wu, Xiaobao and Fu, Jie and Feng, Yichao and Pan, Fengjun and Tuan, Luu Anh",
        "title": "A survey of backdoor attacks and defenses on large language models: Implications for security measures"
      },
      {
        "key": "zhou2025survey",
        "author": "Zhou, Yihe and Ni, Tao and Lee, Wei-Bin and Zhao, Qingchuan",
        "title": "A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations"
      }
    ]
  }
]