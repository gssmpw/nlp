\section{Related Works}
\subsection{Efficient Learning Backdoor Attacks Against LLMs}
% 
From a novel and comprehensive perspective, existing methods for efficient learning backdoor attacks against LLMs can be categorized into parameter efficient fine-tuning (PEFT) techniques and without fine-tuning (W/o FT) approaches. VPI ____ shows that by appending attacker-specified virtual prompts to user instructions and poisoning instruction data, malicious backdoor behavior can be embedded into the LLM. BadChain ____ enables without fine-tuning backdoor attacks by exploiting CoT prompting to embed malicious reasoning steps, manipulating LLMs' responses without requiring fine-tuning or additional computational resources. ____ propose PoisonedRAG, a backdoor attack on RAG in LLMs that injects poisoned texts into the knowledge database, optimizing retrieval and effectiveness to mislead the model's responses. The empirical evidence from current studies substantiates the effectiveness of optimized learning paradigms in executing backdoor attacks on LLMs, thereby exposing critical security implications for end-users operating these sophisticated LLMs.


\subsection{Backdoor Attacks Benchmark for LLMs}
%

To the best of our knowledge, the benchmark research for backdoor attacks introduced BackdoorLLM, which categorizes existing attack methods into DPA, WPA, HSA, and CoTA, providing evaluations for each category. Following____, our benchmark classifies existing attack methods in a more innovative way. Focusing on backdoor attack methods in the context of applying LLMs to downstream tasks, we classify each attack method based on whether fine-tuning is involved, followed by more granular subcategories. Additionally, our benchmark supports a wider range of LLM types and incorporates a more comprehensive set of attack methods and datasets. Table~\ref{tab:ComparisonBenchmark} shows some qualitative and quantitative differences. \textit{ELBA-Bench} offers a more holistic evaluation of attack success, stealthiness, and other critical dimensions, making it a more robust tool for assessing the effectiveness and implications of backdoor attacks.


\begin{table*}[h!]
    \centering
    \fontsize{10}{12}\selectfont{
    \begin{tabular}{c||c|c|c|c|c|c}
    \toprule
      \textbf{Benchmark} & \textbf{Attack} & \textbf{Dataset} & \textbf{LLM} & \textbf{All} & \textbf{LLM} & \textbf{Stealthiness} \\
      & \textbf{Methods} & \textbf{Numbers} & \textbf{Numbers} & \textbf{Exps} & \textbf{Types} & \textbf{Measurement} \\
      \hline
      BackdoorLLM & 8 & 12 &  7 & 200+ & Open Source & X \\ 
      \hline
      \rowcolor{gray!20}
      ELBA-Bench & 12 & 18 & 12  & 1300+ & Open+Close Source & \checkmark \\
    \bottomrule
    
    \end{tabular}
    }
    \caption{Comparison between our benchmark and the existing backdoor attacks benchmark for LLMs}
    \label{tab:ComparisonBenchmark}
\end{table*}