\section{Switching to a lighter weapon}
    \label{sec:model}

    \begin{figure*}
      \centering
      \resizebox{\linewidth}{!}{\input{imgs/svn_skeleton}}
      \vspace{-1cm}
      \caption{Skeleton and fundamental operations of a basic \sname module}
      \label{fig:skeleton}
      \vspace{-0.2cm}
    \end{figure*}
    
    As an alternative approach to traditional virtualization, we propose \snamefull (\sname). \sname is a paradigm to implement hardware modules that build atop the concept of coherence backstabbing~\cite{CAESAR} to arbitrarily manipulate \va-to-\pa translation in a manner that remains seamless to software components.
    \sname can achieve \emph{transparent}, \emph{temporary}, and \emph{on-demand} control over the translation process. This is achieved through observation and selective manipulation of the data payloads returned via coherence in response to \mmu-generated snoops during the page table walk.
    This level of control allows for a \emph{``true''} in-hardware virtualization with little support required from the vendors.\footnote{Although, the model can be further simplified and improved if additional support is provided in hardware, as discussed in \sect~\ref{subsec:on_the_vendors}.}

    \subsection{System Model}
        \label{subsec:system_model}

        A few features are required for \sname to be deployed on a \soc.
        The system must include one or more \pe{s} (\eg \cpu, \cpu{s} cluster, \gpu) supporting memory virtualization (\ie equipped with an \mmu and \tlb{s}).
        The \pe-side cache must be capable of handling coherence and be connected to a coherent controller (\eg coherent interconnect) employing a snoop-based protocol. The latter interfaces the coherence domain with main memory.
        \mmu-originated accesses to \pte{s} during page table walks are treated as cacheable, and therefore generate snoops that are broacasted to all other coherent \pe{s} upon a \pe-side cache miss.
  
        We make no assumptions on whether the module is implemented as soft-logic in a programmable logic fabric (as in \cite{CAESAR}) or as a fixed dedicated piece of hardware. To illustrate the basic principle, however, we hereby make the following simplifying assumptions. We discuss in \sect~\ref{subsec:challenges} how these can be substantially relaxed.
        \begin{enumerate}
        
            \item No \pte{s} are cached. All \mmu-originated accesses miss in the \pe-side cache and the corresponding snoops are broadcasted to the other coherent \pe{s}.
            \item The target \va range is \emph{isolated} and \emph{pre-mapped}. \Ie no other valid \va{s} share the same first index, and all the intermediate \pte{s} have been pre-populated before \sname is activated.
            \item The \pgd of the target address space that contains the target \va{s} is known before \sname is activated.
            \item The new destination \pa{s} and desired mapping attributes are provided by the end-user. %that will be resulting from the translation process. 
        \end{enumerate}

    \subsection{\sname Operation}\label{sec:snv_op}


        As shown in \fig{skeleton}, the \sname module activates each time it receives a snoop command.
        This command is analyzed and compared (step \step{3}) to determine if the snoop command results from a \pte access that was missed in the cache.
        At the very beginning, \ie right after the \sname module has been activated, the check is performed against the known \pgd address plus possible offsets. Later, the check will also include any intermediate PFNs of valid page tables obtained in the previous translation steps for the \va{s} of interest.
        
        If the snooped address indicates access to a \pte of interest, the \sname module acknowledges the request (step \step{5a}), indicating to the cache coherent interconnect (CCI) that it has the most up-to-date data payload.
        From then on, the latter waits for the data to be served at step \step{11a}.
        Meanwhile, the \sname module fetches from main memory the payload of the requested \pte (steps \step{7a} and \step{7b}).
        The payload is passed (step \step{9a}) to the \pte{s} manipulator. Here, it can be altered as necessary following arbitrary logic before being fed to the coherent controller (step \step{11a}) and eventually the \mmu (step \step{12a}).
        Note that, in parallel to this process, the \sname module internally maintains a \emph{context cache} within the translation path checker. This is useful for storing additional metadata about the current translation.
        
        Conversely, if the snoop is not relevant for the translation of any of the \va{s} of interest (step \step{4b}), the \sname module provides a negative acknowledgment to the CCI (step \step{5b}).
        From there, a "text-book" access to the page tables is performed by fetching the non-altered tables directly from main memory (steps \step{6b} and \step{7b}).

        Note that, with no \pte{s} cached on the \pe side, the routine will be repeated once per active page table level to complete a full-page table walk---\eg up to four times in \arm{64}.

    \subsection{Relaxing \sname Assumptions} 
        \label{subsec:challenges}

        The assumptions listed in \sect~\ref{subsec:system_model} are representative of the various technical challenges that remain to be addressed.
        This section explains the rationale behind each assumption and how they can be enforced or relaxed.

        \para{Assumption (1)} 
            Disabling the caching of \pte{s} in the cache hierarchy is undesirable, as it is crucial to hide costly translation latencies.
            On the other hand, if intermediate \pte{s} passed to the \pe might be cached, then not all the \mmu-generated \pte accesses will result in \pe-side cache misses and snoops.             This \emph{partial observability} means that \sname is oblivious to the walks' progress and, thus, cannot determine how to appropriately alter the translations when the next relevant \pte miss occurs. 
            
            Fortunately, the \pte addresses returned by the \sname module do not have to be valid \pa{s}---because accesses to them will be intercepted when later snooped. Thus, we can inject a \emph{watermark} in the payload of all the manipulated \pte{s} served to the \pe.
            In addition to encoding the translation step number, the watermark can be looked up in the internal context cache (\sect~\ref{sec:snv_op}) to recover several other attributes necessary for proper \sname operation.
            

        \para{Assumption (2)}
            The reason for \textbf{Assumption (2)} is to avoid that also neighbor \va{s} sharing intermediate page tables could trigger the same issue raised if Assumption (3) was lifted. Thus, it can be relaxed if Assumption (3) is lifted. 

        \para{Assumption (3)}
            Assuming pre-populated \va mappings before \sname is activated is a simplifying assumption because Linux employs demand paging.
            In brief, if the \sname module serves a manipulated \pte but no subsequent page is allocated (present bit is cleared), the \mmu generates a fault. When handling the fault, the kernel retrieves the potentially invalid \pa of the \pte and might attempt to populate it.
            However, as the address is invalid and only makes sense when looked up in the context cache, it might cause a kernel-side page fault. This problem can be solved with an \sname module capable of consistently manipulating both user-space and kernel-space \va-to-\pa translations.

    \subsection{Enabling Virtualization at All Levels}

        The proposed approach does not preclude the system from running a hypervisor.
        In fact, the mechanism presented earlier can be extended to hypervisor translations, too.
        Instead of intervening only during the \va-to-\pa translation, \sname could also monitor and alter \ipa-to-\pa translations.
       