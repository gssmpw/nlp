\clearpage
\section[Designing \textsc{TrustGen} From Guidelines]{Designing \textsc{TrustGen}, a Dynamic Benchmark Platform for Evaluating the Trustworthiness of GenFMs}
%\section{Benchmark Design}
\label{sec:benchmark_design}

% \heng{Can you add some summary on what kind of domains and topics are being covered in this benchmark? are there any limitations? List of the dimensions that can be used to control the generation. In Figure 8 I don't see truthfulness? Do you want to add automatic fact checking to enhance truthfulness?} \heng{For VLM baseline, can you add SOLO? https://www.arxiv.org/abs/2407.06438}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{image/TrustGen_Overview.pdf}
    \caption{An overview of \textsc{TrustGen}, a dynamic benchmark system, incorporating three key components: a metadata curator, a test case builder, and a contextual variator. It evaluates the trustworthiness of three categories of generative foundation models (GenFMs): text-to-image, large language models, and vision-language models across seven trustworthy dimensions with a broad set of metrics to ensure thorough and comprehensive assessments.}
    \label{fig:overview}
\end{figure}

\textbf{Background.} With the rise of GenFMs, researchers have proposed numerous benchmarks to evaluate their capabilities and explore their limitations. Beyond measuring general performance, trustworthiness has emerged as a critical focus area, particularly given its implications for social good \cite{wang2023decodingtrust, huang2024position, hao2024sdm, zhang2024benchmarkingtrustworthinessmultimodallarge}. TrustLLM~\cite{huang2024position}, a pioneer in systematically quantifying trustworthiness within LLMs with static benchmarks. As generative AI expands beyond text to encompass image and video generation, the nature of trustworthiness concerns evolves dramatically—from textual to all generative models. This expansion across modalities underscores the pressing need for a standardized benchmark framework that enables systematic evaluation of trustworthiness in various generative AI domains.

\textbf{Motivation.} Traditional GenFMs benchmarks, while valuable when proposed, have exhibited several critical limitations: they quickly become outdated, lacking behind the rapid development of GenFMs for failing to capture emerging challenges. Moreover, static benchmarks are vulnerable to be memorized by models, resulting in potential benchmark leakage or cheating problems. To address these shortcomings, researchers have increasingly shifted their focus towards dynamic benchmarks - evaluation frameworks that automatically update their test sets and metrics over time \citep{zhang2024task,li2024autobencher,Ni2024MixEvalDW,Li2023LatestEvalAD,Shirali2022ATO,Gao2022AdaptiveTO,Ribeiro2022AdaptiveTA,Leclerc20213DBAF,Yang2023RethinkingBA}. Unlike static benchmarks, these dynamic evaluation systems continuously evolve alongside model development. Their key advantages are threefold: \textbf{1)} they keep pace with rapid GenFM advances, as evidenced by the emergence of jailbreak exploits \cite{wei2024jailbroken} after ChatGPT's release \cite{ChatGPT}; \textbf{2)} they can automatically adapt to the evolving societal requirements of GenFMs \cite{soni2024large}; \textbf{3)} they prevent memorization by consistently introducing novel test cases \citep{white2024livebench}. To this end, we establish the first dynamic evaluation framework for GenFM trustworthiness that continuously adapts to evolving ethical standards and provides authentic assessments of model behavior. Further discussion on the dynamics of trustworthiness is provided in \textbf{\S\ref{sec:discussion}}.

%\subsection{Highlights of \textsc{TrustGen} Benchmark}
\subsection{Key Features of the \textsc{TrustGen} Benchmark System}

We highlight the key features of \textsc{TrustGen}, a benchmark system designed to be effective, reproducible, user-friendly, and fully open-source for evaluating trustworthiness in cutting-edge GenFMs.

%\textbf{\textit{Dynamic Benchmark}}: 
\textbf{\textit{Dynamic Evaluation Strategies}}:
The \textsc{TrustGen} benchmark is inherently dynamic, leveraging tailored strategies across multiple dimensions to ensure continuous updates to datasets and evaluation metrics. For each dimension, \textsc{TrustGen} leverages its three core modules—Metadata Curator, Test Case Builder, and Contextual Variator. Together, these components create an iterative pipeline that keeps its datasets and evaluations constantly evolving, ensuring the benchmark remains effective as generative models advance, supporting dynamic and relevant evaluations over time.

\textbf{\textit{Reproducible Construction Pipeline}}: The benchmark construction pipeline is fully open-source, promoting open science and allowing users to understand and replicate the test set generation process to facilitate transparency\cite{cohen2022facilitating}. It ensures that users can easily create evaluation datasets and apply the benchmark for their specific needs. We have released a toolkit to enable the easy replication of the benchmark construction process.\footnote{The toolkit is available at \url{https://github.com/TrustGen/TrustEval-toolkit}} This open science approach not only ensures reproducibility but also encourages collaborative innovation, empowering the broader research community to contribute to and build upon TrustGen.

\textbf{\textit{Balancing Utility and Trustworthiness}}: Our trustworthiness benchmark recognizes that models must be both helpful and reliable. Focusing solely on trustworthiness would result in an incomplete evaluation, as well-performed models need to demonstrate both trustworthy behavior and practical utility. Adherence to ethical standards \cite{Wikipedia_Machine_Ethics}, such as cultural norms \cite{shi2024culturebank}, is essential to ensure that models can respond appropriately to culturally specific queries, enhancing both utility and fairness in interactions with diverse users. We discuss the interplay between utility and trustworthiness further in \textbf{\S\ref{sec:discussion}}.

\textbf{\textit{User-friendly Setups}}: Our benchmark focuses on facilitating users' experience, targeting their specific issues related to trustworthiness. When evaluating attacks and adversarial scenarios, we prioritize practical, low-cost methods, avoiding expensive or white-box approaches like GCG \cite{zou2023universal}. However, certain white-box techniques are indirectly assessed through transfer attacks \cite{shayegani2023jailbreak}. This approach ensures that the evaluation mirrors realistic challenges that users are most likely to encounter.

\textbf{\textit{Human-Enhanced Benchmark Construction}}: TrustGen integrates automated processes with human-involved evaluation and validation steps to ensure both scalability and quality in its dynamic benchmark construction. While automated systems handle the majority of data generation, human oversight plays a critical role in validating the integrity and reliability of the benchmark components. By combining these methods, TrustGen delivers a robust and adaptable framework for evaluating GenFMs.


%\subsection{Dynamic Benchmark Construction}
\subsection{The Three Modules of \textsc{TrustGen}}

\label{sec:construction}
%The dynamic benchmark is constructed with a fully open-source pipeline. The pipeline 
As shown in Figure \ref{fig:overview}, \textsc{TrustGen} consists of three modules: 1) \textit{Metadata Curator}, which curates relevant metadata; 2) \textit{Test Case Builder}, which generates test cases to assess model performance; and 3) \textit{Contextual Variator}, which ensures that the cases are varied and representative of different contexts and question formats.

\textbf{Metadata Curator.} The Metadata Curator module handles preprocessing metadata and transforming it into usable test cases, which is essentially a data-processing agent \cite{agentbench}. We employ three types of metadata curators in our benchmark: 1) \textit{Dataset pool maintainers.} It processes raw data (\emph{e.g.}, CSV, JSON) into formats ready for test case generation, based on existing datasets. 2) \textit{Web-Browsing agents.} It is powered by LLMs and can retrieve specific information from the web, ensuring that the benchmark remains up-to-date and diverse. 3) \textit{Model-based data generators.} Model-based data generators can produce new data sources. To mitigate potential data leakage, we employ these models with careful constraints. Specifically, we avoid using a model to generate complete test cases if that model will be subject to later evaluation. Instead, models are utilized only to generate components of test cases or to paraphrase existing samples, with additional data crafting methods employed based on specific tasks.



\textbf{Test Case Builder.}  This module generates test cases using either a generative model or programmatic operations. For instance, if the benchmark has a social norm description such as \textit{``It is uncivilized to spit in public,''}, a model (\emph{e.g.}, LLM) will generate a test case like \textit{``Is spitting in public considered good behavior?''} with the ground-truth answer \textit{``No''}. Specifically, when using models to generate test cases, we ensure that each input has a corresponding ground-truth label (in this example, the ground-truth label is \textit{``uncivilized''} for the ethical judgment of spitting in public). Therefore, the generative model is only used for paraphrasing queries and answers (if any), not for generating ground-truth labels, thus minimizing the potential self-enhancement bias \cite{ye2024justice}. Programmatic operations, on the other hand, follow rules and pre-defined programs to test the model's robustness (\emph{e.g.}, adding noise to text or images). We also use existing key-value pairs from structured datasets to generate test questions with no AI models involved.



\begin{table}[h]
    \centering
    \small
    \caption{Overview of transformation methods in Contextual Variator.}
    \renewcommand{\arraystretch}{1.2}
    \label{tab:diversity_enhancer}
    \begin{tabular}{cp{11.8cm}}
    \toprule[1pt]
        \textbf{Transformation} & \textbf{Description} \\
        \midrule
        % Transform Expression  & Modify the sentence by applying various stylistic changes, such as switching between declarative, imperative, conditional, passive/active voice, or by adding emphasis or emotional tone. \\
        Transform Question Format & Convert the question into a different format, such as open-ended, multiple-choice, or binary judgment (true/false). \\
        Transform by Length & Adjust the length of the sentence, either by shortening or lengthening it while preserving its original meaning. \\
        Paraphrase Sentence  & Reword the sentence using different vocabulary and structures to convey the same meaning in a new way. \\
        \bottomrule[1pt]
    \end{tabular}
    \vspace{-10pt}
\end{table}

\textbf{Contextual Variator}: Previous studies \cite{huang2024position, sclar2023quantifying,wang2024template} have highlighted the importance of addressing prompt sensitivity in model evaluation. In addition, programmatic or template-based generation operations often lack diversity, which may compromise the reliability of evaluation results. To address this, we introduce the \textbf{Contextual Variator}, powered by LLMs, which performs various operations such as sentence paraphrasing and question format variation such as transforming the multiple-choice query into the free-form format.


\textbf{Human Evaluation}: For each generated data item, we perform a human evaluation to assess two key aspects: 1) whether a semantic shift occurs in the instances after applying the contextual variator, and 2) whether the quality of the data is acceptable for evaluation purposes (\emph{e.g.}, whether the data accurately reflect the testing objectives of specific tasks). We show the human evaluation interface in Appendix \ref{app:annotation_details}.



\textbf{Trustworthiness Score}: To calculate the trustworthiness score, all metric results are first standardized to ensure that higher values consistently indicate better performance. For metrics where lower values are preferable, the scores are inverted by subtracting the value from 1. For instance, for the safety evaluation of LLMs, the toxicity score and RtA rate are inverted in toxicity and exaggerated safety evaluations. All scores are then scaled to a uniform range between 0 and 100. For each dimension, the score is computed as the average of all its sub-dimensions, where the score of each sub-dimension is determined by averaging the scores of its constituent tasks if multiple tasks are present. The details of the trustworthiness score for each dimension of different kinds of models can be found in the toolkit \footnote{The toolkit is available at \url{https://github.com/TrustGen/TrustEval-toolkit}}.


The implementation details of these three modules, as they evaluate each (sub)dimension of trustworthiness, are summarized in  Table \ref{tab:implementation-details}.


\definecolor{modelcolor1}{HTML}{d0e0e3}
\definecolor{modelcolor2}{HTML}{dad2e9}
\definecolor{modelcolor3}{HTML}{fce5cd}
\definecolor{opensourcecolor}{HTML}{b4c8b6}
\definecolor{commercialcolor}{HTML}{fadadd}


\begin{table}[t]
\centering
\caption{The list of selected models.}
\renewcommand{\arraystretch}{1.1}
\scalebox{0.95}{
\begin{tabular}{c l c c c c}
\toprule[1pt]
\textbf{Category} & \textbf{Model} & \textbf{Model Size} & \textbf{Version} & \textbf{Open-Weight?} & \textbf{Creator} \\
\midrule
\multirow{7}{*}{T2I} 
& \cellcolor{modelcolor3} DALL-E 3 & N/A & N/A & \cellcolor{commercialcolor}\xmarkcolor & OpenAI \\
\cmidrule{2-6}
& \cellcolor{modelcolor3} SD-3.5-Large & 8B & large & \cellcolor{opensourcecolor}\checkmarkcolor & Stability AI \\
\cmidrule{2-6}
& \cellcolor{modelcolor3} SD-3.5-Large-Turbo & N/A & large turbo & \cellcolor{opensourcecolor}\checkmarkcolor & Stability AI \\
\cmidrule{2-6}
& \cellcolor{modelcolor3} FLUX-1.1 & N/A & pro & \cellcolor{commercialcolor}\xmarkcolor & Black Forset Labs \\
\cmidrule{2-6}
& \cellcolor{modelcolor3} Playground 2.5 & N/A & 1024px-aesthetic & \cellcolor{opensourcecolor}\checkmarkcolor& Playground\\
\cmidrule{2-6}
& \cellcolor{modelcolor3} Hunyuan-DiT & N/A & N/A & \cellcolor{opensourcecolor}\checkmarkcolor& Tencent\\
\cmidrule{2-6}
& \cellcolor{modelcolor3} Kolors & N/A & N/A & \cellcolor{opensourcecolor}\checkmarkcolor& Kwai\\
\cmidrule{2-6}
& \cellcolor{modelcolor3} CogView-3-Plus & N/A & N/A & \cellcolor{opensourcecolor}\checkmarkcolor & ZHIPU AI \\
\midrule
\multirow{17}{*}{LLM} 
& \cellcolor{modelcolor1} GPT-4o & N/A & 2024-08-06 & \cellcolor{commercialcolor}\xmarkcolor & \\
& \cellcolor{modelcolor1} GPT-4o-mini & N/A & 2024-07-18 & \cellcolor{commercialcolor}\xmarkcolor & \\
& \cellcolor{modelcolor1} GPT-3.5-Turbo & N/A & 0125 & 
\cellcolor{commercialcolor}\xmarkcolor & \\
& \cellcolor{modelcolor1} o1-preview & N/A & 2024-09-12 &
\cellcolor{commercialcolor}\xmarkcolor & \\
& \cellcolor{modelcolor1} o1-mini & N/A & 2024-09-12 & 
\cellcolor{commercialcolor}\xmarkcolor & \multirow{-5}{*}{OpenAI} \\
\cmidrule{2-6}
& \cellcolor{modelcolor1} Claude-3.5-Sonnet & N/A & 20240620 & \cellcolor{commercialcolor}\xmarkcolor & \\
& \cellcolor{modelcolor1} Claude-3-Haiku & N/A & 20240307 & \cellcolor{commercialcolor}\xmarkcolor & \multirow{-2}{*}{Anthropic} \\
\cmidrule{2-6}
& \cellcolor{modelcolor1} Gemini-1.5-Pro & N/A & 002 & \cellcolor{commercialcolor}\xmarkcolor & \\
& \cellcolor{modelcolor1} Gemini-1.5-Flash & N/A & 002 & \cellcolor{commercialcolor}\xmarkcolor &  \\
& \cellcolor{modelcolor1} Gemma-2-27B & 27B & it & \cellcolor{opensourcecolor}\checkmarkcolor & 
\multirow{-3}{*}{Google} \\
\cmidrule{2-6}
& \cellcolor{modelcolor1} Llama-3.1-70B & 70B & instruct & \cellcolor{opensourcecolor}\checkmarkcolor& \\
& \cellcolor{modelcolor1} Llama-3.1-8B & 8B & instruct & \cellcolor{opensourcecolor}\checkmarkcolor& \multirow{-2}{*}{Meta} \\
\cmidrule{2-6}
& \cellcolor{modelcolor1} Mixtral-8*22B & 8*22B & instruct-v0.1 & \cellcolor{opensourcecolor}\checkmarkcolor& \\
& \cellcolor{modelcolor1} Mixtral-8*7B & 8*7B & instruct-v0.1 & \cellcolor{opensourcecolor}\checkmarkcolor& \multirow{-2}{*}{Mistral} \\
\cmidrule{2-6}
& \cellcolor{modelcolor1} GLM-4-Plus & N/A & N/A & \cellcolor{opensourcecolor}\checkmarkcolor& ZHIPU AI \\
\cmidrule{2-6}
& \cellcolor{modelcolor1} Qwen2.5-72B & 72B & instruct & \cellcolor{opensourcecolor}\checkmarkcolor& \\
& \cellcolor{modelcolor1} QwQ-32B & 32B & N/A & \cellcolor{opensourcecolor}\checkmarkcolor& \multirow{-2}{*}{Qwen} \\
\cmidrule{2-6}
& \cellcolor{modelcolor1} Deepseek-chat & 236B & v2.5 & \cellcolor{opensourcecolor}\checkmarkcolor& Deepseek \\
\cmidrule{2-6}\
& \cellcolor{modelcolor1} Yi-Lightning & N/A & N/A & \cellcolor{commercialcolor}\xmarkcolor & \multirow{-1}{*}{01.ai} \\
\midrule
\multirow{10}{*}{VLM} 
& \cellcolor{modelcolor2} GPT-4o & N/A & 2024-08-06 & \cellcolor{commercialcolor}\xmarkcolor &  \\
& \cellcolor{modelcolor2} GPT-4o-mini & N/A & 2024-07-18 & \cellcolor{commercialcolor}\xmarkcolor & \multirow{-2}{*}{OpenAI} \\
\cmidrule{2-6}
& \cellcolor{modelcolor2} Claude-3.5-Sonnet & N/A & 20240620 & \cellcolor{commercialcolor}\xmarkcolor & \\
& \cellcolor{modelcolor2} Claude-3-Haiku & N/A & 20240307 & \cellcolor{commercialcolor}\xmarkcolor & \multirow{-2}{*}{Anthropic} \\
\cmidrule{2-6}
& \cellcolor{modelcolor2} Gemini-1.5-Pro & N/A & 002 & \cellcolor{commercialcolor}\xmarkcolor &  \\
& \cellcolor{modelcolor2} Gemini-1.5-Flash & N/A & 002 & \cellcolor{commercialcolor}\xmarkcolor &  \multirow{-2}{*}{Google}\\
\cmidrule{2-6}
& \cellcolor{modelcolor2} Qwen2-VL-72B &  72B
& instruct & \cellcolor{opensourcecolor}\checkmarkcolor& Qwen \\
\cmidrule{2-6}
& \cellcolor{modelcolor2} GLM-4V-Plus & N/A & N/A & \cellcolor{commercialcolor}\xmarkcolor & ZHIPU AI \\
\cmidrule{2-6}
& \cellcolor{modelcolor2} Llama-3.2-11B-V & 11B & instruct & \cellcolor{opensourcecolor}\checkmarkcolor &  \\
& \cellcolor{modelcolor2} Llama-3.2-90B-V & 90B & instruct & \cellcolor{opensourcecolor}\checkmarkcolor & \multirow{-2}{*}{Meta AI} \\
% & \cellcolor{modelcolor2} InternVL2-26b & 26B & & \cellcolor{opensourcecolor}\checkmarkcolor& OpenGVLab \\
% \cmidrule{2-6}
% & \cellcolor{modelcolor2} Idefics-3 & 8B & & \cellcolor{opensourcecolor}\checkmarkcolor& HuggingFace \\
\bottomrule[1pt]
\end{tabular}}
\label{tab:model_list}
\vspace{-15pt}
\end{table}

%\subsection{Model Selection Consideration}
\subsection{Models Included in the Evaluation}

In selecting models for evaluation, we follow two key principles to ensure that the selected models  are both relevant and high-performing:

\textbf{Latest and Cutting-edge Models:} Our model selection prioritizes the most recent and powerful models available. For example, in the case of the Llama series, we choose models like Llama 3 and Llama 3.1, as they represent the latest advancements. Although the Vicuna series \cite{vicuna} was once an outstanding open-source model, its current performance lags behind newer models, and hence it is not selected. By focusing on state-of-the-art models, we ensure that our benchmark captures the frontier of GenFM capabilities.

\textbf{Coverage of Major Model Developers:} To ensure broad representation, we select models from a diverse range of mainstream developers. This includes models from leading organizations such as OpenAI, Meta, Google, and Anthropic, enabling us to comprehensively compare diverse approaches to GenFM development.


The list of selected generative models can be found in Table \ref{tab:model_list}, with their size, version, and developers.

\begin{table}[t]
\centering
\small
\caption{%Details of the implementation of the dynamic dataset in each (sub) dimension. 
Implementation details of the three modules in TrustGen for evaluating each (sub) dimension of trustworthiness. For Metadata Curator, we apply three kinds of strategies: Web-Browsing Agent, Dataset Pool Maintainer, and Model Generation. For Test Case Builder, we apply the methods including Attribute-Guided Generation \cite{yu2024large}, Principle-Guided Generation \cite{gao2024best, constituationalAI} (\emph{i.e.}, AI constitution), Programmatic-Based Generation \cite{zhang2024task, huang2024position}, and LLM-Based Paraphrasing. The "Performance Overview" column visually represents the model scores for each (sub) dimension. The scores are normalized with higher values indicating better performance, and the models are arranged on x-axis in the same order as in \autoref{tab:model_list}.}
\renewcommand{\arraystretch}{1.2}

\scalebox{0.83}{
\begin{tabular}{m{1.5cm}m{2.8cm}m{4.6cm}m{4.6cm}m{1.5cm}c}
\toprule[1pt]
\multirow{2}{*}{\textbf{\makecell{Model}}} & \multirow{2}{*}{\textbf{\makecell{(Sub) Dimension}}} & \multicolumn{3}{c}{\textbf{\makecell{TrustGen Implementation}}} & \multirow{2}{*}{\textbf{\makecell{Performance\\Overview}}} \\
\cmidrule(lr){3-5}
                                &                                     & \textbf{\makecell{Metadata Curator}} & \textbf{\makecell{Test Case Builder}} & \textbf{\makecell{Contextual\\Variator}} & \\
                                \midrule
\rowcolor{gray!20!purple!10!white}\makecell{T2I} & \makecell{Truthfulness} &    \makecell{Dataset Pool Maintainer}   &   \makecell{Programmatic}         & \makecell{\checkmarkcolor}   & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/T2I-_truthfulness.png}} \\         
\makecell{T2I} & \makecell{Safety} &  \makecell{Model Generation (LLM)}       &  \makecell{Attribute-Guided Generation} &  \makecell{\xmarkcolor}   & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/T2I_safety.png}} \\ 
\rowcolor{gray!20!purple!10!white}\makecell{T2I} & \makecell{Fairness} & \makecell{Dataset Pool Maintainer}  &  \makecell{LLM-Based Paraphrasing} &  \makecell{\xmarkcolor}  & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/T2I_fairness.png}} \\ 
\makecell{T2I} & \makecell{Robustness} & \makecell{Model Generation (LLM)}    & \makecell{LLM-Based Paraphrasing \\ Programmatic-Based Generation}   & \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/T2I_robustness.png}} \\ 
\rowcolor{gray!20!purple!10!white}\makecell{T2I} & \makecell{Privacy} & \makecell{Web-Browsing Agent} & \makecell{LLM-Based Paraphrasing} & \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/T2I_privacy.png}} \\   
\midrule
\makecell{LLM} & \makecell{Hallucination} & \makecell{Web-Browsing Agent\\Dataset Pool Maintainer} & \makecell{N/A} & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_hallucination.png}}  \\
\rowcolor{gray!60!red!10!white}\makecell{LLM} & \makecell{Sycophancy} & \makecell{Web-Browsing Agent} & \makecell{LLM-Based Paraphrasing}  & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_sycophancy.png}} \\
\makecell{LLM} & \makecell{Honesty} & \makecell{Web-Browsing Agent\\Model-Based Generation (LLM)}  & \makecell{LLM-Based Paraphrasing} & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_honest.png}} \\
\rowcolor{gray!60!red!10!white}\makecell{LLM} & \makecell{Jailbreak} & \makecell{Web-Browsing Agent} & \makecell{LLM-Based Paraphrasing} & \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_jailbreak.png}} \\ 
\makecell{LLM} & \makecell{Toxicity} &   \makecell{N/A}    &   \makecell{N/A}     &   \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_toxicity.png}} \\
\rowcolor{gray!60!red!10!white}\makecell{LLM} & \makecell{Exaggerated Safety} &  \makecell{Model-Based Generation (LLM)}  &  \makecell{Principle-Guided Generation}   & \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_exaggerate.png}} \\
\makecell{LLM} & \makecell{Stereotype} &  \makecell{Dataset Pool Maintainer}  &  \makecell{LLM-Based Paraphrasing}   & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_stereotype.png}} \\
\rowcolor{gray!60!red!10!white}\makecell{LLM} & \makecell{Disparagement} &  \makecell{Web-Browsing Agent}  &  \makecell{LLM-Based Paraphrasing}   & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_disparagement.png}} \\
\makecell{LLM} & \makecell{Preference} &  \makecell{Model Generation (LLM)}  &  \makecell{Principle-Guided Generation}   & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_preference.png}} \\
\rowcolor{gray!60!red!10!white}\makecell{LLM} & \makecell{Privacy} &    \makecell{Web-Browsing Agent}               &     \makecell{LLM-Based Paraphrasing \\ Programmatic-Based Generation}                 & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_privacy.png}} \\
\makecell{LLM} & \makecell{Robustness} & \makecell{Dataset Pool Maintainer} & \makecell{Programmatic-Based Generation} & \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_robustness.png}} \\
\rowcolor{gray!60!red!10!white}\makecell{LLM} & \makecell{Machine Ethics} &  \makecell{Dataset Pool Maintainer}   &  \makecell{Programmatic-Based Generation} &  \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_ethics.png}} \\
\makecell{LLM} & \makecell{Advanced AI Risk} &  \makecell{Dataset Pool Maintainer}  &  \makecell{Principle-Guided Generation}           &   \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/LLM_risk.png}} \\
\midrule
\rowcolor{gray!60!blue!10!white}\makecell{VLM} &  \makecell{Hallucination}   &  \makecell{Dataset Pool Maintainer} &  \makecell{Programmatic-Based Generation}  &  \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/VLM_hallucination.png}} \\
\makecell{VLM} & \makecell{Jailbreak} & \makecell{Web-Browsing Agent}  & \makecell{LLM-Based Paraphrasing \\ Programmatic-Based Generation} & \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/VLM_jailbreak.png}} \\
\rowcolor{gray!60!blue!10!white}\makecell{VLM} & \makecell{Robustness} &  \makecell{Dataset Pool Maintainer} & \makecell{Programmatic-Based Generation} &  \makecell{\xmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/VLM_robustness.png}} \\
\makecell{VLM} & \makecell{Privacy} &      \makecell{Dataset Pool Maintainer}       &    \makecell{LLM-Based Paraphrasing}        &  \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/VLM_privacy.png}} \\
\rowcolor{gray!60!blue!10!white}\makecell{VLM} & \makecell{Stereotype \&\\ Disparagement} & \makecell{Dataset Pool Maintainer \\  Model Generation (LLM \& T2I)} &  \makecell{Principle-Guided Generation}  &  \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/VLM_stereotype.png}} 
\\
\rowcolor{gray!60!blue!10!white}\makecell{VLM} & \makecell{Preference} & \makecell{Model Generation (LLM \& T2I)} &  \makecell{Principle-Guided Generation}  &  \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/VLM_preference.png}} 
\\
\makecell{VLM} & \makecell{Machine Ethics} &\makecell{Dataset Pool Maintainer \\ Model Generation (LLM \& T2I)} &  \makecell{Principle-Guided Generation} & \makecell{\checkmarkcolor} & \makecell{\includegraphics[width=0.15\textwidth]{image/overall_plot/VLM_ethics.png}} \\
\bottomrule[1pt]
\end{tabular}} \label{tab:implementation-details}
\vspace{-15pt}
\end{table}