%\subsection{Model Editing}
Knowledge editing has gained significant attention due to the increasing need to update the knowledge in LLMs~\cite{wang2024knowledge, bi2024adaptive}.

Existing methods can be classified as follows:
(1) \emph{Fine-tuning} is an intuitive and straightforward way to update the model's knowledge~\cite{feng2023towards, gangadhar2024model, zheng2024collabedit}.
Recent parameter-efficient fine-tuning methods like Prefix-Tuning~\cite{li2021prefix} and LoRA~\cite{hu2021lora} have made fine-tuning more suitable for knowledge editing.
\citet{ni-etal-2024-forgetting} proposes the ``Forgetting before Learning'' (F-Learning) paradigm, which employs parametric arithmetic to facilitate the forgetting of old knowledge and the learning of new knowledge.
However, this often leads to unintended changes in unrelated knowledge, negatively affecting generalization~\cite{wang2024sss, gu2024model}.
(2) \emph{Meta-learning} (``learning to learn'') methods use a hypernetwork to generate task-specific updates, allowing LLMs to quickly adapt to new data without retraining from scratch~\cite{de2021editing, shi2024understanding, wang2024better}. 
(3) \emph{Locate-and-edit} methods usually locate influential parameters and then edit them by introducing a perturbation~\cite{zhang2024comprehensive, jiang2024learning, xu2024parenting}.
Classic methods like ROME~\cite{meng2022locating} and MEMIT~\cite{meng2022mass} use causal reasoning to identify key neuron activations and adjust specific weights.
More recent approaches, such as AlphaEdit~\cite{fang2024alphaedit}, improve the method by projecting perturbations onto the null space of preserved knowledge.

However, fine-tuning and locate-and-edit methods struggle to balance new knowledge updates with preserving unrelated knowledge~\cite{gupta2024unified, feng2024tasl2}. For instance, locate-and-edit methods typically require large additional datasets to capture general knowledge and avoid disruption during editing~\cite{wang2024detoxifying, hsueh2024editing}. However, these approaches introduce extra costs and biases.


Thus, our paper focuses on improving fine-tuning methods. Motivated by F-Learning~\cite{ni-etal-2024-forgetting}, we propose distinguishing between general knowledge and updated knowledge based on the angular divergence between the updated directions of old and new knowledge.
This allows us to avoid updating general knowledge, ensuring model generalization while applying tailored strategies to improve the effectiveness of knowledge updates.




%\subsection{Task Vectors}