
In this section, we present our method for knowledge editing in LLMs.
As illustrated in Figure~\ref{fig:method}, {\ouralg} follows a three-step process:
%Figure~\ref{fig:method} illustrates the diagram of {\ouralg}.

\subsection{Extracting Neuron-level Task Vectors}
Supervised fine-tuning (SFT) on a dataset injects new knowledge into the LLMs, reflected in model parameter changes.  
For an initial model $f_{\theta}$ with parameters $\theta$, fine-tuning on dataset $D$ produces updated parameters. The difference between the updated and original parameters is referred to as the \textit{task vector}~\cite{ilharco2022editing}, calculated as:
\begin{equation}
\tau =\mathrm{FT}\{\theta, D\}-\theta
\end{equation}
where $\tau$ is the corresponding task vector, and FT is the fine-tuning operation.
%$\mathrm{~K}$ refers to the dataset of knowledge.
%To disentangle old and new knowledge adaptations,
Unlike F-Learning, we fine-tune the initial model $f_{\theta}$ separately on the old and new knowledge datasets to isolate their respective adaptations, then compute task vectors:
\begin{equation}
\tau_{old} =\mathrm{FT}\{\theta, D_{old}\}-\theta
\end{equation}
\begin{equation}
\tau_{new} =\mathrm{FT}\{\theta, D_{new}\}-\theta
\end{equation}
where $D_{old}$ and $D_{new}$ are datasets encoding outdated and updated knowledge respectively.

While prior research typically captures task vectors at the model level~\cite{ilharco2022editing}, we propose extracting them at the neuron level for finer control.
Let $\theta = \{ \theta^1, \theta^2, \dots, \theta^N \}$ represent the $N$ neurons in the LLM, where the \( i \)-th neuron is represented by \( \theta^i \in \mathbb{R}^{d_{n}} \) with \( d_{n} \) dimensional parameters.
The neuron-level task vectors are given by \( \tau_{new} = \{ \tau_{new}^1, \tau_{new}^2, \dots, \tau_{new}^N \} \), where \( \tau_{new}^i \) corresponds to the new knowledge task vector for the \( i \)-th neuron.
This approach enables more granular analysis of parameter changes and selective editing of knowledge-specific neurons, enhancing model editing precision.


After obtaining the task vectors for both old and new knowledge, we focus on the directional characteristics, which are more crucial than magnitudes for knowledge editing. We define the direction of $\tau_{old}$ as the knowledge retention direction and $\tau_{new}$ as the knowledge updating direction. 
By analyzing the angle between these directions, we can distinguish general-knowledge-related neurons to avoid harming generalization and new-knowledge-related neurons to enhance editing effectiveness.
%Based on the angle between these two directions, we can distinguish between new knowledge updates and general knowledge perturbations in the model parameters, allowing us to tailor different editing strategies accordingly.



\subsection{Dimensionality Reduction Using AE}
%\subsection{Mitigating Dimensionality Curse Using Auto-Encoder}
After obtaining task vectors $\tau_{old}$ and $\tau_{new}$, we use an auto-encoder (AE) to map them into a low-dimensional latent space for knowledge editing. 
%This step mitigates the angular bias that arises when directly editing high-dimensional task vectors. 
This step mitigates the angular bias inherent in high-dimensional task vectors.
For example, in LLaMA-7B, each neuron-level task vector has 4096 dimensions, which naturally tend toward orthogonality, distorting the interpretation of their relationships.
Dimensionality reduction also removes irrelevant information, improving the editing accuracy.

Thus, we train a semantic encoder and decoder, both implemented using multi-layer perceptrons (MLPs). The encoder maps high-dimensional task vectors to a lower-dimensional space for editing, while the decoder reconstructs the edited vectors, which are then added back to the initial model for the final results.
%The primary objective of the auto-encoder is to map the task vector to a latent space via the encoder, and then reconstruct it through the decoder \cite{wang2016auto}. 
Specifically, the semantic encoder, denoted as \text{SemEnc($\cdot$)}, maps the high-dimensional task vectors $\tau_{old}$ and $\tau_{new}$ into the latent space as:
\begin{equation}
h^i = \text{SemEnc}(\tau^i)
\end{equation}
where $h^i \in \mathbb{R}^{d_{latent}}$ is the latent task vector, and $d_{latent}$ denotes its dimensionality.
%The decoder, \text{Dec($\cdot$)}, reconstructs the original task vector from the latent space:
The decoder, \text{Dec($\cdot$)}, then generates $\hat{\tau}^i$ from $h^i$ as follows:
\begin{equation}
\hat{\tau}^i = \text{Dec}(h^i)
\end{equation}
where $\hat{\tau}^i$ is the reconstructed task vector.
The auto-encoder is optimized using both a reconstruction loss and a semantic consistency loss:
%The auto-ecoder is optimized using the reconstruction loss between $\tau^i$ and $\hat{\tau}^i$, along with a semantic consistency loss:
\begin{equation}
\begin{split}
\mathcal{L}_{AE}=\operatorname{MSE}\left(\tau^i, \hat{\tau}^i\right) + \\ \lambda \cdot \operatorname{KL}\left(f_{\theta+\tau^i}(x) \| f_{\theta+\hat{\tau}^i}(x)\right) \label{eq:ae}
\end{split}
\end{equation}
where \text{MSE($\cdot$)} is mean square error loss function, and \text{KL($\cdot$)} is the Kullback-Leibler divergence. 
%We train the auto-encoder using all $\tau_{old}$ and $\tau_{new}$.



%\subsection{Direction-Aware Geometric Knowledge Editing}
\subsection{Geometric Knowledge Editing}
After training the auto-encoder, we project $\tau_{old}$ and $\tau_{new}$ into the low-dimensional latent space for knowledge editing. {\ouralg} then edit the latent task vectors to obtain $h_{edit}$, which is decoded to produce the edited task vector $\tau_{edit}$.
This vector is subsequently added to the initial model, resulting in the final edited model \(f_{\theta_{e}}\). 


\paragraph{Direction-aware Knowledge Identification}
For neuron \(i\), we first use the encoder to reduce the dimensionality of $\tau_{old}^i$ and $\tau_{new}^i$ yielding the latent task vectors $h_{old}^i$ and $h_{new}^i$. We then compute the angular divergence $\phi$ between $h_{old}^i$ and $h_{new}^i$ as:
\begin{equation}
\phi = \arccos \frac{h_{old}^i \cdot h_{new}^i}{\left|h_{old}^i\right| \cdot\left|h_{new}^i\right|}
\end{equation}

%Based on the angle $\phi$, we classify neurons with angles near orthogonality (i.e., within the range of $\phi_1$ to $\phi_2$) as general-knowledge-related neurons, while the remaining neurons with different angular ranges are classified as new-knowledge-related neurons.
Neurons with angles near orthogonality (within the range of $\phi_1$ to $\phi_2$) are classified as general-knowledge-related, while the remaining neurons are classified as new-knowledge-related.

\paragraph{Importance-guided Task Vector Fusion}
%We then customize the editing strategies based on the different types of neurons as follows:
We then apply customized editing strategies based on the classification of neurons as follows:
\begin{equation}
h_{edit}^i =
\begin{cases}
  \alpha^i h_{old}^i + \beta^i h_{new}^i, & \text{if $\phi \in (0^\circ, \phi_1)$} \\

  0, & \text{if $\phi \in [\phi_1, \phi_2]$} \\
  
  -\alpha^i h_{old}^i + \beta^i h_{new}^i, & \text{if $\phi \in (\phi_2, 180^\circ)$} \\
\end{cases}
\label{eq:fusion}
\end{equation}
where $\alpha^i, \beta^i \in [0, 1]$ are the fusion weights, automatically assigned based on the neuron's importance to both new and old knowledge, removing the need for manual adjustment.

To calculate the fusion weights, we measure the importance of each neuron by analyzing the gradient trajectory of its parameters during fine-tuning. The importance is determined by the collective contribution of its trainable parameters:
\begin{equation}
\mathcal{I}(\theta^i) = \frac{1}{d_n} \sum\limits_{j=1}^{d_n} s(w_{j}) \label{eq:ipt}
\end{equation}
where $w_{j}$ represents the trainable parameters and $d_n$ is the total number of parameters in neuron $\theta^i$. The function $\mathcal{I}(\theta^i)$ reflects the importance of the neuron, with higher values indicating greater significance.
The function $s(\cdot)$ computes the importance of individual parameters based on the magnitude of the gradient-weight product~\cite{zhang2023adalora}:
\begin{equation}
s\left(w\right)=\left|w \nabla_{w} \mathcal{L}\right| \label{eq:1}
\end{equation}

Due to stochastic sampling and training dynamics, the metric in Eq. (\ref{eq:1}) may vary, reducing reliability~\cite{feng2024tasl}. To address this, we apply an exponential moving average to smooth the trajectory gradients across training iterations.  
% \begin{equation}
% \begin{split}
% I_{b(q)}   =\alpha_{1} I_{b(q-1)} + \left(1-\alpha_{1}\right) \bar{I}_{b(q)} \label{eq:I}
% \end{split}
% \end{equation}
% where $\alpha_{1}$ is the smoothing factor, $q \in \left\{ 1, 2, ..., Q \right\}$ is the iteration number in the inner loop, and $I_{b(q)}$ represents smoothed importance.
% The inner task vector \(\tau_b^{\text{in}}\) and its associated parameter importance \(I_b^{\text{in}}\) are then passed to the outer learner.

We normalize the importance scores \( \mathcal{I}_{\text{old}} = \{ \mathcal{I}_{\text{old}}^1, \dots, \mathcal{I}_{\text{old}}^N \} \) and \( \mathcal{I}_{\text{new}} = \{ \mathcal{I}_{\text{new}}^1, \dots, \mathcal{I}_{\text{new}}^N \} \) independently to the range [0, 1]. This yields the final fusion weights \( \alpha = \{ \alpha^1, \dots, \alpha^N \} \) and \( \beta = \{ \beta^1, \dots, \beta^N \} \), which are then applied to the corresponding task vectors \( h_{\text{old}} \) and \( h_{\text{new}} \) for editing.



By applying Eq. (\ref{eq:fusion}), our {\ouralg} effectively addresses the challenges in model editing:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=0pt,parsep=0pt]
\item 
\textbf{Preserving general knowledge} (Case 2): We mask updates to general-knowledge-related neurons to avoid negatively impacting the model's generalization ability.

\item \textbf{Improving knowledge editing} (Case 1 $\&$ 3): For acute angles, we leverage the similarity between old and new knowledge for efficient integration. For obtuse angles, significant conflict triggers a ``forget-then-learn'' strategy, optimizing the updates for new-knowledge-related neurons. 

\end{itemize}


% \textbf{When the vectors are orthogonal} (Case 2): We mask the update to these parameters to prevent any negative impact on the model's generalization ability.
    
% \item \textbf{When the vectors are not orthogonal but the angle is small} (Case 1): We leverage the similarity between the old and new knowledge to promote efficient knowledge integration.
    
% \item \textbf{When the vectors are not orthogonal and the angle is large} (Case 3): A significant conflict between old and new knowledge prompts us to adopt a ``forget-then-learn'' strategy, where we first forget the old knowledge before integrating the new knowledge for better learning.

