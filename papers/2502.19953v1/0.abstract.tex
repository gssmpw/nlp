
% To maintain up-to-date knowledge in large language models (LLMs), regular updates are essential. Thus, various model editing methods have been proposed to update specific knowledge in LLMs. However, training-based approaches still struggle to balance effective incorporation of new knowledge while preserving unrelated general knowledge. 
% To address this challenge, we propose a novel framework called Geometric Knowledge Editing ({\ouralg}).
% {\ouralg} leverages the geometric relationships of parameter updates caused by fine-tuning to distinguish between neurons associated with new knowledge updates and those related to general knowledge perturbations.
Regular updates are essential for maintaining up-to-date knowledge in large language models (LLMs). Consequently, various model editing methods have been developed to update specific knowledge within LLMs. However, training-based approaches often struggle to effectively incorporate new knowledge while preserving unrelated general knowledge. To address this challenge, we propose a novel framework called Geometric Knowledge Editing ({\ouralg}). {\ouralg} utilizes the geometric relationships of parameter updates from fine-tuning to differentiate between neurons associated with new knowledge updates and those related to general knowledge perturbations.
By employing a direction-aware knowledge identification method, we avoid updating neurons with directions approximately orthogonal to existing knowledge, thus preserving the model's generalization ability. For the remaining neurons, we integrate both old and new knowledge for aligned directions and apply a ``forget-then-learn'' editing strategy for opposite directions.
Additionally, we introduce an importance-guided task vector fusion technique that filters out redundant information and provides adaptive neuron-level weighting, further enhancing model editing performance. Extensive experiments on two publicly available datasets demonstrate the superiority of {\ouralg} over existing state-of-the-art methods.
%\footnote{The code will be released upon publication.}


%\footnote{We uploaded the code as supplementary material for review and will release it on GitHub upon publication.}



% we propose Geometric Knowledge Editing (GeoEdit), a novel framework that leverages the geometric relationships of parameter updates after fine-tuning for model editing. GeoEdit optimizes new knowledge updates while identifying and mitigating disturbances to general knowledge, thus preserving model generalization.
% GeoEdit employs an auto-encoder to map neuron-level task vectors into a semantic space, addressing angular bias in high-dimensional space. Then, an importance-guided task vector fusion technique applies synergistic, orthogonal, and conflict knowledge editing strategies based on the direction of parameter updates. Finally, the decoder reconstructs the final editing task vector for the parameter update.
% Extensive experiments on two publicly available datasets demonstrate the superiority of GeoEdit over other fine-tuning-based baselines, particularly in terms of the locality metric.




















%GeoEdit first maps high-dimensional task vectors to a lower-dimensional semantic space using an autoencoder, mitigating the issue of angular bias in high-dimensional spaces. Then, for each pair of task vectors, it calculates the angular divergence and classifies the updates into three categories: synergistic, orthogonal, and conflict knowledge editing. Finally, an importance-guided vector fusion mechanism edits the task vectors, which are then passed through a decoder to return to the original high-dimensional space, integrating with the initial model.
%Experimental results show that GeoEdit addresses the limitations of F-Learning, maintaining high reliability and generality while improving the locality metric by an average of 10\%.
