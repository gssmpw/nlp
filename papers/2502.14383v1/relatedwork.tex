\section{Related Work}
\subsection{Temporal Misinformation Detection}

Posts on social media often come with timestamps. Therefore, many studies use time information to assist in detecting false information. \citet{nie2021early} propose a temporal Bi-GCN model to learn representations for rumor propagation by encoding the temporal information for graph structures. \citet{qu2024temporal} design multimodal graph neural networks that can form a temporal news cluster and learn temporal features for fake news detection. \citet{guo2022temporal} suggest a block-based representation and fusion mechanism that can utilize the information from both spatial and temporal perspectives. \citet{wakamiya2020fake} adopt an attention-based method to combine linguistic and user features alongside temporal features. \citet{cavalcante2024early} propose the time-aware crowd signals method to explore the temporal nature of news propagation, utilizing usersâ€™ reputations obtained from their public behavior when spreading news in the past.

% \subsection{Multi-task misinformation detection}

% Multi-task learning is a multi-objective optimization method that can effectively improve the generalization ability of models \cite{ekbal2024multitasking}. \cite{choudhry2022emotion, chakraborty2023emotion, kumari2021multitask} design various auxiliary tasks (e.g. sentiment, novelty, domain) to improve the main misinformation detection task based on LSTM structure. 
% \citet{jiang2024makes} fed features extracted by BERT into multiple linear classifiers to incorporate auxiliary sentiment and stance tasks. \citet{kumari2024emotion} introduces a multitask framework for video-based multimodal fake news detection, in which emotion recognition is the auxiliary task. It can be seen that sentiments and emotions play important roles in multi-task fake news detection.

\subsection{Emotion-based Misinformation Detection}

Emotion and sentiment are important features in detecting misinformation \cite{liu2024emotion}. 
% {\bf I ADDED THIS SENTENCE TO FIX THE EMOTION-SENTIMENT PROBLEM...PLS CONFIRM} In our work we recognize that positive sentiment correlates with positive emotion and vice versa and use emotion as the principal labeling. 
\citet{choudhry2022emotion,chakraborty2023emotion,jiang2024makes,kumari2024emotion} introduce multitask frameworks for incorporating sentiment/emotion as auxiliary tasks to enhance the main misinformation detection task. \citet{ghanem2021fakeflow} propose the FakeFlow for fake news detection that can capture the flow of affective information by combining topic and sentiments. \citet{Liu2024ConspEmoLLMCT,liu2024raemollm} adapt LLMs for misinformation detection by levering affective information based on fine-tuning and RAG techniques respectively. However, these models are only applicable to fake source text and do not consider social content. \citet{luvembe2023dual} develop an attention-based mechanism by combining CNN and Bi-GRU for enriched extraction of dual emotion features. \citet{zhang2021mining} analyze the relationship between dual emotions and propose dual emotion features, which can be plugged into existing fake news detectors. \citet{wang2024multimodal} further fuses the author's visual emotion for multi-modal rumor detection. These works indicate the importance of dual emotion features. 

\subsection{Comment-based Rumor Detection}

Social media posts often come with rich comments. Combining information from the source and tweets can help improve rumor detection models. Some studies focus on the propagation pattern in rumors. \citet{ma-etal-2018-rumor} apply two recursive neural models based on tree-structured neural networks to learn the propagation layout of tweets. \citet{bian2020rumor} adopt a bi-directional graph model to learn the patterns of rumor propagation. \citet{khoo2020interpretable} propose a post-level attention model, which incorporates tree structure information into the transformer network.  \cite{yang-etal-2023-rumor} design a Crowd Intelligence and ChatGPT-Assisted Network, which combines crowd intelligence-based feature learning, ChatGPT-enhanced knowledge mining, and an entity-aware heterogeneous graph. Also, there are many studies using the features of comments. Like \citet{zhang2021mining} apply the emotion and sentiment features and \citet{enayet2017niletmrg,li2021joint} leverage stance features for misinformation detection.

% develop a Claim-guided Hierarchical Graph Attention Network that models conversation threads as an interaction graph to enhance rumor classification.

% LLMs perform well in tasks involving misinformation due to their outstanding capabilities \cite{augenstein2024factuality}. In addition to the studies in the above sections, \citet{hu2024bad} design an adaptive rationale guidance network that leverages insights on news analysis from LLM to guide small language model in fake news detection. \citet{wang2024llm} propose a framework that utilizes prompting strategy to enable an LLM to become Generator and Detector and for fake news generation and detection. \citet{cheung2023factllama} enhance fact-checking performance of LLMs by leveraging search engines to retrieve external knowledge.  \citet{liu2024fka} design a multimodal fake news detection framework that leverages forgery-specific knowledge to augment one multi-modal LLM, enabling them to reason about manipulations effectively. \citet{liu2024can} design prompts to teach LLMs to reason over clues in news and comments and divide the propagation information into a chain of propagation for rumor detection. 

\subsection{Prompt-tuning and Prefix-tuning}

Prompt-tuning \cite{lester2021power} and prefix-tuning \cite{li2021prefix} typically involve fine-tuning a small number of parameters to adapt to specific tasks, rather than modifying the entire LLM. \citet{peng2024model} develop a soft prompt-based learning architecture based on a clinical LLM for clinical concept and relation extraction. \citet{fischer2024prompt} provide a prompt-able architecture for medical image segmentation, which is frozen post pre-training but remains flexible with class-specific learnable prompt tokens. \citet{ma2024image} propose a super-resolution training method based on prefix and prompt fine-tuning, in which only a few prefix and prompt parameters are added to the self-attention module. \citet{wu2024apt} design an adaptive prefix-tuning technique involving the training of prefix parameters on adapting tasks, followed by fine-tuning on downstream tasks. \citet{ma2024focused} propose focused prefix tuning to enable the control to focus on the desired attribute for controllable text generation. \citet{lin2023zero} propose a zero-shot framework for rumor detection based on prompt learning. They first represent Rumors as different propagation threads, then a hierarchical prompt encoding mechanism is designed to learn context representations.