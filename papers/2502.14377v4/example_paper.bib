### methods
@inproceedings{yu2022metaformer,
  title={Metaformer is actually what you need for vision},
  author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10819--10829},
  year={2022}
}

@article{pires2023sharedFFN,
  title={One wide feedforward is all you need},
  author={Pires, Telmo Pessoa and Lopes, Ant{\'o}nio V and Assogba, Yannick and Setiawan, Hendra},
  journal={arXiv preprint arXiv:2309.01826},
  year={2023}
}

@inproceedings{lee2024ditPruner,
  title={DiT-Pruner: Pruning Diffusion Transformer Models for Text-to-Image Synthesis Using Human Preference Scores},
  author={Lee, Youngwan and Lee, Yong-Ju and Hwang, Sung Ju},
  booktitle={European Conference on Computer Vision (ECCV) 2024},
  pages={1--9},
  year={2024}
}

@article{gromov2024unreasonable,
  title={The unreasonable ineffectiveness of the deeper layers},
  author={Gromov, Andrey and Tirumala, Kushal and Shapourian, Hassan and Glorioso, Paolo and Roberts, Daniel A},
  journal={arXiv preprint arXiv:2403.17887},
  year={2024}
}

@article{zhong2024blockpruner,
  title={BlockPruner: Fine-grained Pruning for Large Language Models},
  author={Zhong, Longguang and Wan, Fanqi and Chen, Ruijun and Quan, Xiaojun and Li, Liangzhi},
  journal={arXiv preprint arXiv:2406.10594},
  year={2024}
}

###

### add
@article{wang2024qihoo,
  title={Qihoo-T2X: An Efficient Proxy-Tokenized Diffusion Transformer for Text-to-Any-Task},
  author={Wang, Jing and Ma, Ao and Feng, Jiasong and Leng, Dawei and Yin, Yuhui and Liang, Xiaodan},
  journal={arXiv preprint arXiv:2409.04005},
  year={2024}
}

@article{he2024idanimator,
  title={Id-animator: Zero-shot identity-preserving human video generation},
  author={He, Xuanhua and Liu, Quande and Qian, Shengju and Wang, Xin and Hu, Tao and Cao, Ke and Yan, Keyu and Zhang, Jie},
  journal={arXiv preprint arXiv:2404.15275},
  year={2024}
}

@article{cao2024shufflemamba,
  title={Shuffle mamba: State space models with random shuffle for multi-modal image fusion},
  author={Cao, Ke and He, Xuanhua and Hu, Tao and Xie, Chengjun and Zhang, Jie and Zhou, Man and Hong, Danfeng},
  journal={arXiv preprint arXiv:2409.01728},
  year={2024}
}
###

### compare methods
@inproceedings{zhang2023controlnet,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

@article{qin2023unicontrol,
  title={Unicontrol: A unified diffusion model for controllable visual generation in the wild},
  author={Qin, Can and Zhang, Shu and Yu, Ning and Feng, Yihao and Yang, Xinyi and Zhou, Yingbo and Wang, Huan and Niebles, Juan Carlos and Xiong, Caiming and Savarese, Silvio and others},
  journal={arXiv preprint arXiv:2305.11147},
  year={2023}
}

@article{zhao2024unicontrolnet,
  title={Uni-controlnet: All-in-one control to text-to-image diffusion models},
  author={Zhao, Shihao and Chen, Dongdong and Chen, Yen-Chun and Bao, Jianmin and Hao, Shaozhe and Yuan, Lu and Wong, Kwan-Yee K},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{zavadski2025controlnetxs,
  title={ControlNet-XS: Rethinking the Control of Text-to-Image Diffusion Models as Feedback-Control Systems},
  author={Zavadski, Denis and Feiden, Johann-Friedrich and Rother, Carsten},
  booktitle={European Conference on Computer Vision},
  pages={343--362},
  year={2025},
  organization={Springer}
}

@article{peng2024controlnext,
  title={Controlnext: Powerful and efficient control for image and video generation},
  author={Peng, Bohao and Wang, Jian and Zhang, Yuechen and Li, Wenbo and Yang, Ming-Chang and Jia, Jiaya},
  journal={arXiv preprint arXiv:2408.06070},
  year={2024}
}


@article{tan2024ominicontrol,
  title={OmniControl: Minimal and Universal Control for Diffusion Transformer},
  author={Zhenxiong Tan and Songhua Liu and Xingyi Yang and Qiaochu Xue and Xinchao Wang},
  journal={arXiv preprint arXiv:2411.15098},
  year={2024}
}



@inproceedings{lin2014microsoftcoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{heusel2017fid,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}

@article{schuhmann2022clipae,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@misc{openai2024videogeneration,
  author = {{OpenAI}},
  title = {Sora},
  howpublished = {\url{https://openai.com/}},
  year = {2024},
  note = {Accessed: 2024-09-03}
}

@misc{kling2024videogeneration,
  author = {{Kuaishou}},
  title = {Kling},
  howpublished = {\url{https://klingai.kuaishou.com/}},
  year = {2024},
  note = {Accessed: 2024-09-03}
}
@misc{stabilityai2024sd3,
  author = {{Stability AI}},
  title = {StableDiffusion3},
  howpublished = {\url{https://stability.ai/news/stable-diffusion-3}},
  year = {2024},
  note = {Accessed: 2024-09-03}
}
@article{chen2023pixarta,
  title={Pixart-$\alpha$: Fast training of diffusion transformer for photorealistic text-to-image synthesis},
  author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and others},
  journal={arXiv preprint arXiv:2310.00426},
  year={2023}
}
@article{chen2024pixartb,
  title={Pixart-$\sigma$: Weak-to-strong training of diffusion transformer for 4k text-to-image generation},
  author={Chen, Junsong and Ge, Chongjian and Xie, Enze and Wu, Yue and Yao, Lewei and Ren, Xiaozhe and Wang, Zhongdao and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
  journal={arXiv preprint arXiv:2403.04692},
  year={2024}
}
@article{chen2024pixartc,
  title={Pixart-$\delta$: Fast and controllable image generation with latent consistency models},
  author={Chen, Junsong and Wu, Yue and Luo, Simian and Xie, Enze and Paul, Sayak and Luo, Ping and Zhao, Hang and Li, Zhenguo},
  journal={arXiv preprint arXiv:2401.05252},
  year={2024}
}
@misc{shengshuai2024vidu,
  author = {{Shengshu AI}},
  title = {Vidu},
  howpublished = {\url{https://www.vidu.studio/}},
  year = {2024},
  note = {Accessed: 2024-09-03}
}

@misc{blackforestlabs2024flux,
  author = {{BlackForestlabs AI}},
  title = {Flux},
  howpublished = {\url{https://blackforestlabs.ai/#get-flux}},
  year = {2024},
  note = {Accessed: 2024-09-03}
}
@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

# open-sora-plan
@software{pku_yuan_lab_and_tuzhan_ai_etc_2024_10948109,
  author       = {PKU-Yuan Lab and Tuzhan AI etc.},
  title        = {Open-Sora-Plan},
  month        = apr,
  year         = 2024,
  publisher    = {GitHub},
  doi          = {10.5281/zenodo.10948109},
  url          = {https://doi.org/10.5281/zenodo.10948109}
}

# open-sora
@software{opensora,
  author = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  title = {Open-Sora: Democratizing Efficient Video Production for All},
  month = {March},
  year = {2024},
  url = {https://github.com/hpcaitech/Open-Sora}
}
# Latte

@article{ma2024latte,
  title={Latte: Latent diffusion transformer for video generation},
  author={Ma, Xin and Wang, Yaohui and Jia, Gengyun and Chen, Xinyuan and Liu, Ziwei and Li, Yuan-Fang and Chen, Cunjian and Qiao, Yu},
  journal={arXiv preprint arXiv:2401.03048},
  year={2024}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{raffel2020t5,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}


@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}


@inproceedings{peebles2023dit,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}
@article{ma2024sit,
  title={Sit: Exploring flow and diffusion-based generative models with scalable interpolant transformers},
  author={Ma, Nanye and Goldstein, Mark and Albergo, Michael S and Boffi, Nicholas M and Vanden-Eijnden, Eric and Xie, Saining},
  journal={arXiv preprint arXiv:2401.08740},
  year={2024}
}

@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}

@article{li2024hunyuan,
  title={Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding},
  author={Li, Zhimin and Zhang, Jianwei and Lin, Qin and Xiong, Jiangfeng and Long, Yanxin and Deng, Xinchi and Zhang, Yingfang and Liu, Xingchao and Huang, Minbin and Xiao, Zedong and others},
  journal={arXiv preprint arXiv:2405.08748},
  year={2024}
}

@article{han2022survey,
  title={A survey on vision transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={1},
  pages={87--110},
  year={2022},
  publisher={IEEE}
}

@article{zhang2019root,
  title={Root mean square layer normalization},
  author={Zhang, Biao and Sennrich, Rico},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5288--5296},
  year={2016}
}

@article{soomro2012dataset,
  title={A dataset of 101 human action classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={Center for Research in Computer Vision},
  volume={2},
  number={11},
  pages={1--7},
  year={2012},
  publisher={Univ. of Central Florida}
}


@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

@inproceedings{zhang2024artbank,
  title={ArtBank: Artistic Style Transfer with Pre-trained Diffusion Model and Implicit Style Prompt Bank},
  author={Zhang, Zhanjie and Zhang, Quanwei and Xing, Wei and Li, Guangyuan and Zhao, Lei and Sun, Jiakai and Lan, Zehua and Luan, Junsheng and Huang, Yiling and Lin, Huaizhong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={7},
  pages={7396--7404},
  year={2024}
}

@article{feng2024fancyvideo,
  title={FancyVideo: Towards Dynamic and Consistent Video Generation via Cross-frame Textual Guidance},
  author={Feng, Jiasong and Ma, Ao and Wang, Jing and Cheng, Bo and Liang, Xiaodan and Leng, Dawei and Yin, Yuhui},
  journal={arXiv preprint arXiv:2408.08189},
  year={2024}
}
@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@inproceedings{rombach2022ldm,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@article{shuai2024survey,
  title={A Survey of Multimodal-Guided Image Editing with Text-to-Image Diffusion Models},
  author={Shuai, Xincheng and Ding, Henghui and Ma, Xingjun and Tu, Rongcheng and Jiang, Yu-Gang and Tao, Dacheng},
  journal={arXiv preprint arXiv:2406.14555},
  year={2024}
}

@article{xue2024raphael,
  title={Raphael: Text-to-image generation via large mixture of diffusion paths},
  author={Xue, Zeyue and Song, Guanglu and Guo, Qiushan and Liu, Boxiao and Zong, Zhuofan and Liu, Yu and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{huttenlocher1993comparing,
  title={Comparing images using the Hausdorff distance},
  author={Huttenlocher, Daniel P and Klanderman, Gregory A. and Rucklidge, William J},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={15},
  number={9},
  pages={850--863},
  year={1993},
  publisher={IEEE}
}

@article{men2024shortgpt,
  title={Shortgpt: Layers in large language models are more redundant than you expect},
  author={Men, Xin and Xu, Mingyu and Zhang, Qingyu and Wang, Bingning and Lin, Hongyu and Lu, Yaojie and Han, Xianpei and Chen, Weipeng},
  journal={arXiv preprint arXiv:2403.03853},
  year={2024}
}

@article{huang2021shuffle,
  title={Shuffle transformer: Rethinking spatial shuffle for vision transformer},
  author={Huang, Zilong and Ben, Youcheng and Luo, Guozhong and Cheng, Pei and Yu, Gang and Fu, Bin},
  journal={arXiv preprint arXiv:2106.03650},
  year={2021}
}