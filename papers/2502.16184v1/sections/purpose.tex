\section{The Purpose of \Art{15}}\label{sec:purpose_15aia}
%
\Art{15(1)} states that high-risk AI systems must achieve an ``appropriate level of accuracy, robustness and cybersecurity'' and must function consistently in this respect throughout their lifecycle. It is one of seven provisions in the AIA that sets specific requirements for high-risk AI systems. 
%
These requirements aim to ensure product safety and 
% 
a ``consistent and high level of protection of public interests as regards health, safety and fundamental rights'' (\EW{7}). Particularly, \Art{15(1)} outlines specific product-related requirements for AI systems, detailing how they must be ``designed and developed'' to achieve trustworthy AI. 
%
This is emphasized by the 2019 Ethics Guidelines for Trustworthy AI developed by
the AI Independent High-level Expert Group (AI IHEG) on AI~\citep{aiiheg2019guidelines} appointed by the European Commission which can be seen as the conceptual basis of the \EUAIAct\ (\EW{27}). 
%
These guidelines state that technical robustness ensures that AI systems ``reliably behave as intended while minimizing unintentional and unexpected harm, and preventing unacceptable harm''.

The question arises as to why it is even necessary to regulate accuracy, robustness and cybersecurity of AI systems. 
%
One could assume that it is in the best interest of an economic actor to fulfill these requirements in the best possible way to gain a market advantage. 
%
The European Commission's impact assessment of the AI Act recognizes this thought with respect to accuracy and robustness, stating that ``an economic operator [...] would anyway have
to ensure that their product actually works''~\citep[Annex 4]{assessment2021commission}.
%
However, the impact assessment clarifies that ``is important that these requirements are included in the regulatory framework so that
substandard operators need to improve their procedures''~\citep[Annex 4]{assessment2021commission}.


Therefore, the purpose of the specific requirements set out in \Art{15} is to achieve the overarching objective of ensuring the trustworthiness of AI systems (see \Art{1(1)}) and to advance the cybersecurity agenda of the EU.\footnote{COM/2010/245 final/2, COM/2021/118 final.}
% 