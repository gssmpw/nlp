
\section{Background on the \EUAIAct\ and \Art{15}}
\label{sec:background_aia}

\paragraph{\EUAIAct} 
The \EUAIAct\ creates harmonized rules for certain AI systems in order to incentivize the use of such systems in the EU market and prevent regulatory fragmentation between member states (\EW{1}).
%
It is formally structured into recitals (\EWx), articles (\Artx), and annexes. Recitals are not strictly legally binding and outline the rationale behind the articles, articles delineate specific binding
%  
obligations, and the annexes provide additional details and 
specifications to support the articles
~\citep{klimas15law}.\footnote{From now on, whenever we cite recitals, we refer to those in the \EUAIAct\ without explicitly indicating it.}
% 
\Art{3(1)} defines an AI system as ``a machine-based system that is designed to operate with varying levels
of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or
implicit objectives, infers, from the input it receives, how to generate outputs [...] that can influence physical or virtual
environments''. 
%
These AI systems are regulated differently based on their perceived risk level~\citep{bomhard2024AIAct, sioli2021}: Those posing unacceptable risks, such as social scoring, are prohibited or subject to qualified prohibitions; \HRAIS, such as those used in 
%
medical devices, are allowed but must comply with certain requirements and undergo pre-assessment; other AI systems are subject only to specific transparency and information obligations. 
%
Among these categories, only \HRAIS\ must fulfill the robustness and cybersecurity requirements under \Art{15}.
%
According to \Art{16(a)}, providers of \HRAIS\ must ensure compliance with these requirements. 
%
An AI system is considered a \HRAIS\ if it is either a safety component of a product or a product itself regulated under specific legislation, such as medical devices, machinery, or toys (\Art{6(1)}, Annex I), or if it poses a significant risk of harm to the health, safety, or fundamental rights of individuals in specific areas, such as education, employment, or law enforcement (\Artx\ 6(2) and (3) \EUAIAct, Annex III).

In addition to AI systems, the \EUAIAct\ establishes a separate regime of legal requirements in chapter V of the \EUAIAct\ for a very specific type of AI models, namely \GPAIM\ (e.g., multimodal large language models, see also Section~\ref{sec:gpai}).
%
GPAI models are AI models that can perform tasks that they were not originally trained for~\citep{gutierrez2023proposal}, such as large language models~\cite{openai2023gpt, team2023gemini}, or large text-to-image models~\cite{ramesh2022hierarchical}. Other types of AI models are not regulated and mentioned in the \EUAIAct.
These are models that are created with a specific objective and can only accomplish tasks they are trained to perform (e.g., translation, classification).

The \EUAIAct\
does not directly define specific technical requirements. Instead, it sets out 'essential requirements' that AI systems must comply with, and which are concretized by so-called technical standards.
The regulatory concept of relying on standardization is a well-established process in EU product legislation and is referred to as the New Legislative Framework~\citep{gorywoda2009new}.
%
It traditionally involves the participation of stakeholders, such as providers of AI systems.
%
The European Commission has already issued a standardization request to the European Committee for Standardisation and the European Committee for Electrotechnical Standardisation to develop standards for the \EUAIAct\ until 30 April 2025.\footnote{C(2023)3215 - Standardisation request M/593.}
%
Specifically, Annex I enlists  `robustness' and `cybersecurity' specifications for AI systems as standardisation deliverables to be developed.
% 
Once accepted by the European Commission, these technical standards become 'harmonized' standards and compliance with the \EUAIAct\ will be presumed if providers adhere to them (\Art{40}).



\paragraph{\Art{15}} 
\Art{15(1)} requires that \HRAIS\ ``shall be designed and developed in such a way that they achieve an appropriate level of accuracy, robustness, and cybersecurity, and that they perform consistently in those respects throughout their lifecycle''.
%
The provision outlines specific product-related requirements for AI systems to ensure they are trustworthy.
%
\Art{15(4)} mandates that \HRAIS\ exhibit resilience ``regarding errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems''.
%
Additionally, \Art{15(5)} requires \HRAIS\ to be ``resilient against attempts by unauthorised third parties to alter their use, outputs or performance by exploiting system
vulnerabilities''. 
%
\Art{15(2)} requires the EU Commission, together with other relevant stakeholders, to encourage the development of benchmarks and measurement methods for assessing accuracy, robustness, and other performance metrics.