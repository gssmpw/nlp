
\section{Summary and Outlook}\label{sec:discussion_outlook}
% 
We identified several legal challenges and potential limitations in implementing robustness and cybersecurity requirements for \HRAIS\ under \Art{15(4) and (5)}. 
%
We also examined \GPAIMSSR, which face cybersecurity but not robustness requirements, and identified additional legal challenges.
%
We proposed a simple explanatory model that maps \emph{non-adversarial robustness} in the ML literature to the term `robustness' used in \Art{15(1) and (4)}, and that maps \emph{adversarial robustness} to the term `cybersecurity' used in \Art\ 15(1) and (5) \EUAIAct.
%
However, 
both `robustness' and `cybersecurity' can refer also to other concepts both within the domain of ML and beyond.
%
Comparing the provisions for \HRAIS\ to those for \GPAIMSSR, we argued that \emph{adversarial robustness} maps to the term `cybersecurity' used in \Art{55(1)(d)}. However, we were not able to find an explicit equivalent legal requirement for \emph{non-adversarial robustness} in the provisions regulating \GPAIMSSR\ models.

Our analysis highlights the need for clearer specifications of these provisions through harmonized standards, guidelines by the EU Commission or the benchmark and measurement methodologies foreseen for robustness and cybersecurity in \Art{15(2)}. These would help define technical requirements and establish evaluation criteria for AI systems.
%
Specifically, we suggest that technical standards and guidelines by the EU Commission should focus on: i) identify the technical requirements associated with vague legal terms; ii) defining the required level of `robustness' and `cybersecurity' and other concepts such as `consistency'; iii) defining the requirements for evaluating and assessing AI systems and its components; and iv) pay attention to some aspects that are not explicitly regulated, such as feedback loops in offline systems in \Art{15(4)} or   organizational measures to ensure `cybersecurity' in \Art{15(5)}.

However, while standards and guidelines can ensure compatibility and practical integration of regulatory frameworks, they can struggle to keep pace with rapid technological advancements. 
%
This can lead to outdated versions that do not fully address emerging technologies or novel applications.
% 
Our analysis is not without limitations. Due to the novelty of the \EUAIAct, we lack empirical data to support claims about the challenges in implementing its requirements. While we focus on identifying these challenges, proposing specific definitions, processes, metrics, or thresholds is left for future work.
%
Future research should focus on non-adversarial robustness for \GPAIMSSR, and explore legal intersections with frameworks like the Medical Device Regulation~\cite{biasin2023new, nolte2024new}. Additionally, the focus on models in ML research versus entire AI systems in the \EUAIAct\ underscores the need for interdisciplinary work. Within the ML domain, future work should explore the impact of accuracy metrics on robustness, potential `robustness hacking', and methods to measure and ensuring long-term performance consistency in the presence of feedback loops.

