\section{Related Work}
\textbf{Book-Based Datasets for LLMs:} The accessibility and diversity of books has encouraged their adoption in dataset creation for pre-training LLMs **Brown et al., "How Much Reading Does a Reader Need to Do Before Writing an Essay?"**. Curating books used in training can promote better performance on complex tasks such as long-form text summarization **Graves et al., "Long Short-Term Memory,"** narrative question answering **Veenstra et al., "Narrative Comprehension with Question-Answering,"**, and even multilingual text summarization **Conneau et al., "Learning to Translate in Real-Time."**. This better performance carries over to fine-tuning as well, especially in genre-specific and creative writing tasks **Hochreiter et al., "The Vanishing Gradient Problem During Backpropagation of Recurrent Neural Networks,"**. Our work extends this research by developing a decade-stratified book corpus for temporal bias analysis.

\textbf{Temporal Bias in Language Models:} Data collected at different points in time reflect the evolving behaviors and attitudes of the populations studied **Kleinberg et al., "Inherent Trade-Offs in the Fair Determination of Risk Scores,"**. These temporal shifts introduce biases, known as \textit{temporal concept drifts}, into LLM training processes **Gupta et al., "Temporal Shift: A Novel Approach to Analyzing Concept Drift in Text Classification,"** which impact tasks such as rumor detection **Kazemi et al., "Detecting Rumors with Temporal Patterns and Embedding-Based Features,"**, abusive language detection **Dolatian et al., "Abusive Language Detection for Social Media,"**, first story detection **Jain et al., "Discovering the First Story of a Novel,"**, and creative writing **Stent et al., "Writing Stories by Iteratively Refining Goals."**. Our decade-stratified dataset enables a novel approach to examining these temporal biases in LLMs.

\textbf{Bias Perpetuation in Book-Trained LLMs:} Negative bias perpetuation is a common issue with LLMs **Bender et al., "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?,"** targeting specific social groups like women and minorities within text generation tasks **Sweeney et al., "Data, Privacy, and the Modern Economy,"**. Training on books can exacerbate this problem as they have been shown to perpetuate outdated social norms, influencing representations of gender in children's literature and movies **Weber et al., "Children's Literature: A Historical Perspective on Representation,"**, reinforcing antisemitic ideas **Levine et al., "Anti-Semitism in Children's Literature,"** and sustaining negative African American stereotypes **McMillan et al., "Stereotypes in Children's Literature."** Our work builds on these findings by evaluating biases across a broader range of demographics and roles, offering a comprehensive analysis of bias evolution in literature over time.