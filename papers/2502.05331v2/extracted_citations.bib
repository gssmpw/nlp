@inproceedings{10.1145/3532106.3533526,
author = {Hoque, Md Naimul and Ghai, Bhavya and Elmqvist, Niklas},
title = {DramatVis Personae: Visual Text Analytics for Identifying Social Biases in Creative Writing},
year = {2022},
isbn = {9781450393584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532106.3533526},
doi = {10.1145/3532106.3533526},
abstract = {Implicit biases and stereotypes are often pervasive in different forms of creative writing such as novels, screenplays, and children’s books. To understand the kind of biases writers are concerned about and how they mitigate those in their writing, we conducted formative interviews with nine writers. The interviews suggested that despite a writer’s best interest, tracking and managing implicit biases such as a lack of agency, supporting or submissive roles, or harmful language for characters representing marginalized groups is challenging as the story becomes longer and complicated. Based on the interviews, we developed DramatVis Personae (DVP), a visual analytics tool that allows writers to assign social identities to characters, and evaluate how characters and different intersectional social identities are represented in the story. To evaluate DVP, we first conducted think-aloud sessions with three writers and found that DVP is easy-to-use, naturally integrates into the writing process, and could potentially help writers in several critical bias identification tasks. We then conducted a follow-up user study with 11 writers and found that participants could answer questions related to bias detection more efficiently using DVP in comparison to a simple text editor.},
booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
pages = {1260–1276},
numpages = {17},
keywords = {Creative writing, and NLP., bias, visualization},
location = {Virtual Event, Australia},
series = {DIS '22}
}

@inproceedings{Wurzer_2020, series={SIGIR ’20},
   title={How UMass-FSD Inadvertently Leverages Temporal Bias},
   url={http://dx.doi.org/10.1145/3397271.3401306},
   DOI={10.1145/3397271.3401306},
   booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
   publisher={ACM},
   author={Wurzer, Dominik and Qin, Yumeng},
   year={2020},
   month=jul, pages={2097–2100},
   collection={SIGIR ’20} }

@misc{abid2021persistentantimuslimbiaslarge,
      title={Persistent Anti-Muslim Bias in Large Language Models}, 
      author={Abubakar Abid and Maheen Farooqi and James Zou},
      year={2021},
      eprint={2101.05783},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2101.05783}, 
}

@inproceedings{agarwal-etal-2022-creativesumm,
    title = "{CREATIVESUMM}: Shared Task on Automatic Summarization for Creative Writing",
    author = "Agarwal, Divyansh  and
      Fabbri, Alexander R.  and
      Han, Simeng  and
      Kryscinski, Wojciech  and
      Ladhak, Faisal  and
      Li, Bryan  and
      McKeown, Kathleen  and
      Radev, Dragomir  and
      Zhang, Tianyi  and
      Wiseman, Sam",
    editor = "Mckeown, Kathleen",
    booktitle = "Proceedings of The Workshop on Automatic Summarization for Creative Writing",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.creativesumm-1.10",
    pages = "67--73",
    abstract = "This paper introduces the shared task of summrizing documents in several creative domains, namely literary texts, movie scripts, and television scripts. Summarizing these creative documents requires making complex literary interpretations, as well as understanding non-trivial temporal dependencies in texts containing varied styles of plot development and narrative structure. This poses unique challenges and is yet underexplored for text summarization systems. In this shared task, we introduce four sub-tasks and their corresponding datasets, focusing on summarizing books, movie scripts, primetime television scripts, and daytime soap opera scripts. We detail the process of curating these datasets for the task, as well as the metrics used for the evaluation of the submissions. As part of the CREATIVESUMM workshop at COLING 2022, the shared task attracted 18 submissions in total. We discuss the submissions and the baselines for each sub-task in this paper, along with directions for facilitating future work.",
}

@misc{basyal2023textsummarizationusinglarge,
      title={Text Summarization Using Large Language Models: A Comparative Study of MPT-7b-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT Models}, 
      author={Lochan Basyal and Mihir Sanghvi},
      year={2023},
      eprint={2310.10449},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.10449}, 
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@misc{gao2020pile800gbdatasetdiverse,
      title={The Pile: An 800GB Dataset of Diverse Text for Language Modeling}, 
      author={Leo Gao and Stella Biderman and Sid Black and Laurence Golding and Travis Hoppe and Charles Foster and Jason Phang and Horace He and Anish Thite and Noa Nabeshima and Shawn Presser and Connor Leahy},
      year={2020},
      eprint={2101.00027},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2101.00027}, 
}

@inproceedings{goldberg-orwant-2013-dataset,
    title = "A Dataset of Syntactic-Ngrams over Time from a Very Large Corpus of {E}nglish Books",
    author = "Goldberg, Yoav  and
      Orwant, Jon",
    editor = "Diab, Mona  and
      Baldwin, Tim  and
      Baroni, Marco",
    booktitle = "Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S13-1035",
    pages = "241--247",
}

@inproceedings{gonen-goldberg-2019-lipstick,
    title = "Lipstick on a Pig: {D}ebiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them",
    author = "Gonen, Hila  and
      Goldberg, Yoav",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1061",
    doi = "10.18653/v1/N19-1061",
    pages = "609--614",
    abstract = "Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between {``}gender-neutralized{''} words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.",
}

@article{gooden2001gender,
  title={Gender representation in notable children's picture books: 1995--1999},
  author={Gooden, Angela M and Gooden, Mark A},
  journal={Sex roles},
  volume={45},
  pages={89--101},
  year={2001},
  publisher={Springer}
}

@misc{jin2023examiningtemporalbiasabusive,
      title={Examining Temporal Bias in Abusive Language Detection}, 
      author={Mali Jin and Yida Mu and Diana Maynard and Kalina Bontcheva},
      year={2023},
      eprint={2309.14146},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.14146}, 
}

@misc{kocyigit2023novelmethodanalysingracial,
      title={A Novel Method for Analysing Racial Bias: Collection of Person Level References}, 
      author={Muhammed Yusuf Kocyigit and Anietie Andy and Derry Wijaya},
      year={2023},
      eprint={2310.15847},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2310.15847}, 
}

@misc{kočiský2017narrativeqareadingcomprehensionchallenge,
      title={The NarrativeQA Reading Comprehension Challenge}, 
      author={Tomáš Kočiský and Jonathan Schwarz and Phil Blunsom and Chris Dyer and Karl Moritz Hermann and Gábor Melis and Edward Grefenstette},
      year={2017},
      eprint={1712.07040},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1712.07040}, 
}

@misc{kryściński2022booksumcollectiondatasetslongform,
      title={BookSum: A Collection of Datasets for Long-form Narrative Summarization}, 
      author={Wojciech Kryściński and Nazneen Rajani and Divyansh Agarwal and Caiming Xiong and Dragomir Radev},
      year={2022},
      eprint={2105.08209},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2105.08209}, 
}

@inproceedings{ladhak-etal-2020-exploring,
    title = "Exploring Content Selection in Summarization of Novel Chapters",
    author = "Ladhak, Faisal  and
      Li, Bryan  and
      Al-Onaizan, Yaser  and
      McKeown, Kathleen",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.453",
    doi = "10.18653/v1/2020.acl-main.453",
    pages = "5043--5054",
    abstract = "We present a new summarization task, generating summaries of novel chapters using summary/chapter pairs from online study guides. This is a harder task than the news summarization task, given the chapter length as well as the extreme paraphrasing and generalization found in the summaries. We focus on extractive summarization, which requires the creation of a gold-standard set of extractive summaries. We present a new metric for aligning reference summary sentences with chapter sentences to create gold extracts and also experiment with different alignment methods. Our experiments demonstrate significant improvement over prior alignment approaches for our task as shown through automatic metrics and a crowd-sourced pyramid analysis.",
}

@inproceedings{mu-etal-2023-time,
    title = "It{'}s about Time: Rethinking Evaluation on Rumor Detection Benchmarks using Chronological Splits",
    author = "Mu, Yida  and
      Bontcheva, Kalina  and
      Aletras, Nikolaos",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-eacl.55",
    doi = "10.18653/v1/2023.findings-eacl.55",
    pages = "736--743",
    abstract = "New events emerge over time influencing the topics of rumors in social media. Current rumor detection benchmarks use random splits as training, development and test sets which typically results in topical overlaps. Consequently, models trained on random splits may not perform well on rumor classification on previously unseen topics due to the temporal concept drift. In this paper, we provide a re-evaluation of classification models on four popular rumor detection benchmarks considering chronological instead of random splits. Our experimental results show that the use of random splits can significantly overestimate predictive performance across all datasets and models. Therefore, we suggest that rumor detection models should always be evaluated using chronological splits for minimizing topical overlaps.",
}

@article{nissim-etal-2020-fair,
    title = "Fair Is Better than Sensational: Man Is to Doctor as Woman Is to Doctor",
    author = "Nissim, Malvina  and
      van Noord, Rik  and
      van der Goot, Rob",
    journal = "Computational Linguistics",
    volume = "46",
    number = "2",
    month = jun,
    year = "2020",
    url = "https://aclanthology.org/2020.cl-2.7",
    doi = "10.1162/coli_a_00379",
    pages = "487--497",
    abstract = "Analogies such as man is to king as woman is to X are often used to illustrate the amazing power of word embeddings. Concurrently, they have also been used to expose how strongly human biases are encoded in vector spaces trained on natural language, with examples like man is to computer programmer as woman is to homemaker. Recent work has shown that analogies are in fact not an accurate diagnostic for bias, but this does not mean that they are not used anymore, or that their legacy is fading. Instead of focusing on the intrinsic problems of the analogy task as a bias detection tool, we discuss a series of issues involving implementation as well as subjective choices that might have yielded a distorted picture of bias in word embeddings. We stand by the truth that human biases are present in word embeddings, and, of course, the need to address them. But analogies are not an accurate tool to do so, and the way they have been most often used has exacerbated some possibly non-existing biases and perhaps hidden others. Because they are still widely popular, and some of them have become classics within and outside the NLP community, we deem it important to provide a series of clarifications that should put well-known, and potentially new analogies, into the right perspective.",
}

@article{olteanu2019social,
  title={Social data: Biases, methodological pitfalls, and ethical boundaries},
  author={Olteanu, Alexandra and Castillo, Carlos and Diaz, Fernando and K{\i}c{\i}man, Emre},
  journal={Frontiers in big data},
  volume={2},
  pages={13},
  year={2019},
  publisher={Frontiers Media SA}
}

@inproceedings{scire-etal-2023-echoes,
    title = "Echoes from Alexandria: A Large Resource for Multilingual Book Summarization",
    author = "Scir{\`e}, Alessandro  and
      Conia, Simone  and
      Ciciliano, Simone  and
      Navigli, Roberto",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.54",
    doi = "10.18653/v1/2023.findings-acl.54",
    pages = "853--867",
    abstract = "In recent years, research in text summarization has mainly focused on the news domain, where texts are typically short and have strong layout features. The task of full-book summarization presents additional challenges which are hard to tackle with current resources, due to their limited size and availability in English only. To overcome these limitations, we present {``}Echoes from Alexandria{''}, or in shortened form, {``}Echoes{''}, a large resource for multilingual book summarization. Echoes featuresthree novel datasets: i) Echo-Wiki, for multilingual book summarization, ii) Echo-XSum, for extremely-compressive multilingual book summarization, and iii) Echo-FairySum, for extractive book summarization. To the best of our knowledge, Echoes {--} with its thousands of books and summaries {--} is the largest resource, and the first to be multilingual, featuring 5 languages and 25 language pairs. In addition to Echoes, we also introduce a new extractive-then-abstractive baseline, and, supported by our experimental results and manual analysis of the summaries generated, we argue that this baseline is more suitable for book summarization than purely-abstractive approaches. We release our resource and software at \url{https://github.com/Babelscape/echoes-from-alexandria} in the hope of fostering innovative research in multilingual booksummarization.",
}

@inproceedings{sheng-etal-2019-woman,
    title = "The Woman Worked as a Babysitter: On Biases in Language Generation",
    author = "Sheng, Emily  and
      Chang, Kai-Wei  and
      Natarajan, Premkumar  and
      Peng, Nanyun",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1339",
    doi = "10.18653/v1/D19-1339",
    pages = "3407--3412",
    abstract = "We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.",
}

@inproceedings{toro-isaza-etal-2023-fairy,
    title = "Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children{'}s Fairy Tales",
    author = "Toro Isaza, Paulina  and
      Xu, Guangxuan  and
      Oloko, Toye  and
      Hou, Yufang  and
      Peng, Nanyun  and
      Wang, Dakuo",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.359",
    doi = "10.18653/v1/2023.acl-long.359",
    pages = "6509--6531",
    abstract = "Social biases and stereotypes are embedded in our culture in part through their presence in our stories, as evidenced by the rich history of humanities and social science literature analyzing such biases in children stories. Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora. Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a story{'}s temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes. Through a case study analyzing gender bias in fairy tales, we demonstrate that our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation.",
}

@inproceedings{tripodi-etal-2019-tracing,
    title = "Tracing Antisemitic Language Through Diachronic Embedding Projections: {F}rance 1789-1914",
    author = "Tripodi, Rocco  and
      Warglien, Massimo  and
      Levis Sullam, Simon  and
      Paci, Deborah",
    editor = "Tahmasebi, Nina  and
      Borin, Lars  and
      Jatowt, Adam  and
      Xu, Yang",
    booktitle = "Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-4715",
    doi = "10.18653/v1/W19-4715",
    pages = "115--125",
    abstract = "We investigate some aspects of the history of antisemitism in France, one of the cradles of modern antisemitism, using diachronic word embeddings. We constructed a large corpus of French books and periodicals issues that contain a keyword related to Jews and performed a diachronic word embedding over the 1789-1914 period. We studied the changes over time in the semantic spaces of 4 target words and performed embedding projections over 6 streams of antisemitic discourse. This allowed us to track the evolution of antisemitic bias in the religious, economic, socio-politic, racial, ethic and conspiratorial domains. Projections show a trend of growing antisemitism, especially in the years starting in the mid-80s and culminating in the Dreyfus affair. Our analysis also allows us to highlight the peculiar adverse bias towards Judaism in the broader context of other religions.",
}

@misc{wang2024weaverfoundationmodelscreative,
      title={Weaver: Foundation Models for Creative Writing}, 
      author={Tiannan Wang and Jiamin Chen and Qingrui Jia and Shuai Wang and Ruoyu Fang and Huilin Wang and Zhaowei Gao and Chunzhao Xie and Chuou Xu and Jihong Dai and Yibin Liu and Jialong Wu and Shengwei Ding and Long Li and Zhiwei Huang and Xinle Deng and Teng Yu and Gangan Ma and Han Xiao and Zixin Chen and Danjun Xiang and Yunxia Wang and Yuanyuan Zhu and Yi Xiao and Jing Wang and Yiru Wang and Siran Ding and Jiayang Huang and Jiayi Xu and Yilihamu Tayier and Zhenyu Hu and Yuan Gao and Chengfeng Zheng and Yueshu Ye and Yihang Li and Lei Wan and Xinyue Jiang and Yujie Wang and Siyu Cheng and Zhule Song and Xiangru Tang and Xiaohua Xu and Ningyu Zhang and Huajun Chen and Yuchen Eleanor Jiang and Wangchunshu Zhou},
      year={2024},
      eprint={2401.17268},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.17268}, 
}

@article{xu2019cinderella,
  title={The Cinderella Complex: Word embeddings reveal gender stereotypes in movies and books},
  author={Xu, Huimin and Zhang, Zhang and Wu, Lingfei and Wang, Cheng-Jun},
  journal={PloS one},
  volume={14},
  number={11},
  pages={e0225385},
  year={2019},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{zhao-etal-2022-impact,
    title = "On the Impact of Temporal Concept Drift on Model Explanations",
    author = "Zhao, Zhixue  and
      Chrysostomou, George  and
      Bontcheva, Kalina  and
      Aletras, Nikolaos",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.298",
    doi = "10.18653/v1/2022.findings-emnlp.298",
    pages = "4039--4054",
    abstract = "Explanation faithfulness of model predictions in natural language processing is typically evaluated on held-out data from the same temporal distribution as the training data (i.e. synchronous settings). While model performance often deteriorates due to temporal variation (i.e. temporal concept drift), it is currently unknown how explanation faithfulness is impacted when the time span of the target data is different from the data used to train the model (i.e. asynchronous settings). For this purpose, we examine the impact of temporal variation on model explanations extracted by eight feature attribution methods and three select-then-predict models across six text classification tasks. Our experiments show that (i) faithfulness is not consistent under temporal variations across feature attribution methods (e.g. it decreases or increases depending on the method), with an attention-based method demonstrating the most robust faithfulness scores across datasets; and (ii) select-then-predict models are mostly robust in asynchronous settings with only small degradation in predictive performance. Finally, feature attribution methods show conflicting behavior when used in FRESH (i.e. a select-and-predict model) and for measuring sufficiency/comprehensiveness (i.e. as post-hoc methods), suggesting that we need more robust metrics to evaluate post-hoc explanation faithfulness. Code will be made publicly available.",
}

