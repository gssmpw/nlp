\section*{Limitations} 

One of the limitations of \ours is that it is more computationally costly than fine-tuned models at test time because of the longer inputs due to the few-shot examples and their corresponding negative samples and explanations. 
However, inference cost for repeating prompts can be significantly lowered by prompt caching.\footnote{\url{https://www.anthropic.com/news/prompt-caching}} 
In addition, inference costs in general are continuously getting lower with optimization efforts that comprehensively span hardware\footnote{\href{https://groq.com/}{Groq} and  \href{https://aws.amazon.com/machine-learning/inferentia/}{AWS Inferentia} are some examples of inference-specific hardware development.} and software~\cite{kwon2023efficient}. 
As the promise of inference-only methods become increasingly evident, we believe these efforts will be further accelerated and lead to even more favorable conditions for methods such as \ours. 

Another limitation of \ours is that it is only effective for models that are able to understand long contexts well. 
In our preliminary experiments, our results on using \ours with smaller models such as Mistral 7B Instruct and GPT-4o mini were poor as these models continued to generate outputs similar in style to what were labeled in-context as bad examples, indicating that they were not able to distinguish between the good and bad examples included in the context.
Therefore, the performance of \ours is dependent on a model's long context understanding. 

Lastly, \ours results in per-user or per-task prompts, which is similar to the limitations of prior work that rely on fine-tuned per-user model parameters. 
Whether we can use \ours to enable a single model to perform personalized task completion for multiple tasks without requiring excessively long prompts by (\textit{i}) discovering methods that maintain or improve performance while compressing the prompt or (\textit{ii}) injecting the information in the prompt for controlling style during decoding is an exciting avenue for future work.





\section*{Generative AI Statement}
No generative AI tools were used in the writing of this work. 
