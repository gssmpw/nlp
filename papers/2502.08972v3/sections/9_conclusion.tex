\section{Conclusion}

In conclusion, we develop \ours, a tuning-free method for personalized alignment that adapts prior work on trial-and-error fine-tuning with scaling inference compute.   
Instead of fine-tuning a model with synthetic negative samples, \ours uses them to augment the prompt and generate explanations that provide further fine-grained guidance on how to align outputs towards a desirable style.
On personalized text generation tasks, \ours outperforms other competitive tuning-free baselines and the previous state-of-the-art.  
\ours provides an approach for leveraging black box models for personalization without any fine-tuning. 
