\section{Method}



\subsection{Preliminary}
\paragraph{AutoRegressive Modeling (AR).} First, an image $I$ in the form of $H\times W \times 3$ is quantized into discrete tokens map $X$ in the form of $h\times w$ by an image tokenizer with $h=H/p, w=W/p$, where p is the down-sampling rate of the tokenizer. Then, according to the raster scanning order, $X$ reshape into 1d sequence $(x_1,x_2,...,x_t), t=h*w$ and the approximate maximum log-likelihood estimation \ref{MLE_vanilla} is used as the training target of the model $\theta$.
\begin{equation}
    \theta_{target} = \arg\max_{\theta} \sum^{T}_{t=1}P_{\theta}(x_t|x_{<t})
    \label{MLE_vanilla}
\end{equation}
In the image generation process, the AR predicts the image token $(x_1,x_2,...,x_t)$ according to the condition $c$ in a prediction manner of `next-token prediction' $\prod^{T}_{t=1}P(x_t|x_{<t},c)$, and finally converts the image token into an image by using a decoder of the image tokenizer.
\subsection{Ours}
\subsubsection{Overview}
Our method still adapts the image tokenizer architecture and `next-token prediction' prediction form of the classic AR model. On this basis, we introduce a set of VF prompts $\Tilde{S}=(s_1,s_2,...,s_k)$ in the training and inference process, and modify the model $\theta$ training target to maximize the log-likelihood function \ref{mle_S}. The way model inference is change to $\prod^{T}_{t=1}P(x_t|x_{<t},\Tilde{S},c)$.
\begin{equation}
    \sum^N_{t=1}\log P_{\theta}(x_t|x_{<t},\Tilde{S},c)
    \label{mle_S}
\end{equation}
\subsubsection{Theoretical Analysis}
\label{theory}
The introduced VF prompt is $\Tilde{S}=(s_1,s_2,...,s_k)$, the generated token sqeuence is $\Tilde{X}=(x_1,x_2,...,x_t)$, the condition is $c$, and the model parameter is $\theta$.

\begin{figure}[t]
  \centering
    \includegraphics[width=\linewidth]{fig/state.pdf}
   \caption{The exhibition of different states with k-length Full-view prompt.}
   \label{fig:state}
\end{figure}

\paragraph{Training Stage} We refer to the derivation of prompt engineering for LLMs in the context of general dynamic programming problems and analyse the impact of introducing prompt engineering in our model while training. As shown in Figure \ref{fig:state}, one sequence shows the different states $i$ with unidirectional transitions between states constrained by the time step $i$. Since there is a target sequence present, for each token prediction during model training, there exists an optimal solution token (\textit{i.e.}, the target token at the corresponding position). Thus, we can express the state transition function as follows:
\begin{equation}
    T(i,j)=
    \begin{cases}
        p_j & \text{if } i=j-1 \\
        p_j*T(i,j-1) & \text{if } i<j-1
    \end{cases}
\end{equation}
$p_j$ represents the probability of the model predicting the optimal state $j$ token at time step $j$. $T(i,j)$ denotes the probability of transitioning from the optimal state $i$ to the optimal state $j$, where the optimal state is defined as a state in which all tokens are the optimal tokens for the current position. Thus, we can formulate $T_{AR}(1,t)$ for the classic AR model and $T_{VF prompt}(1,t)$ for our method as follows:
% Thus, we can identify $T(1,t)=\prod^{T}_{t=1}P_t$ for the classic AR model, and \textcolor{red}{as shown in Figure \ref{fig:state}}, for our method $T'(1,t)$ can be formulated as follows:
\begin{align}
\small
   T_{AR}(1,t) &= T(1,2)*T(2,t) \\
    % T_{VF\_prompt}(1,t) &= T(1,2)*T(2,k+1)*T(k+1,t)
    T_{VF\_prompt}(1,t) &= T(c,k)*T(1,2)**T(2,t)
\end{align}
where k represents the length of the sequence $\Tilde{S}$.

It is easy to infer that, under the ideal condition with the same target, both $T_{AR}(1,t)$ and $T_{VF\_prompt}(1,t)$ should equal to the expression $\prod^{T}_{t=1}P(x_t|x_{<t},c)$, which corresponds to the maximum likelihood estimation (\textit{MLE}) of the target generated image. However, since the limitation of the model ability, what we can do is to approximate the target distribution through \textit{MLE}, these tree equations $T_{AR}(1,t)$, $T_{VF\_prompt}(1,t)$ and $\prod^{T}_{t=1}P(x_t|x_{<t},c)$ are not exactly equal. In this case, due to the introduction of VF prompt, our method gains an additional term $T(c,k)$ compared to the classic AR method.

The final loss of the model is constrained by the cross-entropy between the target sequence and the generated sequence $\Tilde{X}$. While it’s not involved in the cross-entropy calculation of classic AR models, it‘s included in VF prompt's cross-entropy calculation, formatted as $\sum \log T(c,k)$. This term, computed by the model, serves as a bias varying with the VF prompt to help the model avoid instability caused by mismatch between training data and inference scenarios. It maintains a consistent optimization direction across different targets, making it faster to converge to an ideal performance.

% which allows the model to have a set of weights that can be dynamically adjusted based on the condition $c$. Therefore, compared to $T_{AR}(1,t)$, $T(2,k+1)$ makes $T_{VF prompt}(1,t)$ more easily approximated to the target distribution, enabling a model with the same parameter count to converge faster when trained on the same amount of data.

% However, since the model approximates a probability distribution through \textit{MLE}, the above three expressions will not be exactly equal. In this case, due to the introduction of full-view prompt, the model, compared to the classic AR method, gains an additional term $T'(2,k+2))$, which allows the model have a set of weights that can be dynamically adjusted based on the condition $c$. This makes $T'(1,t)$ more easily approximated to the target distribution, enabling a model with the same parameter count to converge faster when trained on the same amount of data.

% The final loss of the model is constrained by the cross-entropy between the target sequence and the generated sequence $\Tilde{X}$.

\begin{figure}[t]
  \centering

\includegraphics[width=\linewidth]{fig/method2.pdf}
   \caption{Our method first receives \textit{Class Token} and \textit{Vision Full-view prompt} as input, and then follows the `next-token prediction' to generate images.
}
   \label{fig:architecture}
\end{figure}
\paragraph{Inference Stage} We analyse the impact of introducing VF prompt on the model's inference phase from the perspective of information entropy. The information entropy of the classic AR model during inference can be expressed as $H(\Tilde{X}|c)$. In contrast, the information entropy of our method with VF prompt during inference can be expressed as $H(\Tilde{X}|\Tilde{S},c)$.
With the definition of entropy, we can derive Eq \ref{eq:entropy1} as follows:
\begin{equation}
    H(\Tilde{X}|\Tilde{S},c) = H(\Tilde{X},\Tilde{S}|c) - H(\Tilde{S}|c)
    \label{eq:entropy1}
\end{equation}
Then we can derive the inequality in eq \ref{ieq:entropy2}.
% \begin{align}
% \small
\begin{align}
    &H(\Tilde{X}|\Tilde{S},c) - H(\Tilde{X}|c) = \nonumber \\
    &H(\Tilde{X},\Tilde{S}|c) - H(\Tilde{X}|c) - H(\Tilde{S}|c) \leq 0
    \label{ieq:entropy2}
\end{align}


% \end{align}
This inequality suggests that, by incorporating VF prompt, our method has less uncertainty during inference compared to classic AR model, which means the generation process is more stable. This reduction in uncertainty helps effectively minimize inconsistencies in the image details represented by the tokens, leading to higher-quality generated images. The more stable token generation process ensures that the generated sequence better preserves the coherence of the visual structure, resulting in images with fewer artifacts and better alignment with the target distribution. 


\subsubsection{Vision Full-view Prompt} 
\label{Prompt}
As shown in Figure \ref{fig:architecture}, we choose two types of vision full-view prompt $\Tilde{S}$ to incorporate into the model's training and inference process.
\begin{enumerate}
    \item We randomly select an image different from the training target while it's still under the same class with the target. After passing it through the image tokenizer, it is converted into tokens, which are then concatenated with the condition $c$ and input into the model. During inference, we randomly choose an image, tokenize it, and use the resulting tokens as input directly. 
    \item We sample a set of indices from the codebook of the image tokenizer based on a uniform distribution, selecting each index with equal probability. The sampled set of indices is then concatenated with the condition $c$ and used as the input to the model.
\end{enumerate}
These two different vision full-view prompts represent two distinct representations used to guide the model in generating images. The first prompt corresponds to a specific category representation called \textit{Class VF prompt}, aimed at helping the model better understand the distribution corresponding to the given condition, thereby generating images that more clearly represent the category information. The second prompt, called \textit{Universal VF prompt}, represents a more universal image distribution and is designed to encourage the model to generate more diverse and varied images, independent of the condition.
% The validity of the VF prompt is discussed in Sec \ref{theory} without explicit categorization, which was made to demonstrate in an experiment that despite the informational differences between the two prompts, they ultimately give good results with little difference.


% \begin{align}
%     \prod^{T}_{t=1}P(x_t|x_{<t},c)
% \end{align}

% \begin{align}
%     \prod^{T}_{t=1}P_t
% \end{align}



% \begin{align}
%     \Tilde{S} &= \{s_1,...,s_t\} \\
%     \prod^{T}_{t=1}P(x_t|x_{<t},\Tilde{S},c)
% \end{align}


% \begin{equation}
%     H(\Tilde{X}|\Tilde{S},c) - H(\Tilde{X}|c) = H(\Tilde{X},\Tilde{S}|c) - H(\Tilde{X}|c) - H(\Tilde{S}|c) \leq 0
% \end{equation}



% \begin{align}
%     \Tilde{S} &= \{s_0,...,s_t\} \\
%     P(x_t|\Tilde{S},x_{<t},y) &= P(s_0|y)*\prod^t_{i=0}P(s_{i+1}|s_i)*\prod^{t-1}_{i=0}P(x_{i+1}|x_i)
% \end{align}

% \begin{equation}
% \begin{aligned}
%     \Tilde{X} &= \{x_0,...,x_t\}
% \end{aligned}
% \end{equation}

% \begin{equation}
% P(\Tilde{X}|\Tilde{S},y) = \frac{P(\Tilde{X}P(\Tilde{S}|\Tilde{X}))P(y|\Tilde{X},\Tilde{S})}{P(\Tilde{S})P(y|\Tilde{S})}
% \end{equation}

% \begin{equation}
% \begin{split}
%     log P(\Tilde{X}|\Tilde{S},y) = log P(\Tilde{X}) + log P(\Tilde{S}|\Tilde{X}) +  \\
%        log P(y|\Tilde{X},\Tilde{S}) - logP(\Tilde{S}) - logP(y|\Tilde{S})
% \end{split}
% \end{equation}

% \begin{equation}
% \begin{split}
%     \nabla_x log P(\Tilde{X}|\Tilde{S},y) = \nabla_xlog P(\Tilde{X}) + \nabla_xlog P(\Tilde{S}|\Tilde{X})\\
%        + \nabla_x log P(y|\Tilde{X},\Tilde{S}) 
% \end{split}
% \end{equation}

% \begin{equation}
%     P(x_0|\overline{S},cls) = P(x_0|cls) 
% \end{equation}

% \subsection{Position embedding}